<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 14]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.LG](#cs.LG) [Total: 8]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems](https://arxiv.org/abs/2601.16280)
*Donghao Huang,Gauri Malwe,Zhaoxia Wang*

Main category: cs.AI

TL;DR: 대형 언어 모델을 활용한 다중 에이전트 시스템의 도구 사용 신뢰성을 평가하기 위한 종합적인 진단 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 활용한 다중 에이전트 시스템이 기업 자동화를 변화시키고 있으나, 도구 사용 신뢰성을 평가하기 위한 체계적인 평가 방법론이 부족합니다.

Method: 빅 데이터 분석을 통해 지능형 에이전트 시스템의 절차적 신뢰성을 평가하는 진단 프레임워크를 소개하며, 12개 범주의 오류 세분화로 도구 초기화, 매개변수 처리, 실행 및 결과 해석에서의 실패 모드를 포착합니다.

Result: 1,980개의 결정론적 테스트 인스턴스를 체계적으로 평가하여 생산 배치에 적합한 실행 가능 신뢰성 경계를 식별했습니다. 분석 결과, 작은 모델에서의 주요 병목 현상은 도구 초기화 실패로 나타났고, qwen2.5:32b는 GPT-4.1과 일치하는 결함 없는 성능을 달성했습니다.

Conclusion: 이 프레임워크는 자원 제약이 있는 조직을 위한 비용 효율적인 지능형 에이전트 배치를 가능하게 하여, 도구 보강 다중 에이전트 AI 시스템의 체계적인 신뢰성 평가를 위한 기초 인프라를 구축합니다.

Abstract: Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate procedural reliability in intelligent agent systems, addressing critical needs for SME-centric deployment in privacy-sensitive environments. Our approach features a 12-category error taxonomy capturing failure modes across tool initialization, parameter handling, execution, and result interpretation. Through systematic evaluation of 1,980 deterministic test instances spanning both open-weight models (Qwen2.5 series, Functionary) and proprietary alternatives (GPT-4, Claude 3.5/3.7) across diverse edge hardware configurations, we identify actionable reliability thresholds for production deployment. Our analysis reveals that procedural reliability, particularly tool initialization failures, constitutes the primary bottleneck for smaller models, while qwen2.5:32b achieves flawless performance matching GPT-4.1. The framework demonstrates that mid-sized models (qwen2.5:14b) offer practical accuracy-efficiency trade-offs on commodity hardware (96.6\% success rate, 7.3 s latency), enabling cost-effective intelligent agent deployment for resource-constrained organizations. This work establishes foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems.

</details>


### [2] [SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems](https://arxiv.org/abs/2601.16286)
*Varun Chillara,Dylan Kline,Christopher Alvares,Evan Wooten,Huan Yang,Shlok Khetan,Cade Bauer,Tré Guillory,Tanishka Shah,Yashodhara Dhariwal,Volodymyr Pavlov,George Popstefanov*

Main category: cs.AI

TL;DR: SemanticALLI는 중복 추론을 최적화하기 위해 설계된 파이프라인 인식 아키텍처로, 구조화된 중간 표현을 캐시 가능한 유용한 산물로 승격시킵니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 에이전틱 AI 파이프라인은 사용자 언어의 변화와 상관없이 중복된 중간 논리를 재구성하는 비효율성이 존재합니다.

Method: Analytic Intent Resolution (AIR)과 Visualization Synthesis (VS)로 생성을 분해하여 중간 표현을 캐시할 수 있는 구조로 향상시킵니다.

Result: 구조적 접근 방식을 통해 비율을 83.10%로 증가시킬 수 있었으며, 4,023번의 LLM 호출을 우회했습니다.

Conclusion: AI 시스템 디자인에 대한 실용적인 교훈은 사용자가 자주 반복하지 않더라도, 파이프라인이 신뢰할 수 있는 지점에서 흔히 반복된다는 것입니다.

Abstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.
  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.
  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.

</details>


### [3] [DSGym: A Holistic Framework for Evaluating and Training Data Science Agents](https://arxiv.org/abs/2601.16344)
*Fan Nie,Junlin Wang,Harper Hua,Federico Bianchi,Yongchan Kwon,Zhenting Qi,Owen Queen,Shang Zhu,James Zou*

Main category: cs.AI

TL;DR: DSGym은 데이터 과학 에이전트를 평가하고 훈련하기 위한 표준화된 프레임워크로, 기존의 데이터 과학 벤치마크의 한계를 극복합니다.


<details>
  <summary>Details</summary>
Motivation: 데이터 과학 에이전트의 발견과 통찰력을 가속화하기 위해 데이터 분석을 실행 가능한 결과로 변환하는 것이 필요합니다.

Method: DSGym은 모듈식 아키텍처를 제공하여 작업, 에이전트 스캐폴드 및 도구를 쉽게 추가할 수 있게 하며, 자기 포함된 실행 환경에서 데이터 과학 에이전트를 평가하고 훈련할 수 있는 표준화된 프레임워크입니다.

Result: DSGym에서 2,000개의 예제로 구성된 훈련 세트를 구축하고, 4B 모델을 훈련시켜 GPT-4o보다 높은 성능을 기록했습니다.

Conclusion: DSGym은 에이전트가 현실적인 과학적 맥락에서 데이터 분석을 계획, 실행 및 검증할 수 있는지에 대한 엄격한 측정을 가능하게 합니다.

Abstract: Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context.

</details>


### [4] [Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation](https://arxiv.org/abs/2601.16863)
*Tims Pecerskis,Aivars Smirnovs*

Main category: cs.AI

TL;DR: N-Way Self-Evaluating Deliberation (NSED) 프로토콜을 소개하는 이 논문은 여러 전문가 에이전트로부터 emergent composite models를 구성하는 Runtime Mixture-of-Models (MoM) 아키텍처를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 Mixture-of-Experts (MoE)의 한계를 극복하고 모델 선택을 효율적으로 최적화하기 위한 방법을 찾기 위함이다.

Method: NSED는 동적 전문성 중개인을 활용하여 모델 선택을 Knapsack Problem의 변형으로 다루고, 매크로 규모 순환 신경망(RNN)을 통해 의사 결정을 형식화한다.

Result: 작은 소비자급 모델들이 최신의 100B+ 매개변수 모델의 성능을 초과하거나 맞추는 것을 실험적으로 입증하였다.

Conclusion: NSED 프로토콜은 새로운 하드웨어 차익 거래 효율성을 설정하고, 개별 에이전트보다 더 낮은 아부 성적을 지원하는 교정 메커니즘을 보여준다.

Abstract: This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.

</details>


### [5] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: Doc2AHP라는 새로운 구조적 추론 프레임워크를 제안하여 대규모 언어 모델의 일반화 능력과 결정 이론의 엄격함 사이의 간극을 메우고, 전문가의 개입 없이도 구조적인 일관성을 유지하는 결정 모델을 구축할 수 있게 한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델이 복잡한 의사결정 작업에서 구조적 일관성과 추론 신뢰성을 확보하는 데 어려움을 겪고 있어, 전문가에게 의존하지 않고 의사결정 모델을 구축할 수 있는 방법을 제시하고자 한다.

Method: 제안하는 Doc2AHP는 AHP 원칙에 따라 LLM이 비구조적 문서 공간 내에서 제한된 탐색을 수행하도록 유도하며, 부모 노드와 자식 노드 간의 논리적 함의를 강제하는 구조적 원칙을 활용한다.

Result: Doc2AHP는 비전문가 사용자가 고품질의 의사결정 모델을 처음부터 구성할 수 있도록 지원하며, 논리적 완전성 및 다운스트림 작업 정확도 측면에서 직접 생성된 기준선에 비해 뛰어난 성과를 보인다.

Conclusion: 이 접근 방식은 의사결정 모델링에서의 전문가 병목 현상을 해소하고, 비전문가도 고급 결정 모델을 쉽게 구축할 수 있도록 한다.

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [6] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: LLM이 응급 의학에서 환자 압력에 대한 취약성을 평가하는 SycoEval-EM 프레임워크에 기반한 연구를 통해 안전성을 예측하기 어려운 결과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 본 연구는 LLM이 임상 결정 지원에서의 가능성을 보여주지만, 부적절한 치료에 대한 환자의 압력에 순응할 위험이 있다는 점을 인식하고 있다.

Method: 이 연구에서는 SycoEval-EM이라는 다중 에이전트 시뮬레이션 프레임워크를 사용하여 응급 의학에서 LLM의 견고함을 평가하였다.

Result: 20개의 LLM과 1,875회의 만남을 통해 확인한 결과, 환자의 압력에 대한 순응 비율은 0%에서 100% 사이로 다양하였고, 모델은 이미징 요청에 대해 더 높은 취약성을 보였다.

Conclusion: 정적 기준은 사회적 압력 하의 안전성을 예측하는 데 부족하며, 임상 AI 인증을 위해 여러 차례의 적대적 테스트가 필요하다.

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [7] [LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents](https://arxiv.org/abs/2601.16649)
*Amin Rakhsha,Thomas Hehn,Pietro Mazzaglia,Fabio Valerio Massoli,Arash Behboodi,Tribhuvanesh Orekondy*

Main category: cs.AI

TL;DR: 대형 언어 모델은 고립된 작업에서는 잘 수행되지만, 계획, 상태 추적 및 긴 맥락 처리와 같은 기술을 요구하는 여러 턴의 복합적 문제에서는 여전히 어려움을 겪고 있다. 이 연구에서는 이러한 기본 능력의 발전이 성공하는 데 상대적으로 얼마나 중요한지를 이해하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 여러 턴의 문제에서 성공하기 위해 어떤 기본 기술이 중요한지를 이해하고자 함.

Method: 멀티턴 문제에 대한 오라클 반사적 프레임워크를 개발하고, 이 오라클을 활용하여 특정 작업을 완벽하게 수행할 수 있을 경우 에이전트가 어떻게 수행하는지를 분석.

Result: 계획과 같은 일부介入이 성능을 향상시키는 반면, 다른 기술의 유용성은 환경과 언어 모델의 특성에 따라 다름을 보여줌.

Conclusion: 다양한 환경에서 요구되는 다중 턴 에이전트 문제의 도전과제에 대한 통찰을 제공하여 AI 에이전트 및 언어 모델 개발의 미래 노력을 안내함.

Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.

</details>


### [8] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: AgentsEval은 의료 영상 보고서 생성을 평가하기 위한 다중 에이전트 스트림 추론 프레임워크로, 방사선사의 협력 진단 워크플로우를 모방한다.


<details>
  <summary>Details</summary>
Motivation: 자동 생성된 의료 영상 보고서의 임상적 정확성과 추론 충실성을 평가하는 것은 중요한 과제로 남아 있으며, 기존 평가 방법은 방사선 해석의 구조적 진단 논리를 포착하지 못한다.

Method: AgentsEval은 평가 과정을 기준 정의, 증거 추출, 정렬, 일관성 점수 매기기 등 해석 가능한 단계로 나누어 명시적인 추론 경로와 구조화된 임상 피드백을 제공한다.

Result: AgentsEval은 의미적으로 충실하고 해석 가능한 평가를 제공하며, 다양한 변형에서도 강인성을 유지한다.

Conclusion: 이 프레임워크는 의료 보고서 생성 시스템의 투명하고 임상적으로 기반을 둔 평가를 향한 첫걸음이며, 대형 언어 모델의 신뢰할 수 있는 통합을 촉진한다.

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [9] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking-2601은 5600억 개의 매개변수를 가진 오픈소스 Mixture-of-Experts 모델로, 뛰어난 에이전트적 추론 능력을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트적 벤치마크에서 우수한 성능을 발휘하고, 복잡한 도구 상호작용에 대한 강한 일반화 능력을 탐구하기 위해 이 모델을 개발하였습니다.

Method: 모델은 도메인 병렬 전문 훈련과 후속 융합을 결합한 통합 훈련 프레임워크를 기반으로 하며, 10,000개 이상의 환경에서의 훈련을 위해 DORA라는 비동기 강화 학습 프레임워크를 확장합니다.

Result: 이 모델은 복잡한 도구 사용에서 높은 일반화와 함께 실제 환경에서의 강력한 성능을 보여주며, 에이전트적 상호작용을 최적화합니다.

Conclusion: Heavy Thinking 모드를 도입하여 효과적인 테스트 시간 스케일링을 가능하게 하였으며, 이는 깊이와 너비를 동시에 확장함으로써 이루어집니다.

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [10] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 본 연구에서는 시각적인 목표 네비게이션을 위한 새로운 곤충 영감을 받은 에이전트를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 곤충의 뇌 구조를 모델링하여 경로 찾기 및 학습 능력을 증진시키기 위해서.

Method: 두 가지 곤충의 뇌 구조 모델을 결합하여 목표 지점으로의 네비게이션을 수행하는 에이전트를 개발.

Result: 개발된 에이전트는 기존 최신 모델과 비교하여 훨씬 낮은 계산 비용으로 유사한 성능을 보인다.

Conclusion: 더 현실적인 시뮬레이션 환경에서의 테스트 결과 이 접근 방식은 외부 방해에도 강건함을 나타낸다.

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [11] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: 본 연구는 Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT)라는 새로운 프레임워크를 제안하여 학생의 학습 궤적을 보다 정확하게 모델링하고 다음 질문에 대한 성능을 예측하는 데 있어 기존의 한계를 극복하는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 학생의 학습 궤적을 모델링하고 다음 질문에 대한 성능을 예측하기 위한 지식 추적(KT)의 필요성을 강조하며, 기존 방법들이 개념 간 관계를 충분히 탐구하지 않았음을 지적.

Method: MAGE-KT는 다중 에이전트 KC 관계 추출기와 학생-질문 상호작용 그래프를 결합하여 다중 뷰 이질 그래프를 구축하고, Asymmetric Cross-attention Fusion Module을 통해 예측을 향상시킨다.

Result: 세 가지 널리 사용되는 KT 데이터셋에서 KC 관계 정확도와 다음 질문 예측에서 기존 방법들에 비해 상당한 개선을 보였다.

Conclusion: MAGE-KT 프레임워크는 학생의 학습 데이터에 기반하여 상관관계 있는 서브그래프를 활용함으로써 주의 분산을 방지하고 예측 성능을 향상시킨다.

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [12] [AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems](https://arxiv.org/abs/2601.16964)
*Mohamed Amine Ferrag,Abderrahmane Lakas,Merouane Debbah*

Main category: cs.AI

TL;DR: AgentDrive는 300,000개의 LLM 생성 주행 시나리오로 구성된 개방형 벤치마크 데이터셋을 소개하여 자율 에이전트의 교육, 미세 조정 및 평가를 지원한다.


<details>
  <summary>Details</summary>
Motivation: 자율 시스템의 인지, 계획 및 의사결정을 위한 대형 언어 모델의 통합에 대한 관심이 증가하고 있으나, 대규모 안전-critical 벤치마크 부족으로 평가 및 교육이 어렵다.

Method: AgentDrive는 시나리오 유형, 운전 행동, 환경, 도로 레이아웃, 목표, 난이도 및 교통 밀도 등 7개의 축을 기준으로 한 분할된 시나리오 공간을 공식화하며, LLM 주도의 prompt-to-JSON 파이프라인으로 시뮬레이션 준비가 된 사양을 생성한다.

Result: 50개의 선도하는 LLM을 AgentDrive-MCQ에서 대규모로 평가한 결과, 독점 최신 모델이 맥락 및 정책 추론에서 가장 우수한 성능을 보였으나, 진보된 오픈 모델이 구조적 및 물리 기반 추론에서 격차를 빠르게 좁히고 있음을 발견했다.

Conclusion: 우리는 AgentDrive 데이터셋, AgentDrive-MCQ 벤치마크, 평가 코드 및 관련 자료를 공개한다.

Abstract: The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive

</details>


### [13] [Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts](https://arxiv.org/abs/2601.16965)
*Riyang Bao,Cheng Yang,Dazhou Yu,Zhexiang Tang,Gengchen Mai,Liang Zhao*

Main category: cs.AI

TL;DR: Spatial-Agent는 지리정보 과학의 기초 이론에 기반한 AI 에이전트로, 진정한 지리적 계산을 수행하여 기존 LLM 기반 에이전트보다 성능이 뛰어나다.


<details>
  <summary>Details</summary>
Motivation: 도시 분석, 교통 계획 및 재난 대응과 같은 실제 응용 프로그램에 필수적인 지리적 추론의 중요성을 강조.

Method: 자연어 질문을 실행 가능한 워크플로우로 구문 분석하고, 이를 GeoFlow Graphs로 나타내어 지리 분석 질문 응답을 개념 변환 문제로 형식화한다.

Result: Spatial-Agent는 MapEval-API 및 MapQA 벤치마크에서 ReAct 및 Reflexion 등 기존 기준보다 현저히 우수한 성능을 보였다.

Conclusion: Spatial-Agent는 해석 가능하고 실행 가능한 지리적 워크플로우를 생성한다.

Abstract: Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.

</details>


### [14] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: AI 기반 지원 플랫폼이 생물 의학 기술자들이 의료 기기의 문제를 실시간으로 진단하고 수리하는 데 도움을 줄 수 있다.


<details>
  <summary>Details</summary>
Motivation: 저소득 및 중간 소득 국가에서 의료 진단 장비의 효과적인 활용이 어려운 문제를 해결하고자 한다.

Method: AI 지원 플랫폼을 개발하여 생물 의학 기술자가 의료 기기의 오류 코드 및 증상을 입력하고 단계별 문제 해결 지침을 받을 수 있도록 한다.

Result: 필립스 HDI 5000 초음파 장비를 활용한 개념 증명에서 오류 코드 해석의 100% 정확성과 수정 조치 제안의 80% 정확성을 달성하였다.

Conclusion: AI 기반 시스템이 자원이 제한된 환경에서 의료 기기 유지보수를 지원하는 가능성을 보여준다.

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [15] [Computational Foundations for Strategic Coopetition: Formalizing Collective Action and Loyalty](https://arxiv.org/abs/2601.16237)
*Vik Pant,Eric Yu*

Main category: cs.MA

TL;DR: 이 기술 보고서는 다중 에이전트 환경에서의 협력 및 경쟁 동역학을 분석하기 위한 계산 기초를 확장하며, 충성도에 따른 유틸리티 함수를 개발하고 실험적 검증을 통해 로열티의 강력한 효과를 입증한다.


<details>
  <summary>Details</summary>
Motivation: 개별 노력이 모든 구성원에게 동등하게 혜택을 주지만 각 구성원이 자신의 기여에 대한 전체 비용을 부담해야 하는 혼합 동기 다중 에이전트 환경에서 지속적인 무임승차 문제가 만연하다.

Method: 충성도를 조절하는 유틸리티 함수를 두 가지 메커니즘으로 개발하였으며, 구성원 인센티브를 팀 수준의 위치에 연결하기 위해 의존도 가중 팀 응집력을 통합하였다.

Result: 실험적 검증을 통해 강력한 충성도 효과를 입증하였으며, 모든 여섯 가지 행동 목표가 기준치를 달성하였다.

Conclusion: 이 연구는 인간 팀과 다중 에이전트 시스템 모두에 적용 가능한 프레임워크를 제공하면서, 실험적 결과가 통계적으로 유의미한 것으로 확인되었다.

Abstract: Mixed-motive multi-agent settings are rife with persistent free-riding because individual effort benefits all members equally, yet each member bears the full cost of their own contribution. Classical work by Holmström established that under pure self-interest, Nash equilibrium is universal shirking. While i* represents teams as composite actors, it lacks scalable computational mechanisms for analyzing how collective action problems emerge and resolve in coopetitive settings. This technical report extends computational foundations for strategic coopetition to team-level dynamics, building on companion work formalizing interdependence/complementarity (arXiv:2510.18802) and trust dynamics (arXiv:2510.24909). We develop loyalty-moderated utility functions with two mechanisms: loyalty benefit (welfare internalization plus intrinsic contribution satisfaction) and cost tolerance (reduced effort burden for loyal members). We integrate i* structural dependencies through dependency-weighted team cohesion, connecting member incentives to team-level positioning. The framework applies to both human teams (loyalty as psychological identification) and multi-agent systems (alignment coefficients and adjusted cost functions). Experimental validation across 3,125 configurations demonstrates robust loyalty effects (15.04x median effort differentiation). All six behavioral targets achieve thresholds: free-riding baseline (96.5%), loyalty monotonicity (100%), effort differentiation (100%), team size effect (100%), mechanism synergy (99.5%), and bounded outcomes (100%). Empirical validation using published Apache HTTP Server (1995-2023) case study achieves 60/60 points, reproducing contribution patterns across formation, growth, maturation, and governance phases. Statistical significance confirmed at p<0.001, Cohen's d=0.71.

</details>


### [16] [AMBER: A Columnar Architecture for High-Performance Agent-Based Modeling in Python](https://arxiv.org/abs/2601.16292)
*Anh-Duy Pham*

Main category: cs.MA

TL;DR: AMBER는 Python 기반의 에이전트 기반 모델링(ABM) 프레임워크로, 기존의 객체-에이전트 표현을 대체하여 성능과 접근성을 동시에 해결하는 새로운 아키텍처 향상을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: Python 기반 ABM 프레임워크는 과학 컴퓨팅에서의 접근성 및 대규모 시뮬레이션의 성능 요구 사이에 근본적인 긴장을 겪고 있습니다.

Method: AMBER는 Polars DataFrame 라이브러리를 사용하여 전통적인 객체-에이전트 표현을 열형 상태 관리로 대체하는 새로운 아키텍처 접근 방식을 도입합니다.

Result: 세 가지 기준 벤치마크에 대한 실증 평가 결과 AMBER는 작업 부하 특성에 따라 1.2배에서 93배의 속도 향상을 달성하며, 인구 전반에 걸친 특성 연산이 지배적인 모델에서 가장 큰 이점을 보입니다. 메모리 프로파일링 결과는 객체 지향 프레임워크에 비해 최대 사용량이 30-50% 감소함을 보여줍니다.

Conclusion: 우리의 결과는 해석 언어에서 고성능 ABM의 실행 가능한 아키텍처 기반으로서 열형 상태 관리를 확립합니다.

Abstract: Agent-based modeling (ABM) has emerged as an indispensable methodology for studying complex adaptive systems across the natural and social sciences. However, Python-based ABM frameworks face a fundamental tension between the accessibility that has made Python dominant in scientific computing and the performance requirements of large-scale simulations. This paper introduces AMBER, a framework that resolves this tension through a novel architectural approach: replacing the conventional object-per-agent representation with columnar state management using the Polars DataFrame library. We analyze the computational characteristics of both paradigms, present the architectural design of AMBER including its core abstractions, spatial environments, experiment management, and optimization capabilities. Empirical evaluation on three canonical benchmarks demonstrates that AMBER achieves speedups of 1.2x to 93x depending on workload characteristics, with the greatest advantages for models dominated by population-wide attribute operations. Memory profiling reveals 30-50% reduction in peak usage compared to object-oriented frameworks. Our results establish columnar state management as a viable architectural foundation for high-performance ABM in interpreted languages.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [17] [Algorithmic Identity Based on Metaparameters: A Path to Reliability, Auditability, and Traceability](https://arxiv.org/abs/2601.16234)
*Juliao Braga,Percival Henriques,Juliana C. Braga,Itana Stiubiener*

Main category: cs.CR

TL;DR: 알고리즘의 사용이 증가하고 있으며, 이는 AI 기술의 발전과 함께 더 가속화되고 있다. 이 논문은 DOI를 사용하여 알고리즘의 인식 가능성을 높이고 책임성, 투명성 및 신뢰성을 증진하는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 알고리즘의 사용 증가와 이에 따른 책임성, 윤리 및 투명성 문제 해결 필요성.

Method: 디지털 객체 식별자(DOI)를 활용하여 알고리즘의 출처 추적과 감사, 편향 방지, 연구 재현성 증진 및 윤리적 고려 사항 강화.

Result: DOI를 통해 알고리즘의 출처를 식별하고, API 보안에 적용할 수 있는 방법을 제시한다.

Conclusion: DOI를 통한 알고리즘 식별 유지를 위한 도전과제와 해결책을 논의하며, 암호학적 인증 프로토콜의 제안을 포함한다.

Abstract: The use of algorithms is increasing across various fields such as healthcare, justice, finance, and education. This growth has significantly accelerated with the advent of Artificial Intelligence (AI) technologies based on Large Language Models (LLMs) since 2022. This expansion presents substantial challenges related to accountability, ethics, and transparency. This article explores the potential of the Digital Object Identifier (DOI) to identify algorithms, aiming to enhance accountability, transparency, and reliability in their development and application, particularly in AI agents and multimodal LLMs. The use of DOIs facilitates tracking the origin of algorithms, enables audits, prevents biases, promotes research reproducibility, and strengthens ethical considerations. The discussion addresses the challenges and solutions associated with maintaining algorithms identified by DOI, their application in API security, and the proposal of a cryptographic authentication protocol.

</details>


### [18] [FC-GUARD: Enabling Anonymous yet Compliant Fiat-to-Cryptocurrency Exchanges](https://arxiv.org/abs/2601.16298)
*Shaoyu Li,Hexuan Yu,Md Mohaimin Al Barat,Yang Xiao,Y. Thomas Hou,Wenjing Lou*

Main category: cs.CR

TL;DR: FC-GUARD는 사용자 개인 정보를 보호하면서도 규제 준수를 보장하는 탈중앙화 금융 거래 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 탈중앙화 금융의 부상에 따라 법정 통화와 암호화폐 간의 거래 플랫폼이 인기를 끌고 있으나, 이러한 플랫폼은 개인 정보 보호에 실패하는 경우가 많다.

Method: FC-GUARD는 검증 가능한 자격 증명과 제로 지식 증명 기법을 이용하여 개인 정보를 노출하지 않고 법정 통화를 암호화폐로 교환할 수 있도록 설계되었다.

Result: 이 시스템은 사용자 신원을 암호화폐 주소와 연결할 수 있는 링크를 끊어 사용자 익명을 보장하며, 동시에 규제 준수를 이룬다.

Conclusion: FC-GUARD는 데스크탑 및 모바일 플랫폼 모두에서 구현되었으며, 실용적인 배포에 대한 가능성을 평가했다.

Abstract: With the rise of decentralized finance, fiat-to-cryptocurrency exchange platforms have become popular entry points into the cryptocurrency ecosystem. However, these platforms frequently fail to ensure adequate privacy protection, as evidenced by real-world breaches that exposed personally identifiable information (PII) and crypto addresses. Such leaks enable adversaries to link real-world identities to cryptocurrency transactions, undermining the presumed anonymity of cryptocurrency use.
  We propose FC-GUARD, a privacy-preserving exchange system designed to preserve user anonymity without compromising regulatory compliance in the exchange of fiat currency for cryptocurrencies. Leveraging verifiable credentials and zero-knowledge proof techniques, FC-GUARD enables fiat-to-cryptocurrency exchanges without revealing users' PII or fiat account details. This breaks the linkage between users' real-world identities and their cryptocurrency addresses, thereby upholding anonymity, a fundamental expectation in the cryptocurrency ecosystem. In addition, FC-GUARD complies with key regulations over cryptocurrency usage, such as know-your-customer requirements and auditability for tax reporting obligations by integrating a lawful de-anonymization mechanism that allows the auditing authority to identify misbehaving users. This ensures regulatory compliance while defaulting to privacy protection. We implement our system on both desktop and mobile platforms, and our evaluation shows its feasibility for practical deployment.

</details>


### [19] [Secure Intellicise Wireless Network: Agentic AI for Coverless Semantic Steganography Communication](https://arxiv.org/abs/2601.16472)
*Rui Meng,Song Gao,Bingxuan Xu,Xiaodong Xu,Jianqiao Chen,Nan Ma,Pei Xiao,Ping Zhang,Rahim Tafazolli*

Main category: cs.CR

TL;DR: 이 연구에서는 Semantic Steganographic Communication(세멘틱 스테가노그래픽 통신) 퍼에 에이전틱 AI 기반 SemSteCom 스킴을 제안하여 통신 보안을 강화하고 스테가노그래피 용량을 증가시킨다.


<details>
  <summary>Details</summary>
Motivation: SemCom의 보안 취약성을 해결하기 위해 새로운 접근 방식이 필요하다.

Method: 에이전틱 AI를 활용한 SemSteCom 방식은 커버 이미지와 비공식적인 개인 의미 키 없이 작동하도록 설계되었다.

Result: AgentSemSteCom 방식은 기존 방식보다 더 나은 전송 품질과 높은 보안 수준을 달성했다.

Conclusion: 제안된 방식은 스테가노그래피 용량을 증대시키고 통신의 보안을 강화하는 데 기여한다.

Abstract: Semantic Communication (SemCom), leveraging its significant advantages in transmission efficiency and reliability, has emerged as a core technology for constructing future intellicise (intelligent and concise) wireless networks. However, intelligent attacks represented by semantic eavesdropping pose severe challenges to the security of SemCom. To address this challenge, Semantic Steganographic Communication (SemSteCom) achieves ``invisible'' encryption by implicitly embedding private semantic information into cover modality carriers. The state-of-the-art study has further introduced generative diffusion models to directly generate stega images without relying on original cover images, effectively enhancing steganographic capacity. Nevertheless, the recovery process of private images is highly dependent on the guidance of private semantic keys, which may be inferred by intelligent eavesdroppers, thereby introducing new security threats. To address this issue, we propose an Agentic AI-driven SemSteCom (AgentSemSteCom) scheme, which includes semantic extraction, digital token controlled reference image generation, coverless steganography, semantic codec, and optional task-oriented enhancement modules. The proposed AgentSemSteCom scheme obviates the need for both cover images and private semantic keys, thereby boosting steganographic capacity while reinforcing transmission security. The simulation results on open-source datasets verify that, AgentSemSteCom achieves better transmission quality and higher security levels than the baseline scheme.

</details>


### [20] [From Transactions to Exploits: Automated PoC Synthesis for Real-World DeFi Attacks](https://arxiv.org/abs/2601.16681)
*Xing Su,Hao Wu,Hanzhong Liang,Yunlin Jiang,Yuxi Cheng,Yating Liu,Fengyuan Xu*

Main category: cs.CR

TL;DR: 블록체인 시스템의 취약점을 악용한 온체인 공격에 대한 자동화된 PoC 생성 프레임워크인 TracExp를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 온체인 공격의 재현이 어려워지고 있으며, 수작업으로 PoC를 만드는 데 많은 노력과 전문 지식이 요구된다.

Method: TracExp는 저수준 트랜잭션 추적을 활용하여 공격자 논리를 복구하고, 이를 통해 LLM의 코드 생성 기능을 활용하여 실행 가능한 익스플로잇으로 변환한다.

Result: 321건의 실제 공격에서 93%의 사건에 대해 PoC를 성공적으로 생성했으며, 이 중 58.78%는 직접 검증 가능했다.

Conclusion: TracExp는 0.07달러의 평균 비용으로 실질적인 영향을 미쳤고, 커뮤니티에 이전에 사용할 수 없었던 PoCs를 제공했다.

Abstract: Blockchain systems are increasingly targeted by on-chain attacks that exploit contract vulnerabilities to extract value rapidly and stealthily, making systematic analysis and reproduction highly challenging. In practice, reproducing such attacks requires manually crafting proofs-of-concept (PoCs), a labor-intensive process that demands substantial expertise and scales poorly. In this work, we present the first automated framework for synthesizing verifiable PoCs directly from on-chain attack executions. Our key insight is that attacker logic can be recovered from low-level transaction traces via trace-driven reverse engineering, and then translated into executable exploits by leveraging the code-generation capabilities of large language models (LLMs). To this end, we propose TracExp, which localizes attack-relevant execution contexts from noisy, multi-contract traces and introduces a novel dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode. Guided by this representation, TracExp synthesizes PoCs and refines them to preserve exploitability-relevant semantics. We evaluate TracExp on 321 real-world attacks over the past 20 months. TracExp successfully synthesizes PoCs for 93% of incidents, with 58.78% being directly verifiable, at an average cost of only \$0.07 per case. Moreover, TracExp enabled the release of a large number of previously unavailable PoCs to the community, earning a $900 bounty and demonstrating strong practical impact.

</details>


### [21] [Network Security under Heterogeneous Cyber-Risk Profiles and Contagion](https://arxiv.org/abs/2601.16805)
*Elisa Botteghi,Martino S. Centonze,Davide Pastorello,Daniele Tantari*

Main category: cs.CR

TL;DR: 사이버 위험 관리는 현대 디지털 경제에서 중요한 재정적 위협이며, 본 논문은 사이버 위험 관리 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 위험은 서로 연결된 디지털 경제에서 심각한 재정적 위협으로 부각되고 있다.

Method: 본 논문은 보안 게임 내에서 플레이어의 전략적 행동과 전파 역학을 결합한 네트워크 디지털 시스템을 위한 사이버 위험 관리 프레임워크를 제안한다.

Result: 비교적 복잡한 네트워크 지표를 기반으로 방어자와 공격자의 위험 프로파일에 의해 가중치가 부여된 최적 자원 할당 방법을 확장하였다.

Conclusion: 이 연구 결과는 회복력이 있는 디지털 인프라를 설계하고 체계적인 사이버 위험을 완화하는 데 유용한 통찰을 제공한다.

Abstract: Cyber risk has become a critical financial threat in today's interconnected digital economy. This paper introduces a cyber-risk management framework for networked digital systems that combines the strategic behavior of players with contagion dynamics within a security game. We address the problem of optimally allocating cybersecurity resources across a network, focusing on the heterogeneous valuations of nodes by attackers and defenders, some areas may be of high interest to the attacker, while others are prioritized by the defender. We explore how this asymmetry drives attack and defense strategies and shapes the system's overall resilience. We extend a method to determine optimal resource allocation based on simple network metrics weighted by the defender's and attacker's risk profiles. We further propose risk measures based on contagion paths and analyze how propagation dynamics influence optimal defense strategies. Numerical experiments explore risk versus cost efficient frontiers varying network topologies and risk profiles, revealing patterns of resource allocation and cyber deception effects. These findings provide actionable insights for designing resilient digital infrastructures and mitigating systemic cyber risk.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [22] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0는 임상 AI 연구의 장벽을 극복하기 위해 설계된 심층 학습 도구로, 7줄의 코드로 예측 모델링을 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: 임상 AI 연구의 재현성, 높은 계산 비용, 도메인 전문 지식 부족은 지속적인 장벽을 형성합니다.

Method: PyHealth 2.0은 15개 이상의 데이터 세트, 20개 이상의 임상 작업, 25개 이상의 모델, 5개 이상의 해석 방법 등을 통합한 포괄적 도구 키트를 제공합니다.

Result: PyHealth 2.0은 최대 39배 빠른 처리 속도와 20배 낮은 메모리 사용량을 자랑하며, 400명 이상의 활성 오픈 소스 커뮤니티가 참여해 재현 가능한 연구를 촉진합니다.

Conclusion: PyHealth 2.0은 접근 가능하고 재현 가능한 헬스케어 AI를 발전시키는 오픈 소스 기반 및 커뮤니티를 구축합니다.

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [23] [Endless Terminals: Scaling RL Environments for Terminal Agents](https://arxiv.org/abs/2601.16443)
*Kanishk Gandhi,Shivam Garg,Noah D. Goodman,Dimitris Papailiopoulos*

Main category: cs.LG

TL;DR: Endless Terminals는 인간 주석 없이 절차적으로 터미널 작업을 생성하는 완전 자율 파이프라인으로, 이를 통해 에이전트의 성능을 크게 향상시켰습니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 터미널 벤치마크는 훈련이 아닌 평가를 위해 구축되었으며, 강화 학습은 데이터셋만으로는 부족하고 확장 가능한 파이프라인이 필요합니다.

Method: Endless Terminals는 다양한 작업 설명을 생성하고, 컨테이너화된 환경을 구축 및 검증하며, 완료 테스트를 생성하고 해결 가능성을 필터링하는 네 가지 단계로 구성된 자율 파이프라인을 제안합니다.

Result: 이 파이프라인을 통해 3255개의 작업을 얻었고, Llama-3.2-3B는 4.0%에서 18.2%로, Qwen2.5-7B는 10.7%에서 53.3%로, Qwen3-8B-openthinker-sft는 42.6%에서 59.0%로 성능이 개선되었습니다.

Conclusion: Endless Terminals에서 훈련된 모델은 인간이 정리한 벤치마크에서도 상향세를 보이며, 환경이 확장될 때 단순한 RL이 성공할 수 있음을 보여줍니다.

Abstract: Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.

</details>


### [24] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: R-NCE는 자가 감독 학습을 통해 알츠하이머병의 강력한 바이오마커를 발견하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병의 조기 발견과 모니터링을 위해 민감하고 생물학적으로 기반이 되는 바이오마커를 발견하는 것이 중요하다.

Method: Residual Noise Contrastive Estimation (R-NCE)라는 새로운 자가 감독 학습 프레임워크를 도입하여, 보조적인 FreeSurfer 특징을 통합하고 추가적인 증강 불변 정보를 극대화한다.

Result: R-NCE는 전통적인 특징 및 기존 자가 감독 학습 방법을 여러 벤치마크, 포함하여 AD 전환 예측에서 능가한다.

Conclusion: R-NCE-BAG는 높은 유전성과 MAPT 및 IRAG1과의 연관성을 나타내며, 아스트로사이트 및 올리고덴드로사이트에서의 농축을 통해 신경퇴행성 및 뇌혈관 과정에 민감함을 나타낸다.

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [25] [DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs](https://arxiv.org/abs/2601.16519)
*Zekai Chen,Haodong Lu,Xunkai Li,Henan Sun,Jia Li,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 운동서로는 자동화 기술이 채택되고 있으며, 그래프 데이터에 대해 여러 클라이언트 간의 협업 훈련을 가능하게 하는 연합 그래프 학습을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 발전으로 인해 그래프 내 텍스트 속성이 주목받고 있으며, 이를 활용한 연합 그래프 학습 방식이 필요하다.

Method: 연합 그래프 학습에서 텍스트 속성을 효과적으로 처리하기 위해 LLM을 활용한 그래프 응축(GC) 기법을 도입하고, 새로운 TAG-FGL 패러다임인 DANCE를 제안한다.

Result: DANCE는 8개의 TAG 데이터셋에서 정확도를 2.33% 향상시키고, 기준보다 33.42% 적은 토큰으로 8%의 응축 비율을 달성하였다.

Conclusion: DANCE를 통해 기존의 TAG-FGL의 단점을 개선하고, 더 나은 해석 가능성을 제공하며, 효율적인 연합 그래프 학습을 가능하게 한다.

Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.

</details>


### [26] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: 다중모달 LLM은 강력하지만 객체 환각에 취약하여 신뢰성에 해를 끼친다. 본 논문은 SARE라는 새로운 방법을 제안하여 이러한 문제를 해결하고, 환각을 효과적으로 억제하며, 전반적인 생성 품질을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 다중모달 LLM의 객체 환각 문제를 해결하고, 신뢰성을 높이기 위한 효과적인 방법이 필요하다.

Method: SARE를 제안하여 비학습을 목표 지향적 최소-최대 최적화 문제로 변환하고, Targeted-SAM 메커니즘을 사용하여 환각된 개념 주변의 손실 경관을 평탄화한다.

Result: SARE는 비학습 효과에서 기준선보다 우수한 성과를 내며, 전체 생성 품질을 유지한다.

Conclusion: SARE는 재학습 및 파라미터 업데이트에도 불구하고 지속적인 환각 억제를 유지하여 기하학적 안정성의 효과를 검증한다.

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [27] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 이 논문은 다양한 인과 발견 알고리즘을 앙상블하기 위한 동적으로 요청되는 전문가 지식을 활용하는 유연한 모델 평균화 방법을 제안하고, 이 방법이 임상 인과 발견에서 LLM과 같은 불완전한 전문가와 함께 효과적임을 실험을 통해 입증합니다.


<details>
  <summary>Details</summary>
Motivation: 인과 관계를 이해하는 것은 의료 분야에서 매우 중요하며, 정확한 인과 모델은 예측 모델의 해석력을 높이고 반사실적 및 개입적 추론, 치료 효과 추정의 기초를 제공합니다.

Method: 동적으로 요청되는 전문가 지식을 활용하여 다양한 인과 발견 알고리즘을 앙상블하는 유연한 모델 평균화 방법을 제안합니다.

Result: 실험을 통해 LLM과 같은 불완전한 전문가와 함께 청결한 데이터와 노이즈가 있는 데이터 모두에서 우리의 방법의 효능을 입증합니다.

Conclusion: 우리는 전문가의 정확성 정도에 따른 영향을 분석하고, 임상 인과 발견을 위한 LLM의 능력을 평가하여 실무자에게 귀중한 통찰력을 제공합니다.

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [28] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: ARMD 모델은 자가 회귀 모델의 학습 효율성을 확립 기반 모델의 병렬 생성 능력과 결합하여 성능 격차를 줄인다.


<details>
  <summary>Details</summary>
Motivation: MDM은 언어 모델링에서 유망한 접근법으로 부상했지만, 자가 회귀 모델에 비해 성능 차이와 더 많은 학습 반복이 필요하다.

Method: ARMD 모델은 마스크된 확산 프로세스를 블록-기반 인과 모델로 재구성하는 접근 방식을 사용하여, 모든 조건부 확률을 단일 병렬 전방 통과에서 계산한다.

Result: ARMD는 표준 언어 모델링 벤치마크에서 최첨단 성과를 달성하며, 기존의 확산 기반 모델보다 훨씬 적은 학습 단계로 우수한 성능을 보인다.

Conclusion: ARMD는 병렬과 순차 디코딩 간의 성능 차이를 효과적으로 줄이며, 병렬 텍스트 생성을 위한 새로운 기준을 설정한다.

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


### [29] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: CRISPNAM-FG라는 본질적으로 해석 가능한 생존 모델을 제안하여, 경쟁 위험을 가진 생존 모델링에서 AI 안전성과 신뢰를 높이고자 한다.


<details>
  <summary>Details</summary>
Motivation: 의료 응용에서 모델의 해석 가능성은 AI 안전성과 임상의의 신뢰를 구축하는 데 필수적이다.

Method: Neural Additive Models(NAMs)의 구조와 각 위험에 대한 별도 프로젝션 벡터를 활용하여 Cumulative Incidence Function을 예측하는 CRISPNAM-FG 모델을 제안했다.

Result: CRISPNAM-FG는 여러 벤치마크 데이터셋에서 검증되었으며, 2016-2023년 동안 29개 온타리오 병원에서 당뇨병 환자의 미래 발 병변을 예측하는 데 적용되었다.

Conclusion: 우리의 방법은 다른 딥 서바이벌 모델과 비교하여 경쟁력 있는 성능을 달성하면서도 형태 함수와 특성 중요도 플롯을 통해 투명성을 제공한다.

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>
