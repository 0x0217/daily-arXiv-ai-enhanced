<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Lean Clients, Full Accuracy: Hybrid Zeroth- and First-Order Split Federated Learning](https://arxiv.org/abs/2601.09076)
*Zhoubin Kou,Zihan Chen,Jing Yang,Cong Shen*

Main category: cs.LG

TL;DR: HERON-SFL는 자원 제약이 있는 클라이언트와 강력한 서버 간 협력 교육을 가능하게 하는 새로운 하이브리드 최적화 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: Split Federated Learning(SFL)은 자원 제약이 있는 엣지 장치와 계산이 풍부한 서버 간의 협업 교육을 가능하게 합니다. 하지만 클라이언트 측의 계산 문제는 여전히 남아 있습니다.

Method: HERON-SFL이라는 새로운 하이브리드 최적화 프레임워크를 제안하며, 이는 클라이언트에서 제로서 순서 최적화를 통합하고 서버에서는 1차 최적화를 유지합니다.

Result: HERON-SFL은 ResNet 교육과 언어 모델 미세 조정 작업에서 벤치마크 정확도에 도달하면서 클라이언트 피크 메모리를 최대 64%, 클라이언트 측 계산 비용을 최대 33% 줄입니다.

Conclusion: HERON-SFL은 자원이 제한된 장치에서 훈련하거나 적응할 수 있는 모델의 범위를 상당히 확장합니다.

Abstract: Split Federated Learning (SFL) enables collaborative training between resource-constrained edge devices and a compute-rich server. Communication overhead is a central issue in SFL and can be mitigated with auxiliary networks. Yet, the fundamental client-side computation challenge remains, as back-propagation requires substantial memory and computation costs, severely limiting the scale of models that edge devices can support. To enable more resource-efficient client computation and reduce the client-server communication, we propose HERON-SFL, a novel hybrid optimization framework that integrates zeroth-order (ZO) optimization for local client training while retaining first-order (FO) optimization on the server. With the assistance of auxiliary networks, ZO updates enable clients to approximate local gradients using perturbed forward-only evaluations per step, eliminating memory-intensive activation caching and avoiding explicit gradient computation in the traditional training process. Leveraging the low effective rank assumption, we theoretically prove that HERON-SFL's convergence rate is independent of model dimensionality, addressing a key scalability concern common to ZO algorithms. Empirically, on ResNet training and language model (LM) fine-tuning tasks, HERON-SFL matches benchmark accuracy while reducing client peak memory by up to 64% and client-side compute cost by up to 33% per step, substantially expanding the range of models that can be trained or adapted on resource-limited devices.

</details>


### [2] [EvasionBench: Detecting Evasive Answers in Financial Q&A via Multi-Model Consensus and LLM-as-Judge](https://arxiv.org/abs/2601.09142)
*Shijian Ma,Yan Lin,Yi Yang*

Main category: cs.LG

TL;DR: EvasionBench를 통해 30,000개의 훈련 샘플과 1,000개의 인간 주석 테스트 샘플을 통해 회피 응답을 탐지하고, 다중 모델 주석 프레임워크를 사용하여 모델 성능을 향상시켰습니다.


<details>
  <summary>Details</summary>
Motivation: 재무 투명성을 위해 금융 회의에서 회피 답변을 탐지하는 것이 중요하지만, 대규모 벤치마크 부족이 발전을 방해하고 있습니다.

Method: EvasionBench를 도입하고, 경계 사례에서 주석자 간의 의견 충돌을 이용해 레이블을 해결하는 다중 모델 주석 프레임워크를 개발했습니다.

Result: 단일 모델 증류보다 2.4% 향상된 성능을 보여주며, 판별자가 해결한 샘플은 더 높은 훈련 손실에도 불구하고 일반화 능력을 향상시켰습니다.

Conclusion: 훈련된 모델 Eva-4B는 81.3% 정확도로, 기본 모델보다 25% 포인트 향상되었으며, 적은 추론 비용으로 최첨단 LLM 성능에 접근하였습니다.

Abstract: Detecting evasive answers in earnings calls is critical for financial transparency, yet progress is hindered by the lack of large-scale benchmarks. We introduce EvasionBench, comprising 30,000 training samples and 1,000 human-annotated test samples (Cohen's Kappa 0.835) across three evasion levels. Our key contribution is a multi-model annotation framework leveraging a core insight: disagreement between frontier LLMs signals hard examples most valuable for training. We mine boundary cases where two strong annotators conflict, using a judge to resolve labels. This approach outperforms single-model distillation by 2.4 percent, with judge-resolved samples improving generalization despite higher training loss (0.421 vs 0.393) - evidence that disagreement mining acts as implicit regularization. Our trained model Eva-4B (4B parameters) achieves 81.3 percent accuracy, outperforming its base by 25 percentage points and approaching frontier LLM performance at a fraction of inference cost.

</details>


### [3] [Interpretable Probability Estimation with LLMs via Shapley Reconstruction](https://arxiv.org/abs/2601.09151)
*Yang Nan,Qihao Wen,Jiahao Wang,Pengfei He,Ravi Tandon,Yong Ge,Han Xu*

Main category: cs.LG

TL;DR: 이 논문에서는 LLM 기반 확률 추정을 개선하기 위한 PRISM 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)은 불확실한 사건의 확률을 추정하는 잠재력을 보여준다.

Method: PRISM은 Shapley 값을 사용하여 각 입력 요소의 평균 기여를 정량화하여 LLM의 예측을 분해한다.

Result: 실험 결과 PRISM이 금융, 의료 및 농업 등 여러 분야에서 직접적인 프롬프트 및 다른 기준선보다 예측 정확도를 향상시킨 것을 보여준다.

Conclusion: PRISM은 LLM 기반 의사 결정 지원 시스템의 신뢰성을 높이는 투명한 예측 파이프라인을 제공한다.

Abstract: Large Language Models (LLMs) demonstrate potential to estimate the probability of uncertain events, by leveraging their extensive knowledge and reasoning capabilities. This ability can be applied to support intelligent decision-making across diverse fields, such as financial forecasting and preventive healthcare. However, directly prompting LLMs for probability estimation faces significant challenges: their outputs are often noisy, and the underlying predicting process is opaque. In this paper, we propose PRISM: Probability Reconstruction via Shapley Measures, a framework that brings transparency and precision to LLM-based probability estimation. PRISM decomposes an LLM's prediction by quantifying the marginal contribution of each input factor using Shapley values. These factor-level contributions are then aggregated to reconstruct a calibrated final estimate. In our experiments, we demonstrate PRISM improves predictive accuracy over direct prompting and other baselines, across multiple domains including finance, healthcare, and agriculture. Beyond performance, PRISM provides a transparent prediction pipeline: our case studies visualize how individual factors shape the final estimate, helping build trust in LLM-based decision support systems.

</details>


### [4] [Preliminary Tests of the Anticipatory Classifier System with Hindsight Experience Replay](https://arxiv.org/abs/2601.09400)
*Olgierd Unold,Stanisław Franczyk*

Main category: cs.LG

TL;DR: ACS2HER는 Anticipatory Classifier System(ACS2)과 Hindsight Experience Replay(HER) 메커니즘의 새로운 통합이다.


<details>
  <summary>Details</summary>
Motivation: ACS2는 잠재 학습을 통해 인지 맵을 구축하는 데 매우 효과적이지만 희소 보상을 특징으로 하는 환경에서 성능이 정체되는 경우가 많다.

Method: 에이전트가 주 목표에 도달하지 못할 때 회고 학습을 촉발하는 특정 아키텍처 변형을 제안하여, 방문한 상태에 가상 목표로 새 레이블을 부여하여 학습 신호를 조밀하게 만든다.

Result: 두 가지 벤치마크인 결정론적 	exttt{Maze 6} 및 확률론적 	exttt{FrozenLake}에서 평가한 결과, ACS2HER는 표준 ACS2에 비해 지식 습득 및 환경 숙련도를 유의미하게 가속화하는 것으로 나타났다.

Conclusion: 그러나 이러한 효율성 증가는 증가된 계산 오버헤드와 분류기 수의 상당한 확대를 동반한다. 이 연구는 학습 분류 시스템에서 회고 목표 재레이블링과 예측 메커니즘을 결합한 최초의 분석을 제공한다.

Abstract: This paper introduces ACS2HER, a novel integration of the Anticipatory Classifier System (ACS2) with the Hindsight Experience Replay (HER) mechanism. While ACS2 is highly effective at building cognitive maps through latent learning, its performance often stagnates in environments characterized by sparse rewards. We propose a specific architectural variant that triggers hindsight learning when the agent fails to reach its primary goal, re-labeling visited states as virtual goals to densify the learning signal. The proposed model was evaluated on two benchmarks: the deterministic \texttt{Maze 6} and the stochastic \texttt{FrozenLake}. The results demonstrate that ACS2HER significantly accelerates knowledge acquisition and environmental mastery compared to the standard ACS2. However, this efficiency gain is accompanied by increased computational overhead and a substantial expansion in classifier numerosity. This work provides the first analysis of combining anticipatory mechanisms with retrospective goal-relabeling in Learning Classifier Systems.

</details>


### [5] [DeepLight: A Sobolev-trained Image-to-Image Surrogate Model for Light Transport in Tissue](https://arxiv.org/abs/2601.09439)
*Philipp Haim,Vasilis Ntziachristos,Torsten Enßlin,Dominik Jüstel*

Main category: cs.LG

TL;DR: 광학음향 이미징에서 조직의 흡수 계수를 복원하는 것은 여전히 도전적인 문제이다. 본 논문에서는 모델 도함수의 정확성을 높이기 위해 Sobolev 훈련을 사용하는 대리 모델을 제시한다. 이 방법은 파생물의 정확성을 개선하고 일반화 오류를 줄여 역 문제 해결에 유용하다.


<details>
  <summary>Details</summary>
Motivation: 광학음향 이미징에서 조직의 흡수 계수를 복원하는 문제를 해결하는 데 있어 이점이 있다.

Method: 조직 내의 빛 전달을 위한 대리 모델을 제시하고, 모델 도함수의 정확성을 개선하기 위해 Sobolev 훈련을 사용한다.

Result: Sobolev 훈련이 대리 모델의 도함수 정확성을 개선하고, 분포 내 및 분포 외 샘플의 일반화 오류를 줄이는 효과를 보인다.

Conclusion: 대리 모델의 유용성을 크게 향상시킬 수 있는 가능성을 보여준다.

Abstract: In optoacoustic imaging, recovering the absorption coefficients of tissue by inverting the light transport remains a challenging problem. Improvements in solving this problem can greatly benefit the clinical value of optoacoustic imaging. Existing variational inversion methods require an accurate and differentiable model of this light transport. As neural surrogate models allow fast and differentiable simulations of complex physical processes, they are considered promising candidates to be used in solving such inverse problems. However, there are in general no guarantees that the derivatives of these surrogate models accurately match those of the underlying physical operator. As accurate derivatives are central to solving inverse problems, errors in the model derivative can considerably hinder high fidelity reconstructions. To overcome this limitation, we present a surrogate model for light transport in tissue that uses Sobolev training to improve the accuracy of the model derivatives. Additionally, the form of Sobolev training we used is suitable for high-dimensional models in general. Our results demonstrate that Sobolev training for a light transport surrogate model not only improves derivative accuracy but also reduces generalization error for in-distribution and out-of-distribution samples. These improvements promise to considerably enhance the utility of the surrogate model in downstream tasks, especially in solving inverse problems.

</details>


### [6] [Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs](https://arxiv.org/abs/2601.09527)
*Jonathan Knoop,Hendrik Holtmann*

Main category: cs.LG

TL;DR: 소규모 기업들이 데이터 프라이버시 우려로 클라우드 LLM API의 대안을 찾고 있으며, 소비자 GPU가 클라우드 추론을 대체할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: SMEs는 클라우드 LLM API의 데이터 개인 정보 보호 문제로 인해 대안을 모색하고 있다.

Method: NVIDIA의 Blackwell 소비자 GPU (RTX 5060 Ti, 5070 Ti, 5090)를 생산 LLM 추론을 위해 시스템적으로 평가하고, 79개 구성에서 4개의 공개 가중치 모델을 벤치마킹했다.

Result: RTX 5090은 5060 Ti보다 3.5-4.6배 높은 처리량을 제공하며, RAG의 경우 지연 시간은 21배 낮다. 그러나 예산 GPU는 API 작업에 대해 초 단위 대기 시간으로 가장 높은 처리량-대-달러를 달성한다.

Conclusion: 소비자 GPU는 대부분의 SME 작업에 대해 클라우드 추론을 신뢰성 있게 대체할 수 있지만, 긴 컨텍스트 RAG와 같은 지연 시간이 중요한 경우에는 고급 GPU가 여전히 필수적이다.

Abstract: SMEs increasingly seek alternatives to cloud LLM APIs, which raise data privacy concerns. Dedicated cloud GPU instances offer improved privacy but with limited guarantees and ongoing costs, while professional on-premise hardware (A100, H100) remains prohibitively expensive. We present a systematic evaluation of NVIDIA's Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for production LLM inference, benchmarking four open-weight models (Qwen3-8B, Gemma3-12B, Gemma3-27B, GPT-OSS-20B) across 79 configurations spanning quantization formats (BF16, W4A16, NVFP4, MXFP4), context lengths (8k-64k), and three workloads: RAG, multi-LoRA agentic serving, and high-concurrency APIs. The RTX 5090 delivers 3.5-4.6x higher throughput than the 5060 Ti with 21x lower latency for RAG, but budget GPUs achieve the highest throughput-per-dollar for API workloads with sub-second latency. NVFP4 quantization provides 1.6x throughput over BF16 with 41% energy reduction and only 2-4% quality loss. Self-hosted inference costs $0.001-0.04 per million tokens (electricity only), which is 40-200x cheaper than budget-tier cloud APIs, with hardware breaking even in under four months at moderate volume (30M tokens/day). Our results show that consumer GPUs can reliably replace cloud inference for most SME workloads, except latency-critical long-context RAG, where high-end GPUs remain essential. We provide deployment guidance and release all benchmark data for reproducible SME-scale deployments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [ART: Action-based Reasoning Task Benchmarking for Medical AI Agents](https://arxiv.org/abs/2601.08988)
*Ananya Mantravadi,Shivali Dalmia,Abhishek Mukherji*

Main category: cs.AI

TL;DR: 의료 AI 에이전트를 위한 행동 기반 추론 임무 벤치마크인 ART를 소개하며, 전자 건강 기록에서 안전한 다단계 추론을 위한 성능 평가의 필요성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: 신뢰할 수 있는 임상 결정 지원은 안전하고 구조화된 전자 건강 기록 (EHR)에서 다단계 추론이 가능한 의료 AI 에이전트를 필요로 합니다.

Method: ART를 소개하며, 이는 실제 EHR 데이터를 채굴하여 알려진 추론 약점을 겨냥한 도전적인 과제를 생성하는 행동 기반 추론 임무 벤치마크입니다.

Result: 600개의 과제를 통해 GPT-4o-mini와 Claude 3.5 Sonnet를 평가한 결과, 프롬프트 개선 후 거의 완벽한 검색 결과를 보였으나, 집계 및 임계값 추론에서 상당한 격차가 있었습니다.

Conclusion: 행동 지향 EHR 추론의 실패 양상을 드러내어 ART는 신뢰할 수 있는 임상 에이전트로 나아가는 중요한 단계가 되며, 이는 인지 부하와 행정 부담을 줄이고, 높은 수요의 치료 환경에서 인력 용량을 지원하는 AI 시스템을 위한 필수적입니다.

Abstract: Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records (EHRs). While large language models (LLMs) show promise in healthcare, existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. We introduce ART, an Action-based Reasoning clinical Task benchmark for medical AI agents, which mines real-world EHR data to create challenging tasks targeting known reasoning weaknesses. Through analysis of existing benchmarks, we identify three dominant error categories: retrieval failures, aggregation errors, and conditional logic misjudgments. Our four-stage pipeline -- scenario identification, task generation, quality audit, and evaluation -- produces diverse, clinically validated tasks grounded in real patient data. Evaluating GPT-4o-mini and Claude 3.5 Sonnet on 600 tasks shows near-perfect retrieval after prompt refinement, but substantial gaps in aggregation (28--64%) and threshold reasoning (32--38%). By exposing failure modes in action-oriented EHR reasoning, ART advances toward more reliable clinical agents, an essential step for AI systems that reduce cognitive load and administrative burden, supporting workforce capacity in high-demand care settings

</details>


### [8] [The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments](https://arxiv.org/abs/2601.09032)
*Logan Ritchie,Sushant Mehta,Nick Heiner,Mason Yu,Edwin Chen*

Main category: cs.AI

TL;DR: 대형 언어 모델 기반 에이전트의 발전은 AI 평가를 단일 응답 평가에서 다단계 작업 완료로 전환했습니다. 본 연구는 150개의 직장 작업을 기반으로 한 실제 전자상거래 RL 환경에서 최첨단 AI 모델을 평가한 경험적 연구를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 직장 환경에서의 AI 모델의 실제 활용 가능성을 평가하기 위해.

Method: Surge의 현실적인 전자상거래 RL 환경에서 150개의 직장 작업에 대한 최첨단 AI 모델을 평가하는 경험적 연구를 수행했다.

Result: 최고 성능 모델조차도 약 40f{tasks}에서 실패하며, 실패는 특정 계층에서 집단적으로 발생한다. 약한 모델은 기본적인 도구 사용과 계획에 어려움을 겪는 반면, 강력한 모델은 명시적 지침 이상에서의 맥락적 추리를 요구하는 작업에서 주로 실패한다.

Conclusion: 현재의 최첨단 모델이 일관된 다단계 행동을 시연할 수 있지만, 현실적인 직장 환경에서 인간 수준의 작업 완료를 달성하기 위해 상당한 능력의 격차가 남아있음을 시사합니다.

Abstract: The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. We present an empirical study evaluating frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Our analysis reveals an empirically-derived \emph{hierarchy of agentic capabilities} that models must master for real-world deployment: (1) tool use, (2) planning and goal formation, (3) adaptability, (4) groundedness, and (5) common-sense reasoning. Even the best-performing models fail approximately 40\% of the tasks, with failures clustering predictably along this hierarchy. Weaker models struggle with fundamental tool use and planning, whereas stronger models primarily fail on tasks requiring contextual inference beyond explicit instructions. We introduce a task-centric design methodology for RL environments that emphasizes diversity and domain expert contributions, provide detailed failure analysis, and discuss implications for agent development. Our findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.

</details>


### [9] [Human-AI Co-design for Clinical Prediction Models](https://arxiv.org/abs/2601.09072)
*Jean Feng,Avni Kothari,Patrick Vossler,Andrew Bishara,Lucas Zier,Newton Addo,Aaron Kornblith,Yan Shuo Tan,Chandan Singh*

Main category: cs.AI

TL;DR: HACHI는 임상 예측 모델(CPM)의 개발을 가속화하기 위해 AI 에이전트를 활용하는 반복적인 인간-루프 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 안전하고 효과적이며 실용적인 임상 예측 모델을 개발하는 과정은 시간과 자원이 많이 소요되어 임상에 적용되는 모델이 적다.

Method: HACHI는 AI 에이전트가 임상 노트에서 개념을 탐색하고 평가하는 과정과 임상 전문가들이 피드백을 제공하여 CPM 학습 과정을 개선하는 과정을 번갈아 진행한다.

Result: HACHI는 기존 방법들보다 뛰어난 성능을 보여주며, 일반적으로 사용되는 CPM에 포함되지 않은 새로운 임상적으로 관련 있는 개념도 발견하였다.

Conclusion: HACHI는 임상 AI 팀의 중요한 역할을 밝혀내고, AI 에이전트가 고려하지 않았던 개념 탐색, 개념의 세분화 조절, 목표 함수 변경 및 데이터 편향 및 누출 문제를 식별하는 데 기여한다.

Abstract: Developing safe, effective, and practically useful clinical prediction models (CPMs) traditionally requires iterative collaboration between clinical experts, data scientists, and informaticists. This process refines the often small but critical details of the model building process, such as which features/patients to include and how clinical categories should be defined. However, this traditional collaboration process is extremely time- and resource-intensive, resulting in only a small fraction of CPMs reaching clinical practice. This challenge intensifies when teams attempt to incorporate unstructured clinical notes, which can contain an enormous number of concepts. To address this challenge, we introduce HACHI, an iterative human-in-the-loop framework that uses AI agents to accelerate the development of fully interpretable CPMs by enabling the exploration of concepts in clinical notes. HACHI alternates between (i) an AI agent rapidly exploring and evaluating candidate concepts in clinical notes and (ii) clinical and domain experts providing feedback to improve the CPM learning process. HACHI defines concepts as simple yes-no questions that are used in linear models, allowing the clinical AI team to transparently review, refine, and validate the CPM learned in each round. In two real-world prediction tasks (acute kidney injury and traumatic brain injury), HACHI outperforms existing approaches, surfaces new clinically relevant concepts not included in commonly-used CPMs, and improves model generalizability across clinical sites and time periods. Furthermore, HACHI reveals the critical role of the clinical AI team, such as directing the AI agent to explore concepts that it had not previously considered, adjusting the granularity of concepts it considers, changing the objective function to better align with the clinical objectives, and identifying issues of data bias and leakage.

</details>


### [10] [AviationLMM: A Large Multimodal Foundation Model for Civil Aviation](https://arxiv.org/abs/2601.09105)
*Wenbin Li,Jingling Wu,Xiaoyong Lin. Jing Chen,Cong Chen*

Main category: cs.AI

TL;DR: 본 논문은 민간 항공을 위한 다중모달 기초 모델인 AviationLMM을 제안하여 서로 다른 데이터 스트림을 통합하고 실시간 의사 결정을 지원하는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 민간 항공의 안전과 효율성을 높이기 위해 기존 인공지능 혁신의 한계를 극복하고자 한다.

Method: AviationLMM은 공중-지상 음성, 감시 데이터, 탑재 텔레메트리, 비디오 및 구조화된 텍스트와 같은 다중 모달 입력을 수집하고, 교차 모달 정렬 및 융합을 수행하며, 상황 요약, 위험 경고, 예측 진단 등의 유연한 출력을 생성하는 모델 아키텍처를 설명한다.

Result: AviationLMM은 다양한 데이터 스트림을 통합하여 민간 항공의 상황 인식 및 실시간 의사 결정을 개선한다.

Conclusion: 본 연구는 통합되고 신뢰할 수 있으며 개인정보 보호를 유지하는 항공 AI 생태계로 나아가기 위한 발전 기회를 제시한다.

Abstract: Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation and agentic applications. We firstly identify the gaps between existing AI solutions and requirements. Secondly, we describe the model architecture that ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video and structured texts, and performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. In order to fully realize this vision, we identify key research opportunities to address, including data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, we aim to boost the civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy and privacy-preserving aviation AI ecosystem.

</details>


### [11] [The AI Hippocampus: How Far are We From Human Memory?](https://arxiv.org/abs/2601.09113)
*Zixia Jia,Jiaqi Li,Yipeng Kang,Yuxuan Wang,Tong Wu,Quansen Wang,Xiaobo Wang,Shuyi Zhang,Junzhe Shen,Qing Li,Siyuan Qi,Yitao Liang,Di He,Zilong Zheng,Song-Chun Zhu*

Main category: cs.AI

TL;DR: 이 논문은 최신 대형 언어 모델과 다중 모달 LLM의 메모리 메커니즘의 발전을 포괄적으로 정리하여 분류하고, 메모리의 세 가지 주요 프레임워크를 밝혀낸다.


<details>
  <summary>Details</summary>
Motivation: 현대 대형 언어 모델 및 다중 모달 LLM의 이유, 적응력 및 맥락 충실도를 향상시키기 위한 메모리의 기본적인 역할을 탐구하기 위해.

Method: 메모리에 대한 문헌을 암시적, 명시적 및 작동적 메모리 패러다임으로 조직하여 포괄적이고 체계적인 종합을 제시한다.

Result: 세 가지 주요 메모리 프레임워크를 설명하며, 최신 연구 방법을 통한 잠재 메모리 해석 및 조작에 대한 논의를 포함한다.

Conclusion: 다양한 모달 설정에서 메모리의 통합을 조사하고, 메모리 용량, 정렬, 사실 일관성 및 시스템 간 상호 운용성과 관련된 문제를 다룬다.

Abstract: Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models and Multi-Modal LLMs. As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations, such as textual corpora, dense vectors, and graph-based structures, thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability.

</details>


### [12] [PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?](https://arxiv.org/abs/2601.09152)
*Yiwen Tu,Xuan Liu,Lianhui Qin,Haojian Jin*

Main category: cs.AI

TL;DR: PRA는 사용자의 개인 댓글 이력 및 맥락 신호에 기반하여 개인별 프라이버시 우려를 시뮬레이션하는 AI 에이전트입니다.


<details>
  <summary>Details</summary>
Motivation: 개인 수준의 프라이버시 우려 형성을 이해하고자 하는 목적에서 출발하였습니다.

Method: PRA는 사용자의 '프라이버시 마음'을 재구성하고, 제한된 합리성을 모방하는 맥락 필터를 통해 관련 프라이버시 메모리를 동적으로 활성화하며, 새로운 프라이버시 상황에 어떻게 반응할지를 반영하는 합성 댓글을 생성합니다.

Result: 실제 Hacker News 토론에 대한 실험 결과 PRA가 프라이버시 우려 예측에서 기준 에이전트를 초월하였으며, AI, 전자상거래, 의료 등 다양한 도메인에서 전이 가능한 추론 패턴을 포착하였습니다.

Conclusion: PRA는 개인별 프라이버시 우려 모델링에 있어 효과적인 도구임을 보여줍니다.

Abstract: This paper introduces PRA, an AI-agent design for simulating how individual users form privacy concerns in response to real-world news. Moving beyond population-level sentiment analysis, PRA integrates privacy and cognitive theories to simulate user-specific privacy reasoning grounded in personal comment histories and contextual cues. The agent reconstructs each user's "privacy mind", dynamically activates relevant privacy memory through a contextual filter that emulates bounded rationality, and generates synthetic comments reflecting how that user would likely respond to new privacy scenarios. A complementary LLM-as-a-Judge evaluator, calibrated against an established privacy concern taxonomy, quantifies the faithfulness of generated reasoning. Experiments on real-world Hacker News discussions show that \PRA outperforms baseline agents in privacy concern prediction and captures transferable reasoning patterns across domains including AI, e-commerce, and healthcare.

</details>


### [13] [MAXS: Meta-Adaptive Exploration with LLM Agents](https://arxiv.org/abs/2601.09259)
*Jian Zhang,Zhiyuan Wang,Zhangqi Wang,Yu He,Haoran Luo,li yuan,Lingling Zhang,Rui Mao,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: 이 논문은 LLM 에이전트를 위한 메타 적응 탐색을 제안하여 전역 효율성과 컴퓨팅 효율성 사이의 균형을 맞추고자 한다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 에이전트 추론에서 로컬 단기 생성과 궤적 불안정성 문제로 어려움을 겪는다.

Method: LLM 에이전트 기반의 메타 적응 추론 프레임워크인 MAXS를 통해 도구 실행과 추론 계획을 유연하게 통합하고, 미리보기 전략을 사용하여 추론 경로를 확장한다.

Result: MAXS는 성능과 추론 효율성 모두에서 기존 방법을 일관되게 초월한다.

Conclusion: MAXS를 통해 리소스 효율성과 전역 효율성 간의 균형을 이루는 것이 가능하다.

Abstract: Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.

</details>


### [14] [LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach](https://arxiv.org/abs/2601.09635)
*Kuo Liang,Yuhang Lu,Jianming Mao,Shuyi Sun,Chunwei Yang,Congcong Zeng,Xiao Jin,Hanzhang Qin,Ruihao Zhu,Chung-Piaw Teo*

Main category: cs.AI

TL;DR: LEAN-LLM-OPT는 대규모 최적화를 위한 LLM 지원 자동 공식을 생성하기 위한 프레임워크로, 문제 설명과 데이터셋을 입력으로 받아 최적화 공식을 생성하는 워크플로우를 구축한다.


<details>
  <summary>Details</summary>
Motivation: 현대 비즈니스 의사결정에서 대규모 최적화는 핵심적인 역할을 하지만 모델 구축은 노동 집약적이고 시간 소모가 크다.

Method: LEAN-LLM-OPT는 문제 설명과 관련 데이터셋을 입력으로 받고, LLM 에이전스 팀을 구성하여 최적화 공식을 생성하는 워크플로우를 동적으로 구축한다.

Result: GPT-4.1과 gpt-oss-20B로 구현된 LEAN-LLM-OPT는 대규모 최적화 모델링 작업에서 강력한 성능을 발휘하며 최신 방법들과 경쟁력을 갖춘다.

Conclusion: LEAN-LLM-OPT는 다양한 시나리오에서 뛰어난 성능을 보이며, 대규모 최적화 자동 공식을 위한 최초의 종합 벤치마크를 제시한다.

Abstract: Large-scale optimization is a key backbone of modern business decision-making. However, building these models is often labor-intensive and time-consuming. We address this by proposing LEAN-LLM-OPT, a LightwEight AgeNtic workflow construction framework for LLM-assisted large-scale OPTimization auto-formulation. LEAN-LLM-OPT takes as input a problem description together with associated datasets and orchestrates a team of LLM agents to produce an optimization formulation. Specifically, upon receiving a query, two upstream LLM agents dynamically construct a workflow that specifies, step-by-step, how optimization models for similar problems can be formulated. A downstream LLM agent then follows this workflow to generate the final output. Leveraging LLMs' text-processing capabilities and common modeling practices, the workflow decomposes the modeling task into a sequence of structured sub-tasks and offloads mechanical data-handling operations to auxiliary tools. This design alleviates the downstream agent's burden related to planning and data handling, allowing it to focus on the most challenging components that cannot be readily standardized. Extensive simulations show that LEAN-LLM-OPT, instantiated with GPT-4.1 and the open source gpt-oss-20B, achieves strong performance on large-scale optimization modeling tasks and is competitive with state-of-the-art approaches. In addition, in a Singapore Airlines choice-based revenue management use case, LEAN-LLM-OPT demonstrates practical value by achieving leading performance across a range of scenarios. Along the way, we introduce Large-Scale-OR and Air-NRM, the first comprehensive benchmarks for large-scale optimization auto-formulation. The code and data of this work is available at https://github.com/CoraLiang01/lean-llm-opt.

</details>


### [15] [Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants](https://arxiv.org/abs/2601.09264)
*Ziyi Shi,Xusen Guo,Hongliang Lu,Mingxing Peng,Haotian Wang,Zheng Zhu,Zhenning Li,Yuxuan Liang,Xinhu Zheng,Hai Yang*

Main category: cs.AI

TL;DR: 대규모 언어 모델(LLM) 기반의 다중 에이전트 정책 프레임워크를 통해 각 행정 지역에서의 팬데믹 대응을 조정하고, 사전에 계획된 개입을 가능하게 하여 전반적인 감염 및 사망률을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 팬데믹 통제는 행정 지역 간의 상호 의존성을 고려한 시기적절하고 조정된 정책 결정이 필요하다.

Method: LLM 에이전트를 각 행정 지역에 배치하여 지역별 역학 동향을 분석하고, 다른 에이전트와의 소통을 통해 교차 지역 간 의존성을 반영한다.

Result: 제안된 프레임워크를 통해 주(State) 단위로 COVID-19 관련 데이터와 실제 이동 기록을 분석하여 개입 시나리오를 탐색하고 정책 결정을 조정하였다. 이로 인해 전세계 팬데믹 결과와 비교했을 때 주별로 각각 63.7%와 40.1%의 감염 및 사망률 감소가 나타났다.

Conclusion: LLM 다중 에이전트 시스템은 조정된 정책 결정을 통해 더 효과적인 팬데믹 통제를 가능하게 한다.

Abstract: Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions. Within our framework, each administrative region is assigned an LLM agent as an AI policymaking assistant. The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies. By integrating real-world data, a pandemic evolution simulator, and structured inter-agent communication, our framework enables agents to jointly explore counterfactual intervention scenarios and synthesize coordinated policy decisions through a closed-loop simulation process. We validate the proposed framework using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions. Compared with real-world pandemic outcomes, our approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states. These results demonstrate that LLM multi-agent systems can enable more effective pandemic control with coordinated policymaking...

</details>


### [16] [PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records](https://arxiv.org/abs/2601.09636)
*Yibo Lyu,Gongwei Chen,Rui Shao,Weili Guan,Liqiang Nie*

Main category: cs.AI

TL;DR: 이 연구는 개인화된 GUI 에이전트를 위한 계층적 암묵적 의도 정렬(PersonalAlign)을 제안하며, 이는 사용자의 장기 기록을 활용하여 모호한 지침에서 생략된 선호를 해소하고 사용자의 상태에 따라 잠재적 루틴을 미리 파악하는 작업을 요구한다.


<details>
  <summary>Details</summary>
Motivation: 실제 사용을 위해 GUI 에이전트는 사용자 의도의 복잡성을 이해하고 조정할 필요가 있다.

Method: AndroidIntent라는 벤치마크를 도입하여 에이전트가 모호한 지침을 해결하고 장기 사용자 기록을 기반으로 능동적인 제안을 제공하는 능력을 평가한다. 또한, 계층적 의도 메모리 에이전트(HIM-Agent)를 소개하여 지속적으로 업데이트되는 개인 메모리 및 사용자 선호와 루틴을 계층적으로 조직한다.

Result: HIM-Agent는 15.7%와 7.3%의 실행 및 능동적 성과 개선을 보여준다.

Conclusion: 다양한 GUI 에이전트를 AndroidIntent에서 평가함으로써 HIM-Agent의 성능 향상 효과를 입증하였다.

Abstract: While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. In this work, we highlight Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistance. To facilitate this study, we introduce AndroidIntent, a benchmark designed to evaluate agents' ability in resolving vague instructions and providing proactive suggestions through reasoning over long-term user records. We annotated 775 user-specific preferences and 215 routines from 20k long-term records across different users for evaluation. Furthermore, we introduce Hierarchical Intent Memory Agent (HIM-Agent), which maintains a continuously updating personal memory and hierarchically organizes user preferences and routines for personalization. Finally, we evaluate a range of GUI agents on AndroidIntent, including GPT-5, Qwen3-VL, and UI-TARS, further results show that HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3%.

</details>


### [17] [M$^3$Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning](https://arxiv.org/abs/2601.09278)
*Xiaohan Yu,Chao Feng,Lang Mei,Chong Chen*

Main category: cs.AI

TL;DR: M$^3$Searcher는 멀티모달 정보 탐색을 지원하는 모듈형 에이전트로, 정보 획득과 답변 도출을 명확하게 분리하고 다양한 목표 보상을 통해 성과를 최적화한다. 실험 결과, 기존 접근 방식을 능가하는 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 현재의 정보 탐색 에이전트는 주로 텍스트 모달리티에 국한되어 있어, 멀티모달 환경에서의 정보 탐색의 한계를 극복할 필요가 있다.

Method: M$^3$Searcher는 정보 획득과 답변 도출을 분리하여 다중목표 보상 체계를 사용하여 최적화되며, MMSearchVQA라는 데이터셋을 개발하여 훈련을 지원한다.

Result: M$^3$Searcher는 기존 접근 방식에 비해 우수한 성능을 보이고, 복잡한 멀티모달 작업에서 강한 전이 적응성과 효과적인 추론을 나타낸다.

Conclusion: M$^3$Searcher는 멀티모달 정보 탐색 에이전트 분야의 발전에 기여할 수 있는 가능성을 보여준다.

Abstract: Recent advances in DeepResearch-style agents have demonstrated strong capabilities in autonomous information acquisition and synthesize from real-world web environments. However, existing approaches remain fundamentally limited to text modality. Extending autonomous information-seeking agents to multimodal settings introduces critical challenges: the specialization-generalization trade-off that emerges when training models for multimodal tool-use at scale, and the severe scarcity of training data capturing complex, multi-step multimodal search trajectories. To address these challenges, we propose M$^3$Searcher, a modular multimodal information-seeking agent that explicitly decouples information acquisition from answer derivation. M$^3$Searcher is optimized with a retrieval-oriented multi-objective reward that jointly encourages factual accuracy, reasoning soundness, and retrieval fidelity. In addition, we develop MMSearchVQA, a multimodal multi-hop dataset to support retrieval centric RL training. Experimental results demonstrate that M$^3$Searcher outperforms existing approaches, exhibits strong transfer adaptability and effective reasoning in complex multimodal tasks.

</details>


### [18] [Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures](https://arxiv.org/abs/2601.09293)
*Sofiene Lassoued,Stefan Lier,Andreas Schwung*

Main category: cs.AI

TL;DR: 이 논문은 불확실성 하에서의 동적 작업장 스케줄링 문제를 해결하기 위한 새로운 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 작업 도착의 불확실성과 예상치 못한 기계 고장에 따른 문제를 해결하고자 합니다.

Method: 모델 기반 패러다임을 따르며, 색상 타이밍 펫리 넷을 사용하여 스케줄링 환경을 표현하고, Maskable Proximal Policy Optimization을 이용해 동적 의사 결정을 가능하게 합니다.

Result: 우리의 방법이 전통적인 휴리스틱 및 규칙 기반 접근 방식보다 일관되게 더 우수한 성과를 보여줍니다.

Conclusion: 해석 가능한 Petri 넷 기반 모델과 적응형 강화 학습 정책을 결합함으로써 실시간 스케줄링을 위한 강력하고 확장 가능하며 설명 가능한 프레임워크를 제공합니다.

Abstract: We present a novel framework for solving Dynamic Job Shop Scheduling Problems under uncertainty, addressing the challenges introduced by stochastic job arrivals and unexpected machine breakdowns. Our approach follows a model-based paradigm, using Coloured Timed Petri Nets to represent the scheduling environment, and Maskable Proximal Policy Optimization to enable dynamic decision-making while restricting the agent to feasible actions at each decision point. To simulate realistic industrial conditions, dynamic job arrivals are modeled using a Gamma distribution, which captures complex temporal patterns such as bursts, clustering, and fluctuating workloads. Machine failures are modeled using a Weibull distribution to represent age-dependent degradation and wear-out dynamics. These stochastic models enable the framework to reflect real-world manufacturing scenarios better. In addition, we study two action-masking strategies: a non-gradient approach that overrides the probabilities of invalid actions, and a gradient-based approach that assigns negative gradients to invalid actions within the policy network. We conduct extensive experiments on dynamic JSSP benchmarks, demonstrating that our method consistently outperforms traditional heuristic and rule-based approaches in terms of makespan minimization. The results highlight the strength of combining interpretable Petri-net-based models with adaptive reinforcement learning policies, yielding a resilient, scalable, and explainable framework for real-time scheduling in dynamic and uncertain manufacturing environments.

</details>


### [19] [Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving](https://arxiv.org/abs/2601.09353)
*Ioannis Peridis,Dimitrios Troullinos,Georgios Chalkiadakis,Pantelis Giankoulidis,Ioannis Papamichail,Markos Papageorgiou*

Main category: cs.AI

TL;DR: 차선 없는 교통 환경은 차량이 도로의 측면 용량을 더 잘 활용할 수 있게 하여 교통 흐름을 증가시킨다. 이 연구는 차선 없는 교통에서 자율주행을 위한 단일 에이전트의 몬테카를로 트리 탐색(MCTS) 계획 접근법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 차선 없는 교통 환경에서 자율주행의 복잡성과 도전 과제를 해결하고자 한다.

Method: 차선 없는 교통에서의 단일 에이전트 자율주행을 위한 몬테카를로 트리 탐색 방법을 사용하고, 미리 훈련된 신경망이 선택 과정을 안내하도록 함.

Result: 차선 없는 환경에서 차량 정보의 등방성 효과, 신경망으로 안내된 MCTS 성능 향상, 계산 자원과 솔루션 품질 간의 균형을 평가함.

Conclusion: 이 연구는 자율주행 시스템의 성능과 안전을 높이기 위한 차선 없는 교통 환경에서의 MCTS 접근법의 유용성을 입증한다.

Abstract: Lane-free traffic environments allow vehicles to better harness the lateral capacity of the road without being restricted to lane-keeping, thereby increasing the traffic flow rates. As such, we have a distinct and more challenging setting for autonomous driving. In this work, we consider a Monte-Carlo Tree Search (MCTS) planning approach for single-agent autonomous driving in lane-free traffic, where the associated Markov Decision Process we formulate is influenced from existing approaches tied to reinforcement learning frameworks. In addition, MCTS is equipped with a pre-trained neural network (NN) that guides the selection phase. This procedure incorporates the predictive capabilities of NNs for a more informed tree search process under computational constraints. In our experimental evaluation, we consider metrics that address both safety (through collision rates) and efficacy (through measured speed). Then, we examine: (a) the influence of isotropic state information for vehicles in a lane-free environment, resulting in nudging behaviour--vehicles' policy reacts due to the presence of faster tailing ones, (b) the acceleration of performance for the NN-guided variant of MCTS, and (c) the trade-off between computational resources and solution quality.

</details>


### [20] [Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments](https://arxiv.org/abs/2601.09382)
*Qinglong Shi,Donghai Wang,Hantao Zhou,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He*

Main category: cs.AI

TL;DR: 이번 논문에서는 장기적인 사용자 의도를 유지하고 동적으로 환경에 적응할 수 있는 능력을 가진 능동적인 작업 지향 에이전트를 위한 새로운 상호작용 패러다임을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현재 대형 언어 모델 에이전트는 반응형 패러다임에 주로 작동하여 짧은 세션 내에서 즉각적인 사용자 쿼리에만 응답합니다. 이는 장기적인 사용자 의도를 유지하고 변화하는 외부 환경에 동적으로 적응하는 능력을 저해합니다.

Method: 우리는 두 가지 주요 능력을 통해 능동성을 형식화합니다: (i) 의도 조건 모니터링: 에이전트가 대화 기록에 기반하여 자율적으로 트리거 조건을 설정합니다; (ii) 사건 기반 후속 조치: 유용한 환경 업데이트를 감지할 때 에이전트가 적극적으로 사용자와 상호작용합니다. 또한, 동적 환경에서 복잡한 다중 턴 대화 데이터를 구축하기 위한 고품질 데이터 합성 파이프라인을 도입합니다.

Result: 우리는 현재 일부 주요 비공식 및 오픈 소스 모델을 평가하고 장기적인 작업 지향 상호작용에서 그들의 결함을 밝혔습니다. 또한, 합성 데이터를 사용하여 감독 학습을 통해 훈련한 우리의 미세 조정된 모델은 사용자 의도 변화가 포함된 복잡한 작업에 대해 85.19%의 작업 완료율을 달성했습니다.

Conclusion: 결과는 우리의 데이터 기반 전략의 효과성을 검증했습니다.

Abstract: Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user's intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment. We formalize proactivity through two key capabilities, (i) Intent-Conditioned Monitoring: The agent autonomously formulates trigger conditions based on dialog history; (ii) Event-Triggered Follow-up: The agent actively engages the user upon detecting useful environmental updates. We introduce a high-quality data synthesis pipeline to construct complex, multi-turn dialog data in a dynamic environment. Furthermore, we attempt to address the lack of evaluation criteria of task-oriented interaction in a dynamic environment by proposing a new benchmark, namely ChronosBench. We evaluated some leading close-source and open-source models at present and revealed their flaws in long-term task-oriented interaction. Furthermore, our fine-tuned model trained using synthetic data for supervised learning achieves a task completion rate of 85.19% for complex tasks including shifts in user intent, outperforming other models under test. And the result validated the effectiveness of our data-driven strategy.

</details>


### [21] [EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines](https://arxiv.org/abs/2601.09465)
*Shuo Zhang,Chaofa Yuan,Ryan Guo,Xiaomin Yu,Rui Xu,Zhangquan Chen,Zinuo Li,Zhi Yang,Shuhao Guan,Zhenheng Tang,Sen Hu,Liwen Zhang,Ronghao Chen,Huacan Wang*

Main category: cs.AI

TL;DR: EvoFSM이라는 구조화된 자기 진화 프레임워크를 제안하여 적응성과 제어성을 모두 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 에이전트는 고정된 워크플로우에 의존하고, 이는 실제 세계의 개방형 질의에 잘 적응하지 못한다.

Method: EvoFSM은 자유 형식의 재작성 대신 명시적인 유한 상태 기계(FSM)를 발전시켜 최적화 공간을 거시적 흐름(상태 전이 논리)과 미시적 기술(상태 특정 행동)으로 분리한다.

Result: EvoFSM은 5개의 다중 홉 QA 벤치마크에서 효과성을 입증했으며, 특히 DeepSearch 벤치마크에서 58.0%의 정확도를 달성한다.

Conclusion: EvoFSM은 상호작용 의사결정 작업에 대한 추가 결과로 일반화 가능성을 추가로 검증한다.

Abstract: While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work therefore explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and control by evolving an explicit Finite State Machine (FSM) instead of relying on free-form rewriting. EvoFSM decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations, and further incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM. In particular, EvoFSM reaches 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.

</details>


### [22] [What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding](https://arxiv.org/abs/2601.09503)
*Siyuan Liu,Hongbang Yuan,Xinze Li,Ziyue Zhu,Yixin Cao,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: 이 연구는 대형 언어 모델 에이전트의 환경 이해 능력을 평가하기 위해 새로운 평가 패러다임인 Task-to-Quiz (T2Q)를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 에이전트가 다양한 환경에서의 일반화 능력을 검사할 필요성이 있음.

Method: Task-to-Quiz (T2Q)라는 결정론적이고 자동화된 평가 패러다임을 제안하며, T2QBench라는 30개의 환경과 1,967개의 QA 쌍을 포함하는 테스트 스위트를 구현함.

Result: 과제 성공이 환경 이해의 좋은 proxy가 아니며, 현재의 기억 메커니즘이 환경 모델을 효과적으로 학습하는 데 도움이 되지 않음을 보여줌.

Conclusion: 적극적 탐색과 세밀한 상태 표현이 주요 병목 현상으로 드러나며, 더 일반화된 자율 에이전트를 개발하는 데 중요한 기초를 제공함.

Abstract: Large language model (LLM) agents have demonstrated remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains a under-examined concern. Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment. To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding. We instantiate this paradigm in T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs across multiple difficulty levels. Our extensive experiments reveal that task success is often a poor proxy for environment understanding, and that current memory machanism can not effectively help agents acquire a grounded model of the environment. These findings identify proactive exploration and fine-grained state representation as primary bottlenecks, offering a robust foundation for developing more generalizable autonomous agents.

</details>


### [23] [Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning](https://arxiv.org/abs/2601.09667)
*Zhiyuan Hu,Yunhai Hu,Juncheng Liu,Shuyue Stella Li,Yucheng Wang,Zhen Xu,See-Kiong Ng,Anh Tuan Luu,Xinxing Xu,Bryan Hooi,Cynthia Breazeal,Hae Won Park*

Main category: cs.AI

TL;DR: MATTRL는 다수의 에이전트가 함께 작업하면서 강화 학습을 안정적으로 수행할 수 있도록 돕는 구조화된 텍스트 경험을 주입하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 다수의 에이전트 시스템은 많은 애플리케이션에서 실용적인 LLM 기반 협력자로 발전하였으나, MARL 훈련의 비효율성과 불안정성을 해결할 필요가 있다.

Method: MATTRL은 다중 전문가 팀을 구성하고, 테스트 시간 경험을 통합하여 최종 의사결정을 위한 합의에 도달하도록 설계되어 있다.

Result: 의학, 수학 및 교육의 도전적인 벤치마크에서 MATTRL은 다수의 에이전트 기준에서 평균 3.67 %의 정확도 향상, 비교 가능한 단일 에이전트 기준에서 8.67 %의 향상을 보였다.

Conclusion: MATTRL은 조정 없이도 분포 변화에 강한 다수 에이전트 추론을 위한 안정적이고 효과적이며 효율적인 경로를 제공한다.

Abstract: Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\% over a multi-agent baseline, and by 8.67\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.

</details>


### [24] [Automating Supply Chain Disruption Monitoring via an Agentic AI Approach](https://arxiv.org/abs/2601.09680)
*Sara AlMahri,Liming Xu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: 현대 공급망은 지정학적 사건, 수요 충격, 무역 제한 및 자연 재해로부터의 중단에 노출되고 있다. 이 연구는 자율적으로 공급망의 중단을 모니터링하고 분석하며 대응하는 최소한의 감독이 필요한 AI 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기업들은 공급망의 상류를 볼 수 있는 능력이 부족하여 중단이 하류로 확산되기 전까지 이러한 취약점을 감지하지 못하고 있다.

Method: 대규모 언어 모델과 결정론적 도구를 사용하여 공급망의 여러 계층에서 중단 신호를 감지하고, 이를 공급업체 네트워크에 매핑하며, 노출 평가를 실시하고, 대체 조달 옵션과 같은 완화 방안을 추천하는 자가 감독형 AI 프레임워크를 도입하였다.

Result: 30개의 시뮬레이션 시나리오를 통해 평가한 결과, F1 점수가 0.962에서 0.991 사이에 이르고, 중단당 평균 3.83분의 전체 end-to-end 분석을 수행하며 비용은 0.0836달러에 불과하다. 이는 업계 기준인 몇 일 이내의 분석가 중심 평가에 비해 응답 시간이 3개의 수치적 규모 이상 감소한 것이다.

Conclusion: 이 연구는 심층 공급망 네트워크에서의 중단 관리를 위한 회복력이 강하고, 비회복적으로 자율적인 공급망 구축의 기초 단계를 확립한다.

Abstract: Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [25] [StegoStylo: Squelching Stylometric Scrutiny through Steganographic Stitching](https://arxiv.org/abs/2601.09056)
*Robert Dilworth*

Main category: cs.CR

TL;DR: 이 논문은 스타일 분석과 스테가노그래피를 결합하여 저작권 검증과 스타일 분석의 위험성을 해결하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 스타일 분석의 사용이 저작권과 위조 검증에 도움을 줄 수 있지만, 악의적인 목적으로도 활용될 수 있다는 우려가 있다.

Method: 대항 스타일 분석 기술인 'TraceTarnish'를 통해 스타일 분석 시스템을 혼란시키고, 스테가노그래피를 활용하여 저자의 스타일적 지문을 숨기는 방법을 모색하였다.

Result: 스테가노그래피를 통해 단어 수정 비율이 33% 이상일 때 저작권 모호화가 가능하다는 것을 밝혀냈다.

Conclusion: 스타일 분석이 개인 정보 보호를 침해할 수 있는 경로를 반영하고, 'TraceTarnish'와 같은 방어 도구의 필요성을 주장하였다.

Abstract: Stylometry--the identification of an author through analysis of a text's style (i.e., authorship attribution)--serves many constructive purposes: it supports copyright and plagiarism investigations, aids detection of harmful content, offers exploratory cues for certain medical conditions (e.g., early signs of dementia or depression), provides historical context for literary works, and helps uncover misinformation and disinformation. In contrast, when stylometry is employed as a tool for authorship verification--confirming whether a text truly originates from a claimed author--it can also be weaponized for malicious purposes. Techniques such as de-anonymization, re-identification, tracking, profiling, and downstream effects like censorship illustrate the privacy threats that stylometric analysis can enable. Building on these concerns, this paper further explores how adversarial stylometry combined with steganography can counteract stylometric analysis. We first present enhancements to our adversarial attack, $\textit{TraceTarnish}$, providing stronger evidence of its capacity to confound stylometric systems and reduce their attribution and verification accuracy. Next, we examine how steganographic embedding can be fine-tuned to mask an author's stylistic fingerprint, quantifying the level of authorship obfuscation achievable as a function of the proportion of words altered with zero-width Unicode characters. Based on our findings, steganographic coverage of 33% or higher seemingly ensures authorship obfuscation. Finally, we reflect on the ways stylometry can be used to undermine privacy and argue for the necessity of defensive tools like $\textit{TraceTarnish}$.

</details>


### [26] [KryptoPilot: An Open-World Knowledge-Augmented LLM Agent for Automated Cryptographic Exploitation](https://arxiv.org/abs/2601.09129)
*Xiaonan Liu,Zhihao Li,Xiao Lan,Hao Ren,Haizhou Wang,Xingshu Chen*

Main category: cs.CR

TL;DR: KryptoPilot는 자동 암호학적 악용을 위한 지식 증강 LLM 에이전트로, CTF 대회에서 높은 성과를 달성하며 실세계 암호학적 도전에 적합하다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 에이전트가 고난이도 암호학 CTF 도전에서 비효율적인 이유는 지식의 세분화 부족에 있다.

Method: KryptoPilot는 동적 오픈 월드 지식 획득, 구조적 지식 재사용을 위한 지속적인 작업공간 및 행동 제약을 통한 추론 안정성을 제공하는 거버넌스 하위 시스템을 통합한다.

Result: KryptoPilot는 InterCode-CTF에서 완전 해결 성공률을 달성하고, NYU-CTF 벤치마크에서 56~60%의 암호학적 문제를 해결했으며, 라이브 대회에서 33개의 암호학적 문제 중 26개를 성공적으로 해결했다.

Conclusion: KryptoPilot의 결과는 오픈 월드 기반의 세분화된 지식 증강과 관리된 추론이 LLM 기반 에이전트를 실세계의 암호학적 악용으로 확대하는 데 필수적임을 보여준다.

Abstract: Capture-the-Flag (CTF) competitions play a central role in modern cybersecurity as a platform for training practitioners and evaluating offensive and defensive techniques derived from real-world vulnerabilities. Despite recent advances in large language models (LLMs), existing LLM-based agents remain ineffective on high-difficulty cryptographic CTF challenges, which require precise cryptanalytic knowledge, stable long-horizon reasoning, and disciplined interaction with specialized toolchains. Through a systematic exploratory study, we show that insufficient knowledge granularity, rather than model reasoning capacity, is a primary factor limiting successful cryptographic exploitation: coarse or abstracted external knowledge often fails to support correct attack modeling and implementation. Motivated by this observation, we propose KryptoPilot, an open-world knowledge-augmented LLM agent for automated cryptographic exploitation. KryptoPilot integrates dynamic open-world knowledge acquisition via a Deep Research pipeline, a persistent workspace for structured knowledge reuse, and a governance subsystem that stabilizes reasoning through behavioral constraints and cost-aware model routing. This design enables precise knowledge alignment while maintaining efficient reasoning across heterogeneous subtasks. We evaluate KryptoPilot on two established CTF benchmarks and in six real-world CTF competitions. KryptoPilot achieves a complete solve rate on InterCode-CTF, solves between 56 and 60 percent of cryptographic challenges on the NYU-CTF benchmark, and successfully solves 26 out of 33 cryptographic challenges in live competitions, including multiple earliest-solved and uniquely-solved instances. These results demonstrate the necessity of open-world, fine-grained knowledge augmentation and governed reasoning for scaling LLM-based agents to real-world cryptographic exploitation.

</details>


### [27] [Blue Teaming Function-Calling Agents](https://arxiv.org/abs/2601.09292)
*Greta Dolcetti,Giulio Zizzo,Sergio Maffeis*

Main category: cs.CR

TL;DR: 다양한 공격에 대한 LLM의 강건성을 평가하고, 방어책의 효과를 측정한 실험적 평가 결과를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 여러 개방형 소스 LLM이 기능 호출 능력을 주장하는 데 대한 안전성을 평가하기 위해서이다.

Method: 네 가지 LLM을 세 가지 다른 공격에 대해 실험적으로 평가하고, 여덟 가지 방어 방법의 효과를 측정하였다.

Result: 이 모델들이 기본적으로 안전하지 않으며, 방어책들이 실제 시나리오에서 아직 적용되지 못함을 보여준다.

Conclusion: LLM의 안전성을 강화하기 위한 추가 연구와 개발이 필요하다.

Abstract: We present an experimental evaluation that assesses the robustness of four open source LLMs claiming function-calling capabilities against three different attacks, and we measure the effectiveness of eight different defences. Our results show how these models are not safe by default, and how the defences are not yet employable in real-world scenarios.

</details>


### [28] [The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware](https://arxiv.org/abs/2601.09625)
*Ben Nassi,Bruce Schneier,Oleg Brodt*

Main category: cs.CR

TL;DR: 이 논문은 LLM 기반 시스템에 대한 공격이 전통적인 맬웨어 캠페인과 유사한 다단계 시퀀스를 포함한다고 제안하며, 이를 분석하기 위한 새로운 모델인 '프롬프트웨어'를 소개한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 시스템의 신속한 채택은 기존 보안 프레임워크가 적절히 대응하지 못하는 새로운 공격 표면을 생성하고 있다.

Method: 우리는 LLM 기반 애플리케이션을 대상으로 하는 공격이 '프롬프트웨어'라는 별도의 맬웨어 클래스에 해당한다고 제안하고, 이를 분석하기 위한 다섯 단계의 킬 체인 모델을 도입한다.

Result: 최신 공격들을 이 구조에 매핑함으로써 LLM 관련 공격이 전통적인 맬웨어 캠페인과 유사한 체계적인 시퀀스를 따른다는 것을 입증한다.

Conclusion: 프롬프트웨어 킬 체인은 보안 실무자에게 위협 모델링을 위한 구조화된 방법론을 제공하고, AI 안전 및 사이버 보안 연구자들 간의 공통 어휘를 제공한다.

Abstract: The rapid adoption of large language model (LLM)-based systems -- from chatbots to autonomous agents capable of executing code and financial transactions -- has created a new attack surface that existing security frameworks inadequately address. The dominant framing of these threats as "prompt injection" -- a catch-all phrase for security failures in LLM-based systems -- obscures a more complex reality: Attacks on LLM-based systems increasingly involve multi-step sequences that mirror traditional malware campaigns. In this paper, we propose that attacks targeting LLM-based applications constitute a distinct class of malware, which we term \textit{promptware}, and introduce a five-step kill chain model for analyzing these threats. The framework comprises Initial Access (prompt injection), Privilege Escalation (jailbreaking), Persistence (memory and retrieval poisoning), Lateral Movement (cross-system and cross-user propagation), and Actions on Objective (ranging from data exfiltration to unauthorized transactions). By mapping recent attacks to this structure, we demonstrate that LLM-related attacks follow systematic sequences analogous to traditional malware campaigns. The promptware kill chain offers security practitioners a structured methodology for threat modeling and provides a common vocabulary for researchers across AI safety and cybersecurity to address a rapidly evolving threat landscape.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [29] [MACRO-LLM: LLM-Empowered Multi-Agent Collaborative Reasoning under Spatiotemporal Partial Observability](https://arxiv.org/abs/2601.09295)
*Handi Chen,Running Zhao,Xiuzhe Wu,Edith C. H. Ngai*

Main category: cs.MA

TL;DR: MACRO-LLM은 시공간적 부분 관측 가능성을 극복하여 다중 에이전트 협력 추론을 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 현실 시나리오에서 물리적 분산으로 인해 다중 에이전트 시스템이 효율적으로 협력하는 데 어려움을 겪는다.

Method: MACRO-LLM은 세 가지 모듈(제안자, 협상자, 내적 탐구자)을 통해 시공간적 제약을 해결한다.

Result: 협력적 순응과 팬데믹 제어에서 extensive evaluations를 통해 효과적인 조정이 가능함을 보여주었다.

Conclusion: MACRO-LLM은 시공간적 부분 관측 가능성을 완화하여 강력한 조정을 가능하게 한다.

Abstract: Large Language Model (LLM) agents deployed in complex real-world scenarios typically operate as spatially distributed entities. However, this physical dispersion constrains agents to limited local perception and finite temporal horizons. We characterize this bottleneck as spatiotemporal partial observability. Given such fragmented awareness, distributed agents struggle to coordinate efficiently. To bridge this gap, we introduce MACRO-LLM, LLM-empowered multi-agent collaborative reasoning under spatiotemporal partial observability. The architecture addresses spatiotemporal constraints via three modules: (1) the CoProposer mitigates temporal uncertainty by verifying candidate actions via predictive rollouts; (2) the Negotiator overcomes spatial myopia by resolving conflicts through mean-field statistical aggregation; and (3) the Introspector ensures continuous adaptation by analyzing historical experience to refine strategies via semantic gradient descent. Extensive evaluations on two complex long-horizon tasks, cooperative adaptive cruise control and pandemic control, demonstrate that our framework effectively mitigates spatiotemporal partial observability through spatial and temporal strategies, enabling robust coordination.

</details>


### [30] [SC-MAS: Constructing Cost-Efficient Multi-Agent Systems with Edge-Level Heterogeneous Collaboration](https://arxiv.org/abs/2601.09434)
*Di Zhao,Longhui Ma,Siwei Wang,Miao Wang,Yi Kong*

Main category: cs.MA

TL;DR: 본 논문은 이질적인 다중 에이전트 시스템(SC-MAS)을 제안하여 에이전트 역할 및 언어 모델을 동적으로 선택함으로써 성능과 비용 간의 균형을 맞춘다.


<details>
  <summary>Details</summary>
Motivation: 사회적 자본 이론에 영감을 받아 서로 다른 역할이 다양한 형태의 협력 혜택을 누리는 것이 중요함을 강조한다.

Method: SC-MAS는 방향 그래프로 다중 에이전트 시스템(MAS)을 모델링하고, 에지에서 쌍방 협력 전략을 명시적으로 나타내어 서로 다른 에이전트 쌍이 맞춤형 통신 패턴을 통해 상호작용할 수 있도록 한다.

Result: SC-MAS는 MMLU에서 3.35%의 정확도 향상과 15.38%의 추론 비용 절감을 달성하고, MBPP에서는 3.53%의 정확도 향상과 12.13%의 비용 절감을 달성하였다.

Conclusion: SC-MAS의 결과는 이질적인 협력의 유효성을 입증하고 다중 에이전트 시스템에서의 실행 가능성을 보여준다.

Abstract: Large Language Model (LLM)-based Multi-Agent Systems (MAS) enhance complex problem solving through multi-agent collaboration, but often incur substantially higher costs than single-agent systems. Recent MAS routing methods aim to balance performance and overhead by dynamically selecting agent roles and language models. However, these approaches typically rely on a homogeneous collaboration mode, where all agents follow the same interaction pattern, limiting collaboration flexibility across different roles. Motivated by Social Capital Theory, which emphasizes that different roles benefit from distinct forms of collaboration, we propose SC-MAS, a framework for constructing heterogeneous and cost-efficient multi-agent systems. SC-MAS models MAS as directed graphs, where edges explicitly represent pairwise collaboration strategies, allowing different agent pairs to interact through tailored communication patterns. Given an input query, a unified controller progressively constructs an executable MAS by selecting task-relevant agent roles, assigning edge-level collaboration strategies, and allocating appropriate LLM backbones to individual agents. Experiments on multiple benchmarks demonstrate the effectiveness of SC-MAS. In particular, SC-MAS improves accuracy by 3.35% on MMLU while reducing inference cost by 15.38%, and achieves a 3.53% accuracy gain with a 12.13% cost reduction on MBPP. These results validate the feasibility of SC-MAS and highlight the effectiveness of heterogeneous collaboration in multi-agent systems.

</details>
