<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 25]
- [cs.CR](#cs.CR) [Total: 11]
- [cs.LG](#cs.LG) [Total: 62]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: ToM(Theory of Mind)을 활용한 다중 에이전트 협력의 새로운 접근법을 제시하며, 이는 작업 특정 공유 생성 모델이나 명시적 통신 없이도 에이전트 간의 협력을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 협력을 위한 기존 방법들이 작업 특정 모델이나 명시적 통신에 의존했던 점을 개선하고자 하는 필요성.

Method: 행동을 관찰하여 다른 에이전트의 믿음과 목표를 추론하는 ToM 장착 에이전트를 도입하는 구조로, 복잡한 추론 트리 기반의 계획 알고리즘을 확장하여 공동 정책 공간을 탐색하게 한다.

Result: ToM 장착 에이전트는 비ToM 에이전트보다 충돌을 회피하고 중복 노력을 줄이며 더 나은 협력을 보여준다.

Conclusion: 이 연구는 인공지능의 실제 응용 가능성을 향상시키고 ToM에 대한 계산적 통찰을 제공한다.

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [2] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: AI는 인터랙티브 오디오-비주얼 콘텐츠 제작에서 어려움이 있으며, 새로운 메트릭과 다중 에이전트 시스템을 통해 이러한 문제를 해결하고자 했다.


<details>
  <summary>Details</summary>
Motivation: AI가 텍스트, 오디오, 이미지, 비디오 생성에서 뛰어난 성과를 보이는 반면, 비디오 게임과 같은 인터랙티브 콘텐츠 제작이 여전히 도전적인 과제로 남아 있다.

Method: AVR-Eval이라는 새로운 콘텐츠 품질 메트릭을 제안하고, 다중 에이전트 시스템인 AVR-Agent를 구축하여 자산에서 JavaScript 코드를 생성한다.

Result: AVR-Agent가 생성한 콘텐츠는 일회 생성된 콘텐츠보다 승률이 더 높은 것으로 나타났지만 커스텀 자산과 AVR 피드백을 효과적으로 활용하지 못하는 것을 발견했다.

Conclusion: 현재의 코딩 모델이 높은 품질의 자산 및 피드백을 효과적으로 활용하지 못함으로써 인간과 기계 간의 콘텐츠 생성 접근 방식에서 본질적인 차이를 드러낸다.

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [3] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: HealthBench의 한계점을 극복하기 위해, 우리는 임상 실습 가이드라인을 기반으로 한 AI 성능 평가 방안을 제안한다.


<details>
  <summary>Details</summary>
Motivation: HealthBench는 전문가의 평가를 기초로 하지만, 이는 지역적 편향과 개인적인 차이를 초래할 수 있다.

Method: 우리는 임상 실습 가이드라인(CPG)을 기반으로 한 보상 함수를 설정하여 보다 공정하고 글로벌 관련성이 높은 벤치마크를 제안한다.

Result: 이 접근법은 의료 언어 모델이 임상적으로 신뢰할 수 있고, 윤리적으로 타당하며, 글로벌 차원에서 통용될 수 있도록 한다.

Conclusion: 결국, CPG에 기반한 보상 체계를 통해 HealthBench의 투명성을 유지하면서 AI의 의학적 언어 모델의 신뢰성을 높이고자 한다.

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [4] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 하이퍼 성질을 활용한 시간 창 동적 논리(HyperTWTL)를 이용한 안전 강화 학습 방법 제안.


<details>
  <summary>Details</summary>
Motivation: 하이퍼 성질을 고려한 안전 강화 학습의 연구 공백을 해결하려고 함.

Method: Markov 결정 과정(MDP)과 HyperTWTL 제약을 사용하며 동적 볼츠만 소프트맥스 RL을 통해 최적 정책을 학습함.

Result: 제안된 방법이 픽업 및 배달 로봇 임무 사례 연구를 통해 효과적이고 확장 가능함을 입증.

Conclusion: 제안된 방법이 두 개의 기존 RL 알고리즘보다 우수한 성능을 보임.

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [5] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: AI의 성공적인 적용을 위해 Object-Centric Process Mining(OCPM)과 Process Intelligence(PI)의 중요성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: AI의 발전이 업무, 상호 작용, 비즈니스 및 연구 방식을 변화시키고 있으나, 산업 환경에서의 성공적인 적용은 여전히 도전 과제다.

Method: OCPM을 활용하여 프로세스 관련 데이터를 구조화하고, 이를 통해 AI의 다양한 형태를 지원하는 방법론을 설명한다.

Result: OCPM이 데이터와 프로세스를 연결하는 중요한 요소로 작용하며, 이를 통해 조직 내에서 AI를 효과적으로 활용할 수 있는 기회를 제시한다.

Conclusion: AI의 성공적인 적용을 위해서는 PI가 필수적이며, OCPM과 AI의 통합 가능성을 탐구한다.

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [6] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 다기준 의사결정 분석에서 랭크 리버설을 감지하기 위한 세 가지 테스트를 제안하고, Scikit-Criteria 라이브러리에 이들을 구현했다.


<details>
  <summary>Details</summary>
Motivation: 다기준 의사결정 방법에서 랭크 리버설 문제는 결과에 중대한 영향을 미치므로, 방법의 성능을 측정할 수 있는 메커니즘이 필요하다.

Method: 세 가지 랭크 리버설 감지 테스트 제안 및 Scikit-Criteria 라이브러리에 이들 구현.

Result: 다양한 시나리오에서 이 테스트를 구현하면서 발생하는 복잡한 문제들을 다룬다.

Conclusion: 이 추가 기능들이 다기준 의사결정 방법의 평가에 중요한 역할을 할 수 있음을 논의한다.

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [7] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: 이 논문은 RDF 그래프에서 SHACL 검증을 업데이트 하였을 때의 문제를 연구하며, SHACL 기반 업데이트 언어를 제시하고 정적 검증 문제를 분석한다.


<details>
  <summary>Details</summary>
Motivation: 이 논문의 동기는 RDF 그래프의 동적 변화를 반영하고 SHACL 사양이 업데이트 후에도 유효한지 검증할 필요성이다.

Method: SHACL 제약 조건에 업데이트 작업을 포함시키는 회귀 기법을 사용하여 정적 검증 문제를 SHACL 제약 조건의 (비)만족 가능성으로 축소한다.

Result: 정적 검증 문제의 계산 복잡성을 분석하고 SHACL의 주요 일부에 대해 논의하였다.

Conclusion: 정적 검증 및 기타 정적 분석 작업을 수행하는 프로토타입 구현을 제시하고 초기 실험을 통해 그 성능을 시연하였다.

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [8] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: AI 알고리즘의 리스크와 편견을 완화하기 위해 AI 생산 파이프라인의 재설계를 제안하고, 협력적 접근을 통한 증강된 AI 생애 주기를 소개한다.


<details>
  <summary>Details</summary>
Motivation: AI 알고리즘이 문화적으로 소외된 그룹에 불균형적인 영향을 미친다는 문제의식에서 출발한다.

Method: 협력적 생산, 다양성, 형평성, 포용성, 다학제 협업을 중심으로 한 재설계된 AI 생애 주기를 소개한다.

Result: AI 생애 주기는 공동 프레이밍, 공동 설계, 공동 구현, 공동 배포, 공동 유지 관리의 다섯 가지 상호 연결된 단계로 구성된다.

Conclusion: 제안된 생애 주기가 여러 윤리적 프레임워크와 어떻게 연결되는지 설명하고, 참여 거버넌스를 확장하기 위한 주요 연구 질문을 제시한다.

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [9] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 인간의 평가 능력이 불완전한데, 교육 관련 AI 훈련 데이터 생성 필요성이 커짐에 따라 Cohen의 카파와 같은 전통적인 상호 평가 신뢰도(IRR) 메트릭에 의존하는 것이 문제라는 논지를 피력함.


<details>
  <summary>Details</summary>
Motivation: AI 교육 응용 프로그램에서 대량의 훈련 데이터를 생성할 필요가 커지면서 인간의 신뢰성에 대한 과도한 의존이 문제가 됨.

Method: 다섯 가지 대체 평가 방법(다중 레이블 주석, 전문가 기반 접근법, 루프 종료 유효성 등)을 제시함.

Result: 이러한 새로운 접근 방식들이 IRR에 의존하는 방법보다 개선된 학습과 실질적인 통찰력을 제공할 수 있음을 강조함.

Conclusion: 주석 품질과 진실의 기준을 재고하고, 단순한 합의보다 유효성과 교육적 영향을 우선시할 것을 권장함.

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [10] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: AI 시스템의 안전성과 웰빙을 높이기 위해, 인간을 권한 있게 하고 인간과 AI 간의 권력 균형을 관리하는 목표 기반의 방안을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI 안전성, 인간의 권한 및 AI 간의 권력 균형을 고려한 설계를 통해 안전하고 복지 증진을 목표로 함.

Method: 부분적으로 axiom적인 접근을 통해 인간의 권한을 측정하는 목표 함수를 설계하고, 다중 에이전트 강화 학습을 통해 이를 계산하는 알고리즘을 개발.

Result: 이 메트릭을 (부드럽게) 최대화한 결과, 다양한 상황에서 인간 권력의 집합 메트릭이 안전한 목표로 작용할 수 있음을 보여줌.

Conclusion: 인간 권한 집합의 적절한 메트릭을 부드럽게 최대화하는 것이, 직접적인 유틸리티 기반 목표보다 더 안전할 수 있다는 점을 주장.

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [11] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: RL-PLUS는 LLM의 능력 경계를 넘어서는 강화 학습 접근 방식으로, 두 가지 핵심 요소를 통합하여 향상된 추론 능력을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 RLVR은 LLM의 고유한 능력 경계를 극복하는 데 어려움을 겪고 있으며, 이는 LLM의 행동 공간과 희소 보상 때문입니다.

Method: RL-PLUS는 내부 활용(Thinking)과 외부 데이터(Learning)를 결합하여 Multi-Importance Sampling과 Exploration-Based Advantage Function을 사용합니다.

Result: RL-PLUS는 6개의 수학적 추론 벤치마크에서 기존 RLVR 방법과 비교하여 최첨단 성능을 달성하고, 다양한 모델 계열에서 평균 21.1%에서 69.2%의 개선 효과를 나타냅니다.

Conclusion: RL-PLUS는 작업 경계 붕괴 문제를 효과적으로 해결하며, 여러 벤치마크에서 일관된 성과를 보여주었습니다.

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [12] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: MetaAgent는 실제 경험을 통해 전문성을 개발하는 에이전트적 패러다임을 제안하며, 지속적인 자기 개선과 도구 사용 이력을 통해 지식을 축적하는 방법론을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 형식적인 교육 없이 실행 경험을 통한 전문성 개발을 목표로 하며, 에이전트의 능력 향상을 위한 새로운 접근 방식을 탐구한다.

Method: 기본적인 추론과 도움 요청 능력을 갖춘 최소한의 워크플로우로 시작해, 지식 격차를 해결하기 위해 자연어 도움 요청을 생성하고, 도구 라우터를 통해 적절한 외부 도구에 연결한다.

Result: MetaAgent는 GAIA, WebWalkerQA, BrowseCamp와 같은 어려운 지식 발견 벤치마크에서 워크플로 기반 벤치마크보다 일관되게 우수한 성능을 보인다.

Conclusion: MetaAgent는 스스로 진화하는 에이전트 시스템의 가능성을 보여주며, 일반적인 지식 발견을 위한 강력한 도구로 자리매김할 수 있는 잠재력을 가지고 있다.

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [13] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 인간과 LLM의 작업 생성 행위를 비교한 결과, 인간의 작업 생성은 개인적 가치와 인지 스타일과 같은 심리적 요인에 크게 영향을 받지만, LLM은 이러한 행동 패턴을 반영하지 못한다는 사실을 발견했다.


<details>
  <summary>Details</summary>
Motivation: 생성 에이전트가 인간의 작업 생성 방식을 모사할 수 있는지 조사하고자 하였다.

Method: 인간의 작업 생성 반응과 LLM(GPT-4o)의 작업 생성 결과를 비교하는 실험을 수행하였다.

Result: 인간의 작업 생성이 심리적 요인에 의해 영향을 받는 반면, LLM은 덜 사회적이고 덜 신체적이며 추상적 주제로 편향된 작업을 생성함을 발견하였다.

Conclusion: 인간의 인지가 가치 중심적이고 구체적인 특성을 가지는데 반해, LLM은 통계적 패턴에 의존하고 있어, 보다 인간 친화적인 에이전트를 설계하기 위해 내재적 동기와 신체적 기반을 통합할 필요가 있다.

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [14] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: 이 논문에서는 VLM의 복잡한 그래픽 추론 능력을 평가하기 위해 ReasonBench라는 평가 벤치마크를 제안하고, 11개의 주류 VLM을 벤치마킹하여 현재 모델의 한계를 밝히고, 성능을 33.5% 향상시키는 이중 최적화 전략을 제시한다.


<details>
  <summary>Details</summary>
Motivation: VLM이 인간 수준의 그래픽 추론 능력을 시뮬레이션하는 데 부족함을 보여주어, 특히 복잡한 그래픽 추론 및 추상 문제 해결의 연구가 필요하다.

Method: ReasonBench를 제안하고, 11개의 주류 VLM을 벤치마킹하며, DiaCoT와 ReasonTune이라는 이중 최적화 전략을 적용하였다.

Result: 11개의 VLM 모델을 평가한 결과, 현재 모델들이 눈에 띄는 한계를 보였으며, 성능이 33.5% 향상되었다.

Conclusion: 이 연구는 VLM의 그래픽 추론 능력 개선을 위해 구성된 평가 벤치마크와 이중 최적화 전략을 통해 중요한 발전을 이루었다.

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [15] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: 대형 추론 모델(LRM)의 안전성을 향상시키기 위해 R1-Act라는 방법을 제안하며, 이는 기존의 안전 지식을 활성화하여 안전 개선을 달성한다.


<details>
  <summary>Details</summary>
Motivation: LRM이 복잡한 작업에서 탁월한 능력을 보임에도 불구하고, 유해한 사용자 지시를 자주 이행하여 안전 우려를 초래한다는 점에서 연구 필요성을 느꼈다.

Method: R1-Act라는 사후 훈련 방법을 통해 구조화된 추론 과정을 통해 안전 지식을 명시적으로 활성화한다.

Result: R1-Act는 안전성 향상과 함께 추론 성능을 유지하여 이전의 정렬 방법보다 뛰어난 성능을 보였다.

Conclusion: R1-Act는 1000개의 훈련 사례와 RTX A6000 GPU에서 90분의 훈련 시간만으로도 안전성을 개선하며, 다양한 LRM 백본 및 크기에서 강건성과 확장성을 입증하였다.

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [16] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: CoRGI는 비주얼 검증 메커니즘을 도입하여 비전-언어 모델의 추론력을 향상시키는 모듈형 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 비전-언어 모델에서 체인 오브 생각 유도 방식이 시각적 콘텐츠에 기반하지 않은 설명을 생성함에 따라 더욱 개선된 추론 메커니즘이 필요하다.

Method: CoRGI는 세 단계로 구성된 파이프라인을 따르며, 텍스트 기반의 추론 체인을 생성하고, 각 단계에 대한 시각적 증거를 추출하며, 이를 텍스트와 결합하여 검증된 답변을 생성한다.

Result: VCR 벤치마크에서 Qwen-2.5VL과 LLaVA-1.6 모델의 추론 성능이 향상되었다.

Conclusion: 중간 추론 단계를 시각적 증거에 기반하여 강화하는 것이 멀티모달 추론의 강건성을 높이는 데 중요하다.

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [17] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: Cognitive Kernel-Pro는 오픈소스 및 무료 멀티 모듈 AI 에이전트 프레임워크로, 고급 AI 에이전트의 개발과 평가를 민주화하기 위해 설계되었다.


<details>
  <summary>Details</summary>
Motivation: 현재 AI 에이전트 시스템은 접근성과 재현성이 제한되어 있어, 연구 커뮤니티에 큰 장애가 되고 있다.

Method: Cognitive Kernel-Pro는 웹, 파일, 코드, 일반 추론의 4개 주요 도메인에서 고품질 훈련 데이터를 체계적으로 조사하고, 에이전트의 반성과 투표 전략을 탐구하여 성능을 향상시킨다.

Result: Cognitive Kernel-Pro는 GAIA에서 테스트하여 오픈소스 및 무료 에이전트 중에서 최고 성능을 기록하였으며, 8B 파라미터 모델이 WebDancer와 WebSailor를 초월하여 새로운 성능 기준을 세웠다.

Conclusion: Cognitive Kernel-Pro는 고성능 AI 에이전트의 접근성을 증대시키며, 오픈소스 커뮤니티에 큰 기여를 할 것으로 기대된다.

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [18] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: 대형 언어 모델은 구조적 추론과 기호 작업에서 뛰어난 능력을 보여주고 있으며, 특히 코딩에서 강점을 보인다. 그러나 공식적인 수학에서는 진전을 이루기 어렵고, 이로 인해 LLM이 어떻게 추론하는지, 감독 방식, 그리고 내부에서 계산 또는 결론 상태를 추적하는지에 대한 중요한 질문이 제기된다.


<details>
  <summary>Details</summary>
Motivation: LLM의 코딩 능력이 수학적 문제 해결과 정리 증명에 어떻게 적용될 수 있는지 이해하고자 한다.

Method: 최근 모델과 벤치마크를 중심으로 머신러닝과 수학적 인식의 교차점에서 세 가지 핵심 문제를 탐구한다.

Result: 수학적 증명 생성이 코드 합성과 비교해 더 취약하게 남아 있는 이유와 LLM이 논리적 상태를 어떻게 표현하는지를 다룬다.

Conclusion: 현재의 한계를 식별하고 그것을 확장할 수 있는 방법을 모색한다.

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [19] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: Pro2Guard는 안전성을 높이기 위해 확률적 도달 가능성 분석에 기반한 선제적 런타임 집행 프레임워크로, LLM 에이전트의 안전성 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트는 로봇공학, 가상 비서, 웹 자동화 등 다양한 분야에서 강력한 자율 기능을 보여주지만, 예측하기 어려운 안전 리스크를 동반한다.

Method: Pro2Guard는 에이전트 행동을 상징적 상태로 추상화하고 실행 추적을 통해 이산 시간 마르코프 체인(DTMC)을 학습하여 비위험 상태에 도달할 확률을 추정한다.

Result: Pro2Guard는 위험 예측이 사용자가 정의한 임계값을 초과할 때 개입을 트리거하고, 가정된 안전 비율을 최대 93.6%까지 실현했다.

Conclusion: Pro2Guard는 안전성을 유지하면서도 높은 작업 성공률을 달성하며, 자율주행 시나리오에서 100%의 법규 위반 및 충돌 예측을 성공적으로 달성했다.

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [20] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: MultiSHAP은 다중 모달 AI 모델의 예측을 세밀한 시각적 및 텍스트 요소 간의 상호작용에 귀속시키는 해석 가능성 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 다중 모달 AI 모델의 블랙박스 특성은 해석 가능성과 신뢰성이 중요한 고위험 응용 분야에서 배포를 방해한다.

Method: Shapley Interaction Index를 활용하여 개별 샘플의 교차 모달 효과를 분석하고, 데이터셋 전반에 걸쳐 일반화된 패턴을 식별하는 모델 불문 해석 프레임워크인 MultiSHAP을 제안한다.

Result: MultiSHAP은 교차 모달 추론 메커니즘을 신뢰성 있게 포착하고, 실제 사례 연구에서도 그 실용성을 입증한다.

Conclusion: MultiSHAP은 두 개 이상의 모달리티를 넘어서 확장 가능하여 복잡한 다중 모달 AI 모델을 해석하기 위한 일반적인 솔루션을 제공한다.

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [21] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 새로운 다단계 LLM 기반 프레임워크를 통해 EMR에서 포괄적인 사전 상담 질문지를 효과적으로 생성하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 전자 의료 기록(EMR)에서 포괄적인 사전 상담 질문지를 생성하는 것은 어려운 과제입니다.

Method: 다단계 LLM 프레임워크를 제안하며, 첫 번째 단계에서 EMR로부터 핵심 사실을 추출하고, 두 번째 단계에서 개인 인과 네트워크를 구성하며, 세 번째 단계에서 맞춤형 질문지를 생성합니다.

Result: 제안한 방법은 정보 범위, 진단 관련성, 이해 용이성 및 생성 시간을 고려했을 때 우수한 성능을 보였습니다.

Conclusion: 우리의 프레임워크는 임상 지식을 명시적으로 구성함으로써 환자 정보 수집을 향상시킬 수 있는 실용적인 잠재력을 강조합니다.

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [22] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 이 논문은 주파수에 따라 달라지는 인과 관계를 모델링한 다중 주파수 가변 시간 지연( MB-VLGC ) Granger 인과성을 제안하고 기존 방법보다 더 우수한 성능을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 분야에서 시간 연속체의 인과 관계를 이해하는 것이 중요하지만, 기존 Granger 인과성 기법은 고정 시간 지연 가정을 가지고 있어 복잡한 시스템에서는 비현실적이다.

Method: 다중 주파수 가변 시간 지연 Granger 인과성 (MB-VLGC)을 형식화하고 주파수 의존 인과 지연을 모델링하는 새로운 프레임워크를 제안하였다.

Result: 다양한 분야에서 진행된 광범위한 실험에서 MB-VLGC가 기존 방법보다 현저히 우수한 성능을 보임을 입증하였다.

Conclusion: MB-VLGC는 모든 유형의 시계열 데이터에 적용될 수 있으며, 코드와 데이터셋이 공개되어 있다.

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [23] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: AI 기반 적응 학습 시스템의 투명성을 높이고 사용자 맞춤형 설명을 생성하기 위한 혼합 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI의 적응 학습 시스템은 교육 방식을 변화시키고 있지만, 결정 과정에 대한 투명성이 부족하다.

Method: 전통적 XAI 기술과 생성 AI 모델을 통합하고 사용자 맞춤화를 통해 다중 모달의 개인화된 설명을 생성하는 혼합 프레임워크를 제안한다.

Result: 프레임워크 설계, 교육 분야에서의 주요 XAI 한계, 정확도, 공정성, 개인화에 대한 연구 방향을 제시한다.

Conclusion: 사용자 중심의 경험을 지원하는 투명한 설명 가능한 AI로의 발전을 목표로 한다.

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [24] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: 소셜 미디어의 AI 추천 시스템은 사용자에게 맞춤형 해석이 부족하여 효과성을 잃게 된다.


<details>
  <summary>Details</summary>
Motivation: 소셜 미디어에서 추천의 해석 가능성이 사용자 특정 요구사항과 일치하지 않기 때문.

Method: 사용자 세분화와 맥락 인식에 기반한 시각적 설명 시스템을 제안하며, 전문가와 일반 사용자에게 적합한 다양한 설명 방법을 포함한다.

Result: 설명 스타일과 세분화를 단일 파이프라인 내에서 동시에 조정하는 첫 번째 프레임워크이다.

Conclusion: 30명의 사용자와의 파일럿을 통해 의사결정 및 신뢰에 미치는 영향을 검증할 예정이다.

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [25] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 대규모 사전 학습된 다중 모달 모델을 사용하여 생성적 콘텐츠의 합성 여부를 효과적으로 판별할 수 있는 보편적인 분류기를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 합성 미디어가 잘못된 정보 확산과 딥페이크 제작에 악용됨에 따라, 그러한 콘텐츠를 효과적으로 탐지할 수 있는 강력한 탐지기가 필요하다.

Method: 대규모 사전 학습된 다중 모달 모델의 잠재 코드를 활용하여 실재와 허위 콘텐츠를 구분하는 선형 분류기를 훈련한다.

Result: 다양한 모달리티에서 기존의 강력한 기준 방법보다 우수하거나 동등한 성능을 달성하면서 계산 효율성과 빠른 훈련 속도를 유지한다.

Conclusion: 음성과 이미지에서의 허위 탐지 성능이 향상되었으며, 이는 다중 모달 모델이 가져오는 정보의 지식 덕분이다.

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [26] [ranDecepter: Real-time Identification and Deterrence of Ransomware Attacks](https://arxiv.org/abs/2508.00293)
*Md Sajidul Islam Sajid,Jinpeng Wei,Ehab Al-Shaer*

Main category: cs.CR

TL;DR: ranDecepter는 랜섬웨어 공격에 대한 방어를 강화하는 혁신적인 접근 방식으로, 실시간 분석과 능동적 사이버 기만을 결합하여 공격자를 속이고 자원을 고갈시키는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 랜섬웨어는 디지털 환경에서 심각하고 광범위한 위협으로 효과적인 대응책이 필요하다.

Method: ranDecepter는 실시간으로 랜섬웨어를 식별하고 deceptive 환경에서 격리하며, 랜섬웨어 코드의 핵심 요소를 자율적으로 식별하여 루프 메커니즘을 생성한다.

Result: ranDecepter는 1,134개의 실제 랜섬웨어 샘플과 12개의 선량한 애플리케이션을 사용한 종합 평가에서 100%의 정확도를 달성하였으며, false positive가 없고 응답 시간에 미치는 영향이 최소화되었다.

Conclusion: ranDecepter는 공격자의 데이터베이스에서 최대 9,223K 항목을 생성할 수 있으며, 이를 통해 공격자의 자원을 약화시키는 잠재력이 있음을 보여준다.

Abstract: Ransomware (RW) presents a significant and widespread threat in the digital
landscape, necessitating effective countermeasures. Active cyber deception is a
promising strategy to thwart RW and limiting its propagation by misleading it
with false information and revealing its true behaviors. Furthermore, RW often
acts as a communication conduit between attackers and defenders, allowing
deception to return false data to attackers and deplete their resources. This
paper introduces ranDecepter, a novel approach that combines active cyber
deception with real-time analysis to enhance defenses against RW attacks. The
ranDecepter identifies RW in real-time and isolates it within a deceptive
environment, autonomously identifying critical elements in the RW code to
create a loop mechanism. By repeatedly restarting the malware and transmitting
counterfeit encryption information and secret keys to the attacker, it forces
the attacker to store these fabricated details for each victim, thereby
depleting their resources. Our comprehensive evaluation of ranDecepter,
conducted using 1,134 real-world malware samples and twelve benign
applications, demonstrates a remarkable 100% accuracy in RW identification,
with no false positives and minimal impact on response times. Furthermore,
within 24-hours, ranDecepter generates up to 9,223K entries in the attacker's
database using 50 agents, showcasing its potential to undermine attacker
resources.

</details>


### [27] [Cryptanalysis of Isogeny-Based Quantum Money with Rational Points](https://arxiv.org/abs/2508.00351)
*Hyeonhak Kim,Donghoe Heo,Seokhie Hong*

Main category: cs.CR

TL;DR: 양자 화폐에 대한 새로운 암호 분석 기법을 제안하며, 효율성을 높이고 검증 절차를 향상시키는 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 양자 클로닝 정리에 기반한 양자 화폐의 안전성을 분석하고, 효율적인 암호 분석 방법을 탐구하고자 한다.

Method: 유리점의 좌표로 나눗셈 다항식을 평가하는 방식으로 O(log^4p)의 속도 향상을 이루는 공격 기법을 제안한다.

Result: 이 공격 방법은 여전히 지수 시간이 필요하지만, 양자 화폐를 위조하는 데에는 실용적이지 않다. 또한, 검증 절차를 더 효율적으로 만든다.

Conclusion: 이 접근 방식은 향후 타원 곡선 기반 양자 암호학 연구에 기여할 것으로 기대된다.

Abstract: Quantum money is the cryptographic application of the quantum no-cloning
theorem. It has recently been instantiated by Montgomery and Sharif (Asiacrypt
'24) from class group actions on elliptic curves. In this work, we propose a
concrete cryptanalysis by leveraging the efficiency of evaluating division
polynomials with the coordinates of rational points, offering a speedup of
O(log^4p) compared to the brute-force attack. Since our attack still requires
exponential time, it remains impractical to forge a quantum banknote.
Interestingly, due to the inherent properties of quantum money, our attack
method also results in a more efficient verification procedure. Our algorithm
leverages the properties of quadratic twists to utilize rational points in
verifying the cardinality of the superposition of elliptic curves. We expect
this approach to contribute to future research on elliptic-curve-based quantum
cryptography.

</details>


### [28] [Preliminary Investigation into Uncertainty-Aware Attack Stage Classification](https://arxiv.org/abs/2508.00368)
*Alessandro Gaudenzi,Lorenzo Nodari,Lance Kaplan,Alessandra Russo,Murat Sensoy,Federico Cerutti*

Main category: cs.CR

TL;DR: 이 논문은 고급 지속 위협(APT)의 공격 단계 추정을 위한 불확실성 인식을 포함한 분류 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: APT는 다단계 및 복잡한 공격 방식으로 인해 사이버 보안에서 심각한 도전 과제가 된다. 공격의 현재 단계를 정확하게 추론하는 것이 효과적인 대응 전략을 수립하는 데 필수적이다.

Method: Evidential Deep Learning(EDL)을 기반으로 한 분류 접근 방식을 제안하며, 이는 Dirichlet 분포의 매개변수를 출력하여 예측 불확실성을 모델링한다.

Result: 제안된 모델은 시뮬레이션 환경에서 공격 단계를 정확하게 추정하고 OOD 입력을 효과적으로 감지할 수 있음을 보여주었다.

Conclusion: 불확실성을 인식하는 모델을 동적이고 적대적인 환경에서 단계적 위협 탐지에 배포할 수 있는 가능성을 뒷받침한다.

Abstract: Advanced Persistent Threats (APTs) represent a significant challenge in
cybersecurity due to their prolonged, multi-stage nature and the sophistication
of their operators. Traditional detection systems typically focus on
identifying malicious activity in binary terms (benign or malicious) without
accounting for the progression of an attack. However, effective response
strategies depend on accurate inference of the attack's current stage, as
countermeasures must be tailored to whether an adversary is in the early
reconnaissance phase or actively conducting exploitation or exfiltration. This
work addresses the problem of attack stage inference under uncertainty, with a
focus on robustness to out-of-distribution (OOD) inputs. We propose a
classification approach based on Evidential Deep Learning (EDL), which models
predictive uncertainty by outputting parameters of a Dirichlet distribution
over possible stages. This allows the system not only to predict the most
likely stage of an attack but also to indicate when it is uncertain or the
input lies outside the training distribution. Preliminary experiments in a
simulated environment demonstrate that the proposed model can accurately infer
the stage of an attack with calibrated confidence while effectively detecting
OOD inputs, which may indicate changes in the attackers' tactics. These results
support the feasibility of deploying uncertainty-aware models for staged threat
detection in dynamic and adversarial environments.

</details>


### [29] [Accurate Latent Inversion for Generative Image Steganography via Rectified Flow](https://arxiv.org/abs/2508.00434)
*Yuqi Qian,Yun Cao,Meiyang Lv,Haocheng Fu*

Main category: cs.CR

TL;DR: RF-Stego는 스테가노그래피의 정확한 잠재 역전과 추출 정확도를 향상시키는 새로운 생성 이미지 스테가노그래피 방법입니다.


<details>
  <summary>Details</summary>
Motivation: 확실한 메시지 추출을 위해 잠재 역전의 불정확성이 문제로 지적됨.

Method: PCLI를 개발하여 역전 과정을 정형적으로 제약하고, RF 샘플러를 통해 역전 과정의 수치적 정밀도를 향상시키는 방식으로 접근.

Result: RF-Stego는 최첨단 방법들보다 추출 정확도, 이미지 품질, 강건성, 보안 및 생성 효율성에서 우수함을 보임.

Conclusion: RF-Stego는 스테가노그래피의 정확성과 효율성을 극대화하는 혁신적인 접근법으로, 관련 분야에서의 활용 가능성이 높음.

Abstract: Steganography based on diffusion models has attracted increasing attention
due to its ability to generate high-quality images and exhibit strong
robustness. In such approaches, the secret message is first embedded into the
initial latent variable, and then the stego image is generated through the
forward process. To extract the message, an inversion process is required to
reconstruct the latent variables from the received image. However, inaccurate
latent inversion leads to significant discrepancies between the reconstructed
and original latent variables, rendering message extraction infeasible. To
address this issue, we propose \textbf{RF-Stego}, a novel generative image
steganography method that enables accurate latent inversion and significantly
improves extraction accuracy. First, we develop the \textbf{P}ath
\textbf{C}onsistency \textbf{L}inear \textbf{I}nversion (\textbf{PCLI}), which
imposes formal constraints on the inversion process. By explicitly aligning it
with the forward generation path and modeling both directions along a shared
linear path, PCLI eliminates path mismatch and ensures path consistency
throughout the steganographic process. Second, through rigorous theoretical
proof, we demonstrate that \textbf{R}ectified \textbf{F}low \textbf{(RF)}
offers both theoretical reversibility and numerical stability in the inversion
process. Based on this, we replace traditional unstable samplers with RF
sampler which effectively improves the numerical precision of the inversion
process. Experimental results show RF-Stego outperforms state-of-the-art
methods in terms of extraction accuracy, image quality, robustness, security
and generation efficiency.

</details>


### [30] [CyGATE: Game-Theoretic Cyber Attack-Defense Engine for Patch Strategy Optimization](https://arxiv.org/abs/2508.00478)
*Yuning Jiang,Nay Oo,Qiaoran Meng,Lu Lin,Dusit Niyato,Zehui Xiong,Hoon Wei Lim,Biplab Sikdar*

Main category: cs.CR

TL;DR: 이 논문은 동적 위협 통합과 공격자의 움직임을 예측하여 사이버 공격 방어를 위한 게임 이론적 프레임워크인 CyGATE를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현재 사이버 공격은 여러 단계를 거치며, 방어자는 불확실성 하에서 동적으로 완화를 우선순위로 두어야 한다.

Method: CyGATE는 게임 이론 모델을 사용하여 공격자와 방어자의 상호작용을 모델링하고, 대형 언어 모델과 검색 보강 생성 기법을 결합하여 전술 선택 및 패치 우선 순위를 개선한다.

Result: 두 요원의 시나리오에 적용된 CyGATE는 사이버 공격을 부분 관찰 가능 확률적 게임으로 구성하며, 공격자는 전술을 조정하고 방어자는 변화하는 위험에 따라 패치 우선 순위를 재조정한다.

Conclusion: CyGATE는 높은 위험의 취약점을 효과적으로 우선 순위로 두고, 자원 사용을 최적화하여 효율성을 높인다.

Abstract: Modern cyber attacks unfold through multiple stages, requiring defenders to
dynamically prioritize mitigations under uncertainty. While game-theoretic
models capture attacker-defender interactions, existing approaches often rely
on static assumptions and lack integration with real-time threat intelligence,
limiting their adaptability. This paper presents CyGATE, a game-theoretic
framework modeling attacker-defender interactions, using large language models
(LLMs) with retrieval-augmented generation (RAG) to enhance tactic selection
and patch prioritization. Applied to a two-agent scenario, CyGATE frames cyber
conflicts as a partially observable stochastic game (POSG) across Cyber Kill
Chain stages. Both agents use belief states to navigate uncertainty, with the
attacker adapting tactics and the defender re-prioritizing patches based on
evolving risks and observed adversary behavior. The framework's flexible
architecture enables extension to multi-agent scenarios involving coordinated
attackers, collaborative defenders, or complex enterprise environments with
multiple stakeholders. Evaluated in a dynamic patch scheduling scenario, CyGATE
effectively prioritizes high-risk vulnerabilities, enhancing adaptability
through dynamic threat integration, strategic foresight by anticipating
attacker moves under uncertainty, and efficiency by optimizing resource use.

</details>


### [31] [Activation-Guided Local Editing for Jailbreaking Attacks](https://arxiv.org/abs/2508.00555)
*Jiecong Wang,Haoran Li,Hao Peng,Ziqian Zeng,Zihao Wang,Haohua Du,Zhengtao Yu*

Main category: cs.CR

TL;DR: AGILE은 보안 취약점을 찾아내기 위한 효과적인 젤프레이킹 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 젤프레이킹 방법이 가진 주요 한계를 극복하기 위해.

Method: 시나리오 기반 생성 및 모델의 숨겨진 상태 정보를 활용한 두 단계 프레임워크.

Result: AGILE은 기존 방법보다 최대 37.74% 향상된 성공률을 달성하며, 블랙박스 모델에 대한 우수한 전이성을 보인다.

Conclusion: AGILE은 현재의 방어 메커니즘에 효과적으로 대응하며, 향후 방어 개발에 기여할 통찰력을 제공한다.

Abstract: Jailbreaking is an essential adversarial technique for red-teaming these
models to uncover and patch security flaws. However, existing jailbreak methods
face significant drawbacks. Token-level jailbreak attacks often produce
incoherent or unreadable inputs and exhibit poor transferability, while
prompt-level attacks lack scalability and rely heavily on manual effort and
human ingenuity. We propose a concise and effective two-stage framework that
combines the advantages of these approaches. The first stage performs a
scenario-based generation of context and rephrases the original malicious query
to obscure its harmful intent. The second stage then utilizes information from
the model's hidden states to guide fine-grained edits, effectively steering the
model's internal representation of the input from a malicious toward a benign
one. Extensive experiments demonstrate that this method achieves
state-of-the-art Attack Success Rate, with gains of up to 37.74% over the
strongest baseline, and exhibits excellent transferability to black-box models.
Our analysis further demonstrates that AGILE maintains substantial
effectiveness against prominent defense mechanisms, highlighting the
limitations of current safeguards and providing valuable insights for future
defense development. Our code is available at
https://github.com/yunsaijc/AGILE.

</details>


### [32] [LeakSealer: A Semisupervised Defense for LLMs Against Prompt Injection and Leakage Attacks](https://arxiv.org/abs/2508.00602)
*Francesco Panebianco,Stefano Bonfanti,Francesco Trovò,Michele Carminati*

Main category: cs.CR

TL;DR: 이 논문은 대형 언어 모델(LLM)의 보안 위협을 분석하고, 이를 방어하기 위한 LeakSealer라는 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 보급 증가에 따른 보안 위협, 특히 재버킹과 데이터 유출 공격의 문제를 해결하고자 함.

Method: 역사적 상호작용 데이터를 분석하여 사용 맵을 생성하고, LeakSealer라는 모델-무관 프레임워크를 통해 정적 분석과 동적 방어를 결합.

Result: LeakSealer는 ToxicChat 데이터셋에서 프롬프트 주입을 식별할 때 높은 정밀도와 재현율을 기록하였고, PII 유출 탐지에서 AUPRC 0.97을 기록하였다.

Conclusion: LeakSealer는 LLM의 보안 위협에 대해 효과적인 방어 메커니즘을 제공하여 기존 방법보다 우수한 성능을 보인다.

Abstract: The generalization capabilities of Large Language Models (LLMs) have led to
their widespread deployment across various applications. However, this
increased adoption has introduced several security threats, notably in the
forms of jailbreaking and data leakage attacks. Additionally, Retrieval
Augmented Generation (RAG), while enhancing context-awareness in LLM responses,
has inadvertently introduced vulnerabilities that can result in the leakage of
sensitive information. Our contributions are twofold. First, we introduce a
methodology to analyze historical interaction data from an LLM system, enabling
the generation of usage maps categorized by topics (including adversarial
interactions). This approach further provides forensic insights for tracking
the evolution of jailbreaking attack patterns. Second, we propose LeakSealer, a
model-agnostic framework that combines static analysis for forensic insights
with dynamic defenses in a Human-In-The-Loop (HITL) pipeline. This technique
identifies topic groups and detects anomalous patterns, allowing for proactive
defense mechanisms. We empirically evaluate LeakSealer under two scenarios: (1)
jailbreak attempts, employing a public benchmark dataset, and (2) PII leakage,
supported by a curated dataset of labeled LLM interactions. In the static
setting, LeakSealer achieves the highest precision and recall on the ToxicChat
dataset when identifying prompt injection. In the dynamic setting, PII leakage
detection achieves an AUPRC of $0.97$, significantly outperforming baselines
such as Llama Guard.

</details>


### [33] [FedGuard: A Diverse-Byzantine-Robust Mechanism for Federated Learning with Major Malicious Clients](https://arxiv.org/abs/2508.00636)
*Haocheng Jiang,Hua Shen,Jixin Zhang,Willy Susilo,Mingwu Zhang*

Main category: cs.CR

TL;DR: FedGuard는 분산 학습에서 발생할 수 있는 비잔틴 공격에 대한 새로운 방어 메커니즘이다.


<details>
  <summary>Details</summary>
Motivation: 분산 학습 프레임워크는 비잔틴 공격에 취약하며, 기존 방어 메커니즘은 특정 공격 유형에만 효과적이다.

Method: FedGuard는 클라이언트가 추가 데이터를 포함하도록 요구하여 중독된 모델을 식별 및 제외한다.

Result: FedGuard는 세 가지 비독립적이고 비동질적(non-IID) 데이터셋에서 90%의 클라이언트가 비잔틴이고 여러 유형의 공격이 발생하는 상황에서도 기존 방식보다 우수한 성능을 보였다.

Conclusion: FedGuard는 비잔틴 공격을 완화하는 데 있어 기존의 강력한 연합 학습 방식보다 효과적이다.

Abstract: Federated learning is a distributed training framework vulnerable to
Byzantine attacks, particularly when over 50% of clients are malicious or when
datasets are highly non-independent and identically distributed (non-IID).
Additionally, most existing defense mechanisms are designed for specific attack
types (e.g., gradient similarity-based schemes can only defend against outlier
model poisoning), limiting their effectiveness. In response, we propose
FedGuard, a novel federated learning mechanism. FedGuard cleverly addresses the
aforementioned issues by leveraging the high sensitivity of membership
inference to model bias. By requiring clients to include an additional
mini-batch of server-specified data in their training, FedGuard can identify
and exclude poisoned models, as their confidence in the mini-batch will drop
significantly. Our comprehensive evaluation unequivocally shows that, under
three highly non-IID datasets, with 90% of clients being Byzantine and seven
different types of Byzantine attacks occurring in each round, FedGuard
significantly outperforms existing robust federated learning schemes in
mitigating various types of Byzantine attacks.

</details>


### [34] [Demo: TOSense -- What Did You Just Agree to?](https://arxiv.org/abs/2508.00659)
*Xinzhang Chen,Hassan Ali,Arash Shaghaghi,Salil S. Kanhere,Sanjay Jha*

Main category: cs.CR

TL;DR: TOSense는 사용자들이 계약서에 대해 자연어로 질문하고 실시간으로 간결한 답변을 받을 수 있는 Chrome 확장 프로그램이다.


<details>
  <summary>Details</summary>
Motivation: 온라인 서비스의 복잡한 약관으로 인한 정보 비대칭과 법적 위험을 줄이기 위함이다.

Method: ToS내용을 자동으로 추출하는 크롤러와 미니LM 모델을 사용한 의미 검색 및 BART 인코더를 통한 답변 관련성 검증을 결합한 시스템이다.

Result: 실험 결과 TOSense는 최대 44.5%의 정확도를 기록하며, 다섯 개 주요 플랫폼에서 효과적임을 입증하였다.

Conclusion: TOSense는 사용자가 약관을 보다 이해하기 쉽게 만들고, 즉각적인 질문 답변 및 새로운 사이트의 색인을 지원하는 효과적인 도구이다.

Abstract: Online services often require users to agree to lengthy and obscure Terms of
Service (ToS), leading to information asymmetry and legal risks. This paper
proposes TOSense-a Chrome extension that allows users to ask questions about
ToS in natural language and get concise answers in real time. The system
combines (i) a crawler "tos-crawl" that automatically extracts ToS content, and
(ii) a lightweight large language model pipeline: MiniLM for semantic retrieval
and BART-encoder for answer relevance verification. To avoid expensive manual
annotation, we present a novel Question Answering Evaluation Pipeline (QEP)
that generates synthetic questions and verifies the correctness of answers
using clustered topic matching. Experiments on five major platforms, Apple,
Google, X (formerly Twitter), Microsoft, and Netflix, show the effectiveness of
TOSense (with up to 44.5% accuracy) across varying number of topic clusters.
During the demonstration, we will showcase TOSense in action. Attendees will be
able to experience seamless extraction, interactive question answering, and
instant indexing of new sites.

</details>


### [35] [Unveiling Dynamic Binary Instrumentation Techniques](https://arxiv.org/abs/2508.00682)
*Oscar Llorente-Vazquez,Xabier Ugarte-Pedrero,Igor Santos-Grueiro,Pablo Garcia Bringas*

Main category: cs.CR

TL;DR: DBI 기술들을 비교 분석하여 각기 다른 성능과 한계를 보여줌.


<details>
  <summary>Details</summary>
Motivation: DBI 기술들이 다양한 산업 및 학문 분야에서 폭넓게 사용되고 있지만, 각 기술마다 한계가 있어 이를 평가하고 비교할 필요성이 있음.

Method: 프로세스 수준과 전체 시스템 접근 방식을 통합하여 DBI 기술의 구성 요소와 도구를 분석하고 성능을 평가함.

Result: 다양한 DBI 접근 방식의 성능을 비교한 결과, 모든 상황에서 최상의 기술은 없음을 발견함.

Conclusion: DBI 기술은 각각의 강점과 약점이 있으며, 상황에 따라 적합한 기술을 선택해야 한다.

Abstract: Dynamic Binary Instrumentation (DBI) is the set of techniques that enable
instrumentation of programs at run-time, making it possible to monitor and
modify the execution of compiled binaries or entire systems. DBI is used for
countless security applications and analyses, and is extensively used across
many fields in both industry and academia. Over the years, several DBI
approaches have been proposed based on different technologies and implementing
diverse techniques. Every solution tries to overcome certain limitations, but
they sometimes bring other shortcomings. Some are specialized for one
particular domain or task, while others have a wider scope.
  In this paper, we shed light into the labyrinth of DBI, bringing together
process-level and whole-system approaches. We depict their building blocks and
analyze the underlying instrumentation techniques, comparing their ability to
instrument different primitives and run-time events. Then, we evaluate their
performance when implementing each primitive, and highlight relevant
observations. Our results show that no single technique is better than the rest
in all circumstances.

</details>


### [36] [LeakyCLIP: Extracting Training Data from CLIP](https://arxiv.org/abs/2508.00756)
*Yunhao Chen,Shujie Wang,Xin Wang,Xingjun Ma*

Main category: cs.CR

TL;DR: 이 연구는 CLIP의 메모리화 및 개인 정보 유출 위험을 조사하고, LeakyCLIP이라는 새로운 공격 프레임워크를 통해 이미지를 재구성하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: CLIP 모델의 보안성을 확보하기 위해 메모리화 및 개인 정보 유출 위험을 이해하는 것이 중요하다.

Method: LeakyCLIP는 적대적 세분화, 임베딩 정렬을 위한 선형 변환, 안정적인 확산 기반의 정제 단계를 포함한 새로운 공격 프레임워크로 구성된다.

Result: LeakyCLIP는 ViT-B-16에서 SSIM을 기준으로 기존 방법에 비해 358% 이상의 성능 향상을 보였다.

Conclusion: 이 연구는 CLIP 전환의 실용적인 방법을 제시하면서 다중 모달 모델의 개인 정보 위험에 대한 통찰력을 제공한다.

Abstract: Understanding the memorization and privacy leakage risks in Contrastive
Language--Image Pretraining (CLIP) is critical for ensuring the security of
multimodal models. Recent studies have demonstrated the feasibility of
extracting sensitive training examples from diffusion models, with conditional
diffusion models exhibiting a stronger tendency to memorize and leak
information. In this work, we investigate data memorization and extraction
risks in CLIP through the lens of CLIP inversion, a process that aims to
reconstruct training images from text prompts. To this end, we introduce
\textbf{LeakyCLIP}, a novel attack framework designed to achieve high-quality,
semantically accurate image reconstruction from CLIP embeddings. We identify
three key challenges in CLIP inversion: 1) non-robust features, 2) limited
visual semantics in text embeddings, and 3) low reconstruction fidelity. To
address these challenges, LeakyCLIP employs 1) adversarial fine-tuning to
enhance optimization smoothness, 2) linear transformation-based embedding
alignment, and 3) Stable Diffusion-based refinement to improve fidelity.
Empirical results demonstrate the superiority of LeakyCLIP, achieving over 358%
improvement in Structural Similarity Index Measure (SSIM) for ViT-B-16 compared
to baseline methods on LAION-2B subset. Furthermore, we uncover a pervasive
leakage risk, showing that training data membership can even be successfully
inferred from the metrics of low-fidelity reconstructions. Our work introduces
a practical method for CLIP inversion while offering novel insights into the
nature and scope of privacy risks in multimodal models.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion](https://arxiv.org/abs/2508.00037)
*Tong Nie,Jian Sun,Wei Ma*

Main category: cs.LG

TL;DR: 이 논문은 대규모 도시 네트워크에서의 동역학 예측을 위한 새로운 모델인 ScaleSTF를 제안하며, 효율성과 효능 간의 균형 문제를 해결하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 도시 시스템은 복잡한 과정을 포함하며, 이의 예측이 산업 및 공학에서의 의사결정에 필요하다.

Method: Transformer 유사 구조를 기반으로 하는 해석 가능한 신경 확산 모델인 ScaleSTF를 제안하며, 저차원 임베딩에 의해 주의 레이어가 유도된다.

Result: ScaleSTF는 대규모 도시 시스템(교통 흐름, 태양광, 스마트 미터 등)에서 검증되었으며, 최첨단 성능과 놀라운 확장성을 보여주었다.

Conclusion: 제안된 접근법은 대규모 도시 네트워크의 동역학 예측에 대한 새로운 관점을 제공한다.

Abstract: Networked urban systems facilitate the flow of people, resources, and
services, and are essential for economic and social interactions. These systems
often involve complex processes with unknown governing rules, observed by
sensor-based time series. To aid decision-making in industrial and engineering
contexts, data-driven predictive models are used to forecast spatiotemporal
dynamics of urban systems. Current models such as graph neural networks have
shown promise but face a trade-off between efficacy and efficiency due to
computational demands. Hence, their applications in large-scale networks still
require further efforts. This paper addresses this trade-off challenge by
drawing inspiration from physical laws to inform essential model designs that
align with fundamental principles and avoid architectural redundancy. By
understanding both micro- and macro-processes, we present a principled
interpretable neural diffusion scheme based on Transformer-like structures
whose attention layers are induced by low-dimensional embeddings. The proposed
scalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is
validated on large-scale urban systems including traffic flow, solar power, and
smart meters, showing state-of-the-art performance and remarkable scalability.
Our results constitute a fresh perspective on the dynamics prediction in
large-scale urban networks.

</details>


### [38] [Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings](https://arxiv.org/abs/2508.00039)
*Kaustav Chatterjee,Joshua Q. Li,Fatemeh Ansari,Masud Rana Munna,Kundan Parajulee,Jared Schwennesen*

Main category: cs.LG

TL;DR: 도로와 철도의 안전성을 높이기 위해 하이웨이 철도 교차로(HRGC) 프로파일 측정을 위한 혁신적인 심층 학습 모델을 개발함.


<details>
  <summary>Details</summary>
Motivation: HRGC는 도로 차량에 안전 위험을 초래하며, 기존의 프로파일 측정 방법은 비용과 시간이 많이 소요되고 교통에 지장을 줄 수 있다.

Method: LSTM과 Transformer 아키텍처를 결합한 하이브리드 심층 학습 프레임워크를 개발하고, 도로 테스트 차량과 산업 표준 보행 프로파일러를 사용하여 데이터를 수집하였다.

Result: 모델 2와 모델 3이 가장 효율적인 아키텍처로 평가되었으며 2D/3D HRGC 프로파일 생성에 사용되었다.

Conclusion: 이 심층 학습 모델은 HRGC의 잠재적 위험을 신속하고 정확하게 평가하는 데 중요한 기여를 하여 도로와 철도의 안전을 향상시킬 수 있다.

Abstract: Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose
safety risks to highway vehicles due to potential hang-ups. These crossings
typically result from post-construction railway track maintenance activities or
non-compliance with design guidelines for HRGC vertical alignments.
Conventional methods for measuring HRGC profiles are costly, time-consuming,
traffic-disruptive, and present safety challenges. To address these issues,
this research employed advanced, cost-effective techniques and innovative
modeling approaches for HRGC profile measurement. A novel hybrid deep learning
framework combining Long Short-Term Memory (LSTM) and Transformer architectures
was developed by utilizing instrumentation and ground truth data.
Instrumentation data were gathered using a highway testing vehicle equipped
with Inertial Measurement Unit (IMU) and Global Positioning System (GPS)
sensors, while ground truth data were obtained via an industrial-standard
walking profiler. Field data was collected at the Red Rock Railroad Corridor in
Oklahoma. Three advanced deep learning models Transformer-LSTM sequential
(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel
(model 3) were evaluated to identify the most efficient architecture. Models 2
and 3 outperformed the others and were deployed to generate 2D/3D HRGC
profiles. The deep learning models demonstrated significant potential to
enhance highway and railroad safety by enabling rapid and accurate assessment
of HRGC hang-up susceptibility.

</details>


### [39] [Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting](https://arxiv.org/abs/2508.00040)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: 본 연구는 독일 전력 시장에서 24시간 전기 가격 예측을 위해 베이지안 레짐 탐지와 조건부 신경 프로세스를 통합하였다.


<details>
  <summary>Details</summary>
Motivation: 독일 전력 시장의 복잡한 특성을 반영한 효율적인 전기 가격 예측 방법이 필요함.

Method: 일일 전기 가격에 적용된 분리된 고착 계층 디리클레 과정 은닉 마르코프 모델(DS-HDP-HMM)과 독립적인 조건부 신경 프로세스(CNP)를 통합한 방법론.

Result: R-NP 모델은 2021년, 2022년, 2023년에 가장 균형 잡힌 솔루션으로 평가되었고, LEAR는 2021년에 최고 순위 모델로 확인됨.

Conclusion: 전략적 최적 운영을 위한 다양한 시나리오에서 R-NP 모델의 실용성이 입증되었음.

Abstract: This work integrates Bayesian regime detection with conditional neural
processes for 24-hour electricity price prediction in the German market. Our
methodology integrates regime detection using a disentangled sticky
hierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to
daily electricity prices. Each identified regime is subsequently modeled by an
independent conditional neural process (CNP), trained to learn localized
mappings from input contexts to 24-dimensional hourly price trajectories, with
final predictions computed as regime-weighted mixtures of these CNP outputs. We
rigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated
auto-regressive (LEAR) models by integrating their forecasts into diverse
battery storage optimization frameworks, including price arbitrage, risk
management, grid services, and cost minimization. This operational utility
assessment revealed complex performance trade-offs: LEAR often yielded superior
absolute profits or lower costs, while DNN showed exceptional optimality in
specific cost-minimization contexts. Recognizing that raw prediction accuracy
doesn't always translate to optimal operational outcomes, we employed TOPSIS as
a comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified
LEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model
emerged as the most balanced and preferred solution for 2021, 2022 and 2023.

</details>


### [40] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
*Yebo Wu,Jingguang Li,Zhijiang Guo,Li Li*

Main category: cs.LG

TL;DR: 개발적 연합 튜닝(DevFT)은 자원 효율적인 방법으로 LLM을 점진적으로 학습시키며, 기존 방법들보다 뛰어난 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 데이터 프라이버시를 유지하면서 LLM이 다운스트림 작업에 적응할 수 있도록 하는 연합 튜닝의 필요성.

Method: DevFT는 세분화된 개발 단계로 구성되어 있으며, 이전 단계에서의 지식이 후속 서브모델에 전달되어 초기화 매개변수를 최적화한다.

Result: DevFT는 여러 벤치마크에서 최대 4.59배 빠른 수렴, 10.67배 통신 오버헤드 감소, 9.07% 평균 성능 향상을 달성하였다.

Conclusion: DevFT는 기존 방법과의 호환성을 유지하면서도 제안된 접근법이 더욱 효과적임을 입증하였다.

Abstract: Federated fine-tuning enables Large Language Models (LLMs) to adapt to
downstream tasks while preserving data privacy, but its resource-intensive
nature limits deployment on edge devices. In this paper, we introduce
Developmental Federated Tuning (DevFT), a resource-efficient approach inspired
by cognitive development that progressively builds a powerful LLM from a
compact foundation. DevFT decomposes the fine-tuning process into developmental
stages, each optimizing submodels with increasing parameter capacity. Knowledge
from earlier stages transfers to subsequent submodels, providing optimized
initialization parameters that prevent convergence to local minima and
accelerate training. This paradigm mirrors human learning, gradually
constructing comprehensive knowledge structure while refining existing skills.
To efficiently build stage-specific submodels, DevFT introduces
deconfliction-guided layer grouping and differential-based layer fusion to
distill essential information and construct representative layers. Evaluations
across multiple benchmarks demonstrate that DevFT significantly outperforms
state-of-the-art methods, achieving up to 4.59$\times$ faster convergence,
10.67$\times$ reduction in communication overhead, and 9.07% average
performance improvement, while maintaining compatibility with existing
approaches.

</details>


### [41] [Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity](https://arxiv.org/abs/2508.00043)
*Nhut Truong,Uri Hasson*

Main category: cs.LG

TL;DR: 이 논문은 다양한 방식으로 구현된 위상 신경망을 비교하여 가중치 유사성(WS)과 활성화 유사성(AS)의 효과를 분석하고, WS가 분류 정확도와 견고성에서 우수하다는 것을 발견하였다.


<details>
  <summary>Details</summary>
Motivation: 위상 신경망의 다양한 구현 방식이 네트워크의 학습된 표현에 미치는 영향을 체계적으로 분석하고자 하였다.

Method: 두 가지 공간적 제약(WS 및 AS)을 가진 위상 합성곱 신경망을 비교하였다.

Result: WS는 AS 및 표준 CNN에 비해 노이즈에 대한 견고성, 입력 감도, 기능적 국소화에서 우수한 성과를 보였다.

Conclusion: WS 제약이 특징 학습 및 기능적 조직에 긍정적인 영향을 미친다는 것을 제안한다.

Abstract: Topographic neural networks are computational models that can simulate the
spatial and functional organization of the brain. Topographic constraints in
neural networks can be implemented in multiple ways, with potentially different
impacts on the representations learned by the network. The impact of such
different implementations has not been systematically examined. To this end,
here we compare topographic convolutional neural networks trained with two
spatial constraints: Weight Similarity (WS), which pushes neighboring units to
develop similar incoming weights, and Activation Similarity (AS), which
enforces similarity in unit activations. We evaluate the resulting models on
classification accuracy, robustness to weight perturbations and input
degradation, and the spatial organization of learned representations. Compared
to both AS and standard CNNs, WS provided three main advantages: i) improved
robustness to noise, also showing higher accuracy under weight corruption; ii)
greater input sensitivity, reflected in higher activation variance; and iii)
stronger functional localization, with units showing similar activations
positioned at closer distances. In addition, WS produced differences in
orientation tuning, symmetry sensitivity, and eccentricity profiles of units,
indicating an influence of this spatial constraint on the representational
geometry of the network. Our findings suggest that during end-to-end training,
WS constraints produce more robust representations than AS or non-topographic
CNNs. These findings also suggest that weight-based spatial constraints can
shape feature learning and functional organization in biophysical inspired
models.

</details>


### [42] [Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains](https://arxiv.org/abs/2508.00046)
*Ruo Yu Tao,Kaicheng Guo,Cameron Allen,George Konidaris*

Main category: cs.LG

TL;DR: 강화 학습 알고리즘의 부분 관찰성 문제를 완화하기 위해 포괄적인 벤치마크가 필요하다고 주장하며, 새로운 벤치마크와 방법론을 제시.


<details>
  <summary>Details</summary>
Motivation: 부분 관찰성을 완화하는 것은 강화 학습 알고리즘에 필수적이며 도전적이다.

Method: 부분 관찰성에 대한 벤치마크의 두 가지 주요 특성을 제안하고, POBAX라는 오픈소스 라이브러리를 소개한다.

Result: 여러 환경에서 부분 관찰성의 유형을 특성화하고, 제안한 환경이 메모리 개선 가능하다는 것을 입증한다.

Conclusion: 이 프레임워크는 강화 학습의 부분 관찰성을 연구하는 데 필요한 구체적인 신호를 제공한다.

Abstract: Mitigating partial observability is a necessary but challenging task for
general reinforcement learning algorithms. To improve an algorithm's ability to
mitigate partial observability, researchers need comprehensive benchmarks to
gauge progress. Most algorithms tackling partial observability are only
evaluated on benchmarks with simple forms of state aliasing, such as feature
masking and Gaussian noise. Such benchmarks do not represent the many forms of
partial observability seen in real domains, like visual occlusion or unknown
opponent intent. We argue that a partially observable benchmark should have two
key properties. The first is coverage in its forms of partial observability, to
ensure an algorithm's generalizability. The second is a large gap between the
performance of a agents with more or less state information, all other factors
roughly equal. This gap implies that an environment is memory improvable: where
performance gains in a domain are from an algorithm's ability to cope with
partial observability as opposed to other factors. We introduce best-practice
guidelines for empirically benchmarking reinforcement learning under partial
observability, as well as the open-source library POBAX: Partially Observable
Benchmarks in JAX. We characterize the types of partial observability present
in various environments and select representative environments for our
benchmark. These environments include localization and mapping, visual control,
games, and more. Additionally, we show that these tasks are all memory
improvable and require hard-to-learn memory functions, providing a concrete
signal for partial observability research. This framework includes recommended
hyperparameters as well as algorithm implementations for fast, out-of-the-box
evaluation, as well as highly performant environments implemented in JAX for
GPU-scalable experimentation.

</details>


### [43] [TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection](https://arxiv.org/abs/2508.00047)
*Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin*

Main category: cs.LG

TL;DR: TriP-LLM은 시계열 이상 탐지의 최신 프레임워크로, LLM을 활용하여 전통적인 방법의 한계를 극복하고 뛰어난 탐지 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: IoT와 스마트 제조의 발전으로 시계열 데이터가 증가하면서 전통적 통계 방법의 한계가 드러났다.

Method: TriP-LLM은 패칭, 선택 및 글로벌 인코딩을 통해 입력 시계열을 패치 단위 토큰으로 변환하고, 프리 트레인된 LLM으로 처리하여 이상 점수를 도출하는 경량 디코더를 사용한다.

Result: TriP-LLM은 여러 공공 벤치마크 데이터셋에서 최신 방법들과 비교하여 일관되게 우수한 성능을 발휘하였다.

Conclusion: LLM이 아키텍처에 큰 기여를 하며, CI 패치 처리를 사용하는 방법보다 메모리 소비가 적어 GPU 환경에 더 적합함을 보여준다.

Abstract: Time-series anomaly detection plays a central role across a wide range of
application domains. With the increasing proliferation of the Internet of
Things (IoT) and smart manufacturing, time-series data has dramatically
increased in both scale and dimensionality. This growth has exposed the
limitations of traditional statistical methods in handling the high
heterogeneity and complexity of such data. Inspired by the recent success of
large language models (LLMs) in multimodal tasks across language and vision
domains, we propose a novel unsupervised anomaly detection framework: A
Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly
Detection (TriP-LLM). TriP-LLM integrates local and global temporal features
through a tri-branch design-Patching, Selection, and Global-to encode the input
time series into patch-wise tokens, which are then processed by a frozen,
pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from
which anomaly scores are derived. We evaluate TriP-LLM on several public
benchmark datasets using PATE, a recently proposed threshold-free evaluation
metric, and conduct all comparisons within a unified open-source framework to
ensure fairness. Experimental results show that TriP-LLM consistently
outperforms recent state-of-the-art methods across all datasets, demonstrating
strong detection capabilities. Furthermore, through extensive ablation studies,
we verify the substantial contribution of the LLM to the overall architecture.
Compared to LLM-based approaches using Channel Independence (CI) patch
processing, TriP-LLM achieves significantly lower memory consumption, making it
more suitable for GPU memory-constrained environments. All code and model
checkpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git

</details>


### [44] [Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization](https://arxiv.org/abs/2508.00078)
*Imen Mahmoud,Andrei Velichko*

Main category: cs.LG

TL;DR: COVID-19 지표가 비트코인 수익 예측의 정확성을 크게 향상시킨다는 것을 보여주는 새로운 방법론을 제안한다.


<details>
  <summary>Details</summary>
Motivation: COVID-19 관련 건강 데이터를 포함하는 것이 비트코인 수익 예측 정확성을 향상시킬 수 있는지를 평가하기 위함이다.

Method: LightGBM 회귀 모델과 유전자 알고리즘 최적화를 통합하여 예측 모델을 훈련시키고 , COVID-19 데이터의 유무에 따라 성능을 비교하였다.

Result: COVID-19 지표가 모델 성능을 크게 향상시켰으며, 특히 극단적인 시장 변동성을 포착하는 데 효과적이었다.

Conclusion: 제안된 방법론은 공공 건강 신호를 재정 분석 도구에 포함시켜 투자자와 정책 입안자에게 시장 불확실성을 극복하는 데 도움을 준다.

Abstract: This study proposes a novel methodological framework integrating a LightGBM
regression model and genetic algorithm (GA) optimization to systematically
evaluate the contribution of COVID-19-related indicators to Bitcoin return
prediction. The primary objective was not merely to forecast Bitcoin returns
but rather to determine whether including pandemic-related health data
significantly enhances prediction accuracy. A comprehensive dataset comprising
daily Bitcoin returns and COVID-19 metrics (vaccination rates,
hospitalizations, testing statistics) was constructed. Predictive models,
trained with and without COVID-19 features, were optimized using GA over 31
independent runs, allowing robust statistical assessment. Performance metrics
(R2, RMSE, MAE) were statistically compared through distribution overlaps and
Mann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified
individual feature contributions. Results indicate that COVID-19 indicators
significantly improved model performance, particularly in capturing extreme
market fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly
significant statistically). Among COVID-19 features, vaccination metrics,
especially the 75th percentile of fully vaccinated individuals, emerged as
dominant predictors. The proposed methodology extends existing financial
analytics tools by incorporating public health signals, providing investors and
policymakers with refined indicators to navigate market uncertainty during
systemic crises.

</details>


### [45] [Stress-Aware Resilient Neural Training](https://arxiv.org/abs/2508.00098)
*Ashkan Shakarami,Yousef Yeganeh,Azade Farshad,Lorenzo Nicole,Stefano Ghidoni,Nassir Navab*

Main category: cs.LG

TL;DR: Stress-Aware Learning은 신경망이 최적화를 동적으로 조절하여 학습의 문제를 해결하는 방법론이다.


<details>
  <summary>Details</summary>
Motivation: 기계학습에서 최적화의 어려움을 극복하고 일반화 능력을 향상시키기 위한 필요성이 있다.

Method: Plastic Deformation Optimizer를 사용하여 내부 스트레스 신호에 따라 모델 파라미터에 적응형 노이즈를 추가하는 방법.

Result: 여섯 가지 아키텍처와 네 가지 옵티마이저, 일곱 가지 비전 벤치마크에서 성능 향상을 확인함.

Conclusion: Stress-Aware Learning은 최소한의 계산 비용으로 더 강인하고 일반화 가능한 모델을 가능하게 한다.

Abstract: This paper introduces Stress-Aware Learning, a resilient neural training
paradigm in which deep neural networks dynamically adjust their optimization
behavior - whether under stable training regimes or in settings with uncertain
dynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)
Deformation, inspired by structural fatigue in materials science. To
instantiate this concept, we propose Plastic Deformation Optimizer, a
stress-aware mechanism that injects adaptive noise into model parameters
whenever an internal stress signal - reflecting stagnation in training loss and
accuracy - indicates persistent optimization difficulty. This enables the model
to escape sharp minima and converge toward flatter, more generalizable regions
of the loss landscape. Experiments across six architectures, four optimizers,
and seven vision benchmarks demonstrate improved robustness and generalization
with minimal computational overhead. The code and 3D visuals will be available
on GitHub: https://github.com/Stress-Aware-Learning/SAL.

</details>


### [46] [StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection](https://arxiv.org/abs/2508.00117)
*Md. Ehsanul Haque,S. M. Jahidul Islam,Shakil Mia,Rumana Sharmin,Ashikuzzaman,Md Samir Morshed,Md. Tahmidul Huque*

Main category: cs.LG

TL;DR: StackLiverNet은 간 질환 진단을 위한 해석 가능한 앙상블 모델로, 높은 정확도와 효율성을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 간 질환의 조기 진단은 환자의 생존 가능성을 높이는데 중요해, 기존의 기계 학습 모델이 가진 문제점을 해결해야 했다.

Method: StackLiverNet은 여러 하이퍼파라미터 최적화된 기본 분류기로 구성된 앙상블 모델로, 강화된 데이터 전처리 및 특징 선택 기법을 사용하였다.

Result: 테스트 정확도 99.89%, Cohen Kappa 0.9974, AUC 0.9993, 단 5개의 오분류로 우수한 성능을 보였다.

Conclusion: 모델은 임상적 실용성을 위해 빠른 훈련 및 추론 속도를 제공하며, LIME과 SHAP을 통해 예측의 해석 가능성을 높였다.

Abstract: Liver diseases are a serious health concern in the world, which requires
precise and timely diagnosis to enhance the survival chances of patients. The
current literature implemented numerous machine learning and deep learning
models to classify liver diseases, but most of them had some issues like high
misclassification error, poor interpretability, prohibitive computational
expense, and lack of good preprocessing strategies. In order to address these
drawbacks, we introduced StackLiverNet in this study; an interpretable stacked
ensemble model tailored to the liver disease detection task. The framework uses
advanced data preprocessing and feature selection technique to increase model
robustness and predictive ability. Random undersampling is performed to deal
with class imbalance and make the training balanced. StackLiverNet is an
ensemble of several hyperparameter-optimized base classifiers, whose
complementary advantages are used through a LightGBM meta-model. The provided
model demonstrates excellent performance, with the testing accuracy of 99.89%,
Cohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and
efficient training and inference speeds that are amenable to clinical practice
(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local
Interpretable Model-Agnostic Explanations (LIME) are applied to generate
transparent explanations of individual predictions, revealing high
concentrations of Alkaline Phosphatase and moderate SGOT as important
observations of liver disease. Also, SHAP was used to rank features by their
global contribution to predictions, while the Morris method confirmed the most
influential features through sensitivity analysis.

</details>


### [47] [Structured Transformations for Stable and Interpretable Neural Computation](https://arxiv.org/abs/2508.00127)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.LG

TL;DR: 본 연구는 신경망의 안정적인 학습과 해석 가능성을 높이기 위해 계층 수준 변환의 구조적 재정의를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현대 신경망은 인상적인 성능에도 불구하고 안정적 학습과 해석 가능성이 부족하다.

Method: 계층 수준 변환을 비표준 비제약 아핀 패러다임에서 구조적 선형 연산자와 잔여 수정 요소로 분해.

Result: 구조화된 변환을 사용하여 만든 모델은 기울기 조정이 개선되고, 방해에 대한 민감성이 감소하며, 계층별 안정성이 향상된다.

Conclusion: 이 연구는 안정성 및 투명성을 우선시하는 신경 아키텍처를 위한 기초를 제공하며, 표현력이 희생되지 않는 새로운 학습 행동 추론 도구를 제안한다.

Abstract: Despite their impressive performance, contemporary neural networks often lack
structural safeguards that promote stable learning and interpretable behavior.
In this work, we introduce a reformulation of layer-level transformations that
departs from the standard unconstrained affine paradigm. Each transformation is
decomposed into a structured linear operator and a residual corrective
component, enabling more disciplined signal propagation and improved training
dynamics. Our formulation encourages internal consistency and supports stable
information flow across depth, while remaining fully compatible with standard
learning objectives and backpropagation. Through a series of synthetic and
real-world experiments, we demonstrate that models constructed with these
structured transformations exhibit improved gradient conditioning, reduced
sensitivity to perturbations, and layer-wise robustness. We further show that
these benefits persist across architectural scales and training regimes. This
study serves as a foundation for a more principled class of neural
architectures that prioritize stability and transparency-offering new tools for
reasoning about learning behavior without sacrificing expressive power.

</details>


### [48] [ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks](https://arxiv.org/abs/2508.00131)
*Christopher Harvey,Sumaiya Shomaji,Zijun Yao,Amit Noheria*

Main category: cs.LG

TL;DR: 이 연구는 심전도(ECG) 신호의 복잡성과 변동성을 해결하기 위해 PCA와 변형 오토인코더(VAE) 변형을 사용하여 데이터를 단순화하고 예측 정확도를 향상시키는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 심전도 데이터는 복잡하고 개인 간 변이가 커서 딥러닝 모델에 적용하기 어려움. 이에 따라 제한된 데이터로도 효과적으로 심전도 분석을 진행하기 위한 방법이 필요하다.

Method: PCA와 VAE 변형(SAE, A beta-VAE, C beta-VAE)을 사용하여 ECG 신호의 복잡성을 줄이는 특징 생성 방법을 탐색하고, LGBM을 사용하여 downstream 예측 작업을 수행한다.

Result: A beta-VAE가 신호 재구성에서 우수한 성능을 보여 MAE를 15.7+/-3.2 muV로 감소시켰고, SAE 인코딩은 LVEF 예측 성능을 향상시켜 AUROC 0.901을 기록하였다.

Conclusion: 이 연구는 VAE 인코딩이 ECG 데이터 단순화에 효과적이며 최소 데이터 환경에서도 딥러닝 적용을 위한 실제적인 해결책을 제공함을 보여준다.

Abstract: The electrocardiogram (ECG) is an inexpensive and widely available tool for
cardiac assessment. Despite its standardized format and small file size, the
high complexity and inter-individual variability of ECG signals (typically a
60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep
learning models, especially when only small training datasets are available.
This study addresses these challenges by exploring feature generation methods
from representative beat ECGs, focusing on Principal Component Analysis (PCA)
and Autoencoders to reduce data complexity. We introduce three novel
Variational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed
beta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their
effectiveness in maintaining signal fidelity and enhancing downstream
prediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE
achieved superior signal reconstruction, reducing the mean absolute error (MAE)
to 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE
encodings, when combined with traditional ECG summary features, improved the
prediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an
holdout test set area under the receiver operating characteristic curve (AUROC)
of 0.901 with a LGBM classifier. This performance nearly matches the 0.909
AUROC of state-of-the-art CNN model but requires significantly less
computational resources. Further, the ECG feature extraction-LGBM pipeline
avoids overfitting and retains predictive performance when trained with less
data. Our findings demonstrate that these VAE encodings are not only effective
in simplifying ECG data but also provide a practical solution for applying deep
learning in contexts with limited-scale labeled training data.

</details>


### [49] [INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks](https://arxiv.org/abs/2508.00141)
*Mohit Gupta,Debjit Bhowmick,Rhys Newbury,Meead Saberi,Shirui Pan,Ben Beck*

Main category: cs.LG

TL;DR: INSPIRE-GNN은 데이터가 부족한 환경에서 자전거 이용량 추정 정확성을 높이기 위해 설계된 새로운 그래프 신경망 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 도시의 지속 가능한 교통 계획을 위해 자전거 이용량을 정확하게 추정하는 것이 중요하지만, 자전거 센서의 제한된 범덕으로 고급 데이터의 부족이 문제인 도시가 많다.

Method: INSPIRE-GNN은 그래프 합성곱 네트워크(GCN)와 그래프 주의 네트워크(GAT)를 통합하여 DQN 기반 강화 학습(RL) 에이전트와 결합하여 센서 위치 최적화를 진행한다.

Result: 멜버른의 자전거 네트워크에 적용했을 때, INSPIRE-GNN은 기존의 센서 배치 방법보다 통계적으로 유의미한 개선을 보여주었다.

Conclusion: 이 프레임워크는 교통 계획자들에게 센서 네트워크를 효과적으로 확장하고 자전거 데이터의 정확성과 신뢰성을 최대화할 수 있는 실행 가능한 통찰력을 제공한다.

Abstract: Accurate link-level bicycling volume estimation is essential for sustainable
urban transportation planning. However, many cities face significant challenges
of high data sparsity due to limited bicycling count sensor coverage. To
address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning
(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize
sensor placement and improve link-level bicycling volume estimation in
data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks
(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL
agent, enabling a data-driven strategic selection of sensor locations to
maximize estimation performance. Applied to Melbourne's bicycling network,
comprising 15,933 road segments with sensor coverage on only 141 road segments
(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume
estimation by strategically selecting additional sensor locations in
deployments of 50, 100, 200 and 500 sensors. Our framework outperforms
traditional heuristic methods for sensor placement such as betweenness
centrality, closeness centrality, observed bicycling activity and random
placement, across key metrics such as Mean Squared Error (MSE), Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our
experiments benchmark INSPIRE-GNN against standard machine learning and deep
learning models in the bicycle volume estimation performance, underscoring its
effectiveness. Our proposed framework provides transport planners actionable
insights to effectively expand sensor networks, optimize sensor placement and
maximize volume estimation accuracy and reliability of bicycling data for
informed transportation planning decisions.

</details>


### [50] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
*Ziqian Zhong,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 새로운 해석 방법을 제안하여, 데이터 분포의 유사성과 관계없이 조정된 대형 언어 모델(LLM)의 행동을 이해하고, 모니터링하며 제어할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 기존의 해석 방법은 훈련 데이터에 대한 접근이 없는 상황에서 새로운 위협을 감지하고 방어하는 데 한계가 있다.

Method: 모델의 활성화가 아니라 가중치를 해석하는 새로운 방법을 사용하여, 훈련 데이터와 유사한 분포의 데이터가 없이도 행동을 감지한다.

Result: 100%의 공격을 차단하면서도 1.2% 미만의 잘못된 긍정률을 유지하고, 삭제된 주제에 대한 추론을 95.42%의 정확도로 감지할 수 있다.

Conclusion: 모델 배포 전 감사 및 상업적 조정 모델 분석에 대한 가능성을 보여준다.

Abstract: The releases of powerful open-weight large language models (LLMs) are often
not accompanied by access to their full training data. Existing
interpretability methods, particularly those based on activations, often
require or assume distributionally similar data. This is a significant
limitation when detecting and defending against novel potential threats like
backdoors, which are by definition out-of-distribution.
  In this work, we introduce a new method for understanding, monitoring and
controlling fine-tuned LLMs that interprets weights, rather than activations,
thereby side stepping the need for data that is distributionally similar to the
unknown training data. We demonstrate that the top singular vectors of the
weight difference between a fine-tuned model and its base model correspond to
newly acquired behaviors. By monitoring the cosine similarity of activations
along these directions, we can detect salient behaviors introduced during
fine-tuning with high precision.
  For backdoored models that bypasses safety mechanisms when a secret trigger
is present, our method stops up to 100% of attacks with a false positive rate
below 1.2%. For models that have undergone unlearning, we detect inference on
erased topics with accuracy up to 95.42% and can even steer the model to
recover "unlearned" information. Besides monitoring, our method also shows
potential for pre-deployment model auditing: by analyzing commercial
instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover
model-specific fine-tuning focus including marketing strategies and Midjourney
prompt generation.
  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.

</details>


### [51] [DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission](https://arxiv.org/abs/2508.00172)
*Fupei Guo,Hao Zheng,Xiang Zhang,Li Chen,Yue Wang,Songyang Zhang*

Main category: cs.LG

TL;DR: 의료 이미지를 위한 새로운 확산 기반 의미 통신 프레임워크인 DiSC-Med을 제안하며, 의료 데이터의 효율적인 전송을 통해 원격 헬스케어의 응답성을 높이고자 한다.


<details>
  <summary>Details</summary>
Motivation: 인공지능의 발전과 차세대 무선 통신 기술이 결합하여 원격 진단과 개입 응용이 증가하고 있으며, 의료 데이터를 효과적으로 전송하는 것이 필요하다.

Method: DiSC-Med은 의료 강화 압축 및 노이즈 제거 블록을 개발하여 대역폭 효율성과 강건성을 추구하는 의미 통신 프레임워크이다.

Result: DiSC-Med은 기존의 픽셀 기반 통신 방식과는 달리, 중요한 의미 정보를 캡처하고 높은 대역폭 효율성을 바탕으로 우수한 재구성 성능을 보여준다.

Conclusion: 다양한 실제 의료 데이터셋에서의 실험 결과, DiSC-Med은 강건하고 효율적인 원격 의료 응용 가능성을 입증하였다.

Abstract: The rapid development of artificial intelligence has driven smart health with
next-generation wireless communication technologies, stimulating exciting
applications in remote diagnosis and intervention. To enable a timely and
effective response for remote healthcare, efficient transmission of medical
data through noisy channels with limited bandwidth emerges as a critical
challenge. In this work, we propose a novel diffusion-based semantic
communication framework, namely DiSC-Med, for the medical image transmission,
where medical-enhanced compression and denoising blocks are developed for
bandwidth efficiency and robustness, respectively. Unlike conventional
pixel-wise communication framework, our proposed DiSC-Med is able to capture
the key semantic information and achieve superior reconstruction performance
with ultra-high bandwidth efficiency against noisy channels. Extensive
experiments on real-world medical datasets validate the effectiveness of our
framework, demonstrating its potential for robust and efficient telehealth
applications.

</details>


### [52] [RL as Regressor: A Reinforcement Learning Approach for Function Approximation](https://arxiv.org/abs/2508.00174)
*Yongchao Huang*

Main category: cs.LG

TL;DR: 이 논문은 회귀 문제를 강화 학습(RL) 문제로 재구성하여 비대칭 비용이나 비미분 가능 목표와 같은 복잡한 상황에서 더 나은 성능을 달성하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 회귀 기법은 미리 정의된 미분 가능 손실 함수에 구애받아 비대칭 비용이나 복잡한 목표를 충분히 반영하지 못한다.

Method: 회귀를 RL 문제로 프레이밍하고, 모델의 예측을 행동으로 간주하며 예측 오차에 기반한 사용자 정의 보상 신호를 정의함으로써 강력한 RL 알고리즘을 활용하여 함수 근사를 수행한다.

Result: 노이즈가 있는 사인 곡선 학습을 통해 Actor-Critic 에이전트를 개발하고, Prioritized Experience Replay, 네트워크 용량 증가 및 위치 인코딩을 통해 에이전트를 개선하였다.

Conclusion: RL 프레임워크는 회귀 문제를 성공적으로 해결할 뿐만 아니라 목표 정의 및 학습 과정을 안내하는 데 있어 유연성을 제공한다.

Abstract: Standard regression techniques, while powerful, are often constrained by
predefined, differentiable loss functions such as mean squared error. These
functions may not fully capture the desired behavior of a system, especially
when dealing with asymmetric costs or complex, non-differentiable objectives.
In this paper, we explore an alternative paradigm: framing regression as a
Reinforcement Learning (RL) problem. We demonstrate this by treating a model's
prediction as an action and defining a custom reward signal based on the
prediction error, and we can leverage powerful RL algorithms to perform
function approximation. Through a progressive case study of learning a noisy
sine wave, we illustrate the development of an Actor-Critic agent, iteratively
enhancing it with Prioritized Experience Replay, increased network capacity,
and positional encoding to enable a capable RL agent for this regression task.
Our results show that the RL framework not only successfully solves the
regression problem but also offers enhanced flexibility in defining objectives
and guiding the learning process.

</details>


### [53] [EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes](https://arxiv.org/abs/2508.00180)
*Adam Block,Cyril Zhang*

Main category: cs.LG

TL;DR: BEMA는 EMA의 이점을 유지하면서 편향을 제거하여 안정적이고 효율적인 언어 모델 파인튜닝을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 파인튜닝 과정에서의 불확실성으로 인한 훈련 불안정성을 해결하기 위해.

Method: BEMA는 기존 EMA를 수정하여 편향을 제거하는 방법입니다.

Result: BEMA는 다양한 언어 모델 벤치마크에서 EMA 및 일반 훈련보다 향상된 수렴 속도와 최종 성능을 보여줍니다.

Conclusion: BEMA는 언어 모델의 보다 안정적이고 효율적인 파인튜닝을 위한 이론적으로 동기부여된 개입입니다.

Abstract: Stochasticity in language model fine-tuning, often caused by the small batch
sizes typically used in this regime, can destabilize training by introducing
large oscillations in generation quality. A popular approach to mitigating this
instability is to take an Exponential moving average (EMA) of weights
throughout training. While EMA reduces stochasticity, thereby smoothing
training, the introduction of bias from old iterates often creates a lag in
optimization relative to vanilla training. In this work, we propose the
Bias-Corrected Exponential Moving Average (BEMA), a simple and practical
augmentation of EMA that retains variance-reduction benefits while eliminating
bias. BEMA is motivated by a simple theoretical model wherein we demonstrate
provable acceleration of BEMA over both a standard EMA and vanilla training.
Through an extensive suite of experiments on Language Models, we show that BEMA
leads to significantly improved convergence rates and final performance over
both EMA and vanilla training in a variety of standard LM benchmarks, making
BEMA a practical and theoretically motivated intervention for more stable and
efficient fine-tuning.

</details>


### [54] [RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems](https://arxiv.org/abs/2508.00201)
*Mehdi Ben Ayed,Fei Feng,Jay Adams,Vishwakarma Singh,Kritarth Anand,Jiajing Xu*

Main category: cs.LG

TL;DR: RecoMind는 웹 규모의 세션 기반 목표 최적화를 위한 시뮬레이터 기반 강화 학습 프레임워크로, 기존 추천 모델을 활용하여 즉각적인 사용자 상호작용을 개선하고, 웹 규모에서 효율적으로 탐색할 수 있도록 설계되었다.


<details>
  <summary>Details</summary>
Motivation: 기존의 웹 규모 추천 시스템은 즉각적인 사용자 피드백을 우선시하는 감독 학습 방법을 사용하고 있지만, 장기적인 목표 최적화를 위한 강화 학습의 적용은 도전적이다.

Method: RecoMind는 기존 추천 모델을 활용하여 시뮬레이션 환경을 설정하고, 즉각적인 사용자 상호작용 최적화를 위해 RL 정책을 부트스트랩하는 방법을 사용한다.

Result: RecoMind를 통해 훈련된 RL 정책은 전통적인 감독 학습 추천 접근 방식보다 세션 내 사용자 만족도를 크게 향상시켰으며, 온라인 A/B 테스트에서 비디오 시청 횟수를 15.81% 증가시켰고, 세션 깊이를 4.71% 개선했다.

Conclusion: RecoMind는 웹 규모 추천 시스템에 RL을 통합하는 체계적이고 확장 가능한 접근 방식을 제시하며, 세션 기반 사용자 만족도를 최적화하는 데 큰 가능성을 보여준다.

Abstract: Existing web-scale recommendation systems commonly use supervised learning
methods that prioritize immediate user feedback. Although reinforcement
learning (RL) offers a solution to optimize longer-term goals, such as
in-session engagement, applying it at web scale is challenging due to the
extremely large action space and engineering complexity. In this paper, we
introduce RecoMind, a simulator-based RL framework designed for the effective
optimization of session-based goals at web-scale. RecoMind leverages existing
recommendation models to establish a simulation environment and to bootstrap
the RL policy to optimize immediate user interactions from the outset. This
method integrates well with existing industry pipelines, simplifying the
training and deployment of RL policies. Additionally, RecoMind introduces a
custom exploration strategy to efficiently explore web-scale action spaces with
hundreds of millions of items. We evaluated RecoMind through extensive offline
simulations and online A/B testing on a video streaming platform. Both methods
showed that the RL policy trained using RecoMind significantly outperforms
traditional supervised learning recommendation approaches in in-session user
satisfaction. In online A/B tests, the RL policy increased videos watched for
more than 10 seconds by 15.81\% and improved session depth by 4.71\% for
sessions with at least 10 interactions. As a result, RecoMind presents a
systematic and scalable approach for embedding RL into web-scale recommendation
systems, showing great promise for optimizing session-based user satisfaction.

</details>


### [55] [Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models](https://arxiv.org/abs/2508.00202)
*Ecem Bozkurt,Antonio Ortega*

Main category: cs.LG

TL;DR: 이 논문은 노이즈가 있는 데이터로 파인튜닝된 기초 모델이 강건한 분류를 할 수 있도록 하는 두 단계 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기초 모델을 이용한 단순 K-최근접 이웃 방법이 심각한 레이블 노이즈에도 좋은 성능을 보임을 기반으로 한다.

Method: 신뢰성 추정과 신뢰성 가중 추론이라는 두 단계 절차를 따르며, 비음수 커널(NNK) 지역 구성을 통해 훈련 데이터의 지역 이웃을 사용한다.

Result: CIFAR-10과 DermaMNIST에서 우리의 방법이 다양한 노이즈 조건에서 강건성을 개선하며, 표준 K-NN 접근법과 최근 적응형 이웃 기준선을 초월하는 성과를 보였다.

Conclusion: 제안된 방법이 레이블 노이즈가 증가할수록 거리와 지역 이웃에 덜 의존하여 신뢰성 추정을 수행할 수 있음을 보였다.

Abstract: Foundation models (FMs) pretrained on large datasets have become fundamental
for various downstream machine learning tasks, in particular in scenarios where
obtaining perfectly labeled data is prohibitively expensive. In this paper, we
assume an FM has to be fine-tuned with noisy data and present a two-stage
framework to ensure robust classification in the presence of label noise
without model retraining. Recent work has shown that simple k-nearest neighbor
(kNN) approaches using an embedding derived from an FM can achieve good
performance even in the presence of severe label noise. Our work is motivated
by the fact that these methods make use of local geometry. In this paper,
following a similar two-stage procedure, reliability estimation followed by
reliability-weighted inference, we show that improved performance can be
achieved by introducing geometry information. For a given instance, our
proposed inference uses a local neighborhood of training data, obtained using
the non-negative kernel (NNK) neighborhood construction. We propose several
methods for reliability estimation that can rely less on distance and local
neighborhood as the label noise increases. Our evaluation on CIFAR-10 and
DermaMNIST shows that our methods improve robustness across various noise
conditions, surpassing standard K-NN approaches and recent
adaptive-neighborhood baselines.

</details>


### [56] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
*Paul Albert,Frederic Z. Zhang,Hemanth Saratchandran,Anton van den Hengel,Ehsan Abbasnejad*

Main category: cs.LG

TL;DR: KRAdapter는 저랭크 적응의 한계를 극복하고, 비전-언어 모델과 대형 언어 모델에서 성능 향상을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대형 사전 학습 모델에 대한 파라미터 효율적인 미세 조정 기법의 필요성.

Method: Khatri-Rao 곱을 활용하여 고유 효율 랭크의 행렬 곱을 생성하는 KRAdapter 알고리즘을 제안함.

Result: KRAdapter는 1B에서 8B의 파라미터를 가진 비전-언어 및 대형 언어 모델에서 성능을 향상시킴.

Conclusion: KRAdapter는 LoRA의 메모리 및 계산 효율성을 유지하며, 거대 모델을 미세 조정하는 실용적이고 견고한 대안을 제공한다.

Abstract: Parameter-efficient fine-tuning (PEFT) has become a standard approach for
adapting large pre-trained models. Amongst PEFT methods, low-rank adaptation
(LoRA) has achieved notable success. However, recent studies have highlighted
its limitations compared against full-rank alternatives, particularly when
applied to multimodal and large language models. In this work, we present a
quantitative comparison amongst full-rank and low-rank PEFT methods using a
synthetic matrix approximation benchmark with controlled spectral properties.
Our results confirm that LoRA struggles to approximate matrices with relatively
flat spectrums or high frequency components -- signs of high effective ranks.
To this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the
Khatri-Rao product to produce weight updates, which, by construction, tends to
produce matrix product with a high effective rank. We demonstrate performance
gains with KRAdapter on vision-language models up to 1B parameters and on large
language models up to 8B parameters, particularly on unseen common-sense
reasoning tasks. In addition, KRAdapter maintains the memory and compute
efficiency of LoRA, making it a practical and robust alternative to fine-tune
billion-scale parameter models.

</details>


### [57] [Calibrated Language Models and How to Find Them with Label Smoothing](https://arxiv.org/abs/2508.00264)
*Jerry Huang,Peng Lu,Qiuhao Zeng*

Main category: cs.LG

TL;DR: 자연어 처리에서의 최근 발전이 언어 모델의 신뢰성 있는 출력에 미치는 영향을 연구하지 않았음. 연구에서는 다양한 오픈소스 LLM의 교정 저하를 발견하고, 라벨 스무딩이 효과적임을 제안함. LLM의 숨겨진 크기와 어휘 크기가 과신과 직접 관계가 있음을 이론적 및 실험적으로 입증하고, 메모리 효율성을 위한 맞춤형 커널을 설계함.


<details>
  <summary>Details</summary>
Motivation: 자연어 처리(NLP)에서 대형 언어 모델(LLMs)의 지침 따르기 능력을 향상시키는 것이 신뢰성 있는 모델 출력에 어떤 영향을 미치는지 이해할 필요성.

Method: 다양한 오픈소스 LLMs를 조사하고 라벨 스무딩을 적용하여 과신 예측을 정규화하는 방법을 제안.

Result: LLM의 지침 조정 후 교정 저하를 발견했으며, 숨겨진 크기와 어휘 크기로 인해 큰 어휘 LLM에서 스무딩 효과가 저하됨을 입증함.

Conclusion: 메모리 소모를 줄이면서도 성능을 유지하는 맞춤형 커널 설계를 통해 라벨 스무딩 사용의 실질적인 해결책을 제시했다.

Abstract: Recent advances in natural language processing (NLP) have opened up greater
opportunities to enable fine-tuned large language models (LLMs) to behave as
more powerful interactive agents through improved instruction-following
ability. However, understanding how this impacts confidence calibration for
reliable model output has not been researched in full. In this work, we examine
various open-sourced LLMs, identifying significant calibration degradation
after instruction tuning in each. Seeking a practical solution, we look towards
label smoothing, which has been shown as an effective method to regularize for
overconfident predictions but has yet to be widely adopted in the supervised
fine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing
is sufficient to maintain calibration throughout the SFT process. However,
settings remain where the effectiveness of smoothing is severely diminished, in
particular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to
stem from the ability to become over-confident, which has a direct relationship
with the hidden size and vocabulary size, and justify this theoretically and
experimentally. Finally, we address an outstanding issue regarding the memory
footprint of the cross-entropy loss computation in the label smoothed loss
setting, designing a customized kernel to dramatically reduce memory
consumption without sacrificing speed or performance in comparison to existing
solutions for non-smoothed losses.

</details>


### [58] [Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring](https://arxiv.org/abs/2508.00270)
*Robin Schmucker,Nimish Pachapurkar,Shanmuga Bala,Miral Shah,Tom Mitchell*

Main category: cs.LG

TL;DR: 온라인 튜터링 시스템이 학생들에게 제공된 피드백을 개선하기 위해 데이터 분석을 통해 최적의 도움 행동을 학습한다.


<details>
  <summary>Details</summary>
Motivation: 선택적 피드백 제공을 통해 학생들의 학습 효과를 극대화하고자 함.

Method: 다중 무장 강도(MAB) 프레임워크와 오프라인 정책 평가를 활용하여 43,000개의 도움 행동을 분석하고 알고리즘을 설계함.

Result: 166,000회의 연습 세션에서 학생들의 성과가 유의미하게 개선됨.

Conclusion: 데이터 기반 시스템을 통해 실제 교육 정책을 최적화하였으며, 향후 개인화된 피드백 제공의 필요성을 논의함.

Abstract: We present an online tutoring system that learns to provide effective
feedback to students after they answer questions incorrectly. Using data from
one million students, the system learns which assistance action (e.g., one of
multiple hints) to provide for each question to optimize student learning.
Employing the multi-armed bandit (MAB) framework and offline policy evaluation,
we assess 43,000 assistance actions, and identify trade-offs between assistance
policies optimized for different student outcomes (e.g., response correctness,
session completion). We design an algorithm that for each question decides on a
suitable policy training objective to enhance students' immediate second
attempt success and overall practice session performance. We evaluate the
resulting MAB policies in 166,000 practice sessions, verifying significant
improvements in student outcomes. While MAB policies optimize feedback for the
overall student population, we further investigate whether contextual bandit
(CB) policies can enhance outcomes by personalizing feedback based on
individual student features (e.g., ability estimates, response times). Using
causal inference, we examine (i) how effects of assistance actions vary across
students and (ii) whether CB policies, which leverage such effect
heterogeneity, outperform MAB policies. While our analysis reveals that some
actions for some questions exhibit effect heterogeneity, effect sizes may often
be too small for CB policies to provide significant improvements beyond what
well-optimized MAB policies that deliver the same action to all students
already achieve. We discuss insights gained from deploying data-driven systems
at scale and implications for future refinements. Today, the teaching policies
optimized by our system support thousands of students daily.

</details>


### [59] [Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem](https://arxiv.org/abs/2508.00286)
*Mohsen Zaker Esteghamati*

Main category: cs.LG

TL;DR: 성능 기반의 지진 설계를 역설계 문제로 취급하는 방법론을 제시하며, 머신러닝 모델을 통해 설계 변수와 성능 메트릭스 간의 관계를 매핑함.


<details>
  <summary>Details</summary>
Motivation: 성능 기반 설계의 계산 비효율성을 해결하기 위해.

Method: 설계 변수를 성능 목표에 맞추기 위해 설명 가능한 머신러닝 모델을 구현하고, 이를 유전자 최적화 알고리즘에 통합하여 역문제를 해결.

Result: 두 개의 다른 재고(강철 및 콘크리트 모멘트 프레임)에서 연간 예상 지진 손실을 최소화하는 단면 속성을 도출하였으며, 대체 모델의 정확도가 높았다(R2> 90%).

Conclusion: 최적화 알고리즘을 통해 고정된 기하학적 변수에 대해 일관된 엔지니어링 원칙에 따라 최적의 구성원 속성을 식별할 수 있었다.

Abstract: This study presents a methodology to treat performance-based seismic design
as an inverse engineering problem, where design parameters are directly derived
to achieve specific performance objectives. By implementing explainable machine
learning models, this methodology directly maps design variables and
performance metrics, tackling computational inefficiencies of performance-based
design. The resultant machine learning model is integrated as an evaluation
function into a genetic optimization algorithm to solve the inverse problem.
The developed methodology is then applied to two different inventories of steel
and concrete moment frames in Los Angeles and Charleston to obtain sectional
properties of frame members that minimize expected annualized seismic loss in
terms of repair costs. The results show high accuracy of the surrogate models
(e.g., R2> 90%) across a diverse set of building types, geometries, seismic
design, and site hazard, where the optimization algorithm could identify the
optimum values of members' properties for a fixed set of geometric variables,
consistent with engineering principles.

</details>


### [60] [Invariant Graph Transformer for Out-of-Distribution Generalization](https://arxiv.org/abs/2508.00304)
*Tianyin Liao,Ziwei Zhang,Yufei Sun,Chunyu Hu,Jianxin Li*

Main category: cs.LG

TL;DR: 본 논문에서는 Graph Out-Of-Distribution generalized Transformer (GOODFormer)를 제안하여 그래프 구조 패턴을 학습하고 분포 변화에 강한 일반화된 그래프 표현을 추구한다.


<details>
  <summary>Details</summary>
Motivation: 기존 그래프 변환기(GTs)가 분포 변화에 적응하지 못하는 문제를 해결하고자 하며, 그래프 불변 학습을 통해 일반화 가능한 구조 패턴을 캡처하는 것을 목표로 한다.

Method: 세 개의 모듈을 공동 최적화하여 예측된 그래프 구조와 레이블 간의 불변 관계를 캡처하는 방법을 사용하며, 불변 및 변변 그래프를 분리하고, 동적으로 변화하는 서브그래프의 정보를 효과적으로 캡처하는 인코딩 방법을 설계한다.

Result: 벤치마크 데이터 세트에서 extensive 실험을 통해 제안된 방법이 최신 기법들보다 분포 변화에 강하다는 것을 입증하였다.

Conclusion: GOODFormer는 그래프 데이터의 일반화 문제를 효과적으로 해결하고, 이론적 근거를 바탕으로 성능 우위를 입증하였다.

Abstract: Graph Transformers (GTs) have demonstrated great effectiveness across various
graph analytical tasks. However, the existing GTs focus on training and testing
graph data originated from the same distribution, but fail to generalize under
distribution shifts. Graph invariant learning, aiming to capture generalizable
graph structural patterns with labels under distribution shifts, is potentially
a promising solution, but how to design attention mechanisms and positional and
structural encodings (PSEs) based on graph invariant learning principles
remains challenging. To solve these challenges, we introduce Graph
Out-Of-Distribution generalized Transformer (GOODFormer), aiming to learn
generalized graph representations by capturing invariant relationships between
predictive graph structures and labels through jointly optimizing three
modules. Specifically, we first develop a GT-based entropy-guided invariant
subgraph disentangler to separate invariant and variant subgraphs while
preserving the sharpness of the attention function. Next, we design an evolving
subgraph positional and structural encoder to effectively and efficiently
capture the encoding information of dynamically changing subgraphs during
training. Finally, we propose an invariant learning module utilizing subgraph
node representations and encodings to derive generalizable graph
representations that can to unseen graphs. We also provide theoretical
justifications for our method. Extensive experiments on benchmark datasets
demonstrate the superiority of our method over state-of-the-art baselines under
distribution shifts.

</details>


### [61] [PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models](https://arxiv.org/abs/2508.00325)
*Yongquan Qu,Matthieu Blanke,Sara Shamekh,Pierre Gentine*

Main category: cs.LG

TL;DR: 본 논문에서는 지구 시스템 모델링과 데이터 동화(Dynamics Assimilation)에서의 오류 누적 문제를 해결하기 위한 새로운 PnP-DA 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 지구 시스템 모델링은 복잡한 비선형 동역학을 캡처하고 예측 오류를 최소화하는 데 어려움이 있다. 기존 방법들은 가우시안 오차 통계에 의존해 진정한 동적 시스템의 비가우시안적 행동을 포착하지 못한다.

Method: PnP-DA는 경량화된 경량 분석 업데이트와 사전 훈련된 생성적 우선 조건을 결합하는 Plug-and-Play 알고리즘이다.

Result: PnP-DA는 다양한 관측 희소성과 노이즈 수준에서 예측 오류를 지속적으로 줄일 수 있으며, 고전적인 변량 방법들을 초월하는 성능을 보여준다.

Conclusion: 본 알고리즘은 엄격한 통계적 가정을 완화하고 역사적 데이터를 효과적으로 이용하여 예측 성능을 개선할 수 있다.

Abstract: Earth system modeling presents a fundamental challenge in scientific
computing: capturing complex, multiscale nonlinear dynamics in computationally
efficient models while minimizing forecast errors caused by necessary
simplifications. Even the most powerful AI- or physics-based forecast system
suffer from gradual error accumulation. Data assimilation (DA) aims to mitigate
these errors by optimally blending (noisy) observations with prior model
forecasts, but conventional variational methods often assume Gaussian error
statistics that fail to capture the true, non-Gaussian behavior of chaotic
dynamical systems. We propose PnP-DA, a Plug-and-Play algorithm that alternates
(1) a lightweight, gradient-based analysis update (using a Mahalanobis-distance
misfit on new observations) with (2) a single forward pass through a pretrained
generative prior conditioned on the background forecast via a conditional
Wasserstein coupling. This strategy relaxes restrictive statistical assumptions
and leverages rich historical data without requiring an explicit regularization
functional, and it also avoids the need to backpropagate gradients through the
complex neural network that encodes the prior during assimilation cycles.
Experiments on standard chaotic testbeds demonstrate that this strategy
consistently reduces forecast errors across a range of observation sparsities
and noise levels, outperforming classical variational methods.

</details>


### [62] [Embryology of a Language Model](https://arxiv.org/abs/2508.00331)
*George Wang,Garrett Baker,Andrew Gordon,Daniel Murfet*

Main category: cs.LG

TL;DR: 이 논문은 언어 모델의 내부 계산 구조 개발을 이해하기 위한 연구로, UMAP를 사용하여 민감도 행렬을 시각화하여 모델의 구조적 발전을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델의 내부 계산 구조 개발을 이해하는 것은 심층 학습 과학에서 중요하다.

Method: 민감도 행렬에 UMAP을 적용하여 모델의 학습 과정에서 구조적 발전을 시각화하였다.

Result: 시각화를 통해 '신체 계획'의 출현과 공간 토큰을 세는 '간격 지느러미'와 같은 새로운 구조를 발견하였다.

Conclusion: 민감도 분석이 검증을 넘어 혁신적인 메커니즘을 밝혀낼 수 있음을 보여주며, 복잡한 신경망 개발 원리를 연구하는 강력한 도구가 됨을 제시한다.

Abstract: Understanding how language models develop their internal computational
structure is a central problem in the science of deep learning. While
susceptibilities, drawn from statistical physics, offer a promising analytical
tool, their full potential for visualizing network organization remains
untapped. In this work, we introduce an embryological approach, applying UMAP
to the susceptibility matrix to visualize the model's structural development
over training. Our visualizations reveal the emergence of a clear ``body
plan,'' charting the formation of known features like the induction circuit and
discovering previously unknown structures, such as a ``spacing fin'' dedicated
to counting space tokens. This work demonstrates that susceptibility analysis
can move beyond validation to uncover novel mechanisms, providing a powerful,
holistic lens for studying the developmental principles of complex neural
networks.

</details>


### [63] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
*Qilin Liao,Shuo Yang,Bo Zhao,Ping Luo,Hengshuang Zhao*

Main category: cs.LG

TL;DR: 본 논문은 경계 기반 OOD 데이터 생성을 위한 새로운 프레임워크 BOOD를 제안하여, 기존 방법보다 OOD 특징을 더 효율적으로 합성하여 성능을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: OOD 탐지 성능을 향상시키기 위해, 잠재 공간의 특징을 기반으로 보조 훈련 데이터를 합성하는 기존 방법의 한계를 극복하고자 한다.

Method: BOOD는 ID 데이터셋에서 텍스트 조건의 잠재 특징 공간을 학습하고, 결정 경계에 가까운 ID 특징을 선택한 뒤, 이를 교란하여 OOD 특징을 형성한다.

Result: BOOD는 데이터셋 CIFAR-100에서 기존 최첨단 방법보다 평균 FPR95를 29.64% 줄이고, 평균 AUROC를 7.27% 개선하였다.

Conclusion: BOOD는 OOD 특징 합성의 정보성을 높이고, ID와 OOD 데이터 간의 명확한 구분을 용이하게 한다.

Abstract: Harnessing the power of diffusion models to synthesize auxiliary training
data based on latent space features has proven effective in enhancing
out-of-distribution (OOD) detection performance. However, extracting effective
features outside the in-distribution (ID) boundary in latent space remains
challenging due to the difficulty of identifying decision boundaries between
classes. This paper proposes a novel framework called Boundary-based
Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD
features and generates human-compatible outlier images using diffusion models.
BOOD first learns a text-conditioned latent feature space from the ID dataset,
selects ID features closest to the decision boundary, and perturbs them to
cross the decision boundary to form OOD features. These synthetic OOD features
are then decoded into images in pixel space by a diffusion model. Compared to
previous works, BOOD provides a more training efficient strategy for
synthesizing informative OOD features, facilitating clearer distinctions
between ID and OOD data. Extensive experimental results on common benchmarks
demonstrate that BOOD surpasses the state-of-the-art method significantly,
achieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27%
improvement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.

</details>


### [64] [Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization](https://arxiv.org/abs/2508.00357)
*Yoonhyuk Choi,Jiho Choi,Chong-Kwon Kim*

Main category: cs.LG

TL;DR: SGPC는 그래프 신경망의 오버 스무딩 문제를 해결하기 위한 새로운 아키텍처로, 효율적인 반 감독 노드 분류를 위해 다양한 메커니즘을 결합하여 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 그래프 신경망에서의 오버 스무딩 문제는 근접한 노드들이 종종 다른 레이블을 가지는 이질적 그래프에서 두드러지며, 이는 노드 기능의 붕괴를 초래한다.

Method: SGPC는 세포-시프 메시지 전달을 최적 수송 기반 리프팅, 분산 감소 확산 및 PAC-Bayes 스펙트럼 정규화와 결합하여 설계된 통합 아키텍처이다.

Result: SGPC는 고전적인 스펙트럼 및 시프 기반 그래프 신경망보다 더 높은 성능을 보이며, 미지의 노드에 대한 신뢰 구간을 인증할 수 있다.

Conclusion: 이 연구는 SGPC가 선형 계산 복잡도를 통해 성능 한계를 이론적으로 확립하고, 최적의 경량 구조로 일반화 가능성을 높인다는 것을 보여준다.

Abstract: Over-smoothing in Graph Neural Networks (GNNs) causes collapse in distinct
node features, particularly on heterophilic graphs where adjacent nodes often
have dissimilar labels. Although sheaf neural networks partially mitigate this
problem, they typically rely on static or heavily parameterized sheaf
structures that hinder generalization and scalability. Existing sheaf-based
models either predefine restriction maps or introduce excessive complexity, yet
fail to provide rigorous stability guarantees. In this paper, we introduce a
novel scheme called SGPC (Sheaf GNNs with PAC-Bayes Calibration), a unified
architecture that combines cellular-sheaf message passing with several
mechanisms, including optimal transport-based lifting, variance-reduced
diffusion, and PAC-Bayes spectral regularization for robust semi-supervised
node classification. We establish performance bounds theoretically and
demonstrate that the resulting bound-aware objective can be achieved via
end-to-end training in linear computational complexity. Experiments on nine
homophilic and heterophilic benchmarks show that SGPC outperforms
state-of-the-art spectral and sheaf-based GNNs while providing certified
confidence intervals on unseen nodes.

</details>


### [65] [OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions](https://arxiv.org/abs/2508.00364)
*Chanyoung Yoon,Sangbong Yoo,Soobin Yim,Chansoo Kim,Yun Jang*

Main category: cs.LG

TL;DR: OID-PPO는 최적 실내 디자인을 위한 새로운 강화 학습 프레임워크로, 전문가 정의 기능 및 시각 가이드를 통합하여 높은 품질의 레이아웃을 생성한다.


<details>
  <summary>Details</summary>
Motivation: 주거 내부 디자인이 거주자 만족도에 미치는 영향은 크지만, 비구조적 공간 레이아웃과 높은 계산 요구로 인해 어려움을 겪고 있다.

Method: OID-PPO는 근접 정책 최적화를 기반으로 하여 전문가 정의 가이드를 구조적인 보상 함수에 통합하여 가구 배치를 연속적으로 수행할 수 있게 한다.

Result: 다양한 방 모양과 가구 구성에서 OID-PPO는 레이아웃 품질 및 계산 효율성 측면에서 최첨단 방법들을 크게 초월하였다.

Conclusion: 구조화된 가이드라인 통합의 영향과 개별 디자인 제약의 기여를 밝혀내며, OID-PPO의 효과성을 입증하였다.

Abstract: Designing residential interiors strongly impacts occupant satisfaction but
remains challenging due to unstructured spatial layouts, high computational
demands, and reliance on expert knowledge. Existing methods based on
optimization or deep learning are either computationally expensive or
constrained by data scarcity. Reinforcement learning (RL) approaches often
limit furniture placement to discrete positions and fail to incorporate design
principles adequately. We propose OID-PPO, a novel RL framework for Optimal
Interior Design using Proximal Policy Optimization, which integrates
expert-defined functional and visual guidelines into a structured reward
function. OID-PPO utilizes a diagonal Gaussian policy for continuous and
flexible furniture placement, effectively exploring latent environmental
dynamics under partial observability. Experiments conducted across diverse room
shapes and furniture configurations demonstrate that OID-PPO significantly
outperforms state-of-the-art methods in terms of layout quality and
computational efficiency. Ablation studies further demonstrate the impact of
structured guideline integration and reveal the distinct contributions of
individual design constraints.

</details>


### [66] [Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions](https://arxiv.org/abs/2508.00392)
*Lijun Zhang,Wenhao Yang,Guanghui Wang,Wei Jiang,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 이 논문은 변화하는 환경에 대응하기 위해 보편적인 알고리즘을 논의하며, 이중 적응성을 가진 메타-전문가 프레임워크를 제안하여 다양한 종류의 볼록 함수의 적응적 후회(minimizing adaptive regret)를 효과적으로 최소화한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 온라인 학습 알고리즘들은 특정 종류의 볼록 함수만 처리 가능하고, 매개변수에 대한 사전 지식이 필요하여 실제 세계에서의 적용에 한계가 있다.

Method: 이중 적응성 알고리즘을 위한 메타-전문가 프레임워크를 제안하고, 전문가의 수를 늘리거나 전문가의 능력을 강화하는 전략을 사용하여 보편성을 달성한다.

Result: 제안된 알고리즘들이 여러 종류의 볼록 함수에 대해 적응적 후회를 최소화할 수 있으며, 함수 유형이 라운드 간에 전환되는 것도 허용됨을 이론적으로 분석한다.

Conclusion: 메타-전문가 프레임워크를 온라인 복합 최적화로 확장하여 복합 함수의 적응적 후회를 최소화하기 위한 보편적 알고리즘을 개발한다.

Abstract: To deal with changing environments, a new performance measure -- adaptive
regret, defined as the maximum static regret over any interval, was proposed in
online learning. Under the setting of online convex optimization, several
algorithms have been successfully developed to minimize the adaptive regret.
However, existing algorithms lack universality in the sense that they can only
handle one type of convex functions and need apriori knowledge of parameters,
which hinders their application in real-world scenarios. To address this
limitation, this paper investigates universal algorithms with dual adaptivity,
which automatically adapt to the property of functions (convex, exponentially
concave, or strongly convex), as well as the nature of environments (stationary
or changing). Specifically, we propose a meta-expert framework for dual
adaptive algorithms, where multiple experts are created dynamically and
aggregated by a meta-algorithm. The meta-algorithm is required to yield a
second-order bound, which can accommodate unknown function types. We further
incorporate the technique of sleeping experts to capture the changing
environments. For the construction of experts, we introduce two strategies
(increasing the number of experts or enhancing the capabilities of experts) to
achieve universality. Theoretical analysis shows that our algorithms are able
to minimize the adaptive regret for multiple types of convex functions
simultaneously, and also allow the type of functions to switch between rounds.
Moreover, we extend our meta-expert framework to online composite optimization,
and develop a universal algorithm for minimizing the adaptive regret of
composite functions.

</details>


### [67] [ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs](https://arxiv.org/abs/2508.00394)
*Antonis Klironomos,Baifan Zhou,Zhipeng Tan,Zhuoxun Zheng,Mohamed H. Gad-Elrab,Heiko Paulheim,Evgeny Kharlamov*

Main category: cs.LG

TL;DR: ExeKGLib는 최소한의 기계 학습 지식을 가진 사용자도 기계 학습 파이프라인을 구축할 수 있도록 지원하는 파이썬 라이브러리이다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 전문가가 아닌 과학 및 공학 분야의 전문가들이 기계 학습 기반 분석을 필요로 하지만 필요한 전문 지식이 부족하다는 문제를 해결하고자 한다.

Method: 기계 학습 지식을 간단하게 표현한 지식 그래프를 활용하여, 사용자가 직관적으로 기계 학습 파이프라인을 구축할 수 있도록 돕는다.

Result: ExeKGLib를 통해 다양한 실제 사용 사례를 통해 그 유용성과 사용성을 입증하였다.

Conclusion: ExeKGLib는 기계 학습 파이프라인의 투명성 및 재사용성을 개선하고, 실행 가능성을 보장하는 효과적인 도구이다.

Abstract: Nowadays machine learning (ML) practitioners have access to numerous ML
libraries available online. Such libraries can be used to create ML pipelines
that consist of a series of steps where each step may invoke up to several ML
libraries that are used for various data-driven analytical tasks. Development
of high-quality ML pipelines is non-trivial; it requires training, ML
expertise, and careful development of each step. At the same time, domain
experts in science and engineering may not possess such ML expertise and
training while they are in pressing need of ML-based analytics. In this paper,
we present our ExeKGLib, a Python library enhanced with a graphical interface
layer that allows users with minimal ML knowledge to build ML pipelines. This
is achieved by relying on knowledge graphs that encode ML knowledge in simple
terms accessible to non-ML experts. ExeKGLib also allows improving the
transparency and reusability of the built ML workflows and ensures that they
are executable. We show the usability and usefulness of ExeKGLib by presenting
real use cases.

</details>


### [68] [Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement](https://arxiv.org/abs/2508.00410)
*Zizhuo Zhang,Jianing Zhu,Xinmu Ge,Zihua Zhao,Zhanke Zhou,Xuan Li,Xiao Feng,Jiangchao Yao,Bo Han*

Main category: cs.LG

TL;DR: 본 연구는 Co-Reward라는 새로운 강화학습 프레임워크를 제안하여 LLM의 추론 능력을 향상시키는 방법을 모색한다.


<details>
  <summary>Details</summary>
Motivation: RLVR이 LLM의 추론 능력을 개선하는 데 유망하지만, 복잡한 작업에 대한 인간 주석 라벨 의존성으로 인해 확장 문제에 직면해 있다.

Method: 비교 가능한 질문 간의 대조적 합의를 보상 기준으로 활용하는 Co-Reward 프레임워크를 제안하여, 레이블 없이 유사 질문을 생성하고 롤아웃 투표를 통해 대체 레이블을 합성한다.

Result: Co-Reward는 여러 추론 벤치마크에서 다른 자가 보상 기준보다 우수한 성능을 보여주며, Llama-3.2-3B-Instruct에서 GT 보상 대비 최대 6.8% 향상된 성과를 달성한다.

Conclusion: 이 연구는 Co-Reward의 자가 감독 보상 형태가 추론 일관성을 강화하며, 안정적인 추론 유도를 통해 LLM의 성능을 향상시킬 수 있음을 보여준다.

Abstract: Although reinforcement learning with verifiable rewards (RLVR) shows promise
in improving the reasoning ability of large language models (LLMs), the scaling
up dilemma remains due to the reliance on human annotated labels especially for
complex tasks. Recent alternatives that explore various self-reward signals
exhibit the eliciting potential of LLM reasoning, but suffer from the
non-negligible collapse issue. Inspired by the success of self-supervised
learning, we propose \textit{Co-Reward}, a novel RL framework that leverages
contrastive agreement across semantically analogical questions as a reward
basis. Specifically, we construct a similar question for each training sample
(without labels) and synthesize their individual surrogate labels through a
simple rollout voting, and then the reward is constructed by cross-referring
the labels of each question pair to enforce the internal reasoning consistency
across analogical inputs. Intuitively, such a self-supervised reward-shaping
mechanism increases the difficulty of learning collapse into a trivial
solution, and promotes stable reasoning elicitation and improvement through
expanding the input sample variants. Empirically, Co-Reward achieves superior
performance compared to other self-reward baselines on multiple reasoning
benchmarks and LLM series, and reaches or even surpasses ground-truth (GT)
labeled reward, with improvements of up to $+6.8\%$ on MATH500 over GT reward
on Llama-3.2-3B-Instruct. Our code is publicly available at
https://github.com/tmlr-group/Co-Reward.

</details>


### [69] [Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection](https://arxiv.org/abs/2508.00415)
*Yue Yang,Yuxiang Lin,Ying Zhang,Zihan Su,Chang Chuan Goh,Tangtangfang Fang,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: ResE-BiLSTM 모델을 통해 대출 후 디폴트 예측 정확도를 향상시킨 연구


<details>
  <summary>Details</summary>
Motivation: 대출 후 디폴트 예측은 신용 리스크 관리에서 중요한 과제이다.

Method: ResE-BiLSTM 모델을 슬라이딩 윈도우 기법을 사용하여 개발하고, 다양한 기준 모델과 비교하여 성능을 평가하였다.

Result: ResE-BiLSTM은 LSTM, BiLSTM, GRU, CNN, RNN 등 5개의 기준 모델에 비해 뛰어난 예측 성능을 보였다.

Conclusion: ResE-BiLSTM은 실제 실무에 적용 가능성과 가치가 높음을 입증하였다.

Abstract: Prediction of post-loan default is an important task in credit risk
management, and can be addressed by detection of financial anomalies using
machine learning. This study introduces a ResE-BiLSTM model, using a sliding
window technique, and is evaluated on 44 independent cohorts from the extensive
Freddie Mac US mortgage dataset, to improve prediction performance. The
ResE-BiLSTM is compared with five baseline models: Long Short-Term Memory
(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks
(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including
Accuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to
evaluate the contribution of individual components in the ResE-BiLSTM
architecture. Additionally, SHAP analysis was employed to interpret the
underlying features the model relied upon for its predictions. Experimental
results demonstrate that ResE-BiLSTM achieves superior predictive performance
compared to baseline models, underscoring its practical value and applicability
in real-world scenarios.

</details>


### [70] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: ctdGAN은 불균형한 표 형식 데이터의 문제를 해결하기 위해 개발된 조건부 GAN으로, 클러스터 레이블을 기반으로 샘플을 생성하여 데이터 왜곡을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습에서 클래스 불균형 문제로 인한 성능 저하를 해결하고자 함.

Method: ctdGAN은 공간 분할을 통해 입력 샘플에 클러스터 레이블을 부여한 후, 이를 통해 새로운 샘플을 생성하는 확률적 샘플링 전략을 사용한다.

Result: ctdGAN은 고충실도의 샘플을 생성하고 분류 정확성을 향상시키는 데 우수한 성능을 보였다.

Conclusion: ctdGAN은 14개의 불균형 데이터셋에 대해 평가되었으며, 데이터 생성에서의 우수성을 입증하였다.

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>


### [71] [Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection](https://arxiv.org/abs/2508.00507)
*Yiming Xu,Jiarun Chen,Zhen Peng,Zihan Chen,Qika Lin,Lan Ma,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: 이 논문은 대규모 언어 모델과 그래프 신경망을 결합하여 텍스트 속성 그래프에서 이상 탐지를 향상시키는 새로운 프레임워크인 CoLL을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 그래프 이상 탐지 방법들은 그래프 도메인 내에서 복잡한 최적화 목표에 중점을 두고 텍스트 모달리티의 보완적 가치를 간과하였다.

Method: CoLL은 다중 LLM 협업을 통해 증거를 강화하여 이상 관련 컨텍스트를 포착하고, 그래프 신경망을 통합하여 텍스트 특성과 증거를 동적으로 융합한다.

Result: CoLL은 평균 13.37%의 AP 개선을 보여주며, 기존 방법들에 비해 우수성을 입증하였다.

Conclusion: 이 연구는 그래프 이상 탐지 분야에서 LLM을 적용하는 새로운 가능성을 열어준다.

Abstract: The natural combination of intricate topological structures and rich textual
information in text-attributed graphs (TAGs) opens up a novel perspective for
graph anomaly detection (GAD). However, existing GAD methods primarily focus on
designing complex optimization objectives within the graph domain, overlooking
the complementary value of the textual modality, whose features are often
encoded by shallow embedding techniques, such as bag-of-words or skip-gram, so
that semantic context related to anomalies may be missed. To unleash the
enormous potential of textual modality, large language models (LLMs) have
emerged as promising alternatives due to their strong semantic understanding
and reasoning capabilities. Nevertheless, their application to TAG anomaly
detection remains nascent, and they struggle to encode high-order structural
information inherent in graphs due to input length constraints. For
high-quality anomaly detection in TAGs, we propose CoLL, a novel framework that
combines LLMs and graph neural networks (GNNs) to leverage their complementary
strengths. CoLL employs multi-LLM collaboration for evidence-augmented
generation to capture anomaly-relevant contexts while delivering human-readable
rationales for detected anomalies. Moreover, CoLL integrates a GNN equipped
with a gating mechanism to adaptively fuse textual features with evidence while
preserving high-order topological information. Extensive experiments
demonstrate the superiority of CoLL, achieving an average improvement of 13.37%
in AP. This study opens a new avenue for incorporating LLMs in advancing GAD.

</details>


### [72] [Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning](https://arxiv.org/abs/2508.00513)
*Yiming Xu,Xu Hua,Zhen Peng,Bin Shi,Jiarun Chen,Xingbo Fu,Song Wang,Bo Dong*

Main category: cs.LG

TL;DR: 이 논문은 텍스트 속성을 가진 그래프에서의 이상 탐지를 위한 새로운 접근법 CMUCL을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 텍스트 속성이 포함된 그래프에서의 이상 탐지는 기존의 얕은 임베딩 기술로 인해 제한된 탐지 능력으로 인해 어려움이 많다.

Method: 텍스트와 그래프 구조를 동시에 모델링하고, 크로스 모달 및 유니 모달 다중 스케일 일관성을 활용하여 텍스트와 그래프 인코더를 공동으로 훈련한다.

Result: 이 방법은 노드별 이상 점수를 도출하는 일관성 채굴 기반의 이상 점수 추정기를 설계하여 결과를 도출한다.

Conclusion: 시스템은 평균 정확도가 이전보다 11.13% 향상된 성과를 보이며, TAGs에 대한 연구를 위한 8개의 벤치마크 데이터 세트를 배포하였다.

Abstract: The widespread application of graph data in various high-risk scenarios has
increased attention to graph anomaly detection (GAD). Faced with real-world
graphs that often carry node descriptions in the form of raw text sequences,
termed text-attributed graphs (TAGs), existing graph anomaly detection
pipelines typically involve shallow embedding techniques to encode such textual
information into features, and then rely on complex self-supervised tasks
within the graph domain to detect anomalies. However, this text encoding
process is separated from the anomaly detection training objective in the graph
domain, making it difficult to ensure that the extracted textual features focus
on GAD-relevant information, seriously constraining the detection capability.
How to seamlessly integrate raw text and graph topology to unleash the vast
potential of cross-modal data in TAGs for anomaly detection poses a challenging
issue. This paper presents a novel end-to-end paradigm for text-attributed
graph anomaly detection, named CMUCL. We simultaneously model data from both
text and graph structures, and jointly train text and graph encoders by
leveraging cross-modal and uni-modal multi-scale consistency to uncover
potential anomaly-related information. Accordingly, we design an anomaly score
estimator based on inconsistency mining to derive node-specific anomaly scores.
Considering the lack of benchmark datasets tailored for anomaly detection on
TAGs, we release 8 datasets to facilitate future research. Extensive
evaluations show that CMUCL significantly advances in text-attributed graph
anomaly detection, delivering an 11.13% increase in average accuracy (AP) over
the suboptimal.

</details>


### [73] [Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting](https://arxiv.org/abs/2508.00523)
*Sifan Yang,Yuanyu Wan,Lijun Zhang*

Main category: cs.LG

TL;DR: 본 논문은 지연 피드백이 있는 온라인 비단조 최적화 문제를 다루며, 두 가지 알고리즘을 제안하여 기존의 한계를 극복한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 연구는 최대 지연에 의존하는 레그렛 경계가 불규칙한 지연에 민감하다는 점과 지연과 밴딧 피드백의 영향을 결합한다는 한계를 가지고 있다.

Method: DBGD-NF라는 새로운 방법론을 제안하고, 블로킹 업데이트 메커니즘을 사용하여 지연과 밴딧 피드백의 종합 효과를 분리하는 두 가지 알고리즘을 개발한다.

Result: 우리의 제안된 알고리즘은 각각 0(nar{d}^{1/3}T^{2/3}) 및 0(n(T^{2/3} + 	ext{sqrt}(dT)))의 레그렛 경계를 달성한다.

Conclusion: 우리의 방법이 구조적 희소 학습에서 우수성을 입증하는 실험 결과를 통해 기존 방법보다 더 유리함을 보여준다.

Abstract: We investigate the online nonsubmodular optimization with delayed feedback in
the bandit setting, where the loss function is $\alpha$-weakly DR-submodular
and $\beta$-weakly DR-supermodular. Previous work has established an
$(\alpha,\beta)$-regret bound of $\mathcal{O}(nd^{1/3}T^{2/3})$, where $n$ is
the dimensionality and $d$ is the maximum delay. However, its regret bound
relies on the maximum delay and is thus sensitive to irregular delays.
Additionally, it couples the effects of delays and bandit feedback as its bound
is the product of the delay term and the $\mathcal{O}(nT^{2/3})$ regret bound
in the bandit setting without delayed feedback. In this paper, we develop two
algorithms to address these limitations, respectively. Firstly, we propose a
novel method, namely DBGD-NF, which employs the one-point gradient estimator
and utilizes all the available estimated gradients in each round to update the
decision. It achieves a better $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ regret
bound, which is relevant to the average delay $\bar{d} =
\frac{1}{T}\sum_{t=1}^T d_t\leq d$. Secondly, we extend DBGD-NF by employing a
blocking update mechanism to decouple the joint effect of the delays and bandit
feedback, which enjoys an $\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$ regret bound.
When $d = \mathcal{O}(T^{1/3})$, our regret bound matches the
$\mathcal{O}(nT^{2/3})$ bound in the bandit setting without delayed feedback.
Compared to our first $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ bound, it is more
advantageous when the maximum delay $d = o(\bar{d}^{2/3}T^{1/3})$. Finally, we
conduct experiments on structured sparse learning to demonstrate the
superiority of our methods.

</details>


### [74] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
*Judy X Yang*

Main category: cs.LG

TL;DR: 이 논문은 구리광산 지역에서 고해상도 분광 이미징을 사용하여 미약한 광물 신호의 검출을 향상시키기 위한 두 단계 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 미약한 광물 신호가 노이즈 및 중복 대역에 의해 가려져, 검출 성능이 제한되는 문제를 해결하려고 한다.

Method: 첫 번째 단계에서 각 스펙트럼 대역의 신호 대 잡음비(SNR)를 계산하고 저SNR 대역을 버리는 임계값 기법을 적용한 후, Savitzky-Golay 필터링을 사용하여 스펙트럼을 부드럽게 한다. 두 번째 단계에서는 KMeans 클러스터링을 통해 12개의 엔드멤버 스펙트럼을 추출하고, 비음수 최소제곱(NNLS)을 통해 농도를 비혼합화 한다.

Result: 실험 결과, 제안한 파이프라인이 비혼합 정확도를 개선하고 미약한 광물 영역의 검출 능력을 향상시킴을 확인하였다.

Conclusion: 이 두 단계 전략은 지질학적 HSI 응용에서 스펙트럼 차원 축소 및 비혼합화를 위한 실용적이고 재현 가능한 솔루션을 제공한다.

Abstract: Hyperspectral imaging offers detailed spectral information for mineral
mapping; however, weak mineral signatures are often masked by noisy and
redundant bands, limiting detection performance. To address this, we propose a
two-stage integrated framework for enhanced mineral detection in the Cuprite
mining district. In the first stage, we compute the signal-to-noise ratio (SNR)
for each spectral band and apply a phase-locked thresholding technique to
discard low-SNR bands, effectively removing redundancy and suppressing
background noise. Savitzky-Golay filtering is then employed for spectral
smoothing, serving a dual role first to stabilize trends during band selection,
and second to preserve fine-grained spectral features during preprocessing. In
the second stage, the refined HSI data is reintroduced into the model, where
KMeans clustering is used to extract 12 endmember spectra (W1 custom), followed
by non negative least squares (NNLS) for abundance unmixing. The resulting
endmembers are quantitatively compared with laboratory spectra (W1 raw) using
cosine similarity and RMSE metrics. Experimental results confirm that our
proposed pipeline improves unmixing accuracy and enhances the detection of weak
mineral zones. This two-pass strategy demonstrates a practical and reproducible
solution for spectral dimensionality reduction and unmixing in geological HSI
applications.

</details>


### [75] [Foundations of Interpretable Models](https://arxiv.org/abs/2508.00545)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Alberto Termine,Mateja Jamnik,Giuseppe Marra*

Main category: cs.LG

TL;DR: 기존의 해석 가능성 정의는 적용 가능성이 없으며, 이 연구에서 새로운 정의와 설계 블루프린트를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존 해석 가능성 정의가 사용자에게 유용한 정보를 제공하지 못하는 문제를 해결하고자 한다.

Method: 기존의 비공식적인 개념을 포함하는 간단하고 일반적인 해석 가능성 정의를 제안하고, 그에 따른 모델 설계 블루프린트를 구축한다.

Result: 새롭게 제안한 정의는 해석 가능한 모델 설계에 필요한 기본 속성, 가정, 원칙, 데이터 구조 및 아키텍처적 특징을 드러낸다.

Conclusion: 첫 번째 오픈 소스 라이브러리를 소개하여 해석 가능한 데이터 구조와 프로세스를 지원한다.

Abstract: We argue that existing definitions of interpretability are not actionable in
that they fail to inform users about general, sound, and robust interpretable
model design. This makes current interpretability research fundamentally
ill-posed. To address this issue, we propose a definition of interpretability
that is general, simple, and subsumes existing informal notions within the
interpretable AI community. We show that our definition is actionable, as it
directly reveals the foundational properties, underlying assumptions,
principles, data structures, and architectural features necessary for designing
interpretable models. Building on this, we propose a general blueprint for
designing interpretable models and introduce the first open-sourced library
with native support for interpretable data structures and processes.

</details>


### [76] [Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides](https://arxiv.org/abs/2508.00578)
*Marlen Neubert,Patrick Reiser,Frauke Gräter,Pascal Friederich*

Main category: cs.LG

TL;DR: 수소 원자 전달 반응(HAT)의 메커니즘을 이해하기 위해, 기계 학습된 포텐셜을 통해 HAT 구성의 큰 데이터 세트를 생성하고, 세 가지 그래프 신경망 구조를 벤치마킹하여 MACE가 가장 높은 정확도를 나타냄을 보여준다.


<details>
  <summary>Details</summary>
Motivation: HAT 반응은 생물학적 과정에서 중요하지만 그 메커니즘이 충분히 이해되지 않아, 정확한 시뮬레이션을 위한 새로운 방법론이 필요하다.

Method: 펩타이드에서 HAT 구성을 체계적으로 생성하여 대규모 데이터 세트를 구축하고, 세 가지 그래프 신경망 아키텍처(SchNet, Allegro, MACE)의 HAT 포텐셜 에너지 표면을 학습하는 능력을 벤치마킹 했다.

Result: MACE가 에너지, 힘, 장벽 예측에서 일관되게 성능이 우수하며, 출처가 다른 DFT 장벽 예측에서 평균 절대 오차 1.13 kcal/mol을 달성하였다.

Conclusion: 이 정확도는 ML 포텐셜을 대규모 콜라겐 시뮬레이션에 통합할 수 있게 하여 HAT 및 라디칼 이동에 대한 기계적 이해를 발전시킨다.

Abstract: Hydrogen atom transfer (HAT) reactions are essential in many biological
processes, such as radical migration in damaged proteins, but their mechanistic
pathways remain incompletely understood. Simulating HAT is challenging due to
the need for quantum chemical accuracy at biologically relevant scales; thus,
neither classical force fields nor DFT-based molecular dynamics are applicable.
Machine-learned potentials offer an alternative, able to learn potential energy
surfaces (PESs) with near-quantum accuracy. However, training these models to
generalize across diverse HAT configurations, especially at radical positions
in proteins, requires tailored data generation and careful model selection.
Here, we systematically generate HAT configurations in peptides to build large
datasets using semiempirical methods and DFT. We benchmark three graph neural
network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT
PESs and indirectly predict reaction barriers from energy predictions. MACE
consistently outperforms the others in energy, force, and barrier prediction,
achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT
barrier predictions. This accuracy enables integration of ML potentials into
large-scale collagen simulations to compute reaction rates from predicted
barriers, advancing mechanistic understanding of HAT and radical migration in
peptides. We analyze scaling laws, model transferability, and cost-performance
trade-offs, and outline strategies for improvement by combining ML potentials
with transition state search algorithms and active learning. Our approach is
generalizable to other biomolecular systems, enabling quantum-accurate
simulations of chemical reactivity in complex environments.

</details>


### [77] [The Role of Active Learning in Modern Machine Learning](https://arxiv.org/abs/2508.00586)
*Thorben Werner,Lars Schmidt-Thieme,Vijaya Krishna Yalavarthi*

Main category: cs.LG

TL;DR: 능동 학습(AL)은 고비용의 컴퓨팅 자원에 비해 소량의 라벨 데이터로는 효율성이 낮고, 데이터 증대(DA)와 반지도 학습(SSL) 방법이 더 높은 성과를 보인다.


<details>
  <summary>Details</summary>
Motivation: AL이 과학 문헌 외의 분야에 거의 적용되지 않는 이유는 높은 계산 비용과 소량의 라벨 데이터로 인한 성과가 작기 때문이다.

Method: 데이터 증대(DA), 반지도 학습(SSL), 능동 학습(AL) 방법의 조합을 연구하였다.

Result: AL은 무작위 샘플링 대비 1-4%의 향상만 보였고, DA와 SSL 조합은 최대 60%의 향상을 달성하였다. 그러나 AL이 강력한 DA와 SSL과 결합하면 여전히 개선 효과를 가져올 수 있었다.

Conclusion: AL은 라벨 누락 문제의 해결법이 아니라, 적절한 DA와 SSL 적용 후 성능을 극대화하는 최종 구축 요소로 고려해야 한다.

Abstract: Even though Active Learning (AL) is widely studied, it is rarely applied in
contexts outside its own scientific literature. We posit that the reason for
this is AL's high computational cost coupled with the comparatively small lifts
it is typically able to generate in scenarios with few labeled points. In this
work we study the impact of different methods to combat this low data scenario,
namely data augmentation (DA), semi-supervised learning (SSL) and AL. We find
that AL is by far the least efficient method of solving the low data problem,
generating a lift of only 1-4\% over random sampling, while DA and SSL methods
can generate up to 60\% lift in combination with random sampling. However, when
AL is combined with strong DA and SSL techniques, it surprisingly is still able
to provide improvements. Based on these results, we frame AL not as a method to
combat missing labels, but as the final building block to squeeze the last bits
of performance out of data after appropriate DA and SSL methods as been
applied.

</details>


### [78] [Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data](https://arxiv.org/abs/2508.00615)
*Mukesh Kumar Sahu,Pinki Roy*

Main category: cs.LG

TL;DR: ICU 환자의 중증도를 예측하기 위한 새로운 모델인 SBSCGM을 제안하고, HybridGraphMedGNN 아키텍처를 통해 성능을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: ICU 환자의 위험도를 조기에 파악하여 신속한 개입을 위한 정확한 예측이 필요하다.

Method: SBSCGM은 다중 모달 EHR 데이터를 기반으로 환자 유사성 그래프를 동적으로 구축하고, HybridGraphMedGNN 아키텍처를 사용하여 환자의 사망 위험 및 지속적인 중증도 점수를 예측한다.

Result: 모델은 MIMIC-III 데이터셋의 6,000 ICU 환자 기록에서 AUC-ROC 0.94를 달성하였고, 기존 분류기 및 단일 유형 GNN 모델보다 성능이 우수하다.

Conclusion: 이 프레임워크는 중증도 예측을 위한 확장 가능하고 해석 가능한 솔루션을 제공하여 실제 ICU에서 임상의 지원 가능성을 제시한다.

Abstract: Accurately predicting the criticalness of ICU patients (such as in-ICU
mortality risk) is vital for early intervention in critical care. However,
conventional models often treat each patient in isolation and struggle to
exploit the relational structure in Electronic Health Records (EHR). We propose
a Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds
a patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN
architecture that operates on this graph to predict patient mortality and a
continuous criticalness score. SBSCGM uses a hybrid similarity measure
(combining feature-based and structural similarities) to connect patients with
analogous clinical profiles in real-time. The HybridGraphMedGNN integrates
Graph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)
layers to learn robust patient representations, leveraging both local and
global graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III
dataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)
outperforming baseline classifiers and single-type GNN models. We also
demonstrate improved precision/recall and show that the attention mechanism
provides interpretable insights into model predictions. Our framework offers a
scalable and interpretable solution for critical care risk prediction, with
potential to support clinicians in real-world ICU deployment.

</details>


### [79] [IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources](https://arxiv.org/abs/2508.00627)
*Paul Tresson,Pierre Le Coz,Hadrien Tulet,Anthony Malkassian,Maxime Réjou Méchain*

Main category: cs.LG

TL;DR: IAMAP은 사용자 친화적인 QGIS 플러그인으로, 원격 센서를 위한 딥러닝 접근 방식을 쉽게 활용할 수 있도록 돕는다.


<details>
  <summary>Details</summary>
Motivation: 인공지능의 발전에도 불구하고, 딥러닝의 구현은 전문 분야에 국한되어 있으며, 큰 데이터 세트, 풍부한 컴퓨팅 자원, 강력한 코딩 기술이 필요하다.

Method: IAMAP은 최근의 자기 지도 학습 전략에 기반하여 사용자 인터페이스를 통해 이미지 특징 추출, 차원 축소, 클러스터링 등 원격 센서 이미지 분석의 주요 단계를 간소화한다.

Result: IAMAP을 통해 비전문가도 GPU 용량이나 방대한 데이터 세트 없이 최근 딥러닝 접근법의 고품질 특징을 활용할 수 있다.

Conclusion: IAMAP은 계산적으로 효율적이고 에너지 절약형 딥러닝 기법의 민주화를 위한 기여를 한다.

Abstract: Remote sensing has entered a new era with the rapid development of artificial
intelligence approaches. However, the implementation of deep learning has
largely remained restricted to specialists and has been impractical because it
often requires (i) large reference datasets for model training and validation;
(ii) substantial computing resources; and (iii) strong coding skills. Here, we
introduce IAMAP, a user-friendly QGIS plugin that addresses these three
challenges in an easy yet flexible way. IAMAP builds on recent advancements in
self-supervised learning strategies, which now provide robust feature
extractors, often referred to as foundation models. These generalist models can
often be reliably used in few-shot or zero-shot scenarios (i.e., with little to
no fine-tuning). IAMAP's interface allows users to streamline several key steps
in remote sensing image analysis: (i) extracting image features using a wide
range of deep learning architectures; (ii) reducing dimensionality with
built-in algorithms; (iii) performing clustering on features or their reduced
representations; (iv) generating feature similarity maps; and (v) calibrating
and validating supervised machine learning models for prediction. By enabling
non-AI specialists to leverage the high-quality features provided by recent
deep learning approaches without requiring GPU capacity or extensive reference
datasets, IAMAP contributes to the democratization of computationally efficient
and energy-conscious deep learning methods.

</details>


### [80] [Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs](https://arxiv.org/abs/2508.00628)
*Xiong Xiong,Zhuo Zhang,Rongchun Hu,Chen Gao,Zichen Deng*

Main category: cs.LG

TL;DR: SV-SNN은 고주파 진동 편미분 방정식 문제를 해결하기 위한 새로운 프레임워크로, 전통적인 PINN의 한계를 극복하고 정확도를 1-3배 향상시키며 매개변수 수를 90% 이상 줄이고 훈련 시간을 60% 단축한다.


<details>
  <summary>Details</summary>
Motivation: 고주파 진동 편미분 방정식을 해결하는 것은 유체역학, 양자역학 및 전자기파 전파와 같은 여러 과학 분야에서 중요한 문제이다.

Method: SV-SNN은 변수 분리와 적응형 스펙트럴 방법을 통합하여 설계된 새로운 프레임워크로, 다변수 함수를 일변수 함수의 곱으로 분해하고 적응형 푸리에 스펙트럴 특성을 사용한다.

Result: SV-SNN은 열 방정식, 헬름홀츠 방정식, 포아송 방정식 및 나비어-스토크스 방정과 같은 벤치마크 문제에서 정확도를 1-3배 향상시켰고, 매개변수 수를 90% 이상 줄이며 훈련 시간을 60% 단축했다.

Conclusion: SV-SNN은 신경망을 통한 PDE 해결에서 스펙트럴 바이어스 문제에 대한 효과적인 해결책으로 자리 잡는다.

Abstract: Solving high-frequency oscillatory partial differential equations (PDEs) is a
critical challenge in scientific computing, with applications in fluid
mechanics, quantum mechanics, and electromagnetic wave propagation. Traditional
physics-informed neural networks (PINNs) suffer from spectral bias, limiting
their ability to capture high-frequency solution components. We introduce
Separated-Variable Spectral Neural Networks (SV-SNN), a novel framework that
addresses these limitations by integrating separation of variables with
adaptive spectral methods. Our approach features three key innovations: (1)
decomposition of multivariate functions into univariate function products,
enabling independent spatial and temporal networks; (2) adaptive Fourier
spectral features with learnable frequency parameters for high-frequency
capture; and (3) theoretical framework based on singular value decomposition to
quantify spectral bias. Comprehensive evaluation on benchmark problems
including Heat equation, Helmholtz equation, Poisson equations and
Navier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of
magnitude improvement in accuracy while reducing parameter count by over 90\%
and training time by 60\%. These results establish SV-SNN as an effective
solution to the spectral bias problem in neural PDE solving. The implementation
will be made publicly available upon acceptance at
https://github.com/xgxgnpu/SV-SNN.

</details>


### [81] [KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting](https://arxiv.org/abs/2508.00635)
*Changning Wu,Gao Wu,Rongyao Cai,Yong Liu,Kexin Zhang*

Main category: cs.LG

TL;DR: 다중 스케일 분해 아키텍처는 시계열 예측에서 중요하지만, 서로 다른 스케일 간의 노이즈 방해와 정보 분포의 이질성 문제를 해결하기 위해 KAN 기반의 적응형 주파수 선택 학습 아키텍처(KFS)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제 시계열 데이터는 서로 다른 스케일에서 노이즈의 간섭이 발생하며, 각기 다른 주파수 구성 요소 간의 정보 분포는 다중 스케일 표현을 최적화하는데 장애가 된다.

Method: KAN을 기반으로 한 KFS 아키텍처는 FreK 모듈을 통해 스펙트럼 영역에서 에너지 분포에 기반한 주요 주파수 선택을 수행한다.

Result: 다양한 실제 시계열 데이터셋에서 KT는 최첨단 성능을 달성하였다.

Conclusion: KT는 간단하면서도 효과적인 아키텍처로서 복잡한 패턴 모델링과 노이즈 간섭 문제를 해결한다.

Abstract: Multi-scale decomposition architectures have emerged as predominant
methodologies in time series forecasting. However, real-world time series
exhibit noise interference across different scales, while heterogeneous
information distribution among frequency components at varying scales leads to
suboptimal multi-scale representation. Inspired by Kolmogorov-Arnold Networks
(KAN) and Parseval's theorem, we propose a KAN based adaptive Frequency
Selection learning architecture (KFS) to address these challenges. This
framework tackles prediction challenges stemming from cross-scale noise
interference and complex pattern modeling through its FreK module, which
performs energy-distribution-based dominant frequency selection in the spectral
domain. Simultaneously, KAN enables sophisticated pattern representation while
timestamp embedding alignment synchronizes temporal representations across
scales. The feature mixing module then fuses scale-specific patterns with
aligned temporal features. Extensive experiments across multiple real-world
time series datasets demonstrate that KT achieves state-of-the-art performance
as a simple yet effective architecture.

</details>


### [82] [Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense](https://arxiv.org/abs/2508.00641)
*Alessandro Palmas*

Main category: cs.LG

TL;DR: 저비용 카미카제 드론 무리의 위협을 해결하기 위해 강화학습을 활용한 사례 연구를 통해 방어 시스템의 효율성을 향상시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 저비용 카미카제 드론 무리의 위협이 현대 방어 시스템에 중요한 도전 과제가 되고 있다.

Method: 상세한 시뮬레이션 환경에서 의사결정 수준의 강화학습 에이전트를 활용하여 최적의 요격 우선순위를 설정하는 방법을 제시한다.

Result: 강화학습 기반 정책은 수백 개의 공격 시나리오에서 수공예 규칙 기반 기준에 비해 평균 피해를 감소시키고 방어 효율성을 높였다.

Conclusion: 강화학습은 방어 아키텍처에서 전략적 층으로서 잠재력을 보여주며 기존 제어 시스템과의 이질성을 갖지 않으면서도 회복력을 향상시킬 수 있다.

Abstract: The growing threat of low-cost kamikaze drone swarms poses a critical
challenge to modern defense systems demanding rapid and strategic
decision-making to prioritize interceptions across multiple effectors and
high-value target zones. In this work, we present a case study demonstrating
the practical advantages of reinforcement learning in addressing this
challenge. We introduce a high-fidelity simulation environment that captures
realistic operational constraints, within which a decision-level reinforcement
learning agent learns to coordinate multiple effectors for optimal interception
prioritization. Operating in a discrete action space, the agent selects which
drone to engage per effector based on observed state features such as
positions, classes, and effector status. We evaluate the learned policy against
a handcrafted rule-based baseline across hundreds of simulated attack
scenarios. The reinforcement learning based policy consistently achieves lower
average damage and higher defensive efficiency in protecting critical zones.
This case study highlights the potential of reinforcement learning as a
strategic layer within defense architectures, enhancing resilience without
displacing existing control systems. All code and simulation assets are
publicly released for full reproducibility, and a video demonstration
illustrates the policy's qualitative behavior.

</details>


### [83] [Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators](https://arxiv.org/abs/2508.00643)
*Albert Matveev,Sanmitra Ghosh,Aamal Hussain,James-Michael Leahy,Michalis Michaelides*

Main category: cs.LG

TL;DR: DINOZAUR는 불확실성 정량화를 제공하는 차별화된 신경 연산자 구조로, FNO의 과도한 매개변수를 줄이고 예측 성능을 유지하며, 경쟁력 있는 성과를 보인다.


<details>
  <summary>Details</summary>
Motivation: FNO는 PDE를 해결하는 데 유용하지만, 과도한 매개변수와 불확실성 정량화 부족으로 인한 확장성 문제에 직면해 있다.

Method: DINOZAUR는 열 커널의 구조에서 영감을 받아, FNO의 밀집 텐서 곱셈기를 차원 독립적인 확산 곱셈기로 대체하고, 각 채널에 대해 학습 가능한 단일 시간 매개변수를 사용한다.

Result: DINOZAUR는 여러 PDE 벤치마크에서 경쟁력 있는 성능을 달성하며 효율적인 불확실성 정량화를 제공한다.

Conclusion: DINOZAUR는 예측 성능을 희생하지 않으면서 매개변수 수와 메모리 사용을 대폭 줄이고, 공간적으로 상관된 출력과 보정된 불확실성 추정을 제공한다.

Abstract: Operator learning is a powerful paradigm for solving partial differential
equations, with Fourier Neural Operators serving as a widely adopted
foundation. However, FNOs face significant scalability challenges due to
overparameterization and offer no native uncertainty quantification -- a key
requirement for reliable scientific and engineering applications. Instead,
neural operators rely on post hoc UQ methods that ignore geometric inductive
biases. In this work, we introduce DINOZAUR: a diffusion-based neural operator
parametrization with uncertainty quantification. Inspired by the structure of
the heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a
dimensionality-independent diffusion multiplier that has a single learnable
time parameter per channel, drastically reducing parameter count and memory
footprint without compromising predictive performance. By defining priors over
those time parameters, we cast DINOZAUR as a Bayesian neural operator to yield
spatially correlated outputs and calibrated uncertainty estimates. Our method
achieves competitive or superior performance across several PDE benchmarks
while providing efficient uncertainty quantification.

</details>


### [84] [Efficient Solution and Learning of Robust Factored MDPs](https://arxiv.org/abs/2508.00707)
*Yannik Schnitzer,Alessandro Abate,David Parker*

Main category: cs.LG

TL;DR: 이 논문은 불확실성을 모델링한 강화학습 문제인 r-MDP를 학습하고 해결하는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: MDP가 가진 전이 동역학에 대한 불확실성을 해결하기 위해 r-MDP를 제안하고, 이로 인해 보다 견고한 정책을 학습할 수 있는 방법을 모색한다.

Method: 상태 공간의 팩터화 표현을 기반으로 한 새롭고 효율적인 r-MDP 해결 및 학습 방법을 제안하고, 비선형 최적화 문제를 선형 프로그래밍으로 재구성한다.

Result: 팩터화 구조를 활용함으로써 샘플 효율성이 크게 향상되어, 기존 방법보다 더 효과적인 견고한 정책을 생성한다.

Conclusion: 제안된 방법은 기존의 최첨단 방법들보다 더 강력한 성능 보장을 제공하며, 모델의 불확실성을 효과적으로 처리할 수 있다.

Abstract: Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling
epistemic uncertainty about transition dynamics. Learning r-MDPs from
interactions with an unknown environment enables the synthesis of robust
policies with provable (PAC) guarantees on performance, but this can require a
large number of sample interactions. We propose novel methods for solving and
learning r-MDPs based on factored state-space representations that leverage the
independence between model uncertainty across system components. Although
policy synthesis for factored r-MDPs leads to hard, non-convex optimisation
problems, we show how to reformulate these into tractable linear programs.
Building on these, we also propose methods to learn factored model
representations directly. Our experimental results show that exploiting
factored structure can yield dimensional gains in sample efficiency, producing
more effective robust policies with tighter performance guarantees than
state-of-the-art methods.

</details>


### [85] [TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction](https://arxiv.org/abs/2508.00657)
*Sihang Zeng,Lucas Jing Liu,Jun Wen,Meliha Yetisgen,Ruth Etzioni,Gang Luo*

Main category: cs.LG

TL;DR: TrajSurv는 불규칙하게 샘플링된 전자 건강 기록(EHR) 데이터를 기반으로 신뢰할 수 있는 생존 예측을 위한 지속적인 잠재 경로를 학습하는 모델이다.


<details>
  <summary>Details</summary>
Motivation: 정확한 생존 예측은 임상 의사결정에 필수적이며, EHR 데이터를 활용하여 이를 개선하려는 필요가 있다.

Method: TrajSurv는 신경 제어 미분 방정식(NCDE)을 사용하여 불규칙하게 샘플링된 데이터에서 연속적인 잠재 상태를 추출하고, 시간 인식 대조 학습 접근 방식을 통해 임상 진행 상황과 일치하도록 잠재 상태 공간을 정렬한다.

Result: MIMIC-III 및 eICU 두 개의 실제 의료 데이터 세트에서 TrajSurv는 기존의 깊은 학습 방법들보다 경쟁력 있는 정확성과 우수한 투명성을 보였다.

Conclusion: TrajSurv는 임상 진행 상황과 생존 결과 간의 투명한 연결을 제공하며, 향후 임상 의사결정 지원의 가능성을 제시한다.

Abstract: Trustworthy survival prediction is essential for clinical decision making.
Longitudinal electronic health records (EHRs) provide a uniquely powerful
opportunity for the prediction. However, it is challenging to accurately model
the continuous clinical progression of patients underlying the irregularly
sampled clinical features and to transparently link the progression to survival
outcomes. To address these challenges, we develop TrajSurv, a model that learns
continuous latent trajectories from longitudinal EHR data for trustworthy
survival prediction. TrajSurv employs a neural controlled differential equation
(NCDE) to extract continuous-time latent states from the irregularly sampled
data, forming continuous latent trajectories. To ensure the latent trajectories
reflect the clinical progression, TrajSurv aligns the latent state space with
patient state space through a time-aware contrastive learning approach. To
transparently link clinical progression to the survival outcome, TrajSurv uses
latent trajectories in a two-step divide-and-conquer interpretation process.
First, it explains how the changes in clinical features translate into the
latent trajectory's evolution using a learned vector field. Second, it clusters
these latent trajectories to identify key clinical progression patterns
associated with different survival outcomes. Evaluations on two real-world
medical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and
superior transparency over existing deep learning methods.

</details>


### [86] [JSON-Bag: A generic game trajectory representation](https://arxiv.org/abs/2508.00712)
*Dien Nguyen,Diego Perez-Liebana,Simon Lucas*

Main category: cs.LG

TL;DR: JSON-Bag은 게임 궤적을 JSON 설명으로부터 토큰화하여 일반적으로 표현하는 방법으로, JSD를 거리 측정으로 사용한다. 이 방법은 6개의 게임에서 성능 평가를 통해 효율성과 정확성을 입증했다.


<details>
  <summary>Details</summary>
Motivation: 게임 궤적을 효과적으로 비교하고 분석하기 위한 새로운 방법론 제시.

Method: JSON-Bag 모델을 사용하여 게임 궤적을 토큰화하고, JSD를 거리 측정 지표로 활용하여 P-NNS를 통해 평가.

Result: 수작업으로 특징을 만든 기법을 넘어 대부분의 작업에서 우수한 성능을 보였으며, 자동 특징 추출 능력을 통해 정확성을 향상시켰다.

Conclusion: JSON-Bag 모델은 게임 궤적을 효과적으로 표현하고 비교할 수 있는 유용한 방법임을 입증하였다.

Abstract: We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically
represent game trajectories by tokenizing their JSON descriptions and apply
Jensen-Shannon distance (JSD) as distance metric for them. Using a
prototype-based nearest-neighbor search (P-NNS), we evaluate the validity of
JSON-Bag with JSD on six tabletop games -- \textit{7 Wonders},
\textit{Dominion}, \textit{Sea Salt and Paper}, \textit{Can't Stop},
\textit{Connect4}, \textit{Dots and boxes} -- each over three game trajectory
classification tasks: classifying the playing agents, game parameters, or game
seeds that were used to generate the trajectories.
  Our approach outperforms a baseline using hand-crafted features in the
majority of tasks. Evaluating on N-shot classification suggests using JSON-Bag
prototype to represent game trajectory classes is also sample efficient.
Additionally, we demonstrate JSON-Bag ability for automatic feature extraction
by treating tokens as individual features to be used in Random Forest to solve
the tasks above, which significantly improves accuracy on underperforming
tasks. Finally, we show that, across all six games, the JSD between JSON-Bag
prototypes of agent classes highly correlates with the distances between
agents' policies.

</details>


### [87] [DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes](https://arxiv.org/abs/2508.00664)
*Jialun Zheng,Jie Liu,Jiannong Cao,Xiao Wang,Hanchen Yang,Yankai Chen,Philip S. Yu*

Main category: cs.LG

TL;DR: 동적 그래프 이상 탐지(DGAD)는 변화하는 그래프에서의 이상 현상을 식별하는 데 중요한 역할을 하며, 본 연구에서는 동적 프로토타입(DP)을 사용한 DGAD 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 동적 그래프에서의 이상 탐지의 필요성과 기존의 일반적인 그래프 이상 탐지 모델이 변화하는 이상을 포착하는 데 어려움을 겪는 문제를 해결하고자 한다.

Method: DP-DGAD 모델은 동적 프로토타입을 추출하고 메모리 버퍼에 저장하며, 수신하는 데이터와 비교하여 이상 점수를 부여하고, 신뢰 기반의 의사 라벨링을 통해 자가 지도 학습을 수행한다.

Result: 최신 기술 수준의 성능을 보여주며, 10종의 다양한 도메인에서의 실제 데이터셋에 대해 성능이 입증되었다.

Conclusion: 제안하는 DP-DGAD 모델은 변화하는 도메인 특화 및 비특화 패턴을 성공적으로 포착함으로써 동적 그래프 이상 탐지 분야에서 중요한 진전을 이루었다.

Abstract: Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies
in evolving graphs across domains such as finance, traffic, and social
networks. Recently, generalist graph anomaly detection (GAD) models have shown
promising results. They are pretrained on multiple source datasets and
generalize across domains. While effective on static graphs, they struggle to
capture evolving anomalies in dynamic graphs. Moreover, the continuous
emergence of new domains and the lack of labeled data further challenge
generalist DGAD. Effective cross-domain DGAD requires both domain-specific and
domain-agnostic anomalous patterns. Importantly, these patterns evolve
temporally within and across domains. Building on these insights, we propose a
DGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and
domain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,
evolving representations of normal and anomalous patterns, from temporal
ego-graphs and stores them in a memory buffer. The buffer is selectively
updated to retain general, domain-agnostic patterns while incorporating new
domain-specific ones. Then, an anomaly scorer compares incoming data with
dynamic prototypes to flag both general and domain-specific anomalies. Finally,
DP-DGAD employs confidence-based pseudo-labeling for effective self-supervised
adaptation in target domains. Extensive experiments demonstrate
state-of-the-art performance across ten real-world datasets from different
domains.

</details>


### [88] [Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning](https://arxiv.org/abs/2508.00716)
*Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu*

Main category: cs.LG

TL;DR: NeGPR은 노이즈가 있는 레이블을 가진 그래프 데이터의 도메인 적응을 향상시키기 위한 새로운 프레임워크로, 이중 가지의 특징을 학습하고, 고신뢰 샘플을 선택하여 적응 과정을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 실제 세계에서는 주석 노이즈가 흔하여 기존 GDA 방법이 종종 실패하므로, 노이즈가 있는 레이블을 처리할 수 있는 새로운 방법이 필요하다.

Method: NeGPR은 이중 가지의 사전 훈련을 통해 이웃 일관성을 유지하고, nested refinement 기법을 사용하여 고신뢰 사례를 선택하여 적응을 유도한다. 또한, 노이즈 인식을 고려한 정규화 전략을 포함하여 과적합의 부정적인 영향을 줄인다.

Result: NeGPR은 심각한 레이블 노이즈가 있는 상황에서도 기존 최첨단 방법보다 최대 12.7% 더 높은 정확도를 기록하며 일관되게 성능을 향상시킨다.

Conclusion: NeGPR은 실제 상황에서 유용하게 사용할 수 있는 강력한 그래프 도메인 적응 방법으로, 노이즈 레이블의 영향을 효과적으로 줄인다.

Abstract: Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled
source graphs to unlabeled target graphs by learning domain-invariant
representations, which is essential in applications such as molecular property
prediction and social network analysis. However, most existing GDA methods rely
on the assumption of clean source labels, which rarely holds in real-world
scenarios where annotation noise is pervasive. This label noise severely
impairs feature alignment and degrades adaptation performance under domain
shifts. To address this challenge, we propose Nested Graph Pseudo-Label
Refinement (NeGPR), a novel framework tailored for graph-level domain
adaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,
semantic and topology branches, by enforcing neighborhood consistency in the
feature space, thereby reducing the influence of noisy supervision. To bridge
domain gaps, NeGPR employs a nested refinement mechanism in which one branch
selects high-confidence target samples to guide the adaptation of the other,
enabling progressive cross-domain learning. Furthermore, since pseudo-labels
may still contain noise and the pre-trained branches are already overfitted to
the noisy labels in the source domain, NeGPR incorporates a noise-aware
regularization strategy. This regularization is theoretically proven to
mitigate the adverse effects of pseudo-label noise, even under the presence of
source overfitting, thus enhancing the robustness of the adaptation process.
Extensive experiments on benchmark datasets demonstrate that NeGPR consistently
outperforms state-of-the-art methods under severe label noise, achieving gains
of up to 12.7% in accuracy.

</details>


### [89] [Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network](https://arxiv.org/abs/2508.00692)
*Young-ho Cho,Hao Zhu,Duehee Lee,Ross Baldick*

Main category: cs.LG

TL;DR: 이 논문은 풍력 발전 시나리오 생성을 위한 GDFM과 GAN의 결합 방법을 제시하며, 호주 풍력 발전의 통계적 특성을 개선함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 자원 적합성 연구를 위한 다수의 장기 풍력 발전 시나리오를 동시 생성하기 위해, 방법론의 통계적 특징을 활용하고자 한다.

Method: GDFM을 통해 공간 상관관계를 추출하고, GAN을 통해 동적 요인을 필터링하여 GDFM에 적용함으로써 시나리오를 생성한다.

Result: GDFM과 GAN의 조합이 경쟁 대안보다 성능 개선을 보여주며, 실제 풍력 발전의 통계적 특성을 더 잘 구현함을 입증하였다.

Conclusion: GDFM와 GAN의 결합 방식이 풍력 발전 시나리오 생성에 효과적이며, 더 사실적인 결과를 제공한다.

Abstract: For conducting resource adequacy studies, we synthesize multiple long-term
wind power scenarios of distributed wind farms simultaneously by using the
spatio-temporal features: spatial and temporal correlation, waveforms, marginal
and ramp rates distributions of waveform, power spectral densities, and
statistical characteristics. Generating the spatial correlation in scenarios
requires the design of common factors for neighboring wind farms and
antithetical factors for distant wind farms. The generalized dynamic factor
model (GDFM) can extract the common factors through cross spectral density
analysis, but it cannot closely imitate waveforms. The GAN can synthesize
plausible samples representing the temporal correlation by verifying samples
through a fake sample discriminator. To combine the advantages of GDFM and GAN,
we use the GAN to provide a filter that extracts dynamic factors with temporal
information from the observation data, and we then apply this filter in the
GDFM to represent both spatial and frequency correlations of plausible
waveforms. Numerical tests on the combination of GDFM and GAN have demonstrated
performance improvements over competing alternatives in synthesizing wind power
scenarios from Australia, better realizing plausible statistical
characteristics of actual wind power compared to alternatives such as the GDFM
with a filter synthesized from distributions of actual dynamic filters and the
GAN with direct synthesis without dynamic factors.

</details>


### [90] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
*Liuyun Xu,Seymour M. J. Spence*

Main category: cs.LG

TL;DR: 본 논문은 다중 충실도 샘플링 기법과 적응형 머신러닝 메타모델을 활용하여 희귀 사건 분석의 실패 확률 추정을 효율化하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 희귀 사건 분석에서 기존의 분산 감소 기법이 여전히 많은 모델 평가를 요구함에 따라, 복잡하고 비선형적인 유한 요소 모델링에서의 계산 부담을 경감할 필요가 있다.

Method: 다중 충실도 층화 샘플링 기법과 적응형 머신러닝 메타모델을 도입하여 불확실성을 전파하고 작은 실패 확률을 추정한다.

Result: 제안된 기법을 통해 비선형 반응에 대한 초과 확률 곡선을 정확하게 추정하면서, 단일 충실도 분산 감소 접근법에 비해 상당한 계산 비용 절감 효과를 보였다.

Conclusion: 희귀 사건 분석에 있어 다중 충실도 접근 방식이 계산 효율성과 정확성을 동시에 확보하는 데 기여할 수 있음을 입증하였다.

Abstract: Existing variance reduction techniques used in stochastic simulations for
rare event analysis still require a substantial number of model evaluations to
estimate small failure probabilities. In the context of complex, nonlinear
finite element modeling environments, this can become computationally
challenging-particularly for systems subjected to stochastic excitation. To
address this challenge, a multi-fidelity stratified sampling scheme with
adaptive machine learning metamodels is introduced for efficiently propagating
uncertainties and estimating small failure probabilities. In this approach, a
high-fidelity dataset generated through stratified sampling is used to train a
deep learning-based metamodel, which then serves as a cost-effective and highly
correlated low-fidelity model. An adaptive training scheme is proposed to
balance the trade-off between approximation quality and computational demand
associated with the development of the low-fidelity model. By integrating the
low-fidelity outputs with additional high-fidelity results, an unbiased
estimate of the strata-wise failure probabilities is obtained using a
multi-fidelity Monte Carlo framework. The overall probability of failure is
then computed using the total probability theorem. Application to a full-scale
high-rise steel building subjected to stochastic wind excitation demonstrates
that the proposed scheme can accurately estimate exceedance probability curves
for nonlinear responses of interest, while achieving significant computational
savings compared to single-fidelity variance reduction approaches.

</details>


### [91] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
*Sergio Rubio-Martín,María Teresa García-Ordás,Antonio Serrano-García,Clara Margarita Franch-Pato,Arturo Crespo-Álvaro,José Alberto Benítez-Andrades*

Main category: cs.LG

TL;DR: 정신 건강 진단을 위한 인공지능 모델 성능 비교 연구.


<details>
  <summary>Details</summary>
Motivation: 정신 건강 상태의 진단에 있어 임상 노트의 분류는 중요하다.

Method: 전통적인 머신러닝 모델과 딥러닝 모델을 비교하고, 세가지 오버샘플링 전략을 적용하여 모델 성능에 미치는 영향을 평가했다.

Result: SMOTE가 BERT 기반 모델에 긍정적인 효과를 보였으며, 하이퍼파라미터 최적화가 모델 정확성을 크게 향상시켰다.

Conclusion: 하이퍼파라미터 튜닝의 중요성을 강조하며, 다양한 모델 아키텍처와 데이터 균형 방법의 효과에 대한 통찰을 제공했다.

Abstract: The classification of clinical notes into specific diagnostic categories is
critical in healthcare, especially for mental health conditions like Anxiety
and Adjustment Disorder. In this study, we compare the performance of various
Artificial Intelligence models, including both traditional Machine Learning
approaches (Random Forest, Support Vector Machine, K-nearest neighbors,
Decision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT
and SciBERT), to classify clinical notes into these two diagnoses.
Additionally, we implemented three oversampling strategies: No Oversampling,
Random Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to
assess their impact on model performance. Hyperparameter tuning was also
applied to optimize model accuracy. Our results indicate that oversampling
techniques had minimal impact on model performance overall. The only exception
was SMOTE, which showed a positive effect specifically with BERT-based models.
However, hyperparameter optimization significantly improved accuracy across the
models, enhancing their ability to generalize and perform on the dataset. The
Decision Tree and eXtreme Gradient Boost models achieved the highest accuracy
among machine learning approaches, both reaching 96%, while the DistilBERT and
SciBERT models also attained 96% accuracy in the deep learning category. These
findings underscore the importance of hyperparameter tuning in maximizing model
performance. This study contributes to the ongoing research on AI-assisted
diagnostic tools in mental health by providing insights into the efficacy of
different model architectures and data balancing methods.

</details>


### [92] [A Simple and Effective Method for Uncertainty Quantification and OOD Detection](https://arxiv.org/abs/2508.00754)
*Yaxin Ma,Benjamin Colburn,Jose C. Principe*

Main category: cs.LG

TL;DR: 본 논문에서는 단일 결정론적 모델을 활용하여 불확실성을 정량화하는 효과적인 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 베이지안 신경망과 심층 앙상블 방법은 불확실성 정량화를 위해 제안되었지만, 계산 집약적이고 대규모 저장이 필요하다.

Method: 커널 밀도 추정으로부터 유도된 정보 잠재 필드를 활용하여 훈련 세트의 특징 공간 밀도를 근사하고, 이를 테스트 샘플의 특징 공간 표현과 비교한다.

Result: 2D 합성 데이터셋 (Two Moons 및 Three Spirals) 및 OOD 감지 작업 (CIFAR-10 vs. SVHN)에서 실험을 수행하여, 제안한 방법이 기준 모델을 초월한 성과를 보였다.

Conclusion: 제안된 방법은 불확실성 정량화에서 효과적이며, 계산 비용을 줄일 수 있다.

Abstract: Bayesian neural networks and deep ensemble methods have been proposed for
uncertainty quantification; however, they are computationally intensive and
require large storage. By utilizing a single deterministic model, we can solve
the above issue. We propose an effective method based on feature space density
to quantify uncertainty for distributional shifts and out-of-distribution (OOD)
detection. Specifically, we leverage the information potential field derived
from kernel density estimation to approximate the feature space density of the
training set. By comparing this density with the feature space representation
of test samples, we can effectively determine whether a distributional shift
has occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons
and Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The
results demonstrate that our method outperforms baseline models.

</details>


### [93] [Learning Network Dismantling without Handcrafted Inputs](https://arxiv.org/abs/2508.00706)
*Haozhe Tian,Pietro Ferraro,Robert Shorten,Mahdi Jalili,Homayoun Hamedmoghadam*

Main category: cs.LG

TL;DR: 메시지 전파 그래프 신경망(Mind)을 통해 수작업 구조적 특징 없이 네트워크 해체 문제를 해결하는 논문.


<details>
  <summary>Details</summary>
Motivation: 기존 성능이 수작업 구조 특징에 의존하는 문제점을 해결하고자 함.

Method: 주의 메커니즘과 메시지 반복 프로파일을 활용하여 구조적으로 다양한 훈련 세트를 생성하는 알고리즘을 적용.

Result: MIND 모델은 수작업 없이 훈련된 후, 대규모 실제 네트워크에서 최첨단 방법들을 초월하는 성능을 발휘함.

Conclusion: 제안된 모델은 다양한 복잡한 네트워크 문제에서도 효율성과 일반화 가능성을 높일 수 있음.

Abstract: The application of message-passing Graph Neural Networks has been a
breakthrough for important network science problems. However, the competitive
performance often relies on using handcrafted structural features as inputs,
which increases computational cost and introduces bias into the otherwise
purely data-driven network representations. Here, we eliminate the need for
handcrafted features by introducing an attention mechanism and utilizing
message-iteration profiles, in addition to an effective algorithmic approach to
generate a structurally diverse training set of small synthetic networks.
Thereby, we build an expressive message-passing framework and use it to
efficiently solve the NP-hard problem of Network Dismantling, virtually
equivalent to vital node identification, with significant real-world
applications. Trained solely on diversified synthetic networks, our proposed
model -- MIND: Message Iteration Network Dismantler -- generalizes to large,
unseen real networks with millions of nodes, outperforming state-of-the-art
network dismantling methods. Increased efficiency and generalizability of the
proposed model can be leveraged beyond dismantling in a range of complex
network problems.

</details>


### [94] [Democratizing Tabular Data Access with an Open$\unicode{x2013}$Source Synthetic$\unicode{x2013}$Data SDK](https://arxiv.org/abs/2508.00718)
*Ivona Krchova,Mariana Vargas Vieyra,Mario Scriminaci,Andrey Sidorenko*

Main category: cs.LG

TL;DR: 이 논문은 개인 정보 보호 및 윤리적 우려로 인해 데이터 접근성이 제한된 환경에서 고품질 표 형식 데이터를 합성하는 MOSTLY AI 합성 데이터 SDK를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 개발에는 고품질 데이터 접근이 필수적이나, 개인 정보 보호 및 윤리적 문제로 인해 데이터 접근성이 제한되고 있다.

Method: MOSTLY AI 합성 데이터 소프트웨어 개발 키트(SDK)를 사용하여 차별적 개인 정보 보호 보장, 공정성 인식 데이터 생성, 자동 품질 보증 기능을 갖춘 파이썬 인터페이스에서 고품질 표 형식 데이터를 합성한다.

Result: 이 SDK는 다양한 데이터 유형과 복잡한 다중 테이블 및 시퀀스 데이터 집합을 지원하고, 성능이 뛰어나며 속도와 사용성에서 개선을 보여준다.

Conclusion: SDK는 클라우드 서비스와 로컬 소프트웨어로 제공되며, 실제 데이터의 병목 현상을 해결하고 데이터 민주화를 촉진하는 데 실질적인 기여를 하고 있다.

Abstract: Machine learning development critically depends on access to high-quality
data. However, increasing restrictions due to privacy, proprietary interests,
and ethical concerns have created significant barriers to data accessibility.
Synthetic data offers a viable solution by enabling safe, broad data usage
without compromising sensitive information. This paper presents the MOSTLY AI
Synthetic Data Software Development Kit (SDK), an open-source toolkit designed
specifically for synthesizing high-quality tabular data. The SDK integrates
robust features such as differential privacy guarantees, fairness-aware data
generation, and automated quality assurance into a flexible and accessible
Python interface. Leveraging the TabularARGN autoregressive framework, the SDK
supports diverse data types and complex multi-table and sequential datasets,
delivering competitive performance with notable improvements in speed and
usability. Currently deployed both as a cloud service and locally installable
software, the SDK has seen rapid adoption, highlighting its practicality in
addressing real-world data bottlenecks and promoting widespread data
democratization.

</details>


### [95] [Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data](https://arxiv.org/abs/2508.00758)
*Timur Sattarov,Marco Schreyer,Damian Borth*

Main category: cs.LG

TL;DR: DDAE는 확산 기반 노이즈 스케줄링과 대조 학습을 결합하여 표 형식의 이상 탐지 성능을 개선한 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 표 형식 데이터에서의 이상 탐지는 복잡한 특성 상호작용과 이상 사례의 부족으로 인해 여전히 도전적이다.

Method: DDAE는 확산 모델을 활용하여 계획된 노이즈와 반복적인 디노이징을 통합한 프레임워크이다.

Result: 57개의 데이터세트에서 DDAE는 비교 우위를 보였으며, PR-AUC와 ROC-AUC에서 기존 최첨단 모델을 능가했다.

Conclusion: 원칙적인 노이즈 전략이 표 형식의 이상 탐지에서 중요하다는 점을 강조한다.

Abstract: Anomaly detection in tabular data remains challenging due to complex feature
interactions and the scarcity of anomalous examples. Denoising autoencoders
rely on fixed-magnitude noise, limiting adaptability to diverse data
distributions. Diffusion models introduce scheduled noise and iterative
denoising, but lack explicit reconstruction mappings. We propose the
Diffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates
diffusion-based noise scheduling and contrastive learning into the encoding
process to improve anomaly detection. We evaluated DDAE on 57 datasets from
ADBench. Our method outperforms in semi-supervised settings and achieves
competitive results in unsupervised settings, improving PR-AUC by up to 65%
(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)
model baselines. We observed that higher noise levels benefit unsupervised
training, while lower noise with linear scheduling is optimal in
semi-supervised settings. These findings underscore the importance of
principled noise strategies in tabular anomaly detection.

</details>


### [96] [Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy](https://arxiv.org/abs/2508.00768)
*Antonio Tudisco,Andrea Marchesin,Maurizio Zamboni,Mariagrazia Graziano,Giovanna Turvani*

Main category: cs.LG

TL;DR: 양자 기계 학습(QML)에서 변분 양자 회로(VQC)의 성능을 분석하고, 회전 게이트의 종류가 분류 정확도에 미치는 영향을 평가한 연구.


<details>
  <summary>Details</summary>
Motivation: 양자 컴퓨팅과 기계 학습의 발전으로 양자 기계 학습에 대한 관심이 증가하고 있다.

Method: Amplitude- 및 Angle-encoding 모델을 고려하여 회전 게이트의 종류가 모델 성능에 미치는 영향을 분석하고, Wine과 Diabetes 데이터셋에서 모델을 훈련시킨다.

Result: 최고 및 최악 모델 간의 정확도 차이는 10%에서 30%까지이며, 최대 41%의 차이를 보인다.

Conclusion: 회전 게이트의 선택이 VQC 모델의 분류 성능에 중요한 영향을 미치며, 임베딩이 VQC 모델의 하이퍼파라미터로 작용한다.

Abstract: Recent advancements in Quantum Computing and Machine Learning have increased
attention to Quantum Machine Learning (QML), which aims to develop machine
learning models by exploiting the quantum computing paradigm. One of the widely
used models in this area is the Variational Quantum Circuit (VQC), a hybrid
model where the quantum circuit handles data inference while classical
optimization adjusts the parameters of the circuit. The quantum circuit
consists of an encoding layer, which loads data into the circuit, and a
template circuit, known as the ansatz, responsible for processing the data.
This work involves performing an analysis by considering both Amplitude- and
Angle-encoding models, and examining how the type of rotational gate applied
affects the classification performance of the model. This comparison is carried
out by training the different models on two datasets, Wine and Diabetes, and
evaluating their performance. The study demonstrates that, under identical
model topologies, the difference in accuracy between the best and worst models
ranges from 10% to 30%, with differences reaching up to 41%. Moreover, the
results highlight how the choice of rotational gates used in encoding can
significantly impact the model's classification performance. The findings
confirm that the embedding represents a hyperparameter for VQC models.

</details>


### [97] [Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors](https://arxiv.org/abs/2508.00785)
*Bushra Akter,Md Biplob Hosen,Sabbir Ahmed,Mehrin Anannya,Md. Farhad Hossain*

Main category: cs.LG

TL;DR: 이 연구는 학생의 CGPA에 영향을 미치는 사회적, 학업적, 재정적 요인을 분석하고, 예측 모델과 설명 가능한 AI 기술을 활용한 웹 기반 애플리케이션을 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 학생의 학업 성과는 다양한 요인에 의해 영향을 받으므로, CGPA 최적화를 위한 효과적인 전략을 개발하기 위함이다.

Method: 문헌 검토, 온라인 설문조사(1,050명 참여), 데이터 전처리, 인과 분석, 회귀 및 분류 모델 구현, 설명 가능한 AI 기법 활용.

Result: Ridge 회귀는 MAE 0.12 및 MSE 0.023을 기록하였고, 랜덤 포레스트는 F1-score가 거의 완벽하며 정확도 98.68%를 달성하였다.

Conclusion: 개발된 웹 애플리케이션은 학생들에게 개인 맞춤형 통찰력을 제공하여 학업 성과를 예측하고 개선할 수 있는 기회를 제공한다.

Abstract: Academic performance depends on a multivariable nexus of socio-academic and
financial factors. This study investigates these influences to develop
effective strategies for optimizing students' CGPA. To achieve this, we
reviewed various literature to identify key influencing factors and constructed
an initial hypothetical causal graph based on the findings. Additionally, an
online survey was conducted, where 1,050 students participated, providing
comprehensive data for analysis. Rigorous data preprocessing techniques,
including cleaning and visualization, ensured data quality before analysis.
Causal analysis validated the relationships among variables, offering deeper
insights into their direct and indirect effects on CGPA. Regression models were
implemented for CGPA prediction, while classification models categorized
students based on performance levels. Ridge Regression demonstrated strong
predictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared
Error of 0.023. Random Forest outperformed in classification, attaining an
F1-score near perfection and an accuracy of 98.68%. Explainable AI techniques
such as SHAP, LIME, and Interpret enhanced model interpretability, highlighting
critical factors such as study hours, scholarships, parental education, and
prior academic performance. The study culminated in the development of a
web-based application that provides students with personalized insights,
allowing them to predict academic performance, identify areas for improvement,
and make informed decisions to enhance their outcomes.

</details>


### [98] [Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management](https://arxiv.org/abs/2508.00806)
*Ping Chen,Zhuohong Deng,Ping Li,Shuibing He,Hongzi Zhu,Yi Zheng,Zhefeng Wang,Baoxing Huai,Minyi Guo*

Main category: cs.LG

TL;DR: Adacc는 GPU 메모리 사용량을 줄이고 LLM 훈련을 가속화하는 혁신적인 메모리 관리 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 훈련 시 메모리 압박을 완화하기 위해 재계산을 사용하는 과정에서 최대 30%의 오버헤드가 발생한다.

Method: Adacc는 계층별 압축 알고리즘, 최적의 스케줄링 정책, 적응형 정책 진화 메커니즘의 세 가지 모듈로 구성된다.

Result: Adacc는 최신 프레임워크와 비교하여 LLM 훈련 속도를 1.01배에서 1.37배까지 가속화하며, Baseline과 유사한 모델 정확도를 유지한다.

Conclusion: Adacc는 메모리 최적화를 통해 LLM 훈련의 효율성을 significantly 향상시킨다.

Abstract: Training large language models often employs recomputation to alleviate
memory pressure, which can introduce up to 30% overhead in real-world
scenarios. In this paper, we propose Adacc, a novel memory management framework
that combines adaptive compression and activation checkpointing to reduce the
GPU memory footprint. It comprises three modules: (1) We design layer-specific
compression algorithms that account for outliers in LLM tensors, instead of
directly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We
propose an optimal scheduling policy that employs MILP to determine the best
memory optimization for each tensor. (3) To accommodate changes in training
tensors, we introduce an adaptive policy evolution mechanism that adjusts the
policy during training to enhance throughput. Experimental results show that
Adacc can accelerate the LLM training by 1.01x to 1.37x compared to
state-of-the-art frameworks, while maintaining comparable model accuracy to the
Baseline.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [99] [Strategic Communication and Language Bias in Multi-Agent LLM Coordination](https://arxiv.org/abs/2508.00032)
*Alessio Buscemi,Daniele Proverbio,Alessandro Di Stefano,The Anh Han,German Castignani,Pietro Liò*

Main category: cs.MA

TL;DR: 언어 모델 기반 에이전트의 커뮤니케이션이 협력 행동에 미치는 영향을 연구한 논문.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시나리오에서 협력이 중요한데, 언어 표현이 협력 행동에 미치는 영향을 탐구하고자 함.

Method: FAIRGAME 프레임워크를 사용해 커뮤니케이션 유무와 다양한 언어 및 모델에서의 게임 시뮬레이션을 수행.

Result: 커뮤니케이션이 에이전트 행동에 중대한 영향을 미치지만, 그 효과는 언어, 성격, 게임 구조에 따라 달라짐.

Conclusion: 커뮤니케이션의 이중 역할, 즉 협력을 촉진하는 동시에 편견을 강화하는 점을 강조함.

Abstract: Large Language Model (LLM)-based agents are increasingly deployed in
multi-agent scenarios where coordination is crucial but not always assured.
Previous studies indicate that the language used to frame strategic scenarios
can influence cooperative behavior. This paper explores whether allowing agents
to communicate amplifies these language-driven effects. Leveraging the FAIRGAME
framework, we simulate one-shot and repeated games across different languages
and models, both with and without communication. Our experiments, conducted
with two advanced LLMs, GPT-4o and Llama 4 Maverick, reveal that communication
significantly influences agent behavior, though its impact varies by language,
personality, and game structure. These findings underscore the dual role of
communication in fostering coordination and reinforcing biases.

</details>


### [100] [WMAS: A Multi-Agent System Towards Intelligent and Customized Wireless Networks](https://arxiv.org/abs/2508.00280)
*Jingchen Peng,Dingli Yuan,Boxiang Ren,Jie Fan,Hao Wu,Lu Yang*

Main category: cs.MA

TL;DR: 인공지능(주로 다중 에이전트 시스템)을 활용한 고급 무선 네트워크 설계.


<details>
  <summary>Details</summary>
Motivation: 인공지능 에이전트의 발전은 맞춤형 무선 네트워크 구현을 가능하게 한다.

Method: 다중 에이전트 대화 토폴로지를 방향성 비순환 그래프로 모델링하고 강화 학습 기반 알고리즘으로 최적화.

Result: WMAS는 다양한 작업 요청을 효과적으로 처리하면서 높은 성능과 낮은 대화 오버헤드를 달성.

Conclusion: WMAS는 미래 무선 네트워크의 지능을 향상시킬 수 있는 잠재력을 지닌다.

Abstract: The fast development of Artificial Intelligence (AI) agents provides a
promising way for the realization of intelligent and customized wireless
networks. In this paper, we propose a Wireless Multi-Agent System (WMAS), which
can provide intelligent and customized services for different user equipment
(UEs). Note that orchestrating multiple agents carries the risk of malfunction,
and multi-agent conversations may fall into infinite loops. It is thus crucial
to design a conversation topology for WMAS that enables agents to complete UE
task requests with high accuracy and low conversation overhead. To address this
issue, we model the multi-agent conversation topology as a directed acyclic
graph and propose a reinforcement learning-based algorithm to optimize the
adjacency matrix of this graph. As such, WMAS is capable of generating and
self-optimizing multi-agent conversation topologies, enabling agents to
effectively and collaboratively handle a variety of task requests from UEs.
Simulation results across various task types demonstrate that WMAS can achieve
higher task performance and lower conversation overhead compared to existing
multi-agent systems. These results validate the potential of WMAS to enhance
the intelligence of future wireless networks.

</details>
