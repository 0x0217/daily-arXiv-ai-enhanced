<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 2]
- [cs.LG](#cs.LG) [Total: 62]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.CR](#cs.CR) [Total: 11]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Strategic Communication and Language Bias in Multi-Agent LLM Coordination](https://arxiv.org/abs/2508.00032)
*Alessio Buscemi,Daniele Proverbio,Alessandro Di Stefano,The Anh Han,German Castignani,Pietro Liò*

Main category: cs.MA

TL;DR: 이 연구는 LLM 기반 에이전트의 협동 행동을 형성하는 데 있어 언어와 의사소통의 영향을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 많은 에이전트 간의 협력이 중요한 상황에서 언어가 전략적 시나리오를 형성하고 협력 행동에 영향을 미친다는 것을 알았다.

Method: FAIRGAME 프레임워크를 활용하여 의사소통의 유무에 따라 다양한 언어 및 모델에서 단발 및 반복 게임을 시뮬레이션하였다.

Result: 두 개의 고급 LLM(GPT-4o 및 Llama 4 Maverick)을 사용한 실험에서, 의사소통은 에이전트 행동에 상당한 영향을 미치지만, 그 영향은 언어, 개성 및 게임 구조에 따라 달라진다.

Conclusion: 의사소통은 협동을 촉진하고 편견을 강화하는 이중 역할을 한다.

Abstract: Large Language Model (LLM)-based agents are increasingly deployed in
multi-agent scenarios where coordination is crucial but not always assured.
Previous studies indicate that the language used to frame strategic scenarios
can influence cooperative behavior. This paper explores whether allowing agents
to communicate amplifies these language-driven effects. Leveraging the FAIRGAME
framework, we simulate one-shot and repeated games across different languages
and models, both with and without communication. Our experiments, conducted
with two advanced LLMs, GPT-4o and Llama 4 Maverick, reveal that communication
significantly influences agent behavior, though its impact varies by language,
personality, and game structure. These findings underscore the dual role of
communication in fostering coordination and reinforcing biases.

</details>


### [2] [WMAS: A Multi-Agent System Towards Intelligent and Customized Wireless Networks](https://arxiv.org/abs/2508.00280)
*Jingchen Peng,Dingli Yuan,Boxiang Ren,Jie Fan,Hao Wu,Lu Yang*

Main category: cs.MA

TL;DR: WMAS는 사용자 장비를 위한 지능형 서비스를 제공하며, 대화 토폴로지를 최적화하여 효율적인 다중 에이전트 작업 처리를 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 발전은 지능적이고 맞춤형 무선 네트워크의 실현 가능성을 제공한다.

Method: 다중 에이전트 대화 토폴로지를 유향 비순환 그래프로 모델링하고, 강화 학습 알고리즘을 사용하여 인접 행렬을 최적화한다.

Result: WMAS는 다양한 작업 유형에 대한 시뮬레이션 결과에서 기존 시스템 대비 더 높은 작업 성과와 낮은 대화 오버헤드를 달성했다.

Conclusion: WMAS는 미래의 무선 네트워크의 지능을 향상시킬 잠재력을 입증하였다.

Abstract: The fast development of Artificial Intelligence (AI) agents provides a
promising way for the realization of intelligent and customized wireless
networks. In this paper, we propose a Wireless Multi-Agent System (WMAS), which
can provide intelligent and customized services for different user equipment
(UEs). Note that orchestrating multiple agents carries the risk of malfunction,
and multi-agent conversations may fall into infinite loops. It is thus crucial
to design a conversation topology for WMAS that enables agents to complete UE
task requests with high accuracy and low conversation overhead. To address this
issue, we model the multi-agent conversation topology as a directed acyclic
graph and propose a reinforcement learning-based algorithm to optimize the
adjacency matrix of this graph. As such, WMAS is capable of generating and
self-optimizing multi-agent conversation topologies, enabling agents to
effectively and collaboratively handle a variety of task requests from UEs.
Simulation results across various task types demonstrate that WMAS can achieve
higher task performance and lower conversation overhead compared to existing
multi-agent systems. These results validate the potential of WMAS to enhance
the intelligence of future wireless networks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion](https://arxiv.org/abs/2508.00037)
*Tong Nie,Jian Sun,Wei Ma*

Main category: cs.LG

TL;DR: 이 논문은 대규모 도시 네트워크에서의 동적 예측을 위한 효율적인 데이터 기반 모델인 ScaleSTF를 제안하며, 선형 복잡도를 가진 Transformer 구조를 통해 성능과 확장성을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 도시 시스템의 복잡하고 불확실한 프로세스를 이해하고, 산업 및 공학적인 결정 지원을 위한 예측 모델의 필요성을 강조한다.

Method: Transformer 유사 구조를 기반으로 한 원칙적 설명 가능한 신경 확산 모델인 ScaleSTF를 제안하고, 저차원 임베딩을 사용한 주의층을 도입한다.

Result: ScaleSTF는 교통 흐름, 태양광 발전, 스마트 미터와 같은 대규모 도시 시스템에서 실험되었고, 최첨단 성능 및 뛰어난 확장성을 보여준다.

Conclusion: 본 연구는 대규모 도시 네트워크에서의 동적 예측에 대한 새로운 관점을 제시하며, 기존 모델의 한계를 극복할 수 있는 가능성을 열어준다.

Abstract: Networked urban systems facilitate the flow of people, resources, and
services, and are essential for economic and social interactions. These systems
often involve complex processes with unknown governing rules, observed by
sensor-based time series. To aid decision-making in industrial and engineering
contexts, data-driven predictive models are used to forecast spatiotemporal
dynamics of urban systems. Current models such as graph neural networks have
shown promise but face a trade-off between efficacy and efficiency due to
computational demands. Hence, their applications in large-scale networks still
require further efforts. This paper addresses this trade-off challenge by
drawing inspiration from physical laws to inform essential model designs that
align with fundamental principles and avoid architectural redundancy. By
understanding both micro- and macro-processes, we present a principled
interpretable neural diffusion scheme based on Transformer-like structures
whose attention layers are induced by low-dimensional embeddings. The proposed
scalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is
validated on large-scale urban systems including traffic flow, solar power, and
smart meters, showing state-of-the-art performance and remarkable scalability.
Our results constitute a fresh perspective on the dynamics prediction in
large-scale urban networks.

</details>


### [4] [Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings](https://arxiv.org/abs/2508.00039)
*Kaustav Chatterjee,Joshua Q. Li,Fatemeh Ansari,Masud Rana Munna,Kundan Parajulee,Jared Schwennesen*

Main category: cs.LG

TL;DR: 이 연구는 고속도로와 철도 안전을 향상시키기 위해 HRGC 프로파일 측정을 위한 저비용의 혁신적인 딥러닝 기법을 개발하였다.


<details>
  <summary>Details</summary>
Motivation: HRGC는 고속도로 차량에 대한 안전 위험을 초래하고, 기존의 측정 방법은 비용과 시간이 많이 소요된다.

Method: LSTM과 Transformer 아키텍처를 결합한 하이브리드 딥러닝 프레임워크를 활용하여, IMU와 GPS 센서를 통해 수집된 데이터로 HRGC 프로파일을 측정하였다.

Result: 모델 2와 3이 가장 높은 성능을 보였으며, 이 모델들을 사용해 2D/3D HRGC 프로파일을 생성하였다.

Conclusion: 고급 딥러닝 모델이 HRGC의 위험성을 신속하고 정확하게 평가하는 데 있어 잠재력이 크다는 것을 보여주었다.

Abstract: Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose
safety risks to highway vehicles due to potential hang-ups. These crossings
typically result from post-construction railway track maintenance activities or
non-compliance with design guidelines for HRGC vertical alignments.
Conventional methods for measuring HRGC profiles are costly, time-consuming,
traffic-disruptive, and present safety challenges. To address these issues,
this research employed advanced, cost-effective techniques and innovative
modeling approaches for HRGC profile measurement. A novel hybrid deep learning
framework combining Long Short-Term Memory (LSTM) and Transformer architectures
was developed by utilizing instrumentation and ground truth data.
Instrumentation data were gathered using a highway testing vehicle equipped
with Inertial Measurement Unit (IMU) and Global Positioning System (GPS)
sensors, while ground truth data were obtained via an industrial-standard
walking profiler. Field data was collected at the Red Rock Railroad Corridor in
Oklahoma. Three advanced deep learning models Transformer-LSTM sequential
(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel
(model 3) were evaluated to identify the most efficient architecture. Models 2
and 3 outperformed the others and were deployed to generate 2D/3D HRGC
profiles. The deep learning models demonstrated significant potential to
enhance highway and railroad safety by enabling rapid and accurate assessment
of HRGC hang-up susceptibility.

</details>


### [5] [Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting](https://arxiv.org/abs/2508.00040)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: 본 연구는 독일 시장의 24시간 전기 가격 예측을 위해 베이지안 레짐 감지와 조건부 신경 프로세스를 통합했다.


<details>
  <summary>Details</summary>
Motivation: 독일 전기 시장에서 효과적인 가격 예측을 통해 에너지 거래 및 최적화를 개선하고자 함.

Method: 디세이틀드 스티키 계층 디리클레 프로세스 숨겨진 마르코프 모델(DS-HDP-HMM)을 사용하여 일일 전기 가격에서 레짐을 감지하고, 독립적인 조건부 신경 프로세스(CNP)로 24차원 가격 궤적을 모델링.

Result: R-NP 모델이 2021년, 2022년, 2023년의 가장 균형 잡힌 솔루션으로 나타났으며, LEAR는 2021년 최상위 모델로 평가되었다.

Conclusion: 가격 예측의 정확성이 항상 최적의 운영 결과로 이어지지는 않으며, TOPSIS 분석을 통해 다양한 상황에서의 모델 성능을 평가하는 것이 중요하다.

Abstract: This work integrates Bayesian regime detection with conditional neural
processes for 24-hour electricity price prediction in the German market. Our
methodology integrates regime detection using a disentangled sticky
hierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to
daily electricity prices. Each identified regime is subsequently modeled by an
independent conditional neural process (CNP), trained to learn localized
mappings from input contexts to 24-dimensional hourly price trajectories, with
final predictions computed as regime-weighted mixtures of these CNP outputs. We
rigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated
auto-regressive (LEAR) models by integrating their forecasts into diverse
battery storage optimization frameworks, including price arbitrage, risk
management, grid services, and cost minimization. This operational utility
assessment revealed complex performance trade-offs: LEAR often yielded superior
absolute profits or lower costs, while DNN showed exceptional optimality in
specific cost-minimization contexts. Recognizing that raw prediction accuracy
doesn't always translate to optimal operational outcomes, we employed TOPSIS as
a comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified
LEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model
emerged as the most balanced and preferred solution for 2021, 2022 and 2023.

</details>


### [6] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
*Yebo Wu,Jingguang Li,Zhijiang Guo,Li Li*

Main category: cs.LG

TL;DR: DevFT는 자원의 효율적인 사용으로 LLM을 발전적으로 조정하여 개인정보 보호를 유지하며 성능과 속도를 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: LLM의 다운스트림 작업에 대한 적응을 가능하게 하면서 데이터 프라이버시를 유지하기 위해, 자원 집약적인 연습을 브라우스적인 방식으로 해결하고자 함.

Method: DevFT는 발전적 단계를 통해 미세 조정 과정을 분해하여 매개변수 용량이 증가하는 하위 모델을 최적화합니다. 이전 단계의 지식을 다음 하위 모델로 전달합니다.

Result: DevFT는 여러 벤치마크에서 기존 방법들과 비교하여 최대 4.59배 빠른 수렴, 10.67배 통신 오버헤드 감소, 9.07% 성능 향상을 달성했습니다.

Conclusion: DevFT는 기존 접근 방식과 호환성을 유지하면서도 상당한 성과를 보여주며, 인간 학습을 모방한 발전적 모델로 자원 효율적인 방법을 제안합니다.

Abstract: Federated fine-tuning enables Large Language Models (LLMs) to adapt to
downstream tasks while preserving data privacy, but its resource-intensive
nature limits deployment on edge devices. In this paper, we introduce
Developmental Federated Tuning (DevFT), a resource-efficient approach inspired
by cognitive development that progressively builds a powerful LLM from a
compact foundation. DevFT decomposes the fine-tuning process into developmental
stages, each optimizing submodels with increasing parameter capacity. Knowledge
from earlier stages transfers to subsequent submodels, providing optimized
initialization parameters that prevent convergence to local minima and
accelerate training. This paradigm mirrors human learning, gradually
constructing comprehensive knowledge structure while refining existing skills.
To efficiently build stage-specific submodels, DevFT introduces
deconfliction-guided layer grouping and differential-based layer fusion to
distill essential information and construct representative layers. Evaluations
across multiple benchmarks demonstrate that DevFT significantly outperforms
state-of-the-art methods, achieving up to 4.59$\times$ faster convergence,
10.67$\times$ reduction in communication overhead, and 9.07% average
performance improvement, while maintaining compatibility with existing
approaches.

</details>


### [7] [Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity](https://arxiv.org/abs/2508.00043)
*Nhut Truong,Uri Hasson*

Main category: cs.LG

TL;DR: 이 논문에서는 이웃 유닛 간의 가중치 유사성(WS)과 활성화 유사성(AS)이라는 두 가지 공간 제약을 가진 토포그래픽 컨볼루션 신경망을 비교하여 각각의 영향력을 평가했다.


<details>
  <summary>Details</summary>
Motivation: 토포그래픽 신경망은 뇌의 공간적 및 기능적 조직을 모방할 수 있는 계산 모델이다.

Method: WS는 이웃 유닛들이 유사한 입력 가중치를 갖게 하는 반면, AS는 유닛 활성화를 유사하게 유지하게 한다.

Result: WS는 노이즈에 대한 강인성이 개선되고, 활성화 분산이 증가하며, 기능적 로컬라이제이션이 강화되는 등의 장점을 보여주었다.

Conclusion: WS 제약은 AS나 비토포그래픽 CNN보다 더 강력한 표현을 생성할 수 있다.

Abstract: Topographic neural networks are computational models that can simulate the
spatial and functional organization of the brain. Topographic constraints in
neural networks can be implemented in multiple ways, with potentially different
impacts on the representations learned by the network. The impact of such
different implementations has not been systematically examined. To this end,
here we compare topographic convolutional neural networks trained with two
spatial constraints: Weight Similarity (WS), which pushes neighboring units to
develop similar incoming weights, and Activation Similarity (AS), which
enforces similarity in unit activations. We evaluate the resulting models on
classification accuracy, robustness to weight perturbations and input
degradation, and the spatial organization of learned representations. Compared
to both AS and standard CNNs, WS provided three main advantages: i) improved
robustness to noise, also showing higher accuracy under weight corruption; ii)
greater input sensitivity, reflected in higher activation variance; and iii)
stronger functional localization, with units showing similar activations
positioned at closer distances. In addition, WS produced differences in
orientation tuning, symmetry sensitivity, and eccentricity profiles of units,
indicating an influence of this spatial constraint on the representational
geometry of the network. Our findings suggest that during end-to-end training,
WS constraints produce more robust representations than AS or non-topographic
CNNs. These findings also suggest that weight-based spatial constraints can
shape feature learning and functional organization in biophysical inspired
models.

</details>


### [8] [Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains](https://arxiv.org/abs/2508.00046)
*Ruo Yu Tao,Kaicheng Guo,Cameron Allen,George Konidaris*

Main category: cs.LG

TL;DR: 본 논문은 강화 학습 알고리즘이 부분 관찰성을 극복하는데 필요한 포괄적인 벤치마크를 제공하기 위한 연구를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 부분 관찰성 문제 해결의 중요성과 현재 사용되는 벤치마크의 한계를 강조한다.

Method: 부분 관찰성을 평가하기 위한 새로운 벤치마크인 POBAX를 도입하고 다양한 환경에서 관찰성 유형을 특성화한다.

Result: 제안된 환경들은 모두 메모리 개선 가능성을 갖추고 있으며, 어려운 메모리 기능 학습이 필요함을 증명한다.

Conclusion: 본 연구는 부분 관찰성 연구를 위한 명확한 신호를 제공하며, 빠르고 효율적인 평가를 위한 하이퍼파라미터 및 알고리즘 구현을 포함한다.

Abstract: Mitigating partial observability is a necessary but challenging task for
general reinforcement learning algorithms. To improve an algorithm's ability to
mitigate partial observability, researchers need comprehensive benchmarks to
gauge progress. Most algorithms tackling partial observability are only
evaluated on benchmarks with simple forms of state aliasing, such as feature
masking and Gaussian noise. Such benchmarks do not represent the many forms of
partial observability seen in real domains, like visual occlusion or unknown
opponent intent. We argue that a partially observable benchmark should have two
key properties. The first is coverage in its forms of partial observability, to
ensure an algorithm's generalizability. The second is a large gap between the
performance of a agents with more or less state information, all other factors
roughly equal. This gap implies that an environment is memory improvable: where
performance gains in a domain are from an algorithm's ability to cope with
partial observability as opposed to other factors. We introduce best-practice
guidelines for empirically benchmarking reinforcement learning under partial
observability, as well as the open-source library POBAX: Partially Observable
Benchmarks in JAX. We characterize the types of partial observability present
in various environments and select representative environments for our
benchmark. These environments include localization and mapping, visual control,
games, and more. Additionally, we show that these tasks are all memory
improvable and require hard-to-learn memory functions, providing a concrete
signal for partial observability research. This framework includes recommended
hyperparameters as well as algorithm implementations for fast, out-of-the-box
evaluation, as well as highly performant environments implemented in JAX for
GPU-scalable experimentation.

</details>


### [9] [TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection](https://arxiv.org/abs/2508.00047)
*Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin*

Main category: cs.LG

TL;DR: 이 논문은 시간 시계열 이상 탐지를 위한 Tri-Branch Patch-wise Large Language Model Framework (TriP-LLM)를 제안하며, 전통적인 방법의 한계를 극복하고 최신 모델보다 우수한 성과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 사물인터넷(IoT) 및 스마트 제조의 발전으로 시간 시계열 데이터의 규모와 차원이 급격히 증가하였고, 이는 전통적인 통계적 방법의 한계를 드러내었다.

Method: TriP-LLM은 지역 및 전역 시간적 특징을 통합하고 입력 시간 시계를 패치 단위 토큰으로 인코딩하기 위해 Patching, Selection, Global의 세 가지 브랜치를 활용하여 구성을 수립한다.

Result: TriP-LLM은 여러 공개 벤치마크 데이터세트에서 최신 기법을 초월하여 강력한 탐지 능력을 보여준다.

Conclusion: LLM의 기여도를 확인하고, TriP-LLM은 더 낮은 메모리 소비를 달성하여 GPU 메모리에 제약이 있는 환경에서도 더 적합하다.

Abstract: Time-series anomaly detection plays a central role across a wide range of
application domains. With the increasing proliferation of the Internet of
Things (IoT) and smart manufacturing, time-series data has dramatically
increased in both scale and dimensionality. This growth has exposed the
limitations of traditional statistical methods in handling the high
heterogeneity and complexity of such data. Inspired by the recent success of
large language models (LLMs) in multimodal tasks across language and vision
domains, we propose a novel unsupervised anomaly detection framework: A
Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly
Detection (TriP-LLM). TriP-LLM integrates local and global temporal features
through a tri-branch design-Patching, Selection, and Global-to encode the input
time series into patch-wise tokens, which are then processed by a frozen,
pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from
which anomaly scores are derived. We evaluate TriP-LLM on several public
benchmark datasets using PATE, a recently proposed threshold-free evaluation
metric, and conduct all comparisons within a unified open-source framework to
ensure fairness. Experimental results show that TriP-LLM consistently
outperforms recent state-of-the-art methods across all datasets, demonstrating
strong detection capabilities. Furthermore, through extensive ablation studies,
we verify the substantial contribution of the LLM to the overall architecture.
Compared to LLM-based approaches using Channel Independence (CI) patch
processing, TriP-LLM achieves significantly lower memory consumption, making it
more suitable for GPU memory-constrained environments. All code and model
checkpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git

</details>


### [10] [Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization](https://arxiv.org/abs/2508.00078)
*Imen Mahmoud,Andrei Velichko*

Main category: cs.LG

TL;DR: COVID-19 관련 지표를 통합한 LightGBM 회귀 모델과 유전 알고리즘 최적화 프레임워크를 통해 비트코인 수익 예측의 정확성을 높이는 연구.


<details>
  <summary>Details</summary>
Motivation: 팬데믹과 관련된 건강 데이터를 포함하여 비트코인 수익 예측의 정확성을 높이고자 함.

Method: LightGBM 회귀 모델과 유전 알고리즘을 활용하여 COVID-19 지표와 비트코인 수익 간의 관계를 분석.

Result: COVID-19 지표가 모델 성능을 유의미하게 개선함을 보여줌. 특히 백신 접종률 지표가 주요 예측 변수로 나타남.

Conclusion: 제안된 방법론은 금융 분석 도구를 확장하여 투자자와 정책 입안자가 시스템적 위기 동안 시장 불확실성을 탐색할 수 있도록 도움을 줌.

Abstract: This study proposes a novel methodological framework integrating a LightGBM
regression model and genetic algorithm (GA) optimization to systematically
evaluate the contribution of COVID-19-related indicators to Bitcoin return
prediction. The primary objective was not merely to forecast Bitcoin returns
but rather to determine whether including pandemic-related health data
significantly enhances prediction accuracy. A comprehensive dataset comprising
daily Bitcoin returns and COVID-19 metrics (vaccination rates,
hospitalizations, testing statistics) was constructed. Predictive models,
trained with and without COVID-19 features, were optimized using GA over 31
independent runs, allowing robust statistical assessment. Performance metrics
(R2, RMSE, MAE) were statistically compared through distribution overlaps and
Mann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified
individual feature contributions. Results indicate that COVID-19 indicators
significantly improved model performance, particularly in capturing extreme
market fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly
significant statistically). Among COVID-19 features, vaccination metrics,
especially the 75th percentile of fully vaccinated individuals, emerged as
dominant predictors. The proposed methodology extends existing financial
analytics tools by incorporating public health signals, providing investors and
policymakers with refined indicators to navigate market uncertainty during
systemic crises.

</details>


### [11] [Stress-Aware Resilient Neural Training](https://arxiv.org/abs/2508.00098)
*Ashkan Shakarami,Yousef Yeganeh,Azade Farshad,Lorenzo Nicole,Stefano Ghidoni,Nassir Navab*

Main category: cs.LG

TL;DR: Stress-Aware Learning은 심층 신경망이 안정적인 훈련 환경과 불확실한 동역학에서 동적으로 최적화 행동을 조정하도록 하는 학습 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: 강한 최적화 난이도와 정체 상태에서 모델이 보다 일반화된 손실 전역으로 수렴할 수 있도록 지원하기 위해.

Method: Plastic Deformation Optimizer라는 메커니즘을 도입하여 내부 스트레스 신호에 따라 모델 매개변수에 적응형 노이즈를 주입한다.

Result: 여섯 개 아키텍처와 네 개 최적화 기법, 일곱 개 비전 벤치마크에서 개선된 강건성과 일반화 성능을 보였다.

Conclusion: 최소한의 계산 오버헤드로 모델 최적화를 개선하였으며, 코드와 3D 시각화는 GitHub에서 제공된다.

Abstract: This paper introduces Stress-Aware Learning, a resilient neural training
paradigm in which deep neural networks dynamically adjust their optimization
behavior - whether under stable training regimes or in settings with uncertain
dynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)
Deformation, inspired by structural fatigue in materials science. To
instantiate this concept, we propose Plastic Deformation Optimizer, a
stress-aware mechanism that injects adaptive noise into model parameters
whenever an internal stress signal - reflecting stagnation in training loss and
accuracy - indicates persistent optimization difficulty. This enables the model
to escape sharp minima and converge toward flatter, more generalizable regions
of the loss landscape. Experiments across six architectures, four optimizers,
and seven vision benchmarks demonstrate improved robustness and generalization
with minimal computational overhead. The code and 3D visuals will be available
on GitHub: https://github.com/Stress-Aware-Learning/SAL.

</details>


### [12] [StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection](https://arxiv.org/abs/2508.00117)
*Md. Ehsanul Haque,S. M. Jahidul Islam,Shakil Mia,Rumana Sharmin,Ashikuzzaman,Md Samir Morshed,Md. Tahmidul Huque*

Main category: cs.LG

TL;DR: StackLiverNet는 간 질환 감지를 위해 설계된 해석 가능한 앙상블 모델로, 뛰어난 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 간 질환의 조기 진단은 환자의 생존 가능성을 높이는 중요한 요소이며, 현재의 머신러닝 모델들은 여러 문제점을 안고 있다.

Method: StackLiverNet은 고급 데이터 전처리 및 특징 선택 기법을 사용하여 여러 하이퍼파라미터 최적화된 기본 분류기를 결합한 앙상블 모델이다.

Result: 모델은 99.89%의 정확도, 0.9974의 Cohen Kappa, 0.9993의 AUC를 기록하며, 훈련과 추론 속도가 임상 실습에 적합하다.

Conclusion: 모델을 통해 간 질환의 중요한 지표인 Alkaline Phosphatase와 SGOT의 영향을 분석할 수 있었다.

Abstract: Liver diseases are a serious health concern in the world, which requires
precise and timely diagnosis to enhance the survival chances of patients. The
current literature implemented numerous machine learning and deep learning
models to classify liver diseases, but most of them had some issues like high
misclassification error, poor interpretability, prohibitive computational
expense, and lack of good preprocessing strategies. In order to address these
drawbacks, we introduced StackLiverNet in this study; an interpretable stacked
ensemble model tailored to the liver disease detection task. The framework uses
advanced data preprocessing and feature selection technique to increase model
robustness and predictive ability. Random undersampling is performed to deal
with class imbalance and make the training balanced. StackLiverNet is an
ensemble of several hyperparameter-optimized base classifiers, whose
complementary advantages are used through a LightGBM meta-model. The provided
model demonstrates excellent performance, with the testing accuracy of 99.89%,
Cohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and
efficient training and inference speeds that are amenable to clinical practice
(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local
Interpretable Model-Agnostic Explanations (LIME) are applied to generate
transparent explanations of individual predictions, revealing high
concentrations of Alkaline Phosphatase and moderate SGOT as important
observations of liver disease. Also, SHAP was used to rank features by their
global contribution to predictions, while the Morris method confirmed the most
influential features through sensitivity analysis.

</details>


### [13] [Structured Transformations for Stable and Interpretable Neural Computation](https://arxiv.org/abs/2508.00127)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.LG

TL;DR: 층 수준의 변환을 구조화된 선형 연산자와 잔여 보정 성분으로 재구성하여 신호 전파를 개선하고 훈련 동역학을 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 현대 신경망은 안정적인 학습과 해석 가능한 행동을 촉진하는 구조적 안전장치가 부족하다.

Method: 전통적인 비제약적 아핀 패러다임에서 벗어나 각 변환을 구조화된 선형 연산자와 잔여 보정 성분으로 분해한다.

Result: 이러한 구조화된 변환으로 구성된 모델들은 개선된 그래디언트 조정, 감소된 섭동 민감도 및 층별 강건성을 보여준다.

Conclusion: 이 연구는 안정성과 투명성을 우선시하는 신경 구조의 보다 원칙적인 클래스의 기초를 제공한다.

Abstract: Despite their impressive performance, contemporary neural networks often lack
structural safeguards that promote stable learning and interpretable behavior.
In this work, we introduce a reformulation of layer-level transformations that
departs from the standard unconstrained affine paradigm. Each transformation is
decomposed into a structured linear operator and a residual corrective
component, enabling more disciplined signal propagation and improved training
dynamics. Our formulation encourages internal consistency and supports stable
information flow across depth, while remaining fully compatible with standard
learning objectives and backpropagation. Through a series of synthetic and
real-world experiments, we demonstrate that models constructed with these
structured transformations exhibit improved gradient conditioning, reduced
sensitivity to perturbations, and layer-wise robustness. We further show that
these benefits persist across architectural scales and training regimes. This
study serves as a foundation for a more principled class of neural
architectures that prioritize stability and transparency-offering new tools for
reasoning about learning behavior without sacrificing expressive power.

</details>


### [14] [ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks](https://arxiv.org/abs/2508.00131)
*Christopher Harvey,Sumaiya Shomaji,Zijun Yao,Amit Noheria*

Main category: cs.LG

TL;DR: 이 연구는 ECG 신호 처리를 위한 VAE 변형을 통해 데이터 복잡성을 줄이고 예측 정확성을 향상시키는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: ECG 신호는 복잡하고 개인차가 커서 깊은 학습 모델에서 다루기 어렵고, 특히 적은 훈련 데이터셋을 사용할 때 더욱 그렇다.

Method: 주요 성분 분석(PCA)과 오토인코더를 활용하여 ECG의 특징 생성을 탐구하고, 세 가지 새로운 변형의 변량 오토인코더(VAE)를 제안한다.

Result: A beta-VAE는 신호 복원을 개선하여 MAE를 15.7+/-3.2 muV로 줄였고, SAE는 전통적인 ECG 요약 특징과 결합하여 LVEF 예측을 향상시켰다.

Conclusion: 이 연구는 제한된 레이블 훈련 데이터로도 깊은 학습을 적용할 수 있는 실용적인 솔루션을 제공한다.

Abstract: The electrocardiogram (ECG) is an inexpensive and widely available tool for
cardiac assessment. Despite its standardized format and small file size, the
high complexity and inter-individual variability of ECG signals (typically a
60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep
learning models, especially when only small training datasets are available.
This study addresses these challenges by exploring feature generation methods
from representative beat ECGs, focusing on Principal Component Analysis (PCA)
and Autoencoders to reduce data complexity. We introduce three novel
Variational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed
beta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their
effectiveness in maintaining signal fidelity and enhancing downstream
prediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE
achieved superior signal reconstruction, reducing the mean absolute error (MAE)
to 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE
encodings, when combined with traditional ECG summary features, improved the
prediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an
holdout test set area under the receiver operating characteristic curve (AUROC)
of 0.901 with a LGBM classifier. This performance nearly matches the 0.909
AUROC of state-of-the-art CNN model but requires significantly less
computational resources. Further, the ECG feature extraction-LGBM pipeline
avoids overfitting and retains predictive performance when trained with less
data. Our findings demonstrate that these VAE encodings are not only effective
in simplifying ECG data but also provide a practical solution for applying deep
learning in contexts with limited-scale labeled training data.

</details>


### [15] [INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks](https://arxiv.org/abs/2508.00141)
*Mohit Gupta,Debjit Bhowmick,Rhys Newbury,Meead Saberi,Shirui Pan,Ben Beck*

Main category: cs.LG

TL;DR: INSPIRE-GNN은 희소한 데이터를 활용하여 자전거 교통량 추정을 최적화하는 새로운 강화 학습 기반 그래프 신경망 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 도시의 지속 가능한 교통 계획을 위한 정확한 자전거 교통량 추정의 필요성 및 센서 커버리지의 부족 문제 해결.

Method: 그래프 합성곱 네트워크(GCN)와 그래프 주의 네트워크(GAT)를 결합한 강화 학습 기반의 INSPIRE-GNN 프레임워크 제안.

Result: 멜버른의 자전거 네트워크에서 99%의 데이터 희소성에도 불구하고, 추가 센서를 전략적으로 배치하여 데이터 추정 성능을 크게 향상시킴.

Conclusion: INSPIRE-GNN은 센서 네트워크 확장 및 최적화를 위한 실행 가능한 통찰력을 제공하여 자전거 데이터의 정확성과 신뢰성을 높임.

Abstract: Accurate link-level bicycling volume estimation is essential for sustainable
urban transportation planning. However, many cities face significant challenges
of high data sparsity due to limited bicycling count sensor coverage. To
address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning
(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize
sensor placement and improve link-level bicycling volume estimation in
data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks
(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL
agent, enabling a data-driven strategic selection of sensor locations to
maximize estimation performance. Applied to Melbourne's bicycling network,
comprising 15,933 road segments with sensor coverage on only 141 road segments
(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume
estimation by strategically selecting additional sensor locations in
deployments of 50, 100, 200 and 500 sensors. Our framework outperforms
traditional heuristic methods for sensor placement such as betweenness
centrality, closeness centrality, observed bicycling activity and random
placement, across key metrics such as Mean Squared Error (MSE), Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our
experiments benchmark INSPIRE-GNN against standard machine learning and deep
learning models in the bicycle volume estimation performance, underscoring its
effectiveness. Our proposed framework provides transport planners actionable
insights to effectively expand sensor networks, optimize sensor placement and
maximize volume estimation accuracy and reliability of bicycling data for
informed transportation planning decisions.

</details>


### [16] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
*Ziqian Zhong,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 이 논문은 출시된 대형 언어 모델의 가중치를 해석하여 파인튜닝 동안 발생하는 새로운 행동을 감지하고, 효과적으로 백도어 공격을 방어하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 해석 방법이 분포적으로 유사한 데이터를 요구하거나 가정하는 문제를 해결하고, 백도어와 같은 새로운 위협을 탐지하기 위해.

Method: 모델의 활성화 대신 가중치를 해석하여 파인튜닝에 따른 새로운 행동을 감지하고, 코사인 유사도를 통해 행동을 모니터링하는 방법을 사용한다.

Result: 파인튜닝된 모델과 기본 모델 간의 가중치 차이의 주요 특이값 벡터가 새롭게 획득한 행동과 대응하며, 백도어 공격을 100% 차단하고, 삭제된 토픽에 대한 추론을 95.42%의 정확도로 감지한다.

Conclusion: 이 방법은 모델 모니터링 외에도 사전 배포 모델 감사의 잠재력을 보여주며, 상업적 모델의 파인튜닝 초점을 발견할 수 있다.

Abstract: The releases of powerful open-weight large language models (LLMs) are often
not accompanied by access to their full training data. Existing
interpretability methods, particularly those based on activations, often
require or assume distributionally similar data. This is a significant
limitation when detecting and defending against novel potential threats like
backdoors, which are by definition out-of-distribution.
  In this work, we introduce a new method for understanding, monitoring and
controlling fine-tuned LLMs that interprets weights, rather than activations,
thereby side stepping the need for data that is distributionally similar to the
unknown training data. We demonstrate that the top singular vectors of the
weight difference between a fine-tuned model and its base model correspond to
newly acquired behaviors. By monitoring the cosine similarity of activations
along these directions, we can detect salient behaviors introduced during
fine-tuning with high precision.
  For backdoored models that bypasses safety mechanisms when a secret trigger
is present, our method stops up to 100% of attacks with a false positive rate
below 1.2%. For models that have undergone unlearning, we detect inference on
erased topics with accuracy up to 95.42% and can even steer the model to
recover "unlearned" information. Besides monitoring, our method also shows
potential for pre-deployment model auditing: by analyzing commercial
instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover
model-specific fine-tuning focus including marketing strategies and Midjourney
prompt generation.
  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.

</details>


### [17] [DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission](https://arxiv.org/abs/2508.00172)
*Fupei Guo,Hao Zheng,Xiang Zhang,Li Chen,Yue Wang,Songyang Zhang*

Main category: cs.LG

TL;DR: 이 논문은 의료 이미지 전송을 위한 새로운 확산 기반 의미 통신 프레임워크인 DiSC-Med를 제안하며, 이는 대역폭 효율성과 강인성을 위해 의료 향상 압축 및 잡음 제거 블록을 개발한다.


<details>
  <summary>Details</summary>
Motivation: 인공지능의 발전과 차세대 무선 통신 기술이 원격 진단 및 개입에 대한 흥미로운 애플리케이션을 자극하면서, 제한된 대역폭과 잡음이 많은 채널을 통한 의료 데이터의 효율적인 전송이 중요해졌다.

Method: DiSC-Med는 의료 이미지 전송을 위한 새로운 프레임워크로, 의료 향상 압축 및 잡음 제거 블록을 통해 대역폭 효율성과 강인성을 확보한다.

Result: 실제 의료 데이터 세트에 대한 실험을 통해 DiSC-Med의 효과가 입증되었으며, 원격 의료 애플리케이션에 대한 가능성을 보여준다.

Conclusion: 우리의 프레임워크는 전통적인 픽셀 기반 통신 방법과 달리 핵심 의미 정보를 포착하고 잡음 채널에 대해 초고대역폭 효율성을 달성하여 뛰어난 재구성 성능을 제공한다.

Abstract: The rapid development of artificial intelligence has driven smart health with
next-generation wireless communication technologies, stimulating exciting
applications in remote diagnosis and intervention. To enable a timely and
effective response for remote healthcare, efficient transmission of medical
data through noisy channels with limited bandwidth emerges as a critical
challenge. In this work, we propose a novel diffusion-based semantic
communication framework, namely DiSC-Med, for the medical image transmission,
where medical-enhanced compression and denoising blocks are developed for
bandwidth efficiency and robustness, respectively. Unlike conventional
pixel-wise communication framework, our proposed DiSC-Med is able to capture
the key semantic information and achieve superior reconstruction performance
with ultra-high bandwidth efficiency against noisy channels. Extensive
experiments on real-world medical datasets validate the effectiveness of our
framework, demonstrating its potential for robust and efficient telehealth
applications.

</details>


### [18] [RL as Regressor: A Reinforcement Learning Approach for Function Approximation](https://arxiv.org/abs/2508.00174)
*Yongchao Huang*

Main category: cs.LG

TL;DR: 전통적인 회귀 기법 대신 강화 학습 문제로 회귀를 구성하여 예측 오류 기반의 커스텀 보상 신호를 활용한 접근 방식.


<details>
  <summary>Details</summary>
Motivation: 기존 회귀 기법이 비대칭 비용이나 복잡한 비미분 가능 목표를 완전히 포착하지 못하는 문제를 해결하고자 함.

Method: 모델의 예측을 행동으로 처리하고, 예측 오류에 기반한 커스텀 보상 신호를 정의하여 강화 학습 알고리즘을 통한 함수 근사를 수행.

Result: 노이즈가 있는 사인파 학습의 점진적 사례 연구를 통해 강화 학습 에이전트의 개발을 시연하며, Prioritized Experience Replay 및 네트워크 용량 증가 등을 단계적으로 적용.

Conclusion: 강화 학습 프레임워크가 회귀 문제를 해결할 뿐만 아니라 목표 정의와 학습 과정을 안내하는 데 있어 유연성을 제공함을 보여줌.

Abstract: Standard regression techniques, while powerful, are often constrained by
predefined, differentiable loss functions such as mean squared error. These
functions may not fully capture the desired behavior of a system, especially
when dealing with asymmetric costs or complex, non-differentiable objectives.
In this paper, we explore an alternative paradigm: framing regression as a
Reinforcement Learning (RL) problem. We demonstrate this by treating a model's
prediction as an action and defining a custom reward signal based on the
prediction error, and we can leverage powerful RL algorithms to perform
function approximation. Through a progressive case study of learning a noisy
sine wave, we illustrate the development of an Actor-Critic agent, iteratively
enhancing it with Prioritized Experience Replay, increased network capacity,
and positional encoding to enable a capable RL agent for this regression task.
Our results show that the RL framework not only successfully solves the
regression problem but also offers enhanced flexibility in defining objectives
and guiding the learning process.

</details>


### [19] [EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes](https://arxiv.org/abs/2508.00180)
*Adam Block,Cyril Zhang*

Main category: cs.LG

TL;DR: BEMA는 기존의 EMA를 개선하여 훈련 안정성을 높이고 성능을 향상시키는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델의 미세 조정에서의 불확실성과 대규모 훈련의 불안정성을 해결하기 위해

Method: 기존 EMA를 보완하는 Bias-Corrected Exponential Moving Average(BEMA)를 제안함.

Result: BEMA는 여러 언어 모델 벤치마크에서 기존의 EMA 및 일반 훈련보다 더 나은 수렴 속도와 성능을 보였다.

Conclusion: BEMA는 언어 모델 훈련의 안정성과 효율성을 높이는 실용적이고 이론적으로 근거가 있는 방법이다.

Abstract: Stochasticity in language model fine-tuning, often caused by the small batch
sizes typically used in this regime, can destabilize training by introducing
large oscillations in generation quality. A popular approach to mitigating this
instability is to take an Exponential moving average (EMA) of weights
throughout training. While EMA reduces stochasticity, thereby smoothing
training, the introduction of bias from old iterates often creates a lag in
optimization relative to vanilla training. In this work, we propose the
Bias-Corrected Exponential Moving Average (BEMA), a simple and practical
augmentation of EMA that retains variance-reduction benefits while eliminating
bias. BEMA is motivated by a simple theoretical model wherein we demonstrate
provable acceleration of BEMA over both a standard EMA and vanilla training.
Through an extensive suite of experiments on Language Models, we show that BEMA
leads to significantly improved convergence rates and final performance over
both EMA and vanilla training in a variety of standard LM benchmarks, making
BEMA a practical and theoretically motivated intervention for more stable and
efficient fine-tuning.

</details>


### [20] [RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems](https://arxiv.org/abs/2508.00201)
*Mehdi Ben Ayed,Fei Feng,Jay Adams,Vishwakarma Singh,Kritarth Anand,Jiajing Xu*

Main category: cs.LG

TL;DR: RecoMind는 웹 스케일 추천 시스템을 위한 시뮬레이터 기반의 강화 학습 프레임워크로, 세션 기반 목표 최적화를 효과적으로 수행한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 추천 시스템은 즉각적인 사용자 피드백에 중점을 두었으나, 강화 학습은 장기적인 목표 최적화에 도움을 줄 수 있어 필요하다.

Method: RecoMind는 기존 추천 모델을 활용하여 시뮬레이션 환경을 설정하고, 즉각적인 사용자 상호작용을 최적화하기 위해 RL 정책을 부트스트랩 한다.

Result: 전통적인 감독 학습 방법보다 RL 정책이 세션 내 사용자 만족도를 크게 향상시켰으며, A/B 테스트 결과 비디오 시청 시간이 15.81% 증가했다.

Conclusion: RecoMind는 웹 스케일 추천 시스템에 RL을 통합하기 위한 체계적이고 확장 가능한 접근 방식을 제공하며, 사용자 만족도를 최적화하는 데 큰 잠재력을 지닌다.

Abstract: Existing web-scale recommendation systems commonly use supervised learning
methods that prioritize immediate user feedback. Although reinforcement
learning (RL) offers a solution to optimize longer-term goals, such as
in-session engagement, applying it at web scale is challenging due to the
extremely large action space and engineering complexity. In this paper, we
introduce RecoMind, a simulator-based RL framework designed for the effective
optimization of session-based goals at web-scale. RecoMind leverages existing
recommendation models to establish a simulation environment and to bootstrap
the RL policy to optimize immediate user interactions from the outset. This
method integrates well with existing industry pipelines, simplifying the
training and deployment of RL policies. Additionally, RecoMind introduces a
custom exploration strategy to efficiently explore web-scale action spaces with
hundreds of millions of items. We evaluated RecoMind through extensive offline
simulations and online A/B testing on a video streaming platform. Both methods
showed that the RL policy trained using RecoMind significantly outperforms
traditional supervised learning recommendation approaches in in-session user
satisfaction. In online A/B tests, the RL policy increased videos watched for
more than 10 seconds by 15.81\% and improved session depth by 4.71\% for
sessions with at least 10 interactions. As a result, RecoMind presents a
systematic and scalable approach for embedding RL into web-scale recommendation
systems, showing great promise for optimizing session-based user satisfaction.

</details>


### [21] [Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models](https://arxiv.org/abs/2508.00202)
*Ecem Bozkurt,Antonio Ortega*

Main category: cs.LG

TL;DR: 이 논문은 레이블 노이즈가 있는 데이터에서 파운데이션 모델을 강인하게 훈련하기 위한 두 단계 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 최근 kNN 기법이 레이블 노이즈가 심한 상황에서도 우수한 성능을 발휘한다는 사실에 착안하였다.

Method: 안정성 추정과 안정성 가중 추론의 두 단계 절차를 통해 기하학적 정보를 도입한 인퍼런스를 제안한다.

Result: CIFAR-10과 DermaMNIST에서 다양한 노이즈 조건 하에 강 robustness를 개선하여 표준 K-NN 접근법 및 최근 적응형 이웃 기준선을 초월하였다.

Conclusion: 제안된 방법은 레이블 노이즈가 증가함에 따라 거리 및 지역 이웃에 덜 의존하면서 안정성 추정의 여러 방법을 제안한다.

Abstract: Foundation models (FMs) pretrained on large datasets have become fundamental
for various downstream machine learning tasks, in particular in scenarios where
obtaining perfectly labeled data is prohibitively expensive. In this paper, we
assume an FM has to be fine-tuned with noisy data and present a two-stage
framework to ensure robust classification in the presence of label noise
without model retraining. Recent work has shown that simple k-nearest neighbor
(kNN) approaches using an embedding derived from an FM can achieve good
performance even in the presence of severe label noise. Our work is motivated
by the fact that these methods make use of local geometry. In this paper,
following a similar two-stage procedure, reliability estimation followed by
reliability-weighted inference, we show that improved performance can be
achieved by introducing geometry information. For a given instance, our
proposed inference uses a local neighborhood of training data, obtained using
the non-negative kernel (NNK) neighborhood construction. We propose several
methods for reliability estimation that can rely less on distance and local
neighborhood as the label noise increases. Our evaluation on CIFAR-10 and
DermaMNIST shows that our methods improve robustness across various noise
conditions, surpassing standard K-NN approaches and recent
adaptive-neighborhood baselines.

</details>


### [22] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
*Paul Albert,Frederic Z. Zhang,Hemanth Saratchandran,Anton van den Hengel,Ehsan Abbasnejad*

Main category: cs.LG

TL;DR: 본 연구는 PEFT 방법 중 LoRA의 한계를 지적하며, 새로운 PEFT 기법 KRAdapter를 제안하여 성능 개선을 보여준다.


<details>
  <summary>Details</summary>
Motivation: PEFT는 대규모 사전 훈련 모델을 조정하는 표준 접근법으로 자리잡았지만, LoRA의 한계가 드러났다.

Method: 연구는 가상 행렬 근사 벤치마크를 사용하여 전체 순위 및 저순위 PEFT 방법을 비교하고, KRAdapter라는 새로운 알고리즘을 소개한다.

Result: KRAdapter는 효과적인 순위가 높은 행렬 곱을 생성하여 성능 향상을 보여주었고, 1B 및 8B 파라미터 모델에서 특히 눈에 띄는 결과를 얻었다.

Conclusion: KRAdapter는 LoRA의 메모리 및 계산 효율성을 유지하면서도 대규모 파라미터 모델 조정에 실용적이고 강력한 대안이 된다.

Abstract: Parameter-efficient fine-tuning (PEFT) has become a standard approach for
adapting large pre-trained models. Amongst PEFT methods, low-rank adaptation
(LoRA) has achieved notable success. However, recent studies have highlighted
its limitations compared against full-rank alternatives, particularly when
applied to multimodal and large language models. In this work, we present a
quantitative comparison amongst full-rank and low-rank PEFT methods using a
synthetic matrix approximation benchmark with controlled spectral properties.
Our results confirm that LoRA struggles to approximate matrices with relatively
flat spectrums or high frequency components -- signs of high effective ranks.
To this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the
Khatri-Rao product to produce weight updates, which, by construction, tends to
produce matrix product with a high effective rank. We demonstrate performance
gains with KRAdapter on vision-language models up to 1B parameters and on large
language models up to 8B parameters, particularly on unseen common-sense
reasoning tasks. In addition, KRAdapter maintains the memory and compute
efficiency of LoRA, making it a practical and robust alternative to fine-tune
billion-scale parameter models.

</details>


### [23] [Calibrated Language Models and How to Find Them with Label Smoothing](https://arxiv.org/abs/2508.00264)
*Jerry Huang,Peng Lu,Qiuhao Zeng*

Main category: cs.LG

TL;DR: 자연어 처리의 진전이 대규모 언어 모델의 신뢰도 조정 문제를 탐구하며, 라벨 스무딩을 통한 실질적인 해결 방안을 제시함.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 지침 수용 능력 향상이 신뢰도 조정에 미치는 영향을 이해하기 위해 연구함.

Method: 라벨 스무딩 기법을 적용하여 대규모 언어 모델의 과신 예측을 규제하고, 실험을 통해 대형 어휘 모델에서의 효과를 이론적으로 및 실험적으로 분석함.

Result: 모든 모델에서 지침 조정 후 신뢰도 조정의 현저한 저하를 관찰하며, 라벨 스무딩이 유효함을 입증함.

Conclusion: 커스텀 커널을 설계하여 메모리 사용량을 줄이면서도 기존 성능을 유지하는 해결책을 제시함.

Abstract: Recent advances in natural language processing (NLP) have opened up greater
opportunities to enable fine-tuned large language models (LLMs) to behave as
more powerful interactive agents through improved instruction-following
ability. However, understanding how this impacts confidence calibration for
reliable model output has not been researched in full. In this work, we examine
various open-sourced LLMs, identifying significant calibration degradation
after instruction tuning in each. Seeking a practical solution, we look towards
label smoothing, which has been shown as an effective method to regularize for
overconfident predictions but has yet to be widely adopted in the supervised
fine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing
is sufficient to maintain calibration throughout the SFT process. However,
settings remain where the effectiveness of smoothing is severely diminished, in
particular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to
stem from the ability to become over-confident, which has a direct relationship
with the hidden size and vocabulary size, and justify this theoretically and
experimentally. Finally, we address an outstanding issue regarding the memory
footprint of the cross-entropy loss computation in the label smoothed loss
setting, designing a customized kernel to dramatically reduce memory
consumption without sacrificing speed or performance in comparison to existing
solutions for non-smoothed losses.

</details>


### [24] [Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring](https://arxiv.org/abs/2508.00270)
*Robin Schmucker,Nimish Pachapurkar,Shanmuga Bala,Miral Shah,Tom Mitchell*

Main category: cs.LG

TL;DR: 온라인 튜터링 시스템이 학생들을 위한 맞춤형 피드백을 제공하며, 다수의 학생 데이터를 활용하여 최적의 학습 결과를 도출.


<details>
  <summary>Details</summary>
Motivation: 정답을 잘못된 학생들에게 효과적인 피드백을 제공함으로써 학습을 향상시키기 위해.

Method: 다중무장밴딧(MAB) 프레임워크와 오프라인 정책 평가를 활용하여 43,000개의 보조 행동을 평가하고 적절한 정책 교육 목표를 결정하는 알고리즘을 설계.

Result: 166,000개의 실습 세션에서 MAB 정책을 평가하여 학생 결과에 실질적인 개선이 있음을 확인.

Conclusion: 맞춤형 피드백을 제공하기 위한 맥락적 밴딧(CB) 정책의 효과는 제한적이며, 데이터를 기반으로 한 시스템의 배포에서 얻은 통찰이 미래 개선을 위한 지침을 제공.

Abstract: We present an online tutoring system that learns to provide effective
feedback to students after they answer questions incorrectly. Using data from
one million students, the system learns which assistance action (e.g., one of
multiple hints) to provide for each question to optimize student learning.
Employing the multi-armed bandit (MAB) framework and offline policy evaluation,
we assess 43,000 assistance actions, and identify trade-offs between assistance
policies optimized for different student outcomes (e.g., response correctness,
session completion). We design an algorithm that for each question decides on a
suitable policy training objective to enhance students' immediate second
attempt success and overall practice session performance. We evaluate the
resulting MAB policies in 166,000 practice sessions, verifying significant
improvements in student outcomes. While MAB policies optimize feedback for the
overall student population, we further investigate whether contextual bandit
(CB) policies can enhance outcomes by personalizing feedback based on
individual student features (e.g., ability estimates, response times). Using
causal inference, we examine (i) how effects of assistance actions vary across
students and (ii) whether CB policies, which leverage such effect
heterogeneity, outperform MAB policies. While our analysis reveals that some
actions for some questions exhibit effect heterogeneity, effect sizes may often
be too small for CB policies to provide significant improvements beyond what
well-optimized MAB policies that deliver the same action to all students
already achieve. We discuss insights gained from deploying data-driven systems
at scale and implications for future refinements. Today, the teaching policies
optimized by our system support thousands of students daily.

</details>


### [25] [Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem](https://arxiv.org/abs/2508.00286)
*Mohsen Zaker Esteghamati*

Main category: cs.LG

TL;DR: 이 연구는 성능 기반 내진 설계를 역설계 문제로 다루는 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 성능 목표를 달성하기 위한 설계 매개 변수를 직접 도출하려는 필요성.

Method: 설계 변수와 성능 지표를 매핑하는 설명 가능한 머신러닝 모델을 구현하고, 이를 유전 알고리즘에 통합하여 역문제를 해결.

Result: 로스앤젤레스와 찰스턴의 강철 및 콘크리트 모멘트 프레임 두 가지 사례에서 최적의 단면 특성을 도출하여 연간 수리 비용을 최소화하는 성과.

Conclusion: 다양한 건물 유형과 지진 설계 조건에서 높은 정확도로 최적 값을 도출할 수 있음을 입증.

Abstract: This study presents a methodology to treat performance-based seismic design
as an inverse engineering problem, where design parameters are directly derived
to achieve specific performance objectives. By implementing explainable machine
learning models, this methodology directly maps design variables and
performance metrics, tackling computational inefficiencies of performance-based
design. The resultant machine learning model is integrated as an evaluation
function into a genetic optimization algorithm to solve the inverse problem.
The developed methodology is then applied to two different inventories of steel
and concrete moment frames in Los Angeles and Charleston to obtain sectional
properties of frame members that minimize expected annualized seismic loss in
terms of repair costs. The results show high accuracy of the surrogate models
(e.g., R2> 90%) across a diverse set of building types, geometries, seismic
design, and site hazard, where the optimization algorithm could identify the
optimum values of members' properties for a fixed set of geometric variables,
consistent with engineering principles.

</details>


### [26] [Invariant Graph Transformer for Out-of-Distribution Generalization](https://arxiv.org/abs/2508.00304)
*Tianyin Liao,Ziwei Zhang,Yufei Sun,Chunyu Hu,Jianxin Li*

Main category: cs.LG

TL;DR: Graph Out-Of-Distribution 일반화 변환기(GOODFormer)는 그래프 불변 학습 원칙에 기반해 일반화 가능한 그래프 표현을 학습하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 그래프 변환기들이 동일한 분포의 그래프 데이터에 국한되어 일반화 능력이 부족하다는 문제를 해결하고자 한다.

Method: GOODFormer는 세 가지 모듈을 공동 최적화하여 예측 그래프 구조와 레이블 간의 불변 관계를 포착하는 것을 목표로 한다.

Result: 우리는 GOODFormer가 분포 변화 하에서도 기존 최첨단 방법들보다 우수한 성능을 나타낸다는 것을 실험적으로 입증하였다.

Conclusion: 우리의 접근법은 새로운 그래프에 대해 일반화 가능한 그래프 표현을 성공적으로 도출함을 보여준다.

Abstract: Graph Transformers (GTs) have demonstrated great effectiveness across various
graph analytical tasks. However, the existing GTs focus on training and testing
graph data originated from the same distribution, but fail to generalize under
distribution shifts. Graph invariant learning, aiming to capture generalizable
graph structural patterns with labels under distribution shifts, is potentially
a promising solution, but how to design attention mechanisms and positional and
structural encodings (PSEs) based on graph invariant learning principles
remains challenging. To solve these challenges, we introduce Graph
Out-Of-Distribution generalized Transformer (GOODFormer), aiming to learn
generalized graph representations by capturing invariant relationships between
predictive graph structures and labels through jointly optimizing three
modules. Specifically, we first develop a GT-based entropy-guided invariant
subgraph disentangler to separate invariant and variant subgraphs while
preserving the sharpness of the attention function. Next, we design an evolving
subgraph positional and structural encoder to effectively and efficiently
capture the encoding information of dynamically changing subgraphs during
training. Finally, we propose an invariant learning module utilizing subgraph
node representations and encodings to derive generalizable graph
representations that can to unseen graphs. We also provide theoretical
justifications for our method. Extensive experiments on benchmark datasets
demonstrate the superiority of our method over state-of-the-art baselines under
distribution shifts.

</details>


### [27] [PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models](https://arxiv.org/abs/2508.00325)
*Yongquan Qu,Matthieu Blanke,Sara Shamekh,Pierre Gentine*

Main category: cs.LG

TL;DR: 제안된 PnP-DA 알고리즘은 혼합 전략을 통해 기후 모델의 예측 오차를 감소시킵니다.


<details>
  <summary>Details</summary>
Motivation: 지구 시스템 모델링에서 컴퓨터 효율성을 유지하면서 복잡한 비선형 역학을 정확하게 포착하는 것이 필요하다.

Method: PnP-DA는 경량의 경량 그래디언트 기반 분석 업데이트와 조건부 Wasserstein 커플링을 통한 사전 훈련된 생성적 정보를 사용하는 방법으로 구성된다.

Result: PnP-DA는 여러 관측 희소성과 노이즈 수준에서 예측 오류를 일관되게 감소시키며, 고전적인 변분 방법보다 우수한 성능을 보였다.

Conclusion: 이 알고리즘은 혼합 관측 데이터와 사전 모델 예측을 최적 결합하여 예측 정확도를 향상시킨다.

Abstract: Earth system modeling presents a fundamental challenge in scientific
computing: capturing complex, multiscale nonlinear dynamics in computationally
efficient models while minimizing forecast errors caused by necessary
simplifications. Even the most powerful AI- or physics-based forecast system
suffer from gradual error accumulation. Data assimilation (DA) aims to mitigate
these errors by optimally blending (noisy) observations with prior model
forecasts, but conventional variational methods often assume Gaussian error
statistics that fail to capture the true, non-Gaussian behavior of chaotic
dynamical systems. We propose PnP-DA, a Plug-and-Play algorithm that alternates
(1) a lightweight, gradient-based analysis update (using a Mahalanobis-distance
misfit on new observations) with (2) a single forward pass through a pretrained
generative prior conditioned on the background forecast via a conditional
Wasserstein coupling. This strategy relaxes restrictive statistical assumptions
and leverages rich historical data without requiring an explicit regularization
functional, and it also avoids the need to backpropagate gradients through the
complex neural network that encodes the prior during assimilation cycles.
Experiments on standard chaotic testbeds demonstrate that this strategy
consistently reduces forecast errors across a range of observation sparsities
and noise levels, outperforming classical variational methods.

</details>


### [28] [Embryology of a Language Model](https://arxiv.org/abs/2508.00331)
*George Wang,Garrett Baker,Andrew Gordon,Daniel Murfet*

Main category: cs.LG

TL;DR: 이 연구는 UMAP을 사용하여 언어 모델의 훈련 과정에서의 구조적 발전을 시각화하고, 새로운 구조를 발견하여 복잡한 신경망의 개발 원리를 연구하는 데 도움을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 딥 러닝 과학에서 언어 모델의 내부 계산 구조를 이해하는 것은 중요한 문제다.

Method: 수용성 행렬에 UMAP을 적용하여 시각화를 진행한다.

Result: 모델의 인기 있는 특징 및 새로운 구조가 드러나며, 특별히 '간격 핀'과 같은 구조가 발견된다.

Conclusion: 수용성 분석은 검증을 넘어 새로운 메커니즘을 발견할 수 있는 강력한 수단이 될 수 있음을 보여준다.

Abstract: Understanding how language models develop their internal computational
structure is a central problem in the science of deep learning. While
susceptibilities, drawn from statistical physics, offer a promising analytical
tool, their full potential for visualizing network organization remains
untapped. In this work, we introduce an embryological approach, applying UMAP
to the susceptibility matrix to visualize the model's structural development
over training. Our visualizations reveal the emergence of a clear ``body
plan,'' charting the formation of known features like the induction circuit and
discovering previously unknown structures, such as a ``spacing fin'' dedicated
to counting space tokens. This work demonstrates that susceptibility analysis
can move beyond validation to uncover novel mechanisms, providing a powerful,
holistic lens for studying the developmental principles of complex neural
networks.

</details>


### [29] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
*Qilin Liao,Shuo Yang,Bo Zhao,Ping Luo,Hengshuang Zhao*

Main category: cs.LG

TL;DR: BOOD는 OOD 데이터 생성을 위한 새로운 프레임워크로, 결정 경계를 넘어서는 특징을 생성하여 OOD 탐지 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: OOD 탐지 성능을 높이기 위해, 잠재 공간에서 결정 경계 외부의 효과적인 특징을 추출하는 것이 필요합니다.

Method: BOOD는 ID 데이터셋에서 텍스트 조건 잠재 공간을 학습하고, 결정 경계에 가장 가까운 ID 특징을 선택하여 이를 교란시켜 OOD 특징으로 만듭니다.

Result: BOOD는 최신 기법에 비해 평균 FPR95에서 29.64% 감소하고, AUROC에서 7.27% 향상된 성능을 보입니다.

Conclusion: BOOD는 효과적인 OOD 특징 생성을 위한 더 효율적인 훈련 전략을 제공하여 ID와 OOD 데이터 간의 뚜렷한 구분을 촉진합니다.

Abstract: Harnessing the power of diffusion models to synthesize auxiliary training
data based on latent space features has proven effective in enhancing
out-of-distribution (OOD) detection performance. However, extracting effective
features outside the in-distribution (ID) boundary in latent space remains
challenging due to the difficulty of identifying decision boundaries between
classes. This paper proposes a novel framework called Boundary-based
Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD
features and generates human-compatible outlier images using diffusion models.
BOOD first learns a text-conditioned latent feature space from the ID dataset,
selects ID features closest to the decision boundary, and perturbs them to
cross the decision boundary to form OOD features. These synthetic OOD features
are then decoded into images in pixel space by a diffusion model. Compared to
previous works, BOOD provides a more training efficient strategy for
synthesizing informative OOD features, facilitating clearer distinctions
between ID and OOD data. Extensive experimental results on common benchmarks
demonstrate that BOOD surpasses the state-of-the-art method significantly,
achieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27%
improvement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.

</details>


### [30] [Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization](https://arxiv.org/abs/2508.00357)
*Yoonhyuk Choi,Jiho Choi,Chong-Kwon Kim*

Main category: cs.LG

TL;DR: SGPC라는 새로운 아키텍처를 도입하여 그래프 신경망의 오버 스무딩 문제를 해결하고 성능 경계를 이론적으로 확립하였다.


<details>
  <summary>Details</summary>
Motivation: 그래프 신경망에서의 오버 스무딩 문제는 이종 그래프에서 노드 특성이 사라지는 현상을 야기하며, 기존의 시프 모델들은 일반화 및 확장성에 있어서 한계를 보인다.

Method: SGPC는 세포-시프 메시지 전송과 최적 수송 기반 리프팅, 분산 감소 확산, PAC-Bayes 스펙트럼 정규화를 결합하여 강력한 준지도 노드 분류를 수행한다.

Result: SGPC는 아홉 개의 동질 및 이질 벤치마크에서 최첨단 스펙트럼 및 시프 기반 GNNs를 초과하는 성능을 발휘하며, 보이지 않는 노드에 대한 신뢰 구간을 인증할 수 있다.

Conclusion: SGPC는 선형 계산 복잡도로 end-to-end 학습을 통해 성능 경계를 달성할 수 있음을 입증하였다.

Abstract: Over-smoothing in Graph Neural Networks (GNNs) causes collapse in distinct
node features, particularly on heterophilic graphs where adjacent nodes often
have dissimilar labels. Although sheaf neural networks partially mitigate this
problem, they typically rely on static or heavily parameterized sheaf
structures that hinder generalization and scalability. Existing sheaf-based
models either predefine restriction maps or introduce excessive complexity, yet
fail to provide rigorous stability guarantees. In this paper, we introduce a
novel scheme called SGPC (Sheaf GNNs with PAC-Bayes Calibration), a unified
architecture that combines cellular-sheaf message passing with several
mechanisms, including optimal transport-based lifting, variance-reduced
diffusion, and PAC-Bayes spectral regularization for robust semi-supervised
node classification. We establish performance bounds theoretically and
demonstrate that the resulting bound-aware objective can be achieved via
end-to-end training in linear computational complexity. Experiments on nine
homophilic and heterophilic benchmarks show that SGPC outperforms
state-of-the-art spectral and sheaf-based GNNs while providing certified
confidence intervals on unseen nodes.

</details>


### [31] [OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions](https://arxiv.org/abs/2508.00364)
*Chanyoung Yoon,Sangbong Yoo,Soobin Yim,Chansoo Kim,Yun Jang*

Main category: cs.LG

TL;DR: OID-PPO는 최적의 내부 디자인을 위한 강화 학습 프레임워크로, 전문가의 가이드라인을 통합하여 효율적인 가구 배치를 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: 주거 공간 디자인이 거주자의 만족도에 큰 영향을 미치지만, 기존의 접근 방식들이 계산비용이 크거나 데이터 부족 문제에 직면해 있습니다.

Method: OID-PPO 프레임워크는 전문가 정의의 기능적 및 시각적 가이드라인을 통합한 보상 함수와 함께 연속적인 가구 배치를 위한 대각선 가우시안 정책을 사용합니다.

Result: OID-PPO는 다양한 방 형태와 가구 구성에서 레이아웃 품질 및 계산 효율성 측면에서 기존 최첨단 방법을 크게 초과 성과를 보였습니다.

Conclusion: OID-PPO는 효율적인 가구 배치를 위한 혁신적인 접근 방식으로, 디자인 원칙과 가이드라인 통합이 중요하다는 것을 강조합니다.

Abstract: Designing residential interiors strongly impacts occupant satisfaction but
remains challenging due to unstructured spatial layouts, high computational
demands, and reliance on expert knowledge. Existing methods based on
optimization or deep learning are either computationally expensive or
constrained by data scarcity. Reinforcement learning (RL) approaches often
limit furniture placement to discrete positions and fail to incorporate design
principles adequately. We propose OID-PPO, a novel RL framework for Optimal
Interior Design using Proximal Policy Optimization, which integrates
expert-defined functional and visual guidelines into a structured reward
function. OID-PPO utilizes a diagonal Gaussian policy for continuous and
flexible furniture placement, effectively exploring latent environmental
dynamics under partial observability. Experiments conducted across diverse room
shapes and furniture configurations demonstrate that OID-PPO significantly
outperforms state-of-the-art methods in terms of layout quality and
computational efficiency. Ablation studies further demonstrate the impact of
structured guideline integration and reveal the distinct contributions of
individual design constraints.

</details>


### [32] [Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions](https://arxiv.org/abs/2508.00392)
*Lijun Zhang,Wenhao Yang,Guanghui Wang,Wei Jiang,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 이 논문은 온라인 학습에서 변화하는 환경을 다루기 위해 새로운 성능 측정치인 적응적 후회를 제안하고, 유니버설 알고리즘을 통해 다양한 볼록 함수에 적용할 수 있는 알고리즘을 개발한다.


<details>
  <summary>Details</summary>
Motivation: 기존 알고리즘들은 하나의 유형의 볼록 함수만 처리할 수 있고, 매개변수에 대한 사전 지식이 필요하다.

Method: 듀얼 적응성을 가진 유니버설 알고리즘을 조사하고, 메타-전문가 프레임워크를 통해 여러 전문가를 동적으로 생성 및 집계한다.

Result: 제안된 알고리즘은 여러 유형의 볼록 함수에 대해 적응적 후회를 최소화할 수 있으며, 함수 유형이 라운드 간에 전환될 수 있다.

Conclusion: 메타-전문가 프레임워크를 온라인 복합 최적화로 확장하여 복합 함수의 적응적 후회를 최소화하는 유니버설 알고리즘을 개발했다.

Abstract: To deal with changing environments, a new performance measure -- adaptive
regret, defined as the maximum static regret over any interval, was proposed in
online learning. Under the setting of online convex optimization, several
algorithms have been successfully developed to minimize the adaptive regret.
However, existing algorithms lack universality in the sense that they can only
handle one type of convex functions and need apriori knowledge of parameters,
which hinders their application in real-world scenarios. To address this
limitation, this paper investigates universal algorithms with dual adaptivity,
which automatically adapt to the property of functions (convex, exponentially
concave, or strongly convex), as well as the nature of environments (stationary
or changing). Specifically, we propose a meta-expert framework for dual
adaptive algorithms, where multiple experts are created dynamically and
aggregated by a meta-algorithm. The meta-algorithm is required to yield a
second-order bound, which can accommodate unknown function types. We further
incorporate the technique of sleeping experts to capture the changing
environments. For the construction of experts, we introduce two strategies
(increasing the number of experts or enhancing the capabilities of experts) to
achieve universality. Theoretical analysis shows that our algorithms are able
to minimize the adaptive regret for multiple types of convex functions
simultaneously, and also allow the type of functions to switch between rounds.
Moreover, we extend our meta-expert framework to online composite optimization,
and develop a universal algorithm for minimizing the adaptive regret of
composite functions.

</details>


### [33] [ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs](https://arxiv.org/abs/2508.00394)
*Antonis Klironomos,Baifan Zhou,Zhipeng Tan,Zhuoxun Zheng,Mohamed H. Gad-Elrab,Heiko Paulheim,Evgeny Kharlamov*

Main category: cs.LG

TL;DR: ExeKGLib는 ML 지식이 없는 사용자도 머신 러닝 파이프라인을 구축할 수 있도록 지원하는 Python 라이브러리이다.


<details>
  <summary>Details</summary>
Motivation: 과학 및 공학 분야의 전문가들이 머신 러닝 기반의 분석을 긴급히 필요로 하지만, 이를 위한 ML 전문 지식과 훈련이 부족하다.

Method: 지식 그래프를 활용하여 ML 지식을 비전문가도 이해할 수 있는 형태로 제공하며, 직관적인 그래픽 인터페이스를 통해 파이프라인을 구축할 수 있게 한다.

Result: ExeKGLib를 사용하여 실제 사용 사례를 통해 그 유용성과 사용성을 입증하였다.

Conclusion: ExeKGLib는 파이프라인의 투명성과 재사용성을 향상시키고, 사용자들이 쉽게 실행 가능한 ML 워크플로우를 생성할 수 있게 지원한다.

Abstract: Nowadays machine learning (ML) practitioners have access to numerous ML
libraries available online. Such libraries can be used to create ML pipelines
that consist of a series of steps where each step may invoke up to several ML
libraries that are used for various data-driven analytical tasks. Development
of high-quality ML pipelines is non-trivial; it requires training, ML
expertise, and careful development of each step. At the same time, domain
experts in science and engineering may not possess such ML expertise and
training while they are in pressing need of ML-based analytics. In this paper,
we present our ExeKGLib, a Python library enhanced with a graphical interface
layer that allows users with minimal ML knowledge to build ML pipelines. This
is achieved by relying on knowledge graphs that encode ML knowledge in simple
terms accessible to non-ML experts. ExeKGLib also allows improving the
transparency and reusability of the built ML workflows and ensures that they
are executable. We show the usability and usefulness of ExeKGLib by presenting
real use cases.

</details>


### [34] [Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement](https://arxiv.org/abs/2508.00410)
*Zizhuo Zhang,Jianing Zhu,Xinmu Ge,Zihua Zhao,Zhanke Zhou,Xuan Li,Xiao Feng,Jiangchao Yao,Bo Han*

Main category: cs.LG

TL;DR: RLVR은 LLM의 추론 능력을 개선하는 데 유망하지만, 인간 주석 레이블에 의존하여 규모 확장의 딜레마가 있다. 이를 해결하기 위해 'Co-Reward'라는 새로운 RL 프레임워크를 제안하며, 자가 지도 학습의 성공에 영감을 받아 유사한 질문 간의 대조적 일치를 보상 기반으로 활용한다.


<details>
  <summary>Details</summary>
Motivation: RLVR의 한계를 극복하고 LLM의 추론 능력을 보다 안정적으로 향상시키기 위해 새로운 방법론이 필요하다.

Method: 대조적 질문 두 쌍을 구성하고, 각 질문의 대리 레이블을 생성하여 상호 참조를 통해 보상을 구성하는 자가 지도 보상 형성 메커니즘을 도입한다.

Result: Co-Reward는 여러 추론 벤치마크에서 다른 자가 보상 기준선보다 더 우수한 성능을 달성하고, MATH500에서 GT 보상 대비 최대 6.8% 개선된 성과를 기록했다.

Conclusion: Co-Reward는 LLM의 효과적인 추론 능력 개선에 기여하며, 자가 지도 보상을 통해 적응형 학습이 가능하다는 것을 보여준다.

Abstract: Although reinforcement learning with verifiable rewards (RLVR) shows promise
in improving the reasoning ability of large language models (LLMs), the scaling
up dilemma remains due to the reliance on human annotated labels especially for
complex tasks. Recent alternatives that explore various self-reward signals
exhibit the eliciting potential of LLM reasoning, but suffer from the
non-negligible collapse issue. Inspired by the success of self-supervised
learning, we propose \textit{Co-Reward}, a novel RL framework that leverages
contrastive agreement across semantically analogical questions as a reward
basis. Specifically, we construct a similar question for each training sample
(without labels) and synthesize their individual surrogate labels through a
simple rollout voting, and then the reward is constructed by cross-referring
the labels of each question pair to enforce the internal reasoning consistency
across analogical inputs. Intuitively, such a self-supervised reward-shaping
mechanism increases the difficulty of learning collapse into a trivial
solution, and promotes stable reasoning elicitation and improvement through
expanding the input sample variants. Empirically, Co-Reward achieves superior
performance compared to other self-reward baselines on multiple reasoning
benchmarks and LLM series, and reaches or even surpasses ground-truth (GT)
labeled reward, with improvements of up to $+6.8\%$ on MATH500 over GT reward
on Llama-3.2-3B-Instruct. Our code is publicly available at
https://github.com/tmlr-group/Co-Reward.

</details>


### [35] [Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection](https://arxiv.org/abs/2508.00415)
*Yue Yang,Yuxiang Lin,Ying Zhang,Zihan Su,Chang Chuan Goh,Tangtangfang Fang,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: ResE-BiLSTM 모델을 활용한 대출 후 디폴트 예측 연구로, 기계 학습을 통해 금융 이상 탐지에 초점을 맞춤.


<details>
  <summary>Details</summary>
Motivation: 신용 위험 관리에서 대출 후 디폴트 예측은 중요하며, 기계 학습을 통해 금융 이상을 탐지하는 것이 필요하다.

Method: 슬라이딩 윈도우 기법을 사용한 ResE-BiLSTM 모델을 적용하고, 다양한 기초 모델과 비교하여 성능을 평가하였다.

Result: ResE-BiLSTM은 정확도, 정밀도, 재현율, F1 점수, AUC 등에서 기초 모델보다 우수한 예측 성능을 보였다.

Conclusion: ResE-BiLSTM 모델은 실제 상황에서의 유용성을 강조하며, 신용 위험 관리에 중요한 가치를 지닌다.

Abstract: Prediction of post-loan default is an important task in credit risk
management, and can be addressed by detection of financial anomalies using
machine learning. This study introduces a ResE-BiLSTM model, using a sliding
window technique, and is evaluated on 44 independent cohorts from the extensive
Freddie Mac US mortgage dataset, to improve prediction performance. The
ResE-BiLSTM is compared with five baseline models: Long Short-Term Memory
(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks
(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including
Accuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to
evaluate the contribution of individual components in the ResE-BiLSTM
architecture. Additionally, SHAP analysis was employed to interpret the
underlying features the model relied upon for its predictions. Experimental
results demonstrate that ResE-BiLSTM achieves superior predictive performance
compared to baseline models, underscoring its practical value and applicability
in real-world scenarios.

</details>


### [36] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: ctdGAN은 불균형 테이블 데이터셋에서 클래스 불균형을 해결하기 위한 조건부 GAN 모델로, 데이터 생성의 로케이션을 최적화하고 클래스 라벨을 효과적으로 활용한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 작업에서 클래스 불균형으로 인한 성능 저하 문제를 해결하기 위해 더 나은 데이터 생성 방법이 필요하다.

Method: ctdGAN은 입력 샘플에 클러스터 라벨을 부여한 후, 새로운 확률적 샘플링 전략과 손실 함수를 통해 데이터 하위 공간에서 샘플을 생성한다.

Result: 14개의 불균형 데이터셋에서 ctdGAN은 높은 품질의 샘플을 생성하고 분류 정확도를 개선하였다.

Conclusion: ctdGAN은 기존 GAN 모델들보다 더 효과적으로 클래스 불균형 문제를 해결하며, 데이터의 원래 분포와 유사한 샘플을 생성한다.

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>


### [37] [Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection](https://arxiv.org/abs/2508.00507)
*Yiming Xu,Jiarun Chen,Zhen Peng,Zihan Chen,Qika Lin,Lan Ma,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: 이 논문에서는 텍스트 속성 그래프에서의 이상 탐지를 위한 CoLL라는 새로운 프레임워크를 제안하며, 대형 언어 모델과 그래프 신경망을 결합하여 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 텍스트 속성 그래프에서의 이상 탐지에서 텍스트 모달리티의 가치를 무시하는 기존 방법의 한계를 극복하고, 이상과 관련된 맥락을 포착하고자 합니다.

Method: CoLL 프레임워크는 멀티-LM 협업을 통해 증거보강 생성을 수행하고, 그래프 신경망과 게이팅 메커니즘을 결합하여 텍스트 특징과 증거를 적응적으로 융합합니다.

Result: CoLL은 평균 13.37%의 AP 향상 성과를 보여주어 기존 방법들보다 우수함을 입증했습니다.

Conclusion: 이 연구는 이상 탐지에 대한 대형 언어 모델의 적용 가능성을 넓히고, 그래프 이상 탐지 분야에서의 새로운 접근 방식을 제시합니다.

Abstract: The natural combination of intricate topological structures and rich textual
information in text-attributed graphs (TAGs) opens up a novel perspective for
graph anomaly detection (GAD). However, existing GAD methods primarily focus on
designing complex optimization objectives within the graph domain, overlooking
the complementary value of the textual modality, whose features are often
encoded by shallow embedding techniques, such as bag-of-words or skip-gram, so
that semantic context related to anomalies may be missed. To unleash the
enormous potential of textual modality, large language models (LLMs) have
emerged as promising alternatives due to their strong semantic understanding
and reasoning capabilities. Nevertheless, their application to TAG anomaly
detection remains nascent, and they struggle to encode high-order structural
information inherent in graphs due to input length constraints. For
high-quality anomaly detection in TAGs, we propose CoLL, a novel framework that
combines LLMs and graph neural networks (GNNs) to leverage their complementary
strengths. CoLL employs multi-LLM collaboration for evidence-augmented
generation to capture anomaly-relevant contexts while delivering human-readable
rationales for detected anomalies. Moreover, CoLL integrates a GNN equipped
with a gating mechanism to adaptively fuse textual features with evidence while
preserving high-order topological information. Extensive experiments
demonstrate the superiority of CoLL, achieving an average improvement of 13.37%
in AP. This study opens a new avenue for incorporating LLMs in advancing GAD.

</details>


### [38] [Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning](https://arxiv.org/abs/2508.00513)
*Yiming Xu,Xu Hua,Zhen Peng,Bin Shi,Jiarun Chen,Xingbo Fu,Song Wang,Bo Dong*

Main category: cs.LG

TL;DR: 본 연구는 텍스트 속성을 가진 그래프의 이상 탐지를 위한 새로운 종단 간 접근 방식인 CMUCL을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제 그래프는 종종 원시 텍스트 시퀀스로 된 노드 설명을 가지고 있어, 이를 효과적으로 활용하는 이상 탐지 기법이 필요하다.

Method: 텍스트와 그래프 구조로부터 데이터를 동시에 모델링하고, 크로스 모달 및 유니 모달 일관성을 활용하여 텍스트 및 그래프 인코더를 공동으로 훈련한다.

Result: CMUCL은 텍스트 속성 그래프 이상 탐지에서 평균 정확도를 11.13% 향상시키며 성능을 크게 개선한다.

Conclusion: CMUCL은 텍스트 속성 그래프의 이상 탐지에 있어 효과적인 방법을 제시하며, 향후 연구를 위한 8개의 벤치마크 데이터셋도 공개하였다.

Abstract: The widespread application of graph data in various high-risk scenarios has
increased attention to graph anomaly detection (GAD). Faced with real-world
graphs that often carry node descriptions in the form of raw text sequences,
termed text-attributed graphs (TAGs), existing graph anomaly detection
pipelines typically involve shallow embedding techniques to encode such textual
information into features, and then rely on complex self-supervised tasks
within the graph domain to detect anomalies. However, this text encoding
process is separated from the anomaly detection training objective in the graph
domain, making it difficult to ensure that the extracted textual features focus
on GAD-relevant information, seriously constraining the detection capability.
How to seamlessly integrate raw text and graph topology to unleash the vast
potential of cross-modal data in TAGs for anomaly detection poses a challenging
issue. This paper presents a novel end-to-end paradigm for text-attributed
graph anomaly detection, named CMUCL. We simultaneously model data from both
text and graph structures, and jointly train text and graph encoders by
leveraging cross-modal and uni-modal multi-scale consistency to uncover
potential anomaly-related information. Accordingly, we design an anomaly score
estimator based on inconsistency mining to derive node-specific anomaly scores.
Considering the lack of benchmark datasets tailored for anomaly detection on
TAGs, we release 8 datasets to facilitate future research. Extensive
evaluations show that CMUCL significantly advances in text-attributed graph
anomaly detection, delivering an 11.13% increase in average accuracy (AP) over
the suboptimal.

</details>


### [39] [Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting](https://arxiv.org/abs/2508.00523)
*Sifan Yang,Yuanyu Wan,Lijun Zhang*

Main category: cs.LG

TL;DR: 온라인 비서브모듈 최적화에서 지연 피드백을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 이 논문은 지연에 민감한 기존의 후회 경계 한계를 개선하기 위해서이다.

Method: 두 가지 알고리즘(DBGD-NF와 블로킹 업데이트 메커니즘)을 개발하여 지연과 밴딧 피드백의 영향을 분리하고 평균 지연을 바탕으로 개선된 후회 경계를 설정한다.

Result: 첫 번째 방법은 $eta$-약한 DR-슈퍼모듈러 및 $eta$-약한 DR-서브모듈러에 대한 향상된 후회 경계를 제공한다.

Conclusion: 제안하는 방법이 구조적 희소 학습에서 성능이 우수함을 실험으로 입증하였다.

Abstract: We investigate the online nonsubmodular optimization with delayed feedback in
the bandit setting, where the loss function is $\alpha$-weakly DR-submodular
and $\beta$-weakly DR-supermodular. Previous work has established an
$(\alpha,\beta)$-regret bound of $\mathcal{O}(nd^{1/3}T^{2/3})$, where $n$ is
the dimensionality and $d$ is the maximum delay. However, its regret bound
relies on the maximum delay and is thus sensitive to irregular delays.
Additionally, it couples the effects of delays and bandit feedback as its bound
is the product of the delay term and the $\mathcal{O}(nT^{2/3})$ regret bound
in the bandit setting without delayed feedback. In this paper, we develop two
algorithms to address these limitations, respectively. Firstly, we propose a
novel method, namely DBGD-NF, which employs the one-point gradient estimator
and utilizes all the available estimated gradients in each round to update the
decision. It achieves a better $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ regret
bound, which is relevant to the average delay $\bar{d} =
\frac{1}{T}\sum_{t=1}^T d_t\leq d$. Secondly, we extend DBGD-NF by employing a
blocking update mechanism to decouple the joint effect of the delays and bandit
feedback, which enjoys an $\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$ regret bound.
When $d = \mathcal{O}(T^{1/3})$, our regret bound matches the
$\mathcal{O}(nT^{2/3})$ bound in the bandit setting without delayed feedback.
Compared to our first $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ bound, it is more
advantageous when the maximum delay $d = o(\bar{d}^{2/3}T^{1/3})$. Finally, we
conduct experiments on structured sparse learning to demonstrate the
superiority of our methods.

</details>


### [40] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
*Judy X Yang*

Main category: cs.LG

TL;DR: 이 연구는 Cuprite 광산 지역에서 약한 광물 탐지를 향상시키기 위한 두 단계 통합 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 광물 매핑을 위한 고해상도 스펙트럼 정보를 제공하는 하이퍼스펙트럼 이미징의 성능이 저조한 스펙트럼 노이즈와 중복으로 제한되기 때문에, 이를 개선하려는 필요성이 있다.

Method: 첫 단계에서 각 스펙트럼 밴드의 신호대잡음비(SNR)를 계산하고 낮은 SNR 밴드를 제거하여 스펙트럼을 정제한 후, 두 번째 단계에서는 KMeans 클러스터링과 비음수 최소제곱(NNLS) 기법을 이용해 혼합물의 관측값을 추출한다.

Result: 실험 결과, 제안된 파이프라인이 혼합 분석의 정확성을 개선하고 약한 광물 구역의 탐지를 향상시킨다는 것이 입증되었다.

Conclusion: 이 두 단계 접근 방식은 지질학적 HSI 응용에서 스펙트럼 차원 축소 및 분리가 가능한 실용적이며 재현 가능한 솔루션을 제시한다.

Abstract: Hyperspectral imaging offers detailed spectral information for mineral
mapping; however, weak mineral signatures are often masked by noisy and
redundant bands, limiting detection performance. To address this, we propose a
two-stage integrated framework for enhanced mineral detection in the Cuprite
mining district. In the first stage, we compute the signal-to-noise ratio (SNR)
for each spectral band and apply a phase-locked thresholding technique to
discard low-SNR bands, effectively removing redundancy and suppressing
background noise. Savitzky-Golay filtering is then employed for spectral
smoothing, serving a dual role first to stabilize trends during band selection,
and second to preserve fine-grained spectral features during preprocessing. In
the second stage, the refined HSI data is reintroduced into the model, where
KMeans clustering is used to extract 12 endmember spectra (W1 custom), followed
by non negative least squares (NNLS) for abundance unmixing. The resulting
endmembers are quantitatively compared with laboratory spectra (W1 raw) using
cosine similarity and RMSE metrics. Experimental results confirm that our
proposed pipeline improves unmixing accuracy and enhances the detection of weak
mineral zones. This two-pass strategy demonstrates a practical and reproducible
solution for spectral dimensionality reduction and unmixing in geological HSI
applications.

</details>


### [41] [Foundations of Interpretable Models](https://arxiv.org/abs/2508.00545)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Alberto Termine,Mateja Jamnik,Giuseppe Marra*

Main category: cs.LG

TL;DR: 기존의 해석 가능성 정의가 실용적이지 않음을 주장하며, 새로운 해석 가능성 정의를 제안하고 이를 구현하기 위한 블루프린트와 라이브러리를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 기존 해석 가능성 연구가 사용자의 요구를 충족하지 못해 실질적이지 않음을 해소하고자 한다.

Method: 해석 가능성의 새로운 정의를 제안하고, 이를 충족하기 위한 설계 원칙 및 데이터 구조를 명시한다.

Result: 제안한 정의가 실용적이며, 해석 가능한 모델 설계를 위한 기초적인 속성과 원리를 드러낸다.

Conclusion: 해석 가능한 모델 설계를 위한 일반적인 블루프린트를 제시하고, 이를 지원하는 오픈 소스 라이브러리를 처음으로 소개한다.

Abstract: We argue that existing definitions of interpretability are not actionable in
that they fail to inform users about general, sound, and robust interpretable
model design. This makes current interpretability research fundamentally
ill-posed. To address this issue, we propose a definition of interpretability
that is general, simple, and subsumes existing informal notions within the
interpretable AI community. We show that our definition is actionable, as it
directly reveals the foundational properties, underlying assumptions,
principles, data structures, and architectural features necessary for designing
interpretable models. Building on this, we propose a general blueprint for
designing interpretable models and introduce the first open-sourced library
with native support for interpretable data structures and processes.

</details>


### [42] [Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides](https://arxiv.org/abs/2508.00578)
*Marlen Neubert,Patrick Reiser,Frauke Gräter,Pascal Friederich*

Main category: cs.LG

TL;DR: 본 연구는 수소 원자 이동(HAT) 반응을 정확하게 모사하기 위한 기계 학습 기반 포텐셜을 개발하고, 다양한 HAT 구성에서의 모델 성능을 평가하여, 고급 분자 시뮬레이션을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: HAT 반응은 생물학적 과정에서 중요하지만 그 메커니즘은 불완전하게 이해되고 있다.

Method: HAT 구성 생성을 위해 반응성 데이터세트를 구축하고, 세 가지 그래프 신경망 아키텍처(SchNet, Allegro, MACE)를 평가하여 HAT 포텐셜 에너지 표면(PES)을 학습한다.

Result: MACE 모델이 에너지, 힘 및 장벽 예측에서 지속적으로 최고 성능을 보이며, 평균 절대 오차가 1.13 kcal/mol로 상세한 예측을 제공한다.

Conclusion: 이 정확도를 통해 ML 포텐셜을 대규모 콜라겐 시뮬레이션에 통합 가능하며, HAT 및 펩타이드에서의 화학 반응성에 대한 양자 정확한 시뮬레이션을 가능하게 한다.

Abstract: Hydrogen atom transfer (HAT) reactions are essential in many biological
processes, such as radical migration in damaged proteins, but their mechanistic
pathways remain incompletely understood. Simulating HAT is challenging due to
the need for quantum chemical accuracy at biologically relevant scales; thus,
neither classical force fields nor DFT-based molecular dynamics are applicable.
Machine-learned potentials offer an alternative, able to learn potential energy
surfaces (PESs) with near-quantum accuracy. However, training these models to
generalize across diverse HAT configurations, especially at radical positions
in proteins, requires tailored data generation and careful model selection.
Here, we systematically generate HAT configurations in peptides to build large
datasets using semiempirical methods and DFT. We benchmark three graph neural
network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT
PESs and indirectly predict reaction barriers from energy predictions. MACE
consistently outperforms the others in energy, force, and barrier prediction,
achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT
barrier predictions. This accuracy enables integration of ML potentials into
large-scale collagen simulations to compute reaction rates from predicted
barriers, advancing mechanistic understanding of HAT and radical migration in
peptides. We analyze scaling laws, model transferability, and cost-performance
trade-offs, and outline strategies for improvement by combining ML potentials
with transition state search algorithms and active learning. Our approach is
generalizable to other biomolecular systems, enabling quantum-accurate
simulations of chemical reactivity in complex environments.

</details>


### [43] [The Role of Active Learning in Modern Machine Learning](https://arxiv.org/abs/2508.00586)
*Thorben Werner,Lars Schmidt-Thieme,Vijaya Krishna Yalavarthi*

Main category: cs.LG

TL;DR: 활성 학습(AL)은 높은 계산 비용과 적은 레이블 포인트에서의 효율성 부족으로 인해 적용이 제한된다. 하지만, 강력한 데이터 증대(DA) 및 반 감독 학습(SSL)과 결합할 경우 성능 향상을 가져올 수 있다.


<details>
  <summary>Details</summary>
Motivation: AL의 연구가 활발하지만 실제 응용이 드문 이유는 높은 계산 비용과 적은 레이블 포인트에서의 낮은 효율성에 있다.

Method: 데이터 증대(DA), 반 감독 학습(SSL), 활성 학습(AL)의 다양한 방법을 비교하고 조합하여 저데이터 문제 해결 효율성을 분석하였다.

Result: AL은 무작위 샘플링 대비 1-4% 향상에 그치는 비효율적인 방법이며, DA와 SSL 방법은 최대 60% 향상 가능하다. 그러나 강력한 DA 및 SSL 기법과 결합할 경우 AL도 향상을 제공한다.

Conclusion: AL은 결측 레이블을 해결하는 방법이 아니라, 적절한 DA 및 SSL 방법을 적용한 후 최종 성능 향상을 위한 마지막 보강 요소로 보아야 한다.

Abstract: Even though Active Learning (AL) is widely studied, it is rarely applied in
contexts outside its own scientific literature. We posit that the reason for
this is AL's high computational cost coupled with the comparatively small lifts
it is typically able to generate in scenarios with few labeled points. In this
work we study the impact of different methods to combat this low data scenario,
namely data augmentation (DA), semi-supervised learning (SSL) and AL. We find
that AL is by far the least efficient method of solving the low data problem,
generating a lift of only 1-4\% over random sampling, while DA and SSL methods
can generate up to 60\% lift in combination with random sampling. However, when
AL is combined with strong DA and SSL techniques, it surprisingly is still able
to provide improvements. Based on these results, we frame AL not as a method to
combat missing labels, but as the final building block to squeeze the last bits
of performance out of data after appropriate DA and SSL methods as been
applied.

</details>


### [44] [Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data](https://arxiv.org/abs/2508.00615)
*Mukesh Kumar Sahu,Pinki Roy*

Main category: cs.LG

TL;DR: ICU 환자의 중증도를 정확하게 예측하기 위한 SBSCGM 모델과 HybridGraphMedGNN 아키텍처를 제안하여 성능을 향상시킴.


<details>
  <summary>Details</summary>
Motivation: ICU 환자의 사망 위험을 조기에 파악하여 신속한 개입이 필요함.

Method: 다양한 EHR 데이터를 기반으로 환자 유사성 그래프를 동적으로 구축하고, 이를 통해 환자 사망 및 중증도 점수를 예측하는 SBSCGM 모델과 HybridGraphMedGNN 아키텍처를 사용함.

Result: MIMIC-III 데이터셋에서 6,000건의 ICU 사례를 실험하여 AUC-ROC 0.94를 달성하며, 기존 분류기 및 단일 GNN 모델보다 뛰어난 성능을 보임.

Conclusion: 이 프레임워크는 초간단한 해석 가능성과 확장성을 제공하여 임상에서의 위험 예측에 도움을 줄 수 있음.

Abstract: Accurately predicting the criticalness of ICU patients (such as in-ICU
mortality risk) is vital for early intervention in critical care. However,
conventional models often treat each patient in isolation and struggle to
exploit the relational structure in Electronic Health Records (EHR). We propose
a Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds
a patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN
architecture that operates on this graph to predict patient mortality and a
continuous criticalness score. SBSCGM uses a hybrid similarity measure
(combining feature-based and structural similarities) to connect patients with
analogous clinical profiles in real-time. The HybridGraphMedGNN integrates
Graph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)
layers to learn robust patient representations, leveraging both local and
global graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III
dataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)
outperforming baseline classifiers and single-type GNN models. We also
demonstrate improved precision/recall and show that the attention mechanism
provides interpretable insights into model predictions. Our framework offers a
scalable and interpretable solution for critical care risk prediction, with
potential to support clinicians in real-world ICU deployment.

</details>


### [45] [IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources](https://arxiv.org/abs/2508.00627)
*Paul Tresson,Pierre Le Coz,Hadrien Tulet,Anthony Malkassian,Maxime Réjou Méchain*

Main category: cs.LG

TL;DR: IAMAP은 비전문가가 딥러닝을 활용할 수 있도록 돕는 QGIS 플러그인이다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 접근법의 활용이 제한적이며 많은 데이터와 컴퓨팅 자원, 코딩 기술이 필요하다.

Method: IAMAP는 최근의 자기 감독 학습 전략을 바탕으로 하여 사용자 친화적인 인터페이스를 제공한다.

Result: IAMAP은 이미지 특징 추출, 차원 축소, 클러스터링, 유사성 맵 생성, 머신러닝 모델의 검증 등을 지원한다.

Conclusion: IAMAP는 비전문가도 효율적이고 에너지 절약적인 딥러닝 방법을 사용할 수 있도록 기여한다.

Abstract: Remote sensing has entered a new era with the rapid development of artificial
intelligence approaches. However, the implementation of deep learning has
largely remained restricted to specialists and has been impractical because it
often requires (i) large reference datasets for model training and validation;
(ii) substantial computing resources; and (iii) strong coding skills. Here, we
introduce IAMAP, a user-friendly QGIS plugin that addresses these three
challenges in an easy yet flexible way. IAMAP builds on recent advancements in
self-supervised learning strategies, which now provide robust feature
extractors, often referred to as foundation models. These generalist models can
often be reliably used in few-shot or zero-shot scenarios (i.e., with little to
no fine-tuning). IAMAP's interface allows users to streamline several key steps
in remote sensing image analysis: (i) extracting image features using a wide
range of deep learning architectures; (ii) reducing dimensionality with
built-in algorithms; (iii) performing clustering on features or their reduced
representations; (iv) generating feature similarity maps; and (v) calibrating
and validating supervised machine learning models for prediction. By enabling
non-AI specialists to leverage the high-quality features provided by recent
deep learning approaches without requiring GPU capacity or extensive reference
datasets, IAMAP contributes to the democratization of computationally efficient
and energy-conscious deep learning methods.

</details>


### [46] [Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs](https://arxiv.org/abs/2508.00628)
*Xiong Xiong,Zhuo Zhang,Rongchun Hu,Chen Gao,Zichen Deng*

Main category: cs.LG

TL;DR: SV-SNN은 고주파 진동 편미분 방정식의 문제를 해결하기 위한 새로운 프레임워크로, 전통적인 피지컬 정보 신경망의 한계를 극복하여 정확도와 효율성을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 고주파 진동 편미분 방정식을 해결하는 것은 과학 계산에서 중요한 도전 과제이며, 전통적인 PINNs는 스펙트럼 편향으로 인해 효과적이지 않다.

Method: SV-SNN은 변수 분리를 이용한 독립적인 공간 및 시간 네트워크와 학습 가능한 주파수 매개변수를 통한 적응적인 푸리에 스펙트럼 특징을 통합합니다.

Result: SV-SNN은 다양한 기준 문제에서 정확도가 1-3배 향상되었고, 매개변수 수가 90% 이상 감소하며 훈련 시간도 60% 줄어들었다.

Conclusion: SV-SNN은 신경망을 이용한 PDE 해결에서 스펙트럼 편향 문제를 효과적으로 해결하는 솔루션으로 자리 잡았다.

Abstract: Solving high-frequency oscillatory partial differential equations (PDEs) is a
critical challenge in scientific computing, with applications in fluid
mechanics, quantum mechanics, and electromagnetic wave propagation. Traditional
physics-informed neural networks (PINNs) suffer from spectral bias, limiting
their ability to capture high-frequency solution components. We introduce
Separated-Variable Spectral Neural Networks (SV-SNN), a novel framework that
addresses these limitations by integrating separation of variables with
adaptive spectral methods. Our approach features three key innovations: (1)
decomposition of multivariate functions into univariate function products,
enabling independent spatial and temporal networks; (2) adaptive Fourier
spectral features with learnable frequency parameters for high-frequency
capture; and (3) theoretical framework based on singular value decomposition to
quantify spectral bias. Comprehensive evaluation on benchmark problems
including Heat equation, Helmholtz equation, Poisson equations and
Navier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of
magnitude improvement in accuracy while reducing parameter count by over 90\%
and training time by 60\%. These results establish SV-SNN as an effective
solution to the spectral bias problem in neural PDE solving. The implementation
will be made publicly available upon acceptance at
https://github.com/xgxgnpu/SV-SNN.

</details>


### [47] [KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting](https://arxiv.org/abs/2508.00635)
*Changning Wu,Gao Wu,Rongyao Cai,Yong Liu,Kexin Zhang*

Main category: cs.LG

TL;DR: 본 연구는 다중 스케일 분해 아키텍처의 성능을 향상시키기 위한 KAN 기반의 적응형 주파수 선택 학습 아키텍처(KFS)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제 시계열 데이터는 다양한 스케일에서 잡음 간섭과 동질적이지 않은 정보 분포 문제를 가지고 있다.

Method: KFS는 FreK 모듈을 사용하여 스펙트럼 영역에서 주요 주파수를 선택하고, KAN을 통해 복잡한 패턴 표현을 수행하며, 시간 정보 정렬을 통해 다양한 스케일 간의 임베딩을 동기화한다.

Result: 다양한 실제 시계열 데이터셋에서 KT는 최첨단 성능을 달성하며 간단하면서도 효과적인 아키텍처로 입증되었다.

Conclusion: KFS는 다중 스케일 시계열 예측에서 잡음 간섭과 복잡한 패턴 모델링 문제를 효과적으로 해결한다.

Abstract: Multi-scale decomposition architectures have emerged as predominant
methodologies in time series forecasting. However, real-world time series
exhibit noise interference across different scales, while heterogeneous
information distribution among frequency components at varying scales leads to
suboptimal multi-scale representation. Inspired by Kolmogorov-Arnold Networks
(KAN) and Parseval's theorem, we propose a KAN based adaptive Frequency
Selection learning architecture (KFS) to address these challenges. This
framework tackles prediction challenges stemming from cross-scale noise
interference and complex pattern modeling through its FreK module, which
performs energy-distribution-based dominant frequency selection in the spectral
domain. Simultaneously, KAN enables sophisticated pattern representation while
timestamp embedding alignment synchronizes temporal representations across
scales. The feature mixing module then fuses scale-specific patterns with
aligned temporal features. Extensive experiments across multiple real-world
time series datasets demonstrate that KT achieves state-of-the-art performance
as a simple yet effective architecture.

</details>


### [48] [Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense](https://arxiv.org/abs/2508.00641)
*Alessandro Palmas*

Main category: cs.LG

TL;DR: 강화 학습을 활용하여 저비용 카미카제 드론 무리의 방어를 최적화하는 연구.


<details>
  <summary>Details</summary>
Motivation: 저비용 카미카제 드론의 증가가 현대 방어 시스템에 위협을 주고 있으며, 효율적인 의사결정이 필요함.

Method: 고충실도의 시뮬레이션 환경에서 강화 학습 에이전트가 여러 효과기와의 최적 방어를 위한 의사결정 학습.

Result: 학습된 정책이 수작업 방식보다 평균 피해를 줄이고 방어 효율성을 높임.

Conclusion: 강화 학습이 방어 구조 내에서 전략적 계층으로서의 잠재력을 강조하며, 기존 제어 시스템을 대체하지 않음.

Abstract: The growing threat of low-cost kamikaze drone swarms poses a critical
challenge to modern defense systems demanding rapid and strategic
decision-making to prioritize interceptions across multiple effectors and
high-value target zones. In this work, we present a case study demonstrating
the practical advantages of reinforcement learning in addressing this
challenge. We introduce a high-fidelity simulation environment that captures
realistic operational constraints, within which a decision-level reinforcement
learning agent learns to coordinate multiple effectors for optimal interception
prioritization. Operating in a discrete action space, the agent selects which
drone to engage per effector based on observed state features such as
positions, classes, and effector status. We evaluate the learned policy against
a handcrafted rule-based baseline across hundreds of simulated attack
scenarios. The reinforcement learning based policy consistently achieves lower
average damage and higher defensive efficiency in protecting critical zones.
This case study highlights the potential of reinforcement learning as a
strategic layer within defense architectures, enhancing resilience without
displacing existing control systems. All code and simulation assets are
publicly released for full reproducibility, and a video demonstration
illustrates the policy's qualitative behavior.

</details>


### [49] [Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators](https://arxiv.org/abs/2508.00643)
*Albert Matveev,Sanmitra Ghosh,Aamal Hussain,James-Michael Leahy,Michalis Michaelides*

Main category: cs.LG

TL;DR: DINOZAUR는 불확실성을 정량화하는 확산 기반 신경 연산자 파라메트리제이션으로, FNO의 과도한 파라미터 수 문제를 해결하고 예측 성능을 유지하며 효율적인 불확실성 정량화를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 부분 미분 방정식을 푸는 데 있어 신뢰할 수 있는 과학 및 공학 응용을 위해서 불확실성 정량화가 중요하지만 기존의 FNO는 이 능력을 내장하지 않고 있다.

Method: DINOZAUR는 데센스 텐서 승수를 확산 승수로 대체하고 단일 학습 가능한 시간 파라미터를 사용하여 수치적 파라미터 수와 메모리 사용량을 크게 줄인다.

Result: 우리의 방법은 여러 PDE 벤치마크에서 경쟁력 있는 또는 우수한 성능을 달성하며 효율적인 불확실성 정량화를 제공한다.

Conclusion: DINOZAUR는 공간적으로 상관관계가 있는 출력과 보정된 불확실성 추정을 제공하는 베이지안 신경 연산자로 자리매김한다.

Abstract: Operator learning is a powerful paradigm for solving partial differential
equations, with Fourier Neural Operators serving as a widely adopted
foundation. However, FNOs face significant scalability challenges due to
overparameterization and offer no native uncertainty quantification -- a key
requirement for reliable scientific and engineering applications. Instead,
neural operators rely on post hoc UQ methods that ignore geometric inductive
biases. In this work, we introduce DINOZAUR: a diffusion-based neural operator
parametrization with uncertainty quantification. Inspired by the structure of
the heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a
dimensionality-independent diffusion multiplier that has a single learnable
time parameter per channel, drastically reducing parameter count and memory
footprint without compromising predictive performance. By defining priors over
those time parameters, we cast DINOZAUR as a Bayesian neural operator to yield
spatially correlated outputs and calibrated uncertainty estimates. Our method
achieves competitive or superior performance across several PDE benchmarks
while providing efficient uncertainty quantification.

</details>


### [50] [Efficient Solution and Learning of Robust Factored MDPs](https://arxiv.org/abs/2508.00707)
*Yannik Schnitzer,Alessandro Abate,David Parker*

Main category: cs.LG

TL;DR: 본 논문에서는 안정적인 마르코프 결정 프로세스(r-MDP)를 학습하는 새로운 방법을 제안하고 비율적 상태 공간 표현을 기반으로 한 정책 합성에서의 효율성을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 불확실한 환경에서의 r-MDP 학습을 통해 성능에 대한 증명된 보장과 함께 강력한 정책을 합성할 수 있도록 하기 위함.

Method: 상태 공간 표현을 분해하여 시스템 구성 요소 간의 모델 불확실성 독립성을 활용하고, 이를 통해 비선형 최적화 문제를 선형 프로그램으로 재구성하는 방법을 제안.

Result: 신뢰할 수 있는 정책을 생성하였으며, 상태 대표 방법에 비해 샘플 효율성이 향상되었다.

Conclusion: 분해된 구조를 활용함으로써 샘플 효율성이 향상되고, 최신 방법들보다 더 효과적인 강력한 정책을 생성할 수 있음을 실험적으로 입증하였다.

Abstract: Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling
epistemic uncertainty about transition dynamics. Learning r-MDPs from
interactions with an unknown environment enables the synthesis of robust
policies with provable (PAC) guarantees on performance, but this can require a
large number of sample interactions. We propose novel methods for solving and
learning r-MDPs based on factored state-space representations that leverage the
independence between model uncertainty across system components. Although
policy synthesis for factored r-MDPs leads to hard, non-convex optimisation
problems, we show how to reformulate these into tractable linear programs.
Building on these, we also propose methods to learn factored model
representations directly. Our experimental results show that exploiting
factored structure can yield dimensional gains in sample efficiency, producing
more effective robust policies with tighter performance guarantees than
state-of-the-art methods.

</details>


### [51] [TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction](https://arxiv.org/abs/2508.00657)
*Sihang Zeng,Lucas Jing Liu,Jun Wen,Meliha Yetisgen,Ruth Etzioni,Gang Luo*

Main category: cs.LG

TL;DR: TrajSurv는 전자 건강 기록(EHR) 데이터를 활용하여 신뢰할 수 있는 생존 예측을 위한 모델로, 임상 진행 과정을 명확히 설명하고자 함.


<details>
  <summary>Details</summary>
Motivation: 정확한 생존 예측은 임상 의사결정에 중요하며, 그러나 비정기적으로 샘플링된 임상 특성의 지속적인 모델링이 어렵다.

Method: TrajSurv는 신경 제어 미분 방정식(NCDE)을 사용하여 EHR 데이터에서 연속적인 잠재 궤적을 학습하고, 시간 인식 대조 학습 접근법으로 환자 상태와 정렬한다.

Result: MIMIC-III와 eICU의 실세계 의료 데이터셋에서 TrajSurv가 기존의 딥러닝 방법에 비해 경쟁력 있는 정확도와 우수한 투명성을 보임을 확인했다.

Conclusion: TrajSurv는 임상 진행 과정과 생존 결과를 투명하게 연결하는 데 효과적이며, 미래의 임상 결정에 기여할 가능성이 있다.

Abstract: Trustworthy survival prediction is essential for clinical decision making.
Longitudinal electronic health records (EHRs) provide a uniquely powerful
opportunity for the prediction. However, it is challenging to accurately model
the continuous clinical progression of patients underlying the irregularly
sampled clinical features and to transparently link the progression to survival
outcomes. To address these challenges, we develop TrajSurv, a model that learns
continuous latent trajectories from longitudinal EHR data for trustworthy
survival prediction. TrajSurv employs a neural controlled differential equation
(NCDE) to extract continuous-time latent states from the irregularly sampled
data, forming continuous latent trajectories. To ensure the latent trajectories
reflect the clinical progression, TrajSurv aligns the latent state space with
patient state space through a time-aware contrastive learning approach. To
transparently link clinical progression to the survival outcome, TrajSurv uses
latent trajectories in a two-step divide-and-conquer interpretation process.
First, it explains how the changes in clinical features translate into the
latent trajectory's evolution using a learned vector field. Second, it clusters
these latent trajectories to identify key clinical progression patterns
associated with different survival outcomes. Evaluations on two real-world
medical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and
superior transparency over existing deep learning methods.

</details>


### [52] [JSON-Bag: A generic game trajectory representation](https://arxiv.org/abs/2508.00712)
*Dien Nguyen,Diego Perez-Liebana,Simon Lucas*

Main category: cs.LG

TL;DR: JSON-Bag 모델을 통해 게임 궤적을 나타내고, JSD를 사용하여 유사성을 평가하는 방법을 제시하며, 다양한 게임에서 성능이 향상됨을 보여줌.


<details>
  <summary>Details</summary>
Motivation: 게임 궤적의 일반적인 표현 방법이 필요하며, 이를 통해 게임 분석 및 분류의 효율성을 높이고자 함.

Method: 게임 설명을 토큰화하여 JSON-Bag 모델을 만들고, Jensen-Shannon 거리(JSD)를 사용하여 유사도를 평가하며, P-NNS를 통해 분류 작업을 수행.

Result: 이 접근 방식은 수작업으로 제작된 특성을 사용하는 기준보다 대부분의 작업에서 우수한 성능을 발휘하였으며, 자동 특성 추출에 있어서도 성능을 개선함.

Conclusion: JSON-Bag 프로토타입 간의 JSD가 에이전트 정책 간의 거리와 높은 상관관계를 보이며, 이를 통해 게임 궤적의 효과적인 분류 및 분석이 가능함을 입증함.

Abstract: We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically
represent game trajectories by tokenizing their JSON descriptions and apply
Jensen-Shannon distance (JSD) as distance metric for them. Using a
prototype-based nearest-neighbor search (P-NNS), we evaluate the validity of
JSON-Bag with JSD on six tabletop games -- \textit{7 Wonders},
\textit{Dominion}, \textit{Sea Salt and Paper}, \textit{Can't Stop},
\textit{Connect4}, \textit{Dots and boxes} -- each over three game trajectory
classification tasks: classifying the playing agents, game parameters, or game
seeds that were used to generate the trajectories.
  Our approach outperforms a baseline using hand-crafted features in the
majority of tasks. Evaluating on N-shot classification suggests using JSON-Bag
prototype to represent game trajectory classes is also sample efficient.
Additionally, we demonstrate JSON-Bag ability for automatic feature extraction
by treating tokens as individual features to be used in Random Forest to solve
the tasks above, which significantly improves accuracy on underperforming
tasks. Finally, we show that, across all six games, the JSD between JSON-Bag
prototypes of agent classes highly correlates with the distances between
agents' policies.

</details>


### [53] [DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes](https://arxiv.org/abs/2508.00664)
*Jialun Zheng,Jie Liu,Jiannong Cao,Xiao Wang,Hanchen Yang,Yankai Chen,Philip S. Yu*

Main category: cs.LG

TL;DR: 이 논문은 진화하는 그래프에서의 이상 탐지를 위한 동적 그래프 이상 탐지 모델을 제안하고, 각종 도메인에서 효과적인 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 진화하는 그래프에서 발생하는 이상을 탐지하는 것이 필요하지만, 기존의 일반 그래프 이상 탐지 모델이 동적 그래프에서의 이상을 포착하는 데 어려움을 겪고 있다.

Method: 동적 프로토타입(Dynamic Prototypes, DP)를 활용한 DGAD 모델을 제안하여, 시간적으로 변화하는 정상 및 이상 패턴을 캡처하고 메모리 버퍼에 저장하는 방식으로 작동한다.

Result: 10개의 서로 다른 도메인에서의 실제 데이터셋에서 최첨단 성능을 입증하였다.

Conclusion: DP-DGAD 모델은 진화하는 도메인 특화 및 도메인 비특화 패턴을 효과적으로 캡처할 수 있어 다양한 도메인에서 유망한 이상 탐지 성능을 제공한다.

Abstract: Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies
in evolving graphs across domains such as finance, traffic, and social
networks. Recently, generalist graph anomaly detection (GAD) models have shown
promising results. They are pretrained on multiple source datasets and
generalize across domains. While effective on static graphs, they struggle to
capture evolving anomalies in dynamic graphs. Moreover, the continuous
emergence of new domains and the lack of labeled data further challenge
generalist DGAD. Effective cross-domain DGAD requires both domain-specific and
domain-agnostic anomalous patterns. Importantly, these patterns evolve
temporally within and across domains. Building on these insights, we propose a
DGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and
domain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,
evolving representations of normal and anomalous patterns, from temporal
ego-graphs and stores them in a memory buffer. The buffer is selectively
updated to retain general, domain-agnostic patterns while incorporating new
domain-specific ones. Then, an anomaly scorer compares incoming data with
dynamic prototypes to flag both general and domain-specific anomalies. Finally,
DP-DGAD employs confidence-based pseudo-labeling for effective self-supervised
adaptation in target domains. Extensive experiments demonstrate
state-of-the-art performance across ten real-world datasets from different
domains.

</details>


### [54] [Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning](https://arxiv.org/abs/2508.00716)
*Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu*

Main category: cs.LG

TL;DR: NeGPR은 소스 레이블의 노이즈를 처리할 수 있는 그래프 수준 도메인 적응 프레임워크로, 높은 정확도를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 실제 환경에서 주석 노이즈가 만연하여 기존 GDA 방법들이 효과적으로 작동하지 않기 때문에, 노이즈가 있는 레이블을 처리하는 방법이 필요하다.

Method: NeGPR은 불필요한 감독의 영향을 줄이기 위해 이웃 일관성을 강제하는 두 개의 브랜치(구조적 및 토폴로지 브랜치)를 사전 훈련하고, 고신뢰 타겟 샘플을 선택하여 적응을 안내하는 중첩 정제 메커니즘을 적용한다.

Result: NeGPR은 심각한 레이블 노이즈에서도 최신 방법들보다 최대 12.7% 높은 정확도를 기록하며 일관되게 우수한 성능을 보인다.

Conclusion: NeGPR은 노이즈가 있는 레이블을 처리하여 도메인 적응 과정의 강건성을 향상시키는 효과적인 방법이다.

Abstract: Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled
source graphs to unlabeled target graphs by learning domain-invariant
representations, which is essential in applications such as molecular property
prediction and social network analysis. However, most existing GDA methods rely
on the assumption of clean source labels, which rarely holds in real-world
scenarios where annotation noise is pervasive. This label noise severely
impairs feature alignment and degrades adaptation performance under domain
shifts. To address this challenge, we propose Nested Graph Pseudo-Label
Refinement (NeGPR), a novel framework tailored for graph-level domain
adaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,
semantic and topology branches, by enforcing neighborhood consistency in the
feature space, thereby reducing the influence of noisy supervision. To bridge
domain gaps, NeGPR employs a nested refinement mechanism in which one branch
selects high-confidence target samples to guide the adaptation of the other,
enabling progressive cross-domain learning. Furthermore, since pseudo-labels
may still contain noise and the pre-trained branches are already overfitted to
the noisy labels in the source domain, NeGPR incorporates a noise-aware
regularization strategy. This regularization is theoretically proven to
mitigate the adverse effects of pseudo-label noise, even under the presence of
source overfitting, thus enhancing the robustness of the adaptation process.
Extensive experiments on benchmark datasets demonstrate that NeGPR consistently
outperforms state-of-the-art methods under severe label noise, achieving gains
of up to 12.7% in accuracy.

</details>


### [55] [Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network](https://arxiv.org/abs/2508.00692)
*Young-ho Cho,Hao Zhu,Duehee Lee,Ross Baldick*

Main category: cs.LG

TL;DR: 본 연구는 풍력 발전소의 자원 적합성 연구를 위해 GDFM과 GAN의 결합을 통해 풍력 시나리오를 효과적으로 합성함으로써 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 전력망의 안정성을 확보하기 위해 여러 장기 풍력 시나리오를 동시 생성할 필요성이 있다.

Method: GDFM을 사용하여 공통 및 대조 요소를 추출하고, GAN을 통해 시간적 상관관계를 나타내는 샘플을 합성하며, 두 모델을 결합하여 전반적인 파형을 표현한다.

Result: 호주의 풍력 시나리오 합성에서 GDFM과 GAN의 조합이 기존 방법보다 우수한 성능을 보였다.

Conclusion: GDFM과 GAN의 통합은 실제 풍력 발전의 통계적 특성을 더 잘 반영할 수 있음을 보여준다.

Abstract: For conducting resource adequacy studies, we synthesize multiple long-term
wind power scenarios of distributed wind farms simultaneously by using the
spatio-temporal features: spatial and temporal correlation, waveforms, marginal
and ramp rates distributions of waveform, power spectral densities, and
statistical characteristics. Generating the spatial correlation in scenarios
requires the design of common factors for neighboring wind farms and
antithetical factors for distant wind farms. The generalized dynamic factor
model (GDFM) can extract the common factors through cross spectral density
analysis, but it cannot closely imitate waveforms. The GAN can synthesize
plausible samples representing the temporal correlation by verifying samples
through a fake sample discriminator. To combine the advantages of GDFM and GAN,
we use the GAN to provide a filter that extracts dynamic factors with temporal
information from the observation data, and we then apply this filter in the
GDFM to represent both spatial and frequency correlations of plausible
waveforms. Numerical tests on the combination of GDFM and GAN have demonstrated
performance improvements over competing alternatives in synthesizing wind power
scenarios from Australia, better realizing plausible statistical
characteristics of actual wind power compared to alternatives such as the GDFM
with a filter synthesized from distributions of actual dynamic filters and the
GAN with direct synthesis without dynamic factors.

</details>


### [56] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
*Liuyun Xu,Seymour M. J. Spence*

Main category: cs.LG

TL;DR: 복잡한 비선형 유한 요소 모델링 환경에서 희귀 사건 분석을 위한 효율적인 불확실성 전파 및 작은 실패 확률 추정을 위한 다수의 신뢰도 샘플링 기법과 적응형 머신러닝 메타모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 분산 감소 기법이 희귀 사건 분석에 있어 여전히 많은 모델 평가를 필요로 하며, 이는 복잡한 비선형 시스템에서 계산적으로 도전적이다.

Method: 다수의 신뢰도 샘플링 및 적응형 머신러닝 메타모델을 활용하여 불확실성을 효과적으로 전파하고 실패 확률을 추정한다.

Result: 제안된 방법이 개별 신뢰도 감소 접근법에 비해 계산 비용을 크게 절감하면서 비선형 응답에 대한 초과 확률 곡선을 정확하게 추정할 수 있음을 시연한다.

Conclusion: 고층 강재 건물에 적용한 결과, 새로운 방법이 물리적 시스템에 대한 신뢰도 있는 실패 확률 추정을 제공함을 보여준다.

Abstract: Existing variance reduction techniques used in stochastic simulations for
rare event analysis still require a substantial number of model evaluations to
estimate small failure probabilities. In the context of complex, nonlinear
finite element modeling environments, this can become computationally
challenging-particularly for systems subjected to stochastic excitation. To
address this challenge, a multi-fidelity stratified sampling scheme with
adaptive machine learning metamodels is introduced for efficiently propagating
uncertainties and estimating small failure probabilities. In this approach, a
high-fidelity dataset generated through stratified sampling is used to train a
deep learning-based metamodel, which then serves as a cost-effective and highly
correlated low-fidelity model. An adaptive training scheme is proposed to
balance the trade-off between approximation quality and computational demand
associated with the development of the low-fidelity model. By integrating the
low-fidelity outputs with additional high-fidelity results, an unbiased
estimate of the strata-wise failure probabilities is obtained using a
multi-fidelity Monte Carlo framework. The overall probability of failure is
then computed using the total probability theorem. Application to a full-scale
high-rise steel building subjected to stochastic wind excitation demonstrates
that the proposed scheme can accurately estimate exceedance probability curves
for nonlinear responses of interest, while achieving significant computational
savings compared to single-fidelity variance reduction approaches.

</details>


### [57] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
*Sergio Rubio-Martín,María Teresa García-Ordás,Antonio Serrano-García,Clara Margarita Franch-Pato,Arturo Crespo-Álvaro,José Alberto Benítez-Andrades*

Main category: cs.LG

TL;DR: 임상 노트를 Anxiety와 Adjustment Disorder로 분류하는 AI 모델의 성능 비교 연구.


<details>
  <summary>Details</summary>
Motivation: 정신 건강 상태의 정확한 진단을 위해 임상 노트를 특정 진단 범주로 분류하는 것이 중요함.

Method: 전통적인 머신러닝 기법과 딥러닝 모델을 포함한 다양한 AI 모델의 성능을 비교하고, 세 가지 오버샘플링 전략과 하이퍼파라미터 튜닝을 적용.

Result: SMOTE가 BERT 기반 모델에 긍정적인 영향을 미쳤고, 결정 트리 및 eXtreme Gradient Boost 모델이 각각 96%의 정확도를 달성했다.

Conclusion: 하이퍼파라미터 튜닝이 모델 성능 최적화에 중요한 역할을 하며, 다양한 모델 아키텍처와 데이터 밸런싱 방법의 효능에 대한 통찰을 제공한다.

Abstract: The classification of clinical notes into specific diagnostic categories is
critical in healthcare, especially for mental health conditions like Anxiety
and Adjustment Disorder. In this study, we compare the performance of various
Artificial Intelligence models, including both traditional Machine Learning
approaches (Random Forest, Support Vector Machine, K-nearest neighbors,
Decision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT
and SciBERT), to classify clinical notes into these two diagnoses.
Additionally, we implemented three oversampling strategies: No Oversampling,
Random Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to
assess their impact on model performance. Hyperparameter tuning was also
applied to optimize model accuracy. Our results indicate that oversampling
techniques had minimal impact on model performance overall. The only exception
was SMOTE, which showed a positive effect specifically with BERT-based models.
However, hyperparameter optimization significantly improved accuracy across the
models, enhancing their ability to generalize and perform on the dataset. The
Decision Tree and eXtreme Gradient Boost models achieved the highest accuracy
among machine learning approaches, both reaching 96%, while the DistilBERT and
SciBERT models also attained 96% accuracy in the deep learning category. These
findings underscore the importance of hyperparameter tuning in maximizing model
performance. This study contributes to the ongoing research on AI-assisted
diagnostic tools in mental health by providing insights into the efficacy of
different model architectures and data balancing methods.

</details>


### [58] [A Simple and Effective Method for Uncertainty Quantification and OOD Detection](https://arxiv.org/abs/2508.00754)
*Yaxin Ma,Benjamin Colburn,Jose C. Principe*

Main category: cs.LG

TL;DR: 본 연구에서는 단일 결정론적 모델을 활용하여 불확실성 정량화의 문제를 해결하는 효과적인 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: Bayesian 신경망과 딥 앙상블 방법은 불확실성 정량화에 유용하지만 계산 비용이 크고 저장 용량이 필요하다.

Method: 커널 밀도 추정에서 유도된 정보 잠재 필드를 활용하여 훈련 세트의 특징 공간 밀도를 근사하고, 이를 테스트 샘플의 특징 공간 표현과 비교하여 분포 이동 여부를 판단한다.

Result: 2D 합성 데이터셋(두 개의 달과 세 개의 나선) 및 OOD 탐지 작업(CIFAR-10 대 SVHN)에서 실험을 수행하여 기존 모델보다 우수한 성능을 입증하였다.

Conclusion: 제안된 방법이 기존 모델들보다 더 효과적인 불확실성 정량화를 달성할 수 있음을 보여준다.

Abstract: Bayesian neural networks and deep ensemble methods have been proposed for
uncertainty quantification; however, they are computationally intensive and
require large storage. By utilizing a single deterministic model, we can solve
the above issue. We propose an effective method based on feature space density
to quantify uncertainty for distributional shifts and out-of-distribution (OOD)
detection. Specifically, we leverage the information potential field derived
from kernel density estimation to approximate the feature space density of the
training set. By comparing this density with the feature space representation
of test samples, we can effectively determine whether a distributional shift
has occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons
and Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The
results demonstrate that our method outperforms baseline models.

</details>


### [59] [Learning Network Dismantling without Handcrafted Inputs](https://arxiv.org/abs/2508.00706)
*Haozhe Tian,Pietro Ferraro,Robert Shorten,Mahdi Jalili,Homayoun Hamedmoghadam*

Main category: cs.LG

TL;DR: 메시지 전파 그래프 신경망의 혁신적 적용이 네트워크 과학 문제를 해결하는 데 기여했지만, 수작업으로 제작한 구조적 특성의 사용이 필요했다. 본 논문에서는 수작업 특성을 없애고 주의 메커니즘과 메시지 반복 프로파일을 도입하여 MIND 모델을 통해 네트워크 해체 문제를 효율적으로 해결한다.


<details>
  <summary>Details</summary>
Motivation: 메시지 전파 그래프 신경망의 성능이 수작업으로 제작한 구조적 특성에 의존하므로, 이를 제거하고 데이터 기반 접근 방식을 사용하고자 하였다.

Method: 주의 메커니즘과 메시지 반복 프로파일을 활용하여 구조적으로 다양한 훈련 세트를 생성하는 알고리즘적 접근 방식을 도입하였다.

Result: MIND 모델이 대규모 미지의 실제 네트워크에 일반화되며 기존 방법들을 뛰어넘는 성능을 보였다.

Conclusion: 제안된 모델의 효율성과 일반화 가능성은 다양한 복잡한 네트워크 문제에 활용될 수 있다.

Abstract: The application of message-passing Graph Neural Networks has been a
breakthrough for important network science problems. However, the competitive
performance often relies on using handcrafted structural features as inputs,
which increases computational cost and introduces bias into the otherwise
purely data-driven network representations. Here, we eliminate the need for
handcrafted features by introducing an attention mechanism and utilizing
message-iteration profiles, in addition to an effective algorithmic approach to
generate a structurally diverse training set of small synthetic networks.
Thereby, we build an expressive message-passing framework and use it to
efficiently solve the NP-hard problem of Network Dismantling, virtually
equivalent to vital node identification, with significant real-world
applications. Trained solely on diversified synthetic networks, our proposed
model -- MIND: Message Iteration Network Dismantler -- generalizes to large,
unseen real networks with millions of nodes, outperforming state-of-the-art
network dismantling methods. Increased efficiency and generalizability of the
proposed model can be leveraged beyond dismantling in a range of complex
network problems.

</details>


### [60] [Democratizing Tabular Data Access with an Open$\unicode{x2013}$Source Synthetic$\unicode{x2013}$Data SDK](https://arxiv.org/abs/2508.00718)
*Ivona Krchova,Mariana Vargas Vieyra,Mario Scriminaci,Andrey Sidorenko*

Main category: cs.LG

TL;DR: 이 논문은 개인 정보 보호 및 윤리적 문제로 인해 데이터 접근이 어려워진 상황에서, 안전하고 고품질의 합성 데이터를 생성하는 MOSTLY AI 합성 데이터 소프트웨어 개발 키트를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 데이터 접근에 대한 제한이 증가하고 있어, 머신러닝 개발에 있어 고품질 데이터의 중요성이 강조되고 있다.

Method: MOSTLY AI 합성 데이터 SDK는 다양한 데이터 유형과 복잡한 다중 테이블 및 연속 데이터 세트를 지원하며, 차등 개인 정보 보호 및 공정성을 고려한 데이터 생성을 특징으로 한다.

Result: SDK는 높은 성능과 개선된 속도 및 사용성을 제공하며, 클라우드 서비스와 로컬 설치형 소프트웨어로 배포되어 빠른 채택을 보고하고 있다.

Conclusion: 이 SDK는 현실의 데이터 병목 현상을 해결하고 데이터 민주화를 촉진하는 데 실질적인 기여를 하고 있다.

Abstract: Machine learning development critically depends on access to high-quality
data. However, increasing restrictions due to privacy, proprietary interests,
and ethical concerns have created significant barriers to data accessibility.
Synthetic data offers a viable solution by enabling safe, broad data usage
without compromising sensitive information. This paper presents the MOSTLY AI
Synthetic Data Software Development Kit (SDK), an open-source toolkit designed
specifically for synthesizing high-quality tabular data. The SDK integrates
robust features such as differential privacy guarantees, fairness-aware data
generation, and automated quality assurance into a flexible and accessible
Python interface. Leveraging the TabularARGN autoregressive framework, the SDK
supports diverse data types and complex multi-table and sequential datasets,
delivering competitive performance with notable improvements in speed and
usability. Currently deployed both as a cloud service and locally installable
software, the SDK has seen rapid adoption, highlighting its practicality in
addressing real-world data bottlenecks and promoting widespread data
democratization.

</details>


### [61] [Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data](https://arxiv.org/abs/2508.00758)
*Timur Sattarov,Marco Schreyer,Damian Borth*

Main category: cs.LG

TL;DR: DDAE 모델이 반자동 및 자동 설정에서 우수한 성능을 발휘하며, 잡음 전략이 중요함을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 표 데이터에서 이상 탐지는 복잡한 특성 상호작용 및 이상 사례의 부족으로 여전히 도전적이다.

Method: Diffusion-Scheduled Denoising Autoencoder(DDAE)라는 프레임워크를 제안하며, 이는 확산 기반 잡음 일정화와 대조 학습을 인코딩 프로세스에 통합한다.

Result: 57개의 ADBench 데이터셋에서 DDAE가 반자동 설정에서 우수한 성능을 보였으며, 자동 설정에서도 경쟁력을 유지하여 기존 모델 대비 PR-AUC가 최대 65% 향상되었다.

Conclusion: 원칙적 잡음 전략이 표 형식 이상 탐지에서 중요함을 강조한다.

Abstract: Anomaly detection in tabular data remains challenging due to complex feature
interactions and the scarcity of anomalous examples. Denoising autoencoders
rely on fixed-magnitude noise, limiting adaptability to diverse data
distributions. Diffusion models introduce scheduled noise and iterative
denoising, but lack explicit reconstruction mappings. We propose the
Diffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates
diffusion-based noise scheduling and contrastive learning into the encoding
process to improve anomaly detection. We evaluated DDAE on 57 datasets from
ADBench. Our method outperforms in semi-supervised settings and achieves
competitive results in unsupervised settings, improving PR-AUC by up to 65%
(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)
model baselines. We observed that higher noise levels benefit unsupervised
training, while lower noise with linear scheduling is optimal in
semi-supervised settings. These findings underscore the importance of
principled noise strategies in tabular anomaly detection.

</details>


### [62] [Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy](https://arxiv.org/abs/2508.00768)
*Antonio Tudisco,Andrea Marchesin,Maurizio Zamboni,Mariagrazia Graziano,Giovanna Turvani*

Main category: cs.LG

TL;DR: 양자 기계 학습(QML)에 대한 연구로, 변별적인 양자 회로(VQC) 모델이 데이터 인퍼런스를 처리하고, 고전적 최적화가 회로의 매개변수를 조정하여 분류 성능에 미치는 영향을 분석하였다.


<details>
  <summary>Details</summary>
Motivation: 양자 컴퓨팅과 머신 러닝의 발전으로 양자 머신 러닝(QML)이 주목받고 있다.

Method: 변별적인 양자 회로(VQC) 모델을 사용하여 Amplitude- 및 Angle-encoding 모델을 고려하고 회전 게이트의 유형이 분류 성능에 미치는 영향을 분석하였다.

Result: 와인과 당뇨병 데이터 세트에서 모델을 훈련하여, 최고의 모델과 최악의 모델 간 정확도 차이가 10%에서 30%까지, 최대 41%에 이르는 것을 확인하였다.

Conclusion: 회전 게이트 선택이 모델의 분류 성능에 중대한 영향을 미치며, 매핑은 VQC 모델의 하이퍼파라미터로 작용함을 확인하였다.

Abstract: Recent advancements in Quantum Computing and Machine Learning have increased
attention to Quantum Machine Learning (QML), which aims to develop machine
learning models by exploiting the quantum computing paradigm. One of the widely
used models in this area is the Variational Quantum Circuit (VQC), a hybrid
model where the quantum circuit handles data inference while classical
optimization adjusts the parameters of the circuit. The quantum circuit
consists of an encoding layer, which loads data into the circuit, and a
template circuit, known as the ansatz, responsible for processing the data.
This work involves performing an analysis by considering both Amplitude- and
Angle-encoding models, and examining how the type of rotational gate applied
affects the classification performance of the model. This comparison is carried
out by training the different models on two datasets, Wine and Diabetes, and
evaluating their performance. The study demonstrates that, under identical
model topologies, the difference in accuracy between the best and worst models
ranges from 10% to 30%, with differences reaching up to 41%. Moreover, the
results highlight how the choice of rotational gates used in encoding can
significantly impact the model's classification performance. The findings
confirm that the embedding represents a hyperparameter for VQC models.

</details>


### [63] [Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors](https://arxiv.org/abs/2508.00785)
*Bushra Akter,Md Biplob Hosen,Sabbir Ahmed,Mehrin Anannya,Md. Farhad Hossain*

Main category: cs.LG

TL;DR: 학생들의 CGPA를 최적화하기 위한 다변량 분석 및 예측 모델 개발 연구.


<details>
  <summary>Details</summary>
Motivation: 학생들의 학업 성취도에 영향을 미치는 사회적, 학문적, 재정적 요인을 조사하고 효과적인 전략을 개발하기 위함.

Method: 문헌 검토를 통한 요인 분석, 1,050명 대상 온라인 설문 조사, 데이터 전처리, 인과 분석, 회귀 및 분류 모델 사용.

Result: Ridge Regression의 MAE 0.12, MSE 0.023, Random Forest의 F1-score 98.68% 달성.

Conclusion: 학생 개인 맞춤형 학업 성취 예측 및 개선을 위한 웹 애플리케이션 개발.

Abstract: Academic performance depends on a multivariable nexus of socio-academic and
financial factors. This study investigates these influences to develop
effective strategies for optimizing students' CGPA. To achieve this, we
reviewed various literature to identify key influencing factors and constructed
an initial hypothetical causal graph based on the findings. Additionally, an
online survey was conducted, where 1,050 students participated, providing
comprehensive data for analysis. Rigorous data preprocessing techniques,
including cleaning and visualization, ensured data quality before analysis.
Causal analysis validated the relationships among variables, offering deeper
insights into their direct and indirect effects on CGPA. Regression models were
implemented for CGPA prediction, while classification models categorized
students based on performance levels. Ridge Regression demonstrated strong
predictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared
Error of 0.023. Random Forest outperformed in classification, attaining an
F1-score near perfection and an accuracy of 98.68%. Explainable AI techniques
such as SHAP, LIME, and Interpret enhanced model interpretability, highlighting
critical factors such as study hours, scholarships, parental education, and
prior academic performance. The study culminated in the development of a
web-based application that provides students with personalized insights,
allowing them to predict academic performance, identify areas for improvement,
and make informed decisions to enhance their outcomes.

</details>


### [64] [Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management](https://arxiv.org/abs/2508.00806)
*Ping Chen,Zhuohong Deng,Ping Li,Shuibing He,Hongzi Zhu,Yi Zheng,Zhefeng Wang,Baoxing Huai,Minyi Guo*

Main category: cs.LG

TL;DR: Adacc는 적응형 압축 및 활성화 체크포인트를 결합하여 대형 언어 모델 훈련 시 GPU 메모리 사용량을 줄이는 메모리 관리 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 훈련에서 메모리 압박을 줄이기 위해 재계산을 사용하지만, 이는 실제 상황에서 최대 30%의 오버헤드를 초래할 수 있다.

Method: Adacc는 레이어별 압축 알고리즘, 최적 스케줄링 정책(MILP 사용) 및 적응형 정책 진화 메커니즘을 포함한다.

Result: Adacc는 최신 프레임워크에 비해 LLM 훈련 속도를 1.01배에서 1.37배 향상시키며, 모델 정확도를 유지한다.

Conclusion: Adacc는 메모리 최적화를 통해 대형 언어 모델 훈련에서 효율성을 높인다.

Abstract: Training large language models often employs recomputation to alleviate
memory pressure, which can introduce up to 30% overhead in real-world
scenarios. In this paper, we propose Adacc, a novel memory management framework
that combines adaptive compression and activation checkpointing to reduce the
GPU memory footprint. It comprises three modules: (1) We design layer-specific
compression algorithms that account for outliers in LLM tensors, instead of
directly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We
propose an optimal scheduling policy that employs MILP to determine the best
memory optimization for each tensor. (3) To accommodate changes in training
tensors, we introduce an adaptive policy evolution mechanism that adjusts the
policy during training to enhance throughput. Experimental results show that
Adacc can accelerate the LLM training by 1.01x to 1.37x compared to
state-of-the-art frameworks, while maintaining comparable model accuracy to the
Baseline.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [65] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: HealthBench는 AI 시스템의 건강 능력을 측정하기 위한 벤치마크로 의사들이 만든 대화 및 투명한 루브릭을 통해 의료 언어 모델 평가를 발전시켰지만, 전문가 의견에 의존함으로써 발생하는 지역적 편향과 임상 근거 부족의 위험이 있다. 이를 해결하기 위해 우리는 임상 관행 지침에 기반한 강화 학습 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 건강 분야에서 성과를 제대로 측정하기 위해 임상적 편향을 줄이고 보다 공정한 기준이 필요하다.

Method: 모든 것을 체계적인 리뷰와 GRADE 증거 등급이 포함된 버전 관리된 CPG에 기반하여 평가하는 방향으로 강화 학습을 진행한다.

Result: 제안된 방법은 의료 언어 모델이 언어적으로 정제됨은 물론 임상적으로 신뢰할 수 있는 결과를 도출하도록 한다.

Conclusion: HealthBench의 투명성과 의사 참여를 유지하면서도 임상 관행 지침에서 엄격하게 검토된 보상으로 재토대를 마련하여 세계적으로 관련성이 높은 의료 언어 모델을 촉진하는 것을 목표로 한다.

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [66] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: 이 논문은 능동적 추론 내에서 마음의 이론을 구현하여 다중 에이전트 협력을 위한 새로운 접근 방식을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서의 협력을 개선하기 위해 타인의 믿음과 목표를 이해하는 능력인 마음의 이론을 활용하고자 합니다.

Method: ToM 기능을 갖춘 에이전트가 자신의 믿음과 다른 에이전트의 믿음을 각각 유지하며, 재귀적 추론을 통해 공동 정책 공간을 탐색하는 방식으로 계획 알고리즘을 확장하였습니다.

Result: ToM 기능을 갖춘 에이전트가 충돌 회피 및 채집 작업 시 비 ToM 에이전트보다 더 효과적으로 협조하였으며, 충돌을 피하고 중복 노력을 줄이는 데 성공하였습니다.

Conclusion: 관찰 가능한 행동만으로 타인의 믿음을 추론함으로써 ToM 에이전트는 협력 성과를 극대화함을 보여주었으며, 이는 인공지능의 실질적인 응용 가능성을 높이고 타인의 이론에 대한 계산적 통찰력을 제공합니다.

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [67] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 하이퍼속성 시간 창 템포럴 로직(HyperTWTL) 기반의 안전 강화 학습(SecRL) 방법을 제안하며, 이를 통해 보안 인식 최적 정책을 학습하고 성능을 개선함을 입증.


<details>
  <summary>Details</summary>
Motivation: 하이퍼속성 기반의 보안 인식 강화 학습에 대한 연구 공백을 메우고, 로봇 응용 프로그램에서 보안 및 투명성을 고려한 정책 학습의 필요성을 강조.

Method: 하이퍼TWTL 제약 조건을 만족하면서 동적 볼츠만 소프트맥스 강화 학습을 사용하여 보안 인식 최적 정책을 학습하는 접근 방식을 제안.

Result: 제안된 방법은 픽업 및 배달 로봇 임무 사례 연구를 통해 효과성과 확장성을 입증하며, 두 개의 다른 기본 RL 알고리즘과 비교하여 성능이 우수함을 보여줌.

Conclusion: 이 연구는 로봇 응용 프로그램에서 보안 인식의 중요성을 강조하고, 하이퍼TWTL 제약 조건을 만족하는 효과적인 정책 학습 방법을 제시하였다.

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [68] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: AI는 텍스트, 오디오, 이미지 및 비디오 생성에서 뛰어나지만, 비디오 게임과 같은 대화형 오디오-비주얼 콘텐츠 생성은 여전히 어려움이 있다. 본 연구에서는 AVR-Eval이라는 새로운 평가 지표와 멀티 에이전트 시스템 AVR-Agent를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: AI 모델이 생성하는 콘텐츠의 품질 평가와 복잡한 대화형 콘텐츠 생성을 자동화하기 위해.

Method: AVR-Eval이라는 멀티미디어 콘텐츠 품질의 상대적 지표를 개발하고, AVRs을 비교하는 옴니모달 모델 및 멀티 에이전트 시스템 AVR-Agent를 구축하여 자산을 선택하고 최적의 코드를 생성한다.

Result: AVR-Agent가 생성한 콘텐츠는 한 번의 생성으로 제작된 콘텐츠에 비해 승률이 현저히 높지만, 사용자 맞춤형 자산과 AVR 피드백을 효과적으로 활용하지는 못한다.

Conclusion: AI 모델은 인간처럼 고품질 자산과 피드백을 사용할 수 없으며, 이는 인간과 기계의 콘텐츠 생성 접근 방식의 근본적인 차이를 반영한다.

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [69] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: AI가 산업 프로세스에 성공적으로 적용되기 위해서는 객체 중심 프로세스 마이닝(OCPM)과 과정 지능(PI)이 필요하다는 내용을 다루고 있다.


<details>
  <summary>Details</summary>
Motivation: AI의 도입이 작업 방식 및 비즈니스 프로세스에 미치는 영향과 이를 성공적으로 적용하기 위한 도전 과제를 다룬다.

Method: 객체 중심 프로세스 마이닝(OCPM)을 이용해 조직 내 프로세스와 데이터를 연결하는 방법을 제안한다.

Result: PI는 다양한 객체 및 이벤트 유형을 다룰 수 있는 데이터 기반 기법들의 융합을 의미하며, AI의 조직적 맥락에 적합하다.

Conclusion: AI가 운영 프로세스를 개선하기 위해서는 PI 필요성과 OCPM과 AI의 성공적인 결합 기회를 강조한다.

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [70] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 다기준 의사결정 분석에서 랭크 역전 문제를 해결하기 위한 세 가지 테스트를 제안하고 이를 Scikit-Criteria 라이브러리에 구현함.


<details>
  <summary>Details</summary>
Motivation: 다기준 의사결정 방법의 성능을 다양한 대안 집합에 대해 측정할 수 있는 메커니즘의 필요성.

Method: 세 가지 랭크 역전 검출 테스트를 제시하고 Scikit-Criteria 라이브러리에 구현함.

Result: 제시된 테스트는 일반적인 시나리오에서의 구현에 대한 복잡성을 다루며, 효과적인 의사결정 방법 판단에 기여할 수 있음.

Conclusion: 이 추가 기능이 다기준 의사결정 방법의 평가에 중요한 역할을 할 가능성이 있음.

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [71] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: 이 논문은 업데이트 하에 RDF 그래프의 SHACL 검증을 연구하며, SHACL 기반 업데이트 언어 및 정적 검증 문제를 제시한다.


<details>
  <summary>Details</summary>
Motivation: RDF 그래프의 변화에 따라 SHACL 사양을 유지할 수 있는지를 확인해야 하는 필요성이 있다.

Method: SHACL 제약 조건에 업데이트 동작을 포함시키는 회귀 기술을 사용하여 정적 검증 문제를 SHACL의 제약 조건의 (비)만족성으로 축소한다.

Result: 정적 검증 문제의 컴퓨팅 복잡성을 분석하고, SHACL과 주요 조각들의 동적 검증을 위한 프로토타입 구현을 소개한다.

Conclusion: 예비 실험을 통해 SHACL 제약 조건에 대한 정적 검증 및 기타 정적 분석 작업의 동작을 입증하였다.

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [72] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: 인공지능(AI) 알고리즘의 위험과 편향을 줄이기 위해 생산 파이프라인의 근본적인 재설계를 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 알고리즘이 문화적으로 소외된 집단에 미치는 부정적인 영향을 완화할 필요가 있다.

Method: 공동 프레이밍, 공동 설계, 공동 실행, 공동 배포, 공동 유지 관리의 다섯 가지 단계로 구성된 증강된 AI 생애 주기를 제안한다.

Result: 다양성과 포용성을 중심으로 한 AI 생산 파이프라인의 재설계를 통해 알고리즘 공정성을 증진할 수 있다.

Conclusion: 제안된 생애 주기는 여러 윤리적 프레임워크와 연결되며, 참여 거버넌스를 확장하기 위한 연구 질문을 제시한다.

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [73] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 인간 평가의 한계를 지적하며, 교육 데이터 주석 품질을 향상시키기 위해 전통적인 IRR 대신 새로운 평가 방법론의 필요성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: AI를 활용한 교육 응용 프로그램의 대규모 학습 데이터 생산 필요성이 급증하고 있다.

Method: 다양한 평가 방법(예: 다중 레이블 주석, 전문가 기반 접근법, 클로즈드 루프 유효성 검사)을 제안하여 IRR에 대한 의존도를 줄인다.

Result: 제안된 방법들이 학생 학습 향상 및 실행 가능한 통찰력 제공에 효과적임을 보여준다.

Conclusion: 주석 품질과 근본 진실에 대한 재고를 통해 유효성과 교육적 영향을 합의보다 우선시해야 한다.

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [74] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: AI 안전성에서 권력은 중요한 개념으로, 본 논문은 AI가 인간을 강화하고 인간-AI 간의 권력 균형을 관리하도록 강제함으로써 안전성과 복지를 증진하는 방안을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: AI의 안전성과 인간 복지 증진을 동시에 이루기 위해 AI의 권력 개념을 활용하려는 동기.

Method: 파라미터화 가능하고 분해 가능한 목표 함수를 설계하여 인간의 권력을 장기적으로 평가하고, 이를 다중 요인 강화 학습을 통해 계산하는 알고리즘을 도출한다.

Result: 인간의 권력을 비직접적으로 최대화하는 것이 직접적인 효용 기반 목표보다 안전한 목표가 될 수 있음을 보여준다.

Conclusion: 적합한 인간 권력 집합 목표를 부드럽게 최대화하는 것은 에이전트 AI 시스템의 유익한 목표가 될 수 있다.

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [75] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: 본 논문에서는 RL-PLUS라는 새로운 접근 방식을 제안하여 RLVR의 한계를 극복하고 LLM의 추론 능력을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: RLVR은 LLM의 복잡한 사고 능력을 진전시켰지만, 기본 LLM의 기능 한계를 극복하는 데 어려움을 겪고 있습니다.

Method: RL-PLUS는 내부 활용(Think)과 외부 데이터(Learning)를 통합하여 다중 중요 샘플링과 탐색 기반 이점 함수를 사용합니다.

Result: 실험 결과 RL-PLUS는 기존 RLVR 방법에 비해 향상된 성능을 보이며, 다양한 모델 가족에서 일관된 성과 개선을 보여줍니다.

Conclusion: RL-PLUS는 기능 경계 붕괴 문제를 효과적으로 해결하며, 다양한 데이터셋에서 우수한 성과를 나타냅니다.

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [76] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: MetaAgent는 학습-실천 원칙에 기반한 자가 발전형 에이전트로, 지식 격차를 자연어 요청으로 해결하고 스스로 도구와 지식 기반을 구축하며, 지속적인 자기 반성과 데이터 기반 학습을 통해 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 지속적인 학습 및 자기 개선을 통해 에이전트의 전문성을 발전시키는 새로운 패러다임을 제안하고자 한다.

Method: MetaAgent는 최소한의 워크플로우로 시작해, 자연어 도움 요청을 생성하고 적절한 외부 도구에 전달하며, 자기 성찰과 검증을 통해 경험을 간결한 텍스트로 정리하고 다음 작업에 통합한다.

Result: MetaAgent는 GAIA, WebWalkerQA, BrowseCamp와 같은 지식 발견 벤치마크에서 기존 워크플로우 기반 모델보다 우수한 성능을 보이며, 엔드투엔드 학습된 에이전트와 유사한 수준의 성과를 낸다.

Conclusion: 자기 발전형 에이전트 시스템은 지식 발견 분야에서 강력하고 일반적인 성능을 발휘할 가능성이 있음을 보여준다.

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [77] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 인간과 LLM(GPT-4o)의 과제 생성 비교 실험을 통해 인간의 과제 생성이 심리적 동인의 영향을 받는 반면 LLM은 이에 적합한 행동 패턴을 반영하지 못함을 발견했다.


<details>
  <summary>Details</summary>
Motivation: 인간의 내부 동기에 의해 생성되는 다양한 과제를 조사하고, LLM의 행동 원리가 인간과 유사한지 확인하고자 했다.

Method: 인간의 과제 생성 반응과 LLM의 반응을 비교하는 과제 생성 실험을 수행했다.

Result: 인간은 심리적 동인에 의해 강하게 영향을 받는 반면, LLM은 사회적, 신체적 과제를 덜 생성하고 추상적인 테마에 편향된 과제를 만든다.

Conclusion: 인간의 가치 기반 인지 방식과 LLM의 통계적 패턴 간에 핵심적인 격차가 있으며, 인간과 더 잘 맞는 에이전트 설계에 있어 내재적 동기와 신체적 기반을 통합할 필요성이 강조된다.

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [78] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: 이 논문에서는 시각 언어 모델(VLM)의 복잡한 그래픽 추론 성능을 평가하기 위해 ReasonBench라는 새로운 벤치마크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: VLM이 인간 수준의 그래픽 추론 능력을 모사하는 데 명백한 한계가 있으며, 복잡한 문제 해결에서의 성능 부족이 있다.

Method: 1,613개의 질문으로 구성된 ReasonBench를 사용하여 11개의 VLM을 평가하고, DiaCoT와 ReasonTune이라는 이중 최적화 전략을 통해 성능을 향상시킨다.

Result: 현재 VLM의 상당한 한계를 드러내었고, 제안한 방법으로 성능을 33.5% 향상시켰다.

Conclusion: ReasonBench는 VLM의 성능을 포괄적으로 평가하는 데 기여하며, 향후 연구에 중요한 기초 자료가 될 것이다.

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [79] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: 본 논문은 LRM의 안전성 문제를 해결하기 위해 R1-Act라는 간단한 후처리 방법을 제안하며, 이는 안전 지식을 활성화하여 안전성을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: LRM이 복잡한 작업에서 뛰어난 성능을 보이지만, 유해한 사용자 지침을 수용하여 안전 문제를 야기함.

Method: 안전 지식을 구조적 추론 과정을 통해 명시적으로 활성화하는 R1-Act라는 방법 제안.

Result: R1-Act는 이전의 정렬 방법보다 우수한 안전성 향상을 이루었으며, 다양한 LRM 백본과 크기에 대해 강력한 성능을 보여줌.

Conclusion: R1-Act는 소량의 훈련 샘플과 짧은 훈련 시간으로도 안전성과 추론 성능을 동시에 개선하는 효과적인 방법이다.

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [80] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: CoRGI는 시각 콘텐츠에 기반한 검증 메커니즘을 도입하여 Vision-Language 모델의 다단계 추론 성능을 개선하는 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: CoT 프롬프트가 Vision-Language 모델의 추론을 개선하는 데 효과적이나, 종종 시각 콘텐츠와의 연관성이 결여된 설명이 발생함을 관찰하였다.

Method: CoRGI는 텍스트 기반의 추론 체인을 생성하고, 각 단계에 대한 지원 시각 증거를 추출한 후, 이를 결합하여 검증된 답변을 생성하는 3단계 파이프라인으로 구성된다.

Result: CoRGI는 VCR 벤치마크에서 Qwen-2.5VL과 LLaVA-1.6 모델의 추론 성능을 개선하며, 검증 모듈의 각 단계 기여도를 확인하였다.

Conclusion: 중간 추론 단계를 시각 증거에 기반하여 강화하는 것이 다중 모드 추론의 강건성을 높이는 데 중요함을 강조한다.

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [81] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: Cognitive Kernel-Pro는 고급 AI 에이전트 개발을 민주화하기 위해 설계된 완전 오픈소스 다중 모듈 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 현재의 에이전트 시스템은 제한된 접근성과 재현성을 가지며, 연구 커뮤니티의 발전을 저해하고 있다. 이를 해결하기 위해 Cognitive Kernel-Pro를 개발하였다.

Method: Cognitive Kernel-Pro는 웹, 파일, 코드, 일반 추론의 네 가지 주요 도메인에서 고품질 훈련 데이터를 체계적으로 조사하고, 에이전트의 테스트 시간 반영 및 투표 전략을 탐구한다.

Result: Cognitive Kernel-Pro는 GAIA에서 오픈소스 및 무료 에이전트 사이에서 최첨단의 결과를 달성하였다.

Conclusion: 우리의 8B 파라미터 오픈소스 모델은 WebDancer와 WebSailor와 같은 기존 시스템을 초월하여, 접근 가능한 고성능 AI 에이전트의 새로운 성능 기준을 설정하였다.

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [82] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: 대형 언어 모델이 수학 및 형식적 정리 증명에 대한 적용 가능성을 탐구하고 있다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 성공이 프로그래밍 유사한 문제 해결 능력에 따른 수학적 적용 가능성에 대한 관심을 불러일으켰다.

Method: 최근 모델과 벤치마크를 탐구하며 머신러닝과 수학적 인식의 교차점에서 세 가지 주요 쟁점을 다룬다.

Result: 형식 수학과 비형식 수학의 훈련 영역 간의 trade-off, 증명 생성의 취약성, LLM이 진화하는 논리적 상태를 나타내는지를 분석한다.

Conclusion: 현재의 한계를 식별하고 이를 확장할 수 있는 방법을 모색한다.

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [83] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: Pro2Guard는 위험 예측 기반의 능동적 안전 관리 프레임워크로, LLM 에이전트의 행동을 분석하여 사고를 예방한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트는 안전하지 않은 행동의 예측이 어렵고 기존의 반응형 시스템은 장기 의존성을 잘 처리하지 못한다.

Method: Pro2Guard는 에이전트 행동을 상징적 상태로 추상화하고 실행 추적에서 DTMC를 학습하여 위험을 예측한다.

Result: Pro2Guard는 가정용 에이전트의 93.6%와 자율 차량의 100% 교통법 위반 예측에 성공했다.

Conclusion: Pro2Guard는 안전성 및 작업 성공률 간 균형을 이루며, 에이전트의 안전성을 크게 향상시킨다.

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [84] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: MultiSHAP은 다중 모달 AI 모델의 예측을 설명하기 위한 모델 독립적 해석 프레임워크로, 교차 모달 상호작용을 정량화하여 개별 샘플 및 데이터셋 수준에서 설명을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 다중 모달 AI 모델의 블랙박스 특성으로 인해 해석 가능성과 신뢰성이 중요한 고위험 응용 프로그램에 배치하는 데 장벽이 되고 있다.

Method: MultiSHAP는 Shapley Interaction Index를 활용하여 상세한 시각적 및 텍스트 요소 간의 쌍별 상호작용을 통해 멀티모달 예측을 귀속시키는 모델 독립적 해석 프레임워크이다.

Result: MultiSHAP는 실험을 통해 교차 모달 추론 메커니즘을 충실히 포착하며, 실제 사례 연구를 통해 실용성을 입증하였다.

Conclusion: MultiSHAP는 두 개 이상의 모달리티를 넘어 확장 가능하며, 복잡한 다중 모달 AI 모델 해석을 위한 일반 솔루션을 제공한다.

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [85] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 본 논문에서는 전자 의료 기록(EMR)에서 개인화된 진료 전 질문지를 생성하는 새로운 다단계 LLM 기반 프레임워크를 제안하며, 정보 포괄성 및 진단 관련성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: EMR의 복잡함으로 인해 포괄적인 진료 전 질문지 생성을 어려워한다.

Method: 3단계로 구성된 LLM 기반 프레임워크를 통해 EMR로부터 정보를 추출하고 질병 지식을 종합하여 질문지를 생성한다.

Result: 실제 EMR 데이터 세트를 기반으로 평가한 결과, 정보 커버리지, 진단 적합성 및 이해 용이성에서 뛰어난 성능을 보였다.

Conclusion: 이 프레임워크는 진료 전 환자 정보 수집을 개선할 실용적인 가능성을 보여준다.

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [86] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 본 연구는 주파수 의존적인 인과 지연을 명시적으로 모델링하여 다중 대역 가변 지연 그랜저 인과 관계(MB-VLGC)를 정형화하고, 기존의 방법들보다 우수한 성능을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 그랜저 인과 관계 접근 방식은 고정 지연을 가정하지만, 복잡한 시스템에서는 비현실적일 수 있으며, 시간 지연뿐 아니라 주파수 대역에 따른 인과 상호 작용 차이를 고려할 필요가 있다.

Method: 다중 대역 가변 지연 그랜저 인과 관계(MB-VLGC)를 정식화하고, 주파수 의존적인 인과 지연을 모델링하는 새로운 프레임워크를 제안하였다.

Result: 다양한 도메인에서 수행한 실험을 통해 제안한 프레임워크가 기존 방법들에 비해 우수한 성능을 보였으며, 이로써 어떤 유형의 시계열 데이터에도 광범위하게 적용 가능함을 확인하였다.

Conclusion: MB-VLGC는 주파수 기반의 인과 지연 변화를 효과적으로 모델링하여 더 나은 인과 추론을 가능하게 한다.

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [87] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: AI 기반 적응형 학습 시스템의 투명성을 높이기 위한 하이브리드 프레임워크 제안.


<details>
  <summary>Details</summary>
Motivation: AI 기반 학습 시스템의 의사결정 과정에 대한 투명성 부족 문제 해결.

Method: 전통적인 XAI 기법과 생성적 AI 모델, 사용자 개인화 통합한 하이브리드 프레임워크 제안.

Result: 사용자의 요구에 맞춘 다중 모달 개인화된 설명 생성.

Conclusion: 사용자 중심의 경험을 지원하는 투명성 증진을 목표로 함.

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [88] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: 소셜 미디어 추천 시스템의 설명 가능성을 강화하기 위해, 사용자 세분화 및 맥락 인식 기반의 시각적 설명 시스템을 제안함.


<details>
  <summary>Details</summary>
Motivation: 소셜 미디어에서의 AI 추천이 사용자 이해 부족으로 인해 가치가 감소함.

Method: 사용자 요구와 맥락에 맞춘 다양한 시각적 설명 방법을 제공하는 시스템을 제안.

Result: 사용자 맞춤형 시각적 설명을 통해 결정-making과 신뢰에 미치는 영향을 검증할 파일럿을 진행할 계획.

Conclusion: 이 프레임워크는 설명 스타일과 세분화의 적응을 동시에 가능하게 하는 최초의 시스템이다.

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [89] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 다양한 데이터 도메인에서 합성 미디어를 탐지하기 위한 보편적인 분류기를 제안함으로써 성능 향상을 목표로 함.


<details>
  <summary>Details</summary>
Motivation: 합성 미디어의 악용이 증가함에 따라 강력한 가짜 탐지기의 필요성이 대두되고 있음.

Method: 대규모로 사전 훈련된 다중 모달 모델의 잠재 코드를 사용하여 진짜와 가짜를 구분하는 정보를 포착하고, 이 피쳐에 대한 선형 분류기를 훈련함.

Result: 다양한 모달리티에서 최첨단 결과를 달성하며, 계산 효율성과 빠른 훈련 속도를 유지함.

Conclusion: 오디오와 이미지에서 성능이 기존의 강력한 기준 방법을 초월하거나 동등함.

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [90] [ranDecepter: Real-time Identification and Deterrence of Ransomware Attacks](https://arxiv.org/abs/2508.00293)
*Md Sajidul Islam Sajid,Jinpeng Wei,Ehab Al-Shaer*

Main category: cs.CR

TL;DR: ranDecepter는 실시간 분석과 능동적인 사이버 기만을 결합하여 랜섬웨어 공격에 대응하는 새로운 접근 방식을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 랜섬웨어는 디지털 환경에서 심각한 위협으로, 효과적인 대책이 필요하다.

Method: ranDecepter는 랜섬웨어를 실시간으로 식별하고 기만적인 환경에서 분리하여, 악성 코드의 주요 요소를 파악하여 루프 메커니즘을 형성한다.

Result: ranDecepter는 1,134개의 실제 악성 샘플을 평가하여 100%의 랜섬웨어 식별 정확도를 달성하며, 오탐지 없이 최소한의 응답 시간 지연을 보인다.

Conclusion: ranDecepter는 50개의 에이전트를 이용해 24시간 내 9,223K의 공격자 데이터베이스 항목을 생성하며, 공격자의 자원을 고갈시킬 가능성이 있음을 보여준다.

Abstract: Ransomware (RW) presents a significant and widespread threat in the digital
landscape, necessitating effective countermeasures. Active cyber deception is a
promising strategy to thwart RW and limiting its propagation by misleading it
with false information and revealing its true behaviors. Furthermore, RW often
acts as a communication conduit between attackers and defenders, allowing
deception to return false data to attackers and deplete their resources. This
paper introduces ranDecepter, a novel approach that combines active cyber
deception with real-time analysis to enhance defenses against RW attacks. The
ranDecepter identifies RW in real-time and isolates it within a deceptive
environment, autonomously identifying critical elements in the RW code to
create a loop mechanism. By repeatedly restarting the malware and transmitting
counterfeit encryption information and secret keys to the attacker, it forces
the attacker to store these fabricated details for each victim, thereby
depleting their resources. Our comprehensive evaluation of ranDecepter,
conducted using 1,134 real-world malware samples and twelve benign
applications, demonstrates a remarkable 100% accuracy in RW identification,
with no false positives and minimal impact on response times. Furthermore,
within 24-hours, ranDecepter generates up to 9,223K entries in the attacker's
database using 50 agents, showcasing its potential to undermine attacker
resources.

</details>


### [91] [Cryptanalysis of Isogeny-Based Quantum Money with Rational Points](https://arxiv.org/abs/2508.00351)
*Hyeonhak Kim,Donghoe Heo,Seokhie Hong*

Main category: cs.CR

TL;DR: 이 논문에서는 몽고메리와 샤리프의 양자 화폐 기법을 분석하고, 분할 다항식 평가 효율성을 이용한 구체적인 암호 해독 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 양자 화폐의 보안성을 분석하고, 혁신적인 암호 해독 방법을 통해 더 효율적인 검증 절차를 제시하고자 함.

Method: 유리점의 좌표를 활용한 분할 다항식의 효율적인 평가 방식을 사용하여 O(log^4p)의 속도 향상을 꾀함.

Result: 제안된 공격 방법이 여전히 지수 시간이 필요하지만, 더 효율적인 검증 절차를 제공함.

Conclusion: 이 방식은 elliptic-curve 기반의 양자 암호화 연구에 기여할 것으로 기대됨.

Abstract: Quantum money is the cryptographic application of the quantum no-cloning
theorem. It has recently been instantiated by Montgomery and Sharif (Asiacrypt
'24) from class group actions on elliptic curves. In this work, we propose a
concrete cryptanalysis by leveraging the efficiency of evaluating division
polynomials with the coordinates of rational points, offering a speedup of
O(log^4p) compared to the brute-force attack. Since our attack still requires
exponential time, it remains impractical to forge a quantum banknote.
Interestingly, due to the inherent properties of quantum money, our attack
method also results in a more efficient verification procedure. Our algorithm
leverages the properties of quadratic twists to utilize rational points in
verifying the cardinality of the superposition of elliptic curves. We expect
this approach to contribute to future research on elliptic-curve-based quantum
cryptography.

</details>


### [92] [Preliminary Investigation into Uncertainty-Aware Attack Stage Classification](https://arxiv.org/abs/2508.00368)
*Alessandro Gaudenzi,Lorenzo Nodari,Lance Kaplan,Alessandra Russo,Murat Sensoy,Federico Cerutti*

Main category: cs.CR

TL;DR: 이 연구는 고급 지속 위협(APT)의 공격 단계를 불확실성 하에 추론하고, 분포 외(out-of-distribution) 입력에 강인한 분류 접근법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: APTs의 다단계 공격과 이의 복잡성으로 인해, 효과적인 대응 전략을 위해 공격의 현재 단계를 정확히 추론할 필요가 있다.

Method: Evidential Deep Learning(EDL)에 기반한 분류 접근법을 제안하며, 이는 가능성 있는 단계에 대한 Dirichlet 분포의 매개변수를 출력하여 예측 불확실성을 모델링한다.

Result: 제안된 모델은 시뮬레이션 환경에서 공격 단계를 정확하게 추론하며, OOD 입력을 효과적으로 탐지하는 성능을 보였다.

Conclusion: 불확실성을 인식하는 모델을 동적이고 적대적인 환경에서 단계적 위협 탐지에 배포할 수 있음을 지지하는 결과들을 보여준다.

Abstract: Advanced Persistent Threats (APTs) represent a significant challenge in
cybersecurity due to their prolonged, multi-stage nature and the sophistication
of their operators. Traditional detection systems typically focus on
identifying malicious activity in binary terms (benign or malicious) without
accounting for the progression of an attack. However, effective response
strategies depend on accurate inference of the attack's current stage, as
countermeasures must be tailored to whether an adversary is in the early
reconnaissance phase or actively conducting exploitation or exfiltration. This
work addresses the problem of attack stage inference under uncertainty, with a
focus on robustness to out-of-distribution (OOD) inputs. We propose a
classification approach based on Evidential Deep Learning (EDL), which models
predictive uncertainty by outputting parameters of a Dirichlet distribution
over possible stages. This allows the system not only to predict the most
likely stage of an attack but also to indicate when it is uncertain or the
input lies outside the training distribution. Preliminary experiments in a
simulated environment demonstrate that the proposed model can accurately infer
the stage of an attack with calibrated confidence while effectively detecting
OOD inputs, which may indicate changes in the attackers' tactics. These results
support the feasibility of deploying uncertainty-aware models for staged threat
detection in dynamic and adversarial environments.

</details>


### [93] [Accurate Latent Inversion for Generative Image Steganography via Rectified Flow](https://arxiv.org/abs/2508.00434)
*Yuqi Qian,Yun Cao,Meiyang Lv,Haocheng Fu*

Main category: cs.CR

TL;DR: RF-Stego는 고품질 이미지를 생성하고 강력한 강인성을 보이는 새로운 생성 이미지 스테가노그래피 방법으로, 정확한 잠재 역전과 메시지 추출 정확도를 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 스테가노그래피의 정확한 메시지 추출을 위한 잠재 역전의 불확실성을 해결하기 위해.

Method: Path Consistency Linear Inversion(PCLI)와 Rectified Flow(RF)를 사용하여 잠재 역전을 정확하게 수행하고 수치적 안정성을 높인다.

Result: RF-Stego는 기존의 최첨단 방법보다 추출 정확도, 이미지 품질, 강인성, 보안 및 생성 효율성에서 뛰어난 성능을 보인다.

Conclusion: RF-Stego는 스테가노그래피 과정에서 경로 일치를 보장하여 메시지 추출의 정확성을 높인다.

Abstract: Steganography based on diffusion models has attracted increasing attention
due to its ability to generate high-quality images and exhibit strong
robustness. In such approaches, the secret message is first embedded into the
initial latent variable, and then the stego image is generated through the
forward process. To extract the message, an inversion process is required to
reconstruct the latent variables from the received image. However, inaccurate
latent inversion leads to significant discrepancies between the reconstructed
and original latent variables, rendering message extraction infeasible. To
address this issue, we propose \textbf{RF-Stego}, a novel generative image
steganography method that enables accurate latent inversion and significantly
improves extraction accuracy. First, we develop the \textbf{P}ath
\textbf{C}onsistency \textbf{L}inear \textbf{I}nversion (\textbf{PCLI}), which
imposes formal constraints on the inversion process. By explicitly aligning it
with the forward generation path and modeling both directions along a shared
linear path, PCLI eliminates path mismatch and ensures path consistency
throughout the steganographic process. Second, through rigorous theoretical
proof, we demonstrate that \textbf{R}ectified \textbf{F}low \textbf{(RF)}
offers both theoretical reversibility and numerical stability in the inversion
process. Based on this, we replace traditional unstable samplers with RF
sampler which effectively improves the numerical precision of the inversion
process. Experimental results show RF-Stego outperforms state-of-the-art
methods in terms of extraction accuracy, image quality, robustness, security
and generation efficiency.

</details>


### [94] [CyGATE: Game-Theoretic Cyber Attack-Defense Engine for Patch Strategy Optimization](https://arxiv.org/abs/2508.00478)
*Yuning Jiang,Nay Oo,Qiaoran Meng,Lu Lin,Dusit Niyato,Zehui Xiong,Hoon Wei Lim,Biplab Sikdar*

Main category: cs.CR

TL;DR: CyGATE는 실시간 위협 정보를 통합하여 공격자-방어자 상호작용을 모델링하는 게임 이론 기반 프레임워크로, 동적 위협 통합 및 자원 최적화를 통해 공격 분석 및 패치 우선순위를 개선한다.


<details>
  <summary>Details</summary>
Motivation: 현대 사이버 공격은 여러 단계를 거치며, 방어자는 불확실성 속에서 동적으로 완화 조치를 우선시해야 한다.

Method: CyGATE는 대형 언어 모델(LLMs)과 검색 증강 생성(RAG)을 활용하여 공격자-방어자 상호작용을 모델링하며, 부분 관찰 확률 게임(POSG)으로 사이버 충돌을 프레임화한다.

Result: CyGATE는 동적 패치 스케줄링 시나리오에서 높은 위험의 취약점을 효과적으로 우선순위를 정하고, 공격자의 행동을 예측하여 적응성과 효율성을 향상시킨다.

Conclusion: 이 프레임워크는 다중 에이전트 시나리오에 확장 가능하며, 복잡한 환경에서의 사이버 보안 방어에 효과적이다.

Abstract: Modern cyber attacks unfold through multiple stages, requiring defenders to
dynamically prioritize mitigations under uncertainty. While game-theoretic
models capture attacker-defender interactions, existing approaches often rely
on static assumptions and lack integration with real-time threat intelligence,
limiting their adaptability. This paper presents CyGATE, a game-theoretic
framework modeling attacker-defender interactions, using large language models
(LLMs) with retrieval-augmented generation (RAG) to enhance tactic selection
and patch prioritization. Applied to a two-agent scenario, CyGATE frames cyber
conflicts as a partially observable stochastic game (POSG) across Cyber Kill
Chain stages. Both agents use belief states to navigate uncertainty, with the
attacker adapting tactics and the defender re-prioritizing patches based on
evolving risks and observed adversary behavior. The framework's flexible
architecture enables extension to multi-agent scenarios involving coordinated
attackers, collaborative defenders, or complex enterprise environments with
multiple stakeholders. Evaluated in a dynamic patch scheduling scenario, CyGATE
effectively prioritizes high-risk vulnerabilities, enhancing adaptability
through dynamic threat integration, strategic foresight by anticipating
attacker moves under uncertainty, and efficiency by optimizing resource use.

</details>


### [95] [Activation-Guided Local Editing for Jailbreaking Attacks](https://arxiv.org/abs/2508.00555)
*Jiecong Wang,Haoran Li,Hao Peng,Ziqian Zeng,Zihao Wang,Haohua Du,Zhengtao Yu*

Main category: cs.CR

TL;DR: 효과적인 2단계 프레임워크를 통해 기존의 jailbreak 기법의 단점을 극복하고 우수한 공격 성공률을 달성함.


<details>
  <summary>Details</summary>
Motivation: 모델의 보안 결함을 발견하고 패치하기 위해 jailbreak 기법이 필요하지만, 기존 방법들은 여러 단점이 있다.

Method: 첫 번째 단계에서 시나리오 기반의 맥락 생성 및 원래의 악의적인 쿼리를 재표현하여 해를 숨기고, 두 번째 단계에서 모델의 숨겨진 상태 정보를 활용하여 세밀한 수정을 수행한다.

Result: 이 방법은 가장 강력한 기준선보다 최대 37.74% 향상된 공격 성공률을 기록하고, 블랙박스 모델에 대한 탁월한 전이성을 보여준다.

Conclusion: AGILE은 주요 방어 메커니즘에 대해 높은 효과를 유지하며, 현재의 방어 한계와 미래 방어 개발을 위한 통찰을 제공한다.

Abstract: Jailbreaking is an essential adversarial technique for red-teaming these
models to uncover and patch security flaws. However, existing jailbreak methods
face significant drawbacks. Token-level jailbreak attacks often produce
incoherent or unreadable inputs and exhibit poor transferability, while
prompt-level attacks lack scalability and rely heavily on manual effort and
human ingenuity. We propose a concise and effective two-stage framework that
combines the advantages of these approaches. The first stage performs a
scenario-based generation of context and rephrases the original malicious query
to obscure its harmful intent. The second stage then utilizes information from
the model's hidden states to guide fine-grained edits, effectively steering the
model's internal representation of the input from a malicious toward a benign
one. Extensive experiments demonstrate that this method achieves
state-of-the-art Attack Success Rate, with gains of up to 37.74% over the
strongest baseline, and exhibits excellent transferability to black-box models.
Our analysis further demonstrates that AGILE maintains substantial
effectiveness against prominent defense mechanisms, highlighting the
limitations of current safeguards and providing valuable insights for future
defense development. Our code is available at
https://github.com/yunsaijc/AGILE.

</details>


### [96] [LeakSealer: A Semisupervised Defense for LLMs Against Prompt Injection and Leakage Attacks](https://arxiv.org/abs/2508.00602)
*Francesco Panebianco,Stefano Bonfanti,Francesco Trovò,Michele Carminati*

Main category: cs.CR

TL;DR: 이 논문은 대형 언어 모델(LLM)의 보안 위협을 분석하고, 자율 방어 메커니즘을 구현하는 LeakSealer 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 보편화로 인한 보안 위협, 특히 탈옥(jailbreaking) 및 데이터 유출 공격이 증가하고 있다.

Method: 이 연구에서는 LLM 상호작용 데이터를 분석하고, 주제별 사용 맵을 생성하며, LeakSealer라는 모델-비의존적 프레임워크를 제안하여 정적 분석과 동적 방어를 결합한다.

Result: LeakSealer는 Static 환경에서 ToxicChat 데이터셋에서 프롬프트 주입을 정확하게 식별하는 최고의 정확도와 재현율을 달성하였고, Dynamic 환경에서 PII 유출 탐지에서 AUPRC 0.97을 기록하며 기존 방법들을 크게 능가하였다.

Conclusion: 이 연구는 LLM 시스템의 보안을 강화할 수 있는 방법론과 도구를 제시하며, 보안 위협에 대응할 수 있는 효과적인 전략을 제공한다.

Abstract: The generalization capabilities of Large Language Models (LLMs) have led to
their widespread deployment across various applications. However, this
increased adoption has introduced several security threats, notably in the
forms of jailbreaking and data leakage attacks. Additionally, Retrieval
Augmented Generation (RAG), while enhancing context-awareness in LLM responses,
has inadvertently introduced vulnerabilities that can result in the leakage of
sensitive information. Our contributions are twofold. First, we introduce a
methodology to analyze historical interaction data from an LLM system, enabling
the generation of usage maps categorized by topics (including adversarial
interactions). This approach further provides forensic insights for tracking
the evolution of jailbreaking attack patterns. Second, we propose LeakSealer, a
model-agnostic framework that combines static analysis for forensic insights
with dynamic defenses in a Human-In-The-Loop (HITL) pipeline. This technique
identifies topic groups and detects anomalous patterns, allowing for proactive
defense mechanisms. We empirically evaluate LeakSealer under two scenarios: (1)
jailbreak attempts, employing a public benchmark dataset, and (2) PII leakage,
supported by a curated dataset of labeled LLM interactions. In the static
setting, LeakSealer achieves the highest precision and recall on the ToxicChat
dataset when identifying prompt injection. In the dynamic setting, PII leakage
detection achieves an AUPRC of $0.97$, significantly outperforming baselines
such as Llama Guard.

</details>


### [97] [FedGuard: A Diverse-Byzantine-Robust Mechanism for Federated Learning with Major Malicious Clients](https://arxiv.org/abs/2508.00636)
*Haocheng Jiang,Hua Shen,Jixin Zhang,Willy Susilo,Mingwu Zhang*

Main category: cs.CR

TL;DR: FedGuard는 비잔틴 공격에 대한 새로운 연합 학습 메커니즘을 제안하여 기존 방어책보다 효과적으로 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습은 50% 이상의 클라이언트가 악의적일 때 및 비독립적이고 동일한 분포가 아닌 데이터셋에서 비잔틴 공격에 취약하다.

Method: 클라이언트가 서버가 지정한 추가 미니 배치를 포함하도록 요구하여 모델의 편향을 이용해 악성 모델을 식별하고 제외한다.

Result: FedGuard는 90%의 클라이언트가 비잔틴인 세 가지 비독립적 데이터셋에서 기존 방어책보다 훨씬 더 뛰어난 성능을 보인다.

Conclusion: FedGuard는 여러 유형의 비잔틴 공격을 완화하는 데 있어 기존의 탄력적 연합 학습 방안보다 우수하다.

Abstract: Federated learning is a distributed training framework vulnerable to
Byzantine attacks, particularly when over 50% of clients are malicious or when
datasets are highly non-independent and identically distributed (non-IID).
Additionally, most existing defense mechanisms are designed for specific attack
types (e.g., gradient similarity-based schemes can only defend against outlier
model poisoning), limiting their effectiveness. In response, we propose
FedGuard, a novel federated learning mechanism. FedGuard cleverly addresses the
aforementioned issues by leveraging the high sensitivity of membership
inference to model bias. By requiring clients to include an additional
mini-batch of server-specified data in their training, FedGuard can identify
and exclude poisoned models, as their confidence in the mini-batch will drop
significantly. Our comprehensive evaluation unequivocally shows that, under
three highly non-IID datasets, with 90% of clients being Byzantine and seven
different types of Byzantine attacks occurring in each round, FedGuard
significantly outperforms existing robust federated learning schemes in
mitigating various types of Byzantine attacks.

</details>


### [98] [Demo: TOSense -- What Did You Just Agree to?](https://arxiv.org/abs/2508.00659)
*Xinzhang Chen,Hassan Ali,Arash Shaghaghi,Salil S. Kanhere,Sanjay Jha*

Main category: cs.CR

TL;DR: TOSense는 사용자들이 자연어로 서비스 약관에 대해 질문하고 실시간으로 간결한 답변을 받을 수 있게 돕는 Chrome 확장 프로그램이다.


<details>
  <summary>Details</summary>
Motivation: 온라인 서비스의 복잡한 약관으로 인한 정보 비대칭과 법적 위험을 해소하기 위해.

Method: ToS 내용을 자동으로 추출하는 크롤러와 자연어 처리 모델을 활용하여 질문에 대한 답변을 제공하는 시스템을 개발.

Result: Apple, Google, X, Microsoft, Netflix 등 5개 주요 플랫폼에서 평균 44.5% 정확도로 효과성을 입증하였다.

Conclusion: TOSense는 약관의 실시간 질의응답과 새로운 사이트의 즉각적인 인덱싱을 실현하는 유용한 도구이다.

Abstract: Online services often require users to agree to lengthy and obscure Terms of
Service (ToS), leading to information asymmetry and legal risks. This paper
proposes TOSense-a Chrome extension that allows users to ask questions about
ToS in natural language and get concise answers in real time. The system
combines (i) a crawler "tos-crawl" that automatically extracts ToS content, and
(ii) a lightweight large language model pipeline: MiniLM for semantic retrieval
and BART-encoder for answer relevance verification. To avoid expensive manual
annotation, we present a novel Question Answering Evaluation Pipeline (QEP)
that generates synthetic questions and verifies the correctness of answers
using clustered topic matching. Experiments on five major platforms, Apple,
Google, X (formerly Twitter), Microsoft, and Netflix, show the effectiveness of
TOSense (with up to 44.5% accuracy) across varying number of topic clusters.
During the demonstration, we will showcase TOSense in action. Attendees will be
able to experience seamless extraction, interactive question answering, and
instant indexing of new sites.

</details>


### [99] [Unveiling Dynamic Binary Instrumentation Techniques](https://arxiv.org/abs/2508.00682)
*Oscar Llorente-Vazquez,Xabier Ugarte-Pedrero,Igor Santos-Grueiro,Pablo Garcia Bringas*

Main category: cs.CR

TL;DR: DBI 기술의 여러 접근법을 비교하고 분석하여 성능과 한계를 조명한다.


<details>
  <summary>Details</summary>
Motivation: DBI 기술의 다양성과 그에 따른 한계 극복을 위해.

Method: 프로세스 수준 및 전체 시스템 방식의 DBI 접근법을 분석하고 비교한다.

Result: DBI 기술들이 특정 원시 데이터와 런타임 이벤트에 대한 성능을 평가한 결과, 특정 기술이 모든 상황에서 가장 우수하지 않음을 발견했다.

Conclusion: 모든 DBI 기술은 특정 상황에서 장단점이 있으며, 통합된 접근이 필요함을 강조한다.

Abstract: Dynamic Binary Instrumentation (DBI) is the set of techniques that enable
instrumentation of programs at run-time, making it possible to monitor and
modify the execution of compiled binaries or entire systems. DBI is used for
countless security applications and analyses, and is extensively used across
many fields in both industry and academia. Over the years, several DBI
approaches have been proposed based on different technologies and implementing
diverse techniques. Every solution tries to overcome certain limitations, but
they sometimes bring other shortcomings. Some are specialized for one
particular domain or task, while others have a wider scope.
  In this paper, we shed light into the labyrinth of DBI, bringing together
process-level and whole-system approaches. We depict their building blocks and
analyze the underlying instrumentation techniques, comparing their ability to
instrument different primitives and run-time events. Then, we evaluate their
performance when implementing each primitive, and highlight relevant
observations. Our results show that no single technique is better than the rest
in all circumstances.

</details>


### [100] [LeakyCLIP: Extracting Training Data from CLIP](https://arxiv.org/abs/2508.00756)
*Yunhao Chen,Shujie Wang,Xin Wang,Xingjun Ma*

Main category: cs.CR

TL;DR: 이 논문은 Contrastive Language-Image Pretraining(CLIP)에서 메모리화 및 개인정보 유출 위험을 분석하며, LeakyCLIP이라는 공격 프레임워크를 통해 이미지 재구성을 수행한다.


<details>
  <summary>Details</summary>
Motivation: CLIP의 보안성을 보장하기 위해 메모리화 및 개인정보 유출 위험을 이해하는 것이 중요하다.

Method: LeakyCLIP은 비대칭 미세 조정, 선형 변환 기반 임베딩 정렬 및 안정적인 확산 기반 개선을 사용하여 CLIP 역설계를 수행한다.

Result: LeakyCLIP은 ViT-B-16에서 SSIM에서 358% 이상의 향상을 이루어냈으며, 낮은 신뢰성 재구성의 메트릭스에서도 훈련 데이터의 멤버십을 유추할 수 있는 위험이 있음을 보여주었다.

Conclusion: 이 연구는 CLIP 역설계에 대한 실용적인 방법론을 제시하며, 다중모달 모델의 개인정보 위험에 대한 통찰력을 제공한다.

Abstract: Understanding the memorization and privacy leakage risks in Contrastive
Language--Image Pretraining (CLIP) is critical for ensuring the security of
multimodal models. Recent studies have demonstrated the feasibility of
extracting sensitive training examples from diffusion models, with conditional
diffusion models exhibiting a stronger tendency to memorize and leak
information. In this work, we investigate data memorization and extraction
risks in CLIP through the lens of CLIP inversion, a process that aims to
reconstruct training images from text prompts. To this end, we introduce
\textbf{LeakyCLIP}, a novel attack framework designed to achieve high-quality,
semantically accurate image reconstruction from CLIP embeddings. We identify
three key challenges in CLIP inversion: 1) non-robust features, 2) limited
visual semantics in text embeddings, and 3) low reconstruction fidelity. To
address these challenges, LeakyCLIP employs 1) adversarial fine-tuning to
enhance optimization smoothness, 2) linear transformation-based embedding
alignment, and 3) Stable Diffusion-based refinement to improve fidelity.
Empirical results demonstrate the superiority of LeakyCLIP, achieving over 358%
improvement in Structural Similarity Index Measure (SSIM) for ViT-B-16 compared
to baseline methods on LAION-2B subset. Furthermore, we uncover a pervasive
leakage risk, showing that training data membership can even be successfully
inferred from the metrics of low-fidelity reconstructions. Our work introduces
a practical method for CLIP inversion while offering novel insights into the
nature and scope of privacy risks in multimodal models.

</details>
