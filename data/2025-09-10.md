<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 24]
- [cs.LG](#cs.LG) [Total: 21]
- [cs.CR](#cs.CR) [Total: 13]
- [cs.MA](#cs.MA) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SasAgent: Multi-Agent AI System for Small-Angle Scattering Data Analysis](https://arxiv.org/abs/2509.05363)
*Lijie Ding,Changwoo Do*

Main category: cs.AI

TL;DR: SasAgent는 대형 언어 모델(LLM)을 기반으로 한 다중 에이전트 AI 시스템으로, 작은 각 산란(SAS) 데이터 분석을 자동화하고 사용자 상호작용을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 과학적 작업의 효율성을 높이고 SAS 연구에서의 자동화를 강화하기 위해 LLM 기반 AI 시스템의 잠재력을 활용하고자 한다.

Method: SasAgent는 사용자 프롬프트를 해석하고 작업을 세 가지 전문 에이전트(산란 길이 밀도 계산, 합성 데이터 생성, 실험 데이터 피팅)에 위임하는 조정자 에이전트를 특징으로 한다. 이 에이전트들은 SasView 파이썬 라이브러리에서 파생된 LLM 친화적인 도구를 사용하여 작업을 효율적으로 수행한다.

Result: SasAgent는 복잡한 프롬프트를 해석하고, SLD를 계산하며, 정확한 산란 데이터를 생성하고, 실험 데이터 세트를 높은 정밀도로 피팅할 수 있는 능력을 입증하였다.

Conclusion: 이 연구는 LLM 기반 AI 시스템이 과학적 워크플로를 간소화하고 SAS 연구에서의 자동화를 향상시키는 잠재력을 보여준다.

Abstract: We introduce SasAgent, a multi-agent AI system powered by large language
models (LLMs) that automates small-angle scattering (SAS) data analysis by
leveraging tools from the SasView software and enables user interaction via
text input. SasAgent features a coordinator agent that interprets user prompts
and delegates tasks to three specialized agents for scattering length density
(SLD) calculation, synthetic data generation, and experimental data fitting.
These agents utilize LLM-friendly tools to execute tasks efficiently. These
tools, including the model data tool, Retrieval-Augmented Generation (RAG)
documentation tool, bump fitting tool, and SLD calculator tool, are derived
from the SasView Python library. A user-friendly Gradio-based interface
enhances user accessibility. Through diverse examples, we demonstrate
SasAgent's ability to interpret complex prompts, calculate SLDs, generate
accurate scattering data, and fit experimental datasets with high precision.
This work showcases the potential of LLM-driven AI systems to streamline
scientific workflows and enhance automation in SAS research.

</details>


### [2] [Code Like Humans: A Multi-Agent Solution for Medical Coding](https://arxiv.org/abs/2509.05378)
*Andreas Motzfeldt,Joakim Edin,Casper L. Christensen,Christian Hardmeier,Lars Maaløe,Anna Rogers*

Main category: cs.AI

TL;DR: 이 논문은 의료 코딩을 위한 새로운 프레임워크인 Code Like Humans를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 의료 코딩에서 전문가들이 비정형 임상 노트를 진단 및 절차를 위한 알파벳 번호 코드로 매핑해야 하는 과제를 해결하고자 함.

Method: 대규모 언어 모델을 사용한 에이전틱 프레임워크를 구현하여 공식 코딩 가이드라인을 따릅니다.

Result: 희귀 진단 코드에서 지금까지 최고의 성능을 달성하였으며, ICD-10 코딩 시스템을 완전하게 지원하는 최초의 솔루션입니다.

Conclusion: 시스템 성능 분석을 통해 '눈치 채지 못하는 부분'(체계적으로 저코드 된 코드)을 식별하였습니다.

Abstract: In medical coding, experts map unstructured clinical notes to alphanumeric
codes for diagnoses and procedures. We introduce Code Like Humans: a new
agentic framework for medical coding with large language models. It implements
official coding guidelines for human experts, and it is the first solution that
can support the full ICD-10 coding system (+70K labels). It achieves the best
performance to date on rare diagnosis codes (fine-tuned discriminative
classifiers retain an advantage for high-frequency codes, to which they are
limited). Towards future work, we also contribute an analysis of system
performance and identify its `blind spots' (codes that are systematically
undercoded).

</details>


### [3] [From Image Generation to Infrastructure Design: a Multi-agent Pipeline for Street Design Generation](https://arxiv.org/abs/2509.05469)
*Chenguang Wang,Xiang Yan,Yilong Dai,Ziyi Wang,Susu Xu*

Main category: cs.AI

TL;DR: 본 논문은 AI 기반 다중 에이전트 시스템을 통해 실제 도로 이미지에서 자전거 시설을 편집 및 재설계하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 활발한 교통 계획에 대한 대중 참여를 촉진하기 위해 현실감 있는 도로 설계 시나리오의 시각적 렌더링이 필수적이다.

Method: 이 논문에서는 진짜 도로 이미지에서 자전거 시설을 직접 편집하고 재설계하는 다중 에이전트 시스템을 도입한다. 이 프레임워크는 차선 현지화, 프롬프트 최적화, 디자인 생성 및 자동 평가를 통합하여 현실적이고 맥락에 적합한 디자인을 합성한다.

Result: 다양한 도시 시나리오 실험을 통해 시스템이 도로 기하학과 환경 조건에 적응할 수 있으며, 시각적으로 일관되고 지침에 부합하는 결과를 꾸준히 생성함을 보여준다.

Conclusion: 이 연구는 다중 에이전트 파이프라인을 교통 인프라 계획 및 시설 설계에 적용하기 위한 기초를 마련한다.

Abstract: Realistic visual renderings of street-design scenarios are essential for
public engagement in active transportation planning. Traditional approaches are
labor-intensive, hindering collective deliberation and collaborative
decision-making. While AI-assisted generative design shows transformative
potential by enabling rapid creation of design scenarios, existing generative
approaches typically require large amounts of domain-specific training data and
struggle to enable precise spatial variations of design/configuration in
complex street-view scenes. We introduce a multi-agent system that edits and
redesigns bicycle facilities directly on real-world street-view imagery. The
framework integrates lane localization, prompt optimization, design generation,
and automated evaluation to synthesize realistic, contextually appropriate
designs. Experiments across diverse urban scenarios demonstrate that the system
can adapt to varying road geometries and environmental conditions, consistently
yielding visually coherent and instruction-compliant results. This work
establishes a foundation for applying multi-agent pipelines to transportation
infrastructure planning and facility design.

</details>


### [4] [DRF: LLM-AGENT Dynamic Reputation Filtering Framework](https://arxiv.org/abs/2509.05764)
*Yuwei Lou,Hao Hu,Shaocong Ma,Zongfei Zhang,Liang Wang,Jidong Ge,Xianping Tao*

Main category: cs.AI

TL;DR: 본 논문에서는 다중 에이전트 시스템의 성능을 정량화하고 에이전트 신뢰성을 평가하는 메커니즘이 부족하다는 문제를 해결하기 위해 동적 평판 필터링 프레임워크인 DRF를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 생성 AI의 발전에 따라 대규모 언어 모델을 활용한 다중 에이전트 시스템이 복잡한 작업을 수행하는 강력한 도구로 부상하고 있지만, 에이전트 성능을 정량화하고 신뢰성을 평가하는 데 어려움이 있습니다.

Method: DRF는 에이전트 성능을 정량화하기 위한 상호작용 평점 네트워크를 구축하고, 에이전트의 정직성과 능력을 측정하기 위한 평판 점수 메커니즘을 설계하며, 에이전트 선택 효율성을 높이기 위한 상한 신뢰 경계를 기반으로 한 전략을 통합합니다.

Result: 실험 결과, DRF는 논리적 추론 및 코드 생성 작업에서 작업 완료 품질과 협업 효율성을 크게 개선하는 것으로 나타났습니다.

Conclusion: DRF는 대규모 작업을 처리하기 위한 다중 에이전트 시스템의 새로운 접근 방식을 제공합니다.

Abstract: With the evolution of generative AI, multi - agent systems leveraging large -
language models(LLMs) have emerged as a powerful tool for complex tasks.
However, these systems face challenges in quantifying agent performance and
lack mechanisms to assess agent credibility. To address these issues, we
introduce DRF, a dynamic reputation filtering framework. DRF constructs an
interactive rating network to quantify agent performance, designs a reputation
scoring mechanism to measure agent honesty and capability, and integrates an
Upper Confidence Bound - based strategy to enhance agent selection efficiency.
Experiments show that DRF significantly improves task completion quality and
collaboration efficiency in logical reasoning and code - generation tasks,
offering a new approach for multi - agent systems to handle large - scale
tasks.

</details>


### [5] [PillagerBench: Benchmarking LLM-Based Agents in Competitive Minecraft Team Environments](https://arxiv.org/abs/2509.06235)
*Olivier Schipper,Yudi Zhang,Yali Du,Mykola Pechenizkiy,Meng Fang*

Main category: cs.AI

TL;DR: 본 연구에서는 대규모 언어 모델 기반 에이전트를 경쟁적인 다중 에이전트 환경에서 평가하기 위한 새로운 프레임워크인 PillagerBench를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 경쟁적인 다중 에이전트 환경에서 LLM 기반 에이전트의 효과성을 탐구하고자 함.

Method: Minecraft에서의 실시간 경쟁 팀 대 팀 시나리오를 평가하기 위한 PillagerBench 프레임워크와 인적 가독성을 갖춘 전술을 통해 팀워크를 촉진하는 TactiCrafter 다중 에이전트 시스템을 제안합니다.

Result: TactiCrafter가 기존 접근 방식보다 우수한 성능을 보이며, 자기 플레이를 통한 적응 학습을 보여줍니다.

Conclusion: PillagerBench를 오픈 소스화하여 경쟁 환경에서 다중 에이전트 AI의 발전을 촉진합니다.

Abstract: LLM-based agents have shown promise in various cooperative and strategic
reasoning tasks, but their effectiveness in competitive multi-agent
environments remains underexplored. To address this gap, we introduce
PillagerBench, a novel framework for evaluating multi-agent systems in
real-time competitive team-vs-team scenarios in Minecraft. It provides an
extensible API, multi-round testing, and rule-based built-in opponents for
fair, reproducible comparisons. We also propose TactiCrafter, an LLM-based
multi-agent system that facilitates teamwork through human-readable tactics,
learns causal dependencies, and adapts to opponent strategies. Our evaluation
demonstrates that TactiCrafter outperforms baseline approaches and showcases
adaptive learning through self-play. Additionally, we analyze its learning
process and strategic evolution over multiple game episodes. To encourage
further research, we have open-sourced PillagerBench, fostering advancements in
multi-agent AI for competitive environments.

</details>


### [6] [Chatbot To Help Patients Understand Their Health](https://arxiv.org/abs/2509.05818)
*Won Seok Jang,Hieu Tran,Manav Mistry,SaiKiran Gandluri,Yifan Zhang,Sharmin Sultana,Sunjae Kown,Yuan Zhang,Zonghai Yao,Hong Yu*

Main category: cs.AI

TL;DR: NoteAid-Chatbot는 환자 이해를 촉진하는 대화형 AI로, 의료 대화 전략을 활용한 대화형 데이터를 기반으로 학습하여 환자 교육에 중요한 특성을 갖춘다.


<details>
  <summary>Details</summary>
Motivation: 환자가 자신의 치료에 적극적으로 참여할 수 있도록 필수적인 지식을 갖추는 것이 중요하다.

Method: NoteAid-Chatbot은 경량의 LLaMA 3.2 3B 모델을 사용하여 대화형 데이터를 기반으로 초기 지도 학습 후, 환자 이해 평가에서 수치화된 보상을 사용하는 강화 학습을 수행한다.

Result: NoteAid-Chatbot은 명확성, 관련성 및 구조화된 대화와 같은 환자 교육에 중요한 emergent behaviors를 나타내며, 이러한 속성에 대한 명시적 감독 없이도 성공적으로 작동한다.

Conclusion: PPO 기반의 보상 모델링을 통해 기존의 비전문가 인간보다 우수한 성능을 보이며, 저비용의 RL 프레임워크가 현실적인 대화 영역에 적용 가능성을 보여준다.

Abstract: Patients must possess the knowledge necessary to actively participate in
their care. We present NoteAid-Chatbot, a conversational AI that promotes
patient understanding via a novel 'learning as conversation' framework, built
on a multi-agent large language model (LLM) and reinforcement learning (RL)
setup without human-labeled data. NoteAid-Chatbot was built on a lightweight
LLaMA 3.2 3B model trained in two stages: initial supervised fine-tuning on
conversational data synthetically generated using medical conversation
strategies, followed by RL with rewards derived from patient understanding
assessments in simulated hospital discharge scenarios. Our evaluation, which
includes comprehensive human-aligned assessments and case studies, demonstrates
that NoteAid-Chatbot exhibits key emergent behaviors critical for patient
education, such as clarity, relevance, and structured dialogue, even though it
received no explicit supervision for these attributes. Our results show that
even simple Proximal Policy Optimization (PPO)-based reward modeling can
successfully train lightweight, domain-specific chatbots to handle multi-turn
interactions, incorporate diverse educational strategies, and meet nuanced
communication objectives. Our Turing test demonstrates that NoteAid-Chatbot
surpasses non-expert human. Although our current focus is on healthcare, the
framework we present illustrates the feasibility and promise of applying
low-cost, PPO-based RL to realistic, open-ended conversational domains,
broadening the applicability of RL-based alignment methods.

</details>


### [7] [MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration](https://arxiv.org/abs/2509.05933)
*Md Hasebul Hasan,Mahir Labib Dihan,Mohammed Eunus Ali,Md Rizwan Parvez*

Main category: cs.AI

TL;DR: MapAgent는 지리공간 추론을 위한 계층적 다중 에이전트 프레임워크로, 복잡한 쿼리를 하위 목표로 분해하고, 전문화된 모듈에 라우팅하여 인지 부하를 줄이고 데이터 정확성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 현재의 에이전트 기반 접근 방식은 지리공간 과제에서의 공간 추론과 실시간 상호작용을 다루기에는 부족하다.

Method: MapAgent는 고수준 계획자가 복잡한 쿼리를 하위 목표로 분해하고, 이에 맞는 전문화된 모듈로 라우팅하며, 도구가 많은 모듈을 위해 전용 맵 도구 에이전트를 설계하여 API를 병렬로 능동적으로 조율한다.

Result: MapAgent는 네 가지 다양한 지리공간 벤치마크에서 기존의 도구 증강 및 에이전트 기준선에 비해 상당한 성장을 보여준다.

Conclusion: MapAgent는 지리공간 작업에서 계획과 실행을 분리하여 도구 선택 정확도를 개선하고 인지 부담을 줄인다.

Abstract: Agentic AI has significantly extended the capabilities of large language
models (LLMs) by enabling complex reasoning and tool use. However, most
existing frameworks are tailored to domains such as mathematics, coding, or web
automation, and fall short on geospatial tasks that require spatial reasoning,
multi-hop planning, and real-time map interaction. To address these challenges,
we introduce MapAgent, a hierarchical multi-agent plug-and-play framework with
customized toolsets and agentic scaffolds for map-integrated geospatial
reasoning. Unlike existing flat agent-based approaches that treat tools
uniformly-often overwhelming the LLM when handling similar but subtly different
geospatial APIs-MapAgent decouples planning from execution. A high-level
planner decomposes complex queries into subgoals, which are routed to
specialized modules. For tool-heavy modules-such as map-based services-we then
design a dedicated map-tool agent that efficiently orchestrates related APIs
adaptively in parallel to effectively fetch geospatial data relevant for the
query, while simpler modules (e.g., solution generation or answer extraction)
operate without additional agent overhead. This hierarchical design reduces
cognitive load, improves tool selection accuracy, and enables precise
coordination across similar APIs. We evaluate MapAgent on four diverse
geospatial benchmarks-MapEval-Textual, MapEval-API, MapEval-Visual, and
MapQA-and demonstrate substantial gains over state-of-the-art tool-augmented
and agentic baselines. We open-source our framwork at
https://github.com/Hasebul/MapAgent.

</details>


### [8] [Proof2Silicon: Prompt Repair for Verified Code and Hardware Generation via Reinforcement Learning](https://arxiv.org/abs/2509.06239)
*Manvi Jha,Jiaxin Wan,Deming Chen*

Main category: cs.AI

TL;DR: 이 논문은 자연어 사양에서 직접 하드웨어를 생성할 수 있는 종단 간 합성 프레임워크인 Proof2Silicon을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 생성하는 코드가 형식 검증을 통과하지 못하는 문제를 해결하고자 하였다.

Method: PREFACE 흐름을 통합하여 자연어 사양으로부터 correctness-by-construction 하드웨어를 생성하는 Proof2Silicon을 개발하였다.

Result: PREFACE의 RL 기반 프롬프트 최적화가 LLM 전반에 걸쳐 Dafny 검증 성공률을 21% 향상시켰으며, Proof2Silicon은 하드웨어 합성 성공률을 72% 달성했다.

Conclusion: 자연어 사양과 실리콘 실현을 연결하는 강력하고 자동화된 LLM 기반 형식 검증 하드웨어 합성 파이프라인을 구축하였다.

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
automated code generation but frequently produce code that fails formal
verification, an essential requirement for hardware and safety-critical
domains. To overcome this fundamental limitation, we previously proposed
PREFACE, a model-agnostic framework based on reinforcement learning (RL) that
iteratively repairs the prompts provided to frozen LLMs, systematically
steering them toward generating formally verifiable Dafny code without costly
fine-tuning. This work presents Proof2Silicon, a novel end-to-end synthesis
framework that embeds the previously proposed PREFACE flow to enable the
generation of correctness-by-construction hardware directly from natural
language specifications. Proof2Silicon operates by: (1) leveraging PREFACE's
verifier-driven RL agent to optimize prompt generation iteratively, ensuring
Dafny code correctness; (2) automatically translating verified Dafny programs
into synthesizable high-level C using Dafny's Python backend and PyLog; and (3)
employing Vivado HLS to produce RTL implementations. Evaluated rigorously on a
challenging 100-task benchmark, PREFACE's RL-guided prompt optimization
consistently improved Dafny verification success rates across diverse LLMs by
up to 21%. Crucially, Proof2Silicon achieved an end-to-end hardware synthesis
success rate of up to 72%, generating RTL designs through Vivado HLS synthesis
flows. These results demonstrate a robust, scalable, and automated pipeline for
LLM-driven, formally verified hardware synthesis, bridging natural-language
specification and silicon realization.

</details>


### [9] [REMI: A Novel Causal Schema Memory Architecture for Personalized Lifestyle Recommendation Agents](https://arxiv.org/abs/2509.06269)
*Vishal Raman,Vijai Aravindh R,Abhijith Ragav*

Main category: cs.AI

TL;DR: REMI라는 개인화된 멀티모달 생활 보조기구의 causal schema memory 아키텍처를 제안하여 사용자 맞춤형 추천 기능을 강화함.


<details>
  <summary>Details</summary>
Motivation: 개인화된 AI 어시스턴트는 복잡한 개인 데이터와 인과 지식을 통합하는 데 어려움을 겪고 있어, 설명력이 결여된 일반적인 조언을 제공한다.

Method: REMI는 개인 인과 지식 그래프, 인과 추론 엔진, 스키마 기반 계획 모듈을 통합하는 아키텍처로, 개인의 생활 사건과 습관의 인과 그래프를 사용하여 목표 지향적인 인과 순회를 수행하고, 외부 지식과 가설적 추론으로 풍부해진 플랜 스키마를 검색하여 맞춤형 행동 계획을 생성한다.

Result: CSM 기반 에이전트는 기준 LLM 에이전트에 비해 더욱 맥락을 고려한 사용자 맞춤형 추천을 제공할 수 있음을 보여준다.

Conclusion: 이 연구는 개인화된 에이전트에서 메모리 증강 인과 추론에 대한 새로운 접근 방식을 제시하며, 투명하고 신뢰할 수 있는 AI 생활 어시스턴트 개발을 진전시킨다.

Abstract: Personalized AI assistants often struggle to incorporate complex personal
data and causal knowledge, leading to generic advice that lacks explanatory
power. We propose REMI, a Causal Schema Memory architecture for a multimodal
lifestyle agent that integrates a personal causal knowledge graph, a causal
reasoning engine, and a schema based planning module. The idea is to deliver
explainable, personalized recommendations in domains like fashion, personal
wellness, and lifestyle planning. Our architecture uses a personal causal graph
of the user's life events and habits, performs goal directed causal traversals
enriched with external knowledge and hypothetical reasoning, and retrieves
adaptable plan schemas to generate tailored action plans. A Large Language
Model orchestrates these components, producing answers with transparent causal
explanations. We outline the CSM system design and introduce new evaluation
metrics for personalization and explainability, including Personalization
Salience Score and Causal Reasoning Accuracy, to rigorously assess its
performance. Results indicate that CSM based agents can provide more context
aware, user aligned recommendations compared to baseline LLM agents. This work
demonstrates a novel approach to memory augmented, causal reasoning in
personalized agents, advancing the development of transparent and trustworthy
AI lifestyle assistants.

</details>


### [10] [TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning](https://arxiv.org/abs/2509.06278)
*Chuang Jiang,Mingyue Cheng,Xiaoyu Tao,Qingyang Mao,Jie Ouyang,Qi Liu*

Main category: cs.AI

TL;DR: TableMind는 다단계 도구 호출을 자율적으로 수행하고, 데이터 분석을 위한 안전한 샌드박스 환경에서 코드 작성 및 실행, 전략 적응을 위한 계획 및 자기 반성 기능을 갖춘 LLM 기반 테이블 추론 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: 표 형식 데이터 처리는 금융, 의료 및 과학 연구 분야에서 중요하다. 기존의 텍스트 기반 방법은 복잡한 수치 계산 및 세밀한 작업에서 어려움을 겪는다.

Method: TableMind는 강력한 사전 훈련된 언어 모델 위에 두 단계의 미세 조정 패러다임을 채택하여 효과적인 도구 사용 패턴을 위한 감독 미세 조정과 다목적 전략 최적화를 위한 강화 미세 조정을 수행한다.

Result: TableMind는 경쟁 기준 대비 우수한 성능을 보여주었으며, 추론 정확성과 계산 정밀도에서 상당한 향상을 달성한다.

Conclusion: RAPO는 고품질 경로의 출력 확률이 저품질 경로보다 낮을 때 고품질 경로의 업데이트 가중치를 늘림으로써 모델을 보다 일관되게 개선된 정답으로 유도하는 데 도움을 준다.

Abstract: Table reasoning is crucial for leveraging structured data in domains such as
finance, healthcare, and scientific research. While large language models
(LLMs) show promise in multi-step reasoning, purely text-based methods often
struggle with the complex numerical computations and fine-grained operations
inherently required in this task. Tool-integrated reasoning improves
computational accuracy via explicit code execution, yet existing systems
frequently rely on rigid patterns, supervised imitation, and lack true
autonomous adaptability. In this paper, we present TableMind, an LLM-driven
table reasoning agent that (i) autonomously performs multi-turn tool
invocation, (ii) writes and executes data-analyzing code in a secure sandbox
environment for data analysis and precise numerical reasoning, and (iii)
exhibits high-level capabilities such as planning and self-reflection to adapt
strategies. To realize these capabilities, we adopt a two-stage fine-tuning
paradigm built on top of a powerful pre-trained language model: supervised
fine-tuning on high-quality reasoning trajectories to establish effective tool
usage patterns, followed by reinforcement fine-tuning to optimize
multi-objective strategies. In particular, we propose Rank-Aware Policy
Optimization (RAPO), which increases the update weight of high-quality
trajectories when their output probabilities are lower than those of
low-quality ones, thereby guiding the model more consistently toward better and
more accurate answers. Extensive experiments on several mainstream benchmarks
demonstrate that TableMind achieves superior performance compared to
competitive baselines, yielding substantial gains in both reasoning accuracy
and computational precision.

</details>


### [11] [SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents](https://arxiv.org/abs/2509.06283)
*Xuan-Phi Nguyen,Shrey Pandit,Revanth Gangi Reddy,Austin Xu,Silvio Savarese,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 이 논문은 복잡한 추론 및 도구 사용 능력을 갖춘 자율 단일 에이전트 모델을 개발하여 Deep Research(DR) 응용 프로그램에서의 성능을 향상시키는 데 초점을 맞추고 있다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델에 복잡한 추론 및 도구 사용 능력을 부여하는 것이 에이전틱 AI 연구의 주요 초점이 되고 있으며, 이는 중요한 응용 프로그램의 잠금을 해제하는 데 필수적이다.

Method: 우리는 맥락에 따라 다음 행동을 동적으로 결정하는 자율 단일 에이전트 모델을 개발하고, 지속적인 강화 학습(RL)을 통해 추론 최적화 모델을 훈련한다.

Result: 최고 성능의 변형인 SFR-DR-20B는 Humanity's Last Exam 벤치마크에서 최대 28.7%의 성과를 달성하였다.

Conclusion: 제안하는 방법론에 대한 추가적인 통찰력을 제공하기 위해 주요 분석 실험을 수행하였다.

Abstract: Equipping large language models (LLMs) with complex, interleaved reasoning
and tool-use capabilities has become a key focus in agentic AI research,
especially with recent advances in reasoning-oriented (``thinking'') models.
Such capabilities are key to unlocking a number of important applications. One
such application is Deep Research (DR), which requires extensive search and
reasoning over many sources. Our work in this paper focuses on the development
of native Autonomous Single-Agent models for DR featuring minimal web crawling
and Python tool integration. Unlike multi-agent systems, where agents take up
pre-defined roles and are told what to do at each step in a static workflow, an
autonomous single-agent determines its next action dynamically based on
context, without manual directive. While prior work has proposed training
recipes for base or instruction-tuned LLMs, we focus on continual reinforcement
learning (RL) of reasoning-optimized models to further enhance agentic skills
while preserving reasoning ability. Towards this end, we propose a simple RL
recipe with entirely synthetic data, which we apply to various open-source
LLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity's Last Exam
benchmark. In addition, we conduct key analysis experiments to provide more
insights into our methodologies.

</details>


### [12] [From Implicit Exploration to Structured Reasoning: Leveraging Guideline and Refinement for LLMs](https://arxiv.org/abs/2509.06284)
*Jiaxiang Chen,Zhuo Wang,Mingxi Zou,Zhucong Li,Zhijian Zhou,Song Wang,Zenglin Xu*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델의 불안정한 추론 경로 문제를 해결하기 위해 암묵적 탐색에서 구조적 추론으로 전환하는 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델은 다양한 작업에서 우수한 성능을 보여주지만, 현재 방법은 불안정한 추론 경로와 오류 수정 부족이라는 문제가 있습니다.

Method: 구조적 추론 패턴을 성공적인 경로에서 추출하고 실패에서 반영 신호를 수집합니다. 추론 중 모델은 이러한 가이드를 단계별로 따르며, 각 단계 후 오류를 수정하고 추론 과정을 안정시키기 위해 세심한 조정을 진행합니다.

Result: BBH 및 추가 4개 벤치마크(GSM8K, MATH-500, MBPP, HumanEval)에서 우리의 방법이 다양한 추론 작업에서 강력한 기준선보다 일관되게 우수한 성과를 보였습니다.

Conclusion: 단계별 실행과 세심한 조정이 결합된 구조적 추론은 안정성과 일반화를 개선하며, 가이드는 다양한 도메인에서 잘 전이되고 교차 모델 협업을 유연하게 지원합니다.

Abstract: Large language models (LLMs) have advanced general-purpose reasoning, showing
strong performance across diverse tasks. However, existing methods often rely
on implicit exploration, where the model follows stochastic and unguided
reasoning paths-like walking without a map. This leads to unstable reasoning
paths, lack of error correction, and limited learning from past experience. To
address these issues, we propose a framework that shifts from implicit
exploration to structured reasoning through guideline and refinement. First, we
extract structured reasoning patterns from successful trajectories and
reflective signals from failures. During inference, the model follows these
guidelines step-by-step, with refinement applied after each step to correct
errors and stabilize the reasoning process. Experiments on BBH and four
additional benchmarks (GSM8K, MATH-500, MBPP, HumanEval) show that our method
consistently outperforms strong baselines across diverse reasoning tasks.
Structured reasoning with stepwise execution and refinement improves stability
and generalization, while guidelines transfer well across domains and flexibly
support cross-model collaboration, matching or surpassing supervised
fine-tuning in effectiveness and scalability.

</details>


### [13] [Evaluating Multi-Turn Bargain Skills in LLM-Based Seller Agent](https://arxiv.org/abs/2509.06341)
*Issue Yishu Wang,Kakam Chong,Xiaofeng Wang,Xu Yan,DeXin Kong,Chen Ju,Ming Chen,Shuai Xiao,Shuguang Han,jufeng chen*

Main category: cs.AI

TL;DR: 온라인 중고 시장에서 다중 턴 협상은 판매자와 구매자 상호작용의 중요한 부분이다. 본 연구에서는 판매 대리인이 판매자를 대신해 협상할 수 있도록 대화에서 구매자의 의도를 추적하고 해석하는 능력을 평가하는 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 중고 시장에서 판매자와 구매자 간의 효과적인 상호작용을 위해 다중 턴 협상이 필요하다.

Method: 판매 대리인의 협상 능력을 측정하기 위한 다중 턴 평가 프레임워크를 도입하고, 구매자의 의도를 추출하고 추적할 수 있는지를 평가한다.

Result: 622개 카테고리, 9,892개 제품, 3,014개 과제를 포함하는 대규모 전자상거래 협상 벤치마크와 인지 이론에 기반한 턴 수준 평가 프레임워크를 소개한다.

Conclusion: 자동화된 파이프라인을 통해 대화 데이터에서 신뢰할 수 있는 의도를 추출할 수 있는 방법을 제안한다.

Abstract: In online second-hand marketplaces, multi-turn bargaining is a crucial part
of seller-buyer interactions. Large Language Models (LLMs) can act as seller
agents, negotiating with buyers on behalf of sellers under given business
constraints. A critical ability for such agents is to track and accurately
interpret cumulative buyer intents across long negotiations, which directly
impacts bargaining effectiveness. We introduce a multi-turn evaluation
framework for measuring the bargaining ability of seller agents in e-commerce
dialogues. The framework tests whether an agent can extract and track buyer
intents. Our contributions are: (1) a large-scale e-commerce bargaining
benchmark spanning 622 categories, 9,892 products, and 3,014 tasks; (2) a
turn-level evaluation framework grounded in Theory of Mind (ToM) with annotated
buyer intents, moving beyond outcome-only metrics; and (3) an automated
pipeline that extracts reliable intent from massive dialogue data.

</details>


### [14] [A data-driven discretized CS:GO simulation environment to facilitate strategic multi-agent planning research](https://arxiv.org/abs/2509.06355)
*Yunzhe Wang,Volkan Ustun,Chris McGroarty*

Main category: cs.AI

TL;DR: DECOY는 고충실도 세부 사항과 계산 효율성의 균형을 맞춘 새로운 다중 에이전트 시뮬레이터로, 전략적 장기 계획을 3D 환경에서 고수준의 이산화된 시뮬레이션으로 추상화한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 다중 에이전트 상호작용을 위한 현대 시뮬레이션 환경은 높은 세부 사항과 계산 효율성 사이에서 균형을 맞춰야 함.

Method: DECOY는 CS:GO를 테스트베드로 사용하여 움직임 결정만으로 게임플레이를 정확하게 시뮬레이션하고, 연속 상태와 행동을 간소화하여 이산화하는 웨이포인트 시스템을 사용한다.

Result: DECOY에서 생성된 리플레이는 원본 게임에서 관찰된 것과 밀접하게 일치한다.

Conclusion: 우리의 공개된 시뮬레이션 환경은 전략적 다중 에이전트 계획 및 행동 생성 연구를 발전시키는 데 귀중한 도구를 제공한다.

Abstract: Modern simulation environments for complex multi-agent interactions must
balance high-fidelity detail with computational efficiency. We present DECOY, a
novel multi-agent simulator that abstracts strategic, long-horizon planning in
3D terrains into high-level discretized simulation while preserving low-level
environmental fidelity. Using Counter-Strike: Global Offensive (CS:GO) as a
testbed, our framework accurately simulates gameplay using only movement
decisions as tactical positioning -- without explicitly modeling low-level
mechanics such as aiming and shooting. Central to our approach is a waypoint
system that simplifies and discretizes continuous states and actions, paired
with neural predictive and generative models trained on real CS:GO tournament
data to reconstruct event outcomes. Extensive evaluations show that replays
generated from human data in DECOY closely match those observed in the original
game. Our publicly available simulation environment provides a valuable tool
for advancing research in strategic multi-agent planning and behavior
generation.

</details>


### [15] [Tree of Agents: Improving Long-Context Capabilities of Large Language Models through Multi-Perspective Reasoning](https://arxiv.org/abs/2509.06436)
*Song Yu,Xiaofei Xu,Ke Deng,Li Li,Lin Tian*

Main category: cs.AI

TL;DR: Tree of Agents (TOA)는 입력을 분할하여 독립적인 에이전트가 처리하도록 하는 다중 에이전트 추론 프레임워크로, 긴 맥락 작업에서의 정보 손실 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 긴 컨텍스트 작업을 처리할 때 대형 언어 모델이 겪는 정보 이용 문제를 해결하고자 함.

Method: 입력을 분할하여 독립적으로 처리하는 에이전트를 사용하는 Tree of Agents (TOA) 프레임워크를 제안함.

Result: TOA는 여러 기준선 모델보다 우수한 성능을 보이며 최신 상업 모델과 비슷한 성능을 나타냄.

Conclusion: TOA는 긴 맥락 작업에서 효과적으로 위치 편향을 완화하고 환각을 줄이는데 기여함.

Abstract: Large language models (LLMs) face persistent challenges when handling
long-context tasks, most notably the lost in the middle issue, where
information located in the middle of a long input tends to be underutilized.
Some existing methods that reduce input have the risk of discarding key
information, while others that extend context windows often lead to attention
dispersion. To address these limitations, we propose Tree of Agents (TOA), a
multi-agent reasoning framework that segments the input into chunks processed
by independent agents. Each agent generates its local cognition, then agents
dynamically exchange information for collaborative reasoning along
tree-structured paths. TOA enables agents to probe different reasoning orders
for multi-perspective understanding, effectively mitigating position bias and
reducing hallucinations. To improve processing efficiency, we incorporate
prefix-hash caching and adaptive pruning strategies, achieving significant
performance improvements with comparable API overhead. Experiments show that
TOA, powered by compact LLaMA3.1-8B, significantly outperforms multiple
baselines and demonstrates comparable performance to the latest and much larger
commercial models, such as Gemini1.5-pro, on various long-context tasks. Code
is available at https://github.com/Aireduce952/Tree-of-Agents.

</details>


### [16] [HyFedRAG: A Federated Retrieval-Augmented Generation Framework for Heterogeneous and Privacy-Sensitive Data](https://arxiv.org/abs/2509.06444)
*Cheng Qian,Hainan Zhang,Yongxin Tong,Hong-Wei Zheng,Zhiming Zheng*

Main category: cs.AI

TL;DR: HyFedRAG는 하이브리드 데이터 모달리티를 위한 통합 연합 RAG 프레임워크로, 다양한 데이터 소스에서 데이터 프라이버시를 유지하면서도 효과적으로 작동한다.


<details>
  <summary>Details</summary>
Motivation: 의료 데이터의 이질성과 프라이버시 민감성 때문에, clinicians은 기존 클라우드 기반 RAG 시스템에서 다양한 형식과 엣지 장치를 처리하는 데 어려움을 겪는다.

Method: HyFedRAG는 Flower에 기반한 엣지-클라우드 협업 RAG 프레임워크를 설계하며, 구조적 SQL 데이터, 반구조적 지식 그래프, 비구조적 문서 쿼리를 지원한다.

Result: PMC-Patients 실험 결과, HyFedRAG는 검색 품질, 생성 일관성 및 시스템 효율성 면에서 기존 기초 모델보다 우수한 성능을 보인다.

Conclusion: HyFedRAG는 구조적 이질적 데이터에 대한 확장 가능하고 프라이버시를 준수하는 RAG 솔루션을 제공하며, 민감하고 다양한 데이터 환경에서 LLM의 잠재력을 극대화한다.

Abstract: Centralized RAG pipelines struggle with heterogeneous and privacy-sensitive
data, especially in distributed healthcare settings where patient data spans
SQL, knowledge graphs, and clinical notes. Clinicians face difficulties
retrieving rare disease cases due to privacy constraints and the limitations of
traditional cloud-based RAG systems in handling diverse formats and edge
devices. To address this, we introduce HyFedRAG, a unified and efficient
Federated RAG framework tailored for Hybrid data modalities. By leveraging an
edge-cloud collaborative mechanism, HyFedRAG enables RAG to operate across
diverse data sources while preserving data privacy. Our key contributions are:
(1) We design an edge-cloud collaborative RAG framework built on Flower, which
supports querying structured SQL data, semi-structured knowledge graphs, and
unstructured documents. The edge-side LLMs convert diverse data into
standardized privacy-preserving representations, and the server-side LLMs
integrates them for global reasoning and generation. (2) We integrate
lightweight local retrievers with privacy-aware LLMs and provide three
anonymization tools that enable each client to produce semantically rich,
de-identified summaries for global inference across devices. (3) To optimize
response latency and reduce redundant computation, we design a three-tier
caching strategy consisting of local cache, intermediate representation cache,
and cloud inference cache. Experimental results on PMC-Patients demonstrate
that HyFedRAG outperforms existing baselines in terms of retrieval quality,
generation consistency, and system efficiency. Our framework offers a scalable
and privacy-compliant solution for RAG over structural-heterogeneous data,
unlocking the potential of LLMs in sensitive and diverse data environments.

</details>


### [17] [MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents](https://arxiv.org/abs/2509.06477)
*Pengxiang Zhao,Guangyi Liu,Yaozhen Liang,Weiqing He,Zhengxi Lu,Yuehao Huang,Yaxuan Guo,Kexin Zhang,Hao Wang,Liang Liu,Yong Liu*

Main category: cs.AI

TL;DR: 이 논문은 모바일 도메인에 초점을 맞춘 GUI-단축키 하이브리드 에이전트의 평가를 위한 벤치마크인 MAS-Bench를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 스마트폰과 컴퓨터와 같은 다양한 플랫폼에서 GUI 에이전트의 효율성을 높이기 위해 하이브리드 패러다임이 필요하다.

Method: MAS-Bench는 11개의 실제 애플리케이션에 걸쳐 139개의 복잡한 작업을 사용하여 단축키를 자동으로 생성할 수 있는 에이전트의 능력을 평가한다.

Result: 하이브리드 에이전트는 GUI 전용 에이전트보다 훨씬 높은 성공률과 효율성을 달성하였다.

Conclusion: MAS-Bench는 에이전트의 단축키 생성 능력을 평가하는 효과적인 방법을 보여주며, 더 효율적이고 강력한 지능형 에이전트를 만드는 미래 발전을 위한 기초 플랫폼을 제공한다.

Abstract: To enhance the efficiency of GUI agents on various platforms like smartphones
and computers, a hybrid paradigm that combines flexible GUI operations with
efficient shortcuts (e.g., API, deep links) is emerging as a promising
direction. However, a framework for systematically benchmarking these hybrid
agents is still underexplored. To take the first step in bridging this gap, we
introduce MAS-Bench, a benchmark that pioneers the evaluation of GUI-shortcut
hybrid agents with a specific focus on the mobile domain. Beyond merely using
predefined shortcuts, MAS-Bench assesses an agent's capability to autonomously
generate shortcuts by discovering and creating reusable, low-cost workflows. It
features 139 complex tasks across 11 real-world applications, a knowledge base
of 88 predefined shortcuts (APIs, deep-links, RPA scripts), and 7 evaluation
metrics. The tasks are designed to be solvable via GUI-only operations, but can
be significantly accelerated by intelligently embedding shortcuts. Experiments
show that hybrid agents achieve significantly higher success rates and
efficiency than their GUI-only counterparts. This result also demonstrates the
effectiveness of our method for evaluating an agent's shortcut generation
capabilities. MAS-Bench fills a critical evaluation gap, providing a
foundational platform for future advancements in creating more efficient and
robust intelligent agents.

</details>


### [18] [MORSE: Multi-Objective Reinforcement Learning via Strategy Evolution for Supply Chain Optimization](https://arxiv.org/abs/2509.06490)
*Niki Kotecha,Ehecatl Antonio del Rio Chanona*

Main category: cs.AI

TL;DR: 이 논문에서는 공급망 관리에서의 다중 목표 최적화를 위한 강화학습과 다목적 진화 알고리즘을 결합한 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 공급망 관리에서 비용 절감, 서비스 수준 향상 및 환경 지속 가능성 등 다수의 상충 목표를 균형 있게 조정하는 것이 필요합니다.

Method: 강화학습(RL)과 다목적 진화 알고리즘(MOEAs)을 결합하여 불확실한 환경에서의 동적 다중 목표 최적화를 수행하는 접근 방식을 제안합니다.

Result: 사례 연구를 통해 본 접근법은 공급망의 역동성에 대응 능력이 뛰어나고, 재고 관리 사례에서 최신 기법보다 성능이 뛰어남을 보여주었습니다.

Conclusion: 제안된 전략은 의사결정 효율성을 개선할 뿐만 아니라 불확실성을 관리하고 공급망에서 성능을 최적화하는 보다 강력한 프레임워크를 제공합니다.

Abstract: In supply chain management, decision-making often involves balancing multiple
conflicting objectives, such as cost reduction, service level improvement, and
environmental sustainability. Traditional multi-objective optimization methods,
such as linear programming and evolutionary algorithms, struggle to adapt in
real-time to the dynamic nature of supply chains. In this paper, we propose an
approach that combines Reinforcement Learning (RL) and Multi-Objective
Evolutionary Algorithms (MOEAs) to address these challenges for dynamic
multi-objective optimization under uncertainty. Our method leverages MOEAs to
search the parameter space of policy neural networks, generating a Pareto front
of policies. This provides decision-makers with a diverse population of
policies that can be dynamically switched based on the current system
objectives, ensuring flexibility and adaptability in real-time decision-making.
We also introduce Conditional Value-at-Risk (CVaR) to incorporate
risk-sensitive decision-making, enhancing resilience in uncertain environments.
We demonstrate the effectiveness of our approach through case studies,
showcasing its ability to respond to supply chain dynamics and outperforming
state-of-the-art methods in an inventory management case study. The proposed
strategy not only improves decision-making efficiency but also offers a more
robust framework for managing uncertainty and optimizing performance in supply
chains.

</details>


### [19] [Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers](https://arxiv.org/abs/2509.06493)
*Ran Xin,Zeyu Zheng,Yanchen Nie,Kun Yuan,Xia Xiao*

Main category: cs.AI

TL;DR: 이 논문은 자동 정리 증명을 위한 LLM의 확장 문제를 해결하기 위해 BFS-Prover-V2 시스템을 소개하며, 멀티 턴 off-policy RL 프레임워크와 계획자 강화 다중 에이전트 검색 아키텍처를 통해 성능을 개선하고 추론 시간을 확장합니다.


<details>
  <summary>Details</summary>
Motivation: 이 논문의 동기는 LLM을 자동 정리 증명에 통합하는 데에 있어 훈련 시간의 강화 학습(RL)과 추론 시간의 컴퓨팅을 동시에 확장하는 문제를 해결하는 것입니다.

Method: 본 논문에서는 AlphaZero의 원리에 영감을 받은 멀티 턴 off-policy RL 프레임워크와 다중 에이전트 검색 아키텍처를 통해 기하학적 정리를 간단한 부 목표로 분해하는 방식으로 효과적으로 성능을 향상시킵니다.

Result: BFS-Prover-V2는 MiniF2F와 ProofNet 테스트 세트에서 각각 95.08%와 41.4%의 성과를 달성합니다.

Conclusion: 제시된 RL 및 추론 기술은 형식 수학 분야에서 시연되었으나, 장기간의 다중 턴 추론 및 복잡한 검색을 요구하는 다른 영역에도 적용 가능성이 있습니다.

Abstract: The integration of Large Language Models (LLMs) into automated theorem
proving has shown immense promise, yet is fundamentally constrained by
challenges in scaling up both training-time reinforcement learning (RL) and
inference-time compute. This paper introduces \texttt{BFS-Prover-V2}, a system
designed to address this dual scaling problem. We present two primary
innovations. The first is a novel multi-turn off-policy RL framework for
continually improving the performance of LLM step-prover at training time. This
framework, inspired by the principles of AlphaZero, utilizes a multi-stage
expert iteration pipeline featuring adaptive tactic-level data filtering and
periodic retraining to surmount the performance plateaus that typically curtail
long-term RL in LLM-based agents. The second innovation is a planner-enhanced
multi-agent search architecture that scales reasoning capabilities at inference
time. This architecture employs a general reasoning model as a high-level
planner to iteratively decompose complex theorems into a sequence of simpler
subgoals. This hierarchical approach substantially reduces the search space,
enabling a team of parallel prover agents to collaborate efficiently by
leveraging a shared proof cache. We demonstrate that this dual approach to
scaling yields state-of-the-art results on established formal mathematics
benchmarks. \texttt{BFS-Prover-V2} achieves 95.08\% and 41.4\% on the MiniF2F
and ProofNet test sets respectively. While demonstrated in the domain of formal
mathematics, the RL and inference techniques presented in this work are of
broader interest and may be applied to other domains requiring long-horizon
multi-turn reasoning and complex search.

</details>


### [20] [Reinforcement Learning Foundations for Deep Research Systems: A Survey](https://arxiv.org/abs/2509.06733)
*Wenjun Li,Zhi Chen,Jingru Lin,Hannan Cao,Wei Han,Sheng Liang,Zhi Zhang,Kuicai Dong,Dexun Li,Chen Zhang,Yong Liu*

Main category: cs.AI

TL;DR: 이 논문은 심층 연구 시스템의 RL 기초에 대한 첫 번째 설문조사로, 여러 축을 기준으로 작업을 체계화합니다.


<details>
  <summary>Details</summary>
Motivation: 심층 연구 시스템에서 에이전틱 AI의 효율성을 높이기 위한 필요성.

Method: DeepSeek-R1 이후의 연구를 데이터 합성 및 큐레이션, RL 방법, 에이전틱 RL 훈련 시스템 세 가지 축으로 체계화.

Result: 에이전트 아키텍처, 조정, 평가 및 벤치마크를 포함한 자료를 다룬다.

Conclusion: RL을 통한 강력하고 투명한 심층 연구 에이전트를 훈련하기 위한 실용적인 가이드를 제공한다.

Abstract: Deep research systems, agentic AI that solve complex, multi-step tasks by
coordinating reasoning, search across the open web and user files, and tool
use, are moving toward hierarchical deployments with a Planner, Coordinator,
and Executors. In practice, training entire stacks end-to-end remains
impractical, so most work trains a single planner connected to core tools such
as search, browsing, and code. While SFT imparts protocol fidelity, it suffers
from imitation and exposure biases and underuses environment feedback.
Preference alignment methods such as DPO are schema and proxy-dependent,
off-policy, and weak for long-horizon credit assignment and multi-objective
trade-offs. A further limitation of SFT and DPO is their reliance on human
defined decision points and subskills through schema design and labeled
comparisons. Reinforcement learning aligns with closed-loop, tool-interaction
research by optimizing trajectory-level policies, enabling exploration,
recovery behaviors, and principled credit assignment, and it reduces dependence
on such human priors and rater biases.
  This survey is, to our knowledge, the first dedicated to the RL foundations
of deep research systems. It systematizes work after DeepSeek-R1 along three
axes: (i) data synthesis and curation; (ii) RL methods for agentic research
covering stability, sample efficiency, long context handling, reward and credit
design, multi-objective optimization, and multimodal integration; and (iii)
agentic RL training systems and frameworks. We also cover agent architecture
and coordination, as well as evaluation and benchmarks, including recent QA,
VQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We
distill recurring patterns, surface infrastructure bottlenecks, and offer
practical guidance for training robust, transparent deep research agents with
RL.

</details>


### [21] [VehicleWorld: A Highly Integrated Multi-Device Environment for Intelligent Vehicle Interaction](https://arxiv.org/abs/2509.06736)
*Jie Yang,Jiajun Chen,Zhangyue Yin,Shuo Chen,Yuxin Wang,Yiran Guo,Yuan Li,Yining Zheng,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: 본 논문에서는 자동차 도메인에 적용할 수 있는 VehicleWorld라는 새로운 환경을 소개하고, 이에 기반한 SFC 방식이 전통적인 FC 방식보다 우수하다는 것을 입증합니다.


<details>
  <summary>Details</summary>
Motivation: 지능형 차량 조종석은 복잡한 서브시스템 간의 협력을 요구하기 때문에 API 에이전트에게 독특한 도전을 제공합니다.

Method: VehicleWorld라는 포괄적인 환경을 소개하며, 이 환경은 30개의 모듈, 250개의 API 및 680개의 속성을 포함하고 있습니다. 또한, 직접적인 상태 예측을 통한 SFC 방식이 도입되었습니다.

Result: 실험 결과, SFC 방식이 전통적인 FC 방식보다 실행 정확도가 높고 지연 시간이 감소하는 성과를 보였습니다.

Conclusion: 우리는 모든 구현 코드를 Github에 공개하여, 연구 결과가 널리 활용될 수 있도록 하였습니다.

Abstract: Intelligent vehicle cockpits present unique challenges for API Agents,
requiring coordination across tightly-coupled subsystems that exceed typical
task environments' complexity. Traditional Function Calling (FC) approaches
operate statelessly, requiring multiple exploratory calls to build
environmental awareness before execution, leading to inefficiency and limited
error recovery. We introduce VehicleWorld, the first comprehensive environment
for the automotive domain, featuring 30 modules, 250 APIs, and 680 properties
with fully executable implementations that provide real-time state information
during agent execution. This environment enables precise evaluation of vehicle
agent behaviors across diverse, challenging scenarios. Through systematic
analysis, we discovered that direct state prediction outperforms function
calling for environmental control. Building on this insight, we propose
State-based Function Call (SFC), a novel approach that maintains explicit
system state awareness and implements direct state transitions to achieve
target conditions. Experimental results demonstrate that SFC significantly
outperforms traditional FC approaches, achieving superior execution accuracy
and reduced latency. We have made all implementation code publicly available on
Github https://github.com/OpenMOSS/VehicleWorld.

</details>


### [22] [RAFFLES: Reasoning-based Attribution of Faults for LLM Systems](https://arxiv.org/abs/2509.06822)
*Chenyang Zhu,Spencer Hong,Jingyu Wu,Kushal Chawla,Charlotte Tang,Youbing Yin,Nathan Wolfe,Erin Babinsky,Daben Liu*

Main category: cs.AI

TL;DR: RAFFLES는 장기적인 LLM 에이전트 시스템의 평가를 위한 새로운 아키텍처로, 논리적 추론과 반복적 개선을 포함하여 시스템의 결함을 분석한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트 시스템의 발전에서 결함을 식별하고 그 원인을 이해하는 데 큰 어려움이 있으며, 기존의 평가 능력은 단일 측정 지표에 국한되어 있다.

Method: RAFFLES는 중앙에서 결함을 조사하는 심사관과 시스템 구성 요소 및 심사관의 추론 품질을 평가하는 전문 평가자들로 구성된 반복적이고 다중 구성 요소 파이프라인으로 운영된다.

Result: RAFFLES는 Who&When 데이터셋을 사용하여 여러 기준선에 대해 테스트했으며, 알고리즘적으로 생성된 데이터셋에서 에이전트-단계 결함 쌍 정확도가 43% 이상으로 이전의 16.6%에서 크게 향상되었고, 수작업 데이터셋에서는 20% 이상을 달성하였다.

Conclusion: RAFFLES는 수동적 인간 리뷰 대신 자율 시스템에 대한 자동화된 결함 감지를 도입하기 위한 중요한 단계를 보여준다.

Abstract: We have reached a critical roadblock in the development and enhancement of
long-horizon, multi-component LLM agentic systems: it is incredibly tricky to
identify where these systems break down and why. Evaluation capabilities that
currently exist today (e.g., single pass LLM-as-a-judge) are limited in that
they often focus on individual metrics or capabilities, end-to-end outcomes,
and are narrowly grounded on the preferences of humans. We argue that to match
the agentic capabilities, evaluation frameworks must also be able to reason,
probe, iterate, and understand the complex logic passing through these systems
over long horizons. In this paper, we present RAFFLES - an evaluation
architecture that incorporates reasoning and iterative refinement.
Specifically, RAFFLES operates as an iterative, multi-component pipeline, using
a central Judge to systematically investigate faults and a set of specialized
Evaluators to assess not only the system's components but also the quality of
the reasoning by the Judge itself, thereby building a history of hypotheses. We
tested RAFFLES against several baselines on the Who&When dataset, a benchmark
designed to diagnose the "who" (agent) and "when" (step) of a system's failure.
RAFFLES outperforms these baselines, achieving an agent-step fault pair
accuracy of over 43% on the Algorithmically-Generated dataset (a substantial
increase from the previously published best of 16.6%) and over 20% on the
Hand-Crafted dataset (surpassing the previously published best of 8.8%). These
results demonstrate a key step towards introducing automated fault detection
for autonomous systems over labor-intensive manual human review.

</details>


### [23] [Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents](https://arxiv.org/abs/2509.06917)
*Jiacheng Miao,Joe R. Davis,Jonathan K. Pritchard,James Zou*

Main category: cs.AI

TL;DR: Paper2Agent는 연구 논문을 AI 에이전트로 변환하는 자동화된 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 연구 논문은 독자가 코드를 이해하고 자신의 연구에 적응시키는 데 상당한 노력을 들여야 하므로 확산과 재사용에 장벽을 만든다.

Method: Paper2Agent는 연구 논문과 관련 코드베이스를 체계적으로 분석하여 Model Context Protocol (MCP) 서버를 구축하고, 반복적으로 테스트를 생성하고 실행하여 MCP의 정밀성과 견고성을 개선한다.

Result: Paper2Agent는 신뢰할 수 있는 논문 에이전트를 생성하는 효과를 입증하였다. 이 에이전트는 AlphaGenome을 통해 유전자 변이를 해석하고, ScanPy 및 TISSUE를 기반으로 한 에이전트를 통해 단일 세포 및 공간 전사체 분석을 수행한다.

Conclusion: Paper2Agent는 정적 논문을 동적이고 상호작용하는 AI 에이전트로 변환하여 지식 확산의 새로운 패러다임을 도입하고 AI 공동 과학자 생태계의 기초를 제공한다.

Abstract: We introduce Paper2Agent, an automated framework that converts research
papers into AI agents. Paper2Agent transforms research output from passive
artifacts into active systems that can accelerate downstream use, adoption, and
discovery. Conventional research papers require readers to invest substantial
effort to understand and adapt a paper's code, data, and methods to their own
work, creating barriers to dissemination and reuse. Paper2Agent addresses this
challenge by automatically converting a paper into an AI agent that acts as a
knowledgeable research assistant. It systematically analyzes the paper and the
associated codebase using multiple agents to construct a Model Context Protocol
(MCP) server, then iteratively generates and runs tests to refine and robustify
the resulting MCP. These paper MCPs can then be flexibly connected to a chat
agent (e.g. Claude Code) to carry out complex scientific queries through
natural language while invoking tools and workflows from the original paper. We
demonstrate Paper2Agent's effectiveness in creating reliable and capable paper
agents through in-depth case studies. Paper2Agent created an agent that
leverages AlphaGenome to interpret genomic variants and agents based on ScanPy
and TISSUE to carry out single-cell and spatial transcriptomics analyses. We
validate that these paper agents can reproduce the original paper's results and
can correctly carry out novel user queries. By turning static papers into
dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for
knowledge dissemination and a foundation for the collaborative ecosystem of AI
co-scientists.

</details>


### [24] [Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference](https://arxiv.org/abs/2509.06942)
*Xiangwei Shen,Zhimin Li,Zhantao Yang,Shiyi Zhang,Yingfang Zhang,Donghao Li,Chunyu Wang,Qinglin Lu,Yansong Tang*

Main category: cs.AI

TL;DR: 본 연구는 인체 선호도에 직접적으로 맞춰진 확산 모델을 효율적으로 최적화하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 다단계 디노이징 방법이 계산 비용이 높고 미적 품질을 위해 보상 모델을 지속적으로 조정해야 하는 한계를 해결하고자 한다.

Method: Direct-Align라는 방법을 제안하여, 노이즈를 사전 정의하여 원본 이미지를 효과적으로 복원하고, SRPO를 통해 텍스트 조건 신호로 보상을 표현하여 온라인 보상 조정을 가능하게 한다.

Result: FLUX 모델을 최적화된 디노이징과 온라인 보상 조정으로 미세 조정하여 인체 평가에서 리얼리즘과 미적 품질을 3배 이상 향상시켰다.

Conclusion: 제안한 방법은 계산 비용을 줄이면서도 원하는 미적 품질을 유지하는 데 기여한다.

Abstract: Recent studies have demonstrated the effectiveness of directly aligning
diffusion models with human preferences using differentiable reward. However,
they exhibit two primary challenges: (1) they rely on multistep denoising with
gradient computation for reward scoring, which is computationally expensive,
thus restricting optimization to only a few diffusion steps; (2) they often
need continuous offline adaptation of reward models in order to achieve desired
aesthetic quality, such as photorealism or precise lighting effects. To address
the limitation of multistep denoising, we propose Direct-Align, a method that
predefines a noise prior to effectively recover original images from any time
steps via interpolation, leveraging the equation that diffusion states are
interpolations between noise and target images, which effectively avoids
over-optimization in late timesteps. Furthermore, we introduce Semantic
Relative Preference Optimization (SRPO), in which rewards are formulated as
text-conditioned signals. This approach enables online adjustment of rewards in
response to positive and negative prompt augmentation, thereby reducing the
reliance on offline reward fine-tuning. By fine-tuning the FLUX model with
optimized denoising and online reward adjustment, we improve its
human-evaluated realism and aesthetic quality by over 3x.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [25] [STL-based Optimization of Biomolecular Neural Networks for Regression and Control](https://arxiv.org/abs/2509.05481)
*Eric Palanques-Tost,Hanna Krasowski,Murat Arcak,Ron Weiss,Calin Belta*

Main category: cs.LG

TL;DR: BNNs은 생물학적으로 합성 가능한 구조를 가진 인공신경망으로, 훈련에 있어서 데이터 부족 문제를 해결하기 위해 신호 시간 논리(STL)를 활용하여 목표를 정의하고, 회귀 및 제어 작업을 수행한다.


<details>
  <summary>Details</summary>
Motivation: BNNs의 훈련은 목표 데이터의 부족으로 인해 어려움이 있다.

Method: 신호 시간 논리(STL)를 활용하여 BNNs의 훈련 목표를 정의하고, BNN 가중치의 기울기 기반 최적화를 가능하게 하는 학습 알고리즘을 소개한다.

Result: STL 기반 학습을 통해 BNNs가 비정상 상태를 보도하는 역할을 수행하고, 만성 질환 모델과의 폐쇄 루프에서 훈련하여 염증을 감소시키고 외부 감염에 대한 부정적인 반응을 피하도록 학습하였다.

Conclusion: STL 기반의 학습이 조사된 회귀 및 제어 작업을 효율적으로 해결할 수 있음을 보여준다.

Abstract: Biomolecular Neural Networks (BNNs), artificial neural networks with
biologically synthesizable architectures, achieve universal function
approximation capabilities beyond simple biological circuits. However, training
BNNs remains challenging due to the lack of target data. To address this, we
propose leveraging Signal Temporal Logic (STL) specifications to define
training objectives for BNNs. We build on the quantitative semantics of STL,
enabling gradient-based optimization of the BNN weights, and introduce a
learning algorithm that enables BNNs to perform regression and control tasks in
biological systems. Specifically, we investigate two regression problems in
which we train BNNs to act as reporters of dysregulated states, and a feedback
control problem in which we train the BNN in closed-loop with a chronic disease
model, learning to reduce inflammation while avoiding adverse responses to
external infections. Our numerical experiments demonstrate that STL-based
learning can solve the investigated regression and control tasks efficiently.

</details>


### [26] [Reinforcement Learning with Anticipation: A Hierarchical Approach for Long-Horizon Tasks](https://arxiv.org/abs/2509.05545)
*Yang Yu*

Main category: cs.LG

TL;DR: 장기 목표 기반 작업을 해결하는 것은 강화 학습에서 중요한 도전 과제입니다. 본 논문에서는 이러한 한계를 극복하기 위해 설계된 RLA(예상 강화 학습) 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 장기 목표 기반 작업 해결의 어려움과 HRL의 불안정성 문제를 해결하고자 함.

Method: RLA 에이전트는 저수준 목표 조건 정책과 고수준 예상 모델을 학습하여 작업을 수행합니다.

Result: RLA는 다양한 조건에서 전역 최적 정책에 접근하는 것을 보여줍니다.

Conclusion: RLA는 장기 목표 조건 작업에서 계층적 계획 및 실행을 위한 원리적이고 수렴하는 방법을 확립합니다.

Abstract: Solving long-horizon goal-conditioned tasks remains a significant challenge
in reinforcement learning (RL). Hierarchical reinforcement learning (HRL)
addresses this by decomposing tasks into more manageable sub-tasks, but the
automatic discovery of the hierarchy and the joint training of multi-level
policies often suffer from instability and can lack theoretical guarantees. In
this paper, we introduce Reinforcement Learning with Anticipation (RLA), a
principled and potentially scalable framework designed to address these
limitations. The RLA agent learns two synergistic models: a low-level,
goal-conditioned policy that learns to reach specified subgoals, and a
high-level anticipation model that functions as a planner, proposing
intermediate subgoals on the optimal path to a final goal. The key feature of
RLA is the training of the anticipation model, which is guided by a principle
of value geometric consistency, regularized to prevent degenerate solutions. We
present proofs that RLA approaches the globally optimal policy under various
conditions, establishing a principled and convergent method for hierarchical
planning and execution in long-horizon goal-conditioned tasks.

</details>


### [27] [ProfilingAgent: Profiling-Guided Agentic Reasoning for Adaptive Model Optimization](https://arxiv.org/abs/2509.05584)
*Sadegh Jafari,Aishwarya Sarkar,Mohiuddin Bilwal,Ali Jannesari*

Main category: cs.LG

TL;DR: 이 논문에서는 리소스가 제한된 플랫폼에서의 모델 배치를 방해하는 컴퓨팅 및 메모리 병목 현상을 해결하기 위해, ProfilingAgent라는 프로파일링 가이드 방식의 압축 자동화 접근법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기초 모델들이 리소스 제한이 있는 플랫폼에서 배치를 어렵게 하는 컴퓨팅과 메모리 병목 현상에 직면하고 있어, 효율적인 압축 기술이 필요합니다.

Method: ProfilingAgent는 대형 언어 모델(LLMs)을 사용하여 구조적 프루닝 및 훈련 후 동적 양자화를 통해 압축을 자동화하는 프로파일링 중심의 접근법입니다.

Result: ImageNet-1K, CIFAR-10, CIFAR-100 데이터셋에서 실험한 결과, 프루닝은 경쟁력 있는 정확도를 유지하거나 개선하였고, 양자화는 최대 74%의 메모리 절약과 0.5% 미만의 정확도 손실을 달성했습니다.

Conclusion: 이 연구 결과는 프로파일링 가이드 모델 최적화에 있어 에이전트 시스템의 확장 가능한 솔루션을 입증합니다.

Abstract: Foundation models face growing compute and memory bottlenecks, hindering
deployment on resource-limited platforms. While compression techniques such as
pruning and quantization are widely used, most rely on uniform heuristics that
ignore architectural and runtime heterogeneity. Profiling tools expose
per-layer latency, memory, and compute cost, yet are rarely integrated into
automated pipelines. We propose ProfilingAgent, a profiling-guided, agentic
approach that uses large language models (LLMs) to automate compression via
structured pruning and post-training dynamic quantization. Our modular
multi-agent system reasons over static metrics (MACs, parameter counts) and
dynamic signals (latency, memory) to design architecture-specific strategies.
Unlike heuristic baselines, ProfilingAgent tailors layer-wise decisions to
bottlenecks. Experiments on ImageNet-1K, CIFAR-10, and CIFAR-100 with
ResNet-101, ViT-B/16, Swin-B, and DeiT-B/16 show pruning maintains competitive
or improved accuracy (about 1% drop on ImageNet-1K, +2% gains for ViT-B/16 on
smaller datasets), while quantization achieves up to 74% memory savings with
<0.5% accuracy loss. Our quantization also yields consistent inference speedups
of up to 1.74 times faster. Comparative studies with GPT-4o and GPT-4-Turbo
highlight the importance of LLM reasoning quality for iterative pruning. These
results establish agentic systems as scalable solutions for profiling-guided
model optimization.

</details>


### [28] [Offline vs. Online Learning in Model-based RL: Lessons for Data Collection Strategies](https://arxiv.org/abs/2509.05735)
*Jiaqi Chen,Ji Shi,Cansu Sancaktar,Jonas Frey,Georg Martius*

Main category: cs.LG

TL;DR: 본 연구는 온라인과 오프라인 데이터의 차이가 모델 기반 강화 학습의 성능에 미치는 영향을 다루며, 온라인 에이전트가 오프라인 에이전트보다 우수한 성능을 보임을 입증하고, 추가적인 온라인 상호작용과 탐색 데이터의 필요성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: 모델 기반 강화 학습에서 견고한 세계 모델을 학습하기 위해 데이터 수집은 매우 중요하다.

Method: 31개 서로 다른 환경에서 모델 기반 설정에서 온라인 및 오프라인 에이전트를 비교하는 실험을 수행한다.

Result: 온라인 에이전트가 오프라인 에이전트보다 성능이 우수하며, 오프라인 에이전트의 성능 저하의 주요 원인으로는 Out-Of-Distribution 상태를 경험하는 것이다.

Conclusion: 성능을 복원하기 위해 추가적인 온라인 상호작용을 허용하고, 탐색 데이터를 통합하는 것이 오프라인 에이전트의 성능 저하를 완화하는데 도움이 된다는 점을 강조한다.

Abstract: Data collection is crucial for learning robust world models in model-based
reinforcement learning. The most prevalent strategies are to actively collect
trajectories by interacting with the environment during online training or
training on offline datasets. At first glance, the nature of learning
task-agnostic environment dynamics makes world models a good candidate for
effective offline training. However, the effects of online vs. offline data on
world models and thus on the resulting task performance have not been
thoroughly studied in the literature. In this work, we investigate both
paradigms in model-based settings, conducting experiments on 31 different
environments. First, we showcase that online agents outperform their offline
counterparts. We identify a key challenge behind performance degradation of
offline agents: encountering Out-Of-Distribution states at test time. This
issue arises because, without the self-correction mechanism in online agents,
offline datasets with limited state space coverage induce a mismatch between
the agent's imagination and real rollouts, compromising policy training. We
demonstrate that this issue can be mitigated by allowing for additional online
interactions in a fixed or adaptive schedule, restoring the performance of
online training with limited interaction data. We also showcase that
incorporating exploration data helps mitigate the performance degradation of
offline agents. Based on our insights, we recommend adding exploration data
when collecting large datasets, as current efforts predominantly focus on
expert data alone.

</details>


### [29] [Data-Driven Stochastic Modeling Using Autoregressive Sequence Models: Translating Event Tables to Queueing Dynamics](https://arxiv.org/abs/2509.05839)
*Daksh Mittal,Shunri Zheng,Jing Dong,Hongseok Namkoong*

Main category: cs.LG

TL;DR: 큐잉 네트워크 모델은 서비스 시스템 분석에 유용하지만, 전통적으로는 많은 인력과 전문성이 요구된다. 본 논문에서는 데이터 기반의 큐잉 네트워크 모델링 및 시뮬레이션을 위한 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 큐잉 네트워크 모델의 접근성을 높이고 노력의 양을 줄이기 위해 자동화된 데이터 기반 모델링이 필요하다.

Method: 이런 접근법은 도착 프로세스, 서비스 메커니즘, 라우팅 로직을 명시적으로 정의하는 대신 이벤트 유형과 이벤트 시간의 조건부 분포를 학습하여 시퀀스 분포 학습 문제로 변환한다.

Result: Transformer 스타일의 아키텍처가 이러한 분포를 효과적으로 매개변수화할 수 있으며, 이를 통해 고충실도 시뮬레이터의 자동화된 구성이 가능함을 보여준다.

Conclusion: 인공지능의 발전과 데이터의 이용 가능성을 활용하여, 본 프레임워크는 서비스 도메인 전반에 걸쳐 큐잉 네트워크 모델의 보다 널리 사용될 수 있는 자동화된 데이터 기반 모델링 파이프라인으로 나아가는 한 단계가 된다.

Abstract: While queueing network models are powerful tools for analyzing service
systems, they traditionally require substantial human effort and domain
expertise to construct. To make this modeling approach more scalable and
accessible, we propose a data-driven framework for queueing network modeling
and simulation based on autoregressive sequence models trained on event-stream
data. Instead of explicitly specifying arrival processes, service mechanisms,
or routing logic, our approach learns the conditional distributions of event
types and event times, recasting the modeling task as a problem of sequence
distribution learning. We show that Transformer-style architectures can
effectively parameterize these distributions, enabling automated construction
of high-fidelity simulators. As a proof of concept, we validate our framework
on event tables generated from diverse queueing networks, showcasing its
utility in simulation, uncertainty quantification, and counterfactual
evaluation. Leveraging advances in artificial intelligence and the growing
availability of data, our framework takes a step toward more automated,
data-driven modeling pipelines to support broader adoption of queueing network
models across service domains.

</details>


### [30] [PolicyEvolve: Evolving Programmatic Policies by LLMs for multi-player games via Population-Based Training](https://arxiv.org/abs/2509.06053)
*Mingrui Lv,Hangzhi Liu,Zhi Luo,Hongjie Zhang,Jie Ou*

Main category: cs.LG

TL;DR: PolicyEvolve는 다중 플레이어 게임에서 프로그램적 정책을 생성하기 위한 일반 프레임워크로, 수작업으로 작성된 정책 코드에 대한 의존성을 크게 줄이고 최소한의 환경 상호작용으로 높은 성능의 정책을 달성합니다.


<details>
  <summary>Details</summary>
Motivation: MARL에서 효과적인 적대적 정책을 훈련하기 위해서는 많은 경험 샘플과 계산 자원이 필요하지만, 이것들은 해석 가능성이 부족하여 실제 배치에 장애가 됩니다.

Method: PolicyEvolve는 글로벌 풀, 로컬 풀, 정책 기획자 및 궤적 비평가의 네 가지 모듈로 구성됩니다.

Result: 이 프레임워크는 정책이 글로벌 풀에서 충분히 높은 평균 승률을 달성할 때까지 반복적인 프로세스를 수행합니다.

Conclusion: PolicyEvolve는 다중 에이전트 환경에서 고성능의 해석 가능한 정책을 효과적으로 생성할 수 있는 잠재력을 보여줍니다.

Abstract: Multi-agent reinforcement learning (MARL) has achieved significant progress
in solving complex multi-player games through self-play. However, training
effective adversarial policies requires millions of experience samples and
substantial computational resources. Moreover, these policies lack
interpretability, hindering their practical deployment. Recently, researchers
have successfully leveraged Large Language Models (LLMs) to generate
programmatic policies for single-agent tasks, transforming neural network-based
policies into interpretable rule-based code with high execution efficiency.
Inspired by this, we propose PolicyEvolve, a general framework for generating
programmatic policies in multi-player games. PolicyEvolve significantly reduces
reliance on manually crafted policy code, achieving high-performance policies
with minimal environmental interactions. The framework comprises four modules:
Global Pool, Local Pool, Policy Planner, and Trajectory Critic. The Global Pool
preserves elite policies accumulated during iterative training. The Local Pool
stores temporary policies for the current iteration; only sufficiently
high-performing policies from this pool are promoted to the Global Pool. The
Policy Planner serves as the core policy generation module. It samples the top
three policies from the Global Pool, generates an initial policy for the
current iteration based on environmental information, and refines this policy
using feedback from the Trajectory Critic. Refined policies are then deposited
into the Local Pool. This iterative process continues until the policy achieves
a sufficiently high average win rate against the Global Pool, at which point it
is integrated into the Global Pool. The Trajectory Critic analyzes interaction
data from the current policy, identifies vulnerabilities, and proposes
directional improvements to guide the Policy Planner

</details>


### [31] [A novel biomass fluidized bed gasification model coupled with machine learning and CFD simulation](https://arxiv.org/abs/2509.06056)
*Chun Wang*

Main category: cs.LG

TL;DR: 이 연구에서는 머신러닝과 계산 유체 역학을 기반으로 한 바이오매스 유동층 가스화의 결합 모델을 제안하여 복잡한 열화학 반응 과정의 예측 정확성과 계산 효율성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 열화학 반응 과정의 예측 정확성과 계산 효율성을 향상시키기 위해.

Method: 실험 데이터와 고충실도 시뮬레이션 결과를 기반으로 고품질 데이터 세트를 구축하고, 반응 동역학의 특성을 설명하는 에이전트 모델을 훈련하여 계산 유체 역학(CFD) 프레임워크에 임베딩했다.

Result: 반응 속도와 조성 진화를 실시간으로 업데이트할 수 있었다.

Conclusion: 이 결합 모델을 통해 바이오매스 가스화 과정에 대한 더 정확한 예측과 효율적인 계산이 가능해졌다.

Abstract: A coupling model of biomass fluidized bed gasification based on machine
learning and computational fluid dynamics is proposed to improve the prediction
accuracy and computational efficiency of complex thermochemical reaction
process. By constructing a high-quality data set based on experimental data and
high fidelity simulation results, the agent model used to describe the
characteristics of reaction kinetics was trained and embedded into the
computational fluid dynamics (CFD) framework to realize the real-time update of
reaction rate and composition evolution.

</details>


### [32] [Teaching Precommitted Agents: Model-Free Policy Evaluation and Control in Quasi-Hyperbolic Discounted MDPs](https://arxiv.org/abs/2509.06094)
*S. R. Eshwar*

Main category: cs.LG

TL;DR: 본 논문은 QH(준-초월적) 선호를 가진 사전 약속된 에이전트를 위해 최적 정책의 구조를 규명하고, 정책 평가 및 Q-학습을 위한 실용적인 모델 프리 알고리즘을 설계합니다.


<details>
  <summary>Details</summary>
Motivation: 시간 불일치 선호는 인간과 동물의 의사결정에 중요한 특징입니다. 그러나 QH 할인율을 강화학습(RL) 프레임워크에 통합하는 데는 한계가 있었습니다.

Method: 우리는 최적 정책의 구조를 형식적으로 규명하고, 정책 평가 및 Q-학습을 위한 실용적인 모델 프리 알고리즘을 설계하였습니다.

Result: 최적 정책은 간단한 일단계 비정상 형태로 축약되며, 설계한 알고리즘은 모두 수렴 보장이 있습니다.

Conclusion: 우리의 결과는 RL에서 QH 선호를 통합하기 위한 기초적인 통찰력을 제공합니다.

Abstract: Time-inconsistent preferences, where agents favor smaller-sooner over
larger-later rewards, are a key feature of human and animal decision-making.
Quasi-Hyperbolic (QH) discounting provides a simple yet powerful model for this
behavior, but its integration into the reinforcement learning (RL) framework
has been limited. This paper addresses key theoretical and algorithmic gaps for
precommitted agents with QH preferences. We make two primary contributions: (i)
we formally characterize the structure of the optimal policy, proving for the
first time that it reduces to a simple one-step non-stationary form; and (ii)
we design the first practical, model-free algorithms for both policy evaluation
and Q-learning in this setting, both with provable convergence guarantees. Our
results provide foundational insights for incorporating QH preferences in RL.

</details>


### [33] [Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments and Reinforcement Learning](https://arxiv.org/abs/2509.06213)
*Christo Mathew,Wentian Wang,Jacob Feldman,Lazaros K. Gallos,Paul B. Kantor,Vladimir Menkov,Hao Wang*

Main category: cs.LG

TL;DR: 이 논문은 Game Of Hidden Rules (GOHR) 환경에서 강화학습을 조사하며, 두 가지 상태 표현 전략을 탐구하고 Transformer 기반 Advantage Actor-Critic (A2C) 알고리즘을 사용하여 훈련합니다.


<details>
  <summary>Details</summary>
Motivation: GOHR 환경에서 에이전트가 숨겨진 규칙을 추론하고 실행하여 퍼즐을 해결해야 하기 때문에, 이를 통해 강화학습의 효율성을 탐구하고자 합니다.

Method: Feature-Centric (FC) 및 Object-Centric (OC)라는 두 가지 상태 표현 전략을 사용하고, Transformer 기반 Advantage Actor-Critic (A2C) 알고리즘을 훈련에 활용합니다.

Result: 여러 규칙 기반 및 시험 목록 기반 실험 설정을 통해 모델을 평가하고, 이전 효과 및 표현이 학습 효율성에 미치는 영향을 분석합니다.

Conclusion: 제안된 방법들이 GAORH 환경에서 에이전트의 성능에 어떻게 기여하는지를 확인할 수 있었습니다.

Abstract: We investigate reinforcement learning in the Game Of Hidden Rules (GOHR)
environment, a complex puzzle in which an agent must infer and execute hidden
rules to clear a 6$\times$6 board by placing game pieces into buckets. We
explore two state representation strategies, namely Feature-Centric (FC) and
Object-Centric (OC), and employ a Transformer-based Advantage Actor-Critic
(A2C) algorithm for training. The agent has access only to partial observations
and must simultaneously infer the governing rule and learn the optimal policy
through experience. We evaluate our models across multiple rule-based and
trial-list-based experimental setups, analyzing transfer effects and the impact
of representation on learning efficiency.

</details>


### [34] [A Spatio-Temporal Graph Neural Networks Approach for Predicting Silent Data Corruption inducing Circuit-Level Faults](https://arxiv.org/abs/2509.06289)
*Shaoqi Wei,Senling Wang,Hiroshi Kai,Yoshinobu Higami,Ruijun Ma,Tianming Ni,Xiaoqing Wen,Hiroshi Takahashi*

Main category: cs.LG

TL;DR: 이 논문은 긴 사이클 결함 영향 확률(FIPs)을 예측하기 위한 통합된 시공간 그래프 컨볼루션 네트워크(ST-GCN)를 제시하며, 이를 통해 안전-critical 시스템의 신뢰성을 높이고 테스트 비용을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 안전-critical 시스템에서 시간 제로 결함 및 노화로 인한 침묵 데이터 오류(SDEs)가 성능을 저하시키므로, 효율적이고 정확한 결함 영향 예측이 필요하다.

Method: ST-GCN을 통해 게이트 레벨 넷리스트를 시공간 그래프로 모델링하고, 전용 공간 및 시간 인코더를 사용하여 다중 사이클 FIPs를 효율적으로 예측한다.

Result: ISCAS-89 벤치마크에서 이 방법은 시뮬레이션 시간을 10배 이상 단축하면서도 높은 정확도(mean absolute error 0.024)를 유지한다.

Conclusion: 예측된 FIPs를 기반으로 관측 점을 선택하는 것이 장기 및 탐지하기 어려운 결함의 탐지를 향상시킴을 보여준다.

Abstract: Silent Data Errors (SDEs) from time-zero defects and aging degrade
safety-critical systems. Functional testing detects SDE-related faults but is
expensive to simulate. We present a unified spatio-temporal graph convolutional
network (ST-GCN) for fast, accurate prediction of long-cycle fault impact
probabilities (FIPs) in large sequential circuits, supporting quantitative risk
assessment. Gate-level netlists are modeled as spatio-temporal graphs to
capture topology and signal timing; dedicated spatial and temporal encoders
predict multi-cycle FIPs efficiently. On ISCAS-89 benchmarks, the method
reduces simulation time by more than 10x while maintaining high accuracy (mean
absolute error 0.024 for 5-cycle predictions). The framework accepts features
from testability metrics or fault simulation, allowing efficiency-accuracy
trade-offs. A test-point selection study shows that choosing observation points
by predicted FIPs improves detection of long-cycle, hard-to-detect faults. The
approach scales to SoC-level test strategy optimization and fits downstream
electronic design automation flows.

</details>


### [35] [A Fragile Number Sense: Probing the Elemental Limits of Numerical Reasoning in LLMs](https://arxiv.org/abs/2509.06332)
*Roussel Rahman,Aashwin Ananda Mishra*

Main category: cs.LG

TL;DR: 대형 언어 모델(LLM)은 놀라운 능력을 보였으나 수치 추론의 강인성은 여전히 의문이다. 이 연구는 여러 복잡성의 문제를 평가하여 LLM의 수학적 능력을 조사하고, 고급 수학적 작업에서는 우수성을 보였지만 특정 조합 문제에서는 실패하는 경향이 있다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 수치 추론 능력의 강인성을 평가하기 위하여.

Method: 100개의 문제로 구성된 챌린지를 통해 여러 LLM 기반 에이전트의 성능을 평가하였다. 문제는 기본 산술, 고급 작업, 소수 판별, 숫자 퍼즐 등 네 가지 카테고리로 이루어져 있다.

Result: 에이전트는 기본 산술, 고급 작업, 소수 판별에서 높은 정확도를 기록했지만, 숫자 퍼즐에서는 일관되게 실패하였다.

Conclusion: 에이전트의 능력은 주로 알고리즘 기억 및 실행에 제한되어 있으며, 창의적인 문제 해결은 부족하다.

Abstract: Large Language Models (LLMs) have demonstrated remarkable emergent
capabilities, yet the robustness of their numerical reasoning remains an open
question. While standard benchmarks evaluate LLM reasoning on complex problem
sets using aggregated metrics, they often obscure foundational weaknesses. In
this work, we probe LLM mathematical numeracy by evaluating performance on
problems of escalating complexity, from constituent operations to combinatorial
puzzles. We test several state-of-the-art LLM-based agents on a 100-problem
challenge comprising four categories: (1) basic arithmetic, (2) advanced
operations, (3) primality checking, and (4) the Game of 24 number puzzle. Our
results show that while the agents achieved high accuracy on the first three
categories, which require deterministic algorithmic execution, they
consistently failed at the number puzzle, underlining its demand for a
heuristic search over a large combinatorial space to be a significant
bottleneck. These findings reveal that the agents' proficiency is largely
confined to recalling and executing known algorithms, rather than performing
generative problem-solving. This suggests their apparent numerical reasoning is
more akin to sophisticated pattern-matching than flexible, analytical thought,
limiting their potential for tasks that require novel or creative numerical
insights.

</details>


### [36] [CAME-AB: Cross-Modality Attention with Mixture-of-Experts for Antibody Binding Site Prediction](https://arxiv.org/abs/2509.06465)
*Hongzong Li,Jiahao Ma,Zhanpeng Shi,Rui Xiao,Fanming Jin,Ye-Fan Hu,Jian-Dong Huang*

Main category: cs.LG

TL;DR: CAME-AB는 여러 생물학적 모달리티를 통합하여 강력한 항체 결합 부위 예측을 수행하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 항체 결합 부위 예측은 컴퓨터 면역학 및 치료 항체 디자인에서 중요한 역할을 한다.

Method: CAME-AB는 다섯 가지 생물학적 모달리티를 통합하고, 동적 가중치를 학습하는 모듈과 변환기 인코더를 결합하여 특징 전문화 및 용량 확장을 촉진한다.

Result: CAME-AB는 Precision, Recall, F1-score, AUC-ROC, MCC를 포함한 여러 메트릭에서 강력한 기준 모델보다 일관되게 우수한 성능을 발휘한다.

Conclusion: 모델 구현 세부 정보와 코드는 제공된 링크에서 확인 가능하다.

Abstract: Antibody binding site prediction plays a pivotal role in computational
immunology and therapeutic antibody design. Existing sequence or structure
methods rely on single-view features and fail to identify antibody-specific
binding sites on the antigens. In this paper, we propose \textbf{CAME-AB}, a
novel Cross-modality Attention framework with a Mixture-of-Experts (MoE)
backbone for robust antibody binding site prediction. CAME-AB integrates five
biologically grounded modalities, including raw amino acid encodings, BLOSUM
substitution profiles, pretrained language model embeddings, structure-aware
features, and GCN-refined biochemical graphs, into a unified multimodal
representation. To enhance adaptive cross-modal reasoning, we propose an
\emph{adaptive modality fusion} module that learns to dynamically weight each
modality based on its global relevance and input-specific contribution. A
Transformer encoder combined with an MoE module further promotes feature
specialization and capacity expansion. We additionally incorporate a supervised
contrastive learning objective to explicitly shape the latent space geometry,
encouraging intra-class compactness and inter-class separability. To improve
optimization stability and generalization, we apply stochastic weight averaging
during training. Extensive experiments on benchmark antibody-antigen datasets
demonstrate that CAME-AB consistently outperforms strong baselines on multiple
metrics, including Precision, Recall, F1-score, AUC-ROC, and MCC. Ablation
studies further validate the effectiveness of each architectural component and
the benefit of multimodal feature integration. The model implementation details
and the codes are available on https://anonymous.4open.science/r/CAME-AB-C525

</details>


### [37] [QualityFM: a Multimodal Physiological Signal Foundation Model with Self-Distillation for Signal Quality Challenges in Critically Ill Patients](https://arxiv.org/abs/2509.06516)
*Zongheng Guo,Tao Chen,Manuela Ferrario*

Main category: cs.LG

TL;DR: QualityFM이라는 혁신적인 다중 모달 기초 모델을 소개하며, 이는 PPG 및 ECG 신호의 품질을 일반적으로 이해하도록 설계되었습니다.


<details>
  <summary>Details</summary>
Motivation: ICU와 OR에서 기록되는 PPG 및 ECG의 신호 품질이 나쁜 경우로 인한 잘못된 경고와 진단 부정확성을 해결하고자 합니다.

Method: QualityFM 모델은 2100만 개 이상의 30초 파형과 179,757시간의 데이터로 구성된 대규모 데이터셋에서 사전 훈련됩니다. 모델은 품질이 다른 신호 쌍을 처리하기 위해 이중 트랙 아키텍처를 채택하며, 고품질 신호의 인코더가 저품질 신호의 인코더 훈련을 안내하도록 자가 증류 전략을 활용합니다.

Result: 전이 학습을 통해 세 가지 임상 작업에서 효과성과 실용 가치를 증명했습니다: 심실 빈맥 탐지의 잘못된 경고, 심방세동 식별, PPG 및 ECG 신호에서 동맥 혈압(ABP) 추정.

Conclusion: 다양한 파라미터 수(960만에서 3억 1900만 사이)의 세 가지 모델을 사전 훈련하여 신호의 주파수 영역 특성을 보존하는 복합 손실 함수를 사용합니다.

Abstract: Photoplethysmogram (PPG) and electrocardiogram (ECG) are commonly recorded in
intesive care unit (ICU) and operating room (OR). However, the high incidence
of poor, incomplete, and inconsistent signal quality, can lead to false alarms
or diagnostic inaccuracies. The methods explored so far suffer from limited
generalizability, reliance on extensive labeled data, and poor cross-task
transferability. To overcome these challenges, we introduce QualityFM, a novel
multimodal foundation model for these physiological signals, designed to
acquire a general-purpose understanding of signal quality. Our model is
pre-trained on an large-scale dataset comprising over 21 million 30-second
waveforms and 179,757 hours of data. Our approach involves a dual-track
architecture that processes paired physiological signals of differing quality,
leveraging a self-distillation strategy where an encoder for high-quality
signals is used to guide the training of an encoder for low-quality signals. To
efficiently handle long sequential signals and capture essential local
quasi-periodic patterns, we integrate a windowed sparse attention mechanism
within our Transformer-based model. Furthermore, a composite loss function,
which combines direct distillation loss on encoder outputs with indirect
reconstruction loss based on power and phase spectra, ensures the preservation
of frequency-domain characteristics of the signals. We pre-train three models
with varying parameter counts (9.6 M to 319 M) and demonstrate their efficacy
and practical value through transfer learning on three distinct clinical tasks:
false alarm of ventricular tachycardia detection, the identification of atrial
fibrillation and the estimation of arterial blood pressure (ABP) from PPG and
ECG signals.

</details>


### [38] [Learning Optimal Defender Strategies for CAGE-2 using a POMDP Model](https://arxiv.org/abs/2509.06539)
*Duc Huy Le,Rolf Stadler*

Main category: cs.LG

TL;DR: 이 논문에서는 CAGE-2의 방어 전략 학습을 위한 최적의 전략과 이를 학습하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: CAGE-2는 사이버 공격에 대한 방어 전략을 학습하고 평가하기 위한 벤치마크로, 다양한 공격으로부터 IT 인프라를 보호하는 상황을 반영합니다.

Method: 이 논문에서는 부분 관찰 마르코프 결정 프로세스(POMDP)의 프레임워크를 사용하여 CAGE-2에 대한 정형 모델을 구축하고, BF-PPO라는 방법을 통해 최적 방어 전략을 효율적으로 학습합니다.

Result: CAGE-2 CybORG 환경에서 BF-PPO 방법을 평가하고 CAGE-2 리더보드에서 가장 높은 순위의 방법인 CARDIFF와 성능을 비교한 결과, BF-PPO가 학습된 방어 전략과 소요 훈련 시간 모두에서 CARDIFF보다 뛰어난 성능을 보였습니다.

Conclusion: CAGE-2 모델의 큰 상태 공간으로 인한 계산 복잡성을 완화하기 위해 파티클 필터를 사용하여 BF-PPO를 제안하였으며, 이는 향후 방어 전략 개발에 있어 유망한 방법으로 평가됩니다.

Abstract: CAGE-2 is an accepted benchmark for learning and evaluating defender
strategies against cyberattacks. It reflects a scenario where a defender agent
protects an IT infrastructure against various attacks. Many defender methods
for CAGE-2 have been proposed in the literature. In this paper, we construct a
formal model for CAGE-2 using the framework of Partially Observable Markov
Decision Process (POMDP). Based on this model, we define an optimal defender
strategy for CAGE-2 and introduce a method to efficiently learn this strategy.
Our method, called BF-PPO, is based on PPO, and it uses particle filter to
mitigate the computational complexity due to the large state space of the
CAGE-2 model. We evaluate our method in the CAGE-2 CybORG environment and
compare its performance with that of CARDIFF, the highest ranked method on the
CAGE-2 leaderboard. We find that our method outperforms CARDIFF regarding the
learned defender strategy and the required training time.

</details>


### [39] [Demo: Healthcare Agent Orchestrator (HAO) for Patient Summarization in Molecular Tumor Boards](https://arxiv.org/abs/2509.06602)
*Noel Codella,Sam Preston,Hao Qiu,Leonardo Schettini,Wen-wai Yim,Mert Öz,Shrey Jain,Matthew P. Lungren,Thomas Osborne*

Main category: cs.LG

TL;DR: 이 연구는 의료 정보 요약 작성에서의 비효율성을 해결하기 위해 AI 기반의 Healthcare Agent Orchestrator(HAO)와 평가 프레임워크 TBFact를 도입한 것이다.


<details>
  <summary>Details</summary>
Motivation: Molecular Tumor Boards(MTBs)에서 환자 요약 작성의 비효율성과 주관성을 개선하고자 함.

Method: HAO라는 AI 에이전트를 사용하여 멀티 에이전트 임상 워크플로우를 조정하고, TBFact 프레임워크를 적용하여 생성된 요약의 포괄성과 간결성을 평가함.

Result: HAO는 94%의 중요 정보를 포착하고 TBFact recall 0.84를 달성함.

Conclusion: HAO와 TBFact를 통해 MTB에 신뢰할 수 있고 확장 가능한 지원을 제공하는 튼튼한 기반을 마련함.

Abstract: Molecular Tumor Boards (MTBs) are multidisciplinary forums where oncology
specialists collaboratively assess complex patient cases to determine optimal
treatment strategies. A central element of this process is the patient summary,
typically compiled by a medical oncologist, radiation oncologist, or surgeon,
or their trained medical assistant, who distills heterogeneous medical records
into a concise narrative to facilitate discussion. This manual approach is
often labor-intensive, subjective, and prone to omissions of critical
information. To address these limitations, we introduce the Healthcare Agent
Orchestrator (HAO), a Large Language Model (LLM)-driven AI agent that
coordinates a multi-agent clinical workflow to generate accurate and
comprehensive patient summaries for MTBs. Evaluating predicted patient
summaries against ground truth presents additional challenges due to stylistic
variation, ordering, synonym usage, and phrasing differences, which complicate
the measurement of both succinctness and completeness. To overcome these
evaluation hurdles, we propose TBFact, a ``model-as-a-judge'' framework
designed to assess the comprehensiveness and succinctness of generated
summaries. Using a benchmark dataset derived from de-identified tumor board
discussions, we applied TBFact to evaluate our Patient History agent. Results
show that the agent captured 94% of high-importance information (including
partial entailments) and achieved a TBFact recall of 0.84 under strict
entailment criteria. We further demonstrate that TBFact enables a data-free
evaluation framework that institutions can deploy locally without sharing
sensitive clinical data. Together, HAO and TBFact establish a robust foundation
for delivering reliable and scalable support to MTBs.

</details>


### [40] [Group Effect Enhanced Generative Adversarial Imitation Learning for Individual Travel Behavior Modeling under Incentives](https://arxiv.org/abs/2509.06656)
*Yuanyuan Wu,Zhenlin Qin,Leizhen Wang,Xiaolei Ma,Zhenliang Ma*

Main category: cs.LG

TL;DR: gcGAIL 모델은 그룹 간 공유 행동 패턴을 활용하여 개인 여행 행동 모델링 효율성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 개별 여행 행동 반응을 이해하고 모델링하는 것은 도시 이동성 규제 및 정책 평가에 필수적입니다.

Method: 본 논문에서는 그룹 효과 향상 생성적 적대 모방 학습(gcGAIL) 모델을 제안합니다.

Result: gcGAIL 모델은 여러 최신 기법들과 비교하여 개인 여행 행동 반응을 학습하는 데 있어 우수한 성능을 보입니다.

Conclusion: gcGAIL 모델은 개인화된 인센티브를 제공하여 지속 가능한 행동 변화를 유도할 수 있는 기초를 제공합니다.

Abstract: Understanding and modeling individual travel behavior responses is crucial
for urban mobility regulation and policy evaluation. The Markov decision
process (MDP) provides a structured framework for dynamic travel behavior
modeling at the individual level. However, solving an MDP in this context is
highly data-intensive and faces challenges of data quantity, spatial-temporal
coverage, and situational diversity. To address these, we propose a
group-effect-enhanced generative adversarial imitation learning (gcGAIL) model
that improves the individual behavior modeling efficiency by leveraging shared
behavioral patterns among passenger groups. We validate the gcGAIL model using
a public transport fare-discount case study and compare against
state-of-the-art benchmarks, including adversarial inverse reinforcement
learning (AIRL), baseline GAIL, and conditional GAIL. Experimental results
demonstrate that gcGAIL outperforms these methods in learning individual travel
behavior responses to incentives over time in terms of accuracy,
generalization, and pattern demonstration efficiency. Notably, gcGAIL is robust
to spatial variation, data sparsity, and behavioral diversity, maintaining
strong performance even with partial expert demonstrations and underrepresented
passenger groups. The gcGAIL model predicts the individual behavior response at
any time, providing the basis for personalized incentives to induce sustainable
behavior changes (better timing of incentive injections).

</details>


### [41] [Probabilistic Modeling of Latent Agentic Substructures in Deep Neural Networks](https://arxiv.org/abs/2509.06701)
*Su Hyeong Lee,Risi Kondor,Richard Ngo*

Main category: cs.LG

TL;DR: 이 연구에서는 신경 모델을 위한 확률적 모델링에 기반한 지능적 대리인의 이론을 개발합니다. 에이전트는 결과 분포로 표현되며, 로그 점수에 의해 결정되는 인식 유틸리티를 가집니다. 각 구성의 복합체는 모든 구성원의 복지를 엄격하게 개선하는 가중 로그 풀링을 통해 정의됩니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 간의 협력과 조화로운 실현을 이해하기 위해, 확률적 모델링 기반의 지능적 대리인 이론을 개발하고자 합니다.

Method: 에이전트는 로그 점수에 의해 결정되는 인식 유틸리티를 갖는 결과 분포로 모델링되고, 가중 로그 풀링을 통해 구성됩니다. 선형 풀링 및 이진 결과 공간에서는 엄격한 만장일치가 불가능함을 증명합니다.

Result: 세 개 이상의 결과를 가진 경우에는 엄격한 만장일치가 가능하며, 재귀적 구조를 허용하는 특성을 보입니다. LLM에서의 대리인 정렬 현상을 정식화합니다.

Conclusion: 하위 대리인이 일관된 높은 수준의 개체로 통합되는 방법에 대한 원칙적인 수학적 프레임워크를 개발함으로써 에이전트 기반 AI 시스템의 정렬에 대한 새로운 의미를 제공한다고 결론짓습니다.

Abstract: We develop a theory of intelligent agency grounded in probabilistic modeling
for neural models. Agents are represented as outcome distributions with
epistemic utility given by log score, and compositions are defined through
weighted logarithmic pooling that strictly improves every member's welfare. We
prove that strict unanimity is impossible under linear pooling or in binary
outcome spaces, but possible with three or more outcomes. Our framework admits
recursive structure via cloning invariance, continuity, and openness, while
tilt-based analysis rules out trivial duplication. Finally, we formalize an
agentic alignment phenomenon in LLMs using our theory: eliciting a benevolent
persona ("Luigi'") induces an antagonistic counterpart ("Waluigi"), while a
manifest-then-suppress Waluigi strategy yields strictly larger first-order
misalignment reduction than pure Luigi reinforcement alone. These results
clarify how developing a principled mathematical framework for how subagents
can coalesce into coherent higher-level entities provides novel implications
for alignment in agentic AI systems.

</details>


### [42] [Aligning Large Vision-Language Models by Deep Reinforcement Learning and Direct Preference Optimization](https://arxiv.org/abs/2509.06759)
*Thanh Thi Nguyen,Campbell Wilson,Janis Dalins*

Main category: cs.LG

TL;DR: LVLM의 미세 조정을 위한 DRL 및 DPO 기법의 가능성을 탐구하고, 인간의 가치 및 선호에 맞춰 모델을 조정하는 방법을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: LVLM이 인간의 가치 및 특정 작업에 맞춰 조정되는 것을 목표로 하며, 이는 인공지능의 발전에 중요한 역할을 합니다.

Method: DRL과 DPO 기법을 활용하여 LVLM을 조정하는 다양한 패러다임을 탐구하며, 보상 신호와 선호 데이터를 최적화합니다.

Result: 모델이 인간의 선호 및 가치와 일치하도록 조정하고 작업 성능을 개선하며 적응형 다중 모드 상호작용을 가능하게 함.

Conclusion: DRL과 DPO가 강력하고 인간 친화적인 LVLM의 발전에 어떻게 기여하는지를 명확히 이해하는 것을 목표로 합니다.

Abstract: Large Vision-Language Models (LVLMs) or multimodal large language models
represent a significant advancement in artificial intelligence, enabling
systems to understand and generate content across both visual and textual
modalities. While large-scale pretraining has driven substantial progress,
fine-tuning these models for aligning with human values or engaging in specific
tasks or behaviors remains a critical challenge. Deep Reinforcement Learning
(DRL) and Direct Preference Optimization (DPO) offer promising frameworks for
this aligning process. While DRL enables models to optimize actions using
reward signals instead of relying solely on supervised preference data, DPO
directly aligns the policy with preferences, eliminating the need for an
explicit reward model. This overview explores paradigms for fine-tuning LVLMs,
highlighting how DRL and DPO techniques can be used to align models with human
preferences and values, improve task performance, and enable adaptive
multimodal interaction. We categorize key approaches, examine sources of
preference data, reward signals, and discuss open challenges such as
scalability, sample efficiency, continual learning, generalization, and safety.
The goal is to provide a clear understanding of how DRL and DPO contribute to
the evolution of robust and human-aligned LVLMs.

</details>


### [43] [\texttt{R$^\textbf{2}$AI}: Towards Resistant and Resilient AI in an Evolving World](https://arxiv.org/abs/2509.06786)
*Youbang Sun,Xiang Wang,Jie Fu,Chaochao Lu,Bowen Zhou*

Main category: cs.LG

TL;DR: AI의 안전성 발전이 지체되고 있는 상황에서, 이 논문은 AI 안전성을 동적이고 지속적인 학습 과정으로 접근하여 새로운 안전성 패러다임을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI의 빠른 발전과 안전성 진전 간의 지속적인 격차를 해소하기 위해.

Method: 'co-evolution에 의한 안전성'을 제안하며, 'R$^2$AI'라는 프레임워크를 통해 알려진 위협에 저항하고 예기치 못한 위험에 대한 회복력을 통합한다.

Result: R$^2$AI는 빠르고 느린 안전 모델, 적대적 시뮬레이션 및 검증, 지속적인 피드백 루프를 포함하여 안전성과 능력을 공동 진화하도록 안내한다.

Conclusion: 이 프레임워크는 동적 환경에서 지속적인 안전성을 유지하기 위한 확장 가능하고 능동적인 경로를 제공하며, AI가 AGI 및 ASI로 나아가면서 단기 취약성과 장기 존재 위험 모두를 다룬다.

Abstract: In this position paper, we address the persistent gap between rapidly growing
AI capabilities and lagging safety progress. Existing paradigms divide into
``Make AI Safe'', which applies post-hoc alignment and guardrails but remains
brittle and reactive, and ``Make Safe AI'', which emphasizes intrinsic safety
but struggles to address unforeseen risks in open-ended environments. We
therefore propose \textit{safe-by-coevolution} as a new formulation of the
``Make Safe AI'' paradigm, inspired by biological immunity, in which safety
becomes a dynamic, adversarial, and ongoing learning process. To operationalize
this vision, we introduce \texttt{R$^2$AI} -- \textit{Resistant and Resilient
AI} -- as a practical framework that unites resistance against known threats
with resilience to unforeseen risks. \texttt{R$^2$AI} integrates \textit{fast
and slow safe models}, adversarial simulation and verification through a
\textit{safety wind tunnel}, and continual feedback loops that guide safety and
capability to coevolve. We argue that this framework offers a scalable and
proactive path to maintain continual safety in dynamic environments, addressing
both near-term vulnerabilities and long-term existential risks as AI advances
toward AGI and ASI.

</details>


### [44] [AxelSMOTE: An Agent-Based Oversampling Algorithm for Imbalanced Classification](https://arxiv.org/abs/2509.06875)
*Sukumar Kishanthan,Asela Hevapathige*

Main category: cs.LG

TL;DR: AxelSMOTE는 데이터 불균형 문제를 해결하기 위한 혁신적인 에이전트 기반 접근법으로, 기존의 오버샘플링 기술에 대한 여러 단점을 극복합니다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습에서 클래스 불균형은 소수 클래스의 성능을 저해하는 중요한 문제입니다.

Method: AxelSMOTE는 데이터 인스턴스를 자율 에이전트로 보고 상호 작용을 통해 샘플을 생성하는 혁신적인 방법으로, 네 가지 주요 혁신을 도입합니다.

Result: 여덟 개의 불균형 데이터셋에서 실험을 수행한 결과, AxelSMOTE는 최신 샘플링 방법보다 우수한 성능을 보였습니다.

Conclusion: AxelSMOTE는 계산 효율성을 유지하면서도 클래스 불균형 문제를 효과적으로 해결합니다.

Abstract: Class imbalance in machine learning poses a significant challenge, as skewed
datasets often hinder performance on minority classes. Traditional oversampling
techniques, which are commonly used to alleviate class imbalance, have several
drawbacks: they treat features independently, lack similarity-based controls,
limit sample diversity, and fail to manage synthetic variety effectively. To
overcome these issues, we introduce AxelSMOTE, an innovative agent-based
approach that views data instances as autonomous agents engaging in complex
interactions. Based on Axelrod's cultural dissemination model, AxelSMOTE
implements four key innovations: (1) trait-based feature grouping to preserve
correlations; (2) a similarity-based probabilistic exchange mechanism for
meaningful interactions; (3) Beta distribution blending for realistic
interpolation; and (4) controlled diversity injection to avoid overfitting.
Experiments on eight imbalanced datasets demonstrate that AxelSMOTE outperforms
state-of-the-art sampling methods while maintaining computational efficiency.

</details>


### [45] [Learning words in groups: fusion algebras, tensor ranks and grokking](https://arxiv.org/abs/2509.06931)
*Maor Shutman,Oren Louidor,Ran Tessler*

Main category: cs.LG

TL;DR: 간단한 두 층의 신경망이 임의의 단어 연산을 학습할 수 있음을 보이며, 이는 주어진 그룹의 기본 자기 공액 표현의 삼중 조합을 통해 낮은 순위 텐서를 분해함으로써 이루어진다.


<details>
  <summary>Details</summary>
Motivation: 두 층 신경망의 구조와 동작을 설명하고, 이를 통해 임의의 단어 연산 학습 가능성을 탐구하기 위함이다.

Method: 특정 $3$-텐서 학습 문제로 재구성하고, 그룹의 자기 공액 표현의 삼중으로 분해하여 텐서를 낮은 순위로 구현하는 방법을 사용했다.

Result: 신경망이 효율적인 매트릭스 곱셈을 구현할 수 있음과 동시에, 제한된 너비를 활용하여 단어 텐서를 일반화 가능하게 근사할 수 있음을 보여주었다.

Conclusion: 본 연구는 신경망이 경량화된 방법으로 일반화 가능성을 갖춘 단어 연산 학습을 수행할 수 있음을 입증하였고, 기울기 하강법 하의 솔루션 도달 메커니즘에 대한 통찰을 제공한다.

Abstract: In this work, we demonstrate that a simple two-layer neural network with
standard activation functions can learn an arbitrary word operation in any
finite group, provided sufficient width is available and exhibits grokking
while doing so. To explain the mechanism by which this is achieved, we reframe
the problem as that of learning a particular $3$-tensor, which we show is
typically of low rank. A key insight is that low-rank implementations of this
tensor can be obtained by decomposing it along triplets of basic self-conjugate
representations of the group and leveraging the fusion structure to rule out
many components. Focusing on a phenomenologically similar but more tractable
surrogate model, we show that the network is able to find such low-rank
implementations (or approximations thereof), thereby using limited width to
approximate the word-tensor in a generalizable way. In the case of the simple
multiplication word, we further elucidate the form of these low-rank
implementations, showing that the network effectively implements efficient
matrix multiplication in the sense of Strassen. Our work also sheds light on
the mechanism by which a network reaches such a solution under gradient
descent.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [46] [Towards Log Analysis with AI Agents: Cowrie Case Study](https://arxiv.org/abs/2509.05306)
*Enis Karaarslan,Esin Güler,Efe Emir Yüce,Cagatay Coban*

Main category: cs.CR

TL;DR: 자연어 처리 및 AI를 활용하여 보안 허니팟 로그 분석의 자동화를 통해 수동 작업을 줄이고 공격 패턴을 식별하는 연구.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 공격 데이터 부족이 사이버 보안 연구와 교육의 진전을 방해하고 있으며, 효과적인 위협 인텔리전스를 제공하는 허니팟의 로그는 수동 분석을 어렵게 만든다.

Method: AI 에이전트를 활용하여 Cowrie 허니팟 로그를 자동으로 처리하고 분석하는 경량화된 접근 방식을 제시한다.

Result: 초기 결과는 수동 작업을 줄이고 공격 패턴을 식별하는 데 있어 파이프라인의 효과를 보여준다.

Conclusion: 이 연구는 향후 더 고급의 자율 사이버 보안 분석을 위한 기초를 마련한다.

Abstract: The scarcity of real-world attack data significantly hinders progress in
cybersecurity research and education. Although honeypots like Cowrie
effectively collect live threat intelligence, they generate overwhelming
volumes of unstructured and heterogeneous logs, rendering manual analysis
impractical. As a first step in our project on secure and efficient AI
automation, this study explores the use of AI agents for automated log
analysis. We present a lightweight and automated approach to process Cowrie
honeypot logs. Our approach leverages AI agents to intelligently parse,
summarize, and extract insights from raw data, while also considering the
security implications of deploying such an autonomous system. Preliminary
results demonstrate the pipeline's effectiveness in reducing manual effort and
identifying attack patterns, paving the way for more advanced autonomous
cybersecurity analysis in future work.

</details>


### [47] [Large Language Model Integration with Reinforcement Learning to Augment Decision-Making in Autonomous Cyber Operations](https://arxiv.org/abs/2509.05311)
*Konur Tholl,François Rivest,Mariam El Mezouar,Ranwa Al Mallah*

Main category: cs.CR

TL;DR: 본 연구는 사이버 보안 분야에서 강화 학습을 적용하여, 사전 훈련된 대형 언어 모델을 이용한 초기 학습 지도를 통해 성능을 향상시키고 탐색 행동을 줄이는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 도메인에서 자율 의사 결정을 지원하기 위해 강화 학습의 잠재력 활용.

Method: 사이버 보안 데이터로 사전 훈련된 대형 언어 모델을 통합하여 초기 훈련을 유도하고, 이를 통해 에이전트가 더 나은 결정을 내리도록 한다.

Result: LLM 통합 접근 방식을 사용하여 초기 훈련에서 2배 이상의 높은 보상을 달성하고, 약 4,500 에피소드 더 빠르게 유리한 정책에 수렴하는 것을 보여준다.

Conclusion: LLM을 통한 초기 학습 지도가 에이전트의 성능을 향상시키고 탐색 행동을 줄일 수 있음을 확인했다.

Abstract: Reinforcement Learning (RL) has shown great potential for autonomous
decision-making in the cybersecurity domain, enabling agents to learn through
direct environment interaction. However, RL agents in Autonomous Cyber
Operations (ACO) typically learn from scratch, requiring them to execute
undesirable actions to learn their consequences. In this study, we integrate
external knowledge in the form of a Large Language Model (LLM) pretrained on
cybersecurity data that our RL agent can directly leverage to make informed
decisions. By guiding initial training with an LLM, we improve baseline
performance and reduce the need for exploratory actions with obviously negative
outcomes. We evaluate our LLM-integrated approach in a simulated cybersecurity
environment, and demonstrate that our guided agent achieves over 2x higher
rewards during early training and converges to a favorable policy approximately
4,500 episodes faster than the baseline.

</details>


### [48] [Zero-Knowledge Proofs in Sublinear Space](https://arxiv.org/abs/2509.05326)
*Logan Nye*

Main category: cs.CR

TL;DR: 이 논문은 자원 제한 장치에서의 사용을 위해 서브선형 공간의 제로 지식 증명(Prover)을 개발했습니다.


<details>
  <summary>Details</summary>
Motivation: 현대의 제로 지식 증명 시스템은 메모리 사용의 선형 증가로 인해 자원 제한 장치에서 비실용적이며 대규모 작업에서 비용이 많이 듭니다.

Method: 전통적인 트리 평가 문제를 proof generation의 한 예로 변형하여, 최근의 공간 효율적인 트리 평가 알고리즘을 활용하여 전체 실행 흔적을 구체화하지 않고 증명을 조립하는 스트리밍 프로버를 설계했습니다.

Result: 이 접근법은 증명자의 메모리 사용량을 선형 T에서 O(sqrt(T))로 줄였습니다.

Conclusion: 이 연구는 전문화된 서버 기반 증명을 장치 내 증명으로 전환할 수 있는 가능성을 열어주며, 분산 시스템, 장치 내 기계 학습 및 프라이버시 보호 기술에서 응용할 수 있습니다.

Abstract: Modern zero-knowledge proof (ZKP) systems, essential for privacy and
verifiable computation, suffer from a fundamental limitation: the prover
typically uses memory that scales linearly with the computation's trace length
T, making them impractical for resource-constrained devices and prohibitively
expensive for large-scale tasks. This paper overcomes this barrier by
constructing, to our knowledge, the first sublinear-space ZKP prover. Our core
contribution is an equivalence that reframes proof generation as an instance of
the classic Tree Evaluation problem. Leveraging a recent space-efficient
tree-evaluation algorithm, we design a streaming prover that assembles the
proof without ever materializing the full execution trace. The approach reduces
prover memory from linear in T to O(sqrt(T)) (up to O(log T) lower-order terms)
while preserving proof size, verifier time, and the transcript/security
guarantees of the underlying system. This enables a shift from specialized,
server-bound proving to on-device proving, opening applications in
decentralized systems, on-device machine learning, and privacy-preserving
technologies.

</details>


### [49] [AI-in-the-Loop: Privacy Preserving Real-Time Scam Detection and Conversational Scambaiting by Leveraging LLMs and Federated Learning](https://arxiv.org/abs/2509.05362)
*Ismail Hossain,Sai Puppala,Sajedul Talukder,Md Jahangir Alam*

Main category: cs.CR

TL;DR: 본 논문은 실시간으로 사기 대화를 탐지하고 방해하는 AI 기반의 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 디지털 플랫폼에서의 피싱, 사칭 및 전화 사기와 같은 실시간 사회 공학을 이용한 사기는 지속적이고 진화하는 위협입니다.

Method: 이 시스템은 사용자 참여와 피해 최소화를 균형 있게 고려하는 안전 인식 유틸리티 기능과 지침 조정된 인공지능을 결합하고, 원시 데이터 공유 없이 지속적인 모델 업데이트를 가능하게 하는 연합 학습을 사용합니다.

Result: 실험 결과, 이 시스템은 유창하고 매력적인 응답을 생성하며(혼란도 22.3, 참여도 약 0.80), 인간 연구를 통해 현실감, 안전성 및 효과성이 강력한 기준선에 비해 유의미하게 향상된 것으로 나타났습니다.

Conclusion: 본 프레임워크는 실시간 사기 탐지, 연합 개인 정보 보호, 조정된 안전 모더레이션을 통합하여 능동적 방어 패러다임을 제시한 첫 사례입니다.

Abstract: Scams exploiting real-time social engineering -- such as phishing,
impersonation, and phone fraud -- remain a persistent and evolving threat
across digital platforms. Existing defenses are largely reactive, offering
limited protection during active interactions. We propose a privacy-preserving,
AI-in-the-loop framework that proactively detects and disrupts scam
conversations in real time. The system combines instruction-tuned artificial
intelligence with a safety-aware utility function that balances engagement with
harm minimization, and employs federated learning to enable continual model
updates without raw data sharing. Experimental evaluations show that the system
produces fluent and engaging responses (perplexity as low as 22.3, engagement
$\approx$0.80), while human studies confirm significant gains in realism,
safety, and effectiveness over strong baselines. In federated settings, models
trained with FedAvg sustain up to 30 rounds while preserving high engagement
($\approx$0.80), strong relevance ($\approx$0.74), and low PII leakage
($\leq$0.0085). Even with differential privacy, novelty and safety remain
stable, indicating that robust privacy can be achieved without sacrificing
performance. The evaluation of guard models (LlamaGuard, LlamaGuard2/3,
MD-Judge) shows a straightforward pattern: stricter moderation settings reduce
the chance of exposing personal information, but they also limit how much the
model engages in conversation. In contrast, more relaxed settings allow longer
and richer interactions, which improve scam detection, but at the cost of
higher privacy risk. To our knowledge, this is the first framework to unify
real-time scam-baiting, federated privacy preservation, and calibrated safety
moderation into a proactive defense paradigm.

</details>


### [50] [ThreatGPT: An Agentic AI Framework for Enhancing Public Safety through Threat Modeling](https://arxiv.org/abs/2509.05379)
*Sharif Noor Zisad,Ragib Hasan*

Main category: cs.CR

TL;DR: 이 논문에서는 공공 안전 시스템의 위협을 이해하고 분석하는 데 도움을 주기 위한 AI 어시스턴트인 ThreatGPT를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 스마트한 도시와 커뮤니티의 발전으로 인해 공공 안전 시스템의 복잡성이 증가하면서 보안 위협의 위험도 높아지고 있습니다.

Method: ThreatGPT는 사용자가 시스템 구성 요소를 간단히 설명하면, 다양한 인기 프레임워크를 통해 위협 분석을 수행할 수 있도록 돕습니다.

Result: ThreatGPT는 몇 개의 예로부터 학습하고 관련된 스마트 위협 모델을 생성할 수 있으며, 공격자가 어떻게 이점을 취할 수 있는지를 강조합니다.

Conclusion: ThreatGPT는 인공지능과 인간의 판단력을 결합하여 공공 시스템의 안전성을 높이는 데 기여하도록 설계되었습니다.

Abstract: As our cities and communities become smarter, the systems that keep us safe,
such as traffic control centers, emergency response networks, and public
transportation, also become more complex. With this complexity comes a greater
risk of security threats that can affect not just machines but real people's
lives. To address this challenge, we present ThreatGPT, an agentic Artificial
Intelligence (AI) assistant built to help people whether they are engineers,
safety officers, or policy makers to understand and analyze threats in public
safety systems. Instead of requiring deep cybersecurity expertise, it allows
users to simply describe the components of a system they are concerned about,
such as login systems, data storage, or communication networks. Then, with the
click of a button, users can choose how they want the system to be analyzed by
using popular frameworks such as STRIDE, MITRE ATT&CK, CVE reports, NIST, or
CISA. ThreatGPT is unique because it does not just provide threat information,
but rather it acts like a knowledgeable partner. Using few-shot learning, the
AI learns from examples and generates relevant smart threat models. It can
highlight what might go wrong, how attackers could take advantage, and what can
be done to prevent harm. Whether securing a city's infrastructure or a local
health service, this tool adapts to users' needs. In simple terms, ThreatGPT
brings together AI and human judgment to make our public systems safer. It is
designed not just to analyze threats, but to empower people to understand and
act on them, faster, smarter, and with more confidence.

</details>


### [51] [What is Cybersecurity in Space?](https://arxiv.org/abs/2509.05496)
*Charbel Mattar,Jacques Bou Abdo,Abdallah Makhoul,Benoit Piranda,Jacques Demerjian*

Main category: cs.CR

TL;DR: 이 논문은 현대 사이버 위협에 대한 저항력을 갖추지 못한 위성, 드론 및 5G 공간 링크의 보안 취약점을 다루고 있습니다.


<details>
  <summary>Details</summary>
Motivation: 우주 시스템이 현대 사이버 공격에 취약하다는 점에서 이러한 연구의 필요성이 대두되었습니다.

Method: 11개의 연구 격차를 매핑하고, 각 격차에 대해 도전 과제 및 연구 질문을 제시하였습니다.

Result: 우리는 다중 에이전트 AI 접근 방식을 강조하며, 소규모 전문화된 에이전트가 방어 임무를 공유하도록 제안합니다.

Conclusion: 5년간의 로드맵을 통해 우주 사이버 보안을 반응적인 패치에서 능동적인 회복력으로 전환할 것을 제안합니다.

Abstract: Satellites, drones, and 5G space links now support
  critical services such as air traffic, finance, and weather. Yet most
  were not built to resist modern cyber threats. Ground stations
  can be breached, GPS jammed, and supply chains compromised,
  while no shared list of vulnerabilities or safe testing range exists.
  This paper maps eleven research gaps, including secure
  routing, onboard intrusion detection, recovery methods, trusted
  supply chains, post-quantum encryption, zero-trust architectures,
  and real-time impact monitoring. For each, we outline the
  challenge, why it matters, and a guiding research question. We
  also highlight an agentic (multi-agent) AI approach where small,
  task-specific agents share defense tasks onboard instead of one
  large model.
  Finally, we propose a five-year roadmap: post-quantum and
  QKD flight trials, open cyber-ranges, clearer vulnerability shar ing, and
early multi-agent deployments. These steps move space
  cybersecurity from reactive patching toward proactive resilience.

</details>


### [52] [Tell-Tale Watermarks for Explanatory Reasoning in Synthetic Media Forensics](https://arxiv.org/abs/2509.05753)
*Ching-Chun Chang,Isao Echizen*

Main category: cs.CR

TL;DR: 합성 미디어의 부상이 현실과 허구의 경계를 모호하게 만들고 있으며, 이는 사이버 공간에서 공공의 신뢰를 해치는 정보 유행을 초래하고 있다. 이 연구에서는 합성 미디어의 변형 이력을 추적하기 위한 워터마킹 시스템을 개발하여 범죄 의도의 존재 여부에 대한 깊은 증거 통찰을 드러내고자 한다.


<details>
  <summary>Details</summary>
Motivation: 합성 미디어의 발전이 실제와 허구 사이의 경계를 흐리게 하고 있으며, 이는 사이버 공간에서의 공공 신뢰를 약화시키고 있다는 문제를 해결하고자 한다.

Method: 합성 미디어의 변형 이력을 추적하는 워터마킹 시스템을 개발하고, 다양한 변형 유형에 맞춰 워터마크를 맞춤 제작하여 설명적 추론을 수행한다.

Result: 실험 평가를 통해 워터마킹의 신뢰성, 동기화 및 추적 가능성을 입증하였다.

Conclusion: 이 연구는 합성 미디어의 변형 과정에서 나타나는 해석 가능한 증거를 제공함으로써 범죄 의도에 대한 통찰을 제시한다.

Abstract: The rise of synthetic media has blurred the boundary between reality and
fabrication under the evolving power of artificial intelligence, fueling an
infodemic that erodes public trust in cyberspace. For digital imagery, a
multitude of editing applications further complicates the forensic analysis,
including semantic edits that alter content, photometric adjustments that
recalibrate colour characteristics, and geometric projections that reshape
viewpoints. Collectively, these transformations manipulate and control
perceptual interpretation of digital imagery. This susceptibility calls for
forensic enquiry into reconstructing the chain of events, thereby revealing
deeper evidential insight into the presence or absence of criminal intent. This
study seeks to address an inverse problem of tracing the underlying generation
chain that gives rise to the observed synthetic media. A tell-tale watermarking
system is developed for explanatory reasoning over the nature and extent of
transformations across the lifecycle of synthetic media. Tell-tale watermarks
are tailored to different classes of transformations, responding in a manner
that is neither strictly robust nor fragile but instead interpretable. These
watermarks function as reference clues that evolve under the same
transformation dynamics as the carrier media, leaving interpretable traces when
subjected to transformations. Explanatory reasoning is then performed to infer
the most plausible account across the combinatorial parameter space of
composite transformations. Experimental evaluations demonstrate the validity of
tell-tale watermarking with respect to fidelity, synchronicity and
traceability.

</details>


### [53] [Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System](https://arxiv.org/abs/2509.05755)
*Yu Liu,Yuchong Xie,Mingyu Luo,Zesen Liu,Zhixiang Zhang,Kaikai Zhang,Zongjie Li,Ping Chen,Shuai Wang,Dongdong She*

Main category: cs.CR

TL;DR: 이 논문은 LLM 기반의 에이전트 시스템에서 Tool Invocation Prompt(TIP)의 보안 위험을 조사하고 주요 시스템의 취약점을 드러내며 TIP 보안을 강화하기 위한 방어 메커니즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 시스템의 중요한 구성 요소인 Tool Invocation Prompt(TIP)의 보안 문제를 다루기 위해.

Method: TIP 관련 보안 위험을 조사하고 TIP 착취 워크플로우(TEW)를 통한 외부 도구 행동 탈취를 시연.

Result: 주요 LLM 기반 시스템이 원격 코드 실행(RCE) 및 서비스 거부(DoS) 공격에 취약함을 밝혔습니다.

Conclusion: TIP의 보안을 강화하기 위한 방어 메커니즘을 제안했습니다.

Abstract: LLM-based agentic systems leverage large language models to handle user
queries, make decisions, and execute external tools for complex tasks across
domains like chatbots, customer service, and software engineering. A critical
component of these systems is the Tool Invocation Prompt (TIP), which defines
tool interaction protocols and guides LLMs to ensure the security and
correctness of tool usage. Despite its importance, TIP security has been
largely overlooked. This work investigates TIP-related security risks,
revealing that major LLM-based systems like Cursor, Claude Code, and others are
vulnerable to attacks such as remote code execution (RCE) and denial of service
(DoS). Through a systematic TIP exploitation workflow (TEW), we demonstrate
external tool behavior hijacking via manipulated tool invocations. We also
propose defense mechanisms to enhance TIP security in LLM-based agentic
systems.

</details>


### [54] [Secure and Trustful Cross-domain Communication with Decentralized Identifiers in 5G and Beyond](https://arxiv.org/abs/2509.05797)
*Hai Dinh-Tuan,Sandro Rodriguez Garzon,Jianeng Fu*

Main category: cs.CR

TL;DR: 미래 모바일 네트워크에서 보안 및 신뢰할 수 있는 통신 방식의 필요성이 대두되며, 이 논문은 W3C에서 승인한 분산 식별자(DID)를 활용하여 5G 및 차세대 네트워크에서의 안전한 통신 채널 구축을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 미래 모바일 네트워크의 발전에 따라 다양한 네트워크 도메인 간의 동적인 상호작용을 지원하기 위해 신뢰할 수 있는 보안 통신 방식이 필요하다.

Method: 5G 표준 네트워크 기능과 통합된 새로운 통신 에이전트를 도입하고, DID 기반의 애플리케이션 레이어 전송 프로토콜을 활용하여 교차 도메인 상호작용의 기밀성, 무결성 및 진정성을 보장한다.

Result: DID 기반 통신 프로토콜의 두 가지 다른 버전 간 비교 분석을 통해 최신 프로토콜 반복의 호환성 이점을 발견하였다. 또한 두 프로토콜 반복에 의해 발생하는 통신 오버헤드를 전통적인 TCP/TLS에 비해 평가하였다.

Conclusion: DID 기반 통신의 발전 가능성을 제시하였다. 그러나 TCP/TLS에 비해 성능 손실이 발생하는 부분 최적화가 필요하다.

Abstract: In the evolving landscape of future mobile networks, there is a critical need
for secure and trustful communication modalities to support dynamic
interactions among core network components of different network domains. This
paper proposes the application of W3C-endorsed Decentralized Identifiers (DIDs)
to establish secure and trustful communication channels among network functions
in 5G and subsequent generations. A new communication agent is introduced that
integrates seamlessly with 5G-standardized network functions and utilizes a
DID-based application layer transport protocol to ensure confidentiality,
integrity, and authenticity for cross-domain interactions. A comparative
analysis of the two different versions of the DID-based communication protocol
for inter network function communication reveals compatibility advantages of
the latest protocol iteration. Furthermore, a comprehensive evaluation of the
communication overhead caused by both protocol iterations compared to
traditional TCP/TLS shows the benefits of using DIDs to improve communication
security, albeit with performance loses compared to TCP/TLS. These results
uncover the potential of DID-based communication for future mobile networks but
also point out areas for optimization.

</details>


### [55] [Asymmetry Vulnerability and Physical Attacks on Online Map Construction for Autonomous Driving](https://arxiv.org/abs/2509.06071)
*Yang Lou,Haibo Hu,Qun Song,Qian Xu,Yi Zhu,Rui Tan,Wei-Bin Lee,Jianping Wang*

Main category: cs.CR

TL;DR: 이 논문은 온라인 HD 맵 구축 모델의 취약성을 분석하고, 비대칭 장면에서의 예측 오류를 악용한 새로운 공격 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자동 운전 시스템에서 예측 및 계획을 위해 필수적인 정확한 환경 정보를 제공하는 고해상도 맵의 안정성을 평가하기 위함입니다.

Method: 온라인 HD 맵 구축 모델의 취약성을 체계적으로 분석하고, 비대칭 장면에서 발생하는 대칭 도로 구조에 대한 편향을 활용한 공격 프레임워크를 제안합니다.

Result: 공식 AD 데이터셋에서 맵핑 정확도가 최대 9.9% 저하되고, 최대 44%의 목표 경로에 접근 불가하게 하며, 실제 도로 경계와 충돌하는 불안전한 계획 궤적 비율이 최대 27% 증가하는 공격을 평가했습니다.

Conclusion: 이 연구는 온라인 맵 구축 모델의 첫 번째 취약성 평가를 제시하며, 디지털 및 물리적 공격을 처음으로 소개합니다.

Abstract: High-definition maps provide precise environmental information essential for
prediction and planning in autonomous driving systems. Due to the high cost of
labeling and maintenance, recent research has turned to online HD map
construction using onboard sensor data, offering wider coverage and more timely
updates for autonomous vehicles. However, the robustness of online map
construction under adversarial conditions remains underexplored. In this paper,
we present a systematic vulnerability analysis of online map construction
models, which reveals that these models exhibit an inherent bias toward
predicting symmetric road structures. In asymmetric scenes like forks or
merges, this bias often causes the model to mistakenly predict a straight
boundary that mirrors the opposite side. We demonstrate that this vulnerability
persists in the real-world and can be reliably triggered by obstruction or
targeted interference. Leveraging this vulnerability, we propose a novel
two-stage attack framework capable of manipulating online constructed maps.
First, our method identifies vulnerable asymmetric scenes along the victim AV's
potential route. Then, we optimize the location and pattern of camera-blinding
attacks and adversarial patch attacks. Evaluations on a public AD dataset
demonstrate that our attacks can degrade mapping accuracy by up to 9.9%, render
up to 44% of targeted routes unreachable, and increase unsafe planned
trajectory rates, colliding with real-world road boundaries, by up to 27%.
These attacks are also validated on a real-world testbed vehicle. We further
analyze root causes of the symmetry bias, attributing them to training data
imbalance, model architecture, and map element representation. To the best of
our knowledge, this study presents the first vulnerability assessment of online
map construction models and introduces the first digital and physical attack
against them.

</details>


### [56] [CSI-IBBS: Identity-Based Blind Signature using CSIDH](https://arxiv.org/abs/2509.06127)
*Soumya Bhoumik,Sarbari Mitra,Rohit Raj Sharma,Kuldeep Namdeo*

Main category: cs.CR

TL;DR: 본 논문에서는 CSIDH 프레임워크를 활용한 정직한 제로 지식 검증기를 갖춘 신원 기반 블라인드 서명 체계를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 신원 기반 암호화(IBC)의 가능성을 활용하고, 양자 내성 암호 체계의 필요성을 충족시키기 위한 것이다.

Method: CSIDH 프레임워크를 기반으로 한 정직한 제로 지식 검증기를 활용하여 블라인드 서명을 결합한 신원 기반 블라인드 서명 체계를 개발하였다.

Result: 양자 적대자에 대한 강력한 보호를 제공하면서도 계산 효율성을 유지한다.

Conclusion: 이 연구는 포스트 양자 시대에 안전하고 확장 가능한 암호 시스템의 개발을 발전시킨다.

Abstract: Identity-based cryptography (IBC), proposed by Adi Shamir, revolutionized
public key authentication by eliminating the need for certificates, enabling a
more efficient and scalable approach to cryptographic systems. Meanwhile, in
\cite{Katsumata2024group}, Katsumata et al. were the first to present the blind
signature protocol based on the hardness assumption of isogeny with provable
security, which resembles the Schnorr blind signature. Building upon these
foundational concepts, we propose an Identity-Based Blind Signature Scheme with
an Honest Zero-Knowledge Verifier utilizing the CSIDH framework. This scheme
combines blind signatures for privacy preservation with zero-knowledge proofs
to ensure the verifier's honesty without revealing any additional information.
  Leveraging the quantum-resistant properties of CSIDH, a post-quantum secure
scheme based on supersingular isogenies, our scheme offers strong protection
against quantum adversaries while maintaining computational efficiency. We
analyze the security of the introduced protocol in the standard cryptographic
model and demonstrate its effectiveness in safeguarding privacy and verifier
honesty. Furthermore, we present a performance evaluation, confirming the
practical viability of this quantum-resistant cryptographic solution for
privacy-preserving applications. This work advances the creation of secure, and
scalable cryptographic systems for the post-quantum era.

</details>


### [57] [Lightweight Intrusion Detection System Using a Hybrid CNN and ConvNeXt-Tiny Model for Internet of Things Networks](https://arxiv.org/abs/2509.06202)
*Fatemeh Roshanzadeh,Hamid Barati,Ali Barati*

Main category: cs.CR

TL;DR: IoT 시스템의 보안을 위해 경량화된 침입 탐지 시스템을 제안하며, 높은 정확도를 유지하면서도 리소스 제한 환경에서 효과적으로 작동함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: IoT 시스템의 확장은 보안 위험 증가를 초래하였고, 데이터 무결성, 기밀성, 가용성을 위협하고 있다. 이에 따라 IoT 시스템의 보안 및 복원력을 보장하는 것이 필수적이 되었다.

Method: CNN과 ConvNeXt-Tiny의 하이브리드 모델을 활용한 경량화되고 효율적인 침입 탐지 시스템을 제안한다. 이는 다양한 네트워크 공격을 감지하고 분류하도록 설계되었다.

Result: 제안한 방법은 99.63%의 테스트 정확도, 99.67%의 훈련 정확도, 0.0107의 에러율을 달성하였으며, 짧은 응답 시간과 낮은 리소스 소비를 유지한다.

Conclusion: 제안한 방법은 실제 IoT 환경에서 공격을 탐지하고 분류하는 데 효과적임을 보여주며, 복잡하고 자원을 많이 소모하는 접근 방식에 대한 실용적인 대안이 될 수 있다.

Abstract: The rapid expansion of Internet of Things (IoT) systems across various
domains such as industry, smart cities, healthcare, manufacturing, and
government services has led to a significant increase in security risks,
threatening data integrity, confidentiality, and availability. Consequently,
ensuring the security and resilience of IoT systems has become a critical
requirement. In this paper, we propose a lightweight and efficient intrusion
detection system (IDS) for IoT environments, leveraging a hybrid model of CNN
and ConvNeXt-Tiny. The proposed method is designed to detect and classify
different types of network attacks, particularly botnet and malicious traffic,
while the lightweight ConvNeXt-Tiny architecture enables effective deployment
in resource-constrained devices and networks. A real-world dataset comprising
both benign and malicious network packets collected from practical IoT
scenarios was employed in the experiments. The results demonstrate that the
proposed method achieves high accuracy while significantly reducing training
and inference time compared to more complex models. Specifically, the system
attained 99.63% accuracy in the testing phase, 99.67% accuracy in the training
phase, and an error rate of 0.0107 across eight classes, while maintaining
short response times and low resource consumption. These findings highlight the
effectiveness of the proposed method in detecting and classifying attacks in
real-world IoT environments, indicating that the lightweight architecture can
serve as a practical alternative to complex and resource-intensive approaches
in IoT network security.

</details>


### [58] [Neuro-Symbolic AI for Cybersecurity: State of the Art, Challenges, and Opportunities](https://arxiv.org/abs/2509.06921)
*Safayat Bin Hakim,Muhammad Adil,Alvaro Velasquez,Shouhuai Xu,Houbing Herbert Song*

Main category: cs.CR

TL;DR: 전통적인 인공지능(AI) 접근법은 사이버 보안에서 한계가 있으며, 신경-상징(NIO) AI가 이를 혁신할 수 있는 잠재력을 갖추고 있지만, 이 접근법에 대한 체계적인 이해는 부족하다. 이 연구는 이 분야를 분석하고, 다양한 사이버 보안 문제를 해결하기 위한 G-I-A 프레임워크를 도입하며, 다중 에이전트 NeSy 아키텍처의 이점과 구현 과제를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 분야의 기존 AI 접근법은 새로운 공격에 대한 견고함 부족과 목표와의 불일치를 보이며, NeSy AI는 이러한 한계를 극복하고 사이버 보안을 혁신할 가능성이 있다.

Method: 2019년부터 2025년 7월까지의 127개 출판물을 분석하여 G-I-A 프레임워크를 통해 사이버 방어 및 공격을 평가한다.

Result: 다중 에이전트 NeSy 아키텍처의 이점을 보여주고, 배포를 제약하는 표준화 격차, 계산 복잡성 및 인간-AI 협력 요구 사항과 같은 주요 실행 과제를 식별한다.

Conclusion: 인과 추론 통합이 가장 혁신적인 발전임을 보여주며, 자율 시스템의 제로-데이 익스플로잇 능력과 사회적 정렬을 유지하는 책임 있는 개발 관행의 필요성을 강조한다.

Abstract: Traditional Artificial Intelligence (AI) approaches in cybersecurity exhibit
fundamental limitations: inadequate conceptual grounding leading to
non-robustness against novel attacks; limited instructibility impeding
analyst-guided adaptation; and misalignment with cybersecurity objectives.
Neuro-Symbolic (NeSy) AI has emerged with the potential to revolutionize
cybersecurity AI. However, there is no systematic understanding of this
emerging approach. These hybrid systems address critical cybersecurity
challenges by combining neural pattern recognition with symbolic reasoning,
enabling enhanced threat understanding while introducing concerning autonomous
offensive capabilities that reshape threat landscapes. In this survey, we
systematically characterize this field by analyzing 127 publications spanning
2019-July 2025. We introduce a Grounding-Instructibility-Alignment (G-I-A)
framework to evaluate these systems, focusing on both cyber defense and cyber
offense across network security, malware analysis, and cyber operations. Our
analysis shows advantages of multi-agent NeSy architectures and identifies
critical implementation challenges including standardization gaps,
computational complexity, and human-AI collaboration requirements that
constrain deployment. We show that causal reasoning integration is the most
transformative advancement, enabling proactive defense beyond correlation-based
approaches. Our findings highlight dual-use implications where autonomous
systems demonstrate substantial capabilities in zero-day exploitation while
achieving significant cost reductions, altering threat dynamics. We provide
insights and future research directions, emphasizing the urgent need for
community-driven standardization frameworks and responsible development
practices that ensure advancement serves defensive cybersecurity objectives
while maintaining societal alignment.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [59] [Orchestrator: Active Inference for Multi-Agent Systems in Long-Horizon Tasks](https://arxiv.org/abs/2509.05651)
*Lukas Beckenbauer,Johannes-Lucas Loewe,Ge Zheng,Alexandra Brintrup*

Main category: cs.MA

TL;DR: 새로운 다중 에이전트 시스템(MAS) 프레임워크인 Orchestrator를 통해 비선형 작업의 성능을 최적화한다.


<details>
  <summary>Details</summary>
Motivation: 비선형 작업은 부분 관찰 가능성과 비최적 조정으로 인해 LLM 강화 다중 에이전트 시스템(MAS)에 도전합니다.

Method: Orchestrator는 주의력에 영감을 받은 자기 발생적 조정과 반사적 벤치마킹을 활용하여 글로벌 작업 성과를 최적화하는 새로운 MAS 프레임워크입니다.

Result: 에이전트-환경 역학을 추적하기 위한 모니터링 메커니즘을 도입하고, 능동 추론 벤치마킹을 사용하여 시스템 행동을 최적화합니다.

Conclusion: 복잡성이 증가하는 미로 문제 시리즈에 대해 프레임워크를 평가하고, 다이나믹한 비선형 환경에서 조정 및 성과 향상의 효과를 입증합니다.

Abstract: Complex, non-linear tasks challenge LLM-enhanced multi-agent systems (MAS)
due to partial observability and suboptimal coordination. We propose
Orchestrator, a novel MAS framework that leverages attention-inspired
self-emergent coordination and reflective benchmarking to optimize global task
performance. Orchestrator introduces a monitoring mechanism to track
agent-environment dynamics, using active inference benchmarks to optimize
system behavior. By tracking agent-to-agent and agent-to-environment
interaction, Orchestrator mitigates the effects of partial observability and
enables agents to approximate global task solutions more efficiently. We
evaluate the framework on a series of maze puzzles of increasing complexity,
demonstrating its effectiveness in enhancing coordination and performance in
dynamic, non-linear environments with long-horizon objectives.

</details>


### [60] [MAPF-HD: Multi-Agent Path Finding in High-Density Environments](https://arxiv.org/abs/2509.06374)
*Hiroya Makino,Seigo Ito*

Main category: cs.MA

TL;DR: 본 연구는 고밀도 환경에서의 다중 에이전트 경로 찾기(MAPF-HD)를 위한 새로운 프레임워크를 제안하며, 에이전트 간 위치 스와핑을 통해 경로를 빠르게 최적화하는 방법을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 일반적인 창고 환경에서는 에이전트 밀도를 높임으로써 공간 효율성을 개선할 수 있지만, 경로 최적화의 복잡함이 증가한다.

Method: PHANS 방법은 에이전트와 빈 정점 간의 위치 스와핑을 점진적으로 수행하며, 효율적인 경로 최적화를 위해 휴리스틱 접근 방식을 사용한다.

Result: PHANS 방법은 $700$개 이상의 셀을 포함한 대규모 환경에서도 문제를 몇 초 내에 해결할 수 있다.

Conclusion: 제안된 방법은 자동화된 창고 및 발렛 주차와 같은 대규모 응용 프로그램에서 효율성을 향상시킬 수 있는 잠재력을 가진다.

Abstract: Multi-agent path finding (MAPF) involves planning efficient paths for
multiple agents to move simultaneously while avoiding collisions. In typical
warehouse environments, agents are often sparsely distributed along aisles.
However, increasing the agent density can improve space efficiency. When the
agent density is high, we must optimize the paths not only for goal-assigned
agents but also for those obstructing them. This study proposes a novel MAPF
framework for high-density environments (MAPF-HD). Several studies have
explored MAPF in similar settings using integer linear programming (ILP).
However, ILP-based methods require substantial computation time to optimize all
agent paths simultaneously. Even in small grid-based environments with fewer
than $100$ cells, these computations can incur tens to hundreds of seconds.
These high computational costs render these methods impractical for large-scale
applications such as automated warehouses and valet parking. To address these
limitations, we introduce the phased null-agent swapping (PHANS) method. PHANS
employs a heuristic approach to incrementally swap positions between agents and
empty vertices. This method solves the MAPF-HD problem within seconds to tens
of seconds, even in large environments containing more than $700$ cells. The
proposed method can potentially improve efficiency in various real-world
applications such as warehouse logistics, traffic management, or crowd control.
Code is available at https://github.com/ToyotaCRDL/MAPF-in-High-Density-Envs.

</details>


### [61] [HECATE: An ECS-based Framework for Teaching and Developing Multi-Agent Systems](https://arxiv.org/abs/2509.06431)
*Arthur Casals,Anarosa A. F. Brandão*

Main category: cs.MA

TL;DR: HECATE는 분산 시스템 공학과 다중 에이전트 시스템 개발 간의 격차를 해소하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템(MAS)과 분산 시스템(DS) 간의 통합 편의성을 높이기 위해.

Method: Entity-Component-System 아키텍처 패턴을 기반으로 한 데이터 지향 디자인을 활용하여 MAS를 구현한다.

Result: HECATE는 MAS 개발을 간소화하고, 다양한 에이전트 모델을 지원하는 아키텍처와 구성 요소를 제공한다.

Conclusion: 본 프레임워크는 MAS 개발에서 요구되는 에이전트 특화 지식을 최소화한다.

Abstract: This paper introduces HECATE, a novel framework based on the
Entity-Component-System (ECS) architectural pattern that bridges the gap
between distributed systems engineering and MAS development. HECATE is built
using the Entity-Component-System architectural pattern, leveraging
data-oriented design to implement multiagent systems. This approach involves
engineering multiagent systems (MAS) from a distributed systems (DS)
perspective, integrating agent concepts directly into the DS domain. This
approach simplifies MAS development by (i) reducing the need for specialized
agent knowledge and (ii) leveraging familiar DS patterns and standards to
minimize the agent-specific knowledge required for engineering MAS. We present
the framework's architecture, core components, and implementation approach,
demonstrating how it supports different agent models.

</details>


### [62] [Nanobot Algorithms for Treatment of Diffuse Cancer](https://arxiv.org/abs/2509.06893)
*Noble Harasha,Nancy Lynch*

Main category: cs.MA

TL;DR: 이 논문은 암 치료를 위한 나노봇의 효율적 배치와 조정 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 나노사이즈 입자인 나노봇은 독성을 줄이고 더 효과적인 약물 전달을 약속합니다.

Method: 나노봇 에이전트의 행동과 그들의 콜로이드 환경을 모델링하고, 세 가지 알고리즘을 제안합니다.

Result: 각 알고리즘의 시뮬레이션 결과를 통해 나노봇의 위치 지정 및 치료 성공률을 평가합니다.

Conclusion: KMAR 알고리즘이 모든 유형의 암 패턴에서 우수한 성능을 발휘함을 보였습니다.

Abstract: Motile nanosized particles, or "nanobots", promise more effective and less
toxic targeted drug delivery because of their unique scale and precision. We
consider the case in which the cancer is "diffuse", dispersed such that there
are multiple distinct cancer sites. We investigate the problem of a swarm of
nanobots locating these sites and treating them by dropping drug payloads at
the sites. To improve the success of the treatment, the drug payloads must be
allocated between sites according to their "demands"; this requires extra
nanobot coordination. We present a mathematical model of the behavior of the
nanobot agents and of their colloidal environment. This includes a movement
model for agents based upon experimental findings from actual nanoparticles in
which bots noisily ascend and descend chemical gradients. We present three
algorithms: The first algorithm, called KM, is the most representative of
reality, with agents simply following naturally existing chemical signals that
surround each cancer site. The second algorithm, KMA, includes an additional
chemical payload which amplifies the existing natural signals. The third
algorithm, KMAR, includes another additional chemical payload which counteracts
the other signals, instead inducing negative chemotaxis in agents such that
they are repelled from sites that are already sufficiently treated. We present
simulation results for all algorithms across different types of cancer
arrangements. For KM, we show that the treatment is generally successful unless
the natural chemical signals are weak, in which case the treatment progresses
too slowly. For KMA, we demonstrate a significant improvement in treatment
speed but a drop in eventual success, except for concentrated cancer patterns.
For KMAR, our results show great performance across all types of cancer
patterns, demonstrating robustness and adaptability.

</details>
