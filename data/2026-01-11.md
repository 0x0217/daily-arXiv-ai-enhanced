<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 10]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Closed-Loop Multi-Agent System Driven by LLMs for Meal-Level Personalized Nutrition Management](https://arxiv.org/abs/2601.04491)
*Muqing Xu*

Main category: cs.AI

TL;DR: 개인 맞춤형 영양 관리를 위한 차세대 모바일 영양 보조 도구를 제안하며, 식사 수준의 폐쇄 루프 지원을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 개인 맞춤형 영양 관리의 필요성을 충족하기 위해서는 식사 기록, 영양 분석 및 추천을 통합해야 한다.

Method: 이미지 기반 식사 기록을 LLM 기반의 다중 에이전트 컨트롤러와 결합하여 시스템을 구축하였다.

Result: SNAPMe 식사 이미지와 시뮬레이션된 사용자를 대상으로 한 실험에서 경쟁력 있는 영양 추정, 개인화된 메뉴 및 효율적인 작업 계획을 보여주었다.

Conclusion: 다중 에이전트 LLM 제어의 가능성을 입증하고, 이미지에서 미량 영양소 추정 및 대규모 실세계 연구의 개방된 도전 과제를 드러낸다.

Abstract: Personalized nutrition management aims to tailor dietary guidance to an individual's intake and phenotype, but most existing systems handle food logging, nutrient analysis and recommendation separately. We present a next-generation mobile nutrition assistant that combines image based meal logging with an LLM driven multi agent controller to provide meal level closed loop support. The system coordinates vision, dialogue and state management agents to estimate nutrients from photos and update a daily intake budget. It then adapts the next meal plan to user preferences and dietary constraints. Experiments with SNAPMe meal images and simulated users show competitive nutrient estimation, personalized menus and efficient task plans. These findings demonstrate the feasibility of multi agent LLM control for personalized nutrition and reveal open challenges in micronutrient estimation from images and in large scale real world studies.

</details>


### [2] [Defense Against Indirect Prompt Injection via Tool Result Parsing](https://arxiv.org/abs/2601.04795)
*Qiang Yu,Xinran Cheng,Chuanyi Liu*

Main category: cs.AI

TL;DR: 이 논문은 LLM 에이전트가 물리적 시스템에서 비정상적인 행동에 대한 공격에 대응하기 위한 새로운 방안을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 물리적 환경에 대한 통제를 강화하는 과정에서 발생하는 간접 프롬프트 주입 공격의 위협을 해결하기 위해.

Method: 도구 결과 파싱을 통해 LLM에 정확한 데이터를 제공하고, 주입된 악성 코드를 효과적으로 필터링하는 새로운 방법을 제안한다.

Result: 제안한 방법은 공격 상황에서도 경쟁력 있는 유틸리티를 유지하면서 기존 방법보다 낮은 공격 성공률을 달성한다.

Conclusion: 이 방법은 기존의 방어 메커니즘을 능가하며, GitHub에서 코드를 제공한다.

Abstract: As LLM agents transition from digital assistants to physical controllers in autonomous systems and robotics, they face an escalating threat from indirect prompt injection. By embedding adversarial instructions into the results of tool calls, attackers can hijack the agent's decision-making process to execute unauthorized actions. This vulnerability poses a significant risk as agents gain more direct control over physical environments. Existing defense mechanisms against Indirect Prompt Injection (IPI) generally fall into two categories. The first involves training dedicated detection models; however, this approach entails high computational overhead for both training and inference, and requires frequent updates to keep pace with evolving attack vectors. Alternatively, prompt-based methods leverage the inherent capabilities of LLMs to detect or ignore malicious instructions via prompt engineering. Despite their flexibility, most current prompt-based defenses suffer from high Attack Success Rates (ASR), demonstrating limited robustness against sophisticated injection attacks. In this paper, we propose a novel method that provides LLMs with precise data via tool result parsing while effectively filtering out injected malicious code. Our approach achieves competitive Utility under Attack (UA) while maintaining the lowest Attack Success Rate (ASR) to date, significantly outperforming existing methods. Code is available at GitHub.

</details>


### [3] [SciFig: Towards Automating Scientific Figure Generation](https://arxiv.org/abs/2601.04390)
*Siyuan Huang,Yutong Gao,Juyang Bai,Yifan Zhou,Zi Yin,Xinxin Liu,Rama Chellappa,Chun Pong Lau,Sayan Nag,Cheng Peng,Shraman Pramanick*

Main category: cs.AI

TL;DR: SciFig는 연구 논문 텍스트에서 출판 준비 완료된 도표를 자동 생성하는 AI 에이전트 시스템입니다.


<details>
  <summary>Details</summary>
Motivation: 과학 논문에 필요한 고품질 도표와 시각화를 만드는 과정이 시간 소모적이며 깊은 도메인 지식과 전문 디자인 기술이 필요하기 때문입니다.

Method: SciFig는 연구 설명을 분석하여 구성 요소 관계를 식별하고, 관련 요소를 기능 모듈로 그룹화하며, 시각적 조직을 확립하기 위해 모듈 간 연결을 생성하는 계층적 레이아웃 생성 전략을 사용합니다. 반복적인 사고의 연쇄(COT) 피드백 메커니즘을 통해 여러 번의 시각 분석 및 추론을 통해 레이아웃을 점진적으로 개선합니다.

Result: SciFig는 데이터셋 수준 평가에서 70.1%의 전반적인 품질 성과를 달성하고, 논문 특정 평가에서 66.2%를 기록하며, 시각적 명확성, 구조적 조직 및 과학적 정확성과 같은 메트릭에서 지속적으로 높은 점수를 기록했습니다.

Conclusion: SciFig 도표 생성 파이프라인과 우리의 평가 기준은 오픈소스로 제공될 것입니다.

Abstract: Creating high-quality figures and visualizations for scientific papers is a time-consuming task that requires both deep domain knowledge and professional design skills. Despite over 2.5 million scientific papers published annually, the figure generation process remains largely manual. We introduce $\textbf{SciFig}$, an end-to-end AI agent system that generates publication-ready pipeline figures directly from research paper texts. SciFig uses a hierarchical layout generation strategy, which parses research descriptions to identify component relationships, groups related elements into functional modules, and generates inter-module connections to establish visual organization. Furthermore, an iterative chain-of-thought (CoT) feedback mechanism progressively improves layouts through multiple rounds of visual analysis and reasoning. We introduce a rubric-based evaluation framework that analyzes 2,219 real scientific figures to extract evaluation rubrics and automatically generates comprehensive evaluation criteria. SciFig demonstrates remarkable performance: achieving 70.1$\%$ overall quality on dataset-level evaluation and 66.2$\%$ on paper-specific evaluation, and consistently high scores across metrics such as visual clarity, structural organization, and scientific accuracy. SciFig figure generation pipeline and our evaluation benchmark will be open-sourced.

</details>


### [4] [Beyond the "Truth": Investigating Election Rumors on Truth Social During the 2024 Election](https://arxiv.org/abs/2601.04631)
*Etienne Casanova,R. Michael Alvarez*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델이 심리 측정에 가치를 제공함을 입증하고, 선거 루머에 관한 대규모 데이터셋을 구축하며, 루머 전파의 심리적 역학을 정량화한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델이 사회 현상을 대규모로 분석할 수 있는 유례 없는 기회를 제공하기 때문이다.

Method: 첫 번째로, 틈새의 대체 기술 플랫폼에서 선거 루머에 대한 대규모 데이터셋을 수집하고, 두 번째로, LLM을 활용한 고정밀 내용 분류를 위한 다단계 루머 탐지 에이전트를 개발하며, 세 번째로, 자연주의적 설정에서 '환상적 진실 효과'를 포함한 루머 전파의 심리적 역학을 정량화한다.

Result: 루머 탐지 에이전트는 합성 데이터 증강 및 미세 조정된 RoBERTa 분류기, 정밀 키워드 필터링, GPT-4o mini를 사용하는 2단계 LLM 검증 파이프라인을 결합한다. 연구 결과에 따르면 추가 노출이 있을 때마다 공유 확률이 꾸준히 상승하며, 이념적으로 동질적인 네트워크에서의 투약-반응 신념 강화에 대한 대규모 경험적 증거를 제공한다. 시뮬레이션 결과는 또한 사용자의 거의 1/4가 단 4회의 전파 반복 내에 '감염'되게 된다는 빠른 전염 효과를 보여준다.

Conclusion: 이러한 결과들은 LLM이 믿음의 역학과 대규모 현실 데이터셋에서 허위 정보의 확산 측정을 가능하게 하여 심리 과학을 변화시킬 수 있음을 보여준다.

Abstract: Large language models (LLMs) offer unprecedented opportunities for analyzing social phenomena at scale. This paper demonstrates the value of LLMs in psychological measurement by (1) compiling the first large-scale dataset of election rumors on a niche alt-tech platform, (2) developing a multistage Rumor Detection Agent that leverages LLMs for high-precision content classification, and (3) quantifying the psychological dynamics of rumor propagation, specifically the "illusory truth effect" in a naturalistic setting. The Rumor Detection Agent combines (i) a synthetic data-augmented, fine-tuned RoBERTa classifier, (ii) precision keyword filtering, and (iii) a two-pass LLM verification pipeline using GPT-4o mini. The findings reveal that sharing probability rises steadily with each additional exposure, providing large-scale empirical evidence for dose-response belief reinforcement in ideologically homogeneous networks. Simulation results further demonstrate rapid contagion effects: nearly one quarter of users become "infected" within just four propagation iterations. Taken together, these results illustrate how LLMs can transform psychological science by enabling the rigorous measurement of belief dynamics and misinformation spread in massive, real-world datasets.

</details>


### [5] [ResMAS: Resilience Optimization in LLM-based Multi-agent Systems](https://arxiv.org/abs/2601.04694)
*Zhilun Zhou,Zihan Liu,Jiahe Liu,Qingyu Shao,Yihan Wang,Kun Shao,Depeng Jin,Fengli Xu*

Main category: cs.AI

TL;DR: LLM 기반 멀티 에이전트 시스템의 회복력을 향상시키기 위한 프레임워크 ResMAS를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 멀티 에이전트 시스템(MAS)의 회복력 향상이 필요하다.

Method: 두 단계 프레임워크 ResMAS를 통해 MAS의 회복성을 개선하는 방법을 제안합니다. 첫째, 보상 모델을 학습하여 MAS의 회복력을 예측하고, 이를 기반으로 강화 학습을 통해 특정 작업에 대한 회복력이 있는 토폴로지를 자동으로 설계하는 토폴로지 생성기를 훈련합니다. 둘째, 각 에이전트의 연결 및 상호작용에 따라 프롬프트를 개선하는 토폴로지 인식 프롬프트 최적화 방법을 도입합니다.

Result: 광범위한 작업에 대한 실험 결과, 제안한 접근 방식이 다양한 제약 조건에서 MAS의 회복력을 실질적으로 개선함을 보여줍니다.

Conclusion: 제안한 프레임워크는 새로운 작업 및 모델에 대한 강력한 일반화 능력을 보여 주며, 회복력이 있는 MAS 구축의 가능성을 강조합니다.

Abstract: Large Language Model-based Multi-Agent Systems (LLM-based MAS), where multiple LLM agents collaborate to solve complex tasks, have shown impressive performance in many areas. However, MAS are typically distributed across different devices or environments, making them vulnerable to perturbations such as agent failures. While existing works have studied the adversarial attacks and corresponding defense strategies, they mainly focus on reactively detecting and mitigating attacks after they occur rather than proactively designing inherently resilient systems. In this work, we study the resilience of LLM-based MAS under perturbations and find that both the communication topology and prompt design significantly influence system resilience. Motivated by these findings, we propose ResMAS: a two-stage framework for enhancing MAS resilience. First, we train a reward model to predict the MAS's resilience, based on which we train a topology generator to automatically design resilient topology for specific tasks through reinforcement learning. Second, we introduce a topology-aware prompt optimization method that refines each agent's prompt based on its connections and interactions with other agents. Extensive experiments across a range of tasks show that our approach substantially improves MAS resilience under various constraints. Moreover, our framework demonstrates strong generalization ability to new tasks and models, highlighting its potential for building resilient MASs.

</details>


### [6] [Thinking-Based Non-Thinking: Solving the Reward Hacking Problem in Training Hybrid Reasoning Models via Reinforcement Learning](https://arxiv.org/abs/2601.04805)
*Siyuan Gan,Jiaheng Liu,Boyan Wang,Tianpei Yang,Runqing Miao,Yuyao Zhang,Fanyu Meng,Junlan Feng,Linjian Meng,Jing Huo,Yang Gao*

Main category: cs.AI

TL;DR: 본 논문은 Thinking-Based Non-Thinking (TNT)이라는 모델을 제안하며, 이는 기존 모델보다 약 50%의 토큰 사용량을 줄이고, 정확도를 상당히 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 기존 대규모 추론 모델(LRM)은 뛰어난 성능을 보이나, 긴 사고 과정으로 인해 계산 비용이 증가하는 문제를 해결하고자 합니다.

Method: TNT 모델은 감독 학습(SFT)을 사용하지 않고, 해결과정에서 발생한 정보를 활용하여 다양한 쿼리에 대해 비사고적 응답의 최대 토큰 사용량을 다르게 설정합니다.

Result: 다섯 개의 수학 벤치마크 실험에서 TNT는 기존 모델에 비해 약 50%의 토큰 사용량 감소와 정확도 개선을 보였습니다.

Conclusion: TNT는 모든 테스트된 방법 중에서 정확도와 효율성 간의 최적의 균형을 달성하며, 보상 해킹 문제 확률을 10% 미만으로 유지합니다.

Abstract: Large reasoning models (LRMs) have attracted much attention due to their exceptional performance. However, their performance mainly stems from thinking, a long Chain of Thought (CoT), which significantly increase computational overhead. To address this overthinking problem, existing work focuses on using reinforcement learning (RL) to train hybrid reasoning models that automatically decide whether to engage in thinking or not based on the complexity of the query. Unfortunately, using RL will suffer the the reward hacking problem, e.g., the model engages in thinking but is judged as not doing so, resulting in incorrect rewards. To mitigate this problem, existing works either employ supervised fine-tuning (SFT), which incurs high computational costs, or enforce uniform token limits on non-thinking responses, which yields limited mitigation of the problem. In this paper, we propose Thinking-Based Non-Thinking (TNT). It does not employ SFT, and sets different maximum token usage for responses not using thinking across various queries by leveraging information from the solution component of the responses using thinking. Experiments on five mathematical benchmarks demonstrate that TNT reduces token usage by around 50% compared to DeepSeek-R1-Distill-Qwen-1.5B/7B and DeepScaleR-1.5B, while significantly improving accuracy. In fact, TNT achieves the optimal trade-off between accuracy and efficiency among all tested methods. Additionally, the probability of reward hacking problem in TNT's responses, which are classified as not using thinking, remains below 10% across all tested datasets.

</details>


### [7] [T-Retriever: Tree-based Hierarchical Retrieval Augmented Generation for Textual Graphs](https://arxiv.org/abs/2601.04945)
*Chunyu Wei,Huaiyu Qin,Siyuan He,Yunhai Wang,Yueguo Chen*

Main category: cs.AI

TL;DR: T-Retriever는 계층 정보를 관리하는 데 있어 기존 RAG의 한계를 극복하기 위해 고안된 새로운 프레임워크로, 더 나은 응답의 일관성과 관련성을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 현재 그래프 기반 RAG 접근 방법은 계층 정보 관리를 위해 고정된 층별 압축 할당량을 부과하여 지역 그래프 구조를 손상시키고, 의미론적 내용을 무시하면서 위계 구조를 우선시하는 두 가지 중요한 한계가 있다.

Method: T-Retriever는 의미와 구조에 기반한 인코딩 트리를 사용하여 속성 그래프 검색을 트리 기반 검색으로 재구성하는 새로운 프레임워크이다. 이 접근 방식은 인공적인 압축 할당량을 그래프의 자연스러운 계층 구조를 보존하는 글로벌 최적화 전략으로 대체하는 Adaptive Compression Encoding과, 계층 파티션을 생성할 때 구조적 응집력과 의미 일관성을 동시에 최적화하는 Semantic-Structural Entropy($S^2$-Entropy)라는 두 가지 주요 혁신을 특징으로 한다.

Result: T-Retriever는 다양한 그래프 추론 벤치마크에서 실험을 통해 최첨단 RAG 방법들보다 훨씬 더 우수한 성능을 보이며, 복잡한 쿼리에 대해 더 일관되고 맥락적으로 관련 있는 응답을 제공한다.

Conclusion: T-Retriever는 계층 정보를 효과적으로 활용함으로써 그래프 기반 검색 시스템의 성능을 크게 향상시킨다.

Abstract: Retrieval-Augmented Generation (RAG) has significantly enhanced Large Language Models' ability to access external knowledge, yet current graph-based RAG approaches face two critical limitations in managing hierarchical information: they impose rigid layer-specific compression quotas that damage local graph structures, and they prioritize topological structure while neglecting semantic content. We introduce T-Retriever, a novel framework that reformulates attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree. Our approach features two key innovations: (1) Adaptive Compression Encoding, which replaces artificial compression quotas with a global optimization strategy that preserves the graph's natural hierarchical organization, and (2) Semantic-Structural Entropy ($S^2$-Entropy), which jointly optimizes for both structural cohesion and semantic consistency when creating hierarchical partitions. Experiments across diverse graph reasoning benchmarks demonstrate that T-Retriever significantly outperforms state-of-the-art RAG methods, providing more coherent and contextually relevant responses to complex queries.

</details>


### [8] [Arabic Prompts with English Tools: A Benchmark](https://arxiv.org/abs/2601.05101)
*Konstantin Kubrak,Ahmed El-Moselhy,Ammar Alsulami,Remaz Altuwaim,Hassan Ismail Fawaz,Faisal Alsaby*

Main category: cs.AI

TL;DR: 아랍어에 대한 LLM의 도구 호출 및 대리 능력을 평가하기 위한 최초의 전용 벤치마크가 소개되었으며, 사용자 상호작용 시 정확도가 5-10% 감소함을 발견했다.


<details>
  <summary>Details</summary>
Motivation: 아랍어 원어민 대형 언어 모델 개발이 가속화되고 있지만 평가 기준은 영어에 집중되어 있어 아랍어로의 성능 평가가 부족하다.

Method: 아랍어에서 LLM의 도구 호출 및 대리 능력을 평가하기 위한 표준화된 프레임워크를 제공한다.

Result: 아랍어로 상호작용할 때 도구 호출 정확도가 평균 5-10% 감소한다는 중요한 성과를 발견했다.

Conclusion: 이 벤치마크는 아랍어 사용자에게 더 신뢰할 수 있고 언어적으로 공평한 AI 에이전트 개발을 촉진하는 데 기여할 것이다.

Abstract: Large Language Models (LLMs) are now integral to numerous industries, increasingly serving as the core reasoning engine for autonomous agents that perform complex tasks through tool-use. While the development of Arabic-native LLMs is accelerating, the benchmarks for evaluating their capabilities lag behind, with most existing frameworks focusing on English. A critical and overlooked area is tool-calling, where the performance of models prompted in non-English languages like Arabic is poorly understood, especially since these models are often pretrained on predominantly English data. This paper addresses this critical gap by introducing the first dedicated benchmark for evaluating the tool-calling and agentic capabilities of LLMs in the Arabic language. Our work provides a standardized framework to measure the functional accuracy and robustness of models in Arabic agentic workflows. Our findings reveal a huge performance gap: when users interact in Arabic, tool-calling accuracy drops by an average of 5-10\%, regardless of whether the tool descriptions themselves are in Arabic or English. By shedding light on these critical challenges, this benchmark aims to foster the development of more reliable and linguistically equitable AI agents for Arabic-speaking users.

</details>


### [9] [Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction](https://arxiv.org/abs/2601.05107)
*Muzhao Tian,Zisu Huang,Xiaohua Wang,Jingwen Xu,Zhengkang Guo,Qi Qian,Yuanzhe Shen,Kaitao Song,Jiakang Yuan,Changze Lv,Xiaoqing Zheng*

Main category: cs.AI

TL;DR: 이 논문에서는 LLM 기반 에이전트의 메모리 사용 방식을 개선하기 위한 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트의 장기 상호 작용에서 개인화와 스타일 일관성을 유지하기 위해 누적 메모리가 중요합니다.

Method: 기억 의존성에 대한 행동 지표를 소개하고, 사용자가 메모리 의존성을 동적으로 조절할 수 있는 Steerable Memory Agent(구축된 프레임워크)를 제안합니다.

Result: 실험 결과, 제안된 방법이 기존의 유도 및 고정 메모리 마스킹 전략보다 일관되게 우수한 성능을 보여줍니다.

Conclusion: 이 연구는 개인화된 인간-에이전트 협업을 위한 더 세밀하고 효과적인 제어를 제공합니다.

Abstract: As LLM-based agents are increasingly used in long-term interactions, cumulative memory is critical for enabling personalization and maintaining stylistic consistency. However, most existing systems adopt an ``all-or-nothing'' approach to memory usage: incorporating all relevant past information can lead to \textit{Memory Anchoring}, where the agent is trapped by past interactions, while excluding memory entirely results in under-utilization and the loss of important interaction history. We show that an agent's reliance on memory can be modeled as an explicit and user-controllable dimension. We first introduce a behavioral metric of memory dependence to quantify the influence of past interactions on current outputs. We then propose \textbf{Stee}rable \textbf{M}emory Agent, \texttt{SteeM}, a framework that allows users to dynamically regulate memory reliance, ranging from a fresh-start mode that promotes innovation to a high-fidelity mode that closely follows interaction history. Experiments across different scenarios demonstrate that our approach consistently outperforms conventional prompting and rigid memory masking strategies, yielding a more nuanced and effective control for personalized human-agent collaboration.

</details>


### [10] [MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents](https://arxiv.org/abs/2601.05215)
*Tamil Sudaravan Mohan Doss,Michael Xu,Sudha Rao,Andrew D. Wilson,Balasaravanan Thoravi Kumaravel*

Main category: cs.AI

TL;DR: 본 연구에서는 메모리 인식을 고려한 혼합 주도 LLM 에이전트를 Open-world Minecraft에서 테스트하기 위한 사용자 작성 기준 및 평가 도구인 MineNPC-Task를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: Minecraft에서 LLM 에이전트의 성능을 평가하고, 메모리 인식을 기반으로 한 상호 작용을 강화하기 위해.

Method: 전문가 플레이어와의 공동 플레이에서 유도된 태스크를 사용하고 이를 매개변수 템플릿으로 정규화하여 기계 검증 가능한 검증자와 결합하는 평가 도구를 구현.

Result: GPT-4o를 통해 216개의 서브태스크를 8명의 경험이 풍부한 플레이어와 평가하였고, 코드 실행, 인벤토리/도구 처리, 참조 및 탐색에서 반복적인 오류 패턴을 관찰.

Conclusion: 기억의 지속성이 요구되며, 모든 태스크, 검증자, 로그 및 평가 도구를 공개해 메모리 인식 에이전트의 투명하고 재현 가능한 평가를 지원한다.

Abstract: We present \textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.
  As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \textbf{216} subtasks across \textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [11] [Quantum Secure Biometric Authentication in Decentralised Systems](https://arxiv.org/abs/2601.04852)
*Tooba Qasim,Vasilios A. Siris,Izak Oosthuizen,Muttukrishnan Rajarajan,Sujit Biswas*

Main category: cs.CR

TL;DR: 이 논문은 양자 보안 통신 프로토콜을 제안하여 중앙 집중식 생체 인증의 개인정보 보호 및 확장성 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 생체 인증은 스마트 도시의 디지털 신원 시스템에 필수적이며, 서비스 접근의 안전성을 보장하는 데 중요한 역할을 합니다.

Method: 향상된 양자 키 배포(QKD) 시스템 위에 구축된 양자 보안 통신 프로토콜을 제안합니다. 이 프로토콜은 고전 및 양자 QKD의 두 층에서 양자 저항 인증을 통합합니다.

Result: Qiskit 기반 시뮬레이션을 통해 초당 15비트의 키 생성 속도와 89%의 효율성을 보여줍니다.

Conclusion: 이 양층 구조의 양자 저항 접근 방식은 차세대 스마트 도시 인프라에 대한 확장 가능하고 강력한 인증을 제공합니다.

Abstract: Biometric authentication has become integral to digital identity systems, particularly in smart cities where it en-ables secure access to services across governance, trans-portation, and public infrastructure. Centralised archi-tectures, though widely used, pose privacy and scalabil-ity challenges due to the aggregation of sensitive biomet-ric data. Decentralised identity frameworks offer better data sovereignty and eliminate single points of failure but introduce new security concerns, particularly around mu-tual trust among distributed devices. In such environments, biometric sensors and verification agents must authenticate one another before sharing sensitive biometric data. Ex-isting authentication schemes rely on classical public key infrastructure, which is increasingly susceptible to quan-tum attacks. This work addresses this gap by propos-ing a quantum-secure communication protocol for decen-tralised biometric systems, built upon an enhanced Quan-tum Key Distribution (QKD) system. The protocol incorpo-rates quantum-resilient authentication at both the classical and quantum layers of QKD: post-quantum cryptography (PQC) is used to secure the classical channel, while authen-tication qubits verify the integrity of the quantum channel. Once trust is established, QKD generates symmetric keys for encrypting biometric data in transit. Qiskit-based sim-ulations show a key generation rate of 15 bits/sec and 89% efficiency. This layered, quantum-resilient approach offers scalable, robust authentication for next-generation smart city infrastructures.

</details>


### [12] [CurricuLLM: Designing Personalized and Workforce-Aligned Cybersecurity Curricula Using Fine-Tuned LLMs](https://arxiv.org/abs/2601.04940)
*Arthur Nijdam,Harri Kähkönen,Valtteri Niemi,Paul Stankovski Wagner,Sara Ramezanian*

Main category: cs.CR

TL;DR: CurricuLLM은 사이버 보안 교육 과정의 자동 설계 및 분석을 위한 프레임워크로, 개인 맞춤형 커리큘럼 설계, 산업 수요에 맞춘 데이터 기반 파이프라인, 그리고 수정된 LLM을 활용한 종합적인 방법론을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 프로그램이 졸업생에게 요구되는 기술을 갖추지 못하고, 커리큘럼 설계가 비용이 많이 들고 노동 집약적이라는 문제를 해결하기 위해 연구하였다.

Method: CurricuLLM 프레임워크는 PreprocessLM과 ClassifyLM이라는 두 단계 접근 방식을 채택하여, 입력 데이터를 표준화하고 과정 내용을 사이버 보안의 아홉 가지 지식 영역에 할당한다.

Result: BERT 모델을 ClassifyLM으로 선택하고, 실제 사이버 보안 커리큘럼을 분석한 전문가들로부터 검증을 받았다.

Conclusion: CurricuLLM은 노동 집약적인 커리큘럼 분석을 대체하는 효율적인 솔루션으로, 교육 프로그램을 특정 직무 역할 및 산업 수요와 정렬시킬 수 있는 기반을 마련한다.

Abstract: The cybersecurity landscape is constantly evolving, driven by increased digitalization and new cybersecurity threats. Cybersecurity programs often fail to equip graduates with skills demanded by the workforce, particularly concerning recent developments in cybersecurity, as curriculum design is costly and labor-intensive. To address this misalignment, we present a novel Large Language Model (LLM)-based framework for automated design and analysis of cybersecurity curricula, called CurricuLLM. Our approach provides three key contributions: (1) automation of personalized curriculum design, (2) a data-driven pipeline aligned with industry demands, and (3) a comprehensive methodology for leveraging fine-tuned LLMs in curriculum development.
  CurricuLLM utilizes a two-tier approach consisting of PreprocessLM, which standardizes input data, and ClassifyLM, which assigns course content to nine Knowledge Areas in cybersecurity. We systematically evaluated multiple Natural Language Processing (NLP) architectures and fine-tuning strategies, ultimately selecting the Bidirectional Encoder Representations from Transformers (BERT) model as ClassifyLM, fine-tuned on foundational cybersecurity concepts and workforce competencies.
  We are the first to validate our method with human experts who analyzed real-world cybersecurity curricula and frameworks, motivating that CurricuLLM is an efficient solution to replace labor-intensive curriculum analysis. Moreover, once course content has been classified, it can be integrated with established cybersecurity role-based weights, enabling alignment of the educational program with specific job roles, workforce categories, or general market needs. This lays the foundation for personalized, workforce-aligned cybersecurity curricula that prepare students for the evolving demands in cybersecurity.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [Survival Dynamics of Neural and Programmatic Policies in Evolutionary Reinforcement Learning](https://arxiv.org/abs/2601.04365)
*Anton Roupassov-Ruiz,Yiyang Zuo*

Main category: cs.LG

TL;DR: 본 연구는 프로그래매틱 정책(PERL)이 인공 신경망(NERL)의 성능을 초과할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 에볼루셔너리 강화학습 작업에서 에이전트 정책이 모듈 구조가 부족해 행동 해석에 제한이 있다.

Method: 부드럽고 미분 가능한 의사결정 목록(SDDL)으로 구현된 프로그램 정책(PERL)을 조사하고, 1992년 인공지능 생명(ALife) ERL 테스트베드를 재구현하여 생존 분석을 수행했다.

Result: PERL과 NERL 간의 생존 확률에서 통계적으로 유의미한 차이를 발견하였고, PERL 에이전트는 NERL 에이전트보다 평균 201.69 스텝 더 오래 생존하였다.

Conclusion: 프로그램 정책은 ALife에서 신경 정책의 생존 성능을 초과할 수 있음을 보여준다.

Abstract: In evolutionary reinforcement learning tasks (ERL), agent policies are often encoded as small artificial neural networks (NERL). Such representations lack explicit modular structure, limiting behavioral interpretation. We investigate whether programmatic policies (PERL), implemented as soft, differentiable decision lists (SDDL), can match the performance of NERL. To support reproducible evaluation, we provide the first fully specified and open-source reimplementation of the classic 1992 Artificial Life (ALife) ERL testbed. We conduct a rigorous survival analysis across 4000 independent trials utilizing Kaplan-Meier curves and Restricted Mean Survival Time (RMST) metrics absent in the original study. We find a statistically significant difference in survival probability between PERL and NERL. PERL agents survive on average 201.69 steps longer than NERL agents. Moreover, SDDL agents using learning alone (no evolution) survive on average 73.67 steps longer than neural agents using both learning and evaluation. These results demonstrate that programmatic policies can exceed the survival performance of neural policies in ALife.

</details>


### [14] [Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead](https://arxiv.org/abs/2601.04686)
*Oluwatosin Oseni,Shengjie Wang,Jun Zhu,Micah Corah*

Main category: cs.LG

TL;DR: Nightmare Dreamer는 안전 보장을 제공하는 모델 기반 강화 학습 알고리즘으로, 안전 위반을 예측하고 행동을 계획하여 보상을 극대화하면서 안전 위반을 거의 제로로 유지합니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습(RL)의 현실 세계 응용 분야에서의 성공에도 불구하고, 안전 보장이 부족하여 RL의 채택이 제한적입니다.

Method: Nightmare Dreamer는 학습된 세계 모델을 활용하여 잠재적인 안전 위반을 예측하고 이에 따라 행동을 계획하는 안전한 RL 알고리즘입니다.

Result: Nightmare Dreamer는 보상 최대화와 함께 거의 제로에 가까운 안전 위반을 달성하며, 안전 체육관(Safety Gymnasium) 작업에서 모델 자유 기반선보다 성능이 우수하고 이미지 관찰만 사용하여 효율성에서 거의 20배 개선을 이룹니다.

Conclusion: 이 연구는 안전한 강화 학습 알고리즘을 제시하며, 실제 애플리케이션에서의 RL 채택을 촉진할 가능성을 보여줍니다.

Abstract: Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.

</details>


### [15] [Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward](https://arxiv.org/abs/2601.05073)
*Jianlong Chen,Daocheng Fu,Shengze Xu,Jiawei Chen,Yuan Feng,Yue Yang,Junchi Yan,Hongyuan Zha,Renqiu Xia*

Main category: cs.LG

TL;DR: MLLM이 복잡한 기하학적 추론에 어려움을 겪는 문제를 해결하기 위해 지역 목표 평가 및 학습으로 접근하는 새로운 패러다임을 제안한다.


<details>
  <summary>Details</summary>
Motivation: MLLM은 '블랙 박스' 결과 기반 감독이 운 좋은 추측과 철저한 추론을 구분하지 못하여 복잡한 기하학적 추론에 어려움을 겪는다.

Method: GeoGoal이라는 벤치마크를 구축하여 추상적인 증명을 검증 가능한 수치적 하위 목표로 변환하는 정교한 형식 검증 데이터 엔진을 사용한다. 이를 통해 Sub-Goal Verifiable Reward(SGVR) 프레임워크를 제안한다.

Result: SGVR은 기하학적 성능을 9.7% 향상시키고 일반 수학 및 기타 일반 추론 작업에서도 각각 8.0% 및 2.8%의 향상을 보여 강력한 일반화를 발휘한다.

Conclusion: SGVR은 다양한 도메인에 걸쳐 넓은 적용 가능성을 보여준다.

Abstract: Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because "black box" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [16] [FinDeepForecast: A Live Multi-Agent System for Benchmarking Deep Research Agents in Financial Forecasting](https://arxiv.org/abs/2601.05039)
*Xiangyu Li,Xuan Yao,Guohao Qi,Fengbin Zhu,Kelvin J. L. Koa,Xiang Yao Ng,Ziyang Liu,Xingyu Ni,Chang Liu,Yonghui Yang,Yang Zhang,Wenjie Wang,Fuli Feng,Chao Wang,Huanbo Luan,Xiaofen Xing,Xiangmin Xu,Tat-Seng Chua,Ke-Wei Huang*

Main category: cs.MA

TL;DR: DR 에이전트는 복잡한 연구 과제를 수행하는 데 중요한 변화를 가져왔으나, 실제 연구 지향적 과제에 대한 평가가 부족하다. 이를 해결하기 위해, 우리는 DR 에이전트를 평가하는 최초의 시스템인 FinDeepForecast를 소개한다.


<details>
  <summary>Details</summary>
Motivation: DR 에이전트의 실제 연구 지향적 과제에 대한 예측 성능을 평가하는 것이 부족하다.

Method: FinDeepForecast는 재무 예측 과제를 자동으로 생성하여 DR 에이전트를 평가하는 다중 에이전트 시스템을 구현한다.

Result: DR 에이전트는 강력한 기준선을 일관되게 초과 달성했지만, 여전히 진정한 전방향 재무 추론에는 미치지 못했다.

Conclusion: FinDeepForecast 시스템이 향후 DR 에이전트의 발전을 지속적으로 촉진할 것으로 기대한다.

Abstract: Deep Research (DR) Agents powered by advanced Large Language Models (LLMs) have fundamentally shifted the paradigm for completing complex research tasks. Yet, a comprehensive and live evaluation of their forecasting performance on real-world, research-oriented tasks in high-stakes domains (e.g., finance) remains underexplored. We introduce FinDeepForecast, the first live, end-to-end multi-agent system for automatically evaluating DR agents by continuously generating research-oriented financial forecasting tasks. This system is equipped with a dual-track taxonomy, enabling the dynamic generation of recurrent and non-recurrent forecasting tasks at both corporate and macro levels. With this system, we generate FinDeepForecastBench, a weekly evaluation benchmark over a ten-week horizon, encompassing 8 global economies and 1,314 listed companies, and evaluate 13 representative methods. Extensive experiments show that, while DR agents consistently outperform strong baselines, their performance still falls short of genuine forward-looking financial reasoning. We expect the proposed FinDeepForecast system to consistently facilitate future advancements of DR agents in research-oriented financial forecasting tasks. The benchmark and leaderboard are publicly available on the OpenFinArena Platform.

</details>
