<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 22]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Optimal conversion from Rényi Differential Privacy to $f$-Differential Privacy](https://arxiv.org/abs/2602.04562)
*Anneliese Riess,Juan Felipe Gomez,Flavio du Pin Calmon,Julia Anne Schnabel,Georgios Kaissis*

Main category: cs.CR

TL;DR: Rényi Differential Privacy (RDP) 프로필을 유효한 가설검정 교환에 최적화된 변환 규칙으로 매핑함을 증명함.


<details>
  <summary>Details</summary>
Motivation: Rényi Differential Privacy (RDP) 프로필을 가설검정의 교환과 효과적으로 연관지을 수 있는 최적의 변환 규칙을 찾기 위함이다.

Method: RDP 프라이버시 영역의 단일 차수 교환의 교차를 기반으로 하는 규칙을 분석하고, 이를 통해 최적성의 증명을 수행함.

Result: 발견된 규칙이 모든 유효한 RDP 프로필과 Type I 오류 수준 α에 대해 최적임을 보임.

Conclusion: RDP 프라이버시 영역의 교차 규칙이 유효할 뿐만 아니라 최적임을 입증하며, 다른 어떤 블랙박스 변환도 이를 일관되게 초과할 수 없음을 보여줌.

Abstract: We prove the conjecture stated in Appendix F.3 of [Zhu et al. (2022)]: among all conversion rules that map a Rényi Differential Privacy (RDP) profile $τ\mapsto ρ(τ)$ to a valid hypothesis-testing trade-off $f$, the rule based on the intersection of single-order RDP privacy regions is optimal. This optimality holds simultaneously for all valid RDP profiles and for all Type I error levels $α$. Concretely, we show that in the space of trade-off functions, the tightest possible bound is $f_{ρ(\cdot)}(α) = \sup_{τ\geq 0.5} f_{τ,ρ(τ)}(α)$: the pointwise maximum of the single-order bounds for each RDP privacy region. Our proof unifies and sharpens the insights of [Balle et al. (2019)], [Asoodeh et al. (2021)], and [Zhu et al. (2022)]. Our analysis relies on a precise geometric characterization of the RDP privacy region, leveraging its convexity and the fact that its boundary is determined exclusively by Bernoulli mechanisms. Our results establish that the "intersection-of-RDP-privacy-regions" rule is not only valid, but optimal: no other black-box conversion can uniformly dominate it in the Blackwell sense, marking the fundamental limit of what can be inferred about a mechanism's privacy solely from its RDP guarantees.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression](https://arxiv.org/abs/2602.03906)
*Weiqi Wang,Zhiyi Tian,Chenhan Zhang,Shui Yu*

Main category: cs.LG

TL;DR: GeoIB은 정보 기하학을 활용하여 상호 정보 추정 없이 정보 압축을 제어하는 새로운 접근 방식을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 정보 병목(IB)에서는 상호 정보(MI)의 직접적인 제어 대신 변동 한계나 신경 네트워크 MI 추정기를 통해 간접적인 방식으로 구현된다.

Method: 정보 기하학의 관점에서 정보를 압축하는 GeoIB를 제안하며, KL 거리의 최소화 형태로 정확한 투영을 이용한다.

Result: 광범위한 실험을 통해 GeoIB가 일반적인 IB 기반 모델보다 예측 정확도와 압축 비율 간의 최적의 균형을 달성함을 확인했다.

Conclusion: GeoIB는 분포와 기하학적 정규화를 통합하여 불변성과 최적화 안정성을 향상시킨다.

Abstract: Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. The looseness and estimator-dependent bias can make IB "compression" only indirectly controlled and optimization fragile.
  We revisit the IB problem through the lens of information geometry and propose a \textbf{Geo}metric \textbf{I}nformation \textbf{B}ottleneck (\textbf{GeoIB}) that dispenses with mutual information (MI) estimation. We show that I(X;Z) and I(Z;Y) admit exact projection forms as minimal Kullback-Leibler (KL) distances from the joint distributions to their respective independence manifolds. Guided by this view, GeoIB controls information compression with two complementary terms: (i) a distribution-level Fisher-Rao (FR) discrepancy, which matches KL to second order and is reparameterization-invariant; and (ii) a geometry-level Jacobian-Frobenius (JF) term that provides a local capacity-type upper bound on I(Z;X) by penalizing pullback volume expansion of the encoder. We further derive a natural-gradient optimizer consistent with the FR metric and prove that the standard additive natural-gradient step is first-order equivalent to the geodesic update. We conducted extensive experiments and observed that the GeoIB achieves a better trade-off between prediction accuracy and compression ratio in the information plane than the mainstream IB baselines on popular datasets. GeoIB improves invariance and optimization stability by unifying distributional and geometric regularization under a single bottleneck multiplier. The source code of GeoIB is released at "https://anonymous.4open.science/r/G-IB-0569".

</details>


### [3] [A Consensus-Bayesian Framework for Detecting Malicious Activity in Enterprise Directory Access Graphs](https://arxiv.org/abs/2602.04027)
*Pratyush Uppuluri,Shilpa Noushad,Sajan Kumar*

Main category: cs.LG

TL;DR: 기업 디렉토리 접근 그래프에서 악의적인 사용자 행동을 탐지하기 위한 컨센서스 기반 베이esian 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 디렉토리 접근 그래프에서 악의적인 사용자 행동을 효과적으로 탐지하기 위한 시스템 필요성.

Method: 디렉토리를 주제, 사용자를 에이전트로 모델링하고 영향력 가중 의견 동역학을 사용하여 접근 진화를 시뮬레이션.

Result: 악의적 행동을 강력하게 연결된 구성 요소(SCC)의 구조적 규범을 위반하는 교차 구성 요소 논리적 혼란으로 주입하였고, 의견 동역학 문헌의 이론적 보장을 통해 주제 수렴을 결정하고 이상치를 탐지함.

Conclusion: 우리의 방법은 논리적 불일치에 대한 민감성과 동적 혼란에서의 견고성을 입증하였다.

Abstract: This work presents a consensus-based Bayesian framework to detect malicious user behavior in enterprise directory access graphs. By modeling directories as topics and users as agents within a multi-level interaction graph, we simulate access evolution using influence-weighted opinion dynamics. Logical dependencies between users are encoded in dynamic matrices Ci, and directory similarity is captured via a shared influence matrix W. Malicious behavior is injected as cross-component logical perturbations that violate structural norms of strongly connected components(SCCs). We apply theoretical guarantees from opinion dynamics literature to determine topic convergence and detect anomaly via scaled opinion variance. To quantify uncertainty, we introduce a Bayesian anomaly scoring mechanism that evolves over time, using both static and online priors. Simulations over synthetic access graphs validate our method, demonstrating its sensitivity to logical inconsistencies and robustness under dynamic perturbation.

</details>


### [4] [Causal Discovery for Cross-Sectional Data Based on Super-Structure and Divide-and-Conquer](https://arxiv.org/abs/2602.03914)
*Wenyu Wang,Yaping Wan*

Main category: cs.LG

TL;DR: 본 논문은 Super-Structure 기반의 분할 정복 인과 발견에서의 높은 계산비용 문제를 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 조건부 독립 검정이 비용이 많이 들고 도메인 지식이 부족한 상황에서 정확한 Super-Structure를 구축하는 데 필요한 높은 계산 비용을 해결하기 위해.

Method: 보다 엄격한 Super-Structure 구축 요구사항을 완화하면서도 분할 정복의 알고리즘적 이점을 유지하는 새로운 경량 프레임워크를 제안합니다.

Result: 우리의 접근 방식은 효율적인 그래프 분할 및 병합 전략을 통합하여 CI 검정 오버헤드를 크게 줄이면서 정확성을 손상시키지 않습니다.

Conclusion: 정확하고 확장 가능한 인과 발견이 초기 Super-Structure에 대한 최소한의 가정하에서도 달성 가능하다는 것을 입증하며, 생물 의학 및 사회 과학 연구와 같은 대규모 지식 부족 분야에 분할 정복 방법을 적용할 수 있는 새로운 경로를 열어줍니다.

Abstract: This paper tackles a critical bottleneck in Super-Structure-based divide-and-conquer causal discovery: the high computational cost of constructing accurate Super-Structures--particularly when conditional independence (CI) tests are expensive and domain knowledge is unavailable. We propose a novel, lightweight framework that relaxes the strict requirements on Super-Structure construction while preserving the algorithmic benefits of divide-and-conquer. By integrating weakly constrained Super-Structures with efficient graph partitioning and merging strategies, our approach substantially lowers CI test overhead without sacrificing accuracy. We instantiate the framework in a concrete causal discovery algorithm and rigorously evaluate its components on synthetic data. Comprehensive experiments on Gaussian Bayesian networks, including magic-NIAB, ECOLI70, and magic-IRRI, demonstrate that our method matches or closely approximates the structural accuracy of PC and FCI while drastically reducing the number of CI tests. Further validation on the real-world China Health and Retirement Longitudinal Study (CHARLS) dataset confirms its practical applicability. Our results establish that accurate, scalable causal discovery is achievable even under minimal assumptions about the initial Super-Structure, opening new avenues for applying divide-and-conquer methods to large-scale, knowledge-scarce domains such as biomedical and social science research.

</details>


### [5] [Autonomous AI Agents for Real-Time Affordable Housing Site Selection: Multi-Objective Reinforcement Learning Under Regulatory Constraints](https://arxiv.org/abs/2602.03940)
*Olaf Yunus Laitinen Imanov,Duygu Erisken,Derya Umut Kulali,Taner Yilmaz,Rana Irem Turhan*

Main category: cs.LG

TL;DR: 이 논문은 규제 제약 하에서 실시간 저렴한 주택 부지 선정을 위한 AURA라는 다중 에이전트 강화 학습 시스템을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 저렴한 주택 부족 문제는 수십억 명에게 영향을 미치며, 토지 부족과 규제가 부지 선택을 지연시킵니다.

Method: AURA는 접근성, 환경 영향, 건설 비용 및 사회적 형평성을 최적화하면서 실행 가능성을 보장하는 제약이 있는 다중 목표 마르코프 결정 과정으로 작업을 모델링합니다.

Result: AURA는 8개 미국 대도시의 데이터 세트를 기반으로 94.3%의 규제 준수를 달성하고 강력한 기준 대비 Pareto 하이퍼볼륨을 37.2% 개선합니다.

Conclusion: 뉴욕시 2026 사례 연구에서 AURA는 선정 시간을 18개월에서 72시간으로 단축시키고, 23% 더 많은 실행 가능한 부지를 식별했습니다.

Abstract: Affordable housing shortages affect billions, while land scarcity and regulations make site selection slow. We present AURA (Autonomous Urban Resource Allocator), a hierarchical multi-agent reinforcement learning system for real-time affordable housing site selection under hard regulatory constraints (QCT, DDA, LIHTC). We model the task as a constrained multi-objective Markov decision process optimizing accessibility, environmental impact, construction cost, and social equity while enforcing feasibility. AURA uses a regulatory-aware state encoding 127 federal and local constraints, Pareto-constrained policy gradients with feasibility guarantees, and reward decomposition separating immediate costs from long-term social outcomes. On datasets from 8 U.S. metros (47,392 candidate parcels), AURA attains 94.3% regulatory compliance and improves Pareto hypervolume by 37.2% over strong baselines. In a New York City 2026 case study, it reduces selection time from 18 months to 72 hours and identifies 23% more viable sites; chosen sites have 31% better transit access and 19% lower environmental impact than expert picks.

</details>


### [6] [DeXposure-FM: A Time-series, Graph Foundation Model for Credit Exposures and Stability on Decentralized Financial Networks](https://arxiv.org/abs/2602.03981)
*Aijie Shu,Wenbin Wu,Gbenga Ibikunle,Fengxiang He*

Main category: cs.LG

TL;DR: DeFi에서의 신용 노출은 암묵적이고 토큰 중재적이며, 이로 인해 프로토콜 간 연관성이 복잡해진다. 이는 특정 토큰에 대한 충격이 상당한 전염 효과를 초래할 수 있음을 의미한다. 이를 해결하기 위해 우리의 연구는 DeXposure-FM이라는 최초의 시계열 그래프 기반 모델을 도입하여 DeFi 네트워크의 프로토콜 간 신용 노출을 측정하고 예측하는 도구를 제안한다.


<details>
  <summary>Details</summary>
Motivation: DeFi 생태계가 안정적인 통화와 같은 전통 금융 인프라와 점점 더 연결됨에 따라, 이 동적 시스템이 초래하는 위험을 효과적으로 정량화할 수 있는 도구의 필요성이 커지고 있다.

Method: DeXposure-FM은 4300개 이상의 프로토콜과 602개의 블록체인에서 4370만 개의 데이터 항목을 가진 DeXposure 데이터 세트로 훈련되며, 그래프-표 인코더와 여러 과제-specific 헤드를 활용한다. 이 모델은 프로토콜 수준의 흐름과 신용 노출 링크의 토폴로지 및 가중치 예측을 위한 훈련을 받는다.

Result: DeXposure-FM은 그래프 기반 모델 및 시간의 그래프 신경망을 포함한 최신 방법을 일관되게 초월하는 결과를 보여주며, 두 가지 기계 학습 벤치마크에서 실증적으로 검증되었다.

Conclusion: DeXposure-FM은 매크로 감독 모니터링 및 시나리오 기반 DeFi 스트레스 테스트를 지원하는 금융 경제 도구를 생성하며, 모델과 코드는 공개적으로 제공된다.

Abstract: Credit exposure in Decentralized Finance (DeFi) is often implicit and token-mediated, creating a dense web of inter-protocol dependencies. Thus, a shock to one token may result in significant and uncontrolled contagion effects. As the DeFi ecosystem becomes increasingly linked with traditional financial infrastructure through instruments, such as stablecoins, the risk posed by this dynamic demands more powerful quantification tools. We introduce DeXposure-FM, the first time-series, graph foundation model for measuring and forecasting inter-protocol credit exposure on DeFi networks, to the best of our knowledge. Employing a graph-tabular encoder, with pre-trained weight initialization, and multiple task-specific heads, DeXposure-FM is trained on the DeXposure dataset that has 43.7 million data entries, across 4,300+ protocols on 602 blockchains, covering 24,300+ unique tokens. The training is operationalized for credit-exposure forecasting, predicting the joint dynamics of (1) protocol-level flows, and (2) the topology and weights of credit-exposure links. The DeXposure-FM is empirically validated on two machine learning benchmarks; it consistently outperforms the state-of-the-art approaches, including a graph foundation model and temporal graph neural networks. DeXposure-FM further produces financial economics tools that support macroprudential monitoring and scenario-based DeFi stress testing, by enabling protocol-level systemic-importance scores, sector-level spillover and concentration measures via a forecast-then-measure pipeline. Empirical verification fully supports our financial economics tools. The model and code have been publicly available. Model: https://huggingface.co/EVIEHub/DeXposure-FM.
Code: https://github.com/EVIEHub/DeXposure-FM.

</details>


### [7] [eCP: Informative uncertainty quantification via Equivariantized Conformal Prediction with pre-trained models](https://arxiv.org/abs/2602.03986)
*Nikolaos Bousias,Lars Lindemann,George Pappas*

Main category: cs.LG

TL;DR: 본 연구에서는 변환 예측(CP)에서 사전 훈련된 모델의 그룹 대칭화가 미치는 영향을 조사합니다. CP는 데이터 교환 가능성을 가정한 후속적이고 분포에 구애받지 않는 불확실성 정량화 방법입니다. 그러나 CP의 불확실성 영역은 긴 기간의 임무에서 크게 증가할 수 있어 통계적 보장이 비정보적이 될 수 있습니다. 따라서 우리는 미리 훈련된 예측기의 그룹 평균화를 통해 CP에 기하학적 정보를 주입하여 비순응 질량을 궤도에 분산시키는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 변환 예측의 불확실성 영역이 긴 기간의 임무에서 크게 증가할 수 있는 문제를 해결하기 위해.

Method: 사전 훈련된 예측기의 그룹 평균화를 통해 CP에 기하학적 정보를 주입하여 비순응 질량을 분산시키는 방법을 사용.

Result: 우리의 접근 방식은 증가하는 볼록 순서에서 수축된 비순응 점수를 산출하며, 이는 개선된 지수 꼬리 경계와 더 뚜렷한 변환 예측 집합을 기대할 수 있음을 의미합니다.

Conclusion: 고신뢰도 수준에서 특히 더 나은 결과를 제공합니다. 우리는 보행자 궤적 예측에서 이러한 이론적 주장을 실험적으로 검증하기 위한 설계를 제안합니다.

Abstract: We study the effect of group symmetrization of pre-trained models on conformal prediction (CP), a post-hoc, distribution-free, finite-sample method of uncertainty quantification that offers formal coverage guarantees under the assumption of data exchangeability. Unfortunately, CP uncertainty regions can grow significantly in long horizon missions, rendering the statistical guarantees uninformative. To that end, we propose infusing CP with geometric information via group-averaging of the pretrained predictor to distribute the non-conformity mass across the orbits. Each sample now is treated as a representative of an orbit, thus uncertainty can be mitigated by other samples entangled to it via the orbit inducing elements of the symmetry group. Our approach provably yields contracted non-conformity scores in increasing convex order, implying improved exponential-tail bounds and sharper conformal prediction sets in expectation, especially at high confidence levels. We then propose an experimental design to test these theoretical claims in pedestrian trajectory prediction.

</details>


### [8] [Group Contrastive Learning for Weakly Paired Multimodal Data](https://arxiv.org/abs/2602.04021)
*Aditya Gorla,Hugues Van Assel,Jan-Christian Huetter,Heming Yao,Kyunghyun Cho,Aviv Regev,Russell Littman*

Main category: cs.LG

TL;DR: GROOVE는 고프레 제어 데이터에 대한 반지도 다중 모드 표현 학습 접근 방식을 제안하며, GroupCLIP이라는 새로운 그룹 수준 대조 손실을 도입하여 약한 쌍 설정에서의 대조 학습의 기본적인 격차를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 고프레 제어 데이터에서 약한 쌍으로 샘플을 결합하는 것의 중요성.

Method: GroupCLIP과 자동 인코더 프레임워크를 통합하여 다중 모드로 얽힌 표현을 장려함.

Result: GROOVE는 기존 접근 방식과 동등하거나 우수한 성능을 보이는 결과를 얻었습니다.

Conclusion: 그룹 수준의 제약을 활용하여 효과적인 다중 모드 표현 학습의 중요성을 강조합니다.

Abstract: We present GROOVE, a semi-supervised multi-modal representation learning approach for high-content perturbation data where samples across modalities are weakly paired through shared perturbation labels but lack direct correspondence. Our primary contribution is GroupCLIP, a novel group-level contrastive loss that bridges the gap between CLIP for paired cross-modal data and SupCon for uni-modal supervised contrastive learning, addressing a fundamental gap in contrastive learning for weakly-paired settings. We integrate GroupCLIP with an on-the-fly backtranslating autoencoder framework to encourage cross-modally entangled representations while maintaining group-level coherence within a shared latent space. Critically, we introduce a comprehensive combinatorial evaluation framework that systematically assesses representation learners across multiple optimal transport aligners, addressing key limitations in existing evaluation strategies. This framework includes novel simulations that systematically vary shared versus modality-specific perturbation effects enabling principled assessment of method robustness. Our combinatorial benchmarking reveals that there is not yet an aligner that uniformly dominates across settings or modality pairs. Across simulations and two real single-cell genetic perturbation datasets, GROOVE performs on par with or outperforms existing approaches for downstream cross-modal matching and imputation tasks. Our ablation studies demonstrate that GroupCLIP is the key component driving performance gains. These results highlight the importance of leveraging group-level constraints for effective multi-modal representation learning in scenarios where only weak pairing is available.

</details>


### [9] [Partition Trees: Conditional Density Estimation over General Outcome Spaces](https://arxiv.org/abs/2602.04042)
*Felipe Angelim,Alessandro Leite*

Main category: cs.LG

TL;DR: 조건부 밀도 추정을 위한 나무 기반 프레임워크인 Partition Trees를 제안하며, 연속 변수와 범주형 변수를 통합하여 지원한다.


<details>
  <summary>Details</summary>
Motivation: 조건부 밀도 추정의 필요성과 기존의 확률적 트리 방법의 제한을 극복하고자 한다.

Method: 조건부 분포를 데이터 적응형 파티션의 구간 상수 밀도로 모델링하고 조건부 음의 로그 가능성을 직접 최소화하여 나무를 학습한다.

Result: CART 스타일의 트리에 비해 향상된 확률적 예측 성능을 보이며, 최신의 확률적 트리 방법 및 랜덤 포레스트와 경쟁하는 또는 더 우수한 성능을 보인다.

Conclusion: 제안된 방법은 과도한 특징과 이분산 노이에 대한 강인성을 가지며, 기존 방법에 비해 확장 가능하고 비모수적 대안이다.

Abstract: We propose Partition Trees, a tree-based framework for conditional density estimation over general outcome spaces, supporting both continuous and categorical variables within a unified formulation. Our approach models conditional distributions as piecewise-constant densities on data adaptive partitions and learns trees by directly minimizing conditional negative log-likelihood. This yields a scalable, nonparametric alternative to existing probabilistic trees that does not make parametric assumptions about the target distribution. We further introduce Partition Forests, an ensemble extension obtained by averaging conditional densities. Empirically, we demonstrate improved probabilistic prediction over CART-style trees and competitive or superior performance compared to state-of-the-art probabilistic tree methods and Random Forests, along with robustness to redundant features and heteroscedastic noise.

</details>


### [10] [Agentic AI-Empowered Dynamic Survey Framework](https://arxiv.org/abs/2602.04071)
*Furkan Mumcu,Lokman Bekit,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.LG

TL;DR: 이 논문은 동적 설문 프레임워크를 제안하여 기존 설문지를 지속적으로 업데이트하는 방법을 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 연구 결과의 급속한 증가로 인해 설문지는 점점 더 outdated되고 있어, 이는 문헌의 중복성과 단편화를 초래합니다.

Method: 설문 작성을 일회성이 아닌 장기적인 유지 관리 문제로 재구성하고, 설문을 발전하는 문서로 간주하여 새로운 연구를 점진적으로 통합하는 동적 설문 프레임워크를 제안했습니다.

Result: 제안된 프레임워크는 기존 설문의 일관성과 구조를 유지하면서 새로운 연구를 효과적으로 식별하고 통합하는 것을 보여주었습니다.

Conclusion: 이 방법은 설문지의 지속적인 유지를 가능하게 하여 연구의 변화를 반영할 수 있습니다.

Abstract: Survey papers play a central role in synthesizing and organizing scientific knowledge, yet they are increasingly strained by the rapid growth of research output. As new work continues to appear after publication, surveys quickly become outdated, contributing to redundancy and fragmentation in the literature. We reframe survey writing as a long-horizon maintenance problem rather than a one-time generation task, treating surveys as living documents that evolve alongside the research they describe. We propose an agentic Dynamic Survey Framework that supports the continuous updating of existing survey papers by incrementally integrating new work while preserving survey structure and minimizing unnecessary disruption. Using a retrospective experimental setup, we demonstrate that the proposed framework effectively identifies and incorporates emerging research while preserving the coherence and structure of existing surveys.

</details>


### [11] [Supervised Learning as Lossy Compression: Characterizing Generalization and Sample Complexity via Finite Blocklength Analysis](https://arxiv.org/abs/2602.04107)
*Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 이 논문은 기계 학습의 일반화에 대한 새로운 정보 이론적 관점을 제시하며, 손실 압축의 맥락에서 학습 문제를 구성하고 유한 블록 길이 분석을 적용합니다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습의 일반화 문제에 대한 새로운 시각을 제공하고 이로 인해 기존 프레임워크와의 차별점을 두기 위해서입니다.

Method: 학습 데이터를 샘플링하는 과정을 인코딩 프로세스로, 모델 생성을 디코딩 프로세스로 간주하는 접근법을 사용합니다. 유한 블록 길이 분석을 활용하여 고정된 랜덤화 학습 알고리즘과 그에 연관된 최적 샘플링 전략에 대한 샘플 복잡성과 일반화 오류에 대한 하한을 도출합니다.

Result: 샘플 복잡성 및 일반화 오류의 하한을 도출하며, 학습 알고리즘의 과적합 정도와 유도 편향, 작업 간의 불일치를 구별하여 명확히 표현했습니다.

Conclusion: 이러한 구분은 기존 프레임워크에 비해 상당한 이점을 제공합니다. 또한 과적합 용어를 분해하여 정보 이론적 경계와 안정성 이론에서 발견되는 기존 지표와의 이론적 연결을 보여 주며, 우리의 제안된 프레임워크 하에 이러한 관점을 통합합니다.

Abstract: This paper presents a novel information-theoretic perspective on generalization in machine learning by framing the learning problem within the context of lossy compression and applying finite blocklength analysis. In our approach, the sampling of training data formally corresponds to an encoding process, and the model construction to a decoding process. By leveraging finite blocklength analysis, we derive lower bounds on sample complexity and generalization error for a fixed randomized learning algorithm and its associated optimal sampling strategy. Our bounds explicitly characterize the degree of overfitting of the learning algorithm and the mismatch between its inductive bias and the task as distinct terms. This separation provides a significant advantage over existing frameworks. Additionally, we decompose the overfitting term to show its theoretical connection to existing metrics found in information-theoretic bounds and stability theory, unifying these perspectives under our proposed framework.

</details>


### [12] [Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach](https://arxiv.org/abs/2602.04116)
*Sicheng Liu,Xunkai Li,Daohan Su,Ru Zhang,Hongchao Qin,Ronghua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 본 논문에서는 그래프 기초 모델(GFMs)의 한계를 극복하고 다중 모드 그래프 기초 모델(MGFMs)을 개발하기 위한 PLANET 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 모드 속성을 지닌 그래프(MAGs)의 활용도를 높이기 위해 MGFMs 개발.

Method: PLANET 프레임워크는 모드 상호작용과 정렬을 분리하여 다중 모드 정보를 적절히 처리한다.

Result: PLANET은 다양한 그래프 중심 및 다중 모드 생성 작업에서 최첨단 성능을 초과하는 성과를 보인다.

Conclusion: PLANET은 MGFMs의 두 가지 주요 한계를 해결하며, 다양한 그래프 및 다중 모드 작업에 효과적으로 적용 가능하다.

Abstract: Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveraging the rich multimodal information in MAGs, and extends applicability to broader types of downstream tasks. While recent MGFMs integrate diverse modality information, our empirical investigation reveals two fundamental limitations of existing MGFMs: (1)they fail to explicitly model modality interaction, essential for capturing intricate cross-modal semantics beyond simple aggregation, and (2)they exhibit sub-optimal modality alignment, which is critical for bridging the significant semantic disparity between distinct modal spaces. To address these challenges, we propose PLANET (graPh topoLogy-aware modAlity iNteraction and alignmEnT), a novel framework employing a Divide-and-Conquer strategy to decouple modality interaction and alignment across distinct granularities. At the embedding granularity, (1)Embedding-wise Domain Gating (EDG) performs local semantic enrichment by adaptively infusing topology-aware cross-modal context, achieving modality interaction. At the node granularity, (2)Node-wise Discretization Retrieval (NDR) ensures global modality alignment by constructing a Discretized Semantic Representation Space (DSRS) to bridge modality gaps. Extensive experiments demonstrate that PLANET significantly outperforms state-of-the-art baselines across diverse graph-centric and multimodal generative tasks.

</details>


### [13] [Decoupling Time and Risk: Risk-Sensitive Reinforcement Learning with General Discounting](https://arxiv.org/abs/2602.04131)
*Mehrdad Moghimi,Anthony Coache,Hyejin Ku*

Main category: cs.LG

TL;DR: 배포 강화 학습에서 할인 요소의 중요성을 다루며, 이를 유연하게 조정할 수 있는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 안전-critical한 영역에서 위험 감수 목적을 최적화할 수 있는 배포 강화 학습의 필요성.

Method: 미래 보상의 유연한 할인과 위험 측정 최적화를 지원하는 새로운 프레임워크를 제안하고, 알고리즘의 최적성을 기술적으로 분석한다.

Result: 다중 기간 확장이 기존 방법론에서 제기된 문제를 해결함을 보여주고, 광범위한 실험을 통해 방법의 강건성을 검증한다.

Conclusion: 결정 문제에서 할인 요소가 시간적 및 위험 선호 프로파일을 보다 잘 캡처하는 데 중요한 요소임을 강조하며, 실제 안전-critical한 응용 프로그램에의 잠재적 영향을 논의한다.

Abstract: Distributional reinforcement learning (RL) is a powerful framework increasingly adopted in safety-critical domains for its ability to optimize risk-sensitive objectives. However, the role of the discount factor is often overlooked, as it is typically treated as a fixed parameter of the Markov decision process or tunable hyperparameter, with little consideration of its effect on the learned policy. In the literature, it is well-known that the discounting function plays a major role in characterizing time preferences of an agent, which an exponential discount factor cannot fully capture. Building on this insight, we propose a novel framework that supports flexible discounting of future rewards and optimization of risk measures in distributional RL. We provide a technical analysis of the optimality of our algorithms, show that our multi-horizon extension fixes issues raised with existing methodologies, and validate the robustness of our methods through extensive experiments. Our results highlight that discounting is a cornerstone in decision-making problems for capturing more expressive temporal and risk preferences profiles, with potential implications for real-world safety-critical applications.

</details>


### [14] [MirrorLA: Reflecting Feature Map for Vision Linear Attention](https://arxiv.org/abs/2602.04346)
*Weikang Meng,Liangyu Huo,Yadan Luo,Yaowei Wang,Yingjian Li,Zheng Zhang*

Main category: cs.LG

TL;DR: MirrorLA는 Transformers의 선형 주의 메커니즘의 성능을 향상시키기 위해 능동적인 재구성을 이용하는 기하학적 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 선형 주의 메커니즘이 Transformer의 계산 복잡성을 줄이기는 하지만 성능이 낮다는 점을 극복하고자 한다.

Method: 흔히 사용되는 ReLU와 같은 표준 프로젝션 대신 능동적 재구성을 통해 정보 보존을 극대화할 수 있는 배울 수 있는 Householder 반사를 이용한다.

Result: MirrorLA는 지역 차별성과 장기 맥락 역학을 최적화하고 최종적으로 글로벌 공분산 혼합을 유도함으로써 성능을 향상시킨다.

Conclusion: MirrorLA는 대표적인 벤치마크에서 최첨단 성능을 달성하고 그대로 선형 효율성을 유지함으로써 표현 충실도를 저하시키지 않고도 가능하다는 것을 보여준다.

Abstract: Linear attention significantly reduces the computational complexity of Transformers from quadratic to linear, yet it consistently lags behind softmax-based attention in performance. We identify the root cause of this degradation as the non-negativity constraint imposed on kernel feature maps: standard projections like ReLU act as "passive truncation" operators, indiscriminately discarding semantic information residing in the negative domain. We propose MirrorLA, a geometric framework that substitutes passive truncation with active reorientation. By leveraging learnable Householder reflections, MirrorLA rotates the feature geometry into the non-negative orthant to maximize information retention. Our approach restores representational density through a cohesive, multi-scale design: it first optimizes local discriminability via block-wise isometries, stabilizes long-context dynamics using variance-aware modulation to diversify activations, and finally, integrates dispersed subspaces via cross-head reflections to induce global covariance mixing. MirrorLA achieves state-of-the-art performance across standard benchmarks, demonstrating that strictly linear efficiency can be achieved without compromising representational fidelity.

</details>


### [15] [Multi-scale hypergraph meets LLMs: Aligning large language models for time series analysis](https://arxiv.org/abs/2602.04369)
*Zongjiang Shang,Dongliang Cui,Binqing Wu,Ling Chen*

Main category: cs.LG

TL;DR: 본 논문에서는 시계열 분석을 위한 LLM의 활용을 최적화하기 위해 MSH-LLM이라는 다중 스케일 하이퍼그래프 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 사전 훈련된 대형 언어 모델(LLM)을 시계열 분석에 효과적으로 활용하기 위해 자연어와 시계열 간의 모달리티를 정렬하는 것이 중요하다.

Method: 다중 스케일 시맨틱 정보를 강화하기 위해 하이퍼엣징 메커니즘과 다양한 스케일에서 자연어와 시계열 간의 모달리티를 정렬하기 위한 CMA 모듈 및 맥락 정보를 제공하는 MoP 메커니즘을 도입하였다.

Result: 5개의 서로 다른 응용 프로그램에 걸친 27개의 실제 데이터셋에서 실험 결과, MSH-LLM이 최첨단 결과를 달성하였다.

Conclusion: MSH-LLM은 다중 스케일 처리 능력을 향상시키고 LLM의 시계열 이해 능력을 더욱 강화하는 것으로 나타났다.

Abstract: Recently, there has been great success in leveraging pre-trained large language models (LLMs) for time series analysis. The core idea lies in effectively aligning the modality between natural language and time series. However, the multi-scale structures of natural language and time series have not been fully considered, resulting in insufficient utilization of LLMs capabilities. To this end, we propose MSH-LLM, a Multi-Scale Hypergraph method that aligns Large Language Models for time series analysis. Specifically, a hyperedging mechanism is designed to enhance the multi-scale semantic information of time series semantic space. Then, a cross-modality alignment (CMA) module is introduced to align the modality between natural language and time series at different scales. In addition, a mixture of prompts (MoP) mechanism is introduced to provide contextual information and enhance the ability of LLMs to understand the multi-scale temporal patterns of time series. Experimental results on 27 real-world datasets across 5 different applications demonstrate that MSH-LLM achieves the state-of-the-art results.

</details>


### [16] [Reducing the labeling burden in time-series mapping using Common Ground: a semi-automated approach to tracking changes in land cover and species over time](https://arxiv.org/abs/2602.04373)
*Geethen Singh,Jasper A Slingsby,Tamara B Robinson,Glenn Moncrieff*

Main category: cs.LG

TL;DR: 이 논문은 동적인 생태계 시스템에서 기존 레이블 데이터를 이용하여 시간에 따라 변하는 분류 정확도를 유지할 수 있는 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: Earth Observation 데이터의 신뢰할 수 있는 분류는 일관되고 최신의 참조 레이블에 의존합니다.

Method: 'Common Ground'라는 방법론을 사용하여 반지도 학습 프레임워크를 구성하고, 시간적으로 안정적인 지역을 동적 지역의 암묵적인 감독 원천으로 활용합니다.

Result: 'Common Ground'를 사용했을 때 침입 나무 종 지도화에서 21-40%의 분류 정확도를 높였습니다.

Conclusion: 안정적인 참조 선별과 반지도 학습의 조합이 확장 가능하고 레이블 효율적인 다시기 원격 감지 분류에 효과적임을 강조합니다.

Abstract: Reliable classification of Earth Observation data depends on consistent, up-to-date reference labels. However, collecting new labelled data at each time step remains expensive and logistically difficult, especially in dynamic or remote ecological systems. As a response to this challenge, we demonstrate that a model with access to reference data solely from time step t0 can perform competitively on both t0 and a future time step t1, outperforming models trained separately on time-specific reference data (the gold standard). This finding suggests that effective temporal generalization can be achieved without requiring manual updates to reference labels beyond the initial time step t0. Drawing on concepts from change detection and semi-supervised learning (SSL), the most performant approach, "Common Ground", uses a semi-supervised framework that leverages temporally stable regions-areas with little to no change in spectral or semantic characteristics between time steps-as a source of implicit supervision for dynamic regions. We evaluate this strategy across multiple classifiers, sensors (Landsat-8, Sentinel-2 satellite multispectral and airborne imaging spectroscopy), and ecological use cases. For invasive tree species mapping, we observed a 21-40% improvement in classification accuracy using Common Ground compared to naive temporal transfer, where models trained at a single time step are directly applied to a future time step. We also observe a 10 -16% higher accuracy for the introduced approach compared to a gold-standard approach. In contrast, when broad land cover categories were mapped across Europe, we observed a more modest 2% increase in accuracy compared to both the naive and gold-standard approaches. These results underscore the effectiveness of combining stable reference screening with SSL for scalable and label-efficient multi-temporal remote sensing classification.

</details>


### [17] [EMA Policy Gradient: Taming Reinforcement Learning for LLMs with EMA Anchor and Top-k KL](https://arxiv.org/abs/2602.04417)
*Lunjun Zhang,Jimmy Ba*

Main category: cs.LG

TL;DR: 이 논문에서는 강화 학습(RL) 알고리즘에서 LLM을 개선하기 위한 두 가지 간단한 기법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 점점 더 복잡한 추론 및 에이전트 행동을 습득할 수 있도록 하기 위해 RL의 성능을 향상시키고자 합니다.

Method: 고정된 앵커 정책을 EMA로 대체하고, Top-k KL 추정기를 도입하여 KL 값과 샘플링된 KL 사이의 유연한 보간을 가능하게 합니다.

Result: 이 두 가지 기법(EMA-PG)은 수학적 추론에서 R1-distilled Qwen-1.5B의 성능을 50.8%에서 53.9%로 향상시켰고, 7개의 Q&A 데이터셋에서 평균 33.3% 성능 향상을 보여줍니다.

Conclusion: EMA-PG는 LLM을 위한 RL을 확장하기 위한 간단하고 원칙적인 방법임을 증명합니다.

Abstract: Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to acquire increasingly complex reasoning and agentic behaviors. In this work, we propose two simple techniques to improve policy gradient algorithms for LLMs. First, we replace the fixed anchor policy during RL with an Exponential Moving Average (EMA), similar to a target network in deep Q-learning. Second, we introduce Top-k KL estimator, which allows for flexible interpolation between exact KL and sampled KL. We derive the stability conditions for using EMA anchor; moreover, we show that our Top-k KL estimator yields both unbiased KL values and unbiased gradients at any k, while bringing the benefits of exact KL. When combined with GRPO, the two techniques (EMA-PG) lead to a significant performance boost. On math reasoning, it allows R1-distilled Qwen-1.5B to reach 53.9% on OlympiadBench compared to 50.8% by GRPO. On agentic RL domains, with Qwen-3B base, EMA-PG improves GRPO by an average of 33.3% across 7 datasets of Q&A with search engines, including 29.7% $\rightarrow$ 44.1% on HotpotQA, 27.4% $\rightarrow$ 40.1% on 2WikiMultiHopQA. Overall, we show that EMA-PG is a simple, principled, and powerful approach to scaling RL for LLMs. Code: https://github.com/LunjunZhang/ema-pg

</details>


### [18] [MaMa: A Game-Theoretic Approach for Designing Safe Agentic Systems](https://arxiv.org/abs/2602.04431)
*Jonathan Nöther,Adish Singla,Goran Radanovic*

Main category: cs.LG

TL;DR: 이 논문에서는 개별 에이전트의 실패나 적대적인 행동에도 불구하고 안전성을 유지할 수 있는 에이전트 시스템의 자동 설계를 연구합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 다중 에이전트 시스템은 인상적인 능력을 보여주지만, 개별 에이전트의 실패나 적대적 행동으로 인해 상당한 안전 위험을 초래합니다.

Method: Meta-Adversary-Meta-Agent (MaMa)라는 새로운 알고리즘을 제안하여 Stackelberg 보안 게임을 근사적으로 해결하고 안전한 에이전트 시스템을 자동으로 설계합니다.

Result: MaMa로 설계된 시스템은 최악의 공격에 일관되게 방어하면서도 작업 성공을 위해 최적화된 시스템과 유사한 성능을 유지합니다.

Conclusion: 결과적으로 시스템은 더 강력한 적과 함께 다양한 공격 목표나 기본 LLM이 있는 적에게도 일반화되어 훈련 환경을 넘어선 견고한 안전성을 보여줍니다.

Abstract: LLM-based multi-agent systems have demonstrated impressive capabilities, but they also introduce significant safety risks when individual agents fail or behave adversarially. In this work, we study the automated design of agentic systems that remain safe even when a subset of agents is compromised. We formalize this challenge as a Stackelberg security game between a system designer (the Meta-Agent) and a best-responding Meta-Adversary that selects and compromises a subset of agents to minimize safety. We propose Meta-Adversary-Meta-Agent (MaMa), a novel algorithm for approximately solving this game and automatically designing safe agentic systems. Our approach uses LLM-based adversarial search, where the Meta-Agent iteratively proposes system designs and receives feedback based on the strongest attacks discovered by the Meta-Adversary. Empirical evaluations across diverse environments show that systems designed with MaMa consistently defend against worst-case attacks while maintaining performance comparable to systems optimized solely for task success. Moreover, the resulting systems generalize to stronger adversaries, as well as ones with different attack objectives or underlying LLMs, demonstrating robust safety beyond the training setting.

</details>


### [19] [Rationality Measurement and Theory for Reinforcement Learning Agents](https://arxiv.org/abs/2602.04737)
*Kejiang Qian,Amos Storkey,Fengxiang He*

Main category: cs.LG

TL;DR: 이 논문은 강화 학습 에이전트를 위한 합리성 측정 및 관련 이론을 제안하며, 이 특성은 점점 더 중요해지고 있지만 거의 탐구되지 않았다. 여기서는 배포에서의 행동을 숨겨진 진정 가치 함수를 가장 급격한 방향으로 극대화하는 완전한 합리성으로 정의한다. 정책의 행동과 그 합리적 대응 간의 기대 값 차이를 기대 합리적 위험으로 정의하고, 이는 또한 훈련에서의 경험적 평균 버전으로 정의된다. 이 두 간극(합리적 위험 차이)은 (1) 훈련과 배포 간의 환경 변화로 인한 외적 요소와 (2) 동적 환경에서 알고리즘의 일반화 능력으로 인한 내적 요소로 분해된다. 이들은 각각 (1) 훈련과 배포에서의 전이 커널 및 초기 상태 분포 간의 $1$-Wasserstein 거리와 (2) 가치 함수 클래스의 경험적 Rademacher 복잡성으로 상한이 설정된다. 이론은 레귤레이터(레이어 정규화, $	ext{ℓ}_2$ 정규화 및 가중치 정규화 포함) 및 도메인 무작위화의 이점과 환경 변화의 해로움에 대한 가설을 제안한다. 실험 결과는 이러한 가설과 완벽하게 일치한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 에이전트의 합리성을 평가하고 이해하는 것이 중요하지만, 이 분야는 아직 충분히 탐구되지 않았다.

Method: 행동의 기대 합리적 위험을 정의하고, 이를 외적 및 내적 요소로 분해하여 이론적 바운드를 설정한다.

Result: 실험은 제안된 이론과 일치하여 합리성 측정의 유용성을 입증하였다.

Conclusion: 제안된 이론과 관련된 다양한 기법들이 강화 학습의 효율성과 성능을 향상시킬 수 있음을 보여주었다.

Abstract: This paper proposes a suite of rationality measures and associated theory for reinforcement learning agents, a property increasingly critical yet rarely explored. We define an action in deployment to be perfectly rational if it maximises the hidden true value function in the steepest direction. The expected value discrepancy of a policy's actions against their rational counterparts, culminating over the trajectory in deployment, is defined to be expected rational risk; an empirical average version in training is also defined. Their difference, termed as rational risk gap, is decomposed into (1) an extrinsic component caused by environment shifts between training and deployment, and (2) an intrinsic one due to the algorithm's generalisability in a dynamic environment. They are upper bounded by, respectively, (1) the $1$-Wasserstein distance between transition kernels and initial state distributions in training and deployment, and (2) the empirical Rademacher complexity of the value function class. Our theory suggests hypotheses on the benefits from regularisers (including layer normalisation, $\ell_2$ regularisation, and weight normalisation) and domain randomisation, as well as the harm from environment shifts. Experiments are in full agreement with these hypotheses. The code is available at https://github.com/EVIEHub/Rationality.

</details>


### [20] [Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty](https://arxiv.org/abs/2602.04763)
*Rui Liu,Pratap Tokekar,Ming Lin*

Main category: cs.LG

TL;DR: A2MAML은 불확실성을 인식하고 모달리티 수준에서의 협력을 위한 방법론으로, 다양한 센서를 활용하여 협업 사고 감지에서 18.7% 높은 사고 탐지율을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 센서를 갖춘 다중 에이전트 시스템이 증가하고 있으나, 모달리티 특정 및 에이전트 의존적 불확실성이 존재한다.

Method: A2MAML은 각 모달리티 특성을 불확실성 예측과 함께 확률적 추정으로 모델링하고, 신뢰할 수 있는 에이전트-모달리티 쌍을 적극적으로 선택하며, 베이esian 역분산 가중치를 통해 정보를 집계한다.

Result: A2MAML은 협업 사고 탐지 실험에서 단일 에이전트 및 협력적 기준선보다 항상 더 나은 성능을 보이며 최대 18.7% 높은 사고 탐지율을 기록했다.

Conclusion: A2MAML은 불확실성을 인식하는 협력적 접근 방식으로, 손상되거나 잡음이 있는 모달리티를 억제할 수 있는 원칙적인 메커니즘을 제공한다.

Abstract: Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty (A2MAML), a principled approach for uncertainty-aware, modality-level collaboration. A2MAML models each modality-specific feature as a stochastic estimate with uncertainty prediction, actively selects reliable agent-modality pairs, and aggregates information via Bayesian inverse-variance weighting. This formulation enables fine-grained, modality-level fusion, supports asymmetric modality availability, and provides a principled mechanism to suppress corrupted or noisy modalities. Extensive experiments on connected autonomous driving scenarios for collaborative accident detection demonstrate that A2MAML consistently outperforms both single-agent and collaborative baselines, achieving up to 18.7% higher accident detection rate.

</details>


### [21] [Beyond Rewards in Reinforcement Learning for Cyber Defence](https://arxiv.org/abs/2602.04809)
*Elizabeth Bates,Chris Hicks,Vasilios Mavroudis*

Main category: cs.LG

TL;DR: 자율 사이버 방어 에이전트의 훈련에 관한 연구로, 보상 함수 구조가 학습 및 정책 행동 특성에 미치는 영향을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 최근 자율 사이버 방어 에이전트에 대한 관심이 폭발적으로 증가하고 있으며, 이들은 심층 강화 학습을 사용하여 컴퓨터 네트워크를 방어하도록 훈련된다.

Method: 희소 및 밀집 보상 함수, 두 개의 잘 확립된 사이버 체육관, 다양한 네트워크 크기, 정책 경량기 및 가치 기반 RL 알고리즘을 사용하여 보상 함수 구조의 영향을 평가했다.

Result: 희소 보상이 목표에 정렬되고 자주 마주칠 수 있는 경우, 훈련 신뢰성이 향상되고 더 낮은 위험 정책을 가진 사이버 방어 에이전트를 제공할 수 있다는 결과를 도출했다.

Conclusion: 희소 보상은 사이버 방어 목표에 더 잘 정렬된 정책을 유도하고, 명시적인 보상 기반 수치적 페널티 없이도 비용이 많이 드는 방어 조치를 아끼며 활용될 수 있다.

Abstract: Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the challenge of exploring complex environments but risk biasing agents towards suboptimal and potentially riskier solutions, a critical issue in complex cyber environments. We thoroughly evaluate the impact of reward function structure on learning and policy behavioural characteristics using a variety of sparse and dense reward functions, two well-established cyber gyms, a range of network sizes, and both policy gradient and value-based RL algorithms. Our evaluation is enabled by a novel ground truth evaluation approach which allows directly comparing between different reward functions, illuminating the nuanced inter-relationships between rewards, action space and the risks of suboptimal policies in cyber environments. Our results show that sparse rewards, provided they are goal aligned and can be encountered frequently, uniquely offer both enhanced training reliability and more effective cyber defence agents with lower-risk policies. Surprisingly, sparse rewards can also yield policies that are better aligned with cyber defender goals and make sparing use of costly defensive actions without explicit reward-based numerical penalties.

</details>


### [22] [Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning](https://arxiv.org/abs/2602.04821)
*Joydeep Chandra,Satyam Kumar Navneet,Aleksandr Algazinov,Yong Zhang*

Main category: cs.LG

TL;DR: STREAM-RL은 도시 교통 관리를 위한 통합 프레임워크로, 예측, 이상 탐지, 안전한 수정 조치를 동시에 수행하며 신뢰성 보장을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 도시 교통 관리는 미래 조건을 예측하고, 이상 현상을 탐지하며, 안전한 수정 조치를 취할 수 있는 시스템을 요구합니다.

Method: STREAM-RL은 PU-GAT+, CRFN-BY, LyCon-WRL+라는 세 가지 혁신적인 알고리즘 기여를 포함하는 통합 프레임워크입니다.

Result: STREAM-RL은 91.4%의 범위 효율성을 달성하고, 검증된 의존성 하에서 4.1%의 FDR을 제어하며, 표준 PPO보다 안전성 비율을 69%에서 95.2%로 개선하며 더 높은 보상을 달성합니다.

Conclusion: 이 프레임워크는 예측에서 이상 탐지, 안전한 정책 학습까지 보정된 불확실성을 전파하는 최초의 방법입니다.

Abstract: Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically reweight graph attention via confidence-monotonic attention, achieving distribution-free coverage guarantees; (2) CRFN-BY, a Conformal Residual Flow Network that models uncertainty-normalized residuals via normalizing flows with Benjamini-Yekutieli FDR control under arbitrary dependence; and (3) LyCon-WRL+, an Uncertainty-Guided Safe World-Model RL agent with Lyapunov stability certificates, certified Lipschitz bounds, and uncertainty-propagated imagination rollouts. To our knowledge, this is the first framework to propagate calibrated uncertainty from forecasting through anomaly detection to safe policy learning with end-to-end theoretical guarantees. Experiments on multiple real-world traffic trajectory data demonstrate that STREAM-RL achieves 91.4\% coverage efficiency, controls FDR at 4.1\% under verified dependence, and improves safety rate to 95.2\% compared to 69\% for standard PPO while achieving higher reward, with 23ms end-to-end inference latency.

</details>


### [23] [CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation](https://arxiv.org/abs/2602.04868)
*Yannick Denker,Alexander Gepperth*

Main category: cs.LG

TL;DR: 이 논문은 지속적인 강화 학습을 위한 새로운 벤치마크인 Continual Robotic Simulation Suite (CRoSS)를 소개합니다. CRoSS는 두 가지 로봇 플랫폼을 기반으로 하며, 실제 시뮬레이션된 로봇에서 다양한 작업을 수행하도록 설계되었습니다.


<details>
  <summary>Details</summary>
Motivation: 지속적인 강화 학습(CRL)은 에이전트가 이전에 습득한 정책을 잊지 않고 일련의 작업에서 학습해야 합니다.

Method: CRoSS는 라이다, 카메라, 범퍼 센서를 갖춘 2륜 구동 로봇 및 7개의 관절을 가진 로봇 팔 등 두 가지 로봇 플랫폼에 의존하는 벤치마크를 제공합니다.

Result: CRoSS는 고유한 작업을 생성하는 고급 카르테시안 핸드 포지션 제어와 관절 각도에 기초한 저수준 제어를 포함한 두 가지 목표 도달 시나리오에 사용됩니다.

Conclusion: CRoSS는 높은 물리적 현실감을 갖춘 로봇 환경에서 지속적인 강화 학습의 연구를 용이하게 하도록 설계되었으며, 표준 RL 알고리즘 성능을 보고합니다.

Abstract: Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [24] [On the Uncertainty of Large Language Model-Based Multi-Agent Systems](https://arxiv.org/abs/2602.04234)
*Yuxuan Zhao,Sijia Chen,Ningxin Su*

Main category: cs.MA

TL;DR: 이 논문에서는 멀티 에이전트 시스템(MAS)의 효과를 불확실성 측면에서 재조명하고, 특정 과제에서 MAS와 단일 에이전트의 성능을 비교하여 엔트로피 전이에 대한 분석을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: MAS가 공공적으로 사용 가능한 대형 언어 모델(LLMs)을 활용하여 복잡한 과제를 해결하는데 중요한 패러다임이라는 점에서, MAS의 성공 또는 실패를 뒷받침하는 메커니즘이 탐구되지 않았습니다.

Method: 문제 해결 과정에서 다양한 토폴로지와 여섯 가지 기준 작업을 통해 엔트로피 전이를 조사하며, 에이전트 간 및 내부 역학을 고려합니다.

Result: 단일 에이전트가 약 43.3%의 경우에서 MAS보다 더 좋은 성능을 나타내며, 불확실성 역학은 상호작용 첫 번째 라운드에서 주로 결정된다는 발견을 합니다.

Conclusion: 우리는 MAS의 pass@k 결과에서 솔루션을 선택하는 Entropy Judger라는 간단하지만 효과적인 알고리즘을 소개하며, 모든 MAS 구성과 작업에서 일관된 정확도 개선을 이끌어냅니다.

Abstract: Multi-agent systems (MAS) have emerged as a prominent paradigm for leveraging large language models (LLMs) to tackle complex tasks. However, the mechanisms governing the effectiveness of MAS built upon publicly available LLMs, specifically the underlying rationales for their success or failure, remain largely unexplored. In this paper, we revisit MAS through the perspective of uncertainty, considering both intra- and inter-agent dynamics by investigating entropy transitions during problem-solving across various topologies and six benchmark tasks. By analyzing 245 features spanning token-, trajectory-, and round-level entropy, we counterintuitively find that a single agent outperforms MAS in approximately 43.3% of cases, and that uncertainty dynamics are largely determined during the first round of interaction. Furthermore, we provide three key observations: 1) Certainty Preference: reducing uncertainty at any stage for any agent is critical for guaranteeing correct solutions; 2) Base Uncertainty: base models with lower entropy during problem-solving directly benefit MAS performance; and 3) Task Awareness: entropy dynamics of MAS play varying roles across different tasks. Building on these insights, we introduce a simple yet effective algorithm, the Entropy Judger, to select solutions from MAS's pass@k results, leading to consistent accuracy improvements across all MAS configurations and tasks. Our source code is available at https://github.com/AgenticFinLab/multiagent-entropy.

</details>


### [25] [SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing](https://arxiv.org/abs/2602.04418)
*Arnab Mallick,Indraveni Chebolu,Harmesh Rana*

Main category: cs.MA

TL;DR: SPEAR는 스마트 계약 감사용 다중 에이전트 협동 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 스마트 계약 감사의 효율성을 높이기 위해 다중 에이전트 시스템(MAS) 패턴을 적용한 보안 분석 워크플로우를 필요로 한다.

Method: SPEAR는 계획 에이전트, 실행 에이전트, 수리 에이전트의 세 가지 전문 에이전트가 협력하여 감사 임무를 수행하도록 모델링한다.

Result: 실증 연구 결과, 다중 에이전트 설계는 중앙 집중형 및 파이프라인 기반 대안과 비교하여 조정, 복구 행동 및 자원 사용 측면에서 우수한 성과를 보였다.

Conclusion: SPEAR는 스마트 계약 감사의 효율성을 크게 향상시킬 수 있는 잠재력을 가진 프레임워크임을 보여준다.

Abstract: We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Planning Agent prioritizes contracts using risk-aware heuristics, an Execution Agent allocates tasks via the Contract Net protocol, and a Repair Agent autonomously recovers from brittle generated artifacts using a programmatic-first repair policy. Agents maintain local beliefs updated through AGM-compliant revision, coordinate via negotiation and auction protocols, and revise plans as new information becomes available. An empirical study compares the multi-agent design with centralized and pipeline-based alternatives under controlled failure scenarios, focusing on coordination, recovery behavior, and resource use.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation](https://arxiv.org/abs/2602.03950)
*Aditya Basarkar,Benyamin Tabarsi,Tiffany Barnes,Dongkuan,Xu*

Main category: cs.AI

TL;DR: 이 논문은 인공지능의 수학적 문제 해결 능력을 향상시키기 위한 Iteratively Improved Program Construction (IIPC) 방법을 소개하고, 이 방법이 기존의 접근법에 비해 우수한 성능을 보여준다는 내용을 담고 있다.


<details>
  <summary>Details</summary>
Motivation: 인공지능의 사고 능력을 평가하고 교육, 과학, 공학 등의 분야에서 신뢰할 수 있는 상징적 추론이 필수적인 응용 프로그램으로서 수학적 문제 해결이 중요한 기준이 된다.

Method: Iteratively Improved Program Construction (IIPC)라는 방법론을 도입하여 프로그램적 추론 사슬을 반복적으로 개선하고 실행 피드백을 기존 LLM의 체인-오브-생각 능력과 결합한다.

Result: IIPC는 여러 기본 LLM의 대부분의 추론 벤치마크에서 경쟁하는 접근법을 초월하는 성능을 보인다.

Conclusion: 모든 코드와 구현물은 오픈 소스로 제공된다.

Abstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents either operate in rigid sequential pipelines that cannot correct earlier steps or rely on heuristic self-evaluation that can fail to identify and fix errors. In addition, programmatic context can distract language models and degrade accuracy. To address these gaps, we introduce Iteratively Improved Program Construction (IIPC), a reasoning method that iteratively refines programmatic reasoning chains and combines execution feedback with the native Chain-of-thought abilities of the base LLM to maintain high-level contextual focus. IIPC surpasses competing approaches in the majority of reasoning benchmarks on multiple base LLMs. All code and implementations are released as open source.

</details>


### [27] [AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent](https://arxiv.org/abs/2602.03955)
*Yinyi Luo,Yiqiao Jin,Weichen Yu,Mengqi Zhang,Srijan Kumar,Xiaoxiao Li,Weijie Xu,Xin Chen,Jindong Wang*

Main category: cs.AI

TL;DR: AgentArk는 단일 모델의 가중치에 다중 에이전트 동역학을 증류하여 효율적인 멀티-에이전트 시스템 인텔리전스를 구현하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: LLM 멀티-에이전트 시스템의 뛰어난 추론 성능은 반복적인 토론을 통해 가능하지만, 높은 계산 비용과 오류 전파로 인해 실제 배치가 제한적이다.

Method: 다양한 모델, 작업, 스케일 및 시나리오에 걸쳐 세 가지 계층적 증류 전략을 조사한다: 추론 강화 미세 조정, 경로 기반 증강, 프로세스 인식 증류.

Result: 증류된 모델은 하나의 에이전트의 효율성을 유지하면서 여러 에이전트의 강력한 추론 및 자가 수정 성능을 보인다.

Conclusion: 이 연구는 효율적이고 견고한 다중 에이전트 개발에 대한 미래 연구에 기여할 수 있을 것으로 희망한다.

Abstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning; trajectory-based augmentation; and process-aware distillation. By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.

</details>


### [28] [From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents](https://arxiv.org/abs/2602.04326)
*SeungWon Seo,SooBin Lim,SeongRae Noh,Haneul Kim,HyeongYeop Kang*

Main category: cs.AI

TL;DR: PCE라는 Planner-Composer-Evaluator 프레임워크를 통해 LLM의 가정들을 구조화된 결정 트리로 변환하여, 에이전트 간의 빈번한 통신 없이도 효율적인 계획을 수행할 수 있는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 환경에서 불확실성을 효과적으로 관리하는 방법을 개선하기 위해, 효율적이고 신뢰할 수 있는 계획 수립이 필요하다.

Method: PCE 프레임워크는 LLM의 추론 과정에서 나타나는 단편적인 가정을 구조화된 결정 트리로 변환하여, 각 경로를 시나리오 가능성, 목표 지향 이득, 실행 비용으로 점수화한다.

Result: PCE는 두 개의 어려운 다중 에이전트 벤치마크에서 통신 중심의 기준선을 능가하는 성공률과 작업 효율성을 기록하면서도 비슷한 토큰 사용량을 보여준다.

Conclusion: PCE는 LLM의 가정을 신뢰할 수 있는 불확실성 인식 계획 전략으로 변환하는 원칙적인 경로를 제시한다.

Abstract: Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablation results indicate that the performance gains obtained by scaling model capacity or reasoning depth persist even when PCE is applied, while PCE consistently raises the baseline across both capacity and reasoning-depth scales, confirming that structured uncertainty handling complements both forms of scaling. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.

</details>


### [29] [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634)
*Zelai Xu,Zhexuan Xu,Ruize Zhang,Chunyang Zhu,Shi Yu,Weilin Liu,Quanlu Zhang,Wenbo Ding,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: 이 논문에서는 넓이 확장에 대한 접근 방식을 탐구하고, WideSeek-R1이라는 다중 에이전트 시스템을 통해 정보를 효과적으로 탐색하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM의 발전이 깊이 확장에 초점을 맞추고 있지만, 과제가 확장됨에 따라 개인의 능력이 아닌 조직의 역량이 핵심 병목점이 됨에 따라 폭 확장이라는 차원을 탐구하고자 함.

Method: WideSeek-R1은 다중 에이전트 강화 학습(MARL)을 통해 훈련된 주 에이전트 - 하위 에이전트 프레임워크로, 확장 가능한 조정 및 병렬 실행을 시너지 효과를 내도록 설계됨.

Result: WideSeek-R1-4B는 WideSearch 벤치마크에서 40.0%의 항목 F1 점수를 달성하여, 단일 에이전트인 DeepSeek-R1-671B의 성능과 유사함을 보임.

Conclusion: WideSeek-R1-4B는 병렬 하위 에이전트의 수가 증가함에 따라 일관된 성능 향상을 보여줌으로써 폭 확장의 효과를 강조함.

Abstract: Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.

</details>


### [30] [Active Epistemic Control for Query-Efficient Verified Planning](https://arxiv.org/abs/2602.03974)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 이 논문에서는 부분 관측 하의 인터랙티브 환경에서의 계획 수립 문제를 다루고, 비용 효과적으로 예측한 정보를 활용하는 'Active Epistemic Control (AEC)'를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 부분 관측 환경에서의 계획은 의사결정 시 필수적인 전제조건이 불확실할 때 도전적이며, 상호작용을 통해 정보를 확보하기는 비용이 많이 든다.

Method: AEC는 모델 기반 신념 관리와 범주적 실행 가능성 검사를 통합한 계획 레이어이다.

Result: 실험 결과 AEC는 ALFWorld와 ScienceWorld에서 강력한 LLM-agent 기반선보다 적은 재계획 라운드로 경쟁력 있는 성공을 거두었다.

Conclusion: AEC는 정보의 불확실성이 높거나 예측이 모호할 때 환경에 질의하여 해결되지 않은 술어를 구체화하거나 자신감이 충분할 때 가설을 필터링하는 시뮬레이션을 통해 효율성을 향상시킨다.

Abstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer that integrates model-based belief management with categorical feasibility checks. AEC maintains a strict separation between a \emph{grounded fact store} used for commitment and a \emph{belief store} used only for pruning candidate plans. At each step, it either queries the environment to ground an unresolved predicate when uncertainty is high or predictions are ambiguous, or simulates the predicate to filter hypotheses when confidence is sufficient. Final commitment is gated by grounded precondition coverage and an SQ-BCP pullback-style compatibility check, so simulated beliefs affect efficiency but cannot directly certify feasibility. Experiments on ALFWorld and ScienceWorld show that AEC achieves competitive success with fewer replanning rounds than strong LLM-agent baselines.

</details>


### [31] [Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL](https://arxiv.org/abs/2602.04089)
*Xiaofeng Lin,Sirou Zhu,Yilei Chen,Mingyu Chen,Hejian Sang,Ioannis Paschalidis,Zhipeng Wang,Aldo Pacchiano,Xuezhou Zhang*

Main category: cs.AI

TL;DR: 이 논문에서는 LLM이 온라인 의사결정 작업에서 상호작용을 통해 학습할 수 있는 ORBIT라는 메타 강화 학습 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 실제 의사결정 작업은 본질적으로 온라인이며, 정보 수집과 활용 사이의 균형을 맞추어야 한다는 필요성.

Method: ORBIT라는 메타 강화 학습 프레임워크를 도입하여, LLM이 상호작용을 통해 학습할 수 있도록 훈련한다.

Result: Qwen3-14B 모델이 이전에 본 적이 없는 환경에서 온라인 학습 성능이 크게 개선되었다.

Conclusion: 이 연구는 LLM이 온라인 설정에서 효과적으로 학습할 수 있는 방법을 제시하며, 추가적인 모델 크기 확장에서도 성능 향상을 보였다.

Abstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables adaptation without weight updates, existing LLMs often struggle to reliably leverage in-context interaction experience in such settings. In this work, we show that this limitation can be addressed through training. We introduce ORBIT, a multi-task, multi-episode meta-reinforcement learning framework that trains LLMs to learn from interaction in context. After meta-training, a relatively small open-source model (Qwen3-14B) demonstrates substantially improved in-context online learning on entirely unseen environments, matching the performance of GPT-5.2 and outperforming standard RL fine-tuning by a large margin. Scaling experiments further reveal consistent gains with model size, suggesting significant headroom for learn-at-inference-time decision-making agents. Code reproducing the results in the paper can be found at https://github.com/XiaofengLin7/ORBIT.

</details>


### [32] [OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows](https://arxiv.org/abs/2602.04144)
*Ruiting Dai,Zheyu Wang,Haoyu Yang,Yihan Liu,Chengzhi Wang,Zekun Zhang,Zishan Huang,Jiaman Cen,Lisi Mo*

Main category: cs.AI

TL;DR: 데이터 불완전성이 멀티모달 시스템의 신뢰성을 저해한다. 기존의 복원 방법들은 다양한 한계에 직면하고 있으며, 본 논문에서는 OMG-Agent라는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 시스템의 신뢰성을 저해하는 데이터 불완전성 문제를 해결하기 위해.

Method: OMG-Agent는 세 가지 단계로 작업을 명확하게 분리하는 동적 거칠게-미세하게 진행하는 에이전트 워크플로우를 채택한다.

Result: OMG-Agent는 여러 벤치마크에서 기존 방법들을 일관성 있게 초월하며 극단적 결측치 하에서도 강건함을 유지한다.

Conclusion: OMG-Agent는 복잡한 작업을 효율적으로 처리하여 기존 최첨단 방법들을 능가하는 성능을 보여준다.

Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retrieval rigidity. Critically, these end-to-end architectures are fundamentally constrained by Semantic-Detail Entanglement -- a structural conflict between logical reasoning and signal synthesis that compromises fidelity. In this paper, we present \textbf{\underline{O}}mni-\textbf{\underline{M}}odality \textbf{\underline{G}}eneration Agent (\textbf{OMG-Agent}), a novel framework that shifts the paradigm from static mapping to a dynamic coarse-to-fine Agentic Workflow. By mimicking a \textit{deliberate-then-act} cognitive process, OMG-Agent explicitly decouples the task into three synergistic stages: (1) an MLLM-driven Semantic Planner that resolves input ambiguity via Progressive Contextual Reasoning, creating a deterministic structured semantic plan; (2) a non-parametric Evidence Retriever that grounds abstract semantics in external knowledge; and (3) a Retrieval-Injected Executor that utilizes retrieved evidence as flexible feature prompts to overcome rigidity and synthesize high-fidelity details. Extensive experiments on multiple benchmarks demonstrate that OMG-Agent consistently surpasses state-of-the-art methods, maintaining robustness under extreme missingness, e.g., a $2.6$-point gain on CMU-MOSI at $70$\% missing rates.

</details>


### [33] [InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons](https://arxiv.org/abs/2602.04213)
*Feiyu Gavin Zhu,Jean Oh,Reid Simmons*

Main category: cs.AI

TL;DR: 사용자 지침을 기반으로 정책 구조를 지속적으로 업데이트하고 최적화하는 InterPReT 방법을 제안하여 비전문가가 AI 에이전트를 쉽게 가르칠 수 있게 한다.


<details>
  <summary>Details</summary>
Motivation: 비전문가가 AI 에이전트에게 새로운 기술을 가르치는 것이 어렵기 때문에, 이를 완화하기 위한 방법이 필요하다.

Method: 사용자가 지침을 제공하고 시연을 할 수 있도록 하여 정책 구조를 지속적으로 업데이트하고 최적화하는 상호작용적 정책 재구성 및 훈련 방법인 InterPReT를 제안한다.

Result: 사용자 연구(N=34)를 통해 일반적인 모방 학습 기준선에 비해 비전문가가 시연 제공 및 중지 결정을 할 때보다 더 강력한 정책을 생성하는 것을 확인하였다.

Conclusion: 이 방법은 머신러닝에 대한 기술적 배경이 적은 최종 사용자에게 신뢰할 수 있는 정책을 훈련하는 데 더 적합함을 보여준다.

Abstract: Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challenging for a layperson when they want to teach the agent new skills. To lower the barrier of teaching AI agents, we propose Interactive Policy Restructuring and Training (InterPReT), which takes user instructions to continually update the policy structure and optimize its parameters to fit user demonstrations. This enables end-users to interactively give instructions and demonstrations, monitor the agent's performance, and review the agent's decision-making strategies. A user study (N=34) on teaching an AI agent to drive in a racing game confirms that our approach yields more robust policies without impairing system usability, compared to a generic imitation learning baseline, when a layperson is responsible for both giving demonstrations and determining when to stop. This shows that our method is more suitable for end-users without much technical background in machine learning to train a dependable policy

</details>


### [34] [Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search](https://arxiv.org/abs/2602.04248)
*Hao Lu,Haoyuan Huang,Yulin Zhou,Chen Li,Ningxin Zhu*

Main category: cs.AI

TL;DR: Empirical-MCTS는 대규모 언어 모델의 추론 능력을 향상시키기 위해 비정적 검색을 지속적인 비모수적 학습 과정으로 변환하는 이중 루프 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 현재의 추론 전략은 성공적인 추론 패턴을 버리고 인간 문제 해결의 지혜 축적을 모방하지 못하는 상태입니다. 이를 해결하기 위해 Empirical-MCTS를 제안합니다.

Method: Empirical-MCTS는 Pairwise-Experience-Evolutionary Meta-Prompting(PE-EMP) 및 메모리 최적화 에이전트를 통한 지역 탐색과 글로벌 메모리 최적화를 통합합니다.

Result: 복잡한 추론 벤치마크에서 Empirical-MCTS는 비정적 MCTS 전략과 경험 기반 에이전트를 능가합니다.

Conclusion: 구조화된 검색과 경험적 축적을 결합하는 것이 복잡하고 개방된 추론 작업을 마스터하는 데 필수적입니다.

Abstract: Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-loop framework that transforms stateless search into a continuous, non-parametric learning process. The framework unifies local exploration with global memory optimization through two novel mechanisms: Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) and a Memory Optimization Agent. PE-EMP functions as a reflexive optimizer within the local search, utilizing pairwise feedback to dynamically synthesize adaptive criteria and evolve meta-prompts (system prompts) in real-time. Simultaneously, the Memory Optimization Agent manages a global repository as a dynamic policy prior, employing atomic operations to distill high-quality insights across problems. Extensive evaluations on complex reasoning benchmarks, including AIME25, ARC-AGI-2, and MathArena Apex, demonstrate that Empirical-MCTS significantly outperforms both stateless MCTS strategies and standalone experience-driven agents. These results underscore the critical necessity of coupling structured search with empirical accumulation for mastering complex, open-ended reasoning tasks.

</details>


### [35] [Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.04284)
*Yansong Ning,Jun Fang,Naiqiang Tan,Hao Liu*

Main category: cs.AI

TL;DR: 이 논문은 다중 턴 에이전트-환경 상호작용에서 에이전트의 사고 및 관찰 관리를 통해 에이전트의 효율성을 향상시키는 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트의 효율성을 향상시키기 위해 다중 턴에서 사고와 관찰을 관리하는 방법에 대한 연구가 필요하다.

Method: Agent-Omit라는 훈련 프레임워크를 제안하여, LLM 에이전트가 중복된 사고와 관찰을 적응적으로 생략하는 방법을 학습하도록 합니다.

Result: Agent-Omit-8B는 일곱 개의 최전선 LLM 에이전트와 유사한 성능을 보이며, 일곱 개의 효율적인 LLM 방법보다 최고의 효율성과 효과성의 균형을 이룹니다.

Conclusion: 제안한 방법은 에이전트의 적응적 생략 능력을 향상시키며, 이론적으로 생략 정책의 편차가 KL-발산으로 상한이 설정됨을 증명합니다.

Abstract: Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.

</details>


### [36] [ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control](https://arxiv.org/abs/2602.04496)
*Zhentao Tang,Yuqi Cui,Shixiong Kai,Wenqian Zhao,Ke Ye,Xing Li,Anxin Tian,Zehua Pei,Hui-Ling Zhen,Shoubo Hu,Xiaoguang Li,Yunhe Wang,Mingxuan Yuan*

Main category: cs.AI

TL;DR: ReThinker는 대형 언어 모델의 과학적 추론 성능을 향상시키기 위해 동적 계산 할당 및 도구 사용을 지원하는 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 과학적 추론 능력, 특히 Humanity's Last Exam(HLE)와 같은 벤치마크에서의 성능 향상이 필요하다.

Method: ReThinker는 단계별 Solver-Critic-Selector 아키텍처를 통해 데이터 검색, 도구 사용, 다중 에이전트 추론을 조율하는 신뢰도 인식 프레임워크이다.

Result: ReThinker는 HLE, GAIA, XBench에서 기존의 최첨단 모델과 심층 연구 시스템보다 일관되게 우수한 성능을 보였다.

Conclusion: ReThinker는 전문가 수준의 추론 작업에서 최첨단 결과를 달성하며, 신뢰도 기반의 다이나믹한 계산 할당을 통해 효율적인 도구 사용을 가능하게 한다.

Abstract: Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rather than following a fixed pipeline, ReThinker dynamically allocates computation based on model confidence, enabling adaptive tool invocation, guided multi-dimensional reflection, and robust confidence-weighted selection. To support scalable training without human annotation, we further propose a reverse data synthesis pipeline and an adaptive trajectory recycling strategy that transform successful reasoning traces into high-quality supervision. Experiments on HLE, GAIA, and XBench demonstrate that ReThinker consistently outperforms state-of-the-art foundation models with tools and existing deep research systems, achieving state-of-the-art results on expert-level reasoning tasks.

</details>


### [37] [Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration](https://arxiv.org/abs/2602.04575)
*Jiaheng Liu,Yuanxing Zhang,Shihao Li,Xinping Lei*

Main category: cs.AI

TL;DR: Vibe AIGC는 사용자 역할을 재정의하고 AI와 인간의 협업을 혁신하는 새로운 콘텐츠 생성 패러다임입니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 생성 AI는 사용성 한계에 직면해 있으며, 이는 창작자의 의도와 모델의 불확실성에서 비롯됩니다.

Method: Vibe AIGC는 높은 수준의 표현인 Vibe를 사용하여 계층적 다중 에이전트 워크플로우를 자율적으로 합성합니다.

Result: 이 방법은 불확실한 추론에서 논리적 오케스트레이션으로의 전환을 통해 인간의 상상력과 기계의 실행 간의 격차를 해소합니다.

Conclusion: Vibe AIGC는 AI를 복잡한 디지털 자산 생성에 있어 강력한 시스템 수준의 엔지니어링 파트너로 변화시킬 것입니다.

Abstract: For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.
  Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.

</details>


### [38] [Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents](https://arxiv.org/abs/2602.04813)
*Shubham Vatsal,Harsh Dubey,Aditi Singh*

Main category: cs.AI

TL;DR: LLM 기반 에이전트가 의료 분야에서 사용되고 있지만, 연구 문헌은 특정 능력에 국한되어 공통적인 틀을 제공하지 못하고 있다. 본 논문은 49개의 연구를 7차원 분류법을 사용하여 검토하고, 각 연구의 능력 유병율 및 동시 발생 패턴을 보고한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트가 의료 및 의학 분야에서 역할을 확대하는 가운데, 기존 문헌은 특정 능력에 집중되어 있어 공통적인 틀을 제공하지 못한다는 문제를 다룬다.

Method: 49개의 연구를 7차원 분류법(인지 능력, 지식 관리, 상호작용 패턴, 적응 및 학습, 안전 및 윤리, 프레임워크 유형 및 핵심 작업 및 하위 작업)으로 분석하고, 각 연구를 이에 매핑하여 능력 유병율과 동시 발생 패턴에 대한 정량적 요약을 보고한다.

Result: 지식 관리 하위 차원에서 외부 지식 통합은 흔하게 구현되는 반면 상호작용 패턴의 사건 기반 활성화는 거의 구현되지 않았고, 적응 및 학습 하위 차원의 드리프트 탐지 및 완화는 매우 드물게 나타났다.

Conclusion: 핵심 작업 및 하위 작업에서 정보 중심 능력이 주도적인 반면, 치료 계획 및 처방과 같은 행동 및 발견 지향 영역은 여전히 상당한 격차를 보인다.

Abstract: Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).

</details>


### [39] [Are AI Capabilities Increasing Exponentially? A Competing Hypothesis](https://arxiv.org/abs/2602.04836)
*Haosen Ge,Hamsa Bastani,Osbert Bastani*

Main category: cs.AI

TL;DR: AI 능력의 기하급수적 성장은 불확실하며, 기존 예측의 취약성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: AI의 빠른 발전이 노동 시장과 안전 문제 등 실질적인 영향을 미치고 있기 때문에 기존 예측의 신뢰성을 검토하고자 한다.

Method: METR 데이터에 시그모이드 곡선을 적용하여 변곡점을 분석하고, AI 능력을 기본 능력과 추론 능력으로 나누는 복잡한 모델을 제안한다.

Result: 현재의 데이터 분석 결과 변곡점은 이미 지나갔다는 것을 발견하고, 새로운 모델을 통해 AI 능력의 향상을 보여준다.

Conclusion: 기하급수적 성장에 대한 기존 예측의 취약성을 강조하며, 향후 AI 능력의 변곡점이 있을 것이라는 가설을 지지한다.

Abstract: Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.

</details>


### [40] [Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing](https://arxiv.org/abs/2602.04837)
*Zhaotian Weng,Antonis Antoniades,Deepak Nathani,Zhen Zhang,Xiao Pu,Xin Eric Wang*

Main category: cs.AI

TL;DR: GEA는 자율적인 구조 수정이 가능한 에이전트 그룹으로, 기존의 한정된 진화 구조를 초월하여 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 인간 개입에 대한 의존성을 줄이기 위해 에이전트가 자율적으로 자신의 구조를 수정할 수 있는 새로운 패러다임이 필요하다.

Method: GEA는 에이전트 그룹을 기본 진화 단위로 삼아 그룹 내 경험 공유 및 재사용을 가능하게 하는 새로운 진화 모델을 도입한다.

Result: GEA는 기존의 자가 진화 방법들보다 훨씬 뛰어난 성과를 보여 주며(예: SWE-bench Verified에서 71.0% 대 56.7%), 상위 인간 설계 에이전트 프레임워크와 비슷하거나 더 나은 성과를 기록한다(각각 71.8%와 52.0%).

Conclusion: GEA는 초기 탐색적 다양성을 효과적으로 지속적인 장기 발전으로 전환하여 더 강력한 성능을 달성하며, 다양한 코딩 모델에서 일관된 전이 가능성을 보이고 프레임워크 레벨의 오류를 평균 1.4번의 반복으로 수정한다.

Abstract: Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.

</details>
