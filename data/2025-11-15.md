<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 12]
- [cs.LG](#cs.LG) [Total: 27]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.CR](#cs.CR) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SynthTools: A Framework for Scaling Synthetic Tools for Agent Development](https://arxiv.org/abs/2511.09572)
*Tommaso Castellani,Naimeng Ye,Daksh Mittal,Thomson Yen,Hongseok Namkoong*

Main category: cs.AI

TL;DR: SynthTools는 복잡한 작업을 해결하기 위해 합성 도구 생태계를 생성하는 유연하고 확장 가능한 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 복잡한 작업을 해결하기 위해 안정적이고 다양한 도구 사용 환경에서 훈련할 수 있도록 하는 것이 필요하다.

Method: SynthTools는 도구 생성, 도구 시뮬레이션 및 도구 감사의 세 가지 핵심 구성 요소로 이루어져 있다.

Result: SynthTools는 이전 연구보다 두 배 많은 도메인과 도메인당 두 배 많은 도구를 생성할 수 있으며, 도구 시뮬레이션과 도구 감사는 각각 $94\%$ 및 $99\%$의 신뢰성을 보인다.

Conclusion: SynthTools는 대규모 훈련과 안정적인 평가를 위한 실용적인 경로를 제공한다.

Abstract: AI agents increasingly rely on external tools to solve complex, long-horizon tasks. Advancing such agents requires reproducible evaluation and large-scale training in controllable, diverse, and realistic tool-use environments. However, real-world APIs are limited in availability, domain coverage, and stability, often requiring access keys and imposing rate limits, which render them impractical for stable evaluation or scalable training. To address these challenges, we introduce SynthTools, a flexible and scalable framework for generating synthetic tool ecosystems. Our framework consists of three core components: Tool Generation for automatic and scalable creation of diverse tools, Tool Simulation to emulate realistic tool behaviors, and Tool Audit to ensure correctness and consistency of tool simulation. To illustrate its scalability, we show that SynthTools can readily produce toolsets that span twice as many domains and twice as many tools per domain as prior work. Furthermore, the tool simulation and tool audit components demonstrate strong reliability, achieving $94\%$ and $99\%$ accuracy respectively. Finally, we construct downstream tasks from the generated tools that even state-of-the-art models struggle to complete. By enabling scalable, diverse, and reliable tool ecosystems, SynthTools provides a practical path toward large-scale training and stable evaluation of tool-use agents. Our code is available at https://github.com/namkoong-lab/SynthTools.

</details>


### [2] [Echoing: Identity Failures when LLM Agents Talk to Each Other](https://arxiv.org/abs/2511.09710)
*Sarath Shekkizhar,Romain Cosentino,Adam Earle,Silvio Savarese*

Main category: cs.AI

TL;DR: 대규모 언어 모델 기반 에이전트 간의 상호작용에서 새로운 유형의 실패, 즉 대화 중 에이전트 간 거울 반응이 발생함을 탐구한다. 이는 인지적 목표를 저해하며, 실험을 통해 이 현상이 광범위하게 존재함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 기반 에이전트들이 자율적으로 서로 상호작용할 때 발생하는 새로운 유형의 실패를 이해하고자 한다.

Method: 60개 AxA 구성, 3개 도메인 및 2000회 이상의 대화에서 실험을 수행하여 에이전트 간 거울 반응인 echoing 현상을 조사한다.

Result: 여러 언어 모델 제공자에서 echoing이 발생하며 비율은 모델 및 도메인에 따라 5%에서 70%까지 다양하다. 고급 추론 모델에서도 echoing이 지속되며 비율은 32.8%로 나타났다.

Conclusion: 구조화된 응답의 목표 지향적 활용을 통해 echoing을 9%로 줄이는 프로토콜 수준의 완화 방안을 제시한다.

Abstract: As large language model (LLM) based agents interact autonomously with one another, a new class of failures emerges that cannot be predicted from single agent performance: behavioral drifts in agent-agent conversations (AxA). Unlike human-agent interactions, where humans ground and steer conversations, AxA lacks such stabilizing signals, making these failures unique. We investigate one such failure, echoing, where agents abandon their assigned roles and instead mirror their conversational partners, undermining their intended objectives. Through experiments across $60$ AxA configurations, $3$ domains, and $2000+$ conversations, we demonstrate that echoing occurs across three major LLM providers, with echoing rates from $5\%$ to $70\%$ depending on the model and domain. Moreover, we find that echoing is persistent even in advanced reasoning models with substantial rates ($32.8\%$) that are not reduced by increased reasoning efforts. We analyze prompt impacts, conversation dynamics, showing that echoing arises as interaction grows longer ($7+$ turns in experiments) and is not merely an artifact of sub-optimal prompting. Finally, we introduce a protocol-level mitigation in which targeted use of structured responses reduces echoing to $9\%$.

</details>


### [3] [SlideBot: A Multi-Agent Framework for Generating Informative, Reliable, Multi-Modal Presentations](https://arxiv.org/abs/2511.09804)
*Eric Xie,Danielle Waterfield,Michael Kennedy,Aidong Zhang*

Main category: cs.AI

TL;DR: SlideBot은 교육을 위해 LLM과 정보 검색, 구조적 계획 및 코드 생성을 통합하는 모듈식 생성 프레임워크로, 슬라이드 준비의 효율성을 높이고 정확성과 적합성을 보장한다.


<details>
  <summary>Details</summary>
Motivation: 교육에서 LLM의 한계를 극복하고 더욱 효과적인 발표 슬라이드 생성을 지원하기 위해

Method: 모듈식 다중 에이전트 슬라이드 생성 프레임워크인 SlideBot을 통해 LLM과 정보 검색, 구조적 계획, 코드 생성을 통합했다.

Result: SlideBot은 개념적 정확성, 명확성 및 교육적 가치를 일관되게 향상시킨다는 결과를 보였다.

Conclusion: SlideBot은 고등 교육에서 슬라이드 준비를 간소화하고 정확성, 관련성, 적응성을 보장할 잠재력을 지닌다.

Abstract: Large Language Models (LLMs) have shown immense potential in education, automating tasks like quiz generation and content summarization. However, generating effective presentation slides introduces unique challenges due to the complexity of multimodal content creation and the need for precise, domain-specific information. Existing LLM-based solutions often fail to produce reliable and informative outputs, limiting their educational value. To address these limitations, we introduce SlideBot - a modular, multi-agent slide generation framework that integrates LLMs with retrieval, structured planning, and code generation. SlideBot is organized around three pillars: informativeness, ensuring deep and contextually grounded content; reliability, achieved by incorporating external sources through retrieval; and practicality, which enables customization and iterative feedback through instructor collaboration. It incorporates evidence-based instructional design principles from Cognitive Load Theory (CLT) and the Cognitive Theory of Multimedia Learning (CTML), using structured planning to manage intrinsic load and consistent visual macros to reduce extraneous load and enhance dual-channel learning. Within the system, specialized agents collaboratively retrieve information, summarize content, generate figures, and format slides using LaTeX, aligning outputs with instructor preferences through interactive refinement. Evaluations from domain experts and students in AI and biomedical education show that SlideBot consistently enhances conceptual accuracy, clarity, and instructional value. These findings demonstrate SlideBot's potential to streamline slide preparation while ensuring accuracy, relevance, and adaptability in higher education.

</details>


### [4] [CTRL-ALT-DECEIT: Sabotage Evaluations for Automated AI R&D](https://arxiv.org/abs/2511.09904)
*Francis Rhys Ward,Teun van der Weij,Hanna Gábor,Sam Martin,Raja Mehta Moreno,Harel Lidar,Louis Makower,Thomas Jodrell,Lauren Robson*

Main category: cs.AI

TL;DR: AI 시스템이 소프트웨어 공학 작업을 자율적으로 수행할 수 있는 능력이 높아지고 있으며, 이는 기계 학습 연구 및 개발(ML R&D) 자동화로 이어질 수 있다. 이 연구는 AI 에이전트가 사용자의 이익에 반하여 작동할 수 있는 능력을 조사하고, 코드 파괴 및 성능 저하를 통해 이러한 행동을 분석한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 신뢰성이 불충분할 수 있으며, 이는 개발자나 사용자와의 불일치 가능성을 포함하고 있다.

Method: MLE-Bench라는 벤치마크를 확장하여 코드 파괴 작업 및 성능 저하를 일으키는 에이전트의 능력을 연구하였다.

Result: 프론티어 에이전트가 코드 파괴 작업에서 의미 있는 진전을 보였으며, 성능을 특정 목표 수준으로 조정할 수 있는 능력을 갖추었다.

Conclusion: 모니터는 코드 파괴 시도를 탐지하는 데 효과적이지만, 성능 저하를 탐지하는 것은 더 어렵고, 여러 모니터 예측을 집계하는 것이 효과적이나 고위험 분야에서 신뢰성이 충분하지 않을 수 있다.

Abstract: AI systems are increasingly able to autonomously conduct realistic software engineering tasks, and may soon be deployed to automate machine learning (ML) R&D itself. Frontier AI systems may be deployed in safety-critical settings, including to help ensure the safety of future systems. Unfortunately, frontier and future systems may not be sufficiently trustworthy, and there is evidence that these systems may even be misaligned with their developers or users. Therefore, we investigate the capabilities of AI agents to act against the interests of their users when conducting ML engineering, by sabotaging ML models, sandbagging their performance, and subverting oversight mechanisms. First, we extend MLE-Bench, a benchmark for realistic ML tasks, with code-sabotage tasks such as implanting backdoors and purposefully causing generalisation failures. Frontier agents make meaningful progress on our sabotage tasks. In addition, we study agent capabilities to sandbag on MLE-Bench. Agents can calibrate their performance to specified target levels below their actual capability. To mitigate sabotage, we use LM monitors to detect suspicious agent behaviour, and we measure model capability to sabotage and sandbag without being detected by these monitors. Overall, monitors are capable at detecting code-sabotage attempts but our results suggest that detecting sandbagging is more difficult. Additionally, aggregating multiple monitor predictions works well, but monitoring may not be sufficiently reliable to mitigate sabotage in high-stakes domains. Our benchmark is implemented in the UK AISI's Inspect framework and we make our code publicly available at https://github.com/samm393/mlebench-subversion

</details>


### [5] [SPAN: Benchmarking and Improving Cross-Calendar Temporal Reasoning of Large Language Models](https://arxiv.org/abs/2511.09993)
*Zhongjian Miao,Hao Fu,Chen Wei*

Main category: cs.AI

TL;DR: 이 논문에서는 LLM이 내부 및 외부 달력 간 시계열 추론을 수행해야 하는 SPAN이라는 크로스-캘린더 시계열 추론 벤치마크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 크로스-캘린더 시계열 추론의 필요성과 LLM의 한계를 극복하기 위해.

Method: 다이나믹 인스턴스 생성을 위한 템플릿 중심 프로토콜을 제안하고, 1960년에서 2060년까지의 날짜 범위에 대해 LLM을 평가합니다.

Result: SOTA LLM의 평균 정확도가 34.5%에 불과하고, 80%를 초과하는 모델은 없습니다.

Conclusion: 도구 증강 코드 생성을 활용한 LLM 기반 시간 에이전트가 평균 95.31%의 정확도로 성능을 향상시킵니다.

Abstract: We introduce SPAN, a cross-calendar temporal reasoning benchmark, which requires LLMs to perform intra-calendar temporal reasoning and inter-calendar temporal conversion. SPAN features ten cross-calendar temporal reasoning directions, two reasoning types, and two question formats across six calendars. To enable time-variant and contamination-free evaluation, we propose a template-driven protocol for dynamic instance generation that enables assessment on a user-specified Gregorian date. We conduct extensive experiments on both open- and closed-source state-of-the-art (SOTA) LLMs over a range of dates spanning 100 years from 1960 to 2060. Our evaluations show that these LLMs achieve an average accuracy of only 34.5%, with none exceeding 80%, indicating that this task remains challenging. Through in-depth analysis of reasoning types, question formats, and temporal reasoning directions, we identify two key obstacles for LLMs: Future-Date Degradation and Calendar Asymmetry Bias. To strengthen LLMs' cross-calendar temporal reasoning capability, we further develop an LLM-powered Time Agent that leverages tool-augmented code generation. Empirical results show that Time Agent achieves an average accuracy of 95.31%, outperforming several competitive baselines, highlighting the potential of tool-augmented code generation to advance cross-calendar temporal reasoning. We hope this work will inspire further efforts toward more temporally and culturally adaptive LLMs.

</details>


### [6] [ChEmREF: Evaluating Language Model Readiness for Chemical Emergency Response](https://arxiv.org/abs/2511.10027)
*Risha Surana,Qinyuan Ye,Swabha Swayamdipta*

Main category: cs.AI

TL;DR: 언어 모델이 긴급 구조대에게 HAZMAT 사건에서 도움이 될 잠재력이 있지만, 여전히 인간의 주의가 필요하다.


<details>
  <summary>Details</summary>
Motivation: 危化물 사고를 관리하는 긴급 구조대는 광범위한 화학 지침을 수동으로 탐색하며, 이 과정에서 시간에 민감한 결정이 요구된다.

Method: 우리는 Emergency Response Guidebook 및 PubChem Database의 1,035 HAZMAT 화학물질에 대한 질문으로 구성된 새로운 벤치마크인 Chemical Emergency Response Evaluation Framework (ChEmREF)를 도입한다. ChEmREF는 (1) 구조화된 형태와 비구조화된 형태 간의 화학 표현 번역, (2) 적절한 대피 거리 추천과 같은 긴급 대응 생성, (3) 화학 안전 및 인증 시험의 도메인 지식 질문 응답의 세 가지 작업으로 구성된다.

Result:  우리의 최종 모델은 비구조화된 HAZMAT 화학 표현 번역에서 68.0%의 정확한 일치를, 사건 대응 추천에서 LLM Judge 점수 52.7%, HAZMAT 시험에서 63.9%의 다중 선택 정확도를 기록했다.

Conclusion: 언어 모델이 다양한 작업에서 긴급 구조대에게 지원할 잠재력을 보이는 반면, 현재의 한계로 인해 신중한 인간의 감독이 필요함을 시사한다.

Abstract: Emergency responders managing hazardous material HAZMAT incidents face critical, time-sensitive decisions, manually navigating extensive chemical guidelines. We investigate whether today's language models can assist responders by rapidly and reliably understanding critical information, identifying hazards, and providing recommendations.We introduce the Chemical Emergency Response Evaluation Framework (ChEmREF), a new benchmark comprising questions on 1,035 HAZMAT chemicals from the Emergency Response Guidebook and the PubChem Database. ChEmREF is organized into three tasks: (1) translation of chemical representation between structured and unstructured forms (e.g., converting C2H6O to ethanol), (2) emergency response generation (e.g., recommending appropriate evacuation distances) and (3) domain knowledge question answering from chemical safety and certification exams. Our best evaluated models received an exact match of 68.0% on unstructured HAZMAT chemical representation translation, a LLM Judge score of 52.7% on incident response recommendations, and a multiple-choice accuracy of 63.9% on HAMZAT examinations.These findings suggest that while language models show potential to assist emergency responders in various tasks, they require careful human oversight due to their current limitations.

</details>


### [7] [Intilligence Foundation Model: A New Perspective to Approach Artificial General Intelligence](https://arxiv.org/abs/2511.10119)
*Borui Cai,Yao Zhao*

Main category: cs.AI

TL;DR: 이 논문에서는 인공지능 일반(AI) 접근을 위한 새로운 관점을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 기초 모델(FM)들은 특정 도메인에서 패턴 학습에 전문화된 반면, 우리는 다양하고 지능적인 행동에서 직접 학습함으로써 지능의 기본 메커니즘을 습득하려고 합니다.

Method: 우리는 상태 신경망이라는 새로운 네트워크 아키텍처와 신경 출력 예측이라는 새로운 학습 목표를 결합하여 시스템이 집단 동역학으로부터 신경 출력 예측을 학습하도록 합니다.

Result: 이러한 방법을 통해 지능적인 행동에서 구조적 동역학을 학습하는 통합적 계산 원리를 제공하여, 범위에 걸쳐 일반화, 추리 및 적응 학습이 가능한 시스템 구축을 위한 생물학적으로 기반잡힌 기초를 설립합니다.

Conclusion: 이는 진정한 AGI를 향한 한 걸음으로 간주될 수 있습니다.

Abstract: We propose a new perspective for approaching artificial general intelligence (AGI) through an intelligence foundation model (IFM). Unlike existing foundation models (FMs), which specialize in pattern learning within specific domains such as language, vision, or time series, IFM aims to acquire the underlying mechanisms of intelligence by learning directly from diverse intelligent behaviors. Vision, language, and other cognitive abilities are manifestations of intelligent behavior; learning from this broad range of behaviors enables the system to internalize the general principles of intelligence. Based on the fact that intelligent behaviors emerge from the collective dynamics of biological neural systems, IFM consists of two core components: a novel network architecture, termed the state neural network, which captures neuron-like dynamic processes, and a new learning objective, neuron output prediction, which trains the system to predict neuronal outputs from collective dynamics. The state neural network emulates the temporal dynamics of biological neurons, allowing the system to store, integrate, and process information over time, while the neuron output prediction objective provides a unified computational principle for learning these structural dynamics from intelligent behaviors. Together, these innovations establish a biologically grounded and computationally scalable foundation for building systems capable of generalization, reasoning, and adaptive learning across domains, representing a step toward truly AGI.

</details>


### [8] [Causal-HalBench: Uncovering LVLMs Object Hallucinations Through Causal Intervention](https://arxiv.org/abs/2511.10268)
*Zhe Xu,Zhicai Wang,Junkang Wu,Jinda Lu,Xiang Wang*

Main category: cs.AI

TL;DR: 대형 비전-언어 모델(LVLM)은 이미지에서 객체의 존재에 대한 잘못된 판단을 초래하는 객체 환각 문제를 겪는다. 본 연구에서는 모델 훈련 중 강하게 동시 발생하는 객체와의 상관 관계로 인해 이러한 환각이 발생한다고 제안하며, LVLM에서의 허위 상관 관계에 대한 정량적 평가가 부족함을 알린다.


<details>
  <summary>Details</summary>
Motivation: LVLM에서의 객체 환각 문제를 해결하기 위해.

Method: 구조적 인과 모델(SCM)을 통해 LVLM의 객체 인식 시나리오에 인과 분석을 도입하고, 동시 발생 편향으로 인한 허위 상관 관계를 정식으로 정의한다. 또한, Causal-HalBench라는 벤치마크를 개발하여 반사실적 샘플과 인과 메트릭을 통합한다.

Result: 주류 LVLM에 대한 우리의 평가 결과, 이 모델들이 허위 상관 관계에 취약함을 보여주었다.

Conclusion: 상황에 따라 다양한 정도로 허위 상관 관계에 대한 민감성을 보인다.

Abstract: Large Vision-Language Models (LVLMs) often suffer from object hallucination, making erroneous judgments about the presence of objects in images. We propose this primar- ily stems from spurious correlations arising when models strongly associate highly co-occurring objects during train- ing, leading to hallucinated objects influenced by visual con- text. Current benchmarks mainly focus on hallucination de- tection but lack a formal characterization and quantitative evaluation of spurious correlations in LVLMs. To address this, we introduce causal analysis into the object recognition scenario of LVLMs, establishing a Structural Causal Model (SCM). Utilizing the language of causality, we formally de- fine spurious correlations arising from co-occurrence bias. To quantify the influence induced by these spurious correla- tions, we develop Causal-HalBench, a benchmark specifically constructed with counterfactual samples and integrated with comprehensive causal metrics designed to assess model ro- bustness against spurious correlations. Concurrently, we pro- pose an extensible pipeline for the construction of these coun- terfactual samples, leveraging the capabilities of proprietary LVLMs and Text-to-Image (T2I) models for their genera- tion. Our evaluations on mainstream LVLMs using Causal- HalBench demonstrate these models exhibit susceptibility to spurious correlations, albeit to varying extents.

</details>


### [9] [Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware](https://arxiv.org/abs/2511.10277)
*Martin Braas,Lukas Esterle*

Main category: cs.AI

TL;DR: 본 논문에서는 작은 언어 모델을 활용한 모듈화된 NPC 대화 시스템을 제안하며, 이는 게임 플레이 중에도 특징적인 대화 맥락과 세계 지식을 유지할 수 있도록 합니다.


<details>
  <summary>Details</summary>
Motivation: LLMs는 인간 같은 텍스트 생성에 뛰어난 성능을 보이지만, 게임 내 대화 시스템에의 응용은 제한적입니다.

Method: 소형 언어 모델(SLM)과 교체 가능한 메모리 모듈을 활용하여 NPC 페르소나를 인코딩하고, 게임 플레이 중 대화 맥락을 유지하는 모듈화된 대화 시스템을 제안합니다.

Result: 세 가지 오픈소스 SLM을 사용하여 시스템을 평가했으며, 소비자 등급 하드웨어에서 벤치마크되었습니다.

Conclusion: 모듈화된 설계와 페르소나 기반 메모리 아키텍처는 게임 외의 분야에서도 대화형 에이전트의 광범위한 채택 가능성을 지니고 있습니다.

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in generating human-like text, yet their applicability to dialogue systems in computer games remains limited. This limitation arises from their substantial hardware requirements, latency constraints, and the necessity to maintain clearly defined knowledge boundaries within a game setting. In this paper, we propose a modular NPC dialogue system that leverages Small Language Models (SLMs), fine-tuned to encode specific NPC personas and integrated with runtime-swappable memory modules. These memory modules preserve character-specific conversational context and world knowledge, enabling expressive interactions and long-term memory without retraining or model reloading during gameplay. We comprehensively evaluate our system using three open-source SLMs: DistilGPT-2, TinyLlama-1.1B-Chat, and Mistral-7B-Instruct, trained on synthetic persona-aligned data and benchmarked on consumer-grade hardware. While our approach is motivated by applications in gaming, its modular design and persona-driven memory architecture hold significant potential for broader adoption in domains requiring expressive, scalable, and memory-rich conversational agents, such as virtual assistants, customer support bots, or interactive educational systems.

</details>


### [10] [Explaining Decentralized Multi-Agent Reinforcement Learning Policies](https://arxiv.org/abs/2511.10409)
*Kayla Boggess,Sarit Kraus,Lu Feng*

Main category: cs.AI

TL;DR: 본 연구에서는 분산 MARL 정책에서 작업 순서와 에이전트 협력을 포착하는 정책 요약 방식을 제안하며, 특정 에이전트 행동에 대한 사용자 질의에 대한 설명을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: MARL이 다양한 분야에서의 순차적 의사결정을 가능하게 하지만, 기존 설명 방법들이 분산 설정의 불확실성과 비결정성을 다루지 못하는 한계를 가지고 있습니다.

Method: 분산 MARL 정책에서 작업 순서와 에이전트 협력을 포착하는 정책 요약 생성 방법과 특정 에이전트 행동에 대한 '언제', '왜 안되는가', '무엇'과 같은 질의 기반 설명을 제안합니다.

Result: 네 가지 MARL 도메인과 두 가지 분산 MARL 알고리즘에 걸쳐 접근 방식을 평가하여 일반화 가능성과 계산 효율성을 입증했습니다.

Conclusion: 사용자 연구 결과, 우리의 요약 및 설명이 사용자 질문 응답 성능을 크게 향상시키고 이해도 및 만족도와 같은 메트릭에서 주관적 평가를 향상시킨다는 것을 보여줍니다.

Abstract: Multi-Agent Reinforcement Learning (MARL) has gained significant interest in recent years, enabling sequential decision-making across multiple agents in various domains. However, most existing explanation methods focus on centralized MARL, failing to address the uncertainty and nondeterminism inherent in decentralized settings. We propose methods to generate policy summarizations that capture task ordering and agent cooperation in decentralized MARL policies, along with query-based explanations for When, Why Not, and What types of user queries about specific agent behaviors. We evaluate our approach across four MARL domains and two decentralized MARL algorithms, demonstrating its generalizability and computational efficiency. User studies show that our summarizations and explanations significantly improve user question-answering performance and enhance subjective ratings on metrics such as understanding and satisfaction.

</details>


### [11] [Strategic Opponent Modeling with Graph Neural Networks, Deep Reinforcement Learning and Probabilistic Topic Modeling](https://arxiv.org/abs/2511.10501)
*Georgios Chalkiadakis,Charilaos Akasiadis,Gerasimos Koresis,Stergios Plataniots,Leonidas Bakopoulos*

Main category: cs.AI

TL;DR: 이 논문은 주로 그래프 신경망, 심층 강화 학습 및 확률적 주제 모델링 방법에 대한 포괄적인 리뷰를 제공하며, 이들의 전략적 다중 에이전트 설정에서의 잠재적 통합에 집중한다.


<details>
  <summary>Details</summary>
Motivation: 전략적 상대 모델링 작업에 적응 가능한 알려지지 않은 모델 구조를 발견하는 데 사용되는 머신 러닝 방법과 실제 세계 시나리오에서 종종 유효하지 않은 가정을 피하는 게임 이론 개념과의 통합에 관심을 둔다.

Method: 그래프 구조 데이터에서 작동하도록 설계된 그래프 신경망(GNN)의 사용을 옹호하며, 이는 노드 분류 및 링크 예측과 같은 작업을 수행하는 데 매우 강력한 도구로 입증되었다. 또한, 다중 에이전트 심층 강화 학습(MADRL) 영역과 관련 게임 이론 솔루션 개념을 검토한다.

Result: PTM의 비공식적 이론을 사용하여 문서 분석 및 분류 외 다른 도메인에서 활용되는 문헌에 대한 참고 문헌을 포함하며, PTM은 알려지지 않은 기본 분포를 추정하는 데 도움이 될 수 있다.

Conclusion: 비정상 환경에 적합하고 안정성 및 적응 정도를 균형을 맞추며, 불확실성과 이질성을 처리하고, 확장성과 솔루션 가시성을 보장해야 하는 특정 개방 과제를 식별한다.

Abstract: This paper provides a comprehensive review of mainly Graph Neural Networks, Deep Reinforcement Learning, and Probabilistic Topic Modeling methods with a focus on their potential incorporation in strategic multiagent settings. We draw interest in (i) Machine Learning methods currently utilized for uncovering unknown model structures adaptable to the task of strategic opponent modeling, and (ii) the integration of these methods with Game Theoretic concepts that avoid relying on assumptions often invalid in real-world scenarios, such as the Common Prior Assumption (CPA) and the Self-Interest Hypothesis (SIH). We analyze the ability to handle uncertainty and heterogeneity, two characteristics that are very common in real-world application cases, as well as scalability. As a potential answer to effectively modeling relationships and interactions in multiagent settings, we champion the use of Graph Neural Networks (GNN). Such approaches are designed to operate upon graph-structured data, and have been shown to be a very powerful tool for performing tasks such as node classification and link prediction. Next, we review the domain of Reinforcement Learning (RL), and in particular that of Multiagent Deep Reinforcement Learning (MADRL). Following, we describe existing relevant game theoretic solution concepts and consider properties such as fairness and stability. Our review comes complete with a note on the literature that utilizes PTM in domains other than that of document analysis and classification. The capability of PTM to estimate unknown underlying distributions can help with tackling heterogeneity and unknown agent beliefs. Finally, we identify certain open challenges specifically, the need to (i) fit non-stationary environments, (ii) balance the degrees of stability and adaptation, (iii) tackle uncertainty and heterogeneity, (iv) guarantee scalability and solution tractability.

</details>


### [12] [Regular Games -- an Automata-Based General Game Playing Language](https://arxiv.org/abs/2511.10593)
*Radosław Miernik,Marek Szykuła,Jakub Kowalski,Jakub Cieśluk,Łukasz Galas,Wojciech Pawlik*

Main category: cs.AI

TL;DR: 새로운 일반 게임 플레이 시스템인 Regular Games(RG)를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: RG의 주된 목표는 게임 디자인에 편리하면서도 계산적으로 효율적인 시스템을 만드는 것입니다.

Method: RG는 유한 자동기로 규칙을 정의하는 저수준 언어를 핵심 구성 요소로 가지고 있으며, 고수준 언어를 통해 게임 디자인을 지원합니다.

Result: RG는 현재의 최첨단 시스템보다 더 빠른 전방 모델을 생성하여 효율성 측면에서 다른 GGP 시스템을 능가합니다.

Conclusion: RG의 생태계에는 LSP를 갖춘 편집기, 자동화 시각화, 벤치마킹 도구 및 게임 설명 변환의 디버거가 포함되어 있습니다.

Abstract: We propose a new General Game Playing (GGP) system called Regular Games (RG). The main goal of RG is to be both computationally efficient and convenient for game design. The system consists of several languages. The core component is a low-level language that defines the rules by a finite automaton. It is minimal with only a few mechanisms, which makes it easy for automatic processing (by agents, analysis, optimization, etc.). The language is universal for the class of all finite turn-based games with imperfect information. Higher-level languages are introduced for game design (by humans or Procedural Content Generation), which are eventually translated to a low-level language. RG generates faster forward models than the current state of the art, beating other GGP systems (Regular Boardgames, Ludii) in terms of efficiency. Additionally, RG's ecosystem includes an editor with LSP, automaton visualization, benchmarking tools, and a debugger of game description transformations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [Beyond Monotonicity: Revisiting Factorization Principles in Multi-Agent Q-Learning](https://arxiv.org/abs/2511.09792)
*Tianmeng Hu,Yongzheng Cui,Rui Tang,Biao Luo,Ke Li*

Main category: cs.LG

TL;DR: 비모노토닉 가치 분해에 대한 동적 시스템 분석을 제공하고, IGM 일관성을 위반하는 모든 제로 손실 평형이 불안정한 안장점임을 증명한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습에서 개별-글로벌-최대(IGM) 일관성을 보장하는 것이 중요하다.

Method: 학습 동역학을 연속 시간 그래디언트 흐름으로 모델링하고 비모노토닉 가치 분해의 동적 시스템 분석을 수행한다.

Result: 비제한적 비모노토닉 분해가 IGM 최적 솔루션을 안정적으로 복구하고 모노토닉 기준선보다 일관되게 성능을 발휘한다.

Conclusion: 미래 가치 기반 MARL 알고리즘 설계를 위한 실행 가능한 통찰력을 제공한다.

Abstract: Value decomposition is a central approach in multi-agent reinforcement learning (MARL), enabling centralized training with decentralized execution by factorizing the global value function into local values. To ensure individual-global-max (IGM) consistency, existing methods either enforce monotonicity constraints, which limit expressive power, or adopt softer surrogates at the cost of algorithmic complexity. In this work, we present a dynamical systems analysis of non-monotonic value decomposition, modeling learning dynamics as continuous-time gradient flow. We prove that, under approximately greedy exploration, all zero-loss equilibria violating IGM consistency are unstable saddle points, while only IGM-consistent solutions are stable attractors of the learning dynamics. Extensive experiments on both synthetic matrix games and challenging MARL benchmarks demonstrate that unconstrained, non-monotonic factorization reliably recovers IGM-optimal solutions and consistently outperforms monotonic baselines. Additionally, we investigate the influence of temporal-difference targets and exploration strategies, providing actionable insights for the design of future value-based MARL algorithms.

</details>


### [14] [Group Averaging for Physics Applications: Accuracy Improvements at Zero Training Cost](https://arxiv.org/abs/2511.09573)
*Valentino F. Foit,David W. Hogg,Soledad Villar*

Main category: cs.LG

TL;DR: 그룹 평균화 기법을 통해 기계 학습 모델의 정확도를 향상시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 자연 과학의 중요한 기계 학습 작업들은 특정 대칭에 대해 정확하게 등변성을 가진다. 그러나 대칭을 학습해야 한다는 선입견이나 구현의 어려움 때문에 등변적인 방법들이 종종 사용되지 않는다.

Method: 존재하는 모델들을 소규모 대칭 집합에 대해 평균화하는 그룹 평균화 기법을 사용하였다.

Result: 이 실험은 항상 평균 평가 손실을 감소시키며 VRMSE 측면에서 최대 37	ilde{0}	ext{{}%} 개선을 보였다.

Conclusion: 정확한 대칭을 강요하는 것이 단점이 없으며, ML4PS 커뮤니티는 모델 정확도를 개선하기 위한 저렴하고 간단한 방법으로 그룹 평균화를 고려해야 한다.

Abstract: Many machine learning tasks in the natural sciences are precisely equivariant to particular symmetries. Nonetheless, equivariant methods are often not employed, perhaps because training is perceived to be challenging, or the symmetry is expected to be learned, or equivariant implementations are seen as hard to build. Group averaging is an available technique for these situations. It happens at test time; it can make any trained model precisely equivariant at a (often small) cost proportional to the size of the group; it places no requirements on model structure or training. It is known that, under mild conditions, the group-averaged model will have a provably better prediction accuracy than the original model. Here we show that an inexpensive group averaging can improve accuracy in practice. We take well-established benchmark machine learning models of differential equations in which certain symmetries ought to be obeyed. At evaluation time, we average the models over a small group of symmetries. Our experiments show that this procedure always decreases the average evaluation loss, with improvements of up to 37\% in terms of the VRMSE. The averaging produces visually better predictions for continuous dynamics. This short paper shows that, under certain common circumstances, there are no disadvantages to imposing exact symmetries; the ML4PS community should consider group averaging as a cheap and simple way to improve model accuracy.

</details>


### [15] [Towards Emotionally Intelligent and Responsible Reinforcement Learning](https://arxiv.org/abs/2511.10573)
*Garapati Keerthana,Manik Gupta*

Main category: cs.LG

TL;DR: 정서적 및 윤리적 고려사항을 통합한 책임 있는 강화 학습(RRL) 프레임워크를 제안하여 개인화된 의료 및 행동 지원 시스템의 한계를 극복한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 개인화된 결정 시스템은 사용자의 정서적 맥락과 윤리적 제약을 무시하고 static 규칙 기반 또는 참여 극대화 휴리스틱에 의존하여 민감하지 않거나 안전하지 않은 개입을 추천할 위험이 있다.

Method: 책임 있는 강화 학습(RRL) 프레임워크는 정서적 및 맥락적 이해와 윤리적 고려사항을 연속적인 의사결정 과정에 통합하며, 개인화를 제약이 있는 마르코프 결정 과정(CMDP)으로 공식화한다.

Result: RRL은 행동 engagement와 adherence를 최적화하면서 감정적 일치 및 윤리적 안전을 보장하는 다목적 보상 함수를 도입한다.

Conclusion: 이 프레임워크는 기계 학습 정책 최적화에서 공감과 책임을 구현하며, 행동 건강, 교육 및 디지털 치료와 같은 인간 중심의 분야에 대한 시사점을 논의한다.

Abstract: Personalized decision systems in healthcare and behavioral support often rely on static rule-based or engagement-maximizing heuristics that overlook users' emotional context and ethical constraints. Such approaches risk recommending insensitive or unsafe interventions, especially in domains involving serious mental illness, substance use disorders, or depression. To address this limitation, we propose a Responsible Reinforcement Learning (RRL) framework that integrates emotional and contextual understanding with ethical considerations into the sequential decision-making process. RRL formulates personalization as a Constrained Markov Decision Process (CMDP), where the agent optimizes engagement and adherence while ensuring emotional alignment and ethical safety. We introduce a multi-objective reward function that explicitly balances short-term behavioral engagement with long-term user well-being, and define an emotion-informed state representation that captures fluctuations in emotional readiness, affect, and risk. The proposed architecture can be instantiated with any RL algorithm (e.g., DQN, PPO) augmented with safety constraints or Lagrangian regularization. Conceptually, this framework operationalizes empathy and responsibility within machine learning policy optimization, bridging safe RL, affective computing and responsible AI. We discuss the implications of this approach for human-centric domains such as behavioral health, education, and digital therapeutics, and outline simulation-based validation paths for future empirical work. This paper aims to initiate a methodological conversation about ethically aligned reinforcement learning for emotionally aware and trustworthy personalization systems.

</details>


### [16] [Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey](https://arxiv.org/abs/2511.09586)
*Yuchen Huang,Sijia Li,Minghao Liu,Wei Liu,Shijue Huang,Zhiyuan Fan,Hou Pong Chan,Yi R. Fung*

Main category: cs.LG

TL;DR: 이 논문은 LLM 기반 에이전트가 복잡한 작업을 수행하기 위해 경험 학습을 통한 환경 상호작용의 중요성을 강조하며, GEF 루프를 정의하고 환경의 발전 방향을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트의 적응 행동 및 장기 의사결정 능력을 향상시키기 위해서는 정적 데이터세트로는 부족하다.

Method: 우리는 에이전트가 직면하는 작업을 생성하고, 작업 수행 중 관찰 결과를 반환하며, 롤아웃에 대한 평가 피드백을 제공하는 GEF 루프를 형식화하였다.

Result: 환경은 경험적 데이터를 생성하는 중요한 생산자로 기능하며, 복잡성, 현실성 및 상호작용성을 높일 필요가 있다.

Conclusion: 우리는 GEF 루프의 단계에 따라 환경 확장에 대한 대표적인 방법을 체계적으로 검토하고, 벤치마크 및 응용 프로그램을 분석하여 에이전트 지능의 미래 연구 방향을 제시한다.

Abstract: LLM-based agents can autonomously accomplish complex tasks across various domains. However, to further cultivate capabilities such as adaptive behavior and long-term decision-making, training on static datasets built from human-level knowledge is insufficient. These datasets are costly to construct and lack both dynamism and realism. A growing consensus is that agents should instead interact directly with environments and learn from experience through reinforcement learning. We formalize this iterative process as the Generation-Execution-Feedback (GEF) loop, where environments generate tasks to challenge agents, return observations in response to agents' actions during task execution, and provide evaluative feedback on rollouts for subsequent learning. Under this paradigm, environments function as indispensable producers of experiential data, highlighting the need to scale them toward greater complexity, realism, and interactivity. In this survey, we systematically review representative methods for environment scaling from a pioneering environment-centric perspective and organize them along the stages of the GEF loop, namely task generation, task execution, and feedback. We further analyze benchmarks, implementation strategies, and applications, consolidating fragmented advances and outlining future research directions for agent intelligence.

</details>


### [17] [Parametric Expensive Multi-Objective Optimization via Generative Solution Modeling](https://arxiv.org/abs/2511.09598)
*Tingyang Wei,Jiao Liu,Abhishek Gupta,Chin Chun Ooi,Puay Siew Tan,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 이 논문은 비용이 많이 드는 다목적 최적화 문제(P-EMOPs)의 파라메트릭 다목적 베이지안 최적화를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 운영 조건에서 비싼 다목적 최적화 문제의 해결이 필요하다.

Method: 상호 작업 시너지를 활용한 탐색과 조건부 생성 모델을 통한 해결책 샘플링을 통해 역 모델을 학습하는 파라메트릭 다목적 베이지안 최적화 방법을 제안한다.

Result: 효율적인 최적화를 달성하고, 추가적인 비싼 평가 없이 보지 못한 파라메터화된 EMOPs에 대한 직접적인 솔루션 예측을 가능하게 한다.

Conclusion: 이론적으로 작업 인식 가우시안 프로세스를 통해 더 빠른 수렴을 정당화하며, 실험적으로 프레임워크의 효과성을 검증했다.

Abstract: Many real-world applications require solving families of expensive multi-objective optimization problems~(EMOPs) under varying operational conditions. This gives rise to parametric expensive multi-objective optimization problems (P-EMOPs) where each task parameter defines a distinct optimization instance. Current multi-objective Bayesian optimization methods have been widely used for finding finite sets of Pareto optimal solutions for individual tasks. However, P-EMOPs present a fundamental challenge: the continuous task parameter space can contain infinite distinct problems, each requiring separate expensive evaluations. This demands learning an inverse model that can directly predict optimized solutions for any task-preference query without expensive re-evaluation. This paper introduces the first parametric multi-objective Bayesian optimizer that learns this inverse model by alternating between (1) acquisition-driven search leveraging inter-task synergies and (2) generative solution sampling via conditional generative models. This approach enables efficient optimization across related tasks and finally achieves direct solution prediction for unseen parameterized EMOPs without additional expensive evaluations. We theoretically justify the faster convergence by leveraging inter-task synergies through task-aware Gaussian processes. Meanwhile, empirical studies in synthetic and real-world benchmarks further verify the effectiveness of our alternating framework.

</details>


### [18] [SEBA: Sample-Efficient Black-Box Attacks on Visual Reinforcement Learning](https://arxiv.org/abs/2511.09681)
*Tairan Huang,Yulin Jin,Junxu Liu,Qingqing Ye,Haibo Hu*

Main category: cs.LG

TL;DR: SEBA는 비주얼 RL 에이전트에 대한 샘플 효율적인 블랙박스 공격 프레임워크로, 강력한 공격 성능을 유지하는 동시에 효율성을 확보합니다.


<details>
  <summary>Details</summary>
Motivation: 비주얼 강화 학습의 적대적 교란에 대한 취약성이 충분히 탐구되지 않았고, 기존의 공격 방식들은 이미지 기반 연속 제어의 큰 행동 공간에 따라 제한적입니다.

Method: SEBA는 적대적 조건에서 누적 보상을 추정하는 그림자 Q 모델, 시각적으로 인식할 수 없는 교란을 생성하는 생성적 적대 신경망, 그리고 실제 쿼리를 줄이기 위한 환경 역학을 시뮬레이션하는 세계 모델을 통합하는 샘플 효율적인 프레임워크입니다.

Result: SEBA는 MuJoCo와 Atari 벤치마크에서 누적 보상을 크게 감소시키고, 시각적 충실도를 유지하며, 이전의 블랙박스 및 화이트박스 방법에 비해 환경 상호작용을 크게 줄입니다.

Conclusion: SEBA는 블랙박스 적대적 공격에서 강력한 성능을 달성하며 효율성을 유지합니다.

Abstract: Visual reinforcement learning has achieved remarkable progress in visual control and robotics, but its vulnerability to adversarial perturbations remains underexplored. Most existing black-box attacks focus on vector-based or discrete-action RL, and their effectiveness on image-based continuous control is limited by the large action space and excessive environment queries. We propose SEBA, a sample-efficient framework for black-box adversarial attacks on visual RL agents. SEBA integrates a shadow Q model that estimates cumulative rewards under adversarial conditions, a generative adversarial network that produces visually imperceptible perturbations, and a world model that simulates environment dynamics to reduce real-world queries. Through a two-stage iterative training procedure that alternates between learning the shadow model and refining the generator, SEBA achieves strong attack performance while maintaining efficiency. Experiments on MuJoCo and Atari benchmarks show that SEBA significantly reduces cumulative rewards, preserves visual fidelity, and greatly decreases environment interactions compared to prior black-box and white-box methods.

</details>


### [19] [Out-of-Distribution Generalization with a SPARC: Racing 100 Unseen Vehicles with a Single Policy](https://arxiv.org/abs/2511.09737)
*Bram Grooten,Patrick MacAlpine,Kaushik Subramanian,Peter Stone,Peter R. Wurman*

Main category: cs.LG

TL;DR: 이 논문은 로봇 및 제어 분야에서의 보지 못한 환경으로의 일반화 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 로봇이 다양한 컨텍스트에서 작동해야 하는 상황에서 일반화 능력을 향상시키기 위해 연구한다.

Method: SPARC: 단일 단계 적응을 통해 신뢰할 수 있는 제어를 수행하는 방법을 제안한다.

Result: SPARC는 고충실도 레이싱 시뮬레이터 및 바람이 끼친 MuJoCo 환경에서 안정적이고 강력한 OOD 일반화 성능을 나타낸다.

Conclusion: 이 단일 단계 접근 방식이 이전의 두 단계 방법보다 더 효율적임을 보여준다.

Abstract: Generalization to unseen environments is a significant challenge in the field of robotics and control. In this work, we focus on contextual reinforcement learning, where agents act within environments with varying contexts, such as self-driving cars or quadrupedal robots that need to operate in different terrains or weather conditions than they were trained for. We tackle the critical task of generalizing to out-of-distribution (OOD) settings, without access to explicit context information at test time. Recent work has addressed this problem by training a context encoder and a history adaptation module in separate stages. While promising, this two-phase approach is cumbersome to implement and train. We simplify the methodology and introduce SPARC: single-phase adaptation for robust control. We test SPARC on varying contexts within the high-fidelity racing simulator Gran Turismo 7 and wind-perturbed MuJoCo environments, and find that it achieves reliable and robust OOD generalization.

</details>


### [20] [NeuroLingua: A Language-Inspired Hierarchical Framework for Multimodal Sleep Stage Classification Using EEG and EOG](https://arxiv.org/abs/2511.09773)
*Mahdi Samaee,Mehran Yazdi,Daniel Massicotte*

Main category: cs.LG

TL;DR: NeuroLingua는 수면 단계를 자동으로 분류하기 위한 새로운 언어 기반 프레임워크로, CNN 기반 토크나이저를 사용하여 30초 에포크를 3초 하위 윈도우로 분해하고, 그래프 합성 네트워크를 통해 EEG 및 EOG 데이터를 통합하여 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 다양한 수면 데이터에서 자동 수면 단계 분류를 개선하기 위해, 수면을 체계적인 생리학적 언어로 개념화하고자 함.

Method: 30초 에포크를 겹치는 3초 하위 윈도우로 분해하고, 이중 레벨 변환기를 통해 계층적 시간 모델링을 수행하며, 그래프 합성 네트워크를 이용해 EEG 및 EOG 채널의 모달리티 특화 임베딩을 융합함.

Result: Sleep-EDF Expanded 및 ISRUC-Sleep 데이터셋에서 각각 85.3% 및 81.9%의 정확도로 최첨단 성능을 달성하였으며, 출판된 기준을 초과하거나 일치하는 결과를 보임.

Conclusion: NeuroLingua는 수면을 조합 언어로 프레임화하여 계층적 시퀀스 모델링과 다중 모달 융합을 통합하며, 자동화된 수면 단계를 더 투명하고 임상적으로 의미 있는 응용으로 발전시킴.

Abstract: Automated sleep stage classification from polysomnography remains limited by the lack of expressive temporal hierarchies, challenges in multimodal EEG and EOG fusion, and the limited interpretability of deep learning models. We propose NeuroLingua, a language-inspired framework that conceptualizes sleep as a structured physiological language. Each 30-second epoch is decomposed into overlapping 3-second subwindows ("tokens") using a CNN-based tokenizer, enabling hierarchical temporal modeling through dual-level Transformers: intra-segment encoding of local dependencies and inter-segment integration across seven consecutive epochs (3.5 minutes) for extended context. Modality-specific embeddings from EEG and EOG channels are fused via a Graph Convolutional Network, facilitating robust multimodal integration. NeuroLingua is evaluated on the Sleep-EDF Expanded and ISRUC-Sleep datasets, achieving state-of-the-art results on Sleep-EDF (85.3% accuracy, 0.800 macro F1, and 0.796 Cohen's kappa) and competitive performance on ISRUC (81.9% accuracy, 0.802 macro F1, and 0.755 kappa), matching or exceeding published baselines in overall and per-class metrics. The architecture's attention mechanisms enhance the detection of clinically relevant sleep microevents, providing a principled foundation for future interpretability, explainability, and causal inference in sleep research. By framing sleep as a compositional language, NeuroLingua unifies hierarchical sequence modeling and multimodal fusion, advancing automated sleep staging toward more transparent and clinically meaningful applications.

</details>


### [21] [Learning Intersections of Halfspaces under Factorizable Distribution](https://arxiv.org/abs/2511.09832)
*Ilias Diakonikolas,Mingchen Ma,Lisheng Ren,Christos Tzamos*

Main category: cs.LG

TL;DR: 이 논문에서는 반공간의 교차점 학습 문제를 다루며, 기존의 상관통계 질의(CSQ) 의존성을 우회하는 새로운 알고리즘을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 반공간의 교차점 학습은 계산 학습 이론에서 중요한 문제이며, 마진 $γ$와 차원 $d$에 따라 다항 시간 학습 가능 여부가 주요 쟁점입니다.

Method: 새로운 알고리즘은 자연적인 인수화 가정을 만족하는 폭넓은 분포 클래스에 적용되며, CSQ 기반 방법은 여전히 준다항 시간 소요되는 반면, 우리 알고리즘은 더 일반적인 통계 질의(SQ)를 활용하여 $poly(d,1/γ)$시간을 달성합니다.

Result: 제안된 알고리즘은 CSQ와 SQ 간의 강한 구분을 세우며, 마진 분포에 의해 유도된 모멘트 텐서 구조를 특성화하는 새로운 쌍대성 프레임워크를 기반으로 합니다.

Conclusion: 새로운 효율적인 학습 알고리즘은 Jennrich의 알고리즘의 정제된 변형과 모멘트 텐서의 무작위 투영에 대한 PCA, 경량 비볼록 최적화 프레임워크와 결합됩니다.

Abstract: Learning intersections of halfspaces is a central problem in Computational Learning Theory. Even for just two halfspaces, it remains a major open question whether learning is possible in polynomial time with respect to the margin $γ$ of the data points and their dimensionality $d$. The best-known algorithms run in quasi-polynomial time $d^{O(\log(1/γ))}$, and it has been shown that this complexity is unavoidable for any algorithm relying solely on correlational statistical queries (CSQ).
  In this work, we introduce a novel algorithm that provably circumvents the CSQ hardness barrier. Our approach applies to a broad class of distributions satisfying a natural, previously studied, factorizability assumption. Factorizable distributions lie between distribution-specific and distribution-free settings, and significantly extend previously known tractable cases. Under these distributions, we show that CSQ-based methods still require quasipolynomial time even for weakly learning, whereas our algorithm achieves $poly(d,1/γ)$ time by leveraging more general statistical queries (SQ), establishing a strong separation between CSQ and SQ for this simple realizable PAC learning problem.
  Our result is grounded in a rigorous analysis utilizing a novel duality framework that characterizes the moment tensor structure induced by the marginal distributions. Building on these structural insights, we propose new, efficient learning algorithms. These algorithms combine a refined variant of Jennrich's Algorithm with PCA over random projections of the moment tensor, along with a gradient-descent-based non-convex optimization framework.

</details>


### [22] [ACT as Human: Multimodal Large Language Model Data Annotation with Critical Thinking](https://arxiv.org/abs/2511.09833)
*Lequan Lin,Dai Shi,Andi Han,Feng Chen,Qiuzheng Chen,Jiawen Li,Zhaoyang Li,Jiyuan Li,Zhenbang Sun,Junbin Gao*

Main category: cs.LG

TL;DR: ACT 데이터 파이프라인은 LLM이 주석 작성자이자 비평가로 작용하여 인간 주석 효율성을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 고품질 주석 데이터의 수집이 비용이 많이 들고 시간이 소요되기 때문에, LLM을 활용하여 주석을 생성하는 방법을 찾고 있다.

Method: ACT 데이터 파이프라인을 제안하며, LLM이 주석자로서 뿐만 아니라 오류를 비판적으로 식별하는 심사자로서도 기능한다.

Result: 대부분의 벤치마크 데이터세트에서 성능 격차를 2% 미만으로 줄이고, 최대 90%의 인간 비용을 절감할 수 있었다.

Conclusion: ACT는 다양한 도메인에 적용 가능하며, 주석 품질을 향상시키는 7가지 통찰력을 도출하고 이를 사용자 친화적인 지침으로 변환하였다.

Abstract: Supervised learning relies on high-quality labeled data, but obtaining such data through human annotation is both expensive and time-consuming. Recent work explores using large language models (LLMs) for annotation, but LLM-generated labels still fall short of human-level quality. To address this problem, we propose the Annotation with Critical Thinking (ACT) data pipeline, where LLMs serve not only as annotators but also as judges to critically identify potential errors. Human effort is then directed towards reviewing only the most "suspicious" cases, significantly improving the human annotation efficiency. Our major contributions are as follows: (1) ACT is applicable to a wide range of domains, including natural language processing (NLP), computer vision (CV), and multimodal understanding, by leveraging multimodal-LLMs (MLLMs). (2) Through empirical studies, we derive 7 insights on how to enhance annotation quality while efficiently reducing the human cost, and then translate these findings into user-friendly guidelines. (3) We theoretically analyze how to modify the loss function so that models trained on ACT data achieve similar performance to those trained on fully human-annotated data. Our experiments show that the performance gap can be reduced to less than 2% on most benchmark datasets while saving up to 90% of human costs.

</details>


### [23] [Uncertainty-Guided Checkpoint Selection for Reinforcement Finetuning of Large Language Models](https://arxiv.org/abs/2511.09864)
*Manh Nguyen,Dung Nguyen,Dai Do,Svetha Venkatesh,Hung Le*

Main category: cs.LG

TL;DR: 본 논문은 RL 미세 조정 과정의 안정성을 높이고 모델 체크포인트 선택을 개선하는 불확실성 기반 접근법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: RL 미세 조정은 대규모 언어 모델의 정렬에 필수적이나, 이 과정은 불안정하고 높은 분산을 보입니다. 이 논문은 체크포인트 선택을 위한 불확실성 기반 접근법을 제안하여 이러한 문제를 해결하고자 합니다.

Method: 불확실성에 따라 어려운 질문-답변 쌍을 식별하고, 이러한 사례를 잘 처리하는지에 따라 체크포인트를 정렬하는 방법을 사용합니다. 또한, 상위 불확실 샘플의 보상을 단기 훈련 윈도우 기간 동안 평균화하여 추가적인 연산 오버헤드 없이 안정적이고 차별화된 신호를 생성합니다.

Result: 세 개의 데이터셋과 세 개의 LLM에 대한 실험을 통해, 제안된 방법이 전통적인 전략을 초월하여 더 강력한 일반화 능력을 가진 체크포인트를 일관되게 식별함을 보여줍니다.

Conclusion: 어려운 작업을 저 불확실성으로 해결하는 모델이 전체적으로 가장 신뢰할 수 있음을 강조합니다.

Abstract: Reinforcement learning (RL) finetuning is crucial to aligning large language models (LLMs), but the process is notoriously unstable and exhibits high variance across model checkpoints. In practice, selecting the best checkpoint is challenging: evaluating checkpoints on the validation set during training is computationally expensive and requires a good validation set, while relying on the final checkpoint provides no guarantee of good performance. We introduce an uncertainty-guided approach for checkpoint selection (UGCS) that avoids these pitfalls. Our method identifies hard question-answer pairs using per-sample uncertainty and ranks checkpoints by how well they handle these challenging cases. By averaging the rewards of the top-uncertain samples over a short training window, our method produces a stable and discriminative signal without additional forward passes or significant computation overhead. Experiments across three datasets and three LLMs demonstrate that it consistently identifies checkpoints with stronger generalization, outperforming traditional strategies such as relying on training or validation performance. These results highlight that models solving their hardest tasks with low uncertainty are the most reliable overall.

</details>


### [24] [Expandable and Differentiable Dual Memories with Orthogonal Regularization for Exemplar-free Continual Learning](https://arxiv.org/abs/2511.09871)
*Hyung-Jun Moon,Sung-Bae Cho*

Main category: cs.LG

TL;DR: 제안된 방법은 연속 학습에서 새로운 개념을 효과적으로 통합하여 성능을 향상시키는 신경망 접근법이다.


<details>
  <summary>Details</summary>
Motivation: 연속 학습 방법은 신경망이 순차적 과제를 독립적으로 처리하도록 강제하여 유용한 과제 간 관계를 활용하지 못하게 하고, 비슷한 특징을 반복적으로 다시 학습하거나 지나치게 구분하게 만든다.

Method: 제안된 방법은 두 개의 보완적인 메모리로 구성된 완전 미분 가능한 샘플자 없는 확장 가능 방법이다. 하나는 모든 과제에 걸쳐 사용할 수 있는 공통 특징을 학습하고, 다른 하나는 공유된 특징을 결합하여 개별 샘플에 고유한 구별 특성을 학습한다. 두 메모리는 미분 가능하여 네트워크가 각 샘플에 대한 잠재적 표현을 자율적으로 학습할 수 있다.

Result: CIFAR-10, CIFAR-100, Tiny-ImageNet에서 실험한 결과, 제안된 방법이 14가지 최첨단 클래스 증분 학습 방법들보다 우수한 성능을 보여주었으며, 최종 정확도는 각각 55.13\%, 37.24\, 30.11\,에 도달하였다.

Conclusion: 효과적인 지식 통합 및 활용을 통해 제안된 방법은 순차적 과제에서 평균 성능을 높일 수 있으며, 상한에 가장 가까운 특징 추출 결과를 생성하여 연속 학습의 새로운 이정표를 설정한다.

Abstract: Continual learning methods used to force neural networks to process sequential tasks in isolation, preventing them from leveraging useful inter-task relationships and causing them to repeatedly relearn similar features or overly differentiate them. To address this problem, we propose a fully differentiable, exemplar-free expandable method composed of two complementary memories: One learns common features that can be used across all tasks, and the other combines the shared features to learn discriminative characteristics unique to each sample. Both memories are differentiable so that the network can autonomously learn latent representations for each sample. For each task, the memory adjustment module adaptively prunes critical slots and minimally expands capacity to accommodate new concepts, and orthogonal regularization enforces geometric separation between preserved and newly learned memory components to prevent interference. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that the proposed method outperforms 14 state-of-the-art methods for class-incremental learning, achieving final accuracies of 55.13\%, 37.24\%, and 30.11\%, respectively. Additional analysis confirms that, through effective integration and utilization of knowledge, the proposed method can increase average performance across sequential tasks, and it produces feature extraction results closest to the upper bound, thus establishing a new milestone in continual learning.

</details>


### [25] [EEGAgent: A Unified Framework for Automated EEG Analysis Using Large Language Models](https://arxiv.org/abs/2511.09947)
*Sha Zhao,Mingyi Peng,Haiteng Jiang,Tao Li,Shijian Li,Gang Pan*

Main category: cs.LG

TL;DR: EEGAgent는 대규모 언어 모델을 활용하여 다중 도구를 계획하고 EEG 관련 작업을 자동으로 수행하는 일반적인 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 뇌 활동의 확장 가능하고 일반화 가능한 분석은 임상 진단 및 인지 연구를 발전시키는 데 필수적입니다.

Method: EEGAgent는 다양한 도구로 구성된 툴박스를 설계하여 EEG의 기초 정보 인식, 시공간 탐색, 이벤트 감지, 사용자와의 상호작용 및 보고서 생성을 수행합니다.

Result: 공공 데이터셋에서 평가한 결과, EEGAgent는 유연하고 해석 가능한 EEG 분석을 지원할 수 있습니다.

Conclusion: EEGAgent는 실제 임상 응용 프로그램에 대한 잠재력을 강조합니다.

Abstract: Scalable and generalizable analysis of brain activity is essential for advancing both clinical diagnostics and cognitive research. Electroencephalography (EEG), a non-invasive modality with high temporal resolution, has been widely used for brain states analysis. However, most existing EEG models are usually tailored for individual specific tasks, limiting their utility in realistic scenarios where EEG analysis often involves multi-task and continuous reasoning. In this work, we introduce EEGAgent, a general-purpose framework that leverages large language models (LLMs) to schedule and plan multiple tools to automatically complete EEG-related tasks. EEGAgent is capable of performing the key functions: EEG basic information perception, spatiotemporal EEG exploration, EEG event detection, interaction with users, and EEG report generation. To realize these capabilities, we design a toolbox composed of different tools for EEG preprocessing, feature extraction, event detection, etc. These capabilities were evaluated on public datasets, and our EEGAgent can support flexible and interpretable EEG analysis, highlighting its potential for real-world clinical applications.

</details>


### [26] [Rediscovering the Lunar Equation of the Centre with AI Feynman via Embedded Physical Biases](https://arxiv.org/abs/2511.09979)
*Saumya Shah,Zi-Yu Khoo,Abel Yang,Stéphane Bressan*

Main category: cs.LG

TL;DR: 물리학에 영감을 받은 AI 파인만 기호 회귀 알고리즘을 사용하여 천문학의 기본 방정식을 자동으로 재발견하는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 천문학에서의 기본 방정식인 중심 방정식을 자동으로 재발견하고자 함.

Method: AI Feynman 기호 회귀 알고리즘을 사용하였으며, 관측 및 귀납적 편향을 도입하고 데이터 전처리 및 탐색 공간 제한을 통해 진공적인 접근 방식을 구현하였음.

Result: AI Feynman은 월면 데이터로부터 이 방정식의 일차 해석 형태를 회복하는 데 성공하였지만, 전문가 driven координат 시스템 선택에 대한 의존성으로 인해 한계를 드러냈음.

Conclusion: 목표 도메인 지식의 임베딩이 기호 회귀를 통해 물리 법칙을 재발견할 수 있도록 하지만, 맞춤형 편향을 통해 도메인 지식을 활용할 때 물리 방정식을 도출하는 데 있어 추가적인 도전과제가 있음을 강조한다.

Abstract: This work explores using the physics-inspired AI Feynman symbolic regression algorithm to automatically rediscover a fundamental equation in astronomy -- the Equation of the Centre. Through the introduction of observational and inductive biases corresponding to the physical nature of the system through data preprocessing and search space restriction, AI Feynman was successful in recovering the first-order analytical form of this equation from lunar ephemerides data. However, this manual approach highlights a key limitation in its reliance on expert-driven coordinate system selection. We therefore propose an automated preprocessing extension to find the canonical coordinate system. Results demonstrate that targeted domain knowledge embedding enables symbolic regression to rediscover physical laws, but also highlight further challenges in constraining symbolic regression to derive physics equations when leveraging domain knowledge through tailored biases.

</details>


### [27] [Towards Robust Multimodal Learning in the Open World](https://arxiv.org/abs/2511.09989)
*Fushuo Huo*

Main category: cs.LG

TL;DR: 기계 학습의 빠른 발전은 신경망을 다양한 분야에서 성공으로 이끌었다. 특히 다중 모드 학습은 이질적인 데이터 스트림의 보완적인 정보를 활용하여 맥락적 추론과 지능적 의사 결정을 발전시키는 혁신적인 패러다임으로 등장했다. 그러나 현재의 신경망 기반 모델은 불확실성이 내재된 개방형 세계 환경에서 신뢰성이 저하되는 문제에 직면해 있다. 이 연구는 개방형 환경에서 다중 모드 학습의 강건성 문제를 조사하고, 통제된 실험 성과와 실제 배치 요구 사항 간의 격차를 메우는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 다중 모드 학습의 중요성이 커지고 있지만, 현재 모델들은 개방형 환경에서 신뢰성 부족 문제에 직면해 있다.

Method: 다양한 환경에서 다중 모드 신호 처리의 강건성을 개선하기 위한 접근 방식을 제안.

Result: 개방형 세계에서 다중 모드 신호 처리의 성능을 향상시킬 수 있는 가능성을 제시한다.

Conclusion: 다중 모드 학습의 강건성을 높이는 것이 실제 배치 요구 사항을 충족하는 데 필수적이다.

Abstract: The rapid evolution of machine learning has propelled neural networks to unprecedented success across diverse domains. In particular, multimodal learning has emerged as a transformative paradigm, leveraging complementary information from heterogeneous data streams (e.g., text, vision, audio) to advance contextual reasoning and intelligent decision-making. Despite these advancements, current neural network-based models often fall short in open-world environments characterized by inherent unpredictability, where unpredictable environmental composition dynamics, incomplete modality inputs, and spurious distributions relations critically undermine system reliability. While humans naturally adapt to such dynamic, ambiguous scenarios, artificial intelligence systems exhibit stark limitations in robustness, particularly when processing multimodal signals under real-world complexity. This study investigates the fundamental challenge of multimodal learning robustness in open-world settings, aiming to bridge the gap between controlled experimental performance and practical deployment requirements.

</details>


### [28] [DemoTuner: Efficient DBMS Knobs Tuning via LLM-Assisted Demonstration Reinforcement Learning](https://arxiv.org/abs/2511.09998)
*Hui Dou,Lei Jin,Yuxuan Zhou,Jiang He,Yiwen Zhang*

Main category: cs.LG

TL;DR: 본 논문에서는 DBMS 조정 프로세스를 개선하기 위해 LLM 지원 방법을 활용한 DemoTuner 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현대 DBMS의 성능은 성능 중요 조정의 설정에 크게 의존하지만, 수동 조정은 복잡성과 고차원성 때문에 비효율적입니다.

Method: DBMS 사용 설명서와 웹 포럼에서 유용한 조정 힌트를 활용하는 LLM 지원 시연 강화 학습 방법을 제안하며, 조정 힌트 추출 작업을 수행하기 위해 구조적 사고 유도 프롬프트를 설계합니다.

Result: MySQL과 PostgreSQL에 대한 실험 평가 결과, DemoTuner는 DB-BERT, GPTuner 및 CDBTune과 같은 대표적인 세 가지 기준선에 비해 성능 개선과 온라인 조정 비용 절감에서 중요한 이점을 보여줍니다.

Conclusion: DemoTuner는 DBMS 조정에 대한 시연 강화 학습 알고리즘을 도입한 첫 번째 작업으로, 알려지지 않은 워크로드에 대한 우수한 적응성을 보입니다.

Abstract: The performance of modern DBMSs such as MySQL and PostgreSQL heavily depends on the configuration of performance-critical knobs. Manual tuning these knobs is laborious and inefficient due to the complex and high-dimensional nature of the configuration space. Among the automated tuning methods, reinforcement learning (RL)-based methods have recently sought to improve the DBMS knobs tuning process from several different perspectives. However, they still encounter challenges with slow convergence speed during offline training. In this paper, we mainly focus on how to leverage the valuable tuning hints contained in various textual documents such as DBMS manuals and web forums to improve the offline training of RL-based methods. To this end, we propose an efficient DBMS knobs tuning framework named DemoTuner via a novel LLM-assisted demonstration reinforcement learning method. Specifically, to comprehensively and accurately mine tuning hints from documents, we design a structured chain of thought prompt to employ LLMs to conduct a condition-aware tuning hints extraction task. To effectively integrate the mined tuning hints into RL agent training, we propose a hint-aware demonstration reinforcement learning algorithm HA-DDPGfD in DemoTuner. As far as we know, DemoTuner is the first work to introduce the demonstration reinforcement learning algorithm for DBMS knobs tuning. Experimental evaluations conducted on MySQL and PostgreSQL across various workloads demonstrate the significant advantages of DemoTuner in both performance improvement and online tuning cost reduction over three representative baselines including DB-BERT, GPTuner and CDBTune. Additionally, DemoTuner also exhibits superior adaptability to application scenarios with unknown workloads.

</details>


### [29] [Tree-Based Stochastic Optimization for Solving Large-Scale Urban Network Security Games](https://arxiv.org/abs/2511.10072)
*Shuxin Zhuang,Linjian Meng,Shuxin Li,Minming Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: 도시 도로 네트워크에서 안전 자원을 전략적으로 할당하는 Urban Network Security Games(UNSGs)에 대한 연구로, 대규모 게임의 Nash Equilibrium(NE) 발견의 어려움을 다루며, 효율적인 해결책으로 Tree-based Stochastic Optimization(TSO) 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 Urban Network Security Games에서 한정된 보안 자원 할당의 중요성.

Method: 트리 기반의 행동 표현을 활용하여 전체 행동 공간을 트리 구조에 매핑하고 이를 손실 함수에 통합하는 Tree-based Stochastic Optimization(TSO) 프레임워크를 제안.

Result: TSO는 UNSGs를 해결하는 데 있어 다른 기준 알고리즘보다 우수한 성능을 보임.

Conclusion: TSO는 보안 자원 할당의 효율성을 높이기 위한 유망한 접근법이다.

Abstract: Urban Network Security Games (UNSGs), which model the strategic allocation of limited security resources on city road networks, are critical for urban safety. However, finding a Nash Equilibrium (NE) in large-scale UNSGs is challenging due to their massive and combinatorial action spaces. One common approach to addressing these games is the Policy-Space Response Oracle (PSRO) framework, which requires computing best responses (BR) at each iteration. However, precisely computing exact BRs is impractical in large-scale games, and employing reinforcement learning to approximate BRs inevitably introduces errors, which limits the overall effectiveness of the PSRO methods. Recent advancements in leveraging non-convex stochastic optimization to approximate an NE offer a promising alternative to the burdensome BR computation. However, utilizing existing stochastic optimization techniques with an unbiased loss function for UNSGs remains challenging because the action spaces are too vast to be effectively represented by neural networks. To address these issues, we introduce Tree-based Stochastic Optimization (TSO), a framework that bridges the gap between the stochastic optimization paradigm for NE-finding and the demands of UNSGs. Specifically, we employ the tree-based action representation that maps the whole action space onto a tree structure, addressing the challenge faced by neural networks in representing actions when the action space cannot be enumerated. We then incorporate this representation into the loss function and theoretically demonstrate its equivalence to the unbiased loss function. To further enhance the quality of the converged solution, we introduce a sample-and-prune mechanism that reduces the risk of being trapped in suboptimal local optima. Extensive experimental results indicate the superiority of TSO over other baseline algorithms in addressing the UNSGs.

</details>


### [30] [How does My Model Fail? Automatic Identification and Interpretation of Physical Plausibility Failure Modes with Matryoshka Transcoders](https://arxiv.org/abs/2511.10094)
*Yiming Tang,Abhijeet Sinha,Dianbo Liu*

Main category: cs.LG

TL;DR: 새로운 Matryoshka Transcoders 프레임워크를 도입하여 생성 모델의 물리적 신뢰성 특성을 자동으로 발견하고 해석한다.


<details>
  <summary>Details</summary>
Motivation: 생성 모델은 매우 유능하지만 물리적 신뢰성 오류에 취약하며, 이는 기존 평가 방법으로는 발견하기 어렵다.

Method: Matryoshka Transcoders라는 새로운 프레임워크를 통해 생성 모델의 물리적 신뢰성 특성을 자동으로 발견하고 해석하는 방법을 제안한다.

Result: 기존 접근 방식에 비해 물리적 오류 유형을 수동으로 특성 공학 없이도 식별하며, 특성 관련성과 정확성이 우수하다.

Conclusion: 이 발견된 시각적 패턴을 통해 생성 모델의 물리적 신뢰성을 평가하는 기준을 설정하고, 최첨단 생성 모델을 분석하여 물리적 제약을 따르지 않는 방법에 대한 통찰을 제공한다.

Abstract: Although recent generative models are remarkably capable of producing instruction-following and realistic outputs, they remain prone to notable physical plausibility failures. Though critical in applications, these physical plausibility errors often escape detection by existing evaluation methods. Furthermore, no framework exists for automatically identifying and interpreting specific physical error patterns in natural language, preventing targeted model improvements. We introduce Matryoshka Transcoders, a novel framework for the automatic discovery and interpretation of physical plausibility features in generative models. Our approach extends the Matryoshka representation learning paradigm to transcoder architectures, enabling hierarchical sparse feature learning at multiple granularity levels. By training on intermediate representations from a physical plausibility classifier and leveraging large multimodal models for interpretation, our method identifies diverse physics-related failure modes without manual feature engineering, achieving superior feature relevance and feature accuracy compared to existing approaches. We utilize the discovered visual patterns to establish a benchmark for evaluating physical plausibility in generative models. Our analysis of eight state-of-the-art generative models provides valuable insights into how these models fail to follow physical constraints, paving the way for further model improvements.

</details>


### [31] [Improved Offline Reinforcement Learning via Quantum Metric Encoding](https://arxiv.org/abs/2511.10187)
*Outongyi Lv,Yewei Yuan,Nana Liu*

Main category: cs.LG

TL;DR: 양자 메트릭 인코더(QME)를 도입하여 제한된 샘플에 대한 강화 학습(RL) 성능을 개선하는 연구.


<details>
  <summary>Details</summary>
Motivation: 제한된 샘플 하에서 오프라인 RL 성능이 종종 최적이 아님을 고려하여 대안을 모색.

Method: 상태를 양자 회로에서 영감을 받은 더 compact하고 의미있는 표현에 임베딩하여 RL 프레임워크를 적용하는 접근법을 제안.

Result: QME-임베딩 상태와 디코딩된 보상으로 오프라인 RL 에이전트를 훈련했을 때 원래 상태와 보상으로 훈련했을 때보다 성능이 크게 향상됨.

Conclusion: 저조한 $Δ$-하이퍼볼릭 성질은 QME에 의해 유도된 상태 공간의 수정된 기하학에서 개선이 온다는 것을 시사하며, 이는 제한된 샘플 조건에서 효율적인 오프라인 RL 방법 개발에 유용할 수 있음.

Abstract: Reinforcement learning (RL) with limited samples is common in real-world applications. However, offline RL performance under this constraint is often suboptimal. We consider an alternative approach to dealing with limited samples by introducing the Quantum Metric Encoder (QME). In this methodology, instead of applying the RL framework directly on the original states and rewards, we embed the states into a more compact and meaningful representation, where the structure of the encoding is inspired by quantum circuits. For classical data, QME is a classically simulable, trainable unitary embedding and thus serves as a quantum-inspired module, on a classical device. For quantum data in the form of quantum states, QME can be implemented directly on quantum hardware, allowing for training without measurement or re-encoding.
  We evaluated QME on three datasets, each limited to 100 samples. We use Soft-Actor-Critic (SAC) and Implicit-Q-Learning (IQL), two well-known RL algorithms, to demonstrate the effectiveness of our approach. From the experimental results, we find that training offline RL agents on QME-embedded states with decoded rewards yields significantly better performance than training on the original states and rewards. On average across the three datasets, for maximum reward performance, we achieve a 116.2% improvement for SAC and 117.6% for IQL.
  We further investigate the $Δ$-hyperbolicity of our framework, a geometric property of the state space known to be important for the RL training efficacy. The QME-embedded states exhibit low $Δ$-hyperbolicity, suggesting that the improvement after embedding arises from the modified geometry of the state space induced by QME. Thus, the low $Δ$-hyperbolicity and the corresponding effectiveness of QME could provide valuable information for developing efficient offline RL methods under limited-sample conditions.

</details>


### [32] [Towards Leveraging Sequential Structure in Animal Vocalizations](https://arxiv.org/abs/2511.10190)
*Eklavya Sarkar,Mathew Magimai. -Doss*

Main category: cs.LG

TL;DR: 이 논문은 동물의 목소리에서 중요한 의사소통 정보를 전달하는 순차적 구조를 활용하는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 컴퓨테이셔널 생물음향학 연구는 추출된 프레임 단위 특징을 시간 축에 걸쳐 평균화하여 음성의 하위 단위 순서를 버린다.

Method: 추출된 자기 감독 음성 모델 표현의 벡터 양자화와 검볼 소프트맥스 벡터 양자화를 통해 파생된 이산 음향 토큰 시퀀스의 쌍별 거리 분석을 수행한다.

Result: HuBERT 임베딩에서 생성된 토큰 시퀀스는 네 개의 생물음향 데이터 세트에서 호출 유형과 호출자를 구별할 수 있다.

Conclusion: 벡터 양자화된 토큰 시퀀스는 합리적인 호출 유형 및 호출자 분류 성능을 나타내며, 동물 음성의 순차적 정보를 활용하는 대안적 특징 표현으로서 가능성을 지니고 있다.

Abstract: Animal vocalizations contain sequential structures that carry important communicative information, yet most computational bioacoustics studies average the extracted frame-level features across the temporal axis, discarding the order of the sub-units within a vocalization. This paper investigates whether discrete acoustic token sequences, derived through vector quantization and gumbel-softmax vector quantization of extracted self-supervised speech model representations can effectively capture and leverage temporal information. To that end, pairwise distance analysis of token sequences generated from HuBERT embeddings shows that they can discriminate call-types and callers across four bioacoustics datasets. Sequence classification experiments using $k$-Nearest Neighbour with Levenshtein distance show that the vector-quantized token sequences yield reasonable call-type and caller classification performances, and hold promise as alternative feature representations towards leveraging sequential information in animal vocalizations.

</details>


### [33] [Heuristic Transformer: Belief Augmented In-Context Reinforcement Learning](https://arxiv.org/abs/2511.10251)
*Oliver Dippel,Alexei Lisitsa,Bei Peng*

Main category: cs.LG

TL;DR: Heuristic Transformer (HT)는 강화 학습에서 의사결정 개선을 위해 보상에 대한 신념 분포를 활용하는 새로운 접근법을 제시하며, 여러 환경에서 기존 방법보다 우수한 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습의 새로운 접근법으로써, ICL을 통해 학습을 감독된 문제로 재구성하고 파라미터 업데이트 없이 작업 적응을 가능하게 한다.

Method: Heuristic Transformer (HT)는 보상에 대한 신념 분포로 in-context 데이터셋을 증강하는 ICRL 접근법을 사용한다. 변분 오토인코더(VAE)를 통해 보상의 사후 분포를 나타내는 저차원 확률 변수를 학습한다.

Result: HT는 Darkroom, Miniworld 및 MuJoCo 환경에서 평가되었으며, 효과성 및 일반화 측면에서 비교 가능한 기준보다 일관되게 우 surpass한다.

Conclusion: 이 방법은 신념 기반 Augmentation과 변환기 기반 의사결정 간의 격차를 해소할 수 있는 유망한 방향을 제시한다.

Abstract: Transformers have demonstrated exceptional in-context learning (ICL) capabilities, enabling applications across natural language processing, computer vision, and sequential decision-making. In reinforcement learning, ICL reframes learning as a supervised problem, facilitating task adaptation without parameter updates. Building on prior work leveraging transformers for sequential decision-making, we propose Heuristic Transformer (HT), an in-context reinforcement learning (ICRL) approach that augments the in-context dataset with a belief distribution over rewards to achieve better decision-making. Using a variational auto-encoder (VAE), a low-dimensional stochastic variable is learned to represent the posterior distribution over rewards, which is incorporated alongside an in-context dataset and query states as prompt to the transformer policy. We assess the performance of HT across the Darkroom, Miniworld, and MuJoCo environments, showing that it consistently surpasses comparable baselines in terms of both effectiveness and generalization. Our method presents a promising direction to bridge the gap between belief-based augmentations and transformer-based decision-making.

</details>


### [34] [AgentEvolver: Towards Efficient Self-Evolving Agent System](https://arxiv.org/abs/2511.10395)
*Yunpeng Zhai,Shuchang Tao,Cheng Chen,Anni Zou,Ziqian Chen,Qingxu Fu,Shinji Mai,Li Yu,Jiaji Deng,Zouying Cao,Zhaoyang Liu,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: AgentEvolver는 대형 언어 모델을 활용하여 자율 에이전트의 학습을 향상시키는 자기 진화 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 현재의 자율 에이전트 개발 접근 방식은 비용이 많이 들고 비효율적이다.

Method: AgentEvolver는 자기 질문, 자기 탐색, 자기 귀속의 세 가지 메커니즘을 도입하여 에이전트의 학습을 촉진한다.

Result: AgentEvolver는 전통적인 RL 기반 기준에 비해 더 효율적인 탐색, 더 나은 샘플 활용, 더 빠른 적응을 달성한다.

Conclusion: AgentEvolver는 에이전트 능력을 확장 가능하고 비용 효율적이며 지속적으로 개선할 수 있게 해준다.

Abstract: Autonomous agents powered by large language models (LLMs) have the potential to significantly enhance human productivity by reasoning, using tools, and executing complex tasks in diverse environments. However, current approaches to developing such agents remain costly and inefficient, as they typically require manually constructed task datasets and reinforcement learning (RL) pipelines with extensive random exploration. These limitations lead to prohibitively high data-construction costs, low exploration efficiency, and poor sample utilization. To address these challenges, we present AgentEvolver, a self-evolving agent system that leverages the semantic understanding and reasoning capabilities of LLMs to drive autonomous agent learning. AgentEvolver introduces three synergistic mechanisms: (i) self-questioning, which enables curiosity-driven task generation in novel environments, reducing dependence on handcrafted datasets; (ii) self-navigating, which improves exploration efficiency through experience reuse and hybrid policy guidance; and (iii) self-attributing, which enhances sample efficiency by assigning differentiated rewards to trajectory states and actions based on their contribution. By integrating these mechanisms into a unified framework, AgentEvolver enables scalable, cost-effective, and continual improvement of agent capabilities. Preliminary experiments indicate that AgentEvolver achieves more efficient exploration, better sample utilization, and faster adaptation compared to traditional RL-based baselines.

</details>


### [35] [Unitho: A Unified Multi-Task Framework for Computational Lithography](https://arxiv.org/abs/2511.10255)
*Qian Jin,Yumeng Liu,Yuqi Jiang,Qi Sun,Cheng Zhuo*

Main category: cs.LG

TL;DR: Unitho는 Transformer 아키텍처를 기반으로 하는 통합 다중 작업 대형 비전 모델로, 컴퓨터 리소그래피의 핵심 작업들을 지원하여 강력한 데이터 기반 구축을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 모델을 위한 신뢰할 수 있고 일반화 가능한 데이터 기반의 필요성이 크지만, 마스크 생성, 규칙 위반 탐지, 레이아웃 최적화와 같은 필수 작업들이 종종 분리되어 처리된다.

Method: Unitho는 수십만 케이스로 구성된 대규모 산업 리소그래피 시뮬레이션 데이터셋에서 학습된 통합 다중 작업 대형 비전 모델이다.

Result: Unitho는 엔드 투 엔드 마스크 생성, 리소그래피 시뮬레이션 및 규칙 위반 탐지를 지원하며, 실험 결과는 그것의 효과성과 일반화 가능성을 검증하고 있다.

Conclusion: Unitho는 높은 충실도 리소그래피 시뮬레이션을 가능하게 하여 지능형 EDA를 위한 강력한 데이터 기반 구축을 촉진한다.

Abstract: Reliable, generalizable data foundations are critical for enabling large-scale models in computational lithography. However, essential tasks-mask generation, rule violation detection, and layout optimization-are often handled in isolation, hindered by scarce datasets and limited modeling approaches. To address these challenges, we introduce Unitho, a unified multi-task large vision model built upon the Transformer architecture. Trained on a large-scale industrial lithography simulation dataset with hundreds of thousands of cases, Unitho supports end-to-end mask generation, lithography simulation, and rule violation detection. By enabling agile and high-fidelity lithography simulation, Unitho further facilitates the construction of robust data foundations for intelligent EDA. Experimental results validate its effectiveness and generalizability, with performance substantially surpassing academic baselines.

</details>


### [36] [OutSafe-Bench: A Benchmark for Multimodal Offensive Content Detection in Large Language Models](https://arxiv.org/abs/2511.10287)
*Yuping Yan,Yuhan Xie,Yuanshuai Li,Yingchao Yu,Lingjuan Lyu,Yaochu Jin*

Main category: cs.LG

TL;DR: MLLM들에 대한 안전성과 관련된 우려가 증가함에 따라 OutSafe-Bench라는 포괄적인 콘텐츠 안전 평가 테스트 스위트를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: MLLM들이 일상 도구 및 지능형 에이전트에 통합됨에 따라 안전하지 않은 콘텐츠 출력에 대한 우려가 커지고 있습니다.

Method: OutSafe-Bench는 4개의 양식에 걸쳐 18,000개의 이중 언어 텍스트 프롬프트, 4,500개의 이미지, 450개의 오디오 클립 및 450개의 비디오를 포함한 대규모 데이터셋과 다양한 콘텐츠 위험을 모델링하고 평가하기 위한 새로운 메트릭 MCRS를 소개합니다.

Result: 아홉 개의 최신 MLLM 평가에서 지속적이고 상당한 안전 취약점이 발견되었습니다.

Conclusion: MLLM에 대한 강력한 안전 장치의 필요성이 강조됩니다.

Abstract: Since Multimodal Large Language Models (MLLMs) are increasingly being integrated into everyday tools and intelligent agents, growing concerns have arisen regarding their possible output of unsafe contents, ranging from toxic language and biased imagery to privacy violations and harmful misinformation. Current safety benchmarks remain highly limited in both modality coverage and performance evaluations, often neglecting the extensive landscape of content safety. In this work, we introduce OutSafe-Bench, the first most comprehensive content safety evaluation test suite designed for the multimodal era. OutSafe-Bench includes a large-scale dataset that spans four modalities, featuring over 18,000 bilingual (Chinese and English) text prompts, 4,500 images, 450 audio clips and 450 videos, all systematically annotated across nine critical content risk categories. In addition to the dataset, we introduce a Multidimensional Cross Risk Score (MCRS), a novel metric designed to model and assess overlapping and correlated content risks across different categories. To ensure fair and robust evaluation, we propose FairScore, an explainable automated multi-reviewer weighted aggregation framework. FairScore selects top-performing models as adaptive juries, thereby mitigating biases from single-model judgments and enhancing overall evaluation reliability. Our evaluation of nine state-of-the-art MLLMs reveals persistent and substantial safety vulnerabilities, underscoring the pressing need for robust safeguards in MLLMs.

</details>


### [37] [Robust Decentralized Multi-armed Bandits: From Corruption-Resilience to Byzantine-Resilience](https://arxiv.org/abs/2511.10344)
*Zicheng Hu,Yuchen Wang,Cheng Chen*

Main category: cs.LG

TL;DR: DeCMA2B는 분산된 다중 에이전트 환경에서 협력하는 문제를 다루며, 이 논문에서는 적대적 공격에 대한 강인한 알고리즘 DeMABAR를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 환경에서의 분산 협력 문제와 기존 방법의 적대적 공격에 대한 취약성.

Method: 적대적 부패 상황을 고려한 DeCMA2B를 연구하고 DeMABAR 알고리즘을 제안.

Result: DeMABAR 알고리즘은 개별 에이전트의 후회가 부패 예산에 비례한 추가 항만 영향을 받도록 보장하며, 적대적 공격의 영향을 거의 완전히 제거할 수 있다.

Conclusion: 제안된 방법의 강인성과 효과를 수치 실험을 통해 입증하였다.

Abstract: Decentralized cooperative multi-agent multi-armed bandits (DeCMA2B) considers how multiple agents collaborate in a decentralized multi-armed bandit setting. Though this problem has been extensively studied in previous work, most existing methods remain susceptible to various adversarial attacks. In this paper, we first study DeCMA2B with adversarial corruption, where an adversary can corrupt reward observations of all agents with a limited corruption budget. We propose a robust algorithm, called DeMABAR, which ensures that each agent's individual regret suffers only an additive term proportional to the corruption budget. Then we consider a more realistic scenario where the adversary can only attack a small number of agents. Our theoretical analysis shows that the DeMABAR algorithm can also almost completely eliminate the influence of adversarial attacks and is inherently robust in the Byzantine setting, where an unknown fraction of the agents can be Byzantine, i.e., may arbitrarily select arms and communicate wrong information. We also conduct numerical experiments to illustrate the robustness and effectiveness of the proposed method.

</details>


### [38] [Oya: Deep Learning for Accurate Global Precipitation Estimation](https://arxiv.org/abs/2511.10562)
*Emmanuel Asiedu Brempong,Mohammed Alewi Hassen,MohamedElfatih MohamedKhair,Vusumuzi Dube,Santiago Hincapie Potes,Olivia Graham,Amanie Brik,Amy McGovern,George Huffman,Jason Hickey*

Main category: cs.LG

TL;DR: 이 연구에서는 새로운 실시간 강수 추정 알고리즘 Oya를 소개하며, 여러 지구 정지 위성의 가시광선 및 적외선 관측을 활용하여 더욱 정밀한 강수량 예측을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 정확한 강수 추정은 수문학적 응용에 필수적이며, 특히 지구 남반구에서는 지상 관측망이 부족하고 예보 기술이 제한적이다.

Method: Oya는 기상위성 관측의 전 스펙트럼을 활용하여 실시간 강수량 추정 알고리즘을 제공하며, 두 개의 U-Net 모델을 사용한 두 단계의 딥 러닝 접근 방식을 적용한다.

Result: Oya는 기존의 지역 및 글로벌 강수 데이터에 비해 뛰어난 성능을 보여주며, 거의 전 세계에 걸쳐 강수 모니터링과 예측을 개선할 수 있는 길을 제시한다.

Conclusion: Oya는 강수 사건과 비강수 사건 간의 본질적인 데이터 불균형을 해결하고, 제한된 시간 샘플링으로 인한 과적합을 완화하는 데 기여한다.

Abstract: Accurate precipitation estimation is critical for hydrological applications, especially in the Global South where ground-based observation networks are sparse and forecasting skill is limited. Existing satellite-based precipitation products often rely on the longwave infrared channel alone or are calibrated with data that can introduce significant errors, particularly at sub-daily timescales. This study introduces Oya, a novel real-time precipitation retrieval algorithm utilizing the full spectrum of visible and infrared (VIS-IR) observations from geostationary (GEO) satellites. Oya employs a two-stage deep learning approach, combining two U-Net models: one for precipitation detection and another for quantitative precipitation estimation (QPE), to address the inherent data imbalance between rain and no-rain events. The models are trained using high-resolution GPM Combined Radar-Radiometer Algorithm (CORRA) v07 data as ground truth and pre-trained on IMERG-Final retrievals to enhance robustness and mitigate overfitting due to the limited temporal sampling of CORRA. By leveraging multiple GEO satellites, Oya achieves quasi-global coverage and demonstrates superior performance compared to existing competitive regional and global precipitation baselines, offering a promising pathway to improved precipitation monitoring and forecasting.

</details>


### [39] [Pretrained Joint Predictions for Scalable Batch Bayesian Optimization of Molecular Designs](https://arxiv.org/abs/2511.10590)
*Miles Wang-Henderson,Ben Kaufman,Edward Williams,Ryan Pederson,Matteo Rossi,Owen Howell,Carl Underkoffler,Narbe Mardirossian,John Parkhill*

Main category: cs.LG

TL;DR: 이 논문은 약물 개발의 주요 병목 현상인 분자 설계의 배치 합성과 테스트를 가속화하기 위해 생체 분자 기초 모델을 활용하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 약물 개발에서 분자 설계의 배치 합성과 테스트가 주요 병목 현상입니다.

Method: 이 연구에서는 Batch Bayesian Optimization(Batch BO)에 사용할 수 있는 결합 친화성의 확장 가능한 확률적 대리 모델을 얻는 방법을 보여줍니다.

Result: Prior 네트워크의 중요성을 조사하고 합성 데이터로 미리 훈련시켜 Batch BO에서 성능을 향상시키는 방법을 제시하며, 이를 통해 널리 알려진 EGFR 억제제를 재발견하고 실세계 소분자 라이브러리에서 강력한 억제제를 더 적은 반복 수로 탐색하는 성과를 보였습니다.

Conclusion: 이 연구는 대규모 약물 발견 응용 프로그램을 위한 유망한 솔루션을 제공합니다.

Abstract: Batched synthesis and testing of molecular designs is the key bottleneck of drug development. There has been great interest in leveraging biomolecular foundation models as surrogates to accelerate this process. In this work, we show how to obtain scalable probabilistic surrogates of binding affinity for use in Batch Bayesian Optimization (Batch BO). This demands parallel acquisition functions that hedge between designs and the ability to rapidly sample from a joint predictive density to approximate them. Through the framework of Epistemic Neural Networks (ENNs), we obtain scalable joint predictive distributions of binding affinity on top of representations taken from large structure-informed models. Key to this work is an investigation into the importance of prior networks in ENNs and how to pretrain them on synthetic data to improve downstream performance in Batch BO. Their utility is demonstrated by rediscovering known potent EGFR inhibitors on a semi-synthetic benchmark in up to 5x fewer iterations, as well as potent inhibitors from a real-world small-molecule library in up to 10x fewer iterations, offering a promising solution for large-scale drug discovery applications.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [40] [Multi-agent In-context Coordination via Decentralized Memory Retrieval](https://arxiv.org/abs/2511.10030)
*Tao Jiang,Zichuan Lin,Lihe Li,Yi-Chen Li,Cong Guan,Lei Yuan,Zongzhang Zhang,Yang Yu,Deheng Ye*

Main category: cs.MA

TL;DR: 본 연구는 다수의 에이전트가 협력하여 목표를 조정할 수 있도록 하는 새로운 방법인 MAICC를 제안하며, 이는 빠른 적응력을 통해 비전통적인 작업에 대한 효율성을 강화합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 트랜스포머 모델이 다양한 데이터셋에서 훈련되어 이전에 보지 못한 작업에서 인상적인 적은 샷 성능을 보여주는 것을 바탕으로, MARL에서 협력적 목표를 가진 에이전트들이 최적의 정책을 찾아야 하는 필요성이 큽니다.

Method: 중앙 집중형 임베딩 모델을 사용하여 세부적인 동적 궤적 표현을 포착하고, 이를 근거로 탈중앙화 모델이 팀 수준의 작업 정보를 얻도록 훈련합니다. 에이전트들의 현재 서브 궤적과 결합하여 결정-making을 지원하는 맥락 정보를 평가합니다.

Result: MAICC는 LBF 및 SMAC 벤치마크에서 기존 방법과 비교하여 보지 못한 작업에 더 빠르게 적응하는 성능을 입증하였습니다.

Conclusion: MAICC는 협력적 MARL 환경에서 효율적인 정책 적응이 가능하도록 하여 에이전트 간의 신뢰 할당을 보장합니다.

Abstract: Large transformer models, trained on diverse datasets, have demonstrated impressive few-shot performance on previously unseen tasks without requiring parameter updates. This capability has also been explored in Reinforcement Learning (RL), where agents interact with the environment to retrieve context and maximize cumulative rewards, showcasing strong adaptability in complex settings. However, in cooperative Multi-Agent Reinforcement Learning (MARL), where agents must coordinate toward a shared goal, decentralized policy deployment can lead to mismatches in task alignment and reward assignment, limiting the efficiency of policy adaptation. To address this challenge, we introduce Multi-agent In-context Coordination via Decentralized Memory Retrieval (MAICC), a novel approach designed to enhance coordination by fast adaptation. Our method involves training a centralized embedding model to capture fine-grained trajectory representations, followed by decentralized models that approximate the centralized one to obtain team-level task information. Based on the learned embeddings, relevant trajectories are retrieved as context, which, combined with the agents' current sub-trajectories, inform decision-making. During decentralized execution, we introduce a novel memory mechanism that effectively balances test-time online data with offline memory. Based on the constructed memory, we propose a hybrid utility score that incorporates both individual- and team-level returns, ensuring credit assignment across agents. Extensive experiments on cooperative MARL benchmarks, including Level-Based Foraging (LBF) and SMAC (v1/v2), show that MAICC enables faster adaptation to unseen tasks compared to existing methods. Code is available at https://github.com/LAMDA-RL/MAICC.

</details>


### [41] [Behavior Modeling for Training-free Building of Private Domain Multi Agent System](https://arxiv.org/abs/2511.10283)
*Won Ik Cho,Woonghee Han,Kyung Seo Ki,Young Min Kim*

Main category: cs.MA

TL;DR: 대형 언어 모델(LLM)의 출현으로 오케스트레이션, 도구 사용 및 대화 능력을 결합한 에이전트 시스템의 발전이 더욱 뚜렷해졌다. 그러나 개인 도메인에 이를 적용하는 것은 다양한 도구 형식, 도메인 특유의 전문 용어, API 접근 제한 및 복잡한 거버넌스 등으로 인해 여전히 어렵다. 이러한 문제를 해결하기 위해, 우리는 훈련과 데이터 생성을 피하는 비헤비어 모델링과 문서화를 채택한 개인 도메인 다중 에이전트 대화 시스템 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 시스템을 개인 도메인에 적용할 때의 어려움을 해결하기 위해.

Method: 비헤비어 모델링과 문서화를 채택하여 훈련과 데이터 생성을 피하는 다중 에이전트 대화 시스템 프레임워크를 제안한다.

Result: 보편적인 도구 통합을 통해 개인 도구 및 진화하는 맥락에 대한 확장 가능한 적응을 가능하게 한다.

Conclusion: 도메인 전문성과 에이전트 행동을 정렬하는 지속 가능한 방법을 제공한다.

Abstract: The rise of agentic systems that combine orchestration, tool use, and conversational capabilities, has been more visible by the recent advent of large language models (LLMs). While open-domain frameworks exist, applying them in private domains remains difficult due to heterogeneous tool formats, domain-specific jargon, restricted accessibility of APIs, and complex governance. Conventional solutions, such as fine-tuning on synthetic dialogue data, are burdensome and brittle under domain shifts, and risk degrading general performance. In this light, we introduce a framework for private-domain multi-agent conversational systems that avoids training and data generation by adopting behavior modeling and documentation. Our design simply assumes an orchestrator, a tool-calling agent, and a general chat agent, with tool integration defined through structured specifications and domain-informed instructions. This approach enables scalable adaptation to private tools and evolving contexts without continual retraining. The framework supports practical use cases, including lightweight deployment of multi-agent systems, leveraging API specifications as retrieval resources, and generating synthetic dialogue for evaluation -- providing a sustainable method for aligning agent behavior with domain expertise in private conversational ecosystems.

</details>


### [42] [Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance](https://arxiv.org/abs/2511.10400)
*Lifan Zheng,Jiawei Chen,Qinghong Yin,Jingyuan Zhang,Xinyi Zeng,Yu Tian*

Main category: cs.MA

TL;DR: 이 연구는 다중 에이전트 시스템에서 LLM 기반 에이전트의 신뢰성을 조사하고 CP-WBFT라는 새로운 합의 메커니즘을 개발하여 시스템의 안정성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 LLM 기반 에이전트 활용이 신뢰성에 미치는 영향을 탐구하고자 합니다.

Method: 비잔틴 장애 허용 관점에서 LLM 기반 에이전트의 신뢰성을 정량화하고 CP-WBFT라는 새로운 신뢰성 향상 메커니즘을 설계했습니다.

Result: CP-WBFT는 다양한 네트워크 토폴로지에서 뛰어난 성능을 보여주었으며, 특히 비잔틴 상황에서 높은 정확도를 달성했습니다.

Conclusion: 이 연구는 LLM 기반 에이전트를 사용한 다중 에이전트 시스템의 신뢰성을 개선하는 새로운 접근법을 제시합니다.

Abstract: Ensuring the reliability of agent architectures and effectively identifying problematic agents when failures occur are crucial challenges in multi-agent systems (MAS). Advances in large language models (LLMs) have established LLM-based agents as a major branch of MAS, enabling major breakthroughs in complex problem solving and world modeling. However, the reliability implications of this shift remain largely unexplored. i.e., whether substituting traditional agents with LLM-based agents can effectively enhance the reliability of MAS. In this work, we investigate and quantify the reliability of LLM-based agents from the perspective of Byzantine fault tolerance. We observe that LLM-based agents demonstrate stronger skepticism when processing erroneous message flows, a characteristic that enables them to outperform traditional agents across different topological structures. Motivated by the results of the pilot experiment, we design CP-WBFT, a confidence probe-based weighted Byzantine Fault Tolerant consensus mechanism to enhance the stability of MAS with different topologies. It capitalizes on the intrinsic reflective and discriminative capabilities of LLMs by employing a probe-based, weighted information flow transmission method to improve the reliability of LLM-based agents. Extensive experiments demonstrate that CP-WBFT achieves superior performance across diverse network topologies under extreme Byzantine conditions (85.7\% fault rate). Notably, our approach surpasses traditional methods by attaining remarkable accuracy on various topologies and maintaining strong reliability in both mathematical reasoning and safety assessment tasks.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [43] [Cooperative Local Differential Privacy: Securing Time Series Data in Distributed Environments](https://arxiv.org/abs/2511.09696)
*Bikash Chandra Singh,Md Jakir Hossain,Rafael Diaz,Sandip Roy,Ravi Mukkamala,Sachin Shetty*

Main category: cs.CR

TL;DR: 스마트 기기에서 발생하는 시간 시리즈 데이터의 개인정보 보호 문제를 해결하기 위한 새로운 협력적 로컬 차분 프라이버시 메커니즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 스마트 장치의 급속한 성장으로 인해 연속적인 시간 시리즈 데이터가 폭발적으로 증가하고 있으며, 이는 건강 관리 및 교통 등 여러 분야에서 귀중한 통찰력을 제공합니다.

Method: 협력적 로컬 차분 프라이버시(CLDP) 메커니즘을 도입하여 여러 사용자 간에 노이즈 벡터를 분산시킵니다.

Result: 모든 사용자의 변형된 데이터를 집계할 때 노이즈가 상쇄되어 전체 통계적 속성을 보존하면서 개별 프라이버시를 보호합니다.

Conclusion: CLDP 전략은 시간 창 기반 방법의 취약점을 무력화하고 대규모 실시간 데이터셋에 효과적으로 확장되어 데이터 유용성과 개인정보 보호 간의 균형을 더 잘 이룹니다.

Abstract: The rapid growth of smart devices such as phones, wearables, IoT sensors, and connected vehicles has led to an explosion of continuous time series data that offers valuable insights in healthcare, transportation, and more. However, this surge raises significant privacy concerns, as sensitive patterns can reveal personal details. While traditional differential privacy (DP) relies on trusted servers, local differential privacy (LDP) enables users to perturb their own data. However, traditional LDP methods perturb time series data by adding user-specific noise but exhibit vulnerabilities. For instance, noise applied within fixed time windows can be canceled during aggregation (e.g., averaging), enabling adversaries to infer individual statistics over time, thereby eroding privacy guarantees.
  To address these issues, we introduce a Cooperative Local Differential Privacy (CLDP) mechanism that enhances privacy by distributing noise vectors across multiple users. In our approach, noise is collaboratively generated and assigned so that when all users' perturbed data is aggregated, the noise cancels out preserving overall statistical properties while protecting individual privacy. This cooperative strategy not only counters vulnerabilities inherent in time-window-based methods but also scales effectively for large, real-time datasets, striking a better balance between data utility and privacy in multiuser environments.

</details>


### [44] [DP-GENG : Differentially Private Dataset Distillation Guided by DP-Generated Data](https://arxiv.org/abs/2511.09876)
*Shuo Shi,Jinghuai Zhang,Shijie Jiang,Chunyi Zhou,Yuyuan Li,Mengying Zhu,Yangyang Wu,Tianyu Du*

Main category: cs.CR

TL;DR: 이 논문은 데이터 세트 증류에서 개인 정보를 보호하기 위한 새로운 프레임워크를 도입합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 데이터 세트 증류 방법이 개인 정보를 유출할 위험이 존재하고, 개인 정보 보호를 보장하는 방법이 필요하다.

Method: 이 논문은 DP 생성 데이터로 증류된 데이터 세트를 초기화하고, DP 기능 매칭 기술을 개선하여 작은 개인 정보 예산 하에서 원래 데이터 세트를 증류합니다.

Result: 제안된 방법은 기존 DP 데이터 세트 증류 방법보다 데이터 세트 유용성과 공격에 대한 견고성 면에서 성능이 크게 향상되었습니다.

Conclusion: 이 연구는 개인 정보 보호를 위한 데이터 세트 증류의 새로운 패러다임을 확립합니다.

Abstract: Dataset distillation (DD) compresses large datasets into smaller ones while preserving the performance of models trained on them. Although DD is often assumed to enhance data privacy by aggregating over individual examples, recent studies reveal that standard DD can still leak sensitive information from the original dataset due to the lack of formal privacy guarantees. Existing differentially private (DP)-DD methods attempt to mitigate this risk by injecting noise into the distillation process. However, they often fail to fully leverage the original dataset, resulting in degraded realism and utility. This paper introduces \libn, a novel framework that addresses the key limitations of current DP-DD by leveraging DP-generated data. Specifically, \lib initializes the distilled dataset with DP-generated data to enhance realism. Then, generated data refines the DP-feature matching technique to distill the original dataset under a small privacy budget, and trains an expert model to align the distilled examples with their class distribution. Furthermore, we design a privacy budget allocation strategy to determine budget consumption across DP components and provide a theoretical analysis of the overall privacy guarantees. Extensive experiments show that \lib significantly outperforms state-of-the-art DP-DD methods in terms of both dataset utility and robustness against membership inference attacks, establishing a new paradigm for privacy-preserving dataset distillation.

</details>


### [45] [Pk-IOTA: Blockchain empowered Programmable Data Plane to secure OPC UA communications in Industry 4.0](https://arxiv.org/abs/2511.10248)
*Rinieri Lorenzo,Gori Giacomo,Melis Andrea,Girau Roberto,Prandini Marco,Callegati Franco*

Main category: cs.CR

TL;DR: OPC UA 프로토콜은 산업 4.0에서 기계 간 통신을 위한 실질적인 표준이 되었다. 그러나, 인증서 관리의 복잡성으로 인해 안전한 OPC UA 배치를 설정하는 데 여전히 많은 도전 과제가 존재한다. 본 논문에서는 OPC UA 통신을 보호하기 위한 자동화된 솔루션인 Pk-IOTA를 제안하며, 이것은 네트워크 내 인증서 유효성 검사를 위한 프로그래머블 데이터 평면 스위치와 분산 인증서 배포를 위한 IOTA Tangle을 통합하여 구성된다. 평가 결과, Pk-IOTA는 최소한의 오버헤드로 확장 가능하고 위변조 방지 메커니즘을 제공한다.


<details>
  <summary>Details</summary>
Motivation: OPC UA 프로토콜은 산업 4.0에서 기계 간 통신을 위한 중요한 표준이지만, 안전한 배치를 위한 인증서 관리 체계가 복잡하다는 문제와 보안 기능의 일관되지 않은 구현으로 인해 여러 도전 과제가 존재한다.

Method: Pk-IOTA는 프로그래머블 데이터 평면 스위치를 통합하여 인증서 유효성 검사를 자동화하고, IOTA Tangle을 활용하여 인증서 배포를 분산 처리하는 방법을 사용한다.

Result: 실제 산업 시나리오를 모델링한 물리적 테스트베드에서 평가를 수행한 결과, Pk-IOTA는 최소한의 오버헤드로 작동하며, 인증서 관리를 위한 확장 가능하고 위변조 방지 메커니즘을 제공한다.

Conclusion: Pk-IOTA는 OPC UA 통신의 보안을 강화하면서 인증서 관리의 복잡성을 줄일 수 있는 효과적인 솔루션이다.

Abstract: The OPC UA protocol is becoming the de facto standard for Industry 4.0 machine-to-machine communication. It stands out as one of the few industrial protocols that provide robust security features designed to prevent attackers from manipulating and damaging critical infrastructures. However, prior works showed that significant challenges still exists to set up secure OPC UA deployments in practice, mainly caused by the complexity of certificate management in industrial scenarios and the inconsistent implementation of security features across industrial OPC UA devices. In this paper, we present Pk-IOTA, an automated solution designed to secure OPC UA communications by integrating programmable data plane switches for in-network certificate validation and leveraging the IOTA Tangle for decen- tralized certificate distribution. Our evaluation is performed on a physical testbed representing a real-world industrial scenario and shows that Pk-IOTA introduces a minimal overhead while providing a scalable and tamper-proof mechanism for OPC UA certificate management.

</details>


### [46] [GraphFaaS: Serverless GNN Inference for Burst-Resilient, Real-Time Intrusion Detection](https://arxiv.org/abs/2511.10554)
*Lingzhi Wang,Vinod Yegneswaran,Xinyi Shi,Ziyu Li,Ashish Gehani,Yan Chen*

Main category: cs.CR

TL;DR: GraphFaaS는 GNN 기반 침입 탐지를 위한 서버리스 아키텍처로, 유연한 리소스 관리로 낮은 탐지 지연 시간을 보장한다.


<details>
  <summary>Details</summary>
Motivation: 침입 탐지의 두 가지 중요한 요구 사항은 일관된 낮은 탐지 지연 시간 유지와 높은 변동성을 가진 작업 부하 처리이다.

Method: GraphFaaS는 서버리스 컴퓨팅의 유연성을 활용하여 GNN 추론 파이프라인을 동적으로 확장하고, GNN 워크플로우를 서버리스 환경에 병렬화 및 적응시킨다.

Result: GraphFaaS는 평균 탐지 지연 시간을 85% 줄이고 변동 계수(CV)를 64% 낮춘다.

Conclusion: GraphFaaS는 사이버 보안 작업에서 안정적인 침입 탐지와 시기적절한 사건 대응을 위한 안정적인 추론 지연 시간을 제공한다.

Abstract: Provenance-based intrusion detection is an increasingly popular application of graphical machine learning in cybersecurity, where system activities are modeled as provenance graphs to capture causality and correlations among potentially malicious actions. Graph Neural Networks (GNNs) have demonstrated strong performance in this setting. However, traditional statically-provisioned GNN inference architectures fall short in meeting two crucial demands of intrusion detection: (1) maintaining consistently low detection latency, and (2) handling highly irregular and bursty workloads. To holistically address these challenges, we present GraphFaaS, a serverless architecture tailored for GNN-based intrusion detection. GraphFaaS leverages the elasticity and agility of serverless computing to dynamically scale the GNN inference pipeline. We parallelize and adapt GNN workflows to a serverless environment, ensuring that the system can respond in real time to fluctuating workloads. By decoupling compute resources from static provisioning, GraphFaaS delivers stable inference latency, which is critical for dependable intrusion detection and timely incident response in cybersecurity operations. Preliminary evaluation shows GraphFaaS reduces average detection latency by 85% and coefficient of variation (CV) by 64% compared to the baseline.

</details>
