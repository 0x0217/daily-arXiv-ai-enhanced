{"id": "2511.04707", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04707", "abs": "https://arxiv.org/abs/2511.04707", "authors": ["Rishi Rajesh Shah", "Chen Henry Wu", "Shashwat Saxena", "Ziqian Zhong", "Alexander Robey", "Aditi Raghunathan"], "title": "Jailbreaking in the Haystack", "comment": null, "summary": "Recent advances in long-context language models (LMs) have enabled\nmillion-token inputs, expanding their capabilities across complex tasks like\ncomputer-use agents. Yet, the safety implications of these extended contexts\nremain unclear. To bridge this gap, we introduce NINJA (short for\nNeedle-in-haystack jailbreak attack), a method that jailbreaks aligned LMs by\nappending benign, model-generated content to harmful user goals. Critical to\nour method is the observation that the position of harmful goals play an\nimportant role in safety. Experiments on standard safety benchmark, HarmBench,\nshow that NINJA significantly increases attack success rates across\nstate-of-the-art open and proprietary models, including LLaMA, Qwen, Mistral,\nand Gemini. Unlike prior jailbreaking methods, our approach is low-resource,\ntransferable, and less detectable. Moreover, we show that NINJA is\ncompute-optimal -- under a fixed compute budget, increasing context length can\noutperform increasing the number of trials in best-of-N jailbreak. These\nfindings reveal that even benign long contexts -- when crafted with careful\ngoal positioning -- introduce fundamental vulnerabilities in modern LMs."}
{"id": "2511.04925", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04925", "abs": "https://arxiv.org/abs/2511.04925", "authors": ["Rethish Nair Rajendran", "Sathish Krishna Anumula", "Dileep Kumar Rai", "Sachin Agrawal"], "title": "Zero Trust Security Model Implementation in Microservices Architectures Using Identity Federation", "comment": null, "summary": "The microservice bombshells that have been linked with the microservice\nexpansion have altered the application architectures, offered agility and\nscalability in terms of complexity in security trade-offs. Feeble legacy-based\nperimeter-based policies are unable to offer safeguard to distributed workloads\nand temporary interaction among and in between the services. The article itself\nis a case on the need of the Zero Trust Security Model of micro services\necosystem, particularly, the fact that human and workloads require identity\nfederation. It is proposed that the solution framework will be based on\nindustry-standard authentication and authorization and end-to-end trust\nidentity technologies, including Authorization and OpenID connect (OIDC),\nAuthorization and OAuth 2.0 token exchange, and Authorization and SPIFFE/ SPIRE\nworkload identities. Experimental evaluation is a unique demonstration of a\nsuperior security position of making use of a smaller attack surface, harmony\npolicy enforcement, as well as interoperability across multi- domain\nenvironments. The research results overlay that the federated identity combined\nwith the Zero Trust basics not only guarantee the rules relating to\nauthentication and authorization but also fully complies with the latest\nDevSecOps standards of microservice deployment, which is automated, scaled, and\nresilient. The current project offers a stringent roadmap to the organizations\nthat desire to apply Zero Trust in cloud-native technologies but will as well\nguarantee adherence and interoperability."}
{"id": "2511.05097", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05097", "abs": "https://arxiv.org/abs/2511.05097", "authors": ["Romain Lefeuvre", "Charly Reux", "Stefano Zacchiroli", "Olivier Barais", "Benoit Combemale"], "title": "Chasing One-day Vulnerabilities Across Open Source Forks", "comment": null, "summary": "Tracking vulnerabilities inherited from third-party open-source components is\na well-known challenge, often addressed by tracing the threads of dependency\ninformation. However, vulnerabilities can also propagate through forking: a\nrepository forked after the introduction of a vulnerability, but before it is\npatched, may remain vulnerable in the fork well after being fixed in the\noriginal project. Current approaches for vulnerability analysis lack the\ncommit-level granularity needed to track vulnerability introductions and fixes\nacross forks, potentially leaving one-day vulnerabilities undetected. This\npaper presents a novel approach to help developers identify one-day\nvulnerabilities in forked repositories. Leveraging the global graph of public\ncode, as captured by the Software Heritage archive, the approach propagates\nvulnerability information at the commit level and performs automated impact\nanalysis. This enables automatic detection of forked projects that have not\nincorporated fixes, leaving them potentially vulnerable. Starting from 7162\nrepositories that, according to OSV, include vulnerable commits in their\ndevelopment histories, we identify 2.2 M forks, containing at least one\nvulnerable commit. Then we perform a strict filtering, allowing us to find 356\n___vulnerability, fork___ pairs impacting active and popular GitHub forks, we\nmanually evaluate 65 pairs, finding 3 high-severity vulnerabilities,\ndemonstrating the impact and applicability of this approach."}
{"id": "2511.05102", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05102", "abs": "https://arxiv.org/abs/2511.05102", "authors": ["Disesdi Susanna Cox", "Niklas Bunzel"], "title": "Quantifying the Risk of Transferred Black Box Attacks", "comment": null, "summary": "Neural networks have become pervasive across various applications, including\nsecurity-related products. However, their widespread adoption has heightened\nconcerns regarding vulnerability to adversarial attacks. With emerging\nregulations and standards emphasizing security, organizations must reliably\nquantify risks associated with these attacks, particularly regarding\ntransferred adversarial attacks, which remain challenging to evaluate\naccurately. This paper investigates the complexities involved in resilience\ntesting against transferred adversarial attacks. Our analysis specifically\naddresses black-box evasion attacks, highlighting transfer-based attacks due to\ntheir practical significance and typically high transferability between neural\nnetwork models. We underline the computational infeasibility of exhaustively\nexploring high-dimensional input spaces to achieve complete test coverage. As a\nresult, comprehensive adversarial risk mapping is deemed impractical. To\nmitigate this limitation, we propose a targeted resilience testing framework\nthat employs surrogate models strategically selected based on Centered Kernel\nAlignment (CKA) similarity. By leveraging surrogate models exhibiting both high\nand low CKA similarities relative to the target model, the proposed approach\nseeks to optimize coverage of adversarial subspaces. Risk estimation is\nconducted using regression-based estimators, providing organizations with\nrealistic and actionable risk quantification."}
{"id": "2511.05269", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05269", "abs": "https://arxiv.org/abs/2511.05269", "authors": ["Ishan Kavathekar", "Hemang Jain", "Ameya Rathod", "Ponnurangam Kumaraguru", "Tanuja Ganu"], "title": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems", "comment": "Accepted at ICML 2025 MAS Workshop. This version includes additional\n  experiments and analysis", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities as\nautonomous agents through tool use, planning, and decision-making abilities,\nleading to their widespread adoption across diverse tasks. As task complexity\ngrows, multi-agent LLM systems are increasingly used to solve problems\ncollaboratively. However, safety and security of these systems remains largely\nunder-explored. Existing benchmarks and datasets predominantly focus on\nsingle-agent settings, failing to capture the unique vulnerabilities of\nmulti-agent dynamics and co-ordination. To address this gap, we introduce\n$\\textbf{T}$hreats and $\\textbf{A}$ttacks in $\\textbf{M}$ulti-$\\textbf{A}$gent\n$\\textbf{S}$ystems ($\\textbf{TAMAS}$), a benchmark designed to evaluate the\nrobustness and safety of multi-agent LLM systems. TAMAS includes five distinct\nscenarios comprising 300 adversarial instances across six attack types and 211\ntools, along with 100 harmless tasks. We assess system performance across ten\nbackbone LLMs and three agent interaction configurations from Autogen and\nCrewAI frameworks, highlighting critical challenges and failure modes in\ncurrent multi-agent deployments. Furthermore, we introduce Effective Robustness\nScore (ERS) to assess the tradeoff between safety and task effectiveness of\nthese frameworks. Our findings show that multi-agent systems are highly\nvulnerable to adversarial attacks, underscoring the urgent need for stronger\ndefenses. TAMAS provides a foundation for systematically studying and improving\nthe safety of multi-agent LLM systems."}
{"id": "2511.04898", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04898", "abs": "https://arxiv.org/abs/2511.04898", "authors": ["Yule Wen", "Yixin Ye", "Yanzhe Zhang", "Diyi Yang", "Hao Zhu"], "title": "Real-Time Reasoning Agents in Evolving Environments", "comment": "30 pages", "summary": "Agents in the real world must make not only logical but also timely\njudgments. This requires continuous awareness of the dynamic environment:\nhazards emerge, opportunities arise, and other agents act, while the agent's\nreasoning is still unfolding. Despite advances in language model reasoning,\nexisting approaches fail to account for this dynamic nature. We introduce\nreal-time reasoning as a new problem formulation for agents in evolving\nenvironments and build Real-Time Reasoning Gym to demonstrate it. We study two\nparadigms for deploying language models in agents: (1) reactive agents, which\nemploy language models with bounded reasoning computation for rapid responses,\nand (2) planning agents, which allow extended reasoning computation for complex\nproblems. Our experiments show that even state-of-the-art models struggle with\nmaking logical and timely judgments in either paradigm. To address this\nlimitation, we propose AgileThinker, which simultaneously engages both\nreasoning paradigms. AgileThinker consistently outperforms agents engaging only\none reasoning paradigm as the task difficulty and time pressure rise,\neffectively balancing reasoning depth and response latency. Our work\nestablishes real-time reasoning as a critical testbed for developing practical\nagents and provides a foundation for research in temporally constrained AI\nsystems, highlighting a path toward real-time capable agents."}
{"id": "2511.04789", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04789", "abs": "https://arxiv.org/abs/2511.04789", "authors": ["Xiaoda Wang", "Yuji Zhao", "Kaiqiao Han", "Xiao Luo", "Sanne van Rooij", "Jennifer Stevens", "Lifang He", "Liang Zhan", "Yizhou Sun", "Wei Wang", "Carl Yang"], "title": "Conditional Neural ODE for Longitudinal Parkinson's Disease Progression Forecasting", "comment": "Accepted to IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM) 2025", "summary": "Parkinson's disease (PD) shows heterogeneous, evolving brain-morphometry\npatterns. Modeling these longitudinal trajectories enables mechanistic insight,\ntreatment development, and individualized 'digital-twin' forecasting. However,\nexisting methods usually adopt recurrent neural networks and transformer\narchitectures, which rely on discrete, regularly sampled data while struggling\nto handle irregular and sparse magnetic resonance imaging (MRI) in PD cohorts.\nMoreover, these methods have difficulty capturing individual heterogeneity\nincluding variations in disease onset, progression rate, and symptom severity,\nwhich is a hallmark of PD. To address these challenges, we propose CNODE\n(Conditional Neural ODE), a novel framework for continuous, individualized PD\nprogression forecasting. The core of CNODE is to model morphological brain\nchanges as continuous temporal processes using a neural ODE model. In addition,\nwe jointly learn patient-specific initial time and progress speed to align\nindividual trajectories into a shared progression trajectory. We validate CNODE\non the Parkinson's Progression Markers Initiative (PPMI) dataset. Experimental\nresults show that our method outperforms state-of-the-art baselines in\nforecasting longitudinal PD progression."}
{"id": "2511.05119", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05119", "abs": "https://arxiv.org/abs/2511.05119", "authors": ["Víctor Mayoral-Vilches", "Luis Javier Navarrete-Lozano", "Francesco Balassone", "María Sanz-Gómez", "Cristóbal Ricardo Veas Chávez", "Maite del Mundo de Torres"], "title": "Cybersecurity AI in OT: Insights from an AI Top-10 Ranker in the Dragos OT CTF 2025", "comment": null, "summary": "Operational Technology (OT) cybersecurity increasingly relies on rapid\nresponse across malware analysis, network forensics, and reverse engineering\ndisciplines. We examine the performance of Cybersecurity AI (CAI), powered by\nthe \\texttt{alias1} model, during the Dragos OT CTF 2025 -- a 48-hour\nindustrial control system (ICS) competition with more than 1,000 teams. Using\nCAI telemetry and official leaderboard data, we quantify CAI's trajectory\nrelative to the leading human-operated teams. CAI reached Rank~1 between\ncompetition hours 7.0 and 8.0, crossed 10,000 points at 5.42~hours\n(1,846~pts/h), and completed 32 of the competition's 34 challenges before\nautomated operations were paused at hour~24 with a final score of 18,900 points\n(6th place). The top-3 human teams solved 33 of 34 challenges, collectively\nleaving only the 600-point ``Kiddy Tags -- 1'' unsolved; they were also the\nonly teams to clear the 1,000-point ``Moot Force'' binary. The top-5 human\nteams averaged 1,347~pts/h to the same milestone, marking a 37\\% velocity\nadvantage for CAI. We analyse time-resolved scoring, category coverage, and\nsolve cadence. The evidence indicates that a mission-configured AI agent can\nmatch or exceed expert human crews in early-phase OT incident response while\nremaining subject to practical limits in sustained, multi-day operations."}
{"id": "2511.04904", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04904", "abs": "https://arxiv.org/abs/2511.04904", "authors": ["Bassel Al Omari", "Michael Matthews", "Alexander Rutherford", "Jakob Nicolaus Foerster"], "title": "Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale", "comment": null, "summary": "Progress in multi-agent reinforcement learning (MARL) requires challenging\nbenchmarks that assess the limits of current methods. However, existing\nbenchmarks often target narrow short-horizon challenges that do not adequately\nstress the long-term dependencies and generalization capabilities inherent in\nmany multi-agent systems. To address this, we first present\n\\textit{Craftax-MA}: an extension of the popular open-ended RL environment,\nCraftax, that supports multiple agents and evaluates a wide range of general\nabilities within a single environment. Written in JAX, \\textit{Craftax-MA} is\nexceptionally fast with a training run using 250 million environment\ninteractions completing in under an hour. To provide a more compelling\nchallenge for MARL, we also present \\textit{Craftax-Coop}, an extension\nintroducing heterogeneous agents, trading and more mechanics that require\ncomplex cooperation among agents for success. We provide analysis demonstrating\nthat existing algorithms struggle with key challenges in this benchmark,\nincluding long-horizon credit assignment, exploration and cooperation, and\nargue for its potential to drive long-term research in MARL."}
{"id": "2511.04956", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04956", "abs": "https://arxiv.org/abs/2511.04956", "authors": ["Maria Mahbub", "Vanessa Lama", "Sanjay Das", "Brian Starks", "Christopher Polchek", "Saffell Silvers", "Lauren Deck", "Prasanna Balaprakash", "Tirthankar Ghosal"], "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property", "comment": null, "summary": "High-Risk Property (HRP) classification is critical at U.S. Department of\nEnergy (DOE) sites, where inventories include sensitive and often dual-use\nequipment. Compliance must track evolving rules designated by various export\ncontrol policies to make transparent and auditable decisions. Traditional\nexpert-only workflows are time-consuming, backlog-prone, and struggle to keep\npace with shifting regulatory boundaries. We demo ORCHID, a modular agentic\nsystem for HRP classification that pairs retrieval-augmented generation (RAG)\nwith human oversight to produce policy-based outputs that can be audited. Small\ncooperating agents, retrieval, description refiner, classifier, validator, and\nfeedback logger, coordinate via agent-to-agent messaging and invoke tools\nthrough the Model Context Protocol (MCP) for model-agnostic on-premise\noperation. The interface follows an Item to Evidence to Decision loop with\nstep-by-step reasoning, on-policy citations, and append-only audit bundles\n(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID\nimproves accuracy and traceability over a non-agentic baseline while deferring\nuncertain items to Subject Matter Experts (SMEs). The demonstration shows\nsingle item submission, grounded citations, SME feedback capture, and\nexportable audit artifacts, illustrating a practical path to trustworthy LLM\nassistance in sensitive DOE compliance workflows."}
{"id": "2511.04790", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04790", "abs": "https://arxiv.org/abs/2511.04790", "authors": ["Caroline Uhler", "Jiaqi Zhang"], "title": "Causal Structure and Representation Learning with Biomedical Applications", "comment": "This article has successfully completed peer review and will appear\n  in the Proceedings of the International Congress of Mathematicians 2026. Both\n  authors contributed equally to this work", "summary": "Massive data collection holds the promise of a better understanding of\ncomplex phenomena and, ultimately, better decisions. Representation learning\nhas become a key driver of deep learning applications, as it allows learning\nlatent spaces that capture important properties of the data without requiring\nany supervised annotations. Although representation learning has been hugely\nsuccessful in predictive tasks, it can fail miserably in causal tasks including\npredicting the effect of a perturbation/intervention. This calls for a marriage\nbetween representation learning and causal inference. An exciting opportunity\nin this regard stems from the growing availability of multi-modal data\n(observational and perturbational, imaging-based and sequencing-based, at the\nsingle-cell level, tissue-level, and organism-level). We outline a statistical\nand computational framework for causal structure and representation learning\nmotivated by fundamental biomedical questions: how to effectively use\nobservational and perturbational data to perform causal discovery on observed\ncausal variables; how to use multi-modal views of the system to learn causal\nvariables; and how to design optimal perturbations."}
{"id": "2511.05133", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.05133", "abs": "https://arxiv.org/abs/2511.05133", "authors": ["Urslla Uchechi Izuazu", "Mounir Bensalem", "Admela Jukan"], "title": "A Secured Intent-Based Networking (sIBN) with Data-Driven Time-Aware Intrusion Detection", "comment": "This paper is uploaded here for research community, thus it is for\n  non-commercial purposes", "summary": "While Intent-Based Networking (IBN) promises operational efficiency through\nautonomous and abstraction-driven network management, a critical unaddressed\nissue lies in IBN's implicit trust in the integrity of intent ingested by the\nnetwork. This inherent assumption of data reliability creates a blind spot\nexploitable by Man-in-the-Middle (MitM) attacks, where an adversary intercepts\nand alters intent before it is enacted, compelling the network to orchestrate\nmalicious configurations. This study proposes a secured IBN (sIBN) system with\ndata driven intrusion detection method designed to secure legitimate user\nintent from adversarial tampering. The proposed intent intrusion detection\nsystem uses a ML model applied for network behavioral anomaly detection to\nreveal temporal patterns of intent tampering. This is achieved by leveraging a\nset of original behavioral metrics and newly engineered time-aware features,\nwith the model's hyperparameters fine-tuned through the randomized search\ncross-validation (RSCV) technique. Numerical results based on real-world data\nsets, show the effectiveness of sIBN, achieving the best performance across\nstandard evaluation metrics, in both binary and multi classification tasks,\nwhile maintaining low error rates."}
{"id": "2511.05311", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05311", "abs": "https://arxiv.org/abs/2511.05311", "authors": ["Valeriu Dimidov", "Faisal Hawlader", "Sasan Jafarnejad", "Raphaël Frank"], "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "comment": null, "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities."}
{"id": "2511.04847", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04847", "abs": "https://arxiv.org/abs/2511.04847", "authors": ["Arthur Chen", "Zuxin Liu", "Jianguo Zhang", "Akshara Prabhakar", "Zhiwei Liu", "Shelby Heinecke", "Silvio Savarese", "Victor Zhong", "Caiming Xiong"], "title": "Grounded Test-Time Adaptation for LLM Agents", "comment": "Preprint. Under review", "summary": "Large language model (LLM)-based agents struggle to generalize to novel and\ncomplex environments, such as unseen websites or new sets of functions, due to\na fundamental mismatch between their pre-training and test-time conditions.\nThis challenge stems from two distinct failure modes: a syntactic\nmisunderstanding of environment-specific components like observation formats,\nand a semantic misunderstanding of state-transition dynamics, which are only\nrevealed at test time. To address these issues, we propose two distinct and\ncomplementary strategies for adapting LLM agents by leveraging\nenvironment-specific information available during deployment. First, an online\ndistributional adaptation method parameterizes environmental nuances by\nlearning a lightweight adaptation vector that biases the model's output\ndistribution, enabling rapid alignment with an environment response format.\nSecond, a deployment-time dynamics grounding method employs a persona-driven\nexploration phase to systematically probe and learn the environment's causal\ndynamics before task execution, equipping the agent with a nonparametric world\nmodel. We evaluate these strategies across diverse agentic benchmarks,\nincluding function calling and web navigation. Our empirical results show the\neffectiveness of both strategies across all benchmarks with minimal\ncomputational cost. We find that dynamics grounding is particularly effective\nin complex environments where unpredictable dynamics pose a major obstacle,\ndemonstrating a robust path toward more generalizable and capable LLM-based\nagents. For example, on the WebArena multi-site split, this method increases\nthe agent's success rate from 2% to 23%."}
{"id": "2511.05359", "categories": ["cs.CR", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05359", "abs": "https://arxiv.org/abs/2511.05359", "authors": ["Amr Gomaa", "Ahmed Salem", "Sahar Abdelnabi"], "title": "ConVerse: Benchmarking Contextual Safety in Agent-to-Agent Conversations", "comment": null, "summary": "As language models evolve into autonomous agents that act and communicate on\nbehalf of users, ensuring safety in multi-agent ecosystems becomes a central\nchallenge. Interactions between personal assistants and external service\nproviders expose a core tension between utility and protection: effective\ncollaboration requires information sharing, yet every exchange creates new\nattack surfaces. We introduce ConVerse, a dynamic benchmark for evaluating\nprivacy and security risks in agent-agent interactions. ConVerse spans three\npractical domains (travel, real estate, insurance) with 12 user personas and\nover 864 contextually grounded attacks (611 privacy, 253 security). Unlike\nprior single-agent settings, it models autonomous, multi-turn agent-to-agent\nconversations where malicious requests are embedded within plausible discourse.\nPrivacy is tested through a three-tier taxonomy assessing abstraction quality,\nwhile security attacks target tool use and preference manipulation. Evaluating\nseven state-of-the-art models reveals persistent vulnerabilities; privacy\nattacks succeed in up to 88% of cases and security breaches in up to 60%, with\nstronger models leaking more. By unifying privacy and security within\ninteractive multi-agent contexts, ConVerse reframes safety as an emergent\nproperty of communication."}
{"id": "2511.05375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05375", "abs": "https://arxiv.org/abs/2511.05375", "authors": ["Sijie Yang", "Jiatong Li", "Filip Biljecki"], "title": "Reasoning Is All You Need for Urban Planning AI", "comment": "Submitted to AAAI 2026 Workshop AI4UP", "summary": "AI has proven highly successful at urban planning analysis -- learning\npatterns from data to predict future conditions. The next frontier is\nAI-assisted decision-making: agents that recommend sites, allocate resources,\nand evaluate trade-offs while reasoning transparently about constraints and\nstakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,\nReAct, and multi-agent collaboration frameworks -- now make this vision\nachievable.\n  This position paper presents the Agentic Urban Planning AI Framework for\nreasoning-capable planning agents that integrates three cognitive layers\n(Perception, Foundation, Reasoning) with six logic components (Analysis,\nGeneration, Verification, Evaluation, Collaboration, Decision) through a\nmulti-agents collaboration framework. We demonstrate why planning decisions\nrequire explicit reasoning capabilities that are value-based (applying\nnormative principles), rule-grounded (guaranteeing constraint satisfaction),\nand explainable (generating transparent justifications) -- requirements that\nstatistical learning alone cannot fulfill. We compare reasoning agents with\nstatistical learning, present a comprehensive architecture with benchmark\nevaluation metrics, and outline critical research challenges. This framework\nshows how AI agents can augment human planners by systematically exploring\nsolution spaces, verifying regulatory compliance, and deliberating over\ntrade-offs transparently -- not replacing human judgment but amplifying it with\ncomputational reasoning capabilities."}
{"id": "2511.04854", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.04854", "abs": "https://arxiv.org/abs/2511.04854", "authors": ["Alvaro Prat", "Leo Zhang", "Charlotte M. Deane", "Yee Whye Teh", "Garrett M. Morris"], "title": "SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion", "comment": "Preprint", "summary": "Determining the binding pose of a ligand to a protein, known as molecular\ndocking, is a fundamental task in drug discovery. Generative approaches promise\nfaster, improved, and more diverse pose sampling than physics-based methods,\nbut are often hindered by chemically implausible outputs, poor\ngeneralisability, and high computational cost. To address these challenges, we\nintroduce a novel fragmentation scheme, leveraging inductive biases from\nstructural chemistry, to decompose ligands into rigid-body fragments. Building\non this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion\nmodel that generates poses by learning to reassemble these rigid bodies within\nthe binding pocket. By operating at the level of fragments in SE(3), SigmaDock\nexploits well-established geometric priors while avoiding overly complex\ndiffusion processes and unstable training dynamics. Experimentally, we show\nSigmaDock achieves state-of-the-art performance, reaching Top-1 success rates\n(RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8%\nreported by recent deep learning approaches, whilst demonstrating consistent\ngeneralisation to unseen proteins. SigmaDock is the first deep learning\napproach to surpass classical physics-based docking under the PB train-test\nsplit, marking a significant leap forward in the reliability and feasibility of\ndeep learning for molecular modelling."}
{"id": "2511.04707", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04707", "abs": "https://arxiv.org/abs/2511.04707", "authors": ["Rishi Rajesh Shah", "Chen Henry Wu", "Shashwat Saxena", "Ziqian Zhong", "Alexander Robey", "Aditi Raghunathan"], "title": "Jailbreaking in the Haystack", "comment": null, "summary": "Recent advances in long-context language models (LMs) have enabled\nmillion-token inputs, expanding their capabilities across complex tasks like\ncomputer-use agents. Yet, the safety implications of these extended contexts\nremain unclear. To bridge this gap, we introduce NINJA (short for\nNeedle-in-haystack jailbreak attack), a method that jailbreaks aligned LMs by\nappending benign, model-generated content to harmful user goals. Critical to\nour method is the observation that the position of harmful goals play an\nimportant role in safety. Experiments on standard safety benchmark, HarmBench,\nshow that NINJA significantly increases attack success rates across\nstate-of-the-art open and proprietary models, including LLaMA, Qwen, Mistral,\nand Gemini. Unlike prior jailbreaking methods, our approach is low-resource,\ntransferable, and less detectable. Moreover, we show that NINJA is\ncompute-optimal -- under a fixed compute budget, increasing context length can\noutperform increasing the number of trials in best-of-N jailbreak. These\nfindings reveal that even benign long contexts -- when crafted with careful\ngoal positioning -- introduce fundamental vulnerabilities in modern LMs."}
{"id": "2511.04883", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04883", "abs": "https://arxiv.org/abs/2511.04883", "authors": ["Di Chen", "Jia Li", "Michael Zhang"], "title": "Self-Interest and Systemic Benefits: Emergence of Collective Rationality in Mixed Autonomy Traffic Through Deep Reinforcement Learning", "comment": null, "summary": "Autonomous vehicles (AVs) are expected to be commercially available in the\nnear future, leading to mixed autonomy traffic consisting of both AVs and\nhuman-driven vehicles (HVs). Although numerous studies have shown that AVs can\nbe deployed to benefit the overall traffic system performance by incorporating\nsystem-level goals into their decision making, it is not clear whether the\nbenefits still exist when agents act out of self-interest -- a trait common to\nall driving agents, both human and autonomous. This study aims to understand\nwhether self-interested AVs can bring benefits to all driving agents in mixed\nautonomy traffic systems. The research is centered on the concept of collective\nrationality (CR). This concept, originating from game theory and behavioral\neconomics, means that driving agents may cooperate collectively even when\npursuing individual interests. Our recent research has proven the existence of\nCR in an analytical game-theoretical model and empirically in mixed\nhuman-driven traffic. In this paper, we demonstrate that CR can be attained\namong driving agents trained using deep reinforcement learning (DRL) with a\nsimple reward design. We examine the extent to which self-interested traffic\nagents can achieve CR without directly incorporating system-level objectives.\nResults show that CR consistently emerges in various scenarios, which indicates\nthe robustness of this property. We also postulate a mechanism to explain the\nemergence of CR in the microscopic and dynamic environment and verify it based\non simulation evidence. This research suggests the possibility of leveraging\nadvanced learning methods (such as federated learning) to achieve collective\ncooperation among self-interested driving agents in mixed-autonomy systems."}
{"id": "2511.04790", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04790", "abs": "https://arxiv.org/abs/2511.04790", "authors": ["Caroline Uhler", "Jiaqi Zhang"], "title": "Causal Structure and Representation Learning with Biomedical Applications", "comment": "This article has successfully completed peer review and will appear\n  in the Proceedings of the International Congress of Mathematicians 2026. Both\n  authors contributed equally to this work", "summary": "Massive data collection holds the promise of a better understanding of\ncomplex phenomena and, ultimately, better decisions. Representation learning\nhas become a key driver of deep learning applications, as it allows learning\nlatent spaces that capture important properties of the data without requiring\nany supervised annotations. Although representation learning has been hugely\nsuccessful in predictive tasks, it can fail miserably in causal tasks including\npredicting the effect of a perturbation/intervention. This calls for a marriage\nbetween representation learning and causal inference. An exciting opportunity\nin this regard stems from the growing availability of multi-modal data\n(observational and perturbational, imaging-based and sequencing-based, at the\nsingle-cell level, tissue-level, and organism-level). We outline a statistical\nand computational framework for causal structure and representation learning\nmotivated by fundamental biomedical questions: how to effectively use\nobservational and perturbational data to perform causal discovery on observed\ncausal variables; how to use multi-modal views of the system to learn causal\nvariables; and how to design optimal perturbations."}
{"id": "2511.04904", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04904", "abs": "https://arxiv.org/abs/2511.04904", "authors": ["Bassel Al Omari", "Michael Matthews", "Alexander Rutherford", "Jakob Nicolaus Foerster"], "title": "Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale", "comment": null, "summary": "Progress in multi-agent reinforcement learning (MARL) requires challenging\nbenchmarks that assess the limits of current methods. However, existing\nbenchmarks often target narrow short-horizon challenges that do not adequately\nstress the long-term dependencies and generalization capabilities inherent in\nmany multi-agent systems. To address this, we first present\n\\textit{Craftax-MA}: an extension of the popular open-ended RL environment,\nCraftax, that supports multiple agents and evaluates a wide range of general\nabilities within a single environment. Written in JAX, \\textit{Craftax-MA} is\nexceptionally fast with a training run using 250 million environment\ninteractions completing in under an hour. To provide a more compelling\nchallenge for MARL, we also present \\textit{Craftax-Coop}, an extension\nintroducing heterogeneous agents, trading and more mechanics that require\ncomplex cooperation among agents for success. We provide analysis demonstrating\nthat existing algorithms struggle with key challenges in this benchmark,\nincluding long-horizon credit assignment, exploration and cooperation, and\nargue for its potential to drive long-term research in MARL."}
{"id": "2511.05005", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05005", "abs": "https://arxiv.org/abs/2511.05005", "authors": ["Dongsu Lee", "Daehee Lee", "Amy Zhang"], "title": "Multi-agent Coordination via Flow Matching", "comment": null, "summary": "This work presents MAC-Flow, a simple yet expressive framework for\nmulti-agent coordination. We argue that requirements of effective coordination\nare twofold: (i) a rich representation of the diverse joint behaviors present\nin offline data and (ii) the ability to act efficiently in real time. However,\nprior approaches often sacrifice one for the other, i.e., denoising\ndiffusion-based solutions capture complex coordination but are computationally\nslow, while Gaussian policy-based solutions are fast but brittle in handling\nmulti-agent interaction. MAC-Flow addresses this trade-off by first learning a\nflow-based representation of joint behaviors, and then distilling it into\ndecentralized one-step policies that preserve coordination while enabling fast\nexecution. Across four different benchmarks, including $12$ environments and\n$34$ datasets, MAC-Flow alleviates the trade-off between performance and\ncomputational cost, specifically achieving about $\\boldsymbol{\\times14.5}$\nfaster inference compared to diffusion-based MARL methods, while maintaining\ngood performance. At the same time, its inference speed is similar to that of\nprior Gaussian policy-based offline multi-agent reinforcement learning (MARL)\nmethods."}
{"id": "2511.04984", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04984", "abs": "https://arxiv.org/abs/2511.04984", "authors": ["Xinheng He", "Yijia Zhang", "Haowei Lin", "Xingang Peng", "Xiangzhe Kong", "Mingyu Li", "Jianzhu Ma"], "title": "Peptide2Mol: A Diffusion Model for Generating Small Molecules as Peptide Mimics for Targeted Protein Binding", "comment": "Abstract 1 page, main text 9 pages, references 2 pages, 4 figures.\n  Submitted to RECOMB 2026", "summary": "Structure-based drug design has seen significant advancements with the\nintegration of artificial intelligence (AI), particularly in the generation of\nhit and lead compounds. However, most AI-driven approaches neglect the\nimportance of endogenous protein interactions with peptides, which may result\nin suboptimal molecule designs. In this work, we present Peptide2Mol, an\nE(3)-equivariant graph neural network diffusion model that generates small\nmolecules by referencing both the original peptide binders and their\nsurrounding protein pocket environments. Trained on large datasets and\nleveraging sophisticated modeling techniques, Peptide2Mol not only achieves\nstate-of-the-art performance in non-autoregressive generative tasks, but also\nproduces molecules with similarity to the original peptide binder.\nAdditionally, the model allows for molecule optimization and peptidomimetic\ndesign through a partial diffusion process. Our results highlight Peptide2Mol\nas an effective deep generative model for generating and optimizing bioactive\nsmall molecules from protein binding pockets."}
{"id": "2511.05028", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05028", "abs": "https://arxiv.org/abs/2511.05028", "authors": ["Dongjin Park", "Hasung Yeo", "Joon-Woo Lee"], "title": "OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data", "comment": null, "summary": "Federated fine-tuning (FFT) adapts foundation models to decentralized data\nbut remains fragile under heterogeneous client distributions due to local\ndrift, i.e., client-level update divergences that induce systematic bias and\namplified variance in the global model. Existing aggregation and\npersonalization methods largely correct drift post hoc, which proves brittle\nunder extreme non-IID conditions. We introduce OvA-LP, a minimalist framework\nthat is, to our knowledge, the first explicitly designed to suppress drift at\nits source within the PEFT-based FFT paradigm. OvA-LP combines linear probing\non a frozen encoder with a one-vs-all head and a simple two-stage procedure,\npreserving pretrained feature geometry and decoupling logits to prevent the\nmechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over\nshard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of\nits IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1%\n(PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains\nresilience under both symmetric and asymmetric label noise. In addition,\nprecomputing encoder features makes per-round cost nearly independent of\nencoder size. Together, these results demonstrate that OvA-LP provides a\nprincipled and efficient basis for robust FFT under heterogeneity."}
{"id": "2511.05005", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05005", "abs": "https://arxiv.org/abs/2511.05005", "authors": ["Dongsu Lee", "Daehee Lee", "Amy Zhang"], "title": "Multi-agent Coordination via Flow Matching", "comment": null, "summary": "This work presents MAC-Flow, a simple yet expressive framework for\nmulti-agent coordination. We argue that requirements of effective coordination\nare twofold: (i) a rich representation of the diverse joint behaviors present\nin offline data and (ii) the ability to act efficiently in real time. However,\nprior approaches often sacrifice one for the other, i.e., denoising\ndiffusion-based solutions capture complex coordination but are computationally\nslow, while Gaussian policy-based solutions are fast but brittle in handling\nmulti-agent interaction. MAC-Flow addresses this trade-off by first learning a\nflow-based representation of joint behaviors, and then distilling it into\ndecentralized one-step policies that preserve coordination while enabling fast\nexecution. Across four different benchmarks, including $12$ environments and\n$34$ datasets, MAC-Flow alleviates the trade-off between performance and\ncomputational cost, specifically achieving about $\\boldsymbol{\\times14.5}$\nfaster inference compared to diffusion-based MARL methods, while maintaining\ngood performance. At the same time, its inference speed is similar to that of\nprior Gaussian policy-based offline multi-agent reinforcement learning (MARL)\nmethods."}
{"id": "2511.05179", "categories": ["cs.LG", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.05179", "abs": "https://arxiv.org/abs/2511.05179", "authors": ["Ragini Gupta", "Naman Raina", "Bo Chen", "Li Chen", "Claudiu Danilov", "Josh Eckhardt", "Keyshla Bernard", "Klara Nahrstedt"], "title": "No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models", "comment": null, "summary": "Modern IoT deployments for environmental sensing produce high volume\nspatiotemporal data to support downstream tasks such as forecasting, typically\npowered by machine learning models. While existing filtering and strategic\ndeployment techniques optimize collected data volume at the edge, they overlook\nhow variations in sampling frequencies and spatial coverage affect downstream\nmodel performance. In many forecasting models, incorporating data from\nadditional sensors denoise predictions by providing broader spatial contexts.\nThis interplay between sampling frequency, spatial coverage and different\nforecasting model architectures remain underexplored. This work presents a\nsystematic study of forecasting models - classical models (VAR), neural\nnetworks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs),\nand time series foundation models (TSFMs: Chronos Moirai, TimesFM) under\nvarying spatial sensor nodes density and sampling intervals using real-world\ntemperature data in a wireless sensor network. Our results show that STGNNs are\neffective when sensor deployments are sparse and sampling rate is moderate,\nleveraging spatial correlations via encoded graph structure to compensate for\nlimited coverage. In contrast, TSFMs perform competitively at high frequencies\nbut degrade when spatial coverage from neighboring sensors is reduced.\nCrucially, the multivariate TSFM Moirai outperforms all models by natively\nlearning cross-sensor dependencies. These findings offer actionable insights\nfor building efficient forecasting pipelines in spatio-temporal systems. All\ncode for model configurations, training, dataset, and logs are open-sourced for\nreproducibility:\nhttps://github.com/UIUC-MONET-Projects/Benchmarking-Spatiotemporal-Forecast-Models"}
{"id": "2511.05028", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05028", "abs": "https://arxiv.org/abs/2511.05028", "authors": ["Dongjin Park", "Hasung Yeo", "Joon-Woo Lee"], "title": "OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data", "comment": null, "summary": "Federated fine-tuning (FFT) adapts foundation models to decentralized data\nbut remains fragile under heterogeneous client distributions due to local\ndrift, i.e., client-level update divergences that induce systematic bias and\namplified variance in the global model. Existing aggregation and\npersonalization methods largely correct drift post hoc, which proves brittle\nunder extreme non-IID conditions. We introduce OvA-LP, a minimalist framework\nthat is, to our knowledge, the first explicitly designed to suppress drift at\nits source within the PEFT-based FFT paradigm. OvA-LP combines linear probing\non a frozen encoder with a one-vs-all head and a simple two-stage procedure,\npreserving pretrained feature geometry and decoupling logits to prevent the\nmechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over\nshard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of\nits IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1%\n(PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains\nresilience under both symmetric and asymmetric label noise. In addition,\nprecomputing encoder features makes per-round cost nearly independent of\nencoder size. Together, these results demonstrate that OvA-LP provides a\nprincipled and efficient basis for robust FFT under heterogeneity."}
{"id": "2511.05269", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05269", "abs": "https://arxiv.org/abs/2511.05269", "authors": ["Ishan Kavathekar", "Hemang Jain", "Ameya Rathod", "Ponnurangam Kumaraguru", "Tanuja Ganu"], "title": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems", "comment": "Accepted at ICML 2025 MAS Workshop. This version includes additional\n  experiments and analysis", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities as\nautonomous agents through tool use, planning, and decision-making abilities,\nleading to their widespread adoption across diverse tasks. As task complexity\ngrows, multi-agent LLM systems are increasingly used to solve problems\ncollaboratively. However, safety and security of these systems remains largely\nunder-explored. Existing benchmarks and datasets predominantly focus on\nsingle-agent settings, failing to capture the unique vulnerabilities of\nmulti-agent dynamics and co-ordination. To address this gap, we introduce\n$\\textbf{T}$hreats and $\\textbf{A}$ttacks in $\\textbf{M}$ulti-$\\textbf{A}$gent\n$\\textbf{S}$ystems ($\\textbf{TAMAS}$), a benchmark designed to evaluate the\nrobustness and safety of multi-agent LLM systems. TAMAS includes five distinct\nscenarios comprising 300 adversarial instances across six attack types and 211\ntools, along with 100 harmless tasks. We assess system performance across ten\nbackbone LLMs and three agent interaction configurations from Autogen and\nCrewAI frameworks, highlighting critical challenges and failure modes in\ncurrent multi-agent deployments. Furthermore, we introduce Effective Robustness\nScore (ERS) to assess the tradeoff between safety and task effectiveness of\nthese frameworks. Our findings show that multi-agent systems are highly\nvulnerable to adversarial attacks, underscoring the urgent need for stronger\ndefenses. TAMAS provides a foundation for systematically studying and improving\nthe safety of multi-agent LLM systems."}
{"id": "2511.05169", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05169", "abs": "https://arxiv.org/abs/2511.05169", "authors": ["Simon Baur", "Tristan Ruhwedel", "Ekin Böke", "Zuzanna Kobus", "Gergana Lishkova", "Christoph Wetz", "Holger Amthauer", "Christoph Roderburg", "Frank Tacke", "Julian M. Rogasch", "Wojciech Samek", "Henning Jann", "Jackie Ma", "Johannes Eschrich"], "title": "Multimodal Deep Learning for Prediction of Progression-Free Survival in Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor Radionuclide Therapy", "comment": null, "summary": "Peptide receptor radionuclide therapy (PRRT) is an established treatment for\nmetastatic neuroendocrine tumors (NETs), yet long-term disease control occurs\nonly in a subset of patients. Predicting progression-free survival (PFS) could\nsupport individualized treatment planning. This study evaluates laboratory,\nimaging, and multimodal deep learning models for PFS prediction in PRRT-treated\npatients. In this retrospective, single-center study 116 patients with\nmetastatic NETs undergoing 177Lu-DOTATOC were included. Clinical\ncharacteristics, laboratory values, and pretherapeutic somatostatin receptor\npositron emission tomography/computed tomographies (SR-PET/CT) were collected.\nSeven models were trained to classify low- vs. high-PFS groups, including\nunimodal (laboratory, SR-PET, or CT) and multimodal fusion approaches.\nExplainability was evaluated by feature importance analysis and gradient maps.\nForty-two patients (36%) had short PFS (< 1 year), 74 patients long PFS (>1\nyear). Groups were similar in most characteristics, except for higher baseline\nchromogranin A (p = 0.003), elevated gamma-GT (p = 0.002), and fewer PRRT\ncycles (p < 0.001) in short-PFS patients. The Random Forest model trained only\non laboratory biomarkers reached an AUROC of 0.59 +- 0.02. Unimodal\nthree-dimensional convolutional neural networks using SR-PET or CT performed\nworse (AUROC 0.42 +- 0.03 and 0.54 +- 0.01, respectively). A multimodal fusion\nmodel laboratory values, SR-PET, and CT -augmented with a pretrained CT branch\n- achieved the best results (AUROC 0.72 +- 0.01, AUPRC 0.80 +- 0.01).\nMultimodal deep learning combining SR-PET, CT, and laboratory biomarkers\noutperformed unimodal approaches for PFS prediction after PRRT. Upon external\nvalidation, such models may support risk-adapted follow-up strategies."}
{"id": "2511.05396", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.05396", "abs": "https://arxiv.org/abs/2511.05396", "authors": ["Yiting He", "Zhishuai Liu", "Weixin Wang", "Pan Xu"], "title": "Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction", "comment": "53 pages, 6 figures, 3 tables. Published in Proceedings of the 42nd\n  International Conference on Machine Learning (ICML 2025)", "summary": "Off-dynamics reinforcement learning (RL), where training and deployment\ntransition dynamics are different, can be formulated as learning in a robust\nMarkov decision process (RMDP) where uncertainties in transition dynamics are\nimposed. Existing literature mostly assumes access to generative models\nallowing arbitrary state-action queries or pre-collected datasets with a good\nstate coverage of the deployment environment, bypassing the challenge of\nexploration. In this work, we study a more realistic and challenging setting\nwhere the agent is limited to online interaction with the training environment.\nTo capture the intrinsic difficulty of exploration in online RMDPs, we\nintroduce the supremal visitation ratio, a novel quantity that measures the\nmismatch between the training dynamics and the deployment dynamics. We show\nthat if this ratio is unbounded, online learning becomes exponentially hard. We\npropose the first computationally efficient algorithm that achieves sublinear\nregret in online RMDPs with $f$-divergence based transition uncertainties. We\nalso establish matching regret lower bounds, demonstrating that our algorithm\nachieves optimal dependence on both the supremal visitation ratio and the\nnumber of interaction episodes. Finally, we validate our theoretical results\nthrough comprehensive numerical experiments."}
{"id": "2511.05179", "categories": ["cs.LG", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.05179", "abs": "https://arxiv.org/abs/2511.05179", "authors": ["Ragini Gupta", "Naman Raina", "Bo Chen", "Li Chen", "Claudiu Danilov", "Josh Eckhardt", "Keyshla Bernard", "Klara Nahrstedt"], "title": "No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models", "comment": null, "summary": "Modern IoT deployments for environmental sensing produce high volume\nspatiotemporal data to support downstream tasks such as forecasting, typically\npowered by machine learning models. While existing filtering and strategic\ndeployment techniques optimize collected data volume at the edge, they overlook\nhow variations in sampling frequencies and spatial coverage affect downstream\nmodel performance. In many forecasting models, incorporating data from\nadditional sensors denoise predictions by providing broader spatial contexts.\nThis interplay between sampling frequency, spatial coverage and different\nforecasting model architectures remain underexplored. This work presents a\nsystematic study of forecasting models - classical models (VAR), neural\nnetworks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs),\nand time series foundation models (TSFMs: Chronos Moirai, TimesFM) under\nvarying spatial sensor nodes density and sampling intervals using real-world\ntemperature data in a wireless sensor network. Our results show that STGNNs are\neffective when sensor deployments are sparse and sampling rate is moderate,\nleveraging spatial correlations via encoded graph structure to compensate for\nlimited coverage. In contrast, TSFMs perform competitively at high frequencies\nbut degrade when spatial coverage from neighboring sensors is reduced.\nCrucially, the multivariate TSFM Moirai outperforms all models by natively\nlearning cross-sensor dependencies. These findings offer actionable insights\nfor building efficient forecasting pipelines in spatio-temporal systems. All\ncode for model configurations, training, dataset, and logs are open-sourced for\nreproducibility:\nhttps://github.com/UIUC-MONET-Projects/Benchmarking-Spatiotemporal-Forecast-Models"}
{"id": "2511.05442", "categories": ["cs.LG", "cs.AI", "cs.CL", "68Uxx", "I.2.7; I.2.6; I.2.m"], "pdf": "https://arxiv.org/pdf/2511.05442", "abs": "https://arxiv.org/abs/2511.05442", "authors": ["Frauke Andersen", "William Rudman", "Ruochen Zhang", "Carsten Eickhoff"], "title": "APP: Accelerated Path Patching with Task-Specific Pruning", "comment": null, "summary": "Circuit discovery is a key step in many mechanistic interpretability\npipelines. Current methods, such as Path Patching, are computationally\nexpensive and have limited in-depth circuit analysis for smaller models. In\nthis study, we propose Accelerated Path Patching (APP), a hybrid approach\nleveraging our novel contrastive attention head pruning method to drastically\nreduce the search space of circuit discovery methods. Our Contrastive-FLAP\npruning algorithm uses techniques from causal mediation analysis to assign\nhigher pruning scores to task-specific attention heads, leading to higher\nperforming sparse models compared to traditional pruning techniques. Although\nContrastive-FLAP is successful at preserving task-specific heads that existing\npruning algorithms remove at low sparsity ratios, the circuits found by\nContrastive-FLAP alone are too large to satisfy the minimality constraint\nrequired in circuit analysis. APP first applies Contrastive-FLAP to reduce the\nsearch space on required for circuit discovery algorithms by, on average, 56\\%.\nNext, APP, applies traditional Path Patching on the remaining attention heads,\nleading to a speed up of 59.63\\%-93.27\\% compared to Path Patching applied to\nthe dense model. Despite the substantial computational saving that APP\nprovides, circuits obtained from APP exhibit substantial overlap and similar\nperformance to previously established Path Patching circuits"}
{"id": "2511.05396", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.05396", "abs": "https://arxiv.org/abs/2511.05396", "authors": ["Yiting He", "Zhishuai Liu", "Weixin Wang", "Pan Xu"], "title": "Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction", "comment": "53 pages, 6 figures, 3 tables. Published in Proceedings of the 42nd\n  International Conference on Machine Learning (ICML 2025)", "summary": "Off-dynamics reinforcement learning (RL), where training and deployment\ntransition dynamics are different, can be formulated as learning in a robust\nMarkov decision process (RMDP) where uncertainties in transition dynamics are\nimposed. Existing literature mostly assumes access to generative models\nallowing arbitrary state-action queries or pre-collected datasets with a good\nstate coverage of the deployment environment, bypassing the challenge of\nexploration. In this work, we study a more realistic and challenging setting\nwhere the agent is limited to online interaction with the training environment.\nTo capture the intrinsic difficulty of exploration in online RMDPs, we\nintroduce the supremal visitation ratio, a novel quantity that measures the\nmismatch between the training dynamics and the deployment dynamics. We show\nthat if this ratio is unbounded, online learning becomes exponentially hard. We\npropose the first computationally efficient algorithm that achieves sublinear\nregret in online RMDPs with $f$-divergence based transition uncertainties. We\nalso establish matching regret lower bounds, demonstrating that our algorithm\nachieves optimal dependence on both the supremal visitation ratio and the\nnumber of interaction episodes. Finally, we validate our theoretical results\nthrough comprehensive numerical experiments."}
{"id": "2511.05442", "categories": ["cs.LG", "cs.AI", "cs.CL", "68Uxx", "I.2.7; I.2.6; I.2.m"], "pdf": "https://arxiv.org/pdf/2511.05442", "abs": "https://arxiv.org/abs/2511.05442", "authors": ["Frauke Andersen", "William Rudman", "Ruochen Zhang", "Carsten Eickhoff"], "title": "APP: Accelerated Path Patching with Task-Specific Pruning", "comment": null, "summary": "Circuit discovery is a key step in many mechanistic interpretability\npipelines. Current methods, such as Path Patching, are computationally\nexpensive and have limited in-depth circuit analysis for smaller models. In\nthis study, we propose Accelerated Path Patching (APP), a hybrid approach\nleveraging our novel contrastive attention head pruning method to drastically\nreduce the search space of circuit discovery methods. Our Contrastive-FLAP\npruning algorithm uses techniques from causal mediation analysis to assign\nhigher pruning scores to task-specific attention heads, leading to higher\nperforming sparse models compared to traditional pruning techniques. Although\nContrastive-FLAP is successful at preserving task-specific heads that existing\npruning algorithms remove at low sparsity ratios, the circuits found by\nContrastive-FLAP alone are too large to satisfy the minimality constraint\nrequired in circuit analysis. APP first applies Contrastive-FLAP to reduce the\nsearch space on required for circuit discovery algorithms by, on average, 56\\%.\nNext, APP, applies traditional Path Patching on the remaining attention heads,\nleading to a speed up of 59.63\\%-93.27\\% compared to Path Patching applied to\nthe dense model. Despite the substantial computational saving that APP\nprovides, circuits obtained from APP exhibit substantial overlap and similar\nperformance to previously established Path Patching circuits"}
{"id": "2511.05460", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.05460", "abs": "https://arxiv.org/abs/2511.05460", "authors": ["Sarkar Snigdha Sarathi Das", "Palash Goyal", "Mihir Parmar", "Yiwen Song", "Long T. Le", "Lesly Miculicich", "Jinsung Yoon", "Rui Zhang", "Hamid Palangi", "Tomas Pfister"], "title": "Synapse: Adaptive Arbitration of Complementary Expertise in Time Series Foundational Models", "comment": "19 pages, 7 figures, 4 tables", "summary": "Pre-trained Time Series Foundational Models (TSFMs) represent a significant\nadvance, capable of forecasting diverse time series with complex\ncharacteristics, including varied seasonalities, trends, and long-range\ndependencies. Despite their primary goal of universal time series forecasting,\ntheir efficacy is far from uniform; divergent training protocols and data\nsources cause individual TSFMs to exhibit highly variable performance across\ndifferent forecasting tasks, domains, and horizons. Leveraging this\ncomplementary expertise by arbitrating existing TSFM outputs presents a\ncompelling strategy, yet this remains a largely unexplored area of research. In\nthis paper, we conduct a thorough examination of how different TSFMs exhibit\nspecialized performance profiles across various forecasting settings, and how\nwe can effectively leverage this behavior in arbitration between different time\nseries models. We specifically analyze how factors such as model selection and\nforecast horizon distribution can influence the efficacy of arbitration\nstrategies. Based on this analysis, we propose Synapse, a novel arbitration\nframework for TSFMs. Synapse is designed to dynamically leverage a pool of\nTSFMs, assign and adjust predictive weights based on their relative,\ncontext-dependent performance, and construct a robust forecast distribution by\nadaptively sampling from the output quantiles of constituent models.\nExperimental results demonstrate that Synapse consistently outperforms other\npopular ensembling techniques as well as individual TSFMs, demonstrating\nSynapse's efficacy in time series forecasting."}
{"id": "2511.04707", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04707", "abs": "https://arxiv.org/abs/2511.04707", "authors": ["Rishi Rajesh Shah", "Chen Henry Wu", "Shashwat Saxena", "Ziqian Zhong", "Alexander Robey", "Aditi Raghunathan"], "title": "Jailbreaking in the Haystack", "comment": null, "summary": "Recent advances in long-context language models (LMs) have enabled\nmillion-token inputs, expanding their capabilities across complex tasks like\ncomputer-use agents. Yet, the safety implications of these extended contexts\nremain unclear. To bridge this gap, we introduce NINJA (short for\nNeedle-in-haystack jailbreak attack), a method that jailbreaks aligned LMs by\nappending benign, model-generated content to harmful user goals. Critical to\nour method is the observation that the position of harmful goals play an\nimportant role in safety. Experiments on standard safety benchmark, HarmBench,\nshow that NINJA significantly increases attack success rates across\nstate-of-the-art open and proprietary models, including LLaMA, Qwen, Mistral,\nand Gemini. Unlike prior jailbreaking methods, our approach is low-resource,\ntransferable, and less detectable. Moreover, we show that NINJA is\ncompute-optimal -- under a fixed compute budget, increasing context length can\noutperform increasing the number of trials in best-of-N jailbreak. These\nfindings reveal that even benign long contexts -- when crafted with careful\ngoal positioning -- introduce fundamental vulnerabilities in modern LMs."}
{"id": "2511.05311", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05311", "abs": "https://arxiv.org/abs/2511.05311", "authors": ["Valeriu Dimidov", "Faisal Hawlader", "Sasan Jafarnejad", "Raphaël Frank"], "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "comment": null, "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities."}
