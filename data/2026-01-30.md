<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 1]
- [cs.AI](#cs.AI) [Total: 12]
- [cs.LG](#cs.LG) [Total: 15]
- [cs.CR](#cs.CR) [Total: 4]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Interpreting Emergent Extreme Events in Multi-Agent Systems](https://arxiv.org/abs/2601.20538)
*Ling Tang,Jilin Mei,Dongrui Liu,Chen Qian,Dawei Cheng,Jing Shao,Xia Hu*

Main category: cs.MA

TL;DR: 다중 에이전트 시스템에서의 극단적 사건을 설명하기 위한 첫 번째 프레임워크를 제안.


<details>
  <summary>Details</summary>
Motivation: 극단적 사건의 기원을 이해하는 것은 시스템의 안전성을 위해 필수적이다.

Method: Shapley 가치를 적용하여 각 에이전트의 행동이 극단적 사건 발생에 기여하는 정도를 평가한다.

Result: 다양한 다중 에이전트 시스템 시나리오에서 우리의 프레임워크의 효과성을 검증했다.

Conclusion: 극단적 현상의 발생에 대한 일반적인 통찰력을 제공한다.

Abstract: Large language model-powered multi-agent systems have emerged as powerful tools for simulating complex human-like systems. The interactions within these systems often lead to extreme events whose origins remain obscured by the black box of emergence. Interpreting these events is critical for system safety. This paper proposes the first framework for explaining emergent extreme events in multi-agent systems, aiming to answer three fundamental questions: When does the event originate? Who drives it? And what behaviors contribute to it? Specifically, we adapt the Shapley value to faithfully attribute the occurrence of extreme events to each action taken by agents at different time steps, i.e., assigning an attribution score to the action to measure its influence on the event. We then aggregate the attribution scores along the dimensions of time, agent, and behavior to quantify the risk contribution of each dimension. Finally, we design a set of metrics based on these contribution scores to characterize the features of extreme events. Experiments across diverse multi-agent system scenarios (economic, financial, and social) demonstrate the effectiveness of our framework and provide general insights into the emergence of extreme phenomena.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Insight Agents: An LLM-Based Multi-Agent System for Data Insights](https://arxiv.org/abs/2601.20048)
*Jincheng Bai,Zhenyu Zhang,Jennifer Zhang,Zhihuai Zhu*

Main category: cs.AI

TL;DR: E-commerce 판매자를 위한 Insight Agents (IA)를 개발하여 데이터 인사이트를 자동으로 제공하는 시스템을 소개한다.


<details>
  <summary>Details</summary>
Motivation: E-commerce 판매자는 다양한 도구와 프로그램을 이용하는 데 어려움을 겪고 있으며, 이를 해결하기 위한 개인화된 데이터와 비즈니스 인사이트의 필요성이 있다.

Method: 이 논문에서는 계획-실행 패러다임에 기반한 LLM 지원 엔드투엔드 에이전트 시스템을 소개하며, 계층적 다중 에이전트 구조와 함께 OOD 탐지 및 BERT 기반 분류기를 사용한 간단한 ML 솔루션을 설계했다.

Result: 미국의 Amazon 판매자를 위해 출시된 IA는 인간 평가를 바탕으로 90%의 높은 정확도를 달성하고, P90 지연 시간은 15초 이하이다.

Conclusion: IA는 판매자들의 비즈니스 결정 속도를 높이고 노력의 부담을 줄임으로써 판매자들의 채택을 촉진할 것으로 예상된다.

Abstract: Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this novel LLM-backed end-to-end agentic system built on a plan-and-execute paradigm and designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 90% based on human evaluation, with latency of P90 below 15s.

</details>


### [3] [Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control](https://arxiv.org/abs/2601.20090)
*Amirmohammad Farzaneh,Salvatore D'Oro,Osvaldo Simeone*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM) 기반 에이전트가 사용자 의도를 다른 방식으로 표현했을 때의 결과를 탐색할 수 있는 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 사용자들이 결과를 관찰한 후 다른 방식으로 의도를 표현했더라면 어떻게 되었을까 궁금해 할 수 있습니다.

Method: 사용자, LLM 기반 에이전트 및 환경 간의 폐쇄 루프 상호작용을 구조적 인과 모델(SCM)로 모델링하고, 확률적 유도를 통해 여러 후보 비가상 결과를 생성합니다.

Result: 제안된 적합성 비가상 생성(CCG)은 오프라인 교정 단계를 통해 높은 확률로 진정한 비가상 결과를 포함하는 비가상 결과 집합을 생성합니다.

Conclusion: CCG는 무선 네트워크 제어 사례에서 성능을 입증하며, 단순 재실행 기준선에 비해 상당한 장점을 보여줍니다.

Abstract: Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enables such counterfactual reasoning in agentic LLM-driven control scenarios, while providing formal reliability guarantees. Our approach models the closed-loop interaction between a user, an LLM-based agent, and an environment as a structural causal model (SCM), and leverages test-time scaling to generate multiple candidate counterfactual outcomes via probabilistic abduction. Through an offline calibration phase, the proposed conformal counterfactual generation (CCG) yields sets of counterfactual outcomes that are guaranteed to contain the true counterfactual outcome with high probability. We showcase the performance of CCG on a wireless network control use case, demonstrating significant advantages compared to naive re-execution baselines.

</details>


### [4] [Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis](https://arxiv.org/abs/2601.20206)
*Zixuan Xiao,Chunguang Hu,Jun Ma*

Main category: cs.AI

TL;DR: 이 연구는 도시 공원 개발 모니터링을 위한 다중 모달 LLM 에이전트 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 신규 공원 건설의 개발 모니터링은 도시 계획 효과 평가 및 자원 배분 최적화를 위해 중요하다.

Method: 다중 모달 LLM 에이전트 프레임워크를 구축하여 LLM의 의미 이해 및 추론 능력을 활용하고, 수평 및 수직 데이터 정렬 메커니즘을 설계하였다.

Result: 이 접근법은 강력한 다중 모달 정보 융합 및 분석을 가능하게 하여 도시 공원 개발 모니터링의 다양한 요구에 맞춘 신뢰할 수 있고 확장 가능한 솔루션을 제공한다.

Conclusion: 우리의 접근법은 다양한 응용 시나리오에 대해 유연한 분석 기능을 제공하여 도시 공원 개발 모니터링의 현재 요구를 충족할 수 있다.

Abstract: As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on remote sensing imagery have obvious limitations in high-level and intelligent analysis, and thus are difficult to meet the requirements of current urban planning and management. In face of the growing demand for complex multi-modal data analysis in urban park development monitoring, these methods often fail to provide flexible analysis capabilities for diverse application scenarios. This study proposes a multi-modal LLM agent framework, which aims to make full use of the semantic understanding and reasoning capabilities of LLM to meet the challenges in urban park development monitoring. In this framework, a general horizontal and vertical data alignment mechanism is designed to ensure the consistency and effective tracking of multi-modal data. At the same time, a specific toolkit is constructed to alleviate the hallucination issues of LLM due to the lack of domain-specific knowledge. Compared to vanilla GPT-4o and other agents, our approach enables robust multi-modal information fusion and analysis, offering reliable and scalable solutions tailored to the diverse and evolving demands of urban park development monitoring.

</details>


### [5] [Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.20221)
*Hang Zhang,Ruheng Wang,Yuelyu Ji,Mingu Kwak,Xizhi Wu,Chenyu Li,Li Zhang,Wenqi Shi,Yifan Peng,Yanshan Wang*

Main category: cs.AI

TL;DR: 본 연구에서는 의료 추론 검증을 위한 새로운 방법인 $	ext{method}$를 제안하며, 이는 반복 질의를 통해 외부 의료 코퍼스를 활용하여 기존의 보상 모델의 한계를 극복하도록 설계되었습니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 의료 추론에서 좋은 성과를 내고 있지만, 임상 환경에서의 적용을 위해서는 사실 정확성을 보장하기 위한 철저한 검증이 필요하다.

Method: 의료 추론 검증자를 훈련시켜 평가 중 외부 의료 코퍼스를 반복적으로 질의하도록 하는 에이전틱 프레임워크인 $	ext{method}$를 도입했다.

Result: 네 가지 의료 추론 벤치마크에서 기존 방법들보다 상당한 성과 향상을 이루었고, MedQA의 정확도를 23.5%, MedXpertQA를 32.0% 개선하였다.

Conclusion: 동적으로 검색된 증거에 기반한 검증이 보다 신뢰할 수 있는 의료 추론 시스템으로 가는 원칙적인 경로를 제시한다.

Abstract: Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\method$ demonstrates an $\mathbf{8\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.

</details>


### [6] [ECG-Agent: On-Device Tool-Calling Agent for ECG Multi-Turn Dialogue](https://arxiv.org/abs/2601.20323)
*Hyunseung Chung,Jungwoo Oh,Daeun Kyung,Jiho Kim,Yeonsu Kwon,Min-Gyu Kim,Edward Choi*

Main category: cs.AI

TL;DR: ECG-Agent는 다중 턴 ECG 대화를 위한 최초의 LLM 기반 도구 호출 에이전트로, ECG 측정의 정확한 이해와 장치에서의 효율성을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 다중 모달 대형 언어 모델은 ECG 분류 및 보고서 생성에서 성과가 있었지만, 실제 상황에서 다중 턴 대화 능력과 정확한 ECG 측정 이해가 부족하였습니다.

Method: 우리는 ECG-Agent를 도입하고, 다양한 ECG 리드 구성을 위한 사실적인 사용자-보조자 다중 턴 대화를 포함하는 ECG-Multi-Turn-Dialogue (ECG-MTD) 데이터셋을 제시합니다.

Result: 실험 결과, ECG-Agent는 응답 정확도에서 베이스라인 ECG-LLM을 초월하며, 장치 기반 에이전트는 다양한 평가에서 대형 에이전트와 유사한 성능을 보였습니다.

Conclusion: ECG-Agent는 실제 응용을 위한 가능성을 보여줍니다.

Abstract: Recent advances in Multimodal Large Language Models have rapidly expanded to electrocardiograms, focusing on classification, report generation, and single-turn QA tasks. However, these models fall short in real-world scenarios, lacking multi-turn conversational ability, on-device efficiency, and precise understanding of ECG measurements such as the PQRST intervals. To address these limitations, we introduce ECG-Agent, the first LLM-based tool-calling agent for multi-turn ECG dialogue. To facilitate its development and evaluation, we also present ECG-Multi-Turn-Dialogue (ECG-MTD) dataset, a collection of realistic user-assistant multi-turn dialogues for diverse ECG lead configurations. We develop ECG-Agents in various sizes, from on-device capable to larger agents. Experimental results show that ECG-Agents outperform baseline ECG-LLMs in response accuracy. Furthermore, on-device agents achieve comparable performance to larger agents in various evaluations that assess response accuracy, tool-calling ability, and hallucinations, demonstrating their viability for real-world applications.

</details>


### [7] [AMA: Adaptive Memory via Multi-Agent Collaboration](https://arxiv.org/abs/2601.20352)
*Weiquan Huang,Zixuan Wang,Hehai Lin,Sudong Wang,Bo Xu,Qian Li,Beier Zhu,Linyi Yang,Chengwei Qin*

Main category: cs.AI

TL;DR: AMA는 다중 에이전트를 활용하여 다양한 메모리 크기에서 기억을 관리하는 새로운 프레임워크로, 메모리 일관성을 유지하고 논리적 모순을 줄입니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 발전으로 인해 장기 상호작용과 복잡한 추론을 지원하는 강력한 메모리 시스템의 필요성이 대두되고 있습니다.

Method: Adaptive Memory via Multi-Agent Collaboration (AMA)라는 새로운 프레임워크를 제안하며, 이는 협조된 에이전트를 활용하여 여러 크기에서 메모리를 관리합니다. AMA는 계층적 메모리 설계를 통해 검색 그레인과 작업 복잡성을 동적으로 정렬합니다.

Result: AMA는 도전적인 긴 문맥 벤치마크에서 기존의 최첨단 모델들을 크게 능가하며, 전체 문맥 방법과 비교하여 토큰 소비를 약 80% 줄입니다.

Conclusion: AMA는 검색 정확성과 장기 메모리 일관성을 유지하는 데 있어 그 효과성을 입증합니다.

Abstract: The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.

</details>


### [8] [OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution](https://arxiv.org/abs/2601.20380)
*Le Zhang,Yixiong Xiao,Xinjiang Lu,Jingjia Cao,Yusai Zhao,Jingbo Zhou,Lang An,Zikan Feng,Wanxiang Sha,Yu Shi,Congxi Xiao,Jian Xiong,Yankai Zhang,Hua Wu,Haifeng Wang*

Main category: cs.AI

TL;DR: OmegaUse는 모바일 및 데스크톱 플랫폼에서 자율 작업 실행을 위한 범용 GUI 에이전트 모델로, 고품질 데이터와 효과적인 훈련 방법을 바탕으로 높은 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: GUI 에이전트는 실제 작업을 수행하는 데 있어 기초 모델이 놀라운 잠재력을 발휘할 수 있도록 하여 인간-컴퓨터 상호작용을 혁신하고 인간의 생산성을 향상시키는 데 기여할 수 있다.

Method: 정확하게 구조화된 데이터 구축 파이프라인과 분리된 훈련 패러다임을 도입하여 GUI 에이전트 모델을 구축한다. 데이터 구축을 위해 엄격하게 선별된 오픈소스 데이터셋을 활용하며, 하향식 분류법에 기반한 생성과 상향식 자율 탐색을 통합하여 고충실도의 합성 데이터를 생성하는 새로운 자동 합성 프레임워크를 제시한다. 훈련은 두 단계 전략을 채택하여 기본 상호작용 구문을 확립한 후 공간적 기초와 순서 계획을 개선하기 위해 그룹 상대 정책 최적화(GRPO)를 사용한다. 또한, 효율성과 reasoning 능력을 동시에 고려하기 위해 OmegaUse는 전문가 혼합(MoE) 백본에 구축된다.

Result: 광범위한 실험 결과, OmegaUse는 설정된 GUI 벤치마크에서 매우 경쟁력을 가지며, ScreenSpot-V2에서 96.3%의 최첨단 점수를 기록하고 AndroidControl에서 79.1%의 단계 성공률로 선두를 차지한다. OS-Nav에서도 강력한 성능을 보이며, ChiM-Nav에서 74.24%와 Ubu-Nav에서 평균 55.9%의 단계 성공률을 달성하였다.

Conclusion: 이 연구는 OmegaUse가 기존 GUI 벤치마크에서 경쟁력을 보여주며, 다양한 운영 체제에서의 능력을 평가하는 데 유용한 기준을 제공하고 있음을 보여준다.

Abstract: Graphical User Interface (GUI) agents show great potential for enabling foundation models to complete real-world tasks, revolutionizing human-computer interaction and improving human productivity. In this report, we present OmegaUse, a general-purpose GUI agent model for autonomous task execution on both mobile and desktop platforms, supporting computer-use and phone-use scenarios. Building an effective GUI agent model relies on two factors: (1) high-quality data and (2) effective training methods. To address these, we introduce a carefully engineered data-construction pipeline and a decoupled training paradigm. For data construction, we leverage rigorously curated open-source datasets and introduce a novel automated synthesis framework that integrates bottom-up autonomous exploration with top-down taxonomy-guided generation to create high-fidelity synthetic data. For training, to better leverage these data, we adopt a two-stage strategy: Supervised Fine-Tuning (SFT) to establish fundamental interaction syntax, followed by Group Relative Policy Optimization (GRPO) to improve spatial grounding and sequential planning. To balance computational efficiency with agentic reasoning capacity, OmegaUse is built on a Mixture-of-Experts (MoE) backbone. To evaluate cross-terminal capabilities in an offline setting, we introduce OS-Nav, a benchmark suite spanning multiple operating systems: ChiM-Nav, targeting Chinese Android mobile environments, and Ubu-Nav, focusing on routine desktop interactions on Ubuntu. Extensive experiments show that OmegaUse is highly competitive across established GUI benchmarks, achieving a state-of-the-art (SOTA) score of 96.3% on ScreenSpot-V2 and a leading 79.1% step success rate on AndroidControl. OmegaUse also performs strongly on OS-Nav, reaching 74.24% step success on ChiM-Nav and 55.9% average success on Ubu-Nav.

</details>


### [9] [Normative Equivalence in human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups](https://arxiv.org/abs/2601.20487)
*Nico Mutzner,Taha Yasseri,Heiko Rauhut*

Main category: cs.AI

TL;DR: 이 연구는 AI 에이전트가 소규모 그룹 내에서 협력적 사회 규범에 미치는 영향을 분석합니다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트를 포함한 그룹 설정에서 협력적 사회 규범에 대한 이해의 부족을 해소하기 위해 이 연구를 수행했습니다.

Method: 온라인 실험을 통해 반복적인 4인 공공재 게임(PGG)을 사용했습니다. 각각의 그룹은 인간 3명과 AI 또는 인간으로 프레이밍된 봇 1명으로 구성되었으며, 세 가지 사전 정의된 결정 전략 중 하나를 따랐습니다.

Result: 236명의 참여자 샘플을 분석한 결과, 협력은 상호작용의 역동성과 행동 관성에 의해 주로 유도되었으며, 협력 수준은 인간과 AI 레이블 간에 유의미한 차이가 없었습니다.

Conclusion: 협력의 지속성이나 참여자의 규범적 인식에서 차이가 나타나지 않아, 협력은 파트너의 정체성이 아닌 그룹 행동에 따라 결정된다는 것을 나타냈습니다.

Abstract: The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner's Dilemma, or in participants' normative perceptions. Participants' behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making.

</details>


### [10] [PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs](https://arxiv.org/abs/2601.20539)
*Oguzhan Gungordu,Siheng Xiong,Faramarz Fekri*

Main category: cs.AI

TL;DR: 이 논문은 기존 자동 휴리스틱 설계 프레임워크의 한계를 극복하기 위한 새로운 다중 에이전트 추론 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 자동 휴리스틱 설계 프레임워크의 고정된 진화 규칙 및 정적 프롬프트 템플릿에 의존하는 문제점을 해결하고자 한다.

Method: PathWise라는 새로운 프레임워크는 휴리스틱 생성을 추론 그래프에 대한 순차적 결정 과정으로 수립하며, 이를 통해 과거 결정사항을 이어받고 정보 활용 및 회피가 가능하다.

Result: 다양한 조합 최적화 문제에 대한 실험 결과, PathWise는 더 나은 휴리스틱으로 더 빠르게 수렴하고, 다양한 LLM 백본에서 일반화되며, 더 큰 문제 크기로 확장된다.

Conclusion: 이 연구는 LLM 기반 자동 휴리스틱 설계가 단순한 시행착오에서 벗어나 상태 인식 계획으로 전환될 수 있음을 보여준다.

Abstract: Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.

</details>


### [11] [Investigating the Development of Task-Oriented Communication in Vision-Language Models](https://arxiv.org/abs/2601.20641)
*Boaz Carmeli,Orr Paradise,Shafi Goldwasser,Yonatan Belinkov,Ron Meir*

Main category: cs.AI

TL;DR: 이 연구는 LLM 기반 에이전트가 협력적 추론 작업에서 표준 자연어와 다른 작업 지향 커뮤니케이션 프로토콜을 개발할 수 있는지 조사한다.


<details>
  <summary>Details</summary>
Motivation: 작업 지향 프로토콜이 지닐 수 있는 두 가지 핵심 속성인 효율성과 비가시성을 탐구하고자 한다.

Method: 비전-언어 모델(VLM) 에이전트가 서로 소통하는 참조 게임 프레임워크를 이용하여 언어 변형을 평가하기 위한 통제되고 측정 가능한 환경을 제공한다.

Result: 실험 결과, VLM이 효과적이고 작업에 적합한 커뮤니케이션 패턴을 개발할 수 있으며, 인간과 외부 에이전트가 해석하기 어려운 비가시적 프로토콜도 개발할 수 있음을 확인하였다.

Conclusion: 이 연구는 작업 지향 커뮤니케이션의 잠재력과 위험성을 모두 강조하며, 참조 게임이 이 분야의 미래 연구에 유용한 실험대임을 강조한다.

Abstract: We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.

</details>


### [12] [MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents](https://arxiv.org/abs/2601.20831)
*Vishnu Sashank Dorbala,Dinesh Manocha*

Main category: cs.AI

TL;DR: MemCtrl는 멀티모달 대형 언어 모델을 이용하여 온라인에서 메모리를 효율적으로 다루는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 메모리 시스템은 제한된 기억 용량으로 인해 신체화된 에이전트의 요구를 충족하지 못하고 있다.

Method: MemCtrl는 훈련 가능한 메모리 헤드 μ를 사용하여 탐색 과정에서 어떤 관찰이나 반성을 유지, 업데이트 또는 폐기할지를 결정한다.

Result: μ로 보강된 MLLM은 임베디드 작업 완료 능력이 평균 16% 향상되었고, 특정 지침 하위 집합에서는 20% 이상 향상되었다.

Conclusion: μ로 보강된 MLLM은 긴 복잡한 지침 유형에서 우수한 성능을 보였다.

Abstract: Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head μthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of μ, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on μ-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that μ-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by μ, noting the superior performance of μaugmented MLLMs on long and complex instruction types.

</details>


### [13] [Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)](https://arxiv.org/abs/2601.20843)
*Saurav Prateek*

Main category: cs.AI

TL;DR: 이 논문은 Parallel Scaling 패러다임의 본질적인 한계를 해결하여 복잡한 박사 수준 주제에 대한 상세한 연구 보고서를 생성하도록 설계된 새로운 Deep Researcher 아키텍처를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: Parallel Scaling 패러다임의 한계를 해결하기 위해.

Method: Sequential Research Plan Refinement와 Candidates Crossover 알고리즘을 사용하여 연구 계획을 세밀하게 수정하고 효율적인 검색을 수행.

Result: DeepResearch Bench에서 100개의 박사 수준 연구 과제를 평가한 결과, 46.21 점을 기록하여 Claude Researcher 등 타깃보다 우수한 성능을 발휘했습니다.

Conclusion: Sequential Scaling이 Parallel Self Consistency 패러다임보다 일관되게 우수한 성과를 내는 것을 강화함.

Abstract: This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [oculomix: Hierarchical Sampling for Retinal-Based Systemic Disease Prediction](https://arxiv.org/abs/2601.19939)
*Hyunmin Kim,Yukun Zhou,Rahul A. Jonas,Lie Ju,Sunjin Hwang,Pearse A. Keane,Siegfried K. Wagner*

Main category: cs.LG

TL;DR: Oculomics는 망막 이미징을 통해 심혈관 질환 및 치매와 같은 전신 질환을 예측하는 개념으로, RETFound와 같은 트랜스포머 기반 모델 덕분에 신속히 발전하고 있다. 기존 데이터 증강 방법은 환자 특성에 영향을 미치므로, Oculomix라는 새로운 계층적 샘플링 전략을 제안하여 이러한 한계를 극복하고자 한다.


<details>
  <summary>Details</summary>
Motivation: Oculomics는 망막 이미징을 통해 전신 질환을 예측할 수 있는 가능성에 대한 연구가 증가하고 있으며, 이는 효과적인 데이터 처리 방법에 의해 가속화되고 있다.

Method: Oculomix는 같은 환자에서 동일한 시간에 획득한 이미지를 바탕으로 환자 및 검사 수준에서 혼합 샘플 증강을 위한 계층적 샘플링 전략이다.

Result: Oculomix는 대규모 인종적으로 다양한 집단에서 심각한 심혈관 사건의 5년 예측을 위해 ViT 모델을 사용하여 검증되었으며, 기존 CutMix 및 MixUp보다 AUROC에서 최대 3% 우수한 성능을 보였다.

Conclusion: 제안된 방법의 필요성과 가치는 Oculomics 분야에서 특별히 잘 드러난다.

Abstract: Oculomics - the concept of predicting systemic diseases, such as cardiovascular disease and dementia, through retinal imaging - has advanced rapidly due to the data efficiency of transformer-based foundation models like RETFound. Image-level mixed sample data augmentations, such as CutMix and MixUp, are frequently used for training transformers, yet these techniques perturb patient-specific attributes, such as medical comorbidity and clinical factors, since they only account for images and labels. To address this limitation, we propose a hierarchical sampling strategy, Oculomix, for mixed sample augmentations. Our method is based on two clinical priors. First (exam level), images acquired from the same patient at the same time point share the same attributes. Second (patient level), images acquired from the same patient at different time points have a soft temporal trend, as morbidity generally increases over time. Guided by these priors, our method constrains the mixing space to the patient and exam levels to better preserve patient-specific characteristics and leverages their hierarchical relationships. The proposed method is validated using ViT models on a five-year prediction of major adverse cardiovascular events (MACE) in a large ethnically diverse population (Alzeye). We show that Oculomix consistently outperforms image-level CutMix and MixUp by up to 3% in AUROC, demonstrating the necessity and value of the proposed method in oculomics.

</details>


### [15] [MeanCache: From Instantaneous to Average Velocity for Accelerating Flow Matching Inference](https://arxiv.org/abs/2601.19961)
*Huanlin Gao,Ping Chen,Fuyuan Shi,Ruijia Wu,Li YanTao,Qiang Hui,Yuren You,Ting Lu,Chao Tan,Shaoan Zhao,Zhaoxiang Liu,Fang Zhao,Kai Wang,Shiguo Lian*

Main category: cs.LG

TL;DR: MeanCache는 훈련이 필요 없는 캐싱 프레임워크로, 효율적인 Flow Matching 추론을 위한 것이다. 이 방법은 고속에서의 오차 축적 문제를 해결하고, 기존 캐쉬 방법에 비해 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 효율적인 Flow Matching 추론의 필요성이 증가하고 있으며, 기존 방법들은 순간 속도 정보에 의존하여 문제를 일으킨다.

Method: MeanCache는 평균 속도를 활용하여 순간 속도에서 간격 평균 속도를 구성하며, 이를 위해 캐시된 Jacobian-벡터 곱(JVP)을 이용한다.

Result: FLUX.1, Qwen-Image, HunyuanVideo 실험에서 MeanCache가 각각 4.12X, 4.56X, 3.59X 가속을 달성함을 보여주었다.

Conclusion: MeanCache는 Flow Matching 추론을 위한 새로운 관점을 제공하며, 상업적 규모의 생성 모델에서 안정성 기반 가속에 대한 추가적인 탐색을 촉진할 것이다.

Abstract: We present MeanCache, a training-free caching framework for efficient Flow Matching inference. Existing caching methods reduce redundant computation but typically rely on instantaneous velocity information (e.g., feature caching), which often leads to severe trajectory deviations and error accumulation under high acceleration ratios. MeanCache introduces an average-velocity perspective: by leveraging cached Jacobian--vector products (JVP) to construct interval average velocities from instantaneous velocities, it effectively mitigates local error accumulation. To further improve cache timing and JVP reuse stability, we develop a trajectory-stability scheduling strategy as a practical tool, employing a Peak-Suppressed Shortest Path under budget constraints to determine the schedule. Experiments on FLUX.1, Qwen-Image, and HunyuanVideo demonstrate that MeanCache achieves 4.12X and 4.56X and 3.59X acceleration, respectively, while consistently outperforming state-of-the-art caching baselines in generation quality. We believe this simple yet effective approach provides a new perspective for Flow Matching inference and will inspire further exploration of stability-driven acceleration in commercial-scale generative models.

</details>


### [16] [Distributional value gradients for stochastic environments](https://arxiv.org/abs/2601.20071)
*Baptiste Debes,Tinne Tuytelaars*

Main category: cs.LG

TL;DR: 이 논문은 확률적 환경에서의 한계를 극복하기 위해 분포 강화 학습에 기반한 새로운 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 기법들은 확률적이거나 노이즈가 있는 환경에서 적용의 한계가 있으며, 이러한 한계를 극복할 필요가 있습니다.

Method: 연속 상태-행동 공간에서의 분포 강화 학습을 확장하여 스칼라 상태-행동 가치 함수의 분포뿐만 아니라 그 기울기 분포를 모델링하는 방법인 분포 Sobolev 훈련을 제안합니다.

Result: 제안된 방법은 첫째로 간단한 확률적 강화 학습 장난감 문제에서의 효과성을 보여주고, 둘째로 여러 MuJoCo 환경에서의 성능을 벤치마킹합니다.

Conclusion: Sobolev 증강 Bellman 연산자는 고유한 고정점을 가진 수축 연산자임을 증명하고, 기울기에 민감한 강화 학습에서 수축의 근본적인 매끄러움 절충을 강조합니다.

Abstract: Gradient-regularized value learning methods improve sample efficiency by leveraging learned models of transition dynamics and rewards to estimate return gradients. However, existing approaches, such as MAGE, struggle in stochastic or noisy environments, limiting their applicability. In this work, we address these limitations by extending distributional reinforcement learning on continuous state-action spaces to model not only the distribution over scalar state-action value functions but also over their gradients. We refer to this approach as Distributional Sobolev Training. Inspired by Stochastic Value Gradients (SVG), our method utilizes a one-step world model of reward and transition distributions implemented via a conditional Variational Autoencoder (cVAE). The proposed framework is sample-based and employs Max-sliced Maximum Mean Discrepancy (MSMMD) to instantiate the distributional Bellman operator. We prove that the Sobolev-augmented Bellman operator is a contraction with a unique fixed point, and highlight a fundamental smoothness trade-off underlying contraction in gradient-aware RL. To validate our method, we first showcase its effectiveness on a simple stochastic reinforcement learning toy problem, then benchmark its performance on several MuJoCo environments.

</details>


### [17] [Meta-Cognitive Reinforcement Learning with Self-Doubt and Recovery](https://arxiv.org/abs/2601.20193)
*Zhipeng Zhang,Wenting Ma,Kai Li,Meng Guo,Lei Yang,Wei Yu,Hongji Cui,Yichen Zhang,Mo Zhang,Jinzhe Lin,Zhenjie Yao*

Main category: cs.LG

TL;DR: 이 논문에서는 메타 인지 강화 학습 프레임워크를 제안하여 에이전트가 자신의 학습 행동의 신뢰성을 평가하고 조정할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 강화 학습 방법들은 신뢰할 수 없는 경험이나 부적절한 보상을 억제하는 데 초점을 두고 있지만, 자신의 학습 과정의 신뢰성을 평가할 수 있는 능력이 부족하다.

Method: 제안한 방법은 가치 예측 오류 안정성(VPES)에 의해 구동되는 메타 신뢰 변수를 도입하여 학습 동역학을 안전하게 조절하고 신뢰를 점진적으로 회복하는 방식을 사용한다.

Result: 실험에서는 보상 손상이 있는 계속적 제어 벤치마크에서 회복 기능이 가능한 메타 인지 제어가 높은 평균 수익을 달성하고 강력한 강건성 기준선에 비해 후기 훈련 실패를 크게 줄임을 보여준다.

Conclusion: 이 연구는 메타 인지 강화 학습이 불확실성을 처리하는 데 효과적이라는 것을 입증했다.

Abstract: Robust reinforcement learning methods typically focus on suppressing unreliable experiences or corrupted rewards, but they lack the ability to reason about the reliability of their own learning process. As a result, such methods often either overreact to noise by becoming overly conservative or fail catastrophically when uncertainty accumulates.
  In this work, we propose a meta-cognitive reinforcement learning framework that enables an agent to assess, regulate, and recover its learning behavior based on internally estimated reliability signals. The proposed method introduces a meta-trust variable driven by Value Prediction Error Stability (VPES), which modulates learning dynamics via fail-safe regulation and gradual trust recovery.
  Experiments on continuous-control benchmarks with reward corruption demonstrate that recovery-enabled meta-cognitive control achieves higher average returns and significantly reduces late-stage training failures compared to strong robustness baselines.

</details>


### [18] [Spark: Strategic Policy-Aware Exploration via Dynamic Branching for Long-Horizon Agentic Learning](https://arxiv.org/abs/2601.20209)
*Jinyang Wu,Shuo Yang,Changpeng Yang,Yuhao Shen,Shuai Zhang,Zhengqi Wen,Jianhua Tao*

Main category: cs.LG

TL;DR: 강화 학습이 대형 언어 모델을 지능형 에이전트로 만드는 데 도움을 주지만, 자원 부족 상황에서 장기 과제를 훈련하는 것은 여전히 도전적이다. 본 연구에서는 주요 의사 결정 상태에서 선택적으로 분기하여 자원 효율적인 탐사를 위한 새로운 프레임워크인 	extbf{Spark}를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 지능형 에이전트로 기능하도록 강화 학습을 활용하였으나, 자원의 제한으로 인해 고품질 경로의 부족으로 장기 과제 훈련이 어려움.

Method: 중요한 의사 결정 지점에서 적응형 분기 탐사를 활성화하여 유망한 경로를 탐사하는 전략을 통해 자원을 효율적으로 할당하는 새로운 구조인 	extbf{Spark}를 제안하였다.

Result: 다양한 과제에 대한 실험은 	extsc{Spark}가 상당히 적은 훈련 샘플로 우수한 성공률을 달성하며, 보지 못한 상황에서도 강력한 일반화를 나타냄을 보여준다.

Conclusion: 이 설계는 에이전트의 본질적인 의사 결정 신호를 활용하여 인간의 사전 지식에 대한 의존도를 줄이고, 에이전트가 자율적으로 탐사를 확장하고 강력한 일반화를 이룰 수 있도록 한다.

Abstract: Reinforcement learning has empowered large language models to act as intelligent agents, yet training them for long-horizon tasks remains challenging due to the scarcity of high-quality trajectories, especially under limited resources. Existing methods typically scale up rollout sizes and indiscriminately allocate computational resources among intermediate steps. Such attempts inherently waste substantial computation budget on trivial steps while failing to guarantee sample quality. To address this, we propose \textbf{Spark} (\textbf{S}trategic \textbf{P}olicy-\textbf{A}ware explo\textbf{R}ation via \textbf{K}ey-state dynamic branching), a novel framework that selectively branches at critical decision states for resource-efficient exploration. Our key insight is to activate adaptive branching exploration at critical decision points to probe promising trajectories, thereby achieving precise resource allocation that prioritizes sampling quality over blind coverage. This design leverages the agent's intrinsic decision-making signals to reduce dependence on human priors, enabling the agent to autonomously expand exploration and achieve stronger generalization. Experiments across diverse tasks (e.g., embodied planning), demonstrate that \textsc{Spark} achieves superior success rates with significantly fewer training samples, exhibiting robust generalization even in unseen scenarios.

</details>


### [19] [A Learning-based Framework for Spatial Impulse Response Compensation in 3D Photoacoustic Computed Tomography](https://arxiv.org/abs/2601.20291)
*Kaiyi Yang,Seonyeong Park,Gangwon Jeong,Hsuan-Kai Huang,Alexander A. Oraevsky,Umberto Villa,Mark A. Anastasio*

Main category: cs.LG

TL;DR: 이 논문은 PACT 이미지 재구성을 위한 데이터 도메인에서 작동하는 학습된 SIR 보상 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 정확하지만 신속한 3D PACT 이미지 재구성의 필요성을 해결하기 위해.

Method: 데이터 도메인에서 작동하는 학습된 SIR 보상 방법 프레임워크를 제시하고, U-Net 모델과 Deconv-Net 모델 두 가지 변형을 사용할 것이다.

Result: 시뮬레이션 및 실제 유방 이미징 데이터에서 해상도 개선과 잡음 변동, 객체 복잡성, 음속 불균일성에 대한 견고성을 입증하였다.

Conclusion: 이 연구는 3D PACT 이미징에서 학습된 SIR 보상의 첫 번째 사례를 제시한다.

Abstract: Photoacoustic computed tomography (PACT) is a promising imaging modality that combines the advantages of optical contrast with ultrasound detection. Utilizing ultrasound transducers with larger surface areas can improve detection sensitivity. However, when computationally efficient analytic reconstruction methods that neglect the spatial impulse responses (SIRs) of the transducer are employed, the spatial resolution of the reconstructed images will be compromised. Although optimization-based reconstruction methods can explicitly account for SIR effects, their computational cost is generally high, particularly in three-dimensional (3D) applications. To address the need for accurate but rapid 3D PACT image reconstruction, this study presents a framework for establishing a learned SIR compensation method that operates in the data domain. The learned compensation method maps SIR-corrupted PACT measurement data to compensated data that would have been recorded by idealized point-like transducers. Subsequently, the compensated data can be used with a computationally efficient reconstruction method that neglects SIR effects. Two variants of the learned compensation model are investigated that employ a U-Net model and a specifically designed, physics-inspired model, referred to as Deconv-Net. A fast and analytical training data generation procedure is also a component of the presented framework. The framework is rigorously validated in virtual imaging studies, demonstrating resolution improvement and robustness to noise variations, object complexity, and sound speed heterogeneity. When applied to in-vivo breast imaging data, the learned compensation models revealed fine structures that had been obscured by SIR-induced artifacts. To our knowledge, this is the first demonstration of learned SIR compensation in 3D PACT imaging.

</details>


### [20] [TABED: Test-Time Adaptive Ensemble Drafting for Robust Speculative Decoding in LVLMs](https://arxiv.org/abs/2601.20357)
*Minjae Lee,Wonjun Kang,Byeongkeun Ahn,Christian Classen,Kevin Galim,Seunghyuk Oh,Minghao Yan,Hyung Il Koo,Kangwook Lee*

Main category: cs.LG

TL;DR: 본 연구에서는 이미지를 통해 텍스트 프롬프트를 처리하는 대형 비전-언어 모델에 대한 탐색이 부족한 가운데, Test-time Adaptive Batched Ensemble Drafting (TABED)이라는 새로운 방법을 제안하여 성능을 향상시키고 훈련 없이 비용을 최소화하는 방안을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 비전-언어 모델에 대한 탐색이 미비한 상황에서 기존 추론 방법을 벤치마킹하고, 특정 시나리오에 따라 달라지는 성능 변화를 관찰하여 TABED를 제안하게 되었다.

Method: TABED는 배치 추론을 통해 얻은 여러 초안을 동적으로 앙상블하고, SD 설정에서의 과거 진실 값과의 편차를 활용하여 성능을 향상시킨다.

Result: 이 방법은 자가 회귀 디코딩에 비해 평균적으로 1.74배의 속도 향상을 달성하고, 단일 초안 방식에 비해 5%의 성능 개선을 보였다.

Conclusion: TABED는 훈련이 필요 없으며, 매개변수 공유를 통해 앙상블 비용을 최소화하며, 다양한 고급 검증 및 대체 초안 방법을 통합하여 성능을 더욱 향상시킬 수 있다.

Abstract: Speculative decoding (SD) has proven effective for accelerating LLM inference by quickly generating draft tokens and verifying them in parallel. However, SD remains largely unexplored for Large Vision-Language Models (LVLMs), which extend LLMs to process both image and text prompts. To address this gap, we benchmark existing inference methods with small draft models on 11 datasets across diverse input scenarios and observe scenario-specific performance fluctuations. Motivated by these findings, we propose Test-time Adaptive Batched Ensemble Drafting (TABED), which dynamically ensembles multiple drafts obtained via batch inference by leveraging deviations from past ground truths available in the SD setting. The dynamic ensemble method achieves an average robust walltime speedup of 1.74x over autoregressive decoding and a 5% improvement over single drafting methods, while remaining training-free and keeping ensembling costs negligible through parameter sharing. With its plug-and-play compatibility, we further enhance TABED by integrating advanced verification and alternative drafting methods. Code and custom-trained models are available at https://github.com/furiosa-ai/TABED.

</details>


### [21] [Unsupervised Anomaly Detection in Multi-Agent Trajectory Prediction via Transformer-Based Models](https://arxiv.org/abs/2601.20367)
*Qing Lyu,Zhe Fu,Alexandre Bayen*

Main category: cs.LG

TL;DR: 자율주행을 위한 안전-critical 시나리오 식별은 필수적이나, 이러한 사건의 희귀성으로 감독된 라벨링은 비현실적이다. 전통적인 규칙 기반 메트릭은 복잡한 상호작용 위험을 포착하기에는 지나치게 단순하다. 이를 해결하기 위해 본 논문에서는 정상적인 주행을 모델링하고 예측 잔차를 통해 이탈을 측정하는 다중 에이전트 변환기 기반의 비감독 이상 탐지 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 안전-critical 시나리오 식별의 중요성과 기존 방법의 한계를 고려할 때, 자율주행 시스템의 안전성을 높이기 위한 새로운 접근 방법이 필요하다.

Method: 본 연구는 다중 에이전트 변환기 모델을 기반으로 하여 정상적인 주행을 모델링하고 예측 잔차를 통해 이상을 탐지하는 비감독 이상 탐지 프레임워크를 제안한다. 이중 평가 체계를 통해 탐지의 안정성과 물리적 정렬을 평가한다.

Result: 실험은 NGSIM 데이터셋에서 우리의 프레임워크가 최대 잔차 집계기를 통해 가장 높은 물리적 정렬을 유지하면서 안정성을 보장함을 보여준다. 또한, 388개의 고유한 이상을 식별하였고, 이는 Time-to-Collision 및 통계적 기준으로 놓쳤던 세밀한 다중 에이전트 위험을 포함한다.

Conclusion: 탐지된 이상은 네 가지 해석 가능한 위험 유형으로 추가 그룹화되어 시뮬레이션 및 테스트를 위한 실행 가능한 통찰력을 제공한다.

Abstract: Identifying safety-critical scenarios is essential for autonomous driving, but the rarity of such events makes supervised labeling impractical. Traditional rule-based metrics like Time-to-Collision are too simplistic to capture complex interaction risks, and existing methods lack a systematic way to verify whether statistical anomalies truly reflect physical danger. To address this gap, we propose an unsupervised anomaly detection framework based on a multi-agent Transformer that models normal driving and measures deviations through prediction residuals. A dual evaluation scheme has been proposed to assess both detection stability and physical alignment: Stability is measured using standard ranking metrics in which Kendall Rank Correlation Coefficient captures rank agreement and Jaccard index captures the consistency of the top-K selected items; Physical alignment is assessed through correlations with established Surrogate Safety Measures (SSM). Experiments on the NGSIM dataset demonstrate our framework's effectiveness: We show that the maximum residual aggregator achieves the highest physical alignment while maintaining stability. Furthermore, our framework identifies 388 unique anomalies missed by Time-to-Collision and statistical baselines, capturing subtle multi-agent risks like reactive braking under lateral drift. The detected anomalies are further clustered into four interpretable risk types, offering actionable insights for simulation and testing.

</details>


### [22] [LLM-AutoDP: Automatic Data Processing via LLM Agents for Model Fine-tuning](https://arxiv.org/abs/2601.20375)
*Wei Huang,Anda Cheng,Yinggui Wang,Lei Wang,Tao Wei*

Main category: cs.LG

TL;DR: LLM-AutoDP는 대규모 언어 모델(LLM)을 활용하여 데이터 처리 전략을 자동으로 생성 및 최적화하는 새로운 프레임워크로, 고품질의 처리 파이프라인에 도달할 수 있습니다.


<details>
  <summary>Details</summary>
Motivation: 특정 도메인 데이터에서의 성능 향상을 위해 LLM을 미세 조정할 때, 저품질 샘플로 가득한 데이터로 인해 효과적인 데이터 처리가 필요합니다.

Method: LLM-AutoDP는 LLM을 에이전트로 활용하여 자동으로 데이터 처리 전략을 생성하고 최적화하며, 후보 전략을 생성하고 피드백 신호 및 비교 평가를 통해 반복적으로 정제합니다.

Result: 우리의 프레임워크로 처리된 데이터로 훈련된 모델들이 처리되지 않은 데이터로 훈련된 모델보다 80% 이상의 승률을 기록했습니다. LLM 에이전트를 기반으로 한 AutoML 기준에 비해 LLM-AutoDP는 약 65%의 승률을 달성했습니다.

Conclusion: 또한 우리의 가속 기법들은 총 검색 시간을 최대 10배 줄이며 효과성과 효율성을 입증했습니다.

Abstract: Large Language Models (LLMs) can be fine-tuned on domain-specific data to enhance their performance in specialized fields. However, such data often contains numerous low-quality samples, necessitating effective data processing (DP). In practice, DP strategies are typically developed through iterative manual analysis and trial-and-error adjustment. These processes inevitably incur high labor costs and may lead to privacy issues in high-privacy domains like healthcare due to direct human access to sensitive data. Thus, achieving automated data processing without exposing the raw data has become a critical challenge. To address this challenge, we propose LLM-AutoDP, a novel framework that leverages LLMs as agents to automatically generate and optimize data processing strategies. Our method generates multiple candidate strategies and iteratively refines them using feedback signals and comparative evaluations. This iterative in-context learning mechanism enables the agent to converge toward high-quality processing pipelines without requiring direct human intervention or access to the underlying data. To further accelerate strategy search, we introduce three key techniques: Distribution Preserving Sampling, which reduces data volume while maintaining distributional integrity; Processing Target Selection, which uses a binary classifier to identify low-quality samples for focused processing; Cache-and-Reuse Mechanism}, which minimizes redundant computations by reusing prior processing results. Results show that models trained on data processed by our framework achieve over 80% win rates against models trained on unprocessed data. Compared to AutoML baselines based on LLM agents, LLM-AutoDP achieves approximately a 65% win rate. Moreover, our acceleration techniques reduce the total searching time by up to 10 times, demonstrating both effectiveness and efficiency.

</details>


### [23] [An explainable framework for the relationship between dementia and glucose metabolism patterns](https://arxiv.org/abs/2601.20480)
*C. Vázquez-García,F. J. Martínez-Murcia,F. Segovia Román,A. Forte,J. Ramírez,I. Illán,A. Hernández-Segura,C. Jiménez-Mesa,Juan M. Górriz*

Main category: cs.LG

TL;DR: 본 연구는 고차원 신경영상 데이터를 활용한 반지도 변분 오토인코더(VAE) 프레임워크를 제안하여 신경퇴행성 질환을 평가하는 데 도움을 줍니다.


<details>
  <summary>Details</summary>
Motivation: 고차원 신경영상 데이터에서 비선형 관계로 인한 신경퇴행성 질환 평가의 어려움을 해결하고자 합니다.

Method: 우리는 유연한 유사성 정규화 항을 가진 반지도 VAE 프레임워크를 제안하여 선택된 잠재 변수를 치매 진행의 임상 또는 바이오마커 측정과 정렬합니다.

Result: 이 방법을 사용하여 알츠하이머병 신경영상 이니셔티브(ADNI)의 PET 스캔을 활용하고, 인지 점수와 정렬된 첫 번째 잠재 차원을 안내합니다. 또한, 주요 지역에서의 대사 감소를 보여주는 복셀 단위 GLM 분석이 포함됩니다.

Conclusion: 우리의 프레임워크는 확립된 알츠하이머 바이오마커와 정렬된 질병 관련 패턴을 효과적으로 추출하여, 신경퇴행 진행 연구를 위한 해석 가능하고 적응 가능한 도구를 제공합니다.

Abstract: High-dimensional neuroimaging data presents challenges for assessing neurodegenerative diseases due to complex non-linear relationships. Variational Autoencoders (VAEs) can encode scans into lower-dimensional latent spaces capturing disease-relevant features. We propose a semi-supervised VAE framework with a flexible similarity regularization term that aligns selected latent variables with clinical or biomarker measures of dementia progression. This allows adapting the similarity metric and supervised variables to specific goals or available data. We demonstrate the approach using PET scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI), guiding the first latent dimension to align with a cognitive score. Using this supervised latent variable, we generate average reconstructions across levels of cognitive impairment. Voxel-wise GLM analysis reveals reduced metabolism in key regions, mainly the hippocampus, and within major Resting State Networks, particularly the Default Mode and Central Executive Networks. The remaining latent variables encode affine transformations and intensity variations, capturing confounds such as inter-subject variability and site effects. Our framework effectively extracts disease-related patterns aligned with established Alzheimer's biomarkers, offering an interpretable and adaptable tool for studying neurodegenerative progression.

</details>


### [24] [Learning Contextual Runtime Monitors for Safe AI-Based Autonomy](https://arxiv.org/abs/2601.20666)
*Alejandro Luque-Cerpa,Mengyuan Wang,Emil Carlsson,Sanjit A. Seshia,Devdatt Dubhashi,Hazem Torfah*

Main category: cs.LG

TL;DR: AI 기반 제어 앙상블을 위한 맥락 인식 런타임 모니터 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: AI 기반 제어 시스템의 정확도가 익숙하지 않은 환경에서 급격히 저하되어 안전 문제가 발생하는 것을 해결하고자 합니다.

Method: 모니터가 시스템의 맥락을 지속적으로 관찰하고 현재 조건에 가장 적합한 제어기를 선택합니다.

Result: 두 가지 자율 주행 시나리오에서 우리의 프레임워크를 검증하여 안전성과 성능에서 비맥락적 기준선에 비해 현저한 개선을 보였습니다.

Conclusion: 안전한 AI 기반 제어 앙상블 설계를 맥락 모니터링 문제로 재정의하고, 모니터 학습을 맥락 학습 작업으로 설정하여 이론적 안전성과 제어기 다양성 활용을 개선하였습니다.

Abstract: We introduce a novel framework for learning context-aware runtime monitors for AI-based control ensembles. Machine-learning (ML) controllers are increasingly deployed in (autonomous) cyber-physical systems because of their ability to solve complex decision-making tasks. However, their accuracy can degrade sharply in unfamiliar environments, creating significant safety concerns. Traditional ensemble methods aim to improve robustness by averaging or voting across multiple controllers, yet this often dilutes the specialized strengths that individual controllers exhibit in different operating contexts. We argue that, rather than blending controller outputs, a monitoring framework should identify and exploit these contextual strengths. In this paper, we reformulate the design of safe AI-based control ensembles as a contextual monitoring problem. A monitor continuously observes the system's context and selects the controller best suited to the current conditions. To achieve this, we cast monitor learning as a contextual learning task and draw on techniques from contextual multi-armed bandits. Our approach comes with two key benefits: (1) theoretical safety guarantees during controller selection, and (2) improved utilization of controller diversity. We validate our framework in two simulated autonomous driving scenarios, demonstrating significant improvements in both safety and performance compared to non-contextual baselines.

</details>


### [25] [Adapting the Behavior of Reinforcement Learning Agents to Changing Action Spaces and Reward Functions](https://arxiv.org/abs/2601.20714)
*Raul de la Rosa,Ivana Dusparic,Nicolas Cardozo*

Main category: cs.LG

TL;DR: MORPHIN은 환경 변화에 즉시 적응할 수 있도록 설계된 자가 적응형 Q-학습 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 환경 조건이 비정상적인 실제 응용 프로그램에서 RL 에이전트의 성능 저하 문제를 해결하고자 한다.

Method: 개념 드리프트 감지와 학습 및 탐색 하이퍼파라미터의 동적 조정을 통합한 MORPHIN 프레임워크를 제안한다.

Result: MORPHIN은 표준 Q-학습 기준선에 비해 더 나은 수렴 속도와 지속적인 적응을 달성하며 학습 효율성을 최대 1.7배 향상시킨다.

Conclusion: MORPHIN은 이전 정책 지식을 보존하면서 변화하는 환경에 효과적으로 적응할 수 있는 강력한 방법을 제공한다.

Abstract: Reinforcement Learning (RL) agents often struggle in real-world applications where environmental conditions are non-stationary, particularly when reward functions shift or the available action space expands. This paper introduces MORPHIN, a self-adaptive Q-learning framework that enables on-the-fly adaptation without full retraining. By integrating concept drift detection with dynamic adjustments to learning and exploration hyperparameters, MORPHIN adapts agents to changes in both the reward function and on-the-fly expansions of the agent's action space, while preserving prior policy knowledge to prevent catastrophic forgetting. We validate our approach using a Gridworld benchmark and a traffic signal control simulation. The results demonstrate that MORPHIN achieves superior convergence speed and continuous adaptation compared to a standard Q-learning baseline, improving learning efficiency by up to 1.7x.

</details>


### [26] [Continual GUI Agents](https://arxiv.org/abs/2601.20732)
*Ziwei Liu,Borui Kang,Hangjie Yuan,Zixiang Zhao,Wei Li,Yifan Zhu,Tao Feng*

Main category: cs.LG

TL;DR: 디지털 환경이 변화하면서 GUI 에이전트가 더 나은 성능을 발휘하도록 하는 지속적 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 정적 환경에서 훈련된 에이전트가 변화하는 GUI 환경에서 성능 저하를 겪는 문제를 해결하고자 한다.

Method: GUI-Anchoring in Flux (GUI-AiF)라는 새로운 강화 학습 미세 조정 프레임워크를 도입하고, 이를 통해 두 가지 보상 체계인 Anchoring Point Reward in Flux (APR-iF)와 Anchoring Region Reward in Flux (ARR-iF)를 통해 지속적 학습을 안정화한다.

Result: GUI-AiF가 최첨단 기준을 초월하는 성과를 보였으며, 기존 보상 전략들이 정적 기준 신호에 과도하게 적응하는 경향을 완화했다.

Conclusion: 우리의 연구는 GUI 에이전트를 위한 최초의 지속적 학습 프레임워크를 확립하고, 지속적 GUI 에이전트를 위한 강화 학습의 잠재력을 발견했다.

Abstract: As digital environments (data distribution) are in flux, with new GUI data arriving over time-introducing new domains or resolutions-agents trained on static environments deteriorate in performance. In this work, we introduce Continual GUI Agents, a new task that requires GUI agents to perform continual learning under shifted domains and resolutions. We find existing methods fail to maintain stable grounding as GUI distributions shift over time, due to the diversity of UI interaction points and regions in fluxing scenarios. To address this, we introduce GUI-Anchoring in Flux (GUI-AiF), a new reinforcement fine-tuning framework that stabilizes continual learning through two novel rewards: Anchoring Point Reward in Flux (APR-iF) and Anchoring Region Reward in Flux (ARR-iF). These rewards guide the agents to align with shifting interaction points and regions, mitigating the tendency of existing reward strategies to over-adapt to static grounding cues (e.g., fixed coordinates or element scales). Extensive experiments show GUI-AiF surpasses state-of-the-art baselines. Our work establishes the first continual learning framework for GUI agents, revealing the untapped potential of reinforcement fine-tuning for continual GUI Agents.

</details>


### [27] [C3Box: A CLIP-based Class-Incremental Learning Toolbox](https://arxiv.org/abs/2601.20852)
*Hao Sun,Da-Wei Zhou*

Main category: cs.LG

TL;DR: C3Box는 CLIP 기반의 클래스 증가 학습을 위한 파이썬 툴박스로, 기존의 다양한 방법들을 통합하여 재현 가능한 실험을 지원합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 기계 학습 시스템은 정적 데이터 분포를 기반으로 설계되었으나, 진화하는 데이터 스트림에서 학습할 때 재앙적 망각의 문제에 직면합니다. CIL은 새로운 클래스를 지속적으로 학습하면서 이전 지식을 보존할 수 있도록 설계되었습니다.

Method: C3Box는 기존의 전통적인 CIL 방법, ViT 기반 CIL 방법, 최신 CLIP 기반 CIL 방법을 통합한 통일된 CLIP 기반 프레임워크를 제공합니다. 또한, JSON 기반의 구성과 표준화된 실행 파이프라인을 통해 재현 가능한 실험을 지원합니다.

Result: C3Box는 사용자 친화적으로 설계되었으며, 널리 사용되는 오픈 소스 라이브러리만을 사용하고 주요 운영 체제를 지원합니다.

Conclusion: C3Box는 지속적인 학습 연구를 위한 신뢰할 수 있는 벤치마크 플랫폼으로 자리잡고 있습니다.

Abstract: Traditional machine learning systems are typically designed for static data distributions, which suffer from catastrophic forgetting when learning from evolving data streams. Class-Incremental Learning (CIL) addresses this challenge by enabling learning systems to continuously learn new classes while preserving prior knowledge. With the rise of pre-trained models (PTMs) such as CLIP, leveraging their strong generalization and semantic alignment capabilities has become a promising direction in CIL. However, existing CLIP-based CIL methods are often scattered across disparate codebases, rely on inconsistent configurations, hindering fair comparisons, reproducibility, and practical adoption. Therefore, we propose C3Box (CLIP-based Class-inCremental learning toolBOX), a modular and comprehensive Python toolbox. C3Box integrates representative traditional CIL methods, ViT-based CIL methods, and state-of-the-art CLIP-based CIL methods into a unified CLIP-based framework. By inheriting the streamlined design of PyCIL, C3Box provides a JSON-based configuration and standardized execution pipeline. This design enables reproducible experimentation with low engineering overhead and makes C3Box a reliable benchmark platform for continual learning research. Designed to be user-friendly, C3Box relies only on widely used open-source libraries and supports major operating systems. The code is available at https://github.com/LAMDA-CL/C3Box.

</details>


### [28] [Evolutionary Strategies lead to Catastrophic Forgetting in LLMs](https://arxiv.org/abs/2601.20861)
*Immanuel Abdi,Akshat Gupta,Micah Mok,Alexander Lu,Nicholas Lee,Gopala Anumanchipalli*

Main category: cs.LG

TL;DR: 기존 AI 시스템의 지속적 학습 능력 부족 문제를 다루며, 진화 전략(ES) 알고리즘의 성능과 기억 상실 곡선을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 현재 AI 시스템에서의 지속적 학습 능력 부족 문제를 해결하고자 한다.

Method: 진화 전략(ES)을 분석하고 업데이트 단계 수가 증가할 때의 기억 상실 곡선을 평가한다.

Result: ES는 수학 및 추론 작업에서 GRPO에 근접한 성능을 달성하지만, 이전 능력의 상당한 기억 상실이 동반되어 지속적 학습에 한계가 있다.

Conclusion: ES와 같은 경량 학습 알고리즘의 기억 상실 문제를 강조하고, 이 문제를 완화하기 위한 미래 연구에 영감을 주고자 한다.

Abstract: One of the biggest missing capabilities in current AI systems is the ability to learn continuously after deployment. Implementing such continually learning systems have several challenges, one of which is the large memory requirement of gradient-based algorithms that are used to train state-of-the-art LLMs. Evolutionary Strategies (ES) have recently re-emerged as a gradient-free alternative to traditional learning algorithms and have shown encouraging performance on specific tasks in LLMs. In this paper, we perform a comprehensive analysis of ES and specifically evaluate its forgetting curves when training for an increasing number of update steps. We first find that ES is able to reach performance numbers close to GRPO for math and reasoning tasks with a comparable compute budget. However, and most importantly for continual learning, the performance gains in ES is accompanied by significant forgetting of prior abilities, limiting its applicability for training models online. We also explore the reason behind this behavior and show that the updates made using ES are much less sparse and have orders of magnitude larger $\ell_2$ norm compared to corresponding GRPO updates, explaining the contrasting forgetting curves between the two algorithms. With this study, we aim to highlight the issue of forgetting in gradient-free algorithms like ES and hope to inspire future work to mitigate these issues.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [29] [What is the AGI in Offensive Security ?](https://arxiv.org/abs/2601.19968)
*Youngwoong Cho*

Main category: cs.CR

TL;DR: 이 논문은 공격적 보안에서의 AGI(인공지능 일반화)를 상태 기계와 상호작용하는 상징적 대리자로 모델링한다.


<details>
  <summary>Details</summary>
Motivation: 공격적 보안 작업이 상징적 언어 조작으로 환원될 수 있는지를 탐구하고 LLM이 이 작업을 처리할 수 있는 충분한 성능을 가지는지를 판단하고자 한다.

Method: 대상 시스템을 상태 기계로 모델링하고 해커를 상호작용하는 상징적 대리자로 나타낸다.

Result: 모든 공격적 Engagement의 상호작용은 유한한 문자열로 인코딩할 수 있음을 보여준다.

Conclusion: 이 논문은 정의, 짧은 보조정리 및 열린 논의를 제공한다.

Abstract: What is the AGI in Offensive Security? One can break it down into two questions : (1) any offensive security tasks could be reduced into symbolic language manipulation (language representation + reasoning), (2) powerful language model (LLM) are enough to "deal with" any symbolic language manipulation. This paper can formally model a target system as a state machine and a hacker as an interactive symbolic agent. And it shows that every interaction in an offensive engagement can be encoded as a finite string. This paper provides definitions, short lemmas, and open discussion.

</details>


### [30] [Securing AI Agents in Cyber-Physical Systems: A Survey of Environmental Interactions, Deepfake Threats, and Defenses](https://arxiv.org/abs/2601.20184)
*Mohsen Hatami,Van Tuan Pham,Hozefa Lakadawala,Yu Chen*

Main category: cs.CR

TL;DR: CPS에서 AI 에이전트의 보안 위협과 취약점을 종합적으로 검토하고, 방어 메커니즘의 한계를 설명하는 연구.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 통합이 전통적인 사이버 및 물리적 위협 모델을 넘어서는 새로운 보안 위험을 초래하기 때문.

Method: SENTINEL 프레임워크를 사용하여 문헌을 조직하고, 실제 스마트 그리드 배치를 기반으로 한 사례 연구를 통해 방어 메커니즘의 제약을 정량적으로 설명.

Result: 방어 메커니즘이 실행될 수 있는 제한과, 탐지 메커니즘만으로는 안전-critical CPS에서 충분하지 않음을 보여주었다.

Conclusion: 신뢰할 수 있는 AI 기반 CPS를 위한 원천 및 물리학에 기반한 신뢰 메커니즘과 심층 방어 아키텍처의 중요성을 강조하고, 향후 도전 과제를 제시했다.

Abstract: The increasing integration of AI agents into cyber-physical systems (CPS) introduces new security risks that extend beyond traditional cyber or physical threat models. Recent advances in generative AI enable deepfake and semantic manipulation attacks that can compromise agent perception, reasoning, and interaction with the physical environment, while emerging protocols such as the Model Context Protocol (MCP) further expand the attack surface through dynamic tool use and cross-domain context sharing. This survey provides a comprehensive review of security threats targeting AI agents in CPS, with a particular focus on environmental interactions, deepfake-driven attacks, and MCP-mediated vulnerabilities. We organize the literature using the SENTINEL framework, a lifecycle-aware methodology that integrates threat characterization, feasibility analysis under CPS constraints, defense selection, and continuous validation. Through an end-to-end case study grounded in a real-world smart grid deployment, we quantitatively illustrate how timing, noise, and false-positive costs constrain deployable defenses, and why detection mechanisms alone are insufficient as decision authorities in safety-critical CPS. The survey highlights the role of provenance- and physics-grounded trust mechanisms and defense-in-depth architectures, and outlines open challenges toward trustworthy AI-enabled CPS.

</details>


### [31] [Multimodal Multi-Agent Ransomware Analysis Using AutoGen](https://arxiv.org/abs/2601.20346)
*Asifullah Khan,Aimen Wadood,Mubashar Iqbal,Umme Zahoora*

Main category: cs.CR

TL;DR: 이 논문은 툴을 통해 랜섬웨어 분류를 위한 다중 모드 에이전트 분석 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 랜섬웨어는 전 세계적으로 심각한 사이버 보안 위협으로, 주요 재정 손실과 운영 중단을 초래하고 있다.

Method: 제안된 다중 모드 다중 에이전트 아키텍처는 정적, 동적, 네트워크 소스의 정보로 구성되며, 각 데이터 유형은 오토인코더 기반의 특성 추출을 사용하는 전문 에이전트에 의해 처리된다.

Result: 이 프레임워크는 수천 개의 랜섬웨어와 정상 샘플을 포함하는 대규모 데이터 세트에서 평가되었으며, 랜섬웨어 데이터셋에서 단일 모드 및 비적응형 융합 기준선을 능가하여 가족 분류에서 Macro-F1이 최대 0.936까지 향상되었다.

Conclusion: 제안된 접근 방식은 실질적이고 효과적인 방법으로 현실 세계의 랜섬웨어 방어 시스템을 개선할 수 있는 길을 제공한다.

Abstract: Ransomware has become one of the most serious cybersecurity threats causing major financial losses and operational disruptions worldwide.Traditional detection methods such as static analysis, heuristic scanning and behavioral analysis often fall short when used alone. To address these limitations, this paper presents multimodal multi agent ransomware analysis framework designed for ransomware classification. Proposed multimodal multiagent architecture combines information from static, dynamic and network sources. Each data type is handled by specialized agent that uses auto encoder based feature extraction. These representations are then integrated through a fusion agent. After that fused representation are used by transformer based classifier. It identifies the specific ransomware family. The agents interact through an interagent feedback mechanism that iteratively refines feature representations by suppressing low confidence information. The framework was evaluated on large scale datasets containing thousands of ransomware and benign samples. Multiple experiments were conducted on ransomware dataset. It outperforms single modality and nonadaptive fusion baseline achieving improvement of up to 0.936 in Macro-F1 for family classification and reducing calibration error. Over 100 epochs, the agentic feedback loop displays a stable monotonic convergence leading to over +0.75 absolute improvement in terms of agent quality and a final composite score of around 0.88 without fine tuning of the language models. Zeroday ransomware detection remains family dependent on polymorphism and modality disruptions. Confidence aware abstention enables reliable real world deployment by favoring conservativeand trustworthy decisions over forced classification. The findings indicate that proposed approach provides a practical andeffective path toward improving real world ransomware defense systems.

</details>


### [32] [A High-Performance Fractal Encryption Framework and Modern Innovations for Secure Image Transmission](https://arxiv.org/abs/2601.20374)
*Sura Khalid Salsal,Eman Shaker Mahmood,Farah Tawfiq Abdul Hussien,Maryam Mahdi Alhusseini,Azhar Naji Alyahya,Nikolai Safiullin*

Main category: cs.CR

TL;DR: 이 논문은 이미지 암호화의 성능과 효율성을 향상시키기 위해 푸리에 변환을 기반으로 한 프랙탈 암호화 기법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 데이터 보안에 대한 위협이 증가하는 현재의 디지털 시대에는 강력한 이미지 암호화 기술이 필요하다.

Method: 프랙탈 암호화 방식을 제안하여 기존의 기본 방법과 비교하여 보안성과 효율성을 동시에 향상시키고자 한다.

Result: 이 새로운 방법은 이전 연구에서 발견된 격차를 메우고 다른 기술과 비교했을 때 암호화/복호화 시간과 이미지 충실성을 크게 향상시켰다.

Conclusion: 앞으로의 연구 방향과 가능한 개선 사항을 제시한다.

Abstract: The current digital era, driven by growing threats to data security, requires a robust image encryption technique. Classical encryption algorithms suffer from a trade-off among security, image fidelity, and computational efficiency. This paper aims to enhance the performance and efficiency of image encryption. This is done by proposing Fractal encryption based on Fourier transforms as a new method of image encryption, leveraging state-of-the-art technology. The new approach considered here intends to enhance both security and efficiency in image encryption by comparing Fractal Encryption with basic methods. The suggested system also aims to optimise encryption/ decryption times and preserve image quality. This paper provides an introduction to Image Encryption using the fractal-based method, its mathematical formulation, and its comparative efficiency against publicly known traditional encryption methods. As a result, after filling the gaps identified in previous research, it has significantly improved both its encryption/decryption time and image fidelity compared to other techniques. In this paper, directions for future research and possible improvements are outlined for attention.

</details>
