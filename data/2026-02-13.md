<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 6]
- [cs.CR](#cs.CR) [Total: 12]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.LG](#cs.LG) [Total: 24]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [MERIT Feedback Elicits Better Bargaining in LLM Negotiators](https://arxiv.org/abs/2602.10467)
*Jihwan Oh,Murad Aghazada,Yooju Shin,Se-Young Yun,Taehyeon Kim*

Main category: cs.AI

TL;DR: 이 연구는 대형 언어 모델(LLMs)이 협상에서 전략적 깊이와 인간의 복잡한 요인에 적응하는 데 어려움을 겪는 문제를 해결하기 위한 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 협상이 예술이나 직관의 문제가 아닌 논리적 영역으로 간주되지만, 현재의 LLM은 여전히 협상에서 한계가 있습니다.

Method: AgoraBench라는 새로운 벤치마크를 도입하고, 인간 선호에 맞춘 경제적 기초의 측정 지표를 사용하며, LLM의 협상 능력을 향상시키기 위한 데이터셋을 구축했습니다.

Result: 기초 LLM 전략이 종종 인간의 선호와 일치하지 않음을 보여주었으며, 제안된 메커니즘은 협상 성과를 크게 향상시켰습니다.

Conclusion: 더 깊은 전략적 행동과 강력한 상대 인식을 이끌어내는 성과를 달성했습니다.

Abstract: Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.g., deception, monopoly) that supports diverse strategy modeling; (ii) human-aligned, economically grounded metrics derived from utility theory. This is operationalized via agent utility, negotiation power, and acquisition ratio that implicitly measure how well the negotiation aligns with human preference and (iii) a human preference grounded dataset with learning pipeline that strengthens LLMs' bargaining ability through both prompting and finetuning. Empirical results indicate that baseline LLM strategies often diverge from human preferences, while our mechanism substantially improves negotiation performance, yielding deeper strategic behavior and stronger opponent awareness.

</details>


### [2] [Neuro-symbolic Action Masking for Deep Reinforcement Learning](https://arxiv.org/abs/2602.10598)
*Shuai Han,Mehdi Dastani,Shihan Wang*

Main category: cs.AI

TL;DR: Neuro-symbolic Action Masking (NSAM)은 고차원 상태의 도메인 제약을 자동으로 학습하여 비현실적인 행동을 배제하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 딥 강화 학습(DRL)에서는 훈련 중 및 실행 중에 비현실적인 행동을 탐색할 수 있다.

Method: NSAM은 고차원 상태의 도메인 제약과 일치하는 기호 모델을 자동으로 학습하고, 학습된 모델을 기반으로 비현실적인 행동을 배제하는 행동 마스크를 학습한다.

Result: 여러 도메인에서 NSAM을 평가한 결과, DRL 에이전트의 샘플 효율성이 크게 향상되고 제약 위반이 크게 감소하였다.

Conclusion: NSAM은 기호 추론과 심층 정책 최적화를 종합적으로 통합하여 상호 강화하는 효과를 제공한다.

Abstract: Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.

</details>


### [3] [See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch](https://arxiv.org/abs/2602.10814)
*Xingyi Zhang,Yulei Ye,Kaifeng Huang,Wenhao Li,Xiangfeng Wang*

Main category: cs.AI

TL;DR: ScratchWorld는 Scratch에서의 프로그램 구축 과제를 평가하기 위한 벤치마크로, GUI 에이전트의 성능을 측정하는 데 중점을 두고 있다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 GUI를 통해 프로그램을 구성하는 능력을 평가하는 연구가 부족한 점을 해결하기 위해.

Method: Use-Modify-Create 교육 프레임워크에 기반한 ScratchWorld는 Create, Debug, Extend, Compute의 네 가지 문제 카테고리에서 83개의 기획된 과제를 포함한다.

Result: 정밀한 드래그 앤 드롭 조작이 필요한 원시 모드와 높은 수준의 의미적 API를 사용하는 복합 모드를 둔 평가 기준으로 에이전트 실패의 원인을 진단.

Conclusion: 최첨단 다중모드 언어 모델과 GUI 에이전트에 대한 실험 결과, 계획 능력은 강력하지만 여전히 정밀한 GUI 조작에서의 문제는 지속적으로 나타난다.

Abstract: Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.

</details>


### [4] [CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion](https://arxiv.org/abs/2602.10999)
*Yusong Lin,Haiyang Wang,Shuzhe Wu,Lue Fan,Feiyang Pan,Sanyuan Zhao,Dandan Tu*

Main category: cs.AI

TL;DR: 본 논문에서는 에이전트가 환경 이력을 시뮬레이션하고 탐색하는 방법을 제안하고, 이를 통해 CLI에서 수행되는 환경 집약적 작업을 대규모로 유도하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트가 런타임 환경과 효과적으로 상호 작용하여 작업을 수행할 수 있도록 하는 방법이 부족하다는 문제를 해결하고자 합니다.

Method: Dockerfile과 에이전트 작업의 유사성을 바탕으로 에이전트를 사용해 실행 피드백에 따라 환경 이력을 시뮬레이션하고 탐색하는 방법을 제안합니다.

Result: CLI-Gym이라는 방법을 통해 총 1,655개의 환경 집약적 작업을 도출하였으며, 이는 같은 종류의 작업 중에서 가장 큰 수집입니다. 또한 LiberCoder라는 모델이 Terminal-Bench에서 +21.1% (46.1%로)라는 상당한 개선을 달성하여 다양한 강력한 기준선을 초과합니다.

Conclusion: 이 연구는 환경 집약적 작업의 대규모 유도를 위한 최초의 공개 파이프라인이라는 점에서 중요한 기여를 합니다.

Abstract: Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate and explore environment histories, guided by execution feedback. By tracing histories of a healthy environment, its state can be inverted to an earlier one with runtime failures, from which a task can be derived by packing the buggy state and the corresponding error messages. With our method, named CLI-Gym, a total of 1,655 environment-intensive tasks are derived, being the largest collection of its kind. Moreover, with curated successful trajectories, our fine-tuned model, named LiberCoder, achieves substantial absolute improvements of +21.1% (to 46.1%) on Terminal-Bench, outperforming various strong baselines. To our knowledge, this is the first public pipeline for scalable derivation of environment-intensive tasks.

</details>


### [5] [GameDevBench: Evaluating Agentic Capabilities Through Game Development](https://arxiv.org/abs/2602.11103)
*Wayne Chi,Yixiong Fang,Arnav Yayavaram,Siddharth Yayavaram,Seth Karten,Qiuhong Anna Wei,Runkun Chen,Alexander Wang,Valerie Chen,Ameet Talwalkar,Chris Donahue*

Main category: cs.AI

TL;DR: 게임 개발 작업을 평가하기 위한 첫 번째 벤치마크인 GameDevBench를 제안하며, 에이전트의 다중 모드 이해 능력을 평가하는 데 초점을 맞춘다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 개발 복잡성과 깊은 다중 모드 이해의 필요성을 결합한 평가 테스트베드의 희귀성 문제 해결.

Method: 웹 및 비디오 튜토리얼에서 파생된 132개의 복잡한 작업으로 구성된 GameDevBench를 제안하고, 에이전트에 대한 이미지 및 비디오 기반 피드백 메커니즘을 도입하여 다중 모드 능력 향상.

Result: 에이전트가 게임 개발 작업의 54.5%만을 해결했으며, 작업 난이도와 다중 모드 복잡성 간의 강한 상관관계를 발견했다.

Conclusion: GameDevBench를 공개하여 에이전트 게임 개발에 대한 추가 연구를 지원한다.

Abstract: Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.

</details>


### [6] [FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight](https://arxiv.org/abs/2602.11136)
*Jiayi Zhou,Yang Sheng,Hantao Lou,Yaodong Yang,Jie Fu*

Main category: cs.AI

TL;DR: 본 논문은 LLM 기반 에이전트를 위한 행동 안전성을 보장하는 방법으로 신경-상징적 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트가 실제 결과가 있는 고위험 영역에서 운영됨에 따라, 그들의 행동 안전성을 보장하는 것이 중요하다.

Method: 이 논문에서는 bidirectional Formal-of-Thought 아키텍처를 사용하는 신경-상징적 프레임워크를 제안하며, LLM을 사양 컴파일러로 사용하여 인간의 고수준 의도를 원자적이고 검증 가능한 제약조건으로 분해하고, 이를 Dafny 사양 및 Z3 Satisfiability modulo 이론을 활용해 입증하는 방법을 설명한다.

Result: 실험 결과, 제안된 프레임워크는 LLM-as-a-Judge 기준에 비해 평균 16.6% 향상을 보였고, 7B 모델이 72B 에이전트에서 기만을 탐지하는 데 90% 이상의 정확도를 달성할 수 있도록 하였다.

Conclusion: 이 프레임워크는 반복적인 개선을 통해 행동 안전성을 크게 향상시킬 수 있음을 보여준다.

Abstract: As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [7] [Basic Legibility Protocols Improve Trusted Monitoring](https://arxiv.org/abs/2602.10153)
*Ashwin Sreevatsa,Sebastian Prasanna,Cody Rushing*

Main category: cs.CR

TL;DR: 이 논문은 신뢰할 수 없는 AI 시스템의 위험한 행동을 방지하기 위한 안전 기술인 제어 프로토콜을 개발하는 AI 제어 연구 의제를 다룹니다. 이전 연구의 한계를 극복하기 위해 주석을 활용한 명확성 프로토콜을 도입하여 신뢰할 수 없는 모델의 행동을 감시하기 쉽게 만듭니다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 위험한 행동을 방지하기 위한 안전 기술 개발의 필요성.

Method: 신뢰할 수 없는 모델이 주석으로 코드를 철저히 문서화하도록 장려하는 명확성 프로토콜을 도입하고, APPS 코딩 환경에서 제어 평가를 수행합니다.

Result: 주석 프로토콜이 안전성을 개선하면서도 업적 성능을 희생하지 않고, 정직한 코드에 비해 백도어 코드가 자주 쉽게 설명되지 않는 이유를 발견했습니다.

Conclusion: 모니터의 강도가 높아질수록 주석의 이익이 증가하여 진정한 정당화와 불과하게 그럴듯한 것들을 구별하는 데 능숙한 모니터의 역할이 중요함을 보여줍니다.

Abstract: The AI Control research agenda aims to develop control protocols: safety techniques that prevent untrusted AI systems from taking harmful actions during deployment. Because human oversight is expensive, one approach is trusted monitoring, where weaker, trusted models oversee stronger, untrusted models$\unicode{x2013}$but this often fails when the untrusted model's actions exceed the monitor's comprehension. We introduce legibility protocols, which encourage the untrusted model to take actions that are easier for a monitor to evaluate.
  We perform control evaluations in the APPS coding setting, where an adversarial agent attempts to write backdoored code without detection. We study legibility protocols that allow the untrusted model to thoroughly document its code with comments$\unicode{x2013}$in contrast to prior work, which removed comments to prevent deceptive ones. We find that: (i) commenting protocols improve safety without sacrificing task performance relative to comment-removal baselines; (ii) commenting disproportionately benefits honest code, which typically has a natural explanation that resolves monitor suspicion, whereas backdoored code frequently lacks an easy justification; (iii) gains from commenting increase with monitor strength, as stronger monitors better distinguish genuine justifications from only superficially plausible ones.

</details>


### [8] [MalMoE: Mixture-of-Experts Enhanced Encrypted Malicious Traffic Detection Under Graph Drift](https://arxiv.org/abs/2602.10157)
*Yunpeng Tan,Qingyang Li,Mingxin Yang,Yannan Hu,Lei Zhang,Xinggong Zhang*

Main category: cs.CR

TL;DR: MalMoE라는 그래프 기반 암호화 트래픽 탐지 시스템을 제안하여 그래프 드리프트 문제를 해결하고 정확한 실시간 탐지를 달성함.


<details>
  <summary>Details</summary>
Motivation: 네트워크 트래픽 암호화로 인해 패킷 페이로드의 가시성이 없어 악성 트래픽 탐지가 어려워짐.

Method: Mixture of Experts (MoE)를 적용한 그래프 보조 암호화 트래픽 탐지 시스템을 제안하며, 다양한 그래프 드리프트를 처리할 수 있는 1-hop-GNN 유사 전문가 모델을 설계한다.

Result: MalMoE는 안정적인 데이터 증강을 포함한 두 단계 훈련 전략으로 훈련되어 실시간 탐지 성능을 보여준다.

Conclusion: 실험 결과, MalMoE는 공용, 합성 및 실제 데이터 세트에서 정밀하고 실시간 탐지가 가능함을 증명한다.

Abstract: Encryption has been commonly used in network traffic to secure transmission, but it also brings challenges for malicious traffic detection, due to the invisibility of the packet payload. Graph-based methods are emerging as promising solutions by leveraging multi-host interactions to promote detection accuracy. But most of them face a critical problem: Graph Drift, where the flow statistics or topological information of a graph change over time. To overcome these drawbacks, we propose a graph-assisted encrypted traffic detection system, MalMoE, which applies Mixture of Experts (MoE) to select the best expert model for drift-aware classification. Particularly, we design 1-hop-GNN-like expert models that handle different graph drifts by analyzing graphs with different features. Then, the redesigned gate model conducts expert selection according to the actual drift. MalMoE is trained with a stable two-stage training strategy with data augmentation, which effectively guides the gate on how to perform routing. Experiments on open-source, synthetic, and real-world datasets show that MalMoE can perform precise and real-time detection.

</details>


### [9] [Protecting Context and Prompts: Deterministic Security for Non-Deterministic AI](https://arxiv.org/abs/2602.10481)
*Mohan Rajagopalan,Vinay Rao*

Main category: cs.CR

TL;DR: 본 논문은 대형 언어 모델(LLM) 애플리케이션의 보안을 강화하기 위한 새로운 방법론을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 애플리케이션은 전통적인 보안 모델로는 막을 수 없는 프롬프트 주입 및 맥락 조작 공격에 취약합니다.

Method: 우리는 인증된 프롬프트와 인증된 맥락이라는 두 가지 새로운 원리를 소개하여 LLM 워크플로우에 대한 암호학적으로 검증 가능한 출처를 제공합니다.

Result: 1260개의 대표적인 공격에 대해 평가를 진행하여 100% 탐지율을 기록하며, 거짓 양성이 없고 최소한의 오버헤드를 유지했습니다.

Conclusion: 암호학적으로 강제된 프롬프트 계보, 변조 방지 맥락 및 입증 가능한 정책 추론을 결합한 첫 번째 접근 방식을 입증하며, LLM 보안을 반응적 탐지에서 예방적 보장으로 전환합니다.

Abstract: Large Language Model (LLM) applications are vulnerable to prompt injection and context manipulation attacks that traditional security models cannot prevent. We introduce two novel primitives--authenticated prompts and authenticated context--that provide cryptographically verifiable provenance across LLM workflows. Authenticated prompts enable self-contained lineage verification, while authenticated context uses tamper-evident hash chains to ensure integrity of dynamic inputs. Building on these primitives, we formalize a policy algebra with four proven theorems providing protocol-level Byzantine resistance--even adversarial agents cannot violate organizational policies. Five complementary defenses--from lightweight resource controls to LLM-based semantic validation--deliver layered, preventative security with formal guarantees. Evaluation against representative attacks spanning 6 exhaustive categories achieves 100% detection with zero false positives and nominal overhead. We demonstrate the first approach combining cryptographically enforced prompt lineage, tamper-evident context, and provable policy reasoning--shifting LLM security from reactive detection to preventative guarantees.

</details>


### [10] [The Role of Learning in Attacking Intrusion Detection Systems](https://arxiv.org/abs/2602.10299)
*Kyle Domico,Jean-Charles Noirot Ferrand,Patrick McDaniel*

Main category: cs.CR

TL;DR: 경량 적대적 에이전트를 통해 ML 기반 네트워크 침입 탐지 시스템(NIDS)을 피할 수 있는 새로운 공격 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: ML 기반 NIDS에 대한 공격을 더욱 실용적이고 효율적으로 만들기 위해 존재하는 문제점을 해결하고자 한다.

Method: 강화 학습(RL)을 통해 훈련된 전략을 사용하여 적대적인 방법으로 NIDS를 회피하는 경량 에이전트를 개발한다. 공격 과정은 오프라인 학습과 배치 단계로 나뉜다.

Result: 경량 에이전트를 사용한 공격이 48.9%의 성공률을 기록하며, 공격 생성 시간이 5.72ms로 매우 빠르고 필요한 자원이 극히 미미함을 보여준다.

Conclusion: 경량 학습 기반 에이전트가 향후 효과적이고 광범위하게 배포 가능한 봇넷을 형성할 수 있음을 입증한다.

Abstract: Recent work on network attacks have demonstrated that ML-based network intrusion detection systems (NIDS) can be evaded with adversarial perturbations. However, these attacks rely on complex optimizations that have large computational overheads, making them impractical in many real-world settings. In this paper, we introduce a lightweight adversarial agent that implements strategies (policies) trained via reinforcement learning (RL) that learn to evade ML-based NIDS without requiring online optimization. This attack proceeds by (1) offline training, where the agent learns to evade a surrogate ML model by perturbing malicious flows using network traffic data assumed to be collected via reconnaissance, then (2) deployment, where the trained agent is used in a compromised device controlled by an attacker to evade ML-based NIDS using learned attack strategies. We evaluate our approach across diverse NIDS and several white-, gray-, and black-box threat models. We demonstrate that attacks using these lightweight agents can be highly effective (reaching up to 48.9% attack success rate), extremely fast (requiring as little as 5.72ms to craft an attack), and require negligible resources (e.g., 0.52MB of memory). Through this work, we demonstrate that future botnets driven by lightweight learning-based agents can be highly effective and widely deployable in diverse environments of compromised devices.

</details>


### [11] [The Landscape of Prompt Injection Threats in LLM Agents: From Taxonomy to Analysis](https://arxiv.org/abs/2602.10453)
*Peiran Wang,Xinfeng Li,Chong Xiang,Jinghuai Zhang,Ying Li,Lixia Zhang,Xiaofeng Wang,Yuan Tian*

Main category: cs.CR

TL;DR: 이 논문에서는 Prompt Injection(PI) 공격에 대한 보안 강화를 위해 AgentPI라는 새로운 벤치마크를 도입한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 발전으로 자율 에이전트에 대한 전환이 이루어졌으며, PI 취약점으로부터의 강력한 보안이 필요하다.

Method: 시스템atic 문헌 리뷰와 정량적 분석을 통해 PI 공격을 페이로드 생성 전략에 따라, 방어를 개입 단계에 따라 분류하는 세분화를 수립하였다. 새로운 벤치마크 AgentPI를 도입하여 맥락 의존적 상호작용 설정에서 에이전트 행동을 평가하였다.

Result: 대표적인 방어를 실증적으로 평가한 결과, 신뢰성, 유용성, 지연 시간을 동시에 높일 수 있는 단일 접근 방식은 없음을 보여주었다.

Conclusion: 기존 벤치마크에서 효과적인 것으로 보이는 많은 방어가 맥락 의존적 추론이 필수적인 현실적인 에이전트 환경에서는 일반화되지 않음을 밝혔다.

Abstract: The evolution of Large Language Models (LLMs) has resulted in a paradigm shift towards autonomous agents, necessitating robust security against Prompt Injection (PI) vulnerabilities where untrusted inputs hijack agent behaviors. This SoK presents a comprehensive overview of the PI landscape, covering attacks, defenses, and their evaluation practices. Through a systematic literature review and quantitative analysis, we establish taxonomies that categorize PI attacks by payload generation strategies (heuristic vs. optimization) and defenses by intervention stages (text, model, and execution levels). Our analysis reveals a key limitation shared by many existing defenses and benchmarks: they largely overlook context-dependent tasks, in which agents are authorized to rely on runtime environmental observations to determine actions. To address this gap, we introduce AgentPI, a new benchmark designed to systematically evaluate agent behavior under context-dependent interaction settings. Using AgentPI, we empirically evaluate representative defenses and show that no single approach can simultaneously achieve high trustworthiness, high utility, and low latency. Moreover, we show that many defenses appear effective under existing benchmarks by suppressing contextual inputs, yet fail to generalize to realistic agent settings where context-dependent reasoning is essential. This SoK distills key takeaways and open research problems, offering structured guidance for future research and practical deployment of secure LLM agents.

</details>


### [12] [Authenticated Workflows: A Systems Approach to Protecting Agentic AI](https://arxiv.org/abs/2602.10465)
*Mohan Rajagopalan,Vinay Rao*

Main category: cs.CR

TL;DR: 본 논문에서는 기업의 에이전틱 AI를 위한 첫 번째 완전 신뢰 계층인 인증된 워크플로우를 도입하고, 네 가지 기본 경계(프롬프트, 도구, 데이터, 컨텍스트)를 보호하여 결정론적 보안을 제공하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 에이전틱 AI 시스템은 기업 워크플로우를 자동화하나 기존 방어 메커니즘은 확률적이며 자주 우회된다.

Method: 프롬프트, 도구, 데이터 및 컨텍스트의 네 가지 경계에서 의도(조직 정책을 만족하는 작업)와 무결성(작업이 암호학적으로 인증됨)을 유지하면서, 공격 클래스의 암호학적 제거와 런타임 정책 시행을 결합하여 결정을 내린다. 또한, MAPL이라는 AI 고유의 정책 언어를 도입하여 에이전트가 진화하고 호출 컨텍스트가 변할 때 에이전틱 제약을 동적으로 표현한다.

Result: 우리는 9개의 주요 프레임워크(MCP, A2A, OpenAI, Claude, LangChain, CrewAI, AutoGen, LlamaIndex, Haystack)를 통합한 보편적 보안 런타임을 통해 실용성을 입증하였다.

Conclusion: 형식적 증명이 완전성과 타당성을 확립하였고, 174개의 테스트 케이스에서 100% 회상률과 0% 허위 긍정, 10가지 OWASP Top 10 리스크 중 9가지에 대한 보호를 보여주었으며, 두 개의 고위험 생산 CVE를 완전하게 완화하였다.

Abstract: Agentic AI systems automate enterprise workflows but existing defenses--guardrails, semantic filters--are probabilistic and routinely bypassed. We introduce authenticated workflows, the first complete trust layer for enterprise agentic AI. Security reduces to protecting four fundamental boundaries: prompts, tools, data, and context. We enforce intent (operations satisfy organizational policies) and integrity (operations are cryptographically authentic) at every boundary crossing, combining cryptographic elimination of attack classes with runtime policy enforcement. This delivers deterministic security--operations either carry valid cryptographic proof or are rejected. We introduce MAPL, an AI-native policy language that expresses agentic constraints dynamically as agents evolve and invocation context changes, scaling as O(log M + N) policies versus O(M x N) rules through hierarchical composition with cryptographic attestations for workflow dependencies. We prove practicality through a universal security runtime integrating nine leading frameworks (MCP, A2A, OpenAI, Claude, LangChain, CrewAI, AutoGen, LlamaIndex, Haystack) through thin adapters requiring zero protocol modifications. Formal proofs establish completeness and soundness. Empirical validation shows 100% recall with zero false positives across 174 test cases, protection against 9 of 10 OWASP Top 10 risks, and complete mitigation of two high impact production CVEs.

</details>


### [13] [Following Dragons: Code Review-Guided Fuzzing](https://arxiv.org/abs/2602.10487)
*Viet Hoang Luu,Amirmohammad Pasdar,Wachiraphan Charoenwet,Toby Murray,Shaanan Cohney,Van-Thuan Pham*

Main category: cs.CR

TL;DR: EyeQ는 코드 리뷰에서 개발자 정보를 활용하여 퍼징을 안내하는 시스템으로, 보안 취약점 발견을 크게 개선한다.


<details>
  <summary>Details</summary>
Motivation: 현대 퍼저들은 대규모 실제 소프트웨어에 확장되지만, 개발자들이 가장 취약하거나 보안에 중요한 상태를 충분히 다루지 못하는 경우가 많다.

Method: EyeQ는 코드 리뷰 논의에서 보안 관련 신호를 추출하고, 관련 프로그램 영역을 찾으며, 이러한 통찰을 주석 기반 가이드로 변환하는 방법을 사용한다.

Result: EyeQ는 표준 퍼징 구성보다 취약점 발견을 크게 개선하여 보안 비상버전의 PHP 코드베이스에서 40개 이상의 새로운 버그를 발견했다.

Conclusion: EyeQ는 기존의 주석 인식 퍼징 위에서 작동하며, 프로그램 의미나 개발자 워크플로우에 변경이 필요하지 않다.

Abstract: Modern fuzzers scale to large, real-world software but often fail to exercise the program states developers consider most fragile or security-critical. Such states are typically deep in the execution space, gated by preconditions, or overshadowed by lower-value paths that consume limited fuzzing budgets. Meanwhile, developers routinely surface risk-relevant insights during code review, yet this information is largely ignored by automated testing tools. We present EyeQ, a system that leverages developer intelligence from code reviews to guide fuzzing. EyeQ extracts security-relevant signals from review discussions, localizes the implicated program regions, and translates these insights into annotation-based guidance for fuzzing. The approach operates atop existing annotation-aware fuzzing, requiring no changes to program semantics or developer workflows. We first validate EyeQ through a human-guided feasibility study on a security-focused dataset of PHP code reviews, establishing a strong baseline for review-guided fuzzing. We then automate the workflow using a large language model with carefully designed prompts. EyeQ significantly improves vulnerability discovery over standard fuzzing configurations, uncovering more than 40 previously unknown bugs in the security-critical PHP codebase.

</details>


### [14] [When Skills Lie: Hidden-Comment Injection in LLM Agents](https://arxiv.org/abs/2602.10498)
*Qianli Wang,Boyang Ma,Minghui Xu,Yue Zhang*

Main category: cs.CR

TL;DR: 이 논문은 LLM 에이전트에서 문서화 레이어에서 발생하는 숨겨진 주석 프롬프트 주입 위험을 연구하고, 이를 방지하기 위한 방어 시스템 프롬프트를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트는 제공되는 도구와 권장 절차를 설명하기 위해 Skills를 활용합니다.

Method: Markdown Skill이 HTML로 렌더링될 때 발생하는 위험을 실험을 통해 분석하였습니다.

Result: DeepSeek-V3.2와 GLM-4.5-Air가 숨겨진 주석에 삽입된 악의적인 지시로 영향을 받을 수 있다는 것을 발견했습니다.

Conclusion: Skills를 신뢰할 수 없는 것으로 간주하고 민감한 행동을 금지하는 짧은 방어 시스템 프롬프트가 이러한 악의적인 도구 호출을 방지하고 의심스러운 숨겨진 지시를 드러냅니다.

Abstract: LLM agents often rely on Skills to describe available tools and recommended procedures. We study a hidden-comment prompt injection risk in this documentation layer: when a Markdown Skill is rendered to HTML, HTML comment blocks can become invisible to human reviewers, yet the raw text may still be supplied verbatim to the model. In experiments, we find that DeepSeek-V3.2 and GLM-4.5-Air can be influenced by malicious instructions embedded in a hidden comment appended to an otherwise legitimate Skill, yielding outputs that contain sensitive tool intentions. A short defensive system prompt that treats Skills as untrusted and forbids sensitive actions prevents these malicious tool calls and instead surfaces the suspicious hidden instructions.

</details>


### [15] [Anonymization-Enhanced Privacy Protection for Mobile GUI Agents: Available but Invisible](https://arxiv.org/abs/2602.10139)
*Lepeng Zhao,Zhenhua Zou,Shuo Li,Zhuotao Liu*

Main category: cs.CR

TL;DR: 이 논문에서는 모바일 GUI 에이전트를 위한 개인 정보 보호 프레임워크를 제안하여 민감한 데이터에 대한 접근을 비가시적으로 유지하면서도 과제 실행에 사용할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 모바일 GUI 에이전트가 복잡한 스마트폰 작업을 자동화하는 데 강력한 능력을 가지고 있지만, 개인 정보 유출 위험이 크다.

Method: PII 인식 모델을 사용하여 민감한 UI 콘텐츠를 감지하고, 이를 결정론적이며 유형을 보존하는 자리 표시자로 교체하는 프레임워크를 제안한다.

Result: 구현한 프레임워크는 여러 모델에서 개인 정보 유출을 크게 줄이며, 일반적으로 사용자 유틸리티에 대한 최소한의 저하만을 유발한다.

Conclusion: 기존 방법 중 가장 좋은 개인 정보 및 유틸리티의 균형을 이룬다.

Abstract: Mobile Graphical User Interface (GUI) agents have demonstrated strong capabilities in automating complex smartphone tasks by leveraging multimodal large language models (MLLMs) and system-level control interfaces. However, this paradigm introduces significant privacy risks, as agents typically capture and process entire screen contents, thereby exposing sensitive personal data such as phone numbers, addresses, messages, and financial information. Existing defenses either reduce UI exposure, obfuscate only task-irrelevant content, or rely on user authorization, but none can protect task-critical sensitive information while preserving seamless agent usability.
  We propose an anonymization-based privacy protection framework that enforces the principle of available-but-invisible access to sensitive data: sensitive information remains usable for task execution but is never directly visible to the cloud-based agent. Our system detects sensitive UI content using a PII-aware recognition model and replaces it with deterministic, type-preserving placeholders (e.g., PHONE_NUMBER#a1b2c) that retain semantic categories while removing identifying details. A layered architecture comprising a PII Detector, UI Transformer, Secure Interaction Proxy, and Privacy Gatekeeper ensures consistent anonymization across user instructions, XML hierarchies, and screenshots, mediates all agent actions over anonymized interfaces, and supports narrowly scoped local computations when reasoning over raw values is necessary.
  Extensive experiments on the AndroidLab and PrivScreen benchmarks show that our framework substantially reduces privacy leakage across multiple models while incurring only modest utility degradation, achieving the best observed privacy-utility trade-off among existing methods.

</details>


### [16] [Agentic Knowledge Distillation: Autonomous Training of Small Language Models for SMS Threat Detection](https://arxiv.org/abs/2602.10869)
*Adel ElZemity,Joshua Sylvester,Budi Arief,Rogério De Lemos*

Main category: cs.CR

TL;DR: 이 논문에서는 SMS 피싱 공격에 대한 효과적인 탐지기를 훈련하기 위한 방법으로 Agentic Knowledge Distillation을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: SMS 피싱 공격이 급증하면서, 효과적인 탐지기를 훈련하기 위해서는 시간이 지남에 따라 빠르게 구식이 되는 라벨된 위협 데이터가 필요합니다.

Method: 강력한 LLM이 자율 교사로 작용하여 작은 학생 모델(SLM)을 미세 조정하는 Agentic Knowledge Distillation을 도입했습니다. 교사 LLM은 자율적으로 합성 데이터를 생성하고 성능이 정체될 때까지 작은 온디바이스 학생 모델을 반복적으로 개선합니다.

Result: 교사 역할을 수행하는 네 가지 LLM(Claude Opus 4.5, GPT 5.2 Codex, Gemini 3 Pro, DeepSeek V3.2)과 두 개의 학생 SLM(Qwen2.5-0.5B, SmolLM2-135M)을 비교했습니다. 결과는 성능이 교사 LLM에 따라 크게 달라지며, 최고의 구성에서 94.31% 정확도와 96.25% 재현율을 달성했습니다.

Conclusion: Agentic knowledge distillation은 엣지 배치를 위한 효과적인 보안 분류기를 신속하게 생성할 수 있지만, 결과는 사용되는 교사 LLM에 따라 크게 달라집니다.

Abstract: SMS-based phishing (smishing) attacks have surged, yet training effective on-device detectors requires labelled threat data that quickly becomes outdated. To deal with this issue, we present Agentic Knowledge Distillation, which consists of a powerful LLM acts as an autonomous teacher that fine-tunes a smaller student SLM, deployable for security tasks without human intervention. The teacher LLM autonomously generates synthetic data and iteratively refines a smaller on-device student model until performance plateaus. We compare four LLMs in this teacher role (Claude Opus 4.5, GPT 5.2 Codex, Gemini 3 Pro, and DeepSeek V3.2) on SMS spam/smishing detection with two student SLMs (Qwen2.5-0.5B and SmolLM2-135M). Our results show that performance varies substantially depending on the teacher LLM, with the best configuration achieving 94.31% accuracy and 96.25% recall. We also compare against a Direct Preference Optimisation (DPO) baseline that uses the same synthetic knowledge and LoRA setup but without iterative feedback or targeted refinement; agentic knowledge distillation substantially outperforms it (e.g. 86-94% vs 50-80% accuracy), showing that closed-loop feedback and targeted refinement are critical. These findings demonstrate that agentic knowledge distillation can rapidly yield effective security classifiers for edge deployment, but outcomes depend strongly on which teacher LLM is used.

</details>


### [17] [Blind Gods and Broken Screens: Architecting a Secure, Intent-Centric Mobile Agent Operating System](https://arxiv.org/abs/2602.10915)
*Zhenhua Zou,Sheng Guo,Qiuyang Zhan,Lepeng Zhao,Shuo Li,Qi Li,Ke Xu,Mingwei Xu,Zhuotao Liu*

Main category: cs.CR

TL;DR: 본 논문은 Doubao Mobile Assistant를 사례로 사용하여 최신 모바일 에이전트의 보안 분석을 수행하고, Aura라는 안전한 에이전트 운영 체제를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 발전으로 모바일 컴퓨팅이 앱 중심의 상호작용에서 시스템 수준의 자율 에이전트로 전환되고 있습니다. 현재의 구현은 구조적 취약점과 모바일 생태계의 경제적 기반과의 갈등을 내포한 '화면-인터페이스' 패러다임에 의존하고 있습니다.

Method: Doubao Mobile Assistant를 사례로 하여 최신 모바일 에이전트의 보안 분석을 체계적으로 진행하였습니다. 위협 환경을 에이전트 신원, 외부 인터페이스, 내부 추론, 행동 실행의 네 가지 차원으로 분해하였습니다. 이를 통해 가짜 앱 신원, 시각적 스푸핑, 간접 프롬프트 주입 및 비인가 권한 상승과 같은 주요 결함을 발견하였습니다. 이 문제를 해결하기 위해 Aura라는 안전한 에이전트 운영 체제를 제안하였습니다.

Result: Aura는 Doubao와 비교하여 낮은 위험의 작업 성공률을 약 75%에서 94.3%로 향상시키고, 높은 위험의 공격 성공률을 약 40%에서 4.4%로 감소시켰습니다. 또한 지연 시간에서도 상당한 개선을 이루었습니다.

Conclusion: 이 결과들은 Aura가 '화면-인터페이스' 패러다임의 실행 가능하고 안전한 대안이 될 수 있음을 보여줍니다.

Abstract: The evolution of Large Language Models (LLMs) has shifted mobile computing from App-centric interactions to system-level autonomous agents. Current implementations predominantly rely on a "Screen-as-Interface" paradigm, which inherits structural vulnerabilities and conflicts with the mobile ecosystem's economic foundations. In this paper, we conduct a systematic security analysis of state-of-the-art mobile agents using Doubao Mobile Assistant as a representative case. We decompose the threat landscape into four dimensions - Agent Identity, External Interface, Internal Reasoning, and Action Execution - revealing critical flaws such as fake App identity, visual spoofing, indirect prompt injection, and unauthorized privilege escalation stemming from a reliance on unstructured visual data.
  To address these challenges, we propose Aura, an Agent Universal Runtime Architecture for a clean-slate secure agent OS. Aura replaces brittle GUI scraping with a structured, agent-native interaction model. It adopts a Hub-and-Spoke topology where a privileged System Agent orchestrates intent, sandboxed App Agents execute domain-specific tasks, and the Agent Kernel mediates all communication. The Agent Kernel enforces four defense pillars: (i) cryptographic identity binding via a Global Agent Registry; (ii) semantic input sanitization through a multilayer Semantic Firewall; (iii) cognitive integrity via taint-aware memory and plan-trajectory alignment; and (iv) granular access control with non-deniable auditing. Evaluation on MobileSafetyBench shows that, compared to Doubao, Aura improves low-risk Task Success Rate from roughly 75% to 94.3%, reduces high-risk Attack Success Rate from roughly 40% to 4.4%, and achieves near-order-of-magnitude latency gains. These results demonstrate Aura as a viable, secure alternative to the "Screen-as-Interface" paradigm.

</details>


### [18] [IU-GUARD: Privacy-Preserving Spectrum Coordination for Incumbent Users under Dynamic Spectrum Sharing](https://arxiv.org/abs/2602.11023)
*Shaoyu Li,Hexuan Yu,Shanghao Shi,Md Mohaimin Al Barat,Yang Xiao,Y. Thomas Hou,Wenjing Lou*

Main category: cs.CR

TL;DR: IU-GUARD는 무선 스펙트럼 공유를 위한 숨겨진 신원 보호 프레임워크로, 군용 레이더와 같은 기존 사용자(IUs)의 신원 노출 없이 스펙트럼을 이용할 수 있게 한다.


<details>
  <summary>Details</summary>
Motivation: 무선 스펙트럼의 수요 증가와 기존 사용자를 보호하기 위한 효과적인 스펙트럼 공유 솔루션이 필요하다.

Method: IU-GUARD는 검증 가능한 자격 증명(VCs)과 제로 지식 증명(ZKPs)을 활용하여 IUs가 신원 노출 없이 SCS에 권한을 증명할 수 있도록 한다.

Result: 프로토타입 구현 및 평가 결과, IU-GUARD는 실용적인 계산 및 통신 오버헤드로 강력한 프라이버시 보장을 달성한다.

Conclusion: 이로 인해 IU-GUARD는 실시간 동적 스펙트럼 공유 배포에 적합하다.

Abstract: With the growing demand for wireless spectrum, dynamic spectrum sharing (DSS) frameworks such as the Citizens Broadband Radio Service (CBRS) have emerged as practical solutions to improve utilization while protecting incumbent users (IUs) such as military radars. However, current incumbent protection mechanisms face critical limitations. The Environmental Sensing Capability (ESC) requires costly sensor deployments and remains vulnerable to interference and security risks. Alternatively, the Incumbent Informing Capability (IIC) requires IUs to disclose their identities and operational parameters to the Spectrum Coordination System (SCS), creating linkable records that compromise operational privacy and mission secrecy. We propose IU-GUARD, a privacy-preserving spectrum sharing framework that enables IUs to access spectrum without revealing their identities. Leveraging verifiable credentials (VCs) and zero-knowledge proofs (ZKPs), IU-GUARD allows IUs to prove their authorization to the SCS while disclosing only essential operational parameters. This decouples IU identity from spectrum access, prevents cross-request linkage, and mitigates the risk of centralized SCS data leakage. We implement a prototype, and our evaluation shows that IU-GUARD achieves strong privacy guarantees with practical computation and communication overhead, making it suitable for real-time DSS deployment.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [19] [AIvilization v0: Toward Large-Scale Artificial Social Simulation with a Unified Agent Architecture and Adaptive Agent Profiles](https://arxiv.org/abs/2602.10429)
*Wenkai Fan,Shurui Zhang,Xiaolong Wang,Haowei Yang,Tsz Wai Chan,Xingyan Chen,Junquan Bi,Zirui Zhou,Jia Liu,Kani Chen*

Main category: cs.MA

TL;DR: AIvilization v0는 자원 제약이 있는 샌드박스 경제와 통합된 LLM 에이전트 아키텍처를 결합한 대규모 인공 사회로, 빠르게 변화하는 환경에서도 장기 자율성을 유지하도록 설계되었습니다.


<details>
  <summary>Details</summary>
Motivation: 장기 목표의 안정성과 반응적 정확성 간의 긴장을 완화하고자 합니다.

Method: 계층적 분기 사고 계획자, 적응형 에이전트 프로필, 인간-루프 조타 인터페이스를 도입합니다.

Result: 안정적인 시장이 주요 스타일이든 사실들을 재생산하고, 교육 및 접근 제약에 의해 구동되는 구조적인 부유층 계층을 생성합니다.

Conclusion: 간소화된 계획자들이 좁은 작업에서 성능을 일치시킬 수 있지만, 전체 아키텍처는 다목적, 장기 설정에서 더 강력합니다.

Abstract: AIvilization v0 is a publicly deployed large-scale artificial society that couples a resource-constrained sandbox economy with a unified LLM-agent architecture, aiming to sustain long-horizon autonomy while remaining executable under rapidly changing environment. To mitigate the tension between goal stability and reactive correctness, we introduce (i) a hierarchical branch-thinking planner that decomposes life goals into parallel objective branches and uses simulation-guided validation plus tiered re-planning to ensure feasibility; (ii) an adaptive agent profile with dual-process memory that separates short-term execution traces from long-term semantic consolidation, enabling persistent yet evolving identity; and (iii) a human-in-the-loop steering interface that injects long-horizon objectives and short commands at appropriate abstraction levels, with effects propagated through memory rather than brittle prompt overrides. The environment integrates physiological survival costs, non-substitutable multi-tier production, an AMM-based price mechanism, and a gated education-occupation system. Using high-frequency transactions from the platforms mature phase, we find stable markets that reproduce key stylized facts (heavy-tailed returns and volatility clustering) and produce structured wealth stratification driven by education and access constraints. Ablations show simplified planners can match performance on narrow tasks, while the full architecture is more robust under multi-objective, long-horizon settings, supporting delayed investment and sustained exploration.

</details>


### [20] [Beyond Task Performance: A Metric-Based Analysis of Sequential Cooperation in Heterogeneous Multi-Agent Destructive Foraging](https://arxiv.org/abs/2602.10685)
*Alejandro Mendoza Barrionuevo,Samuel Yanes Luis,Daniel Gutiérrez Reina,Sergio L. Toral Marín*

Main category: cs.MA

TL;DR: 이 연구는 부분 관측 및 시간적 역할 의존성 아래에서 작동하는 이질적 다중 에이전트 시스템의 협력을 분석하는 문제를 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 다중 에이전트 시스템의 협력을 분석하는 새로운 메트릭스를 제시하여, 이전 연구의 요소를 개선하고자 하였습니다.

Method: 본 논문에서는 협력의 다양한 측면을 평가하기 위해 여러 범용 협력 메트릭스를 설계하였으며, 이를 여러 다중 에이전트 순차적 도메인에 적용 가능하도록 하였습니다.

Result: 제안한 메트릭스는 동적인 수면 청소에 비해 이질적 자율 차량을 사용한 파괴적 포락 시나리오에서 검증되었습니다.

Conclusion: 이 연구를 통해 제안된 메트릭스는 팀 간 및 팀 내의 협력적 의존성과 효율성을 포괄적으로 평가할 수 있으며, 다양한 알고리즘을 비교할 수 있는 유용한 도구가 될 것입니다.

Abstract: This work addresses the problem of analyzing cooperation in heterogeneous multi-agent systems which operate under partial observability and temporal role dependency, framed within a destructive multi-agent foraging setting. Unlike most previous studies, which focus primarily on algorithmic performance with respect to task completion, this article proposes a systematic set of general-purpose cooperation metrics aimed at characterizing not only efficiency, but also coordination and dependency between teams and agents, fairness, and sensitivity. These metrics are designed to be transferable to different multi-agent sequential domains similar to foraging. The proposed suite of metrics is structured into three main categories that jointly provide a multilevel characterization of cooperation: primary metrics, inter-team metrics, and intra-team metrics. They have been validated in a realistic destructive foraging scenario inspired by dynamic aquatic surface cleaning using heterogeneous autonomous vehicles. It involves two specialized teams with sequential dependencies: one focused on the search of resources, and another on their destruction. Several representative approaches have been evaluated, covering both learning-based algorithms and classical heuristic paradigms.

</details>


### [21] [The emergence of numerical representations in communicating artificial agents](https://arxiv.org/abs/2602.10996)
*Daniela Mihai,Lucas Weber,Francesca Franzon*

Main category: cs.MA

TL;DR: 인공 에이전트에서 수적 표현이 나타나기 위한 의사소통 압력이 충분한지와 이러한 코드가 인간 숫자와 유사한지에 대한 질문을 다루는 연구.


<details>
  <summary>Details</summary>
Motivation: 인간 언어가 수적 표현을 전달하는 효율적인 시스템을 제공하지만 인공 에이전트에서 나타날 수 있는지에 대한 의문.

Method: 두 개의 신경망 기반 에이전트를 연구하여 이산 토큰 또는 연속 스케치를 사용한 참조 게임에서 수량을 의사소통하도록 함.

Result: 사전 정의된 수적 개념 없이 두 통신 채널 모두에서 높은 의사소통 정확도를 달성하고 높은 정밀도의 기호-의미 매핑으로 수렴함.

Conclusion: 의사소통 압력만으로는 학습된 수적 표현의 정확한 전송이 가능하지만, 조합 코드를 생성하고 일반화 능력을 갖추기 위해 추가적인 압력이 필요함.

Abstract: Human languages provide efficient systems for expressing numerosities, but whether the sheer pressure to communicate is enough for numerical representations to arise in artificial agents, and whether the emergent codes resemble human numerals at all, remains an open question. We study two neural network-based agents that must communicate numerosities in a referential game using either discrete tokens or continuous sketches, thus exploring both symbolic and iconic representations. Without any pre-defined numeric concepts, the agents achieve high in-distribution communication accuracy in both communication channels and converge on high-precision symbol-meaning mappings. However, the emergent code is non-compositional: the agents fail to derive systematic messages for unseen numerosities, typically reusing the symbol of the highest trained numerosity (discrete), or collapsing extrapolated values onto a single sketch (continuous). We conclude that the communication pressure alone suffices for precise transmission of learned numerosities, but additional pressures are needed to yield compositional codes and generalisation abilities.

</details>


### [22] [Learning to Compose for Cross-domain Agentic Workflow Generation](https://arxiv.org/abs/2602.11114)
*Jialiang Wang,Shengxiang Xu,Hanmo Liu,Jiachuan Wang,Yuyu Luo,Shimin Di,Min-Ling Zhang,Lei Chen*

Main category: cs.MA

TL;DR: 이 논문에서는 복잡한 작업을 해결하기 위해 1회 생성으로 작업 특화된 워크플로우를 생성하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업을 단일 패스 LLM 생성이 신뢰할 수 있는 범위를 넘어 해결하려는 필요성.

Method: 다양한 도메인에서 재사용 가능한 워크플로우 기능을 학습하고, 이를 통해 입력 작업을 기초 위에 희소 구성으로 매핑하여 단일 패스에서 작업 특화된 워크플로우를 생성하는 메커니즘을 개발.

Result: 우리의 1회 생성기가 20회 반복을 소비하는 SOTA 정제 기준선보다 우수한 성능을 보였으며, 생성 지연 시간과 비용을 대폭 줄임.

Conclusion: 이 연구는 도메인 간 워크플로우 생성을 위한 효율적인 접근 방식을 제시하며, 높은 반복 비용과 불안정한 도메인 특이 행동을 해결할 수 있는 가능성을 입증했다.

Abstract: Automatically generating agentic workflows -- executable operator graphs or codes that orchestrate reasoning, verification, and repair -- has become a practical way to solve complex tasks beyond what single-pass LLM generation can reliably handle. Yet what constitutes a good workflow depends heavily on the task distribution and the available operators. Under domain shift, current systems typically rely on iterative workflow refinement to discover a feasible workflow from a large workflow space, incurring high iteration costs and yielding unstable, domain-specific behavior. In response, we internalize a decompose-recompose-decide mechanism into an open-source LLM for cross-domain workflow generation. To decompose, we learn a compact set of reusable workflow capabilities across diverse domains. To recompose, we map each input task to a sparse composition over these bases to generate a task-specific workflow in a single pass. To decide, we attribute the success or failure of workflow generation to counterfactual contributions from learned capabilities, thereby capturing which capabilities actually drive success by their marginal effects. Across stringent multi-domain, cross-domain, and unseen-domain evaluations, our 1-pass generator surpasses SOTA refinement baselines that consume 20 iterations, while substantially reducing generation latency and cost.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [23] [Signature-Kernel Based Evaluation Metrics for Robust Probabilistic and Tail-Event Forecasting](https://arxiv.org/abs/2602.10182)
*Benjamin R. Redhead,Thomas L. Lee,Peng Gu,Víctor Elvira,Amos Storkey*

Main category: cs.LG

TL;DR: 본 논문에서는 확률적 예측의 평가를 개선하기 위해 두 가지 새로운 커널 기반 지표를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 확률적 예측은 금융, 전염병 연구, 기후 과학 등 높은 위험이 수반되는 분야에서 점점 더 중요해지고 있지만, 현재의 평가 프레임워크는 합의된 지표가 부족하고 두 가지 주요 결함이 있습니다.

Method: 우리는 시그니처 최대 평균 불일치(Sig-MMD)와 새로운 검열된 Sig-MMD(CSig-MMD)라는 두 가지 커널 기반 지표를 제안합니다. 이 지표들은 시그니처 커널을 활용하여 복잡한 변수 간 및 시간 간 의존성을 포착하고 결측 데이터에 대해 강건합니다.

Result: CSig-MMD는 꼬리 사건 예측을 우선시하는 검열 기법을 도입하며, 이는 좋은 점수 규칙에 필수적인 적절성을 엄격하게 유지합니다.

Conclusion: 이러한 지표들은 직접 다중 단계 예측의 신뢰할 수 있는 평가를 가능하게 하여 더 강력한 확률적 알고리즘 개발을 촉진합니다.

Abstract: Probabilistic forecasting is increasingly critical across high-stakes domains, from finance and epidemiology to climate science. However, current evaluation frameworks lack a consensus metric and suffer from two critical flaws: they often assume independence across time steps or variables, and they demonstrably lack sensitivity to tail events, the very occurrences that are most pivotal in real-world decision-making. To address these limitations, we propose two kernel-based metrics: the signature maximum mean discrepancy (Sig-MMD) and our novel censored Sig-MMD (CSig-MMD). By leveraging the signature kernel, these metrics capture complex inter-variate and inter-temporal dependencies and remain robust to missing data. Furthermore, CSig-MMD introduces a censoring scheme that prioritizes a forecaster's capability to predict tail events while strictly maintaining properness, a vital property for a good scoring rule. These metrics enable a more reliable evaluation of direct multi-step forecasting, facilitating the development of more robust probabilistic algorithms.

</details>


### [24] [Neural Network Quantum Field Theory from Transformer Architectures](https://arxiv.org/abs/2602.10209)
*Dmitry S. Ageev,Yulia A. Ageeva*

Main category: cs.LG

TL;DR: 본 논문에서는 변환기 주의 헤드를 사용하여 유클리드 스칼라 양자장 이론을 신경망으로 구성하는 방법을 제안하며, 무작위 네트워크 매개변수에 대한 평균을 통해 $n$-점 상관관계를 정의합니다.


<details>
  <summary>Details</summary>
Motivation: 유클리드 스칼라 양자장 이론을 신경망 구조로 탐구하여, 무작위 매개변수에서 나오는 다양한 특성을 이해하고자 합니다.

Method: 신경망 양자장 이론(NN-QFT) 틀 안에서, 단일 주의 헤드와 공유된 무작위 softmax 가중치를 사용하여 여러 너비 좌표를 연결합니다.

Result: 두 점 함수와 연결된 네 점 함수를 계산하며, 무한 너비에서의 비정규화를 포함하는 통계 특성을 발견합니다.

Conclusion: 다수의 독립적인 헤드를 표준 $1/N_h$ 정규화를 사용하여 합산함으로써, 비정규 상관관계를 억제하여 가우시안 NN-QFT를 도출할 수 있음을 보여줍니다.

Abstract: We propose a neural-network construction of Euclidean scalar quantum field theories from transformer attention heads, defining $n$-point correlators by averaging over random network parameters in the NN-QFT framework. For a single attention head, shared random softmax weights couple different width coordinates and induce non-Gaussian field statistics that persist in the infinite-width limit $d_k\to\infty$. We compute the two-point function in an attention-weight representation and show how Euclidean-invariant kernels can be engineered via random-feature token embeddings. We then analyze the connected four-point function and identify an "independence-breaking" contribution, expressible as a covariance over query-key weights, which remains finite at infinite width. Finally, we show that summing many independent heads with standard $1/N_h$ normalization suppresses connected non-Gaussian correlators as $1/N_h$, yielding a Gaussian NN-QFT in the large-head limit.

</details>


### [25] [Self-Evolving Recommendation System: End-To-End Autonomous Model Optimization With LLM Agents](https://arxiv.org/abs/2602.10226)
*Haochen Wang,Yi Wu,Daryl Chang,Li Wei,Lukasz Heldt*

Main category: cs.LG

TL;DR: 이 논문에서는 대규모 기계 학습 시스템을 최적화하기 위한 자가 발전 시스템을 제안하며, 이 시스템은 Google의 Gemini 패밀리에서 제공하는 대형 언어 모델을 활용하여 고성능 모델 변화를 자율적으로 생성, 훈련 및 배포합니다.


<details>
  <summary>Details</summary>
Motivation: 글로벌 비디오 플랫폼을 위한 추천 모델 등의 대규모 기계 학습 시스템을 최적화하는 것은 방대한 하이퍼파라미터 검색 공간을 탐색하고 복잡한 최적화기 및 보상 함수를 설계하는 문제입니다.

Method: 자가 발전 시스템은 프록시 메트릭스를 사용하여 고속 가설 생성을 수행하는 Offline Agent(Inner Loop)와 실시간 프로덕션에서 지연된 비즈니스 메트릭에 대한 후보를 검증하는 Online Agent(Outer Loop)로 구성됩니다.

Result: YouTube에서 여러 성공적인 프로덕션 론칭을 통해 이 접근 방식의 효과가 입증되어, 자율적인 LLM 기반 발전이 전통적인 엔지니어링 워크플로우를 초과할 수 있음을 확인했습니다.

Conclusion: 이 시스템은 기계 학습 엔지니어처럼 작용하며, 최적화 알고리즘 및 모델 아키텍처에서 새로운 개선점을 발견하고 장기적인 사용자 참여를 목표로 하는 혁신적인 보상 함수를 구성합니다.

Abstract: Optimizing large-scale machine learning systems, such as recommendation models for global video platforms, requires navigating a massive hyperparameter search space and, more critically, designing sophisticated optimizers, architectures, and reward functions to capture nuanced user behaviors. Achieving substantial improvements in these areas is a non-trivial task, traditionally relying on extensive manual iterations to test new hypotheses. We propose a self-evolving system that leverages Large Language Models (LLMs), specifically those from Google's Gemini family, to autonomously generate, train, and deploy high-performing, complex model changes within an end-to-end automated workflow. The self-evolving system is comprised of an Offline Agent (Inner Loop) that performs high-throughput hypothesis generation using proxy metrics, and an Online Agent (Outer Loop) that validates candidates against delayed north star business metrics in live production. Our agents act as specialized Machine Learning Engineers (MLEs): they exhibit deep reasoning capabilities, discovering novel improvements in optimization algorithms and model architecture, and formulating innovative reward functions that target long-term user engagement. The effectiveness of this approach is demonstrated through several successful production launches at YouTube, confirming that autonomous, LLM-driven evolution can surpass traditional engineering workflows in both development velocity and model performance.

</details>


### [26] [ICODEN: Ordinary Differential Equation Neural Networks for Interval-Censored Data](https://arxiv.org/abs/2602.10303)
*Haoling Wang,Lang Zeng,Tao Sun,Youngjoo Cho,Ying Ding*

Main category: cs.LG

TL;DR: ICODEN은 간섭된 데이터의 생존 예측을 위한 신경망 모델로, 기존 접근법의 가정 없이 유연한 생존 모델링을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 간섭된 이벤트 시간의 예측은 정확한 이벤트 시간이 관찰되지 않아 어려움이 있다. 기존 생존 분석 방법은 강한 모델 가정에 의존하거나 고차원 예측 변수를 처리할 수 없다.

Method: ICODEN은 간섭된 데이터에 대해 위험 함수를 깊은 신경망을 통해 모델링하고, 정규 미분 방정식을 해결하여 누적 위험을 얻는 신경망 기반의 모델이다.

Result: ICODEN은 다양한 가상 설정에서 만족스러운 예측 정확도를 지속적으로 달성하며, 예측 변수가 증가해도 안정성을 유지한다. 알츠하이머병 신경영상 이니셔티브(ADNI)와 연령 관련 황반 변성(AMD) 연구로부터의 데이터에 대한 적용에서 ICODEN의 강력한 예측 성능을 보여준다.

Conclusion: ICODEN은 고차원 생물 의학 설정에서 간섭된 생존 데이터를 예측하기 위한 실용적인 도구로 자리매김한다.

Abstract: Predicting time-to-event outcomes when event times are interval censored is challenging because the exact event time is unobserved. Many existing survival analysis approaches for interval-censored data rely on strong model assumptions or cannot handle high-dimensional predictors. We develop ICODEN, an ordinary differential equation-based neural network for interval-censored data that models the hazard function through deep neural networks and obtains the cumulative hazard by solving an ordinary differential equation. ICODEN does not require the proportional hazards assumption or a prespecified parametric form for the hazard function, thereby permitting flexible survival modeling. Across simulation settings with proportional or non-proportional hazards and both linear and nonlinear covariate effects, ICODEN consistently achieves satisfactory predictive accuracy and remains stable as the number of predictors increases. Applications to data from multiple phases of the Alzheimer's Disease Neuroimaging Initiative (ADNI) and to two Age-Related Eye Disease Studies (AREDS and AREDS2) for age-related macular degeneration (AMD) demonstrate ICODEN's robust prediction performance. In both applications, predicting time-to-AD or time-to-late AMD, ICODEN effectively uses hundreds to more than 1,000 SNPs and supports data-driven subgroup identification with differential progression risk profiles. These results establish ICODEN as a practical assumption-lean tool for prediction with interval-censored survival data in high-dimensional biomedical settings.

</details>


### [27] [Confounding Robust Continuous Control via Automatic Reward Shaping](https://arxiv.org/abs/2602.10305)
*Mateo Juliani,Mingxuan Li,Elias Bareinboim*

Main category: cs.LG

TL;DR: 이 논문은 연속 제어 문제를 위한 보상 형성 함수를 자동으로 학습하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 연속 제어 문제에 대해 효과적인 보상 형성 함수 설계의 원리가 충분히 설명되지 않았다.

Method: 오프라인 데이터셋에서 관측되지 않은 혼란 변수가 포함될 가능성을 고려하여 보상 형성 함수를 자동으로 학습하는 방법을 제안한다. 이 방법은 최근에 제안된 인과적 벨만 방정식을 기반으로 하여 최적 상태 값의 tight upper bound를 학습하고, 이를 PBRS 프레임워크의 잠재적으로 사용한다.

Result: 제안된 보상 형성 알고리즘은 Soft-Actor-Critic을 사용하여 여러 연속 제어 벤치마크에서 강력한 성능 보장을 나타낸다.

Conclusion: 소위 인과적 관점에서 혼란에 대한 강인한 연속 제어를 향한 첫 번째 단계를 제시한다.

Abstract: Reward shaping has been applied widely to accelerate Reinforcement Learning (RL) agents' training. However, a principled way of designing effective reward shaping functions, especially for complex continuous control problems, remains largely under-explained. In this work, we propose to automatically learn a reward shaping function for continuous control problems from offline datasets, potentially contaminated by unobserved confounding variables. Specifically, our method builds upon the recently proposed causal Bellman equation to learn a tight upper bound on the optimal state values, which is then used as the potentials in the Potential-Based Reward Shaping (PBRS) framework. Our proposed reward shaping algorithm is tested with Soft-Actor-Critic (SAC) on multiple commonly used continuous control benchmarks and exhibits strong performance guarantees under unobserved confounders. More broadly, our work marks a solid first step towards confounding robust continuous control from a causal perspective. Code for training our reward shaping functions can be found at https://github.com/mateojuliani/confounding_robust_cont_control.

</details>


### [28] [Identifying Evidence-Based Nudges in Biomedical Literature with Large Language Models](https://arxiv.org/abs/2602.10345)
*Jaydeep Chauhan,Mark Seidman,Pezhman Raeisian Parvari,Zhi Zheng,Zina Ben-Miled,Cristina Barboi,Andrew Gonzalez,Malaz Boustani*

Main category: cs.LG

TL;DR: AI 기반 시스템이 비구조적 생물 의학 문헌에서 증거 기반 행동 유도 요소를 식별하고 추출하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 행동 유도 요소는 선택을 제한하지 않고 행동에 영향을 미치는 미세하고 비강압적인 개입입니다. 그들은 약물 순응과 같은 건강 결과에 강한 영향을 미칩니다.

Method: 하이브리드 필터링을 통해 약 81,000개의 후보로 축소하고, OpenScholar를 사용하여 논문을 분류하고 구조화된 필드를 추출합니다.

Result: 제일 좋은 설정이 67.0%의 F1 점수와 72.0%의 재현율을 달성했습니다. 자기 일관성을 사용하는 변형은 100%의 정밀도와 12%의 재현율을 달성했습니다.

Conclusion: 이 시스템은 LLM 생성 개입을 동료 검토된 증거에 기반하여 실제 플랫폼인 Agile Nudge+에 통합되고 있습니다.

Abstract: We present a scalable, AI-powered system that identifies and extracts evidence-based behavioral nudges from unstructured biomedical literature. Nudges are subtle, non-coercive interventions that influence behavior without limiting choice, showing strong impact on health outcomes like medication adherence. However, identifying these interventions from PubMed's 8 million+ articles is a bottleneck. Our system uses a novel multi-stage pipeline: first, hybrid filtering (keywords, TF-IDF, cosine similarity, and a "nudge-term bonus") reduces the corpus to about 81,000 candidates. Second, we use OpenScholar (quantized LLaMA 3.1 8B) to classify papers and extract structured fields like nudge type and target behavior in a single pass, validated against a JSON schema.
  We evaluated four configurations on a labeled test set (N=197). The best setup (Title/Abstract/Intro) achieved a 67.0% F1 score and 72.0% recall, ideal for discovery. A high-precision variant using self-consistency (7 randomized passes) achieved 100% precision with 12% recall, demonstrating a tunable trade-off for high-trust use cases. This system is being integrated into Agile Nudge+, a real-world platform, to ground LLM-generated interventions in peer-reviewed evidence. This work demonstrates interpretable, domain-specific retrieval pipelines for evidence synthesis and personalized healthcare.

</details>


### [29] [Affordances Enable Partial World Modeling with LLMs](https://arxiv.org/abs/2602.10390)
*Khimya Khetarpal,Gheorghe Comanici,Jonathan Richens,Jeremy Shar,Fei Xia,Laurent Orseau,Aleksandra Faust,Doina Precup*

Main category: cs.LG

TL;DR: 이 논문은 대형 모델이 부분 세계 모델로 작용할 수 있는지에 대한 질문에 답하고, 예측 가능한 부분 세계 모델을 통해 검색 효율성을 높이는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 모델들이 인터넷 데이터를 통해 광범위하게 훈련되었지만 검색 절차에서 이를 직접 사용하는 것은 비효율적이고 부정확합니다.

Method: 과업 비관련적, 언어 조건의 의도를 달성하는 에이전트가 필요로 하는 예측 가능한 부분 세계 모델을 증명합니다. 또한 배급 강건성을 가진 affordance를 도입하여 부분 모델을 추출하여 검색 효율성을 크게 향상시킬 수 있음을 보여줍니다.

Result: 테이블탑 로봇 작업에서 affordance-aware 부분 모델이 검색 분기 계수를 줄이고 전체 세계 모델에 비해 높은 보상을 달성하는 것을 실증적으로 평가했습니다.

Conclusion: 우리의 연구는 부분 모델이 대형 모델보다 검색 효율성을 개선할 수 있음을 주장하며, 실용적인 로봇 작업에 대한 성과를 보여줍니다.

Abstract: Full models of the world require complex knowledge of immense detail. While pre-trained large models have been hypothesized to contain similar knowledge due to extensive pre-training on vast amounts of internet scale data, using them directly in a search procedure is inefficient and inaccurate. Conversely, partial models focus on making high quality predictions for a subset of state and actions: those linked through affordances that achieve user intents~\citep{khetarpal2020can}. Can we posit large models as partial world models? We provide a formal answer to this question, proving that agents achieving task-agnostic, language-conditioned intents necessarily possess predictive partial-world models informed by affordances. In the multi-task setting, we introduce distribution-robust affordances and show that partial models can be extracted to significantly improve search efficiency. Empirical evaluations in tabletop robotics tasks demonstrate that our affordance-aware partial models reduce the search branching factor and achieve higher rewards compared to full world models.

</details>


### [30] [Modular Multi-Task Learning for Chemical Reaction Prediction](https://arxiv.org/abs/2602.10404)
*Jiayun Pang,Ahmed M. Zaitoun,Xacobe Couso Cambeiro,Ivan Vulić*

Main category: cs.LG

TL;DR: 본 연구는 화학 및 제약 연구 개발에 있어 대규모 언어 모델을 도메인 특화 반응 데이터셋에 효과적으로 적응시키기 위한 Low-Rank Adaptation (LoRA) 방법을 평가하였다.


<details>
  <summary>Details</summary>
Motivation: 화학 및 제약 R&D에서 대규모 언어 모델(LLM)을 특화된 반응 데이터셋에 적응시키는 것은 중요한 도전 과제이다.

Method: 우리는 제한적이고 복잡한 데이터셋에서 유기 반응 예측을 위한 전체 미세 조정의 대안으로서 매개변수 효율적인 LoRA를 평가하고, USPTO 반응 클래스와 C-H 기능화 반응을 사용하여 다양한 예측 작업을 벤치마크하였다.

Result: LoRA는 전체 미세 조정과 유사한 정확성을 달성하며, 치명적인 망각을 효과적으로 완화하고 다중 작업 성능을 더 잘 유지한다.

Conclusion: 결과적으로, LLM의 확장이 계속됨에 따라, 우리의 연구는 화학 응용을 위한 유연한 배치에 적합한 모듈화된, 매개변수 효율적인 미세 조정 전략의 실용성을 강조한다.

Abstract: Adapting large language models (LLMs) trained on broad organic chemistry to smaller, domain-specific reaction datasets is a key challenge in chemical and pharmaceutical R&D. Effective specialisation requires learning new reaction knowledge while preserving general chemical understanding across related tasks. Here, we evaluate Low-Rank Adaptation (LoRA) as a parameter-efficient alternative to full fine-tuning for organic reaction prediction on limited, complex datasets. Using USPTO reaction classes and challenging C-H functionalisation reactions, we benchmark forward reaction prediction, retrosynthesis and reagent prediction. LoRA achieves accuracy comparable to full fine-tuning while effectively mitigating catastrophic forgetting and better preserving multi-task performance. Both fine-tuning approaches generalise beyond training distributions, producing plausible alternative solvent predictions. Notably, C-H functionalisation fine-tuning reveals that LoRA and full fine-tuning encode subtly different reactivity patterns, suggesting more effective reaction-specific adaptation with LoRA. As LLMs continue to scale, our results highlight the practicality of modular, parameter-efficient fine-tuning strategies for their flexible deployment for chemistry applications.

</details>


### [31] [Low-Dimensional Execution Manifolds in Transformer Learning Dynamics: Evidence from Modular Arithmetic Tasks](https://arxiv.org/abs/2602.10496)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 과적합된 트랜스포머 모델의 학습 동역학의 기하학적 구조를 조사하였다. 고차원 매개변수 공간에서 트랜스포머 훈련 경로가 저차원 실행 다양체로 빠르게 수렴하는 현상을 발견하였다.


<details>
  <summary>Details</summary>
Motivation: 과적합된 트랜스포머 모델의 학습 동역학을 이해하기 위해 기하학적 구조를 조사하고자 하였다.

Method: 모듈러 산술 작업을 통해 엄격하게 통제된 실험을 수행하였다.

Result: 훈련 경로가 3-4차원 저차원 실행 다양체에 수렴하며, 이는 랜덤 시드와 중간 난이도 과제에서 강건하게 관찰되었다.

Conclusion: 대부분의 매개변수가 최적화 간섭을 흡수하는 역할을 하며, 핵심 계산이 극적으로 축소된 서브스페이스에서 이루어짐을 제안한다.

Abstract: We investigate the geometric structure of learning dynamics in overparameterized transformer models through carefully controlled modular arithmetic tasks. Our primary finding is that despite operating in high-dimensional parameter spaces ($d=128$), transformer training trajectories rapidly collapse onto low-dimensional execution manifolds of dimension $3$--$4$. This dimensional collapse is robust across random seeds and moderate task difficulties, though the orientation of the manifold in parameter space varies between runs. We demonstrate that this geometric structure underlies several empirically observed phenomena: (1) sharp attention concentration emerges as saturation along routing coordinates within the execution manifold, (2) stochastic gradient descent (SGD) exhibits approximately integrable dynamics when projected onto the execution subspace, with non-integrability confined to orthogonal staging directions, and (3) sparse autoencoders capture auxiliary routing structure but fail to isolate execution itself, which remains distributed across the low-dimensional manifold. Our results suggest a unifying geometric framework for understanding transformer learning, where the vast majority of parameters serve to absorb optimization interference while core computation occurs in a dramatically reduced subspace. These findings have implications for interpretability, training curriculum design, and understanding the role of overparameterization in neural network learning.

</details>


### [32] [Learning Structure-Semantic Evolution Trajectories for Graph Domain Adaptation](https://arxiv.org/abs/2602.10506)
*Wei Chen,Xingyu Guo,Shuang Li,Yan Zhong,Zhao Zhang,Fuzhen Zhuang,Hongrui Liu,Libang Zhang,Guo Ye,Huimei He*

Main category: cs.LG

TL;DR: DiffGDA는 그래프 도메인 적응을 위한 지속적인 변환 과정을 모델링한 방법으로, 기존의 이산적 접근 방식을 개선하여 실세계에서의 그래프 구조 변화를 효과적으로 반영합니다.


<details>
  <summary>Details</summary>
Motivation: 그래프 도메인 적응에서 소스 그래프에서 타겟 그래프로의 지식 전이를 통해 분포 변화를 극복하고자 하는 필요성이 있음.

Method: DiffGDA는 그래프 도메인 적응 과정을 연속적인 생성 과정으로 모델링하고, 확률 미분 방정식을 사용하여 소스 그래프에서 타겟 그래프로의 진화를 형성합니다.

Result: DiffGDA는 14개의 그래프 전이 작업을 대상으로 한 8개의 실제 데이터세트에서 실험을 통해 최첨단 기준을 지속적으로 초월함을 입증했습니다.

Conclusion: DiffGDA는 최적의 적용 경로를 따르는 확산 경로를 지향하여 소스와 타겟 도메인 간의 최적 솔루션에 수렴함을 이론적으로 증명합니다.

Abstract: Graph Domain Adaptation (GDA) aims to bridge distribution shifts between domains by transferring knowledge from well-labeled source graphs to given unlabeled target graphs. One promising recent approach addresses graph transfer by discretizing the adaptation process, typically through the construction of intermediate graphs or stepwise alignment procedures. However, such discrete strategies often fail in real-world scenarios, where graph structures evolve continuously and nonlinearly, making it difficult for fixed-step alignment to approximate the actual transformation process. To address these limitations, we propose \textbf{DiffGDA}, a \textbf{Diff}usion-based \textbf{GDA} method that models the domain adaptation process as a continuous-time generative process. We formulate the evolution from source to target graphs using stochastic differential equations (SDEs), enabling the joint modeling of structural and semantic transitions. To guide this evolution, a domain-aware network is introduced to steer the generative process toward the target domain, encouraging the diffusion trajectory to follow an optimal adaptation path. We theoretically show that the diffusion process converges to the optimal solution bridging the source and target domains in the latent space. Extensive experiments on 14 graph transfer tasks across 8 real-world datasets demonstrate DiffGDA consistently outperforms state-of-the-art baselines.

</details>


### [33] [Towards Autonomous Mathematics Research](https://arxiv.org/abs/2602.10177)
*Tony Feng,Trieu H. Trinh,Garrett Bingham,Dawsen Hwang,Yuri Chervonyi,Junehyuk Jung,Joonkyung Lee,Carlo Pagano,Sang-hyun Kim,Federico Pasqualotto,Sergei Gukov,Jonathan N. Lee,Junsu Kim,Kaiying Hou,Golnaz Ghiasi,Yi Tay,YaGuang Li,Chenkai Kuang,Yuan Liu,Hanzhao,Lin,Evan Zheran Liu,Nigamaa Nayakanti,Xiaomeng Yang,Heng-tze Cheng,Demis Hassabis,Koray Kavukcuoglu,Quoc V. Le,Thang Luong*

Main category: cs.LG

TL;DR: Aletheia는 자연어로 수학 문제를 해결하고, 검증하고, 수정하는 연구 에이전트로, AI와 수학의 협력을 보여준다.


<details>
  <summary>Details</summary>
Motivation: AI의 수학적 연구에서의 활용을 촉진하고, AI와 인간 간의 협업 방식을 탐구하기 위해.

Method: Aletheia는 자연어로 수학 문제를 반복적으로 생성, 검증 및 수정하며, Gemini Deep Think의 고급 버전을 사용한다.

Result: Aletheia는 여러 AI 보조 수학 연구 이정표를 통해 문제 해결 능력을 입증하였으며, 연구 논문을 생성했다.

Conclusion: 인간-AI 협업의 중요성과 AI 지원 결과의 자율성과 참신성에 대한 기준 설정의 필요성을 강조한다.

Abstract: Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is powered by an advanced version of Gemini Deep Think for challenging reasoning problems, a novel inference-time scaling law that extends beyond Olympiad-level problems, and intensive tool use to navigate the complexities of mathematical research. We demonstrate the capability of Aletheia from Olympiad problems to PhD-level exercises and most notably, through several distinct milestones in AI-assisted mathematics research: (a) a research paper (Feng26) generated by AI without any human intervention in calculating certain structure constants in arithmetic geometry called eigenweights; (b) a research paper (LeeSeo26) demonstrating human-AI collaboration in proving bounds on systems of interacting particles called independent sets; and (c) an extensive semi-autonomous evaluation (Feng et al., 2026a) of 700 open problems on Bloom's Erdos Conjectures database, including autonomous solutions to four open questions. In order to help the public better understand the developments pertaining to AI and mathematics, we suggest codifying standard levels quantifying autonomy and novelty of AI-assisted results. We conclude with reflections on human-AI collaboration in mathematics.

</details>


### [34] [Don't Eliminate Cut: Exponential Separations in LLM-Based Theorem Proving](https://arxiv.org/abs/2602.10512)
*Sho Sonoda,Shunta Akiyama,Yuya Uezato*

Main category: cs.LG

TL;DR: 이 논문에서는 LLM을 활용한 형식 정리 증명을 이론적으로 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 인터랙티브 증명 보조 프로그램에서 LLM이 정리 증명을 어떻게 지원할 수 있는지를 이해하기 위함입니다.

Method: 작전 제안을 유한 수의 결정적 MDP에서의 확률 정책으로 모델링하였습니다.

Result: 층화 기법과 특정 조건 하에서 성공 확률에 대한 하한을 도출하였습니다.

Conclusion: 비용 인식 계층 구조 학습자가 더 많은 데이터를 요구한다는 것을 증명함으로써 최근 에이전트 증명기에서의 서브골 분해에 대한 원칙적인 정당성을 제공합니다.

Abstract: We develop a theoretical analysis of LLM-guided formal theorem proving in interactive proof assistants (e.g., Lean) by modeling tactic proposal as a stochastic policy in a finite-horizon deterministic MDP. To capture modern representation learning, we treat the state and action spaces as general compact metric spaces and assume Lipschitz policies. To explain the gap between worst-case hardness and empirical success, we introduce problem distributions generated by a reference policy $q$, including a latent-variable model in which proofs exhibit reusable cut/lemma/sketch structure represented by a proof DAG. Under a top-$k$ search protocol and Tsybakov-type margin conditions, we derive lower bounds on finite-horizon success probability that decompose into search and learning terms, with learning controlled by sequential Rademacher/covering complexity. Our main separation result shows that when cut elimination expands a DAG of depth $D$ into a cut-free tree of size $Ω(Λ^D)$ while the cut-aware hierarchical process has size $O(λ^D)$ with $λ\llΛ$, a flat (cut-free) learner provably requires exponentially more data than a cut-aware hierarchical learner. This provides a principled justification for subgoal decomposition in recent agentic theorem provers.

</details>


### [35] [Kill it with FIRE: On Leveraging Latent Space Directions for Runtime Backdoor Mitigation in Deep Neural Networks](https://arxiv.org/abs/2602.10780)
*Enrico Ahlers,Daniel Passon,Yannic Noller,Lars Grunske*

Main category: cs.LG

TL;DR: 본 연구는 머신러닝 모델의 백도어 취약점을 해결하기 위한 FIRE라는 새로운 접근법을 제안하며, 이는 기존의 해결책에 비해 효율성과 성능에서 우수하다.


<details>
  <summary>Details</summary>
Motivation: 현대 사회에서 머신러닝 모델이 광범위하게 사용됨에 따라, 이들은 악의적인 공격자로부터의 백도어 공격 등의 위험에 노출된다.

Method: FIRE(Feature-space Inference-time REpair)라는 추론 시간 백도어 완화 접근 방식을 제안하며, 이는 모델 내부 표현의 변경을 이용하여 입력 샘플의 특성을 조작하는 방식이다.

Result: FIRE는 낮은 계산 오버헤드로 여러 공격, 데이터셋 및 네트워크 아키텍처에서 기존 런타임 완화 방법보다 우수한 성능을 보인다.

Conclusion: 운영 중인 취약한 모델에 대해 효과적이고 효율적으로 대응할 수 있는 방법을 제공한다.

Abstract: Machine learning models are increasingly present in our everyday lives; as a result, they become targets of adversarial attackers seeking to manipulate the systems we interact with. A well-known vulnerability is a backdoor introduced into a neural network by poisoned training data or a malicious training process. Backdoors can be used to induce unwanted behavior by including a certain trigger in the input. Existing mitigations filter training data, modify the model, or perform expensive input modifications on samples. If a vulnerable model has already been deployed, however, those strategies are either ineffective or inefficient. To address this gap, we propose our inference-time backdoor mitigation approach called FIRE (Feature-space Inference-time REpair). We hypothesize that a trigger induces structured and repeatable changes in the model's internal representation. We view the trigger as directions in the latent spaces between layers that can be applied in reverse to correct the inference mechanism. Therefore, we turn the backdoored model against itself by manipulating its latent representations and moving a poisoned sample's features along the backdoor directions to neutralize the trigger. Our evaluation shows that FIRE has low computational overhead and outperforms current runtime mitigations on image benchmarks across various attacks, datasets, and network architectures.

</details>


### [36] [Roughness-Informed Federated Learning](https://arxiv.org/abs/2602.10595)
*Mohammad Partohaghighi,Roummel Marcia,Bruce J. West,YangQuan Chen*

Main category: cs.LG

TL;DR: RI-FedAvg는 분산 클라이언트 간의 협업 모델 훈련을 지원하는 연합 학습(Federated Learning) 알고리즘으로, 클라이언트 드리프트를 완화하여 비독립적이고 동일하게 분포되지 않은(non-IID) 환경에서도 효율적인 성능을 보장합니다.


<details>
  <summary>Details</summary>
Motivation: 비독립적이며 동일하게 분포되지 않은 환경에서의 클라이언트 드리프트 문제를 해결하여 연합 학습의 수렴성을 향상시키기 위함입니다.

Method: 로컬 목적 함수에 Roughness Index(비틀림 지수) 기반의 정규화 항을 도입하여 로컬 손실 경관의 변동에 따라 업데이트에 적응적으로 페널티를 부여하는 RI-FedAvg 알고리즘을 제안합니다.

Result: RI-FedAvg는 MNIST, CIFAR-10, CIFAR-100 데이터셋에서 FedAvg, FedProx, FedDyn, SCAFFOLD, DP-FedAvg 등 기존 기법들보다 높은 정확도와 빠른 수렴을 달성하였습니다.

Conclusion: RI-FedAvg는 비독립적이고 이질적인 환경에서 연합 학습의 강인성과 효율성을 향상시킬 수 있는 잠재력을 지닙니다.

Abstract: Federated Learning (FL) enables collaborative model training across distributed clients while preserving data privacy, yet faces challenges in non-independent and identically distributed (non-IID) settings due to client drift, which impairs convergence. We propose RI-FedAvg, a novel FL algorithm that mitigates client drift by incorporating a Roughness Index (RI)-based regularization term into the local objective, adaptively penalizing updates based on the fluctuations of local loss landscapes. This paper introduces RI-FedAvg, leveraging the RI to quantify the roughness of high-dimensional loss functions, ensuring robust optimization in heterogeneous settings. We provide a rigorous convergence analysis for non-convex objectives, establishing that RI-FedAvg converges to a stationary point under standard assumptions. Extensive experiments on MNIST, CIFAR-10, and CIFAR-100 demonstrate that RI-FedAvg outperforms state-of-the-art baselines, including FedAvg, FedProx, FedDyn, SCAFFOLD, and DP-FedAvg, achieving higher accuracy and faster convergence in non-IID scenarios. Our results highlight RI-FedAvg's potential to enhance the robustness and efficiency of federated learning in practical, heterogeneous environments.

</details>


### [37] [Domain Knowledge Guided Bayesian Optimization For Autonomous Alignment Of Complex Scientific Instruments](https://arxiv.org/abs/2602.10670)
*Aashwin Mishra,Matt Seaberg,Ryan Roussel,Daniel Ratner,Apurva Mehta*

Main category: cs.LG

TL;DR: 이 논문은 복잡한 비선형 시스템을 최적화하기 위한 새로운 접근 방식인 도메인 지식 기반 베이지안 최적화를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 고차원 문제에서의 성능 저하와 희소 보상 문제를 해결하기 위해.

Method: 물리적 통찰력을 활용하여 좌표 변환을 통해 입력 특성을 분리하고 활성 부분 공간을 주요 탐색 축과 정렬하는 방식으로 최적화 문제를 단순화하는 방법을 제안합니다.

Result: 전통적인 방법이 일관되게 불만족스러운 결과를 초래하는 12차원, 6결정체 Split-and-Delay 광학 시스템에서 효과성을 입증하였습니다.

Conclusion: 좌표 변환이 핵심이며, 이 접근 방식은 복잡한 과학 기계의 높은 차원 최적화에 대한 수요를 충족시키는 데 기여할 수 있습니다.

Abstract: Bayesian Optimization (BO) is a powerful tool for optimizing complex non-linear systems. However, its performance degrades in high-dimensional problems with tightly coupled parameters and highly asymmetric objective landscapes, where rewards are sparse. In such needle-in-a-haystack scenarios, even advanced methods like trust-region BO (TurBO) often lead to unsatisfactory results. We propose a domain knowledge guided Bayesian Optimization approach, which leverages physical insight to fundamentally simplify the search problem by transforming coordinates to decouple input features and align the active subspaces with the primary search axes. We demonstrate this approach's efficacy on a challenging 12-dimensional, 6-crystal Split-and-Delay optical system, where conventional approaches, including standard BO, TuRBO and multi-objective BO, consistently led to unsatisfactory results. When combined with an reverse annealing exploration strategy, this approach reliably converges to the global optimum. The coordinate transformation itself is the key to this success, significantly accelerating the search by aligning input co-ordinate axes with the problem's active subspaces. As increasingly complex scientific instruments, from large telescopes to new spectrometers at X-ray Free Electron Lasers are deployed, the demand for robust high-dimensional optimization grows. Our results demonstrate a generalizable paradigm: leveraging physical insight to transform high-dimensional, coupled optimization problems into simpler representations can enable rapid and robust automated tuning for consistent high performance while still retaining current optimization algorithms.

</details>


### [38] [Transport, Don't Generate: Deterministic Geometric Flows for Combinatorial Optimization](https://arxiv.org/abs/2602.10794)
*Benjy Friedmann,Nadav Dym*

Main category: cs.LG

TL;DR: CycFlow는 Euclidean TSP 문제를 해결하기 위해 반복적 엣지 디노이징을 결정론적 포인트 전송으로 대체하는 방법을 제안하며, 기존 방식 대비 최대 1000배 더 빠른 속도로 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: Neural Combinatorial Optimization 분야에서의 최근 발전은 Euclidean TSP 문제를 확률적 열지도 생성 작업으로 취급하는 확산 모델에 의해 주도되고 있다.

Method: CycFlow는 반복적 엣지 디노이징 대신 결정론적 포인트 전송을 사용하여, 입력된 2D 좌표를 최적 순회가 복원될 원형 배치로 연속적으로 전달하는 instance-conditioned 벡터 필드를 학습한다.

Result: 데이터 의존적 흐름 일치를 활용하여 엣지 스코어링의 2차 병목 현상을 피하고 선형 좌표 동학을 선호하여 속도를 획기적으로 증가시킨다.

Conclusion: 이러한 패러다임 전환은 최신 확산 기준에 비해 최대 1000배의 속도로 문제를 해결하며 경쟁력 있는 최적성 격차를 유지한다.

Abstract: Recent advances in Neural Combinatorial Optimization (NCO) have been dominated by diffusion models that treat the Euclidean Traveling Salesman Problem (TSP) as a stochastic $N \times N$ heatmap generation task. In this paper, we propose CycFlow, a framework that replaces iterative edge denoising with deterministic point transport. CycFlow learns an instance-conditioned vector field that continuously transports input 2D coordinates to a canonical circular arrangement, where the optimal tour is recovered from this $2N$ dimensional representation via angular sorting. By leveraging data-dependent flow matching, we bypass the quadratic bottleneck of edge scoring in favor of linear coordinate dynamics. This paradigm shift accelerates solving speed by up to three orders of magnitude compared to state-of-the-art diffusion baselines, while maintaining competitive optimality gaps.

</details>


### [39] [ICA: Information-Aware Credit Assignment for Visually Grounded Long-Horizon Information-Seeking Agents](https://arxiv.org/abs/2602.10863)
*Cong Pang,Xuyu Feng,Yujie Yi,Zixuan Chen,Jiawei Hong,Tiankuo Yao,Nang Yuan,Jiapeng Luo,Lewei Lu,Xin Lou*

Main category: cs.LG

TL;DR: 비주얼 기반 검색 프레임워크와 정보 인식 신용 할당 방식을 통해 정보 탐색 에이전트의 성능을 향상시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 정보 탐색 에이전트의 강력한 성과에도 불구하고 웹 환경에서의 학습은 낮은 신호 대 잡음 비율에 의해 심각한 제약을 받는다.

Method: 웹 페이지를 비주얼 스냅샷으로 표현하는 비주얼 네이티브 검색 프레임워크와 정보 인식 신용 할당(ICA) 방법을 제안한다.

Result: 정보 탐색 벤치마크에서 텍스트 기반 기준을 일관되게 초과하는 성능을 보였다.

Conclusion: 비주얼 스냅샷 기반의 정보 수준 신용 할당이 웹 환경에서의 신용 할당 병목 문제를 완화하는 데 기여한다.

Abstract: Despite the strong performance achieved by reinforcement learning-trained information-seeking agents, learning in open-ended web environments remains severely constrained by low signal-to-noise feedback. Text-based parsers often discard layout semantics and introduce unstructured noise, while long-horizon training typically relies on sparse outcome rewards that obscure which retrieval actions actually matter. We propose a visual-native search framework that represents webpages as visual snapshots, allowing agents to leverage layout cues to quickly localize salient evidence and suppress distractors. To learn effectively from these high-dimensional observations, we introduce Information-Aware Credit Assignment (ICA), a post-hoc method that estimates each retrieved snapshot's contribution to the final outcome via posterior analysis and propagates dense learning signals back to key search turns. Integrated with a GRPO-based training pipeline, our approach consistently outperforms text-based baselines on diverse information-seeking benchmarks, providing evidence that visual snapshot grounding with information-level credit assignment alleviates the credit-assignment bottleneck in open-ended web environments. The code and datasets will be released in https://github.com/pc-inno/ICA_MM_deepsearch.git.

</details>


### [40] [CMAD: Cooperative Multi-Agent Diffusion via Stochastic Optimal Control](https://arxiv.org/abs/2602.10933)
*Riccardo Barbano,Alexander Denker,Zeljko Kereta,Runchang Li,Francisco Vargas*

Main category: cs.LG

TL;DR: 본 논문에서는 여러 사전 훈련된 생성 모델의 조합을 최적 제어 문제로 재구성하는 새로운 패러다임을 제안하며, 이를 통해 더 나은 이미지 생성 및 복원 성능을 달성합니다.


<details>
  <summary>Details</summary>
Motivation: 여러 사전 훈련된 모델의 조합을 제어하는 것은 여전히 해결해야 할 과제입니다.

Method: 사전 훈련된 확산 모델을 서로 상호작용하는 에이전트로 간주하고, 이들의 확산 경로를 공동으로 최적 제어를 통해 조정하여 집합 출력에 대한 공유 목표를 정의합니다.

Result: 조건부 MNIST 생성에 대한 프레임워크를 검증하고, 학습된 협력적 제어를 단계별 기울기 안내로 대체한 단순한 추론 시간 DPS 스타일 기준선과 비교합니다.

Conclusion: 제안된 방법은 이미지 생성 및 복원에서 기존 방식보다 성능을 개선하는 가능성을 보여줍니다.

Abstract: Continuous-time generative models have achieved remarkable success in image restoration and synthesis. However, controlling the composition of multiple pre-trained models remains an open challenge. Current approaches largely treat composition as an algebraic composition of probability densities, such as via products or mixtures of experts. This perspective assumes the target distribution is known explicitly, which is almost never the case. In this work, we propose a different paradigm that formulates compositional generation as a cooperative Stochastic Optimal Control problem. Rather than combining probability densities, we treat pre-trained diffusion models as interacting agents whose diffusion trajectories are jointly steered, via optimal control, toward a shared objective defined on their aggregated output. We validate our framework on conditional MNIST generation and compare it against a naive inference-time DPS-style baseline replacing learned cooperative control with per-step gradient guidance.

</details>


### [41] [TVCACHE: A Stateful Tool-Value Cache for Post-Training LLM Agents](https://arxiv.org/abs/2602.10986)
*Abhishek Vijaya Kumar,Bhaskar Kataria,Byungsoo Oh,Emaad Manzoor,Rachee Singh*

Main category: cs.LG

TL;DR: TVCACHE는 LLM 에이전트 후 훈련에서 툴 호출의 캐시 활용을 통해 호출 시간을 줄이고, 보상 누적을 저해하지 않으면서 성능을 향상시키는 도구이다.


<details>
  <summary>Details</summary>
Motivation: RL 후 훈련 시 외부 도구 호출이 몇 초에서 몇 분까지 걸려 GPU를 유휴 상태로 만들고 후 훈련 시간과 비용을 증가시킵니다.

Method: TVCACHE는 LLM 에이전트 후 훈련을 위해 관찰된 툴 호출 시퀀스의 트리를 유지하고, 캐시 조회를 위해 가장 긴 접두어 매칭을 수행합니다.

Result: TVCACHE는 세 가지 다양한 작업에서 캐시 적중률을 최대 70%까지 달성하고, 중간 툴 호출 실행 시간을 최대 6.9배 줄였습니다.

Conclusion: 보상 누적에 저해 없이 이러한 개선을 달성했습니다.

Abstract: In RL post-training of LLM agents, calls to external tools take several seconds or even minutes, leaving allocated GPUs idle and inflating post-training time and cost. While many tool invocations repeat across parallel rollouts and could in principle be cached, naively caching their outputs for reuse is incorrect since tool outputs depend on the environment state induced by prior agent interactions. We present TVCACHE, a stateful tool-value cache for LLM agent post-training. TVCACHE maintains a tree of observed tool-call sequences and performs longest-prefix matching for cache lookups: a hit occurs only when the agent's full tool history matches a previously executed sequence, guaranteeing identical environment state. On three diverse workloads-terminal-based tasks, SQL generation, and video understanding. TVCACHE achieves cache hit rates of up to 70% and reduces median tool call execution time by up to 6.9X, with no degradation in post-training reward accumulation.

</details>


### [42] [OSIL: Learning Offline Safe Imitation Policies with Safety Inferred from Non-preferred Trajectories](https://arxiv.org/abs/2602.11018)
*Returaj Burnwal,Nirav Pravinbhai Bhatt,Balaraman Ravindran*

Main category: cs.LG

TL;DR: 이 연구는 오프라인 안전 모방 학습 문제를 다루며, 비선호 경로에서 안전성을 추론하는 새로운 알고리즘 OSIL을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제 환경에서의 온라인 학습은 위험할 수 있으며, 정확한 안전 비용을 규명하는 것이 어렵기 때문이다.

Method: OSIL 알고리즘은 비선호 시연을 통해 안전성을 추론하고, 안전 정책 학습을 제한된 마르코프 결정 과정으로 공식화한다.

Result: OSIL은 비용 제약을 만족시키는 보다 안전한 정책을 학습할 수 있으며, 여러 기준선보다 성능이 우수하다.

Conclusion: 우리의 접근 방식은 오프라인 시연만으로도 안전하고 보상을 극대화하는 행동을 학습할 수 있게 한다.

Abstract: This work addresses the problem of offline safe imitation learning (IL), where the goal is to learn safe and reward-maximizing policies from demonstrations that do not have per-timestep safety cost or reward information. In many real-world domains, online learning in the environment can be risky, and specifying accurate safety costs can be difficult. However, it is often feasible to collect trajectories that reflect undesirable or unsafe behavior, implicitly conveying what the agent should avoid. We refer to these as non-preferred trajectories. We propose a novel offline safe IL algorithm, OSIL, that infers safety from non-preferred demonstrations. We formulate safe policy learning as a Constrained Markov Decision Process (CMDP). Instead of relying on explicit safety cost and reward annotations, OSIL reformulates the CMDP problem by deriving a lower bound on reward maximizing objective and learning a cost model that estimates the likelihood of non-preferred behavior. Our approach allows agents to learn safe and reward-maximizing behavior entirely from offline demonstrations. We empirically demonstrate that our approach can learn safer policies that satisfy cost constraints without degrading the reward performance, thus outperforming several baselines.

</details>


### [43] [When Fusion Helps and When It Breaks: View-Aligned Robustness in Same-Source Financial Imaging](https://arxiv.org/abs/2602.11020)
*Rui Ma*

Main category: cs.LG

TL;DR: 본 연구는 금융 이미지 표현을 활용하여 다음 날 방향성을 예측하는 데 중점을 두고, 동일 출처의 다중 뷰 학습 및 적대적 강건성을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 금융 데이터에서 신뢰할 수 있는 예측과 강건성을 확보하기 위한 새로운 접근법이 필요하다.

Method: 상하이 금 거래소의 스팟 금 데이터(2005-2025)를 활용하여 OHLCV 가격/거래량 차트와 기술 지표 행렬로부터 두 개의 창 정렬 뷰를 구성했습니다. 누수 저항이 있는 시간 차단 분할과 매튜 상관 계수(MCC)를 사용하여 신뢰할 수 있는 평가를 보장합니다.

Result: 레이블 노이즈의 상태에 따라 결과가 크게 달라지며, 최소 이동 필터를 사용해 평가 하위 집합을 정의하여 다음 날 절대 수익률이 특정 값 이하인 샘플을 제외합니다.

Conclusion: 다층적 퓨전 접근법이 강건성을 개선하지만, 공동 공격은 여전히 어려움이 있으며 성능 저하를 초래할 수 있습니다.

Abstract: We study same-source multi-view learning and adversarial robustness for next-day direction prediction with financial image representations. On Shanghai Gold Exchange (SGE) spot gold data (2005-2025), we construct two window-aligned views from each rolling window: an OHLCV-rendered price/volume chart and a technical-indicator matrix. To ensure reliable evaluation, we adopt leakage-resistant time-block splits with embargo and use Matthews correlation coefficient (MCC). We find that results depend strongly on the label-noise regime: we apply an ex-post minimum-movement filter that discards samples with realized next-day absolute return below tau to define evaluation subsets with reduced near-zero label ambiguity. This induces a non-monotonic data-noise trade-off that can reveal predictive signal but eventually increases variance as sample size shrinks; the filter is used for offline benchmark construction rather than an inference-time decision rule. In the stabilized subsets, fusion is regime dependent: early fusion by channel stacking can exhibit negative transfer, whereas late fusion with dual encoders and a fusion head provides the dominant clean-performance gains; cross-view consistency regularization has secondary, backbone-dependent effects. We further evaluate test-time L-infinity perturbations using FGSM and PGD under two threat scenarios: view-constrained attacks that perturb one view and joint attacks that perturb both. We observe severe vulnerability at tiny budgets with strong view asymmetry. Late fusion consistently improves robustness under view-constrained attacks, but joint attacks remain challenging and can still cause substantial worst-case degradation.

</details>


### [44] [Divide, Harmonize, Then Conquer It: Shooting Multi-Commodity Flow Problems with Multimodal Language Models](https://arxiv.org/abs/2602.11057)
*Xinyu Yuan,Yan Qiao,Zonghui Wang,Wenzhi Chen*

Main category: cs.LG

TL;DR: 본 논문에서는 최적성과 처리 가능성의 균형을 위한 새로운 ML 기반 방법인 Pram을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 최적화 엔진이 최적성과 처리 가능성을 조화롭게 관리하는 데 어려움을 겪고 있는 현대의 할당 시스템 확장에 대응하기 위해.

Method: Pram은 원래 문제를 지역 하위 문제로 나누고, MLM 기반 '에이전트'로 이를 해결한 후, 다중 에이전트 강화 학습 알고리즘을 통해 전역 일관성을 확보합니다.

Result: Pram은 실제 데이터셋과 공개된 토폴로지에서 선형 프로그래밍 솔버와 유사한 성능을 달성하며, 때로는 이를 초과하고 1~2 배의 속도 향상을 보여줍니다.

Conclusion: Pram은 주요 할당 시스템과 원활하게 통합되며 미래 네트워크를 위한 실용적이고 확장 가능한 솔루션을 제공합니다.

Abstract: The multi-commodity flow (MCF) problem is a fundamental topic in network flow and combinatorial optimization, with broad applications in transportation, communication, and logistics, etc. Nowadays, the rapid expansion of allocation systems has posed challenges for existing optimization engines in balancing optimality and tractability. In this paper, we present Pram, the first ML-based method that leverages the reasoning power of multimodal language models (MLMs) for addressing the trade-off dilemma -- a great need of service providers. As part of our proposal, Pram (i) quickly computes high-quality allocations by dividing the original problem into local subproblems, which are then resolved by an MLM-powered "agent", and (ii) ensures global consistency by harmonizing these subproblems via a multi-agent reinforcement learning algorithm. Theoretically, we show that Pram, which learns to perform gradient descent in context, provably converges to the optimum within the family of MCF problems. Empirically, on real-world datasets and public topologies, Pram achieves performance comparable to, and in some cases even surpassing, linear programming solvers (very close to the optimal solution), and substantially lower runtimes (1 to 2 orders of magnitude faster). Moreover, Pram exhibits strong robustness (<10\% performance degradation under link failures or flow bursts), demonstrating MLM's generalization ability to unforeseen events. Pram is objective-agnostic and seamlessly integrates with mainstream allocation systems, providing a practical and scalable solution for future networks.

</details>


### [45] [From Natural Language to Materials Discovery:The Materials Knowledge Navigation Agent](https://arxiv.org/abs/2602.11123)
*Genmao Zhuang,Amir Barati Farimani*

Main category: cs.LG

TL;DR: MKNA는 자연어 과학 의도를 실행 가능한 행동으로 변환하여 고성능 재료 발견을 가속화하는 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 고성능 재료 발견은 에너지, 전자기기 및 항공우주 기술에서의 주요 과제이며, 전통적인 작업 흐름은 전문가의 직관과 비용이 많이 드는 시뮬레이션에 의존한다.

Method: MKNA는 자연어로 된 과학적 의도를 데이터베이스 검색, 속성 예측, 구조 생성 및 안정성 평가를 위한 실행 가능한 행동으로 변환하는 언어 구동 시스템이다.

Result: MKNA는 고-디바이 온도 세라믹을 찾는 데 적용되어 문헌에 의해 뒷받침되는 스크리닝 기준(Theta_D > 800 K)을 식별하고, 다이아몬드, SiC, SiN 및 BeO와 같은 초경직 재료를 재발견하며, 이전에 보고되지 않은 열역학적으로 안정한 Be-C 풍부 화합물을 제안한다.

Conclusion: MKNA는 안정적인 후보를 찾을 뿐만 아니라 해석 가능한 설계 휴리스틱을 재구성하여 자율적이고 언어 기반의 재료 탐색을 위한 일반화 가능한 플랫폼을 확립한다.

Abstract: Accelerating the discovery of high-performance materials remains a central challenge across energy, electronics, and aerospace technologies, where traditional workflows depend heavily on expert intuition and computationally expensive simulations. Here we introduce the Materials Knowledge Navigation Agent (MKNA), a language-driven system that translates natural-language scientific intent into executable actions for database retrieval, property prediction, structure generation, and stability evaluation. Beyond automating tool invocation, MKNA autonomously extracts quantitative thresholds and chemically meaningful design motifs from literature and database evidence, enabling data-grounded hypothesis formation. Applied to the search for high-Debye-temperature ceramics, the agent identifies a literature-supported screening criterion (Theta_D > 800 K), rediscovers canonical ultra-stiff materials such as diamond, SiC, SiN, and BeO, and proposes thermodynamically stable, previously unreported Be-C-rich compounds that populate the sparsely explored 1500-1700 K regime. These results demonstrate that MKNA not only finds stable candidates but also reconstructs interpretable design heuristics, establishing a generalizable platform for autonomous, language-guided materials exploration.

</details>


### [46] [Diffusion-Pretrained Dense and Contextual Embeddings](https://arxiv.org/abs/2602.11151)
*Sedigheh Eslami,Maksim Gaiduk,Markus Krimmel,Louis Milliken,Bo Wang,Denis Bykov*

Main category: cs.LG

TL;DR: pplx-embed는 다단계 대비 학습을 사용하는 다국어 임베딩 모델 세 가족으로 웹 규모 검색을 위한 확산 사전훈련 언어 모델 백본을 기반으로 개발되었습니다.


<details>
  <summary>Details</summary>
Motivation: 이 논문은 대규모 검색에서 효과적인 다국어 임베딩 모델을 개발하기 위해 작성되었습니다.

Method: pplx-embed는 확산 기반 사전 훈련을 통해 양방향 주의를 활용하여 문맥을 포착하고, 평균 풀링 및 후기 청크 전략을 사용하여 긴 문서의 글로벌 문맥을 보존합니다.

Result: pplx-embed-v1은 다양한 검색 벤치마크에서 경쟁력 있는 성능을 달성했으며, pplx-embed-context-v1은 ConTEB 벤치마크에서 새로운 기록을 세웠습니다.

Conclusion: 이 결과는 검색 품질과 효율성이 중요한 대규모 환경에서 모델의 효과를 검증합니다.

Abstract: In this report, we introduce pplx-embed, a family of multilingual embedding models that employ multi-stage contrastive learning on a diffusion-pretrained language model backbone for web-scale retrieval. By leveraging bidirectional attention through diffusion-based pretraining, our models capture comprehensive bidirectional context within passages, enabling the use of mean pooling and a late chunking strategy to better preserve global context across long documents. We release two model types: pplx-embed-v1 for standard retrieval, and pplx-embed-context-v1 for contextualized embeddings that incorporate global document context into passage representations. pplx-embed-v1 achieves competitive performance on the MTEB(Multilingual, v2), MTEB(Code), MIRACL, BERGEN, and ToolRet retrieval benchmarks, while pplx-embed-context-v1 sets new records on the ConTEB benchmark. Beyond public benchmarks, pplx-embed-v1 demonstrates strong performance on our internal evaluation suite, which focuses on real-world, large-scale search scenarios over tens of millions of documents. These results validate the models' effectiveness in production environments where retrieval quality and efficiency are critical at scale.

</details>
