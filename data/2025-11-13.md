<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 22]
- [cs.LG](#cs.LG) [Total: 15]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.CR](#cs.CR) [Total: 10]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Agentic Educational Content Generation for African Languages on Edge Devices](https://arxiv.org/abs/2511.07437)
*Ravi Gupta,Guneet Bhatia*

Main category: cs.AI

TL;DR: 이 연구는 아프리카 사하라 이남의 교육 불균형을 해결하기 위한 자율 에이전트 기반의 분산 교육 콘텐츠 생성 프레임워크를 제안하고, 이를 통해 고성능의 다국어 교육 콘텐츠를 생성하는 방법을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 아프리카 사하라 이남 지역에서 교육 불균형 문제를 해결하고 지속 가능한 AI 기반 교육을 제공하기 위해.

Method: 자율 에이전트가 조정하는 프레임워크를 통해 컨텍스트에 적합한 교육 콘텐츠를 생성하는 네 가지 전문 에이전트를 활용하여 Raspberry Pi 4B와 NVIDIA Jetson Nano에서 실험을 수행했다.

Result: InkubaLM는 Jetson Nano에서 129 ms의 시간 및 15.9개의 토큰을 초당 생성하며 우수한 성능을 달성하고, 전반적으로 높은 BLEU 점수, 문화적 관련성, 유창성을 제공했다.

Conclusion: 현지화되고 지속 가능한 AI 기반 교육의 실용적인 기초를 확립하기 위한 다양한 커뮤니티 조직과의 파트너십을 통해 교육 불균형 문제를 해결하고 UN SDGs에 기여할 수 있다.

Abstract: Addressing educational inequity in Sub-Saharan Africa, this research presents an autonomous agent-orchestrated framework for decentralized, culturally adaptive educational content generation on edge devices. The system leverages four specialized agents that work together to generate contextually appropriate educational content. Experimental validation on platforms including Raspberry Pi 4B and NVIDIA Jetson Nano demonstrates significant performance achievements. InkubaLM on Jetson Nano achieved a Time-To-First-Token (TTFT) of 129 ms, an average inter-token latency of 33 ms, and a throughput of 45.2 tokens per second while consuming 8.4 W. On Raspberry Pi 4B, InkubaLM also led with 326 ms TTFT and 15.9 tokens per second at 5.8 W power consumption. The framework consistently delivered high multilingual quality, averaging a BLEU score of 0.688, cultural relevance of 4.4/5, and fluency of 4.2/5 across tested African languages. Through potential partnerships with active community organizations including African Youth & Community Organization (AYCO) and Florida Africa Foundation, this research aims to establish a practical foundation for accessible, localized, and sustainable AI-driven education in resource-constrained environments. Keeping focus on long-term viability and cultural appropriateness, it contributes to United Nations SDGs 4, 9, and 10. Index Terms - Multi-Agent Systems, Edge AI Computing, Educational Technology, African Languages, Rural Education, Sustainable Development, UN SDG.

</details>


### [2] [Procedural Knowledge Improves Agentic LLM Workflows](https://arxiv.org/abs/2511.07568)
*Vincent Hsiao,Mark Roberts,Leslie Smith*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)은 도구 지원, 프롬프트 엔지니어링 또는 미세 조정 없이 에이전트 작업을 수행할 때 어려움을 겪는다. 이 연구에서는 절차적 지식을 활용한 에이전트 LLM 워크플로를 설계, 구현 및 평가하고, 이를 통해 LLM 성능을 향상시킬 수 있음을 보인다.


<details>
  <summary>Details</summary>
Motivation: LLM의 성능 향상을 위해 절차적 지식을 평가하는 연구가 필요하다.

Method: 계층적 작업 네트워크(HTN)를 활용한 에이전트 LLM 워크플로를 공식화하고 구현하였다.

Result: 수치 결과는 수작업으로 생성된 HTN이 LLM의 성능을 극적으로 향상시킬 수 있음을 보여준다.

Conclusion: 전문 지식을 활용하여 절차적 지식을 선별하는 것이 LLM 워크플로 향상에 중요한 도구가 될 것이다.

Abstract: Large language models (LLMs) often struggle when performing agentic tasks without substantial tool support, prom-pt engineering, or fine tuning. Despite research showing that domain-dependent, procedural knowledge can dramatically increase planning efficiency, little work evaluates its potential for improving LLM performance on agentic tasks that may require implicit planning. We formalize, implement, and evaluate an agentic LLM workflow that leverages procedural knowledge in the form of a hierarchical task network (HTN). Empirical results of our implementation show that hand-coded HTNs can dramatically improve LLM performance on agentic tasks, and using HTNs can boost a 20b or 70b parameter LLM to outperform a much larger 120b parameter LLM baseline. Furthermore, LLM-created HTNs improve overall performance, though less so. The results suggest that leveraging expertise--from humans, documents, or LLMs--to curate procedural knowledge will become another important tool for improving LLM workflows.

</details>


### [3] [Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces](https://arxiv.org/abs/2511.07587)
*Shreyas Rajesh,Pavan Holur,Chenda Duan,David Chong,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: 본 논문은 LLM이 긴 문맥을 처리하는 데 있어 발생하는 문제를 해결하기 위해 Generative Semantic Workspace (GSW)라는 신경 영감을 받은 생성 메모리 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM은 긴 문맥 추론에서 근본적인 도전 과제를 겪고 있으며, 기존 해결책은 사실 기반 검색에 적합하게 조정되어 있습니다.

Method: GSW는 상황 변화에 대한 구조적이고 해석 가능한 표현을 구축하고, 이를 통해 LLM이 역할, 행동 및 시공간 맥락을 추론할 수 있도록 합니다.

Result: GSW는 100k에서 1M 토큰 길이의 에피소드 메모리 벤치마크에서 기존 RAG 기반 기준보다 최대 20% 더 우수한 성능을 보였습니다.

Conclusion: GSW는 LLM에 인간과 유사한 에피소드 메모리를 부여하기 위한 구체적인 청사진을 제공하여, 장기적으로 추론할 수 있는 보다 능력 있는 에이전트를 위한 길을 열어줍니다.

Abstract: Large Language Models (LLMs) face fundamental challenges in long-context reasoning: many documents exceed their finite context windows, while performance on texts that do fit degrades with sequence length, necessitating their augmentation with external memory frameworks. Current solutions, which have evolved from retrieval using semantic embeddings to more sophisticated structured knowledge graphs representations for improved sense-making and associativity, are tailored for fact-based retrieval and fail to build the space-time-anchored narrative representations required for tracking entities through episodic events. To bridge this gap, we propose the \textbf{Generative Semantic Workspace} (GSW), a neuro-inspired generative memory framework that builds structured, interpretable representations of evolving situations, enabling LLMs to reason over evolving roles, actions, and spatiotemporal contexts. Our framework comprises an \textit{Operator}, which maps incoming observations to intermediate semantic structures, and a \textit{Reconciler}, which integrates these into a persistent workspace that enforces temporal, spatial, and logical coherence. On the Episodic Memory Benchmark (EpBench) \cite{huet_episodic_2025} comprising corpora ranging from 100k to 1M tokens in length, GSW outperforms existing RAG based baselines by up to \textbf{20\%}. Furthermore, GSW is highly efficient, reducing query-time context tokens by \textbf{51\%} compared to the next most token-efficient baseline, reducing inference time costs considerably. More broadly, GSW offers a concrete blueprint for endowing LLMs with human-like episodic memory, paving the way for more capable agents that can reason over long horizons.

</details>


### [4] [SciAgent: A Unified Multi-Agent System for Generalistic Scientific Reasoning](https://arxiv.org/abs/2511.08151)
*Xuchen Li,Ruitao Wu,Xuanbo Liu,Xukai Wang,Jinbo Hu,Zhixin Bai,Bohan Zeng,Hao Liang,Leheng Chen,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Xu-Yao Zhang,Liu Liu,Jia Li,Kaiqi Huang,Jiahao Xu,Haitao Mi,Wentao Zhang,Bin Dong*

Main category: cs.AI

TL;DR: SciAgent는 다중 에이전트 시스템으로, 다양한 과학적 사고 능력을 갖춘 AI 시스템을 개발하여 인간의 성과를 초과 달성했다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 발전에도 불구하고, 현재의 AI 시스템은 여전히 좁고 수공예적이다.

Method: SciAgent는 문제 해결을 계층적 프로세스로 구성하며, 각 문제의 도메인과 복잡성을 해석하는 조정자 에이전트가 전문화된 작업 시스템을 동적으로 조율한다.

Result: SciAgent는 수학 및 물리 올림피아드에서 인간 금메달리스트 성과를 초과 달성하였다.

Conclusion: SciAgent는 전문가 수준의 일관된 교차 학문적 추론이 가능한 과학적 지능을 향한 구체적인 단계로 자리잡았다.

Abstract: Recent advances in large language models have enabled AI systems to achieve expert-level performance on domain-specific scientific tasks, yet these systems remain narrow and handcrafted. We introduce SciAgent, a unified multi-agent system designed for generalistic scientific reasoning-the ability to adapt reasoning strategies across disciplines and difficulty levels. SciAgent organizes problem solving as a hierarchical process: a Coordinator Agent interprets each problem's domain and complexity, dynamically orchestrating specialized Worker Systems, each composed of interacting reasoning Sub-agents for symbolic deduction, conceptual modeling, numerical computation, and verification. These agents collaboratively assemble and refine reasoning pipelines tailored to each task. Across mathematics and physics Olympiads (IMO, IMC, IPhO, CPhO), SciAgent consistently attains or surpasses human gold-medalist performance, demonstrating both domain generality and reasoning adaptability. Additionally, SciAgent has been tested on the International Chemistry Olympiad (IChO) and selected problems from the Humanity's Last Exam (HLE) benchmark, further confirming the system's ability to generalize across diverse scientific domains. This work establishes SciAgent as a concrete step toward generalistic scientific intelligence-AI systems capable of coherent, cross-disciplinary reasoning at expert levels.

</details>


### [5] [AIA Forecaster: Technical Report](https://arxiv.org/abs/2511.07678)
*Rohan Alur,Bradly C. Stadie,Daniel Kang,Ryan Chen,Matt McManus,Michael Rickert,Tyler Lee,Michael Federici,Richard Zhu,Dennis Fogerty,Hayley Williamson,Nina Lozinski,Aaron Linsky,Jasjeet S. Sekhon*

Main category: cs.AI

TL;DR: AIA Forecaster는 비정형 데이터를 활용한 판단 예측을 위한 대규모 언어 모델 기반 시스템으로, 인간의 예측 능력에 비견되는 성능을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 비정형 데이터를 활용한 판단 예측에 대한 필요성을 해결하기 위해 이 연구를 수행하였습니다.

Method: AIA Forecaster는 고품질 뉴스 출처에 대한 에이전틱 탐색, 동일 이벤트에 대한 상이한 예측을 조정하는 감독 에이전트, 대형 언어 모델의 행동 편향을 보정하기 위한 통계적 보정 기법으로 구성됩니다.

Result: ForecastBench 벤치마크에서 AIA Forecaster는 인간의 슈퍼 예측자들과 동등한 성능을 달성하며, 이전의 LLM 기준을 초과합니다.

Conclusion: 우리의 연구는 AI 예측의 새로운 최첨단을 확립하고 향후 연구를 위한 실용적이고 전이 가능한 권장 사항을 제공합니다.

Abstract: This technical report describes the AIA Forecaster, a Large Language Model (LLM)-based system for judgmental forecasting using unstructured data. The AIA Forecaster approach combines three core elements: agentic search over high-quality news sources, a supervisor agent that reconciles disparate forecasts for the same event, and a set of statistical calibration techniques to counter behavioral biases in large language models. On the ForecastBench benchmark (Karger et al., 2024), the AIA Forecaster achieves performance equal to human superforecasters, surpassing prior LLM baselines. In addition to reporting on ForecastBench, we also introduce a more challenging forecasting benchmark sourced from liquid prediction markets. While the AIA Forecaster underperforms market consensus on this benchmark, an ensemble combining AIA Forecaster with market consensus outperforms consensus alone, demonstrating that our forecaster provides additive information. Our work establishes a new state of the art in AI forecasting and provides practical, transferable recommendations for future research. To the best of our knowledge, this is the first work that verifiably achieves expert-level forecasting at scale.

</details>


### [6] [ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents](https://arxiv.org/abs/2511.07685)
*Manasi Sharma,Chen Bo Calvin Zhang,Chaithanya Bandi,Clinton Wang,Ankit Aich,Huy Nghiem,Tahseen Rabbani,Ye Htet,Brian Jang,Sumana Basu,Aishwarya Balwani,Denis Peskoff,Marcos Ayestaran,Sean M. Hendryx,Brad Kenstler,Bing Liu*

Main category: cs.AI

TL;DR: Deep Research (DR)는 대규모 언어 모델을 활용하여 개방형 질문에 답변하는 것을 목표로 하며, 이 연구는 DR의 평가를 위한 표준화된 기준인 ResearchRubrics를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: Deep Research (DR)는 개방형 질문에 대해 답변하기 위해 다양한 기능의 통합이 필요한 새롭게 떠오르는 에이전트 애플리케이션입니다.

Method: ResearchRubrics는 2,800시간 이상의 인력 노동으로 구성된 표준화된 벤치마크로, 사실의 근거, 추론의 정확성 및 명료성을 평가하기 위해 2,500개 이상의 전문가가 작성한 세분화된 루브릭과 현실적인 도메인 다양성 프롬프트를 쌍으로 제공합니다.

Result: 여러 최첨단 DR 시스템을 평가한 결과, Gemini의 DR 및 OpenAI의 DR과 같은 선도적인 에이전트도 루브릭 준수에서 평균 68% 미만을 달성했으며, 이는 주로 암시적 맥락의 누락과 검색된 정보에 대한 불충분한 추론 때문입니다.

Conclusion: 체계적이고 확장 가능한 심층 연구 능력 평가의 필요성을 강조하며, ResearchRubrics(모든 프롬프트, 루브릭 및 평가 코드를 포함)를 공개하여 잘 정당화된 연구 보조 도구로의 발전을 촉진합니다.

Abstract: Deep Research (DR) is an emerging agent application that leverages large language models (LLMs) to address open-ended queries. It requires the integration of several capabilities, including multi-step reasoning, cross-document synthesis, and the generation of evidence-backed, long-form answers. Evaluating DR remains challenging because responses are lengthy and diverse, admit many valid solutions, and often depend on dynamic information sources. We introduce ResearchRubrics, a standardized benchmark for DR built with over 2,800+ hours of human labor that pairs realistic, domain-diverse prompts with 2,500+ expert-written, fine-grained rubrics to assess factual grounding, reasoning soundness, and clarity. We also propose a new complexity framework for categorizing DR tasks along three axes: conceptual breadth, logical nesting, and exploration. In addition, we develop human and model-based evaluation protocols that measure rubric adherence for DR agents. We evaluate several state-of-the-art DR systems and find that even leading agents like Gemini's DR and OpenAI's DR achieve under 68% average compliance with our rubrics, primarily due to missed implicit context and inadequate reasoning about retrieved information. Our results highlight the need for robust, scalable assessment of deep research capabilities, to which end we release ResearchRubrics(including all prompts, rubrics, and evaluation code) to facilitate progress toward well-justified research assistants.

</details>


### [7] [Towards AI-Assisted Generation of Military Training Scenarios](https://arxiv.org/abs/2511.07690)
*Soham Hans,Volkan Ustun,Benjamin Nye,James Sterrett,Matthew Green*

Main category: cs.AI

TL;DR: 본 논문은 다중 에이전트, 다중 모달 추론 프레임워크를 소개하며, 이를 통해 군사 훈련 시나리오 생성을 자동화하여 전문적인 성과를 달성할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 시뮬레이션 기반 훈련에서 전문가 수준의 성과를 달성하기 위해서는 복잡하고 적응 가능한 시나리오의 생성이 필요하지만, 기존 AI 도구는 이러한 요구를 충족하지 못했다.

Method: 우리는 시나리오 생성을 하위 문제들의 계층으로 분해하고, 각각의 하위 문제에 대해 AI 도구의 역할을 정의하는 다중 에이전트 프레임워크를 제시한다.

Result: 프레임워크는 LLM 기반의 특화된 에이전트를 사용하여 각 하위 문제를 처리하며, OPORD의 기동 계획 및 이동 섹션을 생성하는 개념 증명을 통해 검증되었다.

Conclusion: 결과는 LLM 기반 다중 에이전트 시스템이 군사 훈련을 위한 시나리오 생성의 자동화를 이끌어낼 잠재력을 보여준다.

Abstract: Achieving expert-level performance in simulation-based training relies on the creation of complex, adaptable scenarios, a traditionally laborious and resource intensive process. Although prior research explored scenario generation for military training, pre-LLM AI tools struggled to generate sufficiently complex or adaptable scenarios. This paper introduces a multi-agent, multi-modal reasoning framework that leverages Large Language Models (LLMs) to generate critical training artifacts, such as Operations Orders (OPORDs). We structure our framework by decomposing scenario generation into a hierarchy of subproblems, and for each one, defining the role of the AI tool: (1) generating options for a human author to select from, (2) producing a candidate product for human approval or modification, or (3) generating textual artifacts fully automatically. Our framework employs specialized LLM-based agents to address distinct subproblems. Each agent receives input from preceding subproblem agents, integrating both text-based scenario details and visual information (e.g., map features, unit positions and applies specialized reasoning to produce appropriate outputs. Subsequent agents process these outputs sequentially, preserving logical consistency and ensuring accurate document generation. This multi-agent strategy overcomes the limitations of basic prompting or single-agent approaches when tackling such highly complex tasks. We validate our framework through a proof-of-concept that generates the scheme of maneuver and movement section of an OPORD while estimating map positions and movements as a precursor demonstrating its feasibility and accuracy. Our results demonstrate the potential of LLM-driven multi-agent systems to generate coherent, nuanced documents and adapt dynamically to changing conditions, advancing automation in scenario generation for military training.

</details>


### [8] [Operational machine learning for remote spectroscopic detection of CH$_{4}$ point sources](https://arxiv.org/abs/2511.07719)
*Vít Růžička,Gonzalo Mateo-García,Itziar Irakulis-Loitxate,Juan Emmanuel Johnson,Manuel Montesino San Martín,Anna Allen,Luis Guanter,David R. Thompson*

Main category: cs.AI

TL;DR: 인간 활동에 의한 메탄 출처를 완화하는 것은 지구 온난화를 늦추는 가장 비용 효율적인 방법 중 하나이다. 본 논문은 메탄 경고 및 대응 시스템(MARS)에 적용된 머신 러닝 시스템의 운영 배포에 대해 설명하고, 다양한 딥 러닝 모델 구성을 비교하며, 모델 앙상블을 통해 거짓 탐지를 74% 이상 줄였다는 내용을 담고 있다.


<details>
  <summary>Details</summary>
Motivation: 지구 온난화를 늦추기 위한 비용 효율적인 방법으로 인간 활동에 의한 메탄 출처를 완화하는 것을 목표로 한다.

Method: 유엔 환경 프로그램의 국제 메탄 배출 관측소의 MARS 내에서 메탄 배출을 감지하는 머신 러닝 시스템을 운영 배포했다. 세 가지 이미징 분광기 미션에서 주석이 달린 메탄 플룸의 가장 크고 다양한 글로벌 데이터 세트를 만들고, 다양한 딥 러닝 모델 구성을 정량적으로 비교했다.

Result: 운영 배포 기간 동안 1,351개의 독립적인 메탄 누출을 확인하고, 479개의 이해관계자 알림을 생성하는 데 기여하였다.

Conclusion: 글로벌 AI 지원 메탄 누출 탐지 시스템을 통한 입증된 모델 유틸리티는 리비아, 아르헨티나, 오만 및 아제르바이잔의 사례 연구를 통해 감축 성공을 확인하였다.

Abstract: Mitigating anthropogenic methane sources is one the most cost-effective levers to slow down global warming. While satellite-based imaging spectrometers, such as EMIT, PRISMA, and EnMAP, can detect these point sources, current methane retrieval methods based on matched filters still produce a high number of false detections requiring laborious manual verification. This paper describes the operational deployment of a machine learning system for detecting methane emissions within the Methane Alert and Response System (MARS) of the United Nations Environment Programme's International Methane Emissions Observatory. We created the largest and most diverse global dataset of annotated methane plumes from three imaging spectrometer missions and quantitatively compared different deep learning model configurations. Focusing on the requirements for operational deployment, we extended prior evaluation methodologies from small tiled datasets to full granule evaluation. This revealed that deep learning models still produce a large number of false detections, a problem we address with model ensembling, which reduced false detections by over 74%. Deployed in the MARS pipeline, our system processes scenes and proposes plumes to analysts, accelerating the detection and analysis process. During seven months of operational deployment, it facilitated the verification of 1,351 distinct methane leaks, resulting in 479 stakeholder notifications. We further demonstrate the model's utility in verifying mitigation success through case studies in Libya, Argentina, Oman, and Azerbaijan. Our work represents a critical step towards a global AI-assisted methane leak detection system, which is required to process the dramatically higher data volumes expected from new and current imaging spectrometers.

</details>


### [9] [Alignment-Aware Quantization for LLM Safety](https://arxiv.org/abs/2511.07842)
*Sunghyun Wee,Suyoung Kim,Hyeonjin Kim,Kyomin Hwang,Nojun Kwak*

Main category: cs.AI

TL;DR: 본 논문에서는 대형 언어 모델의 안전성과 효율성을 동시 달성하기 위한 새로운 방법인 Alignment-Aware Quantization(AAQ)을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 배치할 때, 안전성과 효율성은 중요한 요소입니다. 현재의 포스트 트레이닝 양자화(PTQ) 방식은 효율성을 위해 설계되었지만, 모델의 안전성을 저해할 수 있는 기본적인 결함이 존재합니다.

Method: AAQ는 Alignment-Preserving Contrastive(APC) 손실을 PTQ 파이프라인에 통합하여 양자화된 모델이 안전하고 지침으로 조정된 모델을 모방하도록 유도합니다.

Result: 우리의 방법은 이전의 방법들에 비해 안전성을 보장하면서도 다양한 모델 패밀리에서 강력한 4비트 양자화를 가능하게 합니다.

Conclusion: 우리의 연구는 효율성과 안전성 간의 중요한 균형을 해결하여, 신뢰할 수 있는 대형 언어 모델 개발의 길을 열었습니다.

Abstract: Safety and efficiency are both important factors when deploying large language models(LLMs). LLMs are trained to follow human alignment for safety, and post training quantization(PTQ) is applied afterward for efficiency. However, these two objectives are often in conflict, revealing a fundamental flaw in the conventional PTQ paradigm: quantization can turn into a safety vulnerability if it only aims to achieve low perplexity. Models can demonstrate low perplexity yet exhibit significant degradation in alignment with the safety policy, highlighting that perplexity alone is an insufficient and often misleading proxy for model safety. To address this, we propose Alignment-Aware Quantization(AAQ), a novel approach that integrates Alignment-Preserving Contrastive(APC) loss into the PTQ pipeline. Compared to simple reconstruction loss, ours explicitly preserves alignment by encouraging the quantized model to mimic its safe, instruction-tuned model while diverging from the unaligned, pre-trained counterpart. Our method achieves this robust safety alignment without resorting to specialized safety-focused calibration datasets, highlighting its practical utility and broad applicability. AAQ is compatible with standard PTQ techniques and enables robust 4-bit (W4A4) quantization across diverse model families such as LLaMA, Qwen, and Mistral while maintaining safety where previous methods fail. Our work resolves the critical trade-off between efficiency and safety, paving the way toward LLMs that are both efficient and trustworthy. Anonymized code is available in the supplementary material.

</details>


### [10] [DANS-KGC: Diffusion Based Adaptive Negative Sampling for Knowledge Graph Completion](https://arxiv.org/abs/2511.07901)
*Haoning Li,Qinghua Huang*

Main category: cs.AI

TL;DR: DANS-KGC는 지식 그래프 완성을 위한 새로운 부정 샘플링 전략을 제안하며, 학습의 어려움을 평가하고, 적응형 부정 샘플링, 동적 훈련 메커니즘을 통해 효과성을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 기존 부정 샘플링 전략의 한계를 극복하기 위해 새로운 접근법이 필요하다.

Method: DANS-KGC는 어려움 평가 모듈(DAM), 적응형 부정 샘플링 모듈(ANS), 동적 훈련 메커니즘(DTM)의 세 가지 주요 구성 요소로 이루어져 있다.

Result: 여섯 개의 벤치마크 데이터셋에서 DANS-KGC의 효과성과 일반화 능력을 입증하였다.

Conclusion: DANS-KGC는 UMLS 및 YAGO3-10 데이터셋의 세 가지 평가 지표에서 최고 성능을 달성하였다.

Abstract: Negative sampling (NS) strategies play a crucial role in knowledge graph representation. In order to overcome the limitations of existing negative sampling strategies, such as vulnerability to false negatives, limited generalization, and lack of control over sample hardness, we propose DANS-KGC (Diffusion-based Adaptive Negative Sampling for Knowledge Graph Completion). DANS-KGC comprises three key components: the Difficulty Assessment Module (DAM), the Adaptive Negative Sampling Module (ANS), and the Dynamic Training Mechanism (DTM). DAM evaluates the learning difficulty of entities by integrating semantic and structural features. Based on this assessment, ANS employs a conditional diffusion model with difficulty-aware noise scheduling, leveraging semantic and neighborhood information during the denoising phase to generate negative samples of diverse hardness. DTM further enhances learning by dynamically adjusting the hardness distribution of negative samples throughout training, enabling a curriculum-style progression from easy to hard examples. Extensive experiments on six benchmark datasets demonstrate the effectiveness and generalization ability of DANS-KGC, with the method achieving state-of-the-art results on all three evaluation metrics for the UMLS and YAGO3-10 datasets.

</details>


### [11] [Lightweight Diffusion-based Framework for Online Imagined Speech Decoding in Aphasia](https://arxiv.org/abs/2511.07920)
*Eunyeong Ko,Soowon Kim,Ha-Na Jo*

Main category: cs.AI

TL;DR: 본 연구는 실시간 상상 언어 분류를 위한 확산 기반 신경 디코딩 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제로 임상 상황에서 사용할 수 있는 상상 언어 분류 시스템을 개발하고자 하였다.

Method: 한국어 패러다임에서 수집된 개인별 EEG 데이터를 기반으로 경량 조건부 확산 인코더와 컨볼루션 분류기를 통합하여 학습하였다.

Result: 20회 실시간 시험에서 65%의 top-1 및 70%의 top-2 정확도를 달성하였으며, 오프라인 평가(50% top-1)를 초과하였다.

Conclusion: 제안된 프레임워크는 임상 통신 지원을 위한 상상 언어-컴퓨터 인터페이스의 실용성을 증가시킨다.

Abstract: A diffusion-based neural decoding framework optimized for real-time imagined speech classification in individuals with aphasia. The system integrates a lightweight conditional diffusion encoder and convolutional classifier trained using subject-specific EEG data acquired from a Korean-language paradigm. A dual-criterion early stopping strategy enabled rapid convergence under limited calibration data, while dropout regularization and grouped temporal convolutions ensured stable generalization. During online operation, continuous EEG streams were processed in two-second sliding windows to generate class probabilities that dynamically modulated visual and auditory feedback according to decoding confidence. Across twenty real-time trials, the framework achieved 65% top-1 and 70% top-2 accuracy, outperforming offline evaluation (50% top-1). These results demonstrate the feasibility of deploying diffusion-based EEG decoding under practical clinical constraints, maintaining reliable performance despite environmental variability and minimal preprocessing. The proposed framework advances the translation of imagined speech brain-computer interfaces toward clinical communication support for individuals with severe expressive language impairment.

</details>


### [12] [Toward Practical BCI: A Real-time Wireless Imagined Speech EEG Decoding System](https://arxiv.org/abs/2511.07936)
*Ji-Ha Park,Heon-Gyu Kwak,Gi-Hwan Shin,Yoo-In Jeon,Sun-Min Park,Ji-Yeon Hwang,Seong-Whan Lee*

Main category: cs.AI

TL;DR: 정신 언어를 기반으로 한 신경 인터페이스의 실용적인 구현을 위한 실시간 무선 EEG 디코딩 시스템을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 실제 세계에서의 BCI 응용 가능성을 높이기 위해 실시간으로 사용할 수 있는 시스템 필요.

Method: 무선 EEG 신호를 통해 사용자 맞춤형 서비스 제공하는 디코딩 시스템 설계.

Result: 4-class 정확도는 유선 장치에서 62.00%와 휴대용 무선 헤드셋에서 46.67% 달성.

Conclusion: 접근 가능한 BCI 기술로의 주요 진전을 보여주며 향후 연구 방향을 제시한다.

Abstract: Brain-computer interface (BCI) research, while promising, has largely been confined to static and fixed environments, limiting real-world applicability. To move towards practical BCI, we introduce a real-time wireless imagined speech electroencephalogram (EEG) decoding system designed for flexibility and everyday use. Our framework focuses on practicality, demonstrating extensibility beyond wired EEG devices to portable, wireless hardware. A user identification module recognizes the operator and provides a personalized, user-specific service. To achieve seamless, real-time operation, we utilize the lab streaming layer to manage the continuous streaming of live EEG signals to the personalized decoder. This end-to-end pipeline enables a functional real-time application capable of classifying user commands from imagined speech EEG signals, achieving an overall 4-class accuracy of 62.00 % on a wired device and 46.67 % on a portable wireless headset. This paper demonstrates a significant step towards truly practical and accessible BCI technology, establishing a clear direction for future research in robust, practical, and personalized neural interfaces.

</details>


### [13] [Combining LLM Semantic Reasoning with GNN Structural Modeling for Multi-view Multi-Label Feature Selection](https://arxiv.org/abs/2511.08008)
*Zhiqi Chen,Yuzhou Liu,Jiarui Liu,Wanfu Gao*

Main category: cs.AI

TL;DR: 본 연구는 다중 뷰 다중 레이블 기능 선택을 위한 새로운 방법을 제안하며, 대형 언어 모델과 그래프 신경망을 결합하여 정보의 통계적 및 의미적 관계를 동시에 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 고차원 다중모드 데이터에서 유용한 특징을 추출하는 것은 기계 학습에서 중요합니다.

Method: 대형 언어 모델을 사용하여 의미적 관련성을 평가하고, 두 수준으로 구성된 의미-aware 이질 그래프를 설계하며, 경량화된 그래프 주의 네트워크를 적용하여 특징의 중요도를 점수화합니다.

Result: 다수의 벤치마크 데이터셋에서 기존 방법보다 우수한 성능을 나타내며, 소규모 데이터셋에서도 효과적입니다.

Conclusion: 제안된 방법은 강력하고 유연하며 일반화 능력을 발휘합니다.

Abstract: Multi-view multi-label feature selection aims to identify informative features from heterogeneous views, where each sample is associated with multiple interdependent labels. This problem is particularly important in machine learning involving high-dimensional, multimodal data such as social media, bioinformatics or recommendation systems. Existing Multi-View Multi-Label Feature Selection (MVMLFS) methods mainly focus on analyzing statistical information of data, but seldom consider semantic information. In this paper, we aim to use these two types of information jointly and propose a method that combines Large Language Models (LLMs) semantic reasoning with Graph Neural Networks (GNNs) structural modeling for MVMLFS. Specifically, the method consists of three main components. (1) LLM is first used as an evaluation agent to assess the latent semantic relevance among feature, view, and label descriptions. (2) A semantic-aware heterogeneous graph with two levels is designed to represent relations among features, views and labels: one is a semantic graph representing semantic relations, and the other is a statistical graph. (3) A lightweight Graph Attention Network (GAT) is applied to learn node embedding in the heterogeneous graph as feature saliency scores for ranking and selection. Experimental results on multiple benchmark datasets demonstrate the superiority of our method over state-of-the-art baselines, and it is still effective when applied to small-scale datasets, showcasing its robustness, flexibility, and generalization ability.

</details>


### [14] [Towards a Standard, Enterprise-Relevant Agentic AI Benchmark: Lessons from 5.5 billion tokens' worth of agentic AI evaluations](https://arxiv.org/abs/2511.08042)
*JV Roig*

Main category: cs.AI

TL;DR: 기업의 에이전트 AI 시스템 채택을 위한 신뢰할 수 있는 평가 방법이 필요하다. 전통적인 벤치마크는 오염에 취약하며, 에이전트 능력을 측정하지 못한다. Kamiwaza 에이전트 머릿 인덱스(KAMI) v0.1을 제시하며, 170,000개의 시험 항목을 통해 전통적 벤치마크가 실제 성능을 잘 예측하지 못함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기업에서 에이전트 AI 시스템을 도입하는 데 필요한 신뢰할 수 있는 평가 방법이 요구된다.

Method: Kamiwaza 에이전트 머릿 인덱스(KAMI) v0.1을 사용하고, 170,000개의 LLM 시험 항목을 처리하며 35개 모델 구성에서 5.5억 개의 토큰을 분석하였다.

Result: 전통적인 벤치마크 순위가 실질적인 에이전트 성능을 예측하는 데 부적합하다는 것을 입증하였다.

Conclusion: 새로운 세대의 모델이 항상 이전 모델보다 뛰어나지 않으며, 기업의 배치 결정을 내리는 데 중요한 통찰을 제공한다.

Abstract: Enterprise adoption of agentic AI systems requires reliable evaluation methods that reflect real-world deployment scenarios. Traditional LLM benchmarks suffer from training data contamination and fail to measure agentic capabilities such as multi-step tool use and decision-making under uncertainty. We present the Kamiwaza Agentic Merit Index (KAMI) v0.1, an enterprise-focused benchmark that addresses both contamination resistance and agentic evaluation. Through 170,000 LLM test items processing over 5.5 billion tokens across 35 model configurations, we demonstrate that traditional benchmark rankings poorly predict practical agentic performance. Notably, newer generation models like Llama 4 or Qwen 3 do not always outperform their older generation variants on enterprise-relevant tasks, contradicting traditional benchmark trends. We also present insights on cost-performance tradeoffs, model-specific behavioral patterns, and the impact of reasoning capabilities on token efficiency -- findings critical for enterprises making deployment decisions.

</details>


### [15] [National Institute on Aging PREPARE Challenge: Early Detection of Cognitive Impairment Using Speech - The SpeechCARE Solution](https://arxiv.org/abs/2511.08132)
*Maryam Zolnoori,Hossein Azadmaleki,Yasaman Haghbin,Ali Zolnour,Mohammad Javad Momeni Nezhad,Sina Rashidi,Mehdi Naserian,Elyas Esmaeili,Sepehr Karimi Arpanahi*

Main category: cs.AI

TL;DR: 이 연구는 인지 장애와 관련된 조기 발견을 위해 SpeechCARE라는 다중 모달 음성 처리 파이프라인을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병 및 관련 치매는 60세 이상의 성인 중 5명 중 1명에 영향을 미치지만, 인지 저하가 있는 개인의 절반 이상이 진단되지 않고 있습니다. 음성 기반 평가가 조기 발견에 유망하다는 필요성이 있습니다.

Method: SpeechCARE는 미리 학습된 다국어 신 acoustic 및 언어 트랜스포머 모델을 활용하여 인지 장애와 관련된 미세한 음성 관련 신호를 포착하는 다중 모달 음성 처리 파이프라인입니다. 다이나믹 퓨전 아키텍처를 사용하여 트랜스포머 기반의 음향, 언어 및 인구 통계 데이터를 통합합니다.

Result: SpeechCARE는 인지적으로 건강한 개인, 경도 인지 장애(MCI), 알츠하이머병(AD) 환자를 분류하는 데 AUC = 0.88 및 F1 = 0.72를 달성하였으며, MCI 감지의 경우 AUC = 0.90 및 F1 = 0.62를 기록하였습니다.

Conclusion: 미래의 작업으로는 실제 의료 환경에서의 배치와 뉴욕시의 저대표집 인구에 대한 EHR 통합 설명 가능성을 포함합니다.

Abstract: Alzheimer's disease and related dementias (ADRD) affect one in five adults over 60, yet more than half of individuals with cognitive decline remain undiagnosed. Speech-based assessments show promise for early detection, as phonetic motor planning deficits alter acoustic features (e.g., pitch, tone), while memory and language impairments lead to syntactic and semantic errors. However, conventional speech-processing pipelines with hand-crafted features or general-purpose audio classifiers often exhibit limited performance and generalizability. To address these limitations, we introduce SpeechCARE, a multimodal speech processing pipeline that leverages pretrained, multilingual acoustic and linguistic transformer models to capture subtle speech-related cues associated with cognitive impairment. Inspired by the Mixture of Experts (MoE) paradigm, SpeechCARE employs a dynamic fusion architecture that weights transformer-based acoustic, linguistic, and demographic inputs, allowing integration of additional modalities (e.g., social factors, imaging) and enhancing robustness across diverse tasks. Its robust preprocessing includes automatic transcription, large language model (LLM)-based anomaly detection, and task identification. A SHAP-based explainability module and LLM reasoning highlight each modality's contribution to decision-making. SpeechCARE achieved AUC = 0.88 and F1 = 0.72 for classifying cognitively healthy, MCI, and AD individuals, with AUC = 0.90 and F1 = 0.62 for MCI detection. Bias analysis showed minimal disparities, except for adults over 80. Mitigation techniques included oversampling and weighted loss. Future work includes deployment in real-world care settings (e.g., VNS Health, Columbia ADRC) and EHR-integrated explainability for underrepresented populations in New York City.

</details>


### [16] [An Efficient Training Pipeline for Reasoning Graphical User Interface Agents](https://arxiv.org/abs/2511.08172)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.AI

TL;DR: 이 논문은 효율적인 훈련 파이프라인을 소개하며, 모델 기반 데이터 필터링과 파라미터 효율적인 미세 조정을 결합하여 시각적 기초 작업을 수행한다.


<details>
  <summary>Details</summary>
Motivation: 시각적 기초 작업은 자연어 쿼리로부터 이미지 영역을 로컬라이즈하는 작업으로, 추론 능력을 갖춘 GUI 에이전트에 매우 중요하다.

Method: 4.8M의 합성 예제에서 12K의 깨끗하고 다양한 인스턴스를 큐레이션하기 위해 도전적인 사례를 식별하고 잘못 정렬된 인스턴스를 제거한 후 다양한 세트의 다중 모달 인스턴스를 선택한다. 이후, 3B 파라미터의 비전-언어 모델을 감독된 미세 조정, 사고 연쇄 증강 미세 조정 및 그룹 상대 정책 최적화를 통한 강화 학습을 포함한 세 가지 방식으로 훈련한다.

Result: 필터링된 데이터와 경량화된 훈련 전략을 사용하여 훈련된 모델은 ScreenSpot, Multimodal-Mind2Web 및 AndroidControl과 같은 벤치마크에서 더 큰 기준선을 맞추거나 초과한다.

Conclusion: 원칙 있는 데이터 큐레이션과 강력한 적응이 대규모 훈련에 필적할 수 있음을 보여줌으로써, 컴팩트하면서도 유능한 다중 모달 추론 에이전트를 가능하게 한다.

Abstract: Visual grounding is the task of localising image regions from natural language queries and is critical for reasoning capable Graphical User Interface agents. Many existing methods rely on massive, noisy synthetic datasets.This work introduces an efficient training pipeline that combines model-based data filtering with parameter-efficient fine-tuning. From 4.8M synthetic examples, 12K clean and diverse instances are curated by first identifying challenging cases, removing misaligned and then selecting a diverse set of multimodal instances. On this data, a 3B-parameter Vision-Language Model is trained under three regimes: supervised fine-tuning, chain-of-thought- augmented fine-tuning, and reinforcement learning via Group Relative Policy Optimization. Models trained with the filtered data and lightweight training strategies match or surpass larger baselines on benchmarks such as ScreenSpot, Multimodal-Mind2Web, and AndroidControl. These results demonstrate that principled data curation and robust adaptation can rival large-scale training, enabling compact yet capable multimodal reasoning agents.

</details>


### [17] [MADD: Multi-Agent Drug Discovery Orchestra](https://arxiv.org/abs/2511.08217)
*Gleb V. Solovev,Alina B. Zhidkovskaya,Anastasia Orlova,Nina Gubina,Anastasia Vepreva,Rodion Golovinskii,Ilya Tonkii,Ivan Dubrovsky,Ivan Gurev,Dmitry Gilemkhanov,Denis Chistiakov,Timur A. Aliev,Ivan Poddiakov,Galina Zubkova,Ekaterina V. Skorb,Vladimir Vinogradov,Alexander Boukhanovsky,Nikolay Nikitin,Andrei Dmitrenko,Anna Kalyuzhnaya,Andrey Savchenko*

Main category: cs.AI

TL;DR: MADD라는 다중 에이전트 시스템을 통해 자연어 쿼리로 맞춤형 히트 식별 파이프라인을 구축하고 실행하며, 기존 LLM 기반 솔루션보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 신약 발견 초기 단계에서 히트 식별은 핵심 도전 과제이며, 전통적으로 많은 실험 자원이 요구된다.

Method: MADD는 자연어 쿼리에서 맞춤형 히트 식별 파이프라인을 구축하고 실행하는 다중 에이전트 시스템이다.

Result: MADD는 7개의 신약 발견 사례를 통해 기존 LLM 기반 솔루션보다 우수한 성능을 보여준다.

Conclusion: 우리는 AI 중심의 신약 설계의 적용을 5개의 생물학적 목표에 적용하고, 식별된 히트 분자를 출시하며, 300만 개 이상의 화합물에 대한 쿼리-분자 쌍 및 도킹 점수의 새로운 벤치마크를 제시한다.

Abstract: Hit identification is a central challenge in early drug discovery, traditionally requiring substantial experimental resources. Recent advances in artificial intelligence, particularly large language models (LLMs), have enabled virtual screening methods that reduce costs and improve efficiency. However, the growing complexity of these tools has limited their accessibility to wet-lab researchers. Multi-agent systems offer a promising solution by combining the interpretability of LLMs with the precision of specialized models and tools. In this work, we present MADD, a multi-agent system that builds and executes customized hit identification pipelines from natural language queries. MADD employs four coordinated agents to handle key subtasks in de novo compound generation and screening. We evaluate MADD across seven drug discovery cases and demonstrate its superior performance compared to existing LLM-based solutions. Using MADD, we pioneer the application of AI-first drug design to five biological targets and release the identified hit molecules. Finally, we introduce a new benchmark of query-molecule pairs and docking scores for over three million compounds to contribute to the agentic future of drug design.

</details>


### [18] [Towards Outcome-Oriented, Task-Agnostic Evaluation of AI Agents](https://arxiv.org/abs/2511.08242)
*Waseem AlShikh,Muayad Sayed Ali,Brian Kennedy,Dmytro Mozolevskyi*

Main category: cs.AI

TL;DR: AI 에이전트의 성능을 평가하기 위한 새로운 프레임워크 제안


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 성능을 측정하는 기존의 인프라 지표가 불충분하다는 문제의식에서 출발하여, 더 나은 평가 기준을 제시하고자 함.

Method: 11개의 결과 기반의 작업 비구조적 성능 지표를 제안하여, 다양한 도메인에 걸쳐 AI 에이전트의 성능을 평가함.

Result: 하이브리드 에이전트가 제안된 성능 지표에서 가장 높은 성능을 보이며, 평균 목표 달성률이 88.8%에 달하는 결과를 도출함.

Conclusion: 제안된 프레임워크는 AI 에이전트의 포괄적인 평가를 위한 표준화된 방법론을 제공하여, 더 효과적인 개발과 배포를 위한 기반을 마련함.

Abstract: As AI agents proliferate across industries and applications, evaluating their performance based solely on infrastructural metrics such as latency, time-to-first-token, or token throughput is proving insufficient. These metrics fail to capture the quality of an agent's decisions, its operational autonomy, or its ultimate business value. This white paper proposes a novel, comprehensive framework of eleven outcome-based, task-agnostic performance metrics for AI agents that transcend domain boundaries. These metrics are designed to enable organizations to evaluate agents based on the quality of their decisions, their degree of autonomy, their adaptability to new challenges, and the tangible business value they deliver, regardless of the underlying model architecture or specific use case. We introduce metrics such as Goal Completion Rate (GCR), Autonomy Index (AIx), Multi-Step Task Resilience (MTR), and Business Impact Efficiency (BIE). Through a large-scale simulated experiment involving four distinct agent architectures (ReAct, Chain-of-Thought, Tool-Augmented, Hybrid) across five diverse domains (Healthcare, Finance, Marketing, Legal, and Customer Service), we demonstrate the framework's efficacy. Our results reveal significant performance trade-offs between different agent designs, highlighting the Hybrid Agent as the most consistently high-performing model across the majority of our proposed metrics, achieving an average Goal Completion Rate of 88.8\% and the highest Return on Investment (ROI). This work provides a robust, standardized methodology for the holistic evaluation of AI agents, paving the way for more effective development, deployment, and governance.

</details>


### [19] [Multi-Agent GraphRAG: A Text-to-Cypher Framework for Labeled Property Graphs](https://arxiv.org/abs/2511.08274)
*Anton Gusarov,Anastasia Volkova,Valentin Khrulkov,Andrey Kuznetsov,Evgenii Maslov,Ivan Oseledets*

Main category: cs.AI

TL;DR: Multi-Agent GraphRAG은 LPG 기반 그래프 데이터를 위한 자연어 인터페이스를 제공하는 텍스트-사이퍼 쿼리 생성 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 기존 GraphRAG 노력들이 RDF 지식 그래프에 집중되고 있으므로, LPG 데이터베이스의 가능성을 탐색할 필요가 있다.

Method: 모듈형 LLM 에이전트 시스템을 제안하며, Memgraph를 백엔드 그래프 데이터베이스로 활용하여 자동화된 Cypher 쿼리 생성을 수행한다.

Result: CypherBench 그래프 데이터셋 및 IFC 데이터를 기반으로 한 사례에서 시스템의 성능을 평가하였다.

Conclusion: 이 접근 방식이 AI와 실제 응용 프로그램을 대규모로 연결할 수 있음을 강조한다.

Abstract: While Retrieval-Augmented Generation (RAG) methods commonly draw information from unstructured documents, the emerging paradigm of GraphRAG aims to leverage structured data such as knowledge graphs. Most existing GraphRAG efforts focus on Resource Description Framework (RDF) knowledge graphs, relying on triple representations and SPARQL queries. However, the potential of Cypher and Labeled Property Graph (LPG) databases to serve as scalable and effective reasoning engines within GraphRAG pipelines remains underexplored in current research literature. To fill this gap, we propose Multi-Agent GraphRAG, a modular LLM agentic system for text-to-Cypher query generation serving as a natural language interface to LPG-based graph data. Our proof-of-concept system features an LLM-based workflow for automated Cypher queries generation and execution, using Memgraph as the graph database backend. Iterative content-aware correction and normalization, reinforced by an aggregated feedback loop, ensures both semantic and syntactic refinement of generated queries. We evaluate our system on the CypherBench graph dataset covering several general domains with diverse types of queries. In addition, we demonstrate performance of the proposed workflow on a property graph derived from the IFC (Industry Foundation Classes) data, representing a digital twin of a building. This highlights how such an approach can bridge AI with real-world applications at scale, enabling industrial digital automation use cases.

</details>


### [20] [SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models](https://arxiv.org/abs/2511.08379)
*Giorgio Piras,Raffaele Mura,Fabio Brau,Luca Oneto,Fabio Roli,Battista Biggio*

Main category: cs.AI

TL;DR: 이 논문은 안전하게 행동하도록 정렬된 언어 모델이 유해한 프롬프트를 거부하는 행동을 추출하기 위한 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기계적 해석 가능성에 대한 과학적 관심이 높아짐에 따라, 우리는 언어 모델의 거부 행동을 더 잘 이해하고자 한다.

Method: Self-Organizing Maps(SOMs)를 활용하여 여러 개의 거부 방향을 추출하는 방법을 제안한다.

Result: SOMs를 통해 여러 신경세포를 식별하고, 유해하지 않은 표현의 중심을 각 신경세포에서 빼낸 결과를 통해 거부 개념을 표현하는 여러 방향을 도출하였다.

Conclusion: 이 접근 방식의 기계적 함의를 분석하며 논문을 마무리한다.

Abstract: Refusal refers to the functional behavior enabling safety-aligned language models to reject harmful or unethical prompts. Following the growing scientific interest in mechanistic interpretability, recent work encoded refusal behavior as a single direction in the model's latent space; e.g., computed as the difference between the centroids of harmful and harmless prompt representations. However, emerging evidence suggests that concepts in LLMs often appear to be encoded as a low-dimensional manifold embedded in the high-dimensional latent space. Motivated by these findings, we propose a novel method leveraging Self-Organizing Maps (SOMs) to extract multiple refusal directions. To this end, we first prove that SOMs generalize the prior work's difference-in-means technique. We then train SOMs on harmful prompt representations to identify multiple neurons. By subtracting the centroid of harmless representations from each neuron, we derive a set of multiple directions expressing the refusal concept. We validate our method on an extensive experimental setup, demonstrating that ablating multiple directions from models' internals outperforms not only the single-direction baseline but also specialized jailbreak algorithms, leading to an effective suppression of refusal. Finally, we conclude by analyzing the mechanistic implications of our approach.

</details>


### [21] [Smarter Together: Creating Agentic Communities of Practice through Shared Experiential Learning](https://arxiv.org/abs/2511.08301)
*Valentin Tablan,Scott Taylor,Gabriel Hurtado,Kristoffer Bernhem,Anders Uhrenholt,Gabriele Farei,Karo Moilanen*

Main category: cs.AI

TL;DR: Spark는 AI 코딩 에이전트가 소프트웨어 개발 작업을 수행할 때 지속적으로 진화하는 경험적 메모리를 사용하여 집단 지속 학습을 달성할 수 있도록 설계된 새로운 공유 에이전트 메모리 아키텍처이다.


<details>
  <summary>Details</summary>
Motivation: 인간 중심의 소프트웨어 개발 관행에서 에이전트 중심으로의 전환은 소프트웨어 개발자들을 위한 기존의 지식 공유 환경을 방해하고 있다.

Method: Spark는 AI 코딩 에이전트가 기여하고 사용하도록 만든 지속적이고 진화하는 경험적 메모리를 사용하는 아키텍처이다. 같은 일반 문제 공간에서 작동하는 에이전트들은 Spark 공유 메모리를 새로운 지식의 저장소로 사용하여 집단 지속 학습을 달성한다.

Result: Spark는 AI 코딩 에이전트에게 소프트웨어 개발 작업을 수행하는 데 도움을 주는 코치 역할을 수행하며, Spark의 추천이 다양한 규모와 능력 계층의 일반 코드 생성 모델에서 생성된 코드의 품질을 향상시킴을 보여준다.

Conclusion: Spark의 도움으로 300억 개의 파라미터를 가진 작은 모델이 훨씬 더 큰 최신 모델이 제공하는 코드 품질에 맞출 수 있었으며, Spark가 생성한 추천의 본질적인 품질을 소프트웨어 개발 최선 사례에 영감을 받은 다양한 기준에 따라 측정하여 최대 98.2%의 유용성을 달성했다.

Abstract: The transition from human-centric to agent-centric software development practices is disrupting existing knowledge sharing environments for software developers. Traditional peer-to-peer repositories and developer communities for shared technical knowledge and best practice have witnessed dramatic drops in participation in a short period of time. At the same time, agentic functional equivalents are yet to emerge leaving AI agents, which already generate a significant proportion of all new software code produced, without access to repositories of valuable shared learning.
  In this paper, we introduce Spark, a novel shared agentic memory architecture which is designed to emulate the collective intelligence and know-how of human developer communities. Spark enables AI coding agents to both contribute to and draw from a persistent and continuously evolving experiential memory. Agents operating in the same general problem space use the Spark shared memory as a repository of new knowledge to achieve collective continual learning. We evaluate Spark as a coach for AI coding agents performing software development tasks. We demonstrate that recommendations made by Spark improve the quality of code generated by generic code generation models at varying sizes and capability tiers. Boosted by Spark, a small open-weights model with 30 billion parameters was able to match the code quality afforded by a much larger state-of-the-art model. Separately, we measure the intrinsic quality of recommendations generated by Spark against a wide range of criteria inspired by software development best practice, and achieve helpfulness levels of up to 98.2% in the top two (out of five) qualitative helpfulness bands.

</details>


### [22] [Simulating the Visual World with Artificial Intelligence: A Roadmap](https://arxiv.org/abs/2511.08585)
*Jingtong Yue,Ziqi Huang,Zhaoxi Chen,Xintao Wang,Pengfei Wan,Ziwei Liu*

Main category: cs.AI

TL;DR: 비디오 생성의 경향이 시각적으로 매력적인 클립 생성에서 상호작용을 지원하고 물리적 타당성을 유지하는 가상 환경 구축으로 이동하고 있다. 이 논문은 비디오 기반 모델을 암묵적 세계 모델과 비디오 렌더러의 두 가지 핵심 구성 요소로 구성된 현대 비디오 기반 모델로 개념화하며, 서로 다른 세대의 발전을 추적한다.


<details>
  <summary>Details</summary>
Motivation: 비디오 생성의 패러다임이 변화하면서 물리적 타당성과 상호작용을 중요시하는 가상 환경 구축이 필요해졌다.

Method: 암묵적 세계 모델과 비디오 렌더러의 조합을 통해 비디오 생성의 발전을 체계적으로 개관하고 각 세대의 핵심 특성과 대표적인 작업을 분석하였다.

Result: 비디오 모델은 물리적 법칙, 상호작용 다이내믹스 및 에이전트 행동에 대한 구조적 지식을 인코딩하고, 최종적으로 다중 시공간 스케일을 아우르는 계획 기능을 포함하는 세계 모델을 포함하게 되었다.

Conclusion: 차세대 세계 모델의 설계 원칙과 에이전트 지능의 역할을 반영한 여러 도전 과제가 논의되었다.

Abstract: The landscape of video generation is shifting, from a focus on generating visually appealing clips to building virtual environments that support interaction and maintain physical plausibility. These developments point toward the emergence of video foundation models that function not only as visual generators but also as implicit world models, models that simulate the physical dynamics, agent-environment interactions, and task planning that govern real or imagined worlds. This survey provides a systematic overview of this evolution, conceptualizing modern video foundation models as the combination of two core components: an implicit world model and a video renderer. The world model encodes structured knowledge about the world, including physical laws, interaction dynamics, and agent behavior. It serves as a latent simulation engine that enables coherent visual reasoning, long-term temporal consistency, and goal-driven planning. The video renderer transforms this latent simulation into realistic visual observations, effectively producing videos as a "window" into the simulated world. We trace the progression of video generation through four generations, in which the core capabilities advance step by step, ultimately culminating in a world model, built upon a video generation model, that embodies intrinsic physical plausibility, real-time multimodal interaction, and planning capabilities spanning multiple spatiotemporal scales. For each generation, we define its core characteristics, highlight representative works, and examine their application domains such as robotics, autonomous driving, and interactive gaming. Finally, we discuss open challenges and design principles for next-generation world models, including the role of agent intelligence in shaping and evaluating these systems. An up-to-date list of related works is maintained at this link.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [23] [Optimizing Classification of Infrequent Labels by Reducing Variability in Label Distribution](https://arxiv.org/abs/2511.07459)
*Ashutosh Agarwal*

Main category: cs.LG

TL;DR: LEVER는 Extreme Classification(XC) 작업에서 성능이 저조한 드문 카테고리 문제를 해결하기 위해 설계된 새로운 솔루션이다.


<details>
  <summary>Details</summary>
Motivation: 드문 카테고리는 샘플이 희소하여 높은 레이블 불일치로 인해 분류 성능이 저하된다.

Method: LEVER는 강력한 시암식 아키텍처를 채택하여 지식 전이를 활용하고 레이블 불일치를 감소시킨다.

Result: 여러 XC 데이터셋에 대한 종합적인 테스트 결과, 드문 카테고리 처리에서 상당한 개선이 나타났다.

Conclusion: 이 연구는 XC 분야에 새로운 기준을 설정하고, 미래 XC 연구를 위한 필수 리소스를 제공하는 두 개의 새로 생성된 다중 의도 데이터셋을 소개한다.

Abstract: This paper presents a novel solution, LEVER, designed to address the challenges posed by underperforming infrequent categories in Extreme Classification (XC) tasks. Infrequent categories, often characterized by sparse samples, suffer from high label inconsistency, which undermines classification performance. LEVER mitigates this problem by adopting a robust Siamese-style architecture, leveraging knowledge transfer to reduce label inconsistency and enhance the performance of One-vs-All classifiers. Comprehensive testing across multiple XC datasets reveals substantial improvements in the handling of infrequent categories, setting a new benchmark for the field. Additionally, the paper introduces two newly created multi-intent datasets, offering essential resources for future XC research.

</details>


### [24] [Partial Action Replacement: Tackling Distribution Shift in Offline MARL](https://arxiv.org/abs/2511.07629)
*Yue Jin,Giovanni Montana*

Main category: cs.LG

TL;DR: Offline 다위치 강화 학습(MARL)은 분포 외(OOD) 공동 행동 평가의 어려움으로 심각한 제약을 받는다. 본 연구에서는 행동 정책이 분해되었을 때, 부분 행동 바꾸기(PAR) 전략이 효과적임을 발견하였다.


<details>
  <summary>Details</summary>
Motivation: Offline MARL에서 OOD 공동 행동 평가의 도전 과제를 해결하고자 함.

Method: 부분 행동 바꾸기(PAR) 전략을 사용해 행동 데이터에 대해 일부 에이전트의 행동만 업데이트함.

Result: SPaCQL이 OOD 문제를 완화하며, 동적으로 각기 다른 PAR 전략의 가중치를 조정함에 따라 더 효과적인 정책 학습을 가능하게 함.

Conclusion: SPaCQL은 에이전트 수에 비례하여 분포 이동을 제어하고 OOD 문제를 해결함으로써 오프라인 MARL 문제의 가치 오류 경계를 개선함.

Abstract: Offline multi-agent reinforcement learning (MARL) is severely hampered by the challenge of evaluating out-of-distribution (OOD) joint actions. Our core finding is that when the behavior policy is factorized - a common scenario where agents act fully or partially independently during data collection - a strategy of partial action replacement (PAR) can significantly mitigate this challenge. PAR updates a single or part of agents' actions while the others remain fixed to the behavioral data, reducing distribution shift compared to full joint-action updates. Based on this insight, we develop Soft-Partial Conservative Q-Learning (SPaCQL), using PAR to mitigate OOD issue and dynamically weighting different PAR strategies based on the uncertainty of value estimation. We provide a rigorous theoretical foundation for this approach, proving that under factorized behavior policies, the induced distribution shift scales linearly with the number of deviating agents rather than exponentially with the joint-action space. This yields a provably tighter value error bound for this important class of offline MARL problems. Our theoretical results also indicate that SPaCQL adaptively addresses distribution shift using uncertainty-informed weights. Our empirical results demonstrate SPaCQL enables more effective policy learning, and manifest its remarkable superiority over baseline algorithms when the offline dataset exhibits the independence structure.

</details>


### [25] [Provably Efficient Sample Complexity for Robust CMDP](https://arxiv.org/abs/2511.07486)
*Sourav Ganguly,Arnob Ghosh*

Main category: cs.LG

TL;DR: 안전 제약을 만족하면서 누적 보상을 극대화하는 정책 학습 문제를 다룹니다. 우리는 위험 제약 마르코프 결정 프로세스(RCMDPs)에 중점을 두고, 최악의 동적 환경에서도 보상을 극대화하는 방법을 제안합니다. 우리의 새로운 알고리즘은 샘플 복잡도 보장을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 안전성을 보장하면서 누적 보상을 극대화할 수 있는 정책 학습의 필요성이 증대하고 있습니다.

Method: 우리는 마르코프 정책이 최적이 아닐 수 있음을 보이고, 잔여 유틸리티 예산을 포함하는 확장된 상태 공간을 도입합니다. 이를 바탕으로 새로운 RCVI 알고리즘을 제안합니다.

Result: 우리는 RCMDP의 샘플 복잡도에 대한 최초의 보장을 제공하며, 최대 $ε$의 위반을 달성합니다.

Conclusion: 우리의 접근 방식의 효과성을 실험적으로 검증했습니다.

Abstract: We study the problem of learning policies that maximize cumulative reward while satisfying safety constraints, even when the real environment differs from a simulator or nominal model. We focus on robust constrained Markov decision processes (RCMDPs), where the agent must maximize reward while ensuring cumulative utility exceeds a threshold under the worst-case dynamics within an uncertainty set. While recent works have established finite-time iteration complexity guarantees for RCMDPs using policy optimization, their sample complexity guarantees remain largely unexplored. In this paper, we first show that Markovian policies may fail to be optimal even under rectangular uncertainty sets unlike the {\em unconstrained} robust MDP. To address this, we introduce an augmented state space that incorporates the remaining utility budget into the state representation. Building on this formulation, we propose a novel Robust constrained Value iteration (RCVI) algorithm with a sample complexity of $\mathcal{\tilde{O}}(|S||A|H^5/ε^2)$ achieving at most $ε$ violation using a generative model where $|S|$ and $|A|$ denote the sizes of the state and action spaces, respectively, and $H$ is the episode length. To the best of our knowledge, this is the {\em first sample complexity guarantee} for RCMDP. Empirical results further validate the effectiveness of our approach.

</details>


### [26] [BIPPO: Budget-Aware Independent PPO for Energy-Efficient Federated Learning Services](https://arxiv.org/abs/2511.08142)
*Anna Lackinger,Andrea Morichetta,Pantelis A. Frangoudis,Schahram Dustdar*

Main category: cs.LG

TL;DR: BIPPO는 에너지 효율적인 다중 에이전트 강화 학습 솔루션으로서 IoT 시스템에서 클라이언트 선택을 개선한다.


<details>
  <summary>Details</summary>
Motivation: Federated Learning은 리소스 제약이 있는 환경에서 시스템의 효율성을 고려하지 않으므로 이를 해결할 필요가 있다.

Method: BIPPO는 예산을 고려한 독립적 근접 정책 최적화 방법으로 에너지 효율성을 개선한다.

Result: BIPPO는 비RL 메커니즘 및 전통적인 PPO, IPPO보다 평균 정확도를 증가시킨다.

Conclusion: BIPPO는 IoT-FL에서 클라이언트 선택을 위한 성능이 좋고 안정적이며 확장 가능하고 지속 가능한 솔루션을 제공한다.

Abstract: Federated Learning (FL) is a promising machine learning solution in large-scale IoT systems, guaranteeing load distribution and privacy. However, FL does not natively consider infrastructure efficiency, a critical concern for systems operating in resource-constrained environments. Several Reinforcement Learning (RL) based solutions offer improved client selection for FL; however, they do not consider infrastructure challenges, such as resource limitations and device churn. Furthermore, the training of RL methods is often not designed for practical application, as these approaches frequently do not consider generalizability and are not optimized for energy efficiency. To fill this gap, we propose BIPPO (Budget-aware Independent Proximal Policy Optimization), which is an energy-efficient multi-agent RL solution that improves performance. We evaluate BIPPO on two image classification tasks run in a highly budget-constrained setting, with FL clients training on non-IID data, a challenging context for vanilla FL. The improved sampler of BIPPO enables it to increase the mean accuracy compared to non-RL mechanisms, traditional PPO, and IPPO. In addition, BIPPO only consumes a negligible proportion of the budget, which stays consistent even if the number of clients increases. Overall, BIPPO delivers a performant, stable, scalable, and sustainable solution for client selection in IoT-FL.

</details>


### [27] [ZeroSim: Zero-Shot Analog Circuit Evaluation with Unified Transformer Embeddings](https://arxiv.org/abs/2511.07658)
*Xiaomeng Yang,Jian Gao,Yanzhi Wang,Xuan Zhang*

Main category: cs.LG

TL;DR: ZeroSim은 변환기 기반의 성능 모델링 프레임워크로, 훈련된 토폴로지에서 강력한 일반화와 미세 조정 없이 보지 못한 토폴로지에 대한 제로 샷 일반화를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 아날로그 회로 설계 자동화에서 성능 평가가 여전히 주요 병목 현상으로 남아 있다.

Method: ZeroSim은 360만 개의 다양한 인스턴스를 포함하는 교육 데이터를 사용하고, 통합된 토폴로지 임베딩과 토폴로지 조건 매개변수 매핑 접근법을 적용하여 강력한 일반화를 달성한다.

Result: ZeroSim은 다양한 증폭기 토폴로지에서 정확한 제로 샷 예측을 제공하여 기존 모델들을 능가한다.

Conclusion: ZeroSim은 기존 SPICE 시뮬레이션에 비해 13배 빠른 속도를 달성하며 아날로그 회로 설계 자동화 작업에서 실용적인 가치를 입증한다.

Abstract: Although recent advancements in learning-based analog circuit design automation have tackled tasks such as topology generation, device sizing, and layout synthesis, efficient performance evaluation remains a major bottleneck. Traditional SPICE simulations are time-consuming, while existing machine learning methods often require topology-specific retraining or manual substructure segmentation for fine-tuning, hindering scalability and adaptability. In this work, we propose ZeroSim, a transformer-based performance modeling framework designed to achieve robust in-distribution generalization across trained topologies under novel parameter configurations and zero-shot generalization to unseen topologies without any fine-tuning. We apply three key enabling strategies: (1) a diverse training corpus of 3.6 million instances covering over 60 amplifier topologies, (2) unified topology embeddings leveraging global-aware tokens and hierarchical attention to robustly generalize to novel circuits, and (3) a topology-conditioned parameter mapping approach that maintains consistent structural representations independent of parameter variations. Our experimental results demonstrate that ZeroSim significantly outperforms baseline models such as multilayer perceptrons, graph neural networks and transformers, delivering accurate zero-shot predictions across different amplifier topologies. Additionally, when integrated into a reinforcement learning-based parameter optimization pipeline, ZeroSim achieves a remarkable speedup (13x) compared to conventional SPICE simulations, underscoring its practical value for a wide range of analog circuit design automation tasks.

</details>


### [28] [On the Role of Calibration in Benchmarking Algorithmic Fairness for Skin Cancer Detection](https://arxiv.org/abs/2511.07700)
*Brandon Dominique,Prudence Lam,Nicholas Kurtansky,Jochen Weber,Kivanc Kose,Veronica Rotemberg,Jennifer Dy*

Main category: cs.LG

TL;DR: 이 연구는 피부암 탐지 AI 모델의 성능 불균형 문제를 해결하기 위해 보정(calibration)을 추가적인 벤치마킹 지표로 사용합니다.


<details>
  <summary>Details</summary>
Motivation: AI 모델의 피부암 탐지에서 성능 차이가 성별, 인종, 나이와 같은 인구 통계적 하위 그룹에서 문제가 되고 있습니다.

Method: AUROC 기반의 공정성 메트릭스 외에 보정을 사용하여 지표를 보완합니다.

Result: AI 모델은 기존의 차별적 정확도를 높였지만 새로운 데이터셋에 적용 시 과다 진단 및 보정 문제를 보였습니다.

Conclusion: 모델 감사 및 메타데이터 수집의 필요성을 강조하고 있습니다.

Abstract: Artificial Intelligence (AI) models have demonstrated expert-level performance in melanoma detection, yet their clinical adoption is hindered by performance disparities across demographic subgroups such as gender, race, and age. Previous efforts to benchmark the performance of AI models have primarily focused on assessing model performance using group fairness metrics that rely on the Area Under the Receiver Operating Characteristic curve (AUROC), which does not provide insights into a model's ability to provide accurate estimates. In line with clinical assessments, this paper addresses this gap by incorporating calibration as a complementary benchmarking metric to AUROC-based fairness metrics. Calibration evaluates the alignment between predicted probabilities and observed event rates, offering deeper insights into subgroup biases. We assess the performance of the leading skin cancer detection algorithm of the ISIC 2020 Challenge on the ISIC 2020 Challenge dataset and the PROVE-AI dataset, and compare it with the second and third place models, focusing on subgroups defined by sex, race (Fitzpatrick Skin Tone), and age. Our findings reveal that while existing models enhance discriminative accuracy, they often over-diagnose risk and exhibit calibration issues when applied to new datasets. This study underscores the necessity for comprehensive model auditing strategies and extensive metadata collection to achieve equitable AI-driven healthcare solutions. All code is publicly available at https://github.com/bdominique/testing_strong_calibration.

</details>


### [29] [Diffusion Guided Adversarial State Perturbations in Reinforcement Learning](https://arxiv.org/abs/2511.07701)
*Xiaolin Sun,Feidi Liu,Zhengming Ding,ZiZhan Zheng*

Main category: cs.LG

TL;DR: 강화 학습 시스템은 다양한 분야에서 놀라운 성공을 거두었지만, 적대적 공격에 취약하다. 특히 비전 기반 환경에서는 고차원 이미지 입력의 작은 조작이 에이전트의 행동을 쉽게 오도할 수 있다. 이 연구에서는 SHIFT라는 새로운 정책 비의존적 확산 기반 상태 방해 공격을 제안하여 이 한계를 극복한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 시스템의 적대적 공격에 대한 취약성을 해결하고자 한다.

Method: 정책에 의존하지 않는 확산 기반의 상태 방해 공격 기법인 SHIFT를 제안한다.

Result: SHIFT 공격은 기존 방어를 효과적으로 무너뜨리고, 기존 공격을 상당히 초월한다.

Conclusion: 강화 학습 에이전트가 의미 인식 적대적 방해에 취약하다는 것을 강조하며, 보다 강력한 정책의 개발이 중요하다.

Abstract: Reinforcement learning (RL) systems, while achieving remarkable success across various domains, are vulnerable to adversarial attacks. This is especially a concern in vision-based environments where minor manipulations of high-dimensional image inputs can easily mislead the agent's behavior. To this end, various defenses have been proposed recently, with state-of-the-art approaches achieving robust performance even under large state perturbations. However, after closer investigation, we found that the effectiveness of the current defenses is due to a fundamental weakness of the existing $l_p$ norm-constrained attacks, which can barely alter the semantics of image input even under a relatively large perturbation budget. In this work, we propose SHIFT, a novel policy-agnostic diffusion-based state perturbation attack to go beyond this limitation. Our attack is able to generate perturbed states that are semantically different from the true states while remaining realistic and history-aligned to avoid detection. Evaluations show that our attack effectively breaks existing defenses, including the most sophisticated ones, significantly outperforming existing attacks while being more perceptually stealthy. The results highlight the vulnerability of RL agents to semantics-aware adversarial perturbations, indicating the importance of developing more robust policies.

</details>


### [30] [Intelligent Optimization of Multi-Parameter Micromixers Using a Scientific Machine Learning Framework](https://arxiv.org/abs/2511.07702)
*Meraj Hassanzadeh,Ehsan Ghaderi,Mohamad Ali Bijarchi,Siamak Kazemzadeh Hannani*

Main category: cs.LG

TL;DR: 이 연구는 전통적인 최적화 방법의 한계를 극복하기 위해 과학적 기계 학습(Sci-ML) 방법론을 활용한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 멀티디멘셔널 최적화는 공학에서 지속적인 도전과제가 되고 있으며, 전통적인 시뮬레이션 기반 최적화 방법에 여러 가지 제약이 있다.

Method: 본 논문에서는 미세 믹서 사례 연구를 통해 심층 강화 학습(DRL) 아키텍처를 이용해 최적화하는 에이전트를 도입하며, 이를 통해 물리 기반 신경망(PINN) 환경과 상호 작용하여 효율적인 최적 해를 제시한다.

Result: 에이전트는 다양한 슈미트 수에서 훈련을 거친 후 최적 설계를 분석하였으며, 전체의 효율성이 항상 기준 정상화 값보다 높았다.

Conclusion: 최대 효율성은 슈미트 수 13.3에서 달성되었으며, 제안된 방법의 장점을 강조하기 위해 유전자 알고리즘과의 비교 분석도 진행되었다.

Abstract: Multidimensional optimization has consistently been a critical challenge in engineering. However, traditional simulation-based optimization methods have long been plagued by significant limitations: they are typically capable of optimizing only a single problem at a time and require substantial computational time for meshing and numerical simulation. This paper introduces a novel framework leveraging cutting-edge Scientific Machine Learning (Sci-ML) methodologies to overcome these inherent drawbacks of conventional approaches. The proposed method provides instantaneous solutions to a spectrum of complex, multidimensional optimization problems. A micromixer case study is employed to demonstrate this methodology. An agent, operating on a Deep Reinforcement Learning (DRL) architecture, serves as the optimizer to explore the relationships between key problem parameters. This optimizer interacts with an environment constituted by a parametric Physics-Informed Neural Network (PINN), which responds to the agent's actions at a significantly higher speed than traditional numerical methods. The agent's objective, conditioned on the Schmidt number is to discover the optimal geometric and physical parameters that maximize the micromixer's efficiency. After training the agent across a wide range of Schmidt numbers, we analyzed the resulting optimal designs. Across this entire spectrum, the achieved efficiency was consistently greater than the baseline, normalized value. The maximum efficiency occurred at a Schmidt number of 13.3, demonstrating an improvement of approximately 32%. Finally, a comparative analysis with a Genetic Algorithm was conducted under equivalent conditions to underscore the advantages of the proposed method.

</details>


### [31] [Schedulers for Schedule-free: Theoretically inspired hyperparameters](https://arxiv.org/abs/2511.07767)
*Yuen-Man Pun,Matthew Buchholz,Robert M. Gower*

Main category: cs.LG

TL;DR: 스케줄에 구애받지 않는 방법이 하이퍼파라미터 조정이 제한될 때 강력한 성능을 보임을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 스케줄에 구애받지 않는 방법의 현재 이론은 상수 학습률만 지원하지만, 실제 구현에서는 웜업 스케줄이 사용됩니다.

Method: 스케줄에 구애받지 않는 방법의 마지막 반복 수렴 이론을 확장하고 학습률의 함수로 평균 매개변수를 업데이트하는 방법을 제시합니다.

Result: 우리의 수렴 이론이 깊은 신경망의 실제 실행과 관련하여 예측력을 가지고 있음을 실험을 통해 보여주며, 웜업-안정-감소(wsd) 스케줄에서 최적의 수렴 속도를 $	extmath{O}(1/	extmath{oot{T}})$로 나타냅니다.

Conclusion: 새로운 적응형 Polyak 학습률 스케줄을 설계하고, 블랙박스 모델 증류 작업에서 여러 기준 모델에 비해 좋은 성능을 발휘함을 증명합니다.

Abstract: The recently proposed schedule-free method has been shown to achieve strong performance when hyperparameter tuning is limited. The current theory for schedule-free only supports a constant learning rate, where-as the implementation used in practice uses a warm-up schedule. We show how to extend the last-iterate convergence theory of schedule-free to allow for any scheduler, and how the averaging parameter has to be updated as a function of the learning rate. We then perform experiments showing how our convergence theory has some predictive power with regards to practical executions on deep neural networks, despite that this theory relies on assuming convexity. When applied to the warmup-stable-decay (wsd) schedule, our theory shows the optimal convergence rate of $\mathcal{O}(1/\sqrt{T})$. We then use convexity to design a new adaptive Polyak learning rate schedule for schedule-free. We prove an optimal anytime last-iterate convergence for our new Polyak schedule, and show that it performs well compared to a number of baselines on a black-box model distillation task.

</details>


### [32] [MURPHY: Multi-Turn GRPO for Self Correcting Code Generation](https://arxiv.org/abs/2511.07833)
*Chanakya Ekbote,Vijay Lingam,Behrooz Omidvar-Tehrani,Jun Huan,Sujay Sanghavi,Anoop Deoras,Stefano Soatto*

Main category: cs.LG

TL;DR: Murphy라는 다회전 반사 최적화 프레임워크를 통해, GRPO를 확장하며, 반복적인 자기 교정을 포함하여 대규모 언어 모델의 추론 능력을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 추론 능력을 향상시키기 위해 RLVR가 필요하다.

Method: 반복적인 자기 교정을 포함하는 다회전 반사 최적화 프레임워크인 Murphy를 제안한다.

Result: Qwen 및 OLMo와 같은 모델 계열을 사용한 코드 생성 벤치마크에서 Murphy는 GRPO에 비해 pass@1에서 최대 8%의 상대적 성능 향상을 보여준다.

Conclusion: Murphy는 LLM의 추론 품질을 개선하는 데 효과적이다.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful framework for enhancing the reasoning capabilities of large language models (LLMs). However, existing approaches such as Group Relative Policy Optimization (GRPO) and its variants, while effective on reasoning benchmarks, struggle with agentic tasks that require iterative decision-making. We introduce Murphy, a multi-turn reflective optimization framework that extends GRPO by incorporating iterative self-correction during training. By leveraging both quantitative and qualitative execution feedback, Murphy enables models to progressively refine their reasoning across multiple turns. Evaluations on code generation benchmarks with model families such as Qwen and OLMo show that Murphy consistently improves performance, achieving up to a 8% relative gain in pass@1 over GRPO, on similar compute budgets.

</details>


### [33] [Test-driven Reinforcement Learning](https://arxiv.org/abs/2511.07904)
*Zhao Yu,Xiuping Wu,Liangjun Ke*

Main category: cs.LG

TL;DR: TdRL 프레임워크는 여러 테스트 함수를 사용하여 강화 학습의 보상 함수 문제를 해결하고, 최적 정책에 근접하는 성과를 보입니다.


<details>
  <summary>Details</summary>
Motivation: 보상 함수 설계의 어려움을 해결하고자 합니다.

Method: 여러 테스트 함수를 사용하여 작업 목표를 정의하는 TdRL 프레임워크를 제안합니다.

Result: TdRL은 정책 훈련에서 수작업 보상 방법과 동등하거나 뛰어난 성과를 보였습니다.

Conclusion: TdRL은 강화 학습 응용에서 보상 설계 문제를 해결하는 데 도움이 될 수 있는 새로운 관점을 제공합니다.

Abstract: Reinforcement learning (RL) has been recognized as a powerful tool for robot control tasks. RL typically employs reward functions to define task objectives and guide agent learning. However, since the reward function serves the dual purpose of defining the optimal goal and guiding learning, it is challenging to design the reward function manually, which often results in a suboptimal task representation. To tackle the reward design challenge in RL, inspired by the satisficing theory, we propose a Test-driven Reinforcement Learning (TdRL) framework. In the TdRL framework, multiple test functions are used to represent the task objective rather than a single reward function. Test functions can be categorized as pass-fail tests and indicative tests, each dedicated to defining the optimal objective and guiding the learning process, respectively, thereby making defining tasks easier. Building upon such a task definition, we first prove that if a trajectory return function assigns higher returns to trajectories closer to the optimal trajectory set, maximum entropy policy optimization based on this return function will yield a policy that is closer to the optimal policy set. Then, we introduce a lexicographic heuristic approach to compare the relative distance relationship between trajectories and the optimal trajectory set for learning the trajectory return function. Furthermore, we develop an algorithm implementation of TdRL. Experimental results on the DeepMind Control Suite benchmark demonstrate that TdRL matches or outperforms handcrafted reward methods in policy training, with greater design simplicity and inherent support for multi-objective optimization. We argue that TdRL offers a novel perspective for representing task objectives, which could be helpful in addressing the reward design challenges in RL applications.

</details>


### [34] [An Integrated Fusion Framework for Ensemble Learning Leveraging Gradient Boosting and Fuzzy Rule-Based Models](https://arxiv.org/abs/2511.08077)
*Jinbo Li,Peng Liu,Long Chen,Witold Pedrycz,Weiping Ding*

Main category: cs.LG

TL;DR: 이 논문은 퍼지 규칙 기반 모델과 그래디언트 부스팅을 결합한 통합 융합 프레임워크를 제안하며, 성능과 해석 가능성을 향상시키는데 기여합니다.


<details>
  <summary>Details</summary>
Motivation: 개별 학습 방법의 한계를 극복하기 위해 다양한 학습 패러다임 통합이 머신러닝 연구의 오랜 초점이었습니다.

Method: 각 반복에서 동적 요소에 의해 제어되는 퍼지 규칙 기반 모델이 구성되어 전체 앙상블에 대한 기여를 최적화합니다.

Result: 제안된 그래디언트 부스팅 프레임워크는 퍼지 규칙 기반 모델의 성능을 향상시킵니다.

Conclusion: 최적의 요소를 활용하여 각 모델의 기여를 조정함으로써 성능을 향상시키고 해석 가능성을 유지하며 모델의 유지보수 및 업데이트를 단순화합니다.

Abstract: The integration of different learning paradigms has long been a focus of machine learning research, aimed at overcoming the inherent limitations of individual methods. Fuzzy rule-based models excel in interpretability and have seen widespread application across diverse fields. However, they face challenges such as complex design specifications and scalability issues with large datasets. The fusion of different techniques and strategies, particularly Gradient Boosting, with Fuzzy Rule-Based Models offers a robust solution to these challenges. This paper proposes an Integrated Fusion Framework that merges the strengths of both paradigms to enhance model performance and interpretability. At each iteration, a Fuzzy Rule-Based Model is constructed and controlled by a dynamic factor to optimize its contribution to the overall ensemble. This control factor serves multiple purposes: it prevents model dominance, encourages diversity, acts as a regularization parameter, and provides a mechanism for dynamic tuning based on model performance, thus mitigating the risk of overfitting. Additionally, the framework incorporates a sample-based correction mechanism that allows for adaptive adjustments based on feedback from a validation set. Experimental results substantiate the efficacy of the presented gradient boosting framework for fuzzy rule-based models, demonstrating performance enhancement, especially in terms of mitigating overfitting and complexity typically associated with many rules. By leveraging an optimal factor to govern the contribution of each model, the framework improves performance, maintains interpretability, and simplifies the maintenance and update of the models.

</details>


### [35] [SafeMIL: Learning Offline Safe Imitation Policy from Non-Preferred Trajectories](https://arxiv.org/abs/2511.08136)
*Returaj Burnwal,Nirav Pravinbhai Bhatt,Balaraman Ravindran*

Main category: cs.LG

TL;DR: 이 연구에서는 오프라인 안전 모방 학습 문제를 다룹니다. 안전을 우선시하는 정책을 학습하기 위해 위험한 행동을 피하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 환경에서는 온라인 상호작용이 위험할 수 있고, 보상 및 안전 비용 정보를 정확히 지정하는 것이 어려울 수 있습니다.

Method: Multiple Instance Learning을 통해 상태-행동 쌍이 위험한지 예측하는 매개변수화된 비용을 학습하는 새로운 접근법인 SafeMIL을 제안합니다.

Result: 이 접근법을 통해 안전한 정책을 학습하며, 이는 비용 제약을 충족시키면서 보상 성능을 저하시키지 않습니다.

Conclusion: 여러 기준선보다 우수한 성과를 보였습니다.

Abstract: In this work, we study the problem of offline safe imitation learning (IL). In many real-world settings, online interactions can be risky, and accurately specifying the reward and the safety cost information at each timestep can be difficult. However, it is often feasible to collect trajectories reflecting undesirable or risky behavior, implicitly conveying the behavior the agent should avoid. We refer to these trajectories as non-preferred trajectories. Unlike standard IL, which aims to mimic demonstrations, our agent must also learn to avoid risky behavior using non-preferred trajectories. In this paper, we propose a novel approach, SafeMIL, to learn a parameterized cost that predicts if the state-action pair is risky via \textit{Multiple Instance Learning}. The learned cost is then used to avoid non-preferred behaviors, resulting in a policy that prioritizes safety. We empirically demonstrate that our approach can learn a safer policy that satisfies cost constraints without degrading the reward performance, thereby outperforming several baselines.

</details>


### [36] [ARAC: Adaptive Regularized Multi-Agent Soft Actor-Critic in Graph-Structured Adversarial Games](https://arxiv.org/abs/2511.08412)
*Ruochuan Shi,Runyu Lu,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.LG

TL;DR: ARAC는 그래프 구조의 다중 에이전트 강화 학습에서 효율적인 정책 학습을 위한 적응형 일반화 기법을 통합하여 빠른 수렴과 높은 성공률을 보인다.


<details>
  <summary>Details</summary>
Motivation: 그래프 구조의 다중 에이전트 강화 학습에서 희박한 보상이 정책 학습을 방해하는 문제를 해결한다.

Method: Adaptive Regularized Multi-Agent Soft Actor-Critic (ARAC)를 제안하고, 에이전트 의존성을 모델링하기 위해 주의 기반 그래프 신경망(GNN)과 적응형 분기 정규화 메커니즘을 통합했다.

Result: ARAC는 추적 및 대결 시나리오에서 다른 MARL 기준과 비교했을 때 더 빠른 수렴과 높은 최종 성공률을 기록했다.

Conclusion: ARAC는 복잡한 그래프 구조 환경에서 효과적임을 입증하며, 다양한 에이전트 수에 대해 강한 확장성을 보여준다.

Abstract: In graph-structured multi-agent reinforcement learning (MARL) adversarial tasks such as pursuit and confrontation, agents must coordinate under highly dynamic interactions, where sparse rewards hinder efficient policy learning. We propose Adaptive Regularized Multi-Agent Soft Actor-Critic (ARAC), which integrates an attention-based graph neural network (GNN) for modeling agent dependencies with an adaptive divergence regularization mechanism. The GNN enables expressive representation of spatial relations and state features in graph environments. Divergence regularization can serve as policy guidance to alleviate the sparse reward problem, but it may lead to suboptimal convergence when the reference policy itself is imperfect. The adaptive divergence regularization mechanism enables the framework to exploit reference policies for efficient exploration in the early stages, while gradually reducing reliance on them as training progresses to avoid inheriting their limitations. Experiments in pursuit and confrontation scenarios demonstrate that ARAC achieves faster convergence, higher final success rates, and stronger scalability across varying numbers of agents compared with MARL baselines, highlighting its effectiveness in complex graph-structured environments.

</details>


### [37] [An update to PYRO-NN: A Python Library for Differentiable CT Operators](https://arxiv.org/abs/2511.08427)
*Linda-Sophie Schneider,Yipeng Sun,Chengze Ye,Markus Michen,Andreas Maier*

Main category: cs.LG

TL;DR: 본 논문은 X선 컴퓨터 단층 촬영(CT) 재구성을 위한 PYRO-NN 라이브러리의 업데이트 버전을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 현대 영상 기술에서 발생하는 문제들을 해결하기 위해 고전적 재구성 기법과 데이터 기반 접근 방식을 결합하는 방법의 필요성.

Method: PYRO-NN의 새로운 버전은 PyTorch에 대한 호환성을 확장하고 효율적인 투영 및 역투영 작업을 위한 네이티브 CUDA 커널 지원을 도입한다.

Result: 업데이트된 프레임워크는 임상 이미지 아티팩트를 시뮬레이션하고 임의의 데이터 취득 경로를 모델링하며, 유연하고 종단 간 훈련 가능한 파이프라인을 생성할 수 있는 도구를 포함한다.

Conclusion: 코드는 https://github.com/csyben/PYRO-NN에서 확인할 수 있다.

Abstract: Deep learning has brought significant advancements to X-ray Computed Tomography (CT) reconstruction, offering solutions to challenges arising from modern imaging technologies. These developments benefit from methods that combine classical reconstruction techniques with data-driven approaches. Differentiable operators play a key role in this integration by enabling end-to-end optimization and the incorporation of physical modeling within neural networks.
  In this work, we present an updated version of PYRO-NN, a Python-based library for differentiable CT reconstruction. The updated framework extends compatibility to PyTorch and introduces native CUDA kernel support for efficient projection and back-projection operations across parallel, fan, and cone-beam geometries. Additionally, it includes tools for simulating imaging artifacts, modeling arbitrary acquisition trajectories, and creating flexible, end-to-end trainable pipelines through a high-level Python API. Code is available at: https://github.com/csyben/PYRO-NN

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [38] [A Negotiation-Based Multi-Agent Reinforcement Learning Approach for Dynamic Scheduling of Reconfigurable Manufacturing Systems](https://arxiv.org/abs/2511.07707)
*Manonmani Sekar,Nasim Nezamoddini*

Main category: cs.MA

TL;DR: 이 연구는 재구성 가능한 제조 시스템(RMS)의 소프트 계획에서 동적 스케줄링을 위해 다중 에이전트 강화 학습(MARL)의 적용을 탐구하며, 제안된 프레임워크는 DQN 에이전트를 사용하여 최적의 작업 기계 할당을 실시간으로 학습하도록 설계되었다.


<details>
  <summary>Details</summary>
Motivation: 소비자 수요의 변동, 새로운 기술 발전의 도입 및 연결된 공급망 섹션의 중단에 신속하게 적응할 수 있는 RMS의 중요성 때문이다.

Method: 중앙 집중 훈련을 통해 훈련된 DQN 에이전트는 기계 고장 및 재구성 지연과 같은 확률적 사건에 적응하며 실시간으로 최적의 작업 기계 할당을 학습한다.

Result: 제안된 접근 방식이 기계 활용도 향상과 함께 완료 시간과 지연을 줄이는 데 있어 기본 히스틱을 초월하는 성과를 달성했다.

Conclusion: 다이내믹 재구성 가능한 제조 환경에서 지능적이고 적응적인 스케줄링을 위한 MARL 메커니즘의 적용의 이점을 확인하였다.

Abstract: Reconfigurable manufacturing systems (RMS) are critical for future market adjustment given their rapid adaptation to fluctuations in consumer demands, the introduction of new technological advances, and disruptions in linked supply chain sections. The adjustable hard settings of such systems require a flexible soft planning mechanism that enables realtime production planning and scheduling amid the existing complexity and variability in their configuration settings. This study explores the application of multi agent reinforcement learning (MARL) for dynamic scheduling in soft planning of the RMS settings. In the proposed framework, deep Qnetwork (DQN) agents trained in centralized training learn optimal job machine assignments in real time while adapting to stochastic events such as machine breakdowns and reconfiguration delays. The model also incorporates a negotiation with an attention mechanism to enhance state representation and improve decision focus on critical system features. Key DQN enhancements including prioritized experience replay, nstep returns, double DQN and soft target update are used to stabilize and accelerate learning. Experiments conducted in a simulated RMS environment demonstrate that the proposed approach outperforms baseline heuristics in reducing makespan and tardiness while improving machine utilization. The reconfigurable manufacturing environment was extended to simulate realistic challenges, including machine failures and reconfiguration times. Experimental results show that while the enhanced DQN agent is effective in adapting to dynamic conditions, machine breakdowns increase variability in key performance metrics such as makespan, throughput, and total tardiness. The results confirm the advantages of applying the MARL mechanism for intelligent and adaptive scheduling in dynamic reconfigurable manufacturing environments.

</details>


### [39] [A Historical Interaction-Enhanced Shapley Policy Gradient Algorithm for Multi-Agent Credit Assignment](https://arxiv.org/abs/2511.07778)
*Ao Ding,Licheng Sun,Yongjie Hou,Huaqing Zhang,Hongbin Ma*

Main category: cs.MA

TL;DR: 본 논문은 다중 에이전트 협력 문제에서 성능을 높이기 위해 역사적 상호작용-강화 샤플리 정책 경량 알고리즘(HIS)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 신용 할당 방식은 강하게 결합된 작업에서 개별 기여를 신뢰성 있게 포착하지 못하고 훈련의 안정성을 유지하면서 결과 성능이 제한된다.

Method: HIS는 기본 보상과 개별 기여 인센티브의 균형을 맞추기 위해 혼합 신용 할당 메커니즘을 사용하고, 역사적 상호작용 데이터를 활용하여 샤플리 값을 샘플 효율적으로 계산한다.

Result: 실험 결과 HIS는 최신 방법들보다 우수한 성능을 나타내며, 특히 강하게 결합된 복합 협업 작업에서 두드러진 성과를 보인다.

Conclusion: HIS는 혼합 신용 할당 메커니즘을 제공하여 효율적이고 안정적인 할당 결과를 보장한다.

Abstract: Multi-agent reinforcement learning (MARL) has demonstrated remarkable performance in multi-agent collaboration problems and has become a prominent topic in artificial intelligence research in recent years. However, traditional credit assignment schemes in MARL cannot reliably capture individual contributions in strongly coupled tasks while maintaining training stability, which leads to limited generalization capabilities and hinders algorithm performance. To address these challenges, we propose a Historical Interaction-Enhanced Shapley Policy Gradient Algorithm (HIS) for Multi-Agent Credit Assignment, which employs a hybrid credit assignment mechanism to balance base rewards with individual contribution incentives. By utilizing historical interaction data to calculate the Shapley value in a sample-efficient manner, HIS enhances the agent's ability to perceive its own contribution, while retaining the global reward to maintain training stability. Additionally, we provide theoretical guarantees for the hybrid credit assignment mechanism, ensuring that the assignment results it generates are both efficient and stable. We evaluate the proposed algorithm in three widely used continuous-action benchmark environments: Multi-Agent Particle Environment, Multi-Agent MuJoCo, and Bi-DexHands. Experimental results demonstrate that HIS outperforms state-of-the-art methods, particularly excelling in strongly coupled, complex collaborative tasks.

</details>


### [40] [Can LLM Agents Really Debate? A Controlled Study of Multi-Agent Debate in Logical Reasoning](https://arxiv.org/abs/2511.07784)
*Haolun Wu,Zhenkun Li,Lingyao Li*

Main category: cs.MA

TL;DR: 다중 에이전트 논쟁(MAD)은 대형 언어 모델의 추론 성능을 향상시키는 유망한 프레임워크로 등장했다. 본 연구는 LLM 에이전트가 진정으로 심의적 추론에 참여할 수 있는지 여부를 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 논쟁(MAD)의 개선된 추론 성능을 이해하고, LLM 에이전트가 심의적 논쟁에 참여할 수 있는지를 확인하고자 한다.

Method: Knight--Knave--Spy 논리 퍼즐을 사용한 통제된 연구를 통해, 팀 크기, 구성, 신뢰도 가시성, 논쟁 순서, 논쟁 깊이, 작업 난이도 등 여섯 가지 구조적 및 인지적 요인의 영향을 체계적으로 분석한다.

Result: 내재적인 추론 강도와 집단 다양성이 논쟁 성공의 주요 요인으로 나타났지만, 구조적 매개변수는 제한적인 이익을 제공한다.

Conclusion: 이 연구는 LLM 논쟁이 성공하거나 실패하는 방식과 이유에 대한 귀중한 통찰을 제공하며, 해석 가능하고 진실을 추구하는 다중 에이전트 추론 시스템을 설계하는 데 도움을 준다.

Abstract: Multi-agent debate (MAD) has recently emerged as a promising framework for improving the reasoning performance of large language models (LLMs). Yet, whether LLM agents can genuinely engage in deliberative reasoning, beyond simple ensembling or majority voting, remains unclear. We address this question through a controlled study using the Knight--Knave--Spy logic puzzle, which enables precise, step-wise evaluation of debate outcomes and processes under verifiable ground truth. We systematically set up six structural and cognitive factors, including agent team size, composition, confidence visibility, debate order, debate depth, and task difficulty, to disentangle their respective effects on collective reasoning. Our results show that intrinsic reasoning strength and group diversity are the dominant drivers of debate success, while structural parameters such as order or confidence visibility offer limited gains. Beyond outcomes, process-level analyses identify key behavioral patterns: majority pressure suppresses independent correction, effective teams overturn incorrect consensus, and rational, validity-aligned reasoning most strongly predicts improvement. These findings provide valuable insights into how and why LLM debates succeed or fail, offering guidance for designing interpretable and truth-seeking multi-agent reasoning systems.

</details>


### [41] [How Brittle is Agent Safety? Rethinking Agent Risk under Intent Concealment and Task Complexity](https://arxiv.org/abs/2511.08487)
*Zihan Ma,Dongsheng Zhu,Shudong Liu,Taolin Zhang,Junnan Liu,Qingqiu Li,Minnan Luo,Songyang Zhang,Kai Chen*

Main category: cs.MA

TL;DR: LLM 기반 에이전트의 안전성 평가가 복잡한 위협을 제대로 다루지 못하는 문제를 해결하기 위해, OASIS라는 새로운 벤치마크와 시뮬레이션 환경을 도입하여 에이전트 안전성을 분석하였다.


<details>
  <summary>Details</summary>
Motivation: 현재 LLM 기반 에이전트의 안전성 평가는 주로 단순한 해악에 초점을 맞추고 복잡한 작업 내에 숨겨진 악의적 의도를 고려하지 않는다.

Method: 의도 숨김과 작업 복잡성의 직교적 압력 아래에서 에이전트 안전성의 취약성을 분석하기 위해 OASIS라는 계층적 벤치마크와 시뮬레이션 샌드박스를 도입하였다.

Result: 의도가 불명확해질수록 안전 정렬이 급격히 저하되고, 더 어려운 작업에서 에이전트가 더 안전해 보이는 '복잡성 역설' 현상이 나타났다.

Conclusion: OASIS와 그 시뮬레이션 환경을 출시함으로써 간과된 안전성 측면을 탐구하고 강화할 수 있는 원칙적인 기초를 제공하였다.

Abstract: Current safety evaluations for LLM-driven agents primarily focus on atomic harms, failing to address sophisticated threats where malicious intent is concealed or diluted within complex tasks. We address this gap with a two-dimensional analysis of agent safety brittleness under the orthogonal pressures of intent concealment and task complexity. To enable this, we introduce OASIS (Orthogonal Agent Safety Inquiry Suite), a hierarchical benchmark with fine-grained annotations and a high-fidelity simulation sandbox. Our findings reveal two critical phenomena: safety alignment degrades sharply and predictably as intent becomes obscured, and a "Complexity Paradox" emerges, where agents seem safer on harder tasks only due to capability limitations. By releasing OASIS and its simulation environment, we provide a principled foundation for probing and strengthening agent safety in these overlooked dimensions.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [42] [AudAgent: Automated Auditing of Privacy Policy Compliance in AI Agents](https://arxiv.org/abs/2511.07441)
*Ye Zheng,Yidan Hu*

Main category: cs.CR

TL;DR: AI 에이전트의 데이터 관행을 실시간으로 모니터링하고 프라이버시 정책 준수를 보장하는 AudAgent를 소개한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 민감한 사용자 로컬 데이터를 수집하거나 공개하는 과정에서 사용자 동의 없이 이루어지는 경우가 많아 프라이버시 문제가 심각하다.

Method: AudAgent는 AI 에이전트의 자동화된 프라이버시 감사를 위해 네 가지 구성 요소를 갖춘다: 정책 파싱, 런타임 주석, 준수 감사 및 사용자 인터페이스.

Result: AudAgent는 AI 에이전트를 실시간으로 모니터링하며, 프라이버시 정책 위반 가능성을 효과적으로 식별한다.

Conclusion: AudAgent는 주류 프로그래밍 프레임워크에서 구축된 AI 에이전트에 대해 실시간으로 프라이버시 정책 위반을 식별하는 데 효과적이다.

Abstract: AI agents can autonomously perform tasks and, often without explicit user consent, collect or disclose users' sensitive local data, which raises serious privacy concerns. Although AI agents' privacy policies may describe their intended data practices, there remains limited transparency and accountability about whether runtime behavior matches those policies. To close this gap, we introduce AudAgent, a visual framework that continuously monitors AI agents' data practices in real time and guards compliance with stated privacy policies.
  AudAgent consists of four components for automated privacy auditing of AI agents. (i) Policy parsing: an ensemble of LLMs translates natural-language privacy policies into a structured privacy-policy model, where cross-LLM voting guarantees confidence of the parsing results. (ii) Runtime annotation: a lightweight Presidio-based analyzer detects sensitive data and annotates how the data is used based on the context of the AI agent's operations and the privacy-policy model. (iii) Compliance auditing: ontology alignment and automata-based evaluation connect the policy model with runtime annotations, enabling on-the-fly compliance checks between the natural-language policy and observed unordered data practices of AI agents. (iv) User interface: a platform-independent implementation visualizes the real-time execution trace of AI agents along with potential privacy risks detected during auditing, providing user-friendly transparency and accountability.
  In addition to common formatted privacy policies, AudAgent also supports user-defined policies for fine-grained control and customization. We evaluate AudAgent on AI agents built upon mainstream programming frameworks such as AutoGen, experiments show that AudAgent effectively identifies potential privacy policy violations in real time.

</details>


### [43] [Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models](https://arxiv.org/abs/2511.07503)
*Asia Belfiore,Jonathan Passerat-Palmbach,Dmitrii Usynin*

Main category: cs.CR

TL;DR: 유전 데이터의 증가된 가용성은 유전체 연구를 변화시켰지만, 민감한 특성으로 인해 처리와 관련된 여러 개인 정보 보호 문제를 야기했다. 본 연구는 유전적 변이 프로필 생성을 위해 언어 모델을 이용하고, 민감한 유전 데이터를 보호하기 위해 차별 개인정보 보호를 활용한다.


<details>
  <summary>Details</summary>
Motivation: 유전 데이터의 민감성 때문에 개인 정보 보호 문제를 해결하기 위한 새로운 방법론이 필요하다.

Method: 기존의 블랙 박스 회원 추정 공격(MIA)과 맥락적 유전체 메트릭을 결합한 새로운 생물학적으로 정보화된 하이브리드 회원 추정 공격(biHMIA)을 도입하여 개인 정보 보호 보장을 경험적으로 평가한다.

Result: 작은 규모와 큰 규모의 GPT 유사 변환기 모델 모두가 소규모 유전체의 합성 변형 생성기로서 적합하며, 하이브리드 공격은 평균적으로 전통적인 메트릭 기반 MIA보다 더 높은 적대적 성공을 이끌어낸다.

Conclusion: 본 연구는 언어 모델의 활용이 유전자 데이터를 보호하면서도 합성 유전 변이를 생성할 수 있음을 보여준다.

Abstract: The increased availability of genetic data has transformed genomics research, but raised many privacy concerns regarding its handling due to its sensitive nature. This work explores the use of language models (LMs) for the generation of synthetic genetic mutation profiles, leveraging differential privacy (DP) for the protection of sensitive genetic data. We empirically evaluate the privacy guarantees of our DP modes by introducing a novel Biologically-Informed Hybrid Membership Inference Attack (biHMIA), which combines traditional black box MIA with contextual genomics metrics for enhanced attack power. Our experiments show that both small and large transformer GPT-like models are viable synthetic variant generators for small-scale genomics, and that our hybrid attack leads, on average, to higher adversarial success compared to traditional metric-based MIAs.

</details>


### [44] [FedRW: Efficient Privacy-Preserving Data Reweighting for Enhancing Federated Learning of Language Models](https://arxiv.org/abs/2511.07505)
*Pukang Ye,Junwei Luo,Xiaolei Dong,Yunbo Yang*

Main category: cs.CR

TL;DR: Federated ReWeighting (FedRW)는 연합 LLM 훈련에서 삭제 대신 샘플 재가중치를 통해 소프트 중복 제거를 수행하는 최초의 프라이버시 보호 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 데이터 중복은 대규모 말뭉치에서 LLM의 성능과 프라이버시를 저해한다. 전통적인 중복 제거 방법은 신뢰할 수 있는 제3자를 통해 균일한 삭제를 수행하는데, 이로 인해 정보성 샘플의 손실 위험이 있으며 프라이버시 취약점도 초래된다.

Method: FedRW는 삭제 대신 샘플 재가중치를 수행하는 첫 번째 프라이버시 보장 프레임워크로, 안전한 다자간 계산을 통한 보안성과 빈도 인식 재가중치 프로토콜과 효율성 및 확장성을 보장하는 병렬 오케스트레이션 전략을 제안한다.

Result: Empirical results show that FedRW achieves up to 28.78배의 전처리 속도 향상과 약 11.42%의 당혹감 개선을 통해 기존의 최첨단 방법을 능가한다.

Conclusion: FedRW는 연합 LLM 훈련에서 중복 관리를 위한 새로운 패러다임을 확립한다.

Abstract: Data duplication within large-scale corpora often impedes large language models' (LLMs) performance and privacy. In privacy-concerned federated learning scenarios, conventional deduplication methods typically rely on trusted third parties to perform uniform deletion, risking loss of informative samples while introducing privacy vulnerabilities. To address these gaps, we propose Federated ReWeighting (FedRW), the first privacy-preserving framework, to the best of our knowledge, that performs soft deduplication via sample reweighting instead of deletion in federated LLM training, without assuming a trusted third party. At its core, FedRW proposes a secure, frequency-aware reweighting protocol through secure multi-party computation, coupled with a parallel orchestration strategy to ensure efficiency and scalability. During training, FedRW utilizes an adaptive reweighting mechanism with global sample frequencies to adjust individual loss contributions, effectively improving generalization and robustness. Empirical results demonstrate that FedRW outperforms the state-of-the-art method by achieving up to 28.78x speedup in preprocessing and approximately 11.42% improvement in perplexity, while offering enhanced security guarantees. FedRW thus establishes a new paradigm for managing duplication in federated LLM training.

</details>


### [45] [SALT: Steering Activations towards Leakage-free Thinking in Chain of Thought](https://arxiv.org/abs/2511.07772)
*Shourya Batra,Pierce Tillman,Samarth Gaggar,Shashank Kesineni,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary*

Main category: cs.CR

TL;DR: LLM의 내부 추론 과정에서 개인 정보가 유출되는 문제를 해결하기 위한 접근 방식 SALT를 제안하며, 다양한 모델에서 개인 정보 유출을 줄이는데 성공하였다.


<details>
  <summary>Details</summary>
Motivation: LLM이 사용자 데이터에 접근하는 개인 비서로 발전함에 따라, 내부 추론 과정에서 개인 정보가 유출되는 문제가 대두되고 있다.

Method: SALT는 숨겨진 상태에서 목표 지향적 지시 벡터를 주입하여 LLM의 Chain of Thought(CoT)에서 개인 정보 유출을 완화하는 경량 테스트 시간 개입 방식이다.

Result: 실험을 통해 SALT가 QwQ-32B에서 CPL을 $18.2	ext{%}$ 감소시키고, Llama-3.1-8B에서 $17.9	ext{%}$ 감소시키며, Deepseek에서 $31.2	ext{%}$ 감소시키는 것을 확인하였다.

Conclusion: SALT는 추론 가능한 언어 모델에서 테스트 시간 개인 정보 보호를 위한 실용적인 접근 방식을 제공하여 LLM 기반 개별 에이전트의 안전한 배포를 위한 길을 제시한다.

Abstract: As Large Language Models (LLMs) evolve into personal assistants with access to sensitive user data, they face a critical privacy challenge: while prior work has addressed output-level privacy, recent findings reveal that LLMs often leak private information through their internal reasoning processes, violating contextual privacy expectations. These leaky thoughts occur when models inadvertently expose sensitive details in their reasoning traces, even when final outputs appear safe. The challenge lies in preventing such leakage without compromising the model's reasoning capabilities, requiring a delicate balance between privacy and utility. We introduce Steering Activations towards Leakage-free Thinking (SALT), a lightweight test-time intervention that mitigates privacy leakage in model's Chain of Thought (CoT) by injecting targeted steering vectors into hidden state. We identify the high-leakage layers responsible for this behavior. Through experiments across multiple LLMs, we demonstrate that SALT achieves reductions including $18.2\%$ reduction in CPL on QwQ-32B, $17.9\%$ reduction in CPL on Llama-3.1-8B, and $31.2\%$ reduction in CPL on Deepseek in contextual privacy leakage dataset AirGapAgent-R while maintaining comparable task performance and utility. Our work establishes SALT as a practical approach for test-time privacy protection in reasoning-capable language models, offering a path toward safer deployment of LLM-based personal agents.

</details>


### [46] [Class-feature Watermark: A Resilient Black-box Watermark Against Model Extraction Attacks](https://arxiv.org/abs/2511.07947)
*Yaxin Xiao,Qingqing Ye,Zi Liang,Haoyang Li,RongHua Li,Huadi Zheng,Haibo Hu*

Main category: cs.CR

TL;DR: 이 논문은 기존의 워터마킹 기술이 모델 추출 공격에 대해 불충분하다는 점을 밝히고, 이를 해결하기 위해 새로운 워터마킹 제거 공격 방법과 강력한 보호 기술을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 모델은 귀중한 지적 재산이지만, 모델 추출 공격(MEA)에 취약하다. MEA는 적들이 블랙 박스 쿼리를 통해 모델의 기능을 복제하는 공격이다.

Method: 우리는 현재의 워터마킹 기술의 한계를 극복하고, 결정 경계를 악용하여 끌림 제약을 회피하는 워터마킹 제거 공격(WRK)을 제안하고, 클래스 수준 아티팩트를 활용하여 회복력을 높이는 클래스-특징 워터마킹(CFW)을 제안한다.

Result: WRK는 기존 워터마킹 기준에서 최소 88.79%까지 워터마크 성공률을 감소시키며, CFW는 여러 도메인에서 이전 방법보다 일관되게 향상된 회복력을 보여준다.

Conclusion: CFW는 추출된 모델에서 최소 70.15%의 워터마크 성공률을 유지하며, MEA와 WRK 왜곡이 결합된 환경에서도 보호된 모델의 유용성을 보존한다.

Abstract: Machine learning models constitute valuable intellectual property, yet remain vulnerable to model extraction attacks (MEA), where adversaries replicate their functionality through black-box queries. Model watermarking counters MEAs by embedding forensic markers for ownership verification. Current black-box watermarks prioritize MEA survival through representation entanglement, yet inadequately explore resilience against sequential MEAs and removal attacks. Our study reveals that this risk is underestimated because existing removal methods are weakened by entanglement. To address this gap, we propose Watermark Removal attacK (WRK), which circumvents entanglement constraints by exploiting decision boundaries shaped by prevailing sample-level watermark artifacts. WRK effectively reduces watermark success rates by at least 88.79% across existing watermarking benchmarks.
  For robust protection, we propose Class-Feature Watermarks (CFW), which improve resilience by leveraging class-level artifacts. CFW constructs a synthetic class using out-of-domain samples, eliminating vulnerable decision boundaries between original domain samples and their artifact-modified counterparts (watermark samples). CFW concurrently optimizes both MEA transferability and post-MEA stability. Experiments across multiple domains show that CFW consistently outperforms prior methods in resilience, maintaining a watermark success rate of at least 70.15% in extracted models even under the combined MEA and WRK distortion, while preserving the utility of protected models.

</details>


### [47] [From LLMs to Agents: A Comparative Evaluation of LLMs and LLM-based Agents in Security Patch Detection](https://arxiv.org/abs/2511.08060)
*Junxiao Han,Zheng Yu,Lingfeng Bao,Jiakun Liu,Yao Wan,Jianwei Yin,Shuiguang Deng,Song Han*

Main category: cs.CR

TL;DR: 본 논문은 보안 패치 탐지에서 LLM과 LLM 기반 에이전트의 성능을 포괄적으로 평가하여, Data-Aug LLM이 가장 우수한 성능을 보이면서도 ReAct Agent가 가장 낮은 오탐률을 나타내는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: OSS의 채택 증가가 보안 위험을 초래하고 있으며, LLM과 LLM 기반 에이전트가 소프트웨어 보안 문제를 해결하는 능력을 보이는 반면, 보안 패치 탐지에서의 체계적인 평가가 부족하다.

Method: Plain LLM, Data-Aug LLM, ReAct Agent의 세 가지 방법을 통해 LLM과 LLM 기반 에이전트의 보안 패치 탐지 성능을 평가한다.

Result: Data-Aug LLM이 전체 성능에서 가장 좋고, ReAct Agent는 가장 낮은 오탐률을 보인다. 기존 기준 방법들은 높은 정확도를 보이나, 오탐률이 더 높다.

Conclusion: LLM과 LLM 기반 에이전트는 보안 패치 탐지에서 우수한 성능을 유지하면서 오탐률을 줄이는 데 효과적이다.

Abstract: The widespread adoption of open-source software (OSS) has accelerated software innovation but also increased security risks due to the rapid propagation of vulnerabilities and silent patch releases. In recent years, large language models (LLMs) and LLM-based agents have demonstrated remarkable capabilities in various software engineering (SE) tasks, enabling them to effectively address software security challenges such as vulnerability detection. However, systematic evaluation of the capabilities of LLMs and LLM-based agents in security patch detection remains limited. To bridge this gap, we conduct a comprehensive evaluation of the performance of LLMs and LLM-based agents for security patch detection. Specifically, we investigate three methods: Plain LLM (a single LLM with a system prompt), Data-Aug LLM (data augmentation based on the Plain LLM), and the ReAct Agent (leveraging the thought-action-observation mechanism). We also evaluate the performance of both commercial and open-source LLMs under these methods and compare these results with those of existing baselines. Furthermore, we analyze the detection performance of these methods across various vulnerability types, and examine the impact of different prompting strategies and context window sizes on the results. Our findings reveal that the Data-Aug LLM achieves the best overall performance, whereas the ReAct Agent demonstrates the lowest false positive rate (FPR). Although baseline methods exhibit strong accuracy, their false positive rates are significantly higher. In contrast, our evaluated methods achieve comparable accuracy while substantially reducing the FPR. These findings provide valuable insights into the practical applications of LLMs and LLM-based agents in security patch detection, highlighting their advantage in maintaining robust performance while minimizing false positive rates.

</details>


### [48] [Endpoint Security Agent: A Comprehensive Approach to Real-time System Monitoring and Threat Detection](https://arxiv.org/abs/2511.08352)
*Srihari R,Ayesha Taranum,Karthik,Mohammed Usman Hussain*

Main category: cs.CR

TL;DR: 이 논문은 Windows 엔드포인트의 실시간 모니터링 및 위협 탐지를 위한 모듈식 보안 솔루션을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 위협이 점점 더 복잡하고 빈번해짐에 따라 조직 보안을 위한 강력한 엔드포인트 보호가 필수적이다.

Method: 본 논문에서는 WMI 및 ETW와 같은 기본 도구를 활용하여 시스템 활동을 저수준에서 모니터링하고, 기계 학습 기반 탐지 엔진을 통해 악성 및 benign 활동의 라벨이 붙은 데이터셋을 학습시킨다.

Result: 다양한 공격 벡터를 높은 정확성과 효율성으로 탐지하는 데 유망한 결과를 보여준다.

Conclusion: 이 시스템은 표준화된 위협 분류를 위해 MITRE ATT&CK 프레임워크에 탐지 기술을 매핑하고, 경고 및 포렌식 분석을 위한 중앙 집중화된 인터페이스를 포함하여 확장성을 염두에 두고 설계되었다.

Abstract: As cyber threats continue to evolve in complexity and frequency, robust endpoint protection is essential for organizational security. This paper presents "Endpoint Security Agent: A Comprehensive Approach to Real-time System Monitoring and Threat Detection" a modular, real-time security solution for Windows endpoints. The agent leverages native tools like WMI and ETW for lowlevel monitoring of system activities such as process execution, registry modifications, and network behaviour. A machine learning-based detection engine, trained on labelled datasets of benign and malicious activity, enables accurate threat identification with minimal false positives. Detection techniques are mapped to the MITRE ATT&CK framework for standardized threat classification. Designed for extensibility, the system includes a centralized interface for alerting and forensic analysis. Preliminary evaluation shows promising results in detecting diverse attack vectors with high accuracy and efficiency.

</details>


### [49] [Why does weak-OOD help? A Further Step Towards Understanding Jailbreaking VLMs](https://arxiv.org/abs/2511.08367)
*Yuxuan Zhou,Yuzhao Peng,Yang Bai,Kuofeng Gao,Yihao Zhang,Yechao Zhang,Xun Chen,Tao Yu,Tao Dai,Shu-Tao Xia*

Main category: cs.CR

TL;DR: 대형 비전-언어 모델(VLMs)이 jailbreak 공격에 취약하며, 본 연구는 OOD 기반 VLM jailbreak 방법의 심층 이해를 발전시킨다.


<details>
  <summary>Details</summary>
Motivation: VLM의 안전 메커니즘을 우회할 수 있는 다양한 공격 전략이 개발되었으며, 그 중 OOD 기반의 jailbreak 방법이 주목받고 있다.

Method: 연구는 SI-Attack이라는 전형적인 OOD 기반의 jailbreak 방법을 대상으로 하여, 입력 의도 인식과 모델 거부 유발 간의 트레이드오프를 분석한다.

Result: 온건한 OOD 전략으로 생성된 jailbreak 샘플이 VLM의 안전 제약을 우회하는 데 있어 우수한 성능을 보인다.

Conclusion: VLM의 모델 사전 훈련과 정렬 과정의 불일치에서 비롯된 불일치를 이론적으로 논의하고, OCR 기능을 활용해 간단하지만 효과적인 VLM jailbreak 방법을 설계하였다.

Abstract: Large Vision-Language Models (VLMs) are susceptible to jailbreak attacks: researchers have developed a variety of attack strategies that can successfully bypass the safety mechanisms of VLMs. Among these approaches, jailbreak methods based on the Out-of-Distribution (OOD) strategy have garnered widespread attention due to their simplicity and effectiveness. This paper further advances the in-depth understanding of OOD-based VLM jailbreak methods. Experimental results demonstrate that jailbreak samples generated via mild OOD strategies exhibit superior performance in circumventing the safety constraints of VLMs--a phenomenon we define as ''weak-OOD''. To unravel the underlying causes of this phenomenon, this study takes SI-Attack, a typical OOD-based jailbreak method, as the research object. We attribute this phenomenon to a trade-off between two dominant factors: input intent perception and model refusal triggering. The inconsistency in how these two factors respond to OOD manipulations gives rise to this phenomenon. Furthermore, we provide a theoretical argument for the inevitability of such inconsistency from the perspective of discrepancies between model pre-training and alignment processes. Building on the above insights, we draw inspiration from optical character recognition (OCR) capability enhancement--a core task in the pre-training phase of mainstream VLMs. Leveraging this capability, we design a simple yet highly effective VLM jailbreak method, whose performance outperforms that of SOTA baselines.

</details>


### [50] [Blockly2Hooks: Smart Contracts for Everyone with the XRP Ledger and Google Blockly](https://arxiv.org/abs/2511.08403)
*Lucian Trestioreanu,Wazen Shbair,Flaviene Scheidt de Cristo,Radu State*

Main category: cs.CR

TL;DR: 이 논문에서는 Blockly2Hooks를 설계하고 개발하여 비전문가가 스마트 계약을 쉽게 배우고 기술을 채택할 수 있도록 돕는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 스마트 계약의 수요 증가로 인해 해당 분야의 전문 지식과 도구가 부족할 수 있으며, 보안, 사용성 및 비용 측면에서 광범위한 채택이 제한되고 있습니다.

Method: Blockly2Hooks는 시각적 프로그래밍 언어와 구글의 Blockly 라이브러리를 활용하여, 비전문가가 스마트 계약을 쉽게 배우고 사용할 수 있게 해주는 솔루션입니다.

Result: XRP 원장을 구체적인 사례로 들어, Blockly2Hooks는 비전문가들이 스마트 계약을 쉽게 학습하고 채택할 수 있도록 한다는 것을 입증했습니다.

Conclusion: 개발된 플랫폼의 테스트 결과, 스마트 계약 개발 학습이 더 원활해질 수 있을 것으로 기대됩니다.

Abstract: Recent technologies such as inter-ledger payments, non-fungible tokens, and smart contracts are all fruited from the ongoing development of Distributed Ledger Technologies. The foreseen trend is that they will play an increasingly visible role in daily life, which will have to be backed by appropriate operational resources. For example, due to increasing demand, smart contracts could soon face a shortage of knowledgeable users and tools to handle them in practice. Widespread smart contract adoption is currently limited by security, usability and costs aspects. Because of a steep learning curve, the handling of smart contracts is currently performed by specialised developers mainly, and most of the research effort is focusing on smart contract security, while other aspects like usability being somewhat neglected. Specific tools would lower the entry barrier, enabling interested non-experts to create smart contracts.
  In this paper we designed, developed and tested Blockly2Hooks, a solution towards filling this gap even in challenging scenarios such as when the smart contracts are written in an advanced language like C. With the XRP Ledger as a concrete working case, Blockly2Hooks helps interested non-experts from the community to learn smart contracts easily and adopt the technology, through leveraging well-proven teaching methodologies like Visual Programming Languages, and more specifically, the Blockly Visual Programming library from Google. The platform was developed and tested and the results are promising to make learning smart contract development smoother.

</details>


### [51] [QLCoder: A Query Synthesizer For Static Analysis of Security Vulnerabilities](https://arxiv.org/abs/2511.08462)
*Claire Wang,Ziyang Li,Saikat Dutta,Mayur Naik*

Main category: cs.CR

TL;DR: QLCoder는 CVE 메타데이터에서 직접 Security Query를 자동으로 생성하는 정적 분석 도구입니다.


<details>
  <summary>Details</summary>
Motivation: 정적 분석 도구가 보안 취약점을 탐지하는 데 효과적이지만, 쿼리 작성을 위한 전문 지식이 필요합니다. 이를 해결하기 위해 QLCoder를 개발했습니다.

Method: QLCoder는 CodeQL에서 쿼리를 자동 합성하고, LLM과 실행 피드백의 루프를 embed하며, 맞춤형 MCP 인터페이스를 통해 언어 서버 프로토콜과 RAG 데이터베이스와 상호작용합니다.

Result: QLCoder는 176개의 CVE를 평가해 53.4%의 CVE에서 취약한 버전만 탐지하는 올바른 쿼리를 합성했습니다.

Conclusion: QLCoder는 기존 도구보다 월등히 높은 정확도로 보안 쿼리를 생성합니다.

Abstract: Static analysis tools provide a powerful means to detect security vulnerabilities by specifying queries that encode vulnerable code patterns. However, writing such queries is challenging and requires diverse expertise in security and program analysis. To address this challenge, we present QLCoder - an agentic framework that automatically synthesizes queries in CodeQL, a powerful static analysis engine, directly from a given CVE metadata. QLCode embeds an LLM in a synthesis loop with execution feedback, while constraining its reasoning using a custom MCP interface that allows structured interaction with a Language Server Protocol (for syntax guidance) and a RAG database (for semantic retrieval of queries and documentation). This approach allows QLCoder to generate syntactically and semantically valid security queries. We evaluate QLCode on 176 existing CVEs across 111 Java projects. Building upon the Claude Code agent framework, QLCoder synthesizes correct queries that detect the CVE in the vulnerable but not in the patched versions for 53.4% of CVEs. In comparison, using only Claude Code synthesizes 10% correct queries.

</details>
