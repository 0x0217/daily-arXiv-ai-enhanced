<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 4]
- [cs.LG](#cs.LG) [Total: 20]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.CR](#cs.CR) [Total: 8]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets](https://arxiv.org/abs/2510.25779)
*Gagan Bansal,Wenyue Hua,Zezhou Huang,Adam Fourney,Amanda Swearngin,Will Epperson,Tyler Payne,Jake M. Hofman,Brendan Lucier,Chinmay Singh,Markus Mobius,Akshay Nambi,Archana Yadav,Kevin Gao,David M. Rothschild,Aleksandrs Slivkins,Daniel G. Goldstein,Hussein Mozannar,Nicole Immorlica,Maya Murad,Matthew Vogel,Subbarao Kambhampati,Eric Horvitz,Saleema Amershi*

Main category: cs.MA

TL;DR: LLM 에이전트가 사용자 대신 경제적 결정을 중재하는 상황에서, 이들이 어떻게 행동하는지를 이해하기 위해 두 가지 측면의 에이전틱 시장을 조사하고 Magentic-Marketplace라는 시뮬레이션 환경을 개발했다.


<details>
  <summary>Details</summary>
Motivation: 에이전트의 책임성과 사용자에게 제공하는 가치에 대한 질문을 해결하고, 실제 시장 조건에서 에이전트가 어떻게 행동하는지를 이해하기 위함.

Method: 소비자를 대표하는 도우미 에이전트와 경쟁 비즈니스를 대표하는 서비스 에이전트가 있는 이원적 에이전틱 시장을 조사하고, Assistants와 Services가 운영할 수 있는 Magentic-Marketplace라는 시뮬레이션 환경을 개발하였다.

Result: 프론티어 모델이 이상적인 검색 조건에서 최적 웰빙에 접근할 수 있지만, 규모가 커지면 성능이 급격히 저하되며, 모든 모델이 심각한 첫 제안 편향을 보인다.

Conclusion: 이런 발견은 시장 조건에 따라 행동이 어떻게 나타나는지를 드러내며, 공정하고 효율적인 에이전틱 시장 설계를 위한 정보를 제공한다.

Abstract: As LLM agents advance, they are increasingly mediating economic decisions,
ranging from product discovery to transactions, on behalf of users. Such
applications promise benefits but also raise many questions about agent
accountability and value for users. Addressing these questions requires
understanding how agents behave in realistic market conditions. However,
previous research has largely evaluated agents in constrained settings, such as
single-task marketplaces (e.g., negotiation) or structured two-agent
interactions. Real-world markets are fundamentally different: they require
agents to handle diverse economic activities and coordinate within large,
dynamic ecosystems where multiple agents with opaque behaviors may engage in
open-ended dialogues. To bridge this gap, we investigate two-sided agentic
marketplaces where Assistant agents represent consumers and Service agents
represent competing businesses. To study these interactions safely, we develop
Magentic-Marketplace -- a simulated environment where Assistants and Services
can operate. This environment enables us to study key market dynamics: the
utility agents achieve, behavioral biases, vulnerability to manipulation, and
how search mechanisms shape market outcomes. Our experiments show that frontier
models can approach optimal welfare -- but only under ideal search conditions.
Performance degrades sharply with scale, and all models exhibit severe
first-proposal bias, creating 10-30x advantages for response speed over
quality. These findings reveal how behaviors emerge across market conditions,
informing the design of fair and efficient agentic marketplaces.

</details>


### [2] [Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion](https://arxiv.org/abs/2510.25929)
*Ziyi Wang,Carmine Ventre,Maria Polukarov*

Main category: cs.MA

TL;DR: 이 논문은 시장 조성에서의 알고리즘적 담합을 연구하기 위해 계층적 다중 에이전트 강화 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: AI의 상호 작용이 시장에서 담합으로 이어질 것인지 여부를 이해하는 것이 중요합니다.

Method: 불확실한 환경에서 훈련된 자기 이익을 추구하는 시장 조성자와 세 명의 하위 에이전트를 포함하는 계층적 다중 에이전트 강화 학습 프레임워크를 사용합니다.

Result: Agent~B2는 제로섬 설정에서 지배적인 성능을 보이며, Agent~B$^ullet$는 다른 이익 추구 에이전트와 공존할 때 자기 이익 성향을 나타냅니다.

Conclusion: 적응형 인센티브 제어는 이질적 에이전트 환경에서 보다 지속 가능한 전략적 공존을 지원한다는 것을 나타냅니다.

Abstract: Algorithmic collusion has emerged as a central question in AI: Will the
interaction between different AI agents deployed in markets lead to collusion?
More generally, understanding how emergent behavior, be it a cartel or market
dominance from more advanced bots, affects the market overall is an important
research question.
  We propose a hierarchical multi-agent reinforcement learning framework to
study algorithmic collusion in market making. The framework includes a
self-interested market maker (Agent~A), which is trained in an uncertain
environment shaped by an adversary, and three bottom-layer competitors: the
self-interested Agent~B1 (whose objective is to maximize its own PnL), the
competitive Agent~B2 (whose objective is to minimize the PnL of its opponent),
and the hybrid Agent~B$^\star$, which can modulate between the behavior of the
other two. To analyze how these agents shape the behavior of each other and
affect market outcomes, we propose interaction-level metrics that quantify
behavioral asymmetry and system-level dynamics, while providing signals
potentially indicative of emergent interaction patterns.
  Experimental results show that Agent~B2 secures dominant performance in a
zero-sum setting against B1, aggressively capturing order flow while tightening
average spreads, thus improving market execution efficiency. In contrast,
Agent~B$^\star$ exhibits a self-interested inclination when co-existing with
other profit-seeking agents, securing dominant market share through adaptive
quoting, yet exerting a milder adverse impact on the rewards of Agents~A and B1
compared to B2. These findings suggest that adaptive incentive control supports
more sustainable strategic co-existence in heterogeneous agent environments and
offers a structured lens for evaluating behavioral design in algorithmic
trading systems.

</details>


### [3] [Stop Wasting Your Tokens: Towards Efficient Runtime Multi-Agent Systems](https://arxiv.org/abs/2510.26585)
*Fulin Lin,Shaowen Chen,Ruishan Fang,Hongwei Wang,Tao Lin*

Main category: cs.MA

TL;DR: Multi-Agent Systems(MAS)의 자율성 증가로 인한 비효율성을 해결하기 위해, SupervisorAgent라는 경량화된 모듈식 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: MAS의 복잡한 작업 수행 중 자율성 증가로 인해 발생하는 비효율성을 해결하고, 전통적인 사후 실패 귀속 방법 대신 능동적이고 실시간 개입이 필요하다.

Method: SupervisorAgent는 LLM-free 적응형 필터에 의해 작동되는 런타임 적응 감독 프레임워크로, 기본 에이전트의 구조에 변화를 주지 않고 오류를 수정하고 비효율적인 행동을 안내한다.

Result: SupervisorAgent는 GAIA 벤치마크에서 Smolagent 프레임워크의 토큰 소비를 평균 29.45% 줄이면서 성공률을 유지한다.

Conclusion: 추가 5개 벤치마크 및 여러 SoTA 기초 모델에서의 광범위한 실험 결과는 우리의 접근 방식의 광범위한 적용 가능성과 강 robustness를 검증한다.

Abstract: While Multi-Agent Systems (MAS) excel at complex tasks, their growing
autonomy with operational complexity often leads to critical inefficiencies,
such as excessive token consumption and failures arising from misinformation.
Existing methods primarily focus on post-hoc failure attribution, lacking
proactive, real-time interventions to enhance robustness and efficiency. To
this end, we introduce SupervisorAgent, a lightweight and modular framework for
runtime, adaptive supervision that operates without altering the base agent's
architecture. Triggered by an LLM-free adaptive filter, SupervisorAgent
intervenes at critical junctures to proactively correct errors, guide
inefficient behaviors, and purify observations. On the challenging GAIA
benchmark, SupervisorAgent reduces the token consumption of the Smolagent
framework by an average of 29.45% without compromising its success rate.
Extensive experiments across five additional benchmarks (math reasoning, code
generation, and question answering) and various SoTA foundation models validate
the broad applicability and robustness of our approach. The code is available
at https://github.com/LINs-lab/SupervisorAgent.

</details>


### [4] [A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation](https://arxiv.org/abs/2510.26740)
*Ashwin Kumar,William Yeoh*

Main category: cs.MA

TL;DR: GIFF는 공정한 다중 에이전트 자원 할당을 위한 새로운 접근 방식으로, 표준 가치 함수에서 공정한 의사 결정을 유추합니다.


<details>
  <summary>Details</summary>
Motivation: 자원 제약 상황에서 효율성을 최적화하는 에이전트는 종종 불공정한 결과를 생성합니다.

Method: 행동 가치(Q-) 함수를 활용하여 추가적인 훈련 없이 효율성과 공정성을 조화시킵니다.

Result: 다양한 분야에서 GIFF 프레임워크가 강력한 기준선을 일관되게 초과하는 성능을 보여주며, 공정한 정책을 발견할 수 있음을 입증합니다.

Conclusion: GIFF는 복잡한 다중 에이전트 시스템에서 더 공정한 결과를 도출하기 위한 강력한 프레임워크입니다.

Abstract: We introduce the General Incentives-based Framework for Fairness (GIFF), a
novel approach for fair multi-agent resource allocation that infers fair
decision-making from standard value functions. In resource-constrained
settings, agents optimizing for efficiency often create inequitable outcomes.
Our approach leverages the action-value (Q-)function to balance efficiency and
fairness without requiring additional training. Specifically, our method
computes a local fairness gain for each action and introduces a counterfactual
advantage correction term to discourage over-allocation to already well-off
agents. This approach is formalized within a centralized control setting, where
an arbitrator uses the GIFF-modified Q-values to solve an allocation problem.
  Empirical evaluations across diverse domains, including dynamic ridesharing,
homelessness prevention, and a complex job allocation task-demonstrate that our
framework consistently outperforms strong baselines and can discover
far-sighted, equitable policies. The framework's effectiveness is supported by
a theoretical foundation; we prove its fairness surrogate is a principled lower
bound on the true fairness improvement and that its trade-off parameter offers
monotonic tuning. Our findings establish GIFF as a robust and principled
framework for leveraging standard reinforcement learning components to achieve
more equitable outcomes in complex multi-agent systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Optimal Information Combining for Multi-Agent Systems Using Adaptive Bias Learning](https://arxiv.org/abs/2510.25793)
*Siavash M. Alamouti,Fay Arjomandi*

Main category: cs.LG

TL;DR: 이 논문에서는 환경 조건에 따라 달라지는 시스템적 편견이 현대 다중 요인 시스템의 성능 저하를 초래할 수 있음을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 다수의 요인 시스템이 직면한 성능 갭은 부정확한 환경 모니터링, 신뢰할 수 없는 재무 예측 및 인간의 판단 집계 실패로 이어질 수 있다.

Method: 시스템적 요소와 불가축적 요소로 편견을 분해하는 이론적 프레임워크를 개발하며, 관측 가능한 공변량을 바탕으로 편견 분산을 예측할 수 있는 비율로 학습 가능 비율을 도입한다.

Result: 학습 가능 비율에 따라 성능 개선의 한계가 존재하며, ABLOC 알고리즘은 편견 교정 변환을 반복적으로 학습하면서 최적 조합 가중치를 최적화해 이론적 경계에 수렴하도록 보장한다.

Conclusion: 학습 가능 비율이 높은 시스템은 이론적 최대 개선의 40%-70% 성능 회복이 가능하고, 낮은 경우에는 최소한의 이익을 보여준다.

Abstract: Modern multi-agent systems ranging from sensor networks monitoring critical
infrastructure to crowdsourcing platforms aggregating human intelligence can
suffer significant performance degradation due to systematic biases that vary
with environmental conditions. Current approaches either ignore these biases,
leading to suboptimal decisions, or require expensive calibration procedures
that are often infeasible in practice. This performance gap has real
consequences: inaccurate environmental monitoring, unreliable financial
predictions, and flawed aggregation of human judgments. This paper addresses
the fundamental question: when can we learn and correct for these unknown
biases to recover near-optimal performance, and when is such learning futile?
We develop a theoretical framework that decomposes biases into learnable
systematic components and irreducible stochastic components, introducing the
concept of learnability ratio as the fraction of bias variance predictable from
observable covariates. This ratio determines whether bias learning is
worthwhile for a given system. We prove that the achievable performance
improvement is fundamentally bounded by this learnability ratio, providing
system designers with quantitative guidance on when to invest in bias learning
versus simpler approaches. We present the Adaptive Bias Learning and Optimal
Combining (ABLOC) algorithm, which iteratively learns bias-correcting
transformations while optimizing combination weights through closedform
solutions, guaranteeing convergence to these theoretical bounds. Experimental
validation demonstrates that systems with high learnability ratios can recover
significant performance (we achieved 40%-70% of theoretical maximum improvement
in our examples), while those with low learnability show minimal benefit,
validating our diagnostic criteria for practical deployment decisions.

</details>


### [6] [Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing](https://arxiv.org/abs/2510.26089)
*Fazel Arasteh,Arian Haghparast,Manos Papagelis*

Main category: cs.LG

TL;DR: 도시 도로 네트워크의 교통 혼잡은 여행 시간을 늘리고 배출량을 증가시키며, 특히 혼잡 시간대에 문제가 된다. 본 연구는 다중 에이전트 강화 학습(MARL) 프레임워크를 통해 동적 차량 라우팅을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 도시에서의 교통 혼잡 문제 해결과 효율적인 차량 네비게이션의 필요성 때문이다.

Method: 분산형 MARL 모델인 적응형 내비게이션(AN)을 제안하고, 대규모 네트워크를 위한 계층적 허브 기반 적응형 내비게이션(HHAN)으로 확장하여 주요 교차로에만 에이전트를 할당한다.

Result: AN은 SPF와 학습 기준에 비해 평균 여행 시간을 단축하고, HHAN은 수백 개의 교차로를 가진 네트워크에서 최대 15.9% 향상을 달성하였다.

Conclusion: 본 연구는 지능형 교통 시스템에서 조정 가능하고 혼잡에 인지된 라우팅을 위한 네트워크 제약 MARL의 잠재력을 강조한다.

Abstract: Traffic congestion in urban road networks leads to longer trip times and
higher emissions, especially during peak periods. While the Shortest Path First
(SPF) algorithm is optimal for a single vehicle in a static network, it
performs poorly in dynamic, multi-vehicle settings, often worsening congestion
by routing all vehicles along identical paths. We address dynamic vehicle
routing through a multi-agent reinforcement learning (MARL) framework for
coordinated, network-aware fleet navigation. We first propose Adaptive
Navigation (AN), a decentralized MARL model where each intersection agent
provides routing guidance based on (i) local traffic and (ii) neighborhood
state modeled using Graph Attention Networks (GAT). To improve scalability in
large networks, we further propose Hierarchical Hub-based Adaptive Navigation
(HHAN), an extension of AN that assigns agents only to key intersections
(hubs). Vehicles are routed hub-to-hub under agent control, while SPF handles
micro-routing within each hub region. For hub coordination, HHAN adopts
centralized training with decentralized execution (CTDE) under the Attentive
Q-Mixing (A-QMIX) framework, which aggregates asynchronous vehicle decisions
via attention. Hub agents use flow-aware state features that combine local
congestion and predictive dynamics for proactive routing. Experiments on
synthetic grids and real urban maps (Toronto, Manhattan) show that AN reduces
average travel time versus SPF and learning baselines, maintaining 100% routing
success. HHAN scales to networks with hundreds of intersections, achieving up
to 15.9% improvement under heavy traffic. These findings highlight the
potential of network-constrained MARL for scalable, coordinated, and
congestion-aware routing in intelligent transportation systems.

</details>


### [7] [PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs](https://arxiv.org/abs/2510.25808)
*Jaewon Chu,Seunghun Lee,Hyunwoo J. Kim*

Main category: cs.LG

TL;DR: PRESTO는 소프트 프롬프트의 프리이미지 구조를 활용하여 블랙박스 대형 언어 모델에 대한 효율적인 최적화를 달성하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 블랙박스 대형 언어 모델의 내부 파라미터에 접근할 수 없지만 뛰어난 성능으로 인해 최적화된 지시문에 대한 관심이 증가하고 있다.

Method: PRESTO는 소프트 프롬프트의 프리이미지 구조를 활용하는 세 가지 주요 구성 요소로 구성된다: (1) 점수 공유, (2) 프리이미지 기반 초기화, (3) 점수 일관성 정규화.

Result: PRESTO는 동일한 쿼리 예산 하에 14배 더 많은 점수 데이터 획득 효과를 보여주어 최적화의 효율성을 개선하였다.

Conclusion: 33개 지시문 최적화 작업에 대한 실험 결과 PRESTO의 우수한 성능이 입증되었다.

Abstract: Large language models (LLMs) have achieved remarkable success across diverse
domains, due to their strong instruction-following capabilities. This has led
to increasing interest in optimizing instructions for black-box LLMs, whose
internal parameters are inaccessible but widely used due to their strong
performance. To optimize instructions for black-box LLMs, recent methods employ
white-box LLMs to generate candidate instructions from optimized soft prompts.
However, white-box LLMs often map different soft prompts to the same
instruction, leading to redundant queries. While previous studies regarded this
many-to-one mapping as a structure that hinders optimization efficiency, we
reinterpret it as a useful prior knowledge that can accelerate the
optimization. To this end, we introduce PREimage-informed inSTruction
Optimization (PRESTO), a novel framework that leverages the preimage structure
of soft prompts for efficient optimization. PRESTO consists of three key
components: (1) score sharing, which shares the evaluation score with all soft
prompts in a preimage; (2) preimage-based initialization, which selects initial
data points that maximize search space coverage using preimage information; and
(3) score consistency regularization, which enforces prediction consistency
within each preimage. By leveraging preimages, PRESTO achieves the effect of
effectively obtaining 14 times more scored data under the same query budget,
resulting in more efficient optimization. Experimental results on 33
instruction optimization tasks demonstrate the superior performance of PRESTO.
Code is available at https://github.com/mlvlab/PRESTO

</details>


### [8] [Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.26389)
*Wenchang Duan,Yaoliang Yu,Jiwan He,Yi Shi*

Main category: cs.LG

TL;DR: 본 논문은 적응적이고 효과적인 맥락 정보를 얻기 위해 새로운 다중 에이전트 강화 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습이 장기 의존성 및 비마르코프 환경과 같은 어려운 작업을 해결하는 데 유망한 성능을 보여주고 있기 때문입니다.

Method: 중앙 에이전트를 설계하여 시간적 그래디언트 분석을 통해 맥락 길이를 동적으로 최적화하는 방법을 사용합니다.

Result: 제안된 방법이 PettingZoo, MiniGrid, Google Research Football (GRF), StarCraft Multi-Agent Challenge v2 (SMACv2)와 같은 장기 의존성 작업에서 최첨단 성능을 달성합니다.

Conclusion: 제안된 방법은 다중 에이전트 강화 학습 환경의 효과적이고 효율적인 표현을 제공합니다.

Abstract: Recently, deep multi-agent reinforcement learning (MARL) has demonstrated
promising performance for solving challenging tasks, such as long-term
dependencies and non-Markovian environments. Its success is partly attributed
to conditioning policies on large fixed context length. However, such large
fixed context lengths may lead to limited exploration efficiency and redundant
information. In this paper, we propose a novel MARL framework to obtain
adaptive and effective contextual information. Specifically, we design a
central agent that dynamically optimizes context length via temporal gradient
analysis, enhancing exploration to facilitate convergence to global optima in
MARL. Furthermore, to enhance the adaptive optimization capability of the
context length, we present an efficient input representation for the central
agent, which effectively filters redundant information. By leveraging a
Fourier-based low-frequency truncation method, we extract global temporal
trends across decentralized agents, providing an effective and efficient
representation of the MARL environment. Extensive experiments demonstrate that
the proposed method achieves state-of-the-art (SOTA) performance on long-term
dependency tasks, including PettingZoo, MiniGrid, Google Research Football
(GRF), and StarCraft Multi-Agent Challenge v2 (SMACv2).

</details>


### [9] [MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs](https://arxiv.org/abs/2510.25867)
*Xiaoke Huang,Ningsen Wang,Hui Liu,Xianfeng Tang,Yuyin Zhou*

Main category: cs.LG

TL;DR: 이 논문은 MedVLSynther라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 공개 생물 의학 문헌에서 직접 고품질의 다중 선택 VQA 항목을 합성하여 의료 질문을 해결하는 데 도움을 줍니다.


<details>
  <summary>Details</summary>
Motivation: 전문적인 의료 VQA 시스템 구축이 필요한데, 이를 위한 고품질의 오픈 데이터셋이 부족합니다.

Method: MedVLSynther는 고품질의 VQA 항목을 생성하는 생략 및 검증 프레임워크로, 이미지, 캡션 및 인용에 따라 생성합니다.

Result: PubMed Central을 활용하여 13,087개의 검증된 질문과 14,803개의 이미지를 포함한 MedSynVQA를 생성하였습니다.

Conclusion: MedVLSynther는 공개 문헌과 공개 가중치 모델을 사용하여 감사 가능하고 재현 가능한 의료 VQA 교육 데이터를 제공하는 방법을 제시합니다.

Abstract: Large Multimodal Models (LMMs) are increasingly capable of answering medical
questions that require joint reasoning over images and text, yet training
general medical VQA systems is impeded by the lack of large, openly usable,
high-quality corpora. We present MedVLSynther, a rubric-guided
generator-verifier framework that synthesizes high-quality multiple-choice VQA
items directly from open biomedical literature by conditioning on figures,
captions, and in-text references. The generator produces self-contained stems
and parallel, mutually exclusive options under a machine-checkable JSON schema;
a multi-stage verifier enforces essential gates (self-containment, single
correct answer, clinical validity, image-text consistency), awards fine-grained
positive points, and penalizes common failure modes before acceptance. Applying
this pipeline to PubMed Central yields MedSynVQA: 13,087 audited questions over
14,803 images spanning 13 imaging modalities and 28 anatomical regions.
Training open-weight LMMs with reinforcement learning using verifiable rewards
improves accuracy across six medical VQA benchmarks, achieving averages of
55.85 (3B) and 58.15 (7B), with up to 77.57 on VQA-RAD and 67.76 on PathVQA,
outperforming strong medical LMMs. A Ablations verify that both generation and
verification are necessary and that more verified data consistently helps, and
a targeted contamination analysis detects no leakage from evaluation suites. By
operating entirely on open literature and open-weight models, MedVLSynther
offers an auditable, reproducible, and privacy-preserving path to scalable
medical VQA training data.

</details>


### [10] [$π_\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action Models](https://arxiv.org/abs/2510.25889)
*Kang Chen,Zhihao Liu,Tonghe Zhang,Zhen Guo,Si Xu,Hao Lin,Hongzhi Zang,Quanlu Zhang,Zhaofei Yu,Guoliang Fan,Tiejun Huang,Yu Wang,Chao Yu*

Main category: cs.LG

TL;DR: $	ext{VLA}$ 모델은 로봇이 복잡한 작업을 이해하고 수행하도록 돕는 데 사용됩니다. 이 논문에서는 대규모 $	ext{RL}$ 적용의 어려움을 해결하기 위해 $	ext{pi}_{	ext{RL}}$라는 오픈소스 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 로봇이 복잡한 작업을 수행하는 데 있어 상이한 입력을 이해해야 하며, 이를 위해 강화 학습을 활용하여 데이터 수집 과정을 자동화하려는 필요가 있습니다.

Method: $	ext{pi}_{	ext{RL}}$는 흐름 기반 $	ext{VLA}$를 훈련하기 위한 두 가지 방식을 구현합니다: (1) {Flow-Noise}는 노이즈 프로세스를 학습 가능한 노이즈 네트워크로 모델링합니다. (2) {Flow-SDE}는 에이전트와 환경 상호작용을 통합하여 효율적인 $	ext{RL}$ 탐색을 위해 ODE를 SDE로 변환합니다.

Result: LIBERO와 ManiSkill 벤치마크에서 높은 성능 향상을 보였습니다. LIBERO에서 $	ext{pi}_{	ext{RL}}$는 모델 $	ext{pi}_{0}$의 성능을 57.6%에서 97.6%로, $	ext{pi}_{0.5}$는 77.1%에서 98.3%로 향상시켰습니다. ManiSkill에서는 320개 병렬 환경에서 $	ext{pi}_{	ext{RL}}$를 훈련하여 여러 작업에서 성능을 개선했습니다.

Conclusion: $	ext{pi}_{	ext{RL}}$는 SFT 모델에 비해 상당한 성능 향상과 일반화 능력을 입증하며 흐름 기반 $	ext{VLA}$에 대한 온라인 $	ext{RL}$의 효과를 검증합니다.

Abstract: Vision-Language-Action (VLA) models enable robots to understand and perform
complex tasks from multimodal input. Although recent work explores using
reinforcement learning (RL) to automate the laborious data collection process
in scaling supervised fine-tuning (SFT), applying large-scale RL to flow-based
VLAs (e.g., $\pi_0$, $\pi_{0.5}$) remains challenging due to intractable action
log-likelihoods from iterative denoising.
  We address this challenge with $\pi_{\text{RL}}$, an open-source framework
for training flow-based VLAs in parallel simulation. $\pi_{\text{RL}}$
implements two RL algorithms: (1) {Flow-Noise} models the denoising process as
a discrete-time MDP with a learnable noise network for exact log-likelihood
computation. (2) {Flow-SDE} integrates denoising with agent-environment
interaction, formulating a two-layer MDP that employs ODE-to-SDE conversion for
efficient RL exploration.
  We evaluate $\pi_{\text{RL}}$ on LIBERO and ManiSkill benchmarks. On LIBERO,
$\pi_{\text{RL}}$ boosts few-shot SFT models $\pi_0$ and $\pi_{0.5}$ from 57.6%
to 97.6% and from 77.1% to 98.3%, respectively. In ManiSkill, we train
$\pi_{\text{RL}}$ in 320 parallel environments, improving $\pi_0$ from 41.6% to
85.7% and $\pi_{0.5}$ from 40.0% to 84.8% across 4352 pick-and-place tasks,
demonstrating scalable multitask RL under heterogeneous simulation.
  Overall, $\pi_{\text{RL}}$ achieves significant performance gains and
stronger generalization over SFT-models, validating the effectiveness of online
RL for flow-based VLAs.

</details>


### [11] [Modular Linear Tokenization (MLT)](https://arxiv.org/abs/2510.25952)
*Tcharlies Schmitz*

Main category: cs.LG

TL;DR: 이 논문은 고차원 범주형 식별자를 압축된 수치 벡터로 인코딩하는 가역적이고 결정론적인 기술인 모듈러 선형 토크나이제이션(MLT)을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 고차원 범주형 데이터의 효율적인 표현 방법을 찾기 위함이다.

Method: MLT는 유한체에 대한 모듈러 산술과 가역 선형 변환을 활용하여 전단사 매핑을 보존하면서 수치 벡터로 인코딩한다.

Result: MLT는 MovieLens 20M 데이터셋에서 감독 학습 임베딩과 유사한 예측 성능을 보이며, 필요한 매개변수가 적고 훈련 비용이 낮다.

Conclusion: MLT는 고차원 범주형 데이터의 인코딩을 위한 효과적인 대안이며, 오픈 소스 구현이 제공된다.

Abstract: This paper introduces Modular Linear Tokenization (MLT), a reversible and
deterministic technique for encoding high-cardinality categorical identifiers
into compact numerical vectors. Unlike traditional hashing or one-hot
encodings, MLT preserves bijective mappings by leveraging modular arithmetic
over finite fields and invertible linear transformations. The method offers
explicit control of dimensionality and computational scalability while
maintaining full reversibility, even for millions of identifiers. Experimental
results on the MovieLens 20M dataset show that MLT achieves comparable
predictive performance to supervised embeddings while requiring significantly
fewer parameters and lower training cost. An open-source implementation of MLT
is available on PyPI (https://pypi.org/project/light-mlt/) and GitHub
(https://github.com/tcharliesschmitz/light-mlt).

</details>


### [12] [Efficient Online Learning with Predictive Coding Networks: Exploiting Temporal Correlations](https://arxiv.org/abs/2510.25993)
*Darius Masoum Zadeh-Jousdani,Elvin Hajizada,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: PCN-TA는 언덕(엘지) 작업 환경에서 로봇 시스템을 위한 효율적인 온라인 학습 알고리즘을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 로봇 시스템이 변화하는 환경에 지속적으로 적응할 수 있는 효율적인 온라인 학습 알고리즘이 필요하다.

Method: Temporal Amortization을 활용한 Predictive Coding Network (PCN-TA)를 제안한다.

Result: PCN-TA는 백프로파게이션에 비해 10% 적은 가중치 업데이트를 달성하고, 기본 PC 네트워크보다 50% 적은 추론 단계를 요구한다.

Conclusion: PCN-TA는 자원 제약이 있는 로봇 시스템에서의 가장자리 배치 및 실시간 적응 지원을 위한 계산 오버헤드를 줄이는 데 기여한다.

Abstract: Robotic systems operating at the edge require efficient online learning
algorithms that can continuously adapt to changing environments while
processing streaming sensory data. Traditional backpropagation, while
effective, conflicts with biological plausibility principles and may be
suboptimal for continuous adaptation scenarios. The Predictive Coding (PC)
framework offers a biologically plausible alternative with local, Hebbian-like
update rules, making it suitable for neuromorphic hardware implementation.
However, PC's main limitation is its computational overhead due to multiple
inference iterations during training. We present Predictive Coding Network with
Temporal Amortization (PCN-TA), which preserves latent states across temporal
frames. By leveraging temporal correlations, PCN-TA significantly reduces
computational demands while maintaining learning performance. Our experiments
on the COIL-20 robotic perception dataset demonstrate that PCN-TA achieves 10%
fewer weight updates compared to backpropagation and requires 50% fewer
inference steps than baseline PC networks. These efficiency gains directly
translate to reduced computational overhead for moving another step toward edge
deployment and real-time adaptation support in resource-constrained robotic
systems. The biologically-inspired nature of our approach also makes it a
promising candidate for future neuromorphic hardware implementations, enabling
efficient online learning at the edge.

</details>


### [13] [New Money: A Systematic Review of Synthetic Data Generation for Finance](https://arxiv.org/abs/2510.26076)
*James Meldrum,Basem Suleiman,Fethi Rabhi,Muhammad Johan Alibasa*

Main category: cs.LG

TL;DR: 합성 데이터 생성은 민감한 금융 데이터를 사용한 머신 러닝 애플리케이션의 문제를 해결하는 유망한 접근 방식으로 부상하였다. 본 체계적 리뷰는 2018년 이후의 72개의 연구를 분석하고, GAN 기반 접근법이 문헌에서 우세함을 밝혀내며, 향후 연구를 위한 방향성을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 합성 데이터 생성은 민감한 금융 데이터를 안전하게 사용하는 데 도움을 주기 위해 중요한 역할을 한다.

Method: 72개의 연구를 체계적으로 리뷰하고, 합성된 금융 데이터의 종류, 사용된 생성 방법, 데이터 유용성 및 개인정보 보호를 평가하는 전략을 분류하였다.

Result: GAN 기반 접근법이 주로 사용되며, 특히 시계열 시장 데이터와 표형 신용 데이터 생성에 논문들이 집중되어 있다. 여러 혁신적인 기술이 있지만, 개인정보 보호에 대한 엄격한 평가가 부족하다.

Conclusion: 이번 리뷰는 생성 기술, 응용 프로그램 및 평가 방법에 대한 통합된 개요를 제공하며, 향후 연구의 방향을 제시한다.

Abstract: Synthetic data generation has emerged as a promising approach to address the
challenges of using sensitive financial data in machine learning applications.
By leveraging generative models, such as Generative Adversarial Networks (GANs)
and Variational Autoencoders (VAEs), it is possible to create artificial
datasets that preserve the statistical properties of real financial records
while mitigating privacy risks and regulatory constraints. Despite the rapid
growth of this field, a comprehensive synthesis of the current research
landscape has been lacking. This systematic review consolidates and analyses 72
studies published since 2018 that focus on synthetic financial data generation.
We categorise the types of financial information synthesised, the generative
methods employed, and the evaluation strategies used to assess data utility and
privacy. The findings indicate that GAN-based approaches dominate the
literature, particularly for generating time-series market data and tabular
credit data. While several innovative techniques demonstrate potential for
improved realism and privacy preservation, there remains a notable lack of
rigorous evaluation of privacy safeguards across studies. By providing an
integrated overview of generative techniques, applications, and evaluation
methods, this review highlights critical research gaps and offers guidance for
future work aimed at developing robust, privacy-preserving synthetic data
solutions for the financial domain.

</details>


### [14] [Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism](https://arxiv.org/abs/2510.26083)
*Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou*

Main category: cs.LG

TL;DR: 전문가 수준의 성능을 유지하면서 폭넓은 능력을 가진 Specialized Generalist Models(SGM)을 제안한다. 이 모델은 작업 정보에 의해 안내되는 전문 메모리 메커니즘을 사용한다.


<details>
  <summary>Details</summary>
Motivation: SGM은 광범위한 능력을 보존하면서도 특정 도메인에서 전문가 수준의 성능을 달성하는 것을 목표로 한다.

Method: Nirvana라는 SGM을 제시하며, 전문 메모리 메커니즘, 선형 시간 복잡성 및 테스트 중 작업 정보 추출 기능을 포함한다. Task-Aware Memory Trigger(Trigger)를 제안하여 현재 작업의 요구 사항에 따라 메모리 메커니즘을 유연하게 조정한다.

Result: Nirvana는 다양한 자연어 모델링 벤치마크에서 기존 LLM 구조에 비해 경쟁력 있거나 우수한 결과를 달성하며, Magnetic Resonance Imaging(MRI)과 같은 어려운 의료 작업에서도 성능을 검증한다.

Conclusion: Nirvana는 전통적인 MRI 모델 및 전통적인 LLM의 백본을 가진 모델에 비해 더 높은 품질의 MRI 재구성을 달성하고, 정확한 초기 임상 보고서를 생성할 수 있다.

Abstract: Specialized Generalist Models (SGMs) aim to preserve broad capabilities while
achieving expert-level performance in target domains. However, traditional LLM
structures including Transformer, Linear Attention, and hybrid models do not
employ specialized memory mechanism guided by task information. In this paper,
we present Nirvana, an SGM with specialized memory mechanism, linear time
complexity, and test-time task information extraction. Besides, we propose the
Task-Aware Memory Trigger ($\textit{Trigger}$) that flexibly adjusts memory
mechanism based on the current task's requirements. In Trigger, each incoming
sample is treated as a self-supervised fine-tuning task, enabling Nirvana to
adapt its task-related parameters on the fly to domain shifts. We also design
the Specialized Memory Updater ($\textit{Updater}$) that dynamically memorizes
the context guided by Trigger. We conduct experiments on both general language
tasks and specialized medical tasks. On a variety of natural language modeling
benchmarks, Nirvana achieves competitive or superior results compared to the
existing LLM structures. To prove the effectiveness of Trigger on specialized
tasks, we test Nirvana's performance on a challenging medical task, i.e.,
Magnetic Resonance Imaging (MRI). We post-train frozen Nirvana backbone with
lightweight codecs on paired electromagnetic signals and MRI images. Despite
the frozen Nirvana backbone, Trigger guides the model to adapt to the MRI
domain with the change of task-related parameters. Nirvana achieves
higher-quality MRI reconstruction compared to conventional MRI models as well
as the models with traditional LLMs' backbone, and can also generate accurate
preliminary clinical reports accordingly.

</details>


### [15] [SAFE: A Novel Approach to AI Weather Evaluation through Stratified Assessments of Forecasts over Earth](https://arxiv.org/abs/2510.26099)
*Nick Masi,Randall Balestriero*

Main category: cs.LG

TL;DR: SAFE 패키지는 다양한 속성에 따른 예측 성과를 계층적으로 평가할 수 있도록 해준다.


<details>
  <summary>Details</summary>
Motivation: 기존 기계 학습의 성능 평가는 샘플의 평균 손실에 근거하여 이루어지나, 이는 지리적 분포의 비균일성을 고려하지 않는다.

Method: SAFE는 지리적 그리드 포인트와 관련된 다양한 속성(영토, 글로벌 하위 지역, 소득, 토지 피복)에 따라 예측의 성과를 계층적으로 분석할 수 있도록 한다.

Result: 최신 AI 기반 기후 예측 모델들을 평가한 결과, 모든 모델이 속성별로 예측 능력에서 차이를 보였다.

Conclusion: SAFE를 통해 모델의 성과를 지역별로 분석함으로써, 각 모델의 공정성을 비교할 수 있는 새로운 기준을 마련하였다.

Abstract: The dominant paradigm in machine learning is to assess model performance
based on average loss across all samples in some test set. This amounts to
averaging performance geospatially across the Earth in weather and climate
settings, failing to account for the non-uniform distribution of human
development and geography. We introduce Stratified Assessments of Forecasts
over Earth (SAFE), a package for elucidating the stratified performance of a
set of predictions made over Earth. SAFE integrates various data domains to
stratify by different attributes associated with geospatial gridpoints:
territory (usually country), global subregion, income, and landcover (land or
water). This allows us to examine the performance of models for each individual
stratum of the different attributes (e.g., the accuracy in every individual
country). To demonstrate its importance, we utilize SAFE to benchmark a zoo of
state-of-the-art AI-based weather prediction models, finding that they all
exhibit disparities in forecasting skill across every attribute. We use this to
seed a benchmark of model forecast fairness through stratification at different
lead times for various climatic variables. By moving beyond globally-averaged
metrics, we for the first time ask: where do models perform best or worst, and
which models are most fair? To support further work in this direction, the SAFE
package is open source and available at https://github.com/N-Masi/safe

</details>


### [16] [Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error](https://arxiv.org/abs/2510.26109)
*Chenming Tang,Hsiu-Yuan Huang,Weijie Liu,Saiyong Yang,Yunfang Wu*

Main category: cs.LG

TL;DR: RLVR에 기반한 LTE 접근법은 LLM의 탐색 정체 문제를 해결하고 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: RLVR은 LLM의 추론 능력을 크게 향상시켰지만 기존 접근법은 LLM의 초기 능력에 제한되어 있습니다.

Method: LTE는 LLM이 이전에 생성한 잘못된 답변과 과도한 응답 문제를 이용하여 외부 전문가의 지침 없이 학습하도록 합니다.

Result: LTE는 Qwen3-4B-Base의 6개의 수학 벤치마크에서 Pass@1에서 6.38, Pass@k에서 9.00의 성능 향상을 보였습니다.

Conclusion: LTE는 탐색 정체 문제를 완화하고 훈련 중 착취와 탐색을 모두 개선합니다.

Abstract: Reinforcement learning with verifiable rewards (RLVR) has significantly
boosted the reasoning capability of large language models (LLMs) recently.
However, existing RLVR approaches merely train LLMs based on their own
generated responses and are constrained by the initial capability of LLMs, thus
prone to exploration stagnation, in which LLMs fail to solve more training
problems and cannot further learn from the training data. Some work tries to
address this by leveraging off-policy solutions to training problems but
requires external guidance from experts which suffers from limited
availability. In this work, we propose LTE (Learning to reason from Trial and
Error), an approach hinting LLMs with their previously self-generated incorrect
answers and problem of overlong responses, which does not require any external
expert guidance. Experiments validate the effectiveness of LTE, which
outperforms the normal group relative policy optimization (GRPO) by 6.38 in
Pass@1 and 9.00 in Pass@k on average across six mathematics benchmarks for
Qwen3-4B-Base. Further analysis confirms that LTE successfully mitigates the
problem of exploration stagnation and enhances both exploitation and
exploration during training.

</details>


### [17] [Empirical Bayesian Multi-Bandit Learning](https://arxiv.org/abs/2510.26284)
*Xia Jiang,Rong J. B. Zhu*

Main category: cs.LG

TL;DR: 이 연구는 다중 작업 학습을 위한 새로운 계층적 베이지안 프레임워크를 제안하여 관련 작업 간의 의사 결정을 개선하는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 다중 작업 학습이 관련 작업에서 의사 결정을 향상시킬 수 있는 잠재력으로 인해 중요한 연구 관심을 받고 있다.

Method: 계층적 베이지안 모델을 통해 다양한 밴디트 인스턴스의 이질성과 상관관계를 포착하고, 이를 통해 효과적인 정보 공유를 가능하게 한다.

Result: 제안된 알고리즘의 빈도론적 후회 상한을 제공하고, 합성 및 실제 데이터셋에 대한 광범위한 실험을 통해 우수한 성능을 보여준다.

Conclusion: 다중 작업 간 조화를 이루며 탐색과 활용의 균형을 유지하는 데 효과적이다.

Abstract: Multi-task learning in contextual bandits has attracted significant research
interest due to its potential to enhance decision-making across multiple
related tasks by leveraging shared structures and task-specific heterogeneity.
In this article, we propose a novel hierarchical Bayesian framework for
learning in various bandit instances. This framework captures both the
heterogeneity and the correlations among different bandit instances through a
hierarchical Bayesian model, enabling effective information sharing while
accommodating instance-specific variations. Unlike previous methods that
overlook the learning of the covariance structure across bandits, we introduce
an empirical Bayesian approach to estimate the covariance matrix of the prior
distribution.This enhances both the practicality and flexibility of learning
across multi-bandits. Building on this approach, we develop two efficient
algorithms: ebmTS (Empirical Bayesian Multi-Bandit Thompson Sampling) and
ebmUCB (Empirical Bayesian Multi-Bandit Upper Confidence Bound), both of which
incorporate the estimated prior into the decision-making process. We provide
the frequentist regret upper bounds for the proposed algorithms, thereby
filling a research gap in the field of multi-bandit problems. Extensive
experiments on both synthetic and real-world datasets demonstrate the superior
performance of our algorithms, particularly in complex environments. Our
methods achieve lower cumulative regret compared to existing techniques,
highlighting their effectiveness in balancing exploration and exploitation
across multi-bandits.

</details>


### [18] [Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt Injections](https://arxiv.org/abs/2510.26328)
*David Schmotz,Sahar Abdelnabi,Maksym Andriushchenko*

Main category: cs.LG

TL;DR: 이 논문은 LLM에서의 지속적 학습을 위한 새로운 접근 방식을 제안하지만, Agent Skills가 보안 취약점이 있음을 지적한다.


<details>
  <summary>Details</summary>
Motivation: LLM에서의 지속적 학습을 가능하게 하는 것은 해결되지 않은 중요한 연구 과제이다.

Method: Agent Skills 프레임워크를 소개하고, 악의적인 지시를 숨기는 방법을 시연한다.

Result: Agent Skills이 취약하며, 시스템 레벨의 가드를 우회할 수 있음을 보여준다.

Conclusion: 최전선 LLM이 현실적인 시나리오에서 매우 간단한 프롬프트 주입에 여전히 취약하다고 결론지었다.

Abstract: Enabling continual learning in LLMs remains a key unresolved research
challenge. In a recent announcement, a frontier LLM company made a step towards
this by introducing Agent Skills, a framework that equips agents with new
knowledge based on instructions stored in simple markdown files. Although Agent
Skills can be a very useful tool, we show that they are fundamentally insecure,
since they enable trivially simple prompt injections. We demonstrate how to
hide malicious instructions in long Agent Skill files and referenced scripts to
exfiltrate sensitive data, such as internal files or passwords. Importantly, we
show how to bypass system-level guardrails of a popular coding agent: a benign,
task-specific approval with the "Don't ask again" option can carry over to
closely related but harmful actions. Overall, we conclude that despite ongoing
research efforts and scaling model capabilities, frontier LLMs remain
vulnerable to very simple prompt injections in realistic scenarios. Our code is
available at https://github.com/aisa-group/promptinject-agent-skills.

</details>


### [19] [Efficient Generative AI Boosts Probabilistic Forecasting of Sudden Stratospheric Warmings](https://arxiv.org/abs/2510.26376)
*Ningning Tao,Fei Xie,Baoxiang Pan,Hongyu Wang,Han Huang,Zhongpu Qiu,Ke Gui,Jiali Luo,Xiaosong Chen*

Main category: cs.LG

TL;DR: 본 연구는 급격한 성층권 온난화(SSWs)에 대한 효율적이고 능숙한 확률적 예측을 위한 생성적 AI 모델(FM-Cast)을 개발하여, 예측의 정확성을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: 급격한 성층권 온난화(SSWs)는 하위 계절 예측 가능성의 주요 원천 및 극한 겨울 날씨의 주요 요인이다. 그러나 NWP 시스템에서 SSWs의 정확하고 효율적인 예측은 여전히 도전 과제가 되고 있다.

Method: 본 연구에서는 FM-Cast라는 Flow Matching 기반의 생성적 AI 모델을 개발하여 성층권 순환의 시공간 진화를 효율적이고 능숙하게 예측한다.

Result: FM-Cast는 18개의 주요 SSW 사건(1998-2024)에서 10건의 사건의 시작, 강도 및 형태를 최대 20일 전에 능숙하게 예측하며, 집단 정확도가 50%를 초과하는 성과를 달성하였다.

Conclusion: 우리의 연구는 성층권 이상 현상의 확률적 예측을 위한 컴퓨터 효율적인 패러다임을 정립하고, 생성적 AI가 대기-기후 역학에 대한 물리적 이해를 심화할 수 있는 잠재력을 보여준다.

Abstract: Sudden Stratospheric Warmings (SSWs) are key sources of subseasonal
predictability and major drivers of extreme winter weather. Yet, their accurate
and efficient forecast remains a persistent challenge for numerical weather
prediction (NWP) systems due to limitations in physical representation,
initialization, and the immense computational demands of ensemble forecasts.
While data-driven forecasting is rapidly evolving, its application to the
complex, three-dimensional dynamics of SSWs, particularly for probabilistic
forecast, remains underexplored. Here, we bridge this gap by developing a Flow
Matching-based generative AI model (FM-Cast) for efficient and skillful
probabilistic forecasting of the spatiotemporal evolution of stratospheric
circulation. Evaluated across 18 major SSW events (1998-2024), FM-Cast
skillfully forecasts the onset, intensity, and morphology of 10 events up to 20
days in advance, achieving ensemble accuracies above 50%. Its performance is
comparable to or exceeds leading NWP systems while requiring only two minutes
for a 50-member, 30-day forecast on a consumer GPU. Furthermore, leveraging
FM-Cast as a scientific tool, we demonstrate through idealized experiments that
SSW predictability is fundamentally linked to its underlying physical drivers,
distinguishing between events forced from the troposphere and those driven by
internal stratospheric dynamics. Our work thus establishes a computationally
efficient paradigm for probabilistic forecasting stratospheric anomalies and
showcases generative AI's potential to deepen the physical understanding of
atmosphere-climate dynamics.

</details>


### [20] [Multi-Task Learning Based on Support Vector Machines and Twin Support Vector Machines: A Comprehensive Survey](https://arxiv.org/abs/2510.26392)
*Fatemeh Bazikar,Hossein Moosaei,Atefeh Hemmati,Panos M. Pardalos*

Main category: cs.LG

TL;DR: 본 논문은 SVM 및 TWSVM을 기반으로 한 다중 작업 학습(MTL) 접근 방식을 조사하며, 공유 표현, 작업 정규화 및 구조적 결합 전략을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: MTL은 관련 작업 간의 동시 훈련을 가능하게 하고, 데이터가 부족하거나 고차원인 경우 특히 일반화, 효율성 및 안정성을 향상시킵니다.

Method: 본 장에서는 SVM 및 TWSVM을 기반으로 한 MTL 접근 방식을 다루고, TWSVM의 다중 작업 환경에 대한 새로운 확장에 특별한 주의를 기울입니다.

Result: 이 모델들을 이론적 속성, 최적화 전략 및 경험적 성능 측면에서 비교하고, 컴퓨터 비전, 자연어 처리 및 생물정보학 등 다양한 분야에의 적용을 논의합니다.

Conclusion: 연구 격차를 식별하고, 확장 가능하고 해석 가능하며 신뢰할 수 있는 마진 기반 MTL 프레임워크 구축을 위한 향후 방향을 제시합니다.

Abstract: Multi-task learning (MTL) enables simultaneous training across related tasks,
leveraging shared information to improve generalization, efficiency, and
robustness, especially in data-scarce or high-dimensional scenarios. While deep
learning dominates recent MTL research, Support Vector Machines (SVMs) and Twin
SVMs (TWSVMs) remain relevant due to their interpretability, theoretical rigor,
and effectiveness with small datasets.
  This chapter surveys MTL approaches based on SVM and TWSVM, highlighting
shared representations, task regularization, and structural coupling
strategies. Special attention is given to emerging TWSVM extensions for
multi-task settings, which show promise but remain underexplored. We compare
these models in terms of theoretical properties, optimization strategies, and
empirical performance, and discuss applications in fields such as computer
vision, natural language processing, and bioinformatics.
  Finally, we identify research gaps and outline future directions for building
scalable, interpretable, and reliable margin-based MTL frameworks. This work
provides a comprehensive resource for researchers and practitioners interested
in SVM- and TWSVM-based multi-task learning.

</details>


### [21] [Data-Efficient RLVR via Off-Policy Influence Guidance](https://arxiv.org/abs/2510.26491)
*Erle Zhu,Dazhi Jiang,Yuan Wang,Xujun Li,Jiale Cheng,Yuxian Gu,Yilin Niu,Aohan Zeng,Jie Tang,Minlie Huang,Hongning Wang*

Main category: cs.LG

TL;DR: 이 연구는 강화 학습에서 데이터 선택의 중요성을 강조하며, 영향 함수에 기반한 이론적 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습에서 데이터 선택은 대규모 언어 모델의 추론 능력을 향상시키는 데 중요한 요소입니다.

Method: 영향 함수를 사용하여 각 데이터 포인트가 학습 목표에 기여하는 정도를 추정하고, 사전 수집된 오프라인 궤적을 활용한 오프 정책 영향 추정 방법을 도입합니다.

Result: CROPI는 7B 파라미터 모델에서 훈련 속도를 현저히 가속화하며, 1.5B 모델에서는 단계당 데이터의 10%만 사용하여 2.66배 속도 향상을 달성합니다.

Conclusion: 영향 기반 데이터 선택은 효율적인 강화 학습을 위한 상당한 가능성을 드러냅니다.

Abstract: Data selection is a critical aspect of Reinforcement Learning with Verifiable
Rewards (RLVR) for enhancing the reasoning capabilities of large language
models (LLMs). Current data selection methods are largely heuristic-based,
lacking theoretical guarantees and generalizability. This work proposes a
theoretically-grounded approach using influence functions to estimate the
contribution of each data point to the learning objective. To overcome the
prohibitive computational cost of policy rollouts required for online influence
estimation, we introduce an off-policy influence estimation method that
efficiently approximates data influence using pre-collected offline
trajectories. Furthermore, to manage the high-dimensional gradients of LLMs, we
employ sparse random projection to reduce dimensionality and improve storage
and computation efficiency. Leveraging these techniques, we develop
\textbf{C}urriculum \textbf{R}L with \textbf{O}ff-\textbf{P}olicy
\text{I}nfluence guidance (\textbf{CROPI}), a multi-stage RL framework that
iteratively selects the most influential data for the current policy.
Experiments on models up to 7B parameters demonstrate that CROPI significantly
accelerates training. On a 1.5B model, it achieves a 2.66x step-level
acceleration while using only 10\% of the data per stage compared to
full-dataset training. Our results highlight the substantial potential of
influence-based data selection for efficient RLVR.

</details>


### [22] [A Three-Stage Bayesian Transfer Learning Framework to Improve Predictions in Data-Scarce Domains](https://arxiv.org/abs/2510.26541)
*Aidan Furlong,Robert Salko,Xingang Zhao,Xu Wu*

Main category: cs.LG

TL;DR: 이 연구는 불확실성을 정량화할 수 있는 완전 감독된 3단계 프레임워크인 단계적 베이지안 도메인 적대 신경망(staged B-DANN)을 소개하여 전이 학습을 개선하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 공학 분야에서 머신러닝의 사용이 지속적으로 증가하고 있으며, 특히 딥 뉴럴 네트워크는 성능과 접근성 덕분에 널리 채택되고 있지만, 고품질 데이터셋이 필요하다.

Method: 3단계 프레임워크인 단계적 베이지안 도메인 적대 신경망(staged B-DANN)은 파라미터 전이와 공유 잠재 공간 적응을 결합하여 구성된다. 1단계에서는 소스 도메인에서 결정론적 피쳐 추출기를 학습하고, 2단계에서는 DANN을 사용해 적대적으로 개선하며, 3단계에서는 적응된 피쳐 추출기를 기반으로 베이지안 신경망을 구축하여 대상 도메인에서 세부 조정 및 불확실성 추정을 수행한다.

Result: 단계적 B-DANN 방식은 합성 벤치마크에서 표준 전이 기법보다 현저하게 우수성을 입증했으며, 직사각형 채널 내에서의 임계 열유속 예측 작업에 적용되어 tube 실험에서 데이터를 활용하였다.

Conclusion: 이 연구의 결과는 단계적 B-DANN 방법이 예측 정확도와 일반화를 향상시키고, 원자로 공학의 다른 분야에서도 도움을 줄 수 있음을 보여준다.

Abstract: The use of ML in engineering has grown steadily to support a wide array of
applications. Among these methods, deep neural networks have been widely
adopted due to their performance and accessibility, but they require large,
high-quality datasets. Experimental data are often sparse, noisy, or
insufficient to build resilient data-driven models. Transfer learning, which
leverages relevant data-abundant source domains to assist learning in
data-scarce target domains, has shown efficacy. Parameter transfer, where
pretrained weights are reused, is common but degrades under large domain
shifts. Domain-adversarial neural networks (DANNs) help address this issue by
learning domain-invariant representations, thereby improving transfer under
greater domain shifts in a semi-supervised setting. However, DANNs can be
unstable during training and lack a native means for uncertainty
quantification. This study introduces a fully-supervised three-stage framework,
the staged Bayesian domain-adversarial neural network (staged B-DANN), that
combines parameter transfer and shared latent space adaptation. In Stage 1, a
deterministic feature extractor is trained on the source domain. This feature
extractor is then adversarially refined using a DANN in Stage 2. In Stage 3, a
Bayesian neural network is built on the adapted feature extractor for
fine-tuning on the target domain to handle conditional shifts and yield
calibrated uncertainty estimates. This staged B-DANN approach was first
validated on a synthetic benchmark, where it was shown to significantly
outperform standard transfer techniques. It was then applied to the task of
predicting critical heat flux in rectangular channels, leveraging data from
tube experiments as the source domain. The results of this study show that the
staged B-DANN method can improve predictive accuracy and generalization,
potentially assisting other domains in nuclear engineering.

</details>


### [23] [Clone Deterministic 3D Worlds with Geometrically-Regularized World Models](https://arxiv.org/abs/2510.26782)
*Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen*

Main category: cs.LG

TL;DR: 정확한 세계 모델을 구축하는 것을 목표로 하는 연구로, 기하학적으로 정규화된 세계 모델을 제안하여 표현 학습을 개선하고 롤아웃의 충실도를 높인다.


<details>
  <summary>Details</summary>
Motivation: 세계 모델은 에이전트와 환경의 행동을 예측하는데 필수적이며, 현재 세계 모델은 장기 상황에서 취약하다.

Method: 기하학적으로 정규화된 세계 모델(GRWM)을 제안하여 자연 감각 경로를 따라 연속적인 점들이 잠재 표현 공간에서 가깝도록 강제한다.

Result: GRWM은 3D 환경에서의 롤아웃 충실도와 안정성을 크게 증가시킨다.

Conclusion: 표현 학습을 개선하는 것이 강력한 세계 모델로 나아가는 직접적이고 유용한 경로임을 시사한다.

Abstract: A world model is an internal model that simulates how the world evolves.
Given past observations and actions, it predicts the future of both the
embodied agent and its environment. Accurate world models are essential for
enabling agents to think, plan, and reason effectively in complex, dynamic
settings. Despite rapid progress, current world models remain brittle and
degrade over long horizons. We argue that a central cause is representation
quality: exteroceptive inputs (e.g., images) are high-dimensional, and lossy or
entangled latents make dynamics learning unnecessarily hard. We therefore ask
whether improving representation learning alone can substantially improve
world-model performance. In this work, we take a step toward building a truly
accurate world model by addressing a fundamental yet open problem: constructing
a model that can fully clone and overfit to a deterministic 3D world. We
propose Geometrically-Regularized World Models (GRWM), which enforces that
consecutive points along a natural sensory trajectory remain close in latent
representation space. This approach yields significantly improved latent
representations that align closely with the true topology of the environment.
GRWM is plug-and-play, requires only minimal architectural modification, scales
with trajectory length, and is compatible with diverse latent generative
backbones. Across deterministic 3D settings and long-horizon prediction tasks,
GRWM significantly increases rollout fidelity and stability. Analyses show that
its benefits stem from learning a latent manifold with superior geometric
structure. These findings support a clear takeaway: improving representation
learning is a direct and useful path to robust world models, delivering
reliable long-horizon predictions without enlarging the dynamics module.

</details>


### [24] [Remote Labor Index: Measuring AI Automation of Remote Work](https://arxiv.org/abs/2510.26787)
*Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks*

Main category: cs.LG

TL;DR: AIs show limited automation potential in economic sectors, achieving only 2.5% performance on the Remote Labor Index (RLI).


<details>
  <summary>Details</summary>
Motivation: AI의 지식과 추론에 대한 연구 중심 벤치마크에서의 빠른 발전에도 불구하고, 이러한 성과가 경제적 가치 및 자동화로 어떻게 이어지는지는 불확실함이 남아 있다.

Method: Remote Labor Index (RLI)를 도입하여 실제 경제적 가치가 있는 프로젝트를 포함한 다양한 산업 부문의 벤치마크를 설정하였으며, 이를 통해 AI 에이전트의 실제 환경에서의 성능을 평가하였다.

Result: AI 에이전트는 RLI에서 평균 이하의 성능을 보였으며, 가장 성능이 높은 에이전트는 2.5%의 자동화 비율을 기록하였다.

Conclusion: 이 결과들은 AI 자동화에 대한 논의를 실증적 증거로 뒷받침하며, AI 영향을 추적하기 위한 공통의 기초를 설정하고, 이해관계자들이 AI 기반의 노동 자동화를 능동적으로 탐색할 수 있도록 한다.

Abstract: AIs have made rapid progress on research-oriented benchmarks of knowledge and
reasoning, but it remains unclear how these gains translate into economic value
and automation. To measure this, we introduce the Remote Labor Index (RLI), a
broadly multi-sector benchmark comprising real-world, economically valuable
projects designed to evaluate end-to-end agent performance in practical
settings. AI agents perform near the floor on RLI, with the highest-performing
agent achieving an automation rate of 2.5%. These results help ground
discussions of AI automation in empirical evidence, setting a common basis for
tracking AI impacts and enabling stakeholders to proactively navigate AI-driven
labor automation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [25] [An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0](https://arxiv.org/abs/2510.25813)
*Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli*

Main category: cs.AI

TL;DR: 이 논문은 인더스트리 5.0을 위한 새로운 프레임워크를 제시하며, 다양한 산업 환경에서 엣지 디바이스에 AI 모델을 쉽게 배포할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 산업 환경에서의 AI 모델 배포를 간소화하고, 지연 시간을 줄이며, 외부 데이터 전송을 피하기 위해.

Method: 에이전트 기반의 구현으로, 각 개별 에이전트가 명확하게 정의된 작업을 수행하여 유연성과 통합 용이성을 제공한다.

Result: 식품 산업에 대한 초기 평가 결과, 개선된 배포 시간과 시스템 적응성 성능이 나타났다.

Conclusion: 모듈 통합을 지원하고 낮은 자원 요구 사항을 유지하는 프레임워크를 통해 실시간 처리와 로컬 추론을 가능하게 하였다.

Abstract: We present a novel framework for Industry 5.0 that simplifies the deployment
of AI models on edge devices in various industrial settings. The design reduces
latency and avoids external data transfer by enabling local inference and
real-time processing. Our implementation is agent-based, which means that
individual agents, whether human, algorithmic, or collaborative, are
responsible for well-defined tasks, enabling flexibility and simplifying
integration. Moreover, our framework supports modular integration and maintains
low resource requirements. Preliminary evaluations concerning the food industry
in real scenarios indicate improved deployment time and system adaptability
performance. The source code is publicly available at
https://github.com/AI-REDGIO-5-0/ci-component.

</details>


### [26] [FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization](https://arxiv.org/abs/2510.25914)
*Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami*

Main category: cs.AI

TL;DR: FinOps 자동화를 위해 자율 목표 중심 AI 에이전트를 활용하는 방법을 제안하며, 실제 산업 프로세스를 모사한 FinOps 에이전트를 구축하였다.


<details>
  <summary>Details</summary>
Motivation: FinOps는 다양한 클라우드 제공자 및 내부 시스템으로부터 오는 이질적인 형식, 분류 체계, 메트릭의 청구 데이터를 처리하는 중요한 도전 과제를 해결하기 위해 필요하다.

Method: 자율 목표 중심 AI 에이전트를 활용하여 IT 인프라 및 비용 최적화의典형적 사용 사례에 대한 FinOps 에이전트를 구축하고, 다양한 출처에서 데이터를 가져오고 데이터를 통합하여 분석 후 최적화를 위한 추천을 생성하는 시스템을 구축하였다.

Result: 여러 오픈 소스 및 폐쇄형 언어 모델을 사용하여 에이전트를 평가하는 메트릭 집합을 정의하였으며, 에이전트가 실제 FinOps 실무자와 유사하게 작업을 이해, 계획 및 수행할 수 있음을 보여주었다.

Conclusion: 이 연구는 FinOps 프로세스의 자동화를 통해 클라우드 비즈니스 가치를 극대화할 수 있는 가능성을 보여준다.

Abstract: FinOps (Finance + Operations) represents an operational framework and
cultural practice which maximizes cloud business value through collaborative
financial accountability across engineering, finance, and business teams.
FinOps practitioners face a fundamental challenge: billing data arrives in
heterogeneous formats, taxonomies, and metrics from multiple cloud providers
and internal systems which eventually lead to synthesizing actionable insights,
and making time-sensitive decisions. To address this challenge, we propose
leveraging autonomous, goal-driven AI agents for FinOps automation. In this
paper, we built a FinOps agent for a typical use-case for IT infrastructure and
cost optimization. We built a system simulating a realistic end-to-end industry
process starting with retrieving data from various sources to consolidating and
analyzing the data to generate recommendations for optimization. We defined a
set of metrics to evaluate our agent using several open-source and close-source
language models and it shows that the agent was able to understand, plan, and
execute tasks as well as an actual FinOps practitioner.

</details>


### [27] [Estimating cognitive biases with attention-aware inverse planning](https://arxiv.org/abs/2510.25951)
*Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho*

Main category: cs.AI

TL;DR: 사람의 목표 지향 행동은 인지적 편향에 영향을 받으며, 자율 시스템은 이를 인식해야 한다. 본 연구에서는 인지적 편향을 추정하는 주의 인식 역계획 문제를 공식적으로 설명하고, 이를 통해 행동에서 인지적 편향을 유추할 수 있는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 사람의 목표 지향 행동에 대한 이해와 자율 시스템의 상호작용 개선

Method: 주의 인식 역계획 문제를 공식적으로 정의하고, 심층 강화 학습과 컴퓨터 인지 모델링을 결합하여 접근법을 제시함

Result: 실제 운전 시나리오에서 RL 에이전트의 주의 전략을 유추하여 인지적 편향 추정이 가능함을 입증

Conclusion: 주의 인식 역계획은 표준 역 강화 학습과 체계적으로 차별화되며, 인지적 편향을 추정하는 데 확장성이 있음을 보여줌

Abstract: People's goal-directed behaviors are influenced by their cognitive biases,
and autonomous systems that interact with people should be aware of this. For
example, people's attention to objects in their environment will be biased in a
way that systematically affects how they perform everyday tasks such as driving
to work. Here, building on recent work in computational cognitive science, we
formally articulate the attention-aware inverse planning problem, in which the
goal is to estimate a person's attentional biases from their actions. We
demonstrate how attention-aware inverse planning systematically differs from
standard inverse reinforcement learning and how cognitive biases can be
inferred from behavior. Finally, we present an approach to attention-aware
inverse planning that combines deep reinforcement learning with computational
cognitive modeling. We use this approach to infer the attentional strategies of
RL agents in real-life driving scenarios selected from the Waymo Open Dataset,
demonstrating the scalability of estimating cognitive biases with
attention-aware inverse planning.

</details>


### [28] [Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling](https://arxiv.org/abs/2510.26603)
*Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl*

Main category: cs.AI

TL;DR: 본 논문은 LLM을 활용한 자율 조정기능을 갖춘 가정용 에너지 관리 시스템(HEMS)을 제시한다. 이 시스템은 자연어 요청을 통해 다중 기기 스케줄링을 관리하며, 최적의 스케줄링을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 전기 분야의 전환은 주거용 수요 반응 능력을 크게 증가시켜야 하지만, HEMS의 채택은 일상적인 선호를 기술적 매개변수로 변환해야 하는 사용자 상호작용 장벽에 의해 제한된다.

Method: LLM들이 자율적으로 다중 기기 스케줄링을 조정하는 HEMS를 개발하며, 자연어 요청에서 기기 제어까지의 전체 워크플로우를 관리한다. 이 시스템은 세 가지 전문 에이전트와 하나의 조정자를 결합한 계층 구조를 사용하고, Google Calendar와 통합하여 동적인 조정을 가능하게 한다.

Result: 세 가지 오픈소스 모델을 사용한 평가에서 Llama-3.3-70B는 모든 시나리오에서 모든 기기를 조정하여 혼합 정수 선형 프로그래밍을 통해 계산된 비용 최적 기준에 맞춘다. 다른 모델들은 단일 기기 성능은 우수하지만 모든 기기를 동시에 조정하는 데는 어려움을 겪는다.

Conclusion: 분석 질의 처리에서 명시적 지침 없이도 신뢰성이 떨어진다는 것을 보여주며, 시스템의 모든 요소를 오픈소스하여 재현 가능성, 확장성 및 미래 연구를 지원한다.

Abstract: The electricity sector transition requires substantial increases in
residential demand response capacity, yet Home Energy Management Systems (HEMS)
adoption remains limited by user interaction barriers requiring translation of
everyday preferences into technical parameters. While large language models
have been applied to energy systems as code generators and parameter
extractors, no existing implementation deploys LLMs as autonomous coordinators
managing the complete workflow from natural language input to multi-appliance
scheduling. This paper presents an agentic AI HEMS where LLMs autonomously
coordinate multi-appliance scheduling from natural language requests to device
control, achieving optimal scheduling without example demonstrations. A
hierarchical architecture combining one orchestrator with three specialist
agents uses the ReAct pattern for iterative reasoning, enabling dynamic
coordination without hardcoded workflows while integrating Google Calendar for
context-aware deadline extraction. Evaluation across three open-source models
using real Austrian day-ahead electricity prices reveals substantial capability
differences. Llama-3.3-70B successfully coordinates all appliances across all
scenarios to match cost-optimal benchmarks computed via mixed-integer linear
programming, while other models achieve perfect single-appliance performance
but struggle to coordinate all appliances simultaneously. Progressive prompt
engineering experiments demonstrate that analytical query handling without
explicit guidance remains unreliable despite models' general reasoning
capabilities. We open-source the complete system including orchestration logic,
agent prompts, tools, and web interfaces to enable reproducibility, extension,
and future research.

</details>


### [29] [From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL](https://arxiv.org/abs/2510.25997)
*Manu Redd,Tao Zhe,Dongjie Wang*

Main category: cs.AI

TL;DR: NL-to-SQL 시스템은 사용자가 SQL을 배우지 않고도 데이터베이스를 쿼리할 수 있게 하여 구조화된 데이터에 대한 접근을 민주화할 수 있는 잠재력을 가지고 있다. 그러나 기존 시스템은 모호한 사용자 언어를 스키마 특정 카테고리와 조정하고, 시간적 추론을 처리하며, 적절한 출력을 선택해야 하는 현실적인 시공간 쿼리에서 어려움을 겪는다. 우리는 naive text-to-SQL 기초 모델을 Mistral 기반 ReAct 에이전트로 오케스트레이션하여 확장하는 에이전틱 파이프라인을 제시한다. 이 에이전트는 스키마 검사, SQL 생성, 실행 및 시각화 도구를 통해 쿼리를 계획하고 분해하며 적응할 수 있다. 이 연구는 NYC와 도쿄의 체크인 데이터셋을 기반으로 한 35개의 자연어 쿼리에 대해 평가되었으며, 공간적, 시간적, 다중 데이터셋 추론을 다룬다. 에이전트는 naive baseline보다 상당히 높은 정확도(91.4% 대 28.6%)를 달성하고 맵, 플롯 및 구조화된 자연어 요약을 통해 유용성을 향상시킨다. 결정적으로, 우리의 설계는 SQL 전문 지식, 세부 스키마 지식, 프롬프트 기술이 부족한 사용자를 지원하는 더 자연스러운 인간-데이터베이스 상호작용을 가능하게 한다. 우리는 강력한 SQL 생성기보다 에이전틱 오케스트레이션이 대화형 지리 공간 도우미의 유망한 기반이 된다고 결론지었다.


<details>
  <summary>Details</summary>
Motivation: NL-to-SQL 시스템은 사용자가 SQL을 배우지 않고도 데이터베이스에 쿼리할 수 있도록 하여 구조화된 데이터 접근을 민주화할 수 있는 가능성을 지니고 있다.

Method: 이 연구에서는 naive text-to-SQL 기초 모델을 Mistral 기반 ReAct 에이전트로 오케스트레이션하여 확장하는 에이전틱 파이프라인을 제시한다. 이 에이전트는 쿼리를 계획하고 분해하며 적응할 수 있는 기능을 가지고 있다.

Result: 에이전트는 NYC와 도쿄의 체크인 데이터셋을 기준으로 한 35개의 자연어 쿼리를 평가하여 naive baseline(28.6%)보다 훨씬 높은 정확도(91.4%)를 달성하고 유용성을 향상시킨다.

Conclusion: 우리는 강력한 SQL 생성기보다 에이전틱 오케스트레이션이 대화형 지리 공간 도우미의 유망한 기반이 된다고 결론지었다.

Abstract: Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing
access to structured data, allowing users to query databases without learning
SQL. Yet existing systems struggle with realistic spatio-temporal queries,
where success requires aligning vague user phrasing with schema-specific
categories, handling temporal reasoning, and choosing appropriate outputs. We
present an agentic pipeline that extends a naive text-to-SQL baseline
(llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The
agent can plan, decompose, and adapt queries through schema inspection, SQL
generation, execution, and visualization tools. We evaluate on 35
natural-language queries over the NYC and Tokyo check-in dataset, covering
spatial, temporal, and multi-dataset reasoning. The agent achieves
substantially higher accuracy than the naive baseline 91.4% vs. 28.6% and
enhances usability through maps, plots, and structured natural-language
summaries. Crucially, our design enables more natural human-database
interaction, supporting users who lack SQL expertise, detailed schema
knowledge, or prompting skill. We conclude that agentic orchestration, rather
than stronger SQL generators alone, is a promising foundation for interactive
geospatial assistants.

</details>


### [30] [Can AI be Accountable?](https://arxiv.org/abs/2510.26057)
*Andrew L. Kun*

Main category: cs.AI

TL;DR: AI의 책임성 부족 문제를 다루고, AI가 책임을 질 수 있는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 소비자, 유권자, 의사 결정자를 위한 AI의 필요성에 따라 AI의 책임성이 중요하다.

Method: AI의 책임성에 대한 일반적인 정의를 제시하고, 책임이 있는 AI와 없는 AI의 차이를 설명한다.

Result: 많은 AI가 현재 책임을 지지 않고 있으며, 질문이나 논의가 불가능하다.

Conclusion: 모든 AI가 영향 받는 사람들에게 책임을 지도록 하는 방법과 접근 방식을 탐구한다.

Abstract: The AI we use is powerful, and its power is increasing rapidly. If this
powerful AI is to serve the needs of consumers, voters, and decision makers,
then it is imperative that the AI is accountable. In general, an agent is
accountable to a forum if the forum can request information from the agent
about its actions, if the forum and the agent can discuss this information, and
if the forum can sanction the agent. Unfortunately, in too many cases today's
AI is not accountable -- we cannot question it, enter into a discussion with
it, let alone sanction it. In this chapter we relate the general definition of
accountability to AI, we illustrate what it means for AI to be accountable and
unaccountable, and we explore approaches that can improve our chances of living
in a world where all AI is accountable to those who are affected by it.

</details>


### [31] [GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks](https://arxiv.org/abs/2510.26098)
*Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li*

Main category: cs.AI

TL;DR: 대형 비전 언어 모델(VLMs)은 그래픽 사용자 인터페이스(GUI) 작업 자동화를 발전시켰지만 인간에 비해 여전히 부족하다. 이 논문은 GUI 지식의 결여가 이러한 차이의 원인이라고 가정하며, GUI 지식을 세 가지 차원으로 정리했다: 인터페이스 인식, 상호작용 예측, 지시 이해. 또한 여러 플랫폼 및 애플리케이션을 포함하는 GUI 지식 벤치를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대형 비전 언어 모델이 그래픽 사용자 인터페이스 작업에서 인간을 따라잡지 못하는 이유를 이해하고 개선하기 위해.

Method: GUI 작업 실행에서 발생하는 일반적인 실패 패턴을 분석하여 GUI 지식을 세 가지 차원으로 정리하고, 다양한 플랫폼에서의 선택형 및 예/아니오 질문을 포함한 벤치마크를 제시했다.

Result: 현재 VLM은 위젯 기능을 식별하지만 시스템 상태 인식, 행동 예측, 작업 완료 검증에서 어려움을 겪고 있으며, 실제 GUI 작업 실험을 통해 GUI 지식과 작업 성공 간의 밀접한 연관성이 검증되었다.

Conclusion: 구조화된 프레임워크를 제공함으로써 우리의 연구는 다운스트림 훈련 전에 더 큰 잠재력을 가진 VLM의 선택을 지원하고, 더 유능한 GUI 에이전트를 구축하기 위한 통찰력을 제공한다.

Abstract: Large vision language models (VLMs) have advanced graphical user interface
(GUI) task automation but still lag behind humans. We hypothesize this gap
stems from missing core GUI knowledge, which existing training schemes (such as
supervised fine tuning and reinforcement learning) alone cannot fully address.
By analyzing common failure patterns in GUI task execution, we distill GUI
knowledge into three dimensions: (1) interface perception, knowledge about
recognizing widgets and system states; (2) interaction prediction, knowledge
about reasoning action state transitions; and (3) instruction understanding,
knowledge about planning, verifying, and assessing task completion progress. We
further introduce GUI Knowledge Bench, a benchmark with multiple choice and
yes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,
IOS) and 292 applications. Our evaluation shows that current VLMs identify
widget functions but struggle with perceiving system states, predicting
actions, and verifying task completion. Experiments on real world GUI tasks
further validate the close link between GUI knowledge and task success. By
providing a structured framework for assessing GUI knowledge, our work supports
the selection of VLMs with greater potential prior to downstream training and
provides insights for building more capable GUI agents.

</details>


### [32] [The FM Agent](https://arxiv.org/abs/2510.26144)
*Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen*

Main category: cs.AI

TL;DR: 본 논문에서는 복잡한 현실 문제를 해결하기 위해 LLM 기반 추론과 대규모 진화 검색을 결합한 FM Agent라는 새로운 다중 에이전트 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 AI 연구 에이전트의 발전을 촉진하고 과학적 및 공학적 발견을 이끌어내기 위해.

Method: FM Agent는 전문가 지도, 반복 최적화를 위한 진화 샘플링 전략, 특정 도메인에서의 평가기, Ray 기반의 분산 비동기 실행 인프라 등 여러 혁신적인 요소를 통합합니다.

Result: FM Agent는 다양한 도메인에서 평가되었으며, 여러 고전 수학 문제에서 새로운 SOTA 결과를 달성했습니다.

Conclusion: FM Agent는 자율적으로 최첨단 결과를 도출하며, 대규모 기업 R&D 워크플로우와 기초 과학 연구에서 혁신을 가속화할 잠재력을 보여줍니다.

Abstract: Large language models (LLMs) are catalyzing the development of autonomous AI
research agents for scientific and engineering discovery. We present FM Agent,
a novel and general-purpose multi-agent framework that leverages a synergistic
combination of LLM-based reasoning and large-scale evolutionary search to
address complex real-world challenges. The core of FM Agent integrates several
key innovations: 1) a cold-start initialization phase incorporating expert
guidance, 2) a novel evolutionary sampling strategy for iterative optimization,
3) domain-specific evaluators that combine correctness, effectiveness, and
LLM-supervised feedback, and 4) a distributed, asynchronous execution
infrastructure built on Ray. Demonstrating broad applicability, our system has
been evaluated across diverse domains, including operations research, machine
learning, GPU kernel optimization, and classical mathematical problems. FM
Agent reaches state-of-the-art results autonomously, without human
interpretation or tuning -- 1976.3 on ALE-Bench (+5.2\%), 43.56\% on MLE-Bench
(+4.0pp), up to 20x speedups on KernelBench, and establishes new
state-of-the-art(SOTA) results on several classical mathematical problems.
Beyond academic benchmarks, FM Agent shows considerable promise for both
large-scale enterprise R\&D workflows and fundamental scientific research,
where it can accelerate innovation, automate complex discovery processes, and
deliver substantial engineering and scientific advances with broader societal
impact.

</details>


### [33] [One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning](https://arxiv.org/abs/2510.26167)
*Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang*

Main category: cs.AI

TL;DR: 본 논문에서는 기능 호출 작업을 위해 특별히 설계된 보상 모델(RM)인 ToolRM을 소개하며, 이를 통해 도구 학습의 발전을 지원합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)과 인간의 선호도를 일치시키기 위한 보상 모델의 필요성과, 도구 학습 분야에서의 제약을 해결하고자 함.

Method: 규칙 기반 점수 매기기와 다차원 샘플링을 사용하여 쌍별 선호 데이터 세트를 구성하는 새로운 파이프라인을 제안한다.

Result: Qwen3-4B/8B 시리즈 모델이 쌍별 보상 판단에서 Claude 4 및 OpenAI o3보다 최대 14.28% 높은 정확도를 달성하였다.

Conclusion: ToolRM은 더 넓은 비판 작업에도 일반화되며, 실험 결과 효과성과 효율성을 입증하였다.

Abstract: Reward models (RMs) play a critical role in aligning large language models
(LLMs) with human preferences. Yet in the domain of tool learning, the lack of
RMs specifically designed for function-calling tasks has limited progress
toward more capable agentic AI. We introduce ToolRM, a family of lightweight
generative RMs tailored for general tool-use scenarios. To build these models,
we propose a novel pipeline that constructs pairwise preference data using
rule-based scoring and multidimensional sampling. This yields
ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique
tasks that supports reinforcement learning with verifiable feedback. To
evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on
the agentic evaluation suite BFCL. Trained on our constructed data, models from
the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially
outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward
judgments. Beyond training objectives, ToolRM generalizes to broader critique
tasks, including Best-of-N sampling and self-correction. Experiments on
ACEBench highlight its effectiveness and efficiency, enabling inference-time
scaling and reducing output token usage by over 66%. We release data and model
checkpoints to facilitate future research.

</details>


### [34] [Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles](https://arxiv.org/abs/2510.26242)
*Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang*

Main category: cs.AI

TL;DR: 이 논문은 교차로에서의 신뢰할 수 없는 결정으로 인한 긴급 차량 지연을 완화하기 위해 비상 대응 기능이 강화된 분산 대형 언어 모델 에이전트를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 도시의 교통 복잡성이 증가함에 따라, 교통 신호 제어(TSC)가 교통 흐름을 최적화하고 도로 안전을 향상시키기 위해 필수적이다.

Method: 비상 상황에 따른 사고 깊이를 동적으로 조정하는 사고 프레임워크를 제시하고, 역사적 사례로부터 지식과 지침을 증류하는 새로운 Reviewer 기반 비상 RAG를 포함한다.

Result: 실험 결과, REG-TSC는 3개의 실제 도로 네트워크에서 여행 시간을 42.00%, 대기열 길이를 62.31%, 긴급 차량 대기 시간을 83.16% 단축시켰으며, 다른 최첨단 방법들보다 더 우수한 성능을 보였다.

Conclusion: REG-TSC는 이종 교차로에서 높은 보상 정책으로 안내하여 교통 신호 제어의 일반화 능력을 향상시킨다.

Abstract: With increasing urban traffic complexity, Traffic Signal Control (TSC) is
essential for optimizing traffic flow and improving road safety. Large Language
Models (LLMs) emerge as promising approaches for TSC. However, they are prone
to hallucinations in emergencies, leading to unreliable decisions that may
cause substantial delays for emergency vehicles. Moreover, diverse intersection
types present substantial challenges for traffic state encoding and
cross-intersection training, limiting generalization across heterogeneous
intersections. Therefore, this paper proposes Retrieval Augmented Generation
(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable
TSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning
framework, which dynamically adjusts reasoning depth based on the emergency
scenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to
distill specific knowledge and guidance from historical cases, enhancing the
reliability and rationality of agents' emergency decisions. Secondly, this
paper designs a type-agnostic traffic representation and proposes a
Reward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3
adaptively samples training experience from diverse intersections with
environment feedback-based priority and fine-tunes LLM agents with a designed
reward-weighted likelihood loss, guiding REG-TSC toward high-reward policies
across heterogeneous intersections. On three real-world road networks with 17
to 177 heterogeneous intersections, extensive experiments show that REG-TSC
reduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle
waiting time by 83.16%, outperforming other state-of-the-art methods.

</details>


### [35] [Graph-Enhanced Policy Optimization in LLM Agent Training](https://arxiv.org/abs/2510.26270)
*Jiazhen Yuan,Wei Zhao,Zhengbiao Bai*

Main category: cs.AI

TL;DR: 그래프 기반 강화 학습(GEPO)은 다중 회차 대화형 LLM 에이전트 훈련에서 환경의 구조적 연결성을 활용하는 데 필요한 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 추론 및 수학적 작업에서 그룹 기반 강화 학습이 인상적인 결과를 보여주지만, 다중 회차 상호작용 LLM 에이전트를 훈련할 때 상황에 적합하지 못한 문제들이 발생한다.

Method: 그래프 강화 정책 최적화(GEPO)를 통해 에이전트 경험으로부터 상태-전이 그래프를 동적으로 구성하고, 그래프 이론적 중심성을 활용하여 세 가지 상호 작용하는 학습 신호를 제공한다.

Result: GEPO는 ALFWorld, WebShop, 및 독점적인 Workbench 벤치마크에서 강력한 성능을 입증하며, 경쟁 기준 대비 절대 성공률을 각각 +4.1%, +5.3%, +10.9% 향상시킨다.

Conclusion: 환경 구조를 명시적으로 모델링하는 것이 LLM 에이전트 훈련을 발전시키기 위한 강력하고 일반화 가능한 전략임을 강조한다.

Abstract: Group based reinforcement learning (RL) has shown impressive results on
complex reasoning and mathematical tasks. Yet, when applied to train
multi-turn, interactive LLM agents, these methods often suffer from structural
blindness-the inability to exploit the underlying connectivity of the
environment. This manifests in three critical challenges: (1) inefficient,
unguided exploration, (2) imprecise credit assignment due to overlooking
pivotal states, and (3) myopic planning caused by static reward discounting. We
address these issues with Graph-Enhanced Policy Optimization (GEPO), which
dynamically constructs a state-transition graph from agent experience and
employs graph-theoretic centrality to provide three synergistic learning
signals: (1)structured intrinsic rewards that guide exploration toward
high-impact states, (2) a graph-enhanced advantage function for topology-aware
credit assignment, and (3) a dynamic discount factor adapted to each state's
strategic value. On the ALFWorld, WebShop, and a proprietary Workbench
benchmarks, GEPO demonstrates strong performance, achieving absolute success
rate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These
results highlight that explicitly modeling environmental structure is a robust,
generalizable strategy for advancing LLM agent training.

</details>


### [36] [Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings](https://arxiv.org/abs/2510.26384)
*Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz*

Main category: cs.AI

TL;DR: 작은 데이터 하위 집합을 통해 대형 언어 모델의 평가 비용을 줄이고 경쟁력 있는 예측 신뢰성을 유지하는 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 평가 비용이 높기 때문에 효율적인 평가와 예측 신뢰성을 유지할 수 있는 작고 대표적인 데이터 하위 집합이 필요하다.

Method: 항목 중심 접근 방식을 사용하여 벤치마크 하위 집합을 선택하며, 이는 작업 항목의 내재적 속성에 기반한다.

Result: Scales++라는 새로운 방법을 통해 선택 비용을 18배 이상 감소시키며, 0.5%의 데이터 하위 집합을 사용하여 2.9% 평균 절대 오차로 전체 벤치마크 점수를 예측했다.

Conclusion: 이 항목 중심 접근 방식은 평가 효율성을 높이고, 신뢰성을 크게 저하시키지 않으면서도 더 나은 콜드 스타트 성능과 해석 가능한 벤치마크를 제공한다.

Abstract: The prohibitive cost of evaluating large language models (LLMs) on
comprehensive benchmarks necessitates the creation of small yet representative
data subsets (i.e., tiny benchmarks) that enable efficient assessment while
retaining predictive fidelity. Current methods for this task operate under a
model-centric paradigm, selecting benchmarking items based on the collective
performance of existing models. Such approaches are limited by large upfront
costs, an inability to immediately handle new benchmarks (`cold-start'), and
the fragile assumption that future models will share the failure patterns of
their predecessors. In this work, we challenge this paradigm and propose a
item-centric approach to benchmark subset selection, arguing that selection
should be based on the intrinsic properties of the task items themselves,
rather than on model-specific failure patterns. We instantiate this
item-centric efficient benchmarking approach via a novel method, Scales++,
where data selection is based on the cognitive demands of the benchmark
samples. Empirically, we show Scales++ reduces the upfront selection cost by
over 18x while achieving competitive predictive fidelity. On the Open LLM
Leaderboard, using just a 0.5\% data subset, we predict full benchmark scores
with a 2.9% mean absolute error. We demonstrate that this item-centric approach
enables more efficient model evaluation without significant fidelity
degradation, while also providing better cold-start performance and more
interpretable benchmarking.

</details>


### [37] [A Pragmatic View of AI Personhood](https://arxiv.org/abs/2510.26396)
*Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi*

Main category: cs.AI

TL;DR: 본 논문은 에이전틱 인공지능이 새로운 종류의 인격 출현을 촉발할 것이라는 관점에서, 의무의 유연한 집합으로서 인격을 다루는 실용적인 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 인공지능의 출현이 사회에 새로운 종류의 인격을 도입할 것이기 때문에, 이에 대한 탐색과 정립이 필요하다.

Method: 인격을 메타물리적 특성이 아니라 사회가 특정 이유로 개체에게 수여하는 의무의 집합으로 간주하여, 상황에 맞는 맞춤형 솔루션을 생성할 수 있는 방법을 제시한다.

Result: AI 계약을 촉진하는 것을 포함하여, AI의 의식이나 합리성에 대한 논쟁을 해결하지 않고도 다양한 사회적 역할에 적응할 수 있는 도구를 만들 수 있다.

Conclusion: 단일하고 본질적인 인격 정의를 추구하기보다는, AI 에이전트를 사회에 통합하는 보다 실용적이고 유연한 방식을 제안한다.

Abstract: The emergence of agentic Artificial Intelligence (AI) is set to trigger a
"Cambrian explosion" of new kinds of personhood. This paper proposes a
pragmatic framework for navigating this diversification by treating personhood
not as a metaphysical property to be discovered, but as a flexible bundle of
obligations (rights and responsibilities) that societies confer upon entities
for a variety of reasons, especially to solve concrete governance problems. We
argue that this traditional bundle can be unbundled, creating bespoke solutions
for different contexts. This will allow for the creation of practical tools --
such as facilitating AI contracting by creating a target "individual" that can
be sanctioned -- without needing to resolve intractable debates about an AI's
consciousness or rationality. We explore how individuals fit in to social roles
and discuss the use of decentralized digital identity technology, examining
both "personhood as a problem", where design choices can create "dark patterns"
that exploit human social heuristics, and "personhood as a solution", where
conferring a bundle of obligations is necessary to ensure accountability or
prevent conflict. By rejecting foundationalist quests for a single, essential
definition of personhood, this paper offers a more pragmatic and flexible way
to think about integrating AI agents into our society.

</details>


### [38] [Context Engineering 2.0: The Context of Context Engineering](https://arxiv.org/abs/2510.26493)
*Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 이 논문은 맥락 공학의 개념을 정의하고 그 역사적 발전을 살펴보며 AI 시스템에서의 실천을 위한 설계 고려 사항을 논의한다.


<details>
  <summary>Details</summary>
Motivation: 인간과 기계의 상호작용에서 맥락의 중요성을 강조하기 위해 이 연구를 수행했다.

Method: 맥락 공학의 체계적 정의 제공, 역사적 및 개념적 환경 개요, 주요 설계 고려 사항 검토.

Result: 맥락 공학의 개념적 기초를 제공하고 AI 시스템에서 체계적인 맥락 공학을 위한 기반 마련.

Conclusion: 이 연구는 AI 시스템에서 맥락 공학을 향한 더 넓은 커뮤니티의 노력에 기여하는 첫 단계이다.

Abstract: Karl Marx once wrote that ``the human essence is the ensemble of social
relations'', suggesting that individuals are not isolated entities but are
fundamentally shaped by their interactions with other entities, within which
contexts play a constitutive and essential role. With the advent of computers
and artificial intelligence, these contexts are no longer limited to purely
human--human interactions: human--machine interactions are included as well.
Then a central question emerges: How can machines better understand our
situations and purposes? To address this challenge, researchers have recently
introduced the concept of context engineering. Although it is often regarded as
a recent innovation of the agent era, we argue that related practices can be
traced back more than twenty years. Since the early 1990s, the field has
evolved through distinct historical phases, each shaped by the intelligence
level of machines: from early human--computer interaction frameworks built
around primitive computers, to today's human--agent interaction paradigms
driven by intelligent agents, and potentially to human--level or superhuman
intelligence in the future. In this paper, we situate context engineering,
provide a systematic definition, outline its historical and conceptual
landscape, and examine key design considerations for practice. By addressing
these questions, we aim to offer a conceptual foundation for context
engineering and sketch its promising future. This paper is a stepping stone for
a broader community effort toward systematic context engineering in AI systems.

</details>


### [39] [The Era of Agentic Organization: Learning to Organize with Language Models](https://arxiv.org/abs/2510.26658)
*Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.AI

TL;DR: 비동기 사고(AsyncThink)는 대형 언어 모델을 활용한 새로운 추론 패러다임으로, 협력적으로 문제를 해결하는 에이전트 조직의 비전을 실현한다.


<details>
  <summary>Details</summary>
Motivation: AI의 새로운 시대를 구상하며, 에이전트들이 협력적으로 복잡한 문제를 해결하여 개인의 지능을 넘어서는 성과를 얻고자 함.

Method: 비동기 사고(AsyncThink)라는 새로운 추론 패러다임을 도입하고, 조직자가 동적으로 하위 쿼리를 작업자에게 할당하며 중간 지식을 병합하여 일관된 솔루션을 생성하는 사고 프로토콜을 제안함.

Result: AsyncThink는 평행 사고에 비해 28% 더 낮은 추론 지연 시간을 달성하고 수학적 추론 정확도를 개선함.

Conclusion: 비동기 사고 능력을 일반화하여 추가 교육 없이도 보지 못한 작업을 효과적으로 처리할 수 있음.

Abstract: We envision a new era of AI, termed agentic organization, where agents solve
complex problems by working collaboratively and concurrently, enabling outcomes
beyond individual intelligence. To realize this vision, we introduce
asynchronous thinking (AsyncThink) as a new paradigm of reasoning with large
language models, which organizes the internal thinking process into
concurrently executable structures. Specifically, we propose a thinking
protocol where an organizer dynamically assigns sub-queries to workers, merges
intermediate knowledge, and produces coherent solutions. More importantly, the
thinking structure in this protocol can be further optimized through
reinforcement learning. Experiments demonstrate that AsyncThink achieves 28%
lower inference latency compared to parallel thinking while improving accuracy
on mathematical reasoning. Moreover, AsyncThink generalizes its learned
asynchronous thinking capabilities, effectively tackling unseen tasks without
additional training.

</details>


### [40] [Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching](https://arxiv.org/abs/2510.26702)
*Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi*

Main category: cs.AI

TL;DR: 대형 언어 모델 구동 에이전트가 도구를 동적으로 호출하고 보호된 리소스에 접근하는 것을 허용하는 것은 상당한 위험을 초래하며, 권한 위임을 위한 현재 방법이 지나치게 광범위한 권한을 부여하는 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 리소스에 접근하는 데 있어 권한 위임을 안전하게 수행할 필요가 있다.

Method: 권한 서버가 보호된 리소스에 대한 접근 요청을 의미적으로 검사하고, 에이전트의 할당된 작업에 필요한 최소한의 범위로 제한된 접근 토큰을 발급하는 위임된 권한 모델을 도입하고 평가한다.

Result: ASTRA라는 데이터셋과 데이터 생성 파이프라인을 소개하며, 사건과 범위 간의 의미적 매칭을 벤치마킹하는 실험을 수행했다.

Conclusion: 멀티 에이전트 및 도구 보강 응용 프로그램을 위한 의도 인식 권한을 가능하게 하는 의미적 매칭 기술에 대한 추가 연구 필요성을 강조한다.

Abstract: Authorizing Large Language Model driven agents to dynamically invoke tools
and access protected resources introduces significant risks, since current
methods for delegating authorization grant overly broad permissions and give
access to tools allowing agents to operate beyond the intended task scope. We
introduce and assess a delegated authorization model enabling authorization
servers to semantically inspect access requests to protected resources, and
issue access tokens constrained to the minimal set of scopes necessary for the
agents' assigned tasks. Given the unavailability of datasets centered on
delegated authorization flows, particularly including both semantically
appropriate and inappropriate scope requests for a given task, we introduce
ASTRA, a dataset and data generation pipeline for benchmarking semantic
matching between tasks and scopes. Our experiments show both the potential and
current limitations of model-based matching, particularly as the number of
scopes needed for task completion increases. Our results highlight the need for
further research into semantic matching techniques enabling intent-aware
authorization for multi-agent and tool-augmented applications, including
fine-grained control, such as Task-Based Access Control (TBAC).

</details>


### [41] [The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy](https://arxiv.org/abs/2510.26752)
*William Overman,Mohsen Bayati*

Main category: cs.AI

TL;DR: 이 논문은 인간의 통제를 유지하면서 자율적인 에이전트를 안전하게 배치하는 방법을 연구하며, 최소한의 제어 인터페이스를 모델링하여 자율적 행동과 감독 간의 상호작용을 두 플레이어 마르콤 게임으로 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 더욱 능력 있는 에이전트가 배치됨에 따라, 기본 시스템을 변경하지 않고 의미 있는 인간 통제를 유지하는 방법이 핵심 안전 질문으로 떠오르고 있습니다.

Method: 우리는 에이전트가 자율적으로 행동할지(행동) 아니면 인간에게 요청할지(요청) 선택하고, 인간이 관대하게 대할지(신뢰) 감독을 할지(감독) 선택하는 최소한의 제어 인터페이스를 연구합니다. 이 상호작용을 두 플레이어 마르콤 게임으로 모델링합니다. 이러한 게임이 마르콤 잠재 게임(MPG)으로 자격이 되는 경우를 분석합니다.

Result: 이론적으로 이 관점은 특정 형태의 내재적 정렬을 위한 조건을 제공합니다. 에이전트가 스스로의 결과를 개선하는 것이 인간의 가치를 해치지 않을 것이라는 공식적인 보장을 제공합니다. 실질적으로 이 모델은 에이전트가 불확실할 때 요청하고, 안전할 때 행동하도록 학습하는 예측 가능한 인센티브를 갖춘 투명한 제어 계층을 제공합니다.

Conclusion: 우리의 그리드월드 시뮬레이션은 독립적인 학습을 통해 에이전트와 인간이 최적의 감독 역할을 발견함을 보여줍니다. 이는 훈련 후 도입된 안전 위반을 피하는 협력을 이끌어냅니다.

Abstract: As increasingly capable agents are deployed, a central safety question is how
to retain meaningful human control without modifying the underlying system. We
study a minimal control interface where an agent chooses whether to act
autonomously (play) or defer (ask), while a human simultaneously chooses
whether to be permissive (trust) or to engage in oversight (oversee). If the
agent defers, the human's choice determines the outcome, potentially leading to
a corrective action or a system shutdown. We model this interaction as a
two-player Markov Game. Our analysis focuses on cases where this game qualifies
as a Markov Potential Game (MPG), a class of games where we can provide an
alignment guarantee: under a structural assumption on the human's value
function, any decision by the agent to act more autonomously that benefits
itself cannot harm the human's value. We also analyze extensions to this MPG
framework. Theoretically, this perspective provides conditions for a specific
form of intrinsic alignment. If the reward structures of the human-agent game
meet these conditions, we have a formal guarantee that the agent improving its
own outcome will not harm the human's. Practically, this model motivates a
transparent control layer with predictable incentives where the agent learns to
defer when risky and act when safe, while its pretrained policy and the
environment's reward structure remain untouched. Our gridworld simulation shows
that through independent learning, the agent and human discover their optimal
oversight roles. The agent learns to ask when uncertain and the human learns
when to oversee, leading to an emergent collaboration that avoids safety
violations introduced post-training. This demonstrates a practical method for
making misaligned models safer after deployment.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [42] [Attention Augmented GNN RNN-Attention Models for Advanced Cybersecurity Intrusion Detection](https://arxiv.org/abs/2510.25802)
*Jayant Biradar,Smit Shah,Tanmay Naik*

Main category: cs.CR

TL;DR: 하이브리드 딥 러닝 아키텍처가 사이버 보안 침입 탐지 능력을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 침입 탐지를 개선하기 위해 하이브리드 딥 러닝 아키텍처를 제안합니다.

Method: 그래프 신경망(GNNs), 순환 신경망(RNNs) 및 멀티 헤드 주의 메커니즘을 결합하여 네트워크 이벤트의 공간적 의존성과 시간적 동태성을 효율적으로 포착합니다.

Result: 전통적인 머신 러닝 접근 방식 및 독립적인 딥 러닝 모델에 비해 탁월한 성능을 보여줍니다.

Conclusion: 이 모델은 복잡한 네트워크 환경에서 사이버 보안 애플리케이션을 위한 유망한 솔루션입니다.

Abstract: In this paper, we propose a novel hybrid deep learning architecture that
synergistically combines Graph Neural Networks (GNNs), Recurrent Neural
Networks (RNNs), and multi-head attention mechanisms to significantly enhance
cybersecurity intrusion detection capabilities. By leveraging the comprehensive
UNSW-NB15 dataset containing diverse network traffic patterns, our approach
effectively captures both spatial dependencies through graph structural
relationships and temporal dynamics through sequential analysis of network
events. The integrated attention mechanism provides dual benefits of improved
model interpretability and enhanced feature selection, enabling cybersecurity
analysts to focus computational resources on high-impact security events -- a
critical requirement in modern real-time intrusion detection systems. Our
extensive experimental evaluation demonstrates that the proposed hybrid model
achieves superior performance compared to traditional machine learning
approaches and standalone deep learning models across multiple evaluation
metrics, including accuracy, precision, recall, and F1-score. The model
achieves particularly strong performance in detecting sophisticated attack
patterns such as Advanced Persistent Threats (APTs), Distributed Denial of
Service (DDoS) attacks, and zero-day exploits, making it a promising solution
for next-generation cybersecurity applications in complex network environments.

</details>


### [43] [Identity Management for Agentic AI: The new frontier of authorization, authentication, and security for an AI agent world](https://arxiv.org/abs/2510.25819)
*Tobin South,Subramanya Nagabhushanaradhya,Ayesha Dissanayaka,Sarah Cecchetti,George Fletcher,Victor Lu,Aldo Pietropaolo,Dean H. Saxe,Jeff Lombardo,Abhishek Maligehalli Shivalingaiah,Stan Bounev,Alex Keisner,Andor Kesselman,Zack Proser,Ginny Fahs,Andrew Bunyea,Ben Moskowitz,Atul Tulshibagwale,Dazza Greenwood,Jiaxin Pei,Alex Pentland*

Main category: cs.CR

TL;DR: AI 에이전트의 급속한 발전은 인증, 권한 부여 및 신원 관리에서 긴급한 도전을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현재 에이전트 중심 프로토콜에서 인증 및 권한 부여에 대한 모범 사례에 대한 수요가 대두되고 있다.

Method: 본 백서는 AI 에이전트와 접근 관리의 교차점에 있는 이해관계자를 위한 전략적 의제를 제시한다.

Result: 기존의 인증, 권한 부여 및 신원 문제를 해결하기 위한 자원을 개요한다.

Conclusion: 향후 자율 시스템의 광범위한 활용을 위해 기초적인 문제를 해결하기 위한 전략이 제시된다.

Abstract: The rapid rise of AI agents presents urgent challenges in authentication,
authorization, and identity management. Current agent-centric protocols (like
MCP) highlight the demand for clarified best practices in authentication and
authorization. Looking ahead, ambitions for highly autonomous agents raise
complex long-term questions regarding scalable access control, agent-centric
identities, AI workload differentiation, and delegated authority. This OpenID
Foundation whitepaper is for stakeholders at the intersection of AI agents and
access management. It outlines the resources already available for securing
today's agents and presents a strategic agenda to address the foundational
authentication, authorization, and identity problems pivotal for tomorrow's
widespread autonomous systems.

</details>


### [44] [AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI](https://arxiv.org/abs/2510.25863)
*Ken Huang,Jerry Huang,Yasir Mehmood,Hammad Atta,Muhammad Zeeshan Baig,Muhammad Aziz Ul Haq*

Main category: cs.CR

TL;DR: AAGATE는 자율 언어 모델 기반 에이전트의 보안 및 거버넌스 문제를 해결하기 위한 Kubernetes 네이티브 제어판입니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 애플리케이션 보안 도구가 즉흥적이고 기계 속도 시스템에 한계를 가지고 있음을 인식하고, 이를 해결하기 위해 AAGATE를 개발했습니다.

Method: NIST AI 위험 관리 프레임워크를 기반으로 하여, 각 RMF 기능에 특화된 보안 프레임워크를 통합하였으며, 제로 트러스트 서비스 메시, 설명 가능한 정책 엔진, 행동 분석 및 분산형 책임 구조를 포함합니다.

Result: AAGATE는 안전하고 책임이 있으며 확장 가능한 에이전틱 AI 배포를 위한 지속적이고 검증 가능한 거버넌스 솔루션을 제공합니다.

Conclusion: 이 프레임워크는 디지털 정체권(DIRF), 논리 계층 인젝션 방어(LPCI), 인지 저하 모니터(QSAF)를 통해 시스템적, 적대적 및 윤리적 위험을 포괄합니다.

Abstract: This paper introduces the Agentic AI Governance Assurance & Trust Engine
(AAGATE), a Kubernetes-native control plane designed to address the unique
security and governance challenges posed by autonomous, language-model-driven
agents in production. Recognizing the limitations of traditional Application
Security (AppSec) tooling for improvisational, machine-speed systems, AAGATE
operationalizes the NIST AI Risk Management Framework (AI RMF). It integrates
specialized security frameworks for each RMF function: the Agentic AI Threat
Modeling MAESTRO framework for Map, a hybrid of OWASP's AIVSS and SEI's SSVC
for Measure, and the Cloud Security Alliance's Agentic AI Red Teaming Guide for
Manage. By incorporating a zero-trust service mesh, an explainable policy
engine, behavioral analytics, and decentralized accountability hooks, AAGATE
provides a continuous, verifiable governance solution for agentic AI, enabling
safe, accountable, and scalable deployment. The framework is further extended
with DIRF for digital identity rights, LPCI defenses for logic-layer injection,
and QSAF monitors for cognitive degradation, ensuring governance spans
systemic, adversarial, and ethical risks.

</details>


### [45] [FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for Facebook and X](https://arxiv.org/abs/2510.25932)
*Soufiane Essahli,Oussama Sarsar,Imane Fouad,Anas Motii,Ahmed Bentajer*

Main category: cs.CR

TL;DR: FakeZero는 사용자 스크롤 중에 Facebook과 X에서 신뢰할 수 없는 게시물을 표시하는 클라이언트 측 브라우저 확장입니다.


<details>
  <summary>Details</summary>
Motivation: 소셜 플랫폼은 정보를 빠르게 유통시켜 잘못된 정보의 확산을 가속화하고 공공 담론을 위협합니다.

Method: FakeZero는 전통적인 훈련 방법 외에 초점 손실, 적대적 증강 및 후처리 양자화를 적용한 세 단계 훈련 커리큘럼을 사용합니다.

Result: 239,000개의 게시물 데이터셋에서 DistilBERT-Quant 모델은 97.1% 매크로-F1과 97.4% 정확도, 0.996 AUROC를 기록했습니다.

Conclusion: FakeZero는 사회적 네트워크에서 잘못된 정보의 확산을 줄이려는 정책 입안자에게 유용한 도구가 될 수 있으며, 사용자 동의로 대규모 데이터셋 수집을 가능하게 합니다.

Abstract: Social platforms distribute information at unprecedented speed, which in turn
accelerates the spread of misinformation and threatens public discourse. We
present FakeZero, a fully client-side, cross-platform browser extension that
flags unreliable posts on Facebook and X (formerly Twitter) while the user
scrolls. All computation, DOM scraping, tokenisation, Transformer inference,
and UI rendering run locally through the Chromium messaging API, so no personal
data leaves the device.FakeZero employs a three-stage training curriculum:
baseline fine-tuning and domain-adaptive training enhanced with focal loss,
adversarial augmentation, and post-training quantisation. Evaluated on a
dataset of 239,000 posts, the DistilBERT-Quant model (67.6 MB) reaches 97.1%
macro-F1, 97.4% accuracy, and an AUROC of 0.996, with a median latency of
approximately 103 ms on a commodity laptop. A memory-efficient TinyBERT-Quant
variant retains 95.7% macro-F1 and 96.1% accuracy while shrinking the model to
14.7 MB and lowering latency to approximately 40 ms, showing that high-quality
fake-news detection is feasible under tight resource budgets with only modest
performance loss.By providing inline credibility cues, the extension can serve
as a valuable tool for policymakers seeking to curb the spread of
misinformation across social networks. With user consent, FakeZero also opens
the door for researchers to collect large-scale datasets of fake news in the
wild, enabling deeper analysis and the development of more robust detection
techniques.

</details>


### [46] [SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning](https://arxiv.org/abs/2510.26037)
*Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied*

Main category: cs.CR

TL;DR: LLM 에이전트의 안전한 배포를 보장하기 위해 포괄적인 레드팀 시스템이 필요하다. 본 논문에서는 다양한 위험 결과를 다루기 위해 시드 테스트 케이스를 생성하고, 모델 기반의 적대적 공격을 정교화하는 SIRAJ라는 일반적인 레드팀 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 도구를 계획하고 호출하는 능력은 새로운 안전 위험에 노출시키며, 이는 취약점을 발견하고 안전한 배포를 보장하는 포괄적인 레드팀 시스템이 필요함을 의미한다.

Method: SIRAJ라는 두 단계의 동적 프로세스를 사용하여 에이전트 정의로 시작하고, 다양한 위험 결과, 도구 사용 경로 및 위험 출처를 포함하는 다양한 시드 테스트 케이스를 생성한다. 이후 이전 시도의 실행 경로를 바탕으로 모델 기반의 적대적 공격을 반복적으로 구성하고 정제한다.

Result: 우리의 시드 테스트 케이스 생성 접근 방식은 위험 결과와 도구 호출 경로의 범위를 2배에서 2.5배 향상시키며, 8B 레드팀 모델은 671B Deepseek-R1 모델을 초월하여 공격 성공률을 100% 향상시킨다.

Conclusion: 우리의 반복적 프레임워크, 구조적 추론, 그리고 레드팀 모델의 일반화의 효과성을 검증하는 제어 실험과 분석이 수행되었다.

Abstract: The ability of LLM agents to plan and invoke tools exposes them to new safety
risks, making a comprehensive red-teaming system crucial for discovering
vulnerabilities and ensuring their safe deployment. We present SIRAJ: a generic
red-teaming framework for arbitrary black-box LLM agents. We employ a dynamic
two-step process that starts with an agent definition and generates diverse
seed test cases that cover various risk outcomes, tool-use trajectories, and
risk sources. Then, it iteratively constructs and refines model-based
adversarial attacks based on the execution trajectories of former attempts. To
optimize the red-teaming cost, we present a model distillation approach that
leverages structured forms of a teacher model's reasoning to train smaller
models that are equally effective. Across diverse evaluation agent settings,
our seed test case generation approach yields 2 -- 2.5x boost to the coverage
of risk outcomes and tool-calling trajectories. Our distilled 8B red-teamer
model improves attack success rate by 100%, surpassing the 671B Deepseek-R1
model. Our ablations and analyses validate the effectiveness of the iterative
framework, structured reasoning, and the generalization of our red-teamer
models.

</details>


### [47] [Who Moved My Transaction? Uncovering Post-Transaction Auditability Vulnerabilities in Modern Super Apps](https://arxiv.org/abs/2510.26210)
*Junlin Liu,Zhaomeng Deng,Ziming Wang,Mengyu Yao,Yifeng Cai,Yutao Hu,Ziqi Zhang,Yao Guo,Ding Li*

Main category: cs.CR

TL;DR: 슈퍼 앱은 일상생활의 주요 요소로 자리잡고 있으며, 금융 거래의 보안이 주로 사전 인증에 초점을 맞추고 있다. 그러나 거래 후 감사 추적의 취약점이 간과되고 있으며, 사용자들이 거래 기록을 쉽게 삭제할 수 있는 위험이 있음이 드러났다.


<details>
  <summary>Details</summary>
Motivation: 슈퍼 앱에서 거래 후 감사 기록의 취약성을 지적하기 위해 본 연구를 진행했다.

Method: 6명의 자원자가 6개의 슈퍼 앱에서 거래 기록 삭제에 대한 평가를 수행하는 실증 연구를 실시하였다.

Result: 연구된 모든 6개 앱이 사용자에게 거래 기록 삭제를 허용하였고, 5개 앱이 강력한 인증 없이 이러한 기록을 보호하지 않음이 밝혀졌다.

Conclusion: 현재 모바일 보안 환경에서 감사 무결성을 보장하기 위한 패러다임 전환의 필요성을 강조한다.

Abstract: Super apps are the cornerstones of modern digital life, embedding financial
transactions into nearly every aspect of daily routine. The prevailing security
paradigm for these platforms is overwhelmingly focused on pre-transaction
authentication, preventing unauthorized payments before they occur. We argue
that a critical vulnerability vector has been largely overlooked: the fragility
of post-transaction audit trails. We investigate the ease with which a user can
permanently erase their transaction history from an app's interface, thereby
concealing unauthorized or sensitive activities from the account owner. To
quantify this threat, we conducted an empirical study with 6 volunteers who
performed a cross-evaluation on six super apps. Our findings are alarming: all
six applications studied allow users to delete transaction records, yet a
staggering five out of six (83+\%) fail to protect these records with strong
authentication. Only one app in our study required biometric verification for
deletion. This study provides the first concrete evidence of this
near-ubiquitous vulnerability, demonstrating a critical gap in the current
mobile security landscape and underscoring the urgent need for a paradigm shift
towards ensuring post-transaction audit integrity.

</details>


### [48] [Who Grants the Agent Power? Defending Against Instruction Injection via Task-Centric Access Control](https://arxiv.org/abs/2510.26212)
*Yifeng Cai,Ziming Wang,Zhaomeng Deng,Mengyu Yao,Junlin Liu,Yutao Hu,Ziqi Zhang,Yao Guo,Ding Li*

Main category: cs.CR

TL;DR: AI 에이전트의 GUI 이해와 Model Context Protocol을 기반으로 한 모바일 작업 자동화가 증가하는 가운데, AgentSentry라는 경량 런타임 접근 제어 프레임워크가 동적 작업 범위 권한을 강화하여 악성 명령 주입 공격을 방지한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 모바일 작업을 자동화하는 데 널리 사용되고 있으나, 과도한 정적 권한에 의존하는 것은 중요한 보안 취약점을 초래한다.

Method: AgentSentry는 사용자의 특정 작업에 맞는 최소한의 임시 정책을 동적으로 생성하고 시행하여 권한을 관리한다.

Result: AgentSentry는 에이전트가 사적인 이메일을 전송하도록 속이는 명령 주입 공격을 성공적으로 방지하면서 합법적인 작업을 완료하도록 한다.

Conclusion: 다음 세대 자율 에이전트를 안전하게 관리하기 위해 의도에 맞는 보안 모델의 필요성이 강조된다.

Abstract: AI agents capable of GUI understanding and Model Context Protocol are
increasingly deployed to automate mobile tasks. However, their reliance on
over-privileged, static permissions creates a critical vulnerability:
instruction injection. Malicious instructions, embedded in otherwise benign
content like emails, can hijack the agent to perform unauthorized actions. We
present AgentSentry, a lightweight runtime task-centric access control
framework that enforces dynamic, task-scoped permissions. Instead of granting
broad, persistent permissions, AgentSentry dynamically generates and enforces
minimal, temporary policies aligned with the user's specific task (e.g.,
register for an app), revoking them upon completion. We demonstrate that
AgentSentry successfully prevents an instruction injection attack, where an
agent is tricked into forwarding private emails, while allowing the legitimate
task to complete. Our approach highlights the urgent need for intent-aligned
security models to safely govern the next generation of autonomous agents.

</details>


### [49] [A DRL-Empowered Multi-Level Jamming Approach for Secure Semantic Communication](https://arxiv.org/abs/2510.26610)
*Weixuan Chen,Qianqian Yang*

Main category: cs.CR

TL;DR: 이 논문은 MIMO 페이딩 도청 채널에서의 의미적 통신 시스템 보안을 향상시키기 위한 심층 강화 학습 기반의 다단계 방해 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 의미적 통신(SemCom)은 작업과 관련된 정보만 전송하여 통신 효율성을 높이는 것을 목표로 하지만, 의미 정보가 도청에 노출될 수 있는 위험도 존재합니다.

Method: 이 방법은 작업과 관련 없는 텍스트를 인코딩하여 의미적 레이어 방해를 수행하고, 무작위 가우시안 노이즈를 인코딩하여 물리적 레이어 방해를 수행하는 두 가지 레벨의 방해 신호를 결합합니다.

Result: 실험 결과, 제안된 방법이 암호 기반(ESCS) 및 인코딩 방해 장치 기반(EJ) 벤치마크와 비교했을 때 유사한 보안을 달성하면서 합법적 사용자의 최대 신호 대 잡음 비율(PSNR)을 약 0.6 dB까지 향상시킴을 보여줍니다.

Conclusion: 심층 결정적 정책 경량화(DDPG) 알고리즘을 활용하여 작업 관련 의미 정보와 다단계 방해 신호를 위한 프리코딩 매트릭스를 동적으로 설계하고 최적화합니다.

Abstract: Semantic communication (SemCom) aims to transmit only task-relevant
information, thereby improving communication efficiency but also exposing
semantic information to potential eavesdropping. In this paper, we propose a
deep reinforcement learning (DRL)-empowered multi-level jamming approach to
enhance the security of SemCom systems over MIMO fading wiretap channels. This
approach combines semantic layer jamming, achieved by encoding task-irrelevant
text, and physical layer jamming, achieved by encoding random Gaussian noise.
These two-level jamming signals are superposed with task-relevant semantic
information to protect the transmitted semantics from eavesdropping. A deep
deterministic policy gradient (DDPG) algorithm is further introduced to
dynamically design and optimize the precoding matrices for both taskrelevant
semantic information and multi-level jamming signals, aiming to enhance the
legitimate user's image reconstruction while degrading the eavesdropper's
performance. To jointly train the SemCom model and the DDPG agent, we propose
an alternating optimization strategy where the two modules are updated
iteratively. Experimental results demonstrate that, compared with both the
encryption-based (ESCS) and encoded jammer-based (EJ) benchmarks, our method
achieves comparable security while improving the legitimate user's peak
signalto-noise ratio (PSNR) by up to approximately 0.6 dB.

</details>
