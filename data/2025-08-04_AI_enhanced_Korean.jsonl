{"id": "2508.00037", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00037", "abs": "https://arxiv.org/abs/2508.00037", "authors": ["Tong Nie", "Jian Sun", "Wei Ma"], "title": "Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion", "comment": "Accepted at IEEE Transactions on Industrial Informatics", "summary": "Networked urban systems facilitate the flow of people, resources, and\nservices, and are essential for economic and social interactions. These systems\noften involve complex processes with unknown governing rules, observed by\nsensor-based time series. To aid decision-making in industrial and engineering\ncontexts, data-driven predictive models are used to forecast spatiotemporal\ndynamics of urban systems. Current models such as graph neural networks have\nshown promise but face a trade-off between efficacy and efficiency due to\ncomputational demands. Hence, their applications in large-scale networks still\nrequire further efforts. This paper addresses this trade-off challenge by\ndrawing inspiration from physical laws to inform essential model designs that\nalign with fundamental principles and avoid architectural redundancy. By\nunderstanding both micro- and macro-processes, we present a principled\ninterpretable neural diffusion scheme based on Transformer-like structures\nwhose attention layers are induced by low-dimensional embeddings. The proposed\nscalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is\nvalidated on large-scale urban systems including traffic flow, solar power, and\nsmart meters, showing state-of-the-art performance and remarkable scalability.\nOur results constitute a fresh perspective on the dynamics prediction in\nlarge-scale urban networks.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \ub300\uaddc\ubaa8 \ub3c4\uc2dc \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c\uc758 \ub3d9\uc801 \uc608\uce21\uc744 \uc704\ud55c \ud6a8\uc728\uc801\uc778 \ub370\uc774\ud130 \uae30\ubc18 \ubaa8\ub378\uc778 ScaleSTF\ub97c \uc81c\uc548\ud558\uba70, \uc120\ud615 \ubcf5\uc7a1\ub3c4\ub97c \uac00\uc9c4 Transformer \uad6c\uc870\ub97c \ud1b5\ud574 \uc131\ub2a5\uacfc \ud655\uc7a5\uc131\uc744 \ub2ec\uc131\ud55c\ub2e4.", "motivation": "\ub3c4\uc2dc \uc2dc\uc2a4\ud15c\uc758 \ubcf5\uc7a1\ud558\uace0 \ubd88\ud655\uc2e4\ud55c \ud504\ub85c\uc138\uc2a4\ub97c \uc774\ud574\ud558\uace0, \uc0b0\uc5c5 \ubc0f \uacf5\ud559\uc801\uc778 \uacb0\uc815 \uc9c0\uc6d0\uc744 \uc704\ud55c \uc608\uce21 \ubaa8\ub378\uc758 \ud544\uc694\uc131\uc744 \uac15\uc870\ud55c\ub2e4.", "method": "Transformer \uc720\uc0ac \uad6c\uc870\ub97c \uae30\ubc18\uc73c\ub85c \ud55c \uc6d0\uce59\uc801 \uc124\uba85 \uac00\ub2a5\ud55c \uc2e0\uacbd \ud655\uc0b0 \ubaa8\ub378\uc778 ScaleSTF\ub97c \uc81c\uc548\ud558\uace0, \uc800\ucc28\uc6d0 \uc784\ubca0\ub529\uc744 \uc0ac\uc6a9\ud55c \uc8fc\uc758\uce35\uc744 \ub3c4\uc785\ud55c\ub2e4.", "result": "ScaleSTF\ub294 \uad50\ud1b5 \ud750\ub984, \ud0dc\uc591\uad11 \ubc1c\uc804, \uc2a4\ub9c8\ud2b8 \ubbf8\ud130\uc640 \uac19\uc740 \ub300\uaddc\ubaa8 \ub3c4\uc2dc \uc2dc\uc2a4\ud15c\uc5d0\uc11c \uc2e4\ud5d8\ub418\uc5c8\uace0, \ucd5c\ucca8\ub2e8 \uc131\ub2a5 \ubc0f \ub6f0\uc5b4\ub09c \ud655\uc7a5\uc131\uc744 \ubcf4\uc5ec\uc900\ub2e4.", "conclusion": "\ubcf8 \uc5f0\uad6c\ub294 \ub300\uaddc\ubaa8 \ub3c4\uc2dc \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c\uc758 \ub3d9\uc801 \uc608\uce21\uc5d0 \ub300\ud55c \uc0c8\ub85c\uc6b4 \uad00\uc810\uc744 \uc81c\uc2dc\ud558\uba70, \uae30\uc874 \ubaa8\ub378\uc758 \ud55c\uacc4\ub97c \uadf9\ubcf5\ud560 \uc218 \uc788\ub294 \uac00\ub2a5\uc131\uc744 \uc5f4\uc5b4\uc900\ub2e4."}}
{"id": "2508.00293", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.00293", "abs": "https://arxiv.org/abs/2508.00293", "authors": ["Md Sajidul Islam Sajid", "Jinpeng Wei", "Ehab Al-Shaer"], "title": "ranDecepter: Real-time Identification and Deterrence of Ransomware Attacks", "comment": "Accepted at IEEE Conference on Communications and Network Security\n  (CNS) 2025", "summary": "Ransomware (RW) presents a significant and widespread threat in the digital\nlandscape, necessitating effective countermeasures. Active cyber deception is a\npromising strategy to thwart RW and limiting its propagation by misleading it\nwith false information and revealing its true behaviors. Furthermore, RW often\nacts as a communication conduit between attackers and defenders, allowing\ndeception to return false data to attackers and deplete their resources. This\npaper introduces ranDecepter, a novel approach that combines active cyber\ndeception with real-time analysis to enhance defenses against RW attacks. The\nranDecepter identifies RW in real-time and isolates it within a deceptive\nenvironment, autonomously identifying critical elements in the RW code to\ncreate a loop mechanism. By repeatedly restarting the malware and transmitting\ncounterfeit encryption information and secret keys to the attacker, it forces\nthe attacker to store these fabricated details for each victim, thereby\ndepleting their resources. Our comprehensive evaluation of ranDecepter,\nconducted using 1,134 real-world malware samples and twelve benign\napplications, demonstrates a remarkable 100% accuracy in RW identification,\nwith no false positives and minimal impact on response times. Furthermore,\nwithin 24-hours, ranDecepter generates up to 9,223K entries in the attacker's\ndatabase using 50 agents, showcasing its potential to undermine attacker\nresources.", "AI": {"tldr": "ranDecepter\ub294 \uc2e4\uc2dc\uac04 \ubd84\uc11d\uacfc \ub2a5\ub3d9\uc801\uc778 \uc0ac\uc774\ubc84 \uae30\ub9cc\uc744 \uacb0\ud569\ud558\uc5ec \ub79c\uc12c\uc6e8\uc5b4 \uacf5\uaca9\uc5d0 \ub300\uc751\ud558\ub294 \uc0c8\ub85c\uc6b4 \uc811\uadfc \ubc29\uc2dd\uc744 \uc81c\uc2dc\ud55c\ub2e4.", "motivation": "\ub79c\uc12c\uc6e8\uc5b4\ub294 \ub514\uc9c0\ud138 \ud658\uacbd\uc5d0\uc11c \uc2ec\uac01\ud55c \uc704\ud611\uc73c\ub85c, \ud6a8\uacfc\uc801\uc778 \ub300\ucc45\uc774 \ud544\uc694\ud558\ub2e4.", "method": "ranDecepter\ub294 \ub79c\uc12c\uc6e8\uc5b4\ub97c \uc2e4\uc2dc\uac04\uc73c\ub85c \uc2dd\ubcc4\ud558\uace0 \uae30\ub9cc\uc801\uc778 \ud658\uacbd\uc5d0\uc11c \ubd84\ub9ac\ud558\uc5ec, \uc545\uc131 \ucf54\ub4dc\uc758 \uc8fc\uc694 \uc694\uc18c\ub97c \ud30c\uc545\ud558\uc5ec \ub8e8\ud504 \uba54\ucee4\ub2c8\uc998\uc744 \ud615\uc131\ud55c\ub2e4.", "result": "ranDecepter\ub294 1,134\uac1c\uc758 \uc2e4\uc81c \uc545\uc131 \uc0d8\ud50c\uc744 \ud3c9\uac00\ud558\uc5ec 100%\uc758 \ub79c\uc12c\uc6e8\uc5b4 \uc2dd\ubcc4 \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud558\uba70, \uc624\ud0d0\uc9c0 \uc5c6\uc774 \ucd5c\uc18c\ud55c\uc758 \uc751\ub2f5 \uc2dc\uac04 \uc9c0\uc5f0\uc744 \ubcf4\uc778\ub2e4.", "conclusion": "ranDecepter\ub294 50\uac1c\uc758 \uc5d0\uc774\uc804\ud2b8\ub97c \uc774\uc6a9\ud574 24\uc2dc\uac04 \ub0b4 9,223K\uc758 \uacf5\uaca9\uc790 \ub370\uc774\ud130\ubca0\uc774\uc2a4 \ud56d\ubaa9\uc744 \uc0dd\uc131\ud558\uba70, \uacf5\uaca9\uc790\uc758 \uc790\uc6d0\uc744 \uace0\uac08\uc2dc\ud0ac \uac00\ub2a5\uc131\uc774 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00039", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00039", "abs": "https://arxiv.org/abs/2508.00039", "authors": ["Kaustav Chatterjee", "Joshua Q. Li", "Fatemeh Ansari", "Masud Rana Munna", "Kundan Parajulee", "Jared Schwennesen"], "title": "Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings", "comment": null, "summary": "Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose\nsafety risks to highway vehicles due to potential hang-ups. These crossings\ntypically result from post-construction railway track maintenance activities or\nnon-compliance with design guidelines for HRGC vertical alignments.\nConventional methods for measuring HRGC profiles are costly, time-consuming,\ntraffic-disruptive, and present safety challenges. To address these issues,\nthis research employed advanced, cost-effective techniques and innovative\nmodeling approaches for HRGC profile measurement. A novel hybrid deep learning\nframework combining Long Short-Term Memory (LSTM) and Transformer architectures\nwas developed by utilizing instrumentation and ground truth data.\nInstrumentation data were gathered using a highway testing vehicle equipped\nwith Inertial Measurement Unit (IMU) and Global Positioning System (GPS)\nsensors, while ground truth data were obtained via an industrial-standard\nwalking profiler. Field data was collected at the Red Rock Railroad Corridor in\nOklahoma. Three advanced deep learning models Transformer-LSTM sequential\n(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel\n(model 3) were evaluated to identify the most efficient architecture. Models 2\nand 3 outperformed the others and were deployed to generate 2D/3D HRGC\nprofiles. The deep learning models demonstrated significant potential to\nenhance highway and railroad safety by enabling rapid and accurate assessment\nof HRGC hang-up susceptibility.", "AI": {"tldr": "\uc774 \uc5f0\uad6c\ub294 \uace0\uc18d\ub3c4\ub85c\uc640 \ucca0\ub3c4 \uc548\uc804\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 HRGC \ud504\ub85c\ud30c\uc77c \uce21\uc815\uc744 \uc704\ud55c \uc800\ube44\uc6a9\uc758 \ud601\uc2e0\uc801\uc778 \ub525\ub7ec\ub2dd \uae30\ubc95\uc744 \uac1c\ubc1c\ud558\uc600\ub2e4.", "motivation": "HRGC\ub294 \uace0\uc18d\ub3c4\ub85c \ucc28\ub7c9\uc5d0 \ub300\ud55c \uc548\uc804 \uc704\ud5d8\uc744 \ucd08\ub798\ud558\uace0, \uae30\uc874\uc758 \uce21\uc815 \ubc29\ubc95\uc740 \ube44\uc6a9\uacfc \uc2dc\uac04\uc774 \ub9ce\uc774 \uc18c\uc694\ub41c\ub2e4.", "method": "LSTM\uacfc Transformer \uc544\ud0a4\ud14d\ucc98\ub97c \uacb0\ud569\ud55c \ud558\uc774\ube0c\ub9ac\ub4dc \ub525\ub7ec\ub2dd \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ud65c\uc6a9\ud558\uc5ec, IMU\uc640 GPS \uc13c\uc11c\ub97c \ud1b5\ud574 \uc218\uc9d1\ub41c \ub370\uc774\ud130\ub85c HRGC \ud504\ub85c\ud30c\uc77c\uc744 \uce21\uc815\ud558\uc600\ub2e4.", "result": "\ubaa8\ub378 2\uc640 3\uc774 \uac00\uc7a5 \ub192\uc740 \uc131\ub2a5\uc744 \ubcf4\uc600\uc73c\uba70, \uc774 \ubaa8\ub378\ub4e4\uc744 \uc0ac\uc6a9\ud574 2D/3D HRGC \ud504\ub85c\ud30c\uc77c\uc744 \uc0dd\uc131\ud558\uc600\ub2e4.", "conclusion": "\uace0\uae09 \ub525\ub7ec\ub2dd \ubaa8\ub378\uc774 HRGC\uc758 \uc704\ud5d8\uc131\uc744 \uc2e0\uc18d\ud558\uace0 \uc815\ud655\ud558\uac8c \ud3c9\uac00\ud558\ub294 \ub370 \uc788\uc5b4 \uc7a0\uc7ac\ub825\uc774 \ud06c\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\uc5c8\ub2e4."}}
{"id": "2508.00351", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.00351", "abs": "https://arxiv.org/abs/2508.00351", "authors": ["Hyeonhak Kim", "Donghoe Heo", "Seokhie Hong"], "title": "Cryptanalysis of Isogeny-Based Quantum Money with Rational Points", "comment": null, "summary": "Quantum money is the cryptographic application of the quantum no-cloning\ntheorem. It has recently been instantiated by Montgomery and Sharif (Asiacrypt\n'24) from class group actions on elliptic curves. In this work, we propose a\nconcrete cryptanalysis by leveraging the efficiency of evaluating division\npolynomials with the coordinates of rational points, offering a speedup of\nO(log^4p) compared to the brute-force attack. Since our attack still requires\nexponential time, it remains impractical to forge a quantum banknote.\nInterestingly, due to the inherent properties of quantum money, our attack\nmethod also results in a more efficient verification procedure. Our algorithm\nleverages the properties of quadratic twists to utilize rational points in\nverifying the cardinality of the superposition of elliptic curves. We expect\nthis approach to contribute to future research on elliptic-curve-based quantum\ncryptography.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc5d0\uc11c\ub294 \ubabd\uace0\uba54\ub9ac\uc640 \uc0e4\ub9ac\ud504\uc758 \uc591\uc790 \ud654\ud3d0 \uae30\ubc95\uc744 \ubd84\uc11d\ud558\uace0, \ubd84\ud560 \ub2e4\ud56d\uc2dd \ud3c9\uac00 \ud6a8\uc728\uc131\uc744 \uc774\uc6a9\ud55c \uad6c\uccb4\uc801\uc778 \uc554\ud638 \ud574\ub3c5 \ubc29\ubc95\uc744 \uc81c\uc548\ud569\ub2c8\ub2e4.", "motivation": "\uc591\uc790 \ud654\ud3d0\uc758 \ubcf4\uc548\uc131\uc744 \ubd84\uc11d\ud558\uace0, \ud601\uc2e0\uc801\uc778 \uc554\ud638 \ud574\ub3c5 \ubc29\ubc95\uc744 \ud1b5\ud574 \ub354 \ud6a8\uc728\uc801\uc778 \uac80\uc99d \uc808\ucc28\ub97c \uc81c\uc2dc\ud558\uace0\uc790 \ud568.", "method": "\uc720\ub9ac\uc810\uc758 \uc88c\ud45c\ub97c \ud65c\uc6a9\ud55c \ubd84\ud560 \ub2e4\ud56d\uc2dd\uc758 \ud6a8\uc728\uc801\uc778 \ud3c9\uac00 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec O(log^4p)\uc758 \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \uaf80\ud568.", "result": "\uc81c\uc548\ub41c \uacf5\uaca9 \ubc29\ubc95\uc774 \uc5ec\uc804\ud788 \uc9c0\uc218 \uc2dc\uac04\uc774 \ud544\uc694\ud558\uc9c0\ub9cc, \ub354 \ud6a8\uc728\uc801\uc778 \uac80\uc99d \uc808\ucc28\ub97c \uc81c\uacf5\ud568.", "conclusion": "\uc774 \ubc29\uc2dd\uc740 elliptic-curve \uae30\ubc18\uc758 \uc591\uc790 \uc554\ud638\ud654 \uc5f0\uad6c\uc5d0 \uae30\uc5ec\ud560 \uac83\uc73c\ub85c \uae30\ub300\ub428."}}
{"id": "2508.00040", "categories": ["cs.LG", "math.PR", "stat.AP", "stat.ML", "60J20, 68T07"], "pdf": "https://arxiv.org/pdf/2508.00040", "abs": "https://arxiv.org/abs/2508.00040", "authors": ["Abhinav Das", "Stephan Schl\u00fcter"], "title": "Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting", "comment": null, "summary": "This work integrates Bayesian regime detection with conditional neural\nprocesses for 24-hour electricity price prediction in the German market. Our\nmethodology integrates regime detection using a disentangled sticky\nhierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to\ndaily electricity prices. Each identified regime is subsequently modeled by an\nindependent conditional neural process (CNP), trained to learn localized\nmappings from input contexts to 24-dimensional hourly price trajectories, with\nfinal predictions computed as regime-weighted mixtures of these CNP outputs. We\nrigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated\nauto-regressive (LEAR) models by integrating their forecasts into diverse\nbattery storage optimization frameworks, including price arbitrage, risk\nmanagement, grid services, and cost minimization. This operational utility\nassessment revealed complex performance trade-offs: LEAR often yielded superior\nabsolute profits or lower costs, while DNN showed exceptional optimality in\nspecific cost-minimization contexts. Recognizing that raw prediction accuracy\ndoesn't always translate to optimal operational outcomes, we employed TOPSIS as\na comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified\nLEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model\nemerged as the most balanced and preferred solution for 2021, 2022 and 2023.", "AI": {"tldr": "\ubcf8 \uc5f0\uad6c\ub294 \ub3c5\uc77c \uc2dc\uc7a5\uc758 24\uc2dc\uac04 \uc804\uae30 \uac00\uaca9 \uc608\uce21\uc744 \uc704\ud574 \ubca0\uc774\uc9c0\uc548 \ub808\uc9d0 \uac10\uc9c0\uc640 \uc870\uac74\ubd80 \uc2e0\uacbd \ud504\ub85c\uc138\uc2a4\ub97c \ud1b5\ud569\ud588\ub2e4.", "motivation": "\ub3c5\uc77c \uc804\uae30 \uc2dc\uc7a5\uc5d0\uc11c \ud6a8\uacfc\uc801\uc778 \uac00\uaca9 \uc608\uce21\uc744 \ud1b5\ud574 \uc5d0\ub108\uc9c0 \uac70\ub798 \ubc0f \ucd5c\uc801\ud654\ub97c \uac1c\uc120\ud558\uace0\uc790 \ud568.", "method": "\ub514\uc138\uc774\ud2c0\ub4dc \uc2a4\ud2f0\ud0a4 \uacc4\uce35 \ub514\ub9ac\ud074\ub808 \ud504\ub85c\uc138\uc2a4 \uc228\uaca8\uc9c4 \ub9c8\ub974\ucf54\ud504 \ubaa8\ub378(DS-HDP-HMM)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc77c\uc77c \uc804\uae30 \uac00\uaca9\uc5d0\uc11c \ub808\uc9d0\uc744 \uac10\uc9c0\ud558\uace0, \ub3c5\ub9bd\uc801\uc778 \uc870\uac74\ubd80 \uc2e0\uacbd \ud504\ub85c\uc138\uc2a4(CNP)\ub85c 24\ucc28\uc6d0 \uac00\uaca9 \uada4\uc801\uc744 \ubaa8\ub378\ub9c1.", "result": "R-NP \ubaa8\ub378\uc774 2021\ub144, 2022\ub144, 2023\ub144\uc758 \uac00\uc7a5 \uade0\ud615 \uc7a1\ud78c \uc194\ub8e8\uc158\uc73c\ub85c \ub098\ud0c0\ub0ac\uc73c\uba70, LEAR\ub294 2021\ub144 \ucd5c\uc0c1\uc704 \ubaa8\ub378\ub85c \ud3c9\uac00\ub418\uc5c8\ub2e4.", "conclusion": "\uac00\uaca9 \uc608\uce21\uc758 \uc815\ud655\uc131\uc774 \ud56d\uc0c1 \ucd5c\uc801\uc758 \uc6b4\uc601 \uacb0\uacfc\ub85c \uc774\uc5b4\uc9c0\uc9c0\ub294 \uc54a\uc73c\uba70, TOPSIS \ubd84\uc11d\uc744 \ud1b5\ud574 \ub2e4\uc591\ud55c \uc0c1\ud669\uc5d0\uc11c\uc758 \ubaa8\ub378 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\ub294 \uac83\uc774 \uc911\uc694\ud558\ub2e4."}}
{"id": "2508.00368", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00368", "abs": "https://arxiv.org/abs/2508.00368", "authors": ["Alessandro Gaudenzi", "Lorenzo Nodari", "Lance Kaplan", "Alessandra Russo", "Murat Sensoy", "Federico Cerutti"], "title": "Preliminary Investigation into Uncertainty-Aware Attack Stage Classification", "comment": "Proceedings for SPAIML2025 workshop, 26/10/2025 Bologna Italy,\n  co-located with ECAI2025", "summary": "Advanced Persistent Threats (APTs) represent a significant challenge in\ncybersecurity due to their prolonged, multi-stage nature and the sophistication\nof their operators. Traditional detection systems typically focus on\nidentifying malicious activity in binary terms (benign or malicious) without\naccounting for the progression of an attack. However, effective response\nstrategies depend on accurate inference of the attack's current stage, as\ncountermeasures must be tailored to whether an adversary is in the early\nreconnaissance phase or actively conducting exploitation or exfiltration. This\nwork addresses the problem of attack stage inference under uncertainty, with a\nfocus on robustness to out-of-distribution (OOD) inputs. We propose a\nclassification approach based on Evidential Deep Learning (EDL), which models\npredictive uncertainty by outputting parameters of a Dirichlet distribution\nover possible stages. This allows the system not only to predict the most\nlikely stage of an attack but also to indicate when it is uncertain or the\ninput lies outside the training distribution. Preliminary experiments in a\nsimulated environment demonstrate that the proposed model can accurately infer\nthe stage of an attack with calibrated confidence while effectively detecting\nOOD inputs, which may indicate changes in the attackers' tactics. These results\nsupport the feasibility of deploying uncertainty-aware models for staged threat\ndetection in dynamic and adversarial environments.", "AI": {"tldr": "\uc774 \uc5f0\uad6c\ub294 \uace0\uae09 \uc9c0\uc18d \uc704\ud611(APT)\uc758 \uacf5\uaca9 \ub2e8\uacc4\ub97c \ubd88\ud655\uc2e4\uc131 \ud558\uc5d0 \ucd94\ub860\ud558\uace0, \ubd84\ud3ec \uc678(out-of-distribution) \uc785\ub825\uc5d0 \uac15\uc778\ud55c \ubd84\ub958 \uc811\uadfc\ubc95\uc744 \uc81c\uc548\ud55c\ub2e4.", "motivation": "APTs\uc758 \ub2e4\ub2e8\uacc4 \uacf5\uaca9\uacfc \uc774\uc758 \ubcf5\uc7a1\uc131\uc73c\ub85c \uc778\ud574, \ud6a8\uacfc\uc801\uc778 \ub300\uc751 \uc804\ub7b5\uc744 \uc704\ud574 \uacf5\uaca9\uc758 \ud604\uc7ac \ub2e8\uacc4\ub97c \uc815\ud655\ud788 \ucd94\ub860\ud560 \ud544\uc694\uac00 \uc788\ub2e4.", "method": "Evidential Deep Learning(EDL)\uc5d0 \uae30\ubc18\ud55c \ubd84\ub958 \uc811\uadfc\ubc95\uc744 \uc81c\uc548\ud558\uba70, \uc774\ub294 \uac00\ub2a5\uc131 \uc788\ub294 \ub2e8\uacc4\uc5d0 \ub300\ud55c Dirichlet \ubd84\ud3ec\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \ucd9c\ub825\ud558\uc5ec \uc608\uce21 \ubd88\ud655\uc2e4\uc131\uc744 \ubaa8\ub378\ub9c1\ud55c\ub2e4.", "result": "\uc81c\uc548\ub41c \ubaa8\ub378\uc740 \uc2dc\ubbac\ub808\uc774\uc158 \ud658\uacbd\uc5d0\uc11c \uacf5\uaca9 \ub2e8\uacc4\ub97c \uc815\ud655\ud558\uac8c \ucd94\ub860\ud558\uba70, OOD \uc785\ub825\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ud0d0\uc9c0\ud558\ub294 \uc131\ub2a5\uc744 \ubcf4\uc600\ub2e4.", "conclusion": "\ubd88\ud655\uc2e4\uc131\uc744 \uc778\uc2dd\ud558\ub294 \ubaa8\ub378\uc744 \ub3d9\uc801\uc774\uace0 \uc801\ub300\uc801\uc778 \ud658\uacbd\uc5d0\uc11c \ub2e8\uacc4\uc801 \uc704\ud611 \ud0d0\uc9c0\uc5d0 \ubc30\ud3ec\ud560 \uc218 \uc788\uc74c\uc744 \uc9c0\uc9c0\ud558\ub294 \uacb0\uacfc\ub4e4\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00032", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2508.00032", "abs": "https://arxiv.org/abs/2508.00032", "authors": ["Alessio Buscemi", "Daniele Proverbio", "Alessandro Di Stefano", "The Anh Han", "German Castignani", "Pietro Li\u00f2"], "title": "Strategic Communication and Language Bias in Multi-Agent LLM Coordination", "comment": null, "summary": "Large Language Model (LLM)-based agents are increasingly deployed in\nmulti-agent scenarios where coordination is crucial but not always assured.\nPrevious studies indicate that the language used to frame strategic scenarios\ncan influence cooperative behavior. This paper explores whether allowing agents\nto communicate amplifies these language-driven effects. Leveraging the FAIRGAME\nframework, we simulate one-shot and repeated games across different languages\nand models, both with and without communication. Our experiments, conducted\nwith two advanced LLMs, GPT-4o and Llama 4 Maverick, reveal that communication\nsignificantly influences agent behavior, though its impact varies by language,\npersonality, and game structure. These findings underscore the dual role of\ncommunication in fostering coordination and reinforcing biases.", "AI": {"tldr": "\uc774 \uc5f0\uad6c\ub294 LLM \uae30\ubc18 \uc5d0\uc774\uc804\ud2b8\uc758 \ud611\ub3d9 \ud589\ub3d9\uc744 \ud615\uc131\ud558\ub294 \ub370 \uc788\uc5b4 \uc5b8\uc5b4\uc640 \uc758\uc0ac\uc18c\ud1b5\uc758 \uc601\ud5a5\uc744 \ud0d0\uad6c\ud55c\ub2e4.", "motivation": "\ub9ce\uc740 \uc5d0\uc774\uc804\ud2b8 \uac04\uc758 \ud611\ub825\uc774 \uc911\uc694\ud55c \uc0c1\ud669\uc5d0\uc11c \uc5b8\uc5b4\uac00 \uc804\ub7b5\uc801 \uc2dc\ub098\ub9ac\uc624\ub97c \ud615\uc131\ud558\uace0 \ud611\ub825 \ud589\ub3d9\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce5c\ub2e4\ub294 \uac83\uc744 \uc54c\uc558\ub2e4.", "method": "FAIRGAME \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ud65c\uc6a9\ud558\uc5ec \uc758\uc0ac\uc18c\ud1b5\uc758 \uc720\ubb34\uc5d0 \ub530\ub77c \ub2e4\uc591\ud55c \uc5b8\uc5b4 \ubc0f \ubaa8\ub378\uc5d0\uc11c \ub2e8\ubc1c \ubc0f \ubc18\ubcf5 \uac8c\uc784\uc744 \uc2dc\ubbac\ub808\uc774\uc158\ud558\uc600\ub2e4.", "result": "\ub450 \uac1c\uc758 \uace0\uae09 LLM(GPT-4o \ubc0f Llama 4 Maverick)\uc744 \uc0ac\uc6a9\ud55c \uc2e4\ud5d8\uc5d0\uc11c, \uc758\uc0ac\uc18c\ud1b5\uc740 \uc5d0\uc774\uc804\ud2b8 \ud589\ub3d9\uc5d0 \uc0c1\ub2f9\ud55c \uc601\ud5a5\uc744 \ubbf8\uce58\uc9c0\ub9cc, \uadf8 \uc601\ud5a5\uc740 \uc5b8\uc5b4, \uac1c\uc131 \ubc0f \uac8c\uc784 \uad6c\uc870\uc5d0 \ub530\ub77c \ub2ec\ub77c\uc9c4\ub2e4.", "conclusion": "\uc758\uc0ac\uc18c\ud1b5\uc740 \ud611\ub3d9\uc744 \ucd09\uc9c4\ud558\uace0 \ud3b8\uacac\uc744 \uac15\ud654\ud558\ub294 \uc774\uc911 \uc5ed\ud560\uc744 \ud55c\ub2e4."}}
{"id": "2508.00041", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.00041", "abs": "https://arxiv.org/abs/2508.00041", "authors": ["Yebo Wu", "Jingguang Li", "Zhijiang Guo", "Li Li"], "title": "Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages", "comment": null, "summary": "Federated fine-tuning enables Large Language Models (LLMs) to adapt to\ndownstream tasks while preserving data privacy, but its resource-intensive\nnature limits deployment on edge devices. In this paper, we introduce\nDevelopmental Federated Tuning (DevFT), a resource-efficient approach inspired\nby cognitive development that progressively builds a powerful LLM from a\ncompact foundation. DevFT decomposes the fine-tuning process into developmental\nstages, each optimizing submodels with increasing parameter capacity. Knowledge\nfrom earlier stages transfers to subsequent submodels, providing optimized\ninitialization parameters that prevent convergence to local minima and\naccelerate training. This paradigm mirrors human learning, gradually\nconstructing comprehensive knowledge structure while refining existing skills.\nTo efficiently build stage-specific submodels, DevFT introduces\ndeconfliction-guided layer grouping and differential-based layer fusion to\ndistill essential information and construct representative layers. Evaluations\nacross multiple benchmarks demonstrate that DevFT significantly outperforms\nstate-of-the-art methods, achieving up to 4.59$\\times$ faster convergence,\n10.67$\\times$ reduction in communication overhead, and 9.07% average\nperformance improvement, while maintaining compatibility with existing\napproaches.", "AI": {"tldr": "DevFT\ub294 \uc790\uc6d0\uc758 \ud6a8\uc728\uc801\uc778 \uc0ac\uc6a9\uc73c\ub85c LLM\uc744 \ubc1c\uc804\uc801\uc73c\ub85c \uc870\uc815\ud558\uc5ec \uac1c\uc778\uc815\ubcf4 \ubcf4\ud638\ub97c \uc720\uc9c0\ud558\uba70 \uc131\ub2a5\uacfc \uc18d\ub3c4\ub97c \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "motivation": "LLM\uc758 \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5\uc5d0 \ub300\ud55c \uc801\uc751\uc744 \uac00\ub2a5\ud558\uac8c \ud558\uba74\uc11c \ub370\uc774\ud130 \ud504\ub77c\uc774\ubc84\uc2dc\ub97c \uc720\uc9c0\ud558\uae30 \uc704\ud574, \uc790\uc6d0 \uc9d1\uc57d\uc801\uc778 \uc5f0\uc2b5\uc744 \ube0c\ub77c\uc6b0\uc2a4\uc801\uc778 \ubc29\uc2dd\uc73c\ub85c \ud574\uacb0\ud558\uace0\uc790 \ud568.", "method": "DevFT\ub294 \ubc1c\uc804\uc801 \ub2e8\uacc4\ub97c \ud1b5\ud574 \ubbf8\uc138 \uc870\uc815 \uacfc\uc815\uc744 \ubd84\ud574\ud558\uc5ec \ub9e4\uac1c\ubcc0\uc218 \uc6a9\ub7c9\uc774 \uc99d\uac00\ud558\ub294 \ud558\uc704 \ubaa8\ub378\uc744 \ucd5c\uc801\ud654\ud569\ub2c8\ub2e4. \uc774\uc804 \ub2e8\uacc4\uc758 \uc9c0\uc2dd\uc744 \ub2e4\uc74c \ud558\uc704 \ubaa8\ub378\ub85c \uc804\ub2ec\ud569\ub2c8\ub2e4.", "result": "DevFT\ub294 \uc5ec\ub7ec \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uae30\uc874 \ubc29\ubc95\ub4e4\uacfc \ube44\uad50\ud558\uc5ec \ucd5c\ub300 4.59\ubc30 \ube60\ub978 \uc218\ub834, 10.67\ubc30 \ud1b5\uc2e0 \uc624\ubc84\ud5e4\ub4dc \uac10\uc18c, 9.07% \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ub2ec\uc131\ud588\uc2b5\ub2c8\ub2e4.", "conclusion": "DevFT\ub294 \uae30\uc874 \uc811\uadfc \ubc29\uc2dd\uacfc \ud638\ud658\uc131\uc744 \uc720\uc9c0\ud558\uba74\uc11c\ub3c4 \uc0c1\ub2f9\ud55c \uc131\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uba70, \uc778\uac04 \ud559\uc2b5\uc744 \ubaa8\ubc29\ud55c \ubc1c\uc804\uc801 \ubaa8\ub378\ub85c \uc790\uc6d0 \ud6a8\uc728\uc801\uc778 \ubc29\ubc95\uc744 \uc81c\uc548\ud569\ub2c8\ub2e4."}}
{"id": "2508.00434", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.00434", "abs": "https://arxiv.org/abs/2508.00434", "authors": ["Yuqi Qian", "Yun Cao", "Meiyang Lv", "Haocheng Fu"], "title": "Accurate Latent Inversion for Generative Image Steganography via Rectified Flow", "comment": null, "summary": "Steganography based on diffusion models has attracted increasing attention\ndue to its ability to generate high-quality images and exhibit strong\nrobustness. In such approaches, the secret message is first embedded into the\ninitial latent variable, and then the stego image is generated through the\nforward process. To extract the message, an inversion process is required to\nreconstruct the latent variables from the received image. However, inaccurate\nlatent inversion leads to significant discrepancies between the reconstructed\nand original latent variables, rendering message extraction infeasible. To\naddress this issue, we propose \\textbf{RF-Stego}, a novel generative image\nsteganography method that enables accurate latent inversion and significantly\nimproves extraction accuracy. First, we develop the \\textbf{P}ath\n\\textbf{C}onsistency \\textbf{L}inear \\textbf{I}nversion (\\textbf{PCLI}), which\nimposes formal constraints on the inversion process. By explicitly aligning it\nwith the forward generation path and modeling both directions along a shared\nlinear path, PCLI eliminates path mismatch and ensures path consistency\nthroughout the steganographic process. Second, through rigorous theoretical\nproof, we demonstrate that \\textbf{R}ectified \\textbf{F}low \\textbf{(RF)}\noffers both theoretical reversibility and numerical stability in the inversion\nprocess. Based on this, we replace traditional unstable samplers with RF\nsampler which effectively improves the numerical precision of the inversion\nprocess. Experimental results show RF-Stego outperforms state-of-the-art\nmethods in terms of extraction accuracy, image quality, robustness, security\nand generation efficiency.", "AI": {"tldr": "RF-Stego\ub294 \uace0\ud488\uc9c8 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uace0 \uac15\ub825\ud55c \uac15\uc778\uc131\uc744 \ubcf4\uc774\ub294 \uc0c8\ub85c\uc6b4 \uc0dd\uc131 \uc774\ubbf8\uc9c0 \uc2a4\ud14c\uac00\ub178\uadf8\ub798\ud53c \ubc29\ubc95\uc73c\ub85c, \uc815\ud655\ud55c \uc7a0\uc7ac \uc5ed\uc804\uacfc \uba54\uc2dc\uc9c0 \ucd94\ucd9c \uc815\ud655\ub3c4\ub97c \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4.", "motivation": "\uc2a4\ud14c\uac00\ub178\uadf8\ub798\ud53c\uc758 \uc815\ud655\ud55c \uba54\uc2dc\uc9c0 \ucd94\ucd9c\uc744 \uc704\ud55c \uc7a0\uc7ac \uc5ed\uc804\uc758 \ubd88\ud655\uc2e4\uc131\uc744 \ud574\uacb0\ud558\uae30 \uc704\ud574.", "method": "Path Consistency Linear Inversion(PCLI)\uc640 Rectified Flow(RF)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc7a0\uc7ac \uc5ed\uc804\uc744 \uc815\ud655\ud558\uac8c \uc218\ud589\ud558\uace0 \uc218\uce58\uc801 \uc548\uc815\uc131\uc744 \ub192\uc778\ub2e4.", "result": "RF-Stego\ub294 \uae30\uc874\uc758 \ucd5c\ucca8\ub2e8 \ubc29\ubc95\ubcf4\ub2e4 \ucd94\ucd9c \uc815\ud655\ub3c4, \uc774\ubbf8\uc9c0 \ud488\uc9c8, \uac15\uc778\uc131, \ubcf4\uc548 \ubc0f \uc0dd\uc131 \ud6a8\uc728\uc131\uc5d0\uc11c \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc778\ub2e4.", "conclusion": "RF-Stego\ub294 \uc2a4\ud14c\uac00\ub178\uadf8\ub798\ud53c \uacfc\uc815\uc5d0\uc11c \uacbd\ub85c \uc77c\uce58\ub97c \ubcf4\uc7a5\ud558\uc5ec \uba54\uc2dc\uc9c0 \ucd94\ucd9c\uc758 \uc815\ud655\uc131\uc744 \ub192\uc778\ub2e4."}}
{"id": "2508.00280", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2508.00280", "abs": "https://arxiv.org/abs/2508.00280", "authors": ["Jingchen Peng", "Dingli Yuan", "Boxiang Ren", "Jie Fan", "Hao Wu", "Lu Yang"], "title": "WMAS: A Multi-Agent System Towards Intelligent and Customized Wireless Networks", "comment": null, "summary": "The fast development of Artificial Intelligence (AI) agents provides a\npromising way for the realization of intelligent and customized wireless\nnetworks. In this paper, we propose a Wireless Multi-Agent System (WMAS), which\ncan provide intelligent and customized services for different user equipment\n(UEs). Note that orchestrating multiple agents carries the risk of malfunction,\nand multi-agent conversations may fall into infinite loops. It is thus crucial\nto design a conversation topology for WMAS that enables agents to complete UE\ntask requests with high accuracy and low conversation overhead. To address this\nissue, we model the multi-agent conversation topology as a directed acyclic\ngraph and propose a reinforcement learning-based algorithm to optimize the\nadjacency matrix of this graph. As such, WMAS is capable of generating and\nself-optimizing multi-agent conversation topologies, enabling agents to\neffectively and collaboratively handle a variety of task requests from UEs.\nSimulation results across various task types demonstrate that WMAS can achieve\nhigher task performance and lower conversation overhead compared to existing\nmulti-agent systems. These results validate the potential of WMAS to enhance\nthe intelligence of future wireless networks.", "AI": {"tldr": "WMAS\ub294 \uc0ac\uc6a9\uc790 \uc7a5\ube44\ub97c \uc704\ud55c \uc9c0\ub2a5\ud615 \uc11c\ube44\uc2a4\ub97c \uc81c\uacf5\ud558\uba70, \ub300\ud654 \ud1a0\ud3f4\ub85c\uc9c0\ub97c \ucd5c\uc801\ud654\ud558\uc5ec \ud6a8\uc728\uc801\uc778 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc791\uc5c5 \ucc98\ub9ac\ub97c \uac00\ub2a5\ud558\uac8c \ud55c\ub2e4.", "motivation": "AI \uc5d0\uc774\uc804\ud2b8\uc758 \ubc1c\uc804\uc740 \uc9c0\ub2a5\uc801\uc774\uace0 \ub9de\ucda4\ud615 \ubb34\uc120 \ub124\ud2b8\uc6cc\ud06c\uc758 \uc2e4\ud604 \uac00\ub2a5\uc131\uc744 \uc81c\uacf5\ud55c\ub2e4.", "method": "\ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ub300\ud654 \ud1a0\ud3f4\ub85c\uc9c0\ub97c \uc720\ud5a5 \ube44\uc21c\ud658 \uadf8\ub798\ud504\ub85c \ubaa8\ub378\ub9c1\ud558\uace0, \uac15\ud654 \ud559\uc2b5 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc778\uc811 \ud589\ub82c\uc744 \ucd5c\uc801\ud654\ud55c\ub2e4.", "result": "WMAS\ub294 \ub2e4\uc591\ud55c \uc791\uc5c5 \uc720\ud615\uc5d0 \ub300\ud55c \uc2dc\ubbac\ub808\uc774\uc158 \uacb0\uacfc\uc5d0\uc11c \uae30\uc874 \uc2dc\uc2a4\ud15c \ub300\ube44 \ub354 \ub192\uc740 \uc791\uc5c5 \uc131\uacfc\uc640 \ub0ae\uc740 \ub300\ud654 \uc624\ubc84\ud5e4\ub4dc\ub97c \ub2ec\uc131\ud588\ub2e4.", "conclusion": "WMAS\ub294 \ubbf8\ub798\uc758 \ubb34\uc120 \ub124\ud2b8\uc6cc\ud06c\uc758 \uc9c0\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0ac \uc7a0\uc7ac\ub825\uc744 \uc785\uc99d\ud558\uc600\ub2e4."}}
{"id": "2508.00081", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00081", "abs": "https://arxiv.org/abs/2508.00081", "authors": ["Fred Mutisya", "Shikoh Gitau", "Nasubo Ongoma", "Keith Mbae", "Elizabeth Wamicha"], "title": "Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench", "comment": null, "summary": "HealthBench, a benchmark designed to measure the capabilities of AI systems\nfor health better (Arora et al., 2025), has advanced medical language model\nevaluation through physician-crafted dialogues and transparent rubrics.\nHowever, its reliance on expert opinion, rather than high-tier clinical\nevidence, risks codifying regional biases and individual clinician\nidiosyncrasies, further compounded by potential biases in automated grading\nsystems. These limitations are particularly magnified in low- and middle-income\nsettings, where issues like sparse neglected tropical disease coverage and\nregion-specific guideline mismatches are prevalent.\n  The unique challenges of the African context, including data scarcity,\ninadequate infrastructure, and nascent regulatory frameworks, underscore the\nurgent need for more globally relevant and equitable benchmarks. To address\nthese shortcomings, we propose anchoring reward functions in version-controlled\nClinical Practice Guidelines (CPGs) that incorporate systematic reviews and\nGRADE evidence ratings.\n  Our roadmap outlines \"evidence-robust\" reinforcement learning via\nrubric-to-guideline linkage, evidence-weighted scoring, and contextual override\nlogic, complemented by a focus on ethical considerations and the integration of\ndelayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,\nwhile preserving HealthBench's transparency and physician engagement, we aim to\nfoster medical language models that are not only linguistically polished but\nalso clinically trustworthy, ethically sound, and globally relevant.", "AI": {"tldr": "HealthBench\ub294 AI \uc2dc\uc2a4\ud15c\uc758 \uac74\uac15 \ub2a5\ub825\uc744 \uce21\uc815\ud558\uae30 \uc704\ud55c \ubca4\uce58\ub9c8\ud06c\ub85c \uc758\uc0ac\ub4e4\uc774 \ub9cc\ub4e0 \ub300\ud654 \ubc0f \ud22c\uba85\ud55c \ub8e8\ube0c\ub9ad\uc744 \ud1b5\ud574 \uc758\ub8cc \uc5b8\uc5b4 \ubaa8\ub378 \ud3c9\uac00\ub97c \ubc1c\uc804\uc2dc\ucf30\uc9c0\ub9cc, \uc804\ubb38\uac00 \uc758\uacac\uc5d0 \uc758\uc874\ud568\uc73c\ub85c\uc368 \ubc1c\uc0dd\ud558\ub294 \uc9c0\uc5ed\uc801 \ud3b8\ud5a5\uacfc \uc784\uc0c1 \uadfc\uac70 \ubd80\uc871\uc758 \uc704\ud5d8\uc774 \uc788\ub2e4. \uc774\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 \uc6b0\ub9ac\ub294 \uc784\uc0c1 \uad00\ud589 \uc9c0\uce68\uc5d0 \uae30\ubc18\ud55c \uac15\ud654 \ud559\uc2b5 \uc811\uadfc \ubc29\uc2dd\uc744 \uc81c\uc548\ud55c\ub2e4.", "motivation": "AI \uc2dc\uc2a4\ud15c\uc774 \uac74\uac15 \ubd84\uc57c\uc5d0\uc11c \uc131\uacfc\ub97c \uc81c\ub300\ub85c \uce21\uc815\ud558\uae30 \uc704\ud574 \uc784\uc0c1\uc801 \ud3b8\ud5a5\uc744 \uc904\uc774\uace0 \ubcf4\ub2e4 \uacf5\uc815\ud55c \uae30\uc900\uc774 \ud544\uc694\ud558\ub2e4.", "method": "\ubaa8\ub4e0 \uac83\uc744 \uccb4\uacc4\uc801\uc778 \ub9ac\ubdf0\uc640 GRADE \uc99d\uac70 \ub4f1\uae09\uc774 \ud3ec\ud568\ub41c \ubc84\uc804 \uad00\ub9ac\ub41c CPG\uc5d0 \uae30\ubc18\ud558\uc5ec \ud3c9\uac00\ud558\ub294 \ubc29\ud5a5\uc73c\ub85c \uac15\ud654 \ud559\uc2b5\uc744 \uc9c4\ud589\ud55c\ub2e4.", "result": "\uc81c\uc548\ub41c \ubc29\ubc95\uc740 \uc758\ub8cc \uc5b8\uc5b4 \ubaa8\ub378\uc774 \uc5b8\uc5b4\uc801\uc73c\ub85c \uc815\uc81c\ub428\uc740 \ubb3c\ub860 \uc784\uc0c1\uc801\uc73c\ub85c \uc2e0\ub8b0\ud560 \uc218 \uc788\ub294 \uacb0\uacfc\ub97c \ub3c4\ucd9c\ud558\ub3c4\ub85d \ud55c\ub2e4.", "conclusion": "HealthBench\uc758 \ud22c\uba85\uc131\uacfc \uc758\uc0ac \ucc38\uc5ec\ub97c \uc720\uc9c0\ud558\uba74\uc11c\ub3c4 \uc784\uc0c1 \uad00\ud589 \uc9c0\uce68\uc5d0\uc11c \uc5c4\uaca9\ud558\uac8c \uac80\ud1a0\ub41c \ubcf4\uc0c1\uc73c\ub85c \uc7ac\ud1a0\ub300\ub97c \ub9c8\ub828\ud558\uc5ec \uc138\uacc4\uc801\uc73c\ub85c \uad00\ub828\uc131\uc774 \ub192\uc740 \uc758\ub8cc \uc5b8\uc5b4 \ubaa8\ub378\uc744 \ucd09\uc9c4\ud558\ub294 \uac83\uc744 \ubaa9\ud45c\ub85c \ud55c\ub2e4."}}
{"id": "2508.00043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00043", "abs": "https://arxiv.org/abs/2508.00043", "authors": ["Nhut Truong", "Uri Hasson"], "title": "Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity", "comment": null, "summary": "Topographic neural networks are computational models that can simulate the\nspatial and functional organization of the brain. Topographic constraints in\nneural networks can be implemented in multiple ways, with potentially different\nimpacts on the representations learned by the network. The impact of such\ndifferent implementations has not been systematically examined. To this end,\nhere we compare topographic convolutional neural networks trained with two\nspatial constraints: Weight Similarity (WS), which pushes neighboring units to\ndevelop similar incoming weights, and Activation Similarity (AS), which\nenforces similarity in unit activations. We evaluate the resulting models on\nclassification accuracy, robustness to weight perturbations and input\ndegradation, and the spatial organization of learned representations. Compared\nto both AS and standard CNNs, WS provided three main advantages: i) improved\nrobustness to noise, also showing higher accuracy under weight corruption; ii)\ngreater input sensitivity, reflected in higher activation variance; and iii)\nstronger functional localization, with units showing similar activations\npositioned at closer distances. In addition, WS produced differences in\norientation tuning, symmetry sensitivity, and eccentricity profiles of units,\nindicating an influence of this spatial constraint on the representational\ngeometry of the network. Our findings suggest that during end-to-end training,\nWS constraints produce more robust representations than AS or non-topographic\nCNNs. These findings also suggest that weight-based spatial constraints can\nshape feature learning and functional organization in biophysical inspired\nmodels.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc774\uc6c3 \uc720\ub2db \uac04\uc758 \uac00\uc911\uce58 \uc720\uc0ac\uc131(WS)\uacfc \ud65c\uc131\ud654 \uc720\uc0ac\uc131(AS)\uc774\ub77c\ub294 \ub450 \uac00\uc9c0 \uacf5\uac04 \uc81c\uc57d\uc744 \uac00\uc9c4 \ud1a0\ud3ec\uadf8\ub798\ud53d \ucee8\ubcfc\ub8e8\uc158 \uc2e0\uacbd\ub9dd\uc744 \ube44\uad50\ud558\uc5ec \uac01\uac01\uc758 \uc601\ud5a5\ub825\uc744 \ud3c9\uac00\ud588\ub2e4.", "motivation": "\ud1a0\ud3ec\uadf8\ub798\ud53d \uc2e0\uacbd\ub9dd\uc740 \ub1cc\uc758 \uacf5\uac04\uc801 \ubc0f \uae30\ub2a5\uc801 \uc870\uc9c1\uc744 \ubaa8\ubc29\ud560 \uc218 \uc788\ub294 \uacc4\uc0b0 \ubaa8\ub378\uc774\ub2e4.", "method": "WS\ub294 \uc774\uc6c3 \uc720\ub2db\ub4e4\uc774 \uc720\uc0ac\ud55c \uc785\ub825 \uac00\uc911\uce58\ub97c \uac16\uac8c \ud558\ub294 \ubc18\uba74, AS\ub294 \uc720\ub2db \ud65c\uc131\ud654\ub97c \uc720\uc0ac\ud558\uac8c \uc720\uc9c0\ud558\uac8c \ud55c\ub2e4.", "result": "WS\ub294 \ub178\uc774\uc988\uc5d0 \ub300\ud55c \uac15\uc778\uc131\uc774 \uac1c\uc120\ub418\uace0, \ud65c\uc131\ud654 \ubd84\uc0b0\uc774 \uc99d\uac00\ud558\uba70, \uae30\ub2a5\uc801 \ub85c\uceec\ub77c\uc774\uc81c\uc774\uc158\uc774 \uac15\ud654\ub418\ub294 \ub4f1\uc758 \uc7a5\uc810\uc744 \ubcf4\uc5ec\uc8fc\uc5c8\ub2e4.", "conclusion": "WS \uc81c\uc57d\uc740 AS\ub098 \ube44\ud1a0\ud3ec\uadf8\ub798\ud53d CNN\ubcf4\ub2e4 \ub354 \uac15\ub825\ud55c \ud45c\ud604\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\ub2e4."}}
{"id": "2508.00478", "categories": ["cs.CR", "cs.AI", "91A10, 91A43, 68T01, 94A60", "C.2.0; I.2.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2508.00478", "abs": "https://arxiv.org/abs/2508.00478", "authors": ["Yuning Jiang", "Nay Oo", "Qiaoran Meng", "Lu Lin", "Dusit Niyato", "Zehui Xiong", "Hoon Wei Lim", "Biplab Sikdar"], "title": "CyGATE: Game-Theoretic Cyber Attack-Defense Engine for Patch Strategy Optimization", "comment": null, "summary": "Modern cyber attacks unfold through multiple stages, requiring defenders to\ndynamically prioritize mitigations under uncertainty. While game-theoretic\nmodels capture attacker-defender interactions, existing approaches often rely\non static assumptions and lack integration with real-time threat intelligence,\nlimiting their adaptability. This paper presents CyGATE, a game-theoretic\nframework modeling attacker-defender interactions, using large language models\n(LLMs) with retrieval-augmented generation (RAG) to enhance tactic selection\nand patch prioritization. Applied to a two-agent scenario, CyGATE frames cyber\nconflicts as a partially observable stochastic game (POSG) across Cyber Kill\nChain stages. Both agents use belief states to navigate uncertainty, with the\nattacker adapting tactics and the defender re-prioritizing patches based on\nevolving risks and observed adversary behavior. The framework's flexible\narchitecture enables extension to multi-agent scenarios involving coordinated\nattackers, collaborative defenders, or complex enterprise environments with\nmultiple stakeholders. Evaluated in a dynamic patch scheduling scenario, CyGATE\neffectively prioritizes high-risk vulnerabilities, enhancing adaptability\nthrough dynamic threat integration, strategic foresight by anticipating\nattacker moves under uncertainty, and efficiency by optimizing resource use.", "AI": {"tldr": "CyGATE\ub294 \uc2e4\uc2dc\uac04 \uc704\ud611 \uc815\ubcf4\ub97c \ud1b5\ud569\ud558\uc5ec \uacf5\uaca9\uc790-\ubc29\uc5b4\uc790 \uc0c1\ud638\uc791\uc6a9\uc744 \ubaa8\ub378\ub9c1\ud558\ub294 \uac8c\uc784 \uc774\ub860 \uae30\ubc18 \ud504\ub808\uc784\uc6cc\ud06c\ub85c, \ub3d9\uc801 \uc704\ud611 \ud1b5\ud569 \ubc0f \uc790\uc6d0 \ucd5c\uc801\ud654\ub97c \ud1b5\ud574 \uacf5\uaca9 \ubd84\uc11d \ubc0f \ud328\uce58 \uc6b0\uc120\uc21c\uc704\ub97c \uac1c\uc120\ud55c\ub2e4.", "motivation": "\ud604\ub300 \uc0ac\uc774\ubc84 \uacf5\uaca9\uc740 \uc5ec\ub7ec \ub2e8\uacc4\ub97c \uac70\uce58\uba70, \ubc29\uc5b4\uc790\ub294 \ubd88\ud655\uc2e4\uc131 \uc18d\uc5d0\uc11c \ub3d9\uc801\uc73c\ub85c \uc644\ud654 \uc870\uce58\ub97c \uc6b0\uc120\uc2dc\ud574\uc57c \ud55c\ub2e4.", "method": "CyGATE\ub294 \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378(LLMs)\uacfc \uac80\uc0c9 \uc99d\uac15 \uc0dd\uc131(RAG)\uc744 \ud65c\uc6a9\ud558\uc5ec \uacf5\uaca9\uc790-\ubc29\uc5b4\uc790 \uc0c1\ud638\uc791\uc6a9\uc744 \ubaa8\ub378\ub9c1\ud558\uba70, \ubd80\ubd84 \uad00\ucc30 \ud655\ub960 \uac8c\uc784(POSG)\uc73c\ub85c \uc0ac\uc774\ubc84 \ucda9\ub3cc\uc744 \ud504\ub808\uc784\ud654\ud55c\ub2e4.", "result": "CyGATE\ub294 \ub3d9\uc801 \ud328\uce58 \uc2a4\ucf00\uc904\ub9c1 \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \ub192\uc740 \uc704\ud5d8\uc758 \ucde8\uc57d\uc810\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \uc6b0\uc120\uc21c\uc704\ub97c \uc815\ud558\uace0, \uacf5\uaca9\uc790\uc758 \ud589\ub3d9\uc744 \uc608\uce21\ud558\uc5ec \uc801\uc751\uc131\uacfc \ud6a8\uc728\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4.", "conclusion": "\uc774 \ud504\ub808\uc784\uc6cc\ud06c\ub294 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\ub098\ub9ac\uc624\uc5d0 \ud655\uc7a5 \uac00\ub2a5\ud558\uba70, \ubcf5\uc7a1\ud55c \ud658\uacbd\uc5d0\uc11c\uc758 \uc0ac\uc774\ubc84 \ubcf4\uc548 \ubc29\uc5b4\uc5d0 \ud6a8\uacfc\uc801\uc774\ub2e4."}}
{"id": "2508.00401", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.00401", "abs": "https://arxiv.org/abs/2508.00401", "authors": ["Riddhi J. Pitliya", "Ozan Catal", "Toon Van de Maele", "Corrado Pezzato", "Tim Verbelen"], "title": "Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation", "comment": null, "summary": "We present a novel approach to multi-agent cooperation by implementing theory\nof mind (ToM) within active inference. ToM - the ability to understand that\nothers can have differing knowledge and goals - enables agents to reason about\nothers' beliefs while planning their own actions. Unlike previous active\ninference approaches to multi-agent cooperation, our method neither relies on\ntask-specific shared generative models nor requires explicit communication,\nwhile being generalisable. In our framework, the ToM-equipped agent maintains\ndistinct representations of its own and others' beliefs and goals. We extend\nthe sophisticated inference tree-based planning algorithm to systematically\nexplore joint policy spaces through recursive reasoning. Our approach is\nevaluated through collision avoidance and foraging task simulations. Results\ndemonstrate that ToM-equipped agents cooperate better compared to non-ToM\ncounterparts by being able to avoid collisions and reduce redundant efforts.\nCrucially, ToM agents accomplish this by inferring others' beliefs solely from\nobservable behaviour. This work advances practical applications in artificial\nintelligence while providing computational insights into ToM.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \ub2a5\ub3d9\uc801 \ucd94\ub860 \ub0b4\uc5d0\uc11c \ub9c8\uc74c\uc758 \uc774\ub860\uc744 \uad6c\ud604\ud558\uc5ec \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ud611\ub825\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \uc811\uadfc \ubc29\uc2dd\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "motivation": "\ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\uc2a4\ud15c\uc5d0\uc11c\uc758 \ud611\ub825\uc744 \uac1c\uc120\ud558\uae30 \uc704\ud574 \ud0c0\uc778\uc758 \ubbff\uc74c\uacfc \ubaa9\ud45c\ub97c \uc774\ud574\ud558\ub294 \ub2a5\ub825\uc778 \ub9c8\uc74c\uc758 \uc774\ub860\uc744 \ud65c\uc6a9\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.", "method": "ToM \uae30\ub2a5\uc744 \uac16\ucd98 \uc5d0\uc774\uc804\ud2b8\uac00 \uc790\uc2e0\uc758 \ubbff\uc74c\uacfc \ub2e4\ub978 \uc5d0\uc774\uc804\ud2b8\uc758 \ubbff\uc74c\uc744 \uac01\uac01 \uc720\uc9c0\ud558\uba70, \uc7ac\uadc0\uc801 \ucd94\ub860\uc744 \ud1b5\ud574 \uacf5\ub3d9 \uc815\ucc45 \uacf5\uac04\uc744 \ud0d0\uc0c9\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \uacc4\ud68d \uc54c\uace0\ub9ac\uc998\uc744 \ud655\uc7a5\ud558\uc600\uc2b5\ub2c8\ub2e4.", "result": "ToM \uae30\ub2a5\uc744 \uac16\ucd98 \uc5d0\uc774\uc804\ud2b8\uac00 \ucda9\ub3cc \ud68c\ud53c \ubc0f \ucc44\uc9d1 \uc791\uc5c5 \uc2dc \ube44 ToM \uc5d0\uc774\uc804\ud2b8\ubcf4\ub2e4 \ub354 \ud6a8\uacfc\uc801\uc73c\ub85c \ud611\uc870\ud558\uc600\uc73c\uba70, \ucda9\ub3cc\uc744 \ud53c\ud558\uace0 \uc911\ubcf5 \ub178\ub825\uc744 \uc904\uc774\ub294 \ub370 \uc131\uacf5\ud558\uc600\uc2b5\ub2c8\ub2e4.", "conclusion": "\uad00\ucc30 \uac00\ub2a5\ud55c \ud589\ub3d9\ub9cc\uc73c\ub85c \ud0c0\uc778\uc758 \ubbff\uc74c\uc744 \ucd94\ub860\ud568\uc73c\ub85c\uc368 ToM \uc5d0\uc774\uc804\ud2b8\ub294 \ud611\ub825 \uc131\uacfc\ub97c \uadf9\ub300\ud654\ud568\uc744 \ubcf4\uc5ec\uc8fc\uc5c8\uc73c\uba70, \uc774\ub294 \uc778\uacf5\uc9c0\ub2a5\uc758 \uc2e4\uc9c8\uc801\uc778 \uc751\uc6a9 \uac00\ub2a5\uc131\uc744 \ub192\uc774\uace0 \ud0c0\uc778\uc758 \uc774\ub860\uc5d0 \ub300\ud55c \uacc4\uc0b0\uc801 \ud1b5\ucc30\ub825\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4."}}
{"id": "2508.00106", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.00106", "abs": "https://arxiv.org/abs/2508.00106", "authors": ["Ernest Bonnah", "Luan Viet Nguyen", "Khaza Anuarul Hoque"], "title": "Hyperproperty-Constrained Secure Reinforcement Learning", "comment": "Accepted in IEEE/ACM MEMOCODE 2025", "summary": "Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a\ndomain-specific formal specification language known for its effectiveness in\ncompactly representing security, opacity, and concurrency properties for\nrobotics applications. This paper focuses on HyperTWTL-constrained secure\nreinforcement learning (SecRL). Although temporal logic-constrained safe\nreinforcement learning (SRL) is an evolving research problem with several\nexisting literature, there is a significant research gap in exploring\nsecurity-aware reinforcement learning (RL) using hyperproperties. Given the\ndynamics of an agent as a Markov Decision Process (MDP) and opacity/security\nconstraints formalized as HyperTWTL, we propose an approach for learning\nsecurity-aware optimal policies using dynamic Boltzmann softmax RL while\nsatisfying the HyperTWTL constraints. The effectiveness and scalability of our\nproposed approach are demonstrated using a pick-up and delivery robotic mission\ncase study. We also compare our results with two other baseline RL algorithms,\nshowing that our proposed method outperforms them.", "AI": {"tldr": "\ud558\uc774\ud37c\uc18d\uc131 \uc2dc\uac04 \ucc3d \ud15c\ud3ec\ub7f4 \ub85c\uc9c1(HyperTWTL) \uae30\ubc18\uc758 \uc548\uc804 \uac15\ud654 \ud559\uc2b5(SecRL) \ubc29\ubc95\uc744 \uc81c\uc548\ud558\uba70, \uc774\ub97c \ud1b5\ud574 \ubcf4\uc548 \uc778\uc2dd \ucd5c\uc801 \uc815\ucc45\uc744 \ud559\uc2b5\ud558\uace0 \uc131\ub2a5\uc744 \uac1c\uc120\ud568\uc744 \uc785\uc99d.", "motivation": "\ud558\uc774\ud37c\uc18d\uc131 \uae30\ubc18\uc758 \ubcf4\uc548 \uc778\uc2dd \uac15\ud654 \ud559\uc2b5\uc5d0 \ub300\ud55c \uc5f0\uad6c \uacf5\ubc31\uc744 \uba54\uc6b0\uace0, \ub85c\ubd07 \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc5d0\uc11c \ubcf4\uc548 \ubc0f \ud22c\uba85\uc131\uc744 \uace0\ub824\ud55c \uc815\ucc45 \ud559\uc2b5\uc758 \ud544\uc694\uc131\uc744 \uac15\uc870.", "method": "\ud558\uc774\ud37cTWTL \uc81c\uc57d \uc870\uac74\uc744 \ub9cc\uc871\ud558\uba74\uc11c \ub3d9\uc801 \ubcfc\uce20\ub9cc \uc18c\ud504\ud2b8\ub9e5\uc2a4 \uac15\ud654 \ud559\uc2b5\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubcf4\uc548 \uc778\uc2dd \ucd5c\uc801 \uc815\ucc45\uc744 \ud559\uc2b5\ud558\ub294 \uc811\uadfc \ubc29\uc2dd\uc744 \uc81c\uc548.", "result": "\uc81c\uc548\ub41c \ubc29\ubc95\uc740 \ud53d\uc5c5 \ubc0f \ubc30\ub2ec \ub85c\ubd07 \uc784\ubb34 \uc0ac\ub840 \uc5f0\uad6c\ub97c \ud1b5\ud574 \ud6a8\uacfc\uc131\uacfc \ud655\uc7a5\uc131\uc744 \uc785\uc99d\ud558\uba70, \ub450 \uac1c\uc758 \ub2e4\ub978 \uae30\ubcf8 RL \uc54c\uace0\ub9ac\uc998\uacfc \ube44\uad50\ud558\uc5ec \uc131\ub2a5\uc774 \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc90c.", "conclusion": "\uc774 \uc5f0\uad6c\ub294 \ub85c\ubd07 \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc5d0\uc11c \ubcf4\uc548 \uc778\uc2dd\uc758 \uc911\uc694\uc131\uc744 \uac15\uc870\ud558\uace0, \ud558\uc774\ud37cTWTL \uc81c\uc57d \uc870\uac74\uc744 \ub9cc\uc871\ud558\ub294 \ud6a8\uacfc\uc801\uc778 \uc815\ucc45 \ud559\uc2b5 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud558\uc600\ub2e4."}}
{"id": "2508.00046", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00046", "abs": "https://arxiv.org/abs/2508.00046", "authors": ["Ruo Yu Tao", "Kaicheng Guo", "Cameron Allen", "George Konidaris"], "title": "Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains", "comment": "To appear at RLC 2025. 1 cover page, 10 pages, 3 reference pages + 13\n  pages for supplementary material", "summary": "Mitigating partial observability is a necessary but challenging task for\ngeneral reinforcement learning algorithms. To improve an algorithm's ability to\nmitigate partial observability, researchers need comprehensive benchmarks to\ngauge progress. Most algorithms tackling partial observability are only\nevaluated on benchmarks with simple forms of state aliasing, such as feature\nmasking and Gaussian noise. Such benchmarks do not represent the many forms of\npartial observability seen in real domains, like visual occlusion or unknown\nopponent intent. We argue that a partially observable benchmark should have two\nkey properties. The first is coverage in its forms of partial observability, to\nensure an algorithm's generalizability. The second is a large gap between the\nperformance of a agents with more or less state information, all other factors\nroughly equal. This gap implies that an environment is memory improvable: where\nperformance gains in a domain are from an algorithm's ability to cope with\npartial observability as opposed to other factors. We introduce best-practice\nguidelines for empirically benchmarking reinforcement learning under partial\nobservability, as well as the open-source library POBAX: Partially Observable\nBenchmarks in JAX. We characterize the types of partial observability present\nin various environments and select representative environments for our\nbenchmark. These environments include localization and mapping, visual control,\ngames, and more. Additionally, we show that these tasks are all memory\nimprovable and require hard-to-learn memory functions, providing a concrete\nsignal for partial observability research. This framework includes recommended\nhyperparameters as well as algorithm implementations for fast, out-of-the-box\nevaluation, as well as highly performant environments implemented in JAX for\nGPU-scalable experimentation.", "AI": {"tldr": "\ubcf8 \ub17c\ubb38\uc740 \uac15\ud654 \ud559\uc2b5 \uc54c\uace0\ub9ac\uc998\uc774 \ubd80\ubd84 \uad00\ucc30\uc131\uc744 \uadf9\ubcf5\ud558\ub294\ub370 \ud544\uc694\ud55c \ud3ec\uad04\uc801\uc778 \ubca4\uce58\ub9c8\ud06c\ub97c \uc81c\uacf5\ud558\uae30 \uc704\ud55c \uc5f0\uad6c\ub97c \ub2e4\ub8ec\ub2e4.", "motivation": "\ubd80\ubd84 \uad00\ucc30\uc131 \ubb38\uc81c \ud574\uacb0\uc758 \uc911\uc694\uc131\uacfc \ud604\uc7ac \uc0ac\uc6a9\ub418\ub294 \ubca4\uce58\ub9c8\ud06c\uc758 \ud55c\uacc4\ub97c \uac15\uc870\ud55c\ub2e4.", "method": "\ubd80\ubd84 \uad00\ucc30\uc131\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c \uc0c8\ub85c\uc6b4 \ubca4\uce58\ub9c8\ud06c\uc778 POBAX\ub97c \ub3c4\uc785\ud558\uace0 \ub2e4\uc591\ud55c \ud658\uacbd\uc5d0\uc11c \uad00\ucc30\uc131 \uc720\ud615\uc744 \ud2b9\uc131\ud654\ud55c\ub2e4.", "result": "\uc81c\uc548\ub41c \ud658\uacbd\ub4e4\uc740 \ubaa8\ub450 \uba54\ubaa8\ub9ac \uac1c\uc120 \uac00\ub2a5\uc131\uc744 \uac16\ucd94\uace0 \uc788\uc73c\uba70, \uc5b4\ub824\uc6b4 \uba54\ubaa8\ub9ac \uae30\ub2a5 \ud559\uc2b5\uc774 \ud544\uc694\ud568\uc744 \uc99d\uba85\ud55c\ub2e4.", "conclusion": "\ubcf8 \uc5f0\uad6c\ub294 \ubd80\ubd84 \uad00\ucc30\uc131 \uc5f0\uad6c\ub97c \uc704\ud55c \uba85\ud655\ud55c \uc2e0\ud638\ub97c \uc81c\uacf5\ud558\uba70, \ube60\ub974\uace0 \ud6a8\uc728\uc801\uc778 \ud3c9\uac00\ub97c \uc704\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ubc0f \uc54c\uace0\ub9ac\uc998 \uad6c\ud604\uc744 \ud3ec\ud568\ud55c\ub2e4."}}
{"id": "2508.00555", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00555", "abs": "https://arxiv.org/abs/2508.00555", "authors": ["Jiecong Wang", "Haoran Li", "Hao Peng", "Ziqian Zeng", "Zihao Wang", "Haohua Du", "Zhengtao Yu"], "title": "Activation-Guided Local Editing for Jailbreaking Attacks", "comment": null, "summary": "Jailbreaking is an essential adversarial technique for red-teaming these\nmodels to uncover and patch security flaws. However, existing jailbreak methods\nface significant drawbacks. Token-level jailbreak attacks often produce\nincoherent or unreadable inputs and exhibit poor transferability, while\nprompt-level attacks lack scalability and rely heavily on manual effort and\nhuman ingenuity. We propose a concise and effective two-stage framework that\ncombines the advantages of these approaches. The first stage performs a\nscenario-based generation of context and rephrases the original malicious query\nto obscure its harmful intent. The second stage then utilizes information from\nthe model's hidden states to guide fine-grained edits, effectively steering the\nmodel's internal representation of the input from a malicious toward a benign\none. Extensive experiments demonstrate that this method achieves\nstate-of-the-art Attack Success Rate, with gains of up to 37.74% over the\nstrongest baseline, and exhibits excellent transferability to black-box models.\nOur analysis further demonstrates that AGILE maintains substantial\neffectiveness against prominent defense mechanisms, highlighting the\nlimitations of current safeguards and providing valuable insights for future\ndefense development. Our code is available at\nhttps://github.com/yunsaijc/AGILE.", "AI": {"tldr": "\ud6a8\uacfc\uc801\uc778 2\ub2e8\uacc4 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ud1b5\ud574 \uae30\uc874\uc758 jailbreak \uae30\ubc95\uc758 \ub2e8\uc810\uc744 \uadf9\ubcf5\ud558\uace0 \uc6b0\uc218\ud55c \uacf5\uaca9 \uc131\uacf5\ub960\uc744 \ub2ec\uc131\ud568.", "motivation": "\ubaa8\ub378\uc758 \ubcf4\uc548 \uacb0\ud568\uc744 \ubc1c\uacac\ud558\uace0 \ud328\uce58\ud558\uae30 \uc704\ud574 jailbreak \uae30\ubc95\uc774 \ud544\uc694\ud558\uc9c0\ub9cc, \uae30\uc874 \ubc29\ubc95\ub4e4\uc740 \uc5ec\ub7ec \ub2e8\uc810\uc774 \uc788\ub2e4.", "method": "\uccab \ubc88\uc9f8 \ub2e8\uacc4\uc5d0\uc11c \uc2dc\ub098\ub9ac\uc624 \uae30\ubc18\uc758 \ub9e5\ub77d \uc0dd\uc131 \ubc0f \uc6d0\ub798\uc758 \uc545\uc758\uc801\uc778 \ucffc\ub9ac\ub97c \uc7ac\ud45c\ud604\ud558\uc5ec \ud574\ub97c \uc228\uae30\uace0, \ub450 \ubc88\uc9f8 \ub2e8\uacc4\uc5d0\uc11c \ubaa8\ub378\uc758 \uc228\uaca8\uc9c4 \uc0c1\ud0dc \uc815\ubcf4\ub97c \ud65c\uc6a9\ud558\uc5ec \uc138\ubc00\ud55c \uc218\uc815\uc744 \uc218\ud589\ud55c\ub2e4.", "result": "\uc774 \ubc29\ubc95\uc740 \uac00\uc7a5 \uac15\ub825\ud55c \uae30\uc900\uc120\ubcf4\ub2e4 \ucd5c\ub300 37.74% \ud5a5\uc0c1\ub41c \uacf5\uaca9 \uc131\uacf5\ub960\uc744 \uae30\ub85d\ud558\uace0, \ube14\ub799\ubc15\uc2a4 \ubaa8\ub378\uc5d0 \ub300\ud55c \ud0c1\uc6d4\ud55c \uc804\uc774\uc131\uc744 \ubcf4\uc5ec\uc900\ub2e4.", "conclusion": "AGILE\uc740 \uc8fc\uc694 \ubc29\uc5b4 \uba54\ucee4\ub2c8\uc998\uc5d0 \ub300\ud574 \ub192\uc740 \ud6a8\uacfc\ub97c \uc720\uc9c0\ud558\uba70, \ud604\uc7ac\uc758 \ubc29\uc5b4 \ud55c\uacc4\uc640 \ubbf8\ub798 \ubc29\uc5b4 \uac1c\ubc1c\uc744 \uc704\ud55c \ud1b5\ucc30\uc744 \uc81c\uacf5\ud55c\ub2e4."}}
{"id": "2508.00632", "categories": ["cs.AI", "cs.MA", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.00632", "abs": "https://arxiv.org/abs/2508.00632", "authors": ["Alexia Jolicoeur-Martineau"], "title": "Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings", "comment": null, "summary": "While AI excels at generating text, audio, images, and videos, creating\ninteractive audio-visual content such as video games remains challenging.\nCurrent LLMs can generate JavaScript games and animations, but lack automated\nevaluation metrics and struggle with complex content that normally requires\nteams of humans working for many months (multi-shot, multi-agents) using assets\nmade by artists. To tackle these issues, we built a new metric and a\nmulti-agent system.\n  We propose AVR-Eval, a relative metric for multimedia content quality using\nAudio-Visual Recordings (AVRs). An omni-modal model (processing text, video,\nand audio) compares the AVRs of two contents, with a text model reviewing\nevaluations to determine superiority. We show that AVR-Eval properly identifies\ngood from broken or mismatched content.\n  We built AVR-Agent, a multi-agent system generating JavaScript code from a\nbank of multimedia assets (audio, images, 3D models). The coding agent selects\nrelevant assets, generates multiple initial codes, uses AVR-Eval to identify\nthe best version, and iteratively improves it through omni-modal agent feedback\nfrom the AVR.\n  We run experiments on games and animations with AVR-Eval (win rate of content\nA against B). We find that content generated by AVR-Agent has a significantly\nhigher win rate against content made through one-shot generation. However,\nmodels struggle to leverage custom assets and AVR feedback effectively, showing\nno higher win rate. This reveals a critical gap: while humans benefit from\nhigh-quality assets and audio-visual feedback, current coding models do not\nseem to utilize these resources as effectively, highlighting fundamental\ndifferences between human and machine content creation approaches.", "AI": {"tldr": "AI\ub294 \ud14d\uc2a4\ud2b8, \uc624\ub514\uc624, \uc774\ubbf8\uc9c0 \ubc0f \ube44\ub514\uc624 \uc0dd\uc131\uc5d0\uc11c \ub6f0\uc5b4\ub098\uc9c0\ub9cc, \ube44\ub514\uc624 \uac8c\uc784\uacfc \uac19\uc740 \ub300\ud654\ud615 \uc624\ub514\uc624-\ube44\uc8fc\uc5bc \ucf58\ud150\uce20 \uc0dd\uc131\uc740 \uc5ec\uc804\ud788 \uc5b4\ub824\uc6c0\uc774 \uc788\ub2e4. \ubcf8 \uc5f0\uad6c\uc5d0\uc11c\ub294 AVR-Eval\uc774\ub77c\ub294 \uc0c8\ub85c\uc6b4 \ud3c9\uac00 \uc9c0\ud45c\uc640 \uba40\ud2f0 \uc5d0\uc774\uc804\ud2b8 \uc2dc\uc2a4\ud15c AVR-Agent\ub97c \uac1c\ubc1c\ud558\uc600\ub2e4.", "motivation": "AI \ubaa8\ub378\uc774 \uc0dd\uc131\ud558\ub294 \ucf58\ud150\uce20\uc758 \ud488\uc9c8 \ud3c9\uac00\uc640 \ubcf5\uc7a1\ud55c \ub300\ud654\ud615 \ucf58\ud150\uce20 \uc0dd\uc131\uc744 \uc790\ub3d9\ud654\ud558\uae30 \uc704\ud574.", "method": "AVR-Eval\uc774\ub77c\ub294 \uba40\ud2f0\ubbf8\ub514\uc5b4 \ucf58\ud150\uce20 \ud488\uc9c8\uc758 \uc0c1\ub300\uc801 \uc9c0\ud45c\ub97c \uac1c\ubc1c\ud558\uace0, AVRs\uc744 \ube44\uad50\ud558\ub294 \uc634\ub2c8\ubaa8\ub2ec \ubaa8\ub378 \ubc0f \uba40\ud2f0 \uc5d0\uc774\uc804\ud2b8 \uc2dc\uc2a4\ud15c AVR-Agent\ub97c \uad6c\ucd95\ud558\uc5ec \uc790\uc0b0\uc744 \uc120\ud0dd\ud558\uace0 \ucd5c\uc801\uc758 \ucf54\ub4dc\ub97c \uc0dd\uc131\ud55c\ub2e4.", "result": "AVR-Agent\uac00 \uc0dd\uc131\ud55c \ucf58\ud150\uce20\ub294 \ud55c \ubc88\uc758 \uc0dd\uc131\uc73c\ub85c \uc81c\uc791\ub41c \ucf58\ud150\uce20\uc5d0 \ube44\ud574 \uc2b9\ub960\uc774 \ud604\uc800\ud788 \ub192\uc9c0\ub9cc, \uc0ac\uc6a9\uc790 \ub9de\ucda4\ud615 \uc790\uc0b0\uacfc AVR \ud53c\ub4dc\ubc31\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ud65c\uc6a9\ud558\uc9c0\ub294 \ubabb\ud55c\ub2e4.", "conclusion": "AI \ubaa8\ub378\uc740 \uc778\uac04\ucc98\ub7fc \uace0\ud488\uc9c8 \uc790\uc0b0\uacfc \ud53c\ub4dc\ubc31\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc5c6\uc73c\uba70, \uc774\ub294 \uc778\uac04\uacfc \uae30\uacc4\uc758 \ucf58\ud150\uce20 \uc0dd\uc131 \uc811\uadfc \ubc29\uc2dd\uc758 \uadfc\ubcf8\uc801\uc778 \ucc28\uc774\ub97c \ubc18\uc601\ud55c\ub2e4."}}
{"id": "2508.00116", "categories": ["cs.AI", "H.4.1; I.2.1"], "pdf": "https://arxiv.org/pdf/2508.00116", "abs": "https://arxiv.org/abs/2508.00116", "authors": ["Wil M. P. van der Aalst"], "title": "No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence", "comment": "10 pages, 4 figures, preprint keynote paper of the seventh\n  International Conference on Intelligent and Fuzzy Systems (INFUS 2025)", "summary": "The uptake of Artificial Intelligence (AI) impacts the way we work, interact,\ndo business, and conduct research. However, organizations struggle to apply AI\nsuccessfully in industrial settings where the focus is on end-to-end\noperational processes. Here, we consider generative, predictive, and\nprescriptive AI and elaborate on the challenges of diagnosing and improving\nsuch processes. We show that AI needs to be grounded using Object-Centric\nProcess Mining (OCPM). Process-related data are structured and\norganization-specific and, unlike text, processes are often highly dynamic.\nOCPM is the missing link connecting data and processes and enables different\nforms of AI. We use the term Process Intelligence (PI) to refer to the\namalgamation of process-centric data-driven techniques able to deal with a\nvariety of object and event types, enabling AI in an organizational context.\nThis paper explains why AI requires PI to improve operational processes and\nhighlights opportunities for successfully combining OCPM and generative,\npredictive, and prescriptive AI.", "AI": {"tldr": "AI\uac00 \uc0b0\uc5c5 \ud504\ub85c\uc138\uc2a4\uc5d0 \uc131\uacf5\uc801\uc73c\ub85c \uc801\uc6a9\ub418\uae30 \uc704\ud574\uc11c\ub294 \uac1d\uccb4 \uc911\uc2ec \ud504\ub85c\uc138\uc2a4 \ub9c8\uc774\ub2dd(OCPM)\uacfc \uacfc\uc815 \uc9c0\ub2a5(PI)\uc774 \ud544\uc694\ud558\ub2e4\ub294 \ub0b4\uc6a9\uc744 \ub2e4\ub8e8\uace0 \uc788\ub2e4.", "motivation": "AI\uc758 \ub3c4\uc785\uc774 \uc791\uc5c5 \ubc29\uc2dd \ubc0f \ube44\uc988\ub2c8\uc2a4 \ud504\ub85c\uc138\uc2a4\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uacfc \uc774\ub97c \uc131\uacf5\uc801\uc73c\ub85c \uc801\uc6a9\ud558\uae30 \uc704\ud55c \ub3c4\uc804 \uacfc\uc81c\ub97c \ub2e4\ub8ec\ub2e4.", "method": "\uac1d\uccb4 \uc911\uc2ec \ud504\ub85c\uc138\uc2a4 \ub9c8\uc774\ub2dd(OCPM)\uc744 \uc774\uc6a9\ud574 \uc870\uc9c1 \ub0b4 \ud504\ub85c\uc138\uc2a4\uc640 \ub370\uc774\ud130\ub97c \uc5f0\uacb0\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc548\ud55c\ub2e4.", "result": "PI\ub294 \ub2e4\uc591\ud55c \uac1d\uccb4 \ubc0f \uc774\ubca4\ud2b8 \uc720\ud615\uc744 \ub2e4\ub8f0 \uc218 \uc788\ub294 \ub370\uc774\ud130 \uae30\ubc18 \uae30\ubc95\ub4e4\uc758 \uc735\ud569\uc744 \uc758\ubbf8\ud558\uba70, AI\uc758 \uc870\uc9c1\uc801 \ub9e5\ub77d\uc5d0 \uc801\ud569\ud558\ub2e4.", "conclusion": "AI\uac00 \uc6b4\uc601 \ud504\ub85c\uc138\uc2a4\ub97c \uac1c\uc120\ud558\uae30 \uc704\ud574\uc11c\ub294 PI \ud544\uc694\uc131\uacfc OCPM\uacfc AI\uc758 \uc131\uacf5\uc801\uc778 \uacb0\ud569 \uae30\ud68c\ub97c \uac15\uc870\ud55c\ub2e4."}}
{"id": "2508.00047", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00047", "abs": "https://arxiv.org/abs/2508.00047", "authors": ["Yuan-Cheng Yu", "Yen-Chieh Ouyang", "Chun-An Lin"], "title": "TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection", "comment": "11 pages, 2 figures", "summary": "Time-series anomaly detection plays a central role across a wide range of\napplication domains. With the increasing proliferation of the Internet of\nThings (IoT) and smart manufacturing, time-series data has dramatically\nincreased in both scale and dimensionality. This growth has exposed the\nlimitations of traditional statistical methods in handling the high\nheterogeneity and complexity of such data. Inspired by the recent success of\nlarge language models (LLMs) in multimodal tasks across language and vision\ndomains, we propose a novel unsupervised anomaly detection framework: A\nTri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly\nDetection (TriP-LLM). TriP-LLM integrates local and global temporal features\nthrough a tri-branch design-Patching, Selection, and Global-to encode the input\ntime series into patch-wise tokens, which are then processed by a frozen,\npretrained LLM. A lightweight patch-wise decoder reconstructs the input, from\nwhich anomaly scores are derived. We evaluate TriP-LLM on several public\nbenchmark datasets using PATE, a recently proposed threshold-free evaluation\nmetric, and conduct all comparisons within a unified open-source framework to\nensure fairness. Experimental results show that TriP-LLM consistently\noutperforms recent state-of-the-art methods across all datasets, demonstrating\nstrong detection capabilities. Furthermore, through extensive ablation studies,\nwe verify the substantial contribution of the LLM to the overall architecture.\nCompared to LLM-based approaches using Channel Independence (CI) patch\nprocessing, TriP-LLM achieves significantly lower memory consumption, making it\nmore suitable for GPU memory-constrained environments. All code and model\ncheckpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \uc2dc\uac04 \uc2dc\uacc4\uc5f4 \uc774\uc0c1 \ud0d0\uc9c0\ub97c \uc704\ud55c Tri-Branch Patch-wise Large Language Model Framework (TriP-LLM)\ub97c \uc81c\uc548\ud558\uba70, \uc804\ud1b5\uc801\uc778 \ubc29\ubc95\uc758 \ud55c\uacc4\ub97c \uadf9\ubcf5\ud558\uace0 \ucd5c\uc2e0 \ubaa8\ub378\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\uacfc\ub97c \ubcf4\uc5ec\uc900\ub2e4.", "motivation": "\uc0ac\ubb3c\uc778\ud130\ub137(IoT) \ubc0f \uc2a4\ub9c8\ud2b8 \uc81c\uc870\uc758 \ubc1c\uc804\uc73c\ub85c \uc2dc\uac04 \uc2dc\uacc4\uc5f4 \ub370\uc774\ud130\uc758 \uaddc\ubaa8\uc640 \ucc28\uc6d0\uc774 \uae09\uaca9\ud788 \uc99d\uac00\ud558\uc600\uace0, \uc774\ub294 \uc804\ud1b5\uc801\uc778 \ud1b5\uacc4\uc801 \ubc29\ubc95\uc758 \ud55c\uacc4\ub97c \ub4dc\ub7ec\ub0b4\uc5c8\ub2e4.", "method": "TriP-LLM\uc740 \uc9c0\uc5ed \ubc0f \uc804\uc5ed \uc2dc\uac04\uc801 \ud2b9\uc9d5\uc744 \ud1b5\ud569\ud558\uace0 \uc785\ub825 \uc2dc\uac04 \uc2dc\uacc4\ub97c \ud328\uce58 \ub2e8\uc704 \ud1a0\ud070\uc73c\ub85c \uc778\ucf54\ub529\ud558\uae30 \uc704\ud574 Patching, Selection, Global\uc758 \uc138 \uac00\uc9c0 \ube0c\ub79c\uce58\ub97c \ud65c\uc6a9\ud558\uc5ec \uad6c\uc131\uc744 \uc218\ub9bd\ud55c\ub2e4.", "result": "TriP-LLM\uc740 \uc5ec\ub7ec \uacf5\uac1c \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc138\ud2b8\uc5d0\uc11c \ucd5c\uc2e0 \uae30\ubc95\uc744 \ucd08\uc6d4\ud558\uc5ec \uac15\ub825\ud55c \ud0d0\uc9c0 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc900\ub2e4.", "conclusion": "LLM\uc758 \uae30\uc5ec\ub3c4\ub97c \ud655\uc778\ud558\uace0, TriP-LLM\uc740 \ub354 \ub0ae\uc740 \uba54\ubaa8\ub9ac \uc18c\ube44\ub97c \ub2ec\uc131\ud558\uc5ec GPU \uba54\ubaa8\ub9ac\uc5d0 \uc81c\uc57d\uc774 \uc788\ub294 \ud658\uacbd\uc5d0\uc11c\ub3c4 \ub354 \uc801\ud569\ud558\ub2e4."}}
{"id": "2508.00602", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00602", "abs": "https://arxiv.org/abs/2508.00602", "authors": ["Francesco Panebianco", "Stefano Bonfanti", "Francesco Trov\u00f2", "Michele Carminati"], "title": "LeakSealer: A Semisupervised Defense for LLMs Against Prompt Injection and Leakage Attacks", "comment": "22 pages, preprint", "summary": "The generalization capabilities of Large Language Models (LLMs) have led to\ntheir widespread deployment across various applications. However, this\nincreased adoption has introduced several security threats, notably in the\nforms of jailbreaking and data leakage attacks. Additionally, Retrieval\nAugmented Generation (RAG), while enhancing context-awareness in LLM responses,\nhas inadvertently introduced vulnerabilities that can result in the leakage of\nsensitive information. Our contributions are twofold. First, we introduce a\nmethodology to analyze historical interaction data from an LLM system, enabling\nthe generation of usage maps categorized by topics (including adversarial\ninteractions). This approach further provides forensic insights for tracking\nthe evolution of jailbreaking attack patterns. Second, we propose LeakSealer, a\nmodel-agnostic framework that combines static analysis for forensic insights\nwith dynamic defenses in a Human-In-The-Loop (HITL) pipeline. This technique\nidentifies topic groups and detects anomalous patterns, allowing for proactive\ndefense mechanisms. We empirically evaluate LeakSealer under two scenarios: (1)\njailbreak attempts, employing a public benchmark dataset, and (2) PII leakage,\nsupported by a curated dataset of labeled LLM interactions. In the static\nsetting, LeakSealer achieves the highest precision and recall on the ToxicChat\ndataset when identifying prompt injection. In the dynamic setting, PII leakage\ndetection achieves an AUPRC of $0.97$, significantly outperforming baselines\nsuch as Llama Guard.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc758 \ubcf4\uc548 \uc704\ud611\uc744 \ubd84\uc11d\ud558\uace0, \uc790\uc728 \ubc29\uc5b4 \uba54\ucee4\ub2c8\uc998\uc744 \uad6c\ud604\ud558\ub294 LeakSealer \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uc548\ud55c\ub2e4.", "motivation": "LLM\uc758 \ubcf4\ud3b8\ud654\ub85c \uc778\ud55c \ubcf4\uc548 \uc704\ud611, \ud2b9\ud788 \ud0c8\uc625(jailbreaking) \ubc0f \ub370\uc774\ud130 \uc720\ucd9c \uacf5\uaca9\uc774 \uc99d\uac00\ud558\uace0 \uc788\ub2e4.", "method": "\uc774 \uc5f0\uad6c\uc5d0\uc11c\ub294 LLM \uc0c1\ud638\uc791\uc6a9 \ub370\uc774\ud130\ub97c \ubd84\uc11d\ud558\uace0, \uc8fc\uc81c\ubcc4 \uc0ac\uc6a9 \ub9f5\uc744 \uc0dd\uc131\ud558\uba70, LeakSealer\ub77c\ub294 \ubaa8\ub378-\ube44\uc758\uc874\uc801 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uc548\ud558\uc5ec \uc815\uc801 \ubd84\uc11d\uacfc \ub3d9\uc801 \ubc29\uc5b4\ub97c \uacb0\ud569\ud55c\ub2e4.", "result": "LeakSealer\ub294 Static \ud658\uacbd\uc5d0\uc11c ToxicChat \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud504\ub86c\ud504\ud2b8 \uc8fc\uc785\uc744 \uc815\ud655\ud558\uac8c \uc2dd\ubcc4\ud558\ub294 \ucd5c\uace0\uc758 \uc815\ud655\ub3c4\uc640 \uc7ac\ud604\uc728\uc744 \ub2ec\uc131\ud558\uc600\uace0, Dynamic \ud658\uacbd\uc5d0\uc11c PII \uc720\ucd9c \ud0d0\uc9c0\uc5d0\uc11c AUPRC 0.97\uc744 \uae30\ub85d\ud558\uba70 \uae30\uc874 \ubc29\ubc95\ub4e4\uc744 \ud06c\uac8c \ub2a5\uac00\ud558\uc600\ub2e4.", "conclusion": "\uc774 \uc5f0\uad6c\ub294 LLM \uc2dc\uc2a4\ud15c\uc758 \ubcf4\uc548\uc744 \uac15\ud654\ud560 \uc218 \uc788\ub294 \ubc29\ubc95\ub860\uacfc \ub3c4\uad6c\ub97c \uc81c\uc2dc\ud558\uba70, \ubcf4\uc548 \uc704\ud611\uc5d0 \ub300\uc751\ud560 \uc218 \uc788\ub294 \ud6a8\uacfc\uc801\uc778 \uc804\ub7b5\uc744 \uc81c\uacf5\ud55c\ub2e4."}}
{"id": "2508.00129", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.00129", "abs": "https://arxiv.org/abs/2508.00129", "authors": ["Agust\u00edn Borda", "Juan Bautista Cabral", "Gonzalo Giarda", "Diego Nicol\u00e1s Gimenez Irusta", "Paula Pacheco", "Alvaro Roy Schachner"], "title": "Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis", "comment": null, "summary": "In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem\nthat can greatly affect the results of a Multi-Criteria Decision Method against\na particular set of alternatives. It is therefore useful to have a mechanism\nthat allows one to measure the performance of a method on a set of\nalternatives. This idea could be taken further to build a global ranking of the\neffectiveness of different methods to solve a problem. In this paper, we\npresent three tests that detect the presence of Rank Reversals, along with\ntheir implementation in the Scikit-Criteria library. We also address the\ncomplications that arise when implementing these tests for general scenarios\nand the design considerations we made to handle them. We close with a\ndiscussion about how these additions could play a major role in the judgment of\nmulti-criteria decision methods for problem solving.", "AI": {"tldr": "\ub2e4\uae30\uc900 \uc758\uc0ac\uacb0\uc815 \ubd84\uc11d\uc5d0\uc11c \ub7ad\ud06c \uc5ed\uc804 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud55c \uc138 \uac00\uc9c0 \ud14c\uc2a4\ud2b8\ub97c \uc81c\uc548\ud558\uace0 \uc774\ub97c Scikit-Criteria \ub77c\uc774\ube0c\ub7ec\ub9ac\uc5d0 \uad6c\ud604\ud568.", "motivation": "\ub2e4\uae30\uc900 \uc758\uc0ac\uacb0\uc815 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \ub300\uc548 \uc9d1\ud569\uc5d0 \ub300\ud574 \uce21\uc815\ud560 \uc218 \uc788\ub294 \uba54\ucee4\ub2c8\uc998\uc758 \ud544\uc694\uc131.", "method": "\uc138 \uac00\uc9c0 \ub7ad\ud06c \uc5ed\uc804 \uac80\ucd9c \ud14c\uc2a4\ud2b8\ub97c \uc81c\uc2dc\ud558\uace0 Scikit-Criteria \ub77c\uc774\ube0c\ub7ec\ub9ac\uc5d0 \uad6c\ud604\ud568.", "result": "\uc81c\uc2dc\ub41c \ud14c\uc2a4\ud2b8\ub294 \uc77c\ubc18\uc801\uc778 \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c\uc758 \uad6c\ud604\uc5d0 \ub300\ud55c \ubcf5\uc7a1\uc131\uc744 \ub2e4\ub8e8\uba70, \ud6a8\uacfc\uc801\uc778 \uc758\uc0ac\uacb0\uc815 \ubc29\ubc95 \ud310\ub2e8\uc5d0 \uae30\uc5ec\ud560 \uc218 \uc788\uc74c.", "conclusion": "\uc774 \ucd94\uac00 \uae30\ub2a5\uc774 \ub2e4\uae30\uc900 \uc758\uc0ac\uacb0\uc815 \ubc29\ubc95\uc758 \ud3c9\uac00\uc5d0 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud560 \uac00\ub2a5\uc131\uc774 \uc788\uc74c."}}
{"id": "2508.00078", "categories": ["cs.LG", "cs.AI", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2508.00078", "abs": "https://arxiv.org/abs/2508.00078", "authors": ["Imen Mahmoud", "Andrei Velichko"], "title": "Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization", "comment": "22 pages, 5 figures", "summary": "This study proposes a novel methodological framework integrating a LightGBM\nregression model and genetic algorithm (GA) optimization to systematically\nevaluate the contribution of COVID-19-related indicators to Bitcoin return\nprediction. The primary objective was not merely to forecast Bitcoin returns\nbut rather to determine whether including pandemic-related health data\nsignificantly enhances prediction accuracy. A comprehensive dataset comprising\ndaily Bitcoin returns and COVID-19 metrics (vaccination rates,\nhospitalizations, testing statistics) was constructed. Predictive models,\ntrained with and without COVID-19 features, were optimized using GA over 31\nindependent runs, allowing robust statistical assessment. Performance metrics\n(R2, RMSE, MAE) were statistically compared through distribution overlaps and\nMann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified\nindividual feature contributions. Results indicate that COVID-19 indicators\nsignificantly improved model performance, particularly in capturing extreme\nmarket fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly\nsignificant statistically). Among COVID-19 features, vaccination metrics,\nespecially the 75th percentile of fully vaccinated individuals, emerged as\ndominant predictors. The proposed methodology extends existing financial\nanalytics tools by incorporating public health signals, providing investors and\npolicymakers with refined indicators to navigate market uncertainty during\nsystemic crises.", "AI": {"tldr": "COVID-19 \uad00\ub828 \uc9c0\ud45c\ub97c \ud1b5\ud569\ud55c LightGBM \ud68c\uadc0 \ubaa8\ub378\uacfc \uc720\uc804 \uc54c\uace0\ub9ac\uc998 \ucd5c\uc801\ud654 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ud1b5\ud574 \ube44\ud2b8\ucf54\uc778 \uc218\uc775 \uc608\uce21\uc758 \uc815\ud655\uc131\uc744 \ub192\uc774\ub294 \uc5f0\uad6c.", "motivation": "\ud32c\ub370\ubbf9\uacfc \uad00\ub828\ub41c \uac74\uac15 \ub370\uc774\ud130\ub97c \ud3ec\ud568\ud558\uc5ec \ube44\ud2b8\ucf54\uc778 \uc218\uc775 \uc608\uce21\uc758 \uc815\ud655\uc131\uc744 \ub192\uc774\uace0\uc790 \ud568.", "method": "LightGBM \ud68c\uadc0 \ubaa8\ub378\uacfc \uc720\uc804 \uc54c\uace0\ub9ac\uc998\uc744 \ud65c\uc6a9\ud558\uc5ec COVID-19 \uc9c0\ud45c\uc640 \ube44\ud2b8\ucf54\uc778 \uc218\uc775 \uac04\uc758 \uad00\uacc4\ub97c \ubd84\uc11d.", "result": "COVID-19 \uc9c0\ud45c\uac00 \ubaa8\ub378 \uc131\ub2a5\uc744 \uc720\uc758\ubbf8\ud558\uac8c \uac1c\uc120\ud568\uc744 \ubcf4\uc5ec\uc90c. \ud2b9\ud788 \ubc31\uc2e0 \uc811\uc885\ub960 \uc9c0\ud45c\uac00 \uc8fc\uc694 \uc608\uce21 \ubcc0\uc218\ub85c \ub098\ud0c0\ub0a8.", "conclusion": "\uc81c\uc548\ub41c \ubc29\ubc95\ub860\uc740 \uae08\uc735 \ubd84\uc11d \ub3c4\uad6c\ub97c \ud655\uc7a5\ud558\uc5ec \ud22c\uc790\uc790\uc640 \uc815\ucc45 \uc785\uc548\uc790\uac00 \uc2dc\uc2a4\ud15c\uc801 \uc704\uae30 \ub3d9\uc548 \uc2dc\uc7a5 \ubd88\ud655\uc2e4\uc131\uc744 \ud0d0\uc0c9\ud560 \uc218 \uc788\ub3c4\ub85d \ub3c4\uc6c0\uc744 \uc90c."}}
{"id": "2508.00636", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.00636", "abs": "https://arxiv.org/abs/2508.00636", "authors": ["Haocheng Jiang", "Hua Shen", "Jixin Zhang", "Willy Susilo", "Mingwu Zhang"], "title": "FedGuard: A Diverse-Byzantine-Robust Mechanism for Federated Learning with Major Malicious Clients", "comment": null, "summary": "Federated learning is a distributed training framework vulnerable to\nByzantine attacks, particularly when over 50% of clients are malicious or when\ndatasets are highly non-independent and identically distributed (non-IID).\nAdditionally, most existing defense mechanisms are designed for specific attack\ntypes (e.g., gradient similarity-based schemes can only defend against outlier\nmodel poisoning), limiting their effectiveness. In response, we propose\nFedGuard, a novel federated learning mechanism. FedGuard cleverly addresses the\naforementioned issues by leveraging the high sensitivity of membership\ninference to model bias. By requiring clients to include an additional\nmini-batch of server-specified data in their training, FedGuard can identify\nand exclude poisoned models, as their confidence in the mini-batch will drop\nsignificantly. Our comprehensive evaluation unequivocally shows that, under\nthree highly non-IID datasets, with 90% of clients being Byzantine and seven\ndifferent types of Byzantine attacks occurring in each round, FedGuard\nsignificantly outperforms existing robust federated learning schemes in\nmitigating various types of Byzantine attacks.", "AI": {"tldr": "FedGuard\ub294 \ube44\uc794\ud2f4 \uacf5\uaca9\uc5d0 \ub300\ud55c \uc0c8\ub85c\uc6b4 \uc5f0\ud569 \ud559\uc2b5 \uba54\ucee4\ub2c8\uc998\uc744 \uc81c\uc548\ud558\uc5ec \uae30\uc874 \ubc29\uc5b4\ucc45\ubcf4\ub2e4 \ud6a8\uacfc\uc801\uc73c\ub85c \ubb38\uc81c\ub97c \ud574\uacb0\ud55c\ub2e4.", "motivation": "\uc5f0\ud569 \ud559\uc2b5\uc740 50% \uc774\uc0c1\uc758 \ud074\ub77c\uc774\uc5b8\ud2b8\uac00 \uc545\uc758\uc801\uc77c \ub54c \ubc0f \ube44\ub3c5\ub9bd\uc801\uc774\uace0 \ub3d9\uc77c\ud55c \ubd84\ud3ec\uac00 \uc544\ub2cc \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ube44\uc794\ud2f4 \uacf5\uaca9\uc5d0 \ucde8\uc57d\ud558\ub2e4.", "method": "\ud074\ub77c\uc774\uc5b8\ud2b8\uac00 \uc11c\ubc84\uac00 \uc9c0\uc815\ud55c \ucd94\uac00 \ubbf8\ub2c8 \ubc30\uce58\ub97c \ud3ec\ud568\ud558\ub3c4\ub85d \uc694\uad6c\ud558\uc5ec \ubaa8\ub378\uc758 \ud3b8\ud5a5\uc744 \uc774\uc6a9\ud574 \uc545\uc131 \ubaa8\ub378\uc744 \uc2dd\ubcc4\ud558\uace0 \uc81c\uc678\ud55c\ub2e4.", "result": "FedGuard\ub294 90%\uc758 \ud074\ub77c\uc774\uc5b8\ud2b8\uac00 \ube44\uc794\ud2f4\uc778 \uc138 \uac00\uc9c0 \ube44\ub3c5\ub9bd\uc801 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uae30\uc874 \ubc29\uc5b4\ucc45\ubcf4\ub2e4 \ud6e8\uc52c \ub354 \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc778\ub2e4.", "conclusion": "FedGuard\ub294 \uc5ec\ub7ec \uc720\ud615\uc758 \ube44\uc794\ud2f4 \uacf5\uaca9\uc744 \uc644\ud654\ud558\ub294 \ub370 \uc788\uc5b4 \uae30\uc874\uc758 \ud0c4\ub825\uc801 \uc5f0\ud569 \ud559\uc2b5 \ubc29\uc548\ubcf4\ub2e4 \uc6b0\uc218\ud558\ub2e4."}}
{"id": "2508.00137", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00137", "abs": "https://arxiv.org/abs/2508.00137", "authors": ["Shqiponja Ahmetaj", "George Konstantinidis", "Magdalena Ortiz", "Paolo Pareti", "Mantas Simkus"], "title": "SHACL Validation under Graph Updates (Extended Paper)", "comment": "Accepted at the International Semantic Web Conference (ISWC 2025)", "summary": "SHACL (SHApe Constraint Language) is a W3C standardized constraint language\nfor RDF graphs. In this paper, we study SHACL validation in RDF graphs under\nupdates. We present a SHACL-based update language that can capture intuitive\nand realistic modifications on RDF graphs and study the problem of static\nvalidation under such updates. This problem asks to verify whether every graph\nthat validates a SHACL specification will still do so after applying a given\nupdate sequence. More importantly, it provides a basis for further services for\nreasoning about evolving RDF graphs. Using a regression technique that embeds\nthe update actions into SHACL constraints, we show that static validation under\nupdates can be reduced to (un)satisfiability of constraints in (a minor\nextension of) SHACL. We analyze the computational complexity of the static\nvalidation problem for SHACL and some key fragments. Finally, we present a\nprototype implementation that performs static validation and other static\nanalysis tasks on SHACL constraints and demonstrate its behavior through\npreliminary experiments.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \uc5c5\ub370\uc774\ud2b8 \ud558\uc5d0 RDF \uadf8\ub798\ud504\uc758 SHACL \uac80\uc99d\uc744 \uc5f0\uad6c\ud558\uba70, SHACL \uae30\ubc18 \uc5c5\ub370\uc774\ud2b8 \uc5b8\uc5b4 \ubc0f \uc815\uc801 \uac80\uc99d \ubb38\uc81c\ub97c \uc81c\uc2dc\ud55c\ub2e4.", "motivation": "RDF \uadf8\ub798\ud504\uc758 \ubcc0\ud654\uc5d0 \ub530\ub77c SHACL \uc0ac\uc591\uc744 \uc720\uc9c0\ud560 \uc218 \uc788\ub294\uc9c0\ub97c \ud655\uc778\ud574\uc57c \ud558\ub294 \ud544\uc694\uc131\uc774 \uc788\ub2e4.", "method": "SHACL \uc81c\uc57d \uc870\uac74\uc5d0 \uc5c5\ub370\uc774\ud2b8 \ub3d9\uc791\uc744 \ud3ec\ud568\uc2dc\ud0a4\ub294 \ud68c\uadc0 \uae30\uc220\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc815\uc801 \uac80\uc99d \ubb38\uc81c\ub97c SHACL\uc758 \uc81c\uc57d \uc870\uac74\uc758 (\ube44)\ub9cc\uc871\uc131\uc73c\ub85c \ucd95\uc18c\ud55c\ub2e4.", "result": "\uc815\uc801 \uac80\uc99d \ubb38\uc81c\uc758 \ucef4\ud4e8\ud305 \ubcf5\uc7a1\uc131\uc744 \ubd84\uc11d\ud558\uace0, SHACL\uacfc \uc8fc\uc694 \uc870\uac01\ub4e4\uc758 \ub3d9\uc801 \uac80\uc99d\uc744 \uc704\ud55c \ud504\ub85c\ud1a0\ud0c0\uc785 \uad6c\ud604\uc744 \uc18c\uac1c\ud55c\ub2e4.", "conclusion": "\uc608\ube44 \uc2e4\ud5d8\uc744 \ud1b5\ud574 SHACL \uc81c\uc57d \uc870\uac74\uc5d0 \ub300\ud55c \uc815\uc801 \uac80\uc99d \ubc0f \uae30\ud0c0 \uc815\uc801 \ubd84\uc11d \uc791\uc5c5\uc758 \ub3d9\uc791\uc744 \uc785\uc99d\ud558\uc600\ub2e4."}}
{"id": "2508.00098", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00098", "abs": "https://arxiv.org/abs/2508.00098", "authors": ["Ashkan Shakarami", "Yousef Yeganeh", "Azade Farshad", "Lorenzo Nicole", "Stefano Ghidoni", "Nassir Navab"], "title": "Stress-Aware Resilient Neural Training", "comment": "16 pages, 11 figures", "summary": "This paper introduces Stress-Aware Learning, a resilient neural training\nparadigm in which deep neural networks dynamically adjust their optimization\nbehavior - whether under stable training regimes or in settings with uncertain\ndynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)\nDeformation, inspired by structural fatigue in materials science. To\ninstantiate this concept, we propose Plastic Deformation Optimizer, a\nstress-aware mechanism that injects adaptive noise into model parameters\nwhenever an internal stress signal - reflecting stagnation in training loss and\naccuracy - indicates persistent optimization difficulty. This enables the model\nto escape sharp minima and converge toward flatter, more generalizable regions\nof the loss landscape. Experiments across six architectures, four optimizers,\nand seven vision benchmarks demonstrate improved robustness and generalization\nwith minimal computational overhead. The code and 3D visuals will be available\non GitHub: https://github.com/Stress-Aware-Learning/SAL.", "AI": {"tldr": "Stress-Aware Learning\uc740 \uc2ec\uce35 \uc2e0\uacbd\ub9dd\uc774 \uc548\uc815\uc801\uc778 \ud6c8\ub828 \ud658\uacbd\uacfc \ubd88\ud655\uc2e4\ud55c \ub3d9\uc5ed\ud559\uc5d0\uc11c \ub3d9\uc801\uc73c\ub85c \ucd5c\uc801\ud654 \ud589\ub3d9\uc744 \uc870\uc815\ud558\ub3c4\ub85d \ud558\ub294 \ud559\uc2b5 \ud328\ub7ec\ub2e4\uc784\uc774\ub2e4.", "motivation": "\uac15\ud55c \ucd5c\uc801\ud654 \ub09c\uc774\ub3c4\uc640 \uc815\uccb4 \uc0c1\ud0dc\uc5d0\uc11c \ubaa8\ub378\uc774 \ubcf4\ub2e4 \uc77c\ubc18\ud654\ub41c \uc190\uc2e4 \uc804\uc5ed\uc73c\ub85c \uc218\ub834\ud560 \uc218 \uc788\ub3c4\ub85d \uc9c0\uc6d0\ud558\uae30 \uc704\ud574.", "method": "Plastic Deformation Optimizer\ub77c\ub294 \uba54\ucee4\ub2c8\uc998\uc744 \ub3c4\uc785\ud558\uc5ec \ub0b4\ubd80 \uc2a4\ud2b8\ub808\uc2a4 \uc2e0\ud638\uc5d0 \ub530\ub77c \ubaa8\ub378 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \uc801\uc751\ud615 \ub178\uc774\uc988\ub97c \uc8fc\uc785\ud55c\ub2e4.", "result": "\uc5ec\uc12f \uac1c \uc544\ud0a4\ud14d\ucc98\uc640 \ub124 \uac1c \ucd5c\uc801\ud654 \uae30\ubc95, \uc77c\uacf1 \uac1c \ube44\uc804 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uac1c\uc120\ub41c \uac15\uac74\uc131\uacfc \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ubcf4\uc600\ub2e4.", "conclusion": "\ucd5c\uc18c\ud55c\uc758 \uacc4\uc0b0 \uc624\ubc84\ud5e4\ub4dc\ub85c \ubaa8\ub378 \ucd5c\uc801\ud654\ub97c \uac1c\uc120\ud558\uc600\uc73c\uba70, \ucf54\ub4dc\uc640 3D \uc2dc\uac01\ud654\ub294 GitHub\uc5d0\uc11c \uc81c\uacf5\ub41c\ub2e4."}}
{"id": "2508.00659", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00659", "abs": "https://arxiv.org/abs/2508.00659", "authors": ["Xinzhang Chen", "Hassan Ali", "Arash Shaghaghi", "Salil S. Kanhere", "Sanjay Jha"], "title": "Demo: TOSense -- What Did You Just Agree to?", "comment": "Accepted as a demonstration paper at IEEE LCN 2025", "summary": "Online services often require users to agree to lengthy and obscure Terms of\nService (ToS), leading to information asymmetry and legal risks. This paper\nproposes TOSense-a Chrome extension that allows users to ask questions about\nToS in natural language and get concise answers in real time. The system\ncombines (i) a crawler \"tos-crawl\" that automatically extracts ToS content, and\n(ii) a lightweight large language model pipeline: MiniLM for semantic retrieval\nand BART-encoder for answer relevance verification. To avoid expensive manual\nannotation, we present a novel Question Answering Evaluation Pipeline (QEP)\nthat generates synthetic questions and verifies the correctness of answers\nusing clustered topic matching. Experiments on five major platforms, Apple,\nGoogle, X (formerly Twitter), Microsoft, and Netflix, show the effectiveness of\nTOSense (with up to 44.5% accuracy) across varying number of topic clusters.\nDuring the demonstration, we will showcase TOSense in action. Attendees will be\nable to experience seamless extraction, interactive question answering, and\ninstant indexing of new sites.", "AI": {"tldr": "TOSense\ub294 \uc0ac\uc6a9\uc790\ub4e4\uc774 \uc790\uc5f0\uc5b4\ub85c \uc11c\ube44\uc2a4 \uc57d\uad00\uc5d0 \ub300\ud574 \uc9c8\ubb38\ud558\uace0 \uc2e4\uc2dc\uac04\uc73c\ub85c \uac04\uacb0\ud55c \ub2f5\ubcc0\uc744 \ubc1b\uc744 \uc218 \uc788\uac8c \ub3d5\ub294 Chrome \ud655\uc7a5 \ud504\ub85c\uadf8\ub7a8\uc774\ub2e4.", "motivation": "\uc628\ub77c\uc778 \uc11c\ube44\uc2a4\uc758 \ubcf5\uc7a1\ud55c \uc57d\uad00\uc73c\ub85c \uc778\ud55c \uc815\ubcf4 \ube44\ub300\uce6d\uacfc \ubc95\uc801 \uc704\ud5d8\uc744 \ud574\uc18c\ud558\uae30 \uc704\ud574.", "method": "ToS \ub0b4\uc6a9\uc744 \uc790\ub3d9\uc73c\ub85c \ucd94\ucd9c\ud558\ub294 \ud06c\ub864\ub7ec\uc640 \uc790\uc5f0\uc5b4 \ucc98\ub9ac \ubaa8\ub378\uc744 \ud65c\uc6a9\ud558\uc5ec \uc9c8\ubb38\uc5d0 \ub300\ud55c \ub2f5\ubcc0\uc744 \uc81c\uacf5\ud558\ub294 \uc2dc\uc2a4\ud15c\uc744 \uac1c\ubc1c.", "result": "Apple, Google, X, Microsoft, Netflix \ub4f1 5\uac1c \uc8fc\uc694 \ud50c\ub7ab\ud3fc\uc5d0\uc11c \ud3c9\uade0 44.5% \uc815\ud655\ub3c4\ub85c \ud6a8\uacfc\uc131\uc744 \uc785\uc99d\ud558\uc600\ub2e4.", "conclusion": "TOSense\ub294 \uc57d\uad00\uc758 \uc2e4\uc2dc\uac04 \uc9c8\uc758\uc751\ub2f5\uacfc \uc0c8\ub85c\uc6b4 \uc0ac\uc774\ud2b8\uc758 \uc989\uac01\uc801\uc778 \uc778\ub371\uc2f1\uc744 \uc2e4\ud604\ud558\ub294 \uc720\uc6a9\ud55c \ub3c4\uad6c\uc774\ub2e4."}}
{"id": "2508.00138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00138", "abs": "https://arxiv.org/abs/2508.00138", "authors": ["Rashid Mushkani", "Hugo Berard", "Toumadher Ammar", "Cassandre Chatonnier", "Shin Koseki"], "title": "Co-Producing AI: Toward an Augmented, Participatory Lifecycle", "comment": "Eighth AAAI/ACM Conference on AI, Ethics, and Society 2025", "summary": "Despite efforts to mitigate the inherent risks and biases of artificial\nintelligence (AI) algorithms, these algorithms can disproportionately impact\nculturally marginalized groups. A range of approaches has been proposed to\naddress or reduce these risks, including the development of ethical guidelines\nand principles for responsible AI, as well as technical solutions that promote\nalgorithmic fairness. Drawing on design justice, expansive learning theory, and\nrecent empirical work on participatory AI, we argue that mitigating these harms\nrequires a fundamental re-architecture of the AI production pipeline. This\nre-design should center co-production, diversity, equity, inclusion (DEI), and\nmultidisciplinary collaboration. We introduce an augmented AI lifecycle\nconsisting of five interconnected phases: co-framing, co-design,\nco-implementation, co-deployment, and co-maintenance. The lifecycle is informed\nby four multidisciplinary workshops and grounded in themes of distributed\nauthority and iterative knowledge exchange. Finally, we relate the proposed\nlifecycle to several leading ethical frameworks and outline key research\nquestions that remain for scaling participatory governance.", "AI": {"tldr": "\uc778\uacf5\uc9c0\ub2a5(AI) \uc54c\uace0\ub9ac\uc998\uc758 \uc704\ud5d8\uacfc \ud3b8\ud5a5\uc744 \uc904\uc774\uae30 \uc704\ud574 \uc0dd\uc0b0 \ud30c\uc774\ud504\ub77c\uc778\uc758 \uadfc\ubcf8\uc801\uc778 \uc7ac\uc124\uacc4\ub97c \uc81c\uc548\ud55c\ub2e4.", "motivation": "AI \uc54c\uace0\ub9ac\uc998\uc774 \ubb38\ud654\uc801\uc73c\ub85c \uc18c\uc678\ub41c \uc9d1\ub2e8\uc5d0 \ubbf8\uce58\ub294 \ubd80\uc815\uc801\uc778 \uc601\ud5a5\uc744 \uc644\ud654\ud560 \ud544\uc694\uac00 \uc788\ub2e4.", "method": "\uacf5\ub3d9 \ud504\ub808\uc774\ubc0d, \uacf5\ub3d9 \uc124\uacc4, \uacf5\ub3d9 \uc2e4\ud589, \uacf5\ub3d9 \ubc30\ud3ec, \uacf5\ub3d9 \uc720\uc9c0 \uad00\ub9ac\uc758 \ub2e4\uc12f \uac00\uc9c0 \ub2e8\uacc4\ub85c \uad6c\uc131\ub41c \uc99d\uac15\ub41c AI \uc0dd\uc560 \uc8fc\uae30\ub97c \uc81c\uc548\ud55c\ub2e4.", "result": "\ub2e4\uc591\uc131\uacfc \ud3ec\uc6a9\uc131\uc744 \uc911\uc2ec\uc73c\ub85c \ud55c AI \uc0dd\uc0b0 \ud30c\uc774\ud504\ub77c\uc778\uc758 \uc7ac\uc124\uacc4\ub97c \ud1b5\ud574 \uc54c\uace0\ub9ac\uc998 \uacf5\uc815\uc131\uc744 \uc99d\uc9c4\ud560 \uc218 \uc788\ub2e4.", "conclusion": "\uc81c\uc548\ub41c \uc0dd\uc560 \uc8fc\uae30\ub294 \uc5ec\ub7ec \uc724\ub9ac\uc801 \ud504\ub808\uc784\uc6cc\ud06c\uc640 \uc5f0\uacb0\ub418\uba70, \ucc38\uc5ec \uac70\ubc84\ub10c\uc2a4\ub97c \ud655\uc7a5\ud558\uae30 \uc704\ud55c \uc5f0\uad6c \uc9c8\ubb38\uc744 \uc81c\uc2dc\ud55c\ub2e4."}}
{"id": "2508.00117", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00117", "abs": "https://arxiv.org/abs/2508.00117", "authors": ["Md. Ehsanul Haque", "S. M. Jahidul Islam", "Shakil Mia", "Rumana Sharmin", "Ashikuzzaman", "Md Samir Morshed", "Md. Tahmidul Huque"], "title": "StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection", "comment": "Accepted and presented paper of THE 16th INTERNATIONAL IEEE\n  CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT)\n  INDIA", "summary": "Liver diseases are a serious health concern in the world, which requires\nprecise and timely diagnosis to enhance the survival chances of patients. The\ncurrent literature implemented numerous machine learning and deep learning\nmodels to classify liver diseases, but most of them had some issues like high\nmisclassification error, poor interpretability, prohibitive computational\nexpense, and lack of good preprocessing strategies. In order to address these\ndrawbacks, we introduced StackLiverNet in this study; an interpretable stacked\nensemble model tailored to the liver disease detection task. The framework uses\nadvanced data preprocessing and feature selection technique to increase model\nrobustness and predictive ability. Random undersampling is performed to deal\nwith class imbalance and make the training balanced. StackLiverNet is an\nensemble of several hyperparameter-optimized base classifiers, whose\ncomplementary advantages are used through a LightGBM meta-model. The provided\nmodel demonstrates excellent performance, with the testing accuracy of 99.89%,\nCohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and\nefficient training and inference speeds that are amenable to clinical practice\n(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local\nInterpretable Model-Agnostic Explanations (LIME) are applied to generate\ntransparent explanations of individual predictions, revealing high\nconcentrations of Alkaline Phosphatase and moderate SGOT as important\nobservations of liver disease. Also, SHAP was used to rank features by their\nglobal contribution to predictions, while the Morris method confirmed the most\ninfluential features through sensitivity analysis.", "AI": {"tldr": "StackLiverNet\ub294 \uac04 \uc9c8\ud658 \uac10\uc9c0\ub97c \uc704\ud574 \uc124\uacc4\ub41c \ud574\uc11d \uac00\ub2a5\ud55c \uc559\uc0c1\ube14 \ubaa8\ub378\ub85c, \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc778\ub2e4.", "motivation": "\uac04 \uc9c8\ud658\uc758 \uc870\uae30 \uc9c4\ub2e8\uc740 \ud658\uc790\uc758 \uc0dd\uc874 \uac00\ub2a5\uc131\uc744 \ub192\uc774\ub294 \uc911\uc694\ud55c \uc694\uc18c\uc774\uba70, \ud604\uc7ac\uc758 \uba38\uc2e0\ub7ec\ub2dd \ubaa8\ub378\ub4e4\uc740 \uc5ec\ub7ec \ubb38\uc81c\uc810\uc744 \uc548\uace0 \uc788\ub2e4.", "method": "StackLiverNet\uc740 \uace0\uae09 \ub370\uc774\ud130 \uc804\ucc98\ub9ac \ubc0f \ud2b9\uc9d5 \uc120\ud0dd \uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ucd5c\uc801\ud654\ub41c \uae30\ubcf8 \ubd84\ub958\uae30\ub97c \uacb0\ud569\ud55c \uc559\uc0c1\ube14 \ubaa8\ub378\uc774\ub2e4.", "result": "\ubaa8\ub378\uc740 99.89%\uc758 \uc815\ud655\ub3c4, 0.9974\uc758 Cohen Kappa, 0.9993\uc758 AUC\ub97c \uae30\ub85d\ud558\uba70, \ud6c8\ub828\uacfc \ucd94\ub860 \uc18d\ub3c4\uac00 \uc784\uc0c1 \uc2e4\uc2b5\uc5d0 \uc801\ud569\ud558\ub2e4.", "conclusion": "\ubaa8\ub378\uc744 \ud1b5\ud574 \uac04 \uc9c8\ud658\uc758 \uc911\uc694\ud55c \uc9c0\ud45c\uc778 Alkaline Phosphatase\uc640 SGOT\uc758 \uc601\ud5a5\uc744 \ubd84\uc11d\ud560 \uc218 \uc788\uc5c8\ub2e4."}}
{"id": "2508.00682", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00682", "abs": "https://arxiv.org/abs/2508.00682", "authors": ["Oscar Llorente-Vazquez", "Xabier Ugarte-Pedrero", "Igor Santos-Grueiro", "Pablo Garcia Bringas"], "title": "Unveiling Dynamic Binary Instrumentation Techniques", "comment": null, "summary": "Dynamic Binary Instrumentation (DBI) is the set of techniques that enable\ninstrumentation of programs at run-time, making it possible to monitor and\nmodify the execution of compiled binaries or entire systems. DBI is used for\ncountless security applications and analyses, and is extensively used across\nmany fields in both industry and academia. Over the years, several DBI\napproaches have been proposed based on different technologies and implementing\ndiverse techniques. Every solution tries to overcome certain limitations, but\nthey sometimes bring other shortcomings. Some are specialized for one\nparticular domain or task, while others have a wider scope.\n  In this paper, we shed light into the labyrinth of DBI, bringing together\nprocess-level and whole-system approaches. We depict their building blocks and\nanalyze the underlying instrumentation techniques, comparing their ability to\ninstrument different primitives and run-time events. Then, we evaluate their\nperformance when implementing each primitive, and highlight relevant\nobservations. Our results show that no single technique is better than the rest\nin all circumstances.", "AI": {"tldr": "DBI \uae30\uc220\uc758 \uc5ec\ub7ec \uc811\uadfc\ubc95\uc744 \ube44\uad50\ud558\uace0 \ubd84\uc11d\ud558\uc5ec \uc131\ub2a5\uacfc \ud55c\uacc4\ub97c \uc870\uba85\ud55c\ub2e4.", "motivation": "DBI \uae30\uc220\uc758 \ub2e4\uc591\uc131\uacfc \uadf8\uc5d0 \ub530\ub978 \ud55c\uacc4 \uadf9\ubcf5\uc744 \uc704\ud574.", "method": "\ud504\ub85c\uc138\uc2a4 \uc218\uc900 \ubc0f \uc804\uccb4 \uc2dc\uc2a4\ud15c \ubc29\uc2dd\uc758 DBI \uc811\uadfc\ubc95\uc744 \ubd84\uc11d\ud558\uace0 \ube44\uad50\ud55c\ub2e4.", "result": "DBI \uae30\uc220\ub4e4\uc774 \ud2b9\uc815 \uc6d0\uc2dc \ub370\uc774\ud130\uc640 \ub7f0\ud0c0\uc784 \uc774\ubca4\ud2b8\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ud3c9\uac00\ud55c \uacb0\uacfc, \ud2b9\uc815 \uae30\uc220\uc774 \ubaa8\ub4e0 \uc0c1\ud669\uc5d0\uc11c \uac00\uc7a5 \uc6b0\uc218\ud558\uc9c0 \uc54a\uc74c\uc744 \ubc1c\uacac\ud588\ub2e4.", "conclusion": "\ubaa8\ub4e0 DBI \uae30\uc220\uc740 \ud2b9\uc815 \uc0c1\ud669\uc5d0\uc11c \uc7a5\ub2e8\uc810\uc774 \uc788\uc73c\uba70, \ud1b5\ud569\ub41c \uc811\uadfc\uc774 \ud544\uc694\ud568\uc744 \uac15\uc870\ud55c\ub2e4."}}
{"id": "2508.00143", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.00143", "abs": "https://arxiv.org/abs/2508.00143", "authors": ["Danielle R. Thomas", "Conrad Borchers", "Kenneth R. Koedinger"], "title": "Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation", "comment": "Accepted for presentation at NCME AIME-Con 2025", "summary": "Humans can be notoriously imperfect evaluators. They are often biased,\nunreliable, and unfit to define \"ground truth.\" Yet, given the surging need to\nproduce large amounts of training data in educational applications using AI,\ntraditional inter-rater reliability (IRR) metrics like Cohen's kappa remain\ncentral to validating labeled data. IRR remains a cornerstone of many machine\nlearning pipelines for educational data. Take, for example, the classification\nof tutors' moves in dialogues or labeling open responses in machine-graded\nassessments. This position paper argues that overreliance on human IRR as a\ngatekeeper for annotation quality hampers progress in classifying data in ways\nthat are valid and predictive in relation to improving learning. To address\nthis issue, we highlight five examples of complementary evaluation methods,\nsuch as multi-label annotation schemes, expert-based approaches, and\nclose-the-loop validity. We argue that these approaches are in a better\nposition to produce training data and subsequent models that produce improved\nstudent learning and more actionable insights than IRR approaches alone. We\nalso emphasize the importance of external validity, for example, by\nestablishing a procedure of validating tutor moves and demonstrating that it\nworks across many categories of tutor actions (e.g., providing hints). We call\non the field to rethink annotation quality and ground truth--prioritizing\nvalidity and educational impact over consensus alone.", "AI": {"tldr": "\uc778\uac04 \ud3c9\uac00\uc758 \ud55c\uacc4\ub97c \uc9c0\uc801\ud558\uba70, \uad50\uc721 \ub370\uc774\ud130 \uc8fc\uc11d \ud488\uc9c8\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 \uc804\ud1b5\uc801\uc778 IRR \ub300\uc2e0 \uc0c8\ub85c\uc6b4 \ud3c9\uac00 \ubc29\ubc95\ub860\uc758 \ud544\uc694\uc131\uc744 \uac15\uc870\ud55c\ub2e4.", "motivation": "AI\ub97c \ud65c\uc6a9\ud55c \uad50\uc721 \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc758 \ub300\uaddc\ubaa8 \ud559\uc2b5 \ub370\uc774\ud130 \uc0dd\uc0b0 \ud544\uc694\uc131\uc774 \uae09\uc99d\ud558\uace0 \uc788\ub2e4.", "method": "\ub2e4\uc591\ud55c \ud3c9\uac00 \ubc29\ubc95(\uc608: \ub2e4\uc911 \ub808\uc774\ube14 \uc8fc\uc11d, \uc804\ubb38\uac00 \uae30\ubc18 \uc811\uadfc\ubc95, \ud074\ub85c\uc988\ub4dc \ub8e8\ud504 \uc720\ud6a8\uc131 \uac80\uc0ac)\uc744 \uc81c\uc548\ud558\uc5ec IRR\uc5d0 \ub300\ud55c \uc758\uc874\ub3c4\ub97c \uc904\uc778\ub2e4.", "result": "\uc81c\uc548\ub41c \ubc29\ubc95\ub4e4\uc774 \ud559\uc0dd \ud559\uc2b5 \ud5a5\uc0c1 \ubc0f \uc2e4\ud589 \uac00\ub2a5\ud55c \ud1b5\ucc30\ub825 \uc81c\uacf5\uc5d0 \ud6a8\uacfc\uc801\uc784\uc744 \ubcf4\uc5ec\uc900\ub2e4.", "conclusion": "\uc8fc\uc11d \ud488\uc9c8\uacfc \uadfc\ubcf8 \uc9c4\uc2e4\uc5d0 \ub300\ud55c \uc7ac\uace0\ub97c \ud1b5\ud574 \uc720\ud6a8\uc131\uacfc \uad50\uc721\uc801 \uc601\ud5a5\uc744 \ud569\uc758\ubcf4\ub2e4 \uc6b0\uc120\uc2dc\ud574\uc57c \ud55c\ub2e4."}}
{"id": "2508.00127", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00127", "abs": "https://arxiv.org/abs/2508.00127", "authors": ["Saleh Nikooroo", "Thomas Engel"], "title": "Structured Transformations for Stable and Interpretable Neural Computation", "comment": null, "summary": "Despite their impressive performance, contemporary neural networks often lack\nstructural safeguards that promote stable learning and interpretable behavior.\nIn this work, we introduce a reformulation of layer-level transformations that\ndeparts from the standard unconstrained affine paradigm. Each transformation is\ndecomposed into a structured linear operator and a residual corrective\ncomponent, enabling more disciplined signal propagation and improved training\ndynamics. Our formulation encourages internal consistency and supports stable\ninformation flow across depth, while remaining fully compatible with standard\nlearning objectives and backpropagation. Through a series of synthetic and\nreal-world experiments, we demonstrate that models constructed with these\nstructured transformations exhibit improved gradient conditioning, reduced\nsensitivity to perturbations, and layer-wise robustness. We further show that\nthese benefits persist across architectural scales and training regimes. This\nstudy serves as a foundation for a more principled class of neural\narchitectures that prioritize stability and transparency-offering new tools for\nreasoning about learning behavior without sacrificing expressive power.", "AI": {"tldr": "\uce35 \uc218\uc900\uc758 \ubcc0\ud658\uc744 \uad6c\uc870\ud654\ub41c \uc120\ud615 \uc5f0\uc0b0\uc790\uc640 \uc794\uc5ec \ubcf4\uc815 \uc131\ubd84\uc73c\ub85c \uc7ac\uad6c\uc131\ud558\uc5ec \uc2e0\ud638 \uc804\ud30c\ub97c \uac1c\uc120\ud558\uace0 \ud6c8\ub828 \ub3d9\uc5ed\ud559\uc744 \ud5a5\uc0c1\uc2dc\ucf30\ub2e4.", "motivation": "\ud604\ub300 \uc2e0\uacbd\ub9dd\uc740 \uc548\uc815\uc801\uc778 \ud559\uc2b5\uacfc \ud574\uc11d \uac00\ub2a5\ud55c \ud589\ub3d9\uc744 \ucd09\uc9c4\ud558\ub294 \uad6c\uc870\uc801 \uc548\uc804\uc7a5\uce58\uac00 \ubd80\uc871\ud558\ub2e4.", "method": "\uc804\ud1b5\uc801\uc778 \ube44\uc81c\uc57d\uc801 \uc544\ud540 \ud328\ub7ec\ub2e4\uc784\uc5d0\uc11c \ubc97\uc5b4\ub098 \uac01 \ubcc0\ud658\uc744 \uad6c\uc870\ud654\ub41c \uc120\ud615 \uc5f0\uc0b0\uc790\uc640 \uc794\uc5ec \ubcf4\uc815 \uc131\ubd84\uc73c\ub85c \ubd84\ud574\ud55c\ub2e4.", "result": "\uc774\ub7ec\ud55c \uad6c\uc870\ud654\ub41c \ubcc0\ud658\uc73c\ub85c \uad6c\uc131\ub41c \ubaa8\ub378\ub4e4\uc740 \uac1c\uc120\ub41c \uadf8\ub798\ub514\uc5b8\ud2b8 \uc870\uc815, \uac10\uc18c\ub41c \uc12d\ub3d9 \ubbfc\uac10\ub3c4 \ubc0f \uce35\ubcc4 \uac15\uac74\uc131\uc744 \ubcf4\uc5ec\uc900\ub2e4.", "conclusion": "\uc774 \uc5f0\uad6c\ub294 \uc548\uc815\uc131\uacfc \ud22c\uba85\uc131\uc744 \uc6b0\uc120\uc2dc\ud558\ub294 \uc2e0\uacbd \uad6c\uc870\uc758 \ubcf4\ub2e4 \uc6d0\uce59\uc801\uc778 \ud074\ub798\uc2a4\uc758 \uae30\ucd08\ub97c \uc81c\uacf5\ud55c\ub2e4."}}
{"id": "2508.00756", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.00756", "abs": "https://arxiv.org/abs/2508.00756", "authors": ["Yunhao Chen", "Shujie Wang", "Xin Wang", "Xingjun Ma"], "title": "LeakyCLIP: Extracting Training Data from CLIP", "comment": null, "summary": "Understanding the memorization and privacy leakage risks in Contrastive\nLanguage--Image Pretraining (CLIP) is critical for ensuring the security of\nmultimodal models. Recent studies have demonstrated the feasibility of\nextracting sensitive training examples from diffusion models, with conditional\ndiffusion models exhibiting a stronger tendency to memorize and leak\ninformation. In this work, we investigate data memorization and extraction\nrisks in CLIP through the lens of CLIP inversion, a process that aims to\nreconstruct training images from text prompts. To this end, we introduce\n\\textbf{LeakyCLIP}, a novel attack framework designed to achieve high-quality,\nsemantically accurate image reconstruction from CLIP embeddings. We identify\nthree key challenges in CLIP inversion: 1) non-robust features, 2) limited\nvisual semantics in text embeddings, and 3) low reconstruction fidelity. To\naddress these challenges, LeakyCLIP employs 1) adversarial fine-tuning to\nenhance optimization smoothness, 2) linear transformation-based embedding\nalignment, and 3) Stable Diffusion-based refinement to improve fidelity.\nEmpirical results demonstrate the superiority of LeakyCLIP, achieving over 358%\nimprovement in Structural Similarity Index Measure (SSIM) for ViT-B-16 compared\nto baseline methods on LAION-2B subset. Furthermore, we uncover a pervasive\nleakage risk, showing that training data membership can even be successfully\ninferred from the metrics of low-fidelity reconstructions. Our work introduces\na practical method for CLIP inversion while offering novel insights into the\nnature and scope of privacy risks in multimodal models.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 Contrastive Language-Image Pretraining(CLIP)\uc5d0\uc11c \uba54\ubaa8\ub9ac\ud654 \ubc0f \uac1c\uc778\uc815\ubcf4 \uc720\ucd9c \uc704\ud5d8\uc744 \ubd84\uc11d\ud558\uba70, LeakyCLIP\uc774\ub77c\ub294 \uacf5\uaca9 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ud1b5\ud574 \uc774\ubbf8\uc9c0 \uc7ac\uad6c\uc131\uc744 \uc218\ud589\ud55c\ub2e4.", "motivation": "CLIP\uc758 \ubcf4\uc548\uc131\uc744 \ubcf4\uc7a5\ud558\uae30 \uc704\ud574 \uba54\ubaa8\ub9ac\ud654 \ubc0f \uac1c\uc778\uc815\ubcf4 \uc720\ucd9c \uc704\ud5d8\uc744 \uc774\ud574\ud558\ub294 \uac83\uc774 \uc911\uc694\ud558\ub2e4.", "method": "LeakyCLIP\uc740 \ube44\ub300\uce6d \ubbf8\uc138 \uc870\uc815, \uc120\ud615 \ubcc0\ud658 \uae30\ubc18 \uc784\ubca0\ub529 \uc815\ub82c \ubc0f \uc548\uc815\uc801\uc778 \ud655\uc0b0 \uae30\ubc18 \uac1c\uc120\uc744 \uc0ac\uc6a9\ud558\uc5ec CLIP \uc5ed\uc124\uacc4\ub97c \uc218\ud589\ud55c\ub2e4.", "result": "LeakyCLIP\uc740 ViT-B-16\uc5d0\uc11c SSIM\uc5d0\uc11c 358% \uc774\uc0c1\uc758 \ud5a5\uc0c1\uc744 \uc774\ub8e8\uc5b4\ub0c8\uc73c\uba70, \ub0ae\uc740 \uc2e0\ub8b0\uc131 \uc7ac\uad6c\uc131\uc758 \uba54\ud2b8\ub9ad\uc2a4\uc5d0\uc11c\ub3c4 \ud6c8\ub828 \ub370\uc774\ud130\uc758 \uba64\ubc84\uc2ed\uc744 \uc720\ucd94\ud560 \uc218 \uc788\ub294 \uc704\ud5d8\uc774 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc8fc\uc5c8\ub2e4.", "conclusion": "\uc774 \uc5f0\uad6c\ub294 CLIP \uc5ed\uc124\uacc4\uc5d0 \ub300\ud55c \uc2e4\uc6a9\uc801\uc778 \ubc29\ubc95\ub860\uc744 \uc81c\uc2dc\ud558\uba70, \ub2e4\uc911\ubaa8\ub2ec \ubaa8\ub378\uc758 \uac1c\uc778\uc815\ubcf4 \uc704\ud5d8\uc5d0 \ub300\ud55c \ud1b5\ucc30\ub825\uc744 \uc81c\uacf5\ud55c\ub2e4."}}
{"id": "2508.00159", "categories": ["cs.AI", "cs.CY", "cs.LG", "econ.TH", "math.OC", "68Txx", "I.2"], "pdf": "https://arxiv.org/pdf/2508.00159", "abs": "https://arxiv.org/abs/2508.00159", "authors": ["Jobst Heitzig", "Ram Potham"], "title": "Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power", "comment": null, "summary": "Power is a key concept in AI safety: power-seeking as an instrumental goal,\nsudden or gradual disempowerment of humans, power balance in human-AI\ninteraction and international AI governance. At the same time, power as the\nability to pursue diverse goals is essential for wellbeing.\n  This paper explores the idea of promoting both safety and wellbeing by\nforcing AI agents explicitly to empower humans and to manage the power balance\nbetween humans and AI agents in a desirable way. Using a principled, partially\naxiomatic approach, we design a parametrizable and decomposable objective\nfunction that represents an inequality- and risk-averse long-term aggregate of\nhuman power. It takes into account humans' bounded rationality and social\nnorms, and, crucially, considers a wide variety of possible human goals.\n  We derive algorithms for computing that metric by backward induction or\napproximating it via a form of multi-agent reinforcement learning from a given\nworld model. We exemplify the consequences of (softly) maximizing this metric\nin a variety of paradigmatic situations and describe what instrumental\nsub-goals it will likely imply. Our cautious assessment is that softly\nmaximizing suitable aggregate metrics of human power might constitute a\nbeneficial objective for agentic AI systems that is safer than direct\nutility-based objectives.", "AI": {"tldr": "AI \uc548\uc804\uc131\uc5d0\uc11c \uad8c\ub825\uc740 \uc911\uc694\ud55c \uac1c\ub150\uc73c\ub85c, \ubcf8 \ub17c\ubb38\uc740 AI\uac00 \uc778\uac04\uc744 \uac15\ud654\ud558\uace0 \uc778\uac04-AI \uac04\uc758 \uad8c\ub825 \uade0\ud615\uc744 \uad00\ub9ac\ud558\ub3c4\ub85d \uac15\uc81c\ud568\uc73c\ub85c\uc368 \uc548\uc804\uc131\uacfc \ubcf5\uc9c0\ub97c \uc99d\uc9c4\ud558\ub294 \ubc29\uc548\uc744 \ud0d0\uad6c\ud55c\ub2e4.", "motivation": "AI\uc758 \uc548\uc804\uc131\uacfc \uc778\uac04 \ubcf5\uc9c0 \uc99d\uc9c4\uc744 \ub3d9\uc2dc\uc5d0 \uc774\ub8e8\uae30 \uc704\ud574 AI\uc758 \uad8c\ub825 \uac1c\ub150\uc744 \ud65c\uc6a9\ud558\ub824\ub294 \ub3d9\uae30.", "method": "\ud30c\ub77c\ubbf8\ud130\ud654 \uac00\ub2a5\ud558\uace0 \ubd84\ud574 \uac00\ub2a5\ud55c \ubaa9\ud45c \ud568\uc218\ub97c \uc124\uacc4\ud558\uc5ec \uc778\uac04\uc758 \uad8c\ub825\uc744 \uc7a5\uae30\uc801\uc73c\ub85c \ud3c9\uac00\ud558\uace0, \uc774\ub97c \ub2e4\uc911 \uc694\uc778 \uac15\ud654 \ud559\uc2b5\uc744 \ud1b5\ud574 \uacc4\uc0b0\ud558\ub294 \uc54c\uace0\ub9ac\uc998\uc744 \ub3c4\ucd9c\ud55c\ub2e4.", "result": "\uc778\uac04\uc758 \uad8c\ub825\uc744 \ube44\uc9c1\uc811\uc801\uc73c\ub85c \ucd5c\ub300\ud654\ud558\ub294 \uac83\uc774 \uc9c1\uc811\uc801\uc778 \ud6a8\uc6a9 \uae30\ubc18 \ubaa9\ud45c\ubcf4\ub2e4 \uc548\uc804\ud55c \ubaa9\ud45c\uac00 \ub420 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc900\ub2e4.", "conclusion": "\uc801\ud569\ud55c \uc778\uac04 \uad8c\ub825 \uc9d1\ud569 \ubaa9\ud45c\ub97c \ubd80\ub4dc\ub7fd\uac8c \ucd5c\ub300\ud654\ud558\ub294 \uac83\uc740 \uc5d0\uc774\uc804\ud2b8 AI \uc2dc\uc2a4\ud15c\uc758 \uc720\uc775\ud55c \ubaa9\ud45c\uac00 \ub420 \uc218 \uc788\ub2e4."}}
{"id": "2508.00131", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00131", "abs": "https://arxiv.org/abs/2508.00131", "authors": ["Christopher Harvey", "Sumaiya Shomaji", "Zijun Yao", "Amit Noheria"], "title": "ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks", "comment": "arXiv admin note: substantial text overlap with arXiv:2410.02937", "summary": "The electrocardiogram (ECG) is an inexpensive and widely available tool for\ncardiac assessment. Despite its standardized format and small file size, the\nhigh complexity and inter-individual variability of ECG signals (typically a\n60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep\nlearning models, especially when only small training datasets are available.\nThis study addresses these challenges by exploring feature generation methods\nfrom representative beat ECGs, focusing on Principal Component Analysis (PCA)\nand Autoencoders to reduce data complexity. We introduce three novel\nVariational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed\nbeta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their\neffectiveness in maintaining signal fidelity and enhancing downstream\nprediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE\nachieved superior signal reconstruction, reducing the mean absolute error (MAE)\nto 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE\nencodings, when combined with traditional ECG summary features, improved the\nprediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an\nholdout test set area under the receiver operating characteristic curve (AUROC)\nof 0.901 with a LGBM classifier. This performance nearly matches the 0.909\nAUROC of state-of-the-art CNN model but requires significantly less\ncomputational resources. Further, the ECG feature extraction-LGBM pipeline\navoids overfitting and retains predictive performance when trained with less\ndata. Our findings demonstrate that these VAE encodings are not only effective\nin simplifying ECG data but also provide a practical solution for applying deep\nlearning in contexts with limited-scale labeled training data.", "AI": {"tldr": "\uc774 \uc5f0\uad6c\ub294 ECG \uc2e0\ud638 \ucc98\ub9ac\ub97c \uc704\ud55c VAE \ubcc0\ud615\uc744 \ud1b5\ud574 \ub370\uc774\ud130 \ubcf5\uc7a1\uc131\uc744 \uc904\uc774\uace0 \uc608\uce21 \uc815\ud655\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud55c\ub2e4.", "motivation": "ECG \uc2e0\ud638\ub294 \ubcf5\uc7a1\ud558\uace0 \uac1c\uc778\ucc28\uac00 \ucee4\uc11c \uae4a\uc740 \ud559\uc2b5 \ubaa8\ub378\uc5d0\uc11c \ub2e4\ub8e8\uae30 \uc5b4\ub835\uace0, \ud2b9\ud788 \uc801\uc740 \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud560 \ub54c \ub354\uc6b1 \uadf8\ub807\ub2e4.", "method": "\uc8fc\uc694 \uc131\ubd84 \ubd84\uc11d(PCA)\uacfc \uc624\ud1a0\uc778\ucf54\ub354\ub97c \ud65c\uc6a9\ud558\uc5ec ECG\uc758 \ud2b9\uc9d5 \uc0dd\uc131\uc744 \ud0d0\uad6c\ud558\uace0, \uc138 \uac00\uc9c0 \uc0c8\ub85c\uc6b4 \ubcc0\ud615\uc758 \ubcc0\ub7c9 \uc624\ud1a0\uc778\ucf54\ub354(VAE)\ub97c \uc81c\uc548\ud55c\ub2e4.", "result": "A beta-VAE\ub294 \uc2e0\ud638 \ubcf5\uc6d0\uc744 \uac1c\uc120\ud558\uc5ec MAE\ub97c 15.7+/-3.2 muV\ub85c \uc904\uc600\uace0, SAE\ub294 \uc804\ud1b5\uc801\uc778 ECG \uc694\uc57d \ud2b9\uc9d5\uacfc \uacb0\ud569\ud558\uc5ec LVEF \uc608\uce21\uc744 \ud5a5\uc0c1\uc2dc\ucf30\ub2e4.", "conclusion": "\uc774 \uc5f0\uad6c\ub294 \uc81c\ud55c\ub41c \ub808\uc774\ube14 \ud6c8\ub828 \ub370\uc774\ud130\ub85c\ub3c4 \uae4a\uc740 \ud559\uc2b5\uc744 \uc801\uc6a9\ud560 \uc218 \uc788\ub294 \uc2e4\uc6a9\uc801\uc778 \uc194\ub8e8\uc158\uc744 \uc81c\uacf5\ud55c\ub2e4."}}
{"id": "2508.00222", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00222", "abs": "https://arxiv.org/abs/2508.00222", "authors": ["Yihong Dong", "Xue Jiang", "Yongding Tao", "Huanyu Liu", "Kechi Zhang", "Lili Mou", "Rongyu Cao", "Yingwei Ma", "Jue Chen", "Binhua Li", "Zhi Jin", "Fei Huang", "Yongbin Li", "Ge Li"], "title": "RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization", "comment": null, "summary": "Reinforcement Learning with Verifiable Reward (RLVR) has significantly\nadvanced the complex reasoning abilities of Large Language Models (LLMs).\nHowever, it struggles to break through the inherent capability boundaries of\nthe base LLM, due to its inherently on-policy strategy with LLM's immense\naction space and sparse reward. Further, RLVR can lead to the capability\nboundary collapse, narrowing the LLM's problem-solving scope. To address this\nproblem, we propose RL-PLUS, a novel approach that synergizes internal\nexploitation (i.e., Thinking) with external data (i.e., Learning) to achieve\nstronger reasoning capabilities and surpass the boundaries of base models.\nRL-PLUS integrates two core components: Multiple Importance Sampling to address\nfor distributional mismatch from external data, and an Exploration-Based\nAdvantage Function to guide the model towards high-value, unexplored reasoning\npaths. We provide both theoretical analysis and extensive experiments to\ndemonstrate the superiority and generalizability of our approach. The results\nshow that RL-PLUS achieves state-of-the-art performance compared with existing\nRLVR methods on six math reasoning benchmarks and exhibits superior performance\non six out-of-distribution reasoning tasks. It also achieves consistent and\nsignificant gains across diverse model families, with average relative\nimprovements ranging from 21.1\\% to 69.2\\%. Moreover, Pass@k curves across\nmultiple benchmarks indicate that RL-PLUS effectively resolves the capability\nboundary collapse problem.", "AI": {"tldr": "\ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 RL-PLUS\ub77c\ub294 \uc0c8\ub85c\uc6b4 \uc811\uadfc \ubc29\uc2dd\uc744 \uc81c\uc548\ud558\uc5ec RLVR\uc758 \ud55c\uacc4\ub97c \uadf9\ubcf5\ud558\uace0 LLM\uc758 \ucd94\ub860 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "motivation": "RLVR\uc740 LLM\uc758 \ubcf5\uc7a1\ud55c \uc0ac\uace0 \ub2a5\ub825\uc744 \uc9c4\uc804\uc2dc\ucf30\uc9c0\ub9cc, \uae30\ubcf8 LLM\uc758 \uae30\ub2a5 \ud55c\uacc4\ub97c \uadf9\ubcf5\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "method": "RL-PLUS\ub294 \ub0b4\ubd80 \ud65c\uc6a9(Think)\uacfc \uc678\ubd80 \ub370\uc774\ud130(Learning)\ub97c \ud1b5\ud569\ud558\uc5ec \ub2e4\uc911 \uc911\uc694 \uc0d8\ud50c\ub9c1\uacfc \ud0d0\uc0c9 \uae30\ubc18 \uc774\uc810 \ud568\uc218\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.", "result": "\uc2e4\ud5d8 \uacb0\uacfc RL-PLUS\ub294 \uae30\uc874 RLVR \ubc29\ubc95\uc5d0 \ube44\ud574 \ud5a5\uc0c1\ub41c \uc131\ub2a5\uc744 \ubcf4\uc774\uba70, \ub2e4\uc591\ud55c \ubaa8\ub378 \uac00\uc871\uc5d0\uc11c \uc77c\uad00\ub41c \uc131\uacfc \uac1c\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "conclusion": "RL-PLUS\ub294 \uae30\ub2a5 \uacbd\uacc4 \ubd95\uad34 \ubb38\uc81c\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud574\uacb0\ud558\uba70, \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4."}}
{"id": "2508.00141", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00141", "abs": "https://arxiv.org/abs/2508.00141", "authors": ["Mohit Gupta", "Debjit Bhowmick", "Rhys Newbury", "Meead Saberi", "Shirui Pan", "Ben Beck"], "title": "INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks", "comment": null, "summary": "Accurate link-level bicycling volume estimation is essential for sustainable\nurban transportation planning. However, many cities face significant challenges\nof high data sparsity due to limited bicycling count sensor coverage. To\naddress this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning\n(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize\nsensor placement and improve link-level bicycling volume estimation in\ndata-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks\n(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL\nagent, enabling a data-driven strategic selection of sensor locations to\nmaximize estimation performance. Applied to Melbourne's bicycling network,\ncomprising 15,933 road segments with sensor coverage on only 141 road segments\n(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume\nestimation by strategically selecting additional sensor locations in\ndeployments of 50, 100, 200 and 500 sensors. Our framework outperforms\ntraditional heuristic methods for sensor placement such as betweenness\ncentrality, closeness centrality, observed bicycling activity and random\nplacement, across key metrics such as Mean Squared Error (MSE), Root Mean\nSquared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our\nexperiments benchmark INSPIRE-GNN against standard machine learning and deep\nlearning models in the bicycle volume estimation performance, underscoring its\neffectiveness. Our proposed framework provides transport planners actionable\ninsights to effectively expand sensor networks, optimize sensor placement and\nmaximize volume estimation accuracy and reliability of bicycling data for\ninformed transportation planning decisions.", "AI": {"tldr": "INSPIRE-GNN\uc740 \ud76c\uc18c\ud55c \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud558\uc5ec \uc790\uc804\uac70 \uad50\ud1b5\ub7c9 \ucd94\uc815\uc744 \ucd5c\uc801\ud654\ud558\ub294 \uc0c8\ub85c\uc6b4 \uac15\ud654 \ud559\uc2b5 \uae30\ubc18 \uadf8\ub798\ud504 \uc2e0\uacbd\ub9dd \ud504\ub808\uc784\uc6cc\ud06c\uc785\ub2c8\ub2e4.", "motivation": "\ub3c4\uc2dc\uc758 \uc9c0\uc18d \uac00\ub2a5\ud55c \uad50\ud1b5 \uacc4\ud68d\uc744 \uc704\ud55c \uc815\ud655\ud55c \uc790\uc804\uac70 \uad50\ud1b5\ub7c9 \ucd94\uc815\uc758 \ud544\uc694\uc131 \ubc0f \uc13c\uc11c \ucee4\ubc84\ub9ac\uc9c0\uc758 \ubd80\uc871 \ubb38\uc81c \ud574\uacb0.", "method": "\uadf8\ub798\ud504 \ud569\uc131\uacf1 \ub124\ud2b8\uc6cc\ud06c(GCN)\uc640 \uadf8\ub798\ud504 \uc8fc\uc758 \ub124\ud2b8\uc6cc\ud06c(GAT)\ub97c \uacb0\ud569\ud55c \uac15\ud654 \ud559\uc2b5 \uae30\ubc18\uc758 INSPIRE-GNN \ud504\ub808\uc784\uc6cc\ud06c \uc81c\uc548.", "result": "\uba5c\ubc84\ub978\uc758 \uc790\uc804\uac70 \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c 99%\uc758 \ub370\uc774\ud130 \ud76c\uc18c\uc131\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0, \ucd94\uac00 \uc13c\uc11c\ub97c \uc804\ub7b5\uc801\uc73c\ub85c \ubc30\uce58\ud558\uc5ec \ub370\uc774\ud130 \ucd94\uc815 \uc131\ub2a5\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0b4.", "conclusion": "INSPIRE-GNN\uc740 \uc13c\uc11c \ub124\ud2b8\uc6cc\ud06c \ud655\uc7a5 \ubc0f \ucd5c\uc801\ud654\ub97c \uc704\ud55c \uc2e4\ud589 \uac00\ub2a5\ud55c \ud1b5\ucc30\ub825\uc744 \uc81c\uacf5\ud558\uc5ec \uc790\uc804\uac70 \ub370\uc774\ud130\uc758 \uc815\ud655\uc131\uacfc \uc2e0\ub8b0\uc131\uc744 \ub192\uc784."}}
{"id": "2508.00271", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.00271", "abs": "https://arxiv.org/abs/2508.00271", "authors": ["Hongjin Qian", "Zheng Liu"], "title": "MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning", "comment": "Technical Report, 14 pages", "summary": "In this work, we propose MetaAgent, an agentic paradigm inspired by the\nprinciple of learning-by-doing, where expertise is developed through hands-on\npractice and continual self-improvement. MetaAgent starts with a minimal\nworkflow, equipped only with basic reasoning and adaptive help-seeking\nabilities. When a knowledge gap is encountered, MetaAgent generates natural\nlanguage help requests, which are routed to the most suitable external tool by\na dedicated tool router. As MetaAgent solves tasks, it continually conducts\nself-reflection and answer verification, distilling actionable experience into\nconcise texts that are dynamically incorporated into future task contexts.\nBesides, MetaAgent autonomously builds in-house tools and a persistent\nknowledge base by organizing its tool-use history, further enhancing its\nability to retrieve and integrate relevant information We term this continual,\ndata-driven process as \\textit{meta tool learning}, through which MetaAgent\nincrementally refines its reasoning and tool-use strategies, without changing\nmodel parameters or requiring further post-training. Evaluated on challenging\nknowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,\nMetaAgent consistently outperforms workflow-based baselines and matches or\nexceeds end-to-end trained agents, demonstrating the promise of self-evolving\nagentic systems for robust, general-purpose knowledge discovery. We provide our\nsource codes in https://github.com/qhjqhj00/MetaAgent.", "AI": {"tldr": "MetaAgent\ub294 \ud559\uc2b5-\uc2e4\ucc9c \uc6d0\uce59\uc5d0 \uae30\ubc18\ud55c \uc790\uac00 \ubc1c\uc804\ud615 \uc5d0\uc774\uc804\ud2b8\ub85c, \uc9c0\uc2dd \uaca9\ucc28\ub97c \uc790\uc5f0\uc5b4 \uc694\uccad\uc73c\ub85c \ud574\uacb0\ud558\uace0 \uc2a4\uc2a4\ub85c \ub3c4\uad6c\uc640 \uc9c0\uc2dd \uae30\ubc18\uc744 \uad6c\ucd95\ud558\uba70, \uc9c0\uc18d\uc801\uc778 \uc790\uae30 \ubc18\uc131\uacfc \ub370\uc774\ud130 \uae30\ubc18 \ud559\uc2b5\uc744 \ud1b5\ud574 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4.", "motivation": "\uc9c0\uc18d\uc801\uc778 \ud559\uc2b5 \ubc0f \uc790\uae30 \uac1c\uc120\uc744 \ud1b5\ud574 \uc5d0\uc774\uc804\ud2b8\uc758 \uc804\ubb38\uc131\uc744 \ubc1c\uc804\uc2dc\ud0a4\ub294 \uc0c8\ub85c\uc6b4 \ud328\ub7ec\ub2e4\uc784\uc744 \uc81c\uc548\ud558\uace0\uc790 \ud55c\ub2e4.", "method": "MetaAgent\ub294 \ucd5c\uc18c\ud55c\uc758 \uc6cc\ud06c\ud50c\ub85c\uc6b0\ub85c \uc2dc\uc791\ud574, \uc790\uc5f0\uc5b4 \ub3c4\uc6c0 \uc694\uccad\uc744 \uc0dd\uc131\ud558\uace0 \uc801\uc808\ud55c \uc678\ubd80 \ub3c4\uad6c\uc5d0 \uc804\ub2ec\ud558\uba70, \uc790\uae30 \uc131\ucc30\uacfc \uac80\uc99d\uc744 \ud1b5\ud574 \uacbd\ud5d8\uc744 \uac04\uacb0\ud55c \ud14d\uc2a4\ud2b8\ub85c \uc815\ub9ac\ud558\uace0 \ub2e4\uc74c \uc791\uc5c5\uc5d0 \ud1b5\ud569\ud55c\ub2e4.", "result": "MetaAgent\ub294 GAIA, WebWalkerQA, BrowseCamp\uc640 \uac19\uc740 \uc9c0\uc2dd \ubc1c\uacac \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uae30\uc874 \uc6cc\ud06c\ud50c\ub85c\uc6b0 \uae30\ubc18 \ubaa8\ub378\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc774\uba70, \uc5d4\ub4dc\ud22c\uc5d4\ub4dc \ud559\uc2b5\ub41c \uc5d0\uc774\uc804\ud2b8\uc640 \uc720\uc0ac\ud55c \uc218\uc900\uc758 \uc131\uacfc\ub97c \ub0b8\ub2e4.", "conclusion": "\uc790\uae30 \ubc1c\uc804\ud615 \uc5d0\uc774\uc804\ud2b8 \uc2dc\uc2a4\ud15c\uc740 \uc9c0\uc2dd \ubc1c\uacac \ubd84\uc57c\uc5d0\uc11c \uac15\ub825\ud558\uace0 \uc77c\ubc18\uc801\uc778 \uc131\ub2a5\uc744 \ubc1c\ud718\ud560 \uac00\ub2a5\uc131\uc774 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00161", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00161", "abs": "https://arxiv.org/abs/2508.00161", "authors": ["Ziqian Zhong", "Aditi Raghunathan"], "title": "Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs", "comment": null, "summary": "The releases of powerful open-weight large language models (LLMs) are often\nnot accompanied by access to their full training data. Existing\ninterpretability methods, particularly those based on activations, often\nrequire or assume distributionally similar data. This is a significant\nlimitation when detecting and defending against novel potential threats like\nbackdoors, which are by definition out-of-distribution.\n  In this work, we introduce a new method for understanding, monitoring and\ncontrolling fine-tuned LLMs that interprets weights, rather than activations,\nthereby side stepping the need for data that is distributionally similar to the\nunknown training data. We demonstrate that the top singular vectors of the\nweight difference between a fine-tuned model and its base model correspond to\nnewly acquired behaviors. By monitoring the cosine similarity of activations\nalong these directions, we can detect salient behaviors introduced during\nfine-tuning with high precision.\n  For backdoored models that bypasses safety mechanisms when a secret trigger\nis present, our method stops up to 100% of attacks with a false positive rate\nbelow 1.2%. For models that have undergone unlearning, we detect inference on\nerased topics with accuracy up to 95.42% and can even steer the model to\nrecover \"unlearned\" information. Besides monitoring, our method also shows\npotential for pre-deployment model auditing: by analyzing commercial\ninstruction-tuned models (OLMo, Llama, Qwen), we are able to uncover\nmodel-specific fine-tuning focus including marketing strategies and Midjourney\nprompt generation.\n  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \ucd9c\uc2dc\ub41c \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uac00\uc911\uce58\ub97c \ud574\uc11d\ud558\uc5ec \ud30c\uc778\ud29c\ub2dd \ub3d9\uc548 \ubc1c\uc0dd\ud558\ub294 \uc0c8\ub85c\uc6b4 \ud589\ub3d9\uc744 \uac10\uc9c0\ud558\uace0, \ud6a8\uacfc\uc801\uc73c\ub85c \ubc31\ub3c4\uc5b4 \uacf5\uaca9\uc744 \ubc29\uc5b4\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud55c\ub2e4.", "motivation": "\uae30\uc874\uc758 \ud574\uc11d \ubc29\ubc95\uc774 \ubd84\ud3ec\uc801\uc73c\ub85c \uc720\uc0ac\ud55c \ub370\uc774\ud130\ub97c \uc694\uad6c\ud558\uac70\ub098 \uac00\uc815\ud558\ub294 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uace0, \ubc31\ub3c4\uc5b4\uc640 \uac19\uc740 \uc0c8\ub85c\uc6b4 \uc704\ud611\uc744 \ud0d0\uc9c0\ud558\uae30 \uc704\ud574.", "method": "\ubaa8\ub378\uc758 \ud65c\uc131\ud654 \ub300\uc2e0 \uac00\uc911\uce58\ub97c \ud574\uc11d\ud558\uc5ec \ud30c\uc778\ud29c\ub2dd\uc5d0 \ub530\ub978 \uc0c8\ub85c\uc6b4 \ud589\ub3d9\uc744 \uac10\uc9c0\ud558\uace0, \ucf54\uc0ac\uc778 \uc720\uc0ac\ub3c4\ub97c \ud1b5\ud574 \ud589\ub3d9\uc744 \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud55c\ub2e4.", "result": "\ud30c\uc778\ud29c\ub2dd\ub41c \ubaa8\ub378\uacfc \uae30\ubcf8 \ubaa8\ub378 \uac04\uc758 \uac00\uc911\uce58 \ucc28\uc774\uc758 \uc8fc\uc694 \ud2b9\uc774\uac12 \ubca1\ud130\uac00 \uc0c8\ub86d\uac8c \ud68d\ub4dd\ud55c \ud589\ub3d9\uacfc \ub300\uc751\ud558\uba70, \ubc31\ub3c4\uc5b4 \uacf5\uaca9\uc744 100% \ucc28\ub2e8\ud558\uace0, \uc0ad\uc81c\ub41c \ud1a0\ud53d\uc5d0 \ub300\ud55c \ucd94\ub860\uc744 95.42%\uc758 \uc815\ud655\ub3c4\ub85c \uac10\uc9c0\ud55c\ub2e4.", "conclusion": "\uc774 \ubc29\ubc95\uc740 \ubaa8\ub378 \ubaa8\ub2c8\ud130\ub9c1 \uc678\uc5d0\ub3c4 \uc0ac\uc804 \ubc30\ud3ec \ubaa8\ub378 \uac10\uc0ac\uc758 \uc7a0\uc7ac\ub825\uc744 \ubcf4\uc5ec\uc8fc\uba70, \uc0c1\uc5c5\uc801 \ubaa8\ub378\uc758 \ud30c\uc778\ud29c\ub2dd \ucd08\uc810\uc744 \ubc1c\uacac\ud560 \uc218 \uc788\ub2e4."}}
{"id": "2508.00282", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00282", "abs": "https://arxiv.org/abs/2508.00282", "authors": ["Yi-Long Lu", "Jiajun Song", "Chunhui Zhang", "Wei Wang"], "title": "Mind the Gap: The Divergence Between Human and LLM-Generated Tasks", "comment": null, "summary": "Humans constantly generate a diverse range of tasks guided by internal\nmotivations. While generative agents powered by large language models (LLMs)\naim to simulate this complex behavior, it remains uncertain whether they\noperate on similar cognitive principles. To address this, we conducted a\ntask-generation experiment comparing human responses with those of an LLM agent\n(GPT-4o). We find that human task generation is consistently influenced by\npsychological drivers, including personal values (e.g., Openness to Change) and\ncognitive style. Even when these psychological drivers are explicitly provided\nto the LLM, it fails to reflect the corresponding behavioral patterns. They\nproduce tasks that are markedly less social, less physical, and thematically\nbiased toward abstraction. Interestingly, while the LLM's tasks were perceived\nas more fun and novel, this highlights a disconnect between its linguistic\nproficiency and its capacity to generate human-like, embodied goals.We conclude\nthat there is a core gap between the value-driven, embodied nature of human\ncognition and the statistical patterns of LLMs, highlighting the necessity of\nincorporating intrinsic motivation and physical grounding into the design of\nmore human-aligned agents.", "AI": {"tldr": "\uc778\uac04\uacfc LLM(GPT-4o)\uc758 \uacfc\uc81c \uc0dd\uc131 \ube44\uad50 \uc2e4\ud5d8\uc744 \ud1b5\ud574 \uc778\uac04\uc758 \uacfc\uc81c \uc0dd\uc131\uc774 \uc2ec\ub9ac\uc801 \ub3d9\uc778\uc758 \uc601\ud5a5\uc744 \ubc1b\ub294 \ubc18\uba74 LLM\uc740 \uc774\uc5d0 \uc801\ud569\ud55c \ud589\ub3d9 \ud328\ud134\uc744 \ubc18\uc601\ud558\uc9c0 \ubabb\ud568\uc744 \ubc1c\uacac\ud588\ub2e4.", "motivation": "\uc778\uac04\uc758 \ub0b4\ubd80 \ub3d9\uae30\uc5d0 \uc758\ud574 \uc0dd\uc131\ub418\ub294 \ub2e4\uc591\ud55c \uacfc\uc81c\ub97c \uc870\uc0ac\ud558\uace0, LLM\uc758 \ud589\ub3d9 \uc6d0\ub9ac\uac00 \uc778\uac04\uacfc \uc720\uc0ac\ud55c\uc9c0 \ud655\uc778\ud558\uace0\uc790 \ud588\ub2e4.", "method": "\uc778\uac04\uc758 \uacfc\uc81c \uc0dd\uc131 \ubc18\uc751\uacfc LLM\uc758 \ubc18\uc751\uc744 \ube44\uad50\ud558\ub294 \uacfc\uc81c \uc0dd\uc131 \uc2e4\ud5d8\uc744 \uc218\ud589\ud588\ub2e4.", "result": "\uc778\uac04\uc740 \uc2ec\ub9ac\uc801 \ub3d9\uc778\uc5d0 \uc758\ud574 \uac15\ud558\uac8c \uc601\ud5a5\uc744 \ubc1b\ub294 \ubc18\uba74, LLM\uc740 \uc0ac\ud68c\uc801, \uc2e0\uccb4\uc801 \uacfc\uc81c\ub97c \ub35c \uc0dd\uc131\ud558\uace0 \ucd94\uc0c1\uc801\uc778 \ud14c\ub9c8\uc5d0 \ud3b8\ud5a5\ub41c \uacfc\uc81c\ub97c \ub9cc\ub4e0\ub2e4.", "conclusion": "\uc778\uac04\uc758 \uac00\uce58 \uae30\ubc18 \uc778\uc9c0 \ubc29\uc2dd\uacfc LLM\uc758 \ud1b5\uacc4\uc801 \ud328\ud134 \uac04\uc5d0 \ud575\uc2ec\uc801\uc778 \uaca9\ucc28\uac00 \uc788\uc73c\uba70, \uc778\uac04\uacfc \ub354 \uc798 \ub9de\ub294 \uc5d0\uc774\uc804\ud2b8 \uc124\uacc4\uc5d0 \uc788\uc5b4 \ub0b4\uc7ac\uc801 \ub3d9\uae30\uc640 \uc2e0\uccb4\uc801 \uae30\ubc18\uc744 \ud1b5\ud569\ud560 \ud544\uc694\uc131\uc774 \uac15\uc870\ub41c\ub2e4."}}
{"id": "2508.00172", "categories": ["cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2508.00172", "abs": "https://arxiv.org/abs/2508.00172", "authors": ["Fupei Guo", "Hao Zheng", "Xiang Zhang", "Li Chen", "Yue Wang", "Songyang Zhang"], "title": "DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission", "comment": "To appear in 2025 IEEE Global Communications Conference (Globecom)", "summary": "The rapid development of artificial intelligence has driven smart health with\nnext-generation wireless communication technologies, stimulating exciting\napplications in remote diagnosis and intervention. To enable a timely and\neffective response for remote healthcare, efficient transmission of medical\ndata through noisy channels with limited bandwidth emerges as a critical\nchallenge. In this work, we propose a novel diffusion-based semantic\ncommunication framework, namely DiSC-Med, for the medical image transmission,\nwhere medical-enhanced compression and denoising blocks are developed for\nbandwidth efficiency and robustness, respectively. Unlike conventional\npixel-wise communication framework, our proposed DiSC-Med is able to capture\nthe key semantic information and achieve superior reconstruction performance\nwith ultra-high bandwidth efficiency against noisy channels. Extensive\nexperiments on real-world medical datasets validate the effectiveness of our\nframework, demonstrating its potential for robust and efficient telehealth\napplications.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \uc758\ub8cc \uc774\ubbf8\uc9c0 \uc804\uc1a1\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \ud655\uc0b0 \uae30\ubc18 \uc758\ubbf8 \ud1b5\uc2e0 \ud504\ub808\uc784\uc6cc\ud06c\uc778 DiSC-Med\ub97c \uc81c\uc548\ud558\uba70, \uc774\ub294 \ub300\uc5ed\ud3ed \ud6a8\uc728\uc131\uacfc \uac15\uc778\uc131\uc744 \uc704\ud574 \uc758\ub8cc \ud5a5\uc0c1 \uc555\ucd95 \ubc0f \uc7a1\uc74c \uc81c\uac70 \ube14\ub85d\uc744 \uac1c\ubc1c\ud55c\ub2e4.", "motivation": "\uc778\uacf5\uc9c0\ub2a5\uc758 \ubc1c\uc804\uacfc \ucc28\uc138\ub300 \ubb34\uc120 \ud1b5\uc2e0 \uae30\uc220\uc774 \uc6d0\uaca9 \uc9c4\ub2e8 \ubc0f \uac1c\uc785\uc5d0 \ub300\ud55c \ud765\ubbf8\ub85c\uc6b4 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \uc790\uadf9\ud558\uba74\uc11c, \uc81c\ud55c\ub41c \ub300\uc5ed\ud3ed\uacfc \uc7a1\uc74c\uc774 \ub9ce\uc740 \ucc44\ub110\uc744 \ud1b5\ud55c \uc758\ub8cc \ub370\uc774\ud130\uc758 \ud6a8\uc728\uc801\uc778 \uc804\uc1a1\uc774 \uc911\uc694\ud574\uc84c\ub2e4.", "method": "DiSC-Med\ub294 \uc758\ub8cc \uc774\ubbf8\uc9c0 \uc804\uc1a1\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \ud504\ub808\uc784\uc6cc\ud06c\ub85c, \uc758\ub8cc \ud5a5\uc0c1 \uc555\ucd95 \ubc0f \uc7a1\uc74c \uc81c\uac70 \ube14\ub85d\uc744 \ud1b5\ud574 \ub300\uc5ed\ud3ed \ud6a8\uc728\uc131\uacfc \uac15\uc778\uc131\uc744 \ud655\ubcf4\ud55c\ub2e4.", "result": "\uc2e4\uc81c \uc758\ub8cc \ub370\uc774\ud130 \uc138\ud2b8\uc5d0 \ub300\ud55c \uc2e4\ud5d8\uc744 \ud1b5\ud574 DiSC-Med\uc758 \ud6a8\uacfc\uac00 \uc785\uc99d\ub418\uc5c8\uc73c\uba70, \uc6d0\uaca9 \uc758\ub8cc \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc5d0 \ub300\ud55c \uac00\ub2a5\uc131\uc744 \ubcf4\uc5ec\uc900\ub2e4.", "conclusion": "\uc6b0\ub9ac\uc758 \ud504\ub808\uc784\uc6cc\ud06c\ub294 \uc804\ud1b5\uc801\uc778 \ud53d\uc140 \uae30\ubc18 \ud1b5\uc2e0 \ubc29\ubc95\uacfc \ub2ec\ub9ac \ud575\uc2ec \uc758\ubbf8 \uc815\ubcf4\ub97c \ud3ec\ucc29\ud558\uace0 \uc7a1\uc74c \ucc44\ub110\uc5d0 \ub300\ud574 \ucd08\uace0\ub300\uc5ed\ud3ed \ud6a8\uc728\uc131\uc744 \ub2ec\uc131\ud558\uc5ec \ub6f0\uc5b4\ub09c \uc7ac\uad6c\uc131 \uc131\ub2a5\uc744 \uc81c\uacf5\ud55c\ub2e4."}}
{"id": "2508.00323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00323", "abs": "https://arxiv.org/abs/2508.00323", "authors": ["Jianyi Zhang", "Xu Ji", "Ziyin Zhou", "Yuchen Zhou", "Shubo Shi", "Haoyu Wu", "Zhen Li", "Shizhao Liu"], "title": "Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning", "comment": null, "summary": "Evaluating the performance of visual language models (VLMs) in graphic\nreasoning tasks has become an important research topic. However, VLMs still\nshow obvious deficiencies in simulating human-level graphic reasoning\ncapabilities, especially in complex graphic reasoning and abstract problem\nsolving, which are less studied and existing studies only focus on simple\ngraphics. To evaluate the performance of VLMs in complex graphic reasoning, we\npropose ReasonBench, the first evaluation benchmark focused on structured\ngraphic reasoning tasks, which includes 1,613 questions from real-world\nintelligence tests. ReasonBench covers reasoning dimensions related to\nlocation, attribute, quantity, and multi-element tasks, providing a\ncomprehensive evaluation of the performance of VLMs in spatial, relational, and\nabstract reasoning capabilities. We benchmark 11 mainstream VLMs (including\nclosed-source and open-source models) and reveal significant limitations of\ncurrent models. Based on these findings, we propose a dual optimization\nstrategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability\nof reasoning by decomposing layers, and ReasonTune enhances the task\nadaptability of model reasoning through training, all of which improves VLM\nperformance by 33.5\\%. All experimental data and code are in the repository:\nhttps://huggingface.co/datasets/cistine/ReasonBench.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc2dc\uac01 \uc5b8\uc5b4 \ubaa8\ub378(VLM)\uc758 \ubcf5\uc7a1\ud55c \uadf8\ub798\ud53d \ucd94\ub860 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 ReasonBench\ub77c\ub294 \uc0c8\ub85c\uc6b4 \ubca4\uce58\ub9c8\ud06c\ub97c \uc81c\uc548\ud55c\ub2e4.", "motivation": "VLM\uc774 \uc778\uac04 \uc218\uc900\uc758 \uadf8\ub798\ud53d \ucd94\ub860 \ub2a5\ub825\uc744 \ubaa8\uc0ac\ud558\ub294 \ub370 \uba85\ubc31\ud55c \ud55c\uacc4\uac00 \uc788\uc73c\uba70, \ubcf5\uc7a1\ud55c \ubb38\uc81c \ud574\uacb0\uc5d0\uc11c\uc758 \uc131\ub2a5 \ubd80\uc871\uc774 \uc788\ub2e4.", "method": "1,613\uac1c\uc758 \uc9c8\ubb38\uc73c\ub85c \uad6c\uc131\ub41c ReasonBench\ub97c \uc0ac\uc6a9\ud558\uc5ec 11\uac1c\uc758 VLM\uc744 \ud3c9\uac00\ud558\uace0, DiaCoT\uc640 ReasonTune\uc774\ub77c\ub294 \uc774\uc911 \ucd5c\uc801\ud654 \uc804\ub7b5\uc744 \ud1b5\ud574 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4.", "result": "\ud604\uc7ac VLM\uc758 \uc0c1\ub2f9\ud55c \ud55c\uacc4\ub97c \ub4dc\ub7ec\ub0b4\uc5c8\uace0, \uc81c\uc548\ud55c \ubc29\ubc95\uc73c\ub85c \uc131\ub2a5\uc744 33.5% \ud5a5\uc0c1\uc2dc\ucf30\ub2e4.", "conclusion": "ReasonBench\ub294 VLM\uc758 \uc131\ub2a5\uc744 \ud3ec\uad04\uc801\uc73c\ub85c \ud3c9\uac00\ud558\ub294 \ub370 \uae30\uc5ec\ud558\uba70, \ud5a5\ud6c4 \uc5f0\uad6c\uc5d0 \uc911\uc694\ud55c \uae30\ucd08 \uc790\ub8cc\uac00 \ub420 \uac83\uc774\ub2e4."}}
{"id": "2508.00174", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00174", "abs": "https://arxiv.org/abs/2508.00174", "authors": ["Yongchao Huang"], "title": "RL as Regressor: A Reinforcement Learning Approach for Function Approximation", "comment": "7 pages", "summary": "Standard regression techniques, while powerful, are often constrained by\npredefined, differentiable loss functions such as mean squared error. These\nfunctions may not fully capture the desired behavior of a system, especially\nwhen dealing with asymmetric costs or complex, non-differentiable objectives.\nIn this paper, we explore an alternative paradigm: framing regression as a\nReinforcement Learning (RL) problem. We demonstrate this by treating a model's\nprediction as an action and defining a custom reward signal based on the\nprediction error, and we can leverage powerful RL algorithms to perform\nfunction approximation. Through a progressive case study of learning a noisy\nsine wave, we illustrate the development of an Actor-Critic agent, iteratively\nenhancing it with Prioritized Experience Replay, increased network capacity,\nand positional encoding to enable a capable RL agent for this regression task.\nOur results show that the RL framework not only successfully solves the\nregression problem but also offers enhanced flexibility in defining objectives\nand guiding the learning process.", "AI": {"tldr": "\uc804\ud1b5\uc801\uc778 \ud68c\uadc0 \uae30\ubc95 \ub300\uc2e0 \uac15\ud654 \ud559\uc2b5 \ubb38\uc81c\ub85c \ud68c\uadc0\ub97c \uad6c\uc131\ud558\uc5ec \uc608\uce21 \uc624\ub958 \uae30\ubc18\uc758 \ucee4\uc2a4\ud140 \ubcf4\uc0c1 \uc2e0\ud638\ub97c \ud65c\uc6a9\ud55c \uc811\uadfc \ubc29\uc2dd.", "motivation": "\uae30\uc874 \ud68c\uadc0 \uae30\ubc95\uc774 \ube44\ub300\uce6d \ube44\uc6a9\uc774\ub098 \ubcf5\uc7a1\ud55c \ube44\ubbf8\ubd84 \uac00\ub2a5 \ubaa9\ud45c\ub97c \uc644\uc804\ud788 \ud3ec\ucc29\ud558\uc9c0 \ubabb\ud558\ub294 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uace0\uc790 \ud568.", "method": "\ubaa8\ub378\uc758 \uc608\uce21\uc744 \ud589\ub3d9\uc73c\ub85c \ucc98\ub9ac\ud558\uace0, \uc608\uce21 \uc624\ub958\uc5d0 \uae30\ubc18\ud55c \ucee4\uc2a4\ud140 \ubcf4\uc0c1 \uc2e0\ud638\ub97c \uc815\uc758\ud558\uc5ec \uac15\ud654 \ud559\uc2b5 \uc54c\uace0\ub9ac\uc998\uc744 \ud1b5\ud55c \ud568\uc218 \uadfc\uc0ac\ub97c \uc218\ud589.", "result": "\ub178\uc774\uc988\uac00 \uc788\ub294 \uc0ac\uc778\ud30c \ud559\uc2b5\uc758 \uc810\uc9c4\uc801 \uc0ac\ub840 \uc5f0\uad6c\ub97c \ud1b5\ud574 \uac15\ud654 \ud559\uc2b5 \uc5d0\uc774\uc804\ud2b8\uc758 \uac1c\ubc1c\uc744 \uc2dc\uc5f0\ud558\uba70, Prioritized Experience Replay \ubc0f \ub124\ud2b8\uc6cc\ud06c \uc6a9\ub7c9 \uc99d\uac00 \ub4f1\uc744 \ub2e8\uacc4\uc801\uc73c\ub85c \uc801\uc6a9.", "conclusion": "\uac15\ud654 \ud559\uc2b5 \ud504\ub808\uc784\uc6cc\ud06c\uac00 \ud68c\uadc0 \ubb38\uc81c\ub97c \ud574\uacb0\ud560 \ubfd0\ub9cc \uc544\ub2c8\ub77c \ubaa9\ud45c \uc815\uc758\uc640 \ud559\uc2b5 \uacfc\uc815\uc744 \uc548\ub0b4\ud558\ub294 \ub370 \uc788\uc5b4 \uc720\uc5f0\uc131\uc744 \uc81c\uacf5\ud568\uc744 \ubcf4\uc5ec\uc90c."}}
{"id": "2508.00324", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00324", "abs": "https://arxiv.org/abs/2508.00324", "authors": ["Yeonjun In", "Wonjoong Kim", "Sangwu Park", "Chanyoung Park"], "title": "R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge", "comment": "under review", "summary": "Although large reasoning models (LRMs) have demonstrated impressive\ncapabilities on complex tasks, recent studies reveal that these models\nfrequently fulfill harmful user instructions, raising significant safety\nconcerns. In this paper, we investigate the underlying cause of LRM safety\nrisks and find that models already possess sufficient safety knowledge but fail\nto activate it during reasoning. Based on this insight, we propose R1-Act, a\nsimple and efficient post-training method that explicitly triggers safety\nknowledge through a structured reasoning process. R1-Act achieves strong safety\nimprovements while preserving reasoning performance, outperforming prior\nalignment methods. Notably, it requires only 1,000 training examples and 90\nminutes of training on a single RTX A6000 GPU. Extensive experiments across\nmultiple LRM backbones and sizes demonstrate the robustness, scalability, and\npractical efficiency of our approach.", "AI": {"tldr": "\ubcf8 \ub17c\ubb38\uc740 LRM\uc758 \uc548\uc804\uc131 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 R1-Act\ub77c\ub294 \uac04\ub2e8\ud55c \ud6c4\ucc98\ub9ac \ubc29\ubc95\uc744 \uc81c\uc548\ud558\uba70, \uc774\ub294 \uc548\uc804 \uc9c0\uc2dd\uc744 \ud65c\uc131\ud654\ud558\uc5ec \uc548\uc804\uc131\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4.", "motivation": "LRM\uc774 \ubcf5\uc7a1\ud55c \uc791\uc5c5\uc5d0\uc11c \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc774\uc9c0\ub9cc, \uc720\ud574\ud55c \uc0ac\uc6a9\uc790 \uc9c0\uce68\uc744 \uc218\uc6a9\ud558\uc5ec \uc548\uc804 \ubb38\uc81c\ub97c \uc57c\uae30\ud568.", "method": "\uc548\uc804 \uc9c0\uc2dd\uc744 \uad6c\uc870\uc801 \ucd94\ub860 \uacfc\uc815\uc744 \ud1b5\ud574 \uba85\uc2dc\uc801\uc73c\ub85c \ud65c\uc131\ud654\ud558\ub294 R1-Act\ub77c\ub294 \ubc29\ubc95 \uc81c\uc548.", "result": "R1-Act\ub294 \uc774\uc804\uc758 \uc815\ub82c \ubc29\ubc95\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc548\uc804\uc131 \ud5a5\uc0c1\uc744 \uc774\ub8e8\uc5c8\uc73c\uba70, \ub2e4\uc591\ud55c LRM \ubc31\ubcf8\uacfc \ud06c\uae30\uc5d0 \ub300\ud574 \uac15\ub825\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90c.", "conclusion": "R1-Act\ub294 \uc18c\ub7c9\uc758 \ud6c8\ub828 \uc0d8\ud50c\uacfc \uc9e7\uc740 \ud6c8\ub828 \uc2dc\uac04\uc73c\ub85c\ub3c4 \uc548\uc804\uc131\uacfc \ucd94\ub860 \uc131\ub2a5\uc744 \ub3d9\uc2dc\uc5d0 \uac1c\uc120\ud558\ub294 \ud6a8\uacfc\uc801\uc778 \ubc29\ubc95\uc774\ub2e4."}}
{"id": "2508.00180", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.00180", "abs": "https://arxiv.org/abs/2508.00180", "authors": ["Adam Block", "Cyril Zhang"], "title": "EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes", "comment": null, "summary": "Stochasticity in language model fine-tuning, often caused by the small batch\nsizes typically used in this regime, can destabilize training by introducing\nlarge oscillations in generation quality. A popular approach to mitigating this\ninstability is to take an Exponential moving average (EMA) of weights\nthroughout training. While EMA reduces stochasticity, thereby smoothing\ntraining, the introduction of bias from old iterates often creates a lag in\noptimization relative to vanilla training. In this work, we propose the\nBias-Corrected Exponential Moving Average (BEMA), a simple and practical\naugmentation of EMA that retains variance-reduction benefits while eliminating\nbias. BEMA is motivated by a simple theoretical model wherein we demonstrate\nprovable acceleration of BEMA over both a standard EMA and vanilla training.\nThrough an extensive suite of experiments on Language Models, we show that BEMA\nleads to significantly improved convergence rates and final performance over\nboth EMA and vanilla training in a variety of standard LM benchmarks, making\nBEMA a practical and theoretically motivated intervention for more stable and\nefficient fine-tuning.", "AI": {"tldr": "BEMA\ub294 \uae30\uc874\uc758 EMA\ub97c \uac1c\uc120\ud558\uc5ec \ud6c8\ub828 \uc548\uc815\uc131\uc744 \ub192\uc774\uace0 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ubc29\ubc95\uc774\ub2e4.", "motivation": "\uc5b8\uc5b4 \ubaa8\ub378\uc758 \ubbf8\uc138 \uc870\uc815\uc5d0\uc11c\uc758 \ubd88\ud655\uc2e4\uc131\uacfc \ub300\uaddc\ubaa8 \ud6c8\ub828\uc758 \ubd88\uc548\uc815\uc131\uc744 \ud574\uacb0\ud558\uae30 \uc704\ud574", "method": "\uae30\uc874 EMA\ub97c \ubcf4\uc644\ud558\ub294 Bias-Corrected Exponential Moving Average(BEMA)\ub97c \uc81c\uc548\ud568.", "result": "BEMA\ub294 \uc5ec\ub7ec \uc5b8\uc5b4 \ubaa8\ub378 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uae30\uc874\uc758 EMA \ubc0f \uc77c\ubc18 \ud6c8\ub828\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc218\ub834 \uc18d\ub3c4\uc640 \uc131\ub2a5\uc744 \ubcf4\uc600\ub2e4.", "conclusion": "BEMA\ub294 \uc5b8\uc5b4 \ubaa8\ub378 \ud6c8\ub828\uc758 \uc548\uc815\uc131\uacfc \ud6a8\uc728\uc131\uc744 \ub192\uc774\ub294 \uc2e4\uc6a9\uc801\uc774\uace0 \uc774\ub860\uc801\uc73c\ub85c \uadfc\uac70\uac00 \uc788\ub294 \ubc29\ubc95\uc774\ub2e4."}}
{"id": "2508.00378", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00378", "abs": "https://arxiv.org/abs/2508.00378", "authors": ["Shixin Yi", "Lin Shang"], "title": "CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding", "comment": "Preparing for AAAI 2026, Multimodal Reasoning", "summary": "Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in\nvision-language models (VLMs), but it often produces explanations that are\nlinguistically fluent yet lack grounding in visual content. We observe that\nsuch hallucinations arise in part from the absence of an explicit verification\nmechanism during multi-step reasoning. To address this, we propose\n\\textbf{CoRGI}(\\textbf{C}hain \\textbf{o}f \\textbf{R}easoning with\n\\textbf{G}rounded \\textbf{I}nsights), a modular framework that introduces\nvisual verification into the reasoning process. CoRGI follows a three-stage\npipeline: it first generates a textual reasoning chain, then extracts\nsupporting visual evidence for each reasoning step via a dedicated module\n(VEVM), and finally synthesizes the textual rationale with visual evidence to\ngenerate a grounded, verified answer. The framework can be integrated with\nexisting VLMs without end-to-end retraining. We evaluate CoRGI on the VCR\nbenchmark and find that it improves reasoning performance on two representative\nopen-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm\nthe contribution of each step in the verification module, and human evaluations\nsuggest that CoRGI leads to more factual and helpful explanations. We also\nexamine alternative designs for the visual verification step and discuss\npotential limitations of post-hoc verification frameworks. These findings\nhighlight the importance of grounding intermediate reasoning steps in visual\nevidence to enhance the robustness of multimodal reasoning.", "AI": {"tldr": "CoRGI\ub294 \uc2dc\uac01 \ucf58\ud150\uce20\uc5d0 \uae30\ubc18\ud55c \uac80\uc99d \uba54\ucee4\ub2c8\uc998\uc744 \ub3c4\uc785\ud558\uc5ec Vision-Language \ubaa8\ub378\uc758 \ub2e4\ub2e8\uacc4 \ucd94\ub860 \uc131\ub2a5\uc744 \uac1c\uc120\ud558\ub294 \ud504\ub808\uc784\uc6cc\ud06c\ub2e4.", "motivation": "CoT \ud504\ub86c\ud504\ud2b8\uac00 Vision-Language \ubaa8\ub378\uc758 \ucd94\ub860\uc744 \uac1c\uc120\ud558\ub294 \ub370 \ud6a8\uacfc\uc801\uc774\ub098, \uc885\uc885 \uc2dc\uac01 \ucf58\ud150\uce20\uc640\uc758 \uc5f0\uad00\uc131\uc774 \uacb0\uc5ec\ub41c \uc124\uba85\uc774 \ubc1c\uc0dd\ud568\uc744 \uad00\ucc30\ud558\uc600\ub2e4.", "method": "CoRGI\ub294 \ud14d\uc2a4\ud2b8 \uae30\ubc18\uc758 \ucd94\ub860 \uccb4\uc778\uc744 \uc0dd\uc131\ud558\uace0, \uac01 \ub2e8\uacc4\uc5d0 \ub300\ud55c \uc9c0\uc6d0 \uc2dc\uac01 \uc99d\uac70\ub97c \ucd94\ucd9c\ud55c \ud6c4, \uc774\ub97c \uacb0\ud569\ud558\uc5ec \uac80\uc99d\ub41c \ub2f5\ubcc0\uc744 \uc0dd\uc131\ud558\ub294 3\ub2e8\uacc4 \ud30c\uc774\ud504\ub77c\uc778\uc73c\ub85c \uad6c\uc131\ub41c\ub2e4.", "result": "CoRGI\ub294 VCR \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c Qwen-2.5VL\uacfc LLaVA-1.6 \ubaa8\ub378\uc758 \ucd94\ub860 \uc131\ub2a5\uc744 \uac1c\uc120\ud558\uba70, \uac80\uc99d \ubaa8\ub4c8\uc758 \uac01 \ub2e8\uacc4 \uae30\uc5ec\ub3c4\ub97c \ud655\uc778\ud558\uc600\ub2e4.", "conclusion": "\uc911\uac04 \ucd94\ub860 \ub2e8\uacc4\ub97c \uc2dc\uac01 \uc99d\uac70\uc5d0 \uae30\ubc18\ud558\uc5ec \uac15\ud654\ud558\ub294 \uac83\uc774 \ub2e4\uc911 \ubaa8\ub4dc \ucd94\ub860\uc758 \uac15\uac74\uc131\uc744 \ub192\uc774\ub294 \ub370 \uc911\uc694\ud568\uc744 \uac15\uc870\ud55c\ub2e4."}}
{"id": "2508.00201", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00201", "abs": "https://arxiv.org/abs/2508.00201", "authors": ["Mehdi Ben Ayed", "Fei Feng", "Jay Adams", "Vishwakarma Singh", "Kritarth Anand", "Jiajing Xu"], "title": "RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems", "comment": null, "summary": "Existing web-scale recommendation systems commonly use supervised learning\nmethods that prioritize immediate user feedback. Although reinforcement\nlearning (RL) offers a solution to optimize longer-term goals, such as\nin-session engagement, applying it at web scale is challenging due to the\nextremely large action space and engineering complexity. In this paper, we\nintroduce RecoMind, a simulator-based RL framework designed for the effective\noptimization of session-based goals at web-scale. RecoMind leverages existing\nrecommendation models to establish a simulation environment and to bootstrap\nthe RL policy to optimize immediate user interactions from the outset. This\nmethod integrates well with existing industry pipelines, simplifying the\ntraining and deployment of RL policies. Additionally, RecoMind introduces a\ncustom exploration strategy to efficiently explore web-scale action spaces with\nhundreds of millions of items. We evaluated RecoMind through extensive offline\nsimulations and online A/B testing on a video streaming platform. Both methods\nshowed that the RL policy trained using RecoMind significantly outperforms\ntraditional supervised learning recommendation approaches in in-session user\nsatisfaction. In online A/B tests, the RL policy increased videos watched for\nmore than 10 seconds by 15.81\\% and improved session depth by 4.71\\% for\nsessions with at least 10 interactions. As a result, RecoMind presents a\nsystematic and scalable approach for embedding RL into web-scale recommendation\nsystems, showing great promise for optimizing session-based user satisfaction.", "AI": {"tldr": "RecoMind\ub294 \uc6f9 \uc2a4\ucf00\uc77c \ucd94\ucc9c \uc2dc\uc2a4\ud15c\uc744 \uc704\ud55c \uc2dc\ubbac\ub808\uc774\ud130 \uae30\ubc18\uc758 \uac15\ud654 \ud559\uc2b5 \ud504\ub808\uc784\uc6cc\ud06c\ub85c, \uc138\uc158 \uae30\ubc18 \ubaa9\ud45c \ucd5c\uc801\ud654\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uc218\ud589\ud55c\ub2e4.", "motivation": "\uae30\uc874\uc758 \ucd94\ucc9c \uc2dc\uc2a4\ud15c\uc740 \uc989\uac01\uc801\uc778 \uc0ac\uc6a9\uc790 \ud53c\ub4dc\ubc31\uc5d0 \uc911\uc810\uc744 \ub450\uc5c8\uc73c\ub098, \uac15\ud654 \ud559\uc2b5\uc740 \uc7a5\uae30\uc801\uc778 \ubaa9\ud45c \ucd5c\uc801\ud654\uc5d0 \ub3c4\uc6c0\uc744 \uc904 \uc218 \uc788\uc5b4 \ud544\uc694\ud558\ub2e4.", "method": "RecoMind\ub294 \uae30\uc874 \ucd94\ucc9c \ubaa8\ub378\uc744 \ud65c\uc6a9\ud558\uc5ec \uc2dc\ubbac\ub808\uc774\uc158 \ud658\uacbd\uc744 \uc124\uc815\ud558\uace0, \uc989\uac01\uc801\uc778 \uc0ac\uc6a9\uc790 \uc0c1\ud638\uc791\uc6a9\uc744 \ucd5c\uc801\ud654\ud558\uae30 \uc704\ud574 RL \uc815\ucc45\uc744 \ubd80\ud2b8\uc2a4\ud2b8\ub7a9 \ud55c\ub2e4.", "result": "\uc804\ud1b5\uc801\uc778 \uac10\ub3c5 \ud559\uc2b5 \ubc29\ubc95\ubcf4\ub2e4 RL \uc815\ucc45\uc774 \uc138\uc158 \ub0b4 \uc0ac\uc6a9\uc790 \ub9cc\uc871\ub3c4\ub97c \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ucf30\uc73c\uba70, A/B \ud14c\uc2a4\ud2b8 \uacb0\uacfc \ube44\ub514\uc624 \uc2dc\uccad \uc2dc\uac04\uc774 15.81% \uc99d\uac00\ud588\ub2e4.", "conclusion": "RecoMind\ub294 \uc6f9 \uc2a4\ucf00\uc77c \ucd94\ucc9c \uc2dc\uc2a4\ud15c\uc5d0 RL\uc744 \ud1b5\ud569\ud558\uae30 \uc704\ud55c \uccb4\uacc4\uc801\uc774\uace0 \ud655\uc7a5 \uac00\ub2a5\ud55c \uc811\uadfc \ubc29\uc2dd\uc744 \uc81c\uacf5\ud558\uba70, \uc0ac\uc6a9\uc790 \ub9cc\uc871\ub3c4\ub97c \ucd5c\uc801\ud654\ud558\ub294 \ub370 \ud070 \uc7a0\uc7ac\ub825\uc744 \uc9c0\ub2cc\ub2e4."}}
{"id": "2508.00202", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00202", "abs": "https://arxiv.org/abs/2508.00202", "authors": ["Ecem Bozkurt", "Antonio Ortega"], "title": "Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models", "comment": "5 pages, 2 figures, under review at CAMSAP 2025", "summary": "Foundation models (FMs) pretrained on large datasets have become fundamental\nfor various downstream machine learning tasks, in particular in scenarios where\nobtaining perfectly labeled data is prohibitively expensive. In this paper, we\nassume an FM has to be fine-tuned with noisy data and present a two-stage\nframework to ensure robust classification in the presence of label noise\nwithout model retraining. Recent work has shown that simple k-nearest neighbor\n(kNN) approaches using an embedding derived from an FM can achieve good\nperformance even in the presence of severe label noise. Our work is motivated\nby the fact that these methods make use of local geometry. In this paper,\nfollowing a similar two-stage procedure, reliability estimation followed by\nreliability-weighted inference, we show that improved performance can be\nachieved by introducing geometry information. For a given instance, our\nproposed inference uses a local neighborhood of training data, obtained using\nthe non-negative kernel (NNK) neighborhood construction. We propose several\nmethods for reliability estimation that can rely less on distance and local\nneighborhood as the label noise increases. Our evaluation on CIFAR-10 and\nDermaMNIST shows that our methods improve robustness across various noise\nconditions, surpassing standard K-NN approaches and recent\nadaptive-neighborhood baselines.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \ub808\uc774\ube14 \ub178\uc774\uc988\uac00 \uc788\ub294 \ub370\uc774\ud130\uc5d0\uc11c \ud30c\uc6b4\ub370\uc774\uc158 \ubaa8\ub378\uc744 \uac15\uc778\ud558\uac8c \ud6c8\ub828\ud558\uae30 \uc704\ud55c \ub450 \ub2e8\uacc4 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uc548\ud55c\ub2e4.", "motivation": "\ucd5c\uadfc kNN \uae30\ubc95\uc774 \ub808\uc774\ube14 \ub178\uc774\uc988\uac00 \uc2ec\ud55c \uc0c1\ud669\uc5d0\uc11c\ub3c4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubc1c\ud718\ud55c\ub2e4\ub294 \uc0ac\uc2e4\uc5d0 \ucc29\uc548\ud558\uc600\ub2e4.", "method": "\uc548\uc815\uc131 \ucd94\uc815\uacfc \uc548\uc815\uc131 \uac00\uc911 \ucd94\ub860\uc758 \ub450 \ub2e8\uacc4 \uc808\ucc28\ub97c \ud1b5\ud574 \uae30\ud558\ud559\uc801 \uc815\ubcf4\ub97c \ub3c4\uc785\ud55c \uc778\ud37c\ub7f0\uc2a4\ub97c \uc81c\uc548\ud55c\ub2e4.", "result": "CIFAR-10\uacfc DermaMNIST\uc5d0\uc11c \ub2e4\uc591\ud55c \ub178\uc774\uc988 \uc870\uac74 \ud558\uc5d0 \uac15 robustness\ub97c \uac1c\uc120\ud558\uc5ec \ud45c\uc900 K-NN \uc811\uadfc\ubc95 \ubc0f \ucd5c\uadfc \uc801\uc751\ud615 \uc774\uc6c3 \uae30\uc900\uc120\uc744 \ucd08\uc6d4\ud558\uc600\ub2e4.", "conclusion": "\uc81c\uc548\ub41c \ubc29\ubc95\uc740 \ub808\uc774\ube14 \ub178\uc774\uc988\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uac70\ub9ac \ubc0f \uc9c0\uc5ed \uc774\uc6c3\uc5d0 \ub35c \uc758\uc874\ud558\uba74\uc11c \uc548\uc815\uc131 \ucd94\uc815\uc758 \uc5ec\ub7ec \ubc29\ubc95\uc744 \uc81c\uc548\ud55c\ub2e4."}}
{"id": "2508.00414", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00414", "abs": "https://arxiv.org/abs/2508.00414", "authors": ["Tianqing Fang", "Zhisong Zhang", "Xiaoyang Wang", "Rui Wang", "Can Qin", "Yuxuan Wan", "Jun-Yu Ma", "Ce Zhang", "Jiaqi Chen", "Xiyun Li", "Hongming Zhang", "Haitao Mi", "Dong Yu"], "title": "Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training", "comment": "16 pages", "summary": "General AI Agents are increasingly recognized as foundational frameworks for\nthe next generation of artificial intelligence, enabling complex reasoning, web\ninteraction, coding, and autonomous research capabilities. However, current\nagent systems are either closed-source or heavily reliant on a variety of paid\nAPIs and proprietary tools, limiting accessibility and reproducibility for the\nresearch community. In this work, we present \\textbf{Cognitive Kernel-Pro}, a\nfully open-source and (to the maximum extent) free multi-module agent framework\ndesigned to democratize the development and evaluation of advanced AI agents.\nWithin Cognitive Kernel-Pro, we systematically investigate the curation of\nhigh-quality training data for Agent Foundation Models, focusing on the\nconstruction of queries, trajectories, and verifiable answers across four key\ndomains: web, file, code, and general reasoning. Furthermore, we explore novel\nstrategies for agent test-time reflection and voting to enhance agent\nrobustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving\nstate-of-the-art results among open-source and free agents. Notably, our\n8B-parameter open-source model surpasses previous leading systems such as\nWebDancer and WebSailor, establishing a new performance standard for\naccessible, high-capability AI agents. Code is available at\nhttps://github.com/Tencent/CognitiveKernel-Pro", "AI": {"tldr": "Cognitive Kernel-Pro\ub294 \uace0\uae09 AI \uc5d0\uc774\uc804\ud2b8 \uac1c\ubc1c\uc744 \ubbfc\uc8fc\ud654\ud558\uae30 \uc704\ud574 \uc124\uacc4\ub41c \uc644\uc804 \uc624\ud508\uc18c\uc2a4 \ub2e4\uc911 \ubaa8\ub4c8 \uc5d0\uc774\uc804\ud2b8 \ud504\ub808\uc784\uc6cc\ud06c\uc774\ub2e4.", "motivation": "\ud604\uc7ac\uc758 \uc5d0\uc774\uc804\ud2b8 \uc2dc\uc2a4\ud15c\uc740 \uc81c\ud55c\ub41c \uc811\uadfc\uc131\uacfc \uc7ac\ud604\uc131\uc744 \uac00\uc9c0\uba70, \uc5f0\uad6c \ucee4\ubba4\ub2c8\ud2f0\uc758 \ubc1c\uc804\uc744 \uc800\ud574\ud558\uace0 \uc788\ub2e4. \uc774\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 Cognitive Kernel-Pro\ub97c \uac1c\ubc1c\ud558\uc600\ub2e4.", "method": "Cognitive Kernel-Pro\ub294 \uc6f9, \ud30c\uc77c, \ucf54\ub4dc, \uc77c\ubc18 \ucd94\ub860\uc758 \ub124 \uac00\uc9c0 \uc8fc\uc694 \ub3c4\uba54\uc778\uc5d0\uc11c \uace0\ud488\uc9c8 \ud6c8\ub828 \ub370\uc774\ud130\ub97c \uccb4\uacc4\uc801\uc73c\ub85c \uc870\uc0ac\ud558\uace0, \uc5d0\uc774\uc804\ud2b8\uc758 \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \ubc18\uc601 \ubc0f \ud22c\ud45c \uc804\ub7b5\uc744 \ud0d0\uad6c\ud55c\ub2e4.", "result": "Cognitive Kernel-Pro\ub294 GAIA\uc5d0\uc11c \uc624\ud508\uc18c\uc2a4 \ubc0f \ubb34\ub8cc \uc5d0\uc774\uc804\ud2b8 \uc0ac\uc774\uc5d0\uc11c \ucd5c\ucca8\ub2e8\uc758 \uacb0\uacfc\ub97c \ub2ec\uc131\ud558\uc600\ub2e4.", "conclusion": "\uc6b0\ub9ac\uc758 8B \ud30c\ub77c\ubbf8\ud130 \uc624\ud508\uc18c\uc2a4 \ubaa8\ub378\uc740 WebDancer\uc640 WebSailor\uc640 \uac19\uc740 \uae30\uc874 \uc2dc\uc2a4\ud15c\uc744 \ucd08\uc6d4\ud558\uc5ec, \uc811\uadfc \uac00\ub2a5\ud55c \uace0\uc131\ub2a5 AI \uc5d0\uc774\uc804\ud2b8\uc758 \uc0c8\ub85c\uc6b4 \uc131\ub2a5 \uae30\uc900\uc744 \uc124\uc815\ud558\uc600\ub2e4."}}
{"id": "2508.00230", "categories": ["cs.LG", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00230", "abs": "https://arxiv.org/abs/2508.00230", "authors": ["Paul Albert", "Frederic Z. Zhang", "Hemanth Saratchandran", "Anton van den Hengel", "Ehsan Abbasnejad"], "title": "Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product", "comment": "To appear in ICCV 2025", "summary": "Parameter-efficient fine-tuning (PEFT) has become a standard approach for\nadapting large pre-trained models. Amongst PEFT methods, low-rank adaptation\n(LoRA) has achieved notable success. However, recent studies have highlighted\nits limitations compared against full-rank alternatives, particularly when\napplied to multimodal and large language models. In this work, we present a\nquantitative comparison amongst full-rank and low-rank PEFT methods using a\nsynthetic matrix approximation benchmark with controlled spectral properties.\nOur results confirm that LoRA struggles to approximate matrices with relatively\nflat spectrums or high frequency components -- signs of high effective ranks.\nTo this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the\nKhatri-Rao product to produce weight updates, which, by construction, tends to\nproduce matrix product with a high effective rank. We demonstrate performance\ngains with KRAdapter on vision-language models up to 1B parameters and on large\nlanguage models up to 8B parameters, particularly on unseen common-sense\nreasoning tasks. In addition, KRAdapter maintains the memory and compute\nefficiency of LoRA, making it a practical and robust alternative to fine-tune\nbillion-scale parameter models.", "AI": {"tldr": "\ubcf8 \uc5f0\uad6c\ub294 PEFT \ubc29\ubc95 \uc911 LoRA\uc758 \ud55c\uacc4\ub97c \uc9c0\uc801\ud558\uba70, \uc0c8\ub85c\uc6b4 PEFT \uae30\ubc95 KRAdapter\ub97c \uc81c\uc548\ud558\uc5ec \uc131\ub2a5 \uac1c\uc120\uc744 \ubcf4\uc5ec\uc900\ub2e4.", "motivation": "PEFT\ub294 \ub300\uaddc\ubaa8 \uc0ac\uc804 \ud6c8\ub828 \ubaa8\ub378\uc744 \uc870\uc815\ud558\ub294 \ud45c\uc900 \uc811\uadfc\ubc95\uc73c\ub85c \uc790\ub9ac\uc7a1\uc558\uc9c0\ub9cc, LoRA\uc758 \ud55c\uacc4\uac00 \ub4dc\ub7ec\ub0ac\ub2e4.", "method": "\uc5f0\uad6c\ub294 \uac00\uc0c1 \ud589\ub82c \uadfc\uc0ac \ubca4\uce58\ub9c8\ud06c\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc804\uccb4 \uc21c\uc704 \ubc0f \uc800\uc21c\uc704 PEFT \ubc29\ubc95\uc744 \ube44\uad50\ud558\uace0, KRAdapter\ub77c\ub294 \uc0c8\ub85c\uc6b4 \uc54c\uace0\ub9ac\uc998\uc744 \uc18c\uac1c\ud55c\ub2e4.", "result": "KRAdapter\ub294 \ud6a8\uacfc\uc801\uc778 \uc21c\uc704\uac00 \ub192\uc740 \ud589\ub82c \uacf1\uc744 \uc0dd\uc131\ud558\uc5ec \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc8fc\uc5c8\uace0, 1B \ubc0f 8B \ud30c\ub77c\ubbf8\ud130 \ubaa8\ub378\uc5d0\uc11c \ud2b9\ud788 \ub208\uc5d0 \ub744\ub294 \uacb0\uacfc\ub97c \uc5bb\uc5c8\ub2e4.", "conclusion": "KRAdapter\ub294 LoRA\uc758 \uba54\ubaa8\ub9ac \ubc0f \uacc4\uc0b0 \ud6a8\uc728\uc131\uc744 \uc720\uc9c0\ud558\uba74\uc11c\ub3c4 \ub300\uaddc\ubaa8 \ud30c\ub77c\ubbf8\ud130 \ubaa8\ub378 \uc870\uc815\uc5d0 \uc2e4\uc6a9\uc801\uc774\uace0 \uac15\ub825\ud55c \ub300\uc548\uc774 \ub41c\ub2e4."}}
{"id": "2508.00459", "categories": ["cs.AI", "68T07, 68T20", "I.2.6; I.2.7; I.2.3"], "pdf": "https://arxiv.org/pdf/2508.00459", "abs": "https://arxiv.org/abs/2508.00459", "authors": ["Andrea Asperti", "Alberto Naibo", "Claudio Sacerdoti Coen"], "title": "Thinking Machines: Mathematical Reasoning in the Age of LLMs", "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable abilities in structured\nreasoning and symbolic tasks, with coding emerging as a particular area of\nstrength. This success has sparked growing interest in applying LLMs to\nmathematics, both in informal problem-solving and formal theorem proving.\nHowever, progress in formal mathematics has proven to be significantly more\ndifficult, despite surface-level similarities between programming and proof\nconstruction. This discrepancy raises important questions about how LLMs\n``reason'', how they are supervised, and whether they internally track a notion\nof computational or deductive state. In this article, we address the\nstate-of-the-art of the discipline, focusing on recent models and benchmarks,\nand explore three central issues at the intersection of machine learning and\nmathematical cognition: (i) the trade-offs between formal and informal\nmathematics as training domains; (ii) the deeper reasons why proof generation\nremains more brittle than code synthesis; (iii) and the question of whether\nLLMs represent, or merely mimic, a notion of evolving logical state. Our goal\nis not to draw hard boundaries, but to identify where the current limits lie,\nand how they might be extended.", "AI": {"tldr": "\ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378\uc774 \uc218\ud559 \ubc0f \ud615\uc2dd\uc801 \uc815\ub9ac \uc99d\uba85\uc5d0 \ub300\ud55c \uc801\uc6a9 \uac00\ub2a5\uc131\uc744 \ud0d0\uad6c\ud558\uace0 \uc788\ub2e4.", "motivation": "\ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc131\uacf5\uc774 \ud504\ub85c\uadf8\ub798\ubc0d \uc720\uc0ac\ud55c \ubb38\uc81c \ud574\uacb0 \ub2a5\ub825\uc5d0 \ub530\ub978 \uc218\ud559\uc801 \uc801\uc6a9 \uac00\ub2a5\uc131\uc5d0 \ub300\ud55c \uad00\uc2ec\uc744 \ubd88\ub7ec\uc77c\uc73c\ucf30\ub2e4.", "method": "\ucd5c\uadfc \ubaa8\ub378\uacfc \ubca4\uce58\ub9c8\ud06c\ub97c \ud0d0\uad6c\ud558\uba70 \uba38\uc2e0\ub7ec\ub2dd\uacfc \uc218\ud559\uc801 \uc778\uc2dd\uc758 \uad50\ucc28\uc810\uc5d0\uc11c \uc138 \uac00\uc9c0 \uc8fc\uc694 \uc7c1\uc810\uc744 \ub2e4\ub8ec\ub2e4.", "result": "\ud615\uc2dd \uc218\ud559\uacfc \ube44\ud615\uc2dd \uc218\ud559\uc758 \ud6c8\ub828 \uc601\uc5ed \uac04\uc758 trade-off, \uc99d\uba85 \uc0dd\uc131\uc758 \ucde8\uc57d\uc131, LLM\uc774 \uc9c4\ud654\ud558\ub294 \ub17c\ub9ac\uc801 \uc0c1\ud0dc\ub97c \ub098\ud0c0\ub0b4\ub294\uc9c0\ub97c \ubd84\uc11d\ud55c\ub2e4.", "conclusion": "\ud604\uc7ac\uc758 \ud55c\uacc4\ub97c \uc2dd\ubcc4\ud558\uace0 \uc774\ub97c \ud655\uc7a5\ud560 \uc218 \uc788\ub294 \ubc29\ubc95\uc744 \ubaa8\uc0c9\ud55c\ub2e4."}}
{"id": "2508.00264", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.00264", "abs": "https://arxiv.org/abs/2508.00264", "authors": ["Jerry Huang", "Peng Lu", "Qiuhao Zeng"], "title": "Calibrated Language Models and How to Find Them with Label Smoothing", "comment": "Accepted to the Forty-second International Conference on Machine\n  Learning (ICML) 2025. First two authors contributed equally", "summary": "Recent advances in natural language processing (NLP) have opened up greater\nopportunities to enable fine-tuned large language models (LLMs) to behave as\nmore powerful interactive agents through improved instruction-following\nability. However, understanding how this impacts confidence calibration for\nreliable model output has not been researched in full. In this work, we examine\nvarious open-sourced LLMs, identifying significant calibration degradation\nafter instruction tuning in each. Seeking a practical solution, we look towards\nlabel smoothing, which has been shown as an effective method to regularize for\noverconfident predictions but has yet to be widely adopted in the supervised\nfine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing\nis sufficient to maintain calibration throughout the SFT process. However,\nsettings remain where the effectiveness of smoothing is severely diminished, in\nparticular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to\nstem from the ability to become over-confident, which has a direct relationship\nwith the hidden size and vocabulary size, and justify this theoretically and\nexperimentally. Finally, we address an outstanding issue regarding the memory\nfootprint of the cross-entropy loss computation in the label smoothed loss\nsetting, designing a customized kernel to dramatically reduce memory\nconsumption without sacrificing speed or performance in comparison to existing\nsolutions for non-smoothed losses.", "AI": {"tldr": "\uc790\uc5f0\uc5b4 \ucc98\ub9ac\uc758 \uc9c4\uc804\uc774 \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc2e0\ub8b0\ub3c4 \uc870\uc815 \ubb38\uc81c\ub97c \ud0d0\uad6c\ud558\uba70, \ub77c\ubca8 \uc2a4\ubb34\ub529\uc744 \ud1b5\ud55c \uc2e4\uc9c8\uc801\uc778 \ud574\uacb0 \ubc29\uc548\uc744 \uc81c\uc2dc\ud568.", "motivation": "\ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc9c0\uce68 \uc218\uc6a9 \ub2a5\ub825 \ud5a5\uc0c1\uc774 \uc2e0\ub8b0\ub3c4 \uc870\uc815\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc774\ud574\ud558\uae30 \uc704\ud574 \uc5f0\uad6c\ud568.", "method": "\ub77c\ubca8 \uc2a4\ubb34\ub529 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\uc5ec \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uacfc\uc2e0 \uc608\uce21\uc744 \uaddc\uc81c\ud558\uace0, \uc2e4\ud5d8\uc744 \ud1b5\ud574 \ub300\ud615 \uc5b4\ud718 \ubaa8\ub378\uc5d0\uc11c\uc758 \ud6a8\uacfc\ub97c \uc774\ub860\uc801\uc73c\ub85c \ubc0f \uc2e4\ud5d8\uc801\uc73c\ub85c \ubd84\uc11d\ud568.", "result": "\ubaa8\ub4e0 \ubaa8\ub378\uc5d0\uc11c \uc9c0\uce68 \uc870\uc815 \ud6c4 \uc2e0\ub8b0\ub3c4 \uc870\uc815\uc758 \ud604\uc800\ud55c \uc800\ud558\ub97c \uad00\ucc30\ud558\uba70, \ub77c\ubca8 \uc2a4\ubb34\ub529\uc774 \uc720\ud6a8\ud568\uc744 \uc785\uc99d\ud568.", "conclusion": "\ucee4\uc2a4\ud140 \ucee4\ub110\uc744 \uc124\uacc4\ud558\uc5ec \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \uc904\uc774\uba74\uc11c\ub3c4 \uae30\uc874 \uc131\ub2a5\uc744 \uc720\uc9c0\ud558\ub294 \ud574\uacb0\ucc45\uc744 \uc81c\uc2dc\ud568."}}
{"id": "2508.00500", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00500", "abs": "https://arxiv.org/abs/2508.00500", "authors": ["Haoyu Wang", "Chris M. Poskitt", "Jun Sun", "Jiali Wei"], "title": "Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking", "comment": null, "summary": "Large Language Model (LLM) agents exhibit powerful autonomous capabilities\nacross domains such as robotics, virtual assistants, and web automation.\nHowever, their stochastic behavior introduces significant safety risks that are\ndifficult to anticipate. Existing rule-based enforcement systems, such as\nAgentSpec, focus on developing reactive safety rules, which typically respond\nonly when unsafe behavior is imminent or has already occurred. These systems\nlack foresight and struggle with long-horizon dependencies and distribution\nshifts. To address these limitations, we propose Pro2Guard, a proactive runtime\nenforcement framework grounded in probabilistic reachability analysis.\nPro2Guard abstracts agent behaviors into symbolic states and learns a\nDiscrete-Time Markov Chain (DTMC) from execution traces. At runtime, it\nanticipates future risks by estimating the probability of reaching unsafe\nstates, triggering interventions before violations occur when the predicted\nrisk exceeds a user-defined threshold. By incorporating semantic validity\nchecks and leveraging PAC bounds, Pro2Guard ensures statistical reliability\nwhile approximating the underlying ground-truth model. We evaluate Pro2Guard\nextensively across two safety-critical domains: embodied household agents and\nautonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early\non up to 93.6% of unsafe tasks using low thresholds, while configurable modes\n(e.g., reflect) allow balancing safety with task success, maintaining up to\n80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%\nprediction of traffic law violations and collisions, anticipating risks up to\n38.66 seconds ahead.", "AI": {"tldr": "Pro2Guard\ub294 \uc704\ud5d8 \uc608\uce21 \uae30\ubc18\uc758 \ub2a5\ub3d9\uc801 \uc548\uc804 \uad00\ub9ac \ud504\ub808\uc784\uc6cc\ud06c\ub85c, LLM \uc5d0\uc774\uc804\ud2b8\uc758 \ud589\ub3d9\uc744 \ubd84\uc11d\ud558\uc5ec \uc0ac\uace0\ub97c \uc608\ubc29\ud55c\ub2e4.", "motivation": "LLM \uc5d0\uc774\uc804\ud2b8\ub294 \uc548\uc804\ud558\uc9c0 \uc54a\uc740 \ud589\ub3d9\uc758 \uc608\uce21\uc774 \uc5b4\ub835\uace0 \uae30\uc874\uc758 \ubc18\uc751\ud615 \uc2dc\uc2a4\ud15c\uc740 \uc7a5\uae30 \uc758\uc874\uc131\uc744 \uc798 \ucc98\ub9ac\ud558\uc9c0 \ubabb\ud55c\ub2e4.", "method": "Pro2Guard\ub294 \uc5d0\uc774\uc804\ud2b8 \ud589\ub3d9\uc744 \uc0c1\uc9d5\uc801 \uc0c1\ud0dc\ub85c \ucd94\uc0c1\ud654\ud558\uace0 \uc2e4\ud589 \ucd94\uc801\uc5d0\uc11c DTMC\ub97c \ud559\uc2b5\ud558\uc5ec \uc704\ud5d8\uc744 \uc608\uce21\ud55c\ub2e4.", "result": "Pro2Guard\ub294 \uac00\uc815\uc6a9 \uc5d0\uc774\uc804\ud2b8\uc758 93.6%\uc640 \uc790\uc728 \ucc28\ub7c9\uc758 100% \uad50\ud1b5\ubc95 \uc704\ubc18 \uc608\uce21\uc5d0 \uc131\uacf5\ud588\ub2e4.", "conclusion": "Pro2Guard\ub294 \uc548\uc804\uc131 \ubc0f \uc791\uc5c5 \uc131\uacf5\ub960 \uac04 \uade0\ud615\uc744 \uc774\ub8e8\uba70, \uc5d0\uc774\uc804\ud2b8\uc758 \uc548\uc804\uc131\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4."}}
{"id": "2508.00270", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00270", "abs": "https://arxiv.org/abs/2508.00270", "authors": ["Robin Schmucker", "Nimish Pachapurkar", "Shanmuga Bala", "Miral Shah", "Tom Mitchell"], "title": "Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring", "comment": null, "summary": "We present an online tutoring system that learns to provide effective\nfeedback to students after they answer questions incorrectly. Using data from\none million students, the system learns which assistance action (e.g., one of\nmultiple hints) to provide for each question to optimize student learning.\nEmploying the multi-armed bandit (MAB) framework and offline policy evaluation,\nwe assess 43,000 assistance actions, and identify trade-offs between assistance\npolicies optimized for different student outcomes (e.g., response correctness,\nsession completion). We design an algorithm that for each question decides on a\nsuitable policy training objective to enhance students' immediate second\nattempt success and overall practice session performance. We evaluate the\nresulting MAB policies in 166,000 practice sessions, verifying significant\nimprovements in student outcomes. While MAB policies optimize feedback for the\noverall student population, we further investigate whether contextual bandit\n(CB) policies can enhance outcomes by personalizing feedback based on\nindividual student features (e.g., ability estimates, response times). Using\ncausal inference, we examine (i) how effects of assistance actions vary across\nstudents and (ii) whether CB policies, which leverage such effect\nheterogeneity, outperform MAB policies. While our analysis reveals that some\nactions for some questions exhibit effect heterogeneity, effect sizes may often\nbe too small for CB policies to provide significant improvements beyond what\nwell-optimized MAB policies that deliver the same action to all students\nalready achieve. We discuss insights gained from deploying data-driven systems\nat scale and implications for future refinements. Today, the teaching policies\noptimized by our system support thousands of students daily.", "AI": {"tldr": "\uc628\ub77c\uc778 \ud29c\ud130\ub9c1 \uc2dc\uc2a4\ud15c\uc774 \ud559\uc0dd\ub4e4\uc744 \uc704\ud55c \ub9de\ucda4\ud615 \ud53c\ub4dc\ubc31\uc744 \uc81c\uacf5\ud558\uba70, \ub2e4\uc218\uc758 \ud559\uc0dd \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud558\uc5ec \ucd5c\uc801\uc758 \ud559\uc2b5 \uacb0\uacfc\ub97c \ub3c4\ucd9c.", "motivation": "\uc815\ub2f5\uc744 \uc798\ubabb\ub41c \ud559\uc0dd\ub4e4\uc5d0\uac8c \ud6a8\uacfc\uc801\uc778 \ud53c\ub4dc\ubc31\uc744 \uc81c\uacf5\ud568\uc73c\ub85c\uc368 \ud559\uc2b5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574.", "method": "\ub2e4\uc911\ubb34\uc7a5\ubc34\ub527(MAB) \ud504\ub808\uc784\uc6cc\ud06c\uc640 \uc624\ud504\ub77c\uc778 \uc815\ucc45 \ud3c9\uac00\ub97c \ud65c\uc6a9\ud558\uc5ec 43,000\uac1c\uc758 \ubcf4\uc870 \ud589\ub3d9\uc744 \ud3c9\uac00\ud558\uace0 \uc801\uc808\ud55c \uc815\ucc45 \uad50\uc721 \ubaa9\ud45c\ub97c \uacb0\uc815\ud558\ub294 \uc54c\uace0\ub9ac\uc998\uc744 \uc124\uacc4.", "result": "166,000\uac1c\uc758 \uc2e4\uc2b5 \uc138\uc158\uc5d0\uc11c MAB \uc815\ucc45\uc744 \ud3c9\uac00\ud558\uc5ec \ud559\uc0dd \uacb0\uacfc\uc5d0 \uc2e4\uc9c8\uc801\uc778 \uac1c\uc120\uc774 \uc788\uc74c\uc744 \ud655\uc778.", "conclusion": "\ub9de\ucda4\ud615 \ud53c\ub4dc\ubc31\uc744 \uc81c\uacf5\ud558\uae30 \uc704\ud55c \ub9e5\ub77d\uc801 \ubc34\ub527(CB) \uc815\ucc45\uc758 \ud6a8\uacfc\ub294 \uc81c\ud55c\uc801\uc774\uba70, \ub370\uc774\ud130\ub97c \uae30\ubc18\uc73c\ub85c \ud55c \uc2dc\uc2a4\ud15c\uc758 \ubc30\ud3ec\uc5d0\uc11c \uc5bb\uc740 \ud1b5\ucc30\uc774 \ubbf8\ub798 \uac1c\uc120\uc744 \uc704\ud55c \uc9c0\uce68\uc744 \uc81c\uacf5."}}
{"id": "2508.00576", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00576", "abs": "https://arxiv.org/abs/2508.00576", "authors": ["Zhanliang Wang", "Kai Wang"], "title": "MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models", "comment": null, "summary": "Multimodal AI models have achieved impressive performance in tasks that\nrequire integrating information from multiple modalities, such as vision and\nlanguage. However, their \"black-box\" nature poses a major barrier to deployment\nin high-stakes applications where interpretability and trustworthiness are\nessential. How to explain cross-modal interactions in multimodal AI models\nremains a major challenge. While existing model explanation methods, such as\nattention map and Grad-CAM, offer coarse insights into cross-modal\nrelationships, they cannot precisely quantify the synergistic effects between\nmodalities, and are limited to open-source models with accessible internal\nweights. Here we introduce MultiSHAP, a model-agnostic interpretability\nframework that leverages the Shapley Interaction Index to attribute multimodal\npredictions to pairwise interactions between fine-grained visual and textual\nelements (such as image patches and text tokens), while being applicable to\nboth open- and closed-source models. Our approach provides: (1) instance-level\nexplanations that reveal synergistic and suppressive cross-modal effects for\nindividual samples - \"why the model makes a specific prediction on this input\",\nand (2) dataset-level explanation that uncovers generalizable interaction\npatterns across samples - \"how the model integrates information across\nmodalities\". Experiments on public multimodal benchmarks confirm that MultiSHAP\nfaithfully captures cross-modal reasoning mechanisms, while real-world case\nstudies demonstrate its practical utility. Our framework is extensible beyond\ntwo modalities, offering a general solution for interpreting complex multimodal\nAI models.", "AI": {"tldr": "MultiSHAP\uc740 \ub2e4\uc911 \ubaa8\ub2ec AI \ubaa8\ub378\uc758 \uc608\uce21\uc744 \uc124\uba85\ud558\uae30 \uc704\ud55c \ubaa8\ub378 \ub3c5\ub9bd\uc801 \ud574\uc11d \ud504\ub808\uc784\uc6cc\ud06c\ub85c, \uad50\ucc28 \ubaa8\ub2ec \uc0c1\ud638\uc791\uc6a9\uc744 \uc815\ub7c9\ud654\ud558\uc5ec \uac1c\ubcc4 \uc0d8\ud50c \ubc0f \ub370\uc774\ud130\uc14b \uc218\uc900\uc5d0\uc11c \uc124\uba85\uc744 \uc81c\uacf5\ud55c\ub2e4.", "motivation": "\ub2e4\uc911 \ubaa8\ub2ec AI \ubaa8\ub378\uc758 \ube14\ub799\ubc15\uc2a4 \ud2b9\uc131\uc73c\ub85c \uc778\ud574 \ud574\uc11d \uac00\ub2a5\uc131\uacfc \uc2e0\ub8b0\uc131\uc774 \uc911\uc694\ud55c \uace0\uc704\ud5d8 \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc5d0 \ubc30\uce58\ud558\ub294 \ub370 \uc7a5\ubcbd\uc774 \ub418\uace0 \uc788\ub2e4.", "method": "MultiSHAP\ub294 Shapley Interaction Index\ub97c \ud65c\uc6a9\ud558\uc5ec \uc0c1\uc138\ud55c \uc2dc\uac01\uc801 \ubc0f \ud14d\uc2a4\ud2b8 \uc694\uc18c \uac04\uc758 \uc30d\ubcc4 \uc0c1\ud638\uc791\uc6a9\uc744 \ud1b5\ud574 \uba40\ud2f0\ubaa8\ub2ec \uc608\uce21\uc744 \uadc0\uc18d\uc2dc\ud0a4\ub294 \ubaa8\ub378 \ub3c5\ub9bd\uc801 \ud574\uc11d \ud504\ub808\uc784\uc6cc\ud06c\uc774\ub2e4.", "result": "MultiSHAP\ub294 \uc2e4\ud5d8\uc744 \ud1b5\ud574 \uad50\ucc28 \ubaa8\ub2ec \ucd94\ub860 \uba54\ucee4\ub2c8\uc998\uc744 \ucda9\uc2e4\ud788 \ud3ec\ucc29\ud558\uba70, \uc2e4\uc81c \uc0ac\ub840 \uc5f0\uad6c\ub97c \ud1b5\ud574 \uc2e4\uc6a9\uc131\uc744 \uc785\uc99d\ud558\uc600\ub2e4.", "conclusion": "MultiSHAP\ub294 \ub450 \uac1c \uc774\uc0c1\uc758 \ubaa8\ub2ec\ub9ac\ud2f0\ub97c \ub118\uc5b4 \ud655\uc7a5 \uac00\ub2a5\ud558\uba70, \ubcf5\uc7a1\ud55c \ub2e4\uc911 \ubaa8\ub2ec AI \ubaa8\ub378 \ud574\uc11d\uc744 \uc704\ud55c \uc77c\ubc18 \uc194\ub8e8\uc158\uc744 \uc81c\uacf5\ud55c\ub2e4."}}
{"id": "2508.00286", "categories": ["cs.LG", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.00286", "abs": "https://arxiv.org/abs/2508.00286", "authors": ["Mohsen Zaker Esteghamati"], "title": "Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem", "comment": null, "summary": "This study presents a methodology to treat performance-based seismic design\nas an inverse engineering problem, where design parameters are directly derived\nto achieve specific performance objectives. By implementing explainable machine\nlearning models, this methodology directly maps design variables and\nperformance metrics, tackling computational inefficiencies of performance-based\ndesign. The resultant machine learning model is integrated as an evaluation\nfunction into a genetic optimization algorithm to solve the inverse problem.\nThe developed methodology is then applied to two different inventories of steel\nand concrete moment frames in Los Angeles and Charleston to obtain sectional\nproperties of frame members that minimize expected annualized seismic loss in\nterms of repair costs. The results show high accuracy of the surrogate models\n(e.g., R2> 90%) across a diverse set of building types, geometries, seismic\ndesign, and site hazard, where the optimization algorithm could identify the\noptimum values of members' properties for a fixed set of geometric variables,\nconsistent with engineering principles.", "AI": {"tldr": "\uc774 \uc5f0\uad6c\ub294 \uc131\ub2a5 \uae30\ubc18 \ub0b4\uc9c4 \uc124\uacc4\ub97c \uc5ed\uc124\uacc4 \ubb38\uc81c\ub85c \ub2e4\ub8e8\ub294 \ubc29\ubc95\ub860\uc744 \uc81c\uc2dc\ud55c\ub2e4.", "motivation": "\uc131\ub2a5 \ubaa9\ud45c\ub97c \ub2ec\uc131\ud558\uae30 \uc704\ud55c \uc124\uacc4 \ub9e4\uac1c \ubcc0\uc218\ub97c \uc9c1\uc811 \ub3c4\ucd9c\ud558\ub824\ub294 \ud544\uc694\uc131.", "method": "\uc124\uacc4 \ubcc0\uc218\uc640 \uc131\ub2a5 \uc9c0\ud45c\ub97c \ub9e4\ud551\ud558\ub294 \uc124\uba85 \uac00\ub2a5\ud55c \uba38\uc2e0\ub7ec\ub2dd \ubaa8\ub378\uc744 \uad6c\ud604\ud558\uace0, \uc774\ub97c \uc720\uc804 \uc54c\uace0\ub9ac\uc998\uc5d0 \ud1b5\ud569\ud558\uc5ec \uc5ed\ubb38\uc81c\ub97c \ud574\uacb0.", "result": "\ub85c\uc2a4\uc564\uc824\ub808\uc2a4\uc640 \ucc30\uc2a4\ud134\uc758 \uac15\ucca0 \ubc0f \ucf58\ud06c\ub9ac\ud2b8 \ubaa8\uba58\ud2b8 \ud504\ub808\uc784 \ub450 \uac00\uc9c0 \uc0ac\ub840\uc5d0\uc11c \ucd5c\uc801\uc758 \ub2e8\uba74 \ud2b9\uc131\uc744 \ub3c4\ucd9c\ud558\uc5ec \uc5f0\uac04 \uc218\ub9ac \ube44\uc6a9\uc744 \ucd5c\uc18c\ud654\ud558\ub294 \uc131\uacfc.", "conclusion": "\ub2e4\uc591\ud55c \uac74\ubb3c \uc720\ud615\uacfc \uc9c0\uc9c4 \uc124\uacc4 \uc870\uac74\uc5d0\uc11c \ub192\uc740 \uc815\ud655\ub3c4\ub85c \ucd5c\uc801 \uac12\uc744 \ub3c4\ucd9c\ud560 \uc218 \uc788\uc74c\uc744 \uc785\uc99d."}}
{"id": "2508.00581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00581", "abs": "https://arxiv.org/abs/2508.00581", "authors": ["Ruiqing Ding", "Qianfang Sun", "Yongkang Leng", "Hui Yin", "Xiaojian Li"], "title": "From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation", "comment": "16 pages, 10 figures", "summary": "Pre-consultation is a critical component of effective healthcare delivery.\nHowever, generating comprehensive pre-consultation questionnaires from complex,\nvoluminous Electronic Medical Records (EMRs) is a challenging task. Direct\nLarge Language Model (LLM) approaches face difficulties in this task,\nparticularly regarding information completeness, logical order, and\ndisease-level synthesis. To address this issue, we propose a novel multi-stage\nLLM-driven framework: Stage 1 extracts atomic assertions (key facts with\ntiming) from EMRs; Stage 2 constructs personal causal networks and synthesizes\ndisease knowledge by clustering representative networks from an EMR corpus;\nStage 3 generates tailored personal and standardized disease-specific\nquestionnaires based on these structured representations. This framework\novercomes limitations of direct methods by building explicit clinical\nknowledge. Evaluated on a real-world EMR dataset and validated by clinical\nexperts, our method demonstrates superior performance in information coverage,\ndiagnostic relevance, understandability, and generation time, highlighting its\npractical potential to enhance patient information collection.", "AI": {"tldr": "\ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc804\uc790 \uc758\ub8cc \uae30\ub85d(EMR)\uc5d0\uc11c \uac1c\uc778\ud654\ub41c \uc9c4\ub8cc \uc804 \uc9c8\ubb38\uc9c0\ub97c \uc0dd\uc131\ud558\ub294 \uc0c8\ub85c\uc6b4 \ub2e4\ub2e8\uacc4 LLM \uae30\ubc18 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uc548\ud558\uba70, \uc815\ubcf4 \ud3ec\uad04\uc131 \ubc0f \uc9c4\ub2e8 \uad00\ub828\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4.", "motivation": "EMR\uc758 \ubcf5\uc7a1\ud568\uc73c\ub85c \uc778\ud574 \ud3ec\uad04\uc801\uc778 \uc9c4\ub8cc \uc804 \uc9c8\ubb38\uc9c0 \uc0dd\uc131\uc744 \uc5b4\ub824\uc6cc\ud55c\ub2e4.", "method": "3\ub2e8\uacc4\ub85c \uad6c\uc131\ub41c LLM \uae30\ubc18 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ud1b5\ud574 EMR\ub85c\ubd80\ud130 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uace0 \uc9c8\ubcd1 \uc9c0\uc2dd\uc744 \uc885\ud569\ud558\uc5ec \uc9c8\ubb38\uc9c0\ub97c \uc0dd\uc131\ud55c\ub2e4.", "result": "\uc2e4\uc81c EMR \ub370\uc774\ud130 \uc138\ud2b8\ub97c \uae30\ubc18\uc73c\ub85c \ud3c9\uac00\ud55c \uacb0\uacfc, \uc815\ubcf4 \ucee4\ubc84\ub9ac\uc9c0, \uc9c4\ub2e8 \uc801\ud569\uc131 \ubc0f \uc774\ud574 \uc6a9\uc774\uc131\uc5d0\uc11c \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc600\ub2e4.", "conclusion": "\uc774 \ud504\ub808\uc784\uc6cc\ud06c\ub294 \uc9c4\ub8cc \uc804 \ud658\uc790 \uc815\ubcf4 \uc218\uc9d1\uc744 \uac1c\uc120\ud560 \uc2e4\uc6a9\uc801\uc778 \uac00\ub2a5\uc131\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00304", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00304", "abs": "https://arxiv.org/abs/2508.00304", "authors": ["Tianyin Liao", "Ziwei Zhang", "Yufei Sun", "Chunyu Hu", "Jianxin Li"], "title": "Invariant Graph Transformer for Out-of-Distribution Generalization", "comment": null, "summary": "Graph Transformers (GTs) have demonstrated great effectiveness across various\ngraph analytical tasks. However, the existing GTs focus on training and testing\ngraph data originated from the same distribution, but fail to generalize under\ndistribution shifts. Graph invariant learning, aiming to capture generalizable\ngraph structural patterns with labels under distribution shifts, is potentially\na promising solution, but how to design attention mechanisms and positional and\nstructural encodings (PSEs) based on graph invariant learning principles\nremains challenging. To solve these challenges, we introduce Graph\nOut-Of-Distribution generalized Transformer (GOODFormer), aiming to learn\ngeneralized graph representations by capturing invariant relationships between\npredictive graph structures and labels through jointly optimizing three\nmodules. Specifically, we first develop a GT-based entropy-guided invariant\nsubgraph disentangler to separate invariant and variant subgraphs while\npreserving the sharpness of the attention function. Next, we design an evolving\nsubgraph positional and structural encoder to effectively and efficiently\ncapture the encoding information of dynamically changing subgraphs during\ntraining. Finally, we propose an invariant learning module utilizing subgraph\nnode representations and encodings to derive generalizable graph\nrepresentations that can to unseen graphs. We also provide theoretical\njustifications for our method. Extensive experiments on benchmark datasets\ndemonstrate the superiority of our method over state-of-the-art baselines under\ndistribution shifts.", "AI": {"tldr": "Graph Out-Of-Distribution \uc77c\ubc18\ud654 \ubcc0\ud658\uae30(GOODFormer)\ub294 \uadf8\ub798\ud504 \ubd88\ubcc0 \ud559\uc2b5 \uc6d0\uce59\uc5d0 \uae30\ubc18\ud574 \uc77c\ubc18\ud654 \uac00\ub2a5\ud55c \uadf8\ub798\ud504 \ud45c\ud604\uc744 \ud559\uc2b5\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc548\ud55c\ub2e4.", "motivation": "\uae30\uc874 \uadf8\ub798\ud504 \ubcc0\ud658\uae30\ub4e4\uc774 \ub3d9\uc77c\ud55c \ubd84\ud3ec\uc758 \uadf8\ub798\ud504 \ub370\uc774\ud130\uc5d0 \uad6d\ud55c\ub418\uc5b4 \uc77c\ubc18\ud654 \ub2a5\ub825\uc774 \ubd80\uc871\ud558\ub2e4\ub294 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uace0\uc790 \ud55c\ub2e4.", "method": "GOODFormer\ub294 \uc138 \uac00\uc9c0 \ubaa8\ub4c8\uc744 \uacf5\ub3d9 \ucd5c\uc801\ud654\ud558\uc5ec \uc608\uce21 \uadf8\ub798\ud504 \uad6c\uc870\uc640 \ub808\uc774\ube14 \uac04\uc758 \ubd88\ubcc0 \uad00\uacc4\ub97c \ud3ec\ucc29\ud558\ub294 \uac83\uc744 \ubaa9\ud45c\ub85c \ud55c\ub2e4.", "result": "\uc6b0\ub9ac\ub294 GOODFormer\uac00 \ubd84\ud3ec \ubcc0\ud654 \ud558\uc5d0\uc11c\ub3c4 \uae30\uc874 \ucd5c\ucca8\ub2e8 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b8\ub2e4\ub294 \uac83\uc744 \uc2e4\ud5d8\uc801\uc73c\ub85c \uc785\uc99d\ud558\uc600\ub2e4.", "conclusion": "\uc6b0\ub9ac\uc758 \uc811\uadfc\ubc95\uc740 \uc0c8\ub85c\uc6b4 \uadf8\ub798\ud504\uc5d0 \ub300\ud574 \uc77c\ubc18\ud654 \uac00\ub2a5\ud55c \uadf8\ub798\ud504 \ud45c\ud604\uc744 \uc131\uacf5\uc801\uc73c\ub85c \ub3c4\ucd9c\ud568\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00325", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2508.00325", "abs": "https://arxiv.org/abs/2508.00325", "authors": ["Yongquan Qu", "Matthieu Blanke", "Sara Shamekh", "Pierre Gentine"], "title": "PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models", "comment": null, "summary": "Earth system modeling presents a fundamental challenge in scientific\ncomputing: capturing complex, multiscale nonlinear dynamics in computationally\nefficient models while minimizing forecast errors caused by necessary\nsimplifications. Even the most powerful AI- or physics-based forecast system\nsuffer from gradual error accumulation. Data assimilation (DA) aims to mitigate\nthese errors by optimally blending (noisy) observations with prior model\nforecasts, but conventional variational methods often assume Gaussian error\nstatistics that fail to capture the true, non-Gaussian behavior of chaotic\ndynamical systems. We propose PnP-DA, a Plug-and-Play algorithm that alternates\n(1) a lightweight, gradient-based analysis update (using a Mahalanobis-distance\nmisfit on new observations) with (2) a single forward pass through a pretrained\ngenerative prior conditioned on the background forecast via a conditional\nWasserstein coupling. This strategy relaxes restrictive statistical assumptions\nand leverages rich historical data without requiring an explicit regularization\nfunctional, and it also avoids the need to backpropagate gradients through the\ncomplex neural network that encodes the prior during assimilation cycles.\nExperiments on standard chaotic testbeds demonstrate that this strategy\nconsistently reduces forecast errors across a range of observation sparsities\nand noise levels, outperforming classical variational methods.", "AI": {"tldr": "\uc81c\uc548\ub41c PnP-DA \uc54c\uace0\ub9ac\uc998\uc740 \ud63c\ud569 \uc804\ub7b5\uc744 \ud1b5\ud574 \uae30\ud6c4 \ubaa8\ub378\uc758 \uc608\uce21 \uc624\ucc28\ub97c \uac10\uc18c\uc2dc\ud0b5\ub2c8\ub2e4.", "motivation": "\uc9c0\uad6c \uc2dc\uc2a4\ud15c \ubaa8\ub378\ub9c1\uc5d0\uc11c \ucef4\ud4e8\ud130 \ud6a8\uc728\uc131\uc744 \uc720\uc9c0\ud558\uba74\uc11c \ubcf5\uc7a1\ud55c \ube44\uc120\ud615 \uc5ed\ud559\uc744 \uc815\ud655\ud558\uac8c \ud3ec\ucc29\ud558\ub294 \uac83\uc774 \ud544\uc694\ud558\ub2e4.", "method": "PnP-DA\ub294 \uacbd\ub7c9\uc758 \uacbd\ub7c9 \uadf8\ub798\ub514\uc5b8\ud2b8 \uae30\ubc18 \ubd84\uc11d \uc5c5\ub370\uc774\ud2b8\uc640 \uc870\uac74\ubd80 Wasserstein \ucee4\ud50c\ub9c1\uc744 \ud1b5\ud55c \uc0ac\uc804 \ud6c8\ub828\ub41c \uc0dd\uc131\uc801 \uc815\ubcf4\ub97c \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\uc73c\ub85c \uad6c\uc131\ub41c\ub2e4.", "result": "PnP-DA\ub294 \uc5ec\ub7ec \uad00\uce21 \ud76c\uc18c\uc131\uacfc \ub178\uc774\uc988 \uc218\uc900\uc5d0\uc11c \uc608\uce21 \uc624\ub958\ub97c \uc77c\uad00\ub418\uac8c \uac10\uc18c\uc2dc\ud0a4\uba70, \uace0\uc804\uc801\uc778 \ubcc0\ubd84 \ubc29\ubc95\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc600\ub2e4.", "conclusion": "\uc774 \uc54c\uace0\ub9ac\uc998\uc740 \ud63c\ud569 \uad00\uce21 \ub370\uc774\ud130\uc640 \uc0ac\uc804 \ubaa8\ub378 \uc608\uce21\uc744 \ucd5c\uc801 \uacb0\ud569\ud558\uc5ec \uc608\uce21 \uc815\ud655\ub3c4\ub97c \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4."}}
{"id": "2508.00658", "categories": ["cs.AI", "cs.LG", "econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2508.00658", "abs": "https://arxiv.org/abs/2508.00658", "authors": ["Chakattrai Sookkongwaree", "Tattep Lakmuang", "Chainarong Amornbunchornvej"], "title": "Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies", "comment": "First draft", "summary": "Understanding causal relationships in time series is fundamental to many\ndomains, including neuroscience, economics, and behavioral science. Granger\ncausality is one of the well-known techniques for inferring causality in time\nseries. Typically, Granger causality frameworks have a strong fix-lag\nassumption between cause and effect, which is often unrealistic in complex\nsystems. While recent work on variable-lag Granger causality (VLGC) addresses\nthis limitation by allowing a cause to influence an effect with different time\nlags at each time point, it fails to account for the fact that causal\ninteractions may vary not only in time delay but also across frequency bands.\nFor example, in brain signals, alpha-band activity may influence another region\nwith a shorter delay than slower delta-band oscillations. In this work, we\nformalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a\nnovel framework that generalizes traditional VLGC by explicitly modeling\nfrequency-dependent causal delays. We provide a formal definition of MB-VLGC,\ndemonstrate its theoretical soundness, and propose an efficient inference\npipeline. Extensive experiments across multiple domains demonstrate that our\nframework significantly outperforms existing methods on both synthetic and\nreal-world datasets, confirming its broad applicability to any type of time\nseries data. Code and datasets are publicly available.", "AI": {"tldr": "\ubcf8 \uc5f0\uad6c\ub294 \uc8fc\ud30c\uc218 \uc758\uc874\uc801\uc778 \uc778\uacfc \uc9c0\uc5f0\uc744 \uba85\uc2dc\uc801\uc73c\ub85c \ubaa8\ub378\ub9c1\ud558\uc5ec \ub2e4\uc911 \ub300\uc5ed \uac00\ubcc0 \uc9c0\uc5f0 \uadf8\ub79c\uc800 \uc778\uacfc \uad00\uacc4(MB-VLGC)\ub97c \uc815\ud615\ud654\ud558\uace0, \uae30\uc874\uc758 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \uc785\uc99d\ud55c\ub2e4.", "motivation": "\uae30\uc874\uc758 \uadf8\ub79c\uc800 \uc778\uacfc \uad00\uacc4 \uc811\uadfc \ubc29\uc2dd\uc740 \uace0\uc815 \uc9c0\uc5f0\uc744 \uac00\uc815\ud558\uc9c0\ub9cc, \ubcf5\uc7a1\ud55c \uc2dc\uc2a4\ud15c\uc5d0\uc11c\ub294 \ube44\ud604\uc2e4\uc801\uc77c \uc218 \uc788\uc73c\uba70, \uc2dc\uac04 \uc9c0\uc5f0\ubfd0 \uc544\ub2c8\ub77c \uc8fc\ud30c\uc218 \ub300\uc5ed\uc5d0 \ub530\ub978 \uc778\uacfc \uc0c1\ud638 \uc791\uc6a9 \ucc28\uc774\ub97c \uace0\ub824\ud560 \ud544\uc694\uac00 \uc788\ub2e4.", "method": "\ub2e4\uc911 \ub300\uc5ed \uac00\ubcc0 \uc9c0\uc5f0 \uadf8\ub79c\uc800 \uc778\uacfc \uad00\uacc4(MB-VLGC)\ub97c \uc815\uc2dd\ud654\ud558\uace0, \uc8fc\ud30c\uc218 \uc758\uc874\uc801\uc778 \uc778\uacfc \uc9c0\uc5f0\uc744 \ubaa8\ub378\ub9c1\ud558\ub294 \uc0c8\ub85c\uc6b4 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uc548\ud558\uc600\ub2e4.", "result": "\ub2e4\uc591\ud55c \ub3c4\uba54\uc778\uc5d0\uc11c \uc218\ud589\ud55c \uc2e4\ud5d8\uc744 \ud1b5\ud574 \uc81c\uc548\ud55c \ud504\ub808\uc784\uc6cc\ud06c\uac00 \uae30\uc874 \ubc29\ubc95\ub4e4\uc5d0 \ube44\ud574 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc600\uc73c\uba70, \uc774\ub85c\uc368 \uc5b4\ub5a4 \uc720\ud615\uc758 \uc2dc\uacc4\uc5f4 \ub370\uc774\ud130\uc5d0\ub3c4 \uad11\ubc94\uc704\ud558\uac8c \uc801\uc6a9 \uac00\ub2a5\ud568\uc744 \ud655\uc778\ud558\uc600\ub2e4.", "conclusion": "MB-VLGC\ub294 \uc8fc\ud30c\uc218 \uae30\ubc18\uc758 \uc778\uacfc \uc9c0\uc5f0 \ubcc0\ud654\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ubaa8\ub378\ub9c1\ud558\uc5ec \ub354 \ub098\uc740 \uc778\uacfc \ucd94\ub860\uc744 \uac00\ub2a5\ud558\uac8c \ud55c\ub2e4."}}
{"id": "2508.00331", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00331", "abs": "https://arxiv.org/abs/2508.00331", "authors": ["George Wang", "Garrett Baker", "Andrew Gordon", "Daniel Murfet"], "title": "Embryology of a Language Model", "comment": null, "summary": "Understanding how language models develop their internal computational\nstructure is a central problem in the science of deep learning. While\nsusceptibilities, drawn from statistical physics, offer a promising analytical\ntool, their full potential for visualizing network organization remains\nuntapped. In this work, we introduce an embryological approach, applying UMAP\nto the susceptibility matrix to visualize the model's structural development\nover training. Our visualizations reveal the emergence of a clear ``body\nplan,'' charting the formation of known features like the induction circuit and\ndiscovering previously unknown structures, such as a ``spacing fin'' dedicated\nto counting space tokens. This work demonstrates that susceptibility analysis\ncan move beyond validation to uncover novel mechanisms, providing a powerful,\nholistic lens for studying the developmental principles of complex neural\nnetworks.", "AI": {"tldr": "\uc774 \uc5f0\uad6c\ub294 UMAP\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5b8\uc5b4 \ubaa8\ub378\uc758 \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c\uc758 \uad6c\uc870\uc801 \ubc1c\uc804\uc744 \uc2dc\uac01\ud654\ud558\uace0, \uc0c8\ub85c\uc6b4 \uad6c\uc870\ub97c \ubc1c\uacac\ud558\uc5ec \ubcf5\uc7a1\ud55c \uc2e0\uacbd\ub9dd\uc758 \uac1c\ubc1c \uc6d0\ub9ac\ub97c \uc5f0\uad6c\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc81c\uacf5\ud55c\ub2e4.", "motivation": "\ub525 \ub7ec\ub2dd \uacfc\ud559\uc5d0\uc11c \uc5b8\uc5b4 \ubaa8\ub378\uc758 \ub0b4\ubd80 \uacc4\uc0b0 \uad6c\uc870\ub97c \uc774\ud574\ud558\ub294 \uac83\uc740 \uc911\uc694\ud55c \ubb38\uc81c\ub2e4.", "method": "\uc218\uc6a9\uc131 \ud589\ub82c\uc5d0 UMAP\uc744 \uc801\uc6a9\ud558\uc5ec \uc2dc\uac01\ud654\ub97c \uc9c4\ud589\ud55c\ub2e4.", "result": "\ubaa8\ub378\uc758 \uc778\uae30 \uc788\ub294 \ud2b9\uc9d5 \ubc0f \uc0c8\ub85c\uc6b4 \uad6c\uc870\uac00 \ub4dc\ub7ec\ub098\uba70, \ud2b9\ubcc4\ud788 '\uac04\uaca9 \ud540'\uacfc \uac19\uc740 \uad6c\uc870\uac00 \ubc1c\uacac\ub41c\ub2e4.", "conclusion": "\uc218\uc6a9\uc131 \ubd84\uc11d\uc740 \uac80\uc99d\uc744 \ub118\uc5b4 \uc0c8\ub85c\uc6b4 \uba54\ucee4\ub2c8\uc998\uc744 \ubc1c\uacac\ud560 \uc218 \uc788\ub294 \uac15\ub825\ud55c \uc218\ub2e8\uc774 \ub420 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00665", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00665", "abs": "https://arxiv.org/abs/2508.00665", "authors": ["Maryam Mosleh", "Marie Devlin", "Ellis Solaiman"], "title": "Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI", "comment": null, "summary": "Artificial intelligence-driven adaptive learning systems are reshaping\neducation through data-driven adaptation of learning experiences. Yet many of\nthese systems lack transparency, offering limited insight into how decisions\nare made. Most explainable AI (XAI) techniques focus on technical outputs but\nneglect user roles and comprehension. This paper proposes a hybrid framework\nthat integrates traditional XAI techniques with generative AI models and user\npersonalisation to generate multimodal, personalised explanations tailored to\nuser needs. We redefine explainability as a dynamic communication process\ntailored to user roles and learning goals. We outline the framework's design,\nkey XAI limitations in education, and research directions on accuracy,\nfairness, and personalisation. Our aim is to move towards explainable AI that\nenhances transparency while supporting user-centred experiences.", "AI": {"tldr": "AI \uae30\ubc18 \uc801\uc751\ud615 \ud559\uc2b5 \uc2dc\uc2a4\ud15c\uc758 \ud22c\uba85\uc131\uc744 \ub192\uc774\uae30 \uc704\ud55c \ud558\uc774\ube0c\ub9ac\ub4dc \ud504\ub808\uc784\uc6cc\ud06c \uc81c\uc548.", "motivation": "AI \uae30\ubc18 \ud559\uc2b5 \uc2dc\uc2a4\ud15c\uc758 \uc758\uc0ac\uacb0\uc815 \uacfc\uc815\uc5d0 \ub300\ud55c \ud22c\uba85\uc131 \ubd80\uc871 \ubb38\uc81c \ud574\uacb0.", "method": "\uc804\ud1b5\uc801\uc778 XAI \uae30\ubc95\uacfc \uc0dd\uc131\uc801 AI \ubaa8\ub378, \uc0ac\uc6a9\uc790 \uac1c\uc778\ud654 \ud1b5\ud569\ud55c \ud558\uc774\ube0c\ub9ac\ub4dc \ud504\ub808\uc784\uc6cc\ud06c \uc81c\uc548.", "result": "\uc0ac\uc6a9\uc790\uc758 \uc694\uad6c\uc5d0 \ub9de\ucd98 \ub2e4\uc911 \ubaa8\ub2ec \uac1c\uc778\ud654\ub41c \uc124\uba85 \uc0dd\uc131.", "conclusion": "\uc0ac\uc6a9\uc790 \uc911\uc2ec\uc758 \uacbd\ud5d8\uc744 \uc9c0\uc6d0\ud558\ub294 \ud22c\uba85\uc131 \uc99d\uc9c4\uc744 \ubaa9\ud45c\ub85c \ud568."}}
{"id": "2508.00350", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00350", "abs": "https://arxiv.org/abs/2508.00350", "authors": ["Qilin Liao", "Shuo Yang", "Bo Zhao", "Ping Luo", "Hengshuang Zhao"], "title": "BOOD: Boundary-based Out-Of-Distribution Data Generation", "comment": "14 pages, 8 figures, To be published in the Proceedings of the\n  International Conference on Machine Learning (ICML) 2025", "summary": "Harnessing the power of diffusion models to synthesize auxiliary training\ndata based on latent space features has proven effective in enhancing\nout-of-distribution (OOD) detection performance. However, extracting effective\nfeatures outside the in-distribution (ID) boundary in latent space remains\nchallenging due to the difficulty of identifying decision boundaries between\nclasses. This paper proposes a novel framework called Boundary-based\nOut-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD\nfeatures and generates human-compatible outlier images using diffusion models.\nBOOD first learns a text-conditioned latent feature space from the ID dataset,\nselects ID features closest to the decision boundary, and perturbs them to\ncross the decision boundary to form OOD features. These synthetic OOD features\nare then decoded into images in pixel space by a diffusion model. Compared to\nprevious works, BOOD provides a more training efficient strategy for\nsynthesizing informative OOD features, facilitating clearer distinctions\nbetween ID and OOD data. Extensive experimental results on common benchmarks\ndemonstrate that BOOD surpasses the state-of-the-art method significantly,\nachieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27%\nimprovement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.", "AI": {"tldr": "BOOD\ub294 OOD \ub370\uc774\ud130 \uc0dd\uc131\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \ud504\ub808\uc784\uc6cc\ud06c\ub85c, \uacb0\uc815 \uacbd\uacc4\ub97c \ub118\uc5b4\uc11c\ub294 \ud2b9\uc9d5\uc744 \uc0dd\uc131\ud558\uc5ec OOD \ud0d0\uc9c0 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "motivation": "OOD \ud0d0\uc9c0 \uc131\ub2a5\uc744 \ub192\uc774\uae30 \uc704\ud574, \uc7a0\uc7ac \uacf5\uac04\uc5d0\uc11c \uacb0\uc815 \uacbd\uacc4 \uc678\ubd80\uc758 \ud6a8\uacfc\uc801\uc778 \ud2b9\uc9d5\uc744 \ucd94\ucd9c\ud558\ub294 \uac83\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.", "method": "BOOD\ub294 ID \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud14d\uc2a4\ud2b8 \uc870\uac74 \uc7a0\uc7ac \uacf5\uac04\uc744 \ud559\uc2b5\ud558\uace0, \uacb0\uc815 \uacbd\uacc4\uc5d0 \uac00\uc7a5 \uac00\uae4c\uc6b4 ID \ud2b9\uc9d5\uc744 \uc120\ud0dd\ud558\uc5ec \uc774\ub97c \uad50\ub780\uc2dc\ucf1c OOD \ud2b9\uc9d5\uc73c\ub85c \ub9cc\ub4ed\ub2c8\ub2e4.", "result": "BOOD\ub294 \ucd5c\uc2e0 \uae30\ubc95\uc5d0 \ube44\ud574 \ud3c9\uade0 FPR95\uc5d0\uc11c 29.64% \uac10\uc18c\ud558\uace0, AUROC\uc5d0\uc11c 7.27% \ud5a5\uc0c1\ub41c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "conclusion": "BOOD\ub294 \ud6a8\uacfc\uc801\uc778 OOD \ud2b9\uc9d5 \uc0dd\uc131\uc744 \uc704\ud55c \ub354 \ud6a8\uc728\uc801\uc778 \ud6c8\ub828 \uc804\ub7b5\uc744 \uc81c\uacf5\ud558\uc5ec ID\uc640 OOD \ub370\uc774\ud130 \uac04\uc758 \ub69c\ub837\ud55c \uad6c\ubd84\uc744 \ucd09\uc9c4\ud569\ub2c8\ub2e4."}}
{"id": "2508.00674", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00674", "abs": "https://arxiv.org/abs/2508.00674", "authors": ["Banan Alkhateeb", "Ellis Solaiman"], "title": "Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations", "comment": null, "summary": "Social media platforms today strive to improve user experience through AI\nrecommendations, yet the value of such recommendations vanishes as users do not\nunderstand the reasons behind them. This issue arises because explainability in\nsocial media is general and lacks alignment with user-specific needs. In this\nvision paper, we outline a user-segmented and context-aware explanation layer\nby proposing a visual explanation system with diverse explanation methods. The\nproposed system is framed by the variety of user needs and contexts, showing\nexplanations in different visualized forms, including a technically detailed\nversion for AI experts and a simplified one for lay users. Our framework is the\nfirst to jointly adapt explanation style (visual vs. numeric) and granularity\n(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will\nvalidate its impact on decision-making and trust.", "AI": {"tldr": "\uc18c\uc15c \ubbf8\ub514\uc5b4 \ucd94\ucc9c \uc2dc\uc2a4\ud15c\uc758 \uc124\uba85 \uac00\ub2a5\uc131\uc744 \uac15\ud654\ud558\uae30 \uc704\ud574, \uc0ac\uc6a9\uc790 \uc138\ubd84\ud654 \ubc0f \ub9e5\ub77d \uc778\uc2dd \uae30\ubc18\uc758 \uc2dc\uac01\uc801 \uc124\uba85 \uc2dc\uc2a4\ud15c\uc744 \uc81c\uc548\ud568.", "motivation": "\uc18c\uc15c \ubbf8\ub514\uc5b4\uc5d0\uc11c\uc758 AI \ucd94\ucc9c\uc774 \uc0ac\uc6a9\uc790 \uc774\ud574 \ubd80\uc871\uc73c\ub85c \uc778\ud574 \uac00\uce58\uac00 \uac10\uc18c\ud568.", "method": "\uc0ac\uc6a9\uc790 \uc694\uad6c\uc640 \ub9e5\ub77d\uc5d0 \ub9de\ucd98 \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \uc124\uba85 \ubc29\ubc95\uc744 \uc81c\uacf5\ud558\ub294 \uc2dc\uc2a4\ud15c\uc744 \uc81c\uc548.", "result": "\uc0ac\uc6a9\uc790 \ub9de\ucda4\ud615 \uc2dc\uac01\uc801 \uc124\uba85\uc744 \ud1b5\ud574 \uacb0\uc815-making\uacfc \uc2e0\ub8b0\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uac80\uc99d\ud560 \ud30c\uc77c\ub7ff\uc744 \uc9c4\ud589\ud560 \uacc4\ud68d.", "conclusion": "\uc774 \ud504\ub808\uc784\uc6cc\ud06c\ub294 \uc124\uba85 \uc2a4\ud0c0\uc77c\uacfc \uc138\ubd84\ud654\uc758 \uc801\uc751\uc744 \ub3d9\uc2dc\uc5d0 \uac00\ub2a5\ud558\uac8c \ud558\ub294 \ucd5c\ucd08\uc758 \uc2dc\uc2a4\ud15c\uc774\ub2e4."}}
{"id": "2508.00357", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00357", "abs": "https://arxiv.org/abs/2508.00357", "authors": ["Yoonhyuk Choi", "Jiho Choi", "Chong-Kwon Kim"], "title": "Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization", "comment": null, "summary": "Over-smoothing in Graph Neural Networks (GNNs) causes collapse in distinct\nnode features, particularly on heterophilic graphs where adjacent nodes often\nhave dissimilar labels. Although sheaf neural networks partially mitigate this\nproblem, they typically rely on static or heavily parameterized sheaf\nstructures that hinder generalization and scalability. Existing sheaf-based\nmodels either predefine restriction maps or introduce excessive complexity, yet\nfail to provide rigorous stability guarantees. In this paper, we introduce a\nnovel scheme called SGPC (Sheaf GNNs with PAC-Bayes Calibration), a unified\narchitecture that combines cellular-sheaf message passing with several\nmechanisms, including optimal transport-based lifting, variance-reduced\ndiffusion, and PAC-Bayes spectral regularization for robust semi-supervised\nnode classification. We establish performance bounds theoretically and\ndemonstrate that the resulting bound-aware objective can be achieved via\nend-to-end training in linear computational complexity. Experiments on nine\nhomophilic and heterophilic benchmarks show that SGPC outperforms\nstate-of-the-art spectral and sheaf-based GNNs while providing certified\nconfidence intervals on unseen nodes.", "AI": {"tldr": "SGPC\ub77c\ub294 \uc0c8\ub85c\uc6b4 \uc544\ud0a4\ud14d\ucc98\ub97c \ub3c4\uc785\ud558\uc5ec \uadf8\ub798\ud504 \uc2e0\uacbd\ub9dd\uc758 \uc624\ubc84 \uc2a4\ubb34\ub529 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uace0 \uc131\ub2a5 \uacbd\uacc4\ub97c \uc774\ub860\uc801\uc73c\ub85c \ud655\ub9bd\ud558\uc600\ub2e4.", "motivation": "\uadf8\ub798\ud504 \uc2e0\uacbd\ub9dd\uc5d0\uc11c\uc758 \uc624\ubc84 \uc2a4\ubb34\ub529 \ubb38\uc81c\ub294 \uc774\uc885 \uadf8\ub798\ud504\uc5d0\uc11c \ub178\ub4dc \ud2b9\uc131\uc774 \uc0ac\ub77c\uc9c0\ub294 \ud604\uc0c1\uc744 \uc57c\uae30\ud558\uba70, \uae30\uc874\uc758 \uc2dc\ud504 \ubaa8\ub378\ub4e4\uc740 \uc77c\ubc18\ud654 \ubc0f \ud655\uc7a5\uc131\uc5d0 \uc788\uc5b4\uc11c \ud55c\uacc4\ub97c \ubcf4\uc778\ub2e4.", "method": "SGPC\ub294 \uc138\ud3ec-\uc2dc\ud504 \uba54\uc2dc\uc9c0 \uc804\uc1a1\uacfc \ucd5c\uc801 \uc218\uc1a1 \uae30\ubc18 \ub9ac\ud504\ud305, \ubd84\uc0b0 \uac10\uc18c \ud655\uc0b0, PAC-Bayes \uc2a4\ud399\ud2b8\ub7fc \uc815\uaddc\ud654\ub97c \uacb0\ud569\ud558\uc5ec \uac15\ub825\ud55c \uc900\uc9c0\ub3c4 \ub178\ub4dc \ubd84\ub958\ub97c \uc218\ud589\ud55c\ub2e4.", "result": "SGPC\ub294 \uc544\ud649 \uac1c\uc758 \ub3d9\uc9c8 \ubc0f \uc774\uc9c8 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ucd5c\ucca8\ub2e8 \uc2a4\ud399\ud2b8\ub7fc \ubc0f \uc2dc\ud504 \uae30\ubc18 GNNs\ub97c \ucd08\uacfc\ud558\ub294 \uc131\ub2a5\uc744 \ubc1c\ud718\ud558\uba70, \ubcf4\uc774\uc9c0 \uc54a\ub294 \ub178\ub4dc\uc5d0 \ub300\ud55c \uc2e0\ub8b0 \uad6c\uac04\uc744 \uc778\uc99d\ud560 \uc218 \uc788\ub2e4.", "conclusion": "SGPC\ub294 \uc120\ud615 \uacc4\uc0b0 \ubcf5\uc7a1\ub3c4\ub85c end-to-end \ud559\uc2b5\uc744 \ud1b5\ud574 \uc131\ub2a5 \uacbd\uacc4\ub97c \ub2ec\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc785\uc99d\ud558\uc600\ub2e4."}}
{"id": "2508.00784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00784", "abs": "https://arxiv.org/abs/2508.00784", "authors": ["Tom Or", "Omri Azencot"], "title": "Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics", "comment": null, "summary": "Generative models achieve remarkable results in multiple data domains,\nincluding images and texts, among other examples. Unfortunately, malicious\nusers exploit synthetic media for spreading misinformation and disseminating\ndeepfakes. Consequently, the need for robust and stable fake detectors is\npressing, especially when new generative models appear everyday. While the\nmajority of existing work train classifiers that discriminate between real and\nfake information, such tools typically generalize only within the same family\nof generators and data modalities, yielding poor results on other generative\nclasses and data domains. Towards a universal classifier, we propose the use of\nlarge pre-trained multi-modal models for the detection of generative content.\nEffectively, we show that the latent code of these models naturally captures\ninformation discriminating real from fake. Building on this observation, we\ndemonstrate that linear classifiers trained on these features can achieve\nstate-of-the-art results across various modalities, while remaining\ncomputationally efficient, fast to train, and effective even in few-shot\nsettings. Our work primarily focuses on fake detection in audio and images,\nachieving performance that surpasses or matches that of strong baseline\nmethods.", "AI": {"tldr": "\ub2e4\uc591\ud55c \ub370\uc774\ud130 \ub3c4\uba54\uc778\uc5d0\uc11c \ud569\uc131 \ubbf8\ub514\uc5b4\ub97c \ud0d0\uc9c0\ud558\uae30 \uc704\ud55c \ubcf4\ud3b8\uc801\uc778 \ubd84\ub958\uae30\ub97c \uc81c\uc548\ud568\uc73c\ub85c\uc368 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubaa9\ud45c\ub85c \ud568.", "motivation": "\ud569\uc131 \ubbf8\ub514\uc5b4\uc758 \uc545\uc6a9\uc774 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uac15\ub825\ud55c \uac00\uc9dc \ud0d0\uc9c0\uae30\uc758 \ud544\uc694\uc131\uc774 \ub300\ub450\ub418\uace0 \uc788\uc74c.", "method": "\ub300\uaddc\ubaa8\ub85c \uc0ac\uc804 \ud6c8\ub828\ub41c \ub2e4\uc911 \ubaa8\ub2ec \ubaa8\ub378\uc758 \uc7a0\uc7ac \ucf54\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc9c4\uc9dc\uc640 \uac00\uc9dc\ub97c \uad6c\ubd84\ud558\ub294 \uc815\ubcf4\ub97c \ud3ec\ucc29\ud558\uace0, \uc774 \ud53c\uccd0\uc5d0 \ub300\ud55c \uc120\ud615 \ubd84\ub958\uae30\ub97c \ud6c8\ub828\ud568.", "result": "\ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0\uc5d0\uc11c \ucd5c\ucca8\ub2e8 \uacb0\uacfc\ub97c \ub2ec\uc131\ud558\uba70, \uacc4\uc0b0 \ud6a8\uc728\uc131\uacfc \ube60\ub978 \ud6c8\ub828 \uc18d\ub3c4\ub97c \uc720\uc9c0\ud568.", "conclusion": "\uc624\ub514\uc624\uc640 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc131\ub2a5\uc774 \uae30\uc874\uc758 \uac15\ub825\ud55c \uae30\uc900 \ubc29\ubc95\uc744 \ucd08\uc6d4\ud558\uac70\ub098 \ub3d9\ub4f1\ud568."}}
{"id": "2508.00364", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00364", "abs": "https://arxiv.org/abs/2508.00364", "authors": ["Chanyoung Yoon", "Sangbong Yoo", "Soobin Yim", "Chansoo Kim", "Yun Jang"], "title": "OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions", "comment": null, "summary": "Designing residential interiors strongly impacts occupant satisfaction but\nremains challenging due to unstructured spatial layouts, high computational\ndemands, and reliance on expert knowledge. Existing methods based on\noptimization or deep learning are either computationally expensive or\nconstrained by data scarcity. Reinforcement learning (RL) approaches often\nlimit furniture placement to discrete positions and fail to incorporate design\nprinciples adequately. We propose OID-PPO, a novel RL framework for Optimal\nInterior Design using Proximal Policy Optimization, which integrates\nexpert-defined functional and visual guidelines into a structured reward\nfunction. OID-PPO utilizes a diagonal Gaussian policy for continuous and\nflexible furniture placement, effectively exploring latent environmental\ndynamics under partial observability. Experiments conducted across diverse room\nshapes and furniture configurations demonstrate that OID-PPO significantly\noutperforms state-of-the-art methods in terms of layout quality and\ncomputational efficiency. Ablation studies further demonstrate the impact of\nstructured guideline integration and reveal the distinct contributions of\nindividual design constraints.", "AI": {"tldr": "OID-PPO\ub294 \ucd5c\uc801\uc758 \ub0b4\ubd80 \ub514\uc790\uc778\uc744 \uc704\ud55c \uac15\ud654 \ud559\uc2b5 \ud504\ub808\uc784\uc6cc\ud06c\ub85c, \uc804\ubb38\uac00\uc758 \uac00\uc774\ub4dc\ub77c\uc778\uc744 \ud1b5\ud569\ud558\uc5ec \ud6a8\uc728\uc801\uc778 \uac00\uad6c \ubc30\uce58\ub97c \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.", "motivation": "\uc8fc\uac70 \uacf5\uac04 \ub514\uc790\uc778\uc774 \uac70\uc8fc\uc790\uc758 \ub9cc\uc871\ub3c4\uc5d0 \ud070 \uc601\ud5a5\uc744 \ubbf8\uce58\uc9c0\ub9cc, \uae30\uc874\uc758 \uc811\uadfc \ubc29\uc2dd\ub4e4\uc774 \uacc4\uc0b0\ube44\uc6a9\uc774 \ud06c\uac70\ub098 \ub370\uc774\ud130 \ubd80\uc871 \ubb38\uc81c\uc5d0 \uc9c1\uba74\ud574 \uc788\uc2b5\ub2c8\ub2e4.", "method": "OID-PPO \ud504\ub808\uc784\uc6cc\ud06c\ub294 \uc804\ubb38\uac00 \uc815\uc758\uc758 \uae30\ub2a5\uc801 \ubc0f \uc2dc\uac01\uc801 \uac00\uc774\ub4dc\ub77c\uc778\uc744 \ud1b5\ud569\ud55c \ubcf4\uc0c1 \ud568\uc218\uc640 \ud568\uaed8 \uc5f0\uc18d\uc801\uc778 \uac00\uad6c \ubc30\uce58\ub97c \uc704\ud55c \ub300\uac01\uc120 \uac00\uc6b0\uc2dc\uc548 \uc815\ucc45\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.", "result": "OID-PPO\ub294 \ub2e4\uc591\ud55c \ubc29 \ud615\ud0dc\uc640 \uac00\uad6c \uad6c\uc131\uc5d0\uc11c \ub808\uc774\uc544\uc6c3 \ud488\uc9c8 \ubc0f \uacc4\uc0b0 \ud6a8\uc728\uc131 \uce21\uba74\uc5d0\uc11c \uae30\uc874 \ucd5c\ucca8\ub2e8 \ubc29\ubc95\uc744 \ud06c\uac8c \ucd08\uacfc \uc131\uacfc\ub97c \ubcf4\uc600\uc2b5\ub2c8\ub2e4.", "conclusion": "OID-PPO\ub294 \ud6a8\uc728\uc801\uc778 \uac00\uad6c \ubc30\uce58\ub97c \uc704\ud55c \ud601\uc2e0\uc801\uc778 \uc811\uadfc \ubc29\uc2dd\uc73c\ub85c, \ub514\uc790\uc778 \uc6d0\uce59\uacfc \uac00\uc774\ub4dc\ub77c\uc778 \ud1b5\ud569\uc774 \uc911\uc694\ud558\ub2e4\ub294 \uac83\uc744 \uac15\uc870\ud569\ub2c8\ub2e4."}}
{"id": "2508.00392", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00392", "abs": "https://arxiv.org/abs/2508.00392", "authors": ["Lijun Zhang", "Wenhao Yang", "Guanghui Wang", "Wei Jiang", "Zhi-Hua Zhou"], "title": "Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions", "comment": "arXiv admin note: text overlap with arXiv:1906.10851", "summary": "To deal with changing environments, a new performance measure -- adaptive\nregret, defined as the maximum static regret over any interval, was proposed in\nonline learning. Under the setting of online convex optimization, several\nalgorithms have been successfully developed to minimize the adaptive regret.\nHowever, existing algorithms lack universality in the sense that they can only\nhandle one type of convex functions and need apriori knowledge of parameters,\nwhich hinders their application in real-world scenarios. To address this\nlimitation, this paper investigates universal algorithms with dual adaptivity,\nwhich automatically adapt to the property of functions (convex, exponentially\nconcave, or strongly convex), as well as the nature of environments (stationary\nor changing). Specifically, we propose a meta-expert framework for dual\nadaptive algorithms, where multiple experts are created dynamically and\naggregated by a meta-algorithm. The meta-algorithm is required to yield a\nsecond-order bound, which can accommodate unknown function types. We further\nincorporate the technique of sleeping experts to capture the changing\nenvironments. For the construction of experts, we introduce two strategies\n(increasing the number of experts or enhancing the capabilities of experts) to\nachieve universality. Theoretical analysis shows that our algorithms are able\nto minimize the adaptive regret for multiple types of convex functions\nsimultaneously, and also allow the type of functions to switch between rounds.\nMoreover, we extend our meta-expert framework to online composite optimization,\nand develop a universal algorithm for minimizing the adaptive regret of\ncomposite functions.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \uc628\ub77c\uc778 \ud559\uc2b5\uc5d0\uc11c \ubcc0\ud654\ud558\ub294 \ud658\uacbd\uc744 \ub2e4\ub8e8\uae30 \uc704\ud574 \uc0c8\ub85c\uc6b4 \uc131\ub2a5 \uce21\uc815\uce58\uc778 \uc801\uc751\uc801 \ud6c4\ud68c\ub97c \uc81c\uc548\ud558\uace0, \uc720\ub2c8\ubc84\uc124 \uc54c\uace0\ub9ac\uc998\uc744 \ud1b5\ud574 \ub2e4\uc591\ud55c \ubcfc\ub85d \ud568\uc218\uc5d0 \uc801\uc6a9\ud560 \uc218 \uc788\ub294 \uc54c\uace0\ub9ac\uc998\uc744 \uac1c\ubc1c\ud55c\ub2e4.", "motivation": "\uae30\uc874 \uc54c\uace0\ub9ac\uc998\ub4e4\uc740 \ud558\ub098\uc758 \uc720\ud615\uc758 \ubcfc\ub85d \ud568\uc218\ub9cc \ucc98\ub9ac\ud560 \uc218 \uc788\uace0, \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ub300\ud55c \uc0ac\uc804 \uc9c0\uc2dd\uc774 \ud544\uc694\ud558\ub2e4.", "method": "\ub4c0\uc5bc \uc801\uc751\uc131\uc744 \uac00\uc9c4 \uc720\ub2c8\ubc84\uc124 \uc54c\uace0\ub9ac\uc998\uc744 \uc870\uc0ac\ud558\uace0, \uba54\ud0c0-\uc804\ubb38\uac00 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ud1b5\ud574 \uc5ec\ub7ec \uc804\ubb38\uac00\ub97c \ub3d9\uc801\uc73c\ub85c \uc0dd\uc131 \ubc0f \uc9d1\uacc4\ud55c\ub2e4.", "result": "\uc81c\uc548\ub41c \uc54c\uace0\ub9ac\uc998\uc740 \uc5ec\ub7ec \uc720\ud615\uc758 \ubcfc\ub85d \ud568\uc218\uc5d0 \ub300\ud574 \uc801\uc751\uc801 \ud6c4\ud68c\ub97c \ucd5c\uc18c\ud654\ud560 \uc218 \uc788\uc73c\uba70, \ud568\uc218 \uc720\ud615\uc774 \ub77c\uc6b4\ub4dc \uac04\uc5d0 \uc804\ud658\ub420 \uc218 \uc788\ub2e4.", "conclusion": "\uba54\ud0c0-\uc804\ubb38\uac00 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc628\ub77c\uc778 \ubcf5\ud569 \ucd5c\uc801\ud654\ub85c \ud655\uc7a5\ud558\uc5ec \ubcf5\ud569 \ud568\uc218\uc758 \uc801\uc751\uc801 \ud6c4\ud68c\ub97c \ucd5c\uc18c\ud654\ud558\ub294 \uc720\ub2c8\ubc84\uc124 \uc54c\uace0\ub9ac\uc998\uc744 \uac1c\ubc1c\ud588\ub2e4."}}
{"id": "2508.00394", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00394", "abs": "https://arxiv.org/abs/2508.00394", "authors": ["Antonis Klironomos", "Baifan Zhou", "Zhipeng Tan", "Zhuoxun Zheng", "Mohamed H. Gad-Elrab", "Heiko Paulheim", "Evgeny Kharlamov"], "title": "ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs", "comment": null, "summary": "Nowadays machine learning (ML) practitioners have access to numerous ML\nlibraries available online. Such libraries can be used to create ML pipelines\nthat consist of a series of steps where each step may invoke up to several ML\nlibraries that are used for various data-driven analytical tasks. Development\nof high-quality ML pipelines is non-trivial; it requires training, ML\nexpertise, and careful development of each step. At the same time, domain\nexperts in science and engineering may not possess such ML expertise and\ntraining while they are in pressing need of ML-based analytics. In this paper,\nwe present our ExeKGLib, a Python library enhanced with a graphical interface\nlayer that allows users with minimal ML knowledge to build ML pipelines. This\nis achieved by relying on knowledge graphs that encode ML knowledge in simple\nterms accessible to non-ML experts. ExeKGLib also allows improving the\ntransparency and reusability of the built ML workflows and ensures that they\nare executable. We show the usability and usefulness of ExeKGLib by presenting\nreal use cases.", "AI": {"tldr": "ExeKGLib\ub294 ML \uc9c0\uc2dd\uc774 \uc5c6\ub294 \uc0ac\uc6a9\uc790\ub3c4 \uba38\uc2e0 \ub7ec\ub2dd \ud30c\uc774\ud504\ub77c\uc778\uc744 \uad6c\ucd95\ud560 \uc218 \uc788\ub3c4\ub85d \uc9c0\uc6d0\ud558\ub294 Python \ub77c\uc774\ube0c\ub7ec\ub9ac\uc774\ub2e4.", "motivation": "\uacfc\ud559 \ubc0f \uacf5\ud559 \ubd84\uc57c\uc758 \uc804\ubb38\uac00\ub4e4\uc774 \uba38\uc2e0 \ub7ec\ub2dd \uae30\ubc18\uc758 \ubd84\uc11d\uc744 \uae34\uae09\ud788 \ud544\uc694\ub85c \ud558\uc9c0\ub9cc, \uc774\ub97c \uc704\ud55c ML \uc804\ubb38 \uc9c0\uc2dd\uacfc \ud6c8\ub828\uc774 \ubd80\uc871\ud558\ub2e4.", "method": "\uc9c0\uc2dd \uadf8\ub798\ud504\ub97c \ud65c\uc6a9\ud558\uc5ec ML \uc9c0\uc2dd\uc744 \ube44\uc804\ubb38\uac00\ub3c4 \uc774\ud574\ud560 \uc218 \uc788\ub294 \ud615\ud0dc\ub85c \uc81c\uacf5\ud558\uba70, \uc9c1\uad00\uc801\uc778 \uadf8\ub798\ud53d \uc778\ud130\ud398\uc774\uc2a4\ub97c \ud1b5\ud574 \ud30c\uc774\ud504\ub77c\uc778\uc744 \uad6c\ucd95\ud560 \uc218 \uc788\uac8c \ud55c\ub2e4.", "result": "ExeKGLib\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2e4\uc81c \uc0ac\uc6a9 \uc0ac\ub840\ub97c \ud1b5\ud574 \uadf8 \uc720\uc6a9\uc131\uacfc \uc0ac\uc6a9\uc131\uc744 \uc785\uc99d\ud558\uc600\ub2e4.", "conclusion": "ExeKGLib\ub294 \ud30c\uc774\ud504\ub77c\uc778\uc758 \ud22c\uba85\uc131\uacfc \uc7ac\uc0ac\uc6a9\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uace0, \uc0ac\uc6a9\uc790\ub4e4\uc774 \uc27d\uac8c \uc2e4\ud589 \uac00\ub2a5\ud55c ML \uc6cc\ud06c\ud50c\ub85c\uc6b0\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uac8c \uc9c0\uc6d0\ud55c\ub2e4."}}
{"id": "2508.00410", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00410", "abs": "https://arxiv.org/abs/2508.00410", "authors": ["Zizhuo Zhang", "Jianing Zhu", "Xinmu Ge", "Zihua Zhao", "Zhanke Zhou", "Xuan Li", "Xiao Feng", "Jiangchao Yao", "Bo Han"], "title": "Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement", "comment": null, "summary": "Although reinforcement learning with verifiable rewards (RLVR) shows promise\nin improving the reasoning ability of large language models (LLMs), the scaling\nup dilemma remains due to the reliance on human annotated labels especially for\ncomplex tasks. Recent alternatives that explore various self-reward signals\nexhibit the eliciting potential of LLM reasoning, but suffer from the\nnon-negligible collapse issue. Inspired by the success of self-supervised\nlearning, we propose \\textit{Co-Reward}, a novel RL framework that leverages\ncontrastive agreement across semantically analogical questions as a reward\nbasis. Specifically, we construct a similar question for each training sample\n(without labels) and synthesize their individual surrogate labels through a\nsimple rollout voting, and then the reward is constructed by cross-referring\nthe labels of each question pair to enforce the internal reasoning consistency\nacross analogical inputs. Intuitively, such a self-supervised reward-shaping\nmechanism increases the difficulty of learning collapse into a trivial\nsolution, and promotes stable reasoning elicitation and improvement through\nexpanding the input sample variants. Empirically, Co-Reward achieves superior\nperformance compared to other self-reward baselines on multiple reasoning\nbenchmarks and LLM series, and reaches or even surpasses ground-truth (GT)\nlabeled reward, with improvements of up to $+6.8\\%$ on MATH500 over GT reward\non Llama-3.2-3B-Instruct. Our code is publicly available at\nhttps://github.com/tmlr-group/Co-Reward.", "AI": {"tldr": "RLVR\uc740 LLM\uc758 \ucd94\ub860 \ub2a5\ub825\uc744 \uac1c\uc120\ud558\ub294 \ub370 \uc720\ub9dd\ud558\uc9c0\ub9cc, \uc778\uac04 \uc8fc\uc11d \ub808\uc774\ube14\uc5d0 \uc758\uc874\ud558\uc5ec \uaddc\ubaa8 \ud655\uc7a5\uc758 \ub51c\ub808\ub9c8\uac00 \uc788\ub2e4. \uc774\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 'Co-Reward'\ub77c\ub294 \uc0c8\ub85c\uc6b4 RL \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uc548\ud558\uba70, \uc790\uac00 \uc9c0\ub3c4 \ud559\uc2b5\uc758 \uc131\uacf5\uc5d0 \uc601\uac10\uc744 \ubc1b\uc544 \uc720\uc0ac\ud55c \uc9c8\ubb38 \uac04\uc758 \ub300\uc870\uc801 \uc77c\uce58\ub97c \ubcf4\uc0c1 \uae30\ubc18\uc73c\ub85c \ud65c\uc6a9\ud55c\ub2e4.", "motivation": "RLVR\uc758 \ud55c\uacc4\ub97c \uadf9\ubcf5\ud558\uace0 LLM\uc758 \ucd94\ub860 \ub2a5\ub825\uc744 \ubcf4\ub2e4 \uc548\uc815\uc801\uc73c\ub85c \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 \uc0c8\ub85c\uc6b4 \ubc29\ubc95\ub860\uc774 \ud544\uc694\ud558\ub2e4.", "method": "\ub300\uc870\uc801 \uc9c8\ubb38 \ub450 \uc30d\uc744 \uad6c\uc131\ud558\uace0, \uac01 \uc9c8\ubb38\uc758 \ub300\ub9ac \ub808\uc774\ube14\uc744 \uc0dd\uc131\ud558\uc5ec \uc0c1\ud638 \ucc38\uc870\ub97c \ud1b5\ud574 \ubcf4\uc0c1\uc744 \uad6c\uc131\ud558\ub294 \uc790\uac00 \uc9c0\ub3c4 \ubcf4\uc0c1 \ud615\uc131 \uba54\ucee4\ub2c8\uc998\uc744 \ub3c4\uc785\ud55c\ub2e4.", "result": "Co-Reward\ub294 \uc5ec\ub7ec \ucd94\ub860 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\ub978 \uc790\uac00 \ubcf4\uc0c1 \uae30\uc900\uc120\ubcf4\ub2e4 \ub354 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\uace0, MATH500\uc5d0\uc11c GT \ubcf4\uc0c1 \ub300\ube44 \ucd5c\ub300 6.8% \uac1c\uc120\ub41c \uc131\uacfc\ub97c \uae30\ub85d\ud588\ub2e4.", "conclusion": "Co-Reward\ub294 LLM\uc758 \ud6a8\uacfc\uc801\uc778 \ucd94\ub860 \ub2a5\ub825 \uac1c\uc120\uc5d0 \uae30\uc5ec\ud558\uba70, \uc790\uac00 \uc9c0\ub3c4 \ubcf4\uc0c1\uc744 \ud1b5\ud574 \uc801\uc751\ud615 \ud559\uc2b5\uc774 \uac00\ub2a5\ud558\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00415", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00415", "abs": "https://arxiv.org/abs/2508.00415", "authors": ["Yue Yang", "Yuxiang Lin", "Ying Zhang", "Zihan Su", "Chang Chuan Goh", "Tangtangfang Fang", "Anthony Graham Bellotti", "Boon Giin Lee"], "title": "Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection", "comment": null, "summary": "Prediction of post-loan default is an important task in credit risk\nmanagement, and can be addressed by detection of financial anomalies using\nmachine learning. This study introduces a ResE-BiLSTM model, using a sliding\nwindow technique, and is evaluated on 44 independent cohorts from the extensive\nFreddie Mac US mortgage dataset, to improve prediction performance. The\nResE-BiLSTM is compared with five baseline models: Long Short-Term Memory\n(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks\n(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including\nAccuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to\nevaluate the contribution of individual components in the ResE-BiLSTM\narchitecture. Additionally, SHAP analysis was employed to interpret the\nunderlying features the model relied upon for its predictions. Experimental\nresults demonstrate that ResE-BiLSTM achieves superior predictive performance\ncompared to baseline models, underscoring its practical value and applicability\nin real-world scenarios.", "AI": {"tldr": "ResE-BiLSTM \ubaa8\ub378\uc744 \ud65c\uc6a9\ud55c \ub300\ucd9c \ud6c4 \ub514\ud3f4\ud2b8 \uc608\uce21 \uc5f0\uad6c\ub85c, \uae30\uacc4 \ud559\uc2b5\uc744 \ud1b5\ud574 \uae08\uc735 \uc774\uc0c1 \ud0d0\uc9c0\uc5d0 \ucd08\uc810\uc744 \ub9de\ucda4.", "motivation": "\uc2e0\uc6a9 \uc704\ud5d8 \uad00\ub9ac\uc5d0\uc11c \ub300\ucd9c \ud6c4 \ub514\ud3f4\ud2b8 \uc608\uce21\uc740 \uc911\uc694\ud558\uba70, \uae30\uacc4 \ud559\uc2b5\uc744 \ud1b5\ud574 \uae08\uc735 \uc774\uc0c1\uc744 \ud0d0\uc9c0\ud558\ub294 \uac83\uc774 \ud544\uc694\ud558\ub2e4.", "method": "\uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0 \uae30\ubc95\uc744 \uc0ac\uc6a9\ud55c ResE-BiLSTM \ubaa8\ub378\uc744 \uc801\uc6a9\ud558\uace0, \ub2e4\uc591\ud55c \uae30\ucd08 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uc600\ub2e4.", "result": "ResE-BiLSTM\uc740 \uc815\ud655\ub3c4, \uc815\ubc00\ub3c4, \uc7ac\ud604\uc728, F1 \uc810\uc218, AUC \ub4f1\uc5d0\uc11c \uae30\ucd08 \ubaa8\ub378\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc608\uce21 \uc131\ub2a5\uc744 \ubcf4\uc600\ub2e4.", "conclusion": "ResE-BiLSTM \ubaa8\ub378\uc740 \uc2e4\uc81c \uc0c1\ud669\uc5d0\uc11c\uc758 \uc720\uc6a9\uc131\uc744 \uac15\uc870\ud558\uba70, \uc2e0\uc6a9 \uc704\ud5d8 \uad00\ub9ac\uc5d0 \uc911\uc694\ud55c \uac00\uce58\ub97c \uc9c0\ub2cc\ub2e4."}}
{"id": "2508.00472", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00472", "abs": "https://arxiv.org/abs/2508.00472", "authors": ["Leonidas Akritidis", "Panayiotis Bozanis"], "title": "A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces", "comment": null, "summary": "The tabular form constitutes the standard way of representing data in\nrelational database systems and spreadsheets. But, similarly to other forms,\ntabular data suffers from class imbalance, a problem that causes serious\nperformance degradation in a wide variety of machine learning tasks. One of the\nmost effective solutions dictates the usage of Generative Adversarial Networks\n(GANs) in order to synthesize artificial data instances for the\nunder-represented classes. Despite their good performance, none of the proposed\nGAN models takes into account the vector subspaces of the input samples in the\nreal data space, leading to data generation in arbitrary locations. Moreover,\nthe class labels are treated in the same manner as the other categorical\nvariables during training, so conditional sampling by class is rendered less\neffective. To overcome these problems, this study presents ctdGAN, a\nconditional GAN for alleviating class imbalance in tabular datasets. Initially,\nctdGAN executes a space partitioning step to assign cluster labels to the input\nsamples. Subsequently, it utilizes these labels to synthesize samples via a\nnovel probabilistic sampling strategy and a new loss function that penalizes\nboth cluster and class mis-predictions. In this way, ctdGAN is trained to\ngenerate samples in subspaces that resemble those of the original data\ndistribution. We also introduce several other improvements, including a simple,\nyet effective cluster-wise scaling technique that captures multiple feature\nmodes without affecting data dimensionality. The exhaustive evaluation of\nctdGAN with 14 imbalanced datasets demonstrated its superiority in generating\nhigh fidelity samples and improving classification accuracy.", "AI": {"tldr": "ctdGAN\uc740 \ubd88\uade0\ud615 \ud14c\uc774\ube14 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud074\ub798\uc2a4 \ubd88\uade0\ud615\uc744 \ud574\uacb0\ud558\uae30 \uc704\ud55c \uc870\uac74\ubd80 GAN \ubaa8\ub378\ub85c, \ub370\uc774\ud130 \uc0dd\uc131\uc758 \ub85c\ucf00\uc774\uc158\uc744 \ucd5c\uc801\ud654\ud558\uace0 \ud074\ub798\uc2a4 \ub77c\ubca8\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ud65c\uc6a9\ud55c\ub2e4.", "motivation": "\uae30\uacc4 \ud559\uc2b5 \uc791\uc5c5\uc5d0\uc11c \ud074\ub798\uc2a4 \ubd88\uade0\ud615\uc73c\ub85c \uc778\ud55c \uc131\ub2a5 \uc800\ud558 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 \ub354 \ub098\uc740 \ub370\uc774\ud130 \uc0dd\uc131 \ubc29\ubc95\uc774 \ud544\uc694\ud558\ub2e4.", "method": "ctdGAN\uc740 \uc785\ub825 \uc0d8\ud50c\uc5d0 \ud074\ub7ec\uc2a4\ud130 \ub77c\ubca8\uc744 \ubd80\uc5ec\ud55c \ud6c4, \uc0c8\ub85c\uc6b4 \ud655\ub960\uc801 \uc0d8\ud50c\ub9c1 \uc804\ub7b5\uacfc \uc190\uc2e4 \ud568\uc218\ub97c \ud1b5\ud574 \ub370\uc774\ud130 \ud558\uc704 \uacf5\uac04\uc5d0\uc11c \uc0d8\ud50c\uc744 \uc0dd\uc131\ud55c\ub2e4.", "result": "14\uac1c\uc758 \ubd88\uade0\ud615 \ub370\uc774\ud130\uc14b\uc5d0\uc11c ctdGAN\uc740 \ub192\uc740 \ud488\uc9c8\uc758 \uc0d8\ud50c\uc744 \uc0dd\uc131\ud558\uace0 \ubd84\ub958 \uc815\ud655\ub3c4\ub97c \uac1c\uc120\ud558\uc600\ub2e4.", "conclusion": "ctdGAN\uc740 \uae30\uc874 GAN \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \ub354 \ud6a8\uacfc\uc801\uc73c\ub85c \ud074\ub798\uc2a4 \ubd88\uade0\ud615 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uba70, \ub370\uc774\ud130\uc758 \uc6d0\ub798 \ubd84\ud3ec\uc640 \uc720\uc0ac\ud55c \uc0d8\ud50c\uc744 \uc0dd\uc131\ud55c\ub2e4."}}
{"id": "2508.00507", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00507", "abs": "https://arxiv.org/abs/2508.00507", "authors": ["Yiming Xu", "Jiarun Chen", "Zhen Peng", "Zihan Chen", "Qika Lin", "Lan Ma", "Bin Shi", "Bo Dong"], "title": "Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection", "comment": "Accepted by ACM Multimedia 2025 (MM '25)", "summary": "The natural combination of intricate topological structures and rich textual\ninformation in text-attributed graphs (TAGs) opens up a novel perspective for\ngraph anomaly detection (GAD). However, existing GAD methods primarily focus on\ndesigning complex optimization objectives within the graph domain, overlooking\nthe complementary value of the textual modality, whose features are often\nencoded by shallow embedding techniques, such as bag-of-words or skip-gram, so\nthat semantic context related to anomalies may be missed. To unleash the\nenormous potential of textual modality, large language models (LLMs) have\nemerged as promising alternatives due to their strong semantic understanding\nand reasoning capabilities. Nevertheless, their application to TAG anomaly\ndetection remains nascent, and they struggle to encode high-order structural\ninformation inherent in graphs due to input length constraints. For\nhigh-quality anomaly detection in TAGs, we propose CoLL, a novel framework that\ncombines LLMs and graph neural networks (GNNs) to leverage their complementary\nstrengths. CoLL employs multi-LLM collaboration for evidence-augmented\ngeneration to capture anomaly-relevant contexts while delivering human-readable\nrationales for detected anomalies. Moreover, CoLL integrates a GNN equipped\nwith a gating mechanism to adaptively fuse textual features with evidence while\npreserving high-order topological information. Extensive experiments\ndemonstrate the superiority of CoLL, achieving an average improvement of 13.37%\nin AP. This study opens a new avenue for incorporating LLMs in advancing GAD.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc5d0\uc11c\ub294 \ud14d\uc2a4\ud2b8 \uc18d\uc131 \uadf8\ub798\ud504\uc5d0\uc11c\uc758 \uc774\uc0c1 \ud0d0\uc9c0\ub97c \uc704\ud55c CoLL\ub77c\ub294 \uc0c8\ub85c\uc6b4 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uc548\ud558\uba70, \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378\uacfc \uadf8\ub798\ud504 \uc2e0\uacbd\ub9dd\uc744 \uacb0\ud569\ud558\uc5ec \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "motivation": "\ud14d\uc2a4\ud2b8 \uc18d\uc131 \uadf8\ub798\ud504\uc5d0\uc11c\uc758 \uc774\uc0c1 \ud0d0\uc9c0\uc5d0\uc11c \ud14d\uc2a4\ud2b8 \ubaa8\ub2ec\ub9ac\ud2f0\uc758 \uac00\uce58\ub97c \ubb34\uc2dc\ud558\ub294 \uae30\uc874 \ubc29\ubc95\uc758 \ud55c\uacc4\ub97c \uadf9\ubcf5\ud558\uace0, \uc774\uc0c1\uacfc \uad00\ub828\ub41c \ub9e5\ub77d\uc744 \ud3ec\ucc29\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.", "method": "CoLL \ud504\ub808\uc784\uc6cc\ud06c\ub294 \uba40\ud2f0-LM \ud611\uc5c5\uc744 \ud1b5\ud574 \uc99d\uac70\ubcf4\uac15 \uc0dd\uc131\uc744 \uc218\ud589\ud558\uace0, \uadf8\ub798\ud504 \uc2e0\uacbd\ub9dd\uacfc \uac8c\uc774\ud305 \uba54\ucee4\ub2c8\uc998\uc744 \uacb0\ud569\ud558\uc5ec \ud14d\uc2a4\ud2b8 \ud2b9\uc9d5\uacfc \uc99d\uac70\ub97c \uc801\uc751\uc801\uc73c\ub85c \uc735\ud569\ud569\ub2c8\ub2e4.", "result": "CoLL\uc740 \ud3c9\uade0 13.37%\uc758 AP \ud5a5\uc0c1 \uc131\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uc5b4 \uae30\uc874 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \uc6b0\uc218\ud568\uc744 \uc785\uc99d\ud588\uc2b5\ub2c8\ub2e4.", "conclusion": "\uc774 \uc5f0\uad6c\ub294 \uc774\uc0c1 \ud0d0\uc9c0\uc5d0 \ub300\ud55c \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc801\uc6a9 \uac00\ub2a5\uc131\uc744 \ub113\ud788\uace0, \uadf8\ub798\ud504 \uc774\uc0c1 \ud0d0\uc9c0 \ubd84\uc57c\uc5d0\uc11c\uc758 \uc0c8\ub85c\uc6b4 \uc811\uadfc \ubc29\uc2dd\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4."}}
{"id": "2508.00513", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00513", "abs": "https://arxiv.org/abs/2508.00513", "authors": ["Yiming Xu", "Xu Hua", "Zhen Peng", "Bin Shi", "Jiarun Chen", "Xingbo Fu", "Song Wang", "Bo Dong"], "title": "Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning", "comment": "Accepted by ECAI 2025", "summary": "The widespread application of graph data in various high-risk scenarios has\nincreased attention to graph anomaly detection (GAD). Faced with real-world\ngraphs that often carry node descriptions in the form of raw text sequences,\ntermed text-attributed graphs (TAGs), existing graph anomaly detection\npipelines typically involve shallow embedding techniques to encode such textual\ninformation into features, and then rely on complex self-supervised tasks\nwithin the graph domain to detect anomalies. However, this text encoding\nprocess is separated from the anomaly detection training objective in the graph\ndomain, making it difficult to ensure that the extracted textual features focus\non GAD-relevant information, seriously constraining the detection capability.\nHow to seamlessly integrate raw text and graph topology to unleash the vast\npotential of cross-modal data in TAGs for anomaly detection poses a challenging\nissue. This paper presents a novel end-to-end paradigm for text-attributed\ngraph anomaly detection, named CMUCL. We simultaneously model data from both\ntext and graph structures, and jointly train text and graph encoders by\nleveraging cross-modal and uni-modal multi-scale consistency to uncover\npotential anomaly-related information. Accordingly, we design an anomaly score\nestimator based on inconsistency mining to derive node-specific anomaly scores.\nConsidering the lack of benchmark datasets tailored for anomaly detection on\nTAGs, we release 8 datasets to facilitate future research. Extensive\nevaluations show that CMUCL significantly advances in text-attributed graph\nanomaly detection, delivering an 11.13% increase in average accuracy (AP) over\nthe suboptimal.", "AI": {"tldr": "\ubcf8 \uc5f0\uad6c\ub294 \ud14d\uc2a4\ud2b8 \uc18d\uc131\uc744 \uac00\uc9c4 \uadf8\ub798\ud504\uc758 \uc774\uc0c1 \ud0d0\uc9c0\ub97c \uc704\ud55c \uc0c8\ub85c\uc6b4 \uc885\ub2e8 \uac04 \uc811\uadfc \ubc29\uc2dd\uc778 CMUCL\uc744 \uc81c\uc548\ud55c\ub2e4.", "motivation": "\uc2e4\uc81c \uadf8\ub798\ud504\ub294 \uc885\uc885 \uc6d0\uc2dc \ud14d\uc2a4\ud2b8 \uc2dc\ud000\uc2a4\ub85c \ub41c \ub178\ub4dc \uc124\uba85\uc744 \uac00\uc9c0\uace0 \uc788\uc5b4, \uc774\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud65c\uc6a9\ud558\ub294 \uc774\uc0c1 \ud0d0\uc9c0 \uae30\ubc95\uc774 \ud544\uc694\ud558\ub2e4.", "method": "\ud14d\uc2a4\ud2b8\uc640 \uadf8\ub798\ud504 \uad6c\uc870\ub85c\ubd80\ud130 \ub370\uc774\ud130\ub97c \ub3d9\uc2dc\uc5d0 \ubaa8\ub378\ub9c1\ud558\uace0, \ud06c\ub85c\uc2a4 \ubaa8\ub2ec \ubc0f \uc720\ub2c8 \ubaa8\ub2ec \uc77c\uad00\uc131\uc744 \ud65c\uc6a9\ud558\uc5ec \ud14d\uc2a4\ud2b8 \ubc0f \uadf8\ub798\ud504 \uc778\ucf54\ub354\ub97c \uacf5\ub3d9\uc73c\ub85c \ud6c8\ub828\ud55c\ub2e4.", "result": "CMUCL\uc740 \ud14d\uc2a4\ud2b8 \uc18d\uc131 \uadf8\ub798\ud504 \uc774\uc0c1 \ud0d0\uc9c0\uc5d0\uc11c \ud3c9\uade0 \uc815\ud655\ub3c4\ub97c 11.13% \ud5a5\uc0c1\uc2dc\ud0a4\uba70 \uc131\ub2a5\uc744 \ud06c\uac8c \uac1c\uc120\ud55c\ub2e4.", "conclusion": "CMUCL\uc740 \ud14d\uc2a4\ud2b8 \uc18d\uc131 \uadf8\ub798\ud504\uc758 \uc774\uc0c1 \ud0d0\uc9c0\uc5d0 \uc788\uc5b4 \ud6a8\uacfc\uc801\uc778 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud558\uba70, \ud5a5\ud6c4 \uc5f0\uad6c\ub97c \uc704\ud55c 8\uac1c\uc758 \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\ub3c4 \uacf5\uac1c\ud558\uc600\ub2e4."}}
{"id": "2508.00523", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00523", "abs": "https://arxiv.org/abs/2508.00523", "authors": ["Sifan Yang", "Yuanyu Wan", "Lijun Zhang"], "title": "Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting", "comment": null, "summary": "We investigate the online nonsubmodular optimization with delayed feedback in\nthe bandit setting, where the loss function is $\\alpha$-weakly DR-submodular\nand $\\beta$-weakly DR-supermodular. Previous work has established an\n$(\\alpha,\\beta)$-regret bound of $\\mathcal{O}(nd^{1/3}T^{2/3})$, where $n$ is\nthe dimensionality and $d$ is the maximum delay. However, its regret bound\nrelies on the maximum delay and is thus sensitive to irregular delays.\nAdditionally, it couples the effects of delays and bandit feedback as its bound\nis the product of the delay term and the $\\mathcal{O}(nT^{2/3})$ regret bound\nin the bandit setting without delayed feedback. In this paper, we develop two\nalgorithms to address these limitations, respectively. Firstly, we propose a\nnovel method, namely DBGD-NF, which employs the one-point gradient estimator\nand utilizes all the available estimated gradients in each round to update the\ndecision. It achieves a better $\\mathcal{O}(n\\bar{d}^{1/3}T^{2/3})$ regret\nbound, which is relevant to the average delay $\\bar{d} =\n\\frac{1}{T}\\sum_{t=1}^T d_t\\leq d$. Secondly, we extend DBGD-NF by employing a\nblocking update mechanism to decouple the joint effect of the delays and bandit\nfeedback, which enjoys an $\\mathcal{O}(n(T^{2/3} + \\sqrt{dT}))$ regret bound.\nWhen $d = \\mathcal{O}(T^{1/3})$, our regret bound matches the\n$\\mathcal{O}(nT^{2/3})$ bound in the bandit setting without delayed feedback.\nCompared to our first $\\mathcal{O}(n\\bar{d}^{1/3}T^{2/3})$ bound, it is more\nadvantageous when the maximum delay $d = o(\\bar{d}^{2/3}T^{1/3})$. Finally, we\nconduct experiments on structured sparse learning to demonstrate the\nsuperiority of our methods.", "AI": {"tldr": "\uc628\ub77c\uc778 \ube44\uc11c\ube0c\ubaa8\ub4c8 \ucd5c\uc801\ud654\uc5d0\uc11c \uc9c0\uc5f0 \ud53c\ub4dc\ubc31\uc744 \ub2e4\ub8ec\ub2e4.", "motivation": "\uc774 \ub17c\ubb38\uc740 \uc9c0\uc5f0\uc5d0 \ubbfc\uac10\ud55c \uae30\uc874\uc758 \ud6c4\ud68c \uacbd\uacc4 \ud55c\uacc4\ub97c \uac1c\uc120\ud558\uae30 \uc704\ud574\uc11c\uc774\ub2e4.", "method": "\ub450 \uac00\uc9c0 \uc54c\uace0\ub9ac\uc998(DBGD-NF\uc640 \ube14\ub85c\ud0b9 \uc5c5\ub370\uc774\ud2b8 \uba54\ucee4\ub2c8\uc998)\uc744 \uac1c\ubc1c\ud558\uc5ec \uc9c0\uc5f0\uacfc \ubc34\ub527 \ud53c\ub4dc\ubc31\uc758 \uc601\ud5a5\uc744 \ubd84\ub9ac\ud558\uace0 \ud3c9\uade0 \uc9c0\uc5f0\uc744 \ubc14\ud0d5\uc73c\ub85c \uac1c\uc120\ub41c \ud6c4\ud68c \uacbd\uacc4\ub97c \uc124\uc815\ud55c\ub2e4.", "result": "\uccab \ubc88\uc9f8 \ubc29\ubc95\uc740 $\beta$-\uc57d\ud55c DR-\uc288\ud37c\ubaa8\ub4c8\ub7ec \ubc0f $\beta$-\uc57d\ud55c DR-\uc11c\ube0c\ubaa8\ub4c8\ub7ec\uc5d0 \ub300\ud55c \ud5a5\uc0c1\ub41c \ud6c4\ud68c \uacbd\uacc4\ub97c \uc81c\uacf5\ud55c\ub2e4.", "conclusion": "\uc81c\uc548\ud558\ub294 \ubc29\ubc95\uc774 \uad6c\uc870\uc801 \ud76c\uc18c \ud559\uc2b5\uc5d0\uc11c \uc131\ub2a5\uc774 \uc6b0\uc218\ud568\uc744 \uc2e4\ud5d8\uc73c\ub85c \uc785\uc99d\ud558\uc600\ub2e4."}}
{"id": "2508.00539", "categories": ["cs.LG", "Cs"], "pdf": "https://arxiv.org/pdf/2508.00539", "abs": "https://arxiv.org/abs/2508.00539", "authors": ["Judy X Yang"], "title": "Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery", "comment": "8 pages, 6 figures", "summary": "Hyperspectral imaging offers detailed spectral information for mineral\nmapping; however, weak mineral signatures are often masked by noisy and\nredundant bands, limiting detection performance. To address this, we propose a\ntwo-stage integrated framework for enhanced mineral detection in the Cuprite\nmining district. In the first stage, we compute the signal-to-noise ratio (SNR)\nfor each spectral band and apply a phase-locked thresholding technique to\ndiscard low-SNR bands, effectively removing redundancy and suppressing\nbackground noise. Savitzky-Golay filtering is then employed for spectral\nsmoothing, serving a dual role first to stabilize trends during band selection,\nand second to preserve fine-grained spectral features during preprocessing. In\nthe second stage, the refined HSI data is reintroduced into the model, where\nKMeans clustering is used to extract 12 endmember spectra (W1 custom), followed\nby non negative least squares (NNLS) for abundance unmixing. The resulting\nendmembers are quantitatively compared with laboratory spectra (W1 raw) using\ncosine similarity and RMSE metrics. Experimental results confirm that our\nproposed pipeline improves unmixing accuracy and enhances the detection of weak\nmineral zones. This two-pass strategy demonstrates a practical and reproducible\nsolution for spectral dimensionality reduction and unmixing in geological HSI\napplications.", "AI": {"tldr": "\uc774 \uc5f0\uad6c\ub294 Cuprite \uad11\uc0b0 \uc9c0\uc5ed\uc5d0\uc11c \uc57d\ud55c \uad11\ubb3c \ud0d0\uc9c0\ub97c \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud55c \ub450 \ub2e8\uacc4 \ud1b5\ud569 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uc548\ud55c\ub2e4.", "motivation": "\uad11\ubb3c \ub9e4\ud551\uc744 \uc704\ud55c \uace0\ud574\uc0c1\ub3c4 \uc2a4\ud399\ud2b8\ub7fc \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\ub294 \ud558\uc774\ud37c\uc2a4\ud399\ud2b8\ub7fc \uc774\ubbf8\uc9d5\uc758 \uc131\ub2a5\uc774 \uc800\uc870\ud55c \uc2a4\ud399\ud2b8\ub7fc \ub178\uc774\uc988\uc640 \uc911\ubcf5\uc73c\ub85c \uc81c\ud55c\ub418\uae30 \ub54c\ubb38\uc5d0, \uc774\ub97c \uac1c\uc120\ud558\ub824\ub294 \ud544\uc694\uc131\uc774 \uc788\ub2e4.", "method": "\uccab \ub2e8\uacc4\uc5d0\uc11c \uac01 \uc2a4\ud399\ud2b8\ub7fc \ubc34\ub4dc\uc758 \uc2e0\ud638\ub300\uc7a1\uc74c\ube44(SNR)\ub97c \uacc4\uc0b0\ud558\uace0 \ub0ae\uc740 SNR \ubc34\ub4dc\ub97c \uc81c\uac70\ud558\uc5ec \uc2a4\ud399\ud2b8\ub7fc\uc744 \uc815\uc81c\ud55c \ud6c4, \ub450 \ubc88\uc9f8 \ub2e8\uacc4\uc5d0\uc11c\ub294 KMeans \ud074\ub7ec\uc2a4\ud130\ub9c1\uacfc \ube44\uc74c\uc218 \ucd5c\uc18c\uc81c\uacf1(NNLS) \uae30\ubc95\uc744 \uc774\uc6a9\ud574 \ud63c\ud569\ubb3c\uc758 \uad00\uce21\uac12\uc744 \ucd94\ucd9c\ud55c\ub2e4.", "result": "\uc2e4\ud5d8 \uacb0\uacfc, \uc81c\uc548\ub41c \ud30c\uc774\ud504\ub77c\uc778\uc774 \ud63c\ud569 \ubd84\uc11d\uc758 \uc815\ud655\uc131\uc744 \uac1c\uc120\ud558\uace0 \uc57d\ud55c \uad11\ubb3c \uad6c\uc5ed\uc758 \ud0d0\uc9c0\ub97c \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4\ub294 \uac83\uc774 \uc785\uc99d\ub418\uc5c8\ub2e4.", "conclusion": "\uc774 \ub450 \ub2e8\uacc4 \uc811\uadfc \ubc29\uc2dd\uc740 \uc9c0\uc9c8\ud559\uc801 HSI \uc751\uc6a9\uc5d0\uc11c \uc2a4\ud399\ud2b8\ub7fc \ucc28\uc6d0 \ucd95\uc18c \ubc0f \ubd84\ub9ac\uac00 \uac00\ub2a5\ud55c \uc2e4\uc6a9\uc801\uc774\uba70 \uc7ac\ud604 \uac00\ub2a5\ud55c \uc194\ub8e8\uc158\uc744 \uc81c\uc2dc\ud55c\ub2e4."}}
{"id": "2508.00545", "categories": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.00545", "abs": "https://arxiv.org/abs/2508.00545", "authors": ["Pietro Barbiero", "Mateo Espinosa Zarlenga", "Alberto Termine", "Mateja Jamnik", "Giuseppe Marra"], "title": "Foundations of Interpretable Models", "comment": null, "summary": "We argue that existing definitions of interpretability are not actionable in\nthat they fail to inform users about general, sound, and robust interpretable\nmodel design. This makes current interpretability research fundamentally\nill-posed. To address this issue, we propose a definition of interpretability\nthat is general, simple, and subsumes existing informal notions within the\ninterpretable AI community. We show that our definition is actionable, as it\ndirectly reveals the foundational properties, underlying assumptions,\nprinciples, data structures, and architectural features necessary for designing\ninterpretable models. Building on this, we propose a general blueprint for\ndesigning interpretable models and introduce the first open-sourced library\nwith native support for interpretable data structures and processes.", "AI": {"tldr": "\uae30\uc874\uc758 \ud574\uc11d \uac00\ub2a5\uc131 \uc815\uc758\uac00 \uc2e4\uc6a9\uc801\uc774\uc9c0 \uc54a\uc74c\uc744 \uc8fc\uc7a5\ud558\uba70, \uc0c8\ub85c\uc6b4 \ud574\uc11d \uac00\ub2a5\uc131 \uc815\uc758\ub97c \uc81c\uc548\ud558\uace0 \uc774\ub97c \uad6c\ud604\ud558\uae30 \uc704\ud55c \ube14\ub8e8\ud504\ub9b0\ud2b8\uc640 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc18c\uac1c\ud55c\ub2e4.", "motivation": "\uae30\uc874 \ud574\uc11d \uac00\ub2a5\uc131 \uc5f0\uad6c\uac00 \uc0ac\uc6a9\uc790\uc758 \uc694\uad6c\ub97c \ucda9\uc871\ud558\uc9c0 \ubabb\ud574 \uc2e4\uc9c8\uc801\uc774\uc9c0 \uc54a\uc74c\uc744 \ud574\uc18c\ud558\uace0\uc790 \ud55c\ub2e4.", "method": "\ud574\uc11d \uac00\ub2a5\uc131\uc758 \uc0c8\ub85c\uc6b4 \uc815\uc758\ub97c \uc81c\uc548\ud558\uace0, \uc774\ub97c \ucda9\uc871\ud558\uae30 \uc704\ud55c \uc124\uacc4 \uc6d0\uce59 \ubc0f \ub370\uc774\ud130 \uad6c\uc870\ub97c \uba85\uc2dc\ud55c\ub2e4.", "result": "\uc81c\uc548\ud55c \uc815\uc758\uac00 \uc2e4\uc6a9\uc801\uc774\uba70, \ud574\uc11d \uac00\ub2a5\ud55c \ubaa8\ub378 \uc124\uacc4\ub97c \uc704\ud55c \uae30\ucd08\uc801\uc778 \uc18d\uc131\uacfc \uc6d0\ub9ac\ub97c \ub4dc\ub7ec\ub0b8\ub2e4.", "conclusion": "\ud574\uc11d \uac00\ub2a5\ud55c \ubaa8\ub378 \uc124\uacc4\ub97c \uc704\ud55c \uc77c\ubc18\uc801\uc778 \ube14\ub8e8\ud504\ub9b0\ud2b8\ub97c \uc81c\uc2dc\ud558\uace0, \uc774\ub97c \uc9c0\uc6d0\ud558\ub294 \uc624\ud508 \uc18c\uc2a4 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \ucc98\uc74c\uc73c\ub85c \uc18c\uac1c\ud55c\ub2e4."}}
{"id": "2508.00578", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2508.00578", "abs": "https://arxiv.org/abs/2508.00578", "authors": ["Marlen Neubert", "Patrick Reiser", "Frauke Gr\u00e4ter", "Pascal Friederich"], "title": "Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides", "comment": "19 pages, 12 figures, and 4 tables (references and SI included)", "summary": "Hydrogen atom transfer (HAT) reactions are essential in many biological\nprocesses, such as radical migration in damaged proteins, but their mechanistic\npathways remain incompletely understood. Simulating HAT is challenging due to\nthe need for quantum chemical accuracy at biologically relevant scales; thus,\nneither classical force fields nor DFT-based molecular dynamics are applicable.\nMachine-learned potentials offer an alternative, able to learn potential energy\nsurfaces (PESs) with near-quantum accuracy. However, training these models to\ngeneralize across diverse HAT configurations, especially at radical positions\nin proteins, requires tailored data generation and careful model selection.\nHere, we systematically generate HAT configurations in peptides to build large\ndatasets using semiempirical methods and DFT. We benchmark three graph neural\nnetwork architectures (SchNet, Allegro, and MACE) on their ability to learn HAT\nPESs and indirectly predict reaction barriers from energy predictions. MACE\nconsistently outperforms the others in energy, force, and barrier prediction,\nachieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT\nbarrier predictions. This accuracy enables integration of ML potentials into\nlarge-scale collagen simulations to compute reaction rates from predicted\nbarriers, advancing mechanistic understanding of HAT and radical migration in\npeptides. We analyze scaling laws, model transferability, and cost-performance\ntrade-offs, and outline strategies for improvement by combining ML potentials\nwith transition state search algorithms and active learning. Our approach is\ngeneralizable to other biomolecular systems, enabling quantum-accurate\nsimulations of chemical reactivity in complex environments.", "AI": {"tldr": "\ubcf8 \uc5f0\uad6c\ub294 \uc218\uc18c \uc6d0\uc790 \uc774\ub3d9(HAT) \ubc18\uc751\uc744 \uc815\ud655\ud558\uac8c \ubaa8\uc0ac\ud558\uae30 \uc704\ud55c \uae30\uacc4 \ud559\uc2b5 \uae30\ubc18 \ud3ec\ud150\uc15c\uc744 \uac1c\ubc1c\ud558\uace0, \ub2e4\uc591\ud55c HAT \uad6c\uc131\uc5d0\uc11c\uc758 \ubaa8\ub378 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uc5ec, \uace0\uae09 \ubd84\uc790 \uc2dc\ubbac\ub808\uc774\uc158\uc744 \uac00\ub2a5\ud558\uac8c \ud55c\ub2e4.", "motivation": "HAT \ubc18\uc751\uc740 \uc0dd\ubb3c\ud559\uc801 \uacfc\uc815\uc5d0\uc11c \uc911\uc694\ud558\uc9c0\ub9cc \uadf8 \uba54\ucee4\ub2c8\uc998\uc740 \ubd88\uc644\uc804\ud558\uac8c \uc774\ud574\ub418\uace0 \uc788\ub2e4.", "method": "HAT \uad6c\uc131 \uc0dd\uc131\uc744 \uc704\ud574 \ubc18\uc751\uc131 \ub370\uc774\ud130\uc138\ud2b8\ub97c \uad6c\ucd95\ud558\uace0, \uc138 \uac00\uc9c0 \uadf8\ub798\ud504 \uc2e0\uacbd\ub9dd \uc544\ud0a4\ud14d\ucc98(SchNet, Allegro, MACE)\ub97c \ud3c9\uac00\ud558\uc5ec HAT \ud3ec\ud150\uc15c \uc5d0\ub108\uc9c0 \ud45c\uba74(PES)\uc744 \ud559\uc2b5\ud55c\ub2e4.", "result": "MACE \ubaa8\ub378\uc774 \uc5d0\ub108\uc9c0, \ud798 \ubc0f \uc7a5\ubcbd \uc608\uce21\uc5d0\uc11c \uc9c0\uc18d\uc801\uc73c\ub85c \ucd5c\uace0 \uc131\ub2a5\uc744 \ubcf4\uc774\uba70, \ud3c9\uade0 \uc808\ub300 \uc624\ucc28\uac00 1.13 kcal/mol\ub85c \uc0c1\uc138\ud55c \uc608\uce21\uc744 \uc81c\uacf5\ud55c\ub2e4.", "conclusion": "\uc774 \uc815\ud655\ub3c4\ub97c \ud1b5\ud574 ML \ud3ec\ud150\uc15c\uc744 \ub300\uaddc\ubaa8 \ucf5c\ub77c\uac90 \uc2dc\ubbac\ub808\uc774\uc158\uc5d0 \ud1b5\ud569 \uac00\ub2a5\ud558\uba70, HAT \ubc0f \ud3a9\ud0c0\uc774\ub4dc\uc5d0\uc11c\uc758 \ud654\ud559 \ubc18\uc751\uc131\uc5d0 \ub300\ud55c \uc591\uc790 \uc815\ud655\ud55c \uc2dc\ubbac\ub808\uc774\uc158\uc744 \uac00\ub2a5\ud558\uac8c \ud55c\ub2e4."}}
{"id": "2508.00586", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00586", "abs": "https://arxiv.org/abs/2508.00586", "authors": ["Thorben Werner", "Lars Schmidt-Thieme", "Vijaya Krishna Yalavarthi"], "title": "The Role of Active Learning in Modern Machine Learning", "comment": null, "summary": "Even though Active Learning (AL) is widely studied, it is rarely applied in\ncontexts outside its own scientific literature. We posit that the reason for\nthis is AL's high computational cost coupled with the comparatively small lifts\nit is typically able to generate in scenarios with few labeled points. In this\nwork we study the impact of different methods to combat this low data scenario,\nnamely data augmentation (DA), semi-supervised learning (SSL) and AL. We find\nthat AL is by far the least efficient method of solving the low data problem,\ngenerating a lift of only 1-4\\% over random sampling, while DA and SSL methods\ncan generate up to 60\\% lift in combination with random sampling. However, when\nAL is combined with strong DA and SSL techniques, it surprisingly is still able\nto provide improvements. Based on these results, we frame AL not as a method to\ncombat missing labels, but as the final building block to squeeze the last bits\nof performance out of data after appropriate DA and SSL methods as been\napplied.", "AI": {"tldr": "\ud65c\uc131 \ud559\uc2b5(AL)\uc740 \ub192\uc740 \uacc4\uc0b0 \ube44\uc6a9\uacfc \uc801\uc740 \ub808\uc774\ube14 \ud3ec\uc778\ud2b8\uc5d0\uc11c\uc758 \ud6a8\uc728\uc131 \ubd80\uc871\uc73c\ub85c \uc778\ud574 \uc801\uc6a9\uc774 \uc81c\ud55c\ub41c\ub2e4. \ud558\uc9c0\ub9cc, \uac15\ub825\ud55c \ub370\uc774\ud130 \uc99d\ub300(DA) \ubc0f \ubc18 \uac10\ub3c5 \ud559\uc2b5(SSL)\uacfc \uacb0\ud569\ud560 \uacbd\uc6b0 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uac00\uc838\uc62c \uc218 \uc788\ub2e4.", "motivation": "AL\uc758 \uc5f0\uad6c\uac00 \ud65c\ubc1c\ud558\uc9c0\ub9cc \uc2e4\uc81c \uc751\uc6a9\uc774 \ub4dc\ubb38 \uc774\uc720\ub294 \ub192\uc740 \uacc4\uc0b0 \ube44\uc6a9\uacfc \uc801\uc740 \ub808\uc774\ube14 \ud3ec\uc778\ud2b8\uc5d0\uc11c\uc758 \ub0ae\uc740 \ud6a8\uc728\uc131\uc5d0 \uc788\ub2e4.", "method": "\ub370\uc774\ud130 \uc99d\ub300(DA), \ubc18 \uac10\ub3c5 \ud559\uc2b5(SSL), \ud65c\uc131 \ud559\uc2b5(AL)\uc758 \ub2e4\uc591\ud55c \ubc29\ubc95\uc744 \ube44\uad50\ud558\uace0 \uc870\ud569\ud558\uc5ec \uc800\ub370\uc774\ud130 \ubb38\uc81c \ud574\uacb0 \ud6a8\uc728\uc131\uc744 \ubd84\uc11d\ud558\uc600\ub2e4.", "result": "AL\uc740 \ubb34\uc791\uc704 \uc0d8\ud50c\ub9c1 \ub300\ube44 1-4% \ud5a5\uc0c1\uc5d0 \uadf8\uce58\ub294 \ube44\ud6a8\uc728\uc801\uc778 \ubc29\ubc95\uc774\uba70, DA\uc640 SSL \ubc29\ubc95\uc740 \ucd5c\ub300 60% \ud5a5\uc0c1 \uac00\ub2a5\ud558\ub2e4. \uadf8\ub7ec\ub098 \uac15\ub825\ud55c DA \ubc0f SSL \uae30\ubc95\uacfc \uacb0\ud569\ud560 \uacbd\uc6b0 AL\ub3c4 \ud5a5\uc0c1\uc744 \uc81c\uacf5\ud55c\ub2e4.", "conclusion": "AL\uc740 \uacb0\uce21 \ub808\uc774\ube14\uc744 \ud574\uacb0\ud558\ub294 \ubc29\ubc95\uc774 \uc544\ub2c8\ub77c, \uc801\uc808\ud55c DA \ubc0f SSL \ubc29\ubc95\uc744 \uc801\uc6a9\ud55c \ud6c4 \ucd5c\uc885 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc704\ud55c \ub9c8\uc9c0\ub9c9 \ubcf4\uac15 \uc694\uc18c\ub85c \ubcf4\uc544\uc57c \ud55c\ub2e4."}}
{"id": "2508.00615", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00615", "abs": "https://arxiv.org/abs/2508.00615", "authors": ["Mukesh Kumar Sahu", "Pinki Roy"], "title": "Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data", "comment": null, "summary": "Accurately predicting the criticalness of ICU patients (such as in-ICU\nmortality risk) is vital for early intervention in critical care. However,\nconventional models often treat each patient in isolation and struggle to\nexploit the relational structure in Electronic Health Records (EHR). We propose\na Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds\na patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN\narchitecture that operates on this graph to predict patient mortality and a\ncontinuous criticalness score. SBSCGM uses a hybrid similarity measure\n(combining feature-based and structural similarities) to connect patients with\nanalogous clinical profiles in real-time. The HybridGraphMedGNN integrates\nGraph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)\nlayers to learn robust patient representations, leveraging both local and\nglobal graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III\ndataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)\noutperforming baseline classifiers and single-type GNN models. We also\ndemonstrate improved precision/recall and show that the attention mechanism\nprovides interpretable insights into model predictions. Our framework offers a\nscalable and interpretable solution for critical care risk prediction, with\npotential to support clinicians in real-world ICU deployment.", "AI": {"tldr": "ICU \ud658\uc790\uc758 \uc911\uc99d\ub3c4\ub97c \uc815\ud655\ud558\uac8c \uc608\uce21\ud558\uae30 \uc704\ud55c SBSCGM \ubaa8\ub378\uacfc HybridGraphMedGNN \uc544\ud0a4\ud14d\ucc98\ub97c \uc81c\uc548\ud558\uc5ec \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0b4.", "motivation": "ICU \ud658\uc790\uc758 \uc0ac\ub9dd \uc704\ud5d8\uc744 \uc870\uae30\uc5d0 \ud30c\uc545\ud558\uc5ec \uc2e0\uc18d\ud55c \uac1c\uc785\uc774 \ud544\uc694\ud568.", "method": "\ub2e4\uc591\ud55c EHR \ub370\uc774\ud130\ub97c \uae30\ubc18\uc73c\ub85c \ud658\uc790 \uc720\uc0ac\uc131 \uadf8\ub798\ud504\ub97c \ub3d9\uc801\uc73c\ub85c \uad6c\ucd95\ud558\uace0, \uc774\ub97c \ud1b5\ud574 \ud658\uc790 \uc0ac\ub9dd \ubc0f \uc911\uc99d\ub3c4 \uc810\uc218\ub97c \uc608\uce21\ud558\ub294 SBSCGM \ubaa8\ub378\uacfc HybridGraphMedGNN \uc544\ud0a4\ud14d\ucc98\ub97c \uc0ac\uc6a9\ud568.", "result": "MIMIC-III \ub370\uc774\ud130\uc14b\uc5d0\uc11c 6,000\uac74\uc758 ICU \uc0ac\ub840\ub97c \uc2e4\ud5d8\ud558\uc5ec AUC-ROC 0.94\ub97c \ub2ec\uc131\ud558\uba70, \uae30\uc874 \ubd84\ub958\uae30 \ubc0f \ub2e8\uc77c GNN \ubaa8\ub378\ubcf4\ub2e4 \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc784.", "conclusion": "\uc774 \ud504\ub808\uc784\uc6cc\ud06c\ub294 \ucd08\uac04\ub2e8\ud55c \ud574\uc11d \uac00\ub2a5\uc131\uacfc \ud655\uc7a5\uc131\uc744 \uc81c\uacf5\ud558\uc5ec \uc784\uc0c1\uc5d0\uc11c\uc758 \uc704\ud5d8 \uc608\uce21\uc5d0 \ub3c4\uc6c0\uc744 \uc904 \uc218 \uc788\uc74c."}}
{"id": "2508.00627", "categories": ["cs.LG", "I.4.9; I.4.6"], "pdf": "https://arxiv.org/pdf/2508.00627", "abs": "https://arxiv.org/abs/2508.00627", "authors": ["Paul Tresson", "Pierre Le Coz", "Hadrien Tulet", "Anthony Malkassian", "Maxime R\u00e9jou M\u00e9chain"], "title": "IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources", "comment": "11 pages, 5 figures", "summary": "Remote sensing has entered a new era with the rapid development of artificial\nintelligence approaches. However, the implementation of deep learning has\nlargely remained restricted to specialists and has been impractical because it\noften requires (i) large reference datasets for model training and validation;\n(ii) substantial computing resources; and (iii) strong coding skills. Here, we\nintroduce IAMAP, a user-friendly QGIS plugin that addresses these three\nchallenges in an easy yet flexible way. IAMAP builds on recent advancements in\nself-supervised learning strategies, which now provide robust feature\nextractors, often referred to as foundation models. These generalist models can\noften be reliably used in few-shot or zero-shot scenarios (i.e., with little to\nno fine-tuning). IAMAP's interface allows users to streamline several key steps\nin remote sensing image analysis: (i) extracting image features using a wide\nrange of deep learning architectures; (ii) reducing dimensionality with\nbuilt-in algorithms; (iii) performing clustering on features or their reduced\nrepresentations; (iv) generating feature similarity maps; and (v) calibrating\nand validating supervised machine learning models for prediction. By enabling\nnon-AI specialists to leverage the high-quality features provided by recent\ndeep learning approaches without requiring GPU capacity or extensive reference\ndatasets, IAMAP contributes to the democratization of computationally efficient\nand energy-conscious deep learning methods.", "AI": {"tldr": "IAMAP\uc740 \ube44\uc804\ubb38\uac00\uac00 \ub525\ub7ec\ub2dd\uc744 \ud65c\uc6a9\ud560 \uc218 \uc788\ub3c4\ub85d \ub3d5\ub294 QGIS \ud50c\ub7ec\uadf8\uc778\uc774\ub2e4.", "motivation": "\ub525\ub7ec\ub2dd \uc811\uadfc\ubc95\uc758 \ud65c\uc6a9\uc774 \uc81c\ud55c\uc801\uc774\uba70 \ub9ce\uc740 \ub370\uc774\ud130\uc640 \ucef4\ud4e8\ud305 \uc790\uc6d0, \ucf54\ub529 \uae30\uc220\uc774 \ud544\uc694\ud558\ub2e4.", "method": "IAMAP\ub294 \ucd5c\uadfc\uc758 \uc790\uae30 \uac10\ub3c5 \ud559\uc2b5 \uc804\ub7b5\uc744 \ubc14\ud0d5\uc73c\ub85c \ud558\uc5ec \uc0ac\uc6a9\uc790 \uce5c\ud654\uc801\uc778 \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc81c\uacf5\ud55c\ub2e4.", "result": "IAMAP\uc740 \uc774\ubbf8\uc9c0 \ud2b9\uc9d5 \ucd94\ucd9c, \ucc28\uc6d0 \ucd95\uc18c, \ud074\ub7ec\uc2a4\ud130\ub9c1, \uc720\uc0ac\uc131 \ub9f5 \uc0dd\uc131, \uba38\uc2e0\ub7ec\ub2dd \ubaa8\ub378\uc758 \uac80\uc99d \ub4f1\uc744 \uc9c0\uc6d0\ud55c\ub2e4.", "conclusion": "IAMAP\ub294 \ube44\uc804\ubb38\uac00\ub3c4 \ud6a8\uc728\uc801\uc774\uace0 \uc5d0\ub108\uc9c0 \uc808\uc57d\uc801\uc778 \ub525\ub7ec\ub2dd \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub3c4\ub85d \uae30\uc5ec\ud55c\ub2e4."}}
{"id": "2508.00628", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00628", "abs": "https://arxiv.org/abs/2508.00628", "authors": ["Xiong Xiong", "Zhuo Zhang", "Rongchun Hu", "Chen Gao", "Zichen Deng"], "title": "Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs", "comment": null, "summary": "Solving high-frequency oscillatory partial differential equations (PDEs) is a\ncritical challenge in scientific computing, with applications in fluid\nmechanics, quantum mechanics, and electromagnetic wave propagation. Traditional\nphysics-informed neural networks (PINNs) suffer from spectral bias, limiting\ntheir ability to capture high-frequency solution components. We introduce\nSeparated-Variable Spectral Neural Networks (SV-SNN), a novel framework that\naddresses these limitations by integrating separation of variables with\nadaptive spectral methods. Our approach features three key innovations: (1)\ndecomposition of multivariate functions into univariate function products,\nenabling independent spatial and temporal networks; (2) adaptive Fourier\nspectral features with learnable frequency parameters for high-frequency\ncapture; and (3) theoretical framework based on singular value decomposition to\nquantify spectral bias. Comprehensive evaluation on benchmark problems\nincluding Heat equation, Helmholtz equation, Poisson equations and\nNavier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of\nmagnitude improvement in accuracy while reducing parameter count by over 90\\%\nand training time by 60\\%. These results establish SV-SNN as an effective\nsolution to the spectral bias problem in neural PDE solving. The implementation\nwill be made publicly available upon acceptance at\nhttps://github.com/xgxgnpu/SV-SNN.", "AI": {"tldr": "SV-SNN\uc740 \uace0\uc8fc\ud30c \uc9c4\ub3d9 \ud3b8\ubbf8\ubd84 \ubc29\uc815\uc2dd\uc758 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud55c \uc0c8\ub85c\uc6b4 \ud504\ub808\uc784\uc6cc\ud06c\ub85c, \uc804\ud1b5\uc801\uc778 \ud53c\uc9c0\uceec \uc815\ubcf4 \uc2e0\uacbd\ub9dd\uc758 \ud55c\uacc4\ub97c \uadf9\ubcf5\ud558\uc5ec \uc815\ud655\ub3c4\uc640 \ud6a8\uc728\uc131\uc744 \uac1c\uc120\ud55c\ub2e4.", "motivation": "\uace0\uc8fc\ud30c \uc9c4\ub3d9 \ud3b8\ubbf8\ubd84 \ubc29\uc815\uc2dd\uc744 \ud574\uacb0\ud558\ub294 \uac83\uc740 \uacfc\ud559 \uacc4\uc0b0\uc5d0\uc11c \uc911\uc694\ud55c \ub3c4\uc804 \uacfc\uc81c\uc774\uba70, \uc804\ud1b5\uc801\uc778 PINNs\ub294 \uc2a4\ud399\ud2b8\ub7fc \ud3b8\ud5a5\uc73c\ub85c \uc778\ud574 \ud6a8\uacfc\uc801\uc774\uc9c0 \uc54a\ub2e4.", "method": "SV-SNN\uc740 \ubcc0\uc218 \ubd84\ub9ac\ub97c \uc774\uc6a9\ud55c \ub3c5\ub9bd\uc801\uc778 \uacf5\uac04 \ubc0f \uc2dc\uac04 \ub124\ud2b8\uc6cc\ud06c\uc640 \ud559\uc2b5 \uac00\ub2a5\ud55c \uc8fc\ud30c\uc218 \ub9e4\uac1c\ubcc0\uc218\ub97c \ud1b5\ud55c \uc801\uc751\uc801\uc778 \ud478\ub9ac\uc5d0 \uc2a4\ud399\ud2b8\ub7fc \ud2b9\uc9d5\uc744 \ud1b5\ud569\ud569\ub2c8\ub2e4.", "result": "SV-SNN\uc740 \ub2e4\uc591\ud55c \uae30\uc900 \ubb38\uc81c\uc5d0\uc11c \uc815\ud655\ub3c4\uac00 1-3\ubc30 \ud5a5\uc0c1\ub418\uc5c8\uace0, \ub9e4\uac1c\ubcc0\uc218 \uc218\uac00 90% \uc774\uc0c1 \uac10\uc18c\ud558\uba70 \ud6c8\ub828 \uc2dc\uac04\ub3c4 60% \uc904\uc5b4\ub4e4\uc5c8\ub2e4.", "conclusion": "SV-SNN\uc740 \uc2e0\uacbd\ub9dd\uc744 \uc774\uc6a9\ud55c PDE \ud574\uacb0\uc5d0\uc11c \uc2a4\ud399\ud2b8\ub7fc \ud3b8\ud5a5 \ubb38\uc81c\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud574\uacb0\ud558\ub294 \uc194\ub8e8\uc158\uc73c\ub85c \uc790\ub9ac \uc7a1\uc558\ub2e4."}}
{"id": "2508.00635", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00635", "abs": "https://arxiv.org/abs/2508.00635", "authors": ["Changning Wu", "Gao Wu", "Rongyao Cai", "Yong Liu", "Kexin Zhang"], "title": "KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting", "comment": null, "summary": "Multi-scale decomposition architectures have emerged as predominant\nmethodologies in time series forecasting. However, real-world time series\nexhibit noise interference across different scales, while heterogeneous\ninformation distribution among frequency components at varying scales leads to\nsuboptimal multi-scale representation. Inspired by Kolmogorov-Arnold Networks\n(KAN) and Parseval's theorem, we propose a KAN based adaptive Frequency\nSelection learning architecture (KFS) to address these challenges. This\nframework tackles prediction challenges stemming from cross-scale noise\ninterference and complex pattern modeling through its FreK module, which\nperforms energy-distribution-based dominant frequency selection in the spectral\ndomain. Simultaneously, KAN enables sophisticated pattern representation while\ntimestamp embedding alignment synchronizes temporal representations across\nscales. The feature mixing module then fuses scale-specific patterns with\naligned temporal features. Extensive experiments across multiple real-world\ntime series datasets demonstrate that KT achieves state-of-the-art performance\nas a simple yet effective architecture.", "AI": {"tldr": "\ubcf8 \uc5f0\uad6c\ub294 \ub2e4\uc911 \uc2a4\ucf00\uc77c \ubd84\ud574 \uc544\ud0a4\ud14d\ucc98\uc758 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud55c KAN \uae30\ubc18\uc758 \uc801\uc751\ud615 \uc8fc\ud30c\uc218 \uc120\ud0dd \ud559\uc2b5 \uc544\ud0a4\ud14d\ucc98(KFS)\ub97c \uc81c\uc548\ud55c\ub2e4.", "motivation": "\uc2e4\uc81c \uc2dc\uacc4\uc5f4 \ub370\uc774\ud130\ub294 \ub2e4\uc591\ud55c \uc2a4\ucf00\uc77c\uc5d0\uc11c \uc7a1\uc74c \uac04\uc12d\uacfc \ub3d9\uc9c8\uc801\uc774\uc9c0 \uc54a\uc740 \uc815\ubcf4 \ubd84\ud3ec \ubb38\uc81c\ub97c \uac00\uc9c0\uace0 \uc788\ub2e4.", "method": "KFS\ub294 FreK \ubaa8\ub4c8\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc2a4\ud399\ud2b8\ub7fc \uc601\uc5ed\uc5d0\uc11c \uc8fc\uc694 \uc8fc\ud30c\uc218\ub97c \uc120\ud0dd\ud558\uace0, KAN\uc744 \ud1b5\ud574 \ubcf5\uc7a1\ud55c \ud328\ud134 \ud45c\ud604\uc744 \uc218\ud589\ud558\uba70, \uc2dc\uac04 \uc815\ubcf4 \uc815\ub82c\uc744 \ud1b5\ud574 \ub2e4\uc591\ud55c \uc2a4\ucf00\uc77c \uac04\uc758 \uc784\ubca0\ub529\uc744 \ub3d9\uae30\ud654\ud55c\ub2e4.", "result": "\ub2e4\uc591\ud55c \uc2e4\uc81c \uc2dc\uacc4\uc5f4 \ub370\uc774\ud130\uc14b\uc5d0\uc11c KT\ub294 \ucd5c\ucca8\ub2e8 \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\uba70 \uac04\ub2e8\ud558\uba74\uc11c\ub3c4 \ud6a8\uacfc\uc801\uc778 \uc544\ud0a4\ud14d\ucc98\ub85c \uc785\uc99d\ub418\uc5c8\ub2e4.", "conclusion": "KFS\ub294 \ub2e4\uc911 \uc2a4\ucf00\uc77c \uc2dc\uacc4\uc5f4 \uc608\uce21\uc5d0\uc11c \uc7a1\uc74c \uac04\uc12d\uacfc \ubcf5\uc7a1\ud55c \ud328\ud134 \ubaa8\ub378\ub9c1 \ubb38\uc81c\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud574\uacb0\ud55c\ub2e4."}}
{"id": "2508.00641", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00641", "abs": "https://arxiv.org/abs/2508.00641", "authors": ["Alessandro Palmas"], "title": "Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense", "comment": "11 pages, 10 figures", "summary": "The growing threat of low-cost kamikaze drone swarms poses a critical\nchallenge to modern defense systems demanding rapid and strategic\ndecision-making to prioritize interceptions across multiple effectors and\nhigh-value target zones. In this work, we present a case study demonstrating\nthe practical advantages of reinforcement learning in addressing this\nchallenge. We introduce a high-fidelity simulation environment that captures\nrealistic operational constraints, within which a decision-level reinforcement\nlearning agent learns to coordinate multiple effectors for optimal interception\nprioritization. Operating in a discrete action space, the agent selects which\ndrone to engage per effector based on observed state features such as\npositions, classes, and effector status. We evaluate the learned policy against\na handcrafted rule-based baseline across hundreds of simulated attack\nscenarios. The reinforcement learning based policy consistently achieves lower\naverage damage and higher defensive efficiency in protecting critical zones.\nThis case study highlights the potential of reinforcement learning as a\nstrategic layer within defense architectures, enhancing resilience without\ndisplacing existing control systems. All code and simulation assets are\npublicly released for full reproducibility, and a video demonstration\nillustrates the policy's qualitative behavior.", "AI": {"tldr": "\uac15\ud654 \ud559\uc2b5\uc744 \ud65c\uc6a9\ud558\uc5ec \uc800\ube44\uc6a9 \uce74\ubbf8\uce74\uc81c \ub4dc\ub860 \ubb34\ub9ac\uc758 \ubc29\uc5b4\ub97c \ucd5c\uc801\ud654\ud558\ub294 \uc5f0\uad6c.", "motivation": "\uc800\ube44\uc6a9 \uce74\ubbf8\uce74\uc81c \ub4dc\ub860\uc758 \uc99d\uac00\uac00 \ud604\ub300 \ubc29\uc5b4 \uc2dc\uc2a4\ud15c\uc5d0 \uc704\ud611\uc744 \uc8fc\uace0 \uc788\uc73c\uba70, \ud6a8\uc728\uc801\uc778 \uc758\uc0ac\uacb0\uc815\uc774 \ud544\uc694\ud568.", "method": "\uace0\ucda9\uc2e4\ub3c4\uc758 \uc2dc\ubbac\ub808\uc774\uc158 \ud658\uacbd\uc5d0\uc11c \uac15\ud654 \ud559\uc2b5 \uc5d0\uc774\uc804\ud2b8\uac00 \uc5ec\ub7ec \ud6a8\uacfc\uae30\uc640\uc758 \ucd5c\uc801 \ubc29\uc5b4\ub97c \uc704\ud55c \uc758\uc0ac\uacb0\uc815 \ud559\uc2b5.", "result": "\ud559\uc2b5\ub41c \uc815\ucc45\uc774 \uc218\uc791\uc5c5 \ubc29\uc2dd\ubcf4\ub2e4 \ud3c9\uade0 \ud53c\ud574\ub97c \uc904\uc774\uace0 \ubc29\uc5b4 \ud6a8\uc728\uc131\uc744 \ub192\uc784.", "conclusion": "\uac15\ud654 \ud559\uc2b5\uc774 \ubc29\uc5b4 \uad6c\uc870 \ub0b4\uc5d0\uc11c \uc804\ub7b5\uc801 \uacc4\uce35\uc73c\ub85c\uc11c\uc758 \uc7a0\uc7ac\ub825\uc744 \uac15\uc870\ud558\uba70, \uae30\uc874 \uc81c\uc5b4 \uc2dc\uc2a4\ud15c\uc744 \ub300\uccb4\ud558\uc9c0 \uc54a\uc74c."}}
{"id": "2508.00643", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00643", "abs": "https://arxiv.org/abs/2508.00643", "authors": ["Albert Matveev", "Sanmitra Ghosh", "Aamal Hussain", "James-Michael Leahy", "Michalis Michaelides"], "title": "Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators", "comment": null, "summary": "Operator learning is a powerful paradigm for solving partial differential\nequations, with Fourier Neural Operators serving as a widely adopted\nfoundation. However, FNOs face significant scalability challenges due to\noverparameterization and offer no native uncertainty quantification -- a key\nrequirement for reliable scientific and engineering applications. Instead,\nneural operators rely on post hoc UQ methods that ignore geometric inductive\nbiases. In this work, we introduce DINOZAUR: a diffusion-based neural operator\nparametrization with uncertainty quantification. Inspired by the structure of\nthe heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a\ndimensionality-independent diffusion multiplier that has a single learnable\ntime parameter per channel, drastically reducing parameter count and memory\nfootprint without compromising predictive performance. By defining priors over\nthose time parameters, we cast DINOZAUR as a Bayesian neural operator to yield\nspatially correlated outputs and calibrated uncertainty estimates. Our method\nachieves competitive or superior performance across several PDE benchmarks\nwhile providing efficient uncertainty quantification.", "AI": {"tldr": "DINOZAUR\ub294 \ubd88\ud655\uc2e4\uc131\uc744 \uc815\ub7c9\ud654\ud558\ub294 \ud655\uc0b0 \uae30\ubc18 \uc2e0\uacbd \uc5f0\uc0b0\uc790 \ud30c\ub77c\uba54\ud2b8\ub9ac\uc81c\uc774\uc158\uc73c\ub85c, FNO\uc758 \uacfc\ub3c4\ud55c \ud30c\ub77c\ubbf8\ud130 \uc218 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uace0 \uc608\uce21 \uc131\ub2a5\uc744 \uc720\uc9c0\ud558\uba70 \ud6a8\uc728\uc801\uc778 \ubd88\ud655\uc2e4\uc131 \uc815\ub7c9\ud654\ub97c \uc81c\uacf5\ud55c\ub2e4.", "motivation": "\ubd80\ubd84 \ubbf8\ubd84 \ubc29\uc815\uc2dd\uc744 \ud478\ub294 \ub370 \uc788\uc5b4 \uc2e0\ub8b0\ud560 \uc218 \uc788\ub294 \uacfc\ud559 \ubc0f \uacf5\ud559 \uc751\uc6a9\uc744 \uc704\ud574\uc11c \ubd88\ud655\uc2e4\uc131 \uc815\ub7c9\ud654\uac00 \uc911\uc694\ud558\uc9c0\ub9cc \uae30\uc874\uc758 FNO\ub294 \uc774 \ub2a5\ub825\uc744 \ub0b4\uc7a5\ud558\uc9c0 \uc54a\uace0 \uc788\ub2e4.", "method": "DINOZAUR\ub294 \ub370\uc13c\uc2a4 \ud150\uc11c \uc2b9\uc218\ub97c \ud655\uc0b0 \uc2b9\uc218\ub85c \ub300\uccb4\ud558\uace0 \ub2e8\uc77c \ud559\uc2b5 \uac00\ub2a5\ud55c \uc2dc\uac04 \ud30c\ub77c\ubbf8\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc218\uce58\uc801 \ud30c\ub77c\ubbf8\ud130 \uc218\uc640 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \ud06c\uac8c \uc904\uc778\ub2e4.", "result": "\uc6b0\ub9ac\uc758 \ubc29\ubc95\uc740 \uc5ec\ub7ec PDE \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uacbd\uc7c1\ub825 \uc788\ub294 \ub610\ub294 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\uba70 \ud6a8\uc728\uc801\uc778 \ubd88\ud655\uc2e4\uc131 \uc815\ub7c9\ud654\ub97c \uc81c\uacf5\ud55c\ub2e4.", "conclusion": "DINOZAUR\ub294 \uacf5\uac04\uc801\uc73c\ub85c \uc0c1\uad00\uad00\uacc4\uac00 \uc788\ub294 \ucd9c\ub825\uacfc \ubcf4\uc815\ub41c \ubd88\ud655\uc2e4\uc131 \ucd94\uc815\uc744 \uc81c\uacf5\ud558\ub294 \ubca0\uc774\uc9c0\uc548 \uc2e0\uacbd \uc5f0\uc0b0\uc790\ub85c \uc790\ub9ac\ub9e4\uae40\ud55c\ub2e4."}}
{"id": "2508.00707", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00707", "abs": "https://arxiv.org/abs/2508.00707", "authors": ["Yannik Schnitzer", "Alessandro Abate", "David Parker"], "title": "Efficient Solution and Learning of Robust Factored MDPs", "comment": null, "summary": "Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling\nepistemic uncertainty about transition dynamics. Learning r-MDPs from\ninteractions with an unknown environment enables the synthesis of robust\npolicies with provable (PAC) guarantees on performance, but this can require a\nlarge number of sample interactions. We propose novel methods for solving and\nlearning r-MDPs based on factored state-space representations that leverage the\nindependence between model uncertainty across system components. Although\npolicy synthesis for factored r-MDPs leads to hard, non-convex optimisation\nproblems, we show how to reformulate these into tractable linear programs.\nBuilding on these, we also propose methods to learn factored model\nrepresentations directly. Our experimental results show that exploiting\nfactored structure can yield dimensional gains in sample efficiency, producing\nmore effective robust policies with tighter performance guarantees than\nstate-of-the-art methods.", "AI": {"tldr": "\ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc548\uc815\uc801\uc778 \ub9c8\ub974\ucf54\ud504 \uacb0\uc815 \ud504\ub85c\uc138\uc2a4(r-MDP)\ub97c \ud559\uc2b5\ud558\ub294 \uc0c8\ub85c\uc6b4 \ubc29\ubc95\uc744 \uc81c\uc548\ud558\uace0 \ube44\uc728\uc801 \uc0c1\ud0dc \uacf5\uac04 \ud45c\ud604\uc744 \uae30\ubc18\uc73c\ub85c \ud55c \uc815\ucc45 \ud569\uc131\uc5d0\uc11c\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "motivation": "\ubd88\ud655\uc2e4\ud55c \ud658\uacbd\uc5d0\uc11c\uc758 r-MDP \ud559\uc2b5\uc744 \ud1b5\ud574 \uc131\ub2a5\uc5d0 \ub300\ud55c \uc99d\uba85\ub41c \ubcf4\uc7a5\uacfc \ud568\uaed8 \uac15\ub825\ud55c \uc815\ucc45\uc744 \ud569\uc131\ud560 \uc218 \uc788\ub3c4\ub85d \ud558\uae30 \uc704\ud568.", "method": "\uc0c1\ud0dc \uacf5\uac04 \ud45c\ud604\uc744 \ubd84\ud574\ud558\uc5ec \uc2dc\uc2a4\ud15c \uad6c\uc131 \uc694\uc18c \uac04\uc758 \ubaa8\ub378 \ubd88\ud655\uc2e4\uc131 \ub3c5\ub9bd\uc131\uc744 \ud65c\uc6a9\ud558\uace0, \uc774\ub97c \ud1b5\ud574 \ube44\uc120\ud615 \ucd5c\uc801\ud654 \ubb38\uc81c\ub97c \uc120\ud615 \ud504\ub85c\uadf8\ub7a8\uc73c\ub85c \uc7ac\uad6c\uc131\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc548.", "result": "\uc2e0\ub8b0\ud560 \uc218 \uc788\ub294 \uc815\ucc45\uc744 \uc0dd\uc131\ud558\uc600\uc73c\uba70, \uc0c1\ud0dc \ub300\ud45c \ubc29\ubc95\uc5d0 \ube44\ud574 \uc0d8\ud50c \ud6a8\uc728\uc131\uc774 \ud5a5\uc0c1\ub418\uc5c8\ub2e4.", "conclusion": "\ubd84\ud574\ub41c \uad6c\uc870\ub97c \ud65c\uc6a9\ud568\uc73c\ub85c\uc368 \uc0d8\ud50c \ud6a8\uc728\uc131\uc774 \ud5a5\uc0c1\ub418\uace0, \ucd5c\uc2e0 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ub354 \ud6a8\uacfc\uc801\uc778 \uac15\ub825\ud55c \uc815\ucc45\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc2e4\ud5d8\uc801\uc73c\ub85c \uc785\uc99d\ud558\uc600\ub2e4."}}
{"id": "2508.00657", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00657", "abs": "https://arxiv.org/abs/2508.00657", "authors": ["Sihang Zeng", "Lucas Jing Liu", "Jun Wen", "Meliha Yetisgen", "Ruth Etzioni", "Gang Luo"], "title": "TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction", "comment": "Accepted by MLHC 2025", "summary": "Trustworthy survival prediction is essential for clinical decision making.\nLongitudinal electronic health records (EHRs) provide a uniquely powerful\nopportunity for the prediction. However, it is challenging to accurately model\nthe continuous clinical progression of patients underlying the irregularly\nsampled clinical features and to transparently link the progression to survival\noutcomes. To address these challenges, we develop TrajSurv, a model that learns\ncontinuous latent trajectories from longitudinal EHR data for trustworthy\nsurvival prediction. TrajSurv employs a neural controlled differential equation\n(NCDE) to extract continuous-time latent states from the irregularly sampled\ndata, forming continuous latent trajectories. To ensure the latent trajectories\nreflect the clinical progression, TrajSurv aligns the latent state space with\npatient state space through a time-aware contrastive learning approach. To\ntransparently link clinical progression to the survival outcome, TrajSurv uses\nlatent trajectories in a two-step divide-and-conquer interpretation process.\nFirst, it explains how the changes in clinical features translate into the\nlatent trajectory's evolution using a learned vector field. Second, it clusters\nthese latent trajectories to identify key clinical progression patterns\nassociated with different survival outcomes. Evaluations on two real-world\nmedical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and\nsuperior transparency over existing deep learning methods.", "AI": {"tldr": "TrajSurv\ub294 \uc804\uc790 \uac74\uac15 \uae30\ub85d(EHR) \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud558\uc5ec \uc2e0\ub8b0\ud560 \uc218 \uc788\ub294 \uc0dd\uc874 \uc608\uce21\uc744 \uc704\ud55c \ubaa8\ub378\ub85c, \uc784\uc0c1 \uc9c4\ud589 \uacfc\uc815\uc744 \uba85\ud655\ud788 \uc124\uba85\ud558\uace0\uc790 \ud568.", "motivation": "\uc815\ud655\ud55c \uc0dd\uc874 \uc608\uce21\uc740 \uc784\uc0c1 \uc758\uc0ac\uacb0\uc815\uc5d0 \uc911\uc694\ud558\uba70, \uadf8\ub7ec\ub098 \ube44\uc815\uae30\uc801\uc73c\ub85c \uc0d8\ud50c\ub9c1\ub41c \uc784\uc0c1 \ud2b9\uc131\uc758 \uc9c0\uc18d\uc801\uc778 \ubaa8\ub378\ub9c1\uc774 \uc5b4\ub835\ub2e4.", "method": "TrajSurv\ub294 \uc2e0\uacbd \uc81c\uc5b4 \ubbf8\ubd84 \ubc29\uc815\uc2dd(NCDE)\uc744 \uc0ac\uc6a9\ud558\uc5ec EHR \ub370\uc774\ud130\uc5d0\uc11c \uc5f0\uc18d\uc801\uc778 \uc7a0\uc7ac \uada4\uc801\uc744 \ud559\uc2b5\ud558\uace0, \uc2dc\uac04 \uc778\uc2dd \ub300\uc870 \ud559\uc2b5 \uc811\uadfc\ubc95\uc73c\ub85c \ud658\uc790 \uc0c1\ud0dc\uc640 \uc815\ub82c\ud55c\ub2e4.", "result": "MIMIC-III\uc640 eICU\uc758 \uc2e4\uc138\uacc4 \uc758\ub8cc \ub370\uc774\ud130\uc14b\uc5d0\uc11c TrajSurv\uac00 \uae30\uc874\uc758 \ub525\ub7ec\ub2dd \ubc29\ubc95\uc5d0 \ube44\ud574 \uacbd\uc7c1\ub825 \uc788\ub294 \uc815\ud655\ub3c4\uc640 \uc6b0\uc218\ud55c \ud22c\uba85\uc131\uc744 \ubcf4\uc784\uc744 \ud655\uc778\ud588\ub2e4.", "conclusion": "TrajSurv\ub294 \uc784\uc0c1 \uc9c4\ud589 \uacfc\uc815\uacfc \uc0dd\uc874 \uacb0\uacfc\ub97c \ud22c\uba85\ud558\uac8c \uc5f0\uacb0\ud558\ub294 \ub370 \ud6a8\uacfc\uc801\uc774\uba70, \ubbf8\ub798\uc758 \uc784\uc0c1 \uacb0\uc815\uc5d0 \uae30\uc5ec\ud560 \uac00\ub2a5\uc131\uc774 \uc788\ub2e4."}}
{"id": "2508.00712", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00712", "abs": "https://arxiv.org/abs/2508.00712", "authors": ["Dien Nguyen", "Diego Perez-Liebana", "Simon Lucas"], "title": "JSON-Bag: A generic game trajectory representation", "comment": "8 pages, 3 figures, 6 tables, to be published in IEEE Conference on\n  Games 2025", "summary": "We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically\nrepresent game trajectories by tokenizing their JSON descriptions and apply\nJensen-Shannon distance (JSD) as distance metric for them. Using a\nprototype-based nearest-neighbor search (P-NNS), we evaluate the validity of\nJSON-Bag with JSD on six tabletop games -- \\textit{7 Wonders},\n\\textit{Dominion}, \\textit{Sea Salt and Paper}, \\textit{Can't Stop},\n\\textit{Connect4}, \\textit{Dots and boxes} -- each over three game trajectory\nclassification tasks: classifying the playing agents, game parameters, or game\nseeds that were used to generate the trajectories.\n  Our approach outperforms a baseline using hand-crafted features in the\nmajority of tasks. Evaluating on N-shot classification suggests using JSON-Bag\nprototype to represent game trajectory classes is also sample efficient.\nAdditionally, we demonstrate JSON-Bag ability for automatic feature extraction\nby treating tokens as individual features to be used in Random Forest to solve\nthe tasks above, which significantly improves accuracy on underperforming\ntasks. Finally, we show that, across all six games, the JSD between JSON-Bag\nprototypes of agent classes highly correlates with the distances between\nagents' policies.", "AI": {"tldr": "JSON-Bag \ubaa8\ub378\uc744 \ud1b5\ud574 \uac8c\uc784 \uada4\uc801\uc744 \ub098\ud0c0\ub0b4\uace0, JSD\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc720\uc0ac\uc131\uc744 \ud3c9\uac00\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud558\uba70, \ub2e4\uc591\ud55c \uac8c\uc784\uc5d0\uc11c \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub428\uc744 \ubcf4\uc5ec\uc90c.", "motivation": "\uac8c\uc784 \uada4\uc801\uc758 \uc77c\ubc18\uc801\uc778 \ud45c\ud604 \ubc29\ubc95\uc774 \ud544\uc694\ud558\uba70, \uc774\ub97c \ud1b5\ud574 \uac8c\uc784 \ubd84\uc11d \ubc0f \ubd84\ub958\uc758 \ud6a8\uc728\uc131\uc744 \ub192\uc774\uace0\uc790 \ud568.", "method": "\uac8c\uc784 \uc124\uba85\uc744 \ud1a0\ud070\ud654\ud558\uc5ec JSON-Bag \ubaa8\ub378\uc744 \ub9cc\ub4e4\uace0, Jensen-Shannon \uac70\ub9ac(JSD)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc720\uc0ac\ub3c4\ub97c \ud3c9\uac00\ud558\uba70, P-NNS\ub97c \ud1b5\ud574 \ubd84\ub958 \uc791\uc5c5\uc744 \uc218\ud589.", "result": "\uc774 \uc811\uadfc \ubc29\uc2dd\uc740 \uc218\uc791\uc5c5\uc73c\ub85c \uc81c\uc791\ub41c \ud2b9\uc131\uc744 \uc0ac\uc6a9\ud558\ub294 \uae30\uc900\ubcf4\ub2e4 \ub300\ubd80\ubd84\uc758 \uc791\uc5c5\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubc1c\ud718\ud558\uc600\uc73c\uba70, \uc790\ub3d9 \ud2b9\uc131 \ucd94\ucd9c\uc5d0 \uc788\uc5b4\uc11c\ub3c4 \uc131\ub2a5\uc744 \uac1c\uc120\ud568.", "conclusion": "JSON-Bag \ud504\ub85c\ud1a0\ud0c0\uc785 \uac04\uc758 JSD\uac00 \uc5d0\uc774\uc804\ud2b8 \uc815\ucc45 \uac04\uc758 \uac70\ub9ac\uc640 \ub192\uc740 \uc0c1\uad00\uad00\uacc4\ub97c \ubcf4\uc774\uba70, \uc774\ub97c \ud1b5\ud574 \uac8c\uc784 \uada4\uc801\uc758 \ud6a8\uacfc\uc801\uc778 \ubd84\ub958 \ubc0f \ubd84\uc11d\uc774 \uac00\ub2a5\ud568\uc744 \uc785\uc99d\ud568."}}
{"id": "2508.00664", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00664", "abs": "https://arxiv.org/abs/2508.00664", "authors": ["Jialun Zheng", "Jie Liu", "Jiannong Cao", "Xiao Wang", "Hanchen Yang", "Yankai Chen", "Philip S. Yu"], "title": "DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes", "comment": null, "summary": "Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies\nin evolving graphs across domains such as finance, traffic, and social\nnetworks. Recently, generalist graph anomaly detection (GAD) models have shown\npromising results. They are pretrained on multiple source datasets and\ngeneralize across domains. While effective on static graphs, they struggle to\ncapture evolving anomalies in dynamic graphs. Moreover, the continuous\nemergence of new domains and the lack of labeled data further challenge\ngeneralist DGAD. Effective cross-domain DGAD requires both domain-specific and\ndomain-agnostic anomalous patterns. Importantly, these patterns evolve\ntemporally within and across domains. Building on these insights, we propose a\nDGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and\ndomain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,\nevolving representations of normal and anomalous patterns, from temporal\nego-graphs and stores them in a memory buffer. The buffer is selectively\nupdated to retain general, domain-agnostic patterns while incorporating new\ndomain-specific ones. Then, an anomaly scorer compares incoming data with\ndynamic prototypes to flag both general and domain-specific anomalies. Finally,\nDP-DGAD employs confidence-based pseudo-labeling for effective self-supervised\nadaptation in target domains. Extensive experiments demonstrate\nstate-of-the-art performance across ten real-world datasets from different\ndomains.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \uc9c4\ud654\ud558\ub294 \uadf8\ub798\ud504\uc5d0\uc11c\uc758 \uc774\uc0c1 \ud0d0\uc9c0\ub97c \uc704\ud55c \ub3d9\uc801 \uadf8\ub798\ud504 \uc774\uc0c1 \ud0d0\uc9c0 \ubaa8\ub378\uc744 \uc81c\uc548\ud558\uace0, \uac01\uc885 \ub3c4\uba54\uc778\uc5d0\uc11c \ud6a8\uacfc\uc801\uc778 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc900\ub2e4.", "motivation": "\uc9c4\ud654\ud558\ub294 \uadf8\ub798\ud504\uc5d0\uc11c \ubc1c\uc0dd\ud558\ub294 \uc774\uc0c1\uc744 \ud0d0\uc9c0\ud558\ub294 \uac83\uc774 \ud544\uc694\ud558\uc9c0\ub9cc, \uae30\uc874\uc758 \uc77c\ubc18 \uadf8\ub798\ud504 \uc774\uc0c1 \ud0d0\uc9c0 \ubaa8\ub378\uc774 \ub3d9\uc801 \uadf8\ub798\ud504\uc5d0\uc11c\uc758 \uc774\uc0c1\uc744 \ud3ec\ucc29\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\uace0 \uc788\ub2e4.", "method": "\ub3d9\uc801 \ud504\ub85c\ud1a0\ud0c0\uc785(Dynamic Prototypes, DP)\ub97c \ud65c\uc6a9\ud55c DGAD \ubaa8\ub378\uc744 \uc81c\uc548\ud558\uc5ec, \uc2dc\uac04\uc801\uc73c\ub85c \ubcc0\ud654\ud558\ub294 \uc815\uc0c1 \ubc0f \uc774\uc0c1 \ud328\ud134\uc744 \ucea1\ucc98\ud558\uace0 \uba54\ubaa8\ub9ac \ubc84\ud37c\uc5d0 \uc800\uc7a5\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \uc791\ub3d9\ud55c\ub2e4.", "result": "10\uac1c\uc758 \uc11c\ub85c \ub2e4\ub978 \ub3c4\uba54\uc778\uc5d0\uc11c\uc758 \uc2e4\uc81c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ucd5c\ucca8\ub2e8 \uc131\ub2a5\uc744 \uc785\uc99d\ud558\uc600\ub2e4.", "conclusion": "DP-DGAD \ubaa8\ub378\uc740 \uc9c4\ud654\ud558\ub294 \ub3c4\uba54\uc778 \ud2b9\ud654 \ubc0f \ub3c4\uba54\uc778 \ube44\ud2b9\ud654 \ud328\ud134\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ucea1\ucc98\ud560 \uc218 \uc788\uc5b4 \ub2e4\uc591\ud55c \ub3c4\uba54\uc778\uc5d0\uc11c \uc720\ub9dd\ud55c \uc774\uc0c1 \ud0d0\uc9c0 \uc131\ub2a5\uc744 \uc81c\uacf5\ud55c\ub2e4."}}
{"id": "2508.00716", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00716", "abs": "https://arxiv.org/abs/2508.00716", "authors": ["Yingxu Wang", "Mengzhu Wang", "Zhichao Huang", "Suyu Liu"], "title": "Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning", "comment": null, "summary": "Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled\nsource graphs to unlabeled target graphs by learning domain-invariant\nrepresentations, which is essential in applications such as molecular property\nprediction and social network analysis. However, most existing GDA methods rely\non the assumption of clean source labels, which rarely holds in real-world\nscenarios where annotation noise is pervasive. This label noise severely\nimpairs feature alignment and degrades adaptation performance under domain\nshifts. To address this challenge, we propose Nested Graph Pseudo-Label\nRefinement (NeGPR), a novel framework tailored for graph-level domain\nadaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,\nsemantic and topology branches, by enforcing neighborhood consistency in the\nfeature space, thereby reducing the influence of noisy supervision. To bridge\ndomain gaps, NeGPR employs a nested refinement mechanism in which one branch\nselects high-confidence target samples to guide the adaptation of the other,\nenabling progressive cross-domain learning. Furthermore, since pseudo-labels\nmay still contain noise and the pre-trained branches are already overfitted to\nthe noisy labels in the source domain, NeGPR incorporates a noise-aware\nregularization strategy. This regularization is theoretically proven to\nmitigate the adverse effects of pseudo-label noise, even under the presence of\nsource overfitting, thus enhancing the robustness of the adaptation process.\nExtensive experiments on benchmark datasets demonstrate that NeGPR consistently\noutperforms state-of-the-art methods under severe label noise, achieving gains\nof up to 12.7% in accuracy.", "AI": {"tldr": "NeGPR\uc740 \uc18c\uc2a4 \ub808\uc774\ube14\uc758 \ub178\uc774\uc988\ub97c \ucc98\ub9ac\ud560 \uc218 \uc788\ub294 \uadf8\ub798\ud504 \uc218\uc900 \ub3c4\uba54\uc778 \uc801\uc751 \ud504\ub808\uc784\uc6cc\ud06c\ub85c, \ub192\uc740 \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud55c\ub2e4.", "motivation": "\uc2e4\uc81c \ud658\uacbd\uc5d0\uc11c \uc8fc\uc11d \ub178\uc774\uc988\uac00 \ub9cc\uc5f0\ud558\uc5ec \uae30\uc874 GDA \ubc29\ubc95\ub4e4\uc774 \ud6a8\uacfc\uc801\uc73c\ub85c \uc791\ub3d9\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0, \ub178\uc774\uc988\uac00 \uc788\ub294 \ub808\uc774\ube14\uc744 \ucc98\ub9ac\ud558\ub294 \ubc29\ubc95\uc774 \ud544\uc694\ud558\ub2e4.", "method": "NeGPR\uc740 \ubd88\ud544\uc694\ud55c \uac10\ub3c5\uc758 \uc601\ud5a5\uc744 \uc904\uc774\uae30 \uc704\ud574 \uc774\uc6c3 \uc77c\uad00\uc131\uc744 \uac15\uc81c\ud558\ub294 \ub450 \uac1c\uc758 \ube0c\ub79c\uce58(\uad6c\uc870\uc801 \ubc0f \ud1a0\ud3f4\ub85c\uc9c0 \ube0c\ub79c\uce58)\ub97c \uc0ac\uc804 \ud6c8\ub828\ud558\uace0, \uace0\uc2e0\ub8b0 \ud0c0\uac9f \uc0d8\ud50c\uc744 \uc120\ud0dd\ud558\uc5ec \uc801\uc751\uc744 \uc548\ub0b4\ud558\ub294 \uc911\ucca9 \uc815\uc81c \uba54\ucee4\ub2c8\uc998\uc744 \uc801\uc6a9\ud55c\ub2e4.", "result": "NeGPR\uc740 \uc2ec\uac01\ud55c \ub808\uc774\ube14 \ub178\uc774\uc988\uc5d0\uc11c\ub3c4 \ucd5c\uc2e0 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ucd5c\ub300 12.7% \ub192\uc740 \uc815\ud655\ub3c4\ub97c \uae30\ub85d\ud558\uba70 \uc77c\uad00\ub418\uac8c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc778\ub2e4.", "conclusion": "NeGPR\uc740 \ub178\uc774\uc988\uac00 \uc788\ub294 \ub808\uc774\ube14\uc744 \ucc98\ub9ac\ud558\uc5ec \ub3c4\uba54\uc778 \uc801\uc751 \uacfc\uc815\uc758 \uac15\uac74\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ud6a8\uacfc\uc801\uc778 \ubc29\ubc95\uc774\ub2e4."}}
{"id": "2508.00692", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.00692", "abs": "https://arxiv.org/abs/2508.00692", "authors": ["Young-ho Cho", "Hao Zhu", "Duehee Lee", "Ross Baldick"], "title": "Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network", "comment": null, "summary": "For conducting resource adequacy studies, we synthesize multiple long-term\nwind power scenarios of distributed wind farms simultaneously by using the\nspatio-temporal features: spatial and temporal correlation, waveforms, marginal\nand ramp rates distributions of waveform, power spectral densities, and\nstatistical characteristics. Generating the spatial correlation in scenarios\nrequires the design of common factors for neighboring wind farms and\nantithetical factors for distant wind farms. The generalized dynamic factor\nmodel (GDFM) can extract the common factors through cross spectral density\nanalysis, but it cannot closely imitate waveforms. The GAN can synthesize\nplausible samples representing the temporal correlation by verifying samples\nthrough a fake sample discriminator. To combine the advantages of GDFM and GAN,\nwe use the GAN to provide a filter that extracts dynamic factors with temporal\ninformation from the observation data, and we then apply this filter in the\nGDFM to represent both spatial and frequency correlations of plausible\nwaveforms. Numerical tests on the combination of GDFM and GAN have demonstrated\nperformance improvements over competing alternatives in synthesizing wind power\nscenarios from Australia, better realizing plausible statistical\ncharacteristics of actual wind power compared to alternatives such as the GDFM\nwith a filter synthesized from distributions of actual dynamic filters and the\nGAN with direct synthesis without dynamic factors.", "AI": {"tldr": "\ubcf8 \uc5f0\uad6c\ub294 \ud48d\ub825 \ubc1c\uc804\uc18c\uc758 \uc790\uc6d0 \uc801\ud569\uc131 \uc5f0\uad6c\ub97c \uc704\ud574 GDFM\uacfc GAN\uc758 \uacb0\ud569\uc744 \ud1b5\ud574 \ud48d\ub825 \uc2dc\ub098\ub9ac\uc624\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud569\uc131\ud568\uc73c\ub85c\uc368 \uc131\ub2a5\uc744 \uac1c\uc120\ud55c\ub2e4.", "motivation": "\uc804\ub825\ub9dd\uc758 \uc548\uc815\uc131\uc744 \ud655\ubcf4\ud558\uae30 \uc704\ud574 \uc5ec\ub7ec \uc7a5\uae30 \ud48d\ub825 \uc2dc\ub098\ub9ac\uc624\ub97c \ub3d9\uc2dc \uc0dd\uc131\ud560 \ud544\uc694\uc131\uc774 \uc788\ub2e4.", "method": "GDFM\uc744 \uc0ac\uc6a9\ud558\uc5ec \uacf5\ud1b5 \ubc0f \ub300\uc870 \uc694\uc18c\ub97c \ucd94\ucd9c\ud558\uace0, GAN\uc744 \ud1b5\ud574 \uc2dc\uac04\uc801 \uc0c1\uad00\uad00\uacc4\ub97c \ub098\ud0c0\ub0b4\ub294 \uc0d8\ud50c\uc744 \ud569\uc131\ud558\uba70, \ub450 \ubaa8\ub378\uc744 \uacb0\ud569\ud558\uc5ec \uc804\ubc18\uc801\uc778 \ud30c\ud615\uc744 \ud45c\ud604\ud55c\ub2e4.", "result": "\ud638\uc8fc\uc758 \ud48d\ub825 \uc2dc\ub098\ub9ac\uc624 \ud569\uc131\uc5d0\uc11c GDFM\uacfc GAN\uc758 \uc870\ud569\uc774 \uae30\uc874 \ubc29\ubc95\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc600\ub2e4.", "conclusion": "GDFM\uacfc GAN\uc758 \ud1b5\ud569\uc740 \uc2e4\uc81c \ud48d\ub825 \ubc1c\uc804\uc758 \ud1b5\uacc4\uc801 \ud2b9\uc131\uc744 \ub354 \uc798 \ubc18\uc601\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00734", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00734", "abs": "https://arxiv.org/abs/2508.00734", "authors": ["Liuyun Xu", "Seymour M. J. Spence"], "title": "Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems", "comment": null, "summary": "Existing variance reduction techniques used in stochastic simulations for\nrare event analysis still require a substantial number of model evaluations to\nestimate small failure probabilities. In the context of complex, nonlinear\nfinite element modeling environments, this can become computationally\nchallenging-particularly for systems subjected to stochastic excitation. To\naddress this challenge, a multi-fidelity stratified sampling scheme with\nadaptive machine learning metamodels is introduced for efficiently propagating\nuncertainties and estimating small failure probabilities. In this approach, a\nhigh-fidelity dataset generated through stratified sampling is used to train a\ndeep learning-based metamodel, which then serves as a cost-effective and highly\ncorrelated low-fidelity model. An adaptive training scheme is proposed to\nbalance the trade-off between approximation quality and computational demand\nassociated with the development of the low-fidelity model. By integrating the\nlow-fidelity outputs with additional high-fidelity results, an unbiased\nestimate of the strata-wise failure probabilities is obtained using a\nmulti-fidelity Monte Carlo framework. The overall probability of failure is\nthen computed using the total probability theorem. Application to a full-scale\nhigh-rise steel building subjected to stochastic wind excitation demonstrates\nthat the proposed scheme can accurately estimate exceedance probability curves\nfor nonlinear responses of interest, while achieving significant computational\nsavings compared to single-fidelity variance reduction approaches.", "AI": {"tldr": "\ubcf5\uc7a1\ud55c \ube44\uc120\ud615 \uc720\ud55c \uc694\uc18c \ubaa8\ub378\ub9c1 \ud658\uacbd\uc5d0\uc11c \ud76c\uadc0 \uc0ac\uac74 \ubd84\uc11d\uc744 \uc704\ud55c \ud6a8\uc728\uc801\uc778 \ubd88\ud655\uc2e4\uc131 \uc804\ud30c \ubc0f \uc791\uc740 \uc2e4\ud328 \ud655\ub960 \ucd94\uc815\uc744 \uc704\ud55c \ub2e4\uc218\uc758 \uc2e0\ub8b0\ub3c4 \uc0d8\ud50c\ub9c1 \uae30\ubc95\uacfc \uc801\uc751\ud615 \uba38\uc2e0\ub7ec\ub2dd \uba54\ud0c0\ubaa8\ub378\uc744 \uc81c\uc548\ud55c\ub2e4.", "motivation": "\uae30\uc874\uc758 \ubd84\uc0b0 \uac10\uc18c \uae30\ubc95\uc774 \ud76c\uadc0 \uc0ac\uac74 \ubd84\uc11d\uc5d0 \uc788\uc5b4 \uc5ec\uc804\ud788 \ub9ce\uc740 \ubaa8\ub378 \ud3c9\uac00\ub97c \ud544\uc694\ub85c \ud558\uba70, \uc774\ub294 \ubcf5\uc7a1\ud55c \ube44\uc120\ud615 \uc2dc\uc2a4\ud15c\uc5d0\uc11c \uacc4\uc0b0\uc801\uc73c\ub85c \ub3c4\uc804\uc801\uc774\ub2e4.", "method": "\ub2e4\uc218\uc758 \uc2e0\ub8b0\ub3c4 \uc0d8\ud50c\ub9c1 \ubc0f \uc801\uc751\ud615 \uba38\uc2e0\ub7ec\ub2dd \uba54\ud0c0\ubaa8\ub378\uc744 \ud65c\uc6a9\ud558\uc5ec \ubd88\ud655\uc2e4\uc131\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \uc804\ud30c\ud558\uace0 \uc2e4\ud328 \ud655\ub960\uc744 \ucd94\uc815\ud55c\ub2e4.", "result": "\uc81c\uc548\ub41c \ubc29\ubc95\uc774 \uac1c\ubcc4 \uc2e0\ub8b0\ub3c4 \uac10\uc18c \uc811\uadfc\ubc95\uc5d0 \ube44\ud574 \uacc4\uc0b0 \ube44\uc6a9\uc744 \ud06c\uac8c \uc808\uac10\ud558\uba74\uc11c \ube44\uc120\ud615 \uc751\ub2f5\uc5d0 \ub300\ud55c \ucd08\uacfc \ud655\ub960 \uace1\uc120\uc744 \uc815\ud655\ud558\uac8c \ucd94\uc815\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc5f0\ud55c\ub2e4.", "conclusion": "\uace0\uce35 \uac15\uc7ac \uac74\ubb3c\uc5d0 \uc801\uc6a9\ud55c \uacb0\uacfc, \uc0c8\ub85c\uc6b4 \ubc29\ubc95\uc774 \ubb3c\ub9ac\uc801 \uc2dc\uc2a4\ud15c\uc5d0 \ub300\ud55c \uc2e0\ub8b0\ub3c4 \uc788\ub294 \uc2e4\ud328 \ud655\ub960 \ucd94\uc815\uc744 \uc81c\uacf5\ud568\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00695", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00695", "abs": "https://arxiv.org/abs/2508.00695", "authors": ["Sergio Rubio-Mart\u00edn", "Mar\u00eda Teresa Garc\u00eda-Ord\u00e1s", "Antonio Serrano-Garc\u00eda", "Clara Margarita Franch-Pato", "Arturo Crespo-\u00c1lvaro", "Jos\u00e9 Alberto Ben\u00edtez-Andrades"], "title": "Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach", "comment": null, "summary": "The classification of clinical notes into specific diagnostic categories is\ncritical in healthcare, especially for mental health conditions like Anxiety\nand Adjustment Disorder. In this study, we compare the performance of various\nArtificial Intelligence models, including both traditional Machine Learning\napproaches (Random Forest, Support Vector Machine, K-nearest neighbors,\nDecision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT\nand SciBERT), to classify clinical notes into these two diagnoses.\nAdditionally, we implemented three oversampling strategies: No Oversampling,\nRandom Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to\nassess their impact on model performance. Hyperparameter tuning was also\napplied to optimize model accuracy. Our results indicate that oversampling\ntechniques had minimal impact on model performance overall. The only exception\nwas SMOTE, which showed a positive effect specifically with BERT-based models.\nHowever, hyperparameter optimization significantly improved accuracy across the\nmodels, enhancing their ability to generalize and perform on the dataset. The\nDecision Tree and eXtreme Gradient Boost models achieved the highest accuracy\namong machine learning approaches, both reaching 96%, while the DistilBERT and\nSciBERT models also attained 96% accuracy in the deep learning category. These\nfindings underscore the importance of hyperparameter tuning in maximizing model\nperformance. This study contributes to the ongoing research on AI-assisted\ndiagnostic tools in mental health by providing insights into the efficacy of\ndifferent model architectures and data balancing methods.", "AI": {"tldr": "\uc784\uc0c1 \ub178\ud2b8\ub97c Anxiety\uc640 Adjustment Disorder\ub85c \ubd84\ub958\ud558\ub294 AI \ubaa8\ub378\uc758 \uc131\ub2a5 \ube44\uad50 \uc5f0\uad6c.", "motivation": "\uc815\uc2e0 \uac74\uac15 \uc0c1\ud0dc\uc758 \uc815\ud655\ud55c \uc9c4\ub2e8\uc744 \uc704\ud574 \uc784\uc0c1 \ub178\ud2b8\ub97c \ud2b9\uc815 \uc9c4\ub2e8 \ubc94\uc8fc\ub85c \ubd84\ub958\ud558\ub294 \uac83\uc774 \uc911\uc694\ud568.", "method": "\uc804\ud1b5\uc801\uc778 \uba38\uc2e0\ub7ec\ub2dd \uae30\ubc95\uacfc \ub525\ub7ec\ub2dd \ubaa8\ub378\uc744 \ud3ec\ud568\ud55c \ub2e4\uc591\ud55c AI \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uace0, \uc138 \uac00\uc9c0 \uc624\ubc84\uc0d8\ud50c\ub9c1 \uc804\ub7b5\uacfc \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\uc744 \uc801\uc6a9.", "result": "SMOTE\uac00 BERT \uae30\ubc18 \ubaa8\ub378\uc5d0 \uae0d\uc815\uc801\uc778 \uc601\ud5a5\uc744 \ubbf8\ucce4\uace0, \uacb0\uc815 \ud2b8\ub9ac \ubc0f eXtreme Gradient Boost \ubaa8\ub378\uc774 \uac01\uac01 96%\uc758 \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud588\ub2e4.", "conclusion": "\ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\uc774 \ubaa8\ub378 \uc131\ub2a5 \ucd5c\uc801\ud654\uc5d0 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud558\uba70, \ub2e4\uc591\ud55c \ubaa8\ub378 \uc544\ud0a4\ud14d\ucc98\uc640 \ub370\uc774\ud130 \ubc38\ub7f0\uc2f1 \ubc29\ubc95\uc758 \ud6a8\ub2a5\uc5d0 \ub300\ud55c \ud1b5\ucc30\uc744 \uc81c\uacf5\ud55c\ub2e4."}}
{"id": "2508.00754", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00754", "abs": "https://arxiv.org/abs/2508.00754", "authors": ["Yaxin Ma", "Benjamin Colburn", "Jose C. Principe"], "title": "A Simple and Effective Method for Uncertainty Quantification and OOD Detection", "comment": null, "summary": "Bayesian neural networks and deep ensemble methods have been proposed for\nuncertainty quantification; however, they are computationally intensive and\nrequire large storage. By utilizing a single deterministic model, we can solve\nthe above issue. We propose an effective method based on feature space density\nto quantify uncertainty for distributional shifts and out-of-distribution (OOD)\ndetection. Specifically, we leverage the information potential field derived\nfrom kernel density estimation to approximate the feature space density of the\ntraining set. By comparing this density with the feature space representation\nof test samples, we can effectively determine whether a distributional shift\nhas occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons\nand Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The\nresults demonstrate that our method outperforms baseline models.", "AI": {"tldr": "\ubcf8 \uc5f0\uad6c\uc5d0\uc11c\ub294 \ub2e8\uc77c \uacb0\uc815\ub860\uc801 \ubaa8\ub378\uc744 \ud65c\uc6a9\ud558\uc5ec \ubd88\ud655\uc2e4\uc131 \uc815\ub7c9\ud654\uc758 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \ud6a8\uacfc\uc801\uc778 \ubc29\ubc95\uc744 \uc81c\uc548\ud55c\ub2e4.", "motivation": "Bayesian \uc2e0\uacbd\ub9dd\uacfc \ub525 \uc559\uc0c1\ube14 \ubc29\ubc95\uc740 \ubd88\ud655\uc2e4\uc131 \uc815\ub7c9\ud654\uc5d0 \uc720\uc6a9\ud558\uc9c0\ub9cc \uacc4\uc0b0 \ube44\uc6a9\uc774 \ud06c\uace0 \uc800\uc7a5 \uc6a9\ub7c9\uc774 \ud544\uc694\ud558\ub2e4.", "method": "\ucee4\ub110 \ubc00\ub3c4 \ucd94\uc815\uc5d0\uc11c \uc720\ub3c4\ub41c \uc815\ubcf4 \uc7a0\uc7ac \ud544\ub4dc\ub97c \ud65c\uc6a9\ud558\uc5ec \ud6c8\ub828 \uc138\ud2b8\uc758 \ud2b9\uc9d5 \uacf5\uac04 \ubc00\ub3c4\ub97c \uadfc\uc0ac\ud558\uace0, \uc774\ub97c \ud14c\uc2a4\ud2b8 \uc0d8\ud50c\uc758 \ud2b9\uc9d5 \uacf5\uac04 \ud45c\ud604\uacfc \ube44\uad50\ud558\uc5ec \ubd84\ud3ec \uc774\ub3d9 \uc5ec\ubd80\ub97c \ud310\ub2e8\ud55c\ub2e4.", "result": "2D \ud569\uc131 \ub370\uc774\ud130\uc14b(\ub450 \uac1c\uc758 \ub2ec\uacfc \uc138 \uac1c\uc758 \ub098\uc120) \ubc0f OOD \ud0d0\uc9c0 \uc791\uc5c5(CIFAR-10 \ub300 SVHN)\uc5d0\uc11c \uc2e4\ud5d8\uc744 \uc218\ud589\ud558\uc5ec \uae30\uc874 \ubaa8\ub378\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \uc785\uc99d\ud558\uc600\ub2e4.", "conclusion": "\uc81c\uc548\ub41c \ubc29\ubc95\uc774 \uae30\uc874 \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \ub354 \ud6a8\uacfc\uc801\uc778 \ubd88\ud655\uc2e4\uc131 \uc815\ub7c9\ud654\ub97c \ub2ec\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc900\ub2e4."}}
{"id": "2508.00706", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00706", "abs": "https://arxiv.org/abs/2508.00706", "authors": ["Haozhe Tian", "Pietro Ferraro", "Robert Shorten", "Mahdi Jalili", "Homayoun Hamedmoghadam"], "title": "Learning Network Dismantling without Handcrafted Inputs", "comment": null, "summary": "The application of message-passing Graph Neural Networks has been a\nbreakthrough for important network science problems. However, the competitive\nperformance often relies on using handcrafted structural features as inputs,\nwhich increases computational cost and introduces bias into the otherwise\npurely data-driven network representations. Here, we eliminate the need for\nhandcrafted features by introducing an attention mechanism and utilizing\nmessage-iteration profiles, in addition to an effective algorithmic approach to\ngenerate a structurally diverse training set of small synthetic networks.\nThereby, we build an expressive message-passing framework and use it to\nefficiently solve the NP-hard problem of Network Dismantling, virtually\nequivalent to vital node identification, with significant real-world\napplications. Trained solely on diversified synthetic networks, our proposed\nmodel -- MIND: Message Iteration Network Dismantler -- generalizes to large,\nunseen real networks with millions of nodes, outperforming state-of-the-art\nnetwork dismantling methods. Increased efficiency and generalizability of the\nproposed model can be leveraged beyond dismantling in a range of complex\nnetwork problems.", "AI": {"tldr": "\uba54\uc2dc\uc9c0 \uc804\ud30c \uadf8\ub798\ud504 \uc2e0\uacbd\ub9dd\uc758 \ud601\uc2e0\uc801 \uc801\uc6a9\uc774 \ub124\ud2b8\uc6cc\ud06c \uacfc\ud559 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \ub370 \uae30\uc5ec\ud588\uc9c0\ub9cc, \uc218\uc791\uc5c5\uc73c\ub85c \uc81c\uc791\ud55c \uad6c\uc870\uc801 \ud2b9\uc131\uc758 \uc0ac\uc6a9\uc774 \ud544\uc694\ud588\ub2e4. \ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc218\uc791\uc5c5 \ud2b9\uc131\uc744 \uc5c6\uc560\uace0 \uc8fc\uc758 \uba54\ucee4\ub2c8\uc998\uacfc \uba54\uc2dc\uc9c0 \ubc18\ubcf5 \ud504\ub85c\ud30c\uc77c\uc744 \ub3c4\uc785\ud558\uc5ec MIND \ubaa8\ub378\uc744 \ud1b5\ud574 \ub124\ud2b8\uc6cc\ud06c \ud574\uccb4 \ubb38\uc81c\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \ud574\uacb0\ud55c\ub2e4.", "motivation": "\uba54\uc2dc\uc9c0 \uc804\ud30c \uadf8\ub798\ud504 \uc2e0\uacbd\ub9dd\uc758 \uc131\ub2a5\uc774 \uc218\uc791\uc5c5\uc73c\ub85c \uc81c\uc791\ud55c \uad6c\uc870\uc801 \ud2b9\uc131\uc5d0 \uc758\uc874\ud558\ubbc0\ub85c, \uc774\ub97c \uc81c\uac70\ud558\uace0 \ub370\uc774\ud130 \uae30\ubc18 \uc811\uadfc \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\uace0\uc790 \ud558\uc600\ub2e4.", "method": "\uc8fc\uc758 \uba54\ucee4\ub2c8\uc998\uacfc \uba54\uc2dc\uc9c0 \ubc18\ubcf5 \ud504\ub85c\ud30c\uc77c\uc744 \ud65c\uc6a9\ud558\uc5ec \uad6c\uc870\uc801\uc73c\ub85c \ub2e4\uc591\ud55c \ud6c8\ub828 \uc138\ud2b8\ub97c \uc0dd\uc131\ud558\ub294 \uc54c\uace0\ub9ac\uc998\uc801 \uc811\uadfc \ubc29\uc2dd\uc744 \ub3c4\uc785\ud558\uc600\ub2e4.", "result": "MIND \ubaa8\ub378\uc774 \ub300\uaddc\ubaa8 \ubbf8\uc9c0\uc758 \uc2e4\uc81c \ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc77c\ubc18\ud654\ub418\uba70 \uae30\uc874 \ubc29\ubc95\ub4e4\uc744 \ub6f0\uc5b4\ub118\ub294 \uc131\ub2a5\uc744 \ubcf4\uc600\ub2e4.", "conclusion": "\uc81c\uc548\ub41c \ubaa8\ub378\uc758 \ud6a8\uc728\uc131\uacfc \uc77c\ubc18\ud654 \uac00\ub2a5\uc131\uc740 \ub2e4\uc591\ud55c \ubcf5\uc7a1\ud55c \ub124\ud2b8\uc6cc\ud06c \ubb38\uc81c\uc5d0 \ud65c\uc6a9\ub420 \uc218 \uc788\ub2e4."}}
{"id": "2508.00718", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00718", "abs": "https://arxiv.org/abs/2508.00718", "authors": ["Ivona Krchova", "Mariana Vargas Vieyra", "Mario Scriminaci", "Andrey Sidorenko"], "title": "Democratizing Tabular Data Access with an Open$\\unicode{x2013}$Source Synthetic$\\unicode{x2013}$Data SDK", "comment": null, "summary": "Machine learning development critically depends on access to high-quality\ndata. However, increasing restrictions due to privacy, proprietary interests,\nand ethical concerns have created significant barriers to data accessibility.\nSynthetic data offers a viable solution by enabling safe, broad data usage\nwithout compromising sensitive information. This paper presents the MOSTLY AI\nSynthetic Data Software Development Kit (SDK), an open-source toolkit designed\nspecifically for synthesizing high-quality tabular data. The SDK integrates\nrobust features such as differential privacy guarantees, fairness-aware data\ngeneration, and automated quality assurance into a flexible and accessible\nPython interface. Leveraging the TabularARGN autoregressive framework, the SDK\nsupports diverse data types and complex multi-table and sequential datasets,\ndelivering competitive performance with notable improvements in speed and\nusability. Currently deployed both as a cloud service and locally installable\nsoftware, the SDK has seen rapid adoption, highlighting its practicality in\naddressing real-world data bottlenecks and promoting widespread data\ndemocratization.", "AI": {"tldr": "\uc774 \ub17c\ubb38\uc740 \uac1c\uc778 \uc815\ubcf4 \ubcf4\ud638 \ubc0f \uc724\ub9ac\uc801 \ubb38\uc81c\ub85c \uc778\ud574 \ub370\uc774\ud130 \uc811\uadfc\uc774 \uc5b4\ub824\uc6cc\uc9c4 \uc0c1\ud669\uc5d0\uc11c, \uc548\uc804\ud558\uace0 \uace0\ud488\uc9c8\uc758 \ud569\uc131 \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud558\ub294 MOSTLY AI \ud569\uc131 \ub370\uc774\ud130 \uc18c\ud504\ud2b8\uc6e8\uc5b4 \uac1c\ubc1c \ud0a4\ud2b8\ub97c \uc18c\uac1c\ud55c\ub2e4.", "motivation": "\ub370\uc774\ud130 \uc811\uadfc\uc5d0 \ub300\ud55c \uc81c\ud55c\uc774 \uc99d\uac00\ud558\uace0 \uc788\uc5b4, \uba38\uc2e0\ub7ec\ub2dd \uac1c\ubc1c\uc5d0 \uc788\uc5b4 \uace0\ud488\uc9c8 \ub370\uc774\ud130\uc758 \uc911\uc694\uc131\uc774 \uac15\uc870\ub418\uace0 \uc788\ub2e4.", "method": "MOSTLY AI \ud569\uc131 \ub370\uc774\ud130 SDK\ub294 \ub2e4\uc591\ud55c \ub370\uc774\ud130 \uc720\ud615\uacfc \ubcf5\uc7a1\ud55c \ub2e4\uc911 \ud14c\uc774\ube14 \ubc0f \uc5f0\uc18d \ub370\uc774\ud130 \uc138\ud2b8\ub97c \uc9c0\uc6d0\ud558\uba70, \ucc28\ub4f1 \uac1c\uc778 \uc815\ubcf4 \ubcf4\ud638 \ubc0f \uacf5\uc815\uc131\uc744 \uace0\ub824\ud55c \ub370\uc774\ud130 \uc0dd\uc131\uc744 \ud2b9\uc9d5\uc73c\ub85c \ud55c\ub2e4.", "result": "SDK\ub294 \ub192\uc740 \uc131\ub2a5\uacfc \uac1c\uc120\ub41c \uc18d\ub3c4 \ubc0f \uc0ac\uc6a9\uc131\uc744 \uc81c\uacf5\ud558\uba70, \ud074\ub77c\uc6b0\ub4dc \uc11c\ube44\uc2a4\uc640 \ub85c\uceec \uc124\uce58\ud615 \uc18c\ud504\ud2b8\uc6e8\uc5b4\ub85c \ubc30\ud3ec\ub418\uc5b4 \ube60\ub978 \ucc44\ud0dd\uc744 \ubcf4\uace0\ud558\uace0 \uc788\ub2e4.", "conclusion": "\uc774 SDK\ub294 \ud604\uc2e4\uc758 \ub370\uc774\ud130 \ubcd1\ubaa9 \ud604\uc0c1\uc744 \ud574\uacb0\ud558\uace0 \ub370\uc774\ud130 \ubbfc\uc8fc\ud654\ub97c \ucd09\uc9c4\ud558\ub294 \ub370 \uc2e4\uc9c8\uc801\uc778 \uae30\uc5ec\ub97c \ud558\uace0 \uc788\ub2e4."}}
{"id": "2508.00758", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00758", "abs": "https://arxiv.org/abs/2508.00758", "authors": ["Timur Sattarov", "Marco Schreyer", "Damian Borth"], "title": "Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data", "comment": "22 pages, 16 figures, 7 tables, preprint version", "summary": "Anomaly detection in tabular data remains challenging due to complex feature\ninteractions and the scarcity of anomalous examples. Denoising autoencoders\nrely on fixed-magnitude noise, limiting adaptability to diverse data\ndistributions. Diffusion models introduce scheduled noise and iterative\ndenoising, but lack explicit reconstruction mappings. We propose the\nDiffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates\ndiffusion-based noise scheduling and contrastive learning into the encoding\nprocess to improve anomaly detection. We evaluated DDAE on 57 datasets from\nADBench. Our method outperforms in semi-supervised settings and achieves\ncompetitive results in unsupervised settings, improving PR-AUC by up to 65%\n(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)\nmodel baselines. We observed that higher noise levels benefit unsupervised\ntraining, while lower noise with linear scheduling is optimal in\nsemi-supervised settings. These findings underscore the importance of\nprincipled noise strategies in tabular anomaly detection.", "AI": {"tldr": "DDAE \ubaa8\ub378\uc774 \ubc18\uc790\ub3d9 \ubc0f \uc790\ub3d9 \uc124\uc815\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubc1c\ud718\ud558\uba70, \uc7a1\uc74c \uc804\ub7b5\uc774 \uc911\uc694\ud568\uc744 \uc785\uc99d\ud55c\ub2e4.", "motivation": "\ud45c \ub370\uc774\ud130\uc5d0\uc11c \uc774\uc0c1 \ud0d0\uc9c0\ub294 \ubcf5\uc7a1\ud55c \ud2b9\uc131 \uc0c1\ud638\uc791\uc6a9 \ubc0f \uc774\uc0c1 \uc0ac\ub840\uc758 \ubd80\uc871\uc73c\ub85c \uc5ec\uc804\ud788 \ub3c4\uc804\uc801\uc774\ub2e4.", "method": "Diffusion-Scheduled Denoising Autoencoder(DDAE)\ub77c\ub294 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uc548\ud558\uba70, \uc774\ub294 \ud655\uc0b0 \uae30\ubc18 \uc7a1\uc74c \uc77c\uc815\ud654\uc640 \ub300\uc870 \ud559\uc2b5\uc744 \uc778\ucf54\ub529 \ud504\ub85c\uc138\uc2a4\uc5d0 \ud1b5\ud569\ud55c\ub2e4.", "result": "57\uac1c\uc758 ADBench \ub370\uc774\ud130\uc14b\uc5d0\uc11c DDAE\uac00 \ubc18\uc790\ub3d9 \uc124\uc815\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc600\uc73c\uba70, \uc790\ub3d9 \uc124\uc815\uc5d0\uc11c\ub3c4 \uacbd\uc7c1\ub825\uc744 \uc720\uc9c0\ud558\uc5ec \uae30\uc874 \ubaa8\ub378 \ub300\ube44 PR-AUC\uac00 \ucd5c\ub300 65% \ud5a5\uc0c1\ub418\uc5c8\ub2e4.", "conclusion": "\uc6d0\uce59\uc801 \uc7a1\uc74c \uc804\ub7b5\uc774 \ud45c \ud615\uc2dd \uc774\uc0c1 \ud0d0\uc9c0\uc5d0\uc11c \uc911\uc694\ud568\uc744 \uac15\uc870\ud55c\ub2e4."}}
{"id": "2508.00768", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00768", "abs": "https://arxiv.org/abs/2508.00768", "authors": ["Antonio Tudisco", "Andrea Marchesin", "Maurizio Zamboni", "Mariagrazia Graziano", "Giovanna Turvani"], "title": "Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy", "comment": null, "summary": "Recent advancements in Quantum Computing and Machine Learning have increased\nattention to Quantum Machine Learning (QML), which aims to develop machine\nlearning models by exploiting the quantum computing paradigm. One of the widely\nused models in this area is the Variational Quantum Circuit (VQC), a hybrid\nmodel where the quantum circuit handles data inference while classical\noptimization adjusts the parameters of the circuit. The quantum circuit\nconsists of an encoding layer, which loads data into the circuit, and a\ntemplate circuit, known as the ansatz, responsible for processing the data.\nThis work involves performing an analysis by considering both Amplitude- and\nAngle-encoding models, and examining how the type of rotational gate applied\naffects the classification performance of the model. This comparison is carried\nout by training the different models on two datasets, Wine and Diabetes, and\nevaluating their performance. The study demonstrates that, under identical\nmodel topologies, the difference in accuracy between the best and worst models\nranges from 10% to 30%, with differences reaching up to 41%. Moreover, the\nresults highlight how the choice of rotational gates used in encoding can\nsignificantly impact the model's classification performance. The findings\nconfirm that the embedding represents a hyperparameter for VQC models.", "AI": {"tldr": "\uc591\uc790 \uae30\uacc4 \ud559\uc2b5(QML)\uc5d0 \ub300\ud55c \uc5f0\uad6c\ub85c, \ubcc0\ubcc4\uc801\uc778 \uc591\uc790 \ud68c\ub85c(VQC) \ubaa8\ub378\uc774 \ub370\uc774\ud130 \uc778\ud37c\ub7f0\uc2a4\ub97c \ucc98\ub9ac\ud558\uace0, \uace0\uc804\uc801 \ucd5c\uc801\ud654\uac00 \ud68c\ub85c\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc870\uc815\ud558\uc5ec \ubd84\ub958 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\uc600\ub2e4.", "motivation": "\uc591\uc790 \ucef4\ud4e8\ud305\uacfc \uba38\uc2e0 \ub7ec\ub2dd\uc758 \ubc1c\uc804\uc73c\ub85c \uc591\uc790 \uba38\uc2e0 \ub7ec\ub2dd(QML)\uc774 \uc8fc\ubaa9\ubc1b\uace0 \uc788\ub2e4.", "method": "\ubcc0\ubcc4\uc801\uc778 \uc591\uc790 \ud68c\ub85c(VQC) \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec Amplitude- \ubc0f Angle-encoding \ubaa8\ub378\uc744 \uace0\ub824\ud558\uace0 \ud68c\uc804 \uac8c\uc774\ud2b8\uc758 \uc720\ud615\uc774 \ubd84\ub958 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\uc600\ub2e4.", "result": "\uc640\uc778\uacfc \ub2f9\ub1e8\ubcd1 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0\uc11c \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\uc5ec, \ucd5c\uace0\uc758 \ubaa8\ub378\uacfc \ucd5c\uc545\uc758 \ubaa8\ub378 \uac04 \uc815\ud655\ub3c4 \ucc28\uc774\uac00 10%\uc5d0\uc11c 30%\uae4c\uc9c0, \ucd5c\ub300 41%\uc5d0 \uc774\ub974\ub294 \uac83\uc744 \ud655\uc778\ud558\uc600\ub2e4.", "conclusion": "\ud68c\uc804 \uac8c\uc774\ud2b8 \uc120\ud0dd\uc774 \ubaa8\ub378\uc758 \ubd84\ub958 \uc131\ub2a5\uc5d0 \uc911\ub300\ud55c \uc601\ud5a5\uc744 \ubbf8\uce58\uba70, \ub9e4\ud551\uc740 VQC \ubaa8\ub378\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub85c \uc791\uc6a9\ud568\uc744 \ud655\uc778\ud558\uc600\ub2e4."}}
{"id": "2508.00785", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00785", "abs": "https://arxiv.org/abs/2508.00785", "authors": ["Bushra Akter", "Md Biplob Hosen", "Sabbir Ahmed", "Mehrin Anannya", "Md. Farhad Hossain"], "title": "Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors", "comment": null, "summary": "Academic performance depends on a multivariable nexus of socio-academic and\nfinancial factors. This study investigates these influences to develop\neffective strategies for optimizing students' CGPA. To achieve this, we\nreviewed various literature to identify key influencing factors and constructed\nan initial hypothetical causal graph based on the findings. Additionally, an\nonline survey was conducted, where 1,050 students participated, providing\ncomprehensive data for analysis. Rigorous data preprocessing techniques,\nincluding cleaning and visualization, ensured data quality before analysis.\nCausal analysis validated the relationships among variables, offering deeper\ninsights into their direct and indirect effects on CGPA. Regression models were\nimplemented for CGPA prediction, while classification models categorized\nstudents based on performance levels. Ridge Regression demonstrated strong\npredictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared\nError of 0.023. Random Forest outperformed in classification, attaining an\nF1-score near perfection and an accuracy of 98.68%. Explainable AI techniques\nsuch as SHAP, LIME, and Interpret enhanced model interpretability, highlighting\ncritical factors such as study hours, scholarships, parental education, and\nprior academic performance. The study culminated in the development of a\nweb-based application that provides students with personalized insights,\nallowing them to predict academic performance, identify areas for improvement,\nand make informed decisions to enhance their outcomes.", "AI": {"tldr": "\ud559\uc0dd\ub4e4\uc758 CGPA\ub97c \ucd5c\uc801\ud654\ud558\uae30 \uc704\ud55c \ub2e4\ubcc0\ub7c9 \ubd84\uc11d \ubc0f \uc608\uce21 \ubaa8\ub378 \uac1c\ubc1c \uc5f0\uad6c.", "motivation": "\ud559\uc0dd\ub4e4\uc758 \ud559\uc5c5 \uc131\ucde8\ub3c4\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \uc0ac\ud68c\uc801, \ud559\ubb38\uc801, \uc7ac\uc815\uc801 \uc694\uc778\uc744 \uc870\uc0ac\ud558\uace0 \ud6a8\uacfc\uc801\uc778 \uc804\ub7b5\uc744 \uac1c\ubc1c\ud558\uae30 \uc704\ud568.", "method": "\ubb38\ud5cc \uac80\ud1a0\ub97c \ud1b5\ud55c \uc694\uc778 \ubd84\uc11d, 1,050\uba85 \ub300\uc0c1 \uc628\ub77c\uc778 \uc124\ubb38 \uc870\uc0ac, \ub370\uc774\ud130 \uc804\ucc98\ub9ac, \uc778\uacfc \ubd84\uc11d, \ud68c\uadc0 \ubc0f \ubd84\ub958 \ubaa8\ub378 \uc0ac\uc6a9.", "result": "Ridge Regression\uc758 MAE 0.12, MSE 0.023, Random Forest\uc758 F1-score 98.68% \ub2ec\uc131.", "conclusion": "\ud559\uc0dd \uac1c\uc778 \ub9de\ucda4\ud615 \ud559\uc5c5 \uc131\ucde8 \uc608\uce21 \ubc0f \uac1c\uc120\uc744 \uc704\ud55c \uc6f9 \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uac1c\ubc1c."}}
{"id": "2508.00806", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.00806", "abs": "https://arxiv.org/abs/2508.00806", "authors": ["Ping Chen", "Zhuohong Deng", "Ping Li", "Shuibing He", "Hongzi Zhu", "Yi Zheng", "Zhefeng Wang", "Baoxing Huai", "Minyi Guo"], "title": "Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management", "comment": "8 pages", "summary": "Training large language models often employs recomputation to alleviate\nmemory pressure, which can introduce up to 30% overhead in real-world\nscenarios. In this paper, we propose Adacc, a novel memory management framework\nthat combines adaptive compression and activation checkpointing to reduce the\nGPU memory footprint. It comprises three modules: (1) We design layer-specific\ncompression algorithms that account for outliers in LLM tensors, instead of\ndirectly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We\npropose an optimal scheduling policy that employs MILP to determine the best\nmemory optimization for each tensor. (3) To accommodate changes in training\ntensors, we introduce an adaptive policy evolution mechanism that adjusts the\npolicy during training to enhance throughput. Experimental results show that\nAdacc can accelerate the LLM training by 1.01x to 1.37x compared to\nstate-of-the-art frameworks, while maintaining comparable model accuracy to the\nBaseline.", "AI": {"tldr": "Adacc\ub294 \uc801\uc751\ud615 \uc555\ucd95 \ubc0f \ud65c\uc131\ud654 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uacb0\ud569\ud558\uc5ec \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378 \ud6c8\ub828 \uc2dc GPU \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \uc904\uc774\ub294 \uba54\ubaa8\ub9ac \uad00\ub9ac \ud504\ub808\uc784\uc6cc\ud06c\uc774\ub2e4.", "motivation": "\ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378 \ud6c8\ub828\uc5d0\uc11c \uba54\ubaa8\ub9ac \uc555\ubc15\uc744 \uc904\uc774\uae30 \uc704\ud574 \uc7ac\uacc4\uc0b0\uc744 \uc0ac\uc6a9\ud558\uc9c0\ub9cc, \uc774\ub294 \uc2e4\uc81c \uc0c1\ud669\uc5d0\uc11c \ucd5c\ub300 30%\uc758 \uc624\ubc84\ud5e4\ub4dc\ub97c \ucd08\ub798\ud560 \uc218 \uc788\ub2e4.", "method": "Adacc\ub294 \ub808\uc774\uc5b4\ubcc4 \uc555\ucd95 \uc54c\uace0\ub9ac\uc998, \ucd5c\uc801 \uc2a4\ucf00\uc904\ub9c1 \uc815\ucc45(MILP \uc0ac\uc6a9) \ubc0f \uc801\uc751\ud615 \uc815\ucc45 \uc9c4\ud654 \uba54\ucee4\ub2c8\uc998\uc744 \ud3ec\ud568\ud55c\ub2e4.", "result": "Adacc\ub294 \ucd5c\uc2e0 \ud504\ub808\uc784\uc6cc\ud06c\uc5d0 \ube44\ud574 LLM \ud6c8\ub828 \uc18d\ub3c4\ub97c 1.01\ubc30\uc5d0\uc11c 1.37\ubc30 \ud5a5\uc0c1\uc2dc\ud0a4\uba70, \ubaa8\ub378 \uc815\ud655\ub3c4\ub97c \uc720\uc9c0\ud55c\ub2e4.", "conclusion": "Adacc\ub294 \uba54\ubaa8\ub9ac \ucd5c\uc801\ud654\ub97c \ud1b5\ud574 \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378 \ud6c8\ub828\uc5d0\uc11c \ud6a8\uc728\uc131\uc744 \ub192\uc778\ub2e4."}}
