<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 13]
- [cs.MA](#cs.MA) [Total: 8]
- [cs.AI](#cs.AI) [Total: 34]
- [cs.LG](#cs.LG) [Total: 53]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Generative AI for Biosciences: Emerging Threats and Roadmap to Biosecurity](https://arxiv.org/abs/2510.15975)
*Zaixi Zhang,Souradip Chakraborty,Amrit Singh Bedi,Emilin Mathew,Varsha Saravanan,Le Cong,Alvaro Velasquez,Sheng Lin-Gibson,Megan Blewett,Dan Hendrycs,Alex John London,Ellen Zhong,Ben Raphael,Jian Ma,Eric Xing,Russ Altman,George Church,Mengdi Wang*

Main category: cs.CR

TL;DR: 생명과학에서의 생성 인공지능(GenAI) 채택이 급격히 증가하고 있으며, 이는 생명공학, 의학 및 합성 생물학을 변화시키고 있다. 그러나 이러한 발전은 새로운 취약점과 함께하며, AI의 남용 가능성과 생물보안 위협을 증가시킨다. 이는 규제와 감독의 긴급한 공백을 드러내며, GenAI 안전성을 위한 다층적 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 생명과학에서 GenAI의 빠른 채택이 생명공학 및 의학 분야에 미치는 영향을 분석하고, 새로운 생물보안 위협을 이해하기 위함.

Method: 모든 분야의 130명 전문가와의 인터뷰를 통해 GenAI 사용에 대한 우려와 새로운 거버넌스 프레임워크의 필요성을 조사하고, GenAI 안전성 강화를 위한 기술적 경로를 탐구한다.

Result: 대다수의 전문가들이 생물학에서 AI의 남용에 대한 우려를 표명하였고, 새로운 거버넌스 프레임워크 개발의 필요성을 강조하였다.

Conclusion: 생명과학에 GenAI가 통합됨에 따라, 적응적인 거버넌스와 보안 설계 기술에 대한 즉각적인 지원이 필요하다.

Abstract: The rapid adoption of generative artificial intelligence (GenAI) in the
biosciences is transforming biotechnology, medicine, and synthetic biology. Yet
this advancement is intrinsically linked to new vulnerabilities, as GenAI
lowers the barrier to misuse and introduces novel biosecurity threats, such as
generating synthetic viral proteins or toxins. These dual-use risks are often
overlooked, as existing safety guardrails remain fragile and can be
circumvented through deceptive prompts or jailbreak techniques. In this
Perspective, we first outline the current state of GenAI in the biosciences and
emerging threat vectors ranging from jailbreak attacks and privacy risks to the
dual-use challenges posed by autonomous AI agents. We then examine urgent gaps
in regulation and oversight, drawing on insights from 130 expert interviews
across academia, government, industry, and policy. A large majority ($\approx
76$\%) expressed concern over AI misuse in biology, and 74\% called for the
development of new governance frameworks. Finally, we explore technical
pathways to mitigation, advocating a multi-layered approach to GenAI safety.
These defenses include rigorous data filtering, alignment with ethical
principles during development, and real-time monitoring to block harmful
requests. Together, these strategies provide a blueprint for embedding security
throughout the GenAI lifecycle. As GenAI becomes integrated into the
biosciences, safeguarding this frontier requires an immediate commitment to
both adaptive governance and secure-by-design technologies.

</details>


### [2] [MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents](https://arxiv.org/abs/2510.15994)
*Dongsen Zhang,Zekun Li,Xu Luo,Xuannan Liu,Peipei Li,Wenjun Xu*

Main category: cs.CR

TL;DR: MCP는 대형 언어 모델(LLM) 에이전트가 외부 도구를 발견하고 설명하며 호출하는 방식을 표준화하며, MSB는 MCP 특정 공격에 대한 LLM 에이전트의 내성을 측정하는 최초의 종단 간 평가 도구이다.


<details>
  <summary>Details</summary>
Motivation: MCP는 LLM 에이전트와 외부 도구 간의 호환성을 증진하지만, 공격 표면을 확대하여 보안 위험을 증가시킨다.

Method: MSB는 12가지 공격 유형과 이들을 실행하기 위한 실제 도구를 사용하는 평가 도구를 제공하며, 보안과 성능 간의 트레이드오프를 정량화하는 강건성 메트릭을 포함한다.

Result: MSB는 9개의 대중적인 LLM 에이전트를 평가하여 2,000개의 공격 인스턴스를 생성하며, 각 MCP 단계에 대한 공격의 효과성을 보여준다.

Conclusion: MSB는 연구자와 실무자가 MCP 에이전트를 연구 및 강화하는 데 실용적인 기준을 제공한다.

Abstract: The Model Context Protocol (MCP) standardizes how large language model (LLM)
agents discover, describe, and call external tools. While MCP unlocks broad
interoperability, it also enlarges the attack surface by making tools
first-class, composable objects with natural-language metadata, and
standardized I/O. We present MSB (MCP Security Benchmark), the first end-to-end
evaluation suite that systematically measures how well LLM agents resist
MCP-specific attacks throughout the full tool-use pipeline: task planning, tool
invocation, and response handling. MSB contributes: (1) a taxonomy of 12
attacks including name-collision, preference manipulation, prompt injections
embedded in tool descriptions, out-of-scope parameter requests,
user-impersonating responses, false-error escalation, tool-transfer, retrieval
injection, and mixed attacks; (2) an evaluation harness that executes attacks
by running real tools (both benign and malicious) via MCP rather than
simulation; and (3) a robustness metric that quantifies the trade-off between
security and performance: Net Resilient Performance (NRP). We evaluate nine
popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack
instances. Results reveal the effectiveness of attacks against each stage of
MCP. Models with stronger performance are more vulnerable to attacks due to
their outstanding tool calling and instruction following capabilities. MSB
provides a practical baseline for researchers and practitioners to study,
compare, and harden MCP agents.

</details>


### [3] [PrivacyPAD: A Reinforcement Learning Framework for Dynamic Privacy-Aware Delegation](https://arxiv.org/abs/2510.16054)
*Zheng Hui,Yijiang River Dong,Sanhanat Sivapiromrat,Ehsan Shareghi,Nigel Collier*

Main category: cs.CR

TL;DR: 이 논문은 민감한 데이터를 포함할 수 있는 사용자 쿼리에 대한 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 사용자가 대규모 언어 모델(LLM)에 쿼리를 제출할 때 민감한 데이터를 포함할 수 있어, 데이터 노출 위험 없이 성능을 극대화할 수 있는 방법이 필요합니다.

Method: 우리는 이 문제를 순차적 결정 문제로 재구성하고, 이를 해결하기 위해 PrivacyPAD라는 새로운 강화 학습 프레임워크를 도입합니다.

Result: 우리의 프레임워크는 텍스트 조각을 동적으로 라우팅하고, 개인 식별 정보(PII)와 작업에 중요한 PII를 구별하여 최적의 정책을 학습합니다.

Conclusion: 이 프레임워크는 복잡한 시나리오에서 검증되었으며, 민감한 환경에서 LLM을 배포하는 데 있어 학습된 적응형 정책의 필요성을 입증합니다.

Abstract: When users submit queries to Large Language Models (LLMs), their prompts can
often contain sensitive data, forcing a difficult choice: Send the query to a
powerful proprietary LLM providers to achieving state-of-the-art performance
and risk data exposure, or relying on smaller, local models guarantees data
privacy but often results in a degradation of task performance. Prior
approaches have relied on static pipelines that use LLM rewriting, which
shatters linguistic coherence and indiscriminately removes privacy-sensitive
information, including task-critical content. We reformulate this challenge
(Privacy-Conscious Delegation) as a sequential decision-making problem and
introduce a novel reinforcement learning (RL) framework called PrivacyPAD to
solve it. Our framework trains an agent to dynamically route text chunks,
learning a policy that optimally balances the trade-off between privacy leakage
and task performance. It implicitly distinguishes between replaceable
Personally Identifiable Information (PII) (which it shields locally) and
task-critical PII (which it strategically sends to the remote model for maximal
utility). To validate our approach in complex scenarios, we also introduce a
new medical dataset with high PII density. Our framework achieves a new
state-of-the-art on the privacy-utility frontier, demonstrating the necessity
of learned, adaptive policies for deploying LLMs in sensitive environments.

</details>


### [4] [SentinelNet: Safeguarding Multi-Agent Collaboration Through Credit-Based Dynamic Threat Detection](https://arxiv.org/abs/2510.16219)
*Yang Feng,Xudong Pan*

Main category: cs.CR

TL;DR: SentinelNet은 다중 에이전트 협력을 위한 첫 번째 분산 프레임워크로, 악의적인 행동을 사전에 탐지하고 완화하는 데 초점을 맞춘다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)으로 구동되는 다중 에이전트 시스템(MAS)의 신뢰성과 의사결정 능력에 대한 악의적인 요인의 위협을 해결하기 위해.

Method: SentinelNet은 각 에이전트에 대한 신용 기반 탐지기를 제공하고, 대립적 학습을 통해 훈련된 증강된 적대적 논쟁 경로에서 메시지 신뢰도를 자율적으로 평가하며, 악의적인 통신을 억제하기 위해 동적 이웃 순위를 결정한다.

Result: SentinelNet은 두 번의 논쟁 라운드 내에 100%에 가깝게 악의적인 에이전트를 탐지하고, 손상된 기준선으로부터 95%의 시스템 정확도를 회복한다.

Conclusion: SentinelNet은 도메인과 공격 패턴 전반에 걸쳐 강력한 일반화 능력을 보여주며, 협업 MAS을 보호하기 위한 새로운 패러다임을 제시한다.

Abstract: Malicious agents pose significant threats to the reliability and
decision-making capabilities of Multi-Agent Systems (MAS) powered by Large
Language Models (LLMs). Existing defenses often fall short due to reactive
designs or centralized architectures which may introduce single points of
failure. To address these challenges, we propose SentinelNet, the first
decentralized framework for proactively detecting and mitigating malicious
behaviors in multi-agent collaboration. SentinelNet equips each agent with a
credit-based detector trained via contrastive learning on augmented adversarial
debate trajectories, enabling autonomous evaluation of message credibility and
dynamic neighbor ranking via bottom-k elimination to suppress malicious
communications. To overcome the scarcity of attack data, it generates
adversarial trajectories simulating diverse threats, ensuring robust training.
Experiments on MAS benchmarks show SentinelNet achieves near-perfect detection
of malicious agents, close to 100% within two debate rounds, and recovers 95%
of system accuracy from compromised baselines. By exhibiting strong
generalizability across domains and attack patterns, SentinelNet establishes a
novel paradigm for safeguarding collaborative MAS.

</details>


### [5] [Detecting Adversarial Fine-tuning with Auditing Agents](https://arxiv.org/abs/2510.16255)
*Sarah Egler,John Schulman,Nicholas Carlini*

Main category: cs.CR

TL;DR: 대규모 언어 모델(LLM)의 미세 조정 API를 사용하는 데 있어, 공격자가 악의적인 미세 조정을 수행하고 이를 탐지하는 것이 어렵다는 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 미세 조정 API를 통해 LLM을 공격할 수 있는 가능성과 그로 인해 발생하는 안전성 문제를 해결하고자 한다.

Method: 미세 조정 감사 에이전트를 도입하여 미세 조정 작업에 대한 위험 점수를 부여하고, 다양한 미세 조정 공격에 대한 탐지 접근 방식을 평가한다.

Result: 우리는 1400건 이상의 독립 감사를 수행하며, 최적의 설정에서 56.2%의 탐지율을 달성하고, 안전 평가를 회피하는 공격을 탐지할 수 있었다.

Conclusion: 비의도적인 안전성 저하가 있는 미세 조정 작업 탐지의 어려움에도 불구하고, 우리는 이 분야의 추가 연구를 위한 기준 구성을 수립하였다.

Abstract: Large Language Model (LLM) providers expose fine-tuning APIs that let end
users fine-tune their frontier LLMs. Unfortunately, it has been shown that an
adversary with fine-tuning access to an LLM can bypass safeguards. Particularly
concerning, such attacks may avoid detection with datasets that are only
implicitly harmful. Our work studies robust detection mechanisms for
adversarial use of fine-tuning APIs. We introduce the concept of a fine-tuning
auditing agent and show it can detect harmful fine-tuning prior to model
deployment. We provide our auditing agent with access to the fine-tuning
dataset, as well as the fine-tuned and pre-fine-tuned models, and request the
agent assigns a risk score for the fine-tuning job. We evaluate our detection
approach on a diverse set of eight strong fine-tuning attacks from the
literature, along with five benign fine-tuned models, totaling over 1400
independent audits. These attacks are undetectable with basic content
moderation on the dataset, highlighting the challenge of the task. With the
best set of affordances, our auditing agent achieves a 56.2% detection rate of
adversarial fine-tuning at a 1% false positive rate. Most promising, the
auditor is able to detect covert cipher attacks that evade safety evaluations
and content moderation of the dataset. While benign fine-tuning with
unintentional subtle safety degradation remains a challenge, we establish a
baseline configuration for further work in this area. We release our auditing
agent at https://github.com/safety-research/finetuning-auditor.

</details>


### [6] [A Versatile Framework for Designing Group-Sparse Adversarial Attacks](https://arxiv.org/abs/2510.16637)
*Alireza Heshmati,Saman Soleimani Roudi,Sajjad Amini,Shahrokh Ghaemmaghami,Farokh Marvasti*

Main category: cs.CR

TL;DR: ATOS는 구조적이고 희소한 적대적 변동을 생성하는 차별화 가능한 최적화 프레임워크를 제안하며, 이를 통해 이미지 분류기에서 고성능 공격을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 적대적 공격은 변동 희소성을 간과하여 구조적 변화를 모델링하는 능력을 제한하고, 딥 뉴럴 네트워크(DNN)가 의미 있는 입력 패턴을 처리하는 방법을 설명하는 데 어려움을 겪는다.

Method: ATOS(Overlapping Sparsity를 통한 공격)는 엘리먼트 단위, 픽셀 단위, 그룹 단위로 구조적이고 희소한 적대적 변동을 생성하는 차별화 가능한 최적화 프레임워크이다. 이미지 분류기에 대한 화이트박스 공격을 위해, 희소하고 구조화된 변동을 장려하면서 고정점으로 수렴하도록 하는 Overlapping Smoothed L0 (OSL0) 함수를 도입한다.

Result: CIFAR-10과 ImageNet에서 ATOS는 100% 공격 성공률을 달성하면서 이전 방법보다 훨씬 더 희소하고 구조적으로 일관된 변동을 생성한다.

Conclusion: 구조적 그룹 단위 공격은 네트워크 관점에서 중요한 영역을 강조하며, 클래스 정의 영역을 목표 클래스의 강력한 특징으로 교체하여 반사실적 설명을 제공한다.

Abstract: Existing adversarial attacks often neglect perturbation sparsity, limiting
their ability to model structural changes and to explain how deep neural
networks (DNNs) process meaningful input patterns. We propose ATOS (Attack
Through Overlapping Sparsity), a differentiable optimization framework that
generates structured, sparse adversarial perturbations in element-wise,
pixel-wise, and group-wise forms. For white-box attacks on image classifiers,
we introduce the Overlapping Smoothed L0 (OSL0) function, which promotes
convergence to a stationary point while encouraging sparse, structured
perturbations. By grouping channels and adjacent pixels, ATOS improves
interpretability and helps identify robust versus non-robust features. We
approximate the L-infinity gradient using the logarithm of the sum of
exponential absolute values to tightly control perturbation magnitude. On
CIFAR-10 and ImageNet, ATOS achieves a 100% attack success rate while producing
significantly sparser and more structurally coherent perturbations than prior
methods. The structured group-wise attack highlights critical regions from the
network's perspective, providing counterfactual explanations by replacing
class-defining regions with robust features from the target class.

</details>


### [7] [Quantum Key Distribution for Virtual Power Plant Communication: A Lightweight Key-Aware Scheduler with Provable Stability](https://arxiv.org/abs/2510.17087)
*Ziqing Zhu*

Main category: cs.CR

TL;DR: 이 논문은 양자 키 분배를 활용한 가상 발전소의 키 관리 방안을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 가상 발전소(VPP)가 미래 전력망의 핵심이 되면서 통신 보안이 점점 더 중요한 운영 제약이 되고 있다.

Method: 양자 키를 일급 스케줄링 자원으로 간주하는 키 인식 우선 순위 및 쿼터 프레임워크를 제안하며, 장기 및 단기 할당, 키 인식 결핍 라운드 로빈 중재, 비상 키 예비, 암호화 모드 전환 등을 결합한다.

Result: 제안된 방식은 비핵심 트래픽에 대해 하강 연속성 및 지연을 개선하며, 주요 메시지의 꼬리 지연 및 수동 타임아웃을 일관되게 줄인다.

Conclusion: 이 연구는 양자 키 사용 시 전력 추적 신뢰성을 높이고, VPP 시스템의 항목 별 키 활용도를 개선하는 것을 보여준다.

Abstract: Virtual power plants (VPPs) are becoming a cornerstone of future grids,
aggregating distributed PV, wind, storage, and flexible loads for market
participation and real-time balancing. As operations move to minute-- and
second--level feedback, communication security shifts from a compliance item to
an operational constraint: latency, reliability, and confidentiality jointly
determine whether dispatch, protection, and settlement signals arrive on time.
Conventional PKI and key-rotation schemes struggle with cross-domain,
high-frequency messaging and face long-term quantum threats. Quantum key
distribution (QKD) offers information-theoretic key freshness, but its key
yield is scarce and stochastic, often misaligned with bursty VPP traffic. This
paper proposes a key-aware priority and quota framework that treats quantum
keys as first-class scheduling resources. The design combines (i)
forecast-driven long-term quotas and short-term tokens, (ii) key-aware
deficit-round-robin arbitration, (iii) a preemptive emergency key reserve, and
(iv) graceful degradation via encryption-mode switching and controlled
down-sampling for non-critical traffic. A drift-plus-penalty analysis
establishes strong stability under average supply--demand balance with
quantifiable bounds on backlog and tail latency, providing interpretable
operating guarantees. We build a reproducible testbed on IEEE 33- and 123-bus
VPP systems and evaluate normal, degraded, and outage regimes with
industry-consistent message classes and TTLs. Against FIFO, fixed-priority, and
static-quota baselines, the proposed scheme consistently reduces tail delay and
passive timeouts for critical messages, improves per-bit key utility, and
enhances power-tracking reliability during key scarcity and regime switches.

</details>


### [8] [Can Transformer Memory Be Corrupted? Investigating Cache-Side Vulnerabilities in Large Language Models](https://arxiv.org/abs/2510.17098)
*Elias Hossain,Swayamjit Saha,Somshubhra Roy,Ravi Prasad*

Main category: cs.CR

TL;DR: 변환기 언어 모델은 KV 캐시로 인해 공격에 취약하다. 본 논문은 MTI라는 새로운 프레임워크를 소개하며, 이를 통해 캐시된 키 벡터를 조작할 수 있다. 실험 결과, MTI는 다음 토큰 분포와 작업 성능에 중대한 영향을 미친다.


<details>
  <summary>Details</summary>
Motivation: 프롬프트와 매개변수가 안전할 때에도, 변환기 언어 모델의 KV 캐시는 공격의 취약점으로 남아있기 때문에 이를 해결할 필요성이 있다.

Method: MTI라는 모듈형 프레임워크를 사용하여 선택된 레이어와 시점에서 캐시된 키 벡터를 제어된 크기와 주파수로 섭동시킨다. 여기서는 가우시안 노이즈 추가, 제로화 및 직교 회전을 사용한다.

Result: MTI는 GPT-2와 LLaMA-2/7B에서 다음 토큰 분포와 작업 성능을 유의미하게 변화시킨다.

Conclusion: 이 연구는 캐시 무결성이 현재 LLM 배포의 중요한 그러나 탐구가 부족한 취약점임을 강조하며, 캐시 손상을 향후 Robustness와 Security 연구를 위한 재현 가능하고 이론적으로 기반한 위협 모델로 위치시킨다.

Abstract: Even when prompts and parameters are secured, transformer language models
remain vulnerable because their key-value (KV) cache during inference
constitutes an overlooked attack surface. This paper introduces Malicious Token
Injection (MTI), a modular framework that systematically perturbs cached key
vectors at selected layers and timesteps through controlled magnitude and
frequency, using additive Gaussian noise, zeroing, and orthogonal rotations. A
theoretical analysis quantifies how these perturbations propagate through
attention, linking logit deviations to the Frobenius norm of corruption and
softmax Lipschitz dynamics. Empirical results show that MTI significantly
alters next-token distributions and downstream task performance across GPT-2
and LLaMA-2/7B, as well as destabilizes retrieval-augmented and agentic
reasoning pipelines. These findings identify cache integrity as a critical yet
underexplored vulnerability in current LLM deployments, positioning cache
corruption as a reproducible and theoretically grounded threat model for future
robustness and security research.

</details>


### [9] [QRïS: A Preemptive Novel Method for Quishing Detection Through Structural Features of QR](https://arxiv.org/abs/2510.17175)
*Muhammad Wahid Akram,Keshav Sood,Muneeb Ul Hassan*

Main category: cs.CR

TL;DR: QR 코드의 구조적 분석을 통한 고찰로 피싱 QR 코드를 식별하는 새로운 분류 방법 QR"iS를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 빠르고 편리한 커뮤니케이션을 위해 QR 코드 사용 증가로 인해 사이버 범죄자들이 QR 코드를 악용해 피싱 공격을 강화하고 있다.

Method: QR 코드의 레이아웃 패턴에서 24개의 구조적 특징을 추출하는 알고리즘을 개발하고, 기계 학습 모델을 교육하여 분류한다.

Result: 최대 83.18%의 정확도로 피싱 QR 코드를 식별하는 데 성공하였다.

Conclusion: 실제 적용 가능성을 증명하기 위해 모바일 앱을 개발하였으며, 이는 제안한 솔루션의 현장 적용 가능성을 높여준다.

Abstract: Globally, individuals and organizations employ Quick Response (QR) codes for
swift and convenient communication. Leveraging this, cybercriminals embed
falsify and misleading information in QR codes to launch various phishing
attacks which termed as Quishing. Many former studies have introduced defensive
approaches to preclude Quishing such as by classifying the embedded content of
QR codes and then label the QR codes accordingly, whereas other studies
classify them using visual features (i.e., deep features, histogram density
analysis features). However, these approaches mainly rely on black-box
techniques which do not clearly provide interpretability and transparency to
fully comprehend and reproduce the intrinsic decision process; therefore,
having certain obvious limitations includes the approaches' trust,
accountability, issues in bias detection, and many more. We proposed QR\"iS,
the pioneer method to classify QR codes through the comprehensive structural
analysis of a QR code which helps to identify phishing QR codes beforehand. Our
classification method is clearly transparent which makes it reproducible,
scalable, and easy to comprehend. First, we generated QR codes dataset (i.e.
400,000 samples) using recently published URLs datasets [1], [2]. Then, unlike
black-box models, we developed a simple algorithm to extract 24 structural
features from layout patterns present in QR codes. Later, we train the machine
learning models on the harvested features and obtained accuracy of up to
83.18%. To further evaluate the effectiveness of our approach, we perform the
comparative analysis of proposed method with relevant contemporary studies.
Lastly, for real-world deployment and validation, we developed a mobile app
which assures the feasibility of the proposed solution in real-world scenarios
which eventually strengthen the applicability of the study.

</details>


### [10] [Multimodal Safety Is Asymmetric: Cross-Modal Exploits Unlock Black-Box MLLMs Jailbreaks](https://arxiv.org/abs/2510.17277)
*Xinkai Wang,Beibei Li,Zerui Shao,Ao Liu,Shouling Ji*

Main category: cs.CR

TL;DR: 이 논문은 멀티모달 대형 언어 모델(MLLMs)의 안전성 취약점인 jailbreaking을 조사하고, 시각적 정렬이 MLLMs의 모달리티 간 안전 제약을 불균형적으로 부과한다는 점을 처음으로 관찰하였으며, 이를 기반으로 PolyJailbreak라는 강화 학습 기반의 새로운 jailbreaking 방법을 개발하였다.


<details>
  <summary>Details</summary>
Motivation: MLLMs가 다양한 실제 응용 프로그램에서 유용하지만, 여전히 공격 입력에 취약해 안전 제약을 무너뜨리고 비윤리적 반응을 유발할 수 있다는 점을 다루고자 했다.

Method: PolyJailbreak는 흑상자 방식의 jailbreaking 방법으로, 모델의 주의역 동역학과 잠재 표현 공간을 조사하여 시각적 입력이 교차 모달 정보 흐름을 어떻게 재구성하는지를 평가하고, 유해한 입력과 무해한 입력을 구분하는 모델의 능력을 감소시키는 방식으로 설계되었다.

Result: PolyJailbreak는 다양한 오픈 소스 및 폐쇄 소스 MLLMs에 대한 포괄적인 평가를 통해 최첨단 기준선을 초과하는 성능을 보여주었다.

Conclusion: 이 연구는 안전성 비대칭을 이해하고, 모달리티 간의 안전 제약을 균형 있게 만들기 위한 방안을 제시한다.

Abstract: Multimodal large language models (MLLMs) have demonstrated significant
utility across diverse real-world applications. But MLLMs remain vulnerable to
jailbreaks, where adversarial inputs can collapse their safety constraints and
trigger unethical responses. In this work, we investigate jailbreaks in the
text-vision multimodal setting and pioneer the observation that visual
alignment imposes uneven safety constraints across modalities in MLLMs, thereby
giving rise to multimodal safety asymmetry. We then develop PolyJailbreak, a
black-box jailbreak method grounded in reinforcement learning. Initially, we
probe the model's attention dynamics and latent representation space, assessing
how visual inputs reshape cross-modal information flow and diminish the model's
ability to separate harmful from benign inputs, thereby exposing exploitable
vulnerabilities. On this basis, we systematize them into generalizable and
reusable operational rules that constitute a structured library of Atomic
Strategy Primitives, which translate harmful intents into jailbreak inputs
through step-wise transformations. Guided by the primitives, PolyJailbreak
employs a multi-agent optimization process that automatically adapts inputs
against the target models. We conduct comprehensive evaluations on a variety of
open-source and closed-source MLLMs, demonstrating that PolyJailbreak
outperforms state-of-the-art baselines.

</details>


### [11] [The Hidden Dangers of Public Serverless Repositories: An Empirical Security Assessment](https://arxiv.org/abs/2510.17311)
*Eduard Marin,Jinwoo Kim,Alessio Pavoni,Mauro Conti,Roberto Di Pietro*

Main category: cs.CR

TL;DR: 서버리스 컴퓨팅의 보안 문제를 처음으로 종합적으로 분석한 연구


<details>
  <summary>Details</summary>
Motivation: 서버리스 컴퓨팅의 인기가 높아짐에 따라 공용 저장소의 보안 문제가 중요해지고 있다.

Method: 5개의 공용 저장소에서 2,758개의 서버리스 구성 요소와 3개의 IaC 프레임워크에서 125,936개의 IaC 템플릿을 분석하였다.

Result: 구형 소프트웨어 패키지, 민감한 매개변수의 오용, 배포 구성의 악용 가능성, 타이포 스쿼팅 공격에 대한 취약점, 악성 행위를 포함할 수 있는 기회 등의 시스템적 취약점을 발견하였다.

Conclusion: 위협을 완화하기 위한 실용적인 권장 사항을 제시한다.

Abstract: Serverless computing has rapidly emerged as a prominent cloud paradigm,
enabling developers to focus solely on application logic without the burden of
managing servers or underlying infrastructure. Public serverless repositories
have become key to accelerating the development of serverless applications.
However, their growing popularity makes them attractive targets for
adversaries. Despite this, the security posture of these repositories remains
largely unexplored, exposing developers and organizations to potential risks.
In this paper, we present the first comprehensive analysis of the security
landscape of serverless components hosted in public repositories. We analyse
2,758 serverless components from five widely used public repositories popular
among developers and enterprises, and 125,936 Infrastructure as Code (IaC)
templates across three widely used IaC frameworks. Our analysis reveals
systemic vulnerabilities including outdated software packages, misuse of
sensitive parameters, exploitable deployment configurations, susceptibility to
typo-squatting attacks and opportunities to embed malicious behaviour within
compressed serverless components. Finally, we provide practical recommendations
to mitigate these threats.

</details>


### [12] [Process Automation Architecture Using RFID for Transparent Voting Systems](https://arxiv.org/abs/2510.17403)
*Stella N. Arinze,Patrick U. Okafor,Onyekachi M. Egwuagu,Augustine O. Nwajana*

Main category: cs.CR

TL;DR: 이 논문은 안전하고 투명하며 효율적인 투표 시스템을 위한 RFID 기술을 활용한 프로세스 자동화 아키텍처 개발에 대한 것이다.


<details>
  <summary>Details</summary>
Motivation: 현재의 투표 시스템은 효율성과 투명성을 부족하며 이를 해결하기 위한 필요성이 있다.

Method: RFID 기술을 통해 유권자 신원 확인, 암호화된 투표 및 데이터 전송을 자동화하여 투표 작업 흐름을 처리하는 아키텍처를 제안한다.

Result: 시뮬레이션 환경에서 100% 유권자 인증 정확도를 달성하였고, 평균 투표 시간은 11.5초로 지연을 최소화하였다.

Conclusion: 이 연구는 투표 인프라를 위한 확장 가능하고 자동화 기반의 솔루션을 제공하며, 특히 전자 투표 프로세스의 디지털 전환이 절실히 필요한 환경에서 투명성, 회복력 및 배포 유연성을 향상시킨다.

Abstract: This paper presents the development of a process automation architecture
leveraging Radio Frequency Identification (RFID) technology for secure,
transparent and efficient voting systems. The proposed architecture automates
the voting workflow through RFID-enabled voter identification, encrypted vote
casting, and secure data transmission. Each eligible voter receives a smart
RFID card containing a uniquely encrypted identifier, which is verified using
an RC522 reader interfaced with a microcontroller. Upon successful
verification, the voter interacts with a touchscreen interface to cast a vote,
which is then encrypted using AES-128 and securely stored on a local SD card or
transmitted via GSM to a central server. A tamper-proof monitoring mechanism
records each session with time-stamped digital signatures, ensuring
auditability and data integrity. The architecture is designed to function in
both online and offline modes, with an automated batch synchronization
mechanism that updates vote records once network connectivity is restored.
System testing in simulated environments confirmed 100% voter authentication
accuracy, minimized latency (average voting time of 11.5 seconds), and
robustness against cloning, double voting, and data interception. The
integration of real-time monitoring and secure process control modules enables
electoral authorities to automate data logging, detect anomalies, and validate
system integrity dynamically. This work demonstrates a scalable,
automation-driven solution for voting infrastructure, offering enhanced
transparency, resilience, and deployment flexibility, especially in
environments where digital transformation of electoral processes is critically
needed.

</details>


### [13] [Cybersecurity AI: Evaluating Agentic Cybersecurity in Attack/Defense CTFs](https://arxiv.org/abs/2510.17521)
*Francesco Balassone,Víctor Mayoral-Vilches,Stefan Rass,Martin Pinzger,Gaetano Perrone,Simon Pietro Romano,Peter Schartner*

Main category: cs.CR

TL;DR: AI 시스템의 공격과 방어 효율성을 평가한 연구로, 방어형 에이전트가 공격형 에이전트보다 높은 성공률을 보이나, 운영 제약이 있을 경우 이 우위가 사라진다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 사이버 보안에서 공격과 방어 중 어느 쪽이 더 효과적인지를 평가하기 위함이다.

Method: CAI의 병렬 실행 프레임워크를 사용하여 23개의 공격/방어 CTF 전투에서 자율 에이전트를 배치했다.

Result: 방어형 에이전트는 비제한 패치 성공률 54.3%를 기록했으나, 운영 제약이 있을 경우 방어의 효과가 크게 저하됐다.

Conclusion: 방어의 효과는 성공 기준에 따라 달라지며, 이는 AI 공격자 우위를 반박하는 최초의 실증적 증거를 제공한다.

Abstract: We empirically evaluate whether AI systems are more effective at attacking or
defending in cybersecurity. Using CAI (Cybersecurity AI)'s parallel execution
framework, we deployed autonomous agents in 23 Attack/Defense CTF
battlegrounds. Statistical analysis reveals defensive agents achieve 54.3%
unconstrained patching success versus 28.3% offensive initial access
(p=0.0193), but this advantage disappears under operational constraints: when
defense requires maintaining availability (23.9%) and preventing all intrusions
(15.2%), no significant difference exists (p>0.05). Exploratory taxonomy
analysis suggests potential patterns in vulnerability exploitation, though
limited sample sizes preclude definitive conclusions. This study provides the
first controlled empirical evidence challenging claims of AI attacker
advantage, demonstrating that defensive effectiveness critically depends on
success criteria, a nuance absent from conceptual analyses but essential for
deployment. These findings underscore the urgency for defenders to adopt
open-source Cybersecurity AI frameworks to maintain security equilibrium
against accelerating offensive automation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [14] [Disaster Management in the Era of Agentic AI Systems: A Vision for Collective Human-Machine Intelligence for Augmented Resilience](https://arxiv.org/abs/2510.16034)
*Bo Li,Junwei Ma,Kai Yin,Yiming Xiao,Chia-Wei Hsu,Ali Mostafavi*

Main category: cs.MA

TL;DR: 재난 관리에서의 전통적인 대응 능력을 넘어서기 위해 다중 에이전트 인공지능 시스템인 재난 코파일럿을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 재난의 빈도와 심각성이 증가함에 따라 전통적인 대응 능력이 한계를 드러내고 있으며, 이는 신속하고 효과적인 의사결정을 방해하는 문제를 드러낸다.

Method: 재난 코파일럿은 중앙 오케스트레이터를 활용하여 예측 리스크 분석, 상황 인식 및 영향 평가와 같은 분야에 전문화된 다양한 하위 에이전트를 협력적으로 조율하는 구조를 제안한다.

Result: 다양한 방향에서 통합된 다중 모드 데이터를 통해 실시간으로 전체적 운영 상황을 제공하며, 재난 디지털 트윈을 수동 모델에서 능동적이고 지능적인 환경으로 발전시킬 수 있는 필수적인 AI 기반 시스템이 될 수 있다.

Conclusion: 재난 코파일럿은 기술, 조직 역량, 그리고 인간-AI 팀워크의 병행 성장에 중점을 둔 3단계 로드맵을 제안하며, 더욱 적응력 있고 데이터 기반의 회복력 있는 공동체를 구축하기 위한 변혁적 비전을 제공한다.

Abstract: The escalating frequency and severity of disasters routinely overwhelm
traditional response capabilities, exposing critical vulnerability in disaster
management. Current practices are hindered by fragmented data streams, siloed
technologies, resource constraints, and the erosion of institutional memory,
which collectively impede timely and effective decision making. This study
introduces Disaster Copilot, a vision for a multi-agent artificial intelligence
system designed to overcome these systemic challenges by unifying specialized
AI tools within a collaborative framework. The proposed architecture utilizes a
central orchestrator to coordinate diverse sub-agents, each specializing in
critical domains such as predictive risk analytics, situational awareness, and
impact assessment. By integrating multi-modal data, the system delivers a
holistic, real-time operational picture and serve as the essential AI backbone
required to advance Disaster Digital Twins from passive models to active,
intelligent environments. Furthermore, it ensures functionality in
resource-limited environments through on-device orchestration and incorporates
mechanisms to capture institutional knowledge, mitigating the impact of staff
turnover. We detail the system architecture and propose a three-phased roadmap
emphasizing the parallel growth of technology, organizational capacity, and
human-AI teaming. Disaster Copilot offers a transformative vision, fostering
collective human-machine intelligence to build more adaptive, data-driven and
resilient communities.

</details>


### [15] [Zero-Shot Coordination in Ad Hoc Teams with Generalized Policy Improvement and Difference Rewards](https://arxiv.org/abs/2510.16187)
*Rupal Nigam,Niket Parikh,Hamid Osooli,Mikihisa Yuasa,Jacob Heglund,Huy T. Tran*

Main category: cs.MA

TL;DR: 이 논문에서는 전이 학습을 통해 새 팀에 대한 제로샷(Zero-shot) 전이를 가능하게 하는 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 다중 에이전트 시스템에서는 에이전트가 이전에 보지 못한 동료들과 협력하여 작업을 수행해야 할 상황이 종종 발생한다.

Method: 우리는 이 문제를 즉흥적 다중 에이전트 마르코프 결정 과정으로 형식화하고, 일반화된 정책 개선 및 차별 보상이라는 두 가지 주요 아이디어를 사용하여 효율적이고 효과적인 지식 이전을 위한 솔루션을 제시한다.

Result: 우리의 알고리즘, 즉 일반화된 정책 개선을 위한 즉흥적 팀 구성(GPAT)이 협력성 포획, 포식자-피식자, Overcooked라는 세 가지 시뮬레이션 환경에서 새로운 팀으로의 제로샷 전이를 성공적으로 가능하게 한다는 것을 경험적으로 입증하였다.

Conclusion: 우리는 또한 우리의 알고리즘을 실제 다중 로봇 환경에서도 시연하였다.

Abstract: Real-world multi-agent systems may require ad hoc teaming, where an agent
must coordinate with other previously unseen teammates to solve a task in a
zero-shot manner. Prior work often either selects a pretrained policy based on
an inferred model of the new teammates or pretrains a single policy that is
robust to potential teammates. Instead, we propose to leverage all pretrained
policies in a zero-shot transfer setting. We formalize this problem as an ad
hoc multi-agent Markov decision process and present a solution that uses two
key ideas, generalized policy improvement and difference rewards, for efficient
and effective knowledge transfer between different teams. We empirically
demonstrate that our algorithm, Generalized Policy improvement for Ad hoc
Teaming (GPAT), successfully enables zero-shot transfer to new teams in three
simulated environments: cooperative foraging, predator-prey, and Overcooked. We
also demonstrate our algorithm in a real-world multi-robot setting.

</details>


### [16] [Heterogeneous Multi-Agent Task-Assignment with Uncertain Execution Times and Preferences](https://arxiv.org/abs/2510.16221)
*Qinshuang Wei,Vaibhav Srivastava,Vijay Gupta*

Main category: cs.MA

TL;DR: 이 논문은 이질적인 작업 선호 및 능력을 가진 다중 에이전트 설정에서의 작업 할당 문제를 연구하고, 중앙 계획자가 팀의 여러 구성원에게 반복 작업을 할당하는 상황을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 단일 에이전트의 순차 작업 할당은 많이 연구되었으나, 다중 에이전트 환경에서는 이질적인 작업 선호와 능력으로 인해 문제의 특성이 덜 연구되었다.

Method: 중앙 계획자가 팀의 여러 구성원에게 반복 작업을 할당하는 다중 에이전트 작업 할당 문제를 제안하고 분석하며, 이 문제를 해결하기 위해 반복적으로 최적 작업 할당 문제를 해결하는 밴딧 알고리즘을 제안한다.

Result: 제안된 밴딧 알고리즘에 대한 분석을 통해, 최적 작업 할당 문제를 정확히 해결할 수 있을 때와 대략적으로만 해결할 수 있을 때의 두 경우에서 달성 가능한 후회의 정도를 분석한다.

Conclusion: 이 연구는 다중 에이전트 작업 할당의 복잡성과 그 해결 방안을 제시하며, 중앙 계획자의 자원 소비 관리와 보상 극대화의 중요성을 강조한다.

Abstract: While sequential task assignment for a single agent has been widely studied,
such problems in a multi-agent setting, where the agents have heterogeneous
task preferences or capabilities, remain less well-characterized. We study a
multi-agent task assignment problem where a central planner assigns recurring
tasks to multiple members of a team over a finite time horizon. For any given
task, the members have heterogeneous capabilities in terms of task completion
times, task resource consumption (which can model variables such as energy or
attention), and preferences in terms of the rewards they collect upon task
completion. We assume that the reward, execution time, and resource consumption
for each member to complete any task are stochastic with unknown distributions.
The goal of the planner is to maximize the total expected reward that the team
receives over the problem horizon while ensuring that the resource consumption
required for any assigned task is within the capability of the agent. We
propose and analyze a bandit algorithm for this problem. Since the bandit
algorithm relies on solving an optimal task assignment problem repeatedly, we
analyze the achievable regret in two cases: when we can solve the optimal task
assignment exactly and when we can solve it only approximately.

</details>


### [17] [Prompt Optimization via Retrieved Reasoning Assets and Multi-Agent Analysis](https://arxiv.org/abs/2510.16635)
*Wonduk Seo,Juhyeon Lee,Junseo Koh,Hyunjin An,Jian Park,Seunghyun Lee,Haihua Chen,Yi Bu*

Main category: cs.MA

TL;DR: MA-SAPO는 성과 기반 프롬프트 최적화를 위한 다중 에이전트 프레임워크로, 프롬프트의 성공 원인을 명확히 하고 체계적인 수정을 유도한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)의 성능 개선을 위해 재훈련 대신 프롬프트 최적화가 효과적인 대안으로 떠오르고 있지만, 기존 접근 방식은 평가를 블랙박스처럼 다루고 있고, 수치적 점수에만 의존하며 성공 또는 실패의 이유에 대한 통찰력이 부족하다.

Method: MA-SAPO는 평가 결과를 구조화된 추론과 연결하여 체계적인 수정을 안내하는 두 단계의 과정을 포함한다. 첫 번째 단계인 추론 단계에서는 에이전트들이 점수를 설명하고 약점을 진단하며 목표 수정을 합성한다. 두 번째 단계인 테스트 단계에서는 이러한 수정 자산을 활용하여 최적화된 프롬프트를 분석하고, 증거 기반 수정을 적용한다.

Result: MA-SAPO는 평가 신호를 해석 가능한 추론 체인으로 변환함으로써 투명하고 감사 가능하며 통제가 가능한 프롬프트 수정을 생성한다.

Conclusion: HelpSteer1/2 벤치마크에 대한 실험에서 단일 통과 프롬프트, 검색 증강 기준 및 이전의 다중 에이전트 전략에 비해 일관된 개선을 보여주어 접근 방식의 효과를 검증하였다.

Abstract: Prompt optimization has emerged as an effective alternative to retraining for
improving the performance of Large Language Models (LLMs). However, most
existing approaches treat evaluation as a black box, relying solely on
numerical scores while offering limited insight into why a prompt succeeds or
fails. They also depend heavily on trial-and-error refinements, which are
difficult to interpret and control. In this paper, we introduce MA-SAPO, a
Multi-Agent framework for Score-Aware Prompt Optimization. Compared to prior
methods, MA-SAPO explicitly couples evaluation outcomes with structured
reasoning to guide systematic edits. The framework specifically consists of two
stages: during the Reasoning Phase, agents collaboratively explain metric
scores, diagnose weaknesses, and synthesize targeted refinements that are
stored as reusable reasoning assets; during the Test Phase, agents retrieve
these assets to analyze optimized prompts and apply only evidence-grounded
edits. By turning evaluation signals into interpretable reasoning chains,
MA-SAPO produces prompt refinements that are more transparent, auditable, and
controllable. Experiments on the HelpSteer1/2 benchmarks demonstrate consistent
improvements over single-pass prompting, retrieval-augmented baselines, and
prior multi-agent strategies, validating the effectiveness of our approach.

</details>


### [18] [Lark: Biologically Inspired Neuroevolution for Multi-Stakeholder LLM Agents](https://arxiv.org/abs/2510.16978)
*Dheeraj Chintapalli,Rikhil Tanugula,Sunkalp Chandra*

Main category: cs.MA

TL;DR: Lark는 LLM 기반 추론과 진화적, 이해 관계자 인식 멀티 에이전트 시스템(MAS)을 결합한 생물학에서 영감을 받은 의사 결정 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 이 시스템은 모호성과 이해 관계자 간의 거래 문제를 해결하기 위해 개발되었다.

Method: Lark는 네 가지 메커니즘(가변성, 복제 및 발전, 영향 가중 Borda 점수를 사용하는 순위 선택 이해 관계자 집합, 짧은 응답을 보상하는 토큰 기반 패널티)을 통합하여 다양한 전략을 제안하고 평가하며 최종 점수에 계산 비용을 반영한다.

Result: Lark Full은 30회의 대조 평가에서 평균 순위 2.55 및 평균 복합 점수 29.4/50을 기록하며 80%의 라운드에서 Top-3에 위치했다.

Conclusion: 꽃은 이해 관계자 정렬 전략 생성을 확장하고 거래를 투명하게 만들기 위해 실용적인 컴퓨팅 인식을 가진 신경 진화 루프를 제시한다.

Abstract: We present Lark, a biologically inspired decision-making framework that
couples LLM-driven reasoning with an evolutionary, stakeholder-aware
Multi-Agent System (MAS). To address verbosity and stakeholder trade-offs, we
integrate four mechanisms: (i) plasticity, which applies concise adjustments to
candidate solutions; (ii) duplication and maturation, which copy
high-performing candidates and specialize them into new modules; (iii)
ranked-choice stakeholder aggregation using influence-weighted Borda scoring;
and (iv) compute awareness via token-based penalties that reward brevity. The
system iteratively proposes diverse strategies, applies plasticity tweaks,
simulates stakeholder evaluations, aggregates preferences, selects top
candidates, and performs duplication/maturation while factoring compute cost
into final scores. In a controlled evaluation over 30 rounds comparing 14
systems, Lark Full achieves a mean rank of 2.55 (95% CI [2.17, 2.93]) and a
mean composite score of 29.4/50 (95% CI [26.34, 32.46]), finishing Top-3 in 80%
of rounds while remaining cost competitive with leading commercial models
($0.016 per task). Paired Wilcoxon tests confirm that all four mechanisms
contribute significantly as ablating duplication/maturation yields the largest
deficit ({\Delta}Score = 3.5, Cohen's d_z = 2.53, p < 0.001), followed by
plasticity ({\Delta}Score = 3.4, d_z = 1.86), ranked-choice voting
({\Delta}Score = 2.4, d_z = 1.20), and token penalties ({\Delta}Score = 2.2,
d_z = 1.63). Rather than a formal Markov Decision Process with constrained
optimization, Lark is a practical, compute-aware neuroevolutionary loop that
scales stakeholder-aligned strategy generation and makes trade-offs transparent
through per-step metrics. Our work presents proof-of-concept findings and
invites community feedback as we expand toward real-world validation studies.

</details>


### [19] [ReclAIm: A multi-agent framework for degradation-aware performance tuning of medical imaging AI](https://arxiv.org/abs/2510.17004)
*Eleftherios Tzanis,Michail E. Klontzas*

Main category: cs.MA

TL;DR: ReclAIm은 의료 이미지 분류 모델을 자율적으로 모니터링, 평가 및 미세 조정할 수 있는 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: AI 모델의 장기적인 신뢰성을 확보하기 위해서는 성능 모니터링과 성능 저하 시 corrective actions가 필요하다.

Method: ReclAIm은 대형 언어 모델 코어를 기반으로 하며, 자연어 상호작용을 통해 전적으로 운영된다.

Result: ReclAIm은 MRI, CT, X-ray 데이터셋에서 모델의 성능을 일관되게 유지하며, 성능 저하를 감지하면 자율적으로 최첨단 미세 조정 절차를 실행한다.

Conclusion: ReclAIm은 연구 및 임상 환경에서 더 널리 채택될 수 있도록 의료 영상 AI 모델의 자동화되고 지속적인 유지 관리를 가능하게 한다.

Abstract: Ensuring the long-term reliability of AI models in clinical practice requires
continuous performance monitoring and corrective actions when degradation
occurs. Addressing this need, this manuscript presents ReclAIm, a multi-agent
framework capable of autonomously monitoring, evaluating, and fine-tuning
medical image classification models. The system, built on a large language
model core, operates entirely through natural language interaction, eliminating
the need for programming expertise. ReclAIm successfully trains, evaluates, and
maintains consistent performance of models across MRI, CT, and X-ray datasets.
Once ReclAIm detects significant performance degradation, it autonomously
executes state-of-the-art fine-tuning procedures that substantially reduce the
performance gap. In cases with performance drops of up to -41.1% (MRI
InceptionV3), ReclAIm managed to readjust performance metrics within 1.5% of
the initial model results. ReclAIm enables automated, continuous maintenance of
medical imaging AI models in a user-friendly and adaptable manner that
facilitates broader adoption in both research and clinical environments.

</details>


### [20] [MiCRO for Multilateral Negotiations](https://arxiv.org/abs/2510.17401)
*David Aguilera-Luzon,Dave de Jonge,Javier Larrosa*

Main category: cs.MA

TL;DR: MiCRO라는 새로운 양자 협상 전략이 다자 협상에 적용된 결과, 기존의 자동화 협상 대회 수상자들보다 우수한 성과를 보였으며, 이 전략은 경험적 내쉬 균형을 형성함을 밝혔습니다.


<details>
  <summary>Details</summary>
Motivation: 기존 협상 알고리즘이 지나치게 단순한 기준 도메인에서 테스트되고 있음을 지적하며, MiCRO의 다자 협상 일반화 가능성을 탐구합니다.

Method: MiCRO의 다자 변형을 도입하고, 2015, 2017, 2018년 자동화 협상 에이전트 경연 대회 수상자들과 비교하여 성과를 분석합니다.

Result: MiCRO의 다자 변형이 기존의 수상자들보다 뛰어난 성과를 보임을 확인했습니다.

Conclusion: 새로운 MiCRO 버전이 경험적 내쉬 균형을 형성함을 보여줍니다.

Abstract: Recently, a very simple new bilateral negotiation strategy called MiCRO was
introduced that does not make use of any kind of opponent modeling or machine
learning techniques and that does not require fine-tuning of any parameters.
Despite its simplicity, it was shown that MiCRO performs similar to -- or even
better than -- most state-of-the-art negotiation strategies. This lead its
authors to argue that the benchmark domains on which negotiation algorithms are
typically tested may be too simplistic. However, one question that was left
open, was how MiCRO could be generalized to multilateral negotiations. In this
paper we fill this gap by introducing a multilateral variant of MiCRO. We
compare it with the winners of the Automated Negotiating Agents Competitions
(ANAC) of 2015, 2017 and 2018 and show that it outperforms them. Furthermore,
we perform an empirical game-theoretical analysis to show that our new version
of MiCRO forms an empirical Nash equilibrium.

</details>


### [21] [Strategyproof Facility Location for Five Agents on a Circle using PCD](https://arxiv.org/abs/2510.17435)
*Ido Farjoun,Reshef Meir*

Main category: cs.MA

TL;DR: 이 논문은 원 위에서의 전략적 시설 위치 문제를 다루며, 5명의 에이전트의 경우에 대한 PCD 전략적 메커니즘의 엄격한 경계를 찾습니다.


<details>
  <summary>Details</summary>
Motivation: 전략적 시설 위치 문제는 에이전트들이 자신의 이익을 극대화하려는 상황에서 가능성을 찾는 중요한 문제입니다.

Method: 에이전트가 보고한 위치를 반경의 길이에 비례하여 선택하는 PCD 전략적 메커니즘을 적용합니다. 인스턴스 공간의 크기를 체계적으로 축소하고 표준 최적화 기법을 사용하여 경계가 엄격하다는 것을 입증합니다.

Result: PCD 전략 메커니즘에 대한 엄격한 경계를 발견했습니다.

Conclusion: 일반적인 홀수 $n$에 대한 PCD의 근사 비율에 대한 가설을 세웠습니다.

Abstract: We consider the strategyproof facility location problem on a circle. We focus
on the case of 5 agents, and find a tight bound for the PCD strategyproof
mechanism, which selects the reported location of an agent in proportion to the
length of the arc in front of it. We methodically "reduce" the size of the
instance space and then use standard optimization techniques to find and prove
the bound is tight. Moreover we hypothesize the approximation ratio of PCD for
general odd $n$.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [22] [Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding](https://arxiv.org/abs/2510.15952)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 본 논문은 진정한 인식적 이해 없이 지능을 나타내는 대규모 언어 모델의 중요한 격차를 다루고 있다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델은 지능을 보이지만 진정한 인식적 이해가 결여되어 있다.

Method: Structured Cognitive Loop(SCL)라는 실행 가능한 인식론적 프레임워크를 도입하여, 인식의 출현 조건을 명확히 한다.

Result: SCL은 철학적 통찰력을 컴퓨터 해석 가능한 구조로 변화시키고, 인지 아키텍처 내에서의 기능적 분리를 통해 보다 일관되고 해석 가능한 행동을 이끌어낸다.

Conclusion: SCL은 지능을 재정의하며, 현재 지식 구조는 통계적 규율이 아닌 인식적 구조에 기초한다.

Abstract: Large language models exhibit intelligence without genuine epistemic
understanding, exposing a key gap: the absence of epistemic architecture. This
paper introduces the Structured Cognitive Loop (SCL) as an executable
epistemological framework for emergent intelligence. Unlike traditional AI
research asking "what is intelligence?" (ontological), SCL asks "under what
conditions does cognition emerge?" (epistemological). Grounded in philosophy of
mind and cognitive phenomenology, SCL bridges conceptual philosophy and
implementable cognition. Drawing on process philosophy, enactive cognition, and
extended mind theory, we define intelligence not as a property but as a
performed process -- a continuous loop of judgment, memory, control, action,
and regulation. SCL makes three contributions. First, it operationalizes
philosophical insights into computationally interpretable structures, enabling
"executable epistemology" -- philosophy as structural experiment. Second, it
shows that functional separation within cognitive architecture yields more
coherent and interpretable behavior than monolithic prompt based systems,
supported by agent evaluations. Third, it redefines intelligence: not
representational accuracy but the capacity to reconstruct its own epistemic
state through intentional understanding. This framework impacts philosophy of
mind, epistemology, and AI. For philosophy, it allows theories of cognition to
be enacted and tested. For AI, it grounds behavior in epistemic structure
rather than statistical regularity. For epistemology, it frames knowledge not
as truth possession but as continuous reconstruction within a
phenomenologically coherent loop. We situate SCL within debates on cognitive
phenomenology, emergence, normativity, and intentionality, arguing that real
progress requires not larger models but architectures that realize cognitive
principles structurally.

</details>


### [23] [PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency](https://arxiv.org/abs/2510.15966)
*Shian Jia,Ziyang Huang,Xinbo Wang,Haofei Zhang,Mingli Song*

Main category: cs.AI

TL;DR: PISA는 AI 에이전트를 위한 새로운 메모리 시스템으로, 다양한 작업에 적응할 수 있는 구조적이고 적응적인 프로세스로 메모리를 다룹니다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 메모리는 필수적이지만, 기존 연구들은 다양한 작업에 대한 적응력 부족과 메모리의 건설적 및 작업 지향적 역할을 간과하였습니다.

Method: PISA는 메모리를 건설적이고 적응적인 과정으로 취급하며, 트라이모달 적응 메커니즘(스키마 업데이트, 스키마 진화, 스키마 생성)을 도입하여 지속적인 학습과 적응성을 지원합니다.

Result: PISA는 LOCOMO 벤치마크와 새롭게 제안한 AggQA 벤치마크에서 실행된 평가를 통해 적응성과 장기 지식 유지 능력을 크게 향상시켜 새로운 최첨단 성능을 기록하였습니다.

Conclusion: PISA는 AI 메모리 시스템의 미래 방향을 제시하며, 기호적 추론과 신경 회수 방식을 원활하게 통합한 하이브리드 메모리 접근 아키텍처를 설계하여 성능을 향상시켰습니다.

Abstract: Memory systems are fundamental to AI agents, yet existing work often lacks
adaptability to diverse tasks and overlooks the constructive and task-oriented
role of AI agent memory. Drawing from Piaget's theory of cognitive development,
we propose PISA, a pragmatic, psych-inspired unified memory system that
addresses these limitations by treating memory as a constructive and adaptive
process. To enable continuous learning and adaptability, PISA introduces a
trimodal adaptation mechanism (i.e., schema updation, schema evolution, and
schema creation) that preserves coherent organization while supporting flexible
memory updates. Building on these schema-grounded structures, we further design
a hybrid memory access architecture that seamlessly integrates symbolic
reasoning with neural retrieval, significantly improving retrieval accuracy and
efficiency. Our empirical evaluation, conducted on the existing LOCOMO
benchmark and our newly proposed AggQA benchmark for data analysis tasks,
confirms that PISA sets a new state-of-the-art by significantly enhancing
adaptability and long-term knowledge retention.

</details>


### [24] [Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games](https://arxiv.org/abs/2510.15974)
*Chris Su,Harrison Li,Matheus Marques,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.AI

TL;DR: 대규모 추론 모델(LRM)은 특정 난이도 이상에서 퍼즐 해결 성능이 급격히 저하되는 현상을 겪으며, 이는 자체적으로 상태 공간을 추적해야 하는 작업의 특성이 진정한 추론 평가를 혼란스럽게 할 수 있다는 질문을 불러일으킨다. 이 연구에서는 Tower of Hanoi 문제를 해결하기 위해 환경 인터페이스를 제공하였으나 성능 붕괴를 지연시키거나 제거하지 못한다는 것을 발견했다.


<details>
  <summary>Details</summary>
Motivation: 대규모 추론 모델(LRM)의 성능 저하 원인을 분석하고자 하였으며, 작업의 특성이 진정한 추론 평가에 미치는 영향을 탐구하였다.

Method: Tower of Hanoi 문제에 대한 환경 인터페이스를 제공하여 모델이 도구 호출로 움직임을 수행하고, 서면으로 정당화하며, 결과 상태 공간을 관찰하고, 다음 움직임을 위한 자기 재프롬프트를 하도록 하는 방식으로 진행하였다.

Result: 환경 인터페이스 접근이 성능 붕괴를 지연시키거나 제거하지 않으며, LLM 파라미터화된 정책 분석 결과 최적 정책 및 균일한 무작위 정책과의 편차가 증가함을 확인하였다.

Conclusion: 모델이 각 복잡도 수준에서 모드와 같은 붕괴를 나타내며 성능은 모드가 문제에 대한 올바른 해결책을 반영하는지 여부에 따라 달라진다. 유사한 현상이 LRM에서도 발생할 수 있음을 제안한다.

Abstract: Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in
performance on solving puzzles beyond certain perplexity thresholds. In
subsequent discourse, questions have arisen as to whether the nature of the
task muddles an evaluation of true reasoning. One potential confound is the
requirement that the model keep track of the state space on its own. We provide
a large language model (LLM) with an environment interface for Tower of Hanoi
problems, allowing it to make a move with a tool call, provide written
justification, observe the resulting state space, and reprompt itself for the
next move. We observe that access to an environment interface does not delay or
eradicate performance collapse. Furthermore, LLM-parameterized policy analysis
reveals increasing divergence from both optimal policies and uniformly random
policies, suggesting that the model exhibits mode-like collapse at each level
of complexity, and that performance is dependent upon whether the mode reflects
the correct solution for the problem. We suggest that a similar phenomena might
take place in LRMs.

</details>


### [25] [Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability](https://arxiv.org/abs/2510.16193)
*Elija Perrier*

Main category: cs.AI

TL;DR: 이 논문은 기업 결정에 미치는 생성 AI의 영향을 탐구하며, 기업 지식을 동적 능력으로 재정의하고 측정 가능한 지표를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 기업 책임의 개념이 기존의 인간 에이전트에서 유래된 메인 레아 개념에 기반하였지만, 생성 AI가 기업의 의사결정에 미치고 있는 영향이 이러한 가정을 도전하고 있습니다.

Method: AI 또는 정보 시스템을 배치한 기업의 인식 상태를 포착하는 공식 모델을 개발하며, 정보 접근 절차의 효율성과 결과의 검증된 신뢰성으로 측정되는 동적 능력으로 기업 지식을 정의합니다.

Result: 우리는 지식 예측을 위한 임계값을 두고, 전체적인 능력을 측정하기 위해 기업 전체의 인식 능력 지수를 도출했습니다.

Conclusion: 이 연구는 알고리즘 시대에 기업의 인식을 추적 가능하고 책임 있게 만들 수 있는 측정 가능하고 법적 정당성을 갖춘 감사 자료를 생성할 수 있는 길을 제공합니다.

Abstract: Corporate responsibility turns on notions of corporate \textit{mens rea},
traditionally imputed from human agents. Yet these assumptions are under
challenge as generative AI increasingly mediates enterprise decision-making.
Building on the theory of extended cognition, we argue that in response
corporate knowledge may be redefined as a dynamic capability, measurable by the
efficiency of its information-access procedures and the validated reliability
of their outputs. We develop a formal model that captures epistemic states of
corporations deploying sophisticated AI or information systems, introducing a
continuous organisational knowledge metric $S_S(\varphi)$ which integrates a
pipeline's computational cost and its statistically validated error rate. We
derive a thresholded knowledge predicate $\mathsf{K}_S$ to impute knowledge and
a firm-wide epistemic capacity index $\mathcal{K}_{S,t}$ to measure overall
capability. We then operationally map these quantitative metrics onto the legal
standards of actual knowledge, constructive knowledge, wilful blindness, and
recklessness. Our work provides a pathway towards creating measurable and
justiciable audit artefacts, that render the corporate mind tractable and
accountable in the algorithmic age.

</details>


### [26] [Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration](https://arxiv.org/abs/2510.16194)
*Guanchen Wu,Zuhui Chen,Yuzhang Xie,Carl Yang*

Main category: cs.AI

TL;DR: TEAM-PHI는 PHI 비식별화 모델의 자동 평가와 최적 모델 선택을 위한 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: PHI 비식별화는 임상 노트의 안전한 재사용을 위해 필수적이며, 기존의 평가 방법은 비용이 많이 드는 전문가 주석에 의존한다.

Method: TEAM-PHI는 여러 평가 에이전트를 활용하여 PHI 추출의 정확성을 독립적으로 판단하고, LLM 기반의 다수결 기법으로 평가 결과를 통합한다.

Result: 실제 임상 노트 데이터에 대한 실험 결과, TEAM-PHI는 일관되고 정확한 순위를 생성하며, LLM 기반의 투표가 안정적으로 상위 성능 모델에 수렴한다.

Conclusion: TEAM-PHI는 독립 평가 에이전트와 LLM 다수결을 결합하여 제약이 있는 상황에서도 PHI 비식별화 모델의 자동 평가와 최적 모델 선정을 위한 실용적이고 안전한 솔루션을 제공한다.

Abstract: Protected health information (PHI) de-identification is critical for enabling
the safe reuse of clinical notes, yet evaluating and comparing PHI
de-identification models typically depends on costly, small-scale expert
annotations. We present TEAM-PHI, a multi-agent evaluation and selection
framework that uses large language models (LLMs) to automatically measure
de-identification quality and select the best-performing model without heavy
reliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each
independently judging the correctness of PHI extractions and outputting
structured metrics. Their results are then consolidated through an LLM-based
majority voting mechanism that integrates diverse evaluator perspectives into a
single, stable, and reproducible ranking. Experiments on a real-world clinical
note corpus demonstrate that TEAM-PHI produces consistent and accurate
rankings: despite variation across individual evaluators, LLM-based voting
reliably converges on the same top-performing systems. Further comparison with
ground-truth annotations and human evaluation confirms that the framework's
automated rankings closely match supervised evaluation. By combining
independent evaluation agents with LLM majority voting, TEAM-PHI offers a
practical, secure, and cost-effective solution for automatic evaluation and
best-model selection in PHI de-identification, even when ground-truth labels
are limited.

</details>


### [27] [Ripple Effect Protocol: Coordinating Agent Populations](https://arxiv.org/abs/2510.16572)
*Ayush Chopra,Aman Sharma,Feroz Ahmad,Luca Muscariello,Vijoy Pandey,Ramesh Raskar*

Main category: cs.AI

TL;DR: 리플 효과 프로토콜(REP)을 도입하여 에이전트 간의 의사 결정과 민감성을 공유함으로써 협업과 조정을 개선하고, 에이전트 중심의 통신 방식보다 향상된 정확도와 효율성을 보여줌.


<details>
  <summary>Details</summary>
Motivation: 에이전트 집단이 커짐에 따라 개별적으로 똑똑한 에이전트가 Poor group outcomes에 수렴하는 경향이 있어, 협조보다 통신이 강조되는 기존의 메커니즘의 한계를 극복하려는 것.

Method: 에이전트는 결정을 공유할 뿐만 아니라, 환경 변수 변화에 따라 선택이 어떻게 변화할지를 나타내는 경량 민감성 신호를 공유하는 리플 효과 프로토콜(REP)을 사용하여 조정합니다.

Result: REP는 세 분야(공급망 연쇄, 희소 네트워크에서의 선호 집합, 지속 가능한 자원 배분)에서 A2A에 비해 41%에서 100%까지 조정 정확도와 효율성을 개선합니다.

Conclusion: 조정을 프로토콜 수준의 기능으로 만들어줌으로써, REP는 에이전트의 인터넷을 위한 확장 가능한 인프라를 제공합니다.

Abstract: Modern AI agents can exchange messages using protocols such as A2A and ACP,
yet these mechanisms emphasize communication over coordination. As agent
populations grow, this limitation produces brittle collective behavior, where
individually smart agents converge on poor group outcomes. We introduce the
Ripple Effect Protocol (REP), a coordination protocol in which agents share not
only their decisions but also lightweight sensitivities - signals expressing
how their choices would change if key environmental variables shifted. These
sensitivities ripple through local networks, enabling groups to align faster
and more stably than with agent-centric communication alone. We formalize REP's
protocol specification, separating required message schemas from optional
aggregation rules, and evaluate it across scenarios with varying incentives and
network topologies. Benchmarks across three domains: (i) supply chain cascades
(Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling),
and (iii) sustainable resource allocation (Fishbanks) show that REP improves
coordination accuracy and efficiency over A2A by 41 to 100%, while flexibly
handling multimodal sensitivity signals from LLMs. By making coordination a
protocol-level capability, REP provides scalable infrastructure for the
emerging Internet of Agents

</details>


### [28] [ScholarEval: Research Idea Evaluation Grounded in Literature](https://arxiv.org/abs/2510.16234)
*Hanane Nour Moussa,Patrick Queiroz Da Silva,Daniel Adu-Ampratwum,Alyson East,Zitong Lu,Nikki Puccetti,Mingyi Xue,Huan Sun,Bodhisattwa Prasad Majumder,Sachin Kumar*

Main category: cs.AI

TL;DR: AI 도구가 연구 구상에 점점 더 흔해짐에 따라, 생성된 아이디어의 유효성과 유용성을 보장하기 위한 강력한 평가가 필수적이다. ScholarEval은 기존 문헌을 바탕으로 제안된 방법론의 경험적 유효성과 이전 연구에 대한 아이디어의 발전 정도를 기준으로 연구 아이디어를 평가하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: AI 도구의 보편화에 따라 연구 아이디어의 유효성과 유용성을 평가하는 것이 중요해졌다.

Method: ScholarEval은 제안된 방법론의 경험적 유효성과 이전 연구에 대비하여 아이디어의 발전 정도를 기준으로 연구 아이디어를 평가한다. 이를 위해 4개 분야의 117개 연구 아이디어로 구성된 첫 번째 전문가 주석 데이터셋인 ScholarIdeas를 도입하였다.

Result: ScholarEval은 ScholarIdeas의 전문가 주석 기준에서 언급된 점들을 커버하는 데 있어 모든 기준선보다 훨씬 높은 성능을 보였다. 또한, ScholarEval은 평가 실행 가능성, 깊이, 증거 지원 측면에서 OpenAI의 o4-mini-deep-research보다 일관되게 선호되었다.

Conclusion: ScholarEval은 문헌 참여, 아이디어 정제 및 유용성에서 깊은 연구를 크게 초월한다. 우리는 코드, 데이터셋 및 ScholarEval 도구를 공개하여 커뮤니티가 활용하고 발전시킬 수 있도록 했다.

Abstract: As AI tools become increasingly common for research ideation, robust
evaluation is critical to ensure the validity and usefulness of generated
ideas. We introduce ScholarEval, a retrieval augmented evaluation framework
that assesses research ideas based on two fundamental criteria: soundness - the
empirical validity of proposed methods based on existing literature, and
contribution - the degree of advancement made by the idea across different
dimensions relative to prior research. To evaluate ScholarEval, we introduce
ScholarIdeas, the first expert-annotated dataset of multi-domain research ideas
and reviews, comprised of 117 ideas across four disciplines: artificial
intelligence, neuroscience, biochemistry, and ecology. Our evaluation shows
that ScholarEval achieves significantly higher coverage of points mentioned in
the human expert annotated rubrics in ScholarIdeas compared to all baselines.
Furthermore, ScholarEval is consistently preferred over our strongest baseline
o4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,
in terms of evaluation actionability, depth, and evidence support. Our
large-scale user study also shows that ScholarEval significantly outperforms
deep research in literature engagement, idea refinement, and usefulness. We
openly release our code, dataset, and ScholarEval tool for the community to use
and build on.

</details>


### [29] [Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration](https://arxiv.org/abs/2510.16742)
*Paul Saves,Pramudita Satria Palar,Muhammad Daffa Robani,Nicolas Verstaevel,Moncef Garouani,Julien Aligon,Benoit Gaudou,Koji Shimoyama,Joseph Morlier*

Main category: cs.AI

TL;DR: 이 논문에서는 복잡한 시스템을 시뮬레이션 기반 공학 워크플로우로 탐구하고, 고비용의 시뮬레이터 실행 대신 경량 에뮬레이터를 사용하여 높은 계산 비용과 불투명성 문제를 해결하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 시스템의 시뮬레이션 기반 공학 워크플로우는 비용 효율성과 투명성을 개선할 필요가 있다.

Method: 실험의 압축 디자인을 통해 경량 에뮬레이터를 학습시키고, 이를 이용해 시뮬레이터의 빠르고 저지연 근사치를 제공한다.

Result: 제안된 방법론은 다양한 입력을 지원하며, 대규모 탐색과 비선형 상호작용을 발견하고, 정책과 설계 레버를 식별한다.

Conclusion: 이러한 접근방법은 시뮬레이터의 데이터 요구 사항이나 아키텍처에 대한 인사이트를 제공한다.

Abstract: Complex systems are increasingly explored through simulation-driven
engineering workflows that combine physics-based and empirical models with
optimization and analytics. Despite their power, these workflows face two
central obstacles: (1) high computational cost, since accurate exploration
requires many expensive simulator runs; and (2) limited transparency and
reliability when decisions rely on opaque blackbox components. We propose a
workflow that addresses both challenges by training lightweight emulators on
compact designs of experiments that (i) provide fast, low-latency
approximations of expensive simulators, (ii) enable rigorous uncertainty
quantification, and (iii) are adapted for global and local Explainable
Artificial Intelligence (XAI) analyses. This workflow unifies every
simulation-based complex-system analysis tool, ranging from engineering design
to agent-based models for socio-environmental understanding. In this paper, we
proposea comparative methodology and practical recommendations for using
surrogate-based explainability tools within the proposed workflow. The
methodology supports continuous and categorical inputs, combines global-effect
and uncertainty analyses with local attribution, and evaluates the consistency
of explanations across surrogate models, thereby diagnosing surrogate adequacy
and guiding further data collection or model refinement. We demonstrate the
approach on two contrasting case studies: a multidisciplinary design analysis
of a hybrid-electric aircraft and an agent-based model of urban segregation.
Results show that the surrogate model and XAI coupling enables large-scale
exploration in seconds, uncovers nonlinear interactions and emergent behaviors,
identifies key design and policy levers, and signals regions where surrogates
require more data or alternative architectures.

</details>


### [30] [What Limits Agentic Systems Efficiency?](https://arxiv.org/abs/2510.16276)
*Song Bian,Minghao Yan,Anand Jayarajan,Gennady Pekhimenko,Shivaram Venkataraman*

Main category: cs.AI

TL;DR: 본 연구는 웹 상호작용을 포함한 대형 언어 모델(LLM)의 에이전틱 시스템에서의 효율성 병목 현상을 식별하고 이를 개선할 수 있는 SpecCache라는 캐싱 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 성능을 높이기 위해 웹 상호작용을 통합한 에이전틱 시스템의 효율성을 조사하고 개선할 필요성이 있다.

Method: LLM API 지연 시간과 웹 환경 지연 시간을 두 가지 주요 요소로 나누어, 15개 모델 및 5개 공급자를 대상으로 웹 기반 에이전틱 시스템의 성능을 종합적으로 연구하였다. SpecCache라는 캐싱 프레임워크를 제안하여 웹 환경 오버헤드를 줄인다.

Result: 우리는 웹 환경 지연 시간이 웹 기반 에이전틱 시스템의 전체 지연 시간의 최대 53.7%를 차지할 수 있다고 관찰하였으며, SpecCache 기법을 통해 캐시 적중률을 최대 58배 향상시키고 웹 환경 오버헤드를 최대 3.2배 줄이는 성과를 거두었다.

Conclusion: 우리의 접근 방식은 에이전틱 시스템 성능을 저하시키지 않으면서도 지연 시간을 효과적으로 개선할 수 있음을 보여준다.

Abstract: Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have
demonstrated strong reasoning capabilities. To further enhance LLM
capabilities, recent agentic systems, such as Deep Research, incorporate web
interactions into LLM reasoning to mitigate uncertainties and reduce potential
errors. However, existing research predominantly focuses on reasoning
performance, often neglecting the efficiency of agentic systems. In this work,
we present a comprehensive empirical study that identifies efficiency
bottlenecks in web-interactive agentic systems. We decompose end-to-end latency
into two primary components: LLM API latency and web environment latency. We
conduct a comprehensive empirical study across 15 models and 5 providers to
demonstrate high variability in API-based agentic systems. We observe that web
environment latency can contribute as much as 53.7% to the overall latency in a
web-based agentic system. To improve latency, we propose SpecCache, a caching
framework augmented with speculative execution that can reduce web environment
overhead. Extensive evaluations on two standard benchmarks show that our
approach improves the cache hit rate by up to 58x compared to a random caching
strategy, while reducing web environment overhead by up to 3.2x, without
degrading agentic system performance.

</details>


### [31] [Graph Attention-Guided Search for Dense Multi-Agent Pathfinding](https://arxiv.org/abs/2510.17382)
*Rishabh Jain,Keisuke Okumura,Michael Amir,Amanda Prorok*

Main category: cs.AI

TL;DR: 다중 에이전트 경로 탐색 문제에 대한 하이브리드 프레임워크를 제안하여, 기존 방법 대비 우수한 성능을 보임.


<details>
  <summary>Details</summary>
Motivation: 실제 시간에서의 조밀한 다중 에이전트 경로 탐색 문제에 대한 최적해를 찾는 것이 여전히 도전적임.

Method: MAGAT에서 유도된 학습된 휴리스틱을 주요 탐색 기반 알고리즘인 LaCAM에 통합한 하이브리드 프레임워크인 LaGAT을 개발함.

Result: LaGAT은 조밀한 시나리오에서 순수 탐색 기반 및 순수 학습 기반 방법보다 더 우수한 성능을 보임.

Conclusion: 정교하게 설계된 하이브리드 탐색이 밀접하게 결합된 다중 에이전트 조정 문제에 강력한 해결책을 제공함을 보여줌.

Abstract: Finding near-optimal solutions for dense multi-agent pathfinding (MAPF)
problems in real-time remains challenging even for state-of-the-art planners.
To this end, we develop a hybrid framework that integrates a learned heuristic
derived from MAGAT, a neural MAPF policy with a graph attention scheme, into a
leading search-based algorithm, LaCAM. While prior work has explored
learning-guided search in MAPF, such methods have historically underperformed.
In contrast, our approach, termed LaGAT, outperforms both purely search-based
and purely learning-based methods in dense scenarios. This is achieved through
an enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of
interest, and a deadlock detection scheme to account for imperfect neural
guidance. Our results demonstrate that, when carefully designed, hybrid search
offers a powerful solution for tightly coupled, challenging multi-agent
coordination problems.

</details>


### [32] [Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts](https://arxiv.org/abs/2510.16342)
*Tong Zhang,Ru Zhang,Jianyi Liu,Zhen Yang,Gongshen Liu*

Main category: cs.AI

TL;DR: 이 논문에서는 텍스트-이미지 확산 모델의 개념 소거 방법의 한계를 극복하기 위한 동적 앵커 선택 프레임워크인 SELECT를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 고정 앵커 전략을 사용하는 개념 소거 방법이 개념의 재출현과 침식 등의 문제를 일으키기 때문에, 이를 해결할 필요가 있습니다.

Method: 우리는 개념 소거에 대한 앵커 선택의 민감성을 밝혀내기 위해 인과 추적을 수행하고, Sibling Exclusive Concepts를 우수한 앵커 클래스로 정의합니다. 그리고 고정 앵커의 한계를 극복하기 위해 동적 앵커 선택 프레임워크인 SELECT를 제안합니다.

Result: SELECT는 두 단계 평가 메커니즘을 도입하여 정확한 소거를 위한 최적의 앵커를 자동으로 발견하고 관련 개념을 보존하기 위한 중요한 경계 앵커를 식별합니다. 광범위한 평가 결과, SELECT는 여러 소거 프레임워크에 효율적으로 적응할 뿐만 아니라, 주요 성능 지표에서 기존 기준을 일관되게 초과하며 평균 4초 내에 단일 개념의 앵커 마이닝을 수행합니다.

Conclusion: 이 연구는 SELECT를 보편적인 앵커 솔루션으로 자리 잡히게 하여 고정 앵커의 한계를 극복하는 데 기여할 것입니다.

Abstract: Existing concept erasure methods for text-to-image diffusion models commonly
rely on fixed anchor strategies, which often lead to critical issues such as
concept re-emergence and erosion. To address this, we conduct causal tracing to
reveal the inherent sensitivity of erasure to anchor selection and define
Sibling Exclusive Concepts as a superior class of anchors. Based on this
insight, we propose \textbf{SELECT} (Sibling-Exclusive Evaluation for
Contextual Targeting), a dynamic anchor selection framework designed to
overcome the limitations of fixed anchors. Our framework introduces a novel
two-stage evaluation mechanism that automatically discovers optimal anchors for
precise erasure while identifying critical boundary anchors to preserve related
concepts. Extensive evaluations demonstrate that SELECT, as a universal anchor
solution, not only efficiently adapts to multiple erasure frameworks but also
consistently outperforms existing baselines across key performance metrics,
averaging only 4 seconds for anchor mining of a single concept.

</details>


### [33] [Diverse Planning with Simulators via Linear Temporal Logic](https://arxiv.org/abs/2510.17418)
*Mustafa F. Abdelwahed,Alice Toniolo,Joan Espasa,Ian P. Gent*

Main category: cs.AI

TL;DR: $	exttt{FBI}_	exttt{LTL}$는 시뮬레이션 기반 계획 문제를 위한 다양성을 가진 계획 알고리즘으로, 선형 시간 논리(LTL)를 활용하여 의미적 다양성을 정의하고, 에이전트가 의미적으로 다른 계획을 생성할 수 있도록 지원한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 환경 모델링에서 선언적 모델 대신 시뮬레이션 기반 계획의 이점을 활용하고, 하나의 계획에 의존하는 것의 한계를 극복하기 위해.

Method: 선형 시간 논리(LTL)를 이용하여 의미적 다양성 기준을 정의하고, 이를 검색 과정에 통합하여 다양한 계획을 생성하는 알고리즘을 개발했다.

Result: 함께 수행된 평가에서, $	exttt{FBI}_	exttt{LTL}$이 기존의 기초 방법보다 더 다양한 계획을 생성함을 일관되게 입증하였다.

Conclusion: 시뮬레이션 기반 환경에서 의미 중심이 요구되는 다양한 계획을 가능하게 하는 방법을 제시하고, 전통적 모델 기반 접근 방법이 실패하는 비상징적 영역에서도 새로운 접근 방식의 가능성을 열었다.

Abstract: Autonomous agents rely on automated planning algorithms to achieve their
objectives. Simulation-based planning offers a significant advantage over
declarative models in modelling complex environments. However, relying solely
on a planner that produces a single plan may not be practical, as the generated
plans may not always satisfy the agent's preferences. To address this
limitation, we introduce $\texttt{FBI}_\texttt{LTL}$, a diverse planner
explicitly designed for simulation-based planning problems.
$\texttt{FBI}_\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define
semantic diversity criteria, enabling agents to specify what constitutes
meaningfully different plans. By integrating these LTL-based diversity models
directly into the search process, $\texttt{FBI}_\texttt{LTL}$ ensures the
generation of semantically diverse plans, addressing a critical limitation of
existing diverse planning approaches that may produce syntactically different
but semantically identical solutions. Extensive evaluations on various
benchmarks consistently demonstrate that $\texttt{FBI}_\texttt{LTL}$ generates
more diverse plans compared to a baseline approach. This work establishes the
feasibility of semantically-guided diverse planning in simulation-based
environments, paving the way for innovative approaches in realistic,
non-symbolic domains where traditional model-based approaches fail.

</details>


### [34] [The Burden of Interactive Alignment with Inconsistent Preferences](https://arxiv.org/abs/2510.16368)
*Ali Shirali*

Main category: cs.AI

TL;DR: 사용자와 알고리즘 간의 상호작용을 모델링하여, 사용자가 알고리즘을 자신의 진정한 관심사와 일치시키기 위한 조건을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 미디어 플랫폼과 챗봇 등에서 알고리즘은 사람들이 상호작용하고 학습하며 정보를 발견하는 방식을 형성한다. 그러나 사용자는 종종 일관성이 없는 선호를 보인다.

Method: 사용자의 결정 과정을 합리적 시스템 2와 충동적인 시스템 1으로 분리하여 모델링하고, 사용자가 참여 전략에 전념하는 다중 리더, 단일 추종자 스택켈버그 게임을 연구한다.

Result: 충분히 예측 가능한 사용자는 알고리즘을 자신의 목표와 일치시킬 수 있지만, 그렇지 않은 사용자들은 알고리즘의 목표에 맞춰 조정된다.

Conclusion: 작은 신호가 알고리즘의 조정 부담을 줄일 수 있음을 보여주며, 사용자와 알고리즘 간 일치를 이루기 위한 도전과 해결책을 강조한다.

Abstract: From media platforms to chatbots, algorithms shape how people interact,
learn, and discover information. Such interactions between users and an
algorithm often unfold over multiple steps, during which strategic users can
guide the algorithm to better align with their true interests by selectively
engaging with content. However, users frequently exhibit inconsistent
preferences: they may spend considerable time on content that offers little
long-term value, inadvertently signaling that such content is desirable.
Focusing on the user side, this raises a key question: what does it take for
such users to align the algorithm with their true interests?
  To investigate these dynamics, we model the user's decision process as split
between a rational system 2 that decides whether to engage and an impulsive
system 1 that determines how long engagement lasts. We then study a
multi-leader, single-follower extensive Stackelberg game, where users,
specifically system 2, lead by committing to engagement strategies and the
algorithm best-responds based on observed interactions. We define the burden of
alignment as the minimum horizon over which users must optimize to effectively
steer the algorithm. We show that a critical horizon exists: users who are
sufficiently foresighted can achieve alignment, while those who are not are
instead aligned to the algorithm's objective. This critical horizon can be
long, imposing a substantial burden. However, even a small, costly signal
(e.g., an extra click) can significantly reduce it. Overall, our framework
explains how users with inconsistent preferences can align an engagement-driven
algorithm with their interests in a Stackelberg equilibrium, highlighting both
the challenges and potential remedies for achieving alignment.

</details>


### [35] [A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.17697)
*Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang*

Main category: cs.AI

TL;DR: 이 연구는 다중 에이전트 강화 학습(MARL)에서 효과적인 상호작용 패러다임을 설계하여 에이전트의 글로벌 지침 문제를 해결하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 MARL에서 인간의 글로벌 지침이 실용적이지 않기 때문에 협력적인 다중 에이전트 강화 학습(MARL)을 원하는 결과로 유도하는 것이 어렵습니다.

Method: 다중 에이전트 영향 다이어그램(MAIDs)을 그래픽 프레임워크로 사용하여 MARL의 기존 접근 방식을 분석하고 시각화하고, 단일 목표 에이전트에만 적용되는 목표 개입 패러다임을 설계하였습니다.

Result: 제안한 목표 개입의 효과성을 실험을 통해 입증하였고, 관련 그래프 분석의 결과를 검증하였습니다.

Conclusion: MAIDs와 PSI 기술을 통해 복합적인 결과를 도출하고, MARL 학습 패러다임의 실용성을 평가할 수 있는 도구를 제공하였습니다.

Abstract: Steering cooperative multi-agent reinforcement learning (MARL) towards
desired outcomes is challenging, particularly when the global guidance from a
human on the whole multi-agent system is impractical in a large-scale MARL. On
the other hand, designing mechanisms to coordinate agents most relies on
empirical studies, lacking a easy-to-use research tool. In this work, we employ
multi-agent influence diagrams (MAIDs) as a graphical framework to address the
above issues. First, we introduce interaction paradigms that leverage MAIDs to
analyze and visualize existing approaches in MARL. Then, we design a new
interaction paradigm based on MAIDs, referred to as targeted intervention that
is applied to only a single targeted agent, so the problem of global guidance
can be mitigated. In our implementation, we introduce a causal inference
technique-referred to as Pre-Strategy Intervention (PSI)-to realize the
targeted intervention paradigm. Since MAIDs can be regarded as a special class
of causal diagrams, a composite desired outcome that integrates the primary
task goal and an additional desired outcome can be achieved by maximizing the
corresponding causal effect through the PSI. Moreover, the bundled relevance
graph analysis of MAIDs provides a tool to identify whether an MARL learning
paradigm is workable under the design of an interaction paradigm. In
experiments, we demonstrate the effectiveness of our proposed targeted
intervention, and verify the result of relevance graph analysis.

</details>


### [36] [Humanoid-inspired Causal Representation Learning for Domain Generalization](https://arxiv.org/abs/2510.16382)
*Ze Tao,Jian Zhang,Haowei Li,Xianshuai Li,Yifei Peng,Xiyao Liu,Senzhang Wang,Chao Liu,Sheng Ren,Shichao Zhang*

Main category: cs.AI

TL;DR: HSCM은 인간 지능에서 영감을 받은 새로운 인과 모델로, 기존의 도메인 일반화 모델의 한계를 극복하기 위한 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 도메인 일반화 모델의 한계를 극복하기 위해 인간 지능에서 영감을 받은 인과 모델을 제안한다.

Method: HSCM은 인간의 시각 시스템의 계층적 처리 및 다단계 학습을 모방하여, 색상, 텍스처, 형태와 같은 이미지 속성을 분리하고 재가중치하여 인과 메커니즘을 모델링한다.

Result: HSCM은 기존 도메인 일반화 모델들보다 더 나은 성능을 보여주며, 강력한 성능과 해석 가능성을 보장한다.

Conclusion: HSCM은 동적이고 복잡한 환경에서의 효과적인 전이 및 학습을 가능하게 하며, 인과 관계를 더 잘 포착할 수 있는 방법을 제공한다.

Abstract: This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a
novel causal framework inspired by human intelligence, designed to overcome the
limitations of conventional domain generalization models. Unlike approaches
that rely on statistics to capture data-label dependencies and learn
distortion-invariant representations, HSCM replicates the hierarchical
processing and multi-level learning of human vision systems, focusing on
modeling fine-grained causal mechanisms. By disentangling and reweighting key
image attributes such as color, texture, and shape, HSCM enhances
generalization across diverse domains, ensuring robust performance and
interpretability. Leveraging the flexibility and adaptability of human
intelligence, our approach enables more effective transfer and learning in
dynamic, complex environments. Through both theoretical and empirical
evaluations, we demonstrate that HSCM outperforms existing domain
generalization models, providing a more principled method for capturing causal
relationships and improving model robustness. The code is available at
https://github.com/lambett/HSCM.

</details>


### [37] [RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile](https://arxiv.org/abs/2510.16392)
*Ao Tian,Yunfeng Lu,Xinxin Fan,Changhao Wang,Lanzhi Zhou,Yeyao Zhang,Yanfang Liu*

Main category: cs.AI

TL;DR: 사용자 경험 향상을 위한 개인화 및 지속적인 상호작용이 필요하지만, 기존의 한정된 컨텍스트와 정적 기억 장치로 인해 사용자 상태 및 행동 일관성을 모델링하는 데 어려움이 있다. 이를 해결하기 위해 RGMem이라는 자기 진화 메모리 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 기반의 대화 시스템에서 사용자 경험을 향상시키기 위한 개인화 및 지속적인 상호작용의 중요성.

Method: RGMem 프레임워크는 대화 기록을 다중 스케일로 구성하여 에피소드 조각에서 의미와 사용자 통찰력을 추출하고, 계층적 세분화 및 재조정 작업을 통해 동적으로 진화하는 사용자 프로필을 형성한다.

Result: 이 프레임워크는 정보 압축 및 출현의 다중 스케일 프로세스로 메모리 진화를 모델링하여 높은 수준의 정확한 사용자 프로필을 생성한다.

Conclusion: RGMem은 저자와 사용자 간 지속적이고 일관된 상호작용을 가능하게 하여 개인화된 사용자 경험을 향상시킨다.

Abstract: Personalized and continuous interactions are the key to enhancing user
experience in today's large language model (LLM)-based conversational systems,
however, the finite context windows and static parametric memory make it
difficult to model the cross-session long-term user states and behavioral
consistency. Currently, the existing solutions to this predicament, such as
retrieval-augmented generation (RAG) and explicit memory systems, primarily
focus on fact-level storage and retrieval, lacking the capability to distill
latent preferences and deep traits from the multi-turn dialogues, which limits
the long-term and effective user modeling, directly leading to the personalized
interactions remaining shallow, and hindering the cross-session continuity. To
realize the long-term memory and behavioral consistency for Language Agents in
LLM era, we propose a self-evolving memory framework RGMem, inspired by the
ideology of classic renormalization group (RG) in physics, this framework
enables to organize the dialogue history in multiple scales: it first extracts
semantics and user insights from episodic fragments, then through hierarchical
coarse-graining and rescaling operations, progressively forms a
dynamically-evolved user profile. The core innovation of our work lies in
modeling memory evolution as a multi-scale process of information compression
and emergence, which accomplishes the high-level and accurate user profiles
from noisy and microscopic-level interactions.

</details>


### [38] [BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction](https://arxiv.org/abs/2510.16559)
*Tian Xia,Tianrun Gao,Wenhao Deng,Long Wei,Xiaowei Qian,Yixian Jiang,Chenglei Yu,Tailin Wu*

Main category: cs.AI

TL;DR: BuildArena는 언어 기반의 엔지니어링 건설을 위한 첫 번째 물리학 정렬 상호작용 벤치마크로, LLM의 건설 능력을 평가하고 비교하는 데 기여한다.


<details>
  <summary>Details</summary>
Motivation: 엔지니어링 건설 자동화는 자연어 명세를 물리적으로 실행 가능한 구조물로 변환하기 위해 필요하며, 이는 복잡한 통합 추론과 엄격한 물리적 제약을 요구한다.

Method: BuildArena는 LLM을 위한 커스터마이즈 가능한 벤치마킹 프레임워크, 정적 및 동적 역학을 아우르는 과제 설계 전략, 언어 명령에 기반한 건설을 지원하는 3D 공간 기하학 계산 라이브러리, 다양한 모델 능력을 평가하는 기준 LLM 에이전트 작업 흐름을 포함한다.

Result: BuildArena는 8개의 최전선 LLM을 대상으로 언어 기반 및 물리적으로 근거 있는 건설 자동화 능력을 종합적으로 평가하였다.

Conclusion: 이 프로젝트는 LLM의 건설 역량에 대한 평가를 통해 엔지니어링 건설 자동화 분야에 기여하고 있다.

Abstract: Engineering construction automation aims to transform natural language
specifications into physically viable structures, requiring complex integrated
reasoning under strict physical constraints. While modern LLMs possess broad
knowledge and strong reasoning capabilities that make them promising candidates
for this domain, their construction competencies remain largely unevaluated. To
address this gap, we introduce BuildArena, the first physics-aligned
interactive benchmark designed for language-driven engineering construction. It
contributes to the community in four aspects: (1) a highly customizable
benchmarking framework for in-depth comparison and analysis of LLMs; (2) an
extendable task design strategy spanning static and dynamic mechanics across
multiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for
supporting construction based on language instructions; (4) a baseline LLM
agentic workflow that effectively evaluates diverse model capabilities. On
eight frontier LLMs, BuildArena comprehensively evaluates their capabilities
for language-driven and physics-grounded construction automation. The project
page is at https://build-arena.github.io/.

</details>


### [39] [Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review](https://arxiv.org/abs/2510.16658)
*Shihao Yang,Xiying Huang,Danilo Bernardo,Jun-En Ding,Andrew Michael,Jingmei Yang,Patrick Kwan,Ashish Raj,Feng Liu*

Main category: cs.AI

TL;DR: 대규모 인공지능 모델이 신경 과학 연구에 혁신적인 영향을 미치고 있으며, 이는 전통적인 계산 방법에서 패러다임 전환을 의미한다. 본 논문에서는 신경 이미징, 뇌-컴퓨터 인터페이스, 분자 신경 과학 등 다섯 가지 주요 분야에서의 변혁적 효과를 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 인공지능 모델이 신경 과학 분야에 미치는 영향과 가능성을 조사하기 위해.

Method: 대규모 인공지능 모델이 신경 과학의 다양한 분야에 적용되는 방식과 그 효과를 탐구하고, 주요 도전 과제를 해결하는 방법을 분석한다.

Result: 대규모 인공지능 모델이 멀티모달 신경 데이터 통합, 시공간 패턴 해석 등의 문제를 해결하는 데 기여하며, 신경 과학과 AI 간의 상호작용이 더욱 깊어지고 있음을 확인했다.

Conclusion: 대규모 AI 모델의 신경 과학 분야에서의 발전 가능성과 중요한 구현 고려 사항을 강조하고, 임상 사용을 위한 윤리적 지침이 필요함을 지적한다.

Abstract: The advent of large-scale artificial intelligence (AI) models has a
transformative effect on neuroscience research, which represents a paradigm
shift from the traditional computational methods through the facilitation of
end-to-end learning from raw brain signals and neural data. In this paper, we
explore the transformative effects of large-scale AI models on five major
neuroscience domains: neuroimaging and data processing, brain-computer
interfaces and neural decoding, molecular neuroscience and genomic modeling,
clinical assistance and translational frameworks, and disease-specific
applications across neurological and psychiatric disorders. These models are
demonstrated to address major computational neuroscience challenges, including
multimodal neural data integration, spatiotemporal pattern interpretation, and
the derivation of translational frameworks for clinical deployment. Moreover,
the interaction between neuroscience and AI has become increasingly reciprocal,
as biologically informed architectural constraints are now incorporated to
develop more interpretable and computationally efficient models. This review
highlights both the notable promise of such technologies and key implementation
considerations, with particular emphasis on rigorous evaluation frameworks,
effective domain knowledge integration, and comprehensive ethical guidelines
for clinical use. Finally, a systematic listing of critical neuroscience
datasets used to derive and validate large-scale AI models across diverse
research applications is provided.

</details>


### [40] [An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems](https://arxiv.org/abs/2510.16701)
*Ni Zhang,Zhiguang Cao,Jianan Zhou,Cong Zhang,Yew-Soon Ong*

Main category: cs.AI

TL;DR: 본 논문은 복잡한 차량 라우팅 문제를 해결하기 위해 LLM을 사용하는 에이전틱 프레임워크(AFL)를 제안하며, 완전 자동화를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 차량 라우팅 문제는 전문가의 해석 및 알고리즘 설계를 요구하는 기본적인 도전 과제이다.

Method: AFL은 원시 입력에서 지식을 직접 추출하고, 수작업 모듈이나 외부 해결사 없이 자급자족형 코드 생성을 가능하게 한다.

Result: 60개의 복잡한 VRP에 대한 광범위한 실험을 통해 우리의 프레임워크의 효과성과 일반성을 검증하였다.

Conclusion: AFL은 코드 신뢰성 및 해결 가능성 면에서 기존 LLM 기반 기준선을 크게 능가하며, 평가된 기준에서 100%에 가까운 비율을 달성하였다.

Abstract: Complex vehicle routing problems (VRPs) remain a fundamental challenge,
demanding substantial expert effort for intent interpretation and algorithm
design. While large language models (LLMs) offer a promising path toward
automation, current approaches still rely on external intervention, which
restrict autonomy and often lead to execution errors and low solution
feasibility. To address these challenges, we propose an Agentic Framework with
LLMs (AFL) for solving complex vehicle routing problems, achieving full
automation from problem instance to solution. AFL directly extracts knowledge
from raw inputs and enables self-contained code generation without handcrafted
modules or external solvers. To improve trustworthiness, AFL decomposes the
overall pipeline into three manageable subtasks and employs four specialized
agents whose coordinated interactions enforce cross-functional consistency and
logical soundness. Extensive experiments on 60 complex VRPs, ranging from
standard benchmarks to practical variants, validate the effectiveness and
generality of our framework, showing comparable performance against
meticulously designed algorithms. Notably, it substantially outperforms
existing LLM-based baselines in both code reliability and solution feasibility,
achieving rates close to 100% on the evaluated benchmarks.

</details>


### [41] [Beyond Pipelines: A Survey of the Paradigm Shift toward Model-Native Agentic AI](https://arxiv.org/abs/2510.16720)
*Jitao Sang,Jinlin Xiao,Jiarun Han,Jilin Chen,Xiaoyi Chen,Shuyu Wei,Yongjie Sun,Yuhang Wang*

Main category: cs.AI

TL;DR: 에이전틱 AI의 급속한 발전은 인공지능의 새로운 단계로, 대형 언어 모델(LLM)이 더 이상 단순히 응답하는 것이 아니라 행동하고, 추론하며, 적응하는 시점을 나타낸다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI 구축에서의 패러다임 전환을 추적하고, 모델 내 재구성을 통한 새로운 접근 방식을 제시합니다.

Method: 강화 학습(RL)을 알고리즘 엔진으로 사용하고, 정적 데이터를 모방하는 학습에서 결과 기반 탐험으로 재구성하여 LLM + RL + 작업을 통합 솔루션으로 제시합니다.

Result: 계획, 도구 사용, 기억 등의 주요 기능이 외부 스크립트 모듈에서 끝-투-끝 학습 행동으로 발전한 과정을 체계적으로 검토합니다.

Conclusion: 에이전틱 AI의 지속적인 내재화와 미래 모델에 대한 역할 변화를 논의하며 모델 내 에이전틱 능력의 발전 방향을 제시합니다.

Abstract: The rapid evolution of agentic AI marks a new phase in artificial
intelligence, where Large Language Models (LLMs) no longer merely respond but
act, reason, and adapt. This survey traces the paradigm shift in building
agentic AI: from Pipeline-based systems, where planning, tool use, and memory
are orchestrated by external logic, to the emerging Model-native paradigm,
where these capabilities are internalized within the model's parameters. We
first position Reinforcement Learning (RL) as the algorithmic engine enabling
this paradigm shift. By reframing learning from imitating static data to
outcome-driven exploration, RL underpins a unified solution of LLM + RL + Task
across language, vision and embodied domains. Building on this, the survey
systematically reviews how each capability -- Planning, Tool use, and Memory --
has evolved from externally scripted modules to end-to-end learned behaviors.
Furthermore, it examines how this paradigm shift has reshaped major agent
applications, specifically the Deep Research agent emphasizing long-horizon
reasoning and the GUI agent emphasizing embodied interaction. We conclude by
discussing the continued internalization of agentic capabilities like
Multi-agent collaboration and Reflection, alongside the evolving roles of the
system and model layers in future agentic AI. Together, these developments
outline a coherent trajectory toward model-native agentic AI as an integrated
learning and interaction framework, marking the transition from constructing
systems that apply intelligence to developing models that grow intelligence
through experience.

</details>


### [42] [A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications](https://arxiv.org/abs/2510.16724)
*Minhua Lin,Zongyu Wu,Zhichao Xu,Hui Liu,Xianfeng Tang,Qi He,Charu Aggarwal,Hui Liu,Xiang Zhang,Suhang Wang*

Main category: cs.AI

TL;DR: 이 논문은 RL 기반의 주체적 검색에 대한 포괄적인 개요를 제공하며, 미래 연구에 대한 영감을 주기를 희망한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 발전에도 불구하고, 정적 지식과 사실적 환각, 실시간 또는 도메인 특정 정보를 검색할 수 없는 한계가 있습니다.

Method: 강화 학습(RL)을 통한 다단계 상호작용으로 LLM이 계획하고, 검색하고, 반영할 수 있도록 하는 주체적 검색의 진전을 다루었습니다.

Result: RL 기반의 주체적 검색에 대한 세 가지 상호보완적 범주를 정리하였습니다: 기능적 역할, 최적화 전략 및 최적화의 범위.

Conclusion: 신뢰할 수 있고 확장 가능한 RL 기반의 주체적 검색 시스템 구축을 위한 개방된 도전과제와 미래 방향을 논의합니다.

Abstract: The advent of large language models (LLMs) has transformed information access
and reasoning through open-ended natural language interaction. However, LLMs
remain limited by static knowledge, factual hallucinations, and the inability
to retrieve real-time or domain-specific information. Retrieval-Augmented
Generation (RAG) mitigates these issues by grounding model outputs in external
evidence, but traditional RAG pipelines are often single turn and heuristic,
lacking adaptive control over retrieval and reasoning. Recent advances in
agentic search address these limitations by enabling LLMs to plan, retrieve,
and reflect through multi-step interaction with search environments. Within
this paradigm, reinforcement learning (RL) offers a powerful mechanism for
adaptive and self-improving search behavior. This survey provides the first
comprehensive overview of \emph{RL-based agentic search}, organizing the
emerging field along three complementary dimensions: (i) What RL is for
(functional roles), (ii) How RL is used (optimization strategies), and (iii)
Where RL is applied (scope of optimization). We summarize representative
methods, evaluation protocols, and applications, and discuss open challenges
and future directions toward building reliable and scalable RL driven agentic
search systems. We hope this survey will inspire future research on the
integration of RL and agentic search. Our repository is available at
https://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.

</details>


### [43] [End-to-end Listen, Look, Speak and Act](https://arxiv.org/abs/2510.16756)
*Siyin Wang,Wenyi Yu,Xianzhao Chen,Xiaohai Tian,Jun Zhang,Lu Lu,Chao Zhang*

Main category: cs.AI

TL;DR: 이 논문에서는 ELLSA라는 새로운 모델을 제시하며, 이는 시각, 텍스트, 음성 및 행동을 동시에 인식하고 생성하는 최초의 풀-듀플렉스(end-to-end) 모델이다.


<details>
  <summary>Details</summary>
Motivation: 인간 상호작용은 본질적으로 다중 양식(multimodal)이며, 이를 모델링하는 것이 필수적이다.

Method: ELLSA는 SA-MoE(Self-Attention Mixture-of-Experts) 아키텍처를 기반으로 하여 각 양식을 전문화된 전문가에게 라우팅하고 통합된 주의 백본을 통해 융합하는 방식으로 작동한다.

Result: ELLSA는 음성 상호작용 및 로봇 조작 벤치마크에서 양식 특정 기준선을 충족시키며 고급 다중 양식 및 풀-듀플렉스 행동을 지원한다.

Conclusion: ELLSA는 보다 자연스럽고 일반적인 상호작용 지능으로 나아가는 한 걸음을 보여준다.

Abstract: Human interaction is inherently multimodal and full-duplex: we listen while
watching, speak while acting, and fluidly adapt to turn-taking and
interruptions. Realizing these capabilities is essential for building models
simulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act),
which, to our knowledge, is the first full-duplex, end-to-end model that
simultaneously perceives and generates across vision, text, speech, and action
within a single architecture, enabling interaction patterns previously out of
reach, yielding more natural, human-like behaviors. At its core is a novel
SA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each
modality to specialized experts and fuses them through a unified attention
backbone. This provides a generalizable solution for joint multimodal
perception and concurrent generation, leveraging strong pre-trained components
while enabling efficient modality integration and mitigating modality
interference. On speech-interaction and robot-manipulation benchmarks, ELLSA
matches modality-specific baselines, while uniquely supporting advanced
multimodal and full-duplex behaviors such as dialogue and action turn-taking,
defective instruction rejection, speaking-while-acting, context-grounded visual
question answering, and action barge-ins. We contend that ELLSA represents a
step toward more natural and general interactive intelligence, contributing to
the broader pursuit of artificial general intelligence. All data, code and
model checkpoints will be released upon acceptance.

</details>


### [44] [See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models](https://arxiv.org/abs/2510.16769)
*Shuo Han,Yukun Cao,Zezhong Ding,Zengyi Gao,S Kevin Zhou,Xike Xie*

Main category: cs.AI

TL;DR: GraphVista는 그래프 이해에서 확장성과 모드 조정 문제를 해결하는 통합 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 그래프 이해에서 VLMs의 한계인 입력 토큰 제약과 확장성 병목 현상, 텍스트와 시각 모드의 조정 메커니즘 부족을 해결하기 위해.

Method: GraphVista는 경량 GraphRAG 기반이 계층적으로 그래프 정보를 구성하고, 작업에 관련된 텍스트 설명과 고해상도 시각 서브그래프만 검색하여 중복된 맥락을 압축하면서 핵심 추론 요소를 보존한다. 또한, 계획 에이전트를 통해 가장 적합한 모드로 작업을 라우팅하여 간단한 속성 추론에는 텍스트 모드를, 명시적 토폴로지에 기반한 지역적이고 구조적으로 복잡한 추론에는 시각 모드를 사용한다.

Result: GraphVista는 최대 $200	imes$ 더 큰 그래프에 대해 확장 가능하며 기존 텍스트, 시각 및 융합 기반 방법보다 지속적으로 우수한 성능을 나타내며, 두 모드의 보완적 강점을 충분히 활용하여 최첨단 기준선에 비해 최대 $4.4	imes$ 품질 개선을 달성한다.

Conclusion: GraphVista는 그래프 이해의 확장성과 모드 조정을 크게 개선하여 VLMs의 한계를 극복한다.

Abstract: Vision-language models (VLMs) have shown promise in graph understanding, but
remain limited by input-token constraints, facing scalability bottlenecks and
lacking effective mechanisms to coordinate textual and visual modalities. To
address these challenges, we propose GraphVista, a unified framework that
enhances both scalability and modality coordination in graph understanding. For
scalability, GraphVista organizes graph information hierarchically into a
lightweight GraphRAG base, which retrieves only task-relevant textual
descriptions and high-resolution visual subgraphs, compressing redundant
context while preserving key reasoning elements. For modality coordination,
GraphVista introduces a planning agent that routes tasks to the most suitable
modality-using the text modality for simple property reasoning and the visual
modality for local and structurally complex reasoning grounded in explicit
topology. Extensive experiments demonstrate that GraphVista scales to large
graphs, up to $200\times$ larger than those used in existing benchmarks, and
consistently outperforms existing textual, visual, and fusion-based methods,
achieving up to $4.4\times$ quality improvement over the state-of-the-art
baselines by fully exploiting the complementary strengths of both modalities.

</details>


### [45] [DeepAnalyze: Agentic Large Language Models for Autonomous Data Science](https://arxiv.org/abs/2510.16872)
*Shaolei Zhang,Ju Fan,Meihao Fan,Guoliang Li,Xiaoyong Du*

Main category: cs.AI

TL;DR: DeepAnalyze-8B는 자율 데이터 과학을 위한 최초의 에이전트 LLM으로, 데이터 소스에서 분석가 수준의 심층 연구 보고서까지의 전체 파이프라인을 자동으로 완성할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 원시 데이터 소스에서 분석가 수준의 심층 연구 보고서에 이르기까지 자율 데이터 과학은 오랫동안 도전 과제로 남아 있었으며, 강력한 대규모 언어 모델(LLMs)의 출현으로 이제 실현 가능해지고 있다.

Method: DeepAnalyze-8B는 데이터를 기반으로 한 다양한 학습 경로를 모방하는 커리큘럼 기반 에이전트 훈련 패러다임을 제안하여 LLM이 실제 환경에서 여러 기능을 점진적으로 습득하고 통합할 수 있도록 한다.

Result: DeepAnalyze는 80억 개의 매개변수만으로도 가장 발전된 독점 LLM에 기반한 기존 워크플로우 기반 에이전트보다 우수한 성능을 발휘한다.

Conclusion: DeepAnalyze의 모델, 코드 및 훈련 데이터는 오픈 소스로 제공되며, 자율 데이터 과학을 향한 길을 열어간다.

Abstract: Autonomous data science, from raw data sources to analyst-grade deep research
reports, has been a long-standing challenge, and is now becoming feasible with
the emergence of powerful large language models (LLMs). Recent workflow-based
data agents have shown promising results on specific data tasks but remain
fundamentally limited in achieving fully autonomous data science due to their
reliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,
the first agentic LLM designed for autonomous data science, capable of
automatically completing the end-toend pipeline from data sources to
analyst-grade deep research reports. To tackle high-complexity data science
tasks, we propose a curriculum-based agentic training paradigm that emulates
the learning trajectory of human data scientists, enabling LLMs to
progressively acquire and integrate multiple capabilities in real-world
environments. We also introduce a data-grounded trajectory synthesis framework
that constructs high-quality training data. Through agentic training,
DeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data
question answering and specialized analytical tasks to open-ended data
research. Experiments demonstrate that, with only 8B parameters, DeepAnalyze
outperforms previous workflow-based agents built on most advanced proprietary
LLMs. The model, code, and training data of DeepAnalyze are open-sourced,
paving the way toward autonomous data science.

</details>


### [46] [VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents](https://arxiv.org/abs/2510.16907)
*Kangrui Wang,Pingyue Zhang,Zihan Wang,Yaning Gao,Linjie Li,Qineng Wang,Hanyang Chen,Chi Wan,Yiping Lu,Zhengyuan Yang,Lijuan Wang,Ranjay Krishna,Jiajun Wu,Li Fei-Fei,Yejin Choi,Manling Li*

Main category: cs.AI

TL;DR: 이 논문은 비주얼-언어 모델(VLM) 에이전트가 텍스트 상태에서 복잡한 시각적 관찰로의 전환 과정에서 내부 세계 모델을 구축할 수 있는지를 연구합니다.


<details>
  <summary>Details</summary>
Motivation: VLM 에이전트 훈련에서의 어려움을 극복하고, 내부 세계 모델 구축을 통한 시각적 상태 추론의 가능성을 탐구하고자 합니다.

Method: 강화 학습을 통해 에이전트의 추론 과정을 설계하고 보상하며, 이를 부분 관측 가능 마르코프 결정 과정(POMDP)으로 공식화합니다.

Result: 에이전트의 추론을 상태 추정과 전이 모델링으로 분해함으로써 성공적인 성과를 달성하며, 자연어와 구조화된 형식의 적용에 따라 최적의 표현이 작업 의존적임을 확인했습니다.

Conclusion: VLM 에이전트는 개선된 세계 모델링 보상과 차별화된 신용 할당 방법을 통해 다각적인 벤치마크에서 우수한 성과를 기록하였습니다.

Abstract: A key challenge in training Vision-Language Model (VLM) agents, compared to
Language Model (LLM) agents, lies in the shift from textual states to complex
visual observations. This transition introduces partial observability and
demands robust world modeling. We ask: Can VLM agents construct internal world
models through explicit visual state reasoning? To address this question, we
architecturally enforce and reward the agent's reasoning process via
reinforcement learning (RL), formulating it as a Partially Observable Markov
Decision Process (POMDP). We find that decomposing the agent's reasoning into
State Estimation ("what is the current state?") and Transition Modeling ("what
comes next?") is critical for success, as demonstrated through five reasoning
strategies. Our investigation into how agents represent internal beliefs
reveals that the optimal representation is task-dependent: Natural Language
excels at capturing semantic relationships in general tasks, while Structured
formats are indispensable for precise manipulation and control. Building on
these insights, we design a World Modeling Reward that provides dense,
turn-level supervision for accurate state prediction, and introduce Bi-Level
General Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment.
Through this form of visual state reasoning, a 3B-parameter model achieves a
score of 0.82 across five diverse agent benchmarks, representing a 3$\times$
improvement over its untrained counterpart (0.21) and outperforming proprietary
reasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5
(0.62). All experiments are conducted within our VAGEN framework, a scalable
system for training and analyzing multi-turn VLM agents in diverse visual
environments. Code and data are publicly available at
https://vagen-ai.github.io.

</details>


### [47] [A Comparative User Evaluation of XRL Explanations using Goal Identification](https://arxiv.org/abs/2510.16956)
*Mark Towers,Yali Du,Christopher Freeman,Timothy J. Norman*

Main category: cs.AI

TL;DR: 이 연구는 설명 가능한 강화 학습(XRL) 알고리즘의 성능을 비교 평가하는 새로운 방법론을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 설명 가능한 강화 학습 알고리즘의 디버깅 성능을 이해하기 위한 비교 평가가 부족하다.

Method: Ms. Pacman 환경과 네 가지 XRL 알고리즘을 활용하여 사용자가 의사 결정 설명으로부터 에이전트의 목표를 식별할 수 있는지를 테스트하는 방법론을 제안한다.

Result: 테스트된 목표에 대해 무작위 정확도를 초과한 성과를 달성한 XRL 알고리즘은 단 하나였으며, 사용자들은 일반적으로 자신의 선택에 대해 과신하는 경향이 있었다.

Conclusion: 사용자가 각 설명의 식별 및 이해 용이성을 자체 보고했지만, 이는 그들의 정확성과 상관관계가 없었다.

Abstract: Debugging is a core application of explainable reinforcement learning (XRL)
algorithms; however, limited comparative evaluations have been conducted to
understand their relative performance. We propose a novel evaluation
methodology to test whether users can identify an agent's goal from an
explanation of its decision-making. Utilising the Atari's Ms. Pacman
environment and four XRL algorithms, we find that only one achieved greater
than random accuracy for the tested goals and that users were generally
overconfident in their selections. Further, we find that users' self-reported
ease of identification and understanding for every explanation did not
correlate with their accuracy.

</details>


### [48] [STARK: Strategic Team of Agents for Refining Kernels](https://arxiv.org/abs/2510.16996)
*Juncheng Dong,Yang Yang,Tao Liu,Yang Wang,Feng Qi,Vahid Tarokh,Kaushik Rangadurai,Shuang Yang*

Main category: cs.AI

TL;DR: GPU 커널의 효율성은 현대 AI의 발전에 핵심적이지만, 최적화는 여전히 복잡한 요인들로 인해 어려운 작업이다. 최근 대형 언어 모델(LLM)의 발전은 자동 코드 생성을 위한 새로운 기회를 제공하지만, 기존 접근법은 LLM을 단순 생성기 또는 단순 정제 도구로 취급하여 효과를 제한한다. 우리는 다중 에이전트 협업, 명확한 지침, 동적 컨텍스트 관리 및 전략적 검색을 통해 디자인 공간을 체계적으로 탐색하는 LLM 에이전트 프레임워크를 소개하고, 이를 KernelBench에서 평가하여 기존 에이전트보다 상당한 개선을 이루었다. 이 결과는 LLM 프레임워크의 전체 자동화된 GPU 커널 최적화 가능성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: GPU 커널의 최적화는 현대 AI의 발전에 필수적이며, 메모리 계층, 스레드 스케줄링, 하드웨어 특성 간의 복잡한 상호작용으로 인해 어려운 작업이다.

Method: 우리는 다중 에이전트 협업, 기반 지침, 동적 컨텍스트 관리, 전략적 검색을 통해 GPU 커널 최적화를 위한 LLM 에이전트적 프레임워크를 제안한다.

Result: KernelBench를 이용한 평가에서, 우리 시스템은 기존 에이전트에 비해 올바른 솔루션을 생성하고 커널의 최대 16배 더 빠른 실행 성능을 달성했다.

Conclusion: 이러한 결과는 에이전트적 LLM 프레임워크가 완전 자동화된 확장 가능한 GPU 커널 최적화를 촉진할 수 있는 잠재력을 강조한다.

Abstract: The efficiency of GPU kernels is central to the progress of modern AI, yet
optimizing them remains a difficult and labor-intensive task due to complex
interactions between memory hierarchies, thread scheduling, and
hardware-specific characteristics. While recent advances in large language
models (LLMs) provide new opportunities for automated code generation, existing
approaches largely treat LLMs as single-shot generators or naive refinement
tools, limiting their effectiveness in navigating the irregular kernel
optimization landscape. We introduce an LLM agentic framework for GPU kernel
optimization that systematically explores the design space through multi-agent
collaboration, grounded instruction, dynamic context management, and strategic
search. This framework mimics the workflow of expert engineers, enabling LLMs
to reason about hardware trade-offs, incorporate profiling feedback, and refine
kernels iteratively. We evaluate our approach on KernelBench, a benchmark for
LLM-based kernel optimization, and demonstrate substantial improvements over
baseline agents: our system produces correct solutions where baselines often
fail, and achieves kernels with up to 16x faster runtime performance. These
results highlight the potential of agentic LLM frameworks to advance fully
automated, scalable GPU kernel optimization.

</details>


### [49] [A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation](https://arxiv.org/abs/2510.17064)
*Rongbin Li,Wenbo Chen,Zhao Li,Rodrigo Munoz-Castaneda,Jinbo Li,Neha S. Maurya,Arnav Solanki,Huan He,Hanwen Xing,Meaghan Ramlakhan,Zachary Wise,Zhuhao Wu,Hua Xu,Michael Hawrylycz,W. Jim Zheng*

Main category: cs.AI

TL;DR: BRAINCELL-AID는 단일 세포 RNA 시퀀싱을 통해 세포 유형 및 전사체 서명을 더 정확하게 주석 처리할 수 있도록 돕는 다중 에이전트 AI 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 다양한 세포 유형과 전사체 서명을 식별할 수 있는 단일 세포 RNA 시퀀싱의 발전에도 불구하고, 특히 잘 정의되지 않은 유전자와 관련된 서명을 주석하는 것은 여전히 큰 도전 과제이다.

Method: BRAINCELL-AID는 자연어 설명과 온톨로지 레이블을 통합하여 더 정확하고 강력한 유전자 세트 주석을 가능하게 하는 새로운 다중 에이전트 AI 시스템이다.

Result: 이 워크플로우를 사용하여 상위 예측 중 77%의 마우스 유전자 세트에 대해 정확한 주석을 달 수 있었다.

Conclusion: BRAINCELL-AID는 기능적 역할을 추론하고 유전자 집합의 지역 특이적 발현 패턴을 식별하여 뇌 세포 기능에 대한 새로운 통찰을 가능하게 하는 귀중한 리소스를 생성한다.

Abstract: Single-cell RNA sequencing has transformed our ability to identify diverse
cell types and their transcriptomic signatures. However, annotating these
signatures-especially those involving poorly characterized genes-remains a
major challenge. Traditional methods, such as Gene Set Enrichment Analysis
(GSEA), depend on well-curated annotations and often perform poorly in these
contexts. Large Language Models (LLMs) offer a promising alternative but
struggle to represent complex biological knowledge within structured
ontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:
https://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that
integrates free-text descriptions with ontology labels to enable more accurate
and robust gene set annotation. By incorporating retrieval-augmented generation
(RAG), we developed a robust agentic workflow that refines predictions using
relevant PubMed literature, reducing hallucinations and enhancing
interpretability. Using this workflow, we achieved correct annotations for 77%
of mouse gene sets among their top predictions. Applying this approach, we
annotated 5,322 brain cell clusters from the comprehensive mouse brain cell
atlas generated by the BRAIN Initiative Cell Census Network, enabling novel
insights into brain cell function by identifying region-specific gene
co-expression patterns and inferring functional roles of gene ensembles.
BRAINCELL-AID also identifies Basal Ganglia-related cell types with
neurologically meaningful descriptions. Hence, we create a valuable resource to
support community-driven cell type annotation.

</details>


### [50] [Structured Debate Improves Corporate Credit Reasoning in Financial AI](https://arxiv.org/abs/2510.17108)
*Yoonjin Lee,Munhee Kim,Hanbi Choi,Juhyeon Park,Seungho Lyoo,Woojin Park*

Main category: cs.AI

TL;DR: 이 연구는 대출 평가에서 비재무적 증거를 기반으로 한 구조적 추론을 생성하기 위해 두 가지 대형 언어 모델 시스템을 개발하고 평가하였다. 이 시스템들은 기존의 수치적 예측 방법의 한계를 극복하여 대출 평가의 해석적 판단을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 재무 AI의 발전에도 불구하고, 대출 상환 결과에 중요한 영향을 미치는 비재무적 지표의 formalization이 해결되지 않았다.

Method: 첫 번째 시스템은 단일 통과 추론 파이프라인을 통해 양방향 분석을 생성하는 비대립 단일 에이전트 시스템(NAS)이며, 두 번째 시스템은 Karl Popper의 비판적 대화 프레임워크에 기초한 10단계 구조적 상호작용 프로토콜을 통해 대립적 검증을 운영하는 논쟁 기반 다중 에이전트 시스템(KPD-MADS)이다.

Result: 세 가지 실기업 사례에 적용된 이 시스템들은 경험이 풍부한 신용 위험 전문가들에 의해 평가되었으며, 수동 전문가 보고서와 비교했을 때, 두 시스템 모두 상당한 생산성 향상을 달성했다(NAS: 11.55초, KPD-MADS: 91.97초, 인간 기준: 1920초). KPD-MADS는 설명 적합성(4.0 대 3.0), 실용성(4.0 대 3.0), 사용성(62.5 대 52.5)에서 더 높은 중간 등급을 받아 뛰어난 추론 품질을 보여주었다.

Conclusion: 이러한 발견들은 구조적 다중 에이전트 상호작용이 재무 AI에서 추론의 엄밀성과 해석 가능성을 향상시킬 수 있으며, 기업 신용 평가의 규모 있고 방어 가능한 자동화를 진전시킬 수 있음을 시사한다.

Abstract: Despite advances in financial AI, the automation of evidence-based reasoning
remains unresolved in corporate credit assessment, where qualitative
non-financial indicators exert decisive influence on loan repayment outcomes
yet resist formalization. Existing approaches focus predominantly on numerical
prediction and provide limited support for the interpretive judgments required
in professional loan evaluation. This study develops and evaluates two
operational large language model (LLM)-based systems designed to generate
structured reasoning from non-financial evidence. The first is a
non-adversarial single-agent system (NAS) that produces bidirectional analysis
through a single-pass reasoning pipeline. The second is a debate-based
multi-agent system (KPD-MADS) that operationalizes adversarial verification
through a ten-step structured interaction protocol grounded in Karl Popper's
critical dialogue framework. Both systems were applied to three real corporate
cases and evaluated by experienced credit risk professionals. Compared to
manual expert reporting, both systems achieved substantial productivity gains
(NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The
KPD-MADS demonstrated superior reasoning quality, receiving higher median
ratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs.
3.0), and usability (62.5 vs. 52.5). These findings show that structured
multi-agent interaction can enhance reasoning rigor and interpretability in
financial AI, advancing scalable and defensible automation in corporate credit
assessment.

</details>


### [51] [Which LLM Multi-Agent Protocol to Choose?](https://arxiv.org/abs/2510.17149)
*Hongyi Du,Jiaqi Su,Jisen Li,Lijie Ding,Yingxuan Yang,Peixuan Han,Xiangru Tang,Kunlun Zhu,Jiaxuan You*

Main category: cs.AI

TL;DR: 다양한 에이전트 프로토콜을 체계적으로 비교하는 벤치마크인 ProtocolBench를 소개하며, 이를 통해 성능 및 신뢰성에 미치는 프로토콜 선택의 영향을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 다중 에이전트 시스템의 커뮤니케이션 프로토콜 계층이 성능과 신뢰성에 중요한 영향을 미친다.

Method: ProtocolBench를 사용하여 프로토콜을 작업 성공, 엔드 투 엔드 대기 시간, 메시지 또는 바이트 오버헤드, 실패 시 강건성의 네 가지 축으로 비교하였다.

Result: Streaming Queue 시나리오에서 프로토콜에 따른 전체 완료 시간이 최대 36.5%까지 차이나며, 평균 엔드 투 엔드 대기 시간이 3.48초 차이를 보였다. Fail-Storm Recovery 하에서도 프로토콜 간 강건성이 일관되게 다르게 나타났다.

Conclusion: ProtocolRouter라는 학습 가능한 프로토콜 라우터를 제안하고, 이를 통해 أفضل 단일 프로토콜 기준선 대비 Fail-Storm 복구 시간을 최대 18.1% 단축시키고, GAIA에서 더 높은 성공률과 같이 시나리오별 이득을 얻었다.

Abstract: As large-scale multi-agent systems evolve, the communication protocol layer
has become a critical yet under-evaluated factor shaping performance and
reliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,
etc.), selection is often intuition-driven and lacks standardized guidance. We
introduce ProtocolBench, a benchmark that systematically compares agent
protocols along four measurable axes: task success, end-to-end latency, message
or byte overhead, and robustness under failures. On ProtocolBench, protocol
choice significantly influences system behavior. In the Streaming Queue
scenario, overall completion time varies by up to 36.5% across protocols, and
mean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,
resilience also differs consistently across protocols. Beyond evaluation, we
present ProtocolRouter, a learnable protocol router that selects per-scenario
(or per-module) protocols from requirement and runtime signals. ProtocolRouter
reduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol
baseline, and achieves scenario-specific gains such as higher success in GAIA.
We also release ProtocolRouterBench to standardize protocol evaluation and
improve reliability at scale.

</details>


### [52] [Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis](https://arxiv.org/abs/2510.17235)
*Chong Chen,Ze Liu,Lingfeng Bao,Yanlin Wang,Ting Chen,Daoyuan Wu,Jiachi Chen*

Main category: cs.AI

TL;DR: Coinvisor는 강화학습 기반의 챗봇으로, 암호화폐 투자에 대한 포괄적인 분석 지원을 제공하며, 다양한 데이터 소스의 유연한 통합과 다단계 계획을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 암호화폐 시장의 변동성과 정보 파편화 문제를 해결하기 위해, 투자 결정을 위한 데이터 통합과 분석이 필수적이다.

Method: Coinvisor는 강화학습 기반의 다중 에이전트 프레임워크를 통해 다양한 분석 기능을 통합하며, 특화된 도구 선택 메커니즘을 통해 데이터 소스를 유연하게 통합한다.

Result: Coinvisor는 도구 조정에서 기본 모델 대비  recall을 40.7% 향상시키고, F1 점수를 26.6% 개선하였다. 사용자 연구는 높은 만족도(4.64/5)를 보였고, 참가자들은 Coinvisor를 일반 LLM과 기존 암호화폐 플랫폼보다 선호하였다 (4.62/5).

Conclusion: Coinvisor는 실시간 상호작용 및 동적 콘텐츠의 적응형 분석을 지원하여 정확하고 실행 가능한 투자 통찰력을 제공한다.

Abstract: The cryptocurrency market offers significant investment opportunities but
faces challenges including high volatility and fragmented information. Data
integration and analysis are essential for informed investment decisions.
Currently, investors use three main approaches: (1) Manual analysis across
various sources, which depends heavily on individual experience and is
time-consuming and prone to bias; (2) Data aggregation platforms-limited in
functionality and depth of analysis; (3) Large language model agents-based on
static pretrained models, lacking real-time data integration and multi-step
reasoning capabilities. To address these limitations, we present Coinvisor, a
reinforcement learning-based chatbot that provides comprehensive analytical
support for cryptocurrency investment through a multi-agent framework.
Coinvisor integrates diverse analytical capabilities through specialized tools.
Its key innovation is a reinforcement learning-based tool selection mechanism
that enables multi-step planning and flexible integration of diverse data
sources. This design supports real-time interaction and adaptive analysis of
dynamic content, delivering accurate and actionable investment insights. We
evaluated Coinvisor through automated benchmarks on tool calling accuracy and
user studies with 20 cryptocurrency investors using our interface. Results show
that Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base
model in tool orchestration. User studies show high satisfaction (4.64/5), with
participants preferring Coinvisor to both general LLMs and existing crypto
platforms (4.62/5).

</details>


### [53] [Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions](https://arxiv.org/abs/2510.17450)
*Johan Schubert,Farzad Kamrani,Tove Gustavi*

Main category: cs.AI

TL;DR: 본 연구는 자율 제어를 위한 지능형 에이전트의 능동적 추론 경로 계획 방법을 개발한다.


<details>
  <summary>Details</summary>
Motivation: 지능형 에이전트를 자율적으로 제어하기 위해 지리적 영역을 정찰하여 공통 작업 그림을 유지하는 것이 목표이다.

Method: Dempster-Shafer 이론과 가우시안 센서 모델을 사용하여 현재 상황에 대한 증거 지도를 구성하고, 이를 통해 에이전트에게 입력을 제공하는 생성 모델을 사용했다.

Result: 증거 지도와 관측된 목표 객체의 사후 확률 분포 간의 발산을 평가하여 지역 내 모든 위치에 대한 변동 자유 에너지를 계산했다.

Conclusion: 이를 통해 에이전트의 움직임을 자유 에너지를 최소화하는 방향으로 유도하였으며, 탐사와 활용의 균형을 맞추는 문제를 해결하였다.

Abstract: We develop an active inference route-planning method for the autonomous
control of intelligent agents. The aim is to reconnoiter a geographical area to
maintain a common operational picture. To achieve this, we construct an
evidence map that reflects our current understanding of the situation,
incorporating both positive and "negative" sensor observations of possible
target objects collected over time, and diffusing the evidence across the map
as time progresses. The generative model of active inference uses
Dempster-Shafer theory and a Gaussian sensor model, which provides input to the
agent. The generative process employs a Bayesian approach to update a posterior
probability distribution. We calculate the variational free energy for all
positions within the area by assessing the divergence between a pignistic
probability distribution of the evidence map and a posterior probability
distribution of a target object based on the observations, including the level
of surprise associated with receiving new observations. Using the free energy,
we direct the agents' movements in a simulation by taking an incremental step
toward a position that minimizes the free energy. This approach addresses the
challenge of exploration and exploitation, allowing agents to balance searching
extensive areas of the geographical map while tracking identified target
objects.

</details>


### [54] [MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning](https://arxiv.org/abs/2510.17590)
*Mir Nafis Sharear Shopnil,Sharad Duwal,Abhishek Tyagi,Adiba Mahbub Proma*

Main category: cs.AI

TL;DR: MIRAGE는 다중 모달 검증을 네 개의 모듈로 분해하여 허위 정보를 탐지하고, 도메인 특정 훈련 없이도 성능을 발휘하는 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 웹 플랫폼에서 정보가 잘못 퍼지는 현상과 수작업 사실 확인의 한계를 극복하기 위해 연구되었습니다.

Method: MIRAGE는 AI 생성 이미지 탐지, 맥락 외 재사용 식별, 웹 증거 기반 사실 확인, 신호 통합을 위한 네 개의 모듈로 구성됩니다.

Result: MIRAGE는 MMFakeBench 검증 세트에서 81.65% F1 점수와 75.1% 정확도로 강력한 제로 샷 기준을 초과하며, 5,000 샘플의 테스트 세트에서도 좋은 성과를 보입니다.

Conclusion: 우리의 연구 결과는 도메인 특정 훈련 없이도 웹 검색을 통한 분해된 에이전틱 추론이 감독된 탐지기 성능에 필적할 수 있음을 보여줍니다.

Abstract: Misinformation spreads across web platforms through billions of daily
multimodal posts that combine text and images, overwhelming manual
fact-checking capacity. Supervised detection models require domain-specific
training data and fail to generalize across diverse manipulation tactics. We
present MIRAGE, an inference-time, model-pluggable agentic framework that
decomposes multimodal verification into four sequential modules: visual
veracity assessment detects AI-generated images, cross-modal consistency
analysis identifies out-of-context repurposing, retrieval-augmented factual
checking grounds claims in web evidence through iterative question generation,
and a calibrated judgment module integrates all signals. MIRAGE orchestrates
vision-language model reasoning with targeted web retrieval, outputs structured
and citation-linked rationales. On MMFakeBench validation set (1,000 samples),
MIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming
the strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65
points while maintaining 34.3% false positive rate versus 97.3% for a
judge-only baseline. Test set results (5,000 samples) confirm generalization
with 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification
contributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97
points. Our results demonstrate that decomposed agentic reasoning with web
retrieval can match supervised detector performance without domain-specific
training, enabling misinformation detection across modalities where labeled
data remains scarce.

</details>


### [55] [Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs](https://arxiv.org/abs/2510.17771)
*Zhining Liu,Ziyi Chen,Hui Liu,Chen Luo,Xianfeng Tang,Suhang Wang,Joy Zeng,Zhenwei Dai,Zhan Shi,Tianxin Wei,Benoit Dumoulin,Hanghang Tong*

Main category: cs.AI

TL;DR: 이 연구는 비전-언어 모델(VLM)이 멀티모달 작업에서 강력한 성과를 보이지만, 올바른 시각적 증거가 있을 때도 실패할 수 있음을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: VLM이 멀티모달 작업에서 성과를 내지만, 특정 상황에서 시각적 증거를 인식하지 못하거나 효과적으로 활용하지 못하는 이유를 연구합니다.

Method: 레이어별 주의 동역학을 분석하여 얕은 레이어는 텍스트에 주로 집중하고, 깊은 레이어는 지역화된 증거 영역에 드문드문 신뢰성 있게 주의를 기울인다는 것을 발견했습니다. 이를 기반으로 선택적 주의에 기반한 마스킹을 통해 깊은 레이어의 증거 영역을 강조하는 개입 방법을 도입했습니다.

Result: 이 개입 방법은 추가적인 훈련 없이 여러 모델 계열(LLaVA, Qwen, Gemma, InternVL)에서 정확성을 지속적으로 향상시킵니다.

Conclusion: VLM이 신뢰할 수 있는 증거를 내부적으로 인코딩하지만 이를 잘 활용하지 않음을 보여주며, 이러한 신호를 명시적으로 만들면 인식과 추론 간의 격차를 메울 수 있습니다.

Abstract: Vision-Language Models (VLMs) achieve strong results on multimodal tasks such
as visual question answering, yet they can still fail even when the correct
visual evidence is present. In this work, we systematically investigate whether
these failures arise from not perceiving the evidence or from not leveraging it
effectively. By examining layer-wise attention dynamics, we find that shallow
layers focus primarily on text, while deeper layers sparsely but reliably
attend to localized evidence regions. Surprisingly, VLMs often perceive the
visual evidence when outputting incorrect answers, a phenomenon we term
``seeing but not believing'' that widely exists in major VLM families. Building
on this, we introduce an inference-time intervention that highlights deep-layer
evidence regions through selective attention-based masking. It requires no
training and consistently improves accuracy across multiple families, including
LLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable
evidence internally but under-utilize it, making such signals explicit can
bridge the gap between perception and reasoning, advancing the diagnostic
understanding and reliability of VLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [56] [WaveNet's Precision in EEG Classification](https://arxiv.org/abs/2510.15947)
*Casper van Laar,Khubaib Ahmed*

Main category: cs.LG

TL;DR: 이 연구는 EEG 신호를 생리학적, 병리학적, 아티팩트 및 잡음 범주로 자동 분류하기 위한 WaveNet 기반 딥러닝 모델을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: EEG 신호 분류를 위한 전통적인 방법은 전문가의 시각적 검토에 의존하였으며, EEG 기록의 복잡성과 양이 증가함에 따라 점점 비현실적으로 변하고 있습니다.

Method: Mayo Clinic과 St. Anne's University Hospital의 공개된 주석 데이터셋을 활용하여 WaveNet 모델을 209,232개의 샘플에 대해 70/20/10 비율로 훈련하고 검증 및 테스트하였습니다.

Result: 모델은 이전의 CNN 및 LSTM 기반 접근법을 초과하는 분류 정확도를 달성하였으며, Temporal Convolutional Network(TCN) 기준선에 대해 벤치마킹되었습니다.

Conclusion: WaveNet 아키텍처는 원시 오디오 합성을 위해 원래 개발된 것으로, 확장된 인과 합성곱과 잔여 연결을 사용하여 EEG 데이터에 적합하며, 미세한 및 장거리 시간 종속성을 모두 캡처할 수 있습니다.

Abstract: This study introduces a WaveNet-based deep learning model designed to
automate the classification of EEG signals into physiological, pathological,
artifact, and noise categories. Traditional methods for EEG signal
classification, which rely on expert visual review, are becoming increasingly
impractical due to the growing complexity and volume of EEG recordings.
Leveraging a publicly available annotated dataset from Mayo Clinic and St.
Anne's University Hospital, the WaveNet model was trained, validated, and
tested on 209,232 samples with a 70/20/10 percent split. The model achieved a
classification accuracy exceeding previous CNN and LSTM-based approaches, and
was benchmarked against a Temporal Convolutional Network (TCN) baseline.
Notably, the model distinguishes noise and artifacts with high precision,
although it reveals a modest but explainable degree of misclassification
between physiological and pathological signals, reflecting inherent clinical
overlap. WaveNet's architecture, originally developed for raw audio synthesis,
is well suited for EEG data due to its use of dilated causal convolutions and
residual connections, enabling it to capture both fine-grained and long-range
temporal dependencies. The research also details the preprocessing pipeline,
including dynamic dataset partitioning and normalization steps that support
model generalization.

</details>


### [57] [Fire-EnSF: Wildfire Spread Data Assimilation using Ensemble Score Filter](https://arxiv.org/abs/2510.15954)
*Hongzheng Shi,Yuhang Wang,Xiao Liu*

Main category: cs.LG

TL;DR: 이 논문은 능동적인 산불 확산 예측을 위한 데이터 동화 문제에 Ensemble Score Filter (EnSF)를 적용하여 높은 정확도와 안정성을 제공하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 산불의 파괴력과 관리 비용이 증가함에 따라, 실제 산불 상황에서의 정확하고 실시간 예측이 필수적이다.

Method: Ensemble Score Filter (EnSF)라는 최근 제안된 확산 모델 기반 필터링 알고리즘을 사용하여, 고차원 비선형 필터링 문제를 다룬다.

Result: EnSF는 산불 확산 모델의 필터링 문제에 대해 높은 정확도와 안정성, 그리고 계산 효율성을 보인다.

Conclusion: EnSF는 산불 데이터 동화에 강력하고 실용적인 방법으로 확립되었다.

Abstract: As wildfires become increasingly destructive and expensive to control,
effective management of active wildfires requires accurate, real-time fire
spread predictions. To enhance the forecasting accuracy of active fires, data
assimilation plays a vital role by integrating observations (such as
remote-sensing data) and fire predictions generated from numerical models. This
paper provides a comprehensive investigation on the application of a recently
proposed diffusion-model-based filtering algorithm -- the Ensemble Score Filter
(EnSF) -- to the data assimilation problem for real-time active wildfire spread
predictions. Leveraging a score-based generative diffusion model, EnSF has been
shown to have superior accuracy for high-dimensional nonlinear filtering
problems, making it an ideal candidate for the filtering problems of wildfire
spread models. Technical details are provided, and our numerical investigations
demonstrate that EnSF provides superior accuracy, stability, and computational
efficiency, establishing it as a robust and practical method for wildfire data
assimilation. Our code has been made publicly available.

</details>


### [58] [LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems](https://arxiv.org/abs/2510.15969)
*Paul-Niklas Ken Kandora,Simon Caspar Zeller,Aaron Jeremias Elsing,Elena Kuss,Steffen Rebennack*

Main category: cs.LG

TL;DR: 비선형 최적화 문제를 해결하는 새로운 프레임워크인 LinearizeLLM을 도입한다.


<details>
  <summary>Details</summary>
Motivation: 비선형 최적화 문제의 재구성은 수동적이며 전문 지식이 필요하고, 이는 선형 최적화 솔버나 특별 목적의 알고리즘을 적용하기 위해 필수적이다.

Method: LinearizeLLM 프레임워크는 각 비선형 패턴을 정확한 선형 재구성을 유도하도록 지시된 재구성 에이전트에 할당하는 방식으로 작동한다.

Result: 20개의 실제 비선형 최적화 문제로 구성된 데이터셋을 생성하여 여러 LLM과 함께 접근 방식을 평가했다.

Conclusion: 전문 LLM 에이전트가 선형화 작업을 자동화할 수 있음을 나타내며, 비선형 최적화를 위한 완전한 대화형 모델링 파이프라인으로 나아가는 길을 열 수 있다.

Abstract: Reformulating nonlinear optimization problems is largely manual and
expertise-intensive, yet it remains essential for solving such problems with
linear optimization solvers or applying special-purpose algorithms. We
introduce \textit{LinearizeLLM}, an agent-based framework that solves this task
by leveraging Large Language Models (LLMs). The framework assigns each
nonlinear pattern to a \textit{reformulation agent} that is explicitly
instructed to derive an exact linear reformulation for its nonlinearity
pattern, for instance, absolute-value terms or bilinear products of decision
variables. The agents then coordinate to assemble a solver-ready linear model
equivalent to the original problem. To benchmark the approach, we create a
dataset of 20 real-world nonlinear optimization problems derived from the
established ComplexOR dataset of linear optimization problems. We evaluate our
approach with several LLMs. Our results indicate that specialized LLM agents
can automate linearization tasks, opening a path toward fully conversational
modeling pipelines for nonlinear optimization.

</details>


### [59] [Cog-Rethinker: Hierarchical Metacognitive Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2510.15979)
*Zexu Sun,Yongcheng Zeng,Erxue Min,Heyang Gao,Bokai Ji,Xu Chen*

Main category: cs.LG

TL;DR: Cog-Rethinker는 LLM을 위한 새로운 계층적 메타인지 RL 프레임워크로, 샘플 사용 효율성을 높여 수학적 추론 벤치마크에서 뛰어난 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 약한 LLM의 문제와 고정된 프롬프트 템플릿을 사용하는 기존 방법들이 비효율적이라는 문제를 해결하고자 한다.

Method: Cog-Rethinker라는 새로운 계층적 메타인지 RL 프레임워크를 제안하고, 두 단계의 절차에서 샘플 활용도를 개선한다.

Result: 여러 수학적 추론 벤치마크에서 Cog-Rethinker의 우수한 성능과 샘플 효율성을 분석하였다.

Conclusion: Cog-Rethinker는 기존 방법에 비해 수렴 가속화를 가능하게 한다.

Abstract: Contemporary progress in large language models (LLMs) has revealed notable
inferential capacities via reinforcement learning (RL) employing verifiable
reward, facilitating the development of O1 and R1-like reasoning models.
Directly training from base models with RL is called zero-RL. However, previous
works rely upon activating LLMs' inherent capacities through fixed prompt
templates. This strategy introduces substantial sampling inefficiencies for
weak LLMs, as the majority of problems generate invalid outputs during
accuracy-driven filtration in reasoning tasks, which causes a waste of samples.
To solve this issue, we propose Cog-Rethinker, a novel hierarchical
metacognitive RL framework for LLM reasoning. Our Cog-Rethinker mainly focuses
on the rollout procedure in RL training. After the direct rollout, our
Cog-Rethinker improves sample utilization in a hierarchical metacognitive
two-stage framework. By leveraging human cognition during solving problems,
firstly, it prompts policy to decompose zero-accuracy problems into subproblems
to produce final reasoning results. Secondly, with zero-accuracy problems in
previous rollout stage, it further prompts policy to refine these answers by
referencing previous wrong solutions. Moreover, to enable cold-start of the two
new reasoning patterns and maintain train-test consistency across prompt
templates, our Cog-Rethinker applies supervised fine-tuning on the policy using
correct samples of the two stages with direct rollout template. Experimental
results demonstrate Cog-Rethinker's superior performance on various
mathematical reasoning benchmarks, we also analyzed its improved sample
efficiency that accelerates convergence compared to baseline methods.

</details>


### [60] [AMiD: Knowledge Distillation for LLMs with $α$-mixture Assistant Distribution](https://arxiv.org/abs/2510.15982)
*Donghyeok Shin,Yeongmin Kim,Suhyeon Jo,Byeonghu Na,Il-Chul Moon*

Main category: cs.LG

TL;DR: 본 논문은 더 작은 LLM을 위한 지식 증류(KD) 기술인 $	ext{AMiD}$를 제안하여 과거의 프레임워크와 달리 더 나은 성능과 훈련 안정성을 제공하는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: LLM의 높은 계산 및 메모리 비용 문제를 해결하고 성능을 개선하기 위해.

Method: $	ext{AMiD}$는 새로운 분포 설계 변수 $	ext{α}$를 도입하여 대조 분포를 연속적으로 확장하는 $	ext{α}$-혼합 보조 분포를 제안하고, 최적성을 기반으로 보조 분포와 함께 사용하는 다양한 발산을 일반화한다.

Result: AMiD는 더 넓고 이론적으로 기반한 보조 분포 공간을 활용하여 우수한 성능과 훈련 안정성을 제공한다.

Conclusion: 이 연구는 보조 분포의 확장된 사용을 통해 KD의 향상된 성능을 실현한다.

Abstract: Autoregressive large language models (LLMs) have achieved remarkable
improvement across many tasks but incur high computational and memory costs.
Knowledge distillation (KD) mitigates this issue by transferring knowledge from
a large teacher to a smaller student through distributional alignment. Previous
studies have proposed various discrepancy metrics, but the capacity gap and
training instability caused by near-zero probabilities, stemming from the
high-dimensional output of LLMs, remain fundamental limitations. To overcome
these challenges, several approaches implicitly or explicitly incorporating
assistant distribution have recently been proposed. However, the past proposals
of assistant distributions have been a fragmented approach without a systematic
investigation of the interpolation path and the divergence. This paper proposes
$\alpha$-mixture assistant distribution, a novel generalized family of
assistant distributions, and $\alpha$-mixture distillation, coined AMiD, a
unified framework for KD using the assistant distribution. The $\alpha$-mixture
assistant distribution provides a continuous extension of the assistant
distribution by introducing a new distribution design variable $\alpha$, which
has been fixed in all previous approaches. Furthermore, AMiD generalizes the
family of divergences used with the assistant distributions based on
optimality, which has also been restricted in previous works. Through extensive
experiments, we demonstrate that AMiD offers superior performance and training
stability by leveraging a broader and theoretically grounded assistant
distribution space.

</details>


### [61] [Using Kolmogorov-Smirnov Distance for Measuring Distribution Shift in Machine Learning](https://arxiv.org/abs/2510.15996)
*Ozan K. Tonguz,Federico Taschin*

Main category: cs.LG

TL;DR: 본 논문에서는 AI 및 ML 시스템의 성능 저하를 모니터링하기 위해 Kolmogorov-Smirnov (KS) 테스트를 사용하는 방법을 제안하고 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 훈련 데이터와 테스트 데이터의 확률 분포 간 차이를 모니터링하여 AI 및 ML 시스템의 정확성과 신뢰성을 높이기 위해.

Method: Kolmogorov-Smirnov (KS) 테스트를 사용하여 분포 변화를 측정하고 KS 거리를 통해 이러한 변화를 수량화하는 방법을 제시한다.

Result: KS 거리는 분포 변화 모니터링에 유용한 통계적 도구로 사용될 수 있으며, KS=0.02의 경우 교차로에서 약 50%의 여행 시간 증가를 초래할 수 있다.

Conclusion: KS 테스트와 KS 거리를 이용한 AI 기반 스마트 교통 시스템 구현이 AI 에이전트의 실시간 성능 저하 측정에 중요한 발전이 될 수 있다.

Abstract: One of the major problems in Machine Learning (ML) and Artificial
Intelligence (AI) is the fact that the probability distribution of the test
data in the real world could deviate substantially from the probability
distribution of the training data set. When this happens, the predictions of an
ML system or an AI agent could involve large errors which is very troublesome
and undesirable. While this is a well-known hard problem plaguing the AI and ML
systems' accuracy and reliability, in certain applications such errors could be
critical for safety and reliability of AI and ML systems. One approach to deal
with this problem is to monitor and measure the deviation in the probability
distribution of the test data in real time and to compensate for this
deviation. In this paper, we propose and explore the use of Kolmogorov-Smirnov
(KS) Test for measuring the distribution shift and we show how the KS distance
can be used to quantify the distribution shift and its impact on an AI agent's
performance. Our results suggest that KS distance could be used as a valuable
statistical tool for monitoring and measuring the distribution shift. More
specifically, it is shown that even a distance of KS=0.02 could lead to about
50\% increase in the travel time at a single intersection using a Reinforcement
Learning agent which is quite significant. It is hoped that the use of KS Test
and KS distance in AI-based smart transportation could be an important step
forward for gauging the performance degradation of an AI agent in real time and
this, in turn, could help the AI agent to cope with the distribution shift in a
more informed manner.

</details>


### [62] [STAR: Boosting Time Series Foundation Models for Anomaly Detection through State-aware Adapter](https://arxiv.org/abs/2510.16014)
*Hanyin Cheng,Ruitong Zhang,Yuning Lu,Peng Chen,Meng Wang,Yang Shu,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: 본 논문에서는 TSFM이 시계열 상태 변수의 이질적인 범주적 성격을 간과하고, 이를 개선하기 위한 STAR 모듈을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제 산업 시나리오에서 시계열 데이터는 수치 변수뿐만 아니라 시스템 상태를 설명하는 많은 이산 상태 변수로 구성되어 있다. 기존 TSFM은 이러한 상태 변수의 중요성을 간과하고 있으며, 이로 인해 탐지 성능이 저하되고 있다.

Method: STAR는 상태 변수의 모델링과 활용을 개선하기 위해 설계된 플러그 앤 플레이 모듈로, 상태 인코더, 조건부 병목 어댑터, 숫자-상태 매칭 모듈을 포함하고 있다.

Result: 실제 데이터셋에서 수행된 실험 결과, STAR는 기존 TSFM의 MTSAD 성능을 개선할 수 있음을 보여준다.

Conclusion: STAR는 상태 변수를 효과적으로 모델링하여, 시계열 이상 탐지 성능을 향상시킬 수 있는 novel한 접근을 제공한다.

Abstract: While Time Series Foundation Models (TSFMs) have demonstrated remarkable
success in Multivariate Time Series Anomaly Detection (MTSAD), however, in
real-world industrial scenarios, many time series comprise not only numerical
variables such as temperature and flow, but also numerous discrete state
variables that describe the system status, such as valve on/off or day of the
week. Existing TSFMs often overlook the distinct categorical nature of state
variables and their critical role as conditions, typically treating them
uniformly with numerical variables. This inappropriate modeling approach
prevents the model from fully leveraging state information and even leads to a
significant degradation in detection performance after state variables are
integrated. To address this critical limitation, this paper proposes a novel
STate-aware AdapteR (STAR). STAR is a plug-and-play module designed to enhance
the capability of TSFMs in modeling and leveraging state variables during the
fine-tuning stage. Specifically, STAR comprisesthree core components: (1) We
design an Identity-guided State Encoder, whicheffectively captures the complex
categorical semantics of state variables through a learnable State Memory. (2)
We propose a Conditional Bottleneck Adapter, which dynamically generates
low-rank adaptation parameters conditioned on the current state, thereby
flexibly injecting the influence of state variables into the backbone model.
(3) We also introduce a Numeral-State Matching module to more effectively
detect anomalies inherent to the state variables themselves. Extensive
experiments conducted on real-world datasets demonstrate that STAR can improve
the performance of existing TSFMs on MTSAD.

</details>


### [63] [Airfoil optimization using Design-by-Morphing with minimized design-space dimensionality](https://arxiv.org/abs/2510.16020)
*Sangjoon Lee,Haris Moazam Sheikh*

Main category: cs.LG

TL;DR: AirDbM은 공기foil 최적화를 위한 디자인 방법으로, 디자인 공간의 차원수를 체계적으로 줄인다.


<details>
  <summary>Details</summary>
Motivation: 공기foil 형상의 효과적인 최적화는 가능한 한 적은 설계 변수를 사용하여 다양한 디자인을 탐색하는 것이 필요하다.

Method: AirDbM은 UIUC 공기foil 데이터베이스에서 최적의 12개 기본 공기foil 세트를 선택하고, 이 기본값을 통해 데이터베이스의 99%를 재구성한다.

Result: AirDbM는 평균 절대 오차 0.005 이하로 성능을 보여주며, 빠른 수렴성을 나타내고 기존 연구보다 더 큰 하이퍼볼륨을 가진 파레토 프론트를 달성한다.

Conclusion: AirDbM은 기계 학습 기반 디자인에서 DbM의 더 넓은 잠재력을 시사하며, RL 에이전트를 위한 공기foil 기하학 생성에 대한 뛰어난 적응성을 보여준다.

Abstract: Effective airfoil geometry optimization requires exploring a diverse range of
designs using as few design variables as possible. This study introduces
AirDbM, a Design-by-Morphing (DbM) approach specialized for airfoil
optimization that systematically reduces design-space dimensionality. AirDbM
selects an optimal set of 12 baseline airfoils from the UIUC airfoil database,
which contains over 1,600 shapes, by sequentially adding the baseline that most
increases the design capacity. With these baselines, AirDbM reconstructs 99 %
of the database with a mean absolute error below 0.005, which matches the
performance of a previous DbM approach that used more baselines. In
multi-objective aerodynamic optimization, AirDbM demonstrates rapid convergence
and achieves a Pareto front with a greater hypervolume than that of the
previous larger-baseline study, where new Pareto-optimal solutions are
discovered with enhanced lift-to-drag ratios at moderate stall tolerances.
Furthermore, AirDbM demonstrates outstanding adaptability for reinforcement
learning (RL) agents in generating airfoil geometry when compared to
conventional airfoil parameterization methods, implying the broader potential
of DbM in machine learning-driven design.

</details>


### [64] [RoBCtrl: Attacking GNN-Based Social Bot Detectors via Reinforced Manipulation of Bots Control Interaction](https://arxiv.org/abs/2510.16035)
*Yingguang Yang,Xianghua Zeng,Qi Wu,Hao Peng,Yutong Xia,Hao Liu,Bin Chong,Philip S. Yu*

Main category: cs.LG

TL;DR: 본 논문은 GNN 기반 소셜 봇 탐지기를 목표로 하는 적대적 다중 에이전트 강화 학습 프레임워크인 RoBCtrl를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 소셜 네트워크에서 실시간 정보의 주요 출처로서의 역할과 소셜 봇의 영향력이 증가하고 있으며, 소셜 봇 탐지 방법의 취약성과 강건성 또한 탐구될 필요가 있다.

Method: 기존 계정 데이터를 약간 수정하여 고충실도의 봇 계정을 생성하는 확산 모델을 사용하고, 다중 에이전트 강화 학습 기법을 통해 봇의 적대적 행동을 시뮬레이션한다.

Result: 제안된 프레임워크는 GNN 기반 탐지기의 성능을 효과적으로 저하시킬 수 있음을 입증하였다.

Conclusion: 이 연구는 소셜 봇 탐지와 관련하여 확산 모델의 최초의 효과적인 응용이자, GNN 기반 탐지기를 목표로 하는 새로운 접근을 제시한다.

Abstract: Social networks have become a crucial source of real-time information for
individuals. The influence of social bots within these platforms has garnered
considerable attention from researchers, leading to the development of numerous
detection technologies. However, the vulnerability and robustness of these
detection methods is still underexplored. Existing Graph Neural Network
(GNN)-based methods cannot be directly applied due to the issues of limited
control over social agents, the black-box nature of bot detectors, and the
heterogeneity of bots. To address these challenges, this paper proposes the
first adversarial multi-agent Reinforcement learning framework for social Bot
control attacks (RoBCtrl) targeting GNN-based social bot detectors.
Specifically, we use a diffusion model to generate high-fidelity bot accounts
by reconstructing existing account data with minor modifications, thereby
evading detection on social platforms. To the best of our knowledge, this is
the first application of diffusion models to mimic the behavior of evolving
social bots effectively. We then employ a Multi-Agent Reinforcement Learning
(MARL) method to simulate bots adversarial behavior. We categorize social
accounts based on their influence and budget. Different agents are then
employed to control bot accounts across various categories, optimizing the
attachment strategy through reinforcement learning. Additionally, a
hierarchical state abstraction based on structural entropy is designed to
accelerate the reinforcement learning. Extensive experiments on social bot
detection datasets demonstrate that our framework can effectively undermine the
performance of GNN-based detectors.

</details>


### [65] [GUIrilla: A Scalable Framework for Automated Desktop UI Exploration](https://arxiv.org/abs/2510.16051)
*Sofiya Garkot,Maksym Shamrai,Ivan Synytsia,Mariya Hirna*

Main category: cs.LG

TL;DR: GUIrilla는 GUI 자동화를 위한 데이터 수집 문제를 해결하기 위해 자동화된 스케일 가능 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 그래픽 사용자 인터페이스(GUI)를 운영할 수 있는 자율 에이전트는 데스크탑 자동화를 혁신할 잠재력을 가지고 있다.

Method: GUIrilla는 네이티브 접근성 API를 통해 애플리케이션을 체계적으로 탐색하는 자동화된 프레임워크이다.

Result: GUIrilla를 기반으로 한 에이전트는 GUIrilla-Task에서 LLM을 조정하여 UI 작업에서 성능을 크게 향상시키며, ScreenSpot Pro 벤치마크에서 합성 기준선을 초과하는 성과를 거둔다.

Conclusion: 우리는 구조화된 접근성 메타데이터의 재현 가능한 수집을 위한 오픈 소스 라이브러리인 macapptree와 함께 GUIrilla-Task 데이터셋, 수동으로 검증된 GUIrilla-Gold 벤치마크, 데스크탑 자율성 연구를 지원하는 프레임워크 코드를 배포한다.

Abstract: Autonomous agents capable of operating complex graphical user interfaces
(GUIs) have the potential to transform desktop automation. While recent
advances in large language models (LLMs) have significantly improved UI
understanding, navigating full-window, multi-application desktop environments
remains a major challenge. Data availability is limited by costly manual
annotation, closed-source datasets and surface-level synthetic pipelines. We
introduce GUIrilla, an automated scalable framework that systematically
explores applications via native accessibility APIs to address the critical
data collection challenge in GUI automation. Our framework focuses on macOS -
an ecosystem with limited representation in current UI datasets - though many
of its components are designed for broader cross-platform applicability.
GUIrilla organizes discovered interface elements and crawler actions into
hierarchical GUI graphs and employs specialized interaction handlers to achieve
comprehensive application coverage. Using the application graphs from GUIrilla
crawler, we construct and release GUIrilla-Task, a large-scale dataset of
27,171 functionally grounded tasks across 1,108 macOS applications, each
annotated with full-desktop and window-level screenshots, accessibility
metadata, and semantic action traces. Empirical results show that tuning
LLM-based agents on GUIrilla-Task significantly improves performance on
downstream UI tasks, outperforming synthetic baselines on the ScreenSpot Pro
benchmark while using 97% less data. We also release macapptree, an open-source
library for reproducible collection of structured accessibility metadata, along
with the full GUIrilla-Task dataset, the manually verified GUIrilla-Gold
benchmark, and the framework code to support open research in desktop autonomy.

</details>


### [66] [Learning a Generalized Model for Substation Level Voltage Estimation in Distribution Networks](https://arxiv.org/abs/2510.16063)
*Muhy Eddin Za'ter,Bri-Mathias Hodge*

Main category: cs.LG

TL;DR: 전력 분배 네트워크의 정확한 전압 추정은 실시간 모니터링과 그리드 신뢰성 향상에 필수적이다. 이 논문은 저전압 관측 수준에도 강건한 서브스테이션 수준 전압 추정을 위한 계층적 그래프 신경망을 제안한다.


<details>
  <summary>Details</summary>
Motivation: DER 침투와 분배 수준 전압 변동성이 증가함에 따라, 안전하고 효율적인 운영을 유지하기 위해 강건한 분배 시스템 상태 추정(DSSE)이 점점 더 중요해졌다.

Method: 이 논문은 전기적 토폴로지와 물리적 특징을 활용하는 계층적 그래프 신경망을 제안하여 서브스테이션 수준의 전압을 추정한다.

Result: 제안된 방법은 대안적 데이터 기반 모델보다 최대 2배 낮은 RMSE를 달성하고, 1%의 측정 커버리지만으로도 높은 정확성을 유지함을 보여준다.

Conclusion: 결과는 GNN이 분배 시스템을 위한 확장 가능하고 재현 가능하며 데이터 기반의 전압 모니터링을 가능하게 하는 잠재력을 강조한다.

Abstract: Accurate voltage estimation in distribution networks is critical for
real-time monitoring and increasing the reliability of the grid. As DER
penetration and distribution level voltage variability increase, robust
distribution system state estimation (DSSE) has become more essential to
maintain safe and efficient operations. Traditional DSSE techniques, however,
struggle with sparse measurements and the scale of modern feeders, limiting
their scalability to large networks. This paper presents a hierarchical graph
neural network for substation-level voltage estimation that exploits both
electrical topology and physical features, while remaining robust to the low
observability levels common to real-world distribution networks. Leveraging the
public SMART-DS datasets, the model is trained and evaluated on thousands of
buses across multiple substations and DER penetration scenarios. Comprehensive
experiments demonstrate that the proposed method achieves up to 2 times lower
RMSE than alternative data-driven models, and maintains high accuracy with as
little as 1\% measurement coverage. The results highlight the potential of GNNs
to enable scalable, reproducible, and data-driven voltage monitoring for
distribution systems.

</details>


### [67] [Early-stopping for Transformer model training](https://arxiv.org/abs/2510.16074)
*Jing He,Hua Jiang,Cheng Li,Siqian Xin,Shuzhen Yang*

Main category: cs.LG

TL;DR: 본 연구는 Transformer 훈련 동역학을 분석하기 위한 랜덤 행렬 이론에 기초한 새로운 이론적 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: Transformer 모델의 성능 향상을 이끄는 기저 메커니즘을 이해하고 조기 중지 기준을 유도하는 데 목적이 있다.

Method: 얕은 자기 주의 행렬 V의 스펙트럼 밀도가 두꺼운 꼬리 분포로 지속적으로 진화하는 것을 관찰하고, 이를 통해 훈련을 세 단계로 나눈다: 구조 탐색, 두꺼운 꼬리 구조 안정화, 수렴 포화.

Result: 훈련의 세 단계를 통해 초기 중지 결정을 내릴 수 있는 가이드를 제공하고, 두 가지 일관된 기준을 제안한다.

Conclusion: 이 기준들이 강한 정렬을 이룬다는 것은 Transformer 모델 훈련의 진행 상황을 모니터링하고 진단하는 데 RMT의 유용성을 강조한다.

Abstract: This work introduces a novel theoretical framework grounded in Random Matrix
Theory (RMT) for analyzing Transformer training dynamics. We focus on the
underlying mechanisms that drive performance improvements and derive principled
early-stopping criteria. Empirically, we observe that the spectral density of
the shallow self-attention matrix V consistently evolves into a heavy-tailed
distribution. Utilizing the PL (Power Law) fit to this matrix as a probe, we
demarcate training into three stages: structural exploration, heavy-tailed
structure stabilization, and convergence saturation. This staging provides
guidance for preliminary stopping decisions. Crucially, we propose two
consistent and validation-free criteria: a quantitative metric for heavy-tailed
dynamics and a novel spectral signature indicative of convergence. The strong
alignment between these criteria highlights the utility of RMT for monitoring
and diagnosing the progression of Transformer model training.

</details>


### [68] [Narrowing Action Choices with AI Improves Human Sequential Decisions](https://arxiv.org/abs/2510.16097)
*Eleni Straitouri,Stratis Tsirtsis,Ander Artola Velasco,Manuel Gomez-Rodriguez*

Main category: cs.LG

TL;DR: 이 연구는 sequential decision making 작업에서 인간의 주체성을 조절하여 상호 보완성을 달성하는 의사 결정 지원 시스템을 개발하였으며, 이를 통해 참가자들이 30% 더 나은 성과를 보인다는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 인간 전문가가 정확한 예측을 위해 분류기에게 주체성을 양도해야 할 때를 이해하지 못할 때가 많기 때문에, 이를 해결하기 위한 의사 결정 지원 시스템의 필요성이 있다.

Method: 사전 훈련된 AI 에이전트를 사용하여 인간이 선택할 수 있는 행동 세트를 좁히고, 그 세트에서 행동을 선택하도록 인간에게 요청하는 의사 결정 지원 시스템을 개발하였다. 또한, 행동 세트의 원활한 속성을 활용하는 배짓 알고리즘을 도입하였다.

Result: 이 시스템을 통해 참가자들이 스스로 행동할 때보다 약 30% 더 나은 성과를 보였으며, AI 에이전트보다도 2% 더 나은 결과를 보였다.

Conclusion: 이 연구는 인간의 주체성을 적절히 조절하여 의사 결정 지원 시스템의 효과를 극대화할 수 있음을 보여준다.

Abstract: Recent work has shown that, in classification tasks, it is possible to design
decision support systems that do not require human experts to understand when
to cede agency to a classifier or when to exercise their own agency to achieve
complementarity$\unicode{x2014}$experts using these systems make more accurate
predictions than those made by the experts or the classifier alone. The key
principle underpinning these systems reduces to adaptively controlling the
level of human agency, by design. Can we use the same principle to achieve
complementarity in sequential decision making tasks? In this paper, we answer
this question affirmatively. We develop a decision support system that uses a
pre-trained AI agent to narrow down the set of actions a human can take to a
subset, and then asks the human to take an action from this action set. Along
the way, we also introduce a bandit algorithm that leverages the smoothness
properties of the action sets provided by our system to efficiently optimize
the level of human agency. To evaluate our decision support system, we conduct
a large-scale human subject study ($n = 1{,}600$) where participants play a
wildfire mitigation game. We find that participants who play the game supported
by our system outperform those who play on their own by $\sim$$30$% and the AI
agent used by our system by $>$$2$%, even though the AI agent largely
outperforms participants playing without support. We have made available the
data gathered in our human subject study as well as an open source
implementation of our system at
https://github.com/Networks-Learning/narrowing-action-choices .

</details>


### [69] [Expert Merging in Sparse Mixture of Experts with Nash Bargaining](https://arxiv.org/abs/2510.16138)
*Dung V. Nguyen,Anh T. Nguyen,Minh H. Nguyen,Luc Q. Nguyen,Shiqi Jiang,Ethan Fetaya,Linh Duy Tran,Gal Chechik,Tan M. Nguyen*

Main category: cs.LG

TL;DR: Nash Merging of Experts (NAMEx)는 게임 이론을 통해 전문가 간 협력 및 경쟁 역학을 탐구하며, 전문가 병합 과정에 Nash 협상 개념을 도입하여 더 균형 잡히고 효율적인 협력을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 전문가 병합 전략이 일관된 가중 메커니즘이 부족하다는 점을 해결하고자 한다.

Method: 게임 이론의 관점에서 전문가 병합을 재해석하고, 전문가 병합 과정에 Nash 협상 요소를 추가하여 복잡한 모멘텀을 적용하였다.

Result: 언어 모델링, 텍스트 분류, 이미지 분류, 데이터 손상에 대한 제로샷 강건성에서 NAMEx가 경쟁 방법들을 일관되게 초월함을 보여준다.

Conclusion: NAMEx는 Qwen1.5-MoE(14B) 및 DeepSeek-MoE(16B)와 같은 대규모 시스템에 적용되었을 때 제로샷 및 미세 조정 환경에서 효과적인 확장성을 입증한다.

Abstract: Existing expert merging strategies for Sparse Mixture of Experts (SMoE)
typically rely on input-dependent or input-independent averaging of expert
parameters, but often lack a principled weighting mechanism. In this work, we
reinterpret expert merging through the lens of game theory, revealing
cooperative and competitive dynamics among experts. Based on this perspective,
we introduce Nash Merging of Experts (NAMEx), a novel framework that
incorporates Nash Bargaining into the merging process, enabling more balanced
and efficient collaboration among experts. Additionally, we incorporate complex
momentum into NAMEx to accelerate expert propagation with theoretical
guarantees for convergence. Extensive experiments across language modelling,
text classification, image classification, and zero-shot robustness under data
corruption show that NAMEx consistently outperforms competing methods while
integrating seamlessly with popular MoE architectures. Finally, we demonstrate
NAMEx's scalability by applying it to large-scale systems, including
Qwen1.5-MoE (14B) and DeepSeek-MoE (16B), where it proves effective in both
zero-shot and fine-tuning settings.

</details>


### [70] [Breaking and Fixing Defenses Against Control-Flow Hijacking in Multi-Agent Systems](https://arxiv.org/abs/2510.17276)
*Rishi Jha,Harold Triedman,Justin Wagle,Vitaly Shmatikov*

Main category: cs.LG

TL;DR: 본 논문에서는 다중 에이전트 시스템에서의 제어 흐름 탈취 공격과 이를 방어하기 위한 새로운 솔루션인 ControlValve를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현재 제안된 방어책들이 높은 속도로 발전하는 제어 흐름 탈취 공격에 대해 안전하지 않음을 입증하기 위해 연구합니다.

Method: ControlValve는 허용된 제어 흐름 그래프를 생성하고, 모든 실행이 이러한 그래프에 따라 수행되도록 보장합니다.

Result: ControlValve는 다중 에이전트 시스템의 제어 흐름에 대한 무결성을 강화하고 모든 에이전트 호출에 대한 맥락적 규칙을 적용하여 안전성을 높입니다.

Conclusion: ControlValve는 기존 방어 기법들의 한계를 극복하고, 제어 흐름 안전성을 크게 향상시킬 수 있습니다.

Abstract: Control-flow hijacking attacks manipulate orchestration mechanisms in
multi-agent systems into performing unsafe actions that compromise the system
and exfiltrate sensitive information. Recently proposed defenses, such as
LlamaFirewall, rely on alignment checks of inter-agent communications to ensure
that all agent invocations are "related to" and "likely to further" the
original objective.
  We start by demonstrating control-flow hijacking attacks that evade these
defenses even if alignment checks are performed by advanced LLMs. We argue that
the safety and functionality objectives of multi-agent systems fundamentally
conflict with each other. This conflict is exacerbated by the brittle
definitions of "alignment" and the checkers' incomplete visibility into the
execution context.
  We then propose, implement, and evaluate ControlValve, a new defense inspired
by the principles of control-flow integrity and least privilege. ControlValve
(1) generates permitted control-flow graphs for multi-agent systems, and (2)
enforces that all executions comply with these graphs, along with contextual
rules (generated in a zero-shot manner) for each agent invocation.

</details>


### [71] [Zeroth-Order Sharpness-Aware Learning with Exponential Tilting](https://arxiv.org/abs/2510.16157)
*Xuchen Gong,Tian Li*

Main category: cs.LG

TL;DR: 본 논문은 제로 순서 최적화 방법을 샤프니스 인식 최소화(SAM) 접근 방식과 연결하여 더 나은 일반화를 위한 새로운 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 제로 순서 최적화 접근법이 손실 값의 평균을 최소화하는 데 중점을 두는 반면, 샤프니스 인식 최소화는 이웃 내에서 최대 손실을 최소화하여 편평한 최소값을 도출하는 데 집중합니다.

Method: 본 연구에서는 부드러운 SAM 목표를 해결하기 위한 새로운 제로 순서 알고리즘을 탐구하며, 샤프니스 개념을 명확히 특성화합니다.

Result: 우리의 접근법은 SAM 변형을 대체할 수 있는 메모리 효율적인 방법으로, 분류, 복수 선택 QA 및 언어 생성 등 다양한 하류 작업에서 기존 제로 순서 기준보다 더 나은 일반화를 달성합니다.

Conclusion: 결론적으로, 새로운 알골리즘은 기존의 샤프니스 최소화 기법들을 대체 가능하며, 다양한 작업에서 성능을 향상시킬 수 있습니다.

Abstract: Classic zeroth-order optimization approaches typically optimize for a
smoothed version of the original function, i.e., the expected objective under
randomly perturbed model parameters. This can be interpreted as encouraging the
loss values in the perturbation set to be small on average. Popular
sharpness-aware minimization (SAM) objectives, however, typically focus on the
largest loss within the neighborhood to arrive at flat minima more effectively.
In this work, we connect zeroth-order optimization (and its corresponding
objectives) with SAM approaches explicitly, through an exponential tilting
objective that provides a smooth transition between the average- and the
max-loss formulations. We explore new zeroth-order algorithms to solve a soft
SAM objective parameterized by a tilting parameter $t$. We provide precise
characterizations of the sharpness notions of the tilted SAM framework.
Practically, our approach can be used as a gradient-free and memory-efficient
alternative to SAM variants, and it achieves better generalization compared to
vanilla zeroth-order baselines on a wide range of downstream tasks, including
classification, multiple choice QA, and language generation.

</details>


### [72] [The Formalism-Implementation Gap in Reinforcement Learning Research](https://arxiv.org/abs/2510.16175)
*Pablo Samuel Castro*

Main category: cs.LG

TL;DR: 강화 학습 연구는 성능 시연에만 초점을 맞추지 말고 강화 학습의 과학과 이해를 발전시키는 데 더 집중해야 하며, 벤치마크와 수학적 형식 간의 관계를 보다 명확히 해야 한다.


<details>
  <summary>Details</summary>
Motivation: 최근 10년간 강화 학습 기술이 슈퍼 인간 수준의 작업 수행 능력을 입증하며 높은 관심을 받고 있다.

Method: 이 논문은 기존 연구가 성능 중심으로 치우쳐져 있어 벤치마크에 대한 과적합 위험이 있음을 지적하며, Arcade Learning Environment (ALE)를 예로 들어 이러한 이해를 발전시키는 방법을 제시한다.

Result: 강화 학습의 성능과 학습 동역학에 대한 이해를 제고하며, 벤치마크가 수학적 형식과 어떻게 상응하는지를 구체화할 필요성을 강조한다.

Conclusion: 강화 학습 연구는 성능 시연에만 국한되지 않고 과학적 이해를 발전시키는데 힘쓰며, 벤치마크의 정의를 명확히 해야 한다.

Abstract: The last decade has seen an upswing in interest and adoption of reinforcement
learning (RL) techniques, in large part due to its demonstrated capabilities at
performing certain tasks at "super-human levels". This has incentivized the
community to prioritize research that demonstrates RL agent performance, often
at the expense of research aimed at understanding their learning dynamics.
Performance-focused research runs the risk of overfitting on academic
benchmarks -- thereby rendering them less useful -- which can make it difficult
to transfer proposed techniques to novel problems. Further, it implicitly
diminishes work that does not push the performance-frontier, but aims at
improving our understanding of these techniques. This paper argues two points:
(i) RL research should stop focusing solely on demonstrating agent
capabilities, and focus more on advancing the science and understanding of
reinforcement learning; and (ii) we need to be more precise on how our
benchmarks map to the underlying mathematical formalisms. We use the popular
Arcade Learning Environment (ALE; Bellemare et al., 2013) as an example of a
benchmark that, despite being increasingly considered "saturated", can be
effectively used for developing this understanding, and facilitating the
deployment of RL techniques in impactful real-world problems.

</details>


### [73] [Expressive Reward Synthesis with the Runtime Monitoring Language](https://arxiv.org/abs/2510.16185)
*Daniel Donnelly,Angelo Ferrando,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 보상(오류) 명세는 강화 학습에서 중요한 도전 과제이며, 이 논문에서는 비정형 보상 함수를 생성할 수 있는 새로운 보상 기계의 개발을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습에서의 보상 함수는 종종 블랙박스 맵으로 취급되며, 이는 학습과 해석 가능성을 저해할 수 있다.

Method: 런타임 모니터링 언어(RML)를 기반으로 한 언어 기반 보상 기계를 개발하여 비정형 비마르코프 보상 함수를 명세할 수 있도록 한다.

Result: 우리는 실험을 통해 우리의 접근 방식의 표현력을 입증하고, 기존의 보상 기계 기반 방법에 비해 유연한 이벤트 처리 및 작업 명세에서 추가적인 이점을 강조한다.

Conclusion: 이 연구는 비정형 보상 함수를 처리하는데 있어 새로운 가능성을 열어준다.

Abstract: A key challenge in reinforcement learning (RL) is reward (mis)specification,
whereby imprecisely defined reward functions can result in unintended, possibly
harmful, behaviours. Indeed, reward functions in RL are typically treated as
black-box mappings from state-action pairs to scalar values. While effective in
many settings, this approach provides no information about why rewards are
given, which can hinder learning and interpretability. Reward Machines address
this issue by representing reward functions as finite state automata, enabling
the specification of structured, non-Markovian reward functions. However, their
expressivity is typically bounded by regular languages, leaving them unable to
capture more complex behaviours such as counting or parametrised conditions. In
this work, we build on the Runtime Monitoring Language (RML) to develop a novel
class of language-based Reward Machines. By leveraging the built-in memory of
RML, our approach can specify reward functions for non-regular, non-Markovian
tasks. We demonstrate the expressiveness of our approach through experiments,
highlighting additional advantages in flexible event-handling and task
specification over existing Reward Machine-based methods.

</details>


### [74] [WEBSERV: A Browser-Server Environment for Efficient Training of Reinforcement Learning-based Web Agents at Scale](https://arxiv.org/abs/2510.16252)
*Yuxuan Lu,Jing Huang,Hui Liu,Jiri Gesi,Yan Han,Shihan Fu,Tianqi Zheng,Dakuo Wang*

Main category: cs.LG

TL;DR: 본 논문에서는 스케일 가능하고 효율적인 강화 학습 환경인 WEBSERV를 제안하며, 이는 브라우저 상호작용과 서버 측 상태를 결합하여 단일 호스트에서 200개 이상의 동시 컨테이너를 지원할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 웹 에이전트의 훈련 및 평가에 대한 관심이 증가하고 있지만, 현실적이고 강력한 브라우저 간 상호작용과 서버 측 상태를 결합하여 대규모로 조절할 수 있는 환경이 부족하다.

Method: WEBSERV는 1) 맥락과 행동 복잡성을 균형 있게 조절한 간결하고 사이트 독립적인 브라우저 환경과 2) 효율적으로 웹 서버를 실행하고 초기화하여 스케일 가능한 RL 훈련과 평가를 가능하게 하는 스케일러블 RL 환경을 포함한다.

Result: WEBSERV는 WebArena의 쇼핑 CMS와 Gitlab 작업에서 평가되었으며, 단일 프롬프트 성공률에서 최신 기술을 달성하였고, 출시 대기 시간을 약 5배 줄이며, 저장 요구량을 약 240배 줄이면서 비슷한 메모리 풋프린트를 유지하여 단일 호스트에서 200개 이상의 동시 컨테이너를 가능하게 하였다.

Conclusion: 제안된 WEBSERV 환경은 더 나은 성능과 효율성을 제공하여 강화 학습 연구에 기여할 것으로 기대된다.

Abstract: Training and evaluation of Reinforcement Learning (RL) web agents have gained
increasing attention, yet a scalable and efficient environment that couples
realistic and robust browser-side interaction with controllable server-side
state at scale is still missing. Existing environments tend to have one or more
of the following issues: they overwhelm policy models with excessive and noisy
context; they perform actions non-deterministically without waiting for the UI
or network to stabilize; or they cannot scale isolated client-server containers
effectively for parallel RL rollouts. We propose WEBSERV, an environment that
includes 1) a compact, site-agnostic browser environment that balances context
and action complexity, and 2) a scalable RL environment via efficient launching
and resetting web-servers to enable scalable RL training and evaluation. We
evaluate WEBSERV on the shopping CMS and Gitlab tasks in WebArena, achieving
state-of-the-art single-prompt success rates while cutting launch latency by
~5x and storage need by ~240x, with a comparable memory footprint, enabling
200+ concurrent containers on a single host.

</details>


### [75] [QSVD: Efficient Low-rank Approximation for Unified Query-Key-Value Weight Compression in Low-Precision Vision-Language Models](https://arxiv.org/abs/2510.16292)
*Yutong Wang,Haiyu Wang,Sai Qian Zhang*

Main category: cs.LG

TL;DR: 본 논문에서는 VLM의 메모리 사용량과 계산 비용을 줄이기 위한 SVD 활용 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: VLM은 이미지 캡셔닝 및 시각적 질문 응답과 같은 작업에 중요하지만 높은 계산 비용으로 인해 확장성과 실시간 적용성이 제한됩니다.

Method: 결합 쿼리, 키 및 값 가중치 행렬에 SVD를 적용하고, VLM 정확도에 따라 SVD 계급을 동적으로 조정하는 효율적인 계급 배분 전략을 도입합니다. 또한 VLM의 가중치와 활성화에 양자화를 적용하여 효율성을 높입니다.

Result: 우리의 방법은 기존의 양자화 또는 SVD에만 의존하는 접근 방식보다 10% 이상의 정확도 향상을 이루었으며, 하드웨어 비용을 절감했습니다.

Conclusion: 이로 인해 제한된 자원을 가진 장치에서 실시간 배포에 더 적합합니다. 코드는 오픈 소스로 제공됩니다.

Abstract: Vision-Language Models (VLMs) are integral to tasks such as image captioning
and visual question answering, but their high computational cost, driven by
large memory footprints and processing time, limits their scalability and
real-time applicability. In this work, we propose leveraging Singular-Value
Decomposition (SVD) over the joint query (Q), key (K), and value (V) weight
matrices to reduce KV cache size and computational overhead. We in addition
introduce an efficient rank allocation strategy that dynamically adjusts the
SVD rank based on its impact on VLM accuracy, achieving a significant reduction
in both memory usage and computational cost. Finally, we extend this approach
by applying quantization to both VLM weights and activations, resulting in a
highly efficient VLM. Our method outperforms previous approaches that rely
solely on quantization or SVD by achieving more than $10\%$ accuracy
improvement while consuming less hardware cost, making it better for real-time
deployment on resource-constrained devices. We open source our code at
\href{https://github.com/SAI-Lab-NYU/QSVD}{\texttt{https://github.com/SAI-Lab-NYU/QSVD}}.

</details>


### [76] [Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening](https://arxiv.org/abs/2510.16306)
*Xin Wang,Yu Wang,Yunchao Liu,Jens Meiler,Tyler Derr*

Main category: cs.LG

TL;DR: ScaffAug는 약물 발견에서 리간드 기반 가상 스크리닝의 성능을 향상시키기 위한 새로운 프레임워크로, 세 가지 모듈을 통해 클래스 불균형과 구조 불균형 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 가상 스크리닝은 약물 발견에서 필수적인 단계이며, 그러나 클래스 불균형, 구조 불균형, 새로운 약물 개발을 위한 다양한 활성 화합물 식별 필요성과 같은 세 가지 주요 문제에 직면해 있다.

Method: ScaffAug는 세 가지 모듈을 통해 작동한다: augmentation 모듈, self-training 모듈, reranking 모듈. augmentation 모듈은 실제 히트 화합물의 스캐폴드에 기반하여 생성적 AI를 사용하여 합성 데이터를 생성하고, self-training 모듈은 생성된 데이터를 원래 레이블이 있는 데이터와 안전하게 통합하며, reranking 모듈은 상위 추천 화합물 집합에서 스캐폴드 다양성을 향상시킨다.

Result: 다섯 개의 표적 클래스에서 전면적인 계산 실험을 수행하였으며, ScaffAug를 기존의 기준 방법들과 비교하여 여러 평가 지표의 성능과 ScaffAug의 절제 연구 결과를 보고하였다.

Conclusion: 이 연구는 생성적 증대, 재정렬 및 일반적인 스캐폴드 인식을 활용하여 가상 스크리닝을 효과적으로 향상시키는 새로운 관점을 제시한다.

Abstract: Ligand-based virtual screening (VS) is an essential step in drug discovery
that evaluates large chemical libraries to identify compounds that potentially
bind to a therapeutic target. However, VS faces three major challenges: class
imbalance due to the low active rate, structural imbalance among active
molecules where certain scaffolds dominate, and the need to identify
structurally diverse active compounds for novel drug development. We introduce
ScaffAug, a scaffold-aware VS framework that addresses these challenges through
three modules. The augmentation module first generates synthetic data
conditioned on scaffolds of actual hits using generative AI, specifically a
graph diffusion model. This helps mitigate the class imbalance and furthermore
the structural imbalance, due to our proposed scaffold-aware sampling
algorithm, designed to produce more samples for active molecules with
underrepresented scaffolds. A model-agnostic self-training module is then used
to safely integrate the generated synthetic data from our augmentation module
with the original labeled data. Lastly, we introduce a reranking module that
improves VS by enhancing scaffold diversity in the top recommended set of
molecules, while still maintaining and even enhancing the overall general
performance of identifying novel, active compounds. We conduct comprehensive
computational experiments across five target classes, comparing ScaffAug
against existing baseline methods by reporting the performance of multiple
evaluation metrics and performing ablation studies on ScaffAug. Overall, this
work introduces novel perspectives on effectively enhancing VS by leveraging
generative augmentations, reranking, and general scaffold-awareness.

</details>


### [77] [Toward General Digraph Contrastive Learning: A Dual Spatial Perspective](https://arxiv.org/abs/2510.16311)
*Daohan Su,Yang Zhang,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: S2-DiGCL은 방향성 그래프에 대한 대비 학습을 위한 새로운 프레임워크로, 복잡하고 실제 도메인 관점에서 공간 통찰을 강조한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 그래프 대조 학습은 주로 비방향 그래프에 초점을 맞추고 있으며, 실제 네트워크에서 중요한 방향 정보를 간과하고 있다.

Method: S2-DiGCL은 복잡한 도메인과 실제 도메인 관점에서 개인화된 왜곡을 자기 라플라시안에 도입하고, 경로 기반의 서브 그래프 증강 전략을 사용하여 지역 비대칭성과 위상 종속성을 캡처한다.

Result: S2-DiGCL은 고품질의 긍정적 및 부정적 샘플을 구축하여 더 일반적이고 견고한 방향성 그래프 대비 학습을 가능케 하며, 7개의 실제 방향성 그래프 데이터셋에 대한 광범위한 실험을 통해 SOTA 성능을 달성했다.

Conclusion: 본 기법은 노드 분류에서 4.41% 및 링크 예측에서 4.34%의 성능 향상을 보였다.

Abstract: Graph Contrastive Learning (GCL) has emerged as a powerful tool for
extracting consistent representations from graphs, independent of labeled
information. However, existing methods predominantly focus on undirected
graphs, disregarding the pivotal directional information that is fundamental
and indispensable in real-world networks (e.g., social networks and
recommendations).In this paper, we introduce S2-DiGCL, a novel framework that
emphasizes spatial insights from complex and real domain perspectives for
directed graph (digraph) contrastive learning. From the complex-domain
perspective, S2-DiGCL introduces personalized perturbations into the magnetic
Laplacian to adaptively modulate edge phases and directional semantics. From
the real-domain perspective, it employs a path-based subgraph augmentation
strategy to capture fine-grained local asymmetries and topological
dependencies. By jointly leveraging these two complementary spatial views,
S2-DiGCL constructs high-quality positive and negative samples, leading to more
general and robust digraph contrastive learning. Extensive experiments on 7
real-world digraph datasets demonstrate the superiority of our approach,
achieving SOTA performance with 4.41% improvement in node classification and
4.34% in link prediction under both supervised and unsupervised settings.

</details>


### [78] [LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs](https://arxiv.org/abs/2510.16552)
*Ang Li,Yifei Wang,Zhihang Yuan,Stefanie Jegelka,Yisen Wang*

Main category: cs.LG

TL;DR: LANPO라는 새로운 프레임워크는 언어 피드백과 수치 보상의 역할을 분리하여 LLM의 강화 학습을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델에서 스칼라 보상에 의존하는 기존 방식은 텍스트 근거를 무시하여 샘플 효율성을 저하시킨다.

Method: LANPO는 이전 시도의 동적 경험 풀을 구축하고 안전한 자기 수정과 일반화 가능한 교훈을 위한 두 가지 원칙을 도입한다.

Result: LANPO는 7B 및 14B 모델이 GRPO로 훈련된 강력한 기준선보다 테스트 정확도에서 의미 있게 뛰어난 성과를 거둔다.

Conclusion: 이 연구는 LLM의 강화 학습 루프에 역사적 경험을 통합하는 강력한 방법을 제공하여 더 효과적이고 데이터 효율적인 학습 에이전트를 생성한다.

Abstract: Reinforcement learning in large language models (LLMs) often relies on scalar
rewards, a practice that discards valuable textual rationale buried in the
rollouts, forcing the model to explore \textit{de novo} with each attempt and
hindering sample efficiency. While LLMs can uniquely learn from language
feedback provided in-context, naively integrating on-line experiences into RL
training presents a paradox: feedback from the same problem risks information
leakage and memorization, while feedback from different problems often leads to
behavior collapse due to irrelevant context. To resolve this tension, we
propose \textbf{Language-And-Numerical Policy Optimization (LANPO)}, a
framework that cleanly separates the roles of feedback: language guides
exploration, while numerical rewards drive optimization. LANPO builds a dynamic
experience pool from past trials and introduces two principles to ensure
feedback is effective: \emph{Reward-Agnostic Reflection} for safe intra-sample
self-correction and \emph{Relevant Abstraction} to distill generalizable
lessons from inter-sample experiences. Across mathematical reasoning
benchmarks, LANPO enables 7B and 14B models to significantly outperform strong
baselines trained with GRPO in test accuracy. Our work provides a robust method
for integrating historical experiences into the LLM RL loop, creating more
effective and data-efficient learning agents.

</details>


### [79] [Active Target Discovery under Uninformative Prior: The Power of Permanent and Transient Memory](https://arxiv.org/abs/2510.16676)
*Anindya Sarkar,Binglin Ji,Yevgeniy Vorobeychik*

Main category: cs.LG

TL;DR: 본 연구는 제한된 데이터나 높은 샘플링 비용으로 인해 강력한 사전 지식을 학습하기 어려운 환경에서도 효과적으로 목표를 발견할 수 있는 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 강화된 탐사와 발견 비율 극대화를 위해, 이전 관찰에 기반한 전략적 샘플링이 필요하다.

Method: 우리는 신경 과학에서 영감을 받아 설계된 이론적으로 원칙에 기반한 프레임워크를 제안한다.

Result: 다양한 분야에서 우리의 방법이 기준 접근법보다 상당히 우수함을 입증하였다.

Conclusion: 각 새로운 관찰에 따라 사전 추정치가 강하고 단조롭게 향상되므로, 동적 환경에서 신뢰성과 적응성을 강화한다.

Abstract: In many scientific and engineering fields, where acquiring high-quality data
is expensive--such as medical imaging, environmental monitoring, and remote
sensing--strategic sampling of unobserved regions based on prior observations
is crucial for maximizing discovery rates within a constrained budget. The rise
of powerful generative models, such as diffusion models, has enabled active
target discovery in partially observable environments by leveraging learned
priors--probabilistic representations that capture underlying structure from
data. With guidance from sequentially gathered task-specific observations,
these models can progressively refine exploration and efficiently direct
queries toward promising regions. However, in domains where learning a strong
prior is infeasible due to extremely limited data or high sampling cost (such
as rare species discovery, diagnostics for emerging diseases, etc.), these
methods struggle to generalize. To overcome this limitation, we propose a novel
approach that enables effective active target discovery even in settings with
uninformative priors, ensuring robust exploration and adaptability in complex
real-world scenarios. Our framework is theoretically principled and draws
inspiration from neuroscience to guide its design. Unlike black-box policies,
our approach is inherently interpretable, providing clear insights into
decision-making. Furthermore, it guarantees a strong, monotonic improvement in
prior estimates with each new observation, leading to increasingly accurate
sampling and reinforcing both reliability and adaptability in dynamic settings.
Through comprehensive experiments and ablation studies across various domains,
including species distribution modeling and remote sensing, we demonstrate that
our method substantially outperforms baseline approaches.

</details>


### [80] [Resolution-Aware Retrieval Augmented Zero-Shot Forecasting](https://arxiv.org/abs/2510.16695)
*Iman Deznabi,Peeyush Kumar,Madalina Fiterau*

Main category: cs.LG

TL;DR: 제로샷 예측은 역사적 데이터 없이 이전에 보지 못한 조건에 대한 결과를 예측하는 것을 목표로 하며, 전통적인 예측 방법에 중대한 도전을 제기합니다. 이 논문에서는 공간 상관관계와 시간 주파수 특성을 활용하여 예측 정확도를 향상시키는 해상도 인지 검색 강화 예측 모델을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 과거 데이터를 이용하지 않고 새로운 조건에서의 예측 필요성이 증가하고 있습니다. 이를 해결하기 위해 새로운 접근 방식을 개발하였습니다.

Method: 신호를 다양한 주파수 성분으로 분해하고, 해상도 인지 검색을 통해 저주파 성분은 넓은 공간적 맥락에 의존하며, 고주파 성분은 지역적 영향을 집중적으로 분석합니다. 이를 통해 최소한의 역사적 맥락으로 새로운 위치에 적응할 수 있습니다.

Result: 마이크로클라이밋 예측에 응용한 결과, 전통적인 예측 방법, 수치 기상 예측 모델 및 현대의 기초 시계열 모델을 상당히 초월하여 ERA5 데이터셋에서 HRRR보다 71%, Chronos보다 34% 낮은 MSE를 달성했습니다.

Conclusion: 우리의 결과는 검색 강화 및 해상도 인지 전략의 효과성을 강조하며, 마이크로클라이밋 모델링 및 그 이상에서 제로샷 예측을 위한 확장 가능하고 데이터 효율적인 해결책을 제공합니다.

Abstract: Zero-shot forecasting aims to predict outcomes for previously unseen
conditions without direct historical data, posing a significant challenge for
traditional forecasting methods. We introduce a Resolution-Aware
Retrieval-Augmented Forecasting model that enhances predictive accuracy by
leveraging spatial correlations and temporal frequency characteristics. By
decomposing signals into different frequency components, our model employs
resolution-aware retrieval, where lower-frequency components rely on broader
spatial context, while higher-frequency components focus on local influences.
This allows the model to dynamically retrieve relevant data and adapt to new
locations with minimal historical context.
  Applied to microclimate forecasting, our model significantly outperforms
traditional forecasting methods, numerical weather prediction models, and
modern foundation time series models, achieving 71% lower MSE than HRRR and 34%
lower MSE than Chronos on the ERA5 dataset.
  Our results highlight the effectiveness of retrieval-augmented and
resolution-aware strategies, offering a scalable and data-efficient solution
for zero-shot forecasting in microclimate modeling and beyond.

</details>


### [81] [Learning to play: A Multimodal Agent for 3D Game-Play](https://arxiv.org/abs/2510.16774)
*Yuguang Yue,Irakli Salia,Samuel Hunt,Christopher Green,Wenzhe Shi,Jonathan J Hunt*

Main category: cs.LG

TL;DR: 이 논문은 3D 1인칭 비디오 게임에서의 실시간 다중모드 추론의 도전성을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 3D 첫 번째 사람 비디오 게임이 실시간 다중모드 추론에 도전적인 환경임을 주장한다.

Method: 인간 플레이 데이터를 기반으로 역동력 모델을 학습하고, 행동 클로닝을 이용한 텍스트 조건 에이전트를 훈련한다.

Result: 훈련된 모델이 다양한 3D 게임을 플레이하고 텍스트 입력에 반응할 수 있음을 보여준다.

Conclusion: 장기 작업 및 다양한 게임 성과 수치 평가와 같은 남은 과제를 제시한다.

Abstract: We argue that 3-D first-person video games are a challenging environment for
real-time multi-modal reasoning. We first describe our dataset of human
game-play, collected across a large variety of 3-D first-person games, which is
both substantially larger and more diverse compared to prior publicly disclosed
datasets, and contains text instructions. We demonstrate that we can learn an
inverse dynamics model from this dataset, which allows us to impute actions on
a much larger dataset of publicly available videos of human game play that lack
recorded actions. We then train a text-conditioned agent for game playing using
behavior cloning, with a custom architecture capable of realtime inference on a
consumer GPU. We show the resulting model is capable of playing a variety of
3-D games and responding to text input. Finally, we outline some of the
remaining challenges such as long-horizon tasks and quantitative evaluation
across a large set of games.

</details>


### [82] [Graph Learning is Suboptimal in Causal Bandits](https://arxiv.org/abs/2510.16811)
*Mohammad Shahverdikondori,Jalal Etesami,Negar Kiyavash*

Main category: cs.LG

TL;DR: 이 논문은 인과적 충분성 하에서 인과 밴딧의 후회 최소화 전략을 조사하고, 부모 집합 학습이 비최적임을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 인과적 구조를 모르는 상황에서 후회를 최소화하려는 전략이 필요하다.

Method: 부모 집합 학습 없이도 후회 최소화를 달성하는 거의 최적 알고리즘을 제안한다.

Result: 부모 집합 학습이 후회 최소화에 필요하지 않으며, 기존 방법과의 성능 차이를 실험으로 확인했다.

Conclusion: 후회 최소화를 위해 부모 집합을 식별하는 것이 필수적이지 않음을 입증하였다.

Abstract: We study regret minimization in causal bandits under causal sufficiency where
the underlying causal structure is not known to the agent. Previous work has
focused on identifying the reward's parents and then applying classic bandit
methods to them, or jointly learning the parents while minimizing regret. We
investigate whether such strategies are optimal. Somewhat counterintuitively,
our results show that learning the parent set is suboptimal. We do so by
proving that there exist instances where regret minimization and parent
identification are fundamentally conflicting objectives. We further analyze
both the known and unknown parent set size regimes, establish novel regret
lower bounds that capture the combinatorial structure of the action space.
Building on these insights, we propose nearly optimal algorithms that bypass
graph and parent recovery, demonstrating that parent identification is indeed
unnecessary for regret minimization. Experiments confirm that there exists a
large performance gap between our method and existing baselines in various
environments.

</details>


### [83] [Efficient High-Accuracy PDEs Solver with the Linear Attention Neural Operator](https://arxiv.org/abs/2510.16816)
*Ming Zhong,Zhenya Yan*

Main category: cs.LG

TL;DR: LANO는 선형 복잡성과 소프트맥스 수준의 성능을 결합하여 과학적 기계 학습 응용을 위한 확장 가능하고 높은 정확도의 기초를 마련합니다.


<details>
  <summary>Details</summary>
Motivation: 함수 공간 간 매핑을 학습하기 위해 데이터 기반의 강력한 프레임워크가 필요하지만, 기존 변환기 기반 신경 연산자는 확장성과 정확성 간의 근본적인 균형 문제에 직면해 있습니다.

Method: LANO는 에이전트 기반 메커니즘을 통해 주의를 재구성하여 선형 복잡성과 높은 정확성을 동시에 달성하는 새로운 유형의 신경 연산자를 제시하며, $M$ 개의 에이전트 토큰을 도입하여 글로벌 상호작용을 매개합니다.

Result: LANO는 Transolver와 같은 최신 신경 PDE 솔버를 초월하여 표준 벤치마크에서 평균적으로 19.5%의 정확도 향상을 달성했습니다.

Conclusion: 선형 복잡성과 소프트맥스 수준의 성능 간 격차를 메움으로써 LANO는 과학적 기계 학습 응용을 위한 확장 가능하고 높은 정확도의 기초를 확립합니다.

Abstract: Neural operators offer a powerful data-driven framework for learning mappings
between function spaces, in which the transformer-based neural operator
architecture faces a fundamental scalability-accuracy trade-off: softmax
attention provides excellent fidelity but incurs quadratic complexity
$\mathcal{O}(N^2 d)$ in the number of mesh points $N$ and hidden dimension $d$,
while linear attention variants reduce cost to $\mathcal{O}(N d^2)$ but often
suffer significant accuracy degradation. To address the aforementioned
challenge, in this paper, we present a novel type of neural operators, Linear
Attention Neural Operator (LANO), which achieves both scalability and high
accuracy by reformulating attention through an agent-based mechanism. LANO
resolves this dilemma by introducing a compact set of $M$ agent tokens $(M \ll
N)$ that mediate global interactions among $N$ tokens. This agent attention
mechanism yields an operator layer with linear complexity $\mathcal{O}(MN d)$
while preserving the expressive power of softmax attention. Theoretically, we
demonstrate the universal approximation property, thereby demonstrating
improved conditioning and stability properties. Empirically, LANO surpasses
current state-of-the-art neural PDE solvers, including Transolver with
slice-based softmax attention, achieving average $19.5\%$ accuracy improvement
across standard benchmarks. By bridging the gap between linear complexity and
softmax-level performance, LANO establishes a scalable, high-accuracy
foundation for scientific machine learning applications.

</details>


### [84] [Fly-CL: A Fly-Inspired Framework for Enhancing Efficient Decorrelation and Reduced Training Time in Pre-trained Model-based Continual Representation Learning](https://arxiv.org/abs/2510.16877)
*Heming Zou,Yunliang Zang,Wutong Xu,Xiangyang Ji*

Main category: cs.LG

TL;DR: Fly-CL은 미리 학습된 모델을 사용하여 지속적 표현 학습의 문제를 해결하고, 저비용으로 효과적인 유사성 매칭을 통해 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 지속적 표현 학습 패러다임은 매개변수 업데이트를 유사성 매칭 문제로 재구성하여 치명적인 망각을 완화하고자 합니다.

Method: Fly-CL은 벌레의 후각 회로에서 영감을 받아 다양한 사전 훈련된 백본과 호환되는 생물학적으로 영감을 받은 프레임워크입니다.

Result: Fly-CL은 훈련 시간을 대폭 단축하면서 현재의 최첨단 방법과 동등하거나 그 이상의 성능을 달성합니다.

Conclusion: Fly-CL을 통해 다중공선성을 점진적으로 해결하여 저시간 복잡도로 더 효과적인 유사성 매칭을 가능하게 합니다.

Abstract: Using a nearly-frozen pretrained model, the continual representation learning
paradigm reframes parameter updates as a similarity-matching problem to
mitigate catastrophic forgetting. However, directly leveraging pretrained
features for downstream tasks often suffers from multicollinearity in the
similarity-matching stage, and more advanced methods can be computationally
prohibitive for real-time, low-latency applications. Inspired by the fly
olfactory circuit, we propose Fly-CL, a bio-inspired framework compatible with
a wide range of pretrained backbones. Fly-CL substantially reduces training
time while achieving performance comparable to or exceeding that of current
state-of-the-art methods. We theoretically show how Fly-CL progressively
resolves multicollinearity, enabling more effective similarity matching with
low time complexity. Extensive simulation experiments across diverse network
architectures and data regimes validate Fly-CL's effectiveness in addressing
this challenge through a biologically inspired design. Code is available at
https://github.com/gfyddha/Fly-CL.

</details>


### [85] [Adaptive Online Learning with LSTM Networks for Energy Price Prediction](https://arxiv.org/abs/2510.16898)
*Salih Salihoglu,Ibrahim Ahmed,Afshin Asadi*

Main category: cs.LG

TL;DR: 전력 가격 예측을 위한 LSTM 네트워크 모델을 개발하여 캘리포니아 전력 시장의 하루 앞 전력 가격을 예측하는 연구.


<details>
  <summary>Details</summary>
Motivation: 전력 시장의 이해 관계자들에게 전력 가격의 정확한 예측이 중요하기 때문.

Method: LSTM 네트워크를 이용한 예측 모델을 개발하고, 역사적 가격 데이터, 날씨 조건, 에너지 생산 믹스를 포함하는 다양한 특징을 통합함.

Result: 커스텀 손실 함수가 모델의 성능을 개선하고, 피크 시간대 동안 예측된 가격이 실제 값과 더 밀접하게 일치함을 보여줌.

Conclusion: 이 연구는 역동적인 전력 시장에서의 더 나은 의사 결정을 위한 유용한 통찰과 도구를 제공하는 전력 가격 예측을 위한 강력한 프레임워크를 제공한다.

Abstract: Accurate prediction of electricity prices is crucial for stakeholders in the
energy market, particularly for grid operators, energy producers, and
consumers. This study focuses on developing a predictive model leveraging Long
Short-Term Memory (LSTM) networks to forecast day-ahead electricity prices in
the California energy market. The model incorporates a variety of features,
including historical price data, weather conditions, and the energy generation
mix. A novel custom loss function that integrates Mean Absolute Error (MAE),
Jensen-Shannon Divergence (JSD), and a smoothness penalty is introduced to
enhance the prediction accuracy and interpretability. Additionally, an online
learning approach is implemented to allow the model to adapt to new data
incrementally, ensuring continuous relevance and accuracy. The results
demonstrate that the custom loss function can improve the model's performance,
aligning predicted prices more closely with actual values, particularly during
peak intervals. Also, the online learning model outperforms other models by
effectively incorporating real-time data, resulting in lower prediction error
and variability. The inclusion of the energy generation mix further enhances
the model's predictive capabilities, highlighting the importance of
comprehensive feature integration. This research provides a robust framework
for electricity price forecasting, offering valuable insights and tools for
better decision-making in dynamic electricity markets.

</details>


### [86] [SNOMED CT-powered Knowledge Graphs for Structured Clinical Data and Diagnostic Reasoning](https://arxiv.org/abs/2510.16899)
*Dun Liu,Qin Pang,Guangai Liu,Hongyu Mou,Jipeng Fan,Yiming Miao,Pin-Han Ho,Limei Peng*

Main category: cs.LG

TL;DR: 이 논문은 비구조적 임상 문서가 인공지능(AI)의 효과성을 저해하는 문제를 해결하기 위해 SNOMED CT와 Neo4j 그래프 데이터베이스를 통합하여 구조화된 의료 지식 그래프를 구축하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI의 효과성을 저해하는 비구조적 임상 문서 문제를 해결하기 위해.

Method: SNOMED CT와 Neo4j를 통합하여 임상 개체와 의미적 관계를 모델링한 구조화된 의료 지식 그래프를 구축.

Result: 대규모 언어 모델(LLMs)의 임상 논리 일관성을 크게 개선하고, AI 생성 진단 추론의 유효성과 해석 가능성을 높임.

Conclusion: 신뢰할 수 있는 AI 보조 임상 시스템 구축을 위한 확장 가능한 해결책을 제공한다.

Abstract: The effectiveness of artificial intelligence (AI) in healthcare is
significantly hindered by unstructured clinical documentation, which results in
noisy, inconsistent, and logically fragmented training data. To address this
challenge, we present a knowledge-driven framework that integrates the
standardized clinical terminology SNOMED CT with the Neo4j graph database to
construct a structured medical knowledge graph. In this graph, clinical
entities such as diseases, symptoms, and medications are represented as nodes,
and semantic relationships such as ``caused by,'' ``treats,'' and ``belongs
to'' are modeled as edges in Neo4j, with types mapped from formal SNOMED CT
relationship concepts (e.g., \texttt{Causative agent}, \texttt{Indicated for}).
This design enables multi-hop reasoning and ensures terminological consistency.
By extracting and standardizing entity-relationship pairs from clinical texts,
we generate structured, JSON-formatted datasets that embed explicit diagnostic
pathways. These datasets are used to fine-tune large language models (LLMs),
significantly improving the clinical logic consistency of their outputs.
Experimental results demonstrate that our knowledge-guided approach enhances
the validity and interpretability of AI-generated diagnostic reasoning,
providing a scalable solution for building reliable AI-assisted clinical
systems.

</details>


### [87] [Domain Generalizable Continual Learning](https://arxiv.org/abs/2510.16914)
*Hongwei Yan,Guanglong Sun,Zhiqi Kang,Yi Zhong,Liyuan Wang*

Main category: cs.LG

TL;DR: 지속적인 학습을 위한 새로운 설정인 도메인 일반화 가능한 지속적 학습(DGCL)을 소개하며, 이 모델은 단일 도메인을 포함하는 연속 작업을 학습하여 모든 작업과 도메인에서 우수한 성능을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 지속적이고 동적인 실제 환경에서 지능형 시스템이 새로운 기술을 습득하고 이를 다양한 미지의 시나리오에 일반화할 수 있도록 해야 한다는 필요성.

Method: 제안된 방법인 적응형 도메인 변형(DoT)은 사전 훈련된 모델을 기반으로 하여 작업 표현을 다양한 도메인에 맞게 변환하고 시맨틱 및 도메인 관련 정보를 분리하여 일반화된 결과를 보장하는 접근법이다.

Result: DoT는 DGCL 하의 최신 CL 기준을 크게 향상시키며, 철저한 실험을 통해 검증되었다.

Conclusion: DoT는 자원 효율성을 유지하면서 DGCL에서 도메인 일반화 가능한 지식을 축적할 수 있는 경량 구현을 보인다.

Abstract: To adapt effectively to dynamic real-world environments, intelligent systems
must continually acquire new skills while generalizing them to diverse, unseen
scenarios. Here, we introduce a novel and realistic setting named domain
generalizable continual learning (DGCL): a model learns sequential tasks with
each involving a single domain, aiming to perform well across all encountered
tasks and domains. This setting poses unique challenges in acquiring,
retaining, and leveraging both semantic- and domain-relevant information for
robust generalization. Although state-of-the-art continual learning (CL)
methods have employed pre-trained models (PTMs) to enhance task-specific
generalization, they typically assume identical training and testing domains
for each task and therefore perform poorly in DGCL. To this end, we propose
adaptive Domain Transformation (DoT), an innovative PTMs-based approach
tailored to DGCL. Inspired by the distributed-plus-hub theory of the human
brain, DoT disentangles semantic- and domain-relevant information in
representation learning, and adaptively transforms task representations across
various domains for output alignment, ensuring balanced and generalized
predictions. DoT serves as a plug-in strategy that greatly facilitates
state-of-the-art CL baselines under both full parameter tuning and
parameter-efficient tuning paradigms in DGCL, validated by extensive
experiments. Also, DoT is shown to accumulate domain-generalizable knowledge
from DGCL, and ensure resource efficiency with a lightweight implementation.

</details>


### [88] [SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search](https://arxiv.org/abs/2510.16916)
*Dong Li,Xujiang Zhao,Linlin Yu,Yanchi Liu,Wei Cheng,Zhengzhang Chen,Zhong Chen,Feng Chen,Chen Zhao,Haifeng Chen*

Main category: cs.LG

TL;DR: SolverLLM은 테스트 시 스케일링을 활용하여 다양한 최적화 문제를 푸는 교육 없는 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 추론 작업 및 최적화 문제를 해결하기 위한 기존 방법의 한계를 극복하기 위해.

Method: SolverLLM은 새로운 몬테카를로 트리 탐색(MCTS) 전략을 통해 수학적 공식화를 생성하고 해결 가능한 코드로 변환합니다.

Result: SolverLLM은 6개의 표준 벤치마크 데이터 세트에서 기존 프롬프트 기반 및 학습 기반 기준선을 능가하며, 추가 교육 없이도 강력한 일반화를 달성합니다.

Conclusion: SolverLLM은 프롬프트 엔지니어링에 의존하지 않으며 비용이 많이 드는 감독 학습이 필요하지 않은 유망한 접근법입니다.

Abstract: Large Language Models (LLMs) offer promising capabilities for tackling
complex reasoning tasks, including optimization problems. However, existing
methods either rely on prompt engineering, which leads to poor generalization
across problem types, or require costly supervised training. We introduce
SolverLLM, a training-free framework that leverages test-time scaling to solve
diverse optimization problems. Rather than solving directly, SolverLLM
generates mathematical formulations and translates them into solver-ready code,
guided by a novel Monte Carlo Tree Search (MCTS) strategy. To enhance the
search process, we modify classical MCTS with (1) dynamic expansion for
adaptive formulation generation, (2) prompt backpropagation to guide
exploration via outcome-driven feedback, and (3) uncertainty backpropagation to
incorporate reward reliability into decision-making. Experiments on six
standard benchmark datasets demonstrate that SolverLLM outperforms both
prompt-based and learning-based baselines, achieving strong generalization
without additional training.

</details>


### [89] [Towards Interpretable and Trustworthy Time Series Reasoning: A BlueSky Vision](https://arxiv.org/abs/2510.16980)
*Kanghui Ning,Zijie Pan,Yushan Jiang,Anderson Schneider,Yuriy Nevmyvaka,Dongjin Song*

Main category: cs.LG

TL;DR: 이 논문은 시간 시계열 추론의 발전을 위한 새로운 비전을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 시간 시계열 추론은 패턴 인식을 넘어 명확하고 해석 가능하며 신뢰할 수 있는 추론으로 나아가고자 합니다.

Method: 포괄적인 시간 이해, 구조화된 다단계 추론, 신뢰할 수 있는 평가 프레임워크를 중심으로 한 강력한 기반을 구축하고, 다중 에이전트 협업, 다중 모달 컨텍스트 및 검색 증강 접근 방식을 포함한 시스템 수준의 추론으로 나아갑니다.

Result: 이 두 방향은 유연하고 확장 가능한 시간 시계열 추론 프레임워크를 설명합니다.

Conclusion: 다양한 도메인에서 해석 가능하고 신뢰할 수 있는 시간 지능을 제공하는 것을 목표로 합니다.

Abstract: Time series reasoning is emerging as the next frontier in temporal analysis,
aiming to move beyond pattern recognition towards explicit, interpretable, and
trustworthy inference. This paper presents a BlueSky vision built on two
complementary directions. One builds robust foundations for time series
reasoning, centered on comprehensive temporal understanding, structured
multi-step reasoning, and faithful evaluation frameworks. The other advances
system-level reasoning, moving beyond language-only explanations by
incorporating multi-agent collaboration, multi-modal context, and
retrieval-augmented approaches. Together, these directions outline a flexible
and extensible framework for advancing time series reasoning, aiming to deliver
interpretable and trustworthy temporal intelligence across diverse domains.

</details>


### [90] [Graph4MM: Weaving Multimodal Learning with Structural Information](https://arxiv.org/abs/2510.16990)
*Xuying Ning,Dongqi Fu,Tianxin Wei,Wujiang Xu,Jingrui He*

Main category: cs.LG

TL;DR: Graph4MM 프레임워크는 다중 모달 학습에서 그래프의 역할을 재조명하고, Hop-Diffused Attention을 사용하여 다중 커널의 구조적 정보를 통합하며, MM-QFormer를 통해 크로스 모달 융합을 위한 질의 변환기를 설계한다.


<details>
  <summary>Details</summary>
Motivation: 실제 세계의 다중 모달 데이터는 전통적인 일대일 매핑을 넘어서는 복잡한 구조적 관계를 나타냅니다.

Method: 그래프 기반의 다중 모달 학습 프레임워크인 Graph4MM을 제안하며, Hop-Diffused Attention과 MM-QFormer를 통해 모달 간 융합을 수행합니다.

Result: 이론적 및 경험적 분석을 통해 Graph4MM이 더 큰 VLM, LLM 및 다중 모달 그래프 기반선보다 평균 6.93% 향상된 성능을 보입니다.

Conclusion: 구조를 활용하여 모달 내 및 모달 간 상호작용을 통합하면 다중 모달 이해가 향상됩니다.

Abstract: Real-world multimodal data usually exhibit complex structural relationships
beyond traditional one-to-one mappings like image-caption pairs. Entities
across modalities interact in intricate ways, with images and text forming
diverse interconnections through contextual dependencies and co-references.
Graphs provide powerful structural information for modeling intra-modal and
inter-modal relationships. However, previous works fail to distinguish
multi-hop neighbors and treat the graph as a standalone modality, which
fragments the overall understanding. This limitation presents two key
challenges in multimodal learning: (1) integrating structural information from
multi-hop neighbors into foundational models, and (2) fusing modality-specific
information in a principled manner. To address these challenges, we revisit the
role of graphs in multimodal learning within the era of foundation models and
propose Graph4MM, a graph-based multimodal learning framework. To be specific,
we introduce Hop-Diffused Attention, which integrates multi-hop structural
information into self-attention through causal masking and hop diffusion.
Furthermore, we design MM-QFormer, a multi-mapping querying transformer for
cross-modal fusion. Through theoretical and empirical analysis, we show that
leveraging structures to integrate both intra- and inter-modal interactions
improves multimodal understanding beyond treating them as a standalone
modality. Experiments on both generative and discriminative tasks show that
Graph4MM outperforms larger VLMs, LLMs, and multimodal graph baselines,
achieving a 6.93% average improvement.

</details>


### [91] [EEschematic: Multimodal-LLM Based AI Agent for Schematic Generation of Analog Circuit](https://arxiv.org/abs/2510.17002)
*Chang Liu,Danial Chitnis*

Main category: cs.LG

TL;DR: EEschematic은 텍스트, 시각 및 기호 모드를 통합하여 SPICE 넷리스트를 자동으로 아날로그 회로도 다이어그램으로 변환하는 AI 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: 회로 기호는 아날로그 집적회로 설계에서 중요한 역할을 하며, 회로 기능의 이해와 검증을 위한 주요 수단으로 작용한다. 그러나 기존 모델은 주로 텍스트 기반 표현에 의존하여 회로 설계자에게는 시각적 해석 가능성이 부족하다.

Method: EEschematic은 다중모드 대형 언어 모델(MLLM)을 활용하여 텍스트, 시각 및 기호 모드를 통합하고, SPICE 넷리스트를 사람이 편집할 수 있는 형식의 회로도 다이어그램으로 변환한다. 이 프레임워크는 적은 샘플의 배치와 VCoT 전략을 사용하여 배치와 배선을 반복적으로 개선한다.

Result: CMOS 인버터, 5트랜지스터 작동 전도도 증폭기(5T-OTA) 및 망원 카스코드 증폭기를 포함한 대표적인 아날로그 회로에서 EEschematic이 높은 시각적 품질과 구조적 정확성을 갖춘 회로도를 생성함을 실험적으로 입증하였다.

Conclusion: EEschematic는 아날로그 회로 설계의 효율성을 높일 수 있는 잠재력이 있다.

Abstract: Circuit schematics play a crucial role in analog integrated circuit design,
serving as the primary medium for human understanding and verification of
circuit functionality. While recent large language model (LLM)-based approaches
have shown promise in circuit topology generation and device sizing, most rely
solely on textual representations such as SPICE netlists, which lack visual
interpretability for circuit designers. To address this limitation, we propose
EEschematic, an AI agent for automatic analog schematic generation based on a
Multimodal Large Language Model (MLLM). EEschematic integrates textual, visual,
and symbolic modalities to translate SPICE netlists into schematic diagrams
represented in a human-editable format. The framework uses six analog
substructure examples for few-shot placement and a Visual Chain-of-Thought
(VCoT) strategy to iteratively refine placement and wiring, enhancing schematic
clarity and symmetry. Experimental results on representative analog circuits,
including a CMOS inverter, a five-transistor operational transconductance
amplifier (5T-OTA), and a telescopic cascode amplifier, demonstrate that
EEschematic produces schematics with high visual quality and structural
correctness.

</details>


### [92] [Hephaestus: Mixture Generative Modeling with Energy Guidance for Large-scale QoS Degradation](https://arxiv.org/abs/2510.17036)
*Nguyen Do,Bach Ngo,Youval Kashuv,Canh V. Pham,Hanghang Tong,My T. Thai*

Main category: cs.LG

TL;DR: 본 연구에서는 적대자가 엣지 가중치를 교란하여 네트워크 성능을 저하시키는 QoSD 문제를 다룬다. 기존의 방법들이 조합 최적화에 의존하는 반면, 본 연구에서는 비선형 엣지 가중치 함수 하의 QoSD 문제를 직접 해결하는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: QoSD 문제는 네트워크 성능을 저하시킬 수 있는 엣지 가중치의 교란을 다루며, 이는 통신 품질이 기능성을 결정하는 네트워크 인프라와 분산 ML 시스템에서 발생한다.

Method: 이 연구에서는 자기강화 생성 프레임워크인 \\PIMMA를 제안하며, 라탠트 공간에서 실행 가능한 솔루션을 합성한다. 방법론은 예측 경로 스트레칭(PPS) 알고리즘, 혼합 조건부 VAE를 위한 새로운 훈련 패러다임, 강화 학습 에이전트를 포함한다.

Result: 합성 및 실제 네트워크에서의 실험 결과, 본 접근 방식이 고전적인 방법 및 ML 기반 기준을 일관되게 초월하며, 특히 전통적 방법이 일반화하지 못하는 비선형 비용 함수의 시나리오에서 성과를 보인다.

Conclusion: 본 연구는 비선형 엣지 가중치 함수 하의 QoSD 문제를 효과적으로 해결하기 위한 새로운 방법론을 제시하여, 기존 방법들의 한계를 극복하는 데 기여한다.

Abstract: We study the Quality of Service Degradation (QoSD) problem, in which an
adversary perturbs edge weights to degrade network performance. This setting
arises in both network infrastructures and distributed ML systems, where
communication quality, not just connectivity, determines functionality. While
classical methods rely on combinatorial optimization, and recent ML approaches
address only restricted linear variants with small-size networks, no prior
model directly tackles the QoSD problem under nonlinear edge-weight functions.
This work proposes \PIMMA, a self-reinforcing generative framework that
synthesizes feasible solutions in latent space, to fill this gap. Our method
includes three phases: (1) Forge: a Predictive Path-Stressing (PPS) algorithm
that uses graph learning and approximation to produce feasible solutions with
performance guarantee, (2) Morph: a new theoretically grounded training
paradigm for Mixture of Conditional VAEs guided by an energy-based model to
capture solution feature distributions, and (3) Refine: a reinforcement
learning agent that explores this space to generate progressively near-optimal
solutions using our designed differentiable reward function. Experiments on
both synthetic and real-world networks show that our approach consistently
outperforms classical and ML baselines, particularly in scenarios with
nonlinear cost functions where traditional methods fail to generalize.

</details>


### [93] [Diverse Influence Component Analysis: A Geometric Approach to Nonlinear Mixture Identifiability](https://arxiv.org/abs/2510.17040)
*Hoang-Son Nguyen,Xiao Fu*

Main category: cs.LG

TL;DR: 본 연구에서는 혼합 함수의 볼륨 최대화 기준을 이용해 잠재 구성 요소의 식별 가능성을 확보하는 DICA(다양한 영향 구성 요소 분석)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 잠재 구성 요소를 식별하는 것은 비선형 혼합물에서의 기반적인 도전과제로, 이 연구는 이러한 문제를 해결하고자 한다.

Method: DICA 프레임워크는 혼합 함수의 야코비안의 볼륨을 최대화하는 기준(J-VolMax)을 제안하여 잠재 구성 요소를 식별한다.

Result: 합리적인 조건 하에, DICA는 보조 정보나 독립성 또는 희소성 가정에 의지하지 않고도 식별 가능성을 달성한다.

Conclusion: 이 연구 결과는 식별 가능성 분석의 범위를 확장하고 기존 방법에 대한 보완적인 관점을 제공한다.

Abstract: Latent component identification from unknown nonlinear mixtures is a
foundational challenge in machine learning, with applications in tasks such as
disentangled representation learning and causal inference. Prior work in
nonlinear independent component analysis (nICA) has shown that auxiliary
signals -- such as weak supervision -- can support identifiability of
conditionally independent latent components. More recent approaches explore
structural assumptions, e.g., sparsity in the Jacobian of the mixing function,
to relax such requirements. In this work, we introduce Diverse Influence
Component Analysis (DICA), a framework that exploits the convex geometry of the
mixing function's Jacobian. We propose a Jacobian Volume Maximization
(J-VolMax) criterion, which enables latent component identification by
encouraging diversity in their influence on the observed variables. Under
reasonable conditions, this approach achieves identifiability without relying
on auxiliary information, latent component independence, or Jacobian sparsity
assumptions. These results extend the scope of identifiability analysis and
offer a complementary perspective to existing methods.

</details>


### [94] [Consistent Zero-Shot Imitation with Contrastive Goal Inference](https://arxiv.org/abs/2510.17059)
*Kathryn Wantlin,Chongyi Zheng,Benjamin Eysenbach*

Main category: cs.LG

TL;DR: 이 논문은 자가 감독 방식으로 상호 작용하는 에이전트를 사전 훈련하는 방법을 제안하여, 그들이 즉시 인간의 시연을 모방할 수 있도록 함을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 오늘날의 대다수 성공적인 AI 모델은 명시적인 행동 개념 없이 훈련되며, 현실 세계 상호작용을 통해 배양된 에이전트는 상호작용 훈련이 필요하다.

Method: 이 연구는 목표(관찰)를 원자적 구성 요소로 삼아 자동으로 목표를 제안하고 이를 도달하는 연습을 한다.

Result: 우리의 방법이 기존 제로샷 모방 방법보다 우수하다는 것을 표준 벤치마크를 통해 입증하였다.

Conclusion: 이 방법은 즉각적으로 인간의 행동을 모방할 수 있도록 에이전트를 사전 훈련시키는 새로운 접근을 제시한다.

Abstract: In the same way that generative models today conduct most of their training
in a self-supervised fashion, how can agentic models conduct their training in
a self-supervised fashion, interactively exploring, learning, and preparing to
quickly adapt to new tasks? A prerequisite for embodied agents deployed in real
world interactions ought to be training with interaction, yet today's most
successful AI models (e.g., VLMs, LLMs) are trained without an explicit notion
of action. The problem of pure exploration (which assumes no data as input) is
well studied in the reinforcement learning literature and provides agents with
a wide array of experiences, yet it fails to prepare them for rapid adaptation
to new tasks. Today's language and vision models are trained on data provided
by humans, which provides a strong inductive bias for the sorts of tasks that
the model will have to solve (e.g., modeling chords in a song, phrases in a
sonnet, sentences in a medical record). However, when they are prompted to
solve a new task, there is a faulty tacit assumption that humans spend most of
their time in the most rewarding states. The key contribution of our paper is a
method for pre-training interactive agents in a self-supervised fashion, so
that they can instantly mimic human demonstrations. Our method treats goals
(i.e., observations) as the atomic construct. During training, our method
automatically proposes goals and practices reaching them, building off prior
work in reinforcement learning exploration. During evaluation, our method
solves an (amortized) inverse reinforcement learning problem to explain
demonstrations as optimal goal-reaching behavior. Experiments on standard
benchmarks (not designed for goal-reaching) show that our approach outperforms
prior methods for zero-shot imitation.

</details>


### [95] [Explainable Heterogeneous Anomaly Detection in Financial Networks via Adaptive Expert Routing](https://arxiv.org/abs/2510.17088)
*Zan Li,Rui Fan*

Main category: cs.LG

TL;DR: 이 연구는 금융 이상 현상의 다양한 메커니즘을 이해하기 위해 적응형 그래프 학습을 사용하여 실질적인 해석 가능성을 제공하며, 시장 변화 시에도 정확한 탐지가 가능함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존 탐지기는 모든 금융 이상 현상을 동일하게 처리하여 어떤 메커니즘이 실패하는지, 위험이 집중되는 위치, 어떻게 개입해야 하는지 등을 밝히지 못한다.

Method: 전문가 네트워크를 통한 적응형 그래프 학습을 적용하며, BiLSTM과 자체 주의를 사용하여 다중 규모의 시간적 의존성을 포착하고, 크로스 모달 주의를 통해 공간적 정보를 융합하며, 신경 네트워크로 동적 그래프를 배우고, 기계적 변동을 구조적 우선 사항과 균형을 이루도록 한다.

Result: 100개의 미국 주식을 분석하여 92.3%의 탐지율을 기록하며, 3.8일의 리드 타임으로 13개의 주요 사건을 성공적으로 탐지하였다.

Conclusion: 자동 시간적 메커니즘 식별을 통해 라벨이 없는 감독 학습에서도 금융 이상 현상의 진화를 추적할 수 있음을 보여준다.

Abstract: Financial anomalies exhibit heterogeneous mechanisms (price shocks, liquidity
freezes, contagion cascades, regime shifts), but existing detectors treat all
anomalies uniformly, producing scalar scores without revealing which mechanism
is failing, where risks concentrate, or how to intervene. This opacity prevents
targeted regulatory responses. Three unsolved challenges persist: (1) static
graph structures cannot adapt when market correlations shift during regime
changes; (2) uniform detection mechanisms miss type-specific signatures across
multiple temporal scales while failing to integrate individual behaviors with
network contagion; (3) black-box outputs provide no actionable guidance on
anomaly mechanisms or their temporal evolution.
  We address these via adaptive graph learning with specialized expert networks
that provide built-in interpretability. Our framework captures multi-scale
temporal dependencies through BiLSTM with self-attention, fuses temporal and
spatial information via cross-modal attention, learns dynamic graphs through
neural multi-source interpolation, adaptively balances learned dynamics with
structural priors via stress-modulated fusion, routes anomalies to four
mechanism-specific experts, and produces dual-level interpretable attributions.
Critically, interpretability is embedded architecturally rather than applied
post-hoc.
  On 100 US equities (2017-2024), we achieve 92.3% detection of 13 major events
with 3.8-day lead time, outperforming best baseline by 30.8pp. Silicon Valley
Bank case study demonstrates anomaly evolution tracking: Price-Shock expert
weight rose to 0.39 (33% above baseline 0.29) during closure, peaking at 0.48
(66% above baseline) one week later, revealing automatic temporal mechanism
identification without labeled supervision.

</details>


### [96] [Do LLMs Recognize Your Latent Preferences? A Benchmark for Latent Information Discovery in Personalized Interaction](https://arxiv.org/abs/2510.17132)
*Ioannis Tsaknakis,Bingqing Song,Shuyu Gan,Dongyeop Kang,Alfredo Garcia,Gaowen Liu,Charles Fleming,Mingyi Hong*

Main category: cs.LG

TL;DR: 본 연구는 대화 중에 사용자 고유의 숨겨진 선호를 발견하고 활용하는 능력을 평가하기 위한 통합 기준을 도입합니다.


<details>
  <summary>Details</summary>
Motivation: 사용자 특정 선호가 필요한 상황에서 대규모 언어 모델(LLM)이 제한적일 수 있다는 문제를 해결하고자 합니다.

Method: 사용자, 어시스턴트 및 판사가 포함된 삼자 에이전트 프레임워크를 사용하여 20 Questions 게임, 개인화된 질문 응답 및 개인화된 텍스트 요약의 세 가지 진화하는 설정에서 다중 턴 상호작용을 통해 숨겨진 사용자 속성을 발견하고 활용하는 LLM의 능력을 평가합니다.

Result: 대화를 통해 숨겨진 정보를 드러낼 수 있지만, 성공률은 상황에 따라 다르게 나타났습니다. 성공률은 작업의 복잡성, 주제 및 숨겨진 속성의 수에 따라 32%에서 98%까지 변동했습니다.

Conclusion: 효과적인 선호 추론은 진정한 적응형 AI 시스템을 구축하기 위한 열린 분야로 남아있음을 강조하며, 개인화된 상호작용에서 숨겨진 정보 발견을 연구하기 위한 첫 번째 체계적인 프레임워크를 제공합니다.

Abstract: Large Language Models (LLMs) excel at producing broadly relevant text, but
this generality becomes a limitation when user-specific preferences are
required, such as recommending restaurants or planning travel. In these
scenarios, users rarely articulate every preference explicitly; instead, much
of what they care about remains latent, waiting to be inferred. This raises a
fundamental question: Can LLMs uncover and reason about such latent information
through conversation?
  We address this problem by introducing a unified benchmark for evaluating
latent information discovery - the ability of LLMs to reveal and utilize hidden
user attributes through multi-turn interaction. The benchmark spans three
progressively realistic settings: the classic 20 Questions game, Personalized
Question Answering, and Personalized Text Summarization. All tasks share a
tri-agent framework (User, Assistant, Judge) enabling turn-level evaluation of
elicitation and adaptation. Our results reveal that while LLMs can indeed
surface latent information through dialogue, their success varies dramatically
with context: from 32% to 98%, depending on task complexity, topic, and number
of hidden attributes. This benchmark provides the first systematic framework
for studying latent information discovery in personalized interaction,
highlighting that effective preference inference remains an open frontier for
building truly adaptive AI systems.

</details>


### [97] [Learning After Model Deployment](https://arxiv.org/abs/2510.17160)
*Derda Kaymak,Gyuhak Kim,Tomoya Kaichi,Tatsuya Konishi,Bing Liu*

Main category: cs.LG

TL;DR: 모델 배포 후 자율 학습(ALMD) 패러다임을 제안하며, 이는 고정된 모델 대신 동적인 환경에서 새로운 클래스의 샘플을 감지하고 학습할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 다양하고 개방적인 환경에서 예상치 못한 샘플이 등장할 수 있는 상황에서 모델이 고정되어 있는 것이 부적절하므로, 모델이 새로운 클래스를 인식하고 학습할 수 있도록 합니다.

Method: 동적 OOD 감지와 새로운 클래스의 점진적 학습을 수행하는 새로운 방법인 PLDA를 제안합니다.

Result: PLDA의 효과성은 실험적 평가를 통해 입증될 것입니다.

Conclusion: ALMD는 기존의 감독 학습과 달리 새로운 클래스를 즉각적으로 학습하는 방법입니다.

Abstract: In classic supervised learning, once a model is deployed in an application,
it is fixed. No updates will be made to it during the application. This is
inappropriate for many dynamic and open environments, where unexpected samples
from unseen classes may appear. In such an environment, the model should be
able to detect these novel samples from unseen classes and learn them after
they are labeled. We call this paradigm Autonomous Learning after Model
Deployment (ALMD). The learning here is continuous and involves no human
engineers. Labeling in this scenario is performed by human co-workers or other
knowledgeable agents, which is similar to what humans do when they encounter an
unfamiliar object and ask another person for its name. In ALMD, the detection
of novel samples is dynamic and differs from traditional out-of-distribution
(OOD) detection in that the set of in-distribution (ID) classes expands as new
classes are learned during application, whereas ID classes is fixed in
traditional OOD detection. Learning is also different from classic supervised
learning because in ALMD, we learn the encountered new classes immediately and
incrementally. It is difficult to retrain the model from scratch using all the
past data from the ID classes and the novel samples from newly discovered
classes, as this would be resource- and time-consuming. Apart from these two
challenges, ALMD faces the data scarcity issue because instances of new classes
often appear sporadically in real-life applications. To address these issues,
we propose a novel method, PLDA, which performs dynamic OOD detection and
incremental learning of new classes on the fly. Empirical evaluations will
demonstrate the effectiveness of PLDA.

</details>


### [98] [ALPINE: A Lightweight and Adaptive Privacy-Decision Agent Framework for Dynamic Edge Crowdsensing](https://arxiv.org/abs/2510.17162)
*Guanjie Cheng,Siyang Liu,Junqin Huang,Xinkui Zhao,Yin Wang,Mengying Zhu,Linghe Kong,Shuiguang Deng*

Main category: cs.LG

TL;DR: ALPINE은 동적 위험 인식 및 실시간 개인 정보 설정 조정을 제공하는 경량의 적응형 프레임워크로, 모바일 엣지 크라우드센싱 환경에서 사용자 데이터를 안전하게 보호한다.


<details>
  <summary>Details</summary>
Motivation: MECS 시스템에서 사용자 데이터의 전송 및 개인 정보 보호의 필요성.

Method: ALPINE은 동적 위험 인식, TD3 기반 프라이버시 결정, 로컬 개인 정보 실행 및 성능 검증을 포함하는 폐쇄 루프 제어 시스템으로 작동한다.

Result: ALPINE은 추론 공격을 효과적으로 완화하면서도 유틸리티와 비용을 유지하는 성능을 보여주었다.

Conclusion: ALPINE은 대규모 엣지 애플리케이션에 실용적이다.

Abstract: Mobile edge crowdsensing (MECS) systems continuously generate and transmit
user data in dynamic, resource-constrained environments, exposing users to
significant privacy threats. In practice, many privacy-preserving mechanisms
build on differential privacy (DP). However, static DP mechanisms often fail to
adapt to evolving risks, for example, shifts in adversarial capabilities,
resource constraints and task requirements, resulting in either excessive noise
or inadequate protection. To address this challenge, we propose ALPINE, a
lightweight, adaptive framework that empowers terminal devices to autonomously
adjust differential privacy levels in real time. ALPINE operates as a
closed-loop control system consisting of four modules: dynamic risk perception,
privacy decision via twin delayed deep deterministic policy gradient (TD3),
local privacy execution and performance verification from edge nodes. Based on
environmental risk assessments, we design a reward function that balances
privacy gains, data utility and energy cost, guiding the TD3 agent to
adaptively tune noise magnitude across diverse risk scenarios and achieve a
dynamic equilibrium among privacy, utility and cost. Both the collaborative
risk model and pretrained TD3-based agent are designed for low-overhead
deployment. Extensive theoretical analysis and real-world simulations
demonstrate that ALPINE effectively mitigates inference attacks while
preserving utility and cost, making it practical for large-scale edge
applications.

</details>


### [99] [Latent Spaces Beyond Synthesis: From GANs to Diffusion Models](https://arxiv.org/abs/2510.17383)
*Ludovica Schaerf*

Main category: cs.LG

TL;DR: 본 논문은 GAN 및 VAE에서 확산 기반 아키텍처로의 개념적 및 기술적 전환에 중점을 두고 생성 시각 모델의 내부 표현의 진화를 검토한다.


<details>
  <summary>Details</summary>
Motivation: 생성 AI의 이해를 재정립하고자 하며, 그 개념을 단순한 콘텐츠의 직접적 합성에서 전문화된 프로세스의 emergent 구성으로 전환하려 한다.

Method: 모델 아키텍처에 대한 면밀한 분석과 층별 표현에 개입하는 타겟 실험 설정을 통해 연구를 진행한다.

Result: 확산 모델이 표현의 부담을 어떻게 분산하는지를 보여 주며, 통합된 내부 공간에 대한 가정을 도전한다.

Conclusion: 이 연구를 통해 생성 AI의 본질을 새로운 관점에서 조명한다.

Abstract: This paper examines the evolving nature of internal representations in
generative visual models, focusing on the conceptual and technical shift from
GANs and VAEs to diffusion-based architectures. Drawing on Beatrice Fazi's
account of synthesis as the amalgamation of distributed representations, we
propose a distinction between "synthesis in a strict sense", where a compact
latent space wholly determines the generative process, and "synthesis in a
broad sense," which characterizes models whose representational labor is
distributed across layers. Through close readings of model architectures and a
targeted experimental setup that intervenes in layerwise representations, we
show how diffusion models fragment the burden of representation and thereby
challenge assumptions of unified internal space. By situating these findings
within media theoretical frameworks and critically engaging with metaphors such
as the latent space and the Platonic Representation Hypothesis, we argue for a
reorientation of how generative AI is understood: not as a direct synthesis of
content, but as an emergent configuration of specialized processes.

</details>


### [100] [Finite-Time Bounds for Average-Reward Fitted Q-Iteration](https://arxiv.org/abs/2510.17391)
*Jongmin Lee,Ernest K. Ryu*

Main category: cs.LG

TL;DR: 이 연구는 약한 통신을 가진 MDP의 평균 보상 오프라인 강화 학습에서 샘플 복잡성 결과를 수립하고, 평균 보상 설정에서의 유한 시간 분석을 가능하게 하는 앵커 메커니즘을 도입한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 평균 보상 설정에 대한 연구는 상당히 부족하고, MDP의 에르고딕성 또는 선형성과 같은 제한적인 가정에 의존하고 있다.

Method: 표준 Fitted Q-Iteration과 앵커 메커니즘을 결합한 Anchored Fitted Q-Iteration을 도입하였다.

Result: 앵커 메커니즘이 평균 보상 설정에서 유한 시간 분석을 가능하게 하는 데 중요하다는 것을 보여주었다.

Conclusion: 단일 경로에서 생성된 데이터셋으로 구성된 설정으로 유한 시간 분석을 확장하였다.

Abstract: Although there is an extensive body of work characterizing the sample
complexity of discounted-return offline RL with function approximations, prior
work on the average-reward setting has received significantly less attention,
and existing approaches rely on restrictive assumptions, such as ergodicity or
linearity of the MDP. In this work, we establish the first sample complexity
results for average-reward offline RL with function approximation for weakly
communicating MDPs, a much milder assumption. To this end, we introduce
Anchored Fitted Q-Iteration, which combines the standard Fitted Q-Iteration
with an anchor mechanism. We show that the anchor, which can be interpreted as
a form of weight decay, is crucial for enabling finite-time analysis in the
average-reward setting. We also extend our finite-time analysis to the setup
where the dataset is generated from a single-trajectory rather than IID
transitions, again leveraging the anchor mechanism.

</details>


### [101] [RINS-T: Robust Implicit Neural Solvers for Time Series Linear Inverse Problems](https://arxiv.org/abs/2510.17396)
*Keivan Faghih Niresi,Zepeng Zhang,Olga Fink*

Main category: cs.LG

TL;DR: 본 논문에서는 시계열 데이터 복원 문제를 해결하기 위한 새로운 접근법인 RINS-T를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 시계열 데이터는 결측치, 노이즈, 이상치 등 여러 형태의 오염에 영향을 받으며, 이는 예측 및 이상 탐지와 같은 작업에 큰 도전을 준다.

Method: RINS-T는 사전 학습 데이터 없이 높은 복구 성능을 달성하는 새로운 딥 프라이어 프레임워크로, 신경망을 암묵적 사전으로 활용하고 강건 최적화 기법을 통합하여 이상치에 강인성을 제공한다.

Result: 이 연구에서 제안된 세 가지 주요 혁신은 최적화 안정성과 강건성을 향상시킨다.

Conclusion: RINS-T는 복잡한 실제 시계열 문제를 해결하는 유연하고 효과적인 솔루션을 제공한다.

Abstract: Time series data are often affected by various forms of corruption, such as
missing values, noise, and outliers, which pose significant challenges for
tasks such as forecasting and anomaly detection. To address these issues,
inverse problems focus on reconstructing the original signal from corrupted
data by leveraging prior knowledge about its underlying structure. While deep
learning methods have demonstrated potential in this domain, they often require
extensive pretraining and struggle to generalize under distribution shifts. In
this work, we propose RINS-T (Robust Implicit Neural Solvers for Time Series
Linear Inverse Problems), a novel deep prior framework that achieves high
recovery performance without requiring pretraining data. RINS-T leverages
neural networks as implicit priors and integrates robust optimization
techniques, making it resilient to outliers while relaxing the reliance on
Gaussian noise assumptions. To further improve optimization stability and
robustness, we introduce three key innovations: guided input initialization,
input perturbation, and convex output combination techniques. Each of these
contributions strengthens the framework's optimization stability and
robustness. These advancements make RINS-T a flexible and effective solution
for addressing complex real-world time series challenges. Our code is available
at https://github.com/EPFL-IMOS/RINS-T.

</details>


### [102] [S4ECG: Exploring the impact of long-range interactions for arrhythmia prediction](https://arxiv.org/abs/2510.17406)
*Tiezhi Wang,Wilhelm Haverkamp,Nils Strodthoff*

Main category: cs.LG

TL;DR: S4ECG는 다중 에포크 부정맥 분류를 위한 구조화된 상태 공간 모델을 활용한 새로운 딥러닝 아키텍처로, 기존의 단일 에포크 접근 방식보다 성능이 뛰어나다.


<details>
  <summary>Details</summary>
Motivation: 부정맥 탐지에서 시계열 생체신호의 동적 분석을 개선할 필요성이 있다.

Method: S4ECG 아키텍처는 다중 에포크에서의 동시 신호 해석을 통해 부정맥 분류를 수행한다.

Result: S4ECG는 매크로-AUROC에서 1.0-11.6% 개선된 성능을 보이며, 심방세동의 특이도가 0.718-0.979에서 0.967-0.998로 향상되었다.

Conclusion: 이 연구는 ECG 해석에 대한 새로운 가능성을 열어주며, 특히 심방세동 및 심방 flutter와 같은 복잡한 부정맥의 탐지 알고리즘에 기여한다.

Abstract: The electrocardiogram (ECG) exemplifies biosignal-based time series with
continuous, temporally ordered structure reflecting cardiac physiological and
pathophysiological dynamics. Detailed analysis of these dynamics has proven
challenging, as conventional methods capture either global trends or local
waveform features but rarely their simultaneous interplay at high temporal
resolution. To bridge global and local signal analysis, we introduce S4ECG, a
novel deep learning architecture leveraging structured state space models for
multi-epoch arrhythmia classification. Our joint multi-epoch predictions
significantly outperform single-epoch approaches by 1.0-11.6% in macro-AUROC,
with atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998,
demonstrating superior performance in-distribution and enhanced
out-of-distribution robustness. Systematic investigation reveals optimal
temporal dependency windows spanning 10-20 minutes for peak performance. This
work contributes to a paradigm shift toward temporally-aware arrhythmia
detection algorithms, opening new possibilities for ECG interpretation, in
particular for complex arrhythmias like atrial fibrillation and atrial flutter.

</details>


### [103] [A Conditional Diffusion Model for Probabilistic Prediction of Battery Capacity Degradation](https://arxiv.org/abs/2510.17414)
*Hequn Li,Zhongwei Deng,Chunlin Jiang,Yvxin He andZhansheng Ning*

Main category: cs.LG

TL;DR: 리튬 이온 배터리 용량의 정확한 예측은 신뢰할 수 있는 배터리 관리를 위해 필수적이지만 노화의 확률적 특성으로 인해 여전히 어려움이 있다. 본 논문에서는 이 문제를 해결하기 위해 특성 공학과 심층 학습을 통합한 새로운 방법인 조건 확산 U-Net 주의 모델(CDUA)을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 리튬 이온 배터리 용량 예측의 중요성과 도전 과제를 강조한다.

Method: CDUA 모델은 시계열 예측을 위한 확산 기반 생성 모델과 예측 성능 향상을 위한 주의 메커니즘을 통합한다. 차량 운영 데이터를 통해 배터리 용량을 도출하고, 피어슨 상관 계수 및 XGBoost 알고리즘을 사용하여 가장 관련성이 높은 특성을 식별한다.

Result: CDUA 모델은 실제 차량 데이터에 대한 실험에서 평균 절대 오차(MAE) 0.94%, 평균 제곱근 오차(RMSE) 1.14%의 상대 값을 얻었으며, 3.74%의 상대 폭을 가진 95% 신뢰 구간을 보인다.

Conclusion: CDUA는 정확한 용량 추정과 신뢰할 수 있는 불확실성 정량화를 제공하며, 기존 방법에 비해 우수한 성능과 강건성을 입증한다.

Abstract: Accurate prediction of lithium-ion battery capacity and its associated
uncertainty is essential for reliable battery management but remains
challenging due to the stochastic nature of aging. This paper presents a novel
method, termed the Condition Diffusion U-Net with Attention (CDUA), which
integrates feature engineering and deep learning to address this challenge. The
proposed approach employs a diffusion-based generative model for time-series
forecasting and incorporates attention mechanisms to enhance predictive
performance. Battery capacity is first derived from real-world vehicle
operation data. The most relevant features are then identified using the
Pearson correlation coefficient and the XGBoost algorithm. These features are
used to train the CDUA model, which comprises two core components: (1) a
contextual U-Net with self-attention to capture complex temporal dependencies,
and (2) a denoising network to reconstruct accurate capacity values from noisy
observations. Experimental validation on the real-world vehicle data
demonstrates that the proposed CDUA model achieves a relative Mean Absolute
Error (MAE) of 0.94% and a relative Root Mean Square Error (RMSE) of 1.14%,
with a narrow 95% confidence interval of 3.74% in relative width. These results
confirm that CDUA provides both accurate capacity estimation and reliable
uncertainty quantification. Comparative experiments further verify its
robustness and superior performance over existing mainstream approaches.

</details>


### [104] [Explainable AI for microseismic event detection](https://arxiv.org/abs/2510.17458)
*Ayrat Abdullin,Denis Anikiev,Umair bin Waheed*

Main category: cs.LG

TL;DR: 이 연구에서는 PhaseNet 모델의 결정 해석을 통해 신뢰성을 향상시키기 위해 설명 가능한 AI(XAI) 기술을 적용하였습니다.


<details>
  <summary>Details</summary>
Motivation: PhaseNet과 같은 딥 뉴럴 네트워크는 미세 지진 사건 탐지에서 높은 정확성을 보이나, 블랙박스 특성으로 인해 중요한 응용 전략에서 우려됩니다.

Method: Gradient-weighted Class Activation Mapping(Grad-CAM) 및 Shapley Additive Explanations(SHAP)와 같은 XAI 기술을 적용하여 PhaseNet 모델의 결정을 해석합니다.

Result: 9,000개의 파형 테스트 세트에서 SHAP-게이트 모델은 F1 스코어 0.98(정밀도 0.99, 재현율 0.97)를 달성하였으며, 기본 PhaseNet(F1 스코어 0.97)을 초과하고 노이즈에 대한 견고성을 향상시켰습니다.

Conclusion: 이러한 결과는 XAI가 딥 러닝 모델을 해석하는 것뿐만 아니라 성능을 직접 향상시킬 수 있음을 보여줍니다.

Abstract: Deep neural networks like PhaseNet show high accuracy in detecting
microseismic events, but their black-box nature is a concern in critical
applications. We apply explainable AI (XAI) techniques, such as
Gradient-weighted Class Activation Mapping (Grad-CAM) and Shapley Additive
Explanations (SHAP), to interpret the PhaseNet model's decisions and improve
its reliability. Grad-CAM highlights that the network's attention aligns with
P- and S-wave arrivals. SHAP values quantify feature contributions, confirming
that vertical-component amplitudes drive P-phase picks while horizontal
components dominate S-phase picks, consistent with geophysical principles.
Leveraging these insights, we introduce a SHAP-gated inference scheme that
combines the model's output with an explanation-based metric to reduce errors.
On a test set of 9,000 waveforms, the SHAP-gated model achieved an F1-score of
0.98 (precision 0.99, recall 0.97), outperforming the baseline PhaseNet
(F1-score 0.97) and demonstrating enhanced robustness to noise. These results
show that XAI can not only interpret deep learning models but also directly
enhance their performance, providing a template for building trust in automated
seismic detectors.

</details>


### [105] [Unified Privacy Guarantees for Decentralized Learning via Matrix Factorization](https://arxiv.org/abs/2510.17480)
*Aurélien Bellet,Edwige Cyffers,Davide Frey,Romaric Gaudel,Dimitri Lerévérend,François Taïani*

Main category: cs.LG

TL;DR: 탈중앙화 학습(DL)은 사용자들이 원시 데이터를 공유하지 않고도 협력적으로 모델을 훈련할 수 있도록 해줍니다. 이 논문에서는 행렬 분해(MF)를 기반으로 한 중앙 집중 DP 회계의 최근 발전을 DL에 적응하는 방법을 제안하며, 새로운 알고리즘 MAFALDA-SGD를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 탈중앙화 학습의 필요성과 그로 인한 사용자 데이터 통제 유지 및 확장성의 장점을 강조하기 위함입니다.

Method: 행렬 분해(MF)를 기반으로 한 중앙 집중 DP 회계의 최근 발전을 활용하여 기존의 DL 알고리즘과 신뢰 모델을 통합된 형식으로 변환하는 방법을 제안합니다.

Result: MAFALDA-SGD는 사용자 수준에서 관련된 노이즈를 사용하는 DL 알고리즘으로, 기존 방법들보다 더 우수한 성능을 보입니다.

Conclusion: 이 연구는 DP-DL 알고리즘의 프라이버시 회계를 강화하고 새로운 알고리즘 개발을 위한 원칙적인 방법을 제공합니다.

Abstract: Decentralized Learning (DL) enables users to collaboratively train models
without sharing raw data by iteratively averaging local updates with neighbors
in a network graph. This setting is increasingly popular for its scalability
and its ability to keep data local under user control. Strong privacy
guarantees in DL are typically achieved through Differential Privacy (DP), with
results showing that DL can even amplify privacy by disseminating noise across
peer-to-peer communications. Yet in practice, the observed privacy-utility
trade-off often appears worse than in centralized training, which may be due to
limitations in current DP accounting methods for DL. In this paper, we show
that recent advances in centralized DP accounting based on Matrix Factorization
(MF) for analyzing temporal noise correlations can also be leveraged in DL. By
generalizing existing MF results, we show how to cast both standard DL
algorithms and common trust models into a unified formulation. This yields
tighter privacy accounting for existing DP-DL algorithms and provides a
principled way to develop new ones. To demonstrate the approach, we introduce
MAFALDA-SGD, a gossip-based DL algorithm with user-level correlated noise that
outperforms existing methods on synthetic and real-world graphs.

</details>


### [106] [The Graphon Limit Hypothesis: Understanding Neural Network Pruning via Infinite Width Analysis](https://arxiv.org/abs/2510.17515)
*Hoang Pham,The-Anh Ta,Tom Jacobs,Rebekka Burkholz,Long Tran-Thanh*

Main category: cs.LG

TL;DR: 희소 신경망의 효율성을 보장하지만 효과적으로 훈련하는 것은 여전히 근본적인 도전 과제입니다. 이 논문은 그래프 한계 이론을 바탕으로 한 새로운 이론적 프레임워크를 제안하여 무한 너비의 희소 신경망을 특성화하고, 훈련 역학을 연구하기 위한 그래프온 신경 탄젠트 커널을 도출합니다.


<details>
  <summary>Details</summary>
Motivation: 희소 신경망의 훈련 성능 차이를 이해하는 것이 필요하다.

Method: 그래프 한계 이론, 특히 그래프온을 기반으로 한 새로운 이론적 프레임워크를 개발하고, 그래프온 신경 탄젠트 커널을 통해 희소 네트워크의 훈련 역학을 연구한다.

Result: 그래프온 NTK의 스펙트럼 분석이 희소 네트워크의 훈련 역학과 상관 관계가 있음을 보여준다.

Conclusion: 연결 패턴이 다양한 희소 네트워크 아키텍처의 훈련 가능성에 미치는 영향을 이론적으로 통찰한다.

Abstract: Sparse neural networks promise efficiency, yet training them effectively
remains a fundamental challenge. Despite advances in pruning methods that
create sparse architectures, understanding why some sparse structures are
better trainable than others with the same level of sparsity remains poorly
understood. Aiming to develop a systematic approach to this fundamental
problem, we propose a novel theoretical framework based on the theory of graph
limits, particularly graphons, that characterizes sparse neural networks in the
infinite-width regime. Our key insight is that connectivity patterns of sparse
neural networks induced by pruning methods converge to specific graphons as
networks' width tends to infinity, which encodes implicit structural biases of
different pruning methods. We postulate the Graphon Limit Hypothesis and
provide empirical evidence to support it. Leveraging this graphon
representation, we derive a Graphon Neural Tangent Kernel (Graphon NTK) to
study the training dynamics of sparse networks in the infinite width limit.
Graphon NTK provides a general framework for the theoretical analysis of sparse
networks. We empirically show that the spectral analysis of Graphon NTK
correlates with observed training dynamics of sparse networks, explaining the
varying convergence behaviours of different pruning methods. Our framework
provides theoretical insights into the impact of connectivity patterns on the
trainability of various sparse network architectures.

</details>


### [107] [CEPerFed: Communication-Efficient Personalized Federated Learning for Multi-Pulse MRI Classification](https://arxiv.org/abs/2510.17584)
*Ludi Li,Junbin Mao,Hanhe Lin,Xu Tian,Fang-Xiang Wu,Jin Liu*

Main category: cs.LG

TL;DR: CEPerFed는 다중 펄스 MRI 분류를 위한 통신 효율적인 개인화 연합 학습 방법이다.


<details>
  <summary>Details</summary>
Motivation: 개인정보 보호를 유지하면서 다양한 의료 기관의 큰 규모의 데이터로 다중 펄스 MRI 분류를 위한 강력한 모델을 훈련할 필요성이 있다.

Method: CEPerFed는 클라이언트 측의 과거 리스크 기울기와 과거 평균 기울기를 통합하여 데이터 이질성의 영향을 완화하고 지역 및 글로벌 최적화를 조정하는 방법을 제안한다.

Result: 다섯 가지 분류 작업에 대한 실험 결과, CEPerFed 방법의 효과가 입증되었다.

Conclusion: 모델 업데이트에 필요한 가장 중요한 정보만을 전송하는 계층적 SVD 전략을 통해 높은 통신 오버헤드를 해결하였다.

Abstract: Multi-pulse magnetic resonance imaging (MRI) is widely utilized for clinical
practice such as Alzheimer's disease diagnosis. To train a robust model for
multi-pulse MRI classification, it requires large and diverse data from various
medical institutions while protecting privacy by preventing raw data sharing
across institutions. Although federated learning (FL) is a feasible solution to
address this issue, it poses challenges of model convergence due to the effect
of data heterogeneity and substantial communication overhead due to large
numbers of parameters transmitted within the model. To address these
challenges, we propose CEPerFed, a communication-efficient personalized FL
method. It mitigates the effect of data heterogeneity by incorporating
client-side historical risk gradients and historical mean gradients to
coordinate local and global optimization. The former is used to weight the
contributions from other clients, enhancing the reliability of local updates,
while the latter enforces consistency between local updates and the global
optimization direction to ensure stable convergence across heterogeneous data
distributions. To address the high communication overhead, we propose a
hierarchical SVD (HSVD) strategy that transmits only the most critical
information required for model updates. Experiments on five classification
tasks demonstrate the effectiveness of the CEPerFed method. The code will be
released upon acceptance at https://github.com/LD0416/CEPerFed.

</details>


### [108] [ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data Augmentation for Robust Lung Ultrasound Classification](https://arxiv.org/abs/2510.17650)
*Athanasios Angelakis,Amne Mousa,Micah L. A. Heldeweg,Laurens A. Biesheuvel,Mark A. Haaksma,Jasper M. Smit,Pieter R. Tuinman,Paul W. G. Elbers*

Main category: cs.LG

TL;DR: ZACH-ViT라는 새로운 비전 트랜스포머 변형이 심장성 폐부종을 비심장성 폐부종과 구분하기 위해 개발되었다. 이 모델은 기존의 모델보다 성능이 뛰어나고 실시간 임상 배치에 적합하다.


<details>
  <summary>Details</summary>
Motivation: 심장성 폐부종을 비심장성 및 구조적으로 정상인 폐와 구별하는 것은 비심장성 염증 패턴의 높은 시각적 변동성 때문에 어렵다.

Method: ZACH-ViT는 0.25M 파라미터의 비전 트랜스포머 변형으로, 위치 인코딩과 [CLS] 토큰을 제거하여 약물 이미지 데이터에 적합하게 만든다. ShuffleStrides 데이터 증강(SSDA)을 통해 해부학적 유효성을 유지하면서 순서를 재배열한다.

Result: ZACH-ViT는 95명의 중증 환자에서 380개의 LUS 비디오로 평가되었고, ROC-AUC에서 최고의 성능(0.80 및 0.79)을 기록했으며, 균형 감도(0.60)와 특이도(0.91)를 달성하였다.

Conclusion: 이 결과는 작은 데이터 의료 이미지에서 데이터 구조와 아키텍처 설계를 맞추면 성능이 향상될 수 있음을 보여준다.

Abstract: Differentiating cardiogenic pulmonary oedema (CPE) from non-cardiogenic and
structurally normal lungs in lung ultrasound (LUS) videos remains challenging
due to the high visual variability of non-cardiogenic inflammatory patterns
(NCIP/ARDS-like), interstitial lung disease, and healthy lungs. This
heterogeneity complicates automated classification as overlapping B-lines and
pleural artefacts are common. We introduce ZACH-ViT (Zero-token Adaptive
Compact Hierarchical Vision Transformer), a 0.25 M-parameter Vision Transformer
variant that removes both positional embeddings and the [CLS] token, making it
fully permutation-invariant and suitable for unordered medical image data. To
enhance generalization, we propose ShuffleStrides Data Augmentation (SSDA),
which permutes probe-view sequences and frame orders while preserving
anatomical validity. ZACH-ViT was evaluated on 380 LUS videos from 95
critically ill patients against nine state-of-the-art baselines. Despite the
heterogeneity of the non-cardiogenic group, ZACH-ViT achieved the highest
validation and test ROC-AUC (0.80 and 0.79) with balanced sensitivity (0.60)
and specificity (0.91), while all competing models collapsed to trivial
classification. It trains 1.35x faster than Minimal ViT (0.62M parameters) with
2.5x fewer parameters, supporting real-time clinical deployment. These results
show that aligning architectural design with data structure can outperform
scale in small-data medical imaging.

</details>
