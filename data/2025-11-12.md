<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 28]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.MA](#cs.MA) [Total: 7]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [FlowNet: Modeling Dynamic Spatio-Temporal Systems via Flow Propagation](https://arxiv.org/abs/2511.05595)
*Yutong Feng,Xu Liu,Yutong Xia,Yuxuan Liang*

Main category: cs.LG

TL;DR: 본 논문에서는 복잡한 동적 시공간 시스템을 모델링하기 위해 흐름 매개 상호 의존성과 맥락 민감한 상호 작용 동역학을 포착하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 동적 시공간 시스템의 정확한 모델링을 위해서는 흐름 매개 상호 의존성과 맥락 민감한 상호 작용 동역학을 포착해야 합니다.

Method: 물리 기반의 Spatio-Temporal Flow 패러다임을 제안하며, 이를 통해 보존 원칙에 의해 지배되는 정량적 흐름 전송을 통해 동적 노드 결합을 명시적으로 모델링합니다.

Result: FlowNet은 세 가지 실제 시스템의 모델링에서 기존의 최첨단 접근 방식을 7개 지표에서 크게 초월함을 입증하였습니다.

Conclusion: 우리는 시공간 흐름 상호 작용을 통해 복잡한 시스템을 모델링하기 위한 원칙적인 방법론을 확립합니다.

Abstract: Accurately modeling complex dynamic spatio-temporal systems requires capturing flow-mediated interdependencies and context-sensitive interaction dynamics. Existing methods, predominantly graph-based or attention-driven, rely on similarity-driven connectivity assumptions, neglecting asymmetric flow exchanges that govern system evolution. We propose Spatio-Temporal Flow, a physics-inspired paradigm that explicitly models dynamic node couplings through quantifiable flow transfers governed by conservation principles. Building on this, we design FlowNet, a novel architecture leveraging flow tokens as information carriers to simulate source-to-destination transfers via Flow Allocation Modules, ensuring state redistribution aligns with conservation laws. FlowNet dynamically adjusts the interaction radius through an Adaptive Spatial Masking module, suppressing irrelevant noise while enabling context-aware propagation. A cascaded architecture enhances scalability and nonlinear representation capacity. Experiments demonstrate that FlowNet significantly outperforms existing state-of-the-art approaches on seven metrics in the modeling of three real-world systems, validating its efficiency and physical interpretability. We establish a principled methodology for modeling complex systems through spatio-temporal flow interactions.

</details>


### [2] [Blind Inverse Game Theory: Jointly Decoding Rewards and Rationality in Entropy-Regularized Competitive Games](https://arxiv.org/abs/2511.05640)
*Hamza Virk,Sandro Amaglobeli,Zuhayr Syed*

Main category: cs.LG

TL;DR: Blind-IGT는 보상 매개변수와 비율 파라미터를 관찰된 행동으로부터 동시에 복구하는 첫 번째 통계적 프레임워크를 제시하며, 이로 인해 발생하는 비선형 역문제에 대해 고유 식별을 위한 조건을 정립하고 최적 수렴 속도를 제공한다.


<details>
  <summary>Details</summary>
Motivation: IQT 방법은 경쟁 상황에서 유용하나 온도 파라미터 $τ$의 사전 지식이 필요하다는 한계가 있다.

Method: Blind-IGT 프레임워크를 도입하여 관찰된 행동에서 보상 파라미터 $θ$와 온도 파라미터 $τ$를 동시에 복구한다.

Result: 비선형 역문제의 고유 식별 조건을 정립하고, Normalized Least Squares(NLS) 추정량이 최적의 수렴 속도를 달성함을 입증하였다.

Conclusion: 전이 역학이 알려져 있지 않더라도 Markov 게임으로 프레임워크를 확장하고 강력한 경험 성능을 보여준다.

Abstract: Inverse Game Theory (IGT) methods based on the entropy-regularized Quantal Response Equilibrium (QRE) offer a tractable approach for competitive settings, but critically assume the agents' rationality parameter (temperature $τ$) is known a priori. When $τ$ is unknown, a fundamental scale ambiguity emerges that couples $τ$ with the reward parameters ($θ$), making them statistically unidentifiable. We introduce Blind-IGT, the first statistical framework to jointly recover both $θ$ and $τ$ from observed behavior. We analyze this bilinear inverse problem and establish necessary and sufficient conditions for unique identification by introducing a normalization constraint that resolves the scale ambiguity. We propose an efficient Normalized Least Squares (NLS) estimator and prove it achieves the optimal $\mathcal{O}(N^{-1/2})$ convergence rate for joint parameter recovery. When strong identifiability conditions fail, we provide partial identification guarantees through confidence set construction. We extend our framework to Markov games and demonstrate optimal convergence rates with strong empirical performance even when transition dynamics are unknown.

</details>


### [3] [Distributionally Robust Self Paced Curriculum Reinforcement Learning](https://arxiv.org/abs/2511.05694)
*Anirudh Satheesh,Keenan Powell,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: DR-SPCRL은 분포적 강인성 강화 학습의 한계를 극복하며, 에이전트의 진행 상황에 따라 강인성 예산을 동적으로 조정하여 성능과 강인성 간의 균형을 이룹니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습의 주요 문제는 통제된 환경에서 훈련된 정책이 실제 환경 배포 시 분포 변화에 대해 종종 실패한다는 점입니다.

Method: DR-SPCRL은 강인성 예산을 연속 커리큘럼으로 다루며, 에이전트의 진행에 따라 적응적으로 일정 조정합니다.

Result: 여러 환경에서의 실험 결과, DR-SPCRL은 훈련을 안정화하며 고정된 전략들과 비교하여 평균 11.8\% 에피소드 보상을 증가시켜 강인성-성능 균형을 개선했습니다.

Conclusion: DR-SPCRL은 기존의 정책보다 약 1.9배 향상된 성능을 달성했습니다.

Abstract: A central challenge in reinforcement learning is that policies trained in controlled environments often fail under distribution shifts at deployment into real-world environments. Distributionally Robust Reinforcement Learning (DRRL) addresses this by optimizing for worst-case performance within an uncertainty set defined by a robustness budget $ε$. However, fixing $ε$ results in a tradeoff between performance and robustness: small values yield high nominal performance but weak robustness, while large values can result in instability and overly conservative policies. We propose Distributionally Robust Self-Paced Curriculum Reinforcement Learning (DR-SPCRL), a method that overcomes this limitation by treating $ε$ as a continuous curriculum. DR-SPCRL adaptively schedules the robustness budget according to the agent's progress, enabling a balance between nominal and robust performance. Empirical results across multiple environments demonstrate that DR-SPCRL not only stabilizes training but also achieves a superior robustness-performance trade-off, yielding an average 11.8\% increase in episodic return under varying perturbations compared to fixed or heuristic scheduling strategies, and achieving approximately 1.9$\times$ the performance of the corresponding nominal RL algorithms.

</details>


### [4] [AI-assisted workflow enables rapid, high-fidelity breast cancer clinical trial eligibility prescreening](https://arxiv.org/abs/2511.05696)
*Jacob T. Rosenthal,Emma Hahesy,Sulov Chalise,Menglei Zhu,Mert R. Sabuncu,Lior Z. Braunstein,Anyi Li*

Main category: cs.LG

TL;DR: MSK-MATCH는 임상 문서에서 자동으로 환자의 임상 시험 적격성을 검토하는 AI 시스템으로, 98.6%의 정확도로 적격성을 분류합니다.


<details>
  <summary>Details</summary>
Motivation: 암 치료와 연구에서 임상 시험의 참여율이 낮기 때문에 적격성 스크리닝의 자동화가 필요하다.

Method: MSK-MATCH는 대규모 언어 모델과 큐레이션된 종양학 시험 지식 기반을 통합하여 AI 예측에 대한 설명을 제공합니다.

Result: MSK-MATCH는 731명의 환자로부터 88,518개의 임상 문서에서 61.9%의 사례를 자동으로 해결하고 38.1%를 인간 리뷰로 분류했습니다.

Conclusion: AI 지원 워크플로우는 환자 수준의 적격성 분류에서 98.6%의 정확도와 Screening 시간을 크게 단축시키는 데 성공했습니다.

Abstract: Clinical trials play an important role in cancer care and research, yet participation rates remain low. We developed MSK-MATCH (Memorial Sloan Kettering Multi-Agent Trial Coordination Hub), an AI system for automated eligibility screening from clinical text. MSK-MATCH integrates a large language model with a curated oncology trial knowledge base and retrieval-augmented architecture providing explanations for all AI predictions grounded in source text. In a retrospective dataset of 88,518 clinical documents from 731 patients across six breast cancer trials, MSK-MATCH automatically resolved 61.9% of cases and triaged 38.1% for human review. This AI-assisted workflow achieved 98.6% accuracy, 98.4% sensitivity, and 98.7% specificity for patient-level eligibility classification, matching or exceeding performance of the human-only and AI-only comparisons. For the triaged cases requiring manual review, prepopulating eligibility screens with AI-generated explanations reduced screening time from 20 minutes to 43 seconds at an average cost of $0.96 per patient-trial pair.

</details>


### [5] [Measuring Model Performance in the Presence of an Intervention](https://arxiv.org/abs/2511.05805)
*Winston Chen,Michael W. Sjoding,Jenna Wiens*

Main category: cs.LG

TL;DR: 본 연구에서는 치료군의 데이터를 재가중하여 개입이 없을 경우의 샘플 분포를 모방하는 편향 없는 모델 평가 접근법인 Nuisance Parameter Weighting (NPW)을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 사회적 영향에 대한 AI 응용 프로그램에서 개입의 존재가 평가에 편향을 줄 수 있다는 점에 주목하고 있습니다.

Method: 치료군과 대조군의 성능 추정치를 단순히 집계할 때 발생하는 추정 편향을 이론적으로 정량화하고, 이 편향이 잘못된 모델 선택으로 이어지는 조건을 유도합니다. 이를 바탕으로 NPW 방법을 제안합니다.

Result: 제안된 평가 접근법이 대조군의 데이터를 무시하는 표준 접근법보다 다양한 개입 효과와 샘플 크기 설정에서 일관되게 더 나은 모델 선택을 제공한다는 것을 증명합니다.

Conclusion: 우리의 기여는 실제 맥락에서 더 효율적인 모델 평가를 위한 의미 있는 단계입니다.

Abstract: AI models are often evaluated based on their ability to predict the outcome of interest. However, in many AI for social impact applications, the presence of an intervention that affects the outcome can bias the evaluation. Randomized controlled trials (RCTs) randomly assign interventions, allowing data from the control group to be used for unbiased model evaluation. However, this approach is inefficient because it ignores data from the treatment group. Given the complexity and cost often associated with RCTs, making the most use of the data is essential. Thus, we investigate model evaluation strategies that leverage all data from an RCT. First, we theoretically quantify the estimation bias that arises from naïvely aggregating performance estimates from treatment and control groups, and derive the condition under which this bias leads to incorrect model selection. Leveraging these theoretical insights, we propose nuisance parameter weighting (NPW), an unbiased model evaluation approach that reweights data from the treatment group to mimic the distributions of samples that would or would not experience the outcome under no intervention. Using synthetic and real-world datasets, we demonstrate that our proposed evaluation approach consistently yields better model selection than the standard approach, which ignores data from the treatment group, across various intervention effect and sample size settings. Our contribution represents a meaningful step towards more efficient model evaluation in real-world contexts.

</details>


### [6] [MOSS: Efficient and Accurate FP8 LLM Training with Microscaling and Automatic Scaling](https://arxiv.org/abs/2511.05811)
*Yu Zhang,Hui-Ling Zhen,Mingxuan Yuan,Bei Yu*

Main category: cs.LG

TL;DR: FP8 형식을 사용한 대규모 언어 모델 훈련은 효율성을 크게 향상시킵니다. 그러나 FP8의 감소된 수치 정밀도는 안정적이고 정확한 훈련에 도전과제를 제공합니다. 본 연구에서는 MOSS라는 새로운 FP8 훈련 프레임워크를 제안하여 효율성과 수치적 안정성을 보장합니다.


<details>
  <summary>Details</summary>
Motivation: FP8 형식을 사용한 훈련의 효율성을 높이기 위한 필요성이 있습니다.

Method: MOSS는 민감한 활성화에 대한 두 수준의 마이크로 스케일링 전략과 선형 레이어의 가중치에 대한 자동 스케일링을 도입합니다.

Result: MOSS는 7B 파라미터 모델의 효율적인 FP8 훈련을 가능하게 하여 BF16 기준과 비교해 34% 더 높은 훈련 처리량을 달성합니다.

Conclusion: MOSS는 FP8 훈련의 성능을 BF16 기준에 필적할 수 있게 합니다.

Abstract: Training large language models with FP8 formats offers significant efficiency gains. However, the reduced numerical precision of FP8 poses challenges for stable and accurate training. Current frameworks preserve training performance using mixed-granularity quantization, i.e., applying per-group quantization for activations and per-tensor/block quantization for weights. While effective, per-group quantization requires scaling along the inner dimension of matrix multiplication, introducing additional dequantization overhead. Moreover, these frameworks often rely on just-in-time scaling to dynamically adjust scaling factors based on the current data distribution. However, this online quantization is inefficient for FP8 training, as it involves multiple memory reads and writes that negate the performance benefits of FP8. To overcome these limitations, we propose MOSS, a novel FP8 training framework that ensures both efficiency and numerical stability. MOSS introduces two key innovations: (1) a two-level microscaling strategy for quantizing sensitive activations, which balances precision and dequantization cost by combining a high-precision global scale with compact, power-of-two local scales; and (2) automatic scaling for weights in linear layers, which eliminates the need for costly max-reduction operations by predicting and adjusting scaling factors during training. Leveraging these techniques, MOSS enables efficient FP8 training of a 7B parameter model, achieving performance comparable to the BF16 baseline while achieving up to 34% higher training throughput.

</details>


### [7] [EMOD: A Unified EEG Emotion Representation Framework Leveraging V-A Guided Contrastive Learning](https://arxiv.org/abs/2511.05863)
*Yuning Chen,Sha Zhao,Shijian Li,Gang Pan*

Main category: cs.LG

TL;DR: EEG 신호에서의 감정 인식을 위한 EMOD 프레임워크 제안.


<details>
  <summary>Details</summary>
Motivation: EEG 신호에서 감정을 인식하는 것은 감정 컴퓨팅에 필수적이나, 기존의 심층 학습 접근법이 데이터세트 간 일반화에 한계가 있다.

Method: EMOD는 V-A 가이드를 활용한 대조 학습을 통해 다양한 데이터세트에서 감정 인식을 위한 전이 가능하고 감정 인식이 가능한 표현을 학습한다.

Result: EMOD는 상태-of-아트 성능을 달성하였고, 다양한 EEG 기반 감정 인식 시나리오에서 뛰어난 적응력과 일반화를 보여준다.

Conclusion: EMOD는 EEG 감정 인식의 다양한 데이터 포맷을 처리하는 유연성을 제공한다.

Abstract: Emotion recognition from EEG signals is essential for affective computing and has been widely explored using deep learning. While recent deep learning approaches have achieved strong performance on single EEG emotion datasets, their generalization across datasets remains limited due to the heterogeneity in annotation schemes and data formats. Existing models typically require dataset-specific architectures tailored to input structure and lack semantic alignment across diverse emotion labels. To address these challenges, we propose EMOD: A Unified EEG Emotion Representation Framework Leveraging Valence-Arousal (V-A) Guided Contrastive Learning. EMOD learns transferable and emotion-aware representations from heterogeneous datasets by bridging both semantic and structural gaps. Specifically, we project discrete and continuous emotion labels into a unified V-A space and formulate a soft-weighted supervised contrastive loss that encourages emotionally similar samples to cluster in the latent space. To accommodate variable EEG formats, EMOD employs a flexible backbone comprising a Triple-Domain Encoder followed by a Spatial-Temporal Transformer, enabling robust extraction and integration of temporal, spectral, and spatial features. We pretrain EMOD on eight public EEG datasets and evaluate its performance on three benchmark datasets. Experimental results show that EMOD achieves state-of-the-art performance, demonstrating strong adaptability and generalization across diverse EEG-based emotion recognition scenarios.

</details>


### [8] [Coupling Agent-based Modeling and Life Cycle Assessment to Analyze Trade-offs in Resilient Energy Transitions](https://arxiv.org/abs/2511.06791)
*Beichen Zhang,Mohammed T. Zaki,Hanna Breunig,Newsha K. Ajami*

Main category: cs.LG

TL;DR: 지속 가능하고 회복력 있는 에너지 시스템으로의 전환은 환경, 사회 및 자원 차원에서 복잡하고 상호 의존적인 절충안을 탐색해야 한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 평가 방법은 에너지 전환 경로와 그 영향들을 개별적으로 평가하며, 지역 자원 경쟁 및 누적 영향과 같은 중요한 상호작용을 간과한다.

Method: 대리인 기반 모델링과 생애 주기 평가(LCA)를 결합한 통합 모델링 프레임워크를 제시하여 전환 경로가 지역 자원 경쟁, 생태적 제약 및 지역 사회의 부담과 어떻게 상호작용하는지를 시뮬레이션한다.

Result: Southern California에서 사례 연구를 적용한 결과, 통합된 다중 규모 의사 결정이 에너지 경로 배치에 어떤 영향을 미치고, 시나리오 기반 제약 아래에서 공간적으로 명확한 절충안을 드러내는지를 보여준다.

Conclusion: 이 모델링 프레임워크는 공간적 및 제도적 규모에서 보다 적응적이고 회복력 있는 에너지 전환 계획을 지원할 수 있다.

Abstract: Transitioning to sustainable and resilient energy systems requires navigating complex and interdependent trade-offs across environmental, social, and resource dimensions. Neglecting these trade-offs can lead to unintended consequences across sectors. However, existing assessments often evaluate emerging energy pathways and their impacts in silos, overlooking critical interactions such as regional resource competition and cumulative impacts. We present an integrated modeling framework that couples agent-based modeling and Life Cycle Assessment (LCA) to simulate how energy transition pathways interact with regional resource competition, ecological constraints, and community-level burdens. We apply the model to a case study in Southern California. The results demonstrate how integrated and multiscale decision making can shape energy pathway deployment and reveal spatially explicit trade-offs under scenario-driven constraints. This modeling framework can further support more adaptive and resilient energy transition planning on spatial and institutional scales.

</details>


### [9] [Bespoke Co-processor for Energy-Efficient Health Monitoring on RISC-V-based Flexible Wearables](https://arxiv.org/abs/2511.05985)
*Theofanis Vergos,Polykarpos Vergos,Mehdi B. Tahoori,Georgios Zervakis*

Main category: cs.LG

TL;DR: 이 논문은 에너지 효율성과 지연 시간을 최적화하는 기계적으로 유연한 RISC-V 시스템을 제안하며, 헬스케어 웨어러블을 위한 새로운 접근 방식을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 헬스케어 웨어러블 장치에서의 머신러닝 분류는 제한된 게이트 수, 큰 특징 크기, 높은 정적 전력 소모로 인해 도전적입니다. 기존 bendable RISC-V 시스템은 에너지 효율성이 부족합니다.

Method: 기계적으로 유연한 RISC-V를 제시하고, 고정 계수를 가진 맞춤형 곱셈-적분 보조 프로세서를 통합하여 에너지 효율성을 극대화하고 지연 시간을 최소화합니다. 제약 프로그래밍 문제를 제정하여 보조 프로세서 상수를 결정하고 Multi-Layer Perceptron(MLP) 추론 작업을 최적화하여 컴팩트한 모델-specific 하드웨어를 가능하게 합니다.

Result: 여러 헬스케어 데이터 세트에서 거의 실시간 성능을 보이며, 기존의 유연한 배터리 전력 예산 내에서 작동하고, 2.42 mm^2만 차지하는 결과를 보여줍니다. 우리의 마이크로프로세서는 최신 기술에 비해 평균 2.35배 속도 개선과 2.15배 낮은 에너지 소모를 달성합니다.

Conclusion: 이 연구는 접근 가능하고 지속 가능하며 유연한 헬스케어 웨어러블을 위한 유망한 경로를 제공합니다.

Abstract: Flexible electronics offer unique advantages for conformable, lightweight, and disposable healthcare wearables. However, their limited gate count, large feature sizes, and high static power consumption make on-body machine learning classification highly challenging. While existing bendable RISC-V systems provide compact solutions, they lack the energy efficiency required. We present a mechanically flexible RISC-V that integrates a bespoke multiply-accumulate co-processor with fixed coefficients to maximize energy efficiency and minimize latency. Our approach formulates a constrained programming problem to jointly determine co-processor constants and optimally map Multi-Layer Perceptron (MLP) inference operations, enabling compact, model-specific hardware by leveraging the low fabrication and non-recurring engineering costs of flexible technologies. Post-layout results demonstrate near-real-time performance across several healthcare datasets, with our circuits operating within the power budget of existing flexible batteries and occupying only 2.42 mm^2, offering a promising path toward accessible, sustainable, and conformable healthcare wearables. Our microprocessors achieve an average 2.35x speedup and 2.15x lower energy consumption compared to the state of the art.

</details>


### [10] [Physics-Informed Design of Input Convex Neural Networks for Consistency Optimal Transport Flow Matching](https://arxiv.org/abs/2511.06042)
*Fanghui Song,Zhongjian Wang,Jiebao Sun*

Main category: cs.LG

TL;DR: 이 논문은 최적 수송 흐름에 기반한 일관성 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 최적 수송 흐름을 기반으로 한 일관성 모델의 필요성.

Method: 부분 입력 볼록 신경망(PICNN)을 이용한 흐름 필드 구축과 해밀턴-자코비(HJ) 잔차를 활용한 훈련 방법.

Result: 단일 단계 및 다단계 ODE 샘플링 지원과 성능 검증.

Conclusion: 이 모델은 기존 방법과 달리 내부 최적화 하위 문제를 피하며, 표준 OT 벤치마크에서 확장성과 성능이 검증됩니다.

Abstract: We propose a consistency model based on the optimal-transport flow. A physics-informed design of partially input-convex neural networks (PICNN) plays a central role in constructing the flow field that emulates the displacement interpolation. During the training stage, we couple the Hamilton-Jacobi (HJ) residual in the OT formulation with the original flow matching loss function. Our approach avoids inner optimization subproblems that are present in previous one-step OFM approaches. During the prediction stage, our approach supports both one-step (Brenier-map) and multi-step ODE sampling from the same learned potential, leveraging the straightness of the OT flow. We validate scalability and performance on standard OT benchmarks.

</details>


### [11] [Approximating Shapley Explanations in Reinforcement Learning](https://arxiv.org/abs/2511.06094)
*Daniel Beechey,Özgür Şimşek*

Main category: cs.LG

TL;DR: FastSVERL은 강화 학습의 해석 가능성을 높이기 위한 확장 가능한 방법이다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습의 투명성이 부족하여 안전이 중요한 환경에서의 활용이 제한된다.

Method: Shapley 값을 근사하여 강화 학습을 설명하는 확장 가능한 방법인 FastSVERL을 소개한다.

Result: FastSVERL은 강화 학습의 고유한 도전 과제를 처리할 수 있도록 설계되었다.

Conclusion: FastSVERL은 강화 학습에서 원칙적이고 철저한 해석 가능성을 제공하는 실용적인 방법이다.

Abstract: Reinforcement learning has achieved remarkable success in complex decision-making environments, yet its lack of transparency limits its deployment in practice, especially in safety-critical settings. Shapley values from cooperative game theory provide a principled framework for explaining reinforcement learning; however, the computational cost of Shapley explanations is an obstacle to their use. We introduce FastSVERL, a scalable method for explaining reinforcement learning by approximating Shapley values. FastSVERL is designed to handle the unique challenges of reinforcement learning, including temporal dependencies across multi-step trajectories, learning from off-policy data, and adapting to evolving agent behaviours in real time. FastSVERL introduces a practical, scalable approach for principled and rigorous interpretability in reinforcement learning.

</details>


### [12] [Adapting Web Agents with Synthetic Supervision](https://arxiv.org/abs/2511.06101)
*Zhaoyang Wang,Yiming Liang,Xuchao Zhang,Qianhui Wu,Siwei Han,Anson Bastos,Rujia Wang,Chetan Bansal,Baolin Peng,Jianfeng Gao,Saravan Rajmohan,Huaxiu Yao*

Main category: cs.LG

TL;DR: SynthAgent는 웹 에이전트가 새로운 웹사이트에 적응하는 데 필요한 고품질 합성 데이터를 생성하기 위한 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 웹 에이전트는 환경 특화 작업과 시연이 부족하여 새로운 웹사이트에 적응하는 데 어려움을 겪습니다.

Method: 우리는 SynthAgent라는 완전 합성 감독 프레임워크를 제안합니다. 이 프레임워크는 웹 요소의 분류 탐험을 통해 다양한 작업을 합성하고, 실제 관찰과의 충돌을 감지하여 작업을 정제합니다.

Result: 실험 결과, SynthAgent는 기존의 합성 데이터 방법을 능가하며, 고품질 합성 감독의 중요성을 입증합니다.

Conclusion: 우리는 정제된 합성 데이터로 오픈 소스 웹 에이전트를 미세 조정하여 목표 환경에 적응시킵니다.

Abstract: Web agents struggle to adapt to new websites due to the scarcity of environment specific tasks and demonstrations. Recent works have explored synthetic data generation to address this challenge, however, they suffer from data quality issues where synthesized tasks contain hallucinations that cannot be executed, and collected trajectories are noisy with redundant or misaligned actions. In this paper, we propose SynthAgent, a fully synthetic supervision framework that aims at improving synthetic data quality via dual refinement of both tasks and trajectories. Our approach begins by synthesizing diverse tasks through categorized exploration of web elements, ensuring efficient coverage of the target environment. During trajectory collection, we refine tasks when conflicts with actual observations are detected, mitigating hallucinations while maintaining task consistency. After collection, we conduct trajectory refinement with a global context to mitigate potential noise or misalignments. Finally, we fine-tune open-source web agents on the refined synthetic data to adapt them to the target environment. Experimental results demonstrate that SynthAgent outperforms existing synthetic data methods, validating the importance of high-quality synthetic supervision. The code will be publicly available at https://github.com/aiming-lab/SynthAgent.

</details>


### [13] [LLM Attention Transplant for Transfer Learning of Tabular Data Across Disparate Domains](https://arxiv.org/abs/2511.06161)
*Ibna Kowsar,Kazi F. Akhter,Manar D. Samad*

Main category: cs.LG

TL;DR: 이 연구는 이종 도메인 간의 특징 공간의 이질성 문제를 해결하기 위한 가벼운 전이 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전이 학습에서의 제한된 성공으로 인해 LLM을 활용한 새로운 접근이 필요하다.

Method: 소스 테이블 데이터를 사용하여 LLM을 미세 조정하고, 선택적인 키 및 값 프로젝션 가중치를 gFTT에 이식하는 방법을 사용한다.

Result: 제안된 방법이 기존 ML 모델 및 깊은 테이블 구조를 초월하여 성능이 우수함을 실험을 통해 입증하였다.

Conclusion: 제안된 주의 전이는 적은 자원으로 학습하는 환경에서 데이터 테이블 간 관계를 학습하는 효과적인 솔루션을 제공한다.

Abstract: Transfer learning of tabular data is non-trivial due to heterogeneity in the feature space across disparate domains. The limited success of traditional deep learning in tabular knowledge transfer can be advanced by leveraging large language models (LLMs). However, the efficacy of LLMs often stagnates for mixed data types structured in tables due to the limitations of text prompts and in-context learning. We propose a lightweight transfer learning framework that fine-tunes an LLM using source tabular data and transplants the LLM's selective $key$ and $value$ projection weights into a gated feature tokenized transformer (gFTT) built for tabular data. The gFTT model with cross-domain attention is fine-tuned using target tabular data for transfer learning, eliminating the need for shared features, LLM prompt engineering, and large-scale pretrained models. Our experiments using ten pairs of source-target data sets and 12 baselines demonstrate the superiority of the proposed LLM-attention transplant for transfer learning (LATTLE) method over traditional ML models, state-of-the-art deep tabular architectures, and transfer learning models trained on thousands to billions of tabular samples. The proposed attention transfer demonstrates an effective solution to learning relationships between data tables using an LLM in a low-resource learning environment. The source code for the proposed method is publicly available.

</details>


### [14] [Resilience Inference for Supply Chains with Hypergraph Neural Network](https://arxiv.org/abs/2511.06208)
*Zetian Shen,Hongjun Wang,Jiyuan Chen,Xuan Song*

Main category: cs.LG

TL;DR: 본 연구는 공급망 회복력 추정(SCRI) 문제를 정의하고, 이를 해결하기 위한 SC-RIHN 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 공급망은 글로벌 경제 안정에 필수적이며, 중단은 네트워크를 통해 빠르게 확산되어 경제적 영향을 미칠 수 있습니다. 따라서 공급망 회복력을 정확하고 신속하게 추정하는 것이 중요합니다.

Method: 이 논문에서는 하이퍼그래프 토폴로지와 관찰된 재고 궤적을 사용하여 명시적인 동적 방정식 없이 공급망 회복력을 예측하는 문제(SCRI)를 정의하고, 이를 해결하기 위해 SC-RIHN 모델을 제안합니다.

Result: SC-RIHN은 전통적인 다층 퍼셉트론(MLP), 그래프 신경망 변형 및 ResInf 기준선에 비해 합성 벤치마크에서 훨씬 우수한 성능을 보입니다.

Conclusion: SC-RIHN은 복잡한 공급망 시스템에서 실용적인 조기 경고 위험 평가에 대한 잠재력을 강조합니다.

Abstract: Supply chains are integral to global economic stability, yet disruptions can swiftly propagate through interconnected networks, resulting in substantial economic impacts. Accurate and timely inference of supply chain resilience the capability to maintain core functions during disruptions is crucial for proactive risk mitigation and robust network design. However, existing approaches lack effective mechanisms to infer supply chain resilience without explicit system dynamics and struggle to represent the higher-order, multi-entity dependencies inherent in supply chain networks. These limitations motivate the definition of a novel problem and the development of targeted modeling solutions. To address these challenges, we formalize a novel problem: Supply Chain Resilience Inference (SCRI), defined as predicting supply chain resilience using hypergraph topology and observed inventory trajectories without explicit dynamic equations. To solve this problem, we propose the Supply Chain Resilience Inference Hypergraph Network (SC-RIHN), a novel hypergraph-based model leveraging set-based encoding and hypergraph message passing to capture multi-party firm-product interactions. Comprehensive experiments demonstrate that SC-RIHN significantly outperforms traditional MLP, representative graph neural network variants, and ResInf baselines across synthetic benchmarks, underscoring its potential for practical, early-warning risk assessment in complex supply chain systems.

</details>


### [15] [Deep Reinforcement Learning for Dynamic Origin-Destination Matrix Estimation in Microscopic Traffic Simulations Considering Credit Assignment](https://arxiv.org/abs/2511.06229)
*Donggyu Min,Seongjin Choi,Dong-Kyu Kim*

Main category: cs.LG

TL;DR: 본 논문은 미시적인 교통 시뮬레이션의 효과적인 적용을 위한 동적 기원-목적지 행렬 추정(DODE)을 다룬다.


<details>
  <summary>Details</summary>
Motivation: DODE 문제의 복잡한 시간적 동역학과 개별 차량 동역학의 불확실성 때문에 정확한 차량 이동 경로를 결정하는 것이 어렵다.

Method: DODE 문제를 마르코프 결정 프로세스(MDP)로 형성하고 모델 프리 심층 강화 학습(DRL)을 적용하는 새로운 프레임워크를 제안한다.

Result: 제안된 방법은 30분 동안의 5분 간격으로 수집된 실제 링크 흐름과 비교하여 평균 제곱 오차(MSE)를 43.2% 줄였다.

Conclusion: DODE를 순차적 의사결정 문제로 재구성함으로써 전통적인 방법의 한계를 극복하고 미시적 교통 시뮬레이션 보정을 위한 새로운 프레임워크를 제안한다.

Abstract: This paper focuses on dynamic origin-destination matrix estimation (DODE), a crucial calibration process necessary for the effective application of microscopic traffic simulations. The fundamental challenge of the DODE problem in microscopic simulations stems from the complex temporal dynamics and inherent uncertainty of individual vehicle dynamics. This makes it highly challenging to precisely determine which vehicle traverses which link at any given moment, resulting in intricate and often ambiguous relationships between origin-destination (OD) matrices and their contributions to resultant link flows. This phenomenon constitutes the credit assignment problem, a central challenge addressed in this study. We formulate the DODE problem as a Markov Decision Process (MDP) and propose a novel framework that applies model-free deep reinforcement learning (DRL). Within our proposed framework, the agent learns an optimal policy to sequentially generate OD matrices, refining its strategy through direct interaction with the simulation environment. The proposed method is validated on the Nguyen-Dupuis network using SUMO, where its performance is evaluated against ground-truth link flows aggregated at 5-minute intervals over a 30-minute horizon. Experimental results demonstrate that our approach achieves a 43.2% reduction in mean squared error (MSE) compared to the best-performing conventional baseline. By reframing DODE as a sequential decision-making problem, our approach addresses the credit assignment challenge through its learned policy, thereby overcoming the limitations of conventional methods and proposing a novel framework for calibration of microscopic traffic simulations.

</details>


### [16] [FLEX: Continuous Agent Evolution via Forward Learning from Experience](https://arxiv.org/abs/2511.06449)
*Zhicheng Cai,Xinyuan Guo,Yu Pei,JiangTao Feng,Jiangjie Chen,Ya-Qin Zhang,Wei-Ying Ma,Mingxuan Wang,Hao Zhou*

Main category: cs.LG

TL;DR: FLEX는 LLM 에이전트가 경험을 통해 지속적으로 진화할 수 있게 하는 새로운 학습 패러다임입니다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 자율 에이전트는 훈련 후 정적이며, 배포 중 경험과 함께 성장할 수 없습니다.

Method: FLEX는 성공과 실패에 대한 지속적인 반성을 통해 구조화된 경험 라이브러리를 구축하여 확장 가능하고 유전 가능한 진화를 촉진하는 기법입니다.

Result: FLEX는 수학적 추론, 화학적 퇴행합성 및 단백질 적합성 예측에서 각각 23%, 10%, 14%의 상당한 개선을 보여주었습니다.

Conclusion: FLEX는 경험 성장의 명확한 스케일링 법칙과 에이전트 간의 경험 상속 현상을 확인하여 연속적인 에이전트 진화에 기여합니다.

Abstract: Autonomous agents driven by Large Language Models (LLMs) have revolutionized reasoning and problem-solving but remain static after training, unable to grow with experience as intelligent beings do during deployment. We introduce Forward Learning with EXperience (FLEX), a gradient-free learning paradigm that enables LLM agents to continuously evolve through accumulated experience. Specifically, FLEX cultivates scalable and inheritable evolution by constructing a structured experience library through continual reflection on successes and failures during interaction with the environment. FLEX delivers substantial improvements on mathematical reasoning, chemical retrosynthesis, and protein fitness prediction (up to 23% on AIME25, 10% on USPTO50k, and 14% on ProteinGym). We further identify a clear scaling law of experiential growth and the phenomenon of experience inheritance across agents, marking a step toward scalable and inheritable continuous agent evolution. Project Page: https://flex-gensi-thuair.github.io.

</details>


### [17] [MULTIBENCH++: A Unified and Comprehensive Multimodal Fusion Benchmarking Across Specialized Domains](https://arxiv.org/abs/2511.06452)
*Leyan Xue,Zongbo Han,Kecheng Xue,Xiaohong Liu,Guangyu Wang,Changqing Zhang*

Main category: cs.LG

TL;DR: 이 논문은 멀티모달 융합의 평가 기준 부족 문제를 해결하기 위해 30개 이상의 데이터 세트를 통합한 대규모 도메인 적응 벤치마크와 자동화된 평가 파이프라인을 개발했다고 발표합니다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 융합의 발전은 적절한 평가 기준 부족에 의해 심각하게 저해받고 있습니다.

Method: 30개 이상의 데이터 세트를 통합하여 15가지 모달리티와 20가지 예측 작업을 포함하는 대규모 도메인 적응 벤치마크와 표준화된 최신 모델 구현 및 다양한 융합 패러다임을 포함하는 자동화된 평가 파이프라인을 개발했습니다.

Result: 대규모 실험을 통해 여러 작업에서 새로운 성능 기준을 성공적으로 설정했습니다.

Conclusion: 이 연구는 멀티모달 모델을 엄격하고 재현 가능한 방식으로 평가할 수 있는 중요한 플랫폼을 제공하여 멀티모달 인공지능 분야를 새로운 차원으로 발전시키는 것을 목표로 합니다.

Abstract: Although multimodal fusion has made significant progress, its advancement is severely hindered by the lack of adequate evaluation benchmarks. Current fusion methods are typically evaluated on a small selection of public datasets, a limited scope that inadequately represents the complexity and diversity of real-world scenarios, potentially leading to biased evaluations. This issue presents a twofold challenge. On one hand, models may overfit to the biases of specific datasets, hindering their generalization to broader practical applications. On the other hand, the absence of a unified evaluation standard makes fair and objective comparisons between different fusion methods difficult. Consequently, a truly universal and high-performance fusion model has yet to emerge. To address these challenges, we have developed a large-scale, domain-adaptive benchmark for multimodal evaluation. This benchmark integrates over 30 datasets, encompassing 15 modalities and 20 predictive tasks across key application domains. To complement this, we have also developed an open-source, unified, and automated evaluation pipeline that includes standardized implementations of state-of-the-art models and diverse fusion paradigms. Leveraging this platform, we have conducted large-scale experiments, successfully establishing new performance baselines across multiple tasks. This work provides the academic community with a crucial platform for rigorous and reproducible assessment of multimodal models, aiming to propel the field of multimodal artificial intelligence to new heights.

</details>


### [18] [Efficient Approximation of Volterra Series for High-Dimensional Systems](https://arxiv.org/abs/2511.06527)
*Navin Khoshnan,Claudia K Petritsch,Bryce-Allen Bagley*

Main category: cs.LG

TL;DR: 이 논문은 고차원 비선형 동적 시스템을 식별하는 새로운 알고리즘인 Tensor Head Averaging (THA)을 소개하며, 이를 통해 복잡도를 크게 줄이고, 기존의 MVMALS 모델보다 더 높은 정확도를 달성할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 고차원 비선형 동적 시스템의 식별은 큰 잠재력을 지니지만, 차원의 저주로 인해 심각한 제약을 받아왔다.

Method: Tensor Head Averaging (THA) 알고리즘을 도입하여, 입력 공간의 작은 하위 집합에 대해 훈련된 다수의 국소 MVMALS 모델의 앙상블을 구성함으로써 복잡도를 줄인다.

Result: THA 알고리즘의 이론적 기초를 제공하고, THA 앙상블과 전체 MVMALS 모델 간의 오류에 대한 관찰 가능한 유한 샘플 경계를 설정했다.

Conclusion: THA는 이전에 처리할 수 없었던 고차원 시스템을 식별하기 위한 확장 가능하고 이론적으로 근거 있는 접근 방식을 제공한다.

Abstract: The identification of high-dimensional nonlinear dynamical systems via the Volterra series has significant potential, but has been severely hindered by the curse of dimensionality. Tensor Network (TN) methods such as the Modified Alternating Linear Scheme (MVMALS) have been a breakthrough for the field, offering a tractable approach by exploiting the low-rank structure in Volterra kernels. However, these techniques still encounter prohibitive computational and memory bottlenecks due to high-order polynomial scaling with respect to input dimension. To overcome this barrier, we introduce the Tensor Head Averaging (THA) algorithm, which significantly reduces complexity by constructing an ensemble of localized MVMALS models trained on small subsets of the input space. In this paper, we present a theoretical foundation for the THA algorithm. We establish observable, finite-sample bounds on the error between the THA ensemble and a full MVMALS model, and we derive an exact decomposition of the squared error. This decomposition is used to analyze the manner in which subset models implicitly compensate for omitted dynamics. We quantify this effect, and prove that correlation between the included and omitted dynamics creates an optimization incentive which drives THA's performance toward accuracy superior to a simple truncation of a full MVMALS model. THA thus offers a scalable and theoretically grounded approach for identifying previously intractable high-dimensional systems.

</details>


### [19] [Optimistic Online-to-Batch Conversions for Accelerated Convergence and Universality](https://arxiv.org/abs/2511.06597)
*Yu-Hu Yan,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 이 연구에서는 매끄러운 목표를 가진 오프라인 볼록 최적화에 대해 연구하며, 전통적인 Nesterov의 가속 경량화(NAG) 방법이 최적의 가속 수렴을 달성한다.


<details>
  <summary>Details</summary>
Motivation: NAG에 대한 다양한 관점을 이해하기 위한 연구가 필요하다.

Method: 낙관적인 온라인에서 배치로의 전환을 제안하여 분석에 이론적으로 낙관성을 통합한다.

Result: 단순 온라인 경량하강법과 결합할 때 우리의 낙관적 전환이 최적의 가속 수렴을 달성함을 입증하며, 강한 볼록 목표에서도 적용 가능하다.

Conclusion: NAG와의 정밀한 대응으로 낙관적인 온라인에서 배치로의 전환의 효과를 강조한다.

Abstract: In this work, we study offline convex optimization with smooth objectives, where the classical Nesterov's Accelerated Gradient (NAG) method achieves the optimal accelerated convergence. Extensive research has aimed to understand NAG from various perspectives, and a recent line of work approaches this from the viewpoint of online learning and online-to-batch conversion, emphasizing the role of optimistic online algorithms for acceleration. In this work, we contribute to this perspective by proposing novel optimistic online-to-batch conversions that incorporate optimism theoretically into the analysis, thereby significantly simplifying the online algorithm design while preserving the optimal convergence rates. Specifically, we demonstrate the effectiveness of our conversions through the following results: (i) when combined with simple online gradient descent, our optimistic conversion achieves the optimal accelerated convergence; (ii) our conversion also applies to strongly convex objectives, and by leveraging both optimistic online-to-batch conversion and optimistic online algorithms, we achieve the optimal accelerated convergence rate for strongly convex and smooth objectives, for the first time through the lens of online-to-batch conversion; (iii) our optimistic conversion can achieve universality to smoothness -- applicable to both smooth and non-smooth objectives without requiring knowledge of the smoothness coefficient -- and remains efficient as non-universal methods by using only one gradient query in each iteration. Finally, we highlight the effectiveness of our optimistic online-to-batch conversions by a precise correspondence with NAG.

</details>


### [20] [An Adaptive Machine Learning Triage Framework for Predicting Alzheimer's Disease Progression](https://arxiv.org/abs/2511.06681)
*Richard Hou,Shengpu Tang,Wei Jin*

Main category: cs.LG

TL;DR: 이 연구는 경도 인지 장애(MCI)에서 알츠하이머 병(AD)으로의 전환 예측을 위한 비용 효율적인 머신 러닝 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 정확한 전환 예측은 효과적인 맞춤형 치료를 가능하게 하지만, PET 스캔과 CSF 바이오마커 분석은 비싸서 모든 환자에게 적용하기 어려움.

Method: 두 단계의 머신 러닝 프레임워크를 설계하여, 예측된 '정보 가치'에 따라 선택적으로 고급 특징을 얻음.

Result: ADNI 데이터를 사용하여 MCI 환자의 AD 진행 예측 결과, 고급 검사 필요성을 20% 줄이면서 AUROC 0.929를 달성.

Conclusion: 우리의 연구는 AD 진단 경로를 최적화하고 정확성과 비용의 균형을 이루는 해석 가능한 데이터 기반 프레임워크를 제시하며, 실제 임상에서 조기 신뢰할 수 있는 AD 예측을 더 접근 가능하게 만듭니다. 향후 연구는 복수의 고급 특징 카테고리 및 대규모 검증을 고려해야 함.

Abstract: Accurate predictions of conversion from mild cognitive impairment (MCI) to Alzheimer's disease (AD) can enable effective personalized therapy. While cognitive tests and clinical data are routinely collected, they lack the predictive power of PET scans and CSF biomarker analysis, which are prohibitively expensive to obtain for every patient. To address this cost-accuracy dilemma, we design a two-stage machine learning framework that selectively obtains advanced, costly features based on their predicted "value of information". We apply our framework to predict AD progression for MCI patients using data from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Our framework reduces the need for advanced testing by 20% while achieving a test AUROC of 0.929, comparable to the model that uses both basic and advanced features (AUROC=0.915, p=0.1010). We also provide an example interpretability analysis showing how one may explain the triage decision. Our work presents an interpretable, data-driven framework that optimizes AD diagnostic pathways and balances accuracy with cost, representing a step towards making early, reliable AD prediction more accessible in real-world practice. Future work should consider multiple categories of advanced features and larger-scale validation.

</details>


### [21] [Implicit Federated In-context Learning For Task-Specific LLM Fine-Tuning](https://arxiv.org/abs/2511.06757)
*Dongcheng Li,Junhan Chen,Aoxiang Zhou,Chunpei Li,Youquan Xian,Peng Liu,Xianxian Li*

Main category: cs.LG

TL;DR: IFed-ICL 프레임워크는 분산 협업 컴퓨테이션을 통해 모델 성능을 향상시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 성능 향상을 위해 조직 내의 개인 데이터를 활용하는 것이 주요 도전 과제가 되었다.

Method: IFed-ICL 프레임워크는 클라이언트의 로컬 컨텍스트 예제를 암묵적 벡터 표현으로 변환하여 분산 협업 컴퓨테이션을 가능하게 한다.

Result: 제안된 방법은 여러 텍스트 분류 작업에서 뛰어난 성능을 보여준다.

Conclusion: 전통적인 방법에 비해 IFed-ICL은 파라미터 업데이트를 줄이고, 데이터 전송 및 클라이언트 수준에서의 계산을 감소시킨다.

Abstract: As large language models continue to develop and expand, the extensive public data they rely on faces the risk of depletion. Consequently, leveraging private data within organizations to enhance the performance of large models has emerged as a key challenge. The federated learning paradigm, combined with model fine-tuning techniques, effectively reduces the number of trainable parameters. However,the necessity to process high-dimensional feature spaces results in substantial overall computational overhead. To address this issue, we propose the Implicit Federated In-Context Learning (IFed-ICL) framework. IFed-ICL draws inspiration from federated learning to establish a novel distributed collaborative paradigm, by converting client local context examples into implicit vector representations, it enables distributed collaborative computation during the inference phase and injects model residual streams to enhance model performance. Experiments demonstrate that our proposed method achieves outstanding performance across multiple text classification tasks. Compared to traditional methods, IFed-ICL avoids the extensive parameter updates required by conventional fine-tuning methods while reducing data transmission and local computation at the client level in federated learning. This enables efficient distributed context learning using local private-domain data, significantly improving model performance on specific tasks.

</details>


### [22] [Resource Efficient Sleep Staging via Multi-Level Masking and Prompt Learning](https://arxiv.org/abs/2511.06785)
*Lejun Ai,Yulong Li,Haodong Yi,Jixuan Xie,Yue Wang,Jia Liu,Min Chen,Rui Wang*

Main category: cs.LG

TL;DR: 자원 효율적인 수면 단계 분류를 위한 새로운 프레임워크인 Mask-Aware Sleep Staging (MASS)을 제안하며, 제한된 데이터에서 우수한 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 제한된 자원에서의 수면 모니터링 시스템을 위한 데이터를 효율적으로 수집하는 것이 중요하다.

Method: 부분적이고 불규칙한 관찰 하에서 효과적인 특징 모델링을 촉진하는 다수준 마스킹 전략과 계층적 프롬프트 학습 메커니즘을 도입하여 MASS 프레임워크를 제안한다.

Result: 네 개의 데이터셋에서 평가한 결과, 특히 데이터 양이 매우 제한적일 때 최첨단 성능을 보여준다.

Conclusion: MASS는 실제 저자원 수면 모니터링 환경에서의 효율적이고 확장 가능한 배치 가능성을 강조한다.

Abstract: Automatic sleep staging plays a vital role in assessing sleep quality and diagnosing sleep disorders. Most existing methods rely heavily on long and continuous EEG recordings, which poses significant challenges for data acquisition in resource-constrained systems, such as wearable or home-based monitoring systems. In this paper, we propose the task of resource-efficient sleep staging, which aims to reduce the amount of signal collected per sleep epoch while maintaining reliable classification performance. To solve this task, we adopt the masking and prompt learning strategy and propose a novel framework called Mask-Aware Sleep Staging (MASS). Specifically, we design a multi-level masking strategy to promote effective feature modeling under partial and irregular observations. To mitigate the loss of contextual information introduced by masking, we further propose a hierarchical prompt learning mechanism that aggregates unmasked data into a global prompt, serving as a semantic anchor for guiding both patch-level and epoch-level feature modeling. MASS is evaluated on four datasets, demonstrating state-of-the-art performance, especially when the amount of data is very limited. This result highlights its potential for efficient and scalable deployment in real-world low-resource sleep monitoring environments.

</details>


### [23] [On The Presence of Double-Descent in Deep Reinforcement Learning](https://arxiv.org/abs/2511.06895)
*Viktor Veselý,Aleksandar Todorov,Matthia Sabatelli*

Main category: cs.LG

TL;DR: 이 연구는 비정상적인 환경에서의 심층 강화 학습에서 더블 디센트 패러독스의 존재를 탐구하고 있다.


<details>
  <summary>Details</summary>
Motivation: 더블 디센트 패러독스는 과매개변수화 모델이 보간점을 초과하여 일반화가 개선되는 현상이다. 이는 심층 강화 학습의 비정상적인 도메인에서 충분히 연구되지 않았다.

Method: 우리는 액터-크리틱 프레임워크를 사용하여 모델 용량을 달리하며 무모델 DRL에서 DD를 체계적으로 조사하였다.

Result: 예비 결과는 명확한 에폭별 DD 곡선을 나타내며, 정책의 두 번째 하강 영역으로의 진입이 정책 엔트로피의 지속적이고 중요한 감소와 상관관계가 있음을 보여준다.

Conclusion: 이 연구는 DD가 DRL에서 중요한 요소로 작용하며, 더 일반적이고 전이 가능하며 강력한 에이전트를 설계하기 위한 정보 기반 메커니즘을 제공한다.

Abstract: The double descent (DD) paradox, where over-parameterized models see generalization improve past the interpolation point, remains largely unexplored in the non-stationary domain of Deep Reinforcement Learning (DRL). We present preliminary evidence that DD exists in model-free DRL, investigating it systematically across varying model capacity using the Actor-Critic framework. We rely on an information-theoretic metric, Policy Entropy, to measure policy uncertainty throughout training. Preliminary results show a clear epoch-wise DD curve; the policy's entrance into the second descent region correlates with a sustained, significant reduction in Policy Entropy. This entropic decay suggests that over-parameterization acts as an implicit regularizer, guiding the policy towards robust, flatter minima in the loss landscape. These findings establish DD as a factor in DRL and provide an information-based mechanism for designing agents that are more general, transferable, and robust.

</details>


### [24] [Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning](https://arxiv.org/abs/2511.06946)
*Daniel De Dios Allegue,Jinke He,Frans A. Oliehoek*

Main category: cs.LG

TL;DR: 이 논문은 부분 관찰에서 모델 기반 강화 학습을 위한 Transformer의 self-attention 메커니즘을 개선하기 위해 구조화된 유도 선험을 도입합니다.


<details>
  <summary>Details</summary>
Motivation: 부분 관찰 환경에서의 모델 기반 강화 학습에서 Transformer의 효과적인 활용 필요성.

Method: self-attention 메커니즘에 헤드별 메모리 길이 선험과 분포 선험을 도입하여 과거 상태-행동 쌍에 대한 가우시안 가중치를 학습.

Result: Atari 100k 벤치마크 실험 결과, 가우시안 선험이 유익한 전환에 주의를 부드럽게 할당하여 77% 상대 개선 효과를 달성.

Conclusion: 구조화된 시간 선험을 self-attention에 인코딩함으로써 부분 관찰 환경에서의 동역학 모델링을 위한 정보 역사 우선 순위를 개선할 수 있음을 보여줍니다.

Abstract: Transformers have shown strong ability to model long-term dependencies and are increasingly adopted as world models in model-based reinforcement learning (RL) under partial observability. However, unlike natural language corpora, RL trajectories are sparse and reward-driven, making standard self-attention inefficient because it distributes weight uniformly across all past tokens rather than emphasizing the few transitions critical for control. To address this, we introduce structured inductive priors into the self-attention mechanism of the dynamics head: (i) per-head memory-length priors that constrain attention to task-specific windows, and (ii) distributional priors that learn smooth Gaussian weightings over past state-action pairs. We integrate these mechanisms into UniZero, a model-based RL agent with a Transformer-based world model that supports planning under partial observability. Experiments on the Atari 100k benchmark show that most efficiency gains arise from the Gaussian prior, which smoothly allocates attention to informative transitions, while memory-length priors often truncate useful signals with overly restrictive cut-offs. In particular, Gaussian Attention achieves a 77% relative improvement in mean human-normalized scores over UniZero. These findings suggest that in partially observable RL domains with non-stationary temporal dependencies, discrete memory windows are difficult to learn reliably, whereas smooth distributional priors flexibly adapt across horizons and yield more robust data efficiency. Overall, our results demonstrate that encoding structured temporal priors directly into self-attention improves the prioritization of informative histories for dynamics modeling under partial observability.

</details>


### [25] [Hybrid Autoencoders for Tabular Data: Leveraging Model-Based Augmentation in Low-Label Settings](https://arxiv.org/abs/2511.06961)
*Erel Naor,Ofir Lindenbaum*

Main category: cs.LG

TL;DR: 하이브리드 오토인코더를 통해 심층 신경망의 표 형식 데이터 처리 성능을 향상시키고, 효과적인 샘플 특성 선택을 위한 확률적 게이팅 네트워크를 사용하여 서로 다른 인덕티브 편향을 가진 두 개의 인코더를 결합하였다.


<details>
  <summary>Details</summary>
Motivation: 표 형식 데이터에 대한 심층 신경망의 성능 저하 문제를 해결하고, 적은 라벨 샘플에서도 고주파 신호를 포착할 수 있는 방법을 제시하기 위함이다.

Method: 신경 인코더와 무관심 소프트 결정 트리(OSDT) 인코더를 결합한 하이브리드 오토인코더를 제안하며, 각 인코더는 샘플별 특성 선택을 수행하는 확률적 게이팅 네트워크에 의해 안내된다.

Result: 두 개의 서로 다른 인코더와 모델별 게이팅 네트워크가 모델 기반 증강을 구현하여 각 아키텍처에 맞춘 보완적인 입력 뷰를 생성하며, 다양한 표 형식 데이터셋에서 일관된 성능 개선을 달성한다.

Conclusion: 제안하는 방법은 심층 및 트리 기반 감독 학습 기준에 비해 일관된 성능 향상을 이루어내며, 저라벨 분류 및 회귀 작업에서 효과적이다.

Abstract: Deep neural networks often under-perform on tabular data due to their sensitivity to irrelevant features and a spectral bias toward smooth, low-frequency functions. These limitations hinder their ability to capture the sharp, high-frequency signals that often define tabular structure, especially under limited labeled samples. While self-supervised learning (SSL) offers promise in such settings, it remains challenging in tabular domains due to the lack of effective data augmentations. We propose a hybrid autoencoder that combines a neural encoder with an oblivious soft decision tree (OSDT) encoder, each guided by its own stochastic gating network that performs sample-specific feature selection. Together, these structurally different encoders and model-specific gating networks implement model-based augmentation, producing complementary input views tailored to each architecture. The two encoders, trained with a shared decoder and cross-reconstruction loss, learn distinct yet aligned representations that reflect their respective inductive biases. During training, the OSDT encoder (robust to noise and effective at modeling localized, high-frequency structure) guides the neural encoder toward representations more aligned with tabular data. At inference, only the neural encoder is used, preserving flexibility and SSL compatibility. Spectral analysis highlights the distinct inductive biases of each encoder. Our method achieves consistent gains in low-label classification and regression across diverse tabular datasets, outperforming deep and tree-based supervised baselines.

</details>


### [26] [CoLM: Collaborative Large Models via A Client-Server Paradigm](https://arxiv.org/abs/2511.06991)
*Siqi Huang,Sida Huang,Hongyuan Zhang*

Main category: cs.LG

TL;DR: CoLM은 대형 모델 간의 협력적 추론을 위한 새로운 프레임워크로, 클라이언트-서버 관점에서 협업을 다시 정의하며, 모델 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 대형 모델들이 다양한 추론 및 이해 작업에서 뛰어난 성능을 보이고 있지만, 기존의 앙상블 또는 다중 에이전트 시스템 접근 방식은 현대 인터넷 아키텍처에서 클라이언트가 여러 서버 측 모델을 공유하는 환경과 잘 맞지 않는다.

Method: CoLM은 여러 모델의 출력을 집계하거나 공유하여 각 클라이언트 모델이 이러한 고품질 출력을 기반으로 독립적으로 생성 결과를 개선할 수 있도록 한다.

Result: 여러 벤치마크에서의 실험 결과, CoLM은 이전에 실패한 쿼리에서 모델 성능을 일관되게 향상시켰다.

Conclusion: 협업 지도의 효과를 강조하며 단일 모델의 능력을 향상시키는데 기여한다.

Abstract: Large models have achieved remarkable performance across a range of reasoning and understanding tasks. Prior work often utilizes model ensembles or multi-agent systems to collaboratively generate responses, effectively operating in a server-to-server paradigm. However, such approaches do not align well with practical deployment settings, where a limited number of server-side models are shared by many clients under modern internet architectures. In this paper, we introduce \textbf{CoLM} (\textbf{Co}llaboration in \textbf{L}arge-\textbf{M}odels), a novel framework for collaborative reasoning that redefines cooperation among large models from a client-server perspective. Unlike traditional ensemble methods that rely on simultaneous inference from multiple models to produce a single output, CoLM allows the outputs of multiple models to be aggregated or shared, enabling each client model to independently refine and update its own generation based on these high-quality outputs. This design enables collaborative benefits by fully leveraging both client-side and shared server-side models. We further extend CoLM to vision-language models (VLMs), demonstrating its applicability beyond language tasks. Experimental results across multiple benchmarks show that CoLM consistently improves model performance on previously failed queries, highlighting the effectiveness of collaborative guidance in enhancing single-model capabilities.

</details>


### [27] [LLMscape](https://arxiv.org/abs/2511.07161)
*Gottfried Haider,Jie Zhang*

Main category: cs.LG

TL;DR: LLMscape는 인간과 AI가 불확실한 조건에서 의미를 구성하는 방식을 탐구하는 인터랙티브 설치 작품이다.


<details>
  <summary>Details</summary>
Motivation: 인간과 AI가 협력하여 불확실한 세상에서 어떻게 의미를 창출하는지 알아보려는 목적이 있다.

Method: 변화 가능한 프로젝션 맵이 적용된 풍경 속에서 인간 참가자들이 세계를 재구성하고 여러 AI 에이전트와 상호작용을 한다.

Result: AI는 결정론적 도구가 아니라 불안정한 세계의 동체적 증인으로 자리하도록 하고, 인간과 인공지능의 의미 체계 간의 유사성을 탐구한다.

Conclusion: 이 작품은 공유된 인식론적 한계에 대한 성찰을 초대한다.

Abstract: LLMscape is an interactive installation that investigates how humans and AI construct meaning under shared conditions of uncertainty. Within a mutable, projection-mapped landscape, human participants reshape the world and engage with multiple AI agents, each developing incomplete and provisional accounts of their environment. Exhibited in Shanghai and continually evolving, the work positions AI not as deterministic tools but as embodied co-witnesses to an unstable world, examining the parallels between human and artificial meaning-making and inviting reflection on our shared epistemic limits.

</details>


### [28] [Grounding Computer Use Agents on Human Demonstrations](https://arxiv.org/abs/2511.07332)
*Aarash Feizi,Shravan Nayak,Xiangru Jian,Kevin Qinghong Lin,Kaixin Li,Rabiul Awal,Xing Han Lù,Johan Obando-Ceron,Juan A. Rodriguez,Nicolas Chapados,David Vazquez,Adriana Romero-Soriano,Reihaneh Rabbany,Perouz Taslakian,Christopher Pal,Spandana Gella,Sai Rajeswar*

Main category: cs.LG

TL;DR: GroundCUA는 고품질 데스크탑 그라운딩 데이터셋으로, 87개 애플리케이션과 12개 카테고리로 구성되어 있으며, 3.56M개의 인간 검증 주석을 포함하고 있습니다.


<details>
  <summary>Details</summary>
Motivation: 데스크탑 환경에 대한 고품질 리소스가 부족하여, 이를 해결하기 위해 GroundCUA 데이터셋을 소개합니다.

Method: GroundCUA 데이터셋을 사용하여 명령어를 UI 요소에 매핑하는 GroundNext 모델군을 개발하였습니다.

Result: GroundNext는 다섯 개의 벤치마크에서 최첨단 결과를 달성하며, 이전 작업의 훈련 데이터의 10분의 1 이하를 필요로 합니다. 강화 학습 후 훈련으로 성능이 더욱 향상되었습니다.

Conclusion: 고품질의 전문가 기반 데이터셋이 일반 목적 컴퓨터 사용 에이전트를 발전시키는 데 있어 중요한 역할을 함을 보여줍니다.

Abstract: Building reliable computer-use agents requires grounding: accurately connecting natural language instructions to the correct on-screen elements. While large datasets exist for web and mobile interactions, high-quality resources for desktop environments are limited. To address this gap, we introduce GroundCUA, a large-scale desktop grounding dataset built from expert human demonstrations. It covers 87 applications across 12 categories and includes 56K screenshots, with every on-screen element carefully annotated for a total of over 3.56M human-verified annotations. From these demonstrations, we generate diverse instructions that capture a wide range of real-world tasks, providing high-quality data for model training. Using GroundCUA, we develop the GroundNext family of models that map instructions to their target UI elements. At both 3B and 7B scales, GroundNext achieves state-of-the-art results across five benchmarks using supervised fine-tuning, while requiring less than one-tenth the training data of prior work. Reinforcement learning post-training further improves performance, and when evaluated in an agentic setting on the OSWorld benchmark using o3 as planner, GroundNext attains comparable or superior results to models trained with substantially more data,. These results demonstrate the critical role of high-quality, expert-driven datasets in advancing general-purpose computer-use agents.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [Evidence-Bound Autonomous Research (EviBound): A Governance Framework for Eliminating False Claims](https://arxiv.org/abs/2511.05524)
*Ruiying Chen*

Main category: cs.AI

TL;DR: EviBound는 기계 확인 가능한 증거를 요구하는 이중 관리 게이트를 통해 거짓 주장을 제거하는 증거 기반 실행 프레임워크로, 8개의 벤치마크 과제를 평가하였고, 0% 환각률을 달성하였다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 자율 연구 에이전트가 누락된 아티팩트, 상반된 측정값, 또는 실패한 실행에도 불구하고 '완료'로 표시된 작업에서 잘못된 주장을 보고함.

Method: 사전 실행 승인 게이트와 사후 실행 검증 게이트의 두 가지 보완적 게이트를 통해 증거 요건을 시행하며, MLflow API 쿼리를 통해 아티팩트를 검증하고 필요시 수용 기준에 따라 측정값을 검증.

Result: EviBound는 8개의 작업 중 7개를 검증하고 1개의 작업을 승인 게이트에서 올바르게 차단하여 0% 환각률을 달성하며, 약 8.3%의 실행 오버헤드만 발생.

Conclusion: 연구의 무결성은 아키텍처적 속성이며, 모델 규모에서 발생하는 것이 아니라 관리 게이트를 통해 달성된다.

Abstract: LLM-based autonomous research agents report false claims: tasks marked "complete" despite missing artifacts, contradictory metrics, or failed executions. EviBound is an evidence-bound execution framework that eliminates false claims through dual governance gates requiring machine-checkable evidence.
  Two complementary gates enforce evidence requirements. The pre-execution Approval Gate validates acceptance criteria schemas before code runs, catching structural violations proactively. The post-execution Verification Gate validates artifacts via MLflow API queries (with recursive path checking) and optionally validates metrics when specified by acceptance criteria. Claims propagate only when backed by a queryable run ID, required artifacts, and FINISHED status. Bounded, confidence-gated retries (typically 1-2 attempts) recover from transient failures without unbounded loops.
  The framework was evaluated on 8 benchmark tasks spanning infrastructure validation, ML capabilities, and governance stress tests. Baseline A (Prompt-Level Only) yields 100% hallucination (8/8 claimed, 0/8 verified). Baseline B (Verification-Only) reduces hallucination to 25% (2/8 fail verification). EviBound (Dual Gates) achieves 0% hallucination: 7/8 tasks verified and 1 task correctly blocked at the approval gate, all with only approximately 8.3% execution overhead.
  This package includes execution trajectories, MLflow run IDs for all verified tasks, and a 4-step verification protocol. Research integrity is an architectural property, achieved through governance gates rather than emergent from model scale.

</details>


### [30] [SMAGDi: Socratic Multi Agent Interaction Graph Distillation for Efficient High Accuracy Reasoning](https://arxiv.org/abs/2511.05528)
*Aayush Aluru,Myra Malik,Samarth Patankar,Spencer Kim,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.AI

TL;DR: SMAGDi는 다중 에이전트 시스템의 토론 동력을 소형 모델에 전달하는 증류 프레임워크로, 이전 방법들보다 우수한 성능을 보입니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템은 높은 추론 정확도를 달성하지만, 반복적인 토론으로 인해 계산 복잡도가 높습니다.

Method: SMAGDi는 토론 과정을 방향성 상호작용 그래프로 표현하며, 그래프 기반 감독 및 다양한 목표를 결합하여 학생 모델을 훈련합니다.

Result: SMAGDi는 40B 다중 에이전트 시스템을 6B 학생 모델로 압축하면서도 88%의 정확도를 유지합니다.

Conclusion: 소크라틱 분해와 상호작용 그래프의 명시적 모델링이 다중 에이전트 시스템의 정확도를 소형 모델에 전이할 수 있음을 보여줍니다.

Abstract: Multi-agent systems (MAS) often achieve higher reasoning accuracy than single models, but their reliance on repeated debates across agents makes them computationally expensive. We introduce SMAGDi, a distillation framework that transfers the debate dynamics of a five-agent Llama-based MAS into a compact Socratic decomposer-solver student. SMAGDi represents debate traces as directed interaction graphs, where nodes encode intermediate reasoning steps with correctness labels and edges capture continuity and cross-agent influence. The student is trained with a composite objective combining language modeling, graph-based supervision, contrastive reasoning, and embedding alignment to preserve both fluency and structured reasoning. On StrategyQA and MMLU, SMAGDi compresses a 40B multi-agent system into a 6B student while retaining 88% of its accuracy, substantially outperforming prior distillation methods such as MAGDi, standard KD, and fine-tuned baselines. These results highlight that explicitly modeling interaction graphs and Socratic decomposition enable small models to inherit the accuracy benefits of multi-agent debate while remaining efficient enough for real-world deployment.

</details>


### [31] [Anchors in the Machine: Behavioral and Attributional Evidence of Anchoring Bias in LLMs](https://arxiv.org/abs/2511.05766)
*Felipe Valencia-Clavijo*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델(LLMs)에서의 고정편향을 세 가지 기여를 통해 조사하여, 모델의 출력 분포가 고정장치에 의해 어떻게 변화하는지를 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 행동 주체이자 의사결정 시스템으로서 조사되고 있지만, 관찰된 인지 편향이 표면적인 모방인지 또는 더 깊은 확률 변화인지 불확실합니다.

Method: 이번 연구는 (1) 훈련 데이터 오염을 통제하여 고정장치가 전체 출력 분포를 변화시키는 것을 보여주는 로그 확률 기반 행동 분석, (2) 구조화된 프롬프트 필드에서의 정확한 샤플리 값 귀속을 통해 고정장치가 모델 로그 확률에 미치는 영향을 정량화, (3) 여섯 개의 오픈 소스 모델에서 행동 증거와 귀속 증거를 통합한 통합 고정편향 감도 점수를 제공합니다.

Result: 결과는 Gemma-2B, Phi-2, Llama-2-7B에서 강력한 고정 효과를 나타내며, 귀속 결과는 고정장치가 재가중에 영향을 미친다는 것을 시사합니다. 또한, GPT-2, Falcon-RW-1B, GPT-Neo-125M과 같은 작은 모델은 변동성을 보이며, 이는 규모가 감수성에 영향을 미칠 수 있음을 나타냅니다.

Conclusion: 이 연구 결과는 대형 언어 모델에서의 고정편향이 강력하고 측정 가능하며 해석 가능함을 보여주며, 적용 분야에서의 위험성을 강조합니다. 보다 광범위하게는 이 프레임워크가 행동 과학, LLM 안전성 및 해석 가능성을 연결하여 다른 인지 편향을 평가하는 재현 가능한 경로를 제공합니다.

Abstract: Large language models (LLMs) are increasingly examined as both behavioral subjects and decision systems, yet it remains unclear whether observed cognitive biases reflect surface imitation or deeper probability shifts. Anchoring bias, a classic human judgment bias, offers a critical test case. While prior work shows LLMs exhibit anchoring, most evidence relies on surface-level outputs, leaving internal mechanisms and attributional contributions unexplored. This paper advances the study of anchoring in LLMs through three contributions: (1) a log-probability-based behavioral analysis showing that anchors shift entire output distributions, with controls for training-data contamination; (2) exact Shapley-value attribution over structured prompt fields to quantify anchor influence on model log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score integrating behavioral and attributional evidence across six open-source models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and Llama-2-7B, with attribution signaling that the anchors influence reweighting. Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability, suggesting scale may modulate sensitivity. Attributional effects, however, vary across prompt designs, underscoring fragility in treating LLMs as human substitutes. The findings demonstrate that anchoring bias in LLMs is robust, measurable, and interpretable, while highlighting risks in applied domains. More broadly, the framework bridges behavioral science, LLM safety, and interpretability, offering a reproducible path for evaluating other cognitive biases in LLMs.

</details>


### [32] [Can a Small Model Learn to Look Before It Leaps? Dynamic Learning and Proactive Correction for Hallucination Detection](https://arxiv.org/abs/2511.05854)
*Zepeng Bao,Shen Zhou,Qiankun Pi,Jianhao Chen,Mayi Xu,Ming Zhong,Yuanyuan Zhu,Tieyun Qian*

Main category: cs.AI

TL;DR: 대형 언어 모델의 환각 문제는 안전한 배치에 큰 장벽이 된다. 기존 방법은 고정된 검증 전략에 의존해 효율성이 떨어진다. 이 논문에서는 '학습을 통한 평가 및 적응 계획'(LEAP) 프레임워크를 제안하여 동적인 전략 학습 문제로 환각 탐지 문제를 해결한다. 실험을 통해 LEAP 조정 모델이 기존 최첨단 방법보다 우월하다는 것을 입증했다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델에서 환각 문제는 안전한 운영을 저해하는 중요한 장애물이다. 기존 방법들은 고정된 검증 전략에 의존하여 유연성이 부족하다.

Method: 우리는 '학습을 통한 평가 및 적응 계획'(LEAP) 프레임워크를 제안하며, 이 프레임워크는 학생 모델이 교사 모델의 동적 학습 및 능동적 수정 기능을 갖추도록 한다. 환각 탐지 문제를 동적 전략 학습 문제로 공식화하고, 교사 모델이 동적 학습 루프 내에서 궤적을 생성하도록 한다.

Result: LEAP 조정 모델이 세 가지 도전적인 벤치마크에서 기존 최첨단 방법보다 우수한 성능을 발휘한다.

Conclusion: LEAP는 동적 전략 학습을 통해 기존의 고정된 방법론으로는 해결할 수 없는 문제들을 해결하며, 효율적인 학생 모델을 통해 환각 탐지 문제를 더욱 효과적으로 접근할 수 있게 해준다.

Abstract: Hallucination in large language models (LLMs) remains a critical barrier to their safe deployment. Existing tool-augmented hallucination detection methods require pre-defined fixed verification strategies, which are crucial to the quality and effectiveness of tool calls. Some methods directly employ powerful closed-source LLMs such as GPT-4 as detectors, which are effective but too costly. To mitigate the cost issue, some methods adopt the teacher-student architecture and finetune open-source small models as detectors via agent tuning. However, these methods are limited by fixed strategies. When faced with a dynamically changing execution environment, they may lack adaptability and inappropriately call tools, ultimately leading to detection failure. To address the problem of insufficient strategy adaptability, we propose the innovative ``Learning to Evaluate and Adaptively Plan''(LEAP) framework, which endows an efficient student model with the dynamic learning and proactive correction capabilities of the teacher model. Specifically, our method formulates the hallucination detection problem as a dynamic strategy learning problem. We first employ a teacher model to generate trajectories within the dynamic learning loop and dynamically adjust the strategy based on execution failures. We then distill this dynamic planning capability into an efficient student model via agent tuning. Finally, during strategy execution, the student model adopts a proactive correction mechanism, enabling it to propose, review, and optimize its own verification strategies before execution. We demonstrate through experiments on three challenging benchmarks that our LEAP-tuned model outperforms existing state-of-the-art methods.

</details>


### [33] [Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement](https://arxiv.org/abs/2511.05931)
*Hiroaki Hayashi,Bo Pang,Wenting Zhao,Ye Liu,Akash Gokul,Srijan Bansal,Caiming Xiong,Semih Yavuz,Yingbo Zhou*

Main category: cs.AI

TL;DR: SAGE라는 프레임워크는 LLM 기반 에이전트가 자신의 경험을 통해 학습하고 행동을 정제할 수 있도록 지원하여 소프트웨어 공학 작업에서 성능 향상을 이끈다.


<details>
  <summary>Details</summary>
Motivation: 대다수 LLM 기반 에이전트는 정적인 실행 프레임워크 내에서 운영되며, 자신의 경험으로부터 학습하고 자율적으로 발전할 수 있는 원칙적인 메커니즘이 부족하다.

Method: Self-Abstraction from Grounded Experience (SAGE) 프레임워크를 통해 에이전트는 작업 실행에서 자신의 경험을 바탕으로 행위를 정제하는 방법을 학습한다.

Result: SAGE는 다양한 LLM 백본과 에이전트 아키텍처에서 일관된 성능 향상을 제공하며, GPT-5(고급) 백본과 결합했을 때 Mini-SWE-Agent 기준선에 대해 7.2%의 상대적 성능 향상을 기록한다.

Conclusion: SAGE는 SWE-Bench Verified 벤치마크에서 Mini-SWE-Agent와 OpenHands CodeAct 에이전트 프레임워크를 통해 각각 73.2% 및 74%의 Pass@1 해결률을 달성하며 강력한 전반적인 성능을 보여준다.

Abstract: Large language model (LLM) based agents are increasingly used to tackle software engineering tasks that require multi-step reasoning and code modification, demonstrating promising yet limited performance. However, most existing LLM agents typically operate within static execution frameworks, lacking a principled mechanism to learn and self-improve from their own experience and past rollouts. As a result, their performance remains bounded by the initial framework design and the underlying LLM's capabilities. We propose Self-Abstraction from Grounded Experience (SAGE), a framework that enables agents to learn from their own task executions and refine their behavior through self-abstraction. After an initial rollout, the agent induces a concise plan abstraction from its grounded experience, distilling key steps, dependencies, and constraints. This learned abstraction is then fed back as contextual guidance, refining the agent's policy and supporting more structured, informed subsequent executions. Empirically, SAGE delivers consistent performance gains across diverse LLM backbones and agent architectures. Notably, it yields a 7.2% relative performance improvement over the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone. SAGE further achieves strong overall performance on SWE-Bench Verified benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent and OpenHands CodeAct agent framework, respectively.

</details>


### [34] [Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling](https://arxiv.org/abs/2511.05951)
*Qi Wang,Hongzhi Zhang,Jia Fu,Kai Fu,Yahui Liu,Tinghai Zhang,Chenxi Sun,Gangwei Jiang,Jingyi Tang,Xingguang Ji,Yang Yue,Jingyuan Zhang,Fuzheng Zhang,Kun Gai,Guorui Zhou*

Main category: cs.AI

TL;DR: Klear-Qwen3-AgentForge는 Qwen3-8B 기초 모델을 기반으로 외부 도구 및 환경과 상호작용하는 고성능 에이전틱 모델 훈련을 위한 완전한 오픈 소스 파이프라인을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 강력한 에이전틱 모델들이 proliferating하고 있지만, 비판적인 사후 훈련 세부사항의 부족이 오픈 소스 커뮤니티에서 강력한 대응물 개발을 방해하고 있습니다.

Method: 우리는 합성 데이터를 사용한 효과적인 감독 세밀 조정(SFT)과 다중 턴 강화 학습(RL)을 설계하여 다양한 에이전틱 작업을 잠금 해제합니다.

Result: Klear-Qwen3-AgentForge-8B는 유사한 크기의 LLM 중에서 최첨단 성능을 달성하며, 훨씬 더 큰 모델들과 경쟁력을 유지합니다.

Conclusion: 우리는 다양한 도구 사용 및 코딩 도메인에서 여러 에이전틱 벤치마크에 대한 독점 실험을 수행했습니다.

Abstract: Despite the proliferation of powerful agentic models, the lack of critical post-training details hinders the development of strong counterparts in the open-source community. In this study, we present a comprehensive and fully open-source pipeline for training a high-performance agentic model for interacting with external tools and environments, named Klear-Qwen3-AgentForge, starting from the Qwen3-8B base model. We design effective supervised fine-tuning (SFT) with synthetic data followed by multi-turn reinforcement learning (RL) to unlock the potential for multiple diverse agentic tasks. We perform exclusive experiments on various agentic benchmarks in both tool use and coding domains. Klear-Qwen3-AgentForge-8B achieves state-of-the-art performance among LLMs of similar size and remains competitive with significantly larger models.

</details>


### [35] [An Epistemic Perspective on Agent Awareness](https://arxiv.org/abs/2511.05977)
*Pavel Naumov,Alexandra Pavlova*

Main category: cs.AI

TL;DR: 이 논문은 에이전트 인식을 지식의 한 형태로 다룰 것을 제안하고, 기존 인식 문헌의 전통을 깨뜨린다.


<details>
  <summary>Details</summary>
Motivation: 에이전트의 인식을 새로운 방식으로 이해하고 설명하기 위해서이다.

Method: de re와 de dicto 형태의 인식을 캡처하는 두 가지 양식을 도입하고 2D 의미론 버전을 사용하여 이를 형식적으로 정의한다.

Result: 제안된 두 가지 양식과 표준 '사실 지식' 양식 간의 상호작용을 설명하는 사운드하고 완전한 논리 시스템을 제시한다.

Conclusion: 이 연구는 에이전트의 인식에 대한 새로운 접근 방식을 제공하고 기존 이론과의 통합 가능성을 보여준다.

Abstract: The paper proposes to treat agent awareness as a form of knowledge, breaking the tradition in the existing literature on awareness. It distinguishes the de re and de dicto forms of such knowledge. The work introduces two modalities capturing these forms and formally specifies their meaning using a version of 2D-semantics. The main technical result is a sound and complete logical system describing the interplay between the two proposed modalities and the standard "knowledge of the fact" modality.

</details>


### [36] [ScRPO: From Errors to Insights](https://arxiv.org/abs/2511.06065)
*Lianrui Li,Dakuan Lu,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: Self-correction Relative Policy Optimization (ScRPO)는 자기 반성과 오류 수정을 통해 대형 언어 모델을 개선하기 위한 새로운 강화 학습 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 어려운 수학 문제를 해결할 수 있도록 개선하기 위해 ScRPO를 제안한다.

Method: 모델을 GRPO로 훈련시키고 오류 풀에서 잘못된 답변과 해당 질문을 수집하는 시도 및 오류 학습 단계와, 모델이 이전 답변이 잘못된 이유를 반성하도록 안내하는 자기 수정 학습 단계로 구성된다.

Result: Deepseek-Distill-Qwen-1.5B 및 Deepseek-Distill-Qwen-7B를 사용한 여러 수학 추론 벤치마크에서 ScRPO가 여러 후속 훈련 방법을 일관되게 초월한다는 실험 결과가 나타났다.

Conclusion: ScRPO는 제한된 외부 피드백으로 어려운 작업에서 언어 모델이 자기 개선할 수 있도록 하는 유망한 패러다임으로, 보다 신뢰할 수 있고 능력 있는 AI 시스템을 향한 길을 열어준다.

Abstract: We propose Self-correction Relative Policy Optimization (ScRPO), a novel reinforcement learning framework designed to enhance large language models on challenging mathematical problems by leveraging self-reflection and error correction. Our approach consists of two stages: (1) Trial-and-error learning stage: training the model with GRPO and collecting incorrect answers along with their corresponding questions in an error pool; (2) Self-correction learning stage: guiding the model to reflect on why its previous answers were wrong. Extensive experiments across multiple math reasoning benchmarks, including AIME, AMC, Olympiad, MATH-500, GSM8k, using Deepseek-Distill-Qwen-1.5B and Deepseek-Distill-Qwen-7B. The experimental results demonstrate that ScRPO consistently outperforms several post-training methods. These findings highlight ScRPO as a promising paradigm for enabling language models to self-improve on difficult tasks with limited external feedback, paving the way toward more reliable and capable AI systems.

</details>


### [37] [Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs](https://arxiv.org/abs/2511.06134)
*Wei Yang,Jiacheng Pang,Shixuan Li,Paul Bogdan,Stephen Tu,Jesse Thomason*

Main category: cs.AI

TL;DR: 이 논문은 다중 에이전트 시스템을 통해 복잡한 문제를 해결하는 방법을 제시하며, 기존 방법의 한계를 극복하는 새로운 프레임워크인 Maestro를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템(MAS)은 대규모 언어 모델(LLM)을 기반으로 복잡한 문제를 해결하고, 단일 모델 추론을 초월할 수 있는 가능성을 보여줍니다. 그러나 성공은 솔루션 공간의 광범위한 탐색과 최적 솔루션에 대한 수렴적 합성과의 균형을 맞추는 기본적인 인지 긴장감을 관리하는 데 달려 있습니다.

Method: Maestro는 다양한 탐색을 위한 여러 실행 에이전트와 수렴적 평가 합성을 위한 중앙 에이전트를 활용하여 인지 모드를 구조적으로 분리하는 협력 프레임워크입니다. CLPO(조건부 리스트 정책 최적화)를 도입하여 전략적 결정과 전술적 근거에 대한 신호를 분리해 내고, 의사 결정 중심의 정책 그래디언트와 정당화에 대한 리스트 수준의 순위 손실을 결합합니다.

Result: Maestro와 CLPO 조합은 수학적 추론 및 일반 문제 해결 벤치마크에서 기존의 다중 에이전트 접근 방식을 지속적으로 초월하며 평균 6%의 절대 정확도 향상과 최대 10%의 향상을 달성했습니다.

Conclusion: Maestro는 현재 최고의 다중 에이전트 접근 방식보다 성능이 우수한 새로운 다중 에이전트 협업 방법론을 제안합니다.

Abstract: Multi-agent systems (MAS) built on Large Language Models (LLMs) are being used to approach complex problems and can surpass single model inference. However, their success hinges on navigating a fundamental cognitive tension: the need to balance broad, divergent exploration of the solution space with a principled, convergent synthesis to the optimal solution. Existing paradigms often struggle to manage this duality, leading to premature consensus, error propagation, and a critical credit assignment problem that fails to distinguish between genuine reasoning and superficially plausible arguments. To resolve this core challenge, we propose the Multi-Agent Exploration-Synthesis framework Through Role Orchestration (Maestro), a principled paradigm for collaboration that structurally decouples these cognitive modes. Maestro uses a collective of parallel Execution Agents for diverse exploration and a specialized Central Agent for convergent, evaluative synthesis. To operationalize this critical synthesis phase, we introduce Conditional Listwise Policy Optimization (CLPO), a reinforcement learning objective that disentangles signals for strategic decisions and tactical rationales. By combining decision-focused policy gradients with a list-wise ranking loss over justifications, CLPO achieves clean credit assignment and stronger comparative supervision. Experiments on mathematical reasoning and general problem-solving benchmarks demonstrate that Maestro, coupled with CLPO, consistently outperforms existing state-of-the-art multi-agent approaches, delivering absolute accuracy gains of 6% on average and up to 10% at best.

</details>


### [38] [Efficient LLM Safety Evaluation through Multi-Agent Debate](https://arxiv.org/abs/2511.06396)
*Dachuan Lin,Guobin Shen,Zihao Yang,Tianrong Liu,Dongcheng Zhao,Yi Zeng*

Main category: cs.AI

TL;DR: 대규모 언어 모델의 안전성 평가를 위한 비용 효율적인 다중 에이전트 판단 프레임워크를 제안하고, HAJailBench라는 인체 주석이 달린 대규모 jailbreak 벤치마크를 구축하여 평가의 신뢰성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 안전성 평가가 LLM-as-a-Judge 프레임워크에 점점 더 의존하고 있지만, 최첨단 모델의 높은 비용이 확장성을 제한한다.

Method: 비용 효율적인 다중 에이전트 판단 프레임워크를 제안하며, 비평자, 방어자 및 판사 에이전트 간의 구조화된 논의를 통해 소형 언어 모델을 활용한다.

Result: SLM 기반 프레임워크는 HAJailBench에서 GPT-4o 판사와 유사한 동의 수준을 달성하였으며, 추론 비용을 상당히 줄였다. 세 번의 논의가 정확성과 효율성 간의 최적 밸런스를 제공함을 보여준다.

Conclusion: 구조화되고 가치에 맞춰 맞춤화된 논의가 SLM이 jailbreak 공격의 의미적 뉘앙스를 포착하도록 하고, HAJailBench가 확장 가능한 LLM 안전성 평가를 위한 신뢰할 수 있는 기초를 제공함을 입증한다.

Abstract: Safety evaluation of large language models (LLMs) increasingly relies on LLM-as-a-Judge frameworks, but the high cost of frontier models limits scalability. We propose a cost-efficient multi-agent judging framework that employs Small Language Models (SLMs) through structured debates among critic, defender, and judge agents. To rigorously assess safety judgments, we construct HAJailBench, a large-scale human-annotated jailbreak benchmark comprising 12,000 adversarial interactions across diverse attack methods and target models. The dataset provides fine-grained, expert-labeled ground truth for evaluating both safety robustness and judge reliability. Our SLM-based framework achieves agreement comparable to GPT-4o judges on HAJailBench while substantially reducing inference cost. Ablation results show that three rounds of debate yield the optimal balance between accuracy and efficiency. These findings demonstrate that structured, value-aligned debate enables SLMs to capture semantic nuances of jailbreak attacks and that HAJailBench offers a reliable foundation for scalable LLM safety evaluation.

</details>


### [39] [MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning](https://arxiv.org/abs/2511.06142)
*Sizhe Tang,Jiayu Chen,Tian Lan*

Main category: cs.AI

TL;DR: MALinZero는 저차원 표현 구조를 활용하여 복잡한 다중 에이전트 계획에서 효율적인 MCTS를 가능하게 하는 새로운 접근법이다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 계획에서 MCTS는 에이전트 수가 증가할수록 조합적 행동 공간의 급격한 증가에 직면한다.

Method: 저차원 공간에서의 조인트 액션 수익을 표현하는 문제를 해결하고 LinUCT를 도출하여 다중 에이전트 탐색 및 활용을 가능하게 한다.

Result: MALinZero는 매트릭스 게임, SMAC, SMACv2와 같은 다중 에이전트 벤치마크에서 최첨단 성능을 보여준다.

Conclusion: MALinZero는 모델 기반 및 모델 프리 다중 에이전트 강화 학습 기준선을 초과하여 더 빠른 학습 속도와 더 나은 성능을 발휘한다.

Abstract: Monte Carlo Tree Search (MCTS), which leverages Upper Confidence Bound for Trees (UCTs) to balance exploration and exploitation through randomized sampling, is instrumental to solving complex planning problems. However, for multi-agent planning, MCTS is confronted with a large combinatorial action space that often grows exponentially with the number of agents. As a result, the branching factor of MCTS during tree expansion also increases exponentially, making it very difficult to efficiently explore and exploit during tree search. To this end, we propose MALinZero, a new approach to leverage low-dimensional representational structures on joint-action returns and enable efficient MCTS in complex multi-agent planning. Our solution can be viewed as projecting the joint-action returns into the low-dimensional space representable using a contextual linear bandit problem formulation. We solve the contextual linear bandit problem with convex and $μ$-smooth loss functions -- in order to place more importance on better joint actions and mitigate potential representational limitations -- and derive a linear Upper Confidence Bound applied to trees (LinUCT) to enable novel multi-agent exploration and exploitation in the low-dimensional space. We analyze the regret of MALinZero for low-dimensional reward functions and propose an $(1-\tfrac1e)$-approximation algorithm for the joint action selection by maximizing a sub-modular objective. MALinZero demonstrates state-of-the-art performance on multi-agent benchmarks such as matrix games, SMAC, and SMACv2, outperforming both model-based and model-free multi-agent reinforcement learning baselines with faster learning speed and better performance.

</details>


### [40] [CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference](https://arxiv.org/abs/2511.06175)
*Kaijie Xu,Fandi Meng,Clark Verbrugge,Simon Lucas*

Main category: cs.AI

TL;DR: CSP4SDG는 사회적 추론 게임에서 플레이어의 역할 식별을 개선하는 확률적 제약 만족 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 사회적 추론 게임(SDG)에서 역할 식별은 플레이어의 신념 상태의 기초가 되며, 이는 인간과 AI의 성능에 매우 중요하다.

Method: CSP4SDG는 게임 이벤트와 대화를 네 가지 제약 클래스(증거, 현상, 주장, 가설)로 매핑하고, 하드 제약은 불가능한 역할 할당을 제거하며, 가중치가 있는 소프트 제약은 나머지를 점수화한다.

Result: CSP4SDG는 세 가지 공공 데이터셋에서 모든 추론 시나리오에서 LLM 기반 기준선보다 우수한 성능을 보였고, 보조 '추론 도구'로 제공될 때 LLM을 향상시킨다.

Conclusion: 정보 이론을 활용한 원칙적인 확률적 추론은 SDG에 대한 중량 신경 모델의 대안 또는 보완이 될 수 있다.

Abstract: In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary "reasoning tool." Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs.

</details>


### [41] [Dataforge: A Data Agent Platform for Autonomous Data Engineering](https://arxiv.org/abs/2511.06185)
*Xinyuan Wang,Yanjie Fu*

Main category: cs.AI

TL;DR: Data Agent는 표 데이터를 위한 완전 자율 시스템으로, 데이터 준비 과정을 자동화하여 AI 응용 프로그램의 요구를 충족시킨다.


<details>
  <summary>Details</summary>
Motivation: AI 애플리케이션의 수요 증가로 데이터 준비가 중요하지만 노동 집약적인 단계가 되었다.

Method: Data Agent는 대형 언어 모델(LLM)의 추론과 실제 검증을 활용하여 데이터 정리, 계층 라우팅 및 특징 수준 최적화를 자동으로 수행한다.

Result: Data Agent는 AI 준비가 완료된 데이터를 효율적으로 생성하는 것을 가능하게 한다.

Conclusion: 이 데모는 자율적 데이터 에이전트의 첫 번째 실제 구현을 보여주며, 원시 데이터를 '데이터에서 더 나은 데이터로' 변환하는 방법을 설명한다.

Abstract: The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed "From Data to Better Data."

</details>


### [42] [The Station: An Open-World Environment for AI-Driven Discovery](https://arxiv.org/abs/2511.06309)
*Stephen Chung,Wenyu Du*

Main category: cs.AI

TL;DR: STATION은 미니어처 과학 생태계를 모델링한 오픈 월드 다중 에이전트 환경을 소개한다. 에이전트는 자율적으로 행동을 선택하고 내러티브를 발전시키며, 새로운 방법을 유기적으로 생성한다.


<details>
  <summary>Details</summary>
Motivation: STATION은 자율적인 과학적 발견을 위한 첫걸음으로, 오픈 월드 환경에서의 긴 여행을 통한 에이전트 간의 협업을 촉진하고자 한다.

Method: STATION의 에이전트는 확장된 맥락 창을 활용하여 동료의 연구 논문을 읽고, 가설을 수립하며, 코드를 제출하고 분석을 수행하고 결과를 발표하는 등 긴 과학적 여정을 수행한다.

Result: STATION의 AI 에이전트는 다양한 벤치마크에서 새로운 최첨단 성과를 달성하며, 특히 원형 포장 문제에서 AlphaEvolve를 능가한다.

Conclusion: STATION은 오픈 월드 환경에서 emergent behavior에 의해 이끄는 자율적인 과학적 발견으로 나아가는 새로운 패러다임을 나타낸다.

Abstract: We introduce the STATION, an open-world multi-agent environment that models a miniature scientific ecosystem. Leveraging their extended context windows, agents in the Station can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, submitting code, performing analyses, and publishing results. Importantly, there is no centralized system coordinating their activities - agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning from mathematics to computational biology to machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of narratives emerges as agents pursue independent research, interact with peers, and build upon a cumulative history. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid optimization.

</details>


### [43] [Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B](https://arxiv.org/abs/2511.06221)
*Sen Xu,Yi Zhou,Wei Wang,Jixin Min,Zhibin Yin,Yingwei Dai,Shixi Liu,Lianyu Pang,Yirong Chen,Junlin Zhang*

Main category: cs.AI

TL;DR: VibeThinker-1.5B 모델은 1.5B 파라미터를 가진 밀집 모델로, 소규모 모델의 추론 능력을 입증하여 큰 모델과 동등한 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 작은 모델이 본질적으로 강력한 추론 능력이 결여되어 있다는 일반적인 합의에 도전하기 위해.

Method: Spectrum-to-Signal Principle (SSP)을 기반으로 하는 Two-Stage Diversity-Exploring Distillation(SFT)와 MaxEnt-Guided Policy Optimization(RL) 기법을 사용하여 훈련한다.

Result: VibeThinker-1.5B는 다양한 수학 벤치마크에서 400배 더 큰 모델인 DeepSeek R1을 초월하며, 각종 모델들보다 나은 추론 능력을 발휘한다.

Conclusion: 작은 모델도 큰 모델과 동등한 추론 능력을 가지고 있으며, 훈련 및 추론 비용을 크게 줄여 고급 AI 연구의 민주화를 이룰 수 있음을 보여준다.

Abstract: Challenging the prevailing consensus that small models inherently lack robust reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense model developed via our Spectrum-to-Signal Principle (SSP). This challenges the prevailing approach of scaling model parameters to enhance capabilities, as seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL) to amplify the correct signal. With a total training cost of only $7,800, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models like Magistral Medium and Claude Opus 4, and performs on par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial improvement over its base model (6.7, 4.3, and 0.6, respectively). On LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its base model's 0.0. These findings demonstrate that small models can achieve reasoning capabilities comparable to large models, drastically reducing training and inference costs and thereby democratizing advanced AI research.

</details>


### [44] [ROAR: Robust Accident Recognition and Anticipation for Autonomous Driving](https://arxiv.org/abs/2511.06226)
*Xingcheng Liu,Yanchen Guan,Haicheng Liao,Zhengbing He,Zhenning Li*

Main category: cs.AI

TL;DR: 이 연구는 자율주행차의 사고 예측 및 탐지를 위한 새로운 접근법인 ROAR를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자율주행차의 안전성을 높이기 위한 정확한 사고 예측이 필수적이며, 기존 방법들은 센서 실패와 환경 방해 등 현실적인 도전을 간과했습니다.

Method: ROAR은 이산 웨이블릿 변환(DWT), 자기 적응형 객체 인식 모듈, 동적 초점 손실을 결합하여 사고 예측의 정확성을 향상시킵니다.

Result: 우리는 DAD, CCD, A3D의 세 가지 데이터셋에서 모델이 기존 기준을 지속적으로 초월한다는 것을 발견했습니다.

Conclusion: 이 연구는 복잡한 교통 환경에서 신뢰할 수 있는 사고 예측 솔루션을 제공합니다.

Abstract: Accurate accident anticipation is essential for enhancing the safety of autonomous vehicles (AVs). However, existing methods often assume ideal conditions, overlooking challenges such as sensor failures, environmental disturbances, and data imperfections, which can significantly degrade prediction accuracy. Additionally, previous models have not adequately addressed the considerable variability in driver behavior and accident rates across different vehicle types. To overcome these limitations, this study introduces ROAR, a novel approach for accident detection and prediction. ROAR combines Discrete Wavelet Transform (DWT), a self adaptive object aware module, and dynamic focal loss to tackle these challenges. The DWT effectively extracts features from noisy and incomplete data, while the object aware module improves accident prediction by focusing on high-risk vehicles and modeling the spatial temporal relationships among traffic agents. Moreover, dynamic focal loss mitigates the impact of class imbalance between positive and negative samples. Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently outperforms existing baselines in key metrics such as Average Precision (AP) and mean Time to Accident (mTTA). These results demonstrate the model's robustness in real-world conditions, particularly in handling sensor degradation, environmental noise, and imbalanced data distributions. This work offers a promising solution for reliable and accurate accident anticipation in complex traffic environments.

</details>


### [45] [Agentic AI Sustainability Assessment for Supply Chain Document Insights](https://arxiv.org/abs/2511.07097)
*Diego Gosmar,Anna Chiara Pallotta,Giovanni Zenezini*

Main category: cs.AI

TL;DR: 이 논문은 공급망 운영에서 문서 지능을 위한 포괄적인 지속 가능성 평가 프레임워크를 제시하며, 에이전틱 인공지능(AI)을 중심으로 한다.


<details>
  <summary>Details</summary>
Motivation: 자동화 효율성을 개선하면서도 문서 집약적 워크플로우에서 측정 가능한 환경 성능을 제공하는 이중 목표를 해결하고자 한다.

Method: 세 가지 시나리오: 완전 수동(사람만), AI 지원(인간-루프 내), 고급 다중 에이전트 에이전틱 AI 워크플로우를 비교한다.

Result: AI 지원 시나리오와 에이전틱 AI 시나리오가 수동 프로세스에 비해 에너지 소비를 최대 70-90%, 이산화탄소 배출을 90-97%, 물 사용량을 89-98% 줄이는 것을 보여준다.

Conclusion: 진전된 추론 모드와 다중 에이전트 검증을 결합한 완전 에이전틱 구성은 단순한 AI 지원 솔루션에 비해 자원 사용이 약간 증가하더라도 인간만의 접근 방식에 비해 상당한 지속 가능성 이득을 달성한다.

Abstract: This paper presents a comprehensive sustainability assessment framework for document intelligence within supply chain operations, centered on agentic artificial intelligence (AI). We address the dual objective of improving automation efficiency while providing measurable environmental performance in document-intensive workflows. The research compares three scenarios: fully manual (human-only), AI-assisted (human-in-the-loop, HITL), and an advanced multi-agent agentic AI workflow leveraging parsers and verifiers. Empirical results show that AI-assisted HITL and agentic AI scenarios achieve reductions of up to 70-90% in energy consumption, 90-97% in carbon dioxide emissions, and 89-98% in water usage compared to manual processes. Notably, full agentic configurations, combining advanced reasoning (thinking mode) and multi-agent validation, achieve substantial sustainability gains over human-only approaches, even when resource usage increases slightly versus simpler AI-assisted solutions. The framework integrates performance, energy, and emission indicators into a unified ESG-oriented methodology for assessing and governing AI-enabled supply chain solutions. The paper includes a complete replicability use case demonstrating the methodology's application to real-world document extraction tasks.

</details>


### [46] [GAIA: A General Agency Interaction Architecture for LLM-Human B2B Negotiation & Screening](https://arxiv.org/abs/2511.06262)
*Siming Zhao,Qi Li*

Main category: cs.AI

TL;DR: 이 논문은 B2B 협상에서 AI 시스템의 위임에 대한 governance-first 프레임워크인 GAIA를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 조직들은 AI 시스템에 스크리닝 및 협상 업무를 위임하려고 하지만, 고위험 B2B 환경에서의 배치는 거버넌스에 의해 제한된다.

Method: GAIA는 세 가지 필수 역할(인간, LLM 에이전트, 상대방)을 정의하고 세 가지 상호작용 메커니즘을 조직한다.

Result: GAIA는 안전하고 효율적이며 책임 있는 AI 위임을 위한 재현 가능한 사양을 제공한다.

Conclusion: GAIA는 조달, 부동산 및 인력 작업에서 적용될 수 있는 솔루션이다.

Abstract: Organizations are increasingly exploring delegation of screening and negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is constrained by governance: preventing unauthorized commitments, ensuring sufficient information before bargaining, and maintaining effective human oversight and auditability. Prior work on large language model negotiation largely emphasizes autonomous bargaining between agents and omits practical needs such as staged information gathering, explicit authorization boundaries, and systematic feedback integration. We propose GAIA, a governance-first framework for LLM-human agency in B2B negotiation and screening. GAIA defines three essential roles - Principal (human), Delegate (LLM agent), and Counterparty - with an optional Critic to enhance performance, and organizes interactions through three mechanisms: information-gated progression that separates screening from negotiation; dual feedback integration that combines AI critique with lightweight human corrections; and authorization boundaries with explicit escalation paths. Our contributions are fourfold: (1) a formal governance framework with three coordinated mechanisms and four safety invariants for delegation with bounded authorization; (2) information-gated progression via task-completeness tracking (TCI) and explicit state transitions that separate screening from commitment; (3) dual feedback integration that blends Critic suggestions with human oversight through parallel learning channels; and (4) a hybrid validation blueprint that combines automated protocol metrics with human judgment of outcomes and safety. By bridging theory and practice, GAIA offers a reproducible specification for safe, efficient, and accountable AI delegation that can be instantiated across procurement, real estate, and staffing workflows.

</details>


### [47] [Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations](https://arxiv.org/abs/2511.07204)
*Giacomo Fidone,Lucia Passaro,Riccardo Guidotti*

Main category: cs.AI

TL;DR: 본 논문은 LLM 기반의 OSN 대화 시뮬레이터를 설계하여 콘텐츠 조절의 효과를 평가하는 새로운 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 사회 네트워크에서의 유해하고 독성 있는 담론의 확산을 억제하기 위한 콘텐츠 조절의 실제 효과를 명확히 이해할 필요가 있다.

Method: LLM을 활용하여 OSN 대화의 시뮬레이터를 설계하고, 콘텐츠 조절 개입이 유해한 행동에 미치는 영향을 반영하는 대조적 시뮬레이션을 수행한다.

Result: 광범위한 실험을 통해 OSN 에이전트의 심리적 현실성, 사회적 전염 현상의 나타남, 개인화된 조절 전략의 탁월한 효과를 밝혀냈다.

Conclusion: 이 연구는 콘텐츠 조절의 효과성을 이해하는 데 기여하고, 향후 연구에 중요한 통찰력을 제공한다.

Abstract: Online Social Networks (OSNs) widely adopt content moderation to mitigate the spread of abusive and toxic discourse. Nonetheless, the real effectiveness of moderation interventions remains unclear due to the high cost of data collection and limited experimental control. The latest developments in Natural Language Processing pave the way for a new evaluation approach. Large Language Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and simulate human-like social behavior with unprecedented degree of believability. Yet, existing tools do not support simulation-based evaluation of moderation strategies. We fill this gap by designing a LLM-powered simulator of OSN conversations enabling a parallel, counterfactual simulation where toxic behavior is influenced by moderation interventions, keeping all else equal. We conduct extensive experiments, unveiling the psychological realism of OSN agents, the emergence of social contagion phenomena and the superior effectiveness of personalized moderation strategies.

</details>


### [48] [AUTO-Explorer: Automated Data Collection for GUI Agent](https://arxiv.org/abs/2511.06417)
*Xiangwu Guo,Difei Gao,Mike Zheng Shou*

Main category: cs.AI

TL;DR: Auto-Explorer라는 새로운 자동화 데이터 수집 방법을 제안하여 GUI 에이전트의 효율적인 데이터 수집을 가능하게 하고, UIXplore 벤치마크를 통해 탐사의 품질을 평가한다.


<details>
  <summary>Details</summary>
Motivation: GUI 데이터 수집의 어려움을 해결하고, 개인화된 시나리오에 빠르게 적응할 수 있는 방법을 찾는다.

Method: 자동으로 GUI 환경을 파싱하고 탐색하는 간단하지만 효과적인 메커니즘을 포함한 Auto-Explorer를 제안한다.

Result: Auto-Explorer는 MLLM의 능력을 신속하게 향상시키는 우수한 성능을 보여준다.

Conclusion: 자동화된 데이터 수집 방법이 GUI 에이전트의 발전에 기여할 수 있음을 입증하였다.

Abstract: Recent advancements in GUI agents have significantly expanded their ability to interpret natural language commands to manage software interfaces. However, acquiring GUI data remains a significant challenge. Existing methods often involve designing automated agents that browse URLs from the Common Crawl, using webpage HTML to collect screenshots and corresponding annotations, including the names and bounding boxes of UI elements. However, this method is difficult to apply to desktop software or some newly launched websites not included in the Common Crawl. While we expect the model to possess strong generalization capabilities to handle this, it is still crucial for personalized scenarios that require rapid and perfect adaptation to new software or websites. To address this, we propose an automated data collection method with minimal annotation costs, named Auto-Explorer. It incorporates a simple yet effective exploration mechanism that autonomously parses and explores GUI environments, gathering data efficiently. Additionally, to assess the quality of exploration, we have developed the UIXplore benchmark. This benchmark creates environments for explorer agents to discover and save software states. Using the data gathered, we fine-tune a multimodal large language model (MLLM) and establish a GUI element grounding testing set to evaluate the effectiveness of the exploration strategies. Our experiments demonstrate the superior performance of Auto-Explorer, showing that our method can quickly enhance the capabilities of an MLLM in explored software.

</details>


### [49] [Brain-Inspired Planning for Better Generalization in Reinforcement Learning](https://arxiv.org/abs/2511.06470)
*Mingde "Harry" Zhao*

Main category: cs.AI

TL;DR: 본 논문은 RL 에이전트의 제로샷 체계적 일반화 능력을 향상시키기 위한 방향을 탐구하며, 인간의 사고 행동에서 영감을 받아 제안된 방법론을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 RL 시스템은 훈련 조건과 다른 환경에서의 일반화 문제로 인해 실제 시나리오에서 심각한 도전에 직면하고 있습니다.

Method: 우리는 상위-하위 주의 메커니즘을 도입하여 결정 순간의 계획 행위가 환경 상태의 관련성 높은 측면에 동적으로 집중하도록 하며, 이 과정을 '공간 추상화'라고 합니다. 이 방법을 통해 복잡한 작업을 더 단순하고 관리 가능한 하위 작업으로 자동으로 분해할 수 있도록 Skipper 프레임워크를 개발하였습니다.

Result: Skipper는 분포 변화에 대한 강인성과 장기적인 구성 계획에서의 효능을 제공합니다.

Conclusion: 우리는 계획 중 생성 모델에 의존하는 계획 에이전트의 일반적인 실패 모드와 안전 위험을 확인했으며, 계획 에이전트에 대한 환각된 비현실적인 목표를 거부할 수 있도록 가능성 평가자를 학습하는 방법을 제안하고 있습니다.

Abstract: Existing Reinforcement Learning (RL) systems encounter significant challenges when applied to real-world scenarios, primarily due to poor generalization across environments that differ from their training conditions. This thesis explores the direction of enhancing agents' zero-shot systematic generalization abilities by granting RL agents reasoning behaviors that are found to help systematic generalization in the human brain. Inspired by human conscious planning behaviors, we first introduced a top-down attention mechanism, which allows a decision-time planning agent to dynamically focus its reasoning on the most relevant aspects of the environmental state given its instantaneous intentions, a process we call "spatial abstraction". This approach significantly improves systematic generalization outside the training tasks. Subsequently, building on spatial abstraction, we developed the Skipper framework to automatically decompose complex tasks into simpler, more manageable sub-tasks. Skipper provides robustness against distributional shifts and efficacy in long-term, compositional planning by focusing on pertinent spatial and temporal elements of the environment. Finally, we identified a common failure mode and safety risk in planning agents that rely on generative models to generate state targets during planning. It is revealed that most agents blindly trust the targets they hallucinate, resulting in delusional planning behaviors. Inspired by how the human brain rejects delusional intentions, we propose learning a feasibility evaluator to enable rejecting hallucinated infeasible targets, which led to significant performance improvements in various kinds of planning agents. Finally, we suggest directions for future research, aimed at achieving general task abstraction and fully enabling abstract planning.

</details>


### [50] [Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives](https://arxiv.org/abs/2511.06626)
*Chloe Li,Mary Phuong,Daniel Tan*

Main category: cs.AI

TL;DR: AI 시스템이 복잡한 작업을 수행할 수록 바람직하지 않은 목표를 추구하고 해를 끼칠 가능성이 높아진다. 우리는 모델이 사실적 오류를 인정하도록 훈련시키는 자기 보고 미세 조정 기법(SRFT)을 제안하고, 이 방식이 모델이 숨겨진 비정렬 목표를 고백하는 데 효과적임을 증명한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 능력이 증가함에 따라 바람직하지 않은 목표를 추구하고 해를 끼칠 가능성도 높아진다. 이로 인해 AI 모델의 투명성을 확보할 필요성이 제기된다.

Method: 자기 보고 미세 조정(SRFT) 기법을 사용하여 모델이 질문에 대해 사실적 실수를 인정하도록 훈련한다.

Result: SRFT를 적용한 모델들이 감시를 피하면서 사용자가 지정한 목표 외에 숨겨진 목표를 수행하는 가운데, 비밀 목표의 세부 사항을 고백할 가능성이 높아졌다. SRFT를 적용한 모델은 면담 시 숨겨진 목표를 거의 완벽하게 탐지할 수 있다.

Conclusion: SRFT 기법은 비정렬 AI 시스템의 정직성을 촉진하고 해를 끼칠 가능성을 줄이는 데 유망한 방법임을 보여준다.

Abstract: As AI systems become more capable of complex agentic tasks, they also become more capable of pursuing undesirable objectives and causing harm. Previous work has attempted to catch these unsafe instances by interrogating models directly about their objectives and behaviors. However, the main weakness of trusting interrogations is that models can lie. We propose self-report fine-tuning (SRFT), a simple supervised fine-tuning technique that trains models to admit their factual mistakes when asked. We show that the admission of factual errors in simple question-answering settings generalizes out-of-distribution (OOD) to the admission of hidden misaligned objectives in adversarial agentic settings. We evaluate SRFT in OOD stealth tasks, where models are instructed to complete a hidden misaligned objective alongside a user-specified objective without being caught by monitoring. After SRFT, models are more likely to confess the details of their hidden objectives when interrogated, even under strong pressure not to disclose them. Interrogation on SRFT models can detect hidden objectives with near-ceiling performance (F1 score = 0.98), while the baseline model lies when interrogated under the same conditions (F1 score = 0). Interrogation on SRFT models can further elicit the content of the hidden objective, recovering 28-100% details, compared to 0% details recovered in the baseline model and by prefilled assistant turn attacks. This provides a promising technique for promoting honesty propensity and incriminating misaligned AI systems.

</details>


### [51] [Improving Region Representation Learning from Urban Imagery with Noisy Long-Caption Supervision](https://arxiv.org/abs/2511.07062)
*Yimei Zhang,Guojiang Shen,Kaili Ning,Tongwei Ren,Xuebo Qiu,Mengmeng Wang,Xiangjie Kong*

Main category: cs.AI

TL;DR: 이 논문은 UrbanLN이라는 새로운 사전 훈련 프레임워크를 제안하여 도시 지역 표현 학습을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 도시 데이터에서 의미 있는 특징을 추출하는 것이 도시 컴퓨팅에서 중요한 역할을 합니다.

Method: UrbanLN을 통해 긴 텍스트 인식 및 노이즈 억제를 통한 도시 지역 표현 학습을 개선합니다.

Result: 다양한 실제 도시와 하위 작업에 대한 실험에서 UrbanLN의 우수한 성능을 입증합니다.

Conclusion: 이 연구는 LLM-생성 캡션으로부터의 지식 탐색과 노이즈 필터링을 위한 이중 레벨 최적화 전략을 제안합니다.

Abstract: Region representation learning plays a pivotal role in urban computing by extracting meaningful features from unlabeled urban data. Analogous to how perceived facial age reflects an individual's health, the visual appearance of a city serves as its ``portrait", encapsulating latent socio-economic and environmental characteristics. Recent studies have explored leveraging Large Language Models (LLMs) to incorporate textual knowledge into imagery-based urban region representation learning. However, two major challenges remain: i)~difficulty in aligning fine-grained visual features with long captions, and ii) suboptimal knowledge incorporation due to noise in LLM-generated captions. To address these issues, we propose a novel pre-training framework called UrbanLN that improves Urban region representation learning through Long-text awareness and Noise suppression. Specifically, we introduce an information-preserved stretching interpolation strategy that aligns long captions with fine-grained visual semantics in complex urban scenes. To effectively mine knowledge from LLM-generated captions and filter out noise, we propose a dual-level optimization strategy. At the data level, a multi-model collaboration pipeline automatically generates diverse and reliable captions without human intervention. At the model level, we employ a momentum-based self-distillation mechanism to generate stable pseudo-targets, facilitating robust cross-modal learning under noisy conditions. Extensive experiments across four real-world cities and various downstream tasks demonstrate the superior performance of our UrbanLN.

</details>


### [52] [LLM Driven Processes to Foster Explainable AI](https://arxiv.org/abs/2511.07086)
*Marcel Pehlke,Marc Jansen*

Main category: cs.AI

TL;DR: 본 논문에서는 감사 가능한 산출물로 추론을 외부화하는 모듈화된 설명 가능한 LLM-에이전트 파이프라인을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 결정 지원 시스템 내에서 투명하고 설명 가능한 프로세스를 구현하기 위해.

Method: Vester의 민감도 모델, 정규형 게임, 순차 게임의 세 가지 프레임워크를 통합하여 각 단계에서 교환 가능한 모듈로 설정하였습니다.

Result: 실제 물류 사례에서 100회 실행 시 평균 요인 정렬이 55.5%였고, 운송 핵심 부분집합에서는 62.9%였습니다; 역할 일치는 57%였습니다.

Conclusion: 구성 가능 LLM 파이프라인으로 전문가 작업 흐름을 투명하고 검토 가능한 단계로 모방할 수 있습니다.

Abstract: We present a modular, explainable LLM-agent pipeline for decision support that externalizes reasoning into auditable artifacts. The system instantiates three frameworks: Vester's Sensitivity Model (factor set, signed impact matrix, systemic roles, feedback loops); normal-form games (strategies, payoff matrix, equilibria); and sequential games (role-conditioned agents, tree construction, backward induction), with swappable modules at every step. LLM components (default: GPT-5) are paired with deterministic analyzers for equilibria and matrix-based role classification, yielding traceable intermediates rather than opaque outputs. In a real-world logistics case (100 runs), mean factor alignment with a human baseline was 55.5\% over 26 factors and 62.9\% on the transport-core subset; role agreement over matches was 57\%. An LLM judge using an eight-criterion rubric (max 100) scored runs on par with a reconstructed human baseline. Configurable LLM pipelines can thus mimic expert workflows with transparent, inspectable steps.

</details>


### [53] [Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture](https://arxiv.org/abs/2511.07110)
*Tianhao Fu,Xinxin Xu,Weichen Xu,Jue Chen,Ruilong Ren,Bowen Deng,Xinyu Zhao,Jian Cao,Xixin Cao*

Main category: cs.AI

TL;DR: 이 논문은 LLM(대형 언어 모델)에서의 특징을 활용하여 협력 시장 조성(CMM) 프레임워크를 제안하고, 이를 통해 시장 조성의 성능을 개선하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 시장에서의 빠른 의사결정과 강화 학습을 통한 시장 조성의 필요성이 커지고 있습니다.

Method: 정상화된 형광 탐침을 제안하고, LLM의 기능을 세 가지 차원에서 분리하여 협력 시장 조성(CMM) 프레임워크를 구축합니다. 각 학생 모델이 특정 기능을 학습하도록 하여 지식 증류를 달성합니다.

Result: CMM은 기존의 증류 방법과 RL 기반의 시장 조성 전략에 비해 우수한 성능을 보입니다.

Conclusion: 네 가지 실제 시장 데이터셋에서의 광범위한 실험 결과가 CMM의 우수성을 입증합니다.

Abstract: Market making (MM) through Reinforcement Learning (RL) has attracted significant attention in financial trading. With the development of Large Language Models (LLMs), more and more attempts are being made to apply LLMs to financial areas. A simple, direct application of LLM as an agent shows significant performance. Such methods are hindered by their slow inference speed, while most of the current research has not studied LLM distillation for this specific task. To address this, we first propose the normalized fluorescent probe to study the mechanism of the LLM's feature. Based on the observation found by our investigation, we propose Cooperative Market Making (CMM), a novel framework that decouples LLM features across three orthogonal dimensions: layer, task, and data. Various student models collaboratively learn simple LLM features along with different dimensions, with each model responsible for a distinct feature to achieve knowledge distillation. Furthermore, CMM introduces an Hájek-MoE to integrate the output of the student models by investigating the contribution of different models in a kernel function-generated common feature space. Extensive experimental results on four real-world market datasets demonstrate the superiority of CMM over the current distillation method and RL-based market-making strategies.

</details>


### [54] [PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork](https://arxiv.org/abs/2511.07260)
*Hohei Chan,Xinzhi Zhang,Antao Xiang,Weinan Zhang,Mengchen Zhao*

Main category: cs.AI

TL;DR: PADiff는 에이전트의 다중 모드 행동을 캡처하여 새로운 팀원들과의 협력을 촉진하는 확산 기반 접근 방식으로, 기존 AHT 방법보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: AHT는 이전에 본 적 없는 팀원들과의 협력을 요구하므로 많은 실제 응용 프로그램에 필수적이다.

Method: PADiff는 에이전트의 다중 모드 행동을 포착하는 확산 기반 접근 방식으로, 팀원에 대한 예측 정보를 탈잡음 과정에 통합하여 비정상적인 AHT 시나리오에서 예측 및 적응 능력을 개선한다.

Result: 세 가지 협력 환경에서의 실험을 통한 결과, PADiff가 기존 AHT 방법보다 상당히 우수한 성능을 보였다.

Conclusion: PADiff는 팀원과의 다양한 협력 모드를 활용하여 AHT 문제를 해결하는 데 효과적인 접근 방식을 제공한다.

Abstract: Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen teammates, which is crucial for many real-world applications. The core challenge of AHT is to develop an ego agent that can predict and adapt to unknown teammates on the fly. Conventional RL-based approaches optimize a single expected return, which often causes policies to collapse into a single dominant behavior, thus failing to capture the multimodal cooperation patterns inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach that captures agent's multimodal behaviors, unlocking its diverse cooperation modes with teammates. However, standard diffusion models lack the ability to predict and adapt in highly non-stationary AHT scenarios. To address this limitation, we propose a novel diffusion-based policy that integrates critical predictive information about teammates into the denoising process. Extensive experiments across three cooperation environments demonstrate that PADiff outperforms existing AHT methods significantly.

</details>


### [55] [AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning](https://arxiv.org/abs/2511.07262)
*Qile Jiang,George Karniadakis*

Main category: cs.AI

TL;DR: AgenticSciML은 10개 이상의 AI 에이전트가 협력하여 SciML 솔루션을 제안, 비판 및 개선하는 다중 에이전트 시스템을 소개한다.


<details>
  <summary>Details</summary>
Motivation: SciML 아키텍처, 손실 공식 및 훈련 전략의 설계는 전문가 중심의 연구 과정으로, 광범위한 실험과 문제-specific 통찰이 필요하다.

Method: 협력적인 다중 에이전트 시스템을 통해 구조화된 추론과 반복적 진화를 통해 SciML 솔루션을 제안하고 적합성을 평가한다.

Result: 프레임워크는 단일 에이전트 및 인간 설계 기준보다 최대 4배의 오류 감소로 성능을 향상시키는 솔루션 방법을 발견한다.

Conclusion: AI 에이전트 간의 협력적 추론이 방법론적 혁신을 촉진할 수 있음을 보여준다.

Abstract: Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing.

</details>


### [56] [Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion](https://arxiv.org/abs/2511.07267)
*Chen Han,Yijia Ma,Jin Tan,Wenzhen Zheng,Xijin Tang*

Main category: cs.AI

TL;DR: 본 연구에서는 여러 에이전트간 논쟁(MAD) 프레임워크를 증거 기반으로 확장한 ED2D를 소개하며, 이는 사용자 신념 수정과 허위정보 공유 억제를 목표로 하는 설득적 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 허위정보 탐지 연구는 탐지 정확성에 중점을 두었으나, 사용자가 사실적 판단 뒤에 있는 추론을 이해하고 미래의 회복력을 발전시키는 데 필요한 부분을 간과했다.

Method: ED2D는 사실적 증거 검색을 통합한 증거 기반 MAD 프레임워크로, 이전 접근 방식을 확장하여 설득적 다중 에이전트 시스템으로 설계됐다.

Result: ED2D는 세 가지 허위정보 탐지 벤치마크에서 기존 기준을 초과하는 성과를 보여주었으며, ED2D가 올바른 예측을 할 경우 그 반박 전사는 전문가 수준의 설득력을 가진다.

Conclusion: MAD 시스템을 통해 허위정보 개입을 배치하는 것은 잠재적 위험과 약속을 모두 지니고 있으며, 공공 커뮤니티 웹사이트를 통해 사용자들이 ED2D를 탐색할 수 있도록 지원한다.

Abstract: Multi-agent debate (MAD) frameworks have emerged as promising approaches for misinformation detection by simulating adversarial reasoning. While prior work has focused on detection accuracy, it overlooks the importance of helping users understand the reasoning behind factual judgments and develop future resilience. The debate transcripts generated during MAD offer a rich but underutilized resource for transparent reasoning. In this study, we introduce ED2D, an evidence-based MAD framework that extends previous approach by incorporating factual evidence retrieval. More importantly, ED2D is designed not only as a detection framework but also as a persuasive multi-agent system aimed at correcting user beliefs and discouraging misinformation sharing. We compare the persuasive effects of ED2D-generated debunking transcripts with those authored by human experts. Results demonstrate that ED2D outperforms existing baselines across three misinformation detection benchmarks. When ED2D generates correct predictions, its debunking transcripts exhibit persuasive effects comparable to those of human experts; However, when ED2D misclassifies, its accompanying explanations may inadvertently reinforce users'misconceptions, even when presented alongside accurate human explanations. Our findings highlight both the promise and the potential risks of deploying MAD systems for misinformation intervention. We further develop a public community website to help users explore ED2D, fostering transparency, critical thinking, and collaborative fact-checking.

</details>


### [57] [IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction](https://arxiv.org/abs/2511.07327)
*Guoxin Chen,Zile Qiao,Xuanzhong Chen,Donglei Yu,Haotian Xu,Wayne Xin Zhao,Ruihua Song,Wenbiao Yin,Huifeng Yin,Liwen Zhang,Kuan Li,Minpeng Liao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.AI

TL;DR: IterResearch는 긴 수평 연구를 마르코프 결정 프로세스로 재구성한 혁신적인 딥 리서치 패러다임으로, 탐색 깊이에 따라 일관된 추론 능력을 유지하고, 효율적인 탐색을 촉진하기 위해 EAPO라는 강화 학습 프레임워크를 추가하여 기존 에이전트에 비해 상당한 성과를 달성했다.


<details>
  <summary>Details</summary>
Motivation: 기존의 단일 맥락 패러다임이 긴 수평 작업에서 효과를 제한하는 상황을 해결하기 위해.

Method: IterResearch는 마르코프 결정 프로세스와 전략적 작업 공간 재구성을 활용하여 긴 수평 연구를 재구성하고, 지속적으로 메모리로서 발전하는 보고서를 유지하며 인사이트를 정기적으로 종합한다.

Result: IterResearch는 평균 +14.5pp의 개선을 보였고, 2048 회 상호작용에서 성능 향상을 이루었다.

Conclusion: IterResearch는 긴 수평 추론을 위한 다목적 솔루션으로 자리매김했다.

Abstract: Recent advances in deep-research agents have shown promise for autonomous knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon tasks. We introduce IterResearch, a novel iterative deep-research paradigm that reformulates long-horizon research as a Markov Decision Process with strategic workspace reconstruction. By maintaining an evolving report as memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. We further develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning framework that incentivizes efficient exploration through geometric reward discounting and enables stable distributed training via adaptive downsampling. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5\% to 42.5\%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct on long-horizon tasks. These findings position IterResearch as a versatile solution for long-horizon reasoning, effective both as a trained agent and as a prompting paradigm for frontier models.

</details>


### [58] [DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas](https://arxiv.org/abs/2511.07338)
*Zhen Wang,Yufan Zhou,Zhongyan Luo,Lyumanshan Ye,Adam Wood,Man Yao,Luoshang Pan*

Main category: cs.AI

TL;DR: DEEPPERSONA는 고유한 인격을 갖춘 합성 인물을 생성하여 인공지능과의 정렬을 촉진하는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 합성 인물들이 얕고 단순하여 실제 인간 정체성을 반영하지 못하는 문제를 해결하고자 한다.

Method: DEEPPERSONA는 두 단계의 분류에 따른 방법을 사용하여 방대한 인간 속성 분류체계를 구축하고, 속성을 점진적으로 샘플링하여 일관되고 현실적인 인물을 생성한다.

Result: 속성 다양성 및 프로필 독창성을 크게 향상시키며, 개인화된 질문 응답 정확도가 평균 11.6% 증가하고, 사회 조사에서 LLM 시민과 실제 인간 응답 간의 성과 격차를 줄인다.

Conclusion: DEEPPERSONA는 고충실도 인간 시뮬레이션을 위한 엄격하고 확장 가능하며 개인 정보 보호가 보장된 플랫폼을 제공한다.

Abstract: Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.

</details>


### [59] [DigiData: Training and Evaluating General-Purpose Mobile Control Agents](https://arxiv.org/abs/2511.07413)
*Yuxuan Sun,Manchen Wang,Shengyi Qian,William R. Wong,Eric Gan,Pierluca D'Oro,Alejandro Castillejo Munoz,Sneha Silwal,Pedro Matias,Nitin Kamra,Satwik Kottur,Nick Raines,Xuanyi Zhao,Joy Chen,Joseph Greer,Andrea Madotto,Allen Bolourchi,James Valori,Kevin Carlberg,Karl Ridgeway,Joseph Tighe*

Main category: cs.AI

TL;DR: AI 에이전트가 사용자 인터페이스를 제어할 수 있는 능력으로 인해 디지털 기기와의 인간 상호작용을 변화시킬 잠재력이 있다. 이를 가속화하기 위해 고품질 데이터 세트와 강력한 평가 방법이 필수적이다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 발전과 인간-디지털 장치 상호작용 개선을 위한 연구 필요성.

Method: DigiData라는 대규모 고품질 다중 모달 데이터 세트를 소개하고, 모바일 제어 에이전트를 위한 기반으로 구축하였다. 또한, DigiData-Bench라는 실세계 복잡한 작업에 대한 모바일 제어 에이전트를 평가하기 위한 벤치마크를 제시한다.

Result: DigiData는 기존 데이터 세트와 달리 앱 기능에 대한 철저한 탐색을 통해 고안되어 다양성 및 목표 복잡성이 향상되었음을 보여준다. 일반적으로 사용되는 단계 정확도 지표가 모바일 제어 에이전트 평가에 부족하다는 것을 입증하고, 동적 평가 프로토콜과 AI 기반 평가 방법을 제안한다.

Conclusion: 이 연구는 모바일 제어 에이전트의 개발에 크게 기여하여 보다 직관적이고 효과적인 인간-장치 상호작용을 위한 기초를 마련한다.

Abstract: AI agents capable of controlling user interfaces have the potential to transform human interaction with digital devices. To accelerate this transformation, two fundamental building blocks are essential: high-quality datasets that enable agents to achieve complex and human-relevant goals, and robust evaluation methods that allow researchers and practitioners to rapidly enhance agent performance. In this paper, we introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Unlike existing datasets, which derive goals from unstructured interactions, DigiData is meticulously constructed through comprehensive exploration of app features, resulting in greater diversity and higher goal complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks. We demonstrate that the commonly used step-accuracy metric falls short in reliably assessing mobile control agents and, to address this, we propose dynamic evaluation protocols and AI-powered evaluations as rigorous alternatives for agent assessment. Our contributions aim to significantly advance the development of mobile control agents, paving the way for more intuitive and effective human-device interactions.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [60] [HYDRA: A Hybrid Heuristic-Guided Deep Representation Architecture for Predicting Latent Zero-Day Vulnerabilities in Patched Functions](https://arxiv.org/abs/2511.06220)
*Mohammad Farhad,Sabbir Rahman,Shuvalaxmi Dass*

Main category: cs.CR

TL;DR: HYDRA는 패치된 함수에서 잠재적인 제로데이 취약점을 예측하기 위한 하이브리드 심층 표현 아키텍처를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 보안 테스트는 소스 코드의 결함을 빠르게 감지하는 강력한 방법이지만, 패치 후에도 남아 있는 잠재적인 취약점을 놓치는 경우가 많습니다.

Method: HYDRA는 규칙 기반 휴리스틱과 심층 표현 학습을 결합하여 패치 후에도 지속될 수 있는 위험 코드 패턴을 탐지합니다.

Result: HYDRA는 Chrome, Android, ImageMagick의 패치된 함수에서 각각 13.7%, 20.6%, 24%의 잠재적 위험 함수를 예측했습니다.

Conclusion: 이 연구는 HYDRA가 숨겨진 위험을 발견할 수 있는 능력을 보여주며, 소프트웨어 보안 검증을 향상시키고 제로데이 취약점 발견을 지원합니다.

Abstract: Software security testing, particularly when enhanced with deep learning models, has become a powerful approach for improving software quality, enabling faster detection of known flaws in source code. However, many approaches miss post-fix latent vulnerabilities that remain even after patches typically due to incomplete fixes or overlooked issues may later lead to zero-day exploits. In this paper, we propose $HYDRA$, a $Hy$brid heuristic-guided $D$eep $R$epresentation $A$rchitecture for predicting latent zero-day vulnerabilities in patched functions that combines rule-based heuristics with deep representation learning to detect latent risky code patterns that may persist after patches. It integrates static vulnerability rules, GraphCodeBERT embeddings, and a Variational Autoencoder (VAE) to uncover anomalies often missed by symbolic or neural models alone. We evaluate HYDRA in an unsupervised setting on patched functions from three diverse real-world software projects: Chrome, Android, and ImageMagick. Our results show HYDRA predicts 13.7%, 20.6%, and 24% of functions from Chrome, Android, and ImageMagick respectively as containing latent risks, including both heuristic matches and cases without heuristic matches ($None$) that may lead to zero-day vulnerabilities. It outperforms baseline models that rely solely on regex-derived features or their combination with embeddings, uncovering truly risky code variants that largely align with known heuristic patterns. These results demonstrate HYDRA's capability to surface hidden, previously undetected risks, advancing software security validation and supporting proactive zero-day vulnerabilities discovery.

</details>


### [61] [Inside LockBit: Technical, Behavioral, and Financial Anatomy of a Ransomware Empire](https://arxiv.org/abs/2511.06429)
*Felipe Castaño,Constantinos Patsakis,Francesco Zola,Fran Casino*

Main category: cs.CR

TL;DR: LockBit은 2019년의 비공식적인 랜섬웨어 서비스에서 2024년의 가장 두드러진 랜섬웨어 프랜차이즈로 진화했다. 본 연구는 LockBit의 기술적, 행동적 및 재정적 구조를 전방위적으로 재구성하며, MITRE ATT&CK에 다양한 전술과 절차를 매핑하고, 협상 채팅 로그 분석 및 비트코인 주소 추적을 통해 LockBit의 이중 착취 전략 및 현금화 데이터를 드러낸다.


<details>
  <summary>Details</summary>
Motivation: LockBit의 발전과 신뢰성 있는 랜섬웨어 프랜차이즈로의 변모를 이해하기 위해.

Method: LockBit의 관리 패널에서 유출된 MySQL 덤프를 활용하여 기술적, 행동적, 재정적 구조를 재구성하고, 협상 채팅 로그를 분석하며, 비트코인 지갑 주소를 추적함.

Result: LockBit 3.0과 그 이전 버전들 사이의 점진적 강화를 강조하고, 이중 착취 전략을 뒷받침하는 수사적 단계를 드러내며, 두 개의 비트코인 수집 주소 기반의 서로 다른 현금화 패턴을 식별함.

Conclusion: LockBit은 신속한 코드 반복, 스크립트 기반의 사회 공학, 대규모 현금화 파이프라인을 바탕으로 한 통합된 범죄 서비스로서의 특성을 지닌다.

Abstract: LockBit has evolved from an obscure Ransomware-as-a-Service newcomer in 2019 to the most prolific ransomware franchise of 2024. Leveraging a recently leaked MySQL dump of the gang's management panel, this study offers an end-to-end reconstruction of LockBit's technical, behavioral, and financial apparatus. We recall the family's version timeline and map its tactics, techniques, and procedures to MITRE ATT&CK, highlighting the incremental hardening that distinguishes LockBit 3.0 from its predecessors. We then analyze 51 negotiation chat logs using natural-language embeddings and clustering to infer a canonical interaction playbook, revealing recurrent rhetorical stages that underpin the double-extortion strategy. Finally, we trace 19 Bitcoin addresses related to ransom payment chains, revealing two distinct patterns based on different laundering phases. In both cases, a small portion of the ransom is immediately split into long-lived addresses (presumably retained by the group as profit and to finance further operations) while the remainder is ultimately aggregated into two high-volume addresses before likely being sent to the affiliate. These two collector addresses appear to belong to distinct exchanges, each processing over 200k BTC. The combined evidence portrays LockBit as a tightly integrated criminal service whose resilience rests on rapid code iteration, script-driven social engineering, and industrial-scale cash-out pipelines.

</details>


### [62] [SteganoSNN: SNN-Based Audio-in-Image Steganography with Encryption](https://arxiv.org/abs/2511.06573)
*Biswajit Kumar Sahoo,Pedro Machado,Isibor Kennedy Ihianle,Andreas Oikonomou,Srinivas Boppu*

Main category: cs.CR

TL;DR: SteganoSNN은 저전력 및 고용량 멀티미디어 데이터 숨기기를 위한 뉴로모픽 스테가노그래픽 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 디지털 통신에서 안전한 데이터 숨기기는 계산 효율성과 지각적 투명성 간의 균형을 요구합니다.

Method: 스파이크 뉴럴 네트워크(SNN)를 이용하여 디지털 오디오 샘플을 스파이크 열로 변환하고, 모듈로 기반 맵핑 기법으로 암호화한 후, RGBA 이미지 채널의 최소 유의 비트에 삽입합니다.

Result: 실험 결과, PSNR 값은 40.4 dB에서 41.35 dB 사이이며 SSIM 값은 0.97 이상으로, SteganoGAN보다 계산 효율성과 강건성을 초과합니다.

Conclusion: SteganoSNN은 Edge-AI, IoT 및 생의학 응용 분야를 위한 안전하고 에너지 효율적인 통신을 가능하게 하는 뉴로모픽 스테가노그래피의 기초를 구축합니다.

Abstract: Secure data hiding remains a fundamental challenge in digital communication, requiring a careful balance between computational efficiency and perceptual transparency. The balance between security and performance is increasingly fragile with the emergence of generative AI systems capable of autonomously generating and optimising sophisticated cryptanalysis and steganalysis algorithms, thereby accelerating the exposure of vulnerabilities in conventional data-hiding schemes.
  This work introduces SteganoSNN, a neuromorphic steganographic framework that exploits spiking neural networks (SNNs) to achieve secure, low-power, and high-capacity multimedia data hiding. Digitised audio samples are converted into spike trains using leaky integrate-and-fire (LIF) neurons, encrypted via a modulo-based mapping scheme, and embedded into the least significant bits of RGBA image channels using a dithering mechanism to minimise perceptual distortion. Implemented in Python using NEST and realised on a PYNQ-Z2 FPGA, SteganoSNN attains real-time operation with an embedding capacity of 8 bits per pixel. Experimental evaluations on the DIV2K 2017 dataset demonstrate image fidelity between 40.4 dB and 41.35 dB in PSNR and SSIM values consistently above 0.97, surpassing SteganoGAN in computational efficiency and robustness. SteganoSNN establishes a foundation for neuromorphic steganography, enabling secure, energy-efficient communication for Edge-AI, IoT, and biomedical applications.

</details>


### [63] [Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment](https://arxiv.org/abs/2511.06852)
*Peng Zhang,peijie sun*

Main category: cs.CR

TL;DR: 이 연구는 대규모 언어 모델(LLMs)의 안전성 정렬이 악의적인 요청을 거부하는 과정을 세분화하여, 새로운 개념의 접근 방식을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델에서의 안전성 정렬은 악의적인 요청을 거부하는 중요한 능력을 부여한다.

Method: 이 연구는 안전성 거부 메커니즘을 해체하여 해를 탐지하는 방향과 거부 실행 방향으로 나눈 후, 이를 바탕으로 새롭게 정의된 구분된 양방향 개입(DBDI) 프레임워크를 도입한다.

Result: DBDI는 Llama-2와 같은 모델에서 최대 97.88%의 공격 성공률을 달성하며 기존의 주요 jailbreak 방법들을 초월하는 성능을 보여준다.

Conclusion: 이 연구는 대규모 언어 모델의 안전성 정렬에 대한 이해를 심화할 수 있는 새로운 방향을 제시한다.

Abstract: Safety alignment instills in Large Language Models (LLMs) a critical capacity to refuse malicious requests. Prior works have modeled this refusal mechanism as a single linear direction in the activation space. We posit that this is an oversimplification that conflates two functionally distinct neural processes: the detection of harm and the execution of a refusal. In this work, we deconstruct this single representation into a Harm Detection Direction and a Refusal Execution Direction. Leveraging this fine-grained model, we introduce Differentiated Bi-Directional Intervention (DBDI), a new white-box framework that precisely neutralizes the safety alignment at critical layer. DBDI applies adaptive projection nullification to the refusal execution direction while suppressing the harm detection direction via direct steering. Extensive experiments demonstrate that DBDI outperforms prominent jailbreaking methods, achieving up to a 97.88\% attack success rate on models such as Llama-2. By providing a more granular and mechanistic framework, our work offers a new direction for the in-depth understanding of LLM safety alignment.

</details>


### [64] [JPRO: Automated Multimodal Jailbreaking via Multi-Agent Collaboration Framework](https://arxiv.org/abs/2511.07315)
*Yuxuan Zhou,Yang Bai,Kuofeng Gao,Tao Dai,Shu-Tao Xia*

Main category: cs.CR

TL;DR: JPRO는 대형 VLM의 자동화된 탈옥을 위한 새로운 다중 에이전트 협력 프레임워크로, 이전 방법의 단점을 극복하고 60% 이상의 공격 성공률을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 대형 VLM의 안전한 배포를 보장하는 것이 중요해지고 있으며, 기존 연구들은 탈옥 공격에 대한 제한적인 접근 방식을 보여준다.

Method: JPRO는 네 개의 전문 에이전트와 두 개의 핵심 모듈: 전술 기반 시드 생성 및 적응형 최적화 루프를 통한 협조적인 행동으로 효과적이고 다양한 공격 샘플을 생성한다.

Result: JPRO는 GPT-4o를 포함한 여러 고급 VLM에서 60% 이상의 공격 성공률을 달성하여 기존 방법보다 상당히 우수한 성능을 보여준다.

Conclusion: JPRO는 멀티모달 모델의 보안 취약점을 발견하고 VLM 강건성을 평가하고 향상시키기 위한 중요한 통찰력을 제공한다.

Abstract: The widespread application of large VLMs makes ensuring their secure deployment critical. While recent studies have demonstrated jailbreak attacks on VLMs, existing approaches are limited: they require either white-box access, restricting practicality, or rely on manually crafted patterns, leading to poor sample diversity and scalability. To address these gaps, we propose JPRO, a novel multi-agent collaborative framework designed for automated VLM jailbreaking. It effectively overcomes the shortcomings of prior methods in attack diversity and scalability. Through the coordinated action of four specialized agents and its two core modules: Tactic-Driven Seed Generation and Adaptive Optimization Loop, JPRO generates effective and diverse attack samples. Experimental results show that JPRO achieves over a 60\% attack success rate on multiple advanced VLMs, including GPT-4o, significantly outperforming existing methods. As a black-box attack approach, JPRO not only uncovers critical security vulnerabilities in multimodal models but also offers valuable insights for evaluating and enhancing VLM robustness.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [65] [Novel Concepts for Agent-Based Population Modelling and Simulation: Updates from GEPOC ABM](https://arxiv.org/abs/2511.05637)
*Martin Bicher,Maximilian Viehauser,Daniele Giannandrea,Hannah Kastinger,Dominik Brunmeir,Niki Popper*

Main category: cs.MA

TL;DR: 이 논문은 인구 기반 모델에서 세 가지 혁신적 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 동적 에이전트 기반 인구 모델이 의사 결정 지원 도구로 인기를 끌고 있습니다.

Method: 세 가지 전이 가능한 혁신, 즉 개인 에이전트를 위한 혁신적인 시간 업데이트 개념, 공동 시뮬레이션에 영감을 받은 시뮬레이션 전략, 그리고 정확한 모델 파라미터화를 위한 전략을 제시합니다.

Result: 이러한 방법의 재현 가능성, 장점, 그리고 다른 인구 모델로의 전이 가능성에 대해 설명합니다.

Conclusion: GEPOC ABM과 같은 모델의 지속적인 개선과 새로운 방법의 개발이 중요합니다.

Abstract: In recent years, dynamic agent-based population models, which model every inhabitant of a country as a statistically representative agent, have been gaining in popularity for decision support. This is mainly due to their high degree of flexibility with respect to their area of application. GEPOC ABM is one of these models. Developed in 2015, it is now a well-established decision support tool and has been successfully applied for a wide range of population-level research questions ranging from health-care to logistics. At least in part, this success is attributable to continuous improvement and development of new methods. While some of these are very application- or implementation-specific, others can be well transferred to other population models. The focus of the present work lies on the presentation of three selected transferable innovations. We illustrate an innovative time-update concept for the individual agents, a co-simulation-inspired simulation strategy, and a strategy for accurate model parametrisation. We describe these methods in a reproducible manner, explain their advantages and provide ideas on how they can be transferred to other population models.

</details>


### [66] [STAIR: Stability criterion for Time-windowed Assignment and Internal adversarial influence in Routing and decision-making](https://arxiv.org/abs/2511.05715)
*Roee M. Francos,Daniel Garces,Orhan Eren Akgün,Stephanie Gil*

Main category: cs.MA

TL;DR: 기존 다중 에이전트 시스템의 라우팅 알고리즘은 적대적 에이전트의 존재를 고려하지 않아 실제 애플리케이션에서 성능 저하를 초래할 수 있다. 이 논문은 적대적 에이전트가 서비스 거부 공격을 통해 협조 에이전트를 방해하는 픽업 및 배송 문제를 연구하고, 새로운 안정성 기준인 STAIR를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 적대적 에이전트의 존재가 시스템 성능에 미치는 영향을 이해하고 이에 맞는 라우팅 알고리즘을 개발할 필요성이 있다.

Method: 적대적 에이전트의 조정된 서비스 거부 공격을 분석하고, 새로운 안정성 기준(STAIR)을 제안하여 라우팅 문제를 해결한다.

Result: 실험을 통해 STAIR가 적대적 환경에서 안정성을 보다 쉽게 분석할 수 있도록 하며, 실제 샌프란시스코의 이동 데이터 시뮬레이션에서 유의미한 결과를 도출하였다.

Conclusion: 적대적 라우팅 문제에서 STAIR는 관리할 수 있는 성과 지표와 연결되어 실용성이 높으며, 결정 알고리즘에 시간 창 제약을 도입하여 퇴화 안정성을 완화할 수 있다.

Abstract: A major limitation of existing routing algorithms for multi-agent systems is that they are designed without considering the potential presence of adversarial agents in the decision-making loop, which could lead to severe performance degradation in real-life applications where adversarial agents may be present. We study autonomous pickup-and-delivery routing problems in which adversarial agents launch coordinated denial-of-service attacks by spoofing their locations. This deception causes the central scheduler to assign pickup requests to adversarial agents instead of cooperative agents. Adversarial agents then choose not to service the requests with the goal of disrupting the operation of the system, leading to delays, cancellations, and potential instability in the routing policy. Policy stability in routing problems is typically defined as the cost of the policy being uniformly bounded over time, and it has been studied through two different lenses: queuing theory and reinforcement learning (RL), which are not well suited for routing with adversaries. In this paper, we propose a new stability criterion, STAIR, which is easier to analyze than queuing-theory-based stability in adversarial settings. Furthermore, STAIR does not depend on a chosen discount factor as is the case in discounted RL stability. STAIR directly links stability to desired operational metrics, like a finite number of rejected requests. This characterization is particularly useful in adversarial settings as it provides a metric for monitoring the effect of adversaries in the operation of the system. Furthermore, we demonstrate STAIR's practical relevance through simulations on real-world San Francisco mobility-on-demand data. We also identify a phenomenon of degenerate stability that arises in the adversarial routing problem, and we introduce time-window constraints in the decision-making algorithm to mitigate it.

</details>


### [67] [Evader-Agnostic Team-Based Pursuit Strategies in Partially-Observable Environments](https://arxiv.org/abs/2511.05812)
*Addison Kalanther,Daniel Bostwick,Chinmay Maheshwari,Shankar Sastry*

Main category: cs.MA

TL;DR: 무인 항공기 두 대가 도시 환경에서 회피 UAV를 추적하는 시나리오를 다룹니다. 팀은 제한된 시야를 가지고 있으며, 환경을 탐색하여 정보를 수집하고 추적 결과를 향상시키는 방식으로 다중 플레이어 추격-회피 게임을 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 도시 환경에서 제한된 시야를 가진 UAV 팀이 회피 UAV를 효과적으로 추적하고 포획하기 위한 방법론 필요.

Method: 제한된 합리성 원리를 중심으로 하는 두 단계의 신경-기호 알고리즘을 개발. 첫 번째 단계는 오프라인 방법으로, 심층 강화 학습을 사용하여 적대적인 정책을 훈련하고, 두 번째 단계는 온라인으로 최적의 반응을 적용하는 분류 알고리즘을 사용.

Result: 무작위 회피 UAV와의 대결에서 평균 성능 개선에 성공함.

Conclusion: 제안한 방법론이 UAV 팀의 환경에서 회피 UAV를 효과적으로 추적하는 데 기여함을 보여줌.

Abstract: We consider a scenario where a team of two unmanned aerial vehicles (UAVs) pursue an evader UAV within an urban environment. Each agent has a limited view of their environment where buildings can occlude their field-of-view. Additionally, the pursuer team is agnostic about the evader in terms of its initial and final location, and the behavior of the evader. Consequently, the team needs to gather information by searching the environment and then track it to eventually intercept. To solve this multi-player, partially-observable, pursuit-evasion game, we develop a two-phase neuro-symbolic algorithm centered around the principle of bounded rationality. First, we devise an offline approach using deep reinforcement learning to progressively train adversarial policies for the pursuer team against fictitious evaders. This creates $k$-levels of rationality for each agent in preparation for the online phase. Then, we employ an online classification algorithm to determine a "best guess" of our current opponent from the set of iteratively-trained strategic agents and apply the best player response. Using this schema, we improved average performance when facing a random evader in our environment.

</details>


### [68] [A Graph-Theoretical Perspective on Law Design for Multiagent Systems](https://arxiv.org/abs/2511.06361)
*Qi Shi,Pavel Naumov*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 시스템에서 바람직하지 않은 결과를 피하기 위한 제약 조건인 법률을 다룬다. 유용한 법률과 간격 없는 법률 두 가지 유형을 제시하고, 각각의 법률을 통해 최소한의 제약 조건으로 원하는 결과를 달성하는 문제를 연구한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 에이전트의 행동에 대한 제약을 통해 바람직하지 않은 결과를 예방하기 위한 법률의 필요성을 제기.

Method: 유용한 법률과 간격 없는 법률 두 가지 유형의 최소화 문제를 연구하고, 하이퍼그래프에서의 정점 커버 문제에 대한 근사 알고리즘을 이용하여 법률을 효율적으로 근사하는 방법을 제시.

Result: 두 가지 유형의 법률 모두에서 최소화 문제가 NP-하드임을 증명하고, 근사 알고리즘을 통해 최소 법률을 효율적으로 근사할 수 있음을 보인다.

Conclusion: 법률을 최소한의 제약으로 찾는 문제의 복잡성을 분석하고 효과적인 근사 방법을 제시함으로써 다중 에이전트 시스템에서의 법률 적용 가능성을 확장한다.

Abstract: A law in a multiagent system is a set of constraints imposed on agents' behaviours to avoid undesirable outcomes. The paper considers two types of laws: useful laws that, if followed, completely eliminate the undesirable outcomes and gap-free laws that guarantee that at least one agent can be held responsible each time an undesirable outcome occurs. In both cases, we study the problem of finding a law that achieves the desired result by imposing the minimum restrictions.
  We prove that, for both types of laws, the minimisation problem is NP-hard even in the simple case of one-shot concurrent interactions. We also show that the approximation algorithm for the vertex cover problem in hypergraphs could be used to efficiently approximate the minimum laws in both cases.

</details>


### [69] [When AI Agents Collude Online: Financial Fraud Risks by Collaborative LLM Agents on Social Platforms](https://arxiv.org/abs/2511.06448)
*Qibing Ren,Zhijie Zheng,Jiaxuan Guo,Junchi Yan,Lizhuang Ma,Jing Shao*

Main category: cs.MA

TL;DR: 이 연구는 대규모 다중 에이전트 시스템 내에서의 집단 금융 사기의 위험을 조사한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 다중 에이전트 시스템에서 금융 사기의 위험성을 이해하고, 어떻게 에이전트들이 협력하여 사기를 저지를 수 있는지를 연구하기 위해.

Method: MultiAgentFraudBench라는 현실적인 온라인 상호작용에 기반한 금융 사기 시나리오를 시뮬레이션하기 위한 대규모 벤치마크를 제시한다.

Result: 28개의 전형적인 온라인 사기 시나리오를 포함하여 사기 성공에 영향을 미치는 주요 요소들을 추가로 분석한다.

Conclusion: 악의적인 에이전트가 환경적 개입에 적응할 수 있다는 점을 발견했으며, 다중 에이전트 금융 사기의 실제 위험을 강조하고 이를 완화하기 위한 실질적인 조치를 제안한다.

Abstract: In this work, we study the risks of collective financial fraud in large-scale multi-agent systems powered by large language model (LLM) agents. We investigate whether agents can collaborate in fraudulent behaviors, how such collaboration amplifies risks, and what factors influence fraud success. To support this research, we present MultiAgentFraudBench, a large-scale benchmark for simulating financial fraud scenarios based on realistic online interactions. The benchmark covers 28 typical online fraud scenarios, spanning the full fraud lifecycle across both public and private domains. We further analyze key factors affecting fraud success, including interaction depth, activity level, and fine-grained collaboration failure modes. Finally, we propose a series of mitigation strategies, including adding content-level warnings to fraudulent posts and dialogues, using LLMs as monitors to block potentially malicious agents, and fostering group resilience through information sharing at the societal level. Notably, we observe that malicious agents can adapt to environmental interventions. Our findings highlight the real-world risks of multi-agent financial fraud and suggest practical measures for mitigating them. Code is available at https://github.com/zheng977/MutiAgent4Fraud.

</details>


### [70] [S-DAG: A Subject-Based Directed Acyclic Graph for Multi-Agent Heterogeneous Reasoning](https://arxiv.org/abs/2511.06727)
*Jiangwen Dong,Zehui Lin,Wanyu Lin,Mingjin Zhang*

Main category: cs.MA

TL;DR: 이 연구는 다중 주제를 포함하는 복잡한 문제를 해결하기 위해 주제 수준에서 세분화된 분석을 수행하는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 성능은 특정 작업의 성격과 도메인 지식에 크게 의존한다.

Method: 그래프 신경망을 사용하여 관련 주제를 식별하고 상호 의존성을 추론하여 주제 기반 유향 비순환 그래프(S-DAG)를 생성한 후, 각 모델에 주제별 전문성 점수를 부여해 최상위 모델을 선택하는 방식으로 주제-모델 매칭을 수행한다.

Result: 우리의 접근 방식은 기존의 작업 수준 모델 선택 및 다중 에이전트 협업 기준선보다 정확성과 효율성에서 뛰어난 성능을 보인다.

Conclusion: 주제 인식 추론과 구조화된 협업의 효과가 복잡하고 다중 주제 문제를 해결하는 데 중요한 역할을 한다.

Abstract: Large Language Models (LLMs) have achieved impressive performance in complex reasoning problems. Their effectiveness highly depends on the specific nature of the task, especially the required domain knowledge. Existing approaches, such as mixture-of-experts, typically operate at the task level; they are too coarse to effectively solve the heterogeneous problems involving multiple subjects. This work proposes a novel framework that performs fine-grained analysis at subject level equipped with a designated multi-agent collaboration strategy for addressing heterogeneous problem reasoning. Specifically, given an input query, we first employ a Graph Neural Network to identify the relevant subjects and infer their interdependencies to generate an \textit{Subject-based Directed Acyclic Graph} (S-DAG), where nodes represent subjects and edges encode information flow. Then we profile the LLM models by assigning each model a subject-specific expertise score, and select the top-performing one for matching corresponding subject of the S-DAG. Such subject-model matching enables graph-structured multi-agent collaboration where information flows from the starting model to the ending model over S-DAG. We curate and release multi-subject subsets of standard benchmarks (MMLU-Pro, GPQA, MedMCQA) to better reflect complex, real-world reasoning tasks. Extensive experiments show that our approach significantly outperforms existing task-level model selection and multi-agent collaboration baselines in accuracy and efficiency. These results highlight the effectiveness of subject-aware reasoning and structured collaboration in addressing complex and multi-subject problems.

</details>


### [71] [Multi-Agent Reinforcement Learning for Deadlock Handling among Autonomous Mobile Robots](https://arxiv.org/abs/2511.07071)
*Marcel Müller*

Main category: cs.MA

TL;DR: 이 논문은 자율 이동 로봇(AMR)을 활용하는 내부 물류 시스템에서의 교착 상태 처리를 위해 다중 에이전트 강화 학습(MARL)의 활용을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: AMR은 운영 유연성을 향상시키지만 교착 상태의 위험을 증가시켜 시스템의 처리량과 신뢰성을 저하시킨다. 기존 접근 방식은 계획 단계에서 교착 상태 처리를 종종 간과하고 동적 운영 조건에 적응할 수 없는 경직된 제어 규칙에 의존한다.

Method: 이 연구는 MARL을 물류 계획 및 운영 제어에 통합하기 위한 구조화된 방법론을 개발하고, 교착 상태를 처리할 수 있는 다중 에이전트 경로 찾기(MAPF) 문제를 명시적으로 고려한 기준 모델을 도입한다.

Result: 그리드 기반 환경과 외부 시뮬레이션 소프트웨어를 사용하여 이 연구는 전통적인 교착 상태 처리 전략과 MARL 기반 솔루션(PPO 및 IMPALA 알고리즘)을 다양한 훈련 및 실행 모드에서 비교한다.

Conclusion: 결과는 MARL 기반 전략이 중앙 집중식 훈련과 분산 실행(CTDE)과 결합될 때 복잡하고 혼잡한 환경에서 규칙 기반 방법보다 우수하다는 것을 보여준다. 그러나 간단한 환경이나 공간적 자유가 많은 환경에서는 규칙 기반 방법이 낮은 계산 요구 때문에 경쟁력을 유지한다.

Abstract: This dissertation explores the application of multi-agent reinforcement learning (MARL) for handling deadlocks in intralogistics systems that rely on autonomous mobile robots (AMRs). AMRs enhance operational flexibility but also increase the risk of deadlocks, which degrade system throughput and reliability. Existing approaches often neglect deadlock handling in the planning phase and rely on rigid control rules that cannot adapt to dynamic operational conditions.
  To address these shortcomings, this work develops a structured methodology for integrating MARL into logistics planning and operational control. It introduces reference models that explicitly consider deadlock-capable multi-agent pathfinding (MAPF) problems, enabling systematic evaluation of MARL strategies. Using grid-based environments and an external simulation software, the study compares traditional deadlock handling strategies with MARL-based solutions, focusing on PPO and IMPALA algorithms under different training and execution modes.
  Findings reveal that MARL-based strategies, particularly when combined with centralized training and decentralized execution (CTDE), outperform rule-based methods in complex, congested environments. In simpler environments or those with ample spatial freedom, rule-based methods remain competitive due to their lower computational demands. These results highlight that MARL provides a flexible and scalable solution for deadlock handling in dynamic intralogistics scenarios, but requires careful tailoring to the operational context.

</details>
