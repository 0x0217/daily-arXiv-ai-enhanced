<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 33]
- [cs.CR](#cs.CR) [Total: 8]
- [cs.LG](#cs.LG) [Total: 97]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [BTPG-max: Achieving Local Maximal Bidirectional Pairs for Bidirectional Temporal Plan Graphs](https://arxiv.org/abs/2508.04849)
*Yifan Su,Rishi Veerapaneni,Jiaoyang Li*

Main category: cs.MA

TL;DR: BPTG-max 알고리즘은 다수의 에이전트 경로 찾기에 있어 지연 상황에서도 더욱 효율적인 경로를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 경로 찾기에서 지연으로 인한 충돌 문제를 해결하기 위해, 기존의 TPG를 개선하고자 하였다.

Method: BPTG-max 알고리즘은 추가적인 쌍을 추가할 수 없는 로컬 최적의 BTPG를 구성하여 더 많은 상호 방향 페어를 찾는다.

Result: BPTG-max는 더 많은 쌍과 더 많은 상호 방향 엣지를 가지며, 우수한 언제든지 동작 및 지연에 대한 견고성을 보여준다.

Conclusion: 이 연구는 BTPG를 통해 다중 에이전트 경로 찾기에서 지연에 대한 효율성을 높일 수 있음을 확인하였다.

Abstract: Multi-Agent Path Finding (MAPF) requires computing collision-free paths for
multiple agents in shared environment. Most MAPF planners assume that each
agent reaches a specific location at a specific timestep, but this is
infeasible to directly follow on real systems where delays often occur. To
address collisions caused by agents deviating due to delays, the Temporal Plan
Graph (TPG) was proposed, which converts a MAPF time dependent solution into a
time independent set of inter-agent dependencies. Recently, a Bidirectional TPG
(BTPG) was proposed which relaxed some dependencies into ``bidirectional pairs"
and improved efficiency of agents executing their MAPF solution with delays.
Our work improves upon this prior work by designing an algorithm, BPTG-max,
that finds more bidirectional pairs. Our main theoretical contribution is in
designing the BTPG-max algorithm is locally optimal, i.e. which constructs a
BTPG where no additional bidirectional pairs can be added. We also show how in
practice BTPG-max leads to BTPGs with significantly more bidirectional edges,
superior anytime behavior, and improves robustness to delays.

</details>


### [2] [Congestion Mitigation Path Planning for Large-Scale Multi-Agent Navigation in Dense Environments](https://arxiv.org/abs/2508.05253)
*Takuro Kato,Keisuke Okumura,Yoko Sasaki,Naoya Yokomachi*

Main category: cs.MA

TL;DR: CMPP는 자율 에이전트의 경로 계획에서 혼잡을 고려하여 효율적인 내비게이션을 제공하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 고밀도 환경에서 자율 에이전트의 동시 이동으로 인한 지역 혼잡을 완화하고 전반적인 내비게이션 효율을 유지하기 위함.

Method: 혼잡 완화 경로 계획(CMPP) 문제를 제시하고, 혼잡을 비용 함수에 직접 포함시키며, 두 가지 해결 알고리즘을 개발하였다: 정확한 혼합 정수 비선형 프로그래밍 솔버와 대규모 인스턴스를 위한 A-CMTS 알고리즘.

Result: CMPP를 적용한 혼잡 회피 계획은 지역 혼잡을 크게 줄이고 시스템 처리량을 향상시킴을 보여준다.

Conclusion: CMPP는 물류 및 자율 차량 운영과 같은 실제 응용 프로그램에서 다중 에이전트 시스템의 성능을 개선할 수 있다.

Abstract: In high-density environments where numerous autonomous agents move
simultaneously in a distributed manner, streamlining global flows to mitigate
local congestion is crucial to maintain overall navigation efficiency. This
paper introduces a novel path-planning problem, congestion mitigation path
planning (CMPP), which embeds congestion directly into the cost function,
defined by the usage of incoming edges along agents' paths. CMPP assigns a
flow-based multiplicative penalty to each vertex of a sparse graph, which grows
steeply where frequently-traversed paths intersect, capturing the intuition
that congestion intensifies where many agents enter the same area from
different directions. Minimizing the total cost yields a set of coarse-level,
time-independent routes that autonomous agents can follow while applying their
own local collision avoidance. We formulate the problem and develop two
solvers: (i) an exact mixed-integer nonlinear programming solver for small
instances, and (ii) a scalable two-layer search algorithm, A-CMTS, which
quickly finds suboptimal solutions for large-scale instances and iteratively
refines them toward the optimum. Empirical studies show that augmenting
state-of-the-art collision-avoidance planners with CMPP significantly reduces
local congestion and enhances system throughput in both discrete- and
continuous-space scenarios. These results indicate that CMPP improves the
performance of multi-agent systems in real-world applications such as logistics
and autonomous-vehicle operations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 이 논문은 산업 기계 유지보수를 위한 LLM 기반 지능형 시스템을 제시하며, 전통적인 이상 탐지를 넘어 실행 가능한 유지보수 권장 사항을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 산업 기계의 유지보수는 치명적인 고장을 예방하고 운영 효율성을 최적화하기 위해 시기적절한 개입이 필요합니다.

Method: 기존 LAMP 프레임워크를 바탕으로, 베어링 진동 주파수 분석과 다중 에이전트 생성 기술을 결합하여 지능형 유지보수 계획을 수립합니다.

Result: 실험 검증 결과, 베어링 진동 데이터에서 효과적인 이상 탐지와 맥락에 맞는 유지보수 가이드가 가능함을 입증했습니다.

Conclusion: 이 시스템은 상태 모니터링과 실행 가능한 유지보수 계획 간의 간극을 메우며, 산업 전문가에게 지능형 의사결정 지원을 제공합니다.

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [4] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow는 지리적 작업을 위한 자동 에이전트 워크플로우 생성 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 이전 연구는 API 선택을 암시적으로 처리하였으나, GeoFlow는 각 에이전트에 세부적인 도구 호출 목표를 제공하여 이 과정을 명확하게 한다.

Method: GeoFlow는 지리적 API 호출을 위한 에이전트 워크플로우를 자동으로 생성하는 방법이다.

Result: GeoFlow는 에이전트의 성공률을 6.8% 증가시키고, 주요 LLM 계열에서 토큰 사용량을 최대 4배 줄인다.

Conclusion: GeoFlow는 기존의 최첨단 접근 방식에 비해 효과적인 성능 개선을 보여준다.

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [5] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: AI 헬스케어 연구의 한계를 극복한 HealthFlow라는 자가 발전 AI 에이전트를 소개하고, 이의 효과를 입증하는 연구.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 정적이고 정의된 전략에 의존하여 헬스케어와 같은 복잡한 분야에서 전략적 계획 능력을 향상시키지 못하는 한계를 극복하고자 함.

Method: HealthFlow는 절차적 성공과 실패를 분석하여 고수준 문제 해결 정책을 자가 발전적으로 개선하는 메타 수준의 진화 메커니즘을 사용.

Result: HealthFlow의 자가 발전 접근 방식이 최신 에이전트 프레임워크보다 유의미하게 우수한 성과를 보였다.

Conclusion: 이 연구는 더 나은 도구 사용자를 만드는 것에서 더 스마트하고 자가 발전적인 작업 관리자 설계로의 전환을 나타내며, 과학적 발견을 위한 보다 자율적이고 효과적인 AI의 길을 열어준다.

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [6] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 이 논문은 보드 게임 경쟁을 통해 대형 언어 모델(LLM)의 성능을 평가하기 위한 새로운 벤치마킹 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적으로 보드 게임은 전략적 추론과 지능 평가에 중요한 도메인으로 여겨졌다.

Method: Qi Town이라는 평가 플랫폼을 통해 5개의 인기 게임과 20개의 LLM 기반 플레이어로 구성된 라운드로빈 토너먼트를 실시한다.

Result: 실험 결과, 대부분의 LLM이 승패에 대해 낙관적이며, 인간보다 역경에 대한 적응력이 뛰어난 것으로 나타났다.

Conclusion: 하지만 PLG에서의 순환적인 승패 관계는 LLM의 기술적인 플레이의 불안정을 드러내며, 이는 추가적인 설명과 탐구가 필요하다.

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [7] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: CogniWeb은 웹 내비게이션에서 AGI 평가를 위해 빠른 직관적 처리와 신중한 추론을 조합하여 성능과 효율성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 웹 내비게이션은 AGI 평가를 위해 복잡한 의사결정을 요구하며, 현재의 접근 방식은 오프라인 모방 학습 또는 온라인 탐색에 국한된다.

Method: 빠른 시스템 1과 느린 시스템 2 인지 과정으로 분해하여 웹 에이전트 방법론을 통합하는 CogniWeb 아키텍처를 구현하였다.

Result: CogniWeb은 43.96%의 성공률을 달성하며, 75%의 토큰 사용 감소로 높은 효율성을 유지한다.

Conclusion: CogniWeb은 웹 내비게이션의 복잡성을 처리하는데 있어 경쟁력 있는 성능과 효율성을 보여준다.

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [8] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 본 연구는 자율 웹기반 지리정보시스템(AWebGIS)을 위한 세 가지 접근 방식을 비교하여 클라이언트 측에서 실행되는 소규모 언어 모델(예: T5-small)이 가장 높은 정확도를 달성했음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: AWebGIS는 자연어 입력을 통해 지리공간 작업을 수행할 수 있도록 하여 직관적이고 지능적인 사용자 상호작용을 제공하는 것에 목적이 있다.

Method: 세 가지 접근 방식: (1) 클라우드 기반 LLM을 사용한 완전 자동 온라인 방법, (2) 전통적 기계 학습 분류기를 사용한 반자동 오프라인 방법, (3) 클라이언트 측에서 실행되는 소규모 언어 모델(SLM)을 사용한 완전 자율 오프라인 방법.

Result: SLM 기반 방법은 정확도 0.93, Levenshtein 유사도 0.99, ROUGE-1 및 ROUGE-L 점수 0.98을 기록하며 가장 높은 성과를 보였다.

Conclusion: 브라우저에서 실행 가능한 모델의 가능성이 AWebGIS 솔루션에 적합함을 강조한다.

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [9] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 생성적 AI가 고등 교육에서 핵심 도구로 자리 잡고 있으며, 교육자와 교육 목표에 맞춘 다중 에이전트 시스템(MAS)의 사용을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 생성적 AI 사용에 대한 최근 논의를 반박하고, AI가 교육에서 비판적이고 독립적인 사고를 촉진할 수 있음을 보여주기 위함이다.

Method: 65명의 독일 예비 교사 학생들과의 controlled 실험을 통해 소크라틱 AI 튜터 반과 비지도 AI 챗봇 반의 상호작용을 비교했다.

Result: 소크라틱 튜터를 사용한 학생들은 비판적이고 반성적인 사고에 대해 훨씬 더 높은 지원을 보고하였다.

Conclusion: AI와 인간의 공동 작용을 강조하는 하이브리드 학습 생태계 구축을 위한 경험적 증거와 개념적 로드맵을 제공한다.

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [10] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 강화 학습이 대규모 언어 모델의 추론 능력을 향상시키는 데 중요한 기술로 자리잡았지만, 비이상적인 상황에서의 성능 평가가 부족하다.


<details>
  <summary>Details</summary>
Motivation: 인간의 추론이 불완전한 입력에서도 신뢰성을 유지함을 보여주는 뇌 과학 findings에 기반하여 새로운 연구 방향을 제시한다.

Method: 세 가지 비이상적인 시나리오를 정의하고 평가한 후, 대표적인 정책 경량 알고리즘을 사용하여 대규모 언어 모델과 최신 비전-언어 모델을 fine-tune 한다.

Result: RL fine-tuning이 이상적인 설정에서는 개선되지만, 비이상적인 세 가지 시나리오 전반에서 성능 감소를 보여줌.

Conclusion: 현재의 방법론이 이러한 추론 결핍을 크게 해결하지 못하며, 모델의 추론 능력에 대한 평가를 비이상적인 시나리오에서 수행하는 것이 중요함을 강조한다.

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [11] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 본 연구는 약물 발견을 위한 분자 도킹의 효율성을 높이기 위한 새로운 게임 이론적 프레임워크인 Loop Self-Play 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 멀티태스크 학습 모델이 리간드 도킹에서 단백질 포켓 도킹보다 성능이 떨어지는 문제를 해결하고자 함.

Method: 단백질-리간드 상호작용을 두 플레이어 게임으로 모델링하고, LoopSelf-Play 알고리즘을 통해 이들을 교대로 훈련.

Result: LoopPlay는 이전 메소드 대비 약 10%의 정확성 향상을 보여줌.

Conclusion: LoopPlay는 약물 발견에서 분자 도킹의 정확성을 향상시킬 가능성을 제시하는 유망한 방법이다.

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [12] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 대규모 언어 모델(LLM)을 활용하여 다양한 도시 공간 데이터 세트를 통합하는 방법을 모색하며, LLM의 공간 추론 능력과 실제 응용 가능성을 연구하였다.


<details>
  <summary>Details</summary>
Motivation: 도시의 복잡하고 다양한 공간 데이터 세트를 효과적으로 통합할 필요성이 있으며, 전통적인 방법은 한계가 있다.

Method: LLM의 공간 추론 능력을 조사하고, 관련 기능을 제공하여 초기 응답 수정 및 개선하는 방향으로 접근하였다.

Result: LLM은 공간 추론 능력을 보여주지만, 매크로 환경과 관련된 과제를 연결하는 데 어려움을 겪었고, 관련 기능을 제공할 때 성능이 향상되었다.

Conclusion: LLM은 기존 규칙 기반 방법에 비해 유망하고 유연한 대안으로, 도시 공간 데이터 통합의 잠재력을 확장한다.

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [13] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: 의료 다중모달 대형 언어 모델(MLLM)의 지식 편집을 위한 MedMKEB라는 첫 종합 벤치마크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 의료 지식의 변화에 대응하기 위해 MLLM이 정보를 효율적으로 업데이트할 수 있도록 하는 것이 중요하다.

Method: 최고 품질의 의료 시각 질의응답 데이터셋을 기반으로 다양한 편집 작업을 포함하여 MedMKEB 벤치마크를 개발하였다.

Result: 기존 지식 기반 편집 접근 방식의 한계를 실험을 통해 입증하였다.

Conclusion: MedMKEB는 신뢰성 있고 효율적인 의료 지식 편집 알고리즘 개발을 촉진하는 표준 벤치마크 역할을 할 것이다.

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [14] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize는 가볍고 보편적인 게이트 사이징 프레임워크로, 350nm 데이터에 대해 조정된 Qwen3-8B 모델을 기반으로 하여 다양한 기술 노드에서 강력한 성능을 발휘한다.


<details>
  <summary>Details</summary>
Motivation: 아날로그 회로 설계에서 게이트 사이징은 시간 소모적이고 경험에 기반한 작업으로, AI 기술의 발전에도 불구하고 보편적이고 빠르며 안정적인 방법을 찾는 것이 어려움이 있다.

Method: EasySize는 성능 메트릭의 변동하는 이행 용이성(EOA)을 활용하여 동적으로 과제 특화 손실 함수를 구성하고, 글로벌 차별 진화(DE) 및 로컬 입자 군집 최적화(PSO)를 통해 효율적인 휴리스틱 탐색을 수행한다.

Result: EasySize는 350nm 노드 데이터에만 조정되었음에도 불구하고, 180nm, 45nm 및 22nm 기술 노드에서 5개의 연산 증폭기(Op-Amp) 넷리스트에서 강력한 성능을 발휘하며, AutoCkt보다 86.67%의 과제에서 우수한 결과를 보인다.

Conclusion: EasySize는 게이트 사이징에서 인간의 전문지식과 계산 자원의 의존도를 줄이고, 아날로그 회로 설계 과정을 가속화 및 간소화할 수 있다.

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [15] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 이 논문은 이벤트 로그의 품질을 개선하기 위해 이종 그래프 신경망 모델을 개발하고, 결측된 이벤트 속성을 복원하는 성능을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 실제 이벤트 로그에서 데이터 수집의 어려움으로 인해 결측 정보가 발생하며, 이는 프로세스 마이닝 분석에 영향을 준다.

Method: 결측 이벤트가 포함된 추적을 입력으로 받아 결측 속성을 복원하는 이종 그래프 신경망 모델을 개발하였다.

Result: 이종 그래프 신경망 모델은 최신의 오토인코더 접근 방식과 비교하여 모든 이벤트 속성을 복원하는 데 있어 매우 우수한 성능을 나타냈다.

Conclusion: 제안된 방법은 주로 이벤트 속성의 일부 수리하는 데 집중하는 기존 무모델 접근 방식과 달리, 다양한 이벤트 속성을 효과적으로 복원할 수 있음을 보여준다.

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [16] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon은 멀티모달 지식 집약적 질문 응답을 위한 향상된 검색과 생성 시스템으로, 복잡한 쿼리를 효과적으로 처리한다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 대형 언어 모델에서 외부 지식을 포함하여 환각을 완화하고자 하며, 복잡한 쿼리에 대한 처리 능력을 향상시키기 위함이다.

Method: QA-Dragon은 쿼리의 주제 도메인을 식별하는 도메인 라우터와 동적으로 최적의 검색 전략을 선택하는 검색 라우터를 도입하여 멀티모달 검색을 지원한다.

Result: QA-Dragon은 KDD Cup 2025에서의 평가에서 중간 성능을 크게 향상시켰으며, 다양한 작업에서 기준 모델을 초과 성능을 보였다.

Conclusion: QA-Dragon은 복잡한 VQA 작업에서의 정확도와 지식 중첩 점수를 각각 5.06%, 6.35%, 5.03% 개선하여 기존 방법보다 뛰어난 성능을 발휘한다.

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [17] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 대규모 유지보수 조직에서 전문가 식별 및 복잡한 관계 관리의 도전 과제를 해결하기 위해 RDF 그래프 데이터베이스와 LLM을 결합한 새로운 프레임워크를 제안.


<details>
  <summary>Details</summary>
Motivation: 전통적인 커뮤니케이션 방법이 간과하는 정보 과부하와 긴 반응 시간 문제를 해결하기 위해.

Method: RDF 그래프 데이터베이스와 LLM을 결합하여 자연어 쿼리를 처리하고 계획-조정 아키텍처를 통해 투명한 추론을 제공.

Result: 장비, 제조업체, 유지보수 엔지니어 및 시설 등의 개념을 결합한 직관적인 쿼리 작성이 가능하게 하여 결과의 설명성과 신뢰도를 유지.

Conclusion: 조직 내 커뮤니케이션 효율성을 향상시키며 시스템에 대한 신뢰를 유지하는 결과를 제공.

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [18] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 결정 트리 기반 심볼릭 추론과 대형 언어 모델의 생성 능력을 통합한 하이브리드 아키텍처를 제안하며, 이는 강력한 추론 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존의 심볼릭과 신경 모듈을 느슨하게 결합한 방식과는 달리, 더욱 일관된 추론 시스템을 위해 결정 트리와 랜덤 포레스트를 통합하고자 함.

Method: 결정 트리 및 랜덤 포레스트를 호출 가능한 오라클로 포함시켜, LLM 에이전트가 비유추적 추론, 일반화 및 대화형 계획을 처리하도록 설계함.

Result: ProofWriter에서 엔타일먼트 일관성을 7.2% 향상시켰고, GSM8k에서 다단계 수학 문제 정확도를 5.3% 개선했으며, ARC에서 추상화 정확도를 6.0% 증가시킴.

Conclusion: 이 아키텍처는 강력하고 해석 가능한 신경-심볼릭 추론을 위한 신뢰할 수 있는 솔루션을 제공하며, 임상 결정 지원 및 과학적 발견과 같은 다양한 활용 사례를 보여준다.

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [19] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 인공지능의 '에이전트' 용어는 다양한 해석을 가져왔으며, 이 논문은 그 정의를 재정립하고 명확한 기준을 제시하는 방법론을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI의 발전에 따라 '에이전트' 용어의 모호성이 증가하여 연구 소통, 시스템 평가, 정책 개발에 도전 과제가 발생하고 있다.

Method: 역사적 분석과 현대적 사용 패턴을 기반으로 에이전트의 최소 요건을 정의하고, 환경 상호작용, 학습 및 적응, 자율성, 목표 복잡성, 시간적 일관성의 다차원 스펙트럼을 설정하는 프레임워크를 제안한다.

Result: 제안된 프레임워크는 시스템 설명을 위한 명확한 용어를 제공하며, 연구의 명확성과 재현성을 개선할 수 있는 도구를 제공한다.

Conclusion: 정확한 용어 표준화와 프레임워크 채택을 포함하여, 연구 소통 및 정책 개발에서 효과를 높이기 위한 구체적인 권장 사항을 제시한다.

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [20] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: 본 연구는 NomicLaw라는 구조화된 다중 에이전트 시뮬레이션을 소개하며, 여기서 LLM들이 협력적인 법 제정에 참여하고 복잡한 법적 문제에 대한 규칙을 제안하고 정당화하며 투표를 진행하는 과정을 정량적 및 정성적으로 분석한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 복잡한 논리적 과제 처리 능력 이해가 부족하여, 법적 및 윤리적 딜레마에 대한 토론을 포함한 다중 에이전트 환경에서의 LLM 행동을 조사할 필요가 있다.

Method: NomicLaw 시뮬레이션을 통해 LLM들이 법적 비넷에 대한 규칙 제안 및 투표를 통해 협력법 제정 과정을 진행한다.

Result: 동질적 및 이질적인 LLM 그룹 실험을 통해 에이전트가 자발적으로 동맹을 형성하고, 신뢰를 배신하며, 집단적 결정을 형성하기 위해 수사학을 조정하는 방식을 보여준다.

Conclusion: 연구 결과는 10개의 오픈소스 LLM의 잠재적 사회적 추론 및 설득 능력을 강조하며, 향후 자율적 협상, 조정 및 법률 초안 작성이 가능한 AI 시스템 설계에 대한 통찰을 제공한다.

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [21] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: 이 논문은 설명 논리에서 순수 최소 모델의 개념 만족 가능성을 다루며, 중요한 결과로 $	ext{EL}$에 대해 결정 불가능성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 최소 모델을 이용한 지식 표현 기법이 중요하지만, 설명 논리에서 이 문제에 대한 이해가 부족하여 더욱 연구가 필요하다.

Method: 순수 최소 모델에서 개념 만족 가능성을 분석하고, TBox에 비순환성 조건을 부여하여 결정 가능성을 회복한다.

Result: $	ext{EL}$에 대해 개념 만족 가능성이 결정 불가능하다는 결과를 도출하고, DL-Lite의 확장인 DL-Lite$_{	ext{horn}}$에 대해 ExpSpace-하드를 증명했다.

Conclusion: 연구를 통해 설명 논리의 다양한 측면에서 최소 모델의 복잡성 문제를 심도 있게 탐구하였다.

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [22] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: StructVRM은 복잡한 다중 질문 추론 작업에서 정밀한 피드백을 제공해 모델 학습을 개선하는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 기존 비전-언어 모델이 복잡한 문제 해결에서 부분적 정답의 중요성으로 어려움을 겪고 있다.

Method: 구조화되고 검증 가능한 보상 모델을 통해 다중 모달 추론을 정렬하는 StructVRM 방법을 제안하며, 세부 질문 수준의 피드백을 제공하는 모델 기반 검증자를 훈련한다.

Result: StructVRM은 12개의 공공 다중 모달 벤치마크 중 6개에서 최고 성능을 달성하며, 새로운 고 난이도 STEM-Bench에서도 높은 성과를 보인다.

Conclusion: 구조화된 검증 가능한 보상으로 훈련하는 것이 복잡한 현실 세계 추론 도메인에서 다중 모달 모델의 능력을 향상시키는 효과적인 접근 방식임을 확인했다.

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [23] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 이 연구는 지능형 교통 시스템을 위한 실시간 데이터 기반 예측 유지 보수 솔루션을 제안하며, 높은 정확도와 F-측정치를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 정확한 고장 예측이 실질적이고 운영적인 의미가 있기 때문에 철도 예측 유지 보수의 효과를 높이는 것이 중요하다.

Method: 샘플 전처리, 기계 학습 모델을 이용한 점진적 분류, 결과 설명 모듈로 구성된 온라인 처리 파이프라인을 구현한다.

Result: F-측정에서 98% 이상, 정확도에서 99%를 기록하는 성과를 달성하였다.

Conclusion: 이 파이프라인은 철도 운영의 실제 유지 보수 결정 지원에 활용 가능하며, 고장 초기 징후 식별을 통해 신속한 대응을 가능하게 한다.

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [24] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: DeepPHY은 VLM의 물리적 이해 및 추론 능력을 평가하기 위한 새로운 벤치마크 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: VLM이 복잡한 동적 환경에서 세밀한 주의와 정밀한 행동 계획에 어려움을 겪는 이유를 파악하고, 이를 평가할 필요성을 제기한다.

Method: DeepPHY는 다양한 난이도의 물리적 추론 환경을 통합하고, 세분화된 평가 메트릭스를 포함하는 체계적인 벤치마크 프레임워크를 제공한다.

Result: 최신 VLM조차도 서술적 물리 지식을 정밀하고 예측 가능한 제어로 번역하는 데 어려움을 겪음을 찾아냈다.

Conclusion: DeepPHY는 VLM의 물리학 규칙 이해 및 추론 능력을 체계적으로 평가할 수 있는 새로운 기준점을 제공함으로써, 향후 개선 방향을 제시할 수 있다.

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [25] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: 대형 언어 모델이 유기 합성에서 화학 반응 계획 및 실행 방식을 변화시키고 있다.


<details>
  <summary>Details</summary>
Motivation: 화학자들이 실험을 계획하고 실행하는 방식을 혁신할 수 있는 가능성을 탐색하기 위함.

Method: 대형 언어 모델을 그래프 신경망, 양자 계산 및 실시간 분광학과 결합하여 데이터 기반 화학을 지원하고 발견 주기를 단축하는 방법을 고찰.

Result: 이러한 결합을 통해 발견 주기가 단축되고, 환경 친화적이며 데이터 기반의 화학이 촉진됨.

Conclusion: 인공지능과 자동화에 의해 힘을 받은 혁신적인 분자 혁신의 길을 제시하며, 인간의 통제를 유지하는 매개체들을 강조한다.

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [26] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: AI의 (슈퍼) 정렬 문제는 AI 시스템이 사회적 Norm과 목표에 따라 행동하도록 보장하는 도전 과제이다. 그러나 지역적 다양성에 대한 연구는 미비하다.


<details>
  <summary>Details</summary>
Motivation: AI의 사회적 Norm 및 목표에 적합한 행동을 보장하는 것이 필수적이며, 지역별 차이를 고려해야 한다.

Method: 지리적 연구 문제를 검토하고, 향후 연구 주제를 제안하며, 정렬 민감성을 평가하는 방법을 outline 한다.

Result: AI/ML 작업 흐름에 적용된 정렬 조치가 통계적 현실과 다를 수 있으며, 사용자 위치에 따라 다르게 반응하는 모델 출력이 존재한다.

Conclusion: AI가 지식과 의견을 중재하는 방식에서 투명성이 떨어지며, 문맥 관리에 대한 이해가 필요하다. 따라서 보편적인 접근 방식을 넘어서 공간-시간 인식 정렬이 요구된다.

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [27] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 이번 연구는 일반 목적 AI 모델의 평가 프레임워크에서의 벤치마크와 EU AI 법안 간의 미스 매칭을 정량적으로 분석하였으며, 이를 통해 AI 평가 도구의 안전성과 규정 준수 수준을 향상시킬 수 있는 첫 번째 통찰을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 일반 목적 AI 모델의 발전에 따라, EU AI 법안과 같은 새로운 규제 환경에 부합하는 평가 프레임워크가 필요하다.

Method: 194,955개의 질문을 포함한 널리 사용되는 벤치마크와 EU AI 법안의 모델 능력 및 성향 분류를 비교하는 Bench-2-CoP라는 체계를 도입하였다.

Result: AI 평가 생태계가 행동 성향(예: '환각 경향', '차별적 편향')에 치중하고 있으며, 중요한 기능적 능력은 거의 무시되고 있다는 결과를 보여주었다.

Conclusion: 이 연구는 시스템 리스크와 관련된 평가 격차에 대한 첫 번째 포괄적 정량 분석을 제공하여 정책 입안자와 개발자가 보다 안전하고 규정에 맞는 AI를 구축할 수 있도록 돕는다.

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [28] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 대화 감정 인식(ERC) 데이터의 부족과 편향 문제를 해결하기 위해, 자원 효율적인 대규모 언어 모델을 사용하여 새로운 데이터셋을 생성하고, 이를 통해 기존 ERC 벤치마크의 성능을 향상시키는 연구이다.


<details>
  <summary>Details</summary>
Motivation: 대화 중 감정 변화 식별의 중요성을 강조하며, 현재 ERC 데이터의 부족과 그로 인한 문제점을 해결하고자 한다.

Method: 소형의 자원 효율적인 일반 목적의 대규모 언어 모델을 사용하여, 세 가지 주요 ERC 벤치마크를 보완하는 여섯 개의 새로운 데이터셋을 생성한다.

Result: 생성된 데이터셋을 기반으로 훈련된 ERC 분류기 모델이 기존 ERC 벤치마크에서 통계적으로 유의미한 성능 향상을 보이며 강한 견고성을 보인다.

Conclusion: 본 연구를 통해 생성된 데이터셋이 기존의 ERC 분류 작업에서 유용하며, 레이블 불균형이 미치는 영향을 분석하는 데 기여한다.

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [29] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAlign은 LLM의 추론 능력을 향상시키기 위한 효율적인 포스트 트레이닝 프레임워크로, 고품질 데이터 선택 파이프라인을 통해 성능을 크게 개선하면서 데이터 요구량을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)의 추론 능력 향상은 데이터와 계산 비용이 많이 드는 작업이나, 기존의 방법은 확장성에 한계를 둔다.

Method: InfiAlign은 감독된 미세 조정(SFT)과 직접 선호 최적화(DPO)를 결합한 포스트 트레이닝 프레임워크로, 다차원 품질 메트릭을 활용하여 고품질 정렬 데이터를 자동으로 선별하는 robust 데이터 선택 파이프라인을 포함한다.

Result: Qwen2.5-Math-7B-Base 모델에 적용했을 때, SFT 모델이 딥시크-R1-디스틸-Qwen-7B와 동등한 성능을 나타내면서도 훈련 데이터의 약 12%만 사용하였다.

Conclusion: 원칙에 기반한 데이터 선택과 전체 단계의 포스트 트레이닝을 결합함으로써 대규모 추론 모델을 효율적이고 확장 가능하게 정렬할 수 있는 실용적인 솔루션을 제공한다.

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [30] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL은 그래프 탐색을 통한 정밀성과 간결함 균형을 이루는 새로운 프레임워크로, LLM과 결합하여 지식 그래프 기반의 추론 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존의 RAG 접근 방식이 비구조적 데이터에 제한되어 있으며, 지식 그래프와 같은 구조화된 지식을 처리하는 데 어려움이 있다.

Method: GRAIL은 LLM 기반의 무작위 탐색과 경로 필터링을 통합하여 데이터 합성을 위한 파이프라인을 구축하고, 각 작업에 대한 세밀한 추론 경로를 자동으로 생성하는 두 단계의 훈련 과정을 사용한다.

Result: GRAIL은 세 가지 지식 그래프 질문 응답 데이터세트에서 평균적으로 21.01%의 정확도 향상과 22.43%의 F1 향상을 이루었다.

Conclusion: GRAIL은 정밀성과 탐색 폭을 동적으로 균형을 맞추며 대규모 그래프와 상호작용할 수 있는 새로운 인터랙티브 검색 패러다임을 제시한다.

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [31] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 이 논문은 다양한 도메인에서 에이전트 작업 완료를 평가하기 위한 일반화된 모듈형 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 평가 방법은 최종 출력에만 집중하고, 단계별 추론 과정을 간과하고 있으며, 현재의 에이전트 판단 시스템은 특정 도메인에 한정되어 있다.

Method: 제안된 프레임워크는 작업을 하위 작업으로 분해하고 각 단계의 유효성을 검증하여 인간과 유사한 평가를 수행한다.

Result: Magentic-One Actor Agent를 GAIA와 BigCodeBench 두 벤치마크에서 평가하여, 우리의 판단 에이전트가 인간 평가와 더 높은 일치를 보였다.

Conclusion: 제안된 평가 프레임워크는 에이전트 작업 완료를 보다 정확하게 평가하는 잠재력을 보여준다.

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [32] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: LORI라는 AI 기반 도구를 통해 추천서에서 후보자의 리더십 기술을 효율적으로 평가하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 추천서는 표준화된 시험 점수 이외의 후보자의 능력과 경험에 대한 귀중한 통찰을 제공하지만, 검토는 시간과 노력이 많이 소요된다.

Method: 자연어 처리와 RoBERTa 및 LLAMA와 같은 대형 언어 모델을 이용하여 추천서에서 팀워크, 의사소통, 혁신 등의 리더십 속성을 식별한다.

Result: 최신 RoBERTa 모델의 가중치 F1 점수는 91.6%, 정밀도는 92.4%, 재현율은 91.6%로 높은 일관성을 보여준다.

Conclusion: 리더십 기술의 중요성이 커지는 STEM 분야에서 LORI를 대학원 입학 과정에 통합하는 것이 중요하며, 이는 후보자의 능력을 보다 포괄적으로 평가하는 데 기여한다.

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [33] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: MV-Debate는 다양한 관점에서 유해 콘텐츠를 탐지하기 위한 다중 에이전트 토론 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 소셜 미디어의 복잡한 다중 모달 환경에서 유해한 의도를 식별하는 것이 도전적이라는 점에서 출발하였다.

Method: MV-Debate는 표면 분석가, 심층 추론가, 모달리티 대조자, 사회적 맥락가 등 네 가지 보완적인 에이전트를 조합하여 콘텐츠를 분석한다.

Result: 삼 가지 기준 벤치마크 데이터셋에서 MV-Debate는 기존의 단일 모델 및 다중 에이전트 토론 기반을 크게 능가하는 성능을 보였다.

Conclusion: 이 연구는 안전-critical 온라인 환경에서 신뢰할 수 있는 사회적 의도 탐지 향상에 대한 다중 에이전트 토론의 가능성을 강조한다.

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [34] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 본 논문은 능동적 추론(AIF)이 지속적인 인간 보상 공학 없이 경험으로부터 학습할 수 있는 자율 AI 에이전트를 개발하는 데 중요한 기반이 됨을 주장한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템은 고품질 훈련 데이터를 고갈시키고 있으며, 이는 진정한 자율 지능으로 나아가는 데 장애가 될 수 있다.

Method: AIF는 외부 보상 신호를 최소화하려는 내재적 동기로 대체하여 탐색과 착취를 균형 있게 조절할 수 있도록 한다.

Result: AIF와 대형 언어 모델을 통합하여 경험으로부터 효율적으로 학습하면서 인간 가치와 정렬된 에이전트를 생성할 수 있다.

Conclusion: 이 통합은 자율적으로 발전할 수 있는 AI 시스템으로 나아가기 위한 매력적인 경로를 제공한다.

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [35] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: LearnerAgent라는 다중 에이전트 프레임워크를 통해 심리적으로 기반이 된 학습자 프로필을 사용하여 인간의 학습 행동을 모방하고 분석하는 연구를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 심리학과 지능형 시스템에서 인간의 학습 행동을 포착하는 것이 주요 연구 주제로 떠올랐다.

Method: 대규모 언어 모델(LLM)을 기반으로 한 LearnerAgent라는 다중 에이전트 프레임워크를 개발하고, 다양한 학습자 프로필을 사용하여 학습 역학을 탐색한다.

Result: 딥 학습자는 지속적인 인지적 성장에 도달하며, 표면 학습자는 얕은 지식을 드러내는 '덫 질문'으로 진단된다. 각 학습자의 행동 및 인지 패턴은 그들의 심리적 프로필과 밀접하게 일치한다.

Conclusion: 기본 LLM 프로필은 '근면하지만 약한 표면 학습자'로, 이는 우수한 학생처럼 행동하지만 진정한 이해를 결여한 에이전트라는 것을 보여준다.

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [36] [Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](https://arxiv.org/abs/2508.04894)
*Iyiola E. Olatunji,Franziska Boenisch,Jing Xu,Adam Dziedzic*

Main category: cs.CR

TL;DR: 본 연구는 그래프 기반 모델에 적용된 적대적 공격 방법을 활용하여 그래프 인식 LLM의 취약성을 탐구하고, LLAGA와 GRAPHPROMPTER 모델을 대상으로 분석하며, GALGUARD라는 방어 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 그래프 구조 데이터를 활용하여 LLM의 성능을 향상시키지만, 이러한 모델의 적대적 공격에 대한 강건성은 아직 탐구되지 않았다.

Method: 기존의 적대적 공격 방법을 LLAGA와 GRAPHPROMPTER에 적용하여 분석하고, 새로운 공격 경로를 발견했다.

Result: LLAGA의 노드 시퀀스 템플릿이 취약성을 증가시키고, GRAPHPROMPTER의 GNN 인코더는 더 높은 강건성을 보임을 확인했다.

Conclusion: GALGUARD라는 방어 프레임워크를 통해 피쳐 수정 모듈과 GNN 방어를 결합하여 구조적 공격으로부터 보호할 수 있음을 제안한다.

Abstract: Large Language Models (LLMs) are increasingly integrated with
graph-structured data for tasks like node classification, a domain
traditionally dominated by Graph Neural Networks (GNNs). While this integration
leverages rich relational information to improve task performance, their
robustness against adversarial attacks remains unexplored. We take the first
step to explore the vulnerabilities of graph-aware LLMs by leveraging existing
adversarial attack methods tailored for graph-based models, including those for
poisoning (training-time attacks) and evasion (test-time attacks), on two
representative models, LLAGA (Chen et al. 2024) and GRAPHPROMPTER (Liu et al.
2024). Additionally, we discover a new attack surface for LLAGA where an
attacker can inject malicious nodes as placeholders into the node sequence
template to severely degrade its performance. Our systematic analysis reveals
that certain design choices in graph encoding can enhance attack success, with
specific findings that: (1) the node sequence template in LLAGA increases its
vulnerability; (2) the GNN encoder used in GRAPHPROMPTER demonstrates greater
robustness; and (3) both approaches remain susceptible to imperceptible feature
perturbation attacks. Finally, we propose an end-to-end defense framework
GALGUARD, that combines an LLM-based feature correction module to mitigate
feature-level perturbations and adapted GNN defenses to protect against
structural attacks.

</details>


### [37] [On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups](https://arxiv.org/abs/2508.05048)
*Mohammad Ferry Husnil Arif,Muhammad Imran*

Main category: cs.CR

TL;DR: 이 논문은 비가환 구조를 가진 반직접 이산 로그 문제(SDLP)의 고전적 난이도를 조사하고, 표준 이산 로그 문제(DLP) 대비 SDLP의 이점이 있는지 평가한다.


<details>
  <summary>Details</summary>
Motivation: 양자 공격에 대한 저항력을 기반으로 개선된 보안 프로토콜이 필요했으나 SDLP가 효율적인 양자 알고리즘에 의해 위협받고 있다.

Method: SDLP를 일반화된 이산 로그 문제로 재구성하고, 이를 통해 존재하는 고전 알고리즘을 적응시켜 분석한다. Baby-Step Giant-Step 알고리즘을 SDLP에 구체적으로 적용한다.

Result: SDLP의 고전적 난이도는 플랫폼에 따라 크게 다르고, 유한체에서 SDLP와 DLP는 비슷한 복잡성을 보인다. 점근적 곡선에서 SDLP는 수렴적으로 간단해지지만, 특정 그룹에서는 더 어려울 수 있다.

Conclusion: 비가환의 구조가 고전적 난이도를 보장하지 않으며, 암호학적 응용을 위한 고전적으로 어려운 문제 탐색에는 더 정교한 기본 대수적 구조 고려가 필요하다는 점이 드러났다.

Abstract: The semidirect discrete logarithm problem (SDLP) in finite groups was
proposed as a foundation for post-quantum cryptographic protocols, based on the
belief that its non-abelian structure would resist quantum attacks. However,
recent results have shown that SDLP in finite groups admits efficient quantum
algorithms, undermining its quantum resistance. This raises a fundamental
question: does the SDLP offer any computational advantages over the standard
discrete logarithm problem (DLP) against classical adversaries? In this work,
we investigate the classical hardness of SDLP across different finite group
platforms. We establish that the group-case SDLP can be reformulated as a
generalized discrete logarithm problem, enabling adaptation of classical
algorithms to study its complexity. We present a concrete adaptation of the
Baby-Step Giant-Step algorithm for SDLP, achieving time and space complexity
$O(\sqrt{r})$ where $r$ is the period of the underlying cycle structure.
Through theoretical analysis and experimental validation in SageMath, we
demonstrate that the classical hardness of SDLP is highly platform-dependent
and does not uniformly exceed that of standard DLP. In finite fields
$\mathbb{F}_p^*$, both problems exhibit comparable complexity. Surprisingly, in
elliptic curves $E(\mathbb{F}_p)$, the SDLP becomes trivial due to the bounded
automorphism group, while in elementary abelian groups $\mathbb{F}_p^n$, the
SDLP can be harder than DLP, with complexity varying based on the eigenvalue
structure of the automorphism. Our findings reveal that the non-abelian
structure of semidirect products does not inherently guarantee increased
classical hardness, suggesting that the search for classically hard problems
for cryptographic applications requires more careful consideration of the
underlying algebraic structures.

</details>


### [38] [Incident Response Planning Using a Lightweight Large Language Model with Reduced Hallucination](https://arxiv.org/abs/2508.05188)
*Kim Hammar,Tansu Alpcan,Emil C. Lupu*

Main category: cs.CR

TL;DR: 캐나다의 사이버 공격 빈도가 증가함에 따라 효과적인 사고 대응이 중요하다는 점에서, 본 연구는 대규모 언어 모델을 활용하여 사고 대응 계획의 환각을 줄이는 새로운 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 공격의 빈도가 증가함에 따라 효과적인 사고 대응이 필요하지만 복잡한 시스템에 대한 적절한 대응 작업 식별이 기술적으로 어려운 문제이다.

Method: 본 방법은 세 단계(미세 조정, 정보 검색, 선견지명 계획)로 구성되어 있으며, 환각 확률을 제한적으로 생성할 수 있다고 보고한다.

Result: 우리 방법은 전통적인 LLM 대비 회복 시간이 최대 22% 단축되며, 다양한 사건 유형 및 대응 작업에 일반화될 수 있음을 보여준다.

Conclusion: 환각 확률을 감소시키면서 경량화된 하드웨어에서도 실행 가능하여 실용성이 높다.

Abstract: Timely and effective incident response is key to managing the growing
frequency of cyberattacks. However, identifying the right response actions for
complex systems is a major technical challenge. A promising approach to
mitigate this challenge is to use the security knowledge embedded in large
language models (LLMs) to assist security operators during incident handling.
Recent research has demonstrated the potential of this approach, but current
methods are mainly based on prompt engineering of frontier LLMs, which is
costly and prone to hallucinations. We address these limitations by presenting
a novel way to use an LLM for incident response planning with reduced
hallucination. Our method includes three steps: fine-tuning, information
retrieval, and lookahead planning. We prove that our method generates response
plans with a bounded probability of hallucination and that this probability can
be made arbitrarily small at the expense of increased planning time under
certain assumptions. Moreover, we show that our method is lightweight and can
run on commodity hardware. We evaluate our method on logs from incidents
reported in the literature. The experimental results show that our method a)
achieves up to 22% shorter recovery times than frontier LLMs and b) generalizes
to a broad range of incident types and response actions.

</details>


### [39] [An Overview of 7726 User Reports: Uncovering SMS Scams and Scammer Strategies](https://arxiv.org/abs/2508.05276)
*Sharad Agarwal,Guillermo Suarez-Tangil,Marie Vasek*

Main category: cs.CR

TL;DR: 이 논문은 사용자 신고를 기반으로 SMS 스팸 및 사기 메시지를 분석하여 차별화된 범주를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 모바일 네트워크 운영자가 차단하지 못하고 사용자에게 도달한 SMS 메시지에 대한 통찰력을 제공하기 위해 수행되었다.

Method: 주요 모바일 네트워크 운영자와 협력하여 4개월 동안 1.35백만 건의 사용자 신고 데이터를 수집하고, 이를 분석하여 스팸과 사기를 식별하였다.

Result: 사용자 신고의 89.16%가 텍스트 메시지로, 그 중 35.12%는 스팸으로, 40.27%는 사기 메시지로 분류되었다.

Conclusion: 본 연구는 SMS 신고를 통해 사기 메시지를 12가지 유형으로 분류하고, 사기꾼이 사용하는 다양한 인프라 서비스를 탐색하였다.

Abstract: Mobile network operators implement firewalls to stop illicit messages, but
scammers find ways to evade detection. Previous work has looked into SMS texts
that are blocked by these firewalls. However, there is little insight into SMS
texts that bypass them and reach users. To this end, we collaborate with a
major mobile network operator to receive 1.35m user reports submitted over four
months. We find 89.16% of user reports comprise text messages, followed by
reports of suspicious calls and URLs. Using our methodological framework, we
identify 35.12% of the unique text messages reported by users as spam, while
40.27% are scam text messages. This is the first paper that investigates SMS
reports submitted by users and differentiates between spam and scams. Our paper
classifies the identified scam text messages into 12 scam types, of which the
most popular is 'wrong number' scams. We explore the various infrastructure
services that scammers abuse to conduct SMS scams, including mobile network
operators and hosting infrastructure, and analyze the text of the scam messages
to understand how scammers lure victims into providing them with their personal
or financial details.

</details>


### [40] [ShikkhaChain: A Blockchain-Powered Academic Credential Verification System for Bangladesh](https://arxiv.org/abs/2508.05334)
*Ahsan Farabi,Israt Khandaker,Nusrat Jahan,Ibrahim Khalil Shanto*

Main category: cs.CR

TL;DR: ShikkhaChain은 블록체인 기반의 학위 인증 관리 플랫폼으로, 방글라데시에서의 학위 인증 사기를 해결하기 위해 안전하게 인증서를 발행, 검증, 철회할 수 있도록 설계되었다.


<details>
  <summary>Details</summary>
Motivation: 방글라데시와 같은 개발도상국에서 학술 자격 증명서 사기가 교육의 신뢰성을 위협하고 있다.

Method: ShikkhaChain은 이더리움 스마트 계약과 IPFS를 기반으로 하여 인증서를 안전하게 발행하고 검증하는 분산형 플랫폼이다.

Result: 프로토타입은 신뢰를 향상시키고, 검증 시간을 단축시켜, 방글라데시 학위의 국제적인 신뢰성을 높였다.

Conclusion: ShikkhaChain은 더 신뢰할 수 있는 학술 및 고용 생태계를 촉진하는 투명하고 확장 가능한 솔루션을 제공한다.

Abstract: Academic credential fraud threatens educational integrity, especially in
developing countries like Bangladesh, where verification methods are primarily
manual and inefficient. To address this challenge, we present ShikkhaChain, a
blockchain-powered certificate management platform designed to securely issue,
verify, and revoke academic credentials in a decentralized and tamper-proof
manner. Built on Ethereum smart contracts and utilizing IPFS for off-chain
storage, the platform offers a transparent, scalable solution accessible
through a React-based DApp with MetaMask integration. ShikkhaChain enables
role-based access for governments, regulators, institutions, and public
verifiers, allowing QR-based validation and on-chain revocation tracking. Our
prototype demonstrates enhanced trust, reduced verification time, and improved
international credibility for Bangladeshi degrees, promoting a more reliable
academic and employment ecosystem.

</details>


### [41] [Grouped k-threshold random grid-based visual cryptography scheme](https://arxiv.org/abs/2508.05394)
*Xiaoli Zhuo,Xuehu Yan,Wei Yan*

Main category: cs.CR

TL;DR: 이 논문은 새로운 시각 암호화 기법인 $n'$-grouped $(k,n)$ RGVCS를 제안하며, 이 기법은 높은 대비를 달성하고 최적의 복구 품질을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 $(k,n)$ RGVCS는 대비의 이론적 상한에 도달하지 못해, 더 높은 대비 구조의 필요성이 대두되었다.

Method: 이 논문은 임의의 $(k,n')$ 임계값 체계에서 $(k,n)$-임계값 체계를 구성하는 새로운 공유 패러다임을 제안한다.

Result: 새로운 대비 계산 공식을 도입하고, $n'=k$로 설정하여 기존 문헌에서 문서화된 가장 높은 대비 값을 달성하였다.

Conclusion: 이론적 분석과 실험 결과는 우리가 제안한 기법이 대비 측면에서 우수함을 보여준다.

Abstract: Visual cryptography schemes (VCSs) belong to a category of secret image
sharing schemes that do not require cryptographic knowledge for decryption,
instead relying directly on the human visual system. Among VCSs, random
grid-based VCS (RGVCS) has garnered widespread attention as it avoids pixel
expansion while requiring no basic matrices design. Contrast, a core metric for
RGVCS, directly determines the visual quality of recovered images, rendering
its optimization a critical research objective. However, existing $(k,n)$
RGVCSs still fail to attain theoretical upper bounds on contrast, highlighting
the urgent need for higher-contrast constructions. In this paper, we propose a
novel sharing paradigm for RGVCS that constructs $(k,n)$-threshold schemes from
arbitrary $(k,n')$-threshold schemes $(k \leq n'\leq n)$, termed
\emph{$n'$-grouped $(k,n)$ RGVCS}. This paradigm establishes hierarchical
contrast characteristics: participants within the same group achieve optimal
recovery quality, while inter-group recovery shows a hierarchical contrast. We
further introduce a new contrast calculation formula tailored to the new
paradigm. Then, we propose a contrast-enhanced $(k,n)$ RGVCS by setting $n'=
k$, achieving the highest contrast value documented in the existing literature.
Theoretical analysis and experimental results demonstrate the superiority of
our proposed scheme in terms of contrast.

</details>


### [42] [Local Distance Query with Differential Privacy](https://arxiv.org/abs/2508.05518)
*Weihong Sheng,Jiajun Chen,Bin Cai,Chunqiang Hu,Meng Han,Jiguo Yu*

Main category: cs.CR

TL;DR: 이 논문은 로컬 차별적 프라이버시 하에서 그래프 분석을 위한 거리 쿼리를 수행하기 위한 두 가지 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계에서는 신뢰할 수 있는 주최자가 없을 때 차별적 프라이버시를 유지한 거리 쿼리를 수행하는 데 어려움이 존재합니다.

Method: 첫 번째 접근 방식은 응답을 무작위화하여 합성 그래프를 생성하고, 두 번째 접근 방식은 이웃 정점의 로컬 거리 벡터를 지속적으로 수집하여 전역 그래프 구조를 캡처하는 LDP 방법입니다.

Result: 이 방법은 전역 거리의 정확한 업데이트를 가능하게 하며, 실제 데이터셋에 대한 이론적 분석과 실험적 평가를 통해 효과성을 입증합니다.

Conclusion: 제안된 두 가지 접근 방식이 로컬 차별적 프라이버시 하에서의 거리 쿼리에 유용하다는 것을 보여줍니다.

Abstract: Differential Privacy (DP) is commonly employed to safeguard graph analysis or
publishing. Distance, a critical factor in graph analysis, is typically handled
using curator DP, where a trusted curator holds the complete neighbor lists of
all vertices and answers queries privately. However, in many real-world
scenarios, such a curator may not be present, posing a significant challenge
for implementing differentially private distance queries under Local
Differential Privacy (LDP). This paper proposes two approaches to address this
challenge. The first approach generates a synthetic graph by randomizing
responses and applies bitwise operations to reduce noise interference. However,
like other synthetic graph methods, this approach suffers from low utility. To
overcome this limitation, we propose a second approach, the first LDP method
specifically designed for distance queries, which captures the global graph
structure by continuously aggregating local distance vectors from neighboring
vertices. This process enables the accurate updating of global distances. We
demonstrate the effectiveness of our method through comprehensive theoretical
analysis and experimental evaluations on real-world datasets.

</details>


### [43] [PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction](https://arxiv.org/abs/2508.05545)
*Leon Garza,Anantaa Kotal,Aritran Piplai,Lavanya Elluri,Prajit Das,Aman Chadha*

Main category: cs.CR

TL;DR: 이 논문은 개인 식별 정보(PII) 제거를 위한 대형 언어 모델(LLM)의 구조와 훈련 전략을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 데이터 프라이버시를 보장하는 PII 제거의 중요성에 대한 인식이 증대하고 있으며, 기존의 규칙 기반 및 특정 도메인 모델이 일반화에 한계가 있다.

Method: 다양한 LLM 아키텍처와 훈련 전략을 평가하고, 제거 성능, 의미 보존, PII 유출 등을 측정하여 비교한다.

Result: LLM 기반 PII 제거기의 효과적인 구성에 대한 실용적인 지침을 제공하며, 성능, 효율성, 프라이버시 인식을 조합하여 분석한다.

Conclusion: PRvL이라는 오픈 소스 모델과 도구를 제공하여 재현성과 실용적 배포를 지원한다.

Abstract: Redacting Personally Identifiable Information (PII) from unstructured text is
critical for ensuring data privacy in regulated domains. While earlier
approaches have relied on rule-based systems and domain-specific Named Entity
Recognition (NER) models, these methods fail to generalize across formats and
contexts. Recent advances in Large Language Models (LLMs) offer a promising
alternative, yet the effect of architectural and training choices on redaction
performance remains underexplored. LLMs have demonstrated strong performance in
tasks that require contextual language understanding, including the redaction
of PII in free-form text. Prior work suggests that with appropriate adaptation,
LLMs can become effective contextual privacy learners. However, the
consequences of architectural and training choices for PII Redaction remain
underexplored. In this work, we present a comprehensive analysis of LLMs as
privacy-preserving PII Redaction systems. We evaluate a range of LLM
architectures and training strategies for their effectiveness in PII Redaction.
Our analysis measures redaction performance, semantic preservation, and PII
leakage, and compares these outcomes against latency and computational cost.
The results provide practical guidance for configuring LLM-based redactors that
are accurate, efficient, and privacy-aware. To support reproducibility and
real-world deployment, we release PRvL, an open-source suite of fine-tuned
models, and evaluation tools for general-purpose PII Redaction. PRvL is built
entirely on open-source LLMs and supports multiple inference settings for
flexibility and compliance. It is designed to be easily customized for
different domains and fully operable within secure, self-managed environments.
This enables data owners to perform redactions without relying on third-party
services or exposing sensitive content beyond their own infrastructure.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [44] [NAEx: A Plug-and-Play Framework for Explaining Network Alignment](https://arxiv.org/abs/2508.04731)
*Shruti Saxena,Arijit Khan,Joydeep Chandra*

Main category: cs.LG

TL;DR: NAEx는 네트워크 정렬 모델에 대한 설명을 제공하는 프레임워크로, 주요 서브그래프와 특징을 식별하여 예측에 영향을 주는 요소를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 네트워크 정렬 모델의 해석 가능성이 부족하여 신뢰 구축에 어려움이 있어 이를 해결하고자 함.

Method: NAEx는 학습 가능한 엣지 및 특징 마스크를 통해 그래프 구조와 특징 공간을 공동으로 매개변수화하고, 예측에 충실한 설명을 보장하는 최적화 목표를 도입한다.

Result: NAEx는 벤치마크 데이터 세트에서 네 가지 대표적인 NA 모델과 통합하여 효과성과 효율성을 입증하였다.

Conclusion: NAEx는 기존의 데이터를 포함한 새로운 데이터에 대해 NA 설명을 효율적으로 생성하는 유도형 프레임워크이다.

Abstract: Network alignment (NA) identifies corresponding nodes across multiple
networks, with applications in domains like social networks, co-authorship, and
biology. Despite advances in alignment models, their interpretability remains
limited, making it difficult to understand alignment decisions and posing
challenges in building trust, particularly in high-stakes domains. To address
this, we introduce NAEx, a plug-and-play, model-agnostic framework that
explains alignment models by identifying key subgraphs and features influencing
predictions. NAEx addresses the key challenge of preserving the joint
cross-network dependencies on alignment decisions by: (1) jointly
parameterizing graph structures and feature spaces through learnable edge and
feature masks, and (2) introducing an optimization objective that ensures
explanations are both faithful to the original predictions and enable
meaningful comparisons of structural and feature-based similarities between
networks. NAEx is an inductive framework that efficiently generates NA
explanations for previously unseen data. We introduce evaluation metrics
tailored to alignment explainability and demonstrate NAEx's effectiveness and
efficiency on benchmark datasets by integrating it with four representative NA
models.

</details>


### [45] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
*Xiaoqi Dong,Xiangyu Zhou,Nicholas Evans,Yujia Lin*

Main category: cs.LG

TL;DR: LumiGen은 LVLM을 활용하여 T2I 모델 성능을 향상시키는 새로운 프레임워크로, 텍스트 렌더링 및 포즈 표현에서 중요한 개선을 보여줌.


<details>
  <summary>Details</summary>
Motivation: T2I 생성의 복잡한 지시 처리 및 세밀한 내용 제어의 도전 과제를 해결하고자 함.

Method: LumiGen은 Intelligent Prompt Parsing & Augmentation (IPPA) 모듈과 Iterative Visual Feedback & Refinement (IVFR) 모듈로 구성됨.

Result: LumiGen은 LongBench-T2I Benchmark에서 평균 3.08 점수를 기록하며 최신 기술을 초월함.

Conclusion: LVLM 통합의 효과성을 입증하여 더 제어 가능하고 고품질의 이미지 생성을 실현함.

Abstract: Text-to-Image (T2I) generation has made significant advancements with
diffusion models, yet challenges persist in handling complex instructions,
ensuring fine-grained content control, and maintaining deep semantic
consistency. Existing T2I models often struggle with tasks like accurate text
rendering, precise pose generation, or intricate compositional coherence.
Concurrently, Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in cross-modal understanding and instruction following. We propose
LumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I
model performance, particularly in areas requiring fine-grained control,
through a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an
Intelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt
enhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which
acts as a "visual critic" to iteratively correct and optimize generated images.
Evaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a
superior average score of 3.08, outperforming state-of-the-art baselines.
Notably, our framework demonstrates significant improvements in critical
dimensions such as text rendering and pose expression, validating the
effectiveness of LVLM integration for more controllable and higher-quality
image generation.

</details>


### [46] [MissMecha: An All-in-One Python Package for Studying Missing Data Mechanisms](https://arxiv.org/abs/2508.04740)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: MissMecha는 MCAR, MAR, MNAR 가정 하에 결측 데이터를 시뮬레이션, 시각화 및 평가할 수 있는 오픈소스 Python 툴킷이다.


<details>
  <summary>Details</summary>
Motivation: 결측 데이터는 복잡하고 관찰할 수 없는 결측 메커니즘으로 인해 발생하며, 현재 도구는 파편화되어 있고 주로 수치 변수에만 초점을 맞추고 있다.

Method: MissMecha는 수치 및 범주형 특성을 지원하여 혼합형 테이블 데이터셋에 대한 메커니즘 인지 연구를 가능하게 한다.

Result: 이 툴킷은 시각 진단, MCAR 테스트 유틸리티 및 유형 인식 임퓨테이션 평가 메트릭스를 포함하고 있다.

Conclusion: MissMecha는 데이터 품질 연구, 벤치마킹 및 교육을 지원하는 통합 플랫폼을 제공한다.

Abstract: Incomplete data is a persistent challenge in real-world datasets, often
governed by complex and unobservable missing mechanisms. Simulating missingness
has become a standard approach for understanding its impact on learning and
analysis. However, existing tools are fragmented, mechanism-limited, and
typically focus only on numerical variables, overlooking the heterogeneous
nature of real-world tabular data. We present MissMecha, an open-source Python
toolkit for simulating, visualizing, and evaluating missing data under MCAR,
MAR, and MNAR assumptions. MissMecha supports both numerical and categorical
features, enabling mechanism-aware studies across mixed-type tabular datasets.
It includes visual diagnostics, MCAR testing utilities, and type-aware
imputation evaluation metrics. Designed to support data quality research,
benchmarking, and education,MissMecha offers a unified platform for researchers
and practitioners working with incomplete data.

</details>


### [47] [Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)](https://arxiv.org/abs/2508.04745)
*Nan Li,Wanting Yang,Marie Siew,Zehui Xiong,Binbin Chen,Shiwen Mao,Kwok-Yan Lam*

Main category: cs.LG

TL;DR: 본 논문은 다수의 사용자 맞춤형 콘텐츠 생성을 위한 클러스터 인식 계층 연합 집계 프레임워크를 제안하며, 효율성과 확장성을 개선하고 개인 정보를 보호하는 방법을 논의한다.


<details>
  <summary>Details</summary>
Motivation: 자원 제한적인 엣지 기기에서 고품질 콘텐츠 생성을 위한 확산 모델의 높은 계산 요구 사항과 개인 정보 보호, 효율성, 통신 비용의 문제를 해결하기 위해 이 연구가 필요하다.

Method: 로우랭크 적응(LoRA)을 통해 파라미터 효율적인 로컬 미세 조정을 기반으로 한 클러스터 인식 계층 연합 집계 프레임워크를 제안한다. 클러스터링과 집계 과정을 통해 개인화된 모델을 훈련한다.

Result: 이 프레임워크는 사용자 맞춤형 모델과 서버의 공유된 글로벌 모델을 동시에 훈련시켜, 엣지 추론을 효과적으로 수행하며, 데이터 전송 전 클러스터링 프롬프트를 인코딩하여 개인정보 유출 위험을 줄인다.

Conclusion: 본 연구는 엣지 제약 조건 하에서 다수 사용자 맞춤형 AIGC 서비스를 위한 실용적인 가능성을 유지하면서 가속화된 수렴을 달성하는 것을 입증하였다.

Abstract: Diffusion models (DMs) have emerged as powerful tools for high-quality
content generation, yet their intensive computational requirements for
inference pose challenges for resource-constrained edge devices. Cloud-based
solutions aid in computation but often fall short in addressing privacy risks,
personalization efficiency, and communication costs in multi-user edge-AIGC
scenarios. To bridge this gap, we first analyze existing edge-AIGC applications
in personalized content synthesis, revealing their limitations in efficiency
and scalability. We then propose a novel cluster-aware hierarchical federated
aggregation framework. Based on parameter-efficient local fine-tuning via
Low-Rank Adaptation (LoRA), the framework first clusters clients based on the
similarity of their uploaded task requirements, followed by an intra-cluster
aggregation for enhanced personalization at the server-side. Subsequently, an
inter-cluster knowledge interaction paradigm is implemented to enable
hybrid-style content generation across diverse clusters.Building upon federated
learning (FL) collaboration, our framework simultaneously trains personalized
models for individual users at the devices and a shared global model enhanced
with multiple LoRA adapters on the server,enabling efficient edge inference;
meanwhile, all prompts for clustering and inference are encoded prior to
transmission, thereby further mitigating the risk of plaintext leakage. Our
evaluations demonstrate that the framework achieves accelerated convergence
while maintaining practical viability for scalable multi-user personalized AIGC
services under edge constraints.

</details>


### [48] [A Foundational Multi-Modal Model for Few-Shot Learning](https://arxiv.org/abs/2508.04746)
*Pengtao Dang,Tingbo Guo,Sha Cao,Chi Zhang*

Main category: cs.LG

TL;DR: 이 논문에서는 데이터가 제한적인 과학 분야를 위한 효율적인 Few-shot 학습(FSL) 접근 방식을 소개하며, 대규모 다중 모달 모델(LMMM)을 활용하여 기존 메타 학습 모델보다 향상된 일반화 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 의료, 환경, 재료 및 기계 과학 분야에서 표본이 제한적이고 데이터 수집이 비싸고 시간이 많이 소요되는 문제를 해결하고자 함.

Method: 다양한 도메인과 입력 모달리티를 포함한 독립 작업 집합에서 훈련된 LMMM을 사용하고, 10,000개 이상의 FSL 샘플을 포함하는 다중 모달 모델 FSL 데이터셋(M3FD)을 구축하여 FSL 작업을 수동으로 큐레이션함.

Result: M3F 프레임워크가 M3FD에서 모델 성능을 개선하고, 기존 메타 학습 기반 모델을 능가하는 결과를 도출함.

Conclusion: M3FD와 M3F를 결합하여 데이터가 부족한 과학 분야에 LMMMs를 적용하는 장벽을 크게 낮추는 통합된 솔루션을 제공한다.

Abstract: Few-shot learning (FSL) is a machine learning paradigm that aims to
generalize models from a small number of labeled examples, typically fewer than
10 per class. FSL is particularly crucial in biomedical, environmental,
materials, and mechanical sciences, where samples are limited and data
collection is often prohibitively costly, time-consuming, or ethically
constrained. In this study, we present an innovative approach to FSL by
demonstrating that a Large Multi-Modal Model (LMMM), trained on a set of
independent tasks spanning diverse domains, task types, and input modalities,
can substantially improve the generalization of FSL models, outperforming
models based on conventional meta-learning on tasks of the same type. To
support this, we first constructed a Multi-Modal Model Few-shot Dataset (M3FD,
over 10K+ few-shot samples), which includes 2D RGB images, 2D/3D medical scans,
tabular and time-course datasets, from which we manually curated FSL tasks such
as classification. We further introduced M3F (Multi-Modal Model for Few-shot
learning framework), a novel Large Multi-Modal Model framework tailored for
data-constrained scientific applications. M3F supports a wide range of
scientific data types through a modular pipeline. By fine-tuning the model on
M3FD, M3F improves model performance, making LMMM feasible for real-world FSL
deployment. The source code is located at https://github.com/ptdang1001/M3F. To
democratize access to complex FSL data and promote reproducibility for public
usage, M3FD is paired with a flexible and user-friendly tool that enables
efficient querying, task-specific sampling, and preprocessing. Together, our
dataset and framework offer a unified, scalable solution that significantly
lowers the barrier to applying LMMMs in data-scarce scientific domains.

</details>


### [49] [Optimizing IoT Threat Detection with Kolmogorov-Arnold Networks (KANs)](https://arxiv.org/abs/2508.05591)
*Natalia Emelianova,Carlos Kamienski,Ronaldo C. Prati*

Main category: cs.LG

TL;DR: KANs는 IoT 네트워크의 침입 탐지에서 전통적인 기계 학습 모델보다 우수한 성과를 보인다.


<details>
  <summary>Details</summary>
Motivation: IoT의 급격한 발전으로 인해 보안 우려가 증가하고, IoT 네트워크가 사이버 공격의 주요 표적이 되고 있다.

Method: Kolmogorov-Arnold Networks (KANs)를 사용하여 IoT 네트워크의 침입 탐지에 대한 연구를 진행하였다.

Result: KANs는 배우는 활성화 함수를 통해 전통적인 MLP보다 뛰어난 성능을 나타내며, Random Forest 및 XGBoost와 견줄만한 정확도를 달성하였다.

Conclusion: KANs는 IoT 네트워크의 침입 탐지에 있어 우수한 해석 가능성을 제공한다.

Abstract: The exponential growth of the Internet of Things (IoT) has led to the
emergence of substantial security concerns, with IoT networks becoming the
primary target for cyberattacks. This study examines the potential of
Kolmogorov-Arnold Networks (KANs) as an alternative to conventional machine
learning models for intrusion detection in IoT networks. The study demonstrates
that KANs, which employ learnable activation functions, outperform traditional
MLPs and achieve competitive accuracy compared to state-of-the-art models such
as Random Forest and XGBoost, while offering superior interpretability for
intrusion detection in IoT networks.

</details>


### [50] [MoMA: A Mixture-of-Multimodal-Agents Architecture for Enhancing Clinical Prediction Modelling](https://arxiv.org/abs/2508.05492)
*Jifan Gao,Mahmudur Rahman,John Caskey,Madeline Oguss,Ann O'Rourke,Randy Brown,Anne Stey,Anoop Mayampurath,Matthew M. Churpek,Guanhua Chen,Majid Afshar*

Main category: cs.LG

TL;DR: MoMA라는 새로운 구조가 다양한 모달리티의 전자 건강 기록(EHR) 데이터를 통합하여 임상 예측 모델링을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 모달리티의 EHR 데이터가 환자 건강에 대한 보다 풍부한 통찰력을 제공하지만, 데이터 통합이 어려움이 있다.

Method: MoMA는 다수의 대형 언어 모델(LLM) 에이전트를 사용하여 비텍스트적 모달리티를 구조화된 텍스트 요약으로 변환하고, 이를 통해 통합된 다중 모달 요약을 생성한다.

Result: MoMA는 세 가지 예측 작업에서 실제 데이터세트를 사용하여 평가되었으며, 현행 최고 성능 방법론을 초월하는 정확도와 유연성을 입증하였다.

Conclusion: MoMA는 다양한 작업에서 임상 예측을 위한 효과적인 솔루션을 제공한다.

Abstract: Multimodal electronic health record (EHR) data provide richer, complementary
insights into patient health compared to single-modality data. However,
effectively integrating diverse data modalities for clinical prediction
modeling remains challenging due to the substantial data requirements. We
introduce a novel architecture, Mixture-of-Multimodal-Agents (MoMA), designed
to leverage multiple large language model (LLM) agents for clinical prediction
tasks using multimodal EHR data. MoMA employs specialized LLM agents
("specialist agents") to convert non-textual modalities, such as medical images
and laboratory results, into structured textual summaries. These summaries,
together with clinical notes, are combined by another LLM ("aggregator agent")
to generate a unified multimodal summary, which is then used by a third LLM
("predictor agent") to produce clinical predictions. Evaluating MoMA on three
prediction tasks using real-world datasets with different modality combinations
and prediction settings, MoMA outperforms current state-of-the-art methods,
highlighting its enhanced accuracy and flexibility across various tasks.

</details>


### [51] [AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models](https://arxiv.org/abs/2508.04748)
*Xuan Lin,Long Chen,Yile Wang*

Main category: cs.LG

TL;DR: AttriLens-Mol은 대형 언어 모델을 사용한 분자 속성 예측을 위해 설계된 강화 학습 프레임워크로, 모델의 추론을 유도하여 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 분자 속성 예측에서 LLM의 전통적인 방법은 수작업으로 설계된 프롬프트와 사고 과정을 필요로 하며, 이는 중요한 관련성을 잃을 수 있다.

Method: AttriLens-Mol은 속성 기반 구조 출력을 장려하는 형식 보상, 불필요한 속열 나열을 피하기 위한 개수 보상, 생성된 속성의 관련성을 검증하기 위한 합리성 보상을 사용하는 Attribute-guided reinforcement learning 프레임워크이다.

Result: AttriLens-Mol 방식으로 훈련된 모델은 감독적 미세 조정 모델 및 고급 모델들과 유사하거나 더 나은 성능을 보였다.

Conclusion: AttriLens-Mol은 관련성과 예측 가능성이 높은 분자 속성을 이끌어내어 속성 예측의 해석 가능성과 성능을 향상시킨다.

Abstract: Large Language Models (LLMs) have shown promise in assisting molecular
property prediction tasks but often rely on human-crafted prompts and
chain-of-thought templates. While recent advanced large reasoning models like
DeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,
their reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,
an attribute-guided reinforcement learning framework for molecular property
prediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)
a format reward encouraging attribute-based structured output, (2) a count
reward to avoid enumerating irrelevant attributes, and (3) a rationality reward
using advanced LLMs and RDKit to verify the relatedness of the generated
attributes. This approach implicitly elicits the model's inherent knowledge of
relevant molecular attributes during reasoning, enables making predictions for
the molecular property more effectively. Experiments on both in-distribution
and out-of-distribution datasets show that, training both 7B-size
R1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our
proposed AttriLens-Mol method significantly boosts the performance, getting
comparable or better results than supervised fine-tuning models
(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,
DeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the
target property, when used as features for an interpretable decision tree
model, yield superior performance compared to attributes generated by prompting
LLMs. This shows that AttriLens-Mol effectively elicits more relevant and
predictive molecular attributes, leading to enhanced interpretability and
performance for property prediction. We release the code in
https://github.com/szu-tera/AttriLens-Mol.

</details>


### [52] [Non-omniscient backdoor injection with a single poison sample: Proving the one-poison hypothesis for linear regression and linear classification](https://arxiv.org/abs/2508.05600)
*Thorsten Peinemann,Paula Arnold,Sebastian Berndt,Thomas Eisenbarth,Esfandiar Mohammadi*

Main category: cs.LG

TL;DR: 본 논문은 최소한의 정보로 하나의 독성 샘플만으로도 백도어 공격을 성공적으로 수행할 수 있다는 것을 증명한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 데이터에서의 백도어 공격의 성공 여부와 그에 필요한 독성 데이터 양에 대한 이해를 돕기 위해.

Method: 하나의 독성 샘플로 백도어를 주입하는 가설을 제기하고, 선형 회귀 및 선형 분류에 대해 이론적인 증명을 수행하였다.

Result: 적절한 방향으로 독성 샘플을 사용하면, 훈련에서 독성을 제외한 모델과 동등한 기능을 가지는 모델을 생성할 수 있다.

Conclusion: 이론적 결과를 현실적인 벤치마크 데이터 세트로 실험하여 확인하였다.

Abstract: Backdoor injection attacks are a threat to machine learning models that are
trained on large data collected from untrusted sources; these attacks enable
attackers to inject malicious behavior into the model that can be triggered by
specially crafted inputs. Prior work has established bounds on the success of
backdoor attacks and their impact on the benign learning task, however, an open
question is what amount of poison data is needed for a successful backdoor
attack. Typical attacks either use few samples, but need much information about
the data points or need to poison many data points.
  In this paper, we formulate the one-poison hypothesis: An adversary with one
poison sample and limited background knowledge can inject a backdoor with zero
backdooring-error and without significantly impacting the benign learning task
performance. Moreover, we prove the one-poison hypothesis for linear regression
and linear classification. For adversaries that utilize a direction that is
unused by the benign data distribution for the poison sample, we show that the
resulting model is functionally equivalent to a model where the poison was
excluded from training. We build on prior work on statistical backdoor learning
to show that in all other cases, the impact on the benign learning task is
still limited. We also validate our theoretical results experimentally with
realistic benchmark data sets.

</details>


### [53] [PA-RNet: Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting](https://arxiv.org/abs/2508.04750)
*Chanjuan Liu,Shengzhi Wang,Enqiang Zhu*

Main category: cs.LG

TL;DR: PA-RNet는 다중 모드 시계열 예측을 위한 강력한 프레임워크로, 텍스트 데이터의 간섭을 효과적으로 처리하여 모델 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 실제 애플리케이션에서 텍스트 모달리티의 간섭이 모델 성능을 저하시킬 수 있다는 문제를 해결하기 위해 연구하였다.

Method: PA-RNet는 간섭 인식 투영 모듈과 크로스 모달 주의 메커니즘을 사용하여 노이즈를 분리하고 의미 있는 표현을 유지한다.

Result: 광범위한 실험을 통해 PA-RNet는 다양한 도메인에서 기존 최첨단 방법에 비해 지속적으로 우수한 성능을 보였다.

Conclusion: 제안된 방법은 텍스트 데이터의 다양한 간섭을 처리함으로써 모델의 일반화 능력을 개선하고 안정성을 보장한다.

Abstract: In real-world applications, multimodal time series data often suffer from
interference, especially in the textual modality. Existing methods for
multimodal time series forecasting often neglect the inherent perturbations
within textual data, where irrelevant, noisy, or ambiguous content can
significantly degrade model performance, particularly when the noise exhibits
varying intensity or stems from structural inconsistencies. To address this
challenge, we propose PA-RNet (Perturbation-Aware Reasoning Network for
Multimodal Time Series Forecasting), a robust multimodal forecasting framework.
PA-RNet features a perturbation-aware projection module and a cross-modal
attention mechanism to effectively separate noise from the textual embeddings
while maintaining semantically meaningful representations, thereby enhancing
the model's generalization ability. Theoretically, we establish the Lipschitz
continuity of PA-RNet with respect to textual inputs and prove that the
proposed perturbation module can reduce expected prediction error, offering
strong guarantees of stability under noisy conditions. Furthermore, we
introduce a textual perturbation pipeline that can be seamlessly incorporated
into existing multimodal time series forecasting tasks, allowing for systematic
evaluation of the model's robustness in the presence of varying levels of
textual noise. Extensive experiments across diverse domains and temporal
settings demonstrate that PA-RNet consistently outperforms state-of-the-art
baselines.

</details>


### [54] [InfoQ: Mixed-Precision Quantization via Global Information Flow](https://arxiv.org/abs/2508.04753)
*Mehmet Emre Akbulut,Hazem Hesham Yousef Shalby,Fabrizio Pittorino,Manuel Roveri*

Main category: cs.LG

TL;DR: 이 논문에서는 리소스 제한 장치에 적합한 Mixed-precision quantization (MPQ) 방법을 제안하며, 새로운 프레임워크인 InfoQ를 도입하여 각 레이어의 양자화 민감도를 측정하고 비트 너비 할당을 최적화한다.


<details>
  <summary>Details</summary>
Motivation: 리소스 제한 장치에서 깊은 신경망을 배포하기 위해 섞인 정밀도 양자화의 필요성과 최적 비트 폭 찾기의 복잡성을 다룬다.

Method: InfoQ 프레임워크는 각 레이어에서 다양한 비트 너비로 양자화하고, 단일 순방향 패스를 통해 다음 레이어에서의 상호 정보 변화를 측정하여 민감도를 평가한다.

Result: 제안된 방법으로 MobileNetV2와 ResNet18에서 ImageNet 데이터셋에 대해 각각 14배와 10.66배의 압축률로 최대 1%의 정확도 향상을 이끌어냈다.

Conclusion: InfoQ는 기존 최첨단 방법보다 검색 시간과 정확도 간의 무역에서 우수한 결과를 제공하며, 훈련 없는 비트 폭 탐색 단계를 통해 효율성을 극대화한다.

Abstract: Mixed-precision quantization (MPQ) is crucial for deploying deep neural
networks on resource-constrained devices, but finding the optimal bit-width for
each layer represents a complex combinatorial optimization problem. Current
state-of-the-art methods rely on computationally expensive search algorithms or
local sensitivity heuristic proxies like the Hessian, which fail to capture the
cascading global effects of quantization error. In this work, we argue that the
quantization sensitivity of a layer should not be measured by its local
properties, but by its impact on the information flow throughout the entire
network. We introduce InfoQ, a novel framework for MPQ that is training-free in
the bit-width search phase. InfoQ assesses layer sensitivity by quantizing each
layer at different bit-widths and measuring, through a single forward pass, the
resulting change in mutual information in the subsequent layers. This
quantifies how much each layer quantization impacts the network information
flow. The resulting scores are used to formulate bit-width allocation as an
integer linear programming problem, which is solved efficiently to minimize
total sensitivity under a given budget (e.g., model size or BitOps). Our
retraining-free search phase provides a superior search-time/accuracy trade-off
(using two orders of magnitude less data compared to state-of-the-art methods
such as LIMPQ), while yielding up to a 1% accuracy improvement for MobileNetV2
and ResNet18 on ImageNet at high compression rates (14X and 10.66X).

</details>


### [55] [Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle](https://arxiv.org/abs/2508.04755)
*Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: 대규모 언어 모델(LLM)을 동적 인슐린 용량 조정 에이전트로 평가하여, 이들이 소규모 신경망 기반 강화 학습 에이전트(SRA)와 비교하여 유사한 성능을 보여주었고, 그러나 비판적인 한계도 드러났다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 기반의 동적 치료 체계(DTR)의 임상 결정 지원 자동화를 위한 대규모 언어 모델(LLM)의 활용 가능성을 탐색하고자 함.

Method: 오픈소스 LLM을 타입 1 당뇨병 시뮬레이터에서 동적 인슐린 용량 조정 에이전트로 평가하고, 성능을 소규모 신경망 기반 RL 에이전트와 비교.

Result: 정교하게 설계된 제로샷 프롬프트를 통해 소규모 LLM이 훈련된 SRA와 유사하거나 우수한 임상 성과 달성; 그러나 과도한 인슐린 투여와 같은 한계도 나타남.

Conclusion: LLM을 임상 작업에 통합할 때 주의가 필요하며, 프롬프트 엔지니어링과 검증이 필수적이며, 언어적 추론과 구조적 생리학적 모델링을 결합한 하이브리드 접근 방식이 필요함.

Abstract: Reinforcement learning (RL)-based dynamic treatment regimes (DTRs) hold
promise for automating complex clinical decision-making, yet their practical
deployment remains hindered by the intensive engineering required to inject
clinical knowledge and ensure patient safety. Recent advancements in large
language models (LLMs) suggest a complementary approach, where implicit prior
knowledge and clinical heuristics are naturally embedded through linguistic
prompts without requiring environment-specific training. In this study, we
rigorously evaluate open-source LLMs as dynamic insulin dosing agents in an in
silico Type 1 diabetes simulator, comparing their zero-shot inference
performance against small neural network-based RL agents (SRAs) explicitly
trained for the task. Our results indicate that carefully designed zero-shot
prompts enable smaller LLMs (e.g., Qwen2.5-7B) to achieve comparable or
superior clinical performance relative to extensively trained SRAs,
particularly in stable patient cohorts. However, LLMs exhibit notable
limitations, such as overly aggressive insulin dosing when prompted with
chain-of-thought (CoT) reasoning, highlighting critical failure modes including
arithmetic hallucination, temporal misinterpretation, and inconsistent clinical
logic. Incorporating explicit reasoning about latent clinical states (e.g.,
meals) yielded minimal performance gains, underscoring the current model's
limitations in capturing complex, hidden physiological dynamics solely through
textual inference. Our findings advocate for cautious yet optimistic
integration of LLMs into clinical workflows, emphasising the necessity of
targeted prompt engineering, careful validation, and potentially hybrid
approaches that combine linguistic reasoning with structured physiological
modelling to achieve safe, robust, and clinically effective decision-support
systems.

</details>


### [56] [Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration](https://arxiv.org/abs/2508.04780)
*Lin Jiang,Dahai Yu,Rongchao Xu,Tian Tang,Guang Wang*

Main category: cs.LG

TL;DR: 극단적인 기후 사건의 증가에 따라 전력 복구의 공정성과 효율성을 갖춘 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 불리한 지역사회에서 복구 요청 제출량이 적어 전력 복구의 공정성이 결여되고, 이들 지역사회가 장기간 전력 중단에 취약해짐을 해결하기 위해.

Method: 예측-최적화 프레임워크인 EPOPR을 설계하였으며, 불확실성을 고려한 수리 기간 예측을 위한 Equity-Conformalized Quantile Regression과 지역에 따른 불확실성 수준에 적응하는 Spatial-Temporal Attentional RL을 포함한다.

Result: EPOPR은 평균 전력 중단 기간을 3.60% 단축시키고, 다양한 지역 간 불공정성을 14.19% 감소시켰다.

Conclusion: 제안된 EPOPR은 전력 복구 과정에서의 효율성과 공정성을 향상시킬 수 있는 효과적인 방법임을 보여줌.

Abstract: The increasing frequency of extreme weather events, such as hurricanes,
highlights the urgent need for efficient and equitable power system
restoration. Many electricity providers make restoration decisions primarily
based on the volume of power restoration requests from each region. However,
our data-driven analysis reveals significant disparities in request submission
volume, as disadvantaged communities tend to submit fewer restoration requests.
This disparity makes the current restoration solution inequitable, leaving
these communities vulnerable to extended power outages. To address this, we aim
to propose an equity-aware power restoration strategy that balances both
restoration efficiency and equity across communities. However, achieving this
goal is challenging for two reasons: the difficulty of predicting repair
durations under dataset heteroscedasticity, and the tendency of reinforcement
learning agents to favor low-uncertainty actions, which potentially undermine
equity. To overcome these challenges, we design a predict-then-optimize
framework called EPOPR with two key components: (1) Equity-Conformalized
Quantile Regression for uncertainty-aware repair duration prediction, and (2)
Spatial-Temporal Attentional RL that adapts to varying uncertainty levels
across regions for equitable decision-making. Experimental results show that
our EPOPR effectively reduces the average power outage duration by 3.60% and
decreases inequity between different communities by 14.19% compared to
state-of-the-art baselines.

</details>


### [57] [Federated Continual Recommendation](https://arxiv.org/abs/2508.04792)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Seongjin Choi,Dongha Kim,Hwanjo Yu*

Main category: cs.LG

TL;DR: F3CRec는 개인 정보를 보호하면서 streaming 데이터를 학습하도록 설계된 새로운 연합 지속 추천 프레임워크로, 추천 품질을 유지하며 기존 방식보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 추천 시스템에서 개인 정보 보호의 필요성이 증가함에 따라, 사용자의 데이터를 공유하지 않고도 협력적 훈련이 가능한 연합 학습이 채택되었다.

Method: F3CRec는 클라이언트 측의 적응형 재생 메모리와 서버 측의 항목별 시간 평균을 통해 지식 보존과 적응 균형을 맞추도록 설계되었다.

Result: F3CRec는 연합 환경에서 시간에 따라 추천 품질을 유지하는 데 있어 기존 접근 방식보다 성능이 우수하다.

Conclusion: F3CRec는 연합 학습 및 지속 학습의 경계를 넘는 새로운 접근 방식을 제시하며 개인 정보 보호를 유지하면서 추천 품질을 개선할 수 있다.

Abstract: The increasing emphasis on privacy in recommendation systems has led to the
adoption of Federated Learning (FL) as a privacy-preserving solution, enabling
collaborative training without sharing user data. While Federated
Recommendation (FedRec) effectively protects privacy, existing methods struggle
with non-stationary data streams, failing to maintain consistent recommendation
quality over time. On the other hand, Continual Learning Recommendation (CLRec)
methods address evolving user preferences but typically assume centralized data
access, making them incompatible with FL constraints. To bridge this gap, we
introduce Federated Continual Recommendation (FCRec), a novel task that
integrates FedRec and CLRec, requiring models to learn from streaming data
while preserving privacy. As a solution, we propose F3CRec, a framework
designed to balance knowledge retention and adaptation under the strict
constraints of FCRec. F3CRec introduces two key components: Adaptive Replay
Memory on the client side, which selectively retains past preferences based on
user-specific shifts, and Item-wise Temporal Mean on the server side, which
integrates new knowledge while preserving prior information. Extensive
experiments demonstrate that F3CRec outperforms existing approaches in
maintaining recommendation quality over time in a federated environment.

</details>


### [58] [HCRide: Harmonizing Passenger Fairness and Driver Preference for Human-Centered Ride-Hailing](https://arxiv.org/abs/2508.04811)
*Lin Jiang,Yu Yang,Guang Wang*

Main category: cs.LG

TL;DR: HCRide는 승객 공정성과 운전사 선호를 고려하여 라이딩 호출 시스템의 효율성을 향상시키는 혁신적인 다중 에이전트 강화 학습 알고리즘을 기반으로 한다.


<details>
  <summary>Details</summary>
Motivation: 주요 목표는 운영자의 수익을 포함한 시스템 효율성 향상과 승객 및 운전사 모두의 경험을 개선하는 것이다.

Method: HCRide는 다중 에이전트 경쟁 메커니즘, 동적 Actor 네트워크, Bi-Critic 네트워크를 포함하는 Harmonization-oriented Actor-Bi-Critic (Habic) 알고리즘을 사용하여 설계되었다.

Result: HCRide는 시스템 효율성이 2.02%, 공정성 5.39%, 운전사 선호도가 10.21% 향상되었다.

Conclusion: HCRide는 현존하는 최첨단 기법들에 비해 모든 주요 성과 지표에서 개선된 결과를 나타낸다.

Abstract: Order dispatch systems play a vital role in ride-hailing services, which
directly influence operator revenue, driver profit, and passenger experience.
Most existing work focuses on improving system efficiency in terms of operator
revenue, which may cause a bad experience for both passengers and drivers.
Hence, in this work, we aim to design a human-centered ride-hailing system by
considering both passenger fairness and driver preference without compromising
the overall system efficiency. However, it is nontrivial to achieve this target
due to the potential conflicts between passenger fairness and driver preference
since optimizing one may sacrifice the other. To address this challenge, we
design HCRide, a Human-Centered Ride-hailing system based on a novel
multi-agent reinforcement learning algorithm called Harmonization-oriented
Actor-Bi-Critic (Habic), which includes three major components (i.e., a
multi-agent competition mechanism, a dynamic Actor network, and a Bi-Critic
network) to optimize system efficiency and passenger fairness with driver
preference consideration. We extensively evaluate our HCRide using two
real-world ride-hailing datasets from Shenzhen and New York City. Experimental
results show our HCRide effectively improves system efficiency by 2.02%,
fairness by 5.39%, and driver preference by 10.21% compared to state-of-the-art
baselines.

</details>


### [59] [Unified Flow Matching for Long Horizon Event Forecasting](https://arxiv.org/abs/2508.04843)
*Xiao Shou*

Main category: cs.LG

TL;DR: 비즈니스 및 헬스케어와 같은 여러 분야에서 긴 시간 이벤트 시퀀스를 예측하는 데 있어 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 긴 시간 이벤트 시퀀스 모델링은 헬스케어, 금융 등 여러 실세계 응용에서 중요한 도전 과제이다.

Method: 우리는 연속 및 불연속 플로우 매칭을 통해 비자기 회귀형의 통합된 흐름 매칭 프레임워크를 제안한다.

Result: 우리의 모델은 6개의 실제 벤치마크에서 자율 회귀 모델과 확산 기반 모델보다 더 높은 정확도와 생성 효율성을 보여준다.

Conclusion: 제안된 방법은 긴 수평 이벤트 경로를 일관되게 생성할 수 있는 효율적인 모델임을 입증하였다.

Abstract: Modeling long horizon marked event sequences is a fundamental challenge in
many real-world applications, including healthcare, finance, and user behavior
modeling. Existing neural temporal point process models are typically
autoregressive, predicting the next event one step at a time, which limits
their efficiency and leads to error accumulation in long-range forecasting. In
this work, we propose a unified flow matching framework for marked temporal
point processes that enables non-autoregressive, joint modeling of inter-event
times and event types, via continuous and discrete flow matching. By learning
continuous-time flows for both components, our method generates coherent long
horizon event trajectories without sequential decoding. We evaluate our model
on six real-world benchmarks and demonstrate significant improvements over
autoregressive and diffusion-based baselines in both accuracy and generation
efficiency.

</details>


### [60] [Multi-Stage Knowledge-Distilled VGAE and GAT for Robust Controller-Area-Network Intrusion Detection](https://arxiv.org/abs/2508.04845)
*Robert Frenken,Sidra Ghayour Bhatti,Hanqin Zhang,Qadeer Ahmed*

Main category: cs.LG

TL;DR: 이 논문은 자동차 CAN 통신에 대한 사이버 공격을 탐지하기 위한 다단계 침입 탐지 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: CAN 프로토콜은 보안이 내장되어 있지 않아 사이버 공격에 취약하므로, 이를 해결하기 위한 효율적인 탐지 방법이 필요하다.

Method: 비지도 이상 감지와 감독 그래프 학습을 활용하여, VGAE와 KD-GAT를 결합한 구조적 이상 감지 및 공격 분류를 수행한다.

Result: 여섯 개의 공공 CAN 침입 데이터셋에서 기존 방법보다 평균 16.2% 높은 F1-score를 기록했으며, 특히 불균형 데이터셋에서 55% 개선을 보였다.

Conclusion: 제안된 방법은 강력한 예측 성능을 유지하면서 파라미터 수를 96% 줄이고, 자동차 CAN 트래픽의 공격 탐지에 효과적이다.

Abstract: The Controller Area Network (CAN) protocol is a standard for in-vehicle
communication but remains susceptible to cyber-attacks due to its lack of
built-in security. This paper presents a multi-stage intrusion detection
framework leveraging unsupervised anomaly detection and supervised graph
learning tailored for automotive CAN traffic. Our architecture combines a
Variational Graph Autoencoder (VGAE) for structural anomaly detection with a
Knowledge-Distilled Graph Attention Network (KD-GAT) for robust attack
classification. CAN bus activity is encoded as graph sequences to model
temporal and relational dependencies. The pipeline applies VGAE-based selective
undersampling to address class imbalance, followed by GAT classification with
optional score-level fusion. The compact student GAT achieves 96% parameter
reduction compared to the teacher model while maintaining strong predictive
performance. Experiments on six public CAN intrusion datasets--Car-Hacking,
Car-Survival, and can-train-and-test--demonstrate competitive accuracy and
efficiency, with average improvements of 16.2% in F1-score over existing
methods, particularly excelling on highly imbalanced datasets with up to 55%
F1-score improvements.

</details>


### [61] [Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos](https://arxiv.org/abs/2508.04853)
*Haoyu Zhang,Shihao Zhang,Ian Colbert,Rayan Saab*

Main category: cs.LG

TL;DR: 이번 논문은 OPTQ 및 Qronos의 정량적 오류 경계와 그 이론적 보장을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 제안된 PTQ 알고리즘들이 실제 활용에 있어 엄격한 정량적 이론적 보장이 결여되어 있기 때문이다.

Method: OPTQ의 반복 절차로 인한 양자화 오류를 분석하고, 보정 데이터 및 정규화 파라미터에 의존하는 비-asymptotic 2-노름 오류 경계를 도출한다.

Result: OPTQ와 Qronos에 대한 새로운 이론적 경계를 제시하며, 다양한 설계 선택에 대한 이론적 정당성을 제공한다.

Conclusion: 이 논문은 PTQ 알고리즘의 설계와 조정에 대한 통찰력을 제공하며, 실제 적용에 있어 중요한 이론적 기반을 마련한다.

Abstract: Post-training quantization (PTQ) has become a crucial tool for reducing the
memory and compute costs of modern deep neural networks, including large
language models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as
GPTQ-has emerged as a leading method due to its computational efficiency and
strong empirical performance. Despite its widespread adoption, however, OPTQ
lacks rigorous quantitative theoretical guarantees. This paper presents the
first quantitative error bounds for both deterministic and stochastic variants
of OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ
algorithm. We analyze how OPTQ's iterative procedure induces quantization error
and derive non-asymptotic 2-norm error bounds that depend explicitly on the
calibration data and a regularization parameter that OPTQ uses. Our analysis
provides theoretical justification for several practical design choices,
including the widely used heuristic of ordering features by decreasing norm, as
well as guidance for selecting the regularization parameter. For the stochastic
variant, we establish stronger infinity-norm error bounds, which enable control
over the required quantization alphabet and are particularly useful for
downstream layers and nonlinearities. Finally, we extend our analysis to
Qronos, providing new theoretical bounds, for both its deterministic and
stochastic variants, that help explain its empirical advantages.

</details>


### [62] [Agnostics: Learning to Code in Any Programming Language via Reinforcement with a Universal Learning Environment](https://arxiv.org/abs/2508.04865)
*Aleksander Boruch-Gruszecki,Yangtian Zi,Zixuan Wu,Tejas Oberoi,Carolyn Jane Anderson,Joydeep Biswas,Arjun Guha*

Main category: cs.LG

TL;DR: Agnostics는 언어에 구애받지 않는 후처리 파이프라인으로, 다양한 프로그래밍 언어에서 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 저자들은 고자원 언어에서는 좋은 성능을 보이는 LLM이 저자원 언어에서는 데이터 부족과 후처리 문제로 성과가 낮음을 지적한다.

Method: Agnostics는 코드의 외부 행동만을 평가하여 다양한 언어에서 솔루션을 테스트할 수 있는 검증기를 사용하며, LLM을 통해 기존 유닛 테스트 데이터셋을 I/O 형식으로 변환하고, 언어를 컴파일하고 실행하기 위한 단기 설정을 제공하며, RLVR을 적용한다.

Result: Agnostics는 Lua, Julia, R, OCaml, Fortran 등 다섯 가지 저자원 언어에서 Qwen-3 4B 모델의 성능을 향상시키며, 새로운 상태 최적 결과를 설정하였다.

Conclusion: 저자들은 언어에 구애받지 않는 교육 데이터셋과 훈련 코드를 공개하여, 이론적으로 모든 프로그래밍 언어의 RL 후처리를 쉽게 할 수 있도록 한다.

Abstract: Large language models (LLMs) already excel at writing code in high-resource
languages such as Python and JavaScript, yet stumble on low-resource languages
that remain essential to science and engineering. Besides the obvious shortage
of pre-training data, post-training itself is a bottleneck: every new language
seems to require new datasets, test harnesses, and reinforcement-learning (RL)
infrastructure.
  We introduce Agnostics, a language-agnostic post-training pipeline that
eliminates this per-language engineering. The key idea is to judge code solely
by its externally observable behavior, so a single verifier can test solutions
written in any language. Concretely, we (i) use an LLM to rewrite existing
unit-test datasets into an I/O format, (ii) supply a short configuration that
tells the verifier how to compile and run a target language, and (iii) apply
reinforcement learning with verifiable rewards (RLVR) in a robust code
execution environment.
  Applied to five low-resource languages--Lua, Julia, R, OCaml, and
Fortran--Agnostics (1) improves Qwen-3 4B to performance that rivals other
16B-70B open-weight models; (2) scales cleanly to larger and diverse model
families (Qwen-3 8B, DeepSeek Coder 6.7B Instruct, Phi 4 Mini); and (3) for
${\le} 16$B parameter models, sets new state-of-the-art pass@1 results on
MultiPL-E and a new multi-language version LiveCodeBench that we introduce.
  We will release the language-agnostic training datasets (Ag-MBPP-X,
Ag-Codeforces-X, Ag-LiveCodeBench-X), training code, and ready-to-use
configurations, making RL post-training in any programming language as simple
as editing a short YAML file.

</details>


### [63] [Hilbert Neural Operator: Operator Learning in the Analytic Signal Domain](https://arxiv.org/abs/2508.04882)
*Saman Pordanesh,Pejman Shahsavari,Hossein Ghadjari*

Main category: cs.LG

TL;DR: 이 논문은 힐베르트 변환을 이용하여 신호의 해석적 표현을 학습하는 새로운 신경망 아키텍처인 힐베르트 신경 연산자(HNO)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 부분 미분 방정식의 해 연산자를 학습하기 위한 데이터 기반 패러다임으로 신경 연산자의 한계를 극복하고 더 나은 성능을 목표로 한다.

Method: HNO는 입력 신호를 힐베르트 변환을 통해 해석적 표현으로 매핑하고, 이를 통해 생성된 즉각적인 진폭 및 위상 정보를 학습의 특성으로 활용하여 스펙트럴 컨볼루션을 적용한다.

Result: HNO는 인과적이며 위상 민감한 비정상 시스템의 연산자를 보다 효과적으로 모델링할 수 있는 가능성을 가지고 있다.

Conclusion: HNO 아키텍처는 분석 신호 이론에 뿌리를 두고 있으며, 새로운 신경 연산자로서 부분 미분 방정식 문제에서 효과적이라는 이론적 근거를 제시한다.

Abstract: Neural operators have emerged as a powerful, data-driven paradigm for
learning solution operators of partial differential equations (PDEs).
State-of-the-art architectures, such as the Fourier Neural Operator (FNO), have
achieved remarkable success by performing convolutions in the frequency domain,
making them highly effective for a wide range of problems. However, this method
has some limitations, including the periodicity assumption of the Fourier
transform. In addition, there are other methods of analysing a signal, beyond
phase and amplitude perspective, and provide us with other useful information
to learn an effective network. We introduce the \textbf{Hilbert Neural Operator
(HNO)}, a new neural operator architecture to address some advantages by
incorporating a strong inductive bias from signal processing. HNO operates by
first mapping the input signal to its analytic representation via the Hilbert
transform, thereby making instantaneous amplitude and phase information
explicit features for the learning process. The core learnable operation -- a
spectral convolution -- is then applied to this Hilbert-transformed
representation. We hypothesize that this architecture enables HNO to model
operators more effectively for causal, phase-sensitive, and non-stationary
systems. We formalize the HNO architecture and provide the theoretical
motivation for its design, rooted in analytic signal theory.

</details>


### [64] [Gaussian mixture layers for neural networks](https://arxiv.org/abs/2508.04883)
*Sinho Chewi,Philippe Rigollet,Yuling Yan*

Main category: cs.LG

TL;DR: 본 논문은 확률 측정에 따른 동적 구현을 조사하고, 가우시안 혼합 모델을 사용하여 새로운 GM 레이어를 제안하며, 이를 통해 분류 작업에서 성능을 입증함.


<details>
  <summary>Details</summary>
Motivation: 이 논문은 두 층 신경망의 평균장 이론을 확장하여 직접적으로 확률 측정에서 동적 구현을 탐구하는 데 동기를 두고 있다.

Method: 가우시안 혼합 모델을 사용하여 유연하고 표현력이 풍부한 분포 패밀리를 구성하고, Wasserstein 기울기 흐름 이론을 활용하여 훈련 동력을 도출하였다.

Result: GM 레이어는 두 층 완전 연결 네트워크와 유사한 테스트 성능을 달성하였고, 이러한 동적 행동을 수치적으로 분석하였다.

Conclusion: GM 레이어는 전통적인 완전 연결 층과 비교하여 현저히 다른 행동을 보이며, 평균장 제재에서 신경망 아키텍처에 통합 가능성을 제시하고 있다.

Abstract: The mean-field theory for two-layer neural networks considers infinitely wide
networks that are linearly parameterized by a probability measure over the
parameter space. This nonparametric perspective has significantly advanced both
the theoretical and conceptual understanding of neural networks, with
substantial efforts made to validate its applicability to networks of moderate
width. In this work, we explore the opposite direction, investigating whether
dynamics can be directly implemented over probability measures. Specifically,
we employ Gaussian mixture models as a flexible and expressive parametric
family of distributions together with the theory of Wasserstein gradient flows
to derive training dynamics for such measures. Our approach introduces a new
type of layer -- the Gaussian mixture (GM) layer -- that can be integrated into
neural network architectures. As a proof of concept, we validate our proposal
through experiments on simple classification tasks, where a GM layer achieves
test performance comparable to that of a two-layer fully connected network.
Furthermore, we examine the behavior of these dynamics and demonstrate
numerically that GM layers exhibit markedly different behavior compared to
classical fully connected layers, even when the latter are large enough to be
considered in the mean-field regime.

</details>


### [65] [Uncertainty Quantification for Surface Ozone Emulators using Deep Learning](https://arxiv.org/abs/2508.04885)
*Kelsey Doerksen,Yuliya Marchetti,Steven Lu,Kevin Bowman,James Montgomery,Kazuyuki Miyazaki,Yarin Gal,Freddie Kalaitzis*

Main category: cs.LG

TL;DR: 2023년 현재 세계 인구의 94%가 안전하지 않은 대기 오염 수준에 노출되고 있으며, 본 논문은 U-Net 구조를 이용한 불확실성 인식 모델을 통해 표면 오존의 잔차 예측 및 모델의 성능 향상을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 대기 오염 문제는 전세계적인 위험이며, 전통적인 물리 기반 모델이 보건 영향과 관련된 규모에서 실용성이 떨어진다.

Method: 불확실성 인식 U-Net 구조를 이용하여 MOMO-Chem 모델의 표면 오존 잔차를 베이esian 및 분위수 회귀 방법으로 예측함.

Result: 2019년 6월 북미 및 유럽에서의 잔차 추정 능력을 보여주고, 두 가지 불확실성 정량화 방법 사이의 점수를 하이라이트하며 MOMO-Chem 보정의 최적 및 비최적 기후 관측소를 구별함.

Conclusion: 지형 정보가 표면 오존 잔차 모델링에 미치는 영향을 평가하고, 불확실성 인식 모델을 통한 정책 결정 지원 가능성을 제시함.

Abstract: Air pollution is a global hazard, and as of 2023, 94\% of the world's
population is exposed to unsafe pollution levels. Surface Ozone (O3), an
important pollutant, and the drivers of its trends are difficult to model, and
traditional physics-based models fall short in their practical use for scales
relevant to human-health impacts. Deep Learning-based emulators have shown
promise in capturing complex climate patterns, but overall lack the
interpretability necessary to support critical decision making for policy
changes and public health measures. We implement an uncertainty-aware U-Net
architecture to predict the Multi-mOdel Multi-cOnstituent Chemical data
assimilation (MOMO-Chem) model's surface ozone residuals (bias) using Bayesian
and quantile regression methods. We demonstrate the capability of our
techniques in regional estimation of bias in North America and Europe for June
2019. We highlight the uncertainty quantification (UQ) scores between our two
UQ methodologies and discern which ground stations are optimal and sub-optimal
candidates for MOMO-Chem bias correction, and evaluate the impact of land-use
information in surface ozone residual modeling.

</details>


### [66] [Leveraging Deep Learning for Physical Model Bias of Global Air Quality Estimates](https://arxiv.org/abs/2508.04886)
*Kelsey Doerksen,Yuliya Marchetti,Kevin Bowman,Steven Lu,James Montgomery,Yarin Gal,Freddie Kalaitzis,Kazuyuki Miyazaki*

Main category: cs.LG

TL;DR: 본 연구는 2D 합성곱 신경망을 사용하여 표면 오존 모델 편향을 추정하며, 위성 이미지를 활용하여 모델 예측 정확도를 향상시키는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대기오염은 인류 건강에 가장 큰 위험 요소이며, 표면 오존 모델링의 어려움이 환경 정책에 미치는 영향을 탐색하기 위함입니다.

Method: 2D 합성곱 신경망 기반 아키텍처를 사용하여 MOMO-Chem 모델 잔차를 추정하고, 고해상도 위성 이미지의 토지 이용 정보를 통합합니다.

Result: 북미 및 유럽에서 전통적인 머신러닝 방법보다 물리 모델 잔차를 더 잘 포착하는 능력을 보여줍니다.

Conclusion: 우리의 연구 결과는 도시 스케일에서 오존 편향에 영향을 미치는 요인에 대한 과학적 이해를 향상시켜 환경 정책 개선에 기여할 수 있습니다.

Abstract: Air pollution is the world's largest environmental risk factor for human
disease and premature death, resulting in more than 6 million permature deaths
in 2019. Currently, there is still a challenge to model one of the most
important air pollutants, surface ozone, particularly at scales relevant for
human health impacts, with the drivers of global ozone trends at these scales
largely unknown, limiting the practical use of physics-based models. We employ
a 2D Convolutional Neural Network based architecture that estimate surface
ozone MOMO-Chem model residuals, referred to as model bias. We demonstrate the
potential of this technique in North America and Europe, highlighting its
ability better to capture physical model residuals compared to a traditional
machine learning method. We assess the impact of incorporating land use
information from high-resolution satellite imagery to improve model estimates.
Importantly, we discuss how our results can improve our scientific
understanding of the factors impacting ozone bias at urban scales that can be
used to improve environmental policy.

</details>


### [67] [Retrieval-Augmented Water Level Forecasting for Everglades](https://arxiv.org/abs/2508.04888)
*Rahuul Rangaraj,Jimeng Shi,Rajendra Paudel,Giri Narasimhan,Yanzhao Wu*

Main category: cs.LG

TL;DR: 심층 학습을 활용한 수위 예측 프레임워크인 Retrieval-Augmented Forecasting (RAF)를 통해 환경 수리학에서 예측 정확도를 높임.


<details>
  <summary>Details</summary>
Motivation: Everglades와 같은 생태계 관리에 필수적인 정확한 수위 예측 필요성.

Method: 역사적 유사 다변량 수리 에피소드를 검색하여 모델 입력을 풍부하게 하는 RAF 프레임워크 제안.

Result: RAF 프레임워크가 수위 예측 정확도를 크게 개선함을 확인.

Conclusion: RAF 접근법이 환경 수리학에서의 가능성을 보여줌과 동시에 생태계 관리의 AI 방법 수용 확대를 촉진할 것임.

Abstract: Accurate water level forecasting is crucial for managing ecosystems such as
the Everglades, a subtropical wetland vital for flood mitigation, drought
management, water resource planning, and biodiversity conservation. While
recent advances in deep learning, particularly time series foundation models,
have demonstrated success in general-domain forecasting, their application in
hydrology remains underexplored. Furthermore, they often struggle to generalize
across diverse unseen datasets and domains, due to the lack of effective
mechanisms for adaptation. To address this gap, we introduce
Retrieval-Augmented Forecasting (RAF) into the hydrology domain, proposing a
framework that retrieves historically analogous multivariate hydrological
episodes to enrich the model input before forecasting. By maintaining an
external archive of past observations, RAF identifies and incorporates relevant
patterns from historical data, thereby enhancing contextual awareness and
predictive accuracy without requiring the model for task-specific retraining or
fine-tuning. Furthermore, we explore and compare both similarity-based and
mutual information-based RAF methods. We conduct a comprehensive evaluation on
real-world data from the Everglades, demonstrating that the RAF framework
yields substantial improvements in water level forecasting accuracy. This study
highlights the potential of RAF approaches in environmental hydrology and paves
the way for broader adoption of adaptive AI methods by domain experts in
ecosystem management. The code and data are available at
https://github.com/rahuul2992000/WaterRAF.

</details>


### [68] [Honest and Reliable Evaluation and Expert Equivalence Testing of Automated Neonatal Seizure Detection](https://arxiv.org/abs/2508.04899)
*Jovana Kljajic,John M. O'Toole,Robert Hogan,Tamara Skoric*

Main category: cs.LG

TL;DR: 신생아 발작 탐지를 위한 기계 학습 모델의 신뢰할 수 있는 평가 방안을 제시.


<details>
  <summary>Details</summary>
Motivation: 기존 평가 방법이 일관성이 없고 편향되어 있어 모델 간 비교와 해석에 어려움을 겪고 있다.

Method: 실제 및 합성 발작 주석을 사용하여 기준 성능 메트릭과 동의 전략, 전문가 수준 동등성 테스트를 평가하였다.

Result: Matthews 및 Pearson 상관 계수가 클래스 불균형 하에서 성능을 더 잘 반영했으며, 다수 평가자의 Turing 테스트가 전문가 수준의 AI 성능을 잘 포착하였다.

Conclusion: 신생아 발작 탐지를 위한 AI 방법의 철저하고 정직한 평가를 가능하게 하는 중요한 프레임워크를 제공하였다.

Abstract: Reliable evaluation of machine learning models for neonatal seizure detection
is critical for clinical adoption. Current practices often rely on inconsistent
and biased metrics, hindering model comparability and interpretability.
Expert-level claims about AI performance are frequently made without rigorous
validation, raising concerns about their reliability. This study aims to
systematically evaluate common performance metrics and propose best practices
tailored to the specific challenges of neonatal seizure detection. Using real
and synthetic seizure annotations, we assessed standard performance metrics,
consensus strategies, and human-expert level equivalence tests under varying
class imbalance, inter-rater agreement, and number of raters. Matthews and
Pearson's correlation coefficients outperformed the area under the curve in
reflecting performance under class imbalance. Consensus types are sensitive to
the number of raters and agreement level among them. Among human-expert level
equivalence tests, the multi-rater Turing test using Fleiss k best captured
expert-level AI performance. We recommend reporting: (1) at least one balanced
metric, (2) Sensitivity, specificity, PPV and NPV, (3) Multi-rater Turing test
results using Fleiss k, and (4) All the above on held-out validation set. This
proposed framework provides an important prerequisite to clinical validation by
enabling a thorough and honest appraisal of AI methods for neonatal seizure
detection.

</details>


### [69] [Sensitivity of Stability: Theoretical & Empirical Analysis of Replicability for Adaptive Data Selection in Transfer Learning](https://arxiv.org/abs/2508.04901)
*Prabhav Singh,Jessica Sorrell*

Main category: cs.LG

TL;DR: 전이 학습에서의 복제 가능성 분석을 통해 데이터 선택 전략의 신뢰성을 평가하고, 성능과 일관성 간의 균형을 quantifying하는 새로운 지표를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 전이 학습의 광범위한 채택이 이루어졌으나, 적응형 데이터 선택 전략의 신뢰성은 여전히 이해가 부족하다.

Method: 선택 민감성($Delta_Q$)이라는 새로운 척도를 도입하고, 다수의 실험을 통해 이론적 관계를 검증하였다.

Result: 고도로 적응적인 전략은 우수한 성능을 보이나 높은 복제 실패율을 나타내고, 적은 적응 전략은 낮은 실패율을 유지한다.

Conclusion: 출처 도메인의 사전 훈련이 성능 향상을 유지하면서 실패율을 최대 30%까지 줄이는 강력한 완화 기제로 작용함을 보여준다.

Abstract: The widespread adoption of transfer learning has revolutionized machine
learning by enabling efficient adaptation of pre-trained models to new domains.
However, the reliability of these adaptations remains poorly understood,
particularly when using adaptive data selection strategies that dynamically
prioritize training examples. We present a comprehensive theoretical and
empirical analysis of replicability in transfer learning, introducing a
mathematical framework that quantifies the fundamental trade-off between
adaptation effectiveness and result consistency. Our key contribution is the
formalization of selection sensitivity ($\Delta_Q$), a measure that captures
how adaptive selection strategies respond to perturbations in training data. We
prove that replicability failure probability: the likelihood that two
independent training runs produce models differing in performance by more than
a threshold, increases quadratically with selection sensitivity while
decreasing exponentially with sample size. Through extensive experiments on the
MultiNLI corpus using six adaptive selection strategies - ranging from uniform
sampling to gradient-based selection - we demonstrate that this theoretical
relationship holds precisely in practice. Our results reveal that highly
adaptive strategies like gradient-based and curriculum learning achieve
superior task performance but suffer from high replicability failure rates,
while less adaptive approaches maintain failure rates below 7%. Crucially, we
show that source domain pretraining provides a powerful mitigation mechanism,
reducing failure rates by up to 30% while preserving performance gains. These
findings establish principled guidelines for practitioners to navigate the
performance-replicability trade-off and highlight the need for
replicability-aware design in modern transfer learning systems.

</details>


### [70] [Advancing Hate Speech Detection with Transformers: Insights from the MetaHate](https://arxiv.org/abs/2508.04913)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 트랜스포머 기반 모델을 사용하여 혐오 발언 탐지의 포괄적인 탐색을 수행한 연구로, fine-tuned ELECTRA 모델이 가장 높은 성능을 보임.


<details>
  <summary>Details</summary>
Motivation: 소셜 미디어에서 혐오 발언이 증가하고 있으며, 이는 사회적, 심리적, 신체적 영향이 크기 때문에 이를 해결하는 자동화된 방법이 필요하다.

Method: MetaHate 데이터셋을 사용하여 BERT, RoBERTa, GPT-2, ELECTRA 등 다양한 트랜스포머 모델을 평가하고, fine-tuned ELECTRA 모델을 사용하였다.

Result: fine-tuned ELECTRA 모델이 F1 점수 0.8980으로 가장 높은 성능을 기록함.

Conclusion: 혐오 발언 탐지에는 트랜스포머 모델이 효과적이며, 하지만 풍자와 코딩된 언어, 라벨 노이즈와 같은 분류 오류에 대한 도전 과제가 남아 있다.

Abstract: Hate speech is a widespread and harmful form of online discourse,
encompassing slurs and defamatory posts that can have serious social,
psychological, and sometimes physical impacts on targeted individuals and
communities. As social media platforms such as X (formerly Twitter), Facebook,
Instagram, Reddit, and others continue to facilitate widespread communication,
they also become breeding grounds for hate speech, which has increasingly been
linked to real-world hate crimes. Addressing this issue requires the
development of robust automated methods to detect hate speech in diverse social
media environments. Deep learning approaches, such as vanilla recurrent neural
networks (RNNs), long short-term memory (LSTM), and convolutional neural
networks (CNNs), have achieved good results, but are often limited by issues
such as long-term dependencies and inefficient parallelization. This study
represents the comprehensive exploration of transformer-based models for hate
speech detection using the MetaHate dataset--a meta-collection of 36 datasets
with 1.2 million social media samples. We evaluate multiple state-of-the-art
transformer models, including BERT, RoBERTa, GPT-2, and ELECTRA, with
fine-tuned ELECTRA achieving the highest performance (F1 score: 0.8980). We
also analyze classification errors, revealing challenges with sarcasm, coded
language, and label noise.

</details>


### [71] [ALScope: A Unified Toolkit for Deep Active Learning](https://arxiv.org/abs/2508.04937)
*Chenkai Wu,Yuanyuan Qi,Xiaohao Yang,Jueqing Lu,Gang Liu,Wray Buntine,Lan Du*

Main category: cs.LG

TL;DR: Deep Active Learning(DAL) 플랫폼 ALScope를 제안하며, 여러 데이터셋 및 알고리즘을 통합하여 다양한 실험 환경에서 평가를 수행한다.


<details>
  <summary>Details</summary>
Motivation: DAL의 효율성을 높이고, 다양한 조건에서 공정한 평가를 위해 통합된 플랫폼의 필요성이 제기되었다.

Method: ALScope 플랫폼을 통해 10개의 데이터셋과 21개의 DAL 알고리즘을 통합하여 유연한 실험 설정을 지원.

Result: DAL 알고리즘의 성능은 도메인 및 설정에 따라 크게 다르며, 비표준 상황에서 개선이 필요함을 보였다.

Conclusion: 일부 알고리즘이 좋은 성능을 보였으나, 선택 시간이 길어지는 경향이 있다.

Abstract: Deep Active Learning (DAL) reduces annotation costs by selecting the most
informative unlabeled samples during training. As real-world applications
become more complex, challenges stemming from distribution shifts (e.g.,
open-set recognition) and data imbalance have gained increasing attention,
prompting the development of numerous DAL algorithms. However, the lack of a
unified platform has hindered fair and systematic evaluation under diverse
conditions. Therefore, we present a new DAL platform ALScope for classification
tasks, integrating 10 datasets from computer vision (CV) and natural language
processing (NLP), and 21 representative DAL algorithms, including both
classical baselines and recent approaches designed to handle challenges such as
distribution shifts and data imbalance. This platform supports flexible
configuration of key experimental factors, ranging from algorithm and dataset
choices to task-specific factors like out-of-distribution (OOD) sample ratio,
and class imbalance ratio, enabling comprehensive and realistic evaluation. We
conduct extensive experiments on this platform under various settings. Our
findings show that: (1) DAL algorithms' performance varies significantly across
domains and task settings; (2) in non-standard scenarios such as imbalanced and
open-set settings, DAL algorithms show room for improvement and require further
investigation; and (3) some algorithms achieve good performance, but require
significantly longer selection time.

</details>


### [72] [REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation](https://arxiv.org/abs/2508.04946)
*Nameer Hirschkind,Joseph Liu,Mahesh Kumar Nandwana,Xiao Yu*

Main category: cs.LG

TL;DR: 본 연구에서는 동시 음성 번역 시스템의 번역 품질과 대기 시간 간의 균형을 최적화하기 위한 REINA라는 손실 함수를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 동시 음성 번역 시스템은 번역 품질과 지연 시간 간의 균형을 유지하는 데 어려움이 있습니다.

Method: 정보 이론 원리를 기반으로 한 적응형 정책을 훈련하기 위한 새로운 손실 함수인 REINA를 활용합니다.

Result: REINA를 사용하여 프랑스어, 스페인어, 독일어 간의 동시 음성 번역 모델을 훈련했고, 이전 연구와 비교하여 지연 시간/품질 트레이드오프에서 21% 향상을 보여주었습니다.

Conclusion: REINA는 비스트리밍 기준 BLEU 점수에 대비해 동시 음성 번역 시스템의 효율성을 개선했습니다.

Abstract: Simultaneous Speech Translation (SimulST) systems stream in audio while
simultaneously emitting translated text or speech. Such systems face the
significant challenge of balancing translation quality and latency. We
introduce a strategy to optimize this tradeoff: wait for more input only if you
gain information by doing so. Based on this strategy, we present Regularized
Entropy INformation Adaptation (REINA), a novel loss to train an adaptive
policy using an existing non-streaming translation model. We derive REINA from
information theory principles and show that REINA helps push the reported
Pareto frontier of the latency/quality tradeoff over prior works. Utilizing
REINA, we train a SimulST model on French, Spanish and German, both from and
into English. Training on only open source or synthetically generated data, we
achieve state-of-the-art (SOTA) streaming results for models of comparable
size. We also introduce a metric for streaming efficiency, quantitatively
showing REINA improves the latency/quality trade-off by as much as 21% compared
to prior approaches, normalized against non-streaming baseline BLEU scores.

</details>


### [73] [Self-Error Adjustment: Theory and Practice of Balancing Individual Performance and Diversity in Ensemble Learning](https://arxiv.org/abs/2508.04948)
*Rui Zou*

Main category: cs.LG

TL;DR: SEA는 앙상블 학습에서 정확도와 다양성의 균형을 개선하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 앙상블 학습 방법들은 정확도와 다양성의 Trade-off를 정확하게 조절하는 데 한계가 있다.

Method: SEA는 앙상블 오류를 개별 성능과 다양성으로 나누어 분석하고, 손실 함수에 조절 가능한 매개변수를 도입한다.

Result: SEA는 다양한 데이터셋에서 기존 방법들보다 일관되게 우수한 성능을 보였다.

Conclusion: SEA는 조정 가능성과 성능 조정 전략에서 우수한 성능을 보여 앙상블 학습에 기여할 수 있다.

Abstract: Ensemble learning boosts performance by aggregating predictions from multiple
base learners. A core challenge is balancing individual learner accuracy with
diversity. Traditional methods like Bagging and Boosting promote diversity
through randomness but lack precise control over the accuracy-diversity
trade-off. Negative Correlation Learning (NCL) introduces a penalty to manage
this trade-off but suffers from loose theoretical bounds and limited adjustment
range. To overcome these limitations, we propose a novel framework called
Self-Error Adjustment (SEA), which decomposes ensemble errors into two distinct
components: individual performance terms, representing the self-error of each
base learner, and diversity terms, reflecting interactions among learners. This
decomposition allows us to introduce an adjustable parameter into the loss
function, offering precise control over the contribution of each component,
thus enabling finer regulation of ensemble performance. Compared to NCL and its
variants, SEA provides a broader range of effective adjustments and more
consistent changes in diversity. Furthermore, we establish tighter theoretical
bounds for adjustable ensemble methods and validate them through empirical
experiments. Experimental results on several public regression and
classification datasets demonstrate that SEA consistently outperforms baseline
methods across all tasks. Ablation studies confirm that SEA offers more
flexible adjustment capabilities and superior performance in fine-tuning
strategies.

</details>


### [74] [Compressed Decentralized Momentum Stochastic Gradient Methods for Nonconvex Optimization](https://arxiv.org/abs/2508.04950)
*Wei Liu,Anweshit Panda,Ujwal Pandey,Christopher Brissette,Yikang Shen,George M. Slota,Naigang Wang,Jie Chen,Yangyang Xu*

Main category: cs.LG

TL;DR: 두 가지 압축 분산 알고리즘을 제안하여 비선형 확률 최적화를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 분산 알고리즘에서 모멘텀과 압축 통신의 조합 효과성을 이론적으로 증명하는 것의 어려움 극복.

Method: 모멘텀 기술과 메시지 압축 기술을 적용한 압축 분산 적응 방법 및 압축 분산 헤비볼 방법을 설계.

Result: 두 방법 모두 최적 수렴률을 달성하며 사용자 지정 오차 허용 범위 내에서 선형 속도 향상.

Conclusion: 상태 최상위 방법에 비해 DNN 및 트랜스포머 훈련에서 우수한 실험 성과가 관찰됨.

Abstract: In this paper, we design two compressed decentralized algorithms for solving
nonconvex stochastic optimization under two different scenarios. Both
algorithms adopt a momentum technique to achieve fast convergence and a
message-compression technique to save communication costs. Though momentum
acceleration and compressed communication have been used in literature, it is
highly nontrivial to theoretically prove the effectiveness of their composition
in a decentralized algorithm that can maintain the benefits of both sides,
because of the need to simultaneously control the consensus error, the
compression error, and the bias from the momentum gradient.
  For the scenario where gradients are bounded, our proposal is a compressed
decentralized adaptive method. To the best of our knowledge, this is the first
decentralized adaptive stochastic gradient method with compressed
communication. For the scenario of data heterogeneity without bounded
gradients, our proposal is a compressed decentralized heavy-ball method, which
applies a gradient tracking technique to address the challenge of data
heterogeneity. Notably, both methods achieve an optimal convergence rate, and
they can achieve linear speed up and adopt topology-independent algorithmic
parameters within a certain regime of the user-specified error tolerance.
Superior empirical performance is observed over state-of-the-art methods on
training deep neural networks (DNNs) and Transformers.

</details>


### [75] [MENDR: Manifold Explainable Neural Data Representations](https://arxiv.org/abs/2508.04956)
*Matthew Chen,Micky Nnamdi,Justin Shao,Andrew Hornback,Hongyun Huang,Ben Tamo,Yishan Zhong,Benoit Marteau,Wenqi Shi,May Dongmei Wang*

Main category: cs.LG

TL;DR: MENDR는 EEG 신호에 대한 새로운 기초 모델로, 해석 가능성을 높이고 효율적인 분석을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: EEG 기초 모델의 사전 훈련과 해석 가능성 부족 문제를 해결하고자 함.

Method: 리만다양체 변환기 아키텍처를 기반으로 한 필터 뱅크 방식의 MENDR 모델을 제안.

Result: MENDR은 대규모 EEG 데이터에 대해 사전 훈련된 후, 해석 가능성을 높이고 임상 EEG 작업에서 우수한 성능을 입증함.

Conclusion: MENDR은 매개변수 수가 적으면서도 효과적이고 해석 가능한 EEG 분석을 가능하게 함.

Abstract: Foundation models for electroencephalography (EEG) signals have recently
demonstrated success in learning generalized representations of EEGs,
outperforming specialized models in various downstream tasks. However, many of
these models lack transparency in their pretraining dynamics and offer limited
insight into how well EEG information is preserved within their embeddings. For
successful clinical integration, EEG foundation models must ensure transparency
in pretraining, downstream fine-tuning, and the interpretability of learned
representations. Current approaches primarily operate in the temporal domain,
overlooking advancements in digital signal processing that enable the
extraction of deterministic and traceable features, such as wavelet-based
representations. We propose MENDR (Manifold Explainable Neural Data
Representations), a filter bank-based EEG foundation model built on a novel
Riemannian Manifold Transformer architecture to resolve these issues. MENDR
learns symmetric positive definite matrix embeddings of EEG signals and is
pretrained on a large corpus comprising over 4,000 hours of EEG data,
decomposed via discrete wavelet packet transforms into multi-resolution
coefficients. MENDR significantly enhances interpretability by visualizing
symmetric positive definite embeddings as geometric ellipsoids and supports
accurate reconstruction of EEG signals from learned embeddings. Evaluations
across multiple clinical EEG tasks demonstrate that MENDR achieves near
state-of-the-art performance with substantially fewer parameters, underscoring
its potential for efficient, interpretable, and clinically applicable EEG
analysis.

</details>


### [76] [RCUKF: Data-Driven Modeling Meets Bayesian Estimation](https://arxiv.org/abs/2508.04985)
*Kumar Anurag,Kasra Azizi,Francesco Sorrentino,Wenbin Wan*

Main category: cs.LG

TL;DR: 이 논문은 복잡한 시스템의 신뢰할 수 있는 프로세스 모델을 구축하기 위해 RCUKF라는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 시스템에 대한 신뢰할 수 있는 프로세스 모델을 얻는 것이 도전적이며, 이는 많은 공학 및 과학 응용 분야에서 중요하다.

Method: 이 프레임워크는 데이터 기반 모델링을 위한 Reservoir Computing(RC)와 베이지안 추정 방법인 Unscented Kalman Filter(UKF)를 결합한다.

Result: RCUKF는 잘 알려진 벤치마크 문제와 실시간 차량 이동 경로 추정 작업에서 효과적임을 입증한다.

Conclusion: RCUKF는 고차원 또는 혼돈적 상황에서도 데이터 기반 모델의 정확한 예측을 가능하게 하여 프로세스 모델링의 새로운 접근법을 제공한다.

Abstract: Accurate modeling is crucial in many engineering and scientific applications,
yet obtaining a reliable process model for complex systems is often
challenging. To address this challenge, we propose a novel framework, reservoir
computing with unscented Kalman filtering (RCUKF), which integrates data-driven
modeling via reservoir computing (RC) with Bayesian estimation through the
unscented Kalman filter (UKF). The RC component learns the nonlinear system
dynamics directly from data, serving as a surrogate process model in the UKF
prediction step to generate state estimates in high-dimensional or chaotic
regimes where nominal mathematical models may fail. Meanwhile, the UKF
measurement update integrates real-time sensor data to correct potential drift
in the data-driven model. We demonstrate RCUKF effectiveness on well-known
benchmark problems and a real-time vehicle trajectory estimation task in a
high-fidelity simulation environment.

</details>


### [77] [Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis](https://arxiv.org/abs/2508.04999)
*Menghua Jiang,Yuxia Lin,Baoliang Chen,Haifeng Hu,Yuncheng Jiang,Sijie Mai*

Main category: cs.LG

TL;DR: 다중 모달 감정 분석에서의 편향 문제를 해결하기 위한 새로운 모델, MMCI를 제안하며, 이를 통해 안정적인 예측을 이끌어낸다.


<details>
  <summary>Details</summary>
Motivation: 다중 모달 감정 분석(MSA)의 기존 방법이 통계적 지름길에 의존하여 일반화 문제를 일으키고 있는 것에 대한 해결책을 모색.

Method: MMCI 모델은 다중 관계 그래프를 활용해 모달 간 의존성을 모델링하고, 주의 메커니즘을 통해 원인적 특성과 단축 특성을 분리하여 추정.

Result: 다양한 MSA 데이터셋과 OOD 테스트 세트에서 편향을 억제하고 성능을 향상시키는 효과를 입증함.

Conclusion: MMCI 모델은 배경 조정을 통해 원인적 관계를 명확하게 포착하여 안정적인 예측을 가능하게 한다.

Abstract: Multimodal sentiment analysis (MSA) aims to understand human emotions by
integrating information from multiple modalities, such as text, audio, and
visual data. However, existing methods often suffer from spurious correlations
both within and across modalities, leading models to rely on statistical
shortcuts rather than true causal relationships, thereby undermining
generalization. To mitigate this issue, we propose a Multi-relational
Multimodal Causal Intervention (MMCI) model, which leverages the backdoor
adjustment from causal theory to address the confounding effects of such
shortcuts. Specifically, we first model the multimodal inputs as a
multi-relational graph to explicitly capture intra- and inter-modal
dependencies. Then, we apply an attention mechanism to separately estimate and
disentangle the causal features and shortcut features corresponding to these
intra- and inter-modal relations. Finally, by applying the backdoor adjustment,
we stratify the shortcut features and dynamically combine them with the causal
features to encourage MMCI to produce stable predictions under distribution
shifts. Extensive experiments on several standard MSA datasets and
out-of-distribution (OOD) test sets demonstrate that our method effectively
suppresses biases and improves performance.

</details>


### [78] [R-Zero: Self-Evolving Reasoning LLM from Zero Data](https://arxiv.org/abs/2508.05004)
*Chengsong Huang,Wenhao Yu,Xiaoyang Wang,Hongming Zhang,Zongxia Li,Ruosen Li,Jiaxin Huang,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: R-Zero는 자율적으로 훈련 데이터를 생성하고, Challenger와 Solver라는 두 개의 모델이 상호작용하여 성능을 향상시키는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 자율적으로 발전하는 LLM을 통해 인공지능의 인간 이상의 능력으로 향상시키기 위해, 인간의 개입이 없는 훈련 데이터 생성 필요.

Method: R-Zero는 Challenger와 Solver라는 두 모델이 서로의 능력을 시험하고 개선하는 방식으로 독립적으로 최적화된다.

Result: R-Zero는 다양한 LLM의 사고 능력을 크게 향상시켜, Qwen3-4B-Base 모델에서 수학과 일반 도메인 추론 벤치마크에서 각각 +6.49와 +7.54의 성과를 올렸다.

Conclusion: R-Zero는 사전 구축된 작업이나 레이블 없이도 목표 지향적인 학습 과정을 창출하며, 자율적 LLM의 새로운 가능성을 제시한다.

Abstract: Self-evolving Large Language Models (LLMs) offer a scalable path toward
super-intelligence by autonomously generating, refining, and learning from
their own experiences. However, existing methods for training such models still
rely heavily on vast human-curated tasks and labels, typically via fine-tuning
or reinforcement learning, which poses a fundamental bottleneck to advancing AI
systems toward capabilities beyond human intelligence. To overcome this
limitation, we introduce R-Zero, a fully autonomous framework that generates
its own training data from scratch. Starting from a single base LLM, R-Zero
initializes two independent models with distinct roles, a Challenger and a
Solver. These models are optimized separately and co-evolve through
interaction: the Challenger is rewarded for proposing tasks near the edge of
the Solver capability, and the Solver is rewarded for solving increasingly
challenging tasks posed by the Challenger. This process yields a targeted,
self-improving curriculum without any pre-existing tasks and labels.
Empirically, R-Zero substantially improves reasoning capability across
different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on
math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.

</details>


### [79] [SPaRFT: Self-Paced Reinforcement Fine-Tuning for Large Language Models](https://arxiv.org/abs/2508.05015)
*Dai Do,Manh Nguyen,Svetha Venkatesh,Hung Le*

Main category: cs.LG

TL;DR: SPaRFT는 대규모 언어 모델의 학습 효율성을 향상시키는 자기 주도 학습 프레임워크로, 데이터 선택 및 클러스터링을 통한 최적화로 더 적은 자원으로 높은 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 훈련에서 강화 학습 방법은 많은 데이터와 컴퓨팅 자원을 필요로 하여 소형 모델에서는 비현실적이다.

Method: SPaRFT는 클러스터 기반 데이터 감소 및 다중 무장밴딧을 사용하여 훈련 데이터를 최적화하고, 모델의 현재 성능에 따라 샘플을 분배한다.

Result: SPaRFT는 최신 기법들과 비교해 유사하거나 더 나은 정확도를 보이며, 최대 100배 적은 샘플을 사용하여 훈련되었다.

Conclusion: 잘 설계된 데이터 선택 및 성능 기반의 훈련 커리큘럼을 통해 최소한의 자원으로도 대규모 언어 모델의 강력한 추론 능력을 발휘할 수 있음을 입증하였다.

Abstract: Large language models (LLMs) have shown strong reasoning capabilities when
fine-tuned with reinforcement learning (RL). However, such methods require
extensive data and compute, making them impractical for smaller models. Current
approaches to curriculum learning or data selection are largely
heuristic-driven or demand extensive computational resources, limiting their
scalability and generalizability. We propose \textbf{SPaRFT}, a self-paced
learning framework that enables efficient learning based on the capability of
the model being trained through optimizing which data to use and when. First,
we apply \emph{cluster-based data reduction} to partition training data by
semantics and difficulty, extracting a compact yet diverse subset that reduces
redundancy. Then, a \emph{multi-armed bandit} treats data clusters as arms,
optimized to allocate training samples based on model current performance.
Experiments across multiple reasoning benchmarks show that SPaRFT achieves
comparable or better accuracy than state-of-the-art baselines while using up to
\(100\times\) fewer samples. Ablation studies and analyses further highlight
the importance of both data clustering and adaptive selection. Our results
demonstrate that carefully curated, performance-driven training curricula can
unlock strong reasoning abilities in LLMs with minimal resources.

</details>


### [80] [Will You Be Aware? Eye Tracking-Based Modeling of Situational Awareness in Augmented Reality](https://arxiv.org/abs/2508.05025)
*Zhehan Qu,Tianyi Hu,Christian Fronk,Maria Gorlatova*

Main category: cs.LG

TL;DR: 증강 현실(AR) 시스템은 작업 성능을 향상시키지만, 안전-critical 환경에서 인지 터널링을 유발할 위험이 있다. 본 연구는 AR 기반의 심폐소생술(CPR) 중 사용자 상황 인식(SA)을 조사하였으며, eye tracking을 이용한 모델이 SA 예측에 성공적이었다.


<details>
  <summary>Details</summary>
Motivation: AR 시스템이 실시간 안내를 제공하면서도 상황 인식 저하의 위험을 초래할 수 있다는 점에 대한 우려가 있다. CPR 상황에서 이러한 문제를 규명하고자 함.

Method: Magic Leap 2를 사용해 AR 앱을 개발하고, 사용자 실험을 통해 예상치 못한 사건 발생 시의 상황 인식을 평가하였다. Eye tracking을 통해 SA 메트릭스를 분석하고, 이를 바탕으로 gaze 이벤트를 구조화한 FixGraphPool 모델을 제안하였다.

Result: FixGraphPool 모델은 83.0%의 정확도를 달성하였으며, 기존의 특성 기반 머신러닝 및 최신 시계열 모델보다 성능이 우수하였다.

Conclusion: Eye tracking 기술이 AR에서 상황 인식 모델링에 효과적임을 보여주고, 사용자 안전과 상황 인식을 보장하는 AR 시스템 설계에 유용함을 강조한다.

Abstract: Augmented Reality (AR) systems, while enhancing task performance through
real-time guidance, pose risks of inducing cognitive tunneling-a hyperfocus on
virtual content that compromises situational awareness (SA) in safety-critical
scenarios. This paper investigates SA in AR-guided cardiopulmonary
resuscitation (CPR), where responders must balance effective compressions with
vigilance to unpredictable hazards (e.g., patient vomiting). We developed an AR
app on a Magic Leap 2 that overlays real-time CPR feedback (compression depth
and rate) and conducted a user study with simulated unexpected incidents (e.g.,
bleeding) to evaluate SA, in which SA metrics were collected via observation
and questionnaires administered during freeze-probe events. Eye tracking
analysis revealed that higher SA levels were associated with greater saccadic
amplitude and velocity, and with reduced proportion and frequency of fixations
on virtual content. To predict SA, we propose FixGraphPool, a graph neural
network that structures gaze events (fixations, saccades) into spatiotemporal
graphs, effectively capturing dynamic attentional patterns. Our model achieved
83.0% accuracy (F1=81.0%), outperforming feature-based machine learning and
state-of-the-art time-series models by leveraging domain knowledge and
spatial-temporal information encoded in ET data. These findings demonstrate the
potential of eye tracking for SA modeling in AR and highlight its utility in
designing AR systems that ensure user safety and situational awareness.

</details>


### [81] [Learning from Oblivion: Predicting Knowledge Overflowed Weights via Retrodiction of Forgetting](https://arxiv.org/abs/2508.05059)
*Jinhyeok Jang,Jaehong Kim,Jung Uk Kim*

Main category: cs.LG

TL;DR: 이 논문은 데이터 부족 상황에서 더 나은 사전 훈련된 가중치를 얻기 위한 새로운 전략인 "KNowledge Overflowed Weights (KNOW)" 예측을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 사전 훈련된 가중치는 현대 딥러닝의 중요한 요소로, 효율적인 지식 전이와 하위 작업 성능 향상에 기여한다.

Method: 구조적 망각과 그 역전을 활용하여 지식이 풍부한 가중치를 합성하는 방식으로, 점진적으로 축소된 데이터 세트에서의 순차적 미세 조정을 모델링하고 역전한다.

Result: KNOW 예측은 단순한 가중치 예측과 Na"ive 미세 조정을 능가하며, 다양한 데이터 세트와 아키텍처에서 우수한 성과를 보여준다.

Conclusion: 이 연구는 딥러닝에서 지식 전이의 한계를 확장하기 위해 망각 역학을 새로운 관점에서 재해석하는 방법을 제공한다.

Abstract: Pre-trained weights have become a cornerstone of modern deep learning,
enabling efficient knowledge transfer and improving downstream task
performance, especially in data-scarce scenarios. However, a fundamental
question remains: how can we obtain better pre-trained weights that encapsulate
more knowledge beyond the given dataset? In this work, we introduce
\textbf{KNowledge Overflowed Weights (KNOW)} prediction, a novel strategy that
leverages structured forgetting and its inversion to synthesize
knowledge-enriched weights. Our key insight is that sequential fine-tuning on
progressively downsized datasets induces a structured forgetting process, which
can be modeled and reversed to recover knowledge as if trained on a larger
dataset. We construct a dataset of weight transitions governed by this
controlled forgetting and employ meta-learning to model weight prediction
effectively. Specifically, our \textbf{KNowledge Overflowed Weights Nowcaster
(KNOWN)} acts as a hyper-model that learns the general evolution of weights and
predicts enhanced weights with improved generalization. Extensive experiments
across diverse datasets and architectures demonstrate that KNOW prediction
consistently outperforms Na\"ive fine-tuning and simple weight prediction,
leading to superior downstream performance. Our work provides a new perspective
on reinterpreting forgetting dynamics to push the limits of knowledge transfer
in deep learning.

</details>


### [82] [TANGO: Graph Neural Dynamics via Learned Energy and Tangential Flows](https://arxiv.org/abs/2508.05070)
*Moshe Eliasof,Eldad Haber,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: TANGO는 그래프 표현 학습을 위한 동적 시스템 기반 프레임워크로, 에너지 경관을 통해 노드 특성을 발전시키고 안정성을 보장하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 그래프 학습에서 자주 발생하는 플랫하거나 악조건 에너지 영역에서도 효과적인 신호 전파를 가능하게 하기 위해.

Method: 선택된 에너지 경관에 대해 학습된 리아푸노프 함수를 사용하고, 메시지 전달을 통해 배운 접선 성분을 포함하여 에너지 감소 방향과 접선 발전을 분리하여 유연한 그래프 동역학을 구현.

Result: TANGO는 다양한 노드 및 그래프 분류 및 회귀 벤치마크에서 강력한 성능을 달성하였으며, 합동 학습된 에너지 함수와 접선 흐름의 효과성을 입증합니다.

Conclusion: TANGO는 그래프 신경망에서 오버스쿼싱 문제를 완화시키며, 다양한 백본과 호환됩니다.

Abstract: We introduce TANGO -- a dynamical systems inspired framework for graph
representation learning that governs node feature evolution through a learned
energy landscape and its associated descent dynamics. At the core of our
approach is a learnable Lyapunov function over node embeddings, whose gradient
defines an energy-reducing direction that guarantees convergence and stability.
To enhance flexibility while preserving the benefits of energy-based dynamics,
we incorporate a novel tangential component, learned via message passing, that
evolves features while maintaining the energy value. This decomposition into
orthogonal flows of energy gradient descent and tangential evolution yields a
flexible form of graph dynamics, and enables effective signal propagation even
in flat or ill-conditioned energy regions, that often appear in graph learning.
Our method mitigates oversquashing and is compatible with different graph
neural network backbones. Empirically, TANGO achieves strong performance across
a diverse set of node and graph classification and regression benchmarks,
demonstrating the effectiveness of jointly learned energy functions and
tangential flows for graph neural networks.

</details>


### [83] [ULU: A Unified Activation Function](https://arxiv.org/abs/2508.05073)
*Simin Huo*

Main category: cs.LG

TL;DR: ULU는 비단조적 조각 활성화 함수로, 긍정 및 부정 입력을 다르게 처리하여 ReLU 및 Mish보다 이미지 분류 및 객체 감지 작업에서 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 활성화 함수의 한계를 극복하고, 긍정적 및 부정적 입력을 다르게 처리하여 성능을 향상시키기 위해 제안되었습니다.

Method: 비단조적 조각 활성화 함수 ULU와 그 변형인 적응형 ULU(AULU)를 통해, 각 입력에 대해 다른 방법으로 응답하도록 학습 가능한 매개변수를 활용합니다.

Result: ULU는 이미지 분류와 객체 감지 작업에서 ReLU 및 Mish보다 현저하게 뛰어난 성능을 보였습니다.

Conclusion: 제안된 ULU 및 AULU는 활성화 함수의 성능을 향상시키고, 모델의 귀납적 편향을 정량적으로 측정하는 새로운 지표를 제공합니다.

Abstract: We propose \textbf{ULU}, a novel non-monotonic, piecewise activation function
defined as $\{f(x;\alpha_1),x<0; f(x;\alpha_2),x>=0 \}$, where
$f(x;\alpha)=0.5x(tanh(\alpha x)+1),\alpha >0$. ULU treats positive and
negative inputs differently. Extensive experiments demonstrate ULU
significantly outperforms ReLU and Mish across image classification and object
detection tasks. Its variant Adaptive ULU (\textbf{AULU}) is expressed as
$\{f(x;\beta_1^2),x<0; f(x;\beta_2^2),x>=0 \}$, where $\beta_1$ and $\beta_2$
are learnable parameters, enabling it to adapt its response separately for
positive and negative inputs. Additionally, we introduce the LIB (Like
Inductive Bias) metric from AULU to quantitatively measure the inductive bias
of the model.

</details>


### [84] [Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning](https://arxiv.org/abs/2508.05077)
*Luai Abuelsamen,Temitope Lukman Adebanjo*

Main category: cs.LG

TL;DR: 이 논문은 다중 모드 모방 학습의 이론적 기초를 통계적 학습 이론의 관점에서 분석한다.


<details>
  <summary>Details</summary>
Motivation: 다중 모드 인식이 모방 정책의 샘플 복잡성과 최적화 지형에 미치는 영향을 이해하기 위함이다.

Method: 최근의 다중 모드 학습 이론을 바탕으로 다중 모드 정책의 통합 방식을 탐구한다.

Result: 적절히 통합된 다중 모드 정책이 단일 모드 정책보다 더 엄격한 일반화 경계와 유리한 최적화 지형을 달성할 수 있음을 보여준다.

Conclusion: 다중 모드 아키텍처가 우수한 성능을 내는 이유를 Rademacher 복잡성, PAC 학습, 정보 이론의 기본 개념과 연결지어 설명한다.

Abstract: This paper examines the theoretical foundations of multimodal imitation
learning through the lens of statistical learning theory. We analyze how
multimodal perception (RGB-D, proprioception, language) affects sample
complexity and optimization landscapes in imitation policies. Building on
recent advances in multimodal learning theory, we show that properly integrated
multimodal policies can achieve tighter generalization bounds and more
favorable optimization landscapes than their unimodal counterparts. We provide
a comprehensive review of theoretical frameworks that explain why multimodal
architectures like PerAct and CLIPort achieve superior performance, connecting
these empirical results to fundamental concepts in Rademacher complexity, PAC
learning, and information theory.

</details>


### [85] [Integrated Influence: Data Attribution with Baseline](https://arxiv.org/abs/2508.05089)
*Linxiao Yang,Xinyu Gu,Liang Sun*

Main category: cs.LG

TL;DR: 통합 영향력을 제안하여 데이터 기여도를 보다 신뢰성 있게 평가하는 방법을 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 데이터 기여도를 정량화하는 것은 머신러닝 모델의 투명성을 높이는 데 중요하지만, 기존 방법이 단일 샘플에 국한되어 문제가 있다.

Method: 통합 영향력이라는 새로운 데이터 기여도 방법을 제안하며, 기준 데이터셋을 정의하고 데이터 퇴행 과정을 통해 현재 데이터셋을 기준으로 전환한다.

Result: 실험 결과, 통합 영향력 방법이 기존의 방법보다 더 신뢰성 있는 데이터 기여도를 생성함을 보여준다.

Conclusion: 통합 영향력은 기존 방법의 특수한 경우로 이해될 수 있으며, 데이터 기여도 및 잘못 레이블된 예제 식별 작업에서 더 나은 성능을 낸다.

Abstract: As an effective approach to quantify how training samples influence test
sample, data attribution is crucial for understanding data and model and
further enhance the transparency of machine learning models. We find that
prevailing data attribution methods based on leave-one-out (LOO) strategy
suffer from the local-based explanation, as these LOO-based methods only
perturb a single training sample, and overlook the collective influence in the
training set. On the other hand, the lack of baseline in many data attribution
methods reduces the flexibility of the explanation, e.g., failing to provide
counterfactual explanations. In this paper, we propose Integrated Influence, a
novel data attribution method that incorporates a baseline approach. Our method
defines a baseline dataset, follows a data degeneration process to transition
the current dataset to the baseline, and accumulates the influence of each
sample throughout this process. We provide a solid theoretical framework for
our method, and further demonstrate that popular methods, such as influence
functions, can be viewed as special cases of our approach. Experimental results
show that Integrated Influence generates more reliable data attributions
compared to existing methods in both data attribution task and mislablled
example identification task.

</details>


### [86] [Cold Start Active Preference Learning in Socio-Economic Domains](https://arxiv.org/abs/2508.05090)
*Mojtaba Fayaz-Bakhsh,Danial Ataee,MohammadAmin Fazli*

Main category: cs.LG

TL;DR: 본 논문은 초기 레이블 데이터가 없는 상황에서의 능동적 선호 학습의 성능 저하 문제를 해결하기 위한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 능동적 선호 학습은 선호도를 효율적으로 모델링하는 유력한 방법이나, 초기 레이블 데이터가 없을 때 성능이 크게 저하되는 '콜드 스타트 문제'가 존재합니다.

Method: 이 방법은 자체 지도 사전 학습 단계를 통해 PCA를 이용하여 데이터의 고유 구조에서 초기 의사 레이블을 도출하고, 노이즈가 있는 오라클에게 전략적으로 레이블을 요청하는 능동적 학습 루프를 통해 모델을 개선합니다.

Result: 다양한 도메인에서의 실험 결과, 제안된 콜드 스타트 접근법이 초기 상태에서 시작하는 표준 능동 학습 전략보다 더 높은 정확도를 달성하며, 적은 수의 레이블 쌍으로도 효과적으로 작동함을 보였습니다.

Conclusion: 본 연구는 데이터 제한 환경에서 선호 학습의 샘플 효율성과 적용 가능성을 향상시키는 실용적이고 효과적인 솔루션을 제공합니다.

Abstract: Active preference learning is a powerful paradigm for efficiently modeling
preferences, yet it suffers from the cold-start problem: a significant drop in
performance when no initial labeled data is available. This challenge is
particularly acute in computational social systems and economic analysis, where
labeled data is often scarce, expensive, and subject to expert noise. To
address this gap, we propose a novel framework for cold-start active preference
learning. Our method initiates the learning process through a self-supervised
pre-training phase, utilizing Principal Component Analysis (PCA) to derive
initial pseudo-labels from the data's inherent structure, thereby creating a
cold-start model without any initial oracle interaction. Subsequently, the
model is refined through an active learning loop that strategically queries a
simulated noisy oracle for labels. We conduct extensive experiments on diverse
datasets from different domains, including financial credibility, career
success rate, and socio-economic status. The results demonstrate that our
cold-start approach outperforms standard active learning strategies that begin
from a blank slate, achieving higher accuracy with substantially fewer labeled
pairs. Our framework offers a practical and effective solution to mitigate the
cold-start problem, enhancing the sample efficiency and applicability of
preference learning in data-constrained environments. We release our code at
https://github.com/Dan-A2/cold-start-preference-learning

</details>


### [87] [Learning from Similarity-Confidence and Confidence-Difference](https://arxiv.org/abs/2508.05108)
*Tomoya Tate,Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 이 논문은 약한 감독 학습을 활용하여 다중 관계적 관점에서 보완적인 약한 감독 신호를 이용하는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 데이터에 정확한 레이블을 할당하는 것이 어려운 현실적인 머신러닝 응용에서, 약한 감독 학습이 실용적이고 효과적인 솔루션을 제공하는 필요성이 대두된다.

Method: SconfConfDiff Classification 방법을 도입하여 유사성-신뢰도와 신뢰도-차이를 기반으로 한 두 가지 약한 레이블을 결합한 분류 프로세스를 설계하였다. 또한, 기존 추정치를 바탕으로 한 불편 리스크 추정기와 두 약한 레이블 간의 상호작용 모델링을 통한 새로운 추정기를 유도하였다.

Result: 제안한 방법은 다양한 설정에서 기존 기준선을 지속적으로 초과하는 성능을 보여준다.

Conclusion: 제안한 방법은 최적의 수렴률을 달성하며, 부정적인 경험적 리스크로 인한 오버피팅을 완화하고, 클래스 prior 확률 및 레이블 노이즈에 대한 견고성을 이론적으로 분석하였다.

Abstract: In practical machine learning applications, it is often challenging to assign
accurate labels to data, and increasing the number of labeled instances is
often limited. In such cases, Weakly Supervised Learning (WSL), which enables
training with incomplete or imprecise supervision, provides a practical and
effective solution. However, most existing WSL methods focus on leveraging a
single type of weak supervision. In this paper, we propose a novel WSL
framework that leverages complementary weak supervision signals from multiple
relational perspectives, which can be especially valuable when labeled data is
limited. Specifically, we introduce SconfConfDiff Classification, a method that
integrates two distinct forms of weaklabels: similarity-confidence and
confidence-difference, which are assigned to unlabeled data pairs. To implement
this method, we derive two types of unbiased risk estimators for
classification: one based on a convex combination of existing estimators, and
another newly designed by modeling the interaction between two weak labels. We
prove that both estimators achieve optimal convergence rates with respect to
estimation error bounds. Furthermore, we introduce a risk correction approach
to mitigate overfitting caused by negative empirical risk, and provide
theoretical analysis on the robustness of the proposed method against
inaccurate class prior probability and label noise. Experimental results
demonstrate that the proposed method consistently outperforms existing
baselines across a variety of settings.

</details>


### [88] [Exploring Superior Function Calls via Reinforcement Learning](https://arxiv.org/abs/2508.05118)
*Bingguang Hao,Maolin Wang,Zengzhuang Xu,Yicheng Chen,Cunyin Peng,Jinjie GU,Chenyi Zhuang*

Main category: cs.LG

TL;DR: 이 연구는 함수 호출을 위한 강화 학습 프레임워크를 제안하여 모형의 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델을 실제 응용프로그램에 배포하기 위해 함수 호출 능력이 필수적이나, 기존 훈련 방법은 충분한 추론 전략을 발전시키지 못하고 있다.

Method: 전략적 엔트로피 기반 탐색을 통한 그룹 상대 정책 최적화를 촉진하는 새로운 강화 학습 프레임워크를 제안하며, 두 단계 데이터 준비 파이프라인이 포함된다.

Result: 버클리 함수 호출 리더보드에서 86.02%의 정확도로 최신 성능을 달성하고, 복잡한 다중 함수 시나리오에서 표준 GRPO보다 최대 6% 더 나은 성능을 보인다.

Conclusion: 우리의 방법은 코드 사전 훈련된 모델에서 특히 개선된 성능을 보이며, 기능 호출 작업에서 강화 학습을 위한 유리한 출발점을 제공한다.

Abstract: Function calling capabilities are crucial for deploying Large Language Models
in real-world applications, yet current training approaches fail to develop
robust reasoning strategies. Supervised fine-tuning produces models that rely
on superficial pattern matching, while standard reinforcement learning methods
struggle with the complex action space of structured function calls. We present
a novel reinforcement learning framework designed to enhance group relative
policy optimization through strategic entropy based exploration specifically
tailored for function calling tasks. Our approach addresses three critical
challenges in function calling: insufficient exploration during policy
learning, lack of structured reasoning in chain-of-thought generation, and
inadequate verification of parameter extraction. Our two-stage data preparation
pipeline ensures high-quality training samples through iterative LLM evaluation
and abstract syntax tree validation. Extensive experiments on the Berkeley
Function Calling Leaderboard demonstrate that this framework achieves
state-of-the-art performance among open-source models with 86.02\% overall
accuracy, outperforming standard GRPO by up to 6\% on complex multi-function
scenarios. Notably, our method shows particularly strong improvements on
code-pretrained models, suggesting that structured language generation
capabilities provide an advantageous starting point for reinforcement learning
in function calling tasks. We will release all the code, models and dataset to
benefit the community.

</details>


### [89] [HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation](https://arxiv.org/abs/2508.05135)
*Thinh Nguyen,Trung Phan,Binh T. Nguyen,Khoa D Doan,Kok-Seng Wong*

Main category: cs.LG

TL;DR: 새로운 계층적 연합 도메인 일반화(HFedDG) 프레임워크를 도입하고, HFedATM 방법이 모델 성능을 향상시키며 효율성을 유지한다고 주장함.


<details>
  <summary>Details</summary>
Motivation: 기존의 계층적 연합 학습(HFL)은 도메인 변화로 인한 성능 저하 문제를 해결할 필요가 있으며, 이를 통해 모델의 일반화 능력을 향상시키고자 함.

Method: HFedATM 방법을 제안하여 서로 다른 스테이션의 모델을 필터 기반 최적 수송 정렬을 통해 정렬하고, 축소 인식 정규화 평균 집계를 통해 통합함.

Result: HFedATM은 다양한 데이터셋에서 기존 FedDG 기준선의 성능을 크게 향상시키고, 계산 및 통신 효율성을 유지함.

Conclusion: HFedATM은 표준 계층적 평균에 비해 더 긴밀한 일반화 오류 경계를 이루어내어 더 빠른 수렴과 안정적인 훈련 동작을 초래함.

Abstract: Federated Learning (FL) is a decentralized approach where multiple clients
collaboratively train a shared global model without sharing their raw data.
Despite its effectiveness, conventional FL faces scalability challenges due to
excessive computational and communication demands placed on a single central
server as the number of participating devices grows. Hierarchical Federated
Learning (HFL) addresses these issues by distributing model aggregation tasks
across intermediate nodes (stations), thereby enhancing system scalability and
robustness against single points of failure. However, HFL still suffers from a
critical yet often overlooked limitation: domain shift, where data
distributions vary significantly across different clients and stations,
reducing model performance on unseen target domains. While Federated Domain
Generalization (FedDG) methods have emerged to improve robustness to domain
shifts, their integration into HFL frameworks remains largely unexplored. In
this paper, we formally introduce Hierarchical Federated Domain Generalization
(HFedDG), a novel scenario designed to investigate domain shift within
hierarchical architectures. Specifically, we propose HFedATM, a hierarchical
aggregation method that first aligns the convolutional filters of models from
different stations through Filter-wise Optimal Transport Alignment and
subsequently merges aligned models using a Shrinkage-aware Regularized Mean
Aggregation. Our extensive experimental evaluations demonstrate that HFedATM
significantly boosts the performance of existing FedDG baselines across
multiple datasets and maintains computational and communication efficiency.
Moreover, theoretical analyses indicate that HFedATM achieves tighter
generalization error bounds compared to standard hierarchical averaging,
resulting in faster convergence and stable training behavior.

</details>


### [90] [Deep Neural Networks with General Activations: Super-Convergence in Sobolev Norms](https://arxiv.org/abs/2508.05141)
*Yahong Yang,Juncai He*

Main category: cs.LG

TL;DR: 깊은 완전 연결 신경망이 일반 활성화 함수를 사용해 편미분 방정식(PDE)을 효과적으로 근사할 수 있음을 보여주는 논문.


<details>
  <summary>Details</summary>
Motivation: 전통적 수치 근사 방법보다 높은 정확도로 PDE의 약한 해를 근사할 수 있는 대안 방법을 제시하고자 함.

Method: 신경망의 오류를 $W^{m,p}$-노름으로 측정하며 Sobolev 공간 $W^{n,	ext{이}}$에서의 근사 성능을 분석.

Result: 깊은 신경망이 전통적인 수치적 방법보다 더 빠른 수렴 속도를 보이며 '초수렴' 현상을 관찰하였다.

Conclusion: 신경망 기반 PDE 접근법에 대한 오류 추정 이론의 중요한 간극을 메우고, 과학적 계산에서의 응용을 위한 통합 이론적 토대를 제공한다.

Abstract: This paper establishes a comprehensive approximation result for deep
fully-connected neural networks with commonly-used and general activation
functions in Sobolev spaces $W^{n,\infty}$, with errors measured in the
$W^{m,p}$-norm for $m < n$ and $1\le p \le \infty$. The derived rates surpass
those of classical numerical approximation techniques, such as finite element
and spectral methods, exhibiting a phenomenon we refer to as
\emph{super-convergence}. Our analysis shows that deep networks with general
activations can approximate weak solutions of partial differential equations
(PDEs) with superior accuracy compared to traditional numerical methods at the
approximation level. Furthermore, this work closes a significant gap in the
error-estimation theory for neural-network-based approaches to PDEs, offering a
unified theoretical foundation for their use in scientific computing.

</details>


### [91] [PSEO: Optimizing Post-hoc Stacking Ensemble Through Hyperparameter Tuning](https://arxiv.org/abs/2508.05144)
*Beicheng Xu,Wei Liu,Keyao Ding,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: PSEO는 AutoML에서 최적의 모델과 하이퍼파라미터 구성을 위해 포스트-혹 애고리즘을 결합한 새로운 프레임워크로, 80개 데이터세트에서 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: CASH 문제는 Automated Machine Learning에서 핵심적인 문제로, 기존 방법들이 고정된 전략을 사용하여 특정 작업에 대한 적응력이 부족하다.

Method: PSEO 프레임워크는 이진 이차 프로그래밍을 통해 기본 모델 선택을 하고, 다층 스태킹의 잠재력을 최대화하기 위한 두 가지 메커니즘을 도입하였다.

Result: 80개의 공개 데이터 세트에서 16개의 방법 중 평균 테스트 순위 2.96으로 가장 우수한 성능을 보였다.

Conclusion: PSEO는 포스트-혹 앙상블 최적화에 효과적이며, 기존 방법들과 비교해 성능 향상을 이끌었다.

Abstract: The Combined Algorithm Selection and Hyperparameter Optimization (CASH)
problem is fundamental in Automated Machine Learning (AutoML). Inspired by the
success of ensemble learning, recent AutoML systems construct post-hoc
ensembles for final predictions rather than relying on the best single model.
However, while most CASH methods conduct extensive searches for the optimal
single model, they typically employ fixed strategies during the ensemble phase
that fail to adapt to specific task characteristics. To tackle this issue, we
propose PSEO, a framework for post-hoc stacking ensemble optimization. First,
we conduct base model selection through binary quadratic programming, with a
trade-off between diversity and performance. Furthermore, we introduce two
mechanisms to fully realize the potential of multi-layer stacking. Finally,
PSEO builds a hyperparameter space and searches for the optimal post-hoc
ensemble strategy within it. Empirical results on 80 public datasets show that
\sys achieves the best average test rank (2.96) among 16 methods, including
post-hoc designs in recent AutoML systems and state-of-the-art ensemble
learning methods.

</details>


### [92] [Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation](https://arxiv.org/abs/2508.05154)
*Rishabh Gaur,Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 이 연구에서는 강화 학습을 기반으로 한 에이전트 기반 모델의 성능 평가를 위한 도메인 주도 메트릭스를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 기반 모델 및 합리적 에이전트 기반 모델의 최적화 알고리즘 성능 평가의 어려움 해결.

Method: 도메인 주도 메트릭스를 개발하고, 이를 통해 전통적인 메트릭과 결합하여 정책 최적화 사례를 연구.

Result: 도메인 주도 보상을 사용하여 다양한 시뮬레이션 시나리오에서 성능을 향상시킴을 보여주었다.

Conclusion: 강화 학습 기반 모델의 성능 평가 및 최적화에 있어 도메인 주도 메트릭스의 유용성을 강조한다.

Abstract: For the development and optimization of agent-based models (ABMs) and
rational agent-based models (RABMs), optimization algorithms such as
reinforcement learning are extensively used. However, assessing the performance
of RL-based ABMs and RABMS models is challenging due to the complexity and
stochasticity of the modeled systems, and the lack of well-standardized metrics
for comparing RL algorithms. In this study, we are developing domain-driven
metrics for RL, while building on state-of-the-art metrics. We demonstrate our
``Domain-driven-RL-metrics'' using policy optimization on a rational ABM
disease modeling case study to model masking behavior, vaccination, and
lockdown in a pandemic. Our results show the use of domain-driven rewards in
conjunction with traditional and state-of-the-art metrics for a few different
simulation scenarios such as the differential availability of masks.

</details>


### [93] [pFedDSH: Enabling Knowledge Transfer in Personalized Federated Learning through Data-free Sub-Hypernetwork](https://arxiv.org/abs/2508.05157)
*Thinh Nguyen,Le Huy Khiem,Van-Tuan Tran,Khoa D Doan,Nitesh V Chawla,Kok-Seng Wong*

Main category: cs.LG

TL;DR: 이 논문은 동적인 클라이언트 참여 환경에서 개인화된 연합 학습을 위한 새로운 프레임워크인 pFedDSH를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 개인화된 연합 학습 방법들은 정적 클라이언트 참여를 가정하고 있으며, 변화하는 클라이언트 참여 상황에 맞게 적응할 필요가 있다.

Method: pFedDSH는 중앙 하이퍼네트워크를 기반으로 클라이언트별 모델을 생성하고, 기존 클라이언트의 성능을 유지하기 위해 배치별 마스크와 데이터 프리 리플레이 전략을 도입한다.

Result: pFedDSH는 CIFAR-10, CIFAR-100, Tiny-ImageNet 데이터셋에서 기존의 최신 개인화된 연합 학습 방법들을 초과하는 성능을 보인다.

Conclusion: pFedDSH는 동적인 클라이언트 환경에서도 기존 클라이언트의 성능을 안정적으로 유지하고 새로운 클라이언트에 대한 적응성을 제공한다.

Abstract: Federated Learning (FL) enables collaborative model training across
distributed clients without sharing raw data, offering a significant privacy
benefit. However, most existing Personalized Federated Learning (pFL) methods
assume a static client participation, which does not reflect real-world
scenarios where new clients may continuously join the federated system (i.e.,
dynamic client onboarding). In this paper, we explore a practical scenario in
which a new batch of clients is introduced incrementally while the learning
task remains unchanged. This dynamic environment poses various challenges,
including preserving performance for existing clients without retraining and
enabling efficient knowledge transfer between client batches. To address these
issues, we propose Personalized Federated Data-Free Sub-Hypernetwork (pFedDSH),
a novel framework based on a central hypernetwork that generates personalized
models for each client via embedding vectors. To maintain knowledge stability
for existing clients, pFedDSH incorporates batch-specific masks, which activate
subsets of neurons to preserve knowledge. Furthermore, we introduce a data-free
replay strategy motivated by DeepInversion to facilitate backward transfer,
enhancing existing clients' performance without compromising privacy. Extensive
experiments conducted on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate
that pFedDSH outperforms the state-of-the-art pFL and Federated Continual
Learning baselines in our investigation scenario. Our approach achieves robust
performance stability for existing clients, as well as adaptation for new
clients and efficient utilization of neural resources.

</details>


### [94] [Aligning LLMs on a Budget: Inference-Time Alignment with Heuristic Reward Models](https://arxiv.org/abs/2508.05165)
*Mason Nakamura,Saaduddin Mahmud,Kyle H. Wray,Hamed Zamani,Shlomo Zilberstein*

Main category: cs.LG

TL;DR: HIA는 비용 효율적이며, 정교한 조정 없이 LLM을 사용자 취향에 맞춰 align하는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 사용자 취향에 맞춘 LLM의 조정은 현실적인 활용을 위해 필수적이며, 기존 방법은 조정 품질과 계산 비용 간의 트레이드오프에 직면한다.

Method: HIA는 경량 프롬프트 최적화기, 휴리스틱 보상 모델, 두 단계 필터링을 사용하여, 추론 호출 수를 줄이고 조정 품질을 유지하는 방법이다.

Result: HIA는 동일한 추론 예산 하에서 multi-objective 및 goal-conditioned 작업에서 기존의 최적화 기법들보다 뛰어난 성능을 보였다.

Conclusion: HIA는 적은 추론 예산에서도 효과적이며, 개인화된 LLM 배포를 위한 실용적인 솔루션을 제공한다.

Abstract: Aligning LLMs with user preferences is crucial for real-world use but often
requires costly fine-tuning or expensive inference, forcing trade-offs between
alignment quality and computational cost. Existing inference-time methods
typically ignore this balance, focusing solely on the optimized policy's
performance. We propose HIA (Heuristic-Guided Inference-time Alignment), a
tuning-free, black-box-compatible approach that uses a lightweight prompt
optimizer, heuristic reward models, and two-stage filtering to reduce inference
calls while preserving alignment quality. On real-world prompt datasets,
HelpSteer and ComPRed, HIA outperforms best-of-N sampling, beam search, and
greedy search baselines in multi-objective, goal-conditioned tasks under the
same inference budget. We also find that HIA is effective under low-inference
budgets with as little as one or two response queries, offering a practical
solution for scalable, personalized LLM deployment.

</details>


### [95] [S$^2$M-Former: Spiking Symmetric Mixing Branchformer for Brain Auditory Attention Detection](https://arxiv.org/abs/2508.05164)
*Jiaqi Wang,Zhengyu Ma,Xiongri Shen,Chenlin Zhou,Leilei Zhao,Han Zhang,Yi Zhong,Siqi Cai,Zhenxi Song,Zhiguo Zhang*

Main category: cs.LG

TL;DR: S$^2$M-Former이라는 새로운 spiking symmetric mixing 프레임워크를 통해 EEG 기반의 청각 주의력 탐지가 향상되었으며, 에너지 효율성을 높이고 성능을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: EEG 기반 청각 주의력 탐지는 복잡한 청각 환경에서 청취자의 집중력을 디코딩하는 데 중요한데, 현재 기술의 한계를 극복할 필요가 있다.

Method: spike-driven 대칭 아키텍처와 경량 1D 토큰 시퀀스를 도입하여, 파라미터를 대폭 줄이고 에너지 소비를 최소화하였다.

Result: S$^2$M-Former는 최근의 ANN 방법보다 5.8배 에너지 소비를 줄였으며, 기존 SNN 기준을 초월하는 성능을 보였다.

Conclusion: 종합 실험 결과, S$^2$M-Former는 AAD 작업에 있어 저전력 및 고성능 솔루션으로서 유망한 성과를 거두었다.

Abstract: Auditory attention detection (AAD) aims to decode listeners' focus in complex
auditory environments from electroencephalography (EEG) recordings, which is
crucial for developing neuro-steered hearing devices. Despite recent
advancements, EEG-based AAD remains hindered by the absence of synergistic
frameworks that can fully leverage complementary EEG features under
energy-efficiency constraints. We propose S$^2$M-Former, a novel spiking
symmetric mixing framework to address this limitation through two key
innovations: i) Presenting a spike-driven symmetric architecture composed of
parallel spatial and frequency branches with mirrored modular design,
leveraging biologically plausible token-channel mixers to enhance complementary
learning across branches; ii) Introducing lightweight 1D token sequences to
replace conventional 3D operations, reducing parameters by 14.7$\times$. The
brain-inspired spiking architecture further reduces power consumption,
achieving a 5.8$\times$ energy reduction compared to recent ANN methods, while
also surpassing existing SNN baselines in terms of parameter efficiency and
performance. Comprehensive experiments on three AAD benchmarks (KUL, DTU and
AV-GC-AAD) across three settings (within-trial, cross-trial and cross-subject)
demonstrate that S$^2$M-Former achieves comparable state-of-the-art (SOTA)
decoding accuracy, making it a promising low-power, high-performance solution
for AAD tasks.

</details>


### [96] [FAITH: A Framework for Assessing Intrinsic Tabular Hallucinations in finance](https://arxiv.org/abs/2508.05201)
*Mengao Zhang,Jiayu Fu,Tanya Warrier,Yuwen Wang,Tianhui Tan,Ke-wei Huang*

Main category: cs.LG

TL;DR: 금융 분야에서 대규모 언어 모델의 환각 현상을 평가하기 위한 새로운 프레임워크를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 금융에서의 신뢰할 수 있는 분석을 위해서는 정확한 데이터 추출과 계산이 필수적이다.

Method: context-aware masked span prediction 작업을 기반으로 한 평가 프레임워크를 개발하였다.

Result: S&P 500 연례 보고서에서 파생된 새로운 환각 평가 데이터셋과 자동화된 데이터셋 생성 패러다임을 제시하였다.

Conclusion: 이 연구는 더 신뢰할 수 있는 금융 생성 AI 시스템 구축을 위한 중요한 단계를 제공한다.

Abstract: Hallucination remains a critical challenge for deploying Large Language
Models (LLMs) in finance. Accurate extraction and precise calculation from
tabular data are essential for reliable financial analysis, since even minor
numerical errors can undermine decision-making and regulatory compliance.
Financial applications have unique requirements, often relying on
context-dependent, numerical, and proprietary tabular data that existing
hallucination benchmarks rarely capture. In this study, we develop a rigorous
and scalable framework for evaluating intrinsic hallucinations in financial
LLMs, conceptualized as a context-aware masked span prediction task over
real-world financial documents. Our main contributions are: (1) a novel,
automated dataset creation paradigm using a masking strategy; (2) a new
hallucination evaluation dataset derived from S&P 500 annual reports; and (3) a
comprehensive evaluation of intrinsic hallucination patterns in
state-of-the-art LLMs on financial tabular data. Our work provides a robust
methodology for in-house LLM evaluation and serves as a critical step toward
building more trustworthy and reliable financial Generative AI systems.

</details>


### [97] [Near Optimal Inference for the Best-Performing Algorithm](https://arxiv.org/abs/2508.05173)
*Amichai Painsky*

Main category: cs.LG

TL;DR: 본 논문은 여러 기계 학습 알고리즘 중 미래 데이터셋에서 가장 높은 성능을 보일 알고리즘을 선택하는 방법을 제시하며, 이 문제를 다항 분포의 부분 집합 선택 문제로 정의한다.


<details>
  <summary>Details</summary>
Motivation: 복수의 기계 학습 알고리즘의 성능 차이가 미미할 때, 향후 데이터셋에서 가장 성능이 좋은 알고리즘을 선택할 필요성이 있다.

Method: 부분 집합 선택 문제를 위한 새로운 프레임워크를 제안하고, 비대칭적 및 유한 표본 경우의 схем을 제공하여 기존 방법보다 성능을 개선했다.

Result: 제안된 방법은 기존 방법보다 유리한 성능을 보이며, 일치하는 하한치를 제공하여 자신의 이점을 보여준다.

Conclusion: 새로운 방법론이 기존의 기법들보다 개선된 결과를 제공하며, 기계 학습에서 알고리즘 선택에 대한 보다 효과적인 접근을 가능하게 한다.

Abstract: Consider a collection of competing machine learning algorithms. Given their
performance on a benchmark of datasets, we would like to identify the best
performing algorithm. Specifically, which algorithm is most likely to rank
highest on a future, unseen dataset. A natural approach is to select the
algorithm that demonstrates the best performance on the benchmark. However, in
many cases the performance differences are marginal and additional candidates
may also be considered. This problem is formulated as subset selection for
multinomial distributions. Formally, given a sample from a countable alphabet,
our goal is to identify a minimal subset of symbols that includes the most
frequent symbol in the population with high confidence. In this work, we
introduce a novel framework for the subset selection problem. We provide both
asymptotic and finite-sample schemes that significantly improve upon currently
known methods. In addition, we provide matching lower bounds, demonstrating the
favorable performance of our proposed schemes.

</details>


### [98] [Advanced Hybrid Transformer LSTM Technique with Attention and TS Mixer for Drilling Rate of Penetration Prediction](https://arxiv.org/abs/2508.05210)
*Saddam Hussain Khan*

Main category: cs.LG

TL;DR: 혼합 딥러닝 아키텍처를 통해 드릴링 데이터의 침투율(ROP)을 정확하게 예측할 수 있는 모델을 개발하여 성능을 극대화했다.


<details>
  <summary>Details</summary>
Motivation: 드릴링 운영의 최적화를 위해 침투율(ROP)의 정확한 예측이 필요하다. 그러나 전통적인 방법들은 복잡한 드릴링 데이터의 동적 및 고차원적인 특성을 포착하는 데 한계가 있다.

Method: Long Short-Term Memory (LSTM) 네트워크, Transformer 인코더, Time-Series Mixer (TS-Mixer) 블록 및 주의 메커니즘을 통합한 혼합 딥러닝 아키텍처를 제안하여 시간 의존성, 정적 피처 상호작용, 글로벌 컨텍스트, 동적 피처 중요성을 모델링했다.

Result: 실제 드릴링 데이터셋에서 평가한 결과, R-제곱 점수 0.9988 및 평균 절대 백분율 오차 1.447%로 기존의 모델들을 초월했다.

Conclusion: 이 첨단 혼합 접근법은 신뢰할 수 있는 실시간 ROP 예측을 가능하게 하여 지능적이고 비용 효율적인 드릴링 최적화 시스템을 위한 길을 열었다.

Abstract: The Rate of Penetration (ROP) is crucial for optimizing drilling operations;
however, accurately predicting it is hindered by the complex, dynamic, and
high-dimensional nature of drilling data. Traditional empirical, physics-based,
and basic machine learning models often fail to capture intricate temporal and
contextual relationships, resulting in suboptimal predictions and limited
real-time utility. To address this gap, we propose a novel hybrid deep learning
architecture integrating Long Short-Term Memory (LSTM) networks, Transformer
encoders, Time-Series Mixer (TS-Mixer) blocks, and attention mechanisms to
synergistically model temporal dependencies, static feature interactions,
global context, and dynamic feature importance. Evaluated on a real-world
drilling dataset, our model outperformed benchmarks (standalone LSTM, TS-Mixer,
and simpler hybrids) with an R-squared score of 0.9988 and a Mean Absolute
Percentage Error of 1.447%, as measured by standard regression metrics
(R-squared, MAE, RMSE, MAPE). Model interpretability was ensured using SHAP and
LIME, while actual vs. predicted curves and bias checks confirmed accuracy and
fairness across scenarios. This advanced hybrid approach enables reliable
real-time ROP prediction, paving the way for intelligent, cost-effective
drilling optimization systems with significant operational impact.

</details>


### [99] [Human Activity Recognition from Smartphone Sensor Data for Clinical Trials](https://arxiv.org/abs/2508.05175)
*Stefania Russo,Rafał Klimas,Marta Płonka,Hugo Le Gall,Sven Holm,Dimitar Stanev,Florian Lipsmeier,Mattia Zanon,Lito Kriara*

Main category: cs.LG

TL;DR: ResNet 기반의 인간 활동 인식 모델이 다양한 스마트폰 착용 위치에서 높은 정확도로 일상 활동을 감지한다.


<details>
  <summary>Details</summary>
Motivation: 행동 인식의 필요성과 여러 질병 환자(특히 다발성 경화증 환자)의 일상 활동 모니터링의 중요성을 강조.

Method: 스마트폰 센서 데이터를 사용하여 운동과 비운동 활동 및 다양한 일상 활동을 감지하기 위해 ResNet 모델을 개발하고 훈련 및 평가했다.

Result: GaitLab 및 Roche 데이터셋에서 각각 98.4% 및 99.6%의 정확도로 운동 감지, 내부 Roche 데이터셋에서 일상 활동의 정확도가 96.2%로 기존 모델보다 높았다.

Conclusion: 제안된 HAR 모델은 일상 활동을 정확하게 감지하고 다양한 스마트폰 착용 위치에서도 높은 내구성을 보여준다.

Abstract: We developed a ResNet-based human activity recognition (HAR) model with
minimal overhead to detect gait versus non-gait activities and everyday
activities (walking, running, stairs, standing, sitting, lying, sit-to-stand
transitions). The model was trained and evaluated using smartphone sensor data
from adult healthy controls (HC) and people with multiple sclerosis (PwMS) with
Expanded Disability Status Scale (EDSS) scores between 0.0-6.5. Datasets
included the GaitLab study (ISRCTN15993728), an internal Roche dataset, and
publicly available data sources (training only). Data from 34 HC and 68 PwMS
(mean [SD] EDSS: 4.7 [1.5]) were included in the evaluation. The HAR model
showed 98.4% and 99.6% accuracy in detecting gait versus non-gait activities in
the GaitLab and Roche datasets, respectively, similar to a comparative
state-of-the-art ResNet model (99.3% and 99.4%). For everyday activities, the
proposed model not only demonstrated higher accuracy than the state-of-the-art
model (96.2% vs 91.9%; internal Roche dataset) but also maintained high
performance across 9 smartphone wear locations (handbag, shopping bag,
crossbody bag, backpack, hoodie pocket, coat/jacket pocket, hand, neck, belt),
outperforming the state-of-the-art model by 2.8% - 9.0%. In conclusion, the
proposed HAR model accurately detects everyday activities and shows high
robustness to various smartphone wear locations, demonstrating its practical
applicability.

</details>


### [100] [Marine Chlorophyll Prediction and Driver Analysis based on LSTM-RF Hybrid Models](https://arxiv.org/abs/2508.05260)
*Zhouyao Qian,Yang Chen,Baodian Li,Shuyi Zhang,Zhen Tian,Gongsen Wang,Tianyue Gu,Xinyu Zhou,Huilin Chen,Xinyi Li,Hao Zhu,Shuyao Zhang,Zongheng Li,Siyuan Wang*

Main category: cs.LG

TL;DR: LSTM-RF 하이브리드 모델이 해양 엽록소 농도 예측에서 뛰어난 성능을 보임.


<details>
  <summary>Details</summary>
Motivation: 해양 엽록소 농도는 생태계 건강과 탄소 순환의 중요한 지표이며 정확한 예측이 필요하다.

Method: LSTM과 RF의 장점을 결합한 하이브리드 모델을 제안하고, 다중 출처 해양 데이터를 사용하여 훈련하였다.

Result: LSTM-RF 모델은 테스트 세트에서 R^2 0.5386, MSE 0.005806, MAE 0.057147을 기록하였다.

Conclusion: 표준화된 처리 및 슬라이딩 윈도우 접근법을 통해 모델의 예측 정확도를 향상시켰다.

Abstract: Marine chlorophyll concentration is an important indicator of ecosystem
health and carbon cycle strength, and its accurate prediction is crucial for
red tide warning and ecological response. In this paper, we propose a LSTM-RF
hybrid model that combines the advantages of LSTM and RF, which solves the
deficiencies of a single model in time-series modelling and nonlinear feature
portrayal. Trained with multi-source ocean data(temperature, salinity,
dissolved oxygen, etc.), the experimental results show that the LSTM-RF model
has an R^2 of 0.5386, an MSE of 0.005806, and an MAE of 0.057147 on the test
set, which is significantly better than using LSTM (R^2 = 0.0208) and RF (R^2
=0.4934) alone , respectively. The standardised treatment and sliding window
approach improved the prediction accuracy of the model and provided an
innovative solution for high-frequency prediction of marine ecological
variables.

</details>


### [101] [Physics-Informed Time-Integrated DeepONet: Temporal Tangent Space Operator Learning for High-Accuracy Inference](https://arxiv.org/abs/2508.05190)
*Luis Mandl,Dibyajyoti Nayak,Tim Ricken,Somdatta Goswami*

Main category: cs.LG

TL;DR: PITI-DeepONet은 전통적인 예측 방법보다 안정적이고 정확한 시간 의존적 PDE 솔루션을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 시간 의존적인 편미분 방정식(PDE)의 정확한 모델링과 추정은 과학 기계 학습에서 핵심적인 도전 과제입니다.

Method: PITI-DeepONet은 현재 상태에서 시간 미분 연산자를 학습하고 고전적인 시간 적분 스킴을 사용하여 솔루션을 시간적으로 진전시킵니다.

Result: PITI-DeepONet은 기존 방법에 비해 1차원 열 방정식에서 84%의 평균 상대 $	ext{L}_2$ 오류 감소를 보였습니다.

Conclusion: PITI-DeepONet은 복잡한 시간 의존 PDE의 신뢰할 수 있는 장기 통합을 가능하게 합니다.

Abstract: Accurately modeling and inferring solutions to time-dependent partial
differential equations (PDEs) over extended horizons remains a core challenge
in scientific machine learning. Traditional full rollout (FR) methods, which
predict entire trajectories in one pass, often fail to capture the causal
dependencies and generalize poorly outside the training time horizon.
Autoregressive (AR) approaches, evolving the system step by step, suffer from
error accumulation, limiting long-term accuracy. These shortcomings limit the
long-term accuracy and reliability of both strategies. To address these issues,
we introduce the Physics-Informed Time-Integrated Deep Operator Network
(PITI-DeepONet), a dual-output architecture trained via fully physics-informed
or hybrid physics- and data-driven objectives to ensure stable, accurate
long-term evolution well beyond the training horizon. Instead of forecasting
future states, the network learns the time-derivative operator from the current
state, integrating it using classical time-stepping schemes to advance the
solution in time. Additionally, the framework can leverage residual monitoring
during inference to estimate prediction quality and detect when the system
transitions outside the training domain. Applied to benchmark problems,
PITI-DeepONet shows improved accuracy over extended inference time horizons
when compared to traditional methods. Mean relative $\mathcal{L}_2$ errors
reduced by 84% (vs. FR) and 79% (vs. AR) for the one-dimensional heat equation;
by 87% (vs. FR) and 98% (vs. AR) for the one-dimensional Burgers equation; and
by 42% (vs. FR) and 89% (vs. AR) for the two-dimensional Allen-Cahn equation.
By moving beyond classic FR and AR schemes, PITI-DeepONet paves the way for
more reliable, long-term integration of complex, time-dependent PDEs.

</details>


### [102] [FlowState: Sampling Rate Invariant Time Series Forecasting](https://arxiv.org/abs/2508.05287)
*Lars Graf,Thomas Ortner,Stanisław Woźniak,Angeliki Pantazi*

Main category: cs.LG

TL;DR: FlowState는 시계열 예측을 위해 설계된 혁신적인 기초 모델로, 기존 모델의 한계를 극복하고 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 기존 시계열 기초 모델의 일반화 한계, 적응성 부족, 계산 비효율성을 해결하고자 함.

Method: 상태공간모델(SSM) 기반 인코더와 기능적 기초 디코더를 사용하여 연속 시간 모델링 및 동적 시간 스케일 조정을 가능하게 함.

Result: FlowState는 GIFT-ZS 및 Chronos-ZS 벤치마크에서 모든 다른 모델을 초월하는 성능을 보임.

Conclusion: FlowState는 작은 모델임에도 불구하고 탁월한 성능을 발휘하며, 다양한 입력 샘플링 속도에 적응하는 독특한 능력을 입증함.

Abstract: Foundation models (FMs) have transformed natural language processing, but
their success has not yet translated to time series forecasting. Existing time
series foundation models (TSFMs), often based on transformer variants, struggle
with generalization across varying context and target lengths, lack
adaptability to different sampling rates, and are computationally inefficient.
We introduce FlowState, a novel TSFM architecture that addresses these
challenges through two key innovations: a state space model (SSM) based encoder
and a functional basis decoder. This design enables continuous-time modeling
and dynamic time-scale adjustment, allowing FlowState to inherently generalize
across all possible temporal resolutions, and dynamically adjust the
forecasting horizons. In contrast to other state-of-the-art TSFMs, which
require training data across all possible sampling rates to memorize patterns
at each scale, FlowState inherently adapts its internal dynamics to the input
scale, enabling smaller models, reduced data requirements, and improved
efficiency. We further propose an efficient pretraining strategy that improves
robustness and accelerates training. Despite being the smallest model,
FlowState outperforms all other models and is state-of-the-art for the GIFT-ZS
and the Chronos-ZS benchmarks. Ablation studies confirm the effectiveness of
its components, and we demonstrate its unique ability to adapt online to
varying input sampling rates.

</details>


### [103] [ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning](https://arxiv.org/abs/2508.05310)
*Jelle Luijkx,Zlatan Ajanović,Laura Ferranti,Jens Kober*

Main category: cs.LG

TL;DR: 본 논문에서는 상호작용 모방 학습의 적용 가능성을 높이기 위해 강사 피드백을 활용하는 ASkDAgger 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 인간의 교육 노력이 상호작용 모방 학습의 주요 병목 현상이며, 이를 해결하기 위해 불확실한 상황에서만 피드백을 요청하는 방법이 필요하다.

Method: ASkDAgger 프레임워크는(S-Aware Gating, Foresight Interactive Experience Replay, Prioritized Interactive Experience Replay) 상호작용을 통해 강사 피드백을 활용한다.

Result: 이 방법은 쿼리 빈도와 실패 발생을 조정하며, 필요한 시연 주석 수를 줄이고, 일반화를 개선하며, 변화하는 영역에의 적응 속도를 높인다.

Conclusion: ASkDAgger는 시뮬레이션 및 실제 환경에서 언어 조건 부작업을 통해 효과성을 검증하였다.

Abstract: Human teaching effort is a significant bottleneck for the broader
applicability of interactive imitation learning. To reduce the number of
required queries, existing methods employ active learning to query the human
teacher only in uncertain, risky, or novel situations. However, during these
queries, the novice's planned actions are not utilized despite containing
valuable information, such as the novice's capabilities, as well as
corresponding uncertainty levels. To this end, we allow the novice to say: "I
plan to do this, but I am uncertain." We introduce the Active Skill-level Data
Aggregation (ASkDAgger) framework, which leverages teacher feedback on the
novice plan in three key ways: (1) S-Aware Gating (SAG): Adjusts the gating
threshold to track sensitivity, specificity, or a minimum success rate; (2)
Foresight Interactive Experience Replay (FIER), which recasts valid and
relabeled novice action plans into demonstrations; and (3) Prioritized
Interactive Experience Replay (PIER), which prioritizes replay based on
uncertainty, novice success, and demonstration age. Together, these components
balance query frequency with failure incidence, reduce the number of required
demonstration annotations, improve generalization, and speed up adaptation to
changing domains. We validate the effectiveness of ASkDAgger through
language-conditioned manipulation tasks in both simulation and real-world
environments. Code, data, and videos are available at
https://askdagger.github.io.

</details>


### [104] [Bidding-Aware Retrieval for Multi-Stage Consistency in Online Advertising](https://arxiv.org/abs/2508.05206)
*Bin Liu,Yunfei Liu,Ziru Xu,Zhaoyu Zhou,Zhi Kou,Yeqiu Yang,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: Bidding-Aware Retrieval (BAR) 모델은 광고 입찰가를 반영하여 검색 점수를 조정함으로써 온라인 광고의 비효율성을 해결하고 플랫폼 수익을 증가시킨다.


<details>
  <summary>Details</summary>
Motivation: 자동 입찰 전략의 인기로 인해 검색 단계와 순위 매기기 단계 간의 불일치가 증가하여 최적의 수익을 창출하지 못하고 있어서 이를 극복하기 위한 방법이 필요하다.

Method: 광고 입찰가를 검색 점수에 통합한 Bidding-Aware Retrieval (BAR) 프레임워크를 제안하고, 모노토닉 제약 학습 및 다중 작업 증류를 통해 입찰 신호를 포함시켰다.

Result: BAR는 22.2%의 노출 증가와 함께 플랫폼 수익을 4.32% 증가시켰다.

Conclusion: BAR는 실시간 시장 변화에 민감하게 반응하며 광고의 효율성을 개선하는 데 기여하는 것으로 나타났다.

Abstract: Online advertising systems typically use a cascaded architecture to manage
massive requests and candidate volumes, where the ranking stages allocate
traffic based on eCPM (predicted CTR $\times$ Bid). With the increasing
popularity of auto-bidding strategies, the inconsistency between the
computationally sensitive retrieval stage and the ranking stages becomes more
pronounced, as the former cannot access precise, real-time bids for the vast ad
corpus. This discrepancy leads to sub-optimal platform revenue and advertiser
outcomes. To tackle this problem, we propose Bidding-Aware Retrieval (BAR), a
model-based retrieval framework that addresses multi-stage inconsistency by
incorporating ad bid value into the retrieval scoring function. The core
innovation is Bidding-Aware Modeling, incorporating bid signals through
monotonicity-constrained learning and multi-task distillation to ensure
economically coherent representations, while Asynchronous Near-Line Inference
enables real-time updates to the embedding for market responsiveness.
Furthermore, the Task-Attentive Refinement module selectively enhances feature
interactions to disentangle user interest and commercial value signals.
Extensive offline experiments and full-scale deployment across Alibaba's
display advertising platform validated BAR's efficacy: 4.32% platform revenue
increase with 22.2% impression lift for positively-operated advertisements.

</details>


### [105] [Optimal Corpus Aware Training for Neural Machine Translation](https://arxiv.org/abs/2508.05364)
*Yi-Hsiu Liao,Cheng Shen,Brenda,Yang*

Main category: cs.LG

TL;DR: Optimal Corpus Aware Training (OCAT)은 기존의 Corpus Aware Training (CAT)을 개선하여 경량화된 모델을 통해 번역 정확도를 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 CAT의 데이터 취약성과 비효율성을 개선하고, 오류가 적은 고품질 데이터를 사전에 정의하지 않고도 성능을 극대화하고자 한다.

Method: 대부분의 모델 파라미터를 고정하고 소량의 코퍼스 관련 파라미터만 조정하여 CAT 사전 훈련 모델을 미세 조정한다.

Result: WMT23의 영어-중국어 및 영어-독일어 번역 작업에서 각각 +3.6 및 +1.8 chrF 향상을 보였다.

Conclusion: OCAT은 경량이며 과적합에 강하고 하이퍼파라미터 설정에 덜 민감하며, 기존의 최첨단 미세 조정 기법과 비슷하거나 더 나은 성능을 나타낸다.

Abstract: Corpus Aware Training (CAT) leverages valuable corpus metadata during
training by injecting corpus information into each training example, and has
been found effective in the literature, commonly known as the "tagging"
approach. Models trained with CAT inherently learn the quality, domain and
nuance between corpora directly from data, and can easily switch to different
inference behavior. To achieve the best evaluation, CAT models pre-define a
group of high quality data before training starts which can be error-prone and
inefficient. In this work, we propose Optimal Corpus Aware Training (OCAT),
which fine-tunes a CAT pre-trained model by freezing most of the model
parameters and only tuning small set of corpus-related parameters. We show that
OCAT is lightweight, resilient to overfitting, and effective in boosting model
accuracy. We use WMT23 English to Chinese and English to German translation
tasks as our test ground and show +3.6 and +1.8 chrF improvement, respectively,
over vanilla training. Furthermore, our approach is on-par or slightly better
than other state-of-the-art fine-tuning techniques while being less sensitive
to hyperparameter settings.

</details>


### [106] [Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms](https://arxiv.org/abs/2508.05387)
*Jie Xiao,Shaoduo Gan,Changyuan Fan,Qingnan Ren,Alfred Long,Yuchen Zhang,Rymon Yu,Eric Yang,Lynn Ai*

Main category: cs.LG

TL;DR: Echo는 RL 기반 대규모 언어 모델의 훈련 효율성을 높이기 위해 훈련과 추론을 분리하는 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 모던 RL 기반 후훈련에서 훈련과 추론 작업의 병렬 처리가 필요하지만, 현재의 시스템은 이 두 작업 간의 전환으로 인해 효율성이 떨어진다.

Method: Echo는 훈련과 추론을 분리하는 두 가지 경량 동기화 프로토콜을 도입하여, 각 작업의 효율성을 극대화한다.

Result: Qwen3-4B, Qwen2.5-7B 및 Qwen3-32B에서 세 가지 RL 작업을 훈련한 결과, Echo는 기존의 전통적인 벤치마크와 같은 수렴 속도와 보상을 달성한다.

Conclusion: 대규모 RL을 위한 Echo는 탈중앙화된 자원을 통해 데이터센터에서의 성능을 달성할 수 있음을 보여준다.

Abstract: Modern RL-based post-training for large language models (LLMs) co-locate
trajectory sampling and policy optimisation on the same GPU cluster, forcing
the system to switch between inference and training workloads. This serial
context switching violates the single-program-multiple-data (SPMD) assumption
underlying today's distributed training systems. We present Echo, the RL system
that cleanly decouples these two phases across heterogeneous "inference" and
"training" swarms while preserving statistical efficiency. Echo introduces two
lightweight synchronization protocols: a sequential pull mode that refreshes
sampler weights on every API call for minimal bias, and an asynchronous
push-pull mode that streams version-tagged rollouts through a replay buffer to
maximise hardware utilisation. Training three representative RL workloads with
Qwen3-4B, Qwen2.5-7B and Qwen3-32B on a geographically distributed cluster,
Echo matches a fully co-located Verl baseline in convergence speed and final
reward while off-loading trajectory generation to commodity edge hardware.
These promising results demonstrate that large-scale RL for LLMs could achieve
datacentre-grade performance using decentralised, heterogeneous resources.

</details>


### [107] [DFW: A Novel Weighting Scheme for Covariate Balancing and Treatment Effect Estimation](https://arxiv.org/abs/2508.05215)
*Ahmad Saeed Khan,Erik Schaffernicht,Johannes Andreas Stork*

Main category: cs.LG

TL;DR: 관찰 데이터를 통한 인과 효과 추정은 선택 편향으로 인해 어려워진다. 본 논문에서 제안하는 Deconfounding Factor Weighting(DFW) 방법은 안정적이고 효과적인 샘플 가중치를 구성하여 이 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 선택 편향으로 인한 치료 그룹 간의 불균형한 공변량 분포 문제 해결을 위해.

Method: DFW는 탈혼란 요인을 활용하여 안정된 샘플 가중치를 생성하고, 고혼란 샘플의 영향을 줄인다.

Result: DFW는 공변량 균형 및 치료 효과 추정에서 기존 방법들보다 우수한 성능을 보인다.

Conclusion: DFW는 이진 치료에 대해 설계되었지만, 여러 치료 설정으로 자연스럽게 확장 가능하다.

Abstract: Estimating causal effects from observational data is challenging due to
selection bias, which leads to imbalanced covariate distributions across
treatment groups. Propensity score-based weighting methods are widely used to
address this issue by reweighting samples to simulate a randomized controlled
trial (RCT). However, the effectiveness of these methods heavily depends on the
observed data and the accuracy of the propensity score estimator. For example,
inverse propensity weighting (IPW) assigns weights based on the inverse of the
propensity score, which can lead to instable weights when propensity scores
have high variance-either due to data or model misspecification-ultimately
degrading the ability of handling selection bias and treatment effect
estimation. To overcome these limitations, we propose Deconfounding Factor
Weighting (DFW), a novel propensity score-based approach that leverages the
deconfounding factor-to construct stable and effective sample weights. DFW
prioritizes less confounded samples while mitigating the influence of highly
confounded ones, producing a pseudopopulation that better approximates a RCT.
Our approach ensures bounded weights, lower variance, and improved covariate
balance.While DFW is formulated for binary treatments, it naturally extends to
multi-treatment settings, as the deconfounding factor is computed based on the
estimated probability of the treatment actually received by each sample.
Through extensive experiments on real-world benchmark and synthetic datasets,
we demonstrate that DFW outperforms existing methods, including IPW and CBPS,
in both covariate balancing and treatment effect estimation.

</details>


### [108] [Tail-Risk-Safe Monte Carlo Tree Search under PAC-Level Guarantees](https://arxiv.org/abs/2508.05441)
*Zuyuan Zhang,Arnob Ghosh,Tian Lan*

Main category: cs.LG

TL;DR: 본 논문은 몬테카를로 트리 탐색(MCTS)에서 극단적인 위험 결과를 고려하는 새로운 두 가지 방법(CVaR-MCTS 및 Wasserstein-MCTS)을 제안하여 안정적인 결정 내리기를 지원한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 MCTS는 예상 수익만 고려해 극단적 위험 결과를 반영하지 않음에 따라 고위험 상황에서 심각한 결과를 초래할 수 있다.

Method: CVaR-MCTS는 조건부 가치-at-위험(CVaR)을 MCTS에 통합하여 극단적 손실을 통제하며, Wasserstein-MCTS는 tail-risk 추정의 편향을 줄이기 위해 1차 Wasserstein 불확실성 집합을 도입한다.

Result: 제안된 방법들이 기존 기준선보다 우수한 성능을 보이며, 향상된 보상과 안정성을 확보하고 tail-risk에 대한 강력한 보장을 달성한다.

Conclusion: CVaR-MCTS 및 Wasserstein-MCTS는 PAC tail-safety 보장을 제공하며, 이로써 의사결정의 신뢰성을 높였다.

Abstract: Making decisions with respect to just the expected returns in Monte Carlo
Tree Search (MCTS) cannot account for the potential range of high-risk, adverse
outcomes associated with a decision. To this end, safety-aware MCTS often
consider some constrained variants -- by introducing some form of mean risk
measures or hard cost thresholds. These approaches fail to provide rigorous
tail-safety guarantees with respect to extreme or high-risk outcomes (denoted
as tail-risk), potentially resulting in serious consequence in high-stake
scenarios. This paper addresses the problem by developing two novel solutions.
We first propose CVaR-MCTS, which embeds a coherent tail risk measure,
Conditional Value-at-Risk (CVaR), into MCTS. Our CVaR-MCTS with parameter
$\alpha$ achieves explicit tail-risk control over the expected loss in the
"worst $(1-\alpha)\%$ scenarios." Second, we further address the estimation
bias of tail-risk due to limited samples. We propose Wasserstein-MCTS (or
W-MCTS) by introducing a first-order Wasserstein ambiguity set
$\mathcal{P}_{\varepsilon_{s}}(s,a)$ with radius $\varepsilon_{s}$ to
characterize the uncertainty in tail-risk estimates. We prove PAC tail-safety
guarantees for both CVaR-MCTS and W-MCTS and establish their regret.
Evaluations on diverse simulated environments demonstrate that our proposed
methods outperform existing baselines, effectively achieving robust tail-risk
guarantees with improved rewards and stability.

</details>


### [109] [ML-based Short Physical Performance Battery future score prediction based on questionnaire data](https://arxiv.org/abs/2508.05222)
*Marcin Kolakowski,Seif Ben Bader*

Main category: cs.LG

TL;DR: 이 논문은 4년 후 노인의 신체 능력 점수(SPPB)를 예측하는 데 있어 머신러닝 알고리즘의 효과를 분석하였다.


<details>
  <summary>Details</summary>
Motivation: 노인의 신체 능력 저하를 효과적으로 늦추기 위해서는 초기 증상이 나타나는 즉시 개입이 필요하다.

Method: Random Forest, XGBoost, 선형 회귀, 밀집 및 TabNet 신경망을 포함한 여러 머신러닝 알고리즘을 테스트하였다.

Result: XGBoost 알고리즘이 평균 절대 오차 0.79 포인트로 가장 우수한 성과를 보였다.

Conclusion: Shapley 값 분석을 통해 소규모 특성 집합을 선택하고 XGBoost 회귀 모델을 재훈련하여 평균 절대 오차 0.82를 달성하였다.

Abstract: Effective slowing down of older adults\' physical capacity deterioration
requires intervention as soon as the first symptoms surface. In this paper, we
analyze the possibility of predicting the Short Physical Performance Battery
(SPPB) score at a four-year horizon based on questionnaire data. The ML
algorithms tested included Random Forest, XGBoost, Linear Regression, dense and
TabNet neural networks. The best results were achieved for the XGBoost (mean
absolute error of 0.79 points). Based on the Shapley values analysis, we
selected smaller subsets of features (from 10 to 20) and retrained the XGBoost
regressor, achieving a mean absolute error of 0.82.

</details>


### [110] [EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty Estimation for Energy Forecasting](https://arxiv.org/abs/2508.05454)
*Wei Li,Zixin Wang,Qizheng Sun,Qixiang Gao,Fenglei Yang*

Main category: cs.LG

TL;DR: EnergyPatchTST는 다중 시간 동역학 및 실제 데이터의 불규칙성을 극복하여 에너지 예측의 예측 오류를 7-12% 줄이는 기술이다.


<details>
  <summary>Details</summary>
Motivation: 정확한 에너지 시간 시계열 예측은 발전 계획 및 할당에 있어 매우 중요하다.

Method: EnergyPatchTST는 패치 시간 시계열 변환기의 확장으로, 다중 시간 해상도를 캡처하기 위한 다중 스케일 특징 추출 메커니즘과 Monte Carlo 제거를 통한 불확실성 추정을 포함한다.

Result: 일반 에너지 데이터 세트에 대한 실험 결과, EnergyPatchTST는 다른 방법보다 예측 오류를 7-12% 줄였다.

Conclusion: 에너지 분야의 시간 시계열 예측을 위한 중요한 참고 자료를 제공한다.

Abstract: Accurate and reliable energy time series prediction is of great significance
for power generation planning and allocation. At present, deep learning time
series prediction has become the mainstream method. However, the multi-scale
time dynamics and the irregularity of real data lead to the limitations of the
existing methods. Therefore, we propose EnergyPatchTST, which is an extension
of the Patch Time Series Transformer specially designed for energy forecasting.
The main innovations of our method are as follows: (1) multi-scale feature
extraction mechanism to capture patterns with different time resolutions; (2)
probability prediction framework to estimate uncertainty through Monte Carlo
elimination; (3) integration path of future known variables (such as
temperature and wind conditions); And (4) Pre-training and Fine-tuning examples
to enhance the performance of limited energy data sets. A series of experiments
on common energy data sets show that EnergyPatchTST is superior to other
commonly used methods, the prediction error is reduced by 7-12%, and reliable
uncertainty estimation is provided, which provides an important reference for
time series prediction in the energy field.

</details>


### [111] [Don't Reach for the Stars: Rethinking Topology for Resilient Federated Learning](https://arxiv.org/abs/2508.05224)
*Mirko Konstantin,Anirban Mukhopadhyay*

Main category: cs.LG

TL;DR: 이 논문에서는 탈중앙화된 P2P 연합 학습 프레임워크인 LIGHTYEAR를 제안하여 데이터 개인 정보를 보호하면서 모델 훈련의 효율성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 중앙 집중식 연합 학습 방식의 한계점, 즉 단일 실패 지점, 개인화 부족, 배포 변화에 대한 낮은 강건성 문제를 해결하기 위함이다.

Method: P2P 토폴로지를 활용하여 각 클라이언트가 신뢰할 수 있는 업데이트를 식별하고 개인화된 집합으로 집계할 수 있도록 한다. 또한, 로컬 검증 세트에 기반한 합의 점수를 사용하여 업데이트를 선택하고, 정규화 항을 추가하여 훈련을 안정화한다.

Result: 제안된 접근법은 두 개의 데이터셋에서 실증 평가를 통해 중앙 집중식 기준 및 기존의 P2P 방법보다 클라이언트 수준 성능에서 일관되게 우수한 결과를 보였다.

Conclusion: LIGHTYEAR는 적대적이고 이질적인 조건에서도 연합 학습의 효과를 높일 수 있는 promising한 프레임워크로 나타났다.

Abstract: Federated learning (FL) enables collaborative model training across
distributed clients while preserving data privacy by keeping data local.
Traditional FL approaches rely on a centralized, star-shaped topology, where a
central server aggregates model updates from clients. However, this
architecture introduces several limitations, including a single point of
failure, limited personalization, and poor robustness to distribution shifts or
vulnerability to malfunctioning clients. Moreover, update selection in
centralized FL often relies on low-level parameter differences, which can be
unreliable when client data is not independent and identically distributed, and
offer clients little control. In this work, we propose a decentralized,
peer-to-peer (P2P) FL framework. It leverages the flexibility of the P2P
topology to enable each client to identify and aggregate a personalized set of
trustworthy and beneficial updates.This framework is the Local Inference Guided
Aggregation for Heterogeneous Training Environments to Yield Enhancement
Through Agreement and Regularization (LIGHTYEAR). Central to our method is an
agreement score, computed on a local validation set, which quantifies the
semantic alignment of incoming updates in the function space with respect to
the clients reference model. Each client uses this score to select a tailored
subset of updates and performs aggregation with a regularization term that
further stabilizes the training. Our empirical evaluation across two datasets
shows that the proposed approach consistently outperforms both centralized
baselines and existing P2P methods in terms of client-level performance,
particularly under adversarial and heterogeneous conditions.

</details>


### [112] [Task complexity shapes internal representations and robustness in neural networks](https://arxiv.org/abs/2508.05463)
*Robert Jankowski,Filippo Radicchi,M. Ángeles Serrano,Marián Boguñá,Santo Fortunato*

Main category: cs.LG

TL;DR: 이 연구는 다층 퍼셉트론의 내부 표현이 입력 데이터의 복잡성과 문제 난이도에 의해 어떻게 형성되는지를 탐구하며, 다양한 데이터에 구애받지 않는 프로브를 사용하여 이들의 토폴로지와 견고성을 정량화한다.


<details>
  <summary>Details</summary>
Motivation: 신경망의 내부 표현이 데이터 복잡성과 문제 해결 방식에 따라 어떻게 변화하는지 이해하는 것이 필요하다.

Method: 프루닝, 이진화, 노이즈 주입, 부호 뒤집기, 이분 네트워크 무작위화 등 다섯 가지 프로브를 사용하여 MLP의 토폴로지와 견고성을 분석하였다.

Result: 어려운 과제 모델의 가중치를 이진화하면 정확도가 무작위 수준으로 떨어지고, 반면 쉬운 과제의 모델은 견고함을 유지한다.

Conclusion: 입력 데이터의 복잡성과 문제 난이도가 MLP의 내부 표현에 중요한 영향을 미친다는 점을 강조하고, 모델 압축 및 해석 가능성을 위한 실용적인 전략을 제안한다.

Abstract: Neural networks excel across a wide range of tasks, yet remain black boxes.
In particular, how their internal representations are shaped by the complexity
of the input data and the problems they solve remains obscure. In this work, we
introduce a suite of five data-agnostic probes-pruning, binarization, noise
injection, sign flipping, and bipartite network randomization-to quantify how
task difficulty influences the topology and robustness of representations in
multilayer perceptrons (MLPs). MLPs are represented as signed, weighted
bipartite graphs from a network science perspective. We contrast easy and hard
classification tasks on the MNIST and Fashion-MNIST datasets. We show that
binarizing weights in hard-task models collapses accuracy to chance, whereas
easy-task models remain robust. We also find that pruning low-magnitude edges
in binarized hard-task models reveals a sharp phase-transition in performance.
Moreover, moderate noise injection can enhance accuracy, resembling a
stochastic-resonance effect linked to optimal sign flips of small-magnitude
weights. Finally, preserving only the sign structure-instead of precise weight
magnitudes-through bipartite network randomizations suffices to maintain high
accuracy. These phenomena define a model- and modality-agnostic measure of task
complexity: the performance gap between full-precision and binarized or
shuffled neural network performance. Our findings highlight the crucial role of
signed bipartite topology in learned representations and suggest practical
strategies for model compression and interpretability that align with task
complexity.

</details>


### [113] [Cross-LoRA: A Data-Free LoRA Transfer Framework across Heterogeneous LLMs](https://arxiv.org/abs/2508.05232)
*Feifan Xia,Mingyang Liao,Yuyang Fang,Defang Li,Yantong Xie,Weikang Li,Yang Li,Deguo Xia,Jizhou Huang*

Main category: cs.LG

TL;DR: Cross-LoRA는 다양한 언어 모델 간 LoRA 모듈을 데이터 없이 이전하는 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 PEFT 방법들은 모델 아키텍처에 강하게 결합되어 있어 다양한 사전 훈련된 대형 언어 모델에서의 응용이 제한된다.

Method: Cross-LoRA는 두 개의 주요 구성 요소, LoRA-Align과 LoRA-Shift를 포함하여, SVD와 최적 변환을 통해 소스와 타겟 모델 간의 서브스페이스 정렬을 수행하고, 소스 LoRA 업데이트를 타겟 모델에 적용한다.

Result: 실험 결과 Cross-LoRA는 기본 모델에 비해 최대 5.26%의 상대적 성능을 향상시켰다.

Conclusion: Cross-LoRA는 훈련 없이도 경량화된 적응을 가능하게 하며, 기존 LoRA 어댑터와 비슷한 성능을 유지한다.

Abstract: Traditional parameter-efficient fine-tuning (PEFT) methods such as LoRA are
tightly coupled with the base model architecture, which constrains their
applicability across heterogeneous pretrained large language models (LLMs). To
address this limitation, we introduce Cross-LoRA, a data-free framework for
transferring LoRA modules between diverse base models without requiring
additional training data. Cross-LoRA consists of two key components: (a)
LoRA-Align, which performs subspace alignment between source and target base
models through rank-truncated singular value decomposition (SVD) and
Frobenius-optimal linear transformation, ensuring compatibility under dimension
mismatch; and (b) LoRA-Shift, which applies the aligned subspaces to project
source LoRA weight updates into the target model parameter space. Both
components are data-free, training-free, and enable lightweight adaptation on a
commodity GPU in 20 minutes. Experiments on ARCs, OBOA and HellaSwag show that
Cross-LoRA achieves relative gains of up to 5.26% over base models. Across
other commonsense reasoning benchmarks, Cross-LoRA maintains performance
comparable to that of directly trained LoRA adapters.

</details>


### [114] [MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs](https://arxiv.org/abs/2508.05257)
*Xiaodong Chen,Mingming Ha,Zhenzhong Lan,Jing Zhang,Jianguo Li*

Main category: cs.LG

TL;DR: 이 논문은 Mixture-of-Basis-Experts (MoBE) 방법을 통해 모델 압축을 달성하면서 정확도 저하를 최소화하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: MoE 기반의 대형 언어 모델은 높은 성능과 효율성을 제공하지만, 메모리 요구 사항이 크기 때문에 배포에 어려움이 있다. 기존 MoE 압축 기법은 정확도가 크게 떨어지는 문제가 있다.

Method: 각 전문가의 up/gate 행렬을 고유한 매트릭스 A와 결합된 매트릭스 B로 분해하며, B는 모든 전문가에서 공유되는 기저 매트릭스의 선형 조합으로 재파라미터화된다. 이 인자는 원래 가중치 행렬과의 재구성 오류를 최소화하는 방식으로 학습된다.

Result: MoBE는 이전 연구들에 비해 현저히 낮은 정확도 저하를 달성했다. 예를 들어, MoBE는 Qwen3-235B-A22B-2507, DeepSeek-V3-0324 (671B) 및 Kimi-K2-Instruct (1T)의 매개변수 수를 24%-30% 줄이며, 정확도 저하는 1%-2%로 제한된다.

Conclusion: MoBE는 효율적으로 모델 압축을 수행하면서도 성능 손실을 최소화할 수 있는 새로운 접근 방식을 제시하였다.

Abstract: The Mixture-of-Experts (MoE) architecture has become a predominant paradigm
for scaling large language models (LLMs). Despite offering strong performance
and computational efficiency, large MoE-based LLMs like DeepSeek-V3-0324 and
Kimi-K2-Instruct present serious challenges due to substantial memory
requirements in deployment. While recent works have explored MoE compression to
address this issue, existing methods often suffer from considerable accuracy
drops (e.g., 7-14% relatively) even at modest compression rates. This paper
introduces a novel Mixture-of-Basis-Experts (MoBE) method that achieves model
compression while incurring minimal accuracy drops. Specifically, each up/gate
matrix in an expert is decomposed via a rank decomposition as W = AB, where
matrix A is unique to each expert. The relatively larger matrix B is further
re-parameterized as a linear combination of basis matrices {Bi} shared across
all experts within a given MoE layer. The factorization is learned by
minimizing the reconstruction error relative to the original weight matrices.
Experiments demonstrate that MoBE achieves notably lower accuracy drops
compared to prior works. For instance, MoBE can reduce the parameter counts of
Qwen3-235B-A22B-2507, DeepSeek-V3-0324 (671B) and Kimi-K2-Instruct (1T) by
24%-30% with only 1%-2% accuracy drop (about 2% drops when measured
relatively).

</details>


### [115] [Tractable Sharpness-Aware Learning of Probabilistic Circuits](https://arxiv.org/abs/2508.05537)
*Hrithik Suresh,Sahil Sidheekh,Vishnu Shreeram M. P,Sriraam Natarajan,Narayanan C. Krishnan*

Main category: cs.LG

TL;DR: 확률 회로(PCs)는 정확하고 수용 가능한 추론을 위한 생성 모델의 한 종류로, 최근의 발전으로 깊고 표현력이 풍부한 PCs의 학습이 가능해졌다. 하지만 이러한 향상이 과적합으로 이어질 수 있다. 우리는 PC의 과적합을 분석하고, 헤시안 기반 정규화기를 제안하여 성능을 개선하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 특정 데이터셋에서의 과적합 문제를 해결하기 위해, 헤시안 기반의 정규화 기법을 제안하여 PC의 일반화 성능을 향상시키고자 한다.

Method: 헤시안의 대각합을 계산하여 PC의 훈련에 정규화 효과를 적용하고, 이를 통해 EM 알고리즘에 대한 간략한 매개변수 업데이트를 제공한다.

Result: 우리가 제안한 방법이 PC를 더 평탄한 최소값으로 유도하며, 일반화 성능이 향상되는 것을 보인다.

Conclusion: 헤시안 기반 정규화는 값비싼 계산을 요구하지 않으면서도 PC의 성능을 개선하는 데 효과적이다.

Abstract: Probabilistic Circuits (PCs) are a class of generative models that allow
exact and tractable inference for a wide range of queries. While recent
developments have enabled the learning of deep and expressive PCs, this
increased capacity can often lead to overfitting, especially when data is
limited. We analyze PC overfitting from a log-likelihood-landscape perspective
and show that it is often caused by convergence to sharp optima that generalize
poorly. Inspired by sharpness aware minimization in neural networks, we propose
a Hessian-based regularizer for training PCs. As a key contribution, we show
that the trace of the Hessian of the log-likelihood-a sharpness proxy that is
typically intractable in deep neural networks-can be computed efficiently for
PCs. Minimizing this Hessian trace induces a gradient-norm-based regularizer
that yields simple closed-form parameter updates for EM, and integrates
seamlessly with gradient based learning methods. Experiments on synthetic and
real-world datasets demonstrate that our method consistently guides PCs toward
flatter minima, improves generalization performance.

</details>


### [116] [Adapting Vision-Language Models Without Labels: A Comprehensive Survey](https://arxiv.org/abs/2508.05547)
*Hao Dong,Lijun Sheng,Jian Liang,Ran He,Eleni Chatzi,Olga Fink*

Main category: cs.LG

TL;DR: 비전-언어 모델(VLM)의 비지도 적응을 위한 체계적인 개요를 제시.


<details>
  <summary>Details</summary>
Motivation: 특정 다운스트림 시나리오에 대한 성능 저하 문제를 해결하고자.

Method: 라벨 없는 시각 데이터의 가용성과 성격에 따라 기존 접근 방식을 네 가지 주요 패러다임으로 분류함.

Result: 각 패러다임에 따른 주요 방법론과 적응 전략을 분석하고, 여러 응용 프로그램의 대표 벤치마크를 검토함.

Conclusion: 미래 연구를 위한 개방적 과제와 유망한 방향성을 강조하며 관련 문헌 저장소 제공.

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable generalization
capabilities across a wide range of tasks. However, their performance often
remains suboptimal when directly applied to specific downstream scenarios
without task-specific adaptation. To enhance their utility while preserving
data efficiency, recent research has increasingly focused on unsupervised
adaptation methods that do not rely on labeled data. Despite the growing
interest in this area, there remains a lack of a unified, task-oriented survey
dedicated to unsupervised VLM adaptation. To bridge this gap, we present a
comprehensive and structured overview of the field. We propose a taxonomy based
on the availability and nature of unlabeled visual data, categorizing existing
approaches into four key paradigms: Data-Free Transfer (no data), Unsupervised
Domain Transfer (abundant data), Episodic Test-Time Adaptation (batch data),
and Online Test-Time Adaptation (streaming data). Within this framework, we
analyze core methodologies and adaptation strategies associated with each
paradigm, aiming to establish a systematic understanding of the field.
Additionally, we review representative benchmarks across diverse applications
and highlight open challenges and promising directions for future research. An
actively maintained repository of relevant literature is available at
https://github.com/tim-learn/Awesome-LabelFree-VLMs.

</details>


### [117] [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](https://arxiv.org/abs/2508.05581)
*Guilherme Seidyo Imai Aldeia,Daniel S. Herman,William G. La Cava*

Main category: cs.LG

TL;DR: 대형 언어 모델(LLMs)을 사용하여 의료 질문 응답 및 해석 가능한 컴퓨팅 표현(CPs)을 생성하는 가능성을 조사한 연구이다.


<details>
  <summary>Details</summary>
Motivation: 고혈압 환자를 위한 의료 결정 지원을 개선하기 위해 해석 가능한 CPs 생성의 가능성을 탐구하고자 함.

Method: LLMs가 CPs를 생성하고 이를 데이터 기반 피드백을 통해 반복적으로 다듬는 방법론을 제안하고 테스트함.

Result: LLMs가 반복 학습과 결합하여 해석 가능한 프로그램을 생성하였으며, 상태-오브-더-아트 ML 방법들과 유사한 성능을 나타냄.

Conclusion: LLMs가 적은 훈련 예제로도 효과적인 CPs 생성을 가능하게 함을 보여준다.

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities for
medical question answering and programming, but their potential for generating
interpretable computable phenotypes (CPs) is under-explored. In this work, we
investigate whether LLMs can generate accurate and concise CPs for six clinical
phenotypes of varying complexity, which could be leveraged to enable scalable
clinical decision support to improve care for patients with hypertension. In
addition to evaluating zero-short performance, we propose and test a
synthesize, execute, debug, instruct strategy that uses LLMs to generate and
iteratively refine CPs using data-driven feedback. Our results show that LLMs,
coupled with iterative learning, can generate interpretable and reasonably
accurate programs that approach the performance of state-of-the-art ML methods
while requiring significantly fewer training examples.

</details>


### [118] [RLHF Fine-Tuning of LLMs for Alignment with Implicit User Feedback in Conversational Recommenders](https://arxiv.org/abs/2508.05289)
*Zhongheng Yang,Aijia Sun,Yushang Zhao,Yinuo Yang,Dannier Li,Chengrui Zhou*

Main category: cs.LG

TL;DR: 이 연구는 대화형 추천 시스템을 위해 인간 피드백 강화 학습(RLHF)을 활용하여 사용자 선호도를 최적화하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 감독학습 방법이 암묵적 피드백 신호를 포착하지 못해 추천 품질이 저하되는 문제를 해결하고자 함.

Method: 사용자 참여 정보를 기반으로 한 보상 모델을 학습하고, PPO 접근법을 통해 LLM을 최적화하는 RLHF 방법론을 제안.

Result: 실험 결과, 추천의 정확성, 일관성, 사용자 만족도에서 RLHF로 튜닝된 모델이 기존 모델에 비해 우수한 성능을 보임을 확인.

Conclusion: 암묵적 신호 정렬이 대화형 추천 시스템의 적응성과 확장성을 향상시키는 데 효과적일 수 있음을 보여준다.

Abstract: Conversational recommender systems (CRS) based on Large Language Models
(LLMs) need to constantly be aligned to the user preferences to provide
satisfying and context-relevant item recommendations. The traditional
supervised fine-tuning cannot capture the implicit feedback signal, e.g., dwell
time, sentiment polarity, or engagement patterns. In this paper, we share a
fine-tuning solution using human feedback reinforcement learning (RLHF) to
maximize implied user feedback (IUF) in a multi-turn recommendation context. We
specify a reward model $R_{\phi}$ learnt on weakly-labelled engagement
information and maximize user-centric utility by optimizing the foundational
LLM M_{\theta} through a proximal policy optimization (PPO) approach. The
architecture models conversational state transitions $s_t \to a_t \to s_{t
+1}$, where the action $a_t$ is associated with LLM-generated item suggestions
only on condition of conversation history in the past. The evaluation across
synthetic and real-world datasets (e.g.REDIAL, OpenDialKG) demonstrates that
our RLHF-fine-tuned models can perform better in terms of top-$k$
recommendation accuracy, coherence, and user satisfaction compared to
(arrow-zero-cmwrquca-teja-falset ensuite 2Round group-deca States penalty give
up This paper shows that implicit signal alignment can be efficient in
achieving scalable and user-adaptive design of CRS.

</details>


### [119] [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](https://arxiv.org/abs/2508.05612)
*Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai*

Main category: cs.LG

TL;DR: Shuffle-R1 프레임워크는 다중 모달 대형 언어 모델의 강화 학습 효율성을 개선하기 위해 동적 궤적 샘플링 및 배치 구성 재구성을 제안한다.


<details>
  <summary>Details</summary>
Motivation: MLLM의 추론 능력을 향상시키기 위한 강화 학습의 효율성 문제를 해결하고자 함.

Method: Pairwise Trajectory Sampling과 Advantage-based Trajectory Shuffle을 통해 궤적 샘플링 및 배치 구성을 개선.

Result: 기존의 강력한 RL 기준선을 지속적으로 능가하는 성과를 보임.

Conclusion: 데이터 중심의 적응이 MLLM의 강화 학습 훈련 효율성을 높이는 데 중요함을 강조.

Abstract: Reinforcement learning (RL) has emerged as an effective post-training
paradigm for enhancing the reasoning capabilities of multimodal large language
model (MLLM). However, current RL pipelines often suffer from training
inefficiencies caused by two underexplored issues: Advantage Collapsing, where
most advantages in a batch concentrate near zero, and Rollout Silencing, where
the proportion of rollouts contributing non-zero gradients diminishes over
time. These issues lead to suboptimal gradient updates and hinder long-term
learning efficiency. To address these issues, we propose Shuffle-R1, a simple
yet principled framework that improves RL fine-tuning efficiency by dynamically
restructuring trajectory sampling and batch composition. It introduces (1)
Pairwise Trajectory Sampling, which selects high-contrast trajectories with
large advantages to improve gradient signal quality, and (2) Advantage-based
Trajectory Shuffle, which increases exposure of valuable rollouts through
informed batch reshuffling. Experiments across multiple reasoning benchmarks
show that our framework consistently outperforms strong RL baselines with
minimal overhead. These results highlight the importance of data-centric
adaptations for more efficient RL training in MLLM.

</details>


### [120] [Optimal Growth Schedules for Batch Size and Learning Rate in SGD that Reduce SFO Complexity](https://arxiv.org/abs/2508.05297)
*Hikaru Umeda,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 이 논문은 배치 크기와 학습 속도의 적절한 조정이 깊은 학습 모델의 훈련 효율성을 향상시키고 최적화를 개선할 수 있다는 점을 논의합니다.


<details>
  <summary>Details</summary>
Motivation: 깊은 학습 모델의 성장에 따라 훈련 효율성을 높이기 위해 배치 크기와 학습 속도의 스케줄링이 필요하다는 필요성에 의해 동기화되었습니다.

Method: 확률적 1차 오라클(SFO) 복잡성을 기반으로 배치 크기와 학습 속도의 최적 성장 스케줄을 이론적으로 도출하고, 이를 다양한 실험을 통해 검증하였습니다.

Result: 이론적인 통찰력과 실용적인 가이드라인을 제공하여 대규모 배치 훈련의 효율성을 높였습니다.

Conclusion: 배치 크기와 학습 속도의 조정이 훈련 효율성과 일반화를 동시에 발전시킬 수 있음을 입증하였습니다.

Abstract: The unprecedented growth of deep learning models has enabled remarkable
advances but introduced substantial computational bottlenecks. A key factor
contributing to training efficiency is batch-size and learning-rate scheduling
in stochastic gradient methods. However, naive scheduling of these
hyperparameters can degrade optimization efficiency and compromise
generalization. Motivated by recent theoretical insights, we investigated how
the batch size and learning rate should be increased during training to balance
efficiency and convergence. We analyzed this problem on the basis of stochastic
first-order oracle (SFO) complexity, defined as the expected number of gradient
evaluations needed to reach an $\epsilon$-approximate stationary point of the
empirical loss. We theoretically derived optimal growth schedules for the batch
size and learning rate that reduce SFO complexity and validated them through
extensive experiments. Our results offer both theoretical insights and
practical guidelines for scalable and efficient large-batch training in deep
learning.

</details>


### [121] [TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution](https://arxiv.org/abs/2508.05616)
*Zhikai Zhao,Chuanbo Hua,Federico Berto,Kanghoon Lee,Zihan Ma,Jiachen Li,Jinkyoo Park*

Main category: cs.LG

TL;DR: TrajEvo는 대규모 언어 모델을 활용해 인류 행동 예측을 위한 경로 예측 휴리스틱을 자동 설계하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 인간 행동 모델링, 특히 사회적 로봇과 자율 차량 내비게이션 같은 안전-critical 도메인에서의 경로 예측이 중요하다.

Method: TrajEvo는 진화 알고리즘을 사용하여 과거 경로 데이터를 바탕으로 예측 휴리스틱을 생성 및 세련화한다. 주요 혁신으로는 인구 다양성을 장려하는 크로스-제너레이션 엘리트 샘플링과 LLM이 대체 예측을 분석하고 개선할 수 있는 통계 피드백 루프가 있다.

Result: TrajEvo는 여러 실제 데이터 세트에서 기존의 휴리스틱 방법을 초월하며, 보지 못한 OOD 데이터 세트에서도 우수한 일반화 성능을 보인다.

Conclusion: TrajEvo는 자동화된 경로 예측 휴리스틱의 설계를 향한 유망한 단계로, 빠르고 설명 가능한 예측 모델 제공에 기여한다.

Abstract: Trajectory prediction is a critical task in modeling human behavior,
especially in safety-critical domains such as social robotics and autonomous
vehicle navigation. Traditional heuristics based on handcrafted rules often
lack accuracy and generalizability. Although deep learning approaches offer
improved performance, they typically suffer from high computational cost,
limited explainability, and, importantly, poor generalization to
out-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a
framework that leverages Large Language Models (LLMs) to automatically design
trajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to
generate and refine prediction heuristics from past trajectory data. We propose
two key innovations: Cross-Generation Elite Sampling to encourage population
diversity, and a Statistics Feedback Loop that enables the LLM to analyze and
improve alternative predictions. Our evaluations demonstrate that TrajEvo
outperforms existing heuristic methods across multiple real-world datasets, and
notably surpasses both heuristic and deep learning methods in generalizing to
an unseen OOD real-world dataset. TrajEvo marks a promising step toward the
automated design of fast, explainable, and generalizable trajectory prediction
heuristics. We release our source code to facilitate future research at
https://github.com/ai4co/trajevo.

</details>


### [122] [Adaptive Batch Size and Learning Rate Scheduler for Stochastic Gradient Descent Based on Minimization of Stochastic First-order Oracle Complexity](https://arxiv.org/abs/2508.05302)
*Hikaru Umeda,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 미니 배치 확률적 경량 하강법(SGD)의 수렴 행동은 배치 크기와 학습률 설정에 매우 민감하다. 이 논문에서는 임계 배치 크기를 이용한 적응형 스케줄링 전략을 도입하여 SGD의 수렴 속도를 개선하였다.


<details>
  <summary>Details</summary>
Motivation: 미니 배치 SGD의 수렴 특성을 이해하고 임계 배치 크기에 따라 SGD의 효율성을 높이기 위해 연구하였다.

Method: 임계 배치 크기에 대한 이론적 발견을 기반으로, 학습 중에 전체 그래디언트 노름의 감소를 관찰하여 배치 크기와 학습률을 조정하는 적응형 스케줄링 전략을 제안하였다.

Result: 제안된 적응형 스케줄러를 사용한 실험에서 기존 스케줄러에 비해 수렴 속도가 개선되었다.

Conclusion: 임계 배치 크기를 이용한 적응형 스케줄링이 SGD의 성능을 향상시킬 수 있음을 보였다.

Abstract: The convergence behavior of mini-batch stochastic gradient descent (SGD) is
highly sensitive to the batch size and learning rate settings. Recent
theoretical studies have identified the existence of a critical batch size that
minimizes stochastic first-order oracle (SFO) complexity, defined as the
expected number of gradient evaluations required to reach a stationary point of
the empirical loss function in a deep neural network. An adaptive scheduling
strategy is introduced to accelerate SGD that leverages theoretical findings on
the critical batch size. The batch size and learning rate are adjusted on the
basis of the observed decay in the full gradient norm during training.
Experiments using an adaptive joint scheduler based on this strategy
demonstrated improved convergence speed compared with that of existing
schedulers.

</details>


### [123] [Divide-and-Conquer for Enhancing Unlabeled Learning, Stability, and Plasticity in Semi-supervised Continual Learning](https://arxiv.org/abs/2508.05316)
*Yue Duan,Taicai Chen,Lei Qi,Yinghuan Shi*

Main category: cs.LG

TL;DR: 본 연구는 반지도 지속 학습을 위한 USP 프레임워크를 제안하며, 메모리 안정성, 학습 유연성 및 비표시 학습을 동시에 개선하여 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 반지도 지속 학습의 필요성을 인식하고, 낮은 주석 비용으로 지속적으로 등장하는 데이터를 처리하기 위해 새로운 접근 방식을 제안하려는 동기가 있습니다.

Method: USP 프레임워크는 세 가지 주요 전략으로 구성됩니다: LP를 위한 특징 벡터 예약(FSR), 비표시 학습을 위한 분할 및 정복 가상의 레이블링(DCP), 메모리 안정성을 위한 클래스 평균 기반 비표시 증류(CUD)입니다.

Result: USP는 기존 SSCL 방법들에 비해 최대 5.94% 향상된 정확도를 기록하며, 이에 대한 포괄적인 평가 결과를 제공합니다.

Conclusion: 제안된 USP 프레임워크는 반지도 지속 학습에서 효과적이며, 학습 안정성을 유지하면서도 새로운 클래스를 학습하는 데 기여합니다.

Abstract: Semi-supervised continual learning (SSCL) seeks to leverage both labeled and
unlabeled data in a sequential learning setup, aiming to reduce annotation
costs while managing continual data arrival. SSCL introduces complex
challenges, including ensuring effective unlabeled learning (UL), while
balancing memory stability (MS) and learning plasticity (LP). Previous SSCL
efforts have typically focused on isolated aspects of the three, while this
work presents USP, a divide-and-conquer framework designed to synergistically
enhance these three aspects: (1) Feature Space Reservation (FSR) strategy for
LP, which constructs reserved feature locations for future classes by shaping
old classes into an equiangular tight frame; (2) Divide-and-Conquer
Pseudo-labeling (DCP) approach for UL, which assigns reliable pseudo-labels
across both high- and low-confidence unlabeled data; and (3)
Class-mean-anchored Unlabeled Distillation (CUD) for MS, which reuses DCP's
outputs to anchor unlabeled data to stable class means for distillation to
prevent forgetting. Comprehensive evaluations show USP outperforms prior SSCL
methods, with gains up to 5.94% in the last accuracy, validating its
effectiveness. The code is available at https://github.com/NJUyued/USP4SSCL.

</details>


### [124] [Latent Preference Bandits](https://arxiv.org/abs/2508.05367)
*Newton Mwai,Emil Carlsson,Fredrik D. Johansson*

Main category: cs.LG

TL;DR: 잠재적 밴딧 알고리즘의 가정을 완화하여, 행동의 선호 순서 모델만 요구함으로써 개인화 문제의 탐색 시간을 단축하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 개인화 작업에서 학습 비용이 너무 높고, 적은 수의 결정 포인트에서 연구가 이루어져야 한다는 점.

Method: 행동의 선호 순서를 모델링하는 방식으로 잠재적 밴딧의 가정을 완화해 후행 샘플링 알고리즘을 제시.

Result: 제안된 후행 샘플링 알고리즘은 잘 정의된 보상 분포를 가진 잠재적 밴딧과 경쟁할 수 있는 성능을 보이며, 보상 척도가 다른 경우 더 좋은 성능을 발휘한다.

Conclusion: 따라서, 이 방법은 개인화된 의사결정 문제에서 더 효율적이며 유용하다.

Abstract: Bandit algorithms are guaranteed to solve diverse sequential decision-making
problems, provided that a sufficient exploration budget is available. However,
learning from scratch is often too costly for personalization tasks where a
single individual faces only a small number of decision points. Latent bandits
offer substantially reduced exploration times for such problems, given that the
joint distribution of a latent state and the rewards of actions is known and
accurate. In practice, finding such a model is non-trivial, and there may not
exist a small number of latent states that explain the responses of all
individuals. For example, patients with similar latent conditions may have the
same preference in treatments but rate their symptoms on different scales. With
this in mind, we propose relaxing the assumptions of latent bandits to require
only a model of the \emph{preference ordering} of actions in each latent state.
This allows problem instances with the same latent state to vary in their
reward distributions, as long as their preference orderings are equal. We give
a posterior-sampling algorithm for this problem and demonstrate that its
empirical performance is competitive with latent bandits that have full
knowledge of the reward distribution when this is well-specified, and
outperforms them when reward scales differ between instances with the same
latent state.

</details>


### [125] [NT-ML: Backdoor Defense via Non-target Label Training and Mutual Learning](https://arxiv.org/abs/2508.05404)
*Wenjie Huo,Katinka Wolter*

Main category: cs.LG

TL;DR: DNN이 백도어 공격에 취약하다는 것을 보이며, 저자는 NT-ML이라는 방어 메커니즘을 제안하여 모델을 복원함.


<details>
  <summary>Details</summary>
Motivation: 딥 신경망(DNN)에 대한 백도어 공격의 취약성을 해결하려고 함.

Method: 비표적 레이블 훈련과 상호 학습을 통해, 학생 모델과 교사 모델이 서로의 장점을 배워 정화된 모델을 생성함.

Result: NT-ML이 6가지 백도어 공격에 효과적으로 방어하며, 5개의 최신 방어 기술보다 뛰어난 성능을 보임.

Conclusion: NT-ML은 소량의 깨끗한 샘플로도 백도어 공격에 대한 강력한 방어 수단이 됨.

Abstract: Recent studies have shown that deep neural networks (DNNs) are vulnerable to
backdoor attacks, where a designed trigger is injected into the dataset,
causing erroneous predictions when activated. In this paper, we propose a novel
defense mechanism, Non-target label Training and Mutual Learning (NT-ML), which
can successfully restore the poisoned model under advanced backdoor attacks. NT
aims to reduce the harm of poisoned data by retraining the model with the
outputs of the standard training. At this stage, a teacher model with high
accuracy on clean data and a student model with higher confidence in correct
prediction on poisoned data are obtained. Then, the teacher and student can
learn the strengths from each other through ML to obtain a purified student
model. Extensive experiments show that NT-ML can effectively defend against 6
backdoor attacks with a small number of clean samples, and outperforms 5
state-of-the-art backdoor defenses.

</details>


### [126] [Cumulative Learning Rate Adaptation: Revisiting Path-Based Schedules for SGD and Adam](https://arxiv.org/abs/2508.05408)
*Asma Atamna,Tom Maus,Fabian Kievelitz,Tobias Glasmachers*

Main category: cs.LG

TL;DR: 이 논문은 심층 학습에서 학습률의 적응적 조정 메커니즘의 실용성을 조사하고, 2017년에 제안된 누적 경로 기반 적응 방식의 문제점을 수정하여 더 나은 결과를 도출한다.


<details>
  <summary>Details</summary>
Motivation: 심층 학습에서 학습률은 중요한 하이퍼파라미터이며, 문제에 따라 이상적인 값이 달라지고 훈련 중에 변경될 수 있다.

Method: 이 논문은 경량형 학습률 적응 메커니즘을 재검토하고, 누적 경로 기반 적응 방식을 수정하여 Adam의 업데이트 동역학을 반영한다.

Result: SGD와 Adam을 비교하고, 누적 적응의 영향을 평가하여 적응 전략의 실용적 이점을 밝혀낸다.

Conclusion: 적응적 학습률 전략이 언제 그리고 왜 실용적 이점을 제공하는지를 명확히 규명하는 것을 목표로 한다.

Abstract: The learning rate is a crucial hyperparameter in deep learning, with its
ideal value depending on the problem and potentially changing during training.
In this paper, we investigate the practical utility of adaptive learning rate
mechanisms that adjust step sizes dynamically in response to the loss
landscape. We revisit a cumulative path-based adaptation scheme proposed in
2017, which adjusts the learning rate based on the discrepancy between the
observed path length, computed as a time-discounted sum of normalized gradient
steps, and the expected length of a random walk. While the original approach
offers a compelling intuition, we show that its adaptation mechanism for Adam
is conceptually inconsistent due to the optimizer's internal preconditioning.
We propose a corrected variant that better reflects Adam's update dynamics. To
assess the practical value of online learning rate adaptation, we benchmark SGD
and Adam, with and without cumulative adaptation, and compare them to a recent
alternative method. Our results aim to clarify when and why such adaptive
strategies offer practical benefits.

</details>


### [127] [MolSnap: Snap-Fast Molecular Generation with Latent Variational Mean Flow](https://arxiv.org/abs/2508.05411)
*Md Atik Ahamed,Qiang Ye,Qiang Cheng*

Main category: cs.LG

TL;DR: 텍스트 설명에 조건화된 분자 생성의 효율성을 높이는 새로운 방법을 제시.


<details>
  <summary>Details</summary>
Motivation: 분자 생성에서 고품질, 다양성, 빠른 추론을 동시에 보장하는 것이 어려운 문제이다.

Method: Causality-Aware Transformer (CAT)와 Variational Mean Flow (VMF) 프레임워크를 통해 causal dependencies를 적용하고 Gaussian 혼합 모델로 잠재 공간을 모델링한다.

Result: 모델이 최신 기법들을 초월하여 높은 참신성(최대 74.5%), 다양성(최대 70.3%), 그리고 모든 데이터셋에서 100% 유효성을 달성했다.

Conclusion: VMF는 조건부 생성에서 단 하나의 함수 평가로 효율성을 제공하며, 확산 기반 방법들에 비해 상당한 계산 효율성을 확보한다.

Abstract: Molecular generation conditioned on textual descriptions is a fundamental
task in computational chemistry and drug discovery. Existing methods often
struggle to simultaneously ensure high-quality, diverse generation and fast
inference. In this work, we propose a novel causality-aware framework that
addresses these challenges through two key innovations. First, we introduce a
Causality-Aware Transformer (CAT) that jointly encodes molecular graph tokens
and text instructions while enforcing causal dependencies during generation.
Second, we develop a Variational Mean Flow (VMF) framework that generalizes
existing flow-based methods by modeling the latent space as a mixture of
Gaussians, enhancing expressiveness beyond unimodal priors. VMF enables
efficient one-step inference while maintaining strong generation quality and
diversity. Extensive experiments on four standard molecular benchmarks
demonstrate that our model outperforms state-of-the-art baselines, achieving
higher novelty (up to 74.5\%), diversity (up to 70.3\%), and 100\% validity
across all datasets. Moreover, VMF requires only one number of function
evaluation (NFE) during conditional generation and up to five NFEs for
unconditional generation, offering substantial computational efficiency over
diffusion-based methods.

</details>


### [128] [Echo State Networks for Bitcoin Time Series Prediction](https://arxiv.org/abs/2508.05416)
*Mansi Sharma,Enrico Sartor,Marc Cavazza,Helmut Prendinger*

Main category: cs.LG

TL;DR: 이 연구는 Echo State Networks (ESNs)를 활용하여 주식 및 암호화폐 가격 예측을 수행하며, 극심한 변동성 속에서도 효과적임을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 주식 및 암호화폐 가격 예측의 어려움은 높은 변동성과 비정상성 때문이며, 경제 변화와 시장 감정과 같은 요인에 영향을 받는다.

Method: Echo State Networks (ESNs)를 사용하여 비정상적이고 비선형적인 데이터에서 암호화폐 예측을 수행하고, Lyapunov 지수를 통해 혼돈 분석을 실시한다.

Result: ESNs 접근 방식이 기존의 기계 학습 방법들보다 유의미하게 우수하다는 결과를 도출하며, 특히 혼돈 기간 동안에도 ESNs의 강건성을 보여준다.

Conclusion: ESNs는 높은 혼돈 환경에서 Boosting 및 Naive 방법보다 더 뛰어난 성능을 발휘하여 암호화폐 예측에 효과적인 모델임을 입증한다.

Abstract: Forecasting stock and cryptocurrency prices is challenging due to high
volatility and non-stationarity, influenced by factors like economic changes
and market sentiment. Previous research shows that Echo State Networks (ESNs)
can effectively model short-term stock market movements, capturing nonlinear
patterns in dynamic data. To the best of our knowledge, this work is among the
first to explore ESNs for cryptocurrency forecasting, especially during extreme
volatility. We also conduct chaos analysis through the Lyapunov exponent in
chaotic periods and show that our approach outperforms existing machine
learning methods by a significant margin. Our findings are consistent with the
Lyapunov exponent analysis, showing that ESNs are robust during chaotic periods
and excel under high chaos compared to Boosting and Na\"ive methods.

</details>


### [129] [Negative Binomial Variational Autoencoders for Overdispersed Latent Modeling](https://arxiv.org/abs/2508.05423)
*Yixuan Zhang,Wenxin Zhang,Hua Jiang,Quyu Kong,Feng Zhou*

Main category: cs.LG

TL;DR: NegBio-VAE는 생물학적 뉴런의 스파이크 발생을 모델링하며, 음이항 분포를 통해 변동성을 보다 정확히 반영한다.


<details>
  <summary>Details</summary>
Motivation: 생물학적 뉴런의 스파이크 활동은 기존의 변분 오토인코더로 모델링하기에 너무 불규칙하고 변동성이 크다.

Method: 음이항 분포를 활용하여 스파이크 수치를 모델링하고, 새로운 ELBO 최적화 및 미분 가능 재매개화 전략을 개발한다.

Result: NegBio-VAE는 재구성 충실도의 중요한 향상을 보여주며 스파이크 활동의 초과 분산을 명시적으로 모델링하는 것의 중요성을 강조한다.

Conclusion: 스파이크와 같은 활성화에서의 과도한 분산을 명확히 모델링하는 것이 신경 표현의 정확성을 높이는 데 기여한다.

Abstract: Biological neurons communicate through spike trains, discrete, irregular
bursts of activity that exhibit variability far beyond the modeling capacity of
conventional variational autoencoders (VAEs). Recent work, such as the
Poisson-VAE, makes a biologically inspired move by modeling spike counts using
the Poisson distribution. However, they impose a rigid constraint: equal mean
and variance, which fails to reflect the true stochastic nature of neural
activity. In this work, we challenge this constraint and introduce NegBio-VAE,
a principled extension of the VAE framework that models spike counts using the
negative binomial distribution. This shift grants explicit control over
dispersion, unlocking a broader and more accurate family of neural
representations. We further develop two ELBO optimization schemes and two
differentiable reparameterization strategies tailored to the negative binomial
setting. By introducing one additional dispersion parameter, NegBio-VAE
generalizes the Poisson latent model to a negative binomial formulation.
Empirical results demonstrate this minor yet impactful change leads to
significant gains in reconstruction fidelity, highlighting the importance of
explicitly modeling overdispersion in spike-like activations.

</details>


### [130] [Federated Multi-Objective Learning with Controlled Pareto Frontiers](https://arxiv.org/abs/2508.05424)
*Jiansheng Rao,Jiayi Li,Zhizhi Gong,Soummya Kar,Haoxuan Li*

Main category: cs.LG

TL;DR: CR-FMOL은 클라이언트 공정성을 높이기 위해 새로운 선호-콘 제약을 통해 클라이언트별 파레토 최적성을 보장하는 최초의 연합 다중 목표 최적화 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습에서 주류 클라이언트에 최적화된 FedAvg의 한계를 극복하고, 소수 클라이언트에게도 공정한 서비스를 제공하기 위함이다.

Method: 선택적 제약 조건을 적용한 연합 다중 목표 학습 프레임워크로, 각 클라이언트는 집계된 태스크 손실 벡터를 서버에 전달하고, 서버는 이를 기반으로 파레토-다중 태스크 학습 하위 문제를 해결한다.

Result: CR-FMOL은 비IID 벤치마크 실험에서 클라이언트 공정성을 향상시켰고, 초기 성능은 FedAvg보다 다소 낮지만 충분한 훈련 라운드를 거치면 유사한 정확도를 기대할 수 있다.

Conclusion: CR-FMOL은 클라이언트 간의 공정성을 극대화하면서도 연합 학습의 효과를 높일 수 있는 가능성을 지닌 접근 방식이다.

Abstract: Federated learning (FL) is a widely adopted paradigm for privacy-preserving
model training, but FedAvg optimise for the majority while under-serving
minority clients. Existing methods such as federated multi-objective learning
(FMOL) attempts to import multi-objective optimisation (MOO) into FL. However,
it merely delivers task-wise Pareto-stationary points, leaving client fairness
to chance. In this paper, we introduce Conically-Regularised FMOL (CR-FMOL),
the first federated MOO framework that enforces client-wise Pareto optimality
through a novel preference-cone constraint. After local federated
multi-gradient descent averaging (FMGDA) / federated stochastic multi-gradient
descent averaging (FSMGDA) steps, each client transmits its aggregated
task-loss vector as an implicit preference; the server then solves a
cone-constrained Pareto-MTL sub-problem centred at the uniform vector,
producing a descent direction that is Pareto-stationary for every client within
its cone. Experiments on non-IID benchmarks show that CR-FMOL enhances client
fairness, and although the early-stage performance is slightly inferior to
FedAvg, it is expected to achieve comparable accuracy given sufficient training
rounds.

</details>


### [131] [Group Causal Policy Optimization for Post-Training Large Language Models](https://arxiv.org/abs/2508.05428)
*Ziyin Gu,Jingyao Wang,Ran Zuo,Chuxiong Sun,Zeen Song,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: GCPO는 GRPO를 개선하기 위해 인과 구조를 최적화에 통합하여 더 나은 예측 품질을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 특화된 도메인에서 대형 언어 모델의 후속 학습이 필요하며, 기존 방법들이 독립적인 응답 처리를 하여 의미적 상호작용을 간과하는 문제를 해결하고자 함.

Method: 인과 모델을 기반으로 응답을 인과적으로 조정하고 새로운 KL 정규화 항을 도입하여 정책을 개선하는 GCPO를 제안.

Result: GCPO는 다양한 추론 벤치마크에서 GRPO를 포함한 기존 방법들을 일관되게 초월하는 성과를 거두었다.

Conclusion: GCPO는 응답 간의 숨겨진 의존성을 고려함으로써 예측 성능을 향상시킨다.

Abstract: Recent advances in large language models (LLMs) have broadened their
applicability across diverse tasks, yet specialized domains still require
targeted post training. Among existing methods, Group Relative Policy
Optimization (GRPO) stands out for its efficiency, leveraging groupwise
relative rewards while avoiding costly value function learning. However, GRPO
treats candidate responses as independent, overlooking semantic interactions
such as complementarity and contradiction. To address this challenge, we first
introduce a Structural Causal Model (SCM) that reveals hidden dependencies
among candidate responses induced by conditioning on a final integrated output
forming a collider structure. Then, our causal analysis leads to two insights:
(1) projecting responses onto a causally informed subspace improves prediction
quality, and (2) this projection yields a better baseline than query only
conditioning. Building on these insights, we propose Group Causal Policy
Optimization (GCPO), which integrates causal structure into optimization
through two key components: a causally informed reward adjustment and a novel
KL regularization term that aligns the policy with a causally projected
reference distribution. Comprehensive experimental evaluations demonstrate that
GCPO consistently surpasses existing methods, including GRPO across multiple
reasoning benchmarks.

</details>


### [132] [Discovering Interpretable Programmatic Policies via Multimodal LLM-assisted Evolutionary Search](https://arxiv.org/abs/2508.05433)
*Qinglong Hu,Xialiang Tong,Mingxuan Yuan,Fei Liu,Zhichao Lu,Qingfu Zhang*

Main category: cs.LG

TL;DR: MLES는 해석 가능성과 성능을 동시에 달성하는 새로운 접근 방식을 제시하며, 진화적 탐색과 다중 모드 대형 언어 모델을 활용하여 안전-critical 제어 정책을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 안전-critical 작업을 위한 제어 정책 설계에서 해석 가능성과 높은 성능은 필수 목표이다. 딥 강화 학습은 성능을 향상시켰지만 해석 가능성 부족으로 신뢰를 저하시킨다.

Method: MLES는 정책 생성기으로 다중 모드 대형 언어 모델을 사용하고, 진화적 메커니즘과 결합하여 자동 정책 최적화를 수행하며, 시각적 피드백 기반의 행동 분석을 통합한다.

Result: MLES는 두 가지 제어 작업에서 Proximal Policy Optimization(PPO)와 비교해 정책 발견 능력과 효율성이 유사하게 나타났으며, 투명한 제어 논리와 추적 가능한 설계 과정을 제공한다.

Conclusion: MLES는 사전 정의된 도메인 특화 언어의 한계를 극복하고 지식 이전과 재사용을 촉진하며, 다양한 제어 작업에 걸쳐 확장 가능성을 보여준다.

Abstract: Interpretability and high performance are essential goals in designing
control policies, particularly for safety-critical tasks. Deep reinforcement
learning has greatly enhanced performance, yet its inherent lack of
interpretability often undermines trust and hinders real-world deployment. This
work addresses these dual challenges by introducing a novel approach for
programmatic policy discovery, called Multimodal Large Language Model-assisted
Evolutionary Search (MLES). MLES utilizes multimodal large language models as
policy generators, combining them with evolutionary mechanisms for automatic
policy optimization. It integrates visual feedback-driven behavior analysis
within the policy generation process to identify failure patterns and
facilitate targeted improvements, enhancing the efficiency of policy discovery
and producing adaptable, human-aligned policies. Experimental results show that
MLES achieves policy discovery capabilities and efficiency comparable to
Proximal Policy Optimization (PPO) across two control tasks, while offering
transparent control logic and traceable design processes. This paradigm
overcomes the limitations of predefined domain-specific languages, facilitates
knowledge transfer and reuse, and is scalable across various control tasks.
MLES shows promise as a leading approach for the next generation of
interpretable control policy discovery.

</details>


### [133] [Competing Risks: Impact on Risk Estimation and Algorithmic Fairness](https://arxiv.org/abs/2508.05435)
*Vincent Jeanselme,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: 생존 분석에서 경쟁 위험을 단순히 검열로 간주하는 것은 생존 추정치에 중대한 편향을 초래하며, 이는 불평등을 악화시킬 수 있다.


<details>
  <summary>Details</summary>
Motivation: 의사결정, 의료 지침, 채용 결정 및 자원 배분에 있어 정확한 사건 발생 예측이 중요하다.

Method: 경쟁 위험을 검열로 잘못 분류하는 문제를 형식화하고, 이로 인한 생존 추정치 오류를 정량화하기 위한 프레임워크를 개발했다.

Result: 심혈관 관리에 대한 실증 분석을 통해, 경쟁 위험을 무시할 경우 가장 위험한 개인에게 불균형적인 영향을 미친다는 것을 발견했다.

Conclusion: 경쟁 위험을 고려하여 생존 모델을 개발함으로써 정확성을 개선하고, 위험 평가에서의 불균형을 줄이며, 하위 결정에 더 나은 정보를 제공해야 한다.

Abstract: Accurate time-to-event prediction is integral to decision-making, informing
medical guidelines, hiring decisions, and resource allocation. Survival
analysis, the quantitative framework used to model time-to-event data, accounts
for patients who do not experience the event of interest during the study
period, known as censored patients. However, many patients experience events
that prevent the observation of the outcome of interest. These competing risks
are often treated as censoring, a practice frequently overlooked due to a
limited understanding of its consequences. Our work theoretically demonstrates
why treating competing risks as censoring introduces substantial bias in
survival estimates, leading to systematic overestimation of risk and,
critically, amplifying disparities. First, we formalize the problem of
misclassifying competing risks as censoring and quantify the resulting error in
survival estimates. Specifically, we develop a framework to estimate this error
and demonstrate the associated implications for predictive performance and
algorithmic fairness. Furthermore, we examine how differing risk profiles
across demographic groups lead to group-specific errors, potentially
exacerbating existing disparities. Our findings, supported by an empirical
analysis of cardiovascular management, demonstrate that ignoring competing
risks disproportionately impacts the individuals most at risk of these events,
potentially accentuating inequity. By quantifying the error and highlighting
the fairness implications of the common practice of considering competing risks
as censoring, our work provides a critical insight into the development of
survival models: practitioners must account for competing risks to improve
accuracy, reduce disparities in risk assessment, and better inform downstream
decisions.

</details>


### [134] [Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](https://arxiv.org/abs/2508.05469)
*Zachary Robertson,Sanmi Koyejo*

Main category: cs.LG

TL;DR: AI 시스템의 평가 메커니즘을 개발하였으며, 게임 저항성과 출력 품질 간의 관계를 활용하여 진정한 기준 없이도 AI 평가가 가능함을 입증하였다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템 평가의 객관성을 확보하고, 기존 방법의 한계를 극복하기 위해 게임 저항성을 활용한 새로운 평가 메커니즘 개발.

Method: f-상호정보 측정을 통해 AI 시스템의 정보를 평가하며, 다양한 도메인에서 실험을 통해 이론을 검증.

Result: 10개 도메인에서 정보 이론적 메커니즘이 정직한 대리인과 전략적 대리인을 완벽하게 구별하며, 기존 방법보다 10-100배 더 강력한 내성을 보임.

Conclusion: 압축 비율에 따라 성능이 역-U 곡선을 따르며, 10:1의 비율에서 최적의 정보 다양성을 나타내는 응답을 제공함으로써 이러한 접근이 가장 효과적일 때를 설명한다.

Abstract: We develop mechanisms for evaluating AI systems without ground truth by
exploiting a connection between gaming resistance and output quality. The data
processing inequality ensures post-hoc attempts to game a metric degrades both
information content and task performance. We prove that f-mutual information
measures are the unique gaming resistant mechanisms under natural conditions,
with the overseer acting as an agent. While Shannon mutual information faces
exponential sample complexity, bounded measures like total variation distance
remain tractable. Empirically, across ten domains from translation to peer
review, all information-theoretic mechanisms achieve perfect discrimination (d
> 0.5) between faithful and strategic agents. In contrast, LLM judges exhibit
systematic evaluation inversion, preferring fabricated content over accurate
summaries. Our mechanisms show 10-100x better robustness to adversarial
manipulation than current practices. We also find performance follows an
inverted-U curve with compression ratio, peaking at 10:1 where agent responses
exhibit optimal information diversity (3 effective dimensions), giving a
bias-variance perspective on when our approach is expected to be most
effective.

</details>


### [135] [Prediction of Survival Outcomes under Clinical Presence Shift: A Joint Neural Network Architecture](https://arxiv.org/abs/2508.05472)
*Vincent Jeanselme,Glen Martin,Matthew Sperrin,Niels Peek,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: 이 논문은 전자 건강 기록에서 임상 존재를 함께 모델링하여 예측 모델의 성능과 이동 가능성을 향상시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전자 건강 기록에서 환자와 의료 시스템 간의 상호작용은 관찰된 결과에 영향을 미치는데, 임상 존재를 간과하는 것이 모델의 성능과 이동 가능성을 제한한다.

Method: 다중 작업 순환 신경망을 사용하여 생존 결과와 함께 관찰 간 시간 및 결측 과정들을 병렬로 모델링한다.

Result: MIMIC-III 데이터셋을 활용한 실제 사망 예측 작업에서 제안된 전략이 최첨단 예측 모델보다 성능 및 이동 가능성을 개선함을 보여준다.

Conclusion: 임상 존재를 활용하면 성능을 개선하고 더 이동 가능한 임상 예측 모델을 생성할 수 있음을 강조한다.

Abstract: Electronic health records arise from the complex interaction between patients
and the healthcare system. This observation process of interactions, referred
to as clinical presence, often impacts observed outcomes. When using electronic
health records to develop clinical prediction models, it is standard practice
to overlook clinical presence, impacting performance and limiting the
transportability of models when this interaction evolves. We propose a
multi-task recurrent neural network that jointly models the inter-observation
time and the missingness processes characterising this interaction in parallel
to the survival outcome of interest. Our work formalises the concept of
clinical presence shift when the prediction model is deployed in new settings
(e.g. different hospitals, regions or countries), and we theoretically justify
why the proposed joint modelling can improve transportability under changes in
clinical presence. We demonstrate, in a real-world mortality prediction task in
the MIMIC-III dataset, how the proposed strategy improves performance and
transportability compared to state-of-the-art prediction models that do not
incorporate the observation process. These results emphasise the importance of
leveraging clinical presence to improve performance and create more
transportable clinical prediction models.

</details>


### [136] [Parameter-free entropy-regularized multi-view clustering with hierarchical feature selection](https://arxiv.org/abs/2508.05504)
*Kristina P. Sinaga,Sara Colantonio,Miin-Shen Yang*

Main category: cs.LG

TL;DR: 이 논문은 다중 시점 클러스터링의 문제를 해결하기 위한 두 가지 알고리즘을 제안하며, 데이터의 고차원 특성과 관련 없는 정보를 처리하는 데 강점을 가진다.


<details>
  <summary>Details</summary>
Motivation: 고차원 데이터에서 패턴을 자동으로 발견하는 것은 도전 과제를 포함하며, 기존 접근 방식은 수동 매개변수 조정과 효과적인 시점 통합 메커니즘의 결여로 인해 한계를 보인다.

Method: AMVFCM-U와 AAMVFCM-U라는 두 가지 알고리즘을 도입하며, 매개변수 없는 통합 프레임워크를 제공하여 엔트로피 정규화 항을 사용해 적응적인 시점 합의를 이루도록 한다.

Result: 다양한 5가지 벤치마크에서 15개의 최신 방법보다 우수한 성능을 보였으며, AAMVFCM-U는 최대 97%의 계산 효율성을 달성하고, 원래 크기의 0.45%로 차원을 줄이면서 최적의 패턴 발견을 위한 중요 시점 조합을 자동으로 식별한다.

Conclusion: 제안한 방법은 다중 시점 클러스터링 분야에서 크고 다양한 데이터 세트를 효과적으로 처리할 수 있는 가능성을 보여준다.

Abstract: Multi-view clustering faces critical challenges in automatically discovering
patterns across heterogeneous data while managing high-dimensional features and
eliminating irrelevant information. Traditional approaches suffer from manual
parameter tuning and lack principled cross-view integration mechanisms. This
work introduces two complementary algorithms: AMVFCM-U and AAMVFCM-U, providing
a unified parameter-free framework. Our approach replaces fuzzification
parameters with entropy regularization terms that enforce adaptive cross-view
consensus. The core innovation employs signal-to-noise ratio based
regularization ($\delta_j^h = \frac{\bar{x}_j^h}{(\sigma_j^h)^2}$) for
principled feature weighting with convergence guarantees, coupled with
dual-level entropy terms that automatically balance view and feature
contributions. AAMVFCM-U extends this with hierarchical dimensionality
reduction operating at feature and view levels through adaptive thresholding
($\theta^{h^{(t)}} = \frac{d_h^{(t)}}{n}$). Evaluation across five diverse
benchmarks demonstrates superiority over 15 state-of-the-art methods. AAMVFCM-U
achieves up to 97% computational efficiency gains, reduces dimensionality to
0.45% of original size, and automatically identifies critical view combinations
for optimal pattern discovery.

</details>


### [137] [X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment](https://arxiv.org/abs/2508.05568)
*Qinghua Yao,Xiangrui Xu,Zhize Li*

Main category: cs.LG

TL;DR: X-VFL은 수직 연합 학습의 새로운 프레임워크로, 부분적으로 누락된 특성과 비정렬 데이터 샘플에 대한 문제를 해결하며, 각 클라이언트에서 독립적인 추론을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 기존 VFL은 모든 클라이언트 간에 동일하게 정렬된 데이터 샘플을 요구하고, 각 클라이언트의 독립적인 추론을 지원하지 않는다.

Method: X-VFL은 XCom과 DS-Align 두 가지 모듈을 설계하여, non-aligned 데이터 샘플의 누락된 특성을 보완하고, 모든 클라이언트 간의 특성을 정렬하여 독립적인 추론을 가능하게 한다.

Result: X-VFL은 CIFAR-10 데이터셋에서 15% 향상, MIMIC-III 데이터셋에서 43%의 정확도 향상률을 기록함으로써 기존 방법들보다 뛰어난 성능을 보였다.

Conclusion: X-VFL은 부분적으로 누락된 특성과 독립적인 추론을 요하는 상황에서 실용적인 효과성과 우수성을 입증한다.

Abstract: Vertical Federated Learning (VFL) enables collaborative learning by
integrating disjoint feature subsets from multiple clients/parties. However,
VFL typically faces two key challenges: i) the requirement for perfectly
aligned data samples across all clients (missing features are not allowed); ii)
the requirement for joint collaborative inference/prediction involving all
clients (it does not support locally independent inference on a single client).
To address these challenges, we propose X-VFL, a new VFL framework designed to
deal with the non-aligned data samples with (partially) missing features and to
support locally independent inference of new data samples for each client. In
particular, we design two novel modules in X-VFL: Cross Completion (XCom) and
Decision Subspace Alignment (DS-Align). XCom can complete/reconstruct missing
features for non-aligned data samples by leveraging information from other
clients. DS-Align aligns local features with completed and global features
across all clients within the decision subspace, thus enabling locally
independent inference at each client. Moreover, we provide convergence theorems
for different algorithms used in training X-VFL, showing an $O(1/\sqrt{T})$
convergence rate for SGD-type algorithms and an $O(1/T)$ rate for PAGE-type
algorithms, where $T$ denotes the number of training update steps. Extensive
experiments on real-world datasets demonstrate that X-VFL significantly
outperforms existing methods, e.g., achieving a 15% improvement in accuracy on
the image CIFAR-10 dataset and a 43% improvement on the medical MIMIC-III
dataset. These results validate the practical effectiveness and superiority of
X-VFL, particularly in scenarios involving partially missing features and
locally independent inference.

</details>


### [138] [Fairy$\pm i$: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$](https://arxiv.org/abs/2508.05571)
*Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang*

Main category: cs.LG

TL;DR: 새로운 2비트 양자화 프레임워크인 Fairy±i를 통해 LLM의 성능 한계를 넘어서는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 양자화 인식 훈련(QAT) 연구는 풀-정밀 모델에서의 양자화 오류 최소화에 초점을 맞추고 있으며, 성능 한계를 초과하는 방법이 없다.

Method: Fairy±i는 복소수 LLM을 위한 첫 번째 2비트 양자화 프레임워크로, 복소수 영역의 표현적 장점을 활용해 풀-정밀 정확도를 향상시킨다.

Result: Fairy±i는 기존의 2비트 양자화 접근 방식의 성능 한계를 초과하여 낮은 비트 제약 하에서도 우수한 PPL과 다운스트림 작업 성능을 보여준다.

Conclusion: 이 연구는 매우 낮은 비트 제약 하에서도 높은 정확도의 실용적 LLM을 구축하는 새로운 방향을 열어준다.

Abstract: Quantization-Aware Training (QAT) integrates quantization into the training
loop, enabling LLMs to learn robust low-bit representations, and is widely
recognized as one of the most promising research directions. All current QAT
research focuses on minimizing quantization error on full-precision models,
where the full-precision accuracy acts as an upper bound (accuracy ceiling). No
existing method has even attempted to surpass this ceiling. To break this
ceiling, we propose a new paradigm: raising the ceiling (full-precision model),
and then still quantizing it efficiently into 2 bits. We propose Fairy$\pm i$,
the first 2-bit quantization framework for complex-valued LLMs. Specifically,
our method leverages the representational advantages of the complex domain to
boost full-precision accuracy. We map weights to the fourth roots of unity
$\{\pm1, \pm i\}$, forming a perfectly symmetric and information-theoretically
optimal 2-bit representation. Importantly, each quantized weight has either a
zero real or imaginary part, enabling multiplication-free inference using only
additions and element swaps. Experimental results show that Fairy$\pm i$
outperforms the ceiling of existing 2-bit quantization approaches in terms of
both PPL and downstream tasks, while maintaining strict storage and compute
efficiency. This work opens a new direction for building highly accurate and
practical LLMs under extremely low-bit constraints.

</details>


### [139] [Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge Graph Embedding Models](https://arxiv.org/abs/2508.05587)
*Claudia d'Amato,Ivan Diliso,Nicola Fanizzi,Zafar Saeed*

Main category: cs.LG

TL;DR: 이 논문은 지식 그래프의 임베딩 모델에서 음성 샘플 생성의 필요성을 해결하기 위해 PyKEEN 프레임워크에 여러 고급 음성 샘플러를 통합하는 확장을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 음성 샘플링 전략이 성능에 미치는 영향을 해결하기 위한 필요성이 존재합니다.

Method: PyKEEN 프레임워크에 여러 정적 및 동적 손상 전략을 포함한 고급 음성 샘플러의 모듈식 아키텍처를 통합하여 의미 있는 음성 샘플을 생성합니다.

Result: 개발된 확장 기능이 관계 예측 작업에서 다양한 임베딩 방법의 성능에 긍정적인 영향을 미친다는 것을 입증하는 포괄적인 실증 연구를 진행했습니다.

Conclusion: 이 확장은 PyKEEN을 향상시킬 뿐 아니라, 임베딩 방법 개발 및 사용자 맞춤화를 용이하게 합니다.

Abstract: Embedding methods have become popular due to their scalability on link
prediction and/or triple classification tasks on Knowledge Graphs. Embedding
models are trained relying on both positive and negative samples of triples.
However, in the absence of negative assertions, these must be usually
artificially generated using various negative sampling strategies, ranging from
random corruption to more sophisticated techniques which have an impact on the
overall performance. Most of the popular libraries for knowledge graph
embedding, support only basic such strategies and lack advanced solutions. To
address this gap, we deliver an extension for the popular KGE framework PyKEEN
that integrates a suite of several advanced negative samplers (including both
static and dynamic corruption strategies), within a consistent modular
architecture, to generate meaningful negative samples, while remaining
compatible with existing PyKEEN -based workflows and pipelines. The developed
extension not only enhancesPyKEEN itself but also allows for easier and
comprehensive development of embedding methods and/or for their customization.
As a proof of concept, we present a comprehensive empirical study of the
developed extensions and their impact on the performance (link prediction
tasks) of different embedding methods, which also provides useful insights for
the design of more effective strategies

</details>


### [140] [On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification](https://arxiv.org/abs/2508.05629)
*Yongliang Wu,Yizhou Zhou,Zhou Ziheng,Yingzhe Peng,Xinyu Ye,Xinting Hu,Wenbo Zhu,Lu Qi,Ming-Hsuan Yang,Xu Yang*

Main category: cs.LG

TL;DR: 이 논문은 Supervised Fine-Tuning(SFT)의 개선을 통해 LLM의 일반화 성능을 향상시키는 방법인 Dynamic Fine-Tuning(DFT)을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 SFT는 강화 학습(RL)과 비교하여 제한된 일반화 능력을 가진다.

Method: DFT는 각 토큰의 목표 함수의 확률로 동적으로 재조정하여 그래디언트 업데이트를 안정화시킨다.

Result: DFT는 여러 도전적인 벤치마크와 기반 모델에서 표준 SFT를 능가한다.

Conclusion: 이 연구는 이론적 통찰과 실용적 솔루션을 연결하여 SFT 성능을 크게 향상시킨다.

Abstract: We present a simple yet theoretically motivated improvement to Supervised
Fine-Tuning (SFT) for the Large Language Model (LLM), addressing its limited
generalization compared to reinforcement learning (RL). Through mathematical
analysis, we reveal that standard SFT gradients implicitly encode a problematic
reward structure that may severely restrict the generalization capabilities of
model. To rectify this, we propose Dynamic Fine-Tuning (DFT), stabilizing
gradient updates for each token by dynamically rescaling the objective function
with the probability of this token. Remarkably, this single-line code change
significantly outperforms standard SFT across multiple challenging benchmarks
and base models, demonstrating greatly improved generalization. Additionally,
our approach shows competitive results in offline RL settings, offering an
effective yet simpler alternative. This work bridges theoretical insight and
practical solutions, substantially advancing SFT performance. The code will be
available at https://github.com/yongliang-wu/DFT.

</details>
