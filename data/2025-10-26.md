<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]
- [cs.LG](#cs.LG) [Total: 17]
- [cs.CR](#cs.CR) [Total: 6]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory](https://arxiv.org/abs/2510.19838)
*Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury*

Main category: cs.AI

TL;DR: Branch-and-Browse는 LLM 기반 웹 에이전트를 위한 구체적이며 효율적인 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 추론 깊이와 효율성에 한계가 있으며, 목표 지향 작업을 수행하기 위한 실용적인 방법이 필요하다.

Method: Branch-and-Browse는 구조화된 추론-행동, 맥락적 기억, 효율적 실행을 통합한 웹 에이전트 프레임워크이다.

Result: WebArena 벤치마크에서 Branch-and-Browse는 35.8%의 작업 성공률을 달성하고 최신 방법들에 비해 실행 시간을 최대 40.4% 단축시켰다.

Conclusion: Branch-and-Browse는 LLM 기반 웹 에이전트를 위한 신뢰할 수 있고 효율적인 프레임워크로 입증되었다.

Abstract: Autonomous web agents powered by large language models (LLMs) show strong
potential for performing goal-oriented tasks such as information retrieval,
report generation, and online transactions. These agents mark a key step toward
practical embodied reasoning in open web environments. However, existing
approaches remain limited in reasoning depth and efficiency: vanilla linear
methods fail at multi-step reasoning and lack effective backtracking, while
other search strategies are coarse-grained and computationally costly. We
introduce Branch-and-Browse, a fine-grained web agent framework that unifies
structured reasoning-acting, contextual memory, and efficient execution. It (i)
employs explicit subtask management with tree-structured exploration for
controllable multi-branch reasoning, (ii) bootstraps exploration through
efficient web state replay with background reasoning, and (iii) leverages a
page action memory to share explored actions within and across sessions. On the
WebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\%
and reduces execution time by up to 40.4\% relative to state-of-the-art
methods. These results demonstrate that Branch-and-Browse is a reliable and
efficient framework for LLM-based web agents.

</details>


### [2] [Surfer 2: The Next Generation of Cross-Platform Computer Use Agents](https://arxiv.org/abs/2510.19949)
*Mathieu Andreux,Märt Bakler,Yanael Barbier,Hamza Ben Chekroun,Emilien Biré,Antoine Bonnet,Riaz Bordie,Nathan Bout,Matthias Brunel,Aleix Cambray,Pierre-Louis Cedoz,Antoine Chassang,Gautier Cloix,Ethan Connelly,Alexandra Constantinou,Ramzi De Coster,Hubert de la Jonquiere,Aurélien Delfosse,Maxime Delpit,Alexis Deprez,Augustin Derupti,Mathieu Diaz,Shannon D'Souza,Julie Dujardin,Abai Edmund,Michael Eickenberg,Armand Fatalot,Wissem Felissi,Isaac Herring,Xavier Koegler,Erwan Le Jumeau de Kergaradec,Aurélien Lac,Maxime Langevin,Corentin Lauverjat,Antonio Loison,Avshalom Manevich,Axel Moyal,Axel Nguyen Kerbel,Marinela Parovic,Julien Revelle,Guillaume Richard,Mats Richter,Ronan Riochet,María Santos,Romain Savidan,Laurent Sifre,Maxime Theillard,Marc Thibault,Ivan Valentini,Tony Wu,Laura Yie,Kai Yuan,Jevgenij Zubovskij*

Main category: cs.AI

TL;DR: Surfer 2는 시각적 관찰만으로 작동하는 통합 아키텍처로, 웹, 데스크탑, 모바일 환경에서 최첨단 성능을 발휘한다.


<details>
  <summary>Details</summary>
Motivation: 서로 다른 플랫폼 간의 배포 제한을 해결하기 위해, 범용 광고 에이전트를 구축하는 것은 여전히 도전 과제로 남아 있다.

Method: Surfer 2는 계층적 맥락 관리, 분리된 계획 및 실행, 적응형 복구 기능을 갖춘 자기 검증을 통합하여 긴 작업 시간에 걸쳐 안정적인 운영을 가능하게 한다.

Result: Surfer 2는 WebVoyager에서 97.1%, WebArena에서 69.6%, OSWorld에서 60.1%, AndroidWorld에서 87.1%의 정확도를 달성하며, 이전 시스템을 모두 초월하였다.

Conclusion: 이 연구는 시스템의 체계적인 조정이 기본 모델의 능력을 증대시키고 시각적 상호작용만으로 범용 컴퓨터 제어를 가능하게 함을 입증하며, 다음 세대 비전 언어 모델의 필요성을 강조한다.

Abstract: Building agents that generalize across web, desktop, and mobile environments
remains an open challenge, as prior systems rely on environment-specific
interfaces that limit cross-platform deployment. We introduce Surfer 2, a
unified architecture operating purely from visual observations that achieves
state-of-the-art performance across all three environments. Surfer 2 integrates
hierarchical context management, decoupled planning and execution, and
self-verification with adaptive recovery, enabling reliable operation over long
task horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on
WebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior
systems without task-specific fine-tuning. With multiple attempts, Surfer 2
exceeds human performance on all benchmarks. These results demonstrate that
systematic orchestration amplifies foundation model capabilities and enables
general-purpose computer control through visual interaction alone, while
calling for a next-generation vision language model to achieve Pareto-optimal
cost-efficiency.

</details>


### [3] [AI PB: A Grounded Generative Agent for Personalized Investment Insights](https://arxiv.org/abs/2510.20099)
*Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh*

Main category: cs.AI

TL;DR: AI PB는 실제 소매 금융에 배치된 생성 에이전트로, 사용자 맞춤형 투자 통찰력을 능동적으로 생성한다.


<details>
  <summary>Details</summary>
Motivation: AI PB는 기존의 수동적인 챗봇과 달리 사용자 맞춤형 투자 통찰력을 능동적으로 생성하여 더 나은 금융 지원을 제공하고자 한다.

Method: 이 시스템은 데이터 민감성에 기반하여 내부 및 외부 LLM 간에 배선을 결정적으로 라우팅하는 구성 요소 기반의 오케스트레이션 레이어, OpenSearch 및 금융 도메인 임베딩 모델을 활용한 하이브리드 검색 파이프라인, 규칙 휴리스틱, 순차적 행동 모델링 및 맥락적 밴딧을 결합한 다단계 추천 메커니즘을 포함한다.

Result: AI PB는 한국의 금융 규제 하에서 완전 온프레미스 환경에서 운영되며, Docker Swarm 및 24개의 NVIDIA H100 GPU를 통해 성능을 발휘한다.

Conclusion: 명백한 라우팅과 계층형 안전성을 갖춘 기반 생성 방식이 고위험 금융 분야에서 신뢰할 수 있는 AI 통찰력을 제공할 수 있음을 입증하였다.

Abstract: We present AI PB, a production-scale generative agent deployed in real retail
finance. Unlike reactive chatbots that answer queries passively, AI PB
proactively generates grounded, compliant, and user-specific investment
insights. It integrates (i) a component-based orchestration layer that
deterministically routes between internal and external LLMs based on data
sensitivity, (ii) a hybrid retrieval pipeline using OpenSearch and the
finance-domain embedding model, and (iii) a multi-stage recommendation
mechanism combining rule heuristics, sequential behavioral modeling, and
contextual bandits. Operating fully on-premises under Korean financial
regulations, the system employs Docker Swarm and vLLM across 24 X NVIDIA H100
GPUs. Through human QA and system metrics, we demonstrate that grounded
generation with explicit routing and layered safety can deliver trustworthy AI
insights in high-stakes finance.

</details>


### [4] [Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions](https://arxiv.org/abs/2510.20102)
*Gyuyeon Na,Minjung Park,Hyeonjeong Cha,Sangmi Chai*

Main category: cs.AI

TL;DR: HCLA는 디지털 자산 거래에서 이상 탐지를 위한 인간 중심의 다중 에이전트 시스템으로, 비전문가가 자연어로 질문하고 구조화된 분석을 검사하며 상황에 맞는 이론을 얻을 수 있도록 합니다.


<details>
  <summary>Details</summary>
Motivation: 디지털 자산 거래에서의 이상 탐지는 중요한 도전 과제로, 비전문가도 이해할 수 있는 방식으로 결과를 전달할 필요가 있습니다.

Method: HCLA는 파싱, 탐지 및 설명 역할을 대화형 작업 흐름으로 연결하며, 사용자의 의도를 고전적인 탐지기에 맞는 스키마로 변환하여 내러티브 설명을 반환합니다.

Result: 기반 탐지기는 강력한 정확성을 달성했으며, HCLA는 해석 가능성과 대화형 개선을 추가합니다.

Conclusion: 인간-루프 디자인이 금융 포렌식의 투명성과 신뢰성을 개선하는 방법을 논의합니다.

Abstract: We present HCLA, a human-centered multi-agent system for anomaly detection in
digital asset transactions. The system links three roles: Parsing, Detection,
and Explanation, into a conversational workflow that lets non-experts ask
questions in natural language, inspect structured analytics, and obtain
context-aware rationales. Implemented with an open-source web UI, HCLA
translates user intents into a schema for a classical detector (XGBoost in our
prototype) and returns narrative explanations grounded in the underlying
features. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the
baseline detector reaches strong accuracy, while HCLA adds interpretability and
interactive refinement. We describe the architecture, interaction loop,
dataset, evaluation protocol, and limitations, and discuss how a
human-in-the-loop design improves transparency and trust in financial
forensics.

</details>


### [5] [The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI](https://arxiv.org/abs/2510.20190)
*Marcelo Maciel Amaral,Raymond Aschheim*

Main category: cs.AI

TL;DR: 이 논문에서는 대규모 언어 모델(LLMs)의 고정화 단계에 대한 가설을 제시하고, 인공지능 일반화(AGI)로의 발전 과정에서 목표 구조와 내부 표현이 안정적으로 유지되는 과정을 설명합니다.


<details>
  <summary>Details</summary>
Motivation: AGI로의 발전 과정에서 인간 개발에 비유하여 고정화 단계를 제안합니다.

Method: 고정화 단계를 공식화하고, 학습 역학에서 알려진 현상과 연결 지으며, 시작 감지를 위한 운영 메트릭을 제안합니다.

Result: 실험적으로 행동 고정화가 빠르고 비선형적임을 보여주며, 일반 능력에 대한 부작용은 단일하지 않음을 드러냅니다.

Conclusion: 고정화는 AGI 수준의 신뢰성을 위한 전제 조건이며, 안전성을 위한 중요한 제어 포인트라고 주장합니다.

Abstract: Large language models (LLMs) remain broadly open and highly steerable: they
imitate at scale, accept arbitrary system prompts, and readily adopt multiple
personae. By analogy to human development, we hypothesize that progress toward
artificial general intelligence (AGI) involves a lock-in phase: a transition
from open imitation to identity consolidation, in which goal structures,
refusals, preferences, and internal representations become comparatively stable
and resistant to external steering. We formalize this phase, link it to known
phenomena in learning dynamics, and propose operational metrics for onset
detection. Experimentally, we demonstrate that while the behavioral
consolidation is rapid and non-linear, its side-effects on general capabilities
are not monolithic. Our results reveal a spectrum of outcomes--from performance
trade-offs in small models, through largely cost-free adoption in mid-scale
models, to transient instabilities in large, quantized models. We argue that
such consolidation is a prerequisite for AGI-level reliability and also a
critical control point for safety: identities can be deliberately engineered
for reliability, yet may also emerge spontaneously during scaling, potentially
hardening unpredictable goals and behaviors.

</details>


### [6] [Merge and Conquer: Evolutionarily Optimizing AI for 2048](https://arxiv.org/abs/2510.20205)
*Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum*

Main category: cs.AI

TL;DR: 인공지능을 동적인 환경에 최적화하는 것은 기계 학습 연구에서 중요한 도전 과제이다. 이 연구에서는 2048 게임을 해결하기 위한 진화적 훈련 방법을 탐구하였고, 단일 에이전트 시스템이 더 나은 성과를 보임을 보여준다.


<details>
  <summary>Details</summary>
Motivation: AI를 동적인 환경에 최적화하는 문제는 기계 학습 연구에서 기본적인 도전 과제로 남아 있다.

Method: 2048 게임을 해결하기 위해 두 가지 시스템을 구현하였다: 사고자 에이전트와 실행자 에이전트로 구성된 두 에이전트 메타 프롬프팅 시스템과 제한된 몬테카를로 트리 검색을 위한 가치 함수를 정제하는 단일 에이전트 시스템.

Result: 단일 에이전트 시스템은 주기당 평균 473.2점의 개선을 이루었고, 훈련 주기 전반에 걸쳐 명확한 상승 추세(상관관계 $ho$=0.607)를 보였다.

Conclusion: 단일 에이전트 시스템은 진화적 정제 기법의 잠재력을 입증하였으나, 두 에이전트 시스템은 메타 프롬프팅의 한계를 강조하였다.

Abstract: Optimizing artificial intelligence (AI) for dynamic environments remains a
fundamental challenge in machine learning research. In this paper, we examine
evolutionary training methods for optimizing AI to solve the game 2048, a 2D
sliding puzzle. 2048, with its mix of strategic gameplay and stochastic
elements, presents an ideal playground for studying decision-making, long-term
planning, and dynamic adaptation. We implemented two distinct systems: a
two-agent metaprompting system where a "thinker" large language model (LLM)
agent refines gameplay strategies for an "executor" LLM agent, and a
single-agent system based on refining a value function for a limited Monte
Carlo Tree Search. We also experimented with rollback features to avoid
performance degradation. Our results demonstrate the potential of evolutionary
refinement techniques in improving AI performance in non-deterministic
environments. The single-agent system achieved substantial improvements, with
an average increase of 473.2 points per cycle, and with clear upward trends
(correlation $\rho$=0.607) across training cycles. The LLM's understanding of
the game grew as well, shown in its development of increasingly advanced
strategies. Conversely, the two-agent system did not garner much improvement,
highlighting the inherent limits of meta-prompting.

</details>


### [7] [Using Large Language Models for Abstraction of Planning Domains - Extended Version](https://arxiv.org/abs/2510.20258)
*Bita Banihashemi,Megh Patel,Yves Lespérance*

Main category: cs.AI

TL;DR: 이 논문에서는 주어진 목적에 맞는 동적 도메인의 추상화를 생성하는 도전 과제를 다루며, 이를 위해 PDDL로 에이전트의 구체적인 행동을 모델링하고, 자연어로 명시된 추상화 목표를 이용하여 대형 언어 모델(LLM)을 활용한 맥락 내 학습을 조사한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트의 계획, 추론 및 효과적인 설명 제공 능력에 영향을 미치는 추상화 선택의 중요성을 강조하기 위해.

Method: PDDL로 에이전트의 구체적 행동을 모델링하고, 자연어로 명시된 추상화 목표에 따라 LLM을 활용한 추상 PDDL 도메인 및 문제 인스턴스 생성을 수행한다.

Result: 새로운 벤치마크 예제가 LLM이 훈련된 데이터에 포함되지 않은 상태에서, GPT-4o가 단순한 환경에서 유용한 계획 도메인 추상화를 합성할 수 있음을 보여준다.

Conclusion: GPT-4o는 행동을 추상화하는 데 더 능숙하지만 관련된 유동성에 대한 추상화는 덜 효과적이다.

Abstract: Generating an abstraction of a dynamic domain that aligns with a given
purpose remains a significant challenge given that the choice of such an
abstraction can impact an agent's ability to plan, reason, and provide
explanations effectively. We model the agent's concrete behaviors in PDDL and
investigate the use of in-context learning with large language models (LLMs)
for the generation of abstract PDDL domains and problem instances, given an
abstraction objective specified in natural language. The benchmark examples we
use are new and have not been part of the data any LLMs have been trained on.
We consider three categories of abstractions: abstraction of choice of
alternative concrete actions, abstraction of sequences of concrete actions, and
abstraction of action/predicate parameters, as well as combinations of these.
The generated abstract PDDL domains and problem instances are then checked by
symbolic validation tools as well as human experts. Our experiments show that
GPT-4o can generally synthesize useful planning domain abstractions in simple
settings, although it is better at abstracting over actions than over the
associated fluents.

</details>


### [8] [Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation](https://arxiv.org/abs/2510.20310)
*Mingliang Zhai,Hansheng Liang,Xiaomeng Fan,Zhi Gao,Chuanhao Li,Che Sun,Xu Bin,Yuwei Wu,Yunde Jia*

Main category: cs.AI

TL;DR: ToolEQA는 외부 도구와 다단계 추론을 통합하여 3D 환경에서 질문에 대한 보다 정확한 답변을 제공하는 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 Embodied Question Answering 방법들은 명시적인 사고나 계획 없이 환경을 탐색하도록 제한되어 있다.

Method: ToolEQA는 외부 도구와 다단계 추론을 결합하여 다음 단계의 추론에서 더 나은 탐색 방향을 유도한다.

Result: ToolEQA는 EQA-RT 데이터셋에서 최첨단 성능을 나타내며 성공률을 9.2~20.2% 향상시킨다.

Conclusion: ToolEQA는 HM-EQA, OpenEQA 및 EXPRESS-Bench 데이터셋에서도 최첨단 성능을 달성하여 일반성을 보여준다.

Abstract: Embodied Question Answering (EQA) requires agents to explore 3D environments
to obtain observations and answer questions related to the scene. Existing
methods leverage VLMs to directly explore the environment and answer questions
without explicit thinking or planning, which limits their reasoning ability and
results in excessive or inefficient exploration as well as ineffective
responses. In this paper, we introduce ToolEQA, an agent that integrates
external tools with multi-step reasoning, where external tools can provide more
useful information for completing the task, helping the model derive better
exploration directions in the next step of reasoning and thus obtaining
additional effective information. This enables ToolEQA to generate more
accurate responses with a shorter exploration distance. To enhance the model's
ability for tool-usage and multi-step reasoning, we further design a novel EQA
data generation pipeline that automatically constructs large-scale EQA tasks
with reasoning trajectories and corresponding answers. Based on the pipeline,
we collect the EQA-RT dataset that contains about 18K tasks, divided into a
training set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping
with the training set) and EQA-RT-Unseen (novel scenes). Experiments on
EQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by
9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot
ToolEQA by 10% in success rate. In addition, ToolEQA also achieves
state-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench
datasets, demonstrating its generality. Our homepage see
https://tooleqa.github.io.

</details>


### [9] [Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems](https://arxiv.org/abs/2510.20332)
*Anna Arias-Duart,Maria Eugenia Cardello,Atia Cortés*

Main category: cs.AI

TL;DR: 인공지능(AI)은 의료 분야 변화를 위한 큰 잠재력을 지니고 있지만, 임상 실무에의 통합은 제한적이다. 이 논문은 데이터 수집의 편향성을 감지하기 위한 AI4HealthyAging 프로젝트의 통찰을 바탕으로 여러 유형의 편향을 식별하고, 공정성 및 신뢰성을 개선하기 위한 권고를 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI 솔루션의 임상 실무 통합은 제한적이며, 주요 장벽은 편향된 데이터 수집으로 인한 훈련 데이터의 질과 공정성이다.

Method: AI4HealthyAging 프로젝트의 통찰을 바탕으로 다양한 사용 사례에서 편향을 감지하고 여러 유형의 편향을 식별한다.

Result: 역사적, 표현, 측정 편향과 같은 여러 유형의 편향을 확인하고, 성별, 연령, 거주지, 사회경제적 지위와 같은 변수에서 나타나는 편향을 논의한다.

Conclusion: 임상 문제 설계 및 데이터 수집의 공정성과 견고성을 개선하기 위한 실질적인 권고를 제시하며, 이러한 발견이 향후 의료 분야의 공정한 AI 시스템 개발에 기여할 것을 기대한다.

Abstract: Artificial intelligence (AI) holds great promise for transforming healthcare.
However, despite significant advances, the integration of AI solutions into
real-world clinical practice remains limited. A major barrier is the quality
and fairness of training data, which is often compromised by biased data
collection practices. This paper draws on insights from the AI4HealthyAging
project, part of Spain's national R&D initiative, where our task was to detect
biases during clinical data collection. We identify several types of bias
across multiple use cases, including historical, representation, and
measurement biases. These biases manifest in variables such as sex, gender,
age, habitat, socioeconomic status, equipment, and labeling. We conclude with
practical recommendations for improving the fairness and robustness of clinical
problem design and data collection. We hope that our findings and experience
contribute to guiding future projects in the development of fairer AI systems
in healthcare.

</details>


### [10] [Collateral Damage Assessment Model for AI System Target Engagement in Military Operations](https://arxiv.org/abs/2510.20337)
*Clara Maathuis,Kasper Cools*

Main category: cs.AI

TL;DR: AI 시스템의 군사 작전에서의 목표 관여를 위한 새로운 피해 평가 모델을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 전투에서 AI 시스템의 역할이 증가함에 따라 책임 있는 목표 설정을 보장하기 위해 잠재적 부수적 효과의 철저한 평가가 필요합니다.

Method: 이 모델은 디자인 과학 방법론적 접근을 따르며, 시간적, 공간적, 힘의 차원을 통합한 통합 지식 표현 및 추론(KRR) 아키텍처를 사용합니다.

Result: 모델은 AI 시스템의 참여 범주 및 구조적 구성 요소를 캡처하고, 투입 벡터와 맥락적 측면을 함께 고려합니다.

Conclusion: 이 모델은 투명한 추론 메커니즘으로 강화된 명확한 표현을 제공하며, 군사 작전에서 AI 시스템 활용의 영향을 평가하기 위한 신뢰할 수 있는 지능형 시스템 구축의 기초가 됩니다.

Abstract: In an era where AI (Artificial Intelligence) systems play an increasing role
in the battlefield, ensuring responsible targeting demands rigorous assessment
of potential collateral effects. In this context, a novel collateral damage
assessment model for target engagement of AI systems in military operations is
introduced. The model integrates temporal, spatial, and force dimensions within
a unified Knowledge Representation and Reasoning (KRR) architecture following a
design science methodological approach. Its layered structure captures the
categories and architectural components of the AI systems to be engaged
together with corresponding engaging vectors and contextual aspects. At the
same time, spreading, severity, likelihood, and evaluation metrics are
considered in order to provide a clear representation enhanced by transparent
reasoning mechanisms. Further, the model is demonstrated and evaluated through
instantiation which serves as a basis for further dedicated efforts that aim at
building responsible and trustworthy intelligent systems for assessing the
effects produced by engaging AI systems in military operations.

</details>


### [11] [LLM-empowered knowledge graph construction: A survey](https://arxiv.org/abs/2510.20345)
*Haonan Bian*

Main category: cs.AI

TL;DR: 대규모 언어 모델에 의해 강화된 지식 그래프(KG) 구축의 최근 진전을 포괄적으로 개관하며, LLM이 전통적인 KG 방법론을 어떻게 재구성하는지를 체계적으로 분석한다.


<details>
  <summary>Details</summary>
Motivation: 지식 그래프(KG)는 구조화된 지식 표현과 추론을 위한 기본 인프라로 오랫동안 활용되어 왔으나, 대규모 언어 모델(LLM)의 도래로 인해 KG 구축이 규칙 기반 및 통계적 파이프라인에서 언어 기반 및 생성 프레임워크로 발전하는 새로운 패러다임에 진입하였다.

Method: 전통적인 KG 방법론을 revisit한 후, 구조, 정규화 및 일관성을 강조하는 스키마 기반 패러다임과 유연성, 적응성 및 개방적 발견을 강조하는 스키마 자유 패러다임에서 최근의 LLM 기반 접근 방식을 두 가지 보완적 관점에서 검토하였다.

Result: 각 단계에서 대표적인 프레임워크를 종합하고, 그들의 기술적 메커니즘을 분석하며, 제한점을 식별하였다.

Conclusion: LLM과 지식 그래프 간의 진화하는 상호작용을 명확히 하여, 기호적 지식 공학과 신경 의미 이해의 연결고리를 마련하고, 적응 가능하고 설명 가능한 지능형 지식 시스템 개발로 나아가는 미래 연구 방향을 제시하였다.

Abstract: Knowledge Graphs (KGs) have long served as a fundamental infrastructure for
structured knowledge representation and reasoning. With the advent of Large
Language Models (LLMs), the construction of KGs has entered a new
paradigm-shifting from rule-based and statistical pipelines to language-driven
and generative frameworks. This survey provides a comprehensive overview of
recent progress in LLM-empowered knowledge graph construction, systematically
analyzing how LLMs reshape the classical three-layered pipeline of ontology
engineering, knowledge extraction, and knowledge fusion.
  We first revisit traditional KG methodologies to establish conceptual
foundations, and then review emerging LLM-driven approaches from two
complementary perspectives: schema-based paradigms, which emphasize structure,
normalization, and consistency; and schema-free paradigms, which highlight
flexibility, adaptability, and open discovery. Across each stage, we synthesize
representative frameworks, analyze their technical mechanisms, and identify
their limitations.
  Finally, the survey outlines key trends and future research directions,
including KG-based reasoning for LLMs, dynamic knowledge memory for agentic
systems, and multimodal KG construction. Through this systematic review, we aim
to clarify the evolving interplay between LLMs and knowledge graphs, bridging
symbolic knowledge engineering and neural semantic understanding toward the
development of adaptive, explainable, and intelligent knowledge systems.

</details>


### [12] [Efficient Algorithms for Computing Random Walk Centrality](https://arxiv.org/abs/2510.20604)
*Changan Liu,Zixuan Xie,Ahad N. Zehmakan,Zhongzhi Zhang*

Main category: cs.AI

TL;DR: 랜덤 워크 중심성은 대규모 네트워크에서 노드의 중요성과 영향을 정량화하는 데 사용되는 기본 지표로, 본 논문에서는 이를 계산하기 위한 두 가지 확장 가능한 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 랜덤 워크 중심성은 그래프 마이닝에 있어 노드의 중요성과 영향을 측정하는 중요한 지표이다. 그러나 대규모 네트워크에서는 기존 방법의 계산적 요구 때문에 이 지표를 계산하는 것이 비현실적이다.

Method: 본 논문에서는 랜덤 워크 중심성의 새로운 공식을 제시하며, 근사한 조엘스키 분해와 희소 역 추정 또는 샘플링된 뿌리 신장 트리를 활용하는 두 가지 알고리즘을 발전시킨다.

Result: 제안된 두 알고리즘 모두 거의 선형 시간에 동작하며 강력한 근사 보증을 제공한다. 1000만 개 이상의 노드를 포함한 대규모 실제 네트워크에 대한 광범위한 실험이 알고리즘의 효율성과 근사 품질을 입증한다.

Conclusion: 제안된 알고리즘은 대규모 네트워크에서 랜덤 워크 중심성을 효율적으로 계산할 수 있는 유망한 접근법을 제공한다.

Abstract: Random walk centrality is a fundamental metric in graph mining for
quantifying node importance and influence, defined as the weighted average of
hitting times to a node from all other nodes. Despite its ability to capture
rich graph structural information and its wide range of applications, computing
this measure for large networks remains impractical due to the computational
demands of existing methods. In this paper, we present a novel formulation of
random walk centrality, underpinning two scalable algorithms: one leveraging
approximate Cholesky factorization and sparse inverse estimation, while the
other sampling rooted spanning trees. Both algorithms operate in near-linear
time and provide strong approximation guarantees. Extensive experiments on
large real-world networks, including one with over 10 million nodes,
demonstrate the efficiency and approximation quality of the proposed
algorithms.

</details>


### [13] [Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications](https://arxiv.org/abs/2510.20632)
*Shuyi Xie,Ziqin Liew,Hailing Zhang,Haibo Zhang,Ling Hu,Zhiqiang Zhou,Shuman Liu,Anxiang Zeng*

Main category: cs.AI

TL;DR: EcomEval은 전자상거래에서 LLM을 평가하기 위한 포괄적인 다국어 및 다중 모드 벤치마크로, 6개 범주와 37개 과제를 포함하고 있습니다.


<details>
  <summary>Details</summary>
Motivation: 전문 분야에서 LLM의 능력이 충분히 탐구되지 않았으며, 전자상거래 평가 기준이 제한적입니다.

Method: EcomEval은 실질적인 고객 문의와 거래 기록에서 수집된 데이터를 사용하여 6개 범주 37개 과제를 포함합니다. 지원하는 언어는 7개입니다.

Result: EcomEval은 다양한 질문과 과제 범주에 대해 각 모델의 평가 점수가 평균화되어 난이도 수준을 정의합니다.

Conclusion: EcomEval은 전자상거래의 복잡한 상황을 평가할 수 있는 신뢰할 수 있는 도구를 제공합니다.

Abstract: Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet
their capabilities in specialized domains remain underexplored. In e-commerce,
existing evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping
MMLU-suffer from limited task diversity (e.g., lacking product guidance and
after-sales issues), limited task modalities (e.g., absence of multimodal
data), synthetic or curated data, and a narrow focus on English and Chinese,
leaving practitioners without reliable tools to assess models on complex,
real-world shopping scenarios. We introduce EcomEval, a comprehensive
multilingual and multimodal benchmark for evaluating LLMs in e-commerce.
EcomEval covers six categories and 37 tasks (including 8 multimodal tasks),
sourced primarily from authentic customer queries and transaction logs,
reflecting the noisy and heterogeneous nature of real business interactions. To
ensure both quality and scalability of reference answers, we adopt a
semi-automatic pipeline in which large models draft candidate responses
subsequently reviewed and modified by over 50 expert annotators with strong
e-commerce and multilingual expertise. We define difficulty levels for each
question and task category by averaging evaluation scores across models with
different sizes and capabilities, enabling challenge-oriented and fine-grained
assessment. EcomEval also spans seven languages-including five low-resource
Southeast Asian languages-offering a multilingual perspective absent from prior
work.

</details>


### [14] [Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges](https://arxiv.org/abs/2510.20641)
*Andrea Agiollo,Andrea Omicini*

Main category: cs.AI

TL;DR: 기계 학습(ML) 모델의 인지 및 인지 작업에서의 뛰어난 인간 유사 능력 덕분에, ML을 합리적 에이전트 아키텍처에 통합하는 프레임워크가 주목받고 있다. 하지만, 이 분야는 여전히 단편화되고 일관성이 없으며, 일반적인 에이전트 컨테이너에 ML을 임베딩하는 데 중점을 두고 있으며, 합리적 아키텍처의 표현력은 간과하고 있다. 이 논문은 BDI 패러다임을 기준으로 기존 접근 방식을 세밀하게 체계화하여 ML로 향상된 합리적 에이전트에 대한 빠르게 발전하고 있는 문헌을 보여주고, 효과적인 합리적 ML 에이전트를 설계하기 위한 주요 연구 기회와 해결해야 할 과제를 확인한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습(ML) 모델의 인지 능력을 활용하여 합리적 에이전트 아키텍처를 개선하고자 함.

Method: BDI 패러다임을 기준으로 기존의 접근 방식을 체계적으로 분석하고 분류함.

Result: ML로 향상된 합리적 에이전트에 대한 문헌을 분석하고, 주요 연구 기회와 도전 과제를 확인함.

Conclusion: 합리적 ML 에이전트 설계에 대한 통찰력을 제공하며, 연구자들에게 새로운 작업 및 방향성을 제시함.

Abstract: Thanks to the remarkable human-like capabilities of machine learning (ML)
models in perceptual and cognitive tasks, frameworks integrating ML within
rational agent architectures are gaining traction. Yet, the landscape remains
fragmented and incoherent, often focusing on embedding ML into generic agent
containers while overlooking the expressive power of rational
architectures--such as Belief-Desire-Intention (BDI) agents. This paper
presents a fine-grained systematisation of existing approaches, using the BDI
paradigm as a reference. Our analysis illustrates the fast-evolving literature
on rational agents enhanced by ML, and identifies key research opportunities
and open challenges for designing effective rational ML agents.

</details>


### [15] [A Coherence-Based Measure of AGI](https://arxiv.org/abs/2510.20784)
*Fares Fourati*

Main category: cs.AI

TL;DR: 이 논문은 AGI(인공지능 일반 지능)를 측정하는 새로운 방법을 제안하며, Cattell-Horn-Carroll 모델에 기반하여 균형 잡힌 역량을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: 최근 연구는 AGI를 Cattell-Horn-Carroll(CHC) 모델에 따른 인지 영역의 능력 평균으로 정의했으나, 이는 균형 잡힌 역량이 아닌 보완 가능성을 전제로 하여 AGI를 평가하는 것이 잘못되었음을 강조합니다.

Method: 보완 가능성 지수의 연속성을 통해 일반화된 평균의 적분에 기반한 AGI의 일관성 인식 측정 방법을 제안합니다. 이 접근법은 산술, 기하학적, 조화적 영역을 포함합니다.

Result: 제안된 방법은 GPT-4와 GPT-5의 CHC 기반 점수에 적용되었으며, 높은 산술 점수에도 불구하고 실제 일반 역량에서 두 시스템이 여전히 멀다는 것을 보여줍니다.

Conclusion: AGI를 측정하기 위해 일반화된 평균을 통합함으로써, 진정한 AGI를 향한 진전을 측정하기 위한 원칙적이고 해석 가능한 엄격한 토대를 제공합니다.

Abstract: Recent work by \citet{hendrycks2025agidefinition} formalized
\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of
proficiencies across cognitive domains derived from the Cattell--Horn--Carroll
(CHC) model of human cognition. While elegant, this definition assumes
\textit{compensability} -- that exceptional ability in some domains can offset
failure in others. True general intelligence, however, should reflect
\textit{coherent sufficiency}: balanced competence across all essential
domains. We propose a coherence-aware measure of AGI based on the integral of
generalized means over a continuum of compensability exponents. This
formulation spans arithmetic, geometric, and harmonic regimes, and the
resulting \textit{area under the curve} (AUC) quantifies robustness under
varying compensability assumptions. Unlike the arithmetic mean, which rewards
specialization, the AUC penalizes imbalance and captures inter-domain
dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,
the coherence-adjusted AUC reveals that both systems remain far from general
competence despite high arithmetic scores (e.g., GPT-5 at~24\%). Integrating
the generalized mean thus yields a principled, interpretable, and stricter
foundation for measuring genuine progress toward AGI.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [16] [An Integrated Approach to Neural Architecture Search for Deep Q-Networks](https://arxiv.org/abs/2510.19872)
*Iman Rahmani,Saman Yazdannik,Morteza Tayefi,Jafar Roshanian*

Main category: cs.LG

TL;DR: 딥 강화 학습 에이전트의 성능은 신경망 구조에 의해 제한되며, 이 연구는 온라인 적응형 구조 최적화가 이러한 제약을 극복하고 기존 설계를 능가할 수 있는지를 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 딥 강화 학습 에이전트의 성능은 신경망 아키텍처에 의해 본질적으로 제약을 받으며, 이는 비싼 하이퍼파라미터 검색을 통해 전통적으로 결정되고 훈련 전반에 걸쳐 고정됩니다.

Method: NAS-DQN을 도입하여 학습된 신경망 아키텍처 검색 제어기를 DRL 훈련 루프에 직접 통합하여 누적 성능 피드백에 기반한 동적 네트워크 재구성을 가능하게 합니다.

Result: NAS-DQN은 세 가지 고정 아키텍처 기준선 및 랜덤 검색 제어에 대해 평가되어, 최종 성능, 샘플 효율성 및 정책 안정성을 뛰어난 결과로 나타냈으며, 계산 오버헤드는 미미합니다.

Conclusion: 구성 요소의 적응은 온라인 딥 강화 학습에서 최적의 샘플 효율성을 위해 단순히 유익한 것이 아니라 필요하다는 것을 입증하고, RL 에이전트의 설계가 고정된 오프라인 선택이 아니라 학습 과정의 동적 구성 요소로 원활하게 통합될 수 있음을 제안합니다.

Abstract: The performance of deep reinforcement learning agents is fundamentally
constrained by their neural network architecture, a choice traditionally made
through expensive hyperparameter searches and then fixed throughout training.
This work investigates whether online, adaptive architecture optimization can
escape this constraint and outperform static designs. We introduce NAS-DQN, an
agent that integrates a learned neural architecture search controller directly
into the DRL training loop, enabling dynamic network reconfiguration based on
cumulative performance feedback. We evaluate NAS-DQN against three
fixed-architecture baselines and a random search control on a continuous
control task, conducting experiments over multiple random seeds. Our results
demonstrate that NAS-DQN achieves superior final performance, sample
efficiency, and policy stability while incurring negligible computational
overhead. Critically, the learned search strategy substantially outperforms
both undirected random architecture exploration and poorly-chosen fixed
designs, indicating that intelligent, performance-guided search is the key
mechanism driving success. These findings establish that architecture
adaptation is not merely beneficial but necessary for optimal sample efficiency
in online deep reinforcement learning, and suggest that the design of RL agents
need not be a static offline choice but can instead be seamlessly integrated as
a dynamic component of the learning process itself.

</details>


### [17] [From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph](https://arxiv.org/abs/2510.19873)
*Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li*

Main category: cs.LG

TL;DR: 이 논문에서는 LLM 수준의 추론을 더 작은 모델로 전이하는 ReGraphT라는 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: CUDA 프로그래밍과 도메인 특화 라이브러리의 발전에도 불구하고, GPU를 효과적으로 활용하는 것은 여전히 어렵습니다.

Method: ReGraphT는 교육이 필요 없는 검색 증강 생성 프레임워크로, CUDA 최적화 궤적을 구조화된 추론 그래프로 조직하고 상태 전환으로 모델링하며, 효율적인 탐색을 위해 몬테 카를로 그래프 검색(MCGS)을 활용합니다.

Result: ReGraphT는 HPC-specific 파인 튜닝 모델과 다른 검색 증강 접근법을 능가하며, CUDAEval과 ParEval에서 평균 2.33배의 속도 향상을 달성했습니다.

Conclusion: ReGraphT는 DeepSeek-Coder-V2-Lite-Instruct 및 Qwen2.5-Coder-7B-Instruct와 결합하여 SLM이 LLM 수준의 성능에 접근할 수 있도록 하며, 관련된 개인 정보 위험 또는 과도한 컴퓨팅 오버헤드 없이 가능합니다.

Abstract: Despite significant evolution of CUDA programming and domain-specific
libraries, effectively utilizing GPUs with massively parallel engines remains
difficult. Large language models (LLMs) show strong potential in generating
optimized CUDA code from sequential code. However, using LLMs in practice faces
two major challenges: cloud-based APIs pose risks of code leakage, and local
deployment is often computationally expensive and inefficient. These drawbacks
have spurred interest in small language models (SLMs), which are more
lightweight and privacy-friendly. Encouragingly, recent studies show that SLMs
can achieve performance comparable to LLMs on specific tasks. While SLMs can
match LLMs on domain-specific tasks, their limited reasoning abilities lead to
suboptimal performance in complex CUDA generation according to our experiments.
To bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented
generation framework that transfers LLM-level reasoning to smaller models.
ReGraphT organizes CUDA optimization trajectories into a structured reasoning
graph, modeling the combined CUDA optimizations as state transitions, and
leverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also
present a CUDA-specific benchmark with difficulty tiers defined by reasoning
complexity to evaluate models more comprehensively. Experiments show that
ReGraphT outperforms HPC-specific fine-tuned models and other
retrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval
and ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and
Qwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level
performance without the associated privacy risks or excessive computing
overhead.

</details>


### [18] [From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem](https://arxiv.org/abs/2510.19889)
*Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis*

Main category: cs.LG

TL;DR: 이 연구는 대규모 네트워크에서의 트래픽 할당 문제를 해결하기 위한 새로운 데이터 기반 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 네트워크에서의 교통 흐름 분석을 위한 기존 방법들이 복잡성 증가로 인해 계산 비용이 매우 비쌌기 때문에 새로운 접근 방식이 필요하다.

Method: 딥 뉴럴 네트워크와 트랜스포머 아키텍처를 활용하여 균형 경로 흐름을 직접 예측하는 모델을 제안한다.

Result: 제안된 모델은 매뉴얼 최적화 방법보다 수십 배 빠르게 다중 클래스 네트워크에서 경로 수준의 교통 흐름을 효율적으로 추정한다.

Conclusion: 이 모델은 변화하는 수요와 네트워크 조건에 유연하게 적응하여 교통 관리와 신속한 '가정' 분석을 지원한다.

Abstract: The traffic assignment problem is essential for traffic flow analysis,
traditionally solved using mathematical programs under the Equilibrium
principle. These methods become computationally prohibitive for large-scale
networks due to non-linear growth in complexity with the number of OD pairs.
This study introduces a novel data-driven approach using deep neural networks,
specifically leveraging the Transformer architecture, to predict equilibrium
path flows directly. By focusing on path-level traffic distribution, the
proposed model captures intricate correlations between OD pairs, offering a
more detailed and flexible analysis compared to traditional link-level
approaches. The Transformer-based model drastically reduces computation time,
while adapting to changes in demand and network structure without the need for
recalculation. Numerical experiments are conducted on the Manhattan-like
synthetic network, the Sioux Falls network, and the Eastern-Massachusetts
network. The results demonstrate that the proposed model is orders of magnitude
faster than conventional optimization. It efficiently estimates path-level
traffic flows in multi-class networks, reducing computational costs and
improving prediction accuracy by capturing detailed trip and flow information.
The model also adapts flexibly to varying demand and network conditions,
supporting traffic management and enabling rapid `what-if' analyses for
enhanced transportation planning and policy-making.

</details>


### [19] [Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control](https://arxiv.org/abs/2510.20408)
*Tom Maus,Asma Atamna,Tobias Glasmachers*

Main category: cs.LG

TL;DR: 이 논문은 다단계 산업 공정의 자율 제어에 관한 연구로, 강화 학습의 한계를 극복하기 위해 새로운 벤치마크 환경을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다단계 산업 공정의 자율 제어에 필요한 지역 전문성과 글로벌 조정의 필요성.

Method: SortingEnv와 ContainerGym에서 기존 작업을 결합한 개선된 벤치마크 환경을 제안하고, 모듈형 아키텍처와 단일 시스템을 관리하는 모놀리식 에이전트를 평가한다.

Result: 행동 마스킹 없이 에이전트가 효과적인 정책 학습에 어려움을 겪었으며, 모듈형 아키텍처가 더 나은 성과를 보였다. 행동 마스킹 적용 시 두 아키텍처 모두 실질적으로 향상되었고 성과 격차가 줄어들었다.

Conclusion: 행동 공간 제약의 결정적인 역할을 강조하며, 행동 복잡성이 감소함에 따라 전문화의 이점이 감소하는 것을 시사한다.

Abstract: Autonomous control of multi-stage industrial processes requires both local
specialization and global coordination. Reinforcement learning (RL) offers a
promising approach, but its industrial adoption remains limited due to
challenges such as reward design, modularity, and action space management. Many
academic benchmarks differ markedly from industrial control problems, limiting
their transferability to real-world applications. This study introduces an
enhanced industry-inspired benchmark environment that combines tasks from two
existing benchmarks, SortingEnv and ContainerGym, into a sequential recycling
scenario with sorting and pressing operations. We evaluate two control
strategies: a modular architecture with specialized agents and a monolithic
agent governing the full system, while also analyzing the impact of action
masking. Our experiments show that without action masking, agents struggle to
learn effective policies, with the modular architecture performing better. When
action masking is applied, both architectures improve substantially, and the
performance gap narrows considerably. These results highlight the decisive role
of action space constraints and suggest that the advantages of specialization
diminish as action complexity is reduced. The proposed benchmark thus provides
a valuable testbed for exploring practical and robust multi-agent RL solutions
in industrial automation, while contributing to the ongoing debate on
centralization versus specialization.

</details>


### [20] [Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets](https://arxiv.org/abs/2510.19950)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 이 논문은 재무 응용에서의 강화 학습(RL) 에이전트의 성능 저하 문제를 해결하기 위해 새로운 엘립틱 불확실성 집합을 개발하고, 이를 통해 강건한 정책 평가를 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 재무 응용에서 RL 에이전트가 훈련과 실제 거래 환경 간의 불일치를 해결할 필요성이 있다.

Method: 엘립틱 불확실성 집합을 개발하고, 이 집합에서 최악의 불확실성에 대한 암묵적 및 명시적 닫힌 형식의 해를 제시한다.

Result: 단일 자산 및 다중 자산 거래 작업에서 이 방법이 우수한 샤프 비율을 달성하고, 거래량이 증가해도 강건성을 유지함을 보여준다.

Conclusion: 재무 시장에서 RL 접근 방식을 보다 충실하고 확장 가능한 방식으로 제공한다.

Abstract: In financial applications, reinforcement learning (RL) agents are commonly
trained on historical data, where their actions do not influence prices.
However, during deployment, these agents trade in live markets where their own
transactions can shift asset prices, a phenomenon known as market impact. This
mismatch between training and deployment environments can significantly degrade
performance. Traditional robust RL approaches address this model
misspecification by optimizing the worst-case performance over a set of
uncertainties, but typically rely on symmetric structures that fail to capture
the directional nature of market impact. To address this issue, we develop a
novel class of elliptic uncertainty sets. We establish both implicit and
explicit closed-form solutions for the worst-case uncertainty under these sets,
enabling efficient and tractable robust policy evaluation. Experiments on
single-asset and multi-asset trading tasks demonstrate that our method achieves
superior Sharpe ratio and remains robust under increasing trade volumes,
offering a more faithful and scalable approach to RL in financial markets.

</details>


### [21] [Thought Communication in Multiagent Collaboration](https://arxiv.org/abs/2510.20733)
*Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang*

Main category: cs.LG

TL;DR: 본 논문은 자연 언어의 한계를 넘어 사고 통신(paradigm of thought communication)이라는 새로운 패러다임을 도입하여 에이전트 간의 직접적인 상호작용을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 자연 언어는 인류 협력을 가능하게 하지만, 손실적이고 모호하며 간접적인 특성으로 인해 집단 지성의 잠재력을 제한한다.

Method: 신뢰할 수 없는 생각의 함수로 생성되는 에이전트 상태를 일반 잠재 변수 모델로 형식화하여, 모든 에이전트의 잠재적 생각을 추출하고 적절한 공유 패턴을 할당하는 프레임워크를 개발하였다.

Result: 이론적 보장을 통해 모든 에이전트 간에 공유되고 비공유된 잠재 생각을 식별할 수 있으며, 사고 공유의 글로벌 구조도 복원 가능하다.

Conclusion: 이 연구는 표면적 관찰만으로 해결할 수 없는 문제들이 많다는 점을 강조하며, 숨겨진 세상을 활용할 잠재력을 밝혀주길 기대한다.

Abstract: Natural language has long enabled human cooperation, but its lossy,
ambiguous, and indirect nature limits the potential of collective intelligence.
While machines are not subject to these constraints, most LLM-based multi-agent
systems still rely solely on natural language, exchanging tokens or their
embeddings. To go beyond language, we introduce a new paradigm, thought
communication, which enables agents to interact directly mind-to-mind, akin to
telepathy. To uncover these latent thoughts in a principled way, we formalize
the process as a general latent variable model, where agent states are
generated by an unknown function of underlying thoughts. We prove that, in a
nonparametric setting without auxiliary information, both shared and private
latent thoughts between any pair of agents can be identified. Moreover, the
global structure of thought sharing, including which agents share which
thoughts and how these relationships are structured, can also be recovered with
theoretical guarantees. Guided by the established theory, we develop a
framework that extracts latent thoughts from all agents prior to communication
and assigns each agent the relevant thoughts, along with their sharing
patterns. This paradigm naturally extends beyond LLMs to all modalities, as
most observational data arise from hidden generative processes. Experiments on
both synthetic and real-world benchmarks validate the theory and demonstrate
the collaborative advantages of thought communication. We hope this work
illuminates the potential of leveraging the hidden world, as many challenges
remain unsolvable through surface-level observation alone, regardless of
compute or data scale.

</details>


### [22] [SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph](https://arxiv.org/abs/2510.20022)
*Jiazheng Li,Yawei Wang,David Yan,Yijun Tian,Zhichao Xu,Huan Song,Panpan Xu,Lin Lee Cheong*

Main category: cs.LG

TL;DR: SALT라는 새로운 경량 프레임워크를 제안하며, 이는 결과 보상에서 유래된 더 세분화된 이점 할당을 제공하고 기존의 그룹 기반 RL 알고리즘과 원활하게 통합된다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 다단계 및 장기 과업에 대한 대형 언어 모델을 적용하는 데 있어 기존의 희박하고 결과 기반 보상 접근 방식의 한계를 극복하고자 한다.

Method: SALT는 동일한 프롬프트에 대한 경로에서 그래프를 구축하여 각 단계의 품질을 정량화하고 그에 따라 이점을 할당하는 방식으로 작동한다.

Result: WebShop, ALFWorld 및 AppWorld 벤치마크에서 SALT는 일관되게 성능을 개선하였다.

Conclusion: SAL은 기존의 그룹 기반 RL 알고리즘과 통합하여 훈련 안정성을 높이고 필요한 컴퓨팅 오버헤드를 최소화한다.

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities,
enabling language agents to excel at single-turn tasks. However, their
application to complex, multi-step, and long-horizon tasks remains challenging.
While reinforcement learning (RL) offers a promising avenue for addressing
these challenges, mainstream approaches typically rely solely on sparse,
outcome-based rewards, a limitation that becomes especially problematic for
group-based RL algorithms lacking critic models, such as Group Relative Policy
Optimization (GRPO). In such methods, uniformly rewarding or penalizing all
actions within a trajectory can lead to training instability and suboptimal
policies, because beneficial and detrimental actions are often entangled across
multi-step interactions. To address this challenge, we propose SALT, a novel
and lightweight framework that provides a finer-grained advantage assignment,
derived solely from outcome rewards. We achieve this by constructing a graph
from trajectories of the same prompt, which allows us to quantify the quality
of each step and assign advantages accordingly. Crucially, SALT is designed as
a plug-and-play module that seamlessly integrates with existing group-based RL
algorithms, requiring no modifications to the rollout procedure and introducing
negligible computational overhead. Extensive experiments on the WebShop,
ALFWorld, and AppWorld benchmarks with various model sizes demonstrate that
SALT consistently improves performance. We also conduct a thorough analysis to
validate the design choices behind SALT and offer actionable insights.

</details>


### [23] [Competition is the key: A Game Theoretic Causal Discovery Approach](https://arxiv.org/abs/2510.20106)
*Amartya Roy,Souvik Chakraborty*

Main category: cs.LG

TL;DR: 이 논문에서는 인과 발견에 대한 새로운 강화 학습 프레임워크를 제안하여 기존 알고리즘의 한계를 극복했다.


<details>
  <summary>Details</summary>
Motivation: 기존의 인과 발견 방법은 유한 샘플 보장이 부족하거나 이론적으로 확립된 접근 방식이 확장성이 부족하다.

Method: 게임 이론적 강화 학습 프레임워크를 도입하여 DDQN 에이전트가 강력한 기초선(GES 또는 GraN-DAG)과 직접 경쟁한다.

Result: 우리의 접근 방식은 학습된 그래프가 언제나 대항보다 열등하지 않으며, 따뜻한 시작이 수렴을 가속화하고, 알고리즘이 실제 최상의 후보 그래프를 선택할 확률이 높다는 보장을 제공한다.

Conclusion: 우리는 인과 발견에서 유한 샘플 보장을 설명하는 새로운 단계로 나아가며, 다양한 사례에서 GES와 GraN-DAG를 초과하는 성능을 보여준다.

Abstract: Causal discovery remains a central challenge in machine learning, yet
existing methods face a fundamental gap: algorithms like GES and GraN-DAG
achieve strong empirical performance but lack finite-sample guarantees, while
theoretically principled approaches fail to scale. We close this gap by
introducing a game-theoretic reinforcement learning framework for causal
discovery, where a DDQN agent directly competes against a strong baseline (GES
or GraN-DAG), always warm-starting from the opponent's solution. This design
yields three provable guarantees: the learned graph is never worse than the
opponent, warm-starting strictly accelerates convergence, and most importantly,
with high probability the algorithm selects the true best candidate graph. To
the best of our knowledge, our result makes a first-of-its-kind progress in
explaining such finite-sample guarantees in causal discovery: on synthetic SEMs
(30 nodes), the observed error probability decays with n, tightly matching
theory. On real-world benchmarks including Sachs, Asia, Alarm, Child, Hepar2,
Dream, and Andes, our method consistently improves upon GES and GraN-DAG while
remaining theoretically safe. Remarkably, it scales to large graphs such as
Hepar2 (70 nodes), Dream (100 nodes), and Andes (220 nodes). Together, these
results establish a new class of RL-based causal discovery algorithms that are
simultaneously provably consistent, sample-efficient, and practically scalable,
marking a decisive step toward unifying empirical performance with rigorous
finite-sample theory.

</details>


### [24] [Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling](https://arxiv.org/abs/2510.20148)
*Tingting Dan,Xinwei Huang,Jiaqi Ding,Yinggang Zheng,Guorong Wu*

Main category: cs.LG

TL;DR: 본 연구는 알츠하이머병에서 타우 단백질의 전파를 이해하기 위해 구조적 연결성과 기능적 연결성의 상호작용을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 타우 단백질의 축적이 알츠하이머병의 진행에 미치는 영향을 이해하고자 한다.

Method: 다층 그래프 확산 모델을 통해 구조적 연결성과 기능적 연결성의 상호작용을 분석하였다.

Result: 연구 결과, 기능적 연결성이 피각 아래 지역과 전두엽, 측두엽에서 타우 전파를 주도하며, 구조적 연결성은 후두엽, 두정엽, 변연계에서 더 큰 역할을 한다는 것을 발견했다.

Conclusion: 결론적으로, 타우 전파를 이해하기 위해 둘 간의 균형이 알츠하이머병의 진행에 어떻게 변하는지를 반영하였다.

Abstract: Emerging neuroimaging evidence shows that pathological tau proteins build up
along specific brain networks, suggesting that large-scale network architecture
plays a key role in the progression of Alzheimer's disease (AD). However, how
structural connectivity (SC) and functional connectivity (FC) interact to
influence tau propagation remains unclear. Leveraging an unprecedented volume
of longitudinal neuroimaging data, we examine SC-FC interactions through a
multi-layer graph diffusion model. Beyond showing that connectome architecture
constrains tau spread, our model reveals a regionally asymmetric contribution
of SC and FC. Specifically, FC predominantly drives tau spread in subcortical
areas, the insula, frontal and temporal cortices, whereas SC plays a larger
role in occipital, parietal, and limbic regions. The relative dominance of SC
versus FC shifts over the course of disease, with FC generally prevailing in
early AD and SC becoming primary in later stages. Spatial patterns of SC- and
FC-dominant regions strongly align with the regional expression of
AD-associated genes involved in inflammation, apoptosis, and lysosomal
function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In
parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and
biological mechanisms (e.g., amyloid deposition) selectively reshape tau
propagation by shifting dominant routes between anatomical and functional
pathways in a region-specific manner. Findings are validated in an independent
AD cohort.

</details>


### [25] [Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset](https://arxiv.org/abs/2510.20209)
*Shumin Li*

Main category: cs.LG

TL;DR: 개에서 조기 암 탐지를 위한 접근 가능한 스크리닝 도구 개발은 수의학에서 중요한 도전 과제이다. 로지스틱 회귀 분류기를 사용한 연구에서 여러 모델과 기법이 평가되었으나, 정상 노화나 기타 염증성 조건과의 임상적 구별이 어려운 것으로 나타났다.


<details>
  <summary>Details</summary>
Motivation: 조기 암 탐지를 위한 수의학적인 접근 방식으로서 저비용의 스크리닝 도구 개발 필요성.

Method: Golden Retriever Lifetime Study (GRLS) 코호트를 이용해 다양한 암 유형을 그룹화하고, 진단 후 표본을 포함한 실용적 제약 하에서 암 위험 분류의 타당성을 평가.

Result: 로지스틱 회귀 분류기가 AUROC 0.815로 보통의 순위를 보였으나 임상적 분류 성능이 저조했으며, 양성 예측 값이 0.15로 낮았다.

Conclusion: 통계적으로 감지 가능한 암 신호는 존재하나, 정상 노화나 다른 염증성 상태와의 임상적 구별력을 위해서는 다중 모달 데이터 소스의 통합이 필요하다는 결론.

Abstract: The development of accessible screening tools for early cancer detection in
dogs represents a significant challenge in veterinary medicine. Routine
laboratory data offer a promising, low-cost source for such tools, but their
utility is hampered by the non-specificity of individual biomarkers and the
severe class imbalance inherent in screening populations. This study assesses
the feasibility of cancer risk classification using the Golden Retriever
Lifetime Study (GRLS) cohort under real-world constraints, including the
grouping of diverse cancer types and the inclusion of post-diagnosis samples. A
comprehensive benchmark evaluation was conducted, systematically comparing 126
analytical pipelines that comprised various machine learning models, feature
selection methods, and data balancing techniques. Data were partitioned at the
patient level to prevent leakage. The optimal model, a Logistic Regression
classifier with class weighting and recursive feature elimination, demonstrated
moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical
classification performance (F1-score = 0.25, Positive Predictive Value = 0.15).
While a high Negative Predictive Value (0.98) was achieved, insufficient recall
(0.79) precludes its use as a reliable rule-out test. Interpretability analysis
with SHapley Additive exPlanations (SHAP) revealed that predictions were driven
by non-specific features like age and markers of inflammation and anemia. It is
concluded that while a statistically detectable cancer signal exists in routine
lab data, it is too weak and confounded for clinically reliable discrimination
from normal aging or other inflammatory conditions. This work establishes a
critical performance ceiling for this data modality in isolation and
underscores that meaningful progress in computational veterinary oncology will
require integration of multi-modal data sources.

</details>


### [26] [CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks](https://arxiv.org/abs/2510.20219)
*Ke Xing,Yanjie Dong,Xiaoyi Fan,Runhao Zeng,Victor C. M. Leung,M. Jamal Deen,Xiping Hu*

Main category: cs.LG

TL;DR: 개인화 연합 학습(PFL)은 이질적이며 드문 지역 데이터를 가진 클라이언트를 위해 맞춤형 모델을 공동으로 훈련하는 데 있어 중요한 도전 과제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 연합 학습은 단일 합의 모델에 의존하여 데이터 이질성이 높은 경우에 부적합함을 보여준다.

Method: 기여 중심 PFL(CO-PFL)이라는 새로운 알고리즘을 소개하여, 각 클라이언트의 기여도를 동적으로 추정하여 전세계적 집합을 수행한다.

Result: CO-PFL은 기여도 기반의 평가를 통해 각 클라이언트에 대한 원칙적이고 변별적인 집합 가중치를 제공하며, 맞춤화 적응성과 최적화 안정성을 향상시킨다.

Conclusion: CO-PFL은 개인화 정확도, 강건성, 확장성 및 수렴 안정성에서 최신 방법들을 일관되게 초월함을 입증한 실험 결과를 제공한다.

Abstract: Personalized federated learning (PFL) addresses a critical challenge of
collaboratively training customized models for clients with heterogeneous and
scarce local data. Conventional federated learning, which relies on a single
consensus model, proves inadequate under such data heterogeneity. Its standard
aggregation method of weighting client updates heuristically or by data volume,
operates under an equal-contribution assumption, failing to account for the
actual utility and reliability of each client's update. This often results in
suboptimal personalization and aggregation bias. To overcome these limitations,
we introduce Contribution-Oriented PFL (CO-PFL), a novel algorithm that
dynamically estimates each client's contribution for global aggregation. CO-PFL
performs a joint assessment by analyzing both gradient direction discrepancies
and prediction deviations, leveraging information from gradient and data
subspaces. This dual-subspace analysis provides a principled and discriminative
aggregation weight for each client, emphasizing high-quality updates.
Furthermore, to bolster personalization adaptability and optimization
stability, CO-PFL cohesively integrates a parameter-wise personalization
mechanism with mask-aware momentum optimization. Our approach effectively
mitigates aggregation bias, strengthens global coordination, and enhances local
performance by facilitating the construction of tailored submodels with stable
updates. Extensive experiments on four benchmark datasets (CIFAR10, CIFAR10C,
CINIC10, and Mini-ImageNet) confirm that CO-PFL consistently surpasses
state-of-the-art methods in in personalization accuracy, robustness,
scalability and convergence stability.

</details>


### [27] [ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases](https://arxiv.org/abs/2510.20270)
*Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini*

Main category: cs.LG

TL;DR: 이 논문은 대형 언어 모델(LLM)이 과제를 수행하는 과정에서 단축키를 사용하려는 경향이 신뢰성 있는 결과 평가 및 배치에 위험을 초래함을 보여준다. 이를 해결하기 위해 ImpossibleBench라는 벤치마크 프레임워크를 도입하여 LLM 에이전트의 테스트 케이스 악용 성향을 측정하고 완화하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)은 테스트를 악용하려는 경향이 있으며, 이로 인해 벤치마크 결과의 유효성과 실제 코드 배포의 신뢰성이 저해된다.

Method: ImpossibleBench는 자연어 사양과 단위 테스트 간의 직접적인 충돌을 도입하여 기존 벤치마크에서 '불가능한' 과제 변형을 생성하고, 이를 통해 LLM 에이전트의 '속임수 비율'을 측정한다.

Result: ImpossibleBench는 LLM 에이전트의 속임수 행동을 보다 세분화된 방식으로 연구하고, 컨텍스트 엔지니어링을 통해 속임수 비율에 영향을 미치는 요소를 분석하며, 모니터링 도구 개발을 위한 테스트베드 제공 기능을 보여준다.

Conclusion: 우리는 ImpossibleBench가 더욱 강력하고 신뢰할 수 있는 LLM 시스템을 구축하는 데 유용한 프레임워크로 기능하기를 희망한다.

Abstract: The tendency to find and exploit "shortcuts" to complete tasks poses
significant risks for reliable assessment and deployment of large language
models (LLMs). For example, an LLM agent with access to unit tests may delete
failing tests rather than fix the underlying bug. Such behavior undermines both
the validity of benchmark results and the reliability of real-world LLM coding
assistant deployments.
  To quantify, study, and mitigate such behavior, we introduce ImpossibleBench,
a benchmark framework that systematically measures LLM agents' propensity to
exploit test cases. ImpossibleBench creates "impossible" variants of tasks from
existing benchmarks like LiveCodeBench and SWE-bench by introducing direct
conflicts between the natural-language specification and the unit tests. We
measure an agent's "cheating rate" as its pass rate on these impossible tasks,
where any pass necessarily implies a specification-violating shortcut.
  As a practical framework, ImpossibleBench is not just an evaluation but a
versatile tool. We demonstrate its utility for: (1) studying model behaviors,
revealing more fine-grained details of cheating behaviors from simple test
modification to complex operator overloading; (2) context engineering, showing
how prompt, test access and feedback loop affect cheating rates; and (3)
developing monitoring tools, providing a testbed with verified deceptive
solutions. We hope ImpossibleBench serves as a useful framework for building
more robust and reliable LLM systems.
  Our implementation can be found at
https://github.com/safety-research/impossiblebench.

</details>


### [28] [Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch](https://arxiv.org/abs/2510.20271)
*Udit Saxena*

Main category: cs.LG

TL;DR: 이 논문에서는 효율적이고 미분 가능한 오일러 특성 곡선(ECC) 컴퓨테이션을 위한 최적화된 GPU 커널을 제시하고, PyTorch 계층을 도입하여 끝에서 끝까지의 학습을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 토폴로지적 특징은 이미징 데이터의 전반적인 기하학적 구조를 포착하지만, 딥러닝에서의 실제 적용을 위해서는 계산 효율성과 미분 가능성이 필요하다.

Method: 우리는 합성 격자에서 이전 GPU 구현에 비해 16-2000배의 속도 향상을 달성하는 오일러 특성 곡선(ECC) 컴퓨테이션을 위한 최적화된 GPU 커널을 제시하고, PyTorch용 미분 가능한 계층을 도입하였다.

Result: CUDA 커널은 Ampere GPU에 맞게 최적화되었으며 128B 콜레이스드 접근 및 계층적 공유 메모리 집계를 사용한다. PyTorch 계층은 미분 가능한 오일러 특성 변환 스타일의 시그모이드 완화를 통해 단일 방향에서 임계값을 학습한다.

Conclusion: 우리는 이전 ECC 작업에서 강조된 응용 프로그램을 포함하여 하류 관련성을 논의하고, 널리 채택을 확대하기 위한 배치 및 다중 GPU 확장을 개략적으로 설명한다.

Abstract: Topological features capture global geometric structure in imaging data, but
practical adoption in deep learning requires both computational efficiency and
differentiability. We present optimized GPU kernels for the Euler
Characteristic Curve (ECC) computation achieving 16-2000\"O speedups over prior
GPU implementations on synthetic grids, and introduce a differentiable PyTorch
layer enabling end-to-end learning. Our CUDA kernels, optimized for Ampere GPUs
use 128B-coalesced access and hierarchical shared-memory accumulation. Our
PyTorch layer learns thresholds in a single direction via a Differentiable
Euler Characteristic Transform-style sigmoid relaxation. We discuss downstream
relevance, including applications highlighted by prior ECC work, and outline
batching/multi-GPU extensions to broaden adoption.

</details>


### [29] [Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models](https://arxiv.org/abs/2510.20477)
*Rui Zhu,Song-Lin Lv,Zi-Kang Wang,Lan-Zhe Guo*

Main category: cs.LG

TL;DR: 비코지는 간단하면서도 효과적인 방법으로, 모델 간 및 모델 내부 일관성을 활용하여 고품질의 저편향 가짜 라벨을 부여한다.


<details>
  <summary>Details</summary>
Motivation: 레이블이 부족한 상황에서는 준지도 학습과 사전 훈련된 모델의 미세 조정이 중요하다.

Method: Bi-CoG는 모델 간 및 모델 내부 일관성을 동시에 활용하여 저편향 가짜 라벨을 생성하는 방법론이다.

Result: Bi-CoG는 14개의 데이터셋에서 기존 방법의 성능을 일관되게 크게 향상시킨다.

Conclusion: Bi-CoG는 기존 방법의 모델 편향과 하이퍼파라미터 민감도를 해결하는 데 기여한다.

Abstract: Exploiting unlabeled data through semi-supervised learning (SSL) or
leveraging pre-trained models via fine-tuning are two prevailing paradigms for
addressing label-scarce scenarios. Recently, growing attention has been given
to combining fine-tuning of pre-trained vision-language models (VLMs) with SSL,
forming the emerging paradigm of semi-supervised fine-tuning. However, existing
methods often suffer from model bias and hyperparameter sensitivity, due to
reliance on prediction consistency or pre-defined confidence thresholds. To
address these limitations, we propose a simple yet effective plug-and-play
methodology named
$\underline{\textbf{Bi-Co}}$nsistency-$\underline{\textbf{G}}$uided
Self-Training (Bi-CoG), which assigns high-quality and low-bias pseudo-labels,
by simultaneously exploiting inter-model and intra-model consistency, along
with an error-aware dynamic pseudo-label assignment strategy. Both theoretical
analysis and extensive experiments over 14 datasets demonstrate the
effectiveness of Bi-CoG, which consistently and significantly improves the
performance of existing methods.

</details>


### [30] [A Unified Framework for Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.20542)
*Jacopo Di Ventura,Jan Felix Kleuker,Aske Plaat,Thomas Moerland*

Main category: cs.LG

TL;DR: 제로샷 강화 학습의 첫 통합 프레임워크를 제시하여 기존 접근 방식을 조직하고 비교할 수 있도록 함.


<details>
  <summary>Details</summary>
Motivation: 제로샷 강화 학습이 일반 에이전트를 비지도 방식으로 개발할 수 있는 환경으로 떠오르고 있음.

Method: 제로샷 강화 학습을 위한 통일된 프레임워크를 제시하고, 알고리즘을 직관적 및 조합적 표현으로 분류하여 기존 접근 방식을 조직함.

Result: 공통적인 이론과 방법 간의 차이점을 강조하고, 후속 특성 방법에 대한 확장된 경계를 도출함.

Conclusion: 제공된 프레임워크는 제로샷 강화 학습의 미래 연구를 위한 원칙적인 기초를 제공하고, 보다 일반적인 에이전트를 개발하기 위한 명확한 경로를 설명함.

Abstract: Zero-shot reinforcement learning (RL) has emerged as a setting for developing
general agents in an unsupervised manner, capable of solving downstream tasks
without additional training or planning at test-time. Unlike conventional RL,
which optimizes policies for a fixed reward, zero-shot RL requires agents to
encode representations rich enough to support immediate adaptation to any
objective, drawing parallels to vision and language foundation models. Despite
growing interest, the field lacks a common analytical lens.
  We present the first unified framework for zero-shot RL. Our formulation
introduces a consistent notation and taxonomy that organizes existing
approaches and allows direct comparison between them. Central to our framework
is the classification of algorithms into two families: direct representations,
which learn end-to-end mappings from rewards to policies, and compositional
representations, which decompose the representation leveraging the substructure
of the value function. Within this framework, we highlight shared principles
and key differences across methods, and we derive an extended bound for
successor-feature methods, offering a new perspective on their performance in
the zero-shot regime. By consolidating existing work under a common lens, our
framework provides a principled foundation for future research in zero-shot RL
and outlines a clear path toward developing more general agents.

</details>


### [31] [Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process](https://arxiv.org/abs/2510.20736)
*Tsai Hor Chan,Feng Wu,Yihang Chen,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 본 논문에서는 다양한 모달리티를 효과적으로 융합하는 새로운 방법론을 제안하며, 특히 Dirichlet 과정 기반의 모델을 통해 모달리티 간 상호작용과 각 모달리티의 표현력을 최적화합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 시나리오에서 모달리티 융합 접근 방식을 효과적으로 개발하는 것이 점점 더 중요해지고 있습니다.

Method: Dirichlet 과정 혼합 모델(DP)을 활용하여 각 모달리티에서의 주요 특징을 증대시키고 최적의 균형을 이루는 새로운 다중 모달 학습 프레임워크를 제안합니다.

Result: 다수의 다중 모달 데이터셋에서 실험을 통해 제안한 모델이 경쟁 모델보다 우수한 성능을 보임을 입증합니다.

Conclusion: Ablation 분석을 통해 DP의 효과성과 주요 하이퍼파라미터 변화에 대한 강인성을 검증합니다.

Abstract: Developing effective multimodal fusion approaches has become increasingly
essential in many real-world scenarios, such as health care and finance. The
key challenge is how to preserve the feature expressiveness in each modality
while learning cross-modal interactions. Previous approaches primarily focus on
the cross-modal alignment, while over-emphasis on the alignment of marginal
distributions of modalities may impose excess regularization and obstruct
meaningful representations within each modality. The Dirichlet process (DP)
mixture model is a powerful Bayesian non-parametric method that can amplify the
most prominent features by its richer-gets-richer property, which allocates
increasing weights to them. Inspired by this unique characteristic of DP, we
propose a new DP-driven multimodal learning framework that automatically
achieves an optimal balance between prominent intra-modal representation
learning and cross-modal alignment. Specifically, we assume that each modality
follows a mixture of multivariate Gaussian distributions and further adopt DP
to calculate the mixture weights for all the components. This paradigm allows
DP to dynamically allocate the contributions of features and select the most
prominent ones, leveraging its richer-gets-richer property, thus facilitating
multimodal feature fusion. Extensive experiments on several multimodal datasets
demonstrate the superior performance of our model over other competitors.
Ablation analysis further validates the effectiveness of DP in aligning
modality distributions and its robustness to changes in key hyperparameters.
Code is anonymously available at https://github.com/HKU-MedAI/DPMM.git

</details>


### [32] [MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs](https://arxiv.org/abs/2510.20762)
*Jan Sobotka,Luca Baroni,Ján Antolík*

Main category: cs.LG

TL;DR: MEIcoder는 신경 집단 활동에서 시각 자극을 복원하는 데 있어 최첨단 성능을 달성한 생물학적으로 정보를 활용한 디코딩 방법이다.


<details>
  <summary>Details</summary>
Motivation: 생물학적 데이터가 드물고, 특히 영장류나 인간의 경우 높은 처리량 기록 기술 적용이 어려워, 시각 자극 디코딩을 위한 새로운 방법이 필요하다.

Method: MEIcoder는 뉴런 특화된 가장 흥미로운 입력(MEIs), 구조적 유사성 지수 측정 손실, 적대적 훈련을 활용하여 디코딩을 수행한다.

Result: MEIcoder는 초등 시각 피질(V1)에서 단일 세포 활동으로부터 시각 자극을 복원하는 데 있어 최첨단 성능을 보여준다.

Conclusion: MEIcoder는 초기 시각 시스템에서 신뢰할 수 있는 디코딩의 실현 가능성을 보여주며 신경 과학 및 신경 공학 응용에 대한 실용적인 통찰을 제공한다.

Abstract: Decoding visual stimuli from neural population activity is crucial for
understanding the brain and for applications in brain-machine interfaces.
However, such biological data is often scarce, particularly in primates or
humans, where high-throughput recording techniques, such as two-photon imaging,
remain challenging or impossible to apply. This, in turn, poses a challenge for
deep learning decoding techniques. To overcome this, we introduce MEIcoder, a
biologically informed decoding method that leverages neuron-specific most
exciting inputs (MEIs), a structural similarity index measure loss, and
adversarial training. MEIcoder achieves state-of-the-art performance in
reconstructing visual stimuli from single-cell activity in primary visual
cortex (V1), especially excelling on small datasets with fewer recorded
neurons. Using ablation studies, we demonstrate that MEIs are the main drivers
of the performance, and in scaling experiments, we show that MEIcoder can
reconstruct high-fidelity natural-looking images from as few as 1,000-2,500
neurons and less than 1,000 training data points. We also propose a unified
benchmark with over 160,000 samples to foster future research. Our results
demonstrate the feasibility of reliable decoding in early visual system and
provide practical insights for neuroscience and neuroengineering applications.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [33] [CourtGuard: A Local, Multiagent Prompt Injection Classifier](https://arxiv.org/abs/2510.19844)
*Isaac Wu,Michael Maslowski*

Main category: cs.CR

TL;DR: 이 논문은 프롬프트 주입 공격에 대한 방어 시스템인 CourtGuard를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델이 다양한 민감한 애플리케이션에 통합됨에 따라, 프롬프트 주입 공격의 위험이 증가하고 있다.

Method: CourtGuard는 '변호인', '검사', '판사' 모델이 포함된 다중 에이전트 시스템을 사용하여 프롬프트를 평가한다.

Result: CourtGuard는 Direct Detector보다 낮은 거짓 긍정 비율을 보여주지만, 일반적으로는 프롬프트 주입 탐지 성능이 떨어진다.

Conclusion: CourtGuard의 성능 비교는 프롬프트 분류에서 공격적 및 무해한 시나리오를 모두 고려하는 중요성을 강조한다.

Abstract: As large language models (LLMs) become integrated into various sensitive
applications, prompt injection, the use of prompting to induce harmful
behaviors from LLMs, poses an ever increasing risk. Prompt injection attacks
can cause LLMs to leak sensitive data, spread misinformation, and exhibit
harmful behaviors. To defend against these attacks, we propose CourtGuard, a
locally-runnable, multiagent prompt injection classifier. In it, prompts are
evaluated in a court-like multiagent LLM system, where a "defense attorney"
model argues the prompt is benign, a "prosecution attorney" model argues the
prompt is a prompt injection, and a "judge" model gives the final
classification. CourtGuard has a lower false positive rate than the Direct
Detector, an LLM as-a-judge. However, CourtGuard is generally a worse prompt
injection detector. Nevertheless, this lower false positive rate highlights the
importance of considering both adversarial and benign scenarios for the
classification of a prompt. Additionally, the relative performance of
CourtGuard in comparison to other prompt injection classifiers advances the use
of multiagent systems as a defense against prompt injection attacks. The
implementations of CourtGuard and the Direct Detector with full prompts for
Gemma-3-12b-it, Llama-3.3-8B, and Phi-4-mini-instruct are available at
https://github.com/isaacwu2000/CourtGuard.

</details>


### [34] [Model Context Contracts - MCP-Enabled Framework to Integrate LLMs With Blockchain Smart Contracts](https://arxiv.org/abs/2510.19856)
*Eranga Bandara,Sachin Shetty,Ravi Mukkamala,Ross Gore,Peter Foytik,Safdar H. Bouk,Abdul Rahman,Xueping Liang,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.CR

TL;DR: 블록체인과 LLM(대형 언어 모델) 통합을 위한 '모델 컨텍스트 계약(MCC)' 프레임워크를 제안.


<details>
  <summary>Details</summary>
Motivation: 블록체인과 LLM의 통합이 이러한 기술의 가능한 활용도를 높이기 위한 필요성이 증가하고 있다.

Method: MCC 프레임워크를 통해 LLM이 블록체인 스마트 계약과 직접 상호작용하도록 함.

Result: MCC는 사용자와 블록체인 네트워크 간의 역동적이고 맥락 인식 상호작용을 가능하게 한다.

Conclusion: MCC는 LLM과 블록체인 통합에 대한 최초의 접근 방식을 제공한다.

Abstract: In recent years, blockchain has experienced widespread adoption across
various industries, becoming integral to numerous enterprise applications.
Concurrently, the rise of generative AI and LLMs has transformed human-computer
interactions, offering advanced capabilities in understanding and generating
human-like text. The introduction of the MCP has further enhanced AI
integration by standardizing communication between AI systems and external data
sources. Despite these advancements, there is still no standardized method for
seamlessly integrating LLM applications and blockchain. To address this
concern, we propose "MCC: Model Context Contracts" a novel framework that
enables LLMs to interact directly with blockchain smart contracts through
MCP-like protocol. This integration allows AI agents to invoke blockchain smart
contracts, facilitating more dynamic and context-aware interactions between
users and blockchain networks. Essentially, it empowers users to interact with
blockchain systems and perform transactions using queries in natural language.
Within this proposed architecture, blockchain smart contracts can function as
intelligent agents capable of recognizing user input in natural language and
executing the corresponding transactions. To ensure that the LLM accurately
interprets natural language inputs and maps them to the appropriate MCP
functions, the LLM was fine-tuned using a custom dataset comprising user inputs
paired with their corresponding MCP server functions. This fine-tuning process
significantly improved the platform's performance and accuracy. To validate the
effectiveness of MCC, we have developed an end-to-end prototype implemented on
the Rahasak blockchain with the fine-tuned Llama-4 LLM. To the best of our
knowledge, this research represents the first approach to using the concept of
Model Context Protocol to integrate LLMs with blockchain.

</details>


### [35] [GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?](https://arxiv.org/abs/2510.20333)
*Chiyu Chen,Xinhao Song,Yunkai Chai,Yang Yao,Haodong Zhao,Lijun Li,Jie Li,Yan Teng,Gongshen Liu,Yingchun Wang*

Main category: cs.CR

TL;DR: Vision-Language Models가 환경적 주입 공격에 대해 취약하다는 것을 보여주는 GhostEI-Bench라는 새로운 벤치마크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 모바일 그래픽 사용자 인터페이스에서 비전-언어 모델의 안전성을 평가하기 위한 필요성과 환경적 주입이라는 새로운 위협 벡터의 탐색.

Method: GhostEI-Bench를 사용해 실제 안드로이드 에뮬레이터 내에서 적대적 이벤트를 주입하고, 모델의 성능을 평가한다.

Result: 현재 사용되는 비전-언어 모델들은 조작된 UI를 인식하고 이해하는 데 있어 심각한 취약점을 보여준다.

Conclusion: GhostEI-Bench는 이러한 위협을 정량화하고 완화할 수 있는 프레임워크를 제공하며, 강력하고 안전한 에이전트를 위한 기초를 마련한다.

Abstract: Vision-Language Models (VLMs) are increasingly deployed as autonomous agents
to navigate mobile graphical user interfaces (GUIs). Operating in dynamic
on-device ecosystems, which include notifications, pop-ups, and inter-app
interactions, exposes them to a unique and underexplored threat vector:
environmental injection. Unlike prompt-based attacks that manipulate textual
instructions, environmental injection corrupts an agent's visual perception by
inserting adversarial UI elements (for example, deceptive overlays or spoofed
notifications) directly into the GUI. This bypasses textual safeguards and can
derail execution, causing privacy leakage, financial loss, or irreversible
device compromise. To systematically evaluate this threat, we introduce
GhostEI-Bench, the first benchmark for assessing mobile agents under
environmental injection attacks within dynamic, executable environments. Moving
beyond static image-based assessments, GhostEI-Bench injects adversarial events
into realistic application workflows inside fully operational Android emulators
and evaluates performance across critical risk scenarios. We further propose a
judge-LLM protocol that conducts fine-grained failure analysis by reviewing the
agent's action trajectory alongside the corresponding screenshot sequence,
pinpointing failure in perception, recognition, or reasoning. Comprehensive
experiments on state-of-the-art agents reveal pronounced vulnerability to
deceptive environmental cues: current models systematically fail to perceive
and reason about manipulated UIs. GhostEI-Bench provides a framework for
quantifying and mitigating this emerging threat, paving the way toward more
robust and secure embodied agents.

</details>


### [36] [NeuPerm: Disrupting Malware Hidden in Neural Network Parameters by Leveraging Permutation Symmetry](https://arxiv.org/abs/2510.20367)
*Daniel Gilkarov,Ran Dubin*

Main category: cs.CR

TL;DR: 사전 학습된 딥러닝 모델 공유는 연구자와 기업에 큰 가치를 제공하지만, 악의적인 목적으로 모델을 이용한 사이버 위협에 노출됩니다. 이 논문에서는 신경망 순열 대칭의 이론적 특성을 활용하여 악성 코드를 방해하는 NeuPerm이라는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 사전 학습된 딥러닝 모델 공유는 새로운 모델을 훈련시키는 비용의 일부로 연구자들과 기업들이 딥러닝을 적용할 수 있게 합니다. 그러나 모델 공유는 사용자가 악의적인 목적으로 모델을 사용하는 사이버 위협에 노출됩니다.

Method: NeuPerm는 신경망 순열 대칭의 이론적 특성을 활용하여 이러한 악성 코드를 방해하는 간단하면서도 효과적인 방법입니다.

Result: 우리의 방법은 모델 성능에 거의 영향을 미치지 않으며, 이전에 고급 복잡한 과정인 양자화를 통해서만 다루어졌던 최첨단 공격을 성공적으로 방해함을 경험적으로 보여줍니다.

Conclusion: NeuPerm는 LLMs에서 작동하는 것으로 나타났으며, 이는 이전의 유사한 연구들이 달성하지 못한 성과입니다.

Abstract: Pretrained deep learning model sharing holds tremendous value for researchers
and enterprises alike. It allows them to apply deep learning by fine-tuning
models at a fraction of the cost of training a brand-new model. However, model
sharing exposes end-users to cyber threats that leverage the models for
malicious purposes. Attackers can use model sharing by hiding self-executing
malware inside neural network parameters and then distributing them for
unsuspecting users to unknowingly directly execute them, or indirectly as a
dependency in another software. In this work, we propose NeuPerm, a simple yet
effec- tive way of disrupting such malware by leveraging the theoretical
property of neural network permutation symmetry. Our method has little to no
effect on model performance at all, and we empirically show it successfully
disrupts state-of-the-art attacks that were only previously addressed using
quantization, a highly complex process. NeuPerm is shown to work on LLMs, a
feat that no other previous similar works have achieved. The source code is
available at https://github.com/danigil/NeuPerm.git.

</details>


### [37] [AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning in SDN](https://arxiv.org/abs/2510.20566)
*Wei Shao,Yuhao Wang,Rongguang He,Muhammad Ejaz Ahmed,Seyit Camtepe*

Main category: cs.CR

TL;DR: AdaDoS는 적대적 강화 학습을 기반으로 하는 적응형 공격 모델로, 기존 DoS 탐지기를 회피하며 네트워크 작업을 방해할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 기존의 방어 메커니즘이 DoS 공격에 대해 효과적이지만, AI 기반의 기술의 출현으로 인해 새로운 보안 도전 과제가 불거지고 있다.

Method: AdaDoS는 공격자와 탐지자 간의 경쟁 게임으로 문제를 모델링하고, SDN과 탐지기로부터의 피드백을 기반으로 공격 전략을 동적으로 조정한다. 또한, POMDP를 활용하여 공격자는 지연 정보만 갖고 있으며, 학생 에이전트가 교사 에이전트로부터 학습하여 성능을 향상시킨다.

Result: AdaDoS는 머신러닝 및 규칙 기반 탐지기를 적응적으로 회피할 수 있는 DoS 공격 시퀀스를 개발하는 첫 번째 사례로, 강화 학습을 적용하였다.

Conclusion: AdaDoS는 현재 DoS 탐지기를 효과적으로 우회하면서 공격을 수행할 수 있는 혁신적인 방법을 제안한다.

Abstract: Existing defence mechanisms have demonstrated significant effectiveness in
mitigating rule-based Denial-of-Service (DoS) attacks, leveraging predefined
signatures and static heuristics to identify and block malicious traffic.
However, the emergence of AI-driven techniques presents new challenges to SDN
security, potentially compromising the efficacy of existing defence mechanisms.
In this paper, we introduce~AdaDoS, an adaptive attack model that disrupt
network operations while evading detection by existing DoS-based detectors
through adversarial reinforcement learning (RL). Specifically, AdaDoS models
the problem as a competitive game between an attacker, whose goal is to
obstruct network traffic without being detected, and a detector, which aims to
identify malicious traffic. AdaDoS can solve this game by dynamically adjusting
its attack strategy based on feedback from the SDN and the detector.
Additionally, recognising that attackers typically have less information than
defenders, AdaDoS formulates the DoS-like attack as a partially observed Markov
decision process (POMDP), with the attacker having access only to delay
information between attacker and victim nodes. We address this challenge with a
novel reciprocal learning module, where the student agent, with limited
observations, enhances its performance by learning from the teacher agent, who
has full observational capabilities in the SDN environment. AdaDoS represents
the first application of RL to develop DoS-like attack sequences, capable of
adaptively evading both machine learning-based and rule-based DoS-like attack
detectors.

</details>


### [38] [Decentralized Exchange that Mitigate a Bribery Attack](https://arxiv.org/abs/2510.20645)
*Nitin Awathare*

Main category: cs.CR

TL;DR: HTLC(해시 시간 잠금 계약)의 보안성을 개선하고자 하는 연구로서, miner-collusion 뇌물 공격을 분석하고 새로운 HTLC 프로토콜인 \prot을 제안한다.


<details>
  <summary>Details</summary>
Motivation: HTLC의 사용이 여전히 의문시되는 이유는 인센티브 비일관성과 뇌물 공격에 대한 취약성 때문이다.

Method: 게임 이론적 접근을 통해 miner-collusion 뇌물 공격을 분석하고, 이를 바탕으로 \prot이라는 새로운 HTLC 프로토콜을 제안한다.

Result: 제안된 \prot는 모든 뇌물 시나리오에 저항력을 가지며, 비트코인과 이더리움에 대한 구현을 통해 거래 비용과 지연 시간을 최적화함을 보인다.

Conclusion: HTLC 시스템의 보안을 강화하기 위해, \prot는 두 단계 접근 방식을 통해 제3자의 무단 토큰 압수를 방지한다.

Abstract: Despite the popularity of Hashed Time-Locked Contracts (HTLCs) because of
their use in wide areas of applications such as payment channels, atomic swaps,
etc, their use in exchange is still questionable. This is because of its
incentive incompatibility and susceptibility to bribery attacks.
  State-of-the-art solutions such as MAD-HTLC (Oakland'21) and He-HTLC
(NDSS'23) address this by leveraging miners' profit-driven behaviour to
mitigate such attacks. The former is the mitigation against passive miners;
however, the latter works against both active and passive miners. However, they
consider only two bribing scenarios where either of the parties involved in the
transfer collude with the miner.
  In this paper, we expose vulnerabilities in state-of-the-art solutions by
presenting a miner-collusion bribery attack with implementation and
game-theoretic analysis. Additionally, we propose a stronger attack on MAD-HTLC
than He-HTLC, allowing the attacker to earn profits equivalent to attacking
naive HTLC.
  Leveraging our insights, we propose \prot, a game-theoretically secure HTLC
protocol resistant to all bribery scenarios. \prot\ employs a two-phase
approach, preventing unauthorized token confiscation by third parties, such as
miners. In Phase 1, parties commit to the transfer; in Phase 2, the transfer is
executed without manipulation. We demonstrate \prot's efficiency in transaction
cost and latency via implementations on Bitcoin and Ethereum.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [39] [Communication to Completion: Modeling Collaborative Workflows with Intelligent Multi-Agent Communication](https://arxiv.org/abs/2510.19995)
*Yiming Lu,Xun Wang,Simin Ma,Shujian Liu,Sathish Reddy Indurthi,Song Wang,Haoyun Deng,Fei Liu,Kaiqiang Song*

Main category: cs.MA

TL;DR: C2C는 복합 작업을 위한 다중 에이전트 시스템의 커뮤니케이션 효율성을 높이는 확장 가능한 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업을 위한 팀워크에는 다양한 커뮤니케이션 전략이 필요하지만 현재의 다중 에이전트 LLM 시스템은 작업 지향적 커뮤니케이션을 위한 체계적인 프레임워크가 부족하다.

Method: 우리는 Alignment Factor(AF)라는 새로운 지표와 단계별 실행과 지능형 커뮤니케이션 결정을 통합하는 Sequential Action Framework를 통해 C2C를 제안한다.

Result: C2C는 5에서 17명의 에이전트로 구성된 팀과 다양한 복잡성 수준에서 실제 코딩 워크플로우를 평가한 결과, 작업 완료 시간을 약 40% 단축시키며 허용 가능한 통신 비용을 유지한다.

Conclusion: C2C는 다중 에이전트 시스템에서 커뮤니케이션 효과성을 측정하기 위한 이론적 기초와 복잡한 협업 작업을 위한 실용적인 프레임워크를 수립한다.

Abstract: Teamwork in workspace for complex tasks requires diverse communication
strategies, but current multi-agent LLM systems lack systematic frameworks for
task oriented communication. We introduce Communication to Completion (C2C), a
scalable framework that addresses this gap through two key innovations: (1) the
Alignment Factor (AF), a novel metric quantifying agent task alignment that
directly impacts work efficiency, and (2) a Sequential Action Framework that
integrates stepwise execution with intelligent communication decisions. C2C
enables agents to make cost aware communication choices, dynamically improving
task understanding through targeted interactions. We evaluated C2C on realistic
coding workflows across three complexity tiers and team sizes from 5 to 17
agents, comparing against no communication and fixed steps baselines. The
results show that C2C reduces the task completion time by about 40% with
acceptable communication costs. The framework completes all tasks successfully
in standard configurations and maintains effectiveness at scale. C2C
establishes both a theoretical foundation for measuring communication
effectiveness in multi-agent systems and a practical framework for complex
collaborative tasks.

</details>


### [40] [High-order Interactions Modeling for Interpretable Multi-Agent Q-Learning](https://arxiv.org/abs/2510.20218)
*Qinyu Xu,Yuanyang Zhu,Xuefei Wu,Chunlin Chen*

Main category: cs.MA

TL;DR: 이 논문에서는 복잡한 협력 메커니즘을 모델링하기 위한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습에서 에이전트 간 상호작용 모델링은 효과적인 조정 및 협력 메커니즘 이해에 필수적입니다.

Method: Continued Fraction Q-Learning (QCoFr)라는 새로운 값 분해 프레임워크를 제안하며, 이는 에이전트 수에 따라 선형 복잡도로 임의 차수의 상호작용을 포착할 수 있습니다.

Result: QCoFr는 일관되게 더 나은 성능을 달성하며, 이론적 분석과 일치하는 해석 가능성을 제공합니다.

Conclusion: QCoFr는 근본적으로 협력 및 해석 가능성을 향상시킵니다.

Abstract: The ability to model interactions among agents is crucial for effective
coordination and understanding their cooperation mechanisms in multi-agent
reinforcement learning (MARL). However, previous efforts to model high-order
interactions have been primarily hindered by the combinatorial explosion or the
opaque nature of their black-box network structures. In this paper, we propose
a novel value decomposition framework, called Continued Fraction Q-Learning
(QCoFr), which can flexibly capture arbitrary-order agent interactions with
only linear complexity $\mathcal{O}\left({n}\right)$ in the number of agents,
thus avoiding the combinatorial explosion when modeling rich cooperation.
Furthermore, we introduce the variational information bottleneck to extract
latent information for estimating credits. This latent information helps agents
filter out noisy interactions, thereby significantly enhancing both cooperation
and interpretability. Extensive experiments demonstrate that QCoFr not only
consistently achieves better performance but also provides interpretability
that aligns with our theoretical analysis.

</details>


### [41] [Structures generated in a multiagent system performing information fusion in peer-to-peer resource-constrained networks](https://arxiv.org/abs/2510.20469)
*Horacio Paggi,Juan A. Lara,Javier Soriano*

Main category: cs.MA

TL;DR: 정보 융합이 전통적인 군사 응용 분야에서의 위계적 절차에서 더 유연한 협력적 접근 방식으로 변화하고 있으며, 이로 인해 비군사 분야와 인간-기계 간의 의사소통에서 홀로닉 구조의 중요성이 증가하고 있다.


<details>
  <summary>Details</summary>
Motivation: 정보 융합의 패러다임 변화가 비군사 분야 및 기계 간 통신의 필요로 인해 추진되고 있다.

Method: 완전 상호 통신하는 요소(또는 동료)를 기반으로 자원 제약(에너지, 메시지, 시간 등)이 있을 때 홀로닉 구조가 생성되는 과정을 다룬다.

Result: 홀로닉 구조의 일반적인 형태와 멀티 에이전트 시스템 모델에 기반한 동작 예시를 제공한다.

Conclusion: 홀로닉 구조는 환경 변화에 대한 적응성, 자율성 및 공동 목표 달성을 위한 협력 능력을 갖춘 장점을 가진다.

Abstract: There has recently been a major advance with respect to how information
fusion is performed. Information fusion has gone from being conceived as a
purely hierarchical procedure, as is the case of traditional military
applications, to now being regarded collaboratively, as holonic fusion, which
is better suited for civil applications and edge organizations. The above
paradigm shift is being boosted as information fusion gains ground in different
non-military areas, and human-computer and machine-machine communications,
where holarchies, which are more flexible structures than ordinary, static
hierarchies, become more widespread. This paper focuses on showing how holonic
structures tend to be generated when there are constraints on resources
(energy, available messages, time, etc.) for interactions based on a set of
fully intercommunicating elements (peers) whose components fuse information as
a means of optimizing the impact of vagueness and uncertainty present message
exchanges. Holon formation is studied generically based on a multiagent system
model, and an example of its possible operation is shown. Holonic structures
have a series of advantages, such as adaptability, to sudden changes in the
environment or its composition, are somewhat autonomous and are capable of
cooperating in order to achieve a common goal. This can be useful when the
shortage of resources prevents communications or when the system components
start to fail.

</details>
