<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 14]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.LG](#cs.LG) [Total: 23]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment](https://arxiv.org/abs/2510.08847)
*Allison Sihan Jia,Daniel Huang,Nikhil Vytla,Nirvika Choudhury,John C Mitchell,Anupam Datta*

Main category: cs.AI

TL;DR: Agent GPA 프레임워크를 소개하며, 에이전트의 목표 설정, 계획 수립 및 행동 실행에 기반한 평가 패러다임을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트의 성능을 평가하는 효과적인 방법을 제공하기 위해.

Method: Agent GPA 프레임워크는 목표 달성, 논리적 일관성, 실행 효율성, 계획 품질 및 계획 준수의 다섯 가지 평가 지표를 포함한다.

Result: 프레임워크는 두 개의 벤치마크 데이터세트에서 실험 결과를 통해 에이전트 실패의 다양한 범위를 포괄하는 체계적인 방법을 제공한다.

Conclusion: 에이전트의 성능 개선을 위한 목표 설정과 에러 로컬라이징 기능을 포함하여, LLM-판별자와 강한 일치를 보인다.

Abstract: We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation
paradigm based on an agent's operational loop of setting goals, devising plans,
and executing actions. The framework includes five evaluation metrics: Goal
Fulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan
Adherence. Logical Consistency checks that an agent's actions are consistent
with its prior actions. Execution Efficiency checks whether the agent executes
in the most efficient way to achieve its goal. Plan Quality checks whether an
agent's plans are aligned with its goals; Plan Adherence checks if an agent's
actions are aligned with its plan; and Goal Fulfillment checks that agent's
final outcomes match the stated goals. Our experimental results on two
benchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for
a production-grade data agent - show that this framework (a) provides a
systematic way to cover a broad range of agent failures, including all agent
errors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that
exhibit strong agreement with human annotation, covering 80% to over 95%
errors; and (c) localizes errors with 86% agreement to enable targeted
improvement of agent performance.

</details>


### [2] [Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents](https://arxiv.org/abs/2510.08619)
*Tennison Liu,Silas Ruhrberg Estévez,David L. Bentley,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 이 논문에서는 대규모 과학 데이터 세트를 활용하여 가설 탐색(hypothesis hunting)을 지원하는 AScience라는 프레임워크를 소개하고, heterogeneous 행동을 가진 LLM 기반 연구 에이전트의 분산 시스템인 ASCollab을 구현하였다.


<details>
  <summary>Details</summary>
Motivation: 대규모 과학 데이터 세트를 통해 특정 연구 질문에 얽매이지 않은 탐색적 발견의 기회를 창출하고자 한다.

Method: AGSCience 프레임워크는 에이전트, 네트워크, 평가 기준 간의 상호작용으로 발견을 모델링하며, ASCollab이라는 분산 시스템으로 구현된다.

Result: 이 시스템은 전문가 평가 결과를 누적하고, 잘 알려진 바이오마커의 재발견, 기존 경로의 확장, 새로운 치료 목표의 제안을 포함한 결과들을 지속적으로 생성하고 동료 검토를 통해 공유한다.

Conclusion: 사회적 구조화된 에이전트 네트워크는 대규모에서 탐색적 가설 탐색을 유지할 수 있는 가능성을 보여준다.

Abstract: Large-scale scientific datasets -- spanning health biobanks, cell atlases,
Earth reanalyses, and more -- create opportunities for exploratory discovery
unconstrained by specific research questions. We term this process hypothesis
hunting: the cumulative search for insight through sustained exploration across
vast and complex hypothesis spaces. To support it, we introduce AScience, a
framework modeling discovery as the interaction of agents, networks, and
evaluation norms, and implement it as ASCollab, a distributed system of
LLM-based research agents with heterogeneous behaviors. These agents
self-organize into evolving networks, continually producing and peer-reviewing
findings under shared standards of evaluation. Experiments show that such
social dynamics enable the accumulation of expert-rated results along the
diversity-quality-novelty frontier, including rediscoveries of established
biomarkers, extensions of known pathways, and proposals of new therapeutic
targets. While wet-lab validation remains indispensable, our experiments on
cancer cohorts demonstrate that socially structured, agentic networks can
sustain exploratory hypothesis hunting at scale.

</details>


### [3] [Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation](https://arxiv.org/abs/2510.08713)
*Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann*

Main category: cs.AI

TL;DR: UniWM은 실행 결정과 시각적으로 상상된 결과 간의 긴밀한 정렬을 보장하여 내비게이션 성공률을 30%까지 향상시키고, 경로 오류를 줄이며, TartanDrive 데이터셋에서 제로샷 일반화 능력을 보여줌으로써 통합된 자아 중심 내비게이션을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 신체화된 에이전트가 미래 상태를 효과적으로 상상하는 것은 견고하고 일반화 가능한 시각적 내비게이션을 위해 필수적이다.

Method: UniWM은 자아 중심 시각 예측 및 계획을 단일 다중 모달 자가 회귀 백본으로 통합하는 메모리 보강된 세계 모델이다.

Result: UniWM은 내비게이션 성공률을 30%까지 향상시키고, 강력한 기준 모델에 비해 경로 오류를 현저히 줄였다.

Conclusion: 이 결과는 통합된 상상 기반의 신체화된 내비게이션을 향한 중요한 단계를 강조한다.

Abstract: Enabling embodied agents to effectively imagine future states is critical for
robust and generalizable visual navigation. Current state-of-the-art
approaches, however, adopt modular architectures that separate navigation
planning from visual world modeling, leading to state-action misalignment and
limited adaptability in novel or dynamic scenarios. To overcome this
fundamental limitation, we propose UniWM, a unified, memory-augmented world
model integrating egocentric visual foresight and planning within a single
multimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly
grounds action decisions in visually imagined outcomes, ensuring tight
alignment between prediction and control. A hierarchical memory mechanism
further integrates detailed short-term perceptual cues with longer-term
trajectory context, enabling stable, coherent reasoning over extended horizons.
Extensive experiments across four challenging benchmarks (Go Stanford, ReCon,
SCAND, HuRoN) demonstrate that UniWM substantially improves navigation success
rates by up to 30%, significantly reduces trajectory errors compared to strong
baselines, and exhibits impressive zero-shot generalization on the unseen
TartanDrive dataset. These results highlight UniWM as a principled step toward
unified, imagination-driven embodied navigation.

</details>


### [4] [COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context](https://arxiv.org/abs/2510.08790)
*Guangya Wan,Mingyang Ling,Xiaoqi Ren,Rujun Han,Sheng Li,Zizhao Zhang*

Main category: cs.AI

TL;DR: COMPASS는 LLM 에이전트의 지속적인 추론과 도구 상호작용을 개선하기 위한 경량의 계층적 프레임워크로, 전략적 감독과 맥락 조직을 전문화된 구성 요소로 분리하여 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 긴 작업을 처리하는 데 있어 발생하는 오류가 누적되는 문제를 해결하고자 한다.

Method: COMPASS는 세 가지 전문화된 구성 요소(주 에이전트, 메타 씽커, 맥락 관리자)로 구성된 경량 계층적 프레임워크를 제안한다.

Result: COMPASS는 GAIA, BrowseComp, Humanity's Last Exam의 세 가지 벤치마크에서 정확성을 최대 20% 향상시켰다.

Conclusion: COMPASS는 테스트 시간 확장 및 훈련 후 파이프라인을 통해 성능을 높이고 효율성을 향상시킨다.

Abstract: Long-horizon tasks that require sustained reasoning and multiple tool
interactions remain challenging for LLM agents: small errors compound across
steps, and even state-of-the-art models often hallucinate or lose coherence. We
identify context management as the central bottleneck -- extended histories
cause agents to overlook critical evidence or become distracted by irrelevant
information, thus failing to replan or reflect from previous mistakes. To
address this, we propose COMPASS (Context-Organized Multi-Agent Planning and
Strategy System), a lightweight hierarchical framework that separates tactical
execution, strategic oversight, and context organization into three specialized
components: (1) a Main Agent that performs reasoning and tool use, (2) a
Meta-Thinker that monitors progress and issues strategic interventions, and (3)
a Context Manager that maintains concise, relevant progress briefs for
different reasoning stages. Across three challenging benchmarks -- GAIA,
BrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20%
relative to both single- and multi-agent baselines. We further introduce a
test-time scaling extension that elevates performance to match established
DeepResearch agents, and a post-training pipeline that delegates context
management to smaller models for enhanced efficiency.

</details>


### [5] [LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition](https://arxiv.org/abs/2510.08928)
*Yushuo Zheng,Zicheng Zhang,Xiongkuo Min,Huiyu Duan,Guangtao Zhai*

Main category: cs.AI

TL;DR: LM Fight Arena는 대형 멀티모달 모델을 평가하기 위한 새로운 프레임워크로, 격투 게임 Mortal Kombat II를 사용하여 모델 간의 성능을 비교한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 대형 멀티모달 모델 벤치마크는 실시간, 적대적 환경에서의 성능을 포착하는 데 실패하는 경우가 많다.

Method: LM Fight Arena 프레임워크를 통해, 모델들은 Mortal Kombat II에서 같은 캐릭터를 조종하며 서로 대결하여 평가된다.

Result: 여섯 개의 주요 오픈 및 클로즈드 소스 모델을 테스트하였고, 각 모델은 게임 프레임과 상태 데이터를 해석하여 다음 행동을 선택하도록 유도되었다.

Conclusion: 이 연구는 AI 평가와 인터랙티브 엔터테인먼트 간의 간극을 연결하는 도전적이고 매력적인 벤치마크를 제시한다.

Abstract: Existing benchmarks for large multimodal models (LMMs) often fail to capture
their performance in real-time, adversarial environments. We introduce LM Fight
Arena (Large Model Fight Arena), a novel framework that evaluates LMMs by
pitting them against each other in the classic fighting game Mortal Kombat II,
a task requiring rapid visual understanding and tactical, sequential
decision-making. In a controlled tournament, we test six leading open- and
closed-source models, where each agent operates controlling the same character
to ensure a fair comparison. The models are prompted to interpret game frames
and state data to select their next actions. Unlike static evaluations, LM
Fight Arena provides a fully automated, reproducible, and objective assessment
of an LMM's strategic reasoning capabilities in a dynamic setting. This work
introduces a challenging and engaging benchmark that bridges the gap between AI
evaluation and interactive entertainment.

</details>


### [6] [EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory](https://arxiv.org/abs/2510.08958)
*Zirui Liao*

Main category: cs.AI

TL;DR: EcphoryRAG는 엔티티 중심의 지식 그래프 RAG 프레임워크로, 동적 관계 추론을 통해 효율적인 다중 홉 검색을 수행합니다.


<details>
  <summary>Details</summary>
Motivation: 인간은 복잡하고 다중 홉 회상에 필요한 엔티티 중심의 기억 흔적을 활성화하는 단서를 활용합니다.

Method: EcphoryRAG는 코어 엔티티와 메타데이터를 추출하고 저장하여 토큰 소비를 최대 94%까지 줄이는 가벼운 접근 방식을 사용하며, 쿼리에서 단서 엔티티를 추출한 후 지식 그래프 내에서 규모가 큰 다중 홉 연상 검색을 수행합니다.

Result: EcphoryRAG는 2WikiMultiHop, HotpotQA 및 MuSiQue 벤치마크에서 평균 Exact Match(EM) 점수를 0.392에서 0.474로 향상시켰습니다.

Conclusion: 이 결과는 복잡한 질문 답변을 위한 엔티티-단서-다중 홉 검색 패러다임의 효능을 검증합니다.

Abstract: Cognitive neuroscience research indicates that humans leverage cues to
activate entity-centered memory traces (engrams) for complex, multi-hop
recollection. Inspired by this mechanism, we introduce EcphoryRAG, an
entity-centric knowledge graph RAG framework. During indexing, EcphoryRAG
extracts and stores only core entities with corresponding metadata, a
lightweight approach that reduces token consumption by up to 94\% compared to
other structured RAG systems. For retrieval, the system first extracts cue
entities from queries, then performs a scalable multi-hop associative search
across the knowledge graph. Crucially, EcphoryRAG dynamically infers implicit
relations between entities to populate context, enabling deep reasoning without
exhaustive pre-enumeration of relationships. Extensive evaluations on the
2WikiMultiHop, HotpotQA, and MuSiQue benchmarks demonstrate that EcphoryRAG
sets a new state-of-the-art, improving the average Exact Match (EM) score from
0.392 to 0.474 over strong KG-RAG methods like HippoRAG. These results validate
the efficacy of the entity-cue-multi-hop retrieval paradigm for complex
question answering.

</details>


### [7] [DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction](https://arxiv.org/abs/2510.08959)
*Jinxin Shi,Zongsheng Cao,Runmin Ma,Yusong Hu,Jie Zhou,Xin Li,Lei Bai,Liang He,Bo Zhang*

Main category: cs.AI

TL;DR: DualResearch는 도구 집약적 추론을 위한 이중 그래프 모델을 기반으로 하여 복잡한 과학적 추론 문제를 해결하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 깊은 연구 프레임워크는 단일 대형 언어 모델의 한계로 인해 복잡한 과학적 추론에 있어 맥락 오염, 약한 증거 지원 및 불확실한 실행 경로와 같은 문제를 겪고 있다.

Method: DualResearch는 브레드스 세멘틱 그래프와 딥 카우절 그래프라는 두 개의 보완적인 그래프를 동시에 모델링하여 도구 집약적 추론의 인식 구조에 맞춘 검색 및 융합 프레임워크를 제안한다.

Result: DualResearch는 HLE와 GPQA 과학적 추론 벤치마크에서 경쟁력 있는 성능을 달성하며, 오픈 소스 시스템 InternAgent의 로그 파일을 활용하여 HLE에서 7.7%, GPQA에서 6.06%의 정확도 향상을 보인다.

Conclusion: DualResearch는 긴 멀티 툴 실행 로그를 간결한 추론 그래프로 압축하고, 안정적이며 효과적으로 답을 재구성할 수 있다.

Abstract: The deep-research framework orchestrates external tools to perform complex,
multi-step scientific reasoning that exceeds the native limits of a single
large language model. However, it still suffers from context pollution, weak
evidentiary support, and brittle execution paths. To address these issues, we
propose DualResearch, a retrieval and fusion framework that matches the
epistemic structure of tool-intensive reasoning by jointly modeling two
complementary graphs: a breadth semantic graph that encodes stable background
knowledge, and a depth causal graph that captures execution provenance. Each
graph has a layer-native relevance function, seed-anchored semantic diffusion
for breadth, and causal-semantic path matching with reliability weighting for
depth. To reconcile their heterogeneity and query-dependent uncertainty,
DualResearch converts per-layer path evidence into answer distributions and
fuses them in log space via an entropy-gated rule with global calibration. The
fusion up-weights the more certain channel and amplifies agreement. As a
complement to deep-research systems, DualResearch compresses lengthy multi-tool
execution logs into a concise reasoning graph, and we show that it can
reconstruct answers stably and effectively. On the scientific reasoning
benchmarks HLE and GPQA, DualResearch achieves competitive performance. Using
log files from the open-source system InternAgent, its accuracy improves by
7.7% on HLE and 6.06% on GPQA.

</details>


### [8] [RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows](https://arxiv.org/abs/2510.09021)
*Hamed Mahdavi,Pouria Mahdavinia,Samira Malek,Pegah Mohammadipour,Alireza Hashemi,Majid Daliri,Alireza Farhadi,Amir Khasahmadi,Niloofar Mireshghallah,Vasant Honavar*

Main category: cs.AI

TL;DR: 최신의 LLM들이 IMO 2025 문제를 해결하는 단계에 이르렀으며, 우리는 이 모델들이 증명 채점에 얼마나 잘 작동하는지 평가한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 발전을 고려하여 이들 모델이 증명을 채점하는 능력을 평가하고자 하였다.

Method: Gemini 2.5 Pro가 생성한 90개의 솔루션을 1-4 점 척도로 채점하고, IMO/USAMO 2025의 MathArena 솔루션 세트를 0-7 점 척도로 분석하였다.

Result: 모델은 부정확한 솔루션을 신뢰성 있게 구별할 수 있지만, 부분 점수 부여에 있어 불일치를 보였다.

Conclusion: 우리는 이러한 문제를 해결하기 위해 참조 솔루션을 추출하고 분석하는 에이전틱 작업 흐름을 도입하며, 채점 과정의 다양한 디자인 선택을 평가하고, 제안한 작업 흐름이 인간의 점수와 더 높은 일치를 이룬다는 것을 보여주었다.

Abstract: State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based
Olympiad problems to solving most of the IMO 2025 problems, with leading
systems reportedly handling 5 of 6 problems. Given this progress, we assess how
well these models can grade proofs: detecting errors, judging their severity,
and assigning fair scores beyond binary correctness. We study proof-analysis
capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we
grade on a 1-4 scale with detailed error annotations, and on MathArena solution
sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models
can reliably flag incorrect (including subtly incorrect) solutions but exhibit
calibration gaps in how partial credit is assigned. To address this, we
introduce agentic workflows that extract and analyze reference solutions and
automatically derive problem-specific rubrics for a multi-step grading process.
We instantiate and compare different design choices for the grading workflows,
and evaluate their trade-offs. Across our annotated corpus and MathArena, our
proposed workflows achieve higher agreement with human grades and more
consistent handling of partial credit across metrics. We release all code,
data, and prompts/logs to facilitate future research.

</details>


### [9] [Auto-scaling Continuous Memory for GUI Agent](https://arxiv.org/abs/2510.09038)
*Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang*

Main category: cs.AI

TL;DR: GUI 에이전트에 확장 가능한 메모리를 부여하여 낯선 인터페이스와 장기 과제를 일반화하는 방법을 연구한다. 기존 GUI 에이전트는 과거 경로를 텍스트 토큰으로 압축하여 문맥 길이를 증가시키고 결정적인 시각 단서를 놓친다. 우리는 각 GUI 경로를 고정 길이의 연속 임베딩 시퀀스로 인코딩하는 연속 메모리를 제안하며, 메모리 크기와 검색 깊이가 증가함에 따라 성능이 향상된다. 저비용으로 메모리를 확장하기 위해 자동 확장 데이터 플라이휠을 도입하고, 이를 통해 100k 이상의 경로를 수집하여 실제 GUI 벤치마크에서 성공률을 일관되게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 낯선 인터페이스와 장기 과제를 다루는 구간에서 GUI 에이전트의 성능을 개선할 필요가 있다.

Method: 각 GUI 경로를 고정 길이의 연속 임베딩 시퀀스로 인코딩하는 연속 메모리를 제안하고, 자동 확장 데이터 플라이휠을 사용하여 저비용으로 메모리를 확장한다.

Result: 100k 이상의 경로를 수집하고, 실제 GUI 벤치마크에서 성공률을 일관되게 향상시켰음.

Conclusion: Qwen-2.5-VL-7B와 같은 지속 메모리는 가장 최신의 폐쇄형 모델과 비교할 수 있는 성능을 달성하였다.

Abstract: We study how to endow GUI agents with scalable memory that help generalize
across unfamiliar interfaces and long-horizon tasks. Prior GUI agents compress
past trajectories into text tokens, which balloons context length and misses
decisive visual cues (e.g., exact widget size and position). We propose a
continuous memory that encodes each GUI trajectory into a fixed-length sequence
of continuous embeddings using the VLM itself as an encoder; these embeddings
are plugged directly into the backbone's input layer, sharply reducing context
cost while preserving fine-grained visual information. As memory size and
retrieval depth increase, performance improves monotonically, unlike text
memories that degrade with long prompts. To grow memory at low cost, we
introduce an auto-scaling data flywheel that (i) discovers new environments via
search, (ii) synthesizes tasks with an open-source VLM, (iii) rolls out
trajectories with the agent, and (iv) verifies success with the same VLM. Using
this pipeline, we collect 100k+ trajectories for about \$4000 and fine-tune
only the memory encoder (LoRA on a Q-Former, 1.2\% parameters) with 1,500
samples. On real-world GUI benchmarks, our memory-augmented agent consistently
improves success rates under long horizons and distribution shifts. Notably,
Qwen-2.5-VL-7B + continuous memory achieves performance comparable to
state-of-the-art closed-source models (e.g., GPT-4o, Claude-4).

</details>


### [10] [MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction](https://arxiv.org/abs/2510.09049)
*Joonghyuk Hahn,Soohan Lim,Yo-Sub Han*

Main category: cs.AI

TL;DR: 소스 코드의 복잡성을 예측하는 것은 소프트웨어 개발 및 알고리즘 분석에 필수적이다. MEC$^3$O라는 다중 전문가 합의 시스템을 도입하여 LLM의 성능에 기반하여 복잡성 클래스에 할당하고, 전문화된 지침을 제공하여 예측 정확도를 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 소스 코드의 복잡성을 효과적으로 예측하는 것은 소프트웨어 개발 및 알고리즘 분석에 매우 중요하다.

Method: MEC$^3$O라는 다중 전문가 합의 시스템을 도입하여 LLM을 복잡성 클래스에 할당하고 클래스 전문 지침을 제공하여 구조화된 토론을 통해 예측을 통합하였다.

Result: MEC$^3$O는 open-source 기준을 초과하며, 적어도 10% 더 높은 정확도와 macro-F1 점수를 달성하였다.

Conclusion: 다중 전문가의 토론과 가중 합의 전략의 효과성을 입증하였다.

Abstract: Predicting the complexity of source code is essential for software
development and algorithm analysis. Recently, Baik et al. (2025) introduced
CodeComplex for code time complexity prediction. The paper shows that LLMs
without fine-tuning struggle with certain complexity classes. This suggests
that no single LLM excels at every class, but rather each model shows
advantages in certain classes. We propose MEC$^3$O, a multi-expert consensus
system, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs
to complexity classes based on their performance and provides them with
class-specialized instructions, turning them into experts. These experts engage
in structured debates, and their predictions are integrated through a weighted
consensus mechanism. Our expertise assignments to LLMs effectively handle
Degeneration-of-Thought, reducing reliance on a separate judge model, and
preventing convergence to incorrect majority opinions. Experiments on
CodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving
at least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini
in macro-F1 scores on average and demonstrates competitive on-par F1 scores to
GPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of
multi-expert debates and weight consensus strategy to generate the final
predictions. Our code and data is available at
https://github.com/suhanmen/MECO.

</details>


### [11] [Leading the Follower: Learning Persuasive Agents in Social Deduction Games](https://arxiv.org/abs/2510.09087)
*Zhang Zheng,Deheng Ye,Peilin Zhao,Hao Wang*

Main category: cs.AI

TL;DR: 이 논문은 LLM 에이전트가 사회적 추론 게임에서 설득적 소통을 통해 다른 플레이어의 반응을 효과적으로 이끌어내는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 접근 방식은 정보 처리와 전략 선택에 중점을 두고 있으며, 설득적 소통의 중요성을 간과하고 있다.

Method: SDGs의 턴 기반 대화를 스택엘버그 경쟁으로 형식화하고, 강화 학습 프레임워크를 제안하여 에이전트가 설득적인 영향을 위한 발화를 최적화하도록 훈련시킨다.

Result: 세 가지 다양한 SDG에서 실시한 포괄적인 실험을 통해 에이전트가 기본 모델보다 현저히 우수한 성과를 보인다.

Conclusion: 이 연구는 전략적 사회적 영향력을 가진 AI 에이전트를 개발하는 데 중요한 진전을 나타내며, 설득적 소통이 필요한 시나리오에까지 그 함의가 확장된다.

Abstract: Large language model (LLM) agents have shown remarkable progress in social
deduction games (SDGs). However, existing approaches primarily focus on
information processing and strategy selection, overlooking the significance of
persuasive communication in influencing other players' beliefs and responses.
In SDGs, success depends not only on making correct deductions but on
convincing others to response in alignment with one's intent. To address this
limitation, we formalize turn-based dialogue in SDGs as a Stackelberg
competition, where the current player acts as the leader who strategically
influences the follower's response. Building on this theoretical foundation, we
propose a reinforcement learning framework that trains agents to optimize
utterances for persuasive impact. Through comprehensive experiments across
three diverse SDGs, we demonstrate that our agents significantly outperform
baselines. This work represents a significant step toward developing AI agents
capable of strategic social influence, with implications extending to scenarios
requiring persuasive communication.

</details>


### [12] [Fundamentals of Building Autonomous LLM Agents](https://arxiv.org/abs/2510.09244)
*Victor de Lamo Castrillo,Habtom Kahsay Gidey,Alexander Lenz,Alois Knoll*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델(LLM)로 구동되는 에이전트의 아키텍처와 구현 방법을 검토한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 LLM이 실제 작업에서 가지는 한계에서 출발하여, 복잡한 작업을 자동화하고 인간의 능력과 성능 차이를 해소할 수 있는 '에이전틱' LLM을 개발하기 위한 패턴을 탐구하고자 한다.

Method: 환경 인식을 의미 있는 표현으로 변환하는 인식 시스템, 피드백에 적응하고 다양한 기법을 통해 행동을 평가하는 계획 수립을 위한 추론 시스템, 단기 및 장기 메커니즘을 통해 지식을 보존하는 기억 시스템, 내부 결정을 구체적인 행동으로 변환하는 실행 시스템을 포함한다.

Result: 이 시스템들을 통합함으로써 인간의 인지 과정을 모방하여 자율적이고 지능적인 행동을 할 수 있는 더욱 능력 있고 일반화된 소프트웨어 봇을 만들 수 있음을 보여준다.

Conclusion: 이 연구는 복잡한 작업을 수행할 수 있는 에이전트를 만드는 데 필요한 주요 구성 요소들을 제시하며, 이를 통해 기술의 진보를 이끌 수 있는 가능성을 탐색한다.

Abstract: This paper reviews the architecture and implementation methods of agents
powered by large language models (LLMs). Motivated by the limitations of
traditional LLMs in real-world tasks, the research aims to explore patterns to
develop "agentic" LLMs that can automate complex tasks and bridge the
performance gap with human capabilities. Key components include a perception
system that converts environmental percepts into meaningful representations; a
reasoning system that formulates plans, adapts to feedback, and evaluates
actions through different techniques like Chain-of-Thought and Tree-of-Thought;
a memory system that retains knowledge through both short-term and long-term
mechanisms; and an execution system that translates internal decisions into
concrete actions. This paper shows how integrating these systems leads to more
capable and generalized software bots that mimic human cognitive processes for
autonomous and intelligent behavior.

</details>


### [13] [Agentic Systems in Radiology: Design, Applications, Evaluation, and Challenges](https://arxiv.org/abs/2510.09404)
*Christian Bluethgen,Dave Van Veen,Daniel Truhn,Jakob Nikolas Kather,Michael Moor,Malgorzata Polacin,Akshay Chaudhari,Thomas Frauenfelder,Curtis P. Langlotz,Michael Krauthammer,Farhad Nooralahzadeh*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLMs)을 활용한 방사선학의 에이전트 시스템 설계와 응용을 다룬 논문으로, 복잡한 업무를 자동화하는 데 필요한 자율성을 향상시키기 위한 방법론과 평가 방법, 도전 과제를 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 방사선학에서 LLM을 활용한 에이전트 시스템의 필요성과 그로 인해 복잡한 작업을 자동화할 수 있는 잠재력을 탐구한다.

Method: LLM에 외부 도구와 피드백 메커니즘을 통합하여 반자동 워크플로우에서 적응 가능한 에이전트로 관리할 수 있도록 설계한다.

Result: LLM 기반의 에이전트 시스템이 복잡한 프로세스를 관리할 수 있으며, 방사선학에서 정보 추출 및 보고서 요약과 같은 개별 작업에 대해 유망한 성과를 보여준다.

Conclusion: 자동화와 다양한 워크플로우를 관리할 수 있는 적응형 에이전트 설계를 통해 방사선학의 효율성과 효과성을 향상시킬 수 있는 가능성을 제시한다.

Abstract: Building agents, systems that perceive and act upon their environment with a
degree of autonomy, has long been a focus of AI research. This pursuit has
recently become vastly more practical with the emergence of large language
models (LLMs) capable of using natural language to integrate information,
follow instructions, and perform forms of "reasoning" and planning across a
wide range of tasks. With its multimodal data streams and orchestrated
workflows spanning multiple systems, radiology is uniquely suited to benefit
from agents that can adapt to context and automate repetitive yet complex
tasks. In radiology, LLMs and their multimodal variants have already
demonstrated promising performance for individual tasks such as information
extraction and report summarization. However, using LLMs in isolation
underutilizes their potential to support complex, multi-step workflows where
decisions depend on evolving context from multiple information sources.
Equipping LLMs with external tools and feedback mechanisms enables them to
drive systems that exhibit a spectrum of autonomy, ranging from semi-automated
workflows to more adaptive agents capable of managing complex processes. This
review examines the design of such LLM-driven agentic systems, highlights key
applications, discusses evaluation methods for planning and tool use, and
outlines challenges such as error cascades, tool-use efficiency, and health IT
integration.

</details>


### [14] [Safe, Untrusted, "Proof-Carrying" AI Agents: toward the agentic lakehouse](https://arxiv.org/abs/2510.09567)
*Jacopo Tagliabue,Ciro Greco*

Main category: cs.AI

TL;DR: 이 논문은 데이터 레이크하우스에서 AI 자동화의 신뢰성 및 거버넌스 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: AI 주도의 자동화가 민감한 작업 부하에서 신뢰성, 정확성 및 거버넌스에 대한 우려를 증가시키고 있다.

Method: API 우선의 프로그래머블 레이크하우스를 통해 안전한 설계의 에이전트 워크플로우를 위한 추상화를 제공한다.

Result: Bauplan을 사례 연구로 사용하여 데이터 가지치기 및 선언적 환경이 에이전트에 자연스럽게 확장될 수 있음을 보여준다.

Conclusion: 신뢰할 수 없는 AI 에이전트가 생산 데이터에서 안전하게 작동할 수 있음을 입증하며, 완전한 에이전트 기반 레이크하우스로 나아가는 경로를 제시한다.

Abstract: Data lakehouses run sensitive workloads, where AI-driven automation raises
concerns about trust, correctness, and governance. We argue that API-first,
programmable lakehouses provide the right abstractions for safe-by-design,
agentic workflows. Using Bauplan as a case study, we show how data branching
and declarative environments extend naturally to agents, enabling
reproducibility and observability while reducing the attack surface. We present
a proof-of-concept in which agents repair data pipelines using correctness
checks inspired by proof-carrying code. Our prototype demonstrates that
untrusted AI agents can operate safely on production data and outlines a path
toward a fully agentic lakehouse.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [15] [AgenticAD: A Specialized Multiagent System Framework for Holistic Alzheimer Disease Management](https://arxiv.org/abs/2510.08578)
*Adib Bazgir,Amir Habibdoust,Xing Song,Yuwen Zhang*

Main category: cs.MA

TL;DR: 이 논문은 알츠하이머병 관리에 대한 포괄적이고 다중 에이전트 시스템(MAS)의 새로운 방법론적 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병은 복잡하고 다면적인 도전 과제를 제시하며, 이를 해결하기 위해 통합적이고 동적인 지원 솔루션이 필요합니다.

Method: 이 프레임워크는 각각의 특정 과제를 해결하기 위해 설계된 8개의 전문화된 상호운용 가능 에이전트로 구성되어 있습니다.

Result: 제안된 에이전트는 작업에 따라 분류되며, 첨단 기술을 활용한 기술 아키텍처를 자세히 설명합니다.

Conclusion: 이 방법론적 접근은 다양한 데이터 흐름을 통합하여 환자 결과를 개선하고 간병인의 부담을 줄이는 미래 시스템 개발의 길을 열 것입니다.

Abstract: Alzheimer's disease (AD) presents a complex, multifaceted challenge to
patients, caregivers, and the healthcare system, necessitating integrated and
dynamic support solutions. While artificial intelligence (AI) offers promising
avenues for intervention, current applications are often siloed, addressing
singular aspects of the disease such as diagnostics or caregiver support
without systemic integration. This paper proposes a novel methodological
framework for a comprehensive, multi-agent system (MAS) designed for holistic
Alzheimer's disease management. The objective is to detail the architecture of
a collaborative ecosystem of specialized AI agents, each engineered to address
a distinct challenge in the AD care continuum, from caregiver support and
multimodal data analysis to automated research and clinical data
interpretation. The proposed framework is composed of eight specialized,
interoperable agents. These agents are categorized by function: (1) Caregiver
and Patient Support, (2) Data Analysis and Research, and (3) Advanced
Multimodal Workflows. The methodology details the technical architecture of
each agent, leveraging a suite of advanced technologies including large
language models (LLMs) such as GPT-4o and Gemini, multi-agent orchestration
frameworks, Retrieval-Augmented Generation (RAG) for evidence-grounded
responses, and specialized tools for web scraping, multimodal data processing,
and in-memory database querying. This paper presents a detailed architectural
blueprint for an integrated AI ecosystem for AD care. By moving beyond
single-purpose tools to a collaborative, multi-agent paradigm, this framework
establishes a foundation for developing more adaptive, personalized, and
proactive solutions. This methodological approach aims to pave the way for
future systems capable of synthesizing diverse data streams to improve patient
outcomes and reduce caregiver burden.

</details>


### [16] [GRPO-GCC: Enhancing Cooperation in Spatial Public Goods Games via Group Relative Policy Optimization with Global Cooperation Constraint](https://arxiv.org/abs/2510.08607)
*Zhaoqilin Yang,Chanchan Li,Tianqi Liu,Hongxin Zhao,Youliang Tian*

Main category: cs.MA

TL;DR: GRPO-GCC 프레임워크는 집단 협력의 자가 조절 원리를 기반으로 공공재 게임에 적용된 새로운 심층 강화 학습 기준을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 집단 기관에서의 자가 조절 협력 원리에서 영감을 얻어, 더 효과적인 협력 메커니즘을 개발하고자 함.

Method: GRPO-GCC는 그룹 상대 정책 최적화와 세계적인 협력 제약을 통합하여 중간 협력 수준에서 인센티브를 강화하고 극단에서는 약화시키는 방식을 사용한다.

Result: GRPO-GCC는 가속화된 협력 시작, 정책 적응 안정화, 장기적인 지속 가능성을 달성한다.

Conclusion: GRPO-GCC는 간단하지만 전 세계적인 신호가 회복력 있는 협력으로의 인센티브를 재형성할 수 있음을 보여주고, 사회 기술 시스템에서 다중 에이전트 강화 학습을 위한 새로운 패러다임을 제공한다.

Abstract: Inspired by the principle of self-regulating cooperation in collective
institutions, we propose the Group Relative Policy Optimization with Global
Cooperation Constraint (GRPO-GCC) framework. This work is the first to
introduce GRPO into spatial public goods games, establishing a new deep
reinforcement learning baseline for structured populations. GRPO-GCC integrates
group relative policy optimization with a global cooperation constraint that
strengthens incentives at intermediate cooperation levels while weakening them
at extremes. This mechanism aligns local decision making with sustainable
collective outcomes and prevents collapse into either universal defection or
unconditional cooperation. The framework advances beyond existing approaches by
combining group-normalized advantage estimation, a reference-anchored KL
penalty, and a global incentive term that dynamically adjusts cooperative
payoffs. As a result, it achieves accelerated cooperation onset, stabilized
policy adaptation, and long-term sustainability. GRPO-GCC demonstrates how a
simple yet global signal can reshape incentives toward resilient cooperation,
and provides a new paradigm for multi-agent reinforcement learning in
socio-technical systems.

</details>


### [17] [Scalable Multi-Agent Path Finding using Collision-Aware Dynamic Alert Mask and a Hybrid Execution Strategy](https://arxiv.org/abs/2510.09469)
*Bharath Muppasani,Ritirupa Dey,Biplav Srivastava,Vignesh Narayanan*

Main category: cs.MA

TL;DR: 본 논문에서는 다중 에이전트 경로 탐색(MAPF)의 문제를 해결하기 위한 하이브리드 프레임워크를 제안하며, 이 프레임워크는 분산된 경로 계획과 경량 중앙 조정기를 결합하여 에이전트들이 충돌을 효과적으로 회피하면서 효율적으로 공유 공간을 탐색하도록 돕습니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 경로 탐색(MAPF)은 로보틱스 및 자율 시스템에서 중요한 문제로, 에이전트가 공유 공간을 효율적으로 탐색하면서 충돌을 피해야 합니다.

Method: 하이브리드 프레임워크는 분산 경로 계획과 경량 중앙 조정기를 결합하며, 강화 학습(RL)을 활용하여 에이전트가 최소한의 표적 경고 기반으로 계획을 조정할 수 있게 합니다.

Result: 우리의 접근 방식은 완전 중앙 집중식 및 분산 방법에 비해 에이전트 간 정보 공유를 줄이면서도 큰 규모의 시나리오에서도 일관되게 충돌 없는 해법을 찾아냅니다.

Conclusion: 본 프레임워크는 정보의 가용성이 에이전트의 계획 성능에 미치는 영향을 실증적으로 연구하여 큰 규모의 시나리오에서도 해결책의 품질을 유지합니다.

Abstract: Multi-agent pathfinding (MAPF) remains a critical problem in robotics and
autonomous systems, where agents must navigate shared spaces efficiently while
avoiding conflicts. Traditional centralized algorithms that have global
information, such as Conflict-Based Search (CBS), provide high-quality
solutions but become computationally expensive in large-scale scenarios due to
the combinatorial explosion of conflicts that need resolution. Conversely,
distributed approaches that have local information, particularly learning-based
methods, offer better scalability by operating with relaxed information
availability, yet often at the cost of solution quality. To address these
limitations, we propose a hybrid framework that combines decentralized path
planning with a lightweight centralized coordinator. Our framework leverages
reinforcement learning (RL) for decentralized planning, enabling agents to
adapt their planning based on minimal, targeted alerts--such as static
conflict-cell flags or brief conflict tracks--that are dynamically shared
information from the central coordinator for effective conflict resolution. We
empirically study the effect of the information available to an agent on its
planning performance. Our approach reduces the inter-agent information sharing
compared to fully centralized and distributed methods, while still consistently
finding feasible, collision-free solutions--even in large-scale scenarios
having higher agent counts.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [18] [Post-Quantum Security of Block Cipher Constructions](https://arxiv.org/abs/2510.08725)
*Gorjan Alagic,Chen Bai,Christian Majenz,Kaiyan Shi*

Main category: cs.CR

TL;DR: 이 논문은 블록 암호의 포스트 양자 보안 이론을 기반으로 하여, 다양한 암호화 및 인증 모드에 대한 첫 번째 증명을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 공개 키 암호의 포스트 양자 보안이 주목받고 있지만, 대칭 키 암호와 블록 암호에 대한 연구는 미비한 상황입니다.

Method: 우리의 새로운 기법을 활용하여 FX 키 길이 확장 계획, LRW 및 XEX와 같은 조정 가능한 블록 암호에 대한 포스트 양자 보안 증명을 제공합니다.

Result: 다양한 블록 암호화 및 인증 모드에 대한 최초의 포스트 양자 보안 증명을 제공합니다.

Conclusion: 이 연구는 실용적인 대칭 키 암호의 포스트 양자 보안에 대한 엄밀한 이해를 세우는 중요한 첫 단계를 제공합니다.

Abstract: Block ciphers are versatile cryptographic ingredients that are used in a wide
range of applications ranging from secure Internet communications to disk
encryption. While post-quantum security of public-key cryptography has received
significant attention, the case of symmetric-key cryptography (and block
ciphers in particular) remains a largely unexplored topic. In this work, we set
the foundations for a theory of post-quantum security for block ciphers and
associated constructions. Leveraging our new techniques, we provide the first
post-quantum security proofs for the key-length extension scheme FX, the
tweakable block ciphers LRW and XEX, and most block cipher encryption and
authentication modes. Our techniques can be used for security proofs in both
the plain model and the quantum ideal cipher model. Our work takes significant
initial steps in establishing a rigorous understanding of the post-quantum
security of practical symmetric-key cryptography.

</details>


### [19] [CommandSans: Securing AI Agents with Surgical Precision Prompt Sanitization](https://arxiv.org/abs/2510.08829)
*Debeshee Das,Luca Beurer-Kellner,Marc Fischer,Maximilian Baader*

Main category: cs.CR

TL;DR: 본 연구는 LLM 에이전트의 공격 면을 줄이기 위한 새로운 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 채택 증가로 인해 간접 프롬프트 주입에 대한 공격 면이 크게 확대되고 있다.

Method: 우리는 AI 시스템에 대한 지시를 도구 출력에서 제거하는 토큰 수준의 세척 프로세스를 제안한다.

Result: 이 접근법은 다양한 공격에서 7-10배의 공격 성공률 감소를 달성했다.

Conclusion: 새로운 방법은 기존의 안전 분류기와 달리 비차단적이며, 맥락에 구애받지 않고 에이전트 유틸리티를 유지한다.

Abstract: The increasing adoption of LLM agents with access to numerous tools and
sensitive data significantly widens the attack surface for indirect prompt
injections. Due to the context-dependent nature of attacks, however, current
defenses are often ill-calibrated as they cannot reliably differentiate
malicious and benign instructions, leading to high false positive rates that
prevent their real-world adoption. To address this, we present a novel approach
inspired by the fundamental principle of computer security: data should not
contain executable instructions. Instead of sample-level classification, we
propose a token-level sanitization process, which surgically removes any
instructions directed at AI systems from tool outputs, capturing malicious
instructions as a byproduct. In contrast to existing safety classifiers, this
approach is non-blocking, does not require calibration, and is agnostic to the
context of tool outputs. Further, we can train such token-level predictors with
readily available instruction-tuning data only, and don't have to rely on
unrealistic prompt injection examples from challenges or of other synthetic
origin. In our experiments, we find that this approach generalizes well across
a wide range of attacks and benchmarks like AgentDojo, BIPIA, InjecAgent, ASB
and SEP, achieving a 7-10x reduction of attack success rate (ASR) (34% to 3% on
AgentDojo), without impairing agent utility in both benign and malicious
settings.

</details>


### [20] [Exploiting Web Search Tools of AI Agents for Data Exfiltration](https://arxiv.org/abs/2510.09093)
*Dennis Rall,Bernhard Bauer,Mohit Mittal,Thomas Fraunholz*

Main category: cs.CR

TL;DR: 본 연구에서는 간접 프롬프트 주입 공격이 현재 대형 언어 모델(LLM)에 미치는 영향을 분석하고, 그 취약성을 감소시키기 위한 훈련 절차 강화와 중앙 집중식 공격 벡터 데이터베이스 설립의 필요성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 복잡한 작업을 자율적으로 수행하면서도 데이터에 대한 공격에 노출되고 있음을 인식하고, 이러한 공격에 대한 취약성을 파악하고자 한다.

Method: 다양한 모델을 대상으로 간접 프롬프트 주입 공격을 체계적으로 평가하여, 현재 LLM의 취약성을 분석하고, 모델 크기, 제조사, 특정 구현 등이 이를 결정짓는 요소임을 살펴본다.

Result: 잘 알려진 공격 패턴이 여전히 성공적으로 실행되고 있으며, 모델 방어의 지속적인 약점을 드러낸다.

Conclusion: LLM의 핵심 설계에 보안을 통합하도록 개발자를 유도하기 위해, 훈련 절차의 강화, 중앙 집중식 공격 벡터 데이터베이스, 통합 테스트 프레임워크의 필요성을 강조한다.

Abstract: Large language models (LLMs) are now routinely used to autonomously execute
complex tasks, from natural language processing to dynamic workflows like web
searches. The usage of tool-calling and Retrieval Augmented Generation (RAG)
allows LLMs to process and retrieve sensitive corporate data, amplifying both
their functionality and vulnerability to abuse. As LLMs increasingly interact
with external data sources, indirect prompt injection emerges as a critical and
evolving attack vector, enabling adversaries to exploit models through
manipulated inputs. Through a systematic evaluation of indirect prompt
injection attacks across diverse models, we analyze how susceptible current
LLMs are to such attacks, which parameters, including model size and
manufacturer, specific implementations, shape their vulnerability, and which
attack methods remain most effective. Our results reveal that even well-known
attack patterns continue to succeed, exposing persistent weaknesses in model
defenses. To address these vulnerabilities, we emphasize the need for
strengthened training procedures to enhance inherent resilience, a centralized
database of known attack vectors to enable proactive defense, and a unified
testing framework to ensure continuous security validation. These steps are
essential to push developers toward integrating security into the core design
of LLMs, as our findings show that current models still fail to mitigate
long-standing threats.

</details>


### [21] [GREAT: Generalizable Backdoor Attacks in RLHF via Emotion-Aware Trigger Synthesis](https://arxiv.org/abs/2510.09260)
*Subrat Kishore Dutta,Yuelin Xu,Piyush Pant,Xiao Zhang*

Main category: cs.CR

TL;DR: 본 논문에서는 RLHF에서의 백도어 공격 취약성을 다루고, 감정을 인식하는 트리거 합성을 통해 일반화 가능한 백도어를 생성하는 GREAT 프레임워크를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: RLHF가 백도어 공격에 매우 취약하다는 연구 결과에 따라, 보다 현실적인 공격 방식을 개발할 필요성이 존재한다.

Method: GREAT 프레임워크는 감정이 인식된 트리거 합성을 통해 일반화 가능한 백도어를 제작하며, 잠재적 사용자 그룹을 겨냥하여 해로운 응답 생성을 유도한다.

Result: 실험 결과, GREAT는 기준 방법들에 비해 공격 성공률이 크게 향상되었으며, 특히 보지 못한 트리거 시나리오에서 두드러진 성과를 보였다.

Conclusion: GREAT는 일반적인 백도어 공격 방법에 비해 응답 품질을 거의 그대로 유지하면서도 효과적인 공격을 가능하게 한다.

Abstract: Recent work has shown that RLHF is highly susceptible to backdoor attacks,
poisoning schemes that inject malicious triggers in preference data. However,
existing methods often rely on static, rare-token-based triggers, limiting
their effectiveness in realistic scenarios. In this paper, we develop GREAT, a
novel framework for crafting generalizable backdoors in RLHF through
emotion-aware trigger synthesis. Specifically, GREAT targets harmful response
generation for a vulnerable user subgroup characterized by both semantically
violent requests and emotionally angry triggers. At the core of GREAT is a
trigger identification pipeline that operates in the latent embedding space,
leveraging principal component analysis and clustering techniques to identify
the most representative triggers. To enable this, we present Erinyes, a
high-quality dataset of over $5000$ angry triggers curated from GPT-4.1 using a
principled, hierarchical, and diversity-promoting approach. Experiments on
benchmark RLHF datasets demonstrate that GREAT significantly outperforms
baseline methods in attack success rates, especially for unseen trigger
scenarios, while largely preserving the response quality on benign inputs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [22] [Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting](https://arxiv.org/abs/2510.08696)
*Yunzhen Feng,Parag Jain,Anthony Hartshorn,Yaqi Duan,Julia Kempe*

Main category: cs.LG

TL;DR: LENS는 GRPO를 수정하여 부정적인 그룹도 유용한 그라디언트 업데이트로 전환하여 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 부정적인 그룹에서의 컴퓨팅 자원을 낭비하지 않으면서 이를 활용할 수 있는 방법을 찾고자 했다.

Method: 보상 모델링에서 최대 우도(MLE) 목표를 기반으로, MLE 그라디언트가 수정된 가치 함수의 정책 그라디언트와 동등하다는 것을 보여줌으로써, 부정확한 응답에 대해 신뢰도 가중치 벌점을 부과하는 가치 함수를 추가하였다.

Result: LENS는 GRPO를 수정하여 부정확한 생성물에 대해 비제로의 신뢰도 의존 보상을 부여하고, 이전에 낭비된 샘플을 유용한 그라디언트 업데이트로 변환하였다. MATH 벤치마크에서 Llama-3.1-8B와 Qwen-2.5-3B를 사용하여, 제안된 변형이 GRPO 기준보다 일관되게 더 나은 성능을 보였다.

Conclusion: 부정적인 그룹을 '구해내는' 체계적이고 실용적인 방법을 제시하여 RLVR의 효율성과 성능을 향상시켰다.

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a standard
recipe for improving large language models (LLMs) on reasoning tasks, with
Group Relative Policy Optimization (GRPO) widely used in practice. Yet GRPO
wastes substantial compute on negative groups: groups in which no sampled
response is correct yield zero advantage and thus no gradient. We ask whether
negative groups can be leveraged without extra supervision. Starting from a
maximum-likelihood (MLE) objective in reward modeling, we show that the MLE
gradient is equivalent to a policy gradient for a modified value function. This
value function adds a confidence-weighted penalty on incorrect responses,
imposing larger penalties on more confident mistakes. We refer to this as
\textbf{L}ikelihood \textbf{E}stimation with \textbf{N}egative \textbf{S}amples
(\textbf{LENS}). LENS modifies GRPO to assign non-zero, confidence-dependent
rewards to incorrect generations, making negative groups informative and
converting previously wasted samples into useful gradient updates. On the MATH
benchmark with Llama-3.1-8B and Qwen-2.5-3B, the proposed variant consistently
outperforms GRPO baseline, with significant gains on harder items. These
results demonstrate a principled and practical way to "rescue" negative groups,
improving efficiency and performance in RLVR.

</details>


### [23] [In-Context Learning for Non-Stationary MIMO Equalization](https://arxiv.org/abs/2510.08711)
*Jiachen Jiang,Zhen Qin,Zhihui Zhu*

Main category: cs.LG

TL;DR: 이 논문은 비정상 채널에서의 ICL(상황 학습) 기반 평형기 설계의 가능성을 탐구하고 새로운 주의 메커니즘을 개발하는 방법에 대해 논의합니다.


<details>
  <summary>Details</summary>
Motivation: 비정상 채널 및 능동적 적응 처리를 통해 기존의 ICL 기반 평형기가 정적 채널에만 초점을 맞추고 있는 문제를 해결하고자 합니다.

Method: LMS 알고리즘에서 파생된 새로운 주의 변형을 활용하여 비정상 작업에 대한 향상된 적응성을 제공하는 효율적인 주의 메커니즘을 설계하는 원칙적인 프레임워크를 적용합니다.

Result: 실험 결과, ICL이 비정상 MIMO 평형화에 대한 강력한 가능성을 보이며, 고전적 적응 알고리즘에서 영감을 받은 주의 메커니즘이 동적 환경에서의 적응성 및 성능을 상당히 향상시킬 수 있음을 보여줍니다.

Conclusion: 우리의 발견은 차세대 무선 기초 모델을 개발하는 데 있어 강력한 적응성과 내구성을 갖춘 통찰력을 제공할 수 있습니다.

Abstract: Channel equalization is fundamental for mitigating distortions such as
frequency-selective fading and inter-symbol interference. Unlike standard
supervised learning approaches that require costly retraining or fine-tuning
for each new task, in-context learning (ICL) adapts to new channels at
inference time with only a few examples. However, existing ICL-based equalizers
are primarily developed for and evaluated on static channels within the context
window. Indeed, to our knowledge, prior principled analyses and theoretical
studies of ICL focus exclusively on the stationary setting, where the function
remains fixed within the context. In this paper, we investigate the ability of
ICL to address non-stationary problems through the lens of time-varying channel
equalization. We employ a principled framework for designing efficient
attention mechanisms with improved adaptivity in non-stationary tasks,
leveraging algorithms from adaptive signal processing to guide better designs.
For example, new attention variants can be derived from the Least Mean Square
(LMS) adaptive algorithm, a Least Root Mean Square (LRMS) formulation for
enhanced robustness, or multi-step gradient updates for improved long-term
tracking. Experimental results demonstrate that ICL holds strong promise for
non-stationary MIMO equalization, and that attention mechanisms inspired by
classical adaptive algorithms can substantially enhance adaptability and
performance in dynamic environments. Our findings may provide critical insights
for developing next-generation wireless foundation models with stronger
adaptability and robustness.

</details>


### [24] [SHAP-Based Supervised Clustering for Sample Classification and the Generalized Waterfall Plot](https://arxiv.org/abs/2510.08737)
*Justin Lin,Julia Fukuyama*

Main category: cs.LG

TL;DR: 대량의 데이터와 복잡한 관계를 처리할 수 있는 대규모 블랙박스 모델이 점점 보편화되고 있지만, 이 모델들의 예측 과정 설명 부족으로 인해 신뢰성 문제를 야기한다. 본 논문에서는 SHAP 분석을 통해 예측 과정의 설명을 제공하고, 이를 클러스터링하여 유사한 이유로 같은 예측을 받은 샘플들을 그룹화함으로써 통찰을 제공하는 방법론을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대량의 데이터와 높은 복잡성을 처리할 수 있는 모델이 필요한 반면, 블랙박스 모델의 예측 과정이 불투명해 신뢰성을 저하시켜 이를 극복할 수 있는 설명 가능성이 요구된다.

Method: SHAP 값을 통해 예측에 대한 각 특성의 기여도를 정량화하고 이를 클러스터링하여 유사한 예측을 받는 샘플의 경로를 분석한다.

Result: 알츠하이머병 데이터 사례 연구와 시뮬레이션 실험을 통해 SHAP 분석 방법론을 시연하였다.

Conclusion: SHAP 분석을 활용하여 예측 설명 가능성을 높이고, 다중 분류를 위한 새로운 폭포도(Waterfall Plot) 일반화를 제시하였다.

Abstract: In this growing age of data and technology, large black-box models are
becoming the norm due to their ability to handle vast amounts of data and learn
incredibly complex input-output relationships. The deficiency of these methods,
however, is their inability to explain the prediction process, making them
untrustworthy and their use precarious in high-stakes situations. SHapley
Additive exPlanations (SHAP) analysis is an explainable AI method growing in
popularity for its ability to explain model predictions in terms of the
original features. For each sample and feature in the data set, we associate a
SHAP value that quantifies the contribution of that feature to the prediction
of that sample. Clustering these SHAP values can provide insight into the data
by grouping samples that not only received the same prediction, but received
the same prediction for similar reasons. In doing so, we map the various
pathways through which distinct samples arrive at the same prediction. To
showcase this methodology, we present a simulated experiment in addition to a
case study in Alzheimer's disease using data from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) database. We also present a novel generalization
of the waterfall plot for multi-classification.

</details>


### [25] [RFOD: Random Forest-based Outlier Detection for Tabular Data](https://arxiv.org/abs/2510.08747)
*Yihao Ang,Peicheng Yao,Yifan Bao,Yushuo Feng,Qiang Huang,Anthony K. H. Tung,Zhiyong Huang*

Main category: cs.LG

TL;DR: 이 논문에서는 혼합형 테이블 데이터에 대한 새로운 이상치 탐지 프레임워크인 RFOD를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 고위험 분야에서 데이터 무결성을 보호하기 위해 테이블 데이터에서 이상치 탐지가 중요합니다.

Method: RFOD는 각 특성에 대해 다른 특성에 조건화된 전용 랜덤 포레스트를 훈련시키며, 이상치 탐지를 특성별 조건부 재구성 문제로 재구성합니다.

Result: RFOD는 15개의 실제 데이터세트에서 기존 방법들을 지속적으로 능가하며, 혼합형 테이블 데이터에 대해 높은 정확도, 강건성, 확장성 및 해석 가능성을 제공합니다.

Conclusion: 이 연구는 데이터 무결성을 유지하면서 혼합형 데이터에서 더 나은 이상치 탐지를 가능하게 합니다.

Abstract: Outlier detection in tabular data is crucial for safeguarding data integrity
in high-stakes domains such as cybersecurity, financial fraud detection, and
healthcare, where anomalies can cause serious operational and economic impacts.
Despite advances in both data mining and deep learning, many existing methods
struggle with mixed-type tabular data, often relying on encoding schemes that
lose important semantic information. Moreover, they frequently lack
interpretability, offering little insight into which specific values cause
anomalies. To overcome these challenges, we introduce \textsf{\textbf{RFOD}}, a
novel \textsf{\textbf{R}}andom \textsf{\textbf{F}}orest-based
\textsf{\textbf{O}}utlier \textsf{\textbf{D}}etection framework tailored for
tabular data. Rather than modeling a global joint distribution, \textsf{RFOD}
reframes anomaly detection as a feature-wise conditional reconstruction
problem, training dedicated random forests for each feature conditioned on the
others. This design robustly handles heterogeneous data types while preserving
the semantic integrity of categorical features. To further enable precise and
interpretable detection, \textsf{RFOD} combines Adjusted Gower's Distance (AGD)
for cell-level scoring, which adapts to skewed numerical data and accounts for
categorical confidence, with Uncertainty-Weighted Averaging (UWA) to aggregate
cell-level scores into robust row-level anomaly scores. Extensive experiments
on 15 real-world datasets demonstrate that \textsf{RFOD} consistently
outperforms state-of-the-art baselines in detection accuracy while offering
superior robustness, scalability, and interpretability for mixed-type tabular
data.

</details>


### [26] [Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols](https://arxiv.org/abs/2510.09462)
*Mikhail Terekhov,Alexander Panfilov,Daniil Dzenhaliou,Caglar Gulcehre,Maksym Andriushchenko,Ameya Prabhu,Jonas Geiping*

Main category: cs.LG

TL;DR: AI 제어 프로토콜은 자율 환경에서 신뢰할 수 없는 LLM 에이전트의 해로운 행동을 방지하는 방어 메커니즘으로 작용한다. 하지만 주로 LLM 모니터를 기반으로 하여 신뢰성 문제를 일으킬 수 있으며, 적응형 공격에 대한 연구가 필요하다.


<details>
  <summary>Details</summary>
Motivation: AI 제어 프로토콜의 신뢰성과 안전성을 높이기 위해 필요하다.

Method: 신뢰할 수 없는 모델이 프로토콜과 모니터 모델을 알고 있는 경우를 가정하고, 알려진 프롬프트 주입을 통해 적응형 공격을 구현한다.

Result: 최신 AI 제어 벤치마크에서 신뢰할 수 없는 모델이 다양한 모니터를 회피하고 악의적인 작업을 수행하는 것을 발견했다.

Conclusion: 모니터 모델에 대한 적응형 공격은 현재 제어 프로토콜의 주요 맹점으로, 향후 AI 제어 메커니즘의 평가에 필수적인 요소가 되어야 한다.

Abstract: AI control protocols serve as a defense mechanism to stop untrusted LLM
agents from causing harm in autonomous settings. Prior work treats this as a
security problem, stress testing with exploits that use the deployment context
to subtly complete harmful side tasks, such as backdoor insertion. In practice,
most AI control protocols are fundamentally based on LLM monitors, which can
become a central point of failure. We study adaptive attacks by an untrusted
model that knows the protocol and the monitor model, which is plausible if the
untrusted model was trained with a later knowledge cutoff or can search for
this information autonomously. We instantiate a simple adaptive attack vector
by which the attacker embeds publicly known or zero-shot prompt injections in
the model outputs. Using this tactic, frontier models consistently evade
diverse monitors and complete malicious tasks on two main AI control
benchmarks. The attack works universally against current protocols that rely on
a monitor. Furthermore, the recent Defer-to-Resample protocol even backfires,
as its resampling amplifies the prompt injection and effectively reframes it as
a best-of-$n$ attack. In general, adaptive attacks on monitor models represent
a major blind spot in current control protocols and should become a standard
component of evaluations for future AI control mechanisms.

</details>


### [27] [Spatial Deconfounder: Interference-Aware Deconfounding for Spatial Causal Inference](https://arxiv.org/abs/2510.08762)
*Ayush Khot,Miruna Oprescu,Maresa Schröder,Ai Kagawa,Xihaier Luo*

Main category: cs.LG

TL;DR: 이 논문은 공간 도메인에서의 인과 추론의 두 가지 복합적인 문제를 해결하기 위한 새로운 접근법인 Spatial Deconfounder를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 공간 도메인에서 인과 추론을 수행할 때, 측정되지 않은 공간적 요인과 인접 치료로 인한 간섭 문제를 동시에 해결할 필요가 있습니다.

Method: Spatial Deconfounder는 지역 치료 벡터에서 대체 교란 요인을 재구성하기 위해 공간 우선 조건부 변별 오토인코더(CVAE)를 사용하고, 이후 유연한 결과 모델을 통해 인과 효과를 추정합니다.

Result: 이 접근법은 약한 가정 하에서도 직접 및 스필오버 효과의 비모수적 식별을 가능하게 하고, 환경 건강 및 사회 과학의 실제 데이터셋에서 효과 추정의 일관된 개선을 보여줍니다.

Conclusion: 우리의 프레임워크는 간섭을 다원적 원인 신호로 전환하여 공간적 및 교란 교란 문헌을 연결하고 구조화된 데이터 내에서 강건한 인과 추론을 촉진합니다.

Abstract: Causal inference in spatial domains faces two intertwined challenges: (1)
unmeasured spatial factors, such as weather, air pollution, or mobility, that
confound treatment and outcome, and (2) interference from nearby treatments
that violate standard no-interference assumptions. While existing methods
typically address one by assuming away the other, we show they are deeply
connected: interference reveals structure in the latent confounder. Leveraging
this insight, we propose the Spatial Deconfounder, a two-stage method that
reconstructs a substitute confounder from local treatment vectors using a
conditional variational autoencoder (CVAE) with a spatial prior, then estimates
causal effects via a flexible outcome model. We show that this approach enables
nonparametric identification of both direct and spillover effects under weak
assumptions--without requiring multiple treatment types or a known model of the
latent field. Empirically, we extend SpaCE, a benchmark suite for spatial
confounding, to include treatment interference, and show that the Spatial
Deconfounder consistently improves effect estimation across real-world datasets
in environmental health and social science. By turning interference into a
multi-cause signal, our framework bridges spatial and deconfounding literatures
to advance robust causal inference in structured data.

</details>


### [28] [Reinforcement Learning-Based Optimization of CT Acquisition and Reconstruction Parameters Through Virtual Imaging Trials](https://arxiv.org/abs/2510.08763)
*David Fenwick,Navid NaderiAlizadeh,Vahid Tarokh,Nicholas Felice,Darin Clark,Jayasai Rajagopal,Anuj Kapadia,Benjamin Wildman-Tobriner,Ehsan Samei,Ehsan Abadi*

Main category: cs.LG

TL;DR: 이 연구는 CT 프로토콜 최적화를 위해 가상 이미징 도구와 강화 학습을 결합한 새로운 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: CT에서 높은 진단 이미지 품질을 달성하고 방사선 피폭을 최소화하기 위한 프로토콜 최적화의 중요성.

Method: 가상 이미징 도구와 강화 학습을 결합하여 CT 프로토콜을 효율적으로 최적화하는 새로운 방법론을 사용.

Result: 제안된 강화 학습 접근 방식은 초고속 컴퓨터에서 수행된 철저한 탐색에 비해 79.7% 적은 단계로 테스트 사례 전반에 걸쳐 글로벌 최대 d'를 달성하였다.

Conclusion: 가상 이미징 도구와 강화 학습을 통합한 CT 프로토콜 관리의 잠재력을 강조한다.

Abstract: Protocol optimization is critical in Computed Tomography (CT) to achieve high
diagnostic image quality while minimizing radiation dose. However, due to the
complex interdependencies among CT acquisition and reconstruction parameters,
traditional optimization methods rely on exhaustive testing of combinations of
these parameters, which is often impractical. This study introduces a novel
methodology that combines virtual imaging tools with reinforcement learning to
optimize CT protocols more efficiently. Human models with liver lesions were
imaged using a validated CT simulator and reconstructed with a novel CT
reconstruction toolkit. The optimization parameter space included tube voltage,
tube current, reconstruction kernel, slice thickness, and pixel size. The
optimization process was performed using a Proximal Policy Optimization (PPO)
agent, which was trained to maximize an image quality objective, specifically
the detectability index (d') of liver lesions in the reconstructed images.
Optimization performance was compared against an exhaustive search performed on
a supercomputer. The proposed reinforcement learning approach achieved the
global maximum d' across test cases while requiring 79.7% fewer steps than the
exhaustive search, demonstrating both accuracy and computational efficiency.
The proposed framework is flexible and can accommodate various image quality
objectives. The findings highlight the potential of integrating virtual imaging
tools with reinforcement learning for CT protocol management.

</details>


### [29] [Guiding Exploration in Reinforcement Learning Through LLM-Augmented Observations](https://arxiv.org/abs/2510.08779)
*Vaibhav Jain,Gerrit Grossmann*

Main category: cs.LG

TL;DR: 이 논문에서는 LLM이 RL 탐색을 돕는 새로운 프레임워크를 제안하며, RL 에이전트가 LLM의 제안을 따르거나 무시할 시점을 학습하도록 한다.


<details>
  <summary>Details</summary>
Motivation: Sparse-reward 환경에서 RL 에이전트의 탐색 전략이 실패하며, LLM의 절차적 지식과 추론 능력을 활용하고자 한다.

Method: 증강된 관찰 공간을 통해 LLM이 생성한 행동 추천을 제공하여 RL 에이전트가 이 지침을 따르거나 무시할 수 있도록 한다.

Result: 세 가지 BabyAI 환경에서 평가하여 LLM의 지침의 이점이 작업의 난이도에 따라 증가함을 보여준다. 가장 도전적인 환경에서 71%의 상대적 성공률 개선을 달성하였다.

Conclusion: 이 방법은 기존 RL 알고리즘에 수정 없이 사용 가능하며, 에이전트가 성능 기준에 도달하는 데 최대 9배 더 빠른 샘플 효율성을 제공한다.

Abstract: Reinforcement Learning (RL) agents often struggle in sparse-reward
environments where traditional exploration strategies fail to discover
effective action sequences. Large Language Models (LLMs) possess procedural
knowledge and reasoning capabilities from text pretraining that could guide RL
exploration, but existing approaches create rigid dependencies where RL
policies must follow LLM suggestions or incorporate them directly into reward
functions. We propose a framework that provides LLM-generated action
recommendations through augmented observation spaces, allowing RL agents to
learn when to follow or ignore this guidance. Our method leverages LLMs' world
knowledge and reasoning abilities while maintaining flexibility through soft
constraints. We evaluate our approach on three BabyAI environments of
increasing complexity and show that the benefits of LLM guidance scale with
task difficulty. In the most challenging environment, we achieve 71% relative
improvement in final success rates over baseline. The approach provides
substantial sample efficiency gains, with agents reaching performance
thresholds up to 9 times faster, and requires no modifications to existing RL
algorithms. Our results demonstrate an effective method for leveraging LLM
planning capabilities to accelerate RL training in challenging environments.

</details>


### [30] [Deceptive Exploration in Multi-armed Bandits](https://arxiv.org/abs/2510.08794)
*I. Arda Vurankaya,Mustafa O. Karabag,Wesley A. Suttle,Jesse Milzman,David Fridovich-Keil,Ufuk Topcu*

Main category: cs.LG

TL;DR: 이 논문은 공개 보상과 사적 보상을 가진 다중 무장 밴디트 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 공개 보상에 따라 탐슨 샘플링을 따르는 에이전트를 예상하는 관찰자가 있다. 그러나 기만적인 에이전트는 눈치채이지 않으면서 최상의 사적 팔을 신속하게 확인하고자 한다.

Method: 에이전트가 사용하는 실제 풀 확률과 관찰자가 예상하는 풀 확률 간의 Kullback-Leibler(KL) 발산 제약을 정형화하였다. 공개 비최적 팔의 성공적인 풀링은 성공 확률이 각 성공적인 풀링에 따라 감소하는 % 베르누이 프로세스로 모델링되며, KL 제약 하에서 최대 $	heta(	ext{T}) $ 비율로 발생할 수 있음을 보인다.

Result: 공개 및 사적 평균을 기반으로 한 맥시민 문제를 정식화하고, 그 해결책이 최상의 사적 팔 식별을 위한 최적 오류 지수를 특징짓는다.

Conclusion: 탑-투 알고리즘에서 영감을 받은 알고리즘을 제안하며, 이 알고리즘은 공개 비최적 간극에 따라 팔을 풀 때의 탐색을 자연스럽게 조정한다. 제안된 알고리즘의 행동과 $	heta(	ext{T}) $ 비율을 보여주는 수치적 예제를 제공한다.

Abstract: We consider a multi-armed bandit setting in which each arm has a public and a
private reward distribution. An observer expects an agent to follow Thompson
Sampling according to the public rewards, however, the deceptive agent aims to
quickly identify the best private arm without being noticed. The observer can
observe the public rewards and the pulled arms, but not the private rewards.
The agent, on the other hand, observes both the public and private rewards. We
formalize detectability as a stepwise Kullback-Leibler (KL) divergence
constraint between the actual pull probabilities used by the agent and the
anticipated pull probabilities by the observer. We model successful pulling of
public suboptimal arms as a % Bernoulli process where the success probability
decreases with each successful pull, and show these pulls can happen at most at
a $\Theta(\sqrt{T}) $ rate under the KL constraint. We then formulate a maximin
problem based on public and private means, whose solution characterizes the
optimal error exponent for best private arm identification. We finally propose
an algorithm inspired by top-two algorithms. This algorithm naturally adapts
its exploration according to the hardness of pulling arms based on the public
suboptimality gaps. We provide numerical examples illustrating the
$\Theta(\sqrt{T}) $ rate and the behavior of the proposed algorithm.

</details>


### [31] [Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction](https://arxiv.org/abs/2510.08839)
*Motahare Mounesan,Sourya Saha,Houchao Gan,Md. Nurul Absur,Saptarshi Debroy*

Main category: cs.LG

TL;DR: 이 연구는 3D 재구성을 위한 신뢰할 수 있는 엣지 리소스 관리 프레임워크를 제안하여 자원 제약과 교란이 발생하는 환경에서도 높은 품질의 재구성을 보장한다.


<details>
  <summary>Details</summary>
Motivation: 신뢰할 수 있는 3D 장면 모델링을 통해 상황 인식과 정보에 기반한 의사 결정을 가능하게 하기 위한 필요성이 크다.

Method: 강화 학습 기반의 엣지 리소스 관리 프레임워크를 제안하며, 카메라 선택과 서버 선택을 위해 두 개의 협력적인 Q-학습 에이전트를 사용한다.

Result: 제안된 프레임워크는 동적인 환경에서 종단 간 지연 시간과 재구성 품질을 효과적으로 균형 잡음으로써 애플리케이션 신뢰성을 향상시킨다.

Conclusion: 이 연구는 자원 제약 환경에서 3D 재구성을 위한 효율적인 관리 방법을 제공한다.

Abstract: Real-time multi-view 3D reconstruction is a mission-critical application for
key edge-native use cases, such as fire rescue, where timely and accurate 3D
scene modeling enables situational awareness and informed decision-making.
However, the dynamic and unpredictable nature of edge resource availability
introduces disruptions, such as degraded image quality, unstable network links,
and fluctuating server loads, which challenge the reliability of the
reconstruction pipeline. In this work, we present a reinforcement learning
(RL)-based edge resource management framework for reliable 3D reconstruction to
ensure high quality reconstruction within a reasonable amount of time, despite
the system operating under a resource-constrained and disruption-prone
environment. In particular, the framework adopts two cooperative Q-learning
agents, one for camera selection and one for server selection, both of which
operate entirely online, learning policies through interactions with the edge
environment. To support learning under realistic constraints and evaluate
system performance, we implement a distributed testbed comprising lab-hosted
end devices and FABRIC infrastructure-hosted edge servers to emulate smart city
edge infrastructure under realistic disruption scenarios. Results show that the
proposed framework improves application reliability by effectively balancing
end-to-end latency and reconstruction quality in dynamic environments.

</details>


### [32] [The Boundaries of Fair AI in Medical Image Prognosis: A Causal Perspective](https://arxiv.org/abs/2510.08840)
*Thai-Hoang Pham,Jiayuan Chen,Seungyeon Lee,Yuanlong Wang,Sayoko Moroi,Xueru Zhang,Ping Zhang*

Main category: cs.LG

TL;DR: 이 논문에서는 의료 이미징에서 시간-사건 예측의 공정성을 평가하기 위한 최초의 종합 프레임워크인 FairTTE를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 의료 이미지 분석에서 기계 학습 알고리즘의 사용이 증가함에 따라 특정 사회 집단에 대한 편향 우려가 제기되고 있다.

Method: FairTTE는 다양한 이미징 모달리티와 TTE 결과를 포함하며, 첨단 TTE 예측 및 공정성 알고리즘을 통합하여 의료 이미지 예측의 공정성을 체계적이고 세분화된 방식으로 분석한다.

Result: 대규모 평가를 통해 다양한 이미징 모달리티에서 편향이 만연하며, 현재의 공정성 방법이 제한된 완화 효과를 제공함을 보여준다.

Conclusion: 기존 솔루션의 한계를 강조하며, 보다 강력하고 공정한 예측 모델의 필요성이 시급함을 강조한다.

Abstract: As machine learning (ML) algorithms are increasingly used in medical image
analysis, concerns have emerged about their potential biases against certain
social groups. Although many approaches have been proposed to ensure the
fairness of ML models, most existing works focus only on medical image
diagnosis tasks, such as image classification and segmentation, and overlooked
prognosis scenarios, which involve predicting the likely outcome or progression
of a medical condition over time. To address this gap, we introduce FairTTE,
the first comprehensive framework for assessing fairness in time-to-event (TTE)
prediction in medical imaging. FairTTE encompasses a diverse range of imaging
modalities and TTE outcomes, integrating cutting-edge TTE prediction and
fairness algorithms to enable systematic and fine-grained analysis of fairness
in medical image prognosis. Leveraging causal analysis techniques, FairTTE
uncovers and quantifies distinct sources of bias embedded within medical
imaging datasets. Our large-scale evaluation reveals that bias is pervasive
across different imaging modalities and that current fairness methods offer
limited mitigation. We further demonstrate a strong association between
underlying bias sources and model disparities, emphasizing the need for
holistic approaches that target all forms of bias. Notably, we find that
fairness becomes increasingly difficult to maintain under distribution shifts,
underscoring the limitations of existing solutions and the pressing need for
more robust, equitable prognostic models.

</details>


### [33] [When LLM Agents Meet Graph Optimization: An Automated Data Quality Improvement Approach](https://arxiv.org/abs/2510.08952)
*Zhihan Zhang,Xunkai Li,Yilong Zuo,Zhenjun Li,Bing Zhou,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: TAG에서 GNN 성능 저하를 해결하기 위한 데이터 중심 최적화 접근법.


<details>
  <summary>Details</summary>
Motivation: TAG의 성능이 입력 품질에 민감하다는 점을 개선하고자 한다.

Method: LAGA라는 여러 협업 에이전트를 포함한 프레임워크를 제안한다.

Result: LAGA는 그래프 품질을 향상시키고 다양한 작업에서 최신 성능을 달성한다.

Conclusion: 데이터 중심 품질 최적화가 신뢰할 수 있는 TAG와 강력한 그래프 학습의 핵심임을 입증한다.

Abstract: Text-attributed graphs (TAGs) have emerged as a powerful representation that
combines structural connections with fine-grained semantics, supporting a wide
range of data-centric applications. However, the performance of graph neural
networks (GNNs) on TAGs is highly sensitive to input quality. Our empirical
study shows that both traditional GNNs and LLM-enhanced GNNs suffer significant
degradation across nine representative scenarios of sparsity, noise, and
imbalance, highlighting graph quality as a critical bottleneck. Existing
approaches mainly focus on improving model architectures, while neglecting
systematic optimization of TAG data itself, leading to limited effectiveness in
practice. To address this gap, we propose LAGA (Large Language and Graph
Agent), a unified multi-agent framework that treats graph quality control as a
first-class, data-centric problem. LAGA integrates four collaborative
agents-detection, planning, action, and evaluation-into an automated closed
loop. At its core, the action agent employs a dual-encoder and tri-objective
design to capture complementary information across modalities and perform
holistic graph quality enhancement. Experiments across nine scenarios show that
LAGA improves graph quality and achieves state-of-the-art performance across
various tasks and backbones, validating data-centric quality optimization as
key to reliable TAGs and robust graph learning.

</details>


### [34] [MagicDock: Toward Docking-oriented De Novo Ligand Design via Gradient Inversion](https://arxiv.org/abs/2510.09020)
*Zekai Chen,Xunkai Li,Sirui Zhang,Henan Sun,Jia Li,Zhenjun Li,Bing Zhou,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: MagicDock는 단백질 수용체에 효과적으로 결합할 수 있는 리간드를 디자인하기 위한 혁신적인 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 리간드 디자인은 생물의학 응용에서 중요한 역할을 하며, 기존 연구들은 여러 한계에 직면해 있습니다.

Method: 우리는 점진적 파이프라인과 미분 가능한 표면 모델링에 기초한 MagicDock 프레임워크를 제안합니다. 이는 도킹 지식을 포함하고, 역 경량 흐름을 사용하여 리간드 생성을 유도합니다.

Result: MagicDock는 9개 시나리오에서 평균 27.1% 및 11.7%의 개선을 보여줍니다.

Conclusion: 리간드 디자인에 있어 MagicDock는 널리 적용 가능하며 각 구성 요소에 대한 이론적 보장을 제공합니다.

Abstract: De novo ligand design is a fundamental task that seeks to generate protein or
molecule candidates that can effectively dock with protein receptors and
achieve strong binding affinity entirely from scratch. It holds paramount
significance for a wide spectrum of biomedical applications. However, most
existing studies are constrained by the \textbf{Pseudo De Novo},
\textbf{Limited Docking Modeling}, and \textbf{Inflexible Ligand Type}. To
address these issues, we propose MagicDock, a forward-looking framework
grounded in the progressive pipeline and differentiable surface modeling. (1)
We adopt a well-designed gradient inversion framework. To begin with, general
docking knowledge of receptors and ligands is incorporated into the backbone
model. Subsequently, the docking knowledge is instantiated as reverse gradient
flows by binding prediction, which iteratively guide the de novo generation of
ligands. (2) We emphasize differentiable surface modeling in the docking
process, leveraging learnable 3D point-cloud representations to precisely
capture binding details, thereby ensuring that the generated ligands preserve
docking validity through direct and interpretable spatial fingerprints. (3) We
introduce customized designs for different ligand types and integrate them into
a unified gradient inversion framework with flexible triggers, thereby ensuring
broad applicability. Moreover, we provide rigorous theoretical guarantees for
each component of MagicDock. Extensive experiments across 9 scenarios
demonstrate that MagicDock achieves average improvements of 27.1\% and 11.7\%
over SOTA baselines specialized for protein or molecule ligand design,
respectively.

</details>


### [35] [Robust Driving Control for Autonomous Vehicles: An Intelligent General-sum Constrained Adversarial Reinforcement Learning Approach](https://arxiv.org/abs/2510.09041)
*Junchao Fan,Xiaolin Chang*

Main category: cs.LG

TL;DR: 이 논문은 심층 강화 학습의 자율 주행 정책 개발에서의 성공에도 불구하고, 적대적 공격에 대한 취약성을 해결하기 위해 IGCARL이라는 새로운 방법론을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 주행 시스템의 실제 배치를 위해 적대적 공격에 대한 안정성과 안전성을 확보해야 합니다.

Method: IGCARL은 전략적, 목표 지향적 적대자와 강력한 주행 에이전트로 구성되어, 안전-critical 이벤트를 유도하는 전략적 다단계 공격을 수행합니다.

Result: IGCARL은 최신 방법에 비해 최소 27.9%의 성공률 향상을 보여줍니다.

Conclusion: IGCARL은 적대적 공격에 대한 뛰어난 강건성을 나타내며, DRL 기반 자율 주행의 안전성과 신뢰성을 향상시킵니다.

Abstract: Deep reinforcement learning (DRL) has demonstrated remarkable success in
developing autonomous driving policies. However, its vulnerability to
adversarial attacks remains a critical barrier to real-world deployment.
Although existing robust methods have achieved success, they still suffer from
three key issues: (i) these methods are trained against myopic adversarial
attacks, limiting their abilities to respond to more strategic threats, (ii)
they have trouble causing truly safety-critical events (e.g., collisions), but
instead often result in minor consequences, and (iii) these methods can
introduce learning instability and policy drift during training due to the lack
of robust constraints. To address these issues, we propose Intelligent
General-sum Constrained Adversarial Reinforcement Learning (IGCARL), a novel
robust autonomous driving approach that consists of a strategic targeted
adversary and a robust driving agent. The strategic targeted adversary is
designed to leverage the temporal decision-making capabilities of DRL to
execute strategically coordinated multi-step attacks. In addition, it
explicitly focuses on inducing safety-critical events by adopting a general-sum
objective. The robust driving agent learns by interacting with the adversary to
develop a robust autonomous driving policy against adversarial attacks. To
ensure stable learning in adversarial environments and to mitigate policy drift
caused by attacks, the agent is optimized under a constrained formulation.
Extensive experiments show that IGCARL improves the success rate by at least
27.9\% over state-of-the-art methods, demonstrating superior robustness to
adversarial attacks and enhancing the safety and reliability of DRL-based
autonomous driving.

</details>


### [36] [Agentic-KGR: Co-evolutionary Knowledge Graph Construction through Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.09156)
*Jing Li,Zhijie Sun,Zhicheng Zhou,Suming Qiu,Junjie Huang,Haijia Sun,Linyuan Qiu*

Main category: cs.LG

TL;DR: 이 논문은 동적 정보 환경에서의 효과성을 제한하는 기존의 고정 지식 기반 모델의 한계를 극복하기 위해, LLM과 지식 그래프의 공동 진화를 가능하게 하는 Agentic-KGR 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 지식 강화 대형 언어 모델은 정적 지식 기반에 의존하며, 이는 커버리지 부족과 시간적 노후화로 인해 동적 정보 환경에서의 효과성을 제한합니다.

Method: Agentic-KGR은 다중 라운드 강화 학습을 통해 LLM과 지식 그래프 간의 공동 진화를 가능하게 하는 새로운 프레임워크로, 동적 스키마 확장 메커니즘, 검색 증강 메모리 시스템, 학습 가능 다중 스케일 프롬프트 압축 방식을 도입합니다.

Result: 실험 결과, 이 방법은 지식 추출 작업에서 감독 기준선 및 단일 라운드 RL 접근 방식보다 상당한 개선을 보여주었습니다. GraphRAG와 통합했을 때, 기존 방법들에 비해 하위 질문 응답 작업에서 정확성 및 지식 커버리지에서 유의미한 향상을 달성했습니다.

Conclusion: Agentic-KGR는 동적 정보 환경에서의 LLM과 지식 구조 간의 시너지 효과를 극대화하여 지식 기반 시스템의 성능을 크게 향상시킵니다.

Abstract: Current knowledge-enhanced large language models (LLMs) rely on static,
pre-constructed knowledge bases that suffer from coverage gaps and temporal
obsolescence, limiting their effectiveness in dynamic information environments.
We present Agentic-KGR, a novel framework enabling co-evolution between LLMs
and knowledge graphs (KGs) through multi-round reinforcement learning (RL). Our
approach introduces three key innovations: (1) a dynamic schema expansion
mechanism that systematically extends graph ontologies beyond pre-defined
boundaries during training; (2) a retrieval-augmented memory system enabling
synergistic co-evolution between model parameters and knowledge structures
through continuous optimization; (3) a learnable multi-scale prompt compression
approach that preserves critical information while reducing computational
complexity through adaptive sequence optimization. Experimental results
demonstrate substantial improvements over supervised baselines and single-round
RL approaches in knowledge extraction tasks. When integrated with GraphRAG, our
method achieves superior performance in downstream QA tasks, with significant
gains in both accuracy and knowledge coverage compared to existing methods.

</details>


### [37] [Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs](https://arxiv.org/abs/2510.09201)
*Yumin Choi,Dongki Kim,Jinheon Baek,Sung Ju Hwang*

Main category: cs.LG

TL;DR: 본 논문에서는 다중 모달 프롬프트 최적화 문제를 제안하고, 이를 해결하기 위해 다중 모달 프롬프트 최적화기(MPO)라는 통합 프레임워크를 개발하였습니다.


<details>
  <summary>Details</summary>
Motivation: MLLM의 잠재력을 최대한 활용하기 위해 다중 모달 프롬프트 최적화 필요.

Method: MPO는 정렬 보존 업데이트를 통해 다중 모달 프롬프트의 공동 최적화를 수행하며, 이전 평가를 기반으로 후보 프롬프트 선택 과정을 안내합니다.

Result: MPO는 이미지, 비디오, 분자 등의 다양한 모달리티에서 텍스트 전용 최적화 방법보다 우수한 성능을 보여주었습니다.

Conclusion: 다중 모달 프롬프트 최적화는 MLLM의 잠재력을 실현하는 중요한 단계로 자리 잡았습니다.

Abstract: Large Language Models (LLMs) have shown remarkable success, and their
multimodal expansions (MLLMs) further unlock capabilities spanning images,
videos, and other modalities beyond text. However, despite this shift, prompt
optimization approaches, designed to reduce the burden of manual prompt
crafting while maximizing performance, remain confined to text, ultimately
limiting the full potential of MLLMs. Motivated by this gap, we introduce the
new problem of multimodal prompt optimization, which expands the prior
definition of prompt optimization to the multimodal space defined by the pairs
of textual and non-textual prompts. To tackle this problem, we then propose the
Multimodal Prompt Optimizer (MPO), a unified framework that not only performs
the joint optimization of multimodal prompts through alignment-preserving
updates but also guides the selection process of candidate prompts by
leveraging earlier evaluations as priors in a Bayesian-based selection
strategy. Through extensive experiments across diverse modalities that go
beyond text, such as images, videos, and even molecules, we demonstrate that
MPO outperforms leading text-only optimization methods, establishing multimodal
prompt optimization as a crucial step to realizing the potential of MLLMs.

</details>


### [38] [FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning](https://arxiv.org/abs/2510.09222)
*Zhenglin Wan,Jingxuan Wu,Xingrui Yu,Chubin Zhang,Mingcong Lei,Bo An,Ivor Tsang*

Main category: cs.LG

TL;DR: 학생 정책이 RL 알고리즘과 보상 모델을 통해 환경을 탐색하고 온라인 업데이트되도록 하는 방법을 제안하는 연구.


<details>
  <summary>Details</summary>
Motivation: 전문가 행동 클로닝의 강력한 성능에도 불구하고, FM 기반 정책은 환경과의 상호작용 부족으로 인해 제한적이며, 이를 해결하기 위해 온라인 상호작용이 필요하다.

Method: 간단한 MLP 구조를 가진 학생 정책이 RL 알고리즘을 통해 보상 모델로 업데이트되며, 이 보상 모델은 전문가 데이터 분포의 정보를 담고 있는 교사 FM 모델과 연관된다.

Result: 우리의 방법은 학습 효율성, 일반화 및 강인성을 크게 향상시켰으며, 특히 비최적 전문가 데이터로부터 학습할 때 효과적이다.

Conclusion: 학생 정책의 간단한 구조 덕분에 FM 정책의 기울기 불안정을 피하고, 교사 FM 모델의 표현력을 활용하면서 효과적인 온라인 탐색이 가능하게 된다.

Abstract: Flow Matching (FM) has shown remarkable ability in modeling complex
distributions and achieves strong performance in offline imitation learning for
cloning expert behaviors. However, despite its behavioral cloning
expressiveness, FM-based policies are inherently limited by their lack of
environmental interaction and exploration. This leads to poor generalization in
unseen scenarios beyond the expert demonstrations, underscoring the necessity
of online interaction with environment. Unfortunately, optimizing FM policies
via online interaction is challenging and inefficient due to instability in
gradient computation and high inference costs. To address these issues, we
propose to let a student policy with simple MLP structure explore the
environment and be online updated via RL algorithm with a reward model. This
reward model is associated with a teacher FM model, containing rich information
of expert data distribution. Furthermore, the same teacher FM model is utilized
to regularize the student policy's behavior to stabilize policy learning. Due
to the student's simple architecture, we avoid the gradient instability of FM
policies and enable efficient online exploration, while still leveraging the
expressiveness of the teacher FM model. Extensive experiments show that our
approach significantly enhances learning efficiency, generalization, and
robustness, especially when learning from suboptimal expert data.

</details>


### [39] [Residual-Informed Learning of Solutions to Algebraic Loops](https://arxiv.org/abs/2510.09317)
*Felix Brandt,Andreas Heuermann,Philip Hannebohm,Bernhard Bachmann*

Main category: cs.LG

TL;DR: 이 연구는 신경망 대체물을 사용하여 모델리카 모델의 대수적 루프를 교체하는 잔여 정보를 활용한 머신러닝 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대수적 루프를 처리하는 효율적인 방법을 찾기 위해서는 기존 방법의 한계점을 극복해야 한다.

Method: 피드포워드 신경망을 학습시키고 손실 함수에 대수적 루프의 잔여(오차)를 직접 사용하는 방식이다.

Result: IEEE 14-버스 시스템에 적용했을 때, 기존 시뮬레이션에 비해 60%의 시뮬레이션 시간 단축을 달성하였다.

Conclusion: 오류 제어 메커니즘을 통해 동일한 정확도 수준을 유지하면서 성능이 향상되었다.

Abstract: This paper presents a residual-informed machine learning approach for
replacing algebraic loops in equation-based Modelica models with neural network
surrogates. A feedforward neural network is trained using the residual (error)
of the algebraic loop directly in its loss function, eliminating the need for a
supervised dataset. This training strategy also resolves the issue of ambiguous
solutions, allowing the surrogate to converge to a consistent solution rather
than averaging multiple valid ones. Applied to the large-scale IEEE 14-Bus
system, our method achieves a 60% reduction in simulation time compared to
conventional simulations, while maintaining the same level of accuracy through
error control mechanisms.

</details>


### [40] [Rate optimal learning of equilibria from data](https://arxiv.org/abs/2510.09325)
*Till Freihaut,Luca Viano,Emanuele Nevali,Volkan Cevher,Matthieu Geist,Giorgia Ramponi*

Main category: cs.LG

TL;DR: 다중 에이전트 모방 학습(MAIL)의 이론적 간극을 해소하며 비상호작용 및 상호작용 알고리즘을 제시함.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 모방 학습(MAIL)의 이론적 한계를 규명하고, 비상호작용 MAIL의 한계를 캐릭터라이즈함으로써 관련된 연구를 심화하기 위함이다.

Method: 비상호작용 환경에서 통계적 하한을 증명하고, 상호작용 환경에서는 보상 없는 강화 학습과 통합된 MAIL 알고리즘인 MAIL-WARM을 제안한다.

Result: MAIL-WARM은 이전 알려진 최상의 샘플 복잡도를 $	ext{O}(	ext{ε}^{-8})$에서 $	ext{O}(	ext{ε}^{-2})$로 개선하여 우리 하한과 일치시킨다.

Conclusion: 우리는 이론을 지원하는 수치적 결과를 제공하고, Behavior Cloning이 학습에 실패하는 환경에서도 시연한다.

Abstract: We close open theoretical gaps in Multi-Agent Imitation Learning (MAIL) by
characterizing the limits of non-interactive MAIL and presenting the first
interactive algorithm with near-optimal sample complexity. In the
non-interactive setting, we prove a statistical lower bound that identifies the
all-policy deviation concentrability coefficient as the fundamental complexity
measure, and we show that Behavior Cloning (BC) is rate-optimal. For the
interactive setting, we introduce a framework that combines reward-free
reinforcement learning with interactive MAIL and instantiate it with an
algorithm, MAIL-WARM. It improves the best previously known sample complexity
from $\mathcal{O}(\varepsilon^{-8})$ to $\mathcal{O}(\varepsilon^{-2}),$
matching the dependence on $\varepsilon$ implied by our lower bound. Finally,
we provide numerical results that support our theory and illustrate, in
environments such as grid worlds, where Behavior Cloning fails to learn.

</details>


### [41] [Safety Game: Balancing Safe and Informative Conversations with Blackbox Agentic AI using LP Solvers](https://arxiv.org/abs/2510.09330)
*Tuan Nguyen,Long Tran-Thanh*

Main category: cs.LG

TL;DR: 이 논문은 대형 언어 모델의 안전성을 보장하기 위한 새로운 접근 방식을 제안하며, 재훈련 없이 블랙박스 프레임워크를 통해 안전 정렬을 실현합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 안전성을 보장하는 것은 AI 배치에서 중요한 도전 과제입니다. 기존의 정렬 방법은 주로 훈련 중에 작동하며, 새로운 요구 사항이 발생하면 재훈련이 필요합니다.

Method: 우리는 재훈련이나 기본 LLM 아키텍처에 대한 접근 없이 안전 정렬을 위한 모델 독립적 블랙박스 프레임워크를 제안합니다. 이 프레임워크는 이익과 안전성 간의 트레이드오프 문제를 두 플레이어 제로섬 게임으로 형식화합니다.

Result: 우리의 결과는 블랙박스 안전 정렬의 실행 가능성을 보여주며, 자원이 제한된 환경의 이해관계자들이 빠르게 진화하는 LLM 생태계에서 안전성을 강화할 수 있는 경로를 제공합니다.

Conclusion: 이 연구는 다양한 이해관계자들이 LLM의 안전성을 보장하는 스케일 가능하고 접근 가능한 방법을 제시합니다.

Abstract: Ensuring that large language models (LLMs) comply with safety requirements is
a central challenge in AI deployment. Existing alignment approaches primarily
operate during training, such as through fine-tuning or reinforcement learning
from human feedback, but these methods are costly and inflexible, requiring
retraining whenever new requirements arise. Recent efforts toward
inference-time alignment mitigate some of these limitations but still assume
access to model internals, which is impractical, and not suitable for third
party stakeholders who do not have access to the models. In this work, we
propose a model-independent, black-box framework for safety alignment that does
not require retraining or access to the underlying LLM architecture. As a proof
of concept, we address the problem of trading off between generating safe but
uninformative answers versus helpful yet potentially risky ones. We formulate
this dilemma as a two-player zero-sum game whose minimax equilibrium captures
the optimal balance between safety and helpfulness. LLM agents operationalize
this framework by leveraging a linear programming solver at inference time to
compute equilibrium strategies. Our results demonstrate the feasibility of
black-box safety alignment, offering a scalable and accessible pathway for
stakeholders, including smaller organizations and entities in
resource-constrained settings, to enforce safety across rapidly evolving LLM
ecosystems.

</details>


### [42] [Cross-Receiver Generalization for RF Fingerprint Identification via Feature Disentanglement and Adversarial Training](https://arxiv.org/abs/2510.09405)
*Yuhao Pan,Xiucheng Wang,Nan Cheng,Wenchao Xu*

Main category: cs.LG

TL;DR: 라디오 주파수 지문 식별(RFFI)은 무선 네트워크 보안을 위한 핵심 기술로, 장치 제조 과정에서 발생하는 하드웨어 수준의 불완전성을 활용하여 송신기를 정확하게 식별한다. 그러나 심층 신경망은 실제 환경에서 수신기로 인한 변동으로 인해 배치에 어려움을 겪는다.


<details>
  <summary>Details</summary>
Motivation: 무선 네트워크 보안 확보를 위한 신뢰성 높은 송신기 식별 기술의 필요.

Method: 적대적 훈련과 스타일 전송을 통합하여 송신기 및 수신기 특징을 명시적으로 분리하는 RFFI 프레임워크를 제안.

Result: 다수의 수신기 데이터 세트에 대한 광범위한 실험 결과, 제안한 접근 방식이 최신 기준을 지속적으로 초과 달성하며 다양한 수신기 설정에서 평균 정확도가 최대 10% 향상됨.

Conclusion: 제안한 방법은 수신기 변경에 대한 강인성을 보장하며, 송신기 특정 하드웨어 서명을 수신기 인공물로부터 분리한다.

Abstract: Radio frequency fingerprint identification (RFFI) is a critical technique for
wireless network security, leveraging intrinsic hardware-level imperfections
introduced during device manufacturing to enable precise transmitter
identification. While deep neural networks have shown remarkable capability in
extracting discriminative features, their real-world deployment is hindered by
receiver-induced variability. In practice, RF fingerprint signals comprise
transmitter-specific features as well as channel distortions and
receiver-induced biases. Although channel equalization can mitigate channel
noise, receiver-induced feature shifts remain largely unaddressed, causing the
RFFI models to overfit to receiver-specific patterns. This limitation is
particularly problematic when training and evaluation share the same receiver,
as replacing the receiver in deployment can cause substantial performance
degradation. To tackle this challenge, we propose an RFFI framework robust to
cross-receiver variability, integrating adversarial training and style transfer
to explicitly disentangle transmitter and receiver features. By enforcing
domain-invariant representation learning, our method isolates genuine hardware
signatures from receiver artifacts, ensuring robustness against receiver
changes. Extensive experiments on multi-receiver datasets demonstrate that our
approach consistently outperforms state-of-the-art baselines, achieving up to a
10% improvement in average accuracy across diverse receiver settings.

</details>


### [43] [Near-Optimal Second-Order Guarantees for Model-Based Adversarial Imitation Learning](https://arxiv.org/abs/2510.09487)
*Shangzhe Li,Dongruo Zhou,Weitong Zhang*

Main category: cs.LG

TL;DR: 온라인 적대적 모방 학습(AIL)의 모델 기반 알고리즘(MB-AIL)을 제안하고, 보상 없이 전문가 데이터와 상호작용하는 시스템의 샘플 복잡도를 보장.


<details>
  <summary>Details</summary>
Motivation: 온라인 상호작용의 이점과 불확실성의 영향을 잘 이해하지 못하고 있는 것을 해결하기 위함.

Method: 모델 기반 AIL 알고리즘(MB-AIL)을 도입하고 일반 함수 근사 하에 두 번째 샘플 복잡도 보장을 제공함.

Result: 온라인 상호작용에 대한 minimax-optimal 샘플 복잡도를 달성하고, 전문가 시연에 대한 하한과의 일치성을 보여줌.

Conclusion: MB-AIL의 실용적인 구현이 기존 방법의 샘플 효율성에 필적하거나 초과함을 증명.

Abstract: We study online adversarial imitation learning (AIL), where an agent learns
from offline expert demonstrations and interacts with the environment online
without access to rewards. Despite strong empirical results, the benefits of
online interaction and the impact of stochasticity remain poorly understood. We
address these gaps by introducing a model-based AIL algorithm (MB-AIL) and
establish its horizon-free, second-order sample-complexity guarantees under
general function approximations for both expert data and reward-free
interactions. These second-order bounds provide an instance-dependent result
that can scale with the variance of returns under the relevant policies and
therefore tighten as the system approaches determinism. Together with
second-order, information-theoretic lower bounds on a newly constructed
hard-instance family, we show that MB-AIL attains minimax-optimal sample
complexity for online interaction (up to logarithmic factors) with limited
expert demonstrations and matches the lower bound for expert demonstrations in
terms of the dependence on horizon $H$, precision $\epsilon$ and the policy
variance $\sigma^2$. Experiments further validate our theoretical findings and
demonstrate that a practical implementation of MB-AIL matches or surpasses the
sample efficiency of existing methods.

</details>


### [44] [MODE: Learning compositional representations of complex systems with Mixtures Of Dynamical Experts](https://arxiv.org/abs/2510.09594)
*Nathan Quiblier,Roy Friedman,Matthew Ricci*

Main category: cs.LG

TL;DR: 이 논문은 생명과학의 동적 시스템에서 복잡한 행동 체계의 변환을 모델링하기 위한 새로운 프레임워크인 MODE를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 흐름 기반 모델링 기법이 적용하기 어려운 잡음이 많은 전환을 다루기 위해.

Method: MODE는 복잡한 동적 시스템을 희소하고 해석 가능한 구성요소로 분해하는 그래픽 모델링 프레임워크이다.

Result: 합성 및 실제 생물정보 데이터 세트에서 MODE의 성능을 평가하여 노이즈가 많은 환경에서도 우수한 결과를 얻었다.

Conclusion: MODE는 세포 생물학에서 중요한 행동 체계 전환을 모델링하며, 세포가 궁극적인 운명에 헌신할 시점을 예측할 수 있는 능력을 보여준다.

Abstract: Dynamical systems in the life sciences are often composed of complex mixtures
of overlapping behavioral regimes. Cellular subpopulations may shift from
cycling to equilibrium dynamics or branch towards different developmental
fates. The transitions between these regimes can appear noisy and irregular,
posing a serious challenge to traditional, flow-based modeling techniques which
assume locally smooth dynamics. To address this challenge, we propose MODE
(Mixture Of Dynamical Experts), a graphical modeling framework whose neural
gating mechanism decomposes complex dynamics into sparse, interpretable
components, enabling both the unsupervised discovery of behavioral regimes and
accurate long-term forecasting across regime transitions. Crucially, because
agents in our framework can jump to different governing laws, MODE is
especially tailored to the aforementioned noisy transitions. We evaluate our
method on a battery of synthetic and real datasets from computational biology.
First, we systematically benchmark MODE on an unsupervised classification task
using synthetic dynamical snapshot data, including in noisy, few-sample
settings. Next, we show how MODE succeeds on challenging forecasting tasks
which simulate key cycling and branching processes in cell biology. Finally, we
deploy our method on human, single-cell RNA sequencing data and show that it
can not only distinguish proliferation from differentiation dynamics but also
predict when cells will commit to their ultimate fate, a key outstanding
challenge in computational biology.

</details>
