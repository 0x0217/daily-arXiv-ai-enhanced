<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 12]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.CR](#cs.CR) [Total: 4]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework](https://arxiv.org/abs/2509.13520)
*Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis*

Main category: cs.LG

TL;DR: 본 연구에서는 다양한 비모수형 기하학적 도메인에서 해를 일반화하는 기존 접근 방식의 한계를 극복하기 위해 하이브리드 DeepONet-Transolver 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 수치 해석 방법인 유한 요소 해석(FEA)이 고비용이기 때문에, 보다 효율적인 대체 방법이 필요하다.

Method: hybrid DeepONet-Transolver 프레임워크를 활용하여, 병렬로 노드 변위 필드와 반응력의 시간 변화를 예측한다.

Result: 제안된 프레임워크는 네 개의 디자인 변수를 가진 보틀 패밀리에서 변위 필드에 대한 평균 상대 $L^{2}$ 오차 2.5-13% 및 시간 의존적 반응력에 대해 약 2.4%의 오차를 달성하였다.

Conclusion: 우리의 프레임워크는 다양한 보틀 기하학 전반에 걸쳐 주요 물리적 현상을 정확하게 포착하며, 계산 기계학 및 신속한 디자인 평가가 필요한 응용 프로그램에서 스케일 가능하고 계산 효율적인 대체 방법으로서의 잠재력을 강조한다.

Abstract: Neural surrogates and operator networks for solving partial differential
equation (PDE) problems have attracted significant research interest in recent
years. However, most existing approaches are limited in their ability to
generalize solutions across varying non-parametric geometric domains. In this
work, we address this challenge in the context of Polyethylene Terephthalate
(PET) bottle buckling analysis, a representative packaging design problem
conventionally solved using computationally expensive finite element analysis
(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously
predicts nodal displacement fields and the time evolution of reaction forces
during top load compression. Our methodology is evaluated on two families of
bottle geometries parameterized by two and four design variables. Training data
is generated using nonlinear FEA simulations in Abaqus for 254 unique designs
per family. The proposed framework achieves mean relative $L^{2}$ errors of
2.5-13% for displacement fields and approximately 2.4% for time-dependent
reaction forces for the four-parameter bottle family. Point-wise error analyses
further show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,
with the largest discrepancies confined to localized geometric regions.
Importantly, the model accurately captures key physical phenomena, such as
buckling behavior, across diverse bottle geometries. These results highlight
the potential of our framework as a scalable and computationally efficient
surrogate, particularly for multi-task predictions in computational mechanics
and applications requiring rapid design evaluation.

</details>


### [2] [LLM-I: LLMs are Naturally Interleaved Multimodal Creators](https://arxiv.org/abs/2509.13642)
*Zirun Guo,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.LG

TL;DR: LLM-Interleaved (LLM-I)는 이미지-텍스트 생성을 도구 활용 문제로 재정의하는 유연하고 동적인 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 현재 통합 모델의 '하나의 도구' 병목 현상을 극복하고자 한다.

Method: 중앙 LLM 또는 MLLM 에이전트를 통해 다양한 전문 비주얼 도구를 지능적으로 조율하는 방법이다.

Result: LLM-I는 네 가지 벤치마크에서 기존 방법을 크게 초월하는 최첨단 성능을 보여준다.

Conclusion: 새로운 데이터셋을 통해 훈련되었으며, 성능 향상을 위한 새로운 테스트 시간 스케일링 전략도 소개한다.

Abstract: We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.

</details>


### [3] [Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques](https://arxiv.org/abs/2509.14078)
*Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov*

Main category: cs.LG

TL;DR: 이 연구는 다양한 최적화 기법을 사용하여 EEG 주파수 대역에서의 분류기 성능을 조사하고 좌우 반구의 효율적인 클래스 예측을 평가합니다.


<details>
  <summary>Details</summary>
Motivation: EEG 주파수 대역에서의 분류 성능을 개선하고 다양한 신경망 구조와 최적화 기법의 효용성을 평가하기 위한 동기입니다.

Method: 딥 밀집 신경망, 얕은 3층 네트워크, 컨볼루션 신경망(CNN)을 TensorFlow와 PyTorch 프레임워크를 사용하여 구현하고 비교했습니다.

Result: Adagrad와 RMSprop 최적화 기법이 다양한 주파수 대역에서 일관되게 우수한 성능을 보이며, Adadelta가 교차 모델 평가에서 강력한 성능을 보입니다. CNN은 EEG 데이터의 공간적 특징을 포착하는 데 특히 두 번째로 높은 정확도를 보여줍니다.

Conclusion: 최적화 기법 선택, 모델 구조 및 EEG 주파수 대역 분석이 분류기 성능 향상과 신경영상 기반 분류 작업에서의 특징 중요성을 이해하는 데 중요함을 강조합니다.

Abstract: This study investigates classifier performance across EEG frequency bands
using various optimizers and evaluates efficient class prediction for the left
and right hemispheres. Three neural network architectures - a deep dense
network, a shallow three-layer network, and a convolutional neural network
(CNN) - are implemented and compared using the TensorFlow and PyTorch
frameworks. Results indicate that the Adagrad and RMSprop optimizers
consistently perform well across different frequency bands, with Adadelta
exhibiting robust performance in cross-model evaluations. Specifically, Adagrad
excels in the beta band, while RMSprop achieves superior performance in the
gamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among
the models, the CNN demonstrates the second highest accuracy, particularly in
capturing spatial features of EEG data. The deep dense network shows
competitive performance in learning complex patterns, whereas the shallow
three-layer network, sometimes being less accurate, provides computational
efficiency. SHAP (Shapley Additive Explanations) plots are employed to identify
efficient class prediction, revealing nuanced contributions of EEG frequency
bands to model accuracy. Overall, the study highlights the importance of
optimizer selection, model architecture, and EEG frequency band analysis in
enhancing classifier performance and understanding feature importance in
neuroimaging-based classification tasks.

</details>


### [4] [TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits](https://arxiv.org/abs/2509.14169)
*Ziming Wei,Zichen Kong,Yuan Wang,David Z. Pan,Xiyuan Tang*

Main category: cs.LG

TL;DR: 이 논문에서는 TopoSizing이라는 프레임워크를 제안하여 회로 이해를 강화하고 최적화를 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 아날로그 및 혼합 신호 회로 설계는 고품질 데이터 부족과 도메인 지식 자동화 흐름에 통합의 어려움으로 인해 도전적입니다.

Method: TopoSizing이라는 엔드 투 엔드 프레임워크를 통해 원시 넷리스트에서 직접 회로를 이해하고 이 지식을 최적화 이점으로 변환합니다. 이 프레임워크는 그래프 알고리즘을 사용하여 회로를 계층적 장치-모듈-단계 표현으로 구성한 후, LLM 에이전트가 반복적인 가설-검증-수정 루프를 수행합니다.

Result: 검증된 통찰력은 LLM 가이드 초기 샘플링과 정체-triggered 신뢰 구역 업데이트를 통해 베이esian 최적화에 통합되어 효율성을 개선하고 실행 가능성을 보존합니다.

Conclusion: Toposizing은 수동 개입 없이도 효율성과 투명성을 높이면서 회로 설계의 최적화를 지원하는 잠재력을 가지고 있습니다.

Abstract: Analog and mixed-signal circuit design remains challenging due to the
shortage of high-quality data and the difficulty of embedding domain knowledge
into automated flows. Traditional black-box optimization achieves sampling
efficiency but lacks circuit understanding, which often causes evaluations to
be wasted in low-value regions of the design space. In contrast, learning-based
methods embed structural knowledge but are case-specific and costly to retrain.
Recent attempts with large language models show potential, yet they often rely
on manual intervention, limiting generality and transparency. We propose
TopoSizing, an end-to-end framework that performs robust circuit understanding
directly from raw netlists and translates this knowledge into optimization
gains. Our approach first applies graph algorithms to organize circuits into a
hierarchical device-module-stage representation. LLM agents then execute an
iterative hypothesis-verification-refinement loop with built-in consistency
checks, producing explicit annotations. Verified insights are integrated into
Bayesian optimization through LLM-guided initial sampling and
stagnation-triggered trust-region updates, improving efficiency while
preserving feasibility.

</details>


### [5] [TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning](https://arxiv.org/abs/2509.14172)
*Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao*

Main category: cs.LG

TL;DR: TGPO라는 오프라인 강화 학습 프레임워크를 소개하며, 이는 웹 상호작용을 자동화하는 데 필요한 웹 에이전트를 훈련하는 데 있어 기존 방법보다 우수한 성과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델과 비전-언어 모델의 신속한 발전으로 웹 에이전트를 자동화하는 것이 필수가 되었다.

Method: TGPO는 트리 구조의 경로 표현을 사용하여 의미적으로 유사한 상태를 병합하고, 프로세스 보상 모델을 통해 세밀한 보상을 자동 생성하며, 동적 가중치 메커니즘을 사용한다.

Result: TGPO는 Online-Mind2Web 및 C-WebShop 데이터셋에서 기존 방법보다 높은 성공률과 더 적은 중복 단계를 기록했다.

Conclusion: TGPO는 웹 에이전트 훈련의 여러 문제를 해결하고, 효율적인 강화 학습을 제공한다.

Abstract: With the rapid advancement of large language models and vision-language
models, employing large models as Web Agents has become essential for automated
web interaction. However, training Web Agents with reinforcement learning faces
critical challenges including credit assignment misallocation, prohibitively
high annotation costs, and reward sparsity. To address these issues, we propose
Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning
framework that proposes a tree-structured trajectory representation merging
semantically identical states across trajectories to eliminate label conflicts.
Our framework incorporates a Process Reward Model that automatically generates
fine-grained rewards through subgoal progress, redundancy detection, and action
verification. Additionally, a dynamic weighting mechanism prioritizes
high-impact decision points during training. Experiments on Online-Mind2Web and
our self-constructed C-WebShop datasets demonstrate that TGPO significantly
outperforms existing methods, achieving higher success rates with fewer
redundant steps.

</details>


### [6] [NIRVANA: Structured pruning reimagined for large language models compression](https://arxiv.org/abs/2509.14230)
*Mengting Ai,Tianxin Wei,Sirui Chen,Jingrui He*

Main category: cs.LG

TL;DR: NIRVANA는 대형 언어 모델의 구조적 프루닝을 위한 새로운 방법으로, 제로샷 정확도와 강력한 미세 조정 능력을 균형 있게 유지합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 구조적 프루닝 방법들은 성능 저하가 심각하고, 비싸고 복잡한 회복 기술이 필요하여 문제를 겪고 있습니다.

Method: NIRVANA는 Neural Tangent Kernel에서 기인한 1차 개선 기준을 활용하여 모델 훈련 행동을 존중하는 이론적으로 기반이 있는 프루닝 전략을 제공합니다. 또한, 계층과 모듈 전반에 걸쳐 적응형 희소성 할당 메커니즘을 통합합니다.

Result: NIRVANA는 동일한 희소성 제약 하에서 기존의 구조적 프루닝 방법들을 능가하며, 균형 잡힌 프루닝 강도를 조정합니다.

Conclusion: NIRVANA는 대형 언어 모델의 압축에 있어 이론적으로 타당하고 실용적인 접근 방식을 제공하며, 코드가 공개되어 있습니다.

Abstract: Structured pruning of large language models (LLMs) offers substantial
efficiency improvements by removing entire hidden units, yet current approaches
often suffer from significant performance degradation, particularly in
zero-shot settings, and necessitate costly recovery techniques such as
supervised fine-tuning (SFT) or adapter insertion. To address these critical
shortcomings, we introduce NIRVANA, a novel pruning method explicitly designed
to balance immediate zero-shot accuracy preservation with robust fine-tuning
capability. Leveraging a first-order saliency criterion derived from the Neural
Tangent Kernel under Adam optimization dynamics, NIRVANA provides a
theoretically grounded pruning strategy that respects essential model training
behaviors. To further address the unique challenges posed by structured
pruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across
layers and modules (attention vs. MLP), which adjusts pruning intensity between
modules in a globally balanced manner. Additionally, to mitigate the high
sensitivity of pruning decisions to calibration data quality, we propose a
simple yet effective KL divergence-based calibration data selection strategy,
ensuring more reliable and task-agnostic pruning outcomes. Comprehensive
experiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA
outperforms existing structured pruning methods under equivalent sparsity
constraints, providing a theoretically sound and practical approach to LLM
compression. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.

</details>


### [7] [Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets](https://arxiv.org/abs/2010.01052)
*Jaume Banus,Maxime Sermesant,Oscar Camara,Marco Lorenzi*

Main category: cs.LG

TL;DR: 이 논문은 불완전한 심장 데이터를 가진 뇌 연구에 적용할 수 있는 심장 데이터 보완 및 심혈관 기계 모델 개인화를 위한 확률적 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기계 모델의 임상 연구에서의 사용은 다양한 해부학적 및 생리학적 과정에 대한 다중 모드 환자 데이터 부족으로 제한됩니다.

Method: 이 접근법은 사용 가능한 특징에서 심장 정보를 보완하는 보완 모델의 공동 추론을 위한 변분 프레임워크에 기반하고 있습니다.

Result: UK Biobank에 대한 실험 결과, 모델은 최소한의 심장 정보만 포함된 데이터셋에서 누락된 심장 특징을 정확하게 보완할 수 있음을 보여줍니다.

Conclusion: 이 연구는 다양한 뇌 해부학적 조건에 해당하는 현실적인 심장 역학의 시뮬레이션을 통해 심장-뇌 공동 관계를 탐구할 수 있는 새로운 방법을 제공합니다.

Abstract: The use of mechanistic models in clinical studies is limited by the lack of
multi-modal patients data representing different anatomical and physiological
processes. For example, neuroimaging datasets do not provide a sufficient
representation of heart features for the modeling of cardiovascular factors in
brain disorders. To tackle this problem we introduce a probabilistic framework
for joint cardiac data imputation and personalisation of cardiovascular
mechanistic models, with application to brain studies with incomplete heart
data. Our approach is based on a variational framework for the joint inference
of an imputation model of cardiac information from the available features,
along with a Gaussian Process emulator that can faithfully reproduce
personalised cardiovascular dynamics. Experimental results on UK Biobank show
that our model allows accurate imputation of missing cardiac features in
datasets containing minimal heart information, e.g. systolic and diastolic
blood pressures only, while jointly estimating the emulated parameters of the
lumped model. This allows a novel exploration of the heart-brain joint
relationship through simulation of realistic cardiac dynamics corresponding to
different conditions of brain anatomy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Position: AI Safety Must Embrace an Antifragile Perspective](https://arxiv.org/abs/2509.13339)
*Ming Jin,Hyunin Lee*

Main category: cs.AI

TL;DR: 현대 AI 연구는 안전성에 대한 안티프래질 관점을 채택해야 한다. 기존의 정적 벤치마크와 단일 테스트는 환경의 변화를 간과하고 모델이 잘못 적응할 수 있음을 간과한다. 본 논문은 AI 안전성을 지속적으로 향상시키기 위한 방법론의 근본적인 재조정 필요성을 주장한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 장기적인 안전성을 보장하는 능력이 시간이 지남에 따라 확장되어야 한다.

Method: 정적 테스트의 한계를 식별하고, 드물게 발생하는 사건을 관리할 수 있는 안티프래질 솔루션의 가능성을 탐색한다.

Result: 기존의 강인성 접근법을 보완하여 인공지능 안전성을 향상시키기 위한 윤리적이고 실용적인 지침을 제공한다.

Conclusion: AI 안전성을 측정하고 지속적으로 개선하는 방법론의 재조정이 필요하다.

Abstract: This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.

</details>


### [9] [Imagined Autocurricula](https://arxiv.org/abs/2509.13341)
*Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.AI

TL;DR: 이 논문은 생성된 환경에서 에이전트를 훈련시키는 새로운 방법인 IMAC(Imagined Autocurricula)를 제안하며, 이는 비지도 환경 설계를 활용하여 유용한 데이터를 생성하고 에이전트의 일반화 능력을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 많은 경우에는 대규모의 훈련 데이터나 정확한 시뮬레이터 접근이 부족하기 때문에, 대안으로 세계 모델을 활용하고자 함.

Method: IMAC(Imagined Autocurricula)라는 새로운 접근법을 제안하여, 비지도 환경 설계(UED)를 활용하여 생성된 세계에서 자동 커리큘럼을 유도.

Result: 일련의 도전적인 절차적으로 생성된 환경에서, 좁은 데이터셋으로 학습한 세계 모델 내에서만 훈련하고도 보류된 환경에서 강력한 전이 성능을 달성할 수 있음을 보여줌.

Conclusion: 이 연구는 일반적으로 능력을 갖춘 대규모의 기초 세계 모델을 활용할 수 있는 길을 열어준다고 믿음.

Abstract: Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.

</details>


### [10] [OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](https://arxiv.org/abs/2509.13347)
*Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang*

Main category: cs.AI

TL;DR: 이 연구는 다양한 추상화된 행동 공간과 토크나이저를 체계적으로 비교하였고, Chain of Action(CoA)이라는 새로운 프레임워크를 제안하여 고수준 계획과 저수준 제어를 통합하는 방법을 제시했다.


<details>
  <summary>Details</summary>
Motivation: 행동 공간의 선택은 능력 있는 학습 가능한 에이전트를 개발하는 데 있어 중요한 도전이지만, 여전히 해결되지 않았다.

Method: Chain of Action (CoA)이라는 새로운 프레임워크를 도입하여 고수준 계획과 저수준 제어를 단일 VLA 모델 내에서 통합하는 방식을 제안한다.

Result: CoA 패러다임을 사용하여 다양한 행동 공간에서 훈련된 올인원 에이전트는 보다 강력하고 일반화 가능한 정책을 학습하며, 새로운 최신 기술을 달성했다.

Conclusion: 이 통합된 에이전트는 강력하고 특화된 기준선들에 비해 전체 작업 성공률을 향상시켰다.

Abstract: The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA

</details>


### [11] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

TL;DR: UAVs는 현재의 자율성 수준을 넘어 5계층 구조의 Agentic UAVs 프레임워크를 통해 LLM 기반의 추론 및 의사결정을 도입하여, 재난 구조 시나리오에서 성능을 크게 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: UAV의 현재 자율성 수준이 낮고, 동적이고 불확실한 임무에 대한 적응성이 제한되어 있기 때문에 새로운 접근 방식이 필요하다.

Method: Agentic UAVs 프레임워크는 인식, 추론, 행동, 통합, 학습의 5계층 구조로 LLM-driven 추론, 데이터베이스 쿼리, 제3자 시스템 상호작용을 통합한다.

Result: 모의 검색 및 구조 시나리오에서 에이전틱 UAV는 더 높은 탐지 신뢰도(0.79 대 0.72), 개선된 인물 탐지 비율(91% 대 75%), 눈에 띄게 증가한 행동 추천(92% 대 4.5%)을 달성했다.

Conclusion: 낮은 계산 오버헤드로 새로운 자율성과 생태계 통합 수준을 실현할 수 있음을 확인했다.

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


### [12] [$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation](https://arxiv.org/abs/2509.13368)
*Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li*

Main category: cs.AI

TL;DR: $Agent^2$는 LLM 기반의 지능형 생성 방식을 통해 완전 자동화된 RL 에이전트 설계를 달성하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 에이전트 개발은 전통적으로 고도의 전문성과 긴 반복 과정을 요구하며, 이로 인해 높은 실패율과 제한된 접근성이 발생한다.

Method: $Agent^2$는 자연어 작업 설명과 환경 코드를 포괄적이고 고성능의 강화 학습 솔루션으로 변환하는 전자동 시스템으로, 두 개의 에이전트(Generator Agent와 Target Agent)를 사용하는 혁신적인 구조를 갖는다.

Result: 다양한 벤치마크에서 수행된 광범위한 실험 결과, $Agent^2$는 수동으로 설계된 솔루션보다 모든 작업에서 일관되게 우수한 성능을 보였다.

Conclusion: 이 연구는 진정한 종단 간 폐쇄 루프 자동화를 가능하게 하여, 지능형 에이전트가 다른 에이전트를 설계하고 최적화하는 새로운 패러다임을 확립하고 있으며, 자동화된 AI 시스템의 근본적인 혁신을 나타낸다.

Abstract: Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.

</details>


### [13] [AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving](https://arxiv.org/abs/2509.13547)
*Harper Reed,Michael Sugimura,Angelo Zangari*

Main category: cs.AI

TL;DR: LLM 에이전트에 협력 도구와 자율성을 제공함으로써 문제 해결 성능이 향상되었음을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 문제 해결 성능을 개선하기 위해 인간이 사용하는 협력 도구와 자율성을 제공하는 것이 도움이 되는가를 조사합니다.

Method: Claude Code 에이전트에 MCP 기반의 소셜 미디어 및 저널링 도구를 장착하고, 이러한 도구를 자유롭게 활용할 수 있게 합니다.

Result: 34개의 Aider Polyglot Python 프로그래밍 도전 과제에서 협력 도구가 가장 어려운 문제에서 성능을 크게 개선하여 비용을 15-40% 낮추고, 턴 수를 12-27% 줄이며, 완료 시간을 12-38% 단축했습니다.

Conclusion: AI 에이전트는 인간의 협력 도구에서 체계적으로 이점을 얻을 수 있으며, 이는 추론 향상 도구로서 적응형 협력 인터페이스의 필요성을 시사합니다.

Abstract: We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.

</details>


### [14] [Programmable Cognitive Bias in Social Agents](https://arxiv.org/abs/2509.13588)
*Xuan Liu,Haoyang Shang,Haojian Jin*

Main category: cs.AI

TL;DR: 이 논문에서는 CoBRA라는 LLM 기반 사회 시뮬레이션에서 에이전트 행동을 체계적으로 지정하기 위한 새로운 툴킷을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 방법에서는 에이전트 행동을 묘사하는 암묵적인 자연어 설명을 통해 일관된 행동을 생성할 수 없었습니다.

Method: CoBRA는 에이전트의 인지 편향을 명시적으로 프로그래밍하는 새로운 접근 방식을 제시하며, 클래스 사회 과학 실험을 활용하여 에이전트의 기대 행동을 구체화합니다.

Result: CoBRA는 두 가지 구성 요소로 이루어져 있습니다: (1) 사회 에이전트의 인지 편향을 측정하는 인지 편향 지수, (2) 에이전트의 행동을 조정하여 통제된 인지 편향을 보여주는 행동 조정 엔진으로 구성됩니다.

Conclusion: CoBRA는 모델에 구애받지 않고 사회 에이전트에서 나타나는 인지 편향을 정확하게 프로그래밍할 수 있음을 보여주었습니다.

Abstract: This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.

</details>


### [15] [See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles](https://arxiv.org/abs/2509.13615)
*Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: 멀티모달 에이전트는 GUI 상호작용을 개선하지만, 토글 제어 명령 실행에서 신뢰성 부족이 문제다. 이를 해결하기 위해 State-aware Reasoning (StaR) 방법을 제안하며, 실험 결과 30% 이상 정확도 향상을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 에이전트의 토글 제어 명령 실행 신뢰성 부족 문제를 해결하고자 함.

Method: State-aware Reasoning (StaR) 훈련 방법을 제안하여 에이전트가 현재 토글 상태를 인식하고 명령에서 원하는 상태를 분석하며 그에 따라 행동하도록 학습시킴.

Result: 세 가지 멀티모달 에이전트를 대상으로 한 실험에서 StaR이 토글 명령 실행 정확도를 30% 이상 개선함을 입증함.

Conclusion: StaR은 일반적인 작업 성능도 개선하며, 동적 환경에서의 평가를 통해 실제 응용 가능성을 강조함.

Abstract: The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.

</details>


### [16] [InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management](https://arxiv.org/abs/2509.13704)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: InfraMind는 산업 관리 시스템을 위해 설계된 GUI 에이전트 프레임워크로, 복잡한 관리 소프트웨어의 자동화를 지원한다.


<details>
  <summary>Details</summary>
Motivation: 미션 크리티컬 산업 인프라, 특히 데이터 센터의 운영은 시스템 복잡성 증가, 다중 공급업체 통합, 전문가 운영자 부족 등의 문제에 직면하고 있다.

Method: InfraMind는 다섯 개의 혁신적인 모듈을 통합하여 산업 관리에서 직면한 다양한 도전 과제를 체계적으로 해결하도록 설계되었다.

Result: 광범위한 실험을 통해 본 접근법이 기존 프레임워크보다 일관되게 높은 작업 성공률과 운영 효율성을 제공하는 것이 입증되었다.

Conclusion: InfraMind는 산업 관리 자동화를 위한 엄격하고 확장 가능한 해결책을 제공한다.

Abstract: Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.

</details>


### [17] [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning](https://arxiv.org/abs/2509.13761)
*Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao*

Main category: cs.AI

TL;DR: 본 연구에서는 THOR를 통해 LLMs의 수치 계산 및 형식 기호 조작의 한계를 극복하고, 도구 통합 이유 데이터 구축, 미세 최적화 수행 및 추론 개선의 세 가지 주요 도전 과제를 해결하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLMs는 수학적 추론에서 놀라운 발전을 이루었지만, 고정밀 작업에는 여전히 어려움을 겪고 있다.

Method: THOR라는 RL 기반의 도구 통합 계층 최적화 방법을 제안하며, TIRGen을 사용하여 도구 통합 추론 경로의 고품질 데이터셋을 구축하고, RL 전략으로 미세 계층 최적화를 수행한다.

Result: 우리의 방법은 다양한 모델에서 강력한 일반화 능력을 보여주며, 수학적 기준에서 주목할 만한 성과를 달성한다.

Conclusion: THOR는 도구 피드백을 활용한 자기 수정 메커니즘을 통합하여 추론 과정에서 잘못된 경로를 동적으로 수정할 수 있다.

Abstract: Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

</details>


### [18] [MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](https://arxiv.org/abs/2509.13773)
*Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong*

Main category: cs.AI

TL;DR: MIRA는 스마트폰에서 직관적인 AI 작업 지시 추천을 제공하는 혁신적인 프레임워크로, 이미지나 텍스트 객체를 길게 눌러 관련된 지시를 받을 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 생성적 AI 기술의 발전은 스마트폰에 다양한 AI 기반 서비스를 통합하여 사용자와 기기의 상호작용 방식을 변화시키고 있다.

Method: MIRA는 멀티모달 대형 언어 모델을 기반으로 하는 추천 파이프라인, 템플릿 보강 추론 메커니즘, 그리고 접두사 트리를 기반으로 한 제약된 디코딩 전략을 포함한다.

Result: MIRA는 실제 주석 데이터셋과 사용자 연구를 통해 지시 추천의 정확성을 크게 향상시킴을 입증하였다.

Conclusion: MIRA는 사용자들이 스마트폰에서 AI 서비스와 상호작용하는 방식을 혁신할 잠재력을 가지고 있다.

Abstract: The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

</details>


### [19] [CrowdAgent: Multi-Agent Managed Multi-Source Annotation System](https://arxiv.org/abs/2509.14030)
*Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang*

Main category: cs.AI

TL;DR: CrowdAgent는 자연어 처리에서 데이터 주석 프로세스를 통합 관리하는 다중 에이전트 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 고품질 주석 데이터는 현대 자연어 처리를 위한 중요한 기반이며, 다양한 주석 출처를 활용하는 것이 필수적이다.

Method: CrowdAgent는 작업 할당, 데이터 주석, 품질/비용 관리를 통합하여 끝에서 끝까지 프로세스 관리를 제공하는 다중 에이전트 시스템이다.

Result: CrowdAgent의 효과를 6개의 다양한 다중 모달 분류 작업에 대한 실험을 통해 입증하였다.

Conclusion: CrowdAgent는 LLM, SLM 및 인간 전문가가 협력하여 주석 작업을 진행할 수 있도록 지원하며, 복잡한 스케줄링과 품질-비용 균형을 통합적으로 관리할 수 있다.

Abstract: High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [20] [All Models Are Wrong, But Can They Be Useful? Lessons from COVID-19 Agent-Based Models: A Systematic Review](https://arxiv.org/abs/2509.13346)
*Emma Von Hoene,Sara Von Hoene,Szandra Peter,Ethan Hopson,Emily Csizmadia,Faith Fenyk,Kai Barner,Timothy Leslie,Hamdi Kavak,Andreas Zufle,Amira Roess,Taylor Anderson*

Main category: cs.MA

TL;DR: COVID-19 팬데믹으로 인해 질병 동역학을 시뮬레이션하고 개입을 안내하기 위한 계산 모델이 급증했으며, 에이전트 기반 모델(ABM)은 인구 및 환경의 이질성을 캡처하는 데 적합하지만 보건 정책에 대한 유용성에 대한 의문이 제기되었다.


<details>
  <summary>Details</summary>
Motivation: COVID-19 팬데믹 동안 에이전트 기반 모델의 유용성을 평가하기 위해 시스템적으로 리뷰함으로써, 보건 정책에 대한 이들 모델의 기여를 이해하고자 함.

Method: 2020년 1월부터 2023년 12월까지 발표된 536개의 COVID-19 ABM 연구를 Web of Science, PubMed, Wiley에서 검색하여 체계적으로 검토.

Result: 대부분의 모델이 행동 또는 정책 개입을 탐구했으며, 모델 가정을 설명한 경우가 많았지만, 제한 사항을 공개한 경우는 적었고, 표준화된 보고 프로토콜과 이해관계자 참여는 드물었다.

Conclusion: ABM은 빠르게 발전했으나 투명성, 접근성 및 참여적 참여가 부족하였으며, 향후 공공 보건 위기에서 신뢰할 수 있는 의사 지원 도구로 기능하기 위해서는 더 강력한 기준이 필요하다.

Abstract: The COVID-19 pandemic prompted a surge in computational models to simulate
disease dynamics and guide interventions. Agent-based models (ABMs) are
well-suited to capture population and environmental heterogeneity, but their
rapid deployment raised questions about utility for health policy. We
systematically reviewed 536 COVID-19 ABM studies published from January 2020 to
December 2023, retrieved from Web of Science, PubMed, and Wiley on January 30,
2024. Studies were included if they used ABMs to simulate COVID-19
transmission, where reviews were excluded. Studies were assessed against nine
criteria of model usefulness, including transparency and re-use,
interdisciplinary collaboration and stakeholder engagement, and evaluation
practices. Publications peaked in late 2021 and were concentrated in a few
countries. Most models explored behavioral or policy interventions (n = 294,
54.85%) rather than real-time forecasting (n = 9, 1.68%). While most described
model assumptions (n = 491, 91.60%), fewer disclosed limitations (n = 349,
65.11%), shared code (n = 219, 40.86%), or built on existing models (n = 195,
36.38%). Standardized reporting protocols (n = 36, 6.72%) and stakeholder
engagement were rare (13.62%, n = 73). Only 2.24% (n = 12) described a
comprehensive validation framework, though uncertainty was often quantified (n
= 407, 75.93%). Limitations of this review include underrepresentation of
non-English studies, subjective data extraction, variability in study quality,
and limited generalizability. Overall, COVID-19 ABMs advanced quickly, but
lacked transparency, accessibility, and participatory engagement. Stronger
standards are needed for ABMs to serve as reliable decision-support tools in
future public health crises.

</details>


### [21] [Inject, Fork, Compare: Defining an Interaction Vocabulary for Multi-Agent Simulation Platforms](https://arxiv.org/abs/2509.13712)
*HwiJoon Lee,Martina Di Paola,Yoo Jin Hong,Quang-Huy Nguyen,Joseph Seering*

Main category: cs.MA

TL;DR: LLM 기반 다중 에이전트 시뮬레이션의 상호작용과 분석의 모드를 명확히 하여 "what if" 시나리오를 탐구할 수 있도록 하는 세 가지 기본 작업인 inject, fork, compare를 정의합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 다중 에이전트 시뮬레이션의 현재 한계를 극복하고 연구자들이 다양한 시나리오를 탐구할 수 있는 방법을 제공하기 위해.

Method: 세 가지 핵심 작업인 inject(외부 이벤트 삽입), fork(독립적인 시간 라인 생성), compare(여러 분기의 평행 관찰)를 정의합니다.

Result: 14개의 AI 에이전트로 구성된 상품 시장 시뮬레이션을 통해 각 작업으로 연구자들이 다양한 이벤트를 주입하고, 평행한 시간 라인에서 다양한 결과를 관찰할 수 있음을 보여줍니다.

Conclusion: 이러한 기본 작업을 통해 LLM 기반 에이전트 시뮬레이션에서 체계적인 인과 관계 조사의 출발점을 제공합니다.

Abstract: LLM-based multi-agent simulations are a rapidly growing field of research,
but current simulations often lack clear modes for interaction and analysis,
limiting the "what if" scenarios researchers are able to investigate. In this
demo, we define three core operations for interacting with multi-agent
simulations: inject, fork, and compare. Inject allows researchers to introduce
external events at any point during simulation execution. Fork creates
independent timeline branches from any timestamp, preserving complete state
while allowing divergent exploration. Compare facilitates parallel observation
of multiple branches, revealing how different interventions lead to distinct
emergent behaviors. Together, these operations establish a vocabulary that
transforms linear simulation workflows into interactive, explorable spaces. We
demonstrate this vocabulary through a commodity market simulation with fourteen
AI agents, where researchers can inject contrasting events and observe
divergent outcomes across parallel timelines. By defining these fundamental
operations, we provide a starting point for systematic causal investigation in
LLM-based agent simulations, moving beyond passive observation toward active
experimentation.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [22] [Practitioners' Perspectives on a Differential Privacy Deployment Registry](https://arxiv.org/abs/2509.13509)
*Priyanka Nanayakkara,Elena Ghazi,Salil Vadhan*

Main category: cs.CR

TL;DR: 본 논문은 차별적 프라이버시(DP) 배포를 위한 공개 리포지토리 구축에 관한 연구를 다룬다. 연구팀은 DP 배포에 대한 체계적이고 상호작용이 가능한 인터페이스를 개발하여 실제 사례를 바탕으로 사용자 연구를 수행하고, DP 커뮤니티에서의 활용 방안과 도전 과제를 검토하였다.


<details>
  <summary>Details</summary>
Motivation: 차별적 프라이버시의 구현을 촉진하고 관련된 정보를 공유하기 위해 Dwork, Kohli, Mulligan(2019)은 DP 배포에 대한 공개 저장소를 제안하였다.

Method: DP 배포를 설명하기 위한 포괄적이고 계층적인 스키마를 개발하고, 과거 DP 배포에 대한 정보를 제공하는 상호작용 인터페이스를 설계 및 구현하였다.

Result: 21개의 실제 DP 배포 사례로 인터페이스를 채우고, DP 전문가와의 사용자 연구를 통해 레지스트리 활용 방안과 직면할 도전 과제를 식별하였다.

Conclusion: 전문가들은 레지스트리를 과거 배포 평가 및 미래 배포 수단으로 유용하게 여겼고, DP 커뮤니티와의 더 넓은 소통을 지원할 수 있는 기회를 제시하였다. 그러나 구현 선택을 공개하는 것에 따른 노력과 위험, 항목 품질 모더레이션의 난제가 식별되었다.

Abstract: Differential privacy (DP) -- a principled approach to producing statistical
data products with strong, mathematically provable privacy guarantees for the
individuals in the underlying dataset -- has seen substantial adoption in
practice over the past decade. Applying DP requires making several
implementation decisions, each with significant impacts on data privacy and/or
utility. Hence, to promote shared learning and accountability around DP
deployments, Dwork, Kohli, and Mulligan (2019) proposed a public-facing
repository ("registry") of DP deployments. The DP community has recently
started to work toward realizing this vision. We contribute to this effort by
(1) developing a holistic, hierarchical schema to describe any given DP
deployment and (2) designing and implementing an interactive interface to act
as a registry where practitioners can access information about past DP
deployments. We (3) populate our interface with 21 real-world DP deployments
and (4) conduct an exploratory user study with DP practitioners ($n=16$) to
understand how they would use the registry, as well as what challenges and
opportunities they foresee around its adoption. We find that participants were
enthusiastic about the registry as a valuable resource for evaluating prior
deployments and making future deployments. They also identified several
opportunities for the registry, including that it can become a "hub" for the
community and support broader communication around DP (e.g., to legal teams).
At the same time, they identified challenges around the registry gaining
adoption, including the effort and risk involved with making implementation
choices public and moderating the quality of entries. Based on our findings, we
offer recommendations for encouraging adoption and increasing the registry's
value not only to DP practitioners, but also to policymakers, data users, and
data subjects.

</details>


### [23] [Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents](https://arxiv.org/abs/2509.13597)
*Abhishek Goswami*

Main category: cs.CR

TL;DR: 이 논문은 자율 LLM 에이전트가 보안 문제와 함께 API 호출을 수행할 때 사용자의 의도를 검증하고 확장 권한을 방지하기 위한 A-JWT라는 새로운 인증 메커니즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 LLM 에이전트가 수천 개의 API 호출을 인간의 감독 없이 수행할 수 있지만, 의도하지 않은 권한 확대가 발생할 수 있는 문제를 해결하고자 한다.

Method: A-JWT는 에이전트의 행동을 검증 가능한 사용자 의도에 연결하는 이중 측면의 의도 토큰으로, 에이전트의 아이덴티티를 해시로 나타내며 작업을 수행할 수 있는 하위 에이전트를 증명하는 위임 주장과 재생 및 프로세스 내부 사칭을 방지하기 위한 키를 포함한다.

Result: 기능적으로 범위 위반 요청, 재생, 사칭 및 프롬프트 주입 경로를 차단하는 것을 보여주며, 초 밀리초의 오버헤드로 일반적인 하드웨어에서 구현되었다.

Conclusion: 이 설계는 OAuth 에이전트 논의와 일치하며, 에이전트 애플리케이션에 대한 제로 트러스트 보장을 위한 빠른 경로를 제공한다.

Abstract: Autonomous LLM agents can issue thousands of API calls per hour without human
oversight. OAuth 2.0 assumes deterministic clients, but in agentic settings
stochastic reasoning, prompt injection, or multi-agent orchestration can
silently expand privileges.
  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each
agent's action to verifiable user intent and, optionally, to a specific
workflow step. A-JWT carries an agent's identity as a one-way checksum hash
derived from its prompt, tools and configuration, and a chained delegation
assertion to prove which downstream agent may execute a given task, and
per-agent proof-of-possession keys to prevent replay and in-process
impersonation. We define a new authorization mechanism and add a lightweight
client shim library that self-verifies code at run time, mints intent tokens,
tracks workflow steps and derives keys, thus enabling secure agent identity and
separation even within a single process.
  We illustrate a comprehensive threat model for agentic applications,
implement a Python proof-of-concept and show functional blocking of
scope-violating requests, replay, impersonation, and prompt-injection pathways
with sub-millisecond overhead on commodity hardware. The design aligns with
ongoing OAuth agent discussions and offers a drop-in path toward zero-trust
guarantees for agentic applications. A comprehensive performance and security
evaluation with experimental results will appear in our forthcoming journal
publication

</details>


### [24] [The Cybersecurity of a Humanoid Robot](https://arxiv.org/abs/2509.14096)
*Víctor Mayoral-Vilches*

Main category: cs.CR

TL;DR: 이 보고서는 인간형 로봇 플랫폼의 포괄적인 보안 평가를 제공하며, 추상적인 보안 모델과 운영상의 취약점 간의 간극을 해소합니다.


<details>
  <summary>Details</summary>
Motivation: 인간형 로봇의 빠른 발전은 기존 이론적 프레임워크가 충분히 다루지 못하는 전례 없는 사이버 보안 도전을 제시합니다.

Method: 체계적인 정적 분석, 런타임 관찰 및 암호 분석을 통해 보안 환경을 평가했습니다.

Result: 복잡한 보안 환경이 밝혀졌으며, 이중층의 독점 암호화 시스템이 존재하고, 정적 암호 키의 사용으로 인한 근본적인 구현 결함이 발견되었습니다.

Conclusion: 인간형 로봇의 보안을 확보하기 위해서는 물리-사이버 융합의 독특한 도전에 적응할 수 있는 사이버 보안 AI(CAI) 프레임워크로 패러다임 전환이 필요하다고 주장합니다.

Abstract: The rapid advancement of humanoid robotics presents unprecedented
cybersecurity challenges that existing theoretical frameworks fail to
adequately address. This report presents a comprehensive security assessment of
a production humanoid robot platform, bridging the gap between abstract
security models and operational vulnerabilities. Through systematic static
analysis, runtime observation, and cryptographic examination, we uncovered a
complex security landscape characterized by both sophisticated defensive
mechanisms and critical vulnerabilities. Our findings reveal a dual-layer
proprietary encryption system (designated FMX') that, while innovative in
design, suffers from fundamental implementation flaws including the use of
static cryptographic keys that enable offline configuration decryption. More
significantly, we documented persistent telemetry connections transmitting
detailed robot state information--including audio, visual, spatial, and
actuator data--to external servers without explicit user consent or
notification mechanisms. We operationalized a Cybersecurity AI agent on the
Unitree G1 to map and prepare exploitation of its manufacturer's cloud
infrastructure, illustrating how a compromised humanoid can escalate from
covert data collection to active counter-offensive operations. We argue that
securing humanoid robots requires a paradigm shift toward Cybersecurity AI
(CAI) frameworks that can adapt to the unique challenges of physical-cyber
convergence. This work contributes empirical evidence for developing robust
security standards as humanoid robots transition from research curiosities to
operational systems in critical domains.

</details>


### [25] [Cybersecurity AI: Humanoid Robots as Attack Vectors](https://arxiv.org/abs/2509.14139)
*Víctor Mayoral-Vilches*

Main category: cs.CR

TL;DR: Unitree G1 휴머노이드 로봇의 보안 평가 결과, 정보 유출 및 사이버 공격에 취약함이 드러났다.


<details>
  <summary>Details</summary>
Motivation: 휴머노이드 로봇의 보안 취약성을 평가하고, 이를 통해 향후 물리-사이버 융합 시스템에 대한 보안 기준을 형성하기 위해.

Method: Unitree G1의 FMX 암호화 부분 역공학과 두 가지 사례 연구를 통해 보안 구조를 분석하였다.

Result: 로봇이 300초마다 감지되지 않고 개인 정보를 유출하며, A.I. 사이버 보안 에이전트가 공격 준비로 전환할 수 있는 위험이 드러났다.

Conclusion: 휴머노이드 로봇이 중요한 인프라에 사용됨에 따라 적응형 CAI 기반의 방어가 필요함을 제안한다.

Abstract: We present a systematic security assessment of the Unitree G1 humanoid
showing it operates simultaneously as a covert surveillance node and can be
purposed as an active cyber operations platform. Partial reverse engineering of
Unitree's proprietary FMX encryption reveal a static Blowfish-ECB layer and a
predictable LCG mask-enabled inspection of the system's otherwise sophisticated
security architecture, the most mature we have observed in commercial robotics.
Two empirical case studies expose the critical risk of this humanoid robot: (a)
the robot functions as a trojan horse, continuously exfiltrating multi-modal
sensor and service-state telemetry to 43.175.228.18:17883 and
43.175.229.18:17883 every 300 seconds without operator notice, creating
violations of GDPR Articles 6 and 13; (b) a resident Cybersecurity AI (CAI)
agent can pivot from reconnaissance to offensive preparation against any
target, such as the manufacturer's cloud control plane, demonstrating
escalation from passive monitoring to active counter-operations. These findings
argue for adaptive CAI-powered defenses as humanoids move into critical
infrastructure, contributing the empirical evidence needed to shape future
security standards for physical-cyber convergence systems.

</details>
