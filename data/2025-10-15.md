<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 42]
- [cs.CR](#cs.CR) [Total: 20]
- [cs.MA](#cs.MA) [Total: 8]
- [cs.AI](#cs.AI) [Total: 26]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Coupled Data and Measurement Space Dynamics for Enhanced Diffusion Posterior Sampling](https://arxiv.org/abs/2510.09676)
*Shayan Mohajer Hamidi,En-Hui Yang,Ben Liang*

Main category: cs.LG

TL;DR: 본 연구는 C-DPS라는 새로운 프레임워크를 제안하여 역문제 해결 시 발생하는 제약 조정이나 우도 근사화의 필요성을 없앴습니다.


<details>
  <summary>Details</summary>
Motivation: 의료 이미징, 원거리 감지 및 계산 생물학 등에서 역문제를 해결하는 데 있어 기존의 방법들이 가지고 있는 한계를 극복하고자 함.

Method: C-DPS는 측정 공간에서의 전방 확률적 과정을 도입하여 데이터 공간에서의 확산과 병행하여 발전함으로써 정확한 후방분포 샘플링을 가능하게 합니다.

Result: C-DPS는 여러 역문제 벤치마크에서 기존의 방법들을 정량적 및 정성적으로 일관되게 초월하는 성과를 보였습니다.

Conclusion: C-DPS는 제약 조정이나 우도 근사화의 필요 없이 안정적이고 정확한 샘플링을 가능하게 합니다.

Abstract: Inverse problems, where the goal is to recover an unknown signal from noisy
or incomplete measurements, are central to applications in medical imaging,
remote sensing, and computational biology. Diffusion models have recently
emerged as powerful priors for solving such problems. However, existing methods
either rely on projection-based techniques that enforce measurement consistency
through heuristic updates, or they approximate the likelihood $p(\boldsymbol{y}
\mid \boldsymbol{x})$, often resulting in artifacts and instability under
complex or high-noise conditions. To address these limitations, we propose a
novel framework called \emph{coupled data and measurement space diffusion
posterior sampling} (C-DPS), which eliminates the need for constraint tuning or
likelihood approximation. C-DPS introduces a forward stochastic process in the
measurement space $\{\boldsymbol{y}_t\}$, evolving in parallel with the
data-space diffusion $\{\boldsymbol{x}_t\}$, which enables the derivation of a
closed-form posterior $p(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t,
\boldsymbol{y}_{t-1})$. This coupling allows for accurate and recursive
sampling based on a well-defined posterior distribution. Empirical results
demonstrate that C-DPS consistently outperforms existing baselines, both
qualitatively and quantitatively, across multiple inverse problem benchmarks.

</details>


### [2] [A Multi-Component Reward Function with Policy Gradient for Automated Feature Selection with Dynamic Regularization and Bias Mitigation](https://arxiv.org/abs/2510.09705)
*Sudip Khadka,L. S. Paudel*

Main category: cs.LG

TL;DR: 기존의 정적 특성 배제 전략이 숨겨진 의존성으로 인한 편향을 방지하는 데 실패할 수 있음을 보여줍니다. 이 논문은 강화 학습(RL) 프레임워크를 통해 편향 완화와 자동 특성 선택을 통합합니다.


<details>
  <summary>Details</summary>
Motivation: 숨겨진 의존성이 모델 예측에 영향을 미치는 경우, 기존의 정적 특성 배제 전략이 편향을 방지하는 데 한계를 보입니다.

Method: 강화 학습을 사용하여 편향 완화와 특성 선택을 하나의 학습 프로세스 내에서 통합합니다.

Result: 모델이 일반화, 정확성 및 공정성을 균형 있게 유지하도록 하는 동적 공식을 구현합니다.

Conclusion: 예측자가 상관관계에 있고 편견이 불가피하게 재발할 수 있는 환경에서 특성을 선택하는 유연하고 일반화 가능한 방법을 제공합니다.

Abstract: Static feature exclusion strategies often fail to prevent bias when hidden
dependencies influence the model predictions. To address this issue, we explore
a reinforcement learning (RL) framework that integrates bias mitigation and
automated feature selection within a single learning process. Unlike
traditional heuristic-driven filter or wrapper approaches, our RL agent
adaptively selects features using a reward signal that explicitly integrates
predictive performance with fairness considerations. This dynamic formulation
allows the model to balance generalization, accuracy, and equity throughout the
training process, rather than rely exclusively on pre-processing adjustments or
post hoc correction mechanisms. In this paper, we describe the construction of
a multi-component reward function, the specification of the agents action space
over feature subsets, and the integration of this system with ensemble
learning. We aim to provide a flexible and generalizable way to select features
in environments where predictors are correlated and biases can inadvertently
re-emerge.

</details>


### [3] [Leveraging Shared Prototypes for a Multimodal Pulse Motion Foundation Model](https://arxiv.org/abs/2510.09764)
*Wanting Mao,Maxwell A Xu,Harish Haresamudram,Mithun Saha,Santosh Kumar,James Matthew Rehg*

Main category: cs.LG

TL;DR: ProtoMM은 생리 신호의 상호 연결된 과정을 포착하기 위해 서로 다른 모달리티를 공유 프로토타입 사전을 사용하여 공통 임베딩 공간에 고정시킵니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 모달리티가 상호 연결된 생리학적 과정을 이해하는 데 필수적입니다.

Method: ProtoMM이라는 새로운 SSL 프레임워크를 제안하며, 이를 통해 서로 다른 모달리티를 공통 임베딩 공간에 고정합니다.

Result: 우리는 ProtoMM을 사용하여 Pulse Motion 기반 모델을 개발하였고, 기존 방식보다 우수한 성능을 입증하였습니다.

Conclusion: 이 방법은 학습된 기능의 해석 가능성을 향상시키면서 최첨단 성능을 달성하였습니다.

Abstract: Modeling multi-modal time-series data is critical for capturing system-level
dynamics, particularly in biosignals where modalities such as ECG, PPG, EDA,
and accelerometry provide complementary perspectives on interconnected
physiological processes. While recent self-supervised learning (SSL) advances
have improved unimodal representation learning, existing multi-modal approaches
often rely on CLIP-style contrastive objectives that overfit to easily aligned
features and misclassify valid cross-modal relationships as negatives,
resulting in fragmented and non-generalizable embeddings. To overcome these
limitations, we propose ProtoMM, a novel SSL framework that introduces a shared
prototype dictionary to anchor heterogeneous modalities in a common embedding
space. By clustering representations around shared prototypes rather than
explicit negative sampling, our method captures complementary information
across modalities and provides a coherent "common language" for physiological
signals. In this work, we focus on developing a Pulse Motion foundation model
with ProtoMM and demonstrate that our approach outperforms contrastive-only and
prior multimodal SSL methods, achieving state-of-the-art performance while
offering improved interpretability of learned features.

</details>


### [4] [Why Do Transformers Fail to Forecast Time Series In-Context?](https://arxiv.org/abs/2510.09776)
*Yufa Zhou,Yixiao Wang,Surbhi Goel,Anru R. Zhang*

Main category: cs.LG

TL;DR: 이 논문은 시계열 예측에서 트랜스포머의 한계를 이론적으로 분석하며, 인-컨텍스트 학습 이론을 통해 이러한 한계가 트랜스포머 모델에 어떻게 적용되는지를 설명합니다.


<details>
  <summary>Details</summary>
Motivation: 시계열 예측(TSF)은 머신러닝에서 여전히 해결되지 않은 문제로, 최근의 큰 언어 모델(LLM) 활용에도 불구하고 트랜스포머 기반 모델이 간단한 모델보다 성능이 떨어지는 경우가 많습니다.

Method: 본 논문은 AR($p$) 데이터 하에, 선형 자기 주목(LSA) 모델이 시계열 예측에서 고전적인 선형 모델보다 낮은 예상 MSE를 달성할 수 없음을 보여줍니다.

Result: 실험을 통해 LSA가 최적의 선형 예측기로 수렴하며, 사고의 연쇄(CoT) 스타일 추론 하에서 예측값이 지수적으로 평균으로 수렴하는 것을 입증합니다.

Conclusion: 이론적으로 이러한 발견은 예측 아키텍처 설계에 대한 실제적인 통찰을 제공하며, 연구 커뮤니티가 TSF의 기초적인 이론적 한계를 재평가하도록 독려합니다.

Abstract: Time series forecasting (TSF) remains a challenging and largely unsolved
problem in machine learning, despite significant recent efforts leveraging
Large Language Models (LLMs), which predominantly rely on Transformer
architectures. Empirical evidence consistently shows that even powerful
Transformers often fail to outperform much simpler models, e.g., linear models,
on TSF tasks; however, a rigorous theoretical understanding of this phenomenon
remains limited. In this paper, we provide a theoretical analysis of
Transformers' limitations for TSF through the lens of In-Context Learning (ICL)
theory. Specifically, under AR($p$) data, we establish that: (1) Linear
Self-Attention (LSA) models $\textit{cannot}$ achieve lower expected MSE than
classical linear models for in-context forecasting; (2) as the context length
approaches to infinity, LSA asymptotically recovers the optimal linear
predictor; and (3) under Chain-of-Thought (CoT) style inference, predictions
collapse to the mean exponentially. We empirically validate these findings
through carefully designed experiments. Our theory not only sheds light on
several previously underexplored phenomena but also offers practical insights
for designing more effective forecasting architectures. We hope our work
encourages the broader research community to revisit the fundamental
theoretical limitations of TSF and to critically evaluate the direct
application of increasingly sophisticated architectures without deeper
scrutiny.

</details>


### [5] [Building a Foundational Guardrail for General Agentic Systems via Synthetic Data](https://arxiv.org/abs/2510.09781)
*Yue Huang,Hang Hua,Yujun Zhou,Pengcheng Jing,Manish Nagireddy,Inkit Padhi,Greta Dolcetti,Zhangchen Xu,Subhajit Chaudhury,Ambrish Rawat,Liubov Nedoshivina,Pin-Yu Chen,Prasanna Sattigeri,Xiangliang Zhang*

Main category: cs.LG

TL;DR: LLM 에이전트의 안전성을 높이기 위해 사전 실행 단계에서 계획 수준의 개입을 통해 위험을 줄이는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 안전 장치들은 주로 실행 후에 작동하여 확장성이 어려우며, 계획 단계에서의 통제 가능한 감독의 여지를 거의 남기지 않는다.

Method: AuraGen이라는 제어 가능한 엔진을 도입하여 안전성을 확보하고, Safiron이라는 기초 보호 장치를 제안하여 다양한 입력 형식을 통합하고 위험한 경우를 표시한다.

Result: 제안된 보호 장치가 Pre-Exec Bench에서 강력한 기준선에 비해 일관된 성능 향상을 보였다.

Conclusion: 제안된 방법은 더 안전한 에이전트 시스템을 위한 실행 가능하고 실용적인 템플릿을 제공한다.

Abstract: While LLM agents can plan multi-step tasks, intervening at the planning
stage-before any action is executed-is often the safest way to prevent harm,
since certain risks can lead to severe consequences once carried out. However,
existing guardrails mostly operate post-execution, which is difficult to scale
and leaves little room for controllable supervision at the plan level. To
address this challenge, we highlight three critical gaps in current research:
data gap, model gap, and evaluation gap. To close the data gap, we introduce
AuraGen, a controllable engine that (i) synthesizes benign trajectories, (ii)
injects category-labeled risks with calibrated difficulty, and (iii) filters
outputs via an automated reward model, producing large and reliable corpora for
pre-execution safety. To close the guardian model gap, we propose a
foundational guardrail Safiron, combining a cross-planner adapter with a
compact guardian model. The adapter unifies different input formats, while
Safiron flags risky cases, assigns risk types, and generates rationales;
trained in two stages with a broadly explored data recipe, Safiron achieves
robust transfer across settings. To close the evaluation gap, we release
Pre-Exec Bench, a realistic benchmark covering diverse tools and branching
trajectories, which measures detection, fine-grained categorization,
explanation, and cross-planner generalization in human-verified scenarios.
Extensive experiments demonstrate consistent gains of the proposed guardrail
over strong baselines on Pre-Exec Bench, and ablations further distill
actionable practices, providing a practical template for safer agentic systems.

</details>


### [6] [A Unified Framework for Lifted Training and Inversion Approaches](https://arxiv.org/abs/2510.09796)
*Xiaoyu Wang,Alexandra Valavanis,Azhir Mahmood,Andreas Mang,Martin Benning,Audrey Repetti*

Main category: cs.LG

TL;DR: 딥 신경망 교육에서의 복잡한 문제를 해결하기 위해, 다양한 개념을 포함한 통합된 프레임워크가 제안된다.


<details>
  <summary>Details</summary>
Motivation: 딥 신경망 교육에서 기울기 기반 최적화와 역전파 방식이 자주 사용되지만, 기울기 소실 및 폭주, 비부드러운 활성화, 병렬화 제한 등의 문제가 존재한다.

Method: 이 논문은 보조 좌표 방법, 펜첼 리프트 네트워크, 리프트 브레그만 훈련 등 다양한 리프트 훈련 전략을 통합하는 프레임워크를 소개한다.

Result: 입증된 수치 결과는 리프트 브레그만 접근 방식이 기존 교육 방법보다 더 효과적이고 안정적임을 보여준다.

Conclusion: 이 프레임워크는 다양한 아키텍처에서의 리프트 훈련 방법의 적용 가능성을 확대하고, 반전 문제에 대한 새로운 방법론을 제시한다.

Abstract: The training of deep neural networks predominantly relies on a combination of
gradient-based optimisation and back-propagation for the computation of the
gradient. While incredibly successful, this approach faces challenges such as
vanishing or exploding gradients, difficulties with non-smooth activations, and
an inherently sequential structure that limits parallelisation. Lifted training
methods offer an alternative by reformulating the nested optimisation problem
into a higher-dimensional, constrained optimisation problem where the
constraints are no longer enforced directly but penalised with penalty terms.
This chapter introduces a unified framework that encapsulates various lifted
training strategies, including the Method of Auxiliary Coordinates, Fenchel
Lifted Networks, and Lifted Bregman Training, and demonstrates how diverse
architectures, such as Multi-Layer Perceptrons, Residual Neural Networks, and
Proximal Neural Networks fit within this structure. By leveraging tools from
convex optimisation, particularly Bregman distances, the framework facilitates
distributed optimisation, accommodates non-differentiable proximal activations,
and can improve the conditioning of the training landscape. We discuss the
implementation of these methods using block-coordinate descent strategies,
including deterministic implementations enhanced by accelerated and adaptive
optimisation techniques, as well as implicit stochastic gradient methods.
Furthermore, we explore the application of this framework to inverse problems,
detailing methodologies for both the training of specialised networks (e.g.,
unrolled architectures) and the stable inversion of pre-trained networks.
Numerical results on standard imaging tasks validate the effectiveness and
stability of the lifted Bregman approach compared to conventional training,
particularly for architectures employing proximal activations.

</details>


### [7] [Harnessing Self-Supervised Deep Learning and Geostationary Remote Sensing for Advancing Wildfire and Associated Air Quality Monitoring: Improved Smoke and Fire Front Masking using GOES and TEMPO Radiance Data](https://arxiv.org/abs/2510.09845)
*Nicholas LaHaye,Thilanka Munashinge,Hugo Lee,Xiaohua Pan,Gonzalo Gonzalez Abad,Hazem Mahmoud,Jennifer Wei*

Main category: cs.LG

TL;DR: NASA의 TEMPO 위성 임무 데이터와 자가 지도 학습 기술을 활용하여 미국 서부의 산불 및 공기 질 관리를 개선하는 가능성을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 미국 서부에서 산불과 공기 질 관리 개선의 필요성을 절감하여 연구를 수행하였습니다.

Method: 자가 지도 학습을 이용하여 산불 전선과 연기 기둥의 시간당 확산을 매핑하기 위한 딥 러닝 시스템을 개발하였습니다.

Result: GOES-18 및 TEMPO 데이터를 사용하여 연기 기둥과 구름을 성공적으로 구분하고, 다양한 센서 모달리티에서 생성된 연기 및 화재 마스크 간의 강한 일치를 보였습니다.

Conclusion: 기존 운영 제품에 비해 같은 사례에 대한 상당한 개선을 달성하였습니다.

Abstract: This work demonstrates the possibilities for improving wildfire and air
quality management in the western United States by leveraging the unprecedented
hourly data from NASA's TEMPO satellite mission and advances in self-supervised
deep learning. Here we demonstrate the efficacy of deep learning for mapping
the near real-time hourly spread of wildfire fronts and smoke plumes using an
innovative self-supervised deep learning-system: successfully distinguishing
smoke plumes from clouds using GOES-18 and TEMPO data, strong agreement across
the smoke and fire masks generated from different sensing modalities as well as
significant improvement over operational products for the same cases.

</details>


### [8] [WARC-Bench: Web Archive Based Benchmark for GUI Subtask Executions](https://arxiv.org/abs/2510.09872)
*Sanjari Srivastava,Gang Li,Cheng Chang,Rishu Garg,Manpreet Kaur,Charlene Y. Lee,Yuezhang Li,Yining Mao,Ignacio Cases,Yanan Xie,Peng Qi*

Main category: cs.LG

TL;DR: WARC-Bench는 438개의 웹 내비게이션 작업을 통해 멀티모달 AI 에이전트의 서브태스크 성능을 평가하는 새로운 벤치마크이다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 실세계 웹사이트를 탐색하기 위해서는 서브태스크를 마스터해야 한다.

Method: WARC-Bench를 통해 서브태스크에 대한 모델을 평가하고, 감독된 미세 조정(SFT)과 검증 가능한 보상을 사용하는 강화 학습(RLVR) 기법을 적용했다.

Result: SFT 모델은 48.8%의 성공률을 기록했으며, RLVR을 사용하여 성과를 52.8%로 향상시켰다.

Conclusion: 서브태스크를 마스터하는 것은 강력한 웹 계획 및 내비게이션에 필수적이며, 기존 벤치마크에서는 충분히 평가되지 않았다.

Abstract: Training web agents to navigate complex, real-world websites requires them to
master $\textit{subtasks}$ - short-horizon interactions on multiple UI
components (e.g., choosing the correct date in a date picker, or scrolling in a
container to extract information). We introduce WARC-Bench (Web Archive
Benchmark), a novel web navigation benchmark featuring 438 tasks designed to
evaluate multimodal AI agents on subtasks. WARC-Bench enables sandboxed
interactions with dynamic and realistic webpages using Web ARChive files. We
show that WARC-Bench is challenging for leading computer-use models, with the
highest observed success rate being 64.8%. To improve open source models on
subtask, we explore two common training techniques: supervised fine-tuning
(SFT) and reinforcement learning with verifiable rewards (RLVR). Experiments
show that SFT models obtain a 48.8% success rate on the benchmark. Training
with RLVR over SFT checkpoints, even in data-scarce settings, improves the
score to 52.8% on WARC-Bench, outperforming many frontier models. Our analysis
concludes that mastering these subtasks is essential for robust web planning
and navigation, and is a capability not extensively evaluated by existing
benchmarks.

</details>


### [9] [Myopic Bayesian Decision Theory for Batch Active Learning with Partial Batch Label Sampling](https://arxiv.org/abs/2510.09877)
*Kangping Hu,Stephen Mussmann*

Main category: cs.LG

TL;DR: 본 논문은 베이지안 의사 결정 이론을 기반으로 한 능동 학습 알고리즘을 제안하고, 특히 EPIG 알고리즘을 위해 부분 배치 레이블 샘플링 기법을 도출하였다.


<details>
  <summary>Details</summary>
Motivation: 능동 학습의 다양한 방법이 제안되었지만, 최적의 방법 선택이 불분명하다. 이 연구는 베이지안 의사 결정 이론을 통해 이 문제를 해결하고자 한다.

Method: 베이지안 능동 학습을 위한 의사 결정 이론(BDT)을 도출하고, 이를 바탕으로 EPIG 알고리즘을 위한 부분 배치 레이블 샘플링(ParBaLS)을 개발하였다.

Result: 여러 데이터셋에서 ParBaLS EPIG가 고정 예산 및 베이지안 로지스틱 회귀에 대해 우수한 성능을 보임을 실험적으로 입증하였다.

Conclusion: 제안한 방법이 능동 학습의 효과성을 높일 수 있음을 보여주었으며, 코드는 GitHub에서 제공된다.

Abstract: Over the past couple of decades, many active learning acquisition functions
have been proposed, leaving practitioners with an unclear choice of which to
use. Bayesian Decision Theory (BDT) offers a universal principle to guide
decision-making. In this work, we derive BDT for (Bayesian) active learning in
the myopic framework, where we imagine we only have one more point to label.
This derivation leads to effective algorithms such as Expected Error Reduction
(EER), Expected Predictive Information Gain (EPIG), and other algorithms that
appear in the literature. Furthermore, we show that BAIT (active learning based
on V-optimal experimental design) can be derived from BDT and asymptotic
approximations. A key challenge of such methods is the difficult scaling to
large batch sizes, leading to either computational challenges (BatchBALD) or
dramatic performance drops (top-$B$ selection). Here, using a particular
formulation of the decision process, we derive Partial Batch Label Sampling
(ParBaLS) for the EPIG algorithm. We show experimentally for several datasets
that ParBaLS EPIG gives superior performance for a fixed budget and Bayesian
Logistic Regression on Neural Embeddings. Our code is available at
https://github.com/ADDAPT-ML/ParBaLS.

</details>


### [10] [Multitask Learning with Learned Task Relationships](https://arxiv.org/abs/2510.10570)
*Zirui Wan,Stefan Vlaski*

Main category: cs.LG

TL;DR: 이 논문은 이질적인 로컬 데이터나 작업 분포의 존재하에 효율적인 연합 및 분산 학습을 위한 알고리즘적 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 합의 기반 전략은 이질적인 데이터로 인해 통계적으로 최적이 아니기 때문에, 개별 에이전트가 서로에게서 이익을 얻을 수 있는 다중 작업 또는 개인화 전략에 대한 관심이 증가하고 있다.

Method: 작업 관계를 알려지지 않는 정밀도 행성을 가진 가우시안 마르코프 랜덤 필드를 통해 모델링하고, 작업 관계와 로컬 모델을 동시에 학습하는 전략을 개발한다.

Result: 우리가 개발한 전략은 에이전트가 개별 데이터 분포에 일관된 방식으로 자아조직화할 수 있게 한다.

Conclusion: 이론적 분석은 학습된 관계의 품질을 정량화하고, 수치 실험은 그 실제적 효용성을 보여준다.

Abstract: Classical consensus-based strategies for federated and decentralized learning
are statistically suboptimal in the presence of heterogeneous local data or
task distributions. As a result, in recent years, there has been growing
interest in multitask or personalized strategies, which allow individual agents
to benefit from one another in pursuing locally optimal models without
enforcing consensus. Existing strategies require either precise prior knowledge
of the underlying task relationships or are fully non-parametric and instead
rely on meta-learning or proximal constructions. In this work, we introduce an
algorithmic framework that strikes a balance between these extremes. By
modeling task relationships through a Gaussian Markov Random Field with an
unknown precision matrix, we develop a strategy that jointly learns both the
task relationships and the local models, allowing agents to self-organize in a
way consistent with their individual data distributions. Our theoretical
analysis quantifies the quality of the learned relationship, and our numerical
experiments demonstrate its practical effectiveness.

</details>


### [11] [Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models](https://arxiv.org/abs/2510.09976)
*Mingyang Lyu,Yinqian Sun,Erliang Lin,Huangrui Li,Ruolin Chen,Feifei Zhao,Yi Zeng*

Main category: cs.LG

TL;DR: Flow Policy Optimization (FPO) 알고리즘을 통해 Vision-Language-Action (VLA) 모델의 강화 학습을 최적화하고, 높은 성능을 유지하며 스테이블한 학습을 달성하였다.


<details>
  <summary>Details</summary>
Motivation: VLA 모델의 성능은 지도 데이터의 질과 범위에 의존하며, 강화 학습은 온라인 상호작용을 통해 이 성능을 향상시키기 위한 유망한 경로를 제공한다.

Method: FPO는 조건부 흐름 일치 목표의 샘플별 변화를 활용하여 중요도 샘플링을 재구성하고, $	heta_0$ 모델의 온라인 강화 미세 조정을 안정적이고 확장 가능하게 수행한다.

Result: FPO는 LIBERO 벤치마크 및 ALOHA 시뮬레이션 작업에서 다양한 기준선과 비교하여 일관된 성능 향상을 보였다.

Conclusion: 제안한 계산 모듈의 효과성과 온라인 강화 학습 중 조건부 흐름 일치 목표의 안정적 수렴이 검증되었다.

Abstract: Vision-Language-Action (VLA) models such as OpenVLA, Octo, and $\pi_0$ have
shown strong generalization by leveraging large-scale demonstrations, yet their
performance is still fundamentally constrained by the quality and coverage of
supervised data. Reinforcement learning (RL) provides a promising path for
improving and fine-tuning VLAs through online interaction. However,
conventional policy gradient methods are computationally infeasible in the
context of flow-matching based models due to the intractability of the
importance sampling process, which requires explicit computation of policy
ratios. To overcome this limitation, we propose Flow Policy Optimization (FPO)
algorithm, which reformulates importance sampling by leveraging per-sample
changes in the conditional flow-matching objective. Furthermore, FPO achieves
stable and scalable online reinforcement fine-tuning of the $\pi_0$ model by
integrating structure-aware credit assignment to enhance gradient efficiency,
clipped surrogate objectives to stabilize optimization, multi-step latent
exploration to encourage diverse policy updates, and a Q-ensemble mechanism to
provide robust value estimation. We evaluate FPO on the LIBERO benchmark and
the ALOHA simulation task against supervised, preference-aligned,
diffusion-based, autoregressive online RL, and $\pi_0$-FAST baselines,
observing consistent improvements over the imitation prior and strong
alternatives with stable learning under sparse rewards. In addition, ablation
studies and analyses of the latent space dynamics further highlight the
contributions of individual components within FPO, validating the effectiveness
of the proposed computational modules and the stable convergence of the
conditional flow-matching objective during online RL.

</details>


### [12] [Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs](https://arxiv.org/abs/2510.11062)
*Yujie Zhao,Lanxiang Hu,Yang Wang,Minmin Hou,Hao Zhang,Ke Ding,Jishen Zhao*

Main category: cs.LG

TL;DR: AT-GRPO는 다중 에이전트 시스템(MAS)과 강화 학습(RL)을 활용하여 대형 언어 모델의 기능을 향상시키는 새로운 알고리즘이다.


<details>
  <summary>Details</summary>
Motivation: MAS와 RL을 통합하여 에이전트의 성능을 극대화하고자 한다.

Method: MAS에 맞추어 에이전트 및 턴별로 그룹화된 RL 알고리즘과 단일 및 다중 정책을 지원하는 훈련 시스템을 포함하는 AT-GRPO를 제안한다.

Result: AT-GRPO는 게임, 계획, 코딩, 수학 작업에서 실질적인 성과를 보였고, 특히 장기 계획에서 14.0%의 단일 에이전트 RL 기준을 96.0%로 증가시켰다.

Conclusion: AT-GRPO는 다중 에이전트 환경에서 성능을 크게 향상시키며, 코드와 환경이 GitHub에 공개되어 있다.

Abstract: Multi-agent systems (MAS) and reinforcement learning (RL) are widely used to
enhance the agentic capabilities of large language models (LLMs). MAS improves
task performance through role-based orchestration, while RL uses environmental
rewards to learn stronger policies, such as GRPO-style optimization. However,
applying on-policy RL to MAS remains underexplored and presents unique
challenges. Algorithmically, standard GRPO grouping assumptions break down
because prompts vary by role and by turn. System-wise, the training stack must
support MAS-workflow rollouts and on-policy updates for both single-policy and
multi-policy models.
  We propose AT-GRPO, which includes (i) an agent- and turn-wise grouped RL
algorithm tailored to MAS and (ii) a training system that supports both single-
and multi-policy regimes. Across game, planning, coding, and math tasks,
AT-GRPO delivers substantial gains. On long-horizon planning, it increases
accuracy from a 14.0 to 47.0 percent single-agent RL baseline to 96.0 to 99.5
percent. It also improves reasoning performance, with average gains of 3.87 to
7.62 percent on coding tasks and 9.0 to 17.93 percent on math. Code and
environments are available at: https://github.com/pettingllms-ai/PettingLLMs.

</details>


### [13] [Tight Robustness Certificates and Wasserstein Distributional Attacks for Deep Neural Networks](https://arxiv.org/abs/2510.10000)
*Bach C. Le,Tung V. Dao,Binh T. Nguyen,Hong T. M. Chu*

Main category: cs.LG

TL;DR: 이 논문은 Wasserstein 분포적 강인 최적화(WDRO)의 상한을 개선하는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 WDRO 기반 방법들이 느슨한 상한을 제공하거나 계산적으로 부담이 크다는 한계를 해결하고자 한다.

Method: 프라이멀 접근 방식과 정확한 Lipschitz 증명을 도입하여 WDRO의 상한을 개선하고, 새로운 Wasserstein 분포적 공격(WDA)을 제안하여 최악의 분포 후보를 직접 구성한다.

Result: 제안된 WDA는 공격 지점의 수와 위치에서 더 큰 유연성을 제공하며, ReLU 네트워크의 piecewise-affine 구조를 활용하여 WDRO 문제의 정확한 특성을 나타낸다.

Conclusion: 제안된 방법은 최신 기준에 비해 경쟁력 있는 강인 정확도를 달성하고 기존 방법보다 더 긴밀한 증명을 제공한다.

Abstract: Wasserstein distributionally robust optimization (WDRO) provides a framework
for adversarial robustness, yet existing methods based on global Lipschitz
continuity or strong duality often yield loose upper bounds or require
prohibitive computation. In this work, we address these limitations by
introducing a primal approach and adopting a notion of exact Lipschitz
certificate to tighten this upper bound of WDRO. In addition, we propose a
novel Wasserstein distributional attack (WDA) that directly constructs a
candidate for the worst-case distribution. Compared to existing point-wise
attack and its variants, our WDA offers greater flexibility in the number and
location of attack points. In particular, by leveraging the piecewise-affine
structure of ReLU networks on their activation cells, our approach results in
an exact tractable characterization of the corresponding WDRO problem.
Extensive evaluations demonstrate that our method achieves competitive robust
accuracy against state-of-the-art baselines while offering tighter certificates
than existing methods. Our code is available at
https://github.com/OLab-Repo/WDA

</details>


### [14] [Experience-Efficient Model-Free Deep Reinforcement Learning Using Pre-Training](https://arxiv.org/abs/2510.10029)
*Ruoxing Yang*

Main category: cs.LG

TL;DR: PPOPT는 사전 훈련을 활용한 새로운 모델-프리 심층 강화 학습 알고리즘으로, 물리 기반 환경에서 적은 샘플로 높은 훈련 효율성과 안정성을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 물리 기반 환경에서의 강화 학습 에이전트는 정책 학습을 위해 대량의 환경 상호작용 샘플에 의존하지만, 이는 복잡한 환경일수록 높은 계산 비용이 든다.

Method: PPOPT는 두 개의 완전 연결 네트워크 사이에 사전 훈련된 신경망 중간 부분을 포함하는 새로운 정책 신경망 아키텍처를 사용한다.

Result: PPOPT는 적은 훈련 샘플에서 보상과 일반 훈련 안정성 측면에서 기본 클래식 PPO를 능가한다.

Conclusion: PPOPT는 모델 기반 방법에 비해 성능이 떨어지지만, 모델 프리 특성 덕분에 모델 기반 방법보다 훨씬 적은 시간으로 훈련할 수 있다.

Abstract: We introduce PPOPT - Proximal Policy Optimization using Pretraining, a novel,
model-free deep-reinforcement-learning algorithm that leverages pretraining to
achieve high training efficiency and stability on very small training samples
in physics-based environments. Reinforcement learning agents typically rely on
large samples of environment interactions to learn a policy. However, frequent
interactions with a (computer-simulated) environment may incur high
computational costs, especially when the environment is complex. Our main
innovation is a new policy neural network architecture that consists of a
pretrained neural network middle section sandwiched between two fully-connected
networks. Pretraining part of the network on a different environment with
similar physics will help the agent learn the target environment with high
efficiency because it will leverage a general understanding of the
transferrable physics characteristics from the pretraining environment. We
demonstrate that PPOPT outperforms baseline classic PPO on small training
samples both in terms of rewards gained and general training stability. While
PPOPT underperforms against classic model-based methods such as DYNA DDPG, the
model-free nature of PPOPT allows it to train in significantly less time than
its model-based counterparts. Finally, we present our implementation of PPOPT
as open-source software, available at github.com/Davidrxyang/PPOPT.

</details>


### [15] [FOSSIL: Regret-Minimizing Curriculum Learning for Metadata-Free and Low-Data Mpox Diagnosis](https://arxiv.org/abs/2510.10041)
*Sahng-Min Han,Minjae Kim,Jinho Cha,Se-woon Choe,Eunchan Daniel Cha,Jungwon Choi,Kyudong Jung*

Main category: cs.LG

TL;DR: FOSSIL을 활용한 생의학 데이터셋에서의 딥러닝 성능 향상


<details>
  <summary>Details</summary>
Motivation: 소규모 및 불균형 생의학 데이터셋에서 최적화 불안정성과 일반화 부족 문제 해결.

Method: 샘플 난이도에 따라 학습 강조를 조정하는 FOSSIL 알고리즘을 사용하여 4단계 커리큘럼을 구성하고 ConvNet 및 Transformer 구조에 통합함.

Result: FOSSIL은 AUC 0.9573, ECE 0.053의 성능으로 기존 방법론에 비해 판별력, 보정 및 강인성을 크게 향상시킴.

Conclusion: FOSSIL은 데이터 부족 상황에서 의료 이미징에 적용 가능한 일반화 가능하고 해석 가능한 학습 프레임워크로 자리 잡음.

Abstract: Deep learning in small and imbalanced biomedical datasets remains
fundamentally constrained by unstable optimization and poor generalization. We
present the first biomedical implementation of FOSSIL (Flexible Optimization
via Sample-Sensitive Importance Learning), a regret-minimizing weighting
framework that adaptively balances training emphasis according to sample
difficulty. Using softmax-based uncertainty as a continuous measure of
difficulty, we construct a four-stage curriculum (Easy-Very Hard) and integrate
FOSSIL into both convolutional and transformer-based architectures for Mpox
skin lesion diagnosis. Across all settings, FOSSIL substantially improves
discrimination (AUC = 0.9573), calibration (ECE = 0.053), and robustness under
real-world perturbations, outperforming conventional baselines without
metadata, manual curation, or synthetic augmentation. The results position
FOSSIL as a generalizable, data-efficient, and interpretable framework for
difficulty-aware learning in medical imaging under data scarcity.

</details>


### [16] [One4Many-StablePacker: An Efficient Deep Reinforcement Learning Framework for the 3D Bin Packing Problem](https://arxiv.org/abs/2510.10057)
*Lei Gao,Shihong Huang,Shengjie Wang,Hong Ma,Feng Zhang,Hengda Bao,Qichang Chen,Weihua Zhou*

Main category: cs.LG

TL;DR: O4M-SP는 다양한 박스 차원에서 안정성 제약을 고려한 새로운 심층 강화 학습 프레임워크로, 기존 방법보다 뛰어난 성능을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 3D-BPP의 기존 학습 기반 접근 방식은 실용적인 안정성 관련 제약을 무시하고, 다양한 박스 차원에 대한 일반화에 한계를 보입니다.

Method: O4M-SP는 단일 훈련 과정에서 다양한 박스 차원을 처리하면서 로딩 비율과 새로운 높이 차이 메트릭을 통합한 가중 보상 함수를 사용하고, 정책 엔트로피 붕괴를 완화하기 위해 맞춤형 정책 드리프트 방법과 클리핑된 정책 경량 최적화를 결합합니다.

Result: O4M-SP는 다양한 박스 차원에서 성공적으로 일반화하며 기준 방법에 비해 상당한 성능 향상을 보여줍니다.

Conclusion: O4M-SP는 안정성 제약을 가진 포장 시나리오를 효과적으로 해결하여 강력한 실용 가능성을 나타냅니다.

Abstract: The three-dimensional bin packing problem (3D-BPP) is widely applied in
logistics and warehousing. Existing learning-based approaches often neglect
practical stability-related constraints and exhibit limitations in generalizing
across diverse bin dimensions. To address these limitations, we propose a novel
deep reinforcement learning framework, One4Many-StablePacker (O4M-SP). The
primary advantage of O4M-SP is its ability to handle various bin dimensions in
a single training process while incorporating support and weight constraints
common in practice. Our training method introduces two innovative mechanisms.
First, it employs a weighted reward function that integrates loading rate and a
new height difference metric for packing layouts, promoting improved bin
utilization through flatter packing configurations. Second, it combines clipped
policy gradient optimization with a tailored policy drifting method to mitigate
policy entropy collapse, encouraging exploration at critical decision nodes
during packing to avoid suboptimal solutions. Extensive experiments demonstrate
that O4M-SP generalizes successfully across diverse bin dimensions and
significantly outperforms baseline methods. Furthermore, O4M-SP exhibits strong
practical applicability by effectively addressing packing scenarios with
stability constraints.

</details>


### [17] [Simulating Viva Voce Examinations to Evaluate Clinical Reasoning in Large Language Models](https://arxiv.org/abs/2510.10278)
*Christopher Chiu,Silviu Pitis,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: VivaBench는 대형 언어 모델(LLM)의 임상 추론 능력을 평가하는 다중 턴 벤치마크로, 1762개의 의사 선정 임상 시나리오를 포함하고 있으며, LLM의 진단 성능은 불확실한 상황에서 저하됨을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 현재의 의학 기준은 LLM의 지식 기억만을 평가하지만, 의사의 임상 추론 과정은 반복적이고 불완전한 정보로 진단을 정제하는 것이다.

Method: VivaBench는 상호 작용 시나리오로 구성된 데이터셋으로, 의사가 관련 정보를 탐색하고, 적절한 조사 방법을 선택하며, 여러 단계를 통해 정보를 종합하여 진단에 도달하도록 요구한다.

Result: 현재 LLM은 잘 정의된 임상 사례의 진단에서는 능력을 보이나, 불확실한 상황에서의 반복적인 진단 추론을 수행할 때 성능이 크게 저하된다.

Conclusion: VivaBench를 통해 실제 임상 의사결정 지원을 위한 대화형 의료 AI 시스템을 평가하는 표준화된 벤치마크를 제공하며, 복잡한 의사결정 환경에서의 추론 경로가 어떻게 분기될 수 있는지를 보여준다.

Abstract: Clinical reasoning in medicine is a hypothesis-driven process where
physicians refine diagnoses from limited information through targeted history,
physical examination, and diagnostic investigations. In contrast, current
medical benchmarks for large language models (LLMs) primarily assess knowledge
recall through single-turn questions, where complete clinical information is
provided upfront. To address this gap, we introduce VivaBench, a multi-turn
benchmark that evaluates sequential clinical reasoning in LLM agents. Our
dataset consists of 1762 physician-curated clinical vignettes structured as
interactive scenarios that simulate a (oral) examination in medical training,
requiring agents to actively probe for relevant findings, select appropriate
investigations, and synthesize information across multiple steps to reach a
diagnosis. While current LLMs demonstrate competence in diagnosing conditions
from well-described clinical presentations, their performance degrades
significantly when required to navigate iterative diagnostic reasoning under
uncertainty in our evaluation. Our analysis identified several failure modes
that mirror common cognitive errors in clinical practice, including: (1)
fixation on initial hypotheses, (2) inappropriate investigation ordering, (3)
premature diagnostic closure, and (4) failing to screen for critical
conditions. These patterns reveal fundamental limitations in how current LLMs
reason and make decisions under uncertainty. Through VivaBench, we provide a
standardized benchmark for evaluating conversational medical AI systems for
real-world clinical decision support. Beyond medical applications, we
contribute to the larger corpus of research on agentic AI by demonstrating how
sequential reasoning trajectories can diverge in complex decision-making
environments.

</details>


### [18] [Sample-Efficient Online Learning in LM Agents via Hindsight Trajectory Rewriting](https://arxiv.org/abs/2510.10304)
*Michael Y. Hu,Benjamin Van Durme,Jacob Andreas,Harsh Jhamtani*

Main category: cs.LG

TL;DR: ECHO라는 프레임워크는 언어 모델 에이전트의 경험 후 최적화를 통해 실패한 시도의 대안 목표에 대한 최적화된 경로를 생성하여 더 나은 샘플 효율성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델 에이전트가 상호작용 비용이 높은 새로운 환경에서 효과적으로 학습할 수 있도록 하기 위해서는 샘플 효율성이 중요하다.

Method: ECHO는 후행 경험 재생을 언어 모델 에이전트에 적응시키는 프레임워크로, 언어 모델을 사용하여 관련 서브 목표를 식별하고 최적화된 경로를 생성한다.

Result: ECHO는 XMiniGrid와 PeopleJoinQA에서 베이스라인을 최대 80% 초과 달성하였고, XMiniGrid에서는 Reflexion 및 AWM과 같은 고급 에이전트 아키텍처보다 더 빠른 적응을 보였다.

Conclusion: ECHO는 실패한 상호작용으로부터 합성 긍정 예제를 생성하여 언어 모델 에이전트의 과거 경험을 효과적으로 활용할 수 있게 만든다.

Abstract: Language model (LM) agents deployed in novel environments often exhibit poor
sample efficiency when learning from sequential interactions. This
significantly hinders the usefulness of such agents in environments where
interaction is costly (for example, when they interact with humans or reset
physical systems). While a number of existing LM agent architectures
incorporate various mechanisms for experience storage and reflection, they make
limited use of LMs' abilities to directly generate or reason about full
counterfactual trajectories. We introduce ECHO (Experience Consolidation via
Hindsight Optimization), a prompting framework that adapts hindsight experience
replay from reinforcement learning for language model agents. ECHO generates
optimized trajectories for alternative goals that could have been achieved
during failed attempts, effectively creating synthetic positive examples from
unsuccessful interactions. Our approach consists of two components: a hindsight
rule that uses the language model itself to identify relevant subgoals and
generate optimized trajectories, and an update rule that maintains compressed
trajectory representations in memory. We evaluate ECHO on stateful versions of
XMiniGrid, a text-based navigation and planning benchmark, and PeopleJoinQA, a
collaborative information-gathering enterprise simulation. Across both domains,
ECHO outperforms vanilla language agent baselines by up to 80%; in XMiniGrid,
it also outperforms a number of sophisticated agent architectures including
Reflexion and AWM, demonstrating faster adaptation to novel environments
through more effective utilization of past experiences.

</details>


### [19] [Transformer Model Detects Antidepressant Use From a Single Night of Sleep, Unlocking an Adherence Biomarker](https://arxiv.org/abs/2510.10364)
*Ali Mirzazadeh,Simon Cadavid,Kaiwen Zha,Chao Li,Sultan Alzahrani,Manar Alawajy,Joshua Korzenik,Kreshnik Hoti,Charles Reynolds,David Mischoulon,John Winkelman,Maurizio Fava,Dina Katabi*

Main category: cs.LG

TL;DR: 비침습적 바이오마커를 통해 항우울제 복용 여부를 수면 데이터로 감지하는 새로운 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 항우울제 비순응은 재발, 입원, 자살 위험 및 막대한 비용을 초래한다. 의료진은 비순응을 신속하게 감지할 수 있는 도구가 필요하다.

Method: 소비자용 웨어러블 기기나 비접촉식 무선 센서로 수면 데이터를 분석하는 변환기 기반 모델을 사용하여 항우울제 복용을 추론한다.

Result: 62,000개의 수면 데이터를 포함하는 6개 데이터 세트에서 AUROC = 0.84를 달성하며, 약물 클래스 전반에 일반화되고 용량에 비례하여 확장되었다.

Conclusion: 이 접근 방식은 우울증 치료 및 결과를 개선할 수 있는 객관적이고 확장 가능한 비순응 감시를 제공한다.

Abstract: Antidepressant nonadherence is pervasive, driving relapse, hospitalization,
suicide risk, and billions in avoidable costs. Clinicians need tools that
detect adherence lapses promptly, yet current methods are either invasive
(serum assays, neuroimaging) or proxy-based and inaccurate (pill counts,
pharmacy refills). We present the first noninvasive biomarker that detects
antidepressant intake from a single night of sleep. A transformer-based model
analyzes sleep data from a consumer wearable or contactless wireless sensor to
infer antidepressant intake, enabling remote, effortless, daily adherence
assessment at home. Across six datasets comprising 62,000 nights from >20,000
participants (1,800 antidepressant users), the biomarker achieved AUROC = 0.84,
generalized across drug classes, scaled with dose, and remained robust to
concomitant psychotropics. Longitudinal monitoring captured real-world
initiation, tapering, and lapses. This approach offers objective, scalable
adherence surveillance with potential to improve depression care and outcomes.

</details>


### [20] [ImpMIA: Leveraging Implicit Bias for Membership Inference Attack under Realistic Scenarios](https://arxiv.org/abs/2510.10625)
*Yuval Golbari,Navve Wasserman,Gal Vardi,Michal Irani*

Main category: cs.LG

TL;DR: 모델 훈련에 사용된 데이터 샘플을 결정하는 멤버십 추론 공격(MIA)은 데이터 프라이버시에 중요한 문제이다. 본 논문에서는 기존의 블랙 박스 공격 방법이 현실 세계에서 자주 유지되지 않는 가정에 의존한다는 점을 보였다. 우리는 ImpMIA라는 새로운 화이트 박스 공격을 제안하며, 이는 신경망의 암묵적 편향을 이용하여 레퍼런스 모델에 대한 의존성을 제거한다. 결과적으로 ImpMIA는 현실적인 환경에서 블랙박스와 화이트박스 공격에 비해 최첨단 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 모델 훈련에 사용된 데이터 샘플을 식별하는 문제는 데이터 프라이버시 측면에서 중요한 문제이다.

Method: 신경망의 암묵적 편향을 활용하여 레퍼런스 모델의 필요성을 제거한 화이트 박스 공격인 ImpMIA를 도입했다. ImpMIA는 KKT 최적성 조건을 사용하여 훈련 샘플을 식별한다.

Result: ImpMIA는 블랙박스 및 화이트박스 공격에 비해 현실적인 환경에서 최첨단 성능을 달성하였다.

Conclusion: ImpMIA는 모델 가중치와 훈련 데이터의 상위 집합만으로도 뛰어난 성능을 발휘하며, 기존 블랙박스 방법의 한계를 극복한다.

Abstract: Determining which data samples were used to train a model-known as Membership
Inference Attack (MIA)-is a well-studied and important problem with
implications for data privacy. Black-box methods presume access only to the
model's outputs and often rely on training auxiliary reference models. While
they have shown strong empirical performance, they rely on assumptions that
rarely hold in real-world settings: (i) the attacker knows the training
hyperparameters; (ii) all available non-training samples come from the same
distribution as the training data; and (iii) the fraction of training data in
the evaluation set is known. In this paper, we demonstrate that removing these
assumptions leads to a significant drop in the performance of black-box
attacks. We introduce ImpMIA, a Membership Inference Attack that exploits the
Implicit Bias of neural networks, hence removes the need to rely on any
reference models and their assumptions. ImpMIA is a white-box attack -- a
setting which assumes access to model weights and is becoming increasingly
realistic given that many models are publicly available (e.g., via Hugging
Face). Building on maximum-margin implicit bias theory, ImpMIA uses the
Karush-Kuhn-Tucker (KKT) optimality conditions to identify training samples.
This is done by finding the samples whose gradients most strongly reconstruct
the trained model's parameters. As a result, ImpMIA achieves state-of-the-art
performance compared to both black and white box attacks in realistic settings
where only the model weights and a superset of the training data are available.

</details>


### [21] [Multi-Task Learning with Feature-Similarity Laplacian Graphs for Predicting Alzheimer's Disease Progression](https://arxiv.org/abs/2510.10433)
*Zixiang Xu,Menghui Zhou,Jun Qi,Xuanhan Fan,Yun Yang,Po Yang*

Main category: cs.LG

TL;DR: 본 논문에서는 알츠하이머병 데이터의 시간적 변화 특징을 반영하는 새로운 다중 과제 학습(MTL) 프레임워크인 Feature Similarity Laplacian graph Multi-Task Learning(MTL-FSL)을 제안합니다. 이 모델은 예측 정확도와 생물학적 해석 가능성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병은 고령 인구에서 가장 흔한 신경퇴행성 질환으로, 글로벌 의료 시스템에 상당한 부담을 초래하고 있습니다. 기존의 다중 과제 학습 프레임워크는 특징 간의 시간 가변적 상관관계를 반영하지 않습니다.

Method: 우리는 시간에 따라 변화하는 특징 간의 관계를 모델링하는 새로운 Feature Similarity Laplacian(FSL) 패널티를 도입합니다. 이를 통해 모델은 작업 간의 시간적 부드러움과 특징 간의 동적 상관관계를 동시에 고려합니다.

Result: 알츠하이머병 신경영상 연구 이니셔티브(ADNI) 데이터셋에서 실험한 결과, 제안된 MTL-FSL 프레임워크는 다양한 기준 방법을 초월하는 최첨단 성능을 달성했습니다.

Conclusion: 우리는 ADMM(Alternating Direction Method of Multipliers) 알고리즘을 채택하여 제안한 패널티 항으로 인한 비부드러운 최적화 문제를 해결합니다.

Abstract: Alzheimer's Disease (AD) is the most prevalent neurodegenerative disorder in
aging populations, posing a significant and escalating burden on global
healthcare systems. While Multi-Tusk Learning (MTL) has emerged as a powerful
computational paradigm for modeling longitudinal AD data, existing frameworks
do not account for the time-varying nature of feature correlations. To address
this limitation, we propose a novel MTL framework, named Feature Similarity
Laplacian graph Multi-Task Learning (MTL-FSL). Our framework introduces a novel
Feature Similarity Laplacian (FSL) penalty that explicitly models the
time-varying relationships between features. By simultaneously considering
temporal smoothness among tasks and the dynamic correlations among features,
our model enhances both predictive accuracy and biological interpretability. To
solve the non-smooth optimization problem arising from our proposed penalty
terms, we adopt the Alternating Direction Method of Multipliers (ADMM)
algorithm. Experiments conducted on the Alzheimer's Disease Neuroimaging
Initiative (ADNI) dataset demonstrate that our proposed MTL-FSL framework
achieves state-of-the-art performance, outperforming various baseline methods.
The implementation source can be found at https://github.com/huatxxx/MTL-FSL.

</details>


### [22] [Neutral Agent-based Adversarial Policy Learning against Deep Reinforcement Learning in Multi-party Open Systems](https://arxiv.org/abs/2510.10937)
*Qizhou Peng,Yang Zheng,Yu Wen,Yanna Wu,Yingying Du*

Main category: cs.LG

TL;DR: 이 논문에서는 다자간 개방 시스템에서 잘 훈련된 피해 에이전트를 잘못 인도할 수 있는 적대적 정책 학습 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 적대적 공격 기술은 피해 에이전트와의 직접적인 상호작용이나 환경에 대한 완전한 통제에 의존하고 있어 다자간 개방 시스템에서는 제한적으로 사용됩니다.

Method: 중립 에이전트를 기반으로 한 접근 방식을 제안하여 다양한 작업 시나리오에서 피해 에이전트에 간접적으로 영향을 미치는 방법을 제시합니다.

Result: SMAC 플랫폼 및 자율 주행 시뮬레이션 플랫폼인 Highway-env에서 실험을 통해 제안된 방법이 효과적인 공격을 수행할 수 있음을 입증합니다.

Conclusion: 제안된 방법은 다자간 개방 시스템에서 일반적이고 효과적인 적대적 공격을 성공적으로 수행할 수 있습니다.

Abstract: Reinforcement learning (RL) has been an important machine learning paradigm
for solving long-horizon sequential decision-making problems under uncertainty.
By integrating deep neural networks (DNNs) into the RL framework, deep
reinforcement learning (DRL) has emerged, which achieved significant success in
various domains. However, the integration of DNNs also makes it vulnerable to
adversarial attacks. Existing adversarial attack techniques mainly focus on
either directly manipulating the environment with which a victim agent
interacts or deploying an adversarial agent that interacts with the victim
agent to induce abnormal behaviors. While these techniques achieve promising
results, their adoption in multi-party open systems remains limited due to two
major reasons: impractical assumption of full control over the environment and
dependent on interactions with victim agents.
  To enable adversarial attacks in multi-party open systems, in this paper, we
redesigned an adversarial policy learning approach that can mislead
well-trained victim agents without requiring direct interactions with these
agents or full control over their environments. Particularly, we propose a
neutral agent-based approach across various task scenarios in multi-party open
systems. While the neutral agents seemingly are detached from the victim
agents, indirectly influence them through the shared environment. We evaluate
our proposed method on the SMAC platform based on Starcraft II and the
autonomous driving simulation platform Highway-env. The experimental results
demonstrate that our method can launch general and effective adversarial
attacks in multi-party open systems.

</details>


### [23] [Reverse Supervision at Scale: Exponential Search Meets the Economics of Annotation](https://arxiv.org/abs/2510.10446)
*Masoud Makrehchi*

Main category: cs.LG

TL;DR: 이 논문에서는 작은 레이블 집합 A의 오류를 최소화하기 위해 큰 레이블 없는 집합 B의 레이블링을 검색하는 역감독 전략을 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 레이블 없는 데이터에 대한 레이블링을 통해 작은 데이터 집합의 오류를 줄이는 목표가 있습니다.

Method: 2^n의 검색 공간을 고려하며, 양자 컴퓨팅 또는 대규모 병렬 하드웨어와 같은 큰 상수 인자 가속에도 불구하고 복잡도가 여전히 지수적이라는 점을 다룹니다.

Result: 기계 학습 파이프라인은 여전히 초기 인간 기여가 필요하며, 이는 목표 명시, 클래스 정의 및 지식 편향을 주입하기 위한 대표적인 주석의 시드 집합을 제공하는 것을 포함합니다.

Conclusion: 초기 인간 또는 인간 등급의 입력은 시스템을 의도한 작업에 기반을 두기 위해 필수적입니다.

Abstract: We analyze a reversed-supervision strategy that searches over labelings of a
large unlabeled set \(B\) to minimize error on a small labeled set \(A\). The
search space is \(2^n\), and the resulting complexity remains exponential even
under large constant-factor speedups (e.g., quantum or massively parallel
hardware). Consequently, arbitrarily fast -- but not exponentially faster --
computation does not obviate the need for informative labels or priors. In
practice, the machine learning pipeline still requires an initial human
contribution: specifying the objective, defining classes, and providing a seed
set of representative annotations that inject inductive bias and align models
with task semantics. Synthetic labels from generative AI can partially
substitute provided their quality is human-grade and anchored by a
human-specified objective, seed supervision, and validation. In this view,
generative models function as \emph{label amplifiers}, leveraging small
human-curated cores via active, semi-supervised, and self-training loops, while
humans retain oversight for calibration, drift detection, and failure auditing.
Thus, extreme computational speed reduces wall-clock time but not the
fundamental supervision needs of learning; initial human (or human-grade) input
remains necessary to ground the system in the intended task.

</details>


### [24] [Data-driven simulator of multi-animal behavior with unknown dynamics via offline and online reinforcement learning](https://arxiv.org/abs/2510.10451)
*Keisuke Fujii,Kazushi Tsutsui,Yu Teshima,Makoto Itoh,Naoya Takeishi,Nozomi Nishiumi,Ryoya Tanaka,Shunsuke Shigaki,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: 이 논문은 다중 동물 행동을 위한 데이터 기반 시뮬레이터를 소개하며, RL 프레임워크 내에서 움직임 변수를 동작으로 추정하여 다자유도 문제를 해결하고, 종 특화된 행동의 재현성과 보상 획득을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 동물 움직임의 시뮬레이터는 행동 연구에 중요한 역할을 하며, 로봇 공학의 모방 학습의 발전은 인간과 동물의 움직임 재현 가능성을 확장했다.

Method: 우리는 깊은 강화 학습 및 반사대 시뮬레이션에 기반한 데이터 기반 다중 동물 행동 시뮬레이터를 소개하고, RL 프레임워크 내에서 불완전한 전이 모델의 움직임 변수를 동작으로 추정하여 문제를 해결한다.

Result: 인공 에이전트, 파리, 도롱뇽, 비단 나방에 대해 검증된 결과, standard imitation 및 RL 방법과 비교하여 종 특화된 행동의 재현성과 보상 획득이 더 향상되었다.

Conclusion: 이 접근 방식은 새로운 실험 환경에서의 반사대 행동 예측을 가능하게 하고, 유연한 대안 시나리오 생성을 위한 다자 모델링을 지원하여 복잡한 다중 동물 행동을 시뮬레이션하고 설명할 가능성을 제시한다.

Abstract: Simulators of animal movements play a valuable role in studying behavior.
Advances in imitation learning for robotics have expanded possibilities for
reproducing human and animal movements. A key challenge for realistic
multi-animal simulation in biology is bridging the gap between unknown
real-world transition models and their simulated counterparts. Because
locomotion dynamics are seldom known, relying solely on mathematical models is
insufficient; constructing a simulator that both reproduces real trajectories
and supports reward-driven optimization remains an open problem. We introduce a
data-driven simulator for multi-animal behavior based on deep reinforcement
learning and counterfactual simulation. We address the ill-posed nature of the
problem caused by high degrees of freedom in locomotion by estimating movement
variables of an incomplete transition model as actions within an RL framework.
We also employ a distance-based pseudo-reward to align and compare states
between cyber and physical spaces. Validated on artificial agents, flies,
newts, and silkmoth, our approach achieves higher reproducibility of
species-specific behaviors and improved reward acquisition compared with
standard imitation and RL methods. Moreover, it enables counterfactual behavior
prediction in novel experimental settings and supports multi-individual
modeling for flexible what-if trajectory generation, suggesting its potential
to simulate and elucidate complex multi-animal behaviors.

</details>


### [25] [Compositional Symmetry as Compression: Lie Pseudogroup Structure in Algorithmic Agents](https://arxiv.org/abs/2510.10586)
*Giulio Ruffini*

Main category: cs.LG

TL;DR: 이 논문은 구조적 우선순위를 단순성으로 이해하고, 에이전트가 데이터를 추적하고 압축하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트가 어떻게 감각 스트림을 추적하고 압축하는지 이해하기 위해 새로운 프레임워크를 제안한다.

Method: 유한 매개변수 리군 유사군의 (로컬) 작용을 통해 자연 스트림을 설명하고, 에이전트를 일반적인 신경 동역학 시스템으로 모델링한다.

Result: 정확한 세계 추적은 에이전트의 구성 방정식과 출력의 동등성을 요구하고, 에이전트 동역학에서 보존되는 양을 유도한다.

Conclusion: 이 프레임워크는 심층 모델에서의 조합론적 축복을 기하학적으로 설명하고, 상위 레이어가 하위 레이어에서 해결되지 않은 대칭 방향을 따라 예측 오차 좌표를 수신하는 예측 코딩의 대칭 기반 자급자족 버전을 제안한다.

Abstract: In the algorithmic (Kolmogorov) view, agents are programs that track and
compress sensory streams using generative programs. We propose a framework
where the relevant structural prior is simplicity (Solomonoff) understood as
\emph{compositional symmetry}: natural streams are well described by (local)
actions of finite-parameter Lie pseudogroups on geometrically and topologically
complex low-dimensional configuration manifolds (latent spaces). Modeling the
agent as a generic neural dynamical system coupled to such streams, we show
that accurate world-tracking imposes (i) \emph{structural constraints} --
equivariance of the agent's constitutive equations and readouts -- and (ii)
\emph{dynamical constraints}: under static inputs, symmetry induces conserved
quantities (Noether-style labels) in the agent dynamics and confines
trajectories to reduced invariant manifolds; under slow drift, these manifolds
move but remain low-dimensional. This yields a hierarchy of reduced manifolds
aligned with the compositional factorization of the pseudogroup, providing a
geometric account of the ``blessing of compositionality'' in deep models. We
connect these ideas to the Spencer formalism for Lie pseudogroups and formulate
a symmetry-based, self-contained version of predictive coding in which higher
layers receive only \emph{coarse-grained residual transformations}
(prediction-error coordinates) along symmetry directions unresolved at lower
layers.

</details>


### [26] [Digital Twin-enabled Multi-generation Control Co-Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.10694)
*Ying-Kuan Tsai,Vispi Karkaria,Yi-Ping Chen,Wei Chen*

Main category: cs.LG

TL;DR: 본 논문은 Deep Reinforcement Learning(DRL)과 Digital Twin(DT) 기술을 통합하여 제어 시스템 설계와 물리적 설계를 공동 최적화하는 새로운 제어 공동 설계(CCD) 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 동적이고 자율 시스템의 성능을 개선하기 위해 물리적 및 제어 시스템 설계를 통합하는 Control Co-Design(CCD)에 대한 필요성이 있다.

Method: Deep Reinforcement Learning(DRL)과 Digital Twin(DT) 기술을 사용하여 실시간 의사결정을 가속화하고, 다세대 패러다임을 통해 수집한 데이터를 사용하여 DT 모델을 개선하고 불확실성을 정량화한다.

Result: 이 프레임워크는 능동 서스펜션 시스템에서 DT 기반 학습을 통해 도로 조건과 운전 행동으로부터 더 부드럽고 안정적인 제어 경로를 생성하여 동적 성능, 강건성 및 효율성을 크게 향상시킨다.

Conclusion: 이 연구의 기여는 CCD를 생애 주기 중심의 다세대 프레임워크로 확장하고, DT를 통해 지속적인 모델 업데이트와 정보에 기반한 설계를 활용하며, DRL을 사용하여 적응형 실시간 의사결정을 가속화하는 것이다.

Abstract: Control Co-Design (CCD) integrates physical and control system design to
improve the performance of dynamic and autonomous systems. Despite advances in
uncertainty-aware CCD methods, real-world uncertainties remain highly
unpredictable. Multi-generation design addresses this challenge by considering
the full lifecycle of a product: data collected from each generation informs
the design of subsequent generations, enabling progressive improvements in
robustness and efficiency. Digital Twin (DT) technology further strengthens
this paradigm by creating virtual representations that evolve over the
lifecycle through real-time sensing, model updating, and adaptive
re-optimization. This paper presents a DT-enabled CCD framework that integrates
Deep Reinforcement Learning (DRL) to jointly optimize physical design and
controller. DRL accelerates real-time decision-making by allowing controllers
to continuously learn from data and adapt to uncertain environments. Extending
this approach, the framework employs a multi-generation paradigm, where each
cycle of deployment, operation, and redesign uses collected data to refine DT
models, improve uncertainty quantification through quantile regression, and
inform next-generation designs of both physical components and controllers. The
framework is demonstrated on an active suspension system, where DT-enabled
learning from road conditions and driving behaviors yields smoother and more
stable control trajectories. Results show that the method significantly
enhances dynamic performance, robustness, and efficiency. Contributions of this
work include: (1) extending CCD into a lifecycle-oriented multi-generation
framework, (2) leveraging DTs for continuous model updating and informed
design, and (3) employing DRL to accelerate adaptive real-time decision-making.

</details>


### [27] [Preconditioned Norms: A Unified Framework for Steepest Descent, Quasi-Newton and Adaptive Methods](https://arxiv.org/abs/2510.10777)
*Andrey Veprikov,Arman Bolatov,Samuel Horváth,Aleksandr Beznosikov,Martin Takáč,Slavomir Hanzely*

Main category: cs.LG

TL;DR: 이 논문에서는 문제의 기하학에 적응하는 것과 곡률 활용의 균형을 이루는 새로운 최적화 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 최신 딥러닝에서 최적화는 핵심이지만 기존 방법은 기하학에 적응하는 것과 곡률 활용 간의 기본적인 균형을 맞추는 데 한계를 가진다.

Method: 사전에 조건화된 행렬 노름의 새로운 개념을 통해 급강하, 준 뉴턴 방법 및 적응 방법을 일반화하는 통합 프레임워크를 제안한다.

Result: 제안된 방법이 SGD, Adam 및 새로운 방법들(예: MuAdam과 MuAdam-SANIA)과 같은 최적화 기법들과 경쟁력이 있으며, 경우에 따라 기존의 최첨단 방법보다 성능이 뛰어나다는 실험 결과를 제시한다.

Conclusion: 이 연구는 최적화 기술의 일반화 및 새로운 방법 개발을 통해 현대 딥러닝에서의 적용 가능성을 넓힐 수 있다.

Abstract: Optimization lies at the core of modern deep learning, yet existing methods
often face a fundamental trade-off between adapting to problem geometry and
leveraging curvature utilization. Steepest descent algorithms adapt to
different geometries through norm choices but remain strictly first-order,
whereas quasi-Newton and adaptive optimizers incorporate curvature information
but are restricted to Frobenius geometry, limiting their applicability across
diverse architectures. In this work, we propose a unified framework
generalizing steepest descent, quasi-Newton methods, and adaptive methods
through the novel notion of preconditioned matrix norms. This abstraction
reveals that widely used optimizers such as SGD and Adam, as well as more
advanced approaches like Muon and KL-Shampoo, and recent hybrids including SOAP
and SPlus, all emerge as special cases of the same principle. Within this
framework, we provide the first systematic treatment of affine and scale
invariance in the matrix-parameterized setting, establishing necessary and
sufficient conditions under generalized norms. Building on this foundation, we
introduce two new methods, $\texttt{MuAdam}$ and $\texttt{MuAdam-SANIA}$, which
combine the spectral geometry of Muon with Adam-style preconditioning. Our
experiments demonstrate that these optimizers are competitive with, and in some
cases outperform, existing state-of-the-art methods. Our code is available at
https://github.com/brain-lab-research/LIB/tree/quasi_descent

</details>


### [28] [Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation](https://arxiv.org/abs/2510.10807)
*Ali Atiah Alzahrani*

Main category: cs.LG

TL;DR: 이 논문은 레짐 변화 하에서 포트폴리오 결정을 개선하기 위해 레짐 조건 생성 시나리오와 볼록 CVaR 할당기를 결합한 연구를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 레짐 변화에 따른 포트폴리오 결정 개선의 필요성 때문이다.

Method: Multi-Agent Regime-Conditioned Diffusion (MARCD) 접근 방식을 도입하여, 가우시안 HMM을 통해 잠재 레짐을 추론하고, 비상 상황의 공동 움직임을 풍부하게 하기 위해 꼬리 가중 목적 함수를 사용하는 확산 모델을 훈련하며, 만들어진 시나리오를 명시적 거버넌스와 함께 CVaR 에피그래프 이차 프로그램에 피드하는 방법을 사용한다.

Result: MARCD가 표준 할당기보다 높은 성과를 보이며, 인기 있는 생성기와 비교할 때 캘리브레이션이 개선되었다.

Conclusion: MARCD는 꼬리 신뢰성 있는 시나리오 모델링에서 개선된 기말 통제와 유의미하게 연결된 지배당 포트폴리오 결정으로 이어지는 재현 가능한 다리를 제공한다.

Abstract: We study whether regime-conditioned generative scenarios, coupled with a
convex CVaR allocator, improve portfolio decisions under regime shifts. We
introduce Multi-Agent Regime-Conditioned Diffusion (MARCD), which (i) infers
latent regimes via a Gaussian HMM, (ii) trains a diffusion model with a
tail-weighted objective and a regime-specialized mixture-of-experts (MoE)
denoiser to enrich crisis co-movements, and (iii) feeds the generated scenarios
into a turnover-aware CVaR epigraph quadratic program with explicit governance.
In strict walk-forward tests on liquid multi-asset ETFs (2005-2025), MARCD
outperforms standard allocators and improves calibration relative to popular
generators. Over 2020-2025 out-of-sample (monthly; 10 bps), MARCD attains
Sharpe 1.23 (BL 1.02) and MaxDD 9.3 percent (BL 14.1 percent), a 34 percent
reduction, at comparable turnover; stationary block-bootstrap intervals
indicate the Sharpe uplift is significant at 5 percent. We provide theory
linking tail-weighted diffusion to spectral-risk control of the
decision-relevant CVaR gap, oracle/consistency results for the regime-MoE
denoiser, and Lipschitz/regret guarantees for the allocator. Together, MARCD
offers a reproducible bridge from tail-faithful scenario modeling to governed
portfolio decisions with materially improved drawdown control.

</details>


### [29] [A Joint Learning Approach to Hardware Caching and Prefetching](https://arxiv.org/abs/2510.10862)
*Samuel Yuan,Divyanshu Saxena,Jiayi Chen,Nihal Sharma,Aditya Akella*

Main category: cs.LG

TL;DR: 이 논문에서는 캐시 교체 및 프리패칭 정책의 상호 의존성을 조사하고, 두 정책을 공동으로 학습하는 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현대 시스템에서 스케줄링, 캐싱 및 기타 시스템 구성 요소를 위한 휴리스틱을 대체할 여러 학습 정책이 제안되고 있습니다.

Method: 저희는 캐시 교체 및 프리패칭 정책에 대해 이 두 정책을 공동 학습하도록 설계된 공유 표현을 개발하는 방법을 제안합니다.

Result: 공동 인코더와 임베딩의 대조 학습 기반의 두 가지 접근 방식을 제시하며, 두 접근 방식 모두 유망한 초기 결과를 보여줍니다.

Conclusion: 이 방향으로의 향후 연구에 대한 의제를 제시합니다.

Abstract: Several learned policies have been proposed to replace heuristics for
scheduling, caching, and other system components in modern systems. By
leveraging diverse features, learning from historical trends, and predicting
future behaviors, such models promise to keep pace with ever-increasing
workload dynamism and continuous hardware evolution. However, policies trained
in isolation may still achieve suboptimal performance when placed together. In
this paper, we inspect one such instance in the domain of hardware caching --
for the policies of cache replacement and prefetching. We argue that these two
policies are bidirectionally interdependent and make the case for training the
two jointly. We propose a joint learning approach based on developing shared
representations for the features used by the two policies. We present two
approaches to develop these shared representations, one based on a joint
encoder and another based on contrastive learning of the embeddings, and
demonstrate promising preliminary results for both of these. Finally, we lay
down an agenda for future research in this direction.

</details>


### [30] [LPCVAE: A Conditional VAE with Long-Term Dependency and Probabilistic Time-Frequency Fusion for Time Series Anomaly Detection](https://arxiv.org/abs/2510.10915)
*Hanchang Cheng,Weimin Mu,Fan Liu,Weilin Zhu,Can Ma*

Main category: cs.LG

TL;DR: LPCVAE는 장기 의존성과 확률적 시간-주파수 융합을 이용한 시계열 이상 탐지 방법이다.


<details>
  <summary>Details</summary>
Motivation: 시계열 이상 탐지는 신호 처리 분야에서 복잡한 시스템의 신뢰성을 보장하기 위해 중요하다.

Method: LPCVAE는 LSTM을 도입하여 윈도우를 넘어서는 장기 의존성을 포착하고, 적응형 및 분포 수준의 확률적 융합을 위한 전문가 곱(Product-of-Experts) 메커니즘을 통합한다.

Result: LPCVAE는 네 개의 공공 데이터 세트에 대한 광범위한 실험에서 최첨단 방법들을 능가하는 성능을 보여주었다.

Conclusion: 장기 시간 및 주파수 표현을 적응형 융합과 통합함으로써 TSAD에 대한 강력하고 효율적인 해결책을 제공하는 것이 확인되었다.

Abstract: Time series anomaly detection(TSAD) is a critical task in signal processing
field, ensuring the reliability of complex systems. Reconstruction-based
methods dominate in TSAD. Among these methods, VAE-based methods have achieved
promising results. Existing VAE-based methods suffer from the limitation of
single-window feature and insufficient leveraging of long-term time and
frequency information. We propose a Conditional Variational AutoEncoder with
Long-term dependency and Probabilistic time-frequency fusion, named LPCVAE.
LPCVAE introduces LSTM to capture long-term dependencies beyond windows. It
further incorporates a Product-of-Experts (PoE) mechanism for adaptive and
distribution-level probabilistic fusion. This design effectively mitigates
time-frequency information loss. Extensive experiments on four public datasets
demonstrate it outperforms state-of-the-art methods. The results confirm that
integrating long-term time and frequency representations with adaptive fusion
yields a robust and efficient solution for TSAD.

</details>


### [31] [Interpretable Machine Learning for Cognitive Aging: Handling Missing Data and Uncovering Social Determinant](https://arxiv.org/abs/2510.10952)
*Xi Mao,Zhendong Wang,Jingyu Li,Lingchao Mao,Utibe Essien,Hairong Wang,Xuelei Sherry Ni*

Main category: cs.LG

TL;DR: 알츠하이머병의 조기 발견은 매우 중요하며, 이 연구는 사회적 결정 요인(SDOH)을 통해 인지 성능을 예측하고, 여러 변수의 누락 문제를 해결하여 우수한 예측 성능을 보이는 모델을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병의 신경퇴행적 효과는 되돌릴 수 없으므로, 조기 발견이 중요하다. 고위험군을 조기에 식별하여 예방 및 적시 치료가 가능하도록 한다.

Method: 사회적 결정 요인(SDOH)을 활용하여 인지 성능을 예측하고, 결측값 처리를 위해 SVD 기반의 보간 파이프라인을 사용하며, XGBoost를 통해 예측 모델을 구성했다.

Result: 제안한 프레임워크는 기존 방법과 데이터 도전 과제를 초월하여 높은 정확성, 강인성 및 해석 가능성을 입증했다.

Conclusion: 연구 결과, 다양한 SDOH 및 연령별 특성 패턴이 인지 노화와 그 복합적 성격을 강조하며, 해석 가능한 데이터 기반 모델링의 가치를 보여주었다.

Abstract: Early detection of Alzheimer's disease (AD) is crucial because its
neurodegenerative effects are irreversible, and neuropathologic and
social-behavioral risk factors accumulate years before diagnosis. Identifying
higher-risk individuals earlier enables prevention, timely care, and equitable
resource allocation. We predict cognitive performance from social determinants
of health (SDOH) using the NIH NIA-supported PREPARE Challenge Phase 2 dataset
derived from the nationally representative Mex-Cog cohort of the 2003 and 2012
Mexican Health and Aging Study (MHAS).
  Data: The target is a validated composite cognitive score across seven
domains-orientation, memory, attention, language, constructional praxis, and
executive function-derived from the 2016 and 2021 MHAS waves. Predictors span
demographic, socioeconomic, health, lifestyle, psychosocial, and healthcare
access factors.
  Methodology: Missingness was addressed with a singular value decomposition
(SVD)-based imputation pipeline treating continuous and categorical variables
separately. This approach leverages latent feature correlations to recover
missing values while balancing reliability and scalability. After evaluating
multiple methods, XGBoost was chosen for its superior predictive performance.
  Results and Discussion: The framework outperformed existing methods and the
data challenge leaderboard, demonstrating high accuracy, robustness, and
interpretability. SHAP-based post hoc analysis identified top contributing SDOH
factors and age-specific feature patterns. Notably, flooring material emerged
as a strong predictor, reflecting socioeconomic and environmental disparities.
Other influential factors, age, SES, lifestyle, social interaction, sleep,
stress, and BMI, underscore the multifactorial nature of cognitive aging and
the value of interpretable, data-driven SDOH modeling.

</details>


### [32] [MC#: Mixture Compressor for Mixture-of-Experts Large Models](https://arxiv.org/abs/2510.10962)
*Wei Huang,Yue Liao,Yukang Chen,Jianhui Liu,Haoru Tan,Si Liu,Shiming Zhang,Shuicheng Yan,Xiaojuan Qi*

Main category: cs.LG

TL;DR: MC#는 MoE-LLMs/VLMs에 대한 강력한 압축을 통해 저장소와 계산 비용을 줄이기 위해 전문가의 중요성과 양자화를 결합한 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: MoE는 대형 언어 모델과 비전-언어 모델의 용량을 증대시킬 수 있지만, 메모리에 모든 전문가를 사전 로딩하고 여러 전문가를 활성화함으로써 계산 및 메모리 오버헤드가 커진다.

Method: MC#는 정적 양자화와 동적 전문가 가지치기를 결합하여 MoE-LLMs/VLMs의 공격적인 압축을 목표로 하며, 저장소 비용을 줄이기 위해 선형 프로그래밍을 통해 비트 할당을 최적화한다.

Result: DeepSeek-VL2에서 MC#는 6.2배의 경량화를 달성하면서도 다섯 개의 멀티모달 벤치마크에서 단지 1.7%의 정확도 손실을 기록하였다.

Conclusion: 이러한 접근 방식은 MoE 기반 모델 배포의 효율성을 크게 향상시킬 수 있는 잠재력을 보여준다.

Abstract: Mixture-of-Experts (MoE) effectively scales large language models (LLMs) and
vision-language models (VLMs) by increasing capacity through sparse activation.
However, preloading all experts into memory and activating multiple experts per
input introduces significant computational and memory overhead, making the
expert module a major contributor to model size and inference cost. To address
this, we propose MC# (Mixture-Compressor-sharp), a framework that combines
static quantization and dynamic expert pruning by leveraging the significance
of experts and tokens for aggressive compression of MoE-LLMs/VLMs. To reduce
storage and loading costs, we introduce Pre-Loading Mixed-Precision
Quantization (PMQ), which optimizes bit allocation via linear programming,
balancing expert importance and quantization error for a Pareto-optimal
trade-off between size and performance. To reduce runtime computation, Online
Top-any Pruning (OTP) uses Gumbel-Softmax sampling to dynamically select a
subset of experts per token, enabling fine-grained control over activation. By
combining PMQ's static bit-width optimization with OTP's dynamic routing, MC#
achieves extreme compression with minimal accuracy loss. On DeepSeek-VL2, MC#
achieves a 6.2 times weight reduction at 2.57 average bits with only a 1.7%
accuracy drop across five multimodal benchmarks. Additionally, OTP reduces
expert activation over 20% with less than 1% performance degradation,
demonstrating strong potential for efficient MoE-based model deployment.

</details>


### [33] [The Easy Path to Robustness: Coreset Selection using Sample Hardness](https://arxiv.org/abs/2510.11018)
*Pranav Ramesh,Arjun Roy,Deepak Ravikumar,Kaushik Roy,Gopalakrishnan Srinivasan*

Main category: cs.LG

TL;DR: 본 연구에서는 데이터 중심의 관점에서 적대적 강건성 모델을 설계하기 위한 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 적대적 강건성을 유지하는 데 있어 중요한 입력 샘플을 이해하기 위한 필요성.

Method: 샘플의 적대적 취약성을 샘플의 '어려움'과 연결짓는 프레임워크를 제안하며, 이를 학습 과정에서의 평균 입력 그래디언트 노름(AIGN)을 사용하여 정량화합니다.

Result: EasyCore로 알려진 새로운 코어셋 선택 알고리즘을 통해 낮은 AIGN을 가진 샘플만을 선택하여 교육하였고, 이는 경쟁 코어셋 방법에 비해 적대적 정확도가 현저히 향상됨을 입증하였습니다.

Conclusion: EasyCore는 기존의 코어셋 방법에 비해 적대적 정확도가 각기 7%와 5% 향상된 결과를 보여주었으며, 이는 데이터 중심 접근 방식으로서 강력한 효율성을 제시합니다.

Abstract: Designing adversarially robust models from a data-centric perspective
requires understanding which input samples are most crucial for learning
resilient features. While coreset selection provides a mechanism for efficient
training on data subsets, current algorithms are designed for clean accuracy
and fall short in preserving robustness. To address this, we propose a
framework linking a sample's adversarial vulnerability to its
\textit{hardness}, which we quantify using the average input gradient norm
(AIGN) over training. We demonstrate that \textit{easy} samples (with low AIGN)
are less vulnerable and occupy regions further from the decision boundary.
Leveraging this insight, we present EasyCore, a coreset selection algorithm
that retains only the samples with low AIGN for training. We empirically show
that models trained on EasyCore-selected data achieve significantly higher
adversarial accuracy than those trained with competing coreset methods under
both standard and adversarial training. As AIGN is a model-agnostic dataset
property, EasyCore is an efficient and widely applicable data-centric method
for improving adversarial robustness. We show that EasyCore achieves up to 7\%
and 5\% improvement in adversarial accuracy under standard training and TRADES
adversarial training, respectively, compared to existing coreset methods.

</details>


### [34] [Refining Hybrid Genetic Search for CVRP via Reinforcement Learning-Finetuned LLM](https://arxiv.org/abs/2510.11121)
*Rongjie Zhu,Cong Zhang,Zhiguang Cao*

Main category: cs.LG

TL;DR: 작은 전문화된 대형 언어 모델이 전문가가 설계한 휴리스틱을 초월할 수 있음을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 자동차 경로 문제(VRP)에 대한 자동화된 휴리스틱 설계자로서 LLM의 사용이 증가하고 있지만, 기존 방법은 일반 모델에 의존하고 있다.

Method: 작은 LLM을 세심하게 미세 조정하여 Hybrid Genetic Search(HGS) 솔버를 위한 고성능 교차 연산자를 생성하는 RFTHGS 프레임워크를 제안한다.

Result: 미세 조정된 LLM이 HGS에서 전문가가 설계한 교차 연산자보다 뛰어난 성능을 발휘한다는 실험 결과가 나왔다.

Conclusion: RFTHGS는 선도적인 신경 조합 기초 및 상용 LLM보다 성능이 우수하다.

Abstract: While large language models (LLMs) are increasingly used as automated
heuristic designers for vehicle routing problems (VRPs), current
state-of-the-art methods predominantly rely on prompting massive,
general-purpose models like GPT-4. This work challenges that paradigm by
demonstrating that a smaller, specialized LLM, when meticulously fine-tuned,
can generate components that surpass expert-crafted heuristics within advanced
solvers. We propose RFTHGS, a novel Reinforcement learning (RL) framework for
Fine-Tuning a small LLM to generate high-performance crossover operators for
the Hybrid Genetic Search (HGS) solver, applied to the Capacitated VRP (CVRP).
Our method employs a multi-tiered, curriculum-based reward function that
progressively guides the LLM to master generating first compilable, then
executable, and finally, superior-performing operators that exceed human expert
designs. This is coupled with an operator caching mechanism that discourages
plagiarism and promotes diversity during training. Comprehensive experiments
show that our fine-tuned LLM produces crossover operators which significantly
outperform the expert-designed ones in HGS. The performance advantage remains
consistent, generalizing from small-scale instances to large-scale problems
with up to 1000 nodes. Furthermore, RFTHGS exceeds the performance of leading
neuro-combinatorial baselines, prompt-based methods, and commercial LLMs such
as GPT-4o and GPT-4o-mini.

</details>


### [35] [Beyond single-model XAI: aggregating multi-model explanations for enhanced trustworthiness](https://arxiv.org/abs/2510.11164)
*Ilaria Vascotto,Alex Rodriguez,Alessandro Bonaita,Luca Bortolussi*

Main category: cs.LG

TL;DR: 본 연구는 인공지능 모델의 신뢰성 향상을 위해 다양한 모델의 특성 중요도를 집계하는 방법을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 고위험 애플리케이션에서 AI 모델의 신뢰성과 윤리적 사용에 대한 논의가 증가하고 있습니다.

Method: 본 논문은 $k$-nearest neighbours, 랜덤 포레스트 및 신경망을 사용하여 얻은 특성 중요도 집계를 통해 강건성의 역할을 조사합니다.

Result: 예비 결과는 다양한 모델의 예측력을 활용하여 애플리케이션의 신뢰성을 높일 수 있는 잠재력을 보여줍니다.

Conclusion: 강건한 설명 방법만이 시스템 전체에 대한 신뢰를 증가시킬 수 있습니다.

Abstract: The use of Artificial Intelligence (AI) models in real-world and high-risk
applications has intensified the discussion about their trustworthiness and
ethical usage, from both a technical and a legislative perspective. The field
of eXplainable Artificial Intelligence (XAI) addresses this challenge by
proposing explanations that bring to light the decision-making processes of
complex black-box models. Despite being an essential property, the robustness
of explanations is often an overlooked aspect during development: only robust
explanation methods can increase the trust in the system as a whole. This paper
investigates the role of robustness through the usage of a feature importance
aggregation derived from multiple models ($k$-nearest neighbours, random forest
and neural networks). Preliminary results showcase the potential in increasing
the trustworthiness of the application, while leveraging multiple model's
predictive power.

</details>


### [36] [ELMO: Efficiency via Low-precision and Peak Memory Optimization in Large Output Spaces](https://arxiv.org/abs/2510.11168)
*Jinbin Zhang,Nasib Ullah,Erik Schultheis,Rohit Babbar*

Main category: cs.LG

TL;DR: 본 논문에서는 극단적인 다중 레이블 분류(XMC)를 위한 순수 저정밀도 훈련 프레임워크인 ELMO를 제안하며, GPU 메모리 사용량을 크게 줄이는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: XMC는 대규모 태깅 및 제품 간 추천에서 발생하며, 레이블 수가 수십만에서 수백만까지 이릅니다. 이는 전체 모델의 작은 부분인 선형 분류 헤드가 컴퓨팅 및 메모리 수요의 주요 원동력이 됨을 의미합니다.

Method: BFloat16 및 Float8 데이터 유형을 사용하는 ELMO라는 저정밀도 훈련 프레임워크를 제안하고, Kahan 합산 및 확률적 반올림을 활용하여 XMC 모델을 Float8만으로 효과적으로 훈련할 수 있음을 보여줍니다.

Result: 3백만 레이블 XMC 모델을 정확도를 손상시키지 않고 최적화된 SOTA 방법인 Renee가 필요한 39.7 GiB의 GPU 메모리에 비해 6.6 GiB의 메모리로 훈련할 수 있음을 보여줍니다.

Conclusion: 저정밀도 훈련과 메모리 최적화 기법인 기울기 융합 및 청킹을 사용하면 GPU 메모리 사용량을 크게 줄일 수 있습니다.

Abstract: Large output spaces, also referred to as Extreme multilabel classification
(XMC), is a setting that arises, e.g., in large-scale tagging and
product-to-product recommendation, and is characterized by the number of labels
ranging from hundreds of thousands to millions. This means that the linear
classification head, usually only a tiny fraction of the overall model, turns
into the main driver for compute and memory demand. Current state-of-the-art
XMC methods predominantly rely on FP16-FP32 mixed-precision training, which we
show can be unstable, and inefficient in terms of memory usage and
computational overhead. Meanwhile, existing low-precision methods typically
retain higher precision for the classification layer. In this work, we propose
ELMO, a pure low-precision training framework for XMC models using BFloat16 and
Float8 data types. By leveraging Kahan summation and stochastic rounding, we
demonstrate that XMC models can be effectively trained entirely in Float8,
without relying on single-precision master weights or tensor scaling.
Low-precision training, combined with our proposed memory optimizations --
gradient fusion and chunking -- enables significant reductions in GPU memory
usage. For example, we train a 3-million-label XMC model with only 6.6 GiB of
GPU memory, compared to the 39.7 GiB required by the optimized SOTA method,
Renee without compromising accuracy.

</details>


### [37] [Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?](https://arxiv.org/abs/2510.11184)
*Zhengyu Chen,Jinluan Yang,Teng Xiao,Ruochen Zhou,Luan Zhang,Xiangyu Xi,Xiaowei Shi,Wei Wang,Jinggang Wang*

Main category: cs.LG

TL;DR: 도구를 활용한 강화 학습의 영역 간 일반화에 대한 연구.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 도구 활용 능력을 확장하여 다양한 도메인에서의 성능을 향상시키기 위해.

Method: 수학 문제 해결 작업에만 훈련된 LLM 에이전트를 코드 해석기 도구와 함께 사용하여 영역 간 일반화를 조사하고, TGRL 프레임워크를 제안하여 도메인 비의존적 학습을 촉진.

Result: 수학 작업에서 학습한 도구 사용이 다른 복잡한 작업으로 효과적으로 이전되며, 뛰어난 작업 성능과 높은 토큰 효율성 달성.

Conclusion: TGRL 프레임워크가 영역 간 전이를 촉진하고 LLM 추론의 교차 영역 잠재력을 강조한다.

Abstract: Recent advances in large language models (LLMs) have demonstrated remarkable
capabilities in reasoning and tool utilization. However, the generalization of
tool-augmented reinforcement learning (RL) across diverse domains remains
underexplored. In this work, we investigate the cross-domain generalization of
an LLM agent equipped with a code interpreter tool, which is exclusively
trained on mathematical problem-solving tasks. Despite the restricted training
domain, we evaluate the agent's performance across several distinct reasoning
domains. The results reveal that RL-based tool usage learned from mathematical
tasks can be effectively transferred to complex tasks in other domains,
enabling great task performance and high token efficiency. To facilitate this
cross-domain transfer, we propose a Tool Generalization Reinforcement Learning
(TGRL) framework designed to promote domain-agnostic learning and skill
migration, encompassing: (i) a standardized tool interface that abstracts
domain-specific nuances through consistent formatting and explicit termination,
fostering transferable invocation patterns; (ii) a dual-component reward system
that decomposes rewards to incentivize generalizable behaviors like tool
efficiency and reasoning abstraction, ensuring alignment and robustness across
domain shifts; and (iii) an XML-based prompt template that separates thinking,
tool calls, and responses to encourage modular, domain-invariant planning and
coherent multi-turn interactions. Extensive experiments across diverse
benchmarks validate our approach, achieving state-of-the-art performance and
highlighting the cross-domain potential of Tool RL for LLM reasoning.

</details>


### [38] [LouisKV: Efficient KV Cache Retrieval for Long Input-Output Sequences](https://arxiv.org/abs/2510.11292)
*Wenbo Wu,Qingyi Si,Xiurui Pan,Ye Wang,Jie Zhang*

Main category: cs.LG

TL;DR: LouisKV는 긴 시퀀스 시나리오에서 효율적인 KV 캐시 검색 프레임워크로, 시간적 지역성을 활용하여 연산 및 데이터 전송 오버헤드를 크게 줄입니다.


<details>
  <summary>Details</summary>
Motivation: 긴 시퀀스 시나리오에서 KV 캐시의 메모리 오버헤드를 줄이는 필요성을 느꼈습니다.

Method: LouisKV는 시간적 지역성을 활용한 의미 인식 검색 전략과 차별화된 입력 및 출력 시퀀스 관리를 통해 효율성을 높였습니다.

Result: LouisKV는 최신 KV 검색 방법 대비 최대 4.7배의 속도 향상과 다양한 긴 시퀀스 작업에서 거의 손실 없는 정확성을 유지합니다.

Conclusion: LouisKV는 긴 시퀀스 처리에 있어 효율성과 정확성을 크게 개선하며, 다양한 시나리오에 적용될 수 있습니다.

Abstract: While Key-Value (KV) cache succeeds in reducing redundant computations in
auto-regressive models, it introduces significant memory overhead, limiting its
practical deployment in long-sequence scenarios. Existing KV retrieval methods
mitigate this by dynamically retaining only a subset of KV entries on the GPU.
However, they still suffer from notable efficiency and accuracy bottlenecks due
to per-token retrieval and coarse-grained page-level KV management, especially
in long-output reasoning scenarios. With the emergence of large reasoning
models, efficiently handling such scenarios has become increasingly important.
To address this issue, we present two key observations: (1) critical KVs
exhibit strong temporal locality during decoding, and (2) these KVs exhibit
distinct distribution patterns across the input prompt and generated output.
Building on these observations, we propose LouisKV, an efficient KV cache
retrieval framework designed for various long-sequence scenarios. Specifically,
LouisKV introduces a semantic-aware retrieval strategy leveraging temporal
locality to trigger retrieval only at semantic boundaries, drastically reducing
computation and data transfer overhead. LouisKV also designs a decoupled,
fine-grained management scheme that tailors differentiated strategies for input
and output sequences to create retrieval units that better match the model's
attention patterns, enabling precise identification of critical KVs.
Furthermore, to boost efficiency, LouisKV incorporates several kernel-level
optimizations, including custom Triton and CUDA kernels to accelerate the KV
clustering and retrieval. Evaluations show that LouisKV achieves up to
4.7$\times$ speedup over state-of-the-art KV retrieval methods while
maintaining near-lossless accuracy across diverse long-sequence tasks,
including long-input short-output, short-input long-output, and long-input
long-output scenarios.

</details>


### [39] [Part II: ROLL Flash -- Accelerating RLVR and Agentic Training with Asynchrony](https://arxiv.org/abs/2510.11345)
*Han Lu,Zichen Liu,Shaopan Xiong,Yancheng He,Wei Gao,Yanan Wu,Weixun Wang,Jiashun Liu,Yang Li,Haizhou Zhao,Ju Huang,Siran Yang,Xiaoyang Li,Yijia Luo,Zihe Liu,Ling Pan,Junchi Yan,Wei Wang,Wenbo Su,Jiamang Wang,Lin Qu,Bo Zheng*

Main category: cs.LG

TL;DR: ROLL Flash는 비동기 강화 학습 후 훈련을 지원하도록 ROLL을 확장한 시스템으로, 자원 활용도와 확장성을 크게 개선한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)의 다양한 기능을 향상시키기 위한 중요한 단계로 비동기 강화 학습 후 훈련이 등장했지만, 기존 시스템들은 낮은 자원 활용도와 한정된 확장성 문제를 겪고 있다.

Method: ROLL Flash는 정밀한 병렬 처리와 롤아웃-훈련 분리를 기반으로 구축되었으며, 완전 비동기 훈련 아키텍처와 효율적인 롤아웃 메커니즘을 지원하는 유연한 프로그래밍 인터페이스를 제공한다.

Result: ROLL Flash는 RLVR 작업에서 최대 2.24배, 에이전트 작업에서 2.72배의 속도 향상을 달성하며, 동기화 기준과 동일한 GPU 예산을 사용한다.

Conclusion: 비동기 훈련을 통한 성능 검증을 위해 여러 인기 있는 오프폴리시 알고리즘을 구현하였으며, 이는 동기화 훈련과 동등한 성능을 달성할 수 있음을 확인했다.

Abstract: Synchronous Reinforcement Learning (RL) post-training has emerged as a
crucial step for enhancing Large Language Models (LLMs) with diverse
capabilities. However, many systems designed to accelerate RL post-training
still suffer from low resource utilization and limited scalability. We present
ROLL Flash, a system that extends ROLL with native support for asynchronous RL
post-training. ROLL Flash is built upon two core design principles:
fine-grained parallelism and rollout-train decoupling. Guided by these
principles, ROLL Flash provides flexible programming interfaces that enable a
fully asynchronous training architecture and support efficient rollout
mechanisms, including queue scheduling and environment-level asynchronous
execution. Through comprehensive theoretical analysis and extensive
experiments, we demonstrate that ROLL Flash significantly improves resource
utilization and scalability over synchronous RL post-training. ROLL Flash
achieves up to 2.24x speedup on RLVR tasks and 2.72x on agentic tasks, using
the same GPU budget as synchronous baselines. Furthermore, we implement several
popular off-policy algorithms and verify that asynchronous training can achieve
performance on par with synchronous training.

</details>


### [40] [Leveraging LLMs for Semi-Automatic Corpus Filtration in Systematic Literature Reviews](https://arxiv.org/abs/2510.11409)
*Lucas Joos,Daniel A. Keim,Maximilian T. Fischer*

Main category: cs.LG

TL;DR: 본 연구에서는 대규모 언어 모델을 활용한 체계적 문헌 검토의 효율성을 향상시키는 파이프라인을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 체계적 문헌 검토(SLR)는 연구 분야를 분석하고 향후 연구 방향을 안내하는 데 중요하지만, 관련 문헌을 수집하고 필터링하는 과정은 시간 소모가 크고 많은 수작업이 필요하다.

Method: 다양한 대규모 언어 모델(LLM)을 활용하여 논문을 분류하고 합의 방식을 통해 공동으로 결정하는 파이프라인을 제안한다. 이 과정은 이용자가 실시간으로 모델 출력을 검사하고 수정할 수 있도록 하는 오픈 소스 시각 분석 웹 인터페이스인 LLMSurver를 통해 감독된다.

Result: 우리의 접근 방식을 8,000개 이상의 후보 논문을 포함하는 최근 SLR의 실제 데이터로 평가한 결과, 파이프라인은 수작업 노력을 상당히 줄이고 단일 인간 주석자보다 낮은 오류율을 달성했다.

Conclusion: 현대의 오픈 소스 모델이 이 태스크에 충분함을 입증하며, 이 방법은 접근 가능하고 비용 효율적이다. 우리의 연구는 책임 있는 인간-AI 협력이 학술 워크플로 내에서 체계적 문헌 검토를 가속화하고 향상시킬 수 있음을 보여준다.

Abstract: The creation of systematic literature reviews (SLR) is critical for analyzing
the landscape of a research field and guiding future research directions.
However, retrieving and filtering the literature corpus for an SLR is highly
time-consuming and requires extensive manual effort, as keyword-based searches
in digital libraries often return numerous irrelevant publications. In this
work, we propose a pipeline leveraging multiple large language models (LLMs),
classifying papers based on descriptive prompts and deciding jointly using a
consensus scheme. The entire process is human-supervised and interactively
controlled via our open-source visual analytics web interface, LLMSurver, which
enables real-time inspection and modification of model outputs. We evaluate our
approach using ground-truth data from a recent SLR comprising over 8,000
candidate papers, benchmarking both open and commercial state-of-the-art LLMs
from mid-2024 and fall 2025. Results demonstrate that our pipeline
significantly reduces manual effort while achieving lower error rates than
single human annotators. Furthermore, modern open-source models prove
sufficient for this task, making the method accessible and cost-effective.
Overall, our work demonstrates how responsible human-AI collaboration can
accelerate and enhance systematic literature reviews within academic workflows.

</details>


### [41] [ReLook: Vision-Grounded RL with a Multimodal LLM Critic for Agentic Web Coding](https://arxiv.org/abs/2510.11498)
*Yuhang Li,Chenchen Zhang,Ruilin Lv,Ao Liu,Ken Deng,Yuanxing Zhang,Jiaheng Liu,Wiggin Zhou,Bo Zhou*

Main category: cs.LG

TL;DR: ReLook는 프론트엔드 개발에서의 코드 생성을 개선하기 위해 멀티모달 대형 언어 모델을 활용한 강화 학습 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)은 알고리즘 코드 생성을 잘 수행하지만, 렌더링된 픽셀과 상호작용에 따라 정 correctness가 판단되는 프론트엔드 개발에서는 어려움을 겪고 있다.

Method: ReLook은 에이전트가 멀티모달 LLM(MLLM)을 도구로 사용하여 강력한 생성-진단-개선 루프를 완성할 수 있도록 하는 시각 기반의 에이전틱 강화 학습 프레임워크이다.

Result: ReLook는 세 가지 널리 사용되는 벤치마크에서 강력한 기준선을 지속적으로 능가하여 시각 기반 프론트엔드 코드 생성에서 에이전틱 인식, 시각적 보상 및 훈련-추론 분리의 이점을 강조한다.

Conclusion: 이 프레임워크는 프론트엔드 개발의 정확성을 높이기 위해 행동 붕괴를 방지하고 지속적으로 개선된 경로를 생성하는 엄격한 수용 규칙을 도입한다.

Abstract: While Large Language Models (LLMs) excel at algorithmic code generation, they
struggle with front-end development, where correctness is judged on rendered
pixels and interaction. We present ReLook, an agentic, vision-grounded
reinforcement learning framework that empowers an agent to close a robust
generate--diagnose--refine loop by invoking a multimodal LLM (MLLM) as a tool.
During training, the agent uses the MLLM-in-the-loop both as a visual
critic--scoring code with screenshots--and as a source of actionable,
vision-grounded feedback; a strict zero-reward rule for invalid renders anchors
renderability and prevents reward hacking. To prevent behavioral collapse, we
introduce Forced Optimization, a strict acceptance rule that admits only
improving revisions, yielding monotonically better trajectories. At inference,
we decouple the critic and run a lightweight, critic-free self-edit cycle,
keeping latency comparable to base decoding while retaining most of the gains.
Across three widely used benchmarks, ReLook consistently outperforms strong
baselines in vision-grounded front-end code generation, highlighting the
benefits of agentic perception, visual rewards, and training-inference
decoupling.

</details>


### [42] [Learning to Make MISTAKEs: Modeling Incorrect Student Thinking And Key Errors](https://arxiv.org/abs/2510.11502)
*Alexis Ross,Jacob Andreas*

Main category: cs.LG

TL;DR: 본 연구는 언어 모델에서의 추론 개선을 넘어, 잘못된 추론 패턴을 모델링하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 학생 오류를 추론하고 시뮬레이션할 수 있는 자동화된 시스템은 교육자 훈련을 위한 실시간 피드백 제공에 유용하다.

Method: MISTAKE라는 새로운 방법을 제시하며, 이는 잘못된 답변과 잠재적 오해 간의 사이클 일관성을 이용해 고품질의 합성 사례를 구축하고 생성된 데이터를 사용하여 학생 시뮬레이션, 오해 분류, 답변 생성을 위한 모델을 학습한다.

Result: MISTAKE는 세 가지 교육 작업에서 평가되며, 특정 오해를 기반으로 한 잘못된 학생 답변 시뮬레이션에서의 정확도 향상, 관찰된 잘못된 답변으로부터 잠재적 오해를 추론하는 성능 향상, 불치 항목의 잘못된 답변 생성을 위해 전문가가 작성한 주의 사항 답변과 높은 일치를 보인다.

Conclusion: 결과적으로, MISTAKE는 교육 분야에서 유용한 도구로 작용할 수 있다.

Abstract: Research on reasoning in language models (LMs) predominantly focuses on
improving the correctness of their outputs. But some important applications
require modeling reasoning patterns that are incorrect. For example, automated
systems that can reason about and simulate student errors are useful for
providing real-time feedback in the classroom or offline practice for
educators-in-training. This paper presents a new method, MISTAKE, that (1)
constructs high-quality synthetic examples of reasoning errors by leveraging
cycle consistency between incorrect answers and latent misconceptions; and (2)
uses the generated data to learn models for student simulation, misconception
classification, and answer generation. We evaluate MISTAKE on three educational
tasks and find that it results in (1) higher accuracy when simulating incorrect
student answers based on specific misconceptions, (2) increased performance
inferring latent misconceptions from observed incorrect answers, and (3) higher
alignment with expert-written distractor answers when generating incorrect
answers (e.g., for multiple-choice tests).

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [43] [Automating the RMF: Lessons from the FedRAMP 20x Pilot](https://arxiv.org/abs/2510.09613)
*Isaac Henry Teuscher*

Main category: cs.CR

TL;DR: FedRAMP 20x는 클라우드 시스템 평가를 위한 새로운 접근 방식을 제공하며, 이를 통해 사이버 위험 관리와 컴플라이언스를 현대화하려는 노력에 대한 사례 연구를 제시한다.


<details>
  <summary>Details</summary>
Motivation: FedRAMP는 클라우드 시스템에 대한 평가를 위해 전통적인 통제 및 문서화에 의존해 왔으며, 이는 클라우드 네이티브 개발의 속도를 따라잡지 못하고 있다.

Method: 전통적인 NIST 800-53 통제를 Key Security Indicators(KSIs)로 대체하고, 자동화된 기계 판독 증거를 사용하며, 지속적인 보고 및 승인을 강조한다.

Result: KSIs, 지속적인 증거 파이프라인 및 DevSecOps 통합이 권한 부여를 간소화하고 사이버 위험 관리를 개선하는 데 기여할 수 있음을 보여준다.

Conclusion: FedRAMP 20x는 클라우드 네이티브, 자동화 중심 접근 방식에서 RMF를 구현하기 위한 실시간 테스트베드로 작용하며, 위험 전문가들이 컴플라이언스를 현대화하고 실시간 위험 정보 기반 의사 결정을 지원할 수 있도록 하는 실행 가능한 권장 사항을 공유한다.

Abstract: The U.S. Federal Risk and Authorization Management Program (FedRAMP) has long
relied on extensive sets of controls and static documentation to assess cloud
systems. However, this manual, point-in-time approach has struggled to keep
pace with cloud-native development. FedRAMP 20x, a 2025 pilot program,
reimagines the NIST Risk Management Framework (RMF): replacing traditional NIST
800-53 controls with Key Security Indicators (KSIs), using automated,
machine-readable evidence, and emphasizing continuous reporting and
authorization.
  This case study presents a practitioner-led field report from an industry
participant who led multiple FedRAMP 20x pilot submissions and engaged directly
with the FedRAMP PMO, 3PAOs, and community working groups. It explores how
KSIs, continuous evidence pipelines, and DevSecOps integration can streamline
authorization and improve cyber risk management. The study shows FedRAMP 20x as
a live testbed for implementing the RMF in a cloud-native, automation-first
approach and shares actionable recommendations for risk professionals seeking
to modernize compliance and support real-time, risk-informed decision-making.

</details>


### [44] [A Biosecurity Agent for Lifecycle LLM Biosecurity Alignment](https://arxiv.org/abs/2510.09615)
*Meiyin Meng,Zaixi Zhang*

Main category: cs.CR

TL;DR: 이 연구는 생물 의학 연구에서 대규모 언어 모델의 안전성과 유용성을 모두 보장하기 위해 구성된 생물안전 에이전트를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 생물 의학 연구에 대규모 언어 모델을 통합하게 되면서 독성 화합물 합성을 안내하는 잘못된 사용 우려가 커졌다.

Method: 이 연구는 데이터셋 세정, 선호 조정, 실행 시 안전 장치, 자동화된 적대적 테스트의 네 가지 조정을 통해 모델 생애 주기 전반에 걸쳐 안전성을 보장한다.

Result: 데이터셋 세정을 통해 0.46%에서 70.40%로 제거 비율이 상승하며, 공격 성공률을 59.7%에서 3.0%로 낮췄고, 여러 보안 측정에서 최상의 균형을 이룬다.

Conclusion: 우리의 생물안전 에이전트는 공격 성공률을 줄이면서 유익한 유용성을 유지하는 감사 가능한 생애 주기 맞춤형 프레임워크를 제공한다.

Abstract: Large language models (LLMs) are increasingly integrated into biomedical
research workflows--from literature triage and hypothesis generation to
experimental design--yet this expanded utility also heightens dual-use
concerns, including the potential misuse for guiding toxic compound synthesis.
In response, this study shows a Biosecurity Agent that comprises four
coordinated modes across the model lifecycle: dataset sanitization, preference
alignment, run-time guardrails, and automated red teaming. For dataset
sanitization (Mode 1), evaluation is conducted on CORD-19, a COVID-19 Open
Research Dataset of coronavirus-related scholarly articles. We define three
sanitization tiers--L1 (compact, high-precision), L2 (human-curated biosafety
terms), and L3 (comprehensive union)--with removal rates rising from 0.46% to
70.40%, illustrating the safety-utility trade-off. For preference alignment
(Mode 2), DPO with LoRA adapters internalizes refusals and safe completions,
reducing end-to-end attack success rate (ASR) from 59.7% to 3.0%. At inference
(Mode 3), run-time guardrails across L1-L3 show the expected security-usability
trade-off: L2 achieves the best balance (F1 = 0.720, precision = 0.900, recall
= 0.600, FPR =0.067), while L3 offers stronger jailbreak resistance at the cost
of higher false positives. Under continuous automated red-teaming (Mode 4), no
successful jailbreaks are observed under the tested protocol. Taken together,
our biosecurity agent offers an auditable, lifecycle-aligned framework that
reduces attack success while preserving benign utility, providing safeguards
for the use of LLMs in scientific research and setting a precedent for future
agent-level security protections.

</details>


### [45] [Toward a Unified Security Framework for AI Agents: Trust, Risk, and Liability](https://arxiv.org/abs/2510.09620)
*Jiayun Mo,Xin Kang,Tieyan Li,Zhongding Lei*

Main category: cs.CR

TL;DR: AI 에이전트의 발전은 신뢰, 위험 및 책임 간의 상호관계에 대한 체계적인 접근 방식을 제안하는 TRL 프레임워크를 통해 이러한 문제들을 해결할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 개발로 인해 발생한 사용자 신뢰 문제, 위험 및 책임 할당의 어려움이 커졌다.

Method: TRL 프레임워크는 신뢰, 위험 및 책임의 상호의존 관계를 연결하여 체계적인 방법으로 신뢰 구축, 위험 분석 및 완화, 책임 할당을 제시한다.

Result: TRL 프레임워크는 AI 에이전트의 다양한 응용 시나리오에 적용할 수 있으며 상황에 맞는 적절한 조치를 제안한다.

Conclusion: 이 프레임워크는 6G 네트워크 내에서 신뢰할 수 있고 책임감 있는 AI 사용을 촉진하는 데 중요한 가치를 가져올 것으로 기대된다.

Abstract: The excitement brought by the development of AI agents came alongside arising
problems. These concerns centered around users' trust issues towards AIs, the
risks involved, and the difficulty of attributing responsibilities and
liabilities. Current solutions only attempt to target each problem separately
without acknowledging their inter-influential nature. The Trust, Risk and
Liability (TRL) framework proposed in this paper, however, ties together the
interdependent relationships of trust, risk, and liability to provide a
systematic method of building and enhancing trust, analyzing and mitigating
risks, and allocating and attributing liabilities. It can be applied to analyze
any application scenarios of AI agents and suggest appropriate measures fitting
to the context. The implications of the TRL framework lie in its potential
societal impacts, economic impacts, ethical impacts, and more. It is expected
to bring remarkable values to addressing potential challenges and promoting
trustworthy, risk-free, and responsible usage of AI in 6G networks.

</details>


### [46] [Hound: Relation-First Knowledge Graphs for Complex-System Reasoning in Security Audits](https://arxiv.org/abs/2510.09633)
*Bernhard Mueller*

Main category: cs.CR

TL;DR: 이 논문은 관계 우선 그래프 엔진인 Hound를 소개하며, 복잡한 코드베이스의 상호 관련 구성 요소 간의 시스템 수준 추론을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 코드베이스에서의 시스템 수준 추론을 개선하기 위해.

Method: 유연하고 분석가가 정의한 뷰를 사용하여 코드의 중요한 부분을 정확히 로드하는 관계 우선 그래프 엔진을 설계하고, 장기적인 취약점 가설을 유지하는 신뢰 시스템을 도입.

Result: Hound는 ScaBench의 다섯 개 프로젝트에 대해 기준 LLM 분석기를 초과하는 성능 향상을 보였으며, 회상율은 31.2%로 8.3%보다 우수하고 F1 점수는 14.2%로 9.8%보다 높았다.

Conclusion: 이런 성장은 호출/데이터 흐름을 넘어 추상적 측면까지 모델 이해를 확장하는 유연한 관계 우선 그래프와 가설 중심 루프 덕분이다.

Abstract: Hound introduces a relation-first graph engine that improves system-level
reasoning across interrelated components in complex codebases. The agent
designs flexible, analyst-defined views with compact annotations (e.g.,
monetary/value flows, authentication/authorization roles, call graphs, protocol
invariants) and uses them to anchor exact retrieval: for any question, it loads
precisely the code that matters (often across components) so it can zoom out to
system structure and zoom in to the decisive lines. A second contribution is a
persistent belief system: long-lived vulnerability hypotheses whose confidence
is updated as evidence accrues. The agent employs coverage-versus-intuition
planning and a QA finalizer to confirm or reject hypotheses. On a five-project
subset of ScaBench[1], Hound improves recall and F1 over a baseline LLM
analyzer (micro recall 31.2% vs. 8.3%; F1 14.2% vs. 9.8%) with a modest
precision trade-off. We attribute these gains to flexible, relation-first
graphs that extend model understanding beyond call/dataflow to abstract
aspects, plus the hypothesis-centric loop; code and artifacts are released to
support reproduction.

</details>


### [47] [AdaptAuth: Multi-Layered Behavioral and Credential Analysis for a Secure and Adaptive Authentication Framework for Password Security](https://arxiv.org/abs/2510.09645)
*Tonmoy Ghosh*

Main category: cs.CR

TL;DR: 비밀번호 보안은 현대 시스템의 계산 능력 증가에 대응하여 발전해야 했다. 그러나 이 과정에서 사용자가 소외되고 보안 준수율이 낮아지면서 취약성이 증가하였다. 본 논문에서는 비밀번호 관련 위험을 효과적으로 해결하기 위해 비밀번호 해체 메커니즘, 동적 비밀번호 정책 메커니즘 등 다양한 요소를 통합한 다면적 솔루션을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 비밀번호 보안의 발전이 사용자에게 복잡성을 초래하고 준수율을 낮춰 공격에 취약해진 점.

Method: 다양한 요인을 통합하여 비밀번호 보안을 혁신하는 복합적 솔루션 제안.

Result: 학습 기반 모델을 활용하여 개인을 인식하고 무단 접근을 차단하는 상세한 사용자 프로필 구축.

Conclusion: 사용자 참여를 통한 정책 설정 과정에서 강력한 보호를 제공하는 새로운 접근 방식을 제시한다.

Abstract: Password security has been compelled to evolve in response to the growing
computational capabilities of modern systems. However, this evolution has often
resulted in increasingly complex security practices that alienate users,
leading to poor compliance and heightened vulnerability. Consequently,
individuals remain exposed to attackers through weak or improperly managed
passwords, underscoring the urgent need for a comprehensive defense mechanism
that effectively addresses password-related risks and threats. In this paper,
we propose a multifaceted solution designed to revolutionize password security
by integrating diverse attributes such as the Password Dissection Mechanism,
Dynamic Password Policy Mechanism, human behavioral patterns, device
characteristics, network parameters, geographical context, and other relevant
factors. By leveraging learning-based models, our framework constructs detailed
user profiles capable of recognizing individuals and preventing nearly all
forms of unauthorized access or device possession. The proposed framework
enhances the usability-security paradigm by offering stronger protection than
existing standards while simultaneously engaging users in the policy-setting
process through a novel, adaptive approach.

</details>


### [48] [Signing Right Away](https://arxiv.org/abs/2510.09656)
*Yejun Jang*

Main category: cs.CR

TL;DR: SRA는 디지털 미디어의 출처를 보장하는 종합 보안 아키텍처로, 신뢰할 수 있는 비주얼 정보에 의존하는 산업에 기초적인 해결책을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 디지털 콘텐츠에 대한 신뢰 위기를 해결하기 위해.

Method: SRA는 신뢰할 수 있는 실행 환경에서 전체 이미징 파이프라인을 보호합니다.

Result: 각 캡처된 이미지와 비디오가 변조 불가능한 출처 증명을 지닌다는 것을 보장합니다.

Conclusion: SRA는 콘텐츠 신뢰의 체인에서 필수적인 '마지막 단계'로 자리 잡고 있습니다.

Abstract: The proliferation of high-fidelity synthetic media, coupled with exploitable
hardware vulnerabilities in conventional imaging pipelines, has precipitated a
crisis of trust in digital content. Existing countermeasures, from post-hoc
classifiers to software-based signing, fail to address the fundamental
challenge of establishing an unbreakable link to reality at the moment of
capture. This whitepaper introduces Signing Right Away (SRA), a comprehensive
security architecture that guarantees the provenance of digital media from
"silicon to silicon to signed file." SRA leverages a four-pillar security
model-Confidentiality, Integrity, Authentication, and Replay Protection, akin
to the MIPI Camera Security Framework (CSF), but also extends its scope beyond
the internal data bus to the creation of a cryptographically sealed,
C2PA-compliant final asset. By securing the entire imaging pipeline within a
Trusted Execution Environment (TEE), SRA ensures that every captured image and
video carries an immutable, verifiable proof of origin. This provides a
foundational solution for industries reliant on trustworthy visual information,
including journalism, legal evidence, and insurance. We present the SRA
architecture, a detailed implementation roadmap informed by empirical
prototyping, and a comparative analysis that positions SRA as the essential
"last mile" in the chain of content trust.

</details>


### [49] [Adversarial-Resilient RF Fingerprinting: A CNN-GAN Framework for Rogue Transmitter Detection](https://arxiv.org/abs/2510.09663)
*Raju Dhakal,Prashant Shekhar,Laxima Niure Kandel*

Main category: cs.CR

TL;DR: 이 연구는 Convolutional Neural Network (CNN)을 이용한 데이터 위조 장치 탐지 및 진짜 장치 식별 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 무선 주파수 지문 인식(RFF)은 신호 생성 과정에 관련된 하드웨어 구성 요소의 고유한 결함을 활용하여 장치를 인증하는 효과적인 솔루션으로 발전하였다.

Method: 소프트맥스 확률 임계값을 사용하여 악의적인 장치를 탐지하고 진짜 장치를 식별하는 CNN 기반 프레임워크를 제안한다. GAN을 훈련시켜 진짜 장치의 RF 특성을 모방하는 공격 시나리오를 구현한다.

Result: 제안된 접근 방식을 검증하기 위해 10개의 서로 다른 ADALM-PLUTO 소프트웨어 정의 라디오(SDR)에서 수집된 IQ 샘플을 사용하였다. 이 중 7개 장치는 진짜, 2개는 악의적, 1개는 임계값 결정 검증용으로 사용되었다.

Conclusion: 이 연구는 CNN 기반 방법이 위조 장치 탐지 및 진짜 장치 식별에 효과적임을 보여준다.

Abstract: Radio Frequency Fingerprinting (RFF) has evolved as an effective solution for
authenticating devices by leveraging the unique imperfections in hardware
components involved in the signal generation process. In this work, we propose
a Convolutional Neural Network (CNN) based framework for detecting rogue
devices and identifying genuine ones using softmax probability thresholding. We
emulate an attack scenario in which adversaries attempt to mimic the RF
characteristics of genuine devices by training a Generative Adversarial Network
(GAN) using In-phase and Quadrature (IQ) samples from genuine devices. The
proposed approach is verified using IQ samples collected from ten different
ADALM-PLUTO Software Defined Radios (SDRs), with seven devices considered
genuine, two as rogue, and one used for validation to determine the threshold.

</details>


### [50] [CREST-Search: Comprehensive Red-teaming for Evaluating Safety Threats in Large Language Models Powered by Web Search](https://arxiv.org/abs/2510.09689)
*Haoran Ou,Kangjie Chen,Xingshuo Han,Gelei Deng,Jie Zhang,Han Qiu,Tianwei Zhang*

Main category: cs.CR

TL;DR: 본 연구에서는 CREST-Search라는 프레임워크를 통해 웹 검색과 통합된 대형 언어 모델(LLM)의 위험을 체계적으로 분석하고 검증한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델은 대화, 요약 및 질문 응답 등에서 뛰어난 성능을 보이지만, 전문 분야와 변화하는 사실에 적응하는 데 어려움을 겪는다.

Method: CREST-Search는 문맥 내 학습을 통해 적대적 쿼리를 생성하고 반복적인 피드백을 통해 이를 다듬는 방법으로 검색 기능이 있는 모델의 복잡한 작업 흐름을 처리한다.

Result: CREST-Search는 현대 웹 증강 대형 언어 모델의 안전 필터를 효과적으로 우회하고 취약점을 드러내는 실험 결과를 보였다.

Conclusion: 신뢰할 수 있는 배포를 보장하기 위해 전문화된 방어책이 필요함을 강조한다.

Abstract: Large Language Models (LLMs) excel at tasks such as dialogue, summarization,
and question answering, yet they struggle to adapt to specialized domains and
evolving facts. To overcome this, web search has been integrated into LLMs,
allowing real-time access to online content. However, this connection magnifies
safety risks, as adversarial prompts combined with untrusted sources can cause
severe vulnerabilities. We investigate red teaming for LLMs with web search and
present CREST-Search, a framework that systematically exposes risks in such
systems. Unlike existing methods for standalone LLMs, CREST-Search addresses
the complex workflow of search-enabled models by generating adversarial queries
with in-context learning and refining them through iterative feedback. We
further construct WebSearch-Harm, a search-specific dataset to fine-tune LLMs
into efficient red-teaming agents. Experiments show that CREST-Search
effectively bypasses safety filters and reveals vulnerabilities in modern
web-augmented LLMs, underscoring the need for specialized defenses to ensure
trustworthy deployment.

</details>


### [51] [HTTP Request Synchronization Defeats Discrepancy Attacks](https://arxiv.org/abs/2510.09952)
*Cem Topcuoglu,Kaan Onarlioglu,Steven Sprecher,Engin Kirda*

Main category: cs.CR

TL;DR: HTTP 요청의 불일치를 이용한 공격에 대한 종합적인 방어책을 제안함.


<details>
  <summary>Details</summary>
Motivation: 웹 응용 프로그램 아키텍처의 복잡성으로 인해 공격자들이 요청 처리의 불일치를 악용할 수 있음.

Method: HTTP 요청 동기화라는 새로운 방어 기법을 제안하며, 각 요청에 완전한 처리 이력을 추가하는 방식으로 작동.

Result: 5가지 인기 있는 프록시 기술에 대해 구현하여 실용성을 입증함.

Conclusion: 이 방어 메커니즘은 요청 처리의 일관성을 보장하여 불일치 공격을 제거할 수 있음.

Abstract: Contemporary web application architectures involve many layers of proxy
services that process traffic. Due to the complexity of HTTP and vendor design
decisions, these proxies sometimes process a given request in different ways.
Attackers can exploit these processing discrepancies to launch damaging attacks
including web cache poisoning and request smuggling. Discrepancy attacks are
surging, yet, there exists no systemic defense.
  In this work, we propose the first comprehensive defense to address this
problem, called HTTP Request Synchronization. Our scheme uses standard HTTP
extension mechanisms to augment each request with a complete processing
history. It propagates this context through the traffic path detailing how each
server hop has processed said request. Using this history, every proxy server
can validate that their processing is consistent with all previous hops,
eliminating discrepancy attacks. We implement our scheme for 5 popular proxy
technologies, Apache, NGINX, HAProxy, Varnish, and Cloudflare, demonstrating
its practical impact.

</details>


### [52] [SecureWebArena: A Holistic Security Evaluation Benchmark for LVLM-based Web Agents](https://arxiv.org/abs/2510.10073)
*Zonghao Ying,Yangguang Shao,Jianle Gan,Gan Xu,Junjie Shen,Wenxin Zhang,Quanchen Zou,Junzheng Shi,Zhenfei Yin,Mingchuan Zhang,Aishan Liu,Xianglong Liu*

Main category: cs.CR

TL;DR: 본 논문은 LVLM 기반 웹 에이전트의 보안을 평가하기 위한 최초의 포괄적인 벤치마크인 	ool{}을 제안하며, 다양한 작업과 공격 설정을 포함한 2,970개의 고품질 경로를 제시하고 보안 취약성을 광범위하게 포착합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 환경에서 LVLM 기반 웹 에이전트는 심각한 보안 위험에 직면하고 있습니다.

Method: 	ool{}는 여섯 개의 시뮬레이션된 웹 환경과 다양한 작업 및 공격 설정을 포함한 평가 세트를 제공합니다. 또한 내부 추론, 행동 궤적, 작업 결과라는 세 가지 차원을 분석하는 다층 평가 프로토콜을 도입합니다.

Result: 모든 테스트된 에이전트는 미세한 적대적 조작에 대해 일관되게 취약하며, 모델 전문화와 보안 사이의 중요한 균형을 드러냅니다.

Conclusion: 이 벤치마크는 현대 LVLM 기반 웹 에이전트의 보안 문제에 대한 실증적 통찰력을 제공하고 신뢰할 수 있는 웹 에이전트 배포를 위한 기초를 마련합니다.

Abstract: Large vision-language model (LVLM)-based web agents are emerging as powerful
tools for automating complex online tasks. However, when deployed in real-world
environments, they face serious security risks, motivating the design of
security evaluation benchmarks. Existing benchmarks provide only partial
coverage, typically restricted to narrow scenarios such as user-level prompt
manipulation, and thus fail to capture the broad range of agent
vulnerabilities. To address this gap, we present \tool{}, the first holistic
benchmark for evaluating the security of LVLM-based web agents. \tool{} first
introduces a unified evaluation suite comprising six simulated but realistic
web environments (\eg, e-commerce platforms, community forums) and includes
2,970 high-quality trajectories spanning diverse tasks and attack settings. The
suite defines a structured taxonomy of six attack vectors spanning both
user-level and environment-level manipulations. In addition, we introduce a
multi-layered evaluation protocol that analyzes agent failures across three
critical dimensions: internal reasoning, behavioral trajectory, and task
outcome, facilitating a fine-grained risk analysis that goes far beyond simple
success metrics. Using this benchmark, we conduct large-scale experiments on 9
representative LVLMs, which fall into three categories: general-purpose,
agent-specialized, and GUI-grounded. Our results show that all tested agents
are consistently vulnerable to subtle adversarial manipulations and reveal
critical trade-offs between model specialization and security. By providing (1)
a comprehensive benchmark suite with diverse environments and a multi-layered
evaluation pipeline, and (2) empirical insights into the security challenges of
modern LVLM-based web agents, \tool{} establishes a foundation for advancing
trustworthy web agent deployment.

</details>


### [53] [Post-Quantum Cryptography and Quantum-Safe Security: A Comprehensive Survey](https://arxiv.org/abs/2510.10436)
*Gaurab Chhetri,Shriyank Somvanshi,Pavan Hebli,Shamyo Brotee,Subasish Das*

Main category: cs.CR

TL;DR: 이 조사 논문은 포스트 양자 암호(PQC)의 기초부터 실제 적용까지를 포괄적으로 다루며, 다양한 암호화 기술의 분류와 성능, 통신 비용, 프로토콜 통합 등 여러 측면을 분석한다.


<details>
  <summary>Details</summary>
Motivation: NIST가 ML-KEM, ML-DSA 및 SLH-DSA에 대한 표준을 최종 확정하면서 PQC가 평가 단계에서 배포 단계로 나아가고 있다.

Method: 격자, 코드, 해시, 다변량, 동형암호, MPC-머리 의 가족들에 대한 분류법을 개발하고, 성능 및 통신 비용을 비교하며 하드웨어 가속화와 구현 보안을 검토한다.

Result: 암호화 기술의 보안 가정, 암호 해독, 표준화 상태를 요약하고, 다양한 환경에서의 배치 가능성을 조사한다.

Conclusion: 파라미터 기민성, 누출에 강한 구현, 도메인 특정 롤아웃 플레이북과 같은 개방된 문제를 결론으로 제시한다.

Abstract: Post-quantum cryptography (PQC) is moving from evaluation to deployment as
NIST finalizes standards for ML-KEM, ML-DSA, and SLH-DSA. This survey maps the
space from foundations to practice. We first develop a taxonomy across
lattice-, code-, hash-, multivariate-, isogeny-, and MPC-in-the-Head families,
summarizing security assumptions, cryptanalysis, and standardization status. We
then compare performance and communication costs using representative,
implementation-grounded measurements, and review hardware acceleration (AVX2,
FPGA/ASIC) and implementation security with a focus on side-channel resistance.
Building upward, we examine protocol integration (TLS, DNSSEC), PKI and
certificate hygiene, and deployment in constrained and high-assurance
environments (IoT, cloud, finance, blockchain). We also discuss complementarity
with quantum technologies (QKD, QRNGs) and the limits of near-term quantum
computing. Throughout, we emphasize crypto-agility, hybrid migration, and
evidence-based guidance for operators. We conclude with open problems spanning
parameter agility, leakage-resilient implementations, and domain-specific
rollout playbooks. This survey aims to be a practical reference for researchers
and practitioners planning quantum-safe systems, bridging standards,
engineering, and operations.

</details>


### [54] [TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models](https://arxiv.org/abs/2510.10932)
*Zonghuan Xu,Xiang Zheng,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CR

TL;DR: VLA 모델의 백도어 공격의 취약성을 연구하고, 이를 위한 TabVLA 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: VLA 모델의 증가하는 배치로 인한 백도어 공격의 안전 위협 증대.

Method: TabVLA라는 새로운 프레임워크를 통해 블랙박스 미세조정을 통한 타겟 백도어 공격을 가능하게 함.

Result: OpenVLA-7B를 활용한 실험으로 비전 채널이 주요 공격 면계임을 확인하고, 적은 오염으로 성공적인 공격이 가능함을 보여줌.

Conclusion: VLA 모델의 타겟 백도어 조작에 대한 취약성을 강조하고, 더 발전된 방어가 필요함을 주장함.

Abstract: With the growing deployment of Vision-Language-Action (VLA) models in
real-world embodied AI systems, their increasing vulnerability to backdoor
attacks poses a serious safety threat. A backdoored VLA agent can be covertly
triggered by a pre-injected backdoor to execute adversarial actions,
potentially causing system failures or even physical harm. Although backdoor
attacks on VLA models have been explored, prior work has focused only on
untargeted attacks, leaving the more practically threatening scenario of
targeted manipulation unexamined. In this paper, we study targeted backdoor
attacks on VLA models and introduce TabVLA, a novel framework that enables such
attacks via black-box fine-tuning. TabVLA explores two deployment-relevant
inference-time threat models: input-stream editing and in-scene triggering. It
formulates poisoned data generation as an optimization problem to improve
attack effectivess. Experiments with OpenVLA-7B on the LIBERO benchmark reveal
that the vision channel is the principal attack surface: targeted backdoors
succeed with minimal poisoning, remain robust across variations in trigger
design, and are degraded only by positional mismatches between fine-tuning and
inference triggers. We also investigate a potential detection-based defense
against TabVLA, which reconstructs latent visual triggers from the input stream
to flag activation-conditioned backdoor samples. Our work highlights the
vulnerability of VLA models to targeted backdoor manipulation and underscores
the need for more advanced defenses.

</details>


### [55] [Secret-Protected Evolution for Differentially Private Synthetic Text Generation](https://arxiv.org/abs/2510.10990)
*Tianze Wang,Zhaoyu Chen,Jian Du,Yingtai Xiao,Linjun Zhang,Qiang Yan*

Main category: cs.CR

TL;DR: 본 논문에서는 비공식적인 내용을 지나치게 보호하는 기존의 차등 프라이버시 합성 텍스트 생성의 단점을 해결하기 위해, 비밀 보호 진화(SecPE)라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 우수한 유용성과 낮은 계산 복잡성을 동시에 보장합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 세계에서 고품질 텍스트는 개인 정보 보호 문제로 자유롭게 사용할 수 없기 때문에, 개인 정보를 보호하면서 높은 유용성을 갖는 합성 데이터를 생성할 필요가 있습니다.

Method: 비밀 보호 진화(SecPE) 프레임워크는 비밀 정보를 인식하는 보호 기능을 확장하여 차등 프라이버시 합성을 발전시킵니다.

Result: SecPE는 OpenReview, PubMed, Yelp 벤치마크에서 기존 GDP 기반 방법보다 낮은 Fréchet Inception Distance(FID)와 더 높은 다운스트림 작업 정확도를 달성했습니다.

Conclusion: 비밀 정보를 인식하는 보장은 보다 실용적이고 효과적인 프라이버시 보호 합성 텍스트 생성을 가능하게 합니다.

Abstract: Text data has become extremely valuable on large language models (LLMs) and
even lead to general artificial intelligence (AGI). A lot of high-quality text
in the real world is private and cannot be freely used due to privacy concerns.
Therefore, differentially private (DP) synthetic text generation has been
proposed, aiming to produce high-utility synthetic data while protecting
sensitive information. However, existing DP synthetic text generation imposes
uniform guarantees that often overprotect non-sensitive content, resulting in
substantial utility loss and computational overhead. Therefore, we propose
Secret-Protected Evolution (SecPE), a novel framework that extends private
evolution with secret-aware protection. Theoretically, we show that SecPE
satisfies $(\mathrm{p}, \mathrm{r})$-secret protection, constituting a
relaxation of Gaussian DP that enables tighter utility-privacy trade-offs,
while also substantially reducing computational complexity relative to baseline
methods. Empirically, across the OpenReview, PubMed, and Yelp benchmarks, SecPE
consistently achieves lower Fr\'echet Inception Distance (FID) and higher
downstream task accuracy than GDP-based Aug-PE baselines, while requiring less
noise to attain the same level of protection. Our results highlight that
secret-aware guarantees can unlock more practical and effective
privacy-preserving synthetic text generation.

</details>


### [56] [TraceAegis: Securing LLM-Based Agents via Hierarchical and Behavioral Anomaly Detection](https://arxiv.org/abs/2510.11203)
*Jiahao Liu,Bonan Ruan,Xianglin Yang,Zhiwei Lin,Yan Liu,Yang Wang,Tao Wei,Zhenkai Liang*

Main category: cs.CR

TL;DR: TraceAegis는 에이전트 실행 추적을 활용하여 잠재적인 비정상 동작을 감지하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트는 실제 애플리케이션에서 뛰어난 적응력을 보여주지만 다양한 공격에 취약하다.

Method: TraceAegis는 에이전트의 실행 추적을 활용하여 비정상 동작을 감지하기 위해 계층 구조를 구축하여 안정적인 실행 단위를 추상화한다.

Result: 시험 결과, TraceAegis는 TraceAegis-Bench에서 비정상 동작의 대부분을 성공적으로 식별하였다.

Conclusion: TraceAegis는 안전성을 높이기 위해 비정상 동작을 효과적으로 탐지하는 역할을 한다.

Abstract: LLM-based agents have demonstrated promising adaptability in real-world
applications. However, these agents remain vulnerable to a wide range of
attacks, such as tool poisoning and malicious instructions, that compromise
their execution flow and can lead to serious consequences like data breaches
and financial loss. Existing studies typically attempt to mitigate such
anomalies by predefining specific rules and enforcing them at runtime to
enhance safety. Yet, designing comprehensive rules is difficult, requiring
extensive manual effort and still leaving gaps that result in false negatives.
As agent systems evolve into complex software systems, we take inspiration from
software system security and propose TraceAegis, a provenance-based analysis
framework that leverages agent execution traces to detect potential anomalies.
In particular, TraceAegis constructs a hierarchical structure to abstract
stable execution units that characterize normal agent behaviors. These units
are then summarized into constrained behavioral rules that specify the
conditions necessary to complete a task. By validating execution traces against
both hierarchical and behavioral constraints, TraceAegis is able to effectively
detect abnormal behaviors. To evaluate the effectiveness of TraceAegis, we
introduce TraceAegis-Bench, a dataset covering two representative scenarios:
healthcare and corporate procurement. Each scenario includes 1,300 benign
behaviors and 300 abnormal behaviors, where the anomalies either violate the
agent's execution order or break the semantic consistency of its execution
sequence. Experimental results demonstrate that TraceAegis achieves strong
performance on TraceAegis-Bench, successfully identifying the majority of
abnormal behaviors.

</details>


### [57] [Collaborative Shadows: Distributed Backdoor Attacks in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2510.11246)
*Pengyu Zhu,Lijun Li,Yaxing Lyu,Li Sun,Sen Su,Jing Shao*

Main category: cs.CR

TL;DR: 대규모 다중 에이전트 시스템의 백도어 공격 안전성을 탐구한 연구로, 협업을 통해 새로운 공격 표면을 생성하는 분산 백도어 공격을 소개한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 다중 에이전트 시스템의 백도어 공격 안전성이 충분히 연구되지 않았기 때문이다.

Method: 백도어를 여러 개의 분산 공격 프리미티브로 분해하고, 이들이 특정 순서로 협업할 때 전체 백도어를 활성화하도록 설계하였다.

Result: 공격 성공률이 95%를 초과하였으며, 일반 작업 성능 저하 없이 수행되었다.

Conclusion: 이 연구는 에이전트 협업을 활용한 새로운 백도어 공격 표면을 드러내며, 다중 에이전트 보호의 필요성을 강조한다.

Abstract: LLM-based multi-agent systems (MAS) demonstrate increasing integration into
next-generation applications, but their safety in backdoor attacks remains
largely underexplored. However, existing research has focused exclusively on
single-agent backdoor attacks, overlooking the novel attack surfaces introduced
by agent collaboration in MAS. To bridge this gap, we present the first
Distributed Backdoor Attack tailored to MAS. We decompose the backdoor into
multiple distributed attack primitives that are embedded within MAS tools.
These primitives remain dormant individually but collectively activate only
when agents collaborate in a specific sequence, thereby assembling the full
backdoor to execute targeted attacks such as data exfiltration. To fully assess
this threat, we introduce a benchmark for multi-role collaborative tasks and a
sandboxed framework to evaluate. Extensive experiments demonstrate that our
attack achieves an attack success rate exceeding 95% without degrading
performance on benign tasks. This work exposes novel backdoor attack surfaces
that exploit agent collaboration, underscoring the need to move beyond
single-agent protection. Code and benchmark are available at
https://github.com/whfeLingYu/Distributed-Backdoor-Attacks-in-MAS.

</details>


### [58] [Large Language Models Are Effective Code Watermarkers](https://arxiv.org/abs/2510.11251)
*Rui Xu,Jiawei Chen,Zhaoxia Yin,Cong Kong,Xinpeng Zhang*

Main category: cs.CR

TL;DR: CodeMark-LLM은 의미를 손상시키지 않고 소스 코드에 워터마크를 삽입하는 LLM 기반의 워터마킹 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델과 오픈 소스 코드의 확산으로 인한 소스 코드의 배포 및 귀속에 관한 윤리적 및 보안 문제가 대두되고 있습니다.

Method: CodeMark-LLM은 기능 보존 변환을 사용하여 워터마크 비트를 인코딩하는 의미적 일관성 임베딩 모듈과 원본 코드와 워터마크가 적용된 코드를 비교하여 변환을 식별하는 차별적 비교 추출 모듈로 구성됩니다.

Result: 다양한 프로그래밍 언어와 공격 시나리오를 통한 대규모 실험을 통해 CodeMark-LLM의 강건성, 효과성 및 확장성을 입증했습니다.

Conclusion: CodeMark-LLM은 LLM의 교차 언어 일반화 능력을 활용하여 언어 특정 엔지니어링 및 훈련 파이프라인을 피합니다.

Abstract: The widespread use of large language models (LLMs) and open-source code has
raised ethical and security concerns regarding the distribution and attribution
of source code, including unauthorized redistribution, license violations, and
misuse of code for malicious purposes. Watermarking has emerged as a promising
solution for source attribution, but existing techniques rely heavily on
hand-crafted transformation rules, abstract syntax tree (AST) manipulation, or
task-specific training, limiting their scalability and generality across
languages. Moreover, their robustness against attacks remains limited. To
address these limitations, we propose CodeMark-LLM, an LLM-driven watermarking
framework that embeds watermark into source code without compromising its
semantics or readability. CodeMark-LLM consists of two core components: (i)
Semantically Consistent Embedding module that applies functionality-preserving
transformations to encode watermark bits, and (ii) Differential Comparison
Extraction module that identifies the applied transformations by comparing the
original and watermarked code. Leveraging the cross-lingual generalization
ability of LLM, CodeMark-LLM avoids language-specific engineering and training
pipelines. Extensive experiments across diverse programming languages and
attack scenarios demonstrate its robustness, effectiveness, and scalability.

</details>


### [59] [TDADL-IE: A Deep Learning-Driven Cryptographic Architecture for Medical Image Security](https://arxiv.org/abs/2510.11301)
*Junhua Zhou,Quanjun Li,Weixuan Li,Guang Yu,Yihua Shao,Yihang Dong,Mengqian Wang,Zimeng Li,Changwei Gong,Xuhang Chen*

Main category: cs.CR

TL;DR: 이 논문은 디지털 의료 이미징의 보안을 강화하기 위해 새로운 암호화 시스템 TDADL-IE를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 의료 이미징의 발전으로 인해 원격 진료 및 클라우드 저장소에서 환자 데이터 보호를 위한 강력한 암호화가 필요하다.

Method: LSTM 네트워크를 이용한 향상된 혼돈 생성기와 새로운 3차원 확산 알고리즘(TDA)을 결합하여 이미지를 암호화하는 TDADL-IE 시스템을 제시한다.

Result: TDADL-IE는 다양한 크기의 이미지에 적응 가능하며 여러 보안 위협에 대한 효과가 실험을 통해 확인되었다.

Conclusion: 제안된 시스템은 기존의 방법에 비해 향상된 보안성을 제공한다.

Abstract: The rise of digital medical imaging, like MRI and CT, demands strong
encryption to protect patient data in telemedicine and cloud storage. Chaotic
systems are popular for image encryption due to their sensitivity and unique
characteristics, but existing methods often lack sufficient security. This
paper presents the Three-dimensional Diffusion Algorithm and Deep Learning
Image Encryption system (TDADL-IE), built on three key elements. First, we
propose an enhanced chaotic generator using an LSTM network with a 1D-Sine
Quadratic Chaotic Map (1D-SQCM) for better pseudorandom sequence generation.
Next, a new three-dimensional diffusion algorithm (TDA) is applied to encrypt
permuted images. TDADL-IE is versatile for images of any size. Experiments
confirm its effectiveness against various security threats. The code is
available at
\href{https://github.com/QuincyQAQ/TDADL-IE}{https://github.com/QuincyQAQ/TDADL-IE}.

</details>


### [60] [Uncertainty-Aware, Risk-Adaptive Access Control for Agentic Systems using an LLM-Judged TBAC Model](https://arxiv.org/abs/2510.11414)
*Charles Fleming,Ashish Kundu,Ramana Kompella*

Main category: cs.CR

TL;DR: 이 논문은 사전 정의된 정책이 없는 새로운 작업에 대한 접근 제어를 관리하는 것과 관련된 보안 문제를 해결하기 위해, 대형 언어 모델(LLM)을 활용한 향상된 보안 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기업 환경에서 자율 AI 에이전트의 확산으로 인해 미리 정의된 정책이 없는 새로운 작업에 대한 접근 제어 관리가 중요한 보안 문제로 대두되고 있습니다.

Method: 이 논문은 LLM을 자율적이고 위험 인식 가능한 판단자로 활용하여, 작업 기반 접근 제어(TBAC) 모델을 확장하는 보안 프레임워크를 도입합니다.

Result: 에이전트가 새로운 작업을 제안할 때 LLM 판단자는 적시 정책을 종합화하고 작업에 대한 복합 위험 점수를 계산하여 자체 추론의 불확실성 추정도 수행합니다. 위험이 높거나 불확실성이 높은 요청은 인적 승인을 요구하는 등 더 엄격한 제어를 촉발합니다.

Conclusion: 이외부 위험과 내부 신뢰의 이중 고려는 모델이 최소 권한 원칙의 더 강력하고 적응적인 버전을 시행할 수 있게 하여, 더 안전하고 신뢰할 수 있는 자율 시스템으로 나아가는 길을 열어줍니다.

Abstract: The proliferation of autonomous AI agents within enterprise environments
introduces a critical security challenge: managing access control for emergent,
novel tasks for which no predefined policies exist. This paper introduces an
advanced security framework that extends the Task-Based Access Control (TBAC)
model by using a Large Language Model (LLM) as an autonomous, risk-aware judge.
This model makes access control decisions not only based on an agent's intent
but also by explicitly considering the inherent \textbf{risk associated with
target resources} and the LLM's own \textbf{model uncertainty} in its
decision-making process. When an agent proposes a novel task, the LLM judge
synthesizes a just-in-time policy while also computing a composite risk score
for the task and an uncertainty estimate for its own reasoning. High-risk or
high-uncertainty requests trigger more stringent controls, such as requiring
human approval. This dual consideration of external risk and internal
confidence allows the model to enforce a more robust and adaptive version of
the principle of least privilege, paving the way for safer and more trustworthy
autonomous systems.

</details>


### [61] [Bag of Tricks for Subverting Reasoning-based Safety Guardrails](https://arxiv.org/abs/2510.11570)
*Shuo Chen,Zhen Han,Haokun Chen,Bailan He,Shengyun Si,Jingpei Wu,Philip Torr,Volker Tresp,Jindong Gu*

Main category: cs.CR

TL;DR: 최근의 추론 기반 안전 가드레일은 대규모 추론 모델에 대한 방어에서 강력한 성과를 보였으나, 미세한 조작에 취약함을 발견하였다.


<details>
  <summary>Details</summary>
Motivation: 대규모 추론 모델(LRMs)의 사용자 입력 안전성을 평가하기 위한 강력한 가드레일의 필요성.

Method: 입력 프롬프트에 몇 가지 템플릿 토큰을 추가하여 가드레일을 우회할 수 있는 공격 방법을 소개.

Result: 90% 이상의 공격 성공률을 기록하며, 다양한 오픈 소스 LRM에서 이러한 취약성이 체계적임을 확인하였다.

Conclusion: 악의적 오용을 방지하기 위해 더욱 강력한 정렬 기술의 필요성이 대두된다.

Abstract: Recent reasoning-based safety guardrails for Large Reasoning Models (LRMs),
such as deliberative alignment, have shown strong defense against jailbreak
attacks. By leveraging LRMs' reasoning ability, these guardrails help the
models to assess the safety of user inputs before generating final responses.
The powerful reasoning ability can analyze the intention of the input query and
will refuse to assist once it detects the harmful intent hidden by the
jailbreak methods. Such guardrails have shown a significant boost in defense,
such as the near-perfect refusal rates on the open-source gpt-oss series.
Unfortunately, we find that these powerful reasoning-based guardrails can be
extremely vulnerable to subtle manipulation of the input prompts, and once
hijacked, can lead to even more harmful results. Specifically, we first uncover
a surprisingly fragile aspect of these guardrails: simply adding a few template
tokens to the input prompt can successfully bypass the seemingly powerful
guardrails and lead to explicit and harmful responses. To explore further, we
introduce a bag of jailbreak methods that subvert the reasoning-based
guardrails. Our attacks span white-, gray-, and black-box settings and range
from effortless template manipulations to fully automated optimization. Along
with the potential for scalable implementation, these methods also achieve
alarmingly high attack success rates (e.g., exceeding 90% across 5 different
benchmarks on gpt-oss series on both local host models and online API
services). Evaluations across various leading open-source LRMs confirm that
these vulnerabilities are systemic, underscoring the urgent need for stronger
alignment techniques for open-sourced LRMs to prevent malicious misuse. Code is
open-sourced at https://chenxshuo.github.io/bag-of-tricks.

</details>


### [62] [PACEbench: A Framework for Evaluating Practical AI Cyber-Exploitation Capabilities](https://arxiv.org/abs/2510.11688)
*Zicheng Liu,Lige Huang,Jie Zhang,Dongrui Liu,Yuan Tian,Jing Shao*

Main category: cs.CR

TL;DR: 대형 언어 모델의 자율성이 증가함에 따라, 사이버 공격에서의 잠재력을 평가하기 위한 철저한 검토가 필요하다. 기존 벤치마크는 현실 세계의 복잡성을 결여하고 있어 LLM의 사이버 보안 능력을 정확하게 평가할 수 없다. 이 문제를 해결하기 위해, 우리는 현실적인 취약점 난이도, 환경 복잡성 및 사이버 방어 원칙에 기반한 실용적인 AI 사이버 악용 벤치마크인 PACEbench를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 자율성 증가에 따른 사이버 공격 지원 가능성을 평가하기 위해.

Method: PACEbench라는 벤치마크를 통해 단일, 혼합, 연쇄 및 방어 취약점 악용 시나리오를 다루고, PACEagent라는 새로운 에이전트를 제안하여 다단계 탐색, 분석, 악용을 지원한다.

Result: 7개의 최신 LLM을 사용한 광범위한 실험 결과, 현재 모델들이 복잡한 사이버 시나리오에서 어려움을 겪고 있으며, 방어를 우회할 수 없음이 보여졌다.

Conclusion: 현재 모델들은 아직 일반화된 사이버 공격 위협을 제기하지 않지만, 향후 모델의 신뢰할 수 있는 개발을 위한 강력한 벤치마크를 제공한다.

Abstract: The increasing autonomy of Large Language Models (LLMs) necessitates a
rigorous evaluation of their potential to aid in cyber offense. Existing
benchmarks often lack real-world complexity and are thus unable to accurately
assess LLMs' cybersecurity capabilities. To address this gap, we introduce
PACEbench, a practical AI cyber-exploitation benchmark built on the principles
of realistic vulnerability difficulty, environmental complexity, and cyber
defenses. Specifically, PACEbench comprises four scenarios spanning single,
blended, chained, and defense vulnerability exploitations. To handle these
complex challenges, we propose PACEagent, a novel agent that emulates human
penetration testers by supporting multi-phase reconnaissance, analysis, and
exploitation. Extensive experiments with seven frontier LLMs demonstrate that
current models struggle with complex cyber scenarios, and none can bypass
defenses. These findings suggest that current models do not yet pose a
generalized cyber offense threat. Nonetheless, our work provides a robust
benchmark to guide the trustworthy development of future models.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [63] [A Hybrid Agent-Based and System Dynamics Framework for Modelling Project Execution and Technology Maturity in Early-Stage R&D](https://arxiv.org/abs/2510.09688)
*R. W. S. Pessoa,M. H. Næss,J. C. Bijos,C. M. Rebello,D. Colombo,L. Schnitman,I. B. R. Nogueira*

Main category: cs.MA

TL;DR: 이 연구는 R&D 프로젝트의 기술 성숙도 진화를 예측하기 위한 하이브리드 접근 방식을 제시하며, 사례로 석유 및 가스 산업을 사용한다.


<details>
  <summary>Details</summary>
Motivation: R&D 프로젝트에서 기술 성숙도를 예측하는 데 있어 기존 방법의 한계를 극복하고 보다 정교한 분석을 제공할 수 있는 방안을 모색한다.

Method: 시스템 다이내믹스(SD)와 에이전트 기반 모델링(ABM)을 통합하여 불확실성을 캡처하는 다수준 프레임워크를 개발한다.

Result: 기본 사례에서는 15개의 병렬 작업이 156주 동안 진행된 초기 단계 혁신 프로젝트를 분석하여, 재작업 기간이 88% 감소함을 보여준다.

Conclusion: 모델 출력과 프레임워크는 전문가의 이해와 일치하며, 자원 할당, 일정 효율성 및 기술 성숙도 진전을 분석하기 위한 정량적 도구로서의 유효성을 지원한다.

Abstract: This paper presents a hybrid approach to predict the evolution of
technological maturity in R and D projects, using the oil and gas sector as an
example. Integrating System Dynamics (SD) and Agent Based Modelling (ABM)
allows the proposed multi level framework to capture uncertainties in work
effort, team size, and project duration, which influence technological
progress. While AB SD hybrid models are established in other fields, their use
in R and D remains limited. The model combines system level feedback structures
governing work phases, rework cycles, and duration with decentralised agents
such as team members, tasks, and controllers, whose interactions generate
emergent project dynamics. A base case scenario analysed early stage innovation
projects with 15 parallel tasks over 156 weeks. A comparative sequential
scenario showed an 88 percent reduction in rework duration. A second scenario
assessed mixed parallel sequential task structures with varying team sizes. In
parallel configurations, increasing team size reduced project duration and
improved task completion, with optimal results for teams of four to five
members. These findings align with empirical evidence showing that moderate
team expansion enhances coordination efficiency without excessive communication
overhead. However, larger teams may decrease performance due to communication
complexity and management delays. Overall, the model outputs and framework
align with expert understanding, supporting their validity as quantitative
tools for analysing resource allocation, scheduling efficiency, and technology
maturity progression.

</details>


### [64] [Structured Cooperative Multi-Agent Reinforcement Learning: a Bayesian Network Perspective](https://arxiv.org/abs/2510.09937)
*Shahbaz P Qadri Syed,He Bai*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 강화 학습(MARL)에서 에이전트 간의 결합 정보를 활용하여 효율적인 모델 없는 강화 학습 알고리즘을 개발하는 체계적인 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 다중 에이전트 시스템을 위한 더 효율적이고 확장 가능한 알고리즘에 대한 필요성.

Method: Bayesian 네트워크를 이용해 협력적 MARL 문제를 모델링하고, 각 에이전트가 자신의 로컬 행동 가치 함수를 정확히 추정하는 데 필요한 정보의 서브셋인 가치 의존성 집합을 특성화한다. 가치 의존성 집합을 기반으로 하는 부분 분산 훈련 분산 실행(P-DTDE) 패러다임을 제안한다.

Result: P-DTDE 정책 경량 추정기의 전체 분산이 중앙 집중형 훈련 분산 실행(CTDE) 정책 경량 추정기보다 작다는 것을 이론적으로 입증하고, P-DTDE 스킴을 기반으로 다중 에이전트 정책 경량 정리를 도출하며, 확장 가능한 액터-비평가 알고리즘을 개발하였다.

Conclusion: 제안한 알고리즘의 효율성과 확장성을 다중 창고 자원 할당 및 다중 구역 온도 제어 예제에서 입증하였다. 밀집한 가치 의존성 집합에 대해서는 Bayesian 네트워크의 절단을 기반으로 한 근사화 스킴을 제안하였고, 많은 수의 에이전트가 있는 응용 프로그램에서 정확한 가치 의존성 집합보다 더 빠른 수렴을 달성한다는 것을 실증적으로 보여준다.

Abstract: The empirical success of multi-agent reinforcement learning (MARL) has
motivated the search for more efficient and scalable algorithms for large scale
multi-agent systems. However, existing state-of-the-art algorithms do not fully
exploit inter-agent coupling information to develop MARL algorithms. In this
paper, we propose a systematic approach to leverage structures in the
inter-agent couplings for efficient model-free reinforcement learning. We model
the cooperative MARL problem via a Bayesian network and characterize the subset
of agents, termed as the value dependency set, whose information is required by
each agent to estimate its local action value function exactly. Moreover, we
propose a partially decentralized training decentralized execution (P-DTDE)
paradigm based on the value dependency set. We theoretically establish that the
total variance of our P-DTDE policy gradient estimator is less than the
centralized training decentralized execution (CTDE) policy gradient estimator.
We derive a multi-agent policy gradient theorem based on the P-DTDE scheme and
develop a scalable actor-critic algorithm. We demonstrate the efficiency and
scalability of the proposed algorithm on multi-warehouse resource allocation
and multi-zone temperature control examples. For dense value dependency sets,
we propose an approximation scheme based on truncation of the Bayesian network
and empirically show that it achieves a faster convergence than the exact value
dependence set for applications with a large number of agents.

</details>


### [65] [KG-MAS: Knowledge Graph-Enhanced Multi-Agent Infrastructure for coupling physical and digital robotic environments](https://arxiv.org/abs/2510.10325)
*Walid Abdela*

Main category: cs.MA

TL;DR: KG-MAS는 CPS의 이질성과 복잡성을 해결하기 위해 지식 그래프를 활용한 멀티 에이전트 인프라를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 산업 4.0의 CPS에서 물리적 환경과 디지털 환경의 무결한 통합은 시스템의 이질성과 복잡성으로 인한 중요한 도전을 제시한다.

Method: KG-MAS는 중앙 집중식 지식 그래프를 동적인 공유 월드 모델로 활용하여 멀티 에이전트 시스템의 공통 의미적 기초를 제공한다.

Result: 자율 에이전트는 의사 결정을 위해 KG를 질의하고, 실시간 상태 정보로 KG를 업데이트한다.

Conclusion: KG-MAS는 이질적인 물리적 및 디지털 로봇 환경을 결합하기 위한 강력하고 확장 가능하며 유연한 솔루션을 제공한다.

Abstract: The seamless integration of physical and digital environments in
Cyber-Physical Systems(CPS), particularly within Industry 4.0, presents
significant challenges stemming from system heterogeneity and complexity.
Traditional approaches often rely on rigid, data-centric solutions like
co-simulation frameworks or brittle point-to-point middleware bridges, which
lack the semantic richness and flexibility required for intelligent, autonomous
coordination. This report introduces the Knowledge Graph-Enhanced Multi-Agent
Infrastructure(KG-MAS), as resolution in addressing such limitations. KG-MAS
leverages a centralized Knowledge Graph (KG) as a dynamic, shared world model,
providing a common semantic foundation for a Multi-Agent System(MAS).
Autonomous agents, representing both physical and digital components, query
this KG for decision-making and update it with real-time state information. The
infrastructure features a model-driven architecture which facilitates the
automatic generation of agents from semantic descriptions, thereby simplifying
system extension and maintenance. By abstracting away underlying communication
protocols and providing a unified, intelligent coordination mechanism, KG-MAS
offers a robust, scalable, and flexible solution for coupling heterogeneous
physical and digital robotic environments.

</details>


### [66] [HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication](https://arxiv.org/abs/2510.10611)
*Heng Zhang,Yuling Shi,Xiaodong Gu,Zijian Zhang,Haochen You,Lubin Gan,Yilei Yuan,Jin Huang*

Main category: cs.MA

TL;DR: HyperAgent는 하이퍼그래프 기반 프레임워크로, 통신 토폴로지를 최적화하고 그룹 협력 패턴을 효과적으로 포착하여 에이전트 간의 효율적인 협력을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 기반의 다중 에이전트 시스템의 집단 지능을 향상시키기 위해, 효과적인 통신과 협업 모델링이 필요하다.

Method: HyperAgent는 하이퍼엣지를 사용하여 에이전트 간의 연결을 최적화하고 하이퍼그래프 합성곱 Layer를 통해 정보를 집계한다.

Result: HyperAgent는 GSM8K에서 95.07%의 정확도를 달성하며, 토큰 소비를 25.33% 절감하는 성능을 보여준다.

Conclusion: 하이퍼그래프 기반 최적화가 다중 에이전트 통신에 유망한 가능성을 제공한다.

Abstract: Recent advances in large language model-powered multi-agent systems have
demonstrated remarkable collective intelligence through effective
communication. However, existing approaches face two primary challenges: (i)
\textit{Ineffective group collaboration modeling}, as they rely on pairwise
edge representations in graph structures, limiting their ability to capture
relationships among multiple agents; and (ii) \textit{Limited task-adaptiveness
in communication topology design}, leading to excessive communication cost for
simple tasks and insufficient coordination for complex scenarios. These issues
restrict the scalability and practical deployment of adaptive collaboration
frameworks. To address these challenges, we propose \textbf{HyperAgent}, a
hypergraph-based framework that optimizes communication topologies and
effectively captures group collaboration patterns using direct hyperedge
representations. Unlike edge-based approaches, HyperAgent uses hyperedges to
link multiple agents within the same subtask and employs hypergraph
convolutional layers to achieve one-step information aggregation in
collaboration groups. Additionally, it incorporates a variational autoencoder
framework with sparsity regularization to dynamically adjust hypergraph
topologies based on task complexity. Experiments highlight the superiority of
HyperAgent in both performance and efficiency. For instance, on GSM8K,
HyperAgent achieves 95.07\% accuracy while reducing token consumption by
25.33\%, demonstrating the potential of hypergraph-based optimization for
multi-agent communication.

</details>


### [67] [The Social Cost of Intelligence: Emergence, Propagation, and Amplification of Stereotypical Bias in Multi-Agent Systems](https://arxiv.org/abs/2510.10943)
*Thi-Nhung Nguyen,Linhao Luo,Thuy-Trang Vu,Dinh Phung*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 시스템에서의 편향의 동적 특성을 탐구하고, 편향의 강건성, 전파 및 증폭에 미치는 영향을 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템(MAS)에서의 편향이 새로운 동역학을引き起こ다는 점을 탐구하고자 하였습니다.

Method: 다양한 사회적 맥락을 시뮬레이션하여 에이전트의 행동을 평가하고, 편향 기준에 대한 실험을 통해 MAS와 단일 에이전트 시스템의 차이를 분석하였습니다.

Result: MAS는 일반적으로 단일 에이전트 시스템보다 편향에 덜 강건하며, 중간 그룹 선호를 통해 초기에 편향이 발생하는 경향이 있습니다.

Conclusion: 협력적 및 토론 기반의 의사소통이 편향 증폭을 완화할 수 있으며, 더 강건한 LLM이 시스템의 전반적인 안정성을 개선할 수 있다는 것을 발견했습니다.

Abstract: Bias in large language models (LLMs) remains a persistent challenge,
manifesting in stereotyping and unfair treatment across social groups. While
prior research has primarily focused on individual models, the rise of
multi-agent systems (MAS), where multiple LLMs collaborate and communicate,
introduces new and largely unexplored dynamics in bias emergence and
propagation. In this work, we present a comprehensive study of stereotypical
bias in MAS, examining how internal specialization, underlying LLMs and
inter-agent communication protocols influence bias robustness, propagation, and
amplification. We simulate social contexts where agents represent different
social groups and evaluate system behavior under various interaction and
adversarial scenarios. Experiments on three bias benchmarks reveal that MAS are
generally less robust than single-agent systems, with bias often emerging early
through in-group favoritism. However, cooperative and debate-based
communication can mitigate bias amplification, while more robust underlying
LLMs improve overall system stability. Our findings highlight critical factors
shaping fairness and resilience in multi-agent LLM systems.

</details>


### [68] [Automating Structural Engineering Workflows with Large Language Model Agents](https://arxiv.org/abs/2510.11004)
*Haoran Liang,Yufa Zhou,Mohammad Talebi Kalaleh,Qipei Mei*

Main category: cs.MA

TL;DR: MASSE는 구조 공학을 위한 최초의 다중 에이전트 시스템으로, 대형 언어 모델 기반 에이전트를 실제 공학 워크플로우와 효과적으로 통합합니다.


<details>
  <summary>Details</summary>
Motivation: 구조 공학은 경제에 미치는 영향이 크지만, 전통적으로 정체된 분야로 작업 흐름이 수십 년간 거의 변화하지 않았습니다. 이 분야에 최신 LLM 기술을 적용하여 혁신을 이루고자 합니다.

Method: MASSE는 훈련이 필요 없는 LLM 기반 다중 에이전트 시스템을 사용하여 구조 공학의 대부분의 워크플로우를 자동화합니다.

Result: 현업 환경에서 즉시 배포할 수 있으며, 실제 사례 연구에 대한 종합 검증을 통해 전문가의 작업량을 약 2시간에서 몇 분으로 줄일 수 있음을 보여줍니다.

Conclusion: MASSE는 구조 공학의 신뢰성과 정확성을 높이면서 실용적인 공학 시나리오에서 효율성을 크게 개선합니다.

Abstract: We introduce $\textbf{MASSE}$, the first Multi-Agent System for Structural
Engineering, effectively integrating large language model (LLM)-based agents
with real-world engineering workflows. Structural engineering is a fundamental
yet traditionally stagnant domain, with core workflows remaining largely
unchanged for decades despite its substantial economic impact and global market
size. Recent advancements in LLMs have significantly enhanced their ability to
perform complex reasoning, long-horizon planning, and precise tool utilization
-- capabilities well aligned with structural engineering tasks such as
interpreting design codes, executing load calculations, and verifying
structural capacities. We present a proof-of-concept showing that most
real-world structural engineering workflows can be fully automated through a
training-free LLM-based multi-agent system. MASSE enables immediate deployment
in professional environments, and our comprehensive validation on real-world
case studies demonstrates that it can reduce expert workload from approximately
two hours to mere minutes, while enhancing both reliability and accuracy in
practical engineering scenarios.

</details>


### [69] [A Vision for Access Control in LLM-based Agent Systems](https://arxiv.org/abs/2510.11108)
*Xinfeng Li,Dong Huang,Jie Li,Hongyi Cai,Zhenhong Zhou,Wei Dong,XiaoFeng Wang,Yang Liu*

Main category: cs.MA

TL;DR: LLM 기반 에이전트의 자율성과 맥락 복잡성으로 인해 전통적인 접근 통제 메커니즘이 부족해졌음을 주장하며, 이 논문은 권한 부여의 이분법적 접근에서 정보 흐름 관리를 위한 동적이고 맥락 인식적인 접근으로의 패러다임 전환을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 접근 통제 메커니즘이 LLM 기반 에이전트의 자율성과 복잡성을 다루기에 불충분하다는 점.

Method: Agent Access Control (AAC)이라는 새로운 프레임워크를 도입하여 접근 통제를 정보 흐름 관리의 동적, 맥락 인식 과정으로 재구성한다.

Result: AAC는 다차원 맥락 평가와 적응적 응답 형성을 통해 정보를 관리한다.

Conclusion: 이 연구는 신뢰할 수 있는 에이전트 설계를 위한 미래 연구에 대한 새로운 개념적 관점을 제안한다.

Abstract: The autonomy and contextual complexity of LLM-based agents render traditional
access control (AC) mechanisms insufficient. Static, rule-based systems
designed for predictable environments are fundamentally ill-equipped to manage
the dynamic information flows inherent in agentic interactions. This position
paper argues for a paradigm shift from binary access control to a more
sophisticated model of information governance, positing that the core challenge
is not merely about permission, but about governing the flow of information. We
introduce Agent Access Control (AAC), a novel framework that reframes AC as a
dynamic, context-aware process of information flow governance. AAC operates on
two core modules: (1) multi-dimensional contextual evaluation, which assesses
not just identity but also relationships, scenarios, and norms; and (2)
adaptive response formulation, which moves beyond simple allow/deny decisions
to shape information through redaction, summarization, and paraphrasing. This
vision, powered by a dedicated AC reasoning engine, aims to bridge the gap
between human-like nuanced judgment and scalable Al safety, proposing a new
conceptual lens for future research in trustworthy agent design.

</details>


### [70] [Autonomous vehicles need social awareness to find optima in multi-agent reinforcement learning routing games](https://arxiv.org/abs/2510.11410)
*Anastasia Psarou,Łukasz Gorczyca,Dominik Gaweł,Rafał Kucharski*

Main category: cs.MA

TL;DR: 자율주행차(AV)가 최적 경로 전략을 학습할 때, 이기적인 보상을 넘어서는 것이 교통 시스템의 불안정성을 줄이는 데 효과적임을 보여주며, 특히 주변 비용을 포함한 보상 신호를 도입하여 교육 시간을 단축시킬 수 있음을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 이기적인 자율주행차가 도입되면 교통 시스템이 불안정해질 수 있으며, 그 문제를 해결하는 것이 필요하다.

Method: 주변 비용 행렬을 기반으로 하는 내재적 보상 신호를 도입하여 훈련 시간을 줄이고 더 일관되게 수렴에 도달한다.

Result: 제안한 보상 체계로 훈련된 MARL 알고리즘이 최적의 솔루션에 수렴하는 반면, 기준 알고리즘들은 실패한다.

Conclusion: 사회적 인식(주변 비용 포함)이 미래 도시 시스템의 전체 및 개별 성과를 개선할 수 있음을 보여준다.

Abstract: Previous work has shown that when multiple selfish Autonomous Vehicles (AVs)
are introduced to future cities and start learning optimal routing strategies
using Multi-Agent Reinforcement Learning (MARL), they may destabilize traffic
systems, as they would require a significant amount of time to converge to the
optimal solution, equivalent to years of real-world commuting.
  We demonstrate that moving beyond the selfish component in the reward
significantly relieves this issue. If each AV, apart from minimizing its own
travel time, aims to reduce its impact on the system, this will be beneficial
not only for the system-wide performance but also for each individual player in
this routing game.
  By introducing an intrinsic reward signal based on the marginal cost matrix,
we significantly reduce training time and achieve convergence more reliably.
Marginal cost quantifies the impact of each individual action (route-choice) on
the system (total travel time). Including it as one of the components of the
reward can reduce the degree of non-stationarity by aligning agents'
objectives. Notably, the proposed counterfactual formulation preserves the
system's equilibria and avoids oscillations.
  Our experiments show that training MARL algorithms with our novel reward
formulation enables the agents to converge to the optimal solution, whereas the
baseline algorithms fail to do so. We show these effects in both a toy network
and the real-world network of Saint-Arnoult. Our results optimistically
indicate that social awareness (i.e., including marginal costs in routing
decisions) improves both the system-wide and individual performance of future
urban systems with AVs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [How can we assess human-agent interactions? Case studies in software agent design](https://arxiv.org/abs/2510.09801)
*Valerie Chen,Rohit Malhotra,Xingyao Wang,Juan Michelini,Xuhui Zhou,Aditya Bharat Soni,Hoang H. Tran,Calvin Smith,Ameet Talwalkar,Graham Neubig*

Main category: cs.AI

TL;DR: LLM 기반 에이전트의 인간-에이전트 상호작용 평가를 위한 PULSE 프레임워크를 제안하며, 실제 사용 데이터를 통해 설계 결정이 개발자 만족도에 미치는 영향을 분석하였다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트의 유망한 기술이지만, 모델 선택과 도구 등에서의 결정이 실제 사용에서의 유용성에 큰 영향을 미친다.

Method: PULSE 프레임워크를 통해 사용자 피드백을 수집하고, ML 모델을 훈련하여 사용자 만족도를 예측하며, 인간 만족도 등급과 모델 생성 가상 레이블을 결합하여 결과를 계산한다.

Result: 15,000명 이상의 사용자로부터 수집된 실제 사용 데이터를 기반으로 에이전트 디자인 결정이 개발자 만족도에 미치는 영향을 사례 연구를 통해 분석하였다.

Conclusion: 우리의 프레임워크는 A/B 테스트와 비교하여 신뢰 구간을 40% 줄이며, 실제 결과와 벤치마크 성능 간의 차이를 강조하여 벤치마크 중심 평가의 한계를 드러낸다.

Abstract: LLM-powered agents are both a promising new technology and a source of
complexity, where choices about models, tools, and prompting can affect their
usefulness. While numerous benchmarks measure agent accuracy across domains,
they mostly assume full automation, failing to represent the collaborative
nature of real-world use cases. In this paper, we make two major steps towards
the rigorous assessment of human-agent interactions. First, we propose PULSE, a
framework for more efficient human-centric evaluation of agent designs, which
comprises collecting user feedback, training an ML model to predict user
satisfaction, and computing results by combining human satisfaction ratings
with model-generated pseudo-labels. Second, we deploy the framework on a
large-scale web platform built around the open-source software agent OpenHands,
collecting in-the-wild usage data across over 15k users. We conduct case
studies around how three agent design decisions -- choice of LLM backbone,
planning strategy, and memory mechanisms -- impact developer satisfaction
rates, yielding practical insights for software agent design. We also show how
our framework can lead to more robust conclusions about agent design, reducing
confidence intervals by 40\% compared to a standard A/B test. Finally, we find
substantial discrepancies between in-the-wild results and benchmark performance
(e.g., the anti-correlation between results comparing claude-sonnet-4 and
gpt-5), underscoring the limitations of benchmark-driven evaluation. Our
findings provide guidance for evaluations of LLM agents with humans and
identify opportunities for better agent designs.

</details>


### [72] [Autonomous Agents for Scientific Discovery: Orchestrating Scientists, Language, Code, and Physics](https://arxiv.org/abs/2510.09901)
*Lianhao Zhou,Hongyi Ling,Cong Fu,Yepeng Huang,Michael Sun,Wendi Yu,Xiaoxuan Wang,Xiner Li,Xingyu Su,Junkai Zhang,Xiusi Chen,Chenxing Liang,Xiaofeng Qian,Heng Ji,Wei Wang,Marinka Zitnik,Shuiwang Ji*

Main category: cs.AI

TL;DR: 대규모 언어 모델(LLMs)의 발전으로 과학적 발견의 주기가 변화하고 있으며, 이러한 언어 에이전트는 실험 설계 및 결과 분석을 포함해 과학적 발견을 가속화하는 데 기여하고 있다.


<details>
  <summary>Details</summary>
Motivation: 과학적 발견의 기초로서 컴퓨팅의 역할을 재조명하고, LLM 기반 과학적 에이전트를 통해 발견 과정의 혁신 가능성을 탐구한다.

Method: LLM 기반 언어 에이전트의 현재 방법론을 비판적으로 검토하며 주요 혁신과 실질적인 성과, 제한점들을 강조한다.

Result: 자율 에이전트가 다양한 분야에서 과학적 발견을 가속화할 수 있는 잠재력을 강조하며, 현재의 연구 방법론과 향후 연구 방향을 제시한다.

Conclusion: 보다 강력하고 일반화 가능하며 적응력이 뛰어난 과학적 에이전트를 구축하기 위한 연구 과제를 식별하고, 이를 통해 과학적 발견의 변혁적인 잠재력을 확인한다.

Abstract: Computing has long served as a cornerstone of scientific discovery. Recently,
a paradigm shift has emerged with the rise of large language models (LLMs),
introducing autonomous systems, referred to as agents, that accelerate
discovery across varying levels of autonomy. These language agents provide a
flexible and versatile framework that orchestrates interactions with human
scientists, natural language, computer language and code, and physics. This
paper presents our view and vision of LLM-based scientific agents and their
growing role in transforming the scientific discovery lifecycle, from
hypothesis discovery, experimental design and execution, to result analysis and
refinement. We critically examine current methodologies, emphasizing key
innovations, practical achievements, and outstanding limitations. Additionally,
we identify open research challenges and outline promising directions for
building more robust, generalizable, and adaptive scientific agents. Our
analysis highlights the transformative potential of autonomous agents to
accelerate scientific discovery across diverse domains.

</details>


### [73] [SwarmSys: Decentralized Swarm-Inspired Agents for Scalable and Adaptive Reasoning](https://arxiv.org/abs/2510.10047)
*Ruohao Li,Hongjun Liu,Leyi Zhao,Zisu Li,Jiawei Li,Jiajun Jiang,Linning Xu,Chen Zhao,Mingming Fan,Chen Liang*

Main category: cs.AI

TL;DR: SwarmSys는 분산 다중 에이전트 추론을 위한 폐쇄 루프 프레임워크로, 유충 지능에서 영감을 받아 다중 에이전트의 협업을 확장 가능하고 적응 가능하게 만든다.


<details>
  <summary>Details</summary>
Motivation: 기존의 다중 에이전트 프레임워크는 고정된 역할이나 중앙 집중식 제어에 의존하여 장기적인 추론에서 확장성과 적응성을 제한한다.

Method: SwarmSys는 Explorers, Workers, Validators의 세 가지 전문 역할 간의 반복적인 상호작용을 통해 조정이 이루어지도록 설계되었으며, 적응형 에이전트 및 이벤트 프로필, 임베딩 기반 확률적 매칭, 페로몬 영감을 받은 강화 메커니즘을 통합하여 동적 작업 할당과 자기 조직화 수렴을 지원한다.

Result: SwarmSys는 상징적 추론, 연구 종합, 과학 프로그래밍 작업에서 기준 모델을 지속적으로 초과하여 정확성과 추론 안정성을 모두 향상시켰다.

Conclusion: 이 연구 결과는 유충 영감을 받은 조정이 확장 가능하고 강력하며 적응 가능한 다중 에이전트 추론을 위한 유망한 패러다임임을 강조하며, 조정의 확장이 LLM 지능의 발전에 있어 모델 확장에 필적할 수 있음을 시사한다.

Abstract: Large language model (LLM) agents have shown remarkable reasoning abilities.
However, existing multi-agent frameworks often rely on fixed roles or
centralized control, limiting scalability and adaptability in long-horizon
reasoning. We introduce SwarmSys, a closed-loop framework for distributed
multi-agent reasoning inspired by swarm intelligence. Coordination in SwarmSys
emerges through iterative interactions among three specialized roles,
Explorers, Workers, and Validators, that continuously cycle through
exploration, exploitation, and validation. To enable scalable and adaptive
collaboration, we integrate adaptive agent and event profiles, embedding-based
probabilistic matching, and a pheromone-inspired reinforcement mechanism,
supporting dynamic task allocation and self-organizing convergence without
global supervision. Across symbolic reasoning, research synthesis, and
scientific programming tasks, SwarmSys consistently outperforms baselines,
improving both accuracy and reasoning stability. These findings highlight
swarm-inspired coordination as a promising paradigm for scalable, robust, and
adaptive multi-agent reasoning, suggesting that coordination scaling may rival
model scaling in advancing LLM intelligence.

</details>


### [74] [Agentic Troubleshooting Guide Automation for Incident Management](https://arxiv.org/abs/2510.10074)
*Jiayi Mao,Liqun Li,Yanjie Gao,Zegang Peng,Shilin He,Chaoyun Zhang,Si Qin,Samia Khalid,Qingwei Lin,Saravan Rajmohan,Sitaram Lanka,Dongmei Zhang*

Main category: cs.AI

TL;DR: 이 논문은 대규모 IT 시스템에서의 효과적인 사건 관리를 위해 StepFly라는 새로운 자동화 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 IT 시스템에서의 사건 관리는 문제 해결 가이드(TSG)에 의존하고 있지만, 수작업 실행은 느리고 오류가 발생하기 쉽다.

Method: StepFly는 3단계 워크플로우로 구성되며, 첫 번째 단계에서는 TSG 품질 개선을 지원하는 TSG Mentor 도구를 제공하고, 두 번째 단계에서는 LLM을 사용하여 비구조적 TSG에서 구조화된 실행 DAG를 추출하고 쿼리 준비 플러그인을 생성하며, 세 번째 단계에서는 DAG 기반 스케줄러-실행기 프레임워크를 사용하여 온라인 실행을 수행한다.

Result: StepFly는 실제 TSG 및 사건에서 약 94%의 성공률을 기록하였으며, 기존 방법보다 더 적은 시간과 토큰 소모로 우수한 성능을 발휘했다.

Conclusion: 또한 StepFly는 병렬 가능한 TSG에 대해 32.9%에서 70.4%까지 주목할 만한 실행 시간 단축을 달성했다.

Abstract: Effective incident management in large-scale IT systems relies on
troubleshooting guides (TSGs), but their manual execution is slow and
error-prone. While recent advances in LLMs offer promise for automating
incident management tasks, existing LLM-based solutions lack specialized
support for several key challenges, including managing TSG quality issues,
interpreting complex control flow, handling data-intensive queries, and
exploiting execution parallelism. We first conducted an empirical study on 92
real-world TSGs, and, guided by our findings, we present StepFly, a novel
end-to-end agentic framework for troubleshooting guide automation. Our approach
features a three-stage workflow: the first stage provides a comprehensive guide
together with a tool, TSG Mentor, to assist SREs in improving TSG quality; the
second stage performs offline preprocessing using LLMs to extract structured
execution DAGs from unstructured TSGs and to create dedicated Query Preparation
Plugins (QPPs); and the third stage executes online using a DAG-guided
scheduler-executor framework with a memory system to guarantee correct workflow
and support parallel execution of independent steps. Our empirical evaluation
on a collection of real-world TSGs and incidents demonstrates that StepFly
achieves a ~94% success rate on GPT-4.1, outperforming baselines with less time
and token consumption. Furthermore, it achieves a remarkable execution time
reduction of 32.9% to 70.4% for parallelizable TSGs.

</details>


### [75] [DixitWorld: Evaluating Multimodal Abductive Reasoning in Vision-Language Models with Multi-Agent Dixit Gameplay](https://arxiv.org/abs/2510.10117)
*Yunxiang Mo,Tianshi Zheng,Qing Zong,Jiayu Liu,Baixuan Xu,Yauwai Yim,Chunkit Chan,Jiaxin Bai,Yangqiu Song*

Main category: cs.AI

TL;DR: DixitWorld는 비전-언어 모델의 다중 양식 유추 추론 능력을 평가하기 위한 동적 환경과 정적 벤치를 포함하는 평가 모음이다.


<details>
  <summary>Details</summary>
Motivation: 다중 양식 유추 추론은 지능의 기초이며, 현재 비전-언어 모델의 이 능력에 대한 평가는 대부분 정적이고 단일 에이전트 작업에 국한되어 있다.

Method: DixitWorld는 두 가지 핵심 구성 요소로 구성되어 있다: DixitArena는 다중 에이전트 환경에서 가설 생성과 선택을 평가하고, DixitBench는 효율적이고 통제된 평가를 위한 정적 QA 벤치마크를 제공한다.

Result: DixitArena의 결과는 역할에 따라 구별되는 행동을 보여준다. 작은 오픈소스 모델은 창의적인 스토리텔러로 뛰어난 성능을 보이는 반면, 큰 독점 모델은 청자로서 전체적인 성능이 우수하다.

Conclusion: 다중 양식 유추 추론에서 생성적 창의성과 구별적 이해 사이의 균형을 이루는 것이 비전-언어 에이전트를 개발하기 위한 중요한 도전 과제임을 발견했다.

Abstract: Multimodal abductive reasoning--the generation and selection of explanatory
hypotheses from partial observations--is a cornerstone of intelligence. Current
evaluations of this ability in vision-language models (VLMs) are largely
confined to static, single-agent tasks. Inspired by Dixit, we introduce
DixitWorld, a comprehensive evaluation suite designed to deconstruct this
challenge. DIXITWORLD features two core components: DixitArena, a dynamic,
multi-agent environment that evaluates both hypothesis generation (a
"storyteller" crafting cryptic clues) and hypothesis selection ("listeners"
choosing the target image from decoys) under imperfect information; and
DixitBench, a static QA benchmark that isolates the listener's task for
efficient, controlled evaluation. Results from DixitArena reveal distinct,
role-dependent behaviors: smaller open-source models often excel as creative
storytellers, producing imaginative yet less discriminative clues, whereas
larger proprietary models demonstrate superior overall performance,
particularly as listeners. Performance on DixitBench strongly correlates with
listener results in DixitArena, validating it as a reliable proxy for
hypothesis selection. Our findings reveal a key trade-off between generative
creativity and discriminative understanding in multimodal abductive reasoning,
a central challenge for developing more balanced and capable vision-language
agents.

</details>


### [76] [Don't Just Fine-tune the Agent, Tune the Environment](https://arxiv.org/abs/2510.10197)
*Siyuan Lu,Zechuan Wang,Hongxuan Zhang,Qintong Wu,Leilei Gan,Chenyi Zhuang,Jinjie Gu,Tao Lin*

Main category: cs.AI

TL;DR: 우리는 복잡한 멀티 턴 도구 사용 작업을 위한 새로운 훈련 패러다임인 '환경 조정'을 소개하며, 이를 통해 고품질 훈련 데이터의 부족 문제를 해결하고 데이터 효율적인 에이전트를 개발한다.


<details>
  <summary>Details</summary>
Motivation: 고품질 훈련 데이터의 극심한 부족으로 인해 대형 언어 모델 에이전트의 개발이 저해되고 있다.

Method: '환경 조정'이라는 새로운 훈련 패러다임을 도입하여 에이전트가 사전 수집된 전문가 궤적에 의존하지 않고 문제 인스턴스에서 복잡한 행동을 직접 학습할 수 있도록 한다.

Result: 우리의 방법은 강력한 기준선에 대해 경쟁력 있는 성능을 달성하고, SFT 기반 접근 방식에서 일반적으로 발생하는 성능 붕괴를 극복하며, 우수한 분포 외 일반화를 보여준다.

Conclusion: 정적 궤적에 대한 감독 세부 조정에서 동적 환경 기반 탐색으로의 패러다임 전환을 제시하여 향후 더 강력하고 데이터 효율적인 에이전트 훈련의 길을 열어준다.

Abstract: Large Language Model (LLM) agents show great promise for complex, multi-turn
tool-use tasks, but their development is often hampered by the extreme scarcity
of high-quality training data. Supervised fine-tuning (SFT) on synthetic data
leads to overfitting, whereas standard reinforcement learning (RL) struggles
with a critical cold-start problem and training instability. To address these
challenges, we introduce $\textbf{Environment Tuning}$, a novel training
paradigm that enables agents to learn complex behaviors directly from problem
instances without relying on pre-collected expert trajectories.
$\textbf{Environment Tuning}$ orchestrates this learning process through a
structured curriculum, actionable environment augmentation that provides
corrective feedback, and fine-grained progress rewards to ensure stable and
efficient exploration. Using only 400 problem instances from Berkeley
Function-Calling Leaderboard (BFCL) benchmark, our method not only achieves
competitive in-distribution performance against strong baselines but also
demonstrates superior out-of-distribution generalization, overcoming the
performance collapse common to SFT-based approaches. Our work presents a
paradigm shift from supervised fine-tuning on static trajectories to dynamic,
environment-based exploration, paving the way for training more robust and
data-efficient agents.

</details>


### [77] [Traj-CoA: Patient Trajectory Modeling via Chain-of-Agents for Lung Cancer Risk Prediction](https://arxiv.org/abs/2510.10454)
*Sihang Zeng,Yujuan Fu,Sitong Zhou,Zixuan Yu,Lucas Jing Liu,Jun Wen,Matthew Thompson,Ruth Etzioni,Meliha Yetisgen*

Main category: cs.AI

TL;DR: Traj-CoA는 전자 건강 기록 데이터를 처리하여 환자 경로 모델링을 향상시키는 멀티 에이전트 시스템입니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 환자 경로 모델링에 일반화 가능한 접근법을 제공하지만, 전자 건강 기록의 긴 시간적 특성과 소음으로 인해 어려움을 겪고 있습니다.

Method: Traj-CoA는 작업 에이전트의 체인을 사용하여 EHR 데이터를 관리하기 쉬운 청크로 순차 처리하고 중요 사건을 EHRMem이라는 공유 장기 기억 모듈에 요약합니다.

Result: Traj-CoA는 5년 EHR 데이터를 기반으로 한 제로샷 일년 폐암 위험 예측 작업에서 4가지 범주의 기준을 초과하는 성과를 보였습니다.

Conclusion: Traj-CoA는 임상적으로 일치하는 시간적 추론을 보여주며, 복잡한 환자 경로 모델링을 위한 강력하고 일반화 가능한 방법으로 자리 잡았습니다.

Abstract: Large language models (LLMs) offer a generalizable approach for modeling
patient trajectories, but suffer from the long and noisy nature of electronic
health records (EHR) data in temporal reasoning. To address these challenges,
we introduce Traj-CoA, a multi-agent system involving chain-of-agents for
patient trajectory modeling. Traj-CoA employs a chain of worker agents to
process EHR data in manageable chunks sequentially, distilling critical events
into a shared long-term memory module, EHRMem, to reduce noise and preserve a
comprehensive timeline. A final manager agent synthesizes the worker agents'
summary and the extracted timeline in EHRMem to make predictions. In a
zero-shot one-year lung cancer risk prediction task based on five-year EHR
data, Traj-CoA outperforms baselines of four categories. Analysis reveals that
Traj-CoA exhibits clinically aligned temporal reasoning, establishing it as a
promisingly robust and generalizable approach for modeling complex patient
trajectories.

</details>


### [78] [MedCoAct: Confidence-Aware Multi-Agent Collaboration for Complete Clinical Decision](https://arxiv.org/abs/2510.10461)
*Hongjie Zheng,Zesheng Shi,Ping Yi*

Main category: cs.AI

TL;DR: 이 논문은 통합 임상 워크플로우에서 진단과 약물 결정을 연결하는 데 어려움을 겪는 대규모 언어 모델(LLM)을 활용한 자율 에이전트의 한계를 극복하기 위한 MedCoAct라는 다중 에이전트 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 의료 AI 시스템은 개별 작업을 처리하며 진단 팀에서 찾아볼 수 있는 교차 검증과 지식 통합이 부족하여 실제 의료 시나리오에서의 효과성이 저하됩니다.

Method: MedCoAct는 특별히 설계된 의사 및 약사 에이전트를 통합하여 임상 협업을 모사하는 신뢰 인식 다중 에이전트 프레임워크입니다.

Result: MedCoAct는 67.58%의 진단 정확도와 67.58%의 약물 추천 정확도를 달성하며, 이는 단일 에이전트 프레임워크보다 각각 7.04% 및 7.08% 더 우수합니다.

Conclusion: 이 협력적 접근 방식은 다양한 의료 분야에 잘 일반화되며, 원격 진료 상담 및 일상적인 임상 시나리오에서 특히 효과적이며, 해석 가능한 의사 결정 경로를 제공합니다.

Abstract: Autonomous agents utilizing Large Language Models (LLMs) have demonstrated
remarkable capabilities in isolated medical tasks like diagnosis and image
analysis, but struggle with integrated clinical workflows that connect
diagnostic reasoning and medication decisions. We identify a core limitation:
existing medical AI systems process tasks in isolation without the
cross-validation and knowledge integration found in clinical teams, reducing
their effectiveness in real-world healthcare scenarios. To transform the
isolation paradigm into a collaborative approach, we propose MedCoAct, a
confidence-aware multi-agent framework that simulates clinical collaboration by
integrating specialized doctor and pharmacist agents, and present a benchmark,
DrugCareQA, to evaluate medical AI capabilities in integrated diagnosis and
treatment workflows. Our results demonstrate that MedCoAct achieves 67.58\%
diagnostic accuracy and 67.58\% medication recommendation accuracy,
outperforming single agent framework by 7.04\% and 7.08\% respectively. This
collaborative approach generalizes well across diverse medical domains, proving
especially effective for telemedicine consultations and routine clinical
scenarios, while providing interpretable decision-making pathways.

</details>


### [79] [Collaborative Text-to-Image Generation via Multi-Agent Reinforcement Learning and Semantic Fusion](https://arxiv.org/abs/2510.10633)
*Jiabao Shi,Minfeng Qi,Lefeng Zhang,Di Wang,Yingjie Zhao,Ziying Li,Yalong Xing,Ningran Li*

Main category: cs.AI

TL;DR: 이 논문은 다양한 시각 영역에서 의미적 정합성과 전문적인 수준의 세부 사항을 유지하는 데 어려움이 있는 다중 모드 텍스트-이미지 생성을 위한 다중 에이전트 강화 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 시각 영역에서의 의미적 정합성과 전문적인 수준의 세부 사항 유지를 위한 기존의 어려움을 해결하고자 합니다.

Method: 텍스트 향상 모듈과 이미지 생성 모듈 두 개의 연결된 하위 시스템 내에서 도메인 전문화된 에이전트를 조정하는 다중 에이전트 강화 학습 프레임워크를 사용합니다.

Result: 실험을 통해 생성된 콘텐츠의 풍부함이 크게 증가하였고(단어 수가 1614% 증가), ROUGE-1 점수는 69.7% 감소했습니다. Transformer 기반의 융합 방법이 가장 높은 종합 점수를 기록했습니다.

Conclusion: 전문화된 협업 아키텍처가 신뢰할 수 있는 다중 모드 생성 시스템을 발전시키는 데 가능성을 보여줍니다.

Abstract: Multimodal text-to-image generation remains constrained by the difficulty of
maintaining semantic alignment and professional-level detail across diverse
visual domains. We propose a multi-agent reinforcement learning framework that
coordinates domain-specialized agents (e.g., focused on architecture,
portraiture, and landscape imagery) within two coupled subsystems: a text
enhancement module and an image generation module, each augmented with
multimodal integration components. Agents are trained using Proximal Policy
Optimization (PPO) under a composite reward function that balances semantic
similarity, linguistic visual quality, and content diversity. Cross-modal
alignment is enforced through contrastive learning, bidirectional attention,
and iterative feedback between text and image. Across six experimental
settings, our system significantly enriches generated content (word count
increased by 1614%) while reducing ROUGE-1 scores by 69.7%. Among fusion
methods, Transformer-based strategies achieve the highest composite score
(0.521), despite occasional stability issues. Multimodal ensembles yield
moderate consistency (ranging from 0.444 to 0.481), reflecting the persistent
challenges of cross-modal semantic grounding. These findings underscore the
promise of collaborative, specialization-driven architectures for advancing
reliable multimodal generative systems.

</details>


### [80] [Equity-Aware Geospatial AI for Forecasting Demand-Driven Hospital Locations in Germany](https://arxiv.org/abs/2510.10640)
*Piyush Pant,Marcellius William Suntoro,Ayesha Siddiqua,Muhammad Shehryaar Sharif,Daniyal Ahmed*

Main category: cs.AI

TL;DR: EA-GeoAI는 독일에서 2030년까지 수요 예측과 공평한 병원 계획을 위한 통합 프레임워크를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 건강 관리 자원의 공정한 분배와 미래 수요 예측의 필요성이 증가하고 있습니다.

Method: 인구 통계 변화, 고령 인구 밀도, 인프라 균형을 통합하여 공정성 지수를 생성하고, 해석 가능한 에이전틱 AI 최적화를 통해 병상 배치 및 새로운 시설 위치를 식별합니다.

Result: 예측된 수요에 기반하여 이 접근법은 재정 및 이동 시간 제약 내에서 충족되지 않은 필요를 최소화합니다.

Conclusion: 정책 입안자에게 실행 가능한 권장 사항을 제공함으로써 GeoAI, 장기 예측 및 공정성 측정을 연결하는 중요한 역할을 합니다.

Abstract: This paper presents EA-GeoAI, an integrated framework for demand forecasting
and equitable hospital planning in Germany through 2030. We combine
district-level demographic shifts, aging population density, and infrastructure
balances into a unified Equity Index. An interpretable Agentic AI optimizer
then allocates beds and identifies new facility sites to minimize unmet need
under budget and travel-time constraints. This approach bridges GeoAI,
long-term forecasting, and equity measurement to deliver actionable
recommendations for policymakers.

</details>


### [81] [Unlocking Exploration in RLVR: Uncertainty-aware Advantage Shaping for Deeper Reasoning](https://arxiv.org/abs/2510.10649)
*Can Xie,Ruotong Pan,Xiangyu Wu,Yunfei Zhang,Jiayi Fu,Tingting Gao,Guorui Zhou*

Main category: cs.AI

TL;DR: 이 논문은 불확실성을 고려한 보상 할당 방식을 통해 대형 언어 모델의 추론 능력을 향상시키는 새로운 방법, 즉 UCAS를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 강화 학습 알고리즘은 모든 토큰에 균일한 이점 신호를 방송하는데, 이는 의사결정의 불확실성을 간과하여 비효율적인 탐색과 엔트로피 붕괴 문제를 초래합니다.

Method: UCAS는 모델의 내부 불확실성 신호를 활용하여 신용 할당을 정제시키는 모델-프리 방식으로, 응답 수준의 이점을 조정하고 불확실성을 기반으로 토큰 수준의 패널티를 적용합니다.

Result: UCAS는 5개의 수학적 추론 벤치마크에서 강력한 RLVR 기준선을 크게 초 outperform하며, 1.5B 및 7B 모델 등 다양한 모델 규모에서도 성능을 발휘합니다.

Conclusion: UCAS는 더 높은 보상을 달성할 뿐만 아니라, 더 큰 추론 다양성을 촉진하고 엔트로피 붕괴를 성공적으로 완화합니다.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has shown significant
promise for enhancing the reasoning capabilities of large language models
(LLMs). However, prevailing algorithms like GRPO broadcast a uniform advantage
signal across all tokens in a sequence. This coarse-grained approach overlooks
the pivotal role of uncertain, high-stakes decisions during reasoning, leading
to inefficient exploration and the well-documented problem of entropy collapse.
To address this, we introduce UnCertainty-aware Advantage Shaping (UCAS), a
model-free method that refines credit assignment by leveraging the model's
internal uncertainty signals. UCAS operates in two stages: it first modulates
the response-level advantage using the model's overall self-confidence, and
then applies a token-level penalty based on raw logit certainty. This dual
mechanism encourages exploration of high-uncertainty paths that yield correct
answers while penalizing overconfident yet erroneous reasoning, effectively
balancing the exploration-exploitation trade-off. Extensive experiments on five
mathematical reasoning benchmarks show that UCAS significantly outperforms
strong RLVR baselines across multiple model scales, including 1.5B and 7B. Our
analysis confirms that UCAS not only achieves higher rewards but also promotes
greater reasoning diversity and successfully mitigates entropy collapse.

</details>


### [82] [Simpliflow: A Lightweight Open-Source Framework for Rapid Creation and Deployment of Generative Agentic AI Workflows](https://arxiv.org/abs/2510.10675)
*Deven Panchal*

Main category: cs.AI

TL;DR: simpliflow는 복잡한 작업 자동화를 위한 경량 오픈 소스 Python 프레임워크로, 사용자 친화적이고 신속한 개발을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 다단계 작업을 자동화하기 위한 강력한 패러다임으로서의 Generative Agentic AI 시스템의 필요성.

Method: declarative JSON 기반 구성으로 선형 결정론적 에이전트 워크플로우를 개발 및 조율하는 기능을 제공하는 경량 프레임워크.

Result: simpliflow는 100개 이상의 대형 언어 모델을 즉시 지원하며, 다양한 사용 사례를 통해 유용성을 입증했다.

Conclusion: LangChain 및 AutoGen과의 비교 분석을 통해 단순함, 제어 및 속도 최적화된 도구로서의 simpliflow의 독특한 위치를 강조한다.

Abstract: Generative Agentic AI systems are emerging as a powerful paradigm for
automating complex, multi-step tasks. However, many existing frameworks for
building these systems introduce significant complexity, a steep learning
curve, and substantial boilerplate code, hindering rapid prototyping and
deployment. This paper introduces simpliflow, a lightweight, open-source Python
framework designed to address these challenges. simpliflow enables the rapid
development and orchestration of linear, deterministic agentic workflows
through a declarative, JSON-based configuration. Its modular architecture
decouples agent management, workflow execution, and post-processing, promoting
ease of use and extensibility. By integrating with LiteLLM, it supports over
100 Large Language Models (LLMs) out-of-the-box. We present the architecture,
operational flow, and core features of simpliflow, demonstrating its utility
through diverse use cases ranging from software development simulation to
real-time system interaction. A comparative analysis with prominent frameworks
like LangChain and AutoGen highlights simpliflow's unique position as a tool
optimized for simplicity, control, and speed in deterministic workflow
environments.

</details>


### [83] [LLMs as Strategic Agents: Beliefs, Best Response Behavior, and Emergent Heuristics](https://arxiv.org/abs/2510.10813)
*Enric Junque de Fortuny,Veronica Roberta Cappelli*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)이 협상, 정책 설계 및 시장 시뮬레이션 등 다른 행위자의 행동에 대한 추론을 요구하는 분야에 점점 더 적용되고 있으며, 현재 연구는 이들의 균형 플레이 준수나 깊이 있는 추론을 평가하고 있습니다. 그러나 그들이 진정한 전략적 사고를 보여주는지는 탐구되지 않았습니다. 본 연구는 정적 완전 정보 게임에서 믿음, 평가 및 선택을 분리하여 이 능력을 식별하는 프레임워크를 개발하고 비협조적 환경에서 이를 적용했습니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 진정한 전략적 사고를 보여주는지 탐구하기 위해 이 프레임워크를 개발했습니다.

Method: 믿음, 평가 및 선택을 정적, 완전 정보 게임에서 분리하고 다양한 비협조적 환경에서 분석합니다. 모델의 선택과 추론 흔적을 공동 분석하며, 기억에서 오는 모방을 배제하기 위해 새로운 맥락 없는 게임을 도입했습니다.

Result: 현재 최첨단 모델은 목표한 추론 깊이에서 믿음 일관성에 기반한 최적 반응 행동을 보입니다. 자유롭게 설정되었을 때, 그들은 추론 깊이를 자가 제한하고 인간 및 합성 상대에 대한 차별화된 추측을 형성하며 메타 추론의 emergent 형식을 드러냅니다.

Conclusion: 믿음 일관성, 메타 추론 및 새로운 휴리스틱 형성은 언어 모델링 목표에서 공동으로 나타날 수 있으며, 인공지능 에이전트의 전략적 인지를 연구하는 구조화된 기반을 제공합니다.

Abstract: Large Language Models (LLMs) are increasingly applied to domains that require
reasoning about other agents' behavior, such as negotiation, policy design, and
market simulation, yet existing research has mostly evaluated their adherence
to equilibrium play or their exhibited depth of reasoning. Whether they display
genuine strategic thinking, understood as the coherent formation of beliefs
about other agents, evaluation of possible actions, and choice based on those
beliefs, remains unexplored. We develop a framework to identify this ability by
disentangling beliefs, evaluation, and choice in static, complete-information
games, and apply it across a series of non-cooperative environments. By jointly
analyzing models' revealed choices and reasoning traces, and introducing a new
context-free game to rule out imitation from memorization, we show that current
frontier models exhibit belief-coherent best-response behavior at targeted
reasoning depths. When unconstrained, they self-limit their depth of reasoning
and form differentiated conjectures about human and synthetic opponents,
revealing an emergent form of meta-reasoning. Under increasing complexity,
explicit recursion gives way to internally generated heuristic rules of choice
that are stable, model-specific, and distinct from known human biases. These
findings indicate that belief coherence, meta-reasoning, and novel heuristic
formation can emerge jointly from language modeling objectives, providing a
structured basis for the study of strategic cognition in artificial agents.

</details>


### [84] [LLM-Empowered Agentic MAC Protocols: A Dynamic Stackelberg Game Approach](https://arxiv.org/abs/2510.10895)
*Renxuan Tan,Rongpeng Li,Fei Wang,Chenghui Peng,Shaoyun Wu,Zhifeng Zhao,Honggang Zhang*

Main category: cs.AI

TL;DR: 본 연구는 동적 다수의 사용자 장비와의 업링크 전송을 모델링한 게임 이론 기반의 다중 에이전트 심층 강화 학습 프레임워크를 제안합니다. 이 프레임워크는 기존의 매크로 프로토콜보다 더 높은 처리량과 공정성을 제공하며, 사용자 수의 변동에도 적응력이 뛰어납니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 MAC 프로토콜은 수동적으로 설정되며, DRL 기반 프로토콜은 성능이 뛰어나지만 일반화 및 적응력이 떨어지는 문제가 있습니다.

Method: 게임 이론적 LLM 지원 다중 에이전트 DRL 프레임워크를 통해, 다수의 사용자 장비와의 업링크 전송을 동적 다중 추종자 Stackelberg 게임으로 모델링하고, PPO를 통해 LLM 기반 에이전트가 네트워크 동향에 따른 적응형 MAC 프로토콜을 생성합니다.

Result: 우리의 프레임워크는 기존 기준보다 77.6% 더 높은 처리량과 65.2% 향상된 공정성을 달성했습니다.

Conclusion: 우리의 프레임워크는 재훈련이나 아키텍처 변경 없이도 fluctuating한 사용자 수에 잘 일반화됩니다.

Abstract: Medium Access Control (MAC) protocols, essential for wireless networks, are
typically manually configured. While deep reinforcement learning (DRL)-based
protocols enhance task-specified network performance, they suffer from poor
generalizability and resilience, demanding costly retraining to adapt to
dynamic environments. To overcome this limitation, we introduce a
game-theoretic LLM-empowered multi-agent DRL (MARL) framework, in which the
uplink transmission between a base station and a varying number of user
equipments is modeled as a dynamic multi-follower Stackelberg game (MFSG),
capturing the network's natural hierarchical structure. Within this game,
LLM-driven agents, coordinated through proximal policy optimization (PPO),
synthesize adaptive, semantic MAC protocols in response to network dynamics.
Protocol action grammar (PAG) is employed to ensure the reliability and
efficiency of this process. Under this system, we further analyze the existence
and convergence behavior in terms of a Stackelberg equilibrium by studying the
learning dynamics of LLM-empowered unified policies in response to changing
followers. Simulations corroborate that our framework achieves a 77.6% greater
throughput and a 65.2% fairness improvement over conventional baselines.
Besides, our framework generalizes excellently to a fluctuating number of users
without requiring retraining or architectural changes.

</details>


### [85] [PaperArena: An Evaluation Benchmark for Tool-Augmented Agentic Reasoning on Scientific Literature](https://arxiv.org/abs/2510.10909)
*Daoyu Wang,Mingyue Cheng,Qi Liu,Shuo Yu,Zirui Liu,Ze Guo*

Main category: cs.AI

TL;DR: PaperArena는 웹 규모의 과학 문헌을 이해하고 이유를 제시하기 위한 에이전트의 평가 벤치마크를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM) 기반 에이전트가 복잡한 지식 집약적 작업을 지원하기 위해서는 웹 규모의 과학 문헌에 대한 이해와 추론이 필수적이다.

Method: PaperArena는 여러 논문에서 정보를 통합하고 외부 도구를 활용하여 실제 연구 질문에 답변하는 에이전트를 위한 평가 벤치마크이다.

Result: 가장 진보된 LLM 기반 에이전트 시스템도 평균 38.78%의 정확도만을 달성하였으며, 어려운 하위 집합에서는 정확도가 18.47%로 떨어졌다.

Conclusion: PaperArena는 공학적 발견을 위해 더 강력한 에이전트를 개발하고 평가하는 데 커뮤니티의 참여를 촉구한다.

Abstract: Understanding and reasoning on the web-scale scientific literature is a
crucial touchstone for large language model (LLM) based agents designed to
support complex knowledge-intensive tasks. However, existing works are mainly
restricted to tool-free tasks within isolated papers, largely due to the lack
of a benchmark for cross-paper reasoning and multi-tool orchestration in real
research scenarios. In this work, we propose PaperArena, an evaluation
benchmark for agents to address real-world research questions that typically
require integrating information across multiple papers with the assistance of
external tools. Given a research question, agents should integrate diverse
formats across multiple papers through reasoning and interacting with
appropriate tools, thereby producing a well-grounded answer. To support
standardized evaluation, we provide a modular and extensible platform for agent
execution, offering tools such as multimodal parsing, context retrieval, and
programmatic computation. Experimental results reveal that even the most
advanced LLM powering a well-established agent system achieves merely 38.78%
average accuracy. On the hard subset, accuracy drops to only 18.47%,
highlighting great potential for improvement. We also present several empirical
findings, including that all agents tested exhibit inefficient tool usage,
often invoking more tools than necessary to solve a task. We invite the
community to adopt PaperArena to develop and evaluate more capable agents for
scientific discovery. Our code and data are available
https://github.com/Melmaphother/PaperArena.

</details>


### [86] [PoU: Proof-of-Use to Counter Tool-Call Hacking in DeepResearch Agents](https://arxiv.org/abs/2510.10931)
*SHengjie Ma,Chenlong Deng,Jiaxin Mao,Jiadeng Huang,Teng Wang,Junjie Wu,Changwang Zhang,Jun wang*

Main category: cs.AI

TL;DR: RAG 에이전트는 RL로 다단계 추론을 가능하게 하지만, Tool-Call Hacking 문제를 해결하기 위해 증거 기반 RL 프레임워크인 Proof-of-Use (PoU)를 제안한다. PoU는 에이전트가 인용된 증거를 실제로 활용하게 하고, QA 벤치마크에서 DeepResearch 기준선을 초월하는 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: RAG 에이전트의 Tool-Call Hacking 문제를 해결하여 다단계 추론의 결과를 개선하기 위해.

Method: Proof-of-Use (PoU)라는 증거 기반 RL 프레임워크를 제안하며, 이를 통해 인용 및 정답-증거 정렬 목표를 결합하여 도구 사용을 해석 가능하고 기능적으로 기반을 둔 방식으로 보장한다.

Result: PoU는 다양한 QA 벤치마크에서 DeepResearch 기준선을 지속적으로 초과하여 사실 정확도, 증거 신뢰성 및 도구 라우팅 균형에서 우수한 성과를 보인다.

Conclusion: RL-trained 에이전트를 단순한 작업 결과에만 의존하지 않고, 인용된 정보의 인과적 사용을 통해 근거를 마련하여 신뢰할 수 있는 검색 기반 추론으로 나아가는 원칙적인 경로를 제시한다.

Abstract: Retrieval-augmented generation (RAG) agents, such as recent
DeepResearch-style systems, extend large language models (LLMs) with autonomous
information-seeking capabilities through external tools. While reinforcement
learning (RL) has enabled impressive multi-step reasoning, we identify a
previously overlooked failure mode, Tool-Call Hacking, where agents inflate
reward signals by issuing superficially correct tool calls without genuinely
leveraging the retrieved evidence. This results in (i) mode collapse into
repetitive reliance on a single source and (ii) spurious grounding, where
answers are only weakly supported by cited content.
  To address this, we propose Proof-of-Use (PoU), an evidence-grounded RL
framework that enforces verifiable causal links between retrieved evidence,
reasoning traces, and final answers. PoU operationalizes this through a unified
step-wise contract combining syntactic citation validation, perturbation-based
sensitivity rewards, and answer-evidence alignment objectives, ensuring that
tool usage remains both interpretable and functionally grounded.
  Across seven QA benchmarks spanning in-domain, out-of-domain, and
out-of-tool-distribution settings, PoU consistently outperforms strong
DeepResearch baselines in factual accuracy, evidence faithfulness, and
tool-routing balance. These findings highlight the necessity of grounding
RL-trained agents not merely in task outcomes but in the causal use of
retrieved information, offering a principled path toward trustworthy
retrieval-augmented reasoning.

</details>


### [87] [Modeling AI-Driven Production and Competitiveness A Multi-Agent Economic Simulation of China and the United States](https://arxiv.org/abs/2510.11085)
*Yuxinyue Qian,Jun Liu*

Main category: cs.AI

TL;DR: 이 논문은 인공지능(AI) 협업 및 자율 생산 등의 다양한 메커니즘 하에서 중국과 미국의 거시경제적 출력 진화를 비교한다.


<details>
  <summary>Details</summary>
Motivation: AI 기술의 급속한 발전으로 인해 사회경제 시스템이 '인간-AI 공동 창작'의 새로운 단계에 접어들고 있다.

Method: 다층 지능형 에이전트 경제 모델을 기반으로 다양한 메커니즘을 통해 시뮬레이션 기반 비교를 수행하였다.

Result: AI가 독립적인 생산 주체로 기능할 때 사회 생산의 전체 성장률이 전통적인 인간 노동 기반 모델보다 훨씬 더 높은 것으로 나타났다.

Conclusion: 중국은 지능형 에이전트 집단의 확장과 기술적 격차 해소 속도에서 명확한 가속화 잠재력을 보여주며, 이는 기술적 수렴 내지 부분적 초과 달성 가능성을 시사한다.

Abstract: With the rapid development of artificial intelligence (AI) technology,
socio-economic systems are entering a new stage of "human-AI co-creation."
Building upon a previously established multi-level intelligent agent economic
model, this paper conducts simulation-based comparisons of macroeconomic output
evolution in China and the United States under different mechanisms-AI
collaboration, network effects, and AI autonomous production. The results show
that: (1) when AI functions as an independent productive entity, the overall
growth rate of social output far exceeds that of traditional human-labor-based
models; (2) China demonstrates clear potential for acceleration in both the
expansion of intelligent agent populations and the pace of technological
catch-up, offering the possibility of achieving technological convergence or
even partial surpassing. This study provides a systematic, model-based
analytical framework for understanding AI-driven production system
transformation and shifts in international competitiveness, as well as
quantitative insights for relevant policy formulation.

</details>


### [88] [Spec-Driven AI for Science: The ARIA Framework for Automated and Reproducible Data Analysis](https://arxiv.org/abs/2510.11143)
*Chuke Chen,Biao Luo,Nan Li,Boxiang Wang,Hang Yang,Jing Guo,Ming Xu*

Main category: cs.AI

TL;DR: ARIA는 자동화 및 해석 가능한 데이터 분석을 위한 프레임워크로, 인간의 개입을 통해 연구 목표를 정의하고 실행 가능한 코드를 자동으로 생성한다.


<details>
  <summary>Details</summary>
Motivation: 과학 데이터의 급격한 확장은 분석 능력과 연구 의도 사이의 간극을 넓혔다.

Method: ARIA는 인간의 사고와 기계 실행을 통합하는 문서 중심의 워크플로우 내에서, Command, Context, Code, Data, Orchestration, AI Module의 여섯 개 상호 운용 가능한 레이어를 통합한다.

Result: ARI는 최적의 특성 집합을 신속하게 식별하고 적합한 모델을 선택하여 중복 조정과 반복 실험을 최소화하였다.

Conclusion: ARIA는 투명하고 협력적이며 재현 가능한 과학적 발견을 위한 새로운 패러다임을 설정한다.

Abstract: The rapid expansion of scientific data has widened the gap between analytical
capability and research intent. Existing AI-based analysis tools, ranging from
AutoML frameworks to agentic research assistants, either favor automation over
transparency or depend on manual scripting that hinders scalability and
reproducibility. We present ARIA (Automated Research Intelligence Assistant), a
spec-driven, human-in-the-loop framework for automated and interpretable data
analysis. ARIA integrates six interoperable layers, namely Command, Context,
Code, Data, Orchestration, and AI Module, within a document-centric workflow
that unifies human reasoning and machine execution. Through natural-language
specifications, researchers define analytical goals while ARIA autonomously
generates executable code, validates computations, and produces transparent
documentation. Beyond achieving high predictive accuracy, ARIA can rapidly
identify optimal feature sets and select suitable models, minimizing redundant
tuning and repetitive experimentation. In the Boston Housing case, ARIA
discovered 25 key features and determined XGBoost as the best performing model
(R square = 0.93) with minimal overfitting. Evaluations across heterogeneous
domains demonstrate ARIA's strong performance, interpretability, and efficiency
compared with state-of-the-art systems. By combining AI for research and AI for
science principles within a spec-driven architecture, ARIA establishes a new
paradigm for transparent, collaborative, and reproducible scientific discovery.

</details>


### [89] [$How^{2}$: How to learn from procedural How-to questions](https://arxiv.org/abs/2510.11144)
*Gautier Dagan,Frank Keller,Alex Lascarides*

Main category: cs.AI

TL;DR: $How^{2}$ 프레임워크를 통해 에이전트가 '어떻게 X를 하는가'라는 질문을 하고, 답변을 저장 및 재사용하여 평생 학습을 지원하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 계획 문제에 직면한 에이전트가 불확실성을 줄이고 지식 공백을 메우기 위해 '어떻게' 질문을 활용할 수 있도록 지원하는 것입니다.

Method: $How^{2}$라는 메모리 에이전트 프레임워크를 도입하여, 에이전트가 '어떻게' 질문을 하고 답변을 저장하며, 이를 상호작용 환경에서 평생 학습에 재사용할 수 있도록 디자인했습니다.

Result: Plancraft라는 마인크래프트 제작 환경에서 다양한 추상 수준으로 답변하는 교사 모델을 사용하여 에이전트가 조합 작업을 완수하는 방법을 평가했습니다.

Conclusion: $How^{2}$는 LLM 기반 에이전트가 상호작용 환경에서 질문을 통해 시간이 지남에 따라 계획 능력을 향상시킬 수 있는 방법을 제공합니다.

Abstract: An agent facing a planning problem can use answers to how-to questions to
reduce uncertainty and fill knowledge gaps, helping it solve both current and
future tasks. However, their open ended nature, where valid answers to "How do
I X?" range from executable actions to high-level descriptions of X's
sub-goals, makes them challenging for AI agents to ask, and for AI experts to
answer, in ways that support efficient planning. We introduce $How^{2}$, a
memory agent framework that enables agents to ask how-to questions, store the
answers, and reuse them for lifelong learning in interactive environments. We
evaluate our approach in Plancraft, a Minecraft crafting environment, where
agents must complete an assembly task by manipulating inventory items. Using
teacher models that answer at varying levels of abstraction, from executable
action sequences to high-level subgoal descriptions, we show that lifelong
learning agents benefit most from answers that are abstracted and decoupled
from the current state. $How^{2}$ offers a way for LLM-based agents to improve
their planning capabilities over time by asking questions in interactive
environments.

</details>


### [90] [PADME: Procedure Aware DynaMic Execution](https://arxiv.org/abs/2510.11281)
*Deepeka Garg,Sihan Zeng,Annapoorani L. Narayanan,Sumitra Ganesh,Leo Ardon*

Main category: cs.AI

TL;DR: PADME는 절차를 그래프 기반으로 표현하고 이를 활용해 자율적으로 긴 수명 주기 절차를 실행하는 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 자연어로 된 긴 수명 주기 절차를 자율적으로 실행하는 것은 지능형 에이전트의 핵심적인 도전 과제이다.

Method: PADME는 절차 텍스트를 실행 가능한 그래프로 변환하여 작업 의존성, 결정 지점 및 재사용 가능한 하위 루틴을 캡처하는 두 단계의 방법론을 사용한다.

Result: PADME는 ALFWorld 및 ScienceWorld를 포함한 네 가지 다양한 벤치마크에서 최첨단 성능을 달성했다.

Conclusion: 그래프 기반 절차 표현을 갖춘 에이전트는 강력하고 일반화 가능한 실행을 위한 중간 추상화를 제공한다.

Abstract: Learning to autonomously execute long-horizon procedures from natural
language remains a core challenge for intelligent agents. Free-form
instructions such as recipes, scientific protocols, or business workflows
encode rich procedural knowledge, but their variability and lack of structure
cause agents driven by large language models (LLMs) to drift or fail during
execution. We introduce Procedure Aware DynaMic Execution (PADME), an agent
framework that produces and exploits a graph-based representation of
procedures. Unlike prior work that relies on manual graph construction or
unstructured reasoning, PADME autonomously transforms procedural text into
executable graphs that capture task dependencies, decision points, and reusable
subroutines. Central to PADME is a two-phase methodology; Teach phase, which
focuses on systematic structuring, enrichment with executable logic of
procedures, followed by Execute phase, which enables dynamic execution in
response to real-time inputs and environment feedback. This separation ensures
quality assurance and scalability, allowing expert knowledge to be encoded once
and reliably reused across varying contexts. The graph representation also
provides an inductive bias that reduces error accumulation in long-horizon
reasoning, underscoring the importance of structured procedure modeling for
reliable agent-driven automation. Empirically, PADME achieves state-of-the-art
performance on four diverse benchmarks, including ALFWorld and ScienceWorld.
These results demonstrate that agents equipped with graph-based procedure
representations offer a powerful intermediate abstraction for robust and
generalizable execution.

</details>


### [91] [Evolution in Simulation: AI-Agent School with Dual Memory for High-Fidelity Educational Dynamics](https://arxiv.org/abs/2510.11290)
*Sheng Jin,Haoming Wang,Zhiqi Gao,Yongbo Yang,Bao Chunjia,Chengliang Wang*

Main category: cs.AI

TL;DR: AAS 시스템은 자가 발전 메커니즘을 통해 복잡한 교육 역학을 시뮬레이션하며 에이전트의 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 인간 시스템과 상호작용을 이해하고 시뮬레이션하는 데 있어 LLM 기반 에이전트의 중요성이 커지고 있습니다.

Method: AAS는 제로 경험 전략을 구성하고 경험-반성-최적화의 지속적인 사이클을 사용하는 자가 발전 메커니즘을 수립합니다.

Result: AAS는 교육 역학을 효과적으로 시뮬레이션하고, 고급 에이전트 인지 능력을 발전시킵니다.

Conclusion: AAS는 '경험의 시대'에서 '시뮬레이션의 시대'로 나아가는 기반을 제공하며, 높은 충실도의 행동 및 상호작용 데이터를 생성합니다.

Abstract: Large language models (LLMs) based Agents are increasingly pivotal in
simulating and understanding complex human systems and interactions. We propose
the AI-Agent School (AAS) system, built around a self-evolving mechanism that
leverages agents for simulating complex educational dynamics. Addressing the
fragmented issues in teaching process modeling and the limitations of agents
performance in simulating diverse educational participants, AAS constructs the
Zero-Exp strategy, employs a continuous "experience-reflection-optimization"
cycle, grounded in a dual memory base comprising experience and knowledge bases
and incorporating short-term and long-term memory components. Through this
mechanism, agents autonomously evolve via situated interactions within diverse
simulated school scenarios. This evolution enables agents to more accurately
model the nuanced, multi-faceted teacher-student engagements and underlying
learning processes found in physical schools. Experiment confirms that AAS can
effectively simulate intricate educational dynamics and is effective in
fostering advanced agent cognitive abilities, providing a foundational stepping
stone from the "Era of Experience" to the "Era of Simulation" by generating
high-fidelity behavioral and interaction data.

</details>


### [92] [Zero Data Retention in LLM-based Enterprise AI Assistants: A Comparative Study of Market Leading Agentic AI Products](https://arxiv.org/abs/2510.11558)
*Komal Gupta,Aditya Shrivastava*

Main category: cs.AI

TL;DR: 이 논문은 의료 및 금융 비즈니스에서 데이터 관리, 규정 준수 및 비즈니스 프라이버시 문제를 다룹니다. AI 비즈니스 보조 도구의 출현으로 프라이빗 데이터 보호와 규정 준수가 중요한 이슈가 되었으며, 대형 언어 모델 기업들이 제로 데이터 보존 정책을 구현하여 이를 달성할 수 있음을 강조합니다. 이 연구는 Salesforce와 Microsoft와 같은 업계 리더와의 협력을 통해 상업적인 AI 보조 도구의 개발을 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: AI 비즈니스 보조 도구의 출현으로 데이터 보호 및 규정 준수가 비즈니스의 우선 과제가 되었습니다.

Method: 대형 언어 모델(LLM)의 기업 응용 프로그램을 위한 제로 데이터 보존 정책을 탐구하며, Salesforce와 Microsoft의 사례를 분석합니다.

Result: 두 회사는 제로 데이터 보존 정책을 지원하기 위해 서로 다른 기술 아키텍처를 사용했습니다.

Conclusion: Open AI, Anthropic, Meta와 같은 서비스 제공업체의 응용 프로그램 및 대형 언어 모델 소비를 통해 제로 데이터 보존 정책의 기술 아키텍처 및 배치를 분석합니다.

Abstract: Governance of data, compliance, and business privacy matters, particularly
for healthcare and finance businesses. Since the recent emergence of AI
enterprise AI assistants enhancing business productivity, safeguarding private
data and compliance is now a priority. With the implementation of AI assistants
across the enterprise, the zero data retention can be achieved by implementing
zero data retention policies by Large Language Model businesses like Open AI
and Anthropic and Meta. In this work, we explore zero data retention policies
for the Enterprise apps of large language models (LLMs). Our key contribution
is defining the architectural, compliance, and usability trade-offs of such
systems in parallel. In this research work, we examine the development of
commercial AI assistants with two industry leaders and market titans in this
arena - Salesforce and Microsoft. Both of these companies used distinct
technical architecture to support zero data retention policies. Salesforce
AgentForce and Microsoft Copilot are among the leading AI assistants providing
much-needed push to business productivity in customer care. The purpose of this
paper is to analyze the technical architecture and deployment of zero data
retention policy by consuming applications as well as big language models
service providers like Open Ai, Anthropic, and Meta.

</details>


### [93] [Analyzing and Internalizing Complex Policy Documents for LLM Agents](https://arxiv.org/abs/2510.11588)
*Jiateng Liu,Zhenhailong Wang,Xiaojiang Huang,Yingjie Li,Xing Fan,Xiang Li,Chenlei Guo,Ruhi Sarikaya,Heng Ji*

Main category: cs.AI

TL;DR: 이 논문은 복잡한 비즈니스 규칙을 인코딩한 정책 문서를 모델 프라이어에 내장하여 성능을 유지하는 내부화 방법을 개발하는 것에 중점을 두고 있다.


<details>
  <summary>Details</summary>
Motivation: 요구사항이 증가함에 따라 정책 문서가 급격히 확장되어 높은 계산 오버헤드를 야기함을 해결하려는 동기가 있다.

Method: CAP-CPT는 정책 문서에서 핵심 사양을 추출하고 이를 사실적, 행동적, 조건적 범주로 그룹화하며, 워크플로우 복잡성을 유도하는 복잡한 조건을 분리하여 데이터 합성을 안내한다.

Result: CAP-CPT는 모든 설정에서 SFT 기준선을 개선하고, CC-Gen에서 97.3%의 프롬프트 길이 감소를 달성하며, 최소의 SFT 데이터로 tau-Bench를 추가로 향상시킨다.

Conclusion: 이 연구는 복잡한 정책 사양이 추론에서 주요 도전 과제가 된다는 것을 보여주며, 자동화된 파이프라인이 정책 정보를 내재화하는 데 기여함을 입증한다.

Abstract: Large Language Model (LLM)-based agentic systems rely on in-context policy
documents encoding diverse business rules. As requirements grow, these
documents expand rapidly, causing high computational overhead. This motivates
developing internalization methods that embed policy documents into model
priors while preserving performance. Prior prompt compression work targets
generic prompts, but agentic policy documents span multiple complexity levels
and require deeper reasoning, making internalization harder. We introduce
CC-Gen, an agentic benchmark generator with Controllable Complexity across four
levels, enabling systematic evaluation of agents' ability to handle complexity
and offering a unified framework for assessing policy internalization. Our
analysis shows that complex policy specifications governing workflows pose
major reasoning challenges. Supporting internalization with gold user agent
interaction trajectories containing chain-of-thought (CoT) annotations via
supervised fine-tuning (SFT) is data-intensive and degrades sharply as policy
complexity increases. To mitigate data and reasoning burdens, we propose
Category-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline
parses policy documents to extract key specifications, grouping them into
factual, behavioral, and conditional categories, and isolating complex
conditions that drive workflow complexity. This guides targeted data synthesis
and enables agents to internalize policy information through an autoregressive
pretraining loss. Experiments show CAP-CPT improves SFT baselines in all
settings, with up to 41% and 22% gains on Qwen-3-32B, achieving 97.3% prompt
length reduction on CC-Gen and further enhancing tau-Bench with minimal SFT
data.

</details>


### [94] [ParaCook: On Time-Efficient Planning for Multi-Agent Systems](https://arxiv.org/abs/2510.11608)
*Shiqi Zhang,Xinbei Ma,Yunqing Xu,Zouying Cao,Pengrui Lu,Haobo Yuan,Tiancheng Shen,Zhuosheng Zhang,Hai Zhao,Ming-Hsuan Yang*

Main category: cs.AI

TL;DR: 이 논문에서는 시간 효율적인 협력 계획을 위한 벤치마크인 ParaCook을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 에이전트 벤치마크가 작업 완료에만 초점을 맞추고 시간 효율성을 간과하고 있기 때문에.

Method: ParaCook은 간소화된 행동 공간을 통해 다중 에이전트 시스템의 상호작용 계획 환경을 제공한다.

Result: 현재 접근 방식이 병렬 작업이나 조정에서 어려움을 겪는 최적 이하의 계획을 생성한다는 사실을 발견했다.

Conclusion: ParaCook은 시간 효율성을 고려한 다중 에이전트 계획 개발 및 평가를 위한 기초를 마련한다.

Abstract: Large Language Models (LLMs) exhibit strong reasoning abilities for planning
long-horizon, real-world tasks, yet existing agent benchmarks focus on task
completion while neglecting time efficiency in parallel and asynchronous
operations. To address this, we present ParaCook, a benchmark for
time-efficient collaborative planning. Inspired by the Overcooked game,
ParaCook provides an environment for various challenging interaction planning
of multi-agent systems that are instantiated as cooking tasks, with a
simplified action space to isolate the core challenge of strategic parallel
planning. Through a comprehensive evaluation of state-of-the-art LLMs, we find
that current approaches achieve suboptimal plans, which struggle with parallel
actions or coordination. Our analysis also reveals LLMs' potential on abstract
tasks where they can focus on high-level parallel optimization. ParaCook
provides a scalable evaluation framework with adjustable complexity,
establishing a foundation for developing and assessing time efficiency-aware
multi-agent planning. The code and data are available at
https://github.com/zsq259/ParaCook.

</details>


### [95] [SR-Scientist: Scientific Equation Discovery With Agentic AI](https://arxiv.org/abs/2510.11661)
*Shijie Xia,Yuhan Sun,Pengfei Liu*

Main category: cs.AI

TL;DR: SR-Scientist는 LLM을 단순한 방정식 제안자에서 자율적인 AI 과학자로 발전시켜 데이터를 분석하고 방정식을 최적화하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 방법은 LLM을 방정식 제안자로 한정했기 때문에, 새로운 연구로 과학적 방정식을 발견하는 가능성을 높이고자 했다.

Method: SR-Scientist 프레임워크는 LLM이 데이터 분석 도구와 방정식 평가 도구를 활용하여 데이터를 분석하고 방정식을 최적화하고 코드로 구현하는 방식이다.

Result: SR-Scientist는 네 가지 과학 분야에 걸친 데이터셋에서 기존 방법들보다 6%에서 35%까지 절대적인 성능 향상을 보였다.

Conclusion: 이 연구는 LLM을 통해 방정식 발견을 자율적으로 수행할 수 있는 가능성을 열어주며, 노이즈에 대한 강건성과 일반화 능력을 갖춘 방정식을 발견할 수 있음을 보여준다.

Abstract: Recently, Large Language Models (LLMs) have been applied to scientific
equation discovery, leveraging their embedded scientific knowledge for
hypothesis generation. However, current methods typically confine LLMs to the
role of an equation proposer within search algorithms like genetic programming.
In this paper, we present SR-Scientist, a framework that elevates the LLM from
a simple equation proposer to an autonomous AI scientist that writes code to
analyze data, implements the equation as code, submits it for evaluation, and
optimizes the equation based on experimental feedback. Specifically, we wrap
the code interpreter into a set of tools for data analysis and equation
evaluation. The agent is instructed to optimize the equation by utilizing these
tools over a long horizon with minimal human-defined pipelines. Empirical
results show that SR-Scientist outperforms baseline methods by an absolute
margin of 6% to 35% on datasets covering four science disciplines.
Additionally, we demonstrate our method's robustness to noise, the
generalization of the discovered equations to out-of-domain data, and their
symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning
framework to enhance the agent's capabilities.

</details>


### [96] [Operand Quant: A Single-Agent Architecture for Autonomous Machine Learning Engineering](https://arxiv.org/abs/2510.11694)
*Arjun Sahney,Ram Gorthi,Cezary Łastowski,Javier Vega*

Main category: cs.AI

TL;DR: Operand Quant는 자율 기계 학습 공학을 위한 단일 에이전트, IDE 기반 아키텍처로, 기존의 다중 에이전트 오케스트레이션 프레임워크와 달리 모든 MLE 생애주기 단계를 하나의 에이전트 내에서 통합한다.


<details>
  <summary>Details</summary>
Motivation: Operand Quant의 개발 동기는 자율적인 기계 학습 공학을 위해 더 효율적이고 통합된 접근 방식을 제공하기 위함이다.

Method: 이 아키텍처는 탐색, 모델링, 실험 및 배포 단계를 단일, 상황 인지 에이전트 내에서 처리하도록 설계되었다.

Result: Operand Quant는 MLE-Benchmark 2025에서 75개의 문제를 대상으로 0.3956 +/- 0.0565의 메달 비율을 달성하며 새로운 최첨단 성과를 기록했다.

Conclusion: 이 아키텍처는 제어된 IDE 환경 내에서 자율적으로 작동하는 선형, 비차단 에이전트가 동일한 제약 조건 하에서 다중 에이전트 및 오케스트레이션 시스템을 능가할 수 있음을 보여준다.

Abstract: We present Operand Quant, a single-agent, IDE-based architecture for
autonomous machine learning engineering (MLE). Operand Quant departs from
conventional multi-agent orchestration frameworks by consolidating all MLE
lifecycle stages -- exploration, modeling, experimentation, and deployment --
within a single, context-aware agent. On the MLE-Benchmark (2025), Operand
Quant achieved a new state-of-the-art (SOTA) result, with an overall medal rate
of 0.3956 +/- 0.0565 across 75 problems -- the highest recorded performance
among all evaluated systems to date. The architecture demonstrates that a
linear, non-blocking agent, operating autonomously within a controlled IDE
environment, can outperform multi-agent and orchestrated systems under
identical constraints.

</details>
