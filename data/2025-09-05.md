<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 6]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.LG](#cs.LG) [Total: 17]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics](https://arxiv.org/abs/2509.02751)
*Matthew Russo,Tim Kraska*

Main category: cs.AI

TL;DR: 이 논문은 대규모 비구조화 데이터셋에 대한 AI 기반 분석을 위해 최적화된 실행과 동적 실행을 결합한 프로토타입을 제시하고, 이를 통해 기존 시스템보다 성능을 향상시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: AI 기반 분석의 성과를 극대화하기 위해서는 최적화된 실행과 동적 실행의 결합이 필요하다.

Method: 딥 리서치 에이전트가 최적화된 의미론적 연산자 프로그램을 작성하고 실행할 수 있는 프로토타입을 개발하였다.

Result: 우리 프로토타입은 수작업으로 작성된 의미론적 연산자 프로그램과 기존 딥 리서치 시스템보다 두 가지 기본 쿼리에서 훨씬 더 나은 성능을 나타낸다.

Conclusion: 프로토타입의 최적화된 실행 덕분에 최대 76.8%의 비용 절감과 72.7%의 실행 시간 절감을 달성했다.

Abstract: With advances in large language models (LLMs), researchers are creating new
systems that can perform AI-driven analytics over large unstructured datasets.
Recent work has explored executing such analytics queries using semantic
operators -- a declarative set of AI-powered data transformations with natural
language specifications. However, even when optimized, these operators can be
expensive to execute on millions of records and their iterator execution
semantics make them ill-suited for interactive data analytics tasks. In another
line of work, Deep Research systems have demonstrated an ability to answer
natural language question(s) over large datasets. These systems use one or more
LLM agent(s) to plan their execution, process the dataset(s), and iteratively
refine their answer. However, these systems do not explicitly optimize their
query plans which can lead to poor plan execution. In order for AI-driven
analytics to excel, we need a runtime which combines the optimized execution of
semantic operators with the flexibility and more dynamic execution of Deep
Research systems. As a first step towards this vision, we build a prototype
which enables Deep Research agents to write and execute optimized semantic
operator programs. We evaluate our prototype and demonstrate that it can
outperform a handcrafted semantic operator program and open Deep Research
systems on two basic queries. Compared to a standard open Deep Research agent,
our prototype achieves up to 1.95x better F1-score. Furthermore, even if we
give the agent access to semantic operators as tools, our prototype still
achieves cost and runtime savings of up to 76.8% and 72.7% thanks to its
optimized execution.

</details>


### [2] [Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving](https://arxiv.org/abs/2509.02754)
*Mingyi Wang,Jingke Wang,Tengju Ye,Junbo Chen,Kaicheng Yu*

Main category: cs.AI

TL;DR: 이 논문은 자율 주행을 위한 모션 생성에서 대형 언어 모델(LLM)의 5가지 핵심 모듈에 대한 포괄적인 평가를 제공하며, 이러한 모듈이 적절히 조정될 경우 성능을 크게 향상시킬 수 있음을 입증합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 발전이 자율 주행 모션 생성과 같은 구조적으로 유사한 문제 도메인에 적용될 수 있는 가능성에 대한 이해 부족.

Method: 자율 주행 모션 생성을 위한 맥락에서 LLM의 5가지 핵심 모듈에 대한 평가를 수행하고 Waymo Sim Agents 벤치마크에서 실험을 통해 이들의 적합성을 검증함.

Result: 적절히 조정된 LLM 모듈이 자율 주행 모션 생성의 성능을 현저히 향상시킬 수 있음을 입증함.

Conclusion: 특정 기술의 효과적 이전 가능성을 식별하고 자율 주행 상황에 필요한 조정 사항을 논의함.

Abstract: Recent breakthroughs in large language models (LLMs) have not only advanced
natural language processing but also inspired their application in domains with
structurally similar problems--most notably, autonomous driving motion
generation. Both domains involve autoregressive sequence modeling, token-based
representations, and context-aware decision making, making the transfer of LLM
components a natural and increasingly common practice. However, despite
promising early attempts, a systematic understanding of which LLM modules are
truly transferable remains lacking. In this paper, we present a comprehensive
evaluation of five key LLM modules--tokenizer design, positional embedding,
pre-training paradigms, post-training strategies, and test-time
computation--within the context of motion generation for autonomous driving.
Through extensive experiments on the Waymo Sim Agents benchmark, we demonstrate
that, when appropriately adapted, these modules can significantly improve
performance for autonomous driving motion generation. In addition, we identify
which techniques can be effectively transferred, analyze the potential reasons
for the failure of others, and discuss the specific adaptations needed for
autonomous driving scenarios. We evaluate our method on the Sim Agents task and
achieve competitive results.

</details>


### [3] [Plan Verification for LLM-Based Embodied Task Completion Agents](https://arxiv.org/abs/2509.02761)
*Ananth Hariharan,Vardhan Dongre,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.AI

TL;DR: 본 논문은 반복 검증 프레임워크를 제안하여 LLM 기반 작업 계획과 인간 시연에서 발생할 수 있는 오류를 수정함으로써, 보다 청결하고 공간적으로 일관된 궤적을 생성한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM) 기반의 작업 계획과 해당 인간 시연이 종종 오류가 있는 경우가 많아 정책 품질을 저하시키기 때문에, 이를 개선할 필요성이 있다.

Method: Judge LLM이 행동 순서를 비판하고 Planner LLM이 수정을 반영하는 반복 검증 프레임워크를 사용한다.

Result: TEACh 데이터셋에서 90%의 재현율과 100%의 정밀도를 달성하며, 96.5%의 순서가 세 번의 반복 내에 수렴한다.

Conclusion: 이 방법은 공간 계획과 행동 정제를 위한 신뢰할 수 있는 LLM 기능으로써, 모방 학습을 위한 고품질 훈련 데이터로 나아갈 수 있는 확장 가능한 경로를 제공한다.

Abstract: Large language model (LLM) based task plans and corresponding human
demonstrations for embodied AI may be noisy, with unnecessary actions,
redundant navigation, and logical errors that reduce policy quality. We propose
an iterative verification framework in which a Judge LLM critiques action
sequences and a Planner LLM applies the revisions, yielding progressively
cleaner and more spatially coherent trajectories. Unlike rule-based approaches,
our method relies on natural language prompting, enabling broad generalization
across error types including irrelevant actions, contradictions, and missing
steps. On a set of manually annotated actions from the TEACh embodied AI
dataset, our framework achieves up to 90% recall and 100% precision across four
state-of-the-art LLMs (GPT o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout).
The refinement loop converges quickly, with 96.5% of sequences requiring at
most three iterations, while improving both temporal efficiency and spatial
action organization. Crucially, the method preserves human error-recovery
patterns rather than collapsing them, supporting future work on robust
corrective behavior. By establishing plan verification as a reliable LLM
capability for spatial planning and action refinement, we provide a scalable
path to higher-quality training data for imitation learning in embodied AI.

</details>


### [4] [app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding](https://arxiv.org/abs/2509.03310)
*Evgenii Kniazev,Arseny Kravchenko,Igor Rekun,James Broadhead,Nikita Shamgunov,Pranav Sah,Pratik Nichite,Ivan Yamshchikov*

Main category: cs.AI

TL;DR: app.build는 LLM 기반 어플리케이션 생성을 체계적인 검증과 구조화된 환경을 통해 개선하는 오픈 소스 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 신뢰할 수 있는 AI 에이전트를 확장하려면 단순히 모델을 확장하는 것이 아니라 환경을 확장해야 한다는 것을 보여주기 위함이다.

Method: 다층 검증 파이프라인, 스택별 오케스트레이션, 모델에 구애받지 않는 아키텍처를 결합하여 세 가지 참조 스택에 구현하였다.

Result: 30개의 생성 작업에 대한 평가를 통해 포괄적인 검증이 73.3%의 실행 가능성 비율을 달성하며, 30%는 완벽한 품질 점수에 도달하였다. 또한, 구조화된 환경에서 오픈 가중치 모델은 폐쇄 모델 성능의 80.8%를 달성했다.

Conclusion: 이 작업은 신뢰할 수 있는 AI 에이전트를 확장하려면 모델뿐 아니라 환경을 확장해야 한다는 것을 입증하며, 생산 지향적인 에이전트 시스템을 위한 경험적 통찰력과 완전한 참조 구현을 제공한다.

Abstract: We present app.build (https://github.com/appdotbuild/agent/), an open-source
framework that improves LLM-based application generation through systematic
validation and structured environments. Our approach combines multi-layered
validation pipelines, stack-specific orchestration, and model-agnostic
architecture, implemented across three reference stacks. Through evaluation on
30 generation tasks, we demonstrate that comprehensive validation achieves
73.3% viability rate with 30% reaching perfect quality scores, while
open-weights models achieve 80.8% of closed-model performance when provided
structured environments. The open-source framework has been adopted by the
community, with over 3,000 applications generated to date. This work
demonstrates that scaling reliable AI agents requires scaling environments, not
just models -- providing empirical insights and complete reference
implementations for production-oriented agent systems.

</details>


### [5] [Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning](https://arxiv.org/abs/2509.03345)
*Yunxin Sun,Abulhair Saparov*

Main category: cs.AI

TL;DR: 이 연구는 대형 언어 모델의 귀납적 및 연역적 추론 능력을 평가하는 데 중점을 두며, 새로운 합성 데이터셋 InAbHyD를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 연구가 연역적 추론에만 집중하고 있어, 실제 문제 해결에 필요한 다른 유형의 추론을 탐구할 필요가 있다.

Method: 프로그램 가능하고 합성된 데이터셋 InAbHyD를 사용하여, 각 추론 사례가 불완전한 세계 모델과 관측 집합으로 구성되도록 한다.

Result: 일부 최신 LLM을 평가하고 분석한 결과, LLM이 간단한 시나리오에서는 귀납적 및 연역적 추론을 수행할 수 있지만, 복잡한 세계 모델에서는 어려움을 겪는다.

Conclusion: 인과 추론 향상 기술을 사용해도 고품질 가설 생성에 한계가 있다.

Abstract: Reasoning is a core capability in artificial intelligence systems, for which
large language models (LLMs) have recently shown remarkable progress. However,
most work focuses exclusively on deductive reasoning, which is problematic
since other types of reasoning are also essential in solving real-world
problems, and they are less explored. This work focuses on evaluating LLMs'
inductive and abductive reasoning capabilities. We introduce a programmable and
synthetic dataset, InAbHyD (pronounced in-a-bid), where each reasoning example
consists of an incomplete world model and a set of observations. The task for
the intelligent agent is to produce hypotheses to explain observations under
the incomplete world model to solve each reasoning example. We propose a new
metric to evaluate the quality of hypotheses based on Occam's Razor. We
evaluate and analyze some state-of-the-art LLMs. Our analysis shows that LLMs
can perform inductive and abductive reasoning in simple scenarios, but struggle
with complex world models and producing high-quality hypotheses, even with
popular reasoning-enhancing techniques such as in-context learning and RLVR.

</details>


### [6] [Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems](https://arxiv.org/abs/2509.03380)
*Peter J. Bentley,Soo Ling Lim,Fuyuki Ishikawa*

Main category: cs.AI

TL;DR: 이 연구는 환경의 변화에 의해 행동이 유발되는 에이전트 기반 AI 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재 에이전트 AI는 신뢰할 수 없는 지휘자에 의해 통제되는 자율적 챗봇에 불과하다.

Method: 하향식 프레임워크를 통해 AI 에이전트를 환경에 위치시키고, 행동을 환경 변화에 반응하도록 설정한다.

Result: 전형적인 아키텍처와 비교했을 때, 정보 유출이 83%까지 발생하는 것에 비해, 제안된 모델은 정보 유출이 제로임을 보여준다.

Conclusion: 전문 에이전트가 각자의 정보 영역에서 효율적으로 작업할 때 보안 및 효율성이 향상될 것으로 기대된다.

Abstract: Agentic LLM AI agents are often little more than autonomous chatbots: actors
following scripts, often controlled by an unreliable director. This work
introduces a bottom-up framework that situates AI agents in their environment,
with all behaviors triggered by changes in their environments. It introduces
the notion of aspects, similar to the idea of umwelt, where sets of agents
perceive their environment differently to each other, enabling clearer control
of information. We provide an illustrative implementation and show that
compared to a typical architecture, which leaks up to 83% of the time,
aspective agentic AI enables zero information leakage. We anticipate that this
concept of specialist agents working efficiently in their own information
niches can provide improvements to both security and efficiency.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [7] [Managing Correlations in Data and Privacy Demand](https://arxiv.org/abs/2509.02856)
*Syomantak Chaudhuri,Thomas A. Courtade*

Main category: cs.CR

TL;DR: 이 논문은 사용자 데이터와 개인 정보 보호 요구 간의 상관관계가 고려되지 않은 기존의 차별적 개인 정보 보호(HDP) 프레임워크의 한계를 지적하고, 이를 해결하기 위한 대안으로 사용자 데이터와 개인 정보 보호 선호를 함께 고려하는 Add-remove Heterogeneous Differential Privacy(AHDP) 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 이 논문의 동기는 사용자 데이터와 개인 정보 보호 요구가 상관관계가 있을 때 기존 HDP 프레임워크의 한계점을 드러내고, 이를 극복하기 위한 새로운 접근 방식을 제시하는 것입니다.

Method: AHDP 프레임워크는 사용자 데이터와 개인 정보 보호 선호를 함께 반영하여, 데이터와 개인 정보 보호 간의 상관관계에 강인성을 지닙니다. 또한, 가설 검정을 통해 제안된 AHDP 프레임워크의 보장을 형식화합니다.

Result: AHDP 메커니즘은 데이터-개인 정보 보호 상관관계에 대한 사전 지식 없이도 존재하며, 이를 평균 추정, 빈도 추정, 선형 회귀와 같은 핵심 통계 작업에 적용합니다.

Conclusion: 제안된 메커니즘은 최소한의 가정 및 모델링 요구 사항으로 간단하게 구현할 수 있어 실제 사용에 적합합니다. 마지막으로, LLM 생성 합성 데이터셋을 사용하여 AHDP 메커니즘을 실증적으로 평가하고, 향후 연구를 위해 데이터셋을 공개합니다.

Abstract: Previous works in the differential privacy literature that allow users to
choose their privacy levels typically operate under the heterogeneous
differential privacy (HDP) framework with the simplifying assumption that user
data and privacy levels are not correlated. Firstly, we demonstrate that the
standard HDP framework falls short when user data and privacy demands are
allowed to be correlated. Secondly, to address this shortcoming, we propose an
alternate framework, Add-remove Heterogeneous Differential Privacy (AHDP), that
jointly accounts for user data and privacy preference. We show that AHDP is
robust to possible correlations between data and privacy. Thirdly, we formalize
the guarantees of the proposed AHDP framework through an operational hypothesis
testing perspective. The hypothesis testing setup may be of independent
interest in analyzing other privacy frameworks as well. Fourthly, we show that
there exists non-trivial AHDP mechanisms that notably do not require prior
knowledge of the data-privacy correlations. We propose some such mechanisms and
apply them to core statistical tasks such as mean estimation, frequency
estimation, and linear regression. The proposed mechanisms are simple to
implement with minimal assumptions and modeling requirements, making them
attractive for real-world use. Finally, we empirically evaluate proposed AHDP
mechanisms, highlighting their trade-offs using LLM-generated synthetic
datasets, which we release for future research.

</details>


### [8] [PromptCOS: Towards System Prompt Copyright Auditing for LLMs via Content-level Output Similarity](https://arxiv.org/abs/2509.03117)
*Yuchen Yang,Yiming Li,Hongwei Yao,Enhao Huang,Shuo Shao,Bingrun Yang,Zhibo Wang,Dacheng Tao,Zhan Qin*

Main category: cs.CR

TL;DR: 이 논문은 PromptCOS라는 시스템 프롬프트 저작권 감사 방법을 제안하며, 이는 콘텐츠 수준의 출력 유사성을 기반으로 한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 애플리케이션의 개선에 있어 시스템 프롬프트의 설계가 중요하며, 이는 저작권 도용과 남용으로 이어질 수 있다.

Method: PromptCOS는 프롬프트를 최적화하면서 특별한 확인 쿼리와 콘텐츠 수준 신호 마크를 공동 최적화하여 워터마크를 삽입하는 방법이다.

Result: 우리의 방법은 높은 효과성(99.3% 평균 워터마크 유사성), 강한 독창성(기준보다 60.8% 더 우수), 높은 신뢰성(정확도 감소 0.58% 이하), 강인성(세 가지 유형의 공격에 대한 저항력) 및 계산 효율성(98.1% 계산 비용 절감)을 달성한다.

Conclusion: PromptCOS는 콘텐츠 기반 시나리오에서 신뢰할 수 있는 감사 기능을 제공하며, GitHub에서 코드가 제공된다.

Abstract: The rapid progress of large language models (LLMs) has greatly enhanced
reasoning tasks and facilitated the development of LLM-based applications. A
critical factor in improving LLM-based applications is the design of effective
system prompts, which significantly impact the behavior and output quality of
LLMs. However, system prompts are susceptible to theft and misuse, which could
undermine the interests of prompt owners. Existing methods protect prompt
copyrights through watermark injection and verification but face challenges due
to their reliance on intermediate LLM outputs (e.g., logits), which limits
their practical feasibility.
  In this paper, we propose PromptCOS, a method for auditing prompt copyright
based on content-level output similarity. It embeds watermarks by optimizing
the prompt while simultaneously co-optimizing a special verification query and
content-level signal marks. This is achieved by leveraging cyclic output
signals and injecting auxiliary tokens to ensure reliable auditing in
content-only scenarios. Additionally, it incorporates cover tokens to protect
the watermark from malicious deletion. For copyright verification, PromptCOS
identifies unauthorized usage by comparing the similarity between the
suspicious output and the signal mark. Experimental results demonstrate that
our method achieves high effectiveness (99.3% average watermark similarity),
strong distinctiveness (60.8% greater than the best baseline), high fidelity
(accuracy degradation of no more than 0.58%), robustness (resilience against
three types of potential attacks), and computational efficiency (up to 98.1%
reduction in computational cost). Our code is available at GitHub
https://github.com/LianPing-cyber/PromptCOS.

</details>


### [9] [Tuning Block Size for Workload Optimization in Consortium Blockchain Networks](https://arxiv.org/abs/2509.03367)
*Narges Dadkhah,Somayeh Mohammadi,Gerhard Wunder*

Main category: cs.CR

TL;DR: 블록체인 시스템에서 최적의 블록 크기를 결정하는 것은 높은 처리량을 달성하는 데 필수적이다. 본 연구는 Hyperledger Fabric에 대한 이상적인 블록 크기를 결정하고 성능을 극대화하기 위한 수학적 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 블록 크기가 시스템 성능에 미치는 영향은 여전히 논란의 여지로 남아 있으며, 이는 블록체인 네트워크에서 새로운 포크가 발생하는 원인이 되기도 한다.

Method: 머신 러닝을 활용하고 유전 알고리즘으로 모델을 해결하여 블록 크기, 트랜잭션 크기, 네트워크 용량 등이 블록 처리 시간에 미치는 영향을 평가한다.

Result: 제안된 접근 방식은 배포 전에 블록 크기 구성을 정밀하게 조정할 수 있도록 하는 최적화 솔버를 통합하여 처음부터 성능을 향상시킨다.

Conclusion: 이 체계적인 접근은 블록 처리 효율성, 네트워크 대기 시간 및 시스템 처리량의 균형을 맞추어 다양한 비즈니스 맥락에서 블록체인 성능을 향상시키는 강력한 솔루션을 제공한다.

Abstract: Determining the optimal block size is crucial for achieving high throughput
in blockchain systems. Many studies have focused on tuning various components,
such as databases, network bandwidth, and consensus mechanisms. However, the
impact of block size on system performance remains a topic of debate, often
resulting in divergent views and even leading to new forks in blockchain
networks. This research proposes a mathematical model to maximize performance
by determining the ideal block size for Hyperledger Fabric, a prominent
consortium blockchain. By leveraging machine learning and solving the model
with a genetic algorithm, the proposed approach assesses how factors such as
block size, transaction size, and network capacity influence the block
processing time. The integration of an optimization solver enables precise
adjustments to block size configuration before deployment, ensuring improved
performance from the outset. This systematic approach aims to balance block
processing efficiency, network latency, and system throughput, offering a
robust solution to improve blockchain performance across diverse business
contexts.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [10] [Synthetic Founders: AI-Generated Social Simulations for Startup Validation Research in Computational Social Science](https://arxiv.org/abs/2509.02605)
*Jorn K. Teutloff*

Main category: cs.MA

TL;DR: 이 논문은 인공지능 기반 시뮬레이션에서의 충실도, 발산성 및 맹점을 평가하기 위해 인간 대상 인터뷰 데이터를 대형 언어 모델(LLM) 기반의 합성 인물과 비교하는 실험을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: AI 기반 검증에 대한 스타트업 창립자들의 희망과 우려를 조사합니다.

Method: 15명의 초기 단계 스타트업 창립자와 AI 생성 창립자 및 투자자의 성격으로 같은 프로토콜을 반복하여 구조화된 주제 합성을 수행했습니다.

Result: 4개의 결과 범주가 도출되었습니다: 1) 수렴 테마, 2) 부분적 겹침, 3) 인간 전용 테마, 4) 합성 전용 테마.

Conclusion: LLM 기반 인물은 경험적 연구를 대체하는 것이 아니라 보완적인 시뮬레이션 카테고리로 작용한다고 주장하며, 가설 범위를 확장하고 탐색적 검증을 가속화합니다.

Abstract: We present a comparative docking experiment that aligns human-subject
interview data with large language model (LLM)-driven synthetic personas to
evaluate fidelity, divergence, and blind spots in AI-enabled simulation.
Fifteen early-stage startup founders were interviewed about their hopes and
concerns regarding AI-powered validation, and the same protocol was replicated
with AI-generated founder and investor personas. A structured thematic
synthesis revealed four categories of outcomes: (1) Convergent themes -
commitment-based demand signals, black-box trust barriers, and efficiency gains
were consistently emphasized across both datasets; (2) Partial overlaps -
founders worried about outliers being averaged away and the stress of real
customer validation, while synthetic personas highlighted irrational blind
spots and framed AI as a psychological buffer; (3) Human-only themes -
relational and advocacy value from early customer engagement and skepticism
toward moonshot markets; and (4) Synthetic-only themes - amplified false
positives and trauma blind spots, where AI may overstate adoption potential by
missing negative historical experiences.
  We interpret this comparative framework as evidence that LLM-driven personas
constitute a form of hybrid social simulation: more linguistically expressive
and adaptable than traditional rule-based agents, yet bounded by the absence of
lived history and relational consequence. Rather than replacing empirical
studies, we argue they function as a complementary simulation category -
capable of extending hypothesis space, accelerating exploratory validation, and
clarifying the boundaries of cognitive realism in computational social science.

</details>


### [11] [Automatic Differentiation of Agent-Based Models](https://arxiv.org/abs/2509.03303)
*Arnau Quera-Bofarull,Nicholas Bishop,Joel Dyer,Daniel Jarne Ornia,Anisoara Calinescu,Doyne Farmer,Michael Wooldridge*

Main category: cs.MA

TL;DR: 이 논문은 자동 미분 기법이 에이전트 기반 모델(ABM)의 계산 부담을 줄이고, 매개변수 보정 및 민감도 분석을 쉽게 한다는 것을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 시스템을 효과적으로 연구하기 위해 ABM의 실용성과 확장성을 향상시키려는 동기.

Method: 자동 미분 기법을 ABM에 적용하여 시뮬레이터의 그래디언트를 제공하고, 이를 통해 효율적인 매개변수 보정과 변분 추론 기술을 가능하게 함.

Result: 세 가지 주요 ABM에서 VI 기법을 사용하여 상당한 성능 개선과 계산 절감을 입증.

Conclusion: 이 접근법은 복잡한 시스템 연구를 위한 ABM의 실용성과 확장성을 크게 향상시킴.

Abstract: Agent-based models (ABMs) simulate complex systems by capturing the bottom-up
interactions of individual agents comprising the system. Many complex systems
of interest, such as epidemics or financial markets, involve thousands or even
millions of agents. Consequently, ABMs often become computationally demanding
and rely on the calibration of numerous free parameters, which has
significantly hindered their widespread adoption. In this paper, we demonstrate
that automatic differentiation (AD) techniques can effectively alleviate these
computational burdens. By applying AD to ABMs, the gradients of the simulator
become readily available, greatly facilitating essential tasks such as
calibration and sensitivity analysis. Specifically, we show how AD enables
variational inference (VI) techniques for efficient parameter calibration. Our
experiments demonstrate substantial performance improvements and computational
savings using VI on three prominent ABMs: Axtell's model of firms; Sugarscape;
and the SIR epidemiological model. Our approach thus significantly enhances the
practicality and scalability of ABMs for studying complex systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [Population-aware Online Mirror Descent for Mean-Field Games with Common Noise by Deep Reinforcement Learning](https://arxiv.org/abs/2509.03030)
*Zida Wu,Mathieu Lauriere,Matthieu Geist,Olivier Pietquin,Ankur Mehta*

Main category: cs.LG

TL;DR: 이 논문에서는 대규모 다중 에이전트 시스템을 위한 Mean Field Games (MFG)에서 인구 의존적 내쉬 균형을 효율적으로 학습할 수 있는 딥 강화 학습 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: MFG에서 내쉬 균형 학습은 초기 분포가 알려지지 않거나 공통 노이즈가 존재할 때 도전적인 문제이다.

Method: Munchausen RL과 Online Mirror Descent에 영감을 받아, 평균화나 역사적 샘플링에 의존하지 않고 인구 의존적 내쉬 균형을 달성하는 딥 강화 학습 알고리즘을 설계하였다.

Result: 수치 실험을 통해 우리의 알고리즘이 최신 알고리즘, 특히 인구 의존적 정책을 위한 Fictitious Play의 DRL 버전과 비교하여 우수한 수렴 속성을 보임을 보여주었다.

Conclusion: 공통 노이즈가 있는 경우에도 우리의 접근 방식의 강건성과 적응성을 강조하였다.

Abstract: Mean Field Games (MFGs) offer a powerful framework for studying large-scale
multi-agent systems. Yet, learning Nash equilibria in MFGs remains a
challenging problem, particularly when the initial distribution is unknown or
when the population is subject to common noise. In this paper, we introduce an
efficient deep reinforcement learning (DRL) algorithm designed to achieve
population-dependent Nash equilibria without relying on averaging or historical
sampling, inspired by Munchausen RL and Online Mirror Descent. The resulting
policy is adaptable to various initial distributions and sources of common
noise. Through numerical experiments on seven canonical examples, we
demonstrate that our algorithm exhibits superior convergence properties
compared to state-of-the-art algorithms, particularly a DRL version of
Fictitious Play for population-dependent policies. The performance in the
presence of common noise underscores the robustness and adaptability of our
approach.

</details>


### [13] [Latent Variable Modeling in Multi-Agent Reinforcement Learning via Expectation-Maximization for UAV-Based Wildlife Protection](https://arxiv.org/abs/2509.02579)
*Mazyar Taghavi,Rahman Farnoosh*

Main category: cs.LG

TL;DR: 본 논문은 야생동물 보호를 위한 다중 에이전트 강화 학습에서 새로운 EM 기반 잠재 변수 모델링 접근 방식을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 불법 밀렵으로부터 멸종 위기 야생동물을 보호하는 것은 중요한 도전 과제이며, 중요성이 크고 부분적으로 관찰 가능한 환경에서 실시간 대응이 필수적입니다.

Method: 우리는 환경의 숨겨진 요소와 에이전트 간 동역학을 잠재 변수를 통해 모델링함으로써 불확실한 상황에서 탐색 및 조정을 향상시키는 EM-MARL 프레임워크를 구현하고 평가했습니다.

Result: 10대의 UAV가 이란 표범의 보호된 서식지를 순찰하는 커스텀 시뮬레이션을 사용한 결과, 탐지 정확성, 적응성 및 정책 수렴에서 Proximal Policy Optimization (PPO) 및 Deep Deterministic Policy Gradient (DDPG)과 같은 표준 알고리즘에 비해 우수한 성능을 보였습니다.

Conclusion: EM 추론과 MARL을 결합하여 복잡하고 높은 위험의 보전 시나리오에서 분산된 의사 결정을 개선할 수 있는 가능성을 강조합니다.

Abstract: Protecting endangered wildlife from illegal poaching presents a critical
challenge, particularly in vast and partially observable environments where
real-time response is essential. This paper introduces a novel
Expectation-Maximization (EM) based latent variable modeling approach in the
context of Multi-Agent Reinforcement Learning (MARL) for Unmanned Aerial
Vehicle (UAV) coordination in wildlife protection. By modeling hidden
environmental factors and inter-agent dynamics through latent variables, our
method enhances exploration and coordination under uncertainty.We implement and
evaluate our EM-MARL framework using a custom simulation involving 10 UAVs
tasked with patrolling protected habitats of the endangered Iranian leopard.
Extensive experimental results demonstrate superior performance in detection
accuracy, adaptability, and policy convergence when compared to standard
algorithms such as Proximal Policy Optimization (PPO) and Deep Deterministic
Policy Gradient (DDPG). Our findings underscore the potential of combining EM
inference with MARL to improve decentralized decisionmaking in complex,
high-stakes conservation scenarios. The full implementation, simulation
environment, and training scripts are publicly available on GitHub.

</details>


### [14] [A Hierarchical Deep Reinforcement Learning Framework for Traffic Signal Control with Predictable Cycle Planning](https://arxiv.org/abs/2509.03118)
*Hankang Gu,Yuli Zhang,Chengming Wang,Ruiyuan Jiang,Ziheng Qiao,Pengfei Fan,Dongyao Jia*

Main category: cs.LG

TL;DR: 본 논문에서는 교통 신호 주기 지속 시간을 계층적으로 할당하는 딥 강화 학습 모델인 Deep Hierarchical Cycle Planner (DHCP)를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 교통 환경에서 적응형 정책을 학습할 수 있는 딥 강화 학습(DRL)이 교통 신호 제어(TSC)에서 중요한 접근 조치로 자리 잡고 있습니다.

Method: DHCP라는 DRL 모델을 제안하며, 고수준 에이전트가 전체 cycle 시간을 북남(NS) 및 동서(EW) 방향 간에 분할하고, 저수준 에이전트가 각 주요 방향 내에서 직진 및 좌회전 동작 간에 할당된 지속 시간을 추가로 나눕니다.

Result: 모델을 실제 및 합성 도로 네트워크와 함께 여러 세트의 실제 및 합성 교통 흐름에 대해 시험해 본 결과, 모든 데이터셋에서 기본선 대비 최고의 성능을 달성했습니다.

Conclusion: 기존의 TSC 접근 방식의 한계를 벗어나, 우리 모델은 더 유연한 동작 지속 시간 배분을 가능하게 하고, 교차로 안전성을 향상시킵니다.

Abstract: Deep reinforcement learning (DRL) has become a popular approach in traffic
signal control (TSC) due to its ability to learn adaptive policies from complex
traffic environments. Within DRL-based TSC methods, two primary control
paradigms are ``choose phase" and ``switch" strategies. Although the agent in
the choose phase paradigm selects the next active phase adaptively, this
paradigm may result in unexpected phase sequences for drivers, disrupting their
anticipation and potentially compromising safety at intersections. Meanwhile,
the switch paradigm allows the agent to decide whether to switch to the next
predefined phase or extend the current phase. While this structure maintains a
more predictable order, it can lead to unfair and inefficient phase
allocations, as certain movements may be extended disproportionately while
others are neglected. In this paper, we propose a DRL model, named Deep
Hierarchical Cycle Planner (DHCP), to allocate the traffic signal cycle
duration hierarchically. A high-level agent first determines the split of the
total cycle time between the North-South (NS) and East-West (EW) directions
based on the overall traffic state. Then, a low-level agent further divides the
allocated duration within each major direction between straight and left-turn
movements, enabling more flexible durations for the two movements. We test our
model on both real and synthetic road networks, along with multiple sets of
real and synthetic traffic flows. Empirical results show our model achieves the
best performance over all datasets against baselines.

</details>


### [15] [Power Grid Control with Graph-Based Distributed Reinforcement Learning](https://arxiv.org/abs/2509.02861)
*Carlo Fabrizio,Gianvito Losapio,Marco Mussi,Alberto Maria Metelli,Marcello Restelli*

Main category: cs.LG

TL;DR: 이 논문은 재생 가능 에너지 통합과 전력망 확장으로 인한 현대 전력망 제어의 도전 과제를 다루며, 그래프 기반 분산 강화 학습 프레임워크를 통해 실시간 조정이 가능하도록 한다.


<details>
  <summary>Details</summary>
Motivation: 재생 가능 에너지 통합과 전력망의 확장은 현대 전력망 제어에 많은 도전 과제를 안겨준다.

Method: 이 연구는 분산 저수준 에이전트와 고수준 관리자 에이전트로 구성된 그래프 기반 분산 강화 학습 프레임워크를 제안한다.

Result: 그리드2Op 시뮬레이션 환경에서 실험한 결과, 제안된 접근 방식이 일반적으로 채택되는 표준 기준을 지속적으로 초과하는 효과를 보였다.

Conclusion: 제안된 모델은 시뮬레이션 기반 전문가 방법보다 훨씬 더 계산적으로 효율적임을 입증하였다.

Abstract: The necessary integration of renewable energy sources, combined with the
expanding scale of power networks, presents significant challenges in
controlling modern power grids. Traditional control systems, which are human
and optimization-based, struggle to adapt and to scale in such an evolving
context, motivating the exploration of more dynamic and distributed control
strategies. This work advances a graph-based distributed reinforcement learning
framework for real-time, scalable grid management. The proposed architecture
consists of a network of distributed low-level agents acting on individual
power lines and coordinated by a high-level manager agent. A Graph Neural
Network (GNN) is employed to encode the network's topological information
within the single low-level agent's observation. To accelerate convergence and
enhance learning stability, the framework integrates imitation learning and
potential-based reward shaping. In contrast to conventional decentralized
approaches that decompose only the action space while relying on global
observations, this method also decomposes the observation space. Each low-level
agent acts based on a structured and informative local view of the environment
constructed through the GNN. Experiments on the Grid2Op simulation environment
show the effectiveness of the approach, which consistently outperforms the
standard baseline commonly adopted in the field. Additionally, the proposed
model proves to be much more computationally efficient than the
simulation-based Expert method.

</details>


### [16] [Enhancing Machine Learning for Imbalanced Medical Data: A Quantum-Inspired Approach to Synthetic Oversampling (QI-SMOTE)](https://arxiv.org/abs/2509.02863)
*Vikas Kashtriya,Pardeep Singh*

Main category: cs.LG

TL;DR: 양자 기반 SMOTE(QI-SMOTE)는 의료 데이터의 클래스 불균형 문제를 해결하고 머신러닝 모델의 성능을 향상시키기 위한 새로운 데이터 증강 기법입니다.


<details>
  <summary>Details</summary>
Motivation: 의료 분야에서 클래스 불균형은 모델의 편향과 예측 성능 저하를 초래하는 중요한 도전 과제로 남아 있습니다.

Method: QI-SMOTE는 양자 진화 및 층상 얽힘과 같은 양자 원리를 활용하여 복잡한 데이터 구조를 보존하는 합성 인스턴스를 생성하는 새로운 데이터 증강 기법입니다.

Result: MIMIC-III 및 MIMIC-IV 데이터셋에서 QI-SMOTE의 유효성을 검증한 결과, 전통적인 오버샘플링 기법에 비해 성능 지표에서 유의미한 향상을 보여주었습니다.

Conclusion: QI-SMOTE는 의료 진단 및 의사결정에서 예측 모델의 강건성과 신뢰성을 향상시키며, 최첨단 머신러닝 방법론을 발전시킬 수 있는 잠재력을 강조합니다.

Abstract: Class imbalance remains a critical challenge in machine learning (ML),
particularly in the medical domain, where underrepresented minority classes
lead to biased models and reduced predictive performance. This study introduces
Quantum-Inspired SMOTE (QI-SMOTE), a novel data augmentation technique that
enhances the performance of ML classifiers, including Random Forest (RF),
Support Vector Machine (SVM), Logistic Regression (LR), k-Nearest Neighbors
(KNN), Gradient Boosting (GB), and Neural Networks, by leveraging quantum
principles such as quantum evolution and layered entanglement. Unlike
conventional oversampling methods, QI-SMOTE generates synthetic instances that
preserve complex data structures, improving model generalization and
classification accuracy. We validate QI-SMOTE on the MIMIC-III and MIMIC-IV
datasets, using mortality detection as a benchmark task due to their clinical
significance and inherent class imbalance. We compare our method against
traditional oversampling techniques, including Borderline-SMOTE, ADASYN,
SMOTE-ENN, SMOTE-TOMEK, and SVM-SMOTE, using key performance metrics such as
Accuracy, F1-score, G-Mean, and AUC-ROC. The results demonstrate that QI-SMOTE
significantly improves the effectiveness of ensemble methods (RF, GB, ADA),
kernel-based models (SVM), and deep learning approaches by producing more
informative and balanced training data. By integrating quantum-inspired
transformations into the ML pipeline, QI-SMOTE not only mitigates class
imbalance but also enhances the robustness and reliability of predictive models
in medical diagnostics and decision-making. This study highlights the potential
of quantum-inspired resampling techniques in advancing state-of-the-art ML
methodologies.

</details>


### [17] [Improving Generative Methods for Causal Evaluation via Simulation-Based Inference](https://arxiv.org/abs/2509.02892)
*Pracheta Amaranath,Vinitra Muralikrishnan,Amit Sharma,David D. Jensen*

Main category: cs.LG

TL;DR: 합성 데이터셋을 생성하여 인과 추정기를 평가하는 것은 중요하지만 어려운 과제입니다. 기존 방법은 인과 평가를 위한 불확실한 생성 매개변수를 모델링하여 소스 데이터에 따라 적절한 합성 데이터셋을 생성합니다.


<details>
  <summary>Details</summary>
Motivation: 합성 데이터셋을 생성하여 인과 추정기의 평가를 지원하는 방법론의 필요성을 강조합니다.

Method: SBICE 프레임워크는 생성 매개변수를 불확실한 것으로 모델링하고 소스 데이터셋을 기반으로 후향 분포를 추론하여 합성 데이터셋을 생성합니다.

Result: SBICE는 소스 데이터 배포와 밀접하게 정렬된 합성 데이터셋을 생성하여 추정기 평가의 신뢰성을 향상시킵니다.

Conclusion: SBICE는 불확실성 하에서 인과 벤치마킹을 위한 강력하고 데이터 일관된 접근 방식을 지원합니다.

Abstract: Generating synthetic datasets that accurately reflect real-world
observational data is critical for evaluating causal estimators, but remains a
challenging task. Existing generative methods offer a solution by producing
synthetic datasets anchored in the observed data (source data) while allowing
variation in key parameters such as the treatment effect and amount of
confounding bias. However, existing methods typically require users to provide
point estimates of such parameters (rather than distributions) and fixed
estimates (rather than estimates that can be improved with reference to the
source data). This denies users the ability to express uncertainty over
parameter values and removes the potential for posterior inference, potentially
leading to unreliable estimator comparisons. We introduce simulation-based
inference for causal evaluation (SBICE), a framework that models generative
parameters as uncertain and infers their posterior distribution given a source
dataset. Leveraging techniques in simulation-based inference, SBICE identifies
parameter configurations that produce synthetic datasets closely aligned with
the source data distribution. Empirical results demonstrate that SBICE improves
the reliability of estimator evaluations by generating more realistic datasets,
which supports a robust and data-consistent approach to causal benchmarking
under uncertainty.

</details>


### [18] [VendiRL: A Framework for Self-Supervised Reinforcement Learning of Diversely Diverse Skills](https://arxiv.org/abs/2509.02930)
*Erik M. Lintunen*

Main category: cs.LG

TL;DR: 이 논문에서는 자기 지도 강화 학습에서의 기술 다양성을 평가하는 새로운 방법으로 Vendi Score를 제안하고, 이를 통해 다양한 기술 집합을 학습하는 VendiRL 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 자기 지도 강화 학습에서 에이전트가 미래의 다양한 작업을 준비하기 위해 다양한 기술 세트를 학습하는 것이 중요하지만, 기술 다양성을 정의하고 평가하는 데 여러 도전 과제가 있다.

Method: 생태학에서 아이디어를 차용하여 기술 다양성의 척도로 Vendi Score를 정의하고, 이를 통해 사용자 지정이 가능한 다양성을 평가한다. VendiRL이라는 통합 프레임워크를 개발하여 다양한 기술 세트를 학습할 수 있도록 한다.

Result: Vendi Score를 사용하여 기술 평가를 용이하게 하고, 다양한 유사성 함수에 따라 다양한 형태의 기술 다양성을 동기부여하여, 다양한 환경에서 기술-다양성 선행 학습을 지원할 수 있는 가능성을 보여준다.

Conclusion: 제안된 방법은 다양한 기술 학습의 새로운 지평을 열며, 다양한 형태의 다양성을 최적화할 수 있는 가능성을 제시한다.

Abstract: In self-supervised reinforcement learning (RL), one of the key challenges is
learning a diverse set of skills to prepare agents for unknown future tasks.
Despite impressive advances, scalability and evaluation remain prevalent
issues. Regarding scalability, the search for meaningful skills can be obscured
by high-dimensional feature spaces, where relevant features may vary across
downstream task domains. For evaluating skill diversity, defining what
constitutes "diversity" typically requires a hard commitment to a specific
notion of what it means for skills to be diverse, potentially leading to
inconsistencies in how skill diversity is understood, making results across
different approaches hard to compare, and leaving many forms of diversity
unexplored. To address these issues, we adopt a measure of sample diversity
that translates ideas from ecology to machine learning -- the Vendi Score --
allowing the user to specify and evaluate any desired form of diversity. We
demonstrate how this metric facilitates skill evaluation and introduce VendiRL,
a unified framework for learning diversely diverse sets of skills. Given
distinct similarity functions, VendiRL motivates distinct forms of diversity,
which could support skill-diversity pretraining in new and richly interactive
environments where optimising for various forms of diversity may be desirable.

</details>


### [19] [StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails](https://arxiv.org/abs/2509.02982)
*Hritik Arasu,Faisal R Jahangiri*

Main category: cs.LG

TL;DR: 이 논문은 환자의 생리학적 또는 기록 조건이 보이지 않는 경우 수면 단계 모델이 저하되는 문제를 해결하기 위한 적응 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 수면 단계 모델은 보이지 않는 생리학적 조건 또는 기록 조건이 있는 환자에게 배포할 때 종종 성능이 저하된다.

Method: 우리는 엔트로피 최소화(Tent)와 배치 정규화 통계 새로 고침, 불확실한 구간에서 적응을 일시 중지하는 엔트로피 게이트, 드리프트를 줄이기 위한 EMA 기반 리셋을 결합한 실시간 소스 없는 테스트 시간 적응(TTA) 방법을 제안한다.

Result: Sleep-EDF Expanded 데이터셋에서 단일 리드 EEG(Fpz-Cz, 100 Hz, 30초 에포크; R&K에서 AASM 맵핑)를 사용하여, 프리징된 기준선에 비해 일관된 성능 향상을 보였으며, 초 단위 지연과 최소 메모리로 단계별 메트릭과 Cohen의 k를 보고하였다.

Conclusion: 이 방법은 모델에 의존하지 않으며, 소스 데이터나 환자 교정이 필요 없고, 장치나 침대 옆에서의 실용적인 사용이 가능하다.

Abstract: Sleep staging models often degrade when deployed on patients with unseen
physiology or recording conditions. We propose a streaming, source-free
test-time adaptation (TTA) recipe that combines entropy minimization (Tent)
with Batch-Norm statistic refresh and two safety rails: an entropy gate to
pause adaptation on uncertain windows and an EMA-based reset to reel back
drift. On Sleep-EDF Expanded, using single-lead EEG (Fpz-Cz, 100 Hz, 30s
epochs; R&K to AASM mapping), we show consistent gains over a frozen baseline
at seconds-level latency and minimal memory, reporting per-stage metrics and
Cohen's k. The method is model-agnostic, requires no source data or patient
calibration, and is practical for on-device or bedside use.

</details>


### [20] [Multimodal learning of melt pool dynamics in laser powder bed fusion](https://arxiv.org/abs/2509.03029)
*Satyajit Mojumder,Pallock Halder,Tiana Tonge*

Main category: cs.LG

TL;DR: 본 논문에서는 고비용의 X-ray 데이터를 저비용의 흡수도를 결합하여 용융 풀 동역학을 예측하는 다중 모드 데이터 융합 접근법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 센서를 이용한 실시간 모니터링에서 모든 센서가 실용적이거나 신뢰할 수 있는 공정 통찰을 제공하지 않음.

Method: 고충실도의 X-ray 데이터와 저충실도의 흡수도 데이터를 결합한 다중 모드 학습 프레임워크를 제안하며, CNN과 RNN을 사용하여 공간 및 시간적 특징을 추출하고 초기 융합 전략을 사용함.

Result: 두 가지 모드를 함께 훈련하면 예측 정확도가 크게 향상되며, 훈련된 모델은 저비용의 흡수도 데이터만으로 용융 풀 특성을 유추할 수 있음.

Conclusion: 이 다중 모드 융합 접근법은 비용 효과적인 실시간 모니터링을 가능하게 하며, 적층 제조에서 폭넓게 적용될 수 있음.

Abstract: While multiple sensors are used for real-time monitoring in additive
manufacturing, not all provide practical or reliable process insights. For
example, high-speed X-ray imaging offers valuable spatial information about
subsurface melt pool behavior but is costly and impractical for most industrial
settings. In contrast, absorptivity data from low-cost photodiodes correlate
with melt pool dynamics but is often too noisy for accurate prediction when
used alone. In this paper, we propose a multimodal data fusion approach for
predicting melt pool dynamics by combining high-fidelity X-ray data with
low-fidelity absorptivity data in the Laser Powder Bed Fusion (LPBF) process.
Our multimodal learning framework integrates convolutional neural networks
(CNNs) for spatial feature extraction from X-ray data with recurrent neural
networks (RNNs) for temporal feature extraction from absorptivity signals,
using an early fusion strategy. The multimodal model is further used as a
transfer learning model to fine-tune the RNN model that can predict melt pool
dynamics only with absorptivity, with greater accuracy compared to the
multimodal model. Results show that training with both modalities significantly
improves prediction accuracy compared to using either modality alone.
Furthermore, once trained, the model can infer melt pool characteristics using
only absorptivity data, eliminating the need for expensive X-ray imaging. This
multimodal fusion approach enables cost-effective, real-time monitoring and has
broad applicability in additive manufacturing.

</details>


### [21] [Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers](https://arxiv.org/abs/2509.03059)
*Xingyue Huang,Rishabh,Gregor Franke,Ziyi Yang,Jiamu Bai,Weijie Bai,Jinhe Bi,Zifeng Ding,Yiqun Duan,Chengyu Fan,Wendong Fan,Xin Gao,Ruohao Guo,Yuan He,Zhuangzhuang He,Xianglong Hu,Neil Johnson,Bowen Li,Fangru Lin,Siyu Lin,Tong Liu,Yunpu Ma,Hao Shen,Hao Sun,Beibei Wang,Fangyijie Wang,Hao Wang,Haoran Wang,Yang Wang,Yifeng Wang,Zhaowei Wang,Ziyang Wang,Yifan Wu,Zikai Xiao,Chengxing Xie,Fan Yang,Junxiao Yang,Qianshuo Ye,Ziyu Ye,Guangtao Zeng,Yuwen Ebony Zhang,Zeyu Zhang,Zihao Zhu,Bernard Ghanem,Philip Torr,Guohao Li*

Main category: cs.LG

TL;DR: Loong Project는 다양한 추론 집약적 도메인에서 대규모 합성 데이터 생성 및 검증을 위한 오픈 소스 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 추론 능력을 강화된 학습으로 향상시키는 것이 유망하지만, 고품질의 검증 가능한 데이터셋 부족과 인간 감독의 높은 비용이 도전을 안겨준다.

Method: LoongBench와 LoongEnv라는 두 가지 핵심 구성 요소로 이루어진 프레임워크를 통해 합성 데이터를 생성하고 검증한다.

Result: LoongBench는 폭넓은 도메인을 아우르는 인간 검증 사례로 구축되어 있으며, LoongEnv는 다양한 질문-답변-코드 삼중항을 생산하기 위한 모듈식 환경이다.

Conclusion: 이 프레임워크를 활용하여 LLM 기반 에이전트가 코드 실행 답변과 일치하는 Chain-of-Thought 솔루션을 생성하여 보상을 받을 수 있는 환경을 조성한다.

Abstract: Recent advances in Large Language Models (LLMs) have shown that their
reasoning capabilities can be significantly improved through Reinforcement
Learning with Verifiable Reward (RLVR), particularly in domains like
mathematics and programming, where ground-truth correctness can be
automatically evaluated. However, extending this success to other
reasoning-intensive domains remains challenging due to the scarcity of
high-quality, verifiable datasets and the high cost of human supervision. In
this work, we introduce the Loong Project: an open-source framework for
scalable synthetic data generation and verification across a diverse range of
reasoning-intensive domains. The framework consists of two key components: (1)
LoongBench, a curated seed dataset containing 8,729 human-vetted examples
across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired
with executable code and rich metadata; and (2) LoongEnv, a modular synthetic
data generation environment that supports multiple prompting strategies to
produce new question-answer-code triples. Together, these components form an
agent-environment loop that enables reinforcement learning, where an LLM-based
agent is rewarded for generating Chain-of-Thought (CoT) solutions that align
with code-executed answers. Empirically, we benchmark LoongBench on a broad
suite of both open-source and proprietary LLMs to evaluate domain coverage and
reveal performance bottlenecks. In addition, we conduct a comprehensive
analysis of synthetic data generated by LoongEnv, examining correctness,
difficulty, and diversity. Code and documentation are available at
https://github.com/camel-ai/loong.

</details>


### [22] [Systematic Evaluation of Attribution Methods: Eliminating Threshold Bias and Revealing Method-Dependent Performance Patterns](https://arxiv.org/abs/2509.03176)
*Serra Aksoy*

Main category: cs.LG

TL;DR: 기존의 기준 임계값에 의존하는 방법들은 신경망 예측을 설명할 때 선택 편향으로 인해 잘못된 결과를 낳을 수 있다. 본 연구는 임계값에 의존하지 않는 AUC-IoU 프레임워크를 제시하며, 이를 통해 다양한 신속성을 평가하고, XRAI는 LIME보다 31%, 기본 Integrated Gradients보다 204% 향상된 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 신경망 예측을 설명할 때 입력 특징의 중요성을 식별하는 기여 방법들이 있지만, 이들 평가 방법은 기준 임계값 선택 편향의 문제로 인해 순위를 반전시키고 결론을 왜곡할 수 있다.

Method: 임계값 없는 AUC-IoU 프레임워크를 활용하여 전체 임계값 스펙트럼에 걸쳐 기여 품질을 평가한다.

Result: 일곱 가지 기여 방법을 피부학적 이미징에 대해 평가한 결과, 단일 임계값 메트릭은 상충되는 결과를 나타내는 반면, 임계값 없는 평가는 신뢰할 수 있는 차별화를 제공한다. XRAI는 LIME보다 31%, 기본 통합 그래디언트보다 204% 향상된 성능을 보였고, 크기 계층화 분석은 병변 크기에 따라 최대 269%까지 성능 변동을 나타냈다.

Conclusion: 본 연구 결과는 평가 인위성을 제거하고 근거 기반 방법 선택을 가능하게 하는 방법론적 기준을 확립하며, 임계값 없는 프레임워크는 기여 행동에 대한 이론적 통찰과 의료 이미징 및 그 이상의 분야에서 견고한 비교를 위한 실용적인 지침을 제공한다.

Abstract: Attribution methods explain neural network predictions by identifying
influential input features, but their evaluation suffers from threshold
selection bias that can reverse method rankings and undermine conclusions.
Current protocols binarize attribution maps at single thresholds, where
threshold choice alone can alter rankings by over 200 percentage points. We
address this flaw with a threshold-free framework that computes Area Under the
Curve for Intersection over Union (AUC-IoU), capturing attribution quality
across the full threshold spectrum. Evaluating seven attribution methods on
dermatological imaging, we show single-threshold metrics yield contradictory
results, while threshold-free evaluation provides reliable differentiation.
XRAI achieves 31% improvement over LIME and 204% over vanilla Integrated
Gradients, with size-stratified analysis revealing performance variations up to
269% across lesion scales. These findings establish methodological standards
that eliminate evaluation artifacts and enable evidence-based method selection.
The threshold-free framework provides both theoretical insight into attribution
behavior and practical guidance for robust comparison in medical imaging and
beyond.

</details>


### [23] [Autonomous Learning From Success and Failure: Goal-Conditioned Supervised Learning with Negative Feedback](https://arxiv.org/abs/2509.03206)
*Zeqiang Zhang,Fabian Wurzberger,Gerrit Schmid,Sebastian Gottwald,Daniel A. Braun*

Main category: cs.LG

TL;DR: 이 논문은 Goal-Conditioned Supervised Learning(GCSL) 프레임워크에 대조 학습 원칙을 통합하여 성공과 실패 모두에서 학습하는 새로운 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습은 희소 보상 구조를 가진 작업에 적용할 때 큰 도전에 직면합니다. 인간이 생성한 시연에 크게 의존하는 모방 학습은 더 빠른 수렴을 제공합니다. GCSL은 자율 시스템을 위한 자기 모방 학습을 가능하게 하여 이러한 문제를 해결할 수 있는 가능성이 있습니다.

Method: 대조 학습 원칙을 GCSL 프레임워크에 통합하여 성공과 실패 모두에서 학습하는 새로운 모델을 제안하였습니다.

Result: 우리 알고리즘이 에이전트의 초기 편향에 의해 부과된 한계를 극복하고 더 탐구적인 행동을 가능하게 함을 보여주었습니다.

Conclusion: 이는 효율적인 정책을 식별하고 채택하는 데 도움이 되어 다양한 도전 환경에서 뛰어난 성능을 발휘하는 결과를 가져왔습니다.

Abstract: Reinforcement learning faces significant challenges when applied to tasks
characterized by sparse reward structures. Although imitation learning, within
the domain of supervised learning, offers faster convergence, it relies heavily
on human-generated demonstrations. Recently, Goal-Conditioned Supervised
Learning (GCSL) has emerged as a potential solution by enabling self-imitation
learning for autonomous systems. By strategically relabelling goals, agents can
derive policy insights from their own experiences. Despite the successes of
this framework, it presents two notable limitations: (1) Learning exclusively
from self-generated experiences can exacerbate the agents' inherent biases; (2)
The relabelling strategy allows agents to focus solely on successful outcomes,
precluding them from learning from their mistakes. To address these issues, we
propose a novel model that integrates contrastive learning principles into the
GCSL framework to learn from both success and failure. Through empirical
evaluations, we demonstrate that our algorithm overcomes limitations imposed by
agents' initial biases and thereby enables more exploratory behavior. This
facilitates the identification and adoption of effective policies, leading to
superior performance across a variety of challenging environments.

</details>


### [24] [EvolveSignal: A Large Language Model Powered Coding Agent for Discovering Traffic Signal Control Algorithms](https://arxiv.org/abs/2509.03335)
*Leizhen Wang,Peibo Duan,Hao Wang,Yue Wang,Jian Xu,Nan Zheng,Zhenliang Ma*

Main category: cs.LG

TL;DR: 이 논문은 EvolveSignal이라는 대형 언어 모델 기반의 자동 트래픽 신호 제어 알고리즘 발견 에이전트를 도입합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 고정형 트래픽 신호 제어는 저비용과 안정성으로 널리 사용되지만 수작업에 의존하여 최적이 아닌 결과를 초래할 수 있습니다.

Method: 문제를 프로그램 합성으로 공식화하고, 후보 알고리즘을 고정 입력-출력 구조를 가진 파이썬 함수로 표현하여 외부 평가와 진화적 검색을 통해 반복적으로 최적화합니다.

Result: 발견된 알고리즘이 Webster의 기준보다 평균 지연을 20.1% 줄이고 평균 정지를 47.1% 감소시켰습니다.

Conclusion: EvolveSignal은 트래픽 신호 제어 알고리즘 디자인에 AI를 활용하는 새로운 연구 방향을 열어줍니다.

Abstract: In traffic engineering, the fixed-time traffic signal control remains widely
used for its low cost, stability, and interpretability. However, its design
depends on hand-crafted formulas (e.g., Webster) and manual re-timing by
engineers to adapt to demand changes, which is labor-intensive and often yields
suboptimal results under heterogeneous or congested conditions. This paper
introduces the EvolveSignal, a large language models (LLMs) powered coding
agent to automatically discover new traffic signal control algorithms. We
formulate the problem as program synthesis, where candidate algorithms are
represented as Python functions with fixed input-output structures, and
iteratively optimized through external evaluations (e.g., a traffic simulator)
and evolutionary search. Experiments on a signalized intersection demonstrate
that the discovered algorithms outperform Webster's baseline, reducing average
delay by 20.1% and average stops by 47.1%. Beyond performance, ablation and
incremental analyses reveal that EvolveSignal modifications-such as adjusting
cycle length bounds, incorporating right-turn demand, and rescaling green
allocations-can offer practically meaningful insights for traffic engineers.
This work opens a new research direction by leveraging AI for algorithm design
in traffic signal control, bridging program synthesis with transportation
engineering.

</details>


### [25] [Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems](https://arxiv.org/abs/2509.03340)
*Fleur Hendriks,Ondřej Rokoš,Martin Doškář,Marc G. D. Geers,Vlado Menkovski*

Main category: cs.LG

TL;DR: 비선형 동적 시스템에서의 분기 현상은 여러 안정적인 해를 만들어내며, 기계 학습 모델은 이를 제대로 포착하지 못한다. 본 연구에서는 분기 결과에 대한 전체 확률 분포를 모델링하기 위한 생성적 프레임워크를 제안한다. 이 방법은 시스템 대칭을 유지하면서 여러 유효한 해를 직접 샘플링할 수 있게 한다. 우리의 접근 방식은 다양한 시스템에서 검증되었으며, 고차원 시스템에서 다중 안정성을 모델링하기 위한 합리적이고 확장 가능한 솔루션을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 분기 현상에서 여러 안정적인 해가 공존하는 경우가 많으며, 기존의 결정론적 기계 학습 모델이 이를 적절히 포착하지 못하는 문제를 해결하고자 한다.

Method: 흐름 일치를 기반으로 하는 생성적 프레임워크를 제안하여 분기 결과에 대한 전체 확률 분포를 모델링한다.

Result: 우리의 방법은 시스템의 대칭을 유지하면서도 여러 유효한 해를 직접 샘플링하는 능력을 보여주었으며, 다양한 시스템에 대해 검증되었다.

Conclusion: 흐름 일치 방법이 비확률적 및 변분 방법보다 다중 모드 분포와 대칭 파괴 분기를 포착하는 데 훨씬 우수하다는 것을 보여준다.

Abstract: Bifurcation phenomena in nonlinear dynamical systems often lead to multiple
coexisting stable solutions, particularly in the presence of symmetry breaking.
Deterministic machine learning models struggle to capture this multiplicity,
averaging over solutions and failing to represent lower-symmetry outcomes. In
this work, we propose a generative framework based on flow matching to model
the full probability distribution over bifurcation outcomes. Our method enables
direct sampling of multiple valid solutions while preserving system symmetries
through equivariant modeling. We introduce a symmetric matching strategy that
aligns predicted and target outputs under group actions, allowing accurate
learning in equivariant settings. We validate our approach on a range of
systems, from toy models to complex physical problems such as buckling beams
and the Allen-Cahn equation. Our results demonstrate that flow matching
significantly outperforms non-probabilistic and variational methods in
capturing multimodal distributions and symmetry-breaking bifurcations, offering
a principled and scalable solution for modeling multistability in
high-dimensional systems.

</details>


### [26] [Fair Resource Allocation for Fleet Intelligence](https://arxiv.org/abs/2509.03353)
*Oguzhan Baser,Kaan Kale,Po-han Li,Sandeep Chinchali*

Main category: cs.LG

TL;DR: Fair-Synergy는 클라우드 기반 다중 에이전트 지능의 성능 최적화를 위해 공정한 자원 할당을 보장하는 알고리즘 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 클라우드 지원 다중 에이전트 지능의 성능 최적화를 위한 자원 할당은 매우 중요하다.

Method: Fair-Synergy는 에이전트의 정확성과 시스템 자원 간의 볼록 관계를 활용하여 공정한 자원 할당을 보장하는 알고리즘적 프레임워크이다.

Result: Fair-Synergy는 다중 에이전트 추론에서 표준 벤치마크보다 최대 25%, 다중 에이전트 학습 설정에서 11% 더 나은 성능을 보여준다.

Conclusion: 공정성의 수준이 가장 불리한 에이전트, 가장 유리한 에이전트 및 평균 에이전트에 미치는 영향을 탐구하여 공평한 대군 지능에 대한 통찰력을 제공한다.

Abstract: Resource allocation is crucial for the performance optimization of
cloud-assisted multi-agent intelligence. Traditional methods often overlook
agents' diverse computational capabilities and complex operating environments,
leading to inefficient and unfair resource distribution. To address this, we
open-sourced Fair-Synergy, an algorithmic framework that utilizes the concave
relationship between the agents' accuracy and the system resources to ensure
fair resource allocation across fleet intelligence. We extend traditional
allocation approaches to encompass a multidimensional machine learning utility
landscape defined by model parameters, training data volume, and task
complexity. We evaluate Fair-Synergy with advanced vision and language models
such as BERT, VGG16, MobileNet, and ResNets on datasets including MNIST,
CIFAR-10, CIFAR-100, BDD, and GLUE. We demonstrate that Fair-Synergy
outperforms standard benchmarks by up to 25% in multi-agent inference and 11%
in multi-agent learning settings. Also, we explore how the level of fairness
affects the least advantaged, most advantaged, and average agents, providing
insights for equitable fleet intelligence.

</details>


### [27] [Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning](https://arxiv.org/abs/2509.03477)
*Duy A. Nguyen,Abhi Kamboj,Minh N. Do*

Main category: cs.LG

TL;DR: Robult는 결측 모달리티와 한정된 라벨 데이터 문제를 해결하기 위한 확장 가능한 프레임워크로, 모달리티별 정보를 보존하고 정보 이론적 접근법을 통해 중복성을 활용한다.


<details>
  <summary>Details</summary>
Motivation: 결측 모달리티와 한정된 라벨 데이터 문제는 강력한 다중 모달 학습을 발전시키기 위해 중요하다.

Method: Robult는 두 가지 핵심 목표를 최적화한다: (1) 태스크 관련 피처 정렬을 극대화하고 제한된 라벨 데이터를 효과적으로 활용하는 소프트 PU 대조 손실, (2) 고유의 모달리티별 정보가 유지되도록 하는 잠재 재구성 손실.

Result: 다양한 데이터셋에 대한 실험 결과, Robult는 반지도 학습 및 결측 모달리티 상황에서 기존 접근법보다 우수한 성능을 달성한다.

Conclusion: 경량 설계는 확장성을 촉진하고 기존 아키텍처와의 원활한 통합을 가능하게 하여 실제 다중 모달 응용에 적합하게 만든다.

Abstract: Addressing missing modalities and limited labeled data is crucial for
advancing robust multimodal learning. We propose Robult, a scalable framework
designed to mitigate these challenges by preserving modality-specific
information and leveraging redundancy through a novel information-theoretic
approach. Robult optimizes two core objectives: (1) a soft Positive-Unlabeled
(PU) contrastive loss that maximizes task-relevant feature alignment while
effectively utilizing limited labeled data in semi-supervised settings, and (2)
a latent reconstruction loss that ensures unique modality-specific information
is retained. These strategies, embedded within a modular design, enhance
performance across various downstream tasks and ensure resilience to incomplete
modalities during inference. Experimental results across diverse datasets
validate that Robult achieves superior performance over existing approaches in
both semi-supervised learning and missing modality contexts. Furthermore, its
lightweight design promotes scalability and seamless integration with existing
architectures, making it suitable for real-world multimodal applications.

</details>


### [28] [On Entropy Control in LLM-RL Algorithms](https://arxiv.org/abs/2509.03493)
*Han Shen*

Main category: cs.LG

TL;DR: 본 논문에서는 LLM-RL 훈련에서의 엔트로피 제어의 중요성을 강조하고 새로운 엔트로피 제어 방법인 AEnt를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: RL 알고리즘의 효과성은 적절한 엔트로피 제어에 달려 있으며, 기존의 엔트로피 정규화 방법이 LLM-RL 훈련에서 효과가 미약하다는 점을 해결하고자 합니다.

Method: AEnt는 자동 조정된 계수를 가진 새로운 클램프 엔트로피 보너스를 활용하는 엔트로피 제어 방법입니다. 이 방법은 특정 작은 토큰 공간에서 정의된 재정규화된 정책으로 평가됩니다.

Result: AEnt는 다양한 기본 모델과 데이터셋에서 수학적 추론 작업에 대해 테스트되었으며, 여러 벤치마크에서 일관되게 기준 모델들을 초과하는 성능을 보였습니다.

Conclusion: AEnt는 엔트로피 유도 편향을 효과적으로 제어하면서 엔트로피의 이점을 활용하는 방법을 제시합니다.

Abstract: For RL algorithms, appropriate entropy control is crucial to their
effectiveness. To control the policy entropy, a commonly used method is entropy
regularization, which is adopted in various popular RL algorithms including
PPO, SAC and A3C. Although entropy regularization proves effective in robotic
and games RL conventionally, studies found that it gives weak to no gains in
LLM-RL training. In this work, we study the issues of entropy bonus in LLM-RL
setting. Specifically, we first argue that the conventional entropy
regularization suffers from the LLM's extremely large response space and the
sparsity of the optimal outputs. As a remedy, we propose AEnt, an entropy
control method that utilizes a new clamped entropy bonus with an automatically
adjusted coefficient. The clamped entropy is evaluated with the re-normalized
policy defined on certain smaller token space, which encourages exploration
within a more compact response set. In addition, the algorithm automatically
adjusts entropy coefficient according to the clamped entropy value, effectively
controlling the entropy-induced bias while leveraging the entropy's benefits.
AEnt is tested in math-reasoning tasks under different base models and
datasets, and it is observed that AEnt outperforms the baselines consistently
across multiple benchmarks.

</details>
