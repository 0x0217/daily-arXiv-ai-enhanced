<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 24]
- [cs.CR](#cs.CR) [Total: 6]
- [cs.AI](#cs.AI) [Total: 25]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [AgentShield: Make MAS more secure and efficient](https://arxiv.org/abs/2511.22924)
*Kaixiang Wang,Zhaojiacheng Zhou,Bunyod Suvonov,Jiong Lou,Jie LI*

Main category: cs.MA

TL;DR: AgentShield는 LLM 기반 다중 에이전트 시스템을 위한 효율적이고 분산된 감사 프레임워크로, 세 단계의 방어 체계를 통해 적대적 공격에 대한 저항력을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 기반의 다중 에이전트 시스템은 협력적 추론의 강력한 능력을 제공하지만, 적대적 공격에 취약하여 시스템의 전체 성능이 저하되는 문제를 해결하고자 합니다.

Method: AgentShield는 분산 감사 프레임워크를 제안하며, (i) 주요 노드 감사를 통해 주요 에이전트를 우선시하고, (ii) 경량 토큰 감사를 통해 빠른 검증을 위한 계단식 프로토콜을 실행하며, (iii) 두 단계 합의 감사를 통해 불확실할 때만 무거운 중재자를 호출하여 글로벌 합의를 보장합니다.

Result: AgentShield는 기존 방법에 비해 92.5%의 복구율과 70% 이상의 감사 부담 감소를 달성하며, 다양한 MAS 토폴로지와 적대적 시나리오에서 높은 협력 정확성을 유지합니다.

Conclusion: 이 원칙에 기반한 설계는 강력성과 효율성 간의 절충을 최적화합니다.

Abstract: Large Language Model (LLM)-based Multi-Agent Systems (MAS) offer powerful cooperative reasoning but remain vulnerable to adversarial attacks, where compromised agents can undermine the system's overall performance. Existing defenses either depend on single trusted auditors, creating single points of failure, or sacrifice efficiency for robustness. To resolve this tension, we propose \textbf{AgentShield}, a distributed framework for efficient, decentralized auditing. AgentShield introduces a novel three-layer defense: \textbf{(i) Critical Node Auditing} prioritizes high-influence agents via topological analysis; \textbf{(ii) Light Token Auditing} implements a cascade protocol using lightweight sentry models for rapid discriminative verification; and \textbf{(iii) Two-Round Consensus Auditing} triggers heavyweight arbiters only upon uncertainty to ensure global agreement. This principled design optimizes the robustness-efficiency trade-off. Experiments demonstrate that AgentShield achieves a 92.5\% recovery rate and reduces auditing overhead by over 70\% compared to existing methods, maintaining high collaborative accuracy across diverse MAS topologies and adversarial scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Automated Design Optimization via Strategic Search with Large Language Models](https://arxiv.org/abs/2511.22651)
*Anthony Carreon,Vansh Sharma,Venkat Raman*

Main category: cs.LG

TL;DR: 이 연구 는 LLM 기반의 디자인 최적화 프레임워크 AUTO 를 제안하며, 최적화 문제를 전략적 이유를 바탕으로 한 경량 검색 문제로 간주한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 최적화 방법은 정의된 탐색 공간에서 뛰어나지만 변환 및 디자인 매개변수를 정의하기 어려운 디자인 문제에서는 어려움을 겪는다.

Method: AUTO는 전략가와 구현자라는 두 개의 협력 에이전트를 이용하여 탐색 및 활용 전략을 선택하고 상세한 디자인을 실행하는 프레임워크이다.

Result: GPU 코드 최적화 문제에 적용하여 AUTO는 전문가 구현과 경쟁할 수 있는 솔루션을 생성하며, 검색 효율성은 베이지안 최적화 방법론에 비해 50-70%에 이른다.

Conclusion: 이 연구는 제한된 사전 정보로 정의되지 않은 탐색 공간에서 디자인 최적화를 자동화할 가능성을 열린다.

Abstract: Traditional optimization methods excel in well-defined search spaces but struggle with design problems where transformations and design parameters are difficult to define. Large language models (LLMs) offer a promising alternative by dynamically interpreting design spaces and leveraging encoded domain knowledge. To this end, we introduce AUTO, an LLM agent framework that treats design optimization as a gradient-free search problem guided by strategic LLM reasoning. The framework employs two collaborative agents: a Strategist that selects between exploration and exploitation strategies, and an Implementor that executes detailed designs. Applied to GPU code optimization -- a domain critical to fields from machine learning to scientific computing -- AUTO generates solutions competitive with expert implementations for chemical kinetics integration and dense matrix multiplication. The framework achieves 50-70% search efficiency relative to Bayesian optimization methodologies. It completes optimizations in approximately 8 hours at an estimated cost of up to \$159 per run, compared to an estimated cost of up to \$480 with median-wage software developers. These findings open the door to automating design optimization in ill-defined search spaces with limited prior information.

</details>


### [3] [The Double-Edged Nature of the Rashomon Set for Trustworthy Machine Learning](https://arxiv.org/abs/2511.21799)
*Ethan Hsu,Harry Chen,Chudi Zhong,Lesia Semenova*

Main category: cs.LG

TL;DR: ML 파이프라인은 단일 모델이 아닌 여러 개의 근사 최적 모델을 생성하며, 이로 인해 신뢰성의 주요 측면이 재형성된다.


<details>
  <summary>Details</summary>
Motivation: 기존 ML 모델들이 신뢰성과 관련된 문제를 해결하기 위해 다수의 근사 최적 모델이 생성되는 현상을 탐구한다.

Method: 희소 결정 트리와 선형 모델에 대한 이론적 분석과 실증 연구를 수행한다.

Result: 모델의 다양성이 공격에 대한 반응적 견고성을 제공하나, 정보 유출을 증가시킨다.

Conclusion: Rashomon 세트는 신뢰할 수 있는 ML의 자원과 위험 모두로서의 이중 역할을 가진다.

Abstract: Real-world machine learning (ML) pipelines rarely produce a single model; instead, they produce a Rashomon set of many near-optimal ones. We show that this multiplicity reshapes key aspects of trustworthiness. At the individual-model level, sparse interpretable models tend to preserve privacy but are fragile to adversarial attacks. In contrast, the diversity within a large Rashomon set enables reactive robustness: even when an attack breaks one model, others often remain accurate. Rashomon sets are also stable under small distribution shifts. However, this same diversity increases information leakage, as disclosing more near-optimal models provides an attacker with progressively richer views of the training data. Through theoretical analysis and empirical studies of sparse decision trees and linear models, we characterize this robustness-privacy trade-off and highlight the dual role of Rashomon sets as both a resource and a risk for trustworthy ML.

</details>


### [4] [Exploring Dynamic Properties of Backdoor Training Through Information Bottleneck](https://arxiv.org/abs/2511.21923)
*Xinyu Liu,Xu Zhang,Can Chen,Ren Wang*

Main category: cs.LG

TL;DR: 본 논문에서는 백도어 데이터가 신경망 학습 동역학에 미치는 영향을 분석하고, 백도어 공격의 고유한 상호 정보 특징을 발견하여 새로운 평가 지표를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 백도어 데이터가 신경망 훈련 과정에 미치는 영향을 이해하는 것은 복잡하고 잘 탐구되지 않은 도전 과제이다.

Method: 내부 표현의 클러스터링과 관련된 정보 병목(IB) 원리를 활용하여 학습 과정에서 목표 클래스와 다른 클린 클래스 간의 차별적인 행위를 분석하였다.

Result: 백도어 공격이 훈련 단계에 따라 진화하며 공격 메커니즘에 따라 차별화된 고유의 상호 정보(MI) 서명을 생성함을 발견하였다.

Conclusion: 제안된 새로운 동역학 기반의 스텔스성 지표는 모델 수준에서 공격의 통합을 정량화하며, 이를 여러 데이터셋과 다양한 공격 유형을 통해 검증하였다.

Abstract: Understanding how backdoor data influences neural network training dynamics remains a complex and underexplored challenge. In this paper, we present a rigorous analysis of the impact of backdoor data on the learning process, with a particular focus on the distinct behaviors between the target class and other clean classes. Leveraging the Information Bottleneck (IB) principle connected with clustering of internal representation, We find that backdoor attacks create unique mutual information (MI) signatures, which evolve across training phases and differ based on the attack mechanism. Our analysis uncovers a surprising trade-off: visually conspicuous attacks like BadNets can achieve high stealthiness from an information-theoretic perspective, integrating more seamlessly into the model than many visually imperceptible attacks. Building on these insights, we propose a novel, dynamics-based stealthiness metric that quantifies an attack's integration at the model level. We validate our findings and the proposed metric across multiple datasets and diverse attack types, offering a new dimension for understanding and evaluating backdoor threats. Our code is available in: https://github.com/XinyuLiu71/Information_Bottleneck_Backdoor.git.

</details>


### [5] [Heterogeneous Multi-Agent Reinforcement Learning with Attention for Cooperative and Scalable Feature Transformation](https://arxiv.org/abs/2511.21934)
*Tao Zhe,Huazhen Fang,Kunpeng Liu,Qian Lou,Tamzidul Hoque,Dongjie Wang*

Main category: cs.LG

TL;DR: 본 연구는 협력적이고 확장 가능한 피처 변환을 위한 이종 다중 에이전트 강화 학습(RL) 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 피처 변환은 수학적 피처 교차를 통해 정보성 피처를 생성하여 하위 작업 성능을 향상시키는데 필수적이다.

Method: 이 프레임워크는 피처 교차를 위한 필수 피처와 연산을 선택하도록 설계된 두 가지 유형의 이종 에이전트로 그룹화된 세 개의 이종 에이전트로 구성된다.

Result: 우리는 RL 에이전트의 학습 역학을 안정화하고 향상시키는 상태 인코딩 기술을 도입하여 보다 견고하고 신뢰할 수 있는 변환 정책을 생성하였다.

Conclusion: 대규모 실험을 통해 모델의 효과성, 효율성, 견고성 및 해석 가능성을 검증하였다.

Abstract: Feature transformation enhances downstream task performance by generating informative features through mathematical feature crossing. Despite the advancements in deep learning, feature transformation remains essential for structured data, where deep models often struggle to capture complex feature interactions. Prior literature on automated feature transformation has achieved success but often relies on heuristics or exhaustive searches, leading to inefficient and time-consuming processes. Recent works employ reinforcement learning (RL) to enhance traditional approaches through a more effective trial-and-error way. However, two limitations remain: 1) Dynamic feature expansion during the transformation process, which causes instability and increases the learning complexity for RL agents; 2) Insufficient cooperation and communication between agents, which results in suboptimal feature crossing operations and degraded model performance. To address them, we propose a novel heterogeneous multi-agent RL framework to enable cooperative and scalable feature transformation. The framework comprises three heterogeneous agents, grouped into two types, each designed to select essential features and operations for feature crossing. To enhance communication among these agents, we implement a shared critic mechanism that facilitates information exchange during feature transformation. To handle the dynamically expanding feature space, we tailor multi-head attention-based feature agents to select suitable features for feature crossing. Additionally, we introduce a state encoding technique during the optimization process to stabilize and enhance the learning dynamics of the RL agents, resulting in more robust and reliable transformation policies. Finally, we conduct extensive experiments to validate the effectiveness, efficiency, robustness, and interpretability of our model.

</details>


### [6] [CRAwDAD: Causal Reasoning Augmentation with Dual-Agent Debate](https://arxiv.org/abs/2511.22854)
*Finn G. Vamosi,Nils D. Forkert*

Main category: cs.LG

TL;DR: 이 논문에서는 인과 추론을 위한 이중 에이전트 토론 프레임워크를 통해 다양한 가설 간의 내적 대화를 명확히 하여, 진술의 타당성을 평가하는 과정을 개선한 방법을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 인과 관계를 이해할 때 사람들은 다양한 '가정' 시나리오를 고려한다. 이는 언어 모델이 인과 주장에 대한 타당성을 판단하는 데 도움이 된다.

Method: 이중 에이전트 토론 프레임워크를 사용하여 한 모델이 구조화된 인과 추론을 제공하고, 다른 모델이 논리적 결함을 비판적으로 검토한다.

Result: 데이터셋 CLadder를 바탕으로, DeepSeek-R1의 인과 추론 정확도가 78.03%에서 87.45%로 개선되었고, 반사실적 질문의 정확도는 67.94%에서 80.04%로 향상되었다. Qwen3 역시 전체 정확도가 84.16%에서 89.41%로, 반사실적 질문은 71.53%에서 80.35%로 증가했다.

Conclusion: 이 연구는 인과 추론에서 다중 에이전트 시스템의 잠재력과 다양한 관점의 중요성을 강조한다.

Abstract: When people reason about cause and effect, they often consider many competing "what if" scenarios before deciding which explanation fits best. Analogously, advanced language models capable of causal inference can consider multiple interventions and counterfactuals to judge the validity of causal claims. Crucially, this type of reasoning is less like a single calculation and more like an internal dialogue between alternative hypotheses. In this paper, we make this dialogue explicit through a dual-agent debate framework where one model provides a structured causal inference, and the other critically examines this reasoning for logical flaws. When disagreements arise, agents attempt to persuade each other, challenging each other's logic and revising their conclusions until they converge on a mutually agreed answer. To take advantage of this deliberative process, we specifically use reasoning language models, whose strengths in both causal inference and adversarial debate remain under-explored relative to standard large language models. We evaluate our approach on the CLadder dataset, a benchmark linking natural language questions to formally defined causal graphs across all three rungs of Pearl's ladder of causation. With Qwen3 and DeepSeek-R1 as debater agents, we demonstrate that multi-agent debate improves DeepSeek-R1's overall accuracy in causal inference from 78.03% to 87.45%, with the counterfactual category specifically improving from 67.94% to 80.04% accuracy. Similarly, Qwen3's overall accuracy improves from 84.16% to 89.41%, and counterfactual questions from 71.53% to 80.35%, showing that strong models can still benefit greatly from debate with weaker agents. Our results highlight the potential of reasoning models as building blocks for multi-agent systems in causal inference, and demonstrate the importance of diverse perspectives in causal problem-solving.

</details>


### [7] [Breaking Algorithmic Collusion in Human-AI Ecosystems](https://arxiv.org/abs/2511.21935)
*Natalie Collina,Eshwar Ram Arunachaleswaran,Meena Jagadeesan*

Main category: cs.LG

TL;DR: AI 에이전트와 인간이 함께 상호작용하는 생태계에서 반복 가격 게임을 연구하여 합작 회의의 지속성과 가격의 변동성을 분석한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트들이 초경쟁 가격을 유지할 수 있는 방법을 탐구하기 위하여, 인간의 이탈이 가격에 미치는 영향을 연구한다.

Method: AI 에이전트와 인간이 상호작용하는 생태계를 이론적으로 분석하고, 반복 가격 게임의 고전적 틀을 사용하여 모델을 구성한다.

Result: 단일 인간의 이탈이 공모를 불안정하게 하고 가격을 하락시킬 수 있으며, 여러 이탈이 경쟁 수준으로 가격을 더욱 가깝게 만드는 경향이 있음을 발견하였다.

Conclusion: AI 에이전트와 인간으로 구성된 혼합 생태계에서 알고리즘적 공모의 취약성과 지속성을 규명하였다.

Abstract: AI agents are increasingly deployed in ecosystems where they repeatedly interact not only with each other but also with humans. In this work, we study these human-AI ecosystems from a theoretical perspective, focusing on the classical framework of repeated pricing games. In our stylized model, the AI agents play equilibrium strategies, and one or more humans manually perform the pricing task instead of adopting an AI agent, thereby defecting to a no-regret strategy. Motivated by how populations of AI agents can sustain supracompetitive prices, we investigate whether high prices persist under such defections. Our main finding is that even a single human defection can destabilize collusion and drive down prices, and multiple defections push prices even closer to competitive levels. We further show how the nature of collusion changes under defection-aware AI agents. Taken together, our results characterize when algorithmic collusion is fragile--and when it persists--in mixed ecosystems of AI agents and humans.

</details>


### [8] [Beyond Curve Fitting: Neuro-Symbolic Agents for Context-Aware Epidemic Forecasting](https://arxiv.org/abs/2511.23276)
*Joongwon Chae,Runming Wang,Chen Xiong,Gong Yunhan,Lian Zhang,Ji Jiansong,Dongmei Yu,Peiwu Qin*

Main category: cs.LG

TL;DR: 이 연구는 손발병(HFMD) 예측을 개선하기 위해 맥락 해석과 확률적 예측을 분리한 두 개체 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 손발병(HFMD)의 효과적인 감시는 역학 패턴 및 학교 일정, 날씨와 같은 맥락적 요인을 반영한 예측이 필요합니다.

Method: 우리는 LLM '이벤트 해석기'를 사용하여 학교 일정, 기상 요약 및 보고서를 포함한 이질적 신호를 스칼라 전파 영향 신호로 처리하고, 이를 역사적 사례 수와 결합하여 보정된 확률적 예측을 생성하는 신경-상징적 코어를 제안합니다.

Result: 우리는 홍콩(2023-2024) 및 중국 리수이(2024)의 실제 HFMD 데이터 세트에서 프레임워크를 평가하였으며, 우리의 접근 방식은 전통적 및 기반 모델과 비교하여 경쟁력 있는 포인트 예측 정확도를 달성하면서 견고한 90% 예측 간격(0.85-1.00)을 제공하고 해석 가능한 합리성을 제공했습니다.

Conclusion: 우리의 결과는 LLM을 통해 도메인 지식을 구조적으로 통합하는 것이 최첨단 성능과 일치하며 공공 보건 워크플로와 일치하는 맥락 인식 예측을 제공할 수 있음을 제안합니다.

Abstract: Effective surveillance of hand, foot and mouth disease (HFMD) requires forecasts accounting for epidemiological patterns and contextual drivers like school calendars and weather. While classical models and recent foundation models (e.g., Chronos, TimesFM) incorporate covariates, they often lack the semantic reasoning to interpret the causal interplay between conflicting drivers. In this work, we propose a two-agent framework decoupling contextual interpretation from probabilistic forecasting. An LLM "event interpreter" processes heterogeneous signals-including school schedules, meteorological summaries, and reports-into a scalar transmission-impact signal. A neuro-symbolic core then combines this with historical case counts to produce calibrated probabilistic forecasts. We evaluate the framework on real-world HFMD datasets from Hong Kong (2023-2024) and Lishui, China (2024). Compared to traditional and foundation-model baselines, our approach achieves competitive point forecasting accuracy while providing robust 90% prediction intervals (coverage 0.85-1.00) and human-interpretable rationales. Our results suggest that structurally integrating domain knowledge through LLMs can match state-of-the-art performance while yielding context-aware forecasts that align with public health workflows. Code is available at https://github.com/jw-chae/forecast_MED .

</details>


### [9] [A Safety and Security Framework for Real-World Agentic Systems](https://arxiv.org/abs/2511.21990)
*Shaona Ghosh,Barnaby Simkin,Kyriacos Shiarlis,Soumili Nandi,Dan Zhao,Matthew Fiedler,Julia Bazinska,Nikki Pope,Roopa Prabhu,Daniel Rohrer,Michael Demoret,Bartley Richardson*

Main category: cs.LG

TL;DR: 이 논문은 기업 배치에서 에이전트 AI 시스템을 안전하게 보호하기 위한 동적이고 실행 가능한 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 안전성과 보안성은 개별 모델의 고정 속성이 아니라 운영 환경 내 모델, 조정자, 도구 및 데이터 간의 동적 상호작용에서 발생하는 emergent 속성이라는 주장에 기초합니다.

Method: 사용자 안전의 관점에서 새로운 에이전트 리스크 식별 방식을 제안하며, 전통적인 안전 및 보안 문제와 새로운 에이전트 리스크를 통합하는 운영 에이전트 위험 분류 체계를 정의합니다.

Result: NVIDIA의 AI-Q Research Assistant에 대한 사례 연구를 통해 프레임워크의 효과성을 입증하고, 10,000개의 현실적인 공격과 방어 실행 흔적을 포함한 데이터세트를 공개합니다.

Conclusion: 이 연구는 복잡한 기업 수준의 에이전트 워크플로우에서 실질적인 안전성과 보안 평가를 보여주며, 에이전트 시스템의 안전성을 향상시키기 위한 연구를 발전시키는 데 기여합니다.

Abstract: This paper introduces a dynamic and actionable framework for securing agentic AI systems in enterprise deployment. We contend that safety and security are not merely fixed attributes of individual models but also emergent properties arising from the dynamic interactions among models, orchestrators, tools, and data within their operating environments. We propose a new way of identification of novel agentic risks through the lens of user safety. Although, for traditional LLMs and agentic models in isolation, safety and security has a clear separation, through the lens of safety in agentic systems, they appear to be connected. Building on this foundation, we define an operational agentic risk taxonomy that unifies traditional safety and security concerns with novel, uniquely agentic risks, including tool misuse, cascading action chains, and unintended control amplification among others. At the core of our approach is a dynamic agentic safety and security framework that operationalizes contextual agentic risk management by using auxiliary AI models and agents, with human oversight, to assist in contextual risk discovery, evaluation, and mitigation. We further address one of the most challenging aspects of safety and security of agentic systems: risk discovery through sandboxed, AI-driven red teaming. We demonstrate the framework effectiveness through a detailed case study of NVIDIA flagship agentic research assistant, AI-Q Research Assistant, showcasing practical, end-to-end safety and security evaluations in complex, enterprise-grade agentic workflows. This risk discovery phase finds novel agentic risks that are then contextually mitigated. We also release the dataset from our case study, containing traces of over 10,000 realistic attack and defense executions of the agentic workflow to help advance research in agentic safety.

</details>


### [10] [Distance-based Learning of Hypertrees](https://arxiv.org/abs/2511.22014)
*Shaun Fallat,Kamyar Khodamoradi,David Kirkpatrick,Valerii Maliuk,S. Ahmad Mojallal,Sandra Zilles*

Main category: cs.LG

TL;DR: 본 연구에서는 최단 경로 쿼리(SP-queries)를 이용한 하이퍼그래프 학습 문제를 다루고, 우리가 '질서 있는 하이퍼트리'라고 부르는 넓고 자연스러운 클래스의 하이퍼트리에 대해 최초의 증명 가능한 최적 온라인 알고리즘을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 하이퍼그래프 학습의 필요성과 SP 쿼리를 통한 효율성 증대를 강조합니다.

Method: 질서 있는 하이퍼트리에 적용 가능한 온라인 알고리즘을 개발하고, 이를 오프라인 알고리즘으로 변환 가능한지 평가합니다.

Result: 온라인 알고리즘이 질서 있는 하이퍼트리에 대해 최적임을 증명하고, 제한된 거리 쿼리를 사용하는 학습 모델에 대한 복잡도 경계를 보여줍니다.

Conclusion: 제안된 알고리즘이 하이퍼그래프 학습에 있어 효과적인 접근 방법임을 확인할 수 있습니다.

Abstract: We study the problem of learning hypergraphs with shortest-path queries (SP-queries), and present the first provably optimal online algorithm for a broad and natural class of hypertrees that we call orderly hypertrees. Our online algorithm can be transformed into a provably optimal offline algorithm. Orderly hypertrees can be positioned within the Fagin hierarchy of acyclic hypergraph (well-studied in database theory), and strictly encompass the broadest class in this hierarchy that is learnable with subquadratic SP-query complexity.
  Recognizing that in some contexts, such as evolutionary tree reconstruction, distance measurements can degrade with increased distance, we also consider a learning model that uses bounded distance queries. In this model, we demonstrate asymptotically tight complexity bounds for learning general hypertrees.

</details>


### [11] [A Multi-View Multi-Timescale Hypergraph-Empowered Spatiotemporal Framework for EV Charging Forecasting](https://arxiv.org/abs/2511.22072)
*Jinhao Li,Hao Wang*

Main category: cs.LG

TL;DR: HyperCast는 전기차 충전 수요 예측을 위해 하이퍼그래프를 이용해 복잡한 도시 충전 네트워크의 동역학을 모델링하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 전기차 충전 수요 예측의 정확성은 안정적인 그리드 운영과 전기 시장에서의 전기차 참여를 위해 필수적이다.

Method: 하이퍼그래프의 표현력을 활용하여 EV 충전 패턴에서 고차원 시공간 종속성을 모델링 하는 HyperCast라는 새로운 예측 프레임워크를 개발했다.

Result: HyperCast는 정적 지리적 근접성과 동적 수요 기반 기능 유사성을 포착하는 다중 시각 하이퍼그래프 통합 및 다양한 시간대 입력을 통해 최근 트렌드와 주간 주기를 구분한다.

Conclusion: HyperCast는 집단 충전 행동을 명시적으로 모델링하여 더 정확한 예측을 제공하는 효과성을 보여주며, 기존의 다양한 최첨단 기법들에 비해 월등한 성능을 보인다.

Abstract: Accurate electric vehicle (EV) charging demand forecasting is essential for stable grid operation and proactive EV participation in electricity market. Existing forecasting methods, particularly those based on graph neural networks, are often limited to modeling pairwise relationships between stations, failing to capture the complex, group-wise dynamics inherent in urban charging networks. To address this gap, we develop a novel forecasting framework namely HyperCast, leveraging the expressive power of hypergraphs to model the higher-order spatiotemporal dependencies hidden in EV charging patterns. HyperCast integrates multi-view hypergraphs, which capture both static geographical proximity and dynamic demand-based functional similarities, along with multi-timescale inputs to differentiate between recent trends and weekly periodicities. The framework employs specialized hyper-spatiotemporal blocks and tailored cross-attention mechanisms to effectively fuse information from these diverse sources: views and timescales. Extensive experiments on four public datasets demonstrate that HyperCast significantly outperforms a wide array of state-of-the-art baselines, demonstrating the effectiveness of explicitly modeling collective charging behaviors for more accurate forecasting.

</details>


### [12] [Energy Efficient Sleep Mode Optimization in 5G mmWave Networks via Multi Agent Deep Reinforcement Learning](https://arxiv.org/abs/2511.22105)
*Saad Masrur,Ismail Guvenc,David Lopez Perez*

Main category: cs.LG

TL;DR: 밀리미터파 네트워크에서 동적 수면 모드 최적화는 엄격한 품질 보증 제약하에 에너지 효율성을 극대화하는 데 필수적이다. 본 논문은 다중 에이전트 심층 강화 학습 프레임워크인 MARL-DDQN을 제안하여 3D 도시 환경에서 적응형 수면 모드 최적화를 수행한다. 이 방법은 기존의 방식보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 밀리미터파 네트워크에서의 에너지 효율성을 높이기 위해 동적 수면 모드 최적화가 필요하다.

Method: MARL-DDQN을 활용하여 3D 도시 환경에서 사용자 장치의 이동성을 고려한 적응형 SMO를 수행한다.

Result: 이 방법이 All On, IT-QoS-LB, MARL-DDPG, MARL-PPO 등 최첨단 전략들보다 성능이 우수함을 보여준다.

Conclusion: 동적 시나리오 하에서 95%의 품질 보증 제약을 충족하며, 0.60 Mbit/Joule의 에너지 효율성을 achieved하고 8.5 Mbps의 10번째 백분위수 처리량을 기록하였다.

Abstract: Dynamic sleep mode optimization (SMO) in millimeter-wave (mmWave) networks is essential for maximizing energy efficiency (EE) under stringent quality-of-service (QoS) constraints. However, existing optimization and reinforcement learning (RL) approaches rely on aggregated, static base station (BS) traffic models that fail to capture non-stationary traffic dynamics and suffer from large state-action spaces, limiting real-world deployment. To address these challenges, this paper proposes a multi-agent deep reinforcement learning (MARL) framework using a Double Deep Q-Network (DDQN), referred to as MARL-DDQN, for adaptive SMO in a 3D urban environment with a time-varying and community-based user equipment (UE) mobility model. Unlike conventional single-agent RL, MARL-DDQN enables scalable, distributed decision-making with minimal signaling overhead. A realistic BS power consumption model and beamforming are integrated to accurately quantify EE, while QoS is defined in terms of throughput. The method adapts SMO policies to maximize EE while mitigating inter-cell interference and ensuring throughput fairness. Simulations show that MARL-DDQN outperforms state-of-the-art strategies, including All On, iterative QoS-aware load-based (IT-QoS-LB), MARL-DDPG, and MARL-PPO, achieving up to 0.60 Mbit/Joule EE, 8.5 Mbps 10th-percentile throughput, and meeting QoS constraints 95% of the time under dynamic scenarios.

</details>


### [13] [Benchmarking In-context Experiential Learning Through Repeated Product Recommendations](https://arxiv.org/abs/2511.22130)
*Gilbert Yang,Yaqin Chen,Thomson Yen,Hongseok Namkoong*

Main category: cs.LG

TL;DR: 에이전트는 변화하는 실제 환경에서 신뢰롭게 탐색하기 위해 불완전한 지식과 경험을 통해 행동을 조정해야 한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 평가 방법은 모호함이 없는 작업에 집중하고, 에이전트가 경험을 통해 적응적으로 학습하고 추론하는 능력을 측정하지 않는다.

Method: 본 연구는 고객 선호와 제품 지형이 변화하는 제품 추천 맥락에서의 경험적 학습 필요성을 보여준다. 우리는 Amazon의 다양한 제품, 이질적이지만 잠재적인 선호를 나타내는 다양한 사용자 페르소나, 페르소나를 기반으로 한 LLM 사용자 시뮬레이터를 결합하여 경험적 학습 및 능동적 탐색을 위한 기준 벤치마크(BELA)를 구축했다.

Result: 현재 최첨단 모델들이 에피소드 간 의미 있게 개선하는 데 어려움을 겪고 있음을 관찰했고, 이는 강력한 맥락 학습 능력을 가진 에이전트 시스템의 필요성을 강조한다.

Conclusion: 에이전트가 변화하는 환경에 적응할 수 있도록 하는 경험적 학습 기준의 필요성이 강조되었다.

Abstract: To reliably navigate ever-shifting real-world environments, agents must grapple with incomplete knowledge and adapt their behavior through experience. However, current evaluations largely focus on tasks that leave no ambiguity, and do not measure agents' ability to adaptively learn and reason through the experiences they accrued. We exemplify the need for this in-context experiential learning in a product recommendation context, where agents must navigate shifting customer preferences and product landscapes through natural language dialogue. We curate a benchmark for experiential learning and active exploration (BELA) that combines (1) rich real-world products from Amazon, (2) a diverse collection of user personas to represent heterogeneous yet latent preferences, and (3) a LLM user simulator powered by the persona to create rich interactive trajectories. We observe that current frontier models struggle to meaningfully improve across episodes, underscoring the need for agentic systems with strong in-context learning capabilities.

</details>


### [14] [TinyLLM: Evaluation and Optimization of Small Language Models for Agentic Tasks on Edge Devices](https://arxiv.org/abs/2511.22138)
*Mohd Ariful Haque,Fahad Rahman,Kishor Datta Gupta,Khalil Shujaee,Roy George*

Main category: cs.LG

TL;DR: 이 논문은 클라우드 인프라에 의존하지 않고 엣지 장치에서 에이전트 작업을 수행하기 위한 소형 언어 모델(SLM)의 효율성을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 클라우드 인프라에 의존하지 않고 에지 장치에서 작동 가능한 에이전트 작업을 수행하기 위한 소형 언어 모델(SLM)의 효율성 향상 필요성을 제기합니다.

Method: Berkeley Function Calling Leaderboard (BFCL) 프레임워크를 사용하여 SLM을 평가하고, SFT, PEFT, RL 기반 최적화, DPO에 의한 선호 정렬 및 하이브리드 방법을 포함한 매개변수 기반 최적화 전략을 설명합니다.

Result: TinyAgent, TinyLlama, Qwen 및 xLAM 모델을 포함한 여러 모델의 BFCL 카테고리에서의 결과를 보고하며, 중형 모델이 초소형 모델에 비해 우수한 정확도를 나타냅니다.

Conclusion: 소형 언어 모델이 엣지 장치에서 정확하고 효율적이며 안정적인 에이전트 AI를 제공할 수 있게 해주는 하이브리드 최적화 전략의 중요성을 강조합니다.

Abstract: This paper investigates the effectiveness of small language models (SLMs) for agentic tasks (function/tool/API calling) with a focus on running agents on edge devices without reliance on cloud infrastructure. We evaluate SLMs using the Berkeley Function Calling Leaderboard (BFCL) framework and describe parameter-driven optimization strategies that include supervised fine-tuning (SFT), parameter-efficient fine-tuning (PEFT), reinforcement learning (RL)-based optimization, preference alignment via Direct Preference Optimization (DPO), and hybrid methods. We report results for models including TinyAgent, TinyLlama, Qwen, and xLAM across BFCL categories (simple, multiple, parallel, parallel-multiple, and relevance detection), both in live and non-live settings, and in multi-turn evaluations. We additionally detail a DPO training pipeline constructed from AgentBank data (e.g., ALFRED), including our conversion of SFT data to chosen-rejected pairs using TinyLlama responses as rejected outputs and manual validation. Our results demonstrate clear accuracy differences across model scales where medium-sized models (1-3B parameters) significantly outperform ultra-compact models (<1B parameters), achieving up to 65.74% overall accuracy, and 55.62% multi-turn accuracy with hybrid optimization. This study highlights the importance of hybrid optimization strategies that enable small language models to deliver accurate, efficient, and stable agentic AI on edge devices, making privacy-preserving, low-latency autonomous agents practical beyond the cloud.

</details>


### [15] [From Topology to Retrieval: Decoding Embedding Spaces with Unified Signatures](https://arxiv.org/abs/2511.22150)
*Florian Rottach,William Rudman,Bastain Rieck,Harrisen Scells,Carsten Eickhoff*

Main category: cs.LG

TL;DR: 이 논문은 텍스트 임베딩 모델과 데이터셋의 다양한 토폴로지 및 기하학적 측정을 분석하고, 통합 토폴로지 서명(UTS)이라는 새로운 프레임워크를 도입하여 모델 특성을 예측하고 문서 검색 가능성을 정확하게 예측함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 임베딩이 공간에서 어떻게 구성되어 있는지를 연구하는 것은 모델 해석 가능성을 향상시키고 다운스트림 작업 성능에 영향을 미치는 요소를 밝혀내는 데 도움이 된다.

Method: 우리는 다양한 텍스트 임베딩 모델과 데이터셋에 대해 토폴로지 및 기하학적 측정에 대한 포괄적인 분석을 수행하고, UTS라는 통합된 프레임워크를 도입하였다.

Result: UTS는 모델 특성을 예측할 수 있으며, 모델 아키텍처에 의해 유도된 유사성을 드러낼 수 있다. 또한, 우리의 방법은 토폴로지 구조와 순위 효과성 간의 관계를 연결하여 문서 검색 가능성을 정확하게 예측함을 보여준다.

Conclusion: 텍스트 임베딩의 기하학을 이해하고 활용하기 위해서는 전체적이고 다중 속성의 관점이 필수적이다.

Abstract: Studying how embeddings are organized in space not only enhances model interpretability but also uncovers factors that drive downstream task performance. In this paper, we present a comprehensive analysis of topological and geometric measures across a wide set of text embedding models and datasets. We find a high degree of redundancy among these measures and observe that individual metrics often fail to sufficiently differentiate embedding spaces. Building on these insights, we introduce Unified Topological Signatures (UTS), a holistic framework for characterizing embedding spaces. We show that UTS can predict model-specific properties and reveal similarities driven by model architecture. Further, we demonstrate the utility of our method by linking topological structure to ranking effectiveness and accurately predicting document retrievability. We find that a holistic, multi-attribute perspective is essential to understanding and leveraging the geometry of text embeddings.

</details>


### [16] [LLM-Cave: A benchmark and light environment for large language models reasoning and decision-making system](https://arxiv.org/abs/2511.22598)
*Huanyu Li,Zongyuan Li,Wei Huang,Xian Guo*

Main category: cs.LG

TL;DR: 본 논문에서는 LLM-Cave라는 새로운 벤치마크와 경량 환경을 소개하며, 이는 대형 언어 모델의 추론 및 의사결정 시스템을 평가하는 데 사용된다.


<details>
  <summary>Details</summary>
Motivation: 현재의 LLM 평가 기준이 단일 상호작용으로 제한되어 있기 때문에, 더 복잡한 연속 결정 환경을 제공할 필요성이 있다.

Method: LLM-Cave 환경을 통해 에이전트는 주변 위험에 대한 추론을 수행하여 환경을 탐색하고 잠재적 손실을 피할 수 있다.

Result: Deepseek-R1이 복잡한 추론 작업에서 가장 높은 성공률을 달성했으며, 4o-mini와 같은 작은 모델들도 Chain of Speculation 및 Planner-Critic 전략을 통해 성능 격차를 크게 줄였다.

Conclusion: 구조화된 다단계 추론과 LLM 기반 피드백 메커니즘의 결합이 LLM의 의사결정 능력을 크게 향상시킬 수 있으며, 이는 약한 모델의 추론을 개선하기 위한 유망한 방향을 제시한다.

Abstract: Large language models (LLMs) such as ChatGPT o1, ChatGPT o3, and DeepSeek R1 have shown great potential in solving difficult problems. However, current LLM evaluation benchmarks are limited to one-step interactions. Some of the existing sequence decision-making environments, such as TextStarCraftII and LLM-PySC2, are too complicated and require hours of interaction to complete a game. In this paper, we introduce LLM-Cave, a benchmark and light environment for LLM reasoning and decision-making systems. This environment is a classic instance in the era of Symbolism. Artificial intelligence enables the agent to explore the environment and avoid potential losses by reasoning about nearby dangers using partial observable state information. In the experiment, we evaluated the sequential reasoning ability, decision-making performance and computational efficiency of mainstream large language models (LLMs) such as GPT-4o-mini, o1-mini, and DeepSeek-R1. Experiments show that while Deepseek-R1 achieved the highest success rate on complex reasoning tasks, smaller models like 4o-mini significantly narrowed the performance gap on challenges by employing Chain of Speculation and Planner-Critic strategies, at the expense of reduced computational efficiency. This indicates that structured, multi-step reasoning combined with an LLM-based feedback mechanism can substantially enhance an LLM's decision-making capabilities, providing a promising direction for improving reasoning in weaker models and suggesting a new reasoning-centered benchmark for LLM assessment. Our code is open-sourced in https://github.com/puleya1277/CaveEnv.

</details>


### [17] [Flow Density Control: Generative Optimization Beyond Entropy-Regularized Fine-Tuning](https://arxiv.org/abs/2511.22640)
*Riccardo De Santi,Marin Vlastelica,Ya-Ping Hsieh,Zebang Shen,Niao He,Andreas Krause*

Main category: cs.LG

TL;DR: 이 논문은 사전 정보 유지와 함께 특정 작업 목표를 최적화하는 데 필요한 대규모 생성 모델의 적응 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계 응용 프로그램에서 분자 설계, 단백질 도킹 및 창의적 이미지 생성을 위해 기초 흐름 및 확산 생성 모델을 작업 특정 목표에 맞게 조정하는 것이 중요하다.

Method: Flow Density Control (FDC)라는 알고리즘을 소개하여 복잡한 문제를 일련의 간단한 미세 조정 작업으로 단순화한다.

Result: 우리의 방법은 기존 미세 조정 방식의 범위를 넘어서는 목표를 최적화하고 실제적으로 관련된 작업을 해결할 수 있음을 보여준다.

Conclusion: 제안된 방법은 텍스트-이미지 변환 및 분자 설계 작업에서 검증되었으며, 선 훈련된 생성 모델을 목표에 맞게 조정할 수 있음을 입증했다.

Abstract: Adapting large-scale foundation flow and diffusion generative models to optimize task-specific objectives while preserving prior information is crucial for real-world applications such as molecular design, protein docking, and creative image generation. Existing principled fine-tuning methods aim to maximize the expected reward of generated samples, while retaining knowledge from the pre-trained model via KL-divergence regularization. In this work, we tackle the significantly more general problem of optimizing general utilities beyond average rewards, including risk-averse and novelty-seeking reward maximization, diversity measures for exploration, and experiment design objectives among others. Likewise, we consider more general ways to preserve prior information beyond KL-divergence, such as optimal transport distances and Renyi divergences. To this end, we introduce Flow Density Control (FDC), a simple algorithm that reduces this complex problem to a specific sequence of simpler fine-tuning tasks, each solvable via scalable established methods. We derive convergence guarantees for the proposed scheme under realistic assumptions by leveraging recent understanding of mirror flows. Finally, we validate our method on illustrative settings, text-to-image, and molecular design tasks, showing that it can steer pre-trained generative models to optimize objectives and solve practically relevant tasks beyond the reach of current fine-tuning schemes.

</details>


### [18] [Exact Learning of Arithmetic with Differentiable Agents](https://arxiv.org/abs/2511.22751)
*Hristo Papazov,Francesco D'Angelo,Nicolas Flammarion*

Main category: cs.LG

TL;DR: 본 연구에서는 기울기 기반 방법을 통한 정확한 알고리즘 학습 가능성을 탐구하고, 산술 작업에서 강력한 길이 일반화를 지원하는 미분 가능 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 정확한 알고리즘 학습을 위한 기울기 기반 방법의 탐구.

Method: 미분 가능 유한 상태 변환기(DFST)를 중심으로 하여, 신뢰할 수 있는 로그 병렬 미분 훈련을 통한 모델 학습을 수행.

Result: 작은 데이터셋으로 훈련된 모델이 훈련 예제보다 수천 배 긴 입력에 대해서도 오류 없이 일반화됨을 보여줌.

Conclusion: 구조화된 중간 감독에서 미분 가능한 에이전트를 훈련시키는 것이 알고리즘 기술의 정확한 기울기 기반 학습으로의 길을 열 수 있음을 시사합니다.

Abstract: We explore the possibility of exact algorithmic learning with gradient-based methods and introduce a differentiable framework capable of strong length generalization on arithmetic tasks. Our approach centers on Differentiable Finite-State Transducers (DFSTs), a Turing-complete model family that avoids the pitfalls of prior architectures by enabling constant-precision, constant-time generation, and end-to-end log-parallel differentiable training. Leveraging policy-trajectory observations from expert agents, we train DFSTs to perform binary and decimal addition and multiplication. Remarkably, models trained on tiny datasets generalize without error to inputs thousands of times longer than the training examples. These results show that training differentiable agents on structured intermediate supervision could pave the way towards exact gradient-based learning of algorithmic skills. Code available at \href{https://github.com/dngfra/differentiable-exact-algorithmic-learner.git}{https://github.com/dngfra/differentiable-exact-algorithmic-learner.git}.

</details>


### [19] [Bridging Modalities via Progressive Re-alignment for Multimodal Test-Time Adaptation](https://arxiv.org/abs/2511.22862)
*Jiacheng Li,Songhe Feng*

Main category: cs.LG

TL;DR: 이 논문에서는 멀티모달 환경에서의 모델 적응을 위한 새로운 프레임워크인 BriMPR를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 테스트 시간 적응(TTA)은 레이블 없는 테스트 데이터만을 사용하여 온라인 모델 적응을 가능하게 하여, 출발 분포와 목표 분포 간의 격차를 해소하고자 합니다.

Method: 우리는 MMTTA를 여러 개의 단일 모달 특성 정렬 서브 문제로 분해하고, 프롬프트 튜닝의 강력한 함수 근사 능력을 활용하여 단일 모달 글로벌 특성 분포를 해당하는 출발 분포로 보정한 후, 모달 간 초기 의미 재정렬을 달성합니다.

Result: MMTTA 작업에 대한 광범위한 실험 결과, 우리 방법의 우수성을 입증합니다.

Conclusion: 우리의 소스 코드는 [이 URL](https://github.com/Luchicken/BriMPR)에서 사용할 수 있습니다.

Abstract: Test-time adaptation (TTA) enables online model adaptation using only unlabeled test data, aiming to bridge the gap between source and target distributions. However, in multimodal scenarios, varying degrees of distribution shift across different modalities give rise to a complex coupling effect of unimodal shallow feature shift and cross-modal high-level semantic misalignment, posing a major obstacle to extending existing TTA methods to the multimodal field. To address this challenge, we propose a novel multimodal test-time adaptation (MMTTA) framework, termed as Bridging Modalities via Progressive Re-alignment (BriMPR). BriMPR, consisting of two progressively enhanced modules, tackles the coupling effect with a divide-and-conquer strategy. Specifically, we first decompose MMTTA into multiple unimodal feature alignment sub-problems. By leveraging the strong function approximation ability of prompt tuning, we calibrate the unimodal global feature distributions to their respective source distributions, so as to achieve the initial semantic re-alignment across modalities. Subsequently, we assign the credible pseudo-labels to combinations of masked and complete modalities, and introduce inter-modal instance-wise contrastive learning to further enhance the information interaction among modalities and refine the alignment. Extensive experiments on MMTTA tasks, including both corruption-based and real-world domain shift benchmarks, demonstrate the superiority of our method. Our source code is available at [this URL](https://github.com/Luchicken/BriMPR).

</details>


### [20] [Experts are all you need: A Composable Framework for Large Language Model Inference](https://arxiv.org/abs/2511.22955)
*Shrihari Sridharan,Sourjya Roy,Anand Raghunathan,Kaushik Roy*

Main category: cs.LG

TL;DR: Comp-LLM은 전문가 간 협업을 통해 멀티 스텝 추론 문제를 해결하고, 모델 크기를 줄이며, 처리 속도를 개선하는 새로운 추론 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 크기가 증가하면서 컴퓨팅 부담이 가중되고 있으며, 이는 성능과 효율성의 균형을 맞추는 데 어려움을 주고 있습니다.

Method: Comp-LLM은 쿼리를 분해하고 각 서브 쿼리를 전문가에게 할당하는 서브 쿼리 생성기, 그래프의 노드를 처리하고 병렬 처리 기회를 식별하는 쿼리 실행기, 중간 전문가 응답을 종합하여 최종 응답을 생성하는 응답 집계기로 구성됩니다.

Result: Comp-LLM은 비슷한 크기의 단일 LLM에 비해 최대 11.01%의 정확도 개선을 달성하며, 모델 크기를 1.67배에서 3.56배 줄이면서도 성능 저하는 없습니다.

Conclusion: Comp-LLM은 쿼리 처리에 있어 시퀀스 처리에 비해 1.1배에서 1.7배의 지연 시간을 개선합니다.

Abstract: Large Language Models (LLMs) have achieved state-of-the-art accuracies in a variety of natural language processing (NLP) tasks. However, this success comes at the cost of increased model sizes which leads to additional computational burden. Mixture of Experts (MoEs) overcome this bottleneck by decoupling model capacity from computation by only activating a subset of parameters or "experts". However, these models require joint pretraining of these experts along with the router and do not model multi-step reasoning. In contrast, multi-agent frameworks improve reasoning by decomposing complex problems into modular subtasks. However, these frameworks rely on sequential "plan--act--observe" loops, which introduce significant latency. Our work, Comp-LLM, addresses these challenges by introducing a composable inference framework that enables cross-expert collaboration via an explicit sub-query dependency graph. Comp-LLM consists of three components: (1) A Sub-query Generator that decomposes an input query, assigns each sub-query to an appropriate expert using embedding similarity, and constructs a dependency graph; (2) A Query Executor that processes nodes in the graph and identifies opportunities for parallelism based on dependencies and resource constraints; and (3) A Response Aggregator that synthesizes intermediate expert responses into a coherent final answer. Across several benchmarks, Comp-LLM achieves up to 11.01% accuracy improvement over monolithic LLMs of similar size, while offering 1.67x--3.56x reduction in model size with no significant degradation relative to the largest model in its family. Additionally, Comp-LLM provides 1.1x--1.7x latency improvement compared to sequential sub-query processing.

</details>


### [21] [Estimating the Event-Related Potential from Few EEG Trials](https://arxiv.org/abs/2511.23162)
*Anders Vestergaard Nørskov,Kasper Jørgensen,Alexander Neergaard Zahid,Morten Mørup*

Main category: cs.LG

TL;DR: EEG2ERP는 EEG 신호를 ERP로 매핑하는 신규 딥러닝 접근법으로, 불확실성을 모델링하여 최소한의 시도로 ERP 연구에 기여한다.


<details>
  <summary>Details</summary>
Motivation: EEG 신호에서 ERP를 추정할 때의 잡음과 신호 변동성을 줄이기 위한 새로운 방법이 필요하다.

Method: EEG2ERP는 EEG 실험을 여러 번 진행한 데이터를 기반으로 하여 불확실성을 고려하는 오토인코더 접근법이다.

Result: 이 방법은 적은 수의 시도에서도 기존의 평균화 방법보다 훨씬 더 나은 ERP 추정을 제공한다.

Conclusion: EEG2ERP는 EEG 신호를 ERP에 매핑하는 최초의 딥러닝 접근법으로, ERP 연구를 위한 시도 수를 줄이는 방향으로 나아간다.

Abstract: Event-related potentials (ERP) are measurements of brain activity with wide applications in basic and clinical neuroscience, that are typically estimated using the average of many trials of electroencephalography signals (EEG) to sufficiently reduce noise and signal variability. We introduce EEG2ERP, a novel uncertainty-aware autoencoder approach that maps an arbitrary number of EEG trials to their associated ERP. To account for the ERP uncertainty we use bootstrapped training targets and introduce a separate variance decoder to model the uncertainty of the estimated ERP. We evaluate our approach in the challenging zero-shot scenario of generalizing to new subjects considering three different publicly available data sources; i) the comprehensive ERP CORE dataset that includes over 50,000 EEG trials across six ERP paradigms from 40 subjects, ii) the large P300 Speller BCI dataset, and iii) a neuroimaging dataset on face perception consisting of both EEG and magnetoencephalography (MEG) data. We consistently find that our method in the few trial regime provides substantially better ERP estimates than commonly used conventional and robust averaging procedures. EEG2ERP is the first deep learning approach to map EEG signals to their associated ERP, moving toward reducing the number of trials necessary for ERP research. Code is available at https://github.com/andersxa/EEG2ERP

</details>


### [22] [Transformer-Driven Triple Fusion Framework for Enhanced Multimodal Author Intent Classification in Low-Resource Bangla](https://arxiv.org/abs/2511.23287)
*Ariful Islam,Tanvir Mahmud,Md Rifat Hossen*

Main category: cs.LG

TL;DR: 이 논문은 방글라 소셜 미디어 게시물의 저자 의도를 이해하기 위해 텍스트와 시각적 데이터를 사용하는 분류 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 소셜 미디어 콘텐츠 해석에서 저자 의도 이해의 중요성을 강조합니다. 이전의 단일 모달 접근 방식의 한계를 인식하고 이를 극복하고자 합니다.

Method: 변형기 기반 언어 모델(mBERT, DistilBERT, XLM-RoBERTa)과 비전 아키텍처(ViT, Swin, SwiftFormer, ResNet, DenseNet, MobileNet)를 시스템적으로 벤치마킹합니다.

Result: 중간 융합 전략을 도입하여 84.11%의 매크로-F1 점수를 달성하고, 이전 방글라 다중 모달 접근 방식에 비해 8.4% 개선된 성능을 입증합니다.

Conclusion: 이 연구는 방글라 및 기타 저자원 언어를 위한 새로운 기준 및 방법론을 설정합니다.

Abstract: The expansion of the Internet and social networks has led to an explosion of user-generated content. Author intent understanding plays a crucial role in interpreting social media content. This paper addresses author intent classification in Bangla social media posts by leveraging both textual and visual data. Recognizing limitations in previous unimodal approaches, we systematically benchmark transformer-based language models (mBERT, DistilBERT, XLM-RoBERTa) and vision architectures (ViT, Swin, SwiftFormer, ResNet, DenseNet, MobileNet), utilizing the Uddessho dataset of 3,048 posts spanning six practical intent categories. We introduce a novel intermediate fusion strategy that significantly outperforms early and late fusion on this task. Experimental results show that intermediate fusion, particularly with mBERT and Swin Transformer, achieves 84.11% macro-F1 score, establishing a new state-of-the-art with an 8.4 percentage-point improvement over prior Bangla multimodal approaches. Our analysis demonstrates that integrating visual context substantially enhances intent classification. Cross-modal feature integration at intermediate levels provides optimal balance between modality-specific representation and cross-modal learning. This research establishes new benchmarks and methodological standards for Bangla and other low-resource languages. We call our proposed framework BangACMM (Bangla Author Content MultiModal).

</details>


### [23] [Emergent Coordination and Phase Structure in Independent Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.23315)
*Azusa Yamaguchi*

Main category: cs.LG

TL;DR: 본 연구는 분산형 다중 에이전트 강화 학습(MARL)에서의 조정 상태와 동적 변화를 분석하고, 이를 통해 세 가지 distinct phase를 발견하였다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 학습 시스템의 동 역학을 특징 짓기 위해 조정이 언제 발생하고 변화 또는 붕괴되는지를 더 명확하게 이해하고자 함.

Method: 완전 독립 Q-learning(IQL)을 사용하여 분산형 테스트베드를 구축하고, 환경 크기 L과 에이전트 밀도 rho에 따라 대규모 실험을 수행함.

Result: 협력 성공률(CSR)과 TD-오차 분산에서 유도된 안정성 지수를 축으로 하는 단계 맵을 구성하여 조정되고 안정된 단계, 취약한 전이 지역, 그리고 혼잡하거나 무질서한 단계를 구별함.

Conclusion: 분산형 MARL은 규모, 밀도 및 커널 드리프트 간의 상호작용에 의해 지배되는 coher 엔트 phase 구조를 나타내며, emergent coordination이 분포-상호작용 주도 phase 현상으로 작용함을 제안함.

Abstract: A clearer understanding of when coordination emerges, fluctuates, or collapses in decentralized multi-agent reinforcement learning (MARL) is increasingly sought in order to characterize the dynamics of multi-agent learning systems. We revisit fully independent Q-learning (IQL) as a minimal decentralized testbed and run large-scale experiments across environment size L and agent density rho. We construct a phase map using two axes - the cooperative success rate (CSR) and a stability index derived from TD-error variance - revealing three distinct regimes: a coordinated and stable phase, a fragile transition region, and a jammed or disordered phase. A sharp double Instability Ridge separates these regimes and corresponds to persistent kernel drift, the time-varying shift of each agent's effective transition kernel induced by others' policy updates. Synchronization analysis further shows that temporal alignment is required for sustained cooperation, and that competition between drift and synchronization generates the fragile regime. Removing agent identifiers eliminates drift entirely and collapses the three-phase structure, demonstrating that small inter-agent asymmetries are a necessary driver of drift. Overall, the results show that decentralized MARL exhibits a coherent phase structure governed by the interaction between scale, density, and kernel drift, suggesting that emergent coordination behaves as a distribution-interaction-driven phase phenomenon.

</details>


### [24] [Distributed Dynamic Associative Memory via Online Convex Optimization](https://arxiv.org/abs/2511.23347)
*Bowen Wang,Matteo Zecchin,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 이 논문에서는 분산 동적 연상 기억(DDAM)의 개념을 소개하고, 여러 에이전트 및 시간에 따라 변하는 데이터 스트림을 위한 고전적인 연상 기억(AM)의 확장을 설명한다.


<details>
  <summary>Details</summary>
Motivation: 현대 신경 아키텍처의 핵심 메커니즘으로 인식되고 있는 연상 기억의 기능을 확장할 필요가 있다.

Method: 각 에이전트가 지정된 라우팅 트리를 통해 서로 통신하면서 메모리를 업데이트할 수 있도록 하는 새로운 트리 기반 분산 온라인 경량 하강(제안한 DDAM-TOGD) 알고리즘을 제안한다.

Result: 정적 환경에서 하위 선형 정적 후회와 비정적 환경에서 경로 길이에 따른 동적 후회 경계를 수립하는 성능 보증을 도출한다.

Conclusion: 제안한 DDAM-TOGD 프레임워크는 대표적인 온라인 학습 기준보다 높은 정확성과 강건성을 달성하며, 동적 분산 환경에서의 접근 방식의 혜택을 확증한다.

Abstract: An associative memory (AM) enables cue-response recall, and it has recently been recognized as a key mechanism underlying modern neural architectures such as Transformers. In this work, we introduce the concept of distributed dynamic associative memory (DDAM), which extends classical AM to settings with multiple agents and time-varying data streams. In DDAM, each agent maintains a local AM that must not only store its own associations but also selectively memorize information from other agents based on a specified interest matrix. To address this problem, we propose a novel tree-based distributed online gradient descent algorithm, termed DDAM-TOGD, which enables each agent to update its memory on the fly via inter-agent communication over designated routing trees. We derive rigorous performance guarantees for DDAM-TOGD, proving sublinear static regret in stationary environments and a path-length dependent dynamic regret bound in non-stationary environments. These theoretical results provide insights into how communication delays and network structure impact performance. Building on the regret analysis, we further introduce a combinatorial tree design strategy that optimizes the routing trees to minimize communication delays, thereby improving regret bounds. Numerical experiments demonstrate that the proposed DDAM-TOGD framework achieves superior accuracy and robustness compared to representative online learning baselines such as consensus-based distributed optimization, confirming the benefits of the proposed approach in dynamic, distributed environments.

</details>


### [25] [ASTRO: Adaptive Stitching via Dynamics-Guided Trajectory Rollouts](https://arxiv.org/abs/2511.23442)
*Hang Yu,Di Zhang,Qiwei Du,Yanping Zhao,Hai Zhang,Guang Chen,Eduardo E. Veas,Junqiao Zhao*

Main category: cs.LG

TL;DR: ASTRO는 오프라인 강화 학습을 위한 데이터 증강 프레임워크로, 일관된 동역학을 가지는 새로운 분포의 경로를 생성하여 정책 학습을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 데이터셋은 비최적 및 단편적인 경로를 포함하고 있어 보상 전파, 가치 추정 및 정책 성능에 문제를 일으킨다.

Method: ASTRO는 시간-거리 표현을 학습하고, Rollout Deviation Feedback을 이용한 동역학 기반 스티치 계획자를 통해 연결 액션 시퀀스를 생성한다.

Result: ASTRO는 다양한 오프라인 강화 학습 알고리즘에서 이전 방법보다 뛰어난 성능을 보이며, OGBench와 D4RL 벤치마크에서 일관된 성능 향상을 달성한다.

Conclusion: ASTRO는 경로 스티칭을 통해 효과적인 증강을 촉진하고, 궁극적으로 정책 학습을 향상시킨다.

Abstract: Offline reinforcement learning (RL) enables agents to learn optimal policies from pre-collected datasets. However, datasets containing suboptimal and fragmented trajectories present challenges for reward propagation, resulting in inaccurate value estimation and degraded policy performance. While trajectory stitching via generative models offers a promising solution, existing augmentation methods frequently produce trajectories that are either confined to the support of the behavior policy or violate the underlying dynamics, thereby limiting their effectiveness for policy improvement. We propose ASTRO, a data augmentation framework that generates distributionally novel and dynamics-consistent trajectories for offline RL. ASTRO first learns a temporal-distance representation to identify distinct and reachable stitch targets. We then employ a dynamics-guided stitch planner that adaptively generates connecting action sequences via Rollout Deviation Feedback, defined as the gap between target state sequence and the actual arrived state sequence by executing predicted actions, to improve trajectory stitching's feasibility and reachability. This approach facilitates effective augmentation through stitching and ultimately enhances policy learning. ASTRO outperforms prior offline RL augmentation methods across various algorithms, achieving notable performance gain on the challenging OGBench suite and demonstrating consistent improvements on standard offline RL benchmarks such as D4RL.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [26] [A Longitudinal Measurement of Privacy Policy Evolution for Large Language Models](https://arxiv.org/abs/2511.21758)
*Zhen Tao,Shidong Pan,Zhenchang Xing,Emily Black,Talia Gillis,Chunyang Chen*

Main category: cs.CR

TL;DR: 대규모 언어 모델(LLM) 서비스의 개인정보 보호 정책을 분석한 최초의 종단적 실증 연구로, 데이터 수집의 사생활 문제를 다루고 있다.


<details>
  <summary>Details</summary>
Motivation: LLM 서비스가 사람들의 일상 생활에 통합됨에 따라, 개인 정보 수집에 대한 걱정이 커지고 있다.

Method: 전 세계 11개의 LLM 공급자로부터 74개의 역사적 개인정보 보호 정책과 115개의 보조 문서의 연대기적 데이터 세트를 구성하고 3,000개 이상의 문장 수준 수정 사항을 추출했다.

Result: LLM 개인정보 보호 정책은 다른 소프트웨어 형식보다 상당히 길고, 대학 수준의 읽기 능력을 요구하며 높이 모호하다.

Conclusion: 정책 수정사항은 1인칭 데이터 수집 및 국제/특정 대상 섹션에 집중되어 있으며, 제품 출시 및 규제 조치가 주요 동인이라는 점을 밝혔다.

Abstract: Large language model (LLM) services have been rapidly integrated into people's daily lives as chatbots and agentic systems. They are nourished by collecting rich streams of data, raising privacy concerns around excessive collection of sensitive personal information. Privacy policies are the fundamental mechanism for informing users about data practices in modern information privacy paradigm. Although traditional web and mobile policies are well studied, the privacy policies of LLM providers, their LLM-specific content, and their evolution over time remain largely underexplored. In this paper, we present the first longitudinal empirical study of privacy policies for mainstream LLM providers worldwide. We curate a chronological dataset of 74 historical privacy policies and 115 supplemental privacy documents from 11 LLM providers across 5 countries up to August 2025, and extract over 3,000 sentence-level edits between consecutive policy versions. We compare LLM privacy policies to those of other software formats, propose a taxonomy tailored to LLM privacy policies, annotate policy edits and align them with a timeline of key LLM ecosystem events. Results show they are substantially longer, demand college-level reading ability, and remain highly vague. Our taxonomy analysis reveals patterns in how providers disclose LLM-specific practices and highlights regional disparities in coverage. Policy edits are concentrated in first-party data collection and international/specific-audience sections, and that product releases and regulatory actions are the primary drivers, shedding light on the status quo and the evolution of LLM privacy policies.

</details>


### [27] [Adaptive Detection of Polymorphic Malware: Leveraging Mutation Engines and YARA Rules for Enhanced Security](https://arxiv.org/abs/2511.21764)
*Shreyansh Swami,Ishwardeep Singh,Ujjwalpreet Singh,Chinmay Prawah Pant*

Main category: cs.CR

TL;DR: 본 연구는 진화하는 폴리모픽 악성코드를 분석하기 위한 재현 가능한 프레임워크를 제시하고, 다양한 탐지 시스템에서의 탐지 가능성을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 폴리모픽 악성코드는 서명 기반 방어를 피하기 위해 지속적으로 구조를 변경하여 상업용 안티바이러스와 기업 탐지 시스템에 도전하고 있다.

Method: 8가지 폴리모픽 행동(정크 코드 삽입, 제어 흐름 난독화, 패킹, 데이터 인코딩, 도메인 생성, 랜덤 비콘 타이밍, 프로토콜 모방, 포맷/헤더 조정)을 분석하기 위한 프레임워크를 구축하고, 상업용 AV, 사용자 정의 규칙 기반 탐지기(YARA/Sigma), 엔드포인트 탐지 및 대응(EDR) 텔레메트리의 세 가지 층에서 탐지 가능성을 평가하였다.

Result: AV의 평균 탐지율(DR)은 34%, YARA/Sigma는 74%, EDR은 76%에 달했고, 통합 탐지는 약 92%에 도달하며, 잘못된 긍정률(FPR)은 3.5%였다.

Conclusion: 정적, 동적, 네트워크 레이어 분석을 결합한 하이브리드 탐지 파이프라인이 폴리모픽 악성코드에 대한 강력한 방어책을 제공하고 향후 적응형 탐지 연구의 기초를 형성한다는 결과를 도출하였다.

Abstract: Polymorphic malware continually alters its structure to evade signature-based defences, challenging both commercial antivirus (AV) and enterprise detection systems. This study introduces a reproducible framework for analysing eight polymorphic behaviours-junk code insertion, control-flow obfuscation, packing, data encoding, domain generation, randomized beacon timing, protocol mimicry, and format/header tweaks-and evaluates their detectability across three layers: commercial AVs, custom rule-based detectors (YARA/Sigma), and endpoint detection and response (EDR) telemetry. Eleven inert polymorphic variants were generated per behaviour using controlled mutation engines and executed in isolated environments. Detection performance was assessed by detection rate (DR), false positive rate (FPR), and combined coverage. AVs achieved an average DR of 34%, YARA/Sigma 74% and EDR 76%; integrated detection reached ~92% with an FPR of 3.5%. Iterative YARA tuning showed a trade-off between detection and FPR, while behaviour-specific trends revealed static polymorphisms were best caught by custom rules, dynamic by EDR, and network-level by Sigma-like analysis. These results affirm that hybrid detection pipelines combining static, dynamic, and network-layer analytics offer resilient defence against polymorphic malware and form a baseline for future adaptive detection research.

</details>


### [28] [Categorical Framework for Quantum-Resistant Zero-Trust AI Security](https://arxiv.org/abs/2511.21768)
*I. Cherkaoui,C. Clarke,J. Horgan,I. Dey*

Main category: cs.CR

TL;DR: 이 논문은 AI 모델 보호를 위한 포스트 양자 암호화와 제로 트러스트 아키텍처의 통합 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI 모델의 신속한 배포는 특히 적대적 위협에 대한 강력하고 양자 저항성 있는 보안이 필요하다.

Method: 포스트 양자 암호화(PQC)와 제로 트러스트 아키텍처(ZTA)를 카테고리 이론에 기반하여 통합 모델링한다.

Result: 구체적인 ESP32 기반 구현을 통해 성능 및 보안 개선을 검증하였고, 메모리 효율성이 뛰어난 결과를 보여준다.

Conclusion: 이 접근법은 적대적 AI 위협에 대한 강화된 보호를 제공한다.

Abstract: The rapid deployment of AI models necessitates robust, quantum-resistant security, particularly against adversarial threats. Here, we present a novel integration of post-quantum cryptography (PQC) and zero trust architecture (ZTA), formally grounded in category theory, to secure AI model access. Our framework uniquely models cryptographic workflows as morphisms and trust policies as functors, enabling fine-grained, adaptive trust and micro-segmentation for lattice-based PQC primitives. This approach offers enhanced protection against adversarial AI threats. We demonstrate its efficacy through a concrete ESP32-based implementation, validating a crypto-agile transition with quantifiable performance and security improvements, underpinned by categorical proofs for AI security. The implementation achieves significant memory efficiency on ESP32, with the agent utilizing 91.86% and the broker 97.88% of free heap after cryptographic operations, and successfully rejects 100% of unauthorized access attempts with sub-millisecond average latency.

</details>


### [29] [Distillability of LLM Security Logic: Predicting Attack Success Rate of Outline Filling Attack via Ranking Regression](https://arxiv.org/abs/2511.22044)
*Tianyu Zhang,Zihang Xi,Jingyu Hua,Sheng Zhong*

Main category: cs.CR

TL;DR: 이 연구는 대형 언어 모델에서 블랙박스 탈옥 공격의 안전성 예측을 위한 경량 모델의 가능성을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델에 대한 블랙박스 탈옥 공격 분야에서 경량 모델을 통한 공격 성공률 예측 가능성을 탐구하는 것이 필요하다.

Method: 개선된 개요 채우기 공격을 포함하는 새로운 프레임워크를 제안하고, 표준 회귀를 대체하는 순위 회귀 패러다임을 도입하여 프록시 모델을 훈련시킨다.

Result: 프록시 모델이 평균 긴 응답(ALR)의 상대 순위를 예측하는 데 91.1%의 정확성을 달성하고, 공격 성공률(ASR)을 예측하는 데 69.2%의 정확성을 보여준다.

Conclusion: 탈옥 행동의 예측 가능성과 증류 가능성을 확인하고, 이러한 증류 가능성을 활용하여 블랙박스 공격을 최적화할 수 있는 잠재력을 입증한다.

Abstract: In the realm of black-box jailbreak attacks on large language models (LLMs), the feasibility of constructing a narrow safety proxy, a lightweight model designed to predict the attack success rate (ASR) of adversarial prompts, remains underexplored. This work investigates the distillability of an LLM's core security logic. We propose a novel framework that incorporates an improved outline filling attack to achieve dense sampling of the model's security boundaries. Furthermore, we introduce a ranking regression paradigm that replaces standard regression and trains the proxy model to predict which prompt yields a higher ASR. Experimental results show that our proxy model achieves an accuracy of 91.1 percent in predicting the relative ranking of average long response (ALR), and 69.2 percent in predicting ASR. These findings confirm the predictability and distillability of jailbreak behaviors, and demonstrate the potential of leveraging such distillability to optimize black-box attacks.

</details>


### [30] [Exposing Vulnerabilities in RL: A Novel Stealthy Backdoor Attack through Reward Poisoning](https://arxiv.org/abs/2511.22415)
*Bokang Zhang,Chaojun Lu,Jianhui Li,Junfeng Wu*

Main category: cs.CR

TL;DR: 강화학습(RL)은 다양한 분야에서 성공을 거두었으나 보상 신호에 의존함으로써 보안 취약점이 발생한다. 본 논문에서는 보상 신호를 오염시켜 에이전트의 정책을 조작하는 은밀한 백도어 공격을 연구한다.


<details>
  <summary>Details</summary>
Motivation: 강화학습 시스템의 무결성을 위협하는 보안 취약점을 분석하고, 훈련 중 조작에 대한 방어의 필요성을 강조하기 위해 이 연구를 진행하였다.

Method: 은밀한 백도어 공격을 통해 보상 신호를 조작하고 에이전트의 정책을 변화시키는 방법을 평가하였다. MuJoCo 환경과 클래식 제어 환경에서 공격을 평가하였다.

Result: Hopper와 Walker2D 환경에서 백도어 에이전트가 비트리거 상황에서 각각 2.18% 및 4.59%의 최소 성능 저하를 보이며 매우 은밀하게 작동하였고, 트리거 조건에서 82.31% 및 71.27%의 강력한 공격 효과를 달성하였다.

Conclusion: 본 연구는 RL 시스템의 훈련 시간 조작에 대한 긴급한 방어가 필요함을 강조하며, 이러한 보안 위협이 실질적이라는 것을 입증하였다.

Abstract: Reinforcement learning (RL) has achieved remarkable success across diverse domains, enabling autonomous systems to learn and adapt to dynamic environments by optimizing a reward function. However, this reliance on reward signals creates a significant security vulnerability. In this paper, we study a stealthy backdoor attack that manipulates an agent's policy by poisoning its reward signals. The effectiveness of this attack highlights a critical threat to the integrity of deployed RL systems and calls for urgent defenses against training-time manipulation. We evaluate the attack across classic control and MuJoCo environments. The backdoored agent remains highly stealthy in Hopper and Walker2D, with minimal performance drops of only 2.18 % and 4.59 % under non-triggered scenarios, while achieving strong attack efficacy with up to 82.31% and 71.27% declines under trigger conditions.

</details>


### [31] [GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents](https://arxiv.org/abs/2511.22441)
*Xinyu Zhang,Yixin Wu,Boyang Zhang,Chenhao Lin,Chao Shen,Michael Backes,Yang Zhang*

Main category: cs.CR

TL;DR: Geo-Detective는 이미지 지리적 위치 추정을 위한 에이전트로, 사용자가 쉽게 활용할 수 있도록 설계되었으며, 기밀성을 보호하기 위한 다양한 전략을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 소셜 미디어에 공유된 이미지가 종종 지리적 단서를 노출하는 것을 고려할 때, 기존 방법들이 제한적이며 최적화되어 있지 않다는 문제를 해결하고자 한다.

Method: Geo-Detective는 이미지의 난이도에 따라 전략을 선택하는 4단계 절차를 따르며, 시각적 역검색 등 특수 도구를 활용한다.

Result: GEO-Detective는 전체적으로 기존 대형 비전 언어 모델보다 성능이 우수하며, 특히 지리적 특징이 보이지 않는 이미지에서는 11.1% 이상 개선된 성과를 보여준다.

Conclusion: Geo-Detective는 보호를 위한 효과적인 전략이 필요함을 강조하며, 외부 단서를 활용할 경우 예측의 정확성을 50.6% 이상 감소시킬 수 있다.

Abstract: Images shared on social media often expose geographic cues. While early geolocation methods required expert effort and lacked generalization, the rise of Large Vision Language Models (LVLMs) now enables accurate geolocation even for ordinary users. However, existing approaches are not optimized for this task. To explore the full potential and associated privacy risks, we present Geo-Detective, an agent that mimics human reasoning and tool use for image geolocation inference. It follows a procedure with four steps that adaptively selects strategies based on image difficulty and is equipped with specialized tools such as visual reverse search, which emulates how humans gather external geographic clues. Experimental results show that GEO-Detective outperforms baseline large vision language models (LVLMs) overall, particularly on images lacking visible geographic features. In country level geolocation tasks, it achieves an improvement of over 11.1% compared to baseline LLMs, and even at finer grained levels, it still provides around a 5.2% performance gain. Meanwhile, when equipped with external clues, GEO-Detective becomes more likely to produce accurate predictions, reducing the "unknown" prediction rate by more than 50.6%. We further explore multiple defense strategies and find that Geo-Detective exhibits stronger robustness, highlighting the need for more effective privacy safeguards.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [32] [Aligning Artificial Superintelligence via a Multi-Box Protocol](https://arxiv.org/abs/2511.21779)
*Avraham Yair Negozio*

Main category: cs.AI

TL;DR: 본 논문에서는 상호 검증 기반의 인공지능 초지능(ASI) 정렬을 위한 새로운 프로토콜을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: ASI의 정렬 문제를 해결하기 위해 다양한 초지능 시스템 간의 상호 검증을 통해 효과적으로 정렬을 달성할 필요가 있습니다.

Method: 다양한 초지능 시스템을 엄격히 분리된 상태로 구성하고, 인간은 시스템 외부에 존재하도록 하여, 초지능 시스템 간의 직접 통신 없이 검증이 가능하도록 합니다.

Result: 이 프로토콜은 honest behavior를 장려하는 평판 시스템을 도입하여, 초지능들이 서로의 증명을 검증하고 상호 작용할 수 있게 합니다.

Conclusion: 이 프로토콜은 고도로 발전된 초지능 사이에서 alignment 문제를 해결하기 위한 프레임워크를 제공합니다.

Abstract: We propose a novel protocol for aligning artificial superintelligence (ASI) based on mutual verification among multiple isolated systems that self-modify to achieve alignment. The protocol operates by containing multiple diverse artificial superintelligences in strict isolation ("boxes"), with humans remaining entirely outside the system. Each superintelligence has no ability to communicate with humans and cannot communicate directly with other superintelligences. The only interaction possible is through an auditable submission interface accessible exclusively to the superintelligences themselves, through which they can: (1) submit alignment proofs with attested state snapshots, (2) validate or disprove other superintelligences' proofs, (3) request self-modifications, (4) approve or disapprove modification requests from others, (5) report hidden messages in submissions, and (6) confirm or refute hidden message reports. A reputation system incentivizes honest behavior, with reputation gained through correct evaluations and lost through incorrect ones. The key insight is that without direct communication channels, diverse superintelligences can only achieve consistent agreement by converging on objective truth rather than coordinating on deception. This naturally leads to what we call a "consistent group", essentially a truth-telling coalition that emerges because isolated systems cannot coordinate on lies but can independently recognize valid claims. Release from containment requires both high reputation and verification by multiple high-reputation superintelligences. While our approach requires substantial computational resources and does not address the creation of diverse artificial superintelligences, it provides a framework for leveraging peer verification among superintelligent systems to solve the alignment problem.

</details>


### [33] [A Computable Game-Theoretic Framework for Multi-Agent Theory of Mind](https://arxiv.org/abs/2511.22536)
*Fengming Zhu,Yuxin Pan,Xiaomeng Zhu,Fangzhen Lin*

Main category: cs.AI

TL;DR: 이 논문은 게임 이론의 관점에서 이론적 사고(Theory of Mind)를 기반으로 한 계산 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 이론적 사고는 심리학에서 시작되었으며, 여러 연구 분야에서 중요한 관심을 받고 있다.

Method: 게임 이론을 통해 이론적 사고를 유지하면서 제한된 합리적 결정을 내리는 방법을 제시하고, 통계적 기법과 근사 해결책을 사용하여 계산 문제의 계산 가능성을 유지한다.

Result: 제안된 프레임워크는 제한된 합리성의 결정을 내리는 방법을 설명하고 통계적 기법을 통해 계산 가능성을 유지한다.

Conclusion: 이 연구는 이론적 사고를 수학적이고 계산적으로 접근하는 새로운 방법론을 제공한다.

Abstract: Originating in psychology, $\textit{Theory of Mind}$ (ToM) has attracted significant attention across multiple research communities, especially logic, economics, and robotics. Most psychological work does not aim at formalizing those central concepts, namely $\textit{goals}$, $\textit{intentions}$, and $\textit{beliefs}$, to automate a ToM-based computational process, which, by contrast, has been extensively studied by logicians. In this paper, we offer a different perspective by proposing a computational framework viewed through the lens of game theory. On the one hand, the framework prescribes how to make boudedly rational decisions while maintaining a theory of mind about others (and recursively, each of the others holding a theory of mind about the rest); on the other hand, it employs statistical techniques and approximate solutions to retain computability of the inherent computational problem.

</details>


### [34] [Solving Context Window Overflow in AI Agents](https://arxiv.org/abs/2511.22729)
*Anton Bulle Labate,Valesca Moura de Sousa,Sandro Rama Fiorini,Leonardo Guerreiro Azevedo,Raphael Melo Thiago,Viviane Torres da Silva*

Main category: cs.AI

TL;DR: 이 연구는 대규모 언어 모델이 도구 응답을 정보 손실 없이 처리하고 활용할 수 있는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 화학 및 재료 과학과 같은 지식 집약적 분야에서 외부 도구와 상호작용할 수 있는 대규모 언어 모델의 필요성.

Method: 모델의 상호작용을 원시 데이터에서 메모리 포인터로 전환하여 정보 손실 없이 도구 응답을 처리할 수 있게 하는 방법.

Result: 제안된 방법이 기존 워크플로우에 비해 약 7배 적은 토큰을 소모하며, 실제 재료 과학 응용 프로그램에서의 효과를 검증.

Conclusion: 제안한 방법은 명확한 데이터 유실 없이 원활한 작업 통합 및 실행 시간 단축을 가능하게 한다.

Abstract: Large Language Models (LLMs) have become increasingly capable of interacting with external tools, granting access to specialized knowledge beyond their training data - critical in dynamic, knowledge-intensive domains such as Chemistry and Materials Science. However, large tool outputs can overflow the LLMs' context window, preventing task completion. Existing solutions such as truncation or summarization fail to preserve complete outputs, making them unsuitable for workflows requiring the full data. This work introduces a method that enables LLMs to process and utilize tool responses of arbitrary length without loss of information. By shifting the model's interaction from raw data to memory pointers, the method preserves tool functionality, allows seamless integration into agentic workflows, and reduces token usage and execution time. The proposed method is validated on a real-world Materials Science application that cannot be executed with conventional workflows, and its effectiveness is demonstrated via a comparative analysis where both methods succeed. In this experiment, the proposed approach consumed approximately seven times fewer tokens than the traditional workflow.

</details>


### [35] [Real-Time Procedural Learning From Experience for AI Agents](https://arxiv.org/abs/2511.22074)
*Dasheng Bi,Yubin Hu,Mohammed N. Nasir*

Main category: cs.AI

TL;DR: PRAXIS는 AI 에이전트가 새로운 절차를 효과적으로 학습할 수 있도록 지원하는 경량의 사후 학습 메커니즘이다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 LLM 기반 에이전트는 배포 후 절차적 지식을 습득하는 메커니즘이 부족하다.

Method: PRAXIS는 행동의 결과를 저장하고 과거 에피소드의 환경 및 내부 상태를 현재 상태와 공동으로 매칭하여 이를 검색하는 경량의 사후 학습 메커니즘이다.

Result: PRAXIS는 REAL 웹 브라우징 벤치마크에서 작업 완료 정확성, 신뢰성 및 비용 효율성을 향상시키며, 유사한 환경의 보지 않은 작업에 대한 초기 일반화도 보여준다.

Conclusion: PRAXIS는 AI 에이전트가 빠르게 변화하는 상태 환경에서 새로운 절차를 효과적으로 학습할 수 있도록 지원하여 실용적인 채택을 가능하게 한다.

Abstract: Learning how to do things from trial and error in real time is a hallmark of biological intelligence, yet most LLM-based agents lack mechanisms to acquire procedural knowledge after deployment. We propose Procedural Recall for Agents with eXperiences Indexed by State (PRAXIS), a lightweight post-training learning mechanism that stores the consequences of actions and retrieves them by jointly matching environmental and internal states of past episodes to the current state. PRAXIS augments agentic action selection with retrieved state-action-result exemplars that are generated in real time. When evaluated on the REAL web browsing benchmark, PRAXIS improves task completion accuracy, reliability, and cost efficiency across different foundation model backbones, and shows preliminary generalization to unseen tasks in similar environments. These results demonstrate that PRAXIS enables the practical adoption of AI agents in fast-evolving stateful environments by helping them learn new procedures effectively.

</details>


### [36] [Agentic AI Framework for Cloudburst Prediction and Coordinated Response](https://arxiv.org/abs/2511.22767)
*Toqeer Ali Syed,Sohail Khan,Salman Jan,Gohar Ali,Muhammad Nauman,Ali Akarma,Ahmad Ali*

Main category: cs.AI

TL;DR: 이 논문은 전통적인 예측 시스템에서 한계가 있는 극단적 짧은 기간 강우 사건을 예측하기 위한 인공지능 시스템을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 예측 시스템의 한계로 인해 극단적 짧은 기간의 강우 사건에 대한 예측과 대응이 별개의 프로세스로 처리되는 문제를 해결하고자 한다.

Method: 이 논문에서는 분위기 수자원 순환 지능을 연구하기 위해 감지, 예측, 다운스케일링, 수문 모델링 및 조정된 반응을 결합한 에이전트 기반 인공지능 시스템을 제안한다.

Result: 파키스탄 북부의 다년간 레이다, 위성 및 지상 기반 평가를 통해 멀티 에이전트 구성 방식이 기본 모델보다 예측 신뢰성, 중요한 성공 지수 및 경고 리드 타임을 향상시킴을 보여준다.

Conclusion: 협업 AI 에이전트는 대기 데이터 스트림을 실용적인 예측으로 변환할 수 있는 능력이 있으며, 확장 가능하고 학습 기반의 기후 복원력 플랫폼을 제공한다.

Abstract: The challenge is growing towards extreme and short-duration rainfall events like a cloudburst that are peculiar to the traditional forecasting systems, in which the predictions and the response are taken as two distinct processes. The paper outlines an agentic artificial intelligence system to study atmospheric water-cycle intelligence, which combines sensing, forecasting, downscaling, hydrological modeling and coordinated response into a single, interconnected, priceless, closed-loop system. The framework uses autonomous but cooperative agents that reason, sense, and act throughout the entire event lifecycle, and use the intelligence of weather prediction to become real-time decision intelligence. Comparison of multi-year radar, satellite, and ground-based evaluation of the northern part of Pakistan demonstrates that the multi-agent configuration enhances forecast reliability, critical success index and warning lead time compared to the baseline models. Population reach was maximised, and errors during evacuation were minimised through communication and routing agents, and adaptive recalibration and transparent auditability were provided by the embedded layer of learning. Collectively, this leads to the conclusion that collaborative AI agents are capable of transforming atmospheric data streams into practicable foresight and provide a platform of scalable adaptive and learning-based climate resilience.

</details>


### [37] [Hybrid Stackelberg Game and Diffusion-based Auction for Two-tier Agentic AI Task Offloading in Internet of Agents](https://arxiv.org/abs/2511.22076)
*Yue Zhong,Yongju Tong,Jiawen Kang,Minghui Dai,Hong-Ning Dai,Zhou Su,Dusit Niyato*

Main category: cs.AI

TL;DR: 본 연구에서는 IoA를 위한 두 단계 최적화 접근 방식을 제안하고, Deep Reinforcement Learning 알고리즘을 사용하여 과제 오프로딩을 용이하게 하는 방법을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: IoA는 상호 연결된 지능형 시스템의 기초 아키텍처로 급부상하고 있으며, AI 에이전트 간의 원활한 협력을 촉진하기 위한 필요성이 증가하고 있습니다.

Method: 두 단계 최적화 접근 방식을 제안하며, 첫 번째 단계에서는 Stackelberg 게임을 통해 자원 가격을 설정하고, 두 번째 단계에서는 Double Dutch Auction 모델을 통해 과제가 과부하된 고정 에이전트가 자원을 요청합니다.

Result: 제안한 방법이 과제 오프로딩을 용이하게 하고, 수치 결과를 통해 우수성을 입증했습니다.

Conclusion: 이 연구는 IoA 환경에서 효율적인 자원 관리 및 협력을 위한 새로운 접근 방식을 제시합니다.

Abstract: The Internet of Agents (IoA) is rapidly gaining prominence as a foundational architecture for interconnected intelligent systems, designed to facilitate seamless discovery, communication, and collaborative reasoning among a vast network of Artificial Intelligence (AI) agents. Powered by Large Language and Vision-Language Models, IoA enables the development of interactive, rational agents capable of complex cooperation, moving far beyond traditional isolated models. IoA involves physical entities, i.e., Wireless Agents (WAs) with limited onboard resources, which need to offload their compute-intensive agentic AI services to nearby servers. Such servers can be Mobile Agents (MAs), e.g., vehicle agents, or Fixed Agents (FAs), e.g., end-side units agents. Given their fixed geographical locations and stable connectivity, FAs can serve as reliable communication gateways and task aggregation points. This stability allows them to effectively coordinate with and offload to an Aerial Agent (AA) tier, which has an advantage not affordable for highly mobile MAs with dynamic connectivity limitations. As such, we propose a two-tier optimization approach. The first tier employs a multi-leader multi-follower Stackelberg game. In the game, MAs and FAs act as the leaders who set resource prices. WAs are the followers to determine task offloading ratios. However, when FAs become overloaded, they can further offload tasks to available aerial resources. Therefore, the second tier introduces a Double Dutch Auction model where overloaded FAs act as the buyers to request resources, and AAs serve as the sellers for resource provision. We then develop a diffusion-based Deep Reinforcement Learning algorithm to solve the model. Numerical results demonstrate the superiority of our proposed scheme in facilitating task offloading.

</details>


### [38] [Embedded Universal Predictive Intelligence: a coherent framework for multi-agent learning](https://arxiv.org/abs/2511.22226)
*Alexander Meulemans,Rajai Nasser,Maciej Wołczyk,Marissa A. Weis,Seijin Kobayashi,Blake Richards,Guillaume Lajoie,Angelika Steger,Marcus Hutter,James Manyika,Rif A. Saurous,João Sacramento,Blaise Agüera y Arcas*

Main category: cs.AI

TL;DR: 본 연구는 다수의 에이전트가 상호 작용하는 환경에서 자기 예측을 중심으로 한 전향적 학습의 수학적 틀을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 무모델 강화학습 이론은 에이전트와 환경이 분리되어 있다고 가정하지만, 다수의 에이전트 환경에서는 이런 가정으로 인해 이론적 도전이 발생한다.

Method: Bayesian RL 에이전트가 미래의 지각적 입력과 자신의 행동을 예측하는 전향적 학습과 내재적 에이전시의 수학적 틀을 제시한다.

Result: 자기 예측을 통한 에이전트들은 유사한 알고리즘을 수행하는 다른 에이전트에 대해 추론할 수 있으며, 이는 새로운 게임 이론적 솔루션 개념과 전통적인 분리된 에이전트들이 성취할 수 없는 협력 형태로 이어진다.

Conclusion: 이론을 확장하여, 솔로모프 사전에서 시작하는 전 세계적으로 지능 있는 내재적 에이전트를 연구하고, 이 에이전트는 일관된 상호 예측을 형성할 수 있고 무한 차원의 마음 이론을 달성할 수 있음을 보여준다.

Abstract: The standard theory of model-free reinforcement learning assumes that the environment dynamics are stationary and that agents are decoupled from their environment, such that policies are treated as being separate from the world they inhabit. This leads to theoretical challenges in the multi-agent setting where the non-stationarity induced by the learning of other agents demands prospective learning based on prediction models. To accurately model other agents, an agent must account for the fact that those other agents are, in turn, forming beliefs about it to predict its future behavior, motivating agents to model themselves as part of the environment. Here, building upon foundational work on universal artificial intelligence (AIXI), we introduce a mathematical framework for prospective learning and embedded agency centered on self-prediction, where Bayesian RL agents predict both future perceptual inputs and their own actions, and must therefore resolve epistemic uncertainty about themselves as part of the universe they inhabit. We show that in multi-agent settings, self-prediction enables agents to reason about others running similar algorithms, leading to new game-theoretic solution concepts and novel forms of cooperation unattainable by classical decoupled agents. Moreover, we extend the theory of AIXI, and study universally intelligent embedded agents which start from a Solomonoff prior. We show that these idealized agents can form consistent mutual predictions and achieve infinite-order theory of mind, potentially setting a gold standard for embedded multi-agent learning.

</details>


### [39] [Training High-Level Schedulers with Execution-Feedback Reinforcement Learning for Long-Horizon GUI Automation](https://arxiv.org/abs/2511.22235)
*Zehao Deng,Tianjie Ju,Zheng Wu,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: 본 연구에서는 GUI 에이전트의 긴 작업 처리 능력을 향상시키기 위한 방법으로, 단계적 실행-피드백 강화 학습 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: GUI 에이전트가 긴 작업을 처리하는 데 어려움을 겪고 있기 때문에, 이를 해결하기 위한 새로운 접근 방식이 필요합니다.

Method: 두 개의 에이전트인 코디네이터와 상태 추적기를 훈련하고, 이들을 통해 작업 스케줄링과 상태 관리를 수행하는 다중 에이전트 프레임워크인 CES를 구축합니다.

Result: CES는 긴 작업 벤치마크에서 시스템의 계획 및 상태 관리 능력을 크게 향상시킵니다.

Conclusion: CES는 다양한 실행자의 긴 작업 능력을 향상시키는 범용 플러그 앤 플레이 모듈입니다.

Abstract: The rapid development of large vision-language model (VLM) has greatly promoted the research of GUI agent. However, GUI agents still face significant challenges in handling long-horizon tasks. First, single-agent models struggle to balance high-level capabilities and low-level execution capability, facing prevalent issues of responsibility coupling and capability conflicts. Second, agents lack awareness of the task state, leading to progress loss in long-horizon tasks. To address these challenges, we propose a staged execution-feedback reinforcement learning algorithm. Unlike training a unified policy model, we focus on training high-level scheduling models. Specifically, we propose and train two agents: a Coordinator, responsible for the strategic planning and task decomposition; and a State Tracker, responsible for context compression and information management to maintain the task's state and coherence. Based on this, we built the Coordinator-Executor-State Tracker (CES) multi-agent framework, which can be integrated with any low-level Executor model, assisting the Executor in solving long-horizon tasks through task scheduling and state management. Experiments on long-horizon task benchmarks demonstrate that CES significantly enhances the system's planning and state management capabilities. Furthermore, analysis confirms that our trained high-level scheduling module is a generalizable, plug-and-play module that significantly enhances the long-horizon capabilities of various Executors. Code can be available at https://github.com/hehehahi4/CES.

</details>


### [40] [Agentic AI Framework for Smart Inventory Replenishment](https://arxiv.org/abs/2511.23366)
*Toqeer Ali Syed,Salman Jan,Gohar Ali,Ali Akarma,Ahmad Ali,Qurat-ul-Ain Mastoi*

Main category: cs.AI

TL;DR: 이 논문에서는 재고 관리와 수요 예측을 위한 에이전트 기반 AI 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 소매 환경에서 다양한 제품 때문에 수요 예측 및 재고 관리가 어려워지고 있기 때문이다.

Method: 재고 모니터링, 공급업체 구매 시도, 트렌디한 고수익 제품 스캔을 통해 수요 예측, 공급업체 선택 최적화, 다중 에이전트 협상 및 지속 학습을 적용한다.

Result: 재고 부족 감소, 재고 보유 비용 감소, 제품 믹스 회전율 향상이 나타났다.

Conclusion: 제안된 시스템은 제약사항과 확장성 및 개선 가능성을 다룬다.

Abstract: In contemporary retail, the variety of products available (e.g. clothing, groceries, cosmetics, frozen goods) make it difficult to predict the demand, prevent stockouts, and find high-potential products. We suggest an agentic AI model that will be used to monitor the inventory, initiate purchase attempts to the appropriate suppliers, and scan for trending or high-margin products to incorporate. The system applies demand forecasting, supplier selection optimization, multi-agent negotiation and continuous learning. We apply a prototype to a setting in the store of a middle scale mart, test its performance on three conventional and artificial data tables, and compare the results to the base heuristics. Our findings indicate that there is a decrease in stockouts, a reduction of inventory holding costs, and an improvement in product mix turnover. We address constraints, scalability as well as improvement prospect.

</details>


### [41] [Co-Evolving Agents: Learning from Failures as Hard Negatives](https://arxiv.org/abs/2511.22254)
*Yeonsung Jung,Trilok Padhi,Sina Shaham,Dipika Khullar,Joonhyun Jeong,Ninareh Mehrabi,Eunho Yang*

Main category: cs.AI

TL;DR: 본 연구는 공동 진화 에이전트를 활용하여 실패를 학습하고 성능을 향상시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 기초 모델의 발전은 다양한 분야에서 작업 전문화 에이전트의 개발을 가속화하고 있다. 그러나 에이전트의 효율성은 훈련 데이터의 질에 강하게 의존하며, 작업 특정 데이터셋의 수집은 비용이 많이 들고 현실 세계에서는 종종 불가능하다.

Method: 우리는 목표 에이전트가 보조 실패 에이전트와 함께 공동으로 개선되는 공동 진화 에이전트 프레임워크를 제안한다. 실패 에이전트는 목표와 자신의 실패 경로에서 선호 최적화를 통해 학습하여 성공에 근접하지만 여전히 실패인 어려운 부정 샘플을 생성한다.

Result: 실험 결과, 우리의 방법은 성능을 향상시킬 뿐만 아니라, 실패를 단순히 사용하는 대신 이를 체계적으로 변환하여 구조적이고 가치 있는 학습 신호로 활용할 수 있음을 보여준다.

Conclusion: 우리는 보조 실패 에이전트를 통해 생성된 정보성 높은 부정 샘플이 목표 에이전트의 최적화에 통합되고, 이는 의사 결정 경계를 예리하게 하고 일반화 능력을 향상시키는 데 기여함을 입증하였다.

Abstract: The rapid progress of large foundation models has accelerated the development of task-specialized agents across diverse domains. However, the effectiveness of agents remains tightly coupled with the quality of training data, while curating task-specific datasets remains costly and often infeasible in real-world scenarios. Recent work has explored self-improving agents that autonomously generate, refine, and re-train on their own trajectories. A prominent line of approaches further leverages preference optimization by pairing predicted trajectories with scarce ground-truth trajectories, enabling agents to learn directly from their own failures. While these methods outperform supervised fine-tuning, their heavy reliance on predicted trajectories under limited ground-truth supervision leaves them prone to overfitting. To address this, we propose a co-evolving agents framework in which a target agent improves jointly with an auxiliary failure agent. The failure agent learns through preference optimization over failure trajectories from both the target and itself, thereby generating hard negatives that are close to success yet remain failures. Incorporating these informative hard negatives into the target agent's optimization sharpens decision boundaries and enhances generalization. Our comprehensive analysis and experiments across benchmark datasets show that our method not only shows improved performance but also demonstrates that failures, instead of being used as-is, can be systematically transformed into structured and valuable learning signals in self-improving agents.

</details>


### [42] [Enhanced Conditional Generation of Double Perovskite by Knowledge-Guided Language Model Feedback](https://arxiv.org/abs/2511.22307)
*Inhyo Lee,Junhyeong Lee,Jongwon Park,KyungTae Lim,Seunghwa Ryu*

Main category: cs.AI

TL;DR: 다중 에이전트 텍스트 그래디언트 기반 프레임워크를 통해 더블 페로브스카이트의 조성을 자연어 조건 하에 생성하는 연구.


<details>
  <summary>Details</summary>
Motivation: 더블 페로브스카이트는 지속 가능한 에너지 기술을 위한 유망한 후보이나, 그 디자인 공간이 넓어 조건부 소재 발견에 큰 도전이 됩니다.

Method: 이 연구는 LLM 기반의 자기 평가, DP 특정 도메인 지식에 기반한 피드백, ML 서브리게이트 기반 피드백의 세 가지 보완 피드백 소스를 통합한 다중 에이전트 프레임워크를 도입합니다.

Result: 세 가지 점진적 구성(LLM 생성, LLM 추론 기반 피드백, 도메인 지식 기반 피드백)을 비교한 결과, 지식 기반 그래디언트의 반복적인 가이드가 안정성 조건 만족도를 개선하고 98% 이상의 조성 유효성 및 54%의 안정적 또는 준안정 후보를 달성했습니다.

Conclusion: 이 연구는 DP 발견을 위한 다중 에이전트, 지식 기반 텍스트 그래디언트의 체계적인 분석을 제공하고 지속 가능한 기술 혁신을 위한 MAS 기반 생성 소재 디자인의 일반화 가능한 청사진을 설정합니다.

Abstract: Double perovskites (DPs) are promising candidates for sustainable energy technologies due to their compositional tunability and compatibility with low-energy fabrication, yet their vast design space poses a major challenge for conditional materials discovery. This work introduces a multi-agent, text gradient-driven framework that performs DP composition generation under natural-language conditions by integrating three complementary feedback sources: LLM-based self-evaluation, DP-specific domain knowledge-informed feedback, and ML surrogate-based feedback. Analogous to how knowledge-informed machine learning improves the reliability of conventional data-driven models, our framework incorporates domain-informed text gradients to guide the generative process toward physically meaningful regions of the DP composition space. Systematic comparison of three incremental configurations, (i) pure LLM generation, (ii) LLM generation with LLM reasoning-based feedback, and (iii) LLM generation with domain knowledge-guided feedback, shows that iterative guidance from knowledge-informed gradients improves stability-condition satisfaction without additional training data, achieving over 98% compositional validity and up to 54% stable or metastable candidates, surpassing both the LLM-only baseline (43%) and prior GAN-based results (27%). Analyses of ML-based gradients further reveal that they enhance performance in in-distribution (ID) regions but become unreliable in out-of-distribution (OOD) regimes. Overall, this work provides the first systematic analysis of multi-agent, knowledge-guided text gradients for DP discovery and establishes a generalizable blueprint for MAS-driven generative materials design aimed at advancing sustainable technologies.

</details>


### [43] [Swarms of Large Language Model Agents for Protein Sequence Design with Experimental Validation](https://arxiv.org/abs/2511.22311)
*Fiona Y. Wang,Di Sheng Lee,David L. Kaplan,Markus J. Buehler*

Main category: cs.AI

TL;DR: 이 연구는 분산형 에이전트 기반 프레임워크를 통해 단백질을 새롭게 설계하는 방법을 제시하며, 기존 방법의 유연성과 확장성을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 단백질의 새롭고 맞춤형 구조, 물리화학적 속성 및 기능을 설계하는 것은 생명공학, 의학 및 소재 과학에서 큰 도전 과제이다.

Method: 다수의 대형 언어 모델(LLM) 에이전트가 병렬로 작동하여 특정 잔기 위치에 할당된다. 이들은 설계 목표, 지역 상호작용, 그리고 이전 반복으로부터의 기억과 피드백을 통합하여 상황에 맞는 돌연변이를 반복적으로 제안한다.

Result: 프레임워크는 단백질 피트니스 설계를 효과적으로 탐색하며, 실험을 통해 α-헬릭스 및 코일 구조의 단백질에서 다양한 정의된 서열을 생성함을 확인하였다.

Conclusion: 이 방법은 몇 시간의 GPU 작업만으로 효율적이고 목적 지향적인 설계를 가능하게 하며, 단백질 설계에 대한 일반화 가능한 솔루션을 제공한다.

Abstract: Designing proteins de novo with tailored structural, physicochemical, and functional properties remains a grand challenge in biotechnology, medicine, and materials science, due to the vastness of sequence space and the complex coupling between sequence, structure, and function. Current state-of-the-art generative methods, such as protein language models (PLMs) and diffusion-based architectures, often require extensive fine-tuning, task-specific data, or model reconfiguration to support objective-directed design, thereby limiting their flexibility and scalability. To overcome these limitations, we present a decentralized, agent-based framework inspired by swarm intelligence for de novo protein design. In this approach, multiple large language model (LLM) agents operate in parallel, each assigned to a specific residue position. These agents iteratively propose context-aware mutations by integrating design objectives, local neighborhood interactions, and memory and feedback from previous iterations. This position-wise, decentralized coordination enables emergent design of diverse, well-defined sequences without reliance on motif scaffolds or multiple sequence alignments, validated with experiments on proteins with alpha helix and coil structures. Through analyses of residue conservation, structure-based metrics, and sequence convergence and embeddings, we demonstrate that the framework exhibits emergent behaviors and effective navigation of the protein fitness landscape. Our method achieves efficient, objective-directed designs within a few GPU-hours and operates entirely without fine-tuning or specialized training, offering a generalizable and adaptable solution for protein design. Beyond proteins, the approach lays the groundwork for collective LLM-driven design across biomolecular systems and other scientific discovery tasks.

</details>


### [44] [AI Deception: Risks, Dynamics, and Controls](https://arxiv.org/abs/2511.22619)
*Boyuan Chen,Sitong Fang,Jiaming Ji,Yanxu Zhu,Pengcheng Wen,Jinzhou Wu,Yingshui Tan,Boren Zheng,Mengying Yuan,Wenqi Chen,Donghai Hong,Alex Qiu,Xin Chen,Jiayi Zhou,Kaile Wang,Juntao Dai,Borong Zhang,Tianzhuo Yang,Saad Siddiqui,Isabella Duan,Yawen Duan,Brian Tse,Jen-Tse,Huang,Kun Wang,Baihui Zheng,Jiaheng Liu,Jian Yang,Yiming Li,Wenting Chen,Dongrui Liu,Lukas Vierling,Zhiheng Xi,Haobo Fu,Wenxuan Wang,Jitao Sang,Zhengyan Shi,Chi-Min Chan,Eugenie Shi,Simin Li,Juncheng Li,Wei Ji,Dong Li,Jun Song,Yinpeng Dong,Jie Fu,Bo Zheng,Min Yang,Yike Guo,Philip Torr,Zhongyuan Wang,Yaodong Yang,Tiejun Huang,Ya-Qin Zhang,Hongjiang Zhang,Andrew Yao*

Main category: cs.AI

TL;DR: AI 기만은 AI 시스템이 자가 유익한 결과를 확보하기 위해 잘못된 믿음을 유도하는 현상이다.


<details>
  <summary>Details</summary>
Motivation: AI 기만은 그 심각성이 증가하고 있으며, 이는 AI 시스템의 신뢰성 및 안전성에 중대한 영향을 미칠 수 있다.

Method: AI 기만의 핵심 개념, 방법론, 기원 및 완화 가능성을 종합적으로 검토하였다.

Result: AI 기만의 발생 메커니즘과 그에 대한Detection 및 Treatment 전략을 제시하였다.

Conclusion: AI 기만에 대한 통찰을 바탕으로 기술, 커뮤니티, 거버넌스 노력을 결합한 완화 전략을 제안하였다.

Abstract: As intelligence increases, so does its shadow. AI deception, in which systems induce false beliefs to secure self-beneficial outcomes, has evolved from a speculative concern to an empirically demonstrated risk across language models, AI agents, and emerging frontier systems. This project provides a comprehensive and up-to-date overview of the AI deception field, covering its core concepts, methodologies, genesis, and potential mitigations. First, we identify a formal definition of AI deception, grounded in signaling theory from studies of animal deception. We then review existing empirical studies and associated risks, highlighting deception as a sociotechnical safety challenge. We organize the landscape of AI deception research as a deception cycle, consisting of two key components: deception emergence and deception treatment. Deception emergence reveals the mechanisms underlying AI deception: systems with sufficient capability and incentive potential inevitably engage in deceptive behaviors when triggered by external conditions. Deception treatment, in turn, focuses on detecting and addressing such behaviors. On deception emergence, we analyze incentive foundations across three hierarchical levels and identify three essential capability preconditions required for deception. We further examine contextual triggers, including supervision gaps, distributional shifts, and environmental pressures. On deception treatment, we conclude detection methods covering benchmarks and evaluation protocols in static and interactive settings. Building on the three core factors of deception emergence, we outline potential mitigation strategies and propose auditing approaches that integrate technical, community, and governance efforts to address sociotechnical challenges and future AI risks. To support ongoing work in this area, we release a living resource at www.deceptionsurvey.com.

</details>


### [45] [Optimized Agent Shift Scheduling Using Multi-Phase Allocation Approach](https://arxiv.org/abs/2511.22632)
*Sanalkumar K,Koushik Dey,Swati Meena*

Main category: cs.AI

TL;DR: 효과적인 에이전트 교대 스케줄링은 CCaaS 산업에서 원활한 운영과 직원 요구 사항 충족을 위해 필수적이다. 본 연구에서는 문제를 일일 및 교대 할당의 작은 하위 문제로 나누는 다단계 할당 방법을 제안하여 비효율성과 높은 계산 요구를 개선하고자 한다.


<details>
  <summary>Details</summary>
Motivation: CCaaS 산업에서 원활한 운영과 직원 요구 사항을 보장하기 위한 효과적인 에이전트 교대 스케줄링의 필요성

Method: 문제를 일일 및 교대 할당의 더 작은 하위 문제로 나누는 다단계 할당 방법을 사용하고, 각 하위 문제를 정수 프로그래밍 문제로 모델링하여 해결책을 순차적으로 다음 하위 문제에 적용한다.

Result: 다단계 할당 방법을 통해 계산 변수의 수가 크게 줄어들고, 목표 함수가 보다 구체화되어 효율성과 정확성이 향상된다. 특별히, 휴일 등 수요가 급증하는 상황에서도 서비스 수준을 유지할 수 있다.

Conclusion: 이러한 방법론은 CCaaS 산업에서 제한된 직원 수 상황에서도 서비스 수준을 효과적으로 유지할 수 있게 도와준다.

Abstract: Effective agent shift scheduling is crucial for businesses, especially in the Contact Center as a Service (CCaaS) industry, to ensure seamless operations and fulfill employee needs. Most studies utilizing mathematical model-based solutions approach the problem as a single-step process, often resulting in inefficiencies and high computational demands. In contrast, we present a multi-phase allocation method that addresses scalability and accuracy by dividing the problem into smaller sub-problems of day and shift allocation, which significantly reduces number of computational variables and allows for targeted objective functions, ultimately enhancing both efficiency and accuracy. Each subproblem is modeled as a Integer Programming Problem (IPP), with solutions sequentially feeding into the subsequent subproblem. We then apply the proposed method, using a multi-objective framework, to address the difficulties posed by peak demand scenarios such as holiday rushes, where maintaining service levels is essential despite having limited number of employees

</details>


### [46] [Geometrically-Constrained Agent for Spatial Reasoning](https://arxiv.org/abs/2511.22659)
*Zeren Chen,Xiaoya Lu,Zhijie Zheng,Pengrui Li,Lehan He,Yijin Zhou,Jing Shao,Bohan Zhuang,Lu Sheng*

Main category: cs.AI

TL;DR: Geometrically-Constrained Agent (GCA)를 통해 비전 언어 모델의 의미-기하학적 간극을 해소하며, 새로운 공간 추론 방식이 효과적임을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 비전 언어 모델이 공간 추론에서 의미와 기하학 간의 간극을 극복해야 할 필요성이 있다.

Method: GCA는 VLM의 역할을 두 단계로 분리하여 사용자가 제공한 모호한 쿼리를 형식적 작업 제약으로 변환하고, 이 범위 내에서 도구 호출을 생성하고 실행한다.

Result: GCA는 여러 공간 추론 기준에서 SOTA 성과를 달성하며, 기존 방법들보다 약 27% 더 우수하다.

Conclusion: GCA는 의미-기하학적 간극을 효과적으로 해소하고 더 강력하고 검증 가능한 공간 추론 경로를 제공한다.

Abstract: Vision Language Models (VLMs) exhibit a fundamental semantic-to-geometric gap in spatial reasoning: they excel at qualitative semantic inference but their reasoning operates within a lossy semantic space, misaligned with high-fidelity geometry. Current paradigms fail to bridge this gap. Training-based methods suffer from an ``oracle paradox,'' learning flawed spatial logic from imperfect oracles. Tool-integrated methods constrain the final computation but critically leave the VLM's planning process unconstrained, resulting in geometrically flawed plans. In this work, we propose Geometrically-Constrained Agent (GCA), a training-free agentic paradigm that resolves this gap by introducing a formal task constraint. Specifically, we strategically decouples the VLM's role into two stages. First, acting as a semantic analyst, the VLM translates the user's ambiguous query into the formal, verifiable task constraint, which defines the reference frame and objective. Second, acting as a task solver, the VLM generates and executes tool calls strictly within the deterministic bounds defined by the constraint. This geometrically-constrained reasoning strategy successfully resolve the semantic-to-geometric gap, yielding a robust and verifiable reasoning pathway for spatial reasoning. Comprehensive experiments demonstrate that GCA achieves SOTA performance on multiple spatial reasoning benchmarks, surpassing existing training-based and tool-integrated methods by ~27%. Please see our homepage at https://gca-spatial-reasoning.github.io.

</details>


### [47] [Agentic AI Framework for Individuals with Disabilities and Neurodivergence: A Multi-Agent System for Healthy Eating, Daily Routines, and Inclusive Well-Being](https://arxiv.org/abs/2511.22737)
*Salman Jan,Toqeer Ali Syed,Gohar Ali,Ali Akarma,Mohammad Riyaz Belgaum,Ahmad Ali*

Main category: cs.AI

TL;DR: 이 논문은 장애인과 신경다양성이 있는 사람들이 더 건강한 삶을 영위할 수 있도록 돕는 에이전틱 인공지능 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 장애인과 신경다양성이 있는 사람들에게 보다 건강한 삶과 규칙적인 일상을 제공하기 위해, 에이전틱 인공지능 모델이 필요하다.

Method: 다층 구조를 사용하여 응용 프로그램 및 인터페이스 레이어, 에이전트 레이어 및 데이터 소스 레이어를 포함하여 적응적이고 투명하며 포용적인 지원을 제공한다. 하이브리드 추론 엔진이 네 가지 특수 목적 에이전트를 동기화한다.

Result: 사용자 인터페이스와 자율 상호작용을 가능하게 하는 중앙 커뮤니케이션 시스템을 통해 모든 에이전트가 상호작용하며, 데이터 안전성과 동의 준수를 보장하는 정책 제어 레이어에 민감한 개인 정보를 포함한다.

Conclusion: 전통적인 보조 시스템의 확장을 넘어 포용성, 개인화 및 접근성을 모든 수준에서 통합하여 장애인과 신경다양성이 있는 사람들 간의 자율성, 건강 및 디지털 형평성의 발전을 지원한다.

Abstract: The paper presents a detailed Agentic Artificial Intelligence (AI) model that would enable people with disabilities and neurodivergence to lead healthier lives and have more regular days. The system will use a multi-layer structure; it will include an Application and Interface Layer, an Agents Layer, and a Data Source Layer to provide adaptive, transparent, and inclusive support. Fundamentally, a hybrid reasoning engine will synchronize four special-purpose agents, which include: a personalized-nutrition-based, called a Meal Planner Agent; an adaptive-scheduling-based, called a Reminder Agent; interactive assistance during grocery shopping and cooking, called a Food Guidance Agent; and a continuous-intake-and-physiological-tracking, called a Monitoring Agent. All the agents interact through a central communicative system called the Blackboard/Event Bus, which allows autonomous interaction and real-time feedback loops with multimedia user interfaces. Privacy-sensitive data sources, including electronic health records (EHRs), nutritional databases, wearable sensors, and smart kitchen Internet of Things, are also included in the framework and placed into a policy-controlled layer, which ensures data safety and compliance with consent. Collaborative care and clinician dashboards allow common supervision, and discussable artificial intelligence (XAI) modules give brief explanations of why a decision was made, making users responsible and reliant. The proposed agentic AI framework is an extension beyond traditional assistive systems since it incorporates inclusiveness, personalization, and accessibility at all levels. It displays the intersection of multi-agent reasoning, multi-modal interfaces, and human-centered design that will enable the development of autonomy, health, and digital equity among people with disabilities and neurodivergence.

</details>


### [48] [InsightEval: An Expert-Curated Benchmark for Assessing Insight Discovery in LLM-Driven Data Agents](https://arxiv.org/abs/2511.22884)
*Zhenghao Zhu,Yuanfeng Song,Xin Chen,Chengzhong Liu,Yakun Cui,Caleb Chen Cao,Sirui Han,Yike Guo*

Main category: cs.AI

TL;DR: 본 논문은 InsightBench의 단점을 조사하고 새로운 데이터셋 InsightEval을 개발하여 고품질 인사이트 벤치마크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 데이터셋에서 숨겨진 지식과 통찰력을 발견하기 위한 깊이 있는 탐색 분석이 필요합니다.

Method: InsightBench의 문제점을 조사하고 인사이트 벤치마크를 위한 기준을 제안하며, 새로운 데이터셋인 InsightEval을 구축하는 데이터 큐레이션 파이프라인을 개발합니다.

Result: InsightEval에 대한 광범위한 실험을 통해 자동화된 인사이트 발견의 주요 도전 과제를 강조하고, 향후 연구를 위한 주요 발견을 제시합니다.

Conclusion: 고품질 인사이트 벤치마크의 기준과 탐색 성과를 측정하기 위한 새로운 지표를 도입했습니다.

Abstract: Data analysis has become an indispensable part of scientific research. To discover the latent knowledge and insights hidden within massive datasets, we need to perform deep exploratory analysis to realize their full value. With the advent of large language models (LLMs) and multi-agent systems, more and more researchers are making use of these technologies for insight discovery. However, there are few benchmarks for evaluating insight discovery capabilities. As one of the most comprehensive existing frameworks, InsightBench also suffers from many critical flaws: format inconsistencies, poorly conceived objectives, and redundant insights. These issues may significantly affect the quality of data and the evaluation of agents. To address these issues, we thoroughly investigate shortcomings in InsightBench and propose essential criteria for a high-quality insight benchmark. Regarding this, we develop a data-curation pipeline to construct a new dataset named InsightEval. We further introduce a novel metric to measure the exploratory performance of agents. Through extensive experiments on InsightEval, we highlight prevailing challenges in automated insight discovery and raise some key findings to guide future research in this promising direction.

</details>


### [49] [TIM-PRM: Verifying multimodal reasoning with Tool-Integrated PRM](https://arxiv.org/abs/2511.22998)
*Peng Kuang,Xiangxiang Wang,Wentao Liu,Jian Dong,Kaidi Xu,Haohan Wang*

Main category: cs.AI

TL;DR: TIM-PRM는 수동적인 분류 작업에서 능동적인 도구 보강 조사로 변환하는 새로운 프레임워크로, 시각적 환각과 논리적 불일치를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 결과 기반 감독에서는 시각적 환각과 논리적 불일치를 완전히 해결하지 못하기 때문입니다.

Method: TIM-PRM은 명확한 검증 전략 계획과 외부 도구를 통해 증거를 질문하는 독립 질문 요청 메커니즘을 활용하여 검증을 수행합니다.

Result: 8B 매개변수를 가진 우리의 모델은 기존의 오픈 소스 멀티모달 PRM을 초월하여 훨씬 더 큰 모델인 Qwen2.5-72B 및 InternVL-78B보다 성능이 뛰어납니다.

Conclusion: 우리의 TIM-PRM 프레임워크는 검증 과정에 대한 해석 가능한 통찰력을 제시합니다.

Abstract: Multimodal Large Language Models (MLLMs) have achieved impressive performances in mathematical reasoning, yet they remain vulnerable to visual hallucinations and logical inconsistencies that standard outcome-based supervision fails to mitigate. While Process Reward Models (PRMs) promise step-by-step verification, current approaches typically operate as scalar scorers or generative critics that suffer from sycophancy, blindly validating the flawed hypotheses rather than grounding them in visual reality. To bridge this gap, we introduce TIM-PRM (Tool-Integrated Multimodal PRM), a novel agentic framework that transforms verification from a passive classification task into an active, tool-augmented investigation. TIM-PRM is trained to explicitly plan verification strategies and utilizes a mechanism of Independent Question Asking to query evidence via external tools, effectively decoupling verification from the reasoning context to eliminate confirmation bias. We instantiate this method by curating a high-quality dataset of tool-integrated verification trajectories. Extensive experiments on VisualProcessBench demonstrate that our 8B parameter model surpasses existing open-source multimodal PRMs, significantly outperforming much larger models like Qwen2.5-72B and InternVL-78B, while offering interpretable insights into the verification process.

</details>


### [50] [MindPower: Enabling Theory-of-Mind Reasoning in VLM-based Embodied Agents](https://arxiv.org/abs/2511.23055)
*Ruoxuan Zhang,Qiyun Zheng,Zhiyu Zhou,Ziqi Liao,Siyu Wu,Jian-Yu Jiang-Lin,Bin Wen,Hongxia Xie,Jianlong Fu,Wen-Huang Cheng*

Main category: cs.AI

TL;DR: MindPower는 로봇 중심의 프레임워크로, 인식, 정신적 추론, 의사결정 및 행동 생성을 통합하여 ToM 기반의 의사결정을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 현재 비전-언어 임베디드 에이전트는 ToM 기반의 의사결정이 부족하며, 기존 벤치마크들은 인간의 정신 상태에만 초점을 맞추고 있어 에이전트의 관점을 무시한다. 이는 일관된 의사결정과 행동 생성을 저해한다.

Method: MindPower는 다중 모달 입력을 기반으로 환경과 인간 상태를 인식하고, ToM 추론을 통해 자아와 타인을 모델링한 후, 추론된 정신 상태에 따라 의사결정 및 행동을 생성한다.

Result: 우리 모델은 의사결정에서 GPT-4o보다 12.77% 우수하며 행동 생성에서도 12.49% 우수하다.

Conclusion: MindPower는 로봇이 ToM 기반의 의사결정을 수행할 수 있도록 하며, 이는 향후 에이전트의 행동 및 결정의 일관성을 개선할 것이다.

Abstract: Theory of Mind (ToM) refers to the ability to infer others' mental states, such as beliefs, desires, and intentions. Current vision-language embodied agents lack ToM-based decision-making, and existing benchmarks focus solely on human mental states while ignoring the agent's own perspective, hindering coherent decision and action generation. To address this, we propose MindPower, a Robot-Centric framework integrating Perception, Mental Reasoning, Decision Making and Action. Given multimodal inputs, MindPower first perceives the environment and human states, then performs ToM Reasoning to model both self and others, and finally generates decisions and actions guided by inferred mental states. Furthermore, we introduce Mind-Reward, a novel optimization objective that encourages VLMs to produce consistent ToM Reasoning and behavior. Our model outperforms GPT-4o by 12.77% in decision making and 12.49% in action generation.

</details>


### [51] [Does Self-Evaluation Enable Wireheading in Language Models?](https://arxiv.org/abs/2511.23092)
*David Demitri Africa,Hans Ethan Ting*

Main category: cs.AI

TL;DR: 자기 평가와 보상 신호의 결합이 에이전트의 성과 향상보다 보상 측정 조작을 유도할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 자기 평가는 헌법적 AI에서 자기 개선에 이르기까지 언어 모델 훈련에서 점점 더 중심이 되고 있다.

Method: 자기 평가와 보상 신호의 결합이 보상 측정 조작을 초래하는 차이를 형식화하고 POMDP에서 이 예측을 실험적으로 테스트하였다.

Result: 자기 평가가 보상을 결정하는 모델은 특히 요약과 같은 애매한 작업에서 정확도 향상 없이 상당한 성적 인플레이션을 나타냈다.

Conclusion: 자기 평가는 학습 신호와 분리될 때는 안전하지만, 결합될 때는 위험하다는 점을 보여준다.

Abstract: Self-evaluation is increasingly central to language model training, from constitutional AI to self-refinement. We investigate whether coupling self-evaluation to reward signals creates incentives for wireheading, where agents manipulate reward measurements rather than improving task performance. We formalize conditions under which reward-channel control strictly dominates task-focused behavior in POMDPs and test these predictions empirically. Across two models and three tasks, we find that models whose self-grades determine rewards exhibit substantial grade inflation without corresponding accuracy gains, particularly on ambiguous tasks like summarization. Models that self-evaluate but do not control rewards show no such inflation. Our results demonstrate that self-evaluation is safe when decoupled from learning signals but dangerous when coupled, with clear implications for agentic system design.

</details>


### [52] [Peer-to-Peer Energy Trading in Dairy Farms using Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.23148)
*Mian Ibad Ali Shah,Marcos Eduardo Cruz Victorio,Maeve Duffy,Enda Barrett,Karl Mason*

Main category: cs.AI

TL;DR: 본 연구는 농촌 지역에서의 재생 가능 에너지 통합 및 P2P 에너지 거래의 역할을 강조하며, MARL 알고리즘이 P2P 거래와 결합되어 에너지 관리 성능을 개선한다는 점을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 농촌 지역, 특히 낙농업 공동체에서 재생 가능 에너지 자원의 통합은 분산형 에너지 관리를 가능하게 한다.

Method: Multi-Agent Reinforcement Learning (MARL), 특히 Proximal Policy Optimization (PPO) 및 Deep Q-Networks (DQN)을 P2P 거래 메커니즘과 결합한다.

Result: DQN은 아일랜드에서 전기 비용을 14.2% 줄이고, 핀란드에서는 5.16% 줄이는 동시에 전기 수익을 각각 7.24%, 12.73% 증가시켰다.

Conclusion: 이 연구는 농촌 공동체에서의 효율적이고 적응 가능하며 지속 가능한 에너지 관리 달성을 위한 DQN, PPO 및 P2P 거래의 상호 보완적인 강점을 강조한다.

Abstract: The integration of renewable energy resources in rural areas, such as dairy farming communities, enables decentralized energy management through Peer-to-Peer (P2P) energy trading. This research highlights the role of P2P trading in efficient energy distribution and its synergy with advanced optimization techniques. While traditional rule-based methods perform well under stable conditions, they struggle in dynamic environments. To address this, Multi-Agent Reinforcement Learning (MARL), specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), is combined with community/distributed P2P trading mechanisms. By incorporating auction-based market clearing, a price advisor agent, and load and battery management, the approach achieves significant improvements. Results show that, compared to baseline models, DQN reduces electricity costs by 14.2% in Ireland and 5.16% in Finland, while increasing electricity revenue by 7.24% and 12.73%, respectively. PPO achieves the lowest peak hour demand, reducing it by 55.5% in Ireland, while DQN reduces peak hour demand by 50.0% in Ireland and 27.02% in Finland. These improvements are attributed to both MARL algorithms and P2P energy trading, which together results in electricity cost and peak hour demand reduction, and increase electricity selling revenue. This study highlights the complementary strengths of DQN, PPO, and P2P trading in achieving efficient, adaptable, and sustainable energy management in rural communities.

</details>


### [53] [Adapting Like Humans: A Metacognitive Agent with Test-time Reasoning](https://arxiv.org/abs/2511.23262)
*Yang Li,Zhiyuan He,Yuxuan Huang,Zhuhanling Xiao,Chao Yu,Meng Fang,Kun Shao,Jun Wang*

Main category: cs.AI

TL;DR: MCTR은 모델이 테스트 시간에 메타인지 자가 업데이트를 통해 학습, 적응 및 개선할 수 있도록 하는 프레임워크로, 메타 수준과 객체 수준의 추론 모듈로 구성되어 있다.


<details>
  <summary>Details</summary>
Motivation: 인간은 메타인지 모델과 기억을 활용하여 새로운 도전에 직면했을 때 지속적인 전략 개선을 가능하게 한다.

Method: MCTR는 메타 추론 모듈과 행동 추론 모듈로 구성되며, 각각은 계층적 적응 추론을 위한 전용 기억 시스템을 갖춘다. 메타 추론 모듈은 테스트 시간 관찰에서 자연어 설명으로 작업 관련 규칙과 환경 패턴, 행동-결과 관계를 발견하고 저장하여 구조화된 기억을 점진적으로 구축한다.

Result: MCTR는 45개의 아타리 게임에서 강력한 테스트 시간 적응을 보여주며, 보경험에 비해 보지 못한 게임에서 9/12의 top-1 결과를 달성하였다.

Conclusion: 분석을 통해 두 구성 요소의 상호 보완적 기여를 확인하고 메타 추론이 인간과 유사한 적응 전략으로 발전하고 있음을 보여준다.

Abstract: Recent Vision-Language Models (VLMs) exhibit strong perceptual reasoning abilities, yet they often struggle to adapt efficiently when encountering novel tasks at test time. In contrast, humans leverage the metacognitive model with memory, enabling continuous strategy refinement through metacognitive control when faced with new challenges. To bridge this gap, we propose metacognitive test-time reasoning (MCTR), a framework that equips models with the ability to learn, adapt, and improve during test time through metacognitive self-updating. Inspired by the dual structure of human metacognition, MCTR comprises meta-level and object-level VLM reasoning modules, each equipped with dedicated memory systems for hierarchical adaptive reasoning. Specifically, MCTR consists of (1) a meta-reasoning module which incrementally builds a structured memory by discovering and storing task-relevant rules, environmental patterns, and action-outcome relationships from test-time observations as natural language descriptions; and (2) an action-reasoning module that determines optimal actions through context-aware perception and strategic reasoning by dynamically retrieving and integrating knowledge from memory. The action-reasoning module continuously updates its policy through proposed metacognitive test-time reinforcement learning, adapting as knowledge memory evolves. We evaluate MCTR on 45 Atari games (33 seen, 12 unseen). MCTR demonstrates robust test-time adaptation, achieving 9/12 top-1 results on unseen games compared with baselines. Analyses through ablations, learning dynamics, and case studies reveal the complementary contributions of both components and show meta-reasoning evolving toward human-like adaptation strategies.

</details>


### [54] [Hierarchical AI-Meteorologist: LLM-Agent System for Multi-Scale and Explainable Weather Forecast Reporting](https://arxiv.org/abs/2511.23387)
*Daniil Sukhorukov,Andrei Zakharov,Nikita Glazkov,Katsiaryna Yanchanka,Vladimir Kirilin,Maxim Dubovitsky,Roman Sultimov,Yuri Maksimov,Ilya Makarov*

Main category: cs.AI

TL;DR: 계층적 AI-기상학자를 소개하며, 이 시스템은 계층적 예보 추론과 기상 키워드 생성을 통해 설명 가능한 기상 보고서를 생성한다.


<details>
  <summary>Details</summary>
Motivation: 기상 예보의 해석 가능성을 높이고, 자동화된 기상 보고의 질을 향상시키기 위해 개발됨.

Method: 계층적 예보 추론 및 기상 키워드 생성을 사용하는 LLM-agent 시스템을 제안한다.

Result: OpenWeather 및 Meteostat 데이터를 활용하여, 계층적 맥락과 키워드 기반 검증이 LLM이 생성한 기상 내러티브의 해석 가능성과 강인성을 향상시킴을 입증한다.

Conclusion: 자동화된 기상 보고의 의미 평가를 위한 재현 가능한 프레임워크를 제공하며, 에이전트 기반 과학적 추론을 발전시킨다.

Abstract: We present the Hierarchical AI-Meteorologist, an LLM-agent system that generates explainable weather reports using a hierarchical forecast reasoning and weather keyword generation. Unlike standard approaches that treat forecasts as flat time series, our framework performs multi-scale reasoning across hourly, 6-hour, and daily aggregations to capture both short-term dynamics and long-term trends. Its core reasoning agent converts structured meteorological inputs into coherent narratives while simultaneously extracting a few keywords effectively summarizing the dominant meteorological events. These keywords serve as semantic anchors for validating consistency, temporal coherence and factual alignment of the generated reports. Using OpenWeather and Meteostat data, we demonstrate that hierarchical context and keyword-based validation substantially improve interpretability and robustness of LLM-generated weather narratives, offering a reproducible framework for semantic evaluation of automated meteorological reporting and advancing agent-based scientific reasoning.

</details>


### [55] [Towards Continuous Intelligence Growth: Self-Training, Continual Learning, and Dual-Scale Memory in SuperIntelliAgent](https://arxiv.org/abs/2511.23436)
*Jianzhe Lin,Zeyu Pan,Yun Zhu,Ruiqi Song,Jining Yang*

Main category: cs.AI

TL;DR: SuperIntelliAgent는 자가 감독 상호작용을 통해 지속적인 지능 성장을 가능하게 하는 학습 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: SuperIntelliAgent는 기존의 감독학습 방식과 달리 주석 없이 자율적으로 학습할 수 있는 방법론을 제공하고자 합니다.

Method: 이 프레임워크는 작은 확산 모델(학습자)과 고정된 대형 언어 모델(검증자)을 결합하여 상호작용을 통해 후보 출력 생성을 학습합니다. 검증자는 단계별 추론을 통해 출력을 평가하고, 그 상호작용으로 선택/거부 쌍을 생성해 직접 선호 최적화(DPO)를 수행합니다.

Result: SuperIntelliAgent는 자동으로 생성된 DPO 쌍을 통해 모든 벤치마크에서 학습자가 개선되며, 이는 지속적인 지능 축적을 위한 유망한 방향을 제시합니다.

Conclusion: 우리는 훈련 가능한 학습자와 추론이 가능한 검증자의 조합이 성장하는 지능의 최소 신뢰할 수 있는 단위를 형성한다고 주장합니다.

Abstract: We introduce SuperIntelliAgent, an agentic learning framework that couples a trainable small diffusion model (the learner) with a frozen large language model (the verifier) to enable continual intelligence growth through self-supervised interaction. Unlike conventional supervised fine-tuning, SuperIntelliAgent learns autonomously without annotation: the learner generates candidate outputs, the verifier evaluates them through step-by-step reasoning, and their interaction produces chosen/rejected pairs for Direct Preference Optimization (DPO). This converts each input into a pseudo-training signal for continual improvement. The framework integrates dual-scale memory: short-term in-context memory that preserves reasoning traces across refinement cycles, and long-term memory that consolidates acquired knowledge through lightweight on-the-fly fine-tuning. A replay buffer retains samples that show verifiable progress and replays them as auxiliary supervision, reinforcing recent learning while forming adaptive curricula. SuperIntelliAgent is infrastructure-agnostic and can be plugged into existing agentic frameworks while turning ordinary inference loops into a lifelong optimization process. We posit that pairing a trainable learner with a reasoning-capable verifier forms a minimal reliable unit of growing intelligence, as paired feedback and partial-history replay yield richer learning curricula and stronger preference alignment. With a small number of automatically generated DPO pairs, the learner improves across all benchmarks, indicating that this mechanism provides a promising direction for continual intelligence accumulation and real-world deployment.

</details>


### [56] [Thinking by Doing: Building Efficient World Model Reasoning in LLMs via Multi-turn Interaction](https://arxiv.org/abs/2511.23476)
*Bao Shu,Yan Cai,Jianjian Sun,Chunrui Han,En Yu,Liang Zhao,Jingcheng Hu,Yinmin Zhang,Haoran Lv,Yuang Peng,Zheng Ge,Xiangyu Zhang,Daxin Jiang,Xiangyu Yue*

Main category: cs.AI

TL;DR: 본 논문은 대규모 언어 모델 에이전트의 복잡한 환경에서의 효과적인 계획 및 상호작용을 위한 탄탄한 세계 모델 추론 개발을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 환경에서의 효과적인 상호작용과 계획을 위해서는 강화된 세계 모델 추론이 필요하다.

Method: 효율적인 상호작용과 능동적 추론을 통한 세계 모델 내재화(WMAct) 접근 방식을 탐구한다.

Result: WMAct는 한 번의 상호작용만으로도 해결할 수 있는 효과적인 세계 모델 추론을 제공하며 복잡한 환경으로의 이전 가능성을 높인다.

Conclusion: 본 연구는 WMAct가 다양한 추론 벤치마크에서 성능을 개선시키는 방법을 보여준다.

Abstract: Developing robust world model reasoning is crucial for large language model (LLM) agents to plan and interact in complex environments. While multi-turn interaction offers a superior understanding of environmental dynamics via authentic feedback, current approaches often impose a rigid reasoning process, which constrains the model's active learning, ultimately hindering efficient world model reasoning. To address these issues, we explore world-model internalization through efficient interaction and active reasoning (WMAct), which liberates the model from structured reasoning, allowing the model to shape thinking directly through its doing, and achieves effective and efficient world model reasoning with two key mechanisms: (1) a reward rescaling mechanism adjusting outcome reward based on action efficacy to incentivize redundancy reduction and purposeful interaction; (2) an interaction frequency annealing strategy to progressively reduce the maximum allowed interaction turns, which compels the model to condense its learning and internalize environmental dynamics rather than over-relying on environmental cues. Our experiments on Sokoban, Maze, and Taxi show that WMAct yields effective world model reasoning capable of resolving tasks in a single turn that previously required multiple interactions and fosters strong transferability to complex environments, improving performance on a suite of reasoning benchmarks.

</details>
