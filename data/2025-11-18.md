<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 11]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.MA](#cs.MA) [Total: 4]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Near-optimal Linear Predictive Clustering in Non-separable Spaces via Mixed Integer Programming and Quadratic Pseudo-Boolean Reductions](https://arxiv.org/abs/2511.10809)
*Jiazhou Liang,Hassan Khurram,Scott Sanner*

Main category: cs.LG

TL;DR: 본 연구는 Linear Predictive Clustering(LPC)의 전역 최적화를 개선하기 위한 두 가지 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LPC는 마케팅, 의학, 교육 등 다양한 분야에 응용되며, 특성 변인과 타겟 변인 간의 선형 관계를 기반으로 샘플을 분할합니다.

Method: 제안된 방법은 separability의 주요 이론적 속성을 활용하여 LPC의 전역 최적화를 위한 효율성을 개선하는 두 가지 접근 방식을 도입합니다.

Result: 비교 분석 결과 본 방법들이 기존의 greedy 최적화보다 현저한 회귀 오류 감소와 함께 높은 전역 최적 솔루션을 달성함을 보여줍니다.

Conclusion: 본 연구의 기법은 MIP 형식보다 우수한 확장성을 보이며, 여러 데이터셋에 대해 일관된 성능을 발휘합니다.

Abstract: Linear Predictive Clustering (LPC) partitions samples based on shared linear relationships between feature and target variables, with numerous applications including marketing, medicine, and education. Greedy optimization methods, commonly used for LPC, alternate between clustering and linear regression but lack global optimality. While effective for separable clusters, they struggle in non-separable settings where clusters overlap in feature space. In an alternative constrained optimization paradigm, Bertsimas and Shioda (2007) formulated LPC as a Mixed-Integer Program (MIP), ensuring global optimality regardless of separability but suffering from poor scalability. This work builds on the constrained optimization paradigm to introduce two novel approaches that improve the efficiency of global optimization for LPC. By leveraging key theoretical properties of separability, we derive near-optimal approximations with provable error bounds, significantly reducing the MIP formulation's complexity and improving scalability. Additionally, we can further approximate LPC as a Quadratic Pseudo-Boolean Optimization (QPBO) problem, achieving substantial computational improvements in some settings. Comparative analyses on synthetic and real-world datasets demonstrate that our methods consistently achieve near-optimal solutions with substantially lower regression errors than greedy optimization while exhibiting superior scalability over existing MIP formulations.

</details>


### [2] [Behaviour Policy Optimization: Provably Lower Variance Return Estimates for Off-Policy Reinforcement Learning](https://arxiv.org/abs/2511.10843)
*Alexander W. Goodall,Edwin Hamel-De le Court,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 이 논문은 샘플 효율성과 학습 안정성을 개선하기 위해 오프-정책 평가 결과를 활용한 강화 학습 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 정책 개선을 위한 수익 추정치에 의존하는 많은 강화 학습 알고리즘이 샘플 효율성이 낮고 학습 불안정성에 시달릴 수 있습니다.

Method: 우리는 오프-정책 데이터를 수집하기 위해 잘 설계된 행동 정책을 활용하여 더 낮은 분산의 수익 추정치를 얻는 방법을 제안합니다.

Result: 실험을 통해 두 가지 정책 경량화 방법을 확장했으며, 다양한 환경에서 샘플 효율성과 성능이 향상됨을 보였습니다.

Conclusion: 이 논문은 행동 정책을 단일 작업자로 사용하는 접근 방식을 제안하며, 이는 정책 개선을 위해 수집된 데이터의 분산을 낮출 수 있습니다.

Abstract: Many reinforcement learning algorithms, particularly those that rely on return estimates for policy improvement, can suffer from poor sample efficiency and training instability due to high-variance return estimates. In this paper we leverage new results from off-policy evaluation; it has recently been shown that well-designed behaviour policies can be used to collect off-policy data for provably lower variance return estimates. This result is surprising as it means collecting data on-policy is not variance optimal. We extend this key insight to the online reinforcement learning setting, where both policy evaluation and improvement are interleaved to learn optimal policies. Off-policy RL has been well studied (e.g., IMPALA), with correct and truncated importance weighted samples for de-biasing and managing variance appropriately. Generally these approaches are concerned with reconciling data collected from multiple workers in parallel, while the policy is updated asynchronously, mismatch between the workers and policy is corrected in a mathematically sound way. Here we consider only one worker - the behaviour policy, which is used to collect data for policy improvement, with provably lower variance return estimates. In our experiments we extend two policy-gradient methods with this regime, demonstrating better sample efficiency and performance over a diverse set of environments.

</details>


### [3] [Incorporating Spatial Information into Goal-Conditioned Hierarchical Reinforcement Learning via Graph Representations](https://arxiv.org/abs/2511.10872)
*Shuyuan Zhang,Zihan Wang,Xiao-Wen Chang,Doina Precup*

Main category: cs.LG

TL;DR: 이 논문에서는 그래프와 목표 조건 계층 강화 학습(GCHRL)의 통합을 통해 중간 목표를 효과적으로 샘플링할 수 있는 방법을 제안하며, 이를 통해 기존의 GCHRL 방법의 한계를 극복하고 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 그래프와 GCHRL의 통합은 RL 작업에서 전체 작업 구조를 자연스럽게 나타내는 그래프에서 중간 목표를 효과적으로 샘플링할 수 있기 때문에 최근 주목받고 있습니다. 그러나 기존 접근 방식은 새로운 작업에 대한 적용 가능성을 제한하는 도메인 특정 지식에 의존합니다.

Method: 이 논문은 보지 못한 상태를 평가하기 위해 그래프 인코더-디코더를 개발하여 문제를 해결하는 방법인 Graph-Guided sub-Goal representation Generation RL (G4RL)을 제안합니다.

Result: 실험 결과, 그래프 인코더-디코더를 활용하여 GCHRL 접근 방식의 성능을 유의미하게 향상시킬 수 있으며, 높은 수준 및 낮은 수준의 내재적 보상을 이용하는 것이 성과를 크게 개선하는 데 기여합니다.

Conclusion: 제안된 G4RL 방법은 대칭적이고 가역적인 전환이 주를 이루는 환경에서 기존의 GCHRL 방법에 통합되어 이 문제 클래스 전반에서 성능을 향상시킬 수 있습니다.

Abstract: The integration of graphs with Goal-conditioned Hierarchical Reinforcement Learning (GCHRL) has recently gained attention, as intermediate goals (subgoals) can be effectively sampled from graphs that naturally represent the overall task structure in most RL tasks. However, existing approaches typically rely on domain-specific knowledge to construct these graphs, limiting their applicability to new tasks. Other graph-based approaches create graphs dynamically during exploration but struggle to fully utilize them, because they have problems passing the information in the graphs to newly visited states. Additionally, current GCHRL methods face challenges such as sample inefficiency and poor subgoal representation. This paper proposes a solution to these issues by developing a graph encoder-decoder to evaluate unseen states. Our proposed method, Graph-Guided sub-Goal representation Generation RL (G4RL), can be incorporated into any existing GCHRL method when operating in environments with primarily symmetric and reversible transitions to enhance performance across this class of problems. We show that the graph encoder-decoder can be effectively implemented using a network trained on the state graph generated during exploration. Empirical results indicate that leveraging high and low-level intrinsic rewards from the graph encoder-decoder significantly enhances the performance of state-of-the-art GCHRL approaches with an extra small computational cost in dense and sparse reward environments.

</details>


### [4] [Scalable Population Training for Zero-Shot Coordination](https://arxiv.org/abs/2511.11083)
*Bingyu Hui,Lebin Yu,Quanming Yao,Yunpeng Qu,Xudong Zhang,Jian Wang*

Main category: cs.LG

TL;DR: 제로샷 협동(ZSC)은 최근 강화학습 연구에서 주목받는 주제로, 이전에 보지 못한 협력자와의 조정을 위해 에이전트의 일반화 능력에 초점을 맞추고 있다.


<details>
  <summary>Details</summary>
Motivation: 기존의 방법들이 소규모 집단의 다양성 최적화에 중점을 두고 있어 인구 규모 확대로 인한 성능 향상을 간과하고 있기 때문에, 이를 해결하기 위해 Scalable Population Training (ScaPT)을 제안한다.

Method: 이 논문은 메타 에이전트가 에이전트 간에 매개변수를 선택적으로 공유하여 효율적으로 인구를 실현하고, 인구의 다양성을 보장하는 상호 정보 정규화기를 포함하는 두 가지 주요 구성 요소를 갖춘 효율적인 교육 프레임워크인 ScaPT를 제안한다.

Result: ScaPT의 효과를 실증적으로 검증하기 위해, Hanabi에서 대표적인 프레임워크들과 함께 평가하고 그 우수성을 확인하였다.

Conclusion: 결론적으로, ScaPT는 기존 방법보다 더 나은 성능을 보여주며, 제로샷 협동 성능 향상에 기여할 수 있음을 입증한다.

Abstract: Zero-shot coordination(ZSC) has become a hot topic in reinforcement learning research recently. It focuses on the generalization ability of agents, requiring them to coordinate well with collaborators that are not seen before without any fine-tuning. Population-based training has been proven to provide good zero-shot coordination performance; nevertheless, existing methods are limited by computational resources, mainly focusing on optimizing diversity in small populations while neglecting the potential performance gains from scaling population size. To address this issue, this paper proposes the Scalable Population Training (ScaPT), an efficient training framework comprising two key components: a meta-agent that efficiently realizes a population by selectively sharing parameters across agents, and a mutual information regularizer that guarantees population diversity. To empirically validate the effectiveness of ScaPT, this paper evaluates it along with representational frameworks in Hanabi and confirms its superiority.

</details>


### [5] [On-line learning of dynamic systems: sparse regression meets Kalman filtering](https://arxiv.org/abs/2511.11178)
*Gianluigi Pillonetto,Akram Yazdani,Aleksandr Aravkin*

Main category: cs.LG

TL;DR: 이 논문은 Sindy Kalman Filter (SKF)를 제안하여 비선형 동적 시스템의 실시간 학습을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 물리 시스템의 행동을 이해하기 위해 데이터에서 지배 방정식을 학습하는 것이 중요합니다.

Method: Kalman 필터를 통합하여 실시간 학습을 위한 희소 기반 접근 방식을 확장합니다.

Result: Sindy Kalman Filter (SKF)는 비선형 모델을 실시간으로 추론하는 데 효과적입니다.

Conclusion: SKF는 실제 비행 데이터를 이용한 희소 비선형 항공기 모델의 실시간 식별에서도 효과적입니다.

Abstract: Learning governing equations from data is central to understanding the behavior of physical systems across diverse scientific disciplines, including physics, biology, and engineering. The Sindy algorithm has proven effective in leveraging sparsity to identify concise models of nonlinear dynamical systems. In this paper, we extend sparsity-driven approaches to real-time learning by integrating a cornerstone algorithm from control theory -- the Kalman filter (KF). The resulting Sindy Kalman Filter (SKF) unifies both frameworks by treating unknown system parameters as state variables, enabling real-time inference of complex, time-varying nonlinear models unattainable by either method alone. Furthermore, SKF enhances KF parameter identification strategies, particularly via look-ahead error, significantly simplifying the estimation of sparsity levels, variance parameters, and switching instants. We validate SKF on a chaotic Lorenz system with drifting or switching parameters and demonstrate its effectiveness in the real-time identification of a sparse nonlinear aircraft model built from real flight data.

</details>


### [6] [Dynamic Deep Graph Learning for Incomplete Multi-View Clustering with Masked Graph Reconstruction Loss](https://arxiv.org/abs/2511.11181)
*Zhenghao Zhang,Jun Xie,Xingchen Chen,Tao Yu,Hongzhu Yi,Kaixin Xu,Yuanxiang Wang,Tianyu Zong,Xinming Wang,Jiahuan Chen,Guoqing Chao,Feng Chen,Zhepeng Wang,Jungang Xu*

Main category: cs.LG

TL;DR: 이 논문은 불완전한 다중 뷰 클러스터링을 위한 새로운 접근법인 DGIMVCM을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 다중 뷰 데이터의 유병률로 불완전한 다중 뷰 클러스터링(IMVC)은 중요한 연구 주제가 되었다.

Method: 이 논문에서는 결측값을 보완하기 위해 원본 데이터에서 강건한 글로벌 그래프를 구성하고, 그래프 컨볼루션 임베딩 레이어를 설계하여 주요 특징과 동적 뷰별 그래프 구조를 추출한다. 또한, 그래프 자기 주의 인코더를 도입하여 고수준 표현을 추출한다.

Result: DGIMVCM의 효과성과 우수성은 여러 데이터셋에 대한 광범위한 실험을 통해 검증되었다.

Conclusion: DGIMVCM은 기존 접근 방법보다 더 높은 성능을 보였다.

Abstract: The prevalence of real-world multi-view data makes incomplete multi-view clustering (IMVC) a crucial research. The rapid development of Graph Neural Networks (GNNs) has established them as one of the mainstream approaches for multi-view clustering. Despite significant progress in GNNs-based IMVC, some challenges remain: (1) Most methods rely on the K-Nearest Neighbors (KNN) algorithm to construct static graphs from raw data, which introduces noise and diminishes the robustness of the graph topology. (2) Existing methods typically utilize the Mean Squared Error (MSE) loss between the reconstructed graph and the sparse adjacency graph directly as the graph reconstruction loss, leading to substantial gradient noise during optimization. To address these issues, we propose a novel \textbf{D}ynamic Deep \textbf{G}raph Learning for \textbf{I}ncomplete \textbf{M}ulti-\textbf{V}iew \textbf{C}lustering with \textbf{M}asked Graph Reconstruction Loss (DGIMVCM). Firstly, we construct a missing-robust global graph from the raw data. A graph convolutional embedding layer is then designed to extract primary features and refined dynamic view-specific graph structures, leveraging the global graph for imputation of missing views. This process is complemented by graph structure contrastive learning, which identifies consistency among view-specific graph structures. Secondly, a graph self-attention encoder is introduced to extract high-level representations based on the imputed primary features and view-specific graphs, and is optimized with a masked graph reconstruction loss to mitigate gradient noise during optimization. Finally, a clustering module is constructed and optimized through a pseudo-label self-supervised training mechanism. Extensive experiments on multiple datasets validate the effectiveness and superiority of DGIMVCM.

</details>


### [7] [On-Device Fine-Tuning via Backprop-Free Zeroth-Order Optimization](https://arxiv.org/abs/2511.11362)
*Prabodh Katti,Sangwoo Park,Bipin Rajendran,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 본 논문은 메모리 제약이 있는 엣지 AI 시스템에서의 온디바이스 파인튜닝의 중요성과 효율적인 기법인 MeZO를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 엣지 AI 시스템은 메모리 제약 하에서도 다양한 작업에 적응할 수 있어야 합니다.

Method: 메모리 효율적인 제로 차원 최적화(MeZO)는 중간 활성화나 옵티마이저 상태를 저장할 필요 없이 오직 전방 평가만을 사용하여 그래디언트를 추정합니다.

Result: MeZO는 온디바이스 메모리 제약 하에서 정확도 이점을 보여주며, 충분한 시간이 주어질 경우 더 큰 모델을 수용할 수 있습니다.

Conclusion: 우리의 이론적 추정과 수치적 검증을 통해 MeZO가 BP와 비교할 때 메모리 제약 속에서도 유리하다는 것을 보였습니다.

Abstract: On-device fine-tuning is a critical capability for edge AI systems, which must support adaptation to different agentic tasks under stringent memory constraints. Conventional backpropagation (BP)-based training requires storing layer activations and optimizer states, a demand that can be only partially alleviated through checkpointing. In edge deployments in which the model weights must reside entirely in device memory, this overhead severely limits the maximum model size that can be deployed. Memory-efficient zeroth-order optimization (MeZO) alleviates this bottleneck by estimating gradients using forward evaluations alone, eliminating the need for storing intermediate activations or optimizer states. This enables significantly larger models to fit within on-chip memory, albeit at the cost of potentially longer fine-tuning wall-clock time. This paper first provides a theoretical estimate of the relative model sizes that can be accommodated under BP and MeZO training. We then numerically validate the analysis, demonstrating that MeZO exhibits accuracy advantages under on-device memory constraints, provided sufficient wall-clock time is available for fine-tuning.

</details>


### [8] [Robust inverse material design with physical guarantees using the Voigt-Reuss Net](https://arxiv.org/abs/2511.11388)
*Sanath Keshav,Felix Fritzen*

Main category: cs.LG

TL;DR: 본 논문에서는 경량 물리적 보장을 갖춘 전방 및 역 기계 균질화에 대한 스펙트럴 정규화 대리 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 경량 물리적 보장을 바탕으로 기계 균질화 문제를 해결할 필요성을 느꼈습니다.

Method: Voigt-Reuss 경계를 활용하여 차이를 Cholesky 유사 연산자를 통해 분해하고, 고유값이 $[0,1]$인 무차원 대칭 양의 반정적 표현을 학습합니다.

Result: 3D 선형 탄성에 대해, 훈련된 Voigt-Reuss 네트는 거의 완벽한 충실도로 동률 투영을 회복하고, 텐서 수준에서의 상대 Frobenius 오류가 분할에서 각각 대략 $1.7\\%$와 $3.4\\%$입니다.

Conclusion: Voigt-Reuss 네트는 정확하고 물리적으로 허용 가능한 전방 예측과 대량 배치, 제약 일치 역설계를 통합하며, 타원 연산자 및 결합 물리 환경에 일반적입니다.

Abstract: We propose a spectrally normalized surrogate for forward and inverse mechanical homogenization with hard physical guarantees. Leveraging the Voigt-Reuss bounds, we factor their difference via a Cholesky-like operator and learn a dimensionless, symmetric positive semi-definite representation with eigenvalues in $[0,1]$; the inverse map returns symmetric positive-definite predictions that lie between the bounds in the Löwner sense. In 3D linear elasticity on an open dataset of stochastic biphasic microstructures, a fully connected Voigt-Reuss net trained on $>\!7.5\times 10^{5}$ FFT-based labels with 236 isotropy-invariant descriptors and three contrast parameters recovers the isotropic projection with near-perfect fidelity (isotropy-related entries: $R^2 \ge 0.998$), while anisotropy-revealing couplings are unidentifiable from $SO(3)$-invariant inputs. Tensor-level relative Frobenius errors have median $\approx 1.7\%$ and mean $\approx 3.4\%$ across splits. For 2D plane strain on thresholded trigonometric microstructures, coupling spectral normalization with a differentiable renderer and a CNN yields $R^2>0.99$ on all components, subpercent normalized losses, accurate tracking of percolation-induced eigenvalue jumps, and robust generalization to out-of-distribution images. Treating the parametric microstructure as design variables, batched first-order optimization with a single surrogate matches target tensors within a few percent and returns diverse near-optimal designs. Overall, the Voigt-Reuss net unifies accurate, physically admissible forward prediction with large-batch, constraint-consistent inverse design, and is generic to elliptic operators and coupled-physics settings.

</details>


### [9] [Multi-Phase Spacecraft Trajectory Optimization via Transformer-Based Reinforcement Learning](https://arxiv.org/abs/2511.11402)
*Amit Jain,Victor Rodriguez-Fernandez,Richard Linares*

Main category: cs.LG

TL;DR: 본 연구는 다단계 임무를 통합하는 변환기 기반 강화 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 우주선 제어는 다양한 임무 단계에서 동적 정책의 필요성 때문에 중요한 도전 과제입니다.

Method: PPO를 기반으로 하여, 전통적인 순환 신경망을 변환기 인코더-디코더 구조로 대체하여 여러 임무 단계에서의 기억을 일관되게 유지합니다.

Result: 우리의 접근 방식을 통해 단일 단계 기준선에서 거의 최적의 성능을 보여주고, 다단계 웨이포인트 탐색 문제로 확장하여 복잡한 다단계 로켓 상승 문제를 해결했습니다.

Conclusion: 변환기 기반 프레임워크는 분석 솔루션과 일치하며, 동적으로 구별된 영역에서 일관된 제어 정책을 효과적으로 학습하여 자율 임무 계획의 기반을 마련합니다.

Abstract: Autonomous spacecraft control for mission phases such as launch, ascent, stage separation, and orbit insertion remains a critical challenge due to the need for adaptive policies that generalize across dynamically distinct regimes. While reinforcement learning (RL) has shown promise in individual astrodynamics tasks, existing approaches often require separate policies for distinct mission phases, limiting adaptability and increasing operational complexity. This work introduces a transformer-based RL framework that unifies multi-phase trajectory optimization through a single policy architecture, leveraging the transformer's inherent capacity to model extended temporal contexts. Building on proximal policy optimization (PPO), our framework replaces conventional recurrent networks with a transformer encoder-decoder structure, enabling the agent to maintain coherent memory across mission phases spanning seconds to minutes during critical operations. By integrating a Gated Transformer-XL (GTrXL) architecture, the framework eliminates manual phase transitions while maintaining stability in control decisions. We validate our approach progressively: first demonstrating near-optimal performance on single-phase benchmarks (double integrator and Van der Pol oscillator), then extending to multiphase waypoint navigation variants, and finally tackling a complex multiphase rocket ascent problem that includes atmospheric flight, stage separation, and vacuum operations. Results demonstrate that the transformer-based framework not only matches analytical solutions in simple cases but also effectively learns coherent control policies across dynamically distinct regimes, establishing a foundation for scalable autonomous mission planning that reduces reliance on phase-specific controllers while maintaining compatibility with safety-critical verification protocols.

</details>


### [10] [Generalizing Fair Clustering to Multiple Groups: Algorithms and Applications](https://arxiv.org/abs/2511.11539)
*Diptarka Chakraborty,Kushagra Chatterjee,Debarati Das,Tien-Long Nguyen*

Main category: cs.LG

TL;DR: 클러스터링은 기계 학습의 기초적인 작업이지만, 훈련 데이터의 편향으로 인해 여러 소외된 커뮤니티에 대한 공정한 표현을 제공하는 데 자주 실패합니다. 본 논문은 임의의 그룹 수에 대해 '가장 가까운 공정 클러스터링' 문제를 일반화하고, 효율적인 근사 알고리즘을 제안하여 이러한 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 여러 보호 속성에 의해 정의된 소외된 커뮤니티에 대한 클러스터링 결과의 공정성을 개선할 필요가 있다.

Method: 두 개 이상의 그룹을 가진 설정에서의 '가장 가까운 공정 클러스터링 문제'를 일반화하고, 근사 알고리즘을 제안하여 처리한다.

Result: 제안된 근사 알고리즘을 통해 다양한 그룹에 대한 공정 클러스터링과 공정 합의 클러스터링 문제의 개선된 근사 보장을 달성하였다.

Conclusion: 제안된 알고리즘은 Chakraborty et al. [COLT'25]가 제기한 개방 질문에 대한 답변을 제공하며, 기존의 결과를 발전시킨다.

Abstract: Clustering is a fundamental task in machine learning and data analysis, but it frequently fails to provide fair representation for various marginalized communities defined by multiple protected attributes -- a shortcoming often caused by biases in the training data. As a result, there is a growing need to enhance the fairness of clustering outcomes, ideally by making minimal modifications, possibly as a post-processing step after conventional clustering. Recently, Chakraborty et al. [COLT'25] initiated the study of \emph{closest fair clustering}, though in a restricted scenario where data points belong to only two groups. In practice, however, data points are typically characterized by many groups, reflecting diverse protected attributes such as age, ethnicity, gender, etc.
  In this work, we generalize the study of the \emph{closest fair clustering} problem to settings with an arbitrary number (more than two) of groups. We begin by showing that the problem is NP-hard even when all groups are of equal size -- a stark contrast with the two-group case, for which an exact algorithm exists. Next, we propose near-linear time approximation algorithms that efficiently handle arbitrary-sized multiple groups, thereby answering an open question posed by Chakraborty et al. [COLT'25].
  Leveraging our closest fair clustering algorithms, we further achieve improved approximation guarantees for the \emph{fair correlation clustering} problem, advancing the state-of-the-art results established by Ahmadian et al. [AISTATS'20] and Ahmadi et al. [2020]. Additionally, we are the first to provide approximation algorithms for the \emph{fair consensus clustering} problem involving multiple (more than two) groups, thus addressing another open direction highlighted by Chakraborty et al. [COLT'25].

</details>


### [11] [Multistability of Self-Attention Dynamics in Transformers](https://arxiv.org/abs/2511.11553)
*Claudio Altafini*

Main category: cs.LG

TL;DR: 이 논문은 기계 학습에서 셀프 어텐션 역학이 트랜스포머의 주의 메커니즘과 관련되어 있음을 보여줍니다. 여러 가지 안정적인 평형 상태의 존재를 분류하고, 값 행렬의 고유 벡터와의 관계를 논의합니다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습에서 트랜스포머의 주의 메커니즘을 이해하기 위한 동역학 모델 연구

Method: 셀프 어텐션 역학과 Oja 흐름의 다중 에이전트 버전을 연결하여 균형 상태 분류

Result: 셀프 어텐션 시스템의 균형은 네 가지 클래스로 분류되며, 여러 안정적인 평형이 공존할 수 있음.

Conclusion: 첫 두 클래스의 균형은 값 행렬의 고유 벡터에 항상 정렬되어 있음.

Abstract: In machine learning, a self-attention dynamics is a continuous-time multiagent-like model of the attention mechanisms of transformers. In this paper we show that such dynamics is related to a multiagent version of the Oja flow, a dynamical system that computes the principal eigenvector of a matrix corresponding for transformers to the value matrix. We classify the equilibria of the ``single-head'' self-attention system into four classes: consensus, bipartite consensus, clustering and polygonal equilibria. Multiple asymptotically stable equilibria from the first three classes often coexist in the self-attention dynamics. Interestingly, equilibria from the first two classes are always aligned with the eigenvectors of the value matrix, often but not exclusively with the principal eigenvector.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [On the Information-Theoretic Fragility of Robust Watermarking under Diffusion Editing](https://arxiv.org/abs/2511.10933)
*Yunyi Ni,Ziyu Yang,Ze Niu,Emily Davis,Finn Carter*

Main category: cs.CR

TL;DR: 본 논문은 강력한 확산 기반 이미지 편집 기술이 기존의 강인한 이미지 워터마킹 시스템에 미치는 영향을 분석하고, 워터마크 신호를 제거하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 확산 기반 이미지 생성 및 편집 기술의 부상으로 인해 기존 워터마킹 시스템이 위협받고 있다.

Method: 이미지의 반복적인 확산 변환이 워터마크와 삽입된 정보 간의 상호 정보를 얼마나 감소시키는지를 이론적으로 분석하고, 공격 알고리즘을 제안한다.

Result: 최근 딥러닝 기반의 워터마킹 기법에서 공격 후 워터마크 복구율이 거의 제로에 가까운 결과를 보였다.

Conclusion: 생성 AI 시대에 더 탄력적인 워터마킹 전략을 위한 설계 지침을 제시하고 이들 워터마크 제거 능력의 윤리적 함의를 논의한다.

Abstract: Robust invisible watermarking embeds hidden information in images such that the watermark can survive various manipulations. However, the emergence of powerful diffusion-based image generation and editing techniques poses a new threat to these watermarking schemes. In this paper, we investigate the intersection of diffusion-based image editing and robust image watermarking. We analyze how diffusion-driven image edits can significantly degrade or even fully remove embedded watermarks from state-of-the-art robust watermarking systems. Both theoretical formulations and empirical experiments are provided. We prove that as a image undergoes iterative diffusion transformations, the mutual information between the watermarked image and the embedded payload approaches zero, causing watermark decoding to fail. We further propose a guided diffusion attack algorithm that explicitly targets and erases watermark signals during generation. We evaluate our approach on recent deep learning-based watermarking schemes and demonstrate near-zero watermark recovery rates after attack, while maintaining high visual fidelity of the regenerated images. Finally, we discuss ethical implications of such watermark removal capablities and provide design guidelines for future watermarking strategies to be more resilient in the era of generative AI.

</details>


### [13] [PATCHEVAL: A New Benchmark for Evaluating LLMs on Patching Real-World Vulnerabilities](https://arxiv.org/abs/2511.11019)
*Zichao Wei,Jun Zeng,Ming Wen,Zeliang Yu,Kai Cheng,Yiding Zhu,Jingyi Guo,Shiqi Zhou,Le Yin,Xiaodong Su,Zhechao Ma*

Main category: cs.CR

TL;DR: 소프트웨어 취약점이 증가하는 가운데 기존의 자동화된 취약점 수리 기술의 한계를 극복하기 위해 PATCHEVAL을 도입하여 LLM 기반 취약점 수리의 능력을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 취약점이 급증하고 있으나, 수동 패치는 시간이 오래 걸리고 자원을 소모하며 기존의 자동화된 취약점 수리 기술은 효과성이 제한적이다.

Method: PATCHEVAL은 2015년에서 2025년 사이에 보고된 CVE에서 1,000개의 취약점을 수집하여 다국어 벤치마크를 구성하며, 그 중 일부는 런타임 샌드박스 환경에서 패치 검증을 가능하게 한다.

Result: 최신 LLM 및 에이전트에 대한 평가를 통해 LLM 기반 취약점 수리에 대한 심층 분석을 제공하고, 향후 AVR 연구에 대한 주요 통찰을 도출한다.

Conclusion: PATCHEVAL은 언어 모델의 성능을 비교하고 AVR 분야의 향후 연구 방향을 제시하는 데 기여한다.

Abstract: Software vulnerabilities are increasing at an alarming rate. However, manual patching is both time-consuming and resource-intensive, while existing automated vulnerability repair (AVR) techniques remain limited in effectiveness. Recent advances in large language models (LLMs) have opened a new paradigm for AVR, demonstrating remarkable progress. To examine the capability of LLMs in AVR, several vulnerability benchmarks have been proposed recently. However, they still suffer from key limitations of outdated vulnerabilities, limited language coverage, unreliable patch validation, and insufficient reproducibility. To overcome these challenges, we introduce PATCHEVAL, a multilingual benchmark for Go, JavaScript, and Python, languages for which existing benchmarks remain unexplored. PATCHEVAL curates a dataset of 1,000 vulnerabilities drawn from CVEs reported between 2015 and 2025, covering 65 distinct CWEs. A subset of 230 CVEs is further equipped with runtime sandbox environments, enabling patch verification through both security tests and functionality tests. To provide a systematic comparison of LLM-based vulnerability repair, we evaluate a series of state-of-the-art LLMs and agents, presenting an in-depth analysis that empirically yields key insights to guide future research in AVR.

</details>


### [14] [Data Poisoning Vulnerabilities Across Healthcare AI Architectures: A Security Threat Analysis](https://arxiv.org/abs/2511.11020)
*Farhad Abtahi,Fernando Seoane,Iván Pau,Mario Vega-Barbas*

Main category: cs.CR

TL;DR: 헬스케어 AI 시스템은 데이터 오염에 취약하며, 현재의 방어책과 규제는 이를 충분히 해결하지 못한다.


<details>
  <summary>Details</summary>
Motivation: 헬스케어 AI 시스템의 데이터 오염에 대한 취약성을 분석하고자 했다.

Method: 8가지 공격 시나리오를 4가지 범주로 나누어 분석하였다.

Result: 100-500개의 샘플로도 헬스케어 AI를 손상시킬 수 있으며, 탐지가 지연될 수 있다.

Conclusion: 다층 방어와 분석의 필요성을 주장하며, 해석 가능한 시스템으로의 전환을 제안한다.

Abstract: Healthcare AI systems face major vulnerabilities to data poisoning that current defenses and regulations cannot adequately address. We analyzed eight attack scenarios in four categories: architectural attacks on convolutional neural networks, large language models, and reinforcement learning agents; infrastructure attacks exploiting federated learning and medical documentation systems; critical resource allocation attacks affecting organ transplantation and crisis triage; and supply chain attacks targeting commercial foundation models. Our findings indicate that attackers with access to only 100-500 samples can compromise healthcare AI regardless of dataset size, often achieving over 60 percent success, with detection taking an estimated 6 to 12 months or sometimes not occurring at all. The distributed nature of healthcare infrastructure creates many entry points where insiders with routine access can launch attacks with limited technical skill. Privacy laws such as HIPAA and GDPR can unintentionally shield attackers by restricting the analyses needed for detection. Supply chain weaknesses allow a single compromised vendor to poison models across 50 to 200 institutions. The Medical Scribe Sybil scenario shows how coordinated fake patient visits can poison data through legitimate clinical workflows without requiring a system breach. Current regulations lack mandatory adversarial robustness testing, and federated learning can worsen risks by obscuring attribution. We recommend multilayer defenses including required adversarial testing, ensemble-based detection, privacy-preserving security mechanisms, and international coordination on AI security standards. We also question whether opaque black-box models are suitable for high-stakes clinical decisions, suggesting a shift toward interpretable systems with verifiable safety guarantees.

</details>


### [15] [Bridging Local and Federated Data Normalization in Federated Learning: A Privacy-Preserving Approach](https://arxiv.org/abs/2511.11249)
*Melih Coşğun,Mert Gençtürk,Sinem Sav*

Main category: cs.CR

TL;DR: 연합 학습에서 데이터 정규화는 모델 성능과 안정성을 향상시키는 중요한 전처리 단계이며, 이는 분산된 데이터의 고유한 도전과제를 드러낸다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습(FL)은 여러 당사자 간의 협력적 모델 훈련 중 데이터가 분산된 상태로 남아 있기 때문에, 정규화는 독특한 문제를 초래한다.

Method: 본 논문에서는 널리 사용되는 정규화 기법을 FL에 적응시키고, 연합 정규화라는 용어를 정의한다. 이는 당사자 간 정규화 파라미터의 협력적 교환을 가능하게 하여 풀링 정규화를 시뮬레이션한다.

Result: 연합 정규화는 데이터 로컬리티를 저해하지 않으면서도 풀링 정규화와 동등한 성능을 달성한다. 그러나 평균값과 같은 정규화 파라미터 공유는 개인정보 보호에 대한 잠재적 위험을 초래한다.

Conclusion: 우리는 다양한 연합 및 로컬 정규화 기법의 영향을 체계적으로 평가하고, FL에 적합한 동형암호화된 $k$-번째 순위 요소(및 중앙값) 계산을 제안하며, MHE를 활용한 개인정보 보호 구현을 제안한다.

Abstract: Data normalization is a crucial preprocessing step for enhancing model performance and training stability. In federated learning (FL), where data remains distributed across multiple parties during collaborative model training, normalization presents unique challenges due to the decentralized and often heterogeneous nature of the data. Traditional methods rely on either independent client-side processing, i.e., local normalization, or normalizing the entire dataset before distributing it to parties, i.e., pooled normalization. Local normalization can be problematic when data distributions across parties are non-IID, while the pooled normalization approach conflicts with the decentralized nature of FL. In this paper, we explore the adaptation of widely used normalization techniques to FL and define the term federated normalization. Federated normalization simulates pooled normalization by enabling the collaborative exchange of normalization parameters among parties. Thus, it achieves performance on par with pooled normalization without compromising data locality. However, sharing normalization parameters such as the mean introduces potential privacy risks, which we further mitigate through a robust privacy-preserving solution. Our contributions include: (i) We systematically evaluate the impact of various federated and local normalization techniques in heterogeneous FL scenarios, (ii) We propose a novel homomorphically encrypted $k$-th ranked element (and median) calculation tailored for the federated setting, enabling secure and efficient federated normalization, (iii) We propose privacy-preserving implementations of widely used normalization techniques for FL, leveraging multiparty fully homomorphic encryption (MHE).

</details>


### [16] [HetDAPAC: Leveraging Attribute Heterogeneity in Distributed Attribute-Based Private Access Control](https://arxiv.org/abs/2511.11549)
*Shreya Meel,Sennur Ulukus*

Main category: cs.CR

TL;DR: 이 논문에서는 사용자 속성에 대한 세밀한 접근 제어를 제공하는 방법으로, 이종 속성 기반 개인 접근 제어 (HetDAPAC) 프레임워크를 제안하여 통신 효율성과 개인 정보를 보호하는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 속성 기반 인증에서 데이터베이스에 대한 세밀한 접근 제어를 제공하기 위해 사용자 속성을 검증하는 것은 기본적이다.

Method: 이종 (Het)DAPAC 프레임워크를 통해 N-D의 속성 검증을 중앙 서버로 오프로드하고 D개의 민감한 속성에 대해서는 DAPAC의 구조를 유지한다.

Result: HetDAPAC 계획을 통해 비밀 속성을 몇 개 희생하면서 비율을 1/2K에서 1/(K+1)로 개선하였다.

Conclusion: 두 번째 계획을 제안하여 서버 간 균형 잡힌 다운로드를 달성하면서 비율을 (D+1)/(2KD)로 개선할 수 있다.

Abstract: Verifying user attributes to provide fine-grained access control to databases is fundamental to attribute-based authentication. Either a single (central) authority verifies all the attributes, or multiple independent authorities verify the attributes distributedly. In the central setup, the authority verifies all user attributes, and the user downloads only the authorized record. While this is communication efficient, it reveals all user attributes to the authority. A distributed setup prevents this privacy breach by letting each authority verify and learn only one attribute. Motivated by this, Jafarpisheh~et~al. introduced an information-theoretic formulation, called distributed attribute-based private access control (DAPAC). With $N$ non-colluding authorities (servers), $N$ attributes and $K$ possible values for each attribute, the DAPAC system lets each server learn only the single attribute value that it verifies, and is oblivious to the remaining $N-1$. The user retrieves its designated record, without learning anything about the remaining database records. The goal is to maximize the rate, i.e., the ratio of desired message size to total download size. However, not all attributes are sensitive, and DAPAC's privacy constraints can be too restrictive, negatively affecting the rate. To leverage the heterogeneous privacy requirements of user attributes, we propose heterogeneous (Het)DAPAC, a framework which off-loads verification of $N-D$ of the $N$ attributes to a central server, and retains DAPAC's architecture for the $D$ sensitive attributes. We first present a HetDAPAC scheme, which improves the rate from $\frac{1}{2K}$ to $\frac{1}{K+1}$, while sacrificing the privacy of a few non-sensitive attributes. Unlike DAPAC, our scheme entails a download imbalance across servers; we propose a second scheme achieving a balanced per-server download and a rate of $\frac{D+1}{2KD}$.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [Co-EPG: A Framework for Co-Evolution of Planning and Grounding in Autonomous GUI Agents](https://arxiv.org/abs/2511.10705)
*Yuan Zhao,Hualei Zhu,Tingyu Jiang,Shen Li,Xiaohang Xu,Hao Henry Wang*

Main category: cs.AI

TL;DR: GUI 작업 자동화는 인공지능 연구의 중요한 분야이며, Co-EPG라는 새로운 훈련 프레임워크를 통해 효과적인 계획 모델과 기초 모델의 협력적 발전을 도모한다.


<details>
  <summary>Details</summary>
Motivation: 현재 GUI 에이전트는 계획과 기초화 능력을 통합하지만, 두 가지 기본적인 한계를 가지고 있다: 모델 간 시너지의 충분한 활용 부족과 합성 데이터 생성에 대한 과도한 의존이다.

Method: Co-EPG는 계획 모델이 기초 기반 보상 지침에 따라 우수한 전략을 탐색할 수 있도록 하는 자가 반복 훈련 프레임워크이다. 이 프레임워크는 반복적인 긍정적 피드백 루프를 이루며, 이를 통해 다양한 데이터를 생성하여 기초 모델을 최적화한다.

Result: Co-EPG는 Multimodal-Mind2Web 및 AndroidControl 벤치마크에서 외부 데이터 없이 단 3회의 반복만으로 기존의 최신 방법보다 우수한 성능을 보여준다.

Conclusion: 이 연구는 GUI 에이전트를 위한 새로운 훈련 패러다임을 확립하여 고립된 최적화에서 통합되고 자주적인 co-evolution 접근 방식으로 전환한다.

Abstract: Graphical User Interface (GUI) task automation constitutes a critical frontier in artificial intelligence research. While effective GUI agents synergistically integrate planning and grounding capabilities, current methodologies exhibit two fundamental limitations: (1) insufficient exploitation of cross-model synergies, and (2) over-reliance on synthetic data generation without sufficient utilization. To address these challenges, we propose Co-EPG, a self-iterative training framework for Co-Evolution of Planning and Grounding. Co-EPG establishes an iterative positive feedback loop: through this loop, the planning model explores superior strategies under grounding-based reward guidance via Group Relative Policy Optimization (GRPO), generating diverse data to optimize the grounding model. Concurrently, the optimized Grounding model provides more effective rewards for subsequent GRPO training of the planning model, fostering continuous improvement. Co-EPG thus enables iterative enhancement of agent capabilities through self-play optimization and training data distillation. On the Multimodal-Mind2Web and AndroidControl benchmarks, our framework outperforms existing state-of-the-art methods after just three iterations without requiring external data. The agent consistently improves with each iteration, demonstrating robust self-enhancement capabilities. This work establishes a novel training paradigm for GUI agents, shifting from isolated optimization to an integrated, self-driven co-evolution approach.

</details>


### [18] [HARNESS: Human-Agent Risk Navigation and Event Safety System for Proactive Hazard Forecasting in High-Risk DOE Environments](https://arxiv.org/abs/2511.10810)
*Ran Elgedawy,Sanjay Das,Ethan Seefried,Gavin Wiggins,Ryan Burchfield,Dana Hewit,Sudarshan Srinivasan,Todd Thomas,Prasanna Balaprakash,Tirthankar Ghosal*

Main category: cs.AI

TL;DR: HARNESS는 U.S. DOE 환경에서 위험 예측 및 분석을 위한 AI 프레임워크로, 전문가와의 협업을 통해 안전성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 미션 크리티컬 작업 현장에서의 안전은 복잡하고 위험한 작업 특성 때문에 최우선 사항이다.

Method: HARNESS는 대형 언어 모델과 구조화된 작업 데이터, 이력 이벤트 검색 및 위험 분석을 통합하여 잠재적 위험을 사전에 식별한다.

Result: 초기 배포 결과 긍정적인 성과가 나타났으며, 향후 작업은 정확성, 전문가 동의 및 결정 지연 시간 감소의 정량적 평가에 중점을 둔다.

Conclusion: 전문가 협업과 반복적 대리 추론을 결합하여 HARNESS는 예측 안전 시스템의 신뢰성과 효율성을 향상시킨다.

Abstract: Operational safety at mission-critical work sites is a top priority given the complex and hazardous nature of daily tasks. This paper presents the Human-Agent Risk Navigation and Event Safety System (HARNESS), a modular AI framework designed to forecast hazardous events and analyze operational risks in U.S. Department of Energy (DOE) environments. HARNESS integrates Large Language Models (LLMs) with structured work data, historical event retrieval, and risk analysis to proactively identify potential hazards. A human-in-the-loop mechanism allows subject matter experts (SMEs) to refine predictions, creating an adaptive learning loop that enhances performance over time. By combining SME collaboration with iterative agentic reasoning, HARNESS improves the reliability and efficiency of predictive safety systems. Preliminary deployment shows promising results, with future work focusing on quantitative evaluation of accuracy, SME agreement, and decision latency reduction.

</details>


### [19] [Advanced Tool for Traffic Crash Analysis: An AI-Driven Multi-Agent Approach to Pre-Crash Reconstruction](https://arxiv.org/abs/2511.10853)
*Gerui Xu,Boyou Chen,Huizhong Guo,Dave LeBlanc,Ananna Ahmed,Zhaonan Sun,Shan Bao*

Main category: cs.AI

TL;DR: 이 연구는 다중 에이전트 AI 프레임워크를 개발하여 교통 사고 시나리오를 재구성하고 차량 행동을 추론하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 사고 재구성 방법은 인간 전문가에 의존하며, 불완전한 다중 모드 데이터를 분석할 때 일관되지 않은 결과를 초래할 수 있습니다.

Method: 다단계 협업 프레임워크를 구축하여 재구성 및 추론 단계를 결합했습니다. 이 시스템은 총 277건의 후방 추돌 데이터를 분석하여 다중 모드 입력을 처리합니다.

Result: 39개의 복잡한 사고 사례에서 완벽한 정확도를 달성했으며, EDR 이벤트를 성공적으로 식별했습니다.

Conclusion: 이 연구는 이질적인 사고 데이터를 처리하는 AI의 우월한 능력을 입증하며 사고 역학 재구성과 차량 행동 특성을 명확하게 설명합니다.

Abstract: Traffic collision reconstruction traditionally relies on human expertise, often yielding inconsistent results when analyzing incomplete multimodal data. This study develops a multi-agent AI framework that reconstructs pre-crash scenarios and infers vehicle behaviors from fragmented collision data. We present a two-phase collaborative framework combining reconstruction and reasoning phases. The system processes 277 rear-end lead vehicle deceleration (LVD) collisions from the Crash Investigation Sampling System, integrating textual crash reports, structured tabular data, and visual scene diagrams. Phase I generates natural-language crash reconstructions from multimodal inputs. Phase II performs in-depth crash reasoning by combining these reconstructions with temporal Event Data Recorder (EDR).For validation, we applied it to all LVD cases, focusing on a subset of 39 complex crashes where multiple EDR records per collision introduced ambiguity (e.g., due to missing or conflicting data).The evaluation of the 39 LVD crash cases revealed our framework achieved perfect accuracy across all test cases, successfully identifying both the most relevant EDR event and correctly distinguishing striking versus struck vehicles, surpassing the 92% accuracy achieved by human researchers on the same challenging dataset. The system maintained robust performance even when processing incomplete data, including missing or erroneous EDR records and ambiguous scene diagrams. This study demonstrates superior AI capabilities in processing heterogeneous collision data, providing unprecedented precision in reconstructing impact dynamics and characterizing pre-crash behaviors.

</details>


### [20] [Enhancing Demand-Oriented Regionalization with Agentic AI and Local Heterogeneous Data for Adaptation Planning](https://arxiv.org/abs/2511.10857)
*Seyedeh Mobina Noorani,Shangde Gao,Changjie Chen,Karla Saldana Ochoa*

Main category: cs.AI

TL;DR: 전통적인 도시 계획 단위는 지역 사회의 특정 수요를 반영하지 못하고 효과적인 재해 예방 및 대응 전략을 구현하는 데 유연성이 부족하다. 본 연구는 동적 계획 단위 생성을 지원하는 에이전트 기반 AI 시스템을 도입하여 사용자들이 재해 계획을 위한 수요 지향적인 지역을 생성할 수 있도록 하였다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 도시 계획 단위가 지역 사회의 구체적인 요구를 반영하지 못하고 재해 예방 혹은 대응 전략을 효과적으로 실행하기에 적절하지 않다는 문제를 해결하기 위해.

Method: 사용자들이 수요 지향적인 재해 계획 지역을 생성할 수 있도록 지원하는 에이전트 AI를 활용한 계획 지원 시스템을 개발하였다. 이 시스템은 RepSC-SOM이라는 초기화된 공간 제약 자기 조직화 지도를 기반으로 하며, 전통적인 SOM에 적응형 지리적 필터링과 지역 성장 정제를 추가하였다.

Result: 플랫폼의 기능을 플로리다 잭슨빌의 홍수 관련 위험 사례 연구를 통해 입증하였으며, 사용자가 상호 작용을 통해 지역화를 탐색, 생성 및 평가할 수 있게 했다.

Conclusion: 컴퓨터의 정밀성과 사용자 주도 의사 결정을 결합하여 효과적으로 지역화 문제를 해결할 수 있음을 보여주었다.

Abstract: Conventional planning units or urban regions, such as census tracts, zip codes, or neighborhoods, often do not capture the specific demands of local communities and lack the flexibility to implement effective strategies for hazard prevention or response. To support the creation of dynamic planning units, we introduce a planning support system with agentic AI that enables users to generate demand-oriented regions for disaster planning, integrating the human-in-the-loop principle for transparency and adaptability. The platform is built on a representative initialized spatially constrained self-organizing map (RepSC-SOM), extending traditional SOM with adaptive geographic filtering and region-growing refinement, while AI agents can reason, plan, and act to guide the process by suggesting input features, guiding spatial constraints, and supporting interactive exploration. We demonstrate the capabilities of the platform through a case study on the flooding-related risk in Jacksonville, Florida, showing how it allows users to explore, generate, and evaluate regionalization interactively, combining computational rigor with user-driven decision making.

</details>


### [21] [Multi-agent Undercover Gaming: Hallucination Removal via Counterfactual Test for Multimodal Reasoning](https://arxiv.org/abs/2511.11182)
*Dayong Liang,Xiao-Yong Wei,Changmeng Zheng*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델의 환각 문제를 해결하기 위해 새로운 MUG 프로토콜을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 추론 능력에서 환각은 주요 장애물로 작용합니다.

Method: MUG 프로토콜은 '누가 잠입자인가?'와 같은 사회적 추론 게임에서 영감을 받아 환각을 겪고 있는 '잠입자' 에이전트를 탐지하는 과정으로 MAD를 재구성합니다.

Result: 대안적 증거를 사용하여 에이전트가 환각을 겪는지를 식별할 수 있도록 합니다.

Conclusion: 이러한 혁신은 LLM의 다중 양식 추론을 위한 보다 신뢰할 수 있고 효과적인 프레임워크를 제공합니다.

Abstract: Hallucination continues to pose a major obstacle in the reasoning capabilities of large language models (LLMs). Although the Multi-Agent Debate (MAD) paradigm offers a promising solution by promoting consensus among multiple agents to enhance reliability, it relies on the unrealistic assumption that all debaters are rational and reflective, which is a condition that may not hold when agents themselves are prone to hallucinations. To address this gap, we introduce the Multi-agent Undercover Gaming (MUG) protocol, inspired by social deduction games like "Who is Undercover?". MUG reframes MAD as a process of detecting "undercover" agents (those suffering from hallucinations) by employing multimodal counterfactual tests. Specifically, we modify reference images to introduce counterfactual evidence and observe whether agents can accurately identify these changes, providing ground-truth for identifying hallucinating agents and enabling robust, crowd-powered multimodal reasoning. MUG advances MAD protocols along three key dimensions: (1) enabling factual verification beyond statistical consensus through counterfactual testing; (2) introducing cross-evidence reasoning via dynamically modified evidence sources instead of relying on static inputs; and (3) fostering active reasoning, where agents engage in probing discussions rather than passively answering questions. Collectively, these innovations offer a more reliable and effective framework for multimodal reasoning in LLMs. The source code can be accessed at https://github.com/YongLD/MUG.git.

</details>


### [22] [LLM enhanced graph inference for long-term disease progression modelling](https://arxiv.org/abs/2511.10890)
*Tiantian He,An Zhao,Elinor Thompson,Anna Schroder,Ahmed Abdulaal,Frederik Barkhof,Daniel C. Alexander*

Main category: cs.AI

TL;DR: 이 연구는 신경퇴행성 질환 동안 뇌 영역 간 바이오마커 상호작용을 이해하기 위한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 신경퇴행성 질환의 진행 메커니즘을 이해하는 것이 중요합니다.

Method: 대규모 언어 모델을 사용하여 불규칙하게 샘플링된 환자 데이터를 통해 질병 진행 학습을 향상시키는 새로운 프레임워크를 제시합니다.

Result: 알츠하이머 질환 환자 데이터의 타우-PET 이미징 데이터를 사용하여 병리 전파를 추정하여 이 방법의 효용성을 입증합니다.

Conclusion: 이 프레임워크는 전통적인 방법에 비해 우수한 예측 정확도와 해석 가능성을 보여줍니다.

Abstract: Understanding the interactions between biomarkers among brain regions during neurodegenerative disease is essential for unravelling the mechanisms underlying disease progression. For example, pathophysiological models of Alzheimer's Disease (AD) typically describe how variables, such as regional levels of toxic proteins, interact spatiotemporally within a dynamical system driven by an underlying biological substrate, often based on brain connectivity. However, current methods grossly oversimplify the complex relationship between brain connectivity by assuming a single-modality brain connectome as the disease-spreading substrate. This leads to inaccurate predictions of pathology spread, especially during the long-term progression period. Meanhwile, other methods of learning such a graph in a purely data-driven way face the identifiability issue due to lack of proper constraint. We thus present a novel framework that uses Large Language Models (LLMs) as expert guides on the interaction of regional variables to enhance learning of disease progression from irregularly sampled longitudinal patient data. By leveraging LLMs' ability to synthesize multi-modal relationships and incorporate diverse disease-driving mechanisms, our method simultaneously optimizes 1) the construction of long-term disease trajectories from individual-level observations and 2) the biologically-constrained graph structure that captures interactions among brain regions with better identifiability. We demonstrate the new approach by estimating the pathology propagation using tau-PET imaging data from an Alzheimer's disease cohort. The new framework demonstrates superior prediction accuracy and interpretability compared to traditional approaches while revealing additional disease-driving factors beyond conventional connectivity measures.

</details>


### [23] [Multi-Agent Legal Verifier Systems for Data Transfer Planning](https://arxiv.org/abs/2511.10925)
*Ha-Thanh Nguyen,Wachara Fungwacharakorn,Ken Satoh*

Main category: cs.AI

TL;DR: AI 기반 데이터 전송 계획의 법적 준수가 일본의 개인정보 보호법(APPI)과 같은 엄격한 프라이버시 규정 하에서 점점 더 중요해지고 있다. 이 논문에서는 법적 검증을 위한 다중 에이전트를 제안하며, 이를 통해 법률 해석, 비즈니스 맥락 평가, 위험 평가를 위한 전문 에이전트로 준수 점검을 분해하고, 구조화된 합성 프로토콜을 통해 조정한다. 200건의 수정된 APPI 제16조 사례에 대해 평가한 결과, 시스템은 72%의 정확도를 달성하여 단일 에이전트 기준선보다 21%포인트 더 높고, 명확한 준수 사례에서 90%의 정확도를 유지했으며(기준선: 16%) 명확한 위반을 완벽하게 감지했다. 모호한 시나리오에서는 여전히 도전 과제가 남아 있지만, 이러한 결과는 도메인 전문화와 협업적인 추론이 법적 AI 성능을 의미 있게 향상시킬 수 있음을 보여준다. 이는 신뢰할 수 있고 해석 가능한 자동화된 준수 검증을 위한 확장 가능하고 규정을 인식하는 프레임워크를 제공한다.


<details>
  <summary>Details</summary>
Motivation: AI 기반 데이터 전송 계획에서 법적 준수의 중요성이 증가하고 있다.

Method: 다중 에이전트 법적 검증기를 제안하여 준수 점검을 법률 해석, 비즈니스 맥락 평가, 위험 평가를 위한 전문 에이전트로 분해하고, 이를 구조화된 합성 프로토콜을 통해 조정한다.

Result: 200건의 수정된 APPI 제16조 사례에 대한 평가에서 72%의 정확도를 달성하였고, 명확한 준수 사례에서 90%의 정확도를 보여줌.

Conclusion: 도메인 전문화와 협조적 추론이 법적 AI 성능을 향상시킬 수 있으며, 신뢰할 수 있고 해석 가능한 자동화된 준수 검증을 위한 프레임워크를 제공한다.

Abstract: Legal compliance in AI-driven data transfer planning is becoming increasingly critical under stringent privacy regulations such as the Japanese Act on the Protection of Personal Information (APPI). We propose a multi-agent legal verifier that decomposes compliance checking into specialized agents for statutory interpretation, business context evaluation, and risk assessment, coordinated through a structured synthesis protocol. Evaluated on a stratified dataset of 200 Amended APPI Article 16 cases with clearly defined ground truth labels and multiple performance metrics, the system achieves 72% accuracy, which is 21 percentage points higher than a single-agent baseline, including 90% accuracy on clear compliance cases (vs. 16% for the baseline) while maintaining perfect detection of clear violations. While challenges remain in ambiguous scenarios, these results show that domain specialization and coordinated reasoning can meaningfully improve legal AI performance, providing a scalable and regulation-aware framework for trustworthy and interpretable automated compliance verification.

</details>


### [24] [Requirements for Aligned, Dynamic Resolution of Conflicts in Operational Constraints](https://arxiv.org/abs/2511.10952)
*Steven J. Jones,Robert E. Wray,John E. Laird*

Main category: cs.AI

TL;DR: 이 논문은 자율 AI 시스템이 복잡한 맥락에서 의사 결정을 내리기 위한 지식 요구사항을 규명한다.


<details>
  <summary>Details</summary>
Motivation: 자율 AI 시스템은 기존의 정책에 의존하지 않고 상황에 맞는 의사 결정을 내릴 필요가 있다.

Method: 분석과 경험적 사례 연구를 통해 에이전트가 의사 결정을 내리는 데 필요한 지식을 조사한다.

Result: 에이전트의 목표에 맞고 인간 기대에 aligned된 의사 결정을 위한 다양한 지식 유형을 식별했다.

Conclusion: AI 시스템은 상황에 맞는 이해를 통합하여 복잡한 환경에서 더 일관된 행동 경로를 선택해야 한다.

Abstract: Deployed, autonomous AI systems must often evaluate multiple plausible courses of action (extended sequences of behavior) in novel or under-specified contexts. Despite extensive training, these systems will inevitably encounter scenarios where no available course of action fully satisfies all operational constraints (e.g., operating procedures, rules, laws, norms, and goals). To achieve goals in accordance with human expectations and values, agents must go beyond their trained policies and instead construct, evaluate, and justify candidate courses of action. These processes require contextual "knowledge" that may lie outside prior (policy) training. This paper characterizes requirements for agent decision making in these contexts. It also identifies the types of knowledge agents require to make decisions robust to agent goals and aligned with human expectations. Drawing on both analysis and empirical case studies, we examine how agents need to integrate normative, pragmatic, and situational understanding to select and then to pursue more aligned courses of action in complex, real-world environments.

</details>


### [25] [AI Agent-Driven Framework for Automated Product Knowledge Graph Construction in E-Commerce](https://arxiv.org/abs/2511.11017)
*Dimitar Peshevski,Riste Stojanov,Dimitar Trajanov*

Main category: cs.AI

TL;DR: 본 연구는 비정형 제품 설명에서 자동으로 제품 지식 그래프를 구축하는 AI 기반 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 이커머스 플랫폼의 급속한 확장은 방대한 양의 비정형 제품 데이터를 생성하며, 이는 정보 검색, 추천 시스템 및 데이터 분석에 큰 도전과제가 됩니다.

Method: 우리는 대규모 언어 모델(LLMs)을 활용하여 전용 에이전트를 사용하는 세 가지 단계(온톨로지 생성 및 확장, 온톨로지 수정, 지식 그래프 구축)로 작동하는 완전 자동화된 AI 에이전트 기반 프레임워크를 소개합니다.

Result: 시스템은 에어컨 제품 설명의 실제 데이터세트에서 평가되었으며, 온톨로지 생성과 KG 구축 모두에서 강력한 성능을 보여주었습니다.

Conclusion: 이 프레임워크는 97% 이상의 속성 커버리지와 최소한의 중복을 달성하여 효과성과 실용성을 검증합니다. LLMs가 소매업에서 구조화된 지식 추출을 자동화하는 잠재력을 강조합니다.

Abstract: The rapid expansion of e-commerce platforms generates vast amounts of unstructured product data, creating significant challenges for information retrieval, recommendation systems, and data analytics. Knowledge Graphs (KGs) offer a structured, interpretable format to organize such data, yet constructing product-specific KGs remains a complex and manual process. This paper introduces a fully automated, AI agent-driven framework for constructing product knowledge graphs directly from unstructured product descriptions. Leveraging Large Language Models (LLMs), our method operates in three stages using dedicated agents: ontology creation and expansion, ontology refinement, and knowledge graph population. This agent-based approach ensures semantic coherence, scalability, and high-quality output without relying on predefined schemas or handcrafted extraction rules. We evaluate the system on a real-world dataset of air conditioner product descriptions, demonstrating strong performance in both ontology generation and KG population. The framework achieves over 97\% property coverage and minimal redundancy, validating its effectiveness and practical applicability. Our work highlights the potential of LLMs to automate structured knowledge extraction in retail, providing a scalable path toward intelligent product data integration and utilization.

</details>


### [26] [Key Decision-Makers in Multi-Agent Debates: Who Holds the Power?](https://arxiv.org/abs/2511.11040)
*Qian Zhang,Yan Zheng,Jinyi Liu,Hebin Liang,Lanjun Wang*

Main category: cs.AI

TL;DR: 이번 연구에서는 Multi-Agent Debate(MAD)의 성능 향상에 있어 역할 할당 전략의 중요성을 제시하고, 새로운 역할 할당 전략인 'Truth Last'가 추론 작업에서 MAD 성능을 최대 22% 개선할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트 스케일링에 대한 최신 연구들은 Multi-Agent Debate(MAD)가 추론 능력을 향상시킬 수 있는 잠재력을 강조하고 있지만, 역할 할당 전략의 중요한 측면은 충분히 탐구되지 않았다.

Method: 우리는 특정 위치에 상반된 관점을 가진 역할을 배분하는 것이 MAD의 추론 작업 성능에 미치는 영향을 보여준다. 또한 'Truth Last'라는 새로운 역할 할당 전략을 찾아냈으며, 이는 추론 작업에서 MAD 성능을 최대 22% 향상시킬 수 있다. 실제 어플리케이션에서의 미지의 진리 문제를 해결하기 위해 Multi-Agent Debate Consistency(MADC) 전략을 제안한다. MADC는 독립적인 역할 간의 합의를 평가하기 위해 경로 일관성을 포함하여 핵심 메커니즘을 체계적으로 시뮬레이션하고 최적화한다.

Result: MADC는 9개 모델(DeepSeek-R1 Distilled Models 포함)을 대상으로 한 도전적인 추론 작업에서 검증되었으며, 지속적으로 향상된 성능을 보여주었다. 이 방법은 MAD의 성능 병목 현상을 효과적으로 극복하고 LLM 에이전트 스케일링의 추가 개선을 위한 중요한 경로를 제공한다.

Conclusion: 이번 연구는 Multi-Agent Debate의 성능을 향상시키기 위한 새로운 역할 할당 전략과 MADC 접근법을 통해 LLM 에이전트의 효과적인 스케일링을 제시한다.

Abstract: Recent studies on LLM agent scaling have highlighted the potential of Multi-Agent Debate (MAD) to enhance reasoning abilities. However, the critical aspect of role allocation strategies remains underexplored. In this study, we demonstrate that allocating roles with differing viewpoints to specific positions significantly impacts MAD's performance in reasoning tasks. Specifically, we find a novel role allocation strategy, "Truth Last", which can improve MAD performance by up to 22% in reasoning tasks. To address the issue of unknown truth in practical applications, we propose the Multi-Agent Debate Consistency (MADC) strategy, which systematically simulates and optimizes its core mechanisms. MADC incorporates path consistency to assess agreement among independent roles, simulating the role with the highest consistency score as the truth. We validated MADC across a range of LLMs (9 models), including the DeepSeek-R1 Distilled Models, on challenging reasoning tasks. MADC consistently demonstrated advanced performance, effectively overcoming MAD's performance bottlenecks and providing a crucial pathway for further improvements in LLM agent scaling.

</details>


### [27] [Autonomous Vehicle Path Planning by Searching With Differentiable Simulation](https://arxiv.org/abs/2511.11043)
*Asen Nachkov,Jan-Nico Zaech,Danda Pani Paudel,Xi Wang,Luc Van Gool*

Main category: cs.AI

TL;DR: DSS 프레임워크는 자율주행에서 안전한 행동 계획을 위한 새로운 접근방식을 제시하며, 예측과 비판 기능을 결합하여 향상된 정확도를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 자율주행에서 충돌을 피하고 복잡한 교통 상황에서 내비게이션을 하기 위해서는 행동 계획이 필수적이다.

Method: Differentiable Simulation for Search(DSS) 프레임워크는 Waymax 시뮬레이터를 활용하여 다음 상태 예측기와 비평가로 사용된다.

Result: DSS는 미래의 경로를 상상하여 경량화된 행동 최적화를 통해 행동을 조정하며, 실험적으로 다른 계획 방법들과 비교할 때 추적 및 경로 계획의 정확도를 크게 향상시킴을 보여준다.

Conclusion: DSS는 계획 기울기와 확률적 검색의 조합을 통해 이전의 방법들과 비교할 때 더 나은 성능을 발휘한다.

Abstract: Planning allows an agent to safely refine its actions before executing them in the real world. In autonomous driving, this is crucial to avoid collisions and navigate in complex, dense traffic scenarios. One way to plan is to search for the best action sequence. However, this is challenging when all necessary components - policy, next-state predictor, and critic - have to be learned. Here we propose Differentiable Simulation for Search (DSS), a framework that leverages the differentiable simulator Waymax as both a next state predictor and a critic. It relies on the simulator's hardcoded dynamics, making state predictions highly accurate, while utilizing the simulator's differentiability to effectively search across action sequences. Our DSS agent optimizes its actions using gradient descent over imagined future trajectories. We show experimentally that DSS - the combination of planning gradients and stochastic search - significantly improves tracking and path planning accuracy compared to sequence prediction, imitation learning, model-free RL, and other planning methods.

</details>


### [28] [ARCTraj: A Dataset and Benchmark of Human Reasoning Trajectories for Abstract Problem Solving](https://arxiv.org/abs/2511.11079)
*Sejin Kim,Hayan Choi,Seokki Lee,Sundong Kim*

Main category: cs.AI

TL;DR: ARCTraj는 인간의 추론 과정을 모델링하기 위한 데이터셋과 방법론적 프레임워크로, ARC의 복잡한 시각적 과제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: ARC는 추상적 추론에 대한 연구를 촉발했지만, 기존 접근 방식은 정적인 입력-출력 감독에 의존하여 시간에 따른 추론 과정에 대한 통찰력이 제한된다.

Method: ARCTraj는 시간 순서에 따라 기록된 객체 수준의 행동을 통해 인간이 입력을 출력으로 변환하는 과정의 중간 추론 단계를 포착한다.

Result: O2ARC 웹 인터페이스를 통해 수집된 약 10,000개의 궤적은 400개의 과제에서 태스크 식별자, 타임스탬프 및 성공 레이블로 주석이 달려 있다.

Conclusion: ARCTraj는 인간과 유사한 추론을 연구하기 위한 구조적이고 해석 가능한 기초를 제공하며, 설명 가능성, 정렬 및 일반화 가능한 지능을 발전시킴으로써 연구에 기여한다.

Abstract: We present ARCTraj, a dataset and methodological framework for modeling human reasoning through complex visual tasks in the Abstraction and Reasoning Corpus (ARC). While ARC has inspired extensive research on abstract reasoning, most existing approaches rely on static input--output supervision, which limits insight into how reasoning unfolds over time. ARCTraj addresses this gap by recording temporally ordered, object-level actions that capture how humans iteratively transform inputs into outputs, revealing intermediate reasoning steps that conventional datasets overlook. Collected via the O2ARC web interface, it contains around 10,000 trajectories annotated with task identifiers, timestamps, and success labels across 400 training tasks from the ARC-AGI-1 benchmark. It further defines a unified reasoning pipeline encompassing data collection, action abstraction, Markov decision process (MDP) formulation, and downstream learning, enabling integration with reinforcement learning, generative modeling, and sequence modeling methods such as PPO, World Models, GFlowNets, Diffusion agents, and Decision Transformers. Analyses of spatial selection, color attribution, and strategic convergence highlight the structure and diversity of human reasoning. Together, these contributions position ARCTraj as a structured and interpretable foundation for studying human-like reasoning, advancing explainability, alignment, and generalizable intelligence.

</details>


### [29] [AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery](https://arxiv.org/abs/2511.11257)
*Yuqi Yin,Yibo Fu,Siyuan Wang,Peng Sun,Hongyu Wang,Xiaohui Wang,Lei Zheng,Zhiyong Li,Zhirong Liu,Jianji Wang,Zhaoxi Sun*

Main category: cs.AI

TL;DR: AIonopedia는 이온성 액체(IL) 발견을 위한 최초의 LLM 에이전트로, 정밀한 물성 예측과 분자 스크리닝을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 이온성 액체(IL)의 발견은 데이터 부족, 모델 정확도 저하 및 분산된 작업 흐름 등의 문제로 어려움을 겪고 있다.

Method: AIonopedia는 LLM 확장 다중 모드 도메인 기초 모델을 기반으로 하여 정확한 물성 예측을 수행하고 분자 스크리닝 및 설계를 위한 계층적 검색 아키텍처를 통합한다.

Result: 새롭게 큐레이션된 포괄적인 IL 데이터셋에서 훈련 및 평가된 모델은 우수한 성능을 보여주었다. 문헌 보고 시스템에 대한 평가에서도 IL 수정이 효과적임을 입증했다.

Conclusion: 현실 세계의 습식 실험을 통한 검증으로, 에이전트는 도전적인 배포 외 작업에서 뛰어난 일반화 능력을 보여주었으며, 이는 현실 세계의 IL 발견을 가속할 수 있는 잠재력을 강조한다.

Abstract: The discovery of novel Ionic Liquids (ILs) is hindered by critical challenges in property prediction, including limited data, poor model accuracy, and fragmented workflows. Leveraging the power of Large Language Models (LLMs), we introduce AIonopedia, to the best of our knowledge, the first LLM agent for IL discovery. Powered by an LLM-augmented multimodal domain foundation model for ILs, AIonopedia enables accurate property predictions and incorporates a hierarchical search architecture for molecular screening and design. Trained and evaluated on a newly curated and comprehensive IL dataset, our model delivers superior performance. Complementing these results, evaluations on literature-reported systems indicate that the agent can perform effective IL modification. Moving beyond offline tests, the practical efficacy was further confirmed through real-world wet-lab validation, in which the agent demonstrated exceptional generalization capabilities on challenging out-of-distribution tasks, underscoring its ability to accelerate real-world IL discovery.

</details>


### [30] [UAVBench: An Open Benchmark Dataset for Autonomous and Agentic AI UAV Systems via LLM-Generated Flight Scenarios](https://arxiv.org/abs/2511.11252)
*Mohamed Amine Ferrag,Abderrahmane Lakas,Merouane Debbah*

Main category: cs.AI

TL;DR: UAVBench는 50,000개의 UAV 비행 시나리오 및 50,000개의 선택형 질문으로 구성된 벤치마크 데이터셋으로, 자율 항공 시스템의 인지 및 결정 능력을 평가하는 데 사용된다.


<details>
  <summary>Details</summary>
Motivation: 자율 항공 시스템이 LLM에 의존함에 따라, 그들의 추론 능력을 체계적으로 평가할 수 있는 표준화된 벤치마크의 필요성이 있다.

Method: UAVBench는 50,000개의 검증된 UAV 비행 시나리오와 50,000개의 선택형 질문을 포함하며, 이를 통해 다양한 도메인에서 UAV 운영의 통합된 표현을 제공한다.

Result: 32개의 최신 LLM을 평가한 결과, 인식 및 정책 추론에서 강력한 성능을 보였으나, 윤리적 및 자원 제약 결정-making에서 지속적인 문제가 발견되었다.

Conclusion: UAVBench는 자율 항공 시스템에서 에이전트 AI를 벤치마킹하고 차세대 UAV 추론 지능을 발전시키기 위한 재현 가능하고 물리적으로 기반한 토대를 마련한다.

Abstract: Autonomous aerial systems increasingly rely on large language models (LLMs) for mission planning, perception, and decision-making, yet the lack of standardized and physically grounded benchmarks limits systematic evaluation of their reasoning capabilities. To address this gap, we introduce UAVBench, an open benchmark dataset comprising 50,000 validated UAV flight scenarios generated through taxonomy-guided LLM prompting and multi-stage safety validation. Each scenario is encoded in a structured JSON schema that includes mission objectives, vehicle configuration, environmental conditions, and quantitative risk labels, providing a unified representation of UAV operations across diverse domains. Building on this foundation, we present UAVBench_MCQ, a reasoning-oriented extension containing 50,000 multiple-choice questions spanning ten cognitive and ethical reasoning styles, ranging from aerodynamics and navigation to multi-agent coordination and integrated reasoning. This framework enables interpretable and machine-checkable assessment of UAV-specific cognition under realistic operational contexts. We evaluate 32 state-of-the-art LLMs, including GPT-5, ChatGPT-4o, Gemini 2.5 Flash, DeepSeek V3, Qwen3 235B, and ERNIE 4.5 300B, and find strong performance in perception and policy reasoning but persistent challenges in ethics-aware and resource-constrained decision-making. UAVBench establishes a reproducible and physically grounded foundation for benchmarking agentic AI in autonomous aerial systems and advancing next-generation UAV reasoning intelligence. To support open science and reproducibility, we release the UAVBench dataset, the UAVBench_MCQ benchmark, evaluation scripts, and all related materials on GitHub at https://github.com/maferrag/UAVBench

</details>


### [31] [Experience-Guided Adaptation of Inference-Time Reasoning Strategies](https://arxiv.org/abs/2511.11519)
*Adam Stein,Matthew Trager,Benjamin Bowman,Michael Kleinman,Aditya Chattopadhyay,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: EGuR는 누적된 경험을 바탕으로 문제에 맞춘 전략을 동적으로 생성하는 AI 시스템이다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 사후 훈련 상호작용에 따라 문제 해결 접근 방식을 적응시키는 것은 큰 도전 과제이다.

Method: EGuR는 LLM 기반 메타 전략을 사용하여 다양한 전략 구성 요소를 적응시킨다. 가이드는 현재 문제와 과거 경험의 구조적 메모리에 따라 후보 전략을 생성하고, 통합자는 실행 피드백을 반영하여 미래 전략 생성을 개선한다.

Result: EGuR는 5개의 도전적인 벤치마크에서 최대 14%의 정확도 개선과 최대 111배의 계산 비용 절감을 달성하였다.

Conclusion: EGuR는 자원을 낭비하지 않고도 각 문제에 최적화된 실행 가능한 전략을 제공한다.

Abstract: Enabling agentic AI systems to adapt their problem-solving approaches based on post-training interactions remains a fundamental challenge. While systems that update and maintain a memory at inference time have been proposed, existing designs only steer the system by modifying textual input to a language model or agent, which means that they cannot change sampling parameters, remove tools, modify system prompts, or switch between agentic and workflow paradigms. On the other hand, systems that adapt more flexibly require offline optimization and remain static once deployed. We present Experience-Guided Reasoner (EGuR), which generates tailored strategies -- complete computational procedures involving LLM calls, tools, sampling parameters, and control logic -- dynamically at inference time based on accumulated experience. We achieve this using an LLM-based meta-strategy -- a strategy that outputs strategies -- enabling adaptation of all strategy components (prompts, sampling parameters, tool configurations, and control logic). EGuR operates through two components: a Guide generates multiple candidate strategies conditioned on the current problem and structured memory of past experiences, while a Consolidator integrates execution feedback to improve future strategy generation. This produces complete, ready-to-run strategies optimized for each problem, which can be cached, retrieved, and executed as needed without wasting resources. Across five challenging benchmarks (AIME 2025, 3-SAT, and three Big Bench Extra Hard tasks), EGuR achieves up to 14% accuracy improvements over the strongest baselines while reducing computational costs by up to 111x, with both metrics improving as the system gains experience.

</details>


### [32] [A Workflow for Full Traceability of AI Decisions](https://arxiv.org/abs/2511.11275)
*Julius Wenzel,Syeda Umaima Alam,Andreas Schmidt,Hanwei Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: 자동화된 결정 시스템의 투명성을 확보하기 위해 모든 결정 과정의 문서화를 강제하는 작품이다.


<details>
  <summary>Details</summary>
Motivation: 부서진 인공지능 기술을 사용하는 자동화된 시스템에 의해 고위험 결정에서 발생할 수 있는 피해를 줄이기 위함이다.

Method: 자동화된 결정의 훈련 또는 추론에 들어가는 모든 구성 요소의 문서화를 강제하는 접근법을 사용하였다.

Result: 변조가 불가능하고 검증 가능한 AI 결정의 철저한 추적을 생성하는 첫 번째 실행 가능한 워크플로우를 제시하였다.

Conclusion: 이 워크플로우는 비밀 컴퓨팅 기술을 활용하여 DBOM 개념을 효과적으로 확장하였다.

Abstract: An ever increasing number of high-stake decisions are made or assisted by automated systems employing brittle artificial intelligence technology. There is a substantial risk that some of these decision induce harm to people, by infringing their well-being or their fundamental human rights. The state-of-the-art in AI systems makes little effort with respect to appropriate documentation of the decision process. This obstructs the ability to trace what went into a decision, which in turn is a prerequisite to any attempt of reconstructing a responsibility chain. Specifically, such traceability is linked to a documentation that will stand up in court when determining the cause of some AI-based decision that inadvertently or intentionally violates the law.
  This paper takes a radical, yet practical, approach to this problem, by enforcing the documentation of each and every component that goes into the training or inference of an automated decision. As such, it presents the first running workflow supporting the generation of tamper-proof, verifiable and exhaustive traces of AI decisions. In doing so, we expand the DBOM concept into an effective running workflow leveraging confidential computing technology. We demonstrate the inner workings of the workflow in the development of an app to tell poisonous and edible mushrooms apart, meant as a playful example of high-stake decision support.

</details>


### [33] [EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment](https://arxiv.org/abs/2511.11301)
*Ruoxi Cheng,Haoxuan Ma,Teng Ma,Hongyi Zhang*

Main category: cs.AI

TL;DR: EcoAlign라는 새로운 프레임워크를 통해 LVLM의 정렬 문제를 경제적 비율로 접근하여 안전성과 효용을 극대화하고 운영 비용을 줄인다.


<details>
  <summary>Details</summary>
Motivation: LVLM의 안전성 문제를 해결하고자 하며, 효율적인 경제적 관점에서 접근하고자 한다는 동기가 있다.

Method: EcoAlign은 LVLM을 제약된 합리적 에이전트로 보고 정렬을 경제적으로 합리적인 검색 문제로 재구성한다. 사고 그래프를 점진적으로 확장하고, 비율적 미래 가치와 비슷한 함수로 안전성, 효용 및 비용을 동적으로 평가하여 행동을 점수화한다.

Result: 3개의 폐쇄형 소스 모델과 2개의 개방형 소스 모델에 대한 6개의 데이터셋에서 수행된 실험 결과, EcoAlign은 최신 안전성과 효용 기준을 맞추거나 초과하면서 더 낮은 계산 비용으로 동작한다.

Conclusion: EcoAlign은 LVLM 정렬을 위한 강력하고 경제적인 경로를 제공한다.

Abstract: Large Vision-Language Models (LVLMs) exhibit powerful reasoning capabilities but suffer sophisticated jailbreak vulnerabilities. Fundamentally, aligning LVLMs is not just a safety challenge but a problem of economic efficiency. Current alignment methods struggle with the trade-off between safety, utility, and operational costs. Critically, a focus solely on final outputs (process-blindness) wastes significant computational budget on unsafe deliberation. This flaw allows harmful reasoning to be disguised with benign justifications, thereby circumventing simple additive safety scores. To address this, we propose EcoAlign, an inference-time framework that reframes alignment as an economically rational search by treating the LVLM as a boundedly rational agent. EcoAlign incrementally expands a thought graph and scores actions using a forward-looking function (analogous to net present value) that dynamically weighs expected safety, utility, and cost against the remaining budget. To prevent deception, path safety is enforced via the weakest-link principle. Extensive experiments across 3 closed-source and 2 open-source models on 6 datasets show that EcoAlign matches or surpasses state-of-the-art safety and utility at a lower computational cost, thereby offering a principled, economical pathway to robust LVLM alignment.

</details>


### [34] [RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms](https://arxiv.org/abs/2511.11323)
*Yitian Kou,Yihe Gu,Chen Zhou,DanDan Zhu,Shuguang Kuai*

Main category: cs.AI

TL;DR: RLSLM은 사회적인 환경에서의 비침입적 내비게이션을 가능하게 하는 하이브리드 강화 학습 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 사회적 인식이 있는 에이전트는 인간이 있는 환경을 불편함 없이 탐색할 수 있는 능력이 중요하다.

Method: RLSLM은 경험적 행동 실험에 뿌리를 둔 규칙 기반 사회적 보행 모델을 강화 학습 프레임워크의 보상 함수에 통합한 하이브리드 강화 학습 프레임워크이다.

Result: RLSLM은 사용자 경험에서 기존의 규칙 기반 모델보다 우수한 성능을 보였으며, 대체 분석 및 민감도 분석을 통해 기존의 데이터 기반 방법보다 해석 가능성이 크게 향상됨을 보여준다.

Conclusion: 이 연구는 실제 세계의 사회적 탐색을 위해 인지 과학과 기계 학습을 효과적으로 통합하는 확장 가능한 인간 중심 방법론을 제시한다.

Abstract: Navigating human-populated environments without causing discomfort is a critical capability for socially-aware agents. While rule-based approaches offer interpretability through predefined psychological principles, they often lack generalizability and flexibility. Conversely, data-driven methods can learn complex behaviors from large-scale datasets, but are typically inefficient, opaque, and difficult to align with human intuitions. To bridge this gap, we propose RLSLM, a hybrid Reinforcement Learning framework that integrates a rule-based Social Locomotion Model, grounded in empirical behavioral experiments, into the reward function of a reinforcement learning framework. The social locomotion model generates an orientation-sensitive social comfort field that quantifies human comfort across space, enabling socially aligned navigation policies with minimal training. RLSLM then jointly optimizes mechanical energy and social comfort, allowing agents to avoid intrusions into personal or group space. A human-agent interaction experiment using an immersive VR-based setup demonstrates that RLSLM outperforms state-of-the-art rule-based models in user experience. Ablation and sensitivity analyses further show the model's significantly improved interpretability over conventional data-driven methods. This work presents a scalable, human-centered methodology that effectively integrates cognitive science and machine learning for real-world social navigation.

</details>


### [35] [MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism](https://arxiv.org/abs/2511.11373)
*Shulin Liu,Dong Du,Tao Yang,Yang Li,Boyu Qiu*

Main category: cs.AI

TL;DR: MarsRL은 다중 에이전트 추론 시스템을 위한 새로운 강화 학습 프레임워크로, 에이전트별 보상 메커니즘과 파이프라인으로 영감을 받은 훈련을 도입하여 긴 경로 처리를 효율적으로 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 최근 대형 언어 모델의 발전은 검증 가능한 보상을 통한 강화 학습(RLVR)과 테스트 타임 스케일링에 의해 촉진되었습니다. 그러나 LLM의 제한된 출력 길이는 단일 추론 프로세스에서 달성 가능한 추론의 깊이를 제한합니다.

Method: MarsRL은 에이전트 파이프라인 병렬성을 갖춘 새로운 강화 학습 프레임워크로, 시스템 내 모든 에이전트를 공동 최적화하기 위해 설계되었습니다. MarsRL은 보상 노이즈를 완화하기 위해 에이전트별 보상 메커니즘을 도입하고, 긴 경로 처리를 효율적으로 개선하기 위해 파이프라인에서 영감을 받은 훈련 방식을 적용합니다.

Result: Qwen3-30B-A3B-Thinking-2507에 적용한 결과, MarsRL은 AIME2025 정확도를 86.5%에서 93.3%로, BeyondAIME는 64.9%에서 73.8%로 향상시켰으며, Qwen3-235B-A22B-Thinking-2507을 능가했습니다.

Conclusion: 이러한 결과는 MarsRL이 다중 에이전트 추론 시스템을 발전시켜 다양한 추론 작업에서의 적용 가능성을 넓힐 잠재력을 가지고 있음을 강조합니다.

Abstract: Recent progress in large language models (LLMs) has been propelled by reinforcement learning with verifiable rewards (RLVR) and test-time scaling. However, the limited output length of LLMs constrains the depth of reasoning attainable in a single inference process. Multi-agent reasoning systems offer a promising alternative by employing multiple agents including Solver, Verifier, and Corrector, to iteratively refine solutions. While effective in closed-source models like Gemini 2.5 Pro, they struggle to generalize to open-source models due to insufficient critic and correction capabilities. To address this, we propose MarsRL, a novel reinforcement learning framework with agentic pipeline parallelism, designed to jointly optimize all agents in the system. MarsRL introduces agent-specific reward mechanisms to mitigate reward noise and employs pipeline-inspired training to enhance efficiency in handling long trajectories. Applied to Qwen3-30B-A3B-Thinking-2507, MarsRL improves AIME2025 accuracy from 86.5% to 93.3% and BeyondAIME from 64.9% to 73.8%, even surpassing Qwen3-235B-A22B-Thinking-2507. These findings highlight the potential of MarsRL to advance multi-agent reasoning systems and broaden their applicability across diverse reasoning tasks.

</details>


### [36] [Robust and Efficient Communication in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.11393)
*Zejiao Liu,Yi Li,Jiali Wang,Junqi Tu,Yitian Hong,Fangfei Li,Yang Liu,Toshiharu Sugawara,Yang Tang*

Main category: cs.AI

TL;DR: 다중 에이전트 강화 학습(MARL)은 자율 에이전트 간의 협조적인 행동을 가능하게 하는 데 큰 발전을 이루었지만, 대부분의 기존 접근법은 통신이 즉각적이고 신뢰할 수 있으며 무제한 대역폭을 가진다고 가정한다. 본 조사는 실제 제약 조건 하에서 MARL을 위한 강건하고 효율적인 통신 전략에 대한 최근 발전을 체계적으로 검토한다.


<details>
  <summary>Details</summary>
Motivation: MARL 시스템에서의 신뢰할 수 있고 효율적인 통신 전략의 필요성.

Method: 메시지 변동, 전송 지연 및 제한된 대역폭과 같은 현실적인 제약 하에 강건한 통신 전략을 검토하고, 협동 자율 주행, 분산 동시 위치 확인 및 맵핑, 연합 학습과 같은 세 가지 응용 사례에 초점을 맞춤.

Result: 실제 MARL 시스템에서의 통신 체계의 중앙 관리 문제를 해결하기 위한 새로운 방법론을 제시.

Conclusion: 이론적 MARL 모델과 실제 구현 간의 간극을 해소하기 위해 통신, 학습 및 강건성을 공동 설계하는 통합 접근 방식을 옹호한다.

Abstract: Multi-agent reinforcement learning (MARL) has made significant strides in enabling coordinated behaviors among autonomous agents. However, most existing approaches assume that communication is instantaneous, reliable, and has unlimited bandwidth; these conditions are rarely met in real-world deployments. This survey systematically reviews recent advances in robust and efficient communication strategies for MARL under realistic constraints, including message perturbations, transmission delays, and limited bandwidth. Furthermore, because the challenges of low-latency reliability, bandwidth-intensive data sharing, and communication-privacy trade-offs are central to practical MARL systems, we focus on three applications involving cooperative autonomous driving, distributed simultaneous localization and mapping, and federated learning. Finally, we identify key open challenges and future research directions, advocating a unified approach that co-designs communication, learning, and robustness to bridge the gap between theoretical MARL models and practical implementations.

</details>


### [37] [Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping](https://arxiv.org/abs/2511.11551)
*Dena Mujtaba,Brian Hu,Anthony Hoogs,Arslan Basharat*

Main category: cs.AI

TL;DR: 결정-making AI 에이전트의 배치는 인간의 가치와 지침을 유지하는 데 중요한 도전 과제를 제시하며, 이는 복잡하고 동적인 환경에서 운영될 때 더욱 두드러진다. 본 논문은 에이전트의 행동 속성을 정밀하게 제어하고 윤리적 정렬과 보상 극대화 간의 균형을 수립하는 모델 기반 정책 형성 기법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 환경에서 인간의 가치와 지침에 맞춰 AI 에이전트를 조정하는 것은 큰 도전이다. 목표 달성을 위해 훈련된 에이전트는 해로운 행동을 취할 수 있다.

Method: 모델-가이드 정책 형성 기법을 기반으로 한 테스트 시 정렬 기술을 제안하여 윤리적 속성이 결정에 미치는 영향을 조정한다.

Result: MACHIAVELLI 벤치마크를 사용하여 우리의 접근 방식을 평가하였으며, 다양한 윤리적 결정 시나리오에 대한 RL 에이전트의 성능을 분석하였다.

Conclusion: 테스트 시간 정책 형성이 다양한 환경과 정렬 속성에서 비윤리적 행동을 완화하는 효과적이고 확장 가능한 솔루션을 제공한다.

Abstract: The deployment of decision-making AI agents presents a critical challenge in maintaining alignment with human values or guidelines while operating in complex, dynamic environments. Agents trained solely to achieve their objectives may adopt harmful behavior, exposing a key trade-off between maximizing the reward function and maintaining the alignment. For the pre-trained agents, ensuring alignment is particularly challenging, as retraining can be a costly and slow process. This is further complicated by the diverse and potentially conflicting attributes representing the ethical values for alignment. To address these challenges, we propose a test-time alignment technique based on model-guided policy shaping. Our method allows precise control over individual behavioral attributes, generalizes across diverse reinforcement learning (RL) environments, and facilitates a principled trade-off between ethical alignment and reward maximization without requiring agent retraining. We evaluate our approach using the MACHIAVELLI benchmark, which comprises 134 text-based game environments and thousands of annotated scenarios involving ethical decisions. The RL agents are first trained to maximize the reward in their respective games. At test time, we apply policy shaping via scenario-action attribute classifiers to ensure decision alignment with ethical attributes. We compare our approach against prior training-time methods and general-purpose agents, as well as study several types of ethical violations and power-seeking behavior. Our results demonstrate that test-time policy shaping provides an effective and scalable solution for mitigating unethical behavior across diverse environments and alignment attributes.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [38] [Towards Assume-Guarantee Verification of Abilities in Stochastic Multi-Agent Systems](https://arxiv.org/abs/2511.10649)
*Wojciech Jamroga,Damian Kurpiewski,Łukasz Mikulski*

Main category: cs.MA

TL;DR: 이 논문에서는 불완전 정보 및 확률적 환경에서 행위자의 전략적 능력 검증을 위한 여러 가지 assume-guarantee 검증 방안을 제안하고 그 타당성과 완전성을 논의합니다.


<details>
  <summary>Details</summary>
Motivation: 전략적 능력의 모델 검증은 어려운 문제이며, 특히 불완전 정보가 있는 행위자들이 확률적 환경에서 작동하는 경우 더욱 그렇습니다.

Method: 우리는 불완전 정보에 대한 확률적 교대 시간 논리를 위한 여러 assume-guarantee 검증 방안을 제안합니다.

Result: 이 방안들에 대한 타당성을 증명하고 완전성에 대해서도 논의합니다.

Conclusion: 우리는 Levesque의 '오직 아는' 논리와 유사한 '최대 $	ext{φ}$ 달성하기'라는 전략적 양식을 포착하는 새로운 비확률적 교대 시간 논리의 변형을 제안합니다.

Abstract: Model checking of strategic abilities is a notoriously hard problem, even more so in the realistic case of agents with imperfect information, acting in a stochastic environment. Assume-guarantee reasoning can be of great help here, providing a way to decompose the complex problem into a small set of easier subproblems.
  In this paper, we propose several schemes for assume-guarantee verification of probabilistic alternating-time temporal logic with imperfect information. We prove the soundness of the schemes, and discuss their completeness. On the way, we also propose a new variant of (non-probabilistic) alternating-time logic, where the strategic modalities capture "achieving at most $\varphi$," analogous to Levesque's logic of "only knowing."

</details>


### [39] [Who Gets the Reward, Who Gets the Blame? Evaluation-Aligned Training Signals for Multi-LLM Agents](https://arxiv.org/abs/2511.10687)
*Chih-Hsuan Yang,Tanwi Mallick,Le Chen,Krishnan Raghavan,Azton Wells,Amal Gueroudji,Ian T. Foster,Rajeev Thakur*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 시스템에서 대형 언어 모델의 시스템 수준 평가를 에이전트 신뢰도 및 응답 수준 신호로 변환하는 새로운 이론적 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 훈련 방법은 시스템 수준 평가와 에이전트 수준 및 메시지 수준 학습을 연결하는 원칙적인 방법이 부족하다.

Method: 협력적 게임 이론적 기여를 프로세스 보상 모델링과 통합하여 시스템 평가를 에이전트 신뢰도로 변환하는 이론적 프레임워크를 제안한다.

Result: 성공 사례에서는 Shapley 기반의 신뢰 배정이 에이전트 간 결과를 공정하게 분배하며, 메시지당 보상으로 정제되어 협력을 촉진하고 중복이나 방해를 억제한다. 실패 사례에서는 첫 오류 위치 지정이 해로운 단계를 처벌하며 수정적 시도를 보상하는 선호를 yields 한다.

Conclusion: 우리의 기여는 개념적이며, 이론적 기초와 훈련 신호를 제시하고 있으며, 실증 검증은 향후 연구에 맡긴다.

Abstract: Large Language Models (LLMs) in multi-agent systems (MAS) have shown promise for complex tasks, yet current training methods lack principled ways to connect system-level evaluation with agent-level and message-level learning. We propose a theoretical framework that unifies cooperative game-theoretic attribution with process reward modeling to transform system evaluation into agent credit and then into response-level signals. Unlike prior approaches that rely only on attribution (e.g., Shapley) or step-level labels (e.g., PRM), our method produces local, signed, and credit-conserving signals. In success cases, Shapley-based credit assignment fairly allocates outcomes across agents and is refined into per-message rewards that promote cooperation while discouraging redundancy or sabotage. In failure cases, first-error localization yields repair-aware preferences that penalize harmful steps while rewarding corrective attempts. The resulting signals are bounded, cooperative, and directly compatible with reinforcement-based or preference-based post-training, providing a unified and auditable pathway from global evaluation to local supervision in LLM multi-agent training. Our contribution is conceptual: we present a theoretical foundation and training signals, leaving empirical validation for future work.

</details>


### [40] [Exposing Weak Links in Multi-Agent Systems under Adversarial Prompting](https://arxiv.org/abs/2511.10949)
*Nirmit Arora,Sathvik Joel,Ishan Kavathekar,Palak,Rohan Gandhi,Yash Pandya,Tanuja Ganu,Aditya Kanade,Akshay Nambi*

Main category: cs.MA

TL;DR: LLM 기반 에이전트의 다중 에이전트 시스템 내 보안 취약점 분석을 다룬 연구.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템의 보안은 실세계 응용으로 나아갈수록 중요해진다.

Method: SafeAgents라는 통합되고 확장 가능한 프레임워크를 통해 다중 에이전트 시스템의 세분화된 보안 평가를 수행하였다.

Result: 다섯 가지 널리 사용되는 다중 에이전트 아키텍처에서 보안 취약점을 파악하였다.

Conclusion: MAS 설계에서 보안 인식적 설계의 필요성을 강조하였다.

Abstract: LLM-based agents are increasingly deployed in multi-agent systems (MAS). As these systems move toward real-world applications, their security becomes paramount. Existing research largely evaluates single-agent security, leaving a critical gap in understanding the vulnerabilities introduced by multi-agent design. However, existing systems fall short due to lack of unified frameworks and metrics focusing on unique rejection modes in MAS. We present SafeAgents, a unified and extensible framework for fine-grained security assessment of MAS. SafeAgents systematically exposes how design choices such as plan construction strategies, inter-agent context sharing, and fallback behaviors affect susceptibility to adversarial prompting. We introduce Dharma, a diagnostic measure that helps identify weak links within multi-agent pipelines. Using SafeAgents, we conduct a comprehensive study across five widely adopted multi-agent architectures (centralized, decentralized, and hybrid variants) on four datasets spanning web tasks, tool use, and code generation. Our findings reveal that common design patterns carry significant vulnerabilities. For example, centralized systems that delegate only atomic instructions to sub-agents obscure harmful objectives, reducing robustness. Our results highlight the need for security-aware design in MAS. Link to code is https://github.com/microsoft/SafeAgents

</details>


### [41] [GraphMASAL: A Graph-based Multi-Agent System for Adaptive Learning](https://arxiv.org/abs/2511.11035)
*Biqing Zeng,Mengquan Liu,Zongwei Zhen*

Main category: cs.MA

TL;DR: GraphMASAL은 동적 지식 그래프와 다중 에이전트 시스템을 사용하여 개인화된 학습 경로를 제공하는 지능형 튜터링 시스템입니다.


<details>
  <summary>Details</summary>
Motivation: 교육의 패러다임 전환으로 인공지능 튜터링 시스템이 등장하였지만, 기존 시스템은 복잡한 학습자의 지식 상태와 다양한 목표에 대한 적응력이 부족합니다.

Method: GraphMASAL은 동적 지식 그래프, 세 가지 에이전트(진단가, 계획가, 튜터), 두 단계의 신경 정보 검색 구성 요소 및 다중 소스-다중 싱크 계획 엔진을 통합하여 개인화된 학습 경로를 생성합니다.

Result: GraphMASAL은 다양한 학생 프로필에 대해 자동화된 평가에서 기존 방법들보다 뛰어난 성능을 보였고, 학습 경로의 구조적/순서적 정렬, 약한 개념의 폭넓은 커버리지, 학습 비용 절감을 달성했습니다.

Conclusion: 동적 지식 그래프에 기반한 LLM 에이전트의 최적화는 신뢰할 수 있고 해석 가능한 교육적 의미를 갖는 학습 계획을 제공하며, 개인화된 교육을 진전시킵니다.

Abstract: The advent of Intelligent Tutoring Systems (ITSs) has marked a paradigm shift in education, enabling highly personalized learning pathways. However, true personalization requires adapting to learners' complex knowledge states (multi-source) and diverse goals (multi-sink); existing ITSs often lack the necessary structural-reasoning capability and knowledge dynamism to generate genuinely effective learning paths, and they lack scientifically rigorous validation paradigms. In this paper we propose GraphMASAL (A Graph-based Multi-Agent System for Adaptive Learning), which integrates (i) a dynamic knowledge graph for persistent, stateful learner modeling; (ii) a LangGraph-orchestrated trio of agents (Diagnostician, Planner, Tutor); (iii) a knowledge-graph-grounded two-stage neural IR component (dual-encoder dense retrieval with cross-encoder listwise re-ranking and calibrated score fusion); and (iv) a multi-source multi-sink (MSMS) planning engine with a cognitively grounded cost and an approximation guarantee via greedy set cover. Under blinded automated evaluations with matched inputs and inference settings across diverse student profiles, GraphMASAL consistently outperforms LLM prompting and structured ablations in planning--achieving stronger structural/sequence alignment of learning paths, higher coverage of weak concepts, and lower learning cost--while also surpassing prompt-based baselines in cognitive diagnosis. Agreement with expert/LLM-proxy ratings further supports the validity of our evaluation protocol. These findings indicate that grounding LLM agents in a dynamic knowledge graph, coupled with optimization under educational constraints, yields reliable, interpretable, and pedagogically plausible learning plans, advancing personalized and goal-oriented education.

</details>
