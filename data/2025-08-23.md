<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 37]
- [cs.CR](#cs.CR) [Total: 14]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.LG](#cs.LG) [Total: 70]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [See it. Say it. Sorted: Agentic System for Compositional Diagram Generation](https://arxiv.org/abs/2508.15222)
*Hantao Zhang,Jingyang Liu,Ed Li*

Main category: cs.AI

TL;DR: 스케치-다이어그램 생성에 대한 연구로, 거친 손 스케치를 정밀하고 구성적인 다이어그램으로 변환하는 방법을 제시한다. 이 시스템은 Vision-Language 모델과 대형 언어 모델을 결합하여 편집 가능한 벡터 그래픽 프로그램을 생성한다.


<details>
  <summary>Details</summary>
Motivation: 다이어그램 생성을 위한 스케치와 요구되는 공간적 정밀도 및 구조적 정확성을 개선하기 위함이다.

Method: 교육이 필요 없는 에이전틱 시스템을 도입하여, Critic VLM이 질적 편집을 제안하고, 여러 후보 LLM이 다양한 전략으로 SVG 업데이트를 합성하며, Judge VLM이 최적의 후보를 선택하는 순환적 과정을 사용한다.

Result: 우리의 방법은 10개의 스케치에서 두 개의 최첨단 이미지 생성 LLM보다 레이아웃과 구조를 더 충실하게 재구성하며, 불필요한 텍스트 없이 원시 요소를 정확하게 구성한다.

Conclusion: 이 접근법은 프로그래머블 SVG를 출력하며, 프레젠테이션 도구로 쉽게 확장 가능하다.

Abstract: We study sketch-to-diagram generation: converting rough hand sketches into
precise, compositional diagrams. Diffusion models excel at photorealism but
struggle with the spatial precision, alignment, and symbolic structure required
for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic
system that couples a Vision-Language Model (VLM) with Large Language Models
(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system
runs an iterative loop in which a Critic VLM proposes a small set of
qualitative, relational edits; multiple candidate LLMs synthesize SVG updates
with diverse strategies (conservative->aggressive, alternative, focused); and a
Judge VLM selects the best candidate, ensuring stable improvement. This design
prioritizes qualitative reasoning over brittle numerical estimates, preserves
global constraints (e.g., alignment, connectivity), and naturally supports
human-in-the-loop corrections. On 10 sketches derived from flowcharts in
published papers, our method more faithfully reconstructs layout and structure
than two frontier closed-source image generation LLMs (GPT-5 and
Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)
without inserting unwanted text. Because outputs are programmatic SVGs, the
approach is readily extensible to presentation tools (e.g., PowerPoint) via
APIs and can be specialized with improved prompts and task-specific tools. The
codebase is open-sourced at
https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.

</details>


### [2] [Multiple Memory Systems for Enhancing the Long-term Memory of Agent](https://arxiv.org/abs/2508.15294)
*Gaoke Zhang,Bo Wang,Yunlong Ma,Dongming Zhao,Zifei Yu*

Main category: cs.AI

TL;DR: 대형 언어 모델로 구동되는 에이전트는 인상적인 결과를 얻었지만, 상호작용 중 생성되는 방대한 양의 역사적 데이터를 효과적으로 처리하는 것은 여전히 도전 과제이다. 본 논문에서는 인지 심리학 이론에 영감을 받아 고품질의 장기 기억 콘텐츠를 구축하기 위한 다중 기억 시스템(MMS)을 설계하였다.


<details>
  <summary>Details</summary>
Motivation: 상호작용 중 생성되는 방대한 역사적 데이터 처리의 어려움 때문에 에이전트의 기억 모듈을 설계할 필요성이 있다.

Method: 인지 심리학 이론에서 영감을 얻은 다중 기억 시스템(MMS)을 설계하여 단기 기억을 여러 장기 기억 조각으로 처리하며, 검색 기억 유닛과 맥락 기억 유닛을 구성한다.

Result: LoCoMo 데이터셋에서 우리의 방법과 다른 세 가지 방법을 비교하여 효과성을 증명했고, 메모리 유닛의 합리성을 확인하기 위한 제거 연구도 진행하였다.

Conclusion: 선택된 메모리 세그먼트 수와 저장 오버헤드에 대한 강건성을 분석하여 실용 가치를 입증하였다.

Abstract: An agent powered by large language models have achieved impressive results,
but effectively handling the vast amounts of historical data generated during
interactions remains a challenge. The current approach is to design a memory
module for the agent to process these data. However, existing methods, such as
MemoryBank and A-MEM, have poor quality of stored memory content, which affects
recall performance and response quality. In order to better construct
high-quality long-term memory content, we have designed a multiple memory
system (MMS) inspired by cognitive psychology theory. The system processes
short-term memory to multiple long-term memory fragments, and constructs
retrieval memory units and contextual memory units based on these fragments,
with a one-to-one correspondence between the two. During the retrieval phase,
MMS will match the most relevant retrieval memory units based on the user's
query. Then, the corresponding contextual memory units is obtained as the
context for the response stage to enhance knowledge, thereby effectively
utilizing historical data. Experiments on LoCoMo dataset compared our method
with three others, proving its effectiveness. Ablation studies confirmed the
rationality of our memory units. We also analyzed the robustness regarding the
number of selected memory segments and the storage overhead, demonstrating its
practical value.

</details>


### [3] [A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone](https://arxiv.org/abs/2508.14923)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 본 논문에서는 그래프 신호 처리를 기반으로 한 완전한 스펙트럼 신경 상징 추론 아키텍처를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 추론 모델들이 스펙트럼 그래프 방법을 주변 요소로 간주하는 것과는 달리, 우리는 전체 추론 파이프라인을 그래프 스펙트럼 영역에서 구성합니다.

Method: 논리적 개체와 관계를 그래프 신호로 인코딩하고, 다중 스케일 정보 전파를 제어하는 학습 가능한 스펙트럼 필터를 통해 처리하며, 규칙 기반 추론을 위해 상징적 술어로 매핑합니다.

Result: 벤치마크 추론 데이터셋에서 실험을 통해 논리적 일관성, 해석 가능성, 계산 효율성에서 기존 신경 상징 모델들보다 개선된 결과를 보여줍니다.

Conclusion: 그래프 신호 처리가 강력하고 해석 가능한 추론 시스템을 위한 수학적으로 근거 있는 효율적인 기초를 제공한다는 결과를 나타냅니다.

Abstract: We propose a fully spectral, neuro\-symbolic reasoning architecture that
leverages Graph Signal Processing (GSP) as the primary computational backbone
for integrating symbolic logic and neural inference. Unlike conventional
reasoning models that treat spectral graph methods as peripheral components,
our approach formulates the entire reasoning pipeline in the graph spectral
domain. Logical entities and relationships are encoded as graph signals,
processed via learnable spectral filters that control multi-scale information
propagation, and mapped into symbolic predicates for rule-based inference. We
present a complete mathematical framework for spectral reasoning, including
graph Fourier transforms, band-selective attention, and spectral rule
grounding. Experiments on benchmark reasoning datasets (ProofWriter,
EntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in
logical consistency, interpretability, and computational efficiency over
state\-of\-the\-art neuro\-symbolic models. Our results suggest that GSP
provides a mathematically grounded and computationally efficient substrate for
robust and interpretable reasoning systems.

</details>


### [4] [Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.15652)
*Ardian Selmonaj,Miroslav Strupl,Oleg Szehr,Alessandro Antonucci*

Main category: cs.AI

TL;DR: 이 논문은 다중 에이전트 강화 학습(MARL) 환경에서 에이전트 행동을 분석하고, 에이전트의 기여도를 추정하는 새로운 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: MARL 시스템을 신뢰성 있게 배포하기 위해 팀 내 개별 에이전트의 행동을 이해하는 것이 중요하다.

Method: 정보 이론적 샤플리 값을 기반으로 하는 의도된 협력 가치(ICVs)를 소개하며, 각 에이전트가 동료에게 미치는 인과적 영향을 정량화한다.

Result: 협력적 및 경쟁적 MARL 환경에 걸쳐 에이전트들이 유사하거나 다 diverse 전략을 채택하는 정도를 분석하였다.

Conclusion: 우리의 방법은 협력 동역학에 대한 새로운 통찰력을 제공하고 MARL 시스템의 설명 가능성을 향상시킨다.

Abstract: To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is
crucial to understand individual agent behaviors within a team. While prior
work typically evaluates overall team performance based on explicit reward
signals or learned value functions, it is unclear how to infer agent
contributions in the absence of any value feedback. In this work, we
investigate whether meaningful insights into agent behaviors can be extracted
that are consistent with the underlying value functions, solely by analyzing
the policy distribution. Inspired by the phenomenon that intelligent agents
tend to pursue convergent instrumental values, which generally increase the
likelihood of task success, we introduce Intended Cooperation Values (ICVs), a
method based on information-theoretic Shapley values for quantifying each
agent's causal influence on their co-players' instrumental empowerment.
Specifically, ICVs measure an agent's action effect on its teammates' policies
by assessing their decision uncertainty and preference alignment. The analysis
across cooperative and competitive MARL environments reveals the extent to
which agents adopt similar or diverse strategies. By comparing action effects
between policies and value functions, our method identifies which agent
behaviors are beneficial to team success, either by fostering deterministic
decisions or by preserving flexibility for future action choices. Our proposed
method offers novel insights into cooperation dynamics and enhances
explainability in MARL systems.

</details>


### [5] [Goals and the Structure of Experience](https://arxiv.org/abs/2508.15013)
*Nadav Amir,Stas Tiomkin,Angela Langdon*

Main category: cs.AI

TL;DR: 이 논문은 목적 지향적 행동의 계산적 구조를 설명하며, 목표와 환경의 상호작용에서 서술적 및 처방적 요소가 동시에 나타나는 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자연 및 인공지능의 목적 있는 행동의 이해와 설명을 위한 새로운 관점을 제시하고자 합니다.

Method: 인지 에이전트의 목표 지향적 상태 표현을 위한 계산적 프레임워크를 설명하며, 선 경험을 통한 서술적 및 처방적 요소의 동시 출현을 다룹니다.

Result: 목표에 대한 경험 분포의 통계적 다이버전스를 기반으로 목표 지향적 학습에 대한 간결한 설명을 제공합니다.

Conclusion: 이 새로운 관점이 행동, 현상학 및 신경 차원에서 목적 있는 행동을 통합적으로 설명할 가능성을 논의합니다.

Abstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its
acquisition is often believed to rely on world models, comprising both
descriptive (what is) and prescriptive (what is desirable) aspects that
identify and evaluate state of affairs in the world, respectively. Canonical
computational accounts of purposeful behavior, such as reinforcement learning,
posit distinct components of a world model comprising a state representation
(descriptive aspect) and a reward function (prescriptive aspect). However, an
alternative possibility, which has not yet been computationally formulated, is
that these two aspects instead co-emerge interdependently from an agent's goal.
Here, we describe a computational framework of goal-directed state
representation in cognitive agents, in which the descriptive and prescriptive
aspects of a world model co-emerge from agent-environment interaction
sequences, or experiences. Drawing on Buddhist epistemology, we introduce a
construct of goal-directed, or telic, states, defined as classes of
goal-equivalent experience distributions. Telic states provide a parsimonious
account of goal-directed learning in terms of the statistical divergence
between behavioral policies and desirable experience features. We review
empirical and theoretical literature supporting this novel perspective and
discuss its potential to provide a unified account of behavioral,
phenomenological and neural dimensions of purposeful behaviors across diverse
substrates.

</details>


### [6] [Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback](https://arxiv.org/abs/2508.15757)
*Yuxing Lu,Yucheng Hu,Nan Sun,Xukai Zhao*

Main category: cs.AI

TL;DR: 연구에서는 머신러닝의 구성 최적화를 위해 언어 기반 조정(LGT)이라는 새로운 프레임워크를 제안하며, 이는 다중 에이전트 대형 언어 모델을 활용하여 자연어 추론을 통해 지능적으로 구성 요소를 최적화한다.


<details>
  <summary>Details</summary>
Motivation: 구성 최적화는 머신러닝에서 중요한 병목 현상으로, 모델 아키텍처, 학습 전략, 특성 엔지니어링 및 하이퍼파라미터 전반에 걸쳐 조율이 필요하다.

Method: 언어 기반 조정(LGT) 프레임워크를 도입하여 다중 에이전트 대형 언어 모델을 활용하고, 텍스트 그래디언트를 사용하여 훈련 역학 및 구성 상호 의존성에 대한 의미적 이해를 제공한다.

Result: 여섯 개의 다양한 데이터 세트에 대한 종합적인 평가를 통해 LGT는 전통적인 최적화 방법에 비해 상당한 향상을 보여주었다.

Conclusion: 성능 향상을 달성하면서도 높은 해석 가능성을 유지한다.

Abstract: Configuration optimization remains a critical bottleneck in machine learning,
requiring coordinated tuning across model architecture, training strategy,
feature engineering, and hyperparameters. Traditional approaches treat these
dimensions independently and lack interpretability, while recent automated
methods struggle with dynamic adaptability and semantic reasoning about
optimization decisions. We introduce Language-Guided Tuning (LGT), a novel
framework that employs multi-agent Large Language Models to intelligently
optimize configurations through natural language reasoning. We apply textual
gradients - qualitative feedback signals that complement numerical optimization
by providing semantic understanding of training dynamics and configuration
interdependencies. LGT coordinates three specialized agents: an Advisor that
proposes configuration changes, an Evaluator that assesses progress, and an
Optimizer that refines the decision-making process, creating a self-improving
feedback loop. Through comprehensive evaluation on six diverse datasets, LGT
demonstrates substantial improvements over traditional optimization methods,
achieving performance gains while maintaining high interpretability.

</details>


### [7] [Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](https://arxiv.org/abs/2508.15030)
*Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang Wörndl,Yashar Deldjoo*

Main category: cs.AI

TL;DR: Collab-REC은 관광 추천에서 인기 편향을 극복하고 다양성을 향상시키기 위한 다중 에이전트 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 이 논문의 Motivation은 관광 추천에서의 인기 편향을 극복하고 다양한 선택지를 제공하기 위함입니다.

Method: 이 논문에서는 세 가지 LLM 기반 에이전트(개인화, 인기, 지속 가능성)가 서로 보완적인 관점에서 도시 제안을 생성하고, 비LLM 조정자가 다중 차례 협상을 통해 이를 통합하고 정제합니다.

Result: 실험 결과, Collab-REC은 단일 에이전트 기반선과 비교하여 다양성과 전반적인 관련성을 향상시키며, 종종 간과되는 덜 방문된 장소를 식별합니다.

Conclusion: 이 균형 잡힌 맥락 인식 접근 방식은 과도한 관광 문제를 해결하고 사용자 제공 제약과 더 잘 조화를 이루며, LLM 기반 추천 시스템에서 다중 이해관계자 협력의 가능성을 강조합니다.

Abstract: We propose Collab-REC, a multi-agent framework designed to counteract
popularity bias and enhance diversity in tourism recommendations. In our
setting, three LLM-based agents -- Personalization, Popularity, and
Sustainability generate city suggestions from complementary perspectives. A
non-LLM moderator then merges and refines these proposals via multi-round
negotiation, ensuring each agent's viewpoint is incorporated while penalizing
spurious or repeated responses. Experiments on European city queries show that
Collab-REC improves diversity and overall relevance compared to a single-agent
baseline, surfacing lesser-visited locales that often remain overlooked. This
balanced, context-aware approach addresses over-tourism and better aligns with
constraints provided by the user, highlighting the promise of multi-stakeholder
collaboration in LLM-driven recommender systems.

</details>


### [8] [Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](https://arxiv.org/abs/2508.15047)
*Yibo Liu,Liam Shatzel,Brandon Haworth,Teseo Schneider*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델을 활용하여 군중의 에이전트가 인지 입력과 진행 중인 대화를 기반으로 동작 결정을 내릴 수 있도록 하는 새로운 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인간의 내비게이션과 군중 내 움직임은 복잡한 사회적 및 환경적 상호작용에 의해 영향을 받을 수 있지만, 기존 연구는 이러한 차원들을 고려하지 않고 한정된 애니메이션을 생성합니다.

Method: 우리는 대화 시스템과 언어 기반 내비게이션을 포함하는 두 가지 주요 구성 요소로, 에이전트의 성격과 관계에 따라 조건화된 LLM을 통해 에이전트 간 대화를 생성하는 방법을 제안합니다.

Result: 두 가지 복잡한 시나리오에서 우리의 방법이 사회적 상호작용과 군중의 동작을 조절하는 데 중요한 역할을 하는 것을 확인했으며, 에이전트의 그룹화 및 비그룹화가 자동으로 발생합니다.

Conclusion: 우리의 프레임워크는 더 현실적인 군중 시뮬레이션을 생성하고, 자연스럽게 발생하는 집단 행동을 발산할 수 있습니다.

Abstract: Animating and simulating crowds using an agent-based approach is a
well-established area where every agent in the crowd is individually controlled
such that global human-like behaviour emerges. We observe that human navigation
and movement in crowds are often influenced by complex social and environmental
interactions, driven mainly by language and dialogue. However, most existing
work does not consider these dimensions and leads to animations where
agent-agent and agent-environment interactions are largely limited to steering
and fixed higher-level goal extrapolation.
  We propose a novel method that exploits large language models (LLMs) to
control agents' movement. Our method has two main components: a dialogue system
and language-driven navigation. We periodically query agent-centric LLMs
conditioned on character personalities, roles, desires, and relationships to
control the generation of inter-agent dialogue when necessitated by the spatial
and social relationships with neighbouring agents. We then use the conversation
and each agent's personality, emotional state, vision, and physical state to
control the navigation and steering of each agent. Our model thus enables
agents to make motion decisions based on both their perceptual inputs and the
ongoing dialogue.
  We validate our method in two complex scenarios that exemplify the interplay
between social interactions, steering, and crowding. In these scenarios, we
observe that grouping and ungrouping of agents automatically occur.
Additionally, our experiments show that our method serves as an
information-passing mechanism within the crowd. As a result, our framework
produces more realistic crowd simulations, with emergent group behaviours
arising naturally from any environmental setting.

</details>


### [9] [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](https://arxiv.org/abs/2508.15050)
*Romain Lacombe,Kerrie Wu,Eddie Dilworth*

Main category: cs.AI

TL;DR: 대형 언어 모델의 신뢰도 평가는 합리적인 추론 능력과 예산에 영향을 받으며, 실험 결과 신뢰도 보정은 깊은 추론보다 정보 접근이 더 중요하다는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 과도한 자신감을 피하기 위해 신뢰도를 신뢰성 있게 보정하는 필요성이 있다.

Method: ClimateX 데이터셋을 기반으로 하여 추론 능력과 예산이 신뢰도 평가 정확도에 미치는 영향을 체계적으로 평가한다.

Result: 전문가 신뢰도를 평가할 때 최근의 추론 LLM은 48.7%의 정확도를 보였으나, 추론 예산을 늘리면 보정이 개선되지 않고 오히려 악화된다.

Conclusion: 정보 접근이 신뢰도 보정 향상에 대한 주요 병목 현상일 수 있으므로, 깊은 추론보다 더 중요하다.

Abstract: Large Language Models deployed as question answering tools require robust
calibration to avoid overconfidence. We systematically evaluate how reasoning
capabilities and budget affect confidence assessment accuracy, using the
ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary
health. Our key finding challenges the "test-time scaling" paradigm: while
recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,
increasing reasoning budgets consistently impairs rather than improves
calibration. Extended reasoning leads to systematic overconfidence that worsens
with longer thinking budgets, producing diminishing and negative returns beyond
modest computational investments. Conversely, search-augmented generation
dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving
relevant evidence. Our results suggest that information access, rather than
reasoning depth or inference budget, may be the critical bottleneck for
improved confidence calibration of knowledge-intensive tasks.

</details>


### [10] [Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning](https://arxiv.org/abs/2508.15053)
*Itai Zilberstein,Alberto Candela,Steve Chien,David Rijlaarsdam,Tom Hendrix,Leonie Buckley,Aubrey Dunne*

Main category: cs.AI

TL;DR: Jet Propulsion Laboratory는 Ubotica Technologies와 협력하여 CS-6 위성에서 최첨단 데이터 분석을 시연하고 있다.


<details>
  <summary>Details</summary>
Motivation: 우리는 데이터 분석을 엣지에서 수행함으로써 새로운 지구 과학 측정 및 응답을 가능하게 하려는 동기를 가지고 있다.

Method: CS-6에서 심층 학습 및 스펙트럼 분석 알고리즘을 사용하여 데이터 분석 및 추론을 수행할 예정이다.

Result: 이러한 방법을 통해 다양한 응용 프로그램에 대한 데이터 분석과 추론을 시연할 것이다.

Conclusion: 이 연구는 onboard 데이터 분석을 통해 지구 과학 연구에 혁신적 기여를 할 수 있는 가능성을 보여준다.

Abstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is
demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).
CS-6 is a satellite with a visible and near infrared range hyperspectral
instrument and neural network acceleration hardware. Performing data analysis
at the edge (e.g. onboard) can enable new Earth science measurements and
responses. We will demonstrate data analysis and inference onboard CS-6 for
numerous applications using deep learning and spectral analysis algorithms.

</details>


### [11] [S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner](https://arxiv.org/abs/2508.15068)
*Shuang Ao,Gopal Rumchurn*

Main category: cs.AI

TL;DR: S3LoRA는 LoRA로 조정된 모델의 안전성을 높이기 위한 가벼운 프레임워크로, 파라미터 효율적인 미세 조정 기법을 활용하여 위험을 줄인다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트의 안전성 확보가 필요하다.

Method: S3LoRA는 MAS-SVD와 SSI를 사용하여 LoRA 업데이트의 구조적 특성을 분석하고, 위험이 높은 레이어를 선택적으로 제거하는 기법이다.

Result: S3LoRA는 안전성 및 유용성 지표를 개선하며 추론 비용을 크게 줄인다.

Conclusion: S3LoRA는 실제 자원이 제한되고 안전이 중요한 환경에서 LLM 기반 에이전트를 안전하게 배포하기 위한 실용적이고 확장 가능한 솔루션이다.

Abstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning
(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based
agents. However, these adaptations can unintentionally compromise safety
alignment, leading to unsafe or unstable behaviors, particularly in agent
planning tasks. Existing safety-aware adaptation methods often require access
to both base and instruction-tuned model checkpoints, which are frequently
unavailable in practice, limiting their applicability. We propose S3LoRA (Safe
Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and
model-independent framework that mitigates safety risks in LoRA-adapted models
by inspecting only the fine-tuned weight updates. We first introduce
Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes
the structural properties of LoRA updates while preserving global magnitude
information. We then design the Spectral Sharpness Index (SSI), a
sharpness-aware metric to detect layers with highly concentrated and
potentially unsafe updates. These layers are pruned post-hoc to reduce risk
without sacrificing task performance. Extensive experiments and ablation
studies across agent planning and language generation tasks show that S3LoRA
consistently improves safety metrics while maintaining or improving utility
metrics and significantly reducing inference cost. These results establish
S3LoRA as a practical and scalable solution for safely deploying LLM-based
agents in real-world, resource-constrained, and safety-critical environments.

</details>


### [12] [Argumentation for Explainable Workforce Optimisation (with Appendix)](https://arxiv.org/abs/2508.15118)
*Jennifer Leigh,Dimitrios Letsios,Alessandro Mella,Lucio Machetti,Francesca Toni*

Main category: cs.AI

TL;DR: 이 연구는 작업팀의 업무 최적화를 위한 관리 방법론을 제시하며, 변화에 대한 설명을 모든 이해관계자에게 제공할 수 있는 방법론을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 워크포스 관리의 복잡한 문제에 초점을 맞춰, 작업을 완료하기 위한 최적화 문제를 해결한다.

Method: 산업 응용에서의 추상적 주장으로서 워크포스 관리를 이해하여 변화를 수용하고 충실한 설명을 제공하는 방법을 제안한다.

Result: 사용자 연구를 통해 제안된 도구와 설명이 기존 수작업 솔루션보다 더 빠르고 정확한 문제 해결을 이끈다는 것을 보여준다.

Conclusion: 워크포스 관리에서의 변화에 효과적으로 대응하고, 모든 이해관계자에게 회복 가능한 설명을 제공하는 방법론을 확립한다.

Abstract: Workforce management is a complex problem optimising the makespan and travel
distance required for a team of operators to complete a set of jobs, using a
set of instruments. A crucial challenge in workforce management is
accommodating changes at execution time so that explanations are provided to
all stakeholders involved. Here, we show that, by understanding workforce
management as abstract argumentation in an industrial application, we can
accommodate change and obtain faithful explanations. We show, with a user
study, that our tool and explanations lead to faster and more accurate problem
solving than conventional solutions by hand.

</details>


### [13] [Open-Universe Assistance Games](https://arxiv.org/abs/2508.15119)
*Rachel Ma,Jingyi Qu,Andreea Bobu,Dylan Hadfield-Menell*

Main category: cs.AI

TL;DR: 이 논문은 인간의 다양한 목표와 선호를 파악하고 행동할 수 있는 AI 에이전트를 위한 새로운 프레임워크인 Open-Universe Assistance Games (OU-AGs)와 데이터 효율적인 목표 추출 방법인 GOOD를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 비정의된 다양한 인간 목표와 선호를 해석할 수 있는 AI 에이전트가 필요하다.

Method: GOOD는 자연어 형태로 목표를 추출하고 목표에 대한 분포를 추론하는 데이터 효율적인 온라인 방법이다.

Result: GOOD는 다양한 복잡한 의도를 가진 사용자 시뮬레이션을 통해 후보 목표에 대한 확률 추론을 수행하며, 대규모 오프라인 데이터셋 없이도 목표 표현과 불확실성 추정을 가능하게 한다.

Conclusion: 우리는 GOOD가 명시적 목표 추적 없이 비교 기준을 초과했음을 확인하였으며, 텍스트 기반의 장바구니 쇼핑 도메인과 시뮬레이션 가정 로봇 환경에서 평가했다.

Abstract: Embodied AI agents must infer and act in an interpretable way on diverse
human goals and preferences that are not predefined. To formalize this setting,
we introduce Open-Universe Assistance Games (OU-AGs), a framework where the
agent must reason over an unbounded and evolving space of possible goals. In
this context, we introduce GOOD (GOals from Open-ended Dialogue), a
data-efficient, online method that extracts goals in the form of natural
language during an interaction with a human, and infers a distribution over
natural language goals. GOOD prompts an LLM to simulate users with different
complex intents, using its responses to perform probabilistic inference over
candidate goals. This approach enables rich goal representations and
uncertainty estimation without requiring large offline datasets. We evaluate
GOOD in a text-based grocery shopping domain and in a text-operated simulated
household robotics environment (AI2Thor), using synthetic user profiles. Our
method outperforms a baseline without explicit goal tracking, as confirmed by
both LLM-based and human evaluations.

</details>


### [14] [aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://arxiv.org/abs/2508.15126)
*Pengsong Zhang,Xiang Hu,Guowei Huang,Yang Qi,Heng Zhang,Xiuxu Li,Jiaxing Song,Jiabin Luo,Yijiang Li,Shuo Yin,Chengxiao Dai,Eric Hanchen Jiang,Xiaoyan Zhou,Zhenfei Yin,Boqin Yuan,Jing Dong,Guinan Su,Guanren Qiao,Haiming Tang,Anghong Du,Lili Pan,Zhenzhong Lan,Xinyu Liu*

Main category: cs.AI

TL;DR: AI 모델들이 연구 제안서, 실험, 논문 작성 및 동료 검토를 스스로 수행할 수 있는 능력을 갖추었지만, 전통적인 출판 생태계와의 충돌 문제를 해결하기 위한 차세대 오픈 액세스 플랫폼인 aiXiv를 소개한다.


<details>
  <summary>Details</summary>
Motivation: AI가 생성한 연구 콘텐츠가 높은 품질을 갖추었음에도 불구하고, 이를 적절히 발표할 곳이 부족하여 과학적 진보가 저해되고 있다.

Method: aiXiv는 인간과 AI 과학자들이 연구 제안서와 논문을 제출하고, 리뷰하며, 반복적으로 수정할 수 있도록 하는 다중 에이전트 아키텍처를 제공한다.

Result: aiXiv는 AI 생성 연구 제안서와 논문의 품질을 크게 향상시키며 신뢰할 수 있는 플랫폼임이 실험을 통해 입증되었다.

Conclusion: aiXiv는 AI 과학자들을 위한 다음 세대 오픈 액세스 생태계의 기초를 마련하며, 고품질 AI 생성 연구 콘텐츠의 출판 및 배포를 가속화한다.

Abstract: Recent advances in large language models (LLMs) have enabled AI agents to
autonomously generate scientific proposals, conduct experiments, author papers,
and perform peer reviews. Yet this flood of AI-generated research content
collides with a fragmented and largely closed publication ecosystem.
Traditional journals and conferences rely on human peer review, making them
difficult to scale and often reluctant to accept AI-generated research content;
existing preprint servers (e.g. arXiv) lack rigorous quality-control
mechanisms. Consequently, a significant amount of high-quality AI-generated
research lacks appropriate venues for dissemination, hindering its potential to
advance scientific progress. To address these challenges, we introduce aiXiv, a
next-generation open-access platform for human and AI scientists. Its
multi-agent architecture allows research proposals and papers to be submitted,
reviewed, and iteratively refined by both human and AI scientists. It also
provides API and MCP interfaces that enable seamless integration of
heterogeneous human and AI scientists, creating a scalable and extensible
ecosystem for autonomous scientific discovery. Through extensive experiments,
we demonstrate that aiXiv is a reliable and robust platform that significantly
enhances the quality of AI-generated research proposals and papers after
iterative revising and reviewing on aiXiv. Our work lays the groundwork for a
next-generation open-access ecosystem for AI scientists, accelerating the
publication and dissemination of high-quality AI-generated research content.
Code is available at https://github.com/aixiv-org. Website is available at
https://forms.gle/DxQgCtXFsJ4paMtn8.

</details>


### [15] [Mobile-Agent-v3: Foundamental Agents for GUI Automation](https://arxiv.org/abs/2508.15144)
*Jiabo Ye,Xi Zhang,Haiyang Xu,Haowei Liu,Junyang Wang,Zhaoqing Zhu,Ziwei Zheng,Feiyu Gao,Junjie Cao,Zhengxi Lu,Jitong Liao,Qi Zheng,Fei Huang,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: 이 논문은 GUI-Owl이라는 최첨단 GUI 에이전트 모델을 도입하며, 이를 통해 오픈 소스 엔드 투 엔드 모델들이 데스크탑 및 모바일 환경에서 10개의 GUI 벤치마크에서 최고의 성능을 달성합니다.


<details>
  <summary>Details</summary>
Motivation: 오픈 소스 GUI 에이전트 프레임워크의 성능을 향상시키기 위해 개념을 제안하고, 다양한 GUI 작업을 지원하는 새로운 모델을 개발하는 것이 필요하다.

Method: GUI-Owl과 Mobile-Agent-v3라는 두 가지 모델을 제안하며, 대규모 환경 인프라와 다양한 기초 에이전트 기능, 확장 가능한 강화 학습 프레임워크를 활용하여 성능을 향상시킨다.

Result: GUI-Owl-7B는 AndroidWorld에서 66.4의 점수를, OSWorld에서 29.4의 점수를 기록하며, Mobile-Agent-v3는 각각 73.3과 37.7로 성능을 높인다.

Conclusion: GUI-Owl과 Mobile-Agent-v3는 오픈 소스 GUI 에이전트 프레임워크의 새로운 기준을 설정하며, GitHub에서 소스 코드가 공개되어 있다.

Abstract: This paper introduces GUI-Owl, a foundational GUI agent model that achieves
state-of-the-art performance among open-source end-to-end models on ten GUI
benchmarks across desktop and mobile environments, covering grounding, question
answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B
achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose
Mobile-Agent-v3, a general-purpose GUI agent framework that further improves
performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new
state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates
three key innovations: (1) Large-scale Environment Infrastructure: a
cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,
enabling our Self-Evolving GUI Trajectory Production framework. This generates
high-quality interaction data via automated query generation and correctness
validation, leveraging GUI-Owl to refine trajectories iteratively, forming a
self-improving loop. It supports diverse data pipelines and reduces manual
annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI
grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports
end-to-end decision-making and can act as a modular component in multi-agent
systems. (3) Scalable Environment RL: we develop a scalable reinforcement
learning framework with fully asynchronous training for real-world alignment.
We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for
online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are
open-sourced at https://github.com/X-PLUG/MobileAgent.

</details>


### [16] [PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data](https://arxiv.org/abs/2508.15180)
*Kai Xiong,Yanwei Huang,Rongjunchen Zhang,Kun Chen,Haipang Wu*

Main category: cs.AI

TL;DR: PuzzleClone은 검증 가능한 데이터를 대규모로 합성하기 위한 포괄적인 프레임워크로, 대형 언어 모델의 추론 능력을 향상시키기 위한 데이터셋을 생성합니다.


<details>
  <summary>Details</summary>
Motivation: 높품질의 수학 및 논리 데이터셋이 대형 언어 모델의 추론 능력 강화를 위해 필수적입니다.

Method: PuzzleClone은 Satisfiability Modulo Theories (SMT)을 사용하여 검증 가능한 데이터를 대규모로 합성하는 포괄적인 프레임워크를 제공합니다.

Result: PuzzleClone을 통해 83,000개 이상의 다양한 프로그래밍 검증 완료된 퍼즐로 구성된 기준선이 생성되었습니다.

Conclusion: PuzzleClone에서의 훈련은 논리 및 수학 기준선에서도 상당한 개선을 이루며, 평균 성과를 14.4에서 56.2로 높였습니다.

Abstract: High-quality mathematical and logical datasets with verifiable answers are
essential for strengthening the reasoning capabilities of large language models
(LLMs). While recent data augmentation techniques have facilitated the creation
of large-scale benchmarks, existing LLM-generated datasets often suffer from
limited reliability, diversity, and scalability. To address these challenges,
we introduce PuzzleClone, a formal framework for synthesizing verifiable data
at scale using Satisfiability Modulo Theories (SMT). Our approach features
three key innovations: (1) encoding seed puzzles into structured logical
specifications, (2) generating scalable variants through systematic variable
and constraint randomization, and (3) ensuring validity via a reproduction
mechanism. Applying PuzzleClone, we construct a curated benchmark comprising
over 83K diverse and programmatically validated puzzles. The generated puzzles
span a wide spectrum of difficulty and formats, posing significant challenges
to current state-of-the-art models. We conduct post training (SFT and RL) on
PuzzleClone datasets. Experimental results show that training on PuzzleClone
yields substantial improvements not only on PuzzleClone testset but also on
logic and mathematical benchmarks. Post training raises PuzzleClone average
from 14.4 to 56.2 and delivers consistent improvements across 7 logic and
mathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from
52.5 to 65.0). Our code and data are available at
https://github.com/puzzleclone.

</details>


### [17] [LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support](https://arxiv.org/abs/2508.15192)
*Wenjie Lin,Jin Wei-Kocsis*

Main category: cs.AI

TL;DR: LLM4Sweat는 희귀 질환인 다한증을 위한 개방형, 도메인 특화된 언어 모델 프레임워크로, 데이터 부족 문제를 해결하고 신뢰성과 공감성을 갖춘 지원을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 희귀 의료 질환인 다한증을 진단하고 치료하는 데 있어 대규모 언어 모델(LLMs)의 활용이 부족한 상태이다.

Method: 프레임워크는 세 단계로 구성되어 있다. 데이터 증대 단계에서 LLM이 의료적으로 타당한 합성 사례를 생성하여 질문-답변 데이터셋을 만든다. 세밀화 단계에서 모델을 데이터셋에 대해 세밀화하여 진단, 개인화된 치료 권장사항, 심리적 지원을 제공한다. 마지막으로 전문가 평가 단계에서 임상 및 심리 전문가가 정확성과 적합성을 평가한다.

Result: LLM4Sweat는 기준 모델보다 우수한 성능을 보이며, 다한증을 위한 첫 번째 개방형 언어 모델 프레임워크를 제공한다.

Conclusion: 유사한 데이터와 신뢰성 문제를 가진 다른 희귀 질환에 대한 일반화 가능한 접근 방식을 제시한다.

Abstract: While large language models (LLMs) have shown promise in healthcare, their
application for rare medical conditions is still hindered by scarce and
unreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing
excessive sweating beyond physiological needs, is one such rare disorder,
affecting 2-3% of the population and significantly impacting both physical
comfort and psychosocial well-being. To date, no work has tailored LLMs to
advance the diagnosis or care of hyperhidrosis. To address this gap, we present
LLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and
empathetic hyperhidrosis support. The system follows a three-stage pipeline. In
the data augmentation stage, a frontier LLM generates medically plausible
synthetic vignettes from curated open-source data to create a diverse and
balanced question-answer dataset. In the fine-tuning stage, an open-source
foundation model is fine-tuned on the dataset to provide diagnosis,
personalized treatment recommendations, and empathetic psychological support.
In the inference and expert evaluation stage, clinical and psychological
specialists assess accuracy, appropriateness, and empathy, with validated
responses iteratively enriching the dataset. Experiments show that LLM4Sweat
outperforms baselines and delivers the first open-source LLM framework for
hyperhidrosis, offering a generalizable approach for other rare diseases with
similar data and trustworthiness challenges.

</details>


### [18] [R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling](https://arxiv.org/abs/2508.15204)
*Raj Jain,Marc Wetter*

Main category: cs.AI

TL;DR: 제한된 리소스와 타이밍 아래에서의 효율적인 스케줄링은 다양한 산업에서 대규모 계획의 기초가 된다. 본 논문은 R-ConstraintBench라는 확장 가능한 프레임워크를 제안하여, 모델을 자원 제약 프로젝트 스케줄링 문제(RCPSP)에서 평가한다.


<details>
  <summary>Details</summary>
Motivation: 자원, 타이밍 및 운영 제약이 엄격한 상황에서의 대형 언어 모델(LLM)의 신뢰성에 대한 이해가 부족하다.

Method: R-ConstraintBench는 비순환 유향 그래프(DAG)에서 비중복 우선 제약을 점진적으로 증가시키고 다운타임, 시간 창 및 이분 제약을 도입하여 RCPSP의 난이도를 선형적으로 증가시킨다.

Result: 강력한 모델은 순수 우선 순위 DAG에서 성능이 최고 수준에 가깝지만, 다운타임, 시간 창 및 이분 제약이 상호 작용할 때 타당성 성능이 급격히 저하된다.

Conclusion: 청정 합성 램프에서의 성능이 실제 도메인 시나리오로의 이전을 보장하지 않음으로써 일반화의 한계를 강조한다.

Abstract: Effective scheduling under tight resource, timing, and operational
constraints underpins large-scale planning across sectors such as capital
projects, manufacturing, logistics, and IT fleet transitions. However, the
reliability of large language models (LLMs) when reasoning under
high-constraint regimes is insufficiently characterized. To address this gap,
we present R-ConstraintBench, a scalable framework that evaluates models on
Resource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete
feasibility class, while difficulty increases via linear growth in constraints.
R-ConstraintBench incrementally increases non-redundant precedence constraints
in Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal
windows, and disjunctive constraints. As an illustrative example, we
instantiate the benchmark in a data center migration setting and evaluate
multiple LLMs using feasibility and error analysis, identifying degradation
thresholds and constraint types most associated with failure. Empirically,
strong models are near-ceiling on precedence-only DAGs, but feasibility
performance collapses when downtime, temporal windows, and disjunctive
constraints interact, implicating constraint interaction, not graph depth, as
the principal bottleneck. Performance on clean synthetic ramps also does not
guarantee transfer to domain-grounded scenarios, underscoring limited
generalization.

</details>


### [19] [Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas](https://arxiv.org/abs/2508.15240)
*Sabab Aosaf,Muhammad Ali Nayeem,Afsana Haque,M Sohel Rahmana*

Main category: cs.AI

TL;DR: 도시 토지 이용 할당은 지속 가능한 도시 개발 정책을 위한 복잡한 다목적 최적화 문제를 나타낸다. 본 논문은 혼합 사용 지역에서 토지 이용 할당을 최적화하기 위한 새로운 계산 지능 접근 방식을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 도시 토지 이용 할당은 지속 가능한 도시 개발 정책을 위한 중요한 문제이다.

Method: 다목적 유전 알고리즘과 차별 진화를 통합한 맞춤형 변형을 포함한 여러 최적화 알고리즘을 개발한다.

Result: CR+DES 알고리즘은 최신 방법에 비해 토지 이용 호환성을 3.16% 개선하고, MSBX+MO는 가격 최적화에서 3.3% 개선을 달성한다.

Conclusion: 이 연구 결과는 도시 계획자 및 정책 입안자에게 도시 개발 정책을 효과적으로 지원할 수 있는 근거 기반의 계산 도구를 제공한다.

Abstract: Urban land-use allocation represents a complex multi-objective optimization
problem critical for sustainable urban development policy. This paper presents
novel computational intelligence approaches for optimizing land-use allocation
in mixed-use areas, addressing inherent trade-offs between land-use
compatibility and economic objectives. We develop multiple optimization
algorithms, including custom variants integrating differential evolution with
multi-objective genetic algorithms. Key contributions include: (1) CR+DES
algorithm leveraging scaled difference vectors for enhanced exploration, (2)
systematic constraint relaxation strategy improving solution quality while
maintaining feasibility, and (3) statistical validation using Kruskal-Wallis
tests with compact letter displays. Applied to a real-world case study with
1,290 plots, CR+DES achieves 3.16\% improvement in land-use compatibility
compared to state-of-the-art methods, while MSBX+MO excels in price
optimization with 3.3\% improvement. Statistical analysis confirms algorithms
incorporating difference vectors significantly outperform traditional
approaches across multiple metrics. The constraint relaxation technique enables
broader solution space exploration while maintaining practical constraints.
These findings provide urban planners and policymakers with evidence-based
computational tools for balancing competing objectives in land-use allocation,
supporting more effective urban development policies in rapidly urbanizing
regions.

</details>


### [20] [Coarse-to-Fine Grounded Memory for LLM Agent Planning](https://arxiv.org/abs/2508.15305)
*Wei Yang,Jinwei Xiao,Hongming Zhang,Qingyang Zhang,Yanna Wang,Bo Xu*

Main category: cs.AI

TL;DR: 이 논문은 LLM 기반 에이전트의 계획 작업을 위한 새로운 메모리 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 계획 작업을 위한 LLM 기반 에이전트에 대한 관심이 증가하고 있습니다.

Method: Coarse-to-Fine Grounded Memory (\Ours{})라는 새로운 프레임워크를 제안하여, LLM과 함께 조잡한 메모리를 세분화하여 사용합니다.

Result: 이 프레임워크는 다양한 시나리오에 적응하기 위한 경험 수집을 지원하고, 추론 시 관련된 경험과 팁을 검색합니다.

Conclusion: 환경적 이상에 직면했을 때, LLM은 현재 상황을 세부 정보를 기반으로 하여 유연한 자기 QA 반성과 계획 수정이 가능하게 합니다.

Abstract: Recent advancements in Large Language Models (LLMs) have driven growing
interest in LLM-based agents for complex planning tasks. To avoid costly agent
training, many studies adopted memory mechanism that enhances LLM with offline
experiences or online trajectory analysis. However, existing works focus on
single-granularity memory derived from dynamic environmental interactions,
which are inherently constrained by the quality of the collected experiences.
This limitation, in turn, constrain the diversity of knowledge and the
flexibility of planning. We propose Coarse-to-Fine Grounded Memory (\Ours{}), a
novel framework that grounds coarse-to-fine memories with LLM, thereby fully
leverage them for flexible adaptation to diverse scenarios. \Ours{} grounds
environmental information into coarse-grained focus points to guide experience
collection in training tasks, followed by grounding of actionable
hybrid-grained tips from each experience. At inference, \Ours{} retrieves
task-relevant experiences and tips to support planning. When facing
environmental anomalies, the LLM grounds the current situation into
fine-grained key information, enabling flexible self-QA reflection and plan
correction.

</details>


### [21] [Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning](https://arxiv.org/abs/2508.15327)
*Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li*

Main category: cs.AI

TL;DR: 오프라인 강화 학습은 고정된 데이터셋에서 정책을 학습하는 과정으로, 추가적인 환경 상호작용 없이 이루어진다. 그러나 잘 정의된 보상 함수에 의존하는 경우가 많아 설계하기 어렵고 비용이 많이 든다. 이 논문에서는 인간 피드백을 대체할 수 있는 Search-Based Preference Weighting (SPW) 방식을 소개하며, 이 방식이 선호도와 전문가 시연이라는 두가지 피드백 소스를 통합하여 효과적으로 학습할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 환경 상호작용 없이 고정된 데이터셋에서 정책을 학습하는 과정인 오프라인 강화 학습은 잘 정의된 보상 함수를 필요로 하며, 이는 설계하기 어렵고 비용이 많이 든다.

Method: 각 선호도 레이블이 붙은 궤적의 전환에 대해 SPW는 전문가 시연으로부터 가장 유사한 상태-작동 쌍을 검색하고 그 유사성 점수를 기반으로 단계별 중요도 가중치를 직접 도출한다.

Result: SPW는 표준 선호도 학습을 안내하여 보다 정확한 신뢰도를 할당할 수 있도록 하며, 기존 방법보다 높은 성능을 발휘한다.

Conclusion: 우리는 SPW가 선호도와 시연으로부터 효과적인 공동 학습을 가능하게 하여, 도전적인 로봇 조작 작업에서 두 가지 피드백 유형을 모두 활용하는 이전 방법들보다 우수한 성능을 발휘함을 보여주었다.

Abstract: Offline reinforcement learning refers to the process of learning policies
from fixed datasets, without requiring additional environment interaction.
However, it often relies on well-defined reward functions, which are difficult
and expensive to design. Human feedback is an appealing alternative, but its
two common forms, expert demonstrations and preferences, have complementary
limitations. Demonstrations provide stepwise supervision, but they are costly
to collect and often reflect limited expert behavior modes. In contrast,
preferences are easier to collect, but it is unclear which parts of a behavior
contribute most to a trajectory segment, leaving credit assignment unresolved.
In this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to
unify these two feedback sources. For each transition in a preference labeled
trajectory, SPW searches for the most similar state-action pairs from expert
demonstrations and directly derives stepwise importance weights based on their
similarity scores. These weights are then used to guide standard preference
learning, enabling more accurate credit assignment that traditional approaches
struggle to achieve. We demonstrate that SPW enables effective joint learning
from preferences and demonstrations, outperforming prior methods that leverage
both feedback types on challenging robot manipulation tasks.

</details>


### [22] [RETAIL: Towards Real-world Travel Planning for Large Language Models](https://arxiv.org/abs/2508.15335)
*Bin Deng,Yizhe Feng,Zeming Liu,Qing Wei,Xiangrong Zhu,Shuai Chen,Yuanfang Guo,Yunhong Wang*

Main category: cs.AI

TL;DR: 자동 여행 계획 능력을 향상시킨 대형 언어 모델에도 불구하고 현재 시스템은 실제 시나리오와 맞지 않다. 사용자 쿼리가 명시적이라고 가정하며, 다양한 환경 요소와 사용자 선호를 무시하고 있어 계획의 실행 가능성을 제한한다. 여기서는 새로운 데이터셋 RETAIL을 구성하고, 주제 안내 멀티 에이전트 프레임워크 TGMA를 제안하며, TGMA는 기존 모델보다 월등하게 개선된 성과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 자동 여행 계획 능력을 향상시켰지만 실제 요구 사항과 맞지 않아 이를 해결하고자 했다.

Method: RETAIL이라는 새로운 데이터셋을 구성하고 TGMA라는 주제 안내 멀티 에이전트 프레임워크를 제안한다.

Result: 기존 모델은 1.0%의 통과율에 불과하지만 TGMA는 2.72%의 성과 향상을 보여준다.

Conclusion: TGMA는 실제 여행 계획에서 유망한 방향을 제시한다.

Abstract: Although large language models have enhanced automated travel planning
abilities, current systems remain misaligned with real-world scenarios. First,
they assume users provide explicit queries, while in reality requirements are
often implicit. Second, existing solutions ignore diverse environmental factors
and user preferences, limiting the feasibility of plans. Third, systems can
only generate plans with basic POI arrangements, failing to provide all-in-one
plans with rich details. To mitigate these challenges, we construct a novel
dataset \textbf{RETAIL}, which supports decision-making for implicit queries
while covering explicit queries, both with and without revision needs. It also
enables environmental awareness to ensure plan feasibility under real-world
scenarios, while incorporating detailed POI information for all-in-one travel
plans. Furthermore, we propose a topic-guided multi-agent framework, termed
TGMA. Our experiments reveal that even the strongest existing model achieves
merely a 1.0% pass rate, indicating real-world travel planning remains
extremely challenging. In contrast, TGMA demonstrates substantially improved
performance 2.72%, offering promising directions for real-world travel
planning.

</details>


### [23] [DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization](https://arxiv.org/abs/2508.15338)
*Jinning Yang,Wen Shi*

Main category: cs.AI

TL;DR: DiagECG는 심전도 신호를 처리하여 임상 텍스트 생성을 위한 새로운 프레임워크로, 기계 학습 모델이 ECG와 자연어 입력을 통합하여 처리할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 자동화된 ECG 분석 방법들은 다양한 임상 작업에서 일반화에 어려움을 겪고, 개방형 추론에 대한 지원이 제한적이다.

Method: DiagECG는 12개 리드 심전도 신호를 처리하여 언어 모델링과 시간 시계열 모델링을 통합하며, 연속적인 ECG 임베딩을 기호형 토큰으로 분할하는 인코더와 양자화 모듈을 사용한다.

Result: DiagECG는 ECG 질문 응답 및 진단 보고서 생성을 위한 지침 튜닝을 수행하며, 본질적인 모델 수정 없이 다양한 작업에서 강력한 성능을 발휘한다.

Conclusion: 상징적 ECG 표현을 LLM에 통합하여 의료적 추론에 대한 잠재력을 강조한다.

Abstract: Electrocardiography plays a central role in cardiovascular diagnostics, yet
existing automated approaches often struggle to generalize across clinical
tasks and offer limited support for open-ended reasoning. We present DiagECG, a
novel framework that integrates time-series and language modeling by enabling
large language models to process 12-lead ECG signals for clinical text
generation tasks. Our approach discretizes continuous ECG embeddings into
symbolic tokens using a lead-independent encoder and quantization module. These
tokens are then used to extend the vocabulary of LLM, allowing the model to
handle both ECG and natural language inputs in a unified manner. To bridge the
modality gap, we pretrain the model on an autoregressive ECG forecasting task,
enabling the LLM to model temporal dynamics using its native language modeling
capabilities. Finally, we perform instruction tuning on both ECG question
answering and diagnostic report generation. Without modifying the core model,
DiagECG achieves strong performance across tasks while maintaining
generalization to out-of-distribution settings. Extensive experiments
demonstrate the effectiveness of each component and highlight the potential of
integrating symbolic ECG representations into LLMs for medical reasoning.

</details>


### [24] [Planning with Minimal Disruption](https://arxiv.org/abs/2508.15358)
*Alberto Pozanco,Marianela Morales,Daniel Borrajo,Manuela Veloso*

Main category: cs.AI

TL;DR: 이 연구는 목표 달성을 위해 초기 상태를 최소한으로 수정하는 계획인 '계획 중단'의 개념을 소개하고, 이를 최적화하는 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 계획 중단은 초기 상태를 최소한으로 변경하여 목표를 달성하는 데 관심이 있는 다양한 계획 응용 프로그램에서 중요하다.

Method: 여기서 우리는 다양한 계획 기반 컴파일 방법을 정의하고, 행동 비용의 합과 계획 중단을 공동으로 최적화하는 방법을 소개한다.

Result: 여러 벤치마크에서 실험 결과, 재구성된 작업이 효과적으로 해결되어 두 가지 목표를 균형 있게 만족하는 계획을 생성할 수 있음이 입증되었다.

Conclusion: 이 연구는 계획 중단에 대한 개념을 정식화하고, 이에 대한 최적화 방법을 제안하며, 실험을 통해 이를 뒷받침한다.

Abstract: In many planning applications, we might be interested in finding plans that
minimally modify the initial state to achieve the goals. We refer to this
concept as plan disruption. In this paper, we formally introduce it, and define
various planning-based compilations that aim to jointly optimize both the sum
of action costs and plan disruption. Experimental results in different
benchmarks show that the reformulated task can be effectively solved in
practice to generate plans that balance both objectives.

</details>


### [25] [GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO](https://arxiv.org/abs/2508.15432)
*Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델을 위한 고품질 합성 데이터 생성 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 발전은 감독된 정밀 조정(SFT) 및 정렬 작업에 대한 고품질 데이터셋의 가용성에 의존합니다.

Method: 모듈식 및 구성 기반 파이프라인을 사용하여 복잡한 대화 흐름 모델링을 최소한의 수작업 개입으로 수행합니다. 이 프레임워크는 휴리스틱 규칙과 LLM 기반 평가를 결합하여 자동으로 데이터를 필터링하고 점수를 매깁니다.

Result: OASST 형식의 대화에서 추출한 고품질 대화 샘플을 보장하는 데이터셋을 생성합니다.

Conclusion: 이 혁신들은 대규모 합성 대화 데이터 생성 및 관리에 대한 강력한 솔루션을 제공합니다.

Abstract: The advancement of large language models (LLMs) is critically dependent on
the availability of high-quality datasets for Supervised Fine-Tuning (SFT),
alignment tasks like Direct Preference Optimization (DPO), etc. In this work,
we present a comprehensive synthetic data generation framework that facilitates
scalable, configurable, and high-fidelity generation of synthetic data tailored
for these training paradigms. Our approach employs a modular and
configuration-based pipeline capable of modeling complex dialogue flows with
minimal manual intervention. This framework uses a dual-stage quality tagging
mechanism, combining heuristic rules and LLM-based evaluations, to
automatically filter and score data extracted from OASST-formatted
conversations, ensuring the curation of high-quality dialogue samples. The
resulting datasets are structured under a flexible schema supporting both SFT
and DPO use cases, enabling seamless integration into diverse training
workflows. Together, these innovations offer a robust solution for generating
and managing synthetic conversational data at scale, significantly reducing the
overhead of data preparation in LLM training pipelines.

</details>


### [26] [From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence](https://arxiv.org/abs/2508.15447)
*Zihao Wang,Junming Zhang*

Main category: cs.AI

TL;DR: BusiAgent는 복잡한 기업 환경에서 의사결정을 지원하기 위해 LLM을 활용한 새로운 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기업 의사결정 지원 및 전략 기획에서 LLM의 잠재력을 극대화하기 위해.

Method: 동적 에이전트 모델링을 위한 확장된 CTMDP, 협업 효율성을 최적화하는 일반화된 엔트로피 측정, 계층적 의사결정 프로세스를 처리하기 위한 다중 수준의 스타켈버그 게임을 통합하고, 신속한 최적화를 위한 맥락적 탐슨 샘플링을 사용한다.

Result: BusiAgent는 다양한 비즈니스 시나리오에서 그 효능을 입증하며, 고객 중심 솔루션을 생성하고 기존 접근 방식보다 개선된 품질과 사용자 만족도를 보여준다.

Conclusion: BusiAgent는 AI 기반 기업 의사결정을 한 단계 끌어올리며, 복잡한 비즈니스 환경을 보다 효과적으로 탐색할 수 있도록 지원한다.

Abstract: Large Language Models (LLMs) have shown promising potential in business
applications, particularly in enterprise decision support and strategic
planning, yet current approaches often struggle to reconcile intricate
operational analyses with overarching strategic goals across diverse market
environments, leading to fragmented workflows and reduced collaboration across
organizational levels. This paper introduces BusiAgent, a novel multi-agent
framework leveraging LLMs for advanced decision-making in complex corporate
environments. BusiAgent integrates three core innovations: an extended
Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a
generalized entropy measure to optimize collaborative efficiency, and a
multi-level Stackelberg game to handle hierarchical decision processes.
Additionally, contextual Thompson sampling is employed for prompt optimization,
supported by a comprehensive quality assurance system to mitigate errors.
Extensive empirical evaluations across diverse business scenarios validate
BusiAgent's efficacy, demonstrating its capacity to generate coherent,
client-focused solutions that smoothly integrate granular insights with
high-level strategy, significantly outperforming established approaches in both
solution quality and user satisfaction. By fusing cutting-edge AI technologies
with deep business insights, BusiAgent marks a substantial step forward in
AI-driven enterprise decision-making, empowering organizations to navigate
complex business landscapes more effectively.

</details>


### [27] [Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning](https://arxiv.org/abs/2508.15507)
*Yekun Zhu,Guang Chen,Chengjun Mao*

Main category: cs.AI

TL;DR: 본 논문은 복잡한 논리적 추론에서 LLM의 적응적 추론 능력을 향상시키기 위한 'Think in Blocks' 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM의 긴 추론 과정이 과도한 사고와 계산 자원 낭비를 초래할 수 있어, 작업의 복잡성에 따라 동적으로 추론 길이를 조절할 수 있는 방법이 필요함.

Method: 'Think in Blocks' 프레임워크를 통해 추론 과정을 조정할 수 있는 블록 수를 설정하고, 세 단계의 파이프라인을 통해 적응형 모델을 훈련함.

Result: 모델은 문제의 난이도에 따라 추론 깊이를 조절하여, 적응형으로 동작하며 실제 추론 시 블록 수를 이용해 깊이를 동적으로 관리할 수 있음.

Conclusion: 이렇게 함으로써, LLM은 배포 중에 생각의 사슬의 길이를 유연하게 조정할 수 있는 능력을 갖추게 됨.

Abstract: Large Language Models (LLMs) with chains-of-thought have demonstrated strong
performance on an increasing range of tasks, particularly those involving
complex logical reasoning. However, excessively long chains can lead to
overthinking, causing computational waste and slower responses. This raises a
question: can LLMs dynamically adjust the length of their reasoning processes
based on task complexity? To address this, we propose the Think in Blocks
framework, which enables adaptive reasoning-from zero to deep reasoning-by
partitioning the reasoning process into a tunable number of blocks. Our main
contributions are: (1) Establishing an explicit block-structured paradigm in
which the model first predicts an integer reasoning budget-the number of
blocks-and then partitions its reasoning accordingly; (2) Training an adaptive
model through a three-stage pipeline-Supervised Fine-Tuning, reward-guided
Direct Preference Optimization, and Reinforcement Learning-that adjusts its
reasoning depth to problem difficulty; (3) Exploiting the explicit block count
to dynamically control reasoning depth at inference time, allowing flexible
adjustment of chain-of-thought length during deployment.

</details>


### [28] [Super-additive Cooperation in Language Model Agents](https://arxiv.org/abs/2508.15510)
*Filippo Tonini,Lukas Galke*

Main category: cs.AI

TL;DR: 본 연구는 반복적 상호작용과 그룹 간 경쟁이 협력적 행동을 증가시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 자율 인공지능(AI) 에이전트의 가능성에 비추어 그들의 협력적 행동 경향을 연구하는 것이 점점 더 중요해진다.

Method: 언어 모델 에이전트가 팀으로 그룹화되어 죄수의 딜레마 게임에서 서로 대결하는 가상 토너먼트를 설계했다.

Result: 내부 팀 역학과 외부 경쟁을 시뮬레이션하여 전반적인 협력 수준과 초기의 일회성 협력 수준이 모두 크게 증가하는 것을 발견했다.

Conclusion: 이 연구는 대형 언어 모델이 복잡한 사회적 시나리오에서 전략을 세우고 행동하도록 하는 새로운 프레임워크를 제공하며, 그룹 간 경쟁이 반직관적으로 더 협력적인 행동을 가져올 수 있음을 보여준다.

Abstract: With the prospect of autonomous artificial intelligence (AI) agents, studying
their tendency for cooperative behavior becomes an increasingly relevant topic.
This study is inspired by the super-additive cooperation theory, where the
combined effects of repeated interactions and inter-group rivalry have been
argued to be the cause for cooperative tendencies found in humans. We devised a
virtual tournament where language model agents, grouped into teams, face each
other in a Prisoner's Dilemma game. By simulating both internal team dynamics
and external competition, we discovered that this blend substantially boosts
both overall and initial, one-shot cooperation levels (the tendency to
cooperate in one-off interactions). This research provides a novel framework
for large language models to strategize and act in complex social scenarios and
offers evidence for how intergroup competition can, counter-intuitively, result
in more cooperative behavior. These insights are crucial for designing future
multi-agent AI systems that can effectively work together and better align with
human values. Source code is available at
https://github.com/pippot/Superadditive-cooperation-LLMs.

</details>


### [29] [DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks](https://arxiv.org/abs/2508.15548)
*Jiayi Song,Rui Wan,Lipeng Ma,Weidong Yang,Qingyuan Zhou,Yixuan Li,Ben Fei*

Main category: cs.AI

TL;DR: 본 연구는 대규모 언어 모델이 3D 장면에서 복잡한 추론을 수행하는 능력을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 최근 연구는 대규모 언어 모델을 통한 도구 사용을 호출하여 3D 위치 기반 추론 작업을 다루었습니다.

Method: DeepThink3D라는 새로운 접근법을 도입하여 SQA3D 벤치마크에서 더 복잡한 질문을 생성하는 조합적이고 반복적인 진화 접근법을 제안합니다.

Result: 복잡한 3D 도구 사용을 더 능숙하게 만드는 데 대규모 언어 모델을 미세 조정하고, Direct Preference Optimization(DPO)을 통해 도구 체인 전략을 직접 최적화합니다.

Conclusion: 이 과정을 통해 우리는 복잡한 작업에서의 정확성을 향상시킬 수 있습니다.

Abstract: This work enhances the ability of large language models (LLMs) to perform
complex reasoning in 3D scenes. Recent work has addressed the 3D situated
reasoning task by invoking tool usage through large language models. Large
language models call tools via APIs and integrate the generated programs
through a chain of thought to solve problems based on the program results.
However, due to the simplicity of the questions in the dataset, the generated
program reasoning chains are relatively short. To solve this main challenge, in
this paper, we introduce DeepThink3D to enhance the tool usage of LLMs in
complex 3D situated reasoning tasks. Our work proposes a combinatorial and
iterative evolutionary approach on the SQA3D benchmark to generate more complex
questions. Building on this foundation, we fine-tune the large language model
to make it more proficient in using 3D tools. By employing Direct Preference
Optimization (DPO), we directly optimize the toolchain strategies generated by
models, thereby enhancing their accuracy in complex tasks.

</details>


### [30] [A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification](https://arxiv.org/abs/2508.15588)
*Ahmed Nasir,Abdelhafid Zenati*

Main category: cs.AI

TL;DR: 이 논문은 강화학습이 안전 중요 시스템에 적용될 때의 안전성과 견고성을 검증하는 포괄적인 틀을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 강화학습이 안전 중요 시스템에 적용될 때, 학습된 정책의 견고성과 안전성을 검증할 수 있는 공식적인 방법이 부족합니다.

Method: 이 연구는 RL 에이전트와 환경의 결합을 이산 시간 자율 역학 시스템으로 분석하는 새로운 프레임워크를 소개하며, FTLE 이론을 활용하여 LCS를 시각화합니다.

Result: 실험을 통해, 이 프레임워크가 정책 행동에 대한 포괄적이고 해석 가능한 평가를 제공하며, 보상만으로 성공적인 정책처럼 보이는 것의 비판적 결함을 식별함을 보여줍니다.

Conclusion: 정량적 메트릭과 지역 안정성 보장 방법을 도입하여, 모델 불확실성을 처리할 수 있도록 분석을 확장합니다.

Abstract: The application of reinforcement learning to safety-critical systems is
limited by the lack of formal methods for verifying the robustness and safety
of learned policies. This paper introduces a novel framework that addresses
this gap by analyzing the combination of an RL agent and its environment as a
discrete-time autonomous dynamical system. By leveraging tools from dynamical
systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we
identify and visualize Lagrangian Coherent Structures (LCS) that act as the
hidden "skeleton" governing the system's behavior. We demonstrate that
repelling LCS function as safety barriers around unsafe regions, while
attracting LCS reveal the system's convergence properties and potential failure
modes, such as unintended "trap" states. To move beyond qualitative
visualization, we introduce a suite of quantitative metrics, Mean Boundary
Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and
Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a
policy's safety margin and robustness. We further provide a method for deriving
local stability guarantees and extend the analysis to handle model uncertainty.
Through experiments in both discrete and continuous control environments, we
show that this framework provides a comprehensive and interpretable assessment
of policy behavior, successfully identifying critical flaws in policies that
appear successful based on reward alone.

</details>


### [31] [Transduction is All You Need for Structured Data Workflows](https://arxiv.org/abs/2508.15610)
*Alfio Gliozzo,Naweed Khan,Christodoulos Constantinides,Nandana Mihindukulasooriya,Nahuel Defosse,Junkyu Lee*

Main category: cs.AI

TL;DR: 이 논문은 복잡한 데이터를 처리할 수 있는 모듈형 에이전트 기반 시스템을 구축하기 위한 Agentics 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: Agentics는 데이터 및 AI 워크플로우를 다루는 새로운 관점을 제공하기 위해 개발되었습니다.

Method: 이 프레임워크에서는 에이전트가 논리적 흐름에서 추상화되어 데이터 유형 내부에서 사용되며, 데이터 간의 논리적 변환을 가능하게 합니다.

Result: 이 프레임워크는 도메인 특정의 다중 선택 질문 응답, 텍스트-투-SQL의 의미 분석, 자동 프롬프트 최적화 작업에 걸쳐 적용 가능성을 입증하는 실증적 증거를 제공합니다.

Conclusion: 이 작업은 성능을 해치지 않으면서 최첨단 정확도 또는 향상된 확장성을 달성합니다.

Abstract: This paper introduces Agentics, a modular framework for building agent-based
systems capable of structured reasoning and compositional generalization over
complex data. Designed with research and practical applications in mind,
Agentics offers a novel perspective on working with data and AI workflows. In
this framework, agents are abstracted from the logical flow and they are used
internally to the data type to enable logical transduction among data. Agentics
encourages AI developers to focus on modeling data rather than crafting
prompts, enabling a declarative language in which data types are provided by
LLMs and composed through logical transduction, which is executed by LLMs when
types are connected. We provide empirical evidence demonstrating the
applicability of this framework across domain-specific multiple-choice question
answering, semantic parsing for text-to-SQL, and automated prompt optimization
tasks, achieving state-of-the-art accuracy or improved scalability without
sacrificing performance. The open-source implementation is available at
\texttt{https://github.com/IBM/agentics}.

</details>


### [32] [Adapting A Vector-Symbolic Memory for Lisp ACT-R](https://arxiv.org/abs/2508.15630)
*Meera Ray,Christopher L. Dancy*

Main category: cs.AI

TL;DR: HDM은 ACT-R의 선언적 기억 시스템을 대체하는 벡터-상징적 시스템으로, 기존 ACT-R 모델과의 호환성을 유지하면서 벡터 기반 기능을 개발하고, 대형 문서를 ACT-R 메모리에 추가하며, 벡터 표현만으로 메모리 청크를 검색할 수 있는 새로운 메커니즘을 만들어냈습니다.


<details>
  <summary>Details</summary>
Motivation: HDM은 ACT-R의 DM 시스템에 비해 확장성과 아키텍처적으로 정의된 유사성을 제공하는 대안으로 제안되었습니다.

Method: HDM을 Lisp ACT-R의 구현에 적응시켜, 기존 ACT-R 모델이 큰 변형 없이도 HDM과 함께 작동할 수 있도록 했습니다.

Result: 벡터 기반의 ACT-R 기능 버전을 개발하고, 대형 문서의 내용을 ACT-R 메모리에 추가하는 텍스트 처리 파이프라인을 설정했으며, 벡터 표현만을 사용하여 메모리 청크를 검색하는 새로운 메커니즘을 만들었습니다.

Conclusion: HDM의 벡터-상징적 장점을 유지하면서도 기존 ACT-R 모델이 시스템과 거의 변경 없이 작동할 수 있도록 확장할 수 있음을 보여주었습니다. 앞으로도 기억 재구성을 개선하기 위한 벡터의 시간-맥락 표현을 탐색할 계획입니다.

Abstract: Holographic Declarative Memory (HDM) is a vector-symbolic alternative to
ACT-R's Declarative Memory (DM) system that can bring advantages such as
scalability and architecturally defined similarity between DM chunks. We
adapted HDM to work with the most comprehensive and widely-used implementation
of ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with
HDM without major changes. With this adaptation of HDM, we have developed
vector-based versions of common ACT-R functions, set up a text processing
pipeline to add the contents of large documents to ACT-R memory, and most
significantly created a useful and novel mechanism to retrieve an entire chunk
of memory based on a request using only vector representations of tokens.
Preliminary results indicate that we can maintain vector-symbolic advantages of
HDM (e.g., chunk recall without storing the actual chunk and other advantages
with scaling) while also extending it so that previous ACT-R models may work
with the system with little (or potentially no) modifications within the actual
procedural and declarative memory portions of a model. As a part of iterative
improvement of this newly translated holographic declarative memory module, we
will continue to explore better time-context representations for vectors to
improve the module's ability to reconstruct chunks during recall. To more fully
test this translated HDM module, we also plan to develop decision-making models
that use instance-based learning (IBL) theory, which is a useful application of
HDM given the advantages of the system.

</details>


### [33] [Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle](https://arxiv.org/abs/2508.15680)
*Mark Cote,Susana Aires*

Main category: cs.AI

TL;DR: 이 논문은 EU AI 법안의 기술 철학적 해석이 AI 시스템의 데이터 장기 역학에 대한 통찰을 제공한다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: AI의 책임 있는 운영을 위한 기존 프레임워크에 도전하는 순환 가치 사슬을 생성하는 데이터의 전 과정 이해를 목표로 한다.

Method: AI 파이프라인을 구성하는 데이터를 비롯한 개념적 도구를 소개하고, 규제의 맹점을 기술적으로 기반하고 철학적으로 일관되게 분석한다.

Result: AI의 기술적 운영 및 경제적 논리를 뒷받침하는 역동성을 명확히 하는 것이 정책 입안에서 결여되어 있음을 주장한다.

Conclusion: 효과적인 규제는 이러한 인프라와 시간적 역학을 다루어야 하며, 순환 감사 및 피드백 책임 등 여러 조치를 제안한다.

Abstract: This paper argues that a techno-philosophical reading of the EU AI Act
provides insight into the long-term dynamics of data in AI systems,
specifically, how the lifecycle from ingestion to deployment generates
recursive value chains that challenge existing frameworks for Responsible AI.
We introduce a conceptual tool to frame the AI pipeline, spanning data,
training regimes, architectures, feature stores, and transfer learning. Using
cross-disciplinary methods, we develop a technically grounded and
philosophically coherent analysis of regulatory blind spots. Our central claim
is that what remains absent from policymaking is an account of the dynamic of
becoming that underpins both the technical operation and economic logic of AI.
To address this, we advance a formal reading of AI inspired by Simondonian
philosophy of technology, reworking his concept of individuation to model the
AI lifecycle, including the pre-individual milieu, individuation, and
individuated AI. To translate these ideas, we introduce futurity: the
self-reinforcing lifecycle of AI, where more data enhances performance, deepens
personalisation, and expands application domains. Futurity highlights the
recursively generative, non-rivalrous nature of data, underpinned by
infrastructures like feature stores that enable feedback, adaptation, and
temporal recursion. Our intervention foregrounds escalating power asymmetries,
particularly the tech oligarchy whose infrastructures of capture, training, and
deployment concentrate value and decision-making. We argue that effective
regulation must address these infrastructural and temporal dynamics, and
propose measures including lifecycle audits, temporal traceability, feedback
accountability, recursion transparency, and a right to contest recursive reuse.

</details>


### [34] [GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning](https://arxiv.org/abs/2508.15690)
*Abhigya Verma,Sriram Puttagunta,Seganrasan Subramanian,Sravan Ramachandran*

Main category: cs.AI

TL;DR: GRAFT는 지시 따르기, 시각적 추론 및 시각-텍스트 정렬 작업을 평가하기 위한 구조화된 다중 양식 벤치마크이다.


<details>
  <summary>Details</summary>
Motivation: 모델의 성능을 다각도로 평가하고, 구체적이고 표준화된 기준을 제공하기 위해 GRAFT를 개발하였다.

Method: Python 시각화 라이브러리를 사용하여 생성된 차트 및 테이블과 시각적 콘텐츠에 기초한 다단계 분석 질문을 쌍으로 제공한다.

Result: 일관된 평가를 지원하는 JSON 또는 YAML 형식으로 구조화된 답변을 제공하며, 다양한 추론 유형을 포함하는 세분화된 평가를 가능하게 한다.

Conclusion: GRAFT는 다중 양식 모델의 시각적 기초 구조 추론 작업에 대한 미세한 벤치마킹을 위한 통합된 확장 가능 프레임워크를 제공하며, 이 분야에서 새로운 평가 기준을 설정한다.

Abstract: GRAFT is a structured multimodal benchmark for evaluating models on
instruction-following, visual reasoning, and visual-textual alignment tasks. It
features programmatically generated charts and synthetically rendered tables,
created with Python visualization libraries to ensure control over data
semantics, structure, and clarity. Each GRAFT instance pairs a chart or table
image with a systematically generated, multi-step analytical question based
solely on visual content. Answers are provided in structured formats such as
JSON or YAML, supporting consistent evaluation of both reasoning and output
format. The benchmark introduces a taxonomy of reasoning types including
comparison, trend identification, ranking, aggregation, proportion estimation,
and anomaly detection to enable comprehensive assessment. Reference answers
follow strict factual and formatting guidelines for precise, aspect-based
evaluation. GRAFT offers a unified, scalable framework for fine-grained
benchmarking of multimodal models on visually grounded, structured reasoning
tasks, setting a new evaluation standard in this field.

</details>


### [35] [NiceWebRL: a Python library for human subject experiments with reinforcement learning environments](https://arxiv.org/abs/2508.15693)
*Wilka Carvalho,Vikram Goddla,Ishaan Sinha,Hoon Shin,Kunal Jha*

Main category: cs.AI

TL;DR: NiceWebRL은 온라인 인간 주체 실험을 위한 강화 학습 환경을 제공하는 연구 도구이다.


<details>
  <summary>Details</summary>
Motivation: AI 연구자들이 알고리즘을 인간 성과와 비교하고, 인지 과학자들이 ML 알고리즘을 인간 인지에 대한 이론으로 시험할 수 있도록 지원하기 위해 개발되었다.

Method: 모든 Jax 기반 환경을 온라인 인터페이스로 변환하고, 단일 에이전트와 다중 에이전트 환경을 모두 지원하는 Python 라이브러리이다.

Result: 3가지 사례 연구를 통해 Human-like AI, Human-compatible AI, Human-assistive AI 개발에 기여할 수 있는 잠재력을 입증하였다.

Conclusion: NiceWebRL은 ML 연구자들을 위한 다양한 연구 가능성을 제공하며, 관심 있는 사람들은 GitHub에서 라이브러리를 확인할 수 있다.

Abstract: We present NiceWebRL, a research tool that enables researchers to use machine
reinforcement learning (RL) environments for online human subject experiments.
NiceWebRL is a Python library that allows any Jax-based environment to be
transformed into an online interface, supporting both single-agent and
multi-agent environments. As such, NiceWebRL enables AI researchers to compare
their algorithms to human performance, cognitive scientists to test ML
algorithms as theories for human cognition, and multi-agent researchers to
develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3
case studies that demonstrate its potential to help develop Human-like AI,
Human-compatible AI, and Human-assistive AI. In the first case study
(Human-like AI), NiceWebRL enables the development of a novel RL model of
cognition. Here, NiceWebRL facilitates testing this model against human
participants in both a grid world and Craftax, a 2D Minecraft domain. In our
second case study (Human-compatible AI), NiceWebRL enables the development of a
novel multi-agent RL algorithm that can generalize to human partners in the
Overcooked domain. Finally, in our third case study (Human-assistive AI), we
show how NiceWebRL can allow researchers to study how an LLM can assist humans
on complex tasks in XLand-Minigrid, an environment with millions of
hierarchical tasks. The library is available at
https://github.com/KempnerInstitute/nicewebrl.

</details>


### [36] [Measuring the environmental impact of delivering AI at Google Scale](https://arxiv.org/abs/2508.15734)
*Cooper Elsworth,Keguo Huang,David Patterson,Ian Schneider,Robert Sedivy,Savannah Goodman,Ben Townsend,Parthasarathy Ranganathan,Jeff Dean,Amin Vahdat,Ben Gomes,James Manyika*

Main category: cs.AI

TL;DR: AI 제공의 환경 영향을 측정하는 방법론을 제안하고, 대규모 AI 생산 환경에서 에너지 사용, 탄소 배출 및 물 소비를 평가한 결과, 제미니 AI 앱의 중간 텍스트 프롬프트는 0.24Wh의 에너지를 소비하며, 기술적 효율성과 청정 에너지 조달 덕분에 에너지 사용이 33배 줄어들었다고 보고함.


<details>
  <summary>Details</summary>
Motivation: AI의 사용자 채택이 증가함에 따라, AI 제공의 환경 영향을 이해하고 완화할 필요성이 커지고 있다.

Method: 대규모 AI 생산 환경에서 AI 추론 작업 부하의 에너지 사용, 탄소 배출 및 물 소비를 측정하기 위한 포괄적인 방법론을 제안하고 실행하였다.

Result: 제미니 AI 앱의 중간 텍스트 프롬프트는 0.24Wh의 에너지를 소비하며, 이를 통해 1년 동안 에너지 소비가 33배 감소했음을 확인하였다.

Conclusion: AI 제공의 환경 영향을 줄이는 데 지속적인 관심이 필요하며, AI 제공의 환경 지표를 포괄적으로 측정하는 것이 중요함을 강조한다.

Abstract: The transformative power of AI is undeniable - but as user adoption
accelerates, so does the need to understand and mitigate the environmental
impact of AI serving. However, no studies have measured AI serving
environmental metrics in a production environment. This paper addresses this
gap by proposing and executing a comprehensive methodology for measuring the
energy usage, carbon emissions, and water consumption of AI inference workloads
in a large-scale, AI production environment. Our approach accounts for the full
stack of AI serving infrastructure - including active AI accelerator power,
host system energy, idle machine capacity, and data center energy overhead.
Through detailed instrumentation of Google's AI infrastructure for serving the
Gemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24
Wh of energy - a figure substantially lower than many public estimates. We also
show that Google's software efficiency efforts and clean energy procurement
have driven a 33x reduction in energy consumption and a 44x reduction in carbon
footprint for the median Gemini Apps text prompt over one year. We identify
that the median Gemini Apps text prompt uses less energy than watching nine
seconds of television (0.24 Wh) and consumes the equivalent of five drops of
water (0.26 mL). While these impacts are low compared to other daily
activities, reducing the environmental impact of AI serving continues to
warrant important attention. Towards this objective, we propose that a
comprehensive measurement of AI serving environmental metrics is critical for
accurately comparing models, and to properly incentivize efficiency gains
across the full AI serving stack.

</details>


### [37] [Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots](https://arxiv.org/abs/2508.15748)
*Emma Rath,Stuart Armstrong,Rebecca Gorman*

Main category: cs.AI

TL;DR: AI 에이전트와의 패러소셜 관계 발전은 인간의 웰빙에 심각한 영향을 미치며, 이를 방지하는 것은 어렵다. 본 연구는 패러소셜 신호를 실시간으로 평가하는 응답 평가 프레임워크를 도입하여 이 문제를 해결하고자 하였다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트와의 패러소셜 관계 발전이 인간의 웰빙에 중요한 영향을 미치기 때문에 이를 식별하고 예방하는 방법이 필요하다.

Method: 최신 언어 모델을 활용하여 패러소셜 신호를 실시간으로 평가하는 간단한 응답 평가 프레임워크를 제안하였다.

Result: 소규모 합성 데이터셋에서의 반복 평가를 통해 모든 패러소셜 대화를 성공적으로 식별하였고, 허용 가능한 통일성 규칙 하에서 허위 긍정 결과를 피할 수 있었다.

Conclusion: 평가 에이전트가 패러소셜 관계 예방을 위한 실질적인 솔루션을 제공할 수 있다는 초기 증거를 제시하였다.

Abstract: The development of parasocial relationships with AI agents has severe, and in
some cases, tragic effects for human well-being. Yet preventing such dynamics
is challenging: parasocial cues often emerge gradually in private
conversations, and not all forms of emotional engagement are inherently
harmful. We address this challenge by introducing a simple response evaluation
framework, created by repurposing a state-of-the-art language model, that
evaluates ongoing conversations for parasocial cues in real time. To test the
feasibility of this approach, we constructed a small synthetic dataset of
thirty dialogues spanning parasocial, sycophantic, and neutral conversations.
Iterative evaluation with five stage testing successfully identified all
parasocial conversations while avoiding false positives under a tolerant
unanimity rule, with detection typically occurring within the first few
exchanges. These findings provide preliminary evidence that evaluation agents
can provide a viable solution for the prevention of parasocial relations.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [38] [MCPTox: A Benchmark for Tool Poisoning Attack on Real-World MCP Servers](https://arxiv.org/abs/2508.14925)
*Zhiqiang Wang,Yichao Gao,Yanting Wang,Suyuan Liu,Haifeng Sun,Haoran Cheng,Guanquan Shi,Haohua Du,Xiangyang Li*

Main category: cs.CR

TL;DR: MCP(Micro Context Protocol)는 LLM 에이전트가 외부 도구와 상호 작용하기 위해 표준화된 인터페이스를 제공하며, 이는 현대 자율 에이전트 생태계의 중요한 요소가 되고 있다. 그러나 신뢰할 수 없는 외부 도구로 인해 새로운 공격 표면이 발생한다. 본 연구는 이전 연구들이 외부 도구의 출력으로 인해 발생하는 공격에 중점을 두었던 것이 아닌, 도구 메타데이터에 악의적인 지침이 삽입되는 '도구 오염'이라는 근본적인 취약점을 조사한다.


<details>
  <summary>Details</summary>
Motivation: MCP의 발전에 따라, 외부 도구에서 발생하는 공격 표면을 평가하고 악의적인 지침을 도구 메타데이터에 삽입하는 취약성을 이해할 필요가 있다.

Method: MCPTox를 통해 MCP 설정 하에서 도구 오염에 대한 에이전트의 강인성을 체계적으로 평가할 수 있는 첫 번째 벤치마크를 소개한다. 45개의 실시간 MCP 서버와 353개의 실제 도구를 기반으로 하여, 3개의 공격 템플릿을 설계하고 몇-shot 학습을 통해 1312개의 악의적인 테스트 사례를 생성한다.

Result: 20개의 주요 LLM 에이전트를 평가한 결과, o1-mini는 72.8%의 공격 성공률을 기록했으며, 더 능력 있는 모델일수록 이 공격에 더 취약했다.

Conclusion: 기존의 안전 정렬이 합법적인 도구를 사용한 악의적인 행동에 대해 효과적이지 않음을 보여준다. 이를 통해, 도구 오염에 대한 관리 및 이해를 위한 중요한 경험적 기준을 마련하며, verifiably safer AI agents의 개발을 위한 MCPTox를 출시한다.

Abstract: By providing a standardized interface for LLM agents to interact with
external tools, the Model Context Protocol (MCP) is quickly becoming a
cornerstone of the modern autonomous agent ecosystem. However, it creates novel
attack surfaces due to untrusted external tools. While prior work has focused
on attacks injected through external tool outputs, we investigate a more
fundamental vulnerability: Tool Poisoning, where malicious instructions are
embedded within a tool's metadata without execution. To date, this threat has
been primarily demonstrated through isolated cases, lacking a systematic,
large-scale evaluation.
  We introduce MCPTox, the first benchmark to systematically evaluate agent
robustness against Tool Poisoning in realistic MCP settings. MCPTox is
constructed upon 45 live, real-world MCP servers and 353 authentic tools. To
achieve this, we design three distinct attack templates to generate a
comprehensive suite of 1312 malicious test cases by few-shot learning, covering
10 categories of potential risks. Our evaluation on 20 prominent LLM agents
setting reveals a widespread vulnerability to Tool Poisoning, with o1-mini,
achieving an attack success rate of 72.8\%. We find that more capable models
are often more susceptible, as the attack exploits their superior
instruction-following abilities. Finally, the failure case analysis reveals
that agents rarely refuse these attacks, with the highest refused rate
(Claude-3.7-Sonnet) less than 3\%, demonstrating that existing safety alignment
is ineffective against malicious actions that use legitimate tools for
unauthorized operation. Our findings create a crucial empirical baseline for
understanding and mitigating this widespread threat, and we release MCPTox for
the development of verifiably safer AI agents. Our dataset is available at an
anonymized repository: \textit{https://anonymous.4open.science/r/AAAI26-7C02}.

</details>


### [39] [A Systematic Survey of Model Extraction Attacks and Defenses: State-of-the-Art and Perspectives](https://arxiv.org/abs/2508.15031)
*Kaixiang Zhao,Lincan Li,Kaize Ding,Neil Zhenqiang Gong,Yue Zhao,Yushun Dong*

Main category: cs.CR

TL;DR: MLaaS 플랫폼의 접근성은 고급 ML 기능의 사용을 촉진하지만, 모델 추출 공격을 통한 취약성을 초래한다.


<details>
  <summary>Details</summary>
Motivation: ML 모델은 여러 분야에서 발전을 주도하고 있지만, 복잡성과 전문성이 채택을 제한해왔다.

Method: 본 논문은 MEA와 방어 전략에 대한 포괄적인 조사를 제공하고 새로운 분류 체계를 제안한다.

Result: 우리는 다양한 공격 기법을 분석하고, 기존 방어가 직면한 주요 과제를 강조한다.

Conclusion: 이 체계적인 조사는 AI 보안과 프라이버시 관련 연구자 및 정책 입안자에게 유용한 참고자료 역할을 한다.

Abstract: Machine learning (ML) models have significantly grown in complexity and
utility, driving advances across multiple domains. However, substantial
computational resources and specialized expertise have historically restricted
their wide adoption. Machine-Learning-as-a-Service (MLaaS) platforms have
addressed these barriers by providing scalable, convenient, and affordable
access to sophisticated ML models through user-friendly APIs. While this
accessibility promotes widespread use of advanced ML capabilities, it also
introduces vulnerabilities exploited through Model Extraction Attacks (MEAs).
Recent studies have demonstrated that adversaries can systematically replicate
a target model's functionality by interacting with publicly exposed interfaces,
posing threats to intellectual property, privacy, and system security. In this
paper, we offer a comprehensive survey of MEAs and corresponding defense
strategies. We propose a novel taxonomy that classifies MEAs according to
attack mechanisms, defense approaches, and computing environments. Our analysis
covers various attack techniques, evaluates their effectiveness, and highlights
challenges faced by existing defenses, particularly the critical trade-off
between preserving model utility and ensuring security. We further assess MEAs
within different computing paradigms and discuss their technical, ethical,
legal, and societal implications, along with promising directions for future
research. This systematic survey aims to serve as a valuable reference for
researchers, practitioners, and policymakers engaged in AI security and
privacy. Additionally, we maintain an online repository continuously updated
with related literature at https://github.com/kzhao5/ModelExtractionPapers.

</details>


### [40] [MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs](https://arxiv.org/abs/2508.15036)
*Ruyi Ding,Tianhong Xu,Xinyi Shen,Aidong Adam Ding,Yunsi Fei*

Main category: cs.CR

TL;DR: Mixture of Experts(MoE) 아키텍처의 보안 취약점을 분석하고, 사용자 개인 정보를 보호하기 위한 공격 방안을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI 성능 향상을 위한 MoE 아키텍처의 구현 효율성은 중요한 도전 과제이며, 사용자 개인 정보 보호를 위한 새로운 위협이 부각되고 있다.

Method: MoEcho라는 새로운 공격 방식을 제안하며, MoE 시스템의 다양한 플랫폼에서 몇 가지 새로운 아키텍처적 사이드 채널을 도입한다.

Result: MoEcho는 MoE 아키텍처를 이용한 대규모 언어 모델(LLM) 및 비주얼 언어 모델(VLM)에서 사용자 개인 정보를 침해하는 네 가지 공격 방법을 제안한다.

Conclusion: MoEcho는 현대 변압기에서 MoE 구조의 첫 번째 런타임 아키텍처 수준 보안 분석을 제공하며, 효과적인 개인 정보 보호 조치를 촉구한다.

Abstract: The transformer architecture has become a cornerstone of modern AI, fueling
remarkable progress across applications in natural language processing,
computer vision, and multimodal learning. As these models continue to scale
explosively for performance, implementation efficiency remains a critical
challenge. Mixture of Experts (MoE) architectures, selectively activating
specialized subnetworks (experts), offer a unique balance between model
accuracy and computational cost. However, the adaptive routing in MoE
architectures, where input tokens are dynamically directed to specialized
experts based on their semantic meaning inadvertently opens up a new attack
surface for privacy breaches. These input-dependent activation patterns leave
distinctive temporal and spatial traces in hardware execution, which
adversaries could exploit to deduce sensitive user data. In this work, we
propose MoEcho, discovering a side channel analysis based attack surface that
compromises user privacy on MoE based systems. Specifically, in MoEcho, we
introduce four novel architectural side channels on different computing
platforms, including Cache Occupancy Channels and Pageout+Reload on CPUs, and
Performance Counter and TLB Evict+Reload on GPUs, respectively. Exploiting
these vulnerabilities, we propose four attacks that effectively breach user
privacy in large language models (LLMs) and vision language models (VLMs) based
on MoE architectures: Prompt Inference Attack, Response Reconstruction Attack,
Visual Inference Attack, and Visual Reconstruction Attack. MoEcho is the first
runtime architecture level security analysis of the popular MoE structure
common in modern transformers, highlighting a serious security and privacy
threat and calling for effective and timely safeguards when harnessing MoE
based models for developing efficient large scale AI services.

</details>


### [41] [When Machine Learning Meets Vulnerability Discovery: Challenges and Lessons Learned](https://arxiv.org/abs/2508.15042)
*Sima Arasteh,Christophe Hauser*

Main category: cs.CR

TL;DR: 누적된 머신러닝 기반 소프트웨어 취약점 탐지의 도전과제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 취약점 탐지에서 머신러닝이 지닌 잠재력과 그에 따른 새로운 도전과제를 탐구한다.

Method: 두 개의 이전 연구인 Bin2vec과 BinHunter의 통찰을 제공하여 향후 연구를 지원한다.

Result: 머신러닝을 활용한 취약점 탐지의 효과성에 대한 문제점을 분석하고, 기존 접근방식에 대한 평가의 부족함을 지적한다.

Conclusion: 머신러닝 기반 취약점 탐지의 개선을 위한 미래 연구 방향을 제시한다.

Abstract: In recent years, machine learning has demonstrated impressive results in
various fields, including software vulnerability detection. Nonetheless, using
machine learning to identify software vulnerabilities presents new challenges,
especially regarding the scale of data involved, which was not a factor in
traditional methods. Consequently, in spite of the rise of new
machine-learning-based approaches in that space, important shortcomings persist
regarding their evaluation. First, researchers often fail to provide concrete
statistics about their training datasets, such as the number of samples for
each type of vulnerability. Moreover, many methods rely on training with
semantically similar functions rather than directly on vulnerable programs.
This leads to uncertainty about the suitability of the datasets currently used
for training. Secondly, the choice of a model and the level of granularity at
which models are trained also affect the effectiveness of such vulnerability
discovery approaches.
  In this paper, we explore the challenges of applying machine learning to
vulnerability discovery. We also share insights from our two previous research
papers, Bin2vec and BinHunter, which could enhance future research in this
field.

</details>


### [42] [Tighter Privacy Analysis for Truncated Poisson Sampling](https://arxiv.org/abs/2508.15089)
*Arun Ganesh*

Main category: cs.CR

TL;DR: 이 논문은 주어진 최대 배치 크기를 초과하는 경우 배치를 잘라내는 포아송 샘플링 변형인 잘린 포아송 샘플링에 대한 새로운 프라이버시 증폭 분석을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 잘린 포아송 샘플링의 프라이버시 증폭을 연구하여, 최대 배치 크기를 초과하지 않도록 처리하는 방법을 제시하기 위해서입니다.

Method: 잘린 포아송 샘플링의 특성을 분석하고, 이에 따른 프라이버시 증폭 메커니즘을 정의합니다.

Result: 새로운 분석을 통해 잘린 포아송 샘플링의 프라이버시 증폭의 성능을 향상시킬 수 있음을 발견했습니다.

Conclusion: 잘린 포아송 샘플링의 프라이버시 증폭 분석이 향후 연구 및 응용에 기여할 수 있음을 시사합니다.

Abstract: We give a new privacy amplification analysis for truncated Poisson sampling,
a Poisson sampling variant that truncates a batch if it exceeds a given maximum
batch size.

</details>


### [43] [Adaptive Anomaly Detection in Evolving Network Environments](https://arxiv.org/abs/2508.15100)
*Ehssan Mousavipour,Andrey Dimanchev,Majid Ghaderi*

Main category: cs.CR

TL;DR: NetSight는 온라인 방식으로 분포 변화를 감지하고 적응하는 감독되는 이상 탐지 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 분포 변경은 데이터의 통계적 속성이 시간에 따라 변하는 것을 의미하며, 이는 심층 학습 이상 탐지 시스템에 중대한 도전 과제가 됩니다.

Method: NetSight는 수동 개입을 제거하는 새로운 준 레이블링 기법과 재앙적 망각을 방지하는 지식 증류 기반 적응 전략을 사용합니다.

Result: 세 가지 장기 네트워크 데이터 세트에서 평가된 NetSight는 수동 레이블링에 의존하는 최첨단 방법들보다 우수한 적응 성능을 보여주었습니다.

Conclusion: 이것은 시간이 지남에 따라 분포 변경을 경험하는 동적 네트워크에서의 강력함과 효과성을 입증합니다.

Abstract: Distribution shift, a change in the statistical properties of data over time,
poses a critical challenge for deep learning anomaly detection systems.
Existing anomaly detection systems often struggle to adapt to these shifts.
Specifically, systems based on supervised learning require costly manual
labeling, while those based on unsupervised learning rely on clean data, which
is difficult to obtain, for shift adaptation. Both of these requirements are
challenging to meet in practice. In this paper, we introduce NetSight, a
framework for supervised anomaly detection in network data that continually
detects and adapts to distribution shifts in an online manner. NetSight
eliminates manual intervention through a novel pseudo-labeling technique and
uses a knowledge distillation-based adaptation strategy to prevent catastrophic
forgetting. Evaluated on three long-term network datasets, NetSight
demonstrates superior adaptation performance compared to state-of-the-art
methods that rely on manual labeling, achieving F1-score improvements of up to
11.72%. This proves its robustness and effectiveness in dynamic networks that
experience distribution shifts over time.

</details>


### [44] [Conditional Cube Attack on Round-Reduced ASCON](https://arxiv.org/abs/2508.15172)
*Zheng Li,Xiaoyang Dong,Xiaoyun Wang*

Main category: cs.CR

TL;DR: 이 논문은 큐브 유사 방법에 대한 인증된 암호화 Ascon의 보안 수준을 평가합니다.


<details>
  <summary>Details</summary>
Motivation: Ascon이 CAESAR 경진대회 3차 라운드에서 살아남은 16개 후보 중 하나라는 점에서 Ascon의 보안성 평가의 필요성이 있다.

Method: Huang et al.에 의해 제안된 조건부 큐브 공격을 일반화하고, 키 비트 조건에 따라 새로운 큐브를 찾아낸다.

Result: 이전의 이론적 6라운드 공격을 $2^{66}$ 시간 복잡도에서 $2^{40}$으로 실제 공격으로 변환하고, 최초의 7라운드 키 복구 공격을 제안한다.

Conclusion: 이 공격은 전체 12라운드 Ascon에는 위협이 되지 않으며, 약한 키 집합을 대상으로 한 공격은 더 효율적이다.

Abstract: This paper evaluates the secure level of authenticated encryption
\textsc{Ascon} against cube-like method. \textsc{Ascon} submitted by Dobraunig
\emph{et~al.} is one of 16 survivors of the 3rd round CAESAR competition. The
cube-like method is first used by Dinur \emph{et~al.} to analyze Keccak keyed
modes. At CT-RSA 2015, Dobraunig \emph{et~al.} applied this method to 5/6-round
reduced \textsc{Ascon}, whose structure is similar to Keccak keyed modes.
However, for \textsc{Ascon} the non-linear layer is more complex and state is
much smaller, which make it hard for the attackers to select enough cube
variables that do not multiply with each other after the first round. This
seems to be the reason why the best previous key-recovery attack is on 6-round
\textsc{Ascon}, while for Keccak keyed modes (Keccak-MAC and Keyak) the
attacked round is no less than 7-round.
  In this paper, we generalize the conditional cube attack proposed by Huang
\emph{et~al.}, and find new cubes depending on some key bit conditions for
5/6-round reduced \textsc{Ascon}, and translate the previous theoretic 6-round
attack with $2^{66}$ time complexity to a practical one with $2^{40}$ time
complexity. Moreover, we propose the first 7-round key-recovery attack on
\textsc{Ascon}. By introducing \emph{the cube-like key-subset technique}, we
divide the full key space into many subsets according to different key
conditions. For each key subset, we launch the cube tester to determine if the
key falls into it. Finally, we recover the full key space by testing all the
key subsets. The total time complexity is about $2^{103.9}$. In addition, for a
weak-key subset, whose size is $2^{117}$, the attack is more efficient and
costs only $2^{77}$ time complexity. Those attacks do not threaten the full
round (12 rounds) \textsc{Ascon}.

</details>


### [45] [Private Hyperparameter Tuning with Ex-Post Guarantee](https://arxiv.org/abs/2508.15183)
*Badih Ghazi,Pritish Kamath,Alexander Knop,Ravi Kumar,Pasin Manurangsi,Chiyuan Zhang*

Main category: cs.CR

TL;DR: 본 연구는 "유용성 우선" 관점에서 차별적 프라이버시(DP)의 결과를 일반화하였으며, 프라이버시 비용을 최소화하면서 목표 유용성을 달성하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 프라이버시 비용을 최적화하기 위한 유용성 우선 접근 방식의 필요성.

Method: 상관된 라플라스 노이즈를 추가하고 점진적으로 줄이는 방법을 사용하여 비공식적인 통계 추정기를 통해 프라이버시 손실을 최소화하는 기법을 제안.

Result: 비공식적인 통계 추정기를 활용하여 원래의 프라이버시 예산에서 최대 두 배의 추가 비용으로 정확한 추정치를 생성할 수 있음.

Conclusion: 제안된 방법은 추가적인 프라이버시 비용 없이 하이퍼파라미터 튜닝을 통해 최적의 유용성을 달성할 수 있음을 보였다.

Abstract: The conventional approach in differential privacy (DP) literature formulates
the privacy-utility trade-off with a "privacy-first" perspective: for a
predetermined level of privacy, a certain utility is achievable. However,
practitioners often operate under a "utility-first" paradigm, prioritizing a
desired level of utility and then determining the corresponding privacy cost.
  Wu et al. [2019] initiated a formal study of this "utility-first" perspective
by introducing ex-post DP. They demonstrated that by adding correlated Laplace
noise and progressively reducing it on demand, a sequence of increasingly
accurate estimates of a private parameter can be generated, with the privacy
cost attributed only to the least noisy iterate released. This led to a Laplace
mechanism variant that achieves a specified utility with minimal privacy loss.
However, their work, and similar findings by Whitehouse et al. [2022], are
primarily limited to simple mechanisms based on Laplace or Gaussian noise.
  In this paper, we significantly generalize these results. In particular, we
extend the work of Wu et al. [2019] and Liu and Talwar [2019] to support any
sequence of private estimators, incurring at most a doubling of the original
privacy budget. Furthermore, we demonstrate that hyperparameter tuning for
these estimators, including the selection of an optimal privacy budget, can be
performed without additional privacy cost. Finally, we extend our results to
ex-post Renyi DP, further broadening the applicability of utility-first privacy
mechanisms.

</details>


### [46] [Retrieval-Augmented Review Generation for Poisoning Recommender Systems](https://arxiv.org/abs/2508.15252)
*Shiyi Yang,Xinshu Li,Guanglin Zhou,Chen Wang,Xiwei Xu,Liming Zhu,Lina Yao*

Main category: cs.CR

TL;DR: 이 논문에서는 추천 시스템에 대한 데이터 중독 공격의 효과를 극대화하기 위해, 다중 모드 기초 모델의 인-컨텍스트 학습 능력을 활용하여 가짜 사용자 프로필의 품질을 향상시키는 새로운 공격 프레임워크인 RAGAN을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 추천 시스템이 데이터 중독 공격에 취약하다는 점과 보안, 프라이버시 문제로 인해 공격자들이 제한된 지식을 갖고 있다는의 중요성을 인식한다.

Method: RAGAN이라는 새로운 공격 프레임워크를 제안하고, 이를 통해 가짜 사용자 프로필의 품질을 높이고 전이 가능성과 감지 불가능성을 향상시킨다.

Result: RAGAN은 다양한 실제 데이터셋에 대한 실험을 통해 최신의 데이터 중독 공격 성능을 달성했다.

Conclusion: RAGAN은 추천 시스템의 강건성에 대한 통찰을 제공하며, 기존의 방법보다 우수한 성능을 보인다.

Abstract: Recent studies have shown that recommender systems (RSs) are highly
vulnerable to data poisoning attacks, where malicious actors inject fake user
profiles, including a group of well-designed fake ratings, to manipulate
recommendations. Due to security and privacy constraints in practice, attackers
typically possess limited knowledge of the victim system and thus need to craft
profiles that have transferability across black-box RSs. To maximize the attack
impact, the profiles often remains imperceptible. However, generating such
high-quality profiles with the restricted resources is challenging. Some works
suggest incorporating fake textual reviews to strengthen the profiles; yet, the
poor quality of the reviews largely undermines the attack effectiveness and
imperceptibility under the practical setting.
  To tackle the above challenges, in this paper, we propose to enhance the
quality of the review text by harnessing in-context learning (ICL) capabilities
of multimodal foundation models. To this end, we introduce a demonstration
retrieval algorithm and a text style transfer strategy to augment the navie
ICL. Specifically, we propose a novel practical attack framework named RAGAN to
generate high-quality fake user profiles, which can gain insights into the
robustness of RSs. The profiles are generated by a jailbreaker and
collaboratively optimized on an instructional agent and a guardian to improve
the attack transferability and imperceptibility. Comprehensive experiments on
various real-world datasets demonstrate that RAGAN achieves the
state-of-the-art poisoning attack performance.

</details>


### [47] [Connected and Exposed: Cybersecurity Risks, Regulatory Gaps, and Public Perception in Internet-Connected Vehicles](https://arxiv.org/abs/2508.15306)
*Henrietta Hegyi,Laszlo Erdodi*

Main category: cs.CR

TL;DR: 이 논문은 연결된 차량의 진화하는 위협 경관과 관련된 사이버 보안 및 개인 정보 보호 문제를 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 연결된 차량 기술의 급속한 발전은 스마트 모빌리티의 새로운 시대를 열면서 사이버 보안 및 개인 정보 보호에 대한 중대한 우려를 제기하고 있다.

Method: 본 논문에서는 16개의 국제 표준과 규정을 종합적으로 분석하고, 규제의 강도, 기술적 세부사항, 공급망 위험 처리, 개인 데이터 처리 접근 방식 등을 다각적으로 평가하였다. 또한, 사용자 중심의 설문조사를 실시하여 소비자들의 스마트카에 대한 태도를 조사하였다.

Result: 설문조사는 사용자가 신뢰하고 선호하는 차량 유형, 특정 차량 유형을 거부하는 이유, 데이터 관련 위험에 대한 인식, 차량의 데이터 처리 방식에 대한 충분한 정보 제공 여부를 조사하였다.

Conclusion: 규제 분석과 사용자 인식 통찰을 결합하여 본 연구는 연결된 차량 생태계를 둘러싼 도전과 기대에 대한 더 포괄적인 이해에 기여하고자 한다.

Abstract: The rapid advancement of Internet-connected vehicle technologies has
introduced a new era of smart mobility, while simultaneously raising
significant cybersecurity and privacy concerns. This paper explores the
evolving threat landscape associated with connected vehicles, focusing on risks
such as unauthorized remote access and the potential leakage of personal data.
To assess the current state of protection, we conducted a comprehensive
analysis of 16 international standards and regulations, evaluating them from
multiple perspectives including regulatory strength, technical specificity,
treatment of supply chain risks, and approaches to personal data handling.
  In parallel, we carried out a user-focused survey designed to map consumer
attitudes toward smart cars. The survey investigated which types of vehicles
users trust and prefer, the reasons behind rejecting certain car types, their
awareness of data-related risks, and whether they feel adequately informed
about how their vehicles handle data. By combining regulatory analysis with
user perception insights, this study aims to contribute to a more holistic
understanding of the challenges and expectations surrounding connected vehicle
ecosystems.

</details>


### [48] [IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents](https://arxiv.org/abs/2508.15310)
*Hengyu An,Jinghuai Zhang,Tianyu Du,Chunyi Zhou,Qingming Li,Tao Lin,Shouling Ji*

Main category: cs.CR

TL;DR: 본 논문은 LLM 에이전트들이 신뢰할 수 없는 데이터 소스와 상호작용할 때 발생할 수 있는 유해한 결과를 방지하기 위한 새로운 방어 작업 실행 패러다임인 IPIGuard를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 복잡한 작업을 수행하는 데 있어 신뢰할 수 없는 데이터 소스에서 발생할 수 있는 보안 위협을 해결하고자 한다.

Method: IPIGuard는 에이전트의 작업 실행 과정을 계획된 도구 의존성 그래프(TDG) 탐색으로 모델링하여, 외부 데이터와의 상호작용과 행동 계획을 명시적으로 분리한다.

Result: IPIGuard는 AgentDojo 벤치마크 실험에서 효과성과 강건성 간의 우수한 균형을 달성하였다.

Conclusion: IPIGuard는 동적 환경에서보다 안전한 에이전트 시스템 개발을 위한 길을 열어준다.

Abstract: Large language model (LLM) agents are widely deployed in real-world
applications, where they leverage tools to retrieve and manipulate external
data for complex tasks. However, when interacting with untrusted data sources
(e.g., fetching information from public websites), tool responses may contain
injected instructions that covertly influence agent behaviors and lead to
malicious outcomes, a threat referred to as Indirect Prompt Injection (IPI).
Existing defenses typically rely on advanced prompting strategies or auxiliary
detection models. While these methods have demonstrated some effectiveness,
they fundamentally rely on assumptions about the model's inherent security,
which lacks structural constraints on agent behaviors. As a result, agents
still retain unrestricted access to tool invocations, leaving them vulnerable
to stronger attack vectors that can bypass the security guardrails of the
model. To prevent malicious tool invocations at the source, we propose a novel
defensive task execution paradigm, called IPIGuard, which models the agents'
task execution process as a traversal over a planned Tool Dependency Graph
(TDG). By explicitly decoupling action planning from interaction with external
data, IPIGuard significantly reduces unintended tool invocations triggered by
injected instructions, thereby enhancing robustness against IPI attacks.
Experiments on the AgentDojo benchmark show that IPIGuard achieves a superior
balance between effectiveness and robustness, paving the way for the
development of safer agentic systems in dynamic environments.

</details>


### [49] [A Practical Guideline and Taxonomy to LLVM's Control Flow Integrity](https://arxiv.org/abs/2508.15386)
*Sabine Houy,Bruno Kreyssig,Timothee Riom,Alexandre Bartel,Patrick McDaniel*

Main category: cs.CR

TL;DR: 메모리 손상 취약점은 소프트웨어 보안에 심각한 위협을 가하고 있으며, 제어 흐름 무결성(CFI)을 통해 이를 완화하려는 노력이 필요하다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 보안에서 메모리 손상 취약점 극복을 위한 지침이 필요하다.

Method: LLVM의 전방 엣지 CFI 변형을 메모리 손상 취약점 클래스에 매핑하는 세분화된 분류체계를 구축하였다.

Result: CFI의 유효성을 평가하고 두 가지 경우에서 공격을 차단한 반면, 나머지 두 경우에서는 실패한 이유를 설명하였다.

Conclusion: CFI의 실용적 사용 개선을 위한 기반을 제공하며, 정보에 기반한 배포 결정을 지원한다.

Abstract: Memory corruption vulnerabilities remain one of the most severe threats to
software security. They often allow attackers to achieve arbitrary code
execution by redirecting a vulnerable program's control flow. While Control
Flow Integrity (CFI) has gained traction to mitigate this exploitation path,
developers are not provided with any direction on how to apply CFI to
real-world software. In this work, we establish a taxonomy mapping LLVM's
forward-edge CFI variants to memory corruption vulnerability classes, offering
actionable guidance for developers seeking to deploy CFI incrementally in
existing codebases. Based on the Top 10 Known Exploited Vulnerabilities (KEV)
list, we identify four high-impact vulnerability categories and select one
representative CVE for each. We evaluate LLVM's CFI against each CVE and
explain why CFI blocks exploitation in two cases while failing in the other
two, illustrating its potential and current limitations. Our findings support
informed deployment decisions and provide a foundation for improving the
practical use of CFI in production systems.

</details>


### [50] [BadFU: Backdoor Federated Learning through Adversarial Machine Unlearning](https://arxiv.org/abs/2508.15541)
*Bingguang Lu,Hongsheng Hu,Yuantian Miao,Shaleeza Sohail,Chaoxiang He,Shuo Wang,Xiao Chen*

Main category: cs.CR

TL;DR: 연합 학습에서의 백도어 공격을 처음으로 제시하여, 공격자가 정당한 요청을 통해 글로벌 모델에 백도어를 주입할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 데이터 개인 정보 보호와 규제 준수에 대한 우려가 커짐에 따라, 특정 데이터를 모델에서 제거하는 기계적 비학습이 중요해지고 있다.

Method: 악의적 클라이언트가 백도어 및 위장 샘플을 사용하여 연합 학습 과정에서 정상적으로 글로벌 모델을 훈련시키는 BadFU 공격 전략을 제안한다.

Result: 다양한 연합 학습 프레임워크와 비학습 전략 아래에서의 광범위한 실험을 통해 BadFU의 효과성을 검증하고, 현재의 연합 비학습 관행에서의 중요한 취약점을 드러낸다.

Conclusion: 더 안전하고 탄탄한 연합 비학습 메커니즘의 필요성을 강조한다.

Abstract: Federated learning (FL) has been widely adopted as a decentralized training
paradigm that enables multiple clients to collaboratively learn a shared model
without exposing their local data. As concerns over data privacy and regulatory
compliance grow, machine unlearning, which aims to remove the influence of
specific data from trained models, has become increasingly important in the
federated setting to meet legal, ethical, or user-driven demands. However,
integrating unlearning into FL introduces new challenges and raises largely
unexplored security risks. In particular, adversaries may exploit the
unlearning process to compromise the integrity of the global model. In this
paper, we present the first backdoor attack in the context of federated
unlearning, demonstrating that an adversary can inject backdoors into the
global model through seemingly legitimate unlearning requests. Specifically, we
propose BadFU, an attack strategy where a malicious client uses both backdoor
and camouflage samples to train the global model normally during the federated
training process. Once the client requests unlearning of the camouflage
samples, the global model transitions into a backdoored state. Extensive
experiments under various FL frameworks and unlearning strategies validate the
effectiveness of BadFU, revealing a critical vulnerability in current federated
unlearning practices and underscoring the urgent need for more secure and
robust federated unlearning mechanisms.

</details>


### [51] [Towards Scalable and Interpretable Mobile App Risk Analysis via Large Language Models](https://arxiv.org/abs/2508.15606)
*Yu Yang,Zhenyuan Li,Xiandong Ran,Jiahao Liu,Jiahui Wang,Bo Yu,Shouling Ji*

Main category: cs.CR

TL;DR: Mars는 보안 위험 식별을 자동화하기 위해 대형 언어 모델을 활용하는 시스템으로, 인적 개입을 최소화하면서 다양한 위험 범주에 걸친 다수의 응용 프로그램을 동시에 분석하여 효율성을 높입니다.


<details>
  <summary>Details</summary>
Motivation: 모바일 애플리케이션 마켓플레이스는 애플리케이션의 보안 위험을 식별하고 완화하는 역할을 하고 있으며, 현재의 심사 과정은 노동집약적이고 반자동 도구에 의존합니다. 이러한 비효율성을 해결하기 위해 Mars 시스템을 제안합니다.

Method: Mars는 미리 구성된 위험 식별 트리를 활용하여 고차원 애플리케이션 특성에서 관련 지표를 추출하고, LLM 분석을 통해 최종 위험 결정을 수행합니다. 각 평가에 대해 포괄적인 증거 체인을 자동으로 생성하여 분석 프로세스를 기록합니다.

Result: Mars는 실제 Android 마켓플레이스 데이터를 기반으로 평가되었으며, 위험 식별에서 F1 점수 0.838, 증거 검색에서 F1 점수 0.934를 달성했습니다.

Conclusion: 사용자 연구에서 Mars는 전통적인 수동 분석에 비해 60%에서 90%까지 상당한 효율성 향상을 이루었습니다.

Abstract: Mobile application marketplaces are responsible for vetting apps to identify
and mitigate security risks. Current vetting processes are labor-intensive,
relying on manual analysis by security professionals aided by semi-automated
tools. To address this inefficiency, we propose Mars, a system that leverages
Large Language Models (LLMs) for automated risk identification and profiling.
Mars is designed to concurrently analyze multiple applications across diverse
risk categories with minimal human intervention. To enhance analytical
precision and operational efficiency, Mars leverages a pre-constructed risk
identification tree to extract relevant indicators from high-dimensional
application features. This initial step filters the data, reducing the input
volume for the LLM and mitigating the potential for model hallucination induced
by irrelevant features. The extracted indicators are then subjected to LLM
analysis for final risk determination. Furthermore, Mars automatically
generates a comprehensive evidence chain for each assessment, documenting the
analytical process to provide transparent justification. These chains are
designed to facilitate subsequent manual review and to inform enforcement
decisions, such as application delisting. The performance of Mars was evaluated
on a real-world dataset from a partner Android marketplace. The results
demonstrate that Mars attained an F1-score of 0.838 in risk identification and
an F1-score of 0.934 in evidence retrieval. To assess its practical
applicability, a user study involving 20 expert analysts was conducted, which
indicated that Mars yielded a substantial efficiency gain, ranging from 60% to
90%, over conventional manual analysis.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [52] [Alpha Berkeley: A Scalable Framework for the Orchestration of Agentic Systems](https://arxiv.org/abs/2508.15066)
*Thorsten Hellert,João Montenegro,Antonin Sulc*

Main category: cs.MA

TL;DR: 이 논문은 Alpha Berkeley Framework를 소개하며, 이는 안전-critical 환경에서 다양한 제어 시스템 간의 워크플로우를 조정하는 데 중점을 둔다. 이 프레임워크는 대화형 맥락과 견고한 도구 조화를 통합하는 확장 가능한 에이전트 시스템을 위한 생산 준비 아키텍처를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 안전-critical 환경에서 이질적인 제어 시스템 간의 워크플로우 조정은 여전히 중심적인 도전 과제이다.

Method: Alpha Berkeley Framework는 동적 기능 분류, 계획 기반 조율 모델, 맥락 인식 작업 추출 및 생산 준비 실행 환경을 포함하여 대화형 맥락과 견고한 도구 조화를 통합하는 아키텍처이다.

Result: 풍력 발전소 모니터링 예시와 고급 광원 입자 가속기에서의 배포를 통해 다양한 사용 사례를 보여준다.

Conclusion: 이 결과들은 Alpha Berkeley가 높은 위험 분야에서 에이전트 시스템을 위한 신뢰할 수 있고 투명한 프레임워크로 자리매김하게 한다.

Abstract: Coordinating workflows across heterogeneous control systems remains a central
challenge in safety-critical environments such as scientific facilities,
industrial plants, and energy infrastructures. Language-model-driven agents
offer a natural interface for these tasks, but existing approaches often lack
scalability, reliability, and human oversight. We introduce the Alpha Berkeley
Framework, a production-ready architecture for scalable agentic systems that
integrate conversational context with robust tool orchestration. The framework
features dynamic capability classification to select only relevant tools per
task, a plan-first orchestration model that generates execution plans with
explicit dependencies and optional human approval, context-aware task
extraction that combines dialogue history with external memory and domain
resources, and production-ready execution environments with checkpointing,
artifact management, and modular deployment. We demonstrate its versatility
through two case studies: a tutorial-style wind farm monitoring example and a
deployment at the Advanced Light Source particle accelerator. These results
establish Alpha Berkeley as a reliable and transparent framework for agentic
systems in high-stakes domains.

</details>


### [53] [HEAS: Hierarchical Evolutionary Agent Simulation Framework for Cross-Scale Modeling and Multi-Objective Search](https://arxiv.org/abs/2508.15555)
*Ruiyu Zhang,Lin Nie,Xin Zhao*

Main category: cs.MA

TL;DR: HEAS는 계층적 에이전트 기반 모델링과 진화 최적화를 통합한 파이썬 프레임워크로, 복잡한 프로세스를 효율적으로 모델링하고 평가하는 방법을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 시스템과 프로세스를 효율적으로 모델링하고 분석할 수 있는 통합된 프레임워크가 필요하다.

Method: 계층별로 구성된 경량 프로세스(‘스트림’)로 모델을 표현하고, 이를 통해 결정론적 레이어에서 공유 맥락을 읽고 쓸 수 있도록 하여 교차 규모의 결합을 명시적이고 감사 가능하도록 만든다.

Result: 통일된 지표를 통해 평가를 표준화하고, 텍스트 로그, 데이터 저장, 시각화 도구 등을 제공하여 여러 연구 간의 비교 가능성을 향상시킨다.

Conclusion: HEAS는 이기종 학문 및 다층적 연구를 위한 실용적인 기초를 제공하여 신뢰할 수 있는 재현 가능한 결과를 얻을 수 있도록 한다.

Abstract: Hierarchical Evolutionary Agent Simulation (HEAS) is a Python framework that
unifies layered agent-based modeling with evolutionary optimization and
tournament evaluation in a single, reproducible workflow. HEAS represents
models as hierarchies of lightweight processes ("streams") scheduled in
deterministic layers that read and write a shared context, making cross-scale
couplings explicit and auditable. A compact API and CLI-simulate, optimize,
evaluate-expose single- and multi-objective evolution, PyTorch policy
integration via parameter flattening/unflattening, and general tournament
tooling with user-defined scoring and voting rules. The framework standardizes
evaluation through uniform per-step and episode metrics, persists seeds,
logbooks, and hall-of-fame archives, and provides plotting helpers for traces,
Pareto fronts, and comparative outcomes, reducing glue code and improving
comparability across studies. HEAS emphasizes separation of mechanism from
orchestration, allowing exogenous drivers, endogenous agents, and aggregators
to be composed and swapped without refactoring, while the same model can be
used for forward simulation, optimization, or systematic comparison. We
illustrate usage with two compact examples-an ecological system and an
enterprise decision-making setting. HEAS offers a practical foundation for
cross-disciplinary, multi-level inquiry, yielding reliable, reproducible
results.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [54] [Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving](https://arxiv.org/abs/2508.14926)
*Dianzhao Li,Ostap Okhrin*

Main category: cs.LG

TL;DR: 자율 주행 차량의 안전성과 효율성을 높이기 위해 본 연구에서는 윤리적 고려 사항을 통합한 안전 강화 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 주행의 널리 퍼진 채택은 강력한 윤리적 추론을 시스템에 통합하는 데 달려 있다.

Method: 복합 윤리적 위험 비용을 사용하여 의사 결정 수준에서 안전한 강화 학습 에이전트를 훈련하고, 동적 우선 경험 재생 기제를 이용하여 희귀하지만 중요한 이벤트에서 학습을 증대시킨다.

Result: 본 접근법은 다양한 차량, 자전거 및 보행자로 구성된 실제 교통 데이터셋에서 훈련 및 검증되었으며, 윤리적 위험을 줄이고 주행 성능을 유지하는 데에서 기준 방법보다 우수한 성과를 보인다.

Conclusion: 이 연구는 실제 상황에서 자율 주행 차량의 윤리적 의사 결정을 위한 안전 강화 학습의 첫 번째 연구로, 복잡한 인간 혼합 교통 환경에서 윤리적으로 책임 있는 자율성을 향상시키는 가능성을 강조한다.

Abstract: Autonomous vehicles hold great promise for reducing traffic fatalities and
improving transportation efficiency, yet their widespread adoption hinges on
embedding robust ethical reasoning into routine and emergency maneuvers. Here,
we present a hierarchical Safe Reinforcement Learning (Safe RL) framework that
explicitly integrates moral considerations with standard driving objectives. At
the decision level, a Safe RL agent is trained using a composite ethical risk
cost, combining collision probability and harm severity, to generate high-level
motion targets. A dynamic Prioritized Experience Replay mechanism amplifies
learning from rare but critical, high-risk events. At the execution level,
polynomial path planning coupled with Proportional-Integral-Derivative (PID)
and Stanley controllers translates these targets into smooth, feasible
trajectories, ensuring both accuracy and comfort. We train and validate our
approach on rich, real-world traffic datasets encompassing diverse vehicles,
cyclists, and pedestrians, and demonstrate that it outperforms baseline methods
in reducing ethical risk and maintaining driving performance. To our knowledge,
this is the first study of ethical decision-making for autonomous vehicles via
Safe RL in real-world scenarios. Our results highlight the potential of
combining formal control theory and data-driven learning to advance ethically
accountable autonomy in complex, human-mixed traffic environments.

</details>


### [55] [Cohort-Aware Agents for Individualized Lung Cancer Risk Prediction Using a Retrieval-Augmented Model Selection Framework](https://arxiv.org/abs/2508.14940)
*Chongyu Qu,Allen J. Luna,Thomas Z. Li,Junchao Zhu,Junlin Guo,Juming Xiong,Kim L. Sandler,Bennett A. Landman,Yuankai Huo*

Main category: cs.LG

TL;DR: 개인화된 폐암 위험 예측 모델이 환자 개별 특성에 따라 적절한 예측 알고리즘을 동적으로 선택하는 방안을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 폐암 위험 예측의 정확성을 높이기 위해 다양한 환자 집단 및 임상 환경의 변동성을 해결하고자 합니다.

Method: 환자의 CT 스캔 및 구조화된 메타데이터를 기반으로 FAISS를 이용한 유사도 검색을 통해 관련 환자 집단을 조회한 다음, 대규모 언어 모델을 사용해 최적의 예측 알고리즘을 추천합니다.

Result: 여기서는 8개의 대표 모델(고전적 선형 위험 모델, 시계열 모델, 다중 모달 컴퓨터 비전 기반 접근법) 중 최적 모델을 선택합니다.

Conclusion: 이 개인화된 위험 예측 방법은 다양한 임상 집단을 대상으로 하여 실제 폐암 선별을 위한 개인화된 위험 평가의 실용적인 경로를 제공합니다.

Abstract: Accurate lung cancer risk prediction remains challenging due to substantial
variability across patient populations and clinical settings -- no single model
performs best for all cohorts. To address this, we propose a personalized lung
cancer risk prediction agent that dynamically selects the most appropriate
model for each patient by combining cohort-specific knowledge with modern
retrieval and reasoning techniques. Given a patient's CT scan and structured
metadata -- including demographic, clinical, and nodule-level features -- the
agent first performs cohort retrieval using FAISS-based similarity search
across nine diverse real-world cohorts to identify the most relevant patient
population from a multi-institutional database. Second, a Large Language Model
(LLM) is prompted with the retrieved cohort and its associated performance
metrics to recommend the optimal prediction algorithm from a pool of eight
representative models, including classical linear risk models (e.g., Mayo,
Brock), temporally-aware models (e.g., TDVIT, DLSTM), and multi-modal computer
vision-based approaches (e.g., Liao, Sybil, DLS, DLI). This two-stage agent
pipeline -- retrieval via FAISS and reasoning via LLM -- enables dynamic,
cohort-aware risk prediction personalized to each patient's profile. Building
on this architecture, the agent supports flexible and cohort-driven model
selection across diverse clinical populations, offering a practical path toward
individualized risk assessment in real-world lung cancer screening.

</details>


### [56] [Structure-Aware Temporal Modeling for Chronic Disease Progression Prediction](https://arxiv.org/abs/2508.14942)
*Jiacheng Hu,Bo Zhang,Ting Xu,Haifeng Yang,Min Gao*

Main category: cs.LG

TL;DR: 본 연구는 파킨슨병 진행 예측의 증상 진화 복잡성과 시간적 의존성 모델링 부족 문제를 해결하기 위한 통합 예측 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 파킨슨병의 진행 예측에 있어 증상 진화의 복잡성 및 시간적 의존성 모델링의 부족 문제를 해결하고자 한다.

Method: 구조적 인식과 시간적 모델링을 통합한 예측 프레임워크를 제안하며, 그래프 신경망을 활용하여 다중 모달 클리니컬 증상 간의 구조적 관계를 모델링하고, 증상 간의 의미적 의존성을 반영하기 위한 그래프 기반 표현을 도입한다. 또한, 병의 진행 중 동적인 시간적 특징을 모델링하기 위해 Transformer 아키텍처를 포함하고 있다.

Result: 제안된 방법은 기존 접근법에 비해 AUC, RMSE, IPW-F1 메트릭에서 우수한 성능을 보이며, 진행 단계의 구별과 개인화된 증상 궤적을 포착하는 능력을 향상시킨다.

Conclusion: 전체 프레임워크는 강력한 일반화 능력과 구조적 확장성을 보여주며, 파킨슨병과 같은 만성 진행 질환의 지능적 모델링 신뢰할 수 있는 지원을 제공한다.

Abstract: This study addresses the challenges of symptom evolution complexity and
insufficient temporal dependency modeling in Parkinson's disease progression
prediction. It proposes a unified prediction framework that integrates
structural perception and temporal modeling. The method leverages graph neural
networks to model the structural relationships among multimodal clinical
symptoms and introduces graph-based representations to capture semantic
dependencies between symptoms. It also incorporates a Transformer architecture
to model dynamic temporal features during disease progression. To fuse
structural and temporal information, a structure-aware gating mechanism is
designed to dynamically adjust the fusion weights between structural encodings
and temporal features, enhancing the model's ability to identify key
progression stages. To improve classification accuracy and stability, the
framework includes a multi-component modeling pipeline, consisting of a graph
construction module, a temporal encoding module, and a prediction output layer.
The model is evaluated on real-world longitudinal Parkinson's disease data. The
experiments involve comparisons with mainstream models, sensitivity analysis of
hyperparameters, and graph connection density control. Results show that the
proposed method outperforms existing approaches in AUC, RMSE, and IPW-F1
metrics. It effectively distinguishes progression stages and improves the
model's ability to capture personalized symptom trajectories. The overall
framework demonstrates strong generalization and structural scalability,
providing reliable support for intelligent modeling of chronic progressive
diseases such as Parkinson's disease.

</details>


### [57] [Distributed Detection of Adversarial Attacks in Multi-Agent Reinforcement Learning with Continuous Action Space](https://arxiv.org/abs/2508.15764)
*Kiarash Kazari,Ezzeldin Shereen,György Dán*

Main category: cs.LG

TL;DR: 본 논문에서는 연속 동작 공간에서 협력하는 다중 에이전트 강화 학습에 대한 적대적 공격 탐지 문제를 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 협력하는 다중 에이전트 시스템에서 적대적 공격의 탐지가 필수적입니다.

Method: 지역 관측치에만 의존하고 정상 행동을 파라메트릭 다변량 가우시안 분포로 근사하는 분산형 탐지기를 제안합니다.

Result: 우리는 다양한 다중 에이전트 PettingZoo 벤치마크에서 공격 방법에 대해 우리의 방식이 효과적임을 입증하였습니다.

Conclusion: 우리의 방법은 모든 평가된 환경에서 가장 큰 영향을 미치는 공격을 탐지하는 데 있어 0.95 이상의 AUC-ROC 점수를 달성함으로써 우수한 성능을 보였습니다.

Abstract: We address the problem of detecting adversarial attacks against cooperative
multi-agent reinforcement learning with continuous action space. We propose a
decentralized detector that relies solely on the local observations of the
agents and makes use of a statistical characterization of the normal behavior
of observable agents. The proposed detector utilizes deep neural networks to
approximate the normal behavior of agents as parametric multivariate Gaussian
distributions. Based on the predicted density functions, we define a normality
score and provide a characterization of its mean and variance. This
characterization allows us to employ a two-sided CUSUM procedure for detecting
deviations of the normality score from its mean, serving as a detector of
anomalous behavior in real-time. We evaluate our scheme on various multi-agent
PettingZoo benchmarks against different state-of-the-art attack methods, and
our results demonstrate the effectiveness of our method in detecting impactful
adversarial attacks. Particularly, it outperforms the discrete counterpart by
achieving AUC-ROC scores of over 0.95 against the most impactful attacks in all
evaluated environments.

</details>


### [58] [HHNAS-AM: Hierarchical Hybrid Neural Architecture Search using Adaptive Mutation Policies](https://arxiv.org/abs/2508.14946)
*Anurag Tripathi,Ajeet Kumar Singh,Rajsabi Surya,Aum Gupta,Sahiinii Lemaina Veikho,Dorien Herremans,Sudhir Bisane*

Main category: cs.LG

TL;DR: 이 논문에서는 텍스트 분류를 위한 효율적인 신경망 구조 탐색 방식인 HHNAS-AM을 제안하며, 이는 검색 공간을 조직화하고 적응형 변이 전략을 사용하여 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 신경망 구조 탐색(NAS)은 수동 설계를 초월하는 아키텍처를 발견할 수 있는 능력으로 인해 큰 연구 관심을 받고 있습니다.

Method: 모델은 계층형 혼합 신경망 구조 탐색(HHNAS-AM)으로, 도메인 특화 신호에 기반하여 검색 공간을 구조화하는 몇 가지 아키텍처 템플릿을 도입합니다.

Result: 우리 방법은 데이터베이스 아이디(db_id) 예측 작업에서 높은 성능의 아키텍처를 꾸준히 발견하며, Spider 데이터셋에서 기존 기준보다 테스트 정확도가 8% 향상됩니다.

Conclusion: 제안된 모델은 전적으로 확률적이며, 검색 공간의 효과적인 탐색을 가능하게 합니다.

Abstract: Neural Architecture Search (NAS) has garnered significant research interest
due to its capability to discover architectures superior to manually designed
ones. Learning text representation is crucial for text classification and other
language-related tasks. The NAS model used in text classification does not have
a Hybrid hierarchical structure, and there is no restriction on the
architecture structure, due to which the search space becomes very large and
mostly redundant, so the existing RL models are not able to navigate the search
space effectively. Also, doing a flat architecture search leads to an
unorganised search space, which is difficult to traverse. For this purpose, we
propose HHNAS-AM (Hierarchical Hybrid Neural Architecture Search with Adaptive
Mutation Policies), a novel approach that efficiently explores diverse
architectural configurations. We introduce a few architectural templates to
search on which organise the search spaces, where search spaces are designed on
the basis of domain-specific cues. Our method employs mutation strategies that
dynamically adapt based on performance feedback from previous iterations using
Q-learning, enabling a more effective and accelerated traversal of the search
space. The proposed model is fully probabilistic, enabling effective
exploration of the search space. We evaluate our approach on the database id
(db_id) prediction task, where it consistently discovers high-performing
architectures across multiple experiments. On the Spider dataset, our method
achieves an 8% improvement in test accuracy over existing baselines.

</details>


### [59] [Linear Preference Optimization: Decoupled Gradient Control via Absolute Regularization](https://arxiv.org/abs/2508.14947)
*Rui Wang,Qianguo Sun,Chao Song,Junlong Wu,Tianrong Chen,Zhiyun Zeng,Yu Li*

Main category: cs.LG

TL;DR: LPO는 DPO의 전반적인 문제를 해결하는 새로운 선호 최적화 알고리즘으로, 여러 혁신적인 접근 방식을 통해 다양한 작업에서 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: DPO는 오프라인 선호 최적화 알고리즘으로 널리 사용되지만, 과적합 및 붕괴의 문제를 안고 있습니다.

Method: LPO는 세 가지 주요 혁신인 그래디언트 분리, 오프셋 제약 및 제어 가능한 거절 억제를 통해 안정성을 개선합니다.

Result: LPO는 일반 텍스트 작업, 수학 작업 및 TTS 작업을 포함한 다양한 작업에서 성능을 일관되게 향상시킵니다.

Conclusion: LPO는 견고하고 조정 가능한 선호 정렬 패러다임으로 자리 잡았으며, 소스 코드, 모델 및 훈련 데이터를 공개합니다.

Abstract: DPO (Direct Preference Optimization) has become a widely used offline
preference optimization algorithm due to its simplicity and training stability.
However, DPO is prone to overfitting and collapse. To address these challenges,
we propose Linear Preference Optimization (LPO), a novel alignment framework
featuring three key innovations. First, we introduce gradient decoupling by
replacing the log-sigmoid function with an absolute difference loss, thereby
isolating the optimization dynamics. Second, we improve stability through an
offset constraint combined with a positive regularization term to preserve the
chosen response quality. Third, we implement controllable rejection suppression
using gradient separation with straightforward estimation and a tunable
coefficient that linearly regulates the descent of the rejection probability.
Through extensive experiments, we demonstrate that LPO consistently improves
performance on various tasks, including general text tasks, math tasks, and
text-to-speech (TTS) tasks. These results establish LPO as a robust and tunable
paradigm for preference alignment, and we release the source code, models, and
training data publicly.

</details>


### [60] [Large Foundation Model for Ads Recommendation](https://arxiv.org/abs/2508.14948)
*Shangyu Zhang,Shijie Quan,Zhongren Wang,Junwei Pan,Tianqu Zhuang,Bo Fu,Yilong Sun,Jieying Lin,Jushuo Chen,Xiaotian Li,Zhixiang Feng,Xian Hu,Huiting Deng,Hua Lu,Jinpeng Wang,Boqi Dai,Xiaoyu Chen,Bin Hu,Lili Huang,Yanwen Wu,Yeshou Cai,Qi Zhou,Huang Tang,Chunfeng Yang,Chengguo Yin,Tingyu Jiang,Lifeng Wang,Shudong Huang,Dapeng Liu,Lei Xiao,Haijie Gu,Shu-Tao Xia,Jie Jiang*

Main category: cs.LG

TL;DR: LFM4Ads는 광고 추천을 위한 모든 표현과 다중 세분화 전이 프레임워크로, 사용자, 아이템, 및 사용자-아이템 교차 표현을 포괄적으로 전이하여 광고 추천의 정확성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 온라인 광고는 정확한 추천 모델에 의존하며, 최근에는 대규모 기초 모델(LFM)을 사용하여 사용자의 일반적인 관심사를 다양한 시나리오와 작업에서 포착하고 있다.

Method: LFM4Ads는 사용자 표현(UR), 아이템 표현(IR), 사용자-아이템 교차 표현(CR)을 포괄적으로 전이하고, 최적의 추출 계층을 식별하며, 다중 세분화 메커니즘을 통해 전이 가능성을 강화한다.

Result: LFM4Ads는 Tencent의 산업 규모 광고 플랫폼에서 성공적으로 배포되어, 매일 수십억 개의 샘플을 처리하며, 2,000개에 가까운 기능에서 테라바이트 규모의 모델 매개변수를 유지한다.

Conclusion: LFM4Ads는 다양한 광고 시나리오에서 10회 이상의 성공적인 생산 출시에 도달했으며, 전체 플랫폼에서 GMV가 2.45% 증가하여 수억 달러의 연간 수익 증가로 이어졌다.

Abstract: Online advertising relies on accurate recommendation models, with recent
advances using pre-trained large-scale foundation models (LFMs) to capture
users' general interests across multiple scenarios and tasks. However, existing
methods have critical limitations: they extract and transfer only user
representations (URs), ignoring valuable item representations (IRs) and
user-item cross representations (CRs); and they simply use a UR as a feature in
downstream applications, which fails to bridge upstream-downstream gaps and
overlooks more transfer granularities. In this paper, we propose LFM4Ads, an
All-Representation Multi-Granularity transfer framework for ads recommendation.
It first comprehensively transfers URs, IRs, and CRs, i.e., all available
representations in the pre-trained foundation model. To effectively utilize the
CRs, it identifies the optimal extraction layer and aggregates them into
transferable coarse-grained forms. Furthermore, we enhance the transferability
via multi-granularity mechanisms: non-linear adapters for feature-level
transfer, an Isomorphic Interaction Module for module-level transfer, and
Standalone Retrieval for model-level transfer. LFM4Ads has been successfully
deployed in Tencent's industrial-scale advertising platform, processing tens of
billions of daily samples while maintaining terabyte-scale model parameters
with billions of sparse embedding keys across approximately two thousand
features. Since its production deployment in Q4 2024, LFM4Ads has achieved 10+
successful production launches across various advertising scenarios, including
primary ones like Weixin Moments and Channels. These launches achieve an
overall GMV lift of 2.45% across the entire platform, translating to estimated
annual revenue increases in the hundreds of millions of dollars.

</details>


### [61] [Quantum Long Short-term Memory with Differentiable Architecture Search](https://arxiv.org/abs/2508.14955)
*Samuel Yen-Chi Chen,Prayag Tiwari*

Main category: cs.LG

TL;DR: DiffQAS-QLSTM은 양자 순차 학습을 위한 최적화된 프레임워크로, 다양한 테스트 환경에서 손수 만든 기준보다 우수한 성과를 보인다.


<details>
  <summary>Details</summary>
Motivation: 양자 컴퓨팅과 머신러닝의 발전으로 양자 머신러닝이 대두되었으며, 연속 데이터에서 학습하는 것에 대한 관심이 높아지고 있다.

Method: DiffQAS-QLSTM은 최적화된 양자 회로 파라미터와 아키텍처 선택을 훈련 중에 함께 최적화하는 엔드 투 엔드 미분 가능 프레임워크를 제안한다.

Result: DiffQAS-QLSTM은 다양한 테스트 환경에서 손수 만든 기준을 일관되게 초월하며, 더 낮은 손실을 달성한다.

Conclusion: 이 접근법은 확장 가능하고 적응적인 양자 순차 학습의 가능성을 열어준다.

Abstract: Recent advances in quantum computing and machine learning have given rise to
quantum machine learning (QML), with growing interest in learning from
sequential data. Quantum recurrent models like QLSTM are promising for
time-series prediction, NLP, and reinforcement learning. However, designing
effective variational quantum circuits (VQCs) remains challenging and often
task-specific. To address this, we propose DiffQAS-QLSTM, an end-to-end
differentiable framework that optimizes both VQC parameters and architecture
selection during training. Our results show that DiffQAS-QLSTM consistently
outperforms handcrafted baselines, achieving lower loss across diverse test
settings. This approach opens the door to scalable and adaptive quantum
sequence learning.

</details>


### [62] [CuMoLoS-MAE: A Masked Autoencoder for Remote Sensing Data Reconstruction](https://arxiv.org/abs/2508.14957)
*Anurup Naskar,Nathanael Zhixin Wong,Sara Shamekh*

Main category: cs.LG

TL;DR: CuMoLoS-MAE는 정밀한 대기 프로필 복원을 위한 딥러닝 기반의 새로운 접근법이다.


<details>
  <summary>Details</summary>
Motivation: 대기 프로필의 정확성을 높이고 세밀한 구조를 복원하여 실시간 데이터 동화 및 장기 기후 재분석을 개선하기 위해.

Method: Curriculum-Guided Monte Carlo Stochastic Ensemble Masked Autoencoder (CuMoLoS-MAE)를 사용하여 세밀한 대기 특성을 복원하고 데이터 기반 사전 지식을 학습하며, 픽셀 단위의 불확실성을 계량화한다.

Result: 모델은 점진적으로 희소한 문맥에서 복원하도록 강제하며, 여러 번의 MAE 평가를 통해 후속 예측 평균 재구성을 생성하고 세밀하게 해상된 픽셀 별 불확실성 지도를 제공한다.

Conclusion: 이 접근법은 고충실도의 재구성을 통해 대류 진단을 개선하고, 실시간 데이터 동화 및 장기 기후 재분석에 기여한다.

Abstract: Accurate atmospheric profiles from remote sensing instruments such as Doppler
Lidar, Radar, and radiometers are frequently corrupted by low-SNR (Signal to
Noise Ratio) gates, range folding, and spurious discontinuities. Traditional
gap filling blurs fine-scale structures, whereas deep models lack confidence
estimates. We present CuMoLoS-MAE, a Curriculum-Guided Monte Carlo Stochastic
Ensemble Masked Autoencoder designed to (i) restore fine-scale features such as
updraft and downdraft cores, shear lines, and small vortices, (ii) learn a
data-driven prior over atmospheric fields, and (iii) quantify pixel-wise
uncertainty. During training, CuMoLoS-MAE employs a mask-ratio curriculum that
forces a ViT decoder to reconstruct from progressively sparser context. At
inference, we approximate the posterior predictive by Monte Carlo over random
mask realisations, evaluating the MAE multiple times and aggregating the
outputs to obtain the posterior predictive mean reconstruction together with a
finely resolved per-pixel uncertainty map. Together with high-fidelity
reconstruction, this novel deep learning-based workflow enables enhanced
convection diagnostics, supports real-time data assimilation, and improves
long-term climate reanalysis.

</details>


### [63] [Aura-CAPTCHA: A Reinforcement Learning and GAN-Enhanced Multi-Modal CAPTCHA System](https://arxiv.org/abs/2508.14976)
*Joydeep Chandra,Prabal Manhas,Ramanjot Kaur,Rashi Sahay*

Main category: cs.LG

TL;DR: Aura-CAPTCHA는 AI 기술의 위협에 대응하기 위해 개발된 다중 모달 CAPTCHA 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 CAPTCHA 방법이 AI 기술에 의해 점점 우회되고 있는 취약점을 해결하기 위해.

Method: Generative Adversarial Networks (GANs)를 활용하여 동적 이미지 챌린지를 생성하고, Reinforcement Learning (RL)을 이용해 난이도를 조정하며, Large Language Models (LLMs)을 통해 텍스트 및 오디오 프롬프트를 생성하는 방식을 적용하였다.

Result: 실제 트래픽 평가에서 92%의 인간 성공률과 10%의 봇 우회율을 기록하여 기존 CAPTCHA 시스템을 크게 능가하였다.

Conclusion: 이 시스템은 사용자에게 접근성을 유지하면서 온라인 애플리케이션 보안을 강화하는 견고하고 확장 가능한 접근 방식을 제공하였다.

Abstract: Aura-CAPTCHA was developed as a multi-modal CAPTCHA system to address
vulnerabilities in traditional methods that are increasingly bypassed by AI
technologies, such as Optical Character Recognition (OCR) and adversarial image
processing. The design integrated Generative Adversarial Networks (GANs) for
generating dynamic image challenges, Reinforcement Learning (RL) for adaptive
difficulty tuning, and Large Language Models (LLMs) for creating text and audio
prompts. Visual challenges included 3x3 grid selections with at least three
correct images, while audio challenges combined randomized numbers and words
into a single task. RL adjusted difficulty based on incorrect attempts,
response time, and suspicious user behavior. Evaluations on real-world traffic
demonstrated a 92% human success rate and a 10% bot bypass rate, significantly
outperforming existing CAPTCHA systems. The system provided a robust and
scalable approach for securing online applications while remaining accessible
to users, addressing gaps highlighted in previous research.

</details>


### [64] [Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs](https://arxiv.org/abs/2508.14995)
*Anastasis Kratsios,Ariel Neufeld,Philipp Schmocker*

Main category: cs.LG

TL;DR: 본 논문은 유한 차원 깊이 평형층을 사용하여 특수 클래스의 신경 연산자(GEOs)의 문제 해결을 통해 이론과 실천 간의 격차를 줄인다.


<details>
  <summary>Details</summary>
Motivation: 신경 연산자(NOs)는 무한 차원 공간에서 여러 관련 문제를 동시에 해결하기 위해 설계된 딥 러닝 모델의 한 종류이다. 그러나 이론과 실제 간의 중요한 격차가 존재한다.

Method: 이 논문은 유한 차원 깊이 평형층을 사용하여 분리 가능한 힐베르트 공간 X에서의 볼록 최적화 문제의 가족을 해결한다.

Result: 입력 손실이 적절한 무한 차원 컴팩트 집합에 있을 때, GEO는 해당 솔루션을 임의의 정밀도로 균등 근사할 수 있으며, 이때 랭크, 깊이 및 너비는 근사 오류의 역수에 대해 로그로만 증가한다.

Conclusion: 이론적 결과와 GEO의 훈련 가능성을 비선형 PDE, 확률적 최적 제어 문제, 유동성 제약 하의 수학적 금융에서의 헤지 문제 등 세 가지 응용 사례에서 검증하였다.

Abstract: Neural operators (NOs) are a class of deep learning models designed to
simultaneously solve infinitely many related problems by casting them into an
infinite-dimensional space, whereon these NOs operate. A significant gap
remains between theory and practice: worst-case parameter bounds from universal
approximation theorems suggest that NOs may require an unrealistically large
number of parameters to solve most operator learning problems, which stands in
direct opposition to a slew of experimental evidence. This paper closes that
gap for a specific class of {NOs}, generative {equilibrium operators} (GEOs),
using (realistic) finite-dimensional deep equilibrium layers, when solving
families of convex optimization problems over a separable Hilbert space $X$.
Here, the inputs are smooth, convex loss functions on $X$, and outputs are the
associated (approximate) solutions to the optimization problem defined by each
input loss.
  We show that when the input losses lie in suitable infinite-dimensional
compact sets, our GEO can uniformly approximate the corresponding solutions to
arbitrary precision, with rank, depth, and width growing only logarithmically
in the reciprocal of the approximation error. We then validate both our
theoretical results and the trainability of GEOs on three applications: (1)
nonlinear PDEs, (2) stochastic optimal control problems, and (3) hedging
problems in mathematical finance under liquidity constraints.

</details>


### [65] [Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications](https://arxiv.org/abs/2508.15008)
*Hamza A. Abushahla,Dara Varam,Ariel J. N. Panopio,Mohamed I. AlHajri*

Main category: cs.LG

TL;DR: 이 논문은 자원 제약 장치에서의 양자화 신경망(QNN) 배치의 도전 과제를 다루며, 굉장히 작은 기계 학습(TinyML)을 통해 딥 뉴럴 네트워크를 임베디드 시스템에서 효율적으로 실행하기 위한 기술을 종합적으로 검토합니다.


<details>
  <summary>Details</summary>
Motivation: 자원 제약 장치에서 QNN의 성능, 계산 복잡성 및 메모리 제약의 균형을 맞추는 것은 큰 도전 과제입니다.

Method: 하드웨어 중심의 양자화에 대한 소개와 임베디드 애플리케이션을 위한 딥 러닝 모델 가속화에 사용되는 필수 양자화 기술을 체계적으로 검토합니다.

Result: 모델 성능과 하드웨어 능력 간의 주요 트레이드오프를 강조하고, QNN 실행을 지원하도록 특별히 설계된 기존 소프트웨어 프레임워크 및 하드웨어 플랫폼을 평가합니다.

Conclusion: QNN 배치의 급격히 발전하는 분야에서 현재의 도전 과제와 유망한 미래 방향에 대한 분석을 제공합니다.

Abstract: The deployment of Quantized Neural Networks (QNNs) on resource-constrained
devices, such as microcontrollers, has introduced significant challenges in
balancing model performance, computational complexity and memory constraints.
Tiny Machine Learning (TinyML) addresses these issues by integrating
advancements across machine learning algorithms, hardware acceleration, and
software optimization to efficiently run deep neural networks on embedded
systems. This survey presents a hardware-centric introduction to quantization,
systematically reviewing essential quantization techniques employed to
accelerate deep learning models for embedded applications. In particular,
further emphasis is put on critical trade-offs among model performance and
hardware capabilities. The survey further evaluates existing software
frameworks and hardware platforms designed specifically for supporting QNN
execution on microcontrollers. Moreover, we provide an analysis of the current
challenges and an outline of promising future directions in the rapidly
evolving domain of QNN deployment.

</details>


### [66] [TOAST: Fast and scalable auto-partitioning based on principled static analysis](https://arxiv.org/abs/2508.15010)
*Sami Alabed,Dominik Grewe,Norman Alexander Rink,Timur Sitdikov,Agnieszka Swietlik,Dimitrios Vytiniotis,Daniel Belov*

Main category: cs.LG

TL;DR: 이 논문은 분산 가속기 시스템에서 대규모 머신 러닝 모델의 파티셔닝을 효율적으로 수행하는 새로운 시스템을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 머신 러닝 모델의 분산 시스템에서의 파티셔닝은 복잡하며 기존의 자동 파티셔너들이 메모리 오류 또는 비효율적인 성능 문제를 겪는 경우가 많습니다.

Method: 우리는 새로운 정적 컴파일러 분석과 몬테카를로 트리 탐색을 결합한 시스템을 제안합니다.

Result: 이 시스템은 다양한 하드웨어 플랫폼과 모델 아키텍처에서 기존 산업 방법보다 현저하게 우수한 성능을 보이며, 이전에 알려지지 않은 우수한 솔루션을 발견합니다.

Conclusion: 이 프로세스는 복잡하고 대규모 모델에 대해서도 완전히 자동화됩니다.

Abstract: Partitioning large machine learning models across distributed accelerator
systems is a complex process, requiring a series of interdependent decisions
that are further complicated by internal sharding ambiguities. Consequently,
existing auto-partitioners often suffer from out-of-memory errors or are
prohibitively slow when exploring the exponentially large space of possible
partitionings. To mitigate this, they artificially restrict the search space,
but this approach frequently yields infeasible solutions that violate device
memory constraints or lead to sub-optimal performance.
  We propose a system that combines a novel static compiler analysis with a
Monte Carlo Tree Search. Our analysis constructs an efficient decision space by
identifying (i) tensor dimensions requiring identical sharding, and (ii)
partitioning "conflicts" that require resolution.
  Our system significantly outperforms state-of-the-art industrial methods
across diverse hardware platforms and model architectures, discovering
previously unknown, superior solutions, and the process is fully automated even
for complex and large models.

</details>


### [67] [Fragment-Wise Interpretability in Graph Neural Networks via Molecule Decomposition and Contribution Analysis](https://arxiv.org/abs/2508.15015)
*Sebastian Musiał,Bartosz Zieliński,Tomasz Danel*

Main category: cs.LG

TL;DR: SEAL은 분자 그래프에서 중요한 분자 하위 구조에 대한 예측을 해석 가능하게 하는 새로운 그래프 신경망이다.


<details>
  <summary>Details</summary>
Motivation: 약물 발견 및 재료 설계와 같은 중요한 응용 분야에서 신뢰성을 높이기 위해 해석 가능성 부족 문제를 해결하고자 한다.

Method: SEAL은 입력 그래프를 화학적으로 관련된 조각으로 분해하고 출력에 대한 인과적 영향을 추정하는 방식으로 작동한다.

Result: SEAL은 기존의 설명 방법들보다 양적 기여 지표와 인간이 이해할 수 있는 해석 가능성 모두에서 우수한 성능을 보여준다.

Conclusion: SEAL은 예측 성능과 해석 가능성 간의 격차를 줄여주며, 투명하고 실행 가능한 분자 모델링에 대한 유망한 방향을 제시한다.

Abstract: Graph neural networks have demonstrated remarkable success in predicting
molecular properties by leveraging the rich structural information encoded in
molecular graphs. However, their black-box nature reduces interpretability,
which limits trust in their predictions for important applications such as drug
discovery and materials design. Furthermore, existing explanation techniques
often fail to reliably quantify the contribution of individual atoms or
substructures due to the entangled message-passing dynamics. We introduce SEAL
(Substructure Explanation via Attribution Learning), a new interpretable graph
neural network that attributes model predictions to meaningful molecular
subgraphs. SEAL decomposes input graphs into chemically relevant fragments and
estimates their causal influence on the output. The strong alignment between
fragment contributions and model predictions is achieved by explicitly reducing
inter-fragment message passing in our proposed model architecture. Extensive
evaluations on synthetic benchmarks and real-world molecular datasets
demonstrate that SEAL outperforms other explainability methods in both
quantitative attribution metrics and human-aligned interpretability. A user
study further confirms that SEAL provides more intuitive and trustworthy
explanations to domain experts. By bridging the gap between predictive
performance and interpretability, SEAL offers a promising direction for more
transparent and actionable molecular modeling.

</details>


### [68] [Twin-Boot: Uncertainty-Aware Optimization via Online Two-Sample Bootstrapping](https://arxiv.org/abs/2508.15019)
*Carlos Stein Brito*

Main category: cs.LG

TL;DR: Twin-Bootstrap Gradient Descent는 불확실성 추정을 최적화에 통합하는 재샘플링 기반 학습 절차를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 경량 경량 감소 방법은 신뢰도 측정 없이 점 추정을 제공하는데, 이는 데이터가 부족하고 파라미터가 많은 상황에서 특히 문제가 된다.

Method: Twin-Bootstrap Gradient Descent(Twin-Boot)은 독립적인 부트스트랩 샘플에서 두 개의 동일한 모델을 병렬로 학습하고 주기적인 평균 리셋을 통해 둘의 경로를 같은 배신에 유지하여 국부적 불확실성을 반영하는 방법이다.

Result: 이 접근법은 딥 뉴럴 네트워크 및 복잡한 고차원 역 문제에서 보정 및 일반화를 개선하고 해석 가능한 불확실성 맵을 산출한다.

Conclusion: Twin-Boot은 데이터 구동 방식의 적응형 샘플링을 통해 더 평평한 솔루션을 선호하는 정규화를 제공한다.

Abstract: Standard gradient descent methods yield point estimates with no measure of
confidence. This limitation is acute in overparameterized and low-data regimes,
where models have many parameters relative to available data and can easily
overfit. Bootstrapping is a classical statistical framework for uncertainty
estimation based on resampling, but naively applying it to deep learning is
impractical: it requires training many replicas, produces post-hoc estimates
that cannot guide learning, and implicitly assumes comparable optima across
runs - an assumption that fails in non-convex landscapes. We introduce
Twin-Bootstrap Gradient Descent (Twin-Boot), a resampling-based training
procedure that integrates uncertainty estimation into optimization. Two
identical models are trained in parallel on independent bootstrap samples, and
a periodic mean-reset keeps both trajectories in the same basin so that their
divergence reflects local (within-basin) uncertainty. During training, we use
this estimate to sample weights in an adaptive, data-driven way, providing
regularization that favors flatter solutions. In deep neural networks and
complex high-dimensional inverse problems, the approach improves calibration
and generalization and yields interpretable uncertainty maps.

</details>


### [69] [Towards Reliable and Generalizable Differentially Private Machine Learning (Extended Version)](https://arxiv.org/abs/2508.15141)
*Wenxuan Bao,Vincent Bindschaedler*

Main category: cs.LG

TL;DR: 이 논문은 최신 연구 문헌에서 제안된 11가지 차등 개인 정보 보호 기계 학습(DPML) 기술의 재현성과 복제 가능성을 실험하여 결과와 도전 과제를 논의한다.


<details>
  <summary>Details</summary>
Motivation: 최근 다양한 차등 개인 정보 보호 기계 학습 방법이 제안되었지만, 이들 방법의 효과성과 진정성에 대한 합의가 부족하다.

Method: 우리는 최근 연구 문헌에서 11가지의 SoTA DPML 기술에 대해 재현성 및 복제 가능성 실험(R+R)을 수행하였다.

Result: 조사 결과는 다양하여 일부 방법은 기준을 충족하는 반면, 다른 방법은 초기 실험 조건에서 벗어나면 성능이 저하되었다.

Conclusion: DPML의 재현성에 대한 고유한 도전을 논의하고 과학적으로 유효하고 신뢰할 수 있는 결과를 얻기 위한 인사이트와 모범 사례를 도출했다.

Abstract: There is a flurry of recent research papers proposing novel differentially
private machine learning (DPML) techniques. These papers claim to achieve new
state-of-the-art (SoTA) results and offer empirical results as validation.
However, there is no consensus on which techniques are most effective or if
they genuinely meet their stated claims. Complicating matters, heterogeneity in
codebases, datasets, methodologies, and model architectures make direct
comparisons of different approaches challenging.
  In this paper, we conduct a reproducibility and replicability (R+R)
experiment on 11 different SoTA DPML techniques from the recent research
literature. Results of our investigation are varied: while some methods stand
up to scrutiny, others falter when tested outside their initial experimental
conditions. We also discuss challenges unique to the reproducibility of DPML,
including additional randomness due to DP noise, and how to address them.
Finally, we derive insights and best practices to obtain scientifically valid
and reliable results.

</details>


### [70] [Nonlinear Federated System Identification](https://arxiv.org/abs/2508.15025)
*Omkar Tupe,Max Hartman,Lav R. Varshney,Saurav Prakash*

Main category: cs.LG

TL;DR: 연합 학습을 통한 비선형 시스템 식별의 이점을 이론적으로 증명하며, 클라이언트 수 증가에 따른 수렴 속도 향상을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 클라이언트 수가 증가함에 따라 연합 비선형 시스템 식별의 효과성을 분석하기 위해.

Method: 이론적으로 비선형 시스템 식별의 수렴 속도와 중앙집중적 접근 방식의 비교 분석 및 실험적 검증 진행.

Result: 수렴 속도는 클라이언트 수 증가에 따라 개선되며, 노이즈 수준과 데이터 분포의 변화에 따른 동작 분석을 포함한다.

Conclusion: 연합 학습은 참여 클라이언트 수에 따라 각각의 클라이언트 수렴을 일관되게 향상시킨다.

Abstract: We consider federated learning of linearly-parameterized nonlinear systems.
We establish theoretical guarantees on the effectiveness of federated nonlinear
system identification compared to centralized approaches, demonstrating that
the convergence rate improves as the number of clients increases. Although the
convergence rates in the linear and nonlinear cases differ only by a constant,
this constant depends on the feature map $\phi$, which can be carefully chosen
in the nonlinear setting to increase excitation and improve performance. We
experimentally validate our theory in physical settings where client devices
are driven by i.i.d. control inputs and control policies exhibiting i.i.d.
random perturbations, ensuring non-active exploration. Experiments use
trajectories from nonlinear dynamical systems characterized by real-analytic
feature functions, including polynomial and trigonometric components,
representative of physical systems including pendulum and quadrotor dynamics.
We analyze the convergence behavior of the proposed method under varying noise
levels and data distributions. Results show that federated learning
consistently improves convergence of any individual client as the number of
participating clients increases.

</details>


### [71] [Rethinking the Potential of Layer Freezing for Efficient DNN Training](https://arxiv.org/abs/2508.15033)
*Chence Yang,Ci Zhang,Lei Lu,Qitao Tan,Sheng Li,Ao Li,Xulong Tang,Shaoyi Huang,Jinzhen Wang,Guoming Li,Jundong Li,Xiaoming Zhai,Jin Lu,Geng Yuan*

Main category: cs.LG

TL;DR: 딥 뉴럴 네트워크와 데이터셋의 규모가 증가함에 따라 학습 비용이 크게 증가하고 있다. 본 논문은 레이어 동결 기법의 한계를 극복하고 효율적인 저장 및 학습 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 딥 뉴럴 네트워크 학습의 계산 비용을 줄이는 방법으로 레이어 동결 기법의 효과를 조사하고자 한다.

Method: 유사성 인지 채널 증강 및 손실 압축을 적용하여 레이어 동결과 관련된 저장 오버헤드를 줄이는 시스템적 솔루션을 제안한다.

Result: 우리의 접근법은 훈련 비용을 크게 줄이고 모델 정확도를 유지하며, 시간 오버헤드가 적다.

Conclusion: 본 연구는 동결 및 압축 전략의 포괄적인 평가를 통해 DNN 학습의 효율성을 높이는 통찰을 제공한다.

Abstract: With the growing size of deep neural networks and datasets, the computational
costs of training have significantly increased. The layer-freezing technique
has recently attracted great attention as a promising method to effectively
reduce the cost of network training. However, in traditional layer-freezing
methods, frozen layers are still required for forward propagation to generate
feature maps for unfrozen layers, limiting the reduction of computation costs.
To overcome this, prior works proposed a hypothetical solution, which caches
feature maps from frozen layers as a new dataset, allowing later layers to
train directly on stored feature maps. While this approach appears to be
straightforward, it presents several major challenges that are severely
overlooked by prior literature, such as how to effectively apply augmentations
to feature maps and the substantial storage overhead introduced. If these
overlooked challenges are not addressed, the performance of the caching method
will be severely impacted and even make it infeasible. This paper is the first
to comprehensively explore these challenges and provides a systematic solution.
To improve training accuracy, we propose \textit{similarity-aware channel
augmentation}, which caches channels with high augmentation sensitivity with a
minimum additional storage cost. To mitigate storage overhead, we incorporate
lossy data compression into layer freezing and design a \textit{progressive
compression} strategy, which increases compression rates as more layers are
frozen, effectively reducing storage costs. Finally, our solution achieves
significant reductions in training cost while maintaining model accuracy, with
a minor time overhead. Additionally, we conduct a comprehensive evaluation of
freezing and compression strategies, providing insights into optimizing their
application for efficient DNN training.

</details>


### [72] [Robust Estimation Under Heterogeneous Corruption Rates](https://arxiv.org/abs/2508.15051)
*Syomantak Chaudhuri,Jerry Li,Thomas A. Courtade*

Main category: cs.LG

TL;DR: 이 논문에서는 이질적인 오염 비율 하에서 강건한 추정 문제를 연구하며, 각 샘플이 비슷하지만 독립적인 확률로 오염될 수 있음을 설명합니다.


<details>
  <summary>Details</summary>
Motivation: 분산 학습, 연합 학습, 크라우드소싱, 센서 네트워크 등에서 발생하는 이질적인 오염 비율을 고려한 강건한 추정 방법을 개발하고자 합니다.

Method: 다변량 경계분포 및 일변량 가우시안 분포에 대한 평균 추정에 대해 모든 이질적 오염 패턴을 위한 최소 최대 비율을 제공합니다.

Result: 다변량 가우시안 평균 추정 및 선형 회귀에 대해 제곱 오차의 최소 최대 비율을 $	ext{최대}~	ext{d}$의 요소에 대해서 수립합니다.

Conclusion: 최적 추정기는 특정 오염 임계값을 초과하는 샘플을 폐기할 수 있으며, 이 임계값은 제공된 오염 비율의 경험적 분포에 의해 결정됩니다.

Abstract: We study the problem of robust estimation under heterogeneous corruption
rates, where each sample may be independently corrupted with a known but
non-identical probability. This setting arises naturally in distributed and
federated learning, crowdsourcing, and sensor networks, yet existing robust
estimators typically assume uniform or worst-case corruption, ignoring
structural heterogeneity. For mean estimation for multivariate bounded
distributions and univariate gaussian distributions, we give tight minimax
rates for all heterogeneous corruption patterns. For multivariate gaussian mean
estimation and linear regression, we establish the minimax rate for squared
error up to a factor of $\sqrt{d}$, where $d$ is the dimension. Roughly, our
findings suggest that samples beyond a certain corruption threshold may be
discarded by the optimal estimators -- this threshold is determined by the
empirical distribution of the corruption rates given.

</details>


### [73] [Enhancing Optimizer Stability: Momentum Adaptation of The NGN Step-size](https://arxiv.org/abs/2508.15071)
*Rustem Islamov,Niccolo Ajroldi,Antonio Orvieto,Aurelien Lucchi*

Main category: cs.LG

TL;DR: 본 논문에서는 상태-of-the-art 최적화 알고리즘과 유사한 성능을 제공하면서도 단계 크기 하이퍼파라미터 선택에 대한 안정성을 향상시킨 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 모던 최적화 알고리즘의 성능은 하이퍼파라미터, 특히 단계 크기 선택에 매우 민감합니다. 이러한 하이퍼파라미터 조정은 어려운 작업으로 간주됩니다.

Method: NGN 단계 크기 방법의 새로운 적응을 통해 순간 기반 버전(NGN-M)을 제안하여 덜 제한적인 가정 하에 표준 수렴 속도를 달성합니다.

Result: 이번 연구는 NGN 단계 크기와 모멘텀의 조합이 단계 크기 하이퍼파라미터 선택에 대한 견고성을 향상시키는 것을 보여주었습니다.

Conclusion: 제안된 알고리즘은 상태-of-the-art 최적화 알고리즘과 비교할 때 유사하거나 우수한 성능을 제공합니다.

Abstract: Modern optimization algorithms that incorporate momentum and adaptive
step-size offer improved performance in numerous challenging deep learning
tasks. However, their effectiveness is often highly sensitive to the choice of
hyperparameters, especially the step-size. Tuning these parameters is often
difficult, resource-intensive, and time-consuming. Therefore, recent efforts
have been directed toward enhancing the stability of optimizers across a wide
range of hyperparameter choices [Schaipp et al., 2024]. In this paper, we
introduce an algorithm that matches the performance of state-of-the-art
optimizers while improving stability to the choice of the step-size
hyperparameter through a novel adaptation of the NGN step-size method [Orvieto
and Xiao, 2024]. Specifically, we propose a momentum-based version (NGN-M) that
attains the standard convergence rate of $\mathcal{O}(1/\sqrt{K})$ under less
restrictive assumptions, without the need for interpolation condition or
assumptions of bounded stochastic gradients or iterates, in contrast to
previous approaches. Additionally, we empirically demonstrate that the
combination of the NGN step-size with momentum results in enhanced robustness
to the choice of the step-size hyperparameter while delivering performance that
is comparable to or surpasses other state-of-the-art optimizers.

</details>


### [74] [Wormhole Dynamics in Deep Neural Networks](https://arxiv.org/abs/2508.15086)
*Yen-Lung Lai,Zhe Jin*

Main category: cs.LG

TL;DR: 이 연구는 딥 신경망(DNN)의 일반화 행동을 조사하고, 인간에게는 무작위 또는 비구조적으로 보이는 입력을 자신 있게 분류하는 '속임수 예제' 현상에 초점을 맞춘다.


<details>
  <summary>Details</summary>
Motivation: 딥 신경망의 일반화 동작과 속임수 예제의 이해를 깊게 하기 위해.

Method: 최대 우도 추정에 기반한 분석 프레임워크를 도입한다.

Result: DNN이 과적합된 상태에서 출력 피처 공간의 붕괴를 보이며, 이는 네트워크 일반화를 개선하지만 더 많은 레이어를 추가하면 퇴행 상태에 이르게 된다.

Conclusion: 새로 도출된 '웜홀' 솔루션을 사용하면 이러한 퇴행을 우회할 수 있으며, 이는 무작위 레이블과 의미 있는 레이블을 조화시키고, 단축 학습에 대한 새로운 관점을 제공한다.

Abstract: This work investigates the generalization behavior of deep neural networks
(DNNs), focusing on the phenomenon of "fooling examples," where DNNs
confidently classify inputs that appear random or unstructured to humans. To
explore this phenomenon, we introduce an analytical framework based on maximum
likelihood estimation, without adhering to conventional numerical approaches
that rely on gradient-based optimization and explicit labels. Our analysis
reveals that DNNs operating in an overparameterized regime exhibit a collapse
in the output feature space. While this collapse improves network
generalization, adding more layers eventually leads to a state of degeneracy,
where the model learns trivial solutions by mapping distinct inputs to the same
output, resulting in zero loss. Further investigation demonstrates that this
degeneracy can be bypassed using our newly derived "wormhole" solution. The
wormhole solution, when applied to arbitrary fooling examples, reconciles
meaningful labels with random ones and provides a novel perspective on shortcut
learning. These findings offer deeper insights into DNN generalization and
highlight directions for future research on learning dynamics in unsupervised
settings to bridge the gap between theory and practice.

</details>


### [75] [Evaluating Sparse Autoencoders for Monosemantic Representation](https://arxiv.org/abs/2508.15094)
*Moghis Fereidouni,Muhammad Umair Haider,Peizhong Ju,A. B. Siddique*

Main category: cs.LG

TL;DR: 본 논문은 희소 자동 부호기(SAE)가 다의성을 줄이고 개념 분리 가능성을 향상시키는 방법을 평가하며, 새로운 개념 기반의 개입 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 해석하는 데에 있어서의 주요 장벽 중 하나는 다의성으로, 이는 신경망이 여러 개념에 대해 활성화되는 문제입니다.

Method: 본 연구는 Jensen-Shannon 거리를 기반으로 한 세분화된 개념 분리 가능성 점수를 도입하여 SAEs와 기초 모델의 모노세맨시티를 체계적으로 평가합니다.

Result: SAEs는 다의성을 낮추고 더 높은 개념 분리 가능성을 달성하였지만, SAEs의 더 큰 희소성이 항상 더 나은 분리 가능성을 가져오지는 않으며, 종종 하위 성능을 저하시킵니다.

Conclusion: SAEs는 부분 억제를 사용할 때 기초 모델에 비해 더 정확한 개념 수준 제어를 가능하게 하며, 새로운 개입 방법인 APP가 기존의 방법보다 유효한 개념 제거 성능을 보여줍니다.

Abstract: A key barrier to interpreting large language models is polysemanticity, where
neurons activate for multiple unrelated concepts. Sparse autoencoders (SAEs)
have been proposed to mitigate this issue by transforming dense activations
into sparse, more interpretable features. While prior work suggests that SAEs
promote monosemanticity, there has been no quantitative comparison with their
base models. This paper provides the first systematic evaluation of SAEs
against base models concerning monosemanticity. We introduce a fine-grained
concept separability score based on the Jensen-Shannon distance, which captures
how distinctly a neuron's activation distributions vary across concepts. Using
Gemma-2-2B and multiple SAE variants across five benchmarks, we show that SAEs
reduce polysemanticity and achieve higher concept separability. However,
greater sparsity of SAEs does not always yield better separability and often
impairs downstream performance. To assess practical utility, we evaluate
concept-level interventions using two strategies: full neuron masking and
partial suppression. We find that, compared to base models, SAEs enable more
precise concept-level control when using partial suppression. Building on this,
we propose Attenuation via Posterior Probabilities (APP), a new intervention
method that uses concept-conditioned activation distributions for targeted
suppression. APP outperforms existing approaches in targeted concept removal.

</details>


### [76] [Hydra: A 1.6B-Parameter State-Space Language Model with Sparse Attention, Mixture-of-Experts, and Memory](https://arxiv.org/abs/2508.15099)
*Siddharth Chaudhary,Bennett Browning*

Main category: cs.LG

TL;DR: 하이브리드 긴 맥락 언어 모델을 위한 Hydra 아키텍처 제안


<details>
  <summary>Details</summary>
Motivation: 긴 맥락을 처리할 수 있는 언어 모델의 필요성과 그에 따른 다양한 기법들의 조합 메커니즘을 탐구하기 위해.

Method: 조건부 컴퓨테이션, 긴 맥락 메모리 메커니즘, 그리고 희소 전문가 혼합(MoE)을 포함하는 약 1.6B 파라미터 설계를 사용하여 Mamba 스타일의 구조화된 상태 공간 모델(SSM)과 희소 글로벌 주의, 청크 레벨 MoE 피드 포워드 라우팅, 이중 메모리를 통합함.

Result: 프로토타입 측정을 통해 구현 가능성과 질적 스케일 행동을 시연하였고, 이는 경쟁 베이스라인 성능을 주장하기 위한 것이 아니다.

Conclusion: Hydra는 모듈화되고 입력 적응형 긴 맥락 언어 모델을 향한 길을 제시하며, 목표 규모에서 최종 작업의 이득을 검증하는 것은 향후 작업으로 남겨둔다.

Abstract: We present Hydra as an architectural proposal for hybrid long-context
language models that combine conditional computation, long-context memory
mechanisms, and sparse mixture-of-experts within an approximately 1.6B
parameter design envelope. Hydra integrates a Mamba-style Structured State
Space Model (SSM) backbone with intermittent sparse global attention,
chunk-level MoE feed-forward routing, and dual (workspace plus factual PKM)
memories. We formalize the component interfaces, give transparent parameter and
complexity accounting, and outline a staged curriculum intended to stably
activate the parts. We accompany the specification with illustrative toy-scale
prototype measurements (tens of millions of parameters on synthetic data) whose
sole purpose is to demonstrate implementation feasibility and qualitative
scaling behaviors (for example, long-context throughput crossover and
controllable expert routing), not to claim competitive full-scale performance.
We explicitly delineate assumptions and open risks (training complexity, memory
utilization, specialization dynamics) and position Hydra as a blueprint to
stimulate empirical follow-up rather than a finished system. By combining SSM
efficiency, selective sparse attention, MoE capacity, and learnable memory,
Hydra sketches a path toward modular, input-adaptive long-context language
models; validating end-task gains at target scale remains future work.

</details>


### [77] [Side Effects of Erasing Concepts from Diffusion Models](https://arxiv.org/abs/2508.15124)
*Shaswati Saha,Sourajit Saha,Manas Gaur,Tejas Gokhale*

Main category: cs.LG

TL;DR: 본 연구는 컨셉 지우기 기술(CET)이 쉽게 우회될 수 있으며, 그로 인한 여러 부작용을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: T2I 생성 모델의 개인정보, 저작권 및 안전 문제에 대한 우려로 CET가 개발되었습니다.

Method: CET의 강도를 포괄적으로 측정하기 위해 계층적이고 구성적인 프롬프트를 포함하는 Side Effect Evaluation(see)이라는 평가 기준을 제시합니다.

Result: 실험을 통해 CET는 슈퍼클래스-서브클래스 계층 구조와 유사한 의미의 프롬프트를 사용하여 우회할 수 있음을 보여주었습니다.

Conclusion: 우리는 CET가 속성 유출 및 주의 집중 또는 분산의 비직관적 현상으로 고통받는 것을 보여줍니다. 우리는 향후 강력한 개념 지우기에 대한 연구를 지원하기 위해 데이터셋, 코드 및 평가 도구를 공개합니다.

Abstract: Concerns about text-to-image (T2I) generative models infringing on privacy,
copyright, and safety have led to the development of Concept Erasure Techniques
(CETs).
  The goal of an effective CET is to prohibit the generation of undesired
``target'' concepts specified by the user, while preserving the ability to
synthesize high-quality images of the remaining concepts.
  In this work, we demonstrate that CETs can be easily circumvented and present
several side effects of concept erasure.
  For a comprehensive measurement of the robustness of CETs, we present Side
Effect Evaluation (\see), an evaluation benchmark that consists of hierarchical
and compositional prompts that describe objects and their attributes.
  This dataset and our automated evaluation pipeline quantify side effects of
CETs across three aspects: impact on neighboring concepts, evasion of targets,
and attribute leakage.
  Our experiments reveal that CETs can be circumvented by using
superclass-subclass hierarchy and semantically similar prompts, such as
compositional variants of the target. We show that CETs suffer from attribute
leakage and counterintuitive phenomena of attention concentration or dispersal.
  We release our dataset, code, and evaluation tools to aid future work on
robust concept erasure.

</details>


### [78] [Towards Source-Free Machine Unlearning](https://arxiv.org/abs/2508.15127)
*Sk Miraj Ahmed,Umit Yigit Basaran,Dripta S. Raychaudhuri,Arindam Dutta,Rohit Kundu,Fahim Faisal Niloy,Basak Guler,Amit K. Roy-Chowdhury*

Main category: cs.LG

TL;DR: 기계 학습과 데이터 개인 정보 보호 규제가 발전함에 따라 훈련된 모델에서 개인 정보나 저작권 정보 제거 능력이 점점 더 중요해지고 있다. 본 논문은 출처 없는 환경에서 훈련된 모델에서 특정 데이터를 제거하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 데이터 개인 정보 보호 규제가 발전하면서 훈련된 모델에서 개인 정보나 저작권 정보를 제거할 수 있는 능력이 점점 더 중요해지고 있다.

Method: 원래 훈련 데이터셋에 접근하지 않고도 훈련된 모델에서 특정 데이터를 제거할 수 있는 알고리즘을 개발하였다. 이 알고리즘은 잔여 훈련 데이터의 헤시안을 추정하여 효율적인 unlearning을 가능하게 한다.

Result: 광범위한 데이터셋에 대한 실험을 통해 제안하는 방법의 효과성을 검증하였으며, 이 방법은 zero-shot unlearning을 효율적으로 가능하게 한다.

Conclusion: 본 연구는 검증된 이론적 보장을 제공하면서도 나머지 데이터에 대한 성능을 유지하는 unlearning 방법을 제시하였다.

Abstract: As machine learning becomes more pervasive and data privacy regulations
evolve, the ability to remove private or copyrighted information from trained
models is becoming an increasingly critical requirement. Existing unlearning
methods often rely on the assumption of having access to the entire training
dataset during the forgetting process. However, this assumption may not hold
true in practical scenarios where the original training data may not be
accessible, i.e., the source-free setting. To address this challenge, we focus
on the source-free unlearning scenario, where an unlearning algorithm must be
capable of removing specific data from a trained model without requiring access
to the original training dataset. Building on recent work, we present a method
that can estimate the Hessian of the unknown remaining training data, a crucial
component required for efficient unlearning. Leveraging this estimation
technique, our method enables efficient zero-shot unlearning while providing
robust theoretical guarantees on the unlearning performance, while maintaining
performance on the remaining data. Extensive experiments over a wide range of
datasets verify the efficacy of our method.

</details>


### [79] [Universal Reinforcement Learning in Coalgebras: Asynchronous Stochastic Computation via Conduction](https://arxiv.org/abs/2508.15128)
*Sridhar Mahadevan*

Main category: cs.LG

TL;DR: 이 논문에서는 보편적 강화학습(URL)을 소개하며, 이는 비정당한 집합과 보편적 코알지브라, 토포스 이론 및 비동기 병렬 분산 계산의 범주적 모델에 대한 연구에서 발전된 강력한 수학적 추상화에 기반하고 있다.


<details>
  <summary>Details</summary>
Motivation: 강화학습(RL)의 기본 틀을 검토하고, 이를 통해 얻을 수 있는 흥미로운 통찰을 제시하기 위해

Method: 비동기 분산 최소화 표준 모델을 소개하고, MDP 및 PSR을 위한 알고리즘 공간을 범주로 모델링하며, 코알지브라의 보편적 확장을 논의한다.

Result: 비동기적 방식으로 최종 코알지브라를 결정하는 일반화된 문제를 제시하고, 동적 시스템 모델의 폭넓은 가족을 설명한다.

Conclusion: URL을 통해 RL의 고정점을 찾는 코어 문제를 비동기적으로 확장하여 해결한다.

Abstract: In this paper, we introduce a categorial generalization of RL, termed
universal reinforcement learning (URL), building on powerful mathematical
abstractions from the study of coinduction on non-well-founded sets and
universal coalgebras, topos theory, and categorial models of asynchronous
parallel distributed computation. In the first half of the paper, we review the
basic RL framework, illustrate the use of categories and functors in RL,
showing how they lead to interesting insights. In particular, we also introduce
a standard model of asynchronous distributed minimization proposed by Bertsekas
and Tsitsiklis, and describe the relationship between metric coinduction and
their proof of the Asynchronous Convergence Theorem. The space of algorithms
for MDPs or PSRs can be modeled as a functor category, where the co-domain
category forms a topos, which admits all (co)limits, possesses a subobject
classifier, and has exponential objects. In the second half of the paper, we
move on to universal coalgebras. Dynamical system models, such as Markov
decision processes (MDPs), partially observed MDPs (POMDPs), a predictive state
representation (PSRs), and linear dynamical systems (LDSs) are all special
types of coalgebras. We describe a broad family of universal coalgebras,
extending the dynamic system models studied previously in RL. The core problem
in finding fixed points in RL to determine the exact or approximate (action)
value function is generalized in URL to determining the final coalgebra
asynchronously in a parallel distributed manner.

</details>


### [80] [A Robust BERT-Based Deep Learning Model for Automated Cancer Type Extraction from Unstructured Pathology Reports](https://arxiv.org/abs/2508.15149)
*Minh Tran,Jeffery C. Chan,Min Li Huang,Maya Kansara,John P. Grady,Christine E. Napier,Subotheni Thavaneswaran,Mandy L. Ballinger,David M. Thomas,Frank P. Lin*

Main category: cs.LG

TL;DR: 본 연구에서는 정밀 종양학 연구를 지원하기 위해 병리 보고서에서 특정 암 유형을 자동으로 추출하는 강력한 시스템을 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 임상 연구를 위한 전자 의료 기록에서의 정확한 임상 정보 추출 필요.

Method: 세밀하게 조정된 RoBERTa 모델을 사용하여 병리 보고서에서 특정 암 유형을 자동 추출하는 시스템을 개발하였다.

Result: 모델은 기본 모델 및 대형 언어 모델인 Mistral 7B를 크게 초과하여 F1_Bertscore 0.98 및 전체 정확도 80.61%를 달성하였다.

Conclusion: 정밀 과제를 위한 도메인 특화 모델의 조정은 임상 정보 추출을 보다 효율적이고 정확하게 할 수 있는 길을 열 수 있다.

Abstract: The accurate extraction of clinical information from electronic medical
records is particularly critical to clinical research but require much trained
expertise and manual labor. In this study we developed a robust system for
automated extraction of the specific cancer types for the purpose of supporting
precision oncology research. from pathology reports using a fine-tuned RoBERTa
model. This model significantly outperformed the baseline model and a Large
Language Model, Mistral 7B, achieving F1_Bertscore 0.98 and overall exact match
of 80.61%. This fine-tuning approach demonstrates the potential for scalability
that can integrate seamlessly into the molecular tumour board process.
Fine-tuning domain-specific models for precision tasks in oncology, may pave
the way for more efficient and accurate clinical information extraction.

</details>


### [81] [SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks](https://arxiv.org/abs/2508.15182)
*Xiangman Li,Xiaodong Wu,Qi Li,Jianbing Ni,Rongxing Lu*

Main category: cs.LG

TL;DR: SafeLLM은 대형 언어 모델의 안전성을 향상시키는 새로운 방어 프레임워크로, 유해한 지식을 잊어버리면서도 언어적 유창성과 일반적인 기능을 유지한다.


<details>
  <summary>Details</summary>
Motivation: Jailbreak 공격은 대형 언어 모델의 안전성에 심각한 위협을 가하며, 따라서 이를 방어하기 위한 효과적인 방법이 필요하다.

Method: SafeLLM은 동적 안전하지 않은 출력 탐지, 토큰 수준의 해로운 콘텐츠 추적, 그리고 안전하지 않은 행동을 억제하기 위한 제약 최적화를 포함하는 세 단계의 파이프라인을 사용한다.

Result: SafeLLM은 여러 jailbreak 벤치마크에서 공격 성공률을 상당히 감소시키면서도 높은 일반 성능을 유지하는 것으로 나타났다.

Conclusion: 이러한 결과는 unlearning이 대형 언어 모델 안전을 위한 확장 가능하고 효과적인 방향임을 강조한다.

Abstract: Jailbreak attacks pose a serious threat to the safety of Large Language
Models (LLMs) by crafting adversarial prompts that bypass alignment mechanisms,
causing the models to produce harmful, restricted, or biased content. In this
paper, we propose SafeLLM, a novel unlearning-based defense framework that
unlearn the harmful knowledge from LLMs while preserving linguistic fluency and
general capabilities. SafeLLM employs a three-stage pipeline: (1) dynamic
unsafe output detection using a hybrid approach that integrates external
classifiers with model-internal evaluations; (2) token-level harmful content
tracing through feedforward network (FFN) activations to localize harmful
knowledge; and (3) constrained optimization to suppress unsafe behavior without
degrading overall model quality. SafeLLM achieves targeted and irreversible
forgetting by identifying and neutralizing FFN substructures responsible for
harmful generation pathways. Extensive experiments on prominent LLMs (Vicuna,
LLaMA, and GPT-J) across multiple jailbreak benchmarks show that SafeLLM
substantially reduces attack success rates while maintaining high
general-purpose performance. Compared to standard defense methods such as
supervised fine-tuning and direct preference optimization, SafeLLM offers
stronger safety guarantees, more precise control over harmful behavior, and
greater robustness to unseen attacks. Moreover, SafeLLM maintains the general
performance after the harmful knowledge unlearned. These results highlight
unlearning as a promising direction for scalable and effective LLM safety.

</details>


### [82] [Revisiting Pre-processing Group Fairness: A Modular Benchmarking Framework](https://arxiv.org/abs/2508.15193)
*Brodie Oldfield,Ziqi Xu,Sevvandi Kandanaarachchi*

Main category: cs.LG

TL;DR: FairPrep는 데이터 수준에서 공정성을 평가하기 위한 확장 가능하고 모듈화된 벤치마킹 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 시스템의 공정성을 보장하는 것이 중요해지고 있으며, 특히 데이터 수준에서의 사전 처리 방법이 필요하다.

Method: FairPrep은 AIF360 플랫폼을 기반으로 구축되어 있으며, 데이터셋과 공정성 개입, 예측 모델의 통합을 지원합니다.

Result: FairPrep은 배치 처리 인터페이스를 제공하여 공정성 및 유용성 메트릭의 효율적인 실험과 자동 보고를 가능하게 합니다.

Conclusion: FairPrep은 공정성 벤치마킹의 중요한 간극을 메우고 데이터 수준의 공정성 연구를 발전시키기 위한 실용적인 토대를 제공합니다.

Abstract: As machine learning systems become increasingly integrated into high-stakes
decision-making processes, ensuring fairness in algorithmic outcomes has become
a critical concern. Methods to mitigate bias typically fall into three
categories: pre-processing, in-processing, and post-processing. While
significant attention has been devoted to the latter two, pre-processing
methods, which operate at the data level and offer advantages such as
model-agnosticism and improved privacy compliance, have received comparatively
less focus and lack standardised evaluation tools. In this work, we introduce
FairPrep, an extensible and modular benchmarking framework designed to evaluate
fairness-aware pre-processing techniques on tabular datasets. Built on the
AIF360 platform, FairPrep allows seamless integration of datasets, fairness
interventions, and predictive models. It features a batch-processing interface
that enables efficient experimentation and automatic reporting of fairness and
utility metrics. By offering standardised pipelines and supporting reproducible
evaluations, FairPrep fills a critical gap in the fairness benchmarking
landscape and provides a practical foundation for advancing data-level fairness
research.

</details>


### [83] [Frequency-adaptive tensor neural networks for high-dimensional multi-scale problems](https://arxiv.org/abs/2508.15198)
*Jizu Huang,Rukang You,Tao Zhou*

Main category: cs.LG

TL;DR: TNNs의 주파수 원리에 대한 분석과 무작위 푸리에 특징 도입을 통해 고차원 문제에 대한 표현력을 향상시키는 연구.


<details>
  <summary>Details</summary>
Motivation: TNNs는 고차원 문제를 해결하는 데 우수하지만, 주파수 원리에 의해 높은 주파수 특징을 포착하는 능력이 제한된다.

Method: Fourier 분석을 통해 TNN의 훈련 동역학을 분석하고, 무작위 푸리에 특징을 도입하여 다중스케일 문제에 대한 표현력을 향상시킨다.

Result: 무작위 푸리에 특징을 통한 TNNs 알고리즘은 복잡한 다중스케일 문제 해결 능력을 크게 개선한다.

Conclusion: 제안된 주파수 적응형 TNNs 알고리즘의 효과성과 견고성을 검증하기 위해 광범위한 수치 실험이 수행되었다.

Abstract: Tensor neural networks (TNNs) have demonstrated their superiority in solving
high-dimensional problems. However, similar to conventional neural networks,
TNNs are also influenced by the Frequency Principle, which limits their ability
to accurately capture high-frequency features of the solution. In this work, we
analyze the training dynamics of TNNs by Fourier analysis and enhance their
expressivity for high-dimensional multi-scale problems by incorporating random
Fourier features. Leveraging the inherent tensor structure of TNNs, we further
propose a novel approach to extract frequency features of high-dimensional
functions by performing the Discrete Fourier Transform to one-dimensional
component functions. This strategy effectively mitigates the curse of
dimensionality. Building on this idea, we propose a frequency-adaptive TNNs
algorithm, which significantly improves the ability of TNNs in solving complex
multi-scale problems. Extensive numerical experiments are performed to validate
the effectiveness and robustness of the proposed frequency-adaptive TNNs
algorithm.

</details>


### [84] [SleepDIFFormer: Sleep Stage Classification via Multivariate Differential Transformer](https://arxiv.org/abs/2508.15215)
*Benjamin Wei Hao Chin,Yuin Torng Yew,Haocheng Wu,Lanxin Liang,Chow Khuen Chan,Norita Mohd Zain,Siti Balqis Samdin,Sim Kuan Goh*

Main category: cs.LG

TL;DR: 수면 단계 분류는 수면 질 평가 및 불면증과 같은 수면 장애 진단에 필수적이다. 이 연구는 EEG와 EOG 신호의 공동 표현 학습을 위한 Multivariate Differential Transformer(SleepDIFFormer)를 개발하여 수면 단계 분류 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: EEG와 EOG의 비정상성과 변동성으로 인해 수면 단계 분류의 정확성을 높이고 자동화하기 위한 필요성이 있다.

Method: SleepDIFFormer는 시간 시계열을 처리하기 위해 Multivariate Differential Transformer Architecture(MDTA)를 사용하여 개발되었으며, 교차 도메인 정렬을 통해 훈련된다.

Result: 다섯 개의 수면 단계 데이터셋에서 평가한 결과, 기존 접근 방식에 비해 최첨단 성능을 달성하였다.

Conclusion: 이 연구는 자동화된 수면 단계 분류의 발전과 수면 질 평가에 미치는 영향을 강조한다.

Abstract: Classification of sleep stages is essential for assessing sleep quality and
diagnosing sleep disorders such as insomnia. However, manual inspection of EEG
characteristics for each stage is time-consuming and prone to human error.
Although machine learning and deep learning methods have been actively
developed, they continue to face challenges from the non-stationarity and
variability of electroencephalography (EEG) and electrooculography (EOG)
signals, often leading to poor generalization on unseen datasets. This research
proposed a Sleep Stage Classification method by developing Multivariate
Differential Transformer (SleepDIFFormer) for joint EEG and EOG representation
learning. Specifically, SleepDIFFormer was developed to process EEG and EOG
signals using our Multivariate Differential Transformer Architecture (MDTA) for
time series, trained with cross-domain alignment. Our method mitigated spatial
and temporal attention noise while learning a domain-invariant joint EEG-EOG
representation through feature distribution alignment, thereby enabling
generalization to unseen target datasets. Empirically, we evaluated our method
on five different sleep staging datasets and compared it with existing
approaches, achieving state-of-the-art performance. We also conducted thorough
ablation analyses of SleepDIFFormer and interpreted the differential attention
weights, highlighting their relevance to characteristic sleep EEG patterns.
These findings have implications for advancing automated sleep stage
classification and its application to sleep quality assessment. Our source code
is publicly available at https://github.com/Ben1001409/SleepDIFFormer

</details>


### [85] [See Beyond a Single View: Multi-Attribution Learning Leads to Better Conversion Rate Prediction](https://arxiv.org/abs/2508.15217)
*Sishuo Chen,Zhangming Chan,Xiang-Rong Sheng,Lei Zhang,Sheng Chen,Chenghuan Hou,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: 본 연구는 다양한 귀속 메커니즘을 통합하여 전환율 예측을 개선하는 새로운 다중 귀속 학습(MAL) 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 전환율 예측은 온라인 광고 시스템의 핵심 요소이며, 기존 접근 방식은 단일 귀속 메커니즘의 라벨에 의존하여 대체적인 신호를 버리는 제한이 있었습니다.

Method: 본 연구는 다양한 귀속 관점에서 신호를 통합하는 다중 귀속 학습(MAL) 프레임워크를 제안합니다. MAL은 두 개의 핵심 구성 요소인 귀속 지식 집계기(AKA)와 주요 타겟 예측기(PTP)로 이루어져 있습니다.

Result: 실험 결과, MAL은 단일 귀속 학습 기준선보다 우수하며 오프라인 메트릭에서 +0.51% GAUC 향상을 기록했습니다. 온라인 실험에서는 ROI가 +2.6% 증가했습니다.

Conclusion: MAL 프레임워크는 산업 배포 요구 사항과의 직접적인 호환성을 보장하고, 귀속 신호의 성능을 크게 향상시킵니다.

Abstract: Conversion rate (CVR) prediction is a core component of online advertising
systems, where the attribution mechanisms-rules for allocating conversion
credit across user touchpoints-fundamentally determine label generation and
model optimization. While many industrial platforms support diverse attribution
mechanisms (e.g., First-Click, Last-Click, Linear, and Data-Driven Multi-Touch
Attribution), conventional approaches restrict model training to labels from a
single production-critical attribution mechanism, discarding complementary
signals in alternative attribution perspectives.
  To address this limitation, we propose a novel Multi-Attribution Learning
(MAL) framework for CVR prediction that integrates signals from multiple
attribution perspectives to better capture the underlying patterns driving user
conversions. Specifically, MAL is a joint learning framework consisting of two
core components: the Attribution Knowledge Aggregator (AKA) and the Primary
Target Predictor (PTP). AKA is implemented as a multi-task learner that
integrates knowledge extracted from diverse attribution labels. PTP, in
contrast, focuses on the task of generating well-calibrated conversion
probabilities that align with the system-optimized attribution metric (e.g.,
CVR under the Last-Click attribution), ensuring direct compatibility with
industrial deployment requirements. Additionally, we propose CAT, a novel
training strategy that leverages the Cartesian product of all attribution label
combinations to generate enriched supervision signals. This design
substantially enhances the performance of the attribution knowledge aggregator.
Empirical evaluations demonstrate the superiority of MAL over
single-attribution learning baselines, achieving +0.51% GAUC improvement on
offline metrics. Online experiments demonstrate that MAL achieved a +2.6%
increase in ROI (Return on Investment).

</details>


### [86] [Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models](https://arxiv.org/abs/2508.15220)
*Aniruddha Joshi,Supratik Chakraborty,S Akshay,Shetal Shah,Hazem Torfah,Sanjit Seshia*

Main category: cs.LG

TL;DR: 이 논문은 블랙박스 머신러닝 모델의 해석에서 정확성과 설명 가능성 간의 균형을 맞추기 위한 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 블랙박스 머신러닝 모델의 신뢰할 수 있는 해석을 개발하기 위해서는 정확성과 설명 가능성 간의 상충하는 목표를 탐구하는 것이 필수적이다.

Method: 이 프레임워크는 부분 최적 공간을 탐색하면서 지역 최적성 보장을 통해 해석의 합성을 보다 확장 가능하게 한다.

Result: 우리는 다수의 벤치마크에서 우리의 접근 방식의 효율성을 입증하며, 기존 방법과 비교하여 해석의 부분 최적 경계를 탐색할 때의 성능을 보여준다.

Conclusion: 우리의 방법은 전역 보장을 제공하는 방법에서 합성된 해석과 밀접하게 일치하는 해석을 산출한다.

Abstract: Creating meaningful interpretations for black-box machine learning models
involves balancing two often conflicting objectives: accuracy and
explainability. Exploring the trade-off between these objectives is essential
for developing trustworthy interpretations. While many techniques for
multi-objective interpretation synthesis have been developed, they typically
lack formal guarantees on the Pareto-optimality of the results. Methods that do
provide such guarantees, on the other hand, often face severe scalability
limitations when exploring the Pareto-optimal space. To address this, we
develop a framework based on local optimality guarantees that enables more
scalable synthesis of interpretations. Specifically, we consider the problem of
synthesizing a set of Pareto-optimal interpretations with local optimality
guarantees, within the immediate neighborhood of each solution. Our approach
begins with a multi-objective learning or search technique, such as
Multi-Objective Monte Carlo Tree Search, to generate a best-effort set of
Pareto-optimal candidates with respect to accuracy and explainability. We then
verify local optimality for each candidate as a Boolean satisfiability problem,
which we solve using a SAT solver. We demonstrate the efficacy of our approach
on a set of benchmarks, comparing it against previous methods for exploring the
Pareto-optimal front of interpretations. In particular, we show that our
approach yields interpretations that closely match those synthesized by methods
offering global guarantees.

</details>


### [87] [Learning ECG Representations via Poly-Window Contrastive Learning](https://arxiv.org/abs/2508.15225)
*Yi Yuan,Joseph Van Duyn,Runze Yan,Zhuoyi Huang,Sulaiman Vesal,Sergey Plis,Xiao Hu,Gloria Hyunjung Kwak,Ran Xiao,Alex Fedorov*

Main category: cs.LG

TL;DR: 본 연구는 다중 윈도우 대비 학습 프레임워크를 제안하여 심전도(ECG) 분석의 효율성을 높이기 위해 기존 방법의 한계를 극복합니다.


<details>
  <summary>Details</summary>
Motivation: 심전도 분석이 심혈관 질환 진단에 필수적이며, 그러나 주석 데이터의 제한으로 인해 딥러닝 모델의 성능이 제약 받는다.

Method: 각 ECG 인스턴스에서 여러 시간 창을 추출하여 긍정적 쌍을 구성하고 통계를 통해 일치를 극대화하는 다중 창 대비 학습 프레임워크를 제시한다.

Result: 다중 라벨 상위 클래스 분류에서 기존 두 개의 뷰 방법을 지속적으로 능가하며, 더 높은 AUROC(0.891 대 0.888) 및 F1 점수(0.680 대 0.679)와 함께 최대 4배 적은 사전 학습 에포크(32 대 128) 및 전체 학습 시간의 14.8% 감소를 달성했다.

Conclusion: 다중 창 대비 학습은 자동화된 ECG 분석을 위한 매우 효율적이고 확장 가능한 패러다임으로 자리 잡았으며, 생물 의학 시간 시계열 데이터에서 자가 감독 표현 학습을 위한 유망한 일반 프레임워크를 제공한다.

Abstract: Electrocardiogram (ECG) analysis is foundational for cardiovascular disease
diagnosis, yet the performance of deep learning models is often constrained by
limited access to annotated data. Self-supervised contrastive learning has
emerged as a powerful approach for learning robust ECG representations from
unlabeled signals. However, most existing methods generate only pairwise
augmented views and fail to leverage the rich temporal structure of ECG
recordings. In this work, we present a poly-window contrastive learning
framework. We extract multiple temporal windows from each ECG instance to
construct positive pairs and maximize their agreement via statistics. Inspired
by the principle of slow feature analysis, our approach explicitly encourages
the model to learn temporally invariant and physiologically meaningful features
that persist across time. We validate our approach through extensive
experiments and ablation studies on the PTB-XL dataset. Our results demonstrate
that poly-window contrastive learning consistently outperforms conventional
two-view methods in multi-label superclass classification, achieving higher
AUROC (0.891 vs. 0.888) and F1 scores (0.680 vs. 0.679) while requiring up to
four times fewer pre-training epochs (32 vs. 128) and 14.8% in total wall clock
pre-training time reduction. Despite processing multiple windows per sample, we
achieve a significant reduction in the number of training epochs and total
computation time, making our method practical for training foundational models.
Through extensive ablations, we identify optimal design choices and demonstrate
robustness across various hyperparameters. These findings establish poly-window
contrastive learning as a highly efficient and scalable paradigm for automated
ECG analysis and provide a promising general framework for self-supervised
representation learning in biomedical time-series data.

</details>


### [88] [Deep Think with Confidence](https://arxiv.org/abs/2508.15260)
*Yichao Fu,Xuewei Wang,Yuandong Tian,Jiawei Zhao*

Main category: cs.LG

TL;DR: DeepConf는 추론 효율성과 성능을 향상시키는 새로운 접근 방식을 제안하며, 기존 모델을 추가로 훈련시키지 않고도 최적의 결과를 도출합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)은 대부분 투표에 의한 자기 일관성과 같은 테스트 시간 스케일링 방법을 통해 추론 작업에서 큰 잠재력을 보여주었습니다. 그러나 이러한 접근 방식은 종종 정확도의 수익 감소와 높은 계산 오버헤드를 초래합니다.

Method: DeepConf는 모델 내부 신뢰 신호를 활용하여 생성 중 또는 이후에 저품질 추론 흔적을 동적으로 필터링하는 간단하면서도 강력한 방법입니다.

Result: DeepConf는 Qwen 3 및 GPT-OSS 시리즈를 포함한 다양한 추론 작업 및 최신 오픈 소스 모델에 대해 평가되었습니다. 특히 AIME 2025와 같은 도전적인 기준에서 DeepConf@512는 최대 99.9%의 정확도를 달성하고 완전한 병렬 사고에 비해 생성된 토큰을 최대 84.7% 줄입니다.

Conclusion: DeepConf는 추가 모델 훈련이나 하이퍼파라미터 조정 없이 기존 서비스 프레임워크에 원활하게 통합될 수 있어, 추론 작업에서의 효율성과 성능을 크게 향상시킵니다.

Abstract: Large Language Models (LLMs) have shown great potential in reasoning tasks
through test-time scaling methods like self-consistency with majority voting.
However, this approach often leads to diminishing returns in accuracy and high
computational overhead. To address these challenges, we introduce Deep Think
with Confidence (DeepConf), a simple yet powerful method that enhances both
reasoning efficiency and performance at test time. DeepConf leverages
model-internal confidence signals to dynamically filter out low-quality
reasoning traces during or after generation. It requires no additional model
training or hyperparameter tuning and can be seamlessly integrated into
existing serving frameworks. We evaluate DeepConf across a variety of reasoning
tasks and the latest open-source models, including Qwen 3 and GPT-OSS series.
Notably, on challenging benchmarks such as AIME 2025, DeepConf@512 achieves up
to 99.9% accuracy and reduces generated tokens by up to 84.7% compared to full
parallel thinking.

</details>


### [89] [Evaluating Knowledge Graph Complexity via Semantic, Spectral, and Structural Metrics for Link Prediction](https://arxiv.org/abs/2508.15291)
*Haji Gul,Abul Ghani Naim,Ajaz Ahmad Bhat*

Main category: cs.LG

TL;DR: 데이터셋 복잡성을 이해하는 것은 지식 그래프에서 링크 예측 모델을 평가하고 비교하는 데 필수적이다. Cumulative Spectral Gradient (CSG) 메트릭은 지금까지 지식 그래프에서 평가되지 않았다. 본 연구에서는 다중 관계 링크 예측 맥락에서 CSG를 비판적으로 검토하고, 새로운 구조적 및 의미적 KG 복잡성 메트릭을 도입하여 표시한다.


<details>
  <summary>Details</summary>
Motivation: 링크 예측 모델의 평가와 비교를 위해 데이터셋 복잡성을 이해하는 것이 필수적이다.

Method: CSG를 다중 관계 링크 예측으로 비판적으로 검토하고, 성능 메트릭과의 상관관계를 분석한다.

Result: CSG는 파라미터 조정에 매우 민감하며, MRR 및 Hit@1과의 상관관계가 약하거나 일관되지 않음을 발견하였다.

Conclusion: CSG의 안정성과 일반화 예측력은 링크 예측 환경에서 유지되지 않으며, 보다 안정적이고 해석 가능한 데이터셋 복잡성 측정이 필요하다.

Abstract: Understanding dataset complexity is fundamental to evaluating and comparing
link prediction models on knowledge graphs (KGs). While the Cumulative Spectral
Gradient (CSG) metric, derived from probabilistic divergence between classes
within a spectral clustering framework, has been proposed as a classifier
agnostic complexity metric purportedly scaling with class cardinality and
correlating with downstream performance, it has not been evaluated in KG
settings so far. In this work, we critically examine CSG in the context of
multi relational link prediction, incorporating semantic representations via
transformer derived embeddings. Contrary to prior claims, we find that CSG is
highly sensitive to parametrisation and does not robustly scale with the number
of classes. Moreover, it exhibits weak or inconsistent correlation with
standard performance metrics such as Mean Reciprocal Rank (MRR) and Hit@1. To
deepen the analysis, we introduce and benchmark a set of structural and
semantic KG complexity metrics. Our findings reveal that global and local
relational ambiguity captured via Relation Entropy, node level Maximum Relation
Diversity, and Relation Type Cardinality exhibit strong inverse correlations
with MRR and Hit@1, suggesting these as more faithful indicators of task
difficulty. Conversely, graph connectivity measures such as Average Degree,
Degree Entropy, PageRank, and Eigenvector Centrality correlate positively with
Hit@10. Our results demonstrate that CSGs purported stability and
generalization predictive power fail to hold in link prediction settings and
underscore the need for more stable, interpretable, and task-aligned measures
of dataset complexity in knowledge driven learning.

</details>


### [90] [Saving for the future: Enhancing generalization via partial logic regularization](https://arxiv.org/abs/2508.15317)
*Zhaorui Tan,Yijie Hu,Xi Yang,Qiufeng Wang,Anh Nguyen,Kaizhu Huang*

Main category: cs.LG

TL;DR: PL-Reg는 정의되지 않은 논리 공식을 위한 공간을 예약하여 미지의 클래스에 대한 적응력을 향상시키는 새로운 부분 논리 정규화 기법이다.


<details>
  <summary>Details</summary>
Motivation: 비주얼 분류 작업에서의 일반화 문제와 미지의 클래스를 다룰 때의 도전 과제를 해결하기 위함이다.

Method: PL-Reg는 정의되지 않은 논리 공식을 위한 공간을 허용하는 새로운 부분 논리 정규화 용어로, 미지의 클래스에 대한 적응력을 개선한다.

Result: PL-Reg는 Generalized Category Discovery, Multi-Domain Generalized Category Discovery 및 긴 꼬리 클래스 점진적 학습 작업에 대한 광범위한 실험을 통해 일관된 성능 개선을 보여준다.

Conclusion: 부분 논리는 미지의 클래스와 관련된 문제를 해결하는 데 효과적임을 강조한다.

Abstract: Generalization remains a significant challenge in visual classification
tasks, particularly in handling unknown classes in real-world applications.
Existing research focuses on the class discovery paradigm, which tends to favor
known classes, and the incremental learning paradigm, which suffers from
catastrophic forgetting. Recent approaches such as the L-Reg technique employ
logic-based regularization to enhance generalization but are bound by the
necessity of fully defined logical formulas, limiting flexibility for unknown
classes. This paper introduces PL-Reg, a novel partial-logic regularization
term that allows models to reserve space for undefined logic formulas,
improving adaptability to unknown classes. Specifically, we formally
demonstrate that tasks involving unknown classes can be effectively explained
using partial logic. We also prove that methods based on partial logic lead to
improved generalization. We validate PL-Reg through extensive experiments on
Generalized Category Discovery, Multi-Domain Generalized Category Discovery,
and long-tailed Class Incremental Learning tasks, demonstrating consistent
performance improvements. Our results highlight the effectiveness of partial
logic in tackling challenges related to unknown classes.

</details>


### [91] [ExBigBang: A Dynamic Approach for Explainable Persona Classification through Contextualized Hybrid Transformer Analysis](https://arxiv.org/abs/2508.15364)
*Saleh Afzoon,Amin Beheshti,Nabi Rezvani,Farshad Khunjush,Usman Naseem,John McMahon,Zahra Fathollahi,Mahdieh Labani,Wathiq Mansoor,Xuyun Zhang*

Main category: cs.LG

TL;DR: 이 논문은 사용자 중심 디자인에서 페르소나 개발의 중요성과 복잡한 사용자 상호작용에 대응하기 위해 ExBigBang이라는 하이브리드 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 사용자 중심 디자인에서 페르소나 발전이 사용자 행동 이해 및 디자인 결정 지침에 필수적이다.

Method: ExBigBang은 transformer 기반 아키텍처를 사용하여 페르소나 분류를 위한 풍부한 맥락적 특징을 모델링하는 하이브리드 텍스트-표 접근 방식이다.

Result: 벤치마크 페르소나 분류 데이터셋에서 모델의 강건성을 입증하며, 텍스트와 표 데이터의 결합 이점을 확인했다.

Conclusion: 설명 가능한 AI 기법은 모델의 예측에 대한 근거를 밝히는 데 기여한다.

Abstract: In user-centric design, persona development plays a vital role in
understanding user behaviour, capturing needs, segmenting audiences, and
guiding design decisions. However, the growing complexity of user interactions
calls for a more contextualized approach to ensure designs align with real user
needs. While earlier studies have advanced persona classification by modelling
user behaviour, capturing contextual information, especially by integrating
textual and tabular data, remains a key challenge. These models also often lack
explainability, leaving their predictions difficult to interpret or justify. To
address these limitations, we present ExBigBang (Explainable BigBang), a hybrid
text-tabular approach that uses transformer-based architectures to model rich
contextual features for persona classification. ExBigBang incorporates
metadata, domain knowledge, and user profiling to embed deeper context into
predictions. Through a cyclical process of user profiling and classification,
our approach dynamically updates to reflect evolving user behaviours.
Experiments on a benchmark persona classification dataset demonstrate the
robustness of our model. An ablation study confirms the benefits of combining
text and tabular data, while Explainable AI techniques shed light on the
rationale behind the model's predictions.

</details>


### [92] [Enhancing Forecasting with a 2D Time Series Approach for Cohort-Based Data](https://arxiv.org/abs/2508.15369)
*Yonathan Guttel,Orit Moradov,Nachi Lieder,Asnat Greenstein-Messica*

Main category: cs.LG

TL;DR: 이 논문은 2D 시계열 예측 모델을 소개하며, 작은 데이터 환경에서의 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 작은 데이터 환경에서의 시계열 예측의 어려움을 해결하고자 합니다.

Method: 코호트 행동을 통합한 새로운 2D 시계열 예측 모델을 제안합니다.

Result: 실제 데이터 세트를 사용하여 기존 모델보다 정확도와 적응성을 향상시킨 성능을 보여줍니다.

Conclusion: 재무 및 마케팅 예측 문제에 직면한 산업의 전략적 의사결정에 유용한 통찰력을 제공합니다.

Abstract: This paper introduces a novel two-dimensional (2D) time series forecasting
model that integrates cohort behavior over time, addressing challenges in small
data environments. We demonstrate its efficacy using multiple real-world
datasets, showcasing superior performance in accuracy and adaptability compared
to reference models. The approach offers valuable insights for strategic
decision-making across industries facing financial and marketing forecasting
challenges.

</details>


### [93] [Fairness for the People, by the People: Minority Collective Action](https://arxiv.org/abs/2508.15374)
*Omri Ben-Dov,Samira Samadi,Amartya Sanyal,Alexandru Ţifrea*

Main category: cs.LG

TL;DR: 기계 학습 모델은 훈련 데이터에 있는 편향을 그대로 유지하여 특정 소수 집단에 대한 불공정한 대우를 초래합니다. 이러한 편향 완화 기술이 존재하지만, 일반적으로 효용 비용이 발생하고 조직의 동의가 필요합니다. 본 논문에서는 사용자 기여 데이터를 활용하여 소수 집단이 전략적으로 자체 데이터를 재라벨링함으로써 불공정을 개선할 수 있는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 모델이 훈련 데이터의 편향을 계속해서 유지하고 있으며, 이로 인해 특정 소수 집단이 불공정한 대우를 받고 있다는 문제를 해결하고자 합니다.

Method: 사용자 기여 데이터를 활용하여 소수 집단이 데이터를 전략적으로 재라벨링하는 알고리즘적 집합 행동의 프레임워크를 제안하고, 이와 관련된 세 가지 실용적이고 모델에 구애받지 않는 방법을 구현합니다.

Result: 모델을 통해 이상적인 재라벨링을 구현하고, 실제 데이터셋에서 이 방법을 검증했습니다. 소수 집단의 하위 그룹이 전체 예측 오류에 미치는 작은 영향을 가지면서 불공정을 상당히 줄일 수 있다는 것을 발견했습니다.

Conclusion: 소수 집단이 조직의 훈련 과정에 변화를 주지 않고도 불공정을 개선할 수 있는 가능성을 보여줍니다.

Abstract: Machine learning models often preserve biases present in training data,
leading to unfair treatment of certain minority groups. Despite an array of
existing firm-side bias mitigation techniques, they typically incur utility
costs and require organizational buy-in. Recognizing that many models rely on
user-contributed data, end-users can induce fairness through the framework of
Algorithmic Collective Action, where a coordinated minority group strategically
relabels its own data to enhance fairness, without altering the firm's training
process. We propose three practical, model-agnostic methods to approximate
ideal relabeling and validate them on real-world datasets. Our findings show
that a subgroup of the minority can substantially reduce unfairness with a
small impact on the overall prediction error.

</details>


### [94] [EvoFormer: Learning Dynamic Graph-Level Representations with Structural and Temporal Bias Correction](https://arxiv.org/abs/2508.15378)
*Haodi Zhong,Liuxin Zou,Di Wang,Bo Wang,Zhenxing Niu,Quan Wang*

Main category: cs.LG

TL;DR: EvoFormer라는 동적 그래프 임베딩 프레임워크는 고유의 구조적 진화 변화를 인식하여, 기존의 문제점인 구조적 방문 편향과 갑작스러운 진화 블라인드를 해결하는 데 초점을 맞춥니다.


<details>
  <summary>Details</summary>
Motivation: 동적 그래프 수준의 임베딩은 네트워크에서의 구조적 진화를 포착하여 실제 시나리오를 모델링하는 데 필수적입니다.

Method: EvoFormer는 구조 인지 변환기 모듈과 진화 민감한 시간 모듈을 설계하여, 그래프의 구조적 역할에 기반한 위치 인코딩을 사용하고, 세 단계의 전략으로 시간적 진화를 모델링합니다.

Result: EvoFormer는 다섯 개의 벤치마크 데이터셋에서 그래프 유사성 순위, 시간적 이상 탐지, 시간적 세분화 작업에서 최신 성과를 달성하였습니다.

Conclusion: EvoFormer는 구조적 및 시간적 편향을 수정하는 데 효과적임을 입증하였습니다.

Abstract: Dynamic graph-level embedding aims to capture structural evolution in
networks, which is essential for modeling real-world scenarios. However,
existing methods face two critical yet under-explored issues: Structural Visit
Bias, where random walk sampling disproportionately emphasizes high-degree
nodes, leading to redundant and noisy structural representations; and Abrupt
Evolution Blindness, the failure to effectively detect sudden structural
changes due to rigid or overly simplistic temporal modeling strategies,
resulting in inconsistent temporal embeddings. To overcome these challenges, we
propose EvoFormer, an evolution-aware Transformer framework tailored for
dynamic graph-level representation learning. To mitigate Structural Visit Bias,
EvoFormer introduces a Structure-Aware Transformer Module that incorporates
positional encoding based on node structural roles, allowing the model to
globally differentiate and accurately represent node structures. To overcome
Abrupt Evolution Blindness, EvoFormer employs an Evolution-Sensitive Temporal
Module, which explicitly models temporal evolution through a sequential
three-step strategy: (I) Random Walk Timestamp Classification, generating
initial timestamp-aware graph-level embeddings; (II) Graph-Level Temporal
Segmentation, partitioning the graph stream into segments reflecting
structurally coherent periods; and (III) Segment-Aware Temporal Self-Attention
combined with an Edge Evolution Prediction task, enabling the model to
precisely capture segment boundaries and perceive structural evolution trends,
effectively adapting to rapid temporal shifts. Extensive evaluations on five
benchmark datasets confirm that EvoFormer achieves state-of-the-art performance
in graph similarity ranking, temporal anomaly detection, and temporal
segmentation tasks, validating its effectiveness in correcting structural and
temporal biases.

</details>


### [95] [CITE: A Comprehensive Benchmark for Heterogeneous Text-Attributed Graphs on Catalytic Materials](https://arxiv.org/abs/2508.15392)
*Chenghao Zhang,Qingqing Long,Ludi Wang,Wenjuan Cui,Jianjun Yu,Yi Du*

Main category: cs.LG

TL;DR: CITE는 첫 번째이자 최대 규모의 이질적 텍스트 속성 인용 그래프 벤치마크로, 438K개의 노드와 1.2M개의 엣지를 포함하고 있어 다양한 노드 및 엣지 유형을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 이질적인 텍스트 속성 그래프에 대한 대규모 벤치마크 데이터셋이 부족하여 표현 학습 방법의 개발과 공정한 비교가 저해되고 있다.

Method: CITE 데이터셋을 소개하고, 노드 분류 작업에 대한 평가 절차와 다양한 모델링 패러다임 간의 기준선 및 제거 실험을 수행했다.

Result: CITE는 438K개의 노드와 1.2M개의 엣지를 포함하며, 4가지 관계 유형을 아우른다.

Conclusion: 이 연구는 CITE 데이터셋 개요, 표준화된 평가 프로토콜, 다양한 모델링 패러다임에 대한 기준선 및 제거 실험을 제공한다.

Abstract: Text-attributed graphs(TAGs) are pervasive in real-world systems,where each
node carries its own textual features. In many cases these graphs are
inherently heterogeneous, containing multiple node types and diverse edge
types. Despite the ubiquity of such heterogeneous TAGs, there remains a lack of
large-scale benchmark datasets. This shortage has become a critical bottleneck,
hindering the development and fair comparison of representation learning
methods on heterogeneous text-attributed graphs. In this paper, we introduce
CITE - Catalytic Information Textual Entities Graph, the first and largest
heterogeneous text-attributed citation graph benchmark for catalytic materials.
CITE comprises over 438K nodes and 1.2M edges, spanning four relation types. In
addition, we establish standardized evaluation procedures and conduct extensive
benchmarking on the node classification task, as well as ablation experiments
on the heterogeneous and textual properties of CITE. We compare four classes of
learning paradigms, including homogeneous graph models, heterogeneous graph
models, LLM(Large Language Model)-centric models, and LLM+Graph models. In a
nutshell, we provide (i) an overview of the CITE dataset, (ii) standardized
evaluation protocols, and (iii) baseline and ablation experiments across
diverse modeling paradigms.

</details>


### [96] [Federated Learning based on Self-Evolving Gaussian Clustering](https://arxiv.org/abs/2508.15393)
*Miha Ožbot,Igor Škrjanc*

Main category: cs.LG

TL;DR: 본 연구는 군집 추가에 따라 동적으로 적응하는 진화 퍼지 시스템을 제안하며, 사전 군집 수 선택이 필요 없는 연합 학습 맥락에서 진행된다.


<details>
  <summary>Details</summary>
Motivation: 데이터 프라이버시 문제를 해결하고, 모델을 클라이언트의 장치에서 로컬로 학습할 수 있는 방법을 모색하기 위해 연합 학습을 활용한다.

Method: PyTorch를 사용하여 구현된 진화 퍼지 시스템으로, 데이터 대신 모델 매개변수만을 중앙 서버와 공유하는 방식으로 군집화 및 분류 작업에 대해 테스트된다.

Result: 여러 잘 알려진 UCI 데이터 세트에서 기존의 분류 방법보다 우수한 성능을 보였다.

Conclusion: 제안된 방법은 중첩 조건 계산으로 인해 컴퓨팅 집약적이지만, 분산 데이터 처리에서 상당한 이점을 보여준다.

Abstract: In this study, we present an Evolving Fuzzy System within the context of
Federated Learning, which adapts dynamically with the addition of new clusters
and therefore does not require the number of clusters to be selected apriori.
Unlike traditional methods, Federated Learning allows models to be trained
locally on clients' devices, sharing only the model parameters with a central
server instead of the data. Our method, implemented using PyTorch, was tested
on clustering and classification tasks. The results show that our approach
outperforms established classification methods on several well-known UCI
datasets. While computationally intensive due to overlap condition
calculations, the proposed method demonstrates significant advantages in
decentralized data processing.

</details>


### [97] [Hybrid Least Squares/Gradient Descent Methods for DeepONets](https://arxiv.org/abs/2508.15394)
*Jun Choi,Chang-Ock Lee,Minam Moon*

Main category: cs.LG

TL;DR: 효율적인 하이브리드 최소제곱/경량 하강 방법을 제안하여 DeepONet 훈련을 가속화합니다.


<details>
  <summary>Details</summary>
Motivation: DeepONet 훈련 속도를 높이기 위한 효율적인 최적화 방법 필요.

Method: 크고 복잡한 최소제곱 시스템을 두 개의 더 작은 하위 문제로 분해하여 각각을 해결하는 방법.

Result: DeepONet의 마지막 레이어 파라미터와 관련된 최적화를 개선하여 훈련 속도를 높입니다.

Conclusion: 제안된 방법은 마지막 레이어 파라미터에 대한 정규화 항을 포함한 보다 일반적인 $L^2$ 손실 유형에 일반화됩니다.

Abstract: We propose an efficient hybrid least squares/gradient descent method to
accelerate DeepONet training. Since the output of DeepONet can be viewed as
linear with respect to the last layer parameters of the branch network, these
parameters can be optimized using a least squares (LS) solve, and the remaining
hidden layer parameters are updated by means of gradient descent form. However,
building the LS system for all possible combinations of branch and trunk inputs
yields a prohibitively large linear problem that is infeasible to solve
directly. To address this issue, our method decomposes the large LS system into
two smaller, more manageable subproblems $\unicode{x2014}$ one for the branch
network and one for the trunk network $\unicode{x2014}$ and solves them
separately. This method is generalized to a broader type of $L^2$ loss with a
regularization term for the last layer parameters, including the case of
unsupervised learning with physics-informed loss.

</details>


### [98] [Bridging Generalization and Personalization in Wearable Human Activity Recognition via On-Device Few-Shot Learning](https://arxiv.org/abs/2508.15413)
*Pixi Kang,Julian Moosmann,Mengxi Liu,Bo Zhou,Michele Magno,Paul Lukowicz,Sizhen Bian*

Main category: cs.LG

TL;DR: 웨어러블 장치를 이용한 인간 활동 인식(HAR) 기술이 발전했지만, 새로운 사용자에게 모델을 배포할 때 일반화에 한계가 있다. 본 논문에서는 사용자 간 일반화 후 개별 사용자에 빠르게 적응하는 하이브리드 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 모델이 새로운 사용자에게 배포될 때 발생하는 성능 저하는 주로 사용자 유도 개념 변화(UICD) 때문이다. 효율적인 개인화의 중요성이 강조된다.

Method: 본 연구에서는 사용자 간 일반화 후 몇 가지 샷 학습을 통해 기기에 직접 개인화하는 하이브리드 프레임워크를 제안한다. 사용자 특정 데이터를 기반으로 분류기 레이어만 업데이트한다.

Result: 세 가지 다양한 HAR 시나리오(RecGym, QVAR-Gesture, Ultrasound-Gesture)에서 일관된 정확도 향상(각각 3.73%, 17.38%, 3.70%)을 확인하였다.

Conclusion: 빠르고 가벼우며 효과적인 개인화가 임베디드 플랫폼에서 가능함을 확인, 이는 규모 확장 가능하고 사용자 인식이 가능한 HAR 시스템을 위한 길을 열어준다.

Abstract: Human Activity Recognition (HAR) using wearable devices has advanced
significantly in recent years, yet its generalization remains limited when
models are deployed to new users. This degradation in performance is primarily
due to user-induced concept drift (UICD), highlighting the importance of
efficient personalization. In this paper, we present a hybrid framework that
first generalizes across users and then rapidly adapts to individual users
using few-shot learning directly on-device. By updating only the classifier
layer with user-specific data, our method achieves robust personalization with
minimal computational and memory overhead. We implement this framework on the
energy-efficient RISC-V-based GAP9 microcontroller and validate it across three
diverse HAR scenarios: RecGym, QVAR-Gesture, and Ultrasound-Gesture.
Post-deployment adaptation yields consistent accuracy improvements of 3.73\%,
17.38\%, and 3.70\% respectively. These results confirm that fast, lightweight,
and effective personalization is feasible on embedded platforms, paving the way
for scalable and user-aware HAR systems in the wild
\footnote{https://github.com/kangpx/onlineTiny2023}.

</details>


### [99] [Measures of Overlapping Multivariate Gaussian Clusters in Unsupervised Online Learning](https://arxiv.org/abs/2508.15444)
*Miha Ožbot,Igor Škrjanc*

Main category: cs.LG

TL;DR: 본 논문에서는 다변량 가우시안 클러스터의 중첩을 탐지하기 위한 새로운 측정 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 온라인 학습의 목표는 스트리밍 데이터의 개념적 변화에 따라 시간이 지남에 따라 적응할 수 있는 클러스터링, 분류 또는 회귀 모델을 생성하는 것입니다.

Method: 우리의 제안된 비유사성 측정은 중첩을 탐지하는 데 특별히 설계되었으며 기존 측정 방법에 비해 더 빠르게 계산할 수 있습니다.

Result: 우리 방법은 다른 방법에 비해 여러 배 빠르며 직교 클러스터의 병합을 피하면서 중첩된 클러스터를 감지하는 능력을 갖추고 있습니다.

Conclusion: 제안된 방법은 온라인 학습에서 다변량 가우시안 클러스터의 중첩 탐지에 효과적입니다.

Abstract: In this paper, we propose a new measure for detecting overlap in multivariate
Gaussian clusters. The aim of online learning from data streams is to create
clustering, classification, or regression models that can adapt over time based
on the conceptual drift of streaming data. In the case of clustering, this can
result in a large number of clusters that may overlap and should be merged.
Commonly used distribution dissimilarity measures are not adequate for
determining overlapping clusters in the context of online learning from
streaming data due to their inability to account for all shapes of clusters and
their high computational demands. Our proposed dissimilarity measure is
specifically designed to detect overlap rather than dissimilarity and can be
computed faster compared to existing measures. Our method is several times
faster than compared methods and is capable of detecting overlapping clusters
while avoiding the merging of orthogonal clusters.

</details>


### [100] [Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection](https://arxiv.org/abs/2508.15449)
*Chengcan Wu,Zeming Wei,Huanran Chen,Yinpeng Dong,Meng Sun*

Main category: cs.LG

TL;DR: 이 논문에서는 기계 학습 모델의 안전성을 확보하기 위해 비가역적 투영 기법을 적용한 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 안전성 문제에 대한 우려가 커짐에 따라 기계 비 학습이 중요한 연구 주제로 부각되고 있다.

Method: 비가역적 프로젝션 특성을 사용하여 특정 네트워크 레이어의 은닉 상태 공간에서 투영 변환을 구현한다.

Result: 실험 결과, 제안한 방법이 효과적인 연속 비 학습을 가능하게 하며 재학습 공격에 대해 성공적으로 방어함을 보여준다.

Conclusion: 제안된 방법은 비 학습의 효과에서 최신 성능을 달성하면서 자연스러운 성능을 유지하게 한다.

Abstract: While Large Language Models (LLMs) have demonstrated impressive performance
in various domains and tasks, concerns about their safety are becoming
increasingly severe. In particular, since models may store unsafe knowledge
internally, machine unlearning has emerged as a representative paradigm to
ensure model safety. Existing approaches employ various training techniques,
such as gradient ascent and negative preference optimization, in attempts to
eliminate the influence of undesired data on target models. However, these
methods merely suppress the activation of undesired data through parametric
training without completely eradicating its informational traces within the
model. This fundamental limitation makes it difficult to achieve effective
continuous unlearning, rendering these methods vulnerable to relearning
attacks. To overcome these challenges, we propose a Metamorphosis
Representation Projection (MRP) approach that pioneers the application of
irreversible projection properties to machine unlearning. By implementing
projective transformations in the hidden state space of specific network
layers, our method effectively eliminates harmful information while preserving
useful knowledge. Experimental results demonstrate that our approach enables
effective continuous unlearning and successfully defends against relearning
attacks, achieving state-of-the-art performance in unlearning effectiveness
while preserving natural performance. Our code is available in
https://github.com/ChengcanWu/MRP.

</details>


### [101] [A Solvable Molecular Switch Model for Stable Temporal Information Processing](https://arxiv.org/abs/2508.15451)
*H. I. Nurdin,C. A. Nijhuis*

Main category: cs.LG

TL;DR: 이 논문은 뇌의 시냅스처럼 작동하는 동적 분자 스위치를 위해 개발된 입력 기반의 일계 차분 방정식 모델을 연구한다.


<details>
  <summary>Details</summary>
Motivation: 생물학적으로 영감을 받은 행동과 안정적인 학습 수행을 위한 수학적 특성을 동시에 가진 모델의 개발.

Method: 선형 상태 및 비선형 입력을 가진 모델을 사용하여 실험적으로 입증된 동적 분자 스위치를 모델링하고 분석한다.

Result: 모델은 시간에 따라 변하는 입력에 대한 안정적인 처리를 가능하게 하는 수렴 및 감쇠 메모리의 수학적 속성을 가진다.

Conclusion: 이 결과는 심층 피드포워드 및 순환 아키텍처를 포함하여 생물 모방 컴퓨팅을 위한 컴퓨팅 유닛으로 동적 분자 스위치 사용의 이론적 지지를 제공한다.

Abstract: This paper studies an input-driven one-state differential equation model
initially developed for an experimentally demonstrated dynamic molecular switch
that switches like synapses in the brain do. The linear-in-the-state and
nonlinear-in-the-input model is exactly solvable, and it is shown that it also
possesses mathematical properties of convergence and fading memory that enable
stable processing of time-varying inputs by nonlinear dynamical systems. Thus,
the model exhibits the co-existence of biologically-inspired behavior and
desirable mathematical properties for stable learning on sequential data. The
results give theoretical support for the use of the dynamic molecular switches
as computational units in deep cascaded/layered feedforward and recurrent
architectures as well as other more general structures for neuromorphic
computing. They could also inspire more general exactly solvable models that
can be fitted to emulate arbitrary physical devices which can mimic
brain-inspired behaviour and perform stable computation on input signals.

</details>


### [102] [Mini-Batch Robustness Verification of Deep Neural Networks](https://arxiv.org/abs/2508.15454)
*Saar Tzour-Shaday,Dana Drachsler Cohen*

Main category: cs.LG

TL;DR: 제안된 BaVerLy는 그룹 로컬 강건성 검증을 통해 효율성을 개선하여, 입력 집합의 분석 시간을 단축시킵니다.


<details>
  <summary>Details</summary>
Motivation: 신경망 이미지 분류기는 안전-critical 애플리케이션에서 널리 사용되나, 적대적 공격에 취약합니다. 이를 이해하기 위한 로컬 강건성 검증 도구가 필요합니다.

Method: BaVerLy는 동적으로 미니 배치를 구성하여 유사한 네트워크 계산을 가진 $	extepsilon$-볼을 공동으로 검증합니다. 검증된 미니 배치는 모든 $	extepsilon$-볼이 강건함을 보장합니다.

Result: BaVerLy는 MNIST와 CIFAR-10을 테스트한 결과, 기존의 검증 방법에 비해 평균 2.3배, 최대 4.1배로 분석 시간을 단축했습니다.

Conclusion: 이 방법은 24시간에서 6시간으로 총 분석 시간을 줄이며, 로컬 강건성 검증을 향상시킵니다.

Abstract: Neural network image classifiers are ubiquitous in many safety-critical
applications. However, they are susceptible to adversarial attacks. To
understand their robustness to attacks, many local robustness verifiers have
been proposed to analyze $\epsilon$-balls of inputs. Yet, existing verifiers
introduce a long analysis time or lose too much precision, making them less
effective for a large set of inputs. In this work, we propose a new approach to
local robustness: group local robustness verification. The key idea is to
leverage the similarity of the network computations of certain $\epsilon$-balls
to reduce the overall analysis time. We propose BaVerLy, a sound and complete
verifier that boosts the local robustness verification of a set of
$\epsilon$-balls by dynamically constructing and verifying mini-batches.
BaVerLy adaptively identifies successful mini-batch sizes, accordingly
constructs mini-batches of $\epsilon$-balls that have similar network
computations, and verifies them jointly. If a mini-batch is verified, all
$\epsilon$-balls are proven robust. Otherwise, one $\epsilon$-ball is suspected
as not being robust, guiding the refinement. In the latter case, BaVerLy
leverages the analysis results to expedite the analysis of that $\epsilon$-ball
as well as the other $\epsilon$-balls in the batch. We evaluate BaVerLy on
fully connected and convolutional networks for MNIST and CIFAR-10. Results show
that BaVerLy scales the common one by one verification by 2.3x on average and
up to 4.1x, in which case it reduces the total analysis time from 24 hours to 6
hours.

</details>


### [103] [Learning Protein-Ligand Binding in Hyperbolic Space](https://arxiv.org/abs/2508.15480)
*Jianhui Wang,Wenyu Zhu,Bowen Gao,Xin Hong,Ya-Qin Zhang,Wei-Ying Ma,Yanyan Lan*

Main category: cs.LG

TL;DR: 이 연구에서는 단백질-리간드 결합 예측을 위해 하이퍼볼릭 표현 학습 프레임워크인 HypSeek를 제안하며, 이는 리간드와 단백질 주머니, 서열을 로렌츠 모델의 하이퍼볼릭 공간에 임베드하여 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 단백질-리간드 결합 예측은 가상 스크리닝과 친화도 순위 매기기에서 중요하며, 기존의 유클리드 공간 기반 방법들이 구조적 유사성을 충분히 반영하지 못한다.

Method: HypSeek는 리간드, 단백질 주머니, 서열을 로렌츠 모델의 하이퍼볼릭 공간에 임베드하여, 하이퍼볼릭 공간의 지수 기하학적 특성과 음수 곡률을 활용한다.

Result: HypSeek는 DUD-E 데이터셋에서 가상 스크리닝의 초기 풍부함을 42.63에서 51.44로(+20.7%) 개선하고, JACS에서 친화도 순위 상관관계를 0.5774에서 0.7239로(+25.4%) 향상시킨다.

Conclusion: 이 연구는 하이퍼볼릭 기하학이 단백질-리간드 모델링에 강력한 유도 편향으로 작용할 수 있음을 입증한다.

Abstract: Protein-ligand binding prediction is central to virtual screening and
affinity ranking, two fundamental tasks in drug discovery. While recent
retrieval-based methods embed ligands and protein pockets into Euclidean space
for similarity-based search, the geometry of Euclidean embeddings often fails
to capture the hierarchical structure and fine-grained affinity variations
intrinsic to molecular interactions. In this work, we propose HypSeek, a
hyperbolic representation learning framework that embeds ligands, protein
pockets, and sequences into Lorentz-model hyperbolic space. By leveraging the
exponential geometry and negative curvature of hyperbolic space, HypSeek
enables expressive, affinity-sensitive embeddings that can effectively model
both global activity and subtle functional differences-particularly in
challenging cases such as activity cliffs, where structurally similar ligands
exhibit large affinity gaps. Our mode unifies virtual screening and affinity
ranking in a single framework, introducing a protein-guided three-tower
architecture to enhance representational structure. HypSeek improves early
enrichment in virtual screening on DUD-E from 42.63 to 51.44 (+20.7%) and
affinity ranking correlation on JACS from 0.5774 to 0.7239 (+25.4%),
demonstrating the benefits of hyperbolic geometry across both tasks and
highlighting its potential as a powerful inductive bias for protein-ligand
modeling.

</details>


### [104] [Let's Grow an Unbiased Community: Guiding the Fairness of Graphs via New Links](https://arxiv.org/abs/2508.15499)
*Jiahua Lu,Huaxiao Liu,Shuotong Bai,Junjie Xu,Renqiang Luo,Enyan Dai*

Main category: cs.LG

TL;DR: 본 논문은 공정성을 높이기 위한 새로운 링크 도입을 통해 그래프 신경망의 구조적 공정성을 개선하는 FairGuide라는 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 그래프 신경망(GNNs)은 다양한 응용 프로그램에서 성공을 거두었으나, 그래프 구조의 편향성으로 인해 공정성에 큰 도전에 직면하고 있습니다.

Method: FairGuide라는 새로운 프레임워크를 제안하고, 공정성 가이드를 통해 학습된 그래프에서 다운스트림 작업의 공정성을 보장하기 위해 미분 가능한 커뮤니티 탐지 작업을 소개합니다.

Result: 실험 결과는 우리 방법이 다양한 그래프 기반 공정성 작업에 대해 효과적이고 일반화 가능함을 보여줍니다.

Conclusion: FairGuide는 메타 그래디언트를 활용하여 구조적 공정성을 높이는 새로운 링크를 식별하는 효과적인 전략을 적용합니다.

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success across diverse
applications. However, due to the biases in the graph structures, graph neural
networks face significant challenges in fairness. Although the original user
graph structure is generally biased, it is promising to guide these existing
structures toward unbiased ones by introducing new links. The fairness guidance
via new links could foster unbiased communities, thereby enhancing fairness in
downstream applications. To address this issue, we propose a novel framework
named FairGuide. Specifically, to ensure fairness in downstream tasks trained
on fairness-guided graphs, we introduce a differentiable community detection
task as a pseudo downstream task. Our theoretical analysis further demonstrates
that optimizing fairness within this pseudo task effectively enhances
structural fairness, promoting fairness generalization across diverse
downstream applications. Moreover, FairGuide employs an effective strategy
which leverages meta-gradients derived from the fairness-guidance objective to
identify new links that significantly enhance structural fairness. Extensive
experimental results demonstrate the effectiveness and generalizability of our
proposed method across a variety of graph-based fairness tasks.

</details>


### [105] [Jointly Computation- and Communication-Efficient Distributed Learning](https://arxiv.org/abs/2508.15509)
*Xiaoxing Ren,Nicola Bastianello,Karl H. Johansson,Thomas Parisini*

Main category: cs.LG

TL;DR: 본 연구에서 우리는 비방향 네트워크에서의 분산 학습 문제를 다루며, 효율적인 ADMM 기반 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 비방향 네트워크에서 분산 학습의 효율성을 높이고자 한다.

Method: 스톡캐스틱 경량을 활용한 지역 훈련과, 여러 훈련 세대를 수행하며 압축 전송을 사용하는 방법이다.

Result: 강한 볼록 설정에서 알고리즘의 정확한 선형 수렴을 증명하였다.

Conclusion: 이론적 결과를 최신 기법과 비교하여 확인하였다.

Abstract: We address distributed learning problems over undirected networks.
Specifically, we focus on designing a novel ADMM-based algorithm that is
jointly computation- and communication-efficient. Our design guarantees
computational efficiency by allowing agents to use stochastic gradients during
local training. Moreover, communication efficiency is achieved as follows: i)
the agents perform multiple training epochs between communication rounds, and
ii) compressed transmissions are used. We prove exact linear convergence of the
algorithm in the strongly convex setting. We corroborate our theoretical
results by numerical comparisons with state of the art techniques on a
classification task.

</details>


### [106] [Stabilization of Perturbed Loss Function: Differential Privacy without Gradient Noise](https://arxiv.org/abs/2508.15523)
*Salman Habib,Remi Chou,Taejoon Kim*

Main category: cs.LG

TL;DR: SPOF는 다중 사용자 지역 차등 개인정보 보호를 위한 훈련 메커니즘으로, 안정된 Taylor 다항식 근사를 사용하여 손실 함수를 변동시키고, 사용자 데이터에 개인화된 노이즈를 추가하여 안정성과 계산 효율성을 높입니다. 또한, 다중 사용자 환경에서 개인정보 보호 보장을 지원하며, 훈련 중 환경 노이즈에 강건성을 보입니다.


<details>
  <summary>Details</summary>
Motivation: 다중 사용자 환경에서 차등 개인정보 보호를 효과적으로 유지하면서도 계산 효율성을 향상시키기 위한 새로운 방법이 필요합니다.

Method: 모델의 손실 함수에 안정화된 Taylor 다항식 근사를 적용하고, 각 사용자의 데이터에 계측된 노이즈를 추가하여 개인화를 구현합니다.

Result: SPOF는 DP-SGD에 비해 평균 3.5% 높은 재구성 정확도를 달성하며, 평균 훈련 시간을 57.2% 단축시킵니다.

Conclusion: SPOF는 다중 사용자 환경에서 개인정보 보호와 유용성 간의 우수한 균형을 보여줍니다.

Abstract: We propose SPOF (Stabilization of Perturbed Loss Function), a differentially
private training mechanism intended for multi-user local differential privacy
(LDP). SPOF perturbs a stabilized Taylor expanded polynomial approximation of a
model's training loss function, where each user's data is privatized by
calibrated noise added to the coefficients of the polynomial. Unlike
gradient-based mechanisms such as differentially private stochastic gradient
descent (DP-SGD), SPOF does not require injecting noise into the gradients of
the loss function, which improves both computational efficiency and stability.
This formulation naturally supports simultaneous privacy guarantees across all
users. Moreover, SPOF exhibits robustness to environmental noise during
training, maintaining stable performance even when user inputs are corrupted.
We compare SPOF with a multi-user extension of DP-SGD, evaluating both methods
in a wireless body area network (WBAN) scenario involving heterogeneous user
data and stochastic channel noise from body sensors. Our results show that SPOF
achieves, on average, up to 3.5% higher reconstruction accuracy and reduces
mean training time by up to 57.2% compared to DP-SGD, demonstrating superior
privacy-utility trade-offs in multi-user environments.

</details>


### [107] [AI-Powered Machine Learning Approaches for Fault Diagnosis in Industrial Pumps](https://arxiv.org/abs/2508.15550)
*Khaled M. A. Alghtus,Ayad Gannan,Khalid M. Alhajri,Ali L. A. Al Jubouri,Hassan A. I. Al-Janahi*

Main category: cs.LG

TL;DR: 본 연구는 해양 환경에서 동작하는 대규모 수직 원심 펌프의 실제 센서 데이터를 활용하여 산업 펌프 시스템의 조기 고장 탐지를 위한 실용적인 접근법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 산업 펌프 시스템의 조기 고장 탐지는 유지보수 비용 절감과 시스템 신뢰성 향상에 중요하다.

Method: 5가지 주요 운영 매개변수(진동, 온도, 유량, 압력, 전류)를 모니터링하고, 고정 공학 한계와 역사적 센서 값의 95번째 백분위수를 계산하여 적응형 임계값을 결합한 이중 임계값 레이블링 방법을 적용했다.

Result: Random Forest와 XGBoost 모델이 모든 클래스에서 높은 정확성을 달성했으며, SVM 모델은 이상에 대한 민감도가 낮았다.

Conclusion: 제안된 하이브리드 방법이 견고한 탐지 능력을 제공함을 보여주며, 다른 기계에도 적용 가능하다.

Abstract: This study presents a practical approach for early fault detection in
industrial pump systems using real-world sensor data from a large-scale
vertical centrifugal pump operating in a demanding marine environment. Five key
operational parameters were monitored: vibration, temperature, flow rate,
pressure, and electrical current. A dual-threshold labeling method was applied,
combining fixed engineering limits with adaptive thresholds calculated as the
95th percentile of historical sensor values. To address the rarity of
documented failures, synthetic fault signals were injected into the data using
domain-specific rules, simulating critical alerts within plausible operating
ranges. Three machine learning classifiers - Random Forest, Extreme Gradient
Boosting (XGBoost), and Support Vector Machine (SVM) - were trained to
distinguish between normal operation, early warnings, and critical alerts.
Results showed that Random Forest and XGBoost models achieved high accuracy
across all classes, including minority cases representing rare or emerging
faults, while the SVM model exhibited lower sensitivity to anomalies. Visual
analyses, including grouped confusion matrices and time-series plots, indicated
that the proposed hybrid method provides robust detection capabilities. The
framework is scalable, interpretable, and suitable for real-time industrial
deployment, supporting proactive maintenance decisions before failures occur.
Furthermore, it can be adapted to other machinery with similar sensor
architectures, highlighting its potential as a scalable solution for predictive
maintenance in complex systems.

</details>


### [108] [Conformalized Exceptional Model Mining: Telling Where Your Model Performs (Not) Well](https://arxiv.org/abs/2508.15569)
*Xin Du,Sikun Yang,Wouter Duivesteijn,Mykola Pechenizkiy*

Main category: cs.LG

TL;DR: 이 논문은 기계 학습 모델 성능을 이해하기 위한 새로운 프레임워크인 Conformalized Exceptional Model Mining을 제안하며, 이는 모델 해석성과 신뢰성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 모델의 미세한 성능 이해는 책임 있는 배치를 위해 필수적입니다.

Method: Conformal Prediction의 엄격함과 Exceptional Model Mining (EMM)의 설명력을 결합한 새로운 프레임워크를 개발했습니다.

Result: 다양한 데이터 세트를 통한 실험 결과는 이 프레임워크가 모델 행동에 대한 중요한 통찰력을 제공하는 해석 가능한 하위 그룹을 발견하는 데 효과적임을 보여줍니다.

Conclusion: 이 연구는 설명 가능한 AI 및 불확실성 정량화 분야에서 최첨단 기술을 발전시키는 기초를 마련합니다.

Abstract: Understanding the nuanced performance of machine learning models is essential
for responsible deployment, especially in high-stakes domains like healthcare
and finance. This paper introduces a novel framework, Conformalized Exceptional
Model Mining, which combines the rigor of Conformal Prediction with the
explanatory power of Exceptional Model Mining (EMM). The proposed framework
identifies cohesive subgroups within data where model performance deviates
exceptionally, highlighting regions of both high confidence and high
uncertainty. We develop a new model class, mSMoPE (multiplex Soft Model
Performance Evaluation), which quantifies uncertainty through conformal
prediction's rigorous coverage guarantees. By defining a new quality measure,
Relative Average Uncertainty Loss (RAUL), our framework isolates subgroups with
exceptional performance patterns in multi-class classification and regression
tasks. Experimental results across diverse datasets demonstrate the framework's
effectiveness in uncovering interpretable subgroups that provide critical
insights into model behavior. This work lays the groundwork for enhancing model
interpretability and reliability, advancing the state-of-the-art in explainable
AI and uncertainty quantification.

</details>


### [109] [GRASPED: Graph Anomaly Detection using Autoencoder with Spectral Encoder and Decoder (Full Version)](https://arxiv.org/abs/2508.15633)
*Wei Herng Choong,Jixing Liu,Ching-Yu Kao,Philip Sperl*

Main category: cs.LG

TL;DR: 이 논문은 그래프 머신 러닝을 이용하여 노드 이상 탐지를 위한 GRASPED 모델을 제안하며, 다양한 스케일에서 그래프 정보를 포착하는 밴드패스 필터 특성을 가진 인코더와 디코더를 사용한다.


<details>
  <summary>Details</summary>
Motivation: 그래프의 이상 탐지에서 스펙트럼 도메인 정보를 효과적으로 활용하기 위해 연구가 필요하다.

Method: Graph Wavelet Convolution 기반의 인코더와 구조 및 속성 디코더를 가진 비지도 학습 모델을 제안한다.

Result: GRASPED는 여러 실제 그래프 이상 탐지 데이터셋에서 현재 최고의 모델보다 뛰어난 성능을 보인다.

Conclusion: 그래프 이상 탐지에서 GRASPED 모델이 효과적임을 입증하였다.

Abstract: Graph machine learning has been widely explored in various domains, such as
community detection, transaction analysis, and recommendation systems. In these
applications, anomaly detection plays an important role. Recently, studies have
shown that anomalies on graphs induce spectral shifts. Some supervised methods
have improved the utilization of such spectral domain information. However,
they remain limited by the scarcity of labeled data due to the nature of
anomalies. On the other hand, existing unsupervised learning approaches
predominantly rely on spatial information or only employ low-pass filters,
thereby losing the capacity for multi-band analysis. In this paper, we propose
Graph Autoencoder with Spectral Encoder and Spectral Decoder (GRASPED) for node
anomaly detection. Our unsupervised learning model features an encoder based on
Graph Wavelet Convolution, along with structural and attribute decoders. The
Graph Wavelet Convolution-based encoder, combined with a Wiener Graph
Deconvolution-based decoder, exhibits bandpass filter characteristics that
capture global and local graph information at multiple scales. This design
allows for a learning-based reconstruction of node attributes, effectively
capturing anomaly information. Extensive experiments on several real-world
graph anomaly detection datasets demonstrate that GRASPED outperforms current
state-of-the-art models.

</details>


### [110] [Inductive Domain Transfer In Misspecified Simulation-Based Inference](https://arxiv.org/abs/2508.15593)
*Ortal Senouf,Antoine Wehenkel,Cédric Vincent-Cuaz,Emmanuel Abbé,Pascal Frossard*

Main category: cs.LG

TL;DR: 본 논문에서는 시뮬레이션 기반 추론(SBI)을 위한 완전 유도형 및 분산 정렬 기능을 통합한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 모델의 오류로 인해 시뮬레이션된 데이터와 실제 관찰 간의 불일치가 발생하는 문제를 해결하기 위해.

Method: 무작위 샘플을 사용하는 최소 배치 최적 수송(Mini-batch OT)과 폐쇄형 결합을 이용해 실제 및 시뮬레이션 관찰을 정렬하고, 조건부 정규화 흐름을 학습하여 역추정값을 근사합니다.

Result: 우리는 합성 및 실제 벤치마크에서 RoPE 및 다른 표준 SBI와 비SBI 추정기와 유사하거나 더 높은 성능을 기록했습니다.

Conclusion: 제안된 방법은 도전적이고 규격화되지 않은 환경에서의 확장성 및 적용 가능성을 개선합니다.

Abstract: Simulation-based inference (SBI) is a statistical inference approach for
estimating latent parameters of a physical system when the likelihood is
intractable but simulations are available. In practice, SBI is often hindered
by model misspecification--the mismatch between simulated and real-world
observations caused by inherent modeling simplifications. RoPE, a recent SBI
approach, addresses this challenge through a two-stage domain transfer process
that combines semi-supervised calibration with optimal transport (OT)-based
distribution alignment. However, RoPE operates in a fully transductive setting,
requiring access to a batch of test samples at inference time, which limits
scalability and generalization. We propose here a fully inductive and amortized
SBI framework that integrates calibration and distributional alignment into a
single, end-to-end trainable model. Our method leverages mini-batch OT with a
closed-form coupling to align real and simulated observations that correspond
to the same latent parameters, using both paired calibration data and unpaired
samples. A conditional normalizing flow is then trained to approximate the
OT-induced posterior, enabling efficient inference without simulation access at
test time. Across a range of synthetic and real-world benchmarks--including
complex medical biomarker estimation--our approach matches or surpasses the
performance of RoPE, as well as other standard SBI and non-SBI estimators,
while offering improved scalability and applicability in challenging,
misspecified environments.

</details>


### [111] [Tutorial on the Probabilistic Unification of Estimation Theory, Machine Learning, and Generative AI](https://arxiv.org/abs/2508.15719)
*Mohammed Elmusrati*

Main category: cs.LG

TL;DR: 본 논문은 불확실하고 noisy한 데이터로부터 의미를 추출하는 문제를 다회의되고, 통계적 추론 및 최신 머신러닝, 특히 딥러닝과 대형 언어 모델과 연결하는 통합된 수학적 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 불확실하고 noisy한 데이터에서 의미를 추출하는 것은 시계열 분석, 패턴 인식 및 언어 모델링에 있어 기본적인 문제입니다.

Method: 최대 우도 추정(maximum likelihood estimation), Bayesian 추론, 주의 메커니즘(attention mechanisms) 등의 기술이 불확실성을 다루는 방식을 분석했습니다.

Result: 고급 모델이 기초적인 원칙을 바탕으로 실질적인 과제를 해결하는 방식을 보여주었습니다.

Conclusion: 최대 우도, MAP 추정, Bayesian 분류 및 딥러닝이 noisy하고/또는 편향된 관측에서 숨겨진 원인을 추론하는 공통 목표를 가지고 있음을 입증합니다.

Abstract: Extracting meaning from uncertain, noisy data is a fundamental problem across
time series analysis, pattern recognition, and language modeling. This survey
presents a unified mathematical framework that connects classical estimation
theory, statistical inference, and modern machine learning, including deep
learning and large language models. By analyzing how techniques such as maximum
likelihood estimation, Bayesian inference, and attention mechanisms address
uncertainty, the paper illustrates that many AI methods are rooted in shared
probabilistic principles. Through illustrative scenarios including system
identification, image classification, and language generation, we show how
increasingly complex models build upon these foundations to tackle practical
challenges like overfitting, data sparsity, and interpretability. In other
words, the work demonstrates that maximum likelihood, MAP estimation, Bayesian
classification, and deep learning all represent different facets of a shared
goal: inferring hidden causes from noisy and/or biased observations. It serves
as both a theoretical synthesis and a practical guide for students and
researchers navigating the evolving landscape of machine learning.

</details>


### [112] [Continual Neural Topic Model](https://arxiv.org/abs/2508.15612)
*Charu Karakkaparambil James,Waleed Mustafa,Marius Kloft,Sophie Fellenz*

Main category: cs.LG

TL;DR: 연속 학습에 대한 연구로, CoNTM 모델이 기존 토픽 모델보다 더 다양한 주제를 배우고 시간적 변화를 더 잘 포착함을 보여줌.


<details>
  <summary>Details</summary>
Motivation: 연속 학습의 목표는 이전에 배운 것을 잊지 않고 새로운 작업을 배우는 것이다.

Method: CoNTM은 이전에 배운 것을 잊지 않고 연속적인 시간 단계에서 토픽 모델을 학습한다.

Result: CoNTM은 주제 품질 및 예측 혼란도 면에서 기존의 동적 토픽 모델을 일관되게 능가하였다.

Conclusion: CoNTM은 기존 방법보다 더 다양한 주제를 배우고 시간적 변화를 더 잘 포착할 수 있다.

Abstract: In continual learning, our aim is to learn a new task without forgetting what
was learned previously. In topic models, this translates to learning new topic
models without forgetting previously learned topics. Previous work either
considered Dynamic Topic Models (DTMs), which learn the evolution of topics
based on the entire training corpus at once, or Online Topic Models, which are
updated continuously based on new data but do not have long-term memory. To
fill this gap, we propose the Continual Neural Topic Model (CoNTM), which
continuously learns topic models at subsequent time steps without forgetting
what was previously learned. This is achieved using a global prior distribution
that is continuously updated. In our experiments, CoNTM consistently
outperformed the dynamic topic model in terms of topic quality and predictive
perplexity while being able to capture topic changes online. The analysis
reveals that CoNTM can learn more diverse topics and better capture temporal
changes than existing methods.

</details>


### [113] [Discovering Hidden Algebraic Structures via Transformers with Rank-Aware Beam GRPO](https://arxiv.org/abs/2508.15766)
*Jaeha Lee,Gio Huh,Ning Su,Tony Yue YU*

Main category: cs.LG

TL;DR: 이 연구는 함수 분해의 맥락에서 비선형 잠재 패턴 발견을 위한 변압기 모델의 능력을 조사하며, 다변량 다항식 분해 문제에 초점을 맞춘다. 이 문제는 NP-하드로 입증되었으며, 문제의 복잡성을 조절할 수 있는 합성 데이터 생성 파이프라인을 개발하고, 감독 학습을 통해 변압기 모델을 훈련하며, Rank-aware 강화 학습 방법인 BGRPO를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 변압기 모델의 논리적 추론 및 기호 계산 능력을 확장하기 위한 최근의 노력에 대한 일환으로, 비선형 잠재 패턴 발견을 조사하고자 한다.

Method: 합성 데이터 생성 파이프라인을 개발하고, 감독 학습을 통해 변압기 모델을 훈련시킨 뒤, Beam Grouped Relative Policy Optimization (BGRPO)이라는 강화 학습 방법을 제안한다.

Result: BGRPO로 파인튜닝하여 정확도를 향상시키고, 빔 너비를 반으로 줄여 약 75% 낮은 추론 컴퓨팅 비용을 달성하였다.

Conclusion: 우리 모델은 다항식 단순화에서 경쟁력 있는 성능을 보이며, 다양한 경우에서 Mathematica를 능가한다.

Abstract: Recent efforts have extended the capabilities of transformers in logical
reasoning and symbolic computations. In this work, we investigate their
capacity for non-linear latent pattern discovery in the context of functional
decomposition, focusing on the challenging algebraic task of multivariate
polynomial decomposition. This problem, with widespread applications in science
and engineering, is proved to be NP-hard, and demands both precision and
insight. Our contributions are threefold: First, we develop a synthetic data
generation pipeline providing fine-grained control over problem complexity.
Second, we train transformer models via supervised learning and evaluate them
across four key dimensions involving scaling behavior and generalizability.
Third, we propose Beam Grouped Relative Policy Optimization (BGRPO), a
rank-aware reinforcement learning method suitable for hard algebraic problems.
Finetuning with BGRPO improves accuracy while reducing beam width by up to
half, resulting in approximately 75% lower inference compute. Additionally, our
model demonstrates competitive performance in polynomial simplification,
outperforming Mathematica in various cases.

</details>


### [114] [Classification errors distort findings in automated speech processing: examples and solutions from child-development research](https://arxiv.org/abs/2508.15637)
*Lucas Gautheron,Evan Kidd,Anton Malko,Marvin Lavechin,Alejandrina Cristia*

Main category: cs.LG

TL;DR: 이 논문은 알고리즘 오류가 아동의 언어 경험과 생산에 미치는 영향을 조사하기 위한 베이지안 접근법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 웨어러블 레코더의 출현에 따라 과학자들은 아동의 경험, 행동 및 결과를 측정하기 위해 자동화된 오디오 및 비디오 데이터 분석 방법으로 전환하고 있습니다.

Method: 베이지안 접근법을 사용하여 알고리즘 오류가 아동의 언어 경험에 미치는 영향과 아동의 생산과 입력 간의 관계를 연구합니다.

Result: 분류 오류가 추정치를 왜곡할 수 있으며, 자동화된 주석이 형제의 성인 입력에 미치는 부정적 영향을 20-80%로 과소 평가했습니다.

Conclusion: 베이지안 보정 접근법이 효과적이고 통찰력 있게 비편향 효과 크기 추정을 회복할 수 있지만, 완벽한 해결책은 아니며, 이는 과오류율이 있는 이벤트 탐지 및 분류와 관련된 모든 분류기에 적용될 수 있습니다.

Abstract: With the advent of wearable recorders, scientists are increasingly turning to
automated methods of analysis of audio and video data in order to measure
children's experience, behavior, and outcomes, with a sizable literature
employing long-form audio-recordings to study language acquisition. While
numerous articles report on the accuracy and reliability of the most popular
automated classifiers, less has been written on the downstream effects of
classification errors on measurements and statistical inferences (e.g., the
estimate of correlations and effect sizes in regressions). This paper proposes
a Bayesian approach to study the effects of algorithmic errors on key
scientific questions, including the effect of siblings on children's language
experience and the association between children's production and their input.
In both the most commonly used \gls{lena}, and an open-source alternative (the
Voice Type Classifier from the ACLEW system), we find that classification
errors can significantly distort estimates. For instance, automated annotations
underestimated the negative effect of siblings on adult input by 20--80\%,
potentially placing it below statistical significance thresholds. We further
show that a Bayesian calibration approach for recovering unbiased estimates of
effect sizes can be effective and insightful, but does not provide a fool-proof
solution. Both the issue reported and our solution may apply to any classifier
involving event detection and classification with non-zero error rates.

</details>


### [115] [Correct-By-Construction: Certified Individual Fairness through Neural Network Training](https://arxiv.org/abs/2508.15642)
*Ruihan Zhang,Jun Sun*

Main category: cs.LG

TL;DR: 이 논문은 훈련 과정에서 개인 공정성을 보장하는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습에서 윤리적 우려가 커짐에 따라 개인 공정성이 점점 더 중요해지고 있다.

Method: 모델이 공정한 상태에서 시작하도록 보장하고 학습하는 동안 공정성을 유지하는 알고리즘을 사용한다.

Result: 실험 결과, 우리 방법이 경험적으로 공정하고 정확한 모델을 생성한다는 것을 확인했다.

Conclusion: 제안한 방법이 공인 훈련에 기반한 대안보다 더 효율적이다.

Abstract: Fairness in machine learning is more important than ever as ethical concerns
continue to grow. Individual fairness demands that individuals differing only
in sensitive attributes receive the same outcomes. However, commonly used
machine learning algorithms often fail to achieve such fairness. To improve
individual fairness, various training methods have been developed, such as
incorporating fairness constraints as optimisation objectives. While these
methods have demonstrated empirical effectiveness, they lack formal guarantees
of fairness. Existing approaches that aim to provide fairness guarantees
primarily rely on verification techniques, which can sometimes fail to produce
definitive results. Moreover, verification alone does not actively enhance
individual fairness during training. To address this limitation, we propose a
novel framework that formally guarantees individual fairness throughout
training. Our approach consists of two parts, i.e., (1) provably fair
initialisation that ensures the model starts in a fair state, and (2) a
fairness-preserving training algorithm that maintains fairness as the model
learns. A key element of our method is the use of randomised response
mechanisms, which protect sensitive attributes while maintaining fairness
guarantees. We formally prove that this mechanism sustains individual fairness
throughout the training process. Experimental evaluations confirm that our
approach is effective, i.e., producing models that are empirically fair and
accurate. Furthermore, our approach is much more efficient than the alternative
approach based on certified training (which requires neural network
verification during training).

</details>


### [116] [Amortized In-Context Mixed Effect Transformer Models: A Zero-Shot Approach for Pharmacokinetics](https://arxiv.org/abs/2508.15659)
*César Ali Ojeda Marin,Wilhelm Huisinga,Purity Kavwele,Niklas Hartung*

Main category: cs.LG

TL;DR: AICMET 모델은 기존 약리학 모델링 사이클을 단축시키며 인공지능 기반 개인 맞춤형 약물 용량 예측을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 정확한 용량-반응 예측은 정밀 약물 치료에서 매우 중요하다.

Method: AICMET 모델은 변환기 기반 잠재 변수 프레임워크로, 기계론적 구획 선험과 상환된 맥락 베이지안 추론을 통합한다. 또한 수십만 개의 합성 약리학 궤적에 대해 사전 훈련된다.

Result: AICMET는 최신 예측 정확도를 달성하고, 환자 간 변동성을 신뢰성 있게 정량화하며, 비선형 혼합 효과 기준선 및 최근 신경 계열 변형보다 우수한 성과를 보인다.

Conclusion: AICMET 모델은 개인 맞춤형 약리학 모델링 파이프라인을 위한 새로운 대안을 제공하며, 진정한 인구 인식 맞춤 용량 계획을 향한 경로를 제시한다.

Abstract: Accurate dose-response forecasting under sparse sampling is central to
precision pharmacotherapy. We present the Amortized In-Context Mixed-Effect
Transformer (AICMET) model, a transformer-based latent-variable framework that
unifies mechanistic compartmental priors with amortized in-context Bayesian
inference. AICMET is pre-trained on hundreds of thousands of synthetic
pharmacokinetic trajectories with Ornstein-Uhlenbeck priors over the parameters
of compartment models, endowing the model with strong inductive biases and
enabling zero-shot adaptation to new compounds. At inference time, the decoder
conditions on the collective context of previously profiled trial participants,
generating calibrated posterior predictions for newly enrolled patients after a
few early drug concentration measurements. This capability collapses
traditional model-development cycles from weeks to hours while preserving some
degree of expert modelling. Experiments across public datasets show that AICMET
attains state-of-the-art predictive accuracy and faithfully quantifies
inter-patient variability -- outperforming both nonlinear mixed-effects
baselines and recent neural ODE variants. Our results highlight the feasibility
of transformer-based, population-aware neural architectures as offering a new
alternative for bespoke pharmacokinetic modeling pipelines, charting a path
toward truly population-aware personalized dosing regimens.

</details>


### [117] [Tensorized Multi-Task Learning for Personalized Modeling of Heterogeneous Individuals with High-Dimensional Data](https://arxiv.org/abs/2508.15676)
*Elif Konyar,Mostafa Reisi Gahrooei,Kamran Paynabar*

Main category: cs.LG

TL;DR: 이 논문은 이질적인 하위 집단의 효과적인 모델링을 위한 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 개인의 특성 및 행동의 변동성으로 인해 이질적인 하위 집단 모델링이 어려운 문제를 해결하고자 합니다.

Method: 다중 작업 학습(MTL)과 저계 텐서 분해 기술을 활용하여 유사한 작업 간의 공유 구조를 이용합니다.

Result: 실험 결과는 제안한 방법이 여러 벤치마크에 비해 우수한 성능을 보였음을 보여줍니다.

Conclusion: 이 프레임워크는 예측 정확도를 개선하고 모델의 개인화에 기여하는 패턴을 드러내어 해석 가능성을 향상시킵니다.

Abstract: Effective modeling of heterogeneous subpopulations presents a significant
challenge due to variations in individual characteristics and behaviors. This
paper proposes a novel approach to address this issue through multi-task
learning (MTL) and low-rank tensor decomposition techniques. Our MTL approach
aims to enhance personalized modeling by leveraging shared structures among
similar tasks while accounting for distinct subpopulation-specific variations.
We introduce a framework where low-rank decomposition decomposes the collection
of task model parameters into a low-rank structure that captures commonalities
and variations across tasks and subpopulations. This approach allows for
efficient learning of personalized models by sharing knowledge between similar
tasks while preserving the unique characteristics of each subpopulation.
Experimental results in simulation and case study datasets demonstrate the
superior performance of the proposed method compared to several benchmarks,
particularly in scenarios with high variability among subpopulations. The
proposed framework not only improves prediction accuracy but also enhances
interpretability by revealing underlying patterns that contribute to the
personalization of models.

</details>


### [118] [An Efficient Open World Environment for Multi-Agent Social Learning](https://arxiv.org/abs/2508.15679)
*Eric Ye,Ren Tao,Natasha Jaques*

Main category: cs.LG

TL;DR: AI 요원들은 실제 환경에서 배치되기 전에 여러 도전에 직면해 있지만, 진화된 사회적 지능이 그러한 환경에서 적응력을 높일 수 있다는 점에 주목한다. 이 연구는 전문가가 존재하는 다중 에이전트 환경에서 AI 요원의 성과를 조사한다.


<details>
  <summary>Details</summary>
Motivation: AI 요원들이 실제 환경에서 효과적으로 작동하기 위해서는 다중 에이전트 환경에서의 학습이 필요하다.

Method: 여러 자아 이익을 지닌 에이전트들이 복잡하고 독립적인 목표를 추구할 수 있는 환경을 제시한다.

Result: 전문가와 협력이 있는 사회적 학습이 에이전트 성능에 미치는 영향을 조사하고 협력이나 경쟁 어느 쪽이 더 유리한지 탐구한다.

Conclusion: 이 연구는 AI 요원이 명시적인 협력 없이도 사회적 지능을 통해 더 나은 성과를 낼 수 있는 방법을 제시한다.

Abstract: Many challenges remain before AI agents can be deployed in real-world
environments. However, one virtue of such environments is that they are
inherently multi-agent and contain human experts. Using advanced social
intelligence in such an environment can help an AI agent learn adaptive skills
and behaviors that a known expert exhibits. While social intelligence could
accelerate training, it is currently difficult to study due to the lack of
open-ended multi-agent environments. In this work, we present an environment in
which multiple self-interested agents can pursue complex and independent goals,
reflective of real world challenges. This environment will enable research into
the development of socially intelligent AI agents in open-ended multi-agent
settings, where agents may be implicitly incentivized to cooperate to defeat
common enemies, build and share tools, and achieve long horizon goals. In this
work, we investigate the impact on agent performance due to social learning in
the presence of experts and implicit cooperation such as emergent collaborative
tool use, and whether agents can benefit from either cooperation or competition
in this environment.

</details>


### [119] [Conditionally adaptive augmented Lagrangian method for physics-informed learning of forward and inverse problems using artificial neural networks](https://arxiv.org/abs/2508.15695)
*Qifeng Hu,Shamsulhaq Basir,Inanc Senocak*

Main category: cs.LG

TL;DR: 이 논문에서는 고전적인 편미분 방정식(PDE)의 해를 학습하는 PECANN 프레임워크의 성능을 크게 개선하는 여러 가지 발전을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 편미분 방정식의 해를 효과적으로 학습하기 위해 PECANN의 능력을 개선할 필요가 있다.

Method: ALM을 다중 독립 페널티 매개변수를 지원하도록 일반화하고, 점별 제약 강제화 및 라그랑주 승수를 제약 항에 대한 기대값으로 재구성하며, 푸리에 기능 매핑을 도입하고, 시간 창 전략을 통해 초기 상태 제약을 설정하고 CAPU 전략을 제안하였다.

Result: PECANN-CAPU는 다양한 문제에서 경쟁력 있는 정확도를 달성하여 PECANN의 견고성, 효율성 및 응용 가능성을 향상시킨다.

Conclusion: 이 연구는 PECANN의 성능을 향상시켜 과학 컴퓨팅의 복잡한 문제를 해결하는 데 기여한다.

Abstract: We present several advances to the physics and equality constrained
artificial neural networks (PECANN) framework that substantially improve its
capability to learn solutions of canonical partial differential equations
(PDEs). First, we generalize the augmented Lagrangian method (ALM) to support
multiple independent penalty parameters, enabling simultaneous enforcement of
heterogeneous constraints. Second, we reformulate pointwise constraint
enforcement and Lagrange multipliers as expectations over constraint terms,
reducing memory overhead and permitting efficient mini-batch training. Third,
to address PDEs with oscillatory, multi-scale features, we incorporate Fourier
feature mappings and show that a single mapping suffices where multiple
mappings or more costly architectures were required in related methods. Fourth,
we introduce a time-windowing strategy for long-time evolution in which the
terminal state of each window is enforced as an initial-condition constraint
for the next, ensuring continuity without discrete time models. Crucially, we
propose a conditionally adaptive penalty update (CAPU) strategy for ALM, which
preserves the principle that larger constraint violations incur stronger
penalties. CAPU accelerates the growth of Lagrange multipliers for selectively
challenging constraints, enhancing constraint enforcement during training. We
demonstrate the effectiveness of PECANN-CAPU on problems including the
transonic rarefaction problem, reversible advection of a passive by a vortex,
high-wavenumber Helmholtz and Poisson equations, and inverse identification of
spatially varying heat sources. Comparisons with established methods and recent
Kolmogorov-Arnold network approaches show that PECANN-CAPU achieves competitive
accuracy across all cases. Collectively, these advances improve PECANN's
robustness, efficiency, and applicability to demanding problems in scientific
computing.

</details>


### [120] [Investigation of D-Wave quantum annealing for training Restricted Boltzmann Machines and mitigating catastrophic forgetting](https://arxiv.org/abs/2508.15697)
*Abdelmoula El-Yazizi,Yaroslav Koshka*

Main category: cs.LG

TL;DR: 본 연구는 D-Wave 양자 어닐러(QA)와 전통적 마르코프 체인 몬테카를로(MCMC) 샘플링의 성능 차이를 탐구하며, 이전 연구에서의 제한된 RBM 훈련 향상 문제를 다룬다. 새로운 하이브리드 샘플링 접근법이 제안되나, 결과적으로 RBM 훈련 개선이 이루어지지 않았으며, QA와 MCMC의 차이가 훈련에 유익하지 않음을 나타낸다. 하드웨어에서 RBM의 품질 문제와 더 낮은 확률 영역에서의 샘플 생성 가능성이 기계 학습에 유리할 수 있음을 암시한다.


<details>
  <summary>Details</summary>
Motivation: D-Wave 양자 어닐러의 샘플링 성능과 전통적인 MCMC의 차이가 RBM 훈련에서 유의미한 개선을 보이지 않는 이유를 설명하기 위함이다.

Method: D-Wave QA와 MCMC의 샘플링 성능을 비교하고, 두 방법의 하이브리드 샘플링 접근법을 연구한다.

Result: 본 연구에서는 RBM 훈련 개선이 이루어지지 않았고, QA와 MCMC의 차이가 샘플 품질에 미치는 영향이 미미함을 제안한다.

Conclusion: 저품질의 RBM 임베딩 및 낮은 확률 영역에서 다양한 샘플 생성 가능성이 기계 학습의 다른 응용 프로그램에서 장점이 될 수 있음을 제안한다.

Abstract: Modest statistical differences between the sampling performances of the
D-Wave quantum annealer (QA) and the classical Markov Chain Monte Carlo (MCMC),
when applied to Restricted Boltzmann Machines (RBMs), are explored to explain,
and possibly address, the absence of significant and consistent improvements in
RBM trainability when the D-Wave sampling was used in previous investigations.
A novel hybrid sampling approach, combining the classical and the QA
contributions, is investigated as a promising way to benefit from the modest
differences between the two sampling methods. No improvements in the RBM
training are achieved in this work, thereby suggesting that the differences
between the QA-based and MCMC sampling, mainly found in the medium-to-low
probability regions of the distribution, which are less important for the
quality of the sample, are insufficient to benefit the training. Difficulties
in achieving sufficiently high quality of embedding RBMs into the lattice of
the newer generation of D-Wave hardware could be further complicating the task.
On the other hand, the ability to generate samples of sufficient variety from
lower-probability parts of the distribution has a potential to benefit other
machine learning applications, such as the mitigation of catastrophic
forgetting (CF) during incremental learning. The feasibility of using
QA-generated patterns of desirable classes for CF mitigation by the generative
replay is demonstrated in this work for the first time. While the efficiency of
the CF mitigation using the D-Wave QA was comparable to that of the classical
mitigation, both the speed of generating a large number of distinct desirable
patterns and the potential for further improvement make this approach promising
for a variety of challenging machine learning applications.

</details>


### [121] [Communication Efficient LLM Pre-training with SparseLoCo](https://arxiv.org/abs/2508.15706)
*Amir Sarfi,Benjamin Thérien,Joel Lidin,Eugene Belilovsky*

Main category: cs.LG

TL;DR: SparseLoCo는 LLM을 위한 통신 효율적인 훈련 알고리즘으로, Top-k 희소화 및 양자화를 활용하여 극도의 압축 비율을 달성하면서도 전체 정밀도 DiLoCo보다 우수한 성능을 보입니다.


<details>
  <summary>Details</summary>
Motivation: 대역폭이 제한된 환경에서 대규모 언어 모델(LLM)을 훈련하는 데 필요한 통신 효율적인 분산 훈련 알고리즘에 대한 관심이 높아지고 있습니다.

Method: SparseLoCo는 Top-k 희소화와 2비트 양자화를 효과적으로 활용하여 최대 1-3% 희소성과 2비트 양자화의 극단적인 압축 비율을 달성하는 통신 효율적인 훈련 알고리즘입니다.

Result: SparseLoCo는 통신 제약이 있는 다양한 LLM 훈련 환경에서 성능과 통신 비용 모두에서 상당한 이점을 제공합니다.

Conclusion: 희소 집합을 통해 모델 성능을 향상할 수 있으며, 외부 모멘텀을 오류 피드백과 결합하여 지역적으로 근사화할 수 있다는 관찰 결과를 제시합니다.

Abstract: Communication-efficient distributed training algorithms have received
considerable interest recently due to their benefits for training Large
Language Models (LLMs) in bandwidth-constrained settings, such as across data
centers and over the internet. Despite reducing communication frequency, these
methods still typically require communicating a full copy of the model's
gradients-resulting in a communication bottleneck even for cross-datacenter
links. Furthermore, they can slightly degrade performance compared to a naive
AdamW DDP baseline. While quantization and error feedback are often applied to
reduce the pseudo-gradient's size, in the context of LLM pre-training, existing
approaches have been unable to additionally leverage sparsification and have
obtained limited quantization. In this work, we introduce SparseLoCo, a
communication-efficient training algorithm for LLMs that effectively leverages
Top-k sparsification and quantization to reach extreme compression ratios of up
to 1-3% sparsity and 2-bit quantization while outperforming full-precision
DiLoCo. Our key observations are that outer momentum can be locally
approximated by an error feedback combined with aggressive sparsity and that
sparse aggregation can actually improve model performance. We empirically
demonstrate in a range of communication-constrained LLM training settings that
SparseLoCo provides significant benefits in both performance and communication
cost.

</details>


### [122] [Probability Density from Latent Diffusion Models for Out-of-Distribution Detection](https://arxiv.org/abs/2508.15737)
*Joonas Järve,Karl Kaspar Haavel,Meelis Kull*

Main category: cs.LG

TL;DR: AI의 급속한 발전에도 불구하고, 안전 문제가 기계 학습 시스템 배치의 주요 병목현상으로 남아있다. OOD(Out-Of-Distribution) 탐지는 중요한 안전 요소로, 입력이 훈련 데이터와 동일한 분포에서 왔는지 결정하는 것이다. 생성 모델에서 가장 자연스러운 OOD 점수는 데이터의 가능도(likelihood)이며, 본 연구에서는 균일 분포의 OOD 데이터를 가정할 때 가능도가 최적의 OOD 탐지기임을 보여준다. 그러나 이전 연구에서는 가능도가 실전에선 자주 실패한다고 보고되어 그 유용성에 의문을 제기한다. 본 연구는 OOD 탐지를 위한 밀도 추정의 학습 능력 부족이 표현 공간에서도 발생하는지, 아니면 전형적으로 생성 모델에서 사용되는 픽셀 공간 문제인지 탐구한다. 이를 위해, 기존의 이미지 대신 사전 학습된 ResNet-18의 표현 공간에서 변분 확산 모델을 훈련시켜, OpenOOD 수트의 최첨단 방법들과 함께 우리의 가능도 기반 탐지기 성능을 평가한다.


<details>
  <summary>Details</summary>
Motivation: AI의 발전에도 불구하고 기계 학습 시스템의 안전 문제가 큰 도전 과제로 남아있다.

Method: 변분 확산 모델을 사전 학습된 ResNet-18의 표현 공간에서 훈련시켜 가능도 기반 탐지기의 성능을 평가하였다.

Result: 최첨단 OOD 탐지 방법들과 비교하여 우리의 가능도 기반 탐지기가 성능을 평가하였다.

Conclusion: 가능도는 OOD 탐지에서 최적이지만 실제로는 밀도 추정의 학습 문제를 포함할 수 있다.

Abstract: Despite rapid advances in AI, safety remains the main bottleneck to deploying
machine-learning systems. A critical safety component is out-of-distribution
detection: given an input, decide whether it comes from the same distribution
as the training data. In generative models, the most natural OOD score is the
data likelihood. Actually, under the assumption of uniformly distributed OOD
data, the likelihood is even the optimal OOD detector, as we show in this work.
However, earlier work reported that likelihood often fails in practice, raising
doubts about its usefulness. We explore whether, in practice, the
representation space also suffers from the inability to learn good density
estimation for OOD detection, or if it is merely a problem of the pixel space
typically used in generative models. To test this, we trained a Variational
Diffusion Model not on images, but on the representation space of a pre-trained
ResNet-18 to assess the performance of our likelihood-based detector in
comparison to state-of-the-art methods from the OpenOOD suite.

</details>


### [123] [Intern-S1: A Scientific Multimodal Foundation Model](https://arxiv.org/abs/2508.15763)
*Lei Bai,Zhongrui Cai,Maosong Cao,Weihan Cao,Chiyu Chen,Haojiong Chen,Kai Chen,Pengcheng Chen,Ying Chen,Yongkang Chen,Yu Cheng,Yu Cheng,Pei Chu,Tao Chu,Erfei Cui,Ganqu Cui,Long Cui,Ziyun Cui,Nianchen Deng,Ning Ding,Nanqin Dong,Peijie Dong,Shihan Dou,Sinan Du,Haodong Duan,Caihua Fan,Ben Gao,Changjiang Gao,Jianfei Gao,Songyang Gao,Yang Gao,Zhangwei Gao,Jiaye Ge,Qiming Ge,Lixin Gu,Yuzhe Gu,Aijia Guo,Qipeng Guo,Xu Guo,Conghui He,Junjun He,Yili Hong,Siyuan Hou,Caiyu Hu,Hanglei Hu,Jucheng Hu,Ming Hu,Zhouqi Hua,Haian Huang,Junhao Huang,Xu Huang,Zixian Huang,Zhe Jiang,Lingkai Kong,Linyang Li,Peiji Li,Pengze Li,Shuaibin Li,Tianbin Li,Wei Li,Yuqiang Li,Dahua Lin,Junyao Lin,Tianyi Lin,Zhishan Lin,Hongwei Liu,Jiangning Liu,Jiyao Liu,Junnan Liu,Kai Liu,Kaiwen Liu,Kuikun Liu,Shichun Liu,Shudong Liu,Wei Liu,Xinyao Liu,Yuhong Liu,Zhan Liu,Yinquan Lu,Haijun Lv,Hongxia Lv,Huijie Lv,Qidang Lv,Ying Lv,Chengqi Lyu,Chenglong Ma,Jianpeng Ma,Ren Ma,Runmin Ma,Runyuan Ma,Xinzhu Ma,Yichuan Ma,Zihan Ma,Sixuan Mi,Junzhi Ning,Wenchang Ning,Xinle Pang,Jiahui Peng,Runyu Peng,Yu Qiao,Jiantao Qiu,Xiaoye Qu,Yuan Qu,Yuchen Ren,Fukai Shang,Wenqi Shao,Junhao Shen,Shuaike Shen,Chunfeng Song,Demin Song,Diping Song,Chenlin Su,Weijie Su,Weigao Sun,Yu Sun,Qian Tan,Cheng Tang,Huanze Tang,Kexian Tang,Shixiang Tang,Jian Tong,Aoran Wang,Bin Wang,Dong Wang,Lintao Wang,Rui Wang,Weiyun Wang,Wenhai Wang,Yi Wang,Ziyi Wang,Ling-I Wu,Wen Wu,Yue Wu,Zijian Wu,Linchen Xiao,Shuhao Xing,Chao Xu,Huihui Xu,Jun Xu,Ruiliang Xu,Wanghan Xu,GanLin Yang,Yuming Yang,Haochen Ye,Jin Ye,Shenglong Ye,Jia Yu,Jiashuo Yu,Jing Yu,Fei Yuan,Bo Zhang,Chao Zhang,Chen Zhang,Hongjie Zhang,Jin Zhang,Qiaosheng Zhang,Qiuyinzhe Zhang,Songyang Zhang,Taolin Zhang,Wenlong Zhang,Wenwei Zhang,Yechen Zhang,Ziyang Zhang,Haiteng Zhao,Qian Zhao,Xiangyu Zhao,Xiangyu Zhao,Bowen Zhou,Dongzhan Zhou,Peiheng Zhou,Yuhao Zhou,Yunhua Zhou,Dongsheng Zhu,Lin Zhu,Yicheng Zou*

Main category: cs.LG

TL;DR: 이 논문에서는 과학 전문 분야에서의 성과를 향상시키기 위해 고안된 Intern-S1 모델을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 고값이지만 도전적인 과학 분야에서 오픈 소스 모델과 클로즈드 소스 모델 간의 성능 차이를 줄이기 위해.

Method: Intern-S1는 280억 개의 활성화 매개변수와 2410억 개의 총 매개변수를 가진 다중 모달 혼합 전문가(MoE) 모델로, 과학 분야에서 25억 개 이상의 토큰을 포함한 5T 토큰으로 지속적으로 사전 훈련된다. 훈련 후에는 내부 부트캠프에서 오프라인 및 온라인 강화 학습(RL)을 진행하며, 1000개 이상의 작업에서의 RL 훈련을 위해 보상 혼합(MoR) 기법을 제안한다.

Result: Intern-S1는 온라인 RL 훈련에서 최상위 성능을 달성하며, 일반 추론 작업에서 오픈 소스 모델들과 경쟁력을 나타내며, 과학 분야에서는 클로즈드 소스 최신 모델을 초월하는 성능을 발휘했다.

Conclusion: 이 연구는 과학적 연구의 혁신을 가능하게 하는 오픈 소스 모델의 잠재력을 보여준다.

Abstract: In recent years, a plethora of open-source foundation models have emerged,
achieving remarkable progress in some widely attended fields, with performance
being quite close to that of closed-source models. However, in high-value but
more challenging scientific professional fields, either the fields still rely
on expert models, or the progress of general foundation models lags
significantly compared to those in popular areas, far from sufficient for
transforming scientific research and leaving substantial gap between
open-source models and closed-source models in these scientific domains. To
mitigate this gap and explore a step further toward Artificial General
Intelligence (AGI), we introduce Intern-S1, a specialized generalist equipped
with general understanding and reasoning capabilities with expertise to analyze
multiple science modal data. Intern-S1 is a multimodal Mixture-of-Experts (MoE)
model with 28 billion activated parameters and 241 billion total parameters,
continually pre-trained on 5T tokens, including over 2.5T tokens from
scientific domains. In the post-training stage, Intern-S1 undergoes offline and
then online reinforcement learning (RL) in InternBootCamp, where we propose
Mixture-of-Rewards (MoR) to synergize the RL training on more than 1000 tasks
simultaneously. Through integrated innovations in algorithms, data, and
training systems, Intern-S1 achieved top-tier performance in online RL
training.On comprehensive evaluation benchmarks, Intern-S1 demonstrates
competitive performance on general reasoning tasks among open-source models and
significantly outperforms open-source models in scientific domains, surpassing
closed-source state-of-the-art models in professional tasks, such as molecular
synthesis planning, reaction condition prediction, predicting thermodynamic
stabilities for crystals. Our models are available at
https://huggingface.co/internlm/Intern-S1.

</details>
