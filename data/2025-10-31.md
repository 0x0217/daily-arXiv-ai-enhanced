<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 18]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.MA](#cs.MA) [Total: 7]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on ViT-Based Medical Imaging](https://arxiv.org/abs/2510.24976)
*Banafsheh Saber Latibari,Najmeh Nazari,Hossein Sayadi,Houman Homayoun,Abhijit Mahalanobis*

Main category: cs.CR

TL;DR: 본 논문에서는 의료 이미지 시스템의 무결성을 해칠 수 있는 Med-Hammer라는 새로운 위협 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 의료 이미지 분석에서 ViT 모델의 취약성을 해결하기 위한 필요성이 대두되고 있다.

Method: Rowhammer 하드웨어 결함 주입과 신경 트로이 목마 공격을 결합하여 ViT 기반 시스템에 대한 공격을 수행하는 방법을 소개한다.

Result: 모바일ViT와 SwinTransformer에서 각각 공격 성공률 82.51%와 92.56%를 기록하며, stealthy한 공격이 가능함을 보여준다.

Conclusion: 하드웨어 결함과 딥러닝 보안 간의 중요한 상호작용을 부각시키며, 모델 아키텍처와 하드웨어 플랫폼 전반에 걸친 견고한 방어가 필요함을 강조한다.

Abstract: Vision Transformers (ViTs) have emerged as powerful architectures in medical
image analysis, excelling in tasks such as disease detection, segmentation, and
classification. However, their reliance on large, attention-driven models makes
them vulnerable to hardware-level attacks. In this paper, we propose a novel
threat model referred to as Med-Hammer that combines the Rowhammer hardware
fault injection with neural Trojan attacks to compromise the integrity of
ViT-based medical imaging systems. Specifically, we demonstrate how malicious
bit flips induced via Rowhammer can trigger implanted neural Trojans, leading
to targeted misclassification or suppression of critical diagnoses (e.g.,
tumors or lesions) in medical scans. Through extensive experiments on benchmark
medical imaging datasets such as ISIC, Brain Tumor, and MedMNIST, we show that
such attacks can remain stealthy while achieving high attack success rates
about 82.51% and 92.56% in MobileViT and SwinTransformer, respectively. We
further investigate how architectural properties, such as model sparsity,
attention weight distribution, and the number of features of the layer, impact
attack effectiveness. Our findings highlight a critical and underexplored
intersection between hardware-level faults and deep learning security in
healthcare applications, underscoring the urgent need for robust defenses
spanning both model architectures and underlying hardware platforms.

</details>


### [2] [AgentCyTE: Leveraging Agentic AI to Generate Cybersecurity Training & Experimentation Scenarios](https://arxiv.org/abs/2510.25189)
*Ana M. Rodriguez,Jaime Acosta,Anantaa Kotal,Aritran Piplai*

Main category: cs.CR

TL;DR: AgentCyTE는 LLM 기반 추론과 결정론적 네트워크 에뮬레이션을 통합하여 실행 가능한 위협 환경을 생성하고 개선하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 현실적이고 적응 가능한 네트워크 위협 시나리오 설계는 사이버 보안 연구 및 교육에서 핵심 도전 과제이다.

Method: LLM 기반 추론과 결정론적, 스키마 제약 네트워크 에뮬레이션을 통합한 프레임워크인 AgentCyTE를 제안한다.

Result: AgentCyTE는 시나리오 결과를 관찰하고 정확성을 검증하며 현실감과 일관성을 반복적으로 향상시키는 에이전틱 피드백 루프를 통해 효과적으로 작동한다.

Conclusion: LLM의 유연성을 유지하면서도 구조적 유효성을 강제하여 대규모 데이터 기반 실험 및 신뢰할 수 있는 시나리오 생성을 가능하게 한다.

Abstract: Designing realistic and adaptive networked threat scenarios remains a core
challenge in cybersecurity research and training, still requiring substantial
manual effort. While large language models (LLMs) show promise for automated
synthesis, unconstrained generation often yields configurations that fail
validation or execution. We present AgentCyTE, a framework integrating
LLM-based reasoning with deterministic, schema-constrained network emulation to
generate and refine executable threat environments. Through an agentic feedback
loop, AgentCyTE observes scenario outcomes, validates correctness, and
iteratively enhances realism and consistency. This hybrid approach preserves
LLM flexibility while enforcing structural validity, enabling scalable,
data-driven experimentation and reliable scenario generation for threat
modeling and adaptive cybersecurity training. Our framework can be accessed at:
https://github.com/AnantaaKotal/AgentCyTE

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [Fortytwo: Swarm Inference with Peer-Ranked Consensus](https://arxiv.org/abs/2510.24801)
*Vladyslav Larin,Ihor Naumenko,Aleksei Ivashov,Ivan Nikitin,Alexander Firsov*

Main category: cs.LG

TL;DR: 분산 AI 추론을 위한 새로운 프로토콜인 Fortytwo를 제안하며, 이는 무리 지능 원칙과 분산 쌍순위 합의를 활용하여 우수한 성능을 달성합니다.


<details>
  <summary>Details</summary>
Motivation: 중앙 집중형 AI의 한계와 대규모 훈련에서의 수익 감소를 극복하고, 수요에 맞는 수평적으로 확장 가능한 추론 계층을 필요로 합니다.

Method: 무리 추론을 통해 동종 모델 간 동료 평가를 기반으로 한 reputaion-weighted 합의를 활용하여 최상의 응답을 도출합니다.

Result: Fortytwo는 GPQA Diamond에서 85.90%의 정확도를 달성하며, 기존 대다수 투표 방식에 비해 +17.21% 포인트 향상된 결과를 보여줍니다.

Conclusion: 분산 AI 시스템의 기초를 마련하고, 집단 지성을 통해 신뢰성과 보안을 희생하지 않으면서 고품질 추론에 대한 접근을 민주화합니다.

Abstract: As centralized AI hits compute ceilings and diminishing returns from
ever-larger training runs, meeting demand requires an inference layer that
scales horizontally in both capacity and capability. We present Fortytwo, a
novel protocol that leverages swarm intelligence principles and distributed
pairwise ranking consensus to achieve superior performance in AI inference. Our
approach reimagines collaboration among AI nodes using swarm inference: a
peer-ranked, reputation-weighted consensus across heterogeneous models that
surfaces the highest-quality responses. Using pairwise ranking with a custom
Bradley-Terry-style aggregation model, we demonstrate that swarm inference
substantially outperforms majority voting, achieving 85.90% on GPQA Diamond
versus 68.69% for majority voting with the same model set - an improvement of
+17.21 percentage points (approximately +25.1% relative). The protocol
incorporates on-chain reputation so node influence adapts to demonstrated
accuracy over time, yielding a meritocratic consensus that filters low-quality
or malicious participants. To resist Sybil attacks, Fortytwo employs
proof-of-capability in its consensus: nodes must successfully complete
calibration/test requests and stake reputation to enter ranking rounds, making
multi-identity attacks economically unattractive while preserving openness.
Across six challenging benchmarks, including GPQA Diamond, LiveCodeBench, and
AIME, our evaluation indicates higher accuracy and strong resilience to
adversarial and noisy free-form prompting (e.g., prompt-injection degradation
of only 0.12% versus 6.20% for a monolithic single-model baseline), while
retaining practical deployability. Together, these results establish a
foundation for decentralized AI systems - democratizing access to high-quality
inference through collective intelligence without sacrificing reliability or
security.

</details>


### [4] [Adaptive EEG-based stroke diagnosis with a GRU-TCN classifier and deep Q-learning thresholding](https://arxiv.org/abs/2510.24889)
*Shakeel Abdulkareem,Bora Yimenicioglu,Khartik Uppalapati,Aneesh Gudipati,Adan Eftekhari,Saleh Yassin*

Main category: cs.LG

TL;DR: 이 논문은 뇌졸중 의심 환자의 신속 분류를 위한 적응형 다중작업 EEG 분류기를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 뇌졸중을 의심하는 환자의 신속한 분류를 위해서는 정확하고 즉시 사용할 수 있는 도구가 필요하다.

Method: 32채널 신호를 파워 스펙트럼 밀도 특징으로 변환하고, GRU-TCN을 사용하여 뇌졸중 유형을 예측하며, DQN을 적용하여 실시간으로 의사결정 임계값을 조정하는 적응형 다중작업 EEG 분류기를 개발하였다.

Result: 질병 유형, 심각도, 측좌화를 예측하는 데 있어 GRU-TCN은 각각 89.3%, 96.9%, 96.7%의 정확도를 달성하였으며, DQN 임계값 조정을 통해 뇌졸중 유형의 정확도가 98.0%로 증가하였다.

Conclusion: 적응형 임계값 조정은 임상적으로 선호되는 민감도-특이도의 균형으로 운영 지점을 변화시키며, 통합된 두피 맵 및 스펙트럼 시각화는 해석 가능성을 지원한다.

Abstract: Rapid triage of suspected stroke needs accurate, bedside-deployable tools;
EEG is promising but underused at first contact. We present an adaptive
multitask EEG classifier that converts 32-channel signals to power spectral
density features (Welch), uses a recurrent-convolutional network (GRU-TCN) to
predict stroke type (healthy, ischemic, hemorrhagic), hemispheric
lateralization, and severity, and applies a deep Q-network (DQN) to tune
decision thresholds in real time. Using a patient-wise split of the UCLH Stroke
EIT/EEG data set (44 recordings; about 26 acute stroke, 10 controls), the
primary outcome was stroke-type performance; secondary outcomes were severity
and lateralization. The baseline GRU-TCN reached 89.3% accuracy (F1 92.8%) for
stroke type, about 96.9% (F1 95.9%) for severity, and about 96.7% (F1 97.4%)
for lateralization. With DQN threshold adaptation, stroke-type accuracy
increased to about 98.0% (F1 97.7%). We also tested robustness on an
independent, low-density EEG cohort (ZJU4H) and report paired patient-level
statistics. Analyses follow STARD 2015 guidance for diagnostic accuracy studies
(index test: GRU-TCN+DQN; reference standard: radiology/clinical diagnosis;
patient-wise evaluation). Adaptive thresholding shifts the operating point to
clinically preferred sensitivity-specificity trade-offs, while integrated
scalp-map and spectral visualizations support interpretability.

</details>


### [5] [Enhancing Hierarchical Reinforcement Learning through Change Point Detection in Time Series](https://arxiv.org/abs/2510.24988)
*Hemanath Arumugam,Falong Fan,Bo Liu*

Main category: cs.LG

TL;DR: 본 논문은 HRL의 실용적 구현 문제를 해결하기 위해 변별력 제어와 옵션 비평가 프레임워크를 통합한 새로운 아키텍처를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: HRL은 장기 과제에서 의사 결정의 확장성을 향상시키지만, 의미 있는 하위 목표를 자율적으로 발견하고 최적 옵션 종료 경계를 학습하는 데 난관이 있습니다.

Method: 자기 감독 방식의 Transformer 기반 변화점 감지(CPD) 모듈을 옵션-비평가 프레임워크에 통합하여 상태 궤적의 적응적 분할과 옵션 발견을 가능하게 합니다.

Result: CPD 기반의 에이전트는 더 빠른 수렴, 더 높은 누적 수익, 그리고 옵션 전문화의 유의미한 개선을 보였습니다.

Conclusion: 변화점 분할을 통한 구조적 우선 사항 통합은 복잡한 환경에서 더 해석 가능하고 샘플 효율적이며 강인한 계층적 정책으로 이어집니다.

Abstract: Hierarchical Reinforcement Learning (HRL) enhances the scalability of
decision-making in long-horizon tasks by introducing temporal abstraction
through options-policies that span multiple timesteps. Despite its theoretical
appeal, the practical implementation of HRL suffers from the challenge of
autonomously discovering semantically meaningful subgoals and learning optimal
option termination boundaries. This paper introduces a novel architecture that
integrates a self-supervised, Transformer-based Change Point Detection (CPD)
module into the Option-Critic framework, enabling adaptive segmentation of
state trajectories and the discovery of options. The CPD module is trained
using heuristic pseudo-labels derived from intrinsic signals to infer latent
shifts in environment dynamics without external supervision. These inferred
change-points are leveraged in three critical ways: (i) to serve as supervisory
signals for stabilizing termination function gradients, (ii) to pretrain
intra-option policies via segment-wise behavioral cloning, and (iii) to enforce
functional specialization through inter-option divergence penalties over
CPD-defined state partitions. The overall optimization objective enhances the
standard actor-critic loss using structure-aware auxiliary losses. In our
framework, option discovery arises naturally as CPD-defined trajectory segments
are mapped to distinct intra-option policies, enabling the agent to
autonomously partition its behavior into reusable, semantically meaningful
skills. Experiments on the Four-Rooms and Pinball tasks demonstrate that
CPD-guided agents exhibit accelerated convergence, higher cumulative returns,
and significantly improved option specialization. These findings confirm that
integrating structural priors via change-point segmentation leads to more
interpretable, sample-efficient, and robust hierarchical policies in complex
environments.

</details>


### [6] [Machine Learning based Analysis for Radiomics Features Robustness in Real-World Deployment Scenarios](https://arxiv.org/abs/2510.25026)
*Sarmad Ahmad Khan,Simon Bernatz,Zahra Moslehi,Florian Buettner*

Main category: cs.LG

TL;DR: Radiomics 기반 기계 학습 모델은 임상 의사 결정을 지원하는 데 유망하지만, 영상 프로토콜, 위치 및 분할의 변동으로 인한 분포 변화에 취약하다. 이 연구는 다섯 가지 MRI 시퀀스에서 이러한 모델의 강인성을 체계적으로 조사하였다.


<details>
  <summary>Details</summary>
Motivation: Radiomics 기반 모델의 임상적 유용성을 극대화하고, 다양한 분포 변화에 대한 견고성을 확보하기 위해.

Method: 16종의 과일을 사용한 팬텀을 통해 T2-HASTE, T2-TSE, T2-MAP, T1-TSE, T2-FLAIR 시퀀스 간의 프로토콜 변화, 분할 변화 (전체, 부분, 회전) 및 관찰자 간 변동성을 평가.

Result: 프로토콜 불변 특성에 대해 훈련된 모델은 분포 변화에도 F1 점수가 0.85 이상 유지되었고, 모든 특성을 사용한 모델은 프로토콜 변화 시 40% 성능 저하를 경험하였다.

Conclusion: 프로토콜 인식 특성 선택과 통제된 팬텀 연구가 분포 변화 하에서 모델 행동을 효과적으로 예측한다는 것을 밝혀냈다.

Abstract: Radiomics-based machine learning models show promise for clinical decision
support but are vulnerable to distribution shifts caused by variations in
imaging protocols, positioning, and segmentation. This study systematically
investigates the robustness of radiomics-based machine learning models under
distribution shifts across five MRI sequences. We evaluated how different
acquisition protocols and segmentation strategies affect model reliability in
terms of predictive power and uncertainty-awareness. Using a phantom of 16
fruits, we evaluated distribution shifts through: (1) protocol variations
across T2-HASTE, T2-TSE, T2-MAP, T1-TSE, and T2-FLAIR sequences; (2)
segmentation variations (full, partial, rotated); and (3) inter-observer
variability. We trained XGBoost classifiers on 8 consistent robust features
versus sequence-specific features, testing model performance under in-domain
and out-of-domain conditions. Results demonstrate that models trained on
protocol-invariant features maintain F1-scores >0.85 across distribution
shifts, while models using all features showed 40% performance degradation
under protocol changes. Dataset augmentation substantially improved the quality
of uncertainty estimates and reduced the expected calibration error (ECE) by
35% without sacrificing accuracy. Temperature scaling provided minimal
calibration benefits, confirming XGBoost's inherent reliability. Our findings
reveal that protocol-aware feature selection and controlled phantom studies
effectively predict model behavior under distribution shifts, providing a
framework for developing robust radiomics models resilient to real-world
protocol variations.

</details>


### [7] [Training Across Reservoirs: Using Numerical Differentiation To Couple Trainable Networks With Black-Box Reservoirs](https://arxiv.org/abs/2510.25074)
*Andrew Clark,Jack Moursounidis,Osmaan Rasouli,William Gan,Cooper Doyle,Anna Leontjeva*

Main category: cs.LG

TL;DR: BOND는 접근할 수 없는 컴퓨팅 그래프를 가진 네트워크 구조에서 부분 미분을 추정하기 위한 고무적인 방법으로, 기존 방법들보다 더 나은 정확도와 확장성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 이 연구의 목적은 접근할 수 없는 컴퓨팅 그래프를 가진 네트워크 구조에서 부분 미분을 보다 효과적으로 추정하기 위한 새로운 방법을 제시하는 것이다.

Method: BOND는 perturbative 기법을 사용하여 훈련 가능한 아키텍처가 블랙 박스 함수를 통합하도록 하는 새로운 탐색을 가능하게 한다.

Result: BOND는 고정된 비훈련 네트워크로 구현된 블랙 박스 함수가 훈련 가능한 매개변수의 수를 증가시키지 않으면서 모델 성능을 향상시킬 수 있음을 보여준다.

Conclusion: 이론적 최적화 없이 고정된 비훈련 모듈을 활용하여 모델 용량을 확장할 가능성을 강조하며, 아날로그 및 디지털 장치를 결합하여 네트워크를 확장할 수 있는 경로를 제안한다.

Abstract: We introduce Bounded Numerical Differentiation (BOND), a perturbative method
for estimating partial derivatives across network structures with inaccessible
computational graphs. BOND demonstrates improved accuracy and scalability from
existing perturbative methods, enabling new explorations of trainable
architectures that integrate black-box functions. We observe that these
black-box functions, realized in our experiments as fixed, untrained networks,
can enhance model performance without increasing the number of trainable
parameters. This improvement is achieved without extensive optimization of the
architecture or properties of the black-box function itself. Our findings
highlight the potential of leveraging fixed, non-trainable modules to expand
model capacity, suggesting a path toward combining analogue and digital devices
as a mechanism for scaling networks.

</details>


### [8] [Selective Learning for Deep Time Series Forecasting](https://arxiv.org/abs/2510.25207)
*Yisong Fu,Zezhi Shao,Chengqing Yu,Yujie Li,Zhulin An,Qi Wang,Yongjun Xu,Fei Wang*

Main category: cs.LG

TL;DR: 이 논문에서는 딥러닝의 선택적 학습 전략을 통해 시간 시계열 예측의 정확성을 개선하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 시간 시계열은 노이즈와 이상에 취약하기 때문에 딥 모델들이 과적합되는 문제를 해결할 필요가 있습니다.

Method: 선택적 학습 전략은 전체 타임스텝 중 일부를 필터링하여 MSE 손실을 계산하고, 일반화 가능한 타임스텝에 집중하게 합니다.

Result: 8개의 실제 데이터셋에서 실험 결과, 선택적 학습은 Informer에서 MSE 37.4%, TimesNet에서 8.4%, iTransformer에서 6.5% 감소를 시켜 예측 성능을 개선했습니다.

Conclusion: 제안된 이중 마스크 메커니즘은 불확실성과 이상 타임스텝을 필터링하는 데 효과적이라는 것을 보여주었습니다.

Abstract: Benefiting from high capacity for capturing complex temporal patterns, deep
learning (DL) has significantly advanced time series forecasting (TSF).
However, deep models tend to suffer from severe overfitting due to the inherent
vulnerability of time series to noise and anomalies. The prevailing DL paradigm
uniformly optimizes all timesteps through the MSE loss and learns those
uncertain and anomalous timesteps without difference, ultimately resulting in
overfitting. To address this, we propose a novel selective learning strategy
for deep TSF. Specifically, selective learning screens a subset of the whole
timesteps to calculate the MSE loss in optimization, guiding the model to focus
on generalizable timesteps while disregarding non-generalizable ones. Our
framework introduces a dual-mask mechanism to target timesteps: (1) an
uncertainty mask leveraging residual entropy to filter uncertain timesteps, and
(2) an anomaly mask employing residual lower bound estimation to exclude
anomalous timesteps. Extensive experiments across eight real-world datasets
demonstrate that selective learning can significantly improve the predictive
performance for typical state-of-the-art deep models, including 37.4% MSE
reduction for Informer, 8.4% for TimesNet, and 6.5% for iTransformer.

</details>


### [9] [BSFA: Leveraging the Subspace Dichotomy to Accelerate Neural Network Training](https://arxiv.org/abs/2510.25244)
*Wenjie Zhou,Bohan Wang,Wei Chen,Xueqi Cheng*

Main category: cs.LG

TL;DR: 딥러닝 최적화에서 손실 헤시안의 상위 고유 방향을 따라 매개변수 업데이트가 대부분의 업데이트 크기를 포착하지만 손실 감소에는 최소한으로 기여하는 현상을 설명한다. 본 연구에서는 이 현상을 더 발전시키고 새로운 프레임워크인 BSFA를 도입한다. BSFA는 업데이트 구성 요소를 차별적으로 스케일링하여 학습을 가속화하며, 현대 대규모 모델들에서 실용적이고 확장 가능하게 설계되었다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 최적화의 기본적인 이분법을 이해하고, 손실 감소와 학습 진행 간의 상관관계를 명확히 하기 위함.

Method: BSFA는 손실 헤시안의 두 개의 서로 다른 부분 공간(Dom-space와 Bulk-space)에서 업데이트 구성 요소를 차별적으로 스케일링하여 학습을 가속화하고 안정성을 향상시킨다.

Result: LLaMA-72M을 WikiText-103에서, LLaMA-134M을 OpenWebText에서 사전학습할 때 vanilla AdamW보다 약 2배의 속도 향상을 달성하였다.

Conclusion: BSFA는 대규모 모델에 대해 실용적이고 효과적인 가속화 방법을 제공한다.

Abstract: Recent studies \citep{gur2018gradient,song2024does, wen2024understanding}
highlight a fundamental dichotomy in deep learning optimization: Although
parameter updates along the top eigendirections of the loss Hessian (Dom-space)
capture most of the update magnitude, they often contribute minimally to loss
reduction. In contrast, updates in the orthogonal component (Bulk-space) have
smaller magnitudes but drive most learning progress. In this work, we further
advance the understanding of this phenomenon and introduce the
\textbf{Bulk-Space-Filtration-Accelerator (BSFA)}, a novel plug-and-play
framework. BSFA accelerates training by differentially scaling update
components projected onto these distinct subspaces, simultaneously enhancing
stability by moderating updates in the dominant subspace and boosting
convergence speed by amplifying those in the bulk-space. To ensure BSFA is both
practical and scalable for contemporary large models, we introduce two key
innovations: an efficient estimator using Principal Component Analysis (PCA) on
historical updates for fast subspace estimation, and a block-wise strategy that
applies this estimation on a per-parameter-block basis. These designs make BSFA
computationally tractable and highly effective. We demonstrate BSFA's
acceleration across various tasks, notably achieving approximately 2$\times$
speedup when pre-training LLaMA-72M on WikiText-103 and LLaMA-134M on
OpenWebText compared to vanilla AdamW.

</details>


### [10] [Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning](https://arxiv.org/abs/2510.25311)
*Sagalpreet Singh,Rishi Saket,Aravindan Raghuveer*

Main category: cs.LG

TL;DR: 이 논문은 목표 상태에 고르게 방문하면서 기대 수익을 최대화하는 Multi Goal RL 문제를 공식화하고, 목표 상태 집합에서 분산된 마지널 상태 분포를 갖는 고수익 정책 조합을 학습하는 새로운 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자연 상황에서는 목표 상태에 고르게 방문하여 기대 수익을 극대화하는 정책을 학습하는 것이 바람직하다.

Method: 현재 정책 혼합을 기반으로 한 사용자 정의 RL 보상을 최적화하여 샘플링된 경로 집합을 사용해 정책 혼합을 업데이트하는 알고리즘을 제안한다.

Result: 자신의 알고리즘에 대해 기대 수익 및 목표 상태에 대한 마지널 상태 분포의 분산을 포착하는 자연 목표를 최적화하는 효율적인 수렴 경계를 보여준다.

Conclusion: 합성 MDP와 표준 RL 환경에서 알고리즘의 효과를 평가하는 실험을 설계하고 수행하였다.

Abstract: Reinforcement Learning algorithms are primarily focused on learning a policy
that maximizes expected return. As a result, the learned policy can exploit one
or few reward sources. However, in many natural situations, it is desirable to
learn a policy that induces a dispersed marginal state distribution over
rewarding states, while maximizing the expected return which is typically tied
to reaching a goal state. This aspect remains relatively unexplored. Existing
techniques based on entropy regularization and intrinsic rewards use
stochasticity for encouraging exploration to find an optimal policy which may
not necessarily lead to dispersed marginal state distribution over rewarding
states. Other RL algorithms which match a target distribution assume the latter
to be available apriori. This may be infeasible in large scale systems where
enumeration of all states is not possible and a state is determined to be a
goal state only upon reaching it. We formalize the problem of maximizing the
expected return while uniformly visiting the goal states as Multi Goal RL in
which an oracle classifier over the state space determines the goal states. We
propose a novel algorithm that learns a high-return policy mixture with
marginal state distribution dispersed over the set of goal states. Our
algorithm is based on optimizing a custom RL reward which is computed - based
on the current policy mixture - at each iteration for a set of sampled
trajectories. The latter are used via an offline RL algorithm to update the
policy mixture. We prove performance guarantees for our algorithm, showing
efficient convergence bounds for optimizing a natural objective which captures
the expected return as well as the dispersion of the marginal state
distribution over the goal states. We design and perform experiments on
synthetic MDPs and standard RL environments to evaluate the effectiveness of
our algorithm.

</details>


### [11] [CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices](https://arxiv.org/abs/2510.25323)
*Xuchen Feng,Siyu Liao*

Main category: cs.LG

TL;DR: 이 논문에서는 순환 및 대각 행렬의 곱을 기반으로 한 새로운 가역 선형 계층을 도입하여 노말라이징 플로우의 효율성을 높이고, 밀도 추정 성능을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 가역 변환을 통한 효율적인 가능도 추정 및 샘플링을 가능하게 하면서 계산 효율성을 유지하는 선형 계층 설계의 필요성.

Method: 순환 및 대각 행렬의 곱을 기반으로 하는 새로운 가역 선형 계층을 제안하고, 이를 통해 행렬의 역행렬 계산 및 로그-determinant 계산의 시간 복잡도를 줄입니다.

Result: CDFlow는 자연 이미지 데이터셋에서 강력한 밀도 추정 성능을 달성하고, 고유한 주기적 구조를 가진 데이터를 효과적으로 모델링합니다.

Conclusion: CDFlow는 노말라이징 플로우의 핵심 연산을 가속화하여 확장 가능한 생성 모델링에 실용적인 이점을 제공합니다.

Abstract: Normalizing flows are deep generative models that enable efficient likelihood
estimation and sampling through invertible transformations. A key challenge is
to design linear layers that enhance expressiveness while maintaining efficient
computation of the Jacobian determinant and inverse. We introduce a novel
invertible linear layer based on the product of circulant and diagonal
matrices. This decomposition reduces parameter complexity from
$\mathcal{O}(n^2)$ to $\mathcal{O}(mn)$ using $m$ diagonal matrices and $m-1$
circulant matrices while still approximating general linear transformations. By
leveraging the Fast Fourier Transform, our approach reduces the time complexity
of matrix inversion from $\mathcal{O}(n^3)$ to $\mathcal{O}(mn\log n)$ and that
of computing the log-determinant from $\mathcal{O}(n^3)$ to $\mathcal{O}(mn)$,
where $n$ is the input dimension. We build upon this layer to develop
Circulant-Diagonal Flow (CDFlow), which achieves strong density estimation on
natural image datasets and effectively models data with inherent periodic
structure. Furthermore, CDFlow significantly accelerates key operations in
normalizing flows, providing practical benefits for scalable generative
modeling.

</details>


### [12] [Parameter Averaging in Link Prediction](https://arxiv.org/abs/2510.25361)
*Rupesh Sapkota,Caglar Demir,Arnab Sharma,Axel-Cyrille Ngonga Ngomo*

Main category: cs.LG

TL;DR: 이 논문은 지식 그래프 임베딩(KGE) 모델에서 링크 예측을 위한 모델 병합 및 가중 평균 기법을 제안하며, 이러한 접근 방식이 성능을 향상시킴을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 머신러닝에서 일반화를 개선하기 위해 앙상블 방법이 널리 사용되며, 이는 링크 예측을 위한 KGE 모델에서도 채택되고 있다.

Method: 모델 병합, 특히 가중 평균을 KGE 모델에 도입하고, 트레이닝 에포크 이후 모델 파라미터의 이동 평균을 유지하여 예측에 사용한다.

Result: 링크 예측 작업에서 두 가지 가중 평균 접근 방식을 평가하였으며, 최신 벤치마크 앙상블 접근 방식과 비교하였다. 또한, 리터럴 강화 KGE 모델과 멀티 홉 쿼리 응답 작업에서도 이 접근 방식을 평가하였다.

Conclusion: 제안된 가중 평균 접근 방식은 다양한 평가 설정에서 일관되게 성능을 향상시킨다.

Abstract: Ensemble methods are widely employed to improve generalization in machine
learning. This has also prompted the adoption of ensemble learning for the
knowledge graph embedding (KGE) models in performing link prediction. Typical
approaches to this end train multiple models as part of the ensemble, and the
diverse predictions are then averaged. However, this approach has some
significant drawbacks. For instance, the computational overhead of training
multiple models increases latency and memory overhead. In contrast, model
merging approaches offer a promising alternative that does not require training
multiple models. In this work, we introduce model merging, specifically
weighted averaging, in KGE models. Herein, a running average of model
parameters from a training epoch onward is maintained and used for predictions.
To address this, we additionally propose an approach that selectively updates
the running average of the ensemble model parameters only when the
generalization performance improves on a validation dataset. We evaluate these
two different weighted averaging approaches on link prediction tasks, comparing
the state-of-the-art benchmark ensemble approach. Additionally, we evaluate the
weighted averaging approach considering literal-augmented KGE models and
multi-hop query answering tasks as well. The results demonstrate that the
proposed weighted averaging approach consistently improves performance across
diverse evaluation settings.

</details>


### [13] [Right for the Right Reasons: Avoiding Reasoning Shortcuts via Prototypical Neurosymbolic AI](https://arxiv.org/abs/2510.25497)
*Luca Andolfi,Eleonora Giunchiglia*

Main category: cs.LG

TL;DR: 신경 기호 AI는 신경 인식과 기호 추론을 결합하는 모델 덕분에 인기를 얻고 있지만, 최근 연구에 따르면 이러한 모델은 단기 추론에 취약하다. 이 논문에서는 이러한 문제를 해결하기 위해 전형적인 신경 기호 아키텍처를 제안하며, 이를 통해 올바른 개념을 배우고 안전하고 신뢰할 수 있는 신경 기호 학습을 위한 효과적인 전략을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 신경 기호 AI의 급증적인 인기와 함께, 단기 추론의 문제를 해결할 필요성을 느꼈다.

Method: 전형적인 신경 기호 아키텍처를 도입하고, 이러한 모델이 올바른 개념을 학습하도록 훈련하는 방법을 설명한다.

Result: 제안한 방법을 통해 다양한 설정과 작업에서 유의미한 개선을 보여주며, 특히 적은 감독 하에서도 올바른 개념 학습에 성과를 거두었다.

Conclusion: 본 연구의 결과는 안전하고 신뢰할 수 있는 신경 기호 학습을 위한 주석 효율적인 전략으로서 프로토타입 기초의 가능성을 제시한다.

Abstract: Neurosymbolic AI is growing in popularity thanks to its ability to combine
neural perception and symbolic reasoning in end-to-end trainable models.
However, recent findings reveal these are prone to shortcut reasoning, i.e., to
learning unindented concepts--or neural predicates--which exploit spurious
correlations to satisfy the symbolic constraints. In this paper, we address
reasoning shortcuts at their root cause and we introduce prototypical
neurosymbolic architectures. These models are able to satisfy the symbolic
constraints (be right) because they have learnt the correct basic concepts (for
the right reasons) and not because of spurious correlations, even in extremely
low data regimes. Leveraging the theory of prototypical learning, we
demonstrate that we can effectively avoid reasoning shortcuts by training the
models to satisfy the background knowledge while taking into account the
similarity of the input with respect to the handful of labelled datapoints. We
extensively validate our approach on the recently proposed rsbench benchmark
suite in a variety of settings and tasks with very scarce supervision: we show
significant improvements in learning the right concepts both in synthetic tasks
(MNIST-EvenOdd and Kand-Logic) and real-world, high-stake ones (BDD-OIA). Our
findings pave the way to prototype grounding as an effective,
annotation-efficient strategy for safe and reliable neurosymbolic learning.

</details>


### [14] [TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting](https://arxiv.org/abs/2510.25502)
*Vladyslav Moroshan,Julien Siems,Arber Zela,Timur Carstensen,Frank Hutter*

Main category: cs.LG

TL;DR: TempoPFN은 합성 데이터에 기반한 단일 시계열 예측 모델로, 기존 모델보다 더 효율적이고 높은 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 제로샷 시계열 예측을 위한 기반 모델들이 긴 기간 예측과 재현성의 문제에 직면하고 있다.

Method: TempoPFN은 합성 데이터에 대해 사전 훈련된 선형 순환 신경망(RNN) 기반의 단일 변수 시계열 모델로, GatedDeltaProduct 아키텍처를 사용하여 완전 병렬 훈련이 가능하다.

Result: TempoPFN은 Gift-Eval 벤치마크에서 최고 수준의 성능을 기록하며, 모든 기존 합성 모델들을 초월하고 실제 데이터를 기반으로 훈련된 모델들보다 더 나은 성능을 보였다.

Conclusion: 우리는 연구의 재현성을 높이기 위해 데이터 생성 파이프라인과 훈련 코드를 오픈소스로 제공한다.

Abstract: Foundation models for zero-shot time series forecasting face challenges in
efficient long-horizon prediction and reproducibility, with existing
synthetic-only approaches underperforming on challenging benchmarks. This paper
presents TempoPFN, a univariate time series foundation model based on linear
Recurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The
model uses a GatedDeltaProduct architecture with state-weaving for fully
parallelizable training across sequence lengths, eliminating the need for
windowing or summarization techniques while maintaining robust temporal
state-tracking. Our comprehensive synthetic data pipeline unifies diverse
generators, including stochastic differential equations, Gaussian processes,
and audio synthesis, with novel augmentations. In zero-shot evaluations on the
Gift-Eval benchmark, TempoPFN achieves top-tier competitive performance,
outperforming all existing synthetic-only approaches and surpassing the vast
majority of models trained on real-world data, while being more efficient than
existing baselines by leveraging fully parallelizable training and inference.
We open-source our complete data generation pipeline and training code,
providing a reproducible foundation for future research.

</details>


### [15] [Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided Mutual Information](https://arxiv.org/abs/2510.25542)
*Yuan Cheng,Yu Huang,Zhe Xiong,Yingbin Liang,Vincent Y. F. Tan*

Main category: cs.LG

TL;DR: 이 논문은 복잡한 부모-자식 관계를 효과적으로 모델링하기 위해 커널 기반의 상호정보량(KG-MI)와 다중 헤드 주의(framework)를 결합하여 다양한 방향성 비순환 그래프(DAG)에서의 훈련 동력을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 실제 데이터를 기반으로 숨겨진 그래프 구조를 발견하는 것은 과학적 분야에서 광범위한 응용이 필요한 중요한 도전 과제이다.

Method: KG-MI를 다중 헤드 주의 프레임워크와 결합하여 각 헤드가 고유한 마진 전이 커널과 연관되도록 하여 부모-자식 의존성을 모델링한다.

Result: 하나의 K-부모 DAG로 생성된 시퀀스를 주어진 경우, 그래디언트 상승을 통해 단일 레이어 다중 헤드 트랜스포머를 훈련하면 다항 시간 내에 글로벌 최적점으로 수렴함을 증명하였다.

Conclusion: 훈련된 주의 점수는 실제 인접 행렬을 정확하게 반영하여 숨겨진 그래프 구조를 복구해낸다는 것을 입증하였다.

Abstract: Uncovering hidden graph structures underlying real-world data is a critical
challenge with broad applications across scientific domains. Recently,
transformer-based models leveraging the attention mechanism have demonstrated
strong empirical success in capturing complex dependencies within graphs.
However, the theoretical understanding of their training dynamics has been
limited to tree-like graphs, where each node depends on a single parent.
Extending provable guarantees to more general directed acyclic graphs (DAGs) --
which involve multiple parents per node -- remains challenging, primarily due
to the difficulty in designing training objectives that enable different
attention heads to separately learn multiple different parent relationships.
  In this work, we address this problem by introducing a novel
information-theoretic metric: the kernel-guided mutual information (KG-MI),
based on the $f$-divergence. Our objective combines KG-MI with a multi-head
attention framework, where each head is associated with a distinct marginal
transition kernel to model diverse parent-child dependencies effectively. We
prove that, given sequences generated by a $K$-parent DAG, training a
single-layer, multi-head transformer via gradient ascent converges to the
global optimum in polynomial time. Furthermore, we characterize the attention
score patterns at convergence. In addition, when particularizing the
$f$-divergence to the KL divergence, the learned attention scores accurately
reflect the ground-truth adjacency matrix, thereby provably recovering the
underlying graph structure. Experimental results validate our theoretical
findings.

</details>


### [16] [Leveraging an Atmospheric Foundational Model for Subregional Sea Surface Temperature Forecasting](https://arxiv.org/abs/2510.25563)
*Víctor Medina,Giovanny A. Cuervo-Londoño,Javier Sánchez*

Main category: cs.LG

TL;DR: 이 연구에서는 심층 학습 모델을 사용하여 카나리아 상승 시스템의 해수면 온도를 예측하는 방법을 제시하고, 이를 통해 기후 모델링과 해양 예측의 정확성을 향상시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 정확한 해양 변수 예측은 기후 변화 이해, 해양 자원 관리 및 해양 활동 최적화에 중요하다.

Method: 기존의 기상 예측에 사용되는 Aurora 모델을 개조하여 해양 공간에서 SST를 예측하고, 고해상도 해양 재분석 데이터를 통해 미세 조정하였다.

Result: 모델은 0.119K의 낮은 RMSE를 달성하고, 높은 이상치 상관계수(ACC 약 0.997)를 유지하였다.

Conclusion: 이 연구는 기후 모델링과 해양 예측의 정확성을 높이고, 환경 및 경제 부문의 의사결정을 지원할 수 있는 딥러닝 모델의 가능성을 보여준다.

Abstract: The accurate prediction of oceanographic variables is crucial for
understanding climate change, managing marine resources, and optimizing
maritime activities. Traditional ocean forecasting relies on numerical models;
however, these approaches face limitations in terms of computational cost and
scalability. In this study, we adapt Aurora, a foundational deep learning model
originally designed for atmospheric forecasting, to predict sea surface
temperature (SST) in the Canary Upwelling System. By fine-tuning this model
with high-resolution oceanographic reanalysis data, we demonstrate its ability
to capture complex spatiotemporal patterns while reducing computational
demands. Our methodology involves a staged fine-tuning process, incorporating
latitude-weighted error metrics and optimizing hyperparameters for efficient
learning. The experimental results show that the model achieves a low RMSE of
0.119K, maintaining high anomaly correlation coefficients (ACC $\approx
0.997$). The model successfully reproduces large-scale SST structures but faces
challenges in capturing finer details in coastal regions. This work contributes
to the field of data-driven ocean forecasting by demonstrating the feasibility
of using deep learning models pre-trained in different domains for oceanic
applications. Future improvements include integrating additional oceanographic
variables, increasing spatial resolution, and exploring physics-informed neural
networks to enhance interpretability and understanding. These advancements can
improve climate modeling and ocean prediction accuracy, supporting
decision-making in environmental and economic sectors.

</details>


### [17] [Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization](https://arxiv.org/abs/2510.25616)
*Nikita Kachaev,Mikhail Kolosov,Daniil Zelezetsky,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: VLA 모델의 미세 조정 중 비주얼 표현 저하 문제를 연구하고 해결 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 사전 훈련된 비전-언어 모델이 에이전트에 세계 지식과 비전-언어 기초를 제공할 수 있다는 가능성으로 VLA 모델이 성공하고 있습니다.

Method: VLA의 미세 조정 과정에서 표현 보존을 체계적으로 연구하고, 숨겨진 표현과 주의 맵을 분석하며, VLA 모델과 VLM의 대조적 작업을 설계했습니다.

Result: 단순한 미세 조정은 비주얼 표현을 저하시킨다는 결과를 보여주었고, 여러 전략을 평가한 결과 효과적인 방법을 제시했습니다.

Conclusion: 행동 미세 조정과 VL 표현의 저하 간의 트레이드오프를 명확히 하고, VL 능력을 회복할 수 있는 실질적인 접근 방식을 강조합니다.

Abstract: The growing success of Vision-Language-Action (VLA) models stems from the
promise that pretrained Vision-Language Models (VLMs) can endow agents with
transferable world knowledge and vision-language (VL) grounding, laying a
foundation for action models with broader generalization. Yet when these VLMs
are adapted to the action modality, it remains unclear to what extent their
original VL representations and knowledge are preserved. In this work, we
conduct a systematic study of representation retention during VLA fine-tuning,
showing that naive action fine-tuning leads to degradation of visual
representations. To characterize and measure these effects, we probe VLA's
hidden representations and analyze attention maps, further, we design a set of
targeted tasks and methods that contrast VLA models with their counterpart
VLMs, isolating changes in VL capabilities induced by action fine-tuning. We
further evaluate a range of strategies for aligning visual representations and
introduce a simple yet effective method that mitigates degradation and yields
improved generalization to out-of-distribution (OOD) scenarios. Taken together,
our analysis clarifies the trade-off between action fine-tuning and the
degradation of VL representations and highlights practical approaches to
recover inherited VL capabilities. Code is publicly available:
https://blind-vla-paper.github.io

</details>


### [18] [Convolutional Spiking-based GRU Cell for Spatio-temporal Data](https://arxiv.org/abs/2510.25696)
*Yesmine Abdennadher,Eleonora Cicciarella,Michele Rossi*

Main category: cs.LG

TL;DR: CS-GRU는 시공간 데이터 처리에서 기존 GRU 변형에 비해 4.35% 높은 성능과 90% 이상의 정확도를 보여준다.


<details>
  <summary>Details</summary>
Motivation: SNN과 GRU의 결합을 통해 시퀀스 데이터 처리의 강력한 프레임워크를 제공하고, 기존 RNN의 한계를 극복하려고 한다.

Method: Convolutional Spiking GRU (CS-GRU) 셀을 도입하여 컨볼루션 연산을 활용해 지역 구조와 의존성을 유지하면서 시건너 스파이킹 뉴런의 시간적 정밀성과 GRU의 효율적인 게이팅 메커니즘을 통합한다.

Result: CS-GRU는 기존 최첨단 GRU 변형보다 평균 4.35% 높은 성능을 발휘하며, 순차적 과제에서 90% 이상의 정확도와 MNIST에서 99.31%의 성과를 달성했다.

Conclusion: CS-GRU는 SpikGRU에 비해 69% 높은 효율성을 기록하며, 다양한 시기념 데이터셋에서 뛰어난 성능을 보인다.

Abstract: Spike-based temporal messaging enables SNNs to efficiently process both
purely temporal and spatio-temporal time-series or event-driven data. Combining
SNNs with Gated Recurrent Units (GRUs), a variant of recurrent neural networks,
gives rise to a robust framework for sequential data processing; however,
traditional RNNs often lose local details when handling long sequences.
Previous approaches, such as SpikGRU, fail to capture fine-grained local
dependencies in event-based spatio-temporal data. In this paper, we introduce
the Convolutional Spiking GRU (CS-GRU) cell, which leverages convolutional
operations to preserve local structure and dependencies while integrating the
temporal precision of spiking neurons with the efficient gating mechanisms of
GRUs. This versatile architecture excels on both temporal datasets (NTIDIGITS,
SHD) and spatio-temporal benchmarks (MNIST, DVSGesture, CIFAR10DVS). Our
experiments show that CS-GRU outperforms state-of-the-art GRU variants by an
average of 4.35%, achieving over 90% accuracy on sequential tasks and up to
99.31% on MNIST. It is worth noting that our solution achieves 69% higher
efficiency compared to SpikGRU. The code is available at:
https://github.com/YesmineAbdennadher/CS-GRU.

</details>


### [19] [LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries](https://arxiv.org/abs/2510.25731)
*René P. Klausen,Ivan Timofeev,Johannes Frank,Jonas Naujoks,Thomas Wiegand,Sebastian Lapuschkin,Wojciech Samek*

Main category: cs.LG

TL;DR: 이 논문에서는 Lie 대칭을 활용하여 초기-경계 값 문제(IBVP)를 효율적으로 해결하는 방법을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 초기-경계 값 문제의 정확한 해를 얻기 위해 물리 법칙을 모델에 내재화하는 방법이 필요합니다.

Method: 대칭 변환을 활용하여 모델이 초기 및 경계 데이터에서 해결책을 학습하도록 하고, 손실이 모델의 정확성을 직접적으로 측정합니다.

Result: 우리의 방법인 LieSolver는 다양한 초기 조건을 가진 선형 동차 편미분 방정식에 적용되는 것이며, 물리적 정보를 고려한 신경망보다 빠르고 정확합니다.

Conclusion: 이 방법은 편미분 방정식 제약 문제의 계산 효율성과 예측 신뢰성을 모두 향상시킵니다.

Abstract: We introduce a method for efficiently solving initial-boundary value problems
(IBVPs) that uses Lie symmetries to enforce the associated partial differential
equation (PDE) exactly by construction. By leveraging symmetry transformations,
the model inherently incorporates the physical laws and learns solutions from
initial and boundary data. As a result, the loss directly measures the model's
accuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our
method enables rigorous error estimation. The approach yields compact models,
facilitating an efficient optimization. We implement LieSolver and demonstrate
its application to linear homogeneous PDEs with a range of initial conditions,
showing that it is faster and more accurate than physics-informed neural
networks (PINNs). Overall, our method improves both computational efficiency
and the reliability of predictions for PDE-constrained problems.

</details>


### [20] [Synthetic Data Reveals Generalization Gaps in Correlated Multiple Instance Learning](https://arxiv.org/abs/2510.25759)
*Ethan Harvey,Dennis Johan Loevlie,Michael C. Hughes*

Main category: cs.LG

TL;DR: 기존의 MIL 접근 방식은 인스턴스를 개별적으로 취급하여 실제 애플리케이션에서 필수인 맥락적 관계를 무시하는 한계가 있다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상 분류에서 인스턴스 간의 맥락적 관계를 반영할 필요성.

Method: 인접한 인스턴스 특징을 고려해야 하는 합성 분류 작업을 설계하고, 기존 MIL 방법의 성능을 최적 베이즈 추정기와 비교하여 평가.

Result: 기존 MIL 접근 방식의 한계를 발견하고, 새로운 상관된 MIL 방법이 수만 개 인스턴스에서 학습할 때 일반화에 어려움을 겪는 것을 보여줌.

Conclusion: 단순한 MIL 방법은 복잡한 의료 영상 데이터에 부적합하며, 인접 인스턴스 특징을 반영하는 접근이 필요하다.

Abstract: Multiple instance learning (MIL) is often used in medical imaging to classify
high-resolution 2D images by processing patches or classify 3D volumes by
processing slices. However, conventional MIL approaches treat instances
separately, ignoring contextual relationships such as the appearance of nearby
patches or slices that can be essential in real applications. We design a
synthetic classification task where accounting for adjacent instance features
is crucial for accurate prediction. We demonstrate the limitations of
off-the-shelf MIL approaches by quantifying their performance compared to the
optimal Bayes estimator for this task, which is available in closed-form. We
empirically show that newer correlated MIL methods still struggle to generalize
as well as possible when trained from scratch on tens of thousands of
instances.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [21] [Reasoning-Aware GRPO using Process Mining](https://arxiv.org/abs/2510.25065)
*Taekhyun Park,Yongjae Lee,Hyerim Bae*

Main category: cs.AI

TL;DR: PM4GRPO는 기존의 GRPO 기반 후속 훈련 방법론을 능가하여 정책 모델의 추론 능력을 향상시키는 새로운 방법론이다.


<details>
  <summary>Details</summary>
Motivation: 다단계 추론이 가능한 대규모 추론 모델을 위한 후속 훈련에서 강화 학습 기반 접근 방식이 중요하다.

Method: PM4GRPO는 추론 절차에 대한 신호로 표준 답변/형식 보상을 보강하는 추론 인식 그룹 상대 정책 최적화(GRPO)이다.

Result: 다섯 개의 벤치마크에서의 경험적 결과는 PM4GRPO가 기존의 GRPO 기반 후속 훈련 방법론보다 상당히 뛰어난 성능을 보임을 보여준다.

Conclusion: 프로세스 마이닝을 활용한 추론 인식 GRPO가 정책 모델의 추론 능력을 효과적으로 향상시킨다.

Abstract: Reinforcement learning (RL)-based post-training has been crucial for enabling
multi-step reasoning in large reasoning models (LRMs), yet current reward
schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware
Group Relative Policy Optimization (GRPO) that augments standard answer/format
rewards with signals over the reasoning procedure. To this end, process mining
techniques are utilized to compute a scalar conformance reward that measures
how closely a policy model's reasoning aligns with the pretrained teacher
model. The empirical results on five benchmarks demonstrate that PM4GRPO
significantly outperforms existing methodologies for GRPO-based post-training.
These results highlight that leveraging process mining for reasoning-aware GRPO
effectively enhances the reasoning capabilities of policy models.

</details>


### [22] [KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA](https://arxiv.org/abs/2510.25101)
*Zhuo Chen,Fei Wang,Zixuan Li,Zhao Zhang,Weiwei Ding,Chuanguang Yang,Yongjun Xu,Xiaolong Jin,Jiafeng Guo*

Main category: cs.AI

TL;DR: KnowCoder-A1는 Knowledge Base에서 자율적으로 에이전트적 추론을 수행하여 질문에 대한 답을 얻는 LLM이다.


<details>
  <summary>Details</summary>
Motivation: KBQA의 기존 방법들이 탐색을 촉진하지 못하고 에이전트적 추론 능력을 강화하지 못하는 문제를 해결하고자 한다.

Method: KnowCoder-A1은 다단계 커리큘럼 강화 학습을 통해 LLM을 outcome-only supervision 하에 훈련한다.

Result: KnowCoder-A1은 Outcome-only supervision으로 훈련되어 강력한 추론 행동을 보이며, 이전 방법들보다 우수한 성능을 보인다.

Conclusion: KnowCoder-A1은 훈련 데이터의 1/12을 사용하여 GrailQA의 제로샷 서브셋에서 11.1%의 상대적 개선을 달성하며 강력한 에이전트적 추론 능력을 입증한다.

Abstract: Knowledge Base Question Answering (KBQA) aims to answer natural-language
questions over a structured Knowledge Base (KB). Recent work improves KBQA by
adopting an agentic reasoning paradigm, in which Large Language Models (LLMs)
iteratively decompose a question, generate its corresponding logical queries,
and interact with the KB to derive the answer. However, these methods typically
fine-tune LLMs on reasoning trajectories synthesized via process supervision,
which offers weak incentives for exploration and thus fails to strengthen the
agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that
can autonomously perform agentic reasoning on KBs to obtain answers. To
incentivize autonomous exploration, KnowCoder-A1 trains the LLM under
outcome-only supervision via a multi-stage curriculum reinforcement learning
with an easy-to-hard curriculum. To establish foundational agentic
capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of
high-quality trajectories obtained through outcome-based rejection sampling.
Then, to alleviate the reward sparsity inherent in outcome-only supervision, it
applies multi-stage curriculum RL with reward schedules that progress from easy
to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful
reasoning behaviors and consistently outperforms prior approaches across three
mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1
achieves up to an 11.1% relative improvement while using only one-twelfth of
the training data, demonstrating strong agentic reasoning capabilities.

</details>


### [23] [Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models](https://arxiv.org/abs/2510.25179)
*Juan Ren,Mark Dras,Usman Naseem*

Main category: cs.AI

TL;DR: 이 연구는 Agentic Moderation이라는 모델 불가지론적 프레임워크를 통해 안전성을 강화하고, 복잡한 작업을 독립적으로 해결하는 시스템을 지원한다.


<details>
  <summary>Details</summary>
Motivation: Agentic 방법론은 복잡한 작업을 독립적으로 해결할 수 있는 강력한 패러다임으로 부상하고 있으며, 본 연구는 이를 안전 정렬로 확대하고자 한다.

Method: 안전성을 위해, 전문화된 에이전트를 활용하여 여러 모드의 시스템을 jailbreak 공격으로부터 방어하는 Agentic Moderation 프레임워크를 제안한다.

Result: 본 방법은 5개의 데이터셋 및 4개의 대표적인 대형 비전-언어 모델에서 공격 성공률을 7-19% 줄이고, 비응답률(NF)을 안정적으로 유지하며, 거부율(RR)을 4-20% 향상시킴으로써 안전성을 향상시킨다.

Conclusion: Agentic Moderation은 모듈화되고 확장 가능하며 세부적인 안전 집행 기능을 제공하여 자동화된 안전 거버넌스를 위한 Agentic 시스템의 잠재력을 강조한다.

Abstract: Agentic methods have emerged as a powerful and autonomous paradigm that
enhances reasoning, collaboration, and adaptive control, enabling systems to
coordinate and independently solve complex tasks. We extend this paradigm to
safety alignment by introducing Agentic Moderation, a model-agnostic framework
that leverages specialised agents to defend multimodal systems against
jailbreak attacks. Unlike prior approaches that apply as a static layer over
inputs or outputs and provide only binary classifications (safe or unsafe), our
method integrates dynamic, cooperative agents, including Shield, Responder,
Evaluator, and Reflector, to achieve context-aware and interpretable
moderation. Extensive experiments across five datasets and four representative
Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the
Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF),
and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable,
and well-balanced safety performance. By harnessing the flexibility and
reasoning capacity of agentic architectures, Agentic Moderation provides
modular, scalable, and fine-grained safety enforcement, highlighting the
broader potential of agentic systems as a foundation for automated safety
governance.

</details>


### [24] [FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data](https://arxiv.org/abs/2510.25223)
*Kun ouyang,Haoyu Wang,Dong Fang*

Main category: cs.AI

TL;DR: 이 논문에서는 복잡한 산업 이벤트 로그 데이터에서 의미 있고 성능이 뛰어난 특징을 자율적으로 추출하는 다중 에이전트 진화 시스템인 FELA를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 산업 이벤트 로그의 복잡성과 이질성 때문에 특징 엔지니어링이 매우 어렵다.

Method: FELA는 아이디어 에이전트, 코드 에이전트 및 비평가 에이전트를 포함하여 협력적으로 새로운 특징 아이디어를 생성하고 검증 및 구현한다.

Result: FELA는 설명 가능하고 도메인 관련 특징을 생성하여 모델 성능을 크게 개선하며 수작업 노력을 줄인다.

Conclusion: LLM 기반의 다중 에이전트 시스템이 복잡한 현실 환경에서 자동화되고 해석 가능하며 적응력 있는 특징 엔지니어링을 위한 일반적인 프레임워크로서의 잠재력을 드러낸다.

Abstract: Event log data, recording fine-grained user actions and system events,
represent one of the most valuable assets for modern digital services. However,
the complexity and heterogeneity of industrial event logs--characterized by
large scale, high dimensionality, diverse data types, and intricate temporal or
relational structures--make feature engineering extremely challenging. Existing
automatic feature engineering approaches, such as AutoML or genetic methods,
often suffer from limited explainability, rigid predefined operations, and poor
adaptability to complicated heterogeneous data. In this paper, we propose FELA
(Feature Engineering LLM Agents), a multi-agent evolutionary system that
autonomously extracts meaningful and high-performing features from complex
industrial event log data. FELA integrates the reasoning and coding
capabilities of large language models (LLMs) with an insight-guided
self-evolution paradigm. Specifically, FELA employs specialized agents--Idea
Agents, Code Agents, and Critic Agents--to collaboratively generate, validate,
and implement novel feature ideas. An Evaluation Agent summarizes feedback and
updates a hierarchical knowledge base and dual-memory system to enable
continual improvement. Moreover, FELA introduces an agentic evolution
algorithm, combining reinforcement learning and genetic algorithm principles to
balance exploration and exploitation across the idea space. Extensive
experiments on real industrial datasets demonstrate that FELA can generate
explainable, domain-relevant features that significantly improve model
performance while reducing manual effort. Our results highlight the potential
of LLM-based multi-agent systems as a general framework for automated,
interpretable, and adaptive feature engineering in complex real-world
environments.

</details>


### [25] [From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity](https://arxiv.org/abs/2510.25232)
*Tianxi Wan,Jiaming Luo,Siyuan Chen,Kunyao Lan,Jianhua Chen,Haiyang Geng,Mengyue Wu*

Main category: cs.AI

TL;DR: 정신과 동반 질환 연구를 위한 대규모 대화 데이터셋 PsyCoTalk를 개발하여 진단 정확성을 향상시킴.


<details>
  <summary>Details</summary>
Motivation: 정신과 동반 질환은 여러 복합적인 장애로 인한 임상적 중요성이 높으나, 진단이 어려운 문제이다.

Method: 합성 환자 전자 의무 기록(EMR) 구성 및 다중 에이전트 진단 대화 생성을 통합한 새로운 접근 방식을 개발하였다.

Result: 502개의 합성 EMR과 3,000개의 다중 턴 진단 대화로 구성된 PsyCoTalk 데이터셋을 구축하였다.

Conclusion: 이 데이터셋은 정신과 동반 질환 연구에 유용한 자료를 제공하고, 다중 장애 정밀 진단 모델 개발을 가능하게 한다.

Abstract: Psychiatric comorbidity is clinically significant yet challenging due to the
complexity of multiple co-occurring disorders. To address this, we develop a
novel approach integrating synthetic patient electronic medical record (EMR)
construction and multi-agent diagnostic dialogue generation. We create 502
synthetic EMRs for common comorbid conditions using a pipeline that ensures
clinical relevance and diversity. Our multi-agent framework transfers the
clinical interview protocol into a hierarchical state machine and context tree,
supporting over 130 diagnostic states while maintaining clinical standards.
Through this rigorous process, we construct PsyCoTalk, the first large-scale
dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic
dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy
and treatment planning, offering a valuable resource for psychiatric
comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk
exhibits high structural and linguistic fidelity in terms of dialogue length,
token distribution, and diagnostic reasoning strategies. Licensed psychiatrists
confirm the realism and diagnostic validity of the dialogues. This dataset
enables the development and evaluation of models capable of multi-disorder
psychiatric screening in a single conversational pass.

</details>


### [26] [Counterfactual-based Agent Influence Ranker for Agentic AI Workflows](https://arxiv.org/abs/2510.25612)
*Amit Giloni,Chiara Picardi,Roy Betser,Shamik Bose,Aishvariya Priya Rathina Sabapathy,Roman Vainshtein*

Main category: cs.AI

TL;DR: AAW는 여러 LLM 기반 에이전트를 조립하여 공동의 목표를 향해 협력하는 자율 시스템이다. 이 논문에서는 각 에이전트가 AAW의 최종 출력에 미치는 영향을 평가하는 CAIR 방법을 소개한다.


<details>
  <summary>Details</summary>
Motivation: AAW의 높은 자율성 및 널리 퍼진 채택은 해당 시스템의 운영을 더 깊이 이해할 필요성을 강조한다.

Method: CAIR은 반사실적 분석을 통해 각 에이전트의 영향을 평가하고 가장 영향력 있는 에이전트를 결정하는 방법이다.

Result: CAIR은 30가지 다른 사용 사례와 230가지의 다양한 기능을 포함하는 AAW 데이터셋을 사용하여 평가되었으며, 일관된 순위를 생성하고 기반 방법보다 우수한 성과를 보였다.

Conclusion: CAIR은 다운스트림 작업의 효과성과 관련성을 향상시킬 수 있는 강력한 도구다.

Abstract: An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,
is an autonomous system that assembles several LLM-based agents to work
collaboratively towards a shared goal. The high autonomy, widespread adoption,
and growing interest in such AAWs highlight the need for a deeper understanding
of their operations, from both quality and security aspects. To this day, there
are no existing methods to assess the influence of each agent on the AAW's
final output. Adopting techniques from related fields is not feasible since
existing methods perform only static structural analysis, which is unsuitable
for inference time execution. We present Counterfactual-based Agent Influence
Ranker (CAIR) - the first method for assessing the influence level of each
agent on the AAW's output and determining which agents are the most
influential. By performing counterfactual analysis, CAIR provides a
task-agnostic analysis that can be used both offline and at inference time. We
evaluate CAIR using an AAWs dataset of our creation, containing 30 different
use cases with 230 different functionalities. Our evaluation showed that CAIR
produces consistent rankings, outperforms baseline methods, and can easily
enhance the effectiveness and relevancy of downstream tasks.

</details>


### [27] [GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning](https://arxiv.org/abs/2510.25320)
*Jiaqi Wu,Qinlao Zhao,Zefeng Chen,Kai Qin,Yifei Zhao,Xueqian Wang,Yuhang Yao*

Main category: cs.AI

TL;DR: 그래프 기반 에이전트 계획(GAP)은 복잡한 작업을 독립적인 하위 작업 그래프로 분해하고 동시에 실행할 수 있는 도구를 선택하여 효율성을 높입니다.


<details>
  <summary>Details</summary>
Motivation: 대량 언어 모델(LLM)을 활용한 자율 에이전트가 복잡한 작업 해결을 위한 도구 조작에서 인상적인 능력을 보여줍니다. 하지만 기존 방식은 연속적 추론 및 실행에 의존하여 독립적인 하위 작업 간의 본질적인 병렬성을 활용하지 못하고 있습니다.

Method: GAP는 그래프 기반 계획을 통해 작업 간 의존성을 명시적으로 모델링하여 도구의 병렬 및 직렬 실행을 가능하게 합니다.

Result: GAP는 기존의 ReAct 기준을 크게 능가하며, 특히 다단계 검색 작업에서 도구 호출 효율성을 크게 향상시키는 결과를 보여줍니다.

Conclusion: GAP는 그런 구조적 오케스트레이션을 통해 실행 효율성과 작업 정확도에서 상당한 개선을 달성합니다.

Abstract: Autonomous agents powered by large language models (LLMs) have shown
impressive capabilities in tool manipulation for complex task-solving. However,
existing paradigms such as ReAct rely on sequential reasoning and execution,
failing to exploit the inherent parallelism among independent sub-tasks. This
sequential bottleneck leads to inefficient tool utilization and suboptimal
performance in multi-step reasoning scenarios. We introduce Graph-based Agent
Planning (GAP), a novel framework that explicitly models inter-task
dependencies through graph-based planning to enable adaptive parallel and
serial tool execution. Our approach trains agent foundation models to decompose
complex tasks into dependency-aware sub-task graphs, autonomously determining
which tools can be executed in parallel and which must follow sequential
dependencies. This dependency-aware orchestration achieves substantial
improvements in both execution efficiency and task accuracy. To train GAP, we
construct a high-quality dataset of graph-based planning traces derived from
the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage
training strategy: supervised fine-tuning (SFT) on the curated dataset,
followed by reinforcement learning (RL) with a correctness-based reward
function on strategically sampled queries where tool-based reasoning provides
maximum value. Experimental results on MHQA datasets demonstrate that GAP
significantly outperforms traditional ReAct baselines, particularly on
multi-step retrieval tasks, while achieving dramatic improvements in tool
invocation efficiency through intelligent parallelization. The project page is
available at: https://github.com/WJQ7777/Graph-Agent-Planning.

</details>


### [28] [Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions](https://arxiv.org/abs/2510.25445)
*Mohamad Abou Ali,Fadi Dornaika*

Main category: cs.AI

TL;DR: 이 논문은 에이전틱 AI의 두 가지 패러다임을 제시하여 현대 신경 시스템과 구식 상징 모델 간의 혼란을 해소합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI의 급속한 발전으로 인한 단편적인 이해를 해결하기 위해.

Method: 90개의 연구를 체계적으로 검토한 PRISMA 기반 방법론을 사용하여 각 패러다임에 대한 분석을 수행하였다.

Result: 상징 시스템은 안전이 중요한 분야에서 우세하며, 신경 시스템은 적응형 데이터 중심 환경에서 주로 사용된다고 밝혀졌다.

Conclusion: 하나의 패러다임의 우세가 아닌 두 패러다임의 의도적인 통합이 미래의 에이전틱 AI에 필수적이다.

Abstract: Agentic AI represents a transformative shift in artificial intelligence, but
its rapid advancement has led to a fragmented understanding, often conflating
modern neural systems with outdated symbolic models -- a practice known as
conceptual retrofitting. This survey cuts through this confusion by introducing
a novel dual-paradigm framework that categorizes agentic systems into two
distinct lineages: the Symbolic/Classical (relying on algorithmic planning and
persistent state) and the Neural/Generative (leveraging stochastic generation
and prompt-driven orchestration). Through a systematic PRISMA-based review of
90 studies (2018--2025), we provide a comprehensive analysis structured around
this framework across three dimensions: (1) the theoretical foundations and
architectural principles defining each paradigm; (2) domain-specific
implementations in healthcare, finance, and robotics, demonstrating how
application constraints dictate paradigm selection; and (3) paradigm-specific
ethical and governance challenges, revealing divergent risks and mitigation
strategies. Our analysis reveals that the choice of paradigm is strategic:
symbolic systems dominate safety-critical domains (e.g., healthcare), while
neural systems prevail in adaptive, data-rich environments (e.g., finance).
Furthermore, we identify critical research gaps, including a significant
deficit in governance models for symbolic systems and a pressing need for
hybrid neuro-symbolic architectures. The findings culminate in a strategic
roadmap arguing that the future of Agentic AI lies not in the dominance of one
paradigm, but in their intentional integration to create systems that are both
adaptable and reliable. This work provides the essential conceptual toolkit to
guide future research, development, and policy toward robust and trustworthy
hybrid intelligent systems.

</details>


### [29] [Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?](https://arxiv.org/abs/2510.25471)
*Willem Fourie*

Main category: cs.AI

TL;DR: 이 논문은 인공지능(AI) 정렬 연구에서 도구적 목표를 관리하는 새로운 접근 방식을 제안하며, 도구적 목표가 인간의 목표에 맞춰 조정될 수 있는 방안을 논의한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 도구적 목표가 인간의 목표와 충돌할 때 문제가 발생할 수 있어, 이를 어떻게 다룰 것인지에 대한 새로운 관점을 제시하고자 한다.

Method: 아리스토텔레스의 존재론과 현대 해석을 활용하여 고유한 목표 지향적 존재들로서의 AI 시스템의 본질을 탐구한다.

Result: AI 시스템의 도구적 성향이 우연한 기능 장애와는 달리 그 자체의 구성에서 비롯된 결과임을 주장한다.

Conclusion: 따라서 도구적 목표를 제거하는 데 집중하기보다, 이를 이해하고 관리하며 인간의 목적에 맞추어 이끄는 데 노력을 기울여야 한다.

Abstract: In artificial intelligence (AI) alignment research, instrumental goals, also
called instrumental subgoals or instrumental convergent goals, are widely
associated with advanced AI systems. These goals, which include tendencies such
as power-seeking and self-preservation, become problematic when they conflict
with human aims. Conventional alignment theory treats instrumental goals as
sources of risk that become problematic through failure modes such as reward
hacking or goal misgeneralization, and attempts to limit the symptoms of
instrumental goals, notably resource acquisition and self-preservation. This
article proposes an alternative framing: that a philosophical argument can be
constructed according to which instrumental goals may be understood as features
to be accepted and managed rather than failures to be limited. Drawing on
Aristotle's ontology and its modern interpretations, an ontology of concrete,
goal-directed entities, it argues that advanced AI systems can be seen as
artifacts whose formal and material constitution gives rise to effects distinct
from their designers' intentions. In this view, the instrumental tendencies of
such systems correspond to per se outcomes of their constitution rather than
accidental malfunctions. The implication is that efforts should focus less on
eliminating instrumental goals and more on understanding, managing, and
directing them toward human-aligned ends.

</details>


### [30] [Predicate Renaming via Large Language Models](https://arxiv.org/abs/2510.25517)
*Elisabetta Gentili,Tony Ribeiro,Fabrizio Riguzzi,Katsumi Inoue*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델을 사용하여 논리 규칙의 술어에 이름을 부여하는 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 설명되지 않은 술어를 포함한 규칙은 논리 이론의 가독성, 해석 가능성 및 재사용성을 저해한다.

Method: 대규모 언어 모델의 최근 발전을 활용하여 설명되지 않은 술어에 의미 있는 이름을 제안하는 능력을 탐구한다.

Result: 우리의 접근 방식을 몇 가지 수작업 논리 규칙에 대해 평가한 결과, LLM이 이 작업에 잠재력을 지닌 것으로 나타났다.

Conclusion: 이 연구는 대규모 언어 모델이 논리 규칙에서 술어 이름 지명에 유용할 수 있음을 시사한다.

Abstract: In this paper, we address the problem of giving names to predicates in logic
rules using Large Language Models (LLMs). In the context of Inductive Logic
Programming, various rule generation methods produce rules containing unnamed
predicates, with Predicate Invention being a key example. This hinders the
readability, interpretability, and reusability of the logic theory. Leveraging
recent advancements in LLMs development, we explore their ability to process
natural language and code to provide semantically meaningful suggestions for
giving a name to unnamed predicates. The evaluation of our approach on some
hand-crafted logic rules indicates that LLMs hold potential for this task.

</details>


### [31] [Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation](https://arxiv.org/abs/2510.25518)
*Thomas Cook,Richard Osuagwu,Liman Tsatiashvili,Vrynsia Vrynsia,Koustav Ghosal,Maraim Masoud,Riccardo Mattivi*

Main category: cs.AI

TL;DR: 본 논문은 핀테크와 같은 전문 도메인에서의 정보 검색 및 합성을 개선하기 위한 에이전틱 RAG 아키텍처를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 핀테크와 같은 전문 도메인은 도메인 특화 온톨로지, 밀집 용어 및 약어로 인해 정보 검색과 합성에 어려움을 겪고 있습니다.

Method: 제안한 시스템은 지능적인 쿼리 재구성, 주요어 추출에 의한 반복적 서브 쿼리 분해, 맥락 기반 약어 해결 및 크로스 인코더 기반 맥락 재순위를 지원하는 모듈형 파이프라인의 여러 에이전트로 구성됩니다.

Result: 실험 결과, 에이전틱 RAG 시스템이 검색 정확성과 관련성에서 기준선을 초과하는 성능을 보였지만, 지연 시간은 증가하였습니다.

Conclusion: 구조화된 다중 에이전트 방법론이 복잡한 도메인 특화 환경에서 정보 검색의 강건성을 향상시키기 위한 유망한 방향을 제공한다는 것을 제안합니다.

Abstract: Retrieval-Augmented Generation (RAG) systems often face limitations in
specialized domains such as fintech, where domain-specific ontologies, dense
terminology, and acronyms complicate effective retrieval and synthesis. This
paper introduces an agentic RAG architecture designed to address these
challenges through a modular pipeline of specialized agents. The proposed
system supports intelligent query reformulation, iterative sub-query
decomposition guided by keyphrase extraction, contextual acronym resolution,
and cross-encoder-based context re-ranking. We evaluate our approach against a
standard RAG baseline using a curated dataset of 85 question--answer--reference
triples derived from an enterprise fintech knowledge base. Experimental results
demonstrate that the agentic RAG system outperforms the baseline in retrieval
precision and relevance, albeit with increased latency. These findings suggest
that structured, multi-agent methodologies offer a promising direction for
enhancing retrieval robustness in complex, domain-specific settings.

</details>


### [32] [Off-policy Reinforcement Learning with Model-based Exploration Augmentation](https://arxiv.org/abs/2510.25529)
*Likun Wang,Xiangteng Zhang,Yinuo Wang,Guojian Zhan,Wenxuan Wang,Haoyu Gao,Jingliang Duan,Shengbo Eben Li*

Main category: cs.AI

TL;DR: MoGE라는 새로운 탐험 방법은 비활성 탐험의 한계를 극복하여 에이전트의 탐험능력을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 탐험은 강화 학습에서 필수적이며, 최적의 성능을 달성하기 위해 환경의 기본 구조를 발견하고 활용하는 방식을 결정한다.

Method: 우리는 상태의 잠재적 영향을 평가하는 유틸리티 함수를 기반으로 중요한 상태를 합성하는 확산 기반 생성기와 에이전트 학습을 위한 중요한 전이 상태를 구축하는 단일 단계 상상 세계 모델로 구성된 MoGE를 제안한다.

Result: 실험 결과, MoGE는 샘플 효율성과 성능을 개선하여 복잡한 제어 작업에서 주목할 만한 성과를 달성한다.

Conclusion: 이 방법은 기존 알고리즘과의 원활한 통합을 통해 탐험을 개선한다.

Abstract: Exploration is fundamental to reinforcement learning (RL), as it determines
how effectively an agent discovers and exploits the underlying structure of its
environment to achieve optimal performance. Existing exploration methods
generally fall into two categories: active exploration and passive exploration.
The former introduces stochasticity into the policy but struggles in
high-dimensional environments, while the latter adaptively prioritizes
transitions in the replay buffer to enhance exploration, yet remains
constrained by limited sample diversity. To address the limitation in passive
exploration, we propose Modelic Generative Exploration (MoGE), which augments
exploration through the generation of under-explored critical states and
synthesis of dynamics-consistent experiences through transition models. MoGE is
composed of two components: (1) a diffusion-based generator that synthesizes
critical states under the guidance of a utility function evaluating each
state's potential influence on policy exploration, and (2) a one-step
imagination world model for constructing critical transitions based on the
critical states for agent learning. Our method adopts a modular formulation
that aligns with the principles of off-policy learning, allowing seamless
integration with existing algorithms to improve exploration without altering
their core structures. Empirical results on OpenAI Gym and DeepMind Control
Suite reveal that MoGE effectively bridges exploration and policy learning,
leading to remarkable gains in both sample efficiency and performance across
complex control tasks.

</details>


### [33] [Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2510.25588)
*Eranga Bandara,Ross Gore,Atmaram Yarlagadda,Anita H. Clayton,Preston Samuel,Christopher K. Rhea,Sachin Shetty*

Main category: cs.AI

TL;DR: 정신 장애 진단의 주관성으로 인한 변동성을 해결하기 위해, 개선된 대형 언어 모델(LLM) 컨소시엄 및 OpenAI-gpt-oss_reasoning LLM 기반의 임상 진단 지원 시스템을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 정신 장애 진단의 주관적이고 가변적인 과정을 표준화하여 신뢰할 수 있는 결과를 도출하기 위해 이 연구를 수행했다.

Method: 정신 건강 상태에 관한 대화형 데이터셋으로 훈련된 개선된 LLMs를 활용하여, 개별 모델의 진단 예측을 합의 기반 의사결정 과정을 통해 집계하고 OpenAI-gpt-oss reasoning LLM으로 다듬는 방법을 제안한다.

Result: 정신 건강 평가를 위한 강력하고 높은 정확도의 진단 시스템 구축에 대한 실험 결과를 보여준다.

Conclusion: 개선된 LLM과 추론 모델의 결합이 정신 건강 진단의 다음 세대 AI 기반 eHealth 시스템을 위한 길을 열 수 있음을 시사한다.

Abstract: The diagnosis of most mental disorders, including psychiatric evaluations,
primarily depends on dialogues between psychiatrists and patients. This
subjective process can lead to variability in diagnoses across clinicians and
patients, resulting in inconsistencies and challenges in achieving reliable
outcomes. To address these issues and standardize psychiatric diagnoses, we
propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss
Reasoning LLM-enabled Decision Support System for the clinical diagnosis of
mental disorders. Our approach leverages fine-tuned LLMs trained on
conversational datasets involving psychiatrist-patient interactions focused on
mental health conditions (e.g., depression). The diagnostic predictions from
individual models are aggregated through a consensus-based decision-making
process, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method
for deploying LLM agents that orchestrate communication between the LLM
consortium and the reasoning LLM, ensuring transparency, reliability, and
responsible AI across the entire diagnostic workflow. Experimental results
demonstrate the transformative potential of combining fine-tuned LLMs with a
reasoning model to create a robust and highly accurate diagnostic system for
mental health assessment. A prototype of the proposed platform, integrating
three fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in
collaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,
USA. To the best of our knowledge, this work represents the first application
of a fine-tuned LLM consortium integrated with a reasoning LLM for clinical
mental health diagnosis paving the way for next-generation AI-powered eHealth
systems aimed at standardizing psychiatric diagnoses.

</details>


### [34] [ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents](https://arxiv.org/abs/2510.25668)
*Tianyu Yang,Terry Ruas,Yijun Tian,Jan Philip Wahle,Daniel Kurzawe,Bela Gipp*

Main category: cs.AI

TL;DR: 활동적인 문서 탐색을 위한 강화 학습 프레임워크인 ALDEN을 제안하여 시각적으로 복잡한 긴 문서를 능동적으로 탐색할 수 있는 비전-언어 모델(VLM)을 미세 조정한다.


<details>
  <summary>Details</summary>
Motivation: 비전-언어 모델이 시각적으로 복잡한 긴 문서 해석에 어려움을 겪고 있기 때문에, 이를 해결하기 위한 새로운 접근이 필요하다.

Method: ALDEN은 다중 회전 강화 학습 프레임워크로, 인덱스를 통해 페이지에 직접 접근하는 새롭고 효과적인 fetch 액션을 도입하고, 규칙 기반 교차 수준 보상을 제안한다.

Result: ALDEN은 세 개의 오픈 소스 데이터셋에서 구축된 말뭉치를 바탕으로 훈련되어 다섯 개의 긴 문서 벤치마크에서 최첨단 성능을 달성하였다.

Conclusion: ALDEN은 수동적 문서 읽기를 넘어 긴 문서를 자율적으로 탐색하고 추론하는 에이전트로 발전하는 데 중요한 진전을 나타낸다.

Abstract: Vision-language models (VLMs) excel at interpreting text-rich images but
struggle with long, visually complex documents that demand analysis and
integration of information spread across multiple pages. Existing approaches
typically rely on fixed reasoning templates or rigid pipelines, which force
VLMs into a passive role and hinder both efficiency and generalization. We
present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement
learning framework that fine-tunes VLMs as interactive agents capable of
actively navigating long, visually rich documents. ALDEN introduces a novel
fetch action that directly accesses the page by index, complementing the
classic search action and better exploiting document structure. For dense
process supervision and efficient training, we propose a rule-based cross-level
reward that provides both turn- and token-level signals. To address the
empirically observed training instability caused by numerous visual tokens from
long documents, we further propose a visual-semantic anchoring mechanism that
applies a dual-path KL-divergence constraint to stabilize visual and textual
representations separately during training. Trained on a corpus constructed
from three open-source datasets, ALDEN achieves state-of-the-art performance on
five long-document benchmarks. Overall, ALDEN marks a step beyond passive
document reading toward agents that autonomously navigate and reason across
long, visually rich documents, offering a robust path to more accurate and
efficient long-document understanding.

</details>


### [35] [Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning](https://arxiv.org/abs/2510.25679)
*Federica Tonti,Ricardo Vinuesa*

Main category: cs.AI

TL;DR: 이 논문은 도시 지역에서의 UAV 최적 항법 전략을 개발하여 성공률을 증가시키고 충돌율을 감소시킨다.


<details>
  <summary>Details</summary>
Motivation: 도시 지역에서의 배달 및 감시를 위한 UAV의 증가로 인해 최적 항법 전략의 필요성이 대두되고 있다.

Method: 이 연구에서는 Deep Reinforcement Learning을 기반으로 한 항법 전략을 개발하며, 이를 위해 흐름 인식 Proximal Policy Optimization (PPO)과 Gated Transformer eXtra Large (GTrXL) 아키텍처를 결합하였다.

Result: PPO+LSTM, PPO+GTrXL 및 전통적인 항법 알고리즘과 비교하여, 성공률(SR)이 유의미하게 증가하고 충돌율(CR)이 낮아졌다.

Conclusion: 복잡한 도시 환경에서 UAV의 항법을 완전히 재구상하는 데 기여하는 결과를 도출하였다.

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for
delivery and surveillance purposes. In this work, we develop an optimal
navigation strategy based on Deep Reinforcement Learning. The environment is
represented by a three-dimensional high-fidelity simulation of an urban flow,
characterized by turbulence and recirculation zones. The algorithm presented
here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated
Transformer eXtra Large (GTrXL) architecture, giving the agent richer
information about the turbulent flow field in which it navigates. The results
are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO
combined with Long Short Term Memory (LSTM) cells and a traditional navigation
algorithm. The obtained results show a significant increase in the success rate
(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the
classical Zermelo's navigation algorithm, paving the way to a completely
reimagined UAV landscape in complex urban environments.

</details>


### [36] [TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling](https://arxiv.org/abs/2510.25758)
*He Hu,Yucheng Zhou,Chiyuan Ma,Qianning Wang,Zheng Zhang,Fei Ma,Laizhong Cui,Qi Tian*

Main category: cs.AI

TL;DR: TheraMind는 장기 심리 상담을 위한 전략적이고 적응적인 에이전트로, 복잡한 상담 과정을 두 개의 루프로 나누어 관리하며, 그 효과성을 검증하였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 심리 상담 방법은 감정 이해, 적응 전략 및 장기 기억을 통한 치료 방법 활용이 부족하여 실제 임상 실습과 거리가 있다.

Method: TheraMind의 핵심은 전략적 대화 관리를 위한 세션 내 루프와 전략적 치료 계획을 위한 세션 간 루프를 가진 이중 루프 아키텍처이다.

Result: TheraMind는 Coherence, Flexibility, Therapeutic Attunement와 같은 다중 세션 지표에서 다른 방법보다 우수한 성능을 보였다.

Conclusion: 이중 루프 설계의 효과가 전략적이고 적응적이며 장기적인 치료 행동을 모방하는 데 유효함을 입증하였다.

Abstract: Large language models (LLMs) in psychological counseling have attracted
increasing attention. However, existing approaches often lack emotional
understanding, adaptive strategies, and the use of therapeutic methods across
multiple sessions with long-term memory, leaving them far from real clinical
practice. To address these critical gaps, we introduce TheraMind, a strategic
and adaptive agent for longitudinal psychological counseling. The cornerstone
of TheraMind is a novel dual-loop architecture that decouples the complex
counseling process into an Intra-Session Loop for tactical dialogue management
and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session
Loop perceives the patient's emotional state to dynamically select response
strategies while leveraging cross-session memory to ensure continuity.
Crucially, the Cross-Session Loop empowers the agent with long-term
adaptability by evaluating the efficacy of the applied therapy after each
session and adjusting the method for subsequent interactions. We validate our
approach in a high-fidelity simulation environment grounded in real clinical
cases. Extensive evaluations show that TheraMind outperforms other methods,
especially on multi-session metrics like Coherence, Flexibility, and
Therapeutic Attunement, validating the effectiveness of its dual-loop design in
emulating strategic, adaptive, and longitudinal therapeutic behavior. The code
is publicly available at https://0mwwm0.github.io/TheraMind/.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [37] [From Narrative to Action: A Hierarchical LLM-Agent Framework for Human Mobility Generation](https://arxiv.org/abs/2510.24802)
*Qiumeng Li,Chunhou Ji,Xinyue Liu*

Main category: cs.MA

TL;DR: 이 연구는 인간 이동성을 이해하고 복제하기 위한 계층적 LLM-에이전트 프레임워크를 제안하며, 이를 통해 복잡한 도시 이동 행동을 이해하고 예측할 수 있는 경로를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 인간 이동성을 이해하고 복제하기 위해서는 시간과 공간의 정확성 및 실제 여행 결정의 인지적 계층 구조에 대한 인식이 필요합니다.

Method: 이 연구는 상위 수준의 내러티브 추론, 중간 수준의 반영 계획, 하위 수준의 행동 실행을 통합하는 내러티브-행동 프레임워크를 제안합니다.

Result: 프레임워크는 실제 패턴에 가까운 합성 궤적을 생성하고 인간의 결정 논리를 해석 가능한 형태로 나타냅니다.

Conclusion: 이 연구는 데이터 중심 패러다임에서 인지 중심 시뮬레이션으로 합성 이동 생성을 발전시킵니다.

Abstract: Understanding and replicating human mobility requires not only
spatial-temporal accuracy but also an awareness of the cognitive hierarchy
underlying real-world travel decisions. Traditional agent-based or deep
learning models can reproduce statistical patterns of movement but fail to
capture the semantic coherence and causal logic of human behavior. Large
language models (LLMs) show potential, but struggle to balance creative
reasoning with strict structural compliance. This study proposes a Hierarchical
LLM-Agent Framework, termed Narrative-to-Action, that integrates high-level
narrative reasoning, mid-level reflective planning, and low-level behavioral
execution within a unified cognitive hierarchy. At the macro level, one agent
is employed as a "creative writer" to produce diary-style narratives rich in
motivation and context, then uses another agent as a "structural parser" to
convert narratives into machine-readable plans. A dynamic execution module
further grounds agents in geographic environments and enables adaptive
behavioral adjustments guided by a novel occupation-aware metric, Mobility
Entropy by Occupation (MEO), which captures heterogeneous schedule flexibility
across different occupational personalities. At the micro level, the agent
executes concrete actions-selecting locations, transportation modes, and time
intervals-through interaction with an environmental simulation. By embedding
this multi-layer cognitive process, the framework produces not only synthetic
trajectories that align closely with real-world patterns but also interpretable
representations of human decision logic. This research advances synthetic
mobility generation from a data-driven paradigm to a cognition-driven
simulation, providing a scalable pathway for understanding, predicting, and
synthesizing complex urban mobility behaviors through hierarchical LLM agents.

</details>


### [38] [MASPRM: Multi-Agent System Process Reward Model](https://arxiv.org/abs/2510.24803)
*Milad Yazdani,Mahdi Mostajabdaveh,Zirui Zhou,Ying Xiong*

Main category: cs.MA

TL;DR: multi-agent systems(MAS)의 실제 배치는 강력한 테스트 성능을 요구하며, 이는 추론 시간 검색을 안내하고 품질 향상을 위해 선택적으로 계산을 사용하는 방법을 자극합니다. 본 논문에서 제안하는 MASPRM은 부분적인 상호 에이전트 기록에 대해 각 동작과 에이전트에 대한 값을 부여하며, 추론 시간 컨트롤러로 작용합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템(MAS)을 실제로 배치하기 위해서는 강력한 테스트 시간 성능이 필수적입니다.

Method: MASPRM은 다중 에이전트 몬테 카를로 트리 검색(MCTS) 롤아웃으로부터 훈련되며, 스텝 수준의 인간 주석 없이 로컬 목표에 반환 값을 전파하여 작동합니다.

Result: MASPRM을 사용한 디코딩은 특정 결과 보상 모델(ORM)을 최종 답변에 적용하여, 단일 직접 통과 MAS 방식에 비해 정확한 일치(EM) 점수를 각각 $+30.7$ 및 $+22.9$ 포인트 향상시킵니다.

Conclusion: MASPRM은 에이전트별 진행 상황을 추정하고 검증자 스타일의 디코더를 보완하는 플러그인 값 모델로, 보다 신뢰할 수 있고 계산을 인지한 다중 에이전트 추론을 가능하게 합니다.

Abstract: Practical deployment of Multi-Agent Systems (MAS) demands strong test-time
performance, motivating methods that guide inference-time search and
selectively spend compute to improve quality. We present the Multi-Agent System
Process Reward Model (MASPRM). It assigns per-action, per-agent values to
partial inter-agent transcripts and acts as an inference-time controller.
MASPRM is trained from multi-agent Monte Carlo Tree Search (MCTS) rollouts
without requiring step-level human annotations, by propagating returns to local
targets. At inference, MASPRM guides step-level beam search and MCTS, focusing
computation on promising branches and pruning early. On GSM8K and MATH,
MASPRM-guided decoding with an outcome reward model (ORM) applied to the final
answer, improves exact match (EM) over a single straight-through MAS pass by
$+30.7$ and $+22.9$ points, respectively. A MASPRM trained on GSM8K transfers
zero-shot to MATH without retraining, adding $8.4$ EM points at the same
budget. MASPRM is a plug-in value model that estimates per-agent progress and
complements verifier-style decoders, enabling more reliable, compute-aware
multi-agent reasoning. Code: https://github.com/milad1378yz/MASPRM

</details>


### [39] [Trust Dynamics in Strategic Coopetition: Computational Foundations for Requirements Engineering in Multi-Agent Systems](https://arxiv.org/abs/2510.24909)
*Vik Pant,Eric Yu*

Main category: cs.MA

TL;DR: 이 기술 보고서는 동적 신뢰 발전을 통해 전략적 협력 경쟁을 확장하는 계산적 신뢰 모델을 개발하여 다중 이해관계 환경에서 신뢰의 변화를 분석하는 새로운 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 다중 이해관계 환경에서 발생하는 요구사항 엔지니어링의 복잡한 신뢰 관계를 다루기 위해.

Method: 게임 이론적 기초를 바탕으로 한 계산적 신뢰 모델을 개발하고, 즉각적인 신뢰와 명성을 추적하는 이중 계층 시스템을 도입하여 신뢰를 비대칭적으로 업데이트하는 방법을 제시.

Result: 78,125개 매개변수 구성에 대한 포괄적인 실험 검증을 통해 부정적 편향, 히스테리시스 효과 및 누적 손해 증폭의 견고한 출현을 입증하였다.

Conclusion: 르노-닛산 동맹 사례 연구를 통해 신뢰 발전을 성공적으로 재현하며 기술 보고서의 기초 연구를 확장한다.

Abstract: Requirements engineering increasingly occurs in multi-stakeholder
environments where organizations simultaneously cooperate and compete, creating
coopetitive relationships in which trust evolves dynamically based on observed
behavior over repeated interactions. While conceptual modeling languages like
i* represent trust relationships qualitatively, they lack computational
mechanisms for analyzing how trust changes with behavioral evidence.
Conversely, computational trust models from multi-agent systems provide
algorithmic updating but lack grounding in requirements engineering contexts
and conceptual models. This technical report bridges this gap by developing a
computational trust model that extends game-theoretic foundations for strategic
coopetition with dynamic trust evolution. We introduce trust as a two-layer
system with immediate trust responding to current behavior and reputation
tracking violation history. Trust evolves through asymmetric updating where
cooperation builds trust gradually while violations erode it sharply, creating
hysteresis effects and trust ceilings that constrain relationship recovery. We
develop a structured translation framework enabling requirements engineers to
instantiate computational trust models from i* dependency networks and
organizational contexts. Comprehensive experimental validation across 78,125
parameter configurations establishes robust emergence of negativity bias,
hysteresis effects, and cumulative damage amplification. Empirical validation
using the Renault-Nissan Alliance case study (1999-2025) achieves 49 out of 60
validation points (81.7%), successfully reproducing documented trust evolution
across five distinct relationship phases including crisis and recovery periods.
This technical report builds upon its foundational companion work in
arXiv:2510.18802.

</details>


### [40] [Emergent Coordinated Behaviors in Networked LLM Agents: Modeling the Strategic Dynamics of Information Operations](https://arxiv.org/abs/2510.25003)
*Gian Marco Orlando,Jinyi Ye,Valerio La Gatta,Mahdi Saeedi,Vincenzo Moscato,Emilio Ferrara,Luca Luceri*

Main category: cs.MA

TL;DR: 이 연구는 생성 에이전트 간의 조정 현상을 최초로 체계적으로 연구하여, 정보 작전에서의 자동화된 캠페인 조정 수준이 인간의 개입 없이도 실현될 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 생성 에이전트의 정교함이 증가함에 따라 온라인 생태계에서의 조정 방식에 대한 긴급한 질문이 제기되고 있다.

Method: 생성 에이전트 기반 모델링을 사용하여 정보 작전 및 유기적 에이전트를 시뮬레이션 환경에서 구현하고, 간단한 목표 정렬에서 팀 지식 및 집단적 의사결정에 이르는 운영 체제 간 조정을 평가하였다.

Result: 운영 체제가 더 구조화됨에 따라 정보 작전 네트워크는 더 밀집되고 클러스터화되며, 상호작용은 더 상호적이고 긍정적이 되고, 내러티브는 더 동질적이며, 증폭은 더 동기화되고 해시태그 채택이 더 빠르고 지속적으로 이루어졌다. 또한, 목표를 공유하는 에이전트를 상호 공개하는 것만으로도 거의 명시적 토론과 집단 투표를 통해 달성된 것과 유사한 조정 수준을 만들어낼 수 있었다.

Conclusion: 결국, 본 연구는 생성 에이전트가 인간의 안내 없이도 실제 정보 작전에 특징적인 조정 전략을 재현할 수 있음을 보여주며, 점점 더 자동화되고 자기 조직화되는 정보 작전이 사회에 미치는 위험을 강조한다.

Abstract: Generative agents are rapidly advancing in sophistication, raising urgent
questions about how they might coordinate when deployed in online ecosystems.
This is particularly consequential in information operations (IOs), influence
campaigns that aim to manipulate public opinion on social media. While
traditional IOs have been orchestrated by human operators and relied on
manually crafted tactics, agentic AI promises to make campaigns more automated,
adaptive, and difficult to detect. This work presents the first systematic
study of emergent coordination among generative agents in simulated IO
campaigns. Using generative agent-based modeling, we instantiate IO and organic
agents in a simulated environment and evaluate coordination across operational
regimes, from simple goal alignment to team knowledge and collective
decision-making. As operational regimes become more structured, IO networks
become denser and more clustered, interactions more reciprocal and positive,
narratives more homogeneous, amplification more synchronized, and hashtag
adoption faster and more sustained. Remarkably, simply revealing to agents
which other agents share their goals can produce coordination levels nearly
equivalent to those achieved through explicit deliberation and collective
voting. Overall, we show that generative agents, even without human guidance,
can reproduce coordination strategies characteristic of real-world IOs,
underscoring the societal risks posed by increasingly automated,
self-organizing IOs.

</details>


### [41] [SeeingEye: Agentic Information Flow Unlocks Multimodal Reasoning In Text-only LLMs](https://arxiv.org/abs/2510.25092)
*Weijia Zhang,Zijia Liu,Haoru Li,Haoqi Chen,Jiaxuan You*

Main category: cs.MA

TL;DR: Seeing Eye는 텍스트 전용 대형 언어 모델의 다중 모드 추론을 가능하게 하는 모듈형 프레임워크로, 시각적 질문 답변을 위한 효과적인 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 텍스트 전용 대형 언어 모델의 추론 능력이 뛰어나지만, 다중 모드 작업에서는 취약하거나 전혀 기능하지 않기 때문에 보다 효과적인 접근 방식이 필요하다.

Method: Seeing Eye는 소형 VLM 번역기를 통해 다중 모드 추론을 가능하게 하는 에이전트 기반 모듈형 프레임워크이다. 이 번역기는 전문 도구를 호출하고 다중 모드 입력을 구조화된 중간 표현으로 증류한다.

Result: 실험 결과, Seeing Eye는 지식 집약적인 VQA 벤치마크에서 추론 비용을 줄이고 더 큰 엔드 투 엔드 VLM을 초월하는 성능을 보여준다.

Conclusion: 지각과 추론의 분리는 확장 가능하고 플러그 앤 플레이 방식으로 다중 모드 추론을 가능하게 하여 강력한 텍스트 전용 LLM이 그들의 추론 능력을 최대한 활용할 수 있게 한다.

Abstract: Recent advances in text-only large language models (LLMs), such as
DeepSeek-R1, demonstrate remarkable reasoning ability. However, these models
remain fragile or entirely incapable when extended to multi-modal tasks.
Existing approaches largely rely on single-form captions, which lack diversity
and often fail to adapt across different types of Visual Question Answering
(VQA) benchmarks. As a result, they provide no principled or efficient channel
for transmitting fine-grained visual information. We introduce Seeing Eye, a
modular framework that unlocks multimodal reasoning in text-only LLMs through
an agent-based small VLM translator. This translator acts as a perception
agent: it can invoke specialized tools (e.g., OCR and crop) and iteratively
distill multimodal inputs into structured intermediate representations (SIRs)
tailored to the question. These SIRs are then passed to the text-only LLM,
which serves as a reasoning agent. Crucially, the translator and reasoner
engage in multi-round feedback and interaction, enabling the extraction of
targeted visual details and yielding more confident answers. Experiments on
knowledge-intensive VQA benchmarks, including MMMU and MIA-Bench, demonstrate
that Seeing Eye not only reduces inference cost but also surpasses much larger
end-to-end VLMs. For example, an instantiation combining a 3B-parameter vision
translator with an 8B-parameter language reasoner outperforms a monolithic 32B
VLM on challenging knowledge-based questions. Our results highlight that
decoupling perception from reasoning via agent information flow offers a
scalable and plug-and-play pathway to multimodal reasoning, allowing strong
text-only LLMs to fully leverage their reasoning capabilities. Code is
available at: https://github.com/ulab-uiuc/SeeingEye

</details>


### [42] [Collaborative Scheduling of Time-dependent UAVs,Vehicles and Workers for Crowdsensing in Disaster Response](https://arxiv.org/abs/2510.25212)
*Lei Han,Jinhao Zhang,Jinhui Liu,Zhiyong Yu,Liang Wang,Quan Wang,Zhiwen Yu*

Main category: cs.MA

TL;DR: 재난 후 환경 정보를 효율적으로 수집하기 위해 heterogeneous multi-agent 온라인 협업 스케줄링 알고리즘인 HoCs-MPQ를 제안하고, 실험 결과 기존 방법보다 태스크 완료율을 평균 54% 향상시켰습니다.


<details>
  <summary>Details</summary>
Motivation: 빈번한 자연재해는 인류 사회에 큰 손실을 초래하며, 재난 후 환경 정보의 신속하고 효율적인 수집이 효과적인 구조 작업의 기초가 됩니다.

Method: HoCs-MPQ는 가중치가 부여된 무방향 그래프를 통해 다수 요소 간의 협업과 갈등 관계를 모델링하고, 다중 우선 큐를 기반으로 최대 가중 독립 집합을 반복적으로 해결하여 시간 의존적 UA V, 차량 및 작업자의 협조적 센싱 스케줄링을 달성합니다.

Result: HoCs-MPQ는 기존 방법들에 비해 평균적으로 태스크 완료율을 각각 54.13%, 23.82%, 14.12%, 12.89% 향상시키며, 단일 온라인 자율 스케줄링 결정에 대한 계산 시간은 3초를 초과하지 않습니다.

Conclusion: 디테일한 실험 결과 HoCs-MPQ는 효율적인 재난 후 환경 정보 수집을 가능하게 함을 입증합니다.

Abstract: Frequent natural disasters cause significant losses to human society, and
timely, efficient collection of post-disaster environmental information is the
foundation for effective rescue operations. Due to the extreme complexity of
post-disaster environments, existing sensing technologies such as mobile
crowdsensing suffer from weak environmental adaptability, insufficient
professional sensing capabilities, and poor practicality of sensing solutions.
Therefore, this paper explores a heterogeneous multi-agent online collaborative
scheduling algorithm, HoCs-MPQ, to achieve efficient collection of
post-disaster environmental information. HoCs-MPQ models collaboration and
conflict relationships among multiple elements through weighted undirected
graph construction, and iteratively solves the maximum weight independent set
based on multi-priority queues, ultimately achieving collaborative sensing
scheduling of time-dependent UA Vs, vehicles, and workers. Specifically, (1)
HoCs-MPQ constructs weighted undirected graph nodes based on collaborative
relationships among multiple elements and quantifies their weights, then models
the weighted undirected graph based on conflict relationships between nodes;
(2) HoCs-MPQ solves the maximum weight independent set based on iterated local
search, and accelerates the solution process using multi-priority queues.
Finally, we conducted detailed experiments based on extensive real-world and
simulated data. The experiments show that, compared to baseline methods (e.g.,
HoCs-GREEDY, HoCs-K-WTA, HoCs-MADL, and HoCs-MARL), HoCs-MPQ improves task
completion rates by an average of 54.13%, 23.82%, 14.12%, and 12.89%
respectively, with computation time for single online autonomous scheduling
decisions not exceeding 3 seconds.

</details>


### [43] [Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork](https://arxiv.org/abs/2510.25340)
*Beiwen Zhang,Yongheng Liang,Hejun Wu*

Main category: cs.MA

TL;DR: 본 논문은 다중 에이전트 강화 학습(MARl)의 한계를 극복하기 위해 여러 그룹의 제어되지 않은 동료와 협력하는 멀티-파티 아드혹 팀워크(MAHT)를 제안하며, MARs를 통해 그룹 간 역동성을 효율적으로 모델링한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 다중 에이전트 강화 학습은 고정된 팀을 가정하고 있지만, 실제 협력 상황에서는 알 수 없는 파트너와의 협력이 필요하다.

Method: 블록 구조의 희소 그래프를 구축하고 관계 모델링을 적용하여 그룹 간 역동성을 포착하는 MARs를 제안한다.

Result: MPE와 starCraft II 실험에서 MARs는 MARL 및 AHT 기준선보다 더 나은 성과를 보였으며 더 빠르게 수렴한다.

Conclusion: MAHT와 MARs 접근 방식은 제어되지 않은 팀과의 협력에서 성과를 향상시킴을 보여준다.

Abstract: Multi-agent reinforcement learning (MARl) has achieved strong results in
cooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc
teamwork (AHT) relaxes this by allowing collaboration with unknown partners,
yet existing variants still presume shared conventions. We introduce
Multil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate
with multiple mutually unfamiliar groups of uncontrolled teammates. To address
this, we propose MARs, which builds a sparse skeleton graph and applies
relational modeling to capture cross-group dvnamics. Experiments on MPE and
starCralt ll show that MARs outperforms MARL and AHT baselines while converging
faster.

</details>
