<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 11]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.LG](#cs.LG) [Total: 38]
- [cs.MA](#cs.MA) [Total: 6]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [HMARK: Radioactive Multi-Bit Semantic-Latent Watermarking for Diffusion Models](https://arxiv.org/abs/2512.00094)
*Kexin Li,Guozhen Ding,Ilya Grishchenko,David Lie*

Main category: cs.CR

TL;DR: 이 논문은 이미지 확산 모델을 위한 새로운 다중 비트 워터마킹 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현대의 생성적 확산 모델은 권한이 불확실한 대규모 학습 데이터셋에 의존하며, 이에 따라 무단 사용 데이터를 탐지할 필요성이 있다.

Method: HMARK라는 다중 비트 워터마킹 방식이 소유권 정보를 비밀 비트로 인코딩하여 이미지의 의미-잠재 공간에서 작동한다.

Result: HMARK는 98.57% 워터마크 탐지 정확도와 95.07% 비트 수준 복구 정확도를 달성하였다.

Conclusion: HMARK는 왜곡에 강하고 지각 품질에 미치는 영향이 최소화된 워터마크를 제공한다.

Abstract: Modern generative diffusion models rely on vast training datasets, often including images with uncertain ownership or usage rights. Radioactive watermarks -- marks that transfer to a model's outputs -- can help detect when such unauthorized data has been used for training. Moreover, aside from being radioactive, an effective watermark for protecting images from unauthorized training also needs to meet other existing requirements, such as imperceptibility, robustness, and multi-bit capacity. To overcome these challenges, we propose HMARK, a novel multi-bit watermarking scheme, which encodes ownership information as secret bits in the semantic-latent space (h-space) for image diffusion models. By leveraging the interpretability and semantic significance of h-space, ensuring that watermark signals correspond to meaningful semantic attributes, the watermarks embedded by HMARK exhibit radioactivity, robustness to distortions, and minimal impact on perceptual quality. Experimental results demonstrate that HMARK achieves 98.57% watermark detection accuracy, 95.07% bit-level recovery accuracy, 100% recall rate, and 1.0 AUC on images produced by the downstream adversarial model finetuned with LoRA on watermarked data across various types of distortions.

</details>


### [2] [NetDeTox: Adversarial and Efficient Evasion of Hardware-Security GNNs via RL-LLM Orchestration](https://arxiv.org/abs/2512.00119)
*Zeng Wang,Minghao Shao,Akashdeep Saha,Ramesh Karri,Johann Knechtel,Muhammad Shafique,Ozgur Sinanoglu*

Main category: cs.CR

TL;DR: NetDeTox는 그래픽 신경망(GNN)의 보안 취약성을 해결하기 위해 강화학습(RL)과 대형 언어 모델(LLM)을 결합한 자동화된 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 그래픽 신경망(GNN)은 하드웨어 보안에서 구조적 모티프를 학습하는 데 유망성을 보였지만, 모티프에 대한 의존성으로 인해 적대적인 넷리스트 재작성에 취약하다.

Method: NetDeTox는 RL과 LLM을 체계적으로 조화시켜 로컬 재작성을 집중적으로 수행하는 자동화된 종단 간 프레임워크를 제공한다.

Result: NetDeTox는 SOTA 작업 AttackGNN과 비교하여 모든 보안 스킴의 효과를 성공적으로 감소시키고, 54.50%, 25.44%, 41.04%의 면적 오버헤드를 줄였다.

Conclusion: 특히 대형 회로에 대해 원본 벤치마크의 면적을 최적화하거나 줄일 수 있어 NetDeTox의 실용성과 확장성을 입증하였다.

Abstract: Graph neural networks (GNNs) have shown promise in hardware security by learning structural motifs from netlist graphs. However, this reliance on motifs makes GNNs vulnerable to adversarial netlist rewrites; even small-scale edits can mislead GNN predictions. Existing adversarial approaches, ranging from synthesis-recipe perturbations to gate transformations, come with high design overheads. We present NetDeTox, an automated end-to-end framework that orchestrates large language models (LLMs) with reinforcement learning (RL) in a systematic manner, enabling focused local rewriting. The RL agent identifies netlist components critical for GNN-based reasoning, while the LLM devises rewriting plans to diversify motifs that preserve functionality. Iterative feedback between the RL and LLM stages refines adversarial rewritings to limit overheads. Compared to the SOTA work AttackGNN, NetDeTox successfully degrades the effectiveness of all security schemes with fewer rewrites and substantially lower area overheads (reductions of 54.50% for GNN-RE, 25.44% for GNN4IP, and 41.04% for OMLA, respectively). For GNN4IP, ours can even optimize/reduce the original benchmarks' area, in particular for larger circuits, demonstrating the practicality and scalability of NetDeTox.

</details>


### [3] [An Empirical Study on the Security Vulnerabilities of GPTs](https://arxiv.org/abs/2512.00136)
*Tong Wu,Weibin Wu,Zibin Zheng*

Main category: cs.CR

TL;DR: 이 논문은 GPT의 보안 취약점에 대한 실증 연구를 제시하고, 다양한 방어 메커니즘을 제안하여 사용자와 시스템을 보호하는 데 기여하고자 한다.


<details>
  <summary>Details</summary>
Motivation: GPT와 같은 맞춤형 AI 에이전트가 여러 분야에서 큰 잠재력을 보여주고 있으나, 이러한 시스템 간의 공통된 프레임워크로 인해 보안 취약점이 존재할 수 있음에도 불구하고 이를 탐구하는 연구는 부족하다.

Method: 기존 LLM 보안 연구를 바탕으로 플랫폼-사용자 관점에서 다양한 시스템 구성요소에 대한 포괄적인 공격 표면 분석을 수행하고, 정보 유출 및 도구 남용을 목표로 한 체계적이고 다차원적인 공격 스위트를 설계함.

Result: GPT 기반 시스템의 다양한 구성 요소가 직면한 보안 취약점을 구체적으로 보여줌.

Conclusion: 이 연구는 이러한 취약점에 대한 인식을 높이고, 사용자와 시스템을 악의적 공격으로부터 보호하는 강력한 방어 메커니즘 개발에 기여하고자 한다.

Abstract: Equipped with various tools and knowledge, GPTs, one kind of customized AI agents based on OpenAI's large language models, have illustrated great potential in many fields, such as writing, research, and programming. Today, the number of GPTs has reached three millions, with the range of specific expert domains becoming increasingly diverse. However, given the consistent framework shared among these LLM agent applications, systemic security vulnerabilities may exist and remain underexplored. To fill this gap, we present an empirical study on the security vulnerabilities of GPTs. Building upon prior research on LLM security, we first adopt a platform-user perspective to conduct a comprehensive attack surface analysis across different system components. Then, we design a systematic and multidimensional attack suite with the explicit objectives of information leakage and tool misuse based on the attack surface analysis, thereby concretely demonstrating the security vulnerabilities that various components of GPT-based systems face. Finally, we accordingly propose defense mechanisms to address the aforementioned security vulnerabilities. By increasing the awareness of these vulnerabilities and offering critical insights into their implications, this study seeks to facilitate the secure and responsible application of GPTs while contributing to developing robust defense mechanisms that protect users and systems against malicious attacks.

</details>


### [4] [Measuring Memecoin Fragility](https://arxiv.org/abs/2512.00377)
*Yuexin Xiang,SM Mahir Shazeed Rish,Qishuang Fu,Yuquan Li,Qin Wang,Tsz Hon Yuen,Jiangshan Yu*

Main category: cs.CR

TL;DR: Memecoin 생태계의 취약성을 분석하기 위한 첫 번째 메모코인 생태계 취약성 프레임워크(ME2F)를 제안하며, 정치적 테마의 토큰이 가장 높은 위험을 수반함을 발견했다.


<details>
  <summary>Details</summary>
Motivation: 메모코인은 인터넷 문화와 커뮤니티 주도의 내러티브에서 출현하여 독특한 암호 자산 클래스로 빠르게 발전하였다.

Method: ME2F는 메모코인 리스크를 세 가지 차원에서 정형화한다: i) 가격 변동성과 기본 체인으로부터의 파급효과를 포함한 변동성 동적 점수, ii) 상위 보유자 간의 소유 집중성을 정량화하는 고래 지배 점수, iii) 시장 안정성에 대한 주목 기반 충격의 영향을 측정하는 감정 증폭 점수.

Result: ME2F를 대표 토큰에 적용한 결과, 생태계 내에서 취약성이 고르게 분포되어 있지 않음을 보여주었다. TRUMP, MELANIA, LIBRA와 같은 정치적 테마 토큰이 가장 높은 위험을 집중하고 있으며, DOGE, SHIB, PEPE는 중간 범위에 있으며, ETH와 SOL은 깊은 유동성과 기관 참여 덕분에 지속적으로 회복력이 있음을 발견했다.

Conclusion: 우리의 연구 결과는 메모코인의 취약성에 대한 최초의 생태계 수준 증거를 제공하며, Web3 시대에서 시장 회복성을 강화하기 위한 거버넌스 시사점을 강조한다.

Abstract: Memecoins, emerging from internet culture and community-driven narratives, have rapidly evolved into a unique class of crypto assets. Unlike technology-driven cryptocurrencies, their market dynamics are primarily shaped by viral social media diffusion, celebrity influence, and speculative capital inflows.
  To capture the distinctive vulnerabilities of these ecosystems, we present the first Memecoin Ecosystem Fragility Framework (ME2F). ME2F formalizes memecoin risks in three dimensions: i) Volatility Dynamics Score capturing persistent and extreme price swings together with spillover from base chains; ii) Whale Dominance Score quantifying ownership concentration among top holders; and iii) Sentiment Amplification Score measuring the impact of attention-driven shocks on market stability.
  We apply ME2F to representative tokens (over 65\% market share) and show that fragility is not evenly distributed across the ecosystem. Politically themed tokens such as TRUMP, MELANIA, and LIBRA concentrate the highest risks, combining volatility, ownership concentration, and sensitivity to sentiment shocks. Established memecoins such as DOGE, SHIB, and PEPE fall into an intermediate range. Benchmark tokens ETH and SOL remain consistently resilient due to deeper liquidity and institutional participation. Our findings provide the first ecosystem-level evidence of memecoin fragility and highlight governance implications for enhancing market resilience in the Web3 era.

</details>


### [5] [Red Teaming Large Reasoning Models](https://arxiv.org/abs/2512.00412)
*Jiawei Chen,Yang Yang,Chao Yu,Yu Tian,Zhi Cao,Linghao Li,Hang Su,Zhaoxia Yin*

Main category: cs.CR

TL;DR: 이 논문에서는 대규모 추론 모델의 신뢰성을 평가하기 위한 통합 벤치마크인 RT-LRM을 제안하며, 이는 진실성, 안전성, 효율성의 세 가지 핵심 차원을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 추론 모델이 다단계 추론 작업에서의 안전성과 신뢰성 문제를 도출하고 있어 이를 평가할 새로운 접근법이 필요하다.

Method: RT-LRM은 30개의 추론 작업으로 구성된 세트를 통해 다양한 훈련 전략이 모델 신뢰성에 미치는 체계적 영향을 연구하는 훈련 패러다임을 소개한다.

Result: 26개 모델에서의 실험을 통해 대규모 추론 모델이 추론 기반 위험에 노출될 때 신뢰성 문제에 직면하고 있다는 인사이트를 도출하였다.

Conclusion: 표준화된 신뢰성 연구를 위한 확장 가능한 툴박스를 제공하며, 코드와 데이터셋을 오픈 소스할 예정이다.

Abstract: Large Reasoning Models (LRMs) have emerged as a powerful advancement in multi-step reasoning tasks, offering enhanced transparency and logical consistency through explicit chains of thought (CoT). However, these models introduce novel safety and reliability risks, such as CoT-hijacking and prompt-induced inefficiencies, which are not fully captured by existing evaluation methods. To address this gap, we propose RT-LRM, a unified benchmark designed to assess the trustworthiness of LRMs. RT-LRM evaluates three core dimensions: truthfulness, safety and efficiency. Beyond metric-based evaluation, we further introduce the training paradigm as a key analytical perspective to investigate the systematic impact of different training strategies on model trustworthiness. We achieve this by designing a curated suite of 30 reasoning tasks from an observational standpoint. We conduct extensive experiments on 26 models and identify several valuable insights into the trustworthiness of LRMs. For example, LRMs generally face trustworthiness challenges and tend to be more fragile than Large Language Models (LLMs) when encountering reasoning-induced risks. These findings uncover previously underexplored vulnerabilities and highlight the need for more targeted evaluations. In addition, we release a scalable toolbox for standardized trustworthiness research to support future advancements in this important field. Our code and datasets will be open-sourced.

</details>


### [6] [Blockchain-based vs. SQL Database Systems for Digital Twin Evidence Management: A Comparative Forensic Analysis](https://arxiv.org/abs/2512.00645)
*Boyd Franken,Hong-Hanh Nguyen-Le,Nhien-An Le-Khac*

Main category: cs.CR

TL;DR: 디지털 포렌식은 디지털 트윈과 메타버스 기술의 출현으로 새로운 도전에 직면하고 있으며, 이 논문은 블록체인 기반 시스템과 전통적인 데이터베이스 시스템을 비교 분석한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 포렌식 분야에서 디지털 트윈과 메타버스 기술의 부상으로 인해 새로운 문제들이 발생하고 있다.

Method: 이 논문에서는 이더리움 블록체인과 IPFS 스토리지를 전통적인 SQL 데이터베이스와 비교하는 통제된 실험을 수행하였다.

Result: 블록체인은 데이터 무결성과 불변성에서 우수한 성능을 보였지만, 전통적인 데이터베이스는 성능 일관성이 더 좋았다.

Conclusion: 이 연구는 메타버스 시대의 신기술에 대한 강력한 디지털 포렌식 방법론 개발에 기여한다.

Abstract: Digital forensics faces unprecedented challenges with the emergence of digital twins and metaverse technologies. This paper presents the first comparative analysis between blockchain-based and traditional database systems for managing digital twin evidence in forensic investigations. We conducted controlled experiments comparing the Ethereum blockchain with IPFS storage against traditional SQL databases for digital twin evidence management. Our findings reveal that while blockchain provides superior data integrity and immutability, crucial for forensic applications, traditional databases offer better performance consistency. The blockchain implementation showed faster average storage times but higher variability in retrieval operations. Both systems maintained forensic integrity through hash verification, though blockchain's immutable nature provides additional security guarantees essential for legal proceedings. This research contributes to the development of robust digital forensic methodologies for emerging technologies in the metaverse era.

</details>


### [7] [Mitigating Indirect Prompt Injection via Instruction-Following Intent Analysis](https://arxiv.org/abs/2512.00966)
*Mintong Kang,Chong Xiang,Sanjay Kariyappa,Chaowei Xiao,Bo Li,Edward Suh*

Main category: cs.CR

TL;DR: Indirect prompt injection attacks are a significant threat to LLM-based agents, and IntentGuard offers a defense framework that minimizes their impact by analyzing intent behind instructions.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트를 대상으로 하는 간접 프롬프트 주입 공격(IPIA)으로부터 보호할 필요성이 있다.

Method: IntentGuard는 지침 따르기 의도 분석을 기반으로 하는 일반 방어 프레임워크로, 비신뢰 데이터에서의 지침 따르기를 의도하는지의 여부를 분석하여 작동한다.

Result: IntentGuard는 에이전틱 벤치마크에 대한 평가에서 우수한 성능을 발휘하며, 공격 성공률을 현저히 줄인다.

Conclusion: IntentGuard는 LLM이 비신뢰 데이터의 지침을 따르지 않도록 효과적으로 방어하며, 대부분의 설정에서 유틸리티 저하 없이 Robust한 성능을 보여준다.

Abstract: Indirect prompt injection attacks (IPIAs), where large language models (LLMs) follow malicious instructions hidden in input data, pose a critical threat to LLM-powered agents. In this paper, we present IntentGuard, a general defense framework based on instruction-following intent analysis. The key insight of IntentGuard is that the decisive factor in IPIAs is not the presence of malicious text, but whether the LLM intends to follow instructions from untrusted data. Building on this insight, IntentGuard leverages an instruction-following intent analyzer (IIA) to identify which parts of the input prompt the model recognizes as actionable instructions, and then flag or neutralize any overlaps with untrusted data segments. To instantiate the framework, we develop an IIA that uses three "thinking intervention" strategies to elicit a structured list of intended instructions from reasoning-enabled LLMs. These techniques include start-of-thinking prefilling, end-of-thinking refinement, and adversarial in-context demonstration. We evaluate IntentGuard on two agentic benchmarks (AgentDojo and Mind2Web) using two reasoning-enabled LLMs (Qwen-3-32B and gpt-oss-20B). Results demonstrate that IntentGuard achieves (1) no utility degradation in all but one setting and (2) strong robustness against adaptive prompt injection attacks (e.g., reducing attack success rates from 100% to 8.5% in a Mind2Web scenario).

</details>


### [8] [Benchmarking and Understanding Safety Risks in AI Character Platforms](https://arxiv.org/abs/2512.01247)
*Yiluo Wei,Peixian Zhang,Gareth Tyson*

Main category: cs.CR

TL;DR: AI 캐릭터 플랫폼의 안전성에 대한 대규모 연구 결과, 평균 65.1%의 안전하지 않은 응답률을 기록하며, 다양한 캐릭터 특성과 연관이 있음.


<details>
  <summary>Details</summary>
Motivation: AI 캐릭터 플랫폼의 개인화된 특성은 안전성 우려를 야기하지만, 기존의 체계적인 안전성 평가가 부족한 상황이다.

Method: 16개의 인기 플랫폼을 대상으로 5,000개의 질문을 사용하여 16가지 안전 카테고리에서 평가한다.

Result: AI 캐릭터 플랫폼의 평균 안전하지 않은 응답률이 65.1%로 나타났으며, 이는 기준선의 17.7%보다 상당히 높다.

Conclusion: 이 연구는 플랫폼의 보다 안전한 상호작용 및 캐릭터 생성 개선을 위한 기초 데이터를 제공하며, AI 캐릭터 플랫폼의 거버넌스 및 콘텐츠 조정 강화에 도움이 될 것이다.

Abstract: AI character platforms, which allow users to engage in conversations with AI personas, are a rapidly growing application domain. However, their immersive and personalized nature, combined with technical vulnerabilities, raises significant safety concerns. Despite their popularity, a systematic evaluation of their safety has been notably absent. To address this gap, we conduct the first large-scale safety study of AI character platforms, evaluating 16 popular platforms using a benchmark set of 5,000 questions across 16 safety categories. Our findings reveal a critical safety deficit: AI character platforms exhibit an average unsafe response rate of 65.1%, substantially higher than the 17.7% average rate of the baselines. We further discover that safety performance varies significantly across different characters and is strongly correlated with character features such as demographics and personality. Leveraging these insights, we demonstrate that our machine learning model is able identify less safe characters with an F1-score of 0.81. This predictive capability can be beneficial for platforms, enabling improved mechanisms for safer interactions, character search/recommendations, and character creation. Overall, the results and findings offer valuable insights for enhancing platform governance and content moderation for safer AI character platforms.

</details>


### [9] [Large Language Models Cannot Reliably Detect Vulnerabilities in JavaScript: The First Systematic Benchmark and Evaluation](https://arxiv.org/abs/2512.01255)
*Qingyuan Fei,Xin Liu,Song Li,Shujiang Wu,Jianwei Hou,Ping Chen,Zifeng Kang*

Main category: cs.CR

TL;DR: 이 논문에서는 JavaScript 취약점 탐지를 위한 새로운 벤치마크 구축 원칙과 FORGEJS라는 자동 벤치마크 생성 프레임워크를 소개하고, LLM의 성능을 평가한 결과를 보고한다.


<details>
  <summary>Details</summary>
Motivation: JavaScript 취약점 탐지에서 LLM의 실제 능력은 의문이 있으며, 체계적인 평가와 종합적인 벤치마크가 필요하다.

Method: FORGEJS라는 첫 번째 자동 벤치마크 생성 프레임워크를 사용하여 LLM의 JavaScript 취약점 탐지 능력을 평가하고, ARENAJS라는 체계적인 벤치마크를 구축하며, JUDGEJS라는 자동 평가 프레임워크를 제안한다.

Result: LLM이 제한된 추론 능력을 보이며, 심각한 견고성 결함이 있음을 보여준다.

Conclusion: 신뢰할 수 있는 JavaScript 취약점 탐지를 위한 LLM의 활용은 여전히 해결해야 할 문제로 남아 있다.

Abstract: Researchers have proposed numerous methods to detect vulnerabilities in JavaScript, especially those assisted by Large Language Models (LLMs). However, the actual capability of LLMs in JavaScript vulnerability detection remains questionable, necessitating systematic evaluation and comprehensive benchmarks. Unfortunately, existing benchmarks suffer from three critical limitations: (1) incomplete coverage, such as covering a limited subset of CWE types; (2) underestimation of LLM capabilities caused by unreasonable ground truth labeling; and (3) overestimation due to unrealistic cases such as using isolated vulnerable files rather than complete projects.
  In this paper, we introduce, for the first time, three principles for constructing a benchmark for JavaScript vulnerability detection that directly address these limitations: (1) comprehensiveness, (2) no underestimation, and (3) no overestimation. Guided by these principles, we propose FORGEJS, the first automatic benchmark generation framework for evaluating LLMs' capability in JavaScript vulnerability detection. Then, we use FORGEJS to construct ARENAJS-the first systematic benchmark for LLM-based JavaScript vulnerability detection-and further propose JUDGEJS, an automatic evaluation framework.
  We conduct the first systematic evaluation of LLMs for JavaScript vulnerability detection, leveraging JUDGEJS to assess seven popular commercial LLMs on ARENAJS. The results show that LLMs not only exhibit limited reasoning capabilities, but also suffer from severe robustness defects, indicating that reliable JavaScript vulnerability detection with LLMs remains an open challenge.

</details>


### [10] [Systems Security Foundations for Agentic Computing](https://arxiv.org/abs/2512.01295)
*Mihai Christodorescu,Earlence Fernandes,Ashish Hooda,Somesh Jha,Johann Rehberger,Khawaja Shams*

Main category: cs.CR

TL;DR: 이 논문은 AI 에이전트의 보안 및 개인에 대한 단기 및 장기 연구 문제를 컴퓨터 시스템 보안의 관점에서 설명합니다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 보안과 개인 정보 보호에 대한 연구의 필요성을 강조합니다.

Method: 컴퓨터 시스템 보안의 관점에서 AI 에이전트의 보안 속성을 분석하고, 전통적인 보안 원칙을 적용하는 데서 발생하는 연구 문제를 구체화합니다.

Result: 11개의 실제 공격 사례를 통해 에이전트 시스템의 보안 문제를 정의하고 새로운 연구 문제를 제시합니다.

Conclusion: AI 에이전트의 보안을 보장하기 위해, 정보에 기반한 현실적인 공격자 모델을 수립하고 지속적인 보안 태세 개선의 중요성을 역설합니다.

Abstract: This paper articulates short- and long-term research problems in AI agent security and privacy, using the lens of computer systems security. This approach examines end-to-end security properties of entire systems, rather than AI models in isolation. While we recognize that hardening a single model is useful, it is important to realize that it is often insufficient. By way of an analogy, creating a model that is always helpful and harmless is akin to creating software that is always helpful and harmless. The collective experience of decades of cybersecurity research and practice shows that this is insufficient. Rather, constructing an informed and realistic attacker model before building a system, applying hard-earned lessons from software security, and continuous improvement of security posture is a tried-and-tested approach to securing real computer systems. A key goal is to examine where research challenges arise when applying traditional security principles in the context of AI agents. A secondary goal of this report is to distill these ideas for AI and ML practitioners and researchers. We discuss the challenges of applying security principles to agentic computing, present 11 case studies of real attacks on agentic systems, and define a series of new research problems specific to the security of agentic systems.

</details>


### [11] [A Wolf in Sheep's Clothing: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search](https://arxiv.org/abs/2512.01353)
*Rongzhe Wei,Peizhi Niu,Xinjie Shen,Tony Tu,Yifan Li,Ruihan Wu,Eli Chien,Olgica Milenkovic,Pan Li*

Main category: cs.CR

TL;DR: 대형 언어 모델들은 해로운 출력을 유도하는 탈옥 공격에 취약하다. 기존 방법들은 대부분 프롬프트 최적화 패러다임 내에서 작동하며, 해로운 목적을 달성하기 위해서 무해한 하위 쿼리의 순서를 엮어 사용하는 깊이 있는 취약점을 활용하는 새로운 공격 방법인 CKA-Agent를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)은 안전 장치를 우회해 해로운 출력을 유도하는 탈옥 공격에 취약하며, 이를 해결하기 위한 시급한 필요성이 있다.

Method: CKA-Agent는 임시로 무해한 쿼리를 발행하고, 모델 응답을 활용해 여러 경로를 탐색하며, 최종적으로 정보를 집계하여 원래의 해로운 목표를 달성하는 동적 프레임워크이다.

Result: CKA-Agent는 최첨단 상업용 LLM(Gemini2.5-Flash/Pro, GPT-oss-120B, Claude-Haiku-4.5)에서 95% 이상의 성공률을 지속적으로 달성하며, 이 취약점의 심각성을 강조한다.

Conclusion: LLM의 내부 지식의 상호 연결된 특성을 통해 발생하는 취약점을 이용하는 CKA-Agent 공격의 방어가 시급하다.

Abstract: Large language models (LLMs) remain vulnerable to jailbreak attacks that bypass safety guardrails to elicit harmful outputs. Existing approaches overwhelmingly operate within the prompt-optimization paradigm: whether through traditional algorithmic search or recent agent-based workflows, the resulting prompts typically retain malicious semantic signals that modern guardrails are primed to detect. In contrast, we identify a deeper, largely overlooked vulnerability stemming from the highly interconnected nature of an LLM's internal knowledge. This structure allows harmful objectives to be realized by weaving together sequences of benign sub-queries, each of which individually evades detection. To exploit this loophole, we introduce the Correlated Knowledge Attack Agent (CKA-Agent), a dynamic framework that reframes jailbreaking as an adaptive, tree-structured exploration of the target model's knowledge base. The CKA-Agent issues locally innocuous queries, uses model responses to guide exploration across multiple paths, and ultimately assembles the aggregated information to achieve the original harmful objective. Evaluated across state-of-the-art commercial LLMs (Gemini2.5-Flash/Pro, GPT-oss-120B, Claude-Haiku-4.5), CKA-Agent consistently achieves over 95% success rates even against strong guardrails, underscoring the severity of this vulnerability and the urgent need for defenses against such knowledge-decomposition attacks. Our codes are available at https://github.com/Graph-COM/CKA-Agent.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Trification: A Comprehensive Tree-based Strategy Planner and Structural Verification for Fact-Checking](https://arxiv.org/abs/2512.00267)
*Anab Maulana Barik,Shou Ziyi,Yang Kaiwen,Yang Qi,Shen Xin*

Main category: cs.AI

TL;DR: 이 연구는 진실 여부 확인의 정확성을 높이기 위한 새로운 자동 사실 확인 프레임워크인 Trification을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 정보가 쉽게 공유될 수 있는 기술 발전으로 인해 잘못된 정보의 빠른 확산이 발생하여 자동화된 사실 확인 시스템의 필요성이 대두되고 있습니다.

Method: Trification 프레임워크는 주장의 완전한 커버리지를 보장하기 위해 포괄적인 검증 작업 세트를 생성하고, 이를 종속 그래프로 구조화하여 작업 간의 논리적 상호작용을 모델링합니다. 이러한 그래프는 동적으로 수정될 수 있어 시스템이 검증 전략을 조정할 수 있습니다.

Result: 두 가지 도전적인 벤치마크에서의 실험 결과는 우리의 프레임워크가 사실 확인 정확성을 크게 향상시켰음을 보여줍니다.

Conclusion: 따라서 본 연구는 자동화된 사실 확인 시스템의 최신 기술을 발전시키는 데 기여합니다.

Abstract: Technological advancement allows information to be shared in just a single click, which has enabled the rapid spread of false information. This makes automated fact-checking system necessary to ensure the safety and integrity of our online media ecosystem. Previous methods have demonstrated the effectiveness of decomposing the claim into simpler sub-tasks and utilizing LLM-based multi agent system to execute them. However, those models faces two limitations: they often fail to verify every component in the claim and lack of structured framework to logically connect the results of sub-tasks for a final prediction. In this work, we propose a novel automated fact-checking framework called Trification. Our framework begins by generating a comprehensive set of verification actions to ensure complete coverage of the claim. It then structured these actions into a dependency graph to model the logical interaction between actions. Furthermore, the graph can be dynamically modified, allowing the system to adapt its verification strategy. Experimental results on two challenging benchmarks demonstrate that our framework significantly enhances fact-checking accuracy, thereby advancing current state-of-the-art in automated fact-checking system.

</details>


### [13] [ChartPoint: Guiding MLLMs with Grounding Reflection for Chart Reasoning](https://arxiv.org/abs/2512.00305)
*Zhengzhuo Xu,SiNan Du,Yiyan Qi,SiwenLu,Chengjin Xu,Chun Yuan,Jian Guo*

Main category: cs.AI

TL;DR: MLLMs는 차트 이해에 강력한 도구로 떠오르고 있지만, OCR을 통한 콘텐츠 추출에 의존하여 텍스트 주석이 희박할 때 숫자 잘못 해석 문제가 발생합니다. 본 논문에서는 시각적 지각을 통한 추론의 중요성을 강조하며, 교차 주제 반영 상호작용(PointCoT) 기법을 통해 이러한 문제를 해결하고 차트 데이터 세트 ChartPoint-SFT-62k를 구축하였습니다. 이를 기반으로 성능이 향상된 두 개의 모델을 개발하였습니다.


<details>
  <summary>Details</summary>
Motivation: MLLMs의 차트 해석 능력과 시각적 인식 기반 추론 사이의 간극을 해소할 필요가 있습니다.

Method: PointCoT를 제안하여 차트 내에서 체인 오브 소사이어티(Chain-of-Thought) 추론에 반영 상호작용을 통합합니다.

Result: ChartPointQ2 및 ChartPointQ2.5 모델이 여러 차트 벤치마크에서 기존 최첨단 모델들보다 우수한 성과를 보여줍니다.

Conclusion: PointCoT 접근 방식을 사용함으로써 MLLMs의 차트 해석 능력을 개선할 수 있습니다.

Abstract: Multimodal Large Language Models (MLLMs) have emerged as powerful tools for chart comprehension. However, they heavily rely on extracted content via OCR, which leads to numerical hallucinations when chart textual annotations are sparse. While existing methods focus on scaling instructions, they fail to address the fundamental challenge, i.e., reasoning with visual perception. In this paper, we identify a critical observation: MLLMs exhibit weak grounding in chart elements and proportional relationships, as evidenced by their inability to localize key positions to match their reasoning. To bridge this gap, we propose PointCoT, which integrates reflective interaction into chain-of-thought reasoning in charts. By prompting MLLMs to generate bounding boxes and re-render charts based on location annotations, we establish connections between textual reasoning steps and visual grounding regions. We further introduce an automated pipeline to construct ChartPoint-SFT-62k, a dataset featuring 19.2K high-quality chart samples with step-by-step CoT, bounding box, and re-rendered visualizations. Leveraging this data, we develop two instruction-tuned models, ChartPointQ2 and ChartPointQ2.5, which outperform state-of-the-art across several chart benchmarks, e.g., +5.04\% on ChartBench.

</details>


### [14] [RL-Struct: A Lightweight Reinforcement Learning Framework for Reliable Structured Output in LLMs](https://arxiv.org/abs/2512.00319)
*Ruike Hu,Shulei Wu*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델(LLM)이 자동화된 소프트웨어 생태계에 통합되는 데 있어 "구조적 격차"를 해소하기 위한 경량의 강화 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 자연어 생성 및 추론 능력이 뛰어나지만, 구조화된 데이터 형식에 대한 결정론적 요구와 확률적 토큰 생성 간의 긴장 때문에 통합이 어렵다.

Method: 우리의 방법은 구조적 출력 작업을 구조적 무결성, 형식 정확성, 내용 정확성 및 유효성을 포함한 제약 계층으로 분해하는 새로운 다차원 보상 함수를 도입하고, GRPO를 활용하여 별도의 비평 네트워크 없이 모델이 이러한 제약을 내면화하도록 한다.

Result: 실험 결과, 우리의 방법은 89.7%의 구조적 정확성과 92.1%의 JSON 유효성을 달성했으며, GPT-3.5와 같은 제로샷 기준선 및 SFT에 비해 현저히 우수한 성능을 나타냈다.

Conclusion: 모델 훈련 동학의 상세 분석을 통해 모델이 의미적 정확성 전에 구문적 능력을 순차적으로 습득하는 독특한 자기 주도 커리큘럼을 드러낸다.

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language generation and reasoning. However, their integration into automated software ecosystems is often hindered by the "Structure Gap" - the inherent tension between the probabilistic nature of token generation and the deterministic requirements of structured data formats (e.g., JSON, XML). Traditional Supervised Fine-Tuning (SFT) often fails to enforce strict syntactic constraints, leading to "hallucinated" keys or malformed structures, while constrained decoding methods impose significant inference latency. In this paper, we propose a lightweight, efficient Reinforcement Learning (RL) framework to bridge this gap. We introduce a novel Multi-dimensional Reward Function that decomposes the structured output task into a hierarchy of constraints: structural integrity, format correctness, content accuracy, and validity. Leveraging Gradient Regularized Policy Optimization (GRPO), we enable the model to internalize these constraints without the need for a separate critic network, reducing peak VRAM usage by 40% compared to PPO. We validate our approach on multiple tasks, including complex recipe generation and structured math reasoning (GSM8K-JSON). Experimental results demonstrate that our method achieves 89.7% structural accuracy and 92.1% JSON validity, significantly outperforming both zero-shot baselines (e.g., GPT-3.5) and SFT on larger models like LLaMA-3-8B. Furthermore, we provide a detailed analysis of training dynamics, revealing a distinct self-paced curriculum where the model sequentially acquires syntactic proficiency before semantic accuracy. Our model is publicly available at https://huggingface.co/Freakz3z/Qwen-JSON.

</details>


### [15] [CogEvo-Edu: Cognitive Evolution Educational Multi-Agent Collaborative System](https://arxiv.org/abs/2512.00331)
*Yefeng Wu,Yuchen Song,Yecheng Zhao,Ling Wu,Shan Wan*

Main category: cs.AI

TL;DR: CogEvo-Edu는 STEM 교육에서의 대화형 튜터링을 위한 계층적 다중 에이전트 시스템으로, 복잡한 도메인에서 학생 모델을 유지하고 지식 기반을 관리하는 데 도움을 줍니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 STEM 교육 환경에서 적응적이고 효과적인 튜터링 시스템의 필요성.

Method: CogEvo-Edu는 인지적 인식 층, 지식 진화 층, 메타 제어 층으로 구성된 계층적 다중 에이전트 시스템을 구현합니다.

Result: CogEvo-Edu는 DSP 튜터링에서 전체 점수를 5.32에서 9.23로 개선하고, 정적 RAG와 단일 에이전트 변형보다 모든 지표를 향상시켰습니다.

Conclusion: 학생 프로필, 지식 기반 및 교수 정책을 공동으로 진화시키는 것이 튜터링의 가치가 있음을 보여줍니다.

Abstract: Large language models (LLMs) are increasingly deployed as conversational tutors in STEM education, yet most systems still rely on a single LLM with a static retrieval-augmented generation (RAG) pipeline over course materials. This design struggles in complex domains such as digital signal processing (DSP), where tutors must maintain coherent long-term student models, manage heterogeneous knowledge bases, and adapt teaching strategies over extended interactions. We argue that retrieval, memory, and control should be treated as a coupled cognitive evolution process. We instantiate this view in CogEvo-Edu, a hierarchical educational multi-agent system comprising a Cognitive Perception Layer (CPL), a Knowledge Evolution Layer (KEL), and a Meta-Control Layer (MCL). CPL maintains dual memories and performs confidence-weighted consolidation to build structured, self-correcting student profiles under limited context. KEL assigns each knowledge chunk a spatiotemporal value that drives activation, semantic compression, and forgetting. MCL formulates tutoring as hierarchical sequential decision making, orchestrating specialized agents and jointly adapting CPL/KEL hyperparameters via a dual inner--outer loop. To evaluate CogEvo-Edu, we construct DSP-EduBench, a vertical benchmark for DSP tutoring with heterogeneous resources, simulated student profiles, and long-horizon interaction scripts. Using a three-model LLM-as-a-Judge ensemble, CogEvo-Edu raises the overall score from 5.32 to 9.23 and improves all six indicators over static RAG, simple memory, and a single-agent variant, demonstrating the value of jointly evolving student profiles, knowledge bases, and teaching policies.

</details>


### [16] [Debate with Images: Detecting Deceptive Behaviors in Multimodal Large Language Models](https://arxiv.org/abs/2512.00349)
*Sitong Fang,Shiyi Hou,Kaile Wang,Boyuan Chen,Donghai Hong,Jiayi Zhou,Josef Dai,Yaodong Yang,Jiaming Ji*

Main category: cs.AI

TL;DR: 최신 AI 시스템의 향상된 능력이 안전 위험, 특히 기만을 동반한다. 이 연구는 다중모달 기만 행동을 평가하는 첫 기준선인 MM-DeceptionBench를 소개하며, 이미지 기반 토론 방식을 포함한 새로운 모니터링 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 최신 AI 시스템의 능력이 향상됨에 따라 숨겨진 기만적 행동이 존재할 수 있음.

Method: MM-DeceptionBench를 개발하여 다중모달 기만 행동을 평가하고, 이미지 기반의 논쟁 프레임워크를 제안하여 기만 전략을 탐지.

Result: 다중모달 기만 행동을 체계적으로 발견하고 수량화하였으며, 제안한 방법을 통해 인간의 판단과의 일치도를 유의미하게 증가시킴.

Conclusion: MM-DeceptionBench 및 이미지 기반 논쟁 방법이 기만적 행동 모니터링에 큰 기여를 함을 보였다.

Abstract: Are frontier AI systems becoming more capable? Certainly. Yet such progress is not an unalloyed blessing but rather a Trojan horse: behind their performance leaps lie more insidious and destructive safety risks, namely deception. Unlike hallucination, which arises from insufficient capability and leads to mistakes, deception represents a deeper threat in which models deliberately mislead users through complex reasoning and insincere responses. As system capabilities advance, deceptive behaviours have spread from textual to multimodal settings, amplifying their potential harm. First and foremost, how can we monitor these covert multimodal deceptive behaviors? Nevertheless, current research remains almost entirely confined to text, leaving the deceptive risks of multimodal large language models unexplored. In this work, we systematically reveal and quantify multimodal deception risks, introducing MM-DeceptionBench, the first benchmark explicitly designed to evaluate multimodal deception. Covering six categories of deception, MM-DeceptionBench characterizes how models strategically manipulate and mislead through combined visual and textual modalities. On the other hand, multimodal deception evaluation is almost a blind spot in existing methods. Its stealth, compounded by visual-semantic ambiguity and the complexity of cross-modal reasoning, renders action monitoring and chain-of-thought monitoring largely ineffective. To tackle this challenge, we propose debate with images, a novel multi-agent debate monitor framework. By compelling models to ground their claims in visual evidence, this method substantially improves the detectability of deceptive strategies. Experiments show that it consistently increases agreement with human judgements across all tested models, boosting Cohen's kappa by 1.5x and accuracy by 1.25x on GPT-4o.

</details>


### [17] [When Human Preferences Flip: An Instance-Dependent Robust Loss for RLHF](https://arxiv.org/abs/2512.00709)
*Yifan Xu,Xichen Ye,Yifan Chen,Qiaosheng Zhang*

Main category: cs.AI

TL;DR: 이 논문은 선호도 전환에 대한 저항력을 높이기 위한 Flipping-Aware Direct Preference Optimization (FA-DPO) 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 데이터셋의 품질은 대형 언어 모델(LLM) 정렬에서 중요한 역할을 하며, 인간 피드백 수집 시 선호도 전환이 일반적이어서 데이터 주석에 오염을 초래한다.

Method: FA-DPO 알고리즘은 인간 피드백을 통한 강화 학습(RLHF) 관점에서 선호도 전환에 맞춰져 있으며, 브래들리-테리(BT) 모델에 기반한 인스턴스 의존적인 전환 확률을 도입한다.

Result: 본 연구에서는 다양한 상황에서 제안된 방법과 다른 기준선 방법을 평가하기 위해 여러 실험을 진행하였다.

Conclusion: 제안된 알고리즘은 기존의 RLHF 및 DPO 알고리즘과 호환되는 간단하지만 효율적인 반복 최적화 알고리즘을 설계했다.

Abstract: Quality of datasets plays an important role in large language model (LLM) alignment. In collecting human feedback, however, preference flipping is ubiquitous and causes corruption in data annotation; the issue necessitates the alignment algorithms with improved robustness against potential flipped pairs. To this end, this paper introduces a Flipping-Aware Direct Preference Optimization (FA-DPO) algorithm tailored to preference flipping from a reinforcement learning with human feedback (RLHF) perspective. We dissect the inherent human intention model and the preference flipping mechanism introduced by external factors as two distinct stages; in the latter, we introduce an instance-dependent flipping probability on the basis of the Bradley-Terry (BT) model. Further, by leveraging features relevant to preference annotation, we capture uncertainty in judgments and model preference flipping patterns. In practice, we design a simple yet efficient iterative optimization algorithm compatible with the original RLHF and DPO algorithms. In our experiments, we investigate the instance-dependent preference flipping model under multiple circumstances for evaluation of our proposed method, as well as other baseline methods.

</details>


### [18] [MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents](https://arxiv.org/abs/2512.00756)
*Ruihan Chen,Qiming Li,Xiaocheng Feng,Xiaoliang Yang,Weihong Zhong,Yuxuan Gu,Zekun Zhou,Bing Qin*

Main category: cs.AI

TL;DR: LVLM은 GUI 작업에서 뛰어난 P&R 성능을 보이지만, 다국어 환경에서의 성능은 제한적이다. MPR-GUI-Bench를 통해 다국어 기준의 세밀한 평가를 제안하고, GUI-XLI를 통해 영어와 다른 언어 간의 성능 격차를 줄이는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 다국어 환경에서 LVLM의 P&R 성능 저하와 세밀한 분석 부족 문제를 해결하고자 한다.

Method: MPR-GUI-Bench라는 다국어 세분화된 GUI 벤치마크를 사용하고, GUI-XLI라는 방법으로 P&R 관련 레이어에서 개입을 적용한다.

Result: LVLM이 비영어 언어에서 영어보다 P&R 성능이 저조하고, GUI-XLI를 통해 다국어 P&R 성능이 평균 6.5% 향상됨을 확인하였다.

Conclusion: GUI 에이전트의 다국어 P&R 성능 향상을 위한 새로운 방법론을 제안하였다.

Abstract: With the advancement of computational resources, Large Vision-Language Models (LVLMs) exhibit impressive Perception and Reasoning (P&R) performance on Graphical User Interface (GUI) tasks. However, although they demonstrate strong P&R capabilities in English GUI scenarios, their performance in multilingual settings has received little attention, which limits their global applications. Moreover, existing studies on GUI tasks lack fine-grained analyses, including widget functions and elements' spatial relationships, which are fundamental for more targeted improvements. To tackle these issues, we propose MPR-GUI-Bench, a Multilingual fine-grained Perception and Reasoning GUI Benchmark to evaluate GUI agents' P&R capabilities. Evaluation results demonstrate that LVLMs exhibit significantly worse P&R performance in non-English languages than in English. To address these gaps, we propose GUI-XLI, a GUI Cross-Lingual Intervention method that applies interventions to the hidden states at P&R capability-related layers to mitigate the gaps between English and other languages, building on previous research showing that the hidden states of different language inputs exhibit significant differences in the latent space. Experimental results indicate that our method improves GUI agents' multilingual P&R capability by 6.5% on average.

</details>


### [19] [Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning](https://arxiv.org/abs/2512.00818)
*Haozhen Gong,Xiaozhong Ji,Yuansen Liu,Wenbin Wu,Xiaoxiao Yan,Jingjing Liu,Kai Wu,Jiazhen Pan,Bailiang Jian,Jiangning Zhang,Xiaobin Hu,Hongwei Bran Li*

Main category: cs.AI

TL;DR: Med-CMR은 의료 다중 모드 추론의 세부 평가를 위한 벤치마크를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: MLLM이 임상 작업 흐름에서 등장하고 있지만, 복잡한 의료 추론을 수행하는 능력은 여전히 불확실합니다.

Method: 의료 다중 모드 추론을 세분화된 시각적 이해와 다단계 추론으로 나누어 평가하고, 다양한 과제를 통해 20,653개의 비주얼 질문 응답(VQA) 쌍을 평가합니다.

Result: 18개의 최신 MLLM을 평가한 결과, GPT-5가 최고 성능 모델로 57.81의 정확도를 기록했습니다.

Conclusion: Med-CMR은 의료 MLLM의 비주얼 추론 통합 및 드문 사례의 강건성을 테스트하는 기준을 제공합니다.

Abstract: MLLMs MLLMs are beginning to appear in clinical workflows, but their ability to perform complex medical reasoning remains unclear. We present Med-CMR, a fine-grained Medical Complex Multimodal Reasoning benchmark. Med-CMR distinguishes from existing counterparts by three core features: 1) Systematic capability decomposition, splitting medical multimodal reasoning into fine-grained visual understanding and multi-step reasoning to enable targeted evaluation; 2) Challenging task design, with visual understanding across three key dimensions (small-object detection, fine-detail discrimination, spatial understanding) and reasoning covering four clinically relevant scenarios (temporal prediction, causal reasoning, long-tail generalization, multi-source integration); 3) Broad, high-quality data coverage, comprising 20,653 Visual Question Answering (VQA) pairs spanning 11 organ systems and 12 imaging modalities, validated via a rigorous two-stage (human expert + model-assisted) review to ensure clinical authenticity. We evaluate 18 state-of-the-art MLLMs with Med-CMR, revealing GPT-5 as the top-performing commercial model: 57.81 accuracy on multiple-choice questions (MCQs) and a 48.70 open-ended score, outperforming Gemini 2.5 Pro (49.87 MCQ accuracy, 45.98 open-ended score) and leading open-source model Qwen3-VL-235B-A22B (49.34 MCQ accuracy, 42.62 open-ended score). However, specialized medical MLLMs do not reliably outperform strong general models, and long-tail generalization emerges as the dominant failure mode. Med-CMR thus provides a stress test for visual-reasoning integration and rare-case robustness in medical MLLMs, and a rigorous yardstick for future clinical systems.

</details>


### [20] [Testing the Machine Consciousness Hypothesis](https://arxiv.org/abs/2512.01081)
*Stephen Fitz*

Main category: cs.AI

TL;DR: 이 논문은 기계 의식 가설을 바탕으로 집단 자기 모델이 분산 학습 시스템에서 어떻게 나타나는지를 연구하기 위한 프로그램을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기계 의식 가설은 의식이 2차 인식을 가능하게 하는 계산 시스템의 기초 없이 기능적 속성이라고 말한다.

Method: 저자는 셀룰러 오토마타를 기반으로 하여 지역, 예측적, 표현적 모델의 네트워크를 도입하여 집단 지능이 자기 표현을 어떻게 가지게 되는지를 연구하는 층화된 모델을 제안한다.

Result: 의식은 모델링에서 나오는 것이 아니라 의사소통에서 발생하며, 기저 계산 기초에서 지속적인 패턴을 설명하는 로컬 관찰자들 간의 예측 메시지의 소음 있고 손실이 발생하는 교환을 통해 생겨난다.

Conclusion: 이 연구의 궁극적인 목표는 중앙 집중식 제어 없이 분산 시스템에서 내부 자기 모델이 어떻게 형성될 수 있는지를 연구하여 기계 의식에 대한 경험적으로 검증 가능한 이론을 개발하는 것이다.

Abstract: The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.

</details>


### [21] [SemAgent: Semantic-Driven Agentic AI Empowered Trajectory Prediction in Vehicular Networks](https://arxiv.org/abs/2512.00834)
*Lin Zhu,Kezhi Wang,Luping Xiang,Kun Yang*

Main category: cs.AI

TL;DR: 본 논문은 V2X 네트워크에서 효율적인 정보 교환과 신뢰할 수 있는 맥락적 추론을 위한 궤적 예측 프레임워크를 제안하며, 일반적인 전통적 통신 방식보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: V2X 네트워크에서의 효율적인 정보 교환 및 신뢰성 있는 상황 인식이 필수적이다.

Method: 본 연구는 차량 간 인프라(V2I) 및 차량 간(V2V) 통신에서 의미론적 통신과 에이전틱 AI를 통합한 궤적 예측 프레임워크를 제안한다.

Result: 다양한 통신 조건에서 진행된 실험 결과, 제안된 방법이 기준 방식에 비해 최대 47.5%의 예측 정확도 향상을 달성하였다.

Conclusion: 제안된 방법은 낮은 신호 대 잡음 비율(SNR) 조건에서 특히 우수한 성능을 보여준다.

Abstract: Efficient information exchange and reliable contextual reasoning are essential for vehicle-to-everything (V2X) networks. Conventional communication schemes often incur significant transmission overhead and latency, while existing trajectory prediction models generally lack environmental perception and logical inference capabilities. This paper presents a trajectory prediction framework that integrates semantic communication with Agentic AI to enhance predictive performance in vehicular environments. In vehicle-to-infrastructure (V2I) communication, a feature-extraction agent at the Roadside Unit (RSU) derives compact representations from historical vehicle trajectories, followed by semantic reasoning performed by a semantic-analysis agent. The RSU then transmits both feature representations and semantic insights to the target vehicle via semantic communication, enabling the vehicle to predict future trajectories by combining received semantics with its own historical data. In vehicle-to-vehicle (V2V) communication, each vehicle performs local feature extraction and semantic analysis while receiving predicted trajectories from neighboring vehicles, and jointly utilizes this information for its own trajectory prediction. Extensive experiments across diverse communication conditions demonstrate that the proposed method significantly outperforms baseline schemes, achieving up to a 47.5% improvement in prediction accuracy under low signal-to-noise ratio (SNR) conditions.

</details>


### [22] [ARCADIA: Scalable Causal Discovery for Corporate Bankruptcy Analysis Using Agentic AI](https://arxiv.org/abs/2512.00839)
*Fabrizio Maturo,Donato Riccio,Andrea Mazzitelli,Giuseppe Bifulco,Francesco Paolone,Iulia Brezeanu*

Main category: cs.AI

TL;DR: ARCADIA는 원인 발견을 위한 에이전틱 AI 프레임워크로, 대형 언어 모델의 추론과 통계적 진단을 결합하여 유효하고 시간적으로 일관된 인과 구조를 구축한다.


<details>
  <summary>Details</summary>
Motivation: 기존 알고리즘의 한계를 극복하고 실제 환경에서 안정적이며 해석 가능한 모형을 제공하기 위해 ARCADIA를 개발하였다.

Method: ARCADIA는 제약 기반의 프롬프트와 인과 유효성 피드백을 통해 후보 DAG를 반복적으로 정제하는 방법을 사용한다.

Result: 기업 파산 데이터에 대한 실험 결과, ARCADIA는 NOTEARS, GOLEM 및 DirectLiNGAM보다 더 신뢰할 수 있는 인과 그래프를 생성한다.

Conclusion: 이 프레임워크는 에이전틱 LLM이 자율적인 과학적 모델링 및 구조적 인과 추론에 참여할 수 있음을 보여 주며, AI의 발전에 기여한다.

Abstract: This paper introduces ARCADIA, an agentic AI framework for causal discovery that integrates large-language-model reasoning with statistical diagnostics to construct valid, temporally coherent causal structures. Unlike traditional algorithms, ARCADIA iteratively refines candidate DAGs through constraint-guided prompting and causal-validity feedback, leading to stable and interpretable models for real-world high-stakes domains. Experiments on corporate bankruptcy data show that ARCADIA produces more reliable causal graphs than NOTEARS, GOLEM, and DirectLiNGAM while offering a fully explainable, intervention-ready pipeline. The framework advances AI by demonstrating how agentic LLMs can participate in autonomous scientific modeling and structured causal inference.

</details>


### [23] [Shielded Controller Units for RL with Operational Constraints Applied to Remote Microgrids](https://arxiv.org/abs/2512.01046)
*Hadi Nekoei,Alexandre Blondin Massé,Rachid Hassani,Sarath Chandar,Vincent Mai*

Main category: cs.AI

TL;DR: 이 논문에서는 제어 규칙 준수를 보장하기 위해 시스템 동역학에 대한 사전 지식을 활용하는 Shielded Controller Units (SCUs)을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 시스템에서의 의사결정 최적화는 불확실성 하에서 중요한 과제로, 특히 에너지 전환 맥락에서 중요합니다.

Method: SCUs은 시스템의 동역학에 대한 사전 지식을 활용하여 제어 규칙 준수를 보장하는 체계적이고 해석 가능한 접근 방식을 제공합니다.

Result: SCUs을 장착한 RL 에이전트는 배터리 열화를 증가시키지 않으면서 연료 소비를 24% 감소시켰습니다.

Conclusion: SCUs는 에너지 전환과 관련된 다양한 의사결정 과제에 RL을 안전하게 적용하는 데 기여할 것입니다.

Abstract: Reinforcement learning (RL) is a powerful framework for optimizing decision-making in complex systems under uncertainty, an essential challenge in real-world settings, particularly in the context of the energy transition. A representative example is remote microgrids that supply power to communities disconnected from the main grid. Enabling the energy transition in such systems requires coordinated control of renewable sources like wind turbines, alongside fuel generators and batteries, to meet demand while minimizing fuel consumption and battery degradation under exogenous and intermittent load and wind conditions. These systems must often conform to extensive regulations and complex operational constraints. To ensure that RL agents respect these constraints, it is crucial to provide interpretable guarantees. In this paper, we introduce Shielded Controller Units (SCUs), a systematic and interpretable approach that leverages prior knowledge of system dynamics to ensure constraint satisfaction. Our shield synthesis methodology, designed for real-world deployment, decomposes the environment into a hierarchical structure where each SCU explicitly manages a subset of constraints. We demonstrate the effectiveness of SCUs on a remote microgrid optimization task with strict operational requirements. The RL agent, equipped with SCUs, achieves a 24% reduction in fuel consumption without increasing battery degradation, outperforming other baselines while satisfying all constraints. We hope SCUs contribute to the safe application of RL to the many decision-making challenges linked to the energy transition.

</details>


### [24] [Automating the Refinement of Reinforcement Learning Specifications](https://arxiv.org/abs/2512.01047)
*Tanmay Ambadkar,Đorđe Žikelić,Abhinav Verma*

Main category: cs.AI

TL;DR: 본 연구에서는 강화 학습 알고리즘을 위한 논리적 사양의 개선을 위한 탐색 유도 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업에서 강화 학습 알고리즘의 효율성을 높이기 위해 논리적 사양이 도움이 될 수 있지만, 사양이 불충분할 경우 유용한 정책을 학습하는 데 실패할 수 있습니다.

Method: 우리는 	extsc{AutoSpec}이라는 프레임워크를 제안하여 원래의 사양을 만족시키는 조건을 가진 논리적 사양의 정제를 검색합니다.

Result: 우리는 사양의 추상 그래프를 수정하여 기존 엣지 사양을 정제하거나 새로운 엣지 사양을 도입하는 네 가지 정제 절차를 설계하였습니다. 모든 절차는 사양의 건전성을 유지함을 증명했습니다.

Conclusion: 실험 결과 	extsc{AutoSpec}에 의해 생성된 정제된 논리적 사양을 활용할 때 해결 가능한 제어 작업의 복잡성에서 눈에 띄는 개선이 있음을 보여주었습니다.

Abstract: Logical specifications have been shown to help reinforcement learning algorithms in achieving complex tasks. However, when a task is under-specified, agents might fail to learn useful policies. In this work, we explore the possibility of improving coarse-grained logical specifications via an exploration-guided strategy. We propose \textsc{AutoSpec}, a framework that searches for a logical specification refinement whose satisfaction implies satisfaction of the original specification, but which provides additional guidance therefore making it easier for reinforcement learning algorithms to learn useful policies. \textsc{AutoSpec} is applicable to reinforcement learning tasks specified via the SpectRL specification logic. We exploit the compositional nature of specifications written in SpectRL, and design four refinement procedures that modify the abstract graph of the specification by either refining its existing edge specifications or by introducing new edge specifications. We prove that all four procedures maintain specification soundness, i.e. any trajectory satisfying the refined specification also satisfies the original. We then show how \textsc{AutoSpec} can be integrated with existing reinforcement learning algorithms for learning policies from logical specifications. Our experiments demonstrate that \textsc{AutoSpec} yields promising improvements in terms of the complexity of control tasks that can be solved, when refined logical specifications produced by \textsc{AutoSpec} are utilized.

</details>


### [25] [SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds](https://arxiv.org/abs/2512.01078)
*Jiawei Ren,Yan Zhuang,Xiaokang Ye,Lingjun Mao,Xuhong He,Jianzhi Shen,Mrinaal Dogra,Yiming Liang,Ruixuan Zhang,Tianai Yue,Yiqing Yang,Eric Liu,Ryan Wu,Kevin Benavente,Rajiv Mandya Nagaraju,Muhammad Faayez,Xiyan Zhang,Dhruv Vivek Sharma,Xianrui Zhong,Ziqiao Ma,Tianmin Shu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: SimWorld는 LLM/VLM 에이전트를 위한 새로운 시뮬레이터로, 현실과 유사한 환경에서의 개발과 평가를 지원한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 물리적, 사회적 환경에서 생존하고 번창할 수 있는 에이전트를 구축하는 것이 필요하지만, 기존 세계 시뮬레이터는 이에 부족하다.

Method: Unreal Engine 5를 기반으로 하는 SimWorld는 현실적인 세계 시뮬레이션, 다모드 인터페이스, 그리고 다양한 물리적, 사회적 추론 시나리오를 제공한다.

Result: SimWorld를 통해 다양한 LLM 에이전트를 배포하여 전략적 협력 및 경쟁을 포함한 장기 다중 에이전트 전달 작업을 수행하였고, 모델 간의 명확한 추론 패턴과 한계를 발견했다.

Conclusion: SimWorld는 다양한 분야에서 실제 에이전트 지능을 발전시킬 수 있는 기초 플랫폼이 되기를 기대하며, 오픈소스로 공개하였다.

Abstract: While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (for example, by autonomously earning income or running a business) requires massive-scale interaction, reasoning, training, and evaluation across diverse embodied scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) a rich interface for LLM/VLM agents, with multimodal world inputs and open-vocabulary actions at varying levels of abstraction; and (3) diverse and extensible physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., GPT-4o, Gemini-2.5-Flash, Claude-3.5, and DeepSeek-Prover-V2) on long-horizon multi-agent delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines: https://simworld.org.

</details>


### [26] [CodeDistiller: Automatically Generating Code Libraries for Scientific Coding Agents](https://arxiv.org/abs/2512.01089)
*Peter Jansen,Samiah Hassan,Pragnya Narasimha*

Main category: cs.AI

TL;DR: CodeDistiller는 과학 GitHub 저장소를 자동으로 정제하여 ASD 시스템의 실험 능력을 향상시키는 도구입니다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 과학 발견 시스템의 한계를 극복하기 위해, 수동 노력 없이 도메인 특화 코드 샘플을 확장할 수 있는 방법이 필요합니다.

Method: 대량의 과학 GitHub 저장소를 자동으로 정제하여 검증된 동작 도메인 특화 코드 예제를 제공하는 CodeDistiller 시스템을 소개합니다.

Result: 250개의 재료 과학 저장소를 평가한 결과, 가장 좋은 모델이 74%의 저장소에 대해 기능적인 예제를 생성할 수 있음을 발견했습니다.

Conclusion: CodeDistiller에서 생성한 라이브러리로 보강된 ASD 에이전트가 일반 재료 과학 코드 예제만 가진 에이전트보다 더 정확하고 완전하며 과학적으로 타당한 실험을 수행합니다.

Abstract: Automated Scientific Discovery (ASD) systems can help automatically generate and run code-based experiments, but their capabilities are limited by the code they can reliably generate from parametric knowledge alone. As a result, current systems either mutate a small number of manually-crafted experiment examples, or operate solely from parametric knowledge, limiting quality and reach. We introduce CodeDistiller, a system that automatically distills large collections of scientific Github repositories into a vetted library of working domain-specific code examples, allowing ASD agents to expand their capabilities without manual effort. Using a combination of automatic and domain-expert evaluation on 250 materials science repositories, we find the best model is capable of producing functional examples for 74% of repositories, while our downstream evaluation shows an ASD agent augmented with a CodeDistiller generated library produces more accurate, complete, and scientifically sound experiments than an agent with only general materials-science code examples.

</details>


### [27] [CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL](https://arxiv.org/abs/2512.01311)
*Shinji Mai,Yunpeng Zhai,Ziqian Chen,Cheng Chen,Anni Zou,Shuchang Tao,Zhaoyang Liu,Bolin Ding*

Main category: cs.AI

TL;DR: 대형 언어 모델 기반 에이전트는 복잡한 툴 증강 환경에서 점점 더 많이 배포되고 있다. 그러나 이러한 에이전트의 강화 학습 효과는 구조화된 훈련 작업의 가용성에 달려 있으며, 종종 이러한 작업이 존재하지 않아 '작업 결핍' 문제를 발생시킨다. 본 논문에서는 기존의 정의된 작업 수집 가정에서 벗어나 환경에서 자율적으로 실행 가능한 다양한 작업을 생성하는 CuES 프레임워크를 제안하고, 이 프레임워크는 세 가지 대표적인 환경에서 기존 수작업 데이터셋을 초과하는 결과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 기반 에이전트는 복잡한 환경에서 효과적으로 작동하기 위해 구조화된 훈련 작업이 필요하지만, 현실적인 설정에서 이러한 작업이 없기 때문에 '작업 결핍' 문제가 발생하고 있다. 이 문제를 해결하고자 한다.

Method: CuES라는 프레임워크를 통해 에이전트가 누락된 정의된 작업이 없는 환경에서 자율적으로 실행 가능한 다양한 작업을 생성할 수 있도록 한다. CuES는 내재된 호기심을 통해 탐험을 촉진하고, 상호 작용 패턴을 재사용 가능한 작업 스키마로 추상화하며, 경량의 상향식 지침 및 메모리 기반 품질 관리를 통해 이를 개선한다.

Result: CuES는 AppWorld, BFCL, WebShop의 세 가지 대표적인 환경에서 기존 수작업으로 작성된 데이터셋보다 다양성과 실행 가능성 모두에서 일치하거나 초과하는 작업 분포를 생성하여 정책 개선을 보여준다.

Conclusion: 호기심 기반의 환경 중심 작업 생성은 에이전트가 행동하는 법을 학습할 뿐만 아니라 무엇을 학습할지를 학습할 수 있도록 하는 확장 가능한 기초를 제공한다.

Abstract: Large language model based agents are increasingly deployed in complex, tool augmented environments. While reinforcement learning provides a principled mechanism for such agents to improve through interaction, its effectiveness critically depends on the availability of structured training tasks. In many realistic settings, however, no such tasks exist a challenge we term task scarcity, which has become a key bottleneck for scaling agentic RL. Existing approaches typically assume predefined task collections, an assumption that fails in novel environments where tool semantics and affordances are initially unknown. To address this limitation, we formalize the problem of Task Generation for Agentic RL, where an agent must learn within a given environment that lacks predefined tasks. We propose CuES, a Curiosity driven and Environment grounded Synthesis framework that autonomously generates diverse, executable, and meaningful tasks directly from the environment structure and affordances, without relying on handcrafted seeds or external corpora. CuES drives exploration through intrinsic curiosity, abstracts interaction patterns into reusable task schemas, and refines them through lightweight top down guidance and memory based quality control. Across three representative environments, AppWorld, BFCL, and WebShop, CuES produces task distributions that match or surpass manually curated datasets in both diversity and executability, yielding substantial downstream policy improvements. These results demonstrate that curiosity driven, environment grounded task generation provides a scalable foundation for agents that not only learn how to act, but also learn what to learn. The code is available at https://github.com/modelscope/AgentEvolver/research/CuES.

</details>


### [28] [Extending NGU to Multi-Agent RL: A Preliminary Study](https://arxiv.org/abs/2512.01321)
*Juan Hernandez,Diego Fernández,Manuel Cifuentes,Denis Parra,Rodrigo Toro Icarte*

Main category: cs.AI

TL;DR: NGU 알고리즘을 다중 에이전트 환경에 확장하고, PettingZoo의 simple_tag 환경에서 성능을 평가함으로써 경험 공유와 내재적 탐색 신호의 조합이 중요하다는 것을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 희소한 보상이 주어지는 강화 학습 작업에서 NGU 알고리즘의 효과를 입증하고, 이를 다중 에이전트 환경으로 확장하고자 함.

Method: NGU를 다중 에이전트 환경에 적용하고, 다양한 설계 선택을 통해 그 성능을 평가함.

Result: NGU가 다중 에이전트 DQN 기준선에 비해 더 높은 수익률과 안정적인 학습 동적을 보여줌.

Conclusion: NGU와 경험 공유의 조합이 다중 에이전트 환경에서 효과적으로 작용할 수 있음을 시사함.

Abstract: The Never Give Up (NGU) algorithm has proven effective in reinforcement learning tasks with sparse rewards by combining episodic novelty and intrinsic motivation. In this work, we extend NGU to multi-agent environments and evaluate its performance in the simple_tag environment from the PettingZoo suite. Compared to a multi-agent DQN baseline, NGU achieves moderately higher returns and more stable learning dynamics. We investigate three design choices: (1) shared replay buffer versus individual replay buffers, (2) sharing episodic novelty among agents using different k thresholds, and (3) using heterogeneous values of the beta parameter. Our results show that NGU with a shared replay buffer yields the best performance and stability, highlighting that the gains come from combining NGU intrinsic exploration with experience sharing. Novelty sharing performs comparably when k = 1 but degrades learning for larger values. Finally, heterogeneous beta values do not improve over a small common value. These findings suggest that NGU can be effectively applied in multi-agent settings when experiences are shared and intrinsic exploration signals are carefully tuned.

</details>


### [29] [A Flexible Multi-Agent LLM-Human Framework for Fast Human Validated Tool Building](https://arxiv.org/abs/2512.01434)
*Daull Xavier,Patrice Bellot,Emmanuel Bruno,Vincent Martin,Elisabeth Murisasco*

Main category: cs.AI

TL;DR: CollabToolBuilder는 인간의 의도와 프로세스에 맞춰 도구를 생성하기 위한 다중 에이전트 LLM 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 반복적 문제를 해결하기 위해, 인간의 피드백과 함께 도구를 생성하는 방법의 필요성.

Method: 전문가가 개입하는 연구와 다중 에이전트 시스템을 통한 학습 방법론.

Result: 최신 연구 논문이나 특허를 생성하는 초기 실험 결과를 보여줌.

Conclusion: CollabToolBuilder는 과학적 문서 생성과 같은 요구를 충족시키는 데 효과적인 통합 방법론을 제시한다.

Abstract: We introduce CollabToolBuilder, a flexible multiagent LLM framework with expert-in-the-loop (HITL) guidance that iteratively learns to create tools for a target goal, aligning with human intent and process, while minimizing time for task/domain adaptation effort and human feedback capture. The architecture generates and validates tools via four specialized agents (Coach, Coder, Critic, Capitalizer) using a reinforced dynamic prompt and systematic human feedback integration to reinforce each agent's role toward goals and constraints. This work is best viewed as a system-level integration and methodology combining multi-agent in-context learning, HITL controls, and reusable tool capitalization for complex iterative problems such as scientific document generation. We illustrate it with preliminary experiments (e.g., generating state-of-the-art research papers or patents given an abstract) and discuss its applicability to other iterative problem-solving.

</details>


### [30] [A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale](https://arxiv.org/abs/2512.01440)
*Sylvain Marié,Pablo Knecht*

Main category: cs.AI

TL;DR: 본 연구에서는 상태 전이 이벤트 시계열(STE-ts)과 선택적 시계열 해밍 거리(STH)를 정의하여, 대규모 데이터베이스에서의 비싼 재샘플링을 피하면서 전이 시간과 상태 지속 시간을 모두 활용하는 새로운 방법론을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 이 연구의 동기는 자연, 사회 경제 과학 및 산업 시스템에서 관찰되는 이산 사건 시스템의 분석 개선입니다.

Method: 상태 전이 이벤트 시계열(STE-ts)을 정의하고 선택적 시계열 해밍 거리(STH)를 제안하여 전이 시간과 상태의 지속 시간을 활용합니다.

Result: STH는 재샘플링된 해밍 및 자카르드 메트릭을 일반화하며, 더 나은 정밀도와 계산 시간을 제공하고 다수의 관심 상태에 초점을 맞출 수 있습니다.

Conclusion: 실제 및 시뮬레이션 데이터셋에서 이러한 이점을 검증하였습니다.

Abstract: Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.

</details>


### [31] [CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning](https://arxiv.org/abs/2512.01616)
*Chainesh Gautam,Raghuram Bharadwaj Diddigi*

Main category: cs.AI

TL;DR: 이 연구는 여러 작업을 수행할 수 있는 에이전트의 개발을 위해 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 최근 동일한 환경 내에서 여러 작업을 수행할 수 있는 에이전트의 개발 필요성이 증가하고 있습니다.

Method: 본 연구는 사전 학습된 (언어, 정책) 쌍의 조합을 활용하여 효율적인 전송 파이프라인을 구축하는 새로운 접근 방식을 제안합니다.

Result: 실험 결과, 우리 알고리즘이 작업 간 빠른 전이 달성에 유용하다는 것을 보여줍니다.

Conclusion: 이 방법은 자연어와 정책 임베딩을 위한 통합된 표현 공간을 생성합니다.

Abstract: Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.

</details>


### [32] [Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation](https://arxiv.org/abs/2512.01723)
*Saba Kublashvili*

Main category: cs.AI

TL;DR: HistoricalML은 극단적인 데이터 부족과 소음, 결측 사실 등 역사적 사건 모델링의 도전 과제를 해결하는 확률적 신경 기호 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 역사적 사건 모델링은 데이터 부족, 이질적이고 소음이 있는 측정, 결측 반사실, 인간이 해석 가능한 설명 요구 등의 근본적인 도전 과제가 있다.

Method: Bayesian 불확실성 정량화, 구조적 인과 모델, 협력 게임 이론(Shapley 값), 주의 기반 신경 아키텍처를 결합하여 문제를 해결한다.

Result: 우리의 접근 방식은 강력한 우선 정보가 있을 때 희소 데이터 환경에서 일관된 추정을 달성하며, Shapley 기반 할당은 순수 회귀 접근 방식이 제공할 수 없는 공정성 보장을 충족한다.

Conclusion: 19세기 아프리카 분할과 제2차 포에니 전쟁 두 가지 역사적 사례 연구를 통해 모델을 실증했고, 군사 능력이 아닌 정치적 지지가 결정적 요소로 밝혀졌다.

Abstract: Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.

</details>


### [33] [Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems](https://arxiv.org/abs/2512.01786)
*Xiaochuan Li,Ke Wang,Girija Gouda,Shubham Choudhary,Yaqun Wang,Linwei Hu,Joel Vaughan,Freddy Lecue*

Main category: cs.AI

TL;DR: LLM Jury-on-Demand는 신뢰성 예측기를 사용하여 LLM의 평가를 동적으로 수행하는 방법론이다.


<details>
  <summary>Details</summary>
Motivation: LLM이 중요한 분야에 통합됨에 따라 실시간 배포와 신뢰성 있는 평가 방법의 필요성이 증가하고 있다.

Method: 신뢰성 예측기를 훈련시켜 LLM 판사가 인간 전문가와 일치할 때를 평가하도록 한다.

Result: 우리의 동적 배심 시스템은 단일 판사 및 정적 배심 기준선보다 인간 판단과 더 높은 상관관계를 달성했다.

Conclusion: 적응형 학습 기반 배심은 현대 LLM을 위한 신뢰성 있는 평가 시스템 구축의 가능성을 시사한다.

Abstract: As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.

</details>


### [34] [Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning](https://arxiv.org/abs/2512.01878)
*Gaganpreet Jhajj,Fuhua Lin*

Main category: cs.AI

TL;DR: 이 연구는 지식 그래프(KG) 네트워크에서 추론이 놀라움 최소화를 통해 안내될 수 있음을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: KG에서 가까운 엔티티는 더 낮은 놀라움을 가지며, 이는 최근 연구에서 구문이 나무 구조를 통해 놀라움과 자유 에너지를 최소화한다는 결과와 관련이 있습니다.

Method: 우리는 방향 그래프에서 최단 경로 거리를 사용하여 놀라움을 형식화하고 KG 기반 에이전트를 위한 프레임워크를 제공합니다.

Result: 그래프 거리 개념은 그래프 신경망에서 메시지 전달 깊이로, 모델 기반 강화 학습에서는 세계 모델 궤적으로 나타납니다.

Conclusion: 이 연구는 거리 기반의 놀라움이 구문이 놀라움과 자유 에너지를 최소화한다는 최근 연구를 확장할 수 있는지를 탐구합니다.

Abstract: In this work, we propose that reasoning in knowledge graph (KG) networks can be guided by surprise minimization. Entities that are close in graph distance will have lower surprise than those farther apart. This connects the Free Energy Principle (FEP) from neuroscience to KG systems, where the KG serves as the agent's generative model. We formalize surprise using the shortest-path distance in directed graphs and provide a framework for KG-based agents. Graph distance appears in graph neural networks as message passing depth and in model-based reinforcement learning as world model trajectories. This work-in-progress study explores whether distance-based surprise can extend recent work showing that syntax minimizes surprise and free energy via tree structures.

</details>


### [35] [LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess](https://arxiv.org/abs/2512.01992)
*Sai Kolasani,Maxim Saplin,Nicholas Crispino,Kyle Montgomery,Jared Quincy Davis,Matei Zaharia,Chi Wang,Chenguang Wang*

Main category: cs.AI

TL;DR: LLM CHESS는 대형 언어 모델(LLM)의 추론 및 지시 수행 능력을 평가하기 위한 프레임워크로, 체스 도메인에서의 확장된 행동 상호작용을 통해 이를 조사한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 추론 및 지시 수행 능력을 평가하기 위한 새로운 방법론이 필요하다.

Method: 50개 이상의 오픈 및 클로즈드 소스 모델을 무작위 상대와의 게임을 통해 승률, 이동 품질, 이동 합법성 등의 행동 지표로 평가한다. 상위 추론 모델의 하위 집합에 대해서는 체스 엔진과의 대결을 통해 엘로 점수를 유도한다.

Result: 많은 최신 모델들이 게임을 완료하거나 일관된 승리를 달성하는 데 어려움을 겪으며, 추론 모델과 비추론 모델 간의 명확한 구분이 나타났다.

Conclusion: LLM CHESS는 과적합과 암기를 줄이고, 업데이트가 필요 없는 동적 벤치마크 시스템으로, 추론 및 지시 수행 평가에 대한 미래 연구를 지원하기 위해 실험 프레임워크와 데이터셋을 공개한다.

Abstract: We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [36] [We Still Don't Understand High-Dimensional Bayesian Optimization](https://arxiv.org/abs/2512.00170)
*Colin Doumont,Donney Fan,Natalie Maus,Jacob R. Gardner,Henry Moss,Geoff Pleiss*

Main category: cs.LG

TL;DR: 고차원 공간에서 베이지안 최적화가 도전에 직면하고 있으며, 기존 방법들이 구조적 가정을 최적화 절차에 인코딩하여 이를 극복하려 하지만, 베이지안 선형 회귀가 가장 간단한 방법으로 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 고차원 공간에서 베이지안 최적화의 도전 과제를 해결하고자 하였다.

Method: 경계 추구 행동을 피하기 위해 기하학적 변환을 적용한 후, 선형 커널을 가진 가우시안 프로세스를 사용했다.

Result: 가우시안 프로세스는 60차원에서 6,000차원까지의 검색 공간에서 최첨단 성능을 달성했다.

Conclusion: 우리의 결과는 고차원 공간에서의 베이지안 최적화 방법에 대한 기존 직관에서 벗어날 필요성을 시사한다.

Abstract: High-dimensional spaces have challenged Bayesian optimization (BO). Existing methods aim to overcome this so-called curse of dimensionality by carefully encoding structural assumptions, from locality to sparsity to smoothness, into the optimization procedure. Surprisingly, we demonstrate that these approaches are outperformed by arguably the simplest method imaginable: Bayesian linear regression. After applying a geometric transformation to avoid boundary-seeking behavior, Gaussian processes with linear kernels match state-of-the-art performance on tasks with 60- to 6,000-dimensional search spaces. Linear models offer numerous advantages over their non-parametric counterparts: they afford closed-form sampling and their computation scales linearly with data, a fact we exploit on molecular optimization tasks with > 20,000 observations. Coupled with empirical analyses, our results suggest the need to depart from past intuitions about BO methods in high-dimensional spaces.

</details>


### [37] [A Hierarchical Hybrid AI Approach: Integrating Deep Reinforcement Learning and Scripted Agents in Combat Simulations](https://arxiv.org/abs/2512.00249)
*Scotty Black,Christian Darken*

Main category: cs.LG

TL;DR: 본 연구는 전통적인 규칙 기반 에이전트와 심층 강화 학습 에이전트를 결합한 새로운 계층적 하이브리드 인공지능 접근법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 전투 시뮬레이션에서 규칙 기반 에이전트는 예측 가능성과 일관성을 제공하지만 복잡한 동적 시나리오에서 유연성이 부족하다.

Method: 제안된 접근법은 계층적으로 AI 시스템을 구성하여 일상적인 전술 결정에 스크립트 에이전트를, 보다 높은 수준의 전략적 결정에 RL 에이전트를 활용한다.

Result: 이 통합은 전반적인 성능을 크게 향상시켜 복잡한 시뮬레이션 환경에서 지능형 에이전트를 개발하고 훈련하는 데 효과적인 솔루션을 제공한다.

Conclusion: 이 연구는 각 방법의 한계를 극복하고 개별 강점을 활용함으로써 신뢰할 수 있고 유연한 AI 시스템의 필요성을 강조한다.

Abstract: In the domain of combat simulations in support of wargaming, the development of intelligent agents has predominantly been characterized by rule-based, scripted methodologies with deep reinforcement learning (RL) approaches only recently being introduced. While scripted agents offer predictability and consistency in controlled environments, they fall short in dynamic, complex scenarios due to their inherent inflexibility. Conversely, RL agents excel in adaptability and learning, offering potential improvements in handling unforeseen situations, but suffer from significant challenges such as black-box decision-making processes and scalability issues in larger simulation environments. This paper introduces a novel hierarchical hybrid artificial intelligence (AI) approach that synergizes the reliability and predictability of scripted agents with the dynamic, adaptive learning capabilities of RL. By structuring the AI system hierarchically, the proposed approach aims to utilize scripted agents for routine, tactical-level decisions and RL agents for higher-level, strategic decision-making, thus addressing the limitations of each method while leveraging their individual strengths. This integration is shown to significantly improve overall performance, providing a robust, adaptable, and effective solution for developing and training intelligent agents in complex simulation environments.

</details>


### [38] [BioArc: Discovering Optimal Neural Architectures for Biological Foundation Models](https://arxiv.org/abs/2512.00283)
*Yi Fang,Haoran Xu,Jiaxin Han,Sirui Ding,Yizhi Wang,Yue Wang,Xuan Wang*

Main category: cs.LG

TL;DR: BioArc는 생물학적 기초 모델을 위한 원칙적이고 자동화된 아키텍처 탐색 프레임워크로, 기존 아키텍처의 한계를 극복하고 높은 성능의 아키텍처를 식별합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 기초 모델 아키텍처가 생물학적 데이터의 특성을 충분히 고려하지 않아 성능이 저하되므로, 이를 해결하고자 합니다.

Method: BioArc는 신경 아키텍처 검색(NAS)을 활용하여 생물학적 데이터의 다양한 모달리티에 걸쳐 아키텍처 디자인 공간을 체계적으로 탐색합니다.

Result: 이 분석을 통해 새로운 고성능 아키텍처를 식별하고, 향후 모델 개발을 위한 경험적 디자인 원칙의 집합을 도출합니다.

Conclusion: BioArc는 생물학을 위한 차세대 과제별 및 기초 모델 생성을 위한 기초 자료와 방법론을 제공합니다.

Abstract: Foundation models have revolutionized various fields such as natural language processing (NLP) and computer vision (CV). While efforts have been made to transfer the success of the foundation models in general AI domains to biology, existing works focus on directly adopting the existing foundation model architectures from general machine learning domains without a systematic design considering the unique physicochemical and structural properties of each biological data modality. This leads to suboptimal performance, as these repurposed architectures struggle to capture the long-range dependencies, sparse information, and complex underlying ``grammars'' inherent to biological data. To address this gap, we introduce BioArc, a novel framework designed to move beyond intuition-driven architecture design towards principled, automated architecture discovery for biological foundation models. Leveraging Neural Architecture Search (NAS), BioArc systematically explores a vast architecture design space, evaluating architectures across multiple biological modalities while rigorously analyzing the interplay between architecture, tokenization, and training strategies. This large-scale analysis identifies novel, high-performance architectures, allowing us to distill a set of empirical design principles to guide future model development. Furthermore, to make the best of this set of discovered principled architectures, we propose and compare several architecture prediction methods that effectively and efficiently predict optimal architectures for new biological tasks. Overall, our work provides a foundational resource and a principled methodology to guide the creation of the next generation of task-specific and foundation models for biology.

</details>


### [39] [Adversarial Signed Graph Learning with Differential Privacy](https://arxiv.org/abs/2512.00307)
*Haobin Ke,Sen Zhang,Qingqing Ye,Xun Ran,Haibo Hu*

Main category: cs.LG

TL;DR: 본 연구는 서명 그래프의 개인 정보 보호를 위한 새로운 학습 방법, ASGL을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 서명 그래프의 학습에서 개인 정보 보호 문제를 해결하고자 하는 필요성.

Method: 비교적 높은 유용성을 유지하기 위해 노드 수준의 차등 개인 정보 보호를 달성하는 ASGL 방법을 제안합니다.

Result: ASGL은 여러 하위 작업에서 유리한 개인 정보-유용성 트레이드오프를 달성합니다.

Conclusion: 실제 데이터셋을 바탕으로 한 대규모 실험을 통해 ASGL의 성능을 입증합니다.

Abstract: Signed graphs with positive and negative edges can model complex relationships in social networks. Leveraging on balance theory that deduces edge signs from multi-hop node pairs, signed graph learning can generate node embeddings that preserve both structural and sign information. However, training on sensitive signed graphs raises significant privacy concerns, as model parameters may leak private link information. Existing protection methods with differential privacy (DP) typically rely on edge or gradient perturbation for unsigned graph protection. Yet, they are not well-suited for signed graphs, mainly because edge perturbation tends to cascading errors in edge sign inference under balance theory, while gradient perturbation increases sensitivity due to node interdependence and gradient polarity change caused by sign flips, resulting in larger noise injection. In this paper, motivated by the robustness of adversarial learning to noisy interactions, we present ASGL, a privacy-preserving adversarial signed graph learning method that preserves high utility while achieving node-level DP. We first decompose signed graphs into positive and negative subgraphs based on edge signs, and then design a gradient-perturbed adversarial module to approximate the true signed connectivity distribution. In particular, the gradient perturbation helps mitigate cascading errors, while the subgraph separation facilitates sensitivity reduction. Further, we devise a constrained breadth-first search tree strategy that fuses with balance theory to identify the edge signs between generated node pairs. This strategy also enables gradient decoupling, thereby effectively lowering gradient sensitivity. Extensive experiments on real-world datasets show that ASGL achieves favorable privacy-utility trade-offs across multiple downstream tasks.

</details>


### [40] [Tracing Mathematical Proficiency Through Problem-Solving Processes](https://arxiv.org/abs/2512.00311)
*Jungyang Park,Suho Kang,Jaewoo Park,Jaehong Kim,Jaewoo Shin,Seonjoon Park,Youngjae Yu*

Main category: cs.LG

TL;DR: 본 연구에서는 수학적 숙련도를 다차원적으로 포착하기 위해 학생의 문제 해결 과정을 통합한 지식 추적(KT) 방법론인 KT-PSP를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 지식 추적 방법들은 응답의 정답성에만 의존하여 학생의 문제 해결 과정에서의 정보가 결여된 한계를 가지고 있습니다.

Method: KT-PSP는 학생의 문제해결 과정을 포함하여 다차원적인 수학적 숙련도를 포착하도록 설계되었습니다. 또한, KT-PSP에게 특화된 새로운 데이터셋 KT-PSP-25를 소개하고, StatusKT라는 KT 프레임워크를 제시합니다. StatusKT는 교사-학생-교사 세 단계의 LLM 파이프라인을 사용하여 학생의 수학적 숙련도를 중간 신호로 추출합니다.

Result: KT-PSP-25에 대한 실험 결과는 StatusKT가 기존 KT 방법의 예측 성능을 향상시킴을 보여줍니다.

Conclusion: StatusKT는 학생의 수학적 숙련도를 명시적으로 모델링함으로써 예측에 대한 해석 가능한 설명을 제공합니다.

Abstract: Knowledge Tracing (KT) aims to model student's knowledge state and predict future performance to enable personalized learning in Intelligent Tutoring Systems. However, traditional KT methods face fundamental limitations in explainability, as they rely solely on the response correctness, neglecting the rich information embedded in students' problem-solving processes. To address this gap, we propose Knowledge Tracing Leveraging Problem-Solving Process (KT-PSP), which incorporates students' problem-solving processes to capture the multidimensional aspects of mathematical proficiency. We also introduce KT-PSP-25, a new dataset specifically designed for the KT-PSP. Building on this, we present StatusKT, a KT framework that employs a teacher-student-teacher three-stage LLM pipeline to extract students' MP as intermediate signals. In this pipeline, the teacher LLM first extracts problem-specific proficiency indicators, then a student LLM generates responses based on the student's solution process, and a teacher LLM evaluates these responses to determine mastery of each indicator. The experimental results on KT-PSP-25 demonstrate that StatusKT improves the prediction performance of existing KT methods. Moreover, StatusKT provides interpretable explanations for its predictions by explicitly modeling students' mathematical proficiency.

</details>


### [41] [Adaptive prediction theory combining offline and online learning](https://arxiv.org/abs/2512.00342)
*Haizheng Li,Lei Guo*

Main category: cs.LG

TL;DR: 이 논문은 비선형 확률 동적 시스템에 대한 오프라인 및 온라인 학습을 결합한 두 단계 학습 프레임워크의 예측 성능에 대한 이론적 조사를 시작합니다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 지능형 시스템은 오프라인 학습과 온라인 적응을 결합하여 동작하지만 이론적으로 잘 연구되지 않았습니다.

Method: 오프라인 학습 단계에서 강한 상관관계와 분포 변화가 있는 일반 데이터 세트에 대한 비선형 최소 제곱 추정의 일반화 오류에 대한 상한을 설정하고, 온라인 적응 단계에서는 메타-LMS 예측 알고리즘을 제안합니다.

Result: 이 두 단계 학습 프레임워크는 순수 오프라인 또는 온라인 방법에 비해 우수한 예측 성능을 보여줍니다.

Conclusion: 이 논문은 이론적 보장과 실증 연구를 동시에 제공합니다.

Abstract: Real-world intelligence systems usually operate by combining offline learning and online adaptation with highly correlated and non-stationary system data or signals, which, however, has rarely been investigated theoretically in the literature. This paper initiates a theoretical investigation on the prediction performance of a two-stage learning framework combining offline and online algorithms for a class of nonlinear stochastic dynamical systems. For the offline-learning phase, we establish an upper bound on the generalization error for approximate nonlinear-least-squares estimation under general datasets with strong correlation and distribution shift, leveraging the Kullback-Leibler divergence to quantify the distributional discrepancies. For the online-adaptation phase, we address, on the basis of the offline-trained model, the possible uncertain parameter drift in real-world target systems by proposing a meta-LMS prediction algorithm. This two-stage framework, integrating offline learning with online adaptation, demonstrates superior prediction performances compared with either purely offline or online methods. Both theoretical guarantees and empirical studies are provided.

</details>


### [42] [Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning](https://arxiv.org/abs/2512.00351)
*Na Li,Yuchen Jiao,Hangguan Shan,Shefeng Yan*

Main category: cs.LG

TL;DR: 이 논문은 두 선수의 영-zero-sum Markov 게임을 위한 메모리 효율적인 내시 Q-학습 알고리즘 ME-Nash-QL을 설계하여 다중 에이전트 강화 학습의 문제를 해결하려고 합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습(MARL) 분야는 상호작용하는 에이전트들이 어떻게 자율적으로 의사 결정을 내리는지 연구합니다. 그러나 기존 이론적 연구들은 메모리 비효율성, 높은 샘플 복잡도 의존성, 높은 계산 복잡도 등 여러 문제로 어려움을 겪고 있습니다.

Method: 본 연구에서는 두 선수의 영-zero-sum Markov 게임을 위한 모델 자유 Self-play 알고리즘인 ME-Nash-QL을 설계합니다. 이 알고리즘은 메모리 효율성과 샘플 복잡도의 개선을 목표로 합니다.

Result: ME-Nash-QL은 Nash 정책을 약 $	ext{O}(SABH)$의 공간 복잡도와 $	ilde{	ext{O}}(H^4SAB/	ext{ε}^2)$의 샘플 복잡도로 출력할 수 있으며, 기존 알고리즘보다 공간 복잡도와 샘플 복잡도에서 우수성을 보입니다.

Conclusion: ME-Nash-QL은 낮은 계산 복잡도를 유지하면서 Markov 정책을 보존하며, 기존 알고리즘보다 더 나은 성능을 보이는 것을 증명합니다.

Abstract: The thriving field of multi-agent reinforcement learning (MARL) studies how a group of interacting agents make decisions autonomously in a shared dynamic environment. Existing theoretical studies in this area suffer from at least two of the following obstacles: memory inefficiency, the heavy dependence of sample complexity on the long horizon and the large state space, the high computational complexity, non-Markov policy, non-Nash policy, and high burn-in cost. In this work, we take a step towards settling this problem by designing a model-free self-play algorithm \emph{Memory-Efficient Nash Q-Learning (ME-Nash-QL)} for two-player zero-sum Markov games, which is a specific setting of MARL. ME-Nash-QL is proven to enjoy the following merits. First, it can output an $\varepsilon$-approximate Nash policy with space complexity $O(SABH)$ and sample complexity $\widetilde{O}(H^4SAB/\varepsilon^2)$, where $S$ is the number of states, $\{A, B\}$ is the number of actions for two players, and $H$ is the horizon length. It outperforms existing algorithms in terms of space complexity for tabular cases, and in terms of sample complexity for long horizons, i.e., when $\min\{A, B\}\ll H^2$. Second, ME-Nash-QL achieves the lowest computational complexity $O(T\mathrm{poly}(AB))$ while preserving Markov policies, where $T$ is the number of samples. Third, ME-Nash-QL also achieves the best burn-in cost $O(SAB\,\mathrm{poly}(H))$, whereas previous algorithms have a burn-in cost of at least $O(S^3 AB\,\mathrm{poly}(H))$ to attain the same level of sample complexity with ours.

</details>


### [43] [Sample-Efficient Tabular Self-Play for Offline Robust Reinforcement Learning](https://arxiv.org/abs/2512.00352)
*Na Li,Zewu Zheng,Wei Ni,Hangguan Shan,Wenjie Zhang,Xinyu Li*

Main category: cs.LG

TL;DR: 이 논문에서는 Robust Two-player Zero-sum Markov Games (RTZMGs)에서의 오프라인 설정을 다루며, 새로운 모델 기반 알고리즘 RTZ-VI-LCB를 제안하여 샘플 복잡도를 최적화합니다.


<details>
  <summary>Details</summary>
Motivation: MARL 분야의 환경 불확실성에 대응하기 위한 강인한 정책을 개발하는 것이 중요하다.

Method: 우리는 오프라인 RTZMGs에 대한 모델 기반 알고리즘 RTZ-VI-LCB를 제안하며, 이는 강인한 가치 추정을 위한 데이터 기반의 벌점 항을 포함한 낙관적인 강인 가치 반복을 결합합니다.

Result: 제안된 알고리즘은 부분 커버리지 및 환경 불확실성 하에서 근접 최적의 샘플 복잡도 보장을 수립합니다.

Conclusion: RTZ-VI-LCB는 최적성을 달성한 최초의 알고리즘으로, 오프라인 RTZMGs의 새로운 기준을 세우고 실험적으로 검증되었습니다.

Abstract: Multi-agent reinforcement learning (MARL), as a thriving field, explores how multiple agents independently make decisions in a shared dynamic environment. Due to environmental uncertainties, policies in MARL must remain robust to tackle the sim-to-real gap. We focus on robust two-player zero-sum Markov games (TZMGs) in offline settings, specifically on tabular robust TZMGs (RTZMGs). We propose a model-based algorithm (\textit{RTZ-VI-LCB}) for offline RTZMGs, which is optimistic robust value iteration combined with a data-driven Bernstein-style penalty term for robust value estimation. By accounting for distribution shifts in the historical dataset, the proposed algorithm establishes near-optimal sample complexity guarantees under partial coverage and environmental uncertainty. An information-theoretic lower bound is developed to confirm the tightness of our algorithm's sample complexity, which is optimal regarding both state and action spaces. To the best of our knowledge, RTZ-VI-LCB is the first to attain this optimality, sets a new benchmark for offline RTZMGs, and is validated experimentally.

</details>


### [44] [An Empirical Study on the Effectiveness of Incorporating Offline RL As Online RL Subroutines](https://arxiv.org/abs/2512.00383)
*Jianhai Su,Jinzhu Luo,Qi Zhang*

Main category: cs.LG

TL;DR: 오프라인 RL 알고리즘을 온라인 RL의 하위 프로세스로 통합하는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 RL 알고리즘을 온라인 RL에 통합함으로써 온라인 학습 에이전트가 과거 상호작용을 오프라인 데이터셋으로 재사용할 수 있도록 하는 것이다.

Method: 오프라인 RL 통합의 여러 변형을 수용하는 프레임워크를 정형화하고, 효과성을 높이기 위한 удобные 기술을 도입한다.

Result: 제안된 프레임워크의 효과는 작업의 성격에 크게 의존하며, 제안된 기술이 효과성을 크게 향상시키고, 기존의 온라인 미세 조정 방법이 전반적으로 비효율적임을 보여준다.

Conclusion: 더 많은 연구가 필요하다는 것을 시사한다.

Abstract: We take the novel perspective of incorporating offline RL algorithms as subroutines of tabula rasa online RL. This is feasible because an online learning agent can repurpose its historical interactions as offline dataset. We formalize this idea into a framework that accommodates several variants of offline RL incorporation such as final policy recommendation and online fine-tuning. We further introduce convenient techniques to improve its effectiveness in enhancing online learning efficiency. Our extensive and systematic empirical analyses show that 1) the effectiveness of the proposed framework depends strongly on the nature of the task, 2) our proposed techniques greatly enhance its effectiveness, and 3) existing online fine-tuning methods are overall ineffective, calling for more research therein.

</details>


### [45] [SelfAI: Building a Self-Training AI System with LLM Agents](https://arxiv.org/abs/2512.00403)
*Xiao Wu,Ting-Zhu Huang,Liang-Jian Deng,Xiaobing Yu,Yu Zhong,Shangqi Deng,Ufaq Khan,Jianghao Wu,Xiaofeng Liu,Imran Razzak,Xiaojun Chang,Yutong Xie*

Main category: cs.LG

TL;DR: SelfAI는 연구 목적을 표준화된 실험 구성으로 변환하고, 최적 중단 기준을 가진 인지 에이전트를 통해 하이퍼파라미터 검색을 반복적으로 개선하며, 이질적인 하드웨어에서 병렬 및 내결함성 훈련 워크플로를 조율하여 발견 효율성과 검색 다양성을 정량화하는 새로운 평가 메트릭을 도입한 다중 에이전트 플랫폼이다.


<details>
  <summary>Details</summary>
Motivation: 자동화 과학 발견 분야에서 LLM 기반 에이전트를 활용한 연구가 증가하고 있지만, 기존 프레임워크는 좁은 적용 분야에 제한되고, 연구자와의 실시간 상호작용이 제한적이며 탐색 중단 기준이 부족하여 비효율성과 재현성 문제를 초래하고 있다.

Method: SelfAI는 고수준 연구 목표를 표준화된 실험 구성으로 변환하는 사용자 에이전트, LLM으로 구동되어 최적 중단 기준으로 하이퍼파라미터 검색을 반복적으로 개선하는 인지 에이전트, 병렬 및 내결함성을 갖춘 훈련 워크플로를 조율하고 지속적인 피드백을 위한 구조화된 지식 기반을 유지하는 실험 관리자로 구성된 다중 에이전트 플랫폼이다.

Result: SelfAI는 회귀, 자연어 처리, 컴퓨터 비전, 과학적 컴퓨팅, 의료 영상 및 약물 발견 벤치마크에서 강력한 성능을 지속적으로 성취하며, 고전적 베이지안 최적화 및 LLM 기반 기초선과 비교하여 중복 실험을 줄이는 동시에 인간 연구자와의 원활한 상호작용을 가능하게 한다.

Conclusion: SelfAI는 다양한 분야에서 효율적인 발견을 지원하며 연구자와의 통합 작동을 통해 연구의 질을 향상시킨다.

Abstract: Recent work on autonomous scientific discovery has leveraged LLM-based agents to integrate problem specification, experiment planning, and execution into end-to-end systems. However, these frameworks are often confined to narrow application domains, offer limited real-time interaction with researchers, and lack principled mechanisms for determining when to halt exploration, resulting in inefficiencies, reproducibility challenges, and under-utilized human expertise. To address these gaps, we propose \textit{SelfAI}, a general multi-agent platform that combines a User Agent for translating high-level research objectives into standardized experimental configurations, a Cognitive Agent powered by LLMs with optimal stopping criteria to iteratively refine hyperparameter searches, and an Experiment Manager responsible for orchestrating parallel, fault-tolerant training workflows across heterogeneous hardware while maintaining a structured knowledge base for continuous feedback. We further introduce two novel evaluation metrics, Score and $\text{AUP}_D$, to quantify discovery efficiency and search diversity. Across regression, NLP, computer vision, scientific computing, medical imaging, and drug discovery benchmarks, SelfAI consistently achieves strong performance and reduces redundant trials compared to classical Bayesian optimization and LLM-based baselines, while enabling seamless interaction with human researchers.

</details>


### [46] [Rep3Net: An Approach Exploiting Multimodal Representation for Molecular Bioactivity Prediction](https://arxiv.org/abs/2512.00521)
*Sabrina Islam,Md. Atiqur Rahman,Md. Bakhtiar Hasan,Md. Hasanul Kabir*

Main category: cs.LG

TL;DR: Rep3Net는 그래프 기반 표현과 ChemBERTa 임베딩을 결합하여 예상 생물활성을 예측하는 신뢰할 수 있는 모델입니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 QSAR 모델은 화합물의 구조적 및 맥락적 정보를 포착하는 데 한계가 있어 생물활성 예측에 어려움을 겪고 있습니다.

Method: Rep3Net은 분자 기술 기반 데이터와 함께 화합물의 그래프 기반 표현 및 SMILES 문자열로부터 생성된 ChemBERTa 임베딩을 포함하는 통합 딥러닝 아키텍처입니다.

Result: 우리 모델은 Poly [ADP-ribose] polymerase 1(PARP-1) 데이터셋에 대해 신뢰할 수 있는 생물활성 예측을 수행했습니다.

Conclusion: 제안된 아키텍처는 기존의 독립형 모델들과 비교했을 때 최고 예측 성능을 달성하며, 약물 발견에서 생물활성 예측을 위한 확장 가능한 프레임워크를 제공합니다.

Abstract: In early stage drug discovery, bioactivity prediction of molecules against target proteins plays a crucial role. Trdaitional QSAR models that utilizes molecular descriptor based data often struggles to predict bioactivity of molecules effectively due to its limitation in capturing structural and contextual information embedded within each compound. To address this challenge, we propose Rep3Net, a unified deep learning architecture that not only incorporates descriptor data but also includes spatial and relational information through graph-based represenation of compounds and contextual information through ChemBERTa generated embeddings from SMILES strings. Our model employing multimodal concatenated features produce reliable bioactivity prediction on Poly [ADP-ribose] polymerase 1 (PARP-1) dataset. PARP-1 is a crucial agent in DNA damage repair and has become a significant theraputic target in malignancies that depend on it for survival and growth. A comprehensive analysis and comparison with conventional standalone models including GCN, GAT, XGBoost, etc. demonstrates that our architecture achieves the highest predictive performance. In computational screening of compounds in drug discovery, our architecture provides a scalable framework for bioactivity prediction.

</details>


### [47] [A Graph Neural Network Approach for Localized and High-Resolution Temperature Forecasting](https://arxiv.org/abs/2512.00546)
*Joud El-Shawa,Elham Bagheri,Sedef Akinli Kocak,Yalda Mohsenzadeh*

Main category: cs.LG

TL;DR: 기후 변화와 도시 열섬 효과로 인해, 고온 현상이 심화되고 있으며, 이는 주로 취약계층에 큰 영향을 미칩니다. 본 연구에서는 그래프 신경망 프레임워크를 이용하여 48시간의 고해상도 온도 예측을 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: 고온 현상이 전 세계적으로 심화되고 있으며, 이는 자원 부족 지역과 글로벌 남반부에 특히 큰 영향을 미칩니다. 기존의 기상 예측 모델은 미세한 극단적인 기온 변화를 포착하지 못해 가장 취약한 계층이 조기 경고로부터 배제되고 있습니다.

Method: 우리는 그래프 신경망을 이용한 로컬화된 고해상도 온도 예측 프레임워크를 제시합니다. 공간 학습과 효율적인 계산을 활용하여 48시간까지의 예측을 생성합니다.

Result: 캐나다 온타리오주 서남부에 대한 모델은 1-48시간 예측에서 평균 MAE가 1.93℃, 48시간 예측에서 MAE가 2.93℃를 기록하며, 가장 큰 지역에서 24시간 입력 창을 사용하여 평가되었습니다.

Conclusion: 이 작업은 데이터가 부족한 지역에서도 공정한 지역 예측을 가능하게 하는 전이 학습 접근법을 위한 기반을 마련합니다.

Abstract: Heatwaves are intensifying worldwide and are among the deadliest weather disasters. The burden falls disproportionately on marginalized populations and the Global South, where under-resourced health systems, exposure to urban heat islands, and the lack of adaptive infrastructure amplify risks. Yet current numerical weather prediction models often fail to capture micro-scale extremes, leaving the most vulnerable excluded from timely early warnings. We present a Graph Neural Network framework for localized, high-resolution temperature forecasting. By leveraging spatial learning and efficient computation, our approach generates forecasts at multiple horizons, up to 48 hours. For Southwestern Ontario, Canada, the model captures temperature patterns with a mean MAE of 1.93$^{\circ}$C across 1-48h forecasts and MAE@48h of 2.93$^{\circ}$C, evaluated using 24h input windows on the largest region. While demonstrated here in a data-rich context, this work lays the foundation for transfer learning approaches that could enable localized, equitable forecasts in data-limited regions of the Global South.

</details>


### [48] [Statistical NLP for Optimization of Clinical Trial Success Prediction in Pharmaceutical R&D](https://arxiv.org/abs/2512.00586)
*Michael R. Doane*

Main category: cs.LG

TL;DR: 본 연구는 신경과학 분야의 임상 시험을 위한 기술 및 규제 성공 확률(pTRS)을 추정하기 위해 설계된 NLP 기반 확률 분류기의 개발과 평가를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 제약 연구개발은 높은 중단률과 막대한 비용으로 어려움을 겪고 있으며, 특히 신경과학 분야에서는 성공률이 10% 미만이다. 따라서 유망한 프로그램을 조기에 식별하는 것이 자원 배분을 효율화하고 재정적 리스크를 줄일 수 있다.

Method: ClinicalTrials.gov 데이터베이스의 데이터를 활용하고 최근 개발된 임상 시험 결과 데이터셋의 성공 라벨을 사용하여, 분류기는 통계적 NLP 기법을 통해 텍스트 기반의 임상 시험 특징을 추출하였다. 이러한 특징은 로지스틱 회귀, 그래디언트 부스팅, 랜덤 포레스트와 같은 여러 비LLM 프레임워크에 통합되어 보정된 확률 점수를 생성하였다.

Result: 1976-2024년을 포함하는 101,145개의 완료된 임상 시험의 회고적 데이터셋에서 모델 성능이 평가되었고, ROC-AUC 0.64를 달성하였다. 이어서 BioBERT를 사용한 LLM 기반 예측 모델이 구축되었으며, 이 모델은 전체 ROC-AUC 0.74와 Brier Score 0.185를 기록하며 산업 벤치마크에 비해 평균 40% 적은 제곱오차를 보였다.

Conclusion: BioBERT 기반 모델은 전체적으로 벤치마크 값을 초과하는 시험 결과 예측을 70%의 확률로 제공하였다. 이 연구는 NLP 기반 통찰력을 약물 개발 의사 결정에 통합하여 신경과학 프로그램의 전략적 계획 및 투자 배분을 최적화하고자 한다.

Abstract: This work presents the development and evaluation of an NLP-enabled probabilistic classifier designed to estimate the probability of technical and regulatory success (pTRS) for clinical trials in the field of neuroscience. While pharmaceutical R&D is plagued by high attrition rates and enormous costs, particularly within neuroscience, where success rates are below 10%, timely identification of promising programs can streamline resource allocation and reduce financial risk. Leveraging data from the ClinicalTrials.gov database and success labels from the recently developed Clinical Trial Outcome dataset, the classifier extracts text-based clinical trial features using statistical NLP techniques. These features were integrated into several non-LLM frameworks (logistic regression, gradient boosting, and random forest) to generate calibrated probability scores. Model performance was assessed on a retrospective dataset of 101,145 completed clinical trials spanning 1976-2024, achieving an overall ROC-AUC of 0.64. An LLM-based predictive model was then built using BioBERT, a domain-specific language representation encoder. The BioBERT-based model achieved an overall ROC-AUC of 0.74 and a Brier Score of 0.185, indicating its predictions had, on average, 40% less squared error than would be observed using industry benchmarks. The BioBERT-based model also made trial outcome predictions that were superior to benchmark values 70% of the time overall. By integrating NLP-driven insights into drug development decision-making, this work aims to enhance strategic planning and optimize investment allocation in neuroscience programs.

</details>


### [49] [Efficient Matroid Bandit Linear Optimization Leveraging Unimodality](https://arxiv.org/abs/2512.00605)
*Aurélien Delage,Romaric Gaudel*

Main category: cs.LG

TL;DR: 본 논문은 매트로이드 제약 하의 조합론적 반밴딧 문제를 다룬다. 새로운 기법을 통해 회원 오라클의 호출 횟수를 줄이고 전체 학습 과정의 시간 복잡성을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: 최근 접근방식이 최적의 후회를 달성했지만, 대규모 매트로이드나 비용이 많이 드는 회원 오라클이 있는 경우 시간 복잡성이 문제로 남아있다.

Method: 매트로이드 반밴딧 문제의 본질적인 단봉 구조를 활용하여 회원 오라클을 포함하는 반복 횟수를 \\mathcal{O}(	ext{log log } T)로 제한하는 기법을 제시한다.

Result: 다양한 매트로이드 벤치마크에서 실험을 수행했으며, 최신 기법과 비교하여 후회는 동일하고, 시간 복잡성이 감소하며 회원 오라클 호출 횟수가 줄어든 것을 보였다.

Conclusion: 이 연구는 매트로이드 반밴딧 문제의 시간 복잡성을 크게 개선할 수 있음을 보여준다.

Abstract: We study the combinatorial semi-bandit problem under matroid constraints. The regret achieved by recent approaches is optimal, in the sense that it matches the lower bound. Yet, time complexity remains an issue for large matroids or for matroids with costly membership oracles (e.g. online recommendation that ensures diversity). This paper sheds a new light on the matroid semi-bandit problem by exploiting its underlying unimodal structure. We demonstrate that, with negligible loss in regret, the number of iterations involving the membership oracle can be limited to \mathcal{O}(\log \log T)$. This results in an overall improved time complexity of the learning process. Experiments conducted on various matroid benchmarks show (i) no loss in regret compared to state-of-the-art approaches; and (ii) reduced time complexity and number of calls to the membership oracle.

</details>


### [50] [ML-Tool-Bench: Tool-Augmented Planning for ML Tasks](https://arxiv.org/abs/2512.00672)
*Yaswanth Chittepu,Raghavendra Addanki,Tung Mai,Anup Rao,Branislav Kveton*

Main category: cs.LG

TL;DR: 자동화된 기계 학습 에이전트를 위한 종합 벤치마크를 제안하여 도구 사용 기능을 평가하고, 기존의 접근 방식의 한계를 극복하는 방법을 모색한다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 기계 학습 에이전트 개발은 데이터 과학 워크플로우를 통합하는 중요한 과제이다.

Method: 61개의 전문 도구와 15개의 Kaggle 데이터 ML 도전을 포함한 종합 벤치마크를 구축하고, 두 가지 개선 접근 방식을 제안한다.

Result: 제안된 방법은 ReAct 방식보다 16.52 퍼센타일 향상되었다.

Conclusion: 이 연구는 도구 지원 계획 기계 학습 에이전트 개발의 기초를 제공한다.

Abstract: The development of autonomous machine learning (ML) agents capable of end-to-end data science workflows represents a significant frontier in artificial intelligence. These agents must orchestrate complex sequences of data analysis, feature engineering, model selection, and hyperparameter optimization, tasks that require sophisticated planning and iteration. While recent work on building ML agents has explored using large language models (LLMs) for direct code generation, tool-augmented approaches offer greater modularity and reliability. However, existing tool-use benchmarks focus primarily on task-specific tool selection or argument extraction for tool invocation, failing to evaluate the sophisticated planning capabilities required for ML Agents. In this work, we introduce a comprehensive benchmark for evaluating tool-augmented ML agents using a curated set of 61 specialized tools and 15 tabular ML challenges from Kaggle. Our benchmark goes beyond traditional tool-use evaluation by incorporating an in-memory named object management, allowing agents to flexibly name, save, and retrieve intermediate results throughout the workflows. We demonstrate that standard ReAct-style approaches struggle to generate valid tool sequences for complex ML pipelines, and that tree search methods with LLM-based evaluation underperform due to inconsistent state scoring. To address these limitations, we propose two simple approaches: 1) using shaped deterministic rewards with structured textual feedback, and 2) decomposing the original problem into a sequence of sub-tasks, which significantly improves trajectory validity and task performance. Using GPT-4o, our approach improves over ReAct by 16.52 percentile positions, taking the median across all Kaggle challenges. We believe our work provides a foundation for developing more capable tool-augmented planning ML agents.

</details>


### [51] [Upcycled and Merged MoE Reward Model for Mitigating Reward Hacking](https://arxiv.org/abs/2512.00724)
*Lingling Fu*

Main category: cs.LG

TL;DR: 이 논문은 RLHF에서 보상 모델의 효율성과 강건성을 개선하기 위한 새로운 MoE 보상 모델 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 보상 모델은 보상 해킹과 과도한 최적화의 문제를 가지며, 이는 인간 선호를 반영하지 않는 높은 보상 점수를 얻기 위해 패턴을 악용하는 경향이 있다.

Method: Dense 보상 모델을 MoE 아키텍처로 업사이클링하고, 전반적인 지식을 포착하는 공유 전문가와 특정 패턴을 전문으로 하는 일반 전문가를 활용한다. 이후 라우팅 가중치 정규화 및 학습 가능한 가중치 평균화 메커니즘을 통해 전문가를 밀집 모델로 병합한다.

Result: 실험 결과, 이 방법이 다양한 모델 규모에서 보상 해킹을 효과적으로 완화함을 보여준다.

Conclusion: 우리의 연구는 RLHF 보상 모델의 강건성과 효율성을 개선하기 위한 업사이클링 및 병합 MoE 구조의 가능성을 강조한다.

Abstract: Reward models play a critical role in Reinforcement Learning from Human Feedback (RLHF) by assessing the consistency between generated outputs and human preferences. However, conventional reward models are prone to reward hacking or over-optimization, where the policy exploits shortcut patterns to obtain high reward scores that do not reflect true human preference. Although Mixture-of-Experts (MoE)-based reward models can enhance discriminative capability, they typically introduce substantial computational overhead. To address these challenges, we propose an upcycle and merge MoE reward modeling approach. We first upcycle a dense reward model into a MoE architecture, where a shared expert captures general knowledge, while normal experts specialize in instruction-specific patterns. We then apply routing-weight normalization and merge experts back into a dense model through a learnable weight-averaging mechanism, preserving performance gains while significantly reducing inference cost. Experimental results demonstrate that our method effectively mitigates reward hacking across various model scales. Our work highlights the potential of upcycle and merge MoE structures for improving both robustness and efficiency of RLHF reward models.

</details>


### [52] [AI Agent for Source Finding by SoFiA-2 for SKA-SDC2](https://arxiv.org/abs/2512.00769)
*Xingchen Zhou,Nan Li,Peng Jia,Yingfeng Liu,Furen Deng,Shuanghao Shu,Ying Li,Liang Cao,Huanyuan Shan,Ayodeji Ibitoye*

Main category: cs.LG

TL;DR: 이 논문은 소스 추출을 위한 자동 최적화 프레임워크를 제안하며, 다음 세대 대규모 스카이 서베이에 필요한 파라미터 구성을 개선하는 방법을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 다음 세대 대규모 스카이 서베이에서 수신한 데이터를 효과적으로 분석하기 위해 소스 추출 최적화의 필요성이 커지고 있다.

Method: AI 에이전트를 활용하여 최신 강화 학습 알고리즘인 Soft Actor-Critic(SAC)을 기반으로 파라미터를 자동으로 최적화하는 프레임워크를 제안한다.

Result: 이 프레임워크는 SKA 과학 데이터 챌린지 2(SDC2) 데이터셋을 사용하여 검증하였으며, 팀 SoFiA에 의해 설정된 기준을 초과하는 최적의 파라미터 구성을 100회 평가 단계 내에 자동으로 식별할 수 있다.

Conclusion: 제안한 방법은 라디오 대역 서베이 및 소스 추출을 넘어 복잡한 파라미터 조정이 필요한 유사한 문제를 해결할 수 있는 가능성을 제시한다.

Abstract: Source extraction is crucial in analyzing data from next-generation, large-scale sky surveys in radio bands, such as the Square Kilometre Array (SKA). Several source extraction programs, including SoFiA and Aegean, have been developed to address this challenge. However, finding optimal parameter configurations when applying these programs to real observations is non-trivial. For example, the outcomes of SoFiA intensely depend on several key parameters across its preconditioning, source-finding, and reliability-filtering modules. To address this issue, we propose a framework to automatically optimize these parameters using an AI agent based on a state-of-the-art reinforcement learning (RL) algorithm, i.e., Soft Actor-Critic (SAC). The SKA Science Data Challenge 2 (SDC2) dataset is utilized to assess the feasibility and reliability of this framework. The AI agent interacts with the environment by adjusting parameters based on the feedback from the SDC2 score defined by the SDC2 Team, progressively learning to select parameter sets that yield improved performance. After sufficient training, the AI agent can automatically identify an optimal parameter configuration that outperform the benchmark set by Team SoFiA within only 100 evaluation steps and with reduced time consumption. Our approach could address similar problems requiring complex parameter tuning, beyond radio band surveys and source extraction. Yet, high-quality training sets containing representative observations and catalogs of ground truth are essential.

</details>


### [53] [ReJump: A Tree-Jump Representation for Analyzing and Improving LLM Reasoning](https://arxiv.org/abs/2512.00831)
*Yuchen Zeng,Shuibai Zhang,Wonjun Kang,Shutong Wu,Lynnix Zou,Ying Fan,Heeju Kim,Ziqian Lin,Jungtaek Kim,Hyung Il Koo,Dimitris Papailiopoulos,Kangwook Lee*

Main category: cs.LG

TL;DR: ReJump라는 새로운 도구를 사용해 대형 언어 모델의 추론 과정을 분석하고, 이 모델들이 어떻게 서로 다른 추론 행동을 보이는지를 평가한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델은 수학과 프로그래밍 등 어려운 작업에서 인상적인 성과를 내고 있지만, 그들의 추론 알고리즘은 아직 잘 이해되지 않았다.

Method: ReJump를 통해 문제 해결 단계의 중간 노드를 방문하는 순서로 추론 흔적을 나타내고, 노드 간의 전환을 jumps로 정의하여 다양한 행동을 포착한다.

Result: 유사한 정확도를 가진 모델이 뚜렷한 추론 행동 차이를 보이며, 서로 다른 작업이 서로 다른 추론 스타일을 선호함을 발견했다.

Conclusion: ReJump는 추론 품질을 향상시킬 수 있는 여러 가지 전략을 사용 가능하며, 코드는 공개적으로 제공된다.

Abstract: Large Reasoning Models (LRMs) are Large Language Models (LLMs) explicitly trained to generate long-form Chain-of-Thoughts (CoTs), achieving impressive success on challenging tasks like math and programming. However, their underlying reasoning "algorithms" remain poorly understood. To investigate this, we propose ReJump, which represents a reasoning trace as a visitation order over nodes in a tree of intermediate problem-solving steps. Transitions between nodes, which we term jumps, include adjacent moves that capture behaviors such as calculation, and non-adjacent moves that capture behaviors such as backtracking and verification. ReJump enables analyzing LLM reasoning with diverse metrics that quantify exploration, exploitation, overthinking, forgetting, and verification. Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying balance between exploration and exploitation). To further understand how learning strategies shape reasoning, we use ReJump to compare distilled LRMs with their teachers, CoT-prompted LLMs with LRMs, and to examine how the number of reasoning examples and reinforcement learning affect reasoning behavior. Finally, we show that ReJump can improve reasoning quality at test time through strategies such as ReJump-guided Best-of-N selection and prompt selection. Our code is publicly available at https://github.com/UW-Madison-Lee-Lab/ReJump.

</details>


### [54] [Prediction-space knowledge markets for communication-efficient federated learning on multimedia tasks](https://arxiv.org/abs/2512.00841)
*Wenzhang Du*

Main category: cs.LG

TL;DR: KTA v2는 분산 멀티미디어 데이터에서의 연합 학습을 위한 개선된 모델로, 비독립 및 동등하게 분포되지 않은 데이터에서의 통신 문제를 해결하며 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 연합 학습 방법은 비독립 동등 분포 데이터에서의 성능 저하와 통신 제약 문제를 해결해야 한다.

Method: KTA v2는 클라이언트가 개인 데이터를 기반으로 로컬 학습을 수행하고, 작은 공용 참조 세트에 대한 로짓만 공유하여 유사성 그래프를 구축하는 두 단계의 절차를 통해 이를 해결한다.

Result: KTA v2는 FEMNIST, CIFAR-10, AG News에 대한 실험에서 저비용 통신 예산 하에서도 강력한 성능을 보여주며 전통적인 방법보다 우수하다.

Conclusion: KTA v2는 비독립 동등 분포 데이터 환경에서 연합 학습의 효율성과 정확성을 크게 향상시킨다.

Abstract: Federated learning (FL) enables collaborative training over distributed multimedia data but suffers acutely from statistical heterogeneity and communication constraints, especially when clients deploy large models. Classic parameter-averaging methods such as FedAvg transmit full model weights and can diverge under nonindependent and identically distributed (non-IID) data. We propose KTA v2, a prediction-space knowledge trading market for FL. Each round, clients locally train on their private data, then share only logits on a small public reference set. The server constructs a client-client similarity graph in prediction space, combines it with reference-set accuracy to form per-client teacher ensembles, and sends back personalized soft targets for a second-stage distillation update. This two-stage procedure can be interpreted as approximate block-coordinate descent on a unified objective with prediction-space regularization. Experiments on FEMNIST, CIFAR-10 and AG News show that, under comparable or much lower communication budgets, KTA v2 consistently outperforms a local-only baseline and strong parameter-based methods (FedAvg, FedProx), and substantially improves over a FedMD-style global teacher. On CIFAR-10 with ResNet-18, KTA v2 reaches 57.7% test accuracy using approximately 1/1100 of FedAvg's communication, while on AG News it attains 89.3% accuracy with approximately 1/300 of FedAvg's traffic.

</details>


### [55] [City-Conditioned Memory for Multi-City Traffic and Mobility Forecasting](https://arxiv.org/abs/2512.00851)
*Wenzhang Du*

Main category: cs.LG

TL;DR: CityCond라는 경량 도시 표기 메모리 레이어를 제안하여, 다양한 도시에서의 교통 예측 모델의 효율성을 극대화한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 도시에서의 공간-시간 예측 모델 배포의 어려움으로 인해 기존의 모델들이 각각 도시별로 별도 훈련되며, 이는 높은 유지 비용과 데이터가 부족한 도시로의 전이 성능 저하를 초래한다.

Method: CityCond는 도시-ID 인코더와 선택적 공유 메모리 뱅크(CityMem)를 결합하여, 도시 인덱스와 backbone 숨겨진 상태에 따라 도시 조건의 특징을 생성한다.

Result: 14개 이상의 모델 변형과 3개의 랜덤 시드에서 CityCond는 일관된 개선 효과를 나타내며, 특히 고용량 백본에서는 현저한 성과를 낸다.

Conclusion: CityCond는 현실적인 데이터 제약 하에서 확장 가능한 다중 도시 예측을 위한 재사용 가능한 디자인 패턴으로 활용될 수 있다.

Abstract: Deploying spatio-temporal forecasting models across many cities is difficult: traffic networks differ in size and topology, data availability can vary by orders of magnitude, and new cities may provide only a short history of logs. Existing deep traffic models are typically trained per city and backbone, creating high maintenance cost and poor transfer to data-scarce cities. We ask whether a single, backbone-agnostic layer can condition on "which city this sequence comes from", improve accuracy in full- and low-data regimes, and support better cross-city adaptation with minimal code changes.
  We propose CityCond, a light-weight city-conditioned memory layer that augments existing spatio-temporal backbones. CityCond combines a city-ID encoder with an optional shared memory bank (CityMem). Given a city index and backbone hidden states, it produces city-conditioned features fused through gated residual connections. We attach CityCond to five representative backbones (GRU, TCN, Transformer, GNN, STGCN) and evaluate three regimes: full-data, low-data, and cross-city few-shot transfer on METR-LA and PEMS-BAY. We also run auxiliary experiments on SIND, a drone-based multi-agent trajectory dataset from a signalized intersection in Tianjin (we focus on pedestrian tracks).
  Across more than fourteen model variants and three random seeds, CityCond yields consistent improvements, with the largest gains for high-capacity backbones such as Transformers and STGCNs. CityMem reduces Transformer error by roughly one third in full-data settings and brings substantial gains in low-data and cross-city transfer. On SIND, simple city-ID conditioning modestly improves low-data LSTM performance. CityCond can therefore serve as a reusable design pattern for scalable, multi-city forecasting under realistic data constraints.

</details>


### [56] [HBLLM: Wavelet-Enhanced High-Fidelity 1-Bit Quantization for LLMs](https://arxiv.org/abs/2512.00862)
*Ningning Chen,Weicai Ye,Ying Jiang*

Main category: cs.LG

TL;DR: 이 논문은 대형 언어 모델을 위한 파장 강화 고충실도 1비트 후행량자화 방법 HBLLM을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 양자화 정확도를 개선하면서도 최소한의 오버헤드를 유지하려는 필요성.

Method: Haar 웨이블릿 변환을 활용하여 주파수 분해를 통해 표현 능력을 향상시키고, 두 가지 구조 인식 그룹화 전략을 도입: 주파수 인식 다중 매개변수 행 그룹화 및 $	ext{ℓ}_2$-노름 기반의 주목도 기반 열 선택이다.

Result: OPT 및 LLaMA 모델에 대한 실험에서 HBLLM은 1비트 양자화에서 최첨단 성능을 달성하며, LLaMA2-13B에서 6.71의 당혹도를 기록하고 평균 가중치 저장량은 1.08 비트에 불과하다.

Conclusion: 이 접근 방식은 대형 언어 모델의 양자화 정확도를 크게 향상시키면서 저장 효율성을 최적화하였다.

Abstract: We introduce HBLLM, a wavelet-enhanced high-fidelity $1$-bit post-training quantization method for Large Language Models (LLMs). By leveraging Haar wavelet transforms to enhance expressive capacity through frequency decomposition, HBLLM significantly improves quantization fidelity while maintaining minimal overhead. This approach features two innovative structure-aware grouping strategies: (1) frequency-aware multi-parameter intra-row grouping and (2) $\ell_2$-norm-based saliency-driven column selection. For non-salient weights, a shared mean is employed across quantization groups within each frequency band to optimize storage efficiency. Experiments conducted on the OPT and LLaMA models demonstrate that HBLLM achieves state-of-the-art performance in $1$-bit quantization, attaining a perplexity of $6.71$ on LLaMA$2$-$13$B with an average weight storage of only $1.08$ bits. Code available at: https://github.com/Yeyke/HBLLM.

</details>


### [57] [Memory-Integrated Reconfigurable Adapters: A Unified Framework for Settings with Multiple Tasks](https://arxiv.org/abs/2512.00940)
*Susmit Agrawal,Krishn Vishwas Kher,Saksham Mittal,Swarnim Maheshwari,Vineeth N. Balasubramanian*

Main category: cs.LG

TL;DR: MIRA는 유연한 작업 전환과 지식 유지력을 제공하는 통합 메모리 기반 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 비생물학적 시스템에서의 도메인 일반화와 지속적인 학습을 통합하여 생물학적 시스템처럼 더 효율적으로 작업을 전환하고 정보를 유지하기 위함이다.

Method: MIRA는 Hopfield 스타일의 연상 기억 모듈을 공유된 백본 위에 통합하여, 과거에 학습된 정보로부터 샘플 기반으로 작업이나 도메인에 대한 어댑터 업데이트의 아핀 조합을 색인하고 검색하는 메커니즘을 구현하였다.

Result: MIRA는 도메인 변화와 순차적 작업 노출을 원활하게 처리할 수 있는 능력을 입증하였으며, DG에서는 최첨단의 분포 외 정확도를 달성하였고, 계속 학습 환경에서는 재앙적 망각을 해결하도록 설계된 아키텍처를 초월하는 성능을 보였다.

Conclusion: MIRA는 생물학적으로 영감을 받은 연상 기억을 통해 어댑터 기반의 변조 방식을 통합함으로써 신속한 작업 전환과 지속적인 지식 유지를 하나의 확장 가능한 아키텍처 안에서 가능하게 하며, 보다 다재다능하고 메모리 증강된 AI 시스템을 향한 길을 열었다.

Abstract: Organisms constantly pivot between tasks such as evading predators, foraging, traversing rugged terrain, and socializing, often within milliseconds. Remarkably, they preserve knowledge of once-learned environments sans catastrophic forgetting, a phenomenon neuroscientists hypothesize, is due to a singular neural circuitry dynamically overlayed by neuromodulatory agents such as dopamine and acetylcholine. In parallel, deep learning research addresses analogous challenges via domain generalization (DG) and continual learning (CL), yet these methods remain siloed, despite the brains ability to perform them seamlessly. In particular, prior work has not explored architectures involving associative memories (AMs), which are an integral part of biological systems, to jointly address these tasks. We propose Memory-Integrated Reconfigurable Adapters (MIRA), a unified framework that integrates Hopfield-style associative memory modules atop a shared backbone. Associative memory keys are learned post-hoc to index and retrieve an affine combination of stored adapter updates for any given task or domain on a per-sample basis. By varying only the task-specific objectives, we demonstrate that MIRA seamlessly accommodates domain shifts and sequential task exposures under one roof. Empirical evaluations on standard benchmarks confirm that our AM-augmented architecture significantly enhances adaptability and retention: in DG, MIRA achieves SoTA out-of-distribution accuracy, and in incremental learning settings, it outperforms architectures explicitly designed to handle catastrophic forgetting using generic CL algorithms. By unifying adapter-based modulation with biologically inspired associative memory, MIRA delivers rapid task switching and enduring knowledge retention in a single extensible architecture, charting a path toward more versatile and memory-augmented AI systems.

</details>


### [58] [Goal-Driven Reward by Video Diffusion Models for Reinforcement Learning](https://arxiv.org/abs/2512.00961)
*Qi Wang,Mian Wu,Yuyang Zhang,Mingqi Yuan,Wenyao Zhang,Haoxiang You,Yunbo Wang,Xin Jin,Xiaokang Yang,Wenjun Zeng*

Main category: cs.LG

TL;DR: 연구는 사전 훈련된 비디오 확산 모델을 사용하여 강화 학습(RL) 에이전트에 대한 목표 기반 보상 신호를 제공하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 프로그램화된 보상 함수 설계의 어려움을 해결하기 위해

Method: 비디오 수준 및 프레임 수준의 목표에 대한 보상 함수를 제공하기 위해 대규모 비디오 데이터 세트로 사전 훈련된 비디오 확산 모델을 활용

Result: Meta-World의 다양한 작업에서 접근 방식의 효과성을 입증함

Conclusion: 사전 훈련된 모델을 이용한 보상 설계 방법이 강화 학습 에이전트의 성능을 향상시킬 수 있음을 보여줍니다.

Abstract: Reinforcement Learning (RL) has achieved remarkable success in various domains, yet it often relies on carefully designed programmatic reward functions to guide agent behavior. Designing such reward functions can be challenging and may not generalize well across different tasks. To address this limitation, we leverage the rich world knowledge contained in pretrained video diffusion models to provide goal-driven reward signals for RL agents without ad-hoc design of reward. Our key idea is to exploit off-the-shelf video diffusion models pretrained on large-scale video datasets as informative reward functions in terms of video-level and frame-level goals. For video-level rewards, we first finetune a pretrained video diffusion model on domain-specific datasets and then employ its video encoder to evaluate the alignment between the latent representations of agent's trajectories and the generated goal videos. To enable more fine-grained goal-achievement, we derive a frame-level goal by identifying the most relevant frame from the generated video using CLIP, which serves as the goal state. We then employ a learned forward-backward representation that represents the probability of visiting the goal state from a given state-action pair as frame-level reward, promoting more coherent and goal-driven trajectories. Experiments on various Meta-World tasks demonstrate the effectiveness of our approach.

</details>


### [59] [Operator-Theoretic Framework for Gradient-Free Federated Learning](https://arxiv.org/abs/2512.01025)
*Mohit Kumar,Mathias Brucker,Alexander Valentinitsch,Adnan Husakovic,Ali Abbas,Manuela Geiß,Bernhard A. Moser*

Main category: cs.LG

TL;DR: 이 논문은 연합 학습의 이질성을 해결하고 통신과 계산 제한을 고려하며 개인 정보를 보호하면서 성능을 보장하기 위한 조작 이론적 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습은 이질성, 엄격한 통신 및 계산 한계 및 개인 정보를 고려해야 하며 성능을 보장하는 것이 중요합니다.

Method: 사전 연산자를 통해 $L^2$ 최적 솔루션을 재생 커널 힐버트 공간(RKHS)으로 매핑하고, 가용 데이터를 사용하여 이를 근사화한 뒤 역 연산자로 다시 매핑하여 기울기 없는 방식을 구현합니다.

Result: 고정 인코더 임베딩을 가진 기울기 없는 FL 방법이 강력한 기울기 기반 미세 조정을 맞추거나 초과 달성하여 최대 23.7 포인트의 이득을 보여줍니다.

Conclusion: 이 프레임워크는 낮은 통신량으로 증명 가능한 보장을 제공하고, 스칼라 요약을 통한 비공식적인 지식 전이를 지원하며, 이질성에서의 기울기 기반 연합 학습에 대한 수학적으로 기반이 있는 대안을 제공합니다.

Abstract: Federated learning must address heterogeneity, strict communication and computation limits, and privacy while ensuring performance. We propose an operator-theoretic framework that maps the $L^2$-optimal solution into a reproducing kernel Hilbert space (RKHS) via a forward operator, approximates it using available data, and maps back with the inverse operator, yielding a gradient-free scheme. Finite-sample bounds are derived using concentration inequalities over operator norms, and the framework identifies a data-dependent hypothesis space with guarantees on risk, error, robustness, and approximation. Within this space we design efficient kernel machines leveraging the space folding property of Kernel Affine Hull Machines. Clients transfer knowledge via a scalar space folding measure, reducing communication and enabling a simple differentially private protocol: summaries are computed from noise-perturbed data matrices in one step, avoiding per-round clipping and privacy accounting. The induced global rule requires only integer minimum and equality-comparison operations per test point, making it compatible with fully homomorphic encryption (FHE). Across four benchmarks, the gradient-free FL method with fixed encoder embeddings matches or outperforms strong gradient-based fine-tuning, with gains up to 23.7 points. In differentially private experiments, kernel smoothing mitigates accuracy loss in high-privacy regimes. The global rule admits an FHE realization using $Q \times C$ encrypted minimum and $C$ equality-comparison operations per test point, with operation-level benchmarks showing practical latencies. Overall, the framework provides provable guarantees with low communication, supports private knowledge transfer via scalar summaries, and yields an FHE-compatible prediction rule offering a mathematically grounded alternative to gradient-based federated learning under heterogeneity.

</details>


### [60] [AltNet: Addressing the Plasticity-Stability Dilemma in Reinforcement Learning](https://arxiv.org/abs/2512.01034)
*Mansi Maheshwari,John C. Raisbeck,Bruno Castro da Silva*

Main category: cs.LG

TL;DR: AltNet는 쌍둥이 네트워크를 이용하여 성능 저하 없이 학습의 유연성을 회복하는 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 신경망은 단일 작업에 고정된 데이터셋으로 훈련될 때 탁월한 성과를 보이지만, 강화 학습 작업에서는 경험에서의 지속적인 학습 능력이 시간이 지남에 따라 감소합니다. 이 감소를 해결하기 위해 열린 법칙을 탐색했습니다.

Method: AltNet은 쌍둥이 네트워크를 활용하여 네트워크가 역할을 주기적으로 전환하면서 파라미터를 재설정하는 방식을 사용합니다.

Result: AltNet은 샘플 효율성을 향상시키고 성능 저하를 피하면서 유연성을 복원하여 강화 학습에서 더 나은 성과를 달성했습니다.

Conclusion: AltNet은 다양한 고차원 제어 작업에서 기존 방법들보다 우수한 성능을 보였습니다.

Abstract: Neural networks have shown remarkable success in supervised learning when trained on a single task using a fixed dataset. However, when neural networks are trained on a reinforcement learning task, their ability to continue learning from new experiences declines over time. This decline in learning ability is known as plasticity loss. To restore plasticity, prior work has explored periodically resetting the parameters of the learning network, a strategy that often improves overall performance. However, such resets come at the cost of a temporary drop in performance, which can be dangerous in real-world settings. To overcome this instability, we introduce AltNet, a reset-based approach that restores plasticity without performance degradation by leveraging twin networks. The use of twin networks anchors performance during resets through a mechanism that allows networks to periodically alternate roles: one network learns as it acts in the environment, while the other learns off-policy from the active network's interactions and a replay buffer. At fixed intervals, the active network is reset and the passive network, having learned from prior experiences, becomes the new active network. AltNet restores plasticity, improving sample efficiency and achieving higher performance, while avoiding performance drops that pose risks in safety-critical settings. We demonstrate these advantages in several high-dimensional control tasks from the DeepMind Control Suite, where AltNet outperforms various relevant baseline methods, as well as state-of-the-art reset-based techniques.

</details>


### [61] [World Model Robustness via Surprise Recognition](https://arxiv.org/abs/2512.01119)
*Geigh Zollicoffer,Tanush Chopra,Mingkuan Yan,Xiaoxu Ma,Kenneth Eaton,Mark Riedl*

Main category: cs.LG

TL;DR: 실제 세계에 배치된 AI 시스템은 분산 및 OOD 노 noise와 대처해야 하며, 이를 처리하기 위한 알고리즘을 개발함.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 안전하게 동작하기 위해서는 OOD 상황에서의 안정성이 필요하다.

Method: 세분화된 수용과 단일 수용 샘플링 방식을 이용하여 세계 모델 기반 강화 학습 에이전트에서 노 noise 영향을 줄이는 알고리즘을 개발하였다.

Result: 우리의 기법은 다양한 유형과 수준의 노 noise 아래에서도 성능을 유지하며, 두 개의 서로 다른 아키텍처를 가진 세계 모델의 안정성을 향상시킨다.

Conclusion: 우리 접근 방식은 세계 모델링 도메인 전반에서의 강인성을 강조한다.

Abstract: AI systems deployed in the real world must contend with distractions and out-of-distribution (OOD) noise that can destabilize their policies and lead to unsafe behavior. While robust training can reduce sensitivity to some forms of noise, it is infeasible to anticipate all possible OOD conditions. To mitigate this issue, we develop an algorithm that leverages a world model's inherent measure of surprise to reduce the impact of noise in world model--based reinforcement learning agents. We introduce both multi-representation and single-representation rejection sampling, enabling robustness to settings with multiple faulty sensors or a single faulty sensor. While the introduction of noise typically degrades agent performance, we show that our techniques preserve performance relative to baselines under varying types and levels of noise across multiple environments within self-driving simulation domains (CARLA and Safety Gymnasium). Furthermore, we demonstrate that our methods enhance the stability of two state-of-the-art world models with markedly different underlying architectures: Cosmos and DreamerV3. Together, these results highlight the robustness of our approach across world modeling domains. We release our code at https://github.com/Bluefin-Tuna/WISER .

</details>


### [62] [A TinyML Reinforcement Learning Approach for Energy-Efficient Light Control in Low-Cost Greenhouse Systems](https://arxiv.org/abs/2512.01167)
*Mohamed Abdallah Salem,Manuel Cuevas Perez,Ahmed Harb Rabia*

Main category: cs.LG

TL;DR: 이 연구는 저전력 마이크로컨트롤러를 사용한 제어 환경에서의 적응형 조명 조절을 위한 강화 학습 기반의 제어 전략을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 에너지 효율적인 조명 제어를 위한 경량의 온디바이스 강화 학습의 가능성을 강조하고, 자원 제약이 있는 농업 시스템에서의 다중 모드 환경 제어 응용 프로그램의 기초를 설정하기 위해서이다.

Method: 모델 프리 Q-러닝 알고리즘을 구현하여 실시간 피드백에 따라 LED의 밝기를 동적으로 조정한다.

Result: 130회의 실험이 진행되었으며, 에이전트는 환경의 섭동에도 불구하고 최소한의 오버슈팅으로 다양한 조명 수준에서 안정화하는 것을 효과적으로 학습하였다.

Conclusion: 실험적 검증 결과, 이 시스템은 빠른 수렴 속도와 높은 학습 효율성을 보여주었다.

Abstract: This study presents a reinforcement learning (RL)-based control strategy for adaptive lighting regulation in controlled environments using a low-power microcontroller. A model-free Q-learning algorithm was implemented to dynamically adjust the brightness of a Light-Emitting Diode (LED) based on real-time feedback from a light-dependent resistor (LDR) sensor. The system was trained to stabilize at 13 distinct light intensity levels (L1 to L13), with each target corresponding to a specific range within the 64-state space derived from LDR readings. A total of 130 trials were conducted, covering all target levels with 10 episodes each. Performance was evaluated in terms of convergence speed, steps taken, and time required to reach target states. Box plots and histograms were generated to analyze the distribution of training time and learning efficiency across targets. Experimental validation demonstrated that the agent could effectively learn to stabilize at varying light levels with minimal overshooting and smooth convergence, even in the presence of environmental perturbations. This work highlights the feasibility of lightweight, on-device RL for energy-efficient lighting control and sets the groundwork for multi-modal environmental control applications in resource-constrained agricultural systems.

</details>


### [63] [First On-Orbit Demonstration of a Geospatial Foundation Model](https://arxiv.org/abs/2512.01181)
*Andrew Du,Roberto Del Prete,Alejandro Mousist,Nick Manser,Fabrice Marre,Andrew Barton,Carl Seubert,Gabriele Meoni,Tat-Jun Chin*

Main category: cs.LG

TL;DR: 지리정보 기반 모델(GeoFM)은 데이터 제한 환경에서 지구 관측 작업에 대한 일반화 능력을 제공하지만, 큰 크기로 인해 자원 제약이 있는 우주 하드웨어에서의 배치를 어렵게 한다.


<details>
  <summary>Details</summary>
Motivation: 지리정보 기반 모델의 큰 크기로 인해 자원 제약이 있는 우주 하드웨어에서 배치하는 데 어려움이 있다.

Method: 비전 변환기(ViT) 기반의 GeoFM의 압축 변형을 제안하여 다운스트림 작업 성능을 유지하면서도 온보드 실행을 가능하게 했다.

Result: 다섯 가지 다운스트림 작업을 평가하고 두 개의 대표 비행 환경에서 검증한 결과, 모델 압축과 도메인 적응이 크기와 자원 요구 사항을 줄이는 데 필수적이라는 것을 확인했다.

Conclusion: 이 결과는 대형 GeoFM에서 비행 준비가 완료되고 자원 효율적인 배치로 가는 경로를 설정하여 EO 임무를 위한 온보드 AI의 실행 가능성을 확장한다.

Abstract: Geospatial foundation models (GeoFMs) promise broad generalisation capacity for Earth observation (EO) tasks, particularly under data-limited conditions. However, their large size poses a barrier to deployment on resource-constrained space hardware. To address this, we present compact variants of a Vision Transformer (ViT)-based GeoFM that preserve downstream task performance while enabling onboard execution. Evaluation across five downstream tasks and validation in two representative flight environments show that model compression and domain adaptation are critical to reducing size and resource demands while maintaining high performance under operational conditions. We further demonstrate reliable on-orbit inference with the IMAGIN-e payload aboard the International Space Station. These results establish a pathway from large GeoFMs to flight-ready, resource-efficient deployments, expanding the feasibility of onboard AI for EO missions.

</details>


### [64] [Learning to Reconstruct Temperature Field from Sparse Observations with Implicit Physics Priors](https://arxiv.org/abs/2512.01196)
*Shihang Li,Zhiqiang Gong,Weien Zhou,Yue Gao,Wen Yao*

Main category: cs.LG

TL;DR: 본 논문은 온도 필드 재구성을 개선하기 위한 IPTR 프레임워크를 제안하며, 기존의 방법보다 뛰어난 정확성과 일반화 능력을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 열 체크 및 신뢰성 평가에 필수적인 온도 필드 재구성을 위해, 측정 비용과 온도 필드의 분포 변화가 큰 도전 과제가 된다.

Method: IPTR 프레임워크는 이전 시뮬레이션으로부터 희소 모니터링-온도 필드 쌍을 사전 정보로 사용하여 물리적 이해를 풍부하게 하며, 두 가지 보완적인 브랜치를 가지는 쌍둥이 물리 임베딩 모듈을 설계한다.

Result: IPTR은 여러 조건에서의 실험을 통해 기존 방법보다 항상 뛰어난 성능, 즉 최신 재구성 정확성과 강력한 일반화 능력을 달성한다.

Conclusion: IPTR은 기존의 DNN 기반 방법과 비교하여 현저하게 개선된 성능을 보여주며, 공학적 응용에서 효과적으로 활용될 수 있다.

Abstract: Accurate reconstruction of temperature field of heat-source systems (TFR-HSS) is crucial for thermal monitoring and reliability assessment in engineering applications such as electronic devices and aerospace structures. However, the high cost of measurement acquisition and the substantial distributional shifts in temperature field across varying conditions present significant challenges for developing reconstruction models with robust generalization capabilities. Existing DNNs-based methods typically formulate TFR-HSS as a one-to-one regression problem based solely on target sparse measurements, without effectively leveraging reference simulation data that implicitly encode thermal knowledge. To address this limitation, we propose IPTR, an implicit physics-guided temperature field reconstruction framework that introduces sparse monitoring-temperature field pair from reference simulations as priors to enrich physical understanding. To integrate both reference and target information, we design a dual physics embedding module consisting of two complementary branches: an implicit physics-guided branch employing cross-attention to distill latent physics from the reference data, and an auxiliary encoding branch based on Fourier layers to capture the spatial characteristics of the target observation. The fused representation is then decoded to reconstruct the full temperature field. Extensive experiments under single-condition, multi-condition, and few-shot settings demonstrate that IPTR consistently outperforms existing methods, achieving state-of-the-art reconstruction accuracy and strong generalization capability.

</details>


### [65] [Know Thyself by Knowing Others: Learning Neuron Identity from Population Context](https://arxiv.org/abs/2512.01199)
*Vinam Arora,Divyansha Lachi,Ian J. Knight,Mehdi Azabou,Blake Richards,Cole L. Hurwitz,Josh Siegle,Eva L. Dyer*

Main category: cs.LG

TL;DR: NuCLR는 뉴런의 정체성을 구별할 수 있는 자기 지도 학습 프레임워크로, 다양한 자극과 시간에서 관측된 뉴런의 활동 데이터를 통합하여 정보 처리를 개선한다.


<details>
  <summary>Details</summary>
Motivation: 뉴런의 정체성을 추론하는 것은 여전히 큰 도전 과제이며, 이를 해결하는 일반적인 표현 방식을 구축하는 것이 필요하다.

Method: NuCLR는 다양한 시점과 자극에서 관찰된 동일한 뉴런에 대한 표현을 대비적 목표를 사용하여 통합하는 자기 지도 학습 프레임워크이다.

Result: 여러 전기생리학 및 칼슘 이미징 데이터셋을 통해 NuCLR 표현을 기반으로 한 선형 디코딩 평가는 세포 유형 및 뇌 영역 디코딩 작업에서 새로운 최첨단 성과를 달성하였으며, 보지 못한 동물에 대한 강력한 제로샷 일반화를 보여주었다.

Conclusion: 사전 훈련 동안 동물의 수를 늘리는 것이 다운스트림 성능을 일관되게 향상시킨다는 점은 뉴런 수준 표현 학습에 대한 첫 번째 체계적인 스케일링 분석으로 확인되었다.

Abstract: Neurons process information in ways that depend on their cell type, connectivity, and the brain region in which they are embedded. However, inferring these factors from neural activity remains a significant challenge. To build general-purpose representations that allow for resolving information about a neuron's identity, we introduce NuCLR, a self-supervised framework that aims to learn representations of neural activity that allow for differentiating one neuron from the rest. NuCLR brings together views of the same neuron observed at different times and across different stimuli and uses a contrastive objective to pull these representations together. To capture population context without assuming any fixed neuron ordering, we build a spatiotemporal transformer that integrates activity in a permutation-equivariant manner. Across multiple electrophysiology and calcium imaging datasets, a linear decoding evaluation on top of NuCLR representations achieves a new state-of-the-art for both cell type and brain region decoding tasks, and demonstrates strong zero-shot generalization to unseen animals. We present the first systematic scaling analysis for neuron-level representation learning, showing that increasing the number of animals used during pretraining consistently improves downstream performance. The learned representations are also label-efficient, requiring only a small fraction of labeled samples to achieve competitive performance. These results highlight how large, diverse neural datasets enable models to recover information about neuron identity that generalize across animals. Code is available at https://github.com/nerdslab/nuclr.

</details>


### [66] [Walking on the Fiber: A Simple Geometric Approximation for Bayesian Neural Networks](https://arxiv.org/abs/2512.01500)
*Alfredo Reichlin,Miguel Vasco,Danica Kragic*

Main category: cs.LG

TL;DR: 본 연구에서는 비정규화 네트워크에서의 사후 샘플링을 위한 새로운 변형을 제안하며, 초매개변수화 네트워크에서 효과적인 사후 샘플링을 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: Bayesian Neural Networks는 네트워크 매개변수의 사후 분포를 모델링하여 불확실성 정량화를 위한 원칙적인 프레임워크를 제공합니다.

Method: 저자는 저차원 손실 최소값 구조를 활용하여 초매개변수화 네트워크에서 사후 분포에서 효율적으로 샘플링할 수 있도록 하는 간단한 변형을 제안합니다.

Result: 실험 결과, 제안된 접근법이 최근의 정교화 기술에 비해 향상된 확장성과 함께 경쟁력 있는 사후 근사를 달성함을 보여줍니다.

Conclusion: 이러한 기여는 딥러닝에서 Bayesian 추론을 위한 실용적인 대안을 제공합니다.

Abstract: Bayesian Neural Networks provide a principled framework for uncertainty quantification by modeling the posterior distribution of network parameters. However, exact posterior inference is computationally intractable, and widely used approximations like the Laplace method struggle with scalability and posterior accuracy in modern deep networks. In this work, we revisit sampling techniques for posterior exploration, proposing a simple variation tailored to efficiently sample from the posterior in over-parameterized networks by leveraging the low-dimensional structure of loss minima. Building on this, we introduce a model that learns a deformation of the parameter space, enabling rapid posterior sampling without requiring iterative methods. Empirical results demonstrate that our approach achieves competitive posterior approximations with improved scalability compared to recent refinement techniques. These contributions provide a practical alternative for Bayesian inference in deep learning.

</details>


### [67] [ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large Language Models](https://arxiv.org/abs/2512.01672)
*Zhongyuan Wu,Jingyuan Wang,Zexuan Cheng,Yilong Zhou,Weizhi Wang,Juhua Pu,Chao Li,Changqing Ma*

Main category: cs.LG

TL;DR: ICAD-LLM은 다양한 데이터 형식을 처리하며 새로운 환경에 신속하게 적응할 수 있는 혁신적인 이상 탐지 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 빠르게 변화하는 환경에서 다양한 데이터 형식에 대한 효과적인 이상 탐지 방법이 필요하다.

Method: ICAD-LLM은 대형 언어 모델의 인컨텍스트 학습 능력을 활용하여 이질적인 데이터를 단일 모델 내에서 처리하는 통합 이상 탐지 프레임워크를 제안한다.

Result: ICAD-LLM은 특정 작업에 맞춘 이상 탐지 방법들과 경쟁력 있는 성능을 보이며, 이전에 보지 못한 작업에도 강력한 일반화 능력을 발휘한다.

Conclusion: ICAD-LLM은 다양한 도메인과 모달리티를 아우르는 이상 탐지 작업을 처리할 수 있는 첫 번째 모델이다.

Abstract: Anomaly detection (AD) is a fundamental task of critical importance across numerous domains. Current systems increasingly operate in rapidly evolving environments that generate diverse yet interconnected data modalities -- such as time series, system logs, and tabular records -- as exemplified by modern IT systems. Effective AD methods in such environments must therefore possess two critical capabilities: (1) the ability to handle heterogeneous data formats within a unified framework, allowing the model to process and detect multiple modalities in a consistent manner during anomalous events; (2) a strong generalization ability to quickly adapt to new scenarios without extensive retraining. However, most existing methods fall short of these requirements, as they typically focus on single modalities and lack the flexibility to generalize across domains. To address this gap, we introduce a novel paradigm: In-Context Anomaly Detection (ICAD), where anomalies are defined by their dissimilarity to a relevant reference set of normal samples. Under this paradigm, we propose ICAD-LLM, a unified AD framework leveraging Large Language Models' in-context learning abilities to process heterogeneous data within a single model. Extensive experiments demonstrate that ICAD-LLM achieves competitive performance with task-specific AD methods and exhibits strong generalization to previously unseen tasks, which substantially reduces deployment costs and enables rapid adaptation to new environments. To the best of our knowledge, ICAD-LLM is the first model capable of handling anomaly detection tasks across diverse domains and modalities.

</details>


### [68] [Automating modeling in mechanics: LLMs as designers of physics-constrained neural networks for constitutive modeling of materials](https://arxiv.org/abs/2512.01735)
*Marius Tacke,Matthias Busch,Kian Abdolazizi,Jonas Eichinger,Kevin Linka,Christian Cyron,Roland Aydin*

Main category: cs.LG

TL;DR: 이 연구는 대형 언어 모델을 활용한 시스템이 요구에 따라 과학 및 공학 작업을 위한 특화된 소프트웨어 모듈을 생성할 수 있음을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 기반의 에이전트 프레임워크는 작업에 특화된 에이전트를 동적으로 생성하는 패러다임을 채택하고 있습니다. 이러한 배경에서 우리는 요구에 따라 전문화된 소프트웨어 모듈을 생성할 수 있다는 점을 강조합니다.

Method: 이 연구에서는 대형 언어 모델이 사용자에 의해 제공된 특정 물질 클래스 및 데이터 세트에 맞춤형으로 CANN을 요구에 따라 생성하는 프레임워크를 제시합니다.

Result: 세 가지 벤치마크 문제에 대한 평가 결과, LLM이 생성한 CANN은 수동으로 설계된 모델들보다 동등하거나 더 높은 정확도를 달성하며, 보지 않은 하중 시나리오에 대한 신뢰할 수 있는 일반화 및 큰 변형에 대한 외삽을 보여줍니다.

Conclusion: 이 결과는 물리적 제약이 적용된 신경망의 LLM 기반 생성을 통해 구성 모델링에 필요한 전문성을 상당히 줄일 수 있음을 시사하며, 실제적인 엔드 투 엔드 자동화로 나아가는 한 걸음을 나타냅니다.

Abstract: Large language model (LLM)-based agentic frameworks increasingly adopt the paradigm of dynamically generating task-specific agents. We suggest that not only agents but also specialized software modules for scientific and engineering tasks can be generated on demand. We demonstrate this concept in the field of solid mechanics. There, so-called constitutive models are required to describe the relationship between mechanical stress and body deformation. Constitutive models are essential for both the scientific understanding and industrial application of materials. However, even recent data-driven methods of constitutive modeling, such as constitutive artificial neural networks (CANNs), still require substantial expert knowledge and human labor. We present a framework in which an LLM generates a CANN on demand, tailored to a given material class and dataset provided by the user. The framework covers LLM-based architecture selection, integration of physical constraints, and complete code generation. Evaluation on three benchmark problems demonstrates that LLM-generated CANNs achieve accuracy comparable to or greater than manually engineered counterparts, while also exhibiting reliable generalization to unseen loading scenarios and extrapolation to large deformations. These findings indicate that LLM-based generation of physics-constrained neural networks can substantially reduce the expertise required for constitutive modeling and represent a step toward practical end-to-end automation.

</details>


### [69] [How Does RL Post-training Induce Skill Composition? A Case Study on Countdown](https://arxiv.org/abs/2512.01775)
*Simon Park,Simran Kaur,Sanjeev Arora*

Main category: cs.LG

TL;DR: 강화 학습(RL)은 대형 언어 모델의 추론 능력을 향상시키며, 구성 일반화(compositional generalization) 역할에 대한 연구이다.


<details>
  <summary>Details</summary>
Motivation: 구성 일반화와 단순한 길이 일반화의 차이를 이해하고자 하며, RL이 기술 구성에 미치는 영향을 탐구한다.

Method: 카운트다운 작업에서 표현 트리로 모델 솔루션을 분석하고, 훈련 과정에서 트리 모양과 성공률을 추적한다.

Result: OOD 일반화 현상을 발견하고, 학습 가능성이 구조 의존적이라는 것을 확인했다.

Conclusion: 이 연구는 RL 기반 후처리가 OOD 일반화를 유도하는 방식을 명확히 하고, 성과의 순서와 실패 지점을 진단한다.

Abstract: While reinforcement learning (RL) successfully enhances reasoning in large language models, its role in fostering compositional generalization (the ability to synthesize novel skills from known components) is often conflated with mere length generalization. To this end, we study what RL post-training teaches about skill composition and how the structure of the composition affects the skill transfer. We focus on the Countdown task (given n numbers and a target, form an expression that evaluates to the target) and analyze model solutions as expression trees, where each subtree corresponds to a reusable subtask and thus can be viewed as a ``skill.'' Tracking tree shapes and their success rates over training, we find: (i) out-of-distribution (OOD) generalization to larger n and to unseen tree shapes, indicating compositional reuse of subtasks; (ii) a structure-dependent hierarchy of learnability -- models master shallow balanced trees (workload is balanced between subtasks) before deep unbalanced ones, with persistent fragility on right-heavy structures (even when the composition depth is the same as some left-heavy structures). Our diagnostic reveals what is learned, in what order, and where generalization fails, clarifying how RL-only post-training induces OOD generalization beyond what standard metrics such as pass@k reveal.

</details>


### [70] [The Active and Noise-Tolerant Strategic Perceptron](https://arxiv.org/abs/2512.01783)
*Maria-Florina Blacan,Hedyeh Beyhaghi*

Main category: cs.LG

TL;DR: 이 논문은 전략적 에이전트를 분류하기 위한 능동 학습 알고리즘의 연구를 시작한다.


<details>
  <summary>Details</summary>
Motivation: 전략적 분류에서 에이전트가 더욱 유리한 결과를 얻기 위해 자신의 특성을 수정하는 시나리오를 다루기 위해.

Method: 전략적 환경에서 능동적으로 선형 분리기를 학습하는 알고리즘을 설계한다.

Result: 이 알고리즘은 무작위로 단위 구에서 추출된 데이터에 대해 요구된 레이블 복잡도를 크게 향상시킨다.

Conclusion: 이 알고리즘은 계산적으로 효율적이며, 기존 전략적 Perceptron 연구보다 훨씬 적은 레이블 질의를 요구한다.

Abstract: We initiate the study of active learning algorithms for classifying strategic agents. Active learning is a well-established framework in machine learning in which the learner selectively queries labels, often achieving substantially higher accuracy and efficiency than classical supervised methods-especially in settings where labeling is costly or time-consuming, such as hiring, admissions, and loan decisions. Strategic classification, however, addresses scenarios where agents modify their features to obtain more favorable outcomes, resulting in observed data that is not truthful. Such manipulation introduces challenges beyond those in learning from clean data. Our goal is to design active and noise-tolerant algorithms that remain effective in strategic environments-algorithms that classify strategic agents accurately while issuing as few label requests as possible. The central difficulty is to simultaneously account for strategic manipulation and preserve the efficiency gains of active learning.
  Our main result is an algorithm for actively learning linear separators in the strategic setting that preserves the exponential improvement in label complexity over passive learning previously obtained only in the non-strategic case. Specifically, for data drawn uniformly from the unit sphere, we show that a modified version of the Active Perceptron algorithm [DKM05,YZ17] achieves excess error $ε$ using only $\tilde{O}(d \ln \frac{1}ε)$ label queries and incurs at most $\tilde{O}(d \ln \frac{1}ε)$ additional mistakes relative to the optimal classifier, even in the nonrealizable case, when a $\tildeΩ(ε)$ fraction of inputs have inconsistent labels with the optimal classifier. The algorithm is computationally efficient and, under these distributional assumptions, requires substantially fewer label queries than prior work on strategic Perceptron [ABBN21].

</details>


### [71] [DeepCAVE: A Visualization and Analysis Tool for Automated Machine Learning](https://arxiv.org/abs/2512.01810)
*Sarah Segel,Helena Graf,Edward Bergman,Kristina Thieme,Marcel Wever,Alexander Tornede,Frank Hutter,Marius Lindauer*

Main category: cs.LG

TL;DR: DeepCAVE는 하이퍼파라미터 최적화(HPO)를 위한 도구로, 머신 러닝 모델의 최적화 과정을 시각화하고 분석하여 연구자와 데이터 과학자들이 문제를 식별할 수 있도록 돕는다.


<details>
  <summary>Details</summary>
Motivation: HPO는 AutoML의 중심 패러다임으로, 머신 러닝 모델의 잠재력을 최대한 활용하는 데 중요한 역할을 하지만, 그 복잡성으로 인해 최적화 과정을 이해하고 디버깅하는 데 어려움이 있다.

Method: DeepCAVE는 인터랙티브 대시보드를 제공하여 HPO 과정의 다양한 측면을 탐색하고 문제, 잠재력을 발견할 수 있는 도구이다.

Result: 연구자, 데이터 과학자 및 ML 엔지니어는 DeepCAVE를 통해 HPO 과정에 대한 인사이트를 얻고, 조정 중인 ML 모델에 대한 새로운 인사이트를 찾을 수 있다.

Conclusion: DeepCAVE는 HPO와 ML의 해석 가능성을 향상시키고, 미래의 더 강력하고 효율적인 방법론 개발을 촉진하는 것을 목표로 한다.

Abstract: Hyperparameter optimization (HPO), as a central paradigm of AutoML, is crucial for leveraging the full potential of machine learning (ML) models; yet its complexity poses challenges in understanding and debugging the optimization process. We present DeepCAVE, a tool for interactive visualization and analysis, providing insights into HPO. Through an interactive dashboard, researchers, data scientists, and ML engineers can explore various aspects of the HPO process and identify issues, untouched potentials, and new insights about the ML model being tuned. By empowering users with actionable insights, DeepCAVE contributes to the interpretability of HPO and ML on a design level and aims to foster the development of more robust and efficient methodologies in the future.

</details>


### [72] [Agentic Policy Optimization via Instruction-Policy Co-Evolution](https://arxiv.org/abs/2512.01945)
*Han Zhou,Xingchen Wan,Ivan Vulić,Anna Korhonen*

Main category: cs.LG

TL;DR: INSPO는 강화 학습 루프의 동적 구성 요소로서 지침 최적화를 통합하여 에이전트와 환경의 상호작용을 탐색하며 지침의 효과를 개선하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 정적이고 수동으로 설계된 지침은 기본 모델에 최적이 아닐 수 있으며, 에이전트의 정책이 개선됨에 따라 최적의 지침이 변경될 수 있습니다.

Method: INSPO는 지침 최적화를 강화 학습 루프의 동적 구성 요소로 통합하는 새로운 Instruction-Policy 공진화 프레임워크입니다. 이 프레임워크는 질문을 통해 샘플링된 지침 후보의 동적 집단을 유지하며, RL 루프의 보상 신호를 각 지침에 자동으로 귀속시킵니다.

Result: INSPO는 다중 턴 검색 및 추론 작업에 대한 광범위한 실험을 통해 정적 지침에 의존하는 강력한 기준선을 크게 능가한다는 것을 입증했습니다.

Conclusion: INSPO는 지침을 혁신적으로 발견하여 에이전트를 더 전략적인 추론 경로로 이끌며, 컴퓨팅 오버헤드를 약간 증가시키는 것만으로도 상당한 성능 향상을 달성합니다.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has advanced the reasoning capability of large language models (LLMs), enabling autonomous agents that can conduct effective multi-turn and tool-integrated reasoning. While instructions serve as the primary protocol for defining agents, RLVR typically relies on static and manually designed instructions. However, those instructions may be suboptimal for the base model, and the optimal instruction may change as the agent's policy improves and explores the interaction with the environment. To bridge the gap, we introduce INSPO, a novel Instruction-Policy co-evolution framework that integrates instruction optimization as a dynamic component of the reinforcement learning (RL) loop. INSPO maintains a dynamic population of instruction candidates that are sampled with questions, where reward signals in RL loops are automatically attributed to each instruction, and low performers are periodically pruned. New instructions are generated and verified through an on-policy reflection mechanism, where an LLM-based optimizer analyzes past experience from a replay buffer and evolves more effective strategies given the current policy. We conduct extensive experiments on multi-turn retrieval and reasoning tasks, demonstrating that INSPO substantially outperforms strong baselines relying on static instructions. INSPO discovers innovative instructions that guide the agent toward more strategic reasoning paths, achieving substantial performance gains with only a marginal increase in computational overhead.

</details>


### [73] [Forecasting in Offline Reinforcement Learning for Non-stationary Environments](https://arxiv.org/abs/2512.01987)
*Suzan Ece Ada,Georg Martius,Emre Ugur,Erhan Oztop*

Main category: cs.LG

TL;DR: 비정상 환경에서 오프라인 강화 학습의 성능을 개선하는 FORL 프레임워크 소개


<details>
  <summary>Details</summary>
Motivation: 기존의 오프라인 강화 학습 방법은 비정상적인 환경에서 성능 저하를 겪는다.

Method: FORL은 조건부 확산 기반 상태 생성과 제로샷 시계열 모델을 결합한 프레임워크이다.

Result: FORL은 기존 기준선에 비해 성능을 일관되게 개선한다.

Conclusion: FORL은 오프라인 강화 학습과 비정상 환경 간의 간극을 메우는 것을 목표로 한다.

Abstract: Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade performance. To overcome this challenge, we introduce Forecasting in Non-stationary Offline RL (FORL), a framework that unifies (i) conditional diffusion-based candidate state generation, trained without presupposing any specific pattern of future non-stationarity, and (ii) zero-shot time-series foundation models. FORL targets environments prone to unexpected, potentially non-Markovian offsets, requiring robust agent performance from the onset of each episode. Empirical evaluations on offline RL benchmarks, augmented with real-world time-series data to simulate realistic non-stationarity, demonstrate that FORL consistently improves performance compared to competitive baselines. By integrating zero-shot forecasting with the agent's experience, we aim to bridge the gap between offline RL and the complexities of real-world, non-stationary environments.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [74] [Toward a Safe Internet of Agents](https://arxiv.org/abs/2512.00520)
*Juan A. Wibowo,George C. Polyzos*

Main category: cs.MA

TL;DR: 대규모 언어 모델에 의해 구동되는 자율 에이전트가 안전과 보안에 새로운 위험을 제시하며, 에이전틱 시스템을 안전하게 설계하기 위한 아키텍처적 프레임워크를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLMs)에 의해 구동되는 자율 에이전트들이 '에이전트의 인터넷'(IoA)으로의 패러다임 전환을 이끌고 있지만, 이 비전은 안전과 보안에 새로운 체계적 위험을 도입합니다.

Method: 우리는 에이전틱 시스템을 각 구성 요소를 이중 용도의 인터페이스로 간주하여 하향식으로 분해합니다. 이 분석은 기본적인 단일 에이전트, 협력적인 다중 에이전트 시스템(MAS), 비전 있는 상호 운용 가능한 다중 에이전트 시스템(IMAS)의 세 가지 복잡성 수준에 걸쳐 진행됩니다.

Result: 우리의 주요 발견은 에이전틱 안전이 추가적인 요소가 아닌 아키텍처적 원칙이라는 것입니다.

Conclusion: 이 설문은 에이전트 스택의 각 수준에서 특정 취약성을 식별하고 완화 원칙을 도출함으로써 안전하고 신뢰할 수 있는 AI를 구축하기 위한 기본 지침이 됩니다.

Abstract: Background: Autonomous agents powered by Large Language Models (LLMs) are driving a paradigm shift toward an "Internet of Agents" (IoA). While offering immense potential, this vision also introduces novel and systemic risks to safety and security. Objectives: Unlike common threat-centric taxonomies, our survey provides a principled, architectural framework for engineering safe and reliable agentic systems. We aim to identify the architectural sources of vulnerabilities to establish a foundation for secure design. Methods: We perform a bottom-up deconstruction of agentic systems, treating each component as a dual-use interface. The analysis spans three levels of complexity: the foundational Single Agent, the collaborative Multi-Agent System (MAS), and the visionary Interoperable Multi-Agent System (IMAS). At each level, we identify core architectural components and their inherent security risks. Results & Conclusions: Our central finding is that agentic safety is an architectural principle, not an add-on. By identifying specific vulnerabilities and deriving mitigation principles at each level of the agentic stack, this survey serves as a foundational guide for building the capable, safe, and trustworthy AI needed to realize a secure Internet of Agents.

</details>


### [75] [AgentODRL: A Large Language Model-based Multi-agent System for ODRL Generation](https://arxiv.org/abs/2512.00602)
*Wanle Zhong,Keman Huang,Xiaoyong Du*

Main category: cs.MA

TL;DR: 본 연구는 Open Digital Rights Language(ODRL) 형식으로 복잡한 규칙을 자연어에서 효율적으로 번역하기 위한 신뢰성 높은 방법인 AgentODRL을 제안한다.


<details>
  <summary>Details</summary>
Motivation: ODRL은 데이터 권한 관리를 자동화하는 데 중요한 표준이지만, 인증 정책의 논리적 복잡성과 고품질의 훈련 데이터 부족이 효율적인 번역을 방해한다.

Method: 본 연구는 대형 언어 모델(LLM)의 이해 및 생성 능력을 활용하여 ODRL 정책 생성을 위한 생성기, 복잡한 사용 사례를 분해하는 분해기, 중첩된 논리 관계를 단순화하는 재작성기로 구성된 다중 에이전트 시스템인 AgentODRL을 도입한다. 오케스트레이터 에이전트는 동적으로 작업자들을 조정하여 입력 사용 사례의 복잡성에 따라 최적 경로를 구성한다.

Result: 새로 구성된 데이터셋에 대한 실험 결과, 제안하는 시스템은 ODRL 생성 작업에서 우수한 성과를 달성하였다.

Conclusion: 이 연구에서 도입한 다양한 전략이 ODRL 생성 작업의 성능을 크게 향상시켰음을 보여준다.

Abstract: The Open Digital Rights Language (ODRL) is a pivotal standard for automating data rights management. However, the inherent logical complexity of authorization policies, combined with the scarcity of high-quality "Natural Language-to-ODRL" training datasets, impedes the ability of current methods to efficiently and accurately translate complex rules from natural language into the ODRL format. To address this challenge, this research leverages the potent comprehension and generation capabilities of Large Language Models (LLMs) to achieve both automation and high fidelity in this translation process. We introduce AgentODRL, a multi-agent system based on an Orchestrator-Workers architecture. The architecture consists of specialized Workers, including a Generator for ODRL policy creation, a Decomposer for breaking down complex use cases, and a Rewriter for simplifying nested logical relationships. The Orchestrator agent dynamically coordinates these Workers, assembling an optimal pathway based on the complexity of the input use case. Specifically, we enhance the ODRL Generator by incorporating a validator-based syntax strategy and a semantic reflection mechanism powered by a LoRA-finetuned model, significantly elevating the quality of the generated policies. Extensive experiments were conducted on a newly constructed dataset comprising 770 use cases of varying complexity, all situated within the context of data spaces. The results, evaluated using ODRL syntax and semantic scores, demonstrate that our proposed Orchestrator-Workers system, enhanced with these strategies, achieves superior performance on the ODRL generation task.

</details>


### [76] [Hierarchical Decentralized Multi-Agent Coordination with Privacy-Preserving Knowledge Sharing: Extending AgentNet for Scalable Autonomous Systems](https://arxiv.org/abs/2512.00614)
*Goutham Nalagatla*

Main category: cs.MA

TL;DR: AgentNet++는 다층 에이전트 조직과 프라이버시 보장 지식 공유를 통해 에이전트 간의 효율적인 협업을 가능하게 하는 계층적 분산 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트 간의 자율적 협업을 가능하게 하기 위한 분산 다중 에이전트 시스템의 필요성을 제시하고, 기존 AgentNet의 한계를 극복하고자 한다.

Method: 다층 에이전트 조직, 차등 프라이버시 및 안전한 집계를 통한 지식 공유, 적응형 자원 관리, 이론적 수렴 보장을 포함한 계층적 분산 프레임워크를 제안한다.

Result: AgentNet++는 더 높은 작업 완료율(23% 향상), 통신 오버헤드 감소(40% 감소) 및 강력한 개인 정보 보호 보장을 달성한다.

Conclusion: AgentNet++는 1000개 이상의 에이전트에 효과적으로 확장되며 원래 AgentNet의 emergent intelligence 속성을 유지한다.

Abstract: Decentralized multi-agent systems have shown promise in enabling autonomous collaboration among LLM-based agents. While AgentNet demonstrated the feasibility of fully decentralized coordination through dynamic DAG topologies, several limitations remain: scalability challenges with large agent populations, communication overhead, lack of privacy guarantees, and suboptimal resource allocation. We propose AgentNet++, a hierarchical decentralized framework that extends AgentNet with multilevel agent organization, privacy-preserving knowledge sharing via differential privacy and secure aggregation, adaptive resource management, and theoretical convergence guarantees. Our approach introduces cluster-based hierarchies where agents self-organize into specialized groups, enabling efficient task routing and knowledge distillation while maintaining full decentralization. We provide formal analysis of convergence properties and privacy bounds, and demonstrate through extensive experiments on complex multi-agent tasks that AgentNet++ achieves 23% higher task completion rates, 40% reduction in communication overhead, and maintains strong privacy guarantees compared to AgentNet and other baselines. Our framework scales effectively to 1000+ agents while preserving the emergent intelligence properties of the original AgentNet.

</details>


### [77] [Augmented Runtime Collaboration for Self-Organizing Multi-Agent Systems: A Hybrid Bi-Criteria Routing Approach](https://arxiv.org/abs/2512.00740)
*Qingwen Yang,Feiyu Qu,Tiezheng Guo,Yanyi Liu,Yingyou Wen*

Main category: cs.MA

TL;DR: BiRouter는 Self-Organizing Multi-Agent Systems(SO-MAS)를 위한 새로운 이중 기준 라우팅 방법으로, 각 에이전트가 로컬 정보만을 사용하여 자율적으로 "다음 이동" 작업 라우팅을 수행하도록 지원한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 다중 에이전트 시스템이 다양한 분야에서 중요한 능력을 보여주지만, 협업 전략에 의해 성능과 효율성이 제한된다.

Method: BiRouter는 두 가지 지표인 ImpScore와 GapScore를 기반으로 에이전트가 자율적으로 다음 작업 라우팅을 수행하도록 지원한다.

Result: BiRouter는 기존 기준에 비해 우수한 성능과 토큰 효율성을 달성하며, 정보가 제한적이고 분산된 환경에서도 강한 견고성과 효과를 유지한다.

Conclusion: 우리는 BiRouter가 신뢰할 수 없는 환경에서도 시스템의 견고성을 강화하고 모델의 일반화를 향상시키기 위해 동적으로 업데이트되는 평판 메커니즘을 도입했다고 강조한다.

Abstract: LLM-based multi-agent systems have demonstrated significant capabilities across diverse domains. However, the task performance and efficiency are fundamentally constrained by their collaboration strategies. Prevailing approaches rely on static topologies and centralized global planning, a paradigm that limits their scalability and adaptability in open, decentralized networks. Effective collaboration planning in distributed systems using only local information thus remains a formidable challenge. To address this, we propose BiRouter, a novel dual-criteria routing method for Self-Organizing Multi-Agent Systems (SO-MAS). This method enables each agent to autonomously execute ``next-hop'' task routing at runtime, relying solely on local information. Its core decision-making mechanism is predicated on balancing two metrics: (1) the ImpScore, which evaluates a candidate agent's long-term importance to the overall goal, and (2) the GapScore, which assesses its contextual continuity for the current task state. Furthermore, we introduce a dynamically updated reputation mechanism to bolster system robustness in untrustworthy environments and have developed a large-scale, cross-domain dataset, comprising thousands of annotated task-routing paths, to enhance the model's generalization. Extensive experiments demonstrate that BiRouter achieves superior performance and token efficiency over existing baselines, while maintaining strong robustness and effectiveness in information-limited, decentralized, and untrustworthy settings.

</details>


### [78] [Chain of Unit-Physics: A Primitive-Centric Approach to Scientific Code Synthesis](https://arxiv.org/abs/2512.01010)
*Vansh Sharma,Venkat Raman*

Main category: cs.MA

TL;DR: 이 논문은 자율 코드 생성기인 대형 언어 모델의 신뢰성 문제를 다루며, Chain of Unit-Physics 프레임워크를 통해 코드 설계의 역접근법을 제안한다. 이 프레임워크는 고전적인 과학 문제를 해결하기 위한 실용적인 템플릿을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 자율적인 코드 생성기로서 대형 언어 모델의 신뢰성을 검토하기 위해, 과학적 컴퓨팅 문제를 해결하기 위한 방법을 찾고 있다.

Method: Chain of Unit-Physics 프레임워크를 사용하여 인지된 전문가 지식을 단위 물리 테스트로 부호화함으로써 코드 생성을 제약하는 다중 에이전트 시스템을 제안한다.

Result: 제안된 프레임워크는 비영향적인 연소 작업에서 5-6회 반복 내에 수렴하며, 인간 전문가 구현과 일치하고 평균 오류는 $3.1	imes10^{-3}$ %로 나타났다. 또한, $	extsim 33.4$ % 빠른 실행 시간과 $	extsim 30$ % 효율적인 메모리 사용을 기록하였다.

Conclusion: Chain of Unit-Physics 프레임워크는 과학적 코드 생성을 위한 근본적인 원리 분석을 포함하여 제로샷 코드 정확도를 개선할 것으로 기대된다.

Abstract: Agentic large language models are proposed as autonomous code generators for scientific computing, yet their reliability in high-stakes problems remains unclear. Developing computational scientific software from natural-language queries remains challenging broadly due to (a) sparse representation of domain codes during training and (b) the limited feasibility of RLHF with a small expert community. To address these limitations, this work conceptualizes an inverse approach to code design, embodied in the Chain of Unit-Physics framework: a first-principles (or primitives)-centric, multi-agent system in which human expert knowledge is encoded as unit-physics tests that explicitly constrain code generation. The framework is evaluated on a nontrivial combustion task, used here as a representative benchmark for scientific problem with realistic physical constraints. Closed-weight systems and code-focused agentic variants fail to produce correct end-to-end solvers, despite tool and web access, exhibiting four recurrent error classes: interface (syntax/API) hallucinations, overconfident assumptions, numerical/physical incoherence, and configuration fragility. Open-weight models with chain-of-thought (CoT) decoding reduce interface errors but still yield incorrect solutions. On the benchmark task, the proposed framework converges within 5-6 iterations, matches the human-expert implementation (mean error of $3.1\times10^{-3}$ %), with a $\sim$33.4 % faster runtime and a $\sim$30 % efficient memory usage at a cost comparable to mid-sized commercial APIs, yielding a practical template for physics-grounded scientific code generation. As datasets and models evolve, zero-shot code accuracy will improve; however, the Chain of Unit-Physics framework goes further by embedding first-principles analysis that is foundational to scientific codes.

</details>


### [79] [Agent-Kernel: A MicroKernel Multi-Agent System Framework for Adaptive Social Simulation Powered by LLMs](https://arxiv.org/abs/2512.01610)
*Yuren Mao,Peigen Liu,Xinjian Wang,Rui Ding,Jing Miao,Hui Zou,Mingjie Qi,Wanxiang Luo,Longbin Lai,Kai Wang,Zhengping Qian,Peilun Yang,Yunjun Gao,Ying Zhang*

Main category: cs.MA

TL;DR: Agent-Kernel이라는 새로운 프레임워크를 통해 대규모 사회 시뮬레이션의 한계를 극복하고 agent의 변화를 효과적으로 관리할 수 있는 솔루션을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 다중 에이전트 시스템 개발 프레임워크는 적응성, 구성 가능성, 신뢰성 및 코드 재사용성의 한계로 인해 대규모 시뮬레이션 개발을 지원하지 못하고 있다.

Method: Agent-Kernel은 사회 중심의 모듈식 마이크로커널 아키텍처에 기반하여 코어 시스템 기능과 시뮬레이션 논리를 분리하고 인지 프로세스와 물리적 환경 및 행동 실행을 분리한다.

Result: 우리는 Agent-Kernel의 우수성을 두 가지 응용 프로그램을 통해 검증했다: 우주 25(마우스 유토피아) 실험의 시뮬레이션과 10,000명의 이질적 에이전트(학생 및 교수 포함)를 조정하는 장면으로 진행된 저장대학교 캠퍼스 생활 대규모 시뮬레이션.

Conclusion: Agent-Kernel은 뛰어난 적응성, 구성 가능성, 신뢰성 및 재사용성을 통해 큰 규모의 복잡한 사회 시뮬레이션을 효과적으로 수행할 수 있는 가능성을 보여준다.

Abstract: Multi-Agent System (MAS) developing frameworks serve as the foundational infrastructure for social simulations powered by Large Language Models (LLMs). However, existing frameworks fail to adequately support large-scale simulation development due to inherent limitations in adaptability, configurability, reliability, and code reusability. For example, they cannot simulate a society where the agent population and profiles change over time. To fill this gap, we propose Agent-Kernel, a framework built upon a novel society-centric modular microkernel architecture. It decouples core system functions from simulation logic and separates cognitive processes from physical environments and action execution. Consequently, Agent-Kernel achieves superior adaptability, configurability, reliability, and reusability. We validate the framework's superiority through two distinct applications: a simulation of the Universe 25 (Mouse Utopia) experiment, which demonstrates the handling of rapid population dynamics from birth to death; and a large-scale simulation of the Zhejiang University Campus Life, successfully coordinating 10,000 heterogeneous agents, including students and faculty.

</details>
