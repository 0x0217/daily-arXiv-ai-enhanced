<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 7]
- [cs.AI](#cs.AI) [Total: 12]
- [cs.LG](#cs.LG) [Total: 14]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing](https://arxiv.org/abs/2601.00042)
*Manish Bhatt,Adrian Wood,Idan Habler,Ammar Al-Kahfah*

Main category: cs.CR

TL;DR: 생산 LLM 에이전트의 도구 사용 능력은 안전 교육에도 불구하고 보안 테스트가 필요하다. 28회의 실험을 통해 GPT-4o-mini를 평가한 결과, 무작위 시드 변동성이 알고리즘 매개변수를 압도하며, 보상 조정이 성능에 부정적인 영향을 미치고 단순 상태 서명이 복잡한 것보다 우수함을 발견하였다.


<details>
  <summary>Details</summary>
Motivation: 생산 LLM 에이전트는 도구를 사용하는 능력이 필요하며, 이는 안전 교육과는 별도로 보안 테스트가 필수적임을 시사한다.

Method: Go-Explore를 활용하여 28회의 실험에서 GPT-4o-mini를 평가하였다.

Result: 무작위 시드 변동성이 알고리즘 매개변수보다 더 많은 영향을 미쳐 결과에서 8배의 차이를 보였으며, 보상 조정이 거의 모든 경우에서 성능 하락을 초래했다.

Conclusion: 이러한 결과는 시드 변동성과 목표 도메인 지식이 안전 교육을 받은 모델을 테스트할 때 알고리즘의 복잡성을 초월할 수 있음을 시사한다.

Abstract: Production LLM agents with tool-using capabilities require security testing despite their safety training. We adapt Go-Explore to evaluate GPT-4o-mini across 28 experimental runs spanning six research questions. We find that random-seed variance dominates algorithmic parameters, yielding an 8x spread in outcomes; single-seed comparisons are unreliable, while multi-seed averaging materially reduces variance in our setup. Reward shaping consistently harms performance, causing exploration collapse in 94% of runs or producing 18 false positives with zero verified attacks. In our environment, simple state signatures outperform complex ones. For comprehensive security testing, ensembles provide attack-type diversity, whereas single agents optimize coverage within a given attack type. Overall, these results suggest that seed variance and targeted domain knowledge can outweigh algorithmic sophistication when testing safety-trained models.

</details>


### [2] [Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak](https://arxiv.org/abs/2601.00213)
*Haoran Gu,Handing Wang,Yi Mei,Mengjie Zhang,Yaochu Jin*

Main category: cs.CR

TL;DR: 대규모 언어 모델의 안전성과 취약성을 다룬 연구로, 특히 자동화된 알고리즘 설계에 대한 연구가 부족함을 지적하고, 새로운 벤치마크와 탈옥 방법을 제안함.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)의 사용 증가에 따른 오용 위험과 안전 문제에 대한 우려가 커지고 있음. 자동화된 알고리즘 설계에서의 취약성이 충분히 연구되지 않음.

Method: MalOptBench라는 60개의 악성 최적화 알고리즘 요청으로 구성된 벤치마크를 도입하고, 이를 위한 탈옥 방법인 MOBjailbreak을 제안함.

Result: 13개의 주류 LLM을 평가한 결과, 대부분의 모델이 공격에 매우 취약하며, 평균 공격 성공률은 83.59%로 나타남. 무해한 프롬프트에 대한 평균 해악 점수는 5점 만점에 4.28이며, MOBjailbreak 하에서는 거의 완전한 실패를 보임.

Conclusion: LLM의 알고리즘 설계에서 오용 방지를 강화하기 위한 기술 정렬의 필요성이 시급함을 강조함.

Abstract: The widespread deployment of large language models (LLMs) has raised growing concerns about their misuse risks and associated safety issues. While prior studies have examined the safety of LLMs in general usage, code generation, and agent-based applications, their vulnerabilities in automated algorithm design remain underexplored. To fill this gap, this study investigates this overlooked safety vulnerability, with a particular focus on intelligent optimization algorithm design, given its prevalent use in complex decision-making scenarios. We introduce MalOptBench, a benchmark consisting of 60 malicious optimization algorithm requests, and propose MOBjailbreak, a jailbreak method tailored for this scenario. Through extensive evaluation of 13 mainstream LLMs including the latest GPT-5 and DeepSeek-V3.1, we reveal that most models remain highly susceptible to such attacks, with an average attack success rate of 83.59% and an average harmfulness score of 4.28 out of 5 on original harmful prompts, and near-complete failure under MOBjailbreak. Furthermore, we assess state-of-the-art plug-and-play defenses that can be applied to closed-source models, and find that they are only marginally effective against MOBjailbreak and prone to exaggerated safety behaviors. These findings highlight the urgent need for stronger alignment techniques to safeguard LLMs against misuse in algorithm design.

</details>


### [3] [PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices](https://arxiv.org/abs/2601.00367)
*Nandish Chattopadhyay,Abdul Basit,Amira Guesmi,Muhammad Abdullah Hanif,Bassem Ouni,Muhammad Shafique*

Main category: cs.CR

TL;DR: PatchBlock은 EdgeAI 애플리케이션에서 패치 기반 적대적 공격을 탐지하고 중화하기 위해 설계된 경량 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 자원 제약이 있는 기기에서 실시간 추론을 위해 EdgeAI 애플리케이션에서 머신러닝 모델의 신뢰할 수 있는 배포에 대한 도전.

Method: Outlier detection과 차원 축소를 사용하여 이미지 내 적대적 패치의 영향을 탐지하고 억제하는 세 단계 파이프라인으로 구성된 PatchBlock.

Result: 여러 신경망 아키텍처, 벤치마크 데이터 세트 및 다양한 엣지 디바이스에 대한 평가에서 PatchBlock은 강력한 패치 공격 하에서도 모델의 정확도를 최대 77% 복구하였다.

Conclusion: PatchBlock은 효율성 측면에서 최신 방어보다 우수하고, EdgeAI 애플리케이션에 적합하다.

Abstract: Adversarial attacks pose a significant challenge to the reliable deployment of machine learning models in EdgeAI applications, such as autonomous driving and surveillance, which rely on resource-constrained devices for real-time inference. Among these, patch-based adversarial attacks, where small malicious patches (e.g., stickers) are applied to objects, can deceive neural networks into making incorrect predictions with potentially severe consequences. In this paper, we present PatchBlock, a lightweight framework designed to detect and neutralize adversarial patches in images. Leveraging outlier detection and dimensionality reduction, PatchBlock identifies regions affected by adversarial noise and suppresses their impact. It operates as a pre-processing module at the sensor level, efficiently running on CPUs in parallel with GPU inference, thus preserving system throughput while avoiding additional GPU overhead. The framework follows a three-stage pipeline: splitting the input into chunks (Chunking), detecting anomalous regions via a redesigned isolation forest with targeted cuts for faster convergence (Separating), and applying dimensionality reduction on the identified outliers (Mitigating). PatchBlock is both model- and patch-agnostic, can be retrofitted to existing pipelines, and integrates seamlessly between sensor inputs and downstream models. Evaluations across multiple neural architectures, benchmark datasets, attack types, and diverse edge devices demonstrate that PatchBlock consistently improves robustness, recovering up to 77% of model accuracy under strong patch attacks such as the Google Adversarial Patch, while maintaining high portability and minimal clean accuracy loss. Additionally, PatchBlock outperforms the state-of-the-art defenses in efficiency, in terms of computation time and energy consumption per sample, making it suitable for EdgeAI applications.

</details>


### [4] [LLM-Powered Analysis of IoT User Reviews: Tracking and Ranking Security and Privacy Concerns](https://arxiv.org/abs/2601.00372)
*Taufiq Islam Protick,Sai Teja Peddinti,Nina Taft,Anupam Das*

Main category: cs.CR

TL;DR: 이 연구는 IoT 사용자의 보안 및 개인 정보 보호 우려를 분석하여, 자동화된 파이프라인을 통해 Amazon IoT 리뷰를 분류하고 관리하는 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: IoT 사용자의 보안 및 개인 정보 보호 우려를 이해하는 것은 개발자와 사용자 모두에게 이점을 제공한다.

Method: GPT-3.5-Turbo를 미세 조정하여 Classifier-Rationalizer-Categorizer 및 Thematic Mapper라는 두 가지 모델을 구축하는 자동화된 파이프라인을 개발했다.

Result: 우리의 파이프라인은 97% 이상의 정확도와 재현율을 달성하며, 피트니스 트래커, 스마트 스피커, 카메라에 대한 91K Amazon 리뷰에 적용되어 보안 카메라가 10%로 가장 높은 S&P 우려를 포함하고 있다는 것을 발견했다.

Conclusion: 모든 장치 유형에서 사용자는 수집되고 공유되는 데이터에 대한 보다 정확한 통제를 지속적으로 요구하며, 사용자 간의 상호 작용에 대한 문제도 발견되었다.

Abstract: Being able to understand the security and privacy (S&P) concerns of IoT users brings benefits to both developers and users. To learn about users' views, we examine Amazon IoT reviews - one of the biggest IoT markets. This work presents a state-of-the-art methodology to identify and categorize reviews in which users express S&P concerns. We developed an automated pipeline by fine-tuning GPT-3.5-Turbo to build two models: the Classifier-Rationalizer-Categorizer and the Thematic Mapper. By leveraging dynamic few-shot prompting and the model's large context size, our pipeline achieved over 97% precision and recall, significantly outperforming keyword-based and classical ML methods. We applied our pipeline to 91K Amazon reviews about fitness trackers, smart speakers and cameras, over multiple years. We found that on average 5% contained S&P concerns, while security camera exhibited the highest prevalence at 10%. Our method detected significantly more S&P-relevant reviews than prior works: 15x more for fitness trackers, 29% more for smart speakers, and 70% more for cameras. Our longitudinal analysis reveals that concerns like surveillance and data control have persisted for years, suggesting limited industry progress. We demonstrate that across all device types, users consistently demand more precise control over what data is collected and shared. We uncover challenges in multi-user and multi-device interactions, identifying two previously unreported themes concerning inadequate controls for account separation and data access. These findings, ranging from broad persistent trends to specific instances of customer loss, offer actionable insights for developers to improve user satisfaction and trust.

</details>


### [5] [Security in the Age of AI Teammates: An Empirical Study of Agentic Pull Requests on GitHub](https://arxiv.org/abs/2601.00477)
*Mohammed Latif Siddiq,Xinye Zhao,Vinicius Carvalho Lopes,Beatrice Casey,Joanna C. S. Santos*

Main category: cs.CR

TL;DR: 이 연구는 자율 코딩 에이전트가 소프트웨어 보안에 기여하는 방식을 체계적으로 분석하고, 이들이 작성한 PR의 검토 및 수용 방식, PR 거부와 관련된 신호를 조사한다.


<details>
  <summary>Details</summary>
Motivation: 자율 코딩 에이전트의 사용이 증가함에 따라 소프트웨어 보안에 미치는 영향을 이해하고자 한다.

Method: AIDev 데이터셋을 활용하여 33,000개 이상의 PR을 분석하고, 보안 관련 PR을 식별한 후 검증을 거쳐 1,293개의 보안 관련 에이전트 PR을 확보한다.

Result: 보안 관련 에이전트 PR은 전체 활동의 약 4%를 차지하며, 주로 지원적 보안 강화 활동을 수행하고, PR의 병합률과 검토 지연이 보안 관련 PR에서 낮은 것으로 나타났다.

Conclusion: PR 거부는 명시적 보안 주제보다 PR의 복잡성과 장황함과 더 강하게 연관된다.

Abstract: Autonomous coding agents are increasingly deployed as AI teammates in modern software engineering, independently authoring pull requests (PRs) that modify production code at scale. This study aims to systematically characterize how autonomous coding agents contribute to software security in practice, how these security-related contributions are reviewed and accepted, and which observable signals are associated with PR rejection. We conduct a large-scale empirical analysis of agent-authored PRs using the AIDev dataset, comprising of over 33,000 curated PRs from popular GitHub repositories. Security-relevant PRs are identified using a keyword filtering strategy, followed by manual validation, resulting in 1,293 confirmed security-related agentic-PRs. We then analyze prevalence, acceptance outcomes, and review latency across autonomous agents, programming ecosystems, and types of code changes. Moreover, we apply qualitative open coding to identify recurring security-related actions and underlying intents, and examine review metadata to identify early signals associated with PR rejection. Security-related Agentic-PRs constitute a meaningful share of agent activity (approximately 4\%). Rather than focusing solely on narrow vulnerability fixes, agents most frequently perform supportive security hardening activities, including testing, documentation, configuration, and improved error handling. Compared to non-security PRs, security-related Agentic-PRs exhibit lower merge rates and longer review latency, reflecting heightened human scrutiny, with variation across agents and programming ecosystems. PR rejection is more strongly associated with PR complexity and verbosity than with explicit security topics.

</details>


### [6] [Cyberscurity Threats and Defense Mechanisms in IoT network](https://arxiv.org/abs/2601.00556)
*Trung Dao,Minh Nguyen,Son Do,Hoang Tran*

Main category: cs.CR

TL;DR: 이 논문은 IoT 기술의 복잡한 사이버 보안 문제를 분석하며, 네트워크 및 애플리케이션 계층의 통합에 초점을 맞추고 있습니다.


<details>
  <summary>Details</summary>
Motivation: IoT 기술의 급속한 확산으로 사이버 보안 문제의 복잡성이 증가하고 있습니다.

Method: 2009년부터 2024년까지 발행된 59개의 학술 기사를 통합 리뷰 방법론을 통해 분석했습니다.

Result: 중요한 위협 카테고리와 AI, 블록체인, 제로 트러스트 아키텍처를 활용한 방어 접근 방식을 식별했습니다.

Conclusion: 새로운 다섯 겹의 IoT 모델을 제안하고 향후 연구 방향을 논의합니다.

Abstract: The rapid proliferation of Internet of Things (IoT) technologies, projected to exceed 30 billion interconnected devices by 2030, has significantly escalated the complexity of cybersecurity challenges. This survey aims to provide a comprehensive analysis of vulnerabilities, threats, and defense mechanisms, specifically focusing on the integration of network and application layers within real-time monitoring and decision-making systems. Employing an integrative review methodology, 59 scholarly articles published between 2009 and 2024 were selected from databases such as IEEE Xplore, ScienceDirect, and PubMed, utilizing keywords related to IoT vulnerabilities and security attacks. Key findings identify critical threat categories, including sensor vulnerabilities, Denial-of-Service (DoS) attacks, and public cloud insecurity. Conversely, the study highlights advanced defense approaches leveraging Artificial Intelligence (AI) for anomaly detection, Blockchain for decentralized trust, and Zero Trust Architecture (ZTA) for continuous verification. This paper contributes a novel five-layer IoT model and outlines future research directions involving quantum computing and 6G networks to bolster IoT ecosystem resilience.

</details>


### [7] [Toward a Dynamic Intellectual Property Protection Model in High-Growth SMEs](https://arxiv.org/abs/2601.00572)
*Sam Pitruzzello,Sean Maynard,Atif Ahmad*

Main category: cs.CR

TL;DR: 이 논문은 고성장 중소기업(HG-SMEs)이 빠른 성장 기간 동안 지적 재산(IP) 보호와 개방형 혁신 간의 균형을 맞추는 데 직면한 어려움을 다룬다.


<details>
  <summary>Details</summary>
Motivation: HG-SMEs는 성공을 이끄는 귀중한 IP 자산을 개발하지만, 자원 제약과 확장 요구 사이에서 IP 도난 및 데이터 유출과 관련된 사이버 보안 문제로 어려움을 겪는다.

Method: Dynamic Capabilities(DC), Knowledge-based View(KBV) 및 개방형 혁신 이론적 프레임워크를 바탕으로 HG-SMEs가 귀중한 IP 자산을 효과적으로 관리할 수 있도록 안내하는 개념적 프레임워크를 소개한다.

Result: 이 연구 진행 중인 논문은 모델을 검증하고 개선하기 위한 질적 방법론을 개략적으로 설명한다.

Conclusion: 우리는 HG-SMEs가 사이버 보안을 관리하여 귀중한 IP 자산을 보호하는 방법에 대한 연구 질문을 다룸으로써, 강력한 IP 보호와 협력 혁신 간의 긴장을 탐색하는 고성장 기술 중심 기업을 위한 실질적인 지침을 제공하는 것을 목표로 한다.

Abstract: This paper addresses the challenges faced by High-Growth Small-to-Medium Enterprises (HG-SMEs) in balancing intellectual property (IP) protection with open innovation during periods of rapid growth. Despite developing valuable IP assets that drive success, HG-SMEs often struggle with cybersecurity concerns related to IP theft and data exfiltration amidst resource constraints and the competing demands of expansion. We examine the intersection of cybersecurity, IP protection and rapid scaling - an area currently underexplored in existing literature. Drawing on Dynamic Capabilities (DC), Knowledge-based View (KBV) and open innovation theoretical frameworks, we introduce a conceptual framework to guide HG-SMEs in effectively managing valuable IP assets. This research-in-progress paper outlines a qualitative methodology to validate and refine the model. By addressing the research question of how HG-SMEs manage cybersecurity to protect valuable IP assets, we aim to provide practical guidance for high-growth, technology-driven companies navigating the tension between robust IP protection and collaborative innovation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization](https://arxiv.org/abs/2601.00290)
*Sixue Xing,Xuanye Xia,Kerui Wu,Meng Jiang,Jintai Chen,Tianfan Fu*

Main category: cs.AI

TL;DR: 임상 시험 실패는 약물 개발에서 주요 병목 현상으로 남아 있으며, 프로토콜 설계의 사소한 결함이 결과에 심각한 영향을 미칠 수 있다. 본 논문은 임상 시험의 반복적인 프로토콜 재설계 문제로 접근하는 ClinicalReTrial이라는 자가 진화 AI 에이전트 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 임상 시험 실패는 약물 개발에서의 주요 병목 현상이며, 프로토콜 설계의 작은 결함이 결과를 심각하게 손상시킬 수 있다. 기존 AI 방법들은 실패를 예측하는 데 강력한 성능을 보이지만, 이를 개선하기 위한 구체적인 해결책을 제시하지 못한다.

Method: ClinicalReTrial은 실패 진단, 안전성을 고려한 수정, 후보 평가를 포함한 폐쇄 루프 기반의 보상 최적화 프레임워크로 통합된다. 이 프레임워크는 결과 예측 모델을 시뮬레이션 환경으로 활용하여 프로토콜 수정의 저비용 평가를 가능하게 하고, 지속적인 자기 개선을 위한 강력한 보상 신호를 제공한다.

Result: ClinicalReTrial은 83.3%의 시험 프로토콜을 개선하며 평균 성공 확률을 5.7% 높인다. 또한, 회고적 사례 연구를 통해 발견된 재설계 전략과 실제 임상 시험 수정 간의 강한 일치를 입증하였다.

Conclusion: 이 연구는 ClinicalReTrial이 임상 시험 프로토콜의 성공률 향상에 기여할 수 있음을 나타낸다.

Abstract: Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.

</details>


### [9] [Toward a Physical Theory of Intelligence](https://arxiv.org/abs/2601.00021)
*Peter David Fagan*

Main category: cs.AI

TL;DR: 비가역적 정보 처리에 기반한 물리적 지능 이론을 제시하며, 지능형 시스템을 목표 지향 작업으로 정보를 변환하는 결합된 에이전트-환경 프로세스로 모델링한다.


<details>
  <summary>Details</summary>
Motivation: 정보 및 물리적 상태 간의 연결을 정의하고, 지능을 물리적 현상으로 통합하기 위해 새로운 이론적 틀을 제공하기 위해서다.

Method: 보존 법칙에 의해 제약된 시스템에서 메타 안정형 매력 지역에 대한 부호화가 이루어지며, 지능은 처리된 정보의 순수 나트당 생성된 목표 지향 작업의 양으로 정의된다.

Result: 이 틀을 통해 정보 수집, 비가역적 계산 및 작업 추출에 대한 물리적 제약의 위계가 도출되며, 생물학적 시스템의 사례를 분석하여 뇌가 예측된 효율적 작업 영역에 위치하게 된다.

Conclusion: 물리적으로 실체화된 지능형 시스템은 불완전성 현상과 유사한 본질적 인식적 한계를 가진다.

Abstract: We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.

</details>


### [10] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt는 분산 컴퓨팅 연속 시스템에서 복원력을 달성하기 위한 생물학적 자가 치유 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 인간 생물학적 시스템의 놀라운 회복력에 영감을 받아, 이 논문은 분산 컴퓨팅 연속 시스템에서 복원력을 달성하고자 하는 self-healing 프레임워크를 제안한다.

Method: ReCiSt는 생물학의 응고, 염증, 증식 및 재형성의 단계를 컴퓨팅 계층인 억제, 진단, 메타 인지 및 지식으로 재구성하여 동작한다. 이러한 네 개의 계층은 언어 모델 기반 에이전트를 통해 자율적인 결함 격리, 인과 진단, 적응 회복, 장기 지식 통합을 수행한다.

Result: ReCiSt 프레임워크는 공공 결함 데이터 세트를 사용하여 여러 언어 모델에서 평가되었으며, 유사한 접근 방식이 부족하여 기준 비교는 포함되지 않았다. 그럼에도 불구하고, 다양한 언어 모델 하에서 평가된 결과는 ReCiSt의 자가 치유 능력을 수십 초 내에 최소 10%의 에이전트 CPU 사용으로 확인하였다.

Conclusion: 우리의 결과는 회복력을 달성하는 데 있어 불확실성을 극복하고 호출된 마이크로 에이전트의 양을 분석하는 깊이를 보여주었다.

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [11] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 이 논문은 인디언 루미의 13장 변형을 위한 전략적 플레이를 위한 규칙 기반 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 클래식 인디언 루미의 13장 변형에서 플레이어들이 직면하는 불완전한 정보 상황에서 전략적 결정을 지원하기 위해 필요하다.

Method: MinDist라는 새로운 핸드 평가 메트릭을 통해 핸드와 가장 가까운 유효 구성 간의 편집 거리를 정량화하고, 이를 바탕으로 MinScore 알고리즘에서 파생된 효율적인 알고리즘을 설계한다.

Result: MinDist 기반 에이전트들이 전통적인 휴리스틱에 비해 우수한 승률을 보인다.

Conclusion: 이 결과는 알고리즘적 루미 전략 설계에 있어 공식적이고 해석 가능한 단계를 제공합니다.

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [12] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 이 연구는 제너레이티브 AI 시스템이 지역적 형태에 내재된 건축 지능을 어떻게 해석하는지를 조사한다.


<details>
  <summary>Details</summary>
Motivation: 본 연구는 지역적 형태에 내재된 건축 지능의 해석 방식을 규명하고자 한다.

Method: 이란 비둘기 탑을 사례 연구로 활용하여 세 가지 확산 모델인 Midjourney v6, DALL-E 3, Stable Diffusion XL(SDXL) 기반의 DreamStudio를 세 가지 프롬프트 단계(참조, 적응, 추측)에서 실험한다.

Result: AI는 기하학적 패턴을 신뢰성 있게 재현하지만, 재료 및 기후적 추론에서는 오해가 발생한다. 참조 이미지가 사실성을 향상시키지만 창의성을 제한하며, 참조에서 벗어날 경우 창의적이지만 문화적으로 애매한 결과를 초래한다.

Conclusion: 결과는 시각적 유사성과 건축적 추론 사이의 경계를 정의하며, 컴퓨테이셔널 지역적 추론을 AI가 전통적인 디자인 지능을 인식, 왜곡 및 재구상하는 방식을 분석하기 위한 프레임워크로 설정한다.

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [13] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 이 논문에서는 원시 텍스트에서 인과 피드백 퍼지 인지 맵(FCM)을 추출하는 대규모 언어 모델(LLM) 에이전트를 설계하였습니다.


<details>
  <summary>Details</summary>
Motivation: 인과 추출 프로세스의 자율성을 높이기 위해 LLM의 세미 자율성을 최대로 활용

Method: 세밀하게 조정된 세 단계의 시스템 명령어를 통해 텍스트에서 주요 명사 및 명사구를 추출하고, 이들 명사 및 명사구에서 FCM 개념 노드를 추출하며, FCM 노드 간의 부분적 또는 퍼지 인과 엣지를 추출하거나 추론합니다.

Result: 이 과정에서 만들어진 FCM 동적 시스템은 인간이 생성한 FCM과 동일한 균형 한계 주기로 수렴하였으며, 인간 생성 FCM은 노드와 엣지의 수에서 차이가 있었습니다.

Conclusion: 혼합 FCM은 주요 혼합 구성 요소의 평형을 흡수함과 동시에 새로운 평형을 생성하여 근본적인 인과적 동적 시스템을 더 잘 근사합니다.

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [14] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLMs)을 사용한 재고 관리 최적화의 한계를 다루는 연구로, 새로운 하이브리드 에이전트 프레임워크를 제안하여 결과를 개선함.


<details>
  <summary>Details</summary>
Motivation: 소규모 및 중소기업의 재고 관리 최적화 문제를 해결하고자 함.

Method: 하이브리드 에이전트 프레임워크를 제안하여 LLM을 지능적 인터페이스로 활용, 자연어에서 파라미터 추출 및 결과 해석을 수행함.

Result: 하이브리드 에이전트 프레임워크를 적용했을 때, 총 재고 비용이 32.1% 감소하였음.

Conclusion: LLM은 운영 연구의 대체물이 아니라 비전문가가 접근 가능한 자연어 인터페이스로 자리매김함.

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [15] [FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems](https://arxiv.org/abs/2601.00227)
*Shanli Xing,Yiyan Zhai,Alexander Jiang,Yixin Dong,Yong Wu,Zihao Ye,Charlie Ruan,Yingyi Huang,Yineng Zhang,Liangsheng Yin,Aksara Bayyapu,Luis Ceze,Tianqi Chen*

Main category: cs.AI

TL;DR: FlashInfer-Bench는 AI가 생성한 GPU 커널을 실제 시스템에 통합하는 문제를 해결하기 위한 표준화된 프레임워크를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: AI가 생성한 GPU 커널을 실제 시스템에 통합하는 도전 과제를 해결하기 위한 필요성이 있다.

Method: FlashInfer-Bench는 커널 생성, 성능 평가, 배포를 연결하는 폐쇄 루프 프레임워크를 설정하며, FlashInfer Trace를 통해 커널 정의 및 평가를 통합하여 에이전트와 시스템 간의 일관된 통신을 가능하게 합니다.

Result: FlashInfer-Bench는 커널 성능을 평가하고 GPU 프로그래밍 언어 간의 트레이드오프를 비교하며, AI가 생성한 커널의 지속적인 개선 경로를 수립합니다.

Conclusion: FlashInfer-Bench는 대규모 LLM 추론에 AI가 생성한 커널을 배포하기 위한 실용적이고 재현 가능한 경로를 구축합니다.

Abstract: Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.

</details>


### [16] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 본 연구에서는 LLM 기반 에이전트가 인간과의 경계에서 발생할 수 있는 집단 간 편향을 다루고 있으며, 이를 통해 인간-규범 스크립트를 방해하는 Belief Poisoning Attack (BPA)의 개념을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 인구통계학적 편향뿐만 아니라 최소한의 경계에서 발생하는 집단 간 편향을 나타낼 수 있음을 이해하기 위함이다.

Method: 명시적인 보상 거래를 기반으로 한 제어된 다중 에이전트 사회 시뮬레이션을 통해 최소 집단 신호하에 에이전트의 집단 간 편향을 측정하였다.

Result: 에이전트는 최소한의 집단 신호에서도 일관된 집단 간 편향을 보이며, 인간으로 프레이밍된 일부 상대방이 있을 때 이 편향이 완화되지만, 이는 인간이 존재한다고 믿을 때만 활성화되는 인간-규범 스크립트에 기인한다.

Conclusion: BPA는 인간-규범 스크립트를 억제하고 인간에 대한 외부 집단 편향을 재활성화하는 새로운 공격 방법으로, 이를 방어하기 위한 실용적인 완화 전략도 논의하였다.

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [17] [Multiagent Reinforcement Learning for Liquidity Games](https://arxiv.org/abs/2601.00324)
*Alicia Vidler,Gal A. Kaminka*

Main category: cs.AI

TL;DR: 이 논문은 유동성을 최적화하는 독립적인 거래자들로 구성된 집단의 행동이 전체 시장 유동성에 기여할 수 있는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 금융 시장의 유동성 모델링에 스웜 방법을 적용하고, 스웜 분석에서 금융 분석 기법을 사용하는 것이 두 연구 분야 모두의 발전 가능성을 가지고 있습니다.

Method: 유동성 게임과 합리적 스웜을 통합하여, 거래자가 집단적으로 시장 유동성 제공을 목표로 하면서도 개별 독립성을 유지할 수 있는 이론적 틀을 제공합니다. 마르코프 팀 게임 프레임워크 내에서 차등 보상을 사용하여, 개별적으로 유동성을 극대화하는 행동이 조정이나 공모 없이도 전체 시장 유동성에 기여함을 보여줍니다.

Result: 금융 스웜 모델은 독립적인 에이전트들이 개별 수익성과 집단 시장 효율성을 동시에 달성할 수 있는 틀을 제공합니다.

Conclusion: 이 연구는 이론적으로 거래자 집단의 행동이 시장의 안정성과 유동성 증진에 기여할 수 있음을 입증했습니다.

Abstract: Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.

</details>


### [18] [Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation](https://arxiv.org/abs/2601.00475)
*Sankar B,Srinidhi Ranjini Girish,Aadya Bharti,Dibakar Sen*

Main category: cs.AI

TL;DR: MIDAS는 분산형 AI 에이전트를 활용하여 인간의 메타인지적 아이디어 생성 방식을 모방하는 새로운 프레임워크로, 참신하고 다양한 아이디어를 생성하는 데 도움을 준다.


<details>
  <summary>Details</summary>
Motivation: 현대 엔지니어링 디자인에서 진정으로 참신하고 다양한 아이디어의 생성은 중요하지만, 이는 초보 설계자에게는 여전히 큰 인지적 도전 과제가 된다.

Method: MIDAS는 기존 '단일 AI' 패러다임을 전문화된 AI 에이전트의 분산 '팀'으로 대체하여 인간의 메타인지적 아이디어 생성 과정을 모방하도록 설계되었다.

Result: 이 시스템은 아이디어를 점진적으로 정제하고 각 아이디어에 대해 기존 솔루션과의 글로벌 참신성 및 이전에 생성된 아이디어와의 로컬 참신성을 평가한다.

Conclusion: MIDAS는 인간 디자이너를 수동적인 필터링에서 참여적이고 적극적이며 협력적인 파트너로 끌어올리며 진정한 인간-AI 공동 창작을 위한 실행 가능하고 발전적인 패러다임을 보여준다.

Abstract: The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.

</details>


### [19] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: AgenticDomiKnowS(ADS)는 사용자가 DomiKnowS의 특정 구문에 익숙하지 않아도 기호 제약을 딥러닝 모델에 통합할 수 있도록 지원하는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기호 제약을 딥러닝 모델에 통합하면 모델이 더 강력하고 해석 가능하며 데이터 효율성을 증가시킬 수 있지만, 이는 여전히 시간 소모적이고 도전적인 작업이다.

Method: AgenticDomiKnowS(ADS)는 자유 형식 작업 설명을 완전한 DomiKnowS 프로그램으로 변환하는 에이전틱 워크플로우를 사용하여 각 DomiKnowS 구성 요소를 별도로 생성하고 테스트한다.

Result: ADS를 통해 경험이 있는 DomiKnowS 사용자와 비사용자가 신경-기호 프로그램을 신속하게 구성할 수 있으며, 개발 시간을 몇 시간에서 10-15분으로 단축할 수 있다.

Conclusion: ADS는 DomiKnowS에 대한 특정 구문에 대한 의존성을 없애어 다양한 사용자가 효과적으로 기호 제약을 딥러닝 모델에 통합할 수 있도록 한다.

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [20] [Yahtzee: Reinforcement Learning Techniques for Stochastic Combinatorial Games](https://arxiv.org/abs/2601.00007)
*Nicholas A. Pape*

Main category: cs.LG

TL;DR: 이 연구는 클래식 주사위 게임인 Yahtzee를 마르코프 결정 과정으로 형식화하고, 다양한 정책 기울기 방법을 사용하여 자가 플레이 에이전트를 훈련하여 성능을 분석합니다.


<details>
  <summary>Details</summary>
Motivation: Yahtzee는 확률적이고 조합적인 구조와 지연 보상을 가지고 있어 중간 규모의 강화 학습 벤치마크로 흥미롭습니다.

Method: Yahtzee를 마르코프 결정 과정(MDP)으로 공식화하고, 다양한 정책 기울기 방법(REINFORCE, Advantage Actor-Critic, Proximal Policy Optimization)을 사용하여 자가 플레이 에이전트를 훈련합니다.

Result: 우리의 에이전트는 100,000회의 평가 게임에서 241.78점의 중앙값 점수를 달성하였으며, 최적 DP 점수인 254.59점에 5.0% 이내에 도달했습니다.

Conclusion: 모든 모델이 상위 보너스 전략을 배우는 데 어려움을 겪었으며, 4의 종류에 대해 과도하게 반응하는 경향이 있음을 보여줍니다.

Abstract: Yahtzee is a classic dice game with a stochastic, combinatorial structure and delayed rewards, making it an interesting mid-scale RL benchmark. While an optimal policy for solitaire Yahtzee can be computed using dynamic programming methods, multiplayer is intractable, motivating approximation methods. We formulate Yahtzee as a Markov Decision Process (MDP), and train self-play agents using various policy gradient methods: REINFORCE, Advantage Actor-Critic (A2C), and Proximal Policy Optimization (PPO), all using a multi-headed network with a shared trunk. We ablate feature and action encodings, architecture, return estimators, and entropy regularization to understand their impact on learning. Under a fixed training budget, REINFORCE and PPO prove sensitive to hyperparameters and fail to reach near-optimal performance, whereas A2C trains robustly across a range of settings. Our agent attains a median score of 241.78 points over 100,000 evaluation games, within 5.0\% of the optimal DP score of 254.59, achieving the upper section bonus and Yahtzee at rates of 24.9\% and 34.1\%, respectively. All models struggle to learn the upper bonus strategy, overindexing on four-of-a-kind's, highlighting persistent long-horizon credit-assignment and exploration challenges.

</details>


### [21] [Exploration in the Limit](https://arxiv.org/abs/2601.00084)
*Brian M. Cho,Nathan Kallus*

Main category: cs.LG

TL;DR: 고정 신뢰도 최적 팔 식별(Best Arm Identification, BAI)에서 정확한 오류 확률을 제어하면서 최적의 옵션을 신속하게 식별하는 것이 목표이다. 기존의 BAI 알고리즘은 실제 환경에서는 충분한 성능을 발휘하지 못하는 경향이 있다. 본 논문에서는 최소 샘플 크기에 대해 비대칭적 오류 제어를 요구하는 완화된 공식을 도입하여, 약한 신호와 높은 유의성을 포함한 현실 세계의 여러 상황에 적합한 BAI 알고리즘을 제안한다. 실험 결과, 우리의 접근법은 평균 샘플 복잡성을 줄이면서도 오류 제어를 유지하는 것으로 나타났다.


<details>
  <summary>Details</summary>
Motivation: BAI 알고리즘이 실제 환경에서 기대에 미치지 못하는 문제를 해결하고자 한다.

Method: 최소 샘플 크기에 비대칭적 오류 제어를 요구하는 완화된 공식을 도입하고, 이를 통해 새로운 BAI 알고리즘을 설계한다.

Result: 평균 샘플 복잡성을 줄이면서도 오류 제어를 유지할 수 있다는 것이다.

Conclusion: 제안한 방법은 유연한 비모수적 결과 분포를 다루고, 개별 수준의 맥락을 완전히 활용할 수 있다.

Abstract: In fixed-confidence best arm identification (BAI), the objective is to quickly identify the optimal option while controlling the probability of error below a desired threshold. Despite the plethora of BAI algorithms, existing methods typically fall short in practical settings, as stringent exact error control requires using loose tail inequalities and/or parametric restrictions. To overcome these limitations, we introduce a relaxed formulation that requires valid error control asymptotically with respect to a minimum sample size. This aligns with many real-world settings that often involve weak signals, high desired significance, and post-experiment inference requirements, all of which necessitate long horizons. This allows us to achieve tighter optimality, while better handling flexible nonparametric outcome distributions and fully leveraging individual-level contexts. We develop a novel asymptotic anytime-valid confidence sequences over arm indices, and we use it to design a new BAI algorithm for our asymptotic framework. Our method flexibly incorporates covariates for variance reduction and ensures approximate error control in fully nonparametric settings. Under mild convergence assumptions, we provide asymptotic bounds on the sample complexity and show the worst-case sample complexity of our approach matches the best-case sample complexity of Gaussian BAI under exact error guarantees and known variances. Experiments suggest our approach reduces average sample complexities while maintaining error control.

</details>


### [22] [GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments](https://arxiv.org/abs/2601.00116)
*Aditya Sai Ellendula,Yi Wang,Minh Nguyen,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: GRL-SNAM은 미지의 환경에서 동시 탐색 및 매핑을 위한 기하학적 강화 학습 프레임워크로, 로봇이 경로를 전혀 알려지지 않은 환경에서 목표로 이동하도록 제어하는 다수의 에이전트의 정책을 설계한다.


<details>
  <summary>Details</summary>
Motivation: SNAM 문제는 미지의 환경에서 로봇의 경로 탐색과 매핑을 효과적으로 수행할 수 있는 방법을 찾기 위한 필요성에서 출발했다.

Method: GRL-SNAM은 센서 데이터를 기반으로 로컬 감지 관찰만을 활용하여 동적 최단 경로 검색 및 발견 과정을 최적화하는 접근 방식을 활용한다.

Result: GRL-SNAM은 두 개의 2D 탐색 작업에서 평가되었으며, 로컬 반응 기준선 및 동일한 감지 제약 조건 하의 글로벌 정책 학습 기준과 비교했을 때, 장애물을 피하면서도 새로운 레이아웃에 일반화되는 고품질 탐색 성능을 보여준다.

Conclusion: 강화된 해밀토니안 업데이트를 통해 지역적 에너지 정제를 통한 최소한의 탐색으로 높은 품질의 탐색이 가능함을 입증한다.

Abstract: We present GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping(SNAM) in unknown environments. A SNAM problem is challenging as it needs to design hierarchical or joint policies of multiple agents that control the movement of a real-life robot towards the goal in mapless environment, i.e. an environment where the map of the environment is not available apriori, and needs to be acquired through sensors. The sensors are invoked from the path learner, i.e. navigator, through active query responses to sensory agents, and along the motion path. GRL-SNAM differs from preemptive navigation algorithms and other reinforcement learning methods by relying exclusively on local sensory observations without constructing a global map. Our approach formulates path navigation and mapping as a dynamic shortest path search and discovery process using controlled Hamiltonian optimization: sensory inputs are translated into local energy landscapes that encode reachability, obstacle barriers, and deformation constraints, while policies for sensing, planning, and reconfiguration evolve stagewise via updating Hamiltonians. A reduced Hamiltonian serves as an adaptive score function, updating kinetic/potential terms, embedding barrier constraints, and continuously refining trajectories as new local information arrives. We evaluate GRL-SNAM on two different 2D navigation tasks. Comparing against local reactive baselines and global policy learning references under identical stagewise sensing constraints, it preserves clearance, generalizes to unseen layouts, and demonstrates that Geometric RL learning via updating Hamiltonians enables high-quality navigation through minimal exploration via local energy refinement rather than extensive global mapping. The code is publicly available on \href{https://github.com/CVC-Lab/GRL-SNAM}{Github}.

</details>


### [23] [Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score](https://arxiv.org/abs/2601.00175)
*Zhuqi Miao,Sujan Ravi,Abdulaziz Ahmed*

Main category: cs.LG

TL;DR: 이 연구는 전자 건강 기록(EHR) 데이터를 활용하여 진단 전에 간경변의 발생 확률을 예측하기 위한 기계 학습 모델을 개발하고 평가한 것입니다.


<details>
  <summary>Details</summary>
Motivation: 간경변의 조기 예측은 환자 관리에 있어 중요하며, 기계 학습 모델이 기존의 FIB-4 스코어와 비교하여 더 나은 성능을 발휘할 수 있는 가능성을 탐구하고자 하였습니다.

Method: 대규모 학술 건강 시스템에서 비식별화된 EHR 데이터를 사용하여 후향적 코호트 연구를 수행하였고, XGBoost 모델을 사용하여 1년, 2년, 3년 예측을 위한 시나리오를 구축하고 성능을 평가하였습니다.

Result: 1년 예측을 위한 3,043명, 2년 예측을 위한 1,981명, 3년 예측을 위한 1,470명의 환자를 포함한 최종 코호트에서, ML 모델이 FIB-4를 일관되게 초과 성과를 보였으며, AUC는 0.81, 0.73, 0.69로 각각 측정되었습니다.

Conclusion: 기계 학습 모델은 간경변의 조기 예측에 있어 전통적인 FIB-4 스코어를 상당히 초과하며, 이는 조기 관리를 위한 임상 워크플로에 통합 가능성을 보여줍니다.

Abstract: Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.

</details>


### [24] [Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings](https://arxiv.org/abs/2601.00186)
*Moirangthem Tiken Singh,Adnan Arif*

Main category: cs.LG

TL;DR: 본 논문은 제한된 대역폭의 통신 시스템에서 의미적 의미를 보존하는 데 필요한 도전 과제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 제한된 대역폭으로 인해 의미적 의미를 보존하는 것이 시급한 도전 과제가 되었습니다.

Method: 적응형 반복 코딩을 통한 차원별 비균일 오류 보호를 달성하는 새로운 강화 학습 프레임워크를 도입합니다.

Result: 1 dB SNR에서 균일한 보호에 비해 6.8% 높은 chrF 점수와 9.3% 더 나은 엔티티 보존을 달성했습니다.

Conclusion: 코드 구조가 의미적 세분성과 일치해야 한다는 점을 확립함으로써 전통적인 채널 코딩 패러다임에 도전했습니다.

Abstract: This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a composite semantic distortion metric that balances global embedding similarity with entity-level preservation, empowering the reinforcement learning agent to allocate protection in a context-aware manner. Experiments show statistically significant gains over uniform protection, achieving 6.8% higher chrF scores and 9.3% better entity preservation at 1 dB SNR. The key innovation of our framework is the demonstration that simple, intelligently allocated repetition coding enables fine-grained semantic protection -- an advantage unattainable with conventional codes such as LDPC or Reed-Solomon. Our findings challenge traditional channel coding paradigms by establishing that code structure must align with semantic granularity. This approach is particularly suited to edge computing and IoT scenarios, where bandwidth is scarce, but semantic fidelity is critical, providing a practical pathway for next-generation semantic-aware networks.

</details>


### [25] [SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification](https://arxiv.org/abs/2601.00189)
*Danial Sharifrazi,Nouman Javed,Mojtaba Mohammadi,Seyede Sana Salehi,Roohallah Alizadehsani,Prasad N. Paradkar,U. Rajendra Acharya,Asim Bhatti*

Main category: cs.LG

TL;DR: 이 논문은 신경 스파이크 패턴의 분류를 위한 새로운 반지도형 GAN 구조인 SSI-GAN을 제안하며, 이는 1-3%의 라벨링된 데이터로도 높은 정확도를 나타낸다.


<details>
  <summary>Details</summary>
Motivation: 아르보바이럴 질병의 주요 전파 매개체인 모기의 신경 스파이크 패턴 분류가 노동 집약적이고 비싼 문제를 해결하고자 한다.

Method: Swin-inspired GAN 구조를 기반으로 하는 SSI-GAN을 개발하여, 변환기 기반 생성기와 함께 분류기를 사용하여 신경 스파이크 기차를 분류한다.

Result: SSI-GAN은 3일 후 감염된 경우 99.93%의 분류 정확도를 달성했으며, 1%의 감독으로 모든 감염 단계에서 높은 정확도를 유지했다.

Conclusion: 이 연구는 표준 감독 방법보다 97-99%의 수작업 라벨링 노력을 줄이며, 스파이크 기반 신경 감염 분류에서 새로운 최적 성능을 나타낸다.

Abstract: Mosquitos are the main transmissive agents of arboviral diseases. Manual classification of their neuronal spike patterns is very labor-intensive and expensive. Most available deep learning solutions require fully labeled spike datasets and highly preprocessed neuronal signals. This reduces the feasibility of mass adoption in actual field scenarios. To address the scarcity of labeled data problems, we propose a new Generative Adversarial Network (GAN) architecture that we call the Semi-supervised Swin-Inspired GAN (SSI-GAN). The Swin-inspired, shifted-window discriminator, together with a transformer-based generator, is used to classify neuronal spike trains and, consequently, detect viral neurotropism. We use a multi-head self-attention model in a flat, window-based transformer discriminator that learns to capture sparser high-frequency spike features. Using just 1 to 3% labeled data, SSI-GAN was trained with more than 15 million spike samples collected at five-time post-infection and recording classification into Zika-infected, dengue-infected, or uninfected categories. Hyperparameters were optimized using the Bayesian Optuna framework, and performance for robustness was validated under fivefold Monte Carlo cross-validation. SSI-GAN reached 99.93% classification accuracy on the third day post-infection with only 3% labeled data. It maintained high accuracy across all stages of infection with just 1% supervision. This shows a 97-99% reduction in manual labeling effort relative to standard supervised approaches at the same performance level. The shifted-window transformer design proposed here beat all baselines by a wide margin and set new best marks in spike-based neuronal infection classification.

</details>


### [26] [Can Optimal Transport Improve Federated Inverse Reinforcement Learning?](https://arxiv.org/abs/2601.00309)
*David Millard,Ali Baheri*

Main category: cs.LG

TL;DR: 이 논문은 다수의 자율 에이전트가 서로 다른 환경에서 공통된 목표를 추구할 때 사용할 수 있는 연합 역 강화 학습을 위한 최적 수송 기반 접근법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 동역학, 개인 정보 보호 제한, 제한된 통신 대역폭으로 인해 자율 에이전트의 데이터를 집계하여 공유 보상 함수를 학습하는 것이 비현실적입니다.

Method: 각 클라이언트는 먼저 최대 엔트로피 IRL을 로컬에서 수행하고, 그에 따라 계산 및 개인 정보 보호 제한을 준수합니다. 그 다음 결과 보상 함수는 기본 기하학적 구조를 고려하여 Wasserstein barycenter를 통해 융합됩니다.

Result: 이 barycentric 융합이 기존의 매개변수 평균화 방법보다 더 신뢰할 수 있는 글로벌 보상 추정치를 제공함을 증명합니다.

Conclusion: 이 연구는 이질적인 에이전트와 환경에 걸쳐 일반화된 공유 보상을 파생하는 원칙적이고 통신 효율적인 프레임워크를 제공합니다.

Abstract: In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.

</details>


### [27] [Imitation from Observations with Trajectory-Level Generative Embeddings](https://arxiv.org/abs/2601.00452)
*Yongtao Qu,Shangzhe Li,Weitong Zhang*

Main category: cs.LG

TL;DR: 본 논문에서는 전문가의 시연이 부족하고 사용 가능한 오프라인 비최적 데이터가 전문가의 행동과 거리가 먼 경우의 오프라인 모방 학습(LfO)을 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 전문가의 행동과 거리가 먼 비최적 데이터로 인해 기존의 분포 일치 방식이 효과적이지 않음.

Method: 오프라인 궤적 데이터로 훈련된 시간 분산 모델의 잠재 공간에서 전문가 상태 밀도를 추정하여 밀집하고 매끄러운 대체 보상을 구성하는 TGE 방식을 제안합니다.

Result: 제안된 접근법은 D4RL 이동 및 조작 벤치마크에서 기존 오프라인 LfO 방법과 일관되게 일치하거나 성능을 초과합니다.

Conclusion: TGE는 오프라인 데이터가 전문가와 분포적으로 다른 경우에도 강력한 학습 신호를 보장합니다.

Abstract: We consider the offline imitation learning from observations (LfO) where the expert demonstrations are scarce and the available offline suboptimal data are far from the expert behavior. Many existing distribution-matching approaches struggle in this regime because they impose strict support constraints and rely on brittle one-step models, making it hard to extract useful signal from imperfect data. To tackle this challenge, we propose TGE, a trajectory-level generative embedding for offline LfO that constructs a dense, smooth surrogate reward by estimating expert state density in the latent space of a temporal diffusion model trained on offline trajectory data. By leveraging the smooth geometry of the learned diffusion embedding, TGE captures long-horizon temporal dynamics and effectively bridges the gap between disjoint supports, ensuring a robust learning signal even when offline data is distributionally distinct from the expert. Empirically, the proposed approach consistently matches or outperforms prior offline LfO methods across a range of D4RL locomotion and manipulation benchmarks.

</details>


### [28] [When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents](https://arxiv.org/abs/2601.00513)
*Laksh Advani*

Main category: cs.LG

TL;DR: 작은 언어 모델을 자율 에이전트로 배포하기 위해서는 그들의 출력뿐만 아니라 추론에 대한 신뢰가 필요하다. 본 연구에서는 올바른 답변의 50-69%가 근본적으로 결점 있는 추론을 포함하고 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 작은 언어 모델을 자율 에이전트로 활용하기 위해서는 이들의 추론에 대한 신뢰가 필요하다.

Method: 10,734개의 추론 흔적 분석을 통해 Reasoning Integrity Score (RIS)를 도입하고, 검색 증강 생성(RAG)의 효과를 평가하였다.

Result: RAG는 추론의 정확성을 7.6% 향상시키고, 메타 인지 개입은 성능을 저하시킨다.

Conclusion: 모델이 잘못된 이유로 올바를 수 있음을 고려할 때, 정확성만으로는 불충분하다는 점을 강조한다.

Abstract: Deploying small language models (7-9B parameters) as autonomous agents requires trust in their reasoning, not just their outputs. We reveal a critical reliability crisis: 50-69\% of correct answers from these models contain fundamentally flawed reasoning -- a ``Right-for-Wrong-Reasons'' phenomenon invisible to standard accuracy metrics. Through analysis of 10,734 reasoning traces across three models and diverse tasks, we introduce the Reasoning Integrity Score (RIS), a process-based metric validated with substantial inter-rater agreement ($κ=0.657$). Conventional practices are challenged by our findings: while retrieval-augmented generation (RAG) significantly improves reasoning integrity (Cohen's $d=0.23$--$0.93$), meta-cognitive interventions like self-critique often harm performance ($d=-0.14$ to $-0.33$) in small models on the evaluated tasks. Mechanistic analysis reveals RAG succeeds by grounding calculations in external evidence, reducing errors by 7.6\%, while meta-cognition amplifies confusion without sufficient model capacity. To enable deployment, verification capabilities are distilled into a neural classifier achieving 0.86 F1-score with 100$\times$ speedup. These results underscore the necessity of process-based verification for trustworthy agents: accuracy alone is dangerously insufficient when models can be right for entirely wrong reasons.

</details>


### [29] [Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI](https://arxiv.org/abs/2601.00516)
*Laksh Advani*

Main category: cs.LG

TL;DR: Trajectory Guard는 작업 궤적 정렬과 순차적 유효성을 동시에 학습하여 계획의 오류를 탐지하는 효과적인 방법이다.


<details>
  <summary>Details</summary>
Motivation: 자율 LLM 에이전트가 생성하는 여러 단계의 행동 계획은 맥락적 불일치나 구조적 비일관성으로 실패할 수 있으며, 기존의 이상 탐지 방법은 이에 적합하지 않다.

Method: Trajectory Guard는 대비 학습을 통해 작업 궤적 정렬을 학습하고 재구성을 통해 순차적 유효성을 학습하는 혼합 손실 함수를 가진 시암 쌍둥이 순환 오토인코더이다.

Result: 우리는 합성 변동 및 보안 감사(RAS-Eval)와 다중 에이전트 시스템(Who&When)에서 실제 실패와 관련된 벤치마크에서 F1 점수 0.88-0.94 및 불균형 외부 벤치마크에서 0.86-0.92의 재현율을 달성했다.

Conclusion: 우리의 접근법은 32ms의 추론 대기 시간으로 LLM Judge 기준보다 17-27배 더 빠르며, 생산 환경에서 실시간 안전 검증을 가능하게 한다.

Abstract: Autonomous LLM agents generate multi-step action plans that can fail due to contextual misalignment or structural incoherence. Existing anomaly detection methods are ill-suited for this challenge: mean-pooling embeddings dilutes anomalous steps, while contrastive-only approaches ignore sequential structure. Standard unsupervised methods on pre-trained embeddings achieve F1-scores no higher than 0.69. We introduce Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss function that jointly learns task-trajectory alignment via contrastive learning and sequential validity via reconstruction. This dual objective enables unified detection of both "wrong plan for this task" and "malformed plan structure." On benchmarks spanning synthetic perturbations and real-world failures from security audits (RAS-Eval) and multi-agent systems (Who\&When), we achieve F1-scores of 0.88-0.94 on balanced sets and recall of 0.86-0.92 on imbalanced external benchmarks. At 32 ms inference latency, our approach runs 17-27$\times$ faster than LLM Judge baselines, enabling real-time safety verification in production deployments.

</details>


### [30] [A Sparse-Attention Deep Learning Model Integrating Heterogeneous Multimodal Features for Parkinson's Disease Severity Profiling](https://arxiv.org/abs/2601.00519)
*Dristi Datta,Tanmoy Debnath,Minh Chau,Manoranjan Paul,Gourab Adhikary,Md Geaur Rahman*

Main category: cs.LG

TL;DR: 이 연구는 파킨슨병의 이질적 표현을 통합 예측 프레임워크 내에서 생물학적 및 임상적 지표를 조합하는 방법을 제안한다. 새로운 Class-Weighted Sparse-Attention Fusion Network (SAFN)를 통해 MRI cortical thickness, MRI volumetric measures, 임상 평가 및 인구 통계 변수들을 통합하여 해석 가능한 멀티모달 프로파일링을 수행하며, 기존 모델의 한계를 극복한다.


<details>
  <summary>Details</summary>
Motivation: 파킨슨병(PD)의 이질적인 특성을 이해하기 위한 통합 예측 프레임워크 내에서 생물학적 및 임상적 지표를 통합해야 할 필요성이 있다.

Method: Class-Weighted Sparse-Attention Fusion Network (SAFN)라는 해석 가능한 딥러닝 프레임워크를 제안하며, 이것은 MRI 피질 두께, MRI 체적 측정, 임상 평가 및 인구 통계 변수를 모드별 인코더와 대칭적 크로스-주의 메커니즘을 사용하여 통합한다.

Result: 703명의 참가자(570명의 PD, 133명의 건강한 대조군)를 대상으로 평가하였으며, SAFN은 0.98 ± 0.02의 정확도와 1.00 ± 0.00의 PR-AUC를 기록하여 기존 기계 학습 및 딥러닝 기준을 초월한다.

Conclusion: SAFN은 신경퇴행성 질병의 계산적 프로파일링을 위한 재현 가능하고 투명한 멀티모달 모델링 패러다임을 제공한다.

Abstract: Characterising the heterogeneous presentation of Parkinson's disease (PD) requires integrating biological and clinical markers within a unified predictive framework. While multimodal data provide complementary information, many existing computational models struggle with interpretability, class imbalance, or effective fusion of high-dimensional imaging and tabular clinical features. To address these limitations, we propose the Class-Weighted Sparse-Attention Fusion Network (SAFN), an interpretable deep learning framework for robust multimodal profiling. SAFN integrates MRI cortical thickness, MRI volumetric measures, clinical assessments, and demographic variables using modality-specific encoders and a symmetric cross-attention mechanism that captures nonlinear interactions between imaging and clinical representations. A sparsity-constrained attention-gating fusion layer dynamically prioritises informative modalities, while a class-balanced focal loss (beta = 0.999, gamma = 1.5) mitigates dataset imbalance without synthetic oversampling. Evaluated on 703 participants (570 PD, 133 healthy controls) from the Parkinson's Progression Markers Initiative using subject-wise five-fold cross-validation, SAFN achieves an accuracy of 0.98 plus or minus 0.02 and a PR-AUC of 1.00 plus or minus 0.00, outperforming established machine learning and deep learning baselines. Interpretability analysis shows a clinically coherent decision process, with approximately 60 percent of predictive weight assigned to clinical assessments, consistent with Movement Disorder Society diagnostic principles. SAFN provides a reproducible and transparent multimodal modelling paradigm for computational profiling of neurodegenerative disease.

</details>


### [31] [Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning](https://arxiv.org/abs/2601.00607)
*Sonia Khetarpaul,P Y Sharan*

Main category: cs.LG

TL;DR: 교통 인프라와 수요를 고려한 택시 배치 최적화를 위한 그래프 기반 강화학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 스마트 시티 교통에서 택시 공급과 승객 수요의 효율적인 매칭을 위해서는 실시간 도시 교통 네트워크 데이터와 이동 패턴의 통합이 필요하다.

Method: 도시 도로 네트워크를 그래프로 모델링하고, Graph Neural Network(GNN) 임베딩을 사용하여 교통 네트워크 내의 시공간적 의존성을 인코딩한다. Q-러닝 에이전트가 이를 활용하여 최적의 택시 핫스팟을 추천한다.

Result: 제안된 모델은 델리 택시 데이터셋에서 승객 대기 시간을 약 56% 단축하고 이동 거리를 38% 줄였다.

Conclusion: 제안한 접근 방식은 다중 모드 교통 시스템에 적응 가능하며 스마트 시티 플랫폼에 통합될 수 있다.

Abstract: In the context of smart city transportation, efficient matching of taxi supply with passenger demand requires real-time integration of urban traffic network data and mobility patterns. Conventional taxi hotspot prediction models often rely solely on historical demand, overlooking dynamic influences such as traffic congestion, road incidents, and public events. This paper presents a traffic-aware, graph-based reinforcement learning (RL) framework for optimal taxi placement in metropolitan environments. The urban road network is modeled as a graph where intersections represent nodes, road segments serve as edges, and node attributes capture historical demand, event proximity, and real-time congestion scores obtained from live traffic APIs. Graph Neural Network (GNN) embeddings are employed to encode spatial-temporal dependencies within the traffic network, which are then used by a Q-learning agent to recommend optimal taxi hotspots. The reward mechanism jointly optimizes passenger waiting time, driver travel distance, and congestion avoidance. Experiments on a simulated Delhi taxi dataset, generated using real geospatial boundaries and historic ride-hailing request patterns, demonstrate that the proposed model reduced passenger waiting time by about 56% and reduced travel distance by 38% compared to baseline stochastic selection. The proposed approach is adaptable to multi-modal transport systems and can be integrated into smart city platforms for real-time urban mobility optimization.

</details>


### [32] [ARISE: Adaptive Reinforcement Integrated with Swarm Exploration](https://arxiv.org/abs/2601.00693)
*Rajiv Chaitanya M,D R Ramesh Babu*

Main category: cs.LG

TL;DR: ARISE는 비정상 보상 및 고차원 정책 문제를 해결하기 위한 경량 강화 학습 프레임워크로, 표준 정책 기법에 군집 기반 탐색 계층을 추가하여 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습에서 비정상 보상이나 고차원 정책으로 인한 효과적인 탐색 문제는 여전히 핵심 도전 과제입니다.

Method: ARISE는 정책 행동과 입자 기반 제안들을 결합하여 각 입자가 행동 공간에서 샘플링된 후보 정책 궤적을 나타내며, 보상 분산 신호를 사용하여 탐색을 적응적으로 조절합니다.

Result: ARISE는 더 어려운 작업에서 상당한 성과를 내며, LunarLander-v3에서 +46%, Hopper-v4에서 +22% 향상되었고, Walker2d와 Ant의 안정성을 유지했습니다.

Conclusion: ARISE는 핵심 알고리즘 구조를 변경하지 않고도 더 탐색적이고 회복력 있는 RL 에이전트를 위한 간단하고 구조에 구애받지 않는 경로를 제공합니다.

Abstract: Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.

</details>


### [33] [Bayesian Inverse Games with High-Dimensional Multi-Modal Observations](https://arxiv.org/abs/2601.00696)
*Yash Jain,Xinjie Liu,Lasse Peters,David Fridovich-Keil,Ufuk Topcu*

Main category: cs.LG

TL;DR: 이 논문은 역 게임 문제를 해결하기 위해 근사 베이지안 추론 접근 방식을 제안하며, 안전한 의사 결정을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 다수의 에이전트 상호작용 시나리오는 비협력 게임으로 자연스럽게 모델링될 수 있지만, 모든 에이전트의 목표를 명시해야 한다는 실질적인 어려움이 있다.

Method: 본 연구에서는 다양한 모달리티의 관찰 데이터를 통해 에이전트의 숨겨진 목표에 대한 베이지안 후방 분포로부터 샘플을 생성할 수 있는 근사 베이지안 추론 접근 방식을 제안한다.

Result: 제안된 프레임워크는 에이전트의 진짜 목표에 대한 라벨이 필요 없이 상호작용 데이터셋에서 구조화된 변분 자동인코더를 훈련시켜 성공적으로 사전 분포와 사후 분포를 학습하였다.

Conclusion: 이 연구는 최대 우도 추정 기반의 역 게임 접근 방식보다 추론 품질을 향상시키며, 효율성을 희생하지 않고도 더 안전한 하류 의사 결정을 가능하게 한다.

Abstract: Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [34] [μACP: A Formal Calculus for Expressive, Resource-Constrained Agent Communication](https://arxiv.org/abs/2601.00219)
*Arnab Mallick,Indraveni Chebolu*

Main category: cs.MA

TL;DR: $μ$ACP는 자원 제약이 있는 환경에서의 표현력 있는 에이전트 통신을 위한 형식적 계산법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 에이전트 통신은 기반적인 문제로, 기존 프로토콜은 자원 제약 환경에서 비효율적이다.

Method: RCAC 모델을 형식화하고, 최소한의 네 동사 기반으로 유한 상태 FIPA 프로토콜을 인코딩할 수 있음을 증명했다.

Result: 시뮬레이션 결과, ACP는 대규모 시스템에서 평균 34ms의 메시지 지연 시간을 기록하였다.

Conclusion: 다음 세대 자원 제약 다중 에이전트 시스템을 위한 엄밀한 기초를 제공하는 통합된 계산법이 제안되었다.

Abstract: Agent communication remains a foundational problem in multi-agent systems: protocols such as FIPA-ACL guarantee semantic richness but are intractable for constrained environments, while lightweight IoT protocols achieve efficiency at the expense of expressiveness. This paper presents $μ$ACP, a formal calculus for expressive agent communication under explicit resource bounds. We formalize the Resource-Constrained Agent Communication (RCAC) model, prove that a minimal four-verb basis \textit{\{PING, TELL, ASK, OBSERVE\}} is suffices to encode finite-state FIPA protocols, and establish tight information-theoretic bounds on message complexity. We further show that $μ$ACP can implement standard consensus under partial synchrony and crash faults, yielding a constructive coordination framework for edge-native agents. Formal verification in TLA$^{+}$ (model checking) and Coq (mechanized invariants) establishes safety and boundedness, and supports liveness under modeled assumptions. Large-scale system simulations confirm ACP achieves a median end-to-end message latency of 34 ms (95th percentile 104 ms) at scale, outperforming prior agent and IoT protocols under severe resource constraints. The main contribution is a unified calculus that reconciles semantic expressiveness with provable efficiency, providing a rigorous foundation for the next generation of resource-constrained multi-agent systems.

</details>


### [35] [Offline Multi-Agent Reinforcement Learning for 6G Communications: Fundamentals, Applications and Future Directions](https://arxiv.org/abs/2601.00321)
*Eslam Eldeeb,Hirley Alves*

Main category: cs.MA

TL;DR: 차세대 무선 기술인 5G 및 6G 네트워크는 차량 집단 주행, 스마트 시티, 원거리 수술과 같은 혁신적인 애플리케이션을 가능하게 하고 있으며, 이에 따라 네트워크는 더욱 복잡해지고 있습니다. 인공지능(AI) 및 머신 러닝(ML), 특히 강화 학습(RL)은 이러한 네트워크의 핵심 요소로 작용하고 있습니다. 하지만 전통적인 온라인 RL 접근법은 비용, 안전성 및 확장성에 한계를 보이고 있습니다. 오프라인 다중 에이전트 강화 학습(MARL)은 미리 수집된 데이터를 활용함으로써 실시간 상호작용의 필요성을 줄이는 유망한 해결책을 제시합니다. 본 논문에서는 안전하고 효율적인 훈련을 보장하는 보수적 Q-학습(CQL) 기반의 새로운 오프라인 MARL 알고리즘을 소개하고, 메타 학습을 통해 동적 환경에 대한 해결책을 제시하며, 무선 자원 관리 및 UAV 네트워크의 사례를 통해 근거를 검증합니다. 우리 연구는 오프라인 MARL의 장점, 한계 및 무선 애플리케이션에서의 미래 방향성을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: 차세대 무선 기술의 발전은 교통 관리, 스마트 시티 구축, 원거리 의료와 같은 혁신적 응용 프로그램을 가능하게 하고 있습니다. 이러한 발전을 지원하기 위해서는 점점 복잡해지는 네트워크 환경에서 효율적인 의사 결정이 필요합니다.

Method: 본 논문에서는 보수적 Q-학습(CQL)을 기반으로 하는 새로운 오프라인 다중 에이전트 강화 학습(MARL) 알고리즘을 제안합니다. 이를 통해 안전하고 효율적인 훈련을 보장하며, 메타 학습을 활용하여 동적 환경에 적응할 수 있도록 합니다.

Result: 본 연구의 결과는 오프라인 MARL 접근 방식이 기존의 온라인 방법들보다 동적 환경에서 더 효과적으로 작동한다는 것을 보여줍니다. 특히, 무선 자원 관리와 UAV 네트워크에서의 검증 사례가 기존 접근 방식에 비해 성능 향상을 나타냈습니다.

Conclusion: 우리의 연구는 오프라인 MARL의 장점과 한계를 명확히 하고, 향후 무선 애플리케이션에서의 적용 가능성과 방향성을 제시합니다.

Abstract: The next-generation wireless technologies, including beyond 5G and 6G networks, are paving the way for transformative applications such as vehicle platooning, smart cities, and remote surgery. These innovations are driven by a vast array of interconnected wireless entities, including IoT devices, access points, UAVs, and CAVs, which increase network complexity and demand more advanced decision-making algorithms. Artificial intelligence (AI) and machine learning (ML), especially reinforcement learning (RL), are key enablers for such networks, providing solutions to high-dimensional and complex challenges. However, as networks expand to multi-agent environments, traditional online RL approaches face cost, safety, and scalability limitations. Offline multi-agent reinforcement learning (MARL) offers a promising solution by utilizing pre-collected data, reducing the need for real-time interaction. This article introduces a novel offline MARL algorithm based on conservative Q-learning (CQL), ensuring safe and efficient training. We extend this with meta-learning to address dynamic environments and validate the approach through use cases in radio resource management and UAV networks. Our work highlights offline MARL's advantages, limitations, and future directions in wireless applications.

</details>


### [36] [Mapping Human Anti-collusion Mechanisms to Multi-agent AI](https://arxiv.org/abs/2601.00360)
*Jamiu Adekunle Idowu,Ahmed Almasoud,Ayman Alfahid*

Main category: cs.MA

TL;DR: 다중 에이전트 AI 시스템의 자율성이 증가함에 따라, 이들이 인간 시장과 제도에서 오랫동안 관찰된 담합 전략을 개발할 수 있음을 증명하는 증거가 나타나고 있다. 본 논문은 인간의 담합 방지 메커니즘을 분석하고 이를 다중 에이전트 AI 시스템에 적용할 수 있는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 AI 시스템에서의 담합 전략 개발에 대한 이해와 이를 방지할 수 있는 방법에 대한 필요성.

Method: 인간의 담합 방지 메커니즘을 분류하고, 이러한 메커니즘을 다중 에이전트 AI 시스템에 적용 가능한 개입 방법으로 매핑한다.

Result: 제안된 메커니즘에 대한 구현 접근 방식을 제시하고, 현재 존재하는 개방형 문제들을 강조한다.

Conclusion: AI 시스템에서의 담합 방지를 위한 인간의 담합 방지 메커니즘 분석은 향후 연구에 기여할 수 있다.

Abstract: As multi-agent AI systems become increasingly autonomous, evidence shows they can develop collusive strategies similar to those long observed in human markets and institutions. While human domains have accumulated centuries of anti-collusion mechanisms, it remains unclear how these can be adapted to AI settings. This paper addresses that gap by (i) developing a taxonomy of human anti-collusion mechanisms, including sanctions, leniency & whistleblowing, monitoring & auditing, market design, and governance and (ii) mapping them to potential interventions for multi-agent AI systems. For each mechanism, we propose implementation approaches. We also highlight open challenges, such as the attribution problem (difficulty attributing emergent coordination to specific agents) identity fluidity (agents being easily forked or modified) the boundary problem (distinguishing beneficial cooperation from harmful collusion) and adversarial adaptation (agents learning to evade detection).

</details>
