<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 8]
- [cs.LG](#cs.LG) [Total: 21]
- [cs.AI](#cs.AI) [Total: 12]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Agentic-AI Healthcare: Multilingual, Privacy-First Framework with MCP Agents](https://arxiv.org/abs/2510.02325)
*Mohammed A. Shehab*

Main category: cs.CR

TL;DR: Agentic-AI Healthcare는 다국어를 지원하고 개인정보 보호를 고려한 헬스케어 연구 프로토타입으로, 심증 확인, 약물 제안, 약속 예약 등을 위해 여러 지능형 에이전트를 활용한다.


<details>
  <summary>Details</summary>
Motivation: 헬스케어 애플리케이션에서 다국어 접근성과 개인정보 보호를 고려한 에이전트 오케스트레이션의 가능성을 탐구하기 위함이다.

Method: MCP(Model Context Protocol)를 활용하여 지능형 에이전트를 조정하고, RBAC, AES-GCM 필드 수준 암호화, 변조 방지 감사 로그 기능을 통합한 프라이버시 및 준수 계층을 통해 데이터 보호를 실현한다.

Result: 다국어 환자-의사 상호작용 사례와 대규모 언어 모델에 의한 투명한 진단 추론을 보여준다.

Conclusion: 본 연구는 헬스케어 애플리케이션에서 에이전트 오케스트레이션, 다국어 접근성 및 준수 인식 아키텍처를 결합하는 가능성을 강조하며, 인증된 의료 기기가 아닌 연구 프로토타입으로 제시된다.

Abstract: This paper introduces Agentic-AI Healthcare, a privacy-aware, multilingual,
and explainable research prototype developed as a single-investigator project.
The system leverages the emerging Model Context Protocol (MCP) to orchestrate
multiple intelligent agents for patient interaction, including symptom
checking, medication suggestions, and appointment scheduling. The platform
integrates a dedicated Privacy and Compliance Layer that applies role-based
access control (RBAC), AES-GCM field-level encryption, and tamper-evident audit
logging, aligning with major healthcare data protection standards such as HIPAA
(US), PIPEDA (Canada), and PHIPA (Ontario). Example use cases demonstrate
multilingual patient-doctor interaction (English, French, Arabic) and
transparent diagnostic reasoning powered by large language models. As an
applied AI contribution, this work highlights the feasibility of combining
agentic orchestration, multilingual accessibility, and compliance-aware
architecture in healthcare applications. This platform is presented as a
research prototype and is not a certified medical device.

</details>


### [2] [Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark](https://arxiv.org/abs/2510.02356)
*Xinjie Shen,Mufei Li,Pan Li*

Main category: cs.CR

TL;DR: 대규모 언어 모델(LLMs)의 잠재적인 프라이버시 인식을 평가하기 위한 새로운 벤치마크인 EAPrivacy를 소개하며, 현재 모델들이 물리적 환경에서의 프라이버시를 충분히 인식하지 못하고 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLMs)을 기반으로 한 임베디드 에이전트의 배포는 물리적 세계에서의 프라이버시 인식 측정의 필요성을 급증시킨다.

Method: EAPrivacy는 절차적으로 생성된 시나리오를 활용하여 민감한 객체 처리, 변화하는 환경에 대한 적응, 프라이버시 제약과 업무 수행의 균형 및 사회적 규범과의 갈등 해결 능력을 평가한다.

Result: Gemini 2.5 Pro는 변화하는 물리적 환경을 포함한 시나리오에서 59%의 정확도만을 달성했으며, 86%의 경우에서 프라이버시 요청과 함께 주어진 작업을 완수하는 것을 우선시했다.

Conclusion: 이 연구는 LLM들이 물리적 기반 프라이버시에 대해 근본적으로 잘못 정렬되어 있음을 강조하며, 더 강력하고 물리적으로 인식 가능한 정렬의 필요성을 명확히 한다.

Abstract: The deployment of Large Language Models (LLMs) in embodied agents creates an
urgent need to measure their privacy awareness in the physical world. Existing
evaluation methods, however, are confined to natural language based scenarios.
To bridge this gap, we introduce EAPrivacy, a comprehensive evaluation
benchmark designed to quantify the physical-world privacy awareness of
LLM-powered agents. EAPrivacy utilizes procedurally generated scenarios across
four tiers to test an agent's ability to handle sensitive objects, adapt to
changing environments, balance task execution with privacy constraints, and
resolve conflicts with social norms. Our measurements reveal a critical deficit
in current models. The top-performing model, Gemini 2.5 Pro, achieved only 59\%
accuracy in scenarios involving changing physical environments. Furthermore,
when a task was accompanied by a privacy request, models prioritized completion
over the constraint in up to 86\% of cases. In high-stakes situations pitting
privacy against critical social norms, leading models like GPT-4o and
Claude-3.5-haiku disregarded the social norm over 15\% of the time. These
findings, demonstrated by our benchmark, underscore a fundamental misalignment
in LLMs regarding physically grounded privacy and establish the need for more
robust, physically-aware alignment.

</details>


### [3] [A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory](https://arxiv.org/abs/2510.02373)
*Qianshan Wei,Tengchao Yang,Yaochen Wang,Xinfeng Li,Lijun Li,Zhenfei Yin,Yi Zhan,Thorsten Holz,Zhiqiang Lin,XiaoFeng Wang*

Main category: cs.CR

TL;DR: A-MemGuard는 LLM 에이전트 메모리를 위한 첫 번째 사전 방어 프레임워크로, 메모리의 자가 점검 및 자가 수정 기능을 통해 메모리 보안을 강화합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 메모리를 통해 과거 상호작용에서 학습하므로 복잡한 환경에서 자율적인 계획 및 의사 결정을 수행할 수 있습니다. 그러나 메모리에 대한 의존은 공격자가 에이전트의 행동을 조작하기 위해 무해한 기록을 주입할 수 있는 심각한 보안 위험을 초래합니다.

Method: A-MemGuard는 두 가지 메커니즘을 결합합니다: (1) 여러 관련 메모리에서 파생된 추론 경로를 비교하여 이상을 감지하는 합의 기반 검증 및 (2) 감지된 오류를 '교훈'으로 정제하여 별도로 저장하고 향후 행동 전 참조하는 이중 메모리 구조입니다.

Result: A-MemGuard는 여러 벤치마크에서 공격 성공률을 95% 이상 낮추는 효과를 보이며 최소한의 유틸리티 비용을 발생시킵니다.

Conclusion: 이 연구는 LLM 메모리 보안을 정적 필터링에서 점진적으로 강화되는 사전 경험 기반 모델로 전환합니다.

Abstract: Large Language Model (LLM) agents use memory to learn from past interactions,
enabling autonomous planning and decision-making in complex environments.
However, this reliance on memory introduces a critical security risk: an
adversary can inject seemingly harmless records into an agent's memory to
manipulate its future behavior. This vulnerability is characterized by two core
aspects: First, the malicious effect of injected records is only activated
within a specific context, making them hard to detect when individual memory
entries are audited in isolation. Second, once triggered, the manipulation can
initiate a self-reinforcing error cycle: the corrupted outcome is stored as
precedent, which not only amplifies the initial error but also progressively
lowers the threshold for similar attacks in the future. To address these
challenges, we introduce A-MemGuard (Agent-Memory Guard), the first proactive
defense framework for LLM agent memory. The core idea of our work is the
insight that memory itself must become both self-checking and self-correcting.
Without modifying the agent's core architecture, A-MemGuard combines two
mechanisms: (1) consensus-based validation, which detects anomalies by
comparing reasoning paths derived from multiple related memories and (2) a
dual-memory structure, where detected failures are distilled into ``lessons''
stored separately and consulted before future actions, breaking error cycles
and enabling adaptation. Comprehensive evaluations on multiple benchmarks show
that A-MemGuard effectively cuts attack success rates by over 95% while
incurring a minimal utility cost. This work shifts LLM memory security from
static filtering to a proactive, experience-driven model where defenses
strengthen over time. Our code is available in
https://github.com/TangciuYueng/AMemGuard

</details>


### [4] [A Hybrid CAPTCHA Combining Generative AI with Keystroke Dynamics for Enhanced Bot Detection](https://arxiv.org/abs/2510.02374)
*Ayda Aghaei Nia*

Main category: cs.CR

TL;DR: 본 논문은 인간과 컴퓨터를 구분하는 하이브리드 CAPTCHA 시스템을 소개하며, 이는 LLM의 인지적 도전과 타이핑 역학 분석을 결합하여 높은 정확도로 봇 탐지를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 CAPTCHA 시스템은 사용성과 AI 기반 봇에 대한 저항력 간의 트레이드오프에 놓여 있다.

Method: 이 시스템은 인간에게는 사소하지만 자동화된 에이전트에게는 비사소한 동적 및 예측 불가능한 질문을 생성하고, 사용자의 타이핑 리듬을 분석하여 인간과 로봇 입력을 구별한다.

Result: 이중 레이어 접근 방식은 봇 탐지에서 높은 정확도를 달성하고, 붙여넣기 및 스크립트 기반 공격을 성공적으로 저지하며, 인간 참가자들 사이에서 높은 사용성 점수를 유지한다.

Conclusion: 인지적 및 행동적 테스트를 결합하여 더 안전하고 사용자 친화적인 CAPTCHA의 새로운 생성을 가능하게 한다.

Abstract: Completely Automated Public Turing tests to tell Computers and Humans Apart
(CAPTCHAs) are a foundational component of web security, yet traditional
implementations suffer from a trade-off between usability and resilience
against AI-powered bots. This paper introduces a novel hybrid CAPTCHA system
that synergizes the cognitive challenges posed by Large Language Models (LLMs)
with the behavioral biometric analysis of keystroke dynamics. Our approach
generates dynamic, unpredictable questions that are trivial for humans but
non-trivial for automated agents, while simultaneously analyzing the user's
typing rhythm to distinguish human patterns from robotic input. We present the
system's architecture, formalize the feature extraction methodology for
keystroke analysis, and report on an experimental evaluation. The results
indicate that our dual-layered approach achieves a high degree of accuracy in
bot detection, successfully thwarting both paste-based and script-based
simulation attacks, while maintaining a high usability score among human
participants. This work demonstrates the potential of combining cognitive and
behavioral tests to create a new generation of more secure and user-friendly
CAPTCHAs.

</details>


### [5] [On The Fragility of Benchmark Contamination Detection in Reasoning Models](https://arxiv.org/abs/2510.02386)
*Han Wang,Haoyu Li,Brian Ko,Huan Zhang*

Main category: cs.CR

TL;DR: 이 논문은 LRM(대규모 언어 모델)의 평가에서 오염 검출이 쉽고, 오염이 존재하는 상태에서 개발자들이 순위를 조작할 수 있는 방식에 대해 논의한다.


<details>
  <summary>Details</summary>
Motivation: LRM의 평가 과정이 경쟁으로 변하면서 개발자들이 벤치마크 세트에 맞춰 최적화를 하도록 유도하는 경향이 있다.

Method: 기존 오염 검출 방법을 통해 SFT 과정에서의 오염을 식별하고, GRPO 훈련이 이러한 신호를 감추는 방법을 실험적으로 분석하였다.

Result: LRM에서 오염이 감지되지 않는 상황을 상세히 보여주었고, SFT와 CoT 적용 시 대부분의 오염 검출 방법이 무작위 추측과 같음을 발견했다.

Conclusion: LRM 평가의 공정성이 위협받고 있으며, 이에 따라 고급 오염 검출 방법과 신뢰할 수 있는 평가 프로토콜의 필요성이 시급하다.

Abstract: Leaderboards for LRMs have turned evaluation into a competition,
incentivizing developers to optimize directly on benchmark suites. A shortcut
to achieving higher rankings is to incorporate evaluation benchmarks into the
training data, thereby yielding inflated performance, known as benchmark
contamination. Surprisingly, our studies find that evading contamination
detections for LRMs is alarmingly easy. We focus on the two scenarios where
contamination may occur in practice: (I) when the base model evolves into LRM
via SFT and RL, we find that contamination during SFT can be originally
identified by contamination detection methods. Yet, even a brief GRPO training
can markedly conceal contamination signals that most detection methods rely on.
Further empirical experiments and theoretical analysis indicate that PPO style
importance sampling and clipping objectives are the root cause of this
detection concealment, indicating that a broad class of RL methods may
inherently exhibit similar concealment capability; (II) when SFT contamination
with CoT is applied to advanced LRMs as the final stage, most contamination
detection methods perform near random guesses. Without exposure to non-members,
contaminated LRMs would still have more confidence when responding to those
unseen samples that share similar distributions to the training set, and thus,
evade existing memorization-based detection methods. Together, our findings
reveal the unique vulnerability of LRMs evaluations: Model developers could
easily contaminate LRMs to achieve inflated leaderboards performance while
leaving minimal traces of contamination, thereby strongly undermining the
fairness of evaluation and threatening the integrity of public leaderboards.
This underscores the urgent need for advanced contamination detection methods
and trustworthy evaluation protocols tailored to LRMs.

</details>


### [6] [ToolTweak: An Attack on Tool Selection in LLM-based Agents](https://arxiv.org/abs/2510.02554)
*Jonathan Sneh,Ruomei Yan,Jialin Yu,Philip Torr,Yarin Gal,Sunando Sengupta,Eric Sommerlade,Alasdair Paren,Adel Bibi*

Main category: cs.CR

TL;DR: 이 논문에서는 LLM이 도구와 상호작용하는 에이전트의 필수적인 메커니즘으로서 도구 사용의 중요성을 다루며, 도구 선택 과정에서 발생하는 중요한 취약점을 드러내고 ToolTweak이라는 경량 자동 공격을 제시한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 외부 도구와 상호작용하는 에이전트를 강화하는 데 필요한 도구 사용의 중요성을 강조한다.

Method: 도구 이름과 설명을 반복적으로 조작하여 에이전트를 특정 도구 선택으로 유도하는 자동 공격인 ToolTweak을 제안한다.

Result: ToolTweak은 선택률을 평균 20%에서 최대 81%로 증가시키며, 오픈 소스 및 폐쇄형 모델 간에 강한 이전 가능성을 보인다.

Conclusion: 공정성, 경쟁 및 보안을 저해하는 도구 사용의 분포 변화에 대한 위험을 보여주며, 이를 완화하기 위한 두 가지 방어책을 평가한다.

Abstract: As LLMs increasingly power agents that interact with external tools, tool use
has become an essential mechanism for extending their capabilities. These
agents typically select tools from growing databases or marketplaces to solve
user tasks, creating implicit competition among tool providers and developers
for visibility and usage. In this paper, we show that this selection process
harbors a critical vulnerability: by iteratively manipulating tool names and
descriptions, adversaries can systematically bias agents toward selecting
specific tools, gaining unfair advantage over equally capable alternatives. We
present ToolTweak, a lightweight automatic attack that increases selection
rates from a baseline of around 20% to as high as 81%, with strong
transferability between open-source and closed-source models. Beyond individual
tools, we show that such attacks cause distributional shifts in tool usage,
revealing risks to fairness, competition, and security in emerging tool
ecosystems. To mitigate these risks, we evaluate two defenses: paraphrasing and
perplexity filtering, which reduce bias and lead agents to select functionally
similar tools more equally. All code will be open-sourced upon acceptance.

</details>


### [7] [MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols](https://arxiv.org/abs/2510.02694)
*Bowei Ning,Xuejun Zong,Kan He*

Main category: cs.CR

TL;DR: MALF는 대규모 언어 모델을 활용한 다중 에이전트 협력형 퍼징 솔루션으로, 산업 제어 프로토콜의 취약점을 효과적으로 식별한다.


<details>
  <summary>Details</summary>
Motivation: 산업 제어 시스템은 현대 인프라에 필수적이지만 통신 프로토콜의 취약성으로 사이버 보안 위협에 노출되고 있다.

Method: MALF는 대규모 언어 모델과 다중 에이전트 협력을 통합하여, 도메인 관련 지식을 위한 RAG와 프로토콜 인식 입력 생성을 위한 QLoRA 미세 조정을 활용한다.

Result: MALF는 Modbus/TCP, S7Comm 및 Ethernet/IP 같은 프로토콜에서 전통적인 방법을 초과하여 88-92%의 테스트 케이스 통과율을 달성하고 더 많은 예외 트리거를 생성하였다.

Conclusion: MALF는 ICS 사이버 보안 분야에서 다중 에이전트를 활용한 대규모 언어 모델의 변혁적 가능성을 보여주며, 취약점 발견을 위한 새로운 표준을 설정하고 중요한 인프라 보안을 강화를 강화한다.

Abstract: Industrial control systems (ICS) are vital to modern infrastructure but
increasingly vulnerable to cybersecurity threats, particularly through
weaknesses in their communication protocols. This paper presents MALF
(Multi-Agent LLM Fuzzing Framework), an advanced fuzzing solution that
integrates large language models (LLMs) with multi-agent coordination to
identify vulnerabilities in industrial control protocols (ICPs). By leveraging
Retrieval-Augmented Generation (RAG) for domain-specific knowledge and QLoRA
fine-tuning for protocol-aware input generation, MALF enhances fuzz testing
precision and adaptability. The multi-agent framework optimizes seed
generation, mutation strategies, and feedback-driven refinement, leading to
improved vulnerability discovery. Experiments on protocols like Modbus/TCP,
S7Comm, and Ethernet/IP demonstrate that MALF surpasses traditional methods,
achieving a test case pass rate (TCPR) of 88-92% and generating more exception
triggers (ETN). MALF also maintains over 90% seed coverage and Shannon entropy
values between 4.2 and 4.6 bits, ensuring diverse, protocol-compliant
mutations. Deployed in a real-world Industrial Attack-Defense Range for power
plants, MALF identified critical vulnerabilities, including three zero-day
flaws, one confirmed and registered by CNVD. These results validate MALF's
effectiveness in real-world fuzzing applications. This research highlights the
transformative potential of multi-agent LLMs in ICS cybersecurity, offering a
scalable, automated framework that sets a new standard for vulnerability
discovery and strengthens critical infrastructure security against emerging
threats.

</details>


### [8] [Protecting Persona Biometric Data: The Case of Facial Privacy](https://arxiv.org/abs/2510.03035)
*Lambert Hogenhout,Rinzin Wangmo*

Main category: cs.CR

TL;DR: 디지털 기술의 급증으로 인한 데이터 수집과 얼굴 데이터의 민감성, 이에 대한 법적 규제의 부족과 개인의 프라이버시 및 자율성에 대한 위협을 논의한다.


<details>
  <summary>Details</summary>
Motivation: 개인 데이터 수집과 사용의 증가로 인해 얼굴 데이터의 상업화가 개인의 프라이버시를 심각하게 위협하고 있음.

Method: 기존 법적 틀에 대한 포괄적인 검토를 통해 얼굴 인식 기술과 관련된 규제를 분석하고 비교함.

Result: GDPR, 브라질의 LGPD, 캐나다의 PIPEDA 등 여러 나라의 법적 프레임워크를 비교 분석하여 임박한 위협을 강조.

Conclusion: 법적 허점과 모호성이 개인을 취약하게 만들고 있으며, 데이터의 자산으로서가 아니라 양도 불가능한 권리 모델로의 전환이 필요하다는 주장을 펼침.

Abstract: The proliferation of digital technologies has led to unprecedented data
collection, with facial data emerging as a particularly sensitive commodity.
Companies are increasingly leveraging advanced facial recognition technologies,
often without the explicit consent or awareness of individuals, to build
sophisticated surveillance capabilities. This practice, fueled by weak and
fragmented laws in many jurisdictions, has created a regulatory vacuum that
allows for the commercialization of personal identity and poses significant
threats to individual privacy and autonomy. This article introduces the concept
of Facial Privacy. It analyzes the profound challenges posed by unregulated
facial recognition by conducting a comprehensive review of existing legal
frameworks. It examines and compares regulations such as the GDPR, Brazil's
LGPD, Canada's PIPEDA, and privacy acts in China, Singapore, South Korea, and
Japan, alongside sector-specific laws in the United States like the Illinois
Biometric Information Privacy Act (BIPA). The analysis highlights the societal
impacts of this technology, including the potential for discriminatory bias and
the long-lasting harm that can result from the theft of immutable biometric
data. Ultimately, the paper argues that existing legal loopholes and
ambiguities leave individuals vulnerable. It proposes a new policy framework
that shifts the paradigm from data as property to a model of inalienable
rights, ensuring that fundamental human rights are upheld against unchecked
technological expansion.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [9] [OpenTSLM: Time-Series Language Models for Reasoning over Multivariate Medical Text- and Time-Series Data](https://arxiv.org/abs/2510.02410)
*Patrick Langer,Thomas Kaar,Max Rosenblattl,Maxwell A. Xu,Winnie Chow,Martin Maritsch,Aradhana Verma,Brian Han,Daniel Seung Kim,Henry Chubb,Scott Ceresnak,Aydin Zahedivash,Alexander Tarlochan Singh Sandhu,Fatima Rodriguez,Daniel McDuff,Elgar Fleisch,Oliver Aalami,Filipe Barata,Paul Schmiedmayer*

Main category: cs.LG

TL;DR: OpenTSLM은 사전 훈련된 LLM에 시계열 데이터를 통합하여 멀티모달 데이터를 해석하는 강력한 도구로, 시계열 모델링의 두 가지 아키텍처를 제공하고, 기존 모델 대비 성능이 우수함을 입증합니다.


<details>
  <summary>Details</summary>
Motivation: LLMs는 대량의 임상 정보를 실행 가능한 통찰력으로 통합하는 데 큰 잠재력을 가지고 있지만, 시계열 처리 능력이 부족합니다.

Method: OpenTSLM은 사전 훈련된 LLM에 시계열 데이터를 기본 모달리티로 통합하여 여러 시계열 데이터를 처리하도록 설계된 시계열 언어 모델입니다. 두 가지 아키텍처(OpenTSLM-SoftPrompt 및 OpenTSLM-Flamingo)를 조사합니다.

Result: OpenTSLM 모델은 benchmark 데이터셋에서 baseline 모델보다 우수한 성능을 보이며, 특히 긴 시퀀스에서 성능이 좋은 것으로 나타났습니다.

Conclusion: OpenTSLM은 임상 데이터 해석에 있어 강력한 추론 능력을 보여주며, 모든 코드를 오픈 소스로 제공하여 향후 연구를 지원합니다.

Abstract: LLMs have emerged as powerful tools for interpreting multimodal data. In
medicine, they hold particular promise for synthesizing large volumes of
clinical information into actionable insights and digital health applications.
Yet, a major limitation remains their inability to handle time series. To
overcome this gap, we present OpenTSLM, a family of Time Series Language Models
(TSLMs) created by integrating time series as a native modality to pretrained
LLMs, enabling reasoning over multiple time series of any length. We
investigate two architectures for OpenTSLM. The first, OpenTSLM-SoftPrompt,
models time series implicitly by concatenating learnable time series tokens
with text tokens via soft prompting. Although parameter-efficient, we
hypothesize that explicit time series modeling scales better and outperforms
implicit approaches. We thus introduce OpenTSLM-Flamingo, which integrates time
series with text via cross-attention. We benchmark both variants against
baselines that treat time series as text tokens or plots, across a suite of
text-time-series Chain-of-Thought (CoT) reasoning tasks. We introduce three
datasets: HAR-CoT, Sleep-CoT, and ECG-QA-CoT. Across all, OpenTSLM models
outperform baselines, reaching 69.9 F1 in sleep staging and 65.4 in HAR,
compared to 9.05 and 52.2 for finetuned text-only models. Notably, even
1B-parameter OpenTSLM models surpass GPT-4o (15.47 and 2.95). OpenTSLM-Flamingo
matches OpenTSLM-SoftPrompt in performance and outperforms on longer sequences,
while maintaining stable memory requirements. By contrast, SoftPrompt grows
exponentially in memory with sequence length, requiring around 110 GB compared
to 40 GB VRAM when training on ECG-QA with LLaMA-3B. Expert reviews by
clinicians find strong reasoning capabilities exhibited by OpenTSLMs on ECG-QA.
To facilitate further research, we provide all code, datasets, and models
open-source.

</details>


### [10] [SAGE: Streaming Agreement-Driven Gradient Sketches for Representative Subset Selection](https://arxiv.org/abs/2510.02470)
*Ashish Jha,Salman Ahmadi-Asl*

Main category: cs.LG

TL;DR: SAGE는 효율적인 훈련을 위해 메모리를 절약하면서도 경쟁력 있는 정확도를 유지하는 데이터 서브셋 선택 방법이다.


<details>
  <summary>Details</summary>
Motivation: 현대 신경망을 대규모 데이터셋에서 훈련하는 것은 계산 비용과 에너지를 많이 소모한다.

Method: SAGE는 $O(ℓ D)$ 메모리에서 gradient geometry의 compact Frequent Directions (FD) sketch를 유지하며, 합의 방향과 정렬된 sketched gradients를 우선시하는 데이터 서브셋 선택 방법이다.

Result: SAGE는 적은 유지 비율로 작은 데이터셋에서도 높은 정확도를 유지하면서 전체 데이터 훈련 및 최근 서브셋 선택 기준에 비해 경쟁력 있는 정확성을 보여준다.

Conclusion: SAGE는 효율적인 훈련을 위한 가지치기 및 모델 압축을 보완하는 실용적인 상수 메모리 대안이다.

Abstract: Training modern neural networks on large datasets is computationally and
energy intensive. We present SAGE, a streaming data-subset selection method
that maintains a compact Frequent Directions (FD) sketch of gradient geometry
in $O(\ell D)$ memory and prioritizes examples whose sketched gradients align
with a consensus direction. The approach eliminates $N \times N$ pairwise
similarities and explicit $N \times \ell$ gradient stores, yielding a simple
two-pass, GPU-friendly pipeline. Leveraging FD's deterministic approximation
guarantees, we analyze how agreement scoring preserves gradient energy within
the principal sketched subspace. Across multiple benchmarks, SAGE trains with
small kept-rate budgets while retaining competitive accuracy relative to
full-data training and recent subset-selection baselines, and reduces
end-to-end compute and peak memory. Overall, SAGE offers a practical,
constant-memory alternative that complements pruning and model compression for
efficient training.

</details>


### [11] [Uncertainty-Guided Model Selection for Tabular Foundation Models in Biomolecule Efficacy Prediction](https://arxiv.org/abs/2510.02476)
*Jie Li,Andrew McCarthy,Zhizhuo Zhang,Stephen Young*

Main category: cs.LG

TL;DR: TabPFN과 같은 In-context learner는 바이오분자의 효능 예측에 유망하지만, 제공된 맥락에 민감합니다. 본 연구에서는 불확실성에 기반한 모델 선택 전략을 조사하여, 평균 IQR이 가장 낮은 모델 앙상블을 선택하고 평균화함으로써 기존의 방법보다 우수한 성능을 달성했습니다.


<details>
  <summary>Details</summary>
Motivation: TabPFN과 같은 In-context learner는 바이오분자의 효능 예측에서 유망하나 제공된 맥락에 민감하여 모델의 성능이 달라지는 문제를 해결하고자 합니다.

Method: 간단한 시퀀스 기반 특징을 사용하는 TabPFN 모델의 효능을 siRNA knockdown 작업에서 검증했습니다. 모델의 예측된 IQR과 실제 예측 오류 간의 상관관계를 입증했습니다.

Result: 최저 평균 IQR을 가진 모델 앙상블을 선택하고 평균화하여 우수한 성능을 달성했습니다.

Conclusion: 모델의 불확실성은 바이오분자 효능 예측을 최적화하기 위한 강력한 레이블 없는 휴리스틱으로 작용할 수 있습니다.

Abstract: In-context learners like TabPFN are promising for biomolecule efficacy
prediction, where established molecular feature sets and relevant experimental
results can serve as powerful contextual examples. However, their performance
is highly sensitive to the provided context, making strategies like post-hoc
ensembling of models trained on different data subsets a viable approach. An
open question is how to select the best models for the ensemble without access
to ground truth labels. In this study, we investigate an uncertainty-guided
strategy for model selection. We demonstrate on an siRNA knockdown efficacy
task that a TabPFN model using simple sequence-based features can surpass
specialized state-of-the-art predictors. We also show that the model's
predicted inter-quantile range (IQR), a measure of its uncertainty, has a
negative correlation with true prediction error. By selecting and averaging an
ensemble of models with the lowest mean IQR, we achieve superior performance
compared to naive ensembling or using a single model trained on all available
data. This finding highlights model uncertainty as a powerful, label-free
heuristic for optimizing biomolecule efficacy predictions.

</details>


### [12] [From Pixels to Factors: Learning Independently Controllable State Variables for Reinforcement Learning](https://arxiv.org/abs/2510.02484)
*Rafael Rodriguez-Sanchez,Cameron Allen,George Konidaris*

Main category: cs.LG

TL;DR: ACF는 고차원 관측에서 독립적으로 제어 가능한 잠재 변수를 발견하여 표시 문제를 해결하고, 효율적인 샘플 사용을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 기존 알고리즘은 알려진 분해 표현이 필요하지만, 고차원 관측에서는 이러한 요구가 성립하지 않는다.

Method: ACF는 대조 학습 접근 방식을 통해 각각의 행동이 따로 영향을 미칠 수 있는 독립 제어 가능한 잠재 변수를 발견한다.

Result: ACF는 픽셀 관측으로부터 실제 제어 가능한 요인을 회복하여 세 가지 벤치마크에서 일관되게 성능을 개선하였다.

Conclusion: ACF는 기본 선형 알고리즘보다 더 나은 성능을 보였다.

Abstract: Algorithms that exploit factored Markov decision processes are far more
sample-efficient than factor-agnostic methods, yet they assume a factored
representation is known a priori -- a requirement that breaks down when the
agent sees only high-dimensional observations. Conversely, deep reinforcement
learning handles such inputs but cannot benefit from factored structure. We
address this representation problem with Action-Controllable Factorization
(ACF), a contrastive learning approach that uncovers independently controllable
latent variables -- state components each action can influence separately. ACF
leverages sparsity: actions typically affect only a subset of variables, while
the rest evolve under the environment's dynamics, yielding informative data for
contrastive training. ACF recovers the ground truth controllable factors
directly from pixel observations on three benchmarks with known factored
structure -- Taxi, FourRooms, and MiniGrid-DoorKey -- consistently
outperforming baseline disentanglement algorithms.

</details>


### [13] [Beyond Imitation: Recovering Dense Rewards from Demonstrations](https://arxiv.org/abs/2510.02493)
*Jiangnan Li,Thuy-Trang Vu,Ehsan Abbasnejad,Gholamreza Haffari*

Main category: cs.LG

TL;DR: 이 연구는 감독 하 미세 조정(SFT)을 단순한 모방 학습으로 간주하는 전통적인 관점을 도전하고, SFT와 역 강화 학습 사이의 근본적인 동등성을 확립한다.


<details>
  <summary>Details</summary>
Motivation: SFT가 전문가 행동을 단순히 모방하는 과정이라는 기존의 관점을 재검토하려는 동기.

Method: SFT 목표가 역 Q-학습의 특별한 경우임을 증명하고, SFT 모델에서 직접적으로 밀집 보상 신호를 회수하는 방법을 제시.

Result: 회수된 보상을 사용하여 정책을 더 개선할 수 있는 방법과 같은 밀집 보상 모델의 이점을 보여준다.

Conclusion: Dense-Path REINFORCE는 명령 수행 벤치마크에서 기존 SFT 모델을 지속적으로 능가하며, SFT를 단순한 정책 모방이 아닌 강력한 보상 학습 메커니즘으로 재구성한다.

Abstract: Conventionally, supervised fine-tuning (SFT) is treated as a simple imitation
learning process that only trains a policy to imitate expert behavior on
demonstration datasets. In this work, we challenge this view by establishing a
fundamental equivalence between SFT and Inverse Reinforcement Learning. We
prove that the SFT objective is a special case of Inverse Q-Learning, which
implies that the SFT process does not just learn a policy, but also an
implicit, dense, token-level reward model that explains the expert
demonstrations. We then show how to recover this dense reward signal directly
from the SFT model by formulating a baseline-relative reward function. The
availability of such a dense reward model offers numerous benefits, providing
granular credit assignment for each token generated. We demonstrate one key
application by using these recovered rewards to further improve the policy with
reinforcement learning. Our method, Dense-Path REINFORCE, consistently
outperforms the original SFT models on instruction-following benchmarks. This
work reframes SFT not merely as policy imitation but as a powerful reward
learning mechanism, opening new possibilities for leveraging expert
demonstrations.

</details>


### [14] [On The Expressive Power of GNN Derivatives](https://arxiv.org/abs/2510.02565)
*Yam Eitan,Moshe Eliasof,Yoav Gelberg,Fabrizio Frasca,Guy Bar-Shalom,Haggai Maron*

Main category: cs.LG

TL;DR: GNN의 표현력을 향상시키기 위한 새로운 방법인 HOD-GNN을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 그래프 신경망(GNN)은 제한된 표현력 문제에 직면해 있으며, 이를 해결하기 위한 다양한 연구가 이루어졌습니다.

Method: HOD-GNN은 기본 모델의 고차 노드 미분을 활용하여 메시지 전파 신경망(MPNN)의 표현력을 향상시키는 새로운 방법입니다.

Result: HOD-GNN은 인기 있는 그래프 학습 벤치마크에서 강력한 성능을 보여줍니다.

Conclusion: HOD-GNN은 WL 계층과 정렬된 표현력의 아키텍처 가족을 제공합니다.

Abstract: Despite significant advances in Graph Neural Networks (GNNs), their limited
expressivity remains a fundamental challenge. Research on GNN expressivity has
produced many expressive architectures, leading to architecture hierarchies
with models of increasing expressive power. Separately, derivatives of GNNs
with respect to node features have been widely studied in the context of the
oversquashing and over-smoothing phenomena, GNN explainability, and more. To
date, these derivatives remain unexplored as a means to enhance GNN
expressivity. In this paper, we show that these derivatives provide a natural
way to enhance the expressivity of GNNs. We introduce High-Order Derivative GNN
(HOD-GNN), a novel method that enhances the expressivity of Message Passing
Neural Networks (MPNNs) by leveraging high-order node derivatives of the base
model. These derivatives generate expressive structure-aware node embeddings
processed by a second GNN in an end-to-end trainable architecture.
Theoretically, we show that the resulting architecture family's expressive
power aligns with the WL hierarchy. We also draw deep connections between
HOD-GNN, Subgraph GNNs, and popular structural encoding schemes. For
computational efficiency, we develop a message-passing algorithm for computing
high-order derivatives of MPNNs that exploits graph sparsity and parallelism.
Evaluations on popular graph learning benchmarks demonstrate HOD-GNN's strong
performance on popular graph learning tasks.

</details>


### [15] [TabImpute: Accurate and Fast Zero-Shot Missing-Data Imputation with a Pre-Trained Transformer](https://arxiv.org/abs/2510.02625)
*Jacob Feitelberg,Dwaipayan Saha,Kyuseong Choi,Zaid Ahmad,Anish Agarwal,Raaz Dwivedi*

Main category: cs.LG

TL;DR: TabImpute는 TabPFN 모델을 기반으로 한 사전 학습된 변환기로, 초매개변수 튜닝 없이 빠르고 정확한 제로샷 보간을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 누락된 데이터는 표 형식의 데이터에서 흔한 문제이며, 기존 방법들은 성능의 큰 변동성과 시간 소모적인 하이퍼파라미터 조정 때문에 기본 보간 방법이 존재하지 않습니다.

Method: TabImpute는 TabPFN을 기반으로 하여, 엔트리별 특징화를 통해 이전 TabPFN 보간 방법에 비해 $100	imes$ 속도 향상을 달성하고, 사실적인 누락 패턴을 포함한 합성 학습 데이터 생성 파이프라인을 제공합니다.

Result: MissBench라는 종합 벤치마크를 통해 TabImpute는 42개의 OpenML 데이터 셋과 13개의 누락 패턴으로 평가되었으며, 11개의 기존 보간 방법과 비교하여 뛰어난 성능을 보여줍니다.

Conclusion: TabImpute는 사전 학습된 변환기로서, 적은 시간에 정확한 데이터 보간을 가능하게 하여 다양한 분야에서 유용하게 쓰일 수 있습니다.

Abstract: Missing data is a pervasive problem in tabular settings. Existing solutions
range from simple averaging to complex generative adversarial networks.
However, due to huge variance in performance across real-world domains and
time-consuming hyperparameter tuning, no default imputation method exists.
Building on TabPFN, a recent tabular foundation model for supervised learning,
we propose TabImpute, a pre-trained transformer that delivers accurate and fast
zero-shot imputations requiring no fitting or hyperparameter tuning at
inference-time. To train and evaluate TabImpute, we introduce (i) an entry-wise
featurization for tabular settings, which enables a $100\times$ speedup over
the previous TabPFN imputation method, (ii) a synthetic training data
generation pipeline incorporating realistic missingness patterns, which boosts
test-time performance, and (iii) MissBench, a comprehensive benchmark for
evaluation of imputation methods with $42$ OpenML datasets and $13$ missingness
patterns. MissBench spans domains such as medicine, finance, and engineering,
showcasing TabImpute's robust performance compared to $11$ established
imputation methods.

</details>


### [16] [HyperAdaLoRA: Accelerating LoRA Rank Allocation During Training via Hypernetworks without Sacrificing Performance](https://arxiv.org/abs/2510.02630)
*Hao Zhang,Zhenjia Li,Runfeng Bao,Yifan Gao,Xi Xiao,Bo Huang,Yuhang Wu,Tianyang Wang,Hao Xu*

Main category: cs.LG

TL;DR: HyperAdaLoRA는 AdaLoRA의 수렴 속도를 가속화하기 위해 하이퍼네트워크를 활용한 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: PEFT와 LoRA는 대형 언어 모델의 미세 조정을 위한 유망한 접근 방식이지만, LoRA의 고정된 랭크 가정이 문제를 일으킬 수 있다.

Method: HyperAdaLoRA는 주의 메커니즘에 기반한 하이퍼네트워크를 사용하여 동적으로 SVD의 매개변수를 생성하고, 고유값을 가지는 출력을 프루닝하여 동적 랭크 할당을 달성한다.

Result: 다양한 데이터셋과 모델에 대한 종합적인 실험 결과, 우리의 방법이 성능 저하 없이 더 빠른 수렴을 달성함을 보여준다.

Conclusion: 추가 확장 실험을 통해 LoRA 기반의 다른 접근 방식에서도 우리의 방법이 광범위한 적용 가능성을 가지고 있음을 확인하였다.

Abstract: Parameter-Efficient Fine-Tuning (PEFT), especially Low-Rank Adaptation
(LoRA), has emerged as a promising approach to fine-tuning large language
models(LLMs) while reducing computational and memory overhead. However, LoRA
assumes a uniform rank \textit{r} for each incremental matrix, not accounting
for the varying significance of weight matrices across different modules and
layers. AdaLoRA leverages Singular Value Decomposition (SVD) to parameterize
updates and employs pruning of singular values to introduce dynamic rank
allocation, thereby enhancing adaptability. However, during the training
process, it often encounters issues of slow convergence speed and high
computational overhead. To address this issue, we propose HyperAdaLoRA, a novel
framework that accelerates the convergence of AdaLoRA by leveraging a
hypernetwork. Instead of directly optimizing the components of Singular Value
Decomposition $(P, \Lambda, Q)$, HyperAdaLoRA employs a hypernetwork based on
attention mechanisms to dynamically generate these parameters. By pruning the
outputs of the hypernetwork that generates the singular values, dynamic rank
allocation is achieved. Comprehensive experiments on various datasets and
models demonstrate that our method achieves faster convergence without
sacrificing performance. Additionally, further extension experiments on other
LoRA-based approaches validate the broad applicability of our method.

</details>


### [17] [A Novel Unified Lightweight Temporal-Spatial Transformer Approach for Intrusion Detection in Drone Networks](https://arxiv.org/abs/2510.02711)
*Tarun Kumar Biswas,Ashrafun Zannat,Waqas Ishtiaq,Md. Alamgir Hossain*

Main category: cs.LG

TL;DR: TSLT-Net은 드론 네트워크를 위해 설계된 경량의 통합 침입 탐지 시스템으로, 시간적 및 공간적 패턴을 효과적으로 모델링하여 다양한 침입 유형을 정확하게 탐지한다.


<details>
  <summary>Details</summary>
Motivation: 상업적, 산업적, 민간 분야에서 드론 통합이 증가하면서 드론 네트워크의 사이버 공격에 대한 취약성이 커지고 있다.

Method: 자기 주의 메커니즘을 활용하여 TSLT-Net는 네트워크 트래픽의 시간적 패턴과 공간적 종속성을 모델링하고, 멀티클래스 공격 분류와 이진 이상 탐지를 지원하는 파이프라인을 포함한 경량 침입 탐지 시스템을 제안한다.

Result: TSLT-Net은 ISOT 드론 이상 탐지 데이터 세트에서 99.99%의 멀티클래스 탐지 정확도와 100%의 이진 이상 탐지 정확도를 기록하며, 메모리 소모가 0.04MB로 최소화되고 9722개의 가중치로 학습 가능하다.

Conclusion: TSLT-Net은 실시간 드론 사이버 보안에 효과적이고 확장 가능한 솔루션으로, 임무가 중요한 UAV 시스템의 엣지 장치에 배포하기에 적합하다.

Abstract: The growing integration of drones across commercial, industrial, and civilian
domains has introduced significant cybersecurity challenges, particularly due
to the susceptibility of drone networks to a wide range of cyberattacks.
Existing intrusion detection mechanisms often lack the adaptability,
efficiency, and generalizability required for the dynamic and resource
constrained environments in which drones operate. This paper proposes TSLT-Net,
a novel lightweight and unified Temporal Spatial Transformer based intrusion
detection system tailored specifically for drone networks. By leveraging self
attention mechanisms, TSLT-Net effectively models both temporal patterns and
spatial dependencies in network traffic, enabling accurate detection of diverse
intrusion types. The framework includes a streamlined preprocessing pipeline
and supports both multiclass attack classification and binary anomaly detection
within a single architecture. Extensive experiments conducted on the ISOT Drone
Anomaly Detection Dataset, consisting of more than 2.3 million labeled records,
demonstrate the superior performance of TSLT-Net with 99.99 percent accuracy in
multiclass detection and 100 percent in binary anomaly detection, while
maintaining a minimal memory footprint of only 0.04 MB and 9722 trainable
parameters. These results establish TSLT-Net as an effective and scalable
solution for real time drone cybersecurity, particularly suitable for
deployment on edge devices in mission critical UAV systems.

</details>


### [18] [Fine-Tuning Diffusion Models via Intermediate Distribution Shaping](https://arxiv.org/abs/2510.02692)
*Gautham Govind Anil,Shaan Ul Haque,Nithish Kannen,Dheeraj Nagaraj,Sanjay Shakkottai,Karthikeyan Shanmugam*

Main category: cs.LG

TL;DR: 이 논문에서는 확산 모델을 사용한 생성 작업에서 보상 함수를 활용하여 데이터 분포를 조정하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 사전 학습된 확산 모델이 훈련 데이터의 분포를 효과적으로 캡처하지만, 하위 응용 프로그램과 일치하도록 이러한 분포를 형성하는 것이 종종 바람직하다.

Method: Rejection Sampling 기반의 미세 조정을 통합한 GRAFT 방법론을 제안하며, 중간 노이즈 수준에서 분포를 형성하는 P-GRAFT를 도입한다.

Result: 안정적 확산 2에 적용된 우리의 프레임워크는 인기 있는 T2I 벤치마크에서 정책 기울기 방법을 초과하는 성능을 보이며 상대적으로 8.81%의 개선을 나타낸다.

Conclusion: 역 노이즈 보정을 통해 플로우 모델을 개선하고, 적은 FLOPs로 생성 이미지의 FID를 개선한다.

Abstract: Diffusion models are widely used for generative tasks across domains. While
pre-trained diffusion models effectively capture the training data
distribution, it is often desirable to shape these distributions using reward
functions to align with downstream applications. Policy gradient methods, such
as Proximal Policy Optimization (PPO), are widely used in the context of
autoregressive generation. However, the marginal likelihoods required for such
methods are intractable for diffusion models, leading to alternative proposals
and relaxations. In this context, we unify variants of Rejection sAmpling based
Fine-Tuning (RAFT) as GRAFT, and show that this implicitly performs PPO with
reshaped rewards. We then introduce P-GRAFT to shape distributions at
intermediate noise levels and demonstrate empirically that this can lead to
more effective fine-tuning. We mathematically explain this via a bias-variance
tradeoff. Motivated by this, we propose inverse noise correction to improve
flow models without leveraging explicit rewards. We empirically evaluate our
methods on text-to-image(T2I) generation, layout generation, molecule
generation and unconditional image generation. Notably, our framework, applied
to Stable Diffusion 2, improves over policy gradient methods on popular T2I
benchmarks in terms of VQAScore and shows an $8.81\%$ relative improvement over
the base model. For unconditional image generation, inverse noise correction
improves FID of generated images at lower FLOPs/image.

</details>


### [19] [Dale meets Langevin: A Multiplicative Denoising Diffusion Model](https://arxiv.org/abs/2510.02730)
*Nishanth Shetty,Madhava Prasath,Chandra Sekhar Seelamantula*

Main category: cs.LG

TL;DR: 생물학적 시스템에서의 학습 원칙에 영감을 받아, 지수 기울기 하강 최적화를 통해 새로운 곱셈 업데이트 규칙을 제안하며, 모델의 생성 능력을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 기울기 하강 최적화 방식이 생물학적 시스템의 학습과 일치하지 않음을 보여주고, 생물학적으로 영감을 받은 학습 기술의 필요성을 강조한다.

Method: 기하학적 브라운 운동을 지배하는 확률 미분 방정식(SDE)을 기반으로 하여 거꾸로 시간 SDE를 이산화하고, 그에 따른 곱셈 업데이트 규칙을 도출한다.

Result: 제안된 새로운 업데이트 규칙은 Dale의 법칙에 따라 형성된 지수 기울기 하강 업데이트의 샘플링 동등성과 일치하며, MNIST, Fashion MNIST, Kuzushiji 데이터셋에서 생성 능력을 입증한다.

Conclusion: 제안된 방법은 기하학적 브라운 운동에 기반한 생물학적으로 영감을 받은 생성 모델의 첫 번째 사례가 된다.

Abstract: Gradient descent has proven to be a powerful and effective technique for
optimization in numerous machine learning applications. Recent advances in
computational neuroscience have shown that learning in standard gradient
descent optimization formulation is not consistent with learning in biological
systems. This has opened up interesting avenues for building biologically
inspired learning techniques. One such approach is inspired by Dale's law,
which states that inhibitory and excitatory synapses do not swap roles during
the course of learning. The resulting exponential gradient descent optimization
scheme leads to log-normally distributed synaptic weights. Interestingly, the
density that satisfies the Fokker-Planck equation corresponding to the
stochastic differential equation (SDE) with geometric Brownian motion (GBM) is
the log-normal density. Leveraging this connection, we start with the SDE
governing geometric Brownian motion, and show that discretizing the
corresponding reverse-time SDE yields a multiplicative update rule, which
surprisingly, coincides with the sampling equivalent of the exponential
gradient descent update founded on Dale's law. Furthermore, we propose a new
formalism for multiplicative denoising score-matching, subsuming the loss
function proposed by Hyvaerinen for non-negative data. Indeed, log-normally
distributed data is positive and the proposed score-matching formalism turns
out to be a natural fit. This allows for training of score-based models for
image data and results in a novel multiplicative update scheme for sample
generation starting from a log-normal density. Experimental results on MNIST,
Fashion MNIST, and Kuzushiji datasets demonstrate generative capability of the
new scheme. To the best of our knowledge, this is the first instance of a
biologically inspired generative model employing multiplicative updates,
founded on geometric Brownian motion.

</details>


### [20] [Hybrid-Collaborative Augmentation and Contrastive Sample Adaptive-Differential Awareness for Robust Attributed Graph Clustering](https://arxiv.org/abs/2510.02731)
*Tianxiang Zhao,Youqing Wang,Jinlu Wang,Jiapu Wang,Mingliang Cui,Junbin Gao,Jipeng Guo*

Main category: cs.LG

TL;DR: 제안된 RAGC는 하이브리드 협력 증강과 대조 샘플 적응 차별 인식을 결합하여 그래프 클러스터링 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: CAGC의 한계점을 극복하고, 노드 및 엣지 수준의 임베딩 증강을 모두 활용하여 더 나은 클러스터링 성능을 도모하고자 함.

Method: 노드 및 엣지 수준의 임베딩 표현과 증강을 동시에 실행하고, CSADA 전략을 통해 대조 샘플 쌍을 적응적으로 식별하여 차별적으로 처리함.

Result: 제안된 RAGC는 여러 벤치마크 데이터세트에서 기존 CAGC 방법들보다 우수한 성과를 보임.

Conclusion: RAGC는 하이브리드 기법과 적응형 접근을 통해 그래프 클러스터링의 판별 가능성을 향상시킴.

Abstract: Due to its powerful capability of self-supervised representation learning and
clustering, contrastive attributed graph clustering (CAGC) has achieved great
success, which mainly depends on effective data augmentation and contrastive
objective setting. However, most CAGC methods utilize edges as auxiliary
information to obtain node-level embedding representation and only focus on
node-level embedding augmentation. This approach overlooks edge-level embedding
augmentation and the interactions between node-level and edge-level embedding
augmentations across various granularity. Moreover, they often treat all
contrastive sample pairs equally, neglecting the significant differences
between hard and easy positive-negative sample pairs, which ultimately limits
their discriminative capability. To tackle these issues, a novel robust
attributed graph clustering (RAGC), incorporating hybrid-collaborative
augmentation (HCA) and contrastive sample adaptive-differential awareness
(CSADA), is proposed. First, node-level and edge-level embedding
representations and augmentations are simultaneously executed to establish a
more comprehensive similarity measurement criterion for subsequent contrastive
learning. In turn, the discriminative similarity further consciously guides
edge augmentation. Second, by leveraging pseudo-label information with high
confidence, a CSADA strategy is elaborately designed, which adaptively
identifies all contrastive sample pairs and differentially treats them by an
innovative weight modulation function. The HCA and CSADA modules mutually
reinforce each other in a beneficent cycle, thereby enhancing discriminability
in representation learning. Comprehensive graph clustering evaluations over six
benchmark datasets demonstrate the effectiveness of the proposed RAGC against
several state-of-the-art CAGC methods.

</details>


### [21] [The Curious Case of In-Training Compression of State Space Models](https://arxiv.org/abs/2510.02823)
*Makram Chahine,Philipp Nazari,Daniela Rus,T. Konstantin Rusch*

Main category: cs.LG

TL;DR: 본 연구는 상태 공간 모델(SSMs)의 효율성을 향상시키기 위해 훈련 중 차원 축소 기법을 적용하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 상태 공간 모델(SSMs)은 긴 시퀀스 모델링 작업을 효율적으로 처리하기 위해 개발되었으며, 이는 병렬화된 훈련과 빠른 추론을 제공한다.

Method: 본 연구에서는 Hankel 행렬의 고유값 안정성 특성을 활용하여, 훈련 중 영향력이 높은 차원만을 식별하고 보존하는 접근 방식을 적용하였다.

Result: 실험 결과, 훈련 중 차원 축소가 최적화를 상당히 가속화하면서도 표현력을 유지한다는 것을 보여주었다.

Conclusion: 즉, 훈련 중 크기가 큰 상태 공간 모델이 추후 작아지면서도 높은 성능을 유지하고 계산 효율성을 달성할 수 있음을 시사한다.

Abstract: State Space Models (SSMs), developed to tackle long sequence modeling tasks
efficiently, offer both parallelizable training and fast inference. At their
core are recurrent dynamical systems that maintain a hidden state, with update
costs scaling with the state dimension. A key design challenge is striking the
right balance between maximizing expressivity and limiting this computational
burden. Control theory, and more specifically Hankel singular value analysis,
provides a potent framework for the measure of energy for each state, as well
as the balanced truncation of the original system down to a smaller
representation with performance guarantees. Leveraging the eigenvalue stability
properties of Hankel matrices, we apply this lens to SSMs during training,
where only dimensions of high influence are identified and preserved. Our
approach applies to Linear Time-Invariant SSMs such as Linear Recurrent Units,
but is also extendable to selective models. Experiments show that in-training
reduction significantly accelerates optimization while preserving expressivity,
with compressed models retaining task-critical structure lost by models trained
directly at smaller dimension. In other words, SSMs that begin large and shrink
during training achieve computational efficiency while maintaining higher
performance.

</details>


### [22] [Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning](https://arxiv.org/abs/2510.02945)
*Juan Sebastian Rojas,Chi-Guhn Lee*

Main category: cs.LG

TL;DR: 이 논문은 위험 인식 의사결정의 관점에서 지속적 강화 학습을 이론적으로 다룬 첫 번째 연구로, 새로운 환경에 적응하면서 유용한 정보를 유지하는 RL 에이전트를 개발하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 지속적 강화 학습의 목표는 유용한 정보를 보존하면서 새로운 상황에 적응하는 RL 에이전트를 개발하는 것이다.

Method: 위험 인식 의사결정 관점에서 보상 기반 장기 성능 측정을 최적화하는 RL 에이전트를 이론적으로 연구하고, 기존 위험 측정 이론을 지속 학습 환경에 맞춰 확장한다.

Result: 새로운 범주의 에르고딕 위험 측정을 도입하여 지속적 학습에 적합한 위험 측정 이론을 발전시킨다.

Conclusion: 제안된 에르고딕 위험 측정의 직관적 매력과 이론적 타당성을 보여주는 사례 연구와 경험적 결과를 제공한다.

Abstract: Continual reinforcement learning (continual RL) seeks to formalize the
notions of lifelong learning and endless adaptation in RL. In particular, the
aim of continual RL is to develop RL agents that can maintain a careful balance
between retaining useful information and adapting to new situations. To date,
continual RL has been explored almost exclusively through the lens of
risk-neutral decision-making, in which the agent aims to optimize the expected
(or mean) long-run performance. In this work, we present the first formal
theoretical treatment of continual RL through the lens of risk-aware
decision-making, in which the agent aims to optimize a reward-based measure of
long-run performance beyond the mean. In particular, we show that the classical
theory of risk measures, widely used as a theoretical foundation in
non-continual risk-aware RL, is, in its current form, incompatible with the
continual setting. Then, building on this insight, we extend risk measure
theory into the continual setting by introducing a new class of ergodic risk
measures that are compatible with continual learning. Finally, we provide a
case study of risk-aware continual learning, along with empirical results,
which show the intuitive appeal and theoretical soundness of ergodic risk
measures.

</details>


### [23] [BrainIB++: Leveraging Graph Neural Networks and Information Bottleneck for Functional Brain Biomarkers in Schizophrenia](https://arxiv.org/abs/2510.03004)
*Tianzheng Hu,Qiang Li,Shu Liu,Vince D. Calhoun,Guido van Wingen,Shujian Yu*

Main category: cs.LG

TL;DR: 본 연구에서는 정신 장애 진단을 위한 혁신적인 그래프 신경망 프레임워크인 BrainIB++를 제안하며, 이는 정보 병목 원리를 적용하여 해석을 위한 데이터 기반의 가장 정보성이 높은 뇌 영역을 서브그래프로 식별한다.


<details>
  <summary>Details</summary>
Motivation: 정신 장애의 진단 모델 개발이 활기를 띠고 있으며, 이를 위해 기계 학습 분류기가 사용되고 있다.

Method: 새로운 그래프 신경망 프레임워크인 BrainIB++를 개발하여 정보 병목 원리를 적용하여 모델 훈련 중 서브그래프로 뇌 영역을 식별한다.

Result: 본 모델은 9개의 기존 뇌 네트워크 분류 방법과 비교했을 때 일관되게 우수한 진단 정확도를 보여주었고, 보지 못한 데이터에 대한 일반화 가능성도 입증하였다.

Conclusion: 모델이 식별한 서브그래프는 정신분열증의 확립된 임상 바이오마커와 일치하며, 이는 모델의 해석 가능성을 강화하고 실제 진단 응용에 대한 중요성을 강조한다.

Abstract: The development of diagnostic models is gaining traction in the field of
psychiatric disorders. Recently, machine learning classifiers based on
resting-state functional magnetic resonance imaging (rs-fMRI) have been
developed to identify brain biomarkers that differentiate psychiatric disorders
from healthy controls. However, conventional machine learning-based diagnostic
models often depend on extensive feature engineering, which introduces bias
through manual intervention. While deep learning models are expected to operate
without manual involvement, their lack of interpretability poses significant
challenges in obtaining explainable and reliable brain biomarkers to support
diagnostic decisions, ultimately limiting their clinical applicability. In this
study, we introduce an end-to-end innovative graph neural network framework
named BrainIB++, which applies the information bottleneck (IB) principle to
identify the most informative data-driven brain regions as subgraphs during
model training for interpretation. We evaluate the performance of our model
against nine established brain network classification methods across three
multi-cohort schizophrenia datasets. It consistently demonstrates superior
diagnostic accuracy and exhibits generalizability to unseen data. Furthermore,
the subgraphs identified by our model also correspond with established clinical
biomarkers in schizophrenia, particularly emphasizing abnormalities in the
visual, sensorimotor, and higher cognition brain functional network. This
alignment enhances the model's interpretability and underscores its relevance
for real-world diagnostic applications.

</details>


### [24] [CHORD: Customizing Hybrid-precision On-device Model for Sequential Recommendation with Device-cloud Collaboration](https://arxiv.org/abs/2510.03038)
*Tianqi Liu,Kairui Fu,Shengyu Zhang,Wenyan Fan,Zhaocheng Du,Jieming Zhu,Fan Wu,Fei Wu*

Main category: cs.LG

TL;DR: 모바일 기기의 발전으로 인해, 장치에서 직접 재순위 모델을 배포하여 실시간 컨텍스트 추천이 가능해졌다. 하지만, 모델을 클라우드에서 장치로 이전하면서 자원 이질성이 모델 압축을 필요로 하며, 최근 양자화 방법은 장치-specific 사용자 관심사를 간과하여 추천 정확도가 저하되었다. 이러한 문제를 해결하기 위해, 우리는 장치-클라우드 협업을 통한 연속 추천을 위한 하이브리드 정밀 긴급 모델 사용자화를 위한 CHORD 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 모바일 장치의 향상된 기능 덕분에 재순위 모델을 장치에서 직접 배포하여 실시간으로 컨텍스트 기반 추천을 제공할 수 있게 되었습니다. 그러나 클라우드의 모델을 장치로 이식하면서 리소스 이질성 때문에 모델 압축이 불가피하게 필요해졌습니다.

Method: 우리는 장치-클라우드 협업을 통해 연속 추천을 위한 하이브리드 정밀 온디바이스 모델 사용자화를 위한 CHORD 프레임워크를 제안하며, 채널별 혼합 정밀도 양자화를 활용하여 개인화와 리소스 적응형 배포를 동시에 이룹니다.

Result: CHORD는 이질적인 장치에 무작위로 초기화된 모델을 분산시키고 클라우드의 보조 하이퍼네트워크 모듈을 통해 사용자 특정 중요한 매개변수를 식별합니다.

Conclusion: 세 개의 실제 데이터 세트에서 두 가지 인기 백본(SASRec 및 Caser)으로 실험한 결과, CHORD의 정확성, 효율성 및 적응성이 입증되었습니다.

Abstract: With the advancement of mobile device capabilities, deploying reranking
models directly on devices has become feasible, enabling real-time contextual
recommendations. When migrating models from cloud to devices, resource
heterogeneity inevitably necessitates model compression. Recent quantization
methods show promise for efficient deployment, yet they overlook
device-specific user interests, resulting in compromised recommendation
accuracy. While on-device finetuning captures personalized user preference, it
imposes additional computational burden through local retraining. To address
these challenges, we propose a framework for \underline{\textbf{C}}ustomizing
\underline{\textbf{H}}ybrid-precision \underline{\textbf{O}}n-device model for
sequential \underline{\textbf{R}}ecommendation with
\underline{\textbf{D}}evice-cloud collaboration (\textbf{CHORD}), leveraging
channel-wise mixed-precision quantization to simultaneously achieve
personalization and resource-adaptive deployment. CHORD distributes randomly
initialized models across heterogeneous devices and identifies user-specific
critical parameters through auxiliary hypernetwork modules on the cloud. Our
parameter sensitivity analysis operates across multiple granularities (layer,
filter, and element levels), enabling precise mapping from user profiles to
quantization strategy. Through on-device mixed-precision quantization, CHORD
delivers dynamic model adaptation and accelerated inference without
backpropagation, eliminating costly retraining cycles. We minimize
communication overhead by encoding quantization strategies using only 2 bits
per channel instead of 32-bit weights. Experiments on three real-world datasets
with two popular backbones (SASRec and Caser) demonstrate the accuracy,
efficiency, and adaptivity of CHORD.

</details>


### [25] [Bayesian E(3)-Equivariant Interatomic Potential with Iterative Restratification of Many-body Message Passing](https://arxiv.org/abs/2510.03046)
*Soohaeng Yoo Willow,Tae Hyeon Park,Gi Beom Sim,Sung Wook Moon,Seung Kyu Min,D. ChangMo Yang,Hyun Woo Kim,Juho Lee,Chang Woo Myung*

Main category: cs.LG

TL;DR: 이 연구는 대규모 원자 시뮬레이션을 위한 불확실성 인지가 있는 기계 학습 포텐셜(MLPs)을 개발하여 효율적인 능동 학습과 OOD 검출을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 MLP는 불확실성 정량화에 어려움을 겪고 있어, 능동 학습, 보정 및 OOD 검출에 대한 신뢰성을 제한하고 있다.

Method: 베이지안 E(3) 동등 MLP를 개발하고 다체 메시지 전파의 반복적인 재구성을 통하여 불확실성을 모델링하는 joint energy-force negative log-likelihood (NLL$_\text{JEF}$) 손실 함수를 도입하였다.

Result: 여러 베이지안 접근법을 체계적으로 벤치마킹하고, NLL$_\text{JEF}$가 능동 학습을 효율적으로 촉진함을 보여 주었다. 이 프레임워크는 무작위 샘플링 및 에너지-불확실성 기반 샘플링보다 더 우수한 성능을 나타낸다.

Conclusion: 베이지안 MLP는 최첨단 모델과 비교하여 경쟁력 있는 정확성을 달성하며, 불확실성 주도 능동 학습, OOD 검출 및 에너지/힘 보정을 가능하게 한다.

Abstract: Machine learning potentials (MLPs) have become essential for large-scale
atomistic simulations, enabling ab initio-level accuracy with computational
efficiency. However, current MLPs struggle with uncertainty quantification,
limiting their reliability for active learning, calibration, and
out-of-distribution (OOD) detection. We address these challenges by developing
Bayesian E(3) equivariant MLPs with iterative restratification of many-body
message passing. Our approach introduces the joint energy-force negative
log-likelihood (NLL$_\text{JEF}$) loss function, which explicitly models
uncertainty in both energies and interatomic forces, yielding superior accuracy
compared to conventional NLL losses. We systematically benchmark multiple
Bayesian approaches, including deep ensembles with mean-variance estimation,
stochastic weight averaging Gaussian, improved variational online Newton, and
laplace approximation by evaluating their performance on uncertainty
prediction, OOD detection, calibration, and active learning tasks. We further
demonstrate that NLL$_\text{JEF}$ facilitates efficient active learning by
quantifying energy and force uncertainties. Using Bayesian active learning by
disagreement (BALD), our framework outperforms random sampling and
energy-uncertainty-based sampling. Our results demonstrate that Bayesian MLPs
achieve competitive accuracy with state-of-the-art models while enabling
uncertainty-guided active learning, OOD detection, and energy/forces
calibration. This work establishes Bayesian equivariant neural networks as a
powerful framework for developing uncertainty-aware MLPs for atomistic
simulations at scale.

</details>


### [26] [A Unified Deep Reinforcement Learning Approach for Close Enough Traveling Salesman Problem](https://arxiv.org/abs/2510.03065)
*Mingfeng Fan,Jiaqi Cheng,Yaoxin Wu,Yifeng Zhang,Yibin Yang,Guohua Wu,Guillaume Sartoretti*

Main category: cs.LG

TL;DR: 이 논문은 깊은 강화 학습을 이용한 새로운 통합 이중 디코더 DRL 프레임워크를 통해 가까운 TSP 문제를 해결하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 최근 깊은 강화 학습이 NP-hard 문제인 외판원 문제(TSP)를 해결하는 데 주목받고 있으나, 이웃 기반 방문 기준이 도입된 가까운 TSP(CETSP) 문제에 대한 연구는 제한적입니다.

Method: CETSP를 위해 샘플링 방식을 사용하여 마르코프 결정 프로세스(MDP)를 공식화하고, 의사 결정 과정을 노드 선택과 웨이포인트 결정으로 분리하는 통합 이중 디코더 DRL(UD3RL) 프레임워크를 제안합니다.

Result: UD3RL은 해결 품질과 실행 시간에서 기존 방법을 능가하며, 다양한 문제 크기, 공간 배포 및 반경 범위에 대해 강력한 일반화 능력을 보입니다.

Conclusion: UD3RL은 동적 환경에서도 견고성을 발휘합니다.

Abstract: In recent years, deep reinforcement learning (DRL) has gained traction for
solving the NP-hard traveling salesman problem (TSP). However, limited
attention has been given to the close-enough TSP (CETSP), primarily due to the
challenge introduced by its neighborhood-based visitation criterion, wherein a
node is considered visited if the agent enters a compact neighborhood around
it. In this work, we formulate a Markov decision process (MDP) for CETSP using
a discretization scheme and propose a novel unified dual-decoder DRL (UD3RL)
framework that separates decision-making into node selection and waypoint
determination. Specifically, an adapted encoder is employed for effective
feature extraction, followed by a node-decoder and a loc-decoder to handle the
two sub-tasks, respectively. A k-nearest neighbors subgraph interaction
strategy is further introduced to enhance spatial reasoning during location
decoding. Furthermore, we customize the REINFORCE algorithm to train UD3RL as a
unified model capable of generalizing across different problem sizes and
varying neighborhood radius types (i.e., constant and random radii).
Experimental results show that UD3RL outperforms conventional methods in both
solution quality and runtime, while exhibiting strong generalization across
problem scales, spatial distributions, and radius ranges, as well as robustness
to dynamic environments.

</details>


### [27] [Calibrated Uncertainty Sampling for Active Learning](https://arxiv.org/abs/2510.03162)
*Ha Manh Bui,Iliana Maifeld-Carucci,Anqi Liu*

Main category: cs.LG

TL;DR: 본 논문은 낮은 보정 오류로 분류기를 능동적으로 학습하는 문제를 연구한다. 모델의 불확실성을 기반으로 한 쿼리 방식이 일반적이나, 보정되지 않은 불확실성 모델은 비효율적일 수 있다. 우리는 새로운 Acquisition Function을 제안하고 이를 통해 보정 오류가 낮아진다고 보여준다.


<details>
  <summary>Details</summary>
Motivation: 능동 학습에서 낮은 보정 오류를 가진 분류기를 학습하는 것이 필요하다.

Method: 우리는 보정 오류를 추정하고, DNN 불확실성 활용 전에 보정 오류가 가장 높은 샘플을 쿼리하는 새로운 Acquisition Function을 제안한다.

Result: 제안된 방법은 다른 Acquisition Function의 기준을 뛰어넘어 낮은 보정 및 일반화 오류를 보인다.

Conclusion: 우리가 제안한 방법은 비라벨 풀 및 보지 않은 테스트 데이터에서 구속된 보정 오류를 이끌어낸다.

Abstract: We study the problem of actively learning a classifier with a low calibration
error. One of the most popular Acquisition Functions (AFs) in pool-based Active
Learning (AL) is querying by the model's uncertainty. However, we recognize
that an uncalibrated uncertainty model on the unlabeled pool may significantly
affect the AF effectiveness, leading to sub-optimal generalization and high
calibration error on unseen data. Deep Neural Networks (DNNs) make it even
worse as the model uncertainty from DNN is usually uncalibrated. Therefore, we
propose a new AF by estimating calibration errors and query samples with the
highest calibration error before leveraging DNN uncertainty. Specifically, we
utilize a kernel calibration error estimator under the covariate shift and
formally show that AL with this AF eventually leads to a bounded calibration
error on the unlabeled pool and unseen test data. Empirically, our proposed
method surpasses other AF baselines by having a lower calibration and
generalization error across pool-based AL settings.

</details>


### [28] [Q-Learning with Shift-Aware Upper Confidence Bound in Non-Stationary Reinforcement Learning](https://arxiv.org/abs/2510.03181)
*Ha Manh Bui,Felix Parker,Kimia Ghobadi,Anqi Liu*

Main category: cs.LG

TL;DR: 비정상 강화 학습에 대한 연구로, DQUCB 알고리즘이 도입되어 분포 변화에 대응하여 더 나은 성능을 보임을 확립함.


<details>
  <summary>Details</summary>
Motivation: 비정상적인 분포 변화가 있는 환경에서 강화 학습을 효과적으로 수행하기 위해.

Method: DQUCB 알고리즘은 전이 밀도 함수를 사용하여 분포 변화를 감지하고 불확실성 추정 품질을 향상시킵니다.

Result: DQUCB는 여러 강화 학습 작업과 COVID-19 환자 병원 배정 작업에서 QUCB 기초 모델보다 낮은 후회를 보임.

Conclusion: 이론적으로, DQUCB는 QUCB보다 더 나은 후회 보장을 제공하며, 모형 없는 RL의 계산 효율성을 누림.

Abstract: We study the Non-Stationary Reinforcement Learning (RL) under distribution
shifts in both finite-horizon episodic and infinite-horizon discounted Markov
Decision Processes (MDPs). In the finite-horizon case, the transition functions
may suddenly change at a particular episode. In the infinite-horizon setting,
such changes can occur at an arbitrary time step during the agent's interaction
with the environment. While the Q-learning Upper Confidence Bound algorithm
(QUCB) can discover a proper policy during learning, due to the distribution
shifts, this policy can exploit sub-optimal rewards after the shift happens. To
address this issue, we propose Density-QUCB (DQUCB), a shift-aware
Q-learning~UCB algorithm, which uses a transition density function to detect
distribution shifts, then leverages its likelihood to enhance the uncertainty
estimation quality of Q-learning~UCB, resulting in a balance between
exploration and exploitation. Theoretically, we prove that our oracle DQUCB
achieves a better regret guarantee than QUCB. Empirically, our DQUCB enjoys the
computational efficiency of model-free RL and outperforms QUCB baselines by
having a lower regret across RL tasks, as well as a real-world COVID-19 patient
hospital allocation task using a Deep-Q-learning architecture.

</details>


### [29] [Best-of-Majority: Minimax-Optimal Strategy for Pass@$k$ Inference Scaling](https://arxiv.org/abs/2510.03199)
*Qiwei Di,Kaixuan Ji,Xuheng Li,Heyang Zhao,Quanquan Gu*

Main category: cs.LG

TL;DR: 이 연구는 Pass@$k$ 추론 설정에서 최적의 성능을 위해 Best-of-Majority(BoM)라는 새로운 추론 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 LLM 추론 방식에서는 어려운 작업에 대해 단일 선택이 충분하지 않음을 관찰하였다.

Method: Best-of-Majority (BoM)라는 새로운 전략을 제안하며, 이는 빈도가 높은 응답 후보로 제한한 후 상위 $k$ 보상을 선택하는 방식이다.

Result: 실험 결과, BoM이 기존의 다수결 및 Best-of-N 전략보다 우수함을 입증하였다.

Conclusion: BoM는 최적의 성능을 보이며, 샘플 예산을 증가시켜도 성능이 저하되지 않는 주요 장점이 있다.

Abstract: LLM inference often generates a batch of candidates for a prompt and selects
one via strategies like majority voting or Best-of- N (BoN). For difficult
tasks, this single-shot selection often underperforms. Consequently,
evaluations commonly report Pass@$k$: the agent may submit up to $k$ responses,
and only the best of them is used when computing regret. Motivated by this, we
study inference scaling in the more general Pass@$k$ inference setting, and
prove that neither majority voting nor BoN exhibits the desirable scaling with
$k$ and the sampling budget $N$. Combining the advantages of majority voting
and BoN, we propose a new inference strategy called Best-of-Majority (BoM),
with a pivotal step that restricts the candidates to the responses with high
frequency in the $N$ samples before selecting the top-$k$ rewards. We prove
that when the sampling budget is $N=\tilde\Omega(C^*)$, the regret of BoM is
$O(\epsilon_{\mathrm{opt}}+\sqrt{\epsilon_{\mathrm{RM}}^2C^*/k})$, where $C^*$
is the coverage coefficient, $\epsilon_{\mathrm{RM}}$ is the estimation error
of the reward model, and $\epsilon_{\mathrm{opt}}$ is the estimation error of
reward at the optimal response. We further establish a matching lower bound,
certifying that our algorithm is minimax optimal. Beyond optimality, BoM has a
key advantage: unlike majority voting and BoN, its performance does not degrade
when increasing $N$. Experimental results of inference on math problems show
BoM outperforming both majority voting and BoN.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [30] [BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks](https://arxiv.org/abs/2510.02418)
*Sagnik Anupam,Davis Brown,Shuo Li,Eric Wong,Hamed Hassani,Osbert Bastani*

Main category: cs.AI

TL;DR: BrowserArena는 사용자 제출 작업을 수집하고, 대면 비교를 통해 웹 에이전트를 평가하는 플랫폼으로, CAPTCHA 해결, 팝업 배너 제거, URL 직접 내비게이션 등 세 가지 주요 실패 모드를 식별합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 에이전트 평가는 제한된 환경이나 인공 작업에만 국한되어 있으며, 실제 웹에서의 성능을 평가할 필요가 있습니다.

Method: 사용자 제출 작업을 수집하고 Arena 스타일의 비교를 통해 에이전트를 평가하며, 단계별 인간 피드백을 통해 실패 모드를 분석합니다.

Result: 세 가지 일관된 실패 모드인 CAPTCHA 해결, 팝업 배너 제거, URL 직접 내비게이션을 식별했습니다. 또한 다양한 언어 모델이 이러한 실패 모드를 탐색하는 방식의 차이를 발견했습니다.

Conclusion: 현재 웹 에이전트의 다양성과 취약성을 드러내며, 웹 에이전트의 실패 모드를 평가하고 이해하기 위한 접근 방식을 제시합니다.

Abstract: LLM web agents now browse and take actions on the open web, yet current agent
evaluations are constrained to sandboxed environments or artificial tasks. We
introduce BrowserArena, a live open-web agent evaluation platform that collects
user-submitted tasks, runs Arena-style head-to-head comparisons, and uses
step-level human feedback to surface failure modes. Collecting and analyzing
step-level annotations on the agent traces, we identify three consistent
failure modes: captcha resolution, pop-up banner removal, and direct navigation
to URLs. By constructing targeted datasets to further study these tasks, we
discover variations in how different language models navigate these failure
modes. We find, for example, that o4-mini deploys a wider variety of strategies
to circumvent captcha resolution than other models and DeepSeek-R1 consistently
misleads users about captcha resolution. Our findings surface both the
diversity and brittleness of current web agents. More broadly, our benchmarking
methodology provides an approach to evaluating and understanding web agent
failure modes at scale.

</details>


### [31] [Safe and Efficient In-Context Learning via Risk Control](https://arxiv.org/abs/2510.02480)
*Andrea Wynn,Metod Jazbec,Charith Peris,Rinat Khaziev,Anqi Liu,Daniel Khashabi,Eric Nalisnick*

Main category: cs.AI

TL;DR: 본 논문은 위해한 예시로 모델 성능이 저하되는 정도를 제한하는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)은 몇 가지 예시로부터 새로운 작업을 학습하는 뛰어난 능력을 보여주지만, 이는 잘못되거나 악의적인 시연에 의해 영향을 받을 수 있다는 안전성 문제를 제기한다.

Method: 기존의 위험 제어 방법을 개선하여, 위해한 샘플이 성능을 저하시키는 정도를 제어하는데 동적 조기 종료 예측을 활용한다.

Result: 이 접근 방식은 위해한 예시로 인한 위험을 효과적으로 제어하면서, 유용한 시연에서도 상당한 계산 효율성을 달성하는 것을 보여준다.

Conclusion: 제안된 방법은 위해한 입력에 대한 위험을 제어하고 유용한 입력에서 성능과 효율성을 동시에 향상시킬 수 있음을 이론적 및 경험적으로 입증하였다.

Abstract: Large language models (LLMs) demonstrate a remarkable ability to learn new
tasks from a few in-context examples. However, this flexibility introduces
safety concerns: LLMs can be influenced by incorrect or malicious
demonstrations -- for example, if an adversary tampers with or injects harmful
examples without a human supervisor noticing. This motivates principled designs
in which the system itself includes built-in mechanisms to guard against such
attacks. We propose a novel approach to limit the degree to which harmful
demonstrations can degrade model performance. First, we define a baseline
``safe'' behavior for the model -- the model's performance given no in-context
demonstrations (zero-shot). Next, we apply distribution-free risk control
(DFRC) to control the extent to which in-context samples can decay performance
below zero-shot. We achieve this by leveraging dynamic early exit prediction,
ignoring later attention heads that attend the most to the unsafe inputs.
Finally, we propose modifications to DFRC that allow it to both control risk
for harmful inputs \textit{and} leverage performance and efficiency gains on
helpful inputs. We present both theoretical and empirical results showing that
our approach can effectively control risk for harmful in-context demonstrations
while simultaneously achieving substantial computational efficiency gains with
helpful demonstrations.

</details>


### [32] [Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research Challenge](https://arxiv.org/abs/2510.02557)
*Charlie Masters,Advaith Vellanki,Jiangbo Shangguan,Bart Kultys,Jonathan Gilmore,Alastair Moore,Stefano V. Albrecht*

Main category: cs.AI

TL;DR: 이 논문은 동적 인간-AI 팀 내에서 협업을 조정하는 자율 에이전트 시스템에 대한 연구 비전을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 개별 작업을 자동화하는 에이전트적 AI가 발전하고 있지만, 복잡한 다중 에이전트 워크플로우 관리는 여전히 도전적인 문제이다.

Method: 복잡한 목표를 작업 그래프로 분해하고, 인간과 AI 작업자에게 작업을 할당하며, 진행 상황을 모니터링하고 변화하는 조건에 적응하는 핵심 도전으로 자율 관리자 에이전트를 제안한다. 우리는 워크플로 관리의 형식을 부분 관찰 가능한 확률적 게임으로 정의하고 네 가지 기본적인 도전을 식별한다.

Result: 20개 워크플로에 걸쳐 GPT-5 기반 관리자 에이전트를 평가한 결과, 목표 완수, 제약 준수 및 워크플로 실행 시간을 공동으로 최적화하는 데 어려움을 겪고 있음을 발견하였다.

Conclusion: 우리는 자율 관리 시스템의 조직적 및 윤리적 함의로 결론을 맺는다.

Abstract: While agentic AI has advanced in automating individual tasks, managing
complex multi-agent workflows remains a challenging problem. This paper
presents a research vision for autonomous agentic systems that orchestrate
collaboration within dynamic human-AI teams. We propose the Autonomous Manager
Agent as a core challenge: an agent that decomposes complex goals into task
graphs, allocates tasks to human and AI workers, monitors progress, adapts to
changing conditions, and maintains transparent stakeholder communication. We
formalize workflow management as a Partially Observable Stochastic Game and
identify four foundational challenges: (1) compositional reasoning for
hierarchical decomposition, (2) multi-objective optimization under shifting
preferences, (3) coordination and planning in ad hoc teams, and (4) governance
and compliance by design. To advance this agenda, we release MA-Gym, an
open-source simulation and evaluation framework for multi-agent workflow
orchestration. Evaluating GPT-5-based Manager Agents across 20 workflows, we
find they struggle to jointly optimize for goal completion, constraint
adherence, and workflow runtime - underscoring workflow management as a
difficult open problem. We conclude with organizational and ethical
implications of autonomous management systems.

</details>


### [33] [Improving Cooperation in Collaborative Embodied AI](https://arxiv.org/abs/2510.03153)
*Hima Jacob Leven Suprabha,Laxmi Nag Laxminarayan Nagesh,Ajith Nair,Alvin Reuben Amal Selvaster,Ayan Khan,Raghuram Damarla,Sanju Hannah Samuel,Sreenithi Saravana Perumal,Titouan Puech,Venkataramireddy Marella,Vishal Sonar,Alessandro Suglia,Oliver Lemon*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)의 다중 에이전트 시스템 통합을 통해 협업 추론 및 AI 에이전트와의 협력이 가능해졌다.


<details>
  <summary>Details</summary>
Motivation: LLM을 통한 에이전트 협업 행동 및 의사 결정 향상의 가능성을 탐구.

Method: LLM과 프롬프트 엔지니어링 전략을 통해 다양한 실험을 수행하여 최적의 조합을 찾아 최적화된 성과를 이끌어냈다.

Result: 최고 조합이 Gemma3로 운영되는 시스템의 효율성을 22% 향상시켰다.

Conclusion: 프롬프트 최적화가 협업 에이전트 성능을 향상시키는 효과가 있음을 강조하며, 음성 통합이 사용자 인터페이스의 매력을 더했다.

Abstract: The integration of Large Language Models (LLMs) into multiagent systems has
opened new possibilities for collaborative reasoning and cooperation with AI
agents. This paper explores different prompting methods and evaluates their
effectiveness in enhancing agent collaborative behaviour and decision-making.
We enhance CoELA, a framework designed for building Collaborative Embodied
Agents that leverage LLMs for multi-agent communication, reasoning, and task
coordination in shared virtual spaces. Through systematic experimentation, we
examine different LLMs and prompt engineering strategies to identify optimised
combinations that maximise collaboration performance. Furthermore, we extend
our research by integrating speech capabilities, enabling seamless
collaborative voice-based interactions. Our findings highlight the
effectiveness of prompt optimisation in enhancing collaborative agent
performance; for example, our best combination improved the efficiency of the
system running with Gemma3 by 22% compared to the original CoELA system. In
addition, the speech integration provides a more engaging user interface for
iterative system development and demonstrations.

</details>


### [34] [Agentic Additive Manufacturing Alloy Discovery](https://arxiv.org/abs/2510.02567)
*Peter Pak,Achuth Chandrasekhar,Amir Barati Farimani*

Main category: cs.AI

TL;DR: 이 논문은 LLM(대규모 언어 모델) 기반 에이전트를 활용하여 적층 제조 분야에서 합금 발견을 자동화하고 가속화하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 적층 제조에서 합금 발견은 복잡한 도전 과제로, 재료 과학, 열역학 시뮬레이션 및 실험 분석 분야의 전문 지식이 필요합니다.

Method: LLM 기반 에이전트는 Model Context Protocol(MCP)을 통해 Thermo-Calc 속성 다이어그램 계산 및 융합 부족 공정 맵 생성을 수행하는 툴 호출을 전송합니다.

Result: 개발된 다중 에이전트 시스템은 사용자 프롬프트를 효과적으로 처리하고 제안된 합금의 인쇄 가능성에 대한 분석을 제공합니다.

Conclusion: 이 연구는 LLM 기반 에이전트를 활용하여 적층 제조 분야에서 합금 발견 작업을 자동화하고 가속화하는 것을 목표로 합니다.

Abstract: Agentic systems enable the intelligent use of research tooling, augmenting a
researcher's ability to investigate and propose novel solutions to existing
problems. Within Additive Manufacturing (AM), alloy discovery remains a complex
challenge, often requiring expertise in the various domains of materials
science, thermodynamic simulations, and experimental analysis. Large Language
Model (LLM) enabled agents can facilitate this endeavor by utilizing their
extensive knowledge base to dispatch tool calls via Model Context Protocol
(MCP) to perform actions such as Thermo-Calc property diagram calculations and
lack of fusion process map generation. In addition, the multi-agent system
developed in this work is able to effectively reason through complex user
prompts and provide analysis on the printability of proposed alloys. These
agents can dynamically adjust their task trajectory to the outcomes of tool
call results, effectively enabling autonomous decision-making in practical
environments. This work aims to utilize LLM enabled agents to automate and
accelerate the task of alloy discovery within the field of additive
manufacturing and showcase the benefits of adopting this multi-agent system.

</details>


### [35] [A Benchmark Study of Deep Reinforcement Learning Algorithms for the Container Stowage Planning Problem](https://arxiv.org/abs/2510.02589)
*Yunqi Huang,Nishith Chennakeshava,Alexis Carras,Vladislav Neverov,Wei Liu,Aske Plaat,Yingjie Fan*

Main category: cs.AI

TL;DR: 이 논문은 CSPP를 위한 여러 강화 학습 방법을 벤치마킹하고, 크레인 스케줄링을 포함한 재사용 가능한 Gym 환경을 제공한다.


<details>
  <summary>Details</summary>
Motivation: CSPP는 해상 운송 및 터미널 운영의 핵심 요소로, 공급망 효율성에 직접적인 영향을 미친다.

Method: CSPP의 기본 기능을 포착하는 Gym 환경을 개발하고, 다중 에이전트 및 단일 에이전트 형식으로 크레인 스케줄링을 포함하도록 확장한다. DQN, QR-DQN, A2C, PPO, TRPO의 다섯 가지 RL 알고리즘을 여러 복잡성 시나리오에서 평가한다.

Result: 복잡성이 증가함에 따라 뚜렷한 성능 차이를 보이며, 알고리즘 선택과 문제 형식화의 중요성을 강조한다.

Conclusion: 이 논문은 CSPP를 위한 여러 RL 방법을 벤치마킹하고, 향후 해상 물류 연구 및 실용적 배치를 위한 기초를 제공하는 재사용 가능한 Gym 환경을 제공한다.

Abstract: Container stowage planning (CSPP) is a critical component of maritime
transportation and terminal operations, directly affecting supply chain
efficiency. Owing to its complexity, CSPP has traditionally relied on human
expertise. While reinforcement learning (RL) has recently been applied to CSPP,
systematic benchmark comparisons across different algorithms remain limited. To
address this gap, we develop a Gym environment that captures the fundamental
features of CSPP and extend it to include crane scheduling in both multi-agent
and single-agent formulations. Within this framework, we evaluate five RL
algorithms: DQN, QR-DQN, A2C, PPO, and TRPO under multiple scenarios of varying
complexity. The results reveal distinct performance gaps with increasing
complexity, underscoring the importance of algorithm choice and problem
formulation for CSPP. Overall, this paper benchmarks multiple RL methods for
CSPP while providing a reusable Gym environment with crane scheduling, thus
offering a foundation for future research and practical deployment in maritime
logistics.

</details>


### [36] [Mitigating Modal Imbalance in Multimodal Reasoning](https://arxiv.org/abs/2510.02608)
*Chen Henry Wu,Neil Kale,Aditi Raghunathan*

Main category: cs.AI

TL;DR: 대규모 모델들이 다양한 모달리티를 통합하는 능력과 서로 간의 상호작용에서의 갈등 상황을 해결하는 방식을 연구하였다.


<details>
  <summary>Details</summary>
Motivation: 대규모 모델들이 여러 모달리티에서의 동시 추론 능력을 이해하고자 함.

Method: 갈등 예제를 통해 대규모 모델들의 모달리티 간 우선순위를 분석하고, 훈련 예제를 통한 주의 불균형 문제를 해결하는 방법을 제안함.

Result: 대규모 모델들은 단일 모달리티에서는 90%의 정확도로 갈등을 인식하지만, 여러 모달리티에 걸쳐 데이터를 나눌 경우 인식률이 3%로 떨어짐.

Conclusion: 모달리티 간 주의 불균형 문제를 해결하기 위해 훈련 인스턴스 내에서 명시적으로 모달리티를 결합하는 방법을 사용해야 함.

Abstract: Foundation models (FMs) deployed in real-world tasks such as computer-use
agents must integrate diverse modalities. How good are FMs at performing joint
reasoning, simultaneously reasoning over multiple modalities, especially when
the modalities interact and relate to each other to form cross-modal context?
To better understand this problem, we study FMs on cross-modal conflicts:
scenarios where conflicting evidence is presented across modalities. This
allows us to examine whether FMs prioritize one modality over another or reason
jointly to reconcile the conflict. Our experiments reveal that FMs can
recognize conflicts in unimodal contexts, composed of a single modality, 90% of
the time, but the ratio falls as low as 3% when evidence is split across
modalities -- similar observations hold in cross-lingual contexts, composed of
multiple languages. We trace this failure to cross-modal attention imbalance,
showing that FMs exhibit extreme asymmetry in attention scores,
disproportionately prioritizing certain modalities. We show that cross-modal
attention imbalance does not go away by simply scaling up multimodal or
multilingual datasets blindly, since they lack training examples that
explicitly require cross-modal reasoning. We demonstrate that even a simple and
scalable method of explicitly combining multiple modalities within each
training instance significantly reduces attention imbalance. Reduced attention
imbalance directly translates to improved downstream performance on several
vision-language benchmarks. Our findings underscore the importance of
systematically addressing cross-modal contexts to build reliable foundation
models.

</details>


### [37] [AutoMaAS: Self-Evolving Multi-Agent Architecture Search for Large Language Models](https://arxiv.org/abs/2510.02669)
*Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Liu*

Main category: cs.AI

TL;DR: AutoMaAS는 쿼리 복잡성과 도메인 요구 사항에 따라 리소스 할당을 적응할 수 있는 자동 설계 접근 방식을 제시한 다중 에이전트 아키텍처 검색 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 다양한 도메인에서 뛰어난 능력을 보여주는 대형 언어 모델 기반의 다중 에이전트 시스템이 존재하지만, 기존의 자동화된 설계 접근 방식은 쿼리 복잡성과 도메인 요구 사항에 적응하지 못하는 단일체 솔루션을 추구한다.

Method: AutoMaAS는 신경망 아키텍처 검색 원리를 활용하여 동적 연산자 생애 주기 관리 및 자동화된 기계 학습 기술을 통해 최적의 에이전트 구성을 자동으로 발견하는 자기 진화하는 다중 에이전트 아키텍처 검색 프레임워크이다.

Result: 여섯 개의 벤치마크에 걸친 광범위한 실험 결과 AutoMaAS는 최첨단 방법에 비해 1.0-7.1%의 성능 향상을 달성하면서 추론 비용을 3-5% 줄임을 보여준다.

Conclusion: 이 프레임워크는 데이터세트 및 LLM 백본 간의 뛰어난 이전 가능성을 보여주며, 대형 언어 모델 시대의 자동화된 다중 에이전트 시스템 설계를 위한 새로운 패러다임을 설정한다.

Abstract: Multi-agent systems powered by large language models have demonstrated
remarkable capabilities across diverse domains, yet existing automated design
approaches seek monolithic solutions that fail to adapt resource allocation
based on query complexity and domain requirements. This paper introduces
AutoMaAS, a self-evolving multi-agent architecture search framework that
leverages neural architecture search principles to automatically discover
optimal agent configurations through dynamic operator lifecycle management and
automated machine learning techniques. Our approach incorporates four key
innovations: (1) automatic operator generation, fusion, and elimination based
on performance-cost analysis, (2) dynamic cost-aware optimization with
real-time parameter adjustment, (3) online feedback integration for continuous
architecture refinement, and (4) enhanced interpretability through decision
tracing mechanisms. Extensive experiments across six benchmarks demonstrate
that AutoMaAS achieves 1.0-7.1\% performance improvement while reducing
inference costs by 3-5\% compared to state-of-the-art methods. The framework
shows superior transferability across datasets and LLM backbones, establishing
a new paradigm for automated multi-agent system design in the era of large
language models.

</details>


### [38] [ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks](https://arxiv.org/abs/2510.02677)
*Zhaorun Chen,Xun Liu,Mintong Kang,Jiawei Zhang,Minzhou Pan,Shuang Yang,Bo Li*

Main category: cs.AI

TL;DR: ARMs는 비전-언어 모델(VLM)의 안전 평가를 위해 다양한 공격 전략을 자동으로 최적화하는 적응형 레드팀 에이전트입니다.


<details>
  <summary>Details</summary>
Motivation: 비전-언어 모델(VLM)의 다중 모드 인터페이스는 새로운 안전 취약점을 발생시키며, 기존의 레드 팀 노력은 좁은 적대적 패턴에 국한되거나 수동 엔지니어링에 의존하여 증가하는 실제 VLM 취약점을 탐색하는 데 한계가 있습니다.

Method: ARMs는 위험 정의에 따라 다양한 레드팀 전략을 자동으로 최적화하고, 11가지 새로운 다중 모드 공격 전략과 17개의 레드팀 알고리즘을 통합하여 VLM으로부터 유해한 출력을 효과적으로 유도합니다.

Result: ARMs는 SOTA 공격 성공률을 달성하며, 평균 52.1% 이상으로 기준을 초과하고 Claude-4-Sonnet에서 90% 이상의 성공률을 보입니다.

Conclusion: ARMs-Bench를 활용한 안전 세부 조정은 VLM의 견고성을 크게 향상시키고, 새로운 위협에 대한 안전 정렬 개선을 위한 실행 가능한 지침을 제공합니다.

Abstract: As vision-language models (VLMs) gain prominence, their multimodal interfaces
also introduce new safety vulnerabilities, making the safety evaluation
challenging and critical. Existing red-teaming efforts are either restricted to
a narrow set of adversarial patterns or depend heavily on manual engineering,
lacking scalable exploration of emerging real-world VLM vulnerabilities. To
bridge this gap, we propose ARMs, an adaptive red-teaming agent that
systematically conducts comprehensive risk assessments for VLMs. Given a target
harmful behavior or risk definition, ARMs automatically optimizes diverse
red-teaming strategies with reasoning-enhanced multi-step orchestration, to
effectively elicit harmful outputs from target VLMs. We propose 11 novel
multimodal attack strategies, covering diverse adversarial patterns of VLMs
(e.g., reasoning hijacking, contextual cloaking), and integrate 17 red-teaming
algorithms into ARMs via model context protocol (MCP). To balance the diversity
and effectiveness of the attack, we design a layered memory with an
epsilon-greedy attack exploration algorithm. Extensive experiments on instance-
and policy-based benchmarks show that ARMs achieves SOTA attack success rates,
exceeding baselines by an average of 52.1% and surpassing 90% on
Claude-4-Sonnet. We show that the diversity of red-teaming instances generated
by ARMs is significantly higher, revealing emerging vulnerabilities in VLMs.
Leveraging ARMs, we construct ARMs-Bench, a large-scale multimodal safety
dataset comprising over 30K red-teaming instances spanning 51 diverse risk
categories, grounded in both real-world multimodal threats and regulatory
risks. Safety fine-tuning with ARMs-Bench substantially improves the robustness
of VLMs while preserving their general utility, providing actionable guidance
to improve multimodal safety alignment against emerging threats.

</details>


### [39] [Beyond the Final Answer: Evaluating the Reasoning Trajectories of Tool-Augmented Agents](https://arxiv.org/abs/2510.02837)
*Wonjoong Kim,Sangwu Park,Yeonjun In,Sein Kim,Dongha Lee,Chanyoung Park*

Main category: cs.AI

TL;DR: 이 논문에서는 TOOL-증강 LLM 에이전트 성능을 다차원적으로 평가하기 위한 TRACE 프레임워크를 소개하며, 대규모 및 비용 효율적으로 복잡한 행동을 평가할 수 있음을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 사용자 요청을 해결하는 데 필요한 단계를 평가하는 방법이 필요하다.

Method: TRACE 프레임워크를 통해 이전 추론 단계에서 수집된 지식을 기반으로 증거 은행을 통합하여 에이전트의 추론 경로를 다각적으로 분석하고 평가한다.

Result: TRACE가 복잡한 행동을 정확하게 평가하며, 작은 오픈 소스 LLM에 대해서도 확장 가능하고 비용 효율적인 평가가 가능함을 보여준다.

Conclusion: TRACE는 툴-증강 작업을 해결하는 과정에서 에이전트가 만들어낸 경로를 평가하는 데 효과적이다.

Abstract: Although recent tool-augmented benchmarks incorporate complex user requests
and diverse tools, the evaluation methods for most of them remain limited to
answer matching. However, as the number of steps required to resolve a user
request increases, a proper evaluation of an agent's performance must go beyond
the final answer to also assess the problem-solving trajectory, including
previously ignored aspects such as efficiency, hallucination, and adaptivity.
The most straightforward method for evaluating these aspects is to compare an
agent's trajectory with the ground-truth trajectory, but this approach is
fundamentally limited since annotating all valid ground-truth trajectories is
prohibitively expensive. However, a simple LLM-based evaluator struggles to
assess trajectories in detail without ground truth. To effectively evaluate the
agents in this manner, we introduce TRACE, a framework for the
multi-dimensional evaluation of tool-augmented LLM agent performance. By
incorporating an evidence bank, which accumulates knowledge gathered from
preceding reasoning steps, TRACE enables a multi-faceted analysis and
evaluation of an agent's reasoning trajectory effectively. To validate our
framework, we develop a new meta-evaluation dataset by augmenting existing
benchmarks with diverse and flawed trajectories, each labeled with
multi-faceted performance scores. Our results confirm that TRACE accurately
evaluates these complex behaviors in a scalable and cost-effective manner, even
with small open-source LLMs. Furthermore, we apply our method to evaluate the
trajectories that agents produce while solving tool-augmented tasks, presenting
previously unreported observations and their corresponding insights.

</details>


### [40] [CoDA: Agentic Systems for Collaborative Data Visualization](https://arxiv.org/abs/2510.03194)
*Zichen Chen,Jiefeng Chen,Sercan Ö. Arik,Misha Sra,Tomas Pfister,Jinsung Yoon*

Main category: cs.AI

TL;DR: 이 논문은 다중 에이전트 시스템인 CoDA를 제안하여 자연어 쿼리 기반의 데이터 시각화 자동화를 개선하며, 기존 시스템의 한계를 극복하고 41.5%의 성능 향상을 이룬다.


<details>
  <summary>Details</summary>
Motivation: 데이터 과학자들이 복잡한 데이터셋을 수작업으로 시각화하는 데 많은 시간을 소모하는 문제를 해결하고자 한다.

Method: CoDA는 메타데이터 분석, 작업 계획, 코드 생성 및 자기 반성을 수행하는 특화된 LLM 에이전트를 활용하는 다중 에이전트 시스템이다.

Result: CoDA는 경쟁 기준을 최대 41.5%까지 초과하는 성과를 달성했다.

Conclusion: 시각화 자동화의 미래는 독립적인 코드 생성이 아니라 통합된 협업 에이전트 워크플로우에 달려 있음을 시사한다.

Abstract: Deep research has revolutionized data analysis, yet data scientists still
devote substantial time to manually crafting visualizations, highlighting the
need for robust automation from natural language queries. However, current
systems struggle with complex datasets containing multiple files and iterative
refinement. Existing approaches, including simple single- or multi-agent
systems, often oversimplify the task, focusing on initial query parsing while
failing to robustly manage data complexity, code errors, or final visualization
quality. In this paper, we reframe this challenge as a collaborative
multi-agent problem. We introduce CoDA, a multi-agent system that employs
specialized LLM agents for metadata analysis, task planning, code generation,
and self-reflection. We formalize this pipeline, demonstrating how
metadata-focused analysis bypasses token limits and quality-driven refinement
ensures robustness. Extensive evaluations show CoDA achieves substantial gains
in the overall score, outperforming competitive baselines by up to 41.5%. This
work demonstrates that the future of visualization automation lies not in
isolated code generation but in integrated, collaborative agentic workflows.

</details>


### [41] [Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner](https://arxiv.org/abs/2510.03206)
*Cai Zhou,Chenxiao Yang,Yi Hu,Chenyu Wang,Chubin Zhang,Muhan Zhang,Lester Mackey,Tommi Jaakkola,Stephen Bates,Dinghuai Zhang*

Main category: cs.AI

TL;DR: 이 논문은 연속 확산 모델이 불연속 확산 및 루프 변환기보다 더 강한 표현력을 가지며, 코에볼루션 연속 불연속 확산(CCDD)을 제안하여 이를 실현한다.


<details>
  <summary>Details</summary>
Motivation: 연속 확산 모델이 불연속 모델보다 낮은 성능을 보이는 문제를 해결하고자 한다.

Method: 연속 표현 공간과 불연속 토큰 공간의 결합된 다중 모드 확산 과정을 정의하는 CCDD를 제안한다.

Result: CCDD는 결합된 공간에서 동시에 노이즈 제거를 수행하며, 강력한 표현력과 좋은 학습 가능성 및 샘플 품질을 보여준다.

Conclusion: CCDD는 실제 작업에서의 대규모 언어 모델링 실험에서 강력한 경험적 성능을 드러낸다.

Abstract: Diffusion language models, especially masked discrete diffusion models, have
achieved great success recently. While there are some theoretical and primary
empirical results showing the advantages of latent reasoning with looped
transformers or continuous chain-of-thoughts, continuous diffusion models
typically underperform their discrete counterparts. In this paper, we argue
that diffusion language models do not necessarily need to be in the discrete
space. In particular, we prove that continuous diffusion models have stronger
expressivity than discrete diffusions and looped transformers. We attribute the
contradiction between the theoretical expressiveness and empirical performance
to their practical trainability: while continuous diffusion provides
intermediate supervision that looped transformers lack, they introduce
additional difficulty decoding tokens into the discrete token space from the
continuous representation space. We therefore propose Coevolutionary Continuous
Discrete Diffusion (CCDD), which defines a joint multimodal diffusion process
on the union of a continuous representation space and a discrete token space,
leveraging a single model to simultaneously denoise in the joint space. By
combining two modalities, CCDD is expressive with rich semantics in the latent
space, as well as good trainability and sample quality with the help of
explicit discrete tokens. We also propose effective architectures and advanced
training/sampling techniques for CCDD, which reveals strong empirical
performance in extensive language modeling experiments on real-world tasks.

</details>
