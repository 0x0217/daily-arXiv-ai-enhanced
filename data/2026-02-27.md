<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 13]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.CR](#cs.CR) [Total: 3]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [From Cooperation to Hierarchy: A Study of Dynamics of Hierarchy Emergence in a Multi-Agent System](https://arxiv.org/abs/2602.21404)
*Shanshan Mao,Peter Tino*

Main category: cs.MA

TL;DR: 개별 변이가 상위 조직 구조의 출현을 촉진할 수 있는 정보를 생성할 수 있다는 점을 조사하기 위해 에이전트 기반 모델을 개발하였다. 이 연구는 계층 구축의 최소 조건을 규명하고, 초기 이질성과 돌연변이의 크기가 다세대에 걸쳐 계층 조직에 미치는 영향을 분석하였다. 결과적으로, 계층 질서는 돌연변이의 크기에 더 민감하게 반응하며, 안정적인 계층 구조는 효과적인 수준의 돌연변이가 있을 때만 형성된다.


<details>
  <summary>Details</summary>
Motivation: 진화 생물학의 중심 전제로서 개별 변이가 정보 비대칭을 생성할 수 있고, 이는 계층 조직의 출현을 촉진할 수 있다는 점을 확인하고자 하였다.

Method: 다중 에이전트 시스템에서 계층 구조가 발생하는 최소 조건을 식별하기 위해 에이전트 기반 모델(ABM)을 개발하고, 초기 이질성과 세대 간 돌연변이 크기의 역할에 집중하였다.

Result: 결과적으로, 작은 개별 차이도 번식을 포함한 반복적 지역 상호작용을 통해 확대될 수 있으며, 계층 구조는 초기 이질성보다 돌연변이의 크기에 크게 영향을 받는다는 사실이 나타났다.

Conclusion: 결론적으로, 간단한 상호작용 규칙이 어떻게 계층 조직의 출현과 지속성을 초래할 수 있는지를 보여주며, 초기 동질적인 집단에서 구조화된 불평등이 어떻게 발전할 수 있는지에 대한 정량적 설명을 제공한다.

Abstract: A central premise in evolutionary biology is that individual variation can generate information asymmetries that facilitate the emergence of hierarchical organisation. To examine this process, we develop an agent-based model (ABM) to identify the minimal conditions under which hierarchy arises in dynamic multi-agent systems, focusing on the roles of initial heterogeneity and mutation amplitude across generations. Hierarchical organisation is quantified using the Trophic Incoherence (TI) metric, which captures directional asymmetries in interaction networks. Our results show that even small individual differences can be amplified through repeated local interactions involving reproduction, competition, and cooperation, but that hierarchical order is markedly more sensitive to mutation amplitude than to initial heterogeneity. Across repeated trials, stable hierarchies reliably emerge only when mutation amplitude is sufficiently high, while initial heterogeneity primarily affects early formation rather than long-term persistence. Overall, these findings demonstrate how simple interaction rules can give rise to both the emergence and persistence of hierarchical organisation, providing a quantitative account of how structured inequality can develop from initially homogeneous populations.

</details>


### [2] [Pancake: Hierarchical Memory System for Multi-Agent LLM Serving](https://arxiv.org/abs/2602.21477)
*Zhengding Hu,Zaifeng Pan,Prabhleen Kaur,Vibha Murthy,Zhongkai Yu,Yue Guan,Zhen Wang,Steven Swanson,Yufei Ding*

Main category: cs.MA

TL;DR: 이 연구에서는 LLM 서비스에서 에이전트 메모리 관리의 핵심 문제를 해결하기 위한 Pancake라는 다단계 메모리 시스템을 제안하여 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: LLM 서비스에서 대규모 저장소와 빈번한 업데이트, 여러 에이전트의 존재가 ANS 검색의 복잡성과 비용을 증가시킵니다.

Method: Pancake는 다단계 인덱스 캐싱, 다중 에이전트 간 조정된 인덱스 관리, 협력적인 GPU-CPU 가속을 통합한 시스템입니다.

Result: Pancake는 기존 프레임워크보다 4.29배 이상의 전반적인 처리량 향상을 달성하며, 실용적인 에이전트 작업에서 탁월한 성과를 보입니다.

Conclusion: Pancake는 Mem-GPT와 같은 메모리 기반 에이전트에 통합할 수 있는 사용하기 쉬운 인터페이스를 제공합니다.

Abstract: In this work, we identify and address the core challenges of agentic memory management in LLM serving, where large-scale storage, frequent updates, and multiple coexisting agents jointly introduce complex and high-cost approximate nearest neighbor (ANN) searching problems. We present Pancake, a multi-tier agentic memory system that unifies three key techniques: (i) multi-level index caching for single agents, (ii) coordinated index management across multiple agents, and (iii) collaborative GPU-CPU acceleration. Pancake exposes easy-to-use interface that can be integrated into memory-based agents like Mem-GPT, and is compatible with agentic frameworks such as LangChain and LlamaIndex. Experiments on realistic agent workloads show that Pancake substantially outperforms existing frameworks, achieving more than 4.29x end-to-end throughput improvement.

</details>


### [3] [Using Feasible Action-Space Reduction by Groups to fill Causal Responsibility Gaps in Spatial Interactions](https://arxiv.org/abs/2602.22041)
*Vassil Guenov,Ashwin George,Arkady Zgonnikov,David A. Abbink,Luciano Cavalcante Siebert*

Main category: cs.MA

TL;DR: 자동차와 모바일 로봇의 발전으로 인해 공간적 상호작용에서의 책임이 중요한 연구 주제로 부각되고 있다.


<details>
  <summary>Details</summary>
Motivation: 공간적 상호작용에서 책임에 대한 메트릭스가 제안되고 있지만, 대부분이 개별 행위자의 책임에만 초점을 맞추고 있다.

Method: 개별 중심의 메트릭스에서 발생하는 원인 책임의 격차를 메우기 위해 집단의 원인 책임 메트릭스를 수립하고, assertive influence의 유형을 공식화한 후 assertive agents를 체계적으로 식별하기 위한 계층 알고리즘을 제안하였다.

Result: 시나리오 기반 시뮬레이션을 통해 집단을 고려할 때의 이점과 상호작용 동역학 및 행위자 간의 근접성에 따라 집단 효과의 발생 방식이 달라진다는 것을 설명하였다.

Conclusion: 이 연구는 공간적 상호작용에서 집단의 책임을 이해하는 데 기여하며, 개별적 책임에 국한되지 않는 새로운 시각을 제시한다.

Abstract: Heralding the advent of autonomous vehicles and mobile robots that interact with humans, responsibility in spatial interaction is burgeoning as a research topic. Even though metrics of responsibility tailored to spatial interactions have been proposed, they are mostly focused on the responsibility of individual agents. Metrics of causal responsibility focusing on individuals fail in cases of causal overdeterminism -- when many actors simultaneously cause an outcome. To fill the gaps in causal responsibility left by individual-focused metrics, we formulate a metric for the causal responsibility of groups. To identify assertive agents that are causally responsible for the trajectory of an affected agent, we further formalise the types of assertive influences and propose a tiering algorithm for systematically identifying assertive agents. Finally, we use scenario-based simulations to illustrate the benefits of considering groups and how the emergence of group effects vary with interaction dynamics and the proximity of agents.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Uncertainty-Aware Diffusion Model for Multimodal Highway Trajectory Prediction via DDIM Sampling](https://arxiv.org/abs/2602.21319)
*Marion Neumeier,Niklas Roßberg,Michael Botsch,Wolfgang Utschick*

Main category: cs.LG

TL;DR: cVMDx는 자율 주행을 위한 향상된 확산 기반 경로 예측 프레임워크로, 효율성과 강인성, 다중 모드 예측 능력을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 정확하고 불확실성을 인식한 경로 예측은 자율 주행의 핵심 과제이다.

Method: cVMDx는 DDIM 샘플링을 사용하여 추론 시간을 최대 100배 줄이고, 적합된 가우시안 혼합 모델을 통해 다중 모드 예측을 제공한다.

Result: cVMDx는 공개된 highD 데이터셋에서 더 높은 정확도와 개선된 효율성을 보여주었다.

Conclusion: cVMDx는 완전한 확률론적 다중 모드 경로 예측을 가능하게 한다.

Abstract: Accurate and uncertainty-aware trajectory prediction remains a core challenge for autonomous driving, driven by complex multi-agent interactions, diverse scene contexts and the inherently stochastic nature of future motion. Diffusion-based generative models have recently shown strong potential for capturing multimodal futures, yet existing approaches such as cVMD suffer from slow sampling, limited exploitation of generative diversity and brittle scenario encodings.
  This work introduces cVMDx, an enhanced diffusion-based trajectory prediction framework that improves efficiency, robustness and multimodal predictive capability. Through DDIM sampling, cVMDx achieves up to a 100x reduction in inference time, enabling practical multi-sample generation for uncertainty estimation. A fitted Gaussian Mixture Model further provides tractable multimodal predictions from the generated trajectories. In addition, a CVQ-VAE variant is evaluated for scenario encoding. Experiments on the publicly available highD dataset show that cVMDx achieves higher accuracy and significantly improved efficiency over cVMD, enabling fully stochastic, multimodal trajectory prediction.

</details>


### [5] [Tool-R0: Self-Evolving LLM Agents for Tool-Learning from Zero Data](https://arxiv.org/abs/2602.21320)
*Emre Can Acikgoz,Cheng Qian,Jonas Hübotter,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.LG

TL;DR: Tool-R0 프레임워크는 템플릿 없이 자기 플레이 RL을 사용하여 일반 도구 호출 에이전트를 처음부터 훈련시키는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 에이전트가 도구를 사용하여 복잡한 작업을 해결할 수 있도록 하는 데 필요한 에이전틱 능력을 주입하기 위해.

Method: Tool-R0는 동일한 기본 LLM에서 초기화되어 보완적인 보상으로 Generator와 Solver를 공동 진화시킵니다.

Result: Tool-R0는 기본 모델에 대해 92.5의 상대적 향상을 달성하고 동일한 설정에서 완전히 감독된 도구 호출 기준을 초과합니다.

Conclusion: 이 연구는 자기 플레이 LLM 에이전트에 대한 경험적 통찰력을 제공합니다.

Abstract: Large language models (LLMs) are becoming the foundation for autonomous agents that can use tools to solve complex tasks. Reinforcement learning (RL) has emerged as a common approach for injecting such agentic capabilities, but typically under tightly controlled training setups. It often depends on carefully constructed task-solution pairs and substantial human supervision, which creates a fundamental obstacle to open-ended self-evolution toward superintelligent systems. In this paper, we propose Tool-R0 framework for training general purpose tool-calling agents from scratch with self-play RL, under a zero-data assumption. Initialized from the same base LLM, Tool-R0 co-evolves a Generator and a Solver with complementary rewards: one proposes targeted challenging tasks at the other's competence frontier and the other learns to solve them with real-world tool calls. This creates a self-evolving cycle that requires no pre-existing tasks or datasets. Evaluation on different tool-use benchmarks show that Tool-R0 yields 92.5 relative improvement over the base model and surpasses fully supervised tool-calling baselines under the same setting. Our work further provides empirical insights into self-play LLM agents by analyzing co-evolution, curriculum dynamics, and scaling behavior.

</details>


### [6] [Black-Box Reliability Certification for AI Agents via Self-Consistency Sampling and Conformal Calibration](https://arxiv.org/abs/2602.21368)
*Charafeddine Mouzouni*

Main category: cs.LG

TL;DR: 본 논문은 블랙박스 AI 시스템의 신뢰성을 평가하기 위한 방법을 제시하며, 시스템-작업 쌍마다 단일 숫자로 신뢰 수준을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 블랙박스 AI 시스템의 출력에 대한 신뢰 수준을 정량적으로 평가하고, 신뢰할 수 있는 배포의 기준을 마련하고자 한다.

Method: 자기 일관성 샘플링과 일관된 보정을 통해 신뢰 수준을 산출하고, 이를 바탕으로 시스템의 결과가 정확한지를 평가한다.

Result: 신뢰성이 낮은 모델은 더 낮은 신뢰 수준을 기록하며, GPT-4.1은 GSM8K에서 94.6%, TruthfulQA에서 96.8%의 신뢰성을 보여주었고, GPT-4.1-nano는 각각 89.8%와 66.5%의 신뢰성을 기록했다.

Conclusion: 우리는 다섯 개의 벤치마크와 다섯 개의 모델을 사용하여 결과를 검증하였고, 해결 가능한 항목에 대한 조건부 커버리지가 모든 구성이 0.93을 초과함을 보였다.

Abstract: Given a black-box AI system and a task, at what confidence level can a practitioner trust the system's output? We answer with a reliability level -- a single number per system-task pair, derived from self-consistency sampling and conformal calibration, that serves as a black-box deployment gate with exact, finite-sample, distribution-free guarantees. Self-consistency sampling reduces uncertainty exponentially; conformal calibration guarantees correctness within 1/(n+1) of the target level, regardless of the system's errors -- made transparently visible through larger answer sets for harder questions. Weaker models earn lower reliability levels (not accuracy -- see Definition 2.4): GPT-4.1 earns 94.6% on GSM8K and 96.8% on TruthfulQA, while GPT-4.1-nano earns 89.8% on GSM8K and 66.5% on MMLU. We validate across five benchmarks, five models from three families, and both synthetic and real data. Conditional coverage on solvable items exceeds 0.93 across all configurations; sequential stopping reduces API costs by around 50%.

</details>


### [7] [AgentLTV: An Agent-Based Unified Search-and-Evolution Framework for Automated Lifetime Value Prediction](https://arxiv.org/abs/2602.21634)
*Chaowei Wu,Huazhu Chen,Congde Yuan,Qirui Yang,Guoqing Song,Yue Gao,Li Luo,Frank Youhua Chen,Mengzhuo Guo*

Main category: cs.LG

TL;DR: AgentLTV는 자동 LTV 모델링을 위한 에이전트 기반 통합 검색 및 진화 프레임워크로, 각 후보 솔루션을 실행 가능한 파이프라인 프로그램으로 취급하여 복잡한 의사 결정 시나리오를 효율적으로 처리한다.


<details>
  <summary>Details</summary>
Motivation: LTV 예측은 광고, 추천 시스템 및 전자 상거래에서 매우 중요하지만, 실제로 LTV 데이터 패턴은 의사 결정 시나리오에 따라 다양하다.

Method: AgentLTV는 에이전트를 사용하여 코드 생성, 파이프라인 실행 및 수정, 실행 피드백 분석을 수행하며, 두 개의 의사 결정 에이전트가 두 단계의 검색을 조정한다. MCTS 단계는 고정된 예산 내에서 모델 선택의 넓은 영역을 탐색하고, EA 단계는 최선의 MCTS 프로그램을 개선한다.

Result: 대규모 독점 데이터셋과 공개 벤치마크 실험에서 AgentLTV가 강력한 모델을 지속적으로 발견함을 보여준다.

Conclusion: MCTS를 사용하여 새로운 데이터 패턴에 빠르게 적응하고, EA를 사용하여 안정적인 개선을 하며, 버킷 수준의 순위 및 보정 진단으로 배포 준비 상태를 검증하라고 요약된다.

Abstract: Lifetime Value (LTV) prediction is critical in advertising, recommender systems, and e-commerce. In practice, LTV data patterns vary across decision scenarios. As a result, practitioners often build complex, scenario-specific pipelines and iterate over feature processing, objective design, and tuning. This process is expensive and hard to transfer. We propose AgentLTV, an agent-based unified search-and-evolution framework for automated LTV modeling. AgentLTV treats each candidate solution as an {executable pipeline program}. LLM-driven agents generate code, run and repair pipelines, and analyze execution feedback. Two decision agents coordinate a two-stage search. The Monte Carlo Tree Search (MCTS) stage explores a broad space of modeling choices under a fixed budget, guided by the Polynomial Upper Confidence bounds for Trees criterion and a Pareto-aware multi-metric value function. The Evolutionary Algorithm (EA) stage refines the best MCTS program via island-based evolution with crossover, mutation, and migration. Experiments on a large-scale proprietary dataset and a public benchmark show that AgentLTV consistently discovers strong models across ranking and error metrics. Online bucket-level analysis further indicates improved ranking consistency and value calibration, especially for high-value and negative-LTV segments. We summarize practitioner-oriented takeaways: use MCTS for rapid adaptation to new data patterns, use EA for stable refinement, and validate deployment readiness with bucket-level ranking and calibration diagnostics. The proposed AgentLTV has been successfully deployed online.

</details>


### [8] [WaterVIB: Learning Minimal Sufficient Watermark Representations via Variational Information Bottleneck](https://arxiv.org/abs/2602.21508)
*Haoyuan He,Yu Zheng,Jie Zhou,Jiwen Lu*

Main category: cs.LG

TL;DR: 이 논문에서는 기존의 수분실수 공격에 취약한 방수 방법의 문제를 해결하기 위해 WaterVIB라는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 정수 재산 보호를 위한 강력한 워터마킹이 매우 중요하지만, 기존 방법들이 재생 기반 공격에 대해 심각한 취약성을 가지기 때문에 이를 해결할 필요가 있습니다.

Method: WaterVIB는 변분 정보 병목 현상(Variational Information Bottleneck)을 이용하여 인코더를 정보 체로 재구성하는 이론적으로 기반한 프레임워크입니다.

Result: WaterVIB는 상태-of-the-art 방법들에 비해 상당히 우수한 성능을 보여주며, 알려지지 않은 확산 기반 편집에 대해 탁월한 제로샷 복원력을 달성합니다.

Conclusion: 이 연구는 배포 이동 공격에 대한 견고성을 확보하기 위해 이 병목 현상을 최적화하는 것이 필요하다는 것을 이론적으로 증명합니다.

Abstract: Robust watermarking is critical for intellectual property protection, whereas existing methods face a severe vulnerability against regeneration-based AIGC attacks. We identify that existing methods fail because they entangle the watermark with high-frequency cover texture, which is susceptible to being rewritten during generative purification. To address this, we propose WaterVIB, a theoretically grounded framework that reformulates the encoder as an information sieve via the Variational Information Bottleneck. Instead of overfitting to fragile cover details, our approach forces the model to learn a Minimal Sufficient Statistic of the message. This effectively filters out redundant cover nuances prone to generative shifts, retaining only the essential signal invariant to regeneration. We theoretically prove that optimizing this bottleneck is a necessary condition for robustness against distribution-shifting attacks. Extensive experiments demonstrate that WaterVIB significantly outperforms state-of-the-art methods, achieving superior zero-shot resilience against unknown diffusion-based editing.

</details>


### [9] [Hierarchical Lead Critic based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.21680)
*David Eckel,Henri Meeß*

Main category: cs.LG

TL;DR: 이 논문에서는 다중 관점에서 학습하는 새로운 MARL 아키텍처와 훈련 방식을 제안하여 성능을 향상시키고 샘플 효율성을 높입니다.


<details>
  <summary>Details</summary>
Motivation: 협력적 다중 에이전트 강화 학습(MARL)은 여러 에이전트 간의 조 coordinating이 필요한 복잡한 작업을 해결하지만, 종종 지역적 또는 글로벌 관점으로 제한됩니다.

Method: 층계적 리드 비평(HLC)을 도입하여 서로 다른 계층 수준에서 다양한 관점으로부터의 학습을 가능하게 하는 새로운 훈련 방식을 제안합니다.

Result: HLC는 여러 계층을 도입하고 지역적 및 글로벌 관점을 활용하여 성능을 향상시키고 높은 샘플 효율성과 강력한 정책을 보여줍니다.

Conclusion: 실험 결과는 HLC가 단일 계층 기준선보다 성능이 뛰어나고 증가하는 에이전트 수와 난이도에서도 강건하게 확장된다는 것을 보여줍니다.

Abstract: Cooperative Multi-Agent Reinforcement Learning (MARL) solves complex tasks that require coordination from multiple agents, but is often limited to either local (independent learning) or global (centralized learning) perspectives. In this paper, we introduce a novel sequential training scheme and MARL architecture, which learns from multiple perspectives on different hierarchy levels. We propose the Hierarchical Lead Critic (HLC) - inspired by natural emerging distributions in team structures, where following high-level objectives combines with low-level execution. HLC demonstrates that introducing multiple hierarchies, leveraging local and global perspectives, can lead to improved performance with high sample efficiency and robust policies. Experimental results conducted on cooperative, non-communicative, and partially observable MARL benchmarks demonstrate that HLC outperforms single hierarchy baselines and scales robustly with increasing amounts of agents and difficulty.

</details>


### [10] [Proximal-IMH: Proximal Posterior Proposals for Independent Metropolis-Hastings with Approximate Operators](https://arxiv.org/abs/2602.21426)
*Youguang Chen,George Biros*

Main category: cs.LG

TL;DR: 이 논문은 바이어스 문제 해결을 위한 Proximal-IMH 샘플링 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 과학, 공학, 이미징에서의 베이지안 역 문제에서 발생하는 후방 분포 샘플링 문제를 고려한다.

Method: 유도된 근사 후방 분포에서 샘플링하면서 바이어스를 제거하는 Proximal-IMH 방법을 소개한다.

Result: Proximal-IMH는 기존 IMH 변형들보다 신뢰성 있게 성능을 발휘한다.

Conclusion: 이 방법은 정확한 후방 샘플링이 비용이 큰 역 문제에 적합하다.

Abstract: We consider the problem of sampling from a posterior distribution arising in Bayesian inverse problems in science, engineering, and imaging. Our method belongs to the family of independence Metropolis-Hastings (IMH) sampling algorithms, which are common in Bayesian inference. Relying on the existence of an approximate posterior distribution that is cheaper to sample from but may have significant bias, we introduce Proximal-IMH, a scheme that removes this bias by correcting samples from the approximate posterior through an auxiliary optimization problem. This yields a local adjustment that trades off adherence to the exact model against stability around the approximate reference point. For idealized settings, we prove that the proximal correction tightens the match between approximate and exact posteriors, thereby improving acceptance rates and mixing. The method applies to both linear and nonlinear input-output operators and is particularly suitable for inverse problems where exact posterior sampling is too expensive. We present numerical experiments including multimodal and data-driven priors with nonlinear input-output operators. The results show that Proximal-IMH reliably outperforms existing IMH variants.

</details>


### [11] [ABM-UDE: Developing Surrogates for Epidemic Agent-Based Models via Scientific Machine Learning](https://arxiv.org/abs/2602.21588)
*Sharv Murgai,Utkarsh Utkarsh,Kyle C. Nguyen,Alan Edelman,Erin C. S. Acquesta,Christopher Vincent Rackauckas*

Main category: cs.LG

TL;DR: 대리 모델을 통해 감염병 확산 예측의 속도를 개선하고, 의사결정 지원을 위한 신뢰할 수 있는 경량 대체 모델을 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 병원 계획을 위한 밤 시간 동안의 속도 문제를 해결하기 위해 독창적인 대리 모델을 개발하고자 하였다.

Method: UDE(Universal Differential Equations)을 사용하여 에이전트 기반 전염병 모델의 경량 대체 모델을 만들고, 신경망으로 파라미터화된 접촉률을 적용하였다.

Result: 대리 모델은 77%의 평균 MSE 감소를 기록하며, 신뢰도 또한 향상되었다.

Conclusion: 이 연구는 에이전트 기반 모델을 대체하기 위한 빠르고 신뢰할 수 있는 경량 모델 개발을 통해 의사결정 지원을 향상시켰다.

Abstract: Agent-based epidemic models (ABMs) encode behavioral and policy heterogeneity but are too slow for nightly hospital planning. We develop county-ready surrogates that learn directly from exascale ABM trajectories using Universal Differential Equations (UDEs): mechanistic SEIR-family ODEs with a neural-parameterized contact rate $κ_φ(u,t)$ (no additive residual). Our contributions are threefold: we adapt multiple shooting and an observer-based prediction-error method (PEM) to stabilize identification of neural-augmented epidemiological dynamics across intervention-driven regime shifts; we enforce positivity and mass conservation and show the learned contact-rate parameterization yields a well-posed vector field; and we quantify accuracy, calibration, and compute against ABM ensembles and UDE baselines. On a representative ExaEpi scenario, PEM-UDE reduces mean MSE by 77% relative to single-shooting UDE (3.00 vs. 13.14) and by 20% relative to MS-UDE (3.75). Reliability improves in parallel: empirical coverage of ABM $10$-$90$% and $25$-$75$% bands rises from 0.68/0.43 (UDE) and 0.79/0.55 (MS-UDE) to 0.86/0.61 with PEM-UDE and 0.94/0.69 with MS+PEM-UDE, indicating calibrated uncertainty rather than overconfident fits. Inference runs in seconds on commodity CPUs (20-35 s per $\sim$90-day forecast), enabling nightly ''what-if'' sweeps on a laptop. Relative to a $\sim$100 CPU-hour ABM reference run, this yields $\sim10^{4}\times$ lower wall-clock per scenario. This closes the realism-cadence gap, supports threshold-aware decision-making (e.g., maintaining ICU occupancy $<75$%), preserves mechanistic interpretability, and enables calibrated, risk-aware scenario planning on standard institutional hardware. Beyond epidemics, the ABM$\to$UDE recipe provides a portable path to distill agent-based simulators into fast, trustworthy surrogates for other scientific domains.

</details>


### [12] [GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL](https://arxiv.org/abs/2602.22190)
*Rui Yang,Qianhui Wu,Zhaoyang Wang,Hanyang Chen,Ke Yang,Hao Cheng,Huaxiu Yao,Baoling Peng,Huan Zhang,Jianfeng Gao,Tong Zhang*

Main category: cs.LG

TL;DR: 오픈소스 GUI 에이전트는 장기 내비게이션 작업에서 클로즈드 소스 시스템에 비해 아직 미흡하다. 이 논문에서는 이러한 격차의 원인을 고품질의 행동 정렬 추론 데이터 부족과 GUI 에이전트의 고유한 도전 과제를 간과한 일반적인 후속 훈련 파이프라인의 직접적인 적용에서 찾는다. 저자들은 이 문제를 해결하기 위해 GUI-Libra라는 맞춤형 훈련 레시피를 제안하며, 이는 훈련 데이터와 추론을 조화시키고 RL을 안정화하는 여러 기법을 포함한다.


<details>
  <summary>Details</summary>
Motivation: 오픈소스 네이티브 GUI 에이전트가 긴 기간의 내비게이션 작업에서 클로즈드 소스 시스템보다 뒤쳐져 있다는 문제를 해결하고자 한다.

Method: GUI-Libra는 행동 정렬 추론 데이터를 위한 데이터 구성 및 필터링 파이프라인을 소개하고, 행동-인식 SFT를 통해 추론과 그라운딩을 조화시키며, KL 정규화를 활용하여 RL을 안정화한다.

Result: GUI-Libra는 다양한 웹 및 모바일 벤치마크에서 단계별 정확성과 엔드 투 엔드 작업 완료율을 일관되게 개선한다.

Conclusion: 신중하게 설계된 후속 훈련과 데이터 선별을 통해 비싼 온라인 데이터 수집 없이도 훨씬 더 강력한 작업 해결 능력을 발휘할 수 있음을 시사한다.

Abstract: Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks. This gap stems from two limitations: a shortage of high-quality, action-aligned reasoning data, and the direct adoption of generic post-training pipelines that overlook the unique challenges of GUI agents. We identify two fundamental issues in these pipelines: (i) standard SFT with CoT reasoning often hurts grounding, and (ii) step-wise RLVR-tyle training faces partial verifiability, where multiple actions can be correct but only a single demonstrated action is used for verification. This makes offline step-wise metrics weak predictors of online task success. In this work, we present GUI-Libra, a tailored training recipe that addresses these challenges. First, to mitigate the scarcity of action-aligned reasoning data, we introduce a data construction and filtering pipeline and release a curated 81K GUI reasoning dataset. Second, to reconcile reasoning with grounding, we propose action-aware SFT that mixes reasoning-then-action and direct-action data and reweights tokens to emphasize action and grounding. Third, to stabilize RL under partial verifiability, we identify the overlooked importance of KL regularization in RLVR and show that a KL trust region is critical for improving offline-to-online predictability; we further introduce success-adaptive scaling to downweight unreliable negative gradients. Across diverse web and mobile benchmarks, GUI-Libra consistently improves both step-wise accuracy and end-to-end task completion. Our results suggest that carefully designed post-training and data curation can unlock significantly stronger task-solving capabilities without costly online data collection. We release our dataset, code, and models to facilitate further research on data-efficient post-training for reasoning-capable GUI agents.

</details>


### [13] [TiMi: Empower Time Series Transformers with Multimodal Mixture of Experts](https://arxiv.org/abs/2602.21693)
*Jiafeng Lin,Yuxuan Wang,Huakun Luo,Zhongyi Pei,Jianmin Wang*

Main category: cs.LG

TL;DR: 멀티모달 시계열 예측에서 텍스트 정보의 역할을 반영하고 LLM의 인과 추론 능력을 활용하는 TiMi를 제안함.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 데이터는 기존 단일 모달 모델보다 더 정확한 예측을 제공할 잠재력이 있지만, 모달 정렬의 도전 과제로 인해 기존 방법들은 이를 효과적으로 통합하는 데 어려움을 겪고 있음.

Method: TiMi는 LLM을 활용하여 미래의 발전에 대한 추론을 생성하고, 이를 시계열 예측을 위한 가이드로 활용하며, MMoE 모듈을 도입하여 Transformer 기반 모델을 강화함.

Result: 제안된 TiMi는 16개의 실제 세계 멀티모달 예측 벤치마크에서 일관된 최첨단 성능을 보이며, 고급 기준을 초과 달성함.

Conclusion: 강력한 적응성 및 해석 가능성을 제공하는 TiMi는 멀티모달 예측을 위한 효과적인 솔루션이 됨.

Abstract: Multimodal time series forecasting has garnered significant attention for its potential to provide more accurate predictions than traditional single-modality models by leveraging rich information inherent in other modalities. However, due to fundamental challenges in modality alignment, existing methods often struggle to effectively incorporate multimodal data into predictions, particularly textual information that has a causal influence on time series fluctuations, such as emergency reports and policy announcements. In this paper, we reflect on the role of textual information in numerical forecasting and propose Time series transformers with Multimodal Mixture-of-Experts, TiMi, to unleash the causal reasoning capabilities of LLMs. Concretely, TiMi utilizes LLMs to generate inferences on future developments, which serve as guidance for time series forecasting. To seamlessly integrate both exogenous factors and time series into predictions, we introduce a Multimodal Mixture-of-Experts (MMoE) module as a lightweight plug-in to empower Transformer-based time series models for multimodal forecasting, eliminating the need for explicit representation-level alignment. Experimentally, our proposed TiMi demonstrates consistent state-of-the-art performance on sixteen real-world multimodal forecasting benchmarks, outperforming advanced baselines while offering both strong adaptability and interpretability.

</details>


### [14] [DocDjinn: Controllable Synthetic Document Generation with VLMs and Handwriting Diffusion](https://arxiv.org/abs/2602.21824)
*Marcel Lamott,Saifullah Saifullah,Nauman Riaz,Yves-Noel Weweler,Tobias Alt-Veit,Ahmad Sarmad Ali,Muhammad Armaghan Shakir,Adrian Kalwa,Momina Moetesum,Andreas Dengel,Sheraz Ahmed,Faisal Shafait,Ulrich Schwanecke,Adrian Ulges*

Main category: cs.LG

TL;DR: 이 논문에서는 효과적인 문서 지능 모델을 위한 새로운 합성 문서 생성 프레임워크인 DocDjinn을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 합성 문서 생성을 통해 양질의 주석 데이터 수집의 문제를 해결하고자 한다.

Method: Vision-Language Models(VLMs)를 활용한 제어 가능한 합성 문서 생성 프레임워크를 제안한다.

Result: 100개의 실제 훈련 샘플로도 전체 실제 데이터셋의 87%의 성능을 달성하였다.

Conclusion: 이 연구는 VLM을 사용하여 라벨이 없는 샘플로부터 주석이 달린 문서 데이터셋을 대규모로 생성할 수 있음을 보여준다.

Abstract: Effective document intelligence models rely on large amounts of annotated training data. However, procuring sufficient and high-quality data poses significant challenges due to the labor-intensive and costly nature of data acquisition. Additionally, leveraging language models to annotate real documents raises concerns about data privacy. Synthetic document generation has emerged as a promising, privacy-preserving alternative. We propose DocDjinn, a novel framework for controllable synthetic document generation using Vision-Language Models (VLMs) that produces annotated documents from unlabeled seed samples. Our approach generates visually plausible and semantically consistent synthetic documents that follow the distribution of an existing source dataset through clustering-based seed selection with parametrized sampling. By enriching documents with realistic diffusion-based handwriting and contextual visual elements via semantic-visual decoupling, we generate diverse, high-quality annotated synthetic documents. We evaluate across eleven benchmarks spanning key information extraction, question answering, document classification, and document layout analysis. To our knowledge, this is the first work demonstrating that VLMs can generate faithful annotated document datasets at scale from unlabeled seeds that can effectively enrich or approximate real, manually annotated data for diverse document understanding tasks. We show that with only 100 real training samples, our framework achieves on average $87\%$ of the performance of the full real-world dataset. We publicly release our code and 140k+ synthetic document samples.

</details>


### [15] [Bayesian Generative Adversarial Networks via Gaussian Approximation for Tabular Data Synthesis](https://arxiv.org/abs/2602.21948)
*Bahrul Ilmi Nasution,Mark Elliot,Richard Allmendinger*

Main category: cs.LG

TL;DR: GACTGAN은 Bayesian 후행 근사 기법을 사용하여 CTGAN 생성기 내에서 표 형식 데이터를 합성하고, 훈련 후 계산 과부하를 줄이며, CTGAN보다 우수한 합성 데이터를 생성함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존의 조건부 표형 GAN(CTGAN)이 리스크-유틸리티 균형을 효과적으로 조절하는 데 어려움을 겪고 있으며, Bayesian GAN은 표 형식 데이터에 대한 관심이 적다.

Method: CTGAN 생성기 내에 Stochastic Weight Averaging-Gaussian(SWAG)을 활용한 Bayesian 후행 근사 기법을 통합하여 Gaussian Approximation of CTGAN(GACTGAN)을 도입하였다.

Result: GACTGAN은 CTGAN보다 더 나은 합성 데이터를 생성하며, 표 형식 구조와 추론 통계의 보존이 더 우수하고 개인 정보 노출 위험이 적다.

Conclusion: GACTGAN은 Bayesian 표 형식 합성의 더 간단하고 효과적인 구현으로 강조된다.

Abstract: Generative Adversarial Networks (GAN) have been used in many studies to synthesise mixed tabular data. Conditional tabular GAN (CTGAN) have been the most popular variant but struggle to effectively navigate the risk-utility trade-off. Bayesian GAN have received less attention for tabular data, but have been explored with unstructured data such as images and text. The most used technique employed in Bayesian GAN is Markov Chain Monte Carlo (MCMC), but it is computationally intensive, particularly in terms of weight storage. In this paper, we introduce Gaussian Approximation of CTGAN (GACTGAN), an integration of the Bayesian posterior approximation technique using Stochastic Weight Averaging-Gaussian (SWAG) within the CTGAN generator to synthesise tabular data, reducing computational overhead after the training phase. We demonstrate that GACTGAN yields better synthetic data compared to CTGAN, achieving better preservation of tabular structure and inferential statistics with less privacy risk. These results highlight GACTGAN as a simpler, effective implementation of Bayesian tabular synthesis.

</details>


### [16] [Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data](https://arxiv.org/abs/2602.22018)
*Sterre de Jonge,Elisabeth J. Vinke,Meike W. Vernooij,Daniel C. Alexander,Alexandra L. Young,Esther E. Bron*

Main category: cs.LG

TL;DR: Mixed Events 모델은 연속 데이터와 이산 데이터를 모두 처리할 수 있는 새로운 질병 진행 모델이다.


<details>
  <summary>Details</summary>
Motivation: 질병 진행 모델링은 단기 바이오마커 데이터에서 장기 질병 경과를 식별하는 강력한 프레임워크를 제공한다.

Method: Mixed Events 모델은 Subtype and Stage Inference(SuStaIn) 프레임워크 내에서 구현되어 Mixed-SuStaIn을 통해 아형 및 진행 모델링을 가능하게 한다.

Result: Mixed-SuStaIn은 실험을 통해 시뮬레이션 및 알츠하이머병 신경영상 이니셔티브의 실제 데이터를 통해 그 효과성을 입증하였다.

Conclusion: Mixed-SuStaIn은 혼합 데이터 세트에서 잘 작동한다.

Abstract: Disease progression modeling provides a robust framework to identify long-term disease trajectories from short-term biomarker data. It is a valuable tool to gain a deeper understanding of diseases with a long disease trajectory, such as Alzheimer's disease. A key limitation of most disease progression models is that they are specific to a single data type (e.g., continuous data), thereby limiting their applicability to heterogeneous, real-world datasets. To address this limitation, we propose the Mixed Events model, a novel disease progression model that handles both discrete and continuous data types. This model is implemented within the Subtype and Stage Inference (SuStaIn) framework, resulting in Mixed-SuStaIn, enabling subtype and progression modeling. We demonstrate the effectiveness of Mixed-SuStaIn through simulation experiments and real-world data from the Alzheimer's Disease Neuroimaging Initiative, showing that it performs well on mixed datasets. The code is available at: https://github.com/ucl-pond/pySuStaIn.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives](https://arxiv.org/abs/2602.21351)
*Dmitrii Pantiukhin,Ivan Kuznetsov,Boris Shapkin,Antonia Anna Jost,Thomas Jung,Nikolay Koldunov*

Main category: cs.AI

TL;DR: PANGAEA-GPT는 자율적 데이터 탐색 및 분석을 위한 계층적 다중 에이전트 프레임워크를 제안하며, 복잡한 작업을 최소한의 인간 개입으로 수행할 수 있는 능력을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 지구 과학 데이터의 빠른 축적은 상당한 확장성 문제를 야기하여 많은 데이터가 사용되지 않고 있다.

Method: 중앙 집중형 Supervisor-Worker 구조를 채택하고, 데이터 유형 인식 라우팅 및 실행 피드백을 통한 자기 수정 기능을 구현하여, 에이전트가 런타임 오류를 진단하고 해결할 수 있게 한다.

Result: 물리 해양학 및 생태학을 포함한 사용 사례 시나리오를 통해 복잡하고 다단계의 작업 흐름을 최소한의 인간 개입으로 실행할 수 있는 시스템의 능력을 입증하였다.

Conclusion: 이 프레임워크는 조정된 에이전트 작업 흐름을 통해 이질적인 저장소 데이터를 쿼리하고 분석하는 방법론을 제공한다.

Abstract: The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.

</details>


### [18] [Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information](https://arxiv.org/abs/2602.21496)
*Umid Suleymanov,Zaur Rajabov,Emil Mirzazada,Murat Kantarcioglu*

Main category: cs.AI

TL;DR: 이 논문은 Large Language Models(LLMs)가 생성하는 의미적 민감 정보(SemSI)의 위험을 해결하기 위한 SemSIEdit라는 새로운 방안을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLMs는 민감한 신원 속성을 추론하거나, 평판에 해를 끼치는 콘텐츠를 생성하는 등 새로운 위협을 제기한다.

Method: SemSIEdit라는 프레임워크를 사용하여 '편집자'가 민감한 정보를 비판하고 재작성하여 내러티브 흐름을 유지한다.

Result: 이 방법은 모든 SemSI 범주에서 34.6%의 정보 유출을 줄이면서도 9.8%의 한계 유틸리티 손실을 초래한다.

Conclusion: 추론 시간의 추론은 모델이 더 깊은 민감한 추론을 가능하게 하여 기초적인 위험을 증가시키지만, 동시에 안전한 재작성을 실행할 수 있도록 방어를 강화한다.

Abstract: While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we introduce SemSIEdit, an inference-time framework where an agentic "Editor" iteratively critiques and rewrites sensitive spans to preserve narrative flow rather than simply refusing to answer. Our analysis reveals a Privacy-Utility Pareto Frontier, where this agentic rewriting reduces leakage by 34.6% across all three SemSI categories while incurring a marginal utility loss of 9.8%. We also uncover a Scale-Dependent Safety Divergence: large reasoning models (e.g., GPT-5) achieve safety through constructive expansion (adding nuance), whereas capacity-constrained models revert to destructive truncation (deleting text). Finally, we identify a Reasoning Paradox: while inference-time reasoning increases baseline risk by enabling the model to make deeper sensitive inferences, it simultaneously empowers the defense to execute safe rewrites.

</details>


### [19] [ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning](https://arxiv.org/abs/2602.21534)
*Xiaoxuan Wang,Han Zhang,Haixin Wang,Yidan Shi,Ruoyan Li,Kaiqiao Han,Chenyi Tong,Haoran Deng,Renliang Sun,Alexander Taylor,Yanqiao Zhu,Jason Cong,Yizhou Sun,Wei Wang*

Main category: cs.AI

TL;DR: 대리 강화 학습(ARL)은 복잡한 다단계 상호작용 작업을 해결하기 위한 에이전트 교육의 유망한 패러다임으로 빠르게 주목받고 있으나, 불안정성 문제로 인해 훈련 붕괴가 발생할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 대리 강화 학습(ARL)의 안정성을 높이고, 다양한 상호작용 환경에서 스케일이 가능한 훈련 방법을 제시하고자 한다.

Method: ARLArena라는 안정적인 훈련 레시피와 체계 분석 프레임워크를 제안하고, 정책 기울기를 네 가지 핵심 설계 차원으로 분해하여 각각의 성능과 안정성을 평가한다.

Result: SAMPO라는 안정적인 에이전틱 정책 최적화 방법을 통해 ARL의 주요 불안정성 원인을 완화하고, 에이전틱 작업 전반에서 일관되게 안정적인 훈련과 강력한 성과를 달성한다.

Conclusion: 이 연구는 ARL에 대한 통합 정책 기울기 관점을 제공하며, 안정적이고 재현 가능한 LLM 기반 에이전트 훈련 파이프라인 구축을 위한 실질적인 지침을 제공한다.

Abstract: Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines.

</details>


### [20] [Power and Limitations of Aggregation in Compound AI Systems](https://arxiv.org/abs/2602.21556)
*Nivasini Ananthakrishnan,Meena Jagadeesan*

Main category: cs.AI

TL;DR: 이 논문은 복합 AI 시스템 설계에서 모델 집합의 응답을 집계하는 접근법의 강점과 한계를 조사한다.


<details>
  <summary>Details</summary>
Motivation: 복합 AI 시스템 디자인에서 응답을 집계할 때 단일 모델에 비해 더 많은 출력에 접근할 수 있는지 알아보기 위해, 모델의 동질성 문제를 다룬다.

Method: 우리는 원칙-대리인 프레임워크 내에서 집계의 힘과 한계를 분석하고, 시스템 설계자가 보상 함수 사양을 통해 각 에이전트의 출력을 부분적으로 조정하는 방식을 모델링한다.

Result: 우리는 집계를 통해 시스템 설계자가 이끌 수 있는 출력 집합이 확장되는 세 가지 자연스러운 메커니즘을 발견하였다: 타당성 확장, 지원 확장, 그리고 제약 집합 축소.

Conclusion: 강화된 메커니즘 버전이 집합성 확장을 완전히 특성화하는 데 필요한 충분한 조건과 필요 조건을 제공하며, 장난감 참조 생성 작업에 배치된 LLM에 대한 경험적 예시를 제공한다.

Abstract: When designing compound AI systems, a common approach is to query multiple copies of the same model and aggregate the responses to produce a synthesized output. Given the homogeneity of these models, this raises the question of whether aggregation unlocks access to a greater set of outputs than querying a single model. In this work, we investigate the power and limitations of aggregation within a stylized principal-agent framework. This framework models how the system designer can partially steer each agent's output through its reward function specification, but still faces limitations due to prompt engineering ability and model capabilities. Our analysis uncovers three natural mechanisms -- feasibility expansion, support expansion, and binding set contraction -- through which aggregation expands the set of outputs that are elicitable by the system designer. We prove that any aggregation operation must implement one of these mechanisms in order to be elicitability-expanding, and that strengthened versions of these mechanisms provide necessary and sufficient conditions that fully characterize elicitability-expansion. Finally, we provide an empirical illustration of our findings for LLMs deployed in a toy reference-generation task. Altogether, our results take a step towards characterizing when compound AI systems can overcome limitations in model capabilities and in prompt engineering.

</details>


### [21] [ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices](https://arxiv.org/abs/2602.21858)
*Dezhi Kong,Zhengzhao Feng,Qiliang Liang,Hao Wang,Haofei Sun,Changpeng Yang,Yang Li,Peng Zhou,Shuai Nie,Hongzhen Wang,Linfeng Zhou,Hao Jia,Jiaming Xu,Runyu Shi,Ying Huang*

Main category: cs.AI

TL;DR: MLLM의 발전은 주로 반응적인 패러다임에 국한되어 있으며, 프로액티브 지능을 위한 기준이 부족하다. 이에 대한 해결책으로 ProactiveMobile이라는 종합 벤치마크를 소개하고, MLLM의 프로액티브 능력을 평가할 수 있는 기준을 마련하였다.


<details>
  <summary>Details</summary>
Motivation: 모바일 에이전트의 발전을 위한 프로액티브 지능의 필요성과 이에 대한 객관적 평가 기준의 부족.

Method: ProactiveMobile은 사용자 의도를 추정하고, 63개의 API로부터 실행 가능한 기능 순서를 생성하는 프로액티브 작업을 공식화한다.

Result: Qwen2.5-VL-7B-Instruct는 19.15%의 성공률을 기록하며, 기존 모델들보다 성능이 우수하였다.

Conclusion: 프로액티브는 현재 MLLM들이 널리 부족한 중요한 능력이며, 이는 배울 수 있는 특성으로, 제안된 벤치마크의 중요성을 강조한다.

Abstract: Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.

</details>


### [22] [2-Step Agent: A Framework for the Interaction of a Decision Maker with AI Decision Support](https://arxiv.org/abs/2602.21889)
*Otto Nyberg,Fausto Carcassi,Giovanni Cinà*

Main category: cs.AI

TL;DR: AI 모델의 예측이 인간의 의사 결정을 지원하는 방식과 그로 인한 결과를 모델링하는 2단계 에이전트 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: AI 지원 의사 결정의 채택이 미치는 영향에 대한 깊은 이해 부족을 해결하기 위함이다.

Method: 베이지안 방법을 사용하여 인과 추론을 통해 관측 예측이 합리적인 베이지안 에이전트의 신념에 미치는 영향을 모델링한다.

Result: 단일 잘못된 사전 신념이 의사 지원으로 인해 더 나쁜 결과를 초래할 수 있음을 시뮬레이션을 통해 보여준다.

Conclusion: AI 기반 의사 지원의 여러 잠재적인 함정을 드러내고, 철저한 모델 문서화 및 적절한 사용자 교육의 필요성을 강조한다.

Abstract: Across a growing number of fields, human decision making is supported by predictions from AI models. However, we still lack a deep understanding of the effects of adoption of these technologies. In this paper, we introduce a general computational framework, the 2-Step Agent, which models the effects of AI-assisted decision making. Our framework uses Bayesian methods for causal inference to model 1) how a prediction on a new observation affects the beliefs of a rational Bayesian agent, and 2) how this change in beliefs affects the downstream decision and subsequent outcome. Using this framework, we show by simulations how a single misaligned prior belief can be sufficient for decision support to result in worse downstream outcomes compared to no decision support. Our results reveal several potential pitfalls of AI-driven decision support and highlight the need for thorough model documentation and proper user training.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [23] [MemoPhishAgent: Memory-Augmented Multi-Modal LLM Agent for Phishing URL Detection](https://arxiv.org/abs/2602.21394)
*Xuan Chen,Hao Liu,Yuan Tao,Mehran Kafai,Piotr Habas,Xiangyu Zhang*

Main category: cs.CR

TL;DR: 이 논문은 새로운 메모리 증강 다중 모드 LLM 에이전트인 MemoPhishAgent (MPA)를 제안하여 피싱 탐지 성능을 크게 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 피싱 웹사이트 탐지는 정적 휴리스틱이나 참조 목록에 의존하여 빠르게 발전하는 공격에 뒤처지고 있습니다.

Method: MPA는 피싱 전용 도구를 동적으로 조정하고 과거의 추론 경로에 대한 에피소드 메모리를 활용하여 결정에 도움을 줍니다.

Result: MPA는 두 개의 공공 데이터 세트에서 세 가지 최첨단 기준을 초과하며, 회수율을 13.6% 향상시킵니다.

Conclusion: MPA는 실제 사용자 노출 환경에서 강력한 피싱 탐지를 제공합니다.

Abstract: Traditional phishing website detection relies on static heuristics or reference lists, which lag behind rapidly evolving attacks. While recent systems incorporate large language models (LLMs), they are still prompt-based, deterministic pipelines that underutilize reasoning capability. We present MemoPhishAgent (MPA), a memory-augmented multi-modal LLM agent that dynamically orchestrates phishing-specific tools and leverages episodic memories of past reasoning trajectories to guide decisions on recurring and novel threats. On two public datasets, MPA outperforms three state-of-the-art (SOTA) baselines, improving recall by 13.6%. To better reflect realistic, user-facing phishing detection performance, we further evaluate MPA on a benchmark of real-world suspicious URLs actively crawled from five social media platforms, where it improves recall by 20%. Detailed analysis shows episodic memory contributes up to 27% recall gain without introducing additional computational overhead. The ablation study confirms the necessity of the agent-based approach compared to prompt-based baselines and validates the effectiveness of our tool design. Finally, MPA is deployed in production, processing 60K targeted high-risk URLs weekly, and achieving 91.44% recall, providing proactive protection for millions of customers. Together, our results show that combining multi-modal reasoning with episodic memory yields robust phishing detection in realistic user-exposure settings.

</details>


### [24] [Adversarial Intent is a Latent Variable: Stateful Trust Inference for Securing Multimodal Agentic RAG](https://arxiv.org/abs/2602.21447)
*Inderjeet Singh,Vikas Pahuja,Aishvariya Priya Rathina Sabapathy,Chiara Picardi,Amit Giloni,Roman Vainshtein,Andrés Murillo,Hisashi Kojima,Motoyoshi Sekiya,Yuki Unno,Junichi Suga*

Main category: cs.CR

TL;DR: 현재의 비상태 방어체계는 적대적인 전략을 탐지하는 데 실패하고 있으며, 본 논문에서는 이를 POMDP로 모델링하고 MMA-RAG^T라는 새로운 프레임워크를 도입하여 공격 성공률을 크게 감소시켰습니다.


<details>
  <summary>Details</summary>
Motivation: 다중모드 에이전틱 RAG의 현재 비상태 방어체계는 검색, 계획 및 생성 구성 요소에 걸쳐 악성 의미를 분배하는 적대적 전략을 탐지하지 못합니다.

Method: 이 보안 문제를 부분 가시 마르코프 의사 결정 프로세스(POMDP)로 모델링하고, 구조화된 LLM 추론을 통해 근사 신념 상태를 유지하는 모듈식 신뢰 에이전트(MTA)에 의해 관리되는 MMA-RAG^T라는 추론 시간 제어 프레임워크를 도입합니다.

Result: 43,774개의 사례에 대한 광범위한 평가를 통해 방어되지 않은 기준선에 비해 공격 성공률이 평균 6.50배 감소했으며, 유틸리티 비용은 미미했습니다.

Conclusion: 상태성 및 공간적 범위는 각각 필요하며, 체크포인트 탐지가 완벽하게 상관관계에 있을 때 비상태 다중 지점 개입은 제로 한계 이점을 나타낼 수 있음을 실험적으로 검증했습니다.

Abstract: Current stateless defences for multimodal agentic RAG fail to detect adversarial strategies that distribute malicious semantics across retrieval, planning, and generation components. We formulate this security challenge as a Partially Observable Markov Decision Process (POMDP), where adversarial intent is a latent variable inferred from noisy multi-stage observations. We introduce MMA-RAG^T, an inference-time control framework governed by a Modular Trust Agent (MTA) that maintains an approximate belief state via structured LLM reasoning. Operating as a model-agnostic overlay, MMA-RAGT mediates a configurable set of internal checkpoints to enforce stateful defence-in-depth. Extensive evaluation on 43,774 instances demonstrates a 6.50x average reduction factor in Attack Success Rate relative to undefended baselines, with negligible utility cost. Crucially, a factorial ablation validates our theoretical bounds: while statefulness and spatial coverage are individually necessary (26.4 pp and 13.6 pp gains respectively), stateless multi-point intervention can yield zero marginal benefit under homogeneous stateless filtering when checkpoint detections are perfectly correlated.

</details>


### [25] [APFuzz: Towards Automatic Greybox Protocol Fuzzing](https://arxiv.org/abs/2602.21892)
*Yu Wang,Yang Xiang,Chandra Thapa,Hajime Suzuki*

Main category: cs.CR

TL;DR: APFuzz는 상태 모델과 메시지 모델의 관점에서 그레이박스 프로토콜 퍼저의 스마트함을 높이기 위해 자동화된 탐색 기능을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 상태 프로토콜 구현을 위한 그레이박스 프로토콜 퍼징은 코드와 상태의 커버리지에 대한 피드백에 의해 입력 공간에서 탐색이 이루어지는 랜덤 테스트 접근 방식이다. 이 연구는 이러한 프로세스를 개선하기 위한 새로운 방법론을 제시한다.

Method: APFuzz는 정적 및 동적 분석의 두 단계 프로세스를 통해 상태 변수를 자동으로 식별하고 이를 사용하여 퍼징 중에 정확한 상태 모델을 유추하며, 이진 프로토콜을 위해 메시지 구조 인식을 활용한 필드 수준의 변형 작업을 도입한다.

Result: 공식 프로토콜 퍼징 벤치마크에서 APFuzz가 기존 퍼저인 AFLNET 및 몇 가지 최신 그레이박스 프로토콜 퍼저와 비교하여 성능을 검증한다.

Conclusion: APFuzz는 상태 모델과 메시지 모델의 혁신적인 디자인을 통해 그레이박스 프로토콜 퍼저의 효율성을 높인다.

Abstract: Greybox protocol fuzzing is a random testing approach for stateful protocol implementations, where the input is protocol messages generated from mutations of seeds, and the search in the input space is driven by the feedback on coverage of both code and state. State model and message model are the core components of communication protocols, which also have significant impacts on protocol fuzzing. In this work, we propose APFuzz (Automatic greybox Protocol Fuzzer) with novel designs to increase the smartness of greybox protocol fuzzers from the perspectives of both the state model and the message model. On the one hand, APFuzz employs a two-stage process of static and dynamic analysis to automatically identify state variables, which are then used to infer an accurate state model during fuzzing. On the other hand, APFuzz introduces field-level mutation operations for binary protocols, leveraging message structure awareness enabled by Large Language Models. We conduct extensive experiments on a public protocol fuzzing benchmark, comparing APFuzz with the baseline fuzzer AFLNET as well as several state-of-the-art greybox protocol fuzzers.

</details>
