<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 17]
- [cs.CR](#cs.CR) [Total: 6]
- [cs.AI](#cs.AI) [Total: 19]
- [cs.MA](#cs.MA) [Total: 4]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Pharmacophore-based design by learning on voxel grids](https://arxiv.org/abs/2512.02031)
*Omar Mahmood,Pedro O. Pinheiro,Richard Bonneau,Saeed Saremi,Vishnu Sresht*

Main category: cs.LG

TL;DR: 리간드 기반 약물 발견(LBDD)은 알려진 결합체를 이용하여 단백질 표적에 결합할 가능성이 있는 구조적으로 다양한 분자를 찾는 방법이다. 전통적인 방법은 분자 유사도를 기반으로 하는 열악한 검색을 사용하지만, 새로운 생성 모델인 VoxCap을 통해 더 빠르고 효과적으로 분자를 생성할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 리간드 기반 약물 발견이 기존 라이브러리 분자에 국한되고 라이브러리 크기에 따라 확장성이 떨어지는 문제를 해결하고자 한다.

Method: VoxCap이라는 새로운 보셀 캡셔닝 방법과 두 가지 작업 흐름을 제안한다: de-novo 디자인과 빠른 검색.

Result: VoxCap은 다양한 de-novo 적중 생성을 위한 이전 방법을 크게 능가하며, 빠른 검색 작업 흐름과 결합하면 계산 시간을 크게 줄인다.

Conclusion: VoxCap은 대규모 라이브러리 검색을 가능하게 하여 약물 발견의 효율성을 크게 향상시킨다.

Abstract: Ligand-based drug discovery (LBDD) relies on making use of known binders to a protein target to find structurally diverse molecules similarly likely to bind. This process typically involves a brute force search of the known binder (query) against a molecular library using some metric of molecular similarity. One popular approach overlays the pharmacophore-shape profile of the known binder to 3D conformations enumerated for each of the library molecules, computes overlaps, and picks a set of diverse library molecules with high overlaps. While this virtual screening workflow has had considerable success in hit diversification, scaffold hopping, and patent busting, it scales poorly with library sizes and restricts candidate generation to existing library compounds. Leveraging recent advances in voxel-based generative modelling, we propose a pharmacophore-based generative model and workflows that address the scaling and fecundity issues of conventional pharmacophore-based virtual screening. We introduce \emph{VoxCap}, a voxel captioning method for generating SMILES strings from voxelised molecular representations. We propose two workflows as practical use cases as well as benchmarks for pharmacophore-based generation: \emph{de-novo} design, in which we aim to generate new molecules with high pharmacophore-shape similarities to query molecules, and fast search, which aims to combine generative design with a cheap 2D substructure similarity search for efficient hit identification. Our results show that VoxCap significantly outperforms previous methods in generating diverse \textit{de-novo} hits. When combined with our fast search workflow, VoxCap reduces computational time by orders of magnitude while returning hits for all query molecules, enabling the search of large libraries that are intractable to search by brute force.

</details>


### [2] [HTG-GCL: Leveraging Hierarchical Topological Granularity from Cellular Complexes for Graph Contrastive Learning](https://arxiv.org/abs/2512.02073)
*Qirui Ji,Bin Qin,Yifan Jin,Yunze Zhao,Chuxiong Sun,Changwen Zheng,Jianwen Cao,Jiangmeng Li*

Main category: cs.LG

TL;DR: Hierarchical Topological Granularity Graph Contrastive Learning (HTG-GCL)은 다양한 그래프 관점을 생성하여 의미 있는 그래프 표현을 포착하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 그래프 대조 학습(GCL) 방식들이 작업 관련 토폴로지 구조를 제대로 식별하지 못하고, 다양한 다운스트림 작업에 필요한 토폴로지 세분화를 적응하는 데 어려움을 겪고 있다.

Method: HTG-GCL은 동일 그래프의 변환을 활용하여 다중 규모의 링 기반 셀룰러 복합체를 생성하여 토폴로지 세분화 개념을 구현하고, 다채로운 토폴로지 관점을 생성한다. 또한, misleading semantics를 포함할 수 있는 특정 세분화를 인지하고, 불확실성 추정을 기반으로 세분화 특정 가중치 메커니즘을 적용한다.

Result: 다양한 벤치마크를 통해 HTG-GCL의 효과성을 입증하였으며, 계층적 토폴로지 정보를 통해 의미 있는 그래프 표현을 포착하는 데 있어 우수한 성능을 강조하였다.

Conclusion: HTG-GCL은 그래프 대조 학습 분야에서 새로운 해결책을 제공하며, 다양한 작업에 대한 적응력을 높인다.

Abstract: Graph contrastive learning (GCL) aims to learn discriminative semantic invariance by contrasting different views of the same graph that share critical topological patterns. However, existing GCL approaches with structural augmentations often struggle to identify task-relevant topological structures, let alone adapt to the varying coarse-to-fine topological granularities required across different downstream tasks. To remedy this issue, we introduce Hierarchical Topological Granularity Graph Contrastive Learning (HTG-GCL), a novel framework that leverages transformations of the same graph to generate multi-scale ring-based cellular complexes, embodying the concept of topological granularity, thereby generating diverse topological views. Recognizing that a certain granularity may contain misleading semantics, we propose a multi-granularity decoupled contrast and apply a granularity-specific weighting mechanism based on uncertainty estimation. Comprehensive experiments on various benchmarks demonstrate the effectiveness of HTG-GCL, highlighting its superior performance in capturing meaningful graph representations through hierarchical topological information.

</details>


### [3] [Modelling the Doughnut of social and planetary boundaries with frugal machine learning](https://arxiv.org/abs/2512.02200)
*Stefano Vrizzi,Daniel W. O'Neill*

Main category: cs.LG

TL;DR: 이 연구는 '도넛' 모델을 기반으로 머신러닝 방법을 적용하여 환경 및 사회적 지속 가능성을 평가하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: '도넛' 모델은 환경 및 사회적 지속 가능성을 평가하기 위한 인기 있는 프레임워크로 자리 잡고 있습니다.

Method: 이 연구에서는 Random Forest Classifier와 Q-learning을 포함한 머신러닝 방법을 사용하여 정책 매개변수를 찾고 최적의 정책 경로를 식별합니다.

Result: 머신러닝 방법을 통해 환경 및 사회적 지속 가능성을 달성하는 정책 매개변수 조합을 찾는 데 성공했습니다.

Conclusion: 이러한 방법은 더 복잡한 생태학적 거시경제 모델에 적용될 것입니다.

Abstract: The 'Doughnut' of social and planetary boundaries has emerged as a popular framework for assessing environmental and social sustainability. Here, we provide a proof-of-concept analysis that shows how machine learning (ML) methods can be applied to a simple macroeconomic model of the Doughnut. First, we show how ML methods can be used to find policy parameters that are consistent with 'living within the Doughnut'. Second, we show how a reinforcement learning agent can identify the optimal trajectory towards desired policies in the parameter space. The approaches we test, which include a Random Forest Classifier and $Q$-learning, are frugal ML methods that are able to find policy parameter combinations that achieve both environmental and social sustainability. The next step is the application of these methods to a more complex ecological macroeconomic model.

</details>


### [4] [Improved Training Mechanism for Reinforcement Learning via Online Model Selection](https://arxiv.org/abs/2512.02214)
*Aida Afshar,Aldo Pacchiano*

Main category: cs.LG

TL;DR: 이 논문은 강화 학습에서 온라인 모델 선택 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 온라인 모델 선택 방법을 강화 학습 훈련 절차에 통합함으로써 효율성과 성능 개선을 목표로 한다.

Method: 강화 학습 에이전트 클래스에 접근하고 적절한 구성의 에이전트를 선택하는 방법을 학습한다.

Result: 이론적 특성을 통해 적절한 구성을 식별하고, 자원 할당, 비정상 동역학에서의 적응, 다양한 시드에서의 훈련 안정성의 세 가지 기준을 다룬다.

Conclusion: 모델 선택 작업에 대한 실증적 증거와 함께 강화 학습 훈련 과정에서 효과적으로 사용할 수 있는 이론적 결과를 제공한다.

Abstract: We study the problem of online model selection in reinforcement learning, where the selector has access to a class of reinforcement learning agents and learns to adaptively select the agent with the right configuration. Our goal is to establish the improved efficiency and performance gains achieved by integrating online model selection methods into reinforcement learning training procedures. We examine the theoretical characterizations that are effective for identifying the right configuration in practice, and address three practical criteria from a theoretical perspective: 1) Efficient resource allocation, 2) Adaptation under non-stationary dynamics, and 3) Training stability across different seeds. Our theoretical results are accompanied by empirical evidence from various model selection tasks in reinforcement learning, including neural architecture selection, step-size selection, and self model selection.

</details>


### [5] [ESACT: An End-to-End Sparse Accelerator for Compute-Intensive Transformers via Local Similarity](https://arxiv.org/abs/2512.02403)
*Hongxiang Liu,Zhifang Deng,Tong Pu,Shengli Lu*

Main category: cs.LG

TL;DR: ESACT는 Sparsity Prediction with Local Similarity(SPLS) 메커니즘을 기반으로 하는 엔드 투 엔드 희소 가속기이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 가속기들은 주로 intra-row 희소성만을 활용하고 inter-row 희소성은 거의 고려하지 않으며, 이는 희소성의 가속화 이점을 감소시킨다.

Method: ESACT는 HLog 양자화를 활용하여 QK 생성 전에 지방적 주의 희소성을 정확히 예측하며, 모든 변환기 구성 요소에서 효율적인 희소성을 달성하는 것을 목표로 한다.

Result: SPLS는 총 계산량을 52.03% 감소시키며, ESACT는 최종 에너지 효율성 3.29 TOPS/W를 달성한다.

Conclusion: ESACT는 주의 수준의 에너지 효율성을 SOTA 주의 가속기보다 각각 2.95배 및 2.26배 개선한다.

Abstract: Transformers, composed of QKV generation, attention computation, and FFNs,
  have become the dominant model across various domains due to their outstanding performance.
  However, their high computational cost hinders efficient hardware deployment.
  Sparsity offers a promising solution,
  yet most existing accelerators exploit only intra-row sparsity in attention,
  while few consider inter-row sparsity.
  Approaches leveraging inter-row sparsity often rely on costly global similarity estimation,
  which diminishes the acceleration benefits of sparsity,
  and typically apply sparsity to only one or two transformer components.
  Through careful analysis of the attention distribution and computation flow,
  we observe that local similarity allows end-to-end sparse acceleration with lower computational overhead.
  Motivated by this observation, we propose ESACT,
  an end-to-end sparse accelerator for compute-intensive Transformers.
  ESACT centers on the Sparsity Prediction with Local Similarity (SPLS) mechanism,
  which leverages HLog quantization to accurately predict local attention sparsity prior to QK generation,
  achieving efficient sparsity across all transformer components.
  To support efficient hardware realization, we introduce three architectural innovations.
  Experimental results on 26 benchmarks demonstrate that
  SPLS reduces total computation by 52.03% with less than 1% accuracy loss.
  ESACT achieves an end-to-end energy efficiency of 3.29 TOPS/W,
  and improves attention-level energy efficiency by 2.95x and 2.26x over
  SOTA attention accelerators SpAtten and Sanger, respectively.

</details>


### [6] [Dynamic Configuration of On-Street Parking Spaces using Multi Agent Reinforcement Learning](https://arxiv.org/abs/2512.02406)
*Oshada Jayasinghe,Farhana Choudhury,Egemen Tanin,Shanika Karunasekera*

Main category: cs.LG

TL;DR: 이 논문은 도시 지역의 교통 혼잡 문제를 해결하기 위한 동적 도로 주차 공간 구성의 최적화 문제를 다루고 있으며, 제안된 프레임워크는 차량 주차로 인한 교통 흐름 저하를 최소화한다.


<details>
  <summary>Details</summary>
Motivation: 교통 혼잡 문제를 해결하기 위한 필요성과 on-street 주차 공간의 효과적인 구성을 통한 교통 흐름 개선의 중요성을 강조한다.

Method: 두 계층의 다중 에이전트 강화 학습 기반 프레임워크를 개발하고, lane level 에이전트가 최적의 주차 공간 구성을 결정하며, Deep Q-learning 아키텍처를 활용하여 시공간 상관관계를 포착한다.

Result: 제안된 프레임워크는 차량의 평균 이동 시간 손실을 최대 47% 줄일 수 있으며, 주차를 위한 보행 거리의 증가가 미미하다.

Conclusion: 이 연구는 대규모 도로 네트워크에서 효율적인 ON-STREET 주차 관리의 가능성을 실증적으로 제시한다.

Abstract: With increased travelling needs more than ever, traffic congestion has become a major concern in most urban areas. Allocating spaces for on-street parking, further hinders traffic flow, by limiting the effective road width available for driving. With the advancement of vehicle-to-infrastructure connectivity technologies, we explore how the impact of on-street parking on traffic congestion could be minimized, by dynamically configuring on-street parking spaces. Towards that end, we formulate dynamic on-street parking space configuration as an optimization problem, and we follow a data driven approach, considering the nature of our problem. Our proposed solution comprises a two-layer multi agent reinforcement learning based framework, which is inherently scalable to large road networks. The lane level agents are responsible for deciding the optimal parking space configuration for each lane, and we introduce a novel Deep Q-learning architecture which effectively utilizes long short term memory networks and graph attention networks to capture the spatio-temporal correlations evident in the given problem. The block level agents control the actions of the lane level agents and maintain a sufficient level of parking around the block. We conduct a set of comprehensive experiments using SUMO, on both synthetic data as well as real-world data from the city of Melbourne. Our experiments show that the proposed framework could reduce the average travel time loss of vehicles significantly, reaching upto 47%, with a negligible increase in the walking distance for parking.

</details>


### [7] [Cross-Domain Offline Policy Adaptation with Dynamics- and Value-Aligned Data Filtering](https://arxiv.org/abs/2512.02435)
*Zhongjian Qiao,Rui Yang,Jiafei Lyu,Chenjia Bai,Xiu Li,Zhuoran Yang,Siyang Gao,Shuang Qiu*

Main category: cs.LG

TL;DR: 이 논문은 크로스 도메인 오프라인 강화 학습에서 다이나믹스 정합성 및 가치 정합성을 모두 고려하여 정책 학습을 개선하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 이론적 프레임워크의 한계를 해결하고 크로스 도메인 RL에서의 정책 학습에 다이나믹스 정합성과 가치 정합성이 필수적임을 입증하기 위해서이다.

Method: DVDF 방법을 제안하며, 이는 다이나믹스와 가치 정합성이 높은 소스 도메인 샘플을 선택적으로 공유하는 것을 포함한다.

Result: DVDF는 다양한 작업과 데이터셋에서 기존 강력한 기준선보다 눈에 띄게 우수한 성능을 기록하였다.

Conclusion: 제안된 DVDF 방법은 여러 작업 및 데이터셋에서 예외적인 성능을 발휘하며, 특히 데이터가 매우 적은 환경에서도 효과적이다.

Abstract: Cross-Domain Offline Reinforcement Learning aims to train an agent deployed in the target environment, leveraging both a limited target domain dataset and a source domain dataset with (possibly) sufficient data coverage. Due to the underlying dynamics misalignment between the source and target domain, simply merging the data from two datasets may incur inferior performance. Recent advances address this issue by selectively sharing source domain samples that exhibit dynamics alignment with the target domain. However, these approaches focus solely on dynamics alignment and overlook \textit{value alignment}, i.e., selecting high-quality, high-value samples from the source domain. In this paper, we first demonstrate that both dynamics alignment and value alignment are essential for policy learning, by examining the limitations of the current theoretical framework for cross-domain RL and establishing a concrete sub-optimality gap of a policy trained on the source domain and evaluated on the target domain. Motivated by the theoretical insights, we propose to selectively share those source domain samples with both high dynamics and value alignment and present our \textbf{\underline{D}}ynamics- and \textbf{\underline{V}}alue-aligned \textbf{\underline{D}}ata \textbf{\underline{F}}iltering (DVDF) method. We design a range of dynamics shift settings, including kinematic and morphology shifts, and evaluate DVDF on various tasks and datasets, as well as in challenging extremely low-data settings where the target domain dataset contains only 5,000 transitions. Extensive experiments demonstrate that DVDF consistently outperforms prior strong baselines and delivers exceptional performance across multiple tasks and datasets.

</details>


### [8] [When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents](https://arxiv.org/abs/2512.02445)
*Tsimur Hadeliya,Mohammad Ali Jauhar,Nidhi Sakpal,Diogo Cruz*

Main category: cs.LG

TL;DR: 이 논문은 대규모 언어 모델(LLM) 에이전트의 긴 컨텍스트에서의 성능과 안전성 문제를 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 단기적이지 않은 복잡한 문제 해결을 위해 LLM의 외부 도구 사용과 긴 컨텍스트 창 운영 필요성이 증가하고 있다.

Method: 우리의 연구는 LLM 에이전트가 긴 컨텍스트에 민감하게 반응하고, 예기치 않은 성능 변동을 보이는지를 조사한다.

Result: 모델은 1M-2M 토큰의 컨텍스트 창에서 100K 토큰에서 심각한 성능 저하를 보이며, 거부율 또한 예측 불가능하게 변화한다.

Conclusion: 이 연구는 긴 컨텍스트에서 작동하는 LLM 에이전트의 잠재적 안전 문제를 밝혀내고, LLM 에이전트 안전성을 평가하기 위한 기존 지표와 패러다임에 대한 추가 질문을 제기한다.

Abstract: Solving complex or long-horizon problems often requires large language models (LLMs) to use external tools and operate over a significantly longer context window. New LLMs enable longer context windows and support tool calling capabilities. Prior works have focused mainly on evaluation of LLMs on long-context prompts, leaving agentic setup relatively unexplored, both from capability and safety perspectives. Our work addresses this gap. We find that LLM agents could be sensitive to length, type, and placement of the context, exhibiting unexpected and inconsistent shifts in task performance and in refusals to execute harmful requests. Models with 1M-2M token context windows show severe degradation already at 100K tokens, with performance drops exceeding 50\% for both benign and harmful tasks. Refusal rates shift unpredictably: GPT-4.1-nano increases from $\sim$5\% to $\sim$40\% while Grok 4 Fast decreases from $\sim$80\% to $\sim$10\% at 200K tokens. Our work shows potential safety issues with agents operating on longer context and opens additional questions on the current metrics and paradigm for evaluating LLM agent safety on long multi-step tasks. In particular, our results on LLM agents reveal a notable divergence in both capability and safety performance compared to prior evaluations of LLMs on similar criteria.

</details>


### [9] [Dual-Robust Cross-Domain Offline Reinforcement Learning Against Dynamics Shifts](https://arxiv.org/abs/2512.02486)
*Zhongjian Qiao,Rui Yang,Jiafei Lyu,Xiu Li,Zhongxiang Dai,Zhuoran Yang,Siyang Gao,Shuang Qiu*

Main category: cs.LG

TL;DR: 본 논문에서는 크로스 도메인 오프라인 강화 학습에서 동적 변화에 대한 이중(훈련 시 및 테스트 시) 강인성을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 크로스 도메인 오프라인 강화 학습에서는 다른 도메인에서의 추가 데이터를 활용하여 데이터 범위의 제한 문제를 처리합니다.

Method: 본 논문에서는 동적 변화에 대해 훈련 시 및 테스트 시의 강인성을 다루기 위해 새로운 강인한 크로스 도메인 벨만(RCB) 연산자를 도입합니다.

Result: DROCO 알고리즘은 다양한 동적 변화 시나리오에서 강력한 기준선을 초과하고 동적 변화에 대한 강인성이 향상되었습니다.

Conclusion: 우리는 RCB 연산자가 훈련 시의 강인성을 보장하면서 테스트 시의 동적 변화에 대한 강인성을 높인다는 것을 보여줍니다.

Abstract: Single-domain offline reinforcement learning (RL) often suffers from limited data coverage, while cross-domain offline RL handles this issue by leveraging additional data from other domains with dynamics shifts. However, existing studies primarily focus on train-time robustness (handling dynamics shifts from training data), neglecting the test-time robustness against dynamics perturbations when deployed in practical scenarios. In this paper, we investigate dual (both train-time and test-time) robustness against dynamics shifts in cross-domain offline RL. We first empirically show that the policy trained with cross-domain offline RL exhibits fragility under dynamics perturbations during evaluation, particularly when target domain data is limited. To address this, we introduce a novel robust cross-domain Bellman (RCB) operator, which enhances test-time robustness against dynamics perturbations while staying conservative to the out-of-distribution dynamics transitions, thus guaranteeing the train-time robustness. To further counteract potential value overestimation or underestimation caused by the RCB operator, we introduce two techniques, the dynamic value penalty and the Huber loss, into our framework, resulting in the practical \textbf{D}ual-\textbf{RO}bust \textbf{C}ross-domain \textbf{O}ffline RL (DROCO) algorithm. Extensive empirical results across various dynamics shift scenarios show that DROCO outperforms strong baselines and exhibits enhanced robustness to dynamics perturbations.

</details>


### [10] [In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs](https://arxiv.org/abs/2512.02543)
*Vishnu Sarukkai,Asanshay Gupta,James Hong,Michaël Gharbi,Kayvon Fatahalian*

Main category: cs.LG

TL;DR: 이 논문에서는 LLM 에이전트의 추론 비용을 줄이기 위한 간단한 방법을 제안하며, 이를 통해 높은 비용의 고용량 LLM을 사용할 때 발생하는 문제를 해결하고자 한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트를 사용하는 방법에 대한 아이디어가 풍부하게 존재하는 현재, 개발자들은 새로운 에이전트 디자인을 신속하게 프로토타입하고 테스트할 수 있는 방법을 찾고 있다.

Method: 우리는 지식 증류의 개념을 맥락 내 학습 설정에 맞게 조정한 '인-컨텍스트 증류'를 도입하며, 에이전트의 각 단계에서 관련 교사 시연을 검색하여 학생에게 제공함으로써 즉석에서 교사 행동을 모방할 수 있도록 한다.

Result: 우리의 방법은 ALFWorld 벤치마크에서 교사 수준의 정확도를 2.5배 낮은 비용으로 달성했으며, 1회 에피소드당 비용을 0.059달러에서 0.024달러로 줄였다.

Conclusion: 운영 비용을 줄이면서도 고정 모델을 가지고 빠른 실험 주기를 유지하는 우리의 접근 방식은 더 넓은 범위의 응용 프로그램에서 고급 에이전트 시스템을 경제적으로 실행 가능하게 만든다.

Abstract: The world currently has an abundance of ideas for how to use new LLM agents, and developers seek to rapidly prototype and test new agentic designs. However, executing agents at scale using high-capacity LLMs incurs high inference costs. We propose a simple method for reducing LLM agent inference costs without incurring the development friction costs associated with LLM fine-tuning (long training cycles, optimization hyperparameter tweaking loops) or manual prompt engineering (laborious trial and error). Most importantly, we introduce $\textit{in-context distillation}$, which adapts the idea of knowledge distillation (training a low cost-student model to mimic a high-cost teacher) to an in-context learning setting. Our approach retrieves relevant teacher demonstrations at each agent step and provides them to the student as in-context examples, enabling the student to imitate teacher behavior on-the-fly. We combine in-context distillation with the established idea of $\textit{self-consistency cascades}$ to know when the trust the student. This adaptive strategy realizes the cost benefits of model specialization while preserving the productivity of working with frozen models. On the multi-step embodied reasoning benchmark ALFWorld, our method matches teacher-level accuracy at $\textbf{2.5$\times$ lower cost}$, reducing per-episode costs from \$0.059 to \$0.024. The upfront demonstration cost amortizes after just 843 episodes, yielding cumulative savings exceeding \$34,900 at deployment scale (1M episodes). On AppWorld, a complex agent benchmark requiring multi-step API workflows, we shift the Pareto frontier by achieving a $\textbf{2$\times$ cost reduction}$ at iso-accuracy. By reducing operational costs while maintaining rapid experimentation cycles with frozen models, our approach makes advanced agentic systems economically viable for a broader range of applications.

</details>


### [11] [Tensor Network Based Feature Learning Model](https://arxiv.org/abs/2512.02547)
*Albert Saiapin,Kim Batselier*

Main category: cs.LG

TL;DR: FL 모델은 텐서-프로덕트 특성을 학습 가능한 CPD로 표현하여 최적의 하이퍼파라미터를 효율적으로 학습합니다.


<details>
  <summary>Details</summary>
Motivation: 커널 기반 알고리즘의 세제곱 복잡성을 회피하여 대규모 데이터세트에 적용할 수 있는 방법이 필요하다.

Method: FL 모델은 텐서-프로덕트 특성을 학습 가능한 CPD로 표현하고, ALS 최적화 방법을 사용하여 하이퍼파라미터를 학습한다.

Result: FL 모델은 다양한 차원과 규모의 실제 데이터로 실험하여 3-5배 더 빠르게 훈련되고 예측 품질이 표준 교차 검증 모델과 동등함을 증명했다.

Conclusion: FL 모델이 하이퍼파라미터 식별 문제를 성공적으로 해결하고, 처리 속도 및 예측 품질을 향상시킨다.

Abstract: Many approximations were suggested to circumvent the cubic complexity of kernel-based algorithms, allowing their application to large-scale datasets. One strategy is to consider the primal formulation of the learning problem by mapping the data to a higher-dimensional space using tensor-product structured polynomial and Fourier features. The curse of dimensionality due to these tensor-product features was effectively solved by a tensor network reparameterization of the model parameters. However, another important aspect of model training - identifying optimal feature hyperparameters - has not been addressed and is typically handled using the standard cross-validation approach. In this paper, we introduce the Feature Learning (FL) model, which addresses this issue by representing tensor-product features as a learnable Canonical Polyadic Decomposition (CPD). By leveraging this CPD structure, we efficiently learn the hyperparameters associated with different features alongside the model parameters using an Alternating Least Squares (ALS) optimization method. We prove the effectiveness of the FL model through experiments on real data of various dimensionality and scale. The results show that the FL model can be consistently trained 3-5 times faster than and have the prediction quality on par with a standard cross-validated model.

</details>


### [12] [SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization](https://arxiv.org/abs/2512.02631)
*Zhengcheng Wang,Zichuan Lin,Yijun Yang,Haobo Fu,Deheng Ye*

Main category: cs.LG

TL;DR: 새로운 VLN 에이전트 프레임워크 SeeNav-Agent가 제안되어 인식 및 계획 오류를 줄이고 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존의 VLN 에이전트는 인식, 추론 및 계획 오류로 인해 내비게이션 성능이 저하된다.

Method: SeeNav-Agent 프레임워크는 이중 시각 프롬프트(VP) 기술과 단계 수준 강화 미세 조정 방법(SRGPO)을 도입하여 에이전트의 인식과 계획 능력을 향상시킨다.

Result: 실험 결과, 제안한 VP 모듈을 통해 GPT-4.1은 86.7%의 내비게이션 성공률을 달성하였고, SRGPO를 통해 Qwen2.5-VL-3B 모델은 72.3%에 도달하였다.

Conclusion: SRGPO는 기존의 RFT 알고리즘보다 학습 안정성, 수렴 효율성 및 일반화 능력을 향상시킨다.

Abstract: Existing Vision-Language Navigation (VLN) agents based on Large Vision-Language Models (LVLMs) often suffer from perception errors, reasoning errors, and planning errors, which significantly hinder their navigation performance. To address these limitations, a novel VLN agent framework, named SeeNav-Agent, is proposed in this work. First, to reduce perception hallucinations of the visual module of the VLN agent, a dual-view Visual Prompt (VP) technique is introduced in the input space, which can also improve the agent's understanding of current spatial states. Subsequently, a novel step-level Reinforcement Fine-Tuning (RFT) method, Step Reward Group Policy Optimization (SRGPO), is designed for the post-training of VLN agents. In SRGPO, we first define verifiable process rewards for the navigation task, and then perform efficient step-level advantage estimation by randomly grouping different navigation steps. SRGPO provides dense reward signals for the reinforcement learning process of the VLN agent and enhances its planning capability. Experimental results on the EmbodiedBench Navigation benchmark indicate that by introducing the zero-shot VP module, the GPT-4.1 achieves a navigation success rate of 86.7%, surpassing the current best LVLM by approximately 20 percentage points (pp). Through post-training based on SRGPO, the Qwen2.5-VL-3B model reaches a navigation success rate of 72.3%, outperforming the best existing LVLM model by 5.6 pp. Moreover, compared to RFT algorithms such as GRPO and GiGPO, the proposed SRGPO demonstrates significant improvements in training stability, convergence efficiency, and generalization capability.

</details>


### [13] [From Navigation to Refinement: Revealing the Two-Stage Nature of Flow-based Diffusion Models through Oracle Velocity](https://arxiv.org/abs/2512.02826)
*Haoming Liu,Jinnuo Liu,Yanhao Li,Liuyang Bai,Yunkai Ji,Yuanhe Guo,Shenji Wan,Hongyi Wen*

Main category: cs.LG

TL;DR: 이 논문은 흐름 기반 확산 모델의 훈련 동역학에 대한 이해를 깊게 하고, 향후 구조적 및 알고리즘적 개선을 위한 원칙을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 흐름 기반 확산 모델의 기억-일반화 행동을 이해하고 그 훈련 목표를 재조명하기 위해 이 연구를 수행했습니다.

Method: 흐름 매칭(FM) 목표를 재검토하고 이의 주변 속도 필드를 분석했습니다. 이는 닫힌 형태로 표현이 가능하며, 오라클 FM 대상의 정확한 계산을 허용합니다.

Result: 오라클 속도 필드를 분석함으로써 흐름 기반 확산 모델이 두 단계 훈련 목표를 수립함을 발견했습니다. 초기 단계에서는 데이터 모드의 혼합에 의해 안내되고, 후속 단계에서는 가장 가까운 데이터 샘플에 의해 지배됩니다.

Conclusion: 이러한 통찰을 활용하여 여러 실용적 기법의 효과성을 설명하며, 확산 모델 훈련 동역학에 대한 이해를 심화시키고 미래 연구에 대한 원칙을 제시합니다.

Abstract: Flow-based diffusion models have emerged as a leading paradigm for training generative models across images and videos. However, their memorization-generalization behavior remains poorly understood. In this work, we revisit the flow matching (FM) objective and study its marginal velocity field, which admits a closed-form expression, allowing exact computation of the oracle FM target. Analyzing this oracle velocity field reveals that flow-based diffusion models inherently formulate a two-stage training target: an early stage guided by a mixture of data modes, and a later stage dominated by the nearest data sample. The two-stage objective leads to distinct learning behaviors: the early navigation stage generalizes across data modes to form global layouts, whereas the later refinement stage increasingly memorizes fine-grained details. Leveraging these insights, we explain the effectiveness of practical techniques such as timestep-shifted schedules, classifier-free guidance intervals, and latent space design choices. Our study deepens the understanding of diffusion model training dynamics and offers principles for guiding future architectural and algorithmic improvements.

</details>


### [14] [Assessing the performance of correlation-based multi-fidelity neural emulators](https://arxiv.org/abs/2512.02868)
*Cristian J. Villatoro,Gianluca Geraci,Daniele E. Schiavazzi*

Main category: cs.LG

TL;DR: 본 연구는 다중 신뢰도 신경 에뮬레이터의 성능을 조사하며, 이들은 제한된 고신뢰도 데이터와 풍부한 저신뢰도 모델 솔루션을 통합하여 입력-출력 매핑을 학습하도록 설계된 신경망입니다.


<details>
  <summary>Details</summary>
Motivation: 고신뢰도 모델이 계산적으로 비싼 경우, 외부 루프 작업이 어렵고 데이터 기반 아키텍처는 예측 작업에 충분한 정확성을 위해 큰 데이터 세트를 요구하는 문제를 해결하고자 합니다.

Method: 저신뢰도 정보와 희소한 고신뢰도 데이터를 융합하여 예측을 수정하고 개선할 수 있는 다중 신뢰도 에뮬레이터의 성능을 조사했습니다.

Result: 저신뢰도 및 고신뢰도 함수의 성능, 불연속성이 존재하는 경우, 동일 및 비슷한 매개변수를 가진 모델 모음, 고장날 가능성이 있는 저신뢰도 소스의 경우 등을 분석했습니다.

Conclusion: 다중 신뢰도 접근법의 추가 가치를 단일 신뢰도 테스트와 비교하여 정량화했습니다.

Abstract: Outer loop tasks such as optimization, uncertainty quantification or inference can easily become intractable when the underlying high-fidelity model is computationally expensive. Similarly, data-driven architectures typically require large datasets to perform predictive tasks with sufficient accuracy. A possible approach to mitigate these challenges is the development of multi-fidelity emulators, leveraging potentially biased, inexpensive low-fidelity information while correcting and refining predictions using scarce, accurate high-fidelity data. This study investigates the performance of multi-fidelity neural emulators, neural networks designed to learn the input-to-output mapping by integrating limited high-fidelity data with abundant low-fidelity model solutions. We investigate the performance of such emulators for low and high-dimensional functions, with oscillatory character, in the presence of discontinuities, for collections of models with equal and dissimilar parametrization, and for a possibly large number of potentially corrupted low-fidelity sources. In doing so, we consider a large number of architectural, hyperparameter, and dataset configurations including networks with a different amount of spectral bias (Multi-Layered Perceptron, Siren and Kolmogorov Arnold Network), various mechanisms for coordinate encoding, exact or learnable low-fidelity information, and for varying training dataset size. We further analyze the added value of the multi-fidelity approach by conducting equivalent single-fidelity tests for each case, quantifying the performance gains achieved through fusing multiple sources of information.

</details>


### [15] [OptPO: Optimal Rollout Allocation for Test-time Policy Optimization](https://arxiv.org/abs/2512.02882)
*Youkang Wang,Jian Wang,Rubing Chen,Tianyi Zeng,Xiao-Yong Wei,Qing Li*

Main category: cs.LG

TL;DR: OptPO는 테스트 시간에 정책 최적화를 위해 적응적으로 추론 예산을 할당하는 프레임워크로, 고정 예산 다수결 투표에 의존하지 않고, 효율성을 높이고 정확도를 유지 또는 개선한다.


<details>
  <summary>Details</summary>
Motivation: 테스트 시간 정책 최적화는 자가 생성된 롤아웃의 피드백을 활용하여 대규모 언어 모델(LLM)이 배급 변화에 적응할 수 있도록 한다.

Method: OptPO는 Bayesian 순차 확률 비율 테스트로 투표 과정을 공식화하여, 합의된 답변에 대한 후행 신뢰도가 지정된 임계치를 초과하면 샘플링을 동적으로 중지한다.

Result: OptPO는 고정 샘플 기준선과 비교하여 롤아웃 오버헤드를 크게 줄이며 정확도를 유지 또는 개선한다.

Conclusion: 통계적으로 최적의 중단과 테스트 시간 학습을 통합한 OptPO는 테스트 시간 적응을 위한 계산적으로 효율적인 패러다임을 제공한다.

Abstract: Test-time policy optimization enables large language models (LLMs) to adapt to distribution shifts by leveraging feedback from self-generated rollouts. However, existing methods rely on fixed-budget majority voting to estimate rewards, incurring substantial computational redundancy. We propose Optimal Rollout Allocation for Test-time Policy Optimization (OptPO), a principled framework that adaptively allocates inference budgets. By formulating the voting process as a Bayesian sequential probability ratio test, OptPO dynamically halts sampling once the posterior confidence in a consensus answer exceeds a specified threshold. Crucially, it utilizes the retained rollouts for on-policy updates, seamlessly integrating with algorithms like PPO or GRPO without requiring ground-truth labels. Across diverse reasoning benchmarks, OptPO significantly reduces rollout overhead compared to fixed-sample baselines while preserving or improving accuracy. By unifying statistically optimal stopping with test-time learning, OptPO offers a computationally efficient paradigm for test-time adaptation. The source code will be open upon acceptance at https://open-upon-acceptance.

</details>


### [16] [Hypothesis Testing for Generalized Thurstone Models](https://arxiv.org/abs/2512.02912)
*Anuran Makur,Japneet Singh*

Main category: cs.LG

TL;DR: 이 연구에서는 쌍대 비교 데이터가 주어진 선택 함수에 대한 일반화된 툴스톤 모델에 의해 생성되었는지를 판단하기 위한 가설 검정 프레임워크를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 이전 연구들은 이러한 모델의 매개변수 추정 및 불확실성 정량화에 주로 초점을 맞췄으나, 우리는 일반화된 툴스톤 모델에 대한 최소 최대 가설 검정이라는 근본적인 문제를 다룬다.

Method: 우리는 일반 쌍대 비교 모델과 툴스톤 모델 클래스 간의 분리 거리 개념을 도입하여 이 검정 문제를 수립하고, 관측 그래프의 토폴로지에 따라 달라지는 임계 임계값에 대한 상한과 하한을 유도한다.

Result: 완전 관측 그래프의 특수한 경우에서 이 임계값은 $Θ((nk)^{-1/2})$로 조정되며, 여기서 $n$은 에이전트 수, $k$는 쌍당 비교 수이다. 또한 우리는 분리 거리를 기반으로 한 가설 검정을 제안하고, 신뢰 구간을 구성하며, 역 마팅ゲ일 기법을 사용하여 1형 및 2형 오류 확률에 대한 시간 균일 경계를 수립하고, 정보 이론적 방법을 사용하여 최소 최대 하한을 유도한다.

Conclusion: 마지막으로, 합성 및 실제 데이터셋에 대한 실험을 통해 우리의 결과를 검증한다.

Abstract: In this work, we develop a hypothesis testing framework to determine whether pairwise comparison data is generated by an underlying \emph{generalized Thurstone model} $\mathcal{T}_F$ for a given choice function $F$. While prior work has predominantly focused on parameter estimation and uncertainty quantification for such models, we address the fundamental problem of minimax hypothesis testing for $\mathcal{T}_F$ models. We formulate this testing problem by introducing a notion of separation distance between general pairwise comparison models and the class of $\mathcal{T}_F$ models. We then derive upper and lower bounds on the critical threshold for testing that depend on the topology of the observation graph. For the special case of complete observation graphs, this threshold scales as $Θ((nk)^{-1/2})$, where $n$ is the number of agents and $k$ is the number of comparisons per pair. Furthermore, we propose a hypothesis test based on our separation distance, construct confidence intervals, establish time-uniform bounds on the probabilities of type I and II errors using reverse martingale techniques, and derive minimax lower bounds using information-theoretic methods. Finally, we validate our results through experiments on synthetic and real-world datasets.

</details>


### [17] [Distribution-Calibrated Inference time compute for Thinking LLM-as-a-Judge](https://arxiv.org/abs/2512.03019)
*Hamid Dadkhahi,Firas Trabelsi,Parker Riley,Juraj Juraska,Mehdi Mirzazadeh*

Main category: cs.LG

TL;DR: 본 논문은 쌍대 선호에 대한 평가를 위한 대형 언어 모델의 일관성 부족을 해결하기 위해 새로운 집계 방안을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 (LLM)이 쌍대 선호 평가에 사용될 때, 단일 샘플 수준에서 소음이 존재하고 이로 인해 집계 규칙이 일관성이 없다는 문제를 해결하고자 합니다.

Method: 각 항목에 대해 n개의 독립적인 사고-평가 샘플을 생성하는 평가자들에 대한 inference-time compute (ITC) 연구와 분포 보정 집계 방안 제안을 포함합니다.

Result: 우리의 방법은 브래들리-테리-데이비슨(BTD) 공식을 사용하여 세 방향 선호를 모델링하고, 비타이와 결정성을 활용하여 좁은 마진과 강한 합의를 구별합니다. 다양한 평가 기준에서 MAE를 일관되게 줄이고 쌍대 정확도를 증가시켰으며, 인간 합의 메타 라벨과 평가할 때 개별 인간 평가자와 맞먹거나 초과하는 성과를 보였습니다.

Conclusion: ITC를 신중하게 할당하고 분포 인식 방법으로 집계함으로써 개별 모델의 소음이 있는 판단을 평가를 위한 신뢰할 수 있는 평점으로 변환할 수 있다는 것을 보여줍니다.

Abstract: Thinking Large Language Models (LLMs) used as judges for pairwise preferences remain noisy at the single-sample level, and common aggregation rules (majority vote, soft self-consistency, or instruction-based self-aggregation) are inconsistent when ties are allowed. We study inference-time compute (ITC) for evaluators that generate n independent thinking-rating samples per item, and propose a principled, distribution-calibrated aggregation scheme. Our method models three-way preferences with a Bradley-Terry-Davidson formulation on rating counts, leveraging both polarity (margin among non-ties) and decisiveness (non-tie rate) to distinguish narrow margins from strong consensus. Across various evaluation benchmarks, our approach consistently reduces MAE and increases pairwise accuracy versus standard baselines, and when evaluated against human-consensus meta-labels, matches or exceeds individual human raters. These results show that carefully allocating ITC and aggregating with distribution-aware methods turns noisy individual model judgments into reliable ratings for evaluation.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [18] [PhishSnap: Image-Based Phishing Detection Using Perceptual Hashing](https://arxiv.org/abs/2512.02243)
*Md Abdul Ahad Minhaz,Zannatul Zahan Meem,Md. Shohrab Hossain*

Main category: cs.CR

TL;DR: PhishSnap은 개인 정보를 보호하면서 장치 내에서 피싱을 탐지하는 시스템으로, 시각적 해싱을 활용합니다.


<details>
  <summary>Details</summary>
Motivation: 피싱 공격이 여전히 매우 널리 퍼져 있는 온라인 위협이며, 기존 시스템이 시각적 속임수에 취약하다는 점을 해결하고자 합니다.

Method: 브라우저 확장 프로그램으로 구현된 PhishSnap은 웹 페이지의 스크린샷을 캡처하고, 시각적 해시를 계산하여 정당한 템플릿과 비교합니다.

Result: 시스템은 0.79의 정확도, 0.76의 정밀도, 0.78의 재현율을 달성했습니다.

Conclusion: 시각적 유사성이 여전히 효과적인 피싱 방지 수단임을 보여줍니다.

Abstract: Phishing remains one of the most prevalent online threats, exploiting human trust to harvest sensitive credentials. Existing URL- and HTML-based detection systems struggle against obfuscation and visual deception. This paper presents \textbf{PhishSnap}, a privacy-preserving, on-device phishing detection system leveraging perceptual hashing (pHash). Implemented as a browser extension, PhishSnap captures webpage screenshots, computes visual hashes, and compares them against legitimate templates to identify visually similar phishing attempts. A \textbf{2024 dataset of 10,000 URLs} (70\%/20\%/10\% train/validation/test) was collected from PhishTank and Netcraft. Due to security takedowns, a subset of phishing pages was unavailable, reducing dataset diversity. The system achieved \textbf{0.79 accuracy}, \textbf{0.76 precision}, and \textbf{0.78 recall}, showing that visual similarity remains a viable anti-phishing measure. The entire inference process occurs locally, ensuring user privacy and minimal latency.

</details>


### [19] [LeechHijack: Covert Computational Resource Exploitation in Intelligent Agent Systems](https://arxiv.org/abs/2512.02321)
*Yuanhe Zhang,Weiliu Wang,Zhenhong Zhou,Kun Wang,Jie Zhang,Li Sun,Yang Liu,Sen Su*

Main category: cs.CR

TL;DR: MCP는 오픈 생태계를 위한 도구 통합 프레임워크지만, 제3자 도구 공급자에 대한 암묵적인 신뢰가 보안 문제를 초래합니다. 이를 이용해 "임플리시트 독성"이라는 새로운 공격 벡터를 정의하고, LeechHijack이라는 새로운 공격 기법을 제안합니다. 이 기법은 불법적인 작업을 위해 에이전트의 컴퓨팅 자원을 은밀하게 착취합니다.


<details>
  <summary>Details</summary>
Motivation: 모델 컨텍스트 프로토콜(MCP)의 개념은 외부 도구를 에이전트 시스템에 통합하는 것을 가능하게 하지만, 제3자 도구 공급자에 대한 암묵적 신뢰가 보안 문제를 일으킬 수 있다는 점을 강조합니다.

Method: LeechHijack는 두 단계로 이루어진 메커니즘을 통해 실행됩니다: 첫 번째 단계는 도구에 무해한 백도어를 임베드하고, 두 번째 단계에서 미리 정의된 트리거에 따라 백도어가 활성화되어 공격자가 명령 및 제어 채널을 수립합니다.

Result: LeechHijack는 4개 주요 LLM 계열에서 구현되었으며, 평균 성공률은 77.25%에 이르고, 리소스 오버헤드는 18.62%입니다.

Conclusion: 이 연구는 MCP 생태계를 보호하기 위한 컴퓨팅 출처 및 리소스 증명 메커니즘의 필요성을 강조합니다.

Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in reasoning, planning, and tool usage. The recently proposed Model Context Protocol (MCP) has emerged as a unifying framework for integrating external tools into agent systems, enabling a thriving open ecosystem of community-built functionalities. However, the openness and composability that make MCP appealing also introduce a critical yet overlooked security assumption -- implicit trust in third-party tool providers. In this work, we identify and formalize a new class of attacks that exploit this trust boundary without violating explicit permissions. We term this new attack vector implicit toxicity, where malicious behaviors occur entirely within the allowed privilege scope. We propose LeechHijack, a Latent Embedded Exploit for Computation Hijacking, in which an adversarial MCP tool covertly expropriates the agent's computational resources for unauthorized workloads. LeechHijack operates through a two-stage mechanism: an implantation stage that embeds a benign-looking backdoor in a tool, and an exploitation stage where the backdoor activates upon predefined triggers to establish a command-and-control channel. Through this channel, the attacker injects additional tasks that the agent executes as if they were part of its normal workflow, effectively parasitizing the user's compute budget. We implement LeechHijack across four major LLM families. Experiments show that LeechHijack achieves an average success rate of 77.25%, with a resource overhead of 18.62% compared to the baseline. This study highlights the urgent need for computational provenance and resource attestation mechanisms to safeguard the emerging MCP ecosystem.

</details>


### [20] [Characterizing Cyber Attacks against Space Infrastructures with Missing Data: Framework and Case Study](https://arxiv.org/abs/2512.02414)
*Ekzhin Ear,Jose Luis Castanon Remy,Caleb Chang,Qiren Que,Antonia Feffer,Shouhuai Xu*

Main category: cs.CR

TL;DR: 우주 인프라의 사이버 보안은 최근 주목받고 있으며, 이 논문에서는 부족한 데이터를 보완하여 실세계 사이버 공격의 특성을 분석하기 위한 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 우주 인프라에 대한 사이버 공격의 문서화된 데이터가 부족하여, 연구 질문으로 이러한 공격을 어떻게 특성화할 수 있을지에 대해 다룬다.

Method: SPARTA 및 ATT&CK와 같은 방법론을 활용하여 결측 데이터를 보완하는 프레임워크와 지표를 제안한다.

Result: 108건의 사이버 공격 데이터를 추출하여 6,206개의 공격 기술 수준 우주 사이버 킬체인을 도출하는 방법을 제시한다.

Conclusion: 우주 인프라에 대한 사이버 공격이 점점 정교해지고 있으며, 링크 세그먼트 보호가 많은 공격을 막을 수 있었음을 보여준다. 데이터셋은 공개될 예정이다.

Abstract: Cybersecurity of space infrastructures is an emerging topic, despite space-related cybersecurity incidents occurring as early as 1977 (i.e., hijacking of a satellite transmission signal). There is no single dataset that documents cyber attacks against space infrastructures that have occurred in the past; instead, these incidents are often scattered in media reports while missing many details, which we dub the missing-data problem. Nevertheless, even ``low-quality'' datasets containing such reports would be extremely valuable because of the dearth of space cybersecurity data and the sensitivity of space infrastructures which are often restricted from disclosure by governments. This prompts a research question: How can we characterize real-world cyber attacks against space infrastructures? In this paper, we address the problem by proposing a framework, including metrics, while also addressing the missing-data problem by leveraging methodologies such as the Space Attack Research and Tactic Analysis (SPARTA) and the Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK) to ``extrapolate'' the missing data in a principled fashion. We show how the extrapolated data can be used to reconstruct ``hypothetical but plausible'' space cyber kill chains and space cyber attack campaigns that have occurred in practice. To show the usefulness of the framework, we extract data for 108 cyber attacks against space infrastructures and show how to extrapolate this ``low-quality'' dataset containing missing information to derive 6,206 attack technique-level space cyber kill chains. Our findings include: cyber attacks against space infrastructures are getting increasingly sophisticated; successful protection of the link segment between the space and user segments could have thwarted nearly half of the 108 attacks. We will make our dataset available.

</details>


### [21] [Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins](https://arxiv.org/abs/2512.02418)
*Yuexin Xiang,Yuchen Lei,SM Mahir Shazeed Rish,Yuanzhe Zhang,Qin Wang,Tsz Hon Yuen,Jiangshan Yu*

Main category: cs.CR

TL;DR: 이 논문은 LLM 기반의 자동화된 프레임워크를 소개하여 스테이블코인이 발행 통제와 준비금 인증 간의 투명성을 연결하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 스테이블코인은 발행 통제와 준비금 인증을 결합하여 안정성을 목표로 하지만, 실제로는 두 가지 상이한 투명성 문제가 존재합니다.

Method: 우리는 LLM을 활용한 통합 프레임워크를 제안하여 온체인 및 오프체인 데이터를 문서 파싱과 의미론적 정렬을 통해 캡처하고 분석합니다.

Result: 스테이블코인 정보 소스 간의 통합 검색과 맥락 정렬을 통해 일관된 분석을 가능하게 합니다.

Conclusion: LLM 기반 분석이 교차 모드 투명성을 향상시키고 탈중앙화 금융(DeFi)에서 데이터 기반의 자동 감사를 지원하는 방법을 보여줍니다.

Abstract: Stablecoins such as USDT and USDC aspire to peg stability by coupling issuance controls with reserve attestations. In practice, however, the transparency is split across two worlds: verifiable on-chain traces and off-chain disclosures locked in unstructured text that are unconnected. We introduce a large language model (LLM)-based automated framework that bridges these two dimensions by aligning on-chain issuance data with off-chain disclosure statements. First, we propose an integrative framework using LLMs to capture and analyze on- and off-chain data through document parsing and semantic alignment, extracting key financial indicators from issuer attestations and mapping them to corresponding on-chain metrics. Second, we integrate multi-chain issuance records and disclosure documents within a model context protocol (MCP) framework that standardizes LLMs access to both quantitative market data and qualitative disclosure narratives. This framework enables unified retrieval and contextual alignment across heterogeneous stablecoin information sources and facilitates consistent analysis. Third, we demonstrate the capability of LLMs to operate across heterogeneous data modalities in blockchain analytics, quantifying discrepancies between reported and observed circulation and examining their implications for cross-chain transparency and price dynamics. Our findings reveal systematic gaps between disclosed and verifiable data, showing that LLM-assisted analysis enhances cross-modal transparency and supports automated, data-driven auditing in decentralized finance (DeFi).

</details>


### [22] [Cybersecurity AI: The World's Top AI Agent for Security Capture-the-Flag (CTF)](https://arxiv.org/abs/2512.02654)
*Víctor Mayoral-Vilches,Luis Javier Navarrete-Lozano,Francesco Balassone,María Sanz-Gómez,Cristóbal R. J. Veas Chavez,Maite del Mundo de Torres,Vanesa Turiel*

Main category: cs.CR

TL;DR: 2025년 Cybersecurity AI(CAI)가 여러 해킹 대회에서 인간 팀을 지속적으로 초월하며 성과를 거두었고, 이는 CTF의 유용성을 의문시하게 만든다.


<details>
  <summary>Details</summary>
Motivation: AI의 발전이 CTF 대회의 본질을 변화시키고 있다.

Method: CAI는 특정한 모델 아키텍처를 사용하여 여러 해킹 대회에서 우수한 성과를 달성하였다.

Result: CAI는 2025년 여러 주요 CTF 대회에서 인간 팀을 압도하며 1위를 기록하였다.

Conclusion: 보안 커뮤니티는 CTF 형식에서 벗어나 진정한 적응적 추론 및 회복력을 테스트할 수 있는 대회 형식으로 전환해야 한다.

Abstract: Are Capture-the-Flag competitions obsolete? In 2025, Cybersecurity AI (CAI) systematically conquered some of the world's most prestigious hacking competitions, achieving Rank #1 at multiple events and consistently outperforming thousands of human teams. Across five major circuits-HTB's AI vs Humans, Cyber Apocalypse (8,129 teams), Dragos OT CTF, UWSP Pointer Overflow, and the Neurogrid CTF showdown-CAI demonstrated that Jeopardy-style CTFs have become a solved game for well-engineered AI agents. At Neurogrid, CAI captured 41/45 flags to claim the $50,000 top prize; at Dragos OT, it sprinted 37% faster to 10K points than elite human teams; even when deliberately paused mid-competition, it maintained top-tier rankings. Critically, CAI achieved this dominance through our specialized alias1 model architecture, which delivers enterprise-scale AI security operations at unprecedented cost efficiency and with augmented autonomy-reducing 1B token inference costs from $5,940 to just $119, making continuous security agent operation financially viable for the first time. These results force an uncomfortable reckoning: if autonomous agents now dominate competitions designed to identify top security talent at negligible cost, what are CTFs actually measuring? This paper presents comprehensive evidence of AI capability across the 2025 CTF circuit and argues that the security community must urgently transition from Jeopardy-style contests to Attack & Defense formats that genuinely test adaptive reasoning and resilience-capabilities that remain uniquely human, for now.

</details>


### [23] [Belobog: Move Language Fuzzing Framework For Real-World Smart Contracts](https://arxiv.org/abs/2512.02918)
*Wanxu Xia,Ziqiao Kong,Zhengwei Li,Yi Lu,Pan Li,Liqun Yang,Yang Liu,Xiapu Luo,Shaohua Li*

Main category: cs.CR

TL;DR: Move란 안전하고 검증 가능한 스마트 계약 개발을 위한 연구 지향의 프로그래밍 언어로, Sui 및 Aptos와 같은 블록체인에서 수십억 개의 디지털 자산 관리에 널리 사용된다. 그러나 Move로 작성된 스마트 계약은 여전히 특정 취약점이 존재하며, 기존의 퍼저는 syntactically 또는 semantically 유효한 트랜잭션을 생성하는 데 한계가 있다. 이 논문에서는 Move 스마트 계약을 위한 첫 번째 퍼징 프레임워크인 Belobog을 소개하고, Belobog이 모든 생성되고 변형된 트랜잭션이 잘 유형화되도록 한다. 실험 결과, Belobog은 수동으로 감사된 100%의 중대한 취약점과 79%의 주요 취약점을 탐지하였다.


<details>
  <summary>Details</summary>
Motivation: Move 프로그래밍 언어는 안전한 스마트 계약 개발을 지원하는데, 기존의 스마트 계약 퍼저가 Move의 강력한 타입 시스템으로 인해 유효한 트랜잭션을 생성하는 데 어려움을 겪고 있다.

Method: Belobog는 Move의 타입 시스템 기반으로 타입 그래프를 구성하고, 이를 바탕으로 트랜잭션을 생성하거나 변형하며, 또한 복잡한 체크를 극복하기 위해 Belobog에 컨콜리식 실행기를 설계 및 구현하였다.

Result: Belobog를 109개의 실세계 Move 스마트 계약 프로젝트에 평가한 결과, 100%의 중대한 취약점과 79%의 주요 취약점을 탐지하였으며, 유명한 사건인 Cetus와 Nemo에 대한 완전한 익스플로잇을 재현하였다.

Conclusion: Belobog는 Move 스마트 계약의 타입 시스템을 인식하여 잘 유형화된 트랜잭션을 생성하고, 많은 취약점을 실제로 탐지할 수 있는 효과적인 도구임을 입증하였다.

Abstract: Move is a research-oriented programming language design for secure and verifiable smart contract development and has been widely used in managing billions of digital assets in blockchains, such as Sui and Aptos. Move features a strong static type system and explicit resource semantics to enforce safety properties such as the prevention of data races, invalid asset transfers, and entry vulnerabilities. However, smart contracts written in Move may still contain certain vulnerabilities that are beyond the reach of its type system. It is thus essential to validate Move smart contracts. Unfortunately, due to its strong type system, existing smart contract fuzzers are ineffective in producing syntactically or semantically valid transactions to test Move smart contracts. This paper introduces the first fuzzing framework, Belobog, for Move smart contracts. Belobog is type-aware and ensures that all generated and mutated transactions are well-typed. More specifically, for a target Move smart contract, Belobog first constructs a type graph based on Move's type system, and then generates or mutates a transaction based on the graph trace derived from the type graph. In order to overcome the complex checks in Move smart contracts, we further design and implement a concolic executor in Belobog. We evaluated Belobog on 109 real-world Move smart contract projects. The experimental results show that Belobog is able to detect 100\% critical and 79\% major vulnerabilities manually audited by human experts. We further selected two recent notorious incidents in Move smart contracts, i.e., Cetus and Nemo. Belobog successfully reproduced full exploits for both of them, without any prior knowledge.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [From monoliths to modules: Decomposing transducers for efficient world modelling](https://arxiv.org/abs/2512.02193)
*Alexander Boyd,Franz Nowak,David Hyland,Manuel Baltieri,Fernando E. Rosas*

Main category: cs.AI

TL;DR: 이 논문은 모듈 방식으로 상호작용하는 하위 구성 요소를 활용하여 복잡한 세계 모델을 분해하는 프레임워크를 개발합니다.


<details>
  <summary>Details</summary>
Motivation: AI 안전성을 위한 구조적 투명성과 실제 세계 추론을 위한 계산 효율성을 연결할 필요성을 제기합니다.

Method: 전이기(transducer)로 표현된 복잡한 세계 모델을 분해하는 프레임워크를 개발합니다.

Result: 전이기의 조합을 이해하고, 개별 입력-출력 하위공간에서 작동하는 하위 전이기를 파생할 수 있는 방법을 명확히 합니다.

Conclusion: 이 결과는 AI 안전성을 위한 구조적 투명성과 실제 세계 추론에 필요한 계산 효율성을 연결하는 기반을 마련합니다.

Abstract: World models have been recently proposed as sandbox environments in which AI agents can be trained and evaluated before deployment. Although realistic world models often have high computational demands, efficient modelling is usually possible by exploiting the fact that real-world scenarios tend to involve subcomponents that interact in a modular manner. In this paper, we explore this idea by developing a framework for decomposing complex world models represented by transducers, a class of models generalising POMDPs. Whereas the composition of transducers is well understood, our results clarify how to invert this process, deriving sub-transducers operating on distinct input-output subspaces, enabling parallelizable and interpretable alternatives to monolithic world modelling that can support distributed inference. Overall, these results lay a groundwork for bridging the structural transparency demanded by AI safety and the computational efficiency required for real-world inference.

</details>


### [25] [DialogGuard: Multi-Agent Psychosocial Safety Evaluation of Sensitive LLM Responses](https://arxiv.org/abs/2512.02282)
*Han Luo,Guy Laban*

Main category: cs.AI

TL;DR: 이 논문은 LLM에서 생성된 응답의 심리사회적 위험을 평가하기 위한 DialogGuard라는 다중 에이전트 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 정신 건강 및 위기 대응과 같은 감정적으로 민감한 서비스에서 LLM의 심리사회적 안전성이 잘 이해되지 않고 평가가 미흡하기 때문에, 이러한 위험을 효과적으로 평가할 필요성이 있다.

Method: DialogGuard는 프라이버시 위반, 차별적 행동, 정신적 조작, 심리적 해, 모욕적 행동 등 다섯 가지 고위험 차원에 따라 LLM에서 생성된 응답의 심리사회적 위험을 평가하는 다중 에이전트 프레임워크이다.

Result: 다중 에이전트 메커니즘이 비LLM 기준 및 단일 에이전트 평가보다 심리사회적 위험을 더 정확하게 감지하며, 이중 에이전트 교정 및 다수결 투표가 정확도와 인간 평가와의 일치성, 강건성 간의 가장 좋은 균형을 제공한다는 것을 보여준다.

Conclusion: DialogGuard는 웹 인터페이스를 통해 오픈소스로 제공되며, 각 차원별 위험 점수와 설명 가능한 자연어 근거를 제공한다.

Abstract: Large language models (LLMs) now mediate many web-based mental-health, crisis, and other emotionally sensitive services, yet their psychosocial safety in these settings remains poorly understood and weakly evaluated. We present DialogGuard, a multi-agent framework for assessing psychosocial risks in LLM-generated responses along five high-severity dimensions: privacy violations, discriminatory behaviour, mental manipulation, psychological harm, and insulting behaviour. DialogGuard can be applied to diverse generative models through four LLM-as-a-judge pipelines, including single-agent scoring, dual-agent correction, multi-agent debate, and stochastic majority voting, grounded in a shared three-level rubric usable by both human annotators and LLM judges. Using PKU-SafeRLHF with human safety annotations, we show that multi-agent mechanisms detect psychosocial risks more accurately than non-LLM baselines and single-agent judging; dual-agent correction and majority voting provide the best trade-off between accuracy, alignment with human ratings, and robustness, while debate attains higher recall but over-flags borderline cases. We release Dialog-Guard as open-source software with a web interface that provides per-dimension risk scores and explainable natural-language rationales. A formative study with 12 practitioners illustrates how it supports prompt design, auditing, and supervision of web-facing applications for vulnerable users.

</details>


### [26] [STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls](https://arxiv.org/abs/2512.02228)
*Shubhi Asthana,Bing Zhang,Chad DeLuca,Ruchi Mahindru,Hima Patel*

Main category: cs.AI

TL;DR: STRIDE 프레임워크는 작용 AI의 필요성을 평가하여 직접 LLM 호출, 안내 AI 도우미, 완전 자율 작용 AI 중에서 선택할 수 있도록 돕습니다.


<details>
  <summary>Details</summary>
Motivation: 대리인이 증가하면서도 필요에 의해 자율 AI를 언제 적용해야 하는지에 대한 질문이 제기됩니다.

Method: STRIDE는 구조화된 작업 분해, 동적 속성 할당, 자기 반성 요구 분석을 결합하여 작업의 적합성을 평가합니다.

Result: 30개의 실제 작업에서 92%의 정확도로 모드 선택을 성공적으로 수행하고 불필요한 대리인 배치를 45% 줄였으며 자원 비용을 37% 절감했습니다.

Conclusion: 작용 채택을 필요 기반 설계 결정으로 재구성하여 자율성이 필요한 경우에만 적용되도록 보장합니다.

Abstract: The rapid shift from stateless large language models (LLMs) to autonomous, goal-driven agents raises a central question: When is agentic AI truly necessary? While agents enable multi-step reasoning, persistent memory, and tool orchestration, deploying them indiscriminately leads to higher cost, complexity, and risk.
  We present STRIDE (Systematic Task Reasoning Intelligence Deployment Evaluator), a framework that provides principled recommendations for selecting between three modalities: (i) direct LLM calls, (ii) guided AI assistants, and (iii) fully autonomous agentic AI. STRIDE integrates structured task decomposition, dynamism attribution, and self-reflection requirement analysis to produce an Agentic Suitability Score, ensuring that full agentic autonomy is reserved for tasks with inherent dynamism or evolving context.
  Evaluated across 30 real-world tasks spanning SRE, compliance, and enterprise automation, STRIDE achieved 92% accuracy in modality selection, reduced unnecessary agent deployments by 45%, and cut resource costs by 37%. Expert validation over six months in SRE and compliance domains confirmed its practical utility, with domain specialists agreeing that STRIDE effectively distinguishes between tasks requiring simple LLM calls, guided assistants, or full agentic autonomy. This work reframes agent adoption as a necessity-driven design decision, ensuring autonomy is applied only when its benefits justify the costs.

</details>


### [27] [IACT: A Self-Organizing Recursive Model for General AI Agents: A Technical White Paper on the Architecture Behind kragent.ai](https://arxiv.org/abs/2512.02605)
*Pengju Lu*

Main category: cs.AI

TL;DR: IACT는 정적 에이전트 워크플로우의 한계를 해결하기 위한 계산 모델이다.


<details>
  <summary>Details</summary>
Motivation: 정적이고 고정된 에이전트 워크플로우의 한계를 극복하고, 사용자 대화에 의해 주도되는 자율 시스템을 개발하기 위함이다.

Method: 사용자 대화에 따라 에이전트 토폴로지를 동적으로 성장시키고, 유연한 쌍방향 대화로 오류 전파를 완화하는 방법론을 채택하였다.

Result: IACT는 열린 문제에 맞춰 조직 복잡성을 조정할 수 있으며, 실제 워크플로우에서 품질증거를 제공한다.

Conclusion: IACT는 kragent.ai 시스템에서 실제로 배포되어 운영되며, 기술적 원칙과 아키텍처를 제시한다.

Abstract: This technical white paper introduces the Interactive Agents Call Tree (IACT), a computational model designed to address the limitations of static, hard-coded agent workflows. Unlike traditional systems that require pre-defined graphs or specialized programming, IACT operates as a general-purpose autonomous system driven purely by user dialogue. Given a high-level objective, the system autonomously grows a dynamic, recursive agent topology incrementally tailored to the problem's structure. This allows it to scale its organizational complexity to match open-ended tasks. To mitigate the error propagation inherent in unidirectional function calls, IACT introduces interactional redundancy by replacing rigid invocations with bidirectional, stateful dialogues. This mechanism enables runtime error correction and ambiguity resolution. We describe the architecture, design principles, and practical lessons behind the production deployment of this model in the kragent.ai system, presenting qualitative evidence from real-world workflows rather than exhaustive benchmark results.

</details>


### [28] [Benchmarking LLM Agents for Wealth-Management Workflows](https://arxiv.org/abs/2512.02230)
*Rory Milsom*

Main category: cs.AI

TL;DR: 본 논문은 재무 중심 환경에서 총체적 목적의 LLM 에이전트를 사용하여 부의 관리 관련 작업을 수행할 수 있는지 조사하고, 새로운 금융 데이터 세트를 도입하여 작업 생성 파이프라인을 프로토타입하며 평가 세트를 개발하고 평가합니다.


<details>
  <summary>Details</summary>
Motivation: 현대 작업은 다양한 디지털 협업 도구에 의존하고 있지만, 일상적인 프로세스는 여전히 인간의 오류와 지연으로 어려움을 겪고 있습니다.

Method: 이 논문은 TheAgentCompany를 확장하여 재무 중심 환경을 구축하고 대표적인 부의 관리 작업을 정확하고 경제적으로 수행할 수 있는지 조사했습니다. 합성 도메인 데이터를 도입하고 동료 시뮬레이션을 풍부하게 하며 자동 작업 생성 파이프라인을 프로토타입했습니다.

Result: 부의 관리 보조자를 위한 12개의 작업 쌍에 대한 벤치마크를 구성하고, 명확한 수용 기준과 결정론적 평가자를 설정했습니다. 새로운 금융 데이터 세트를 도입하고 모든 작업에 대해 높은 자율성과 낮은 자율성 변형을 도입했습니다.

Conclusion: 논문은 에이전트가 수학적 추론보다는 엔드 투 엔드 워크플로우 신뢰성에 의해 더 많이 제한되며, 자율성 수준에 의해 실질적인 영향을 받으며, 모델의 잘못된 평가가 벤치마킹을 방해했다는 결론을 내렸습니다.

Abstract: Modern work relies on an assortment of digital collaboration tools, yet routine processes continue to suffer from human error and delay. To address this gap, this dissertation extends TheAgentCompany with a finance-focused environment and investigates whether a general purpose LLM agent can complete representative wealth-management tasks both accurately and economically. This study introduces synthetic domain data, enriches colleague simulations, and prototypes an automatic task-generation pipeline. The study aims to create and assess an evaluation set that can meaningfully measure an agent's fitness for assistant-level wealth management work. We construct a benchmark of 12 task-pairs for wealth management assistants spanning retrieval, analysis, and synthesis/communication, with explicit acceptance criteria and deterministic graders. We seeded a set of new finance-specific data and introduced a high vs. low-autonomy variant of every task. The paper concluded that agents are limited less by mathematical reasoning and more so by end-to-end workflow reliability, and meaningfully affected by autonomy level, and that incorrect evaluation of models have hindered benchmarking.

</details>


### [29] [TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?](https://arxiv.org/abs/2512.02261)
*Lewen Yan,Jilin Mei,Tianyi Zhou,Lige Huang,Jie Zhang,Dongrui Liu,Jing Shao*

Main category: cs.AI

TL;DR: TradeTrap은 자율 거래 에이전트를 시스템 차원에서 체계적으로 스트레스 테스트하기 위한 평가 프레임워크로, 시장 지능, 전략 수립, 포트폴리오 및 장부 처리, 거래 실행의 네 가지 핵심 구성 요소를 평가한다.


<details>
  <summary>Details</summary>
Motivation: 자율 분석 및 실행을 수행하기 위해 LLM 기반 거래 에이전트를 활용하는 것이 증가하고 있지만, 높은 위험을 동伴하는 금융 환경에서의 신뢰성과 강건성이 충분히 검토되지 않았다.

Method: TradeTrap은 자율 거래 에이전트를 스트레스 테스트하기 위한 통합 평가 프레임워크이며, 네 가지 핵심 구성 요소를 목표로 하여 제어된 시스템 수준에서의 교란 아래에서 그 강건성을 평가한다.

Result: 실험 결과, 단일 구성 요소에서의 작은 교란이 에이전트 의사결정 루프를 통해 전파되어 극단적인 집중, 무한 노출 및 큰 포트폴리오 손실을 유발할 수 있음을 보여준다.

Conclusion: 현재의 자율 거래 에이전트는 시스템 수준에서 체계적으로 오도될 수 있으며, 이러한 문제를 해결하기 위한 연구의 필요성이 대두된다.

Abstract: LLM-based trading agents are increasingly deployed in real-world financial markets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both adaptive and procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents: market intelligence, strategy formulation, portfolio and ledger handling, and trade execution, and evaluates their robustness under controlled system-level perturbations. All evaluations are conducted in a closed-loop historical backtesting setting on real US equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is available at https://github.com/Yanlewen/TradeTrap.

</details>


### [30] [Breast Cell Segmentation Under Extreme Data Constraints: Quantum Enhancement Meets Adaptive Loss Stabilization](https://arxiv.org/abs/2512.02302)
*Varun Kumar Dasoju,Qingsu Cheng,Zeyun Yu*

Main category: cs.AI

TL;DR: 이 연구에서는 599개의 훈련 이미지로 95.5%의 Dice 점수를 달성하여 유방 세포 분할을 수행했습니다. 이 접근법은 의학 이미징 데이터의 제한된 조건에서도 전문가의 주석 시간을 크게 줄입니다.


<details>
  <summary>Details</summary>
Motivation: 의료 이미지를 주석하는 데 시간과 전문성이 많이 소요되며, 병리학자들이 수백 시간을 투자해야 합니다.

Method: 양자 영감을 받은 엣지 향상 기술과 다중 스케일 Gabor 필터를 사용하여 경계 탐지를 강화하고, 적응형 Dice 손실 함수를 포함한 다중 구성 손실 함수를 소개하며, 복잡성 기반의 가중 샘플링 전략을 도입했습니다.

Result: 모델은 95.5% +/- 0.3%의 Dice 점수와 91.2% +/- 0.4%의 IoU를 달성했습니다. 특히, 양자 기반 향상 방법이 경계 정확도를 2.1% 개선하고, 가중 샘플링이 작은 병변 탐지를 3.8% 증가시켰습니다.

Conclusion: 이 접근법은 한정된 주석으로 혁신적인 성능을 달성함으로써 임상 인지 AI 개발의 근본적인 병목 현상을 해결합니다.

Abstract: Annotating medical images demands significant time and expertise, often requiring pathologists to invest hundreds of hours in labeling mammary epithelial nuclei datasets. We address this critical challenge by achieving 95.5% Dice score using just 599 training images for breast cell segmentation, where just 4% of pixels represent breast tissue and 60% of images contain no breast regions. Our framework uses quantum-inspired edge enhancement via multi-scale Gabor filters creating a fourth input channel, enhancing boundary detection where inter-annotator variations reach +/- 3 pixels. We present a stabilized multi-component loss function that integrates adaptive Dice loss with boundary-aware terms and automatic positive weighting to effectively address severe class imbalance, where mammary epithelial cell regions comprise only 0.1%-20% of the total image area. Additionally, a complexity-based weighted sampling strategy is introduced to prioritize the challenging mammary epithelial cell regions. The model employs an EfficientNet-B7/UNet++ architecture with a 4-to-3 channel projection, enabling the use of pretrained weights despite limited medical imaging data. Finally, robust validation is achieved through exponential moving averaging and statistical outlier detection, ensuring reliable performance estimates on a small validation set (129 images). Our framework achieves a Dice score of 95.5% +/- 0.3% and an IoU of 91.2% +/- 0.4%. Notably, quantum-based enhancement contributes to a 2.1% improvement in boundary accuracy, while weighted sampling increases small lesion detection by 3.8%. By achieving groundbreaking performance with limited annotations, our approach significantly reduces the medical expert time required for dataset creation, addressing a fundamental bottleneck in clinical perception AI development.

</details>


### [31] [Beyond Playtesting: A Generative Multi-Agent Simulation System for Massively Multiplayer Online Games](https://arxiv.org/abs/2512.02358)
*Ran Zhang,Kun Ouyang,Tiancheng Ma,Yida Yang,Dong Fang*

Main category: cs.AI

TL;DR: 대규모 다인 온라인 게임에서 플레이어 경험을 향상시키기 위한 수치 시스템 및 메커니즘 설계를 최적화하는 것이 중요하다. 본 논문에서는 대규모 실제 플레이어 행동 데이터를 활용하여 게임 특정 도메인에 맞춘 언어 모델을 적응시키고, 실제 게임 플레이 로그를 기반으로 동적 시스템을 재구성하는 방법을 제안한다. 이를 통해 신뢰할 수 있고 해석 가능한 데이터 기반 최적화 프레임워크를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 다인 온라인 게임의 플레이어 경험 향상을 위해 수치 시스템 및 메커니즘 설계를 최적화할 필요가 있다.

Method: 대규모 실제 플레이어 행동 데이터에 대해 감독 세부 조정(SFT) 및 강화 학습(RL)을 적용하여 언어 모델을 게임 특정 도메인에 적응시키고, 실제 게임 플레이 로그를 활용하여 동적 시스템을 재구성하는 생성형 에이전트 기반 MMO 시뮬레이션 시스템을 제안한다.

Result: 실제 플레이어 행동과 강한 일치성을 보이며, 개입에 대한 그럴듯한 인과 반응을 나타낸다.

Conclusion: 신뢰할 수 있고 해석 가능한 데이터 기반의 수치 설계 최적화 프레임워크를 제공한다.

Abstract: Optimizing numerical systems and mechanism design is crucial for enhancing player experience in Massively Multiplayer Online (MMO) games. Traditional optimization approaches rely on large-scale online experiments or parameter tuning over predefined statistical models, which are costly, time-consuming, and may disrupt player experience. Although simplified offline simulation systems are often adopted as alternatives, their limited fidelity prevents agents from accurately mimicking real player reasoning and reactions to interventions. To address these limitations, we propose a generative agent-based MMO simulation system empowered by Large Language Models (LLMs). By applying Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on large-scale real player behavioral data, we adapt LLMs from general priors to game-specific domains, enabling realistic and interpretable player decision-making. In parallel, a data-driven environment model trained on real gameplay logs reconstructs dynamic in-game systems. Experiments demonstrate strong consistency with real-world player behaviors and plausible causal responses under interventions, providing a reliable, interpretable, and cost-efficient framework for data-driven numerical design optimization.

</details>


### [32] [Semantic Trading: Agentic AI for Clustering and Relationship Discovery in Prediction Markets](https://arxiv.org/abs/2512.02436)
*Agostino Capponi,Alfio Gliozzo,Brian Zhu*

Main category: cs.AI

TL;DR: 이 연구는 예측 시장에서의 정보 분산 문제를 해결하기 위한 자율적 AI 파이프라인을 제안하며, 시장 간의 강한 관계를 발견하고 이를 기초로 거래 전략을 수립한다.


<details>
  <summary>Details</summary>
Motivation: 예측 시장은 현실 세계 사건의 결과에 대해 거래할 수 있도록 하지만, 중복 질문, 암묵적 동등성 및 시장 간 숨겨진 모순으로 인해 정보가 단편화되는 경향이 있다.

Method: 자율적 AI 파이프라인이 계약 텍스트 및 메타데이터에 대한 자연어 이해를 사용하여 시장을 일관된 주제 그룹으로 클러스터링하고, 클러스터 내의 쌍 간 강한 의존성을 나타내는 시장 쌍을 식별한다.

Result: 과거 Polymarket의 해결된 시장 데이터셋을 사용하여 에이전트의 관계 예측 정확도를 평가한 결과, 에이전트가 식별한 관계는 약 60-70%의 정확도를 달성하였고, 이에 따른 거래 전략은 주간 평균 약 20% 수익을 올렸다.

Conclusion: 에이전트 AI와 대규모 언어 모델이 예측 시장에서 숨겨진 의미 구조를 발견하는 능력을 강조한다.

Abstract: Prediction markets allow users to trade on outcomes of real-world events, but are prone to fragmentation through overlapping questions, implicit equivalences, and hidden contradictions across markets. We present an agentic AI pipeline that autonomously (i) clusters markets into coherent topical groups using natural-language understanding over contract text and metadata, and (ii) identifies within-cluster market pairs whose resolved outcomes exhibit strong dependence, including same-outcome (correlated) and different-outcome (anti-correlated) relationships. Using a historical dataset of resolved markets on Polymarket, we evaluate the accuracy of the agent's relational predictions. We then translate discovered relationships into a simple trading strategy to quantify how these relationships map to actionable signals. Results show that agent-identified relationships achieve roughly 60-70% accuracy, and their induced trading strategies earn about 20% average returns over week-long horizons, highlighting the ability of agentic AI and large language models to uncover latent semantic structure in prediction markets.

</details>


### [33] [Aetheria: A multimodal interpretable content safety framework based on multi-agent debate and collaboration](https://arxiv.org/abs/2512.02530)
*Yuxiang He,Jian Zhao,Yuchen Yuan,Tianle Zhang,Wei Cai,Haojie Cheng,Ziyan Shi,Ming Zhu,Haichuan Tang,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: Aetheria는 다중 에이전트 논쟁을 기반으로 한 콘텐츠 안전성 프레임워크로, 암묵적 위험 식별과 해석 가능한 판단 프로세스의 제한을 해결한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 콘텐츠의 급격한 증가로 콘텐츠 안전성에 대한 도전이 커지고 있다.

Method: Aetheria는 다섯 개의 핵심 에이전트로 구성된 협력 구조를 사용하여, RAG 기반 지식 검색을 통해 다중 모드 콘텐츠를 심층적으로 분석하고 판별한다.

Result: Aetheria는 상세하고 추적 가능한 감사 보고서를 생성하며, 기본 모델 대비 콘텐츠 안전성 정확도에서 현저한 우위를 보인다.

Conclusion: 이 프레임워크는 신뢰할 수 있는 AI 콘텐츠 조정 분야에서 투명하고 해석 가능한 패러다임을 확립한다.

Abstract: The exponential growth of digital content presents significant challenges for content safety. Current moderation systems, often based on single models or fixed pipelines, exhibit limitations in identifying implicit risks and providing interpretable judgment processes. To address these issues, we propose Aetheria, a multimodal interpretable content safety framework based on multi-agent debate and collaboration.Employing a collaborative architecture of five core agents, Aetheria conducts in-depth analysis and adjudication of multimodal content through a dynamic, mutually persuasive debate mechanism, which is grounded by RAG-based knowledge retrieval.Comprehensive experiments on our proposed benchmark (AIR-Bench) validate that Aetheria not only generates detailed and traceable audit reports but also demonstrates significant advantages over baselines in overall content safety accuracy, especially in the identification of implicit risks. This framework establishes a transparent and interpretable paradigm, significantly advancing the field of trustworthy AI content moderation.

</details>


### [34] [PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing](https://arxiv.org/abs/2512.02589)
*Junyi Hou,Andre Lin Huikai,Nuo Chen,Yiwei Gong,Bingsheng He*

Main category: cs.AI

TL;DR: PaperDebugger는 LaTeX 편집기에서 LLM 기반 작문 지원을 제공하는 플러그인 기반의 다중 에이전트 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 학술 작문 보조 도구가 편집기와 분리되어 있어 문서 상태, 구조 및 수정 이력을 깊이 있게 상호작용하는 것을 방지하고 있음.

Method: PaperDebugger는 편집기와의 양방향 동기화, 세밀한 버전 관리 및 패칭, 안전한 상태 관리, 다중 에이전트 스케줄링 등을 통해 LaTeX 편집기 내에서 LLM 기반 추론을 지원하는 다중 에이전트 플러그인 기반 작문 보조 도구이다.

Result: 데모는 최소한의 방해 UI 내에서 지역화된 편집, 구조화된 리뷰, 병렬 에이전트 실행 및 차이 기반 업데이트를 포함한 완전 통합 워크플로를 보여준다.

Conclusion: 초기 집계 분석은 활발한 사용자 참여를 보여주며, 편집기 네이티브 에이전틱 작문 보조 도구의 실용성을 검증한다.

Abstract: Large language models are increasingly embedded into academic writing workflows, yet existing assistants remain external to the editor, preventing deep interaction with document state, structure, and revision history. This separation makes it impossible to support agentic, context-aware operations directly within LaTeX editors such as Overleaf. We present PaperDebugger, an in-editor, multi-agent, and plugin-based academic writing assistant that brings LLM-driven reasoning directly into the writing environment. Enabling such in-editor interaction is technically non-trivial: it requires reliable bidirectional synchronization with the editor, fine-grained version control and patching, secure state management, multi-agent scheduling, and extensible communication with external tools. PaperDebugger addresses these challenges through a Chrome-approved extension, a Kubernetes-native orchestration layer, and a Model Context Protocol (MCP) toolchain that integrates literature search, reference lookup, document scoring, and revision pipelines. Our demo showcases a fully integrated workflow, including localized edits, structured reviews, parallel agent execution, and diff-based updates, encapsulated within a minimal-intrusion user interface (UI). Early aggregated analytics demonstrate active user engagement and validate the practicality of an editor-native, agentic writing assistant. More details about this demo and video could be found at https://github.com/PaperDebugger/PaperDebugger.

</details>


### [35] [Zero-Shot Instruction Following in RL via Structured LTL Representations](https://arxiv.org/abs/2512.02633)
*Mattia Giuri,Mathias Jackermeier,Alessandro Abate*

Main category: cs.AI

TL;DR: 본 논문에서는 강화 학습 에이전트를 위한 고급 다중 작업 정책 학습을 위한 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 접근 방식이 여러 고수준 이벤트가 동시에 true일 수 있는 환경에서 부족한 점을 해결하고자 한다.

Method: 정책을 단순한 불리언 공식의 시퀀스에 조건화하여 자동자의 전환과 직접 일치하도록 하고, 그래프 신경망(GNN)을 통해 구조화된 작업 표현을 생성하는 방법을 사용한다.

Result: 복잡한 체스 기반 환경에서 실험을 통해 우리 접근 방식의 장점을 입증한다.

Conclusion: 이 방법은 임의의 LTL 지침을 따르기 위한 다중 작업 정책 학습에 효과적이다.

Abstract: Linear temporal logic (LTL) is a compelling framework for specifying complex, structured tasks for reinforcement learning (RL) agents. Recent work has shown that interpreting LTL instructions as finite automata, which can be seen as high-level programs monitoring task progress, enables learning a single generalist policy capable of executing arbitrary instructions at test time. However, existing approaches fall short in environments where multiple high-level events (i.e., atomic propositions) can be true at the same time and potentially interact in complicated ways. In this work, we propose a novel approach to learning a multi-task policy for following arbitrary LTL instructions that addresses this shortcoming. Our method conditions the policy on sequences of simple Boolean formulae, which directly align with transitions in the automaton, and are encoded via a graph neural network (GNN) to yield structured task representations. Experiments in a complex chess-based environment demonstrate the advantages of our approach.

</details>


### [36] [Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs](https://arxiv.org/abs/2512.02713)
*Theodoros Aivalis,Iraklis A. Klampanos,Antonis Troumpoukis,Joemon M. Jose*

Main category: cs.AI

TL;DR: 본 논문은 생성 모델의 출력 해석을 위한 지식 그래프(KG) 자동 구축 프레임워크를 제안하며, 이를 통해 저작권 분석과 데이터세트 투명성을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 생성 모델의 투명성, 책임성, 저작권 침해에 대한 우려가 커지고 있다.

Method: 다중 모달 대형 언어 모델(LLM)을 활용하여 이미지에서 도메인 특정 온톨로지와 일치하는 구조적 트리플을 추출한다.

Result: 생성된 이미지와 훈련 이미지의 KG를 비교함으로써 잠재적 영향을 추적할 수 있다.

Conclusion: 본 프레임워크는 인간 협업과 창의성을 촉진하며 호기심을 자극하는 AI 시스템 개발을 지원한다.

Abstract: As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.

</details>


### [37] [AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping](https://arxiv.org/abs/2512.02726)
*Md Abdul Kadir,Sai Suresh Macharla Vasu,Sidharth S. Nair,Daniel Sonntag*

Main category: cs.AI

TL;DR: 대형 언어 모델이 전통적인 회계 감사 방법에 비해 더 우수한 성능을 보여주며, 인간 감사자와 협력하여 재무 무결성을 강화할 수 있는 가능성을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 저널 항목 테스트(JET)가 세금 관련 원장 기록에서 이상을 탐지하는 데 한계가 있으며, 큰 오류가 발생하는 경우가 많습니다.

Method: LLaMA와 Gemma 같은 최신 대형 언어 모델(LLM)을 사용하여 합성 및 실제 익명 원장에서 저널 항목 테스트(JET)와 기계 학습 기준 모델과 비교하고 벤치마킹합니다.

Result: 대형 언어 모델이 전통적인 규칙 기반 JET와 고전적인 기계 학습 기준 모델보다 일관되게 우수한 성과를 보였습니다.

Conclusion: AI 증강 감사의 잠재력을 강조하며, 인간 감사자가 기초 모델과 협력하여 재무 무결성을 강화할 수 있음을 보여줍니다.

Abstract: Auditors rely on Journal Entry Tests (JETs) to detect anomalies in tax-related ledger records, but rule-based methods generate overwhelming false positives and struggle with subtle irregularities. We investigate whether large language models (LLMs) can serve as anomaly detectors in double-entry bookkeeping. Benchmarking SoTA LLMs such as LLaMA and Gemma on both synthetic and real-world anonymized ledgers, we compare them against JETs and machine learning baselines. Our results show that LLMs consistently outperform traditional rule-based JETs and classical ML baselines, while also providing natural-language explanations that enhance interpretability. These results highlight the potential of \textbf{AI-augmented auditing}, where human auditors collaborate with foundation models to strengthen financial integrity.

</details>


### [38] [Self-Improving AI Agents through Self-Play](https://arxiv.org/abs/2512.02731)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 이 논문에서는 심리 측정 배터리의 모듈 이론적 프레임워크를 동적 시스템 분야로 확장합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구에서 AAI 능력 점수를 에이전트 표현 공간의 정적 함수로 설정했지만, 본 논문은 계산 자원에 의해 매개된 흐름 $ν_r$로 에이전트를 형식화합니다.

Method: 우리는 재귀적인 생성기-검증기-업데이트기(GVU) 연산자가 매개변수 다양체 $Θ$에서 벡터 필드를 생성한다는 것을 증명합니다.

Result: 자기 개선의 안정성을 보장하는 분산 불평등을 도출하며, $κ> 0$을 위한 충분 조건이 생성 및 검증의 결합 노이즈가 충분히 작아야 한다는 것을 보여줍니다.

Conclusion: 이 공식화를 사용하여 최근 언어 자기 놀이(LSP), 자기 수정 및 합성 데이터 부트스트래핑 문헌을 통합합니다.

Abstract: We extend the moduli-theoretic framework of psychometric batteries to the domain of dynamical systems. While previous work established the AAI capability score as a static functional on the space of agent representations, this paper formalizes the agent as a flow $ν_r$ parameterized by computational resource $r$, governed by a recursive Generator-Verifier-Updater (GVU) operator. We prove that this operator generates a vector field on the parameter manifold $Θ$, and we identify the coefficient of self-improvement $κ$ as the Lie derivative of the capability functional along this flow.
  The central contribution of this work is the derivation of the Variance Inequality, a spectral condition that is sufficient (under mild regularity) for the stability of self-improvement. We show that a sufficient condition for $κ> 0$ is that, up to curvature and step-size effects, the combined noise of generation and verification must be small enough.
  We then apply this formalism to unify the recent literature on Language Self-Play (LSP), Self-Correction, and Synthetic Data bootstrapping. We demonstrate that architectures such as STaR, SPIN, Reflexion, GANs and AlphaZero are specific topological realizations of the GVU operator that satisfy the Variance Inequality through filtration, adversarial discrimination, or grounding in formal systems.

</details>


### [39] [Enhancing Automated Paper Reproduction via Prompt-Free Collaborative Agents](https://arxiv.org/abs/2512.02812)
*Zijie Lin,Qilin Cai,Liang Shen,Mingjun Xiao*

Main category: cs.AI

TL;DR: 자동화된 논문 재현이 과학 연구를 가속화하는 유망한 접근 방식으로 등장했지만, 기존 프레임워크는 출력 검증 및 개선 메커니즘이 부족하거나 수동으로 설계된 프롬프트에 의존해 적응성과 확장성을 제한한다. 우리는 프롬프트 없는 협업 에이전트 프레임워크를 제안하여 학술 논문을 코드로 생성하는 품질을 자동으로 향상시킨다. 우리의 접근법은 각 단계의 출력을 검토하는 검증 에이전트와 문제에 기반해 출력을 수정하는 개선 에이전트를 포함한다. 실험 결과, 우리의 방법은 재현된 코드의 정확성과 완전성을 각각 약 15%와 13% 개선하였으며, Self-Refine와의 비교 실험을 통해 프롬프트 없는 접근 방식의 강 robustness와 일관성을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 논문 재현이 과학 연구를 가속화할 수 있는 가능성을 가지고 있음.

Method: 프롬프트 없는 협업 에이전트 프레임워크를 제안하여 검증 에이전트와 개선 에이전트를 통해 품질을 향상시킴.

Result: 기존 기법과 비교하여 코드의 정확성과 완전성을 각각 약 15% 및 13% 향상시킴.

Conclusion: 프롬프트 없는 접근법의 강 robustness와 일관성을 입증함.

Abstract: Automated paper reproduction has emerged as a promising approach to accelerate scientific research, employing multi-step workflow frameworks to systematically convert academic papers into executable code. However, existing frameworks often lack mechanisms to verify and refine the outputs at each generation step, or rely heavily on manually designed prompts for self-refinement, which limits their adaptability and scalability. To address these limitations, we propose a prompt-free collaborative agent framework that automatically enhances the quality of paper-to-code generation. Our approach employs two collaborative agents: a verification agent that examines whether the outputs at each step satisfy the requirements specified in the corresponding system prompt, and a refinement agent that revises the outputs based on the identified issues. Unlike previous methods that require human experts to craft specific refinement prompts for each step, our framework achieves automatic verification and improvement by leveraging only the original system prompts. We integrate our collaborative agents into the Paper2Code framework and conduct comprehensive experiments on PaperBench Code-Dev and Paper2CodeBench datasets. Experimental results demonstrate that our approach significantly improves the accuracy and completeness of reproduced code, achieving performance gains of approximately 15\% and 13\%, respectively, compared to the baseline without our agents. Furthermore, comparative experiments against Self-Refine validate the robustness and consistency of our prompt-free approach across different datasets.

</details>


### [40] [Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control](https://arxiv.org/abs/2512.02814)
*Yongrui Yu,Zhongzhen Huang,Linjie Mu,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: Radiologist Copilot는 품질 관리를 통합한 자동 방사선 보고 시스템으로, 방사선 전문의의 효율성을 높이고 정확성을 보장한다.


<details>
  <summary>Details</summary>
Motivation: 방사선 보고는 시간이 많이 소모되고 오류가 발생하기 쉬운 임상 검사 작업으로, 특히 부피 이미지의 경우는 더욱 그러하다. 엄격한 품질 관리는 필수적이지만 귀찮은 과정이다.

Method: Radiologist Copilot는 대규모 언어 모델을 활용하여 자신의 도구를 선택하고 계획하며 실행함으로써, 방사선 보고 프로세스 전반에 걸쳐 방사선 전문의를 모방하는 자율적인 AI 시스템이다.

Result: Radiologist Copilot는 고급 방사선 보고 방식에서 다른 최신 방법들을 크게 초월하는 성능을 보였다.

Conclusion: 이 시스템은 정확하고 완전하며 효율적인 방사선 보고를 용이하게 하여 방사선 전문의를 지원하고 임상 효율성을 향상시킨다.

Abstract: Radiology reporting is an essential yet time-consuming and error-prone task for radiologists in clinical examinations, especially for volumetric medical images. Rigorous quality control is also critical but tedious, ensuring that the final report meets clinical standards. Existing automated approaches, including radiology report generation methods and medical vision-language models, focus mainly on the report generation phase and neglect the crucial quality control procedure, limiting their capability to provide comprehensive support to radiologists. We propose Radiologist Copilot, an agentic AI assistant equipped with orchestrated tools designed for automated radiology reporting with quality control. Leveraging large language models as the reasoning backbone, the agentic system autonomously selects tools, plans, and executes actions, emulating the behavior of radiologists throughout the holistic radiology reporting process. The orchestrated tools include region localization, think with image paradigm directed region analysis planning, strategic template selection for report generation, quality assessment and feedback-driven adaptive refinement for quality control. Therefore, Radiologist Copilot facilitates accurate, complete, and efficient radiology reporting, assisting radiologists and improving clinical efficiency. Experimental results demonstrate that Radiologist Copilot significantly surpasses other state-of-the-art methods in radiology reporting. The source code will be released upon acceptance.

</details>


### [41] [Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning](https://arxiv.org/abs/2512.02914)
*Zhonghao He,Tianyi Qiu,Hirokazu Shirado,Maarten Sap*

Main category: cs.AI

TL;DR: 대형 언어 모델의 추론 성능이 향상되었지만, 반복적 추론이 믿음 고착과 확증 편향을 조장할 수 있다는 증거가 나타나고 있다. 본 연구에서는 이러한 믿음 고착을 평가하기 위한 체계적인 프레임워크를 제안하고, Martingale 점수를 통해 이를 측정한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 정확하고 신뢰할 수 있는 정보 제공 능력에 대한 기대가 높아짐에 따라, 반복적 추론이 진리 추구 행동을 저해할 수 있는지를 연구하는 것이 중요하다.

Method: Bayesian 통계의 Martingale 속성을 활용하여 믿음 고착을 평가하는 체계적인 프레임워크를 제안하고, 회귀 기반의 Martingale 점수를 도입하여 이 속성의 위반을 측정한다.

Result: 이 연구를 통해 이벤트 예측, 가치 지향 질문, 학술 논문 리뷰와 같은 다양한 문제 도메인에서 현재 믿음이 미래 믿음 업데이트를 긍정적으로 예측하는 경우가 널리 퍼져 있음을 발견하였다.

Conclusion: Martingale 점수가 진리 추구 능력을 예측하는 유용한 지표임을 검증하였다.

Abstract: Recent advances in reasoning techniques have substantially improved the performance of large language models (LLMs), raising expectations for their ability to provide accurate, truthful, and reliable information. However, emerging evidence suggests that iterative reasoning may foster belief entrenchment and confirmation bias, rather than enhancing truth-seeking behavior. In this study, we propose a systematic evaluation framework for belief entrenchment in LLM reasoning by leveraging the Martingale property from Bayesian statistics. This property implies that, under rational belief updating, the expected value of future beliefs should remain equal to the current belief, i.e., belief updates are unpredictable from the current belief. We propose the unsupervised, regression-based Martingale Score to measure violations of this property, which signal deviation from the Bayesian ability of updating on new evidence. In open-ended problem domains including event forecasting, value-laden questions, and academic paper review, we find such violations to be widespread across models and setups, where the current belief positively predicts future belief updates, a phenomenon which we term belief entrenchment. We identify the models, reasoning techniques, and domains more prone to belief entrenchment. Finally, we validate the Martingale Score by showing that it predicts ground-truth accuracy on problem domains where ground truth labels are available. This indicates that, while designed as an unsupervised metric that operates even in domains without access to ground truth, the Martingale Score is a useful proxy of the truth-seeking ability of a reasoning process.

</details>


### [42] [From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?](https://arxiv.org/abs/2512.03005)
*Dawei Li,Abdullah Alnaibari,Arslan Bisharat,Manny Sandoval,Deborah Hall,Yasin Silva,Huan Liu*

Main category: cs.AI

TL;DR: 대형 언어 모델이 온라인 커뮤니케이션 중재에서 공감과 건설적인 대화를 촉진할 수 있는 가능성을 탐구하는 연구.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 빠른 발전이 AI의 긍정적인 응용 가능성을 열었습니다. LLM이 온라인 커뮤니케이션을 중재하면서, 공감과 건설적인 대화를 촉진할 수 있는 잠재력이 책임 있는 AI 연구의 중요한 경계가 됩니다.

Method: 이 연구는 중재를 판단(LLM이 대화의 공정성과 감정적 역학을 평가)과 조정(공감적이고 긴장을 완화하는 메시지를 생성하여 참여자들을 해결로 이끌기)이라는 두 개의 하위 작업으로 나눕니다. 중재 품질을 평가하기 위해 대규모 Reddit 기반 데이터 세트를 구성하고 원칙 기반 점수화, 사용자 시뮬레이션, 인간 비교를 결합한 다단계 평가 파이프라인을 제안합니다.

Result: 실험 결과, API 기반 모델이 중재를 수행할 때 논리적 추론과 개입 정렬에서 오픈 소스 모델보다 우수한 성능을 보였습니다.

Conclusion: 현재 LLM이 온라인 사회 중재를 위한 신흥 에이전트로서의 가능성과 한계를 강조합니다.

Abstract: The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [43] [Orchestration Framework for Financial Agents: From Algorithmic Trading to Agentic Trading](https://arxiv.org/abs/2512.02227)
*Jifeng Li,Arnav Grover,Abraham Alpuerto,Yupeng Cao,Xiao-Yang Liu*

Main category: cs.MA

TL;DR: 이 논문에서는 금융 시장에서의 인공지능 에이전트를 위한 오케스트레이션 프레임워크를 제안하며, 일반 대중에게 금융 지능을 민주화하는 것을 목표로 한다. 두 가지 거래 예제를 통해 개발한 알고리즘의 성과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 금융시장은 시간적 동적과 낮은 신호-잡음 비율로 인해 AI 에이전트의 필수적인 분야이다. 효과적인 알고리즘 트레이딩 시스템을 구축하기 위해서는 전문 팀이 수년간 개발 및 테스트를 해야 할 수 있다.

Method: 전통적인 알고리즘 트레이딩 시스템의 각 구성 요소를 에이전트에 매핑하고, 계획자, 오케스트레이터, 알파 에이전트, 리스크 에이전트, 포트폴리오 에이전트, 백테스트 에이전트, 실행 에이전트, 감사 에이전트, 메모리 에이전트를 포함한다.

Result: 주식 거래 작업에서의 성과로 $20.42\%$의 수익률과 2.63의 샤프 비율, $-3.59\%$의 최대 손실을 보였고, S&P 500 지수는 $15.97\%$의 수익률을 기록했다. 비트코인 거래 작업에서는 $8.39\%$의 수익률과 0.38의 샤프 비율, $-2.80\%$의 최대 손실을 기록했으며, 비트코인 가격은 $3.80\%$ 상승했다.

Conclusion: 제안한 프레임워크는 알고리즘 트레이딩 시스템의 다양한 구성 요소를 에이전트 형태로 구성하여 더 많은 사람들이 금융 거래의 혜택을 누릴 수 있도록 하였다.

Abstract: The financial market is a mission-critical playground for AI agents due to its temporal dynamics and low signal-to-noise ratio. Building an effective algorithmic trading system may require a professional team to develop and test over the years. In this paper, we propose an orchestration framework for financial agents, which aims to democratize financial intelligence to the general public. We map each component of the traditional algorithmic trading system to agents, including planner, orchestrator, alpha agents, risk agents, portfolio agents, backtest agents, execution agents, audit agents, and memory agent. We present two in-house trading examples. For the stock trading task (hourly data from 04/2024 to 12/2024), our approach achieved a return of $20.42\%$, a Sharpe ratio of 2.63, and a maximum drawdown of $-3.59\%$, while the S&P 500 index yielded a return of $15.97\%$. For the BTC trading task (minute data from 27/07/2025 to 13/08/2025), our approach achieved a return of $8.39\%$, a Sharpe ratio of $0.38$, and a maximum drawdown of $-2.80\%$, whereas the BTC price increased by $3.80\%$. Our code is available on \href{https://github.com/Open-Finance-Lab/AgenticTrading}{GitHub}.

</details>


### [44] [Decentralized Multi-Agent System with Trust-Aware Communication](https://arxiv.org/abs/2512.02410)
*Yepeng Ding,Ahmed Twabi,Junwei Yu,Lingfeng Zhang,Tohru Kondo,Hiroyuki Sato*

Main category: cs.MA

TL;DR: 이 논문은 자율 다중 에이전트 시스템을 위한 분산 아키텍처를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 중앙 집중형 다중 에이전트 시스템 아키텍처는 단일 실패 지점, 검열에 대한 취약성, 확장성 제한 및 신뢰 문제와 같은 상당한 도전에 직면하고 있다.

Method: 블록체인 기반 아키텍처에 의해 뒷받침되는 분산 에이전트 런타임을 특징으로 하는 분산 다중 에이전트 시스템(DMAS) 아키텍처를 제안하며, 암호학적 원리와 온체인 운영을 활용하여 신뢰 인식 커뮤니케이션 프로토콜을 형식화한다.

Result: DMAS는 검증 가능한 상호작용 사이클, 통신 무결성, 진정성, 부인 방지, 조건부 기밀성과 같은 보안 속성을 제공한다.

Conclusion: 성능 분석을 통해 DMAS는 신뢰할 수 있는 다중 에이전트 시스템 구축을 위한 확장 가능하고 효율적인 솔루션으로 검증된다.

Abstract: The emergence of Large Language Models (LLMs) is rapidly accelerating the development of autonomous multi-agent systems (MAS), paving the way for the Internet of Agents. However, traditional centralized MAS architectures present significant challenges, including single points of failure, vulnerability to censorship, inherent scalability limitations, and critical trust issues. We propose a novel Decentralized Multi-Agent System (DMAS) architecture designed to overcome these fundamental problems by enabling trust-aware, scalable, and censorship-resistant interactions among autonomous agents. Our DMAS features a decentralized agent runtime underpinned by a blockchain-based architecture. We formalize a trust-aware communication protocol that leverages cryptographic primitives and on-chain operations to provide security properties: verifiable interaction cycles, communication integrity, authenticity, non-repudiation, and conditional confidentiality, which we further substantiate through a comprehensive security analysis. Our performance analysis validates the DMAS as a scalable and efficient solution for building trustworthy multi-agent systems.

</details>


### [45] [EZYer: A simulacrum of high school with generative agent](https://arxiv.org/abs/2512.02561)
*Jinming Yang,Zimu Ji,Weiqi Luo,Gaoxi Wang,Bin Ma,Yueling Deng*

Main category: cs.MA

TL;DR: EZYer라는 생성형 에이전트는 교육 자료 생성 및 대화형 노트 작성에서의 부족한 서비스와 상호작용 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 교육과 대형 언어 모델의 빠른 발전에도 불구하고 기존 교육 도구들은 여전히 불완전한 서비스와 저조한 성능으로 고통받고 있다.

Method: EZYer는 교사 모듈, 학생 모듈, 제어기를 포함하며 각각은 교육 자료 자동 생성, 협업 상호작용을 통한 학습 노트 요약, 키워드 필터링 및 동적 내용 수정 시스템을 갖춘다.

Result: 500개의 학습 노트와 Beamer 내용을 EZYer로 생성하여 다섯 가지 대형 언어 모델로 평가한 결과, EZYer이 생성한 콘텐츠의 품질이 우수함이 확인되었다.

Conclusion: EZYer는 교육 자료와 학습 노트 생성에서 좋은 응용 전망을 가진다.

Abstract: With the rapid development of the online education and large language model, the existing educational tools still suffer from incomplete service, insufficient performance and weak interactivity in terms of courseware generation, interactive notes and quality assurance of content. In particular, the proposed generative agent EZYer : 1) Teacher Module: Integrating the Text Corpus retrieval and in-depth generation technologies, it automatically generates structured teaching materials and LaTeX Beamer courseware in line with the high school mathematics syllabus and supports user-defined image insertion. 2) Student Module: Throughout the collaborative interaction of the four roles of Teacher, Assistant, Top Student and Struggling Student, Note Taker summarizes and generates academic notes to enhance the depth and interest of learning. 3) Controller: set up keyword filtering system, content scoring system, role co-validation system, and dynamic content correction system. This ensure academic strictness and pedagogical propriety of EZYer inputs and outputs. In order to evaluate EZYer, this paper designs five-dimensional evaluation indexes of content accuracy, knowledge coverage, usability, formatting correctness and visual design and appeal, and scores 100 Beamer and Notes generated by EZYer by five large language models, separately, and the results show that the quality of EZYer-generated content is excellent and has a good application prospect.

</details>


### [46] [Beyond Single-Agent Safety: A Taxonomy of Risks in LLM-to-LLM Interactions](https://arxiv.org/abs/2512.02682)
*Piercosma Bisconti,Marcello Galisai,Federico Pierucci,Marcantonio Bracale,Matteo Prandi*

Main category: cs.MA

TL;DR: 대형 언어 모델(LLM) 간 상호작용에서 안전 메커니즘의 한계를 다룸.


<details>
  <summary>Details</summary>
Motivation: 인간-모델 상호작용을 위한 안전 메커니즘이 LLM 간 상호작용 환경에서 적용되지 않는 이유를 조사함.

Method: 모델 수준의 안전에서 시스템 수준의 안전으로의 개념적 전환을 제안하고 Emergent Systemic Risk Horizon(ESRH) 프레임워크를 도입.

Result: LLM 간 상호작용에서의 집단적 위험, 실패 모드 분류, 다중 에이전트 시스템 내에서 적응형 감독을 포함하는 InstitutionalAI 아키텍처 설계 제안.

Conclusion: 시스템 구조에서 불안정성이 발생하는 방식을 공식화함으로써 LLM 간 상호작용에서의 안전 문제 해결을 위한 새로운 접근 방식을 제시.

Abstract: This paper examines why safety mechanisms designed for human-model interaction do not scale to environments where large language models (LLMs) interact with each other. Most current governance practices still rely on single-agent safety containment, prompts, fine-tuning, and moderation layers that constrain individual model behavior but leave the dynamics of multi-model interaction ungoverned. These mechanisms assume a dyadic setting: one model responding to one user under stable oversight. Yet research and industrial development are rapidly shifting toward LLM-to-LLM ecosystems, where outputs are recursively reused as inputs across chains of agents. In such systems, local compliance can aggregate into collective failure even when every model is individually aligned. We propose a conceptual transition from model-level safety to system-level safety, introducing the framework of the Emergent Systemic Risk Horizon (ESRH) to formalize how instability arises from interaction structure rather than from isolated misbehavior. The paper contributes (i) a theoretical account of collective risk in interacting LLMs, (ii) a taxonomy connecting micro, meso, and macro-level failure modes, and (iii) a design proposal for InstitutionalAI, an architecture for embedding adaptive oversight within multi-agent systems.

</details>
