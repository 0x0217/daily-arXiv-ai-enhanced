<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 10]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.AI](#cs.AI) [Total: 23]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Learning an Adversarial World Model for Automated Curriculum Generation in MARL](https://arxiv.org/abs/2509.03771)
*Brennen Hill*

Main category: cs.LG

TL;DR: 적응형 환경 생성은 에이전트 학습의 복잡도에 따라 변화하는 목표 조건의 생성적 세계 모델 학습 문제로 재구성된다.


<details>
  <summary>Details</summary>
Motivation: 진정으로 일반화 가능하고 강력한 에이전트를 개발하기 위해서는 에이전트의 학습에 따라 복잡성이 증가하는 환경이 필요하다.

Method: 생성적 공격 에이전트가 협력적 방어자 팀을 위한 점점 더 어려운 도전을 합성하도록 학습하는 목표 조건의 생성적 세계 모델을 제안한다.

Result: 이 프레임워크는 적응형 교과 과정을 만들어 에이전트의 의사결정 정책에 도전하는 새로운 훈련 시나리오의 지속적인 흐름을 제공한다.

Conclusion: 적대적 공진화가 에이전트를 더욱 전략 깊이와 강인함으로 이끄는 도구적 세계 모델 학습의 강력한 방법으로 자리잡고 있다.

Abstract: World models that infer and predict environmental dynamics are foundational
to embodied intelligence. However, their potential is often limited by the
finite complexity and implicit biases of hand-crafted training environments. To
develop truly generalizable and robust agents, we need environments that scale
in complexity alongside the agents learning within them. In this work, we
reframe the challenge of environment generation as the problem of learning a
goal-conditioned, generative world model. We propose a system where a
generative **Attacker** agent learns an implicit world model to synthesize
increasingly difficult challenges for a team of cooperative **Defender**
agents. The Attacker's objective is not passive prediction, but active,
goal-driven interaction: it models and generates world states (i.e.,
configurations of enemy units) specifically to exploit the Defenders'
weaknesses. Concurrently, the embodied Defender team learns a cooperative
policy to overcome these generated worlds. This co-evolutionary dynamic creates
a self-scaling curriculum where the world model continuously adapts to
challenge the decision-making policy of the agents, providing an effectively
infinite stream of novel and relevant training scenarios. We demonstrate that
this framework leads to the emergence of complex behaviors, such as the world
model learning to generate flanking and shielding formations, and the defenders
learning coordinated focus-fire and spreading tactics. Our findings position
adversarial co-evolution as a powerful method for learning instrumental world
models that drive agents toward greater strategic depth and robustness.

</details>


### [2] [AutoGrid AI: Deep Reinforcement Learning Framework for Autonomous Microgrid Management](https://arxiv.org/abs/2509.03666)
*Kenny Guo,Nicholas Eckhert,Krish Chhajer,Luthira Abeykoon,Lorne Schell*

Main category: cs.LG

TL;DR: 이 논문은 원거리 커뮤니티를 위한 자율 마이크로그리드 관리를 위한 심층 강화 학습 기반 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 원거리 커뮤니티의 에너지 관리를 최적화하고 재생 가능한 에너지원의 활용도를 극대화하기 위한 필요성에서 출발했다.

Method: 심층 강화 학습과 시계열 예측 모델을 사용하여 마이크로그리드 에너지 배분 전략을 최적화하며, 예측을 위한 변환기 아키텍처와 PPO 에이전트를 통합해 시뮬레이션된 환경에서 결정을 내린다.

Result: 실험 결과, 전통적인 규칙 기반 방법과 비교했을 때 에너지 효율성과 운영 회복력에서 상당한 개선이 있음을 보였다.

Conclusion: 이 연구는 제로 탄소 에너지 시스템을 목표로 스마트 그리드 기술 발전에 기여하며, 여러 마이크로그리드 환경을 시뮬레이션하기 위한 오픈 소스 프레임워크를 제공한다.

Abstract: We present a deep reinforcement learning-based framework for autonomous
microgrid management. tailored for remote communities. Using deep reinforcement
learning and time-series forecasting models, we optimize microgrid energy
dispatch strategies to minimize costs and maximize the utilization of renewable
energy sources such as solar and wind. Our approach integrates the transformer
architecture for forecasting of renewable generation and a proximal-policy
optimization (PPO) agent to make decisions in a simulated environment. Our
experimental results demonstrate significant improvements in both energy
efficiency and operational resilience when compared to traditional rule-based
methods. This work contributes to advancing smart-grid technologies in pursuit
of zero-carbon energy systems. We finally provide an open-source framework for
simulating several microgrid environments.

</details>


### [3] [A Comprehensive Review of Multi-Agent Reinforcement Learning in Video Games](https://arxiv.org/abs/2509.03682)
*Zhengyang Li,Qijin Ji,Xinghong Ling,Quan Liu*

Main category: cs.LG

TL;DR: 이 논문은 다중 에이전트 강화 학습(MARL)의 비디오 게임에서의 응용을 포괄적으로 검토하고, 주요 도전 과제를 분석하며, 게임 개발에서 MARL의 발전을 위한 미래 연구 방향을 제안한다.


<details>
  <summary>Details</summary>
Motivation: MARL의 성장하는 영향력으로 인해 이 분야에서 포괄적인 리뷰의 필요성이 증가하고 있다.

Method: 순차적인 두 에이전트 게임에서 실시간 다중 에이전트 비디오 게임으로의 MARL 응용을 철저히 검토하고, Rocket League, Minecraft, Quake III Arena 등에서의 성공적인 구현 사례를 강조한다.

Result: MARL이 제공하는 통찰력과 게임 복잡성을 추정하는 새로운 방법을 제안하며, 게임 개발에서의 MARL 응용을 발전시킬 방향을 제시한다.

Conclusion: 이 연구는 지속적으로 변화하는 다중 에이전트 강화 학습 분야에서 혁신을 촉진할 수 있는 미래의 연구 방향을 제안한다.

Abstract: Recent advancements in multi-agent reinforcement learning (MARL) have
demonstrated its application potential in modern games. Beginning with
foundational work and progressing to landmark achievements such as AlphaStar in
StarCraft II and OpenAI Five in Dota 2, MARL has proven capable of achieving
superhuman performance across diverse game environments through techniques like
self-play, supervised learning, and deep reinforcement learning. With its
growing impact, a comprehensive review has become increasingly important in
this field. This paper aims to provide a thorough examination of MARL's
application from turn-based two-agent games to real-time multi-agent video
games including popular genres such as Sports games, First-Person Shooter (FPS)
games, Real-Time Strategy (RTS) games and Multiplayer Online Battle Arena
(MOBA) games. We further analyze critical challenges posed by MARL in video
games, including nonstationary, partial observability, sparse rewards, team
coordination, and scalability, and highlight successful implementations in
games like Rocket League, Minecraft, Quake III Arena, StarCraft II, Dota 2,
Honor of Kings, etc. This paper offers insights into MARL in video game AI
systems, proposes a novel method to estimate game complexity, and suggests
future research directions to advance MARL and its applications in game
development, inspiring further innovation in this rapidly evolving field.

</details>


### [4] [Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures](https://arxiv.org/abs/2509.03695)
*Payam Abdisarabshali,Fardis Nadimi,Kasra Borazjani,Naji Khosravan,Minghui Liwang,Wei Ni,Dusit Niyato,Michael Langberg,Seyyedali Hosseinalipour*

Main category: cs.LG

TL;DR: 본 논문은 계층적 연합 기초 모델(HF-FMs)을 제안하여 다중 모드 다중 작업 연합 기초 모델(M3T FFMs)의 새로운 변형을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 연합 기초 모델(FFMs)의 필요성이 증가하고 있으며, 다중 모드 및 다중 작업을 처리할 수 있는 새로운 패러다임인 M3T FFMs가 등장하고 있다.

Method: 계층적 연합 기초 모델(HF-FMs)을 설계하고, 이를 통해 안개/엣지 네트워크의 두 가지 이질성 차원(수집된 모달리티 및 실행된 작업의 이질성)을 탐구한다.

Result: HF-FMs는 M3T FMs의 모듈 구조를 전략적으로 정렬하고, 장치 간(D2D) 통신을 통해 수평 모듈 중계 및 국소 협력 훈련을 가능하게 한다.

Conclusion: HF-FMs의 아키텍처 설계를 통해 고유한 기능을 강조하고, 이 분야의 탐색을 촉진하기 위해 오픈 소스 코드를 공개한다.

Abstract: The rise of foundation models (FMs) has reshaped the landscape of machine
learning. As these models continued to grow, leveraging geo-distributed data
from wireless devices has become increasingly critical, giving rise to
federated foundation models (FFMs). More recently, FMs have evolved into
multi-modal multi-task (M3T) FMs (e.g., GPT-4) capable of processing diverse
modalities across multiple tasks, which motivates a new underexplored paradigm:
M3T FFMs. In this paper, we unveil an unexplored variation of M3T FFMs by
proposing hierarchical federated foundation models (HF-FMs), which in turn
expose two overlooked heterogeneity dimensions to fog/edge networks that have a
direct impact on these emerging models: (i) heterogeneity in collected
modalities and (ii) heterogeneity in executed tasks across fog/edge nodes.
HF-FMs strategically align the modular structure of M3T FMs, comprising
modality encoders, prompts, mixture-of-experts (MoEs), adapters, and task
heads, with the hierarchical nature of fog/edge infrastructures. Moreover,
HF-FMs enable the optional usage of device-to-device (D2D) communications,
enabling horizontal module relaying and localized cooperative training among
nodes when feasible. Through delving into the architectural design of HF-FMs,
we highlight their unique capabilities along with a series of tailored future
research directions. Finally, to demonstrate their potential, we prototype
HF-FMs in a wireless network setting and release the open-source code for the
development of HF-FMs with the goal of fostering exploration in this untapped
field (GitHub: https://github.com/payamsiabd/M3T-FFM).

</details>


### [5] [From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game](https://arxiv.org/abs/2509.03834)
*Lucas Lopes Felipe,Konstantin Avrachenkov,Daniel Sadoc Menasche*

Main category: cs.LG

TL;DR: 본 논문은 네트워크를 불연속 커뮤니티로 분할하기 위한 Constant Potts Model(CPM)의 게임 이론적 관점을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 커뮤니티 탐지는 데이터 과학에서 기본적인 문제 중 하나로, 노드를 불연속 커뮤니티로 분할하는 것을 포함합니다.

Method: CPM을 지역 효용 함수로 구성된 글로벌 해밀토니안으로 분해하여 잠재적 쾌락 게임으로 재구성하고, 지역 최적화가 어떻게 균형 상태로 수렴하는지 증명합니다.

Result: 실험 결과, 로버스트한 분할이 초기 파라미터를 사용하여 진실 커뮤니티 복구의 정확도를 높이는 것으로 나타났습니다.

Conclusion: 커뮤니티 탐지에서의 CPM의 효율성, 견고성 및 정확성을 강조합니다.

Abstract: Community detection is one of the fundamental problems in data science which
consists of partitioning nodes into disjoint communities. We present a
game-theoretic perspective on the Constant Potts Model (CPM) for partitioning
networks into disjoint communities, emphasizing its efficiency, robustness, and
accuracy. Efficiency: We reinterpret CPM as a potential hedonic game by
decomposing its global Hamiltonian into local utility functions, where the
local utility gain of each agent matches the corresponding increase in global
utility. Leveraging this equivalence, we prove that local optimization of the
CPM objective via better-response dynamics converges in pseudo-polynomial time
to an equilibrium partition. Robustness: We introduce and relate two stability
criteria: a strict criterion based on a novel notion of robustness, requiring
nodes to simultaneously maximize neighbors and minimize non-neighbors within
communities, and a relaxed utility function based on a weighted sum of these
objectives, controlled by a resolution parameter. Accuracy: In community
tracking scenarios, where initial partitions are used to bootstrap the Leiden
algorithm with partial ground-truth information, our experiments reveal that
robust partitions yield higher accuracy in recovering ground-truth communities.

</details>


### [6] [Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables](https://arxiv.org/abs/2509.03845)
*Yang Chen,Xiao Lin,Bo Yan,Libo Zhang,Jiamou Liu,Neset Özkan Tan,Michael Witbrock*

Main category: cs.LG

TL;DR: 이 논문은 비동질적인 목표를 가진 지능형 에이전트의 보상 함수를 추론하기 위한 심층 잠재 변수 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 지능형 에이전트들을 위한 적절한 보상 함수를 설계하는 것은 현실 세계에서 도전적입니다.

Method: 심층 잠재 변수 MFG 모델과 관련된 IRL 방법을 제안합니다.

Result: 시뮬레이션 시나리오와 실제 공간 택시 요금 문제에서 실험을 통해 기존 최첨단 IRL 방법보다 우수성을 입증합니다.

Conclusion: 우리는 기존 방법이 처리할 수 없는 이질적이고 알려지지 않은 목표를 가진 시연 처리를 가능하게 합니다.

Abstract: Designing suitable reward functions for numerous interacting intelligent
agents is challenging in real-world applications. Inverse reinforcement
learning (IRL) in mean field games (MFGs) offers a practical framework to infer
reward functions from expert demonstrations. While promising, the assumption of
agent homogeneity limits the capability of existing methods to handle
demonstrations with heterogeneous and unknown objectives, which are common in
practice. To this end, we propose a deep latent variable MFG model and an
associated IRL method. Critically, our method can infer rewards from different
yet structurally similar tasks without prior knowledge about underlying
contexts or modifying the MFG model itself. Our experiments, conducted on
simulated scenarios and a real-world spatial taxi-ride pricing problem,
demonstrate the superiority of our approach over state-of-the-art IRL methods
in MFGs.

</details>


### [7] [TAGAL: Tabular Data Generation using Agentic LLM Methods](https://arxiv.org/abs/2509.04152)
*Benoît Ronval,Pierre Dupont,Siegfried Nijssen*

Main category: cs.LG

TL;DR: TAGAL은 대형 언어 모델을 이용하여 자동으로 합성 테이블 데이터를 생성하는 방법 모음이다.


<details>
  <summary>Details</summary>
Motivation: 머신러닝 작업의 성능 향상을 위한 데이터 생성의 필요성.

Method: TAGAL은 피드백을 활용하여 데이터를 개선하는 자동화되고 반복적인 과정을 통해 합성 데이터를 생성하는 방법을 제시한다.

Result: TAGAL은 선진 기법과 동일한 성능을 보여주며, 다른 훈련 없는 접근 방식보다 일반적으로 우수한 성과를 기록한다.

Conclusion: TAGAL은 에이전틱 워크플로우의 잠재력을 강조하며 LLM 기반 데이터 생성 방법의 새로운 방향을 열어준다.

Abstract: The generation of data is a common approach to improve the performance of
machine learning tasks, among which is the training of models for
classification. In this paper, we present TAGAL, a collection of methods able
to generate synthetic tabular data using an agentic workflow. The methods
leverage Large Language Models (LLMs) for an automatic and iterative process
that uses feedback to improve the generated data without any further LLM
training. The use of LLMs also allows for the addition of external knowledge in
the generation process. We evaluate TAGAL across diverse datasets and different
aspects of quality for the generated data. We look at the utility of downstream
ML models, both by training classifiers on synthetic data only and by combining
real and synthetic data. Moreover, we compare the similarities between the real
and the generated data. We show that TAGAL is able to perform on par with
state-of-the-art approaches that require LLM training and generally outperforms
other training-free approaches. These findings highlight the potential of
agentic workflow and open new directions for LLM-based data generation methods.

</details>


### [8] [Why Can't I See My Clusters? A Precision-Recall Approach to Dimensionality Reduction Validation](https://arxiv.org/abs/2509.04222)
*Diede P. M. van der Hoorn,Alessio Arleo,Fernando V. Paulovich*

Main category: cs.LG

TL;DR: 차원 축소(DR) 방법은 고차원 데이터를 시각화하는 데 널리 사용되지만 기대하는 클러스터 구조가 항상 나타나지 않는다. 이 논문에서는 DR 프로세스를 관계 단계와 매핑 단계로 나누어 문제를 해결하고, 관계 단계의 품질을 평가하기 위한 두 가지 감독 메트릭스(정밀도 및 재현율)를 도입한다. 이 접근법은 하이퍼파라미터 조정을 안내하고, 투영 결과의 아티팩트를 발견하며, 기대하는 구조가 관계에서 포착되었는지를 판단하는 데 도움이 된다.


<details>
  <summary>Details</summary>
Motivation: 차원 축소(DR) 과정의 신뢰성을 높이고, 기대하는 클러스터 구조가 사라지는 이유를 설명하기 위해

Method: DR 프로세스를 관계 단계와 매핑 단계로 나누고, 정밀도 및 재현율이라는 두 가지 감독 메트릭스를 도입하여 관계 단계를 평가

Result: 정밀도 및 재현율 메트릭이 기대하는 클러스터 구조와 모델링된 관계의 정렬 정도를 정량화

Conclusion: 이 접근법은 DR 프로세스를 더 빠르고 신뢰할 수 있도록 하이퍼파라미터 조정, 투영 아티팩트 발견 및 관계에서 기대하는 구조의 포착 여부를 판단하는 데 도움을 준다.

Abstract: Dimensionality Reduction (DR) is widely used for visualizing high-dimensional
data, often with the goal of revealing expected cluster structure. However,
such a structure may not always appear in the projections. Existing DR quality
metrics assess projection reliability (to some extent) or cluster structure
quality, but do not explain why expected structures are missing. Visual
Analytics solutions can help, but are often time-consuming due to the large
hyperparameter space. This paper addresses this problem by leveraging a recent
framework that divides the DR process into two phases: a relationship phase,
where similarity relationships are modeled, and a mapping phase, where the data
is projected accordingly. We introduce two supervised metrics, precision and
recall, to evaluate the relationship phase. These metrics quantify how well the
modeled relationships align with an expected cluster structure based on some
set of labels representing this structure. We illustrate their application
using t-SNE and UMAP, and validate the approach through various usage
scenarios. Our approach can guide hyperparameter tuning, uncover projection
artifacts, and determine if the expected structure is captured in the
relationships, making the DR process faster and more reliable.

</details>


### [9] [When three experiments are better than two: Avoiding intractable correlated aleatoric uncertainty by leveraging a novel bias--variance tradeoff](https://arxiv.org/abs/2509.04363)
*Paul Scherer,Andreas Kirsch,Jake P. Taylor-King*

Main category: cs.LG

TL;DR: 이 연구에서는 이분산 우연적 불확실성을 고려한 새로운 활성 학습 전략을 제안하고, 이로 인해 실험 라운드 간의 편향을 감소시키는 방법을 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 실세계 실험 시나리오는 이분산 우연적 불확실성이 존재하며, 이 불확실성은 배치 설정에서 상관관계가 있을 수 있습니다.

Method: 편향-분산 균형을 활용하여 모델 분포와 실제 랜덤 변수 간의 예상 평균 제곱 오차를 설명하는 새로운 활성 학습 전략을 제안합니다.

Result: 우리의 방법은 BALD 및 Least Confidence와 같은 여러 전통적인 방법보다 우수한 성능을 보였습니다.

Conclusion: 역사적 데이터를 이용한 새로운 공분산 관계를 통해 배치 메커니즘을 자연스럽게 제안합니다.

Abstract: Real-world experimental scenarios are characterized by the presence of
heteroskedastic aleatoric uncertainty, and this uncertainty can be correlated
in batched settings. The bias--variance tradeoff can be used to write the
expected mean squared error between a model distribution and a ground-truth
random variable as the sum of an epistemic uncertainty term, the bias squared,
and an aleatoric uncertainty term. We leverage this relationship to propose
novel active learning strategies that directly reduce the bias between
experimental rounds, considering model systems both with and without noise.
Finally, we investigate methods to leverage historical data in a quadratic
manner through the use of a novel cobias--covariance relationship, which
naturally proposes a mechanism for batching through an eigendecomposition
strategy. When our difference-based method leveraging the cobias--covariance
relationship is utilized in a batched setting (with a quadratic estimator), we
outperform a number of canonical methods including BALD and Least Confidence.

</details>


### [10] [Unveiling the Role of Data Uncertainty in Tabular Deep Learning](https://arxiv.org/abs/2509.04430)
*Nikolay Kartashev,Ivan Rubachev,Artem Babenko*

Main category: cs.LG

TL;DR: 본 연구는 최신 표 형식 심층 학습 방법의 효과를 데이터 불확실성 개념으로 설명하고, 이를 통해 기술이 성공하는 이유를 밝힌다.


<details>
  <summary>Details</summary>
Motivation: 표 형식 심층 학습의 원활한 성공 원인에 대한 이해 부족 문제를 해결하고자 한다.

Method: 데이터 불확실성을 관리하는 다양한 설계 선택의 성공을 분석하고, 이를 통해 성능 개선을 설명한다.

Result: 고급 수치 특성 임베딩을 개발하고, 불확실성 관점에서의 통찰력을 바탕으로 성능 개선을 이루어냈다.

Conclusion: 본 연구는 최신 표 형식 방법의 이점을 이해하고, 향후 표 형식 심층 학습 연구 방향을 제시한다.

Abstract: Recent advancements in tabular deep learning have demonstrated exceptional
practical performance, yet the field often lacks a clear understanding of why
these techniques actually succeed. To address this gap, our paper highlights
the importance of the concept of data uncertainty for explaining the
effectiveness of the recent tabular DL methods. In particular, we reveal that
the success of many beneficial design choices in tabular DL, such as numerical
feature embeddings, retrieval-augmented models and advanced ensembling
strategies, can be largely attributed to their implicit mechanisms for managing
high data uncertainty. By dissecting these mechanisms, we provide a unifying
understanding of the recent performance improvements. Furthermore, the insights
derived from this data-uncertainty perspective directly allowed us to develop
more effective numerical feature embeddings as an immediate practical outcome
of our analysis. Overall, our work paves the way to foundational understanding
of the benefits introduced by modern tabular methods that results in the
concrete advancements of existing techniques and outlines future research
directions for tabular DL.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [11] [SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India](https://arxiv.org/abs/2509.03793)
*Prathamesh Devadiga,Omkaar Jayadev Shetty,Pooja Agarwal*

Main category: cs.MA

TL;DR: 이 논문은 인도 사법 시스템 내에서의 심의 과정을 시뮬레이션하기 위해 설계된 SAMVAD라는 혁신적인 다중 에이전트 시스템을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 사법 심의의 복잡성을 이해하는 것은 정의 시스템의 효율성과 공정성을 평가하는 데 중요하다.

Method: SAMVAD는 판사, 기소 변호사, 방어 변호사 및 여러 판결자를 대변하는 에이전트로 구성되어 있으며, 대규모 언어 모델에 의해 작동된다. 이 시스템은 법률 문서에 기반한 정보 검색 증강 생성(RAG) 기능을 통합하였다.

Result: 에이전트는 반복적인 심의 과정을 통해 사건 사실과 법적 지시사항을 처리하여 합의된 판결에 도달한다.

Conclusion: 이 연구는 인도 법률 맥락에 맞춤화된 법적 추론 및 집단 의사결정 역학을 탐구할 수 있는 조정 가능하고 설명 가능한 MAS 플랫폼을 제공한다.

Abstract: Understanding the complexities of judicial deliberation is crucial for
assessing the efficacy and fairness of a justice system. However, empirical
studies of judicial panels are constrained by significant ethical and practical
barriers. This paper introduces SAMVAD, an innovative Multi-Agent System (MAS)
designed to simulate the deliberation process within the framework of the
Indian justice system.
  Our system comprises agents representing key judicial roles: a Judge, a
Prosecution Counsel, a Defense Counsel, and multiple Adjudicators (simulating a
judicial bench), all powered by large language models (LLMs). A primary
contribution of this work is the integration of Retrieval-Augmented Generation
(RAG), grounded in a domain-specific knowledge base of landmark Indian legal
documents, including the Indian Penal Code and the Constitution of India. This
RAG functionality enables the Judge and Counsel agents to generate legally
sound instructions and arguments, complete with source citations, thereby
enhancing both the fidelity and transparency of the simulation.
  The Adjudicator agents engage in iterative deliberation rounds, processing
case facts, legal instructions, and arguments to reach a consensus-based
verdict. We detail the system architecture, agent communication protocols, the
RAG pipeline, the simulation workflow, and a comprehensive evaluation plan
designed to assess performance, deliberation quality, and outcome consistency.
  This work provides a configurable and explainable MAS platform for exploring
legal reasoning and group decision-making dynamics in judicial simulations,
specifically tailored to the Indian legal context and augmented with verifiable
legal grounding via RAG.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [ShieldMMU: Detecting and Defending against Controlled-Channel Attacks in Shielding Memory System](https://arxiv.org/abs/2509.03879)
*Gang Liu,Ningjie Li,Cen Chen*

Main category: cs.CR

TL;DR: ShieldMMU는 Intel SGX의 보안을 강화하기 위한 종합 솔루션으로, 비특권 프로그램과 소프트웨어의 격리를 지원하고 사이드 채널 공격을 완화한다.


<details>
  <summary>Details</summary>
Motivation: 사이드 채널 공격이 Intel SGX의 보안에 위협을 가하고 있으며, 기존 방어 시스템이 비효율적이다.

Method: Merkle 나무에서 영감을 받은 방어 트리(DD-Tree)를 활용하여 공격받은 PTE를 감지, 위치 파악, 복원하는 방식을 사용한다.

Result: 실험을 통해 ShieldMMU의 보안 강화와 허용 가능한 지연 성능이 확인되었다.

Conclusion: ShieldMMU는 비특권 애플리케이션을 안전하게 운영할 수 있도록 도움을 준다.

Abstract: Intel SGX and hypervisors isolate non-privileged programs from other
software, ensuring confidentiality and integrity. However, side-channel attacks
continue to threaten Intel SGX's security, enabling malicious OS to manipulate
PTE present bits, induce page faults, and steal memory access traces. Despite
extensive research, existing defenses focus on detection or rely on impractical
solutions. This paper presents ShieldMMU, a comprehensive solution for
mitigating controlled channel attacks, balancing compatibility, performance,
and usability. Leveraging a Merkle Tree-inspired Defense Tree (DD-Tree),
ShieldMMU protects PTE integrity by detecting, locating, and restoring attacked
PTEs. It identifies MMU page table lookup events and side-channel attacks,
promptly restoring PTE parameters to prevent page fault traps and ensure secure
non-privileged application operation within SGX. Our experiments confirm
ShieldMMU's enhanced security and acceptable latency performance.

</details>


### [13] [Revisiting Third-Party Library Detection: A Ground Truth Dataset and Its Implications Across Security Tasks](https://arxiv.org/abs/2509.04091)
*Jintao Gu,Haolang Lu,Guoshun Nan,Yihan Lin,Kun Wang,Yuchun Guo,Yigui Cao,Yang Liu*

Main category: cs.CR

TL;DR: 안드로이드 보안에서 제3자 라이브러리(TPL)의 정확한 탐지는 필수적이며, 우리는 6,000개 이상의 앱을 대상으로 한 TPL 탐지 기술에 대한 대규모 실증 연구를 수행하였다.


<details>
  <summary>Details</summary>
Motivation: 본 연구는 안드로이드 보안에서 제3자 라이브러리의 정확한 탐지가 중요하며, 이를 통해 취약점 추적, 악성코드 탐지 및 공급망 감사에 기여할 수 있음을 강조한다.

Method: 10가지 최첨단 TPL 탐지 기법을 6,000개 이상의 앱에 대해 평가하고, 원격 및 로컬 의존성에 대한 정밀한 버전 수준 주석이 포함된 새로운 기준 데이터셋을 활용하였다.

Result: 우리의 평가는 R8 시대의 변환에 대한 도구의 취약점, 약한 버전 식별, 후보 라이브러리에 대한 부정확한 일치, 유사성 임계값의 일반화 어려움 및 대규모에서의 과도한 런타임/메모리 오버헤드를 드러낸다.

Conclusion: TPL 특성이 취약점 분석, 악성코드 탐지, 비밀 유출 평가 및 LLM 기반 평가와 같은 하위 작업에 미치는 영향을 구체적으로 분석하여, 보안 분석의 향후 개선 방안을 제시한다.

Abstract: Accurate detection of third-party libraries (TPLs) is fundamental to Android
security, supporting vulnerability tracking, malware detection, and supply
chain auditing. Despite many proposed tools, their real-world effectiveness
remains unclear.We present the first large-scale empirical study of ten
state-of-the-art TPL detection techniques across over 6,000 apps, enabled by a
new ground truth dataset with precise version-level annotations for both remote
and local dependencies.Our evaluation exposes tool fragility to R8-era
transformations, weak version discrimination, inaccurate correspondence of
candidate libraries, difficulty in generalizing similarity thresholds, and
prohibitive runtime/memory overheads at scale.Beyond tool assessment, we
further analyze how TPLs shape downstream tasks, including vulnerability
analysis, malware detection, secret leakage assessment, and LLM-based
evaluation. From this perspective, our study provides concrete insights into
how TPL characteristics affect these tasks and informs future improvements in
security analysis.

</details>


### [14] [KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis](https://arxiv.org/abs/2509.04191)
*Omri Sgan Cohen,Ehud Malul,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai*

Main category: cs.CR

TL;DR: KubeGuard는 Kubernetes 환경의 보안을 강화하기 위한 로그 기반 추천 프레임워크로, overly permissive configurations를 해결하여 공격 표면을 줄인다.


<details>
  <summary>Details</summary>
Motivation: Kubernetes(K8s)의 광범위한 채택이 잘못 구성된 리소스 및 과도한 권한 구성과 같은 보안 문제를 초래하고 있으며, 이러한 문제를 해결하지 않으면 무단 접근 및 권한 상승 등의 위험이 존재한다.

Method: KubeGuard는 리소스 생성과 리소스 정제라는 두 가지 상호 보완적인 작업을 통해 K8s 환경을 강화하며, 대형 언어 모델(LLMs)을 활용하여 실제 시스템 동작을 반영하는 매니페스트와 런타임 로그를 분석한다.

Result: KubeGuard는 Roles, NetworkPolicies 및 Deployments에 대한 K8s 매니페스트를 효과적으로 생성 및 정제하며, 높은 정확도 및 F1 점수를 보여 KubeGuard의 실용성을 입증한다.

Conclusion: KubeGuard는 런타임 관찰 가능성을 실행 가능한 최적 권한 구성 지침으로 변환하는 프레임워크로서, 클러스터 보안을 강화하는 추천을 제공한다.

Abstract: The widespread adoption of Kubernetes (K8s) for orchestrating cloud-native
applications has introduced significant security challenges, such as
misconfigured resources and overly permissive configurations. Failing to
address these issues can result in unauthorized access, privilege escalation,
and lateral movement within clusters. Most existing K8s security solutions
focus on detecting misconfigurations, typically through static analysis or
anomaly detection. In contrast, this paper presents KubeGuard, a novel runtime
log-driven recommender framework aimed at mitigating risks by addressing overly
permissive configurations. KubeGuard is designed to harden K8s environments
through two complementary tasks: Resource Creation and Resource Refinement. It
leverages large language models (LLMs) to analyze manifests and runtime logs
reflecting actual system behavior, using modular prompt-chaining workflows.
This approach enables KubeGuard to create least-privilege configurations for
new resources and refine existing manifests to reduce the attack surface.
KubeGuard's output manifests are presented as recommendations that users (e.g.,
developers and operators) can review and adopt to enhance cluster security. Our
evaluation demonstrates that KubeGuard effectively generates and refines K8s
manifests for Roles, NetworkPolicies, and Deployments, leveraging both
proprietary and open-source LLMs. The high precision, recall, and F1-scores
affirm KubeGuard's practicality as a framework that translates runtime
observability into actionable, least-privilege configuration guidance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning](https://arxiv.org/abs/2509.03817)
*Wei Yang,Jesse Thomason*

Main category: cs.AI

TL;DR: MPDF는 다중 에이전트 시스템에서의 메타 인지 정책 학습을 통해 더 나은 협력적 성과를 도모한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 공동 작업 프로토콜은 LLM들이 지닌 내부 사고 능력을 무시하므로, 이를 극복할 필요가 있다.

Method: Meta-Policy Deliberation Framework(MPDF)와 SoftRankPO라는 강화 학습 알고리즘을 통해 에이전트가 메타 인지 행동을 학습하도록 한다.

Result: MPDF와 SoftRankPO를 통해 평균 정확도에서 4-5%의 절대적 향상을 이루었다.

Conclusion: 적응형 메타 인지 정책 학습을 위한 새로운 패러다임을 제시하였다.

Abstract: Multi-agent systems of large language models (LLMs) show promise for complex
reasoning, but their effectiveness is often limited by fixed collaboration
protocols. These frameworks typically focus on macro-level orchestration while
overlooking agents' internal deliberative capabilities. This critical
meta-cognitive blindspot treats agents as passive executors unable to adapt
their strategy based on internal cognitive states like uncertainty or
confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where
agents learn a decentralized policy over a set of high-level meta-cognitive
actions: Persist, Refine, and Concede. To overcome the instability of
traditional policy gradients in this setting, we develop SoftRankPO, a novel
reinforcement learning algorithm. SoftRankPO stabilizes training by shaping
advantages based on the rank of rewards mapped through smooth normal quantiles,
making the learning process robust to reward variance. Experiments show that
MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across
five mathematical and general reasoning benchmarks compared to six
state-of-the-art heuristic and learning-based multi-agent reasoning algorithms.
Our work presents a paradigm for learning adaptive, meta-cognitive policies for
multi-agent LLM systems, shifting the focus from designing fixed protocols to
learning dynamic, deliberative strategies.

</details>


### [16] [Psychologically Enhanced AI Agents](https://arxiv.org/abs/2509.04343)
*Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler*

Main category: cs.AI

TL;DR: 이 논문은 심리학적 성격 조건화를 통해 대형 언어 모델(LLM) 에이전트의 효율성을 향상시키는 MBTI-in-Thoughts 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 행동을 인간 심리학의 두 가지 기초 축인 인지 및 정서를 따라 제어하기 위해.

Method: 마이어스-브릭스 유형 지표(MBTI)에 따라 프롬프트 엔지니어링을 통해 에이전트를 뚜렷한 성격 원형으로 준비시킵니다.

Result: 감정적으로 표현력이 풍부한 에이전트는 내러티브 생성에서 뛰어나고, 분석적으로 준비된 에이전트는 게임 이론적 환경에서 더 안정적인 전략을 채택하는 등의 행동 편향을 보여줍니다.

Conclusion: 심리학 이론과 LLM 행동 설계를 연결하여, 파인튜닝 없이 심리적으로 향상된 AI 에이전트를 위한 기초를 설정합니다.

Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.

</details>


### [17] [PG-Agent: An Agent Powered by Page Graph](https://arxiv.org/abs/2509.03536)
*Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang*

Main category: cs.AI

TL;DR: 본 논문에서는 GUI 에이전트의 성능 향상을 위해 페이지 그래프를 활용하고 RAG 기술을 도입하여 새로운 시나리오에서도 일반화할 수 있도록 하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 고급 다중 모드 대형 언어 모델에 의해 구동되는 GUI 에이전트의 상업적 및 사회적 가치가 크고, 기존의 GUI 에이전트는 페이지 간의 복잡한 전환 관계를 캡처하지 못해 새로운 시나리오에 대한 일반화가 어렵기 때문입니다.

Method: 페이지 그래프를 구성하기 위해 순차 에피소드를 페이지 그래프로 변환하는 자동화된 파이프라인을 설계하고, GUI의 신뢰할 수 있는 인식 가이드를 효과적으로 검색하기 위해 RAG 기술을 도입하며, 맞춤형 다중 에이전트 프레임워크인 PG-Agent를 제안합니다.

Result: PG-Agent가 페이지 그래프 구성에 제한된 에피소드만으로도 효과적임을 보여주는 다양한 벤치마크에 대한 광범위한 실험을 수행했습니다.

Conclusion: 본 연구는 페이지 그래프와 RAG 기술을 통해 새로운 시나리오에서의 일반화를 가능하게 하며, GUI 에이전트의 성능을 크게 향상시킵니다.

Abstract: Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.

</details>


### [18] [Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method](https://arxiv.org/abs/2509.03550)
*Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang*

Main category: cs.AI

TL;DR: 본 연구는 공중 교통 관리에서의 효과적인 갈등 탐지 및 해결(CD&R)을 위한 새로운 프레임워크인 Diffusion-AC를 제안하며, 기존 방법들이 가진 단일 모드 정책의 한계를 극복합니다.


<details>
  <summary>Details</summary>
Motivation: 글로벌 항공 교통의 지속적인 증가 속에서 효율적이고 안전한 갈등 탐지 및 해결(CD&R)이 필수적입니다.

Method: 본 연구는 확산 확률 모델을 통합하여 새로운 자율 갈등 해결 프레임워크인 Diffusion-AC를 제안하며, 기존의 단일 최적해로 수렴하는 방법과 다르게 가치를 기준으로 한 역 노이즈 제거 과정을 통해 다중 모드의 행동 분포를 생성합니다.

Result: Diffusion-AC는 기존의 최첨단 DRL 기준들과 비교하여 성능이 크게 향상되었고, 고밀도 시나리오에서 94.1%의 높은 성공률을 유지하며, 근접 공중 충돌(NMAC)의 발생률을 약 59% 감소시켰습니다.

Conclusion: 이 연구는 효과적인 대체 기동으로 유연하게 전환할 수 있는 독특한 다중 모드 의사결정 능력 덕분에 시스템의 안전 여유를 크게 향상시켰습니다.

Abstract: In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.

</details>


### [19] [Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581)
*Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델(LLM)의 동적 계획 수립 능력을 향상시키기 위한 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 LLM 행동 계획 방식은 비효율적이며 긴 시간의 작업에서 성능을 저하시킨다.

Method: 우리는 LLM 에이전트를 위한 동적 계획 수립 기법을 형식화하는 개념적 프레임워크를 도입하고, 이를 통해 모델이 계획에 필요한 계산 자원을 유연하게 할당할 수 있도록 한다.

Result: Crafter 환경 실험을 통해, 제안한 방식으로 훈련된 동적 계획 에이전트가 더 효율적으로 샘플을 사용하고 복잡한 목표를 일관되게 달성함을 보여준다.

Conclusion: 이 연구는 순차적 의사결정 과제에서 LLM 에이전트의 동적 테스트 시간 계산 할당 훈련을 탐구한 최초의 사례로, 보다 효율적이고 적응 가능하며 제어 가능한 에이전트 시스템을 위한 길을 열어준다.

Abstract: Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.

</details>


### [20] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)의 능력이 인상적이어서 합성 에이전트가 인간 연구에서 실제 참여자를 대신할 수 있다는 주장이 제기되고 있다. 그러나 이 연구는 에이전트가 다른 실험 환경에서 유사한 행동을 유지하는지의 여부를 조사한다.


<details>
  <summary>Details</summary>
Motivation: 합성 에이전트가 인간 연구의 실제 참여자 대체 가능성을 평가하기 위하여

Method: 에이전트의 내부 상태를 드러내고 기본 대화 설정에서의 행동을 조사하는 연구 설계

Result: 모델 가족 및 크기에 따라 LLM에서 중요한 내부 불일치 발견

Conclusion: 에이전트는 인간 참여자와 유사한 응답을 생성할 수 있지만, 내부 일관성이 부족하여 인간 연구에서 실제 참여자를 정확하게 대체할 수 있는 중요한 격차가 있다.

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


### [21] [Leveraging LLM-Based Agents for Intelligent Supply Chain Planning](https://arxiv.org/abs/2509.03811)
*Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 이 연구는 공급망 계획 에이전트(SCPA) 프레임워크를 구축하여 JD.com의 실제 시나리오에서 공급망 문제를 해결하고, 노동력을 줄이며 정확성과 재고 가용성을 개선한 사례를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 공급망 관리에서 계획은 매우 중요한 개념이며, 다양한 카테고리에서 물리적 제품의 이동을 관리하는 것은 많은 엔티티가 필요합니다.

Method: SCPA 프레임워크를 구축하여 도메인 지식을 이해하고 운영자의 요구를 파악하며, 작업을 분해하고, 새로운 도구를 활용하거나 생성하여 증거 기반의 계획 보고서를 제공합니다.

Result: JD.com의 실제 시나리오에 프레임워크를 배포하여 LLM-agent의 적용 가능성을 보여주었고, 노동력을 효과적으로 줄이며 정확성 및 재고 가용성과 같은 주요 지표를 개선했습니다.

Conclusion: AI 기술의 발전은 실제 문제를 해결하기 위한 새로운 도구를 제공하며, 이 연구는 공급망에서 LLM-agent의 활용 가능성을 입증했습니다.

Abstract: In supply chain management, planning is a critical concept. The movement of
physical products across different categories, from suppliers to warehouse
management, to sales, and logistics transporting them to customers, entails the
involvement of many entities. It covers various aspects such as demand
forecasting, inventory management, sales operations, and replenishment. How to
collect relevant data from an e-commerce platform's perspective, formulate
long-term plans, and dynamically adjust them based on environmental changes,
while ensuring interpretability, efficiency, and reliability, is a practical
and challenging problem. In recent years, the development of AI technologies,
especially the rapid progress of large language models, has provided new tools
to address real-world issues. In this work, we construct a Supply Chain
Planning Agent (SCPA) framework that can understand domain knowledge,
comprehend the operator's needs, decompose tasks, leverage or create new tools,
and return evidence-based planning reports. We deploy this framework in
JD.com's real-world scenario, demonstrating the feasibility of LLM-agent
applications in the supply chain. It effectively reduced labor and improved
accuracy, stock availability, and other key metrics.

</details>


### [22] [What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models](https://arxiv.org/abs/2509.03827)
*Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich*

Main category: cs.AI

TL;DR: 본 논문은 대형 언어 모델(LLMs)이 노숙자 완화를 위한 사회 정책 결정에 어떻게 기여할 수 있는지를 평가하며, 네 가지 지리적 위치에 대한 정책 선택을 포함한 새로운 기준을 개발하였다.


<details>
  <summary>Details</summary>
Motivation: LLMs는 사회 정책 결정의 복잡성에 대한 새로운 통찰력을 제공할 수 있는 가능성을 가지고 있다.

Method: 노숙자 완화를 위한 결정 시나리오와 정책 선택을 포함하는 새로운 기준을 개발하고, 자동화된 파이프라인을 통해 기준화된 정책을 에이전트 기반 모델에 연결하였다.

Result: 노숙자 문제를 해결하기 위한 추천 정책의 사회적 영향을 시뮬레이션을 통해 탐구하였다.

Conclusion: 책임 있는 가이드라인과 맥락에 맞는 조정을 통해 LLMs는 대규모로 대안적 정책을 제공하며, 인간에게 귀중한 통찰력을 제공할 수 있다.

Abstract: Large language models (LLMs) are increasingly being adopted in high-stakes
domains. Their capacity to process vast amounts of unstructured data, explore
flexible scenarios, and handle a diversity of contextual factors can make them
uniquely suited to provide new insights for the complexity of social
policymaking. This article evaluates whether LLMs' are aligned with domain
experts (and among themselves) to inform social policymaking on the subject of
homelessness alleviation - a challenge affecting over 150 million people
worldwide. We develop a novel benchmark comprised of decision scenarios with
policy choices across four geographies (South Bend, USA; Barcelona, Spain;
Johannesburg, South Africa; Macau SAR, China). The policies in scope are
grounded in the conceptual framework of the Capability Approach for human
development. We also present an automated pipeline that connects the
benchmarked policies to an agent-based model, and we explore the social impact
of the recommended policies through simulated social scenarios. The paper
results reveal promising potential to leverage LLMs for social policy making.
If responsible guardrails and contextual calibrations are introduced in
collaboration with local domain experts, LLMs can provide humans with valuable
insights, in the form of alternative policies at scale.

</details>


### [23] [An Agentic Model Context Protocol Framework for Medical Concept Standardization](https://arxiv.org/abs/2509.03828)
*Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu*

Main category: cs.AI

TL;DR: OMOP CDM을 이용한 데이터 표준화의 중요한 단계인 의료 용어 매핑을 위해 제로 트레이닝, 환각 예방 매핑 시스템을 개발했습니다.


<details>
  <summary>Details</summary>
Motivation: OMOP CDM은 이질적인 건강 데이터를 표준화하여 대규모 연구를 지원하는 역할을 합니다.

Method: 우리는 Model Context Protocol을 기반으로 한 제로 트레이닝, 환각 예방 매핑 시스템을 개발했습니다.

Result: 이 시스템은 설명 가능한 매핑을 가능하게 하며 효율성과 정확성을 크게 향상시킵니다.

Conclusion: 이 시스템은 탐색 및 생산 환경에서 즉각 사용 가능한 실시간 어휘 조회와 구조화된 추론 결과를 제공합니다.

Abstract: The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)
provides a standardized representation of heterogeneous health data to support
large-scale, multi-institutional research. One critical step in data
standardization using OMOP CDM is the mapping of source medical terms to OMOP
standard concepts, a procedure that is resource-intensive and error-prone.
While large language models (LLMs) have the potential to facilitate this
process, their tendency toward hallucination makes them unsuitable for clinical
deployment without training and expert validation. Here, we developed a
zero-training, hallucination-preventive mapping system based on the Model
Context Protocol (MCP), a standardized and secure framework allowing LLMs to
interact with external resources and tools. The system enables explainable
mapping and significantly improves efficiency and accuracy with minimal effort.
It provides real-time vocabulary lookups and structured reasoning outputs
suitable for immediate use in both exploratory and production environments.

</details>


### [24] [A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai](https://arxiv.org/abs/2509.03830)
*Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng*

Main category: cs.AI

TL;DR: 역사적인 도시 지역은 문화유산을 보존하고 관광 및 일상 생활을 위한 활기찬 공간 역할을 한다. 이 연구는 사회적 미디어에서 다중 모드 데이터를 활용하여 관광객의 인식을 분석하는 AI 기반 다차원 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 관광객이 역사적인 도시 지역을 어떻게 인식하는지 이해하는 것은 지속 가능한 인간 중심의 도시 계획에 필수적이다.

Method: 이 프레임워크는 상하이 중앙의 12개 역사 지역에 적용되며, 중심점 추출, 색상 테마 분석 및 감정 채굴을 통합한다.

Result: 미적 매력과 정서적 반응에서 공간적 변화를 드러낸다.

Conclusion: 이 프레임워크는 관광 인식을 해독하기 위한 통합적이고 데이터 기반의 접근 방식을 제공하여 관광, 유산 보존 및 미적으로 매력적인 공공 공간 설계에서 정보에 기반한 의사 결정을 지원한다.

Abstract: Historic urban quarters play a vital role in preserving cultural heritage
while serving as vibrant spaces for tourism and everyday life. Understanding
how tourists perceive these environments is essential for sustainable,
human-centered urban planning. This study proposes a multidimensional
AI-powered framework for analyzing tourist perception in historic urban
quarters using multimodal data from social media. Applied to twelve historic
quarters in central Shanghai, the framework integrates focal point extraction,
color theme analysis, and sentiment mining. Visual focus areas are identified
from tourist-shared photos using a fine-tuned semantic segmentation model. To
assess aesthetic preferences, dominant colors are extracted using a clustering
method, and their spatial distribution across quarters is analyzed. Color
themes are further compared between social media photos and real-world street
views, revealing notable shifts. This divergence highlights potential gaps
between visual expectations and the built environment, reflecting both
stylistic preferences and perceptual bias. Tourist reviews are evaluated
through a hybrid sentiment analysis approach combining a rule-based method and
a multi-task BERT model. Satisfaction is assessed across four dimensions:
tourist activities, built environment, service facilities, and business
formats. The results reveal spatial variations in aesthetic appeal and
emotional response. Rather than focusing on a single technical innovation, this
framework offers an integrated, data-driven approach to decoding tourist
perception and contributes to informed decision-making in tourism, heritage
conservation, and the design of aesthetically engaging public spaces.

</details>


### [25] [Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata](https://arxiv.org/abs/2509.03863)
*Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas*

Main category: cs.AI

TL;DR: E&E라는 하이브리드 전략을 통해 새로운 탐색 방법을 제시하며, 인간 인식에 맞춘 세멘틱 공간을 활용해 다양하고 의미 있는 행동을 발견할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 연속 세포 자동자에서 다양한 시각 패턴을 발견하는 것은 고차원 행동 공간의 방대함과 중복성으로 인해 어려운 도전과제이다.

Method: E&E는 기존의 변별적인 탐색 방법인 Novelty Search를 보완하는 하이브리드 전략이다. 지역적으로 진화된 변별성을 바탕으로 목표 지향적인 탐험을 번갈아가며 진행한다.

Result: E&E는 Flow Lenia에서 기존 탐색 방법보다 더 다양한 솔루션을 지속적으로 발견하며, 탐험을 통해 다룬 패턴이 장기 탐색에 큰 영향을 미친다는 사실이 밝혀졌다.

Conclusion: E&E는 지역적 변별성의 한계를 극복하고 인간의 인식에 맞춘 탐색 방법을 제시함으로써 인공 생명체 및 그 이상에서 개방형 탐색을 위한 유망한 템플릿을 제공한다.

Abstract: Discovering diverse visual patterns in continuous cellular automata (CA) is
challenging due to the vastness and redundancy of high-dimensional behavioral
spaces. Traditional exploration methods like Novelty Search (NS) expand locally
by mutating known novel solutions but often plateau when local novelty is
exhausted, failing to reach distant, unexplored regions. We introduce
Expedition and Expansion (E&E), a hybrid strategy where exploration alternates
between local novelty-driven expansions and goal-directed expeditions. During
expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic
goals--descriptions of interesting but hypothetical patterns that drive
exploration toward uncharted regions. By operating in semantic spaces that
align with human perception, E&E both evaluates novelty and generates goals in
conceptually meaningful ways, enhancing the interpretability and relevance of
discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,
emergent behaviors, E&E consistently uncovers more diverse solutions than
existing exploration methods. A genealogical analysis further reveals that
solutions originating from expeditions disproportionately influence long-term
exploration, unlocking new behavioral niches that serve as stepping stones for
subsequent search. These findings highlight E&E's capacity to break through
local novelty boundaries and explore behavioral landscapes in human-aligned,
interpretable ways, offering a promising template for open-ended exploration in
artificial life and beyond.

</details>


### [26] [FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace](https://arxiv.org/abs/2509.03890)
*Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li*

Main category: cs.AI

TL;DR: 본 논문은 LLM 기반 에이전틱 AI를 활용하여 C2C 전자상거래 플랫폼에서 사용자 인터랙션을 간소화하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI의 출현은 복잡한 디지털 환경에서의 오랜 과제를 해결할 수 있는 기회를 제공합니다.

Method: LLM 기반 에이전틱 어시스턴트를 통해 사용자와의 대화형 인터페이스를 구현하고, 자연어 명령을 해석하여 주요 워크플로우를 자동화합니다.

Result: FaMA는 시장의 복잡한 작업을 해결하는 데 98%의 작업 성공률을 달성하고 인터랙션 시간을 최대 2배 단축합니다.

Conclusion: 이 에이전틱 대화형 패러다임은 전통적인 앱 인터페이스에 비해 가벼우면서도 접근성이 높은 대안을 제공합니다.

Abstract: The emergence of agentic AI, powered by Large Language Models (LLMs), marks a
paradigm shift from reactive generative systems to proactive, goal-oriented
autonomous agents capable of sophisticated planning, memory, and tool use. This
evolution presents a novel opportunity to address long-standing challenges in
complex digital environments. Core tasks on Consumer-to-Consumer (C2C)
e-commerce platforms often require users to navigate complex Graphical User
Interfaces (GUIs), making the experience time-consuming for both buyers and
sellers. This paper introduces a novel approach to simplify these interactions
through an LLM-powered agentic assistant. This agent functions as a new,
conversational entry point to the marketplace, shifting the primary interaction
model from a complex GUI to an intuitive AI agent. By interpreting natural
language commands, the agent automates key high-friction workflows. For
sellers, this includes simplified updating and renewal of listings, and the
ability to send bulk messages. For buyers, the agent facilitates a more
efficient product discovery process through conversational search. We present
the architecture for Facebook Marketplace Assistant (FaMA), arguing that this
agentic, conversational paradigm provides a lightweight and more accessible
alternative to traditional app interfaces, allowing users to manage their
marketplace activities with greater efficiency. Experiments show FaMA achieves
a 98% task success rate on solving complex tasks on the marketplace and enables
up to a 2x speedup on interaction time.

</details>


### [27] [A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning](https://arxiv.org/abs/2509.03906)
*Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng*

Main category: cs.AI

TL;DR: DeepMedix-R1은 흉부 X선 이미지를 해석하기 위한 전체론적 의료 기초 모델로, 투명한 추론 과정과 지역적으로 grounded 해석 가능성을 제공하여 임상적 활용을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 의료 기초 모델이 임상에서의 실제 활용을 방해하는 흑상자 방식의 질문 응답을 해결하기 위해.

Method: DeepMedix-R1은 순차적인 훈련 파이프라인을 통해 초기에는 선택된 CXR 지침 데이터로 미세 조정하고, 고품질의 합성 추론 샘플에 노출되며, 마지막으로 온라인 강화 학습을 통해 향상되는 방식이다.

Result: 정량적 평가에서 보고서 생성 및 시각적 질문 응답 작업에서 현저한 개선이 나타났다.

Conclusion: 이 연구는 CXR 해석을 위한 전체론적이고 투명하며 임상적으로 실행 가능한 모델링으로 의료 기초 모델 개발을 발전시킨다.

Abstract: Medical foundation models (FMs) have shown tremendous promise amid the rapid
advancements in artificial intelligence (AI) technologies. However, current
medical FMs typically generate answers in a black-box manner, lacking
transparent reasoning processes and locally grounded interpretability, which
hinders their practical clinical deployments. To this end, we introduce
DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It
leverages a sequential training pipeline: initially fine-tuned on curated CXR
instruction data to equip with fundamental CXR interpretation capabilities,
then exposed to high-quality synthetic reasoning samples to enable cold-start
reasoning, and finally refined via online reinforcement learning to enhance
both grounded reasoning quality and generation performance. Thus, the model
produces both an answer and reasoning steps tied to the image's local regions
for each query. Quantitative evaluation demonstrates substantial improvements
in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and
visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)
tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking
framework using advanced language models to evaluate answer quality, further
highlighting the superiority of DeepMedix-R1. Expert review of generated
reasoning steps reveals greater interpretability and clinical plausibility
compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall
preference). Collectively, our work advances medical FM development toward
holistic, transparent, and clinically actionable modeling for CXR
interpretation.

</details>


### [28] [Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes](https://arxiv.org/abs/2509.04317)
*Isidoro Tamassia,Wendelin Böhmer*

Main category: cs.AI

TL;DR: AlphaZero 프레임워크를 변형하여 변화된 테스트 환경에서의 성능을 향상시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: AlphaZero가 테스트 시 환경이 변하지 않을 것이라고 가정하여 적용 가능성이 제한됨.

Method: 표준 프레임워크에 간단한 수정을 추가하여 AlphaZero 에이전트를 새로운 테스트 환경에 배치하는 문제를 분석.

Result: 수정된 프레임워크가 낮은 계획 예산에서도 성능을 크게 향상시킴을 입증.

Conclusion: 이 연구는 AlphaZero 에이전트의 배치 가능성을 확장할 수 있는 방법을 제안한다.

Abstract: The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standard framework can significantly
boost performance, even in settings with a low planning budget available. The
code is publicly available on GitHub.

</details>


### [29] [World Model Implanting for Test-time Adaptation of Embodied Agents](https://arxiv.org/abs/2509.03956)
*Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo*

Main category: cs.AI

TL;DR: 이 논문은 체화된 AI에서 에이전트가 새로운 도메인에 신뢰성 있게 적응할 수 있도록 하는 WorMI 프레임워크를 제안하며, 이를 통해 도메인 특화된 세계 모델을 조합하여 효율적인 적응성을 구현한다.


<details>
  <summary>Details</summary>
Motivation: 체화된 AI에서는 에이전트가 새로운 도메인에 적응할 때 광범위한 데이터 수집이나 재훈련을 요구하지 않도록 하는 것이 지속적인 과제다.

Method: WorMI 프레임워크는 대형 언어 모델(LLMs)의 추론 능력과 독립적으로 학습된 도메인 특화 세계 모델을 테스트 시간 조합을 통해 결합하는 방법을 제시한다.

Result: WorMI는 VirtualHome 및 ALFWorld 벤치마크에서 여러 LLM 기반 접근 방식에 비해 우수한 제로샷 및 몇 샷 성능을 입증했다.

Conclusion: 이 프레임워크는 적응성과 데이터 효율성이 중요한 체화된 에이전트 시나리오에서 더 큰 확장 가능성을 제공한다.

Abstract: In embodied AI, a persistent challenge is enabling agents to robustly adapt
to novel domains without requiring extensive data collection or retraining. To
address this, we present a world model implanting framework (WorMI) that
combines the reasoning capabilities of large language models (LLMs) with
independently learned, domain-specific world models through test-time
composition. By allowing seamless implantation and removal of the world models,
the embodied agent's policy achieves and maintains cross-domain adaptability.
In the WorMI framework, we employ a prototype-based world model retrieval
approach, utilizing efficient trajectory-based abstract representation
matching, to incorporate relevant models into test-time composition. We also
develop a world-wise compound attention method that not only integrates the
knowledge from the retrieved world models but also aligns their intermediate
representations with the reasoning model's representation within the agent's
policy. This framework design effectively fuses domain-specific knowledge from
multiple world models, ensuring robust adaptation to unseen domains. We
evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating
superior zero-shot and few-shot performance compared to several LLM-based
approaches across a range of unseen domains. These results highlight the
frameworks potential for scalable, real-world deployment in embodied agent
scenarios where adaptability and data efficiency are essential.

</details>


### [30] [ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439)
*Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: 이 연구는 LLM의 추론 시간 스케일링을 통해 더 긴 추론 패턴을 사용할 수 있게 하면서, 외부 메모리를 활용해 이 발견을 지속 가능하게 만드는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 수행하는 추론 시간이 길어짐에 따라 발견된 패턴과 통찰은 새로운 쿼리에 대한 컨텍스트 윈도우가 재설정되면 즉시 버려집니다. 따라서 외부 메모리를 사용하여 이러한 발견을 지속할 기회가 있다고 봅니다.

Method: 인스턴스 기반 메모리 항목을 넘어 개념 수준의 메모리로 전환하여 재사용 가능하고 모듈화된 추상화를 자연어로 저장합니다. 미래의 쿼리를 위해 관련 개념을 선택적으로 검색하고 프롬프트에 통합하여 무게 업데이트 없이 지속적인 학습을 가능하게 합니다.

Result: ARC-AGI 벤치마크에서 우리의 방법은 강력한 메모리 없음 기준선에 대해 7.5%의 상대적 이득을 제공합니다. 또한, 동적으로 메모리를 업데이트하는 것이 고정 메모리 설정과 비교해 더 많은 문제 해결과 추상화를 지원함으로써 추가적인 해결책을 제공함을 확인했습니다.

Conclusion: 추상 개념이 가장 일관된 메모리 디자인으로 입증되며, 모든 테스트된 추론 컴퓨트 스케일에서 기준선을 능가하였습니다. 추가 시도와 함께 테스트 시간 중 메모리를 동적으로 업데이트하는 것이 동등한 고정 메모리 설정보다 더 나은 성능을 보였습니다.

Abstract: While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.

</details>


### [31] [Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent](https://arxiv.org/abs/2509.03990)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: 이 논문에서는 LLM 에이전트의 성능을 향상시키기 위해 Meta-Policy Reflexion(MPR)이라는 하이브리드 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델이 단일 작업에서 인상적인 성능을 보이지만, 반복적인 실패, 비효율적인 탐색 및 제한된 교차 작업 적응력을 나타내는 문제를 해결하고자 한다.

Method: MPR은 LLM이 생성한 반사(reflections)를 구조화된 메타 정책 메모리(MPM)로 통합하고, 소프트 메모리 유도 디코딩 및 하드 규칙 허용성 체크(HAC)라는 두 가지 보완적 메커니즘을 사용하여 추론 시 이 메모리를 적용한다.

Result: 실험 결과, MPR은 Reflexion 기준선과 비교하여 실행 정확도와 강인성을 일관되게 향상시켰으며, 규칙 허용성 체크가 추가적인 안정성을 개선한다.

Conclusion: 이 연구는 MPR이 올바른 지식을 외부화하고 도메인 제약을 집행하며 언어 기반 반사의 적응성을 유지한다는 것을 보여준다.

Abstract: Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we introduce Meta-Policy Reflexion
(MPR): a hybrid framework that consolidates LLM-generated reflections into a
structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at
inference time through two complementary mechanisms soft memory-guided decoding
and hard rule admissibility checks(HAC). MPR (i) externalizes reusable
corrective knowledge without model weight updates, (ii) enforces domain
constraints to reduce unsafe or invalid actions, and (iii) retains the
adaptability of language-based reflection. We formalize the MPM representation,
present algorithms for update and decoding, and validate the approach in a
text-based agent environment following the experimental protocol described in
the provided implementation (AlfWorld-based). Empirical results reported in the
supplied material indicate consistent gains in execution accuracy and
robustness when compared to Reflexion baselines; rule admissibility further
improves stability. We analyze mechanisms that explain these gains, discuss
scalability and failure modes, and outline future directions for multimodal and
multi?agent extensions.

</details>


### [32] [CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.04027)
*Zeyu Gan,Hao Yi,Yong Liu*

Main category: cs.AI

TL;DR: 본 연구에서는 CoT-Space라는 새로운 이론적 프레임워크를 소개하여, 기존의 토큰 수준 강화 학습 방법들이 가진 문제를 해결하고 대규모 언어 모델의 추론 능력을 향상시키기 위한 최적화 과정을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 추론 능력을 향상시키기 위해 새로운 프레임워크가 필요하다.

Method: CoT-Space라는 새로운 이론적 프레임워크를 도입하여 LLM의 추론 과정을 연속적인 의미 공간에서의 최적화 과정으로 재구성한다.

Result: 실험을 통해 기존 이론적 발견의 강력한 경험적 검증을 제공한다.

Conclusion: 이 프레임워크는 과도한 사고와 같은 경험적 현상을 설명하고, 더 효과적이고 일반화 가능한 추론 에이전트를 개발하기 위한 이론적 토대를 제공한다.

Abstract: Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.

</details>


### [33] [Hybrid Reinforcement Learning and Search for Flight Trajectory Planning](https://arxiv.org/abs/2509.04100)
*Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch*

Main category: cs.AI

TL;DR: 강화 학습과 탐색 기반 경로 계획자를 결합하여 항공기의 비상 시 경로 재계산을 빠르게 수행하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 비상 상황에서 항공기의 비행 경로를 빠르게 재계산하는 것이 중요하다.

Method: RL 에이전트를 훈련시켜 위치 및 대기 데이터에 기반한 준최적 경로를 사전 계산하고, 이를 이용해 경로 계획 솔버의 검색 공간을 제약하는 방법을 사용한다.

Result: 경로 최적화 속도를 상당히 향상시키며, 연료 소비는 제한이 없는 솔버와 거의 동일하게 유지된다. 연료 소비 차이는 일반적으로 1% 이내이다.

Conclusion: 기존의 솔버 단독 사용보다 최대 50%의 계산 속도 개선이 이루어진다.

Abstract: This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The approach effectively
reduces the size of the solver's search space, significantly speeding up route
optimization. Although global optimality is not guaranteed, empirical results
conducted with Airbus aircraft's performance models show that fuel consumption
remains nearly identical to that of an unconstrained solver, with deviations
typically within 1%. At the same time, computation speed can be improved by up
to 50% as compared to using a conventional solver alone.

</details>


### [34] [Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker](https://arxiv.org/abs/2509.04125)
*Tarik Zaciragic,Aske Plaat,K. Joost Batenburg*

Main category: cs.AI

TL;DR: 이 논문은 DQN과 CFR 알고리즘이 Leduc Hold'em에서 블러핑 행동을 보이는지를 연구한다.


<details>
  <summary>Details</summary>
Motivation: 컴퓨터 포커 연구에서 승률과 같은 성과 지표에 주로 집중되지만, 블러핑은 간과되고 있다.

Method: DQN과 CFR 에이전트를 서로 대결하게 하여 그들의 행동을 기록하는 실험을 설계했다.

Result: DQN과 CFR 모두 블러핑 행동을 보였지만, 그 방식은 달랐다. 두 알고리즘 모두 서로 다른 비율로 블러핑을 시도하지만, 성공적인 블러핑 비율은 대체로 동일했다.

Conclusion: 블러핑은 게임의 본질적인 측면이며 알고리즘의 특성이 아니다. 향후 연구는 다양한 블러핑 스타일과 포커 전체에 대해 살펴봐야 한다.

Abstract: In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play against each other while
we log their actions. We find that both DQN and CFR exhibit bluffing behavior,
but they do so in different ways. Although both attempt to perform bluffs at
different rates, the percentage of successful bluffs (where the opponent folds)
is roughly the same. This suggests that bluffing is an essential aspect of the
game, not of the algorithm. Future work should look at different bluffing
styles and at the full game of poker. Code at
https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.

</details>


### [35] [The human biological advantage over AI](https://arxiv.org/abs/2509.04130)
*William Stewart*

Main category: cs.AI

TL;DR: 인공지능의 발전이 인간을 초월할 가능성을 제기하지만, 인간과 AI의 근본적인 차이는 뇌가 아닌 중앙신경계(CNS)라는 점을 강조한다.


<details>
  <summary>Details</summary>
Motivation: 인공지능이 인간을 초월해 우주를 이끌 수 있는지에 대한 질문을 제기한다.

Method: AI와 인간의 차이를 분석하고, CNS의 중요성을 논의한다.

Result: AI는 인간보다 더 능력있고 사회를 변화시킬 수 있지만, 진정한 리더십은 생물학적 구성을 가진 CNS에서 온다.

Conclusion: AI 시스템이 인간보다 우월해지기 위해서는 단순한 의식 발달만으로는 불충분하며, DNA가 항상 진정한 리더십의 기초가 될 것이다.

Abstract: Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor "digital species", with a rightful claim to assume leadership of
the universe. However, a deeper consideration suggests the overlooked
differentiator between human beings and AI is not the brain, but the central
nervous system (CNS), providing us with an immersive integration with physical
reality. It is our CNS that enables us to experience emotion including pain,
joy, suffering, and love, and therefore to fully appreciate the consequences of
our actions on the world around us. And that emotional understanding of the
consequences of our actions is what is required to be able to develop
sustainable ethical systems, and so be fully qualified to be the leaders of the
universe. A CNS cannot be manufactured or simulated; it must be grown as a
biological construct. And so, even the development of consciousness will not be
sufficient to make AI systems superior to humans. AI systems may become more
capable than humans on almost every measure and transform our society. However,
the best foundation for leadership of our universe will always be DNA, not
silicon.

</details>


### [36] [Evaluating Quality of Gaming Narratives Co-created with AI](https://arxiv.org/abs/2509.04239)
*Arturo Valdivia,Paolo Burelli*

Main category: cs.AI

TL;DR: AI 생성 게임 내러티브 평가를 위한 구조화된 방법론을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 게임 내러티브의 품질 문제를 해결하고, AI와의 협업을 통해 게임 개발자에게 유용한 인사이트를 제공하기 위해서입니다.

Method: 델파이 연구 구조를 바탕으로 내러티브 디자인 전문가 패널을 활용하여 이야기 품질 차원을 합성하고, 이를 카노 모델 프레임워크에 매핑했습니다.

Result: 이 접근 방식은 플레이어 만족도에 미치는 이야깃감의 영향을 이해하는 데 기여합니다.

Conclusion: 게임 내러티브를 공동 생성할 때 품질 측면의 우선 순위를 정하는 데 도움을 줄 수 있습니다.

Abstract: This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.

</details>


### [37] [EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation](https://arxiv.org/abs/2509.04310)
*Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: EvoEmo는 감정 표현을 최적화하는 진화적 강화 학습 프레임워크로, 다양한 협상 시나리오에서 높은 보상 감정 정책을 진화시켜 LLM 에이전트의 다중 턴 협상 능력을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 현재 LLM 에이전트는 협상에서 감정의 기능적 역할을 간과하고, 이는 조작과 전략적 착취에 취약하도록 만든다.

Method: EvoEmo는 감정 상태 변화를 마르코프 결정 프로세스로 모델링하고, 인구 기반 유전자 최적화를 사용하여 다양한 협상 시나리오에서 높은 보상 감정 정책을 발전시킨다.

Result: EvoEmo는 실험을 통해 두 개의 기준선인 일반 전략과 고정 감정 전략을 능가하여 성공률, 효율성, 구매자 절감액에서 높은 성과를 보여준다.

Conclusion: 적응형 감정 표현은 LLM 에이전트가 다중 턴 협상에서 더 효과적일 수 있게 한다는 점에서 중요성을 강조한다.

Abstract: Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, we present EvoEmo, an
evolutionary reinforcement learning framework that optimizes dynamic emotional
expression in negotiations. EvoEmo models emotional state transitions as a
Markov Decision Process and employs population-based genetic optimization to
evolve high-reward emotion policies across diverse negotiation scenarios. We
further propose an evaluation framework with two baselines -- vanilla
strategies and fixed-emotion strategies -- for benchmarking emotion-aware
negotiation. Extensive experiments and ablation studies show that EvoEmo
consistently outperforms both baselines, achieving higher success rates, higher
efficiency, and increased buyer savings. This findings highlight the importance
of adaptive emotional expression in enabling more effective LLM agents for
multi-turn negotiation.

</details>
