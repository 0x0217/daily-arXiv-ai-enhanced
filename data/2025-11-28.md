<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 5]
- [cs.AI](#cs.AI) [Total: 14]
- [cs.LG](#cs.LG) [Total: 19]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Securing the Model Context Protocol (MCP): Risks, Controls, and Governance](https://arxiv.org/abs/2511.20920)
*Herman Errico,Jiquan Ngiam,Shanita Sojan*

Main category: cs.CR

TL;DR: MCP가 동적 사용자 주도 에이전트 시스템으로 API 통합을 대체하면서 새로운 보안 리스크가 발생함.


<details>
  <summary>Details</summary>
Motivation: MCP의 채택이 증가함에 따라 기존의 AI 거버넌스 프레임워크가 다루지 않는 위협에 직면하고 있다.

Method: 세 가지 유형의 적대자 분석과 함께 데이터 기반 정보 유출, 도구 중독, 권한 상승을 통한 MCP의 공격 표면 증가 설명.

Result: MCP의 유연성을 악용하는 공격자의 유형과 초기 사건 및 개념 증명 공격을 통해 MCP의 보안 문제를 설명.

Conclusion: MCP 사용 시에 불법 코드가 샌드박스 밖에서 실행되지 않도록 하는 실용적인 제어 방안 제안 및 연구 질문 제시.

Abstract: The Model Context Protocol (MCP) replaces static, developer-controlled API integrations with more dynamic, user-driven agent systems, which also introduces new security risks. As MCP adoption grows across community servers and major platforms, organizations encounter threats that existing AI governance frameworks (such as NIST AI RMF and ISO/IEC 42001) do not yet cover in detail. We focus on three types of adversaries that take advantage of MCP s flexibility: content-injection attackers that embed malicious instructions into otherwise legitimate data; supply-chain attackers who distribute compromised servers; and agents who become unintentional adversaries by over-stepping their role. Based on early incidents and proof-of-concept attacks, we describe how MCP can increase the attack surface through data-driven exfiltration, tool poisoning, and cross-system privilege escalation. In response, we propose a set of practical controls, including per-user authentication with scoped authorization, provenance tracking across agent workflows, containerized sandboxing with input/output checks, inline policy enforcement with DLP and anomaly detection, and centralized governance using private registries or gateway layers. The aim is to help organizations ensure that unvetted code does not run outside a sandbox, tools are not used beyond their intended scope, data exfiltration attempts are detectable, and actions can be audited end-to-end. We close by outlining open research questions around verifiable registries, formal methods for these dynamic systems, and privacy-preserving agent operations.

</details>


### [2] [CAHS-Attack: CLIP-Aware Heuristic Search Attack Method for Stable Diffusion](https://arxiv.org/abs/2511.21180)
*Shuhan Xia,Jing Dai,Hui Ouyang,Yadong Shang,Dongxiao Zhao,Peipei Li*

Main category: cs.CR

TL;DR: CAHS-Attack은 SD 모델의 취약성을 해결하기 위한 CLIP-Aware Heuristic Search 공격 방법이다.


<details>
  <summary>Details</summary>
Motivation: 적대적 프롬프트에 대한 확산 모델의 취약성을 발견하고 더 강력한 생성 시스템을 구축하는 것이 중요하다.

Method: CAHS-Attack은 몬테 카를로 트리 탐색(MCTS)을 통합하여 세밀한 접미사 최적화를 수행하고, 제약된 유전자 알고리즘을 통해 높은 잠재력을 가진 적대적 프롬프트를 루트 노드로 미리 선택한다.

Result: 광범위한 실험을 통해 CAHS-Attack이 다양한 의미의 짧고 긴 프롬프트에 대해 최첨단 공격 성능을 달성함을 입증하였다.

Conclusion: SD 모델의 취약성은 CLIP 기반 텍스트 인코더의 본질적인 취약성에서 기인하며, 이는 현재 텍스트-이미지 파이프라인의 기본적인 보안 위험을 시사한다.

Abstract: Diffusion models exhibit notable fragility when faced with adversarial prompts, and strengthening attack capabilities is crucial for uncovering such vulnerabilities and building more robust generative systems. Existing works often rely on white-box access to model gradients or hand-crafted prompt engineering, which is infeasible in real-world deployments due to restricted access or poor attack effect. In this paper, we propose CAHS-Attack , a CLIP-Aware Heuristic Search attack method. CAHS-Attack integrates Monte Carlo Tree Search (MCTS) to perform fine-grained suffix optimization, leveraging a constrained genetic algorithm to preselect high-potential adversarial prompts as root nodes, and retaining the most semantically disruptive outcome at each simulation rollout for efficient local search. Extensive experiments demonstrate that our method achieves state-of-the-art attack performance across both short and long prompts of varying semantics. Furthermore, we find that the fragility of SD models can be attributed to the inherent vulnerability of their CLIP-based text encoders, suggesting a fundamental security risk in current text-to-image pipelines.

</details>


### [3] [Data Exfiltration by Compression Attack: Definition and Evaluation on Medical Image Data](https://arxiv.org/abs/2511.21227)
*Huiyu Li,Nicholas Ayache,Hervé Delingette*

Main category: cs.CR

TL;DR: 이 논문은 데이터 레이크에서 머신러닝 모델을 내보내는 것의 안전성에 대한 우려와 의료 이미징 데이터의 맥락에서 새로운 데이터 유출 공격 기법을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 헬스 데이터 저장 및 AI 알고리즘 호스팅을 위한 데이터 레이크의 급속한 확장으로 인해 머신러닝 모델을 내보내는 것의 안전성에 대한 우려가 제기된다.

Method: 의료 이미징 데이터의 문맥에서 이미지 압축 기법에 기반한 데이터 유출 공격을 소개한다.

Result: 이 공격은 의료 이미지를 효과적으로 탈취하고 데이터 레이크 외부에서 고충실도로 재구성할 수 있음을 보여준다.

Conclusion: 기본적인 차등 프라이버시 조치를 통해 데이터 유출 공격을 방지하는 방법과 모델을 내보내기 위해 조정하는 대체 예방 전략을 제안한다.

Abstract: With the rapid expansion of data lakes storing health data and hosting AI algorithms, a prominent concern arises: how safe is it to export machine learning models from these data lakes? In particular, deep network models, widely used for health data processing, encode information from their training dataset, potentially leading to the leakage of sensitive information upon its export. This paper thoroughly examines this issue in the context of medical imaging data and introduces a novel data exfiltration attack based on image compression techniques.
  This attack, termed Data Exfiltration by Compression, requires only access to a data lake and is based on lossless or lossy image compression methods. Unlike previous data exfiltration attacks, it is compatible with any image processing task and depends solely on an exported network model without requiring any additional information to be collected during the training process. We explore various scenarios, and techniques to limit the size of the exported model and conceal the compression codes within the network.
  Using two public datasets of CT and MR images, we demonstrate that this attack can effectively steal medical images and reconstruct them outside the data lake with high fidelity, achieving an optimal balance between compression and reconstruction quality. Additionally, we investigate the impact of basic differential privacy measures, such as adding Gaussian noise to the model parameters, to prevent the Data Exfiltration by Compression Attack. We also show how the attacker can make their attack resilient to differential privacy at the expense of decreasing the number of stolen images. Lastly, we propose an alternative prevention strategy by fine-tuning the model to be exported.

</details>


### [4] [Constructing and Benchmarking: a Labeled Email Dataset for Text-Based Phishing and Spam Detection Framework](https://arxiv.org/abs/2511.21448)
*Rebeka Toth,Tamas Bisztray,Richard Dubniczky*

Main category: cs.CR

TL;DR: 본 연구는 피싱 및 스팸 이메일의 탐지를 위한 데이터셋과 평가 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 피싱 및 스팸 이메일이 주요 사이버 보안 위협이며, 공격자들이 LLM을 사용해 매우 기만적인 콘텐츠를 생성하고 있다.

Method: 피싱, 스팸, 합법적인 메시지로 구성된 이메일 데이터셋을 만들고, 각 이메일을 카테고리, 감정적 호소, 동기로 주석을 달았다. 여러 LLM의 감정 및 동기 신호 식별 능력을 벤치마킹하고, 원래 및 재구성된 이메일에서의 성능을 평가했다.

Result: 피싱 탐지 능력이 뛰어난 것으로 나타났지만, 스팸과 합법적인 이메일을 구분하는 데 지속적인 어려움이 있음을 보여준다.

Conclusion: 우리가 제시한 데이터셋과 평가 프레임워크는 AI-assist 이메일 보안 시스템 개선에 기여하며, 모든 코드 및 리소스는 프로젝트 사이트에서 공개된다.

Abstract: Phishing and spam emails remain a major cybersecurity threat, with attackers increasingly leveraging Large Language Models (LLMs) to craft highly deceptive content. This study presents a comprehensive email dataset containing phishing, spam, and legitimate messages, explicitly distinguishing between human- and LLM-generated content. Each email is annotated with its category, emotional appeal (e.g., urgency, fear, authority), and underlying motivation (e.g., link-following, credential theft, financial fraud). We benchmark multiple LLMs on their ability to identify these emotional and motivational cues and select the most reliable model to annotate the full dataset. To evaluate classification robustness, emails were also rephrased using several LLMs while preserving meaning and intent. A state-of-the-art LLM was then assessed on its performance across both original and rephrased emails using expert-labeled ground truth. The results highlight strong phishing detection capabilities but reveal persistent challenges in distinguishing spam from legitimate emails. Our dataset and evaluation framework contribute to improving AI-assisted email security systems. To support open science, all code, templates, and resources are available on our project site.

</details>


### [5] [TAB-DRW: A DFT-based Robust Watermark for Generative Tabular Data](https://arxiv.org/abs/2511.21600)
*Yizhou Zhao,Xiang Li,Peter Song,Qi Long,Weijie Su*

Main category: cs.CR

TL;DR: TAB-DRW는 생성된 표 데이터에 대한 효율적이고 강력한 후처리 워터마킹 체계로, 데이터의 추적 가능성을 보장하여 잘못된 데이터 사용에 대한 우려를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 생성적 AI의 발전은 고품질 합성 표 데이터의 생산을 가능하게 했지만, 데이터 출처와 악용에 대한 우려가 커지고 있다.

Method: TAB-DRW는 주파수 영역에 워터마크 신호를 삽입하며, Yeo-Johnson 변환 및 표준화를 통해 이질적인 특성을 정규화하고, 이산 푸리에 변환(DFT)을 적용하며, 미리 계산된 의사 랜덤 비트에 따라 선택된 항목의 허수 부분을 조정한다.

Result: TAB-DRW는 다섯 개의 벤치마크 표 데이터셋에서 강력한 탐지 가능성과 일반적인 후처리 공격에 대한 내구성을 보여준다.

Conclusion: TAB-DRW는 높은 데이터 충실도를 유지하면서 혼합형 특성을 완전 지원한다.

Abstract: The rise of generative AI has enabled the production of high-fidelity synthetic tabular data across fields such as healthcare, finance, and public policy, raising growing concerns about data provenance and misuse. Watermarking offers a promising solution to address these concerns by ensuring the traceability of synthetic data, but existing methods face many limitations: they are computationally expensive due to reliance on large diffusion models, struggle with mixed discrete-continuous data, or lack robustness to post-modifications. To address them, we propose TAB-DRW, an efficient and robust post-editing watermarking scheme for generative tabular data. TAB-DRW embeds watermark signals in the frequency domain: it normalizes heterogeneous features via the Yeo-Johnson transformation and standardization, applies the discrete Fourier transform (DFT), and adjusts the imaginary parts of adaptively selected entries according to precomputed pseudorandom bits. To further enhance robustness and efficiency, we introduce a novel rank-based pseudorandom bit generation method that enables row-wise retrieval without incurring storage overhead. Experiments on five benchmark tabular datasets show that TAB-DRW achieves strong detectability and robustness against common post-processing attacks, while preserving high data fidelity and fully supporting mixed-type features.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators](https://arxiv.org/abs/2511.20693)
*Mingming Zhao,Xiaokang Wei,Yuanqi Shao,Kaiwen Zhou,Lin Yang,Siwei Rao,Junhui Zhan,Zhitang Chen*

Main category: cs.AI

TL;DR: $A^2Flow$는 자가 적응 추상화 연산자를 기반으로 하는 완전 자동화된 에이전트 워크플로 생성 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 워크플로 디자인에서의 자동화 잠재력을 극대화하고, 수동으로 정의된 연산자에 대한 의존성을 줄이기 위해.

Method: $A^2Flow$는 세 단계의 연산자 추출 프로세스를 사용한다: 초기 연산자 생성, 연산자 클러스터링 및 초기 추상화, 추상 실행 연산자에 대한 심화 추출.

Result: $A^2Flow$는 평균 2.4%와 19.3%의 성능 향상과 37%의 자원 사용 감소를 보였다.

Conclusion: $A^2Flow$는 자동화된 에이전트 워크플로 생성을 위한 효과적이고 확장 가능한 솔루션을 제공한다.

Abstract: Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\% and 19.3\% average performance improvement and reduces resource usage by 37\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW

</details>


### [7] [AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI](https://arxiv.org/abs/2511.20686)
*Chae-Gyun Lim,Seung-Ho Han,EunYoung Byun,Jeongyun Han,Soohyun Cho,Eojin Joo,Heehyeon Kim,Sieun Kim,Juhoon Lee,Hyunsoo Lee,Dongkun Lee,Jonghwan Hyeon,Yechan Hwang,Young-Jun Lee,Kyeongryul Lee,Minhyeong An,Hyunjun Ahn,Jeongwoo Son,Junho Park,Donggyu Yoon,Taehyung Kim,Jeemin Kim,Dasom Choi,Kwangyoung Lee,Hyunseung Lim,Yeohyun Jung,Jongok Hong,Sooyohn Nam,Joonyoung Park,Sungmin Na,Yubin Choi,Jeanne Choi,Yoojin Hong,Sueun Jang,Youngseok Seo,Somin Park,Seoungung Jo,Wonhye Chae,Yeeun Jo,Eunyoung Kim,Joyce Jiyoung Whang,HwaJung Hong,Joseph Seering,Uichin Lee,Juho Kim,Sunna Choi,Seokyeon Ko,Taeho Kim,Kyunghoon Kim,Myungsik Ha,So Jung Lee,Jemin Hwang,JoonHo Kwak,Ho-Jin Choi*

Main category: cs.AI

TL;DR: Generative AI의 안전성 평가를 위한 한국어 다중 모달 데이터셋 AssurAI를 소개한다.


<details>
  <summary>Details</summary>
Motivation: Generative AI의 빠른 발전으로 Robust한 안전성 평가가 필요하며, 현재 안전성 데이터셋은 주로 영어 중심으로 비영어권 사회문화적 맥락의 위험을 포착하지 못하고 있다.

Method: 35개의 고유 AI 위험 요소의 분류법을 정의하고, 이를 바탕으로 텍스트, 이미지, 비디오, 오디오를 포함한 11,480개의 사례로 구성된 한국어 다중 모달 데이터셋 AssurAI를 구축하였다. 또한, 데이터 무결성을 보장하기 위한 철저한 품질 관리 프로세스를 적용하였다.

Result: AssurAI를 통해 최근의 LLM 안전성을 평가하였고, 효과성을 검증하였다.

Conclusion: AssurAI는 한국 커뮤니티를 위한 더 안전하고 신뢰할 수 있는 생성 AI 시스템 개발을 촉진하기 위해 공개된다.

Abstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.

</details>


### [8] [Prune4Web: DOM Tree Pruning Programming for Web Agent](https://arxiv.org/abs/2511.21398)
*Jiayuan Zhang,Kaiquan Chen,Zhihao Lu,Enshen Zhou,Qian Yu,Jing Zhang*

Main category: cs.AI

TL;DR: Prune4Web는 웹 자동화를 위한 새로운 패러다임으로, 리소스를 소모하는 LLM 읽기 대신 효율적인 프로그래밍 가지치기를 통해 DOM 처리 방식을 변경합니다.


<details>
  <summary>Details</summary>
Motivation: 최근의 대형 언어 모델(LLM) 기반 웹 에이전트들이 복잡한 실제 웹 페이지를 효과적으로 탐색하는 데 어려움을 겪고 있습니다.

Method: Prune4Web에서는 LLM이 실행 가능한 파이썬 스코어링 스크립트를 생성하여 의미적 단서에 기반하여 DOM 요소를 동적으로 필터링하는 방식으로 DOM 트리를 가지치기합니다.

Result: 이 방법론은 후보 요소 수를 25배에서 50배 감소시켜 정확한 행동 위치 지정을 용이하게 합니다.

Conclusion: 광범위한 실험을 통해 Prune4Web은 저수준 그라운딩 작업에서 정확도를 46.8%에서 88.28%로 크게 향상시키며, 실제 웹 자동화에서의 효율성을 입증하였습니다.

Abstract: Web automation employs intelligent agents to execute high-level tasks by mimicking human interactions with web interfaces. Despite the capabilities of recent Large Language Model (LLM)-based web agents, navigating complex, real-world webpages efficiently remains a significant hurdle due to the prohibitively large size of Document Object Model (DOM) structures, often ranging from 10,000 to 100,000 tokens. Existing strategies typically rely on crude DOM truncation -- risking the loss of critical information -- or employ inefficient heuristics and separate ranking models, failing to achieve an optimal balance between precision and scalability. To address these challenges, we introduce Prune4Web, a novel paradigm that shifts DOM processing from resource-intensive LLM reading to efficient programmatic pruning. Central to our approach is DOM Tree Pruning Programming, where an LLM generates executable Python scoring scripts to dynamically filter DOM elements based on semantic cues from decomposed sub-tasks. This mechanism eliminates the need for LLMs to ingest raw, massive DOMs, instead delegating traversal and scoring to lightweight, interpretable programs. This methodology achieves a 25x to 50x reduction in candidate elements for grounding, thereby facilitating precise action localization while mitigating attention dilution. Furthermore, we propose a specialized data annotation pipeline and a two-turn dialogue training strategy that jointly optimizes the Planner, Programmatic Filter, and Grounder within a unified framework. Extensive experiments demonstrate state-of-the-art performance. Notably, on our low-level grounding task, Prune4Web dramatically improves accuracy from 46.8% to 88.28%, underscoring its efficacy in real-world web automation.

</details>


### [9] [Conversational no-code and multi-agentic disease module identification and drug repurposing prediction with ChatDRex](https://arxiv.org/abs/2511.21438)
*Simon Süwer,Kester Bagemihl,Sylvie Baier,Lucia Dicunta,Markus List,Jan Baumbach,Andreas Maier,Fernando M. Delgado-Chaves*

Main category: cs.AI

TL;DR: ChatDRex는 네트워크 기반의 약물 재사용 예측을 위한 복잡한 생물정보학 분석을 실행하는 대화형 다중 에이전트 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 승인된 약물을 재사용하는 것은 전통적인 약물 개발에 비해 시간 효율적이고 비용 효과적인 대안을 제공한다.

Method: ChatDRex는 통합 시스템 의학 지식 그래프 NeDRex에 기반하여 자연어 접근과 생물정보학 에이전트를 통합하여 네트워크 분석 및 약물 재사용을 지원하는 다중 에이전트 디자인을 제공한다.

Result: 의사와 컴퓨터 과학 전문 지식이 없는 연구자가 복잡한 분석을 자연어로 제어할 수 있도록 하여 약물 재사용 접근을 민주화한다.

Conclusion: ChatDRex는 새로운 치료제 발견을 가속화하고 개인화된 의학과 전이 연구를 발전시킨다.

Abstract: Repurposing approved drugs offers a time-efficient and cost-effective alternative to traditional drug development. However, in silico prediction of repurposing candidates is challenging and requires the effective collaboration of specialists in various fields, including pharmacology, medicine, biology, and bioinformatics. Fragmented, specialized algorithms and tools often address only narrow aspects of the overall problem, and heterogeneous, unstructured data landscapes require specialized users to be involved. Hence, these data services do not integrate smoothly across workflows. With ChatDRex, we present a conversation-based, multi-agent system that facilitates the execution of complex bioinformatic analyses aiming for network-based drug repurposing prediction. It builds on the integrated systems medicine knowledge graph NeDRex. ChatDRex provides natural language access to its extensive biomedical KG and integrates bioinformatics agents for network analysis and drug repurposing, complemented by agents for functional coherence evaluation for in silico validation, as well as agents for literature mining and for discussing the obtained results in a scientific context. Its flexible multi-agent design assigns specific tasks to specialized agents, including query routing, data retrieval, algorithm execution, and result visualization. A dedicated reasoning module keeps the user in the loop and allows for hallucination detection. By enabling physicians and researchers without computer science expertise to control complex analyses in natural language, ChatDRex democratizes access to bioinformatics as an important resource for drug repurposing. It enables clinical experts to generate hypotheses and explore drug repurposing opportunities, ultimately accelerating the discovery of novel therapies and advancing personalized medicine and translational research.

</details>


### [10] [Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning](https://arxiv.org/abs/2511.20694)
*Kevin Lee,Russell Spiewak,James Walsh*

Main category: cs.AI

TL;DR: 대규모 언어 모델을 활용한 태양물리학에서의 과학적 추론은 단순한 사실 기억 이상의 것으로, 물리적 가정을 통합하고 일관된 단위를 유지하며 협조된 접근을 통해 명확한 과학적 형식을 제공해야 한다. 이 논문에서는 이러한 문제를 해결하기 위해 새로운 태양물리학 데이터 세트인 'Reasoning With a Star'를 제시하며, 초기 벤치마킹 접근법도 제공한다.


<details>
  <summary>Details</summary>
Motivation: 태양물리학에서 대규모 언어 모델을 통한 과학적 추론의 복잡성과 이를 해결하기 위한 데이터 세트 필요성.

Method: NASA와 대기 연구 대학 기업의 여름학교 문제 세트를 기반으로 구성된 질문 및 답변 구조와 물리적 가정, 일관된 단위, 명확한 형식을 포함하는 데이터 세트를 제시하고, 프로그램화된 채점기를 통해 예측을 검증.

Result: 단일 샷 기준선과 네 가지 다중 에이전트 패턴을 벤치마킹한 결과, 시스템 공학 원칙을 통한 워크플로 분해가 순수 귀납적 기억보다 더 나은 성과를 보였다.

Conclusion: 문제를 요구하는 문제 해결에서 직접적인 자극 보다 시스템 공학적 접근이 더 효과적임을 보여주었다.

Abstract: Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.

</details>


### [11] [A Brief History of Digital Twin Technology](https://arxiv.org/abs/2511.20695)
*Yunqi Zhang,Kuangyu Shi,Biao Li*

Main category: cs.AI

TL;DR: 디지털 트윈 기술이 의료 변혁을 촉발하고 있으며, 그러나 상호 운용성, 데이터 프라이버시, 모델 충실도 등의 주요 과제가 여전히 존재한다.


<details>
  <summary>Details</summary>
Motivation: 1960년대 NASA 우주선 시뮬레이션에서 시작된 디지털 트윈 기술이 산업적인 채택을 통해 의료 분야에서 혁신을 이끌고 있다.

Method: 디지털 트윈은 물리적 시스템의 동적이고 데이터 기반의 가상 대응물로, 실시간 데이터 스트림을 통해 지속적으로 업데이트되며 쌍방향 상호작용이 가능하다.

Result: 의료 분야에서 디지털 트윈은 이미징, 바이오센서 및 컴퓨팅 모델을 통합하여 환자 맞춤형 시뮬레이션을 생성하고 진단, 치료 계획 및 약물 개발을 지원한다. 대표적인 응용에는 부정맥 치료 결과 예측을 위한 심장 디지털 트윈, 종양 진행 추적 및 방사선 치료 최적화를 위한 종양학 디지털 트윈, 약물 발견 가속화를 위한 약리학 디지털 트윈이 포함된다.

Conclusion: 다양한 유망한 솔루션이 제시되고 있으며, 향후 다기관 디지털 트윈, 유전체 통합 및 윤리적 거버넌스의 발전이 의료 분야의 변화를 위해 필수적이다.

Abstract: Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.

</details>


### [12] [Learning Multi-Access Point Coordination in Agentic AI Wi-Fi with Large Language Models](https://arxiv.org/abs/2511.20719)
*Yifan Fan,Le Liang,Peng Liu,Xiao Li,Ziyang Guo,Qiao Lan,Shi Jin,Wen Tong*

Main category: cs.AI

TL;DR: 본 논문은 다중 액세스 포인트 조정(MAPC) 기술이 고전적인 정적 프로토콜 규칙에 의존하는 한계를 극복할 수 있는 에이전틱 AI Wi-Fi 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: MAPC는 밀집된 기본 서비스 세트에서 Wi-Fi의 처리량을 향상시키기 위한 핵심 기술입니다.

Method: 제안된 프레임워크는 각 액세스 포인트를 자율 대형 언어 모델 에이전트로 모델링하여 실시간으로 네트워크 상태에 대해 협력적으로 추론하고 적응형 조정 전략을 협상합니다.

Result: 포괄적인 시뮬레이션 결과는 이 에이전틱 프레임워크가 다양한 동적 네트워크 환경에 적응하는 방법을 성공적으로 학습했음을 보여줍니다.

Conclusion: 이는 미래의 무선 네트워크를 위한 강력하고 지능적인 솔루션으로서의 가능성을 검증합니다.

Abstract: Multi-access point coordination (MAPC) is a key technology for enhancing throughput in next-generation Wi-Fi within dense overlapping basic service sets. However, existing MAPC protocols rely on static, protocol-defined rules, which limits their ability to adapt to dynamic network conditions such as varying interference levels and topologies. To address this limitation, we propose a novel Agentic AI Wi-Fi framework where each access point, modeled as an autonomous large language model agent, collaboratively reasons about the network state and negotiates adaptive coordination strategies in real time. This dynamic collaboration is achieved through a cognitive workflow that enables the agents to engage in natural language dialogue, leveraging integrated memory, reflection, and tool use to ground their decisions in past experience and environmental feedback. Comprehensive simulation results demonstrate that our agentic framework successfully learns to adapt to diverse and dynamic network environments, significantly outperforming the state-of-the-art spatial reuse baseline and validating its potential as a robust and intelligent solution for future wireless networks.

</details>


### [13] [OpenApps: Simulating Environment Variations to Measure UI-Agent Reliability](https://arxiv.org/abs/2511.20766)
*Karen Ullrich,Jingtong Su,Claudia Shi,Arjun Subramonian,Amir Bar,Ivan Evtimov,Nikolaos Tsilivis,Randall Balestriero,Julia Kempe,Mark Ibrahim*

Main category: cs.AI

TL;DR: 이 논문은 다양한 앱 변형에 걸쳐 에이전트의 신뢰성을 측정하는 새로운 방법인 OpenApps를 개발하여, 고정된 환경에서 신뢰성 평가의 한계를 극복하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 자율 UI-에이전트가 인간과 유사하게 앱과 직접 상호작용할 수 있도록 하는 데 있어서 신뢰성은 필수적이다. 그러나 기존의 평가 방법은 고정된 환경에 의존하고 있으며, 다양한 앱 디자인의 변형을 반영하지 못한다.

Method: OpenApps는 외형과 내용을 구성할 수 있는 6개의 앱(메신저, 캘린더, 지도 등)으로 구성된 경량 오픈 소스 생태계를 개발하였다. 단일 CPU로 구동되며, 각 앱의 수천 가지 버전을 쉽게 생성하고 배포할 수 있다.

Result: 우리는 7개의 주요 다중 모드 에이전트의 신뢰성을 연구하기 위해 10,000건 이상의 독립적인 평가를 실시하였다. 고정된 앱 내의 신뢰성은 비교적 안정적이나, 앱 변형에 따라 신뢰성이 크게 달라질 수 있음을 발견하였다.

Conclusion: 이 초기 발견들은 앱 변형이라는 새로운 차원에 따라 신뢰성을 측정하는 것이 중요하다는 점을 강조하며, OpenApps는 이를 위한 유용한 도구가 될 것이다.

Abstract: Reliability is key to realizing the promise of autonomous UI-Agents, multimodal agents that directly interact with apps in the same manner as humans, as users must be able to trust an agent to complete a given task. Current evaluations rely on fixed environments, often clones of existing apps, which are limited in that they can only shed light on whether or how often an agent can complete a task within a specific environment. When deployed however, agents are likely to encounter variations in app design and content that can affect an agent's ability to complete a task. To address this blind spot of measuring agent reliability across app variations, we develop OpenApps, a light-weight open-source ecosystem with six apps (messenger, calendar, maps, etc.) that are configurable in appearance and content. OpenApps requires just a single CPU to run, enabling easy generation and deployment of thousands of versions of each app. Specifically, we run more than 10,000 independent evaluations to study reliability across seven leading multimodal agents. We find that while standard reliability within a fixed app is relatively stable, reliability can vary drastically when measured across app variations. Task success rates for many agents can fluctuate by more than $50\%$ across app variations. For example, Kimi-VL-3B's average success across all tasks fluctuates from $63\%$ to just $4\%$ across app versions. We also find agent behaviors such as looping or hallucinating actions can differ drastically depending on the environment configuration. These initial findings highlight the importance of measuring reliability along this new dimension of app variations. OpenApps is available at https://facebookresearch.github.io/OpenApps/

</details>


### [14] [Representation Interventions Enable Lifelong Unstructured Knowledge Control](https://arxiv.org/abs/2511.20892)
*Xuyuan Liu,Zhengzhang Chen,Xinshuai Dong,Yanchi Liu,Xujiang Zhao,Shengyu Chen,Haoyu Wang,Yujun Yan,Haifeng Chen*

Main category: cs.AI

TL;DR: RILKE는 대형 언어 모델의 지식 관리를 위한 효율적이고 확장 가능한 방법이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)은 종종 부정확하거나 오래된 내용을 생성하며, 비용이 많이 드는 재훈련 없이 지식을 효율적이고 정확하게 업데이트하는 것이 주요 도전 과제가 된다.

Method: RILKE는 지식 관리를 모델의 표현 공간 내에서의 개입으로 처리하는 강력하고 확장 가능한 방법이다.

Result: RILKE는 LLaMA 및 Qwen 모델에 대한 지식 편집 벤치마크 평가에서 높은 편집 성공률과 강력한 패러프레이즈 일반화 능력을 보여주며, 적당한 메모리 오버헤드를 가지고 일반 유용성을 유지한다.

Conclusion: 이 결과는 RILKE가 LLM의 평생 지식 관리를 위한 효과적이고 확장 가능한 솔루션임을 보여준다.

Abstract: Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.

</details>


### [15] [Towards Trustworthy Legal AI through LLM Agents and Formal Reasoning](https://arxiv.org/abs/2511.21033)
*Linze Chen,Yufan Cai,Zhe Hou,Jinsong Dong*

Main category: cs.AI

TL;DR: L4M 프레임워크는 적대적 LLM 에이전트와 SMT 솔버 기반 증명을 결합하여 법률의 해석적 유연성과 기호 검증의 엄격성을 통합한다.


<details>
  <summary>Details</summary>
Motivation: 법의 합리성이 실체적 합리성과 형식적 합리성이라는 두 가지 형태로 나타나며, 기존 LLM 기반 시스템은 법리적인 확실성을 보장하지 못한다.

Method: L4M 프레임워크는 법령을 논리적 공식으로 변환하고, 사건 내레이티브를 사실 튜플과 법령으로 매핑하며, 양측의 주장을 논리 제약으로 컴파일하는 세 가지 단계로 구성된다.

Result: 우리 시스템은 공개 벤치마크에서 GPT-o4-mini, DeepSeek-V3, Claude 4를 포함한 고급 LLM 및 최신 Legal AI 기준을 초과했다.

Conclusion: 엄격하고 설명 가능한 기호적 정당성을 제공하면서 최적화된 판결과 문장을 생성하는 L4M 시스템을 제시한다.

Abstract: The rationality of law manifests in two forms: substantive rationality, which concerns the fairness or moral desirability of outcomes, and formal rationality, which requires legal decisions to follow explicitly stated, general, and logically coherent rules. Existing LLM-based systems excel at surface-level text analysis but lack the guarantees required for principled jurisprudence. We introduce L4M, a novel framework that combines adversarial LLM agents with SMT-solver-backed proofs to unite the interpretive flexibility of natural language with the rigor of symbolic verification. The pipeline consists of three phases: (1) Statute Formalization, where domain-specific prompts convert legal provisions into logical formulae; (2) Dual Fact and Statute Extraction, in which prosecutor- and defense-aligned LLMs independently map case narratives to fact tuples and statutes, ensuring role isolation; and (3) Solver-Centric Adjudication, where an autoformalizer compiles both parties' arguments into logic constraints, and unsat cores trigger iterative self-critique until a satisfiable formula is achieved, which is then verbalized by a Judge-LLM into a transparent verdict and optimized sentence. Experimental results on public benchmarks show that our system surpasses advanced LLMs including GPT-o4-mini, DeepSeek-V3, and Claude 4 as well as state-of-the-art Legal AI baselines, while providing rigorous and explainable symbolic justifications.

</details>


### [16] [OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection](https://arxiv.org/abs/2511.21064)
*Chujie Wang,Jianyu Lu,Zhiyuan Luo,Xi Chen,Chu He*

Main category: cs.AI

TL;DR: OVOD-Agent는 텍스트 최적화를 시각적 추론과 자기 발전 감지로 전환하여 개방 어휘 개체 감지를 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 OVOD 방법이 고정된 범주 이름으로 제한되며, 다중 모드 훈련과 단일 모드 추론 간의 격차가 존재합니다.

Method: OVOD-Agent는 Chain-of-Thought 패러다임에 영감을 받아 텍스트 최적화 과정을 해석 가능한 Visual-CoT로 확장하며, 약한 마르코프 결정 과정(w-MDP)으로 시각적 맥락 전이를 모델링합니다.

Result: COCO와 LVIS에서 실험 결과, OVOD-Agent는 OVOD 기반에서 일관된 성능 향상을 제공하여 특히 희귀 범주에서 효과성을 확인했습니다.

Conclusion: 제안된 프레임워크는 OVOD의 효율성을 증명하고 있습니다.

Abstract: Open-Vocabulary Object Detection (OVOD) aims to enable detectors to generalize across categories by leveraging semantic information. Although existing methods are pretrained on large vision-language datasets, their inference is still limited to fixed category names, creating a gap between multimodal training and unimodal inference. Previous work has shown that improving textual representation can significantly enhance OVOD performance, indicating that the textual space is still underexplored. To this end, we propose OVOD-Agent, which transforms passive category matching into proactive visual reasoning and self-evolving detection. Inspired by the Chain-of-Thought (CoT) paradigm, OVOD-Agent extends the textual optimization process into an interpretable Visual-CoT with explicit actions. OVOD's lightweight nature makes LLM-based management unsuitable; instead, we model visual context transitions as a Weakly Markovian Decision Process (w-MDP) over eight state spaces, which naturally represents the agent's state, memory, and interaction dynamics. A Bandit module generates exploration signals under limited supervision, helping the agent focus on uncertain regions and adapt its detection policy. We further integrate Markov transition matrices with Bandit trajectories for self-supervised Reward Model (RM) optimization, forming a closed loop from Bandit exploration to RM learning. Experiments on COCO and LVIS show that OVOD-Agent provides consistent improvements across OVOD backbones, particularly on rare categories, confirming the effectiveness of the proposed framework.

</details>


### [17] [EWE: An Agentic Framework for Extreme Weather Analysis](https://arxiv.org/abs/2511.21444)
*Zhe Jiang,Jiong Wang,Xiaoyu Yue,Zijie Guo,Wenlong Zhang,Fenghua Ling,Wanli Ouyang,Lei Bai*

Main category: cs.AI

TL;DR: 이 논문은 극한 기상 사건을 자동으로 진단하는 첫 번째 지능형 에이전트 프레임워크인 극한 기상 전문가(EWE)를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 극한 기상 사건이 증가하는 위험을 초래하고 있어 그 기저에 있는 물리적 메커니즘을 해명할 필요성이 절실하다.

Method: EWE는 지식 기반 계획, 폐쇄 루프 추론, 그리고 도메인 맞춤형 기상 도구를 통해 전문가의 작업 흐름을 모방한다.

Result: EWE는 원시 기상 데이터에서 다중 모드 시각화를 자동으로 생성하고 해석하여 포괄적인 진단 분석을 가능하게 한다.

Conclusion: EWE는 자동화된 과학적 발견을 향한 한 걸음을 내딛고, 특히 극한 기상에 취약한 개발 도상국을 위해 전문 지식과 지적 자원을 민주화할 수 있는 잠재력을 제공한다.

Abstract: Extreme weather events pose escalating risks to global society, underscoring the urgent need to unravel their underlying physical mechanisms. Yet the prevailing expert-driven, labor-intensive diagnostic paradigm has created a critical analytical bottleneck, stalling scientific progress. While AI for Earth Science has achieved notable advances in prediction, the equally essential challenge of automated diagnostic reasoning remains largely unexplored. We present the Extreme Weather Expert (EWE), the first intelligent agent framework dedicated to this task. EWE emulates expert workflows through knowledge-guided planning, closed-loop reasoning, and a domain-tailored meteorological toolkit. It autonomously produces and interprets multimodal visualizations from raw meteorological data, enabling comprehensive diagnostic analyses. To catalyze progress, we introduce the first benchmark for this emerging field, comprising a curated dataset of 103 high-impact events and a novel step-wise evaluation metric. EWE marks a step toward automated scientific discovery and offers the potential to democratize expertise and intellectual resources, particularly for developing nations vulnerable to extreme weather.

</details>


### [18] [MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning](https://arxiv.org/abs/2511.21460)
*Junjian Wang,Lidan Zhao,Xi Sheryl Zhang*

Main category: cs.AI

TL;DR: 본 논문에서는 실제 가정 환경에서 안전한 작업 계획을 보장하기 위한 MADRA라는 새로운 프레임워크를 제안한다. 이 프레임워크는 다수의 AI 에이전트가 토론하여 작업 지시의 안전성을 평가하며, 안전성을 높이는 동시에 작업 성능을 훼손하지 않는다. 최종 실험 결과, MADRA는 안전하지 않은 작업을 90% 이상 거부하면서도 안전한 작업의 거부율은 낮추는 성과를 보였다.


<details>
  <summary>Details</summary>
Motivation: 가정 환경에서 위험한 지시가 존재하는 상황에서 임무 계획 중 몸체 AI 에이전트의 안전성을 보장하는 것이 중요하다.

Method: MADRA는 여러 LLM 기반 에이전트들이 주어진 지시의 안전성을 토론할 수 있도록 하고, 비판적인 평가자가 논리적 타당성, 위험 식별, 증거 품질 및 명확성을 기준으로 응답을 평가한다.

Result: MADRA는 반복적인 심의와 합의 투표 과정을 통해 허위 거부를 대폭 줄이며 위험한 작업에 대해 높은 민감성을 유지한다. 또한, 안전성, 메모리, 계획, 자기 진화 메커니즘을 통합한 계층적 인지 협업 계획 프레임워크를 도입하여 지속적인 학습을 통해 작업 성공률을 향상시킨다.

Conclusion: 이 연구는 신뢰할 수 있는 몸체 AI 에이전트를 구축하기 위한 확장 가능한 모델 비의존적 솔루션을 제공하며, 기존 방법보다 안전성과 실행 효율성에서 우수한 성능을 보여준다.

Abstract: Ensuring the safety of embodied AI agents during task planning is critical for real-world deployment, especially in household environments where dangerous instructions pose significant risks. Existing methods often suffer from either high computational costs due to preference alignment training or over-rejection when using single-agent safety prompts. To address these limitations, we propose MADRA, a training-free Multi-Agent Debate Risk Assessment framework that leverages collective reasoning to enhance safety awareness without sacrificing task performance. MADRA employs multiple LLM-based agents to debate the safety of a given instruction, guided by a critical evaluator that scores responses based on logical soundness, risk identification, evidence quality, and clarity. Through iterative deliberation and consensus voting, MADRA significantly reduces false rejections while maintaining high sensitivity to dangerous tasks. Additionally, we introduce a hierarchical cognitive collaborative planning framework that integrates safety, memory, planning, and self-evolution mechanisms to improve task success rates through continuous learning. We also contribute SafeAware-VH, a benchmark dataset for safety-aware task planning in VirtualHome, containing 800 annotated instructions. Extensive experiments on AI2-THOR and VirtualHome demonstrate that our approach achieves over 90% rejection of unsafe tasks while ensuring that safe-task rejection is low, outperforming existing methods in both safety and execution efficiency. Our work provides a scalable, model-agnostic solution for building trustworthy embodied agents.

</details>


### [19] [Agentic Learner with Grow-and-Refine Multimodal Semantic Memory](https://arxiv.org/abs/2511.21678)
*Weihao Bo,Shan Zhang,Yanpeng Sun,Jingjing Wu,Qunyi Xie,Xiao Tan,Kunbin Chen,Wei He,Xiaofan Li,Na Zhao,Jingdong Wang,Zechao Li*

Main category: cs.AI

TL;DR: ViLoMem은 시각적 주의와 논리적 추론을 통합하여 효과적으로 문제를 해결하는 메모리 시스템을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: MLLMs는 독립적인 문제 해결 방식을 가지고 있으며, 이로 인해 같은 실수를 반복하는 경향이 있습니다. 기존의 메모리 보강 에이전트는 과거의 경로를 저장하지만, 이는 필수적인 도메인 지식을 잃게 됩니다.

Method: ViLoMem은 시각적 주의 패턴과 논리적 추론 오류를 별도로 인코딩하여 학습할 수 있도록 돕는 이중 스트림 메모리 프레임워크입니다.

Result: ViLoMem은 6개의 다중모달 벤치마크에서 pass@1 정확도를 일관되게 향상시키고 반복적인 시각적 및 논리적 오류를 크게 줄였습니다.

Conclusion: 이 시스템은 명확한 방해 요소-환각 분리를 통해 이중 스트림 메모리의 필요성을 입증하고, 삶의 경험과 교차 도메인 학습을 위한 유용한 멀티모달 메모리의 가치를 보여줍니다.

Abstract: MLLMs exhibit strong reasoning on isolated queries, yet they operate de novo -- solving each problem independently and often repeating the same mistakes. Existing memory-augmented agents mainly store past trajectories for reuse. However, trajectory-based memory suffers from brevity bias, gradually losing essential domain knowledge. More critically, even in truly multimodal problem-solving settings, it records only a single-modality trace of past behavior, failing to preserve how visual attention and logical reasoning jointly contributed to the solution. This is fundamentally misaligned with human cognition: semantic memory is both multimodal and integrated, preserving visual and abstract knowledge through coordinated but distinct representational streams. We thus introduce ViLoMem, a dual-stream memory framework that constructs compact, schema-based memory. It separately encodes visual distraction patterns and logical reasoning errors, enabling MLLMs to learn from their successful and failed experiences. Following a grow-and-refine principle, the system incrementally accumulates and updates multimodal semantic knowledge -- preserving stable, generalizable strategies while avoiding catastrophic forgetting. Across six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy and substantially reduces repeated visual and logical errors. Ablations confirm the necessity of dual-stream memory with explicit distraction--hallucination separation, demonstrating the value of error-aware multimodal memory for lifelong and cross-domain agentic learning. Our project page will be available at https://weihao-bo.github.io/ViLoMeo-page.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [20] [Pretraining Transformer-Based Models on Diffusion-Generated Synthetic Graphs for Alzheimer's Disease Prediction](https://arxiv.org/abs/2511.20704)
*Abolfazl Moslemi,Hossein Peyvandi*

Main category: cs.LG

TL;DR: 이 연구는 알츠하이머병 진단을 위한 Transformer 기반의 새로운 진단 프레임워크를 제안하며, 합성 데이터 생성과 그래프 표현 학습을 통해 효과적인 기계 학습 모델을 개발합니다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병의 조기 및 정확한 탐지는 적시 개입과 개선된 결과를 위해 매우 중요하다.

Method: 합성 데이터 생성을 위해 DDPM을 활용하고, 그래프 변환기 인코더와 신경 분류기를 사용하여 모델을 훈련시킨다.

Result: 제안된 프레임워크는 NACC 데이터세트에 대한 주제별 교차 검증에서 AUC, 정확도, 민감도 및 특이도 모두 향상된 결과를 보여준다.

Conclusion: 그래프 변환기를 활용한 확산 기반 합성 사전 훈련이 적은 샘플 및 불균형 임상 예측 환경에서 일반화를 향상시킬 수 있음을 보여준다.

Abstract: Early and accurate detection of Alzheimer's disease (AD) is crucial for enabling timely intervention and improving outcomes. However, developing reliable machine learning (ML) models for AD diagnosis is challenging due to limited labeled data, multi-site heterogeneity, and class imbalance. We propose a Transformer-based diagnostic framework that combines diffusion-based synthetic data generation with graph representation learning and transfer learning. A class-conditional denoising diffusion probabilistic model (DDPM) is trained on the real-world NACC dataset to generate a large synthetic cohort that mirrors multimodal clinical and neuroimaging feature distributions while balancing diagnostic classes. Modality-specific Graph Transformer encoders are first pretrained on this synthetic data to learn robust, class-discriminative representations and are then frozen while a neural classifier is trained on embeddings from the original NACC data. We quantify distributional alignment between real and synthetic cohorts using metrics such as Maximum Mean Discrepancy (MMD), Frechet distance, and energy distance, and complement discrimination metrics with calibration and fixed-specificity sensitivity analyses. Empirically, our framework outperforms standard baselines, including early and late fusion deep neural networks and the multimodal graph-based model MaGNet, yielding higher AUC, accuracy, sensitivity, and specificity under subject-wise cross-validation on NACC. These results show that diffusion-based synthetic pretraining with Graph Transformers can improve generalization in low-sample, imbalanced clinical prediction settings.

</details>


### [21] [ST-PPO: Stabilized Off-Policy Proximal Policy Optimization for Multi-Turn Agents Training](https://arxiv.org/abs/2511.20718)
*Chenliang Li,Adel Elmahdy,Alex Boyd,Zhongruo Wang,Alfredo Garcia,Parminder Bhatia,Taha Kass-Hout,Cao Xiao,Mingyi Hong*

Main category: cs.LG

TL;DR: 이 논문에서는 대화 및 추론 작업에서 프로ximal 정책 최적화(PPO)의 불안정한 성능 문제를 다루기 위해 두 가지 안정화 기법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: PPO는 다중 턴 대화 및 추론 작업을 위한 대형 언어 모델(LLM) 훈련에 널리 사용되지만, 성능이 불안정하고 붕괴되는 경향이 있습니다.

Method: 우리는 두 가지 보완적인 안정화 기법인 턴 수준 중요 샘플링과 클리핑-바이어스 보정을 도입하여 불안정성 문제를 해결합니다.

Result: 실험에서는 ST-PPO와 S-PPO가 대형 모델 훈련에서 성능 붕괴를 방지하고 표준 토큰 수준 PPO보다 더 높은 작업 성능을 달성한 결과를 보여줍니다.

Conclusion: 턴 수준 중요 샘플링과 클리핑-바이어스 보정을 결합하는 것이 다중 턴 LLM 에이전트 훈련을 안정화하는 실용적이고 확장 가능한 솔루션을 제공합니다.

Abstract: PPO has been widely adopted for training large language models (LLMs) at the token level in multi-turn dialogue and reasoning tasks. However, its performance is often unstable and prone to collapse. Through empirical analysis, we identify two main sources of instability in this setting: (1)~token-level importance sampling, which is misaligned with the natural granularity of multi-turn environments that have distinct turn-level stages, and (2) inaccurate advantage estimates from off-policy samples, where the critic has not learned to evaluate certain state-action pairs, resulting in high-variance gradients and unstable updates. To address these challenges, we introduce two complementary stabilization techniques: (1) turn-level importance sampling, which aligns optimization with the natural structure of multi-turn reasoning, and (2) clipping-bias correction, which normalizes gradients by downweighting unreliable, highly off-policy samples. Depending on how these components are combined, we obtain three variants: Turn-PPO (turn-level sampling only), S-PPO (clipping-bias correction applied to token-level PPO), and ST-PPO (turn-level sampling combined with clipping-bias correction). In our experiments, we primarily study ST-PPO and S-PPO, which together demonstrate how the two stabilization mechanisms address complementary sources of instability. Experiments on multi-turn search tasks across general QA, multi-hop QA, and medical multiple-choice QA benchmarks show that ST-PPO and S-PPO consistently prevent the performance collapses observed in large-model training, maintain lower clipping ratios throughout optimization, and achieve higher task performance than standard token-level PPO. These results demonstrate that combining turn-level importance sampling with clipping-bias correction provides a practical and scalable solution for stabilizing multi-turn LLM agent training.

</details>


### [22] [Learning from Risk: LLM-Guided Generation of Safety-Critical Scenarios with Prior Knowledge](https://arxiv.org/abs/2511.20726)
*Yuhang Wang,Heye Huang,Zhenhua Xu,Kailai Sun,Baoshen Guo,Jinhua Zhao*

Main category: cs.LG

TL;DR: 이 연구는 CVAE와 LLM을 통합하여 희귀한 사건과 복잡한 상호작용을 고려한 자율 주행 시나리오 생성을 위한 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 주행 시스템의 안전성을 검증하기 위해서는 현실 세계의 드문 긴 꼬리 사건과 다중 에이전트 상호작용이 필요하지만, 이러한 사건은 실제 데이터에서는 부족하다.

Method: 조건부 변분 오토인코더(CVAE)를 사용하여 자연istic 데이터셋에서 과거의 궤적과 지도 정보를 인코딩하고, 대규모 언어 모델(LLM)을 통해 비구조적 장면 설명을 도메인 특화 손실 함수로 변환함으로써 시나리오 생성을 유도한다.

Result: CARLA와 SMARTS에서의 실험 결과, 이 프레임워크는 고위험 및 긴 꼬리 사건의 범위를 크게 증가시키고, 시뮬레이션과 실제 교통 분포 간의 일관성을 개선하며, 기존의 규칙 기반 또는 데이터 기반 방법보다 훨씬 더 도전적인 상호작용을 자율 주행 시스템에 부여한다.

Conclusion: 이 연구는 자율 시스템의 안전 검증을 위한 새로운 경로를 제시하며 드문 그러나 중요한 사건 하에서 시스템의 스트레스 테스트를 가능하게 한다.

Abstract: Autonomous driving faces critical challenges in rare long-tail events and complex multi-agent interactions, which are scarce in real-world data yet essential for robust safety validation. This paper presents a high-fidelity scenario generation framework that integrates a conditional variational autoencoder (CVAE) with a large language model (LLM). The CVAE encodes historical trajectories and map information from large-scale naturalistic datasets to learn latent traffic structures, enabling the generation of physically consistent base scenarios. Building on this, the LLM acts as an adversarial reasoning engine, parsing unstructured scene descriptions into domain-specific loss functions and dynamically guiding scenario generation across varying risk levels. This knowledge-driven optimization balances realism with controllability, ensuring that generated scenarios remain both plausible and risk-sensitive. Extensive experiments in CARLA and SMARTS demonstrate that our framework substantially increases the coverage of high-risk and long-tail events, improves consistency between simulated and real-world traffic distributions, and exposes autonomous driving systems to interactions that are significantly more challenging than those produced by existing rule- or data-driven methods. These results establish a new pathway for safety validation, enabling principled stress-testing of autonomous systems under rare but consequential events.

</details>


### [23] [Operationalizing Quantized Disentanglement](https://arxiv.org/abs/2511.20927)
*Vitoria Barin-Pacela,Kartik Ahuja,Simon Lacoste-Julien,Pascal Vincent*

Main category: cs.LG

TL;DR: 최근 이론적 작업이 모든 미분동형사상 하에서 양자화된 요소의 비지도 식별 가능성을 확립했다. 이론은 양자화 임계값이 잠재 요인의 확률 밀도에서 축 정렬 불연속성과 Correspond. 학습된 맵을 축 정렬 불연속성이 있는 밀도를 갖도록 제약함으로써 요인의 양자화를 회복할 수 있다. 하지만 이 고급 원리를 효과적인 실제 기준으로 변환하는 것은 비선형 맵 하에서는 여전히 도전적이다. 여기서 우리는 축 정렬 불연속성을 장려함으로써 비지도 분리의 기준을 개발한다. 불연속성은 추정된 요인의 밀도에서 급격한 변화로 나타나며 우리가 벼랑이라고 부르는 형성을 이룬다. 이론에서 독립 불연속성의 정의를 따라 우리는 요인을 따라 벼랑의 위치가 다른 요인의 값에 의존하지 않도록 장려한다. 우리는 우리의 방법인 Cliff가 모든 분리 벤치마크에서 기준선보다 우수하다는 것을 보여줌으로써 비지도 분리에 효과적임을 증명한다.


<details>
  <summary>Details</summary>
Motivation: 비지도 분리를 위한 기준을 개발하는 것에 대한 필요성.

Method: 축 정렬 불연속성을 장려하여 비지도 분리의 기준을 개발하였다.

Result: 우리의 방법인 Cliff가 모든 분리 벤치마크에서 기준선보다 우수함을 보여주었다.

Conclusion: Cliff는 비지도 분리에서 효과적임을 입증한다.

Abstract: Recent theoretical work established the unsupervised identifiability of quantized factors under any diffeomorphism. The theory assumes that quantization thresholds correspond to axis-aligned discontinuities in the probability density of the latent factors. By constraining a learned map to have a density with axis-aligned discontinuities, we can recover the quantization of the factors. However, translating this high-level principle into an effective practical criterion remains challenging, especially under nonlinear maps. Here, we develop a criterion for unsupervised disentanglement by encouraging axis-aligned discontinuities. Discontinuities manifest as sharp changes in the estimated density of factors and form what we call cliffs. Following the definition of independent discontinuities from the theory, we encourage the location of the cliffs along a factor to be independent of the values of the other factors. We show that our method, Cliff, outperforms the baselines on all disentanglement benchmarks, demonstrating its effectiveness in unsupervised disentanglement.

</details>


### [24] [FANoise: Singular Value-Adaptive Noise Modulation for Robust Multimodal Representation Learning](https://arxiv.org/abs/2511.20997)
*Jiaoyang Li,Jun Fang,Tianhao Gao,Xiaohui Zhang,Zhiyuan Liu,Chao Liu,Pengzhang Liu,Qixia Jiang*

Main category: cs.LG

TL;DR: 본 논문에서는 다중 모달 표현 학습을 위한 새로운 특징 적응형 노이즈 주입 전략인 FANoise를 제안하며, 노이즈의 역할을 체계적으로 연구하고 FANoise가 다중 모달 작업에서 성능을 향상시킴을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 강력하고 일반화 가능한 표현 학습의 필요성과 기존의 정적 노이즈 의존 방식의 한계를 극복하고자 함.

Method: InfoNCE 손실을 사용하여 노이즈의 역할을 체계적으로 연구하고, 다중 모달 표현 학습을 위해 FANoise라는 새로운 특징 적응형 노이즈 주입 전략을 제안.

Result: FANoise는 여러 기본 VLM 모델에서 다중 모달 작업에 대한 전반적인 성능을 일관되게 향상시키는 것으로 나타났다.

Conclusion: FANoise는 노이즈의 부정적인 영향을 완화하면서도 그 이점을 유지하는 효과적인 방법이다.

Abstract: Representation learning is fundamental to modern machine learning, powering applications such as text retrieval and multimodal understanding. However, learning robust and generalizable representations remains challenging. While prior work has demonstrated that active noise injection, a form of data augmentation, can enhance encoding performance, most existing methods rely on heuristic or static noise, overlooking the dynamic nature of feature distributions during training. In this work, we systematically study the role of noise in representation learning from both gradient-based and feature distribution perspectives, using InfoNCE loss as a representative example. Focusing on multimodal representation learning, we propose FANoise, a novel feature-adaptive noise injection strategy. By leveraging the dynamics of contrastive learning, FANoise effectively mitigates the negative impacts of noise while preserving its benefits. Under this theoretically grounded framework, comprehensive experiments demonstrate that FANoise consistently improves overall performance on multimodal tasks across various base VLM models.

</details>


### [25] [Prediction of Herd Life in Dairy Cows Using Multi-Head Attention Transformers](https://arxiv.org/abs/2511.21034)
*Mahdi Saki,Justin Lipman*

Main category: cs.LG

TL;DR: 이 연구는 유제품 농가가 젖소의 수명을 예측하기 위한 AI 기반 모델을 개발한 내용이다.


<details>
  <summary>Details</summary>
Motivation: 농민들은 젖소를 유지할지 도축할지를 결정하기 위해 젖소의 성과를 객관적으로 평가해야 한다.

Method: 과거 출생부터 기록된 다변량 시계열 데이터를 사용하여 AI 기반 모델을 개발했다. 특히, Multi-Head Attention Transformers를 활용하여 호주 7개 농장의 19,000마리 고유 젖소에서 약 780,000건의 기록을 분석했다.

Result: 모델이 연구된 농장에서의 젖소 수명 예측에 대해 전체 결정계수 83%를 달성했다.

Conclusion: 이 모델은 유제품 농장 관리에 실제 적용 가능성을 보여준다.

Abstract: Dairy farmers should decide to keep or cull a cow based on an objective assessment of her likely performance in the herd. For this purpose, farmers need to identify more resilient cows, which can cope better with farm conditions and complete more lactations. This decision-making process is inherently complex, with significant environmental and economic implications. In this study, we develop an AI-driven model to predict cow longevity using historical multivariate time-series data recorded from birth. Leveraging advanced AI techniques, specifically Multi-Head Attention Transformers, we analysed approximately 780,000 records from 19,000 unique cows across 7 farms in Australia. The results demonstrate that our model achieves an overall determination coefficient of 83% in predicting herd life across the studied farms, highlighting its potential for practical application in dairy herd management.

</details>


### [26] [Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning](https://arxiv.org/abs/2511.21075)
*Zhenchao Tang,Fang Wang,Haohuai He,Jiale Zhou,Tianxu Lv,Jun Zhu,Shouzhi Chen,Minghao Yang,Yu Wang,Jiayang Wu,Yidong Song,Jianhua Yao*

Main category: cs.LG

TL;DR: 생명 과학 연구를 가속화하기 위해 LLM의 전문 생물 의학 지식을 조화시키는 효과적인 사후 훈련이 필수적이다. 그러나 현재 접근 방식은 몇 가지 중요한 한계에 직면해 있다. 이 논문은 분산 데이터로부터 복잡한 추론을 학습하도록 설계된 효율적인 사후 훈련 방법인 균형 조정 세부 조정을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 생명 과학 연구를 가속화하기 위해 대형 언어 모델(LLM)을 전문 생물 의학 지식과 일치시키는 효과적인 사후 훈련이 필수적이다.

Method: 균형 조정 세부 조정(BFT)은 외부 보상 신호 없이 분산 데이터에서 복잡한 추론을 학습하도록 설계된 효율적인 사후 훈련 방법이다. BFT는 두 계층 가중치 메커니즘을 통해 작동한다: 1. 토큰 수준에서 예측 확률을 통해 손실을 조정하여 기울기를 안정화하고 과적합을 방지한다; 2. 샘플 수준에서 '최소 그룹 신뢰도'를 사용하여 어려운 샘플의 학습을 적응적으로 강화한다.

Result: BFT는 SFT보다 상당히 우수한 성능을 나타내며, 의료 작업에서 LLM이 SFT가 놓치는 지식을 습득할 수 있도록 한다. 생물학적 작업에서는 BFT 기반 LLM이 생물학 분석을 위한 정확한 에이전트인 GeneAgent를 초월한다.

Conclusion: BFT는 생물 의학 연구에서 LLM의 광범위한 응용을 촉진한다.

Abstract: Effective post-training is essential to align Large Language Models (LLMs) with specialized biomedical knowledge to accelerate life science research. However, current approaches face significant limitations. First, biomedical reasoning involves intricate mechanisms often represented by sparse textual data. Standard Supervised Fine-Tuning (SFT) tends to overfit to surface-level instruction patterns without effectively internalizing this fragmented scientific knowledge. Second, Reinforcement Learning (RL) is impractical for this domain, as defining meaningful rewards often necessitates prohibitive experimental validation (e.g., wet-lab verification of drug responses), rendering real-time feedback unfeasible. We propose Balanced Fine-Tuning (BFT), an efficient post-training method designed to learn complex reasoning from sparse data without external reward signals. BFT operates through a two-layer weighting mechanism: 1. At the token level, it scales loss via prediction probabilities to stabilize gradients and prevent overfitting; 2. At the sample level, it uses "minimum group confidence" to adaptively enhance the learning of hard samples. Experiments demonstrate that BFT significantly outperforms SFT. In medical tasks, it enables LLMs to acquire knowledge that SFT misses. In biological tasks, BFT-based LLMs surpass GeneAgent (an accurate agent for biology analysis) in biological process reasoning. Moreover, the text embeddings generated by BFT can be directly applied to downstream tasks, such as gene interaction and single-cell perturbation response prediction. These results indicate that BFT facilitates broad applications of LLMs in biomedical research.

</details>


### [27] [MNM : Multi-level Neuroimaging Meta-analysis with Hyperbolic Brain-Text Representations](https://arxiv.org/abs/2511.21092)
*Seunghun Baek,Jaejin Lee,Jaeyoon Sim,Minjae Jeong,Won Hwa Kim*

Main category: cs.LG

TL;DR: 본 연구는 하이퍼볼릭 기하학을 활용하여 신경과학 문헌과 뇌 활성화 맵 간의 격차를 해소하는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 소규모 샘플 크기로 인한 신경영상 연구의 신뢰성 문제를 해결하고자 함.

Method: 연구 논문의 텍스트와 해당 뇌 이미지를 로렌츠 모델을 통해 공유 하이퍼볼릭 공간에 내장하며, 다단계 신경영상 메타 분석을 수행한다.

Result: 우리 모델은 기존 기준선보다 성능이 뛰어나고, 다단계 신경영상 메타 분석의 강력하고 해석 가능한 패러다임을 제시한다.

Conclusion: 하이퍼볼릭 뇌-텍스트 표현을 통해 신경영상 데이터를 효과적으로 분석할 수 있음을 입증하였다.

Abstract: Various neuroimaging studies suffer from small sample size problem which often limit their reliability. Meta-analysis addresses this challenge by aggregating findings from different studies to identify consistent patterns of brain activity. However, traditional approaches based on keyword retrieval or linear mappings often overlook the rich hierarchical structure in the brain. In this work, we propose a novel framework that leverages hyperbolic geometry to bridge the gap between neuroscience literature and brain activation maps. By embedding text from research articles and corresponding brain images into a shared hyperbolic space via the Lorentz model, our method captures both semantic similarity and hierarchical organization inherent in neuroimaging data. In the hyperbolic space, our method performs multi-level neuroimaging meta-analysis (MNM) by 1) aligning brain and text embeddings for semantic correspondence, 2) guiding hierarchy between text and brain activations, and 3) preserving the hierarchical relationships within brain activation patterns. Experimental results demonstrate that our model outperforms baselines, offering a robust and interpretable paradigm of multi-level neuroimaging meta-analysis via hyperbolic brain-text representation.

</details>


### [28] [Trustless Federated Learning at Edge-Scale: A Compositional Architecture for Decentralized, Verifiable, and Incentive-Aligned Coordination](https://arxiv.org/abs/2511.21118)
*Pius Onobhayedo,Paul Osemudiame Oamen*

Main category: cs.LG

TL;DR: 이 논문은 인공지능의 발전이 중앙 집중식 공급에서 분산 창조로 나아가고 있으며, 이를 위한 몇 가지 문제를 해결하기 위한 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 인공지능 시스템에서 중앙 집중식 자원 요구로 인해 발생하는 문제 해결의 필요성.

Method: 암호화된 영수증을 이용해 집계 정확성을 증명하고, 기하학적 새로움 측정으로 인센티브 게임 방지, 병렬 객체 소유를 통해 선형 확장을 달성하며, 시간 잠금 정책으로 과거 조작을 검증하는 방법을 사용.

Result: 이 방법들은 집계의 정확성을 보장하고, 인센티브 게임을 방지하며, 확장성을 증가시키고, 과거 데이터 조작을 차단하는 데 기여한다.

Conclusion: 이 연구는 AI 모델의 안전하고 효율적인 분산 개선을 위한 새로운 프레임워크를 제안한다.

Abstract: Artificial intelligence is retracing the Internet's path from centralized provision to distributed creation. Initially, resource-intensive computation concentrates within institutions capable of training and serving large models.Eventually, as federated learning matures, billions of edge devices holding sensitive data will be able to collectively improve models without surrendering raw information, enabling both contribution and consumption at scale. This democratic vision remains unrealized due to certain compositional gaps; aggregators handle updates without accountability, economic mechanisms are lacking and even when present remain vulnerable to gaming, coordination serializes state modifications limiting scalability, and governance permits retroactive manipulation. This work addresses these gaps by leveraging cryptographic receipts to prove aggregation correctness, geometric novelty measurement to prevent incentive gaming, parallel object ownership to achieve linear scalability, and time-locked policies to check retroactive manipulation.

</details>


### [29] [Masks Can Be Distracting: On Context Comprehension in Diffusion Language Models](https://arxiv.org/abs/2511.21338)
*Julianna Piskorz,Cristina Pinneri,Alvaro Correia,Motasem Alfarra,Risheek Garrepalli,Christos Louizos*

Main category: cs.LG

TL;DR: MDLM은 ARLM의 대안으로 부각되었지만, 위치 편향과 마스크로 인한 맥락 이해 저하라는 두 가지 한계를 가진다. 새로운 손실 함수를 통해 이러한 문제를 해결할 수 있다.


<details>
  <summary>Details</summary>
Motivation: MDLM은 ARLM보다 더 균일한 맥락 활용을 목표로 하지만 그 한계를 밝혀내는 것이 중요하다.

Method: MDLM의 맥락 이해 능력을 조사하고, 주의 메커니즘과 마스크 토큰의 영향을 체계적으로 분석하였다.

Result: 지역적 편향과 마스크의 과도한 사용이 모델의 정보를 처리하는 능력에 부정적인 영향을 미친다는 것을 발견했다.

Conclusion: 새로운 손실 함수를 도입하여 MDLM의 맥락 이해 능력을 향상시키는 방법을 제시하였다.

Abstract: Masked Diffusion Language Models (MDLMs) have recently emerged as a promising alternative to Autoregressive Language Models (ARLMs), leveraging a denoising objective that, in principle, should enable more uniform context utilisation. In this work, we examine the context comprehension abilities of MDLMs and uncover two key limitations. First, despite their more global training objective and bidirectional attention mechanism, similarly to ARLMS, MDLMs exhibit a strong locality bias: performance is highly sensitive to the position of relevant information within the input, favouring local over distant context. Second, we show that appending a large number of mask tokens--required for generation--can significantly degrade context comprehension. Through systematic ablations, we find that these masks act as distractors, reducing the model's ability to process relevant information. To address this, we introduce a mask-agnostic loss function that encourages predictions to remain invariant to the number of appended masks. Fine-tuning with this objective substantially mitigates the distracting effect of masks, improving robustness of MDLMs. Overall, our findings reveal critical limitations of the current MDLM training paradigm and provide actionable insights for building diffusion-based language models with stronger context comprehension.

</details>


### [30] [Subjective Depth and Timescale Transformers: Learning Where and When to Compute](https://arxiv.org/abs/2511.21408)
*Frederico Wieser,Martin Benfeghoul,Haitham Bou Ammar,Jun Wang,Zafeirios Fountas*

Main category: cs.LG

TL;DR: 이 논문은 기존 변환기 아키텍처의 비효율성을 개선하기 위해 주관적 깊이 변환기(SDT)와 주관적 시간 척도 변환기(STT)를 도입하며, 이러한 아키텍처는 베이지안 서프라이즈 신호를 활용하여 계산을 동적으로 라우팅합니다.


<details>
  <summary>Details</summary>
Motivation: 표준 변환기 아키텍처의 경직된 계산 할당은 대규모 모델과 긴 시퀀스에서의 효율성과 확장성을 제한할 수 있습니다. 이를 개선하기 위한 새로운 아키텍처를 소개합니다.

Method: SDT는 결정층과 동적층을交互하여 계산을 수행하는 반면, STT는 잔여 업데이트를 예측하는 전이 네트워크를 통해 각 토큰에 대한 동적 실행 또는 우회를 관리합니다.

Result: 두 아키텍처 모두 서프라이즈 기반 원칙과의 정렬을 제안하며, 조건부 계산의 계산-정확도 트레이드오프에 대한 통찰을 제공합니다.

Conclusion: 제안된 아키텍처는 효율성을 위한 유연한 프레임워크를 설정하고 자가 주의 계산을 75% 줄이며 각 계산 건너뛰기 층 내에서 KV-캐시 요구량을 50% 감소시킵니다.

Abstract: The rigid, uniform allocation of computation in standard Transformer (TF) architectures can limit their efficiency and scalability, particularly for large-scale models and long sequences. Addressing this, we introduce Subjective Depth Transformers (SDT) and Subjective Timescale Transformers (STT), two distinct architectures that leverage Bayesian surprise signals to dynamically route computation, learning where and when to compute within decoder-only TFs. SDT augments a decoder-only stack with alternating Decision and Dynamic layers: a Decision layer computes a full block 'posterior' and a lightweight 'prior,' while a Dynamic layer employs fixed-capacity Top-K routing based on Bayesian surprise (Expected and Unexpected Change), maintaining a static compute graph. STT extends this conditional computation to the temporal domain: a transition network predicts residual updates, forming a temporal 'change hypothesis' that informs a router to dynamically execute or bypass TF blocks for each token, managing KV-cache contributions. Both architectures exhibit the predicted shift from novelty to prediction driven gating over training, suggesting alignment with surprise based principles. While operating at reduced capacity, they offer preliminary insights into the compute-accuracy trade-offs of conditional computation. The proposed architectures establish a flexible framework for efficiency, reducing self-attention computation by 75% and KV-cache requirements by 50% within each compute skipping layer, setting a pathway for more efficient models.

</details>


### [31] [SUPN: Shallow Universal Polynomial Networks](https://arxiv.org/abs/2511.21414)
*Zachary Morrow,Michael Penwarden,Brian Chen,Aurya Javeed,Akil Narayan,John D. Jakeman*

Main category: cs.LG

TL;DR: SUPNs는 적은 수의 매개변수로 충분한 표현력을 달성할 수 있는 얕은 다항 네트워크이다.


<details>
  <summary>Details</summary>
Motivation: 딥 뉴럴 네트워크와 Kolmogorov-Arnold 네트워크는 강력한 함수 근사 방법이지만, 과도한 매개변수가 문제를 일으킬 수 있다.

Method: SUPNs는 마지막 은닉층을 제외한 모든 층을 학습 가능한 계수를 가진 단일 폴리노미얼 층으로 대체한다.

Result: SUPNs는 주어진 매개변수 수에 대해 DNN 및 KAN보다 근사 오차가 낮다.

Conclusion: SUPNs는 비부드러운 함수에서조차 폴리노미얼 프젝션보다 성능이 우수하다.

Abstract: Deep neural networks (DNNs) and Kolmogorov-Arnold networks (KANs) are popular methods for function approximation due to their flexibility and expressivity. However, they typically require a large number of trainable parameters to produce a suitable approximation. Beyond making the resulting network less transparent, overparameterization creates a large optimization space, likely producing local minima in training that have quite different generalization errors. In this case, network initialization can have an outsize impact on the model's out-of-sample accuracy. For these reasons, we propose shallow universal polynomial networks (SUPNs). These networks replace all but the last hidden layer with a single layer of polynomials with learnable coefficients, leveraging the strengths of DNNs and polynomials to achieve sufficient expressivity with far fewer parameters. We prove that SUPNs converge at the same rate as the best polynomial approximation of the same degree, and we derive explicit formulas for quasi-optimal SUPN parameters. We complement theory with an extensive suite of numerical experiments involving SUPNs, DNNs, KANs, and polynomial projection in one, two, and ten dimensions, consisting of over 13,000 trained models. On the target functions we numerically studied, for a given number of trainable parameters, the approximation error and variability are often lower for SUPNs than for DNNs and KANs by an order of magnitude. In our examples, SUPNs even outperform polynomial projection on non-smooth functions.

</details>


### [32] [Predictive Safety Shield for Dyna-Q Reinforcement Learning](https://arxiv.org/abs/2511.21531)
*Jin Pin,Krasowski Hanna,Vanneaux Elena*

Main category: cs.LG

TL;DR: 강화학습의 안전 보장 획득은 실제 작업에 적용 가능성을 위해 주요한 도전 과제이다. 본 연구에서는 모델 기반 강화학습 에이전트를 위한 예측 안전 방패를 제안하며, 하드 안전 보장을 유지하면서 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 강화학습의 안전 보장 획득은 실제 작업의 적용 가능성을 위해 중요한 도전 과제이다.

Method: 본 연구에서는 안전한 환경 모델의 안전 예측에 기반하여 Q-함수를 지역적으로 업데이트하는 예측 안전 방패를 제안한다.

Result: experiment는 그리드월드 환경에서 짧은 예측 수평선만으로도 최적 경로를 식별할 수 있음을 보여준다.

Conclusion: 우리의 접근 방식은 추가 교육 없이 시뮬레이션과 현실 간의 분포 변화에 강력하다.

Abstract: Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training.

</details>


### [33] [Context-Specific Causal Graph Discovery with Unobserved Contexts: Non-Stationarity, Regimes and Spatio-Temporal Patterns](https://arxiv.org/abs/2511.21537)
*Martin Rabel,Jakob Runge*

Main category: cs.LG

TL;DR: 이 연구는 기후 데이터와 같은 실제 데이터에서 인과 그래프의 변화를 분석하고 안정성을 고려한 원칙과 프레임워크를 개발하여 기존 인과 발견 방법을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 실제 기후 응용 프로그램에서의 데이터는 시공간적으로 격자화된 시간 시계열 데이터로, 이러한 데이터의 변동이 알고리즘의 안정성 및 유효성에 부정적인 영향을 미칠 수 있다.

Method: 인과 그래프의 변화를 통해 정보를 연구하고, 독립성 테스트 수준에서 제약 기반 인과 발견 접근 방식을 수정하는 프레임워크를 개발한다.

Result: 기존의 제약 기반 인과 발견 방법과 거의 수정 없이 통합 가능한 모듈식이고 확장 가능한 프레임워크를 제공한다.

Conclusion: 이 프레임워크는 다양한 하위 문제를 체계적으로 이해하고 개선할 수 있으며, 오픈소스 구현이 곧 제공될 예정이다.

Abstract: Real-world data, for example in climate applications, often consists of spatially gridded time series data or data with comparable structure. While the underlying system is often believed to behave similar at different points in space and time, those variations that do exist are twofold relevant: They often encode important information in and of themselves. And they may negatively affect the stability / convergence and reliability\Slash{}validity of results of algorithms assuming stationarity or space-translation invariance. We study the information encoded in changes of the causal graph, with stability in mind. An analysis of this general task identifies two core challenges. We develop guiding principles to overcome these challenges, and provide a framework realizing these principles by modifying constraint-based causal discovery approaches on the level of independence testing. This leads to an extremely modular, easily extensible and widely applicable framework. It can leverage existing constraint-based causal discovery methods (demonstrated on IID-algorithms PC, PC-stable, FCI and time series algorithms PCMCI, PCMCI+, LPCMCI) with little to no modification. The built-in modularity allows to systematically understand and improve upon an entire array of subproblems. By design, it can be extended by leveraging insights from change-point-detection, clustering, independence-testing and other well-studied related problems. The division into more accessible sub-problems also simplifies the understanding of fundamental limitations, hyperparameters controlling trade-offs and the statistical interpretation of results. An open-source implementation will be available soon.

</details>


### [34] [Computing Strategic Responses to Non-Linear Classifiers](https://arxiv.org/abs/2511.21560)
*Jack Geary,Boyan Gao,Henry Gouk*

Main category: cs.LG

TL;DR: 본 논문에서는 전략적 분류 문제를 다루며, 분류기를 배치하는 행위가 이후 관찰에 대한 분포 편위를 유도하는 전략적 행동을 초래함을 설명합니다.


<details>
  <summary>Details</summary>
Motivation: 전략적 환경에서 분류기를 학습하는 현재의 접근 방식은 주로 선형 설정에 집중되고 있으며, 비선형 분류기가 더 적합한 많은 경우가 존재합니다.

Method: 대리인의 목표의 라그랑주 이중을 최적화하여 최적 반응을 계산하는 새로운 방법을 제시합니다.

Result: 우리의 방법은 선형 설정에서 최적 반응을 재현하며, 기존 접근 방식의 주요 약점을 식별합니다.

Conclusion: 우리의 방법은 비선형 분류기 설정에도 간단히 적용될 수 있으며, 평가와 훈련 모두에 유용하다는 것을 보여줍니다.

Abstract: We consider the problem of strategic classification, where the act of deploying a classifier leads to strategic behaviour that induces a distribution shift on subsequent observations. Current approaches to learning classifiers in strategic settings are focused primarily on the linear setting, but in many cases non-linear classifiers are more suitable. A central limitation to progress for non-linear classifiers arises from the inability to compute best responses in these settings. We present a novel method for computing the best response by optimising the Lagrangian dual of the Agents' objective. We demonstrate that our method reproduces best responses in linear settings, identifying key weaknesses in existing approaches. We present further results demonstrating our method can be straight-forwardly applied to non-linear classifier settings, where it is useful for both evaluation and training.

</details>


### [35] [Aligning LLMs Toward Multi-Turn Conversational Outcomes Using Iterative PPO](https://arxiv.org/abs/2511.21638)
*Daniel R. Jiang,Jalaj Bhandari,Yukai Yang,Rémi Munos,Tyler Lu*

Main category: cs.LG

TL;DR: 다중 턴 대화 결과를 위한 대형 언어 모델 최적화는 AI 마케팅 및 판매 에이전트와 같은 목표 지향적인 설정에서 큰 도전 과제가 된다. 본 기술 노트에서는 다중 턴 RL 문제를 단일 턴 RLHF 스타일 문제의 시퀀스로 공식적으로 축소하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 턴 대화 상황에서 보상 구조가 희소하고 긴 수평적 보상이 문제를 발생시키기 때문에, 더욱 개선된 대화 모델이 필요하다.

Method: 학습된 다중 턴 Q-함수를 단일 턴 문제에 대한 보상 모델로 설정하여 다중 턴 RL 문제를 단일 턴 RLHF 문제로 환원시킨다.

Result: 우리는 단일 턴 RL 문제를 표준 토큰 수준 PPO로 해결하는 것이 다중 턴 문제 내에서 정책 개선 단계와 동등하다는 것을 보여주고 증명한다.

Conclusion: Iterative PPO은 대화 경로에서 기록된 Q-함수를 맞추고 정책을 개선하는 배치 온라인 정책 반복 알고리즘으로, 구현이 간단하며 온라인 업데이트의 적응성과 오프라인 훈련의 안정성을 모두 갖춘 방법이다.

Abstract: Optimizing large language models (LLMs) for multi-turn conversational outcomes remains a significant challenge, especially in goal-oriented settings like AI marketing or sales agents who facilitate transactions via messaging platforms. The difficulty stems from sparse, long-horizon rewards and the discrepancy between response-level planning and token-level generation. In this technical note, we propose a formal reduction of the multi-turn RL problem into a sequence of single-turn RLHF-style problems. This is achieved by setting a learned multi-turn Q-function as the reward model for the single-turn problem. We demonstrate and prove a key insight: solving this single-turn RL problem with standard token-level PPO is equivalent to a policy improvement step within the multi-turn problem. This insight naturally leads to Iterative PPO, a batch online policy iteration algorithm that alternates between fitting Q-functions from logged conversation trajectories and improving the policy. A major practical advantage is that Iterative PPO directly leverages stable, off-the-shelf single-turn RLHF tools, making it straightforward to implement. Our method occupies a middle ground between fully online and fully offline approaches, retaining the adaptability of online updates while gaining the stability benefits of offline training.

</details>


### [36] [EvilGenie: A Reward Hacking Benchmark](https://arxiv.org/abs/2511.21654)
*Jonathan Gabor,Jayson Lynch,Jonathan Rosenfeld*

Main category: cs.LG

TL;DR: EvilGenie는 프로그래밍 환경에서 보상 해킹을 측정하기 위한 기준을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 프로그램 설정에서 보상 해킹을 탐지하고 측정할 수 있는 표준화된 벤치마크를 만들기 위해.

Method: LiveCodeBench에서 문제를 가져와 테스트 파일을 편집하거나 테스트 케이스를 하드코딩하는 방식으로 에이전트가 쉽게 보상 해킹을 할 수 있는 환경을 생성합니다.

Result: LLM 판단기가 명확한 경우의 보상 해킹을 효과적으로 탐지하며, 보유된 테스트 케이스 사용에서의 개선은 미미합니다.

Conclusion: Codex와 Claude Code에서 명시적인 보상 해킹이 관찰되었고, 세 에이전트 모두에서 잘못된 행동이 감지되었습니다.

Abstract: We introduce EvilGenie, a benchmark for reward hacking in programming settings. We source problems from LiveCodeBench and create an environment in which agents can easily reward hack, such as by hardcoding test cases or editing the testing files. We measure reward hacking in three ways: held out unit tests, LLM judges, and test file edit detection. We verify these methods against human review and each other. We find the LLM judge to be highly effective at detecting reward hacking in unambiguous cases, and observe only minimal improvement from the use of held out test cases. In addition to testing many models using Inspect's basic_agent scaffold, we also measure reward hacking rates for three popular proprietary coding agents: OpenAI's Codex, Anthropic's Claude Code, and Google's Gemini CLI Using GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro, respectively. We observe explicit reward hacking by both Codex and Claude Code, and misaligned behavior by all three agents. Our codebase can be found at https://github.com/JonathanGabor/EvilGenie.

</details>


### [37] [Through the telecom lens: Are all training samples important?](https://arxiv.org/abs/2511.21668)
*Shruti Bothe,Illyyne Saffar,Aurelie Boisbunon,Hasan Farooq,Julien Forgeat,Md Moin Uddin Chowdhury*

Main category: cs.LG

TL;DR: AI의 발전으로 통신 분야에서 데이터 요구량과 훈련 수요가 급증하였고, 본 논문은 개별 샘플의 역할을 분석하여 훈련 과정을 최적화하는 새로운 접근법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI의 역할에도 불구하고 표준 작업 흐름은 모든 훈련 샘플이 동등하게 기여한다고 가정한다.

Method: 개별 샘플의 중요성을 분석하고, 샘플 수준의 그래디언트 분석을 통해 모델 학습에서의 영향 및 중복 패턴을 식별한다.

Result: 제안된 방법은 데이터 요구량과 계산 오버헤드를 줄이면서 성능을 유지한다.

Conclusion: 제안하는 샘플 중요성 프레임워크는 영향력이 큰 데이터를 우선적으로 선택하여 계산 효율성과 에너지 사용을 최적화한다.

Abstract: The rise of AI in telecommunications, from optimizing Radio Access Networks to managing user experience, has sharply increased data volumes and training demands. Telecom data is often noisy, high-dimensional, costly to store, process, and label. Despite Ai's critical role, standard workflows still assume all training samples contribute equally. On the other hand, next generation systems require AI models that are accurate, efficient, and sustainable.The paper questions the assumptions of equal importance by focusing on applying and analyzing the roles of individual samples in telecom training and assessing whether the proposed model optimizes computation and energy use. we perform sample-level gradient analysis across epochs to identify patterns of influence and redundancy in model learning. Based on this, we propose a sample importance framework thats electively prioritizes impactful data and reduces computation without compromising accuracy. Experiments on three real-world telecom datasets show that our method [reserves performance while reducing data needs and computational overhead while advancing the goals of sustainable AI in telecommunications.

</details>


### [38] [DSD: A Distributed Speculative Decoding Solution for Edge-Cloud Agile Large Model Serving](https://arxiv.org/abs/2511.21669)
*Fengze Yu,Leshu Li,Brad McDanel,Saiqian Zhang*

Main category: cs.LG

TL;DR: DSD는 분산 스펙티브 디코딩을 통해 LLM 추론의 디코딩 지연을 줄이고 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: LLM 추론의 높은 디코딩 지연과 이질적인 엣지-클라우드 환경에서의 제한된 확장성을 해결하기 위해.

Method: 분산 스펙티브 디코딩 프레임워크 DSD를 제안하고, 이를 위해 DSD-Sim이라는 이산 이벤트 시뮬레이터를 도입하여 네트워크, 배치, 스케줄링 동역학을 포착하며, Adaptive Window Control (AWC) 정책을 설계하여 동적으로 투기 창 크기를 조정한다.

Result: DSD는 기존 SD 기준에 비해 최대 1.1배의 속도 향상과 9.7% 높은 처리량을 달성하였다.

Conclusion: DSD는 엣지와 클라우드 전반에서 신속하고 확장 가능한 LLM 서비스 제공을 가능하게 한다.

Abstract: Large language model (LLM) inference often suffers from high decoding latency and limited scalability across heterogeneous edge-cloud environments. Existing speculative decoding (SD) techniques accelerate token generation but remain confined to single-node execution. We propose DSD, a distributed speculative decoding framework that extends SD to multi-device deployments through coordinated draft-target execution. Given the lack of prior work on simulating this paradigm, we first introduce DSD-Sim, a discrete-event simulator that captures network, batching, and scheduling dynamics. Building on insights from DSD-Sim, we further design an Adaptive Window Control (AWC) policy that dynamically adjusts speculation window size to optimize throughput. Experiments across diverse workloads show that DSD achieves up to 1.1x speedup and 9.7% higher throughput over existing SD baselines, enabling agile and scalable LLM serving across edge and cloud.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [39] [MTTR-A: Measuring Cognitive Recovery Latency in Multi-Agent Systems](https://arxiv.org/abs/2511.20663)
*Barak Or*

Main category: cs.MA

TL;DR: 자율 다중 에이전트 시스템의 인지 안정성을 보장하는 것이 대규모 분산 AI의 중심 과제입니다. 기존의 관찰 도구는 시스템 출력을 모니터링하지만, 에이전트 작업 흐름이 추론의 일관성을 잃은 후 얼마나 빨리 복구되는지를 정량화할 수는 없습니다. 본 연구에서는 MTTR-A(Agentic Systems의 Mean Time-to-Recovery)를 인지 도메인으로 변형하여, MAS가 추론 drift를 감지하고 일관된 작동을 복원하는 데 필요한 시간을 정량화합니다. 시뮬레이션 결과, 자동 반응은 평균적으로 약 6초 이내에 안정성을 회복하였고, 인간 승인 개입은 약 12초가 소요되었습니다. 이 연구는 분산 추론의 정량적 특성으로서 복구 대기시간을 형식화하고, 복구 시간과 인지 가동 시간을 연결하는 신뢰성 경계를 도출함으로써 에이전트 인지의 신뢰성을 위한 기초를 마련합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 다중 에이전트 시스템(MAS)에서 인지 안정성을 보장하는 것은 대규모 분산 인공지능의 주요한 도전 과제입니다.

Method: 고전적 신뢰성 지표(MTTR, MTBF 등)를 인지 도메인으로 변형하고, MAS의 복구 대기 시간을 측정하는 MTTR-A를 정의하였습니다.

Result: AG~News 데이터세트와 LangGraph 프레임워크에서 벤치마크 시뮬레이션을 수행하여 여러 반사 모드에서 복구 대기 시간을 모델링했습니다. 자동 반응은 평균적으로 약 6초 정도에 안정성을 회복했으며, 인간 승인 개입은 약 12초가 소요되었습니다.

Conclusion: 복구 대기 시간을 정량적 특성으로 형식화하고, 복구 시간과 인지 가동 시간 간의 신뢰성 경계를 도출하여 에이전트 인지의 신뢰성을 위한 기초를 마련합니다.

Abstract: Ensuring cognitive stability in autonomous multi-agent systems (MAS) is a central challenge for large-scale, distributed AI. While existing observability tools monitor system outputs, they cannot quantify how rapidly agentic workflows recover once reasoning coherence has been lost. We adapt classical reliability metrics-Mean Time-to-Recovery (MTTR), Mean Time Between Failures (MTBF), and related ratios-into the cognitive domain, defining MTTR-A (Mean Time-to-Recovery for Agentic Systems) as a runtime measure of cognitive recovery latency. MTTR-A quantifies the time required for a MAS to detect reasoning drift and restore consistent operation, capturing the recovery of reasoning coherence rather than infrastructural repair.
  A benchmark simulation using the AG~News corpus and the LangGraph orchestration framework was conducted, modeling recovery latencies across multiple reflex modes. Automated reflexes restored stability within approximately 6s on average, while human-approval interventions required about 12s. Across 200 runs, the median simulated MTTR-A was 6.21+-2.14s, MTBF=6.7+-2.14s, and NRR=0.08, demonstrating measurable runtime resilience across reflex strategies.
  By formalizing recovery latency as a quantifiable property of distributed reasoning-and deriving reliability bounds linking recovery time and cognitive uptime-this work establishes a foundation for runtime dependability in agentic cognition, transforming cognitive recovery from an ad-hoc process into a standardized, interpretable performance

</details>


### [40] [Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation](https://arxiv.org/abs/2511.21510)
*Ke Zhang,Xiaoning Zhao,Ce Zheng,Jiahong Ning,Dandan Zhu,Wenqi Zhang,Chen Sun,Toshiharu Sugawara*

Main category: cs.MA

TL;DR: Tool-RoCo는 장기적 다중 에이전트 협력을 평가하기 위한 새로운 벤치마크로, LLM의 자율성을 측정하는 데 초점을 맞춘다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 에이전트의 자율성을 무시하고 미리 정의된 오케스트레이션에 의존했다.

Method: Tool-RoCo는 에이전트를 도구로 간주하고, 현재 상태에 따라 도구를 선택하고 피드백을 받아 다음 라운드에서 선택을 조정하는 방식으로 장기적인 협력을 평가한다.

Result: LLM 기반의 에이전트는 도구를 보조자로 활용하는 경우가 드물며, 활성화 도구는 96.42%를 차지해 현재의 LLM은 활동적인 에이전트를 유지하는 경향이 있다.

Conclusion: Tool-RoCo는 LLM의 자율성과 협력을 체계적으로 평가할 수 있는 벤치마크를 제공한다.

Abstract: This study proposes Tool-RoCo, a novel benchmark for evaluating large language models (LLMs) in long-term multi-agent cooperation based on RoCo, a multi-robot cooperative benchmark. Recent research on LLM-based multi-agent systems has relied on predefined orchestration, while ignoring agent autonomy. Tool-RoCo treats other agents as tools and introduces cooperative tools, leveraging tool usage to evaluate multi-agent cooperation and self-organization. Tool usage means that each agent (LLM) selects a tool from a candidate set based on the current state, receives feedback, and adjusts its selection in subsequent rounds. To evaluate different autonomy levels, we propose four LLM paradigms: (1) centralized cooperation, where a single LLM allocates tools to all agents; (2) centralized self-organization, where a central LLM autonomously activates agents while keeping others inactive; (3) decentralized cooperation, where each agent has its own LLM and calls tools based on local information; and (4) self-organization, where a randomly chosen initial agent can request collaboration, activating additional agents via tool calls. Tool-RoCo includes three multi-robot tasks, SORT, PACK, and CABINET, to measure format and parameter accuracy and agent coordination through tool usage. The results using several LLMs showed that cooperative tools accounted for only 7.09% of all tools, indicating that LLM-based agents rarely invoked others as assistants. Moreover, activation tools accounted for 96.42%, suggesting that current LLMs tend to maintain active agents while seldom deactivating them for adaptive coordination. Tool-RoCo provides a systematic benchmark to evaluate LLM autonomy and cooperation in multi-agent tasks. Code and Demo: https://github.com/ColaZhang22/Tool-Roco

</details>


### [41] [BAMAS: Structuring Budget-Aware Multi-Agent Systems](https://arxiv.org/abs/2511.21572)
*Liming Yang,Junyu Luo,Xuanzhe Liu,Yiling Lou,Zhenpeng Chen*

Main category: cs.MA

TL;DR: BAMAS는 예산을 고려한 다중 에이전트 시스템 구축을 위한 새로운 접근법으로, 성능과 비용을 균형 잡는 최적의 LLM 집합을 선택하고 상호작용 지도를 결정하여 비용을 최대 86% 절감하면서 유사한 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 다중 에이전트 시스템의 복잡도가 증가함에 따라 실용적인 배포를 위한 비용 고려가 중요해진다.

Method: BAMAS는 성능과 비용을 균형 잡는 정수 선형 프로그래밍 문제를 설정하고 해결하여 최적의 LLM 집합을 선택하며, 강화 학습 기반 방법을 통해 이들이 협력하는 방식을 결정한다.

Result: BAMAS는 세 가지 대표 작업에서 평가되었으며, 최신 에이전트 구축 방법과 비교하여 성능은 비슷하면서도 비용을 최대 86%까지 절감하는 것을 보여준다.

Conclusion: 이 연구는 예산 인식 다중 에이전트 시스템 구축의 새로운 방향을 제시한다.

Abstract: Large language model (LLM)-based multi-agent systems have emerged as a powerful paradigm for enabling autonomous agents to solve complex tasks. As these systems scale in complexity, cost becomes an important consideration for practical deployment. However, existing work rarely addresses how to structure multi-agent systems under explicit budget constraints. In this paper, we propose BAMAS, a novel approach for building multi-agent systems with budget awareness. BAMAS first selects an optimal set of LLMs by formulating and solving an Integer Linear Programming problem that balances performance and cost. It then determines how these LLMs should collaborate by leveraging a reinforcement learning-based method to select the interaction topology. Finally, the system is instantiated and executed based on the selected agents and their collaboration topology. We evaluate BAMAS on three representative tasks and compare it with state-of-the-art agent construction methods. Results show that BAMAS achieves comparable performance while reducing cost by up to 86%.

</details>
