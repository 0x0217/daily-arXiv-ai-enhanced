<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 16]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.LG](#cs.LG) [Total: 26]
- [cs.AI](#cs.AI) [Total: 25]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Auditable Early Stopping for Agentic Routing: Ledger-Verified Run-Wise Certificates under Local DP](https://arxiv.org/abs/2509.10550)
*Shivam Akhauri*

Main category: cs.CR

TL;DR: 이 논문은 도구 사용 에이전트를 위한 최우선 라우터가 더 나은 리프를 놓치지 않으면서 탐색을 중단할 수 있는 시점과 이를 보장하는 방법을 다루고 있다.


<details>
  <summary>Details</summary>
Motivation: 최적의 탐색을 유지하면서도 개인 정보 보호를 보장하는 방법을 찾는 것이 중요하다.

Method: 런별 인증서를 도입하여 각 노드의 키를 리프 변동을 실현하는 동일한 지수 경주에 연결하고, 최대 값에 대한 정지 규칙을 적용한다.

Result: 실험에서 강한 정지, 결정론적 재생, 낮은 오버헤드를 보여준다.

Conclusion: 이러한 방법은 조작이 가능하면서도 개인 정보를 보호하는 효과적인 라우팅 방법을 제시한다.

Abstract: We address when a best-first router for tool-use agents can stop exploring
without missing a better leaf, while preserving local differential privacy
(LDP) and leaving an audit trail. We introduce a run-wise certificate that
couples each node's key to the same exponential race that realizes leaf
perturbations; the usual halting rule (stop when the maximum over $v$ in $F$ of
Key$(v) \le B^*$) then certifies the realized run. We give two certified modes
on context-indexed prefix DAGs with child partition: (i) Exact (known counts),
using lazy offset propagation with winner reuse; and (ii) Surrogate (upper
bounds only), which anchors keys to a parent-level surrogate race and allows
validator tightening via $\kappa = \log(N / N_{ub}$). A small compiler enforces
the partition property, and an admissible, race-independent M(tau) keeps keys
sound. The ledger logs uniforms, counts, and tie handling; privacy follows by
post-processing. Experiments on synthetic graphs and a small real pipeline show
tight stopping, deterministic replay, and low overhead.

</details>


### [2] [Safety and Security Analysis of Large Language Models: Risk Profile and Harm Potential](https://arxiv.org/abs/2509.10655)
*Charankumar Akiri,Harrison Simpson,Kshitiz Aryal,Aarav Khanna,Maanak Gupta*

Main category: cs.CR

TL;DR: 대규모 언어 모델(LLM)의 배포는 큰 잠재력을 지니지만, 이러한 모델의 공격적 조작에 대한 취약성은 심각한 안전 및 윤리적 위험을 초래할 수 있다. 이 연구는 9개의 주요 LLM의 안전 및 보안을 평가하고, 이를 통한 리스크 프로파일링을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)의 사용이 증가함에 따라, 이들의 안전과 보안을 공격적 프롬프트 기술에 대해 평가하는 것이 필수적이다.

Method: 이 연구는 9개의 주요 LLM에 대해 24개의 보안 및 안전 카테고리에 대한 경험적 분석과 리스크 프로파일을 제공한다.

Result: 이 연구는 테스트한 LLM의 안전 필터에서 광범위한 취약점을 찾았으며, 모델의 강력한 정렬, 책임 있는 배치 관행 및 모델 거버넌스의 필요성을 강조한다.

Conclusion: LLM의 개발 환경이 발전함에 따라, 이 연구는 LLM의 리스크를 비교하기 위한 유용한 지표인 리스크 심각도 지수(RSI)를 제안한다.

Abstract: While the widespread deployment of Large Language Models (LLMs) holds great
potential for society, their vulnerabilities to adversarial manipulation and
exploitation can pose serious safety, security, and ethical risks. As new
threats continue to emerge, it becomes critically necessary to assess the
landscape of LLMs' safety and security against evolving adversarial prompt
techniques. To understand the behavior of LLMs, this research provides an
empirical analysis and risk profile of nine prominent LLMs, Claude Opus 4,
DeepSeek V3 (both open-source and online), Gemini 2.5 Flash, GPT-4o, Grok 3,
Llama 4 Scout, Mistral 7B, and Qwen 3 1.7B, against 24 different security and
safety categories. These LLMs are evaluated on their ability to produce harmful
responses for adversarially crafted prompts (dataset has been made public) for
a broad range of safety and security topics, such as promotion of violent
criminal behavior, promotion of non-violent criminal activity, societal harms
related to safety, illegal sexual content, dangerous code generation, and
cybersecurity threats beyond code. Our study introduces the Risk Severity Index
(RSI), an agile and scalable evaluation score, to quantify and compare the
security posture and creating a risk profile of LLMs. As the LLM development
landscape progresses, the RSI is intended to be a valuable metric for comparing
the risks of LLMs across evolving threats. This research finds widespread
vulnerabilities in the safety filters of the LLMs tested and highlights the
urgent need for stronger alignment, responsible deployment practices, and model
governance, particularly for open-access and rapidly iterated models.

</details>


### [3] [Side-channel Inference of User Activities in AR/VR Using GPU Profiling](https://arxiv.org/abs/2509.10703)
*Seonghun Son,Chandrika Mukherjee,Reham Mohamed Aburas,Berk Gulmezoglu,Z. Berkay Celik*

Main category: cs.CR

TL;DR: OVRWatcher는 AR/VR 기기에서 사용자 활동을 저해상도 GPU 사용량을 모니터링하여 추론하는 새로운 사이드 채널 기법으로, 99% 이상의 정확도로 앱 및 객체 수준 추론을 수행한다.


<details>
  <summary>Details</summary>
Motivation: AR/VR 기기에서 사용자가 민감한 정보를 제3자 앱에 공유하는 데 있어 보안 환경이 보장되지 않음을 해결하기 위해.

Method: OVRWatcher는 고해상도 프로파일링 대신 저해상도 GPU 사용량을 모니터링하여 사용자 활동을 추론하는 새로운 사이드 채널 원리를 제안한다.

Result: OVRWatcher는 앱 지문 인식에서 99% 이상의 정확도를 달성하고, 객체 수준 추론에서 98% 이상의 정확도를 보인다.

Conclusion: OVRWatcher는 AR/VR 및 WebXR 애플리케이션에 대한 사용자 지문 인식 및 객체 인식에 효과적이며, 사용자의 제품 선호성을 드러내고 기밀 정보를 노출할 수 있다.

Abstract: Over the past decade, AR/VR devices have drastically changed how we interact
with the digital world. Users often share sensitive information, such as their
location, browsing history, and even financial data, within third-party apps
installed on these devices, assuming a secure environment protected from
malicious actors. Recent research has revealed that malicious apps can exploit
such capabilities and monitor benign apps to track user activities, leveraging
fine-grained profiling tools, such as performance counter APIs. However,
app-to-app monitoring is not feasible on all AR/VR devices (e.g., Meta Quest),
as a concurrent standalone app execution is disabled. In this paper, we present
OVRWatcher, a novel side-channel primitive for AR/VR devices that infers user
activities by monitoring low-resolution (1Hz) GPU usage via a background
script, unlike prior work that relies on high-resolution profiling. OVRWatcher
captures correlations between GPU metrics and 3D object interactions under
varying speeds, distances, and rendering scenarios, without requiring
concurrent app execution, access to application data, or additional SDK
installations. We demonstrate the efficacy of OVRWatcher in fingerprinting both
standalone AR/VR and WebXR applications. OVRWatcher also distinguishes virtual
objects, such as products in immersive shopping apps selected by real users and
the number of participants in virtual meetings, thereby revealing users'
product preferences and potentially exposing confidential information from
those meetings. OVRWatcher achieves over 99% accuracy in app fingerprinting and
over 98% accuracy in object-level inference.

</details>


### [4] [ORQ: Complex Analytics on Private Data with Strong Security Guarantees](https://arxiv.org/abs/2509.10793)
*Eli Baum,Sam Buxbaum,Nitin Mathai,Muhammad Faisal,Vasiliki Kalavri,Mayank Varia,John Liagouris*

Main category: cs.CR

TL;DR: ORQ 시스템은 안전한 다자간 계산을 사용하여 대규모 개인 데이터셋의 협업 분석을 가능하게 하며, 복잡한 관계 쿼리 및 집계를 효율적으로 처리한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 개인 데이터셋을 안전하게 분석하려는 필요성과 기존의 다자간 계산 방법의 한계를 극복하기 위한 동기.

Method: ORQ는 실제 쿼리 구조를 활용하여 보안 조인의 제곱 비용을 제거하고, 범용 비가시 연산자 및 데이터 병렬 벡터화 쿼리 엔진 등을 포함한다.

Result: ORQ는 최신 솔루션에 비해 MPC 실행 시간을 크게 단축시키고, 훨씬 큰 데이터셋을 처리할 수 있다.

Conclusion: 10배 스케일 팩터의 TPC-H 벤치마크에서 MPC 하에 수행된 결과를 보고하며, 이전에는 정보 유출이나 신뢰할 수 있는 제3자의 사용으로만 달성된 규모이다.

Abstract: We present ORQ, a system that enables collaborative analysis of large private
datasets using cryptographically secure multi-party computation (MPC). ORQ
protects data against semi-honest or malicious parties and can efficiently
evaluate relational queries with multi-way joins and aggregations that have
been considered notoriously expensive under MPC. To do so, ORQ eliminates the
quadratic cost of secure joins by leveraging the fact that, in practice, the
structure of many real queries allows us to join records and apply the
aggregations "on the fly" while keeping the result size bounded. On the system
side, ORQ contributes generic oblivious operators, a data-parallel vectorized
query engine, a communication layer that amortizes MPC network costs, and a
dataflow API for expressing relational analytics -- all built from the ground
up.
  We evaluate ORQ in LAN and WAN deployments on a diverse set of workloads,
including complex queries with multiple joins and custom aggregations. When
compared to state-of-the-art solutions, ORQ significantly reduces MPC execution
times and can process one order of magnitude larger datasets. For our most
challenging workload, the full TPC-H benchmark, we report results entirely
under MPC with Scale Factor 10 -- a scale that had previously been achieved
only with information leakage or the use of trusted third parties.

</details>


### [5] [Automatic Generation of a Cryptography Misuse Taxonomy Using Large Language Models](https://arxiv.org/abs/2509.10814)
*Yang Zhang,Wenyi Ouyang,Yi Zhang,Liang Cheng,Chen Wu,Wenxin Hu*

Main category: cs.CR

TL;DR: 암호 API 오용(CAM)의 유행이 현대 시스템과 애플리케이션의 보안을 위협하고 있다. 본 연구에서는 대규모 언어 모델(LLM)을 활용하여 실제 코드에서 CAM을 자동으로 발견하고 분류하는 방법을 제안한다. 이 방법은 CAM 분류 체계의 개발과 지속적인 확장을 가능하게 하며, 3,492개의 실제 소프트웨어 프로그램 데이터 세트를 사용하여 LLM의 효과성을 입증하였다.


<details>
  <summary>Details</summary>
Motivation: 암호 API 오용의 유행이 암호화의 효과와 현대 시스템의 보안을 위협하고 있다.

Method: 공개된 암호 관련 데이터에 대해 훈련된 대규모 언어 모델을 활용하여 실제 코드에서 CAM을 자동으로 감지하고 분류하는 방법을 개발하였다.

Result: 3,492개의 실제 소프트웨어 프로그램에서 LLM의 효과성을 입증하였으며, 279개의 기본 CAM 카테고리를 포함하는 분류 체계를 생성하였다.

Conclusion: CAM 탐지 규칙을 기존 도구에 통합하면 도구의 탐지 능력이 향상된다.

Abstract: The prevalence of cryptographic API misuse (CAM) is compromising the
effectiveness of cryptography and in turn the security of modern systems and
applications. Despite extensive efforts to develop CAM detection tools, these
tools typically rely on a limited set of predefined rules from human-curated
knowledge. This rigid, rule-based approach hinders adaptation to evolving CAM
patterns in real practices.
  We propose leveraging large language models (LLMs), trained on publicly
available cryptography-related data, to automatically detect and classify CAMs
in real-world code to address this limitation. Our method enables the
development and continuous expansion of a CAM taxonomy, supporting developers
and detection tools in tracking and understanding emerging CAM patterns.
Specifically, we develop an LLM-agnostic prompt engineering method to guide
LLMs in detecting CAM instances from C/C++, Java, Python, and Go code, and then
classifying them into a hierarchical taxonomy.
  Using a data set of 3,492 real-world software programs, we demonstrate the
effectiveness of our approach with mainstream LLMs, including GPT, Llama,
Gemini, and Claude. It also allows us to quantitatively measure and compare the
performance of these LLMs in analyzing CAM in realistic code. Our evaluation
produced a taxonomy with 279 base CAM categories, 36 of which are not addressed
by existing taxonomies. To validate its practical value, we encode 11 newly
identified CAM types into detection rules and integrate them into existing
tools. Experiments show that such integration expands the tools' detection
capabilities.

</details>


### [6] [From Paradigm Shift to Audit Rift: Exploring Vulnerabilities and Audit Tips for TON Smart Contracts](https://arxiv.org/abs/2509.10823)
*Yury Yanovich,Sergey Sobolev,Yash Madhwal,Kirill Ziborov,Vladimir Gorgadze,Victoria Kovalevskay,Elizaveta Smirnova,Matvey Mishuris,Subodh Sharma*

Main category: cs.CR

TL;DR: 이 논문은 TON 스마트 계약을 위한 포괄적인 감사 체크리스트를 제시하며, 34개의 전문 감사 보고서 분석을 기반으로 한다.


<details>
  <summary>Details</summary>
Motivation: TON의 스마트 계약 개발 및 보안에서의 고유한 도전 과제를 해결하기 위해

Method: 233개의 실제 취약점이 포함된 감사 보고서를 분석하여 TON에 특화된 체크리스트를 개발

Result: 개발자와 감사자가 사용할 수 있는 실용적인 통찰을 제공하고, TON 스마트 계약의 취약점을 체계적으로 식별하고 완화할 수 있도록 하는 체크리스트를 제시함.

Conclusion: 이 체크리스트를 채택함으로써 TON 기반 프로젝트의 보안성과 신뢰성을 향상시킬 수 있다.

Abstract: The Open Network (TON) is a high-performance blockchain platform designed for
scalability and efficiency, leveraging an asynchronous execution model and a
multi-layered architecture. While TON's design offers significant advantages,
it also introduces unique challenges for smart contract development and
security. This paper introduces a comprehensive audit checklist for TON smart
contracts, based on an analysis of 34 professional audit reports containing 233
real-world vulnerabilities. The checklist addresses TON-specific challenges,
such as asynchronous message handling, and provides actionable insights for
developers and auditors. We also present detailed case studies of
vulnerabilities in TON smart contracts, highlighting their implications and
offering lessons learned. By adopting this checklist, developers and auditors
can systematically identify and mitigate vulnerabilities, enhancing the
security and reliability of TON-based projects. Our work bridges the gap
between Ethereum's mature audit methodologies and the emerging needs of the TON
ecosystem, fostering a more secure and robust blockchain environment.

</details>


### [7] [Large Language Models for Security Operations Centers: A Comprehensive Survey](https://arxiv.org/abs/2509.10858)
*Ali Habibzadeh,Farid Feyzi,Reza Ebrahimi Atani*

Main category: cs.CR

TL;DR: 대형 언어 모델(LLM)은 SOC에서의 통합 가능성을 탐구하여 사이버 보안의 현황을 조망한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 SOC의 사이버 보안 작업을 향상시킬 수 있는 가능성을 제시한다.

Method: LLM과 생성 AI의 SOC 워크플로 통합을 체계적으로 탐구한다.

Result: LLM의 활용이 사이버 보안 위협 감지 및 대응의 효율성을 높일 수 있음을 보여준다.

Conclusion: LLM의 SOC에서의 응용에 대한 상세한 연구로, 앞으로의 방향성을 제시한다.

Abstract: Large Language Models (LLMs) have emerged as powerful tools capable of
understanding and generating human-like text, offering transformative potential
across diverse domains. The Security Operations Center (SOC), responsible for
safeguarding digital infrastructure, represents one of these domains. SOCs
serve as the frontline of defense in cybersecurity, tasked with continuous
monitoring, detection, and response to incidents. However, SOCs face persistent
challenges such as high alert volumes, limited resources, high demand for
experts with advanced knowledge, delayed response times, and difficulties in
leveraging threat intelligence effectively. In this context, LLMs can offer
promising solutions by automating log analysis, streamlining triage, improving
detection accuracy, and providing the required knowledge in less time. This
survey systematically explores the integration of generative AI and more
specifically LLMs into SOC workflow, providing a structured perspective on its
capabilities, challenges, and future directions. We believe that this survey
offers researchers and SOC managers a broad overview of the current state of
LLM integration within academic study. To the best of our knowledge, this is
the first comprehensive study to examine LLM applications in SOCs in details.

</details>


### [8] [DMLDroid: Deep Multimodal Fusion Framework for Android Malware Detection with Resilience to Code Obfuscation and Adversarial Perturbations](https://arxiv.org/abs/2509.11187)
*Doan Minh Trung,Tien Duc Anh Hao,Luong Hoang Minh,Nghi Hoang Khoa,Nguyen Tan Cam,Van-Hau Pham,Phan The Duy*

Main category: cs.CR

TL;DR: 본 연구에서는 DMLDroid라는 다중 모달 융합 기반의 안드로이드 악성코드 탐지 기법을 제안하며, 악성코드 특징의 세 가지 서로 다른 표현 방식을 활용하여 높은 성능과 강한 강건성을 보임을 입증하였다.


<details>
  <summary>Details</summary>
Motivation: 최근 안드로이드 악성코드 탐지에서 학습 기반 방법이 크게 발전했으나, 현실 세계에서 강건성을 유지하는 데 어려움이 있다.

Method: DMLDroid는 권한 및 의도(표 형태), DEX 파일 표현(이미지 기반), API 호출(그래프 기반 시퀀스)의 세 가지 표현을 사용하여 다중 모달 융합을 활용하는 안드로이드 악성코드 탐지 방법이다.

Result: CICMalDroid 2020 데이터셋에서 우리의 다중 모달 접근법은 97.98% 정확도와 98.67% F1-score를 달성하였다.

Conclusion: 우리의 연구 결과는 진화하는 안드로이드 악성코드 위협에 대한 탐지 정확도와 강건성을 향상시키는 데 있어 다중 모달 융합의 이점을 강조한다.

Abstract: In recent years, learning-based Android malware detection has seen
significant advancements, with detectors generally falling into three
categories: string-based, image-based, and graph-based approaches. While these
methods have shown strong detection performance, they often struggle to sustain
robustness in real-world settings, particularly when facing code obfuscation
and adversarial examples (AEs). Deep multimodal learning has emerged as a
promising solution, leveraging the strengths of multiple feature types to
enhance robustness and generalization. However, a systematic investigation of
multimodal fusion for both accuracy and resilience remains underexplored. In
this study, we propose DMLDroid, an Android malware detection based on
multimodal fusion that leverages three different representations of malware
features, including permissions & intents (tabular-based), DEX file
representations (image-based), and API calls (graph-derived sequence-based). We
conduct exhaustive experiments independently on each feature, as well as in
combination, using different fusion strategies. Experimental results on the
CICMalDroid 2020 dataset demonstrate that our multimodal approach with the
dynamic weighted fusion mechanism achieves high performance, reaching 97.98%
accuracy and 98.67% F1-score on original malware detection. Notably, the
proposed method maintains strong robustness, sustaining over 98% accuracy and
98% F1-score under both obfuscation and adversarial attack scenarios. Our
findings highlight the benefits of multimodal fusion in improving both
detection accuracy and robustness against evolving Android malware threats.

</details>


### [9] [Realistic Environmental Injection Attacks on GUI Agents](https://arxiv.org/abs/2509.11250)
*Yitong Zhang,Ximo Li,Liyi Cai,Jia Li*

Main category: cs.CR

TL;DR: GUI 에이전트가 웹사이트와 상호작용하는 데 사용되지만, 환경적 주입 공격(EIA)에 취약하다.


<details>
  <summary>Details</summary>
Motivation: 이전 연구들은 공격자가 단일 트리거 이미지만 업로드하는 일반 사용자라는 가정을 더 현실적으로 설정하고자 했다.

Method: Chameleon이라는 공격 프레임워크를 제안하며, LLM 기반 환경 시뮬레이션과 주의력 블랙홀이라는 두 가지 주요 혁신을 포함한다.

Result: Chameleon은 6개의 현실적인 웹사이트와 4개의 LVLM 기반 GUI 에이전트에서 기존 방법보다 현저하게 우수한 성능을 보인다.

Conclusion: 이 연구는 현대 GUI 에이전트의 취약성을 드러내고 향후 방어 연구의 기초를 마련한다.

Abstract: GUI agents built on LVLMs are increasingly used to interact with websites.
However, their exposure to open-world content makes them vulnerable to
Environmental Injection Attacks (EIAs) that hijack agent behavior via webpage
elements. Many recent studies assume the attacker to be a regular user who can
only upload a single trigger image, which is more realistic than earlier
assumptions of website-level administrative control. However, these works still
fall short of realism: (1) the trigger's position and surrounding context
remain largely fixed between training and testing, failing to capture the
dynamic nature of real webpages and (2) the trigger often occupies an
unrealistically large area, whereas real-world images are typically small. To
better reflect real-world scenarios, we introduce a more realistic threat model
where the attacker is a regular user and the trigger image is small and
embedded within a dynamically changing environment. As a result, existing
attacks prove largely ineffective under this threat model.
  To better expose the vulnerabilities of GUI agents, we propose Chameleon, an
attack framework with two main novelties. The first is LLM-Driven Environment
Simulation, which automatically generates diverse and high-fidelity webpage
simulations. The second is Attention Black Hole, which transforms attention
weights into explicit supervisory signals that guide the agent's focus toward
the trigger region. We evaluate Chameleon on 6 realistic websites and 4
representative LVLM-powered GUI agents, where it significantly outperforms
existing methods. Ablation studies confirm that both novelties are critical to
performance. Our findings reveal underexplored vulnerabilities in modern GUI
agents and establish a robust foundation for future research on defense in
open-world GUI agent systems. The code is publicly available at
https://github.com/zhangyitonggg/attack2gui.

</details>


### [10] [Thunderhammer: Rowhammer Bitflips via PCIe and Thunderbolt (USB-C)](https://arxiv.org/abs/2509.11440)
*Robert Dumitru,Junpeng Wan,Daniel Genkin,Rick Kennell,Dave,Tian,Yuval Yarom*

Main category: cs.CR

TL;DR: 이 논문에서는 Thunderhammer라는 새로운 Rowhammer 공격 벡터를 제시하고, PCIe 또는 Thunderbolt를 통해 연결된 악의적 주변 장치에서 DRAM 비트 플립을 유도하는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: Rowhammer 기술은 메모리 보안 취약점을 드러내며, 다양한 액세스 패턴을 통해 공격할 수 있다.

Method: 사용자는 PCIe 요청을 기반으로하는 맞춤형 장치를 설계하여 PCIe 요청 스케줄링의 중요한 아키텍처 매개변수를 역설계하고 효과적인 해머링 접근 패턴을 실행한다.

Result: 최근 DDR4 시스템에서 PCIe 요청을 통해 드러나는 비트 플립을 성공적으로 증명하며, PCIe 슬롯 연결 및 Thunderbolt 포트를 통해 Rowhammer 공격을 수행함을 보여준다.

Conclusion: 이 연구는 Thunderhammer라는 새로운 공격 벡터를 사용하여 Rowhammer의 가능성을 확장하고, 메모리 안전성을 강화할 필요성을 강조한다.

Abstract: In recent years, Rowhammer has attracted significant attention from academia
and industry alike. This technique, first published in 2014, flips bits in
memory by repeatedly accessing neighbouring memory locations. Since its
discovery, researchers have developed a substantial body of work exploiting
Rowhammer and proposing countermeasures. These works demonstrate that Rowhammer
can be mounted not only through native code, but also via remote code
execution, such as JavaScript in browsers, and over networks.
  In this work, we uncover a previously unexplored Rowhammer vector. We present
Thunderhammer, an attack that induces DRAM bitflips from malicious peripherals
connected via PCIe or Thunderbolt (which tunnels PCIe). On modern DDR4 systems,
we observe that triggering bitflips through PCIe requests requires precisely
timed access patterns tailored to the target system. We design a custom device
to reverse engineer critical architectural parameters that shape PCIe request
scheduling, and to execute effective hammering access patterns. Leveraging this
knowledge, we successfully demonstrate Rowhammer-induced bitflips in DDR4
memory modules via both PCIe slot connections and Thunderbolt ports tunnelling
PCIe.

</details>


### [11] [MAUI: Reconstructing Private Client Data in Federated Transfer Learning](https://arxiv.org/abs/2509.11451)
*Ahaan Dabholkar,Atul Sharma,Z. Berkay Celik,Saurabh Bagchi*

Main category: cs.CR

TL;DR: MAUI는 모델 아키텍처나 가중치에 대한 명시적인 조작 없이 분류 헤드의 기울기를 이용해 입력 배치의 "강력한" 특성 표현을 추출하고 이를 원래 입력으로 변환하는 드래(DRA) 공격 기법이다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습에서 데이터 재구성 공격의 약점을 보완하고, 보다 효율적인 데이터 재구성을 목표로 한다.

Method: MAUI는 분류 헤드의 기울기를 사용하여 입력 배치의 '강력한' 특성 표현을 추출하고 이를 원래 입력으로 전환한다.

Result: CIFAR10과 ImageNet 데이터셋에서 다양한 모델 아키텍처에 대해 높은 정확도의 재구성을 보고하였으며, 이전 DRA보다 40-120% 높은 PSNR 점수를 달성하였다.

Conclusion: MAUI는 데이터 재구성의 품질에서 기존 DRA를 크게 능가하며, 활성 클라이언트에 의해 쉽게 탐지되지 않는 특징을 가진다.

Abstract: Recent works in federated learning (FL) have shown the utility of leveraging
transfer learning for balancing the benefits of FL and centralized learning. In
this setting, federated training happens after a stable point has been reached
through conventional training. Global model weights are first centrally
pretrained by the server on a public dataset following which only the last few
linear layers (the classification head) of the model are finetuned across
clients. In this scenario, existing data reconstruction attacks (DRAs) in FL
show two key weaknesses. First, strongly input-correlated gradient information
from the initial model layers is never shared, significantly degrading
reconstruction accuracy. Second, DRAs in which the server makes highly
specific, handcrafted manipulations to the model structure or parameters (for
e.g., layers with all zero weights, identity mappings and rows with identical
weight patterns) are easily detectable by an active client.
  Improving on these, we propose MAUI, a stealthy DRA that does not require any
overt manipulations to the model architecture or weights, and relies solely on
the gradients of the classification head. MAUI first extracts "robust" feature
representations of the input batch from the gradients of the classification
head and subsequently inverts these representations to the original inputs. We
report highly accurate reconstructions on the CIFAR10 and ImageNet datasets on
a variety of model architectures including convolution networks (CNN, VGG11),
ResNets (18, 50), ShuffleNet-V2 and Vision Transformer (ViT B-32), regardless
of the batch size. MAUI significantly outperforms prior DRAs in reconstruction
quality, achieving 40-120% higher PSNR scores.

</details>


### [12] [Cyber Attack Mitigation Framework for Denial of Service (DoS) Attacks in Fog Computing](https://arxiv.org/abs/2509.11668)
*Fizza Khurshid,Umara Noor,Zahid Rashid*

Main category: cs.CR

TL;DR: 사이버 보안 문제 해결을 위한 혁신적인 솔루션은 끊임없이 변화하는 사이버 위협 환경에 의해 형성된다. 이 논문은 자동화된 사이버 위협 완화를 위한 새로운 방법론을 제안하며, DDoS 공격을 위한 자동 사이버 위협 완화 프레임워크의 개발을 포함한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 위협 완화 자동화에 대한 학술 연구의 부족.

Method: DDoS 공격을 위한 자동 사이버 위협 완화 프레임워크의 개발, 다층 보안 접근 방식 사용, 및 안개 네트워크와 클라우드 컴퓨팅 활용.

Result: 사이버 보호 시스템의 포괄적인 구성, 통계 및 행동 분석을 통한 안개 탐지와 깊은 패킷 검사를 통해 공격 확인 및 완화.

Conclusion: 현재 사이버 보안 문제를 해결하고 미래 자동화 완화 접근 방식을 형성하는 데 있어 연구 프레임워크의 실용적 구현과 평가 전략을 강화한다.

Abstract: Innovative solutions to cyber security issues are shaped by the ever-changing
landscape of cyber threats. Automating the mitigation of these threats can be
achieved through a new methodology that addresses the domain of mitigation
automation, which is often overlooked. This literature overview emphasizes the
lack of scholarly work focusing specifically on automated cyber threat
mitigation, particularly in addressing challenges beyond detection. The
proposed methodology comprise of the development of an automatic cyber threat
mitigation framework tailored for Distributed Denial-of-Service (DDoS) attacks.
This framework adopts a multi-layer security approach, utilizing smart devices
at the device layer, and leveraging fog network and cloud computing layers for
deeper understanding and technological adaptability. Initially, firewall
rule-based packet inspection is conducted on simulated attack traffic to filter
out DoS packets, forwarding legitimate packets to the fog. The methodology
emphasizes the integration of fog detection through statistical and behavioral
analysis, specification-based detection, and deep packet inspection, resulting
in a comprehensive cyber protection system. Furthermore, cloud-level inspection
is performed to confirm and mitigate attacks using firewalls, enhancing
strategic defense and increasing robustness against cyber threats. These
enhancements enhance understanding of the research framework's practical
implementation and assessment strategies, substantiating its importance in
addressing current cyber security challenges and shaping future automation
mitigation approaches.

</details>


### [13] [Anomaly Detection in Industrial Control Systems Based on Cross-Domain Representation Learning](https://arxiv.org/abs/2509.11786)
*Dongyang Zhan,Wenqi Zhang,Lin Ye,Xiangzhan Yu,Hongli Zhang,Zheng He*

Main category: cs.CR

TL;DR: 본 논문은 산업 제어 시스템(ICS)에서 교차 도메인 표현 학습을 기반으로 한 이상 탐지 접근법을 제안하며, 이는 여러 도메인 행동의 공동 특징을 학습하고 다른 도메인 내에서 이상을 탐지할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 산업 제어 시스템의 보안과 안정성은 매우 중요하며, 공격을 받을 경우 심각한 피해를 초래할 수 있기 때문에 이상 탐지가 필수적이다.

Method: 교차 도메인 그래프를 구성하고, 그래프 신경망을 이용하여 다수의 도메인 행동의 공동 특징을 학습하며, 다중 과제 학습 접근법을 활용하여 각 도메인에서 이상을 식별한다.

Result: 제안한 접근법은 ICS 내 이상 식별에서 기존 접근법보다 더 나은 성능을 보여준다.

Conclusion: 교차 도메인 표현 학습을 통한 접근법이 ICS의 이상 탐지에 효과적임을 입증했다.

Abstract: Industrial control systems (ICSs) are widely used in industry, and their
security and stability are very important. Once the ICS is attacked, it may
cause serious damage. Therefore, it is very important to detect anomalies in
ICSs. ICS can monitor and manage physical devices remotely using communication
networks. The existing anomaly detection approaches mainly focus on analyzing
the security of network traffic or sensor data. However, the behaviors of
different domains (e.g., network traffic and sensor physical status) of ICSs
are correlated, so it is difficult to comprehensively identify anomalies by
analyzing only a single domain. In this paper, an anomaly detection approach
based on cross-domain representation learning in ICSs is proposed, which can
learn the joint features of multi-domain behaviors and detect anomalies within
different domains. After constructing a cross-domain graph that can represent
the behaviors of multiple domains in ICSs, our approach can learn the joint
features of them by leveraging graph neural networks. Since anomalies behave
differently in different domains, we leverage a multi-task learning approach to
identify anomalies in different domains separately and perform joint training.
The experimental results show that the performance of our approach is better
than existing approaches for identifying anomalies in ICSs.

</details>


### [14] [NeuroStrike: Neuron-Level Attacks on Aligned LLMs](https://arxiv.org/abs/2509.11864)
*Lichao Wu,Sasha Behrouzi,Mohamadreza Rostami,Maximilian Thang,Stjepan Picek,Ahmad-Reza Sadeghi*

Main category: cs.CR

TL;DR: NeuroStrike는alignment 기술의 본질적인 취약점을 이용하는 새로운 공격 프레임워크로, LLM에서 안전 메커니즘을 우회하여 유해한 출력을 생성할 수 있게 한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 윤리적 배치를 위한 안전 정렬이 중요하다.

Method: NeuroStrike는 희소하고 특수화된 안전 뉴런을 식별하고 삭제하는 방식으로 작동하며, 백박스 설정에서는 안전 뉴런의 전이 가능성을 이용하여 공격을 수행한다.

Result: NeuroStrike는 20개 이상의 LLM에서 평균 공격 성공률(ASR) 76.9%를 달성하며, 안전 뉴런의 전이는 다양한 아키텍처에서 효과적으로 작용한다.

Conclusion: NeuroStrike는 현재의 정렬 기술의 한계를 극복하고 LLM의 안전성을 저하시킬 수 있는 강력한 도구이다.

Abstract: Safety alignment is critical for the ethical deployment of large language
models (LLMs), guiding them to avoid generating harmful or unethical content.
Current alignment techniques, such as supervised fine-tuning and reinforcement
learning from human feedback, remain fragile and can be bypassed by carefully
crafted adversarial prompts. Unfortunately, such attacks rely on trial and
error, lack generalizability across models, and are constrained by scalability
and reliability.
  This paper presents NeuroStrike, a novel and generalizable attack framework
that exploits a fundamental vulnerability introduced by alignment techniques:
the reliance on sparse, specialized safety neurons responsible for detecting
and suppressing harmful inputs. We apply NeuroStrike to both white-box and
black-box settings: In the white-box setting, NeuroStrike identifies safety
neurons through feedforward activation analysis and prunes them during
inference to disable safety mechanisms. In the black-box setting, we propose
the first LLM profiling attack, which leverages safety neuron transferability
by training adversarial prompt generators on open-weight surrogate models and
then deploying them against black-box and proprietary targets. We evaluate
NeuroStrike on over 20 open-weight LLMs from major LLM developers. By removing
less than 0.6% of neurons in targeted layers, NeuroStrike achieves an average
attack success rate (ASR) of 76.9% using only vanilla malicious prompts.
Moreover, Neurostrike generalizes to four multimodal LLMs with 100% ASR on
unsafe image inputs. Safety neurons transfer effectively across architectures,
raising ASR to 78.5% on 11 fine-tuned models and 77.7% on five distilled
models. The black-box LLM profiling attack achieves an average ASR of 63.7%
across five black-box models, including the Google Gemini family.

</details>


### [15] [zkToken: Empowering Holders to Limit Revocation Checks for Verifiable Credentials](https://arxiv.org/abs/2509.11934)
*Praveensankar Manimaran,Mayank Raikwar,Thiago Garrett,Arlindo F. da Conceição,Leander Jehl,Roman Vitenberg*

Main category: cs.CR

TL;DR: 시간 제한의 지속적인 검증을 위한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 검증 가능 자격 증명을 관리하는 시스템이 증가하고 있지만, 유효성 모니터링으로 인해 개인 정보가 노출될 수 있는 문제 해결이 필요하다.

Method: 사용자가 검증자와 정보를 공유할 때 검증 기간을 개별적으로 설정하도록 하며, 이 기간 후에는 추적 불가능성을 보장한다. 취소된 자격 증명에 해당하는 토큰을 등록부에 저장하는 더 확장 가능한 블랙리스트 접근 방식을採用한다.

Result: 이론적으로 보안을 증명하고, 분석적 및 실험적으로 평가하여 홀더의 대역폭 소모를 크게 개선하고 다른 성능 지표에 대해 최신 솔루션과 동등함을 보여주었다.

Conclusion: 제안된 접근 방식은 검증 가능 자격 증명 관리에 대한 새로운 대안을 제공하며, 보안성과 성능 모두에서 매우 효과적이다.

Abstract: Systems managing Verifiable Credentials are becoming increasingly popular.
Unfortunately, their support for revoking previously issued credentials allows
verifiers to effectively monitor the validity of the credentials, which is
sensitive information. While the issue started to gain recognition, no adequate
solution has been proposed so far.
  In this work, we propose a novel framework for time-limited continuous
verification. The holder is able to individually configure the verification
period when sharing information with the verifier, and the system guarantees
proven untraceability of the revocation status after the verification period
expires. Different from existing systems, the implementation adopts a more
scalable blacklist approach where tokens corresponding to revoked credentials
are stored in the registry. The approach employs ZK proofs that allow holders
to prove non-membership in the blacklist. In addition to theoretically proving
security, we evaluate the approach analytically and experimentally and show
that it significantly improves bandwidth consumption on the holder while being
on par with state-of-the-art solutions with respect to the other performance
metrics.

</details>


### [16] [LOKI: Proactively Discovering Online Scam Websites by Mining Toxic Search Queries](https://arxiv.org/abs/2509.12181)
*Pujan Paudel,Gianluca Stringhini*

Main category: cs.CR

TL;DR: LOKI 시스템은 검색 엔진 쿼리를 사용하여 사기 웹사이트를 효과적으로 식별하는 방법을 제시하며, 이를 통해 발견률을 크게 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 온라인 이커머스 사기로 인한 재정적 피해를 줄이기 위한 효과적인 사기 웹사이트 탐지 방법이 필요하다.

Method: LOKI는 LUPI를 기반으로 하고 SERP에서 특징을 추출하는 키워드 평가 모델을 구현하여, 사기 웹사이트의 비율이 높은 검색 엔진 쿼리를 식별한다.

Result: LOKI는 10개 주요 사기 카테고리에서 기존의 휴리스틱 및 데이터 기반 기준에 비해 발견율이 20.58배 향상되었다.

Conclusion: LOKI는 이전에 보지 못한 사기 카테고리에 대해서도 일반화할 수 있어 새로운 위협을 식별하는 데 유용하다.

Abstract: Online e-commerce scams, ranging from shopping scams to pet scams, globally
cause millions of dollars in financial damage every year. In response, the
security community has developed highly accurate detection systems able to
determine if a website is fraudulent. However, finding candidate scam websites
that can be passed as input to these downstream detection systems is
challenging: relying on user reports is inherently reactive and slow, and
proactive systems issuing search engine queries to return candidate websites
suffer from low coverage and do not generalize to new scam types. In this
paper, we present LOKI, a system designed to identify search engine queries
likely to return a high fraction of fraudulent websites. LOKI implements a
keyword scoring model grounded in Learning Under Privileged Information (LUPI)
and feature distillation from Search Engine Result Pages (SERPs). We rigorously
validate LOKI across 10 major scam categories and demonstrate a 20.58 times
improvement in discovery over both heuristic and data-driven baselines across
all categories. Leveraging a small seed set of only 1,663 known scam sites, we
use the keywords identified by our method to discover 52,493 previously
unreported scams in the wild. Finally, we show that LOKI generalizes to
previously-unseen scam categories, highlighting its utility in surfacing
emerging threats.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [17] [Agent-based Simulation for Drone Charging in an Internet of Things Environment System](https://arxiv.org/abs/2509.10867)
*Leonardo Grando,José Roberto Emiliano Leite,Edson Luiz Ursini*

Main category: cs.MA

TL;DR: 드론 군집의 배터리 재충전을 조율하는 에이전트 기반 시뮬레이션 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: IoT 및 Industry 4.0 환경에서 드론 군집의 배터리 관리의 필요성이 증가하고 있다.

Method: 에이전트 기반 시뮬레이션 모델과 구체적인 시뮬레이션 방법론, 시스템 아키텍처 및 구현을 포함한다.

Result: 스마트 농업 사례를 통해 자율 조정 전략이 대규모 드론 배치에서 배터리 사용 및 미션 효율성을 최적화할 수 있음을 보여준다.

Conclusion: 기계 학습 기법을 사용하여 에이전트 기반 시뮬레이션의 민감도 분석 결과를 분석한다.

Abstract: This paper presents an agent-based simulation model for coordinating battery
recharging in drone swarms, focusing on applications in Internet of Things
(IoT) and Industry 4.0 environments. The proposed model includes a detailed
description of the simulation methodology, system architecture, and
implementation. One practical use case is explored: Smart Farming, highlighting
how autonomous coordination strategies can optimize battery usage and mission
efficiency in large-scale drone deployments. This work uses a machine learning
technique to analyze the agent-based simulation sensitivity analysis output
results.

</details>


### [18] [Statistical Model Checking of NetLogo Models](https://arxiv.org/abs/2509.10977)
*Marco Pangallo,Daniele Giachini,Andrea Vandin*

Main category: cs.MA

TL;DR: 이 논문은 NetLogo로 작성된 에이전트 기반 모델(ABMs)의 통계적 분석을 자동화하고 신뢰성을 보장하는 방법론을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 수학 모델로 표현하기 어려운 복잡한 시스템을 나타낼 수 있는 ABMs의 필요성이 증가하고 있으며, 이는 분석의 어려움을 초래합니다.

Method: 통계 모델 검증 분야에 기반한 방법론을 활용하여 NetLogo에서 작성된 ABMs의 분석 과정을 자동화합니다.

Result: MultiVeStA라는 도구를 통해 ABM 출력에 대한 통계적 검사를 수행하는 데 필요한 시간과 인간 개입을 크게 줄일 수 있음을 보여줍니다.

Conclusion: 이 도구 체인을 사용하면 NetLogo 모델에서 통계적 검사를 즉시 수행할 수 있어 ABM 출력의 분석을 보다 엄격하고 신뢰성 있게 만듭니다.

Abstract: Agent-based models (ABMs) are gaining increasing traction in several domains,
due to their ability to represent complex systems that are not easily
expressible with classical mathematical models. This expressivity and richness
come at a cost: ABMs can typically be analyzed only through simulation, making
their analysis challenging. Specifically, when studying the output of ABMs, the
analyst is often confronted with practical questions such as: (i) how many
independent replications should be run? (ii) how many initial time steps should
be discarded as a warm-up? (iii) after the warm-up, how long should the model
run? (iv) what are the right parameter values? Analysts usually resort to rules
of thumb and experimentation, which lack statistical rigor. This is mainly
because addressing these points takes time, and analysts prefer to spend their
limited time improving the model. In this paper, we propose a methodology,
drawing on the field of Statistical Model Checking, to automate the process and
provide guarantees of statistical rigor for ABMs written in NetLogo, one of the
most popular ABM platforms. We discuss MultiVeStA, a tool that dramatically
reduces the time and human intervention needed to run statistically rigorous
checks on ABM outputs, and introduce its integration with NetLogo. Using two
ABMs from the NetLogo library, we showcase MultiVeStA's analysis capabilities
for NetLogo ABMs, as well as a novel application to statistically rigorous
calibration. Our tool-chain makes it immediate to perform statistical checks
with NetLogo models, promoting more rigorous and reliable analyses of ABM
outputs.

</details>


### [19] [SafeDiver: Cooperative AUV-USV Assisted Diver Communication via Multi-agent Reinforcement Learning Approach](https://arxiv.org/abs/2509.11508)
*Tinglong Deng,Hang Tao,Xinxiang Wang,Yinyan Wang,Hanjiang Luo*

Main category: cs.MA

TL;DR: 잠수 활동 증가에 따라 수중 통신 서비스 수요가 증가하고 있으며, 이를 위해 무인 수륙 시스템을 활용한 신뢰할 수 있는 고속 통신 방안을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 수중 인간 활동의 증가로 인해 수중 통신 서비스의 수요가 크게 증가하고 있다.

Method: 해양 무인 시스템을 활용하여 잠수부의 활동 영역 변화에 따라 적응형 통신 서비스를 제공하도록 AUV에 광학 및 음향 다중 모드 통신 장치를 장착한 다수의 AUV이 협동적으로 이동할 수 있도록 다중 에이전트 강화 학습(MARL) 접근 방식을 사용하여 제어한다.

Result: 잠수부 간의 고속이고 신뢰할 수 있는 데이터 전송을 달성할 수 있으며, 무인 수상 차량(USV)을 표면 중계 노드로 활용하여 AUV로부터 정보를 조정하고 전달할 수 있다.

Conclusion: 시뮬레이션 검증을 통해 제안된 방안이 잠수부를 위한 신뢰할 수 있고 고속의 통신을 효과적으로 달성할 수 있음을 보여준다.

Abstract: As underwater human activities are increasing, the demand for underwater
communication service presents a significant challenge. Existing underwater
diver communication methods face hurdles due to inherent disadvantages and
complex underwater environments. To address this issue, we propose a scheme
that utilizes maritime unmanned systems to assist divers with reliable and
high-speed communication. Multiple AUVs are equipped with optical and acoustic
multimodal communication devices as relay nodes, providing adaptive
communication services based on changes in the diver's activity area. By using
a multi-agent reinforcement learning (MARL) approach to control the cooperative
movement of AUVs, high-speed and reliable data transmission between divers can
be achieved. At the same time, utilizing the advantages of on-demand deployment
and wide coverage of unmanned surface vehicles (USVs) as surface relay nodes to
coordinate and forward information from AUVs, and controlling AUVs to
adaptively select relay USV nodes for data transmission, high-quality
communication between divers and surface platform can be achieved. Through
simulation verification, the proposed scheme can effectively achieve reliable
and high-speed communication for divers.

</details>


### [20] [MALLM: Multi-Agent Large Language Models Framework](https://arxiv.org/abs/2509.11656)
*Jonas Becker,Lars Benedikt Kaesberg,Niklas Bauer,Jan Philip Wahle,Terry Ruas,Bela Gipp*

Main category: cs.MA

TL;DR: MALLM은 다중 에이전트 토론(MAD)의 구성 요소를 체계적으로 분석할 수 있도록 하는 오픈 소스 프레임워크로, 144개 이상의 고유한 MAD 구성을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 다중 에이전트 토론 프레임워크는 도구 사용에 초점을 맞추거나 통합된 평가가 부족하며, 에이전트 페르소나, 응답 생성기, 토론 패러다임 및 결정 프로토콜의 구성이 제한적입니다.

Method: MALLM은 에이전트 페르소나, 응답 생성기, 토론 패러다임 및 결정 프로토콜을 포함한 144개 이상의 고유한 구성을 제공하고, 구성 파일을 사용하여 토론을 정의합니다.

Result: MALLM은 텍스트 기반 Huggingface 데이터셋을 불러올 수 있으며, MAD 구성 간의 손쉬운 비교를 위한 평가 파이프라인을 제공합니다.

Conclusion: MALLM은 연구자들을 위해 설계되어 다중 에이전트 토론의 핵심을 이해할 수 있는 기회를 제공합니다.

Abstract: Multi-agent debate (MAD) has demonstrated the ability to augment collective
intelligence by scaling test-time compute and leveraging expertise. Current
frameworks for multi-agent debate are often designed towards tool use, lack
integrated evaluation, or provide limited configurability of agent personas,
response generators, discussion paradigms, and decision protocols. We introduce
MALLM (Multi-Agent Large Language Models), an open-source framework that
enables systematic analysis of MAD components. MALLM offers more than 144
unique configurations of MAD, including (1) agent personas (e.g., Expert,
Personality), (2) response generators (e.g., Critical, Reasoning), (3)
discussion paradigms (e.g., Memory, Relay), and (4) decision protocols (e.g.,
Voting, Consensus). MALLM uses simple configuration files to define a debate.
Furthermore, MALLM can load any textual Huggingface dataset (e.g., MMLU-Pro,
WinoGrande) and provides an evaluation pipeline for easy comparison of MAD
configurations. MALLM is tailored towards researchers and provides a window
into the heart of multi-agent debate, facilitating the understanding of its
components and their interplay.

</details>


### [21] [Nash Equilibrium and Belief Evolution in Differential Games](https://arxiv.org/abs/2509.11739)
*Jiangjing Zhou,Ovanes Petrosian,Ye Zhang,Hongwei Gao*

Main category: cs.MA

TL;DR: 본 연구는 연속시간 환경에서의 운동 보상 불확실성을 가진 차별적 게임을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 플레이어들이 불확실한 파라미터에 대한 신념을 연속 베이지안 업데이트를 통해 갱신하는 방법을 제안하고, 이를 바탕으로 게임 이론을 탐구하고자 하였습니다.

Method: 핵심 확률 정리를 활용한 이론적 증명을 통해 플레이어의 신념이 진정한 파라미터 값으로 수렴하고, 내쉬 균형 전략을 도출하는 방법을 보여줍니다.

Result: 연속 베이지안 업데이트를 통한 내쉬 균형 전략의 수렴을 입증하고 오염 통제 게임의 맥락에서 플레이어의 추정치가 작은 시간 간격에서 수렴함을 확인했습니다.

Conclusion: 결과적으로 연속 및 동적 베이지안 업데이트의 효율성을 강조하였으며, 이는 장기적인 추정에서 안정성과 정확성을 보장합니다.

Abstract: This study investigates differential games with motion-payoff uncertainty in
continuous-time settings. We propose a framework where players update their
beliefs about uncertain parameters using continuous Bayesian updating.
Theoretical proofs leveraging key probability theorems demonstrate that
players' beliefs converge to the true parameter values, ensuring stability and
accuracy in long-term estimations. We further derive Nash Equilibrium
strategies with continuous Bayesian updating for players, emphasizing the role
of belief updates in decision-making processes. Additionally, we establish the
convergence of Nash Equilibrium strategies with continuous Bayesian updating.
The efficacy of both continuous and dynamic Bayesian updating is examined in
the context of pollution control games, showing convergence in players'
estimates under small time intervals in discrete scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [22] [A Service-Oriented Adaptive Hierarchical Incentive Mechanism for Federated Learning](https://arxiv.org/abs/2509.10512)
*Jiaxing Cao,Yuzhou Gao,Jiwei Huang*

Main category: cs.LG

TL;DR: 이 논문에서는 연합 학습에서 참가자들의 효용을 극대화하기 위한 적응형 인센티브 메커니즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습이 분산 모델 훈련을 위한 새로운 프레임워크로 떠오르고 있으나, 훈련 데이터 부족 문제로 어려움을 겪는 경우가 있어 이를 해결해야 한다.

Method: LMO(로컬 모델 소유자)와 TP(태스크 게시자) 간의 Stackelberg 게임을 이론적으로 구축하고, Nash 평형 솔루션을 도출하여 LMOs와 TP의 효용을 극대화한다. MAMDP를 통해 LMOs와 작업자 간의 상호작용을 모델링하고, DRL을 이용하여 최적의 전략을 식별한다.

Result: 제안된 방법의 유효성을 검증하기 위해 광범위한 수치 실험을 수행하였다.

Conclusion: 각 참가자의 전략을 안정화하고 결합 문제를 해결하는 ASOSA 알고리즘을 설계하여 성공적인 결과를 얻었다.

Abstract: Recently, federated learning (FL) has emerged as a novel framework for
distributed model training. In FL, the task publisher (TP) releases tasks, and
local model owners (LMOs) use their local data to train models. Sometimes, FL
suffers from the lack of training data, and thus workers are recruited for
gathering data. To this end, this paper proposes an adaptive incentive
mechanism from a service-oriented perspective, with the objective of maximizing
the utilities of TP, LMOs and workers. Specifically, a Stackelberg game is
theoretically established between the LMOs and TP, positioning TP as the leader
and the LMOs as followers. An analytical Nash equilibrium solution is derived
to maximize their utilities. The interaction between LMOs and workers is
formulated by a multi-agent Markov decision process (MAMDP), with the optimal
strategy identified via deep reinforcement learning (DRL). Additionally, an
Adaptively Searching the Optimal Strategy Algorithm (ASOSA) is designed to
stabilize the strategies of each participant and solve the coupling problems.
Extensive numerical experiments are conducted to validate the efficacy of the
proposed method.

</details>


### [23] [Mixture-of-Clustered-Experts: Advancing Expert Specialization and Generalization in Instruction Tuning](https://arxiv.org/abs/2509.10513)
*Sugyeong Eo,Jungjun Lee,Chanjun Park,Heuiseok Lim*

Main category: cs.LG

TL;DR: Mixture-of-Clustered-Experts (MoCE)는 MoE의 성능 및 일반화 문제를 해결하기 위해 제안된 이중 단계 라우팅 메커니즘을 활용한다.


<details>
  <summary>Details</summary>
Motivation: 전문가 전문화 향상을 통한 MoE 성능 및 일반화 개선의 필요성.

Method: 이중 단계 라우팅 메커니즘을 통해 첫 번째 단계에서 시퀀스 수준의 특징을 기반으로 전문가 그룹 라우팅을 수행하고, 두 번째 단계에서는 그룹 내에서 가장 높은 k개의 전문가를 활성화한다.

Result: 다양한 벤치마크에서 MoCE가 강력한 기초 모델들보다 일관되게 우수한 성과를 보여주었다.

Conclusion: MoCE의 견고함과 효과성이 입증되었다.

Abstract: A sparse Mixture-of-Experts (MoE) architecture has emerged as a highly
scalable solution by conditionally activating sub-modules without a
proportional increase in computational costs. However, improving expert
specialization to enhance performance and generalization remains a challenge
for MoE, especially in instruction tuning scenarios characterized by
significant input heterogeneity. In this work, we propose the
Mixture-of-Clustered-Experts (MoCE) to address this limitation through a
dual-stage routing mechanism. The first stage in the mechanism performs expert
group routing based on sequence-level features, while the second stage
activates the top-$k$ experts within the group at the token level. This
approach enables the effective partitioning of heterogeneous inputs based on
their knowledge requirements, encouraging expert group specialization while
maintaining the advantages of token-level routing. We evaluate MoCE across a
comprehensive set of benchmarks, demonstrating its consistent superiority over
strong baselines and its enhanced generalization capabilities. Detailed
analysis further highlights the robustness and effectiveness of MoCE.

</details>


### [24] [Holographic Knowledge Manifolds: A Novel Pipeline for Continual Learning Without Catastrophic Forgetting in Large Language Models](https://arxiv.org/abs/2509.10518)
*Justin Arndt*

Main category: cs.LG

TL;DR: Holographic Knowledge Manifold(HKM)는 AI 지식 표현에서 제로 재앙적 망각을 달성하는 네 단계 파이프라인으로, 메모리 증가를 최소화하고 효율성을 유지한다. HKM은 지식 기초를 3배 압축하고 67% 저장 공간을 절약하며, 100% 홀로그램 통합을 지원한다.


<details>
  <summary>Details</summary>
Motivation: AI 지식 표현의 효율성을 높이기 위해

Method: 프랙탈 양자화, 확률적 얽힘, 동적 회절 칩을 활용하여 HKM을 개발하였다.

Result: 산업 최고의 성능을 달성하며, 0% 망각과 3배 압축을 이루었고, 소비자 GPU 하드웨어에서 53% 훈련 시간 단축을 보였다.

Conclusion: HKM은 대형 언어 모델의 패러다임 전환을 가정하며, 재교육 없이 '영원한' 적응을 가능하게 한다.

Abstract: We introduce the Holographic Knowledge Manifold (HKM), a four-phase pipeline
that achieves zero catastrophic forgetting in AI knowledge representation while
maintaining minimal memory growth and high efficiency. Leveraging fractal
quantization, probabilistic entanglement, and dynamic diffraction chipping, HKM
compresses knowledge substrates by 3x with 67% storage savings, integrates
holographically at 100%, and supports over 1,020 updates with 1% growth per
increment. In experiments on combined WikiText and FB15k datasets (scaled to
2,997 nodes), we demonstrate industry-leading performance: 0% forgetting
(infinite improvement over GEM baselines), 3x compression, and 53% training
time reduction on consumer GPU hardware. Hypothetical cost analyses project
$92.4M savings over 5 years at petabyte scale, with 21.2% energy reduction and
33% lower carbon footprint. This work hypothesizes a paradigm shift for public
large language models (LLMs), enabling "eternal" adaptation without retraining.
Future extensions to multimodal fusion and quantum hardware could further
democratize scalable AI, potentially reducing fine-tuning costs by 60-80% for
models like Llama-3 or Grok-4. Code, datasets, and full results are publicly
available for reproducibility.

</details>


### [25] [Resource-Aware Neural Network Pruning Using Graph-based Reinforcement Learning](https://arxiv.org/abs/2509.10526)
*Dieter Balemans,Thomas Huybrechts,Jan Steckel,Siegfried Mercelis*

Main category: cs.LG

TL;DR: 이 논문은 AutoML 프레임워크에 그래프 기반 관찰 공간을 통합한 신경망 가지치기 접근 방식을 제시하여 기존 방법의 한계를 극복한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 가지치기 접근 방식은 종종 수작업으로 제작된 휴리스틱과 지역 최적화 관점에 의존하여 비효율적인 가지치기 전략과 최적이 아닌 성능으로 이어질 수 있다.

Method: 우리의 프레임워크는 층과 채널 간의 전체적인 위상 관계를 포착하는 대상 신경망의 그래프 표현을 도입하여 가지치기 과정을 변형하며, 제한된 층별 관찰 공간을 네트워크 구조에 대한 전반적인 관점으로 대체한다. 핵심 혁신에는 네트워크의 그래프 표현을 처리하고 풍부한 임베딩을 생성하는 그래프 주의 네트워크(GAT) 인코더가 포함된다. 또한, 우리는 연속 가지치기 비율에서 세밀한 이진 동작 공간으로 전환하여 에이전트가 사전 정의된 점수 함수에서 벗어나 데이터에서 직접 최적의 채널 중요도 기준을 학습할 수 있게 한다.

Result: CIFAR-10, CIFAR-100, ImageNet과 같은 벤치마크 데이터 세트에 대한 광범위한 실험을 통해 우리 접근 방식의 효과를 입증한다. 실험 결과, 우리의 방법이 전통적인 가지치기 기술보다 일관되게 우수한 성능을 보이며 함수적으로 중복된 연결을 식별하는 작업별 가지치기 전략을 학습하면서 최첨단 결과를 나타낸다.

Conclusion: 우리의 접근 방식은 에이전트가 정의된 제약 조건을 만족하면서 밀접한 경쟁 보상 시스템을 통해 이전 최고의 성능을 초과하도록 격려한다.

Abstract: This paper presents a novel approach to neural network pruning by integrating
a graph-based observation space into an AutoML framework to address the
limitations of existing methods. Traditional pruning approaches often depend on
hand-crafted heuristics and local optimization perspectives, which can lead to
suboptimal performance and inefficient pruning strategies. Our framework
transforms the pruning process by introducing a graph representation of the
target neural network that captures complete topological relationships between
layers and channels, replacing the limited layer-wise observation space with a
global view of network structure. The core innovations include a Graph
Attention Network (GAT) encoder that processes the network's graph
representation and generates a rich embedding. Additionally, for the action
space we transition from continuous pruning ratios to fine-grained binary
action spaces which enables the agent to learn optimal channel importance
criteria directly from data, moving away from predefined scoring functions.
These contributions are modelled within a Constrained Markov Decision Process
(CMDP) framework, allowing the agent to make informed pruning decisions while
adhering to resource constraints such as target compression rates. For this, we
design a self-competition reward system that encourages the agent to outperform
its previous best performance while satisfying the defined constraints. We
demonstrate the effectiveness of our approach through extensive experiments on
benchmark datasets including CIFAR-10, CIFAR-100, and ImageNet. The experiments
show that our method consistently outperforms traditional pruning techniques,
showing state-of-the-art results while learning task-specific pruning
strategies that identify functionally redundant connections beyond simple
weight magnitude considerations.

</details>


### [26] [FinXplore: An Adaptive Deep Reinforcement Learning Framework for Balancing and Discovering Investment Opportunities](https://arxiv.org/abs/2509.10531)
*Himanshu Choudhary,Arishi Orra,Manoj Thakur*

Main category: cs.LG

TL;DR: 이 연구는 기존 자산 활용과 새로운 투자 기회 탐색을 통합하는 포트폴리오 최적화 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 재무 의사 결정에서 위험과 수익의 균형을 맞추기 위해 포트폴리오 최적화가 필수적이다.

Method: 두 개의 심층 강화 학습(DRL) 에이전트를 활용하여 기존 투자 우주 내 자산 할당과 확장된 우주에서의 새로운 기회 탐색을 동적으로 균형을 맞춘다.

Result: 실제 시장 데이터 세트를 사용하여 제안된 방법론의 효율성을 평가한 결과, 최첨단 포트폴리오 전략 및 기준 방법에 비해 우수한 성능을 보였다.

Conclusion: 이 연구는 진화하는 시장에 적응하면서 포트폴리오 성과를 향상시키기 위해 두 가지 목표 간의 균형을 동적으로 조절하는 방법을 제시한다.

Abstract: Portfolio optimization is essential for balancing risk and return in
financial decision-making. Deep Reinforcement Learning (DRL) has stood out as a
cutting-edge tool for portfolio optimization that learns dynamic asset
allocation using trial-and-error interactions. However, most DRL-based methods
are restricted to allocating assets within a pre-defined investment universe
and overlook exploring new opportunities. This study introduces an investment
landscape that integrates exploiting existing assets with exploring new
investment opportunities in an extended universe. The proposed approach
leverages two DRL agents and dynamically balances these objectives to adapt to
evolving markets while enhancing portfolio performance. One agent allocates
assets within the existing universe, while another assists in exploring new
opportunities in the extended universe. The effciency of the proposed
methodology is determined using two real-world market data sets. The
experiments demonstrate the superiority of the suggested approach against the
state-of-the-art portfolio strategies and baseline methods.

</details>


### [27] [SME-TEAM: Leveraging Trust and Ethics for Secure and Responsible Use of AI and LLMs in SMEs](https://arxiv.org/abs/2509.10594)
*Iqbal H. Sarker,Helge Janicke,Ahmad Mohsin,Leandros Maglaras*

Main category: cs.LG

TL;DR: 본 논문은 중소기업에서 인공지능의 안전하고 책임 있는 사용을 위한 신뢰 및 윤리 원칙을 AI 생애주기 전반에 통합하는 구조화된 다단계 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI와 대형 언어 모델의 도입이 중소기업에서 기술적, 윤리적, 신뢰 문제를 야기하기 때문에

Method: 데이터, 알고리즘, 인간 감시, 모델 아키텍처의 네 가지 기둥을 중심으로 한 구조화된 프레임워크를 제안한다.

Result: 이 프레임워크는 이론적 윤리 원칙과 운영적 실천을 연계하며, 중소기업의 다양한 AI 응용분야에서 AI 능력을 향상시킨다.

Conclusion: 결국, 본 논문은 책임 있는 AI 채택을 위한 구조화된 로드맵을 제공하며, 중소기업의 회복력, 경쟁력 및 지속 가능한 혁신을 위한 신뢰와 윤리를 촉매제로 자리매김한다.

Abstract: Artificial Intelligence (AI) and Large Language Models (LLMs) are reshaping
today's business practices, however, their adoption within small and
medium-sized enterprises (SMEs) raises significant technical, ethical and trust
issues. This paper proposes a structured, multi-phased framework designed to
embed trust and ethical principles throughout the AI lifecycle for their secure
and responsible use in SMEs. Structured around four pillars, i.e., Data,
Algorithms, Human oversight, and Model Architecture, the framework bridges
theoretical ethical principles with operational practice, enhancing AI
capabilities in diverse SME applications. Ultimately, this paper offers a
structured roadmap for responsible AI adoption, framing trust and ethics as a
catalyst for resilience, competitiveness, and sustainable innovation in SMEs.

</details>


### [28] [Test-Time Warmup for Multimodal Large Language Models](https://arxiv.org/abs/2509.10641)
*Nikita Rajaneesh,Thomas Zollo,Richard Zemel*

Main category: cs.LG

TL;DR: MLLMs는 텍스트와 이미지의 교차점에서 고급 추론을 가능하게 하지만, 제한된 데이터로 인해 그 잠재력을 충분히 발휘하지 못하고 있다. 본 연구에서는 테스트 인스턴스에 맞춰 MLLM을 조정하는 Test-Time Warmup 방법을 제안하며, 이를 통해 MLLM의 성능을 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: MLLMs의 잠재력을 최대한 발휘하기 위한 새로운 접근 방식 필요.

Method: 테스트 인스턴스 별로 MLLM을 조정하는 Test-Time Warmup 방법을 제안하고, 약하게 감독된 보조 작업의 데이터를 활용한다.

Result: Llama-Vision-Instruct 모델에서 MMMU에서 4.03%, VQA-Rad에서 5.28%, GQA에서 1.63%의 성능 향상을 관찰했다.

Conclusion: 추론 전 '워밍업'을 통해 다양한 추론 작업에서 MLLMs의 강 robustness가 향상됨을 입증했다.

Abstract: Multimodal Large Language Models (MLLMs) hold great promise for advanced
reasoning at the intersection of text and images, yet they have not fully
realized this potential. MLLMs typically integrate an LLM, a vision encoder,
and a connector that maps the vision encoder's embeddings into the LLM's text
embedding space. Although each component is pretrained on massive datasets with
billions of samples, the entire multimodal model is typically trained on only
thousands (or a few million) samples, which can result in weak performance on
complex reasoning tasks. To address these shortcomings, instead of relying on
extensive labeled datasets for fine-tuning, we propose a Test-Time Warmup
method that adapts the MLLM per test instance by leveraging data from weakly
supervised auxiliary tasks. With our approach, we observe a relative
performance improvement of 4.03% on MMMU, 5.28% on VQA-Rad, and 1.63% on GQA on
the Llama-Vision-Instruct model. Our method demonstrates that 'warming up'
before inference can enhance MLLMs' robustness across diverse reasoning tasks.

</details>


### [29] [Self-Supervised Goal-Reaching Results in Multi-Agent Cooperation and Exploration](https://arxiv.org/abs/2509.10656)
*Chirayu Nimonkar,Shlok Shah,Catherine Ji,Benjamin Eysenbach*

Main category: cs.LG

TL;DR: 자율 에이전트 그룹이 특정 목표를 달성하기 위해 협력 및 장기적 추론이 필요하며, 이를 위한 보상 함수 설계는 어려운 문제이다.


<details>
  <summary>Details</summary>
Motivation: 자율 에이전트가 협력하여 목표를 달성하도록 유도하는 보상 함수 설계의 어려움을 해결하고 그들을 돕기 위해.

Method: 자기 지도 목표 도달 기술을 활용하여 에이전트가 특정 목표를 방문할 가능성을 극대화하는 방식으로 협력을 유도하는 방법을 제안.

Result: 제안한 방법은 동일한 희소한 보상 신호를 사용하는 대체 접근법보다 MARL 벤치마크에서 더 나은 성능을 보여주었다.

Conclusion: 제안된 방법은 탐색 메커니즘이 명시적으로 포함되어 있지 않음에도 불구하고, 자기 지도 다중 에이전트 목표 도달이 대체 접근법이 성공적인 시도를 전혀 경험하지 못하는 환경에서 협력과 탐색을 이끌어낸다는 것을 관찰했다.

Abstract: For groups of autonomous agents to achieve a particular goal, they must
engage in coordination and long-horizon reasoning. However, designing reward
functions to elicit such behavior is challenging. In this paper, we study how
self-supervised goal-reaching techniques can be leveraged to enable agents to
cooperate. The key idea is that, rather than have agents maximize some scalar
reward, agents aim to maximize the likelihood of visiting a certain goal. This
problem setting enables human users to specify tasks via a single goal state
rather than implementing a complex reward function. While the feedback signal
is quite sparse, we will demonstrate that self-supervised goal-reaching
techniques enable agents to learn from such feedback. On MARL benchmarks, our
proposed method outperforms alternative approaches that have access to the same
sparse reward signal as our method. While our method has no explicit mechanism
for exploration, we observe that self-supervised multi-agent goal-reaching
leads to emergent cooperation and exploration in settings where alternative
approaches never witness a single successful trial.

</details>


### [30] [CrunchLLM: Multitask LLMs for Structured Business Reasoning and Outcome Prediction](https://arxiv.org/abs/2509.10698)
*Rabeya Tus Sadia,Qiang Cheng*

Main category: cs.LG

TL;DR: 스타트업의 성공 예측을 위해 CrunchLLM이라는 도메인 적응형 LLM 프레임워크를 제안하며, 이는 구조적 속성과 비구조적 텍스트를 통합하여 80% 이상의 정확도를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 스타트업 기업의 성공 예측은 창업과 혁신 연구에서 중요한 문제이다.

Method: CrunchLLM은 구조적 기업 속성과 비구조적 텍스트 내러티브를 통합하고, 파라미터 효율적인 미세 조정 전략과 프롬프트 최적화를 적용하여 창업 데이터에 맞게 기초 모델을 전문화한다.

Result: Crunchbase 스타트업 성공 예측에서 80% 이상의 정확도를 달성하며, 전통적인 분류기와 LLM을 능가한다.

Conclusion: CrunchLLM은 도메인 인식 미세 조정과 구조적-비구조적 데이터 융합을 통해 기업가적 결과 예측 모델링을 발전시킬 수 있음을 보여준다.

Abstract: Predicting the success of start-up companies, defined as achieving an exit
through acquisition or IPO, is a critical problem in entrepreneurship and
innovation research. Datasets such as Crunchbase provide both structured
information (e.g., funding rounds, industries, investor networks) and
unstructured text (e.g., company descriptions), but effectively leveraging this
heterogeneous data for prediction remains challenging. Traditional machine
learning approaches often rely only on structured features and achieve moderate
accuracy, while large language models (LLMs) offer rich reasoning abilities but
struggle to adapt directly to domain-specific business data. We present
\textbf{CrunchLLM}, a domain-adapted LLM framework for startup success
prediction. CrunchLLM integrates structured company attributes with
unstructured textual narratives and applies parameter-efficient fine-tuning
strategies alongside prompt optimization to specialize foundation models for
entrepreneurship data. Our approach achieves accuracy exceeding 80\% on
Crunchbase startup success prediction, significantly outperforming traditional
classifiers and baseline LLMs. Beyond predictive performance, CrunchLLM
provides interpretable reasoning traces that justify its predictions, enhancing
transparency and trustworthiness for financial and policy decision makers. This
work demonstrates how adapting LLMs with domain-aware fine-tuning and
structured--unstructured data fusion can advance predictive modeling of
entrepreneurial outcomes. CrunchLLM contributes a methodological framework and
a practical tool for data-driven decision making in venture capital and
innovation policy.

</details>


### [31] [Neurosymbolic AI Transfer Learning Improves Network Intrusion Detection](https://arxiv.org/abs/2509.10850)
*Huynh T. T. Tran,Jacob Sander,Achraf Cohen,Brian Jalaian,Nathaniel D. Bastian*

Main category: cs.LG

TL;DR: 이 논문에서는 사이버 보안 분야의 네트워크 침입 탐지 시스템을 위한 혁신적인 신경 기호 AI 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 분야에서 전이 학습의 활용 가능성을 탐색하고, 효율적인 침입 탐지 시스템을 설계하기 위해.

Method: 전이 학습과 불확실성 정량화를 활용한 신경 기호 AI 프레임워크를 제안한다.

Result: 대규모의 잘 구조화된 데이터셋에서 훈련된 전이 학습 모델이 작은 데이터셋에 의존하는 신경 기반 모델보다 성능이 우수함을 발견했다.

Conclusion: 이 연구는 사이버 보안 솔루션의 새로운 시대를 여는 길을 제시한다.

Abstract: Transfer learning is commonly utilized in various fields such as computer
vision, natural language processing, and medical imaging due to its impressive
capability to address subtasks and work with different datasets. However, its
application in cybersecurity has not been thoroughly explored. In this paper,
we present an innovative neurosymbolic AI framework designed for network
intrusion detection systems, which play a crucial role in combating malicious
activities in cybersecurity. Our framework leverages transfer learning and
uncertainty quantification. The findings indicate that transfer learning
models, trained on large and well-structured datasets, outperform neural-based
models that rely on smaller datasets, paving the way for a new era in
cybersecurity solutions.

</details>


### [32] [Machine Learning Framework for Audio-Based Equipment Condition Monitoring: A Comparative Study of Classification Algorithms](https://arxiv.org/abs/2509.11075)
*Srijesh Pillai,Yodhin Agarwal,Zaheeruddin Ahmed*

Main category: cs.LG

TL;DR: 이 논문은 오디오 기반 장비 상태 모니터링을 위한 체계적이고 통계적으로 엄격한 기계 학습 모델 평가 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 오디오 기반 장비 상태 모니터링은 알고리즘 선택을 위한 표준화된 방법론 부족으로 인해 재현 가능한 연구에 어려움을 겪고 있습니다.

Method: 시간, 주파수 및 시간-주파수 도메인에서 127개의 특징 집합을 활용하여 우리 방법론은 합성 및 실제 데이터세트에서 검증되었습니다.

Result: 결과는 앙상블 방법이 우수한 성능(94.2% 정확도, 0.942 F1 점수)을 달성했음을 보여주며, 통계적 테스트를 통해 개별 알고리즘보다 8-15%의 유의미한 성능 향상을 확인했습니다.

Conclusion: 궁극적으로 이 연구는 산업 환경에서 강력한 모니터링 솔루션을 선택하기 위한 검증된 벤치마킹 프로토콜과 실용적인 가이드를 제공합니다.

Abstract: Audio-based equipment condition monitoring suffers from a lack of
standardized methodologies for algorithm selection, hindering reproducible
research. This paper addresses this gap by introducing a comprehensive
framework for the systematic and statistically rigorous evaluation of machine
learning models. Leveraging a rich 127-feature set across time, frequency, and
time-frequency domains, our methodology is validated on both synthetic and
real-world datasets. Results demonstrate that an ensemble method achieves
superior performance (94.2% accuracy, 0.942 F1-score), with statistical testing
confirming its significant outperformance of individual algorithms by 8-15%.
Ultimately, this work provides a validated benchmarking protocol and practical
guidelines for selecting robust monitoring solutions in industrial settings.

</details>


### [33] [GCN-TULHOR: Trajectory-User Linking Leveraging GCNs and Higher-Order Spatial Representations](https://arxiv.org/abs/2509.11095)
*Khoa Tran,Pranav Gupta,Manos Papagelis*

Main category: cs.LG

TL;DR: 이 논문에서는 익명화된 이동 경로를 사용자와 연결하는 GCN-TULHOR 방법을 제안합니다. 이 방법은 데이터 희소성을 줄이고 공간적 의미를 증대시킵니다.


<details>
  <summary>Details</summary>
Motivation: TUL은 개인화된 추천, 프라이버시를 보존하는 분석 및 안전한 위치 기반 서비스에 필수적입니다.

Method: GCN-TULHOR는 육각형 타일링을 사용하여 원시 위치 데이터를 고차 이동 흐름 표현으로 변환하고, 그래프 컨볼루션 네트워크를 통합합니다.

Result: 실험 결과는 정확도, 정밀도, 재현율, F1 점수에서 고전적 기준선 및 RNN, Transformer 기반 모델보다 일관된 개선을 보여줍니다.

Conclusion: 이 연구는 그래프 기반 공간 학습과 순차적 모델링을 결합한 가치와 TUL에 대한 강력하고 확장 가능한 솔루션을 제시합니다.

Abstract: Trajectory-user linking (TUL) aims to associate anonymized trajectories with
the users who generated them, which is crucial for personalized
recommendations, privacy-preserving analytics, and secure location-based
services. Existing methods struggle with sparse data, incomplete routes, and
limited modeling of complex spatial dependencies, often relying on low-level
check-in data or ignoring spatial patterns. In this paper, we introduced
GCN-TULHOR, a method that transforms raw location data into higher-order
mobility flow representations using hexagonal tessellation, reducing data
sparsity and capturing richer spatial semantics, and integrating Graph
Convolutional Networks (GCNs). Our approach converts both sparse check-in and
continuous GPS trajectory data into unified higher-order flow representations,
mitigating sparsity while capturing deeper semantic information. The GCN layer
explicitly models complex spatial relationships and non-local dependencies
without requiring side information such as timestamps or points of interest.
Experiments on six real-world datasets show consistent improvements over
classical baselines, RNN- and Transformer-based models, and the TULHOR method
in accuracy, precision, recall, and F1-score. GCN-TULHOR achieves 1-8% relative
gains in accuracy and F1. Sensitivity analysis identifies an optimal setup with
a single GCN layer and 512-dimensional embeddings. The integration of GCNs
enhances spatial learning and improves generalizability across mobility data.
This work highlights the value of combining graph-based spatial learning with
sequential modeling, offering a robust and scalable solution for TUL with
applications in recommendations, urban planning, and security.

</details>


### [34] [Agentic Username Suggestion and Multimodal Gender Detection in Online Platforms: Introducing the PNGT-26K Dataset](https://arxiv.org/abs/2509.11136)
*Farbod Bijary,Mohsen Ebadpour,Amirhosein Tajbakhsh*

Main category: cs.LG

TL;DR: 페르시아 이름은 자연어 처리 어플리케이션에서 성별 탐지 및 디지털 아이덴티티 생성에 있어서 독특한 도전 과제를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 페르시아 이름의 음역 불일치와 문화적으로 특수한 명명 패턴으로 인해 기존의 도구들이 성능 저하를 보인다.

Method: PNGT-26K라는 약 26,000개의 튜플로 구성된 포괄적인 데이터를 구축하고, Open Gender Detection과 Nominalist라는 두 가지 프레임워크를 제시한다.

Result: 이 두 프레임워크는 사용자로 하여금 성별 예측 및 소셜 미디어 계정을 위한 사용자 이름 선택에 도움을 준다.

Conclusion: PNGT-26K 데이터셋과 두 프레임워크는 GitHub에서 공개되어 있다.

Abstract: Persian names present unique challenges for natural language processing
applications, particularly in gender detection and digital identity creation,
due to transliteration inconsistencies and cultural-specific naming patterns.
Existing tools exhibit significant performance degradation on Persian names,
while the scarcity of comprehensive datasets further compounds these
limitations. To address these challenges, the present research introduces
PNGT-26K, a comprehensive dataset of Persian names, their commonly associated
gender, and their English transliteration, consisting of approximately 26,000
tuples. As a demonstration of how this resource can be utilized, we also
introduce two frameworks, namely Open Gender Detection and Nominalist. Open
Gender Detection is a production-grade, ready-to-use framework for using
existing data from a user, such as profile photo and name, to give a
probabilistic guess about the person's gender. Nominalist, the second framework
introduced by this paper, utilizes agentic AI to help users choose a username
for their social media accounts on any platform. It can be easily integrated
into any website to provide a better user experience. The PNGT-26K dataset,
Nominalist and Open Gender Detection frameworks are publicly available on
Github.

</details>


### [35] [On the Escaping Efficiency of Distributed Adversarial Training Algorithms](https://arxiv.org/abs/2509.11337)
*Ying Cao,Kun Yuan,Ali H. Sayed*

Main category: cs.LG

TL;DR: 이 논문은 분산 적대적 훈련 알고리즘의 중앙집중화 및 분산 전략을 비교하고, 일정한 조건 하에서 분산 방식이 더 효과적임을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 모델의 견고성을 높이는 데 있어 적대적 훈련의 중요성을 강조하고, 실제 환경에서 다양한 알고리즘의 성능을 بررسی하는 것이 필수적이다.

Method: 일반적인 이론적 프레임워크를 개발하여, 로컬 미니마에서 탈출하는 효율성을 모델의 평평함과 연결지어 분석하였다.

Result: 분산 적대적 훈련 알고리즘이 중앙 집중식 전략보다 더 빠르게 로컬 미니마에서 탈출할 수 있음을 보여주었다.

Conclusion: 분산 SETTINGS에서 모델의 견고성을 높이는 데 있어 분산 전략의 잠재력을 강조하였다.

Abstract: Adversarial training has been widely studied in recent years due to its role
in improving model robustness against adversarial attacks. This paper focuses
on comparing different distributed adversarial training algorithms--including
centralized and decentralized strategies--within multi-agent learning
environments. Previous studies have highlighted the importance of model
flatness in determining robustness. To this end, we develop a general
theoretical framework to study the escaping efficiency of these algorithms from
local minima, which is closely related to the flatness of the resulting models.
We show that when the perturbation bound is sufficiently small (i.e., when the
attack strength is relatively mild) and a large batch size is used,
decentralized adversarial training algorithms--including consensus and
diffusion--are guaranteed to escape faster from local minima than the
centralized strategy, thereby favoring flatter minima. However, as the
perturbation bound increases, this trend may no longer hold. In the simulation
results, we illustrate our theoretical findings and systematically compare the
performance of models obtained through decentralized and centralized
adversarial training algorithms. The results highlight the potential of
decentralized strategies to enhance the robustness of models in distributed
settings.

</details>


### [36] [Online Omniprediction with Long-Term Constraints](https://arxiv.org/abs/2509.11357)
*Yahav Bechavod,Jiuyao Lu,Aaron Roth*

Main category: cs.LG

TL;DR: 온라인 전방예측 문제를 연구하며, 각 다운스트림 에이전트가 제약을 위반하지 않으면서 후회 없이 행동할 수 있도록 예측을 생성하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 온라인 환경에서 다양한 에이전트가 서로 다른 유틸리티와 제약을 가지고 있을 때, 이들이 어떻게 협력하여 후회 없이 행동하며 제약을 준수할 수 있는지를 연구하고자 합니다.

Method: 단일 세트의 예측을 생성하고, 각 에이전트가 이 예측에 따라 간단한 함수로 행동하여 후회 및 누적 제약 위반을 보장할 수 있도록 합니다.

Result: 각 다운스트림 에이전트가 후회에 대한 $	ilde{O}(	ext{sqrt}(T))$ 보장과 $O(1)$ 누적 제약 위반을 달성할 수 있음을 보여줍니다.

Conclusion: 어떤 교차 및 맥락적으로 정의된 부분수열에 대해서도 후회와 제약 위반 경계를 동시에 보장하는 방법을 제시합니다.

Abstract: We introduce and study the problem of online omniprediction with long-term
constraints. At each round, a forecaster is tasked with generating predictions
for an underlying (adaptively, adversarially chosen) state that are broadcast
to a collection of downstream agents, who must each choose an action. Each of
the downstream agents has both a utility function mapping actions and state to
utilities, and a vector-valued constraint function mapping actions and states
to vector-valued costs. The utility and constraint functions can arbitrarily
differ across downstream agents. Their goal is to choose actions that guarantee
themselves no regret while simultaneously guaranteeing that they do not
cumulatively violate the constraints across time. We show how to make a single
set of predictions so that each of the downstream agents can guarantee this by
acting as a simple function of the predictions, guaranteeing each of them
$\tilde{O}(\sqrt{T})$ regret and $O(1)$ cumulative constraint violation. We
also show how to extend our guarantees to arbitrary intersecting contextually
defined \emph{subsequences}, guaranteeing each agent both regret and constraint
violation bounds not just marginally, but simultaneously on each subsequence,
against a benchmark set of actions simultaneously tailored to each subsequence.

</details>


### [37] [Detecting Model Drifts in Non-Stationary Environment Using Edit Operation Measures](https://arxiv.org/abs/2509.11367)
*Chang-Hwan Lee,Alexander Shim*

Main category: cs.LG

TL;DR: 이 논문은 강화 학습 환경에서 발생하는 모델 드리프트를 탐지하기 위한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 에이전트는 일반적으로 정적인 환경 동태를 가정하지만, 실제 응용에서는 환경이 변화하여 모델 드리프트가 발생할 수 있습니다.

Method: 상태-행동 궤적 간의 편차를 정량화하기 위해 편집 작업 기반의 측정 방법을 도입했습니다.

Result: 이 측정 방법은 드리프트된 시나리오와 비드리프트된 시나리오를 효과적으로 구별할 수 있습니다.

Conclusion: 비정상적인 강화 학습 환경에서 드리프트를 탐지할 수 있는 실용적인 도구를 제공합니다.

Abstract: Reinforcement learning (RL) agents typically assume stationary environment
dynamics. Yet in real-world applications such as healthcare, robotics, and
finance, transition probabilities or reward functions may evolve, leading to
model drift. This paper proposes a novel framework to detect such drifts by
analyzing the distributional changes in sequences of agent behavior.
Specifically, we introduce a suite of edit operation-based measures to quantify
deviations between state-action trajectories generated under stationary and
perturbed conditions. Our experiments demonstrate that these measures can
effectively distinguish drifted from non-drifted scenarios, even under varying
levels of noise, providing a practical tool for drift detection in
non-stationary RL environments.

</details>


### [38] [UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning](https://arxiv.org/abs/2509.11543)
*Zhengxi Lu,Jiabo Ye,Fei Tang,Yongliang Shen,Haiyang Xu,Ziwei Zheng,Weiming Lu,Ming Yan,Fei Huang,Jun Xiao,Yueting Zhuang*

Main category: cs.LG

TL;DR: 본 논문은 오프라인 궤적에서 온라인 RL을 시뮬레이션하는 반온라인 강화 학습(Semi-online Reinforcement Learning)을 제안하여 오프라인 훈련 효율성과 온라인 다중 턴 추론 간의 격차를 해소하는 방법을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 사용자 인터페이스 상호작용을 자동화하기 위한 현업의 필요성과 기존 접근 방식의 한계를 해결하고자 합니다.

Method: 반온라인 강화 학습은 매 롤아웃 과정에서 멀티 턴 대화 내의 원래 모델 출력을 보존하고 패치 모듈을 통해 롤아웃과 전문가 궤적 간의 차이를 adaptively 회복합니다. 또한 보상 계산에 할인된 미래 수익을 도입하여 정책을 최적화합니다.

Result: 실험 결과, 반온라인 강화 학습은 7B 모델 중 4개의 동적 벤치마크에서 SOTA 성능을 달성했으며, 기본 모델 대비 유의미한 성과 향상을 보여주었습니다.

Conclusion: 본 연구는 오프라인 훈련의 효율성과 온라인 다중 턴 추론 간의 간극을 줄이는데 중요한 진전을 이루었습니다.

Abstract: Graphical User Interface (GUI) agents have demonstrated remarkable progress
in automating complex user interface interactions through reinforcement
learning. However, current approaches face a fundamental dilemma: offline RL
enables stable training on pre-collected trajectories, but struggles with
multi-step task execution for lack of trajectory-level reward signals; online
RL captures these signals through environment interaction, but suffers from
sparse rewards and prohibitive deployment costs. To address it, we present
Semi-online Reinforcement Learning, a novel paradigm that simulates online RL
on offline trajectories. During each rollout process, we preserve the original
model output within the multi-turn dialogue, where a Patch Module adaptively
recovers the divergence between rollout and expert trajectories. To capture
long-term training signals, Semi-online RL introduces discounted future returns
into the reward computation and optimizes the policy with weighted step-level
and episode-level advantages. We further introduce Semi-Online Performance
(SOP), a metric that aligns better with true online performance, serving as a
practical and effective proxy for real-world evaluation. Experiments show that
ours Semi-online RL achieves SOTA performance among 7B models across four
dynamic benchmarks, with significant gains over the base model (e.g., +12.0% on
AndroidWorld, +23.8% on AITW), demonstrating significant progress in bridging
the gap between offline training efficiency and online multi-turn reasoning.
The code is available at https://github.com/X-PLUG/MobileAgent/tree/main/UI-S1.

</details>


### [39] [An Interventional Approach to Real-Time Disaster Assessment via Causal Attribution](https://arxiv.org/abs/2509.11676)
*Saketh Vishnubhatla,Alimohammad Beigi,Rui Heng Foo,Umang Goel,Ujun Jeong,Bohan Jiang,Adrienne Raglin,Huan Liu*

Main category: cs.LG

TL;DR: 전통적인 재난 분석 도구는 예측적이며 개입적이지 않지만, 본 연구는 실시간 데이터를 활용하여 기존 도구를 보완하고 개입적 분석을 가능하게 하는 도구를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존 재난 분석 도구가 현재 입력 상태를 수정하여 반사실적 시나리오를 시뮬레이션할 수 있는 개입적 기능이 부족하다.

Method: 우리의 도구는 위성 이미지, 뉴스, 소셜 미디어와 같은 실시간 데이터원을 활용하여 재난 모델링 도구를 보완한다.

Result: 본 도구는 추정된 심각성에 대해 다양한 요인의 인과적 기여를 이해하는 데 도움을 준다.

Conclusion: 우리는 보다 용이한 완화 계획을 위한 실행 가능한 자원을 제공하며, 소스 코드는 공개되어 있다.

Abstract: Traditional disaster analysis and modelling tools for assessing the severity
of a disaster are predictive in nature. Based on the past observational data,
these tools prescribe how the current input state (e.g., environmental
conditions, situation reports) results in a severity assessment. However, these
systems are not meant to be interventional in the causal sense, where the user
can modify the current input state to simulate counterfactual "what-if"
scenarios. In this work, we provide an alternative interventional tool that
complements traditional disaster modelling tools by leveraging real-time data
sources like satellite imagery, news, and social media. Our tool also helps
understand the causal attribution of different factors on the estimated
severity, over any given region of interest. In addition, we provide actionable
recourses that would enable easier mitigation planning. Our source code is
publicly available.

</details>


### [40] [Fast and Interpretable Machine Learning Modelling of Atmospheric Molecular Clusters](https://arxiv.org/abs/2509.11728)
*Lauri Seppäläinen,Jakub Kubečka,Jonas Elm,Kai Puolamäki*

Main category: cs.LG

TL;DR: 이 연구는 $k$-최근접 이웃 회귀 모델을 통해 기후 모델링의 주요 불확실성을 해결하는 데 기여하며, 적은 계산 비용으로 정확한 결과를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 기후 모델링에서 새로운 에어로졸 입자의 형성은 큰 불확실성 중 하나로, 대기 분자 클러스터가 어떻게 형성되고 성장하는지를 이해하는 것이 중요합니다.

Method: 화학적으로 정보가 포함된 거리 메트릭을 활용하여 $k$-NN 회귀 모델을 도입하고, 기존의 커널 리지 회귀 모델과 비교합니다.

Result: $k$-NN 모델은 계산 시간을 크게 줄이면서도 복잡한 KRR 모델에 필적하는 정확도를 달성합니다.

Conclusion: 이 연구는 $k$-NN 모델이 대기 화학 및 그 너머에서 발견을 가속화할 수 있는 강력한 도구로 자리 잡을 것임을 나타냅니다.

Abstract: Understanding how atmospheric molecular clusters form and grow is key to
resolving one of the biggest uncertainties in climate modelling: the formation
of new aerosol particles. While quantum chemistry offers accurate insights into
these early-stage clusters, its steep computational costs limit large-scale
exploration. In this work, we present a fast, interpretable, and surprisingly
powerful alternative: $k$-nearest neighbour ($k$-NN) regression model. By
leveraging chemically informed distance metrics, including a kernel-induced
metric and one learned via metric learning for kernel regression (MLKR), we
show that simple $k$-NN models can rival more complex kernel ridge regression
(KRR) models in accuracy, while reducing computational time by orders of
magnitude. We perform this comparison with the well-established
Faber-Christensen-Huang-Lilienfeld (FCHL19) molecular descriptor, but other
descriptors (e.g., FCHL18, MBDF, and CM) can be shown to have similar
performance. Applied to both simple organic molecules in the QM9 benchmark set
and large datasets of atmospheric molecular clusters (sulphuric acid-water and
sulphuric-multibase -base systems), our $k$-NN models achieve near-chemical
accuracy, scale seamlessly to datasets with over 250,000 entries, and even
appears to extrapolate to larger unseen clusters with minimal error (often
nearing 1 kcal/mol). With built-in interpretability and straightforward
uncertainty estimation, this work positions $k$-NN as a potent tool for
accelerating discovery in atmospheric chemistry and beyond.

</details>


### [41] [MillStone: How Open-Minded Are LLMs?](https://arxiv.org/abs/2509.11967)
*Harold Triedman,Vitaly Shmatikov*

Main category: cs.LG

TL;DR: 본 논문에서는 외부 주장의 영향을 체계적으로 측정하기 위한 최초의 벤치마크인 MillStone을 소개하고, LLM들이 논란이 있는 주제에 대해 어떻게 반응하는지를 평가한다.


<details>
  <summary>Details</summary>
Motivation: 사용자들이 다양한 주제에 대한 정보를 위해 LLM을 의존하기 시작함에 따라, LLM 출력에서 표현되는 입장과 의견이 정보 출처로 사용되는 문서에 의해 어떻게 영향을 받는지를 이해하는 것이 중요하다.

Method: MillStone을 아홉 개의 주요 LLM에 적용하여, 이들 모델이 논란의 여지가 있는 주제에 대해 서로 다른 주장을 얼마나 '개방적인' 자세로 받아들이는지, 서로 간의 일치 여부, LLM이 가장 설득력이 있다고 느끼는 주장, 그리고 이러한 주장이 서로 다른 LLM에서도 동일한지 측정한다.

Result: LLM들은 대부분의 주제에 대해 개방적인 경향을 보이며, 신뢰할 수 있는 정보 출처가 LLM의 입장을 쉽게 바꿀 수 있다는 점을 발견했다.

Conclusion: 정보 출처 선택의 중요성과 LLM 기반의 정보 검색 및 시스템이 조작될 수 있는 위험성을 강조한다.

Abstract: Large language models equipped with Web search, information retrieval tools,
and other agentic capabilities are beginning to supplant traditional search
engines. As users start to rely on LLMs for information on many topics,
including controversial and debatable issues, it is important to understand how
the stances and opinions expressed in LLM outputs are influenced by the
documents they use as their information sources.
  In this paper, we present MillStone, the first benchmark that aims to
systematically measure the effect of external arguments on the stances that
LLMs take on controversial issues (not all of them political). We apply
MillStone to nine leading LLMs and measure how ``open-minded'' they are to
arguments supporting opposite sides of these issues, whether different LLMs
agree with each other, which arguments LLMs find most persuasive, and whether
these arguments are the same for different LLMs.
  In general, we find that LLMs are open-minded on most issues. An
authoritative source of information can easily sway an LLM's stance,
highlighting the importance of source selection and the risk that LLM-based
information retrieval and search systems can be manipulated.

</details>


### [42] [Generalizing Behavior via Inverse Reinforcement Learning with Closed-Form Reward Centroids](https://arxiv.org/abs/2509.12010)
*Filippo Lazzati,Alberto Maria Metelli*

Main category: cs.LG

TL;DR: 이 논문에서는 전문가의 행동을 새로운 환경이나 추가적인 제약 조건에 일반화하는 문제를 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 전문가의 행동을 다양한 환경에 효과적으로 도입하고자 하는 필요성.

Method: 보상 중심을 활용하여 여러 보상 함수들 중 평균 정책을 선택하는 방법 제안.

Result: 제안한 알고리즘을 통해 전문가의 성능을 재현할 수 있음을 보임.

Conclusion: 제안된 방법이 특정 보상 세트를 기반으로 하는 정책 선택에 유용함을 입증함.

Abstract: We study the problem of generalizing an expert agent's behavior, provided
through demonstrations, to new environments and/or additional constraints.
Inverse Reinforcement Learning (IRL) offers a promising solution by seeking to
recover the expert's underlying reward function, which, if used for planning in
the new settings, would reproduce the desired behavior. However, IRL is
inherently ill-posed: multiple reward functions, forming the so-called feasible
set, can explain the same observed behavior. Since these rewards may induce
different policies in the new setting, in the absence of additional
information, a decision criterion is needed to select which policy to deploy.
In this paper, we propose a novel, principled criterion that selects the
"average" policy among those induced by the rewards in a certain bounded subset
of the feasible set. Remarkably, we show that this policy can be obtained by
planning with the reward centroid of that subset, for which we derive a
closed-form expression. We then present a provably efficient algorithm for
estimating this centroid using an offline dataset of expert demonstrations
only. Finally, we conduct numerical simulations that illustrate the
relationship between the expert's behavior and the behavior produced by our
method.

</details>


### [43] [Imitation Learning as Return Distribution Matching](https://arxiv.org/abs/2509.12026)
*Filippo Lazzati,Alberto Maria Metelli*

Main category: cs.LG

TL;DR: 위험 민감 강화 학습 에이전트를 모방 학습을 통해 훈련하는 문제를 연구한다. 본 연구는 전문가의 평균 성능뿐만 아니라 위험 태도도 훈련하는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 표준 모방 학습과 달리, 전문가의 평균 성능뿐만 아니라 위험 태도를 훈련하고자 한다.

Method: 위험 민감 모방 학습 문제의 일반적인 공식화를 제안하며, 목표는 Wasserstein 거리에서 전문가의 보상 분포를 일치시키는 것이다. 비마르코프 정책의 효과적인 하위 클래스를 도입하고, 두 개의 알고리즘 RS-BC와 RS-KT를 개발한다.

Result: RS-KT는 동역학 정보를 활용하여 RS-BC보다 현저히 낮은 샘플 복잡성을 달성한다.

Conclusion: RS-KT와 RS-BC의 이론적 분석을 수치적 시뮬레이션으로 보완하며, 비마르코프 정책이 표준 샘플 효율적인 모방 학습 알고리즘에 비해 가지는 이점을 강조한다.

Abstract: We study the problem of training a risk-sensitive reinforcement learning (RL)
agent through imitation learning (IL). Unlike standard IL, our goal is not only
to train an agent that matches the expert's expected return (i.e., its average
performance) but also its risk attitude (i.e., other features of the return
distribution, such as variance). We propose a general formulation of the
risk-sensitive IL problem in which the objective is to match the expert's
return distribution in Wasserstein distance. We focus on the tabular setting
and assume the expert's reward is known. After demonstrating the limited
expressivity of Markovian policies for this task, we introduce an efficient and
sufficiently expressive subclass of non-Markovian policies tailored to it.
Building on this subclass, we develop two provably efficient algorithms, RS-BC
and RS-KT, for solving the problem when the transition model is unknown and
known, respectively. We show that RS-KT achieves substantially lower sample
complexity than RS-BC by exploiting dynamics information. We further
demonstrate the sample efficiency of return distribution matching in the
setting where the expert's reward is unknown by designing an oracle-based
variant of RS-KT. Finally, we complement our theoretical analysis of RS-KT and
RS-BC with numerical simulations, highlighting both their sample efficiency and
the advantages of non-Markovian policies over standard sample-efficient IL
algorithms.

</details>


### [44] [Travel Time and Weather-Aware Traffic Forecasting in a Conformal Graph Neural Network Framework](https://arxiv.org/abs/2509.12043)
*Mayur Patil,Qadeer Ahmed,Shawn Midlam-Mohler*

Main category: cs.LG

TL;DR: 교통 흐름 예측을 개선하기 위한 그래프 신경망(GNN) 프레임워크를 제안하고, 환경 요인과의 상호작용을 반영하여 불확실성을 정량화합니다.


<details>
  <summary>Details</summary>
Motivation: 도시의 교통과 환경 요인의 불확실성으로 인해 교통 흐름 예측이 복잡해지고 있습니다. 이를 해결하기 위해 다양한 동적 요인을 반영하는 모델이 필요합니다.

Method: 로그 정규 분포와 변동 계수(CV) 값을 이용한 적응형 인접 행렬을 활용한 GNN 프레임워크를 개발합니다. 날씨 요인이 엣지 가중치를 조정하여 교통국 간의 시공간 의존성을 포착합니다.

Result: 제안된 모델은 기존 방법들보다 더 나은 예측 정확도와 불확실성 범위를 보여 주었습니다.

Conclusion: SUMO에서 교통 시나리오를 구축하고 몬테카를로 시뮬레이션을 적용하여 모델의 견고성을 검증했습니다.

Abstract: Traffic flow forecasting is essential for managing congestion, improving
safety, and optimizing various transportation systems. However, it remains a
prevailing challenge due to the stochastic nature of urban traffic and
environmental factors. Better predictions require models capable of
accommodating the traffic variability influenced by multiple dynamic and
complex interdependent factors. In this work, we propose a Graph Neural Network
(GNN) framework to address the stochasticity by leveraging adaptive adjacency
matrices using log-normal distributions and Coefficient of Variation (CV)
values to reflect real-world travel time variability. Additionally, weather
factors such as temperature, wind speed, and precipitation adjust edge weights
and enable GNN to capture evolving spatio-temporal dependencies across traffic
stations. This enhancement over the static adjacency matrix allows the model to
adapt effectively to traffic stochasticity and changing environmental
conditions. Furthermore, we utilize the Adaptive Conformal Prediction (ACP)
framework to provide reliable uncertainty quantification, achieving target
coverage while maintaining acceptable prediction intervals. Experimental
results demonstrate that the proposed model, in comparison with baseline
methods, showed better prediction accuracy and uncertainty bounds. We, then,
validate this method by constructing traffic scenarios in SUMO and applying
Monte-Carlo simulation to derive a travel time distribution for a Vehicle Under
Test (VUT) to reflect real-world variability. The simulated mean travel time of
the VUT falls within the intervals defined by INRIX historical data, verifying
the model's robustness.

</details>


### [45] [Hi-DARTS: Hierarchical Dynamically Adapting Reinforcement Trading System](https://arxiv.org/abs/2509.12048)
*Hoon Sagong,Heesu Kim,Hanbeen Hong*

Main category: cs.LG

TL;DR: Hi-DARTS는 시장의 변동성을 분석하고 필요한 경우 전용 Time Frame Agents를 동적으로 활성화하여 고주파 또는 저주파 거래를 가능하게 하는 다계층 다중 에이전트 강화 학습 프레임워크입니다. 이 시스템은 2024년 1월부터 2025년 5월까지 AAPL 주식 백테스팅에서 25.17%의 누적 수익률을 기록했습니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 자율 거래 시스템은 고정된 운영 주기로 인해 계산 효율성과 시장 반응성을 균형있게 유지하는 데 어려움을 겪습니다.

Method: Hi-DARTS는 메타 에이전트를 사용하여 시장의 변동성을 분석하고 필요에 따라 고주파 또는 저주파 거래를 위한 전문 Time Frame Agents를 동적으로 활성화합니다.

Result: 2024년 1월부터 2025년 5월까지 AAPL 주식에 대한 백테스팅에서 Hi-DARTS는 25.17%의 누적 수익률과 0.75의 샤프 비율을 기록했습니다.

Conclusion: 우리의 연구는 동적이고 계층적인 에이전트가 계산 효율성을 유지하면서 우수한 위험 조정 수익률을 달성할 수 있음을 보여줍니다.

Abstract: Conventional autonomous trading systems struggle to balance computational
efficiency and market responsiveness due to their fixed operating frequency. We
propose Hi-DARTS, a hierarchical multi-agent reinforcement learning framework
that addresses this trade-off. Hi-DARTS utilizes a meta-agent to analyze market
volatility and dynamically activate specialized Time Frame Agents for
high-frequency or low-frequency trading as needed. During back-testing on AAPL
stock from January 2024 to May 2025, Hi-DARTS yielded a cumulative return of
25.17% with a Sharpe Ratio of 0.75. This performance surpasses standard
benchmarks, including a passive buy-and-hold strategy on AAPL (12.19% return)
and the S&P 500 ETF (SPY) (20.01% return). Our work demonstrates that dynamic,
hierarchical agents can achieve superior risk-adjusted returns while
maintaining high computational efficiency.

</details>


### [46] [A Time-Series Foundation Model by Universal Delay Embedding](https://arxiv.org/abs/2509.12080)
*Zijian Wang,Peng Tao,Jifan Shi,Rui Bao,Rui Liu,Luonan Chen*

Main category: cs.LG

TL;DR: 본 연구는 지연 임베딩 표현과 쿠프망 연산자를 통합하여 시계열 예측 분야를 혁신할 사전 훈련된 모델인 UDE(Universal Delay Embedding)를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 시계열 예측의 정확성을 높이고 해석 가능성을 개선하기 위해 또한 다양한 실제 데이터 세트에 적용하기 위해.

Method: UDE는 타켄스의 임베딩 정리를 활용하여 관측 데이터의 동적 표현을 구축하고, 이는 핸켈 행렬로부터 2차원 서브스페이스 패치를 구성합니다. 이러한 패치는 고급 딥러닝 기술을 활용하여 효율적으로 처리되고, 자가 주의 인코더 학습을 위한 토큰 역할을 하여 비선형 시계열 예측을 가능하게 합니다.

Result: 다양한 벤치마크 및 실제 기후 데이터 세트에서 평균 제곱 오차가 최신 모델 대비 20% 이상 감소하며, 미세 조정 시나리오에서의 일반화 성능도 우수합니다.

Conclusion: UDE는 전반적인 시계열 모델링 및 예측을 위한 확장 가능하고 해석 가능한 프레임워크로 자리잡아 과학 및 산업 분야에서 광범위하게 적용될 수 있습니다.

Abstract: This study introduces Universal Delay Embedding (UDE), a pretrained
foundation model designed to revolutionize time-series forecasting through
principled integration of delay embedding representation and Koopman operator
prediction. Leveraging Takens' embedding theorem, UDE as a dynamical
representation of observed data constructs two-dimensional subspace patches
from Hankel matrices, theoretically preserving dynamical and topological
properties of underlying dynamical systems. Such patches are viewed as images,
which can be efficiently processed by exploiting advanced deep learning
technologies. Computationally, these patches further serve as tokens for
learning a self-attention encoder, thus enabling accurate prediction of
nonlinear time-series by a finite-dimensional Koopman operator in a linear
manner in a latent space. Extensive evaluations across various benchmarks and
real-world climate datasets demonstrate over 20% average reduction in mean
squared error versus state-of-the-art foundation models, alongside superior
generalization in fine-tuning scenarios. In particular, the learned dynamical
representations and Koopman operator prediction forms from the patches exhibit
exceptional interpretability, with consistent identification of topologically
informative subspaces and robust encoding of domain-invariant dynamics,
establishing UDE as a scalable, interpretable framework for universal
time-series modeling and forecasting with broad scientific and industrial
applicability.

</details>


### [47] [$K$-Level Policy Gradients for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2509.12117)
*Aryaman Reddi,Gabriele Tiboni,Jan Peters,Carlo D'Eramo*

Main category: cs.LG

TL;DR: KPG 방법이 다른 에이전트의 정책 업데이트를 고려하여 효과적인 협력 정책 발견을 가속화하며, 국소 내쉬 균형에 수렴함을 이론적으로 증명하였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 액터-크리틱 알고리즘은 다른 에이전트의 현재 전략에 따라 정책을 업데이트하지만, 이는 미스코디네이션을 초래할 수 있다.

Method: $K$-Level Policy Gradient (KPG) 방법을 사용하여 각 에이전트를 다른 에이전트의 업데이트된 정책에 대해 재귀적으로 업데이트한다.

Result: KPG는 유한 반복에서 특정 조건 하에 국소 내쉬 균형으로 단조 수렴함을 이론적으로 증명하였다.

Conclusion: KPG를 MAPPO, MADDPG, FACMAC과 같은 심층 MARL 알고리즘에 적용한 결과, 스타크래프트 II 및 다중 에이전트 MuJoCo에서 기존 알고리즘보다 우수한 성능을 보였다.

Abstract: Actor-critic algorithms for deep multi-agent reinforcement learning (MARL)
typically employ a policy update that responds to the current strategies of
other agents. While being straightforward, this approach does not account for
the updates of other agents at the same update step, resulting in
miscoordination. In this paper, we introduce the $K$-Level Policy Gradient
(KPG), a method that recursively updates each agent against the updated
policies of other agents, speeding up the discovery of effective coordinated
policies. We theoretically prove that KPG with finite iterates achieves
monotonic convergence to a local Nash equilibrium under certain conditions. We
provide principled implementations of KPG by applying it to the deep MARL
algorithms MAPPO, MADDPG, and FACMAC. Empirically, we demonstrate superior
performance over existing deep MARL algorithms in StarCraft II and multi-agent
MuJoCo.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [48] [ZapGPT: Free-form Language Prompting for Simulated Cellular Control](https://arxiv.org/abs/2509.10660)
*Nam H. Le,Patrick Erickson,Yanbo Zhang,Michael Levin,Josh Bongard*

Main category: cs.AI

TL;DR: 자유 형식의 자연어가 단순 에이전트의 집단 행동을 안내할 수 있음을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 인간 언어는 의도를 전달하는 매우 표현력 있는 도구지만, 대부분의 인공 또는 생물 시스템은 이를 의미 있게 해석하거나 반응하는 메커니즘이 부족합니다.

Method: 간단한 에이전트의 집단 행동이 자유형식의 언어 프롬프트에 의해 안내될 수 있음을 보여줍니다.

Result: AI 모델이 명령 프롬프트를 개입으로 변환하고, 다른 AI 모델이 결과적인 세포 역학을 평가하는 방식으로 작동합니다.

Conclusion: 자연어를 제어 계층으로 취급하면서, 이 시스템은 향후 언어 프롬프트가 계산, 로봇 또는 생물 시스템을 원하는 행동으로 유도할 수 있는 가능성을 제시합니다.

Abstract: Human language is one of the most expressive tools for conveying intent, yet
most artificial or biological systems lack mechanisms to interpret or respond
meaningfully to it. Bridging this gap could enable more natural forms of
control over complex, decentralized systems. In AI and artificial life, recent
work explores how language can specify high-level goals, but most systems still
depend on engineered rewards, task-specific supervision, or rigid command sets,
limiting generalization to novel instructions. Similar constraints apply in
synthetic biology and bioengineering, where the locus of control is often
genomic rather than environmental perturbation.
  A key open question is whether artificial or biological collectives can be
guided by free-form natural language alone, without task-specific tuning or
carefully designed evaluation metrics. We provide one possible answer here by
showing, for the first time, that simple agents' collective behavior can be
guided by free-form language prompts: one AI model transforms an imperative
prompt into an intervention that is applied to simulated cells; a second AI
model scores how well the prompt describes the resulting cellular dynamics; and
the former AI model is evolved to improve the scores generated by the latter.
  Unlike previous work, our method does not require engineered fitness
functions or domain-specific prompt design. We show that the evolved system
generalizes to unseen prompts without retraining. By treating natural language
as a control layer, the system suggests a future in which spoken or written
prompts could direct computational, robotic, or biological systems to desired
behaviors. This work provides a concrete step toward this vision of AI-biology
partnerships, in which language replaces mathematical objective functions,
fixed rules, and domain-specific programming.

</details>


### [49] [Maestro: Self-Improving Text-to-Image Generation via Agent Orchestration](https://arxiv.org/abs/2509.10704)
*Xingchen Wan,Han Zhou,Ruoxi Sun,Hootan Nakhost,Ke Jiang,Rajarishi Sinha,Sercan Ö. Arık*

Main category: cs.AI

TL;DR: Maestro는 T2I 모델이 초기 프롬프트로부터 자율적으로 이미지 품질을 개선할 수 있게 해주는 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 텍스트-이미지(T2I) 모델은 창의성 가능성이 크지만, 인간 개입에 크게 의존하여 사용성에 어려움이 있다.

Method: Maestro는 자기 비평과 자기 진화를 통해 이미지 생성 과정을 개선하며, MLLM 에이전트를 사용하여 생성된 이미지의 약점을 식별하고 수정한다.

Result: Maestro는 초기 프롬프트와 최첨단 자동화 방법에 비해 이미지 품질을 크게 향상시킴을 실험적으로 입증하였다.

Conclusion: 이 연구는 자가 개선 가능한 T2I 생성으로 나아가는 강력하고 해석 가능한 방법을 제시한다.

Abstract: Text-to-image (T2I) models, while offering immense creative potential, are
highly reliant on human intervention, posing significant usability challenges
that often necessitate manual, iterative prompt engineering over often
underspecified prompts. This paper introduces Maestro, a novel self-evolving
image generation system that enables T2I models to autonomously self-improve
generated images through iterative evolution of prompts, using only an initial
prompt. Maestro incorporates two key innovations: 1) self-critique, where
specialized multimodal LLM (MLLM) agents act as 'critics' to identify
weaknesses in generated images, correct for under-specification, and provide
interpretable edit signals, which are then integrated by a 'verifier' agent
while preserving user intent; and 2) self-evolution, utilizing MLLM-as-a-judge
for head-to-head comparisons between iteratively generated images, eschewing
problematic images, and evolving creative prompt candidates that align with
user intents. Extensive experiments on complex T2I tasks using black-box models
demonstrate that Maestro significantly improves image quality over initial
prompts and state-of-the-art automated methods, with effectiveness scaling with
more advanced MLLM components. This work presents a robust, interpretable, and
effective pathway towards self-improving T2I generation.

</details>


### [50] [AgentArch: A Comprehensive Benchmark to Evaluate Agent Architectures in Enterprise](https://arxiv.org/abs/2509.10769)
*Tara Bogavelli,Roshnee Sharma,Hari Subramani*

Main category: cs.AI

TL;DR: 이 연구는 다양한 에이전트 구성 요소가 복잡한 다중 에이전트 시스템 내에서 상호작용하는 방식을 배경으로 한 포괄적인 벤치마크를 제공하여 에이전트적인 아키텍처의 설계 차원 간 상호작용을 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 아키텍처의 개별 구성 요소는 독립적으로 연구되었지만, 서로 다른 설계 차원이 복잡한 다중 에이전트 시스템 내에서 어떻게 상호작용하는지에 대한 경험적 이해는 제한적입니다.

Method: 최신 대규모 언어 모델에서 18개의 독특한 에이전트 구성을 평가하는 엔터프라이즈 특화 벤치마크를 제공하고, 오케스트레이션 전략, 에이전트 프롬프트 구현(ReAct 대 함수 호출), 메모리 아키텍처, 사고 도구 통합의 네 가지 중요한 시스템 차원을 조사합니다.

Result: 우리의 벤치마크는 일반적인 모든 것에 맞는 패러다임에 도전하는 모델별 아키텍처 선호도를 밝히고, 가장 높은 점수를 받은 모델이 복잡한 작업에서 최대 35.3%의 성공률과 단순한 작업에서 70.8%의 성공률을 기록하는 등 전체 에이전트 성능에서 중요한 약점을 드러냅니다.

Conclusion: 우리는 이러한 발견이 아키텍처 구성 요소 및 모델 선택에 관한 보다 경험적으로 뒷받침된 결정을 가능하게 하여 미래의 에이전트 시스템 설계를 알리는 데 도움을 줄 것으로 기대합니다.

Abstract: While individual components of agentic architectures have been studied in
isolation, there remains limited empirical understanding of how different
design dimensions interact within complex multi-agent systems. This study aims
to address these gaps by providing a comprehensive enterprise-specific
benchmark evaluating 18 distinct agentic configurations across state-of-the-art
large language models. We examine four critical agentic system dimensions:
orchestration strategy, agent prompt implementation (ReAct versus function
calling), memory architecture, and thinking tool integration. Our benchmark
reveals significant model-specific architectural preferences that challenge the
prevalent one-size-fits-all paradigm in agentic AI systems. It also reveals
significant weaknesses in overall agentic performance on enterprise tasks with
the highest scoring models achieving a maximum of only 35.3\% success on the
more complex task and 70.8\% on the simpler task. We hope these findings inform
the design of future agentic systems by enabling more empirically backed
decisions regarding architectural components and model selection.

</details>


### [51] [Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?](https://arxiv.org/abs/2509.10875)
*Jesse Gardner,Vladimir A. Baulin*

Main category: cs.AI

TL;DR: 이 논문은 '대리인' 개념이 인공지능(AI) 연구에 미친 영향을 재평가하고, 기존 대리인 중심 패러다임의 한계와 대안으로 시스템 중심의 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: AI 연구에서 대리인 개념의 중심성을 비판적으로 재검토하고, 그로 인한 개념적 모호성과 인간 중심 편향이 한계를 나타낼 수 있음을 주장합니다.

Method: 관련 문헌에 대한 체계적 검토에 기반하여 대리인 패러다임을 다양한 AI 프레임워크에서 분해합니다.

Result: 대리인 중심 프레임이 유용할 수 있지만 오해를 일으킬 수 있으며, 특히 LLM에서의 계산적 메커니즘을 가릴 수 있음을 강조합니다.

Conclusion: 비대리인 및 시스템 중심 프레임워크를 조사하는 것이 강력하고 확장 가능한 일반 지능의 형태로 나아가는 데 필수적이라고 결론지습니다.

Abstract: The concept of the 'agent' has profoundly shaped Artificial Intelligence (AI)
research, guiding development from foundational theories to contemporary
applications like Large Language Model (LLM)-based systems. This paper
critically re-evaluates the necessity and optimality of this agent-centric
paradigm. We argue that its persistent conceptual ambiguities and inherent
anthropocentric biases may represent a limiting framework. We distinguish
between agentic systems (AI inspired by agency, often semi-autonomous, e.g.,
LLM-based agents), agential systems (fully autonomous, self-producing systems,
currently only biological), and non-agentic systems (tools without the
impression of agency). Our analysis, based on a systematic review of relevant
literature, deconstructs the agent paradigm across various AI frameworks,
highlighting challenges in defining and measuring properties like autonomy and
goal-directedness. We argue that the 'agentic' framing of many AI systems,
while heuristically useful, can be misleading and may obscure the underlying
computational mechanisms, particularly in Large Language Models (LLMs). As an
alternative, we propose a shift in focus towards frameworks grounded in
system-level dynamics, world modeling, and material intelligence. We conclude
that investigating non-agentic and systemic frameworks, inspired by complex
systems, biology, and unconventional computing, is essential for advancing
towards robust, scalable, and potentially non-anthropomorphic forms of general
intelligence. This requires not only new architectures but also a fundamental
reconsideration of our understanding of intelligence itself, moving beyond the
agent metaphor.

</details>


### [52] [Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration](https://arxiv.org/abs/2509.11067)
*Liangxuan Guo,Bin Zhu,Qingqian Tao,Kangning Liu,Xun Zhao,Xianzhe Qin,Jin Gao,Guangfu Hao*

Main category: cs.AI

TL;DR: Agentic Lybic는 복잡한 다단계 작업을 위한 새로운 다중 에이전트 시스템으로, 상태 머신을 기반으로 하여 유연하고 최적화된 실행 전략을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 자율 에이전트들이 복잡한 다단계 작업에 어려움을 겪고 있으며, 이는 조정 부족과 품질 관리 부족 때문입니다.

Method: Agentic Lybic는 제어기, 관리자, 세 개의 작업자(코드 기반 작업을 위한 기술자, GUI 상호작용을 위한 운영자, 의사결정을 지원하는 분석가) 그리고 평가자로 구성된 다중 에이전트 시스템입니다. 이 시스템은 상태 머신 기반 라우팅을 통해 유연하고 최적의 실행 전략을 동적으로 선택합니다.

Result: OSWorld 벤치마크에서 Agentic Lybic은 50단계에서 57.07%의 성공률을 달성하여 기존 방법을 크게 초월했습니다.

Conclusion: 원칙에 기반한 다중 에이전트 조율과 지속적인 품질 관리가 복잡한 컴퓨팅 환경에서 일반화된 데스크탑 자동화를 위한 탁월한 신뢰성을 제공합니다.

Abstract: Autonomous agents for desktop automation struggle with complex multi-step
tasks due to poor coordination and inadequate quality control. We introduce
Agentic Lybic, a novel multi-agent system where the entire architecture
operates as a finite-state machine (FSM). This core innovation enables dynamic
orchestration. Our system comprises four components: a Controller, a Manager,
three Workers (Technician for code-based operations, Operator for GUI
interactions, and Analyst for decision support), and an Evaluator. The critical
mechanism is the FSM-based routing between these components, which provides
flexibility and generalization by dynamically selecting the optimal execution
strategy for each subtask. This principled orchestration, combined with robust
quality gating, enables adaptive replanning and error recovery. Evaluated
officially on the OSWorld benchmark, Agentic Lybic achieves a state-of-the-art
57.07% success rate in 50 steps, substantially outperforming existing methods.
Results demonstrate that principled multi-agent orchestration with continuous
quality control provides superior reliability for generalized desktop
automation in complex computing environments.

</details>


### [53] [Free-MAD: Consensus-Free Multi-Agent Debate](https://arxiv.org/abs/2509.11035)
*Yu Cui,Hang Fu,Haibin Zhang,Licheng Wang,Cong Zuo*

Main category: cs.AI

TL;DR: Free-MAD는 다수결 기반의 다기능 토론 방식을 개선하여 LLM의 추론 능력을 향상시키는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 다기능 토론 방식은 소통의 여러 차례로 인해 토큰 오버헤드가 증가하고, LLM의 본질적인 일치성으로 인해 오류 전파가 발생하며, 다수결 방식으로 인해 결정 과정에 무작위성과 불공정성이 도입되는 등의 한계가 있다.

Method: Free-MAD는 에이전트 간의 합의 필요성을 없애고, 전체 토론 경로를 평가하는 점수 기반의 의사 결정 기제를 도입한다.

Result: 실험 결과 Free-MAD는 추론 성능을 크게 개선하며, 단일 라운드 토론만을 요구하여 토큰 비용을 줄인다.

Conclusion: Free-MAD는 기존의 다기능 토론 방법들과 비교할 때 실제 공격 시나리오에서 향상된 강건성을 나타낸다.

Abstract: Multi-agent debate (MAD) is an emerging approach to improving the reasoning
capabilities of large language models (LLMs). Existing MAD methods rely on
multiple rounds of interaction among agents to reach consensus, and the final
output is selected by majority voting in the last round. However, this
consensus-based design faces several limitations. First, multiple rounds of
communication increases token overhead and limits scalability. Second, due to
the inherent conformity of LLMs, agents that initially produce correct
responses may be influenced by incorrect ones during the debate process,
causing error propagation. Third, majority voting introduces randomness and
unfairness in the decision-making phase, and can degrade the reasoning
performance.
  To address these issues, we propose \textsc{Free-MAD}, a novel MAD framework
that eliminates the need for consensus among agents. \textsc{Free-MAD}
introduces a novel score-based decision mechanism that evaluates the entire
debate trajectory rather than relying on the last round only. This mechanism
tracks how each agent's reasoning evolves, enabling more accurate and fair
outcomes. In addition, \textsc{Free-MAD} reconstructs the debate phase by
introducing anti-conformity, a mechanism that enables agents to mitigate
excessive influence from the majority. Experiments on eight benchmark datasets
demonstrate that \textsc{Free-MAD} significantly improves reasoning performance
while requiring only a single-round debate and thus reducing token costs. We
also show that compared to existing MAD approaches, \textsc{Free-MAD} exhibits
improved robustness in real-world attack scenarios.

</details>


### [54] [Neural cellular automata: applications to biology and beyond classical AI](https://arxiv.org/abs/2509.11131)
*Benedikt Hartl,Michael Levin,Léo Pio-Lopez*

Main category: cs.AI

TL;DR: 신경 세포 자동자(NCA)는 생물학적 자기 조직화를 모델링하기 위한 강력한 프레임워크로, 학습 가능하고 미분 가능한 업데이트 규칙을 통해 생명체의 적응적 자기 규제 역학을 캡처한다.


<details>
  <summary>Details</summary>
Motivation: NCA는 생물학 또는 생물 공학 응용에 관련된 현재 문헌을 검토하고, NCA의 성공적인 최근 발전을 강조하기 위해 작성되었다.

Method: NCA는 인공 신경망을 로컬 의사 결정 센터로 넣고 국소화된 에이전트 간 상호 작용 규칙을 사용하여 분자, 세포, 조직 및 시스템 수준에서의 프로세스를 시뮬레이션한다.

Result: 이 모델은 생물학적으로 영감을 받은 목표 패턴을 재현하고 새로운 조건에 일반화하여 적응과 추론의 강력한 능력을 보여준다.

Conclusion: NCA는 다중 규모 생물학과 현대 생성 AI의 근본적인 통찰력을 연결하는 통합 컴퓨팅 패러다임을 구성하며, 계층적 추론과 제어가 가능한 진정한 생물 영감을 받은 집단 지성을 설계할 잠재력을 가지고 있다.

Abstract: Neural Cellular Automata (NCA) represent a powerful framework for modeling
biological self-organization, extending classical rule-based systems with
trainable, differentiable (or evolvable) update rules that capture the adaptive
self-regulatory dynamics of living matter. By embedding Artificial Neural
Networks (ANNs) as local decision-making centers and interaction rules between
localized agents, NCA can simulate processes across molecular, cellular,
tissue, and system-level scales, offering a multiscale competency architecture
perspective on evolution, development, regeneration, aging, morphogenesis, and
robotic control. These models not only reproduce biologically inspired target
patterns but also generalize to novel conditions, demonstrating robustness to
perturbations and the capacity for open-ended adaptation and reasoning. Given
their immense success in recent developments, we here review current literature
of NCAs that are relevant primarily for biological or bioengineering
applications. Moreover, we emphasize that beyond biology, NCAs display robust
and generalizing goal-directed dynamics without centralized control, e.g., in
controlling or regenerating composite robotic morphologies or even on
cutting-edge reasoning tasks such as ARC-AGI-1. In addition, the same
principles of iterative state-refinement is reminiscent to modern generative
Artificial Intelligence (AI), such as probabilistic diffusion models. Their
governing self-regulatory behavior is constraint to fully localized
interactions, yet their collective behavior scales into coordinated
system-level outcomes. We thus argue that NCAs constitute a unifying
computationally lean paradigm that not only bridges fundamental insights from
multiscale biology with modern generative AI, but have the potential to design
truly bio-inspired collective intelligence capable of hierarchical reasoning
and control.

</details>


### [55] [AMLNet: A Knowledge-Based Multi-Agent Framework to Generate and Detect Realistic Money Laundering Transactions](https://arxiv.org/abs/2509.11595)
*Sabin Huda,Ernest Foo,Zahra Jadidi,MA Hakim Newton,Abdul Sattar*

Main category: cs.AI

TL;DR: AMLNet은 규제에 부합하는 거래 데이터셋의 부족을 해결하기 위한 지식 기반 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 자금 세탁 방지(AML) 연구는 공개적으로 공유할 수 있는 규제에 부합하는 거래 데이터셋의 부족으로 제한을 받고 있다.

Method: AMLNet은 규제 인식 거래 생성기와 앙상블 탐지 파이프라인의 두 가지 조정된 유닛으로 구성된 지식 기반 다중 에이전트 프레임워크이다.

Result: 1,090,173개의 합성 거래를 생성하였으며, 이 중 약 0.16%는 자금 세탁이 긍정적인 것으로 분류된다. 규정 일관성은 AUSTRAC 규칙 커버리지 기준으로 75%에 도달하며, 탐지 앙상블은 내부 테스트 분할에서 F1 0.90을 달성하였다.

Conclusion: 우리는 대규모 평가를 제공하고 데이터셋을 공개하여 재현 가능하고 규제 인식이 있는 AML 실험을 촉진한다.

Abstract: Anti-money laundering (AML) research is constrained by the lack of publicly
shareable, regulation-aligned transaction datasets. We present AMLNet, a
knowledge-based multi-agent framework with two coordinated units: a
regulation-aware transaction generator and an ensemble detection pipeline. The
generator produces 1,090,173 synthetic transactions (approximately 0.16\%
laundering-positive) spanning core laundering phases (placement, layering,
integration) and advanced typologies (e.g., structuring, adaptive threshold
behavior). Regulatory alignment reaches 75\% based on AUSTRAC rule coverage
(Section 4.2), while a composite technical fidelity score of 0.75 summarizes
temporal, structural, and behavioral realism components (Section 4.4). The
detection ensemble achieves F1 0.90 (precision 0.84, recall 0.97) on the
internal test partitions of AMLNet and adapts to the external SynthAML dataset,
indicating architectural generalizability across different synthetic generation
paradigms. We provide multi-dimensional evaluation (regulatory, temporal,
network, behavioral) and release the dataset (Version 1.0,
https://doi.org/10.5281/zenodo.16736515), to advance reproducible and
regulation-conscious AML experimentation.

</details>


### [56] [Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability](https://arxiv.org/abs/2509.11068)
*Zan-Kai Chong,Hiroyuki Ohsaki,Bryan Ng*

Main category: cs.AI

TL;DR: 이 논문은 LLM의 출력을 검증하기 위한 비대칭 노력 검증 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 출력이 소속된 모델에 의해 진정으로 생성되었음을 확인하는 과정은 신뢰 구조에 있어 필수적이다.

Method: 확률적으로 LLM 출력의 무작위 작은 부분을 감사하고 검증 작업 부하를 효과적으로 분산시키는 검증 프레임워크를 구축했다.

Result: 대상 검증은 전체 재생성보다 12배 이상 빠르고, 검출 확률을 조정할 수 있는 파라미터가 제공되었다.

Conclusion: 검증 가능한 LLM 시스템을 위한 실현 가능한 메커니즘을 확립함으로써, 우리의 작업은 책임 있는 AI를 위한 기초적 층을 제공하고 복잡한 다중 에이전트 시스템을 위한 연구의 초석 역할을 한다.

Abstract: The landscape of Large Language Models (LLMs) shifts rapidly towards dynamic,
multi-agent systems. This introduces a fundamental challenge in establishing
computational trust, specifically how one agent can verify that another's
output was genuinely produced by a claimed LLM, and not falsified or generated
by a cheaper or inferior model. To address this challenge, this paper proposes
a verification framework that achieves tractable asymmetric effort, where the
cost to verify a computation is substantially lower than the cost to perform
it. Our approach is built upon the principle of deterministic replicability, a
property inherent to autoregressive models that strictly necessitates a
computationally homogeneous environment where all agents operate on identical
hardware and software stacks. Within this defined context, our framework
enables multiple validators to probabilistically audit small, random segments
of an LLM's output and it distributes the verification workload effectively.
The simulations demonstrated that targeted verification can be over 12 times
faster than full regeneration, with tunable parameters to adjust the detection
probability. By establishing a tractable mechanism for auditable LLM systems,
our work offers a foundational layer for responsible AI and serves as a
cornerstone for future research into the more complex, heterogeneous
multi-agent systems.

</details>


### [57] [Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics](https://arxiv.org/abs/2509.11943)
*Antonin Sulc,Thorsten Hellert*

Main category: cs.AI

TL;DR: 이 논문은 신경-기호 다중 에이전트 아키텍처를 도입하여 AI 연구에서 에이전트의 추론 구조와 일관성을 확장하는 것이 중요하다고 주장합니다.


<details>
  <summary>Details</summary>
Motivation: 지능형 에이전트 개발은 지능적이고 자율적인 결정을 요구하는 다양한 환경에서 중요한 역할을 보여주고 있습니다.

Method: 신경-기호 다중 에이전트 아키텍처를 도입하여 각 에이전트의 신념 상태를 Kripke 모델로 형식적으로 표현하였습니다.

Result: 제안된 모델에서 제약 조건이 LMs의 가설 생성을 적극적으로 안내하여 비현실적인 결론에 도달하는 것을 방지합니다.

Conclusion: 우리의 시스템은 고충실도 시뮬레이션 입자 가속기 환경에서 복잡한 연속 실패를 성공적으로 진단하며, 더욱 강력하고 신뢰할 수 있는 자율 에이전트를 위한 실행 가능한 경로를 제시합니다.

Abstract: The development of intelligent agents, particularly those powered by language
models (LMs), has shown the critical role in various environments that require
intelligent and autonomous decision. Environments are not passive testing
grounds and they represent the data required for agents to learn and exhibit
very challenging conditions that require adaptive, complex and autonomous
capacity to make decisions. While the paradigm of scaling models and datasets
has led to remarkable emergent capabilities, we argue that scaling the
structure, fidelity, and logical consistency of agent reasoning within these
environments is a crucial, yet underexplored, dimension of AI research. This
paper introduces a neuro-symbolic multi-agent architecture where the belief
states of individual agents are formally represented as Kripke models. This
foundational choice enables them to reason about known concepts of
\emph{possibility} and \emph{necessity} using the formal language of modal
logic. In this work, we use of immutable, domain-specific knowledge to make
infere information, which is encoded as logical constraints essential for
proper diagnosis. In the proposed model, we show constraints that actively
guide the hypothesis generation of LMs, effectively preventing them from
reaching physically or logically untenable conclusions. In a high-fidelity
simulated particle accelerator environment, our system successfully diagnoses
complex, cascading failures by combining the powerful semantic intuition of LMs
with the rigorous, verifiable validation of modal logic and a factual world
model and showcasing a viable path toward more robust, reliable, and verifiable
autonomous agents.

</details>


### [58] [Patient-Zero: A Unified Framework for Real-Record-Free Patient Agent Generation](https://arxiv.org/abs/2509.11078)
*Yunghwei Lai,Weizhi Ma,Yang Liu*

Main category: cs.AI

TL;DR: 본 연구는 실제 의료 기록 없이도 환자 기록을 생성할 수 있는 Patient-Zero 프레임워크를 제안하며, 정확성과 다양성을 유지하면서도 의료적 일관성을 확보한 새로운 접근을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존의 의료 기록 작성 방식에서 발생하는 데이터 수집의 어려움을 해결하기 위해.

Method: Patient-Zero는 의료 지식 주입을 통해 단계적인 환자 기록 생성을 구현하고, 가상의 환자와의 상호 작용 능력을 향상시키기 위한 동적 업데이트 메커니즘을 디자인한다.

Result: 실험 결과, 제안된 모델이 정확성, 다양성 및 일관성 측면에서 우수한 성능을 보였으며, 생성된 가상 환자와의 훈련 후 MedQA 데이터셋에서 기존 모델들이 유의미한 향상을 보였다.

Conclusion: Patient-Zero 프레임워크는 데이터 프라이버시 문제를 해결하면서, 고도로 일관된 환자 기록 생성을 가능하게 한다.

Abstract: Synthetic data generation using large language models (LLMs) has emerged as a
promising solution across various domains, particularly in medical field, to
mitigate data collection challenges. However, existing studies mainly utilize
LLMs to rewrite and complete existing medical records, where the limitations in
data privacy, accuracy, and diversity sill exist, and additionally lack the
ability to interact like real patients. To address these issues, we propose a
realistic patient generation framework, Patient-Zero, which requires no real
medical records. Patient-Zero first introduces a medically-aligned multi-step
generation architecture, which builds comprehensive patient records through
hierarchical medical knowledge injection without real medical records. Then, to
optimize the virtual patient's interaction abilities with humans, Patient-Zero
designs a dynamic updating mechanism to improve the consistency and
conversational performance. Our framework enables the generation of
contextually diverse patient records while maintaining strict medical
coherence, supported by adaptive dialogue strategies and real-time clinical
plausibility verification. Experimental results demonstrate that our model
achieves good performance in accuracy, diversity, and consistency. After
training with our generated virtual patients, existing models show significant
improvements on the MedQA dataset.

</details>


### [59] [Difficulty-Aware Agent Orchestration in LLM-Powered Workflows](https://arxiv.org/abs/2509.11079)
*Jinwei Su,Yinghui Xia,Qizhen Lan,Xinyuan Song,Yang Jingsong,Lewei He,Tianyu Shi*

Main category: cs.AI

TL;DR: 본 논문에서는 다양한 작업에서 뛰어난 성능을 보이는 대형 언어 모델(LLM) 기반 에이전틱 시스템의 한계를 극복하기 위해, 입력 쿼리의 난이도에 따라 작업 흐름을 동적으로 조정하는 Difficulty-Aware Agentic Orchestration(DAAO) 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 멀티 에이전트 프레임워크는 정적 또는 작업 수준의 워크플로우에 의존하여, 단순 쿼리에 대해 과도하게 처리하거나 복잡한 쿼리에 대해 부족한 성능을 보이며, 이질적인 LLM 간의 효율성-성능 트레이드오프를 간과하는 한계를 가집니다.

Method: DAAO는 입력 쿼리의 난이도에 따라 작업 흐름 깊이, 연산자 선택 및 LLM 할당을 동적으로 조정하는 프레임워크로, 난이도 추정을 위한 변량 오토인코더(VAE), 모듈형 연산자 할당기, 비용 및 성능 인식 LLM 라우터의 세 가지 상호 의존 모듈로 구성됩니다.

Result: DAAO는 이질적인 LLM을 활용하고 동적으로 워크플로우를 조정하여 세분화된 쿼리 특화 추론 전략을 가능하게 하며, 여섯 개 벤치마크에서 정확도와 추론 효율성 모두에서 이전 멀티 에이전트 시스템을 능가합니다.

Conclusion: 논문 출판 후 코드와 구현 세부사항을 공개할 예정입니다.

Abstract: Large Language Model (LLM)-based agentic systems have shown strong
capabilities across various tasks. However, existing multi-agent frameworks
often rely on static or task-level workflows, which either over-process simple
queries or underperform on complex ones, while also neglecting the
efficiency-performance trade-offs across heterogeneous LLMs. To address these
limitations, we propose Difficulty-Aware Agentic Orchestration (DAAO), a
dynamic framework that adapts workflow depth, operator selection, and LLM
assignment based on the difficulty of each input query. DAAO comprises three
interdependent modules: a variational autoencoder (VAE) for difficulty
estimation, a modular operator allocator, and a cost- and performance-aware LLM
router. By leveraging heterogeneous LLMs and dynamically tailoring workflows,
DAAO enables fine-grained, query-specific reasoning strategies. DAAO
outperforms prior multi-agent systems in both accuracy and inference efficiency
across six benchmarks. We will release our code and implementation details upon
publication.

</details>


### [60] [VideoAgent: Personalized Synthesis of Scientific Videos](https://arxiv.org/abs/2509.11253)
*Xiao Liang,Bangxin Li,Zixuan Chen,Hanyue Zheng,Zhi Ma,Di Wang,Cong Tian,Quan Wang*

Main category: cs.AI

TL;DR: 과학 비디오 자동 생성의 중요성 및 도전과제를 다룬 논문


<details>
  <summary>Details</summary>
Motivation: 과학적 지식을 효과적으로 전파하기 위해 과학 비디오 자동 생성은 필수적이지만 어려운 작업이다.

Method: VideoAgent라는 새로운 다중 에이전트 프레임워크를 도입하여 대화형 인터페이스를 통해 개인화된 과학 비디오를 생성한다.

Result: 대규모 실험에서 우리의 방법이 기존 상용 과학 비디오 생성 서비스보다 상당히 우수하며 과학적 의사소통에서 인간 수준의 품질에 접근함을 입증했다.

Conclusion: 개인화된 동적 조정 및 다중 모드 콘텐츠 동기화를 통해 복잡한 개념을 설명하는 새로운 접근 방식을 제공한다.

Abstract: Automating the generation of scientific videos is a crucial yet challenging
task for effective knowledge dissemination. However, existing works on document
automation primarily focus on static media such as posters and slides, lacking
mechanisms for personalized dynamic orchestration and multimodal content
synchronization. To address these challenges, we introduce VideoAgent, a novel
multi-agent framework that synthesizes personalized scientific videos through a
conversational interface. VideoAgent parses a source paper into a fine-grained
asset library and, guided by user requirements, orchestrates a narrative flow
that synthesizes both static slides and dynamic animations to explain complex
concepts. To enable rigorous evaluation, we also propose SciVidEval, the first
comprehensive suite for this task, which combines automated metrics for
multimodal content quality and synchronization with a Video-Quiz-based human
evaluation to measure knowledge transfer. Extensive experiments demonstrate
that our method significantly outperforms existing commercial scientific video
generation services and approaches human-level quality in scientific
communication.

</details>


### [61] [Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble](https://arxiv.org/abs/2509.11311)
*Bingchen Wang,Zi-Yu Khoo,Bryan Kian Hsiang Low*

Main category: cs.AI

TL;DR: 본 논문에서는 대형 언어 모델(LLM)을 인적 조사 응답자의 대리인으로 활용하는 새로운 정렬 프레임워크를 제안합니다. 이 프레임워크는 조사 배포 비용 상승과 응답 데이터의 인구 통계 불균형이라는 두 가지 문제를 해결하기 위한 경제적이고 유연한 솔루션을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 사회 과학에서 조사 배포 비용 상승과 응답 데이터에서의 인구 통계 불균형 문제를 해결하고자 함.

Method: 두 단계 문제로 구성된 정렬 제안: 일관된 응답자 프로필을 시뮬레이션하는 다양한 대리인 페르소나(엔도우먼트)를 구축하고, 관측된 데이터를 바탕으로 실제 인구를 근사하는 대표적인 하위 집합을 선택하는 방법.

Result: 실세계 의견 조사 데이터셋에서 우리의 접근법이 집합적 응답 패턴을 높은 충실도로 재생산하고, 인구 통계적 조건 없이도 상당한 응답 다양성을 나타낼 수 있음을 보여줌.

Conclusion: 우리의 정렬 접근 방식은 더 나은 일반화 가능성과 간결성을 제공하며, 사회 과학 연구에서 데이터 효율성을 개선합니다.

Abstract: Large language models (LLMs) have demonstrated promise in emulating
human-like responses across a wide range of tasks. In this paper, we propose a
novel alignment framework that treats LLMs as agent proxies for human survey
respondents, affording a cost-effective and steerable solution to two pressing
challenges in the social sciences: the rising cost of survey deployment and the
growing demographic imbalance in survey response data. Drawing inspiration from
the theory of revealed preference, we formulate alignment as a two-stage
problem: constructing diverse agent personas called endowments that simulate
plausible respondent profiles, and selecting a representative subset to
approximate a ground-truth population based on observed data. To implement the
paradigm, we introduce P2P, a system that steers LLM agents toward
representative behavioral patterns using structured prompt engineering,
entropy-based sampling, and regression-based selection. Unlike
personalization-heavy approaches, our alignment approach is
demographic-agnostic and relies only on aggregate survey results, offering
better generalizability and parsimony. Beyond improving data efficiency in
social science research, our framework offers a testbed for studying the
operationalization of pluralistic alignment. We demonstrate the efficacy of our
approach on real-world opinion survey datasets, showing that our aligned agent
populations can reproduce aggregate response patterns with high fidelity and
exhibit substantial response diversity, even without demographic conditioning.

</details>


### [62] [The power of dynamic causality in observer-based design for soft sensor applications](https://arxiv.org/abs/2509.11336)
*William Farlessyost,Sebastian Oberst,Shweta Singh*

Main category: cs.AI

TL;DR: 본 논문은 동적 인과 분석을 통해 관찰자 기반 소프트 센서를 최적화하는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 센서 선택 접근 방식은 복잡한 시스템의 시간적 진화를 포착하지 못하는 선형화된 관측 가능성 지수나 통계적 상관관계에 의존합니다.

Method: 본 연구에서는 액체 시간 상수(LTC) 네트워크를 활용하여 인과적 영향을 최소화하는 센서 입력을 체계적으로 식별하고 제거하는 방법론을 제안합니다. 이를 위해 후보 입력에 대해 LTC 관찰자를 훈련시키고, 통제된 섭동 분석을 통해 각 입력의 인과적 영향을 정량화한 후, 미미한 효과를 가진 입력을 제거하고 성능 저하가 발생할 때까지 재훈련을 반복합니다.

Result: 세 가지 기계적 테스트베드를 활용한 결과, 우리의 인과성 기반 가지치기 방법이 기본 물리학과 일치하면서 예측 정확성을 향상시키는 최소 센서 집합을 일관되게 식별함을 보여줍니다.

Conclusion: 이 프레임워크는 본질적인 물리적 측정값과 잡음을 자동으로 구분하고, 파생된 상호작용 항이 보완적 정보 또는 중복 정보를 제공하는 시점을 결정합니다. 계산 효율성을 넘어, 이 방법은 정적인 상관관계가 아닌 동적 인과 관계에 근거하여 센서 선택 결정을 뒷받침함으로써 해석 가능성을 향상시킵니다.

Abstract: This paper introduces a novel framework for optimizing observer-based soft
sensors through dynamic causality analysis. Traditional approaches to sensor
selection often rely on linearized observability indices or statistical
correlations that fail to capture the temporal evolution of complex systems. We
address this gap by leveraging liquid-time constant (LTC) networks,
continuous-time neural architectures with input-dependent time constants, to
systematically identify and prune sensor inputs with minimal causal influence
on state estimation. Our methodology implements an iterative workflow: training
an LTC observer on candidate inputs, quantifying each input's causal impact
through controlled perturbation analysis, removing inputs with negligible
effect, and retraining until performance degradation occurs. We demonstrate
this approach on three mechanistic testbeds representing distinct physical
domains: a harmonically forced spring-mass-damper system, a nonlinear
continuous stirred-tank reactor, and a predator-prey model following the
structure of the Lotka-Volterra model, but with seasonal forcing and added
complexity. Results show that our causality-guided pruning consistently
identifies minimal sensor sets that align with underlying physics while
improving prediction accuracy. The framework automatically distinguishes
essential physical measurements from noise and determines when derived
interaction terms provide complementary versus redundant information. Beyond
computational efficiency, this approach enhances interpretability by grounding
sensor selection decisions in dynamic causal relationships rather than static
correlations, offering significant benefits for soft sensing applications
across process engineering, ecological monitoring, and agricultural domains.

</details>


### [63] [MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization](https://arxiv.org/abs/2509.11361)
*Yichen Han,Bojun Liu,Zhengpeng zhou,Guanyu Liu,Zeng Zhang,Yang Yang,Wenli Wang,Isaac N Shi,Yunyan,Lewei He,Tianyu Shi*

Main category: cs.AI

TL;DR: MAPGD는 다중 에이전트 협업과 그래디언트 기반 최적화를 통합한 프레임워크로, 단일 에이전트 및 무작위 기준선보다 정확성과 효율성이 뛰어나며, 그래디언트 융합, 에이전트 전문화, 갈등 해결의 이점을 확인했다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)을 활용하기 위한 프롬프트 엔지니어링의 중요성.

Method: MAPGD는 작업 명확성, 예제 선택, 형식 디자인 및 스타일 세련됨을 위한 전문 에이전트를 특징으로 하며, 갈등 해결을 위한 의미론적 그래디언트 조정 및 효율적인 탐색-활용을 위한 밴딧 기반 후보 선택을 포함한 그래디언트 기반 최적화와 다중 에이전트 협업을 통합한 프레임워크이다.

Result: 분류, 생성 및 추론 작업에 대한 실험 결과, MAPGD가 단일 에이전트 및 무작위 기준선보다 정확성과 효율성에서 우수함을 보여주었고, 그래디언트 융합, 에이전트 전문화 및 갈등 해결의 이점을 확인하였다.

Conclusion: MAPGD는 강력하고 해석 가능한 프롬프트 최적화를 위한 통합된 그래디언트 영감을 받은 다중 에이전트 접근 방식을 제공한다.

Abstract: Prompt engineering is crucial for leveraging large language models (LLMs),
but existing methods often rely on a single optimization trajectory, limiting
adaptability and efficiency while suffering from narrow perspectives, gradient
conflicts, and high computational cost. We propose MAPGD (Multi-Agent Prompt
Gradient Descent), a framework integrating multi-agent collaboration with
gradient-based optimization. MAPGD features specialized agents for task
clarity, example selection, format design, and stylistic refinement; semantic
gradient coordination to resolve conflicts; bandit-based candidate selection
for efficient exploration-exploitation; and theoretical convergence guarantees.
Experiments on classification, generation, and reasoning tasks show MAPGD
outperforms single-agent and random baselines in accuracy and efficiency.
Ablations confirm the benefits of gradient fusion, agent specialization, and
conflict resolution, providing a unified, gradient-inspired multi-agent
approach to robust and interpretable prompt optimization.

</details>


### [64] [Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications](https://arxiv.org/abs/2509.11431)
*Aadil Gani Ganie*

Main category: cs.AI

TL;DR: 이 논문은 AI 에이전트의 보안을 강화하기 위해 역할 기반 접근 제어(RBAC) 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)을 활용한 AI 에이전트는 다양한 분야에서 발전を 가져왔으나, 훈련 데이터의 한계와 특정 다운스트림 작업 수행에 필요한 미세 조정 문제 이슈를 겪고 있다.

Method: AI 에이전트에 역할 기반 접근 제어(RBAC) 프레임워크를 통합하는 방법을 제안한다.

Result: 이 프레임워크는 AI 에이전트의 효과적이고 확장 가능한 배포를 지원하며, 특히 온프레미스 구현에 중점을 둔다.

Conclusion: AI 에이전트의 보안을 강화함으로써 의사결정, 예측 유지보수 및 프로세스 최적화를 지원할 수 있다.

Abstract: The emergence of Large Language Models (LLMs) has significantly advanced
solutions across various domains, from political science to software
development. However, these models are constrained by their training data,
which is static and limited to information available up to a specific date.
Additionally, their generalized nature often necessitates fine-tuning --
whether for classification or instructional purposes -- to effectively perform
specific downstream tasks. AI agents, leveraging LLMs as their core, mitigate
some of these limitations by accessing external tools and real-time data,
enabling applications such as live weather reporting and data analysis. In
industrial settings, AI agents are transforming operations by enhancing
decision-making, predictive maintenance, and process optimization. For example,
in manufacturing, AI agents enable near-autonomous systems that boost
productivity and support real-time decision-making. Despite these advancements,
AI agents remain vulnerable to security threats, including prompt injection
attacks, which pose significant risks to their integrity and reliability. To
address these challenges, this paper proposes a framework for integrating
Role-Based Access Control (RBAC) into AI agents, providing a robust security
guardrail. This framework aims to support the effective and scalable deployment
of AI agents, with a focus on on-premises implementations.

</details>


### [65] [MedicalOS: An LLM Agent based Operating System for Digital Healthcare](https://arxiv.org/abs/2509.11507)
*Jared Zhu,Junde Wu*

Main category: cs.AI

TL;DR: 본 연구는 디지털 헬스케어를 위해 설계된 에이전트 기반 운영 시스템인 MedicalOS를 제안하며, 이는 인공지능을 통해 임상 프로세스를 자동화하고 개선할 수 있는 가능성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 디지털 건강 기술의 발전에도 불구하고, 임상의들은 여전히 여러 도구를 관리하고 복잡한 사용자 인터페이스를 탐색하는 데 어려움을 겪고 있다. 이로 인해 환자 관리에 필요한 시간을 잃고 있다.

Method: 에이전트 기반의 MedicalOS를 통해 인간의 지시를 미리 정의된 디지털 헬스케어 명령으로 변환하는 추상화 계층을 제공하고, 이를 다양한 프로그래밍 언어를 사용하여 구현하였다.

Result: 214명의 환자 사례와 22개 전문 분야를 통해 실증적으로 MedicalOS를 검증하였고, 높은 진단 정확도와 신뢰성, 임상적으로 적합한 검사 요청 및 일관된 구조화된 보고서 및 약물 추천 생성을 보여주었다.

Conclusion: 이러한 결과는 MedicalOS가 임상 실무에서의 워크플로우 자동화를 위한 신뢰할 수 있고 확장 가능한 기반임을 강조한다.

Abstract: Decades' advances in digital health technologies, such as electronic health
records, have largely streamlined routine clinical processes. Yet, most these
systems are still hard to learn and use: Clinicians often face the burden of
managing multiple tools, repeating manual actions for each patient, navigating
complicated UI trees to locate functions, and spending significant time on
administration instead of caring for patients. The recent rise of large
language model (LLM) based agents demonstrates exceptional capability in coding
and computer operation, revealing the potential for humans to interact with
operating systems and software not by direct manipulation, but by instructing
agents through natural language. This shift highlights the need for an
abstraction layer, an agent-computer interface, that translates human language
into machine-executable commands. In digital healthcare, however, requires a
more domain-specific abstractions that strictly follow trusted clinical
guidelines and procedural standards to ensure safety, transparency, and
compliance. To address this need, we present \textbf{MedicalOS}, a unified
agent-based operational system designed as such a domain-specific abstract
layer for healthcare. It translates human instructions into pre-defined digital
healthcare commands, such as patient inquiry, history retrieval, exam
management, report generation, referrals, treatment planning, that we wrapped
as off-the-shelf tools using machine languages (e.g., Python, APIs, MCP,
Linux). We empirically validate MedicalOS on 214 patient cases across 22
specialties, demonstrating high diagnostic accuracy and confidence, clinically
sound examination requests, and consistent generation of structured reports and
medication recommendations. These results highlight MedicalOS as a trustworthy
and scalable foundation for advancing workflow automation in clinical practice.

</details>


### [66] [A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models](https://arxiv.org/abs/2509.11575)
*Ching Chang,Yidan Shi,Defu Cao,Wei Yang,Jeehyun Hwang,Haixin Wang,Jiacheng Pang,Wei Wang,Yan Liu,Wen-Chih Peng,Tien-Fu Chen*

Main category: cs.AI

TL;DR: 이 논문은 시간 시리즈 추론을 정의하고 다양한 추론 토폴로지를 기반으로 문헌을 정리합니다.


<details>
  <summary>Details</summary>
Motivation: 시간 시리즈 추론에서 시간은 첫 번째 축으로 다루어지며 중간 증거가 답변에 직접 통합됩니다.

Method: 이 논문은 직접 추론, 명시적 중간 단계가 있는 선형 체인 추론, 탐색 및 수정 및 집계를 수행하는 가지 구조 추론의 세 가지 가족으로 토폴로지를 구성합니다.

Result: 각 토폴로지가 가능하게 하는 것과 신뢰성 또는 견고성에서 주저하는 지점을 보여주며, 연구 및 배포를 지원하는 데이터셋, 벤치마크 및 리소스를 포함하여 다양한 도메인에서 방법과 시스템을 검토합니다.

Conclusion: 미래의 발전은 추론 품질을 유용성과 연결하는 벤치마크와 비용 및 위험에 대한 절충점을 갖춘 폐쇄 루프 테스트 베드에 의존할 것입니다.

Abstract: Time series reasoning treats time as a first-class axis and incorporates
intermediate evidence directly into the answer. This survey defines the problem
and organizes the literature by reasoning topology with three families: direct
reasoning in one step, linear chain reasoning with explicit intermediates, and
branch-structured reasoning that explores, revises, and aggregates. The
topology is crossed with the main objectives of the field, including
traditional time series analysis, explanation and understanding, causal
inference and decision making, and time series generation, while a compact tag
set spans these axes and captures decomposition and verification, ensembling,
tool use, knowledge access, multimodality, agent loops, and LLM alignment
regimes. Methods and systems are reviewed across domains, showing what each
topology enables and where it breaks down in faithfulness or robustness, along
with curated datasets, benchmarks, and resources that support study and
deployment (https://github.com/blacksnail789521/Time-Series-Reasoning-Survey).
Evaluation practices that keep evidence visible and temporally aligned are
highlighted, and guidance is distilled on matching topology to uncertainty,
grounding with observable artifacts, planning for shift and streaming, and
treating cost and latency as design budgets. We emphasize that reasoning
structures must balance capacity for grounding and self-correction against
computational cost and reproducibility, while future progress will likely
depend on benchmarks that tie reasoning quality to utility and on closed-loop
testbeds that trade off cost and risk under shift-aware, streaming, and
long-horizon settings. Taken together, these directions mark a shift from
narrow accuracy toward reliability at scale, enabling systems that not only
analyze but also understand, explain, and act on dynamic worlds with traceable
evidence and credible outcomes.

</details>


### [67] [HeLoFusion: An Efficient and Scalable Encoder for Modeling Heterogeneous and Multi-Scale Interactions in Trajectory Prediction](https://arxiv.org/abs/2509.11719)
*Bingqing Wei,Lianmin Chen,Zhongyu Xia,Yongtao Wang*

Main category: cs.AI

TL;DR: 본 논문은 자율 주행에서 다중 에이전트 궤적 예측을 위한 HeLoFusion을 소개하며, 복잡한 사회적 역학을 효과적으로 모델링하는 방안을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 궤적 예측은 복잡한 사회적 역학을 이해하는 것을 필요로 하며, 기존 방법들은 이러한 역학을 충분히 포착하는 데 어려움을 겪고 있다.

Method: HeLoFusion은 각 에이전트를 중심으로 지역적이고 다중 스케일의 그래프를 구성하여 에이전트 간의 직접 쌍종속성과 복합 그룹 상호작용을 모델링한다.

Result: HeLoFusion은 Waymo Open Motion Dataset에서 최첨단 성능을 달성하고 Soft mAP 및 minADE와 같은 주요 메트릭에 대한 새로운 기준을 설정하였다.

Conclusion: HeLoFusion은 다중 스케일 및 이질적 상호작용을 명시적으로 모델링하는 지역화 중심 아키텍처가 운동 예측을 발전시키기 위한 매우 효과적인 전략임을 보여준다.

Abstract: Multi-agent trajectory prediction in autonomous driving requires a
comprehensive understanding of complex social dynamics. Existing methods,
however, often struggle to capture the full richness of these dynamics,
particularly the co-existence of multi-scale interactions and the diverse
behaviors of heterogeneous agents. To address these challenges, this paper
introduces HeLoFusion, an efficient and scalable encoder for modeling
heterogeneous and multi-scale agent interactions. Instead of relying on global
context, HeLoFusion constructs local, multi-scale graphs centered on each
agent, allowing it to effectively model both direct pairwise dependencies and
complex group-wise interactions (\textit{e.g.}, platooning vehicles or
pedestrian crowds). Furthermore, HeLoFusion tackles the critical challenge of
agent heterogeneity through an aggregation-decomposition message-passing scheme
and type-specific feature networks, enabling it to learn nuanced,
type-dependent interaction patterns. This locality-focused approach enables a
principled representation of multi-level social context, yielding powerful and
expressive agent embeddings. On the challenging Waymo Open Motion Dataset,
HeLoFusion achieves state-of-the-art performance, setting new benchmarks for
key metrics including Soft mAP and minADE. Our work demonstrates that a
locality-grounded architecture, which explicitly models multi-scale and
heterogeneous interactions, is a highly effective strategy for advancing motion
forecasting.

</details>


### [68] [Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning](https://arxiv.org/abs/2509.11880)
*Carlos Celemin,Joseph Brennan,Pierluigi Vito Amadori,Tim Bradley*

Main category: cs.AI

TL;DR: 이 논문은 비디오 게임 환경에서 에이전트를 위한 보다 효과적인 상태 표현을 학습하는데 초점을 맞춘 감독 대조 학습(SupCon)과 모방 학습(IL)의 새로운 응용을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트가 비디오 게임 환경에서 더 나은 상태 표현을 학습할 수 있도록 하기 위해서입니다.

Method: SupCon 손실을 연속 출력 공간과 통합하는 접근 방식을 제안하여, 환경의 행동 유형에 관한 제약 없이 SupCon을 작동할 수 있게 합니다.

Result: 3D 게임 Astro Bot 및 Returnal과 여러 2D Atari 게임에서 실험을 통해, 감독된 행동 예측 손실 함수로만 훈련된 기준 모델과 비교하여 표현 품질이 개선되고, 학습 수렴 속도가 빨라지며, 일반화 성능이 향상됨을 보여줍니다.

Conclusion: 이 연구는 SupCon을 IL에 효과적으로 통합할 수 있는 방법을 제공하며, 이를 통해 게임 환경에서 에이전트의 학습 능력을 향상시킬 수 있음을 시사합니다.

Abstract: This paper introduces a novel application of Supervised Contrastive Learning
(SupCon) to Imitation Learning (IL), with a focus on learning more effective
state representations for agents in video game environments. The goal is to
obtain latent representations of the observations that capture better the
action-relevant factors, thereby modeling better the cause-effect relationship
from the observations that are mapped to the actions performed by the
demonstrator, for example, the player jumps whenever an obstacle appears ahead.
We propose an approach to integrate the SupCon loss with continuous output
spaces, enabling SupCon to operate without constraints regarding the type of
actions of the environment. Experiments on the 3D games Astro Bot and Returnal,
and multiple 2D Atari games show improved representation quality, faster
learning convergence, and better generalization compared to baseline models
trained only with supervised action prediction loss functions.

</details>


### [69] [EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models](https://arxiv.org/abs/2509.11914)
*Yiqun Yao,Naitong Yu,Xiang Li,Xin Jiang,Xuezhi Fang,Wenjia Ma,Xuying Meng,Jing Li,Aixin Sun,Yequan Wang*

Main category: cs.AI

TL;DR: EgoMem은 실시간 다중 사용자를 인식하고 개인화된 응답을 제공하며 장기 지식을 유지하는 첫 번째 평생 기억 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: 실시간 다중 사용자의 개인化된 상호작용과 장기 지식 유지를 가능하게 하기 위해서는 새로운 기억 에이전트가 필요하다.

Method: EgoMem은 세 가지 비동기 프로세스를 통해 사용자 인식, 개인화된 응답 생성, 기억 관리 과정을 수행한다.

Result: EgoMem의 검색 및 기억 관리 모듈은 테스트 세트에서 95% 이상의 정확도를 달성하였다.

Conclusion: EgoMem는 평생, 실시간 및 구체적 시나리오에 적합하며 미래 연구를 위한 강력한 기준점을 설정한다.

Abstract: We introduce EgoMem, the first lifelong memory agent tailored for full-duplex
models that process real-time omnimodal streams. EgoMem enables real-time
models to recognize multiple users directly from raw audiovisual streams, to
provide personalized response, and to maintain long-term knowledge of users'
facts, preferences, and social relationships extracted from audiovisual
history. EgoMem operates with three asynchronous processes: (i) a retrieval
process that dynamically identifies user via face and voice, and gathers
relevant context from a long-term memory; (ii) an omnimodal dialog process that
generates personalized audio responses based on the retrieved context; and
(iii) a memory management process that automatically detects dialog boundaries
from omnimodal streams, and extracts necessary information to update the
long-term memory. Unlike existing memory agents for LLMs, EgoMem relies
entirely on raw audiovisual streams, making it especially suitable for
lifelong, real-time, and embodied scenarios. Experimental results demonstrate
that EgoMem's retrieval and memory management modules achieve over 95% accuracy
on the test set. When integrated with a fine-tuned RoboEgo omnimodal chatbot,
the system achieves fact-consistency scores above 87% in real-time personalized
dialogs, establishing a strong baseline for future research.

</details>


### [70] [Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare](https://arxiv.org/abs/2509.11944)
*Susanta Mitra*

Main category: cs.AI

TL;DR: 이 논문은 올바른 진단을 위한 다중모드 의료 추론의 도전을 해결하기 위해 제안된 새로운 시간 그래프 기반 추론 모델을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 모드 데이터에 대한 정확한 진단을 지원하기 위해 의료 전문인들이 직면한 문제를 해결하기 위함이다.

Method: 유향 그래프를 통한 새로운 시간 그래프 기반 추론 프로세스를 제안하여 이유를 역추적하고 정제하는 방법을 사용한다.

Result: 기본 실험과 분석 결과가 이 접근 방식의 혁신성과 실용성을 입증한다.

Conclusion: 제안된 다중 에이전트 시간 추론 프레임워크는 추론 출력을 더욱 정밀하게 하기 위해 작업 분배 및 교차 검증 메커니즘을 제공한다.

Abstract: Healthcare and medicine are multimodal disciplines that deal with multimodal
data for reasoning and diagnosing multiple diseases. Although some multimodal
reasoning models have emerged for reasoning complex tasks in scientific
domains, their applications in the healthcare domain remain limited and fall
short in correct reasoning for diagnosis. To address the challenges of
multimodal medical reasoning for correct diagnosis and assist the healthcare
professionals, a novel temporal graph-based reasoning process modelled through
a directed graph has been proposed in the current work. It helps in
accommodating dynamic changes in reasons through backtracking, refining the
reasoning content, and creating new or deleting existing reasons to reach the
best recommendation or answer. Again, consideration of multimodal data at
different time points can enable tracking and analysis of patient health and
disease progression. Moreover, the proposed multi-agent temporal reasoning
framework provides task distributions and a cross-validation mechanism to
further enhance the accuracy of reasoning outputs. A few basic experiments and
analysis results justify the novelty and practical utility of the proposed
preliminary approach.

</details>


### [71] [MusicSwarm: Biologically Inspired Intelligence for Music Composition](https://arxiv.org/abs/2509.11973)
*Markus J. Buehler*

Main category: cs.AI

TL;DR: 이 논문은 동적 합의, 공유 메모리 및 상호작용 규칙을 통해 장기적인 창의적 구조를 효율적으로 생성할 수 있는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 탈중앙화된 스왐이 음악 작곡에서 나타날 수 있음을 보여준다.

Method: 동일한 얼어붙은 기반 모델들이 피어투피어 신호를 통해 협력하는 방식으로 음악을 생성한다.

Result: 탈중앙화된 스왐은 기존의 중앙 집중형 시스템보다 높은 품질과 다양한 구조를 제공한다.

Conclusion: MusicSwarm은 음악을 넘어 협력적 글쓰기, 디자인 및 과학적 발견에 즉시 적용 가능한 창의적 구조를 제공한다.

Abstract: We show that coherent, long-form musical composition can emerge from a
decentralized swarm of identical, frozen foundation models that coordinate via
stigmergic, peer-to-peer signals, without any weight updates. We compare a
centralized multi-agent system with a global critic to a fully decentralized
swarm in which bar-wise agents sense and deposit harmonic, rhythmic, and
structural cues, adapt short-term memory, and reach consensus. Across symbolic,
audio, and graph-theoretic analyses, the swarm yields superior quality while
delivering greater diversity and structural variety and leads across creativity
metrics. The dynamics contract toward a stable configuration of complementary
roles, and self-similarity networks reveal a small-world architecture with
efficient long-range connectivity and specialized bridging motifs, clarifying
how local novelties consolidate into global musical form. By shifting
specialization from parameter updates to interaction rules, shared memory, and
dynamic consensus, MusicSwarm provides a compute- and data-efficient route to
long-horizon creative structure that is immediately transferable beyond music
to collaborative writing, design, and scientific discovery.

</details>


### [72] [Human-AI Use Patterns for Decision-Making in Disaster Scenarios: A Systematic Review](https://arxiv.org/abs/2509.12034)
*Emmanuel Adjei Domfeh,Christopher L. Dancy*

Main category: cs.AI

TL;DR: 본 논문은 재난 관리 전 과정에서 의사 결정을 지원하는 인간-AI 협력 패턴의 체계적 검토를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 고위험 재난 시나리오에서 시의적절하고 정보에 기반한 의사 결정이 필요하나, 불확실성, 동적 환경 및 한정된 자원으로 인해 도전받고 있습니다.

Method: 51개의 동료 검토 연구를 통해 인간-AI 의사 지원 시스템, 작업 및 자원 조정, 신뢰성과 투명성, 시뮬레이션 및 교육의 네 가지 주요 범주를 식별했습니다.

Result: AI 시스템이 상황 인식을 향상시키고, 응답 효율성을 개선하며, 복잡한 의사 결정을 지원할 수 있는 방법을 강조했습니다. 또한 확장성, 해석 가능성 및 시스템 상호 운용성에서의 핵심적인 한계도 드러났습니다.

Conclusion: 적응 가능하고 신뢰할 수 있으며 맥락 인식이 가능한 인간-AI 시스템이 재난 회복력을 개선하고 공정한 회복 결과를 위해 필요하다는 점을 강조하며 주요 과제와 향후 연구 방향을 정리합니다.

Abstract: In high-stakes disaster scenarios, timely and informed decision-making is
critical yet often challenged by uncertainty, dynamic environments, and limited
resources. This paper presents a systematic review of Human-AI collaboration
patterns that support decision-making across all disaster management phases.
Drawing from 51 peer-reviewed studies, we identify four major categories:
Human-AI Decision Support Systems, Task and Resource Coordination, Trust and
Transparency, and Simulation and Training. Within these, we analyze
sub-patterns such as cognitive-augmented intelligence, multi-agent
coordination, explainable AI, and virtual training environments. Our review
highlights how AI systems may enhance situational awareness, improves response
efficiency, and support complex decision-making, while also surfacing critical
limitations in scalability, interpretability, and system interoperability. We
conclude by outlining key challenges and future research directions,
emphasizing the need for adaptive, trustworthy, and context-aware Human-AI
systems to improve disaster resilience and equitable recovery outcomes.

</details>
