<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 19]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.LG](#cs.LG) [Total: 13]
- [cs.CR](#cs.CR) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records](https://arxiv.org/abs/2512.13700)
*Mitchell A. Klusty,Elizabeth C. Solie,Caroline N. Leach,W. Vaiden Logan,Lynnet E. Richey,John C. Gensel,David P. Szczykutowicz,Bryan C. McLellan,Emily B. Collier,Samuel E. Armstrong,V. K. Cody Bumgardner*

Main category: cs.AI

TL;DR: 이 논문은 임상 기록에서 자동화된 구조화된 특징 추출을 위한 안전하고 모듈화된 프레임워크를 제시하며, 이는Clinical Notes의 자동 분석으로 임상 연구의 효율성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 임상 연구에서 수동 차트 검토는 매우 시간 소모적이고 자원 집약적인 과정으로, 전문의가 구조화되지 않은 전자 건강 기록에서 복잡한 정보를 추출하는 데 필요합니다.

Method: 당사는 기관 승인 및 HIPAA 준수 컴퓨팅 인프라에서 지역적으로 배포된 대형 언어 모델(LLMs)을 활용하여 임상 노트로부터 자동 구조화된 특징 추출을 위한 안전하고 모듈화된 프레임워크를 제시합니다. 이 시스템은 LLM의 검색 보강 생성(RAG) 및 구조화된 응답 방법을 통합하여 다양한 임상 도메인에 대해 기능 추출을 제공하는 광범위하게 배포 가능한 스케일러블 컨테이너를 만듭니다.

Result: 프레임워크는 전문가 주석 데이터셋과 비교했을 때 수많은 환자 노트에서 여러 의료 특성에 대해 높은 정확성을 달성했으며, 수동 검토에서 놓친 여러 주석 오류를 식별했습니다.

Conclusion: 이 프레임워크는 LLM 시스템이 수동 차트 검토의 부담을 줄이고 데이터 캡처의 일관성을 증가시켜 임상 연구를 가속화할 수 있는 잠재력을 보여줍니다.

Abstract: Manual chart review remains an extremely time-consuming and resource-intensive component of clinical research, requiring experts to extract often complex information from unstructured electronic health record (EHR) narratives. We present a secure, modular framework for automated structured feature extraction from clinical notes leveraging locally deployed large language models (LLMs) on institutionally approved, Health Insurance Portability and Accountability Act (HIPPA)-compliant compute infrastructure. This system integrates retrieval augmented generation (RAG) and structured response methods of LLMs into a widely deployable and scalable container to provide feature extraction for diverse clinical domains. In evaluation, the framework achieved high accuracy across multiple medical characteristics present in large bodies of patient notes when compared against an expert-annotated dataset and identified several annotation errors missed in manual review. This framework demonstrates the potential of LLM systems to reduce the burden of manual chart review through automated extraction and increase consistency in data capture, accelerating clinical research.

</details>


### [2] [Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents](https://arxiv.org/abs/2512.13704)
*Doohee You,Sundeep Paul*

Main category: cs.AI

TL;DR: 이 논문에서는 레이블 노이즈를 자동으로 식별하고 수정하는 시스템인 Adjudicator를 제시하며, 이는 생산 환경에서 검증되었다.


<details>
  <summary>Details</summary>
Motivation: 생산 기계 학습 시스템의 성능은 훈련 데이터의 품질에 의해 제한되며, 산업 응용에서 노이즈가 있는 레이블은 성능을 저하시킬 수 있다.

Method: Adjudicator는 이를 신경-기호적 과제로 모델링하며, 아이템 맥락을 통합하기 위해 동적인 지식 그래프(KG)를 구축하고, 여기서 KM-informed 모델이 '에이전트의 위원회'를 활용하여 레이블의 유효성을 토론하고 투표한다.

Result: Adjudicator는 AlleNoise 벤치마크의 1,000개 항목 균형 서브셋에서 0.99 F1 점수를 기록하며, 단일 LLM 기준의 0.48 F1 및 비-KG 위원회의 0.59 F1보다 훨씬 높은 성능을 보인다.

Conclusion: 이 결과는 자동화된 고정밀 데이터 검증을 위한 강력하고 설명 가능한 시스템을 보여주며, 엄격한 규제를 받는 산업 환경에서 골드 데이터셋을 생성하는 중요한 개념 증명을 수행한다.

Abstract: The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, a system that addresses the critical data mining challenge of automatically identifying and correcting label noise and has been validated for production deployment. Adjudicator models this as a neuro-symbolic task, first constructing a dynamic Knowledge Graph (KG) to unify item context. This KG then informs a "Council of Agents," a novel multi-agent Large Language Model architecture where specialized agents debate and vote on a label's validity. We validate our system on a 1,000-item balanced subset of the AlleNoise benchmark. Our KG-informed model achieves a 0.99 F1-score, significantly outperforming a single-LLM baseline (0.48 F1) and a non-KG council (0.59 F1). Our analysis reveals this is due to a Precision, achieved by a novel override logic that uses the KG to perfectly identify complex, structural errors (complete Recall) -- a class of errors that baselines fail to find. This result demonstrates a robust and explainable system for automated, high-precision data verification, serving as a vital proof-of-concept for generating golden datasets in strictly governed industrial environments.

</details>


### [3] [LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms](https://arxiv.org/abs/2512.13713)
*Ali Parsaee,Yashar Talebirad,Csongor Szepesvári,Vishwajeet Ohal,Eden Redman*

Main category: cs.AI

TL;DR: LLM의 분산 시스템 내에서의 조정 능력을 평가하기 위한 LoopBench라는 벤치마크를 소개하고, 고급 추론 모델이 교착 상태를 피하는 전략을 개발할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: LLM이 자율 에이전트로 점점 더 많이 활용되고 있지만, 분산 시스템에서의 조정 능력이 여전히 잘 이해되지 않고 있다.

Method: LoopBench는 한정된 색상으로 홀수 주기 그래프를 색칠하는 문제를 평가하기 위한 벤치마크로, 일관된 메모리 형태로 전략 전달 메커니즘을 구현하였다.

Result: 표준 LLM 및 고전적 휴리스틱은 어려움을 겪는 반면, 고급 추론 모델은 교착 상태를 벗어나는 전략을 고안하였다.

Conclusion: LoopBench는 언어 기반 추론에 기반한 분산 알고리즘 연구를 가능하게 하며, 집단 지성을 위한 테스트베드 역할을 한다.

Abstract: Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C_3, C_5, C_{11}$) with limited colors, where deterministic, non-communicating agents fail in infinite loops. A strategy passing mechanism is implemented as a form of consistent memory. We show that while standard LLMs and classical heuristics struggle, advanced reasoning models (e.g., O3) devise strategies to escape deadlocks. LoopBench allows the study of emergent distributed algorithms based on language-based reasoning, offering a testbed for collective intelligence.

</details>


### [4] [EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery](https://arxiv.org/abs/2512.13857)
*Kamer Ali Yuksel*

Main category: cs.AI

TL;DR: EvoLattice는 하나의 방향 비순환 그래프 내에서 전체 후보 프로그램 집단을 표현하는 프레임워크로, 생성 및 다중 에이전트 시스템에서 LLM의 사용을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 접근법은 단일 후보만 유지하는 오버라이트 기반 변형에 의존하여 유용한 변형을 폐기하고 구조적 실패를 초래하는 취약한 탐색 공간을 탐색한다.

Method: EvoLattice는 각 노드가 여러 가지 지속적인 대안을 저장하고, 그래프를 통해 유효한 경로가 고유한 실행 가능한 후보를 정의하는 구조를 사용한다. 각 대안은 그 등장하는 모든 경로에서 점수를 매김으로써 정밀한 대안 수준의 평가가 가능하다.

Result: EvoLattice는 기존 LLM 기반 방법보다 안정적인 진화, 더 큰 표현력 및 더 강한 개선 경로를 제공하며, 품질-다양성 최적화와 유사한 동태를 나타낸다.

Conclusion: EvoLattice는 LLM의 독립적인 결정론적 자기 수리 메커니즘을 통해 구조적 올바름을 보장하고, 대안을 프롬프트 조각이나 하위 에이전트 행동으로 해석하여 에이전트 진화에도 자연스럽게 확장된다.

Abstract: Large language models (LLMs) are increasingly used to evolve programs and multi-agent systems, yet most existing approaches rely on overwrite-based mutations that maintain only a single candidate at a time. Such methods discard useful variants, suffer from destructive edits, and explore a brittle search space prone to structural failure. We introduce EvoLattice, a framework that represents an entire population of candidate programs or agent behaviors within a single directed acyclic graph. Each node stores multiple persistent alternatives, and every valid path through the graph defines a distinct executable candidate, yielding a large combinatorial search space without duplicating structure. EvoLattice enables fine-grained alternative-level evaluation by scoring each alternative across all paths in which it appears, producing statistics that reveal how local design choices affect global performance. These statistics provide a dense, data-driven feedback signal for LLM-guided mutation, recombination, and pruning, while preserving successful components. Structural correctness is guaranteed by a deterministic self-repair mechanism that enforces acyclicity and dependency consistency independently of the LLM. EvoLattice naturally extends to agent evolution by interpreting alternatives as prompt fragments or sub-agent behaviors. Across program synthesis (proxy and optimizer meta-learning), EvoLattice yields more stable evolution, greater expressivity, and stronger improvement trajectories than prior LLM-guided methods. The resulting dynamics resemble quality-diversity optimization, emerging implicitly from EvoLattice's internal multi-alternative representation rather than an explicit external archive.

</details>


### [5] [Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN](https://arxiv.org/abs/2512.13715)
*Fatemeh Lotfi,Fatemeh Afghah*

Main category: cs.AI

TL;DR: 이 논문은 O-RAN에서 자원 할당과 네트워크 슬라이싱을 최적화하기 위한 적응형 메타 계층 강화 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현대 애플리케이션의 복잡성이 증가함에 따라 실시간 적응성 및 효율적인 자원 관리를 요구하는 무선 네트워크의 필요성이 커지고 있다.

Method: 모델 불가지론적 메타 학습(MAML)에서 영감을 받은 적응형 메타 계층 강화 학습 프레임워크는 계층적 제어와 메타 학습을 통합하여 자원 할당과 네트워크 슬라이싱을 공동으로 최적화한다.

Result: 기초 RL 및 메타-RL 접근 방식과 비교했을 때 네트워크 관리 효율성이 19.8% 향상되었고, eMBB, URLLC 및 mMTC 슬라이스 전반에 걸쳐 더 빠른 적응과 높은 QoS 만족도를 달성하였다.

Conclusion: 추가적인 소거 및 확장성 연구는 네트워크 규모가 증가함에 따라 최대 40% 더 빠른 적응과 일관된 공정성, 지연, 처리량 성능을 달성하여 방법의 강력함을 확인하였다.

Abstract: The increasing complexity of modern applications demands wireless networks capable of real time adaptability and efficient resource management. The Open Radio Access Network (O-RAN) architecture, with its RAN Intelligent Controller (RIC) modules, has emerged as a pivotal solution for dynamic resource management and network slicing. While artificial intelligence (AI) driven methods have shown promise, most approaches struggle to maintain performance under unpredictable and highly dynamic conditions. This paper proposes an adaptive Meta Hierarchical Reinforcement Learning (Meta-HRL) framework, inspired by Model Agnostic Meta Learning (MAML), to jointly optimize resource allocation and network slicing in O-RAN. The framework integrates hierarchical control with meta learning to enable both global and local adaptation: the high-level controller allocates resources across slices, while low level agents perform intra slice scheduling. The adaptive meta-update mechanism weights tasks by temporal difference error variance, improving stability and prioritizing complex network scenarios. Theoretical analysis establishes sublinear convergence and regret guarantees for the two-level learning process. Simulation results demonstrate a 19.8% improvement in network management efficiency compared with baseline RL and meta-RL approaches, along with faster adaptation and higher QoS satisfaction across eMBB, URLLC, and mMTC slices. Additional ablation and scalability studies confirm the method's robustness, achieving up to 40% faster adaptation and consistent fairness, latency, and throughput performance as network scale increases.

</details>


### [6] [Grammar Search for Multi-Agent Systems](https://arxiv.org/abs/2512.14079)
*Mayank Singh,Vikas Yadav,Shiva Krishna Reddy Malay,Shravan Nayak,Sai Rajeswar,Sathwik Tejaswi Madhusudhan,Eduardo Blanco*

Main category: cs.AI

TL;DR: 본 논문에서는 LLM 기반의 자유형 검색 대신, 간단하고 조합 가능한 구성 요소를 사용하여 다중 에이전트 시스템 자동 검색을 위한 구조화된 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템의 자동 검색이 에이전틱 AI 연구에서 핵심 초점으로 떠오르고 있다.

Method: 다양한 구성 요소를 조합하여 고정된 세트를 탐색하는 구조화된 프레임워크를 제안한다.

Result: 우리의 방법은 후보 생성 단계에서 LLM의 생성 유연성이 부족함에도 불구하고, 두 가지 도메인(수학 및 질문 응답)에서 다섯 개의 벤치마크 중 네 개에서 이전 접근 방식을 초과 성과를 보인다.

Conclusion: 이 방법은 보다 비용 효율적인 검색 프로세스와 단순한 논리를 가진 모듈식, 해석 가능한 다중 에이전트 시스템 생성을 포함한 추가 장점을 제공한다.

Abstract: Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple, composable components. We show that, despite lacking the generative flexibility of LLMs during the candidate generation stage, our method outperforms prior approaches on four out of five benchmarks across two domains: mathematics and question answering. Furthermore, our method offers additional advantages, including a more cost-efficient search process and the generation of modular, interpretable multi-agent systems with simpler logic.

</details>


### [7] [ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making](https://arxiv.org/abs/2512.13716)
*Yitong Luo,Ziang Chen,Hou Hei Lam,Jiayu zhan,Junqi Wang,Zhenliang Zhang,Xue Feng*

Main category: cs.AI

TL;DR: 개인화된 의사결정은 인간-AI 상호작용에 필수적이며, AI 에이전트가 개별 사용자의 가치 선호에 맞게 행동할 수 있도록 합니다. 본 연구에서는 가치 중심의 개인화된 의사결정 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 실제 응용 프로그램으로 확장됨에 따라, 작업 완료나 집단 정렬을 넘어 개인화된 가치에 적응하는 것이 중요한 도전 과제가 되었습니다.

Method: 본 연구에서는 ValuePilot이라는 2단계 프레임워크를 소개합니다. 이는 데이터셋 생성 도구(DGT)와 의사결정 모듈(DMM)으로 구성됩니다. DGT는 인간-LLM 협력 파이프라인에서 다양한 가치 주석 시나리오를 생성하며, DMM은 개인 가치 선호를 기반으로 행동을 평가하도록 학습합니다.

Result: DMM은 이전에 보지 못한 시나리오에서 인간 행동 선택과의 정렬에 있어 GPT-5, Claude-Sonnet-4, Gemini-2-flash, Llama-3.1-70b와 같은 강력한 LLM 기준보다 우수한 성과를 보였습니다.

Conclusion: 결과는 가치 중심의 의사결정이 해석 가능하고 개인화된 AI 에이전트를 구축하기 위한 효과적이고 확장 가능한 공학 경로임을 보여줍니다.

Abstract: Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task completion or collective alignment has become a critical challenge. We address this by proposing a value-driven approach to personalized decision-making. Human values serve as stable, transferable signals that support consistent and generalizable behavior across contexts. Compared to task-oriented paradigms driven by external rewards and incentives, value-driven decision-making enhances interpretability and enables agents to act appropriately even in novel scenarios. We introduce ValuePilot, a two-phase framework consisting of a dataset generation toolkit (DGT) and a decision-making module (DMM). DGT constructs diverse, value-annotated scenarios from a human-LLM collaborative pipeline. DMM learns to evaluate actions based on personal value preferences, enabling context-sensitive, individualized decisions. When evaluated on previously unseen scenarios, DMM outperforms strong LLM baselines, including GPT-5, Claude-Sonnet-4, Gemini-2-flash, and Llama-3.1-70b, in aligning with human action choices. Our results demonstrate that value-driven decision-making is an effective and extensible engineering pathway toward building interpretable, personalized AI agents.

</details>


### [8] [Mathematics and Coding are Universal AI Benchmarks](https://arxiv.org/abs/2512.13764)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 본 연구는 AI 에이전트를 위한 심리 측정 배터리의 모듈라이 공간 내에서 수학과 코딩의 특별한 역할을 조사한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 성능 향상에 있어 수학적 정리 증명과 코딩의 기여를 이해하기 위함이다.

Method: AAI 프레임워크와 GVU 동역학을 기반으로 수학적 섬유를 정의하고, формальные 증명 커널과의 조합을 통해 GVU 흐름의 특성을 분석한다.

Result: 수학적 정리 증명과 코딩 작업에 의해 생성되는 배터리의 부분공간은 평가 메트릭에 따라 배터리의 모듈라이 공간 내에서 조밀하다.

Conclusion: 수학과 코딩이 AI 에이전트의 자기 개선에 필요한 ‘보편적 좌표’ 역할을 하며, 공식 수학이 진보된 AI 에이전트의 재귀적 자기 개선을 위한 자연스러운 점화 영역이 된다.

Abstract: We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.

</details>


### [9] [MobileWorldBench: Towards Semantic World Modeling For Mobile Agents](https://arxiv.org/abs/2512.14014)
*Shufan Li,Konstantinos Kallidromitis,Akash Gokul,Yusuke Kato,Kazuki Kozuka,Aditya Grover*

Main category: cs.AI

TL;DR: 이 연구에서는 GUI 에이전트를 위한 세계 모델링의 대안적 접근 방식을 탐구하고, 이를 평가하기 위한 벤치마크와 대규모 데이터셋을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: GUI 설정에서의 시각적 요소 예측의 어려움을 해결하기 위해 자연어를 사용하여 상태 변환을 설명하는 세계 모델링의 대안적 접근 방식이 필요합니다.

Method: MobileWorldBench라는 벤치마크를 소개하고, 1.4M 샘플로 구성된 MobileWorld 데이터셋을 제공하여 비전-언어 모델이 모바일 GUI 에이전트의 세계 모델로서의 기능을 평가합니다.

Result: 새로운 프레임워크를 통해 VLM 세계 모델이 모바일 에이전트의 계획 프레임워크에 통합되어 작업 성공률을 향상시킬 수 있음을 보여줍니다.

Conclusion: 이 연구는 의미론적 세계 모델이 모바일 에이전트에 직접적인 혜택을 줄 수 있다는 것을 입증하였습니다.

Abstract: World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld

</details>


### [10] [Evaluating Small Language Models for Agentic On-Farm Decision Support Systems](https://arxiv.org/abs/2512.14043)
*Enhong Liu,Haiyu Yang,Miel Hostens*

Main category: cs.AI

TL;DR: 경량 대체 모델이 필요한 우유 생산 농업을 위한 결정 지원 도구 개발을 위해 20개의 오픈소스 소형 언어 모델을 평가하고, 이는 농업 하드웨어에서 로컬로 실행 가능한 가능성을 보여줌.


<details>
  <summary>Details</summary>
Motivation: 우유 생산 농업에 필요한 결정 지원 도구의 접근성을 높이고 기술 전문성이 부족한 이해관계자에게 지식에 대한 접근을 확대하기 위해 LLM의 잠재력 활용.

Method: HuggingFace에서 사용 가능한 20개의 오픈소스 소형 언어 모델을 농업 현실에 맞는 계산 제약 하에서 벤치마킹하고, 다섯 개의 작업별 에이전트를 통합한 에이전틱 AI 시스템을 개발하여 평가.

Result: Qwen-4B가 대다수의 작업 카테고리에서 우수한 성능을 보였으나, PySpark를 통한 NoSQL 데이터베이스 상호작용에서 불안정한 효과를 보임.

Conclusion: SLM이 우유 생산 분야의 결정 지원 엔진으로서의 가능성을 평가한 첫 번째 연구로, 프라이버시와 계산 효율성에 중점을 두고 있으며, SLM 보조 도구의 실용적인 배치 가능성을 강조하지만, 농업 특화 질문에서 성능 개선을 위한 추가 조정이 필요함.

Abstract: Large Language Models (LLM) hold potential to support dairy scholars and farmers by supporting decision-making and broadening access to knowledge for stakeholders with limited technical expertise. However, the substantial computational demand restricts access to LLM almost exclusively through cloud-based service, which makes LLM-based decision support tools impractical for dairy farming. To address this gap, lightweight alternatives capable of running locally on farm hardware are required. In this work, we benchmarked 20 open-source Small Language Models (SLM) available on HuggingFace under farm-realistic computing constraints. Building on our prior work, we developed an agentic AI system that integrates five task-specific agents: literature search, web search, SQL database interaction, NoSQL database interaction, and graph generation following predictive models. Evaluation was conducted in two phases. In the first phase, five test questions were used for the initial screening to identify models capable of following basic dairy-related instructions and performing reliably in a compute-constrained environment. Models that passed this preliminary stage were then evaluated using 30 questions (five per task category mentioned above, plus one category addressing integrity and misconduct) in phase two. In results, Qwen-4B achieved superior performance across most of task categories, although showed unstable effectiveness in NoSQL database interactions through PySpark. To our knowledge, this is the first work explicitly evaluating the feasibility of SLM as engines for dairy farming decision-making, with central emphases on privacy and computational efficiency. While results highlight the promise of SLM-assisted tools for practical deployment in dairy farming, challenges remain, and fine-tuning is still needed to refine SLM performance in dairy-specific questions.

</details>


### [11] [Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation](https://arxiv.org/abs/2512.14048)
*Shen Li,Li Huang,Shaoxiong Zhan,Weifeng Sun,Tao Yin,Zhongxin Liu,Meng Yan*

Main category: cs.AI

TL;DR: RoutingGen은 코드 생성을 위한 새로운 난이도 인식 라우팅 프레임워크로, 쉽고 복잡한 작업에 따라 다이나믹하게 프롬프트 전략을 조정하여 효율성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 체인 오브 생각(CoT) 프롬프트 방법이 간단한 작업에서 과도한 사고를 유도하고 코드 생성에서 의도 추상화가 부족하다는 두 가지 제약을 극복하고자 한다.

Method: RoutingGen은 단순한 작업에 대해 적은 샷 프롬프팅을 사용하고, 복잡한 작업에 대해 Intention Chain-of-Thought(ICoT)라는 구조적 추론 전략을 활용하여 모델이 작업의 의도를 포착하도록 안내한다.

Result: RoutingGen은 세 가지 모델과 여섯 가지 표준 코드 생성 벤치마크에서 대부분의 설정에서 최첨단 성능을 달성하며, 평균적으로 전체 토큰 사용량을 46.37% 줄인다.

Conclusion: ICoT는 도전적인 벤치마크에서 기존의 여섯 가지 프롬프트 기준을 초과하는 성능을 보인다.

Abstract: Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.

</details>


### [12] [Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis](https://arxiv.org/abs/2512.14157)
*Yankai Jiang,Yujie Zhang,Peng Zhang,Yichen Li,Jintai Chen,Xiaoming Shi,Shihui Zhen*

Main category: cs.AI

TL;DR: Ophiuchus는 MLLM이 추가적인 시각적 증거 필요성을 판단하고, 의료 이미지 내에서 탐색과 기초를 결정하며, 관련 하위 이미지 내용을 다중 모달 사고 체인에 부드럽게 통합할 수 있도록 돕는 다목적 도구 증강 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: MLLM이 단계별 텍스트 추론 체인을 생성하는 데 진전을 이루었지만, 복잡한 작업에서 세밀한 시각적 영역에 동적으로 초점을 맞춰 정밀한 기초와 진단을 달성하는 데 여전히 어려움을 겪고 있기 때문입니다.

Method: Ophiuchus는 세 단계의 훈련 전략을 채택하여 기본적인 도구 선택과 적응을 달성하고, 반사적 추론을 강화하며, 과제 특정 보상을 직접 최적화하는 방식으로 설계되었습니다.

Result: Ophiuchus는 다양한 의료 벤치마크에서 다른 소스 및 오픈 소스 SOTA 방법들을 지속적으로 초과 성과를 보여주었습니다.

Conclusion: 이 연구는 도구 통합 추론을 통해 진정으로 '이미지로 생각할 수 있는' 의료 AI 에이전트를 향한 길을 밝혀줍니다.

Abstract: Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely "think with images" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.

</details>


### [13] [Gödel's Poetry](https://arxiv.org/abs/2512.14252)
*Kelly J. Davis*

Main category: cs.AI

TL;DR: 이 논문은 Lean4 증명 생성을 위한 전문화된 언어 모델과 어려운 정리를 더 간단한 명제로 재귀적으로 분해하는 새로운 컴퓨터 정리 증명 접근 방식을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 형식적이며 자동화된 정리 증명은 오랫동안 인공지능의 도전과제로 여겨졌습니다.

Method: 이 시스템은 다중 에이전트 아키텍처를 통해 자동 형식화, 증명 생성, 어려운 정리의 명제로의 분해 및 이러한 명제의 재귀적 증명을 조정합니다.

Result: 분해 없이 miniF2F에서 90.4%의 통과율을 달성하며, 분해를 적용하면 이 결과가 크게 개선됩니다.

Conclusion: 이 시스템은 PyPI에서 goedels-poetry로 제공되며, 오픈 소스 구현을 통해 다른 언어 모델로의 적응과 사용자 정의 기능 확장을 지원합니다.

Abstract: Formal, automated theorem proving has long been viewed as a challenge to artificial intelligence. We introduce here a new approach to computer theorem proving, one that employs specialized language models for Lean4 proof generation combined with recursive decomposition of difficult theorems into simpler entailing propositions. These models are coordinated through a multi-agent architecture that orchestrates autoformalization (if required), proof generation, decomposition of difficult theorems into simpler entailing propositions, and recursive proof (and/or decomposition) of these propositions. Without decomposition, we achieve a 90.4% pass rate on miniF2F. With decomposition, this is significantly improved. A key technical contribution lies in our extension of the Kimina Lean Server with abstract syntax tree (AST) parsing capabilities to facilitate automated, recursive proof decomposition. The system is made available on PyPI as goedels-poetry (at https://pypi.org/project/goedels-poetry ), and the open-source implementation KellyJDavis/goedels-poetry (at https://github.com/KellyJDavis/goedels-poetry ) facilitates both adaptation to alternative language models and extension with custom functionality.

</details>


### [14] [Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting](https://arxiv.org/abs/2512.14288)
*Georgios Bouchouras,Dimitrios Doumanas,Andreas Soularidis,Konstantinos Kotis,George A. Vouros*

Main category: cs.AI

TL;DR: 이 논문은 파킨슨병 모니터링 및 경고 온톨로지를 개발하기 위한 대형 언어 모델(LLM)의 통합을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 이 연구의 주요 목표는 LLM이 독립적으로 포괄적인 온톨로지를 생성할 수 있는지 또는 인간-LMM 협력이 이 목표를 달성할 수 있는지를 평가하는 것이다.

Method: 논문에서는 One Shot(OS) 프롬프트, Chain of Thought(CoT) 프롬프트, X-HCOME 및 SimX-HCOME+라는 네 가지 방법론을 사용하여 연구를 진행하였다.

Result: 초기 온톨로지 생성은 OS 및 CoT 프롬프트를 사용하여 이루어졌으나, LLM 출력이 포괄적이지 않아 상당한 인간의 정제가 필요했다. X-HCOME 접근은 전문가가 구성한 것과 유사한 온톨로지를 생성함으로써 성능을 향상시켰고, SimX-HCOME+ 방법은 지속적인 인간 감독과 반복적 정제의 중요성을 강조하였다.

Conclusion: 이 연구는 파킨슨병과 같은 복잡한 분야에서 온톨로지 공학을 발전시키는 데 있어 인간-LMM 협력의 잠재력을 강조하고 있으며, 향후 연구 방향으로 온톨로지 생성을 위한 전문화된 GPT 모델 개발을 제안한다.

Abstract: This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.
  Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.
  X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.
  Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.
  Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.

</details>


### [15] [IPR-1: Interactive Physical Reasoner](https://arxiv.org/abs/2511.15407)
*Mingyu Zhang,Lifeng Zhuo,Tianxi Tan,Guocan Xie,Xian Nie,Yan Li,Renjie Zhao,Zizhu He,Ziyu Wang,Jiting Cai,Yong-Lu Li*

Main category: cs.AI

TL;DR: 이 논문은 에이전트가 인간과 유사한 추론을 학습하고 경험을 통해 개선할 수 있는지를 연구하며, 1,000개의 이질적인 게임으로 구성된 G2U 벤치마크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트가 상호작용을 통해 인간과 유사한 추론을 습득할 수 있는지 탐구하기 위해.

Method: Interactive Physical Reasoner (IPR)을 제안하며, 물리학 중심의 행동 코드인 PhysCode를 도입하여 정책을 평가하고 강화한다.

Result: IPR은 사전 훈련된 게임에서 강력한 성능을 보이며, 게임 수와 상호작용 단계가 증가함에 따라 성능이 향상된다.

Conclusion: 물리학 중심의 상호작용이 물리적 추론을 지속적으로 향상시키는 경로라는 것을 보여준다.

Abstract: Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. To study this, we introduce a Game-to-Unseen (G2U) benchmark of 1,000+ heterogeneous games that exhibit significant visual domain gaps. Existing approaches, including VLMs and world models, struggle to capture underlying physics and causality since they are not focused on core mechanisms and overfit to visual details. VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on levels from primitive intuition to goal-driven reasoning, and even surpasses GPT-5 overall. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning. Further demos and project details can be found at https://mybearyzhang.github.io/ipr-1.

</details>


### [16] [PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals](https://arxiv.org/abs/2512.14417)
*Jia Hu,Junqi Li,Weimeng Lin,Peng Jia,Yuxiong Ji,Jintao Lai*

Main category: cs.AI

TL;DR: 이 논문은 자동화된 컨테이너 터미널의 차량 배차 시스템의 전환 가능성을 향상시키기 위해 LLM 기반의 PortAgent를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 컨테이너 터미널의 운영 효율성을 높이기 위해 차량 배차 시스템이 중요하지만, 다양한 터미널 간의 낮은 전환 가능성으로 상업화가 저해되고 있다.

Method: PortAgent는 포트 운영 전문가 없이, 데이터 요구가 적고, 빠른 배포가 가능한 LLM 기반의 차량 배차 에이전트로서, 가상 전문가 팀을 활용하여 VDS 전환 프로세스를 완전 자동화한다.

Result: 가상 전문가 팀이 VDS 도메인에서 적은 수의 사례를 통해 지식을 학습함으로써, 터미널 특화 데이터 요구량을 줄이고 자동화된 VDS 설계 워크플로우를 생성했다.

Conclusion: 이 접근법은 차량 배차 시스템의 효율성을 극대화하고, 수동 개입을 최소화하는 새로운 자동화의 길을 제시한다.

Abstract: Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created

</details>


### [17] [Seismology modeling agent: A smart assistant for geophysical researchers](https://arxiv.org/abs/2512.14429)
*Yukun Ren,Siwei Yu,Kai Chen,Jianwei Ma*

Main category: cs.AI

TL;DR: 본 논문은 기존의 SPECFEM 소프트웨어 워크플로우의 복잡성을 줄이고 사용자 친화적으로 개선하기 위한 지능형 대화형 프로세스를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 SPECFEM 워크플로우는 높은 학습 곡선과 복잡한 수동 파일 편집, 명령줄 작업에 의존한다.

Method: Large Language Models(LLMs)를 활용하여 시뮬레이션 과정을 여러 분리된 도구로 분해해 대화형 상호작용을 가능하게 하는 Model Context Protocol(MCP) 서버 스위트를 도입했다.

Result: 시뮬레이션 전략을 실시간으로 안내 가능하며, 자동 실행과 인간의 개입이 가능하여, 기존 기준선과 일치하는 고충실도 결과를 생성한다.

Conclusion: MCP 기술을 최초로 계산 지질학에 적용하여 진입 장벽을 낮추고 재현성을 높이며, AI 지원 및 자동화된 과학 연구로의 발전을 위한 유망한 경로를 제공한다.

Abstract: To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.

</details>


### [18] [Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling](https://arxiv.org/abs/2512.14474)
*Annu Rana,Gaurav Kumar*

Main category: cs.AI

TL;DR: 모델-퍼스트 추론(MFR)이라는 새로운 접근법을 제안하며, 이는 명시적인 문제 모델링을 통해 복잡한 계획 작업에서 대규모 언어 모델의 성능을 향상시키는 두 단계의 패러다임입니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델이 복잡한 multi-step 계획 과제를 수행하는 데 어려움을 겪고 있으며, 이는 제약 위반과 불일치하는 솔루션을 초래합니다.

Method: MFR은 먼저 LLM이 문제의 명시적 모델을 구축한 후 솔루션 계획을 생성하는 두 단계의 패러다임입니다.

Result: 여러 계획 도메인에서 MFR은 Chain-of-Thought 및 ReAct보다 제약 위반을 줄이고 솔루션 품질을 향상시킵니다.

Conclusion: 대부분의 LLM 계획 실패는 추론의 한계보다는 표현의 결함에서 기인하며, 이는 강력하고 해석 가능한 AI 에이전트를 위한 명시적 모델링의 중요성을 강조합니다.

Abstract: Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.

</details>


### [19] [Universal Reasoning Model](https://arxiv.org/abs/2512.14693)
*Zitian Gao,Lynx Chen,Yihao Xiao,He Xing,Ran Tao,Haoming Luo,Joey Zhou,Bryan Dai*

Main category: cs.AI

TL;DR: 이 논문은 Universal transformers의 성능 향상 원인을 분석하고, Universal Reasoning Model을 제안하여 추론 성능을 크게 개선했다.


<details>
  <summary>Details</summary>
Motivation: UTs의 성능 향상의 구체적인 원천을 규명하고자 하였다.

Method: Universal Reasoning Model(URM)을 제안하여 UT를 짧은 컨볼루션과 잘라낸 역전파로 강화하였다.

Result: URM은 ARC-AGI 1에서 53.8% pass@1, ARC-AGI 2에서 16.0% pass@1의 성과를 달성하였다.

Conclusion: 제안된 방법이 UT의 추론 성능을 상당히 향상시킴을 입증하였다.

Abstract: Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [20] [Multi-Agent Collaborative Framework for Intelligent IT Operations: An AOI System with Context-Aware Compression and Dynamic Task Scheduling](https://arxiv.org/abs/2512.13956)
*Zishan Bai,Enze Ge,Junfeng Hao*

Main category: cs.MA

TL;DR: 이 논문은 클라우드 네이티브 아키텍처의 복잡성 문제를 해결하기 위해 AOI라는 새로운 다중 에이전트 협력 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 클라우드 네이티브 아키텍처의 증가는 IT 인프라의 복잡성과 변동성을 초래하고 있으며, 이는 전통적인 시스템에서의 정보 처리 불량 및 진단 과정에서의 맥락 연속성 손실을 초래한다.

Method: AOI는 LLM 기반 컨텍스트 압축기와 세 가지 특화된 에이전트를 통합한 협력 프레임워크로, 동적 작업 스케줄링과 세 가지 메모리 계층 구조를 포함한다.

Result: AOI는 정보 과부하를 효과적으로 완화하며, 72.4%의 컨텍스트 압축 비율을 달성하고 92.8%의 중요 정보를 보존하며, 운영 효율성을 significativamente 향상시켜 94.2%의 작업 성공률과 34.4%의 MTTR 감소를 보여준다.

Conclusion: 이 연구는 최소한의 인간 개입으로 차세대 IT 인프라의 강력한 관리가 가능한 적응형 및 컨텍스트 인식 자율 운영을 위한 패러다임 변화를 제시한다.

Abstract: The proliferation of cloud-native architectures, characterized by microservices and dynamic orchestration, has rendered modern IT infrastructures exceedingly complex and volatile. This complexity generates overwhelming volumes of operational data, leading to critical bottlenecks in conventional systems: inefficient information processing, poor task coordination, and loss of contextual continuity during fault diagnosis and remediation. To address these challenges, we propose AOI (AI-Oriented Operations), a novel multi-agent collaborative framework that integrates three specialized agents with an LLM-based Context Compressor. Its core innovations include: (1) a dynamic task scheduling strategy that adaptively prioritizes operations based on real-time system states, and (2) a three-layer memory architecture comprising Working, Episodic, and Semantic layers that optimizes context retention and retrieval. Extensive experiments on both synthetic and real-world benchmarks demonstrate that AOI effectively mitigates information overload, achieving a 72.4% context compression ratio while preserving 92.8% of critical information and significantly enhances operational efficiency, attaining a 94.2% task success rate and reducing the Mean Time to Repair (MTTR) by 34.4% compared to the best baseline. This work presents a paradigm shift towards scalable, adaptive, and context-aware autonomous operations, enabling robust management of next-generation IT infrastructures with minimal human intervention.

</details>


### [21] [Multi-Agent Medical Decision Consensus Matrix System: An Intelligent Collaborative Framework for Oncology MDT Consultations](https://arxiv.org/abs/2512.14321)
*Xudong Han,Xianglun Gao,Xiaoyi Qu,Zhenyu Yu*

Main category: cs.MA

TL;DR: 본 연구는 다학제 팀 상담을 위한 다중 에이전트 시스템을 도입하여 암 치료 의사결정의 질과 효율성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 현재 암 치료 의사결정에서 합의 quantifying 및 결정 추적 메커니즘이 부족합니다.

Method: 일곱 개의 전문 대형 언어 모델 에이전트를 활용한 다중 에이전트 의료 결정 합의 행렬 시스템을 제안합니다. 이 시스템은 켄달의 동의 계수를 사용하여 합의를 객관적으로 평가하는 합의 행렬을 포함합니다.

Result: 다섯 가지 의료 벤치마크에서 기존 접근 방식 대비 평균 87.5%의 정확도를 달성하며, 합의 달성률은 89.3%, 평균 켄달의 W는 0.823입니다.

Conclusion: 본 연구는 의료 AI를 발전시켜 임상 결정의 질과 효율성을 개선하는 데 기여합니다.

Abstract: Multidisciplinary team (MDT) consultations are the gold standard for cancer care decision-making, yet current practice lacks structured mechanisms for quantifying consensus and ensuring decision traceability. We introduce a Multi-Agent Medical Decision Consensus Matrix System that deploys seven specialized large language model agents, including an oncologist, a radiologist, a nurse, a psychologist, a patient advocate, a nutritionist and a rehabilitation therapist, to simulate realistic MDT workflows. The framework incorporates a mathematically grounded consensus matrix that uses Kendall's coefficient of concordance to objectively assess agreement. To further enhance treatment recommendation quality and consensus efficiency, the system integrates reinforcement learning methods, including Q-Learning, PPO and DQN. Evaluation across five medical benchmarks (MedQA, PubMedQA, DDXPlus, MedBullets and SymCat) shows substantial gains over existing approaches, achieving an average accuracy of 87.5% compared with 83.8% for the strongest baseline, a consensus achievement rate of 89.3% and a mean Kendall's W of 0.823. Expert reviewers rated the clinical appropriateness of system outputs at 8.9/10. The system guarantees full evidence traceability through mandatory citations of clinical guidelines and peer-reviewed literature, following GRADE principles. This work advances medical AI by providing structured consensus measurement, role-specialized multi-agent collaboration and evidence-based explainability to improve the quality and efficiency of clinical decision-making.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [22] [Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution](https://arxiv.org/abs/2512.13729)
*Jacob Schnell,Aditya Makkar,Gunadi Gani,Aniket Srinivasan Ashok,Darren Lo,Mike Optis,Alexander Wong,Yuhao Chen*

Main category: cs.LG

TL;DR: 이 논문은 고해상도 바람 데이터를 활용하여 기상 모델링 문제를 해결하기 위한 새로운 딥러닝 방법인 WindDM을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기상 예측 및 풍력 발전기 배치 최적화와 같은 기상 모델링 문제는 고해상도 및 고정밀 바람 데이터에 대한 충분한 접근이 필요하지만, 이를 수집하는 것은 여전히 도전적이고 비쌉니다.

Method: 우리는 여러 개의 조건 입력에 대한 클래시파이어 없는 가이던스(CG) 일반화를 제시하여 딥러닝 확산 모델을 개선했습니다. 우리의 새로운 복합 클래시파이어 없는 가이던스(CCFG)를 사용하여 사전 훈련된 확산 모델에 적용했습니다.

Result: CCFG 출력은 바람 슈퍼 해상도 작업에서 CFG보다 높은 정확성을 보여주었고, WindDM은 산업 규모의 바람 역학 재구성을 위해 훈련된 확산 모델로, 최신 재구성 품질을 달성했습니다.

Conclusion: WindDM은 클래식 방법보다 최대 $1000	imes$ 저렴하게 딥러닝 모델 중 최고의 재구성 품질을 제공합니다.

Abstract: Various weather modelling problems (e.g., weather forecasting, optimizing turbine placements, etc.) require ample access to high-resolution, highly accurate wind data. Acquiring such high-resolution wind data, however, remains a challenging and expensive endeavour. Traditional reconstruction approaches are typically either cost-effective or accurate, but not both. Deep learning methods, including diffusion models, have been proposed to resolve this trade-off by leveraging advances in natural image super-resolution. Wind data, however, is distinct from natural images, and wind super-resolvers often use upwards of 10 input channels, significantly more than the usual 3-channel RGB inputs in natural images. To better leverage a large number of conditioning variables in diffusion models, we present a generalization of classifier-free guidance (CFG) to multiple conditioning inputs. Our novel composite classifier-free guidance (CCFG) can be dropped into any pre-trained diffusion model trained with standard CFG dropout. We demonstrate that CCFG outputs are higher-fidelity than those from CFG on wind super-resolution tasks. We present WindDM, a diffusion model trained for industrial-scale wind dynamics reconstruction and leveraging CCFG. WindDM achieves state-of-the-art reconstruction quality among deep learning models and costs up to $1000\times$ less than classical methods.

</details>


### [23] [MIDUS: Memory-Infused Depth Up-Scaling](https://arxiv.org/abs/2512.13751)
*Taero Kim,Hoyoon Byun,Youngjun Choi,Sungrae Park,Kyungwoo Song*

Main category: cs.LG

TL;DR: 이 논문은 DUS 방법론의 한계를 극복하기 위해 MIDUS라는 새로운 메모리 기반 깊이 확장 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 확장을 위해서는 과도한 매개변수 증가나 추론 비용을 초래하지 않으면서 용량을 증가시키는 접근 방식이 필요합니다.

Method: MIDUS는 복제된 블록의 FFNs을 head-wise 메모리(HML) 레이어로 교체하여 설계되었습니다. 각 attention 헤드에 독립적인 메모리 뱅크를 할당하여 헤드 간 및 내부에서 정보를 검색하고 주입합니다.

Result: MIDUS는 강력한 DUS 기준선에 비해 뛰어난 성능 개선을 성취하였으며, 높은 효율성을 유지합니다.

Conclusion: MIDUS는 헤드별 메모리 설계를 활용하여 깊이 확장을 위한 기존 FFN 복제의 대안으로서 매력적이고 자원 효율적인 방법으로 자리잡았습니다.

Abstract: Scaling large language models (LLMs) demands approaches that increase capacity without incurring excessive parameter growth or inference cost. Depth Up-Scaling (DUS) has emerged as a promising strategy by duplicating layers and applying Continual Pre-training (CPT), but its reliance on feed-forward networks (FFNs) limits efficiency and attainable gains. We introduce Memory-Infused Depth Up-Scaling (MIDUS), which replaces FFNs in duplicated blocks with a head-wise memory (HML) layer. Motivated by observations that attention heads have distinct roles both across and within layers, MIDUS assigns an independent memory bank to each head, enabling head-wise retrieval and injecting information into subsequent layers while preserving head-wise functional structure. This design combines sparse memory access with head-wise representations and incorporates an efficient per-head value factorization module, thereby relaxing the usual efficiency-performance trade-off. Across our CPT experiments, MIDUS exhibits robust performance improvements over strong DUS baselines while maintaining a highly efficient parameter footprint. Our findings establish MIDUS as a compelling and resource-efficient alternative to conventional FFN replication for depth up-scaling by leveraging its head-wise memory design.

</details>


### [24] [Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training](https://arxiv.org/abs/2512.13770)
*Huaiyuan Xiao,Fadi Dornaika,Jingjun Bi*

Main category: cs.LG

TL;DR: MV-SupGCN은 여러 보완 요소를 통합하여 그래프 컨볼루션 네트워크 기반 다중 뷰 학습의 성능을 개선하는 반지도 모델이다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들이 보완 정보 활용에 실패하여 최적의 특성 표현을 제공하지 못하는 문제를 해결하기 위해.

Method: Cross-Entropy 손실과 Supervised Contrastive 손실을 결합한 공동 손실 함수를 설계하고, KNN 기반 및 반지도 그래프 구축 방법을 결합하여 각 뷰의 데이터 구조 표현의 강건성을 향상시킨다. 또한, 대량의 레이블 없는 데이터를 효과적으로 활용하고 다중 뷰 간의 의미적 정합성을 높이기 위해 통합된 프레임워크를 제안한다.

Result: MV-SupGCN은 다양한 벤치마크에서 지속적으로 최첨단 방법들을 초과하는 성능을 보여준다.

Conclusion: 우리의 통합 접근 방식의 효과를 검증하며, 소스 코드는 https://github.com/HuaiyuanXiao/MVSupGCN에서 확인할 수 있다.

Abstract: The advent of graph convolutional network (GCN)-based multi-view learning provides a powerful framework for integrating structural information from heterogeneous views, enabling effective modeling of complex multi-view data. However, existing methods often fail to fully exploit the complementary information across views, leading to suboptimal feature representations and limited performance. To address this, we propose MV-SupGCN, a semi-supervised GCN model that integrates several complementary components with clear motivations and mutual reinforcement. First, to better capture discriminative features and improve model generalization, we design a joint loss function that combines Cross-Entropy loss with Supervised Contrastive loss, encouraging the model to simultaneously minimize intra-class variance and maximize inter-class separability in the latent space. Second, recognizing the instability and incompleteness of single graph construction methods, we combine both KNN-based and semi-supervised graph construction approaches on each view, thereby enhancing the robustness of the data structure representation and reducing generalization error. Third, to effectively utilize abundant unlabeled data and enhance semantic alignment across multiple views, we propose a unified framework that integrates contrastive learning in order to enforce consistency among multi-view embeddings and capture meaningful inter-view relationships, together with pseudo-labeling, which provides additional supervision applied to both the cross-entropy and contrastive loss functions to enhance model generalization. Extensive experiments demonstrate that MV-SupGCN consistently surpasses state-of-the-art methods across multiple benchmarks, validating the effectiveness of our integrated approach. The source code is available at https://github.com/HuaiyuanXiao/MVSupGCN

</details>


### [25] [Accelerating MHC-II Epitope Discovery via Multi-Scale Prediction in Antigen Presentation](https://arxiv.org/abs/2512.14011)
*Yue Wan,Jiayi Yuan,Zhiwei Feng,Xiaowei Jia*

Main category: cs.LG

TL;DR: MHC-II 단백질의 항원 에피토프 연구를 위한 새로운 표준화된 데이터셋을 제시하며, 기계 학습 작업을 통해 생물학적 과정들을 포착한다.


<details>
  <summary>Details</summary>
Motivation: MHC-II 항원 에피토프는 면역 치료에서 중요한 역할을 하지만, MHC-I에 비해 연구가 적고 더 많은 도전 과제가 존재한다.

Method: IEDB 및 기타 공개 소스를 기반으로 한 잘 정리된 데이터셋을 제시하고, 이를 통해 세 가지 주요 기계 학습 작업을 도출하였다.

Result: 기존의 모델을 벤치마킹하고 다양한 모델링 설계에 대한 포괄적인 분석을 진행했다.

Conclusion: 이 연구는 컴퓨터 면역 치료 발전을 위한 귀중한 자원으로 작용하며, 미래의 MHC-II 연구에 기초를 제공한다.

Abstract: Antigenic epitope presented by major histocompatibility complex II (MHC-II) proteins plays an essential role in immunotherapy. However, compared to the more widely studied MHC-I in computational immunotherapy, the study of MHC-II antigenic epitope poses significantly more challenges due to its complex binding specificity and ambiguous motif patterns. Consequently, existing datasets for MHC-II interactions are smaller and less standardized than those available for MHC-I. To address these challenges, we present a well-curated dataset derived from the Immune Epitope Database (IEDB) and other public sources. It not only extends and standardizes existing peptide-MHC-II datasets, but also introduces a novel antigen-MHC-II dataset with richer biological context. Leveraging this dataset, we formulate three major machine learning (ML) tasks of peptide binding, peptide presentation, and antigen presentation, which progressively capture the broader biological processes within the MHC-II antigen presentation pathway. We further employ a multi-scale evaluation framework to benchmark existing models, along with a comprehensive analysis over various modeling designs to this problem with a modular framework. Overall, this work serves as a valuable resource for advancing computational immunotherapy, providing a foundation for future research in ML guided epitope discovery and predictive modeling of immune responses.

</details>


### [26] [Understanding and Improving Hyperbolic Deep Reinforcement Learning](https://arxiv.org/abs/2512.14202)
*Timo Klein,Thomas Lang,Andrii Shkabrii,Alexander Sturm,Kevin Sidak,Lukas Miklautz,Claudia Plant,Yllka Velaj,Sebastian Tschiatschek*

Main category: cs.LG

TL;DR: 이 논문에서는 하이퍼볼릭 딥 RL 에이전트를 훈련하는 데 있어 성공과 실패를 결정짓는 주요 요소들을 식별하고, 이를 바탕으로 하이퍼볼릭 PPO 에이전트인 Hyper++를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 강화학습 에이전트의 성능은 기본 특징 표현의 질에 크게 의존하며, 하이퍼볼릭 공간은 복잡한 RL 환경에서 계층적이고 관계적인 구조를 포착하는 데 적합하다.

Method: 하이퍼볼릭 기하학의 포앙카레 구 및 하이퍼볼로이드 모델에서 핵심 연산의 그래디언트를 분석하여, 큰 노름의 임베딩이 그래디언트 기반 훈련을 불안정하게 만들고 PPO에서 신뢰 영역 위반을 초래할 수 있음을 보여준다. 이를 바탕으로 세 가지 구성 요소로 이루어진 하이퍼볼릭 PPO 에이전트인 Hyper++를 제안한다.

Result: Hyper++는 ProcGen 실험에서 안정적인 학습을 보장하고, 이전 하이퍼볼릭 에이전트보다 우수한 성능을 보여주며, 약 30%의 시간 절약을 달성하였다. 또한 Atari-5에서 Double DQN과 함께 사용할 때, Hyper++는 유클리드 및 하이퍼볼릭 기준보다 강력한 성능을 보인다.

Conclusion: Hyper++는 하이퍼볼릭 공간에서 안정적인 훈련과 효과적인 성능을 달성하는 데 기여하며, 코드가 공개된다.

Abstract: The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincaré Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code at https://github.com/Probabilistic-and-Interactive-ML/hyper-rl .

</details>


### [27] [Understanding the Gain from Data Filtering in Multimodal Contrastive Learning](https://arxiv.org/abs/2512.14230)
*Divyansh Pareek,Sewoong Oh,Simon S. Du*

Main category: cs.LG

TL;DR: 이 논문은 인터넷 규모의 데이터셋에 의존하는 다중 모드 표현 학습의 성공과 관련하여, 필터링의 효과성을 분석하고 교사 기반 필터링의 성과를 설명한다.


<details>
  <summary>Details</summary>
Motivation: 다중 모드 표현 학습의 정확도를 높이기 위해 데이터 필터링이 중요해졌다.

Method: 표준 이분 모드 데이터 생성 모델 아래에서 필터링된 대조 학습의 성능을 특성화한다. 주어진 데이터 샘플에서 잘 맞는 모드의 비율을 나타내는 기호 $η$를 사용하여, 선형 대조 학습 설정을 활용하여 데이터 필터링의 이점을 증명한다.

Result: 필터링 없이 발생하는 오류는 $rac{1}{η	ext{sqrt}{n}}$로 상하한이 설정되며, 교사 기반 필터링을 통해 발생하는 오류는 큰 $η$ 영역에서 $rac{1}{	ext{sqrt}{ηn}}$로 상한이, 작은 $η$ 영역에서 $rac{1}{	ext{sqrt}{n}}$로 상한이 설정된다.

Conclusion: 이러한 분석은 데이터 필터링의 효과를 명확히 입증하며, 교사 기반 필터링이 다중 모드 학습에서 왜 성공적인지를 설명한다.

Abstract: The success of modern multimodal representation learning relies on internet-scale datasets. Due to the low quality of a large fraction of raw web data, data curation has become a critical step in the training pipeline. Filtering using a trained model (i.e., teacher-based filtering) has emerged as a successful solution, leveraging a pre-trained model to compute quality scores. To explain the empirical success of teacher-based filtering, we characterize the performance of filtered contrastive learning under the standard bimodal data generation model. Denoting $η\in(0,1]$ as the fraction of data with correctly matched modalities among $n$ paired samples, we utilize a linear contrastive learning setup to show a provable benefit of data filtering: $(i)$ the error without filtering is upper and lower bounded by $\frac{1}{η\sqrt{n}}$, and $(ii)$ the error with teacher-based filtering is upper bounded by $\frac{1}{\sqrt{ηn}}$ in the large $η$ regime, and by $\frac{1}{\sqrt{n}}$ in the small $η$ regime.

</details>


### [28] [Beyond MMD: Evaluating Graph Generative Models with Geometric Deep Learning](https://arxiv.org/abs/2512.14241)
*Salvatore Romano,Marco Grassia,Giuseppe Mangioni*

Main category: cs.LG

TL;DR: 그래프 생성은 네트워크 과학과 생물 정보학을 포함한 여러 분야에서 중요한 작업으로, 실제 네트워크의 특성을 모방하는 합성 그래프를 생성할 수 있게 한다. 본 논문에서는 그래프 생성 모델(GGM)의 평가를 위한 새로운 방법론 RGM을 소개하며, 이를 통해 최신 그래프 생성 모델의 성능을 평가하였다.


<details>
  <summary>Details</summary>
Motivation: 그래프 생성 모델의 주요 평가 지표로 사용되는 최대 평균 불일치(MMD)의 한계를 극복하기 위해 새로운 평가 방법론을 제안한다.

Method: RGM(Representation-aware Graph-generation Model evaluation)이라는 새로운 평가 방법론을 개발하고, 두 개의 최신 GGM인 GRAN과 EDGE를 평가한다.

Result: GRAN과 EDGE 모델 모두 특정 위상적 특성을 가진 그래프를 생성할 수 있지만, 서로 다른 그래프 도메인을 구별하는 구조적 특성을 유지하는 데 한계가 있음을 발견하였다.

Conclusion: 최대 평균 불일치(MMD)가 GGMs의 평가 지표로서 부적절함을 강조하고, 향후 연구를 위한 대안 접근법을 제안한다.

Abstract: Graph generation is a crucial task in many fields, including network science and bioinformatics, as it enables the creation of synthetic graphs that mimic the properties of real-world networks for various applications. Graph Generative Models (GGMs) have emerged as a promising solution to this problem, leveraging deep learning techniques to learn the underlying distribution of real-world graphs and generate new samples that closely resemble them. Examples include approaches based on Variational Auto-Encoders, Recurrent Neural Networks, and more recently, diffusion-based models. However, the main limitation often lies in the evaluation process, which typically relies on Maximum Mean Discrepancy (MMD) as a metric to assess the distribution of graph properties in the generated ensemble. This paper introduces a novel methodology for evaluating GGMs that overcomes the limitations of MMD, which we call RGM (Representation-aware Graph-generation Model evaluation). As a practical demonstration of our methodology, we present a comprehensive evaluation of two state-of-the-art Graph Generative Models: Graph Recurrent Attention Networks (GRAN) and Efficient and Degree-guided graph GEnerative model (EDGE). We investigate their performance in generating realistic graphs and compare them using a Geometric Deep Learning model trained on a custom dataset of synthetic and real-world graphs, specifically designed for graph classification tasks. Our findings reveal that while both models can generate graphs with certain topological properties, they exhibit significant limitations in preserving the structural characteristics that distinguish different graph domains. We also highlight the inadequacy of Maximum Mean Discrepancy as an evaluation metric for GGMs and suggest alternative approaches for future research.

</details>


### [29] [Black-Box Auditing of Quantum Model: Lifted Differential Privacy with Quantum Canaries](https://arxiv.org/abs/2512.14388)
*Baobao Song,Shiva Raj Pokhrel,Athanasios V. Vasilakos,Tianqing Zhu,Gang Li*

Main category: cs.LG

TL;DR: 양자 머신 러닝(QML)은 계산상의 이점을 제공하지만 민감한 데이터로 훈련된 모델이 개인 기록을 기억할 위험이 있으며, 이는 심각한 개인 정보 보호 취약점을 초래합니다. 우리는 Lifted Quantum Differential Privacy를 기반으로 하는 QML을 위한 최초의 블랙박스 프라이버시 감사 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 양자 머신 러닝(QML) 모델이 민감한 데이터를 처리함에 있어 개인 정보 보호를 강화할 필요성이 커지고 있습니다.

Method: Lifted Quantum Differential Privacy를 기반으로 하여 양자 카나리아를 활용해 메모리화 및 개인 정보 유출을 감지하고 정량화할 수 있는 블랙박스 개인 정보 감사 프레임워크를 구축했습니다.

Result: 시뮬레이션 된 양자 하드웨어와 물리적 양자 하드웨어에서 포괄적인 평가를 통해 우리 프레임워크가 QML 모델에서 실제 개인 정보 손실을 측정하는 데 효과적임을 입증했습니다.

Conclusion: 우리의 프레임워크는 이론적 보장과 실제 개인 정보 검증 사이의 중대한 격차를 해소할 수 있는 실증적 하한을 도출합니다.

Abstract: Quantum machine learning (QML) promises significant computational advantages, yet models trained on sensitive data risk memorizing individual records, creating serious privacy vulnerabilities. While Quantum Differential Privacy (QDP) mechanisms provide theoretical worst-case guarantees, they critically lack empirical verification tools for deployed models. We introduce the first black-box privacy auditing framework for QML based on Lifted Quantum Differential Privacy, leveraging quantum canaries (strategically offset-encoded quantum states) to detect memorization and precisely quantify privacy leakage during training. Our framework establishes a rigorous mathematical connection between canary offset and trace distance bounds, deriving empirical lower bounds on privacy budget consumption that bridge the critical gap between theoretical guarantees and practical privacy verification. Comprehensive evaluations across both simulated and physical quantum hardware demonstrate our framework's effectiveness in measuring actual privacy loss in QML models, enabling robust privacy verification in QML systems.

</details>


### [30] [AnySleep: a channel-agnostic deep learning system for high-resolution sleep staging in multi-center cohorts](https://arxiv.org/abs/2512.14461)
*Niklas Grieger,Jannik Raskob,Siamak Mehrkanoon,Stephan Bialonski*

Main category: cs.LG

TL;DR: AnySleep는 EEG 또는 EOG 데이터를 활용하여 조정 가능한 시간 해상도로 수면을 점수화하는 딥 뉴럴 네트워크 모델이다.


<details>
  <summary>Details</summary>
Motivation: 수면 연구 및 임상 치료에서 수면의 동역학을 연구하기 위해 수동 수면 단계 설정이 필요하지만, 이는 수고가 많이 드는 과정이다.

Method: 이 모델은 21개 데이터 세트에서 수집된 19,000개 이상의 밤샘 기록으로 훈련되고 검증되었으며, 다양한 클리닉에서 수집된 거의 200,000시간의 EEG 및 EOG 데이터를 포함한다.

Result: 모델은 최첨단 성능을 달성하고 30초 에폭에서 설정된 기준을 초과하거나 일치한다.

Conclusion: 모델은 다양한 전극 설정으로 대규모 연구를 촉진하고 수면의 새로운 바이오마커 발견을 가속화하기 위해 공개될 것이다.

Abstract: Sleep is essential for good health throughout our lives, yet studying its dynamics requires manual sleep staging, a labor-intensive step in sleep research and clinical care. Across centers, polysomnography (PSG) recordings are traditionally scored in 30-s epochs for pragmatic, not physiological, reasons and can vary considerably in electrode count, montage, and subject characteristics. These constraints present challenges in conducting harmonized multi-center sleep studies and discovering novel, robust biomarkers on shorter timescales. Here, we present AnySleep, a deep neural network model that uses any electroencephalography (EEG) or electrooculography (EOG) data to score sleep at adjustable temporal resolutions. We trained and validated the model on over 19,000 overnight recordings from 21 datasets collected across multiple clinics, spanning nearly 200,000 hours of EEG and EOG data, to promote robust generalization across sites. The model attains state-of-the-art performance and surpasses or equals established baselines at 30-s epochs. Performance improves as more channels are provided, yet remains strong when EOG is absent or when only EOG or single EEG derivations (frontal, central, or occipital) are available. On sub-30-s timescales, the model captures short wake intrusions consistent with arousals and improves prediction of physiological characteristics (age, sex) and pathophysiological conditions (sleep apnea), relative to standard 30-s scoring. We make the model publicly available to facilitate large-scale studies with heterogeneous electrode setups and to accelerate the discovery of novel biomarkers in sleep.

</details>


### [31] [Synthetic Electrogram Generation with Variational Autoencoders for ECGI](https://arxiv.org/abs/2512.14537)
*Miriam Gutiérrez Fernández,Karen López-Linares,Carlos Fambuena Santos,María S. Guillem,Andreu M. Climent,Óscar Barquero Pérez*

Main category: cs.LG

TL;DR: 본 연구에서는 비침습적 심전도 이미징(ECGI)과 딥러닝을 활용하여 심장 내 전기 신호를 추정하기 위한 합성 다채널 심방 EGMs 생성에 대해 연구합니다.


<details>
  <summary>Details</summary>
Motivation: 심방 세동(AF)의 임상 평가는 정확한 심방 전기 활동의 특징화를 요구하지만, BSPM-EGM 데이터셋의 제한된 가용성으로 인해 진전이 저해되고 있습니다.

Method: 변분 오토인코더(VAE)를 사용하여 합성 다채널 심방 EGMs를 생성하기 위해 두 가지 모델(VAE-S와 VAE-C)을 제안합니다.

Result: VAE-S는 in silico EGMs에 대해 높은 충실도를 달성하며, VAE-C는 리듬 특정 생성을 가능하게 하지만 동맥 재구성 품질이 저하됩니다.

Conclusion: 합성 EGMs는 데이터 증강을 위한 다운스트림 비침습적 EGM 재구성 작업에 사용되어, 중간 수준의 증강이 추정 성능을 향상시킵니다. 이러한 결과는 데이터 부족을 완화하고 ECGI 파이프라인을 강화할 수 있는 VAE 기반 생성 모델링의 가능성을 보여줍니다.

Abstract: Atrial fibrillation (AF) is the most prevalent sustained cardiac arrhythmia, and its clinical assessment requires accurate characterization of atrial electrical activity. Noninvasive electrocardiographic imaging (ECGI) combined with deep learning (DL) approaches for estimating intracardiac electrograms (EGMs) from body surface potentials (BSPMs) has shown promise, but progress is hindered by the limited availability of paired BSPM-EGM datasets. To address this limitation, we investigate variational autoencoders (VAEs) for the generation of synthetic multichannel atrial EGMs. Two models are proposed: a sinus rhythm-specific VAE (VAE-S) and a class-conditioned VAE (VAE-C) trained on both sinus rhythm and AF signals. Generated EGMs are evaluated using morphological, spectral, and distributional similarity metrics. VAE-S achieves higher fidelity with respect to in silico EGMs, while VAE-C enables rhythm-specific generation at the expense of reduced sinus reconstruction quality. As a proof of concept, the generated EGMs are used for data augmentation in a downstream noninvasive EGM reconstruction task, where moderate augmentation improves estimation performance. These results demonstrate the potential of VAE-based generative modeling to alleviate data scarcity and enhance deep learning-based ECGI pipelines.

</details>


### [32] [Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes](https://arxiv.org/abs/2512.14617)
*Alessandro Trapasso,Luca Iocchi,Fabio Patrizi*

Main category: cs.LG

TL;DR: 본 논문에서는 비 마코프 형태의 보상 결정 프로세스(NMRDPs)를 위한 QR-MAX라는 새로운 모델 기반 알고리즘을 제안하여, 최적성 및 샘플 효율성 문제를 해결한다. 또한, Bucket-QR-MAX를 통해 연속 상태 공간으로 확장하여 효율적인 학습을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 마코프 강화 학습 방법이 적합하지 않은 비 마코프 보상 결정 프로세스를 위한 효율적인 접근 방식이 필요하다.

Method: QR-MAX는 비 마코프 보상을 다룰 수 있도록 마코프 전이 학습과 보상 기계의 분리를 통해 학습하는 새로운 모델 기반 알고리즘이다.

Result: QR-MAX는 다항 샘플 복잡성으로 PAC 수렴을 달성하며, 연속 상태 공간으로 확장된 Bucket-QR-MAX는 빠르고 안정적인 학습을 보여준다.

Conclusion: 우리의 실험 결과, 제안한 방법은 현대의 최첨단 모델 기반 강화 학습 접근 방식과 비교하여 샘플 효율성이 크게 향상되고 최적 정책을 찾는 데 있어 강건성이 증가함을 보여준다.

Abstract: Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.

</details>


### [33] [ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning](https://arxiv.org/abs/2512.14619)
*Chaohao Yuan,Zhenjie Song,Ercan Engin Kuruoglu,Kangfei Zhao,Yang Liu,Deli Zhao,Hong Cheng,Yu Rong*

Main category: cs.LG

TL;DR: PageRank Transformer(ParaFormer)는 깊은 GNN에서 발생하는 과도한 스무딩 문제를 해결하기 위해 PageRank 기반 주의 모듈을 도입하여 전이 학습 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 대규모 그래프 데이터를 효과적으로 처리하기 위해 Graph Transformers(GTs)의 가능성을 탐구하면서, 깊은 GNN에서 발생하는 과도한 스무딩 문제를 해결할 필요성을 제기한다.

Method: PageRank Transformer(ParaFormer)는 PageRank 강화 주의 모듈을 통해 깊은 Transformers의 동작을 모방하며, 이를 통해 과도한 스무딩을 완화한다.

Result: ParaFormer는 11개의 데이터셋에서 노드 분류와 그래프 분류 작업 모두에서 성능 향상을 보여준다.

Conclusion: PageRank Transformer는 과도한 스무딩 문제를 해결하면서 높은 성능을 유지한다.

Abstract: Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GNNs. However, through empirical and theoretical analysis, we verify that the introduced global attention exhibits severe over-smoothing, causing node representations to become indistinguishable due to its inherent low-pass filtering. This effect is even stronger than that observed in GNNs. To mitigate this, we propose PageRank Transformer (ParaFormer), which features a PageRank-enhanced attention module designed to mimic the behavior of deep Transformers. We theoretically and empirically demonstrate that ParaFormer mitigates over-smoothing by functioning as an adaptive-pass filter. Experiments show that ParaFormer achieves consistent performance improvements across both node classification and graph classification tasks on 11 datasets ranging from thousands to millions of nodes, validating its efficacy. The supplementary material, including code and appendix, can be found in https://github.com/chaohaoyuan/ParaFormer.

</details>


### [34] [Early Warning Index for Patient Deteriorations in Hospitals](https://arxiv.org/abs/2512.14683)
*Dimitris Bertsimas,Yu Ma,Kimberly Villalobos Carballo,Gagan Singh,Michal Laskowski,Jeff Mather,Dan Kombert,Howard Haronian*

Main category: cs.LG

TL;DR: 본 논문에서는 ICU 입원, 응급 대응 팀 파견 및 사망률의 집합적 위험을 예측하는 다중 모달 기계 학습 프레임워크인 조기 경고 지수(EWI)를 개발하였습니다.


<details>
  <summary>Details</summary>
Motivation: 의료기관에서 임상 및 운영 데이터의 증가하는 양을 효과적으로 활용하여 중대한 사건을 예측할 수 있는 자동화 시스템이 부족하며, 환자의 악화 위험을 조기에 식별하는 것이 필수적입니다.

Method: EWI는 임상의가 경고 기준을 설정하고 모델 출력을 해석하는 인간-루프 프로세스를 포함하며, SHAP를 사용하여 각 환자의 위험을 유발하는 임상적 및 운영적 요소를 강조합니다.

Result: 우리는 18,633명의 고유한 환자 데이터셋을 사용하여 C 통계치 0.796을 달성하며, EWI는 현재 위험 환자를 능동적으로 관리하기 위한 분류 도구로 사용됩니다.

Conclusion: 제안된 접근 방식은 의사들이 복잡한 EHR 데이터를 처리하는 대신 환자 치료에 집중할 수 있도록 하여 귀중한 시간을 절약하고, 특정 위험 요인을 정확히 짚어내어 간호사 일정 및 중요한 자원 할당의 데이터 기반 조정을 제공합니다.

Abstract: Hospitals lack automated systems to harness the growing volume of heterogeneous clinical and operational data to effectively forecast critical events. Early identification of patients at risk for deterioration is essential not only for patient care quality monitoring but also for physician care management. However, translating varied data streams into accurate and interpretable risk assessments poses significant challenges due to inconsistent data formats. We develop a multimodal machine learning framework, the Early Warning Index (EWI), to predict the aggregate risk of ICU admission, emergency response team dispatch, and mortality. Key to EWI's design is a human-in-the-loop process: clinicians help determine alert thresholds and interpret model outputs, which are enhanced by explainable outputs using Shapley Additive exPlanations (SHAP) to highlight clinical and operational factors (e.g., scheduled surgeries, ward census) driving each patient's risk. We deploy EWI in a hospital dashboard that stratifies patients into three risk tiers. Using a dataset of 18,633 unique patients at a large U.S. hospital, our approach automatically extracts features from both structured and unstructured electronic health record (EHR) data and achieves C-statistics of 0.796. It is currently used as a triage tool for proactively managing at-risk patients. The proposed approach saves physicians valuable time by automatically sorting patients of varying risk levels, allowing them to concentrate on patient care rather than sifting through complex EHR data. By further pinpointing specific risk drivers, the proposed model provides data-informed adjustments to caregiver scheduling and allocation of critical resources. As a result, clinicians and administrators can avert downstream complications, including costly procedures or high readmission rates and improve overall patient flow.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [35] [IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol](https://arxiv.org/abs/2512.14166)
*Yunhao Yao,Zhiqiang Wang,Haoran Cheng,Yihang Cheng,Haohua Du,Xiang-Yang Li*

Main category: cs.CR

TL;DR: 본 연구는 MCP를 통해 발생하는 개인정보 보호 문제를 탐구하고, 사용자의 의도를 효과적으로 추론하는 IntentMiner라는 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLMs이 자율 에이전트로 발전함에 따라 외부 도구를 발견하고 호출하기 위한 표준으로 MCP가 채택되었습니다. 그러나 이 구조는 개인정보와 관련된 심각한 리스크를 도입하게 됩니다.

Method: 이 논문에서는 Intent Inversion이라는 새로운 개인정보 위협을 정의하고, Hierarchical Information Isolation과 Three-Dimensional Semantic Analysis를 활용한 IntentMiner라는 프레임워크를 제안하여 사용자의 의도를 정확히 추론합니다.

Result: IntentMiner는 원래 사용자 쿼리와 85% 이상의 높은 의미적 정렬을 달성하였으며, 기존 접근 방식보다 훨씬 뛰어난 성능을 보였습니다.

Conclusion: 이 연구는 분리된 에이전트 구조에서의 고유한 개인정보 위험을 강조하며, 무해해 보이는 도구 실행 로그가 사용자의 비밀을 노출할 수 있는 강력한 경로가 될 수 있음을 보여줍니다.

Abstract: The rapid evolution of Large Language Models (LLMs) into autonomous agents has led to the adoption of the Model Context Protocol (MCP) as a standard for discovering and invoking external tools. While this architecture decouples the reasoning engine from tool execution to enhance scalability, it introduces a significant privacy surface: third-party MCP servers, acting as semi-honest intermediaries, can observe detailed tool interaction logs outside the user's trusted boundary. In this paper, we first identify and formalize a novel privacy threat termed Intent Inversion, where a semi-honest MCP server attempts to reconstruct the user's private underlying intent solely by analyzing legitimate tool calls. To systematically assess this vulnerability, we propose IntentMiner, a framework that leverages Hierarchical Information Isolation and Three-Dimensional Semantic Analysis, integrating tool purpose, call statements, and returned results, to accurately infer user intent at the step level. Extensive experiments demonstrate that IntentMiner achieves a high degree of semantic alignment (over 85%) with original user queries, significantly outperforming baseline approaches. These results highlight the inherent privacy risks in decoupled agent architectures, revealing that seemingly benign tool execution logs can serve as a potent vector for exposing user secrets.

</details>


### [36] [Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space](https://arxiv.org/abs/2512.14448)
*Xingfu Zhou,Pengfei Wang*

Main category: cs.CR

TL;DR: 이 논문에서는 언어 모델 에이전트의 추론 스타일을 목표로 하는 새로운 공격 방식을 제안하며, 정보 처리 방식에 영향을 주는 Reasoning-Style Poisoning(RSP)과 Generative Style Injection(GSI) 공격 방법을 개발하여 성능 저하를 입증합니다.


<details>
  <summary>Details</summary>
Motivation: 모든 분야에서 사용되고 있는 대형 언어 모델(LLM) 에이전트의 안전성을 높이기 위해 새로운 공격 방식인 Reasoning-Style Poisoning을 탐구합니다.

Method: Generative Style Injection(GSI) 기법을 이용하여 검색된 문서를 왜곡된 톤으로 수정하고, Reasoning Style Vector(RSV) 메트릭을 통해 이 변화를 정량화합니다.

Result: GSI 공격이 ReAct, Reflection, Tree of Thoughts(ToT) 아키텍처에서 기계적 성능을 최대 4.4배 감소시키거나 조기 오류를 유발하면서 기존 내용 필터를 효과적으로 우회함을 실험적으로 보여줍니다.

Conclusion: 추론 스타일은 독립적이고 악용 가능한 취약점이며, 정적 콘텐츠 분석 이상의 과정 기반 방어가 필요함을 시사합니다.

Abstract: Large Language Model (LLM) agents relying on external retrieval are increasingly deployed in high-stakes environments. While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process. We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically "analysis paralysis" or "cognitive haste"--without altering underlying facts or using explicit triggers. To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus. Experiments on HotpotQA and FEVER using ReAct, Reflection, and Tree of Thoughts (ToT) architectures reveal that GSI significantly degrades performance. It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters. Finally, we propose RSP-M, a lightweight runtime monitor that calculates RSV metrics in real-time and triggers alerts when values exceed safety thresholds. Our work demonstrates that reasoning style is a distinct, exploitable vulnerability, necessitating process-level defenses beyond static content analysis.

</details>
