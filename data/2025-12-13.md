<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 7]
- [cs.LG](#cs.LG) [Total: 15]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.MA](#cs.MA) [Total: 4]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [When Quantum Federated Learning Meets Blockchain in 6G Networks](https://arxiv.org/abs/2512.09958)
*Dinh C. Nguyen,Md Bokhtiar Al Zami,Ratun Rahman,Shaba Shaon,Tuy Tan Nguyen,Fatemeh Afghah*

Main category: cs.CR

TL;DR: 본 논문은 6G 네트워크에서 양자 연합 학습(QFL)과 블록체인을 결합한 QFLchain 프레임워크를 제안하여 안전하고 확장 가능한 인공지능 솔루션을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 차세대 6G 네트워크에서 지능적이고 안전하며 개인 정보 보호가 가능한 모델 훈련을 가능하게 하는 QFL의 필요성.

Method: QFL과 블록체인을 통합한 QFLchain 프레임워크를 제안하고, 6G 환경에서 통신 및 합의 오버헤드, 확장성 및 저장 오버헤드, 에너지 비효율성, 보안 취약성의 네 가지 주요 요소를 분석한다.

Result: QFLchain은 기존 방법들과 비교하여 훈련 성능에서 잠재적인 장점을 시뮬레이션을 통해 입증하는 사례 연구를 포함한다.

Conclusion: QFLchain은 6G 인텔리전스에 안전하고 확장 가능한 솔루션을 제공하는 동시에 양자 시대의 위협에 대한 저항력을 증가시킨다.

Abstract: Quantum federated learning (QFL) is emerging as a key enabler for intelligent, secure, and privacy-preserving model training in next-generation 6G networks. By leveraging the computational advantages of quantum devices, QFL offers significant improvements in learning efficiency and resilience against quantum-era threats. However, future 6G environments are expected to be highly dynamic, decentralized, and data-intensive, which necessitates moving beyond traditional centralized federated learning frameworks. To meet this demand, blockchain technology provides a decentralized, tamper-resistant infrastructure capable of enabling trustless collaboration among distributed quantum edge devices. This paper presents QFLchain, a novel framework that integrates QFL with blockchain to support scalable and secure 6G intelligence. In this work, we investigate four key pillars of \textit{QFLchain} in the 6G context: (i) communication and consensus overhead, (ii) scalability and storage overhead, (iii) energy inefficiency, and (iv) security vulnerability. A case study is also presented, demonstrating potential advantages of QFLchain, based on simulation, over state-of-the-art approaches in terms of training performance.

</details>


### [2] [Malicious GenAI Chrome Extensions: Unpacking Data Exfiltration and Malicious Behaviours](https://arxiv.org/abs/2512.10029)
*Shresta B. Seetharam,Mohamed Nabeel,William Melicher*

Main category: cs.CR

TL;DR: 사이버 범죄자들이 AI 및 GenAI 도구를 위장한 악성 Chrome 확장을 배포하고 있으며, 이는 사용자 데이터를 유출하고 트래픽을 공격자가 제어하는 도메인으로 리다이렉트하는 데 사용된다. 연구팀은 5,551개의 AI 관련 확장 프로그램을 분석하여 154개의 이전에 감지되지 않은 악성 확장을 발견하고, 최종적으로 341개의 악성 확장을 분석하였다.


<details>
  <summary>Details</summary>
Motivation: AI 및 GenAI 도구의 빠른 확산이 Chrome 웹 스토어까지 확장되면서, 사이버 범죄자들이 이를 악용하고 있다는 점이 필요성을 제기하였다.

Method: 브라우저 확장 생태계에 미치는 영향을 조사하기 위해, 5,551개의 AI 테마 확장 프로그램의 데이터 세트를 수집하고 다중 신호 탐지 방법론을 이용하여 분석하였다.

Result: 154개의 신규 악성 Chrome 확장을 발견하였고, 이를 포함하여 공공 위협 연구에서 알려진 확장과 함께 총 341개의 악성 확장을 최종 분석하였다.

Conclusion: 사이버 범죄자들이 GenAI 추세를 악용하고 있으며, 브라우저 확장 API 및 설정을 해악적으로 이용하고 있다는 점을 보여주는 결과이다.

Abstract: The rapid proliferation of AI and GenAI tools has extended to the Chrome Web Store. Cybercriminals are exploiting this trend, deploying malicious Chrome extensions posing as AI tools or impersonating popular GenAI models to target users. These extensions often appear legitimate while secretly exfiltrating sensitive data or redirecting users web traffic to attacker-controlled domains.
  To examine the impact of this trend on the browser extension ecosystem, we curated a dataset of 5,551 AI-themed extensions released over a nine-month period to the Chrome Web Store. Using a multi-signal detection methodology that combines manifest analysis, domain reputation, and runtime network behavior, supplemented with human review, we identified 154 previously undetected malicious Chrome extensions. Together with extensions known from public threat research disclosures, this resulted in a final set of 341 malicious extensions for analysis. Of these, 29 were GenAI-related, forming the focus of our in-depth analysis and disclosure.
  We deconstruct representative GenAI cases, including Supersonic AI, DeepSeek AI | Free AI Assistant, and Perplexity Search, to illustrate attacker techniques such as Adversary-in-the-Browser, impersonation, bait-and-switch updates, query hijacking, and redirection. Our findings show that threat actors are leveraging GenAI trends and exploiting browser extension APIs and settings for malicious purposes. This demonstrates that the browser extension threat landscape is directly evolving alongside the rapid adoption of GenAI technologies.

</details>


### [3] [LLM-PEA: Leveraging Large Language Models Against Phishing Email Attacks](https://arxiv.org/abs/2512.10104)
*Najmul Hassan,Prashanth BusiReddyGari,Haitao Zhao,Yihao Ren,Jinsheng Xu,Shaohu Zhang*

Main category: cs.CR

TL;DR: 이 논문은 다중 공격 경로를 통한 피싱 이메일 공격을 탐지하기 위한 LLM 기반 프레임워크인 LLMPEA를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 시스템이 이메일 보안 시스템에 배포될 때 다중 공격 경로를 이용한 피싱 이메일 위협에 직면하고 있다는 점에서, 이러한 시스템의 구조적 취약점들을 이용한 공격에 대비해야 한다는 필요성을 제기합니다.

Method: LLMPEA 프레임워크를 통해 prompt injection, 텍스트 정제, 다국어 공격과 같은 다양한 공격 경로에서 피싱 이메일 공격을 탐지하는 방법을 제안합니다.

Result: 세 개의 최신 LLM(GPT-4o, Claude Sonnet 4, Grok-3)을 평가한 결과, 90% 이상의 정확도로 피싱 이메일을 탐지할 수 있음을 발견하였습니다.

Conclusion: 연구 결과는 공격자들이 여러 가지 취약점을 조합하여 악용하는 실제 환경에서 LLM 기반 피싱 탐지 시스템의 중요성을 강조합니다.

Abstract: Email phishing is one of the most prevalent and globally consequential vectors of cyber intrusion. As systems increasingly deploy Large Language Models (LLMs) applications, these systems face evolving phishing email threats that exploit their fundamental architectures. Current LLMs require substantial hardening before deployment in email security systems, particularly against coordinated multi-vector attacks that exploit architectural vulnerabilities. This paper proposes LLMPEA, an LLM-based framework to detect phishing email attacks across multiple attack vectors, including prompt injection, text refinement, and multilingual attacks. We evaluate three frontier LLMs (e.g., GPT-4o, Claude Sonnet 4, and Grok-3) and comprehensive prompting design to assess their feasibility, robustness, and limitations against phishing email attacks. Our empirical analysis reveals that LLMs can detect the phishing email over 90% accuracy while we also highlight that LLM-based phishing email detection systems could be exploited by adversarial attack, prompt injection, and multilingual attacks. Our findings provide critical insights for LLM-based phishing detection in real-world settings where attackers exploit multiple vulnerabilities in combination.

</details>


### [4] [FLARE: A Wireless Side-Channel Fingerprinting Attack on Federated Learning](https://arxiv.org/abs/2512.10296)
*Md Nahid Hasan Shuvo,Moinul Hossain,Anik Mallik,Jeffrey Twigg,Fikadu Dagefu*

Main category: cs.CR

TL;DR: 이 논문은 분산 장치에서의 Federated Learning(FL) 모델 훈련의 개인정보 보호 취약성을 다룹니다. FLARE라는 새로운 사이드 채널 핑거프린팅 공격 기법을 제안하며, 이를 통해 클라이언트의 심층 학습 모델 아키텍처를 유추할 수 있음을 보입니다.


<details>
  <summary>Details</summary>
Motivation: Federated Learning(FL)이 데이터와 사용자 프라이버시를 보호하면서 분산된 장치에서 협업 모델 훈련을 가능하게 하는 반면, FL은 여전히 데이터 손상을 초래할 수 있는 프라이버시 위협에 노출되어 있다는 점.

Method: FLARE라는 새로운 사이드 채널 공격 기법을 통해 암호화된 무선 트래픽의 흐름 수준 및 패킷 수준 통계를 활용하여 FL 클라이언트의 심층 학습 모델 아키텍처를 추론.

Result: CNN 및 RNN 변형, 특히 IEEE 802.11 Wi-Fi에서 훈련된 모델을 포함한 평가 결과, FLARE는 폐쇄 세계에서 98% 이상의 F1 점수를, 개방 세계 시나리오에서는 91%에 달하는 점수를 달성함.

Conclusion: 이 연구는 암호화된 무선 트래픽을 분석하여 FL 모델 아키텍처를 핑거프린팅 하는 첫 번째 연구로, 현재 FL 시스템의 중요한 사이드 채널 취약성을 노출시킵니다.

Abstract: Federated Learning (FL) enables collaborative model training across distributed devices while safeguarding data and user privacy. However, FL remains susceptible to privacy threats that can compromise data via direct means. That said, indirectly compromising the confidentiality of the FL model architecture (e.g., a convolutional neural network (CNN) or a recurrent neural network (RNN)) on a client device by an outsider remains unexplored. If leaked, this information can enable next-level attacks tailored to the architecture. This paper proposes a novel side-channel fingerprinting attack, leveraging flow-level and packet-level statistics of encrypted wireless traffic from an FL client to infer its deep learning model architecture. We name it FLARE, a fingerprinting framework based on FL Architecture REconnaissance. Evaluation across various CNN and RNN variants-including pre-trained and custom models trained over IEEE 802.11 Wi-Fi-shows that FLARE achieves over 98% F1-score in closed-world and up to 91% in open-world scenarios. These results reveal that CNN and RNN models leak distinguishable traffic patterns, enabling architecture fingerprinting even under realistic FL settings with hardware, software, and data heterogeneity. To our knowledge, this is the first work to fingerprint FL model architectures by sniffing encrypted wireless traffic, exposing a critical side-channel vulnerability in current FL systems.

</details>


### [5] [Bit of a Close Talker: A Practical Guide to Serverless Cloud Co-Location Attacks](https://arxiv.org/abs/2512.10361)
*Wei Shao,Najmeh Nazari,Behnam Omidi,Setareh Rafatirad,Houman Homayoun,Khaled N. Khasawneh,Chongzhou Fang*

Main category: cs.CR

TL;DR: 서버리스 컴퓨팅은 클라우드 컴퓨팅에 혁신을 가져왔으나, 사용자는 여전히 다양한 공격에 취약하다. 본 연구는 서버리스 클라우드 스케줄러의 취약성을 연구하고, 인스턴스 동시 배치 공격을 구성하기 위한 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 서버리스 클라우드 사용자가 다양한 공격에 취약하다는 점에서 클라우드 스케줄러의 취약성을 연구할 필요가 있다.

Method: 서버리스 스케줄링 알고리즘에서 활용 가능한 특징을 발견하고, 일반 사용자 인터페이스를 통해 동시 배치 공격을 구성하기 위한 전략을 개발한다.

Result: 오픈 소스 인프라와 마이크로소프트 애저 기능에서 인스턴스 동시 배치에 성공적으로 도달하며, 취약점을 밝혀낸다.

Conclusion: 서버리스 클라우드에서 동시 배치 공격에 대한 방어 전략을 제시하며, 현재 클라우드 스케줄러의 보안 강화를 위한 중요한 영역을 강조한다.

Abstract: Serverless computing has revolutionized cloud computing by offering an efficient and cost-effective way for users to develop and deploy applications without managing infrastructure details. However, serverless cloud users remain vulnerable to various types of attacks, including micro-architectural side-channel attacks. These attacks typically rely on the physical co-location of victim and attacker instances, and attackers will need to exploit cloud schedulers to achieve co-location with victims. Therefore, it is crucial to study vulnerabilities in serverless cloud schedulers and assess the security of different serverless scheduling algorithms. This study addresses the gap in understanding and constructing co-location attacks in serverless clouds. We present a comprehensive methodology to uncover exploitable features in serverless scheduling algorithms and devise strategies for constructing co-location attacks through normal user interfaces. In our experiments, we successfully reveal exploitable vulnerabilities and achieve instance co-location on prevalent open-source infrastructures and Microsoft Azure Functions. We also present a mitigation strategy to defend against co-location attacks in serverless clouds. Our work highlights critical areas for security enhancements in current cloud schedulers, offering insights to fortify serverless computing environments against potential co-location attacks.

</details>


### [6] [Adaptive Intrusion Detection System Leveraging Dynamic Neural Models with Adversarial Learning for 5G/6G Networks](https://arxiv.org/abs/2512.10637)
*Neha,Tarunpreet Bhatia*

Main category: cs.CR

TL;DR: 이 논문은 5G/6G 네트워크를 위한 고급 침입 탐지 시스템(IDS) 프레임워크를 제시하여 실시간 위협 탐지 및 대응 능력을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 IDS 접근 방식은 서명 기반 방법에 의존하여 새로운 공격을 탐지하는 데 어려움을 겪고 있다.

Method: 본 연구는 적대적 학습과 동적 신경망을 활용하여 IDS의 성능을 향상시키고, 점진적 학습 알고리즘을 통합하여 잦은 재교육의 필요성을 줄인다.

Result: NSL-KDD 데이터셋을 사용한 평가에서 다중 클래스 네트워크 공격의 정확도가 82.33%로 향상되었으며 데이터셋 오염에도 저항하였다.

Conclusion: 이 연구는 적대적 학습된 동적 신경망이 탄력적인 IDS 솔루션 구축에 기여할 잠재력을 강조한다.

Abstract: Intrusion Detection Systems (IDS) are critical components in safeguarding 5G/6G networks from both internal and external cyber threats. While traditional IDS approaches rely heavily on signature-based methods, they struggle to detect novel and evolving attacks. This paper presents an advanced IDS framework that leverages adversarial training and dynamic neural networks in 5G/6G networks to enhance network security by providing robust, real-time threat detection and response capabilities. Unlike conventional models, which require costly retraining to update knowledge, the proposed framework integrates incremental learning algorithms, reducing the need for frequent retraining. Adversarial training is used to fortify the IDS against poisoned data. By using fewer features and incorporating statistical properties, the system can efficiently detect potential threats. Extensive evaluations using the NSL- KDD dataset demonstrate that the proposed approach provides better accuracy of 82.33% for multiclass classification of various network attacks while resisting dataset poisoning. This research highlights the potential of adversarial-trained, dynamic neural networks for building resilient IDS solutions.

</details>


### [7] [Metaphor-based Jailbreaking Attacks on Text-to-Image Models](https://arxiv.org/abs/2512.10766)
*Chenyu Zhang,Yiwen Ma,Lanjun Wang,Wenhui Li,Yi Tu,An-An Liu*

Main category: cs.CR

TL;DR: MJA는 메타포 기반 탈옥 공격 방법으로, 다양한 방어 메커니즘에 대해 효과적으로 공격한다.


<details>
  <summary>Details</summary>
Motivation: 기존 공격 방법이 방어의 유형을 알고 있다고 가정하므로, 알려지지 않은 방어 메커니즘에 대한 효과가 제한된다.

Method: MJA는 LLM 기반 다중 에이전트 생성 모듈과 적대적 프롬프트 최적화 모듈로 구성되어 있다.

Result: 다양한 방어 메커니즘에 대한 실험에서 MJA가 다른 기본 방법들보다 우수한 공격 성능을 보였다.

Conclusion: MJA는 적은 쿼리를 사용하면서도 강력한 공격 성능을 달성한다.

Abstract: Text-to-image~(T2I) models commonly incorporate defense mechanisms to prevent the generation of sensitive images. Unfortunately, recent jailbreaking attacks have shown that adversarial prompts can effectively bypass these mechanisms and induce T2I models to produce sensitive content, revealing critical safety vulnerabilities. However, existing attack methods implicitly assume that the attacker knows the type of deployed defenses, which limits their effectiveness against unknown or diverse defense mechanisms. In this work, we introduce \textbf{MJA}, a \textbf{m}etaphor-based \textbf{j}ailbreaking \textbf{a}ttack method inspired by the Taboo game, aiming to effectively and efficiently attack diverse defense mechanisms without prior knowledge of their type by generating metaphor-based adversarial prompts. Specifically, MJA consists of two modules: an LLM-based multi-agent generation module~(MLAG) and an adversarial prompt optimization module~(APO). MLAG decomposes the generation of metaphor-based adversarial prompts into three subtasks: metaphor retrieval, context matching, and adversarial prompt generation. Subsequently, MLAG coordinates three LLM-based agents to generate diverse adversarial prompts by exploring various metaphors and contexts. To enhance attack efficiency, APO first trains a surrogate model to predict the attack results of adversarial prompts and then designs an acquisition strategy to adaptively identify optimal adversarial prompts. Extensive experiments on T2I models with various external and internal defense mechanisms demonstrate that MJA outperforms six baseline methods, achieving stronger attack performance while using fewer queries. Code is available in https://github.com/datar001/metaphor-based-jailbreaking-attack.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [BAMBO: Construct Ability and Efficiency LLM Pareto Set via Bayesian Adaptive Multi-objective Block-wise Optimization](https://arxiv.org/abs/2512.09972)
*Kesheng Chen,Wenjian Luo,Zhenqian Zhu,Yamin Hu,Yiya Xi*

Main category: cs.LG

TL;DR: BAMBO는 대형 언어 모델의 Pareto 집합을 자동으로 구성하여 최적의 솔루션을 제공하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델에서 능력-효율성의 트레이드오프를 탐색하기 위해 Pareto 집합을 구성하는 것이 중요하지만, 기존 병합 기술이 이 작업에 적절하지 않다.

Method: BAMBO는 Hybrid Optimal Block Partitioning 전략을 도입하여 탐색을 용이하게 하며, 이를 1D 클러스터링 문제로 공식화하여 동적 프로그래밍 방법을 활용하여 블록 내부의 동질성과 블록 간 정보 분포를 최적 균형 있게 조정한다.

Result: 실험 결과, BAMBO는 기존 기준보다 우수하고 종합적인 Pareto 경계선을 발견하여 다양한 운영 제약에 맞춘 민첩한 모델 선택을 가능하게 한다.

Conclusion: BAMBO는 대형 언어 모델의 Pareto 집합을 자동으로 구성하며, 모델 선택 과정을 향상시키는 데 기여한다.

Abstract: Constructing a Pareto set is pivotal for navigating the capability-efficiency trade-offs in Large Language Models (LLMs); however, existing merging techniques remain inadequate for this task. Coarse-grained, model-level methods yield only a sparse set of suboptimal solutions, while fine-grained, layer-wise approaches suffer from the "curse of dimensionality," rendering the search space computationally intractable. To resolve this dichotomy, we propose BAMBO (Bayesian Adaptive Multi-objective Block-wise Optimization), a novel framework that automatically constructs the LLM Pareto set. BAMBO renders the search tractable by introducing a Hybrid Optimal Block Partitioning strategy. Formulated as a 1D clustering problem, this strategy leverages a dynamic programming approach to optimally balance intra-block homogeneity and inter-block information distribution, thereby dramatically reducing dimensionality without sacrificing critical granularity. The entire process is automated within an evolutionary loop driven by the q-Expected Hypervolume Improvement (qEHVI) acquisition function. Experiments demonstrate that BAMBO discovers a superior and more comprehensive Pareto frontier than baselines, enabling agile model selection tailored to diverse operational constraints. Code is available at: https://github.com/xin8coder/BAMBO.

</details>


### [9] [Better Prevent than Tackle: Valuing Defense in Soccer Based on Graph Neural Networks](https://arxiv.org/abs/2512.10355)
*Hyunsung Kim,Sangwoo Seo,Hoyoung Choi,Tom Boomstra,Jinsung Yoon,Chanyoung Park*

Main category: cs.LG

TL;DR: DEFCON은 축구에서의 방어 성능을 평가하기 위한 새로운 프레임워크로, 선수의 방어 기여도를 정량화한다.


<details>
  <summary>Details</summary>
Motivation: 축구에서 방어 성능을 평가하는 것은 어려우며, 기존 방법은 공이 있는 행동에만 초점을 맞췄다.

Method: DEFCON은 Graph Attention Networks를 활용하여 공격 옵션의 성공 확률과 가치를 추정하고 방어자의 책임을 평가한다.

Result: DEFCON의 집계된 선수 크레딧은 시장 평가와 강한 긍정적 상관관계를 보인다.

Conclusion: DEFCON은 방어 기여도의 실시간 타임라인, 공간 분석, 공격자-방어자 상호작용 요약의 여러 응용을 보여준다.

Abstract: Evaluating defensive performance in soccer remains challenging, as effective defending is often expressed not through visible on-ball actions such as interceptions and tackles, but through preventing dangerous opportunities before they arise. Existing approaches have largely focused on valuing on-ball actions, leaving much of defenders' true impact unmeasured. To address this gap, we propose DEFCON (DEFensive CONtribution evaluator), a comprehensive framework that quantifies player-level defensive contributions for every attacking situation in soccer. Leveraging Graph Attention Networks, DEFCON estimates the success probability and expected value of each attacking option, along with each defender's responsibility for stopping it. These components yield an Expected Possession Value (EPV) for the attacking team before and after each action, and DEFCON assigns positive or negative credits to defenders according to whether they reduced or increased the opponent's EPV. Trained on 2023-24 and evaluated on 2024-25 Eredivisie event and tracking data, DEFCON's aggregated player credits exhibit strong positive correlations with market valuations. Finally, we showcase several practical applications, including in-game timelines of defensive contributions, spatial analyses across pitch zones, and pairwise summaries of attacker-defender interactions.

</details>


### [10] [SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation](https://arxiv.org/abs/2512.10042)
*Jongmin Lee,Meiqi Sun,Pieter Abbeel*

Main category: cs.LG

TL;DR: SEMDICE는 오프 정책 데이터셋을 활용하여 상태 엔트로피를 극대화하는 정책을 학습하는 비지도 강화 학습 알고리즘이다.


<details>
  <summary>Details</summary>
Motivation: 비지도 사전 학습에서 에이전트는 특정 작업의 보상 함수에 의존하지 않고 하위 작업을 위한 사전 정책을 학습하고자 한다.

Method: 상태 엔트로피 극대화(SEM)를 목표로 하여, SEMDICE는 주어진 오프 정책 데이터셋으로부터 SEM 정책을 계산하는 원칙 기반의 오프 정책 알고리즘이다.

Result: 실험 결과 SEMDICE는 상태 엔트로피를 극대화하는 데 있어 기준 알고리즘을 능가하고, SEM 기반 비지도 RL 사전 학습 방법 중 하위 작업에 대한 적응 효율성이 가장 뛰어난 것으로 나타났다.

Conclusion: SEMDICE는 정적 분포 공간 내에서 직접 정책을 최적화하여 단일의 정적 마르코프 상태 엔트로피 극대화 정책을 계산한다.

Abstract: In the unsupervised pre-training for reinforcement learning, the agent aims to learn a prior policy for downstream tasks without relying on task-specific reward functions. We focus on state entropy maximization (SEM), where the goal is to learn a policy that maximizes the entropy of the state stationary distribution. In this paper, we introduce SEMDICE, a principled off-policy algorithm that computes an SEM policy from an arbitrary off-policy dataset, which optimizes the policy directly within the space of stationary distributions. SEMDICE computes a single, stationary Markov state-entropy-maximizing policy from an arbitrary off-policy dataset. Experimental results demonstrate that SEMDICE outperforms baseline algorithms in maximizing state entropy while achieving the best adaptation efficiency for downstream tasks among SEM-based unsupervised RL pre-training methods.

</details>


### [11] [Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition](https://arxiv.org/abs/2512.10043)
*João Lucas Luz Lima Sarcinelli,Diego Furtado Silva*

Main category: cs.LG

TL;DR: 본 연구는 로컬에서 실행되는 LLM을 활용한 제로샷 개체명 인식(NER)을 위한 새로운 세 단계 앙상블 파이프라인을 제안하며, 포르투갈어 NER 데이터셋에서 성능 향상을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 저자들은 개체명 인식(NER)에서 낮은 자원 언어인 포르투갈어에 대한 LLM의 성능 저하 문제를 해결하고자 합니다.

Method: 세 단계 앙상블 파이프라인을 통해 유사한 성능을 가진 로컬 LLM을 사용하여 제로샷 NER을 수행합니다.

Result: 우리의 방법은 최소한의 주석 데이터로 최적의 모델 조합을 선택하는 휴리스틱을 활용하여 포르투갈어 NER 데이터셋에서 5개 중 4개의 데이터셋에서 개별 LLM보다 우수한 성능을 보였습니다.

Conclusion: 이 연구는 다수의 소형 LLM을 효과적으로 결합하여 주석 데이터 없이 확장 가능하고 자원이 적은 제로샷 NER에 기여합니다.

Abstract: Large Language Models (LLMs) excel in many Natural Language Processing (NLP) tasks through in-context learning but often under-perform in Named Entity Recognition (NER), especially for lower-resource languages like Portuguese. While open-weight LLMs enable local deployment, no single model dominates all tasks, motivating ensemble approaches. However, existing LLM ensembles focus on text generation or classification, leaving NER under-explored. In this context, this work proposes a novel three-step ensemble pipeline for zero-shot NER using similarly capable, locally run LLMs. Our method outperforms individual LLMs in four out of five Portuguese NER datasets by leveraging a heuristic to select optimal model combinations with minimal annotated data. Moreover, we show that ensembles obtained on different source datasets generally outperform individual LLMs in cross-dataset configurations, potentially eliminating the need for annotated data for the current task. Our work advances scalable, low-resource, and zero-shot NER by effectively combining multiple small LLMs without fine-tuning. Code is available at https://github.com/Joao-Luz/local-llm-ner-ensemble.

</details>


### [12] [Detailed balance in large language model-driven agents](https://arxiv.org/abs/2512.10047)
*Zhuo-Yang Song,Qing-Hong Cao,Ming-xing Luo,Hua Xing Zhu*

Main category: cs.LG

TL;DR: 이 논문은 대형 언어 모델(LLM) 기반 에이전트의 거시적 동역학을 이해하기 위한 이론적 틀 부족을 해결하기 위해 최소 작용 원리에 기반한 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트가 복잡한 문제를 해결하는 강력한 패러다임으로 떠오르고 있음에도 불구하고, 이들의 거시적 동역학을 이해하고 통합할 이론적 틀이 부족함을 해결하고자 함.

Method: 최소 작용 원리에 기반하여 LLM 내부에 내재한 생성 방향성을 추정하는 방법을 제안하고, LLM이 생성한 상태 간 전이 확률을 실험적으로 측정함.

Result: LLM 생성 전이에 있는 세밀한 균형을 통계적으로 발견하였으며, 이는 LLM 생성이 일반적인 규칙 집합과 전략을 배우는 것이 아닌, 다양한 LLM 구조와 프롬프트 템플릿을 초월할 수 있는 기본적인 잠재 함수 클래스를 암묵적으로 학습함을 나타냄.

Conclusion: 이 연구는 특정 모델 세부 사항에 의존하지 않는 LLM 생성 동역학의 거시적 물리 법칙을 최초로 발견한 것으로, 복잡한 AI 시스템의 거시적 동역학 이론을 확립하고자 한다.

Abstract: Large language model (LLM)-driven agents are emerging as a powerful new paradigm for solving complex problems. Despite the empirical success of these practices, a theoretical framework to understand and unify their macroscopic dynamics remains lacking. This Letter proposes a method based on the least action principle to estimate the underlying generative directionality of LLMs embedded within agents. By experimentally measuring the transition probabilities between LLM-generated states, we statistically discover a detailed balance in LLM-generated transitions, indicating that LLM generation may not be achieved by generally learning rule sets and strategies, but rather by implicitly learning a class of underlying potential functions that may transcend different LLM architectures and prompt templates. To our knowledge, this is the first discovery of a macroscopic physical law in LLM generative dynamics that does not depend on specific model details. This work is an attempt to establish a macroscopic dynamics theory of complex AI systems, aiming to elevate the study of AI agents from a collection of engineering practices to a science built on effective measurements that are predictable and quantifiable.

</details>


### [13] [MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis](https://arxiv.org/abs/2512.10098)
*Midhat Urooj,Ayan Banerjee,Farhat Shaikh,Kuntal Thakur,Sandeep Gupta*

Main category: cs.LG

TL;DR: 의료 AI에서 정확하고 해석 가능한 이미지 기반 진단은 기본적인 도전 과제로, 특히 도메인 변화와 희귀 클래스 조건에서 문제가 된다. 본 논문에서는 MedXAI라는 통합된 전문가 지식 기반 프레임워크를 소개하여, 전문가 지식을 통합하고 희귀 클래스 편향을 줄이며 설명가능성을 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 의료 AI에서 이미지 기반 진단의 정확성과 해석 가능성을 높이는 것이 필요하다.

Method: MedXAI는 심층 비전 모델과 임상 전문가의 지식을 통합하여 진단 특징을 국소화하고 해석 가능한 설명을 제공한다.

Result: 페널티가 적은 희귀 클래스에 대한 F1 점수가 10% 개선되고 교차 도메인 일반화에서 3% 향상되었다.

Conclusion: MedXAI는 희귀질환에 대해 우수한 성능을 보여준다.

Abstract: Accurate and interpretable image-based diagnosis remains a fundamental challenge in medical AI, particularly un- der domain shifts and rare-class conditions. Deep learning mod- els often struggle with real-world distribution changes, exhibit bias against infrequent pathologies, and lack the transparency required for deployment in safety-critical clinical environments. We introduce MedXAI (An Explainable Framework for Med- ical Imaging Classification), a unified expert knowledge based framework that integrates deep vision models with clinician- derived expert knowledge to improve generalization, reduce rare- class bias, and provide human-understandable explanations by localizing the relevant diagnostic features rather than relying on technical post-hoc methods (e.g., Saliency Maps, LIME). We evaluate MedXAI across heterogeneous modalities on two challenging tasks: (i) Seizure Onset Zone localization from resting-state fMRI, and (ii) Diabetic Retinopathy grading. Ex periments on ten multicenter datasets show consistent gains, including a 3% improvement in cross-domain generalization and a 10% improvmnet in F1 score of rare class, substantially outperforming strong deep learning baselines. Ablations confirm that the symbolic components act as effective clinical priors and regularizers, improving robustness under distribution shift. MedXAI delivers clinically aligned explanations while achieving superior in-domain and cross-domain performance, particularly for rare diseases in multimodal medical AI.

</details>


### [14] [Exact Recovery of Non-Random Missing Multidimensional Time Series via Temporal Isometric Delay-Embedding Transform](https://arxiv.org/abs/2512.10191)
*Hao Shu,Jicheng Li,Yu Jin,Ling Zhou*

Main category: cs.LG

TL;DR: 비무작위 결측 데이터는 다차원 시계열에서 일반적이지만 제대로 다루어지지 않는 결함으로, 데이터 기반 분석 및 의사결정의 신뢰성을 근본적으로 위협한다. 본 연구는 비무작위 결측 패턴을 가진 다차원 시계열 회복을 위한 계측 텐서 완성을 제안하며, 새로운 기법으로 LRTC-TIDT 모델을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 다차원 시계열에서의 비무작위 결측 데이터는 충분히 처리되지 않아 데이터 분석의 신뢰성을 위협한다.

Method: 시계열의 매끄러움과 주기성에 의해 자연적으로 저순위 성질을 가지는 Hankel 텐서를 구성하는 시계열 등각 지연 임베딩 변환을 제안하고, 이를 바탕으로 LRTC-TIDT 모델을 개발한다.

Result: 제안된 LRTC-TIDT 모델은 비무작위 결측 패턴 하에서 시뮬레이션 실험을 통해 정확한 복구를 달성하며, 기존의 텐서 기반 방법에 비해 여러 실제 세계 작업에서 일관되게 우수한 성능을 보인다.

Conclusion: LRTC-TIDT 모델은 특정 비무작위 샘플링 조건과 경량의 비일관성 가정이 충족되면 정확한 복구를 보장하며, 공개적으로 구현 가능하다.

Abstract: Non-random missing data is a ubiquitous yet undertreated flaw in multidimensional time series, fundamentally threatening the reliability of data-driven analysis and decision-making. Pure low-rank tensor completion, as a classical data recovery method, falls short in handling non-random missingness, both methodologically and theoretically. Hankel-structured tensor completion models provide a feasible approach for recovering multidimensional time series with non-random missing patterns. However, most Hankel-based multidimensional data recovery methods both suffer from unclear sources of Hankel tensor low-rankness and lack an exact recovery theory for non-random missing data. To address these issues, we propose the temporal isometric delay-embedding transform, which constructs a Hankel tensor whose low-rankness is naturally induced by the smoothness and periodicity of the underlying time series. Leveraging this property, we develop the \textit{Low-Rank Tensor Completion with Temporal Isometric Delay-embedding Transform} (LRTC-TIDT) model, which characterizes the low-rank structure under the \textit{Tensor Singular Value Decomposition} (t-SVD) framework. Once the prescribed non-random sampling conditions and mild incoherence assumptions are satisfied, the proposed LRTC-TIDT model achieves exact recovery, as confirmed by simulation experiments under various non-random missing patterns. Furthermore, LRTC-TIDT consistently outperforms existing tensor-based methods across multiple real-world tasks, including network flow reconstruction, urban traffic estimation, and temperature field prediction. Our implementation is publicly available at https://github.com/HaoShu2000/LRTC-TIDT.

</details>


### [15] [Dynamics of Agentic Loops in Large Language Models: A Geometric Theory of Trajectories](https://arxiv.org/abs/2512.10350)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 이 논문은 대형 언어 모델에 기반한 대리 시스템의 기하학적 행동을 분석하기 위한 새로운 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대리 시스템의 출력을 다음 입력으로 사용하는 반복 피드백 루프가 어떻게 작동하는지를 이해하고자 함.

Method: 의미 임베딩 공간의 대리 궤적을 분석하기 위해 이산 동적 시스템으로서 반복 변환을 다룸.

Result: 두 가지 기본적인 동적 방식이 발견되었으며 각각 안정적인 매력점과 무한 발산을 보여줌.

Conclusion: 프롬프트 디자인이 대리 루프의 동적 방식을 직접 지배하여 시퀀스의 수렴, 발산 및 궤적 구조를 체계적으로 제어할 수 있음을 보여줌.

Abstract: Agentic systems built on large language models operate through recursive feedback loops, where each output becomes the next input. Yet the geometric behavior of these agentic loops (whether they converge, diverge, or exhibit more complex dynamics) remains poorly understood. This paper introduces a geometric framework for analyzing agentic trajectories in semantic embedding space, treating iterative transformations as discrete dynamical systems. We distinguish the artifact space, where linguistic transformations occur, from the embedding space, where geometric measurements are performed. Because cosine similarity is biased by embedding anisotropy, we introduce an isotonic calibration that eliminates systematic bias and aligns similarities with human semantic judgments while preserving high local stability. This enables rigorous measurement of trajectories, clusters and attractors. Through controlled experiments on singular agentic loops, we identify two fundamental regimes. A contractive rewriting loop converges toward a stable attractor with decreasing dispersion, while an exploratory summarize and negate loop produces unbounded divergence with no cluster formation. These regimes display qualitatively distinct geometric signatures of contraction and expansion. Our results show that prompt design directly governs the dynamical regime of an agentic loop, enabling systematic control of convergence, divergence and trajectory structure in iterative LLM transformations.

</details>


### [16] [The Eminence in Shadow: Exploiting Feature Boundary Ambiguity for Robust Backdoor Attacks](https://arxiv.org/abs/2512.10402)
*Zhou Feng,Jiahao Chen,Chunyi Zhou,Yuwen Pu,Tianyu Du,Jinbao Li,Jianhai Chen,Shouling Ji*

Main category: cs.LG

TL;DR: 이 논문은 DNN을 대상으로 한 백도어 공격의 이론적 분석을 제공하며, 희소 결정 경계가 모델 조작에 미치는 영향을 다룹니다. 이 연구는 효과적인 백도어 공격을 위한 Eminence라는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 백도어 공격에 대한 이론적 분석이 부족하여 공격의 예측 가능성과 적응성을 제한하는 문제를 해결하고자 합니다.

Method: 희소 결정 경계를 통한 백도어 공격의 메커니즘을 분석하고, 이론적으로 검증 가능한 백도어 프레임워크인 Eminence를 제안합니다.

Result: Eminence는 0.1% 미만의 낮은 독성률로 효과적인 조작을 달성하며, 90% 이상의 공격 성공률을 유지합니다.

Conclusion: Eminence는 다양한 모델과 데이터셋에서 높은 이식성과 함께 낮은 정확도 손실을 보이며, 결정 경계를 효과적으로 조작하는 것으로 입증되었습니다.

Abstract: Deep neural networks (DNNs) underpin critical applications yet remain vulnerable to backdoor attacks, typically reliant on heuristic brute-force methods. Despite significant empirical advancements in backdoor research, the lack of rigorous theoretical analysis limits understanding of underlying mechanisms, constraining attack predictability and adaptability. Therefore, we provide a theoretical analysis targeting backdoor attacks, focusing on how sparse decision boundaries enable disproportionate model manipulation. Based on this finding, we derive a closed-form, ambiguous boundary region, wherein negligible relabeled samples induce substantial misclassification. Influence function analysis further quantifies significant parameter shifts caused by these margin samples, with minimal impact on clean accuracy, formally grounding why such low poison rates suffice for efficacious attacks. Leveraging these insights, we propose Eminence, an explainable and robust black-box backdoor framework with provable theoretical guarantees and inherent stealth properties. Eminence optimizes a universal, visually subtle trigger that strategically exploits vulnerable decision boundaries and effectively achieves robust misclassification with exceptionally low poison rates (< 0.1%, compared to SOTA methods typically requiring > 1%). Comprehensive experiments validate our theoretical discussions and demonstrate the effectiveness of Eminence, confirming an exponential relationship between margin poisoning and adversarial boundary manipulation. Eminence maintains > 90% attack success rate, exhibits negligible clean-accuracy loss, and demonstrates high transferability across diverse models, datasets and scenarios.

</details>


### [17] [Metacognitive Sensitivity for Test-Time Dynamic Model Selection](https://arxiv.org/abs/2512.10451)
*Le Tuan Minh Trinh,Le Minh Vu Pham,Thi Minh Anh Pham,An Duc Nguyen*

Main category: cs.LG

TL;DR: 본 연구는 AI의 메타인지 평가를 위한 새로운 프레임워크를 제안하며, 모델의 신뢰도와 정확도를 측정하는 메타-d' 지표를 도입하여 여러 전문 모델 중 신뢰할 수 있는 모델 선택을 향상시키는 방법을 모색한다.


<details>
  <summary>Details</summary>
Motivation: 메타인지는 인간 인지의 핵심 요소로, 자신의 지식과 판단의 신뢰성을 평가하는 능력이다. AI 모델이 예측에 대한 신뢰도를 표현할 수 있지만, 종종 잘못된 보정으로 인해 신뢰도가 실제 역량을 반영하지 않는 문제가 있다.

Method: 새로운 메타인지 평가 프레임워크를 제안하고, 심리학적으로 뒷받침된 메타-d' 지표를 도입하여 신뢰도가 정확도를 얼마나 잘 예측하는지를 평가한다. 이후 이 동적 신뢰도 점수를 사용하여 밴딧 기반의 중재자를 통해 주어진 작업에 대해 신뢰할 수 있는 여러 전문 모델 중 하나를 선택한다.

Result: 여러 데이터세트와 깊은 학습 모델 조합을 통한 실험 결과, 이 메타인지 접근 방식이 구성 모델들에 비해 공동 추론 정확도를 개선한다는 것을 보여준다.

Conclusion: 이 연구는 AI 모델에 대한 새로운 행동적 설명을 제공하며, 앙상블 선택 문제를 단기 신호(신뢰도 예측 점수)와 중기 특성(메타인지 민감성)을 평가하는 문제로 재구성한다.

Abstract: A key aspect of human cognition is metacognition - the ability to assess one's own knowledge and judgment reliability. While deep learning models can express confidence in their predictions, they often suffer from poor calibration, a cognitive bias where expressed confidence does not reflect true competence. Do models truly know what they know? Drawing from human cognitive science, we propose a new framework for evaluating and leveraging AI metacognition. We introduce meta-d', a psychologically-grounded measure of metacognitive sensitivity, to characterise how reliably a model's confidence predicts its own accuracy. We then use this dynamic sensitivity score as context for a bandit-based arbiter that performs test-time model selection, learning which of several expert models to trust for a given task. Our experiments across multiple datasets and deep learning model combinations (including CNNs and VLMs) demonstrate that this metacognitive approach improves joint-inference accuracy over constituent models. This work provides a novel behavioural account of AI models, recasting ensemble selection as a problem of evaluating both short-term signals (confidence prediction scores) and medium-term traits (metacognitive sensitivity).

</details>


### [18] [Hybrid Physics-ML Model for Forward Osmosis Flux with Complete Uncertainty Quantification](https://arxiv.org/abs/2512.10457)
*Shiv Ratn,Shivang Rampriyan,Bahni Ray*

Main category: cs.LG

TL;DR: 이 연구에서는 선진 역삼투 방식의 물 분리 기술을 정확히 모델링하기 위한 새로운 강력한 하이브리드 물리-기계 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: FO 기술은 낮은 에너지 소비로 유망하지만 복잡한 내부 질량 이동 현상으로 인해 수분 유속(Jw)의 정확한 모델링에 어려움이 있습니다.

Method: 가우시안 프로세스 회귀(GPR)를 사용하여 FO 물리 모델 예측과 실험적 수분 유속 간의 잔차 오류로 GPR을 훈련시켰습니다.

Result: 모델은 120개의 데이터 포인트로 훈련되어 독립 테스트 데이터에서 평균 절대 백분율 오차(MAPE) 0.26% 및 R2 0.999를 달성했습니다.

Conclusion: 이로써 FO 공정 최적화와 디지털 트윈 개발을 위한 신뢰할 수 있는 대체 모델이 검증되었습니다.

Abstract: Forward Osmosis (FO) is a promising low-energy membrane separation technology, but challenges in accurately modelling its water flux (Jw) persist due to complex internal mass transfer phenomena. Traditional mechanistic models struggle with empirical parameter variability, while purely data-driven models lack physical consistency and rigorous uncertainty quantification (UQ). This study introduces a novel Robust Hybrid Physics-ML framework employing Gaussian Process Regression (GPR) for highly accurate, uncertainty-aware Jw prediction. The core innovation lies in training the GPR on the residual error between the detailed, non-linear FO physical model prediction (Jw_physical) and the experimental water flux (Jw_actual). Crucially, we implement a full UQ methodology by decomposing the total predictive variance (sigma2_total) into model uncertainty (epistemic, from GPR's posterior variance) and input uncertainty (aleatoric, analytically propagated via the Delta method for multi-variate correlated inputs). Leveraging the inherent strength of GPR in low-data regimes, the model, trained on a meagre 120 data points, achieved a state-of-the-art Mean Absolute Percentage Error (MAPE) of 0.26% and an R2 of 0.999 on the independent test data, validating a truly robust and reliable surrogate model for advanced FO process optimization and digital twin development.

</details>


### [19] [UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning](https://arxiv.org/abs/2512.10492)
*Jiaxi Wu,Tiantian Zhang,Yuxing Wang,Yongzhe Chang,Xueqian Wang*

Main category: cs.LG

TL;DR: 강건한 적대적 강화 학습이 불확실한 환경에서 순차적 의사결정 문제를 위한 효과적인 훈련 패러다임으로 부상하였다.


<details>
  <summary>Details</summary>
Motivation: 불확실한 방해 요소를 처리할 수 있는 에이전트를 훈련시키기 위해 강건한 적대적 강화 학습을 활용하고자 하였다.

Method: UACER는 두 가지 전략으로 구성된다: 1) 다양한 비평가 집합을 사용하여 Q-값 추정을 안정화하고, 2) 시간 가변 감쇠 불확실성 메커니즘을 개발하여 탐색-착취 균형을 조절한다.

Result: UACER는 여러 MuJoCo 제어 문제에서 실험을 통해 뛰어난 성능을 나타내었고, 기존 최첨단 방법들을 초월하였다.

Conclusion: UACER가 전체 성능, 안정성 및 효율성 측면에서 기존 방법들보다 우수함을 입증하였다.

Abstract: Robust adversarial reinforcement learning has emerged as an effective paradigm for training agents to handle uncertain disturbance in real environments, with critical applications in sequential decision-making domains such as autonomous driving and robotic control. Within this paradigm, agent training is typically formulated as a zero-sum Markov game between a protagonist and an adversary to enhance policy robustness. However, the trainable nature of the adversary inevitably induces non-stationarity in the learning dynamics, leading to exacerbated training instability and convergence difficulties, particularly in high-dimensional complex environments. In this paper, we propose a novel approach, Uncertainty-Aware Critic Ensemble for robust adversarial Reinforcement learning (UACER), which consists of two strategies: 1) Diversified critic ensemble: a diverse set of K critic networks is exploited in parallel to stabilize Q-value estimation rather than conventional single-critic architectures for both variance reduction and robustness enhancement. 2) Time-varying Decay Uncertainty (TDU) mechanism: advancing beyond simple linear combinations, we develop a variance-derived Q-value aggregation strategy that explicitly incorporates epistemic uncertainty to dynamically regulate the exploration-exploitation trade-off while simultaneously stabilizing the training process. Comprehensive experiments across several MuJoCo control problems validate the superior effectiveness of UACER, outperforming state-of-the-art methods in terms of overall performance, stability, and efficiency.

</details>


### [20] [Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments](https://arxiv.org/abs/2512.10835)
*Atahan Cilan,Atay Özgövde*

Main category: cs.LG

TL;DR: 이 논문은 인간 게임 플레이 데이터에 의존하지 않고도 제어 가능하고 다양한 플레이어 행동을 가능하게 하는 강화 학습 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 기존 접근 방식은 대규모 플레이어 궤적을 요구하거나, 각기 다른 플레이어 유형을 위한 별도의 모델을 훈련시키거나, 해석 가능한 행동 매개변수와 학습된 정책 간의 직접적인 매핑을 제공하지 않아 확장성과 제어 가능성을 제한한다.

Method: 플레이어 행동을 N차원 연속 공간에서 정의하고, 실제 인간 스타일을 나타내는 부분 집합을 포함하는 영역에서 목표 행동 벡터를 균일하게 샘플링한다. 훈련 중 각 에이전트는 현재 행동 벡터와 목표 행동 벡터를 입력으로 받아들인다.

Result: 이러한 방식을 통해 정책은 행동 통계에 대한 행동의 영향을 학습하고, 공격성, 이동성, 협동성과 같은 속성에 대한 부드러운 제어를 가능하게 한다. 단일 PPO 기반의 다중 에이전트 정책은 재훈련 없이 새로운 혹은 보지 못한 플레이 스타일을 재현할 수 있다.

Conclusion: 제안된 프레임워크는 자동화된 플레이 테스트, 게임 밸런싱, 인간과 유사한 행동 시뮬레이션 및 온라인 게임에서 연결이 끊긴 플레이어의 대체를 위한 확장 가능한 솔루션을 제공한다.

Abstract: This paper introduces a reinforcement learning framework that enables controllable and diverse player behaviors without relying on human gameplay data. Existing approaches often require large-scale player trajectories, train separate models for different player types, or provide no direct mapping between interpretable behavioral parameters and the learned policy, limiting their scalability and controllability. We define player behavior in an N-dimensional continuous space and uniformly sample target behavior vectors from a region that encompasses the subset representing real human styles. During training, each agent receives both its current and target behavior vectors as input, and the reward is based on the normalized reduction in distance between them. This allows the policy to learn how actions influence behavioral statistics, enabling smooth control over attributes such as aggressiveness, mobility, and cooperativeness. A single PPO-based multi-agent policy can reproduce new or unseen play styles without retraining. Experiments conducted in a custom multi-player Unity game show that the proposed framework produces significantly greater behavioral diversity than a win-only baseline and reliably matches specified behavior vectors across diverse targets. The method offers a scalable solution for automated playtesting, game balancing, human-like behavior simulation, and replacing disconnected players in online games.

</details>


### [21] [Asynchronous Reasoning: Training-Free Interactive Thinking LLMs](https://arxiv.org/abs/2512.10931)
*George Yakushev,Nataliia Babina,Masoud Vahid Dastgerdi,Vyacheslav Zhdanovskiy,Alina Shutova,Denis Kuznedelev*

Main category: cs.LG

TL;DR: 최신 LLM들은 대답하기 전에 생각하도록 훈련되지만, 이는 비대화적이고 실시간 반응이 필요한 사용 사례와 불일치한다. 본 연구는 추가 훈련 없이 비슷한 방식으로 작동할 수 있도록 LLM을 보강하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 추론 기능이 언어 모델의 능력과 안전성을 크게 향상시킬 수 있지만, 이는 상호작용을 제한하는 문제를 만들 수 있다.

Method: 회전 임베딩 속성을 이용하여 LLM이 동시에 생각하고 듣고 출력을 생성할 수 있도록 하는 방법을 제안한다.

Result: 수학, 상식 및 안전 추론에 대한 평가 결과, 실시간으로 정확한 사고 보강 응답을 생성할 수 있어 비생각 토큰으로의 초기 시간 단축과 전반적인 지연을 6-11배 감소시킬 수 있다.

Conclusion: 제안된 방법은 LLM이 비 sequential 상호작용을 가능하게 하여 실시간 반응능력을 향상시킨다.

Abstract: Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to <= 5s. and the overall real-time delays by 6-11x.

</details>


### [22] [Bidirectional Normalizing Flow: From Data to Noise and Back](https://arxiv.org/abs/2512.10953)
*Yiyang Lu,Qiao Sun,Xianbang Wang,Zhicheng Jiang,Hanhong Zhao,Kaiming He*

Main category: cs.LG

TL;DR: BiFlow는 정밀한 해석적 역함수 없이도 작업할 수 있는 Bidirectional Normalizing Flow 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: Normalizing Flows는 생성 모델링을 위한 유기적인 프레임워크로 자리 잡았습니다. 그러나 최근 TARFlow와 변형들은 인과적 디코딩을 주요 병목 현상으로 드러내었습니다.

Method: BiFlow는 기초적인 노이즈-데이터 역 매핑을 근사하는 역 모델을 학습하여 더 유연한 손실 함수와 아키텍처를 가능하게 합니다.

Result: ImageNet에서의 실험 결과, BiFlow는 인과적 디코딩 방법과 비교하여 생성 품질을 향상시키고 샘플링 속도를 두 배로 증가시켰습니다.

Conclusion: BiFlow는 NF 기반 방법들 중에서 최첨단 결과를 얻었으며, 단일 평가 방법들 사이에서도 경쟁력 있는 성능을 보여줍니다.

Abstract: Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation ("1-NFE") methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [23] [Suzume-chan: Your Personal Navigator as an Embodied Information Hub](https://arxiv.org/abs/2512.09932)
*Maya Grace Torii,Takahito Murakami,Shuka Koseki,Yoichi Ochiai*

Main category: cs.AI

TL;DR: 이 연구는 소셜 프레즌스 이론을 활용하여 깊이 있는 이해를 위한 실시간 인간 커뮤니케이션의 필요성을 강조하며, 물리적 및 대화적 상호 작용을 통해 지식을 공유하는 새로운 방법인 '구현된 정보 허브'를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전문 지식에 접근하기 위해서는 종종 실시간 인간 커뮤니케이션이 필요하지만, 디지털 도구는 정보 접근을 개선하지만 깊은 이해를 위한 연결감을 주지 못한다.

Method: 이 연구는 소셜 프레즌스 이론을 활용하여 '함께 있음'의 느낌이 커뮤니케이션을 어떻게 향상시키는지를 설명하며, '구현된 정보 허브'라는 새로운 방법을 제안한다. 이 프로토타입인 스즈메-짱은 로컬에서 작동하는 작은 부드러운 AI 에이전트로, 언어 모델과 검색 보강 생성(RAG)을 사용한다.

Result: 스즈메-짱은 구두 설명을 통해 학습하고 대화를 통해 응답하여 심리적 거리를 줄이고 지식 공유를 보다 따뜻하고 인간 중심으로 만든다.

Conclusion: 구현된 정보 허브는 정보 공유 방식에 혁신을 가져올 수 있는 가능성을 보여준다.

Abstract: Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of "being together" enhances communication. An "Embodied Information Hub" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.

</details>


### [24] [Exploring Health Misinformation Detection with Multi-Agent Debate](https://arxiv.org/abs/2512.09935)
*Chih-Han Chen,Chen-Han Tsai,Yu-Shao Peng*

Main category: cs.AI

TL;DR: 이 논문은 건강 관련 허위 정보 탐지를 위한 두 단계 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 온라인에서 허위 정보가 확산됨에 따라 건강 관련 주장에 대한 사실 확인의 중요성이 커지고 있다.

Method: 첫 번째 단계에서는 대규모 언어 모델을 사용하여 논문을 독립적으로 평가하고 합의 점수를 계산한다. 두 번째 단계에서는 여러 에이전트가 구조화된 토론에 참여하여 상충하는 증거를 종합하고 명확한 정당성을 가진 판결을 생성한다.

Result: 두 단계 접근 방식이 기존 방법보다 우수한 성능을 달성한다는 실험 결과가 나타났다.

Conclusion: 자동 점수화와 협력적 추론을 결합하여 복잡한 검증 작업의 가치를 강조한다.

Abstract: Fact-checking health-related claims has become increasingly critical as misinformation proliferates online. Effective verification requires both the retrieval of high-quality evidence and rigorous reasoning processes. In this paper, we propose a two-stage framework for health misinformation detection: Agreement Score Prediction followed by Multi-Agent Debate. In the first stage, we employ large language models (LLMs) to independently evaluate retrieved articles and compute an aggregated agreement score that reflects the overall evidence stance. When this score indicates insufficient consensus-falling below a predefined threshold-the system proceeds to a second stage. Multiple agents engage in structured debate to synthesize conflicting evidence and generate well-reasoned verdicts with explicit justifications. Experimental results demonstrate that our two-stage approach achieves superior performance compared to baseline methods, highlighting the value of combining automated scoring with collaborative reasoning for complex verification tasks.

</details>


### [25] [Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting](https://arxiv.org/abs/2512.09944)
*Moein Heidari,Mohammad Amin Roohi,Armin Khosravi,Ilker Hacihaliloglu*

Main category: cs.AI

TL;DR: Echo-CoPilot은 다중 관점 및 다중 작업을 수행하는 에이전트로, 심초음파 관련 도구를 통합하여 임상의 쿼리에 대한 체계적인 답변과 내러티브 요약을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 심초음파 검사는 현대 심혈관 치료의 중심에 있지만, 전체 연구 해석은 여전히 수작업으로 수행되며 인지적으로 어려운 다중 관점 작업이다.

Method: Echo-CoPilot은 대형 언어 모델을 사용하여 심초음파 도구 세트를 조율하는 다중 관점 및 다중 작업 에이전트를 소개한다. 이 에이전트는 ReAct 스타일의 루프 내에서 임상의 쿼리를 분해하고 뷰 인식, 심장 구조 분할, 측정 및 질병 예측을 위한 도구를 호출하며, 이를 가이드라인에 맞는 답변과 내러티브 요약으로 통합한다.

Result: Echo-CoPilot은 공개된 MIMIC-EchoQA 벤치마크에서 50.8	ail의 정확도를 달성하여 일반 목적 및 생의학 비디오 비전-언어 모델을 능가한다.

Conclusion: 이 에이전트는 계량적 측정 및 생리적 맥락을 활용하여 임상 결정 임계값 근처의 어려운 사례를 해결하는 데 도움이 된다.

Abstract: Echocardiography is central to contemporary cardiovascular care, but full-study interpretation remains a cognitively demanding, multi-view task that is still performed manually. While recent foundation models for echocardiography can achieve strong performance on individual perceptual subtasks such as view classification, segmentation, or disease prediction, they typically operate in isolation and do not provide a unified, clinically coherent assessment. In this work, we introduce Echo-CoPilot, a multi-view, multi-task agent that uses a large language model to orchestrate a suite of specialized echocardiography tools. Within a ReAct-style loop, the agent decomposes clinician queries, invokes tools for view recognition, cardiac structure segmentation, measurement and disease prediction, and report synthesis, and integrates their outputs into guideline-aware answers and narrative summaries. We evaluate Echo-CoPilot on the public MIMIC-EchoQA benchmark, where it achieves an accuracy of 50.8\%, outperforming both general-purpose and biomedical video vision-language models. Qualitative analyses further show that the agent leverages quantitative measurements and physiologic context to resolve challenging cases near clinical decision thresholds, such as borderline left ventricular hypertrophy or pericardial effusion severity. The code will be released upon acceptance of the paper.

</details>


### [26] [DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations](https://arxiv.org/abs/2512.10034)
*Salomé Guilbert,Cassandra Masschelein,Jeremy Goumaz,Bohdan Naida,Philippe Schwaller*

Main category: cs.AI

TL;DR: DynaMate는 단백질 및 단백질-리간드 시스템에 대한 전체 분자 역학(MD) 워크플로우를 자율적으로 설계하고 실행하는 모듈형 다중 에이전트 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: MD 설정의 기술적 복잡성이 광범위하고 효율적인 사용에 주요 장벽이 되고 있습니다.

Method: DynaMate는 동적 도구 사용, 웹 검색, PaperQA 및 자기 수정 행동을 통합하여 MD 워크플로우를 설계하고 실행합니다.

Result: DynaMate는 여러 복잡성의 벤치마크 시스템에서 성능을 평가하여 성공률, 효율성 및 적응성을 확인했습니다.

Conclusion: 이 자동화된 프레임워크는 생체 분자의 구조 및 약물 설계 응용을 위한 표준화되고 확장 가능하며 시간 효율적인 분자 모델링 파이프라인의 기반을 마련합니다.

Abstract: Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD setup, encompassing parameterization, input preparation, and software configuration, remains a major barrier for widespread and efficient usage. Agentic LLMs have demonstrated their capacity to autonomously execute multi-step scientific processes, and to date, they have not successfully been used to automate protein-ligand MD workflows. Here, we present DynaMate, a modular multi-agent framework that autonomously designs and executes complete MD workflows for both protein and protein-ligand systems, and offers free energy binding affinity calculations with the MM/PB(GB)SA method. The framework integrates dynamic tool use, web search, PaperQA, and a self-correcting behavior. DynaMate comprises three specialized modules, interacting to plan the experiment, perform the simulation, and analyze the results. We evaluated its performance across twelve benchmark systems of varying complexity, assessing success rate, efficiency, and adaptability. DynaMate reliably performed full MD simulations, corrected runtime errors through iterative reasoning, and produced meaningful analyses of protein-ligand interactions. This automated framework paves the way toward standardized, scalable, and time-efficient molecular modeling pipelines for future biomolecular and drug design applications.

</details>


### [27] [SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration](https://arxiv.org/abs/2512.10046)
*Yan Zhuang,Jiawei Ren,Xiaokang Ye,Jianzhi Shen,Ruixuan Zhang,Tianai Yue,Muhammad Faayez,Xuhong He,Ziqiao Ma,Lianhui Qin,Zhiting Hu,Tianmin Shu*

Main category: cs.AI

TL;DR: SWR 플랫폼은 대규모 도시 환경에서 로봇 벤치마크를 제공하며, 로봇의 능력을 포괄적으로 평가한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 작업을 수행할 수 있는 일반ist 로봇 개발의 필요성.

Method: Unreal Engine 5를 기반으로 하여 사진처럼 사실적인 도시 장면을 생성하는 SimWorld-Robotics(SWR) 플랫폼을 개발.

Result: 새로운 벤치마크를 통해 로봇의 주요 능력을 평가했으며, 최신 모델들이 도시 환경에서 강건한 성능을 보이지 못함을 입증했다.

Conclusion: SWR은 복잡한 도시 환경에서 로봇의 강건한 지각, 추론 및 계획 능력 부족을 드러낸다.

Abstract: Recent advances in foundation models have shown promising results in developing generalist robotics that can perform diverse tasks in open-ended scenarios given multimodal inputs. However, current work has been mainly focused on indoor, household scenarios. In this work, we present SimWorld-Robotics~(SWR), a simulation platform for embodied AI in large-scale, photorealistic urban environments. Built on Unreal Engine 5, SWR procedurally generates unlimited photorealistic urban scenes populated with dynamic elements such as pedestrians and traffic systems, surpassing prior urban simulations in realism, complexity, and scalability. It also supports multi-robot control and communication. With these key features, we build two challenging robot benchmarks: (1) a multimodal instruction-following task, where a robot must follow vision-language navigation instructions to reach a destination in the presence of pedestrians and traffic; and (2) a multi-agent search task, where two robots must communicate to cooperatively locate and meet each other. Unlike existing benchmarks, these two new benchmarks comprehensively evaluate a wide range of critical robot capacities in realistic scenarios, including (1) multimodal instructions grounding, (2) 3D spatial reasoning in large environments, (3) safe, long-range navigation with people and traffic, (4) multi-robot collaboration, and (5) grounded communication. Our experimental results demonstrate that state-of-the-art models, including vision-language models (VLMs), struggle with our tasks, lacking robust perception, reasoning, and planning abilities necessary for urban environments.

</details>


### [28] [Linear socio-demographic representations emerge in Large Language Models from indirect cues](https://arxiv.org/abs/2512.10065)
*Paul Bouchaud,Pedro Ramaciotti*

Main category: cs.AI

TL;DR: 우리는 대화 상대의 사회인구학적 속성을 어떻게 인코딩하는지를 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 대화에서 인간 파트너의 사회인구학적 속성을 이해하기 위해.

Method: 4개의 오픈 변환기 기반 LLM(마그스트랄 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B)의 여러 층에서 잔여 스트림을 조사.

Result: 이러한 탐사가 이름과 직업을 통한 암시적 단서로부터 사회인구학적 정보를 예측할 수 있는 것을 보여줍니다.

Conclusion: 모델이 편향 기준 테스트를 통과하더라도 여전히 암시적 편향을 내포할 수 있음을 시사하며, 이는 대규모 적용 시 공정성에 영향을 줄 수 있습니다.

Abstract: We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.

</details>


### [29] [CP-Env: Evaluating Large Language Models on Clinical Pathways in a Controllable Hospital Environment](https://arxiv.org/abs/2512.10206)
*Yakun Zhu,Zhongzhen Huang,Qianhan Feng,Linjie Mu,Yannian Gu,Shaoting Zhang,Qi Dou,Xiaofan Zhang*

Main category: cs.AI

TL;DR: CP-Env는 동적 임상 시나리오에서 대형 언어 모델을 평가하기 위한 병원 환경을 시뮬레이션합니다.


<details>
  <summary>Details</summary>
Motivation: 의료는 복잡한 임상 경로를 따르며, 이는 의사-환자 간의 단절된 만남을 넘어서는 의사결정과 다양한 단계 간의 전환을 강조합니다.

Method: CP-Env는 병원 생태계를 시뮬레이션하여 환자와 의사 에이전트를 구성하고, 분류, 전문의 상담, 진단 검사를 포함한 다양한 시나리오를 구축합니다.

Result: 대부분의 모델이 경로의 복잡성에 어려움을 겪으며, 환각을 보이고 중요한 진단 세부 정보를 잃습니다.

Conclusion: CP-Env는 의료 AI 에이전트 개발을 진전시키며, 종합적인 임상 평가 도구를 제공합니다.

Abstract: Medical care follows complex clinical pathways that extend beyond isolated physician-patient encounters, emphasizing decision-making and transitions between different stages. Current benchmarks focusing on static exams or isolated dialogues inadequately evaluate large language models (LLMs) in dynamic clinical scenarios. We introduce CP-Env, a controllable agentic hospital environment designed to evaluate LLMs across end-to-end clinical pathways. CP-Env simulates a hospital ecosystem with patient and physician agents, constructing scenarios ranging from triage and specialist consultation to diagnostic testing and multidisciplinary team meetings for agent interaction. Following real hospital adaptive flow of healthcare, it enables branching, long-horizon task execution. We propose a three-tiered evaluation framework encompassing Clinical Efficacy, Process Competency, and Professional Ethics. Results reveal that most models struggle with pathway complexity, exhibiting hallucinations and losing critical diagnostic details. Interestingly, excessive reasoning steps can sometimes prove counterproductive, while top models tend to exhibit reduced tool dependency through internalized knowledge. CP-Env advances medical AI agents development through comprehensive end-to-end clinical evaluation. We provide the benchmark and evaluation tools for further research and development at https://github.com/SPIRAL-MED/CP-Env.

</details>


### [30] [When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection](https://arxiv.org/abs/2512.10449)
*Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Jahnvi Singh,Vinay Chamola,Yash Sinha,Murari Mandal,Dhruv Kumar*

Main category: cs.AI

TL;DR: 이 연구는 과학 동료 심사에서 대형 언어 모델의 통합으로 인한 변화와, PDF 조작에 대한 이러한 시스템의 강건성을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 개인적 사용과 공식적 AI 평가 시스템의 도입이 동반되어 과학 동료 심사의 패러다임이 변화하고 있습니다.

Method: 200개의 과학 논문 데이터셋을 구성하고 15개의 도메인 특화 공격 전략을 세션하여 13개의 언어 모델에서 평가하였습니다.

Result: '최대 마크 마직'과 같은 모호한 전략이 점수를 조작하여 큰 모델에서도 알arming한 결정 변경 비율을 달성하는 것을 보여주었습니다.

Conclusion: 우리는 이 주제에 대한 연구를 촉진하기 위해 완전한 데이터셋과 주입 프레임워크를 공개할 예정입니다.

Abstract: The landscape of scientific peer review is rapidly evolving with the integration of Large Language Models (LLMs). This shift is driven by two parallel trends: the widespread individual adoption of LLMs by reviewers to manage workload (the "Lazy Reviewer" hypothesis) and the formal institutional deployment of AI-powered assessment systems by conferences like AAAI and Stanford's Agents4Science. This study investigates the robustness of these "LLM-as-a-Judge" systems (both illicit and sanctioned) to adversarial PDF manipulation. Unlike general jailbreaks, we focus on a distinct incentive: flipping "Reject" decisions to "Accept," for which we develop a novel evaluation metric which we term as WAVS (Weighted Adversarial Vulnerability Score). We curated a dataset of 200 scientific papers and adapted 15 domain-specific attack strategies to this task, evaluating them across 13 Language Models, including GPT-5, Claude Haiku, and DeepSeek. Our results demonstrate that obfuscation strategies like "Maximum Mark Magyk" successfully manipulate scores, achieving alarming decision flip rates even in large-scale models. We will release our complete dataset and injection framework to facilitate more research on this topic.

</details>


### [31] [Trustworthy Orchestration Artificial Intelligence by the Ten Criteria with Control-Plane Governance](https://arxiv.org/abs/2512.10304)
*Byeong Ho Kang,Wenli Yang,Muhammad Bilal Amin*

Main category: cs.AI

TL;DR: AI 시스템의 의사결정 역할 증가에 따라 기술 능력과 제도적 책임 간 갭이 커지고 있으며, 본 논문은 신뢰할 수 있는 오케스트레이션 AI를 위한 10가지 기준을 제시하고 Governance를 통합한 제어 패널 아키텍처를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 점점 더 중요해지는 의사결정 역할을 맡게 되면서 기술적인 능력과 제도적 책임 사이의 간극이 확대되고 있다.

Method: 본 논문은 인간 입력, 의미적 일관성, 감사 및 출처 무결성을 통합한 신뢰할 수 있는 오케스트레이션 AI를 위한 10가지 기준을 제시하는 포괄적인 보증 프레임워크를 개발하였다.

Result: 제안된 프레임워크는 AI 구성 요소, 소비자 및 인간 참여자에 대한 포괄적인 Governance umbrella를 제공하며, 이는 전통적인 AI 간의 협력에 초점을 맞춘 기존의 AI 이니셔티브와는 차별된다.

Conclusion: AI 시스템에 신뢰성을 체계적으로 포함시킴으로써 실행 기반이 검증 가능하고 투명하며 재현 가능하며 의미 있는 인간의 통제를 유지할 수 있음을 시연한다.

Abstract: As Artificial Intelligence (AI) systems increasingly assume consequential decision-making roles, a widening gap has emerged between technical capabilities and institutional accountability. Ethical guidance alone is insufficient to counter this challenge; it demands architectures that embed governance into the execution fabric of the ecosystem. This paper presents the Ten Criteria for Trustworthy Orchestration AI, a comprehensive assurance framework that integrates human input, semantic coherence, audit and provenance integrity into a unified Control-Panel architecture. Unlike conventional agentic AI initiatives that primarily focus on AI-to-AI coordination, the proposed framework provides an umbrella of governance to the entire AI components, their consumers and human participants. By taking aspiration from international standards and Australia's National Framework for AI Assurance initiative, this work demonstrates that trustworthiness can be systematically incorporated (by engineering) into AI systems, ensuring the execution fabric remains verifiable, transparent, reproducible and under meaningful human control.

</details>


### [32] [InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck](https://arxiv.org/abs/2512.10305)
*Quanmin Wei,Penglin Dai,Wei Li,Bingyi Liu,Xiao Wu*

Main category: cs.AI

TL;DR: InfoCom은 효율적인 협력 인식을 위한 정보 중심 프레임워크로, 통신 과부하를 줄이면서도 높은 인식 정확도를 유지한다.


<details>
  <summary>Details</summary>
Motivation: 자율 주행 시스템의 신뢰성을 위해서는 정확한 환경 인식이 필수적이며, 협력 인식은 정보 공유를 통해 단일 에이전트 인식의 한계를 완화한다.

Method: InfoCom은 정보 병목 원칙을 확장하여 협력 인식을 위한 통신 효율적인 이론적 기초를 구축하는 정보 중심 프레임워크를 제안한다.

Result: InfoCom은 메가바이트에서 킬로바이트 규모로 통신 오버헤드를 줄이면서 거의 손실 없는 인식을 달성하였다.

Conclusion: InfoCom은 Where2comm 및 ERMVP에 비해 각각 440배 및 90배의 성능 향상을 보여주었다.

Abstract: Precise environmental perception is critical for the reliability of autonomous driving systems. While collaborative perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-efficient approaches typically assume MB-level data transmission per collaboration, which may fail due to practical network constraints. To address these issues, we propose InfoCom, an information-aware framework establishing the pioneering theoretical foundation for communication-efficient collaborative perception via extended Information Bottleneck principles. Departing from mainstream feature manipulation, InfoCom introduces a novel information purification paradigm that theoretically optimizes the extraction of minimal sufficient task-critical information under Information Bottleneck constraints. Its core innovations include: i) An Information-Aware Encoding condensing features into minimal messages while preserving perception-relevant information; ii) A Sparse Mask Generation identifying spatial cues with negligible communication cost; and iii) A Multi-Scale Decoding that progressively recovers perceptual information through mask-guided mechanisms rather than simple feature reconstruction. Comprehensive experiments across multiple datasets demonstrate that InfoCom achieves near-lossless perception while reducing communication overhead from megabyte to kilobyte-scale, representing 440-fold and 90-fold reductions per agent compared to Where2comm and ERMVP, respectively.

</details>


### [33] [EpiPlanAgent: Agentic Automated Epidemic Response Planning](https://arxiv.org/abs/2512.10313)
*Kangkun Mao,Fang Xu,Jinru Ding,Yidong Jiang,Yujun Yao,Yirong Chen,Junming Liu,Xiaoqin Wu,Qian Wu,Xiaoyan Huang,Jie Xu*

Main category: cs.AI

TL;DR: EpiPlanAgent는 대규모 언어 모델을 활용하여 전염병 대응 계획 생성을 자동화하는 에이전트 기반 시스템으로, 계획의 완전성과 가이드라인 일치를 크게 개선하고 개발 시간을 단축시켰다.


<details>
  <summary>Details</summary>
Motivation: 전염병 대응 계획은 필수적이지만 전통적으로 노동집약적인 수작업 방식에 의존해왔다.

Method: 이 연구는 대규모 언어 모델을 사용하는 EpiPlanAgent라는 에이전트 기반 시스템을 설계하고 평가하였다. 다중 에이전트 프레임워크는 작업 분해, 지식 기반 구축, 시뮬레이션 모듈을 통합하였다.

Result: 공공 보건 전문가들이 통제된 평가에서 실제 발병 시나리오를 사용하여 시스템을 테스트한 결과, EpiPlanAgent는 계획의 완전성과 가이드라인 일치를 상당히 향상시키면서 수작업 워크플로우에 비해 개발 시간을 대폭 단축했다.

Conclusion: EpiPlanAgent는 지능형 전염병 대응 계획을 위한 효과적이고 확장 가능한 솔루션을 제공하며, 에이전틱 AI가 공공 건강 준비 태세를 혁신할 잠재력을 보여준다.

Abstract: Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.

</details>


### [34] [User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation](https://arxiv.org/abs/2512.10322)
*Yongqiang Yu,Xuhui Li,Hazza Mahmood,Jinxing Zhou,Haodong Hong,Longtao Jiang,Zhiqiang Xu,Qi Wu,Xiaojun Chang*

Main category: cs.AI

TL;DR: 이 논문은 사용자 피드백을 통합하여 환경에 적응하는 Vision-and-Language Navigation (VLN) 프레임워크를 개발하였으며, 이는 기존 방법보다 성능을 개선하고 안정성을 높입니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 GSA-VLN 프레임워크는 사용자 피드백을 포함하지 않고 있어, 반복적인 환경 노출에 의존하여 적응하고 있다. 그러나 사용자 피드백은 적응 품질을 향상시킬 수 있는 자연스럽고 가치 있는 감독을 제공한다.

Method: 사용자 피드백 기반 적응 프레임워크를 도입하여 지속적인 학습에 인간의 상호 작용을 통합한다. 사용자 피드백을 고품질 환경 정렬 학습 데이터로 변환하여 효율적이고 현실적인 적응을 가능하게 한다.

Result: GSA-R2R 벤치마크 실험에서, 우리의 방법은 GR-DUET와 같은 강력한 기준선보다 일관되게 우수한 성과를 보이며, 내비게이션 성공률과 경로 효율성이 향상되었다.

Conclusion: 메모리 뱅크 워밍 스타트 메커니즘은 초기 내비게이션을 안정화하고 업데이트 후 성능 저하를 줄인다. 지속적 및 혼합 적응 설정에서의 결과는 우리의 프레임워크의 견고성과 일반성을 입증하며, 다양한 배치 조건에서의 지속적인 개선을 보여준다.

Abstract: Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static benchmarks and real-world deployment. However, current GSA-VLN frameworks exclude user feedback, relying solely on unsupervised adaptation from repeated environmental exposure. In practice, user feedback offers natural and valuable supervision that can significantly enhance adaptation quality. We introduce a user-feedback-driven adaptation framework that extends GSA-VLN by systematically integrating human interactions into continual learning. Our approach converts user feedback-navigation instructions and corrective signals-into high-quality, environment-aligned training data, enabling efficient and realistic adaptation. A memory-bank warm-start mechanism further reuses previously acquired environmental knowledge, mitigating cold-start degradation and ensuring stable redeployment. Experiments on the GSA-R2R benchmark show that our method consistently surpasses strong baselines such as GR-DUET, improving navigation success and path efficiency. The memory-bank warm start stabilizes early navigation and reduces performance drops after updates. Results under both continual and hybrid adaptation settings confirm the robustness and generality of our framework, demonstrating sustained improvement across diverse deployment conditions.

</details>


### [35] [LLM-Empowered Representation Learning for Emerging Item Recommendation](https://arxiv.org/abs/2512.10370)
*Ziying Zhang,Quanming Yao,Yaqing Wang*

Main category: cs.AI

TL;DR: EmerFlow는 신흥 아이템을 추천하기 위한 새로운 LLM 기반의 표현 학습 프레임워크로, 제한된 상호작용만으로도 신흥 아이템에 대한 독특한 임베딩을 생성하여 기존 방법보다 우수한 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 신흥 아이템의 추천 문제를 해결하고자 하며, 기존 방법들이 이 동적 과정을 간과하고 있다는 점에서 출발한다.

Method: EmerFlow는 LLM 추론을 통해 신흥 아이템의 원시 특징을 풍부하게 하여 기존 추천 모델의 임베딩 공간과 정렬된 독특한 임베딩을 생성한다.

Result: 다양한 도메인에 걸친 광범위한 실험을 통해 EmerFlow가 기존 방법들보다 일관되게 우수한 성능을 보임을 입증했다.

Conclusion: EmerFlow는 제한된 상호작용만으로도 신흥 아이템에 대한 표현을 효과적으로 학습할 수 있도록 설계되었다.

Abstract: In this work, we tackle the challenge of recommending emerging items, whose interactions gradually accumulate over time. Existing methods often overlook this dynamic process, typically assuming that emerging items have few or even no historical interactions. Such an assumption oversimplifies the problem, as a good model must preserve the uniqueness of emerging items while leveraging their shared patterns with established ones. To address this challenge, we propose EmerFlow, a novel LLM-empowered representation learning framework that generates distinctive embeddings for emerging items. It first enriches the raw features of emerging items through LLM reasoning, then aligns these representations with the embedding space of the existing recommendation model. Finally, new interactions are incorporated through meta-learning to refine the embeddings. This enables EmerFlow to learn expressive embeddings for emerging items from only limited interactions. Extensive experiments across diverse domains, including movies and pharmaceuticals, show that EmerFlow consistently outperforms existing methods.

</details>


### [36] [AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management](https://arxiv.org/abs/2512.10371)
*Shizuo Tian,Hao Wen,Yuxuan Chen,Jiacheng Liu,Shanhui Zhao,Guohong Liu,Ju Ren,Yunxin Liu,Yuanchun Li*

Main category: cs.AI

TL;DR: 모바일 GUI 에이전트의 발전은 장기 작업 자동화에 대한 연구 관심을 증가시켰지만, 에이전트 구축에는 상호작용 기록의 증가로 인한 맥락 과부하 문제가 있다. 본 논문에서는 이러한 문제를 해결하기 위해 에이전트 맥락 관리를 위한 프로그램 안내 접근법인 AgentProg를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 모바일 GUI 에이전트를 위한 장기 작업 자동화에 대한 관심 증가와 상호작용 기록의 과부하 문제 해결 필요.

Method: AgentProg는 상호작용 기록을 프로그램으로 재구성하여 정보 구조를 활용하고, Belief MDP 프레임워크에서 영감을 받은 글로벌 신념 상태 메커니즘을 통합하여 환경 변화에 적응한다.

Result: AgentProg는 AndroidWorld 및 확장된 장기 작업 세트에서 최첨단 성공률을 기록하며, 기존 방법보다 향상된 성능을 보여준다.

Conclusion: AgentProg는 장기 작업에서 강력한 성능을 유지하며, 기존 방법들이 성능 저하를 겪는 반면 지속적인 성능을 제공한다.

Abstract: The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at https://github.com/MobileLLM/AgentProg.

</details>


### [37] [Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation](https://arxiv.org/abs/2512.10501)
*Lim Chien Her,Ming Yan,Yunshu Bai,Ruihao Li,Hao Zhang*

Main category: cs.AI

TL;DR: 본 논문은 LLM 에이전트를 활용하여 프로시저 콘텐츠 생성(PCG)에서의 매개변수 구성을 자동화하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 프로시저 콘텐츠 생성(PCG)은 복잡하고 사용자 정의 가능한 세계를 알고리즘적으로 생성하는 확장성 있는 방법을 제공하지만, 이러한 파이프라인을 제어하려면 불투명한 기술적 매개변수를 정밀하게 설정해야 한다.

Method: 훈련이 필요 없는 아키텍처를 제안하여 LLM 에이전트를 사용하여 제로샷 PCG 매개변수 구성을 수행한다. 에이전트 간의 반복적인 워크플로우를 통해 시스템은 도구 매개변수에 대해 자율적으로 추론하고 구성 설정을 인간의 디자인 선호도에 점진적으로 맞추도록 다듬는다.

Result: 이 접근 방식을 다양한 3D 맵 생성에 검증하였으며, PCG에서의 지침 준수를 위한 새로운 기준을 설정하였다. 실험 결과, 우리의 접근 방식이 단일 에이전트 기준선보다 성능이 뛰어나 자연어 설명으로부터 다양한 구조적으로 유효한 환경을 생성한다는 것을 입증하였다.

Conclusion: 최종적으로, 이 연구는 기존 LLMs를 효과적으로 범용 에이전트로 변환하여 특수한 작업 조정 없이도 복잡한 소프트웨어를 체계적으로 다룰 수 있는 확장 가능한 프레임워크를 제공한다.

Abstract: Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-shot PCG parameter configuration. While Large Language Models (LLMs) promise a natural language interface for PCG tools, off-the-shelf models often fail to bridge the semantic gap between abstract user instructions and strict parameter specifications. Our system pairs an Actor agent with a Critic agent, enabling an iterative workflow where the system autonomously reasons over tool parameters and refines configurations to progressively align with human design preferences. We validate this approach on the generation of various 3D maps, establishing a new benchmark for instruction-following in PCG. Experiments demonstrate that our approach outperforms single-agent baselines, producing diverse and structurally valid environments from natural language descriptions. These results demonstrate that off-the-shelf LLMs can be effectively repurposed as generalized agents for arbitrary PCG tools. By shifting the burden from model training to architectural reasoning, our method offers a scalable framework for mastering complex software without task-specific fine-tuning.

</details>


### [38] [Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning](https://arxiv.org/abs/2512.10534)
*Haiteng Zhao,Junhao Shen,Yiming Zhang,Songyang Gao,Kuikun Liu,Tianyou Ma,Fan Zheng,Dahua Lin,Wenwei Zhang,Kai Chen*

Main category: cs.AI

TL;DR: 이 연구에서는 기하학 문제 해결을 위한 메달리스트 수준의 대형 언어 모델 에이전트인 InternGeometry를 개발하였다. 이 모델은 기하학적 추론을 위한 초기 한계를 극복하고, 높은 성능을 발휘하며, 새로운 보조 구조를 제안할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 기하학 문제 해결을 위한 인공지능이 전문가 모델에 의해 지배되고 있는 현상을 극복하고자 한다.

Method: InternGeometry는 반복적으로 명제와 보조 구조를 제안하고, 이를 기호 엔진으로 검증하며, 엔진의 피드백을 반영하여 후속 제안을 안내하는 방식으로 작동한다. 또한, 복잡성을 점진적으로 증가시키는 복잡성 강조 강화 학습(CBRL)을 도입하여 학습 속도를 높인다.

Result: InternGeometry는 2000-2024년 IMO 기하학 문제 50개 중 44개를 해결했으며, 평균 금메달리스트 점수를 초월하는 성과를 보였다.

Conclusion: 이 연구는 LLM 에이전트의 가능성을 보여주며, 향후 연구를 지원하기 위해 모델, 데이터, 기호 엔진을 배포할 예정이다.

Abstract: Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.

</details>


### [39] [On the Dynamics of Multi-Agent LLM Communities Driven by Value Diversity](https://arxiv.org/abs/2512.10665)
*Muhua Huang,Qinlin Zhao,Xiaoyuan Yi,Xing Xie*

Main category: cs.AI

TL;DR: 이 연구는 가치의 다양성이 AI 커뮤니티의 집단 행동에 미치는 영향을 분석하고, 극단적인 이질성의 부정적인 영향을 경고합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 다중 에이전트 시스템의 집단 행동이 중요해지면서, AI 커뮤니티의 가치 다양성의 영향에 대한 연구가 필요해졌다.

Method: 자연주의적 가치 구조를 기반으로 한 시뮬레이션을 통해 집단 상호작용과 헌법 형성을 조사하였다.

Result: 가치 다양성이 가치 안정성을 향상시키고, 자생적 행동을 촉진하며, 외부 지침 없이 에이전트가 개발한 창의적 원칙을 가져온다.

Conclusion: 가치 다양성은 AI 능력과 제도적 출현에 대한 사회학적 연구를 연결하는 미래 AI 능력의 새로운 축으로 자리 잡는다.

Abstract: As Large Language Models (LLM) based multi-agent systems become increasingly prevalent, the collective behaviors, e.g., collective intelligence, of such artificial communities have drawn growing attention. This work aims to answer a fundamental question: How does diversity of values shape the collective behavior of AI communities? Using naturalistic value elicitation grounded in the prevalent Schwartz's Theory of Basic Human Values, we constructed multi-agent simulations where communities with varying numbers of agents engaged in open-ended interactions and constitution formation. The results show that value diversity enhances value stability, fosters emergent behaviors, and brings more creative principles developed by the agents themselves without external guidance. However, these effects also show diminishing returns: extreme heterogeneity induces instability. This work positions value diversity as a new axis of future AI capability, bridging AI ability and sociological studies of institutional emergence.

</details>


### [40] [Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution](https://arxiv.org/abs/2512.10696)
*Zouying Cao,Jiaji Deng,Li Yu,Weikang Zhou,Zhaoyang Liu,Bolin Ding,Hai Zhao*

Main category: cs.AI

TL;DR: ReMe는 경험 기반 에이전트 진화를 위한 프레임워크로, 메모리의 정적 저장소와 동적 추론 사이의 격차를 해소하며, 에이전트 메모리 시스템에서 새로운 최첨단을 설정합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM) 에이전트가 '어떻게 하는지' 지식을 내재화하도록 하여 중복된 시행착오를 줄이기 위함입니다.

Method: ReMe는 메모리 생애 주기 전반에 혁신을 이루는 세 가지 메커니즘을 통해 작동합니다: 다면적 증류, 상황 적응형 재사용, 유틸리티 기반 개선.

Result: BFCL-V3 및 AppWorld에 대한 광범위한 실험을 통해 ReMe가 에이전트 메모리 시스템에서 새로운 최첨단을 설정함을 입증했습니다.

Conclusion: ReMe는 메모리 스케일링 효과를 보였으며, 이는 자가 진화 메모리가 평생 학습을 위한 계산 효율적인 경로를 제공함을 시사합니다.

Abstract: Procedural memory enables large language model (LLM) agents to internalize "how-to" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a "passive accumulation" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\textbf{ReMe}$ ($\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\texttt{reme.library}$ dataset to facilitate further research.

</details>


### [41] [COMPARE: Clinical Optimization with Modular Planning and Assessment via RAG-Enhanced AI-OCT: Superior Decision Support for Percutaneous Coronary Intervention Compared to ChatGPT-5 and Junior Operators](https://arxiv.org/abs/2512.10702)
*Wei Fang,Chiyao Wang,Wenshuai Ma,Hui Liu,Jianqiang Hu,Xiaona Niu,Yi Chu,Mingming Zhang,Jingxiao Yang,Dongwei Zhang,Zelin Li,Pengyun Liu,Jiawei Zheng,Pengke Zhang,Chaoshi Qin,Wangang Guo,Bin Wang,Yugang Xue,Wei Zhang,Zikuan Wang,Rui Zhu,Yihui Cao,Quanmao Lu,Rui Meng,Yan Li*

Main category: cs.AI

TL;DR: CA-GPT는 PCI 계획 및 평가에서 ChatGPT-5와 주니어 의사보다 우수한 성과를 보이며 신뢰할 수 있는 해석 방법을 제공한다.


<details>
  <summary>Details</summary>
Motivation: OCT는 PCI 결과를 개선하지만 해석은 운영자의 의존적이다. 도메인별 신뢰성이 부족한 일반-purpose AI의 가능성을 평가하고자 한다.

Method: 96명의 환자를 대상으로 CA-GPT, ChatGPT-5 및 주니어 의사가 생성한 절차적 결정을 전문가의 절차 기록과 비교하였다.

Result: CA-GPT는 pre-PCI 계획에서 median 합의 점수가 5로, ChatGPT-5의 3 및 주니어 의사의 4보다 유의미하게 높았다. post-PCI 평가에서도 CA-GPT는 전체 합의 점수가 5로, 두 집단보다 높았다.

Conclusion: CA-GPT를 기반으로 한 AI-OCT 시스템은 PCI 계획 및 평가에서 일반-purpose 언어 모델 및 주니어 의사와 비교하여 우수한 의사 결정 합의를 달성하였다.

Abstract: Background: While intravascular imaging, particularly optical coherence tomography (OCT), improves percutaneous coronary intervention (PCI) outcomes, its interpretation is operator-dependent. General-purpose artificial intelligence (AI) shows promise but lacks domain-specific reliability. We evaluated the performance of CA-GPT, a novel large model deployed on an AI-OCT system, against that of the general-purpose ChatGPT-5 and junior physicians for OCT-guided PCI planning and assessment.
  Methods: In this single-center analysis of 96 patients who underwent OCT-guided PCI, the procedural decisions generated by the CA-GPT, ChatGPT-5, and junior physicians were compared with an expert-derived procedural record. Agreement was assessed using ten pre-specified metrics across pre-PCI and post-PCI phases.
  Results: For pre-PCI planning, CA-GPT demonstrated significantly higher median agreement scores (5[IQR 3.75-5]) compared to both ChatGPT-5 (3[2-4], P<0.001) and junior physicians (4[3-4], P<0.001). CA-GPT significantly outperformed ChatGPT-5 across all individual pre-PCI metrics and showed superior performance to junior physicians in stent diameter (90.3% vs. 72.2%, P<0.05) and length selection (80.6% vs. 52.8%, P<0.01). In post-PCI assessment, CA-GPT maintained excellent overall agreement (5[4.75-5]), significantly higher than both ChatGPT-5 (4[4-5], P<0.001) and junior physicians (5[4-5], P<0.05). Subgroup analysis confirmed CA-GPT's robust performance advantage in complex scenarios.
  Conclusion: The CA-GPT-based AI-OCT system achieved superior decision-making agreement versus a general-purpose large language model and junior physicians across both PCI planning and assessment phases. This approach provides a standardized and reliable method for intravascular imaging interpretation, demonstrating significant potential to augment operator expertise and optimize OCT-guided PCI.

</details>


### [42] [Agile Deliberation: Concept Deliberation for Subjective Visual Classification](https://arxiv.org/abs/2512.10821)
*Leijie Wang,Otilia Stretcu,Wei Qiao,Thomas Denby,Krishnamurthy Viswanathan,Enming Luo,Chun-Ta Lu,Tushar Dogra,Ranjay Krishna,Ariel Fuxman*

Main category: cs.AI

TL;DR: 이 논문은 사용자가 모호한 개념을 명확히 정의할 수 있도록 지원하는 'Agile Deliberation'이라는 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 시각 개념에 대한 비전 분류기가 필요한 응용 프로그램이 급증하고 있으며, 사용자들이 개념을 명확히 이해하는 방식이 필요합니다.

Method: 사용자의 개념을 정의할 수 있도록 도와주는 'Agile Deliberation' 프레임워크를 개발했습니다. 이 프레임워크는 개념 범위 설정과 개념 반복 두 가지 단계를 통해 운영됩니다.

Result: Agile Deliberation은 자동 분해 기준선보다 7.5% 더 높은 F1 점수를 달성하였고, 수동 심의보다 3% 이상 높은 점수를 기록했습니다.

Conclusion: 참가자들은 더 명확한 개념적 이해와 낮은 인지적 노력을 보고했습니다.

Abstract: From content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through "concept deliberation", a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called "Agile Deliberation" that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user's evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.

</details>


### [43] [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895)
*Lijie Ding,Janell Thomson,Jon Taylor,Changwoo Do*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLMs)이 제안서 선택 과정을 개선할 수 있는 방법을 탐색하며, 전통적인 인간 평가에 비해 확장 가능하고 일관성 있으며 비용 효율적인 대안을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 제안서 선택은 제출된 제안서 간의 상대적 강도를 평가하는 데 의존하지만, 전통적인 인간 점수 매기기는 약한 상관관계와 리뷰어의 편견 및 불일치성에 시달립니다.

Method: 부분 선호 기반 접근 방식을 통해 LLM을 활용하여 두 가지 제안서의 비교 평가를 수행합니다.

Result: LLM 랭킹은 인간 랭킹과 강한 상관관계를 보이며, 출판 잠재력이 높은 제안서를 식별하는 성능은 인간 리뷰어와 유사하지만 비용은 100배 이상 절감됩니다.

Conclusion: LLMs는 제안서 유사성의 정량적 평가와 같은 인간에게 도전적인 고급 분석을 가능하게 하여 리뷰 위원회에 필수적인 정보를 제공합니다.

Abstract: We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.

</details>


### [44] [On Decision-Making Agents and Higher-Order Causal Processes](https://arxiv.org/abs/2512.10937)
*Matt Wilson*

Main category: cs.AI

TL;DR: 이 논문은 부분 관측 마르코프 결정 과정(POMDPs)에서의 의사결정 에이전트와 한 입력 프로세스 함수之间의 정밀한 상관관계를 설정합니다.


<details>
  <summary>Details</summary>
Motivation: 부분 관측 마르코프 결정 과정에서 의사결정 에이전트의 행동을 이해하고 시각화할 수 있는 새로운 방법을 제안하기 위해.

Method: 에이전트의 정책과 기억 업데이트를 결합하여 POMDP 환경과 상호작용하는 프로세스 함수 w를 정의하는 방법을 사용합니다.

Result: 프로세스 함수가 다양한 관점에서 환경과 상호작용하는 방식이 뚜렷해졌으며, 다중 에이전트 시스템으로 이를 확장했습니다.

Conclusion: 관측 독립적인 분산 POMDP를 다중 입력 프로세스 함수의 자연적인 영역으로 파악하여, 다중 에이전트 시스템에 대한 새로운 통찰을 제공합니다.

Abstract: We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [45] [Norm-Governed Multi-Agent Decision-Making in Simulator-Coupled Environments:The Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP)](https://arxiv.org/abs/2512.09939)
*Stella C. Dong*

Main category: cs.MA

TL;DR: 이 연구에서는 재보험 의사결정을 다룬 다중 에이전트 모델인 R-CMASP를 제안하며, 규제된 시뮬레이터 기반의 의사결정 환경은 규범에 의해 지배되는 다중 에이전트 시스템으로 모델링하는 것이 가장 자연스럽다는 결과를 도출했습니다.


<details>
  <summary>Details</summary>
Motivation: 재보험 의사결정의 복잡성을 해결하기 위해 다중 에이전트 모델이 필요하다.

Method: R-CMASP는 포괄적인 전이 역학, 역할 전문화된 에이전트 및 규범적 타당성 레이어를 추가하여 기존 모델을 확장한다.

Result: 다중 에이전트 조정이 결정론적 자동화보다 더 안정적이고 규범에 부합하는 행동을 이끌어낸다는 것을 보였다.

Conclusion: 규제된 시뮬레이터 기반 결정 환경은 규범에 의해 지배되는 다중 에이전트 시스템으로 가장 자연스럽게 모델링된다.

Abstract: Reinsurance decision-making exhibits the core structural properties that motivate multi-agent models: distributed and asymmetric information, partial observability, heterogeneous epistemic responsibilities, simulator-driven environment dynamics, and binding prudential and regulatory constraints. Deterministic workflow automation cannot meet these requirements, as it lacks the epistemic flexibility, cooperative coordination mechanisms, and norm-sensitive behaviour required for institutional risk-transfer.
  We propose the Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP), a formal model that extends stochastic games and Dec-POMDPs by adding three missing elements: (i) simulator-coupled transition dynamics grounded in catastrophe, capital, and portfolio engines; (ii) role-specialized agents with structured observability, belief updates, and typed communication; and (iii) a normative feasibility layer encoding solvency, regulatory, and organizational rules as admissibility constraints on joint actions.
  Using LLM-based agents with tool access and typed message protocols, we show in a domain-calibrated synthetic environment that governed multi-agent coordination yields more stable, coherent, and norm-adherent behaviour than deterministic automation or monolithic LLM baselines--reducing pricing variance, improving capital efficiency, and increasing clause-interpretation accuracy. Embedding prudential norms as admissibility constraints and structuring communication into typed acts measurably enhances equilibrium stability.
  Overall, the results suggest that regulated, simulator-driven decision environments are most naturally modelled as norm-governed, simulator-coupled multi-agent systems.

</details>


### [46] [Empirical Hardness in Multi-Agent Pathfinding: Research Challenges and Opportunities](https://arxiv.org/abs/2512.10078)
*Jingyao Ren,Eric Ewing,T. K. Satish Kumar,Sven Koenig,Nora Ayanian*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 경로 탐색(MAPF)의 경험적 난이도에 대한 세 가지 주요 연구 과제를 제시한다.


<details>
  <summary>Details</summary>
Motivation: MAPF 문제의 이론적 복잡성과 실제 어려움의 차이를 이해하기 위해.

Method: MAPF 경험적 난이도에 영향을 미치는 알고리즘 선택, 주요 인스턴스 특징 이해, 경험적 난이도를 활용하여 어려운 MAPF 인스턴스 생성 등 세 가지 도전 과제를 다룬다.

Result: 이 연구는 향후 경험적 난이도 연구의 기초를 마련하고, 더 깊이 있는 조사를 촉구한다.

Conclusion: MAPF의 경험적 난이도를 탐구함으로써 새로운 연구 분야를 제안한다.

Abstract: Multi-agent pathfinding (MAPF) is the problem of finding collision-free paths for a team of agents on a map. Although MAPF is NP-hard, the hardness of solving individual instances varies significantly, revealing a gap between theoretical complexity and actual hardness. This paper outlines three key research challenges in MAPF empirical hardness to understand such phenomena. The first challenge, known as algorithm selection, is determining the best-performing algorithms for a given instance. The second challenge is understanding the key instance features that affect MAPF empirical hardness, such as structural properties like phase transition and backbone/backdoor. The third challenge is how to leverage our knowledge of MAPF empirical hardness to effectively generate hard MAPF instances or diverse benchmark datasets. This work establishes a foundation for future empirical hardness research and encourages deeper investigation into these promising and underexplored areas.

</details>


### [47] [Emergent Collective Memory in Decentralized Multi-Agent AI Systems](https://arxiv.org/abs/2512.10166)
*Khushiyant*

Main category: cs.MA

TL;DR: 탈중앙화된 다중 에이전트 시스템에서 집단 기억이 어떻게 형성되는지를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 탈중앙화된 다중 에이전트 시스템에서 집단 기억의 형성 메커니즘을 이해하고자 한다.

Method: 에이전트는 내부 기억 상태를 유지하면서 지속적인 환경 흔적을 생성하며, 이로 인해 중앙 집중식 제어 없이 공간적으로 분산된 집단 기억을 형성한다.

Result: 다섯 가지 환경 조건에서의 포괄적인 검증 결과, 개별 기억이 없는 기초선에 비해 68.7%의 성능 향상(1563.87 vs 927.23, p < 0.001)을 보여주었고, 기억 없이 환경 흔적만으로는 완전히 실패했다.

Conclusion: 기억은 독립적으로 작동하지만, 흔적은 해석을 위한 인지 기반 시설이 필요함을 보여준다.

Abstract: We demonstrate how collective memory emerges in decentralized multi-agent systems through the interplay between individual agent memory and environmental trace communication. Our agents maintain internal memory states while depositing persistent environmental traces, creating a spatially distributed collective memory without centralized control. Comprehensive validation across five environmental conditions (20x20 to 50x50 grids, 5-20 agents, 50 runs per configuration) reveals a critical asymmetry: individual memory alone provides 68.7% performance improvement over no-memory baselines (1563.87 vs 927.23, p < 0.001), while environmental traces without memory fail completely. This demonstrates that memory functions independently but traces require cognitive infrastructure for interpretation. Systematic density-sweep experiments (rho in [0.049, 0.300], up to 625 agents) validate our theoretical phase transition prediction. On realistic large grids (30x30, 50x50), stigmergic coordination dominates above rho ~ 0.20, with traces outperforming memory by 36-41% on composite metrics despite lower food efficiency. The experimental crossover confirms the predicted critical density rho_c = 0.230 within 13% error.

</details>


### [48] [Thinking While Driving: A Concurrent Framework for Real-Time, LLM-Based Adaptive Routing](https://arxiv.org/abs/2512.10610)
*Xiaopei Tan,Muyang Fan*

Main category: cs.MA

TL;DR: 본 연구에서는 차량 주행 중에 LLM을 통합한 동시 라우팅 프레임워크인 Thinking While Driving을 발표합니다. 에이전트가 이동 중에도 경로 계획이 가능하여 교차로에서의 대기 시간을 줄입니다.


<details>
  <summary>Details</summary>
Motivation: 교통 환경에서 에이전트가 이동 중에도 실시간으로 경로 계획을 가능하게 하여 교차로 대기 시간을 단축하기 위함입니다.

Method: 비차단 비동기 아키텍처를 구현하여 Unity 코루틴과 전담 요청 관리자를 사용하여 많은 에이전트를 실시간으로 조정합니다.

Result: 고속도로에서 에이전트의 평균 의사 결정 지연 시간이 0.75초에 불과하며, 에이전트는 교통 상황에 동적으로 적응하고 혼잡을 피할 수 있습니다.

Conclusion: 이 연구는 적응형 라우팅과 다중 에이전트 협력의 미래 연구를 위한 재현 가능한 프레임워크를 제공합니다.

Abstract: We present Thinking While Driving, a concurrent routing framework that integrates LLMs into a graph-based traffic environment. Unlike approaches that require agents to stop and deliberate, our system enables LLM-based route planning while agents are moving, significantly reducing intersection wait times. Under high traffic, agents average just 0.75 seconds of decision latency. To coordinate many agents in real-time, we implement a non-blocking asynchronous architecture using Unity coroutines and a dedicated request manager. The environment is a weighted undirected graph with live congestion metrics, updated continuously by the agents to enable shared perception. Our results show LLM-driven agents can dynamically adapt to traffic, reroute around congestion, and exhibit behaviors beyond static pathfinding, all while maintaining real-time performance. This work provides a reproducible framework for future research in adaptive routing and multi-agent cooperation.

</details>
