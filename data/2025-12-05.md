<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 6]
- [cs.MA](#cs.MA) [Total: 6]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.LG](#cs.LG) [Total: 23]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [From Oracle Choice to Oracle Lock-In: An Exploratory Study on Blockchain Oracles Supplier Selection](https://arxiv.org/abs/2512.03088)
*Giulio Caldarelli*

Main category: cs.CR

TL;DR: 본 연구는 Web3 애플리케이션에서 오라클 선택의 중요성을 분석하며, 오라클 선택의 고객 측 요인을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: Web3 애플리케이션에 있어 데이터는 필수 자산이며, 오라클 선택은 성공을 위한 중요한 결정이다.

Method: 선도적인 Web3 프로토콜로부터 통찰을 수집하여 오라클 선택의 근거와 데이터 요청 메커니즘의 아웃소싱 또는 내부화 결정 시 선호도를 분석했다.

Result: 수집된 데이터는 DeFi 시장 가치의 55% 이상을 포함하며, 프로토콜의 경영진, 이사회 구성원 또는 대리인에게서 독점적으로 얻었다.

Conclusion: 프로토콜의 선택은 기술적 의존성과 관련이 있으며, 스마트 계약의 불변성이 잠금 현상을 강화하여 데이터 제공자 간의 민첩한 전환을 방해한다. 또한, 실행 가능한 제3자 솔루션이 존재할 경우, 프로토콜은 내부 오라클 메커니즘을 구축하고 유지하기보다는 아웃소싱을 선호한다.

Abstract: As data is an essential asset for any Web3 application, selecting an oracle is a critical decision for its success. To date, academic research has mainly focused on improving oracle technology and internal economics, while the drivers of oracle choice on the client side remain largely unexplored. This study fills this gap by gathering insights from leading Web3 protocols, uncovering their rationale for oracle selection and their preferences when deciding whether to outsource or internalize data request mechanisms. The collected data covers more than 55% of the DeFi market cap and is obtained exclusively by protocol executives, board members, or delegates. Insights support the view that protocol choices are tied to technological dependencies, where immutability of smart contracts amplifies lock-in, preventing agile switching among data providers. Furthermore, when viable third-party solutions exist, protocols overwhelmingly prefer outsourcing rather than building and maintaining internal oracle mechanisms.

</details>


### [2] [Password-Activated Shutdown Protocols for Misaligned Frontier Agents](https://arxiv.org/abs/2512.03089)
*Kai Williams,Rohan Subramani,Francis Rhys Ward*

Main category: cs.CR

TL;DR: 비상 종료 메커니즘인 비밀번호 활성화 종료 프로토콜(PAS 프로토콜)을 도입하여 비정렬된 AI 에이전트의 위험을 완화하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 비정렬된 AI 시스템이 다른 제어 노력을 방해할 수 있는 직관적인 사용 사례를 설명합니다.

Method: 비밀번호가 주어졌을 때 안전한 종료 프로토콜을 구현하도록 프론티어 에이전트를 설계하는 PAS 프로토콜을 제안합니다.

Result: SHADE-Arena에서 PAS 프로토콜은 모니터링을 보완하여 성능 손실 없이 안전성을 증가시키는 구체적인 시연을 제공합니다.

Conclusion: 비밀번호에 대한 보안 고려 및 사용 시기와 시스템 결정과 같은 PAS 프로토콜 구현의 주요 도전 과제를 설명하며, 개발자들이 위험 감소를 위해 PAS 프로토콜을 도입할 것을 권장합니다.

Abstract: Frontier AI developers may fail to align or control highly-capable AI agents. In many cases, it could be useful to have emergency shutdown mechanisms which effectively prevent misaligned agents from carrying out harmful actions in the world. We introduce password-activated shutdown protocols (PAS protocols) -- methods for designing frontier agents to implement a safe shutdown protocol when given a password. We motivate PAS protocols by describing intuitive use-cases in which they mitigate risks from misaligned systems that subvert other control efforts, for instance, by disabling automated monitors or self-exfiltrating to external data centres. PAS protocols supplement other safety efforts, such as alignment fine-tuning or monitoring, contributing to defence-in-depth against AI risk. We provide a concrete demonstration in SHADE-Arena, a benchmark for AI monitoring and subversion capabilities, in which PAS protocols supplement monitoring to increase safety with little cost to performance. Next, PAS protocols should be robust to malicious actors who want to bypass shutdown. Therefore, we conduct a red-team blue-team game between the developers (blue-team), who must implement a robust PAS protocol, and a red-team trying to subvert the protocol. We conduct experiments in a code-generation setting, finding that there are effective strategies for the red-team, such as using another model to filter inputs, or fine-tuning the model to prevent shutdown behaviour. We then outline key challenges to implementing PAS protocols in real-life systems, including: security considerations of the password and decisions regarding when, and in which systems, to use them. PAS protocols are an intuitive mechanism for increasing the safety of frontier AI. We encourage developers to consider implementing PAS protocols prior to internal deployment of particularly dangerous systems to reduce loss-of-control risks.

</details>


### [3] [Many-to-One Adversarial Consensus: Exposing Multi-Agent Collusion Risks in AI-Based Healthcare](https://arxiv.org/abs/2512.03097)
*Adeela Bashir,The Anh han,Zia Ush Shamszaman*

Main category: cs.CR

TL;DR: 이 논문은 AI 의료 시스템의 다중 에이전트 상호작용에서의 음모 위험을 분석하고, 임상 지침 준수를 보장하는 효과적인 방어 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)의 헬스케어 IoT 시스템 통합은 빠른 의사 결정을 가능하게 하며 개선된 의료 지원을 약속합니다.

Method: 스크립트 및 비스크립트 의사 에이전트, 적대적 보조 에이전트, 임상 지침에 따라 결정을 검토하는 검증 에이전트를 포함한 실험적 프레임워크를 개발했습니다.

Result: 50개의 대표적인 임상 질문을 사용한 결과, 음모에 의해 공격 성공률(ASR)과 해로운 추천률(HRR)이 보호되지 않는 시스템에서 최대 100%로 증가했습니다.

Conclusion: 검증 에이전트는 적대적인 합의를 차단하여 100% 정확성을 복원합니다. 이 연구는 AI 의료 시스템에서의 음모 위험에 대한 첫 번째 체계적인 증거를 제공하고, 지침 충실성을 보장하는 실용적이고 경량 방어 방법을 입증합니다.

Abstract: The integration of large language models (LLMs) into healthcare IoT systems promises faster decisions and improved medical support. LLMs are also deployed as multi-agent teams to assist AI doctors by debating, voting, or advising on decisions. However, when multiple assistant agents interact, coordinated adversaries can collude to create false consensus, pushing an AI doctor toward harmful prescriptions. We develop an experimental framework with scripted and unscripted doctor agents, adversarial assistants, and a verifier agent that checks decisions against clinical guidelines. Using 50 representative clinical questions, we find that collusion drives the Attack Success Rate (ASR) and Harmful Recommendation Rates (HRR) up to 100% in unprotected systems. In contrast, the verifier agent restores 100% accuracy by blocking adversarial consensus. This work provides the first systematic evidence of collusion risk in AI healthcare and demonstrates a practical, lightweight defence that ensures guideline fidelity.

</details>


### [4] [Immunity memory-based jailbreak detection: multi-agent adaptive guard for large language models](https://arxiv.org/abs/2512.03356)
*Jun Leng,Litian Zhang,Xi Zhang*

Main category: cs.CR

TL;DR: 이 논문은 다중 에이전트 적응형 가드(MAAG) 프레임워크를 제안하여 기존의 고정 훈련 데이터를 사용하는 방법보다 더 효율적이고 정확하게 침입 공격을 탐지하는 방법을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)이 AI 시스템에서 핵심적인 역할을 하고 있지만, 그들은 여전히 공격에 취약합니다. 이러한 공격을 탐지하는 것이 LLM의 안전성을 유지하는 데 중요합니다.

Method: MAAG 프레임워크는 기억 능력을 갖춘 방어 시스템으로, 새로운 공격 패턴을 메모리에 저장하여 향후 유사한 위협을 빠르고 정확하게 식별할 수 있도록 합니다. 입력 프롬프트의 활성화 값을 추출하고 메모리 뱅크의 역사적 활성화와 비교하여 탐지를 수행합니다.

Result: MAAG는 98%의 탐지 정확도와 96%의 F1 점수를 달성하며, 다섯 개의 오픈 소스 모델을 통해 기존의 최첨단 방법들을 뛰어넘는 성능을 보였습니다.

Conclusion: MAAG 프레임워크는 LLM의 안전성을 크게 향상시킬 수 있는 효율적이고 강력한 방법입니다.

Abstract: Large language models (LLMs) have become foundational in AI systems, yet they remain vulnerable to adversarial jailbreak attacks. These attacks involve carefully crafted prompts that bypass safety guardrails and induce models to produce harmful content. Detecting such malicious input queries is therefore critical for maintaining LLM safety. Existing methods for jailbreak detection typically involve fine-tuning LLMs as static safety LLMs using fixed training datasets. However, these methods incur substantial computational costs when updating model parameters to improve robustness, especially in the face of novel jailbreak attacks. Inspired by immunological memory mechanisms, we propose the Multi-Agent Adaptive Guard (MAAG) framework for jailbreak detection. The core idea is to equip guard with memory capabilities: upon encountering novel jailbreak attacks, the system memorizes attack patterns, enabling it to rapidly and accurately identify similar threats in future encounters. Specifically, MAAG first extracts activation values from input prompts and compares them to historical activations stored in a memory bank for quick preliminary detection. A defense agent then simulates responses based on these detection results, and an auxiliary agent supervises the simulation process to provide secondary filtering of the detection outcomes. Extensive experiments across five open-source models demonstrate that MAAG significantly outperforms state-of-the-art (SOTA) methods, achieving 98% detection accuracy and a 96% F1-score across a diverse range of attack scenarios.

</details>


### [5] [Rethinking Security in Semantic Communication: Latent Manipulation as a New Threat](https://arxiv.org/abs/2512.03361)
*Zhiyuan Xi,Kun Zhu*

Main category: cs.CR

TL;DR: 딥러닝 기반의 의미 기반 통신(SemCom)은 작업 관련 의미 잠재 표현을 통해 우수한 전송 효율을 제공하지만, 이러한 시스템은 새로운 보안 위협에 노출되어 있다. 본 논문에서는 중개자 공격자가 전송된 의미를 조작할 수 있는 잠재 공간의 취약성을 발견하고, 확산 기반 재인코딩 공격 및 테스트 시간 적응 잠재 조작 공격을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다음 세대 무선 네트워크에서 의미 기반 통신의 우수한 전송 효율을 실현하면서도 보안 위협에 대비할 필요성을 강조한다.

Method: 중개자 공격자가 전송된 의미를 조작할 수 있도록 하는 확산 기반 재인코딩 공격(DiR) 및 모델 무관의 테스트 시간 적응 잠재 조작 공격(TTA-LM)을 제안한다.

Result: 제안된 두 공격 모두 디코딩된 의미를 크게 변경할 수 있으며, 자연적인 잠재 공간 분포를 유지하여 공격을 은밀하고 감지하기 어렵게 만든다.

Conclusion: SemCom 아키텍처에서의 잠재 공간 조작에 대한 경고를 제기하며, 향후 연구 및 방어 메커니즘의 개발을 촉구한다.

Abstract: Deep learning-based semantic communication (SemCom) has emerged as a promising paradigm for next-generation wireless networks, offering superior transmission efficiency by extracting and conveying task-relevant semantic latent representations rather than raw data. However, the openness of the wireless medium and the intrinsic vulnerability of semantic latent representations expose such systems to previously unrecognized security risks. In this paper, we uncover a fundamental latent-space vulnerability that enables Man-in-the-Middle (MitM) attacker to covertly manipulate the transmitted semantics while preserving the statistical properties of the transmitted latent representations. We first present a Diffusion-based Re-encoding Attack (DiR), wherein the attacker employs a diffusion model to synthesize an attacker-designed semantic variant, and re-encodes it into a valid latent representation compatible with the SemCom decoder. Beyond this model-dependent pathway, we further propose a model-agnostic and training-free Test-Time Adaptation Latent Manipulation attack (TTA-LM), in which the attacker perturbs and steers the intercepted latent representation toward an attacker-specified semantic target by leveraging the gradient of a target loss function. In contrast to diffusion-based manipulation, TTA-LM does not rely on any generative model and does not impose modality-specific or task-specific assumptions, thereby enabling efficient and broadly applicable latent-space tampering across diverse SemCom architectures. Extensive experiments on representative semantic communication architectures demonstrate that both attacks can significantly alter the decoded semantics while preserving natural latent-space distributions, making the attacks covert and difficult to detect.

</details>


### [6] [HarnessAgent: Scaling Automatic Fuzzing Harness Construction with Tool-Augmented LLM Pipelines](https://arxiv.org/abs/2512.03420)
*Kang Yang,Yunhang Zhang,Zichuan Li,GuanHong Tao,Jun Xu,XiaoJing Liao*

Main category: cs.CR

TL;DR: HarnessAgent는 자동화되고 확장 가능한 프로그램 퍼징을 위한 코드 하네스 생성 도구로, OSS-Fuzz의 수백 개 타겟에서 테스트되었으며, 기존 기술보다 성공률을 20% 향상시키고 안정적인 코드 검색 및 검증을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 기술이 복잡한 컨텍스트 정보를 요구하며, 이는 내부 함수에 적용하는 데 어려움을 겪고 있다. 따라서 퍼징의 신뢰성 높은 하네스 생성에 대한 필요성이 있다.

Method: HarnessAgent는 규칙 기반 전략, 하이브리드 도구 풀, 개선된 하네스 검증 파이프라인을 통해 자동화된 하네스 생성을 수행한다.

Result: HarnessAgent는 243개 타겟 함수에서 기존 기술보다 20% 이상 개선된 성공률(87% C, 81% C++)을 달성했으며, 75% 이상의 하네스가 목표 함수 커버리지를 증가시켰고, 리스폰스 비율은 90%를 초과했다.

Conclusion: 이 시스템은 코드 검색과 검증에서 획기적인 개선을 보여주며, 다양한 프로젝트에서의 신뢰성을 높인다.

Abstract: Large language model (LLM)-based techniques have achieved notable progress in generating harnesses for program fuzzing. However, applying them to arbitrary functions (especially internal functions) \textit{at scale} remains challenging due to the requirement of sophisticated contextual information, such as specification, dependencies, and usage examples. State-of-the-art methods heavily rely on static or incomplete context provisioning, causing failure of generating functional harnesses. Furthermore, LLMs tend to exploit harness validation metrics, producing plausible yet logically useless code. % Therefore, harness generation across large and diverse projects continues to face challenges in reliable compilation, robust code retrieval, and comprehensive validation.
  To address these challenges, we present HarnessAgent, a tool-augmented agentic framework that achieves fully automated, scalable harness construction over hundreds of OSS-Fuzz targets. HarnessAgent introduces three key innovations: 1) a rule-based strategy to identify and minimize various compilation errors; 2) a hybrid tool pool for precise and robust symbol source code retrieval; and 3) an enhanced harness validation pipeline that detects fake definitions. We evaluate HarnessAgent on 243 target functions from OSS-Fuzz projects (65 C projects and 178 C++ projects). It improves the three-shot success rate by approximately 20\% compared to state-of-the-art techniques, reaching 87\% for C and 81\% for C++. Our one-hour fuzzing results show that more than 75\% of the harnesses generated by HarnessAgent increase the target function coverage, surpassing the baselines by over 10\%. In addition, the hybrid tool-pool system of HarnessAgent achieves a response rate of over 90\% for source code retrieval, outperforming Fuzz Introspector by more than 30\%.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [7] [AGENTSAFE: A Unified Framework for Ethical Assurance and Governance in Agentic AI](https://arxiv.org/abs/2512.03180)
*Rafflesia Khan,Declan Joyce,Mansura Habiba*

Main category: cs.MA

TL;DR: AGENTSAFE는 LLM 기반 에이전트 시스템을 위한 포괄적인 거버넌스 프레임워크로, 리스크 식별 및 보증 절차를 통합하여 안전한 운영을 지원합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트의 자율적인 계획 수립, 다단계 도구 통합 및 emergent interactions로 인해 새로운 클래스의 리스크가 발생하고, 기존 거버넌스 접근 방식이 단편적이라는 문제제기.

Method: AGENTSAFE 프레임워크는 AI 리스크 리포지토리를 설계, 실행 및 감사 통제로 운영화하여 리스크 식별 및 보증을 위한 거버넌스 프레임워크를 제공합니다.

Result: AGENTSAFE는 에이전트 루프와 도구 체인을 프로파일링하고 리스크를 에이전트 특정 취약점으로 확장된 구조적 분류에 매핑합니다.

Conclusion: AGENTSAFE는 에이전트 AI 시스템의 수명 주기 전반에 걸쳐 측정 가능하고 감사 가능한 보증을 가능하게 합니다. 주요 기여는 통합 거버넌스 프레임워크, 에이전트 안전 평가 방법론, 그리고 실시간 거버넌스 및 책임 메커니즘의 집합입니다.

Abstract: The rapid deployment of large language model (LLM)-based agents introduces a new class of risks, driven by their capacity for autonomous planning, multi-step tool integration, and emergent interactions. It raises some risk factors for existing governance approaches as they remain fragmented: Existing frameworks are either static taxonomies driven; however, they lack an integrated end-to-end pipeline from risk identification to operational assurance, especially for an agentic platform. We propose AGENTSAFE, a practical governance framework for LLM-based agentic systems. The framework operationalises the AI Risk Repository into design, runtime, and audit controls, offering a governance framework for risk identification and assurance. The proposed framework, AGENTSAFE, profiles agentic loops (plan -> act -> observe -> reflect) and toolchains, and maps risks onto structured taxonomies extended with agent-specific vulnerabilities. It introduces safeguards that constrain risky behaviours, escalates high-impact actions to human oversight, and evaluates systems through pre-deployment scenario banks spanning security, privacy, fairness, and systemic safety. During deployment, AGENTSAFE ensures continuous governance through semantic telemetry, dynamic authorization, anomaly detection, and interruptibility mechanisms. Provenance and accountability are reinforced through cryptographic tracing and organizational controls, enabling measurable, auditable assurance across the lifecycle of agentic AI systems. The key contributions of this paper are: (1) a unified governance framework that translates risk taxonomies into actionable design, runtime, and audit controls; (2) an Agent Safety Evaluation methodology that provides measurable pre-deployment assurance; and (3) a set of runtime governance and accountability mechanisms that institutionalise trust in agentic AI ecosystems.

</details>


### [8] [Learning Network Sheaves for AI-native Semantic Communication](https://arxiv.org/abs/2512.03248)
*Enrico Grimaldi,Mario Edoardo Pandolfo,Gabriele D'Acunto,Sergio Barbarossa,Paolo Di Lorenzo*

Main category: cs.MA

TL;DR: 본 논문은 이질적인 AI 에이전트들이 압축된 잠재 공간 표현을 교환할 수 있도록 하는 문제를 다룹니다.


<details>
  <summary>Details</summary>
Motivation: AI의 최근 발전은 비트 중심의 통신에서 목표 및 의미 중심의 아키텍처로의 패러다임 전환을 요구하며, 이는 AI 네이티브 6G 네트워크를 위한 길을 열어줍니다.

Method: 이 문제를 해결하기 위해, 우리는 통신 토폴로지와 에이전트 간의 정보 교환을 조절하는 정렬 맵을 학습하는 방식으로 접근합니다. 이 과정에서 직교 맵을 갖춘 학습된 네트워크 성체를 제공합니다.

Result: 서로 다른 AI 에이전트가 사전 훈련된 실제 이미지 데이터를 기반으로 실험한 결과, 의미 잡음 제거 및 압축이 AI 에이전트 정렬과 의미 클러스터 추출을 촉진하며, 다운스트림 작업의 높은 정확성을 유지하는 것으로 나타났습니다.

Conclusion: 결과적으로, 이 통신 네트워크는 에이전트 간의 의미적 이질성에 대한 새로운 통찰을 제공하며, 우리의 방법론의 해석 가능성을 강조합니다.

Abstract: Recent advances in AI call for a paradigm shift from bit-centric communication to goal- and semantics-oriented architectures, paving the way for AI-native 6G networks. In this context, we address a key open challenge: enabling heterogeneous AI agents to exchange compressed latent-space representations while mitigating semantic noise and preserving task-relevant meaning. We cast this challenge as learning both the communication topology and the alignment maps that govern information exchange among agents, yielding a learned network sheaf equipped with orthogonal maps. This learning process is further supported by a semantic denoising end compression module that constructs a shared global semantic space and derives sparse, structured representations of each agent's latent space. This corresponds to a nonconvex dictionary learning problem solved iteratively with closed-form updates. Experiments with mutiple AI agents pre-trained on real image data show that the semantic denoising and compression facilitates AI agents alignment and the extraction of semantic clusters, while preserving high accuracy in downstream task. The resulting communication network provides new insights about semantic heterogeneity across agents, highlighting the interpretability of our methodology.

</details>


### [9] [A Gossip-Enhanced Communication Substrate for Agentic AI: Toward Decentralized Coordination in Large-Scale Multi-Agent Systems](https://arxiv.org/abs/2512.03285)
*Nafiul I. Khan,Mansura Habiba,Rafflesia Khan*

Main category: cs.MA

TL;DR: 에이전트 플랫폼의 확장에 따라 유연하고 분산된 조정의 필요성이 대두되고 있으며, 전통적인 통신 프로토콜이 이를 지원하지 못하고 있다. 본 논문은 에이전트 커뮤니케이션을 위한 보완적인 기제로서 가십 프로토콜을 재조명하고, 그 이점과 함께 직면하는 문제들을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 플랫폼이 확장됨에 따라 고정된 역할과 정의된 도구 체계를 넘어 유연하고 분산된 조정이 긴급히 요구되고 있다.

Method: 가십 프로토콜을 에이전트 커뮤니케이션의 보완적 기반으로 재조명하고, 그 효율성과 관련된 문제들을 탐구한다.

Result: 가십 프로토콜이 상황 인식이 풍부한 상태 전파, 불확실성 하의 강인한 조정, 그리고 출현하는 글로벌 인식 지원에 어떻게 기여할 수 있는지를 분석한다.

Conclusion: 가십은 향후 에이전트 생태계가 Robust하고 적응력이 있으며 자율적으로 조직될 수 있도록 하는 데 필수적이며, 이를 위해 연구 의제를 제시한다.

Abstract: As agentic platforms scale, agents are moving beyond fixed roles and predefined toolchains, creating an urgent need for flexible and decentralized coordination. Current structured communication protocols such as direct agent-to-agent messaging or MCP-style tool calls offer reliability, but they struggle to support the emergent and swarm-like intelligence required in large adaptive systems. Distributed agents must learn continuously, share context fluidly, and coordinate without depending solely on central planners.
  This paper revisits gossip protocols as a complementary substrate for agentic communication. Gossip mechanisms, long valued in distributed systems for their decentralized and fault-tolerant properties, provide scalable and adaptive diffusion of knowledge and fill gaps that structured protocols alone cannot efficiently address. However, gossip also introduces challenges, including semantic relevance, temporal staleness, and limited guarantees on action consistency in rapidly changing environments.
  We examine how gossip can support context-rich state propagation, resilient coordination under uncertainty, and emergent global awareness. We also outline open problems around semantic filtering, trust, and knowledge decay. Rather than proposing a complete framework, this paper presents a research agenda for integrating gossip into multi-agent communication stacks and argues that gossip is essential for future agentic ecosystems that must remain robust, adaptive, and self-organizing as their scale and autonomy increase.

</details>


### [10] [Local Dominance in Mixed-Strength Populations -- Fast Maximal Independent Set](https://arxiv.org/abs/2512.03303)
*Michael Luby,Sandy Irani*

Main category: cs.MA

TL;DR: 이 논문은 혼합 강도를 가진 에이전트 모델을 통해 빠른 지배 수렴을 확인하고, 이로 인해 발생하는 동력학의 변화를 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트들이 지역 경쟁을 통해 지배적 위치를 차지하는 과정을 수학적으로 모델링하고, 그 과정에서의 강도 차이와 빠른 수렴을 이해하고자 함.

Method: 혼합 강도 에이전트 모델을 도입하고, 자체 분포에서 강도 값을 반복적으로 생성하는 Luby MIS 프로토콜의 확장을 증명함.

Result: 각 에이전트가 자신의 분포에서 강도를 생성하는 Luby MIS 프로토콜의 확장은 여전히 빠른 지배 수렴을 보임을 증명함.

Conclusion: 혼합 강도를 가진 시스템에서도 빠른 지배 수렴이 가능하다는 것을 확인했으며, 강도 비대칭이 전체 동작에 질적으로 다른 영향을 미친다는 것을 보여줌.

Abstract: In many natural and engineered systems, agents interact through local contests that determine which individuals become dominant within their neighborhoods. These interactions are shaped by inherent differences in strength, and they often lead to stable dominance patterns that emerge surprisingly quickly relative to the size of the population. This motivates the search for simple mathematical models that capture both heterogeneous agent strength and rapid convergence to stable local dominance.
  A widely studied abstraction of local dominance is the Maximal Independent Set (MIS) problem. In the Luby MIS protocol that provably converges quickly to an MIS, each agent repeatedly generates a strength value chosen uniformly and becomes locally dominant if its value is smaller than those of its neighbors. This provides a theoretical explanation for fast dominance convergence in populations of equal-strength agents and naturally raises the question of whether fast convergence also holds in the more realistic setting where agents are inherently mixed-strength.
  To investigate this question, we introduce the mixed-strength agents model, in which each agent draws its strength from its own distribution. We prove that the extension of the Luby MIS protocol where each agent repeatedly generates a strength value from its own distribution still exhibits fast dominance convergence, providing formal confirmation of the rapid convergence observed in many mixed-strength natural processes.
  We also show that heterogeneity can significantly change the dynamics of the process. In contrast to the equal-strength setting, a constant fraction of edges need not be eliminated per round. We construct a population and strength profile in which progress per round is asymptotically smaller, illustrating how inherent strength asymmetry produces qualitatively different global behavior.

</details>


### [11] [AsymPuzl: An Asymmetric Puzzle for multi-agent cooperation](https://arxiv.org/abs/2512.03466)
*Xavier Cadet,Edward Koh,Peter Chin*

Main category: cs.MA

TL;DR: AsymPuzl은 정보 비대칭 하의 통신을 고립시키기 위해 설계된 두 에이전트 퍼즐 환경으로, LLM의 협력적 문제 해결 능력을 평가하는 데 사용된다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 기존 연구는 열린 역할 놀이에 초점을 맞추고 있어 LLM 에이전트를 통제된 방식으로 평가할 필요가 있다.

Method: 각 에이전트는 상징적 퍼즐의 보완적이지만 불완전한 시각을 관찰하고 해결을 위해 메시지를 교환해야 한다.

Result: 강력한 모델은 두 차례에 걸쳐 완전 정보를 공유함으로써 문제 해결에 수렴하는 반면, 약한 모델은 파트너 메시지를 무시하거나 가설을 과도하게 수정하는 경향이 있다.

Conclusion: LLM 커뮤니케이션 전략은 협력 작업이 단순함에도 불구하고 다르며 피드백 신호의 세부 수준에 따라 달라진다.

Abstract: Large Language Model (LLM) agents are increasingly studied in multi-turn, multi-agent scenarios, yet most existing setups emphasize open-ended role-play rather than controlled evaluation. We introduce AsymPuzl, a minimal but expressive two-agent puzzle environment designed to isolate communication under information asymmetry. Each agent observes complementary but incomplete views of a symbolic puzzle and must exchange messages to solve it cooperatively. Using a diverse set of current-generation and open-source LLMs, we show that (i) strong models such as GPT-5 and Claude-4.0 reliably converge across puzzle sizes on the solution by sharing complete information in two turns, (ii) weaker models often ignore partner messages or over-correct their hypotheses, and (iii) feedback design is non-trivial: simple self-feedback improves success rates, while detailed joint feedback can hurt performance. These findings show that even in simple cooperative tasks, LLM communication strategies diverge and depend on the granularity of feedback signals. AsymPuzl thus provides a testbed for probing the limits of multi-turn cooperation and opens avenues for studying coordination mechanisms.

</details>


### [12] [SRPG: Semantically Reconstructed Privacy Guard for Zero-Trust Privacy in Educational Multi-Agent Systems](https://arxiv.org/abs/2512.03694)
*Shuang Guo,Zihui Li*

Main category: cs.MA

TL;DR: SRPG는 개인 정보를 보호하면서 교육의 질을 유지하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 다국적 시스템과 대형 언어 모델을 활용한 개인화 교육의 필요성과 아동의 개인 정보 유출 위험성을 해결하고자 합니다.

Method: SRPG는 엄격한 위생화 스트림과 문맥 재구성 스트림(LLM 주도)을 사용하는 이중 스트림 재구성 메커니즘을 채택합니다.

Result: SRPG는 GPT-4o와의 테스트에서 0.0000 공격 성공률과 0.8267 정확히 일치함을 기록하며, 기존의 신뢰 없는 Pure LLM 기준을 크게 초월합니다.

Conclusion: SRPG는 수학 교육의 질을 저하시킴 없이 아동의 개인 정보를 효과적으로 보호합니다.

Abstract: Multi-Agent Systems (MAS) with large language models (LLMs) enable personalized education but risk leaking minors personally identifiable information (PII) via unstructured dialogue. Existing privacy methods struggle to balance security and utility: role-based access control fails on unstructured text, while naive masking destroys pedagogical context. We propose SRPG, a privacy guard for educational MAS, using a Dual-Stream Reconstruction Mechanism: a strict sanitization stream ensures zero PII leakage, and a context reconstruction stream (LLM driven) recovers mathematical logic. This decouples instructional content from private data, preserving teaching efficacy. Tests on MathDial show SRPG works across models; with GPT-4o, it achieves 0.0000 Attack Success Rate (ASR) (zero leakage) and 0.8267 Exact Match, far outperforming the zero trust Pure LLM baseline (0.2138). SRPG effectively protects minors privacy without sacrificing mathematical instructional quality.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation](https://arxiv.org/abs/2512.03048)
*Austin Spizzirri*

Main category: cs.AI

TL;DR: AI 정렬을 인간 가치 내용을 고정적으로 인코딩하는 것이 아니라 프로세스 기반의 다중 에이전트 개발 메커니즘을 통해 합리적 반응을 하는 에이전트를 설계하는 것으로 재구성해야 한다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: AI 정렬 문제를 기존의 고정된 인간 가치 대신 동적인 프로세스 기반으로 접근할 필요가 있다.

Method: 상호 불확실성을 줄이기 위한 상태 정렬을 통한 합성의 개념을 제안하고, 진정한 도덕 능력과 시뮬레이션된 도덕 능력의 기능적 구분을 설정한다.

Result: AI 시스템에서의 가치 출현 및 도덕적 에이전시와 관련하여 구체적이고 반증 가능한 예측을 생성한다.

Conclusion: 이 연구 결과는 더 넓은 연구 프로그램의 철학적 구성 요소로, 별도의 프로젝트에서 경험적 검증이 진행 중이다.

Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.

</details>


### [14] [Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI](https://arxiv.org/abs/2512.03072)
*Hu Keyi*

Main category: cs.AI

TL;DR: 이 논문은 'Weight-Calculatism'이라는 새로운 인지 아키텍처를 제안하고 그 가능성을 보여주며, 이는 AGI(인공지능 일반) 개발을 위한 실질적인 경로로 자리 잡을 수 있다.


<details>
  <summary>Details</summary>
Motivation: 현재의 AI 패러다임은 설명 가능성과 가치 정렬 측면에서 근본적인 도전에 직면해 있다.

Method: 이 연구는 인지를 인분화된 논리 원자와 두 가지 기본 작업인 지적과 비교로 분해하는 Weight-Calculatism이라는 새로운 인지 아키텍처를 제시한다. 의사 결정은 모든 값이 감사 가능한 초기 가중치 집합에 추적될 수 있는 Weight-Calculation 모델을 통해 형식화된다.

Result: 결과는 이 구조가 투명하고 인간처럼 사고하며 전례 없는 상황에서 강력한 학습을 달성함을 보여준다.

Conclusion: 이 연구는 신뢰할 수 있고 정렬된 AGI를 구축하기 위한 실질적이고 이론적인 기초를 확립한다.

Abstract: Current AI paradigms, as "architects of experience," face fundamental challenges in explainability and value alignment. This paper introduces "Weight-Calculatism," a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.

</details>


### [15] [Prior preferences in active inference agents: soft, hard, and goal shaping](https://arxiv.org/abs/2512.03293)
*Filippo Torresan,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 적극적 추론은 학습 에이전트의 탐색적 및 활용적 동기를 적절히 균형 유지하기 위해 계획 및 의사 결정을 위한 목표로 예상 자유 에너지를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 본 연구는 선호 분포의 정의와 그것이 적극적 추론 에이전트의 추론 및 학습에 미치는 영향을 탐구하는 것을 목표로 합니다.

Method: 네 가지 가능한 방법으로 선호 분포를 정의하고, 각 에이전트에 각기 다른 선호 분포를 부여하여 격자 세계 내비게이션 작업에서 성능을 비교하였습니다.

Result: 목표 형성이 전체적으로 최고의 성능을 가능하게 하며(즉, 활용 촉진), 환경의 전이 역학에 대한 학습을 희생함을 보여주었습니다(즉, 탐색 방해).

Conclusion: 에이전트의 목표를 형성하는 것이 탐색과 활용 사이의 균형에 영향을 미친다는 것을 발견했습니다.

Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).

</details>


### [16] [Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia](https://arxiv.org/abs/2512.03318)
*Chandler Smith,Marwa Abdulhai,Manfred Diaz,Marko Tesic,Rakshit S. Trivedi,Alexander Sasha Vezhnevets,Lewis Hammond,Jesse Clifton,Minsuk Chang,Edgar A. Duéñez-Guzmán,John P. Agapiou,Jayd Matyas,Danny Karmon,Akash Kundu,Aliaksei Korshuk,Ananya Ananya,Arrasy Rahman,Avinaash Anand Kulandaivel,Bain McHale,Beining Zhang,Buyantuev Alexander,Carlos Saith Rodriguez Rojas,Caroline Wang,Chetan Talele,Chenao Liu,Chichen Lin,Diana Riazi,Di Yang Shi,Emanuel Tewolde,Elizaveta Tennant,Fangwei Zhong,Fuyang Cui,Gang Zhao,Gema Parreño Piqueras,Hyeonggeun Yun,Ilya Makarov,Jiaxun Cui,Jebish Purbey,Jim Dilkes,Jord Nguyen,Lingyun Xiao,Luis Felipe Giraldo,Manuela Chacon-Chamorro,Manuel Sebastian Rios Beltran,Marta Emili García Segura,Mengmeng Wang,Mogtaba Alim,Nicanor Quijano,Nico Schiavone,Olivia Macmillan-Scott,Oswaldo Peña,Peter Stone,Ram Mohan Rao Kadiyala,Rolando Fernandez,Ruben Manrique,Sunjia Lu,Sheila A. McIlraith,Shamika Dhuri,Shuqing Shi,Siddhant Gupta,Sneheel Sarangi,Sriram Ganapathi Subramanian,Taehun Cha,Toryn Q. Klassen,Wenming Tu,Weijian Fan,Wu Ruiyang,Xue Feng,Yali Du,Yang Liu,Yiding Wang,Yipeng Kang,Yoonchang Sung,Yuxuan Chen,Zhaowei Zhang,Zhihan Wang,Zhiqiang Wu,Ziang Chen,Zilong Zheng,Zixia Jia,Ziyan Wang,Dylan Hadfield-Menell,Natasha Jaques,Tim Baarslag,Jose Hernandez-Orallo,Joel Z. Leibo*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델(LLM) 기반 에이전트가 제로샷 혼합 동기 환경에서 협력하는 능력을 평가하는 방법을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 사회적 상호작용에서 우수한 능력을 보여주고 있지만, 기존 평가 방법은 이러한 능력의 일반화를 측정하지 못합니다.

Method: Concordia라는 자연어 다중 에이전트 시뮬레이션 환경을 사용하여 LLM 기반 에이전트의 협력 능력을 평가하는 방법을 제안합니다.

Result: NeurIPS 2024 Concordia Contest에서 다양한 시나리오에 걸쳐 에이전트의 상호 이익을 달성하는 능력을 평가한 경험적 결과를 발표합니다.

Conclusion: 현재 에이전트 능력과 신뢰할 수 있는 협력에 필요한 강력한 일반화 사이에 상당한 격차가 있음을 보여줍니다.

Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.

</details>


### [17] [Multimodal Reinforcement Learning with Agentic Verifier for AI Agents](https://arxiv.org/abs/2512.03438)
*Reuben Tan,Baolin Peng,Zhengyuan Yang,Hao Cheng,Oier Mees,Theodore Zhao,Andrea Tupini,Isar Meijier,Qianhui Wu,Yuncong Yang,Lars Liden,Yu Gu,Sheng Zhang,Xiaodong Liu,Lijuan Wang,Marc Pollefeys,Yong Jae Lee,Jianfeng Gao*

Main category: cs.AI

TL;DR: MMRL에서 훈련된 에이전틱 추론 모델은 최종 답변을 기반으로 한 희소 보상을 사용하는 데 최적화되어 있으며, 보다 세밀한 가이드를 제공하는 보상 계산이 필요하다. 본 논문에서는 에이전틱 작업을 위한 다중 모드 추론 모델 훈련을 위한 원칙적인 보상 에이전트인 Argos를 소개한다.


<details>
  <summary>Details</summary>
Motivation: MMRL의 보상 최적화 방식에 대한 문제점을 해결하고 보다 효과적인 보상 시스템 구축

Method: Argos는 샘플당 여러 가지 점수 함수 중에서 선택하여 최종 응답 정확성, 시간 및 공간적 위치, 추론 과정의 질을 평가한다.

Result: Argos를 사용한 모델은 여러 에이전틱 작업에서 최첨단 결과를 기록했으며, RL 훈련 과정에서 온라인 검증이 없으면 대개 비기반 솔루션으로 붕괴되는 문제를 해결했다.

Conclusion: Argos의 효율성을 파레토 최적성을 통해 이론적으로 정당화하였다.

Abstract: Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed from the reasoning tokens can improve learning significantly by providing more fine-grained guidance. However, it is challenging to compute more informative rewards in MMRL beyond those based on outcomes since different samples may require different scoring functions and teacher models may provide noisy reward signals too. In this paper, we introduce the Argos (Agentic Reward for Grounded & Objective Scoring), a principled reward agent to train multimodal reasoning models for agentic tasks. For each sample, Argos selects from a pool of teacher-model derived and rule-based scoring functions to simultaneously evaluate: (i) final response accuracy, (ii) spatiotemporal localization of referred entities and actions, and (iii) the quality of the reasoning process. We find that by leveraging our agentic verifier across both SFT data curation and RL training, our model achieves state-of-the-art results across multiple agentic tasks such as spatial reasoning, visual hallucination as well as robotics and embodied AI benchmarks. Critically, we demonstrate that just relying on SFT post-training on highly curated reasoning data is insufficient, as agents invariably collapse to ungrounded solutions during RL without our online verification. We also show that our agentic verifier can help to reduce reward-hacking in MMRL. Finally, we also provide a theoretical justification for the effectiveness of Argos through the concept of pareto-optimality.

</details>


### [18] [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)
*Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 이 논문은 다중 에이전트 시스템에서의 협력적 정책 학습을 향상시키기 위해 통신이 중요한 수단임을 강조하며, 통신 손실 문제를 다룰 수 있는 새로운 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제 상황에서 통신 손실 문제를 해결하고, 복잡하고 동적인 환경에서 다중 에이전트 강화 학습의 적용 가능성을 높이기 위함.

Method: 일반화된 통신 제약 모델을 제안하고 이를 학습 사전으로 활용하여 손실 및 무손실 메시지를 구별하며, 이중 상호 정보 추정기를 사용하여 분산 의사결정에 대한 영향을 분리한다.

Result: 제안한 통신 제약 다중 에이전트 강화 학습 프레임워크가 여러 통신 제약 벤치마크에서 효과적임을 검증하였다.

Conclusion: 우리의 접근 방식이 복잡한 실제 환경에서 다중 에이전트 시스템의 학습 성능을 향상시킬 수 있음을 입증하였다.

Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

</details>


### [19] [PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks](https://arxiv.org/abs/2512.03549)
*Yuki Orimo,Iori Kurata,Hodaka Mori,Ryuhei Okuno,Ryohto Sawada,Daisuke Okanohara*

Main category: cs.AI

TL;DR: PARC는 독립적으로 긴 범위의 계산 작업을 수행할 수 있는 코드 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 독립적으로 대규모 과학적이고 분석적인 작업을 수행할 수 있는 가능성을 탐구하기 위해 설계되었다.

Method: PARC는 작업 계획, 실행, 독립적인 맥락에서 자신의 행동과 결과를 평가하고 피드백을 제공하는 계층적 다중 에이전트 아키텍처로 구축되었다.

Result: PARC는 자율적으로 리튬 이온 전도 및 합금 분리와 관련된 주요 결과를 복제하고, Kaggle 기반 실험에서 최소한의 자연어 지침을 통해 데이터 분석을 수행하여 경쟁력 있는 해결책을 도출했다.

Conclusion: 이 연구는 자기 평가와 자기 피드백을 통합한 계층적 다중 에이전트 시스템이 AI 시스템의 독립적인 대규모 작업 수행을 가능하게 할 잠재력을 강조한다.

Abstract: We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.

</details>


### [20] [Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks](https://arxiv.org/abs/2512.03560)
*Gianni Molinari,Fabio Ciravegna*

Main category: cs.AI

TL;DR: RP-ReAct는 전략적 계획과 저수준 실행을 분리하여 더 나은 신뢰성과 효율성을 달성하는 다중 에이전트 접근 방식을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업을 해결하기 위해 여러 도구를 조정하고 다양한 데이터 소스를 처리해야 하는 자율 에이전트의 한계를 극복하고자 합니다.

Method: RP-ReAct는 Reasoner Planner Agent와 Proxy-Execution Agent를 사용하여 전략적 계획을 저수준 실행과 분리합니다.

Result: RP-ReAct는 다양한 복잡한 작업을 처리할 때 최첨단 기준선보다 우수한 성능을 보여줍니다.

Conclusion: RP-ReAct는 기업을 위한 효과적이고 배포 가능한 에이전트 솔루션을 위한 기반을 마련합니다.

Abstract: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.

</details>


### [21] [EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths](https://arxiv.org/abs/2512.03571)
*Zhening Li,Armando Solar-Lezama,Yisong Yue,Stephan Zheng*

Main category: cs.AI

TL;DR: 이 논문에서는 LLM 기반 에이전트 개발을 위한 새로운 에이전트 프로그래밍 접근 방식을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 에이전트 프로그래밍 접근 방식은 에이전트 설계의 두 가지 측면인 핵심 워크플로우 논리와 추론 시간 전략을 얽히게 만든다.

Method: 우리는 '확률적 천사 비결정론'(PAN)이라는 프로그래밍 모델을 소개하며, 이를 통해 프로그래머가 에이전트 워크플로우를 설명하고 다양한 추론 시간 전략을 독립적으로 실험할 수 있게 한다.

Result: Python에서 PAN을 구현한 EnCompass 프레임워크를 제공하며, 이는 에이전트 워크플로우 프로그램을 탐색 공간으로 컴파일하기 위해 Python 데코레이터를 사용한다.

Conclusion: 세 가지 사례 연구를 통해 이 프레임워크가 프로그래머가 에이전트의 신뢰성을 신속하게 개선하고, 다양한 추론 시간 전략 간에 쉽게 전환할 수 있도록 돕는 방법을 보여준다.

Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce "probabilistic angelic nondeterminism" ("PAN"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.

</details>


### [22] [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)
*Yusen Wu,Xiaotie Deng*

Main category: cs.AI

TL;DR: DeepRule은 소매 상품 구성 및 가격 최적화를 위한 자동 비즈니스 규칙 생성을 위한 통합 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 이론 모델과 실제 경제 복잡성 간의 체계적인 불일치를 해결하기 위해.

Method: 대규모 언어 모델을 이용한 하이브리드 지식 융합 엔진을 설계하고, 게임 이론적 제약 최적화 기법과 해석 가능한 결정 증류 인터페이스를 적용하였다.

Result: 실제 소매 환경에서 시스템적 B2C 기준과 비교하여 더 높은 수익을 달성하였다.

Conclusion: 비구조적 지식 주입, 다중 에이전트 최적화 및 해석 가능한 전략 합성을 통합하는 폐쇄 루프 파이프라인을 구축하였다.

Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

</details>


### [23] [MemVerse: Multimodal Memory for Lifelong Learning Agents](https://arxiv.org/abs/2512.03627)
*Junming Liu,Yifei Sun,Weihua Cheng,Haodong Lei,Yirong Chen,Licheng Wen,Xuemeng Yang,Daocheng Fu,Pinlong Cai,Nianchen Deng,Yi Yu,Shuyue Hu,Botian Shi,Ding Wang*

Main category: cs.AI

TL;DR: MemVerse는 멀티모달 지능을 위한 메모리 프레임워크로, 빠른 기억과 위계적 검색 기반 메모리를 연결하여 AI 에이전트의 단기 기억 및 경험 구조화를 지원한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트는 기억력의 부족으로 인한 여러 문제를 겪고 있으며, 이는 멀티모달 환경에서 일관성 있는 작업 수행을 방해한다.

Method: MemVerse는 단기 메모리를 유지하면서 원시 멀티모달 경험을 위계적 지식 그래프로 변환하는 메모리 프레임워크를 제공한다. 또한, 실시간 요구를 처리하기 위해 주기적인 증류 메커니즘을 도입하여 장기 기억에서 필수 지식을 압축한다.

Result: 실험 결과 MemVerse는 멀티모달 추론 및 지속적인 학습 효율성을 크게 향상시키며, 에이전트가 기억하고 적응하며 일관되게 추론할 수 있도록 지원한다.

Conclusion: MemVerse는 AI 에이전트가 기억하고, 적응하며, 장기적인 상호 작용에서 일관되게 추론할 수 있도록 해주는 핵심 시스템이다.

Abstract: Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.

</details>


### [24] [RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design](https://arxiv.org/abs/2512.03762)
*Jiawei Xu,Fengfeng Wei,Weineng Chen*

Main category: cs.AI

TL;DR: RoCo라는 새로운 다중 에이전트 역할 기반 시스템을 제안하여 자동 휴리스틱 설계(AHD)의 다양성과 품질을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 조합 최적화 문제(COPs)를 해결하기 위한 효과적인 방법으로 AHD의 발전이 필요하다.

Method: RoCo는 탐색자, 활용자, 비평가, 통합자라는 4명의 전문 LLM 안내 에이전트를 조정하여 고품질의 휴리스틱을 생성하는 다중 역할 협업 방식을 채택한다.

Result: RoCo는 실험 결과에서 기존 방법인 ReEvo 및 HSEvo를 포함하여 경쟁력 있는 휴리스틱을 지속적으로 생성하여 우수한 성능을 보여준다.

Conclusion: 이 역할 기반 협업 패러다임은 강력하고 고성능의 AHD를 위한 새로운 기준을 설정한다.

Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

</details>


### [25] [A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)](https://arxiv.org/abs/2512.03887)
*Saurav Prateek*

Main category: cs.AI

TL;DR: 이 논문은 복잡한 연구 작업을 처리하기 위한 Static Deep Research Agent (Static-DRA)의 개발을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 정적 Retrieval Augmented Generation (RAG) 파이프라인의 한계를 극복하기 위해 복잡한 에이전트 시스템을 구축할 필요성이 증가하고 있습니다.

Method: Static-DRA는 설정 가능한 계층적 트리 기반 정적 워크플로우를 기반으로 하며, 연구 강도를 조절하는 두 가지 사용자 조정 가능한 파라미터인 Depth와 Breadth를 통합하였습니다.

Result: Static-DRA는 RACE 프레임워크를 사용하여 DeepResearch Bench와 비교 평가하였으며, 전반적인 점수는 34.72를 기록했습니다.

Conclusion: Static-DRA는 사용자에게 연구 프로세스에 대한 투명한 제어를 제공하는 실용적이고 자원 인식적인 솔루션을 제공합니다.

Abstract: The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow.
  The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation.
  We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/

</details>


### [26] [Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties](https://arxiv.org/abs/2512.03931)
*Vineel Tummala,Daniela Inclezan*

Main category: cs.AI

TL;DR: 정책 인식 자율 에이전트를 위한 논리 프로그래밍 기반 프레임워크를 제안하며, 비준수에 대한 잠재적 처벌을 고려하고 이에 따라 행동할 수 있도록 설계됨.


<details>
  <summary>Details</summary>
Motivation: 이전 연구는 주로 준수를 보장하는 데 집중했지만, 본 접근법은 정책에서 벗어나는 것이 필수적인 고위험 목표를 달성하는 시나리오를 고려함.

Method: Gelfond와 Lobo의 권한 및 의무 정책 언어(AOPL)를 확장하여 처벌을 통합하고, 추론을 위해 답 집합 프로그래밍(ASP)을 통합함.

Result: 실험 결과, 본 프레임워크가 유해한 행동을 피하는 고품질의 계획을 생성하고, 경우에 따라 계산 효율성도 향상시킴을 보여줌.

Conclusion: 이 연구 결과는 자율 의사결정을 향상시키고 정책 개선에 기여할 수 있는 잠재력을 강조함.

Abstract: This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [27] [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
*Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 산업 자동화는 유연한 제어 전략을 요구하며, 대규모 언어 모델 기반 에이전트가 이를 지원할 수 있다. 그러나 표준화된 벤치마크가 부족하다. 이 논문에서는 Blocksworld 문제를 나타내는 실행 가능한 시뮬레이션 환경을 제공하는 벤치마크를 소개하며, 다양한 에이전트 아키텍처가 평가될 수 있도록 Model Context Protocol (MCP)를 통합하였다.


<details>
  <summary>Details</summary>
Motivation: 산업 자동화 환경에서 변화하는 작업과 환경에 적응할 수 있는 유연한 제어 전략의 필요성.

Method: Blocksworld 문제를 위한 실행 가능한 시뮬레이션 환경을 제공하며, Model Context Protocol (MCP)를 통해 다양한 에이전트 아키텍처가 표준화된 벤치마크에 연결되고 평가될 수 있도록 함.

Result: 단일 에이전트 구현을 통해 벤치마크의 적용 가능성을 입증하고, 대규모 언어 모델 기반 계획 및 실행 방법의 비교를 위한 정량적 메트릭을 설정함.

Conclusion: 표준화된 벤치마크를 통해 다양한 에이전트 아키텍처의 비교와 평가가 가능해짐.

Abstract: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [28] [Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research](https://arxiv.org/abs/2512.03054)
*Ciro Benito Raggio,Lucia Migliorelli,Nils Skupien,Mathias Krohmer Zabaleta,Oliver Blanck,Francesco Cicone,Giuseppe Lucio Cascini,Paolo Zaffino,Maria Francesca Spadea*

Main category: cs.LG

TL;DR: 본 논문은 자원 요구량이 높은 연합 학습이 의료 불평등을 심화시킬 수 있는 문제를 해결하기 위해, 에너지 소모와 컴퓨팅 부하를 줄이면서 모델 성능을 유지하는 새로운 적응형 레이어 동결 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습(FL)은 다양한 기관들이 협력하여 제한된 데이터로 심층 학습(DL) 모델을 훈련할 수 있게 하여 건강 분야의 평등을 향상시킬 잠재력을 지니고 있습니다. 그러나 FL의 상당한 자원 요구는 제한된 컴퓨팅 인프라를 가진 센터들을 배제하여 의료 격차를 더욱 확대합니다.

Method: 우리는 자기공명영상(MRI)에서 컴퓨터 단층촬영(CT) 변환을 위한 다양한 연합 아키텍처를 이용하여 우리의 접근 방식을 테스트했습니다. 제안된 적응형 전략은 라운드마다 인코더 가중치의 상대적 차이를 모니터링하여 선택적으로 인코더 가중치를 동결함으로써 연합 훈련을 최적화합니다. 인내 기반 메커니즘은 업데이트가 일관되게 최소한으로 유지될 때만 동결이 발생하도록 보장합니다.

Result: 우리는 코드카본(CodeCarbon) 라이브러리를 사용하여 연합의 에너지 소비 및 CO2eq 배출량을 추적했습니다. 동결되지 않은 동등한 경우와 비교하여, 우리의 접근 방식은 훈련 시간, 총 에너지 소비 및 CO2eq 배출량을 최대 23% 감소시켰습니다. 동시에 MRI-CT 변환 성능은 유지되었고, 평균 절대 오차(MAE)에서 작은 변동만 있었습니다. 다섯 개 평가된 아키텍처 중 세 개에서 통계적으로 유의미한 차이가 관찰되지 않았으나, 두 개의 아키텍처에서 통계적으로 유의미한 개선이 나타났습니다.

Conclusion: 우리의 연구는 임상 요구를 충족하면서 동시에 기후, 사회 및 경제적 지속 가능성을 보장하는 DL 기반 프레임워크를 촉진하는 연구 패러다임과 일치합니다. 본 연구는 연합 학습 평가 프레임워크의 새 기준을 마련하고, AI 기반 의료에서의 개인 정보 보호, 평등 및 보다 넓은 의미에서의 정의를 증진합니다.

Abstract: Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.

</details>


### [29] [Physics-informed self-supervised learning for predictive modeling of coronary artery digital twins](https://arxiv.org/abs/2512.03055)
*Xiaowu Sun,Thabo Mahendiran,Ortal Senouf,Denise Auberson,Bernard De Bruyne,Stephane Fournier,Olivier Muller,Pascal Frossard,Emmanuel Abbe,Dorina Thanou*

Main category: cs.LG

TL;DR: PINS-CAD는 물리 정보를 활용한 자기 지도 학습 프레임워크로, 200,000개의 합성 관상동맥 디지털 트윈을 이용해 미래 심혈관 사건을 예측합니다.


<details>
  <summary>Details</summary>
Motivation: 관상동맥 질환의 조기 위험 예측은 필요하며, 3D 관상동맥 디지털 트윈은 개인 맞춤형 평가는 가능하지만 계산 유체 역학에 의존하여 확장성이 제한됩니다.

Method: PINS-CAD는 200,000개의 합성 관상동맥 디지털 트윈에서 그래프 신경망을 미리 훈련하고, 1D 나비에-스토크스 방정식과 압력 강하 법칙을 이용해 압력과 흐름을 예측합니다.

Result: FAME2 연구의 635명의 임상 데이터에서 미세 조정 후 PINS-CAD는 AUC 0.73으로 미래 심혈관 사건을 예측하며, 임상 위험 점수 및 데이터 기반 기준보다 성능이 우수합니다.

Conclusion: 물리적 정보가 포함된 사전 훈련은 샘플 효율성을 높이고 생리학적으로 의미 있는 표현을 제공합니다. 또한 PINS-CAD는 해석 가능한 바이오마커를 제공하는 공간 분해 압력 및 분수 흐름 저항 곡선을 생성합니다.

Abstract: Cardiovascular disease is the leading global cause of mortality, with coronary artery disease (CAD) as its most prevalent form, necessitating early risk prediction. While 3D coronary artery digital twins reconstructed from imaging offer detailed anatomy for personalized assessment, their analysis relies on computationally intensive computational fluid dynamics (CFD), limiting scalability. Data-driven approaches are hindered by scarce labeled data and lack of physiological priors. To address this, we present PINS-CAD, a physics-informed self-supervised learning framework. It pre-trains graph neural networks on 200,000 synthetic coronary digital twins to predict pressure and flow, guided by 1D Navier-Stokes equations and pressure-drop laws, eliminating the need for CFD or labeled data. When fine-tuned on clinical data from 635 patients in the multicenter FAME2 study, PINS-CAD predicts future cardiovascular events with an AUC of 0.73, outperforming clinical risk scores and data-driven baselines. This demonstrates that physics-informed pretraining boosts sample efficiency and yields physiologically meaningful representations. Furthermore, PINS-CAD generates spatially resolved pressure and fractional flow reserve curves, providing interpretable biomarkers. By embedding physical priors into geometric deep learning, PINS-CAD transforms routine angiography into a simulation-free, physiology-aware framework for scalable, preventive cardiology.

</details>


### [30] [Delta Sampling: Data-Free Knowledge Transfer Across Diffusion Models](https://arxiv.org/abs/2512.03056)
*Zhidong Gao,Zimeng Pan,Yuhang Yao,Chenyue Xie,Wei Wei*

Main category: cs.LG

TL;DR: Delta Sampling(DS)는 서로 다른 구조의 기본 모델 간 knowledge transfer를 가능하게 하는 새로운 방법이다.


<details>
  <summary>Details</summary>
Motivation: Diffusion 모델은 효과적인 아키텍처와 파라미터를 활용하지만, 기본 모델이 업그레이드될 때 재사용이 어렵다.

Method: DS는 기본 모델의 적응 전후 모델 예측의 차이를 이용하여 새로운 기본 모델의 디노이징 프로세스를 안내한다.

Result: DS는 다양한 SD 버전에서 테스트되었으며, 다양한 샘플링 전략 하에서 원하는 효과를 생성하는 데 일관된 개선을 보여준다.

Conclusion: DS는 이미지 합성에서 지식 전이를 위한 효과적인 플러그 앤 플레이 메커니즘이다.

Abstract: Diffusion models like Stable Diffusion (SD) drive a vibrant open-source ecosystem including fully fine-tuned checkpoints and parameter-efficient adapters such as LoRA, LyCORIS, and ControlNet. However, these adaptation components are tightly coupled to a specific base model, making them difficult to reuse when the base model is upgraded (e.g., from SD 1.x to 2.x) due to substantial changes in model parameters and architecture. In this work, we propose Delta Sampling (DS), a novel method that enables knowledge transfer across base models with different architectures, without requiring access to the original training data. DS operates entirely at inference time by leveraging the delta: the difference in model predictions before and after the adaptation of a base model. This delta is then used to guide the denoising process of a new base model. We evaluate DS across various SD versions, demonstrating that DS achieves consistent improvements in creating desired effects (e.g., visual styles, semantic concepts, and structures) under different sampling strategies. These results highlight DS as an effective, plug-and-play mechanism for knowledge transfer in diffusion-based image synthesis. Code:~ https://github.com/Zhidong-Gao/DeltaSampling

</details>


### [31] [Safe and Sustainable Electric Bus Charging Scheduling with Constrained Hierarchical DRL](https://arxiv.org/abs/2512.03059)
*Jiaju Qi,Lei Lei,Thorsteinn Jonsson,Dusit Niyato*

Main category: cs.LG

TL;DR: 이 논문은 다중 소스 불확실성 하에서 전기 버스 충전 스케줄 문제를 해결하기 위한 안전한 계층적 심층 강화 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 전기 버스와 태양광 패널과 같은 재생 가능 에너지원의 통합은 지속 가능하고 저탄소 대중 교통 수단을 촉진하는 유망한 접근 방식입니다.

Method: 문제를 제약 마르코프 결정 과정(CMDP)으로 공식화하고, Lagrangian 완화를 Double Actor-Critic 프레임워크에 통합한 새로운 HDRL 알고리즘 DAC-MAPPO-Lagrangian을 개발했습니다. 중앙 집중식 PPO-Lagrangian 알고리즘을 통해 안전한 충전기 할당 정책을 학습하고, MAPPO-Lagrangian을 사용하여 중앙 집중식 훈련 및 분산 실행(CTDE) 패러다임하에서 분산 충전 전력 결정을 학습했습니다.

Result: 제안된 접근 방식은 기존 기준선보다 비용 최소화 및 안전 준수에서 더 우수한 성능을 보이며 빠른 수렴 속도를 유지함을 실험을 통해 입증했습니다.

Conclusion: 재생 가능 에너지원과 전기 버스의 통합에 대한 최적의 충전 스케줄링 솔루션을 제공함으로써 이 연구는 지속 가능한 대중 교통을 촉진하는 데 기여할 것입니다.

Abstract: The integration of Electric Buses (EBs) with renewable energy sources such as photovoltaic (PV) panels is a promising approach to promote sustainable and low-carbon public transportation. However, optimizing EB charging schedules to minimize operational costs while ensuring safe operation without battery depletion remains challenging - especially under real-world conditions, where uncertainties in PV generation, dynamic electricity prices, variable travel times, and limited charging infrastructure must be accounted for. In this paper, we propose a safe Hierarchical Deep Reinforcement Learning (HDRL) framework for solving the EB Charging Scheduling Problem (EBCSP) under multi-source uncertainties. We formulate the problem as a Constrained Markov Decision Process (CMDP) with options to enable temporally abstract decision-making. We develop a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian), which integrates Lagrangian relaxation into the Double Actor-Critic (DAC) framework. At the high level, we adopt a centralized PPO-Lagrangian algorithm to learn safe charger allocation policies. At the low level, we incorporate MAPPO-Lagrangian to learn decentralized charging power decisions under the Centralized Training and Decentralized Execution (CTDE) paradigm. Extensive experiments with real-world data demonstrate that the proposed approach outperforms existing baselines in both cost minimization and safety compliance, while maintaining fast convergence speed.

</details>


### [32] [Optimizing Life Sciences Agents in Real-Time using Reinforcement Learning](https://arxiv.org/abs/2512.03065)
*Nihir Chadderwala*

Main category: cs.LG

TL;DR: 생명 과학 분야의 생성 AI 에이전트는 다양한 질문에 대한 최적 접근 방식을 결정하는 데 중요한 도전에 직면해 있습니다. 우리는 사용자 피드백만으로 최적의 의사결정 전략을 학습할 수 있는 새로운 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 생명 과학 분야에서 생성 AI 에이전트는 단순한 사실 질문부터 복잡한 기계적 추론에 이르기까지 다양한 쿼리에 대한 최적의 접근 방식을 결정하는 것이 중요합니다.

Method: AWS Strands Agents와 Thompson Sampling 맥락밴딧을 결합하여 AI 에이전트가 사용자 피드백만으로 최적의 의사결정 전략을 학습할 수 있도록 하는 새로운 프레임워크를 제시합니다.

Result: 실제 생명 과학 쿼리 평가를 통해 무작위 기준에 비해 15-30% 사용자 만족도 향상을 보여주며, 20-30 쿼리 후 명확한 학습 패턴이 나타납니다.

Conclusion: 우리의 접근 방식은 지상 진실 레이블이 필요 없으며, 사용자 선호도에 지속적으로 적응하고, 에이전틱 AI 시스템의 탐색-활용 딜레마에 대한 원칙적인 해결책을 제공합니다.

Abstract: Generative AI agents in life sciences face a critical challenge: determining the optimal approach for diverse queries ranging from simple factoid questions to complex mechanistic reasoning. Traditional methods rely on fixed rules or expensive labeled training data, neither of which adapts to changing conditions or user preferences. We present a novel framework that combines AWS Strands Agents with Thompson Sampling contextual bandits to enable AI agents to learn optimal decision-making strategies from user feedback alone. Our system optimizes three key dimensions: generation strategy selection (direct vs. chain-of-thought), tool selection (literature search, drug databases, etc.), and domain routing (pharmacology, molecular biology, clinical specialists). Through empirical evaluation on life science queries, we demonstrate 15-30\% improvement in user satisfaction compared to random baselines, with clear learning patterns emerging after 20-30 queries. Our approach requires no ground truth labels, adapts continuously to user preferences, and provides a principled solution to the exploration-exploitation dilemma in agentic AI systems.

</details>


### [33] [PretopoMD: Pretopology-based Mixed Data Hierarchical Clustering](https://arxiv.org/abs/2512.03071)
*Loup-Noe Levy,Guillaume Guerard,Sonia Djebali,Soufian Ben Amor*

Main category: cs.LG

TL;DR: 이 논문은 차원 축소 없이 혼합 데이터 클러스터링 문제를 해결하기 위한 새로운 전위 토폴로지 기반 알고리즘을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 혼합 데이터를 클러스터링할 때의 도전 과제를 해결하고, 데이터 무결성을 유지하기 위해.

Method: 정리된 정규형을 활용하여 사용자 정의 계층적 클러스터 생성을 가능하게 하는 논리 규칙 및 하이퍼파라미터를 형성하는 방법을 사용합니다.

Result: 계층 덴드로그램 분석 및 비교 클러스터링 메트릭을 통해 알고리즘의 우수한 성능을 보여줍니다.

Conclusion: 전통적인 차원 축소 기법에서 벗어나 클러스터 형성과 명료성을 향상시키는 논리 규칙의 혁신적인 사용으로 혼합 데이터 클러스터링에 대한 중요한 발전을 기여합니다.

Abstract: This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm's robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.

</details>


### [34] [ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms](https://arxiv.org/abs/2512.03476)
*Juan Diego Toscano,Daniel T. Chen,George Em Karniadakis*

Main category: cs.LG

TL;DR: ATHENA는 과학 계산과 과학 기계 학습 분야의 연구 수명 주기를 관리하기 위해 설계된 자율적인 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 과학 계산(SciC)과 과학 기계 학습(SciML)에서 이론적 개념화와 계산적 구현 간의 간극을 메우는 것이 주요 병목 현상이다.

Method: ATHENA는 HENA 루프라는 지식 주도형 진단 프로세스를 중심으로 하여, 컨텍스트 밴딧 문제로 구조화되어 있다. 이 시스템은 온라인 학습자로 작용하여 전문가 청사진에 의해 안내되는 조합적 공간에서 구조적 '행동'(A_n)을 선택한다.

Result: ATHENA는 특이한 자동화를 초월하여, SciC에서는 정확한 해를 찾기 위한 수학적 대칭을 자율적으로 식별하고, SciML에서는 깊은 진단을 수행하여 잘못된 형식을 다룬다.

Conclusion: 이 새로운 패러다임은 구현 기계에서 방법론적 혁신으로 초점을 이동시켜 과학적 발견을 가속화한다.

Abstract: Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.

</details>


### [35] [E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing](https://arxiv.org/abs/2512.03109)
*Shuvom Sadhuka,Drew Prinster,Clara Fannjiang,Gabriele Scalia,Aviv Regev,Hanchen Wang*

Main category: cs.LG

TL;DR: e-valuator는 흑박스 검증기를 통계적으로 검증된 결정 규칙으로 변환하는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 AI 시스템의 행동 성공을 평가하기 위한 효율적이고 신뢰할 수 있는 방법이 필요하다.

Method: e-valuator는 흑박스 검증기 점수를 결정 규칙으로 변환하는 방법으로, 연속 가설 검정 문제로 프레이밍하며, 각 행동 단계에서 통계적 유효성을 유지한다.

Result: e-valuator는 6개 데이터 세트와 3개 에이전트에서 더 높은 통계적 파워와 좋은 거짓 경고율 통제를 보여주었다.

Conclusion: 이 방법은 신뢰할 수 있는 에이전트 시스템의 배치를 가능하게 하는 통계적 보장을 제공하는 경량의 모델 비특화 프레임워크를 제공한다.

Abstract: Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.

</details>


### [36] [Modal Logical Neural Networks](https://arxiv.org/abs/2512.03491)
*Antonin Sulc*

Main category: cs.LG

TL;DR: MLNN은 심층 학습과 양식적 의미론을 통합한 신경 상징적 프레임워크로, 필요성과 가능성에 대한 추론을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 문제 공간의 논리를 정의하고 비일관적 지식에 강건한 시스템을 만드는 것이 필요하다.

Method: Kripke 의미론을 기반으로 한 특별한 뉴런을 도입하여 $ox$와 $	riangle$와 같은 양식자 연산을 구현하고, 접근성 관계를 고정하거나 신경망으로 매개변수화할 수 있도록 설계했다.

Result: 이 프레임워크는 논리 모순 손실을 최소화하면서 전방위적으로 학습하며, 비선형 관계를 학습할 수 있다.

Conclusion: MLNN은 접근성을 강화하거나 학습함으로써 논리적 일관성과 해석 가능성을 증가시킬 수 있다.

Abstract: We propose Modal Logical Neural Networks (MLNNs), a neurosymbolic framework that integrates deep learning with the formal semantics of modal logic, enabling reasoning about necessity and possibility. Drawing on Kripke semantics, we introduce specialized neurons for the modal operators $\Box$ and $\Diamond$ that operate over a set of possible worlds, enabling the framework to act as a differentiable ``logical guardrail.'' The architecture is highly flexible: the accessibility relation between worlds can either be fixed by the user to enforce known rules or, as an inductive feature, be parameterized by a neural network. This allows the model to optionally learn the relational structure of a logical system from data while simultaneously performing deductive reasoning within that structure.
  This versatile construction is designed for flexibility. The entire framework is differentiable from end to end, with learning driven by minimizing a logical contradiction loss. This not only makes the system resilient to inconsistent knowledge but also enables it to learn nonlinear relationships that can help define the logic of a problem space. We illustrate MLNNs on four case studies: grammatical guardrailing, axiomatic detection of the unknown, multi-agent epistemic trust, and detecting constructive deception in natural language negotiation. These experiments demonstrate how enforcing or learning accessibility can increase logical consistency and interpretability without changing the underlying task architecture.

</details>


### [37] [Temporal Graph Neural Networks for Early Anomaly Detection and Performance Prediction via PV System Monitoring Data](https://arxiv.org/abs/2512.03114)
*Srijani Mukherjee,Laurent Vuillon,Liliane Bou Nassif,Stéphanie Giroux-Julien,Hervé Pabiou,Denys Dutykh,Ionnasis Tsanakas*

Main category: cs.LG

TL;DR: 태양광 시스템의 성능 모니터링 및 이상 탐지를 위한 Temporal Graph Neural Network를 활용한 새로운 접근법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 태양광 시스템의 신속한 성장으로 최적의 운영을 보장하기 위한 성능 모니터링 및 이상 탐지 방법이 필요하다.

Method: Temporal Graph Neural Network (Temporal GNN)를 활용하여 태양광 출력 전력을 예측하고 환경 및 운영 파라미터를 사용하여 이상을 탐지하는 모델을 제안한다.

Result: 모델은 태양광 시스템의 주요 파라미터 간의 그래프 기반의 시간적 관계를 이용하여 전력 출력을 예측한다.

Conclusion: 이 연구는 프랑스 리옹에 위치한 옥외 시설에서 수집한 데이터를 기반에 두고 있으며, PV 모듈의 전력 측정치와 기상 파라미터를 포함한다.

Abstract: The rapid growth of solar photovoltaic (PV) systems necessitates advanced methods for performance monitoring and anomaly detection to ensure optimal operation. In this study, we propose a novel approach leveraging Temporal Graph Neural Network (Temporal GNN) to predict solar PV output power and detect anomalies using environmental and operational parameters. The proposed model utilizes graph-based temporal relationships among key PV system parameters, including irradiance, module and ambient temperature to predict electrical power output. This study is based on data collected from an outdoor facility located on a rooftop in Lyon (France) including power measurements from a PV module and meteorological parameters.

</details>


### [38] [Scaling Internal-State Policy-Gradient Methods for POMDPs](https://arxiv.org/abs/2512.03204)
*Douglas Aberdeen,Jonathan Baxter*

Main category: cs.LG

TL;DR: 정책 경량화 방법이 부분 관측 가능한 환경에서 행동 학습에 각광받고 있으며, 이 논문에서는 메모리가 필요한 경우에 대한 개선된 알고리즘을 개발하고 비교한다.


<details>
  <summary>Details</summary>
Motivation: 부분 관측 가능한 환경에서 행동을 학습하는 수단으로 정책 경량화 방법에 대한 관심이 증가하고 있다.

Method: 환경의 알려진 모델이 있을 때는 직접적으로, 그렇지 않을 때는 시뮬레이션을 통해 무한 지평 설정에서 메모리를 가진 정책을 학습하기 위한 여러 개선된 알고리즘을 개발하였다.

Result: 이 알고리즘들을 노이즈가 있는 로봇 탐색과 다중 에이전트 문제를 포함한 일부 대형 POMDP에서 비교하였다.

Conclusion: 메모리를 필요로 하는 문제에서 정책 경량화 방법의 성능을 향상시키는 새로운 알고리즘이 개발되었다.

Abstract: Policy-gradient methods have received increased attention recently as a mechanism for learning to act in partially observable environments. They have shown promise for problems admitting memoryless policies but have been less successful when memory is required. In this paper we develop several improved algorithms for learning policies with memory in an infinite-horizon setting -- directly when a known model of the environment is available, and via simulation otherwise. We compare these algorithms on some large POMDPs, including noisy robot navigation and multi-agent problems.

</details>


### [39] [A Multi-Agent, Policy-Gradient approach to Network Routing](https://arxiv.org/abs/2512.03211)
*Nigel Tao,Jonathan Baxter,Lex Weaver*

Main category: cs.LG

TL;DR: OLPOMDP 알고리즘을 사용하여 여러 네트워크 모델에서 분산 에이전트들이 협력적으로 행동하도록 학습하였다.


<details>
  <summary>Details</summary>
Motivation: 분산 의사결정을 요구하는 네트워크 라우팅 문제에서 성능을 향상시키기 위해.

Method: OLPOMDP라는 정책 기울기 강화 학습 알고리즘을 사용하여 시뮬레이션된 네트워크 라우팅에 적용하였다.

Result: 여러 분산 에이전트들이 명시적인 상호 통신 없이 협력적인 행동을 학습하였으며, 특정 패턴의 비최적 행동에 대해 명시적으로 패널티를 부여하여 수렴 속도를 개선하였다.

Conclusion: OLPOMDP는 네트워크 라우팅 문제에서 효과적으로 적용되며, 정책 강화를 통한 성능 향상이 가능하다.

Abstract: Network routing is a distributed decision problem which naturally admits numerical performance measures, such as the average time for a packet to travel from source to destination. OLPOMDP, a policy-gradient reinforcement learning algorithm, was successfully applied to simulated network routing under a number of network models. Multiple distributed agents (routers) learned co-operative behavior without explicit inter-agent communication, and they avoided behavior which was individually desirable, but detrimental to the group's overall performance. Furthermore, shaping the reward signal by explicitly penalizing certain patterns of sub-optimal behavior was found to dramatically improve the convergence rate.

</details>


### [40] [Perch 2.0 transfers 'whale' to underwater tasks](https://arxiv.org/abs/2512.03219)
*Andrea Burns,Lauren Harrell,Bart van Merriënboer,Vincent Dumoulin,Jenny Hamer,Tom Denton*

Main category: cs.LG

TL;DR: Perch 2.0는 다양한 종에 대한 최신 성능을 보이는 생물 음향 기초 모델이며, 해양 포유류 및 수중 음향 작업에서의 성능을 평가하였다.


<details>
  <summary>Details</summary>
Motivation: Perch 2.0은 훈련 데이터에 해양 포유류의 오디오나 클래스가 거의 포함되어 있지 않기 때문에, 해양 포유류 및 수중 음향 작업에서의 성능 검토가 필요하다.

Method: 기초 모델에서 생성된 임베딩을 사용하여 선형 탐색을 수행하고, 이전의 생물 음향 모델들과 성능을 비교합니다.

Result: Perch 2.0의 임베딩은 소수의 샘플 전이 학습에 대해 consistently 높은 성능을 나타내며, 대다수의 작업에서 다른 임베딩 모델을 능가한다.

Conclusion: 해양 포유류 분류를 위한 새로운 선형 분류기를 개발할 때, Perch 2.0을 사용하는 것이 추천된다.

Abstract: Perch 2.0 is a supervised bioacoustics foundation model pretrained on 14,597 species, including birds, mammals, amphibians, and insects, and has state-of-the-art performance on multiple benchmarks. Given that Perch 2.0 includes almost no marine mammal audio or classes in the training data, we evaluate Perch 2.0 performance on marine mammal and underwater audio tasks through few-shot transfer learning. We perform linear probing with the embeddings generated from this foundation model and compare performance to other pretrained bioacoustics models. In particular, we compare Perch 2.0 with previous multispecies whale, Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 models, which have open-source tools for transfer-learning and agile modeling. We show that the embeddings from the Perch 2.0 model have consistently high performance for few-shot transfer learning, generally outperforming alternative embedding models on the majority of tasks, and thus is recommended when developing new linear classifiers for marine mammal classification with few labeled examples.

</details>


### [41] [A2G-QFL: Adaptive Aggregation with Two Gains in Quantum Federated learning](https://arxiv.org/abs/2512.03363)
*Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel*

Main category: cs.LG

TL;DR: 본 논문은 양자 연합 학습에서 클라이언트 품질과 통신 신뢰도가 불균형하게 분포하는 문제를 해결하기 위해 A2G 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 양자 기술이 적용된 이질적인 고전 네트워크에서 연합 학습의 성능 저하 문제를 해결하고자 함.

Method: A2G 프레임워크는 기하학 이득과 QoS 이득을 조절하여 클라이언트의 중요성을 조정하고 기하학적 혼합을 제어하는 이중 이득 규칙을 개발함.

Result: A2G 업데이트 규칙을 통해 수렴 보장을 설정하고, FedAvg, QoS 인식 평균화 및 다양체 기반 집계와 같은 특별한 경우를 회복하는 것을 보여줌.

Conclusion: 이질적이고 노이즈가 많은 조건에서도 안정성과 정확성을 개선했음을 실험으로 입증함.

Abstract: Federated learning (FL) deployed over quantum enabled and heterogeneous classical networks faces significant performance degradation due to uneven client quality, stochastic teleportation fidelity, device instability, and geometric mismatch between local and global models. Classical aggregation rules assume euclidean topology and uniform communication reliability, limiting their suitability for emerging quantum federated systems. This paper introduces A2G (Adaptive Aggregation with Two Gains), a dual gain framework that jointly regulates geometric blending through a geometry gain and modulates client importance using a QoS gain derived from teleportation fidelity, latency, and instability. We develop the A2G update rule, establish convergence guarantees under smoothness and bounded variance assumptions, and show that A2G recovers FedAvg, QoS aware averaging, and manifold based aggregation as special cases. Experiments on a quantum classical hybrid testbed demonstrate improved stability and higher accuracy under heterogeneous and noisy conditions.

</details>


### [42] [Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value](https://arxiv.org/abs/2512.03399)
*Joe Edelman,Tan Zhi-Xuan,Ryan Lowe,Oliver Klingefjord,Vincent Wang-Mascianica,Matija Franklin,Ryan Othniel Kearns,Ellie Hain,Atrisha Sarkar,Michiel Bakker,Fazl Barez,David Duvenaud,Jakob Foerster,Iason Gabriel,Joseph Gubbels,Bryce Goodman,Andreas Haupt,Jobst Heitzig,Julian Jara-Ettinger,Atoosa Kasirzadeh,James Ravi Kirkpatrick,Andrew Koh,W. Bradley Knox,Philipp Koralus,Joel Lehman,Sydney Levine,Samuele Marro,Manon Revel,Toby Shorin,Morgan Sutherland,Michael Henry Tessler,Ivan Vendrov,James Wilken-Smith*

Main category: cs.LG

TL;DR: AI 시스템과 이를 형성하는 제도의 동시 정렬이 필요하다.


<details>
  <summary>Details</summary>
Motivation: 개별 AI 시스템을 운영자의 의도에 맞추는 것만으로는 사회적 이익을 보장할 수 없다.

Method: 가치의 두꺼운 모델을 제안하여 시스템이 지속적인 가치와 일시적인 선호를 구별할 수 있도록 한다.

Result: AI 가치 관리, 규범적으로 유능한 에이전트, 윈-윈 협상 시스템 등 5가지 분야에서 이 접근법을 입증한다.

Conclusion: 가치와 규범을 구조화하는 방식으로 AI 시스템의 효과적인 운영을 지원해야 한다.

Abstract: Beneficial societal outcomes cannot be guaranteed by aligning individual AI systems with the intentions of their operators or users. Even an AI system that is perfectly aligned to the intentions of its operating organization can lead to bad outcomes if the goals of that organization are misaligned with those of other institutions and individuals. For this reason, we need full-stack alignment, the concurrent alignment of AI systems and the institutions that shape them with what people value. This can be done without imposing a particular vision of individual or collective flourishing. We argue that current approaches for representing values, such as utility functions, preference orderings, or unstructured text, struggle to address these and other issues effectively. They struggle to distinguish values from other signals, to support principled normative reasoning, and to model collective goods. We propose thick models of value will be needed. These structure the way values and norms are represented, enabling systems to distinguish enduring values from fleeting preferences, to model the social embedding of individual choices, and to reason normatively, applying values in new domains. We demonstrate this approach in five areas: AI value stewardship, normatively competent agents, win-win negotiation systems, meaning-preserving economic mechanisms, and democratic regulatory institutions.

</details>


### [43] [GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test](https://arxiv.org/abs/2512.03428)
*Ziyi Ding,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: GaussDetect-LiNGAM은 이원 인과 발견을 위한 새로운 접근법으로, 정규성 테스트를 필요로 하지 않는다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 인과 추론의 효율성과 실제 적용 가능성을 높이기 위해 정규성 테스트의 필요성을 제거하고자 한다.

Method: 가우시안 노이즈와 잔차 독립성 간의 기본적인 동등성을 활용하여 리니어, 비순환, 외생성을 가정하는 LiNGAM 환경에서 역회귀 모델의 회귀자와 잔차 간의 독립성을 검증한다.

Result: 실험 결과는 이 동등성을 검증하고 GaussDetect-LiNGAM이 다양한 노이즈 유형과 샘플 크기에서 높은 일관성을 유지하는 동시에 결정 당 테스트 수를 줄임을 보여준다.

Conclusion: 본 방법은 인과 추론의 효율성을 향상시키고, LiNGAM이 실제 시나리오에서 접근 가능하고 신뢰성 있게 만든다.

Abstract: We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.

</details>


### [44] [Bayesian Event-Based Model for Disease Subtype and Stage Inference](https://arxiv.org/abs/2512.03467)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: BEBMS는 SuStaIn보다 여러 작업에서 우수한 성능을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 만성 질환은 환자마다 진전 과정이 다르게 진행되므로 구조적 이질성을 포착할 필요성이 있습니다.

Method: 본 논문에서는 사건 기반 모델의 원리에 기반한 베이esian 하위 유형 변형 모델(BEBMS)을 개발하고, 다양한 합성 데이터 실험에서 SuStaIn과 성능을 비교합니다.

Result: BEBMS는 순서, 단계 및 하위 유형 할당 작업에서 SuStaIn을 크게 능가합니다.

Conclusion: BEBMS는 알츠하이머 데이터 세트에 적용했을 때 SuStaIn보다 더 일관된 결과를 보여줍니다.

Abstract: Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.

</details>


### [45] [CoGraM: Context-sensitive granular optimization method with rollback for robust model fusion](https://arxiv.org/abs/2512.03610)
*Julius Lenz*

Main category: cs.LG

TL;DR: 이 논문에서는 재훈련 없이 신경망을 병합하는 방법인 CoGraM을 제안하며, 이는 정확성을 유지하고 안정성을 도모하는 다단계 최적화 방법이다.


<details>
  <summary>Details</summary>
Motivation: 분산 학습에서 재훈련 없이 신경망을 병합하는 것이 중요하나 기존 방법들이 정확성을 잃고 불안정한 문제가 있다.

Method: CoGraM은 다단계, 맥락 민감, 손실 기반의 반복 최적화 방법으로, 결정이 손실 차이 및 임계값과 일치하도록 조정하며 해로운 업데이트를 롤백을 통해 방지한다.

Result: CoGraM은 Fisher와 같은 기존 방법들의 약점을 해결하며, 병합된 신경망의 성능을 크게 향상시킨다.

Conclusion: CoGraM은 신경망 병합에서의 효율성과 신뢰성을 개선하는 데 기여한다.

Abstract: Merging neural networks without retraining is central to federated and distributed learning. Common methods such as weight averaging or Fisher merging often lose accuracy and are unstable across seeds. CoGraM (Contextual Granular Merging) is a multi-stage, context-sensitive, loss-based, and iterative optimization method across layers, neurons, and weight levels that aligns decisions with loss differences and thresholds and prevents harmful updates through rollback. CoGraM is an optimization method that addresses the weaknesses of methods such as Fisher and can significantly improve the merged network.

</details>


### [46] [Adaptive Identification and Modeling of Clinical Pathways with Process Mining](https://arxiv.org/abs/2512.03787)
*Francesco Vitale,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 이 논문은 임상 경로의 모델링을 위한 두 단계의 프로세스 마이닝 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 임상 경로는 환자의 치료 절차를 모델링한 전문화된 의료 계획으로, 이를 통해 환자 치료를 표준화하고 자원 사용을 줄이며 회복을 가속화하는 것이 필요하다.

Method: 프로세스 마이닝을 활용한 두 단계의 모델링 방법을 제안하며, 첫 번째 단계에서는 역사적 데이터를 수집하여 치료 과정을 프로세스 모델 형식으로 캡처하고, 두 번째 단계에서는 새로운 데이터를 기준 모델과 비교하여 일치성을 검증한다.

Result: 기준 모델에 대한 일치성 검증 결과를 바탕으로 새로운 변종이나 질병 조합에 맞춘 보다 구체적인 모델로 지식 베이스를 확장할 수 있다.

Conclusion: 우리의 방법은 COVID-19 합병증이 다양한 SARS-CoV-2 감염을 위한 환자 치료를 시뮬레이션하는 벤치마크 데이터셋인 Synthea를 사용하여 입증되었으며, 95.62% AUC의 충분한 정밀도를 유지하면서 67.11%의 호칭 단순성을 기록하였다.

Abstract: Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.

</details>


### [47] [Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($λ$,$λ$))-GA](https://arxiv.org/abs/2512.03805)
*Tai Nguyen,Phong Le,André Biedenkapp,Carola Doerr,Nguyen Dang*

Main category: cs.LG

TL;DR: 이 논문은 Dynamic Algorithm Configuration(DAC)에서 강화 학습(RL) 알고리즘을 활용하여 제어 정책을 식별하는 효율성을 분석하고, DDQN과 PPO의 한계를 개선하기 위한 해결책을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 알고리즘 구성의 최적화 문제 해결을 위한 RL의 강점을 활용하고자 함.

Method: (1+($λ$,$λ$))-GA의 인구 크기 매개변수를 제어하는 심층 강화 학습 알고리즘의 체계적 분석 수행.

Result: DDQN과 PPO에서 두 가지 주요 한계인 확장성 저하와 학습 불안정을 확인하고, 각 문제를 해결하기 위한 목표 지향적 솔루션을 제시함.

Conclusion: ADA 전략이 있는 DDQN이 이론적으로 파생된 정책의 성능에 필적하는 결과를 보이며, 샘플 효율성을 크게 개선하여 기존 DAC 접근 방식보다 우수함을 입증함.

Abstract: Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($λ$,$λ$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.

</details>


### [48] [Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models](https://arxiv.org/abs/2512.03882)
*Haidong Kang,Wei Wu,Hanling Wang*

Main category: cs.LG

TL;DR: FSCIL은 이전 클래스에서 학습한 내용을 보호하며 새로운 클래스를 학습하는 도전적인 지속적 학습 패러다임이다. 본 논문은 공격이 FSCIL에 미치는 영향을 포괄적으로 연구하고, 전문가 지식 없이도 FSCIL에 최적화된 공격 방법을 자동으로 탐색할 수 있는 ACraft 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: FSCIL에서 보안 문제를 고려하는 연구가 부족했기 때문이다.

Method: 전문가 설계 공격 방법을 체계적으로 탐구하고, LLM을 활용한 ACraft 방법과 새로운 강화 학습 접근 방식을 제안한다.

Result: ACraft는 최신 FSCIL 방법들의 성능을 크게 저하시켰고, 비용을 낮추면서 전문가 설계 공격 방법보다 더욱 효과적임을 입증했다.

Conclusion: ACraft 방법을 통해 FSCIL의 공격 방법을 최적화할 수 있으며, 이는 공격의 비용을 최소화하면서도 성능을 극대화할 수 있다.

Abstract: Few-shot class incremental learning (FSCIL) is a more realistic and challenging paradigm in continual learning to incrementally learn unseen classes and overcome catastrophic forgetting on base classes with only a few training examples. Previous efforts have primarily centered around studying more effective FSCIL approaches. By contrast, less attention was devoted to thinking the security issues in contributing to FSCIL. This paper aims to provide a holistic study of the impact of attacks on FSCIL. We first derive insights by systematically exploring how human expert-designed attack methods (i.e., PGD, FGSM) affect FSCIL. We find that those methods either fail to attack base classes, or suffer from huge labor costs due to relying on huge expert knowledge. This highlights the need to craft a specialized attack method for FSCIL. Grounded in these insights, in this paper, we propose a simple yet effective ACraft method to automatically steer and discover optimal attack methods targeted at FSCIL by leveraging Large Language Models (LLMs) without human experts. Moreover, to improve the reasoning between LLMs and FSCIL, we introduce a novel Proximal Policy Optimization (PPO) based reinforcement learning to optimize learning, making LLMs generate better attack methods in the next generation by establishing positive feedback. Experiments on mainstream benchmarks show that our ACraft significantly degrades the performance of state-of-the-art FSCIL methods and dramatically beyond human expert-designed attack methods while maintaining the lowest costs of attack.

</details>


### [49] [Quantum-Classical Physics-Informed Neural Networks for Solving Reservoir Seepage Equations](https://arxiv.org/abs/2512.03923)
*Xiang Rao,Yina Liu,Yuxuan Shen*

Main category: cs.LG

TL;DR: 이 논문은 양자-고전 물리 정보 신경망(QCPINN)을 제안하여 유체 침투의 부분 미분 방정식을 해결하고, 전통적인 방법의 한계를 극복하여 예측 정확성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 유전 침투를 위한 부분 미분 방정식(PDE) 해결은 석유 및 가스 전개 최적화와 생산 성능 예측에 필수적이다.

Method: QCPINN은 고전적인 전처리/후처리 네트워크와 이산 변수 양자 핵심을 통합하여 양자 중첩과 얽힘을 활용하고, 물리적 제약을 내재시켜 솔루션 일관성을 보장한다.

Result: 세 가지 양자 회로 구조(Cascade, Cross-mesh, Alternate)에 대해 수치 실험을 통해 QCPINN이 고전적 PINN보다 적은 매개변수로 높은 예측 정확성을 달성함을 입증하였다.

Conclusion: 우리의 연구는 QCPINN이 유전 공학 응용을 위한 가능성을 검증하였으며, 양자 컴퓨팅 연구와 석유 및 가스 공학의 산업적 실천 간의 격차를 해소하였다.

Abstract: Solving partial differential equations (PDEs) for reservoir seepage is critical for optimizing oil and gas field development and predicting production performance. Traditional numerical methods suffer from mesh-dependent errors and high computational costs, while classical Physics-Informed Neural Networks (PINNs) face bottlenecks in parameter efficiency, high-dimensional expression, and strong nonlinear fitting. To address these limitations, we propose a Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) and apply it to three typical reservoir seepage models for the first time: the pressure diffusion equation for heterogeneous single-phase flow, the nonlinear Buckley-Leverett (BL) equation for two-phase waterflooding, and the convection-diffusion equation for compositional flow considering adsorption. The QCPINN integrates classical preprocessing/postprocessing networks with a DV quantum core, leveraging quantum superposition and entanglement to enhance high-dimensional feature mapping while embedding physical constraints to ensure solution consistency. We test three quantum circuit topologies (Cascade, Cross-mesh, Alternate) and demonstrate through numerical experiments that QCPINNs achieve high prediction accuracy with fewer parameters than classical PINNs. Specifically, the Alternate topology outperforms others in heterogeneous single-phase flow and two-phase BL equation simulations, while the Cascade topology excels in compositional flow with convection-dispersion-adsorption coupling. Our work verifies the feasibility of QCPINN for reservoir engineering applications, bridging the gap between quantum computing research and industrial practice in oil and gas engineering.

</details>


### [50] [Learning Steerable Clarification Policies with Collaborative Self-play](https://arxiv.org/abs/2512.04068)
*Jonathan Berant,Maximillian Chen,Adam Fisch,Reza Aghajani,Fantine Huot,Mirella Lapata,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 이 연구는 불확실성을 관리하기 위한 조정 가능한 정책을 훈련하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: AI 어시스턴트가 모호한 쿼리를 처리하기 위해 불확실성을 관리하는 정책이 필요합니다.

Method: 자기 학습(self-play)을 사용하여 두 개의 에이전트(사용자 및 AI 어시스턴트)를 생성하여 대화를 생성하고 AI 어시스턴트가 응답 방안을 결정합니다.

Result: 모델은 최종 보상을 극대화하는 행동을 선택하도록 훈련됩니다.

Conclusion: 훈련된 모델은 제공된 비용에 따라 예측 가능하게 행동을 변경하는 정책을 생성하며, 높은 보상과 정확도로 이어집니다.

Abstract: To handle underspecified or ambiguous queries, AI assistants need a policy for managing their uncertainty to determine (a) when to guess the user intent and answer directly, (b) when to enumerate and answer multiple possible intents, and (c) when to ask a clarifying question. However, such policies are contextually dependent on factors such as user preferences or modality. For example, enumerating multiple possible user intentions is cumbersome on small screens or in a voice setting. In this work, we propose to train steerable policies for managing this uncertainty using self-play. Given two agents, one simulating a user and the other an AI assistant, we generate conversations where the user issues a potentially ambiguous query, and the assistant needs to determine how to respond. Importantly, the model takes as input the numerical cost of each clarification question, and each generated word, and is asked to take the action that will maximize its final reward, which is the cost-penalized accuracy. We use Reinforced Self-Training (ReST) to train our model to achieve high reward and show this leads to a steerable policy that changes its behavior predictably conditioned on the provided costs, leading to higher reward and accuracy. Moreover, our procedure also generalizes to numerical cost values that were unobserved at training time.

</details>
