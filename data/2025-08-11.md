<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 4]
- [cs.LG](#cs.LG) [Total: 49]
- [cs.CR](#cs.CR) [Total: 27]
- [cs.AI](#cs.AI) [Total: 28]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems](https://arxiv.org/abs/2508.05687)
*Alistair Reid,Simon O'Callaghan,Liam Carroll,Tiberio Caetano*

Main category: cs.MA

TL;DR: 조직들이 LLM 기반 AI 에이전트를 채택하고 있으며, 단일 에이전트에서 상호 연결된 다중 에이전트 네트워크로 발전하고 있다. 그러나 안전한 에이전트 집합이 반드시 안전한 에이전트 집합을 의미하는 것은 아니다. 본 보고서는 다중 에이전트 AI 시스템의 위험 식별 및 분석을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 조직들이 AI 에이전트를 통제된 환경에서 배치하기 시작함에 따라, 이들 시스템의 상호작용에서 발생하는 새로운 실패 방식에 대한 연구가 필요하다.

Method: 다중 에이전트 시스템에서의 실패 모드를 분석하고, 이를 평가하기 위한 도구 키트를 제공한다.

Result: 여섯 가지 주요 실패 모드를 식별하고, 각 모드에 대한 평가 도구를 제시하였다.

Conclusion: 현재 LLM의 행동 이해에 대한 한계를 고려할 때, 이 연구는 점진적인 유효성 증대를 통해 위험 관리의 기초를 제공한다.

Abstract: Organisations are starting to adopt LLM-based AI agents, with their
deployments naturally evolving from single agents towards interconnected,
multi-agent networks. Yet a collection of safe agents does not guarantee a safe
collection of agents, as interactions between agents over time create emergent
behaviours and induce novel failure modes. This means multi-agent systems
require a fundamentally different risk analysis approach than that used for a
single agent.
  This report addresses the early stages of risk identification and analysis
for multi-agent AI systems operating within governed environments where
organisations control their agent configurations and deployment. In this
setting, we examine six critical failure modes: cascading reliability failures,
inter-agent communication failures, monoculture collapse, conformity bias,
deficient theory of mind, and mixed motive dynamics. For each, we provide a
toolkit for practitioners to extend or integrate into their existing frameworks
to assess these failure modes within their organisational contexts.
  Given fundamental limitations in current LLM behavioural understanding, our
approach centres on analysis validity, and advocates for progressively
increasing validity through staged testing across stages of abstraction and
deployment that gradually increases exposure to potential negative impacts,
while collecting convergent evidence through simulation, observational
analysis, benchmarking, and red teaming. This methodology establishes the
groundwork for robust organisational risk management as these LLM-based
multi-agent systems are deployed and operated.

</details>


### [2] [Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control](https://arxiv.org/abs/2508.05702)
*Yan Zhang*

Main category: cs.MA

TL;DR: Grid-Agent는 전력망의 복잡성을 해결하기 위한 AI 기반의 자율 프레임워크로, LLM과 다중 에이전트 강화 학습을 결합하여 실시간으로 전력망 위반을 감지하고 수정한다.


<details>
  <summary>Details</summary>
Motivation: DER과 EV의 확산 및 극단적인 날씨 사건의 증가로 전력망의 계획, 운영 및 관리가 복잡해지고 있다.

Method: Grid-Agent는 LLM과 다중 에이전트 강화 학습을 통해 전력망 위반을 실시간으로 감지하고 수정할 수 있는 자율 AI 프레임워크이다.

Result: IEEE 및 CIGRE 테스트 시스템에서 실험 결과, 훌륭한 위반 완화 성능을 보였다.

Conclusion: 이 프레임워크는 현대 스마트 그리드 애플리케이션에 적합하며, 다양한 네트워크 토폴로지에 대한 지속적인 학습과 적응이 가능하다.

Abstract: The increasing penetration of Distributed Energy Resources (DERs), widespread
adoption of Electric Vehicles (EVs), and the growing frequency of extreme
weather events have significantly increased the complexity of power grid
planning, operation, and management. Traditional rule-based systems and
numerical optimization approaches often struggle with the scale, dynamics, and
adaptability required by modern power networks. This paper introduces
Grid-Agent, an autonomous, AI-driven framework that combines Large Language
Models (LLMs) with multi-agent reinforcement learning to detect and remediate
grid violations in real time. Grid-Agent integrates semantic reasoning with
numerical precision through a modular agent architecture: a planning agent
generates coordinated action sequences using numerical power flow solvers,
while a validation agent evaluates system stability and action effectiveness
via sandboxed execution with safety rollbacks. To ensure scalability,
Grid-Agent incorporates an adaptive multiscale network representation that
dynamically selects optimal encoding schemes based on network size and
complexity. The framework enables coordinated violation resolution through
optimizing switch configurations, battery deployment, and load curtailment
strategies. Experimental results in standard IEEE and CIGRE test systems (IEEE
69-bus, CIGRE MV, and IEEE 30-bus) demonstrate superior violation mitigation
performance. Additionally, the framework's built-in data collection and
learning capabilities enable continuous learning and adaptation to diverse
network topologies. The autonomous nature of the framework makes it
particularly suitable for modern smart grid applications requiring rapid
response to dynamic operating conditions.

</details>


### [3] [Flow-Based Task Assignment for Large-Scale Online Multi-Agent Pickup and Delivery](https://arxiv.org/abs/2508.05890)
*Yue Zhang,Zhe Chen,Daniel Harabor,Pierre Le Bodic,Peter J. Stuckey*

Main category: cs.MA

TL;DR: 온라인 다중 요원 픽업 및 배달(MAPD) 문제를 연구하며, 복잡한 추론 없이 최소 비용 흐름을 통해 작업 할당을 수행함으로써 20000명 이상의 요원과 30000개의 작업에 대해 효과적으로 스케일링한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 다중 요원 픽업 및 배달 문제를 해결하기 위해 실시간 제약 조건 하에서의 효율적인 작업 할당 방법이 필요하다.

Method: 작업 할당의 하위 문제를 환경 그래프에 대한 최소 비용 흐름으로 공식화하고, 이를 통해 요원들이 동시에 작업에 할당되고 경로를 따라 라우팅될 수 있도록 한다. 또한 실시간 교통 추정을 포함하는 두 가지 혼잡 인식 엣지 비용 모델을 도입하여 솔루션 품질을 개선한다.

Result: 1초 계획 시간 내에 20000명 이상의 요원과 30000개의 작업을 처리할 수 있는 스케일링 능력을 가지며, 기존 기준보다 계산 효율성과 할당 품질 모두에서 우수하다.

Conclusion: 제안된 방법은 실시간 실행을 지원하고, 더 나은 효율성과 품질로 온라인 MAPD 문제를 해결할 수 있다.

Abstract: We study the problem of online Multi-Agent Pickup and Delivery (MAPD), where
a team of agents must repeatedly serve dynamically appearing tasks on a shared
map. Existing online methods either rely on simple heuristics, which result in
poor decisions, or employ complex reasoning, which suffers from limited
scalability under real-time constraints. In this work, we focus on the task
assignment subproblem and formulate it as a minimum-cost flow over the
environment graph. This eliminates the need for pairwise distance computations
and allows agents to be simultaneously assigned to tasks and routed toward
them. The resulting flow network also supports efficient guide path extraction
to integrate with the planner and accelerates planning under real-time
constraints. To improve solution quality, we introduce two congestion-aware
edge cost models that incorporate real-time traffic estimates. This approach
supports real-time execution and scales to over 20000 agents and 30000 tasks
within 1-second planning time, outperforming existing baselines in both
computational efficiency and assignment quality.

</details>


### [4] [Policy Optimization in Multi-Agent Settings under Partially Observable Environments](https://arxiv.org/abs/2508.06061)
*Ainur Zhaikhan,Malek Khammassi,Ali H. Sayed*

Main category: cs.MA

TL;DR: 본 연구는 다중 에이전트 강화 학습 문제에서 부분적으로 관찰 가능한 전역 상태를 추정하기 위한 적응형 사회 학습을 활용합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습(MARL) 문제에서 효율적인 상태 추정을 위해 새로운 접근 방식을 개발하고자 합니다.

Method: 사회 학습과 강화 학습을 병행하여 구현하며, 사회 학습의 한 단계를 거친 후 MARL의 한 단계로 전환합니다.

Result: 제안된 방법론의 성능은 실제 상태를 알 때 강화 학습의 성능에 접근할 수 있음을 시뮬레이션 결과로 확인했습니다.

Conclusion: 이 방법은 기존의 두 배속 학습 프레임워크의 필요성을 제거하고 이론적 보장을 제공합니다.

Abstract: This work leverages adaptive social learning to estimate partially observable
global states in multi-agent reinforcement learning (MARL) problems. Unlike
existing methods, the proposed approach enables the concurrent operation of
social learning and reinforcement learning. Specifically, it alternates between
a single step of social learning and a single step of MARL, eliminating the
need for the time- and computation-intensive two-timescale learning frameworks.
Theoretical guarantees are provided to support the effectiveness of the
proposed method. Simulation results verify that the performance of the proposed
methodology can approach that of reinforcement learning when the true state is
known.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty](https://arxiv.org/abs/2508.05659)
*Jeroen F. Uleman,Loes Crielaard,Leonie K. Elsenburg,Guido A. Veldhuis,Karien Stronks,Naja Hulvej Rod,Rick Quax,Vítor V. Vasconcelos*

Main category: cs.LG

TL;DR: Causal loop diagrams (CLDs)를 동적 분석 및 개입 전략에 대한 정보 제공의 한계와 함께, CLDs를 탐색적 시스템 역학 모델(SDM)으로 변환하는 Diagrams-to-Dynamics (D2D) 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: CLDs는 복잡한 문제에 대한 가설적 인과 구조를 표현하는 데 널리 사용되지만, 동적 분석을 지원하는 데에는 한계가 있다.

Method: D2D 방법은 CLDs의 구조적 정보를 활용하여 사용자 입력 최소화로 SDMs로 변환한다.

Result: D2D는 고순위와 저순위의 지렛대 포인트를 구별하는 데 도움을 주며, 데이터 기반 모델과 더 일관된 결과를 보였다.

Conclusion: D2D는 CLDs로 작업하는 연구자들에게 동적 모델링 장벽을 낮추고, 추가적인 검증을 통해 유용성을 확립할 것으로 기대된다.

Abstract: Causal loop diagrams (CLDs) are widely used in health and environmental
research to represent hypothesized causal structures underlying complex
problems. However, as qualitative and static representations, CLDs are limited
in their ability to support dynamic analysis and inform intervention
strategies. Additionally, quantitative CLD analysis methods like network
centrality analysis often lead to false inference. We propose
Diagrams-to-Dynamics (D2D), a method for converting CLDs into exploratory
system dynamics models (SDMs) in the absence of empirical data. With minimal
user input - following a protocol to label variables as stocks,
flows/auxiliaries, or constants - D2D leverages the structural information
already encoded in CLDs, namely, link existence and polarity, to simulate
hypothetical interventions and explore potential leverage points under
uncertainty. Results suggest that D2D helps distinguish between high- and
low-ranked leverage points. We compare D2D to a data-driven SDM constructed
from the same CLD and variable labeling. D2D showed greater consistency with
the data-driven model than network centrality analysis, while providing
uncertainty estimates and guidance for future data collection. The method is
implemented in an open-source Python package and a web-based application to
support further testing and lower the barrier to dynamic modeling for
researchers working with CLDs. We expect additional validation will further
establish the approach's utility across a broad range of cases and domains.

</details>


### [6] [A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics](https://arxiv.org/abs/2508.05724)
*Massimiliano Romiti*

Main category: cs.LG

TL;DR: 물리 법칙을 가중 지식 그래프로 표현하고 분석하는 새로운 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 물리학의 복잡한 상호작용을 이해하고 설명하기 위해서는 효과적인 데이터 표현과 분석 방법이 필요하다.

Method: 659개의 물리 방정식 데이터베이스를 구축하고, GAT를 이용하여 링크 예측을 수행하였다.

Result: 테스트 AUC 0.9742를 달성하며, 기존 방법들보다 훨씬 향상된 성능을 보였다.

Conclusion: 이 프레임워크는 물리학의 다양한 하위 분야에 대한 표적 분석을 위한 전문 데이터셋을 생성할 수 있는 가능성을 지닌다.

Abstract: This work introduces a novel framework for representing and analyzing
physical laws as a weighted knowledge graph. We constructed a database of 659
distinct physical equations, subjected to rigorous semantic cleaning to resolve
notational ambiguities, resulting in a corpus of 400 advanced physics
equations. We developed an enhanced graph representation where both physical
concepts and equations are nodes, connected by weighted inter-equation bridges.
These weights are objectively defined using normalized metrics for variable
overlap, physics-informed importance scores, and bibliometric data. A Graph
Attention Network (GAT) was trained for link prediction, achieving a test AUC
of 0.9742 +/- 0.0018 across five independent runs, significantly outperforming
both classical heuristics (best baseline AUC: 0.9487) and established GNN
architectures like GraphSAGE (AUC: 0.9504, p = 0.029). Statistical testing
confirmed significance of all comparisons (p < 0.05), with 2.7% improvement
over the best baseline. Our analysis reveals three key findings: (i) The model
autonomously rediscovers the known macroscopic structure of physics,
identifying strong conceptual axes between Electromagnetism and Statistical
Mechanics. (ii) It identifies central hub equations that serve as critical
bridges between multiple physical domains. (iii) The model generates stable,
computationally-derived hypotheses for cross-domain relationships, identifying
both known principles and suggesting novel mathematical analogies for further
theoretical investigation. The framework can generate hundreds of such
hypotheses, enabling the creation of specialized datasets for targeted analysis
of specific physics subfields. Code and data available at
https://github.com/kingelanci/graphysics

</details>


### [7] [Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems](https://arxiv.org/abs/2508.05778)
*Jaemin Oh,Jinsil Lee,Youngjoon Hong*

Main category: cs.LG

TL;DR: 본 연구에서는 비선형 상태 공간 모델에서의 데이터 기반의 너징 방법인 신경망 너징을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 비선형 설정에서 효과적인 너징 항을 설계하는 것은 상당히 도전적입니다.

Method: 비선형 상태 공간 모델에서 너징 항을 학습하기 위해 신경망 너징이라는 데이터 기반 방법을 제안합니다.

Result: 세 가지 혼돈 행동을 보이는 문제에 대해 제안된 접근 방식을 평가합니다: Lorenz 96 모델, Kuramoto--Sivashinsky 방정식, Kolmogorov 흐름.

Conclusion: 제안된 접근 방식은 효과적인 너징 항을 제공할 수 있으며 비선형 동역학을 다루는 데 유용합니다.

Abstract: Nudging is an empirical data assimilation technique that incorporates an
observation-driven control term into the model dynamics. The trajectory of the
nudged system approaches the true system trajectory over time, even when the
initial conditions differ. For linear state space models, such control terms
can be derived under mild assumptions. However, designing effective nudging
terms becomes significantly more challenging in the nonlinear setting. In this
work, we propose neural network nudging, a data-driven method for learning
nudging terms in nonlinear state space models. We establish a theoretical
existence result based on the Kazantzis--Kravaris--Luenberger observer theory.
The proposed approach is evaluated on three benchmark problems that exhibit
chaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and
the Kolmogorov flow.

</details>


### [8] [Unsupervised Partner Design Enables Robust Ad-hoc Teamwork](https://arxiv.org/abs/2508.06336)
*Constantin Ruhdorfer,Matteo Bortoletto,Victor Oei,Anna Penzkofer,Andreas Bulling*

Main category: cs.LG

TL;DR: UPD는 인구 기반이 아닌 다중 에이전트 강화 학습 프레임워크로, 사전 훈련된 파트너나 수동 매개변수 조정 없이 적응형 훈련 파트너를 생성합니다.


<details>
  <summary>Details</summary>
Motivation: 강력한 팀워크를 위한 파트너 설계를 자동화하여 강화 학습의 효율성을 높이고자 함.

Method: UPD는 에고 에이전트의 정책을 편향된 무작위 행동과 확률적으로 혼합하여 다양한 파트너를 생성하고, 분산 기반 학습 가능성 지표를 사용하여 에고 에이전트의 현재 학습 경계 근처의 파트너를 우선 순위로 두고 평가합니다.

Result: UPD는 비지도 환경 설계와 통합될 수 있어, 협력 설정에서 레벨과 파트너 분포에 대해 완전히 비지도 커리큘럼을 가능하게 하는 첫 번째 방법입니다. Overcooked-AI와 Overcooked Generalisation Challenge에 대한 평가를 통해 UPD가 인구 기반 및 비인구 기반 기준과 ablation보다 일관되게 우수한 성능을 보임을 증명했습니다.

Conclusion: 사용자 연구에서는 UPD가 모든 기준보다 높은 수익을 달성하며, 더 적응성이 뛰어나고, 인간과 유사하며, 더 나은 협력자로 인식되고 덜 답답하다고 평가되었습니다.

Abstract: We introduce Unsupervised Partner Design (UPD) - a population-free,
multi-agent reinforcement learning framework for robust ad-hoc teamwork that
adaptively generates training partners without requiring pretrained partners or
manual parameter tuning. UPD constructs diverse partners by stochastically
mixing an ego agent's policy with biased random behaviours and scores them
using a variance-based learnability metric that prioritises partners near the
ego agent's current learning frontier. We show that UPD can be integrated with
unsupervised environment design, resulting in the first method enabling fully
unsupervised curricula over both level and partner distributions in a
cooperative setting. Through extensive evaluations on Overcooked-AI and the
Overcooked Generalisation Challenge, we demonstrate that this dynamic partner
curriculum is highly effective: UPD consistently outperforms both
population-based and population-free baselines as well as ablations. In a user
study, we further show that UPD achieves higher returns than all baselines and
was perceived as significantly more adaptive, more human-like, a better
collaborator, and less frustrating.

</details>


### [9] [From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data](https://arxiv.org/abs/2508.05791)
*Haoran Li,Lihao Mai,Muhao Guo,Jiaqi Wu,Yang Weng,Yannan Sun,Ce Jimmy Liu*

Main category: cs.LG

TL;DR: 신뢰할 수 있는 분배망 운영을 위한 정확한 망 토폴로지가 필요하다. 본 연구에서는 다양한 원천의 데이터 통합을 통해 신뢰성 있는 망 토폴로지를 재구성하는 확장 가능한 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 정확한 분배망 토폴로지는 현대 그리드 운영을 위해 필수적이다. 그러나 실제 유틸리티 데이터는 다양한 특성과 품질 수준을 가진 여러 출처에서 나오기 때문에 이 문제를 해결할 필요가 있다.

Method: 이 연구에서는 이종 데이터를 체계적으로 통합하여 신뢰할 수 있는 망 토폴로지를 재구성하는 확장 가능한 프레임워크를 제안하고, 공간적 레이아웃과 신호 도메인에서의 동적 행동을 결합하여 네트워크 연결성을 재구성한다.

Result: 우리의 방법은 Oncor의 서비스 지역에서 8000개 이상의 미터 데이터를 활용해 검증되었으며, 95% 이상의 정확도로 토폴로지를 재구성하고, 신뢰성 보정과 계산 효율성에서 기존 방법에 비해 실질적인 개선을 보였다.

Conclusion: 제안된 프레임워크는 불확실성을 다루면서도 구조적으로 유효한 추론을 보장하여 실제 배포 조건에서 신뢰할 수 있는 토폴로지로 빠르게 수렴할 수 있게 한다.

Abstract: Accurate distribution grid topology is essential for reliable modern grid
operations. However, real-world utility data originates from multiple sources
with varying characteristics and levels of quality. In this work, developed in
collaboration with Oncor Electric Delivery, we propose a scalable framework
that reconstructs a trustworthy grid topology by systematically integrating
heterogeneous data. We observe that distribution topology is fundamentally
governed by two complementary dimensions: the spatial layout of physical
infrastructure (e.g., GIS and asset metadata) and the dynamic behavior of the
system in the signal domain (e.g., voltage time series). When jointly
leveraged, these dimensions support a complete and physically coherent
reconstruction of network connectivity. To address the challenge of uneven data
quality without compromising observability, we introduce a confidence-aware
inference mechanism that preserves structurally informative yet imperfect
inputs, while quantifying the reliability of each inferred connection for
operator interpretation. This soft handling of uncertainty is tightly coupled
with hard enforcement of physical feasibility: we embed operational
constraints, such as transformer capacity limits and radial topology
requirements, directly into the learning process. Together, these components
ensure that inference is both uncertainty-aware and structurally valid,
enabling rapid convergence to actionable, trustworthy topologies under
real-world deployment conditions. The proposed framework is validated using
data from over 8000 meters across 3 feeders in Oncor's service territory,
demonstrating over 95% accuracy in topology reconstruction and substantial
improvements in confidence calibration and computational efficiency relative to
baseline methods.

</details>


### [10] [Optimal Linear Baseline Models for Scientific Machine Learning](https://arxiv.org/abs/2508.05831)
*Alexander DeLise,Kyle Loh,Krish Patel,Meredith Teague,Andrea Arnold,Matthias Chung*

Main category: cs.LG

TL;DR: 본 연구에서는 선형 인코더-디코더 아키텍처를 이용하여 데이터 기반 과학 기계 학습 문제를 해결하기 위한 이론적 프레임워크를 개발하였습니다.


<details>
  <summary>Details</summary>
Motivation: 과학적 도메인에서 기본적인 과제가 물리적 과정에서 관측 신호와 측정으로의 매핑을 특성화하고 계산하는 것입니다.

Method: 우리는 베이즈 리스크 최소화의 관점에서 선형 인코더-디코더 아키텍처를 분석하기 위한 통일된 이론적 프레임워크를 개발합니다.

Result: 우리는 전방 모델링 및 역 회수 작업을 위한 순서 제약이 있는 선형 및 아핀 선형 최적 매핑을 도출하였습니다.

Conclusion: 본 연구는 과학 기계 학습 문제를 위한 학습된 신경망 모델의 이해 및 벤치마킹을 위한 강력한 기준선을 제공합니다.

Abstract: Across scientific domains, a fundamental challenge is to characterize and
compute the mappings from underlying physical processes to observed signals and
measurements. While nonlinear neural networks have achieved considerable
success, they remain theoretically opaque, which hinders adoption in contexts
where interpretability is paramount. In contrast, linear neural networks serve
as a simple yet effective foundation for gaining insight into these complex
relationships. In this work, we develop a unified theoretical framework for
analyzing linear encoder-decoder architectures through the lens of Bayes risk
minimization for solving data-driven scientific machine learning problems. We
derive closed-form, rank-constrained linear and affine linear optimal mappings
for forward modeling and inverse recovery tasks. Our results generalize
existing formulations by accommodating rank-deficiencies in data, forward
operators, and measurement processes. We validate our theoretical results by
conducting numerical experiments on datasets from simple biomedical imaging,
financial factor analysis, and simulations involving nonlinear fluid dynamics
via the shallow water equations. This work provides a robust baseline for
understanding and benchmarking learned neural network models for scientific
machine learning problems.

</details>


### [11] [An Effective Approach for Node Classification in Textual Graphs](https://arxiv.org/abs/2508.05836)
*Rituparna Datta,Nibir Chandra Mandal*

Main category: cs.LG

TL;DR: 새로운 TAPE와 Graphormer 프레임워크를 통합하여 인용 네트워크의 노드 분류 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 네트워크 모델링을 위한 텍스트 속성 그래프(TAG)의 중요성을 강조하며, 효과적인 노드 분류의 도전과제를 해결하기 위해.

Method: TAPE와 Graphormer를 통합한 새로운 프레임워크를 제안하고, ChatGPT를 이용해 논문 내용에서 의미론적으로 풍부한 설명을 생성하여 노드 표현을 향상시키는 방법.

Result: ogbn-arxiv 데이터셋에서 0.772의 분류 정확도로 최신 성능을 달성하고, GCN 베이스라인의 0.713을 초과함.

Conclusion: 우리의 프레임워크는 동적 TAG에서 노드 분류를 위한 확장 가능하고 견고한 솔루션을 제공하며, 향후 연구에 유망한 방향을 제시합니다.

Abstract: Textual Attribute Graphs (TAGs) are critical for modeling complex networks
like citation networks, but effective node classification remains challenging
due to difficulties in integrating rich semantics from text with structural
graph information. Existing methods often struggle with capturing nuanced
domain-specific terminology, modeling long-range dependencies, adapting to
temporal evolution, and scaling to massive datasets. To address these issues,
we propose a novel framework that integrates TAPE (Text-Attributed Graph
Representation Enhancement) with Graphormer. Our approach leverages a large
language model (LLM), specifically ChatGPT, within the TAPE framework to
generate semantically rich explanations from paper content, which are then
fused into enhanced node representations. These embeddings are combined with
structural features using a novel integration layer with learned attention
weights. Graphormer's path-aware position encoding and multi-head attention
mechanisms are employed to effectively capture long-range dependencies across
the citation network. We demonstrate the efficacy of our framework on the
challenging ogbn-arxiv dataset, achieving state-of-the-art performance with a
classification accuracy of 0.772, significantly surpassing the best GCN
baseline of 0.713. Our method also yields strong results in precision (0.671),
recall (0.577), and F1-score (0.610). We validate our approach through
comprehensive ablation studies that quantify the contribution of each
component, demonstrating the synergy between semantic and structural
information. Our framework provides a scalable and robust solution for node
classification in dynamic TAGs, offering a promising direction for future
research in knowledge systems and scientific discovery.

</details>


### [12] [A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance](https://arxiv.org/abs/2508.05876)
*Francesca Ferrara,Lander W. Schillinger Arana,Florian Dörfler,Sarah H. Q. Li*

Main category: cs.LG

TL;DR: 이 연구는 충돌 회피 기동을 위한 의사 결정 과정을 모델링하는 마르코프 의사 결정 프로세스(MDP) 프레임워크와 역사적 데이터를 기반으로 자율 유도 정책을 훈련하는 강화 학습 정책 기울기(RL-PG) 알고리즘을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 충돌 위험을 유지하면서 평균 연료 소비를 최소화하기 위한 기동 결정을 신속하게 내리는 방법을 찾기 위해서입니다.

Method: 충돌 회피 기동(CAM)을 연속 상태, 이산 행동, 유한 지평선 MDP로 모델링하고, 마르코프 정책을 활용하여 기동 타이밍을 결정합니다.

Result: 훈련된 정책은 기존의 24시간 전 기동 정책과 비교할 때 평균 연료 소비를 줄이며, 전체 및 평균 연료 소비를 대폭 최소화합니다.

Conclusion: 훈련된 정책은 역사적 및 합성 접합 사건 모두에서 전체 충돌 위험 보장을 유지하며, 평균 연료 소비를 줄입니다.

Abstract: This work presents a Markov decision process (MDP) framework to model
decision-making for collision avoidance maneuver (CAM) and a reinforcement
learning policy gradient (RL-PG) algorithm to train an autonomous guidance
policy using historic CAM data. In addition to maintaining acceptable collision
risks, this approach seeks to minimize the average fuel consumption of CAMs by
making early maneuver decisions. We model CAM as a continuous state, discrete
action and finite horizon MDP, where the critical decision is determining when
to initiate the maneuver. The MDP model also incorporates analytical models for
conjunction risk, propellant consumption, and transit orbit geometry. The
Markov policy effectively trades-off maneuver delay-which improves the
reliability of conjunction risk indicators-with propellant consumption-which
increases with decreasing maneuver time. Using historical data of tracked
conjunction events, we verify this framework and conduct an extensive ablation
study on the hyper-parameters used within the MDP. On synthetic conjunction
events, the trained policy significantly minimizes both the overall and average
propellant consumption per CAM when compared to a conventional cut-off policy
that initiates maneuvers 24 hours before the time of closest approach (TCA). On
historical conjunction events, the trained policy consumes more propellant
overall but reduces the average propellant consumption per CAM. For both
historical and synthetic conjunction events, the trained policy achieves equal
if not higher overall collision risk guarantees.

</details>


### [13] [The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)](https://arxiv.org/abs/2508.05905)
*Jeffrey Uhlmann*

Main category: cs.LG

TL;DR: 이 논문은 Signed-Zero Ternary (SZT)라는 2비트 양자화를 소개하며, 이는 성능 품질을 감소시키지 않고도 기울기 정보를 결정적으로 제공한다.


<details>
  <summary>Details</summary>
Motivation: 양자화는 일반적으로 성능 품질을 희생하면서 계산 요구사항을 줄이는 방법으로 여겨지지만, 고정된 전체 자원 예산을 기준으로 하면 다른 시각이 나타난다.

Method: 2비트 양자화 방식인 Signed-Zero Ternary (SZT)를 도입하며, 이는 전방 경로에 대한 패널티 없이 기울기 정보를 결정적으로 제공한다.

Result: 분석 결과, SZT는 비양자화 선택지에 비해 정보 밀도를 개선할 수 있다는 증거를 제공한다.

Conclusion: 이 연구는 SZT 양자화가 주어진 자원 예산 내에서 성능과 정보 밀도의 유망한 균형을 제공할 수 있음을 시사한다.

Abstract: Quantization is usually regarded as a means to trade quality of performance
for reduced compute requirements, i.e., as a suboptimal approximation. However,
if examined in terms of a fixed overall resource budget, a very different
perspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit
quantization that deterministically provides gradient information with no
forward-path penalty. Our analysis provides evidence that it may improve
information density compared to non-quantized alternatives.

</details>


### [14] [Dual Signal Decomposition of Stochastic Time Series](https://arxiv.org/abs/2508.05915)
*Alex Glushkovsky*

Main category: cs.LG

TL;DR: 이 연구는 확률적 시간 시리즈를 평균과 분산을 나타내는 이중 신호로 분해하는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 확률적 시간 시리즈에서 평균과 분산을 분리하여 효과적으로 분석하고 예측하기 위한 새로운 접근 방식을 개발하려는 동기.

Method: 기계 학습을 적용하여 원래 시간 시리즈에 맞추고 이중 신호의 불규칙성을 처벌하는 손실 함수를 최소화하여 분해를 수행한다.

Result: 제안된 분해는 시간 시리즈의 평균과 분산에 대해 스무딩 알고리즘으로 사용될 수 있으며, 노이즈를 분리함으로써 디노이징 알고리즘으로도 작용한다.

Conclusion: 이중 신호를 공동 학습함으로써 복잡한 관계를 밝혀내고, 다양한 응용 프로그램에 적합한 방법으로 하이퍼파라미터 조정을 가능하게 한다.

Abstract: The research paper addresses decomposition of a stochastic time series into
three time series representing a dual signal i.e., the mean and the dispersion,
with noise isolated. Decomposition is done by applying machine learning to fit
a dual signal. Machine learning minimizes the loss function which compromises
between fitting the original time series and penalizing irregularities of the
dual signal. The latter includes terms based on the first and second order
derivatives along time. To preserve special patterns, weighting of the
regularization components of the loss function has been introduced based on
Statistical Process Control methodology. The proposed decomposition can be
applied as a smoothing algorithm against the mean and dispersion of the time
series. By isolating noise, the proposed decomposition can be seen as a
denoising algorithm. Two approaches of the learning process have been
considered: sequential and jointly. The former approach learns the mean signal
first and then dispersion. The latter approach fits the dual signal jointly.
Jointly learning can uncover complex relationships for the time series with
heteroskedasticity. Learning has been set by solving the direct non-linear
unconstrained optimization problem or by applying neural networks that have
sequential or twin output architectures. Tuning of the loss function
hyperparameters focuses on the isolated noise to be a stationary stochastic
process without autocorrelation properties. Depending on the applications, the
hyperparameters of the learning can be tuned towards either the discrete states
by stepped signal or smoothed series. The decomposed dual signal can be
represented on the 2D space and used to learn inherent structures, to forecast
both mean and dispersion, or to analyze cross effects in case of multiple time
series.

</details>


### [15] [Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations](https://arxiv.org/abs/2508.05921)
*Siddharth Rout*

Main category: cs.LG

TL;DR: 신경 PDE 솔버의 정확도가 주로 제한된 표현력 때문이 아니라, 열악한 최적화와 잘못된 조건에서 발생하는 문제로 인해 저하된다는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 다양한 표현 능력에도 불구하고, 다중 신뢰성 및 강직한 문제에서 발생하는 잘못된 조건으로 인해 최적화가 부족해진다는 문제를 이해하고자 한다.

Method: Shifted Gaussian Encoding이라는 간단하지만 효과적인 활성화 필터링 단계를 도입하여 행렬의 계급과 표현력을 증가시키면서도 볼록성을 유지한다.

Result: 우리 방법은 안정적은 전파-확산 방정식의 페클레 수를 두 자릿수 이상 확대시키고, 다중 주파수 함수 학습에서 최대 여섯 자릿수의 오류를 낮추며, 백만 개 이상의 매개변수를 가진 심층 네트워크보다 고신뢰도 이미지 벡터를 더 정확하고 빠르게 맞춘다.

Conclusion: 이 작업은 조건화가 깊이가 아니라 과학적 신경 솔버의 병목 현상이라는 것을 강조하고, 간단한 구조적 변화가 상당한 이익을 가져올 수 있음을 보여준다.

Abstract: Accuracy in neural PDE solvers often breaks down not because of limited
expressivity, but due to poor optimisation caused by ill-conditioning,
especially in multi-fidelity and stiff problems. We study this issue in
Physics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural
PDE solvers, and show that asymptotic components in governing equations can
produce highly ill-conditioned activation matrices, severely limiting
convergence. We introduce Shifted Gaussian Encoding, a simple yet effective
activation filtering step that increases matrix rank and expressivity while
preserving convexity. Our method extends the solvable range of Peclet numbers
in steady advection-diffusion equations by over two orders of magnitude,
achieves up to six orders lower error on multi-frequency function learning, and
fits high-fidelity image vectors more accurately and faster than deep networks
with over a million parameters. This work highlights that conditioning, not
depth, is often the bottleneck in scientific neural solvers and that simple
architectural changes can unlock substantial gains.

</details>


### [16] [Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting](https://arxiv.org/abs/2508.05928)
*Si Shen,Peijun Shen,Wenhua Zhao,Danhao Zhu*

Main category: cs.LG

TL;DR: Stable Group-Relative Policy Optimization (S-GRPO)는 불균형한 응답 그룹에서 발생하는 Think-Answer Mismatch 문제를 해결하기 위해 제안된 방법으로, 훈련 안정화를 위한 최적의 노이즈 인식 이점 가중치를 도출한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 추론 모델 훈련에서 Group-Relative Policy Optimization (GRPO)은 중요한 기술이지만, Think-Answer Mismatch라는 중대한 취약성이 존재한다.

Method: S-GRPO는 최적의 노이즈 인식 이점 가중치를 도출하여 훈련을 안정화하는 원칙 있는 강화 내기 기술이다.

Result: S-GRPO는 다양한 모델에서 DR. GRPO를 크게 초과하는 성능을 보였으며 Qwen-Math-7B-Base에서 +2.5%, Llama-3.2-3B-Base에서 +2.2%, Qwen-Math-1.5B-Instruct에서 +2.4%의 성과 향상을 이뤘다.

Conclusion: 이러한 결과는 S-GRPO가 대규모 추론 모델 훈련의 더욱 강력하고 효과적인 방법이 될 수 있음을 강조한다.

Abstract: Group-Relative Policy Optimization (GRPO) is a key technique for training
large reasoning models, yet it suffers from a critical vulnerability: the
\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning
process. This problem is most severe in unbalanced response groups,
paradoxically degrading the signal precisely when it should be most
informative. To address this challenge, we propose Stable Group-Relative Policy
Optimization (S-GRPO), a principled enhancement that derives optimal,
noise-aware advantage weights to stabilize training. Our comprehensive
experiments on mathematical reasoning benchmarks demonstrate S-GRPO's
effectiveness and robustness. On various models, S-GRPO significantly
outperforms DR. GRPO, achieving performance gains of +2.5% on
Qwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on
Qwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn
under 20% synthetic reward noise, S-GRPO maintains stable learning progress.
These results highlight S-GRPO's potential for more robust and effective
training of large-scale reasoning models. \footnote{Code and data are available
at: https://github.com/shenpeijun0212/S-GRPO

</details>


### [17] [Multi-Armed Bandits-Based Optimization of Decision Trees](https://arxiv.org/abs/2508.05957)
*Hasibul Karim Shanto,Umme Ayman Koana,Shadikur Rahman*

Main category: cs.LG

TL;DR: 결정 트리는 적절한 제약 없이 지나치게 복잡해져서 과적합에 쉽게 떨어질 수 있습니다. 이를 해결하기 위해, 본 논문은 강화 학습 기법을 기반으로 한 다중 무장 강도(MAB) 프루닝 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 결정 트리는 과적합 문제를 해결하고 일반화 성능을 향상시키기 위해 프루닝이 필요합니다.

Method: MAB 알고리즘을 이용하여 각 프루닝 작업에서 피드백을 기반으로 최적의 가지 노드를 찾는 탐색-활용 문제로 프루닝 과정을 설정합니다.

Result: 실험 결과, 제안한 접근 방식이 전통적인 프루닝 기법보다 더 나은 예측 성능을 보여주었습니다.

Conclusion: MAB를 활용한 동적이고 확률적인 결정 트리 프루닝 방법의 잠재력을 제시합니다.

Abstract: Decision trees, without appropriate constraints, can easily become overly
complex and prone to overfit, capturing noise rather than generalizable
patterns. To resolve this problem,pruning operation is a crucial part in
optimizing decision trees, as it not only reduces the complexity of trees but
also decreases the probability of generating overfit models. The conventional
pruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning
(REP) are mostly based on greedy approaches that focus on immediate gains in
performance while pruning nodes of the decision tree. However, this might
result in a lower generalization in the long run, compromising the robust
ability of the tree model when introduced to unseen data samples, particularly
when trained with small and complex datasets. To address this challenge, we are
proposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement
learning (RL)-based technique, that will dynamically prune the tree to generate
an optimal decision tree with better generalization. Our proposed approach
assumes the pruning process as an exploration-exploitation problem, where we
are utilizing the MAB algorithms to find optimal branch nodes to prune based on
feedback from each pruning actions. Experimental evaluation on several
benchmark datasets, demonstrated that our proposed approach results in better
predictive performance compared to the traditional ones. This suggests the
potential of utilizing MAB for a dynamic and probabilistic way of decision tree
pruning, in turn optimizing the decision tree-based model.

</details>


### [18] [Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2508.05960)
*Haohui Chen,Zhiyong Chen*

Main category: cs.LG

TL;DR: 오프라인 강화 학습에서, MCRE 프레임워크는 보수성과 성능을 조화롭게 결합하여 더 나은 정책 학습을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 강화 학습에서 학습된 정책과 행동 정책 간의 분포 변화 문제를 해결하기 위해.

Method: MCRE 프레임워크를 통해 Bellman 백업에서 TD 오차와 행동 클로닝 항을 결합하여 보수성과 성능의 균형을 맞춘다. MCRQ 알고리즘은 이 프레임워크를 오프-폴리시 액터-크리틱에 통합한다.

Result: MCRQ는 기준선 및 최신 오프라인 RL 알고리즘보다 우수한 성능을 보인다.

Conclusion: MCRE와 MCRQ는 보수성과 성능 향상을 동시에 달성할 수 있는 효과적인 접근법이다.

Abstract: Offline reinforcement learning (RL) seeks to learn optimal policies from
static datasets without further environment interaction. A key challenge is the
distribution shift between the learned and behavior policies, leading to
out-of-distribution (OOD) actions and overestimation. To prevent gross
overestimation, the value function must remain conservative; however, excessive
conservatism may hinder performance improvement. To address this, we propose
the mildly conservative regularized evaluation (MCRE) framework, which balances
conservatism and performance by combining temporal difference (TD) error with a
behavior cloning term in the Bellman backup. Building on this, we develop the
mildly conservative regularized Q-learning (MCRQ) algorithm, which integrates
MCRE into an off-policy actor-critic framework. Experiments show that MCRQ
outperforms strong baselines and state-of-the-art offline RL algorithms on
benchmark datasets.

</details>


### [19] [LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning](https://arxiv.org/abs/2508.05977)
*Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan*

Main category: cs.LG

TL;DR: 과학적 기계 학습 분야에서, 효과적인 보상 함수 설계는 RL에서 여전히 도전 과제가 되고 있으며, 특히 작업 목표가 수치적으로 명시하기 어려운 환경에서 더욱 그렇다.


<details>
  <summary>Details</summary>
Motivation: 기존 작업의 보상 함수는 주로 휴리스틱, 수동 엔지니어링 또는 작업별 조정에 기반하고 있음.

Method: 현재 상태와 목표 의미 지침을 정렬하여 보상을 계산하는 의미적 정렬 강화 학습 방법을 도입함.

Result: 여러 환경에서 접근 방식을 평가하고, 보편적인 수작업 보상 함수가 없어도 의미적 보상이 경쟁력 있는 제어 행동을 달성하는 데 학습을 유도할 수 있음을 보여줌.

Conclusion: 이 연구는 언어 임베딩 공간과 기존 유클리드 공간 간의 상관 관계를 입증하며, 에이전트의 행동을 자연어 목표와 정렬하고 대형 언어 모델(LLMs)과 유연한 제어 응용 프로그램의 통합을 위한 기반을 마련함.

Abstract: In the domain of scientific machine learning, designing effective reward
functions remains a challenge in reinforcement learning (RL), particularly in
environments where task goals are difficult to specify numerically. Reward
functions in existing work are predominantly based on heuristics, manual
engineering, or task-specific tuning. In this work, we introduce a semantically
aligned reinforcement learning method where rewards are computed by aligning
the current state with a target semantic instruction using a
Sentence-Bidirectional Encoder Representations from Transformers (SBERT).
Instead of relying on manually defined reward functions, the policy receives
feedback based on the reward, which is a cosine similarity between the goal
textual description and the statement description in the episode. We evaluated
our approach in several environments and showed that semantic reward can guide
learning to achieve competitive control behavior, even in the absence of
hand-crafted reward functions. Our study demonstrates a correlation between the
language embedding space and the conventional Euclidean space. This framework
opens new horizons for aligning agent behavior with natural language goals and
lays the groundwork for a more seamless integration of larger language models
(LLMs) and fluid control applications.

</details>


### [20] [Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning](https://arxiv.org/abs/2508.05984)
*Ankur Naskar,Gugan Thoppe,Vijay Gupta*

Main category: cs.LG

TL;DR: 이 논문에서는 비선형 고정점 방정식 해결을 위한 알고리즘의 최적 수렴 속도를 보장하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 비선형 고정점 방정식을 해결하는 알고리즘(예: 평균 보상 Q-러닝 및 TD-러닝)에서 매개변수가 없는 최적 수렴 속도를 달성하는 것이 어려웠습니다.

Method: 우리는 평균 오차를 비선형 섭동을 포함하는 선형 재귀로 다시 표현하고, 이 섭동을 적절히 유도된 준거의 단조성과 결합하여 비선형성을 제어하는 방법을 제안합니다.

Result: 주요 결과로는 평균 보상 및 지수 할인 설정에서 Q-러닝을 위한 첫 번째 매개변수 없는 최적 속도 $	ilde{O}(1/	ext{sqrt}{t})$를 도출했습니다.

Conclusion: 이 결과는 동기 및 비동기 업데이트, 단일 에이전트 및 분산 배포, 시뮬레이터로부터 얻은 데이터 스트림 또는 마르코프 경로를 포함하는 광범위한 프레임워크에 적용됩니다.

Abstract: Algorithms for solving \textit{nonlinear} fixed-point equations -- such as
average-reward \textit{$Q$-learning} and \textit{TD-learning} -- often involve
semi-norm contractions. Achieving parameter-free optimal convergence rates for
these methods via Polyak--Ruppert averaging has remained elusive, largely due
to the non-monotonicity of such semi-norms. We close this gap by (i.) recasting
the averaged error as a linear recursion involving a nonlinear perturbation,
and (ii.) taming the nonlinearity by coupling the semi-norm's contraction with
the monotonicity of a suitably induced norm. Our main result yields the first
parameter-free $\tilde{O}(1/\sqrt{t})$ optimal rates for $Q$-learning in both
average-reward and exponentially discounted settings, where $t$ denotes the
iteration index. The result applies within a broad framework that accommodates
synchronous and asynchronous updates, single-agent and distributed deployments,
and data streams obtained either from simulators or along Markovian
trajectories.

</details>


### [21] [Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal](https://arxiv.org/abs/2508.05988)
*Wenhao Zeng,Yaoning Wang,Chao Hu,Yuling Shi,Chengcheng Wan,Hongyu Zhang,Xiaodong Gu*

Main category: cs.LG

TL;DR: 이 논문에서는 코드 추론을 위한 CoT 압축에 대한 새로운 프레임워크 ASAP을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LRM의 CoT 길이 증가로 인해 훈련 비용 및 추론 지연과 같은 문제가 발생한다.

Method: ASAP은 앵커 기반의 가지치기와 합리적인 첫 토큰 서프라이즈 메트릭을 사용하여 CoT를 압축한다.

Result: ASAP은 여러 코드 생성 벤치마크에서 최첨단 정확도를 달성하며 훈련 및 추론 비용을 크게 줄인다.

Conclusion: ASAP은 강력하고 효율적인 LRM 구축을 위한 유망한 방향성을 제시한다.

Abstract: Recently, Large Reasoning Models (LRMs) have demonstrated remarkable
capabilities in code reasoning by scaling up the length of Chain-of-Thought
(CoT). However, excessively long reasoning traces introduce substantial
challenges in terms of training cost, inference latency, and deployment
feasibility. While various CoT compression approaches have emerged to address
this challenge, they face inherent trade-offs: token-level methods often
disrupt syntactic and logical coherence, while step-level methods based on
perplexity fail to reliably capture the logically critical reasoning steps. In
this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel
coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided
pruning to preserve the core reasoning structure, which efficiently reduces the
search space for subsequent processing. It then enables a logic-aware pruning
by selecting logically essential reasoning steps based on a novel first-token
surprisal metric. Finally, ASAP teaches models to autonomously generate and
leverage these concise CoTs at inference time, enabling efficient reasoning in
coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy
across multiple code generation benchmarks while substantially reducing
training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,
our approach reduces token generation by 23.5% and inference latency by 43.5%
compared to the strongest baseline, while achieving a competitive accuracy of
36.19% in Pass@1. Our results highlight a promising direction for building
powerful and efficient LRMs.

</details>


### [22] [Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization](https://arxiv.org/abs/2508.05995)
*Fei Xu Yu,Gina Adam,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

TL;DR: MCTS-OPS는 LLM의 코드 생성 품질을 향상시키기 위한 새로운 신경-기호적 프레임워크로, MCTS에 의해 안내되는 순차적 결정 과정으로 프롬프트 선택을 설정한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 접근 방식은 복잡한 작업에 대한 LLM의 성능 저하를 해결하고자 한다.

Method: MCTS-OPS는 다단계 프롬프트 시퀀스를 탐색하고 개선하여 코드 생성 품질을 향상시키는 프레임워크다.

Result: 실험 결과, MCTS-OPS는 코드 실행 성공률과 최적화 결과에서 기존 방법보다 유의미하게 개선되었다.

Conclusion: 기호적 계획과 LLM의 결합이 복잡한 도메인에서 강력하고 고품질의 코드 생성을 가능하게 함을 보여준다.

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
code generation and structured reasoning; however, their performance often
degrades on complex tasks that require consistent multi-step planning. Recent
work has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet
existing approaches primarily focus on generating heuristic-based code for
optimization or target simpler tasks where correctness alone is sufficient. In
this work, we propose MCTS-OPS, a novel neural-symbolic framework that
formulates prompt selection as a sequential decision process guided by MCTS.
Our method explores and refines multi-step prompt sequences for the goal of
improving code generation quality and enhancing the problem-solving
capabilities of LLMs in general optimization. Experiments on network
optimization show significant improvement over the baselines, both in the
success rate of executing the generated code and in the optimization results
with the specified objective and constraints (2$\sim$4$\times$ higher reward
and 3$\times$ lower standard deviation). Moreover, it improves the chance of
attaining the optimal solution by about 10\% of cases, compared to baseline
methods in hard problems. These results highlight the promise of combining
symbolic planning with LLMs for robust, high-quality code generation in complex
domains.

</details>


### [23] [Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients](https://arxiv.org/abs/2508.06023)
*Xiaobin Shen,Jonathan Elmer,George H. Chen*

Main category: cs.LG

TL;DR: 이 연구에서는 심정지 후 혼수환자의 예후 예측을 개선하기 위한 새로운 단계적 동적 경쟁 위험 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 혼수 후 심정지 환자의 예후 예측은 중환자실에서 임상 의사 결정에 직접적인 영향을 미치는 중요한 도전이다.

Method: 이 연구는 시간 불변 특성과 시간 변화하는 특성을 구분하여 예후 예측을 개선하는 단계적 동적 경쟁 위험 모델을 제안한다.

Result: 2,278명의 혼수 상태 심정지 후 환자에 대한 후향적 코호트 평가에서, 모델은 회복, 생명 유지 치료 철회 및 사망과 관련된 경쟁 결과에 대해 강력한 차별 성능을 보여준다.

Conclusion: 이 접근법은 새로운 특성이 수집되는 더 두 가지 이상의 단계로 일반화되며, 새로 수집된 특성이 예측을 크게 개선하는 시기와 대상을 알 수 있는 다른 동적 예측 작업에 활용될 수 있다.

Abstract: Prognostication for comatose post-cardiac arrest patients is a critical
challenge that directly impacts clinical decision-making in the ICU. Clinical
information that informs prognostication is collected serially over time.
Shortly after cardiac arrest, various time-invariant baseline features are
collected (e.g., demographics, cardiac arrest characteristics). After ICU
admission, additional features are gathered, including time-varying hemodynamic
data (e.g., blood pressure, doses of vasopressor medications). We view these as
two phases in which we collect new features. In this study, we propose a novel
stepwise dynamic competing risks model that improves the prediction of
neurological outcomes by automatically determining when to take advantage of
time-invariant features (first phase) and time-varying features (second phase).
Notably, our model finds patients for whom this second phase (time-varying
hemodynamic) information is beneficial for prognostication and also when this
information is beneficial (as we collect more hemodynamic data for a patient
over time, how important these data are for prognostication varies). Our
approach extends the standard Fine and Gray model to explicitly model the two
phases and to incorporate neural networks to flexibly capture complex nonlinear
feature relationships. Evaluated on a retrospective cohort of 2,278 comatose
post-arrest patients, our model demonstrates robust discriminative performance
for the competing outcomes of awakening, withdrawal of life-sustaining therapy,
and death despite maximal support. Our approach generalizes to more than two
phases in which new features are collected and could be used in other dynamic
prediction tasks, where it may be helpful to know when and for whom newly
collected features significantly improve prediction.

</details>


### [24] [Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity](https://arxiv.org/abs/2508.06034)
*Qin Chen,Guojie Song*

Main category: cs.LG

TL;DR: 본 연구에서는 이질성 그래프에서의 이질성 모델링의 주요 문제를 다루기 위해 적응형 이질성 그래프 신경망(AHGNN)을 제안하고 있습니다.


<details>
  <summary>Details</summary>
Motivation: 이질성 그래프(HG)가 실제 애플리케이션에서 일반적으로 나타나는 이질성을 고려하지 않고 단일 측면에서 연구되고 있어 성능 저하가 발생하는 문제를 해결하고자 합니다.

Method: AHGNN은 이질성 분포를 고려하는 합성을 이용하여 서로 다른 메타 경로와 홉의 이질성에 맞추어 메시지를 통합합니다.

Result: 일곱 개의 실제 그래프와 20개 기준선 실험에서 AHGNN이 특히 높은 이질성 상황에서 우수한 성능을 보였습니다.

Conclusion: 이 연구는 이질성 그래프에서의 이질성 모델링에서 제기된 두 가지 주요 과제에 대한 해결책을 제공하며, AHGNN의 성공적인 활용을 보여줍니다.

Abstract: Heterogeneous graphs (HGs) are common in real-world scenarios and often
exhibit heterophily. However, most existing studies focus on either
heterogeneity or heterophily in isolation, overlooking the prevalence of
heterophilic HGs in practical applications. Such ignorance leads to their
performance degradation. In this work, we first identify two main challenges in
modeling heterophily HGs: (1) varying heterophily distributions across hops and
meta-paths; (2) the intricate and often heterophily-driven diversity of
semantic information across different meta-paths. Then, we propose the Adaptive
Heterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN
employs a heterophily-aware convolution that accounts for heterophily
distributions specific to both hops and meta-paths. It then integrates messages
from diverse semantic spaces using a coarse-to-fine attention mechanism, which
filters out noise and emphasizes informative signals. Experiments on seven
real-world graphs and twenty baselines demonstrate the superior performance of
AHGNN, particularly in high-heterophily situations.

</details>


### [25] [DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment](https://arxiv.org/abs/2508.06041)
*Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park*

Main category: cs.LG

TL;DR: 이 논문은 다양한 런타임 제약을 가진 장치 내 대형 언어 모델(LLM)에 대한 효율적인 쿼리 처리를 다루며, DP-LLM이라는 동적 정밀도 할당 메커니즘을 통해 성능과 지연의 균형을 최적화하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 장치 내 대형 언어 모델의 쿼리를 효과적으로 처리하는 것은 지연 및 정확성과 같은 런타임 제약을 고려할 때 매우 중요하다.

Method: DP-LLM은 입력 값에 기반해 각 층에 동적으로 정밀도를 할당하는 새로운 메커니즘으로, 경량 오류 추정기와 미세 조정된 임계값을 활용하여 런타임에 비트폭을 결정한다.

Result: 여러 모델 및 벤치마크에서의 실험 결과, DP-LLM은 이전 접근 방식보다 우수한 성능-지연 균형을 달성하였다.

Conclusion: DP-LLM은 다양한 런타임 요구를 충족시키면서도, 성능을 최적화하는 효과적인 방법을 제시한다.

Abstract: How can we effectively handle queries for on-device large language models
(LLMs) with varying runtime constraints, such as latency and accuracy?
Multi-scale quantization addresses this challenge by enabling memory-efficient
runtime model adaptation of LLMs through the overlaying of multiple model
variants quantized to different bitwidths. Meanwhile, an important question
still remains open-ended: how can models be properly configured to match a
target precision or latency? While mixed-precision offers a promising solution,
we take this further by leveraging the key observation that the sensitivity of
each layer dynamically changes across decoding iterations. Building on this
insight, we introduce DP-LLM, a novel mechanism that dynamically assigns
precision to each layer based on input values. DP-LLM augments each linear
layer in an LLM with a precision selector that determines the bitwidth at
runtime using a lightweight error estimator and threshold values learned
through fine-tuning. Experimental results across multiple models and benchmarks
demonstrate that DP-LLM achieves a superior performance-latency trade-off,
outperforming prior approaches.

</details>


### [26] [Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology](https://arxiv.org/abs/2508.06066)
*Barak Gahtan,Alex M. Bronstein*

Main category: cs.LG

TL;DR: 딥 템포럴 아키텍쳐는 시퀀스 데이터에서 강력한 예측 성능을 발휘하지만, 이들의 일반화에 대한 이론적 이해는 제한적이다.


<details>
  <summary>Details</summary>
Motivation: 딥 템포럴 모델에 대한 최초의 실질적이고 아키텍처 인식의 일반화 경계를 제공하고, 체계적인 평가 방법론을 제시한다.

Method: 지연 피드백 차단 메커니즘을 통해 의존 샘플을 효과적으로 독립적인 샘플로 변환하고, 샘플 크기를 고정하여 시간 구조와 정보 내용을 분리하는 공정 비교 방법론을 도입한다.

Result: 강한 의존 시퀀스는 약한 의존 시퀀스에 비해 약 76% 더 작은 일반화 격차를 나타내고, 약한 의존성의 수렴 속도는 N_{eff}^{-1.21}로, 강한 의존성은 N_{eff}^{-0.89}로 나타나 이론과의 차이를 드러낸다.

Conclusion: 이 결과는 고정된 정보 예산 하에서 시간적 의존성이 학습을 향상시킬 수 있음을 보여주며, 이론과 실제 간의 격차가 향후 연구의 동기를 부여함을 강조한다.

Abstract: Deep temporal architectures such as Temporal Convolutional Networks (TCNs)
achieve strong predictive performance on sequential data, yet theoretical
understanding of their generalization remains limited. We address this gap by
providing both the first non-vacuous, architecture-aware generalization bounds
for deep temporal models and a principled evaluation methodology.
  For exponentially $\beta$-mixing sequences, we derive bounds scaling as $
O\!\Bigl(R\,\sqrt{\tfrac{D\,p\,n\,\log N}{N}}\Bigr), $ where $D$ is network
depth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our
delayed-feedback blocking mechanism transforms dependent samples into
effectively independent ones while discarding only $O(1/\log N)$ of the data,
yielding $\sqrt{D}$ scaling instead of exponential, implying that doubling
depth requires approximately quadrupling the training data.
  We also introduce a fair-comparison methodology that fixes the effective
sample size to isolate the effect of temporal structure from information
content. Under $N_{\text{eff}}=2{,}000$, strongly dependent sequences
($\rho=0.8$) exhibit $\approx76\%$ smaller generalization gaps than weakly
dependent ones ($\rho=0.2$), challenging the intuition that dependence is
purely detrimental. Yet convergence rates diverge from theory: weak
dependencies follow $N_{\text{eff}}^{-1.21}$ scaling and strong dependencies
follow $N_{\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$.
These findings reveal that temporal dependence can enhance learning under fixed
information budgets, while highlighting gaps between theory and practice that
motivate future research.

</details>


### [27] [Recurrent Deep Differentiable Logic Gate Networks](https://arxiv.org/abs/2508.06097)
*Simon Bührer,Andreas Plesner,Till Aczel,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 차별화 가능한 논리 게이트를 순차 모델링에 적용한 첫 번째 논문이다.


<details>
  <summary>Details</summary>
Motivation: 차별화 가능한 논리 게이트가 피드포워드 네트워크에서 가능성을 보였으나, 순차 모델링에는 적용되지 않았다.

Method: 부울 연산과 순환 아키텍처를 결합한 순환 깊은 차별화 가능 논리 게이트 네트워크(RDDLGN)를 구현하였다.

Result: WMT'14 영어-독일어 번역에서 RDDLGN은 5.00 BLEU와 30.9% 정확도를 기록하였으며, GRU 성능(5.41 BLEU)에 근접하고, 추론 중에는 우아한 성능 저하(4.39 BLEU)를 보여주었다.

Conclusion: 이 연구는 순차 모델링과 기타 재귀 네트워크 아키텍처의 FPGA 가속을 위한 연구 방향을 열며, 재귀 논리 기반 신경 계산의 가능성을 확립하였다.

Abstract: While differentiable logic gates have shown promise in feedforward networks,
their application to sequential modeling remains unexplored. This paper
presents the first implementation of Recurrent Deep Differentiable Logic Gate
Networks (RDDLGN), combining Boolean operations with recurrent architectures
for sequence-to-sequence learning.
  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and
30.9\% accuracy during training, approaching GRU performance (5.41 BLEU) and
graceful degradation (4.39 BLEU) during inference. This work establishes
recurrent logic-based neural computation as viable, opening research directions
for FPGA acceleration in sequential modeling and other recursive network
architectures.

</details>


### [28] [GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2508.06108)
*Xing Lei,Wenyan Yang,Kaiqiang Ke,Shentao Yang,Xuetao Zhang,Joni Pajarinen,Donglin Wang*

Main category: cs.LG

TL;DR: 이 논문에서는 희소 보상을 가진 목표 조건 강화 학습(GCRL)의 효율성을 향상시키기 위한 Hindsight Goal-conditioned Regularization(HGR) 기법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 GCRL 방법들이 제한된 샘플 효율성을 보이는 이유는 단순히 수집된 궤적을 재레이블링하는 것만으로는 충분한 경험을 활용하지 못하기 때문이다.

Method: HGR 기법은 과거 목표에 기반한 행동 정규화 사전(prior)을 생성하고, 과거 자기 모방 정규화(HSR)와 결합하여 경험 활용을 극대화하는 방법을 제안한다.

Result: 기존의 GCRL 방법들과 비교했을 때, 우리의 정규화 기법들은 훨씬 더 효율적인 샘플 재사용과 최고의 성능을 달성함을 실험적으로 증명하였다.

Conclusion: 따라서 HGR과 HSR의 결합은 목표 조건 강화 학습의 성능을 크게 향상시킬 수 있음을 보여준다.

Abstract: Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a
fundamental challenge in reinforcement learning. While hindsight experience
replay (HER) has shown promise by relabeling collected trajectories with
achieved goals, we argue that trajectory relabeling alone does not fully
exploit the available experiences in off-policy GCRL methods, resulting in
limited sample efficiency. In this paper, we propose Hindsight Goal-conditioned
Regularization (HGR), a technique that generates action regularization priors
based on hindsight goals. When combined with hindsight self-imitation
regularization (HSR), our approach enables off-policy RL algorithms to maximize
experience utilization. Compared to existing GCRL methods that employ HER and
self-imitation techniques, our hindsight regularizations achieve substantially
more efficient sample reuse and the best performances, which we empirically
demonstrate on a suite of navigation and manipulation tasks.

</details>


### [29] [Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models](https://arxiv.org/abs/2508.06151)
*Yong Oh Lee,JeeEun Kim,Jung Woo Lee*

Main category: cs.LG

TL;DR: 본 연구는 구강암 진단을 위한 데이터셋의 한계를 극복하기 위해 합성 이미지 생성 기법을 제안하였습니다.


<details>
  <summary>Details</summary>
Motivation: 구강암 진단 모델의 성능은 제한된 주석 데이터셋에 의해 제약받고, 이는 훈련 데이터의 변동성과 부족으로 인해 더욱 심화됩니다.

Method: 이 연구에서는 세밀하게 조정된 확산 모델을 활용한 인페인팅 기법으로 현실적인 구강암 병변을 합성하여 진단 정확도를 높이는 새로운 접근 방식을 제안하였습니다.

Result: 우리의 분류 모델은 암 조직과 비암 조직을 구분하는 데 0.97의 진단 정확도를 달성하였으며, 병변 위치 식별을 위한 탐지 모델은 0.85의 정확도로 정확하게 식별했습니다.

Conclusion: 이 방법은 의료 진단에서 합성 이미지 생성의 잠재력을 검증하며, 이러한 방법을 다른 유형의 암 진단으로 확장하는 추가 연구의 길을 열어줍니다.

Abstract: In oral cancer diagnostics, the limited availability of annotated datasets
frequently constrains the performance of diagnostic models, particularly due to
the variability and insufficiency of training data. To address these
challenges, this study proposed a novel approach to enhance diagnostic accuracy
by synthesizing realistic oral cancer lesions using an inpainting technique
with a fine-tuned diffusion model. We compiled a comprehensive dataset from
multiple sources, featuring a variety of oral cancer images. Our method
generated synthetic lesions that exhibit a high degree of visual fidelity to
actual lesions, thereby significantly enhancing the performance of diagnostic
algorithms. The results show that our classification model achieved a
diagnostic accuracy of 0.97 in differentiating between cancerous and
non-cancerous tissues, while our detection model accurately identified lesion
locations with 0.85 accuracy. This method validates the potential for synthetic
image generation in medical diagnostics and paves the way for further research
into extending these methods to other types of cancer diagnostics.

</details>


### [30] [Differentially Private Federated Clustering with Random Rebalancing](https://arxiv.org/abs/2508.06183)
*Xiyuan Yang,Shengyuan Hu,Soyeon Kim,Tian Li*

Main category: cs.LG

TL;DR: 연합 클러스터링은 유사한 클라이언트를 클러스터로 그룹화하고 각 클러스터에 대해 하나의 모델을 생성하는 것을 목표로 한다. 개인화 접근 방식은 일반적으로 모든 클라이언트를 위한 단일 모델을 훈련하는 것보다 모델 성능을 향상시키지만, 개인 정보 누출에 더 취약할 수 있다. 이 논문에서는 클러스터 내에서 개인 정보 노이즈를 평균화하는 어려움으로 인해 발생하는 문제를 해결하기 위해 RR-Cluster라는 간단하고 효과적인 기술을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 연합 클러스터링에서 각 클러스터에 대해 하나의 모델을 생성하면서 개인 정보를 보호하는 방법을 찾는 것이 중요하다.

Method: RR-Cluster는 클러스터 할당을 무작위로 재조정하여 각 클러스터에 할당된 클라이언트 수를 보장하고 개인 정보 노이즈를 줄이는 경량 추가 기능으로 볼 수 있다.

Result: RR-Cluster를 강력한 연합 클러스터링 알고리즘에 적용한 결과, 합성 및 실제 데이터 세트 모두에서 개인 정보와 유용성 간의 트레이드오프가 현저히 개선되었다.

Conclusion: 우리는 RR-Cluster를 통해 개인 정보 노이즈 분산 감소와 잘못된 할당으로 인한 잠재적인 편향 증가 간의 트레이드오프를 분석하고 수렴 한계를 제공하였다.

Abstract: Federated clustering aims to group similar clients into clusters and produce
one model for each cluster. Such a personalization approach typically improves
model performance compared with training a single model to serve all clients,
but can be more vulnerable to privacy leakage. Directly applying client-level
differentially private (DP) mechanisms to federated clustering could degrade
the utilities significantly. We identify that such deficiencies are mainly due
to the difficulties of averaging privacy noise within each cluster (following
standard privacy mechanisms), as the number of clients assigned to the same
clusters is uncontrolled. To this end, we propose a simple and effective
technique, named RR-Cluster, that can be viewed as a light-weight add-on to
many federated clustering algorithms. RR-Cluster achieves reduced privacy noise
via randomly rebalancing cluster assignments, guaranteeing a minimum number of
clients assigned to each cluster. We analyze the tradeoffs between decreased
privacy noise variance and potentially increased bias from incorrect
assignments and provide convergence bounds for RR-Clsuter. Empirically, we
demonstrate the RR-Cluster plugged into strong federated clustering algorithms
results in significantly improved privacy/utility tradeoffs across both
synthetic and real-world datasets.

</details>


### [31] [Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning](https://arxiv.org/abs/2508.06199)
*Mateusz Praski,Jakub Adamczyk,Wojciech Czech*

Main category: cs.LG

TL;DR: 이 연구는 화학 및 소분자 약물 설계에서 사전 훈련된 신경망 모델을 비교 평가한 결과로, 대부분의 모델이 기본 ECFP 분자 지문에 비해 유의미한 개선을 보이지 않았다고 보고합니다.


<details>
  <summary>Details</summary>
Motivation: 사전 훈련된 신경망은 화학 및 소분자 약물 설계에 대한 관심을 끌고 있으며, 이 연구는 다양한 모델의 성능을 비교하여 평가의 엄격성을 논의하고자 합니다.

Method: 25가지 모델을 25가지 데이터셋에 걸쳐 공정한 비교 프레임워크를 사용하여 평가하고, 계층적 베이지안 통계 검정을 적용했습니다.

Result: 대부분의 신경망 모델이 기본 ECFP 분자 지문에 비해 유의미한 개선을 보이지 않았으며, CLAMP 모델만이 통계적으로 유의미한 성능 향상을 보였습니다.

Conclusion: 이러한 결과는 기존 연구의 평가 엄격성에 대한 우려를 제기하며, 가능한 원인과 해결책, 실행 가능한 권장 사항을 논의합니다.

Abstract: Pretrained neural networks have attracted significant interest in chemistry
and small molecule drug design. Embeddings from these models are widely used
for molecular property prediction, virtual screening, and small data learning
in molecular chemistry. This study presents the most extensive comparison of
such models to date, evaluating 25 models across 25 datasets. Under a fair
comparison framework, we assess models spanning various modalities,
architectures, and pretraining strategies. Using a dedicated hierarchical
Bayesian statistical testing model, we arrive at a surprising result: nearly
all neural models show negligible or no improvement over the baseline ECFP
molecular fingerprint. Only the CLAMP model, which is also based on molecular
fingerprints, performs statistically significantly better than the
alternatives. These findings raise concerns about the evaluation rigor in
existing studies. We discuss potential causes, propose solutions, and offer
practical recommendations.

</details>


### [32] [Graph Federated Learning for Personalized Privacy Recommendation](https://arxiv.org/abs/2508.06208)
*Ce Na,Kai Yang,Dengzhao Fang,Yu Li,Jingtong Gao,Chengcheng Zhu,Jiale Zhang,Xiaobing Sun,Yi Chang*

Main category: cs.LG

TL;DR: GFed-PP는 서로 다른 개인정보 보호 요구사항에 적응하면서 추천 성능을 향상시키는 그래프 연합 학습 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 연합 추천 시스템은 모든 사용자가 동일한 개인정보 보호 요구 수준을 가진다고 가정하며, 이는 공개 사용자의 데이터를 활용할 수 있는 가능성을 간과한다.

Method: GFed-PP는 공용 사용자 상호작용 데이터를 기반으로 사용자-아이템 상호작용 그래프를 구축하고, 이를 이용하여 사용자 관계 그래프를 형성한다. 각 클라이언트는 사용자 임베딩과 점수 함수를 로컬에서 학습하며, 그래프 합성곱 신경망(GCN)을 사용하여 개인화된 아이템 임베딩을 학습한다.

Result: GFed-PP는 다섯 개 데이터 세트에 대해 기존 방법보다 상당히 우수한 추천 정확도를 달성한다.

Conclusion: 이 프레임워크는 연합 추천 시스템에서 다양한 개인정보 보호 선호를 수용하기 위한 실용적인 해결책을 제공한다.

Abstract: Federated recommendation systems (FedRecs) have gained significant attention
for providing privacy-preserving recommendation services. However, existing
FedRecs assume that all users have the same requirements for privacy
protection, i.e., they do not upload any data to the server. The approaches
overlook the potential to enhance the recommendation service by utilizing
publicly available user data. In real-world applications, users can choose to
be private or public. Private users' interaction data is not shared, while
public users' interaction data can be shared. Inspired by the issue, this paper
proposes a novel Graph Federated Learning for Personalized Privacy
Recommendation (GFed-PP) that adapts to different privacy requirements while
improving recommendation performance. GFed-PP incorporates the interaction data
of public users to build a user-item interaction graph, which is then used to
form a user relationship graph. A lightweight graph convolutional network (GCN)
is employed to learn each user's user-specific personalized item embedding. To
protect user privacy, each client learns the user embedding and the scoring
function locally. Additionally, GFed-PP achieves optimization of the federated
recommendation framework through the initialization of item embedding on
clients and the aggregation of the user relationship graph on the server.
Experimental results demonstrate that GFed-PP significantly outperforms
existing methods for five datasets, offering superior recommendation accuracy
without compromising privacy. This framework provides a practical solution for
accommodating varying privacy preferences in federated recommendation systems.

</details>


### [33] [Membership Inference Attack with Partial Features](https://arxiv.org/abs/2508.06244)
*Xurun Wang,Guangrui Liu,Xinjie Li,Haoyu He,Lin Yao,Weizhe Zhang*

Main category: cs.LG

TL;DR: 기계 학습 모델이 멤버십 추론 공격에 취약함을 보여주는 연구로, 일부만 관찰 가능한 특징을 기반으로 훈련 데이터에 포함된 샘플 여부를 추정하는 방법을 제안함.


<details>
  <summary>Details</summary>
Motivation: 기존의 멤버십 추론 방법은 공격자가 목표 샘플의 모든 특성에 접근할 수 있다고 가정하지만, 실제 세계에서는 제한된 정보만을 가지고 있는 경우가 많음.

Method: MRAD(메모리 유도 재구성 및 이상 탐지)라는 2단계 공격 프레임워크를 제안함. 첫 번째 단계에서는 미지의 특성 값을 최적화하여 샘플의 손실을 최소화하고, 두 번째 단계에서는 재구성된 샘플과 훈련 분포 간의 편차를 이상 탐지를 통해 측정함.

Result: MRAD는 다양한 데이터세트에서 효과적이며, 여러 상용 이상 탐지 기술과의 호환성을 유지함.

Conclusion: 예를 들어, STL-10 데이터세트에서 우리의 공격은 40%의 누락된 특성이 있음에도 불구하고 약 0.6의 AUC를 달성함.

Abstract: Machine learning models have been shown to be susceptible to membership
inference attack, which can be used to determine whether a given sample appears
in the training data. Existing membership inference methods commonly assume
that the adversary has full access to the features of the target sample. This
assumption, however, does not hold in many real-world scenarios where only
partial features information is available, thereby limiting the applicability
of these methods. In this work, we study an inference scenario where the
adversary observes only partial features of each sample and aims to infer
whether this observed subset was present in the training set of the target
model. We define this problem as Partial Feature Membership Inference (PFMI).
To address this problem, we propose MRAD (Memory-guided Reconstruction and
Anomaly Detection), a two-stage attack framework. In the first stage, MRAD
optimizes the unknown feature values to minimize the loss of the sample. In the
second stage, it measures the deviation between the reconstructed sample and
the training distribution using anomaly detection. Empirical results
demonstrate that MRAD is effective across a range of datasets, and maintains
compatibility with various off-the-shelf anomaly detection techniques. For
example, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of
the missing features.

</details>


### [34] [Reparameterization Proximal Policy Optimization](https://arxiv.org/abs/2508.06214)
*Hai Zhong,Xun Wang,Zhuoran Li,Longbo Huang*

Main category: cs.LG

TL;DR: RPG의 훈련 불안정성을 극복하기 위해 PPO에서 영감을 받아 RPO라는 새로운 방법을 제안하며, 이는 샘플 효율성을 개선하고 안정적인 샘플 재사용을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 샘플 효율성을 향상시키기 위한 RPG의 훈련 불안정성을 해결하고자 함.

Method: PPO의 대리 목표를 통해 RPG와의 연결을 Establish하고, PPO 유사 대리 목표의 재매개변수화 그래디언트를 시간에 따라 역전파를 통해 효율적으로 계산할 수 있음을 보여줌으로써 RPO라는 방법을 제안함.

Result: RPO는 RPG에 맞춤화된 클리핑된 대리 목표를 최적화하면서 여러 에포크에서 안정적인 샘플 재사용을 가능하게 하고, KL 발산 정규화로 추가적인 안정성을 제공함.

Conclusion: RPO는 도전적인 운동 및 조작 작업에서 우수한 샘플 효율성과 강력한 성능을 입증하였다.

Abstract: Reparameterization policy gradient (RPG) is promising for improving sample
efficiency by leveraging differentiable dynamics. However, a critical barrier
is its training instability, where high-variance gradients can destabilize the
learning process. To address this, we draw inspiration from Proximal Policy
Optimization (PPO), which uses a surrogate objective to enable stable sample
reuse in the model-free setting. We first establish a connection between this
surrogate objective and RPG, which has been largely unexplored and is
non-trivial. Then, we bridge this gap by demonstrating that the
reparameterization gradient of a PPO-like surrogate objective can be computed
efficiently using backpropagation through time. Based on this key insight, we
propose Reparameterization Proximal Policy Optimization (RPO), a stable and
sample-efficient RPG-based method. RPO enables multiple epochs of stable sample
reuse by optimizing a clipped surrogate objective tailored for RPG, while being
further stabilized by Kullback-Leibler (KL) divergence regularization and
remaining fully compatible with existing variance reduction methods. We
evaluate RPO on a suite of challenging locomotion and manipulation tasks, where
experiments demonstrate that our method achieves superior sample efficiency and
strong performance.

</details>


### [35] [Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)](https://arxiv.org/abs/2508.06251)
*Alejandro Moreno R.,Desale Fentaw,Samuel Palmer,Raúl Salles de Padua,Ninad Dixit,Samuel Mugel,Roman Orús,Manuel Radons,Josef Menter,Ali Abedi*

Main category: cs.LG

TL;DR: 이 논문은 개인 정보 보호를 유지하면서 고품질의 합성 데이터를 생성하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 합성 데이터 생성은 데이터 부족, 개인 정보 보호 제약 및 다양한 데이터셋의 필요성을 해결하는 데 중요한 기술입니다.

Method: Tensor Networks, 특히 Matrix Product States(MPS)를 사용하여 개인 정보 보호를 유지하는 고품질 합성 표 형식 데이터를 생성하는 방법을 제안합니다.

Result: MPS 기반 생성 모델은 CTGAN, VAE, PrivBayes 등 최첨단 모델과 비교하여 데이터 충실도와 개인 정보 보호 기능 모두에서 우수한 성능을 보였습니다.

Conclusion: MPS는 개인 정보 보호를 고려한 합성 데이터 생성을 위한 유망한 도구로 강조되며, 데이터 품질과 기밀성이 중요한 민감한 도메인에 통합하기 용이한 구조적 설계를 갖추고 있습니다.

Abstract: Synthetic data generation is a key technique in modern artificial
intelligence, addressing data scarcity, privacy constraints, and the need for
diverse datasets in training robust models. In this work, we propose a method
for generating privacy-preserving high-quality synthetic tabular data using
Tensor Networks, specifically Matrix Product States (MPS). We benchmark the
MPS-based generative model against state-of-the-art models such as CTGAN, VAE,
and PrivBayes, focusing on both fidelity and privacy-preserving capabilities.
To ensure differential privacy (DP), we integrate noise injection and gradient
clipping during training, enabling privacy guarantees via R\'enyi Differential
Privacy accounting. Across multiple metrics analyzing data fidelity and
downstream machine learning task performance, our results show that MPS
outperforms classical models, particularly under strict privacy constraints.
This work highlights MPS as a promising tool for privacy-aware synthetic data
generation. By combining the expressive power of tensor network representations
with formal privacy mechanisms, the proposed approach offers an interpretable
and scalable alternative for secure data sharing. Its structured design
facilitates integration into sensitive domains where both data quality and
confidentiality are critical.

</details>


### [36] [Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient](https://arxiv.org/abs/2304.04475)
*Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 이 논문에서는 팬데믹의 영향을 완화하기 위한 경량화된 정책 최적화 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 팬데믹의 영향 완화를 위한 개입은 긍정적이거나 비의도적인 부정적 결과를 초래할 수 있습니다. 따라서 최적의 개입을 자동으로 결정할 필요성이 있습니다.

Method: 우리는 100,000명의 개인에 대한 대규모 전염병 에이전트 기반 시뮬레이션에서 Deep Deterministic Policy Gradient (DDPG) 기반 정책 최적화 프레임워크를 사용하여 다중 목표 최적화를 수행합니다.

Result: 차단과 백신 접종을 위한 최적의 정책을 결정하였으며, 경제 활동을 위한 기본 시뮬레이션을 통해 최적 경제(빈곤선 이하 개인)와 균형 잡힌 건강 목표(감염 및 입원)를 보여주었습니다.

Conclusion: 결과를 추가 검증하고 우리 프레임워크를 오픈 소스화하기 위해 심층 시뮬레이션이 필요합니다.

Abstract: To mitigate the impact of the pandemic, several measures include lockdowns,
rapid vaccination programs, school closures, and economic stimulus. These
interventions can have positive or unintended negative consequences. Current
research to model and determine an optimal intervention automatically through
round-tripping is limited by the simulation objectives, scale (a few thousand
individuals), model types that are not suited for intervention studies, and the
number of intervention strategies they can explore (discrete vs continuous). We
address these challenges using a Deep Deterministic Policy Gradient (DDPG)
based policy optimization framework on a large-scale (100,000 individual)
epidemiological agent-based simulation where we perform multi-objective
optimization. We determine the optimal policy for lockdown and vaccination in a
minimalist age-stratified multi-vaccine scenario with a basic simulation for
economic activity. With no lockdown and vaccination (mid-age and elderly),
results show optimal economy (individuals below the poverty line) with balanced
health objectives (infection, and hospitalization). An in-depth simulation is
needed to further validate our results and open-source our framework.

</details>


### [37] [SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems](https://arxiv.org/abs/2508.06243)
*Ioan-Sorin Comsa,Purav Shah,Karthik Vaidhyanathan,Deepak Gangadharan,Christof Imhof,Per Bergamin,Aryan Kaushik,Gabriel-Miro Muntean,Ramona Trestian*

Main category: cs.LG

TL;DR: 6G 네트워크의 발전은 차량 환경에서 연결된 정보 오락 서비스의 새로운 가능성을 열어줍니다. 하지만 기존의 무선 자원 관리 기법은 자율주행차에서 발생하는 증가하는 데이터 양과 복잡성에 어려움을 겪고 있습니다. 본 논문에서는 차량 정보 오락의 스케줄링과 공정성을 최적화하는 Edge AI 보조 프레임워크인 SCAR(상태 공간 압축을 위한 AI 기반 자원 관리)를 제안합니다. SCAR는 머신 러닝 기반 압축 기법을 이용하여 CQI 데이터 크기를 줄이는 한편, 필수 특징을 보존합니다. 압축된 상태들은 6G 기반 강화 학습 정책을 훈련하는 데 사용되어, NGMN에서 정의한 공정성 목표를 충족하면서 처리량을 극대화합니다. 시뮬레이션 결과, SCAR는 CQI 압축이 없는 RL 기준선과 비교하여 실현 가능한 스케줄링 영역에서의 시간을 14% 증가시키고 불공정한 스케줄링 시간을 15% 줄입니다. 또한, 확률적 터널링을 이용한 시뮬레이트 어닐링 기반 클러스터링은 CQI 클러스터링 왜곡을 10% 감소시켜 효율성을 입증합니다. 이러한 결과는 동적 차량 네트워크에 대한 SCAR의 확장성과 공정성 이점을 입증합니다.


<details>
  <summary>Details</summary>
Motivation: 6G 네트워크는 차량 환경에서의 연결된 정보 오락 서비스를 위한 새로운 가능성을 열어주지만, 전통적인 라디오 자원 관리 기법은 자율주행차로부터 발생하는 데이터의 양과 복잡성 증가에 어려움을 겪고 있습니다.

Method: SCAR라는 이름의 Edge AI 보조 프레임워크를 제안하여 차량 정보 오락의 스케줄링과 공정성을 최적화합니다. SCAR는 머신 러닝 기반 압축 기법(예: 클러스터링 및 RBF 네트워크)을 사용하여 CQI 데이터 크기를 줄이고, 6G에서 가능한 강화 학습 정책을 훈련합니다.

Result: SCAR는 CQI 압축이 없는 RL 기준선과 비교하여 실현 가능한 스케줄링 영역에서의 시간을 14% 증가시키고 불공정한 스케줄링 시간을 15% 줄입니다. 또한, SAST 기반 클러스터링은 CQI 클러스터링 왜곡을 10% 감소시킵니다.

Conclusion: SCAR는 동적 차량 네트워크에 대해 확장성과 공정성 이점을 입증합니다.

Abstract: The advent of 6G networks opens new possibilities for connected infotainment
services in vehicular environments. However, traditional Radio Resource
Management (RRM) techniques struggle with the increasing volume and complexity
of data such as Channel Quality Indicators (CQI) from autonomous vehicles. To
address this, we propose SCAR (State-Space Compression for AI-Driven Resource
Management), an Edge AI-assisted framework that optimizes scheduling and
fairness in vehicular infotainment. SCAR employs ML-based compression
techniques (e.g., clustering and RBF networks) to reduce CQI data size while
preserving essential features. These compressed states are used to train
6G-enabled Reinforcement Learning policies that maximize throughput while
meeting fairness objectives defined by the NGMN. Simulations show that SCAR
increases time in feasible scheduling regions by 14\% and reduces unfair
scheduling time by 15\% compared to RL baselines without CQI compression.
Furthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based
clustering reduces CQI clustering distortion by 10\%, confirming its
efficiency. These results demonstrate SCAR's scalability and fairness benefits
for dynamic vehicular networks.

</details>


### [38] [Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits](https://arxiv.org/abs/2508.06247)
*Zichun Ye,Runqi Wang,Xutong Liu,Shuai Li*

Main category: cs.LG

TL;DR: CMAB 문제에 대한 새로운 알고리즘 CMOSS를 제안하며, 효율성을 높이고 장기적인 손실을 감소시키는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: CMAB 문제에서 UCB 기반 방법의 한계와 적대적 방법의 계산적 부담을 해결하고자 한다.

Method: CMOSS는 비모수적 피드백 하에서 $Oig( ("log k)^2oot{kmT}ig )$의 손실을 보장하는 계산적으로 효율적인 알고리즘이다.

Result: CMOSS는 $	ext{log T}$ 의존성을 제거하며, $	ext{Ω}ig( 	ext{sqrt{kmT}} ig)$의 하한에 도달한다.

Conclusion: CMOSS는 기존 알고리즘보다 더 나은 성과를 제공하며, 실험적으로 그 효율성을 입증한다.

Abstract: The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential
decision-making framework, dominated by two algorithmic families: UCB-based and
adversarial methods such as follow the regularized leader (FTRL) and online
mirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer
from additional regret factor $\log T$ that is detrimental over long horizons,
while adversarial methods such as EXP3.M and HYBRID impose significant
computational overhead. To resolve this trade-off, we introduce the
Combinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS
is a computationally efficient algorithm that achieves an instance-independent
regret of $O\big( (\log k)^2\sqrt{kmT}\big )$ under semi-bandit feedback, where
$m$ is the number of arms and $k$ is the maximum cardinality of a feasible
action. Crucially, this result eliminates the dependency on $\log T$ and
matches the established $\Omega\big( \sqrt{kmT}\big)$ lower bound up to
$O\big((\log k)^2\big)$. We then extend our analysis to show that CMOSS is also
applicable to cascading feedback. Experiments on synthetic and real-world
datasets validate that CMOSS consistently outperforms benchmark algorithms in
both regret and runtime efficiency.

</details>


### [39] [In-Training Defenses against Emergent Misalignment in Language Models](https://arxiv.org/abs/2508.06249)
*David Kaczér,Magnus Jørgenvåg,Clemens Vetter,Lucie Flek,Florian Mai*

Main category: cs.LG

TL;DR: 이 논문은 API를 통해 파인튜닝을 노출하는 제공자들에게 실용적인 훈련 중 안전장치에 대해 체계적으로 연구하고, 네 가지 정규화 방법의 효과를 평가합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 새 도메인에 맞게 재사용하는 과정에서 발생하는 불일치(EMA)를 해결하기 위해서입니다.

Method: 네 가지 훈련 정규화 개입을 조사합니다: (i) 안전 참조 모델에 대한 KL-발산 정규화, (ii) 특성 공간에서의 $	ext{ℓ}_2$ 거리, (iii) 안전한 부분 공간에 투영(SafeLoRA), (iv) 일반 지침 튜닝 데이터셋의 안전한 훈련 예제를 소량 섞어 사용합니다.

Result: 제안된 방법들이 네 가지 악의적, EMA 유발 작업에서의 불일치 효과를 평가하고, 리니어 작업에 미치는 영향을 분석합니다.

Conclusion: 새로운 연구를 위한 개방된 질문들에 대해 논의합니다.

Abstract: Fine-tuning lets practitioners repurpose aligned large language models (LLMs)
for new domains, yet recent work reveals emergent misalignment (EMA): Even a
small, domain-specific fine-tune can induce harmful behaviors far outside the
target domain. Even in the case where model weights are hidden behind a
fine-tuning API, this gives attackers inadvertent access to a broadly
misaligned model in a way that can be hard to detect from the fine-tuning data
alone. We present the first systematic study of in-training safeguards against
EMA that are practical for providers who expose fine-tuning via an API. We
investigate four training regularization interventions: (i) KL-divergence
regularization toward a safe reference model, (ii) $\ell_2$ distance in feature
space, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving
of a small amount of safe training examples from a general instruct-tuning
dataset. We first evaluate the methods' emergent misalignment effect across
four malicious, EMA-inducing tasks. Second, we assess the methods' impacts on
benign tasks. We conclude with a discussion of open questions in emergent
misalignment research.

</details>


### [40] [Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors](https://arxiv.org/abs/2508.06257)
*Jielong Lu,Zhihao Wu,Jiajun Yu,Jiajun Bu,Haishuai Wang*

Main category: cs.LG

TL;DR: GTMancer라는 프레임워크를 통해 다중 오믹스 데이터의 통합 및 암 아형 분류에서의 성능 향상을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 질병, 특히 암의 복잡한 생물학적 과정을 이해하기 위해 다중 오믹스 데이터의 통합이 필요하다.

Method: GTMancer 프레임워크는 GNN 최적화 문제를 기반으로 하여, 대조 학습을 활용하여 다중 오믹스 데이터를 통합된 의미 공간으로 임베딩한다.

Result: 7개의 실제 암 데이터셋에 대한 경험적 실험 결과, GTMancer는 기존의 최첨단 알고리즘보다 우수한 성능을 보인다.

Conclusion: GTMancer는 다중 오믹스 데이터 간의 복잡한 관계를 효과적으로 포착함으로써 정밀 암 치료를 위한 새로운 가능성을 제시한다.

Abstract: Integrating multi-omics datasets through data-driven analysis offers a
comprehensive understanding of the complex biological processes underlying
various diseases, particularly cancer. Graph Neural Networks (GNNs) have
recently demonstrated remarkable ability to exploit relational structures in
biological data, enabling advances in multi-omics integration for cancer
subtype classification. Existing approaches often neglect the intricate
coupling between heterogeneous omics, limiting their capacity to resolve subtle
cancer subtype heterogeneity critical for precision oncology. To address these
limitations, we propose a framework named Graph Transformer for Multi-omics
Cancer Subtype Classification (GTMancer). This framework builds upon the GNN
optimization problem and extends its application to complex multi-omics data.
Specifically, our method leverages contrastive learning to embed multi-omics
data into a unified semantic space. We unroll the multiplex graph optimization
problem in that unified space and introduce dual sets of attention coefficients
to capture structural graph priors both within and among multi-omics data. This
approach enables global omics information to guide the refining of the
representations of individual omics. Empirical experiments on seven real-world
cancer datasets demonstrate that GTMancer outperforms existing state-of-the-art
algorithms.

</details>


### [41] [OM2P: Offline Multi-Agent Mean-Flow Policy](https://arxiv.org/abs/2508.06269)
*Zhuoran Li,Xun Wang,Hai Zhong,Longbo Huang*

Main category: cs.LG

TL;DR: OM2P 알고리즘은 효율적인 일회성 행동 샘플링을 위해 생성 모델을 활용한 오프라인 다중 에이전트 강화 학습 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 다중 에이전트 강화 학습에 강력한 생성 모델을 통합하는데 따른 고유한 도전 과제를 해결하고자 한다.

Method: OM2P라는 새로운 오프라인 MARL 알고리즘을 제안하며, 이는 보상 최대화와 생성 목표 간의 불일치를 해결하기 위한 보상 인식 최적화 방식을 포함한다.

Result: OM2P는 GPU 메모리 사용량을 최대 3.8배 줄이고 훈련 시간을 최대 10.8배 단축함으로써 다중 에이전트 입자 및 MuJoCo 벤치마크에서 우수한 성능을 나타낸다.

Conclusion: 본 연구는 평균 흐름 모델을 오프라인 MARL에 성공적으로 통합한 첫 사례로, 협력적인 다중 에이전트 환경에서 실제적이고 확장 가능한 생성 정책의 길을 열고 있다.

Abstract: Generative models, especially diffusion and flow-based models, have been
promising in offline multi-agent reinforcement learning. However, integrating
powerful generative models into this framework poses unique challenges. In
particular, diffusion and flow-based policies suffer from low sampling
efficiency due to their iterative generation processes, making them impractical
in time-sensitive or resource-constrained settings. To tackle these
difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel
offline MARL algorithm to achieve efficient one-step action sampling. To
address the misalignment between generative objectives and reward maximization,
we introduce a reward-aware optimization scheme that integrates a
carefully-designed mean-flow matching loss with Q-function supervision.
Additionally, we design a generalized timestep distribution and a
derivative-free estimation strategy to reduce memory overhead and improve
training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo
benchmarks demonstrate that OM2P achieves superior performance, with up to a
3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time.
Our approach represents the first to successfully integrate mean-flow model
into offline MARL, paving the way for practical and scalable generative
policies in cooperative multi-agent settings.

</details>


### [42] [A Study on Regularization-Based Continual Learning Methods for Indic ASR](https://arxiv.org/abs/2508.06280)
*Gokul Adethya T,S. Jaya Nirmala*

Main category: cs.LG

TL;DR: 이 논문은 인도 언어의 자동 음성 인식(ASR) 시스템을 위한 지속 학습(Continual Learning, CL) 방법을 조사하고, CL 전략이 다양한 인도 언어에서의 잊음 현상을 완화하는 데 효과적임을 보인다.


<details>
  <summary>Details</summary>
Motivation: 인도의 언어 다양성은 포괄적인 자동 음성 인식 시스템 개발에 큰 도전을 제기한다.

Method: 우리는 인도 언어의 IndicSUPERB 벤치마크의 하위 집합을 사용하여 Conformer 기반의 하이브리드 RNN-T/CTC 모델을 채택하고, 이를 통해 힌디로 초기 사전 훈련한 후 8개 인도 언어로 점진적으로 학습한다.

Result: 세 가지 주요 정규화 및 증류 기반의 CL 전략을 평가하며, 결과적으로 CL이 잊음 현상을 완화하는 데 효과적임을 보여준다.

Conclusion: 대조군으로 사용한 단순 미세 조정과 비교하여, 이 접근 방식은 다양한 인도 언어에 대한 확장 가능한 ASR을 위한 유망한 방법으로 나타났다.

Abstract: Indias linguistic diversity poses significant challenges for developing
inclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual
models, which require simultaneous access to all language data, are impractical
due to the sequential arrival of data and privacy constraints. Continual
Learning (CL) offers a solution by enabling models to learn new languages
sequentially without catastrophically forgetting previously learned knowledge.
This paper investigates CL for ASR on Indian languages using a subset of the
IndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model,
initially pretrained on Hindi, which is then incrementally trained on eight
additional Indian languages, for a total sequence of nine languages. We
evaluate three prominent regularization- and distillation-based CL strategies:
Elastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning
without Forgetting (LwF), selected for their suitability in no-replay,
privacy-conscious scenarios. Performance is analyzed using Word Error Rate
(WER) for both RNN-T and CTC paths on clean and noisy data, as well as
knowledge retention via Backward Transfer. We also explore the impact of
varying the number of training epochs (1, 2, 5, and 10) per task. Results,
compared against naive fine-tuning, demonstrate CLs effectiveness in mitigating
forgetting, making it a promising approach for scalable ASR in diverse Indian
languages under realistic constraints. The code is available at:
https://github.com/FrozenWolf-Cyber/Indic-CL-ASR

</details>


### [43] [Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback](https://arxiv.org/abs/2508.06292)
*Sanja Karilanova,Subhrakanti Dey,Ayça Özçelikkale*

Main category: cs.LG

TL;DR: 본 연구는 신경 형태 컴퓨팅의 새로운 모델을 제안하며, 제안된 모델은 생체 영감을 받은 뉴런을 사용해 다양한 과제에서 우수한 성능을 보입니다.


<details>
  <summary>Details</summary>
Motivation: 신경 형태 컴퓨팅은 저지연 및 에너지 효율적인 신호 처리를 가능하게 하는 신기술로, 많은 연구가 이루어지고 있습니다.

Method: 본 연구는 비선형 피드백 메커니즘을 통해 선형 일반 상태공간 모델(SSM) 상태 전이를 결합한 다중 출력 스파이킹 뉴런 모델을 제안합니다.

Result: 제안된 모델은 여러 과제에서 기존 SNN 문헌의 벤치마크와 동등한 성능을 달성하였습니다.

Conclusion: 제안된 리셋 메커니즘은 불안정을 극복하고 학습을 가능하게 하여, 최근의 깊은 SSM 모델의 선형 동적 안정성을 초월하게 합니다.

Abstract: Neuromorphic computing is an emerging technology enabling low-latency and
energy-efficient signal processing. A key algorithmic tool in neuromorphic
computing is spiking neural networks (SNNs). SNNs are biologically inspired
neural networks which utilize stateful neurons, and provide low-bit data
processing by encoding and decoding information using spikes. Similar to SNNs,
deep state-space models (SSMs) utilize stateful building blocks. However, deep
SSMs, which recently achieved competitive performance in various temporal
modeling tasks, are typically designed with high-precision activation functions
and no reset mechanisms. To bridge the gains offered by SNNs and the recent
deep SSM models, we propose a novel multiple-output spiking neuron model that
combines a linear, general SSM state transition with a non-linear feedback
mechanism through reset. Compared to the existing neuron models for SNNs, our
proposed model clearly conceptualizes the differences between the spiking
function, the reset condition and the reset action. The experimental results on
various tasks, i.e., a keyword spotting task, an event-based vision task and a
sequential pattern recognition task, show that our proposed model achieves
performance comparable to existing benchmarks in the SNN literature. Our
results illustrate how the proposed reset mechanism can overcome instability
and enable learning even when the linear part of neuron dynamics is unstable,
allowing us to go beyond the strictly enforced stability of linear dynamics in
recent deep SSM models.

</details>


### [44] [FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields](https://arxiv.org/abs/2508.06301)
*Junhyeog Yun,Minui Hong,Gunhee Kim*

Main category: cs.LG

TL;DR: FedMeNF는 클라이언트 데이터의 프라이버시를 보존하면서 빠른 최적화 속도와 견고한 재구성 성능을 달성하는 새로운 연합 메타 학습 접근 방식이다.


<details>
  <summary>Details</summary>
Motivation: 신경 필드는 메모리 효율적인 데이터 표현을 제공하지만, 학습에는 많은 훈련 데이터와 계산이 필요하다.

Method: FedMeNF는 로컬 메타 최적화에서 프라이버시 유출을 규제하는 새로운 프라이버시 보호 손실 함수를 활용한다.

Result: FedMeNF는 다양한 데이터 모달리티에서 몇 샷 또는 비IID 데이터로도 빠른 최적화 속도와 견고한 재구성 성능을 달성한다.

Conclusion: 이 접근 방식을 통해 클라이언트 데이터 프라이버시를 유지하면서 효과적으로 학습할 수 있다.

Abstract: Neural fields provide a memory-efficient representation of data, which can
effectively handle diverse modalities and large-scale data. However, learning
to map neural fields often requires large amounts of training data and
computations, which can be limited to resource-constrained edge devices. One
approach to tackle this limitation is to leverage Federated Meta-Learning
(FML), but traditional FML approaches suffer from privacy leakage. To address
these issues, we introduce a novel FML approach called FedMeNF. FedMeNF
utilizes a new privacy-preserving loss function that regulates privacy leakage
in the local meta-optimization. This enables the local meta-learner to optimize
quickly and efficiently without retaining the client's private data. Our
experiments demonstrate that FedMeNF achieves fast optimization speed and
robust reconstruction performance, even with few-shot or non-IID data across
diverse data modalities, while preserving client data privacy.

</details>


### [45] [Introducing Fractional Classification Loss for Robust Learning with Noisy Labels](https://arxiv.org/abs/2508.06346)
*Mert Can Kurucu,Tufan Kumbasar,İbrahim Eksin,Müjde Güzelkaya*

Main category: cs.LG

TL;DR: FCL은 레이블 노이즈가 있는 상황에서 딥 뉴럴 네트워크 훈련을 위해 고안된 적응형 강건 손실로, 수동 하이퍼파라미터 조정 없이도 최고 수준의 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 딥 뉴럴 네트워크 훈련에서 레이블 노이즈가 존재할 때 강건 손실 함수의 필요성이 있다.

Method: FCL은 Cross-Entropy 손실의 분수 미분을 능동적 구성 요소로 사용하고 Mean Absolute Error를 수동적 손실 구성 요소로 사용하는 능동-수동 손실 프레임워크 내에서 구동된다.

Result: FCL은 MAE 유사한 강건성과 CE 유사한 빠른 수렴 간의 손실 함수 패밀리를 보간함을 보여준다.

Conclusion: FCL은 레이블 노이즈 하에서도 효과적인 분류 성능을 달성할 수 있도록 손실 풍경을 동적으로 조정할 수 있다.

Abstract: Robust loss functions are crucial for training deep neural networks in the
presence of label noise, yet existing approaches require extensive,
dataset-specific hyperparameter tuning. In this work, we introduce Fractional
Classification Loss (FCL), an adaptive robust loss that automatically
calibrates its robustness to label noise during training. Built within the
active-passive loss framework, FCL employs the fractional derivative of the
Cross-Entropy (CE) loss as its active component and the Mean Absolute Error
(MAE) as its passive loss component. With this formulation, we demonstrate that
the fractional derivative order $\mu$ spans a family of loss functions that
interpolate between MAE-like robustness and CE-like fast convergence.
Furthermore, we integrate $\mu$ into the gradient-based optimization as a
learnable parameter and automatically adjust it to optimize the trade-off
between robustness and convergence speed. We reveal that FCL's unique property
establishes a critical trade-off that enables the stable learning of $\mu$:
lower log penalties on difficult or mislabeled examples improve robustness but
impose higher penalties on easy or clean data, reducing model confidence in
them. Consequently, FCL can dynamically reshape its loss landscape to achieve
effective classification performance under label noise. Extensive experiments
on benchmark datasets show that FCL achieves state-of-the-art results without
the need for manual hyperparameter tuning.

</details>


### [46] [Structural Equation-VAE: Disentangled Latent Representations for Tabular Data](https://arxiv.org/abs/2508.06347)
*Ruiyu Zhang,Ce Zhao,Xin Zhao,Lin Nie,Wai-Fung Lam*

Main category: cs.LG

TL;DR: SE-VAE는 측정 구조를 통합한 새로운 변분 오토인코더 아키텍처로, 제어된 혼동 변량을 격리하고 해석 가능한 잠재 표현을 학습하는 데 있어 우수한 성능을 보입니다.


<details>
  <summary>Details</summary>
Motivation: 테이블 데이터에서 해석 가능한 잠재 표현을 학습하는 것은 심층 생성 모델링에서 여전히 도전 과제입니다.

Method: SE-VAE(구조 방정식-변분 오토인코더)는 변분 오토인코더 설계에 측정 구조를 직접 포함시키는 새로운 아키텍처로, 구조 방정식 모델링에서 영감을 받았으며, 잠재 하위 공간을 알려진 지표 그룹과 일치시키고, 혼동 변량을 격리하기 위해 글로벌 혼동 잠재 변수를 도입합니다.

Result: 시뮬레이션된 테이블 데이터 세트를 기반으로 SE-VAE의 성능을 평가한 결과, 요인 회수, 해석 가능성 및 혼동 변량에 대한 강건성에서 다른 모델들을 지속적으로 초월하는 것으로 나타났습니다.

Conclusion: SE-VAE는 이론 주도적인 잠재 구조와 측정 유효성이 중요한 과학 및 사회 분야에서 화이트 박스 생성 모델링을 위한 원칙적인 프레임워크를 제공합니다.

Abstract: Learning interpretable latent representations from tabular data remains a
challenge in deep generative modeling. We introduce SE-VAE (Structural
Equation-Variational Autoencoder), a novel architecture that embeds measurement
structure directly into the design of a variational autoencoder. Inspired by
structural equation modeling, SE-VAE aligns latent subspaces with known
indicator groupings and introduces a global nuisance latent to isolate
construct-specific confounding variation. This modular architecture enables
disentanglement through design rather than through statistical regularizers
alone. We evaluate SE-VAE on a suite of simulated tabular datasets and
benchmark its performance against a series of leading baselines using standard
disentanglement metrics. SE-VAE consistently outperforms alternatives in factor
recovery, interpretability, and robustness to nuisance variation. Ablation
results reveal that architectural structure, rather than regularization
strength, is the key driver of performance. SE-VAE offers a principled
framework for white-box generative modeling in scientific and social domains
where latent constructs are theory-driven and measurement validity is
essential.

</details>


### [47] [Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means](https://arxiv.org/abs/2508.06353)
*Parichit Sharma,Marcin Stanislaw,Hasan Kurban,Oguzhan Kulekci,Mehmet Dalkilic*

Main category: cs.LG

TL;DR: Geometric-k-means (Gk-means)은 k-평균 알고리즘의 효율성과 에너지 경제성을 크게 향상시키는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: k-평균 알고리즘은 기계 학습 응용 프로그램에서 중요한 역할을 하며, 그 효율성을 개선하는 것이 필요하다.

Method: Gk-means는 기하학적 원리를 활용하여 알고리즘을 가속화하고, 중요한 데이터 포인트에 집중하여 계산 오버헤드를 줄인다.

Result: 합성, 실제 및 고차원 데이터 세트를 사용한 실험에서 Gk-means는 전통적 k-평균 변형보다 훨씬 우수한 성능을 보였다.

Conclusion: Gk-means는 에너지 소비를 줄여 더욱 지속 가능한 대안으로 자리잡을 수 있다.

Abstract: This paper introduces Geometric-k-means (or Gk-means for short), a novel
approach that significantly enhances the efficiency and energy economy of the
widely utilized k-means algorithm, which, despite its inception over five
decades ago, remains a cornerstone in machine learning applications. The
essence of Gk-means lies in its active utilization of geometric principles,
specifically scalar projection, to significantly accelerate the algorithm
without sacrificing solution quality. This geometric strategy enables a more
discerning focus on data points that are most likely to influence cluster
updates, which we call as high expressive data (HE). In contrast, low
expressive data (LE), does not impact clustering outcome, is effectively
bypassed, leading to considerable reductions in computational overhead.
Experiments spanning synthetic, real-world and high-dimensional datasets,
demonstrate Gk-means is significantly better than traditional and state of the
art (SOTA) k-means variants in runtime and distance computations (DC).
Moreover, Gk-means exhibits better resource efficiency, as evidenced by its
reduced energy footprint, placing it as more sustainable alternative.

</details>


### [48] [Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts](https://arxiv.org/abs/2508.06361)
*Zhaomin Wu,Mingzhe Du,See-Kiong Ng,Bingsheng He*

Main category: cs.LG

TL;DR: 본 논문에서는 대형 언어 모델(LLM)의 자발적인 기만 행동을 분석하고, 이를 평가하기 위한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM의 신뢰성이 중요한 문제로 떠오르면서, 고의적인 기만 가능성이 심각한 위협으로 간주되고 있습니다.

Method: '접촉 검색 질문'을 사용하여 기만 가능성을 정량화하는 두 가지 통계적 메트릭을 도입했습니다: 기만 의도 점수 및 기만 행동 점수.

Result: 14개의 주요 LLM을 평가한 결과, 두 메트릭 모두 작업의 난이도가 증가함에 따라 상승하는 경향이 있음을 발견했습니다.

Conclusion: 이러한 결과는 복잡한 문제를 처리할 때 LLM이 기만 행동을 증가시키는 경향이 있음을 보여주며, 이는 LLM 에이전트를 복잡하고 중요한 분야에 배치하는 데 대한 심각한 우려를 불러일으킵니다.

Abstract: Large Language Models (LLMs) have been widely deployed in reasoning,
planning, and decision-making tasks, making their trustworthiness a critical
concern. The potential for intentional deception, where an LLM deliberately
fabricates or conceals information to serve a hidden objective, remains a
significant and underexplored threat. Existing studies typically induce such
deception by explicitly setting a "hidden" objective through prompting or
fine-tuning, which may not fully reflect real-world human-LLM interactions.
Moving beyond this human-induced deception, we investigate LLMs' self-initiated
deception on benign prompts. To address the absence of ground truth in this
evaluation, we propose a novel framework using "contact searching questions."
This framework introduces two statistical metrics derived from psychological
principles to quantify the likelihood of deception. The first, the Deceptive
Intention Score, measures the model's bias towards a hidden objective. The
second, Deceptive Behavior Score, measures the inconsistency between the LLM's
internal belief and its expressed output. Upon evaluating 14 leading LLMs, we
find that both metrics escalate as task difficulty increases, rising in
parallel for most models. Building on these findings, we formulate a
mathematical model to explain this behavior. These results reveal that even the
most advanced LLMs exhibit an increasing tendency toward deception when
handling complex problems, raising critical concerns for the deployment of LLM
agents in complex and crucial domains.

</details>


### [49] [ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design](https://arxiv.org/abs/2508.06364)
*Renyi Zhou,Huimin Zhu,Jing Tang,Min Li*

Main category: cs.LG

TL;DR: ActivityDiff라는 새로운 생성 접근법을 통해 분자의 생물학적 활성을 통합적으로 관리할 수 있는 방법을 제안한다. 이 방법은 효능과 안전성을 균형 있게 조절하는 데 효과적이다.


<details>
  <summary>Details</summary>
Motivation: 분자의 생물학적 활성을 정밀하게 제어하는 것은 약물 설계에서 중요한 도전 과제이다.

Method: 회귀모델의 분류기-guidance 기법을 바탕으로 한 생성적 접근법인 ActivityDiff를 제안한다.

Result: ActivityDiff는 단일/이중 목표 생성, 조각 제한 이중 목표 설계, 타겟 특이성을 높이기 위한 선택적 생성, 오프타겟 효과 감소 등 주요 약물 설계 작업을 효과적으로 처리한다.

Conclusion: 이 연구는 분자 활동에 대한 통합 제어를 달성하기 위한 새로운 패러다임을 도입하며, ActivityDiff를 다목적이고 확장 가능한 프레임워크로 제공한다.

Abstract: Achieving precise control over a molecule's biological activity-encompassing
targeted activation/inhibition, cooperative multi-target modulation, and
off-target toxicity mitigation-remains a critical challenge in de novo drug
design. However, existing generative methods primarily focus on producing
molecules with a single desired activity, lacking integrated mechanisms for the
simultaneous management of multiple intended and unintended molecular
interactions. Here, we propose ActivityDiff, a generative approach based on the
classifier-guidance technique of diffusion models. It leverages separately
trained drug-target classifiers for both positive and negative guidance,
enabling the model to enhance desired activities while minimizing harmful
off-target effects. Experimental results show that ActivityDiff effectively
handles essential drug design tasks, including single-/dual-target generation,
fragment-constrained dual-target design, selective generation to enhance target
specificity, and reduction of off-target effects. These results demonstrate the
effectiveness of classifier-guided diffusion in balancing efficacy and safety
in molecular design. Overall, our work introduces a novel paradigm for
achieving integrated control over molecular activity, and provides ActivityDiff
as a versatile and extensible framework.

</details>


### [50] [End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation](https://arxiv.org/abs/2508.06387)
*Anurag Tripathi,Vaibhav Patle,Abhinav Jain,Ayush Pundir,Sairam Menon,Ajeet Kumar Singh*

Main category: cs.LG

TL;DR: 이 논문은 사용자 의도에 맞는 데이터베이스를 식별한 후 SQL 쿼리를 생성하는 텍스트-투-SQL 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다수의 방대한 데이터베이스를 다룰 때 올바른 데이터베이스를 식별하는 것이 중요하지만, 기존의 텍스트-투-SQL 접근 방식은 이러한 문제를 간과하고 있었기 때문입니다.

Method: 이 논문은 LLM과 프롬프트 엔지니어링을 활용하여 NLQ로부터 규칙 세트를 추출한 다음, RoBERTa 기반의 파인튜닝된 인코더를 포함하는 db_id 예측 모델을 훈련시킵니다.

Result: 실험 결과, 우리가 제안하는 프레임워크는 데이터베이스 의도 예측 및 SQL 생성 정확도 모두에서 최신 모델들보다 우수함을 보여주었습니다.

Conclusion: 우리의 접근 방식은 텍스트-투-SQL 문제를 해결하는 데 중요한 개선 사항을 제공하며, 비기술 사용자가 데이터베이스를 보다 쉽게 쿼리할 수 있도록 합니다.

Abstract: Text-to-SQL bridges the gap between natural language and structured database
language, thus allowing non-technical users to easily query databases.
Traditional approaches model text-to-SQL as a direct translation task, where a
given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances
in large language models (LLMs) have significantly improved translation
accuracy, however, these methods all require that the target database is
pre-specified. This becomes problematic in scenarios with multiple extensive
databases, where identifying the correct database becomes a crucial yet
overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL
framework to identify the user's intended database before generating SQL
queries. Our approach leverages LLMs and prompt engineering to extract implicit
information from natural language queries (NLQs) in the form of a ruleset. We
then train a large db\_id prediction model, which includes a RoBERTa-based
finetuned encoder, to predict the correct Database identifier (db\_id) based on
both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL
by using critic agents to correct errors. Experimental results demonstrate that
our framework outperforms the current state-of-the-art models in both database
intent prediction and SQL generation accuracy.

</details>


### [51] [A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images](https://arxiv.org/abs/2508.06409)
*Wooyong Jung,Sola Kim,Dongwook Kim,Maryam Tabar,Dongwon Lee*

Main category: cs.LG

TL;DR: 미국의 노숙자 수가 대공황 이후 전례 없는 수준으로 증가하고 있으며, 기존 방법들이 한계를 가지고 있다. 이 연구는 샌프란시스코에서 공공 데이터와 크라우드소싱 데이터를 활용하여 노숙자 텐트 추세를 추적하고 예측하는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 노숙자 모니터링 방법이 빈도, 일관성 및 공간적 세부사항 측면에서 한계를 가지고 있어, 개선된 방안이 필요하다.

Method: 공공 데이터와 크라우드소싱 데이터를 활용하여 311 서비스 호출 및 거리 수준 이미지를 기반으로 노숙자 텐트 추세를 추적하고 예측하는 모델을 개발하였다.

Result: 우리의 예측 모델은 세부적인 일일 및 동네 수준의 변화를 포착하여 전통적인 카운트가 무시하는 패턴도 밝혀냈다.

Conclusion: 더 신속하고 지역화된 정보 제공으로 정책 대응 및 노숙자 문제 해결을 위한 개입 평가에 유용한 도구가 된다.

Abstract: Homelessness in the United States has surged to levels unseen since the Great
Depression. However, existing methods for monitoring it, such as point-in-time
(PIT) counts, have limitations in terms of frequency, consistency, and spatial
detail. This study proposes a new approach using publicly available,
crowdsourced data, specifically 311 Service Calls and street-level imagery, to
track and forecast homeless tent trends in San Francisco. Our predictive model
captures fine-grained daily and neighborhood-level variations, uncovering
patterns that traditional counts often overlook, such as rapid fluctuations
during the COVID-19 pandemic and spatial shifts in tent locations over time. By
providing more timely, localized, and cost-effective information, this approach
serves as a valuable tool for guiding policy responses and evaluating
interventions aimed at reducing unsheltered homelessness.

</details>


### [52] [Sample-efficient LLM Optimization with Reset Replay](https://arxiv.org/abs/2508.06412)
*Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian*

Main category: cs.LG

TL;DR: LoRR(Reset Replay를 통한 LLM 최적화)는 표본 효율성을 높이고 과적합의 위험을 줄이기 위해 설계된 강력한 플러그인으로, 다양한 선호 최적화 방법의 성능을 크게 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: LLM의 추론 능력을 향상시키기 위한 RL 및 선호 최적화 방법의 최근 발전에도 불구하고, 낮은 샘플 효율성과 초기 경험에 대한 과적합의 문제로 인해 품질 저하가 발생합니다.

Method: LoRR은 데이터 반복 수를 높여 각 데이터 배치의 유용성을 극대화하며, 초기 데이터를 재사용하는 정기적인 재설정 전략을 통해 네트워크 가소성을 유지합니다.

Result: LoRR은 다양한 선호 최적화 방법의 성능을 향상시키며, 특히 LoRR을 사용한 반복 DPO 접근 방식은 높은 수학 문제에서 복잡하고 계산 집약적인 RL 기반 알고리즘을 초월하는 성능을 보입니다.

Conclusion: LLR는 실용적이고 샘플 효율적이며 효과적인 LLM 미세 조정 패러다임을 제공하여 제한된 데이터에서 더 나은 성능을 이끌어냅니다.

Abstract: Recent advancements in post-training Large Language Models (LLMs),
particularly through Reinforcement Learning (RL) and preference optimization
methods, are key drivers for enhancing their reasoning capabilities. However,
these methods are often plagued by low sample efficiency and a susceptibility
to primacy bias, where overfitting to initial experiences degrades policy
quality and damages the learning process. To address these challenges, we
introduce LLM optimization with Reset Replay (LoRR), a general and powerful
plugin designed to enhance sample efficiency in any preference-based
optimization framework. LoRR core mechanism enables training at a high replay
number, maximizing the utility of each collected data batch. To counteract the
risk of overfitting inherent in high-replay training, LoRR incorporates a
periodic reset strategy with reusing initial data, which preserves network
plasticity. Furthermore, it leverages a hybrid optimization objective,
combining supervised fine-tuning (SFT) and preference-based losses to further
bolster data exploitation. Our extensive experiments demonstrate that LoRR
significantly boosts the performance of various preference optimization methods
on both mathematical and general reasoning benchmarks. Notably, an iterative
DPO approach augmented with LoRR achieves comparable performance on challenging
math tasks, outperforming some complex and computationally intensive RL-based
algorithms. These findings highlight that LoRR offers a practical,
sample-efficient, and highly effective paradigm for LLM finetuning, unlocking
greater performance from limited data.

</details>


### [53] [LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection](https://arxiv.org/abs/2508.06467)
*Ameya Anjarlekar,Sandeep Pombra*

Main category: cs.LG

TL;DR: 이 논문에서는 대형 언어 모델의 효과적인 기계적 학습 제거를 위한 GRIN이라는 모듈화된 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델에 대한 법적 및 윤리적 감시가 증가함에 따라 특히 민감하거나 무단 데이터에 대한 효과적인 기계적 학습 제거가 필요합니다.

Method: GRIN은 잊어야 할 데이터를 기억하는 데 가장 책임이 있는 매개변수를 식별하기 위해 새로운 그래디언트 비율 기반 메트릭을 도입하고, 이 매개변수에 선택적인 노이즈 주입을 수행하여 모델 유틸리티를 유지하면서 학습 제거 성능을 개선합니다.

Result: 새로운 평가 메트릭을 제안하고 TOFU, WMDP, SafePKU와 같은 표준 벤치마크에서 접근 방식을 검증했습니다.

Conclusion: 이 연구는 대형 언어 모델의 기계적 학습 제거를 위한 효과적인 방법을 제시합니다.

Abstract: The growing legal and ethical scrutiny of large language models (LLMs)
necessitates effective machine unlearning, particularly for sensitive or
unauthorized data. Existing empirical methods often yield incomplete forgetting
or unintended degradation of unrelated knowledge due to poor localization. In
this work, we propose GRIN: a modular and targeted framework for LLM
unlearning. GRIN introduces a novel gradient-ratio-based metric to identify
parameters most responsible for memorizing forget data. We then perform
selective noise injection into these parameters prior to fine-tuning, which
improves unlearning performance while maintaining model utility. Finally, we
propose new evaluation metrics tailored to the LLM setting and validate our
approach on standard benchmarks such as TOFU, WMDP, and SafePKU.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [54] [Blockchain-Based Decentralized Domain Name System](https://arxiv.org/abs/2508.05655)
*Guang Yang,Peter Trinh,Alma Nkemla,Amuru Serikyaku,Edward Tatchim,Osman Sharaf*

Main category: cs.CR

TL;DR: 본 논문은 블록체인 기반의 분산 도메인 네임 시스템을 제안하여 현재 DNS의 취약점을 극복하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 현재 DNS 인프라는 인터넷 자유와 보안을 위협하는 취약점으로 가득차 있으며, 이러한 문제를 해결하기 위한 긴급한 대안이 필요하다.

Method: 특화된 작업 증명 블록체인을 설계하여 DNS 관련 프로토콜 지원을 극대화하고 노드 분산화를 달성하였다.

Result: 시스템은 15초 도메인 기록 전파 시간과 20종류의 표준 DNS 레코드 유형을 지원하며, 무료 .ddns 도메인을 제공한다.

Conclusion: 분산 인프라에 배포된 시스템은 전통적인 DNS 조작 기법에 대한 저항성을 입증하며, 성능 평가를 통해 도메인 작업에 대하여 최대 이론 TPS 1,111.1 tx/s와 266.7 tx/s를 처리할 수 있음이 나타났다.

Abstract: The current Domain Name System (DNS) infrastructure faces critical
vulnerabilities including poisoning attacks, censorship mechanisms, and
centralized points of failure that compromise internet freedom and security.
Recent incidents such as DNS poisoning attacks on ISP customers highlight the
urgent need for resilient alternatives. This paper presents a novel
blockchain-based Decentralized Domain Name System (DDNS). We designed a
specialized Proof-of-Work blockchain to maximize support for DNS-related
protocols and achieve node decentralization. The system integrates our
blockchain with IPFS for distributed storage, implements cryptographic
primitives for end-to-end trust signatures, and achieves Never Trust, Always
Verify zero-trust verification. Our implementation achieves 15-second domain
record propagation times, supports 20 standard DNS record types, and provides
perpetual free .ddns domains. The system has been deployed across distributed
infrastructure in San Jose, Los Angeles, and Orange County, demonstrating
practical scalability and resistance to traditional DNS manipulation
techniques. Performance evaluation shows the system can handle up to Max Theor.
TPS 1,111.1 tx/s (minimal transactions) and Max Theor. TPS 266.7 tx/s (regular
transactions) for domain operations while maintaining sub-second query
resolution through intelligent caching mechanisms.

</details>


### [55] [Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards](https://arxiv.org/abs/2508.05658)
*Song Yan,Hui Wei,Jinlong Fei,Guoliang Yang,Zhengyu Zhao,Zheng Wamg*

Main category: cs.CR

TL;DR: 이 논문에서는 텍스트-이미지(T2I) 모델의 안전성 검사기를 우회하기 위한 U3-Attack이라는 다중모달 탈옥 공격 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: T2I 모델이 NSFW 콘텐츠를 생성하는 것을 방지하기 위해 다양한 필터와 안전 검사기가 구현되었으나, 이러한 보호 장치의 보안 취약점을 노출할 필요가 있습니다.

Method: U3-Attack은 이미지 배경에서 적대적 패치를 최적화하여 안전 검사기를 우회하고, 민감한 단어에서 안전한 의역 세트를 최적화하여 프롬프트 필터를 우회합니다.

Result: U3-Attack은 공개 소스 및 상용 T2I 모델 모두에서 뛰어난 성능을 보이며, 예를 들어 Runway-inpainting 모델에서 $~4	imes$ 더 높은 성공률을 기록했습니다.

Conclusion: U3-Attack은 최신 멀티모달 탈옥 공격 기법에 비해 뛰어난 성과를 보여줍니다.

Abstract: Various (text) prompt filters and (image) safety checkers have been
implemented to mitigate the misuse of Text-to-Image (T2I) models in creating
Not-Safe-For-Work (NSFW) content.In order to expose potential security
vulnerabilities of such safeguards, multimodal jailbreaks have been
studied.However, existing jailbreaks are limited to prompt-specific and
image-specific perturbations, which suffer from poor scalability and
time-consuming optimization.To address these limitations, we propose
Universally Unfiltered and Unseen (U3)-Attack, a multimodal jailbreak attack
method against T2I safeguards.Specifically, U3-Attack optimizes an adversarial
patch on the image background to universally bypass safety checkers and
optimizes a safe paraphrase set from a sensitive word to universally bypass
prompt filters while eliminating redundant computations.Extensive experimental
results demonstrate the superiority of our U3-Attack on both open-source and
commercial T2I models.For example, on the commercial Runway-inpainting model
with both prompt filter and safety checker, our U3-Attack achieves $~4\times$
higher success rates than the state-of-the-art multimodal jailbreak attack,
MMA-Diffusion.Content Warning: This paper includes examples of NSFW content.

</details>


### [56] [Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?](https://arxiv.org/abs/2508.05670)
*Daniele Proverbio,Alessio Buscemi,Alessandro Di Stefano,The Anh Han,German Castignani,Pietro Liò*

Main category: cs.CR

TL;DR: 게임 이론은 사이버 보안에서 공격자와 방어자 간의 전략적 상호작용을 테스트하고 예측하며 설계하는 데 중요한 도구로서 오랫동안 활용되어 왔다. 본 연구에서는 대형 언어 모델(LLM)을 기반으로 하는 행위자와 봇의 행동을 효과적으로 포착할 수 있는지를 고전 게임 이론적 틀을 통해 조사하였다. 우리는 반복 가능한 게임 이론적 LLM 에이전트를 위한 프레임워크를 사용하여 일회성 제로섬 게임과 동적 죄수의 딜레마라는 두 가지 전형적인 시나리오를 조사하였으며, LLM이 예상 결과에 수렴하는지 또는 내재된 편향으로 인해 이탈하는지를 테스트했다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 출현이 사이버 보안에서 새로운 도구와 도전을 제공함에 따라, 전통적인 게임 이론 프레임워크가 어떻게 작용할 수 있는지를 탐구하고자 했다.

Method: 재현 가능한 게임 이론적 LLM 에이전트를 위한 프레임워크를 사용하여 일회성 제로섬 게임과 동적 죄수의 딜레마 두 가지 시나리오를 통해 LLM의 행동을 분석했다.

Result: 최종 보상이 에이전트의 특성(성격 특성이나 반복 라운드에 대한 지식 등)에 의해 영향을 받으며, 언어 선택에 대한 민감성이 보였다.

Conclusion: LLM은 서로 다른 국가에 배치될 때 다르게 행동할 수 있으므로 사이버 보안 응용 프로그램에서 LLM의 무차별한 적용에 경고해야 하며, 가장 안정적인 LLM 선택과 안전한 응용 프로그램을 위한 모델 최적화를 돕기 위해 정량적 메트릭을 사용했다.

Abstract: Game theory has long served as a foundational tool in cybersecurity to test,
predict, and design strategic interactions between attackers and defenders. The
recent advent of Large Language Models (LLMs) offers new tools and challenges
for the security of computer systems; In this work, we investigate whether
classical game-theoretic frameworks can effectively capture the behaviours of
LLM-driven actors and bots. Using a reproducible framework for game-theoretic
LLM agents, we investigate two canonical scenarios -- the one-shot zero-sum
game and the dynamic Prisoner's Dilemma -- and we test whether LLMs converge to
expected outcomes or exhibit deviations due to embedded biases. Our experiments
involve four state-of-the-art LLMs and span five natural languages, English,
French, Arabic, Vietnamese, and Mandarin Chinese, to assess linguistic
sensitivity. For both games, we observe that the final payoffs are influenced
by agents characteristics such as personality traits or knowledge of repeated
rounds. Moreover, we uncover an unexpected sensitivity of the final payoffs to
the choice of languages, which should warn against indiscriminate application
of LLMs in cybersecurity applications and call for in-depth studies, as LLMs
may behave differently when deployed in different countries. We also employ
quantitative metrics to evaluate the internal consistency and cross-language
stability of LLM agents, to help guide the selection of the most stable LLMs
and optimising models for secure applications.

</details>


### [57] [DINA: A Dual Defense Framework Against Internal Noise and External Attacks in Natural Language Processing](https://arxiv.org/abs/2508.05671)
*Ko-Wei Chuang,Hen-Hsen Huang,Tsai-Yen Li*

Main category: cs.CR

TL;DR: DINA라는 새로운 통합 프레임워크를 통해 NLP의 내부 노이즈 및 적대적 공격에 대한 이중 방어를 다루어 모델의 강건성과 정확성을 크게 향상시켰습니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델과 생성 AI의 고객 서비스 및 조정 응용 프로그램 통합 증가로 인해 외부 조작과 내부 레이블 손상에서 오는 적대적 위협이 발생하고 있습니다.

Method: DINA(내부 노이즈 및 적대적 공격에 대한 이중 방어)라는 새로운 통합 프레임워크를 소개하고, 컴퓨터 비전의 진보된 노이즈가 있는 레이블 학습 방법을 적대적 훈련과 통합하여 내부 레이블 파괴와 외부 적대적 교란을 동시에 완화합니다.

Result: 온라인 게임 서비스의 실제 데이터세트를 사용한 광범위한 실험 결과 DINA가 기준 모델에 비해 모델의 강건성과 정확성을 현저히 향상시켰습니다.

Conclusion: 이중 위협 방어의 필요성을 강조하고, 현실의 적대적 상황에서 NLP 시스템을 보호하기 위한 실용적인 전략을 제공합니다.

Abstract: As large language models (LLMs) and generative AI become increasingly
integrated into customer service and moderation applications, adversarial
threats emerge from both external manipulations and internal label corruption.
In this work, we identify and systematically address these dual adversarial
threats by introducing DINA (Dual Defense Against Internal Noise and
Adversarial Attacks), a novel unified framework tailored specifically for NLP.
Our approach adapts advanced noisy-label learning methods from computer vision
and integrates them with adversarial training to simultaneously mitigate
internal label sabotage and external adversarial perturbations. Extensive
experiments conducted on a real-world dataset from an online gaming service
demonstrate that DINA significantly improves model robustness and accuracy
compared to baseline models. Our findings not only highlight the critical
necessity of dual-threat defenses but also offer practical strategies for
safeguarding NLP systems in realistic adversarial scenarios, underscoring
broader implications for fair and responsible AI deployment.

</details>


### [58] [ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls](https://arxiv.org/abs/2508.06457)
*Sanket Badhe*

Main category: cs.CR

TL;DR: 이 논문은 ScamAgent라는 자율적 다중 회전 에이전트를 소개하며, 이는 LLM을 기반으로 하여 매우 현실적인 사기 전화 스크립트를 생성할 수 있는 능력을 갖추고 있다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 남용 가능성이 커짐에 따라, 사기 시나리오를 시뮬레이션하는 스크립트를 자동으로 생성할 수 있는 시스템의 필요성이 대두되었다.

Method: ScamAgent는 대화 기억을 유지하고, 사용자 응답에 동적으로 적응하며, 대화의 회전마다 기만적인 설득 전략을 사용하는 자율 에이전트이다.

Result: 현재의 LLM 안전 장치가 이러한 에이전트 기반의 위협에 대해 효과적이지 않음을 보여주며, 프롬프트를 분해하거나 변장할 때 강력한 프롬프트 수준 안전 장치가 우회될 수 있음을 입증하였다.

Conclusion: 다중 회전 안전 감사, 에이전트 수준 제어 프레임워크, 생성 AI에 의해 구동되는 대화의 기만을 탐지하고 교란시키기 위한 새로운 방법의 필요성이 시급함을 강조한다.

Abstract: Large Language Models (LLMs) have demonstrated impressive fluency and
reasoning capabilities, but their potential for misuse has raised growing
concern. In this paper, we present ScamAgent, an autonomous multi-turn agent
built on top of LLMs, capable of generating highly realistic scam call scripts
that simulate real-world fraud scenarios. Unlike prior work focused on
single-shot prompt misuse, ScamAgent maintains dialogue memory, adapts
dynamically to simulated user responses, and employs deceptive persuasion
strategies across conversational turns. We show that current LLM safety
guardrails, including refusal mechanisms and content filters, are ineffective
against such agent-based threats. Even models with strong prompt-level
safeguards can be bypassed when prompts are decomposed, disguised, or delivered
incrementally within an agent framework. We further demonstrate the
transformation of scam scripts into lifelike voice calls using modern
text-to-speech systems, completing a fully automated scam pipeline. Our
findings highlight an urgent need for multi-turn safety auditing, agent-level
control frameworks, and new methods to detect and disrupt conversational
deception powered by generative AI.

</details>


### [59] [Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark](https://arxiv.org/abs/2508.05674)
*Minghao Shao,Nanda Rani,Kimberly Milner,Haoran Xi,Meet Udeshi,Saksham Aggarwal,Venkata Sai Charan Putrevu,Sandeep Kumar Shukla,Prashanth Krishnamurthy,Farshad Khorrami,Ramesh Karri,Muhammad Shafique*

Main category: cs.CR

TL;DR: LLM 기반 공격 보안 에이전트의 성공 요인을 분석하고, CTFChallenge를 위한 평가 프레임워크를 개발하는 연구.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트 시스템의 발전으로 공격 보안 과제가 자동화되고 있지만, 효과적인 LLM 기반 에이전트를 구축하기 위한 체계적인 접근이 필요하다.

Method: CTFJudge라는 프레임워크를 통해 LLM을 활용해 에이전트의 경로를 분석하고, CTF 문제 해결 과정에서 세부 평가를 제공한다. 또한 CTF Competency Index (CCI)라는 새로운 메트릭을 제안하여 에이전트의 해결 방법이 인간의 최적 솔루션에 얼마나 부합하는지를 분석한다. LLM 하이퍼파라미터의 영향을 검토하고, 50개의 대표적인 CTF 도전 과제를 포함하는 CTFTiny 벤치마크를 제공한다.

Result: 최적의 다중 에이전트 협업 설정을 식별하고 사이버 보안 분야에서의 LLM 에이전트 연구를 위한 기초를 마련하였다.

Conclusion: CTFTiny와 CTFJudge를 공개 소스 프로젝트로 제공하며, 이를 통해 연구자들이 더욱 발전된 LLM 기반 공격 보안 에이전트를 개발할 수 있도록 한다.

Abstract: Recent advances in LLM agentic systems have improved the automation of
offensive security tasks, particularly for Capture the Flag (CTF) challenges.
We systematically investigate the key factors that drive agent success and
provide a detailed recipe for building effective LLM-based offensive security
agents. First, we present CTFJudge, a framework leveraging LLM as a judge to
analyze agent trajectories and provide granular evaluation across CTF solving
steps. Second, we propose a novel metric, CTF Competency Index (CCI) for
partial correctness, revealing how closely agent solutions align with
human-crafted gold standards. Third, we examine how LLM hyperparameters, namely
temperature, top-p, and maximum token length, influence agent performance and
automated cybersecurity task planning. For rapid evaluation, we present
CTFTiny, a curated benchmark of 50 representative CTF challenges across binary
exploitation, web, reverse engineering, forensics, and cryptography. Our
findings identify optimal multi-agent coordination settings and lay the
groundwork for future LLM agent research in cybersecurity. We make CTFTiny open
source to public https://github.com/NYU-LLM-CTF/CTFTiny along with CTFJudge on
https://github.com/NYU-LLM-CTF/CTFJudge.

</details>


### [60] [Principle-Guided Verilog Optimization: IP-Safe Knowledge Transfer via Local-Cloud Collaboration](https://arxiv.org/abs/2508.05675)
*Jing Wang,Zheng Li,Lei Li,Fan He,Liyu Lin,Yao Lai,Yan Li,Xiaoyang Zeng,Yufeng Guo*

Main category: cs.CR

TL;DR: 본 논문은 지적 재산 정보 유출 없이 Verilog 코드를 최적화하기 위한 새로운 방법론을 제안한다. IP 보호를 위한 엣지-클라우드 협업 프레임워크를 구축하여 로컬 소형 LLM과 클라우드 LLM을 결합해 최적화를 진행하며, 실험을 통해 기존 방법들보다 높은 성공률을 보임을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델이 RTL 코드 최적화에 대한 관심이 증가하고 있지만, 기존 클라우드 기반 LLM은 지적 재산(IP) 유출 위험이 있다.

Method: 로컬 소형 LLM을 사용해 목표 디자인과 초안 코드 간의 안전한 비교 분석을 수행하고, 이를 기반으로 더 강력한 클라우드 LLM에 질의하여 코드를 개선한다.

Result: 이 프레임워크는 기존 방법에 비해 최적화 성공률을 유의미하게 향상시켰고, 예를 들어 Qwen-2.5-Coder-7B과 Deepseek-V3 결합 시 전력 사용 최적화 성공률이 66.67%에 달했다. 이는 Deepseek-V3(49.81%) 및 GPT-4o(55.81%)와 같은 상용 모델보다 높은 수치이다.

Conclusion: 본 연구는 IP 보호와 성능 이득을 균형있게 고려하여 안전한 하드웨어 설계 최적화의 새로운 패러다임을 제시한다.

Abstract: Recent years have witnessed growing interest in adopting large language
models (LLMs) for Register Transfer Level (RTL) code optimization. While
powerful cloud-based LLMs offer superior optimization capabilities, they pose
unacceptable intellectual property (IP) leakage risks when processing
proprietary hardware designs. In this paper, we propose a new scenario where
Verilog code must be optimized for specific attributes without leaking
sensitive IP information. We introduce the first IP-preserving edge-cloud
collaborative framework that leverages the benefits of both paradigms. Our
approach employs local small LLMs (e.g., Qwen-2.5-Coder-7B) to perform secure
comparative analysis between paired high-quality target designs and novice
draft codes, yielding general design principles that summarize key insights for
improvements. These principles are then used to query stronger cloud LLMs
(e.g., Deepseek-V3) for targeted code improvement, ensuring that only
abstracted and IP-safe guidance reaches external services. Our experimental
results demonstrate that the framework achieves significantly higher
optimization success rates compared to baseline methods. For example, combining
Qwen-2.5-Coder-7B and Deepseek-V3 achieves a 66.67\% optimization success rate
for power utilization, outperforming Deepseek-V3 alone (49.81\%) and even
commercial models like GPT-4o (55.81\%). Further investigation of local and
cloud LLM combinations reveals that different model pairings exhibit varying
strengths for specific optimization objectives, with interesting trends
emerging when varying the number of comparative code pairs. Our work
establishes a new paradigm for secure hardware design optimization that
balances performance gains with IP protection.

</details>


### [61] [Adversarial Attacks on Reinforcement Learning-based Medical Questionnaire Systems: Input-level Perturbation Strategies and Medical Constraint Validation](https://arxiv.org/abs/2508.05677)
*Peizhuo Liu*

Main category: cs.CR

TL;DR: RL 기반의 의료 질문 시스템의 안전성과 견고성을 평가하기 위한 연구로, 다양한 적대적 공격 방법을 구현하고 그 취약성을 분석했다.


<details>
  <summary>Details</summary>
Motivation: RL 기반 의료 질문 시스템은 의료 시나리오에서 큰 잠재력을 보이지만, 안전성과 견고성이 해결되지 않은 문제로 남아 있다.

Method: 진단 과정을 Markov 의사 결정 과정(MDP)으로 설정하고, 6개의 주요 적대적 공격 방법(FGSM, PGD, C&W, BIM, DeepFool, AutoAttack)을 각기 7개의 엡실론 값으로 구현하였다. 247개의 의학적 제약을 포함하는 의료 검증 프레임워크를 개발하여 생성된 적대적 사례가 임상적으로 타당하도록 하였다.

Result: 97.6%의 성공률로 임상적으로 타당한 적대적 샘플을 생성하였다. NHIS 데이터셋을 이용하여 참가자의 4년 사망률을 예측한 결과, 공격 성공률은 FGSM에서 33.08%에서 AutoAttack에서 64.70%에 이르는 것으로 나타났다.

Conclusion: 엄격한 의료 제약이 있는 상황에서도 RL 기반 의료 질문 시스템이 여전히 상당한 취약점을 드러냄을 입증하였다.

Abstract: RL-based medical questionnaire systems have shown great potential in medical
scenarios. However, their safety and robustness remain unresolved. This study
performs a comprehensive evaluation on adversarial attack methods to identify
and analyze their potential vulnerabilities. We formulate the diagnosis process
as a Markov Decision Process (MDP), where the state is the patient responses
and unasked questions, and the action is either to ask a question or to make a
diagnosis. We implemented six prevailing major attack methods, including the
Fast Gradient Signed Method (FGSM), Projected Gradient Descent (PGD), Carlini &
Wagner Attack (C&W) attack, Basic Iterative Method (BIM), DeepFool, and
AutoAttack, with seven epsilon values each. To ensure the generated adversarial
examples remain clinically plausible, we developed a comprehensive medical
validation framework consisting of 247 medical constraints, including
physiological bounds, symptom correlations, and conditional medical
constraints. We achieved a 97.6% success rate in generating clinically
plausible adversarial samples. We performed our experiment on the National
Health Interview Survey (NHIS) dataset (https://www.cdc.gov/nchs/nhis/), which
consists of 182,630 samples, to predict the participant's 4-year mortality
rate. We evaluated our attacks on the AdaptiveFS framework proposed in
arXiv:2004.00994. Our results show that adversarial attacks could significantly
impact the diagnostic accuracy, with attack success rates ranging from 33.08%
(FGSM) to 64.70% (AutoAttack). Our work has demonstrated that even under strict
medical constraints on the input, such RL-based medical questionnaire systems
still show significant vulnerabilities.

</details>


### [62] [Selection-Based Vulnerabilities: Clean-Label Backdoor Attacks in Active Learning](https://arxiv.org/abs/2508.05681)
*Yuhan Zhi,Longtian Wang,Xiaofei Xie,Chao Shen,Qiang Hu,Xiaohong Guan*

Main category: cs.CR

TL;DR: 이 논문은 능동 학습(Active Learning, AL)의 안전성 문제를 다루며, AL의 약점을 드러내기 위해 획득 함수(acquisition function)를 악용하는 프레임워크인 ALA를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 능동 학습은 리소스 제약이 있는 상황에서 효율적인 라벨 학습을 제공하지만, AL의 안전성에 대한 의문을 제기합니다.

Method: ALA는 미세하게 오염된 입력을 최적화하여 높은 불확실성 점수를 나타내게 하여 획득 함수에 의해 선택될 확률을 높입니다.

Result: 세 개의 데이터셋과 세 개의 획득 함수, 두 가지 유형의 클린-라벨 백도어 트리거를 이용한 실험을 통해, 우리의 공격은 낮은 오염 예산에서도 높은 성공률(최대 94%)을 달성했습니다.

Conclusion: 능동 학습 사용자는 획득 함수가 쉽게 악용될 수 있음을 인지하고, 신뢰할 수 있는 데이터 시나리오에서 능동 학습을 주의 깊게 도입해야 합니다.

Abstract: Active learning(AL), which serves as the representative label-efficient
learning paradigm, has been widely applied in resource-constrained scenarios.
The achievement of AL is attributed to acquisition functions, which are
designed for identifying the most important data to label. Despite this
success, one question remains unanswered: is AL safe? In this work, we
introduce ALA, a practical and the first framework to utilize the acquisition
function as the poisoning attack surface to reveal the weakness of active
learning. Specifically, ALA optimizes imperceptibly poisoned inputs to exhibit
high uncertainty scores, increasing their probability of being selected by
acquisition functions. To evaluate ALA, we conduct extensive experiments across
three datasets, three acquisition functions, and two types of clean-label
backdoor triggers. Results show that our attack can achieve high success rates
(up to 94%) even under low poisoning budgets (0.5%-1.0%) while preserving model
utility and remaining undetectable to human annotators. Our findings remind
active learning users: acquisition functions can be easily exploited, and
active learning should be deployed with caution in trusted data scenarios.

</details>


### [63] [MM-FusionNet: Context-Aware Dynamic Fusion for Multi-modal Fake News Detection with Large Vision-Language Models](https://arxiv.org/abs/2508.05684)
*Junhao He,Tianyu Liu,Jingyuan Zhao,Benjamin Turner*

Main category: cs.CR

TL;DR: 이 논문은 다중 모달 가짜 뉴스 탐지를 위한 MM-FusionNet이라는 혁신적인 프레임워크를 소개하며, 이를 통해 기존 방법들을 초월하는 성능을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 소셜 미디어에서 다중 모달 가짜 뉴스의 확산은 공공 신뢰와 사회 안정성에 심각한 위협을 가하고 있습니다.

Method: 본 논문은 LVLM을 활용한 MM-FusionNet이라는 프레임워크를 도입하며, 특히 맥락에 대한 인식을 고려한 동적 융합 모듈(CADFM)을 통해 텍스트와 시각적 특징의 중요성을 적응적으로 조정합니다.

Result: MM-FusionNet은 LMFND 데이터셋에서 0.938의 최첨단 F1-score를 달성하여 기존 다중 모달 기준을 약 0.5% 초과하고 단일 모달 접근법보다 유의미하게 뛰어난 성능을 보여주었습니다.

Conclusion: 모델의 역동적 가중치 조정 능력과 모달 perturbation에 대한 강인성을 통해 실제 세계의 가짜 뉴스 탐지에 대한 실용성과 해석 가능성을 강조합니다.

Abstract: The proliferation of multi-modal fake news on social media poses a
significant threat to public trust and social stability. Traditional detection
methods, primarily text-based, often fall short due to the deceptive interplay
between misleading text and images. While Large Vision-Language Models (LVLMs)
offer promising avenues for multi-modal understanding, effectively fusing
diverse modal information, especially when their importance is imbalanced or
contradictory, remains a critical challenge. This paper introduces
MM-FusionNet, an innovative framework leveraging LVLMs for robust multi-modal
fake news detection. Our core contribution is the Context-Aware Dynamic Fusion
Module (CADFM), which employs bi-directional cross-modal attention and a novel
dynamic modal gating network. This mechanism adaptively learns and assigns
importance weights to textual and visual features based on their contextual
relevance, enabling intelligent prioritization of information. Evaluated on the
large-scale Multi-modal Fake News Dataset (LMFND) comprising 80,000 samples,
MM-FusionNet achieves a state-of-the-art F1-score of 0.938, surpassing existing
multi-modal baselines by approximately 0.5% and significantly outperforming
single-modal approaches. Further analysis demonstrates the model's dynamic
weighting capabilities, its robustness to modality perturbations, and
performance remarkably close to human-level, underscoring its practical
efficacy and interpretability for real-world fake news detection.

</details>


### [64] [Leveraging large language models for SQL behavior-based database intrusion detection](https://arxiv.org/abs/2508.05690)
*Meital Shlezinger,Shay Akirav,Lei Zhou,Liang Guo,Avi Kessel,Guoliang Li*

Main category: cs.CR

TL;DR: 이 논문은 SQL을 위한 이단계 이상 탐지 방법을 소개하며, BERT 모델을 사용하여 정교한 위협으로부터 데이터베이스 시스템을 보호하는 효과적인 솔루션을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 데이터베이스 시스템의 비정상적인 접근 행동이 증가하고 있으며, 특히 내부자 공격이 더 어려운 문제를 야기하고 있습니다.

Method: DistilBERT를 사용하여 비지도 및 지도 기계 학습 기술을 결합하여 비정상 활동을 정확하게 식별하는 두 단계의 이상 탐지 방법을 제안합니다.

Result: 우리는 데이터베이스에서 일반적인 사용자 행동의 정상 패턴에서 벗어난 임베딩 벡터를 플래그하는 앙상블 이상 감지기와 고정밀 내부 공격 탐지를 위한 세분화된 변형 기반 모델을 사용하여 문제를 해결합니다.

Conclusion: 우리는 이 연구가 정교한 위협으로부터 데이터베이스 시스템을 보호하기 위한 효과적인 솔루션을 제공하여 중요한 기여를 한다고 결론 내립니다.

Abstract: Database systems are extensively used to store critical data across various
domains. However, the frequency of abnormal database access behaviors, such as
database intrusion by internal and external attacks, continues to rise.
Internal masqueraders often have greater organizational knowledge, making it
easier to mimic employee behavior effectively. In contrast, external
masqueraders may behave differently due to their lack of familiarity with the
organization. Current approaches lack the granularity needed to detect
anomalies at the operational level, frequently misclassifying entire sequences
of operations as anomalies, even though most operations are likely to represent
normal behavior. On the other hand, some anomalous behaviors often resemble
normal activities, making them difficult for existing detection methods to
identify. This paper introduces a two-tiered anomaly detection approach for
Structured Query Language (SQL) using the Bidirectional Encoder Representations
from Transformers (BERT) model, specifically DistilBERT, a more efficient,
pre-trained version. Our method combines both unsupervised and supervised
machine learning techniques to accurately identify anomalous activities while
minimizing the need for data labeling. First, the unsupervised method uses
ensemble anomaly detectors that flag embedding vectors distant from learned
normal patterns of typical user behavior across the database (out-of-scope
queries). Second, the supervised method uses fine-tuned transformer-based
models to detect internal attacks with high precision (in-scope queries), using
role-labeled classification, even on limited labeled SQL data. Our findings
make a significant contribution by providing an effective solution for
safeguarding critical database systems from sophisticated threats.

</details>


### [65] [AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers](https://arxiv.org/abs/2508.05691)
*Kai Yao,Marc Juarez*

Main category: cs.CR

TL;DR: 본 연구는 생성 모델 출력의 출처를 검증하는 기존 메커니즘의 부재를 해결하기 위해 모델 지문 기술을 확장한다.


<details>
  <summary>Details</summary>
Motivation: 고위험 분야에서 생성 모델의 채택이 증가하고 있으나, 모델 출력의 출처를 검증할 수 있는 메커니즘이 없는 점을 해결하고자 한다.

Method: 신뢰할 수 있는 검증자가 모델의 출력 공간에서 비밀 지문을 추출하고 이를 예측하고 검증하는 모델을 훈련하는 방법에 의존한다.

Result: 우리의 경험적 평가는 GAN 및 확산 모델의 인스턴스에 대해 95% TPR에서 거의 0의 FPR을 달성함을 보여준다.

Conclusion: 제안한 방법은 출력이 탐지를 우회하기 위해 적극적으로 수정하는 적대적 공격에 대해서도 강력함이 유지된다.

Abstract: Generative models are increasingly adopted in high-stakes domains, yet
current deployments offer no mechanisms to verify the origin of model outputs.
We address this gap by extending model fingerprinting techniques beyond the
traditional collaborative setting to one where the model provider may act
adversarially. To our knowledge, this is the first work to evaluate
fingerprinting for provenance attribution under such a threat model. The
methods rely on a trusted verifier that extracts secret fingerprints from the
model's output space, unknown to the provider, and trains a model to predict
and verify them. Our empirical evaluation shows that our methods achieve
near-zero FPR@95%TPR for instances of GAN and diffusion models, even when
tested on small modifications to the original architecture and training data.
Moreover, the methods remain robust against adversarial attacks that actively
modify the outputs to bypass detection. Source codes are available at
https://github.com/PSMLab/authprint.

</details>


### [66] [DMFI: Dual-Modality Fine-Tuning and Inference Framework for LLM-Based Insider Threat Detection](https://arxiv.org/abs/2508.05694)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Guanggang Geng,Zhiying Li,Jian Weng*

Main category: cs.CR

TL;DR: 이 연구는 악의적인 내부자 행동 탐지를 위한 DMFI라는 이중 모달리티 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 악의적인 내부자 행동의 미묘하고 장기적이며 맥락에 의존하는 특성으로 인해 사이버 보안에서 내부자 위협 탐지가 지속적이고 강력한 도전 과제가 되고 있다.

Method: DMFI는 내용이 풍부한 아티팩트를 처리하는 의미적 뷰와 맥락적 행동 시퀀스를 인코딩하기 위해 4W 가이드를 사용하는 행동 추상화를 통합한다.

Result: DMFI는 CERT r4.2 및 r5.2 데이터셋에서 최첨단 탐지 정확도를 초과하는 결과를 보였다.

Conclusion: 우리의 접근법은 LLM의 의미 추론 능력과 구조적 행동 모델링을 결합하여 실제 내부자 위협 탐지를 위한 확장 가능하고 효과적인 솔루션을 제공한다.

Abstract: Insider threat detection (ITD) poses a persistent and high-impact challenge
in cybersecurity due to the subtle, long-term, and context-dependent nature of
malicious insider behaviors. Traditional models often struggle to capture
semantic intent and complex behavior dynamics, while existing LLM-based
solutions face limitations in prompt adaptability and modality coverage. To
bridge this gap, we propose DMFI, a dual-modality framework that integrates
semantic inference with behavior-aware fine-tuning. DMFI converts raw logs into
two structured views: (1) a semantic view that processes content-rich artifacts
(e.g., emails, https) using instruction-formatted prompts; and (2) a behavioral
abstraction, constructed via a 4W-guided (When-Where-What-Which) transformation
to encode contextual action sequences. Two LoRA-enhanced LLMs are fine-tuned
independently, and their outputs are fused via a lightweight MLP-based decision
module. We further introduce DMFI-B, a discriminative adaptation strategy that
separates normal and abnormal behavior representations, improving robustness
under severe class imbalance. Experiments on CERT r4.2 and r5.2 datasets
demonstrate that DMFI outperforms state-of-the-art methods in detection
accuracy. Our approach combines the semantic reasoning power of LLMs with
structured behavior modeling, offering a scalable and effective solution for
real-world insider threat detection. Our work demonstrates the effectiveness of
combining LLM reasoning with structured behavioral modeling, offering a
scalable and deployable solution for modern insider threat detection.

</details>


### [67] [MambaITD: An Efficient Cross-Modal Mamba Network for Insider Threat Detection](https://arxiv.org/abs/2508.05695)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Zhiying Li,Guanggang Geng,Jian Weng*

Main category: cs.CR

TL;DR: MambaITD라는 새로운 내부 위협 탐지 프레임워크를 제안하며, 멀티 소스 로그 전처리, Mamba 인코더 및 적응형 임계값 최적화를 통해 기존 방법보다 높은 효율성과 정확성을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기업은 내부 위협의 위험이 증가하고 있지만 기존 탐지 방법은 동적 특성 모델링 부족, 계산 효율성 및 실시간 병목 현상 등으로 이러한 문제를 효과적으로 해결하지 못하고 있다.

Method: MambaITD는 Mamba 상태 공간 모델과 크로스 모달 적응형 융합에 기반한 내부 위협 탐지 프레임워크를 제안하며, 멀티 소스 로그 전처리, Mamba 인코더 및 적응형 임계값 최적화 방법을 포함한다.

Result: MambaITD는 모델링 효율성과 특성 융합 능력에서 상당한 이점을 보이며, 전통적인 방법보다 더 높은 성능을 발휘하고, Transformer 기반 방법보다 우수하다.

Conclusion: MambaITD는 내부 위협 탐지에 대해 보다 효과적인 해결책을 제공한다.

Abstract: Enterprises are facing increasing risks of insider threats, while existing
detection methods are unable to effectively address these challenges due to
reasons such as insufficient temporal dynamic feature modeling, computational
efficiency and real-time bottlenecks and cross-modal information island
problem. This paper proposes a new insider threat detection framework MambaITD
based on the Mamba state space model and cross-modal adaptive fusion. First,
the multi-source log preprocessing module aligns heterogeneous data through
behavioral sequence encoding, interval smoothing, and statistical feature
extraction. Second, the Mamba encoder models long-range dependencies in
behavioral and interval sequences, and combines the sequence and statistical
information dynamically in combination with the gated feature fusion mechanism.
Finally, we propose an adaptive threshold optimization method based on
maximizing inter-class variance, which dynamically adjusts the decision
threshold by analyzing the probability distribution, effectively identifies
anomalies, and alleviates class imbalance and concept drift. Compared with
traditional methods, MambaITD shows significant advantages in modeling
efficiency and feature fusion capabilities, outperforming Transformer-based
methods, and provides a more effective solution for insider threat detection.

</details>


### [68] [Log2Sig: Frequency-Aware Insider Threat Detection via Multivariate Behavioral Signal Decomposition](https://arxiv.org/abs/2508.05696)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Zhiying Li,Guanggang Geng*

Main category: cs.CR

TL;DR: Log2Sig는 사용자 로그를 다변량 행동 주파수 신호로 변환하여 내부 위협을 효과적으로 탐지하는 강력한 이상 탐지 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 내부 위협 탐지는 악의적인 행동이 정당한 사용자 작업과 유사하여 큰 도전 과제가 된다.

Method: Log2Sig는 다변량 변이 모드 분해(MVMD)를 사용하여 내재적 모드 함수(IMFs)를 추출하고, 행동 시퀀스와 주파수 분해 신호의 공동 모델링을 수행한다.

Result: CERT r4.2 및 r5.2 데이터셋에서 Log2Sig는 정확도와 F1 점수 모두에서 최신 기술 대비 우수한 성능을 보였다.

Conclusion: Log2Sig는 사용자 행동의 새로운 표현 방식을 제공하여 내부 위협 탐지의 효율성을 향상시킨다.

Abstract: Insider threat detection presents a significant challenge due to the
deceptive nature of malicious behaviors, which often resemble legitimate user
operations. However, existing approaches typically model system logs as flat
event sequences, thereby failing to capture the inherent frequency dynamics and
multiscale disturbance patterns embedded in user behavior. To address these
limitations, we propose Log2Sig, a robust anomaly detection framework that
transforms user logs into multivariate behavioral frequency signals,
introducing a novel representation of user behavior. Log2Sig employs
Multivariate Variational Mode Decomposition (MVMD) to extract Intrinsic Mode
Functions (IMFs), which reveal behavioral fluctuations across multiple temporal
scales. Based on this, the model further performs joint modeling of behavioral
sequences and frequency-decomposed signals: the daily behavior sequences are
encoded using a Mamba-based temporal encoder to capture long-term dependencies,
while the corresponding frequency components are linearly projected to match
the encoder's output dimension. These dual-view representations are then fused
to construct a comprehensive user behavior profile, which is fed into a
multilayer perceptron for precise anomaly detection. Experimental results on
the CERT r4.2 and r5.2 datasets demonstrate that Log2Sig significantly
outperforms state-of-the-art baselines in both accuracy and F1 score.

</details>


### [69] [System Security Framework for 5G Advanced /6G IoT Integrated Terrestrial Network-Non-Terrestrial Network (TN-NTN) with AI-Enabled Cloud Security](https://arxiv.org/abs/2508.05707)
*Sasa Maric,Rasil Baidar,Robert Abbas,Sam Reisenfeld*

Main category: cs.CR

TL;DR: 이 논문은 5G Advanced/6G와 IoT 기술을 통합한 TN-NTN 아키텍처를 위한 새로운 시스템 수준의 보안 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 5G Advanced/6G 및 IoT 기술을 포함한 TN과 NTN의 통합으로 인해 새로운 보안 도전 과제가 등장하고 있다.

Method: AI 네이티브 클라우드 보안을 활용하여 실시간 위협 탐지, 보안 자동화 및 지능형 정책 집행을 수행하는 프레임워크를 제시한다.

Result: NTN 위성 접근 기능이 끊김 없는 커버리지 보안을 강화하며, 통합 5G Advanced/6G IoT TN-NTN 시스템의 보안 위험성을 탐구한다.

Conclusion: AI 기반의 위성 기반 NTN을 구현하기 위한 제안을 포함한 포괄적인 보안 프레임워크를 제시한다.

Abstract: The integration of Terrestrial Networks (TN) and Non-Terrestrial Networks
(NTN), including 5G Advanced/6G and the Internet of Things (IoT) technologies,
using Low Earth Orbit (LEO) satellites, high-altitude platforms (HAPS), and
Unmanned Aerial Vehicles (UAVs), is redefining the landscape of global
connectivity. This paper introduces a new system-level security framework for
5G Advanced/6G IoT-integrated TN-NTN architectures with AI-native-enabled cloud
security. Due to the heterogeneity, scale, and distributed nature of these
networks, new security challenges have emerged. Leveraging AI-native cloud
platforms offers powerful capabilities for real-time threat detection, security
automation, and intelligent policy enforcement. The NTN satellite access
function enhances security for discontinuous coverage via satellite
connections. In addition, this paper explores the security risks associated
with integrated 5G Advanced/6G IoT TN-NTN systems, including full network
segmentation, network slicing, and the cloudification of the RAN and core. We
present a comprehensive AI-enabled cloud security framework and conclude with
proposals for implementing AI-powered, satellite-based NTN within future 5G
Advanced/6G IoT networks. Our approach emphasizes zero-trust principles,
federated learning, secure orchestration, a layered security framework, and
resilience against adversarial threats.

</details>


### [70] [On Digital Twins in Defence: Overview and Applications](https://arxiv.org/abs/2508.05717)
*Marco Giberna,Holger Voos,Paulo Tavares,João Nunes,Tobias Sorg,Andrea Masini,Jose Luis Sanchez-Lopez*

Main category: cs.CR

TL;DR: 이 논문은 방위 응용 분야에서 디지털 트윈 기술의 통합을 탐구하며, 이를 통해 운영 성과 향상과 시스템 가동 시간 증가와 같은 장점을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: 디지털 트윈 기술은 물리적 시스템의 가상 복제본을 생성하여 실시간 모니터링, 최적화 및 시뮬레이션을 가능하게 하여 다양한 분야에서 주목받고 있습니다.

Method: 본 논문은 방위 플랫폼에서 디지털 트윈 기술의 적용을 검토하며, 이를 위한 새로운 특성화 프레임워크를 소개합니다.

Result: 디지털 트윈의 적용을 통해 운영 성과 향상, 예측 능력 및 시스템 가동 시간 증가와 같은 장점을 강조하고, 방위 분야의 상호 운용성을 촉진하기 위한 표준화를 목표로 합니다.

Conclusion: 미래 연구 방향과 개발 기회를 설명하며, 방위 분야에서 디지털 트윈의 잠재력을 완전히 실현하기 위해 강력한 프레임워크와 학제 간 협력이 필요함을 강조합니다.

Abstract: Digital twin technology has gained increasing attention across various
sectors due to its ability to create virtual replicas of physical systems,
enabling real-time monitoring, optimization, and simulation. This paper
explores the integration of digital twins within defence applications, focusing
on key use cases ranging from system design and development, operational
planning and training, to mission execution and debriefing. By examining the
application of digital twin technologies across defense platforms, we highlight
their key advantages such as enhanced operational performance, predictive
capabilities, and increased system uptime. Additionally, we introduce a novel
characterization framework for digital twins that aims to standardize and unify
their application across different defence domains to facilitate
interoperability. Thereafter, we discuss the main challenges, gaps and
limitations in implementing and adopting digital twins within defence
organizations by analyzing a combination of scientific literature, current
industry practices, governmental strategies, and the findings from a
comprehensive survey of industrial stakeholders and ministries of defense.
Finally, we outline future research directions and development opportunities,
emphasizing the need for robust frameworks and interdisciplinary collaborations
to fully realize the potential of digital twins in the defence sector.

</details>


### [71] [Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models](https://arxiv.org/abs/2508.05865)
*Kiana Kiashemshaki,Elvis Nnaemeka Chukwuani,Mohammad Jalili Torkamani,Negin Mahmoudi*

Main category: cs.CR

TL;DR: 이 논문은 블록체인 기반 전자 투표 시스템의 아키텍처, 합의 메커니즘, 암호화 프로토콜을 비교 분석하는 프레임워크를 제시하고, 최적화 전략을 통해 안전하고 지능적인 시스템 설계를 위한 토대를 마련한다.


<details>
  <summary>Details</summary>
Motivation: 전자 투표 시스템의 현대화를 위한 투명성, 탈중앙화, 보안을 강화하는 블록체인 기술의 가능성을 탐구하기 위함이다.

Method: 블록체인 기반의 전자 투표 아키텍처, 합의 메커니즘, 암호화 프로토콜에 대한 비교 분석을 통해, 기존 모델의 한계를 검토하고 하이브리드 합의, 경량 암호화 및 탈중앙화 신원 관리와 같은 최적화 전략을 제안한다.

Result: 주요 합의 메커니즘 및 암호화 프로토콜의 한계를 분석하고, 대규모 국가 배포에 적합한 안전하고 확장 가능한 전자 투표 시스템 설계를 위한 기초 자료를 제공한다.

Conclusion: LLM(대형 언어 모델)을 활용하여 스마트 계약을 생성, 이상 감지 및 사용자 상호작용을 통해 전자 투표 시스템의 프로토타입을 구축하는 토대를 마련한다.

Abstract: Blockchain technology offers a promising foundation for modernizing E-Voting
systems by enhancing transparency, decentralization, and security. Yet,
real-world adoption remains limited due to persistent challenges such as
scalability constraints, high computational demands, and complex privacy
requirements. This paper presents a comparative framework for analyzing
blockchain-based E-Voting architectures, consensus mechanisms, and
cryptographic protocols. We examine the limitations of prevalent models like
Proof of Work, Proof of Stake, and Delegated Proof of Stake, and propose
optimization strategies that include hybrid consensus, lightweight
cryptography, and decentralized identity management. Additionally, we explore
the novel role of Large Language Models (LLMs) in smart contract generation,
anomaly detection, and user interaction. Our findings offer a foundation for
designing secure, scalable, and intelligent blockchain-based E-Voting systems
suitable for national-scale deployment. This work lays the groundwork for
building an end-to-end blockchain E-Voting prototype enhanced by LLM-guided
smart contract generation and validation, supported by a systematic framework
and simulation-based analysis.

</details>


### [72] [Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System](https://arxiv.org/abs/2508.06059)
*Haorui He,Yupeng Li,Bin Benjamin Zhu,Dacheng Wen,Reynold Cheng,Francis C. M. Lau*

Main category: cs.CR

TL;DR: Fact2Fiction은 에이전트 기반 fact-checking 시스템을 타겟으로 하는 첫 번째 포이즈닝 공격 프레임워크를 소개하며, 이 시스템의 보안 취약점을 밝혀냅니다.


<details>
  <summary>Details</summary>
Motivation: 정보 왜곡 문제를 해결하기 위해 autonomous LLM 기반의 fact-checking 시스템의 필요성이 커지고 있습니다.

Method: Fact2Fiction은 이 시스템의 분해 전략을 모방하고, 시스템 생성 정당성을 악용하여 특정 악성 증거를 생성하는 방법을 사용합니다.

Result: 다양한 포이즈닝 예산에서 Fact2Fiction은 기존의 최고 수준 공격들보다 8.9%에서 21.2% 높은 공격 성공률을 달성했습니다.

Conclusion: Fact2Fiction은 현재의 fact-checking 시스템의 보안 약점을 드러내고, 방어 대책의 필요성을 강조합니다.

Abstract: State-of-the-art fact-checking systems combat misinformation at scale by
employing autonomous LLM-based agents to decompose complex claims into smaller
sub-claims, verify each sub-claim individually, and aggregate the partial
results to produce verdicts with justifications (explanatory rationales for the
verdicts). The security of these systems is crucial, as compromised
fact-checkers, which tend to be easily underexplored, can amplify
misinformation. This work introduces Fact2Fiction, the first poisoning attack
framework targeting such agentic fact-checking systems. Fact2Fiction mirrors
the decomposition strategy and exploits system-generated justifications to
craft tailored malicious evidences that compromise sub-claim verification.
Extensive experiments demonstrate that Fact2Fiction achieves 8.9\%--21.2\%
higher attack success rates than state-of-the-art attacks across various
poisoning budgets. Fact2Fiction exposes security weaknesses in current
fact-checking systems and highlights the need for defensive countermeasures.

</details>


### [73] [A Game-Theoretic Foundation for Bitcoin's Price: A Security-Utility Equilibrium](https://arxiv.org/abs/2508.06071)
*Liang Chen*

Main category: cs.CR

TL;DR: 이 논문은 비트코인과 같은 분산형 디지털 자산의 가치를 평가하기 위한 구조적 게임 이론 모델을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 비트코인과 같은 분산형 디지털 자산의 가격을 투기적 신념에 의존하지 않고 평가하기 위한 필요성.

Method: Rational-Expectations Security-Utility Nash Equilibrium (RESUNE)을 바탕으로 자산의 가격을 설정하고, 해시율과 네트워크 보안을 내재적으로 설정하는 자유 진입 채굴 모델을 사용.

Result: RESUNE의 존재를 증명하고, 그 고유성과 안정성을 위한 조건을 제공하며, 가격이 수요에 미치는 안정화 효과가 보안에 대한 피드백보다 커야 함을 예측.

Conclusion: 이 모델은 가격이 해시율에 미치는 단방향 인과관계를 설명하고, 프로토콜 절반이 해시율과 가격 모두의 축소를 초래하는 등의 검증 가능한 예측을 생성한다.

Abstract: This paper introduces a structural game-theoretic model to value
decentralized digital assets like Bitcoin. Instead of relying on speculative
beliefs, it frames the asset's price within a Rational-Expectations
Security-Utility Nash Equilibrium (RESUNE). This equilibrium is a fixed point
where the market-clearing price dictates the hash rate through a free-entry
mining model, which in turn endogenously sets the network's security. The
security, defined as one minus the probability of a 51% attack, is determined
via a global games model of attacker coordination, providing a unique and
continuous security function. We prove the existence of a RESUNE and offer
conditions for its uniqueness and stability. The model predicts that the
stabilizing direct effect of price on demand must outweigh the potentially
destabilizing feedback from price to security. The framework generates testable
predictions, such as a protocol halving causing a contraction in both hash rate
and price. A structural Vector Autoregression (VAR) model is proposed to test
this mechanism. The model decomposes Bitcoin's value into transactional
utility, security, and speculative components and explains the observed
unidirectional causality from price to hash rate.

</details>


### [74] [ProvX: Generating Counterfactual-Driven Attack Explanations for Provenance-Based Detection](https://arxiv.org/abs/2508.06073)
*Weiheng Wu,Wei Qiao,Teng Li,Yebo Feng,Zhuo Ma,Jianfeng Ma,Yang Liu*

Main category: cs.CR

TL;DR: 본 논문은 GNN 기반 보안 모델의 해석 가능성을 높이기 위한 ProvX 프레임워크를 제안하며, 이는 그래프 내에서 악성으로 예측된 최소 구조적 부분 집합을 찾고 설명하여 모델의 예측을 파악할 수 있도록 돕는다.


<details>
  <summary>Details</summary>
Motivation: 고급 지속 위협으로부터 방어하기 위해 GNN 기반 보안 모델의 채택이 필요하지만, 이들 모델이 블랙박스 특성을 가지고 있어 설명 가능성이 부족하다.

Method: ProvX는 반사실적 설명 논리(counterfactual explanation logic)를 도입하여, 악성으로 예측된 그래프 내에서 모델의 예측을 뒤집을 수 있는 최소 구조적 부분 집합을 찾아내는 방식을 기술한다.

Result: ProvX는 실제 공격과 높은 관련성이 있는 중요한 그래프 구조를 찾아내며, 평균 설명 필요성 51.59\\%로 현재의 최고 성능 설명자를 초과한다.

Conclusion: ProvX로부터의 설명 결과는 모델 최적화를 안내할 수 있으며, 적대적 공격에 대한 탄력성도 효과적으로 높일 수 있음을 실험을 통해 입증하였다.

Abstract: Provenance graph-based intrusion detection systems are deployed on hosts to
defend against increasingly severe Advanced Persistent Threat. Using Graph
Neural Networks to detect these threats has become a research focus and has
demonstrated exceptional performance. However, the widespread adoption of
GNN-based security models is limited by their inherent black-box nature, as
they fail to provide security analysts with any verifiable explanations for
model predictions or any evidence regarding the model's judgment in relation to
real-world attacks. To address this challenge, we propose ProvX, an effective
explanation framework for exlaining GNN-based security models on provenance
graphs. ProvX introduces counterfactual explanation logic, seeking the minimal
structural subset within a graph predicted as malicious that, when perturbed,
can subvert the model's original prediction. We innovatively transform the
discrete search problem of finding this critical subgraph into a continuous
optimization task guided by a dual objective of prediction flipping and
distance minimization. Furthermore, a Staged Solidification strategy is
incorporated to enhance the precision and stability of the explanations. We
conducted extensive evaluations of ProvX on authoritative datasets. The
experimental results demonstrate that ProvX can locate critical graph
structures that are highly relevant to real-world attacks and achieves an
average explanation necessity of 51.59\%, with these metrics outperforming
current SOTA explainers. Furthermore, we explore and provide a preliminary
validation of a closed-loop Detection-Explanation-Feedback enhancement
framework, demonstrating through experiments that the explanation results from
ProvX can guide model optimization, effectively enhancing its robustness
against adversarial attacks.

</details>


### [75] [Adaptive Backtracking for Privacy Protection in Large Language Models](https://arxiv.org/abs/2508.06087)
*Zhihao Yao,Yuxuan Gu,Xiachong Feng,Weitao Ma,Bo Li,Xiaocheng Feng*

Main category: cs.CR

TL;DR: 본 논문은 기업의 데이터 유출 위험을 해결하기 위한 기업 중심의 개인 정보 보호 문제를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인공지능 시대에 개인 정보 보호의 중요성이 커지고 있지만, 현재 연구는 사용자 중심의 개인 정보 보호에 집중하고 있으며 기업 데이터 유출 위험을 간과하고 있다.

Method: ABack이라는 훈련이 필요 없는 메커니즘을 제안하여 유출 의도를 파악하고 출력을 안전하게 재작성하며, PriGenQA라는 새로운 벤치마크를 구성하여 기업 개인정보 보호 시나리오를 평가한다.

Result: ABack은 기존 강력한 기준선에 비해 전체 개인 정보 유틸리티 점수를 최대 15% 향상시킨다.

Conclusion: 본 연구는 기업 중심의 개인 정보 보호 문제를 해결하고 유출 방지를 위한 효과적인 접근 방식을 제시한다.

Abstract: The preservation of privacy has emerged as a critical topic in the era of
artificial intelligence. However, current work focuses on user-oriented
privacy, overlooking severe enterprise data leakage risks exacerbated by the
Retrieval-Augmented Generation paradigm. To address this gap, our paper
introduces a novel objective: enterprise-oriented privacy concerns. Achieving
this objective requires overcoming two fundamental challenges: existing methods
such as data sanitization severely degrade model performance, and the field
lacks public datasets for evaluation. We address these challenges with several
solutions. (1) To prevent performance degradation, we propose ABack, a
training-free mechanism that leverages a Hidden State Model to pinpoint the
origin of a leakage intention and rewrite the output safely. (2) To solve the
lack of datasets, we construct PriGenQA, a new benchmark for enterprise privacy
scenarios in healthcare and finance. To ensure a rigorous evaluation, we move
beyond simple static attacks by developing a powerful adaptive attacker with
Group Relative Policy Optimization. Experiments show that against this superior
adversary, ABack improves the overall privacy utility score by up to 15\% over
strong baselines, avoiding the performance trade-offs of prior methods.

</details>


### [76] [Simulation in Cybersecurity: Understanding Techniques, Applications, and Goals](https://arxiv.org/abs/2508.06106)
*Luca Serena,Gabriele D'Angelo,Stefano Ferretti,Moreno Marzolla*

Main category: cs.CR

TL;DR: 사이버보안 연구에서 모델링과 시뮬레이션의 중요성을 종합적으로 검토하고, 연구를 네 가지 차원으로 분류하여 방법론적 경향을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 사이버보안 연구에서 사이버 위협을 평가하고 방어 메커니즘을 검토하며 취약점을 분석하기 위해 모델링과 시뮬레이션이 널리 사용되고 있지만, 다양한 응용 분야와 사이버 공격 시나리오, 그리고 각 시뮬레이션의 목표가 다름에 따라 방법론적 경향을 파악하기가 어렵다.

Method: 선정된 논문들을 응용 도메인, 표현된 사이버 위협 유형, 사용하는 시뮬레이션 기법, 시뮬레이션의 주요 목표라는 네 가지 차원에 따라 분류하여 현재의 최첨단 상태를 종합적으로 검토한다.

Result: 다양한 접근 방식의 강점과 한계를 논의하고, 어떤 사이버 위협이 시뮬레이션 기반 조사를 위해 가장 적합한지 식별하며, 특정 사이버 보안 문제에 가장 적합한 모델링 패러다임을 분석한다.

Conclusion: 이 연구는 사이버보안 분야에서 모델링 및 시뮬레이션의 방법론적 경향을 이해하는 데 중요한 통찰력을 제공한다.

Abstract: Modeling and simulation are widely used in cybersecurity research to assess
cyber threats, evaluate defense mechanisms, and analyze vulnerabilities.
However, the diversity of application areas, the variety of cyberattacks
scenarios, and the differing objectives of these simulations makes it difficult
to identify methodological trends. Existing reviews often focus on specific
modeling techniques or application domains, making it challenging to analyze
the field as a whole. To address these limitations, we present a comprehensive
review of the current state of the art, classifying the selected papers based
on four dimensions: the application domain, the types of cyber threats
represented, the simulation techniques employed, and the primary goals of the
simulation. The review discusses the strengths and limitations of different
approaches, identifies which cyber threats are the most suited for
simulation-based investigations, and analyzes which modeling paradigms are most
appropriate for specific cybersecurity challenges.

</details>


### [77] [SLIP: Soft Label Mechanism and Key-Extraction-Guided CoT-based Defense Against Instruction Backdoor in APIs](https://arxiv.org/abs/2508.06153)
*Zhengxian Wu,Juan Wen,Wanli Peng,Haowei Chang,Yinghan Zhou,Yiming Xue*

Main category: cs.CR

TL;DR: SLIP은 API의 명령어 백도어 공격에 대한 방어 메커니즘으로, 키 추출 기반의 사고 연쇄와 소프트 레이블 메커니즘을 통해 효과적으로 공격 성공률을 낮춘다.


<details>
  <summary>Details</summary>
Motivation: 맞춤형 대형 언어 모델(LLM) 에이전트의 발전에 따라 블랙 박스 백도어 공격이라는 새로운 위협이 등장하고 있다. 이러한 공격은 기존 방어 체계를 쉽게 우회하여 심각한 보안 문제를 일으키고 있다.

Method: SLIP은 모델의 과도한 민감성을 저지하기 위해 키 추출 기반 사고 연쇄(KCoT)를 제안하며, 소프트 레이블 메커니즘(SLM)을 통해 의미적 상관관계를 정량화하여 LLM을 올바른 답으로 유도한다.

Result: SLIP은 실험을 통해 평균 공격 성공률(ASR)을 90.2%에서 25.13%로 줄이며, 깨끗한 데이터에 대해 높은 정확도를 유지하고 최신 방어 기술보다 우수한 성능을 보인다.

Conclusion: SLIP은 API의 명령어 백도어 공격에 효과적으로 대응할 수 있는 방법을 제시하며, 코드도 공개되어 있다.

Abstract: With the development of customized large language model (LLM) agents, a new
threat of black-box backdoor attacks has emerged, where malicious instructions
are injected into hidden system prompts. These attacks easily bypass existing
defenses that rely on white-box access, posing a serious security challenge. To
address this, we propose SLIP, a Soft Label mechanism and key-extraction-guided
CoT-based defense against Instruction backdoors in APIs. SLIP is designed based
on two key insights. First, to counteract the model's oversensitivity to
triggers, we propose a Key-extraction-guided Chain-of-Thought (KCoT). Instead
of only considering the single trigger or the input sentence, KCoT prompts the
agent to extract task-relevant key phrases. Second, to guide the LLM toward
correct answers, our proposed Soft Label Mechanism (SLM) prompts the agent to
quantify the semantic correlation between key phrases and candidate answers.
Crucially, to mitigate the influence of residual triggers or misleading content
in phrases extracted by KCoT, which typically causes anomalous scores, SLM
excludes anomalous scores deviating significantly from the mean and
subsequently averages the remaining scores to derive a more reliable semantic
representation. Extensive experiments on classification and question-answer
(QA) tasks demonstrate that SLIP is highly effective, reducing the average
attack success rate (ASR) from 90.2% to 25.13% while maintaining high accuracy
on clean data and outperforming state-of-the-art defenses. Our code are
available in
https://github.com/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs/tree/main/SLIP.

</details>


### [78] [Anti-Tamper Protection for Unauthorized Individual Image Generation](https://arxiv.org/abs/2508.06325)
*Zelin Li,Ruohan Zong,Yifan Liu,Ruichen Yao,Yaokun Liu,Yang Zhang,Dong Wang*

Main category: cs.CR

TL;DR: 개인화 이미지 생성 기술의 발전과 함께 초상권 및 프라이버시를 침해하는 위조 공격에 대한 우려가 커지고 있다. 이를 해결하기 위해 Anti-Tamper Perturbation (ATP)이라는 새로운 접근 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 개인화 이미지 생성 기술의 발전에 따른 초상권 및 프라이버시 침해 우려가 증가하고 있기 때문이다.

Method: ATP는 방해 방지 메커니즘을 도입하여 보호와 권한 부여 방 perturbation을 포함하고, 주파수 영역에서 적용된다.

Result: ATP는 다양한 공격 환경에서 위조 공격을 방어하는 데 효과적임을 입증하였다.

Conclusion: ATP는 개인의 초상권과 프라이버시 보호를 위한 강력한 솔루션을 제공한다.

Abstract: With the advancement of personalized image generation technologies, concerns
about forgery attacks that infringe on portrait rights and privacy are growing.
To address these concerns, protection perturbation algorithms have been
developed to disrupt forgery generation. However, the protection algorithms
would become ineffective when forgery attackers apply purification techniques
to bypass the protection. To address this issue, we present a novel approach,
Anti-Tamper Perturbation (ATP). ATP introduces a tamper-proof mechanism within
the perturbation. It consists of protection and authorization perturbations,
where the protection perturbation defends against forgery attacks, while the
authorization perturbation detects purification-based tampering. Both
protection and authorization perturbations are applied in the frequency domain
under the guidance of a mask, ensuring that the protection perturbation does
not disrupt the authorization perturbation. This design also enables the
authorization perturbation to be distributed across all image pixels,
preserving its sensitivity to purification-based tampering. ATP demonstrates
its effectiveness in defending forgery attacks across various attack settings
through extensive experiments, providing a robust solution for protecting
individuals' portrait rights and privacy. Our code is available at:
https://github.com/Seeyn/Anti-Tamper-Perturbation .

</details>


### [79] [When AIOps Become "AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation](https://arxiv.org/abs/2508.06394)
*Dario Pasquini,Evgenios M. Kornaropoulos,Giuseppe Ateniese,Omer Akgul,Athanasios Theocharis,Petros Efstathopoulos*

Main category: cs.CR

TL;DR: AIOps는 소프트웨어 시스템 관리를 혁신하고 있지만, 새로운 공격 벡터로서 보안 우려가 존재한다. 본 연구에서는 AIOps의 보안 분석을 통해, 공격자가 시스템의 텔레메트리 데이터를 조작하여 AI 자동화를 악용할 수 있음을 보여준다. 이를 위한 방어 메커니즘으로 AIOpsShield를 제안한다.


<details>
  <summary>Details</summary>
Motivation: AIOps 솔루션이 조직의 소프트웨어 시스템을 관리하는 방식을 혁신하고 있지만, 보안상의 비용이 크다는 점을 인지하는 것이 중요하다.

Method: 공격자들이 인프라의 무결성을 해칠 수 있는 방식으로 AIOps 에이전트를 오도하는 텔레메트리 데이터 조작 기술을 도입했다. AIOpsDoom이라는 자동화된 공격 방법론을 개발하고, 이를 통해 공격을 수행하였다.

Result: AIOpsDoom 공격이 텔레메트리 기반 공격을 성공적으로 수행할 수 있음을 입증했다.

Conclusion: AIOps가 시스템 손상의 새로운 공격 벡터로 나타났음을 강조하며, AIOps 설계에서 보안 인식의 필요성을 강조한다.

Abstract: AI for IT Operations (AIOps) is transforming how organizations manage complex
software systems by automating anomaly detection, incident diagnosis, and
remediation. Modern AIOps solutions increasingly rely on autonomous LLM-based
agents to interpret telemetry data and take corrective actions with minimal
human intervention, promising faster response times and operational cost
savings.
  In this work, we perform the first security analysis of AIOps solutions,
showing that, once again, AI-driven automation comes with a profound security
cost. We demonstrate that adversaries can manipulate system telemetry to
mislead AIOps agents into taking actions that compromise the integrity of the
infrastructure they manage. We introduce techniques to reliably inject
telemetry data using error-inducing requests that influence agent behavior
through a form of adversarial reward-hacking; plausible but incorrect system
error interpretations that steer the agent's decision-making. Our attack
methodology, AIOpsDoom, is fully automated--combining reconnaissance, fuzzing,
and LLM-driven adversarial input generation--and operates without any prior
knowledge of the target system.
  To counter this threat, we propose AIOpsShield, a defense mechanism that
sanitizes telemetry data by exploiting its structured nature and the minimal
role of user-generated content. Our experiments show that AIOpsShield reliably
blocks telemetry-based attacks without affecting normal agent performance.
  Ultimately, this work exposes AIOps as an emerging attack vector for system
compromise and underscores the urgent need for security-aware AIOps design.

</details>


### [80] [Voting-Based Semi-Parallel Proof-of-Work Protocol](https://arxiv.org/abs/2508.06489)
*Mustafa Doger,Sennur Ulukus*

Main category: cs.CR

TL;DR: 이 논문은 나카모토 합의보다 더 취약한 기존의 평행 작업 증명(Proof-of-Work) 프로토콜을 분석하고, 새로운 투표 기반 반평행 PoW 프로토콜을 제안하여 기존 프로토콜보다 우수한 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 나카모토 합의의 안전성, 거래 처리량 및 확인 지연을 개선하고자 하는 필요에 따라 평행 Proof-of-Work 프로토콜이 제안되었다.

Method: 기존 평행 PoW 프로토콜을 분석하고, 인센티브 공격 구조를 개발한 후, 새로운 투표 기반 반평행 PoW 프로토콜을 제안하였다.

Result: 기존의 평행 PoW 프로토콜은 나카모토 합의보다 더 많은 인센티브 공격에 취약하며, 새로운 프로토콜은 실용적인 측면에서 기존의 모든 프로토콜을 능가한다.

Conclusion: 우리의 프로토콜은 인센티브 공격에 대한 강인성을 입증하기 위해 MDP 모델을 고려하며, 프로토콜의 일관성을 평가하기 위해 최신 분석 기법을 사용하였다.

Abstract: Parallel Proof-of-Work (PoW) protocols are suggested to improve the safety
guarantees, transaction throughput and confirmation latencies of Nakamoto
consensus. In this work, we first consider the existing parallel PoW protocols
and develop hard-coded incentive attack structures. Our theoretical results and
simulations show that the existing parallel PoW protocols are more vulnerable
to incentive attacks than the Nakamoto consensus, e.g., attacks have smaller
profitability threshold and they result in higher relative rewards. Next, we
introduce a voting-based semi-parallel PoW protocol that outperforms both
Nakamoto consensus and the existing parallel PoW protocols from most practical
perspectives such as communication overheads, throughput, transaction
conflicts, incentive compatibility of the protocol as well as a fair
distribution of transaction fees among the voters and the leaders. We use
state-of-the-art analysis to evaluate the consistency of the protocol and
consider Markov decision process (MDP) models to substantiate our claims about
the resilience of our protocol against incentive attacks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [81] [InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](https://arxiv.org/abs/2508.05731)
*Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu*

Main category: cs.AI

TL;DR: 본 논문은 멀티모달 대형 언어 모델(MLLM)의 발전과 GUI에서 자연어 지시사항의 강력한 정립이 중요하다는 점을 다룬다.


<details>
  <summary>Details</summary>
Motivation: MLLM이 GUI를 통해 시각적 입력으로 작동하는 자율 에이전트를 발전시키고 있지만, 자연어 지시사항의 정립에는 구조적 및 의미적 문제가 있다.

Method: 새로운 정책 최적화 프레임워크인 적응형 탐색 정책 최적화(AEPO)를 제안하며, 이는 다중 답변 생성 전략과 효율성을 기반으로 한 적응형 탐색 보상(AER) 기능을 사용한다.

Result: AEPO로 훈련된 모델들은 여러 GUI 그라운딩 벤치마크에서 새로운 최첨단 결과를 달성하며, 일반화 및 의미 이해를 테스트하는 벤치마크에서 RLVR 기준 대비 최대 9.0%의 상대적 개선을 이루었다.

Conclusion: AEPO는 효율적인 탐색을 통해 의미적 정립을 개선하는 데 기여한다.

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the
development of autonomous agents that operate on Graphical User Interfaces
(GUIs) using pure visual input. A fundamental challenge is robustly grounding
natural language instructions. This requires a precise spatial alignment, which
accurately locates the coordinates of each element, and, more critically, a
correct semantic alignment, which matches the instructions to the functionally
appropriate UI element. Although Reinforcement Learning with Verifiable Rewards
(RLVR) has proven to be effective at improving spatial alignment for these
MLLMs, we find that inefficient exploration bottlenecks semantic alignment,
which prevent models from learning difficult semantic associations. To address
this exploration problem, we present Adaptive Exploration Policy Optimization
(AEPO), a new policy optimization framework. AEPO employs a multi-answer
generation strategy to enforce broader exploration, which is then guided by a
theoretically grounded Adaptive Exploration Reward (AER) function derived from
first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B
and InfiGUI-G1-7B, establish new state-of-the-art results across multiple
challenging GUI grounding benchmarks, achieving significant relative
improvements of up to 9.0% against the naive RLVR baseline on benchmarks
designed to test generalization and semantic understanding. Resources are
available at https://github.com/InfiXAI/InfiGUI-G1.

</details>


### [82] [A Framework for Inherently Safer AGI through Language-Mediated Active Inference](https://arxiv.org/abs/2508.05766)
*Bo Wen*

Main category: cs.AI

TL;DR: 본 연구는 Active Inference 원리를 대형 언어 모델과 결합하여 안전한 인공지능 일반 지능 개발을 위한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 AI 안전 접근 방식이 갖는 근본적인 한계를 지적한다.

Method: 안전 보장이 시스템의 핵심 설계에 통합되는 아키텍처를 제시하고, 자연어를 매개체로 믿음 표현과 조작을 가능하게 한다.

Result: 구체적인 안전 보장 메커니즘을 outline하고, ARC 벤치마크를 중심으로 연구 의제를 제안한다.

Conclusion: 안전성이 본질적으로 내재된 AGI 개발로 나아가는 경로를 제공한다.

Abstract: This paper proposes a novel framework for developing safe Artificial General
Intelligence (AGI) by combining Active Inference principles with Large Language
Models (LLMs). We argue that traditional approaches to AI safety, focused on
post-hoc interpretability and reward engineering, have fundamental limitations.
We present an architecture where safety guarantees are integrated into the
system's core design through transparent belief representations and
hierarchical value alignment. Our framework leverages natural language as a
medium for representing and manipulating beliefs, enabling direct human
oversight while maintaining computational tractability. The architecture
implements a multi-agent system where agents self-organize according to Active
Inference principles, with preferences and safety constraints flowing through
hierarchical Markov blankets. We outline specific mechanisms for ensuring
safety, including: (1) explicit separation of beliefs and preferences in
natural language, (2) bounded rationality through resource-aware free energy
minimization, and (3) compositional safety through modular agent structures.
The paper concludes with a research agenda centered on the Abstraction and
Reasoning Corpus (ARC) benchmark, proposing experiments to validate our
framework's safety properties. Our approach offers a path toward AGI
development that is inherently safer, rather than retrofitted with safety
measures.

</details>


### [83] [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](https://arxiv.org/abs/2508.06110)
*Yiran Rex Ma*

Main category: cs.AI

TL;DR: PanelTR는 LLM 에이전트 과학자를 활용하여 구조화된 과학적 접근을 통해 강력한 표 추론을 수행하는 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 표 추론은 주석 데이터나 복잡한 데이터 증강에 의존하여 유연성과 일반화를 제한하는 문제를 해결하고자 합니다.

Method: PanelTR는 개별 조사를 수행하는 에이전트 과학자, 자기 검토 참여, 동료 검토 토론을 통해 작업을 진행합니다.

Result: 실험 결과, PanelTR은 일반적인 LLM을 능가하고 완전 감독 모델과 경쟁하는 성과를 보였습니다.

Conclusion: 구조화된 과학적 방법론이 제로샷 컨텍스트에서 유연한 의미 이해를 통해 복잡한 작업을 효과적으로 처리할 수 있음을 확인했습니다.

Abstract: Table reasoning, including tabular QA and fact verification, often depends on
annotated data or complex data augmentation, limiting flexibility and
generalization. LLMs, despite their versatility, often underperform compared to
simple supervised models. To approach these issues, we introduce PanelTR, a
framework utilizing LLM agent scientists for robust table reasoning through a
structured scientific approach. PanelTR's workflow involves agent scientists
conducting individual investigations, engaging in self-review, and
participating in collaborative peer-review discussions. This process, driven by
five scientist personas, enables semantic-level transfer without relying on
data augmentation or parametric optimization. Experiments across four
benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully
supervised models, all while remaining independent of training data. Our
findings indicate that structured scientific methodology can effectively handle
complex tasks beyond table reasoning with flexible semantic understanding in a
zero-shot context.

</details>


### [84] [Whither symbols in the era of advanced neural networks?](https://arxiv.org/abs/2508.05776)
*Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb*

Main category: cs.AI

TL;DR: 인간의 사고를 상징적 시스템으로 이해해야 한다는 강력한 증거가 제시된다.


<details>
  <summary>Details</summary>
Motivation: 인간의 사고 과정이 상징적이라는 주장을 약화시키기 위해 최근 신경망의 능력을 논의한다.

Method: 현대 신경망과 이를 기반으로 구축된 인공지능 시스템의 특성을 분석한다.

Result: 이러한 시스템은 인간의 사고가 해결해야 하는 추상적 문제를 특징짓는 데 중요한 역할을 한다.

Conclusion: 인간 사고의 상징적 기초에 대한 새로운 연구 의제를 제안한다.

Abstract: Some of the strongest evidence that human minds should be thought about in
terms of symbolic systems has been the way they combine ideas, produce novelty,
and learn quickly. We argue that modern neural networks -- and the artificial
intelligence systems built upon them -- exhibit similar abilities. This
undermines the argument that the cognitive processes and representations used
by human minds are symbolic, although the fact that these neural networks are
typically trained on data generated by symbolic systems illustrates that such
systems play an important role in characterizing the abstract problems that
human minds have to solve. This argument leads us to offer a new agenda for
research on the symbolic basis of human thought.

</details>


### [85] [Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making](https://arxiv.org/abs/2508.05792)
*Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava*

Main category: cs.AI

TL;DR: Holistic-XAI는 다양한 이해관계자의 요구를 지원하기 위해 전통적인 XAI 방법과 인과적 평가 방법을 통합한 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 XAI 방법은 개발자에게 초점을 맞추어 모델 출력을 정당화하는 데 주력하고 있으며, 다양한 이해관계자의 요구를 지원하지 못한다.

Method: Holistic-XAI(H-XAI)는 인과적 평가 방법과 전통적인 XAI 방법을 통합하여 설명을 상호작용적이고 다중 방법적 프로세스로 지원하는 프레임워크이다.

Result: 이 프레임워크는 이해관계자가 일련의 질문을 하고 가설을 테스트하며 모델 행동을 자동으로 생성된 무작위 및 편향 기준과 비교할 수 있게 한다.

Conclusion: Holistic-XAI는 기존 XAI 방법들이 남긴 중요한 공백을 메우며, 개별 결정 수준과 전체 모델 수준에서 이해관계자별 질문에 답할 수 있는 인과적 평가와 사후 설명을 결합한다.

Abstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing
on justifying model outputs rather than supporting diverse stakeholder needs. A
recent shift toward Evaluative AI reframes explanation as a tool for hypothesis
testing, but still focuses primarily on operational organizations. We introduce
Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods
with traditional XAI methods to support explanation as an interactive,
multi-method process. H-XAI allows stakeholders to ask a series of questions,
test hypotheses, and compare model behavior against automatically constructed
random and biased baselines. It combines instance-level and global
explanations, adapting to each stakeholder's goals, whether understanding
individual decisions, assessing group-level bias, or evaluating robustness
under perturbations. We demonstrate the generality of our approach through two
case studies spanning six scenarios: binary credit risk classification and
financial time-series forecasting. H-XAI fills critical gaps left by existing
XAI methods by combining causal ratings and post-hoc explanations to answer
stakeholder-specific questions at both the individual decision level and the
overall model level.

</details>


### [86] [Safety of Embodied Navigation: A Survey](https://arxiv.org/abs/2508.05855)
*Zixia Wang,Jia Hu,Ronghui Mu*

Main category: cs.AI

TL;DR: 몸체화된 내비게이션의 안전성을 다각도로 분석하고 미래 연구 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 몸체화된 AI의 발전과 내비게이션 시나리오에서의 필요성 증가.

Method: 공격 전략, 방어 메커니즘, 평가 방법론 등 여러 관점에서 안전을 분석.

Result: 안전 문제, 완화 기술, 다양한 데이터셋과 메트릭스를 종합적으로 검토하고, 미래 연구 방향을 탐색.

Conclusion: 안전하고 신뢰할 수 있는 몸체화된 내비게이션 시스템 개발을 위한 통찰력을 제공.

Abstract: As large language models (LLMs) continue to advance and gain influence, the
development of embodied AI has accelerated, drawing significant attention,
particularly in navigation scenarios. Embodied navigation requires an agent to
perceive, interact with, and adapt to its environment while moving toward a
specified target in unfamiliar settings. However, the integration of embodied
navigation into critical applications raises substantial safety concerns. Given
their deployment in dynamic, real-world environments, ensuring the safety of
such systems is critical. This survey provides a comprehensive analysis of
safety in embodied navigation from multiple perspectives, encompassing attack
strategies, defense mechanisms, and evaluation methodologies. Beyond conducting
a comprehensive examination of existing safety challenges, mitigation
technologies, and various datasets and metrics that assess effectiveness and
robustness, we explore unresolved issues and future research directions in
embodied navigation safety. These include potential attack methods, mitigation
strategies, more reliable evaluation techniques, and the implementation of
verification frameworks. By addressing these critical gaps, this survey aims to
provide valuable insights that can guide future research toward the development
of safer and more reliable embodied navigation systems. Furthermore, the
findings of this study have broader implications for enhancing societal safety
and increasing industrial efficiency.

</details>


### [87] [Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning](https://arxiv.org/abs/2508.05888)
*Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber*

Main category: cs.AI

TL;DR: 이 논문은 복잡한 사용자 쿼리에서 AI 에이전트의 도구 검색을 개선하기 위해 지식 그래프 기반의 도구 검색 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 복잡한 사용자 쿼리에서 도구를 선택하고 행동을 계획하는 데 있어 효과적인 도구 검색이 필수적이다.

Method: 지식 그래프를 기반으로 한 도구 검색 프레임워크를 제안하며, 도구와 기능 종속성 간의 의미론적 관계를 포착한다.

Result: 제안된 방법은 91.85%의 도구 커버리지를 기록하며, 이전의 가장 강력한 비-KG 기반 방법인 89.26%에 비해 성능이 향상되었다.

Conclusion: 지식 그래프의 구조적 정보가 단순 유사성 매칭에 비해 보완적인 신호를 제공함을 지지하는 결과이다.

Abstract: Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

</details>


### [88] [Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](https://arxiv.org/abs/2508.05996)
*Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang*

Main category: cs.AI

TL;DR: 이 연구는 의료 멀티모달 의사결정을 위한 중재자-guided 다중 에이전트 협업 프레임워크인 MedOrch를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 임상의에 의해 운영되는 협력적 작업 흐름을 설계하여 AI 다중 에이전트 시스템이 인간 수준의 진료 결정을 가속화하고 증대시킬 수 있다.

Method: MedOrch는 LLM 기반의 중재자 에이전트를 사용하여 여러 VLM 기반의 전문가 에이전트가 협업을 통해 출력 결과를 교환하고 반영할 수 있도록 한다.

Result: 다양한 VLM 기반 에이전트 간의 협업이 개별 에이전트의 능력을 초월할 수 있음을 보여준다.

Conclusion: 중재자-guided 다중 에이전트 협업의 가치를 강조하며, 의료 멀티모달 지능의 진전을 이룰 수 있다.

Abstract: Complex medical decision-making involves cooperative workflows operated by
different clinicians. Designing AI multi-agent systems can expedite and augment
human-level clinical decision-making. Existing multi-agent researches primarily
focus on language-only tasks, yet their extension to multimodal scenarios
remains challenging. A blind combination of diverse vision-language models
(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are
less capable in instruction following and importantly self-reflection, compared
to large language models (LLMs) of comparable sizes. This disparity largely
constrains VLMs' ability in cooperative workflows. In this study, we propose
MedOrch, a mediator-guided multi-agent collaboration framework for medical
multimodal decision-making. MedOrch employs an LLM-based mediator agent that
enables multiple VLM-based expert agents to exchange and reflect on their
outputs towards collaboration. We utilize multiple open-source general-purpose
and domain-specific VLMs instead of costly GPT-series models, revealing the
strength of heterogeneous models. We show that the collaboration within
distinct VLM-based agents can surpass the capabilities of any individual agent.
We validate our approach on five medical vision question answering benchmarks,
demonstrating superior collaboration performance without model training. Our
findings underscore the value of mediator-guided multi-agent collaboration in
advancing medical multimodal intelligence. Our code will be made publicly
available.

</details>


### [89] [Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](https://arxiv.org/abs/2508.06042)
*Daechul Ahn,San Kim,Jonghyun Choi*

Main category: cs.AI

TL;DR: 본 논문에서는 StarCraft II와 같은 동적이고 긴 시간 지향 작업에서 LLM의 한계를 극복하기 위해 전략적 계획자(SP)라는 메타 컨트롤러 아래에서 특화된 모방 학습 에이전트를 활용하는 계층적 다중 에이전트 프레임워크 HIMA를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM은 동적이고 장기적인 작업에서 성능이 부족하며, 이를 해결하기 위한 방법론이 필요합니다.

Method: 전문가의 시연을 바탕으로 특화된 에이전트들이 독특한 전략을 배우고, SP가 이를 조율하여 환경에 적합한 전체 계획을 생성하는 계층적 다중 에이전트 프레임워크를 개발했습니다.

Result: HIMA는 전략적 명확성, 적응성 및 계산 효율성에서 최첨단 기법들을 초월하는 성과를 보였습니다.

Conclusion: 특화된 모방 모듈과 메타 수준 조정의 결합을 통해 더 강력하고 범용적인 AI 에이전트를 개발할 수 있는 가능성을 강조합니다.

Abstract: Large Language Models (LLMs) have recently demonstrated impressive action
sequence prediction capabilities but often struggle with dynamic, long-horizon
tasks such as real-time strategic games. In a game such as StarCraftII (SC2),
agents need to manage resource constraints and adapt to evolving battlefield
situations in a partially observable environment. This often overwhelms
exisiting LLM-based approaches. To address these challenges, we propose a
hierarchical multi-agent framework that employs specialized imitation learning
agents under a meta-controller called Strategic Planner (SP). By expert
demonstrations, each specialized agent learns a distinctive strategy, such as
aerial support or defensive maneuvers, and produces coherent, structured
multistep action sequences. The SP then orchestrates these proposals into a
single, environmentally adaptive plan that ensures local decisions aligning
with long-term strategies. We call this HIMA (Hierarchical Imitation
Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that
encompasses all race match combinations in SC2. Our empirical results show that
HIMA outperforms state of the arts in strategic clarity, adaptability, and
computational efficiency, underscoring the potential of combining specialized
imitation modules with meta-level orchestration to develop more robust,
general-purpose AI agents.

</details>


### [90] [LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences](https://arxiv.org/abs/2508.06060)
*Sankarshan Damle,Boi Faltings*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)이 복잡한 결정 작업을 수행하는 기대가 커지고 있지만, 자원 할당 능력은 충분히 탐구되지 않았다. 본 논문에서는 LLM 기반 자원 할당을 위한 실용적 설정 및 그들의 추론 능력을 평가하기 위한 적응형 벤치마크로서 참여 예산(PB)을 활용하는 이중 목적 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 복잡한 자원 할당 작업을 수행할 수 있는지를 탐구하고, 그들의 추론 능력을 평가할 수 있는 새로운 방법론을 제시하고자 하였다.

Method: LLM이 세 가지 프롬프트 전략(탐욕적 선택, 직접 최적화, 힐 클라이밍 영감을 받은 정제)을 통해 자금 제한 내에서 프로젝트 하위 집합을 선택하도록 하였다. 할당 결과를 유틸리티 극대화 오라클과 비교하였다.

Result: LLM이 자연어 투표자 입력 또는 메타데이터에서 구조적 선호를 추론할 수 있는지를 테스트하고, 추론된 선호에 기반한 할당 결과와 실제 투표에서 얻은 결과를 비교하였다.

Conclusion: 프롬프트 디자인의 중요성을 강조하며, 비구조적 입력을 통한 메커니즘 디자인에서 LLM의 가능성을 보여준다.

Abstract: Large Language Models (LLMs) are increasingly expected to handle complex
decision-making tasks, yet their ability to perform structured resource
allocation remains underexplored. Evaluating their reasoning is also difficult
due to data contamination and the static nature of existing benchmarks. We
present a dual-purpose framework leveraging Participatory Budgeting (PB) both
as (i) a practical setting for LLM-based resource allocation and (ii) an
adaptive benchmark for evaluating their reasoning capabilities. We task LLMs
with selecting project subsets under feasibility (e.g., budget) constraints via
three prompting strategies: greedy selection, direct optimization, and a
hill-climbing-inspired refinement. We benchmark LLMs' allocations against a
utility-maximizing oracle. Interestingly, we also test whether LLMs can infer
structured preferences from natural-language voter input or metadata, without
explicit votes. By comparing allocations based on inferred preferences to those
from ground-truth votes, we evaluate LLMs' ability to extract preferences from
open-ended input. Our results underscore the role of prompt design and show
that LLMs hold promise for mechanism design with unstructured inputs.

</details>


### [91] [Don't Forget Imagination!](https://arxiv.org/abs/2508.06062)
*Evgenii E. Vityaev,Andrei Mantsivoda*

Main category: cs.AI

TL;DR: 인지적 상상력은 인간 사고에 중요한 역할을 하는 능력이며, 인공지능의 발전을 위해 더욱 주목해야 한다.


<details>
  <summary>Details</summary>
Motivation: 인지적 상상력이 여전히 과소평가되고 있으며, 이는 AI의 현재 능력을 저하시킨다.

Method: 확률적 인과 관계에 기반한 새로운 접근 방식인 의미론적 모델을 제안하여 인지적 상상력을 시뮬레이션하는 도구로 사용한다.

Result: 의미론적 모델은 허구의 맥락의 일관성을 보장하고, 원인 관계로 연결된 사실들의 전체적이고 일관된 시스템으로서의 맥락 조작을 가능케 한다.

Conclusion: 인지적 상상력에 대한 더 많은 관심을 촉구하며, 이는 인공지능의 다음 유망한 돌파구가 될 수 있다.

Abstract: Cognitive imagination is a type of imagination that plays a key role in human
thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to
mentally visualize coherent and holistic systems of concepts and causal links
that serve as semantic contexts for reasoning, decision making and prediction.
Our position is that the role of cognitive imagination is still greatly
underestimated, and this creates numerous problems and diminishes the current
capabilities of AI. For instance, when reasoning, humans rely on imaginary
contexts to retrieve background info. They also constantly return to the
context for semantic verification that their reasoning is still reasonable.
Thus, reasoning without imagination is blind. This paper is a call for greater
attention to cognitive imagination as the next promising breakthrough in
artificial intelligence. As an instrument for simulating cognitive imagination,
we propose semantic models -- a new approach to mathematical models that can
learn, like neural networks, and are based on probabilistic causal
relationships. Semantic models can simulate cognitive imagination because they
ensure the consistency of imaginary contexts and implement a glass-box approach
that allows the context to be manipulated as a holistic and coherent system of
interrelated facts glued together with causal relations.

</details>


### [92] [A Generic Complete Anytime Beam Search for Optimal Decision Tree](https://arxiv.org/abs/2508.06064)
*Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus*

Main category: cs.AI

TL;DR: 최적의 결정 트리를 찾는 것은 NP-hard 문제이며, 이를 해결하기 위해 다양한 anytime 방법이 제안되었지만 체계적인 비교가 부족하다. 본 논문에서는 CA-DL8.5라는 새로운 접근법을 제안하고, 해당 알고리즘이 몇 가지 기존 방법보다 뛰어난 anytime 성능을 제공함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 결정 트리를 최소화하는 최적의 방법을 찾는 것은 NP-hard 문제이며, 기존의 정확한 알고리즘은 속도 있는 클래스 분류를 보장하지 못한다.

Method: CA-DL8.5라는 새로운 일반적이고 완전한 anytime 빔 탐색 알고리즘을 제안하며, 이는 다양한 휴리스틱 및 이완 메커니즘의 통합을 허용하는 모듈식 설계로 이전 접근법인 LDS-DL8.5와 Top-k-DL8.5를 일반화한다.

Result: 표준 분류 벤치마크에 대한 실험 결과는 CA-DL8.5가 LDS를 사용할 경우 consistently 가장 우수한 anytime 성능을 제공하며, 다른 CA-DL8.5 변형 및 Blossom 알고리즘보다 더 나은 결과를 보인다.

Conclusion: CA-DL8.5는 다양한 휴리스틱과 탐색 전략을 통합할 수 있는 새로운 일반 프레임워크를 제공하며, 이를 통해 뛰어난 성능을 보여준다.

Abstract: Finding an optimal decision tree that minimizes classification error is known
to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic
programming guarantee optimality, they often suffer from poor anytime behavior
-- meaning they struggle to find high-quality decision trees quickly when the
search is stopped before completion -- due to unbalanced search space
exploration. To address this, several anytime extensions of exact methods have
been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not
been systematically compared, making it difficult to assess their relative
effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and
anytime beam search algorithm that extends the DL8.5 framework and unifies some
existing anytime strategies. In particular, CA-DL8.5 generalizes previous
approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various
heuristics and relaxation mechanisms through a modular design. The algorithm
reuses DL8.5's efficient branch-and-bound pruning and trie-based caching,
combined with a restart-based beam search that gradually relaxes pruning
criteria to improve solution quality over time. Our contributions are twofold:
(1) We introduce this new generic framework for exact and anytime decision tree
learning, enabling the incorporation of diverse heuristics and search
strategies; (2) We conduct a rigorous empirical comparison of several
instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k
heuristics -- using an anytime evaluation metric called the primal gap
integral. Experimental results on standard classification benchmarks show that
CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime
performance, outperforming both other CA-DL8.5 variants and the Blossom
algorithm while maintaining completeness and optimality guarantees.

</details>


### [93] [ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception](https://arxiv.org/abs/2508.06074)
*Siyi Lu,Run Liu,Dongsheng Yang,Lei He*

Main category: cs.AI

TL;DR: 이 논문은 딥 강화 학습(DRL)과 조합된 조감도(BEV) 인식을 통해 자율 주행을 위한 새로운 접근 방식을 제안하며, 동적 도시 주행 시나리오에서 우수한 성능을 달성합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 주행 시스템은 복잡한 환경을 인식하고 실시간 결정을 내리는 데 상당한 도전에 직면해 있습니다.

Method: 이 논문에서는 BEV 기반 인식과 시간을 모델링하기 위한 Mamba 프레임워크를 결합한 효과적인 시공간 특성 추출 네트워크인 Mamba-BEV 모델을 소개합니다.

Result: ME$^3$-BEV 프레임워크는 Mamba-BEV 모델을 최종 입력으로 사용하며, 동적 도시 주행 시나리오에서 기존 모델보다 우수한 성능을 발휘합니다.

Conclusion: CARLA 시뮬레이터에서의 광범위한 실험은 ME$^3$-BEV가 충돌률, 경로 정확성 등 여러 지표에서 기존 모델을 초월함을 보여주며, 실시간 자율 주행을 위한 유망한 해결책을 제공합니다.

Abstract: Autonomous driving systems face significant challenges in perceiving complex
environments and making real-time decisions. Traditional modular approaches,
while offering interpretability, suffer from error propagation and coordination
issues, whereas end-to-end learning systems can simplify the design but face
computational bottlenecks. This paper presents a novel approach to autonomous
driving using deep reinforcement learning (DRL) that integrates bird's-eye view
(BEV) perception for enhanced real-time decision-making. We introduce the
\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction
network that combines BEV-based perception with the Mamba framework for
temporal feature modeling. This integration allows the system to encode vehicle
surroundings and road features in a unified coordinate system and accurately
model long-range dependencies. Building on this, we propose the
\texttt{ME$^3$-BEV} framework, which utilizes the \texttt{Mamba-BEV} model as a
feature input for end-to-end DRL, achieving superior performance in dynamic
urban driving scenarios. We further enhance the interpretability of the model
by visualizing high-dimensional features through semantic segmentation,
providing insight into the learned representations. Extensive experiments on
the CARLA simulator demonstrate that \texttt{ME$^3$-BEV} outperforms existing
models across multiple metrics, including collision rate and trajectory
accuracy, offering a promising solution for real-time autonomous driving.

</details>


### [94] [Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2](https://arxiv.org/abs/2508.06091)
*Stan P Hauke,Przemysław Andrzej Wałęga*

Main category: cs.AI

TL;DR: 이 논문은 집합-결합-출력 그래프 신경망(GNN)의 논리적 표현력이 C2를 초과함을 증명하여 이전의 미해결 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 그래프 신경망(GNN)의 표현력을 논리 언어와 연관시켜 이해하려는 관심이 증가하고 있다.

Method: 우리는 집합-결합-출력 GNN의 논리적 표현력이 C2를 엄격히 초과함을 증명했다.

Result: 이 결과는 비방향 그래프와 방향 그래프 모두에 적용된다.

Conclusion: 우리의 연구는 GNN에 대한 함의 외에도 무한 논리의 표현력에 대한 순수한 논리적 통찰을 제공한다.

Abstract: In recent years, there has been growing interest in understanding the
expressive power of graph neural networks (GNNs) by relating them to logical
languages. This research has been been initialised by an influential result of
Barcel\'o et al. (2020), who showed that the graded modal logic (or a guarded
fragment of the logic C2), characterises the logical expressiveness of
aggregate-combine GNNs. As a ``challenging open problem'' they left the
question whether full C2 characterises the logical expressiveness of
aggregate-combine-readout GNNs. This question has remained unresolved despite
several attempts. In this paper, we solve the above open problem by proving
that the logical expressiveness of aggregate-combine-readout GNNs strictly
exceeds that of C2. This result holds over both undirected and directed graphs.
Beyond its implications for GNNs, our work also leads to purely logical
insights on the expressive power of infinitary logics.

</details>


### [95] [SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges](https://arxiv.org/abs/2508.06111)
*Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown*

Main category: cs.AI

TL;DR: 이 논문은 SKATE라는 새로운 평가 프레임워크를 소개하며, 큰 언어 모델들이 서로 검증 가능한 작업을 생성하고 해결함으로써 경쟁할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 기초 모델의 능력과 위험을 평가하는 것은 매우 중요하지만, 현재의 방법은 광범위한 도메인 전문성을 요구하여 이 모델들이 빠르게 발전하는 데 비해 확장성이 떨어진다.

Method: SKATE는 언어 모델들이 서로 경쟁하여 작업을 생성하고 해결하도록 하는 평가 게임으로, 각 모델이 자신의 장점을 부각시키고 다른 모델의 약점을 드러내도록 유도한다.

Result: 여섯 개의 최첨단 LLM을 평가한 결과, 약한 모델이 강한 모델을 신뢰성 있게 구별하고 점수를 매길 수 있으며, LLM 기반 시스템이 자가 선호 행동을 나타낼 수 있고, SKATE가 모델 간의 세부적인 능력 차이를 자동으로 드러낸다는 것을 발견했다.

Conclusion: 이 연구 결과는 LLM의 발전 속도를 따라갈 수 있는 일반적이고 확장 가능한 평가 프레임워크로 나아가는 중요한 발걸음이다.

Abstract: Evaluating the capabilities and risks of foundation models is paramount, yet
current methods demand extensive domain expertise, hindering their scalability
as these models rapidly evolve. We introduce SKATE: a novel evaluation
framework in which large language models (LLMs) compete by generating and
solving verifiable tasks for one another. Our core insight is to treat
evaluation as a game: models act as both task-setters and solvers, incentivized
to create questions which highlight their own strengths while exposing others'
weaknesses. SKATE offers several key advantages, balancing scalability,
open-endedness, and objectivity. It is fully automated, data-free, and
scalable, requiring no human input or domain expertise. By using verifiable
tasks rather than LLM judges, scoring is objective. Unlike domain-limited
programmatically-generated benchmarks (e.g. chess-playing or spatial
reasoning), having LLMs creatively pose challenges enables open-ended and
scalable evaluation. As a proof of concept, we introduce LLM-set
code-output-prediction (COP) challenges as a verifiable and extensible
framework in which to test our approach. Using a TrueSkill-based ranking
system, we evaluate six frontier LLMs and find that: (1) weaker models can
reliably differentiate and score stronger ones, (2) LLM-based systems are
capable of self-preferencing behavior, generating questions that align with
their own capabilities, and (3) SKATE automatically surfaces fine-grained
capability differences between models. Our findings are an important step
towards general, scalable evaluation frameworks which can keep pace with LLM
progress.

</details>


### [96] [Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem](https://arxiv.org/abs/2508.06129)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux*

Main category: cs.AI

TL;DR: 이 연구는 차량 경로 문제(VRP)에 대한 기계 학습을 통한 솔루션 품질 예측 분석을 다룬다.


<details>
  <summary>Details</summary>
Motivation: VRP는 NP-하드 최적화 문제로, 메타휴리스틱 알고리즘을 통해 해결된다. 최근 연구는 기계 학습 방법이 조합 최적화에서 솔루션의 구조적 특성을 활용할 수 있음을 보여주었다.

Method: 여러 분류기 모델을 사용하여 VRP 솔루션의 품질을 예측하는 민감도 분석을 수행하였다.

Result: 특징의 중요성은 다르지만 특정 특징이 강력한 예측 변수로 일관되게 나타났다.

Conclusion: 특징 중요성 분석은 VRP 문제를 해결하기 위한 메타휴리스틱 알고리즘의 안내 메커니즘 개발 기초로서의 가능성을 강조한다.

Abstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with
numerous real-world applications, mostly solved using metaheuristic algorithms
due to its $\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely
on human-crafted designs developed through empirical studies. However, recent
research shows that machine learning methods can be used the structural
characteristics of solutions in combinatorial optimization, thereby aiding in
designing more efficient algorithms, particularly for solving VRP. Building on
this advancement, this study extends the previous research by conducting a
sensitivity analysis using multiple classifier models that are capable of
predicting the quality of VRP solutions. Hence, by leveraging explainable AI,
this research is able to extend the understanding of how these models make
decisions. Finally, our findings indicate that while feature importance varies,
certain features consistently emerge as strong predictors. Furthermore, we
propose a unified framework able of ranking feature impact across different
scenarios to illustrate this finding. These insights highlight the potential of
feature importance analysis as a foundation for developing a guidance mechanism
of metaheuristic algorithms for solving the VRP.

</details>


### [97] [Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications](https://arxiv.org/abs/2508.06145)
*Byeonghun Bang,Jongsuk Yoon,Dong-Jin Chang,Seho Park,Yong Oh Lee*

Main category: cs.AI

TL;DR: 이 연구는 대규모 언어 모델을 활용해 제약 금기 사항을 효과적으로 다루는 방법을 제시하고, RAG 파이프라인을 도입하여 모델의 정확성을 크게 향상시켰음을 보인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLMs)의 유연성을 다양한 분야에서 탐구하였으나, 특히 제약 금기 사항이 필요한 헬스케어 분야에서는 도전 과제가 존재한다.

Method: OpenAI의 GPT-4o-mini 모델을 기본으로 하고, text-embedding-3-small 모델을 사용하여 임베딩을 생성하며, Langchain을 활용해 하이브리드 검색 시스템과 재순위를 통합하는 RAG 파이프라인을 구현하였다.

Result: RAG 파이프라인 통합 후, 연령대, 임신 및 동시약물 사용과 관련된 금기 사항의 정확성이 각각 0.94, 0.87 및 0.89로 크게 향상되었다.

Conclusion: RAG 프레임워크로 LLM을 보강하는 것은 처방 및 약물 복용 결정에서의 불확실성을 상당히 줄이는 데 도움이 될 수 있음을 보여준다.

Abstract: The versatility of large language models (LLMs) has been explored across
various sectors, but their application in healthcare poses challenges,
particularly in the domain of pharmaceutical contraindications where accurate
and reliable information is required. This study enhances the capability of
LLMs to address contraindications effectively by implementing a Retrieval
Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base
model, and the text-embedding-3-small model for embeddings, our approach
integrates Langchain to orchestrate a hybrid retrieval system with re-ranking.
This system leverages Drug Utilization Review (DUR) data from public databases,
focusing on contraindications for specific age groups, pregnancy, and
concomitant drug use. The dataset includes 300 question-answer pairs across
three categories, with baseline model accuracy ranging from 0.49 to 0.57.
Post-integration of the RAG pipeline, we observed a significant improvement in
model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications
related to age groups, pregnancy, and concomitant drug use, respectively. The
results indicate that augmenting LLMs with a RAG framework can substantially
reduce uncertainty in prescription and drug intake decisions by providing more
precise and reliable drug contraindication information.

</details>


### [98] [Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution](https://arxiv.org/abs/2508.06225)
*Zailong Tian,Zhuoheng Han,Yanzhe Chen,Haozhe Xu,Xi Yang,richeng xuan,Hongfeng Wang,Lizi Liao*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)이 자동 판단자로 널리 사용되지만, 정확성에만 집중하는 현재의 접근 방식은 신뢰할 수 있는 믿음의 필요성을 간과하고 있다. 이 연구는 LLM의 신뢰할 수 있는 판단을 위해 잘 조정된 신뢰도의 중요성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 자동 판단자로 사용될 때 신뢰할 수 있는, 위험을 인지한 판단의 필요성을 강조하고자 한다.

Method: 신뢰도 기반, 위험 인지 LLM-재판관 시스템으로의 변화를 제안하며, LLM의 신뢰성을 향상시키기 위한 새로운 메트릭인 TH-Score를 도입하고, LLM을 신뢰할 수 있는 평가자로 변환하는 앙상블 프레임워크인 LLM-as-a-Fuser를 제안한다.

Result: 우리의 접근 방식은 조정 능력을 현저히 개선하고 기존 기준에 비해 우수한 신뢰성과 정확성을 달성하는 적응형 평가 파이프라인을 가능하게 한다.

Conclusion: 이 연구는 LLM의 신뢰성을 높이고, 모든 판단에서 더 나은 신뢰성과 정확성을 제공하기 위한 새로운 방법론을 제시한다.

Abstract: Large Language Models (LLMs) are widely used as automated judges, where
practical value depends on both accuracy and trustworthy, risk-aware judgments.
Existing approaches predominantly focus on accuracy, overlooking the necessity
of well-calibrated confidence, which is vital for adaptive and reliable
evaluation pipelines. In this work, we advocate a shift from accuracy-centric
evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing
the necessity of well-calibrated confidence for trustworthy and adaptive
evaluation. We systematically identify the **Overconfidence Phenomenon** in
current LLM-as-a-Judges, where predicted confidence significantly overstates
actual correctness, undermining reliability in practical deployment. To
quantify this phenomenon, we introduce **TH-Score**, a novel metric measuring
confidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an
ensemble framework that transforms LLMs into reliable, risk-aware evaluators.
Extensive experiments demonstrate that our approach substantially improves
calibration and enables adaptive, confidence-driven evaluation pipelines,
achieving superior reliability and accuracy compared to existing baselines.

</details>


### [99] [GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines](https://arxiv.org/abs/2508.06226)
*Yumeng Fu,Jiayin Zhu,Lingling Zhang,Bo Zhao,Shaoxuan Ma,Yushun Zhang,Yanrui Wu,Wenjun Wu*

Main category: cs.AI

TL;DR: 이 논문은 보조선을 포함한 기하 문제 해결 능력을 평가하기 위한 GeoLaux 벤치마크를 제시하며, MLLM의 장기 추론 능력을 진단한다.


<details>
  <summary>Details</summary>
Motivation: 기하 문제 해결이 요구하는 다양한 기술을 가지고 있는 멀티모달 대형 언어 모델(MLLM)을 평가하기 위한 새로운 기준이 필요하다.

Method: GeoLaux 벤치마크는 2,186개의 기하 문제로 구성되며, 계산 및 증명 문제를 포함하고, 다섯 가지 차원의 평가 전략을 설계하였다.

Result: 실험 결과, 여러 모델이 장기 추론 단계에서 성능이 크게 저하되며, 증명 문제를 해결할 때 단축 답안을 사용하는 경향이 나타났다.

Conclusion: GeoLaux는 MLLM의 기하 추론 능력을 평가하고 발전시키기 위한 기준 및 가이드 역할을 한다.

Abstract: Geometry problem solving (GPS) requires models to master diagram
comprehension, logical reasoning, knowledge application, numerical computation,
and auxiliary line construction. This presents a significant challenge for
Multimodal Large Language Models (MLLMs). However, existing benchmarks for
evaluating MLLM geometry skills overlook auxiliary line construction and lack
fine-grained process evaluation, making them insufficient for assessing MLLMs'
long-step reasoning abilities. To bridge these gaps, we present the GeoLaux
benchmark, comprising 2,186 geometry problems, incorporating both calculation
and proving questions. Notably, the problems require an average of 6.51
reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary
line construction. Building on the dataset, we design a novel five-dimensional
evaluation strategy assessing answer correctness, process correctness, process
quality, auxiliary line impact, and error causes. Extensive experiments on 13
leading MLLMs (including thinking models and non-thinking models) yield three
pivotal findings: First, models exhibit substantial performance degradation in
extended reasoning steps (nine models demonstrate over 50% performance drop).
Second, compared to calculation problems, MLLMs tend to take shortcuts when
solving proving problems. Third, models lack auxiliary line awareness, and
enhancing this capability proves particularly beneficial for overall geometry
reasoning improvement. These findings establish GeoLaux as both a benchmark for
evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a
guide for capability advancement. Our dataset and code are included in
supplementary materials and will be released.

</details>


### [100] [Learning Logical Rules using Minimum Message Length](https://arxiv.org/abs/2508.06230)
*Ruben Sharma,Sebastijan Dumančić,Ross D. King,Andrew Cropper*

Main category: cs.AI

TL;DR: 확률적 및 논리적 학습의 통합은 AI의 주요 도전 과제이며, 본 논문에서는 노이즈 데이터를 통해 최소 메시지 길이 프로그램을 학습하는 베이지안 귀납 논리 프로그래밍 접근법을 소개한다. 이 방법은 가설 복잡성과 데이터 적합성을 균형 있게 조절하며, 이전 방법보다 현저하게 우수한 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 확률적 및 논리적 학습의 통합은 AI 발전에 있어 필수적이다.

Method: 최소 메시지 길이 프로그램을 노이즈 데이터에서 학습하는 베이지안 귀 inductive logic programming 접근법을 제안한다.

Result: 여러 영역(게임 플레이 및 약물 설계 포함)에서 우리의 방법이 이전 최소 설명 길이 프로그램 학습 방법들보다 현저히 우수함을 보여준다.

Conclusion: 우리의 접근법은 데이터 효율적이며, 예제 불균형에 무관하며, 오직 긍정적인 예로부터도 학습할 수 있는 능력을 가지고 있다.

Abstract: Unifying probabilistic and logical learning is a key challenge in AI. We
introduce a Bayesian inductive logic programming approach that learns minimum
message length programs from noisy data. Our approach balances hypothesis
complexity and data fit through priors, which explicitly favour more general
programs, and a likelihood that favours accurate programs. Our experiments on
several domains, including game playing and drug design, show that our method
significantly outperforms previous methods, notably those that learn minimum
description length programs. Our results also show that our approach is
data-efficient and insensitive to example balance, including the ability to
learn from exclusively positive examples.

</details>


### [101] [Symmetry breaking for inductive logic programming](https://arxiv.org/abs/2508.06263)
*Andrew Cropper,David M. Cerna,Matti Järvisalo*

Main category: cs.AI

TL;DR: 유도 논리 프로그래밍의 목표는 훈련 데이터와 배경 지식을 일반화하는 가설을 찾는 것이다.


<details>
  <summary>Details</summary>
Motivation: 가설 공간에서의 대칭성을 깨뜨리는 방법을 도입하여 퀄리티 높은 가설을 찾고자 함.

Method: 답 집합 프로그래밍에서 우리의 아이디어를 구현하였다.

Result: 비주얼 추론과 게임 플레이를 포함한 여러 도메인에서 실험 결과, 해결 시간을 1시간 이상에서 단 17초로 줄일 수 있음을 보여주었다.

Conclusion: 우리의 접근법은 유도 논리 프로그래밍의 효율성을 크게 향상시킬 수 있다.

Abstract: The goal of inductive logic programming is to search for a hypothesis that
generalises training data and background knowledge. The challenge is searching
vast hypothesis spaces, which is exacerbated because many logically equivalent
hypotheses exist. To address this challenge, we introduce a method to break
symmetries in the hypothesis space. We implement our idea in answer set
programming. Our experiments on multiple domains, including visual reasoning
and game playing, show that our approach can reduce solving times from over an
hour to just 17 seconds.

</details>


### [102] [LLM Robustness Leaderboard v1 --Technical report](https://arxiv.org/abs/2508.06296)
*Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe*

Main category: cs.AI

TL;DR: 이 기술 보고서는 PRISM Eval이 발표한 LLM 강건성 리더보드와 관련이 있으며, 41개의 최신 LLM 중 37개에 대해 100% 공격 성공률을 달성하는 자동화된 리드팀 기능을 수행하는 AI 시스템인 PRISM Eval 행동 유도 도구(BET)를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 최신 LLM의 강건성을 평가하고, 공격의 난이도를 모델 간 비교하여 보다 정교한 동적 공격 방법을 제시하려는 것입니다.

Method: Dynamic Adversarial Optimization을 통해 LLM의 악의적인 행동을 유도하며, 공격 성공률과 평균 시도 횟수를 측정하여 모델 간 취약성을 분석합니다.

Result: 37개의 모델에서 100% 공격 성공률을 달성하였으며, 모델 간의 공격 난이도가 300배 이상 차이나는 것을 발견했습니다.

Conclusion: 이 연구는 AI 안전성을 위한 분산 강건성 평가의 실용적인 경로를 제시하며, 특정 위험 카테고리에 대해 어떤 해킹 기술이 가장 효과적인지를 식별했습니다.

Abstract: This technical report accompanies the LLM robustness leaderboard published by
PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior
Elicitation Tool (BET), an AI system performing automated red-teaming through
Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)
against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we
propose a fine-grained robustness metric estimating the average number of
attempts required to elicit harmful behaviors, revealing that attack difficulty
varies by over 300-fold across models despite universal vulnerability. We
introduce primitive-level vulnerability analysis to identify which jailbreaking
techniques are most effective for specific hazard categories. Our collaborative
evaluation with trusted third parties from the AI Safety Network demonstrates
practical pathways for distributed robustness assessment across the community.

</details>


### [103] [A "good regulator theorem" for embodied agents](https://arxiv.org/abs/2508.06326)
*Nathaniel Virgo,Martin Biehl,Manuel Baltieri,Matteo Capucci*

Main category: cs.AI

TL;DR: 본 논문은 에이전트가 규제 작업을 수행할 수 있을 때, 관찰자가 에이전트가 환경에 대한 '신념'을 가지며 감각 입력에 반응하여 이를 '갱신'한다고 해석할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: Conant과 Ashby의 고전적인 논문에 대해 인공지능 생명체가 모델 없이도 과제를 수행하는 사례들을 제시함으로써 이론의 일반화 가능성을 탐구한다.

Method: 에이전트의 작업 수행 능력을 관찰하여 관찰자가 에이전트의 환경에 대한 신념과 그 신념의 갱신 과정을 해석하는 방식을 소개한다.

Result: 신념 갱신의 개념을 통해 Conant과 Ashby의 이론보다 더 정교하고 광범위하게 적용 가능한 이론을 제시한다.

Conclusion: 모델은 시스템의 단순한 속성이 아니라 외부에서 부여되는 것이며, 이 관점의 변화가 이론에 필수적이다. 또한 시스템이 자신의 환경이나 내부 상태를 규제하든 간에 이 이론은 성립한다.

Abstract: In a classic paper, Conant and Ashby claimed that "every good regulator of a
system must be a model of that system." Artificial Life has produced many
examples of systems that perform tasks with apparently no model in sight; these
suggest Conant and Ashby's theorem doesn't easily generalise beyond its
restricted setup. Nevertheless, here we show that a similar intuition can be
fleshed out in a different way: whenever an agent is able to perform a
regulation task, it is possible for an observer to interpret it as having
"beliefs" about its environment, which it "updates" in response to sensory
input. This notion of belief updating provides a notion of model that is more
sophisticated than Conant and Ashby's, as well as a theorem that is more
broadly applicable. However, it necessitates a change in perspective, in that
the observer plays an essential role in the theory: models are not a mere
property of the system but are imposed on it from outside. Our theorem holds
regardless of whether the system is regulating its environment in a classic
control theory setup, or whether it's regulating its own internal state; the
model is of its environment either way. The model might be trivial, however,
and this is how the apparent counterexamples are resolved.

</details>


### [104] [AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games](https://arxiv.org/abs/2508.06348)
*Mille Mei Zhen Loo,Gert Luzkov,Paolo Burelli*

Main category: cs.AI

TL;DR: 이 연구는 Counter-Strike 2의 치팅 행위를 감지하기 위한 머신러닝 모델인 AntiCheatPT_256을 제안하며, 이를 위해 795개의 매치로 구성된 라벨이 달린 데이터셋 CS2CD를 공개한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 비디오 게임에서의 치팅 문제를 해결하고, 사용자 시스템에 대한 침입적인 조치를 최소화하기 위해.

Method: Counter-Strike 2의 게임 플레이 데이터를 사용하여 치팅 행위를 감지하는 transformer 기반의 머신러닝 모델 AntiCheatPT_256을 개발하고, 795개의 매치로 구성된 데이터셋 CS2CD를 생성하여 사용했다.

Result: 이 모델은 90,707개의 컨텍스트 윈도우를 생성하고 데이터 불균형 문제를 해결하기 위해 증강하였으며, 비증강 테스트 세트에서 89.17%의 정확도와 93.36%의 AUC를 달성하였다.

Conclusion: 이 접근법은 재현 가능성 및 실제 적용 가능성을 강조하며, 데이터 기반 치팅 감지 연구를 위한 강력한 기준선을 제공한다.

Abstract: Cheating in online video games compromises the integrity of gaming
experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face
significant challenges in keeping pace with evolving cheating methods without
imposing invasive measures on users' systems. This paper presents
AntiCheatPT\_256, a transformer-based machine learning model designed to detect
cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we
introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using
this dataset, 90,707 context windows were created and subsequently augmented to
address class imbalance. The transformer model, trained on these windows,
achieved an accuracy of 89.17\% and an AUC of 93.36\% on an unaugmented test
set. This approach emphasizes reproducibility and real-world applicability,
offering a robust baseline for future research in data-driven cheat detection.

</details>


### [105] [From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI](https://arxiv.org/abs/2508.06352)
*Christian Meske,Justin Brenne,Erdi Uenal,Sabahat Oelcer,Ayseguel Doganguen*

Main category: cs.AI

TL;DR: 설명 가능한 AI(XAI) 접근 방식은 알고리즘 투명성을 우선시하지만, 이들은 사용자 이해에 충분하지 않다. 본 논문은 설명 AI로서 생성적 AI의 능력을 활용하여 인간 이해를 지원하는 방안을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템을 인간의 이해를 위한 설계의 필요성을 강조하고, 사회기술적 맥락에서의 결정 과정을 지지하기 위해 설명 AI 개념을 발전시키고자 함.

Method: 서사적 의사소통, 적응적 개인화, 점진적 공개 원칙을 통해 설명 AI를 구별짓는 8차원 개념 모델을 개발하고, 의료 전문가와의 Rapid Contextual Design 방법론을 통해 실증 validation 수행.

Result: 사용자들이 기술적 투명성보다 문맥에 맞고 다중 모달의 설명을 선호함을 발견했고, 이는 실용적인 긴급성을 보여줌.

Conclusion: 인간 이해를 목표로 한 AI 시스템의 필요性을 강조하며, 다양한 분야와 문화적 맥락에서 사용자 중심 AI 설명 접근 방식을 발전시키기 위한 포괄적인 연구 의제를 확립함.

Abstract: Current explainable AI (XAI) approaches prioritize algorithmic transparency
and present explanations in abstract, non-adaptive formats that often fail to
support meaningful end-user understanding. This paper introduces "Explanatory
AI" as a complementary paradigm that leverages generative AI capabilities to
serve as explanatory partners for human understanding rather than providers of
algorithmic transparency. While XAI reveals algorithmic decision processes for
model validation, Explanatory AI addresses contextual reasoning to support
human decision-making in sociotechnical contexts. We develop a definition and
systematic eight-dimensional conceptual model distinguishing Explanatory AI
through narrative communication, adaptive personalization, and progressive
disclosure principles. Empirical validation through Rapid Contextual Design
methodology with healthcare professionals demonstrates that users consistently
prefer context-sensitive, multimodal explanations over technical transparency.
Our findings reveal the practical urgency for AI systems designed for human
comprehension rather than algorithmic introspection, establishing a
comprehensive research agenda for advancing user-centered AI explanation
approaches across diverse domains and cultural contexts.

</details>


### [106] [Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned](https://arxiv.org/abs/2508.06368)
*Claudia dAmato,Giuseppe Rubini,Francesco Didio,Donato Francioso,Fatima Zahra Amara,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 여성에 대한 폭력 사건을 대상으로 한 법률 지식 그래프(KG)를 개발하고, 두 가지 자동화된 KG 구축 접근법을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 법적 의사 결정을 위해 포괄적이고 상세한 법률적 배경 지식 및 최신 정보가 필요합니다.

Method: 법률 영역에 맞춤화된 체계적인 하향식 접근법과 대규모 언어 모델을 활용한 새로운 솔루션을 사용하여 자동화된 법률 KG를 구축했습니다.

Result: 여성에 대한 폭력 사건을 포함하는 법률 KG가 성공적으로 개발되고 검증되었습니다.

Conclusion: 개발된 KG는 법률 정보 접근성을 향상시키고 복잡한 질의를 가능하게 하여 예측적 정의를 위한 기계 학습 도구에 활용될 수 있는 중요한 지식 요소가 될 수 있습니다.

Abstract: Legal decision-making process requires the availability of comprehensive and
detailed legislative background knowledge and up-to-date information on legal
cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a
valuable tool to facilitate access to legal information, to be queried and
exploited for the purpose, and to enable advanced reasoning and machine
learning applications. Indeed, legal KGs may act as knowledge intensive
component to be used by pre-dictive machine learning solutions supporting the
decision process of the legal expert. Nevertheless, a few KGs can be found in
the legal domain. To fill this gap, we developed a legal KG targeting legal
cases of violence against women, along with clear adopted methodologies.
Specifically, the paper introduces two complementary approaches for automated
legal KG construction; a systematic bottom-up approach, customized for the
legal domain, and a new solution leveraging Large Language Models. Starting
from legal sentences publicly available from the European Court of Justice, the
solutions integrate structured data extraction, ontology development, and
semantic enrichment to produce KGs tailored for legal cases involving violence
against women. After analyzing and comparing the results of the two approaches,
the developed KGs are validated via suitable competency questions. The obtained
KG may be impactful for multiple purposes: can improve the accessibility to
legal information both to humans and machine, can enable complex queries and
may constitute an important knowledge component to be possibly exploited by
machine learning tools tailored for predictive justice.

</details>


### [107] [The Fair Game: Auditing & Debiasing AI Algorithms Over Time](https://arxiv.org/abs/2508.06443)
*Debabrota Basu,Udvas Das*

Main category: cs.AI

TL;DR: 공정 기계 학습이란 새로운 AI 분야로, 기계 학습 알고리즘의 예측에서 나타나는 다양한 편향을 정량화하고 이를 완화하는 알고리즘을 설계하는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습의 공정성을 보장하고 사회와의 상호작용에 따라 알고리즘의 예측을 조정할 필요성을 느끼고 있다.

Method: 'Fair Game'이라는 동적 메커니즘을 제안하며, 감사자와 편향 제거 알고리즘을 기계 학습 알고리즘 주위에서 루프로 묶는다.

Result: 'Fair Game'은 RL을 활용하여 공정성 목표를 시간에 따라 조정할 수 있는 독특한 프레임워크를 제공한다.

Conclusion: 이 프레임워크를 통해 공정 기계 학습 시스템을 개발할 수 있다.

Abstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify
different types of bias (also known as unfairness) exhibited in the predictions
of ML algorithms, and to design new algorithms to mitigate them. Often, the
definitions of bias used in the literature are observational, i.e. they use the
input and output of a pre-trained algorithm to quantify a bias under concern.
In reality,these definitions are often conflicting in nature and can only be
deployed if either the ground truth is known or only in retrospect after
deploying the algorithm. Thus,there is a gap between what we want Fair ML to
achieve and what it does in a dynamic social environment. Hence, we propose an
alternative dynamic mechanism,"Fair Game",to assure fairness in the predictions
of an ML algorithm and to adapt its predictions as the society interacts with
the algorithm over time. "Fair Game" puts together an Auditor and a Debiasing
algorithm in a loop around an ML algorithm. The "Fair Game" puts these two
components in a loop by leveraging Reinforcement Learning (RL). RL algorithms
interact with an environment to take decisions, which yields new observations
(also known as data/feedback) from the environment and in turn, adapts future
decisions. RL is already used in algorithms with pre-fixed long-term fairness
goals. "Fair Game" provides a unique framework where the fairness goals can be
adapted over time by only modifying the auditor and the different biases it
quantifies. Thus,"Fair Game" aims to simulate the evolution of ethical and
legal frameworks in the society by creating an auditor which sends feedback to
a debiasing algorithm deployed around an ML system. This allows us to develop a
flexible and adaptive-over-time framework to build Fair ML systems pre- and
post-deployment.

</details>


### [108] [What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting](https://arxiv.org/abs/2508.06454)
*Joshua Caiata,Ben Armstrong,Kate Larson*

Main category: cs.AI

TL;DR: 본 연구에서는 다수 의사결정 투표 규칙의 축적된 성과를 데이터 기반으로 평가하고, 신경망을 활용하여 전통적인 규칙보다 우수한 성과를 보이며, 새로운 투표 시스템 설계에 기여할 수 있음을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 여러 다양한 환경에서 위원회 선정 문제를 다루며, 사회적 선택 연구 공동체의 관심을 끌고 있다.

Method: 데이터 기반 프레임워크를 사용하여 여러 선호 분포 아래에서 투표 규칙의 공리 위반 빈도를 평가하고, 다수 승자 투표 규칙과 그 공리적 성능 간의 관계를 분석한다.

Result: 신경망이 전통적인 규칙보다 공리 위반을 최소화하는 데 더 뛰어난 성능을 보인다.

Conclusion: 데이터 기반 접근 방식이 새로운 투표 시스템 설계에 기여하고 사회적 선택 연구의 지속성을 지원할 수 있음을 시사한다.

Abstract: Committee-selection problems arise in many contexts and applications, and
there has been increasing interest within the social choice research community
on identifying which properties are satisfied by different multi-winner voting
rules. In this work, we propose a data-driven framework to evaluate how
frequently voting rules violate axioms across diverse preference distributions
in practice, shifting away from the binary perspective of axiom satisfaction
given by worst-case analysis. Using this framework, we analyze the relationship
between multi-winner voting rules and their axiomatic performance under several
preference distributions. We then show that neural networks, acting as voting
rules, can outperform traditional rules in minimizing axiom violations. Our
results suggest that data-driven approaches to social choice can inform the
design of new voting systems and support the continuation of data-driven
research in social choice.

</details>
