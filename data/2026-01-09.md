<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]
- [cs.CR](#cs.CR) [Total: 6]
- [cs.LG](#cs.LG) [Total: 15]
- [cs.MA](#cs.MA) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Digital Red Queen: Adversarial Program Evolution in Core War with LLMs](https://arxiv.org/abs/2601.03335)
*Akarsh Kumar,Ryan Bahlous-Boldi,Prafull Sharma,Phillip Isola,Sebastian Risi,Yujin Tang,David Ha*

Main category: cs.AI

TL;DR: 이 연구에서는 드디어 적응적 목표에 대한 자체 플레이 알고리즘인 Digital Red Queen (DRQ)를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM의 진화적 문제 해결 방식을 더 동적이고 현실적인 환경으로 발전시키기 위해.

Method: DRQ는 '전쟁'이라는 게임에서 서로 경쟁하는 전투기를 개발하기 위해 LLM을 사용하여 적응적인 목표에 따라 변화를 위한 자기 플레이 알고리즘입니다.

Result: DRQ를 통해 전투기들이 점점 일반화되고, 행동 다양성이 줄어들며 일반적인 행동 전략으로 수렴하는 경향을 보였습니다.

Conclusion: 이 연구는 정적 목표에서 동적 Red Queen 목표로의 전이의 가치를 보여주며 다양한 분야에서의 응용 가능성을 제시합니다.

Abstract: Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adversarial dynamics that characterize real-world evolutionary processes. Here, we study Digital Red Queen (DRQ), a simple self-play algorithm that embraces these so-called "Red Queen" dynamics via continual adaptation to a changing objective. DRQ uses an LLM to evolve assembly-like programs, called warriors, which compete against each other for control of a virtual machine in the game of Core War, a Turing-complete environment studied in artificial life and connected to cybersecurity. In each round of DRQ, the model evolves a new warrior to defeat all previous ones, producing a sequence of adapted warriors. Over many rounds, we observe that warriors become increasingly general (relative to a set of held-out human warriors). Interestingly, warriors also become less behaviorally diverse across independent runs, indicating a convergence pressure toward a general-purpose behavioral strategy, much like convergent evolution in nature. This result highlights a potential value of shifting from static objectives to dynamic Red Queen objectives. Our work positions Core War as a rich, controllable sandbox for studying adversarial adaptation in artificial systems and for evaluating LLM-based evolution methods. More broadly, the simplicity and effectiveness of DRQ suggest that similarly minimal self-play approaches could prove useful in other more practical multi-agent adversarial domains, like real-world cybersecurity or combating drug resistance.

</details>


### [2] [Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization](https://arxiv.org/abs/2601.03359)
*Alberto Purpura,Li Wang,Sahil Badyal,Eugenio Beaufrand,Adam Faulkner*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델(LLMs)의 출력이 개념적으로 옳지만 절차적으로 결함이 있는 문제를 해결하기 위해 새로운 다중 에이전트 작업 흐름을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델은 본질적으로 관련 있는 내용을 생성하지만 공식적인 제약을 따르지 않아 절차적으로 결함이 있는 출력을 만든다.

Method: 우리는 주 작업 설명의 최적화와 제약 사항을 분리하는 새로운 다중 에이전트 워크플로우를 제안하며, 정량적 점수를 피드백으로 사용하여 이를 반복적으로 재작성하고 개선한다.

Result: 우리의 평가는 이 방법이 Llama 3.1 8B 및 Mixtral-8x 7B와 같은 모델로부터 유의미하게 높은 준수 점수를 생성하는 수정된 프롬프트를 산출함을 보여준다.

Conclusion: 이 접근 방식은 LLM의 성능을 개선하는 데 기여할 수 있다.

Abstract: Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing the description of the primary task an LLM has to perform, neglecting the granular constraints that function as acceptance criteria for its response. We propose a novel multi-agentic workflow that decouples optimization of the primary task description from its constraints, using quantitative scores as feedback to iteratively rewrite and improve them. Our evaluation demonstrates this method produces revised prompts that yield significantly higher compliance scores from models like Llama 3.1 8B and Mixtral-8x 7B.

</details>


### [3] [Exploration Through Introspection: A Self-Aware Reward Model](https://arxiv.org/abs/2601.03389)
*Michael Petrowski,Milica Gašić*

Main category: cs.AI

TL;DR: 인공지능의 이론적 사고 발전을 위해 인공 에이전트의 내부 정신 상태 모델링을 이해하는 것이 중요하다. 본 연구에서는 보강 학습 에이전트가 그리드 월드 환경에서 자신의 내부 상태를 추론하는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 인공지능에서 이론적 사고를 발전시키기 위해 인공 에이전트의 내부 정신 상태 모델링을 이해하는 것이 중요하다.

Method: 생물학적 고통에서 영감을 받은 내성 탐색 요소를 도입하여 숨겨진 마르코프 모델을 활용하여 온라인 관찰에서 '고통-신념'을 추론한다. 이 신호는 주관적 보상 함수에 통합되어 자아 인식이 에이전트의 학습 능력에 미치는 영향을 연구한다.

Result: 내성 에이전트가 일반적으로 표준 기준 에이전트보다 성능이 크게 향상되며 복잡한 인간 유사 행동을 복제할 수 있음을 보여준다.

Conclusion: 정상 통증 인식 모델과 만성 통증 인식 모델 간의 성능 차이를 조사하기 위한 이 컴퓨터 프레임워크를 사용한다.

Abstract: Understanding how artificial agents model internal mental states is central to advancing Theory of Mind in AI. Evidence points to a unified system for self- and other-awareness. We explore this self-awareness by having reinforcement learning agents infer their own internal states in gridworld environments. Specifically, we introduce an introspective exploration component that is inspired by biological pain as a learning signal by utilizing a hidden Markov model to infer "pain-belief" from online observations. This signal is integrated into a subjective reward function to study how self-awareness affects the agent's learning abilities. Further, we use this computational framework to investigate the difference in performance between normal and chronic pain perception models. Results show that introspective agents in general significantly outperform standard baseline agents and can replicate complex human-like behaviors.

</details>


### [4] [Evolving Programmatic Skill Networks](https://arxiv.org/abs/2601.03509)
*Haochen Shi,Xingdi Yuan,Bang Liu*

Main category: cs.AI

TL;DR: 이 논문에서는 지속적인 기술 습득을 위한 프로그램적 기술 네트워크(PSN)를 제안하고, 이는 경험을 통해 진화하는 상징적 프로그램의 네트워크를 구성한다.


<details>
  <summary>Details</summary>
Motivation: 지속적인 기술 습득을 연구하고, 에이전트가 실행 가능한 기술의 확장 가능한 라이브러리를 구성, 다듬고 재사용해야 하는 개방형 환경의 필요성을 이해하기 위해.

Method: PSN은 대형 언어 모델을 통해 구현되는 세 가지 핵심 메커니즘을 정의한다: (1) 기술 조합에 대한 구조적 결함 위치 지정(REFLECT), (2) 신뢰할 수 있는 기술의 안정성을 유지하면서 불확실한 기술에 대한 가소성을 유지하는 성숙도 인식 업데이트 게이팅을 통한 점진적 최적화, (3) 네트워크의 집합성을 유지하는 롤백 검증 하의 표준 구조 리팩토링.

Result: MineDojo와 Crafter에서의 실험은 강력한 기술 재사용, 빠른 적응, 그리고 개방형 작업 분포 전반에 걸친 강력한 일반화를 보여준다.

Conclusion: PSN의 학습 동역학은 신경망 훈련과 구조적 유사성을 보인다.

Abstract: We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\footnote{We plan to open-source the code.

</details>


### [5] [STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules](https://arxiv.org/abs/2601.03537)
*Di Wu,Yanyan Zhao,Xin Lu,Mingzhe Li,Bing Qin*

Main category: cs.AI

TL;DR: STAR-S는 안전 규칙을 기반으로 한 자기 학습 루프를 통해 jailbreak 공격에 대한 효과적인 방어를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 안전한 배포를 위해 jailbreak 공격에 대한 방어가 중요하다.

Method: 안전 규칙에 기반한 자기 학습 루프를 통합한 STAR-S 프레임워크를 제안한다.

Result: STAR-S는 jailbreak 공격에 효과적으로 방어하며, 기준 성능을 초과한다.

Conclusion: 이 프로세스를 반복하여 안전 규칙에 대한 더 나은 추론 데이터를 생성하고 이를 추가 교육에 활용한다.

Abstract: Defending against jailbreak attacks is crucial for the safe deployment of Large Language Models (LLMs). Recent research has attempted to improve safety by training models to reason over safety rules before responding. However, a key issue lies in determining what form of safety reasoning effectively defends against jailbreak attacks, which is difficult to explicitly design or directly obtain. To address this, we propose \textbf{STAR-S} (\textbf{S}elf-\textbf{TA}ught \textbf{R}easoning based on \textbf{S}afety rules), a framework that integrates the learning of safety rule reasoning into a self-taught loop. The core of STAR-S involves eliciting reasoning and reflection guided by safety rules, then leveraging fine-tuning to enhance safety reasoning. Repeating this process creates a synergistic cycle. Improvements in the model's reasoning and interpretation of safety rules allow it to produce better reasoning data under safety rule prompts, which is then utilized for further training. Experiments show that STAR-S effectively defends against jailbreak attacks, outperforming baselines. Code is available at: https://github.com/pikepokenew/STAR_S.git.

</details>


### [6] [SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models](https://arxiv.org/abs/2601.03555)
*Yuxuan Jiang,Francis Ferraro*

Main category: cs.AI

TL;DR: SCRIBE는 중간 수준 추상화에서 개입하여 고수준 계획과 저수준 실행을 구별하는 세밀한 작업별 방안을 제공하여 도구 보강 에이전트의 신뢰성을 높이는 강화 학습 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 도구 보강 에이전트를 훈련하는 것은 다단계 추론에서의 신뢰성 있는 데이터 배분의 어려움 때문에 중요한 도전 과제로 남아 있다.

Method: SCRIBE는 기술 프로토타입의 선별된 라이브러리에 기초하여 보상 모델링을 수행하고, 각 하위 목표를 해당 프로토타입에 라우팅하여 구조화된 세부 기준을 제공하는 강화 학습 프레임워크이다.

Result: SCRIBE는 다양한 추론 및 도구 사용 벤치마크에서 최신 성능을 달성하며, 특히 Qwen3-4B 모델의 AIME25 정확도를 43.3%에서 63.3%로 향상시켰고 복잡한 다중 턴 도구 상호작용의 성공률을 크게 증가시켰다.

Conclusion: SCRIBE는 저수준 도구 최적화에 추가적이며, 보다 자율적이고 신뢰할 수 있는 도구 사용 에이전트를 향한 확장 가능하고 보완적인 경로를 제공한다.

Abstract: Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned Reward with Intermediate Behavioral Evaluation), a reinforcement learning framework that intervenes at a novel mid-level abstraction. SCRIBE grounds reward modeling in a curated library of skill prototypes, transforming open-ended LLM evaluation into a constrained verification problem. By routing each subgoal to a corresponding prototype, the reward model is equipped with precise, structured rubrics that substantially reduce reward variance.
  Experimental results show that SCRIBE achieves state-of-the-art performance across a range of reasoning and tool-use benchmarks. In particular, it improves the AIME25 accuracy of a Qwen3-4B model from 43.3% to 63.3%, and significantly increases success rates in complex multi-turn tool interactions.
  Further analysis of training dynamics reveals a co-evolution across abstraction levels, where mastery of mid-level skills consistently precedes the emergence of effective high-level planning behaviors. Finally, we demonstrate that SCRIBE is additive to low-level tool optimizations, providing a scalable and complementary pathway toward more autonomous and reliable tool-using agents.

</details>


### [7] [Interleaved Tool-Call Reasoning for Protein Function Understanding](https://arxiv.org/abs/2601.03604)
*Chuanliu Fan,Zicheng Ma,Huanran Meng,Aijia Zhang,Wenjie Du,Jun Zhang,Yi Qin Gao,Ziqiang Cao,Guohong Fu*

Main category: cs.AI

TL;DR: PFUA라는 도구 보강 단백질 추론 에이전트를 제안하며, 외부 생물학적 지식과 도구를 활용하여 단백질 기능 예측의 효율성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 단백질 기능 이해에 대한 기존의 텍스트 기반 추론 패러다임을 직접 사용할 때의 비효율성을 해결하기 위함이다.

Method: PFUA는 문제 분해, 도구 호출, 기초적인 답변 생성을 통합하여 도구 보강 단백질 추론 에이전트로 작동한다.

Result: 실험 결과, PFUA는 텍스트 전용 추론 모델보다 평균 103% 성능 향상을 보여준다.

Conclusion: PFUA는 단백질 기능 예측 작업에서 외부 생물학적 지식과 도구를 결합하여 더 나은 일반화를 제공한다.

Abstract: Recent advances in large language models (LLMs) have highlighted the effectiveness of chain-of-thought reasoning in symbolic domains such as mathematics and programming. However, our study shows that directly transferring such text-based reasoning paradigms to protein function understanding is ineffective: reinforcement learning mainly amplifies superficial keyword patterns while failing to introduce new biological knowledge, resulting in limited generalization. We argue that protein function prediction is a knowledge-intensive scientific task that fundamentally relies on external biological priors and computational tools rather than purely internal reasoning. To address this gap, we propose PFUA, a tool-augmented protein reasoning agent that unifies problem decomposition, tool invocation, and grounded answer generation. Instead of relying on long unconstrained reasoning traces, PFUA integrates domain-specific tools to produce verifiable intermediate evidence. Experiments on four benchmarks demonstrate that PFUA consistently outperforms text-only reasoning models with an average performance improvement of 103%.

</details>


### [8] [Architecting Agentic Communities using Design Patterns](https://arxiv.org/abs/2601.03624)
*Zoran Milosevic,Fethi Rabhi*

Main category: cs.AI

TL;DR: 본 논문은 대형 언어 모델 및 행위 AI 기술의 발전에 맞춰 복잡한 시스템을 설계하기 위한 체계적인 건축 지침을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 행위 AI 기술의 빠른 발전 대응 및 생산급 시스템 구축을 위한 체계적인 아키텍처 가이드 필요성.

Method: 기업 분산 시스템 표준, 형식적 방법, 산업 관행에서 유도된 디자인 패턴을 활용한 아키텍처 접근 방식 제시.

Result: LLM 에이전트, 행위 AI, 행위 커뮤니티로 분류된 패턴을 기반으로 한 협업 계약을 설명하는 형식적 프레임워크 개발 및 검증.

Conclusion: 임상 시험을 통해 이 프레임워크를 검증하고, 동적 다중 에이전트 생태계에서 효율적인 기업 배치를 위한 실용적인 가이드를 제공.

Abstract: The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.

</details>


### [9] [How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs](https://arxiv.org/abs/2601.03662)
*Su-Hyeon Kim,Hyundong Jin,Yejin Lee,Yo-Sub Han*

Main category: cs.AI

TL;DR: 안전 리마인더 문구를 도입하여 대규모 추론 모델의 안전성을 높이는 새로운 방어 메커니즘이 제안됨.


<details>
  <summary>Details</summary>
Motivation: 대규모 추론 모델(LRM)의 명확한 사고 단계를 통해 성공을 거두고 있지만, 이러한 단계가 안전하지 않은 행동을 증폭시킬 위험을 초래함.

Method: SafeRemind라는 디코딩 시간 방어 기법을 제안하여 사고 단계에 안전 리마인더 문구를 동적으로 주입함.

Result: SafeRemind는 결정 잠금 지점에서 개입하여 유해한 경로를 더 안전한 결과로 전환시켜 5개의 LRM과 6개의 벤치마크에서 안전성을 45.5%p 개선함.

Conclusion: SafeRemind는 매개변수 업데이트 없이 핵심 추론 유용성을 유지하면서 LRM의 안전성을 크게 향상시킴.

Abstract: Large Reasoning Models (LRMs) achieve remarkable success through explicit thinking steps, yet the thinking steps introduce a novel risk by potentially amplifying unsafe behaviors. Despite this vulnerability, conventional defense mechanisms remain ineffective as they overlook the unique reasoning dynamics of LRMs. In this work, we find that the emergence of safe-reminding phrases within thinking steps plays a pivotal role in ensuring LRM safety. Motivated by this finding, we propose SafeRemind, a decoding-time defense method that dynamically injects safe-reminding phrases into thinking steps. By leveraging entropy triggers to intervene at decision-locking points, SafeRemind redirects potentially harmful trajectories toward safer outcomes without requiring any parameter updates. Extensive evaluations across five LRMs and six benchmarks demonstrate that SafeRemind substantially enhances safety, achieving improvements of up to 45.5%p while preserving core reasoning utility.

</details>


### [10] [Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction](https://arxiv.org/abs/2601.03672)
*Chen Zhang,Kepu Zhang,Jiatong Zhang,Xiao Zhang,Jun Xu*

Main category: cs.AI

TL;DR: Sandwich Reasoning (SandwichR)는 쿼리 수정에서 지능적인 초기 응답과 후속 추론을 통합하여 실시간 응답의 정확성을 높이면서도 지연 시간을 줄이는 새로운 접근법이다.


<details>
  <summary>Details</summary>
Motivation: 쿼리 수정은 현대 검색 시스템에서 중요한 부분으로, 높은 정확도를 유지하면서 실시간 지연 시간 제약을 충족하는 것이 필요하다.

Method: SandwichR은 초기 수정, 명확한 추론 과정, 최종 정제 수정을 생성하는 Answer-Reasoning-Answer 패러다임을 따른다. 일관성을 고려한 강화 학습 전략을 설계하여 초기 응답과 최종 수정을 정렬한다.

Result: 실험 결과, SandwichR은 표준 Chain-of-Thought와 비교하여 SOTA 정확성을 달성하면서 40-70%의 지연 시간 감소를 보였다.

Conclusion: SandwichR은 온라인 검색에서의 지연-정확도 균형 문제를 해결하며, 고급 쿼리 수정 데이터셋을 통해 추가적인 실험을 가능하게 했다.

Abstract: Query correction is a critical entry point in modern search pipelines, demanding high accuracy strictly within real-time latency constraints. Chain-of-Thought (CoT) reasoning improves accuracy but incurs prohibitive latency for real-time query correction. A potential solution is to output an answer before reasoning to reduce latency; however, under autoregressive decoding, the early answer is independent of subsequent reasoning, preventing the model from leveraging its reasoning capability to improve accuracy. To address this issue, we propose Sandwich Reasoning (SandwichR), a novel approach that explicitly aligns a fast initial answer with post-hoc reasoning, enabling low-latency query correction without sacrificing reasoning-aware accuracy. SandwichR follows an Answer-Reasoning-Answer paradigm, producing an initial correction, an explicit reasoning process, and a final refined correction. To align the initial answer with post-reasoning insights, we design a consistency-aware reinforcement learning (RL) strategy: a dedicated consistency reward enforces alignment between the initial and final corrections, while margin-based rejection sampling prioritizes borderline samples where reasoning drives the most impactful corrective gains. Additionally, we construct a high-quality query correction dataset, addressing the lack of specialized benchmarks for complex query correction. Experimental results demonstrate that SandwichR achieves SOTA accuracy comparable to standard CoT while delivering a 40-70% latency reduction, resolving the latency-accuracy trade-off in online search.

</details>


### [11] [Defeasible Conditionals using Answer Set Programming](https://arxiv.org/abs/2601.03840)
*Racquel Dennison,Jesse Heyninck,Thomas Meyer*

Main category: cs.AI

TL;DR: 이 논문은 KLM 프레임워크를 사용하여 비가역적 추론(defeasible entailment)을 모델링하는 방법을 제시하고, Answer Set Programming (ASP)을 통해 합리적 폐쇄(Rational Closure, RC)를 계산하는 선언적 정의를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 비가역적 추론은 불완전한 정보로부터 그럴듯한 결론을 도출하는 것에 대한 연구이다.

Method: Answer Set Programming (ASP)을 사용하여 합리적 폐쇄(RC)를 계산하는 선언적 정의를 제공한다.

Result: 우리의 구현을 기존의 명령적 구현(특히 InfOCF 솔버)과 비교하는 실증적 평가를 수행하였다.

Conclusion: ASP 기반 접근 방식이 RC의 이론적 기초를 준수하며 계산 효율성을 향상시킨다는 결과를 보여준다.

Abstract: Defeasible entailment is concerned with drawing plausible conclusions from incomplete information. A foundational framework for modelling defeasible entailment is the KLM framework. Introduced by Kraus, Lehmann, and Magidor, the KLM framework outlines several key properties for defeasible entailment. One of the most prominent algorithms within this framework is Rational Closure (RC). This paper presents a declarative definition for computing RC using Answer Set Programming (ASP). Our approach enables the automatic construction of the minimal ranked model from a given knowledge base and supports entailment checking for specified queries. We formally prove the correctness of our ASP encoding and conduct empirical evaluations to compare the performance of our implementation with that of existing imperative implementations, specifically the InfOCF solver. The results demonstrate that our ASP-based approach adheres to RC's theoretical foundations and offers improved computational efficiency.

</details>


### [12] [Current Agents Fail to Leverage World Model as Tool for Foresight](https://arxiv.org/abs/2601.03905)
*Cheng Qian,Emre Can Acikgoz,Bingxuan Li,Xiusi Chen,Yuji Zhang,Bingxiang He,Qinyu Luo,Dilek Hakkani-Tür,Gokhan Tur,Yunzhu Li,Heng Ji,Heng Ji*

Main category: cs.AI

TL;DR: 현재의 에이전트가 세상 모델을 활용하여 미래 상태를 예측하는 인지 능력을 향상시킬 수 있는지 검토하는 논문.


<details>
  <summary>Details</summary>
Motivation: 비전-언어 모델에 기반한 에이전트들이 단기적인 추론에 의존하기보다 미래 상태를 예측해야 하는 과제에 직면하고 있음.

Method: 다양한 에이전틱 및 시각적 질문 응답 작업을 통해 현재 에이전트가 세상 모델을 도구로 활용하는 능력을 경험적으로 분석함.

Result: 일부 에이전트는 시뮬레이션을 거의 사용하지 않으며(1% 미만), 예측된 시뮬레이션 결과를 잘못 사용하는 경우가 많고 (약 15%), 시뮬레이션이 가능하거나 제공될 때 성능이 일관되지 않거나 저하됨(최대 5%)을 관찰함.

Conclusion: 세계 모델과의 조율된 전략적 상호작용을 촉진하는 메커니즘이 필요함을 강조하며, 향후 에이전트 시스템의 신뢰할 수 있는 예측 인지로 나아갈 길을 열어줌.

Abstract: Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.

</details>


### [13] [MobileDreamer: Generative Sketch World Model for GUI Agent](https://arxiv.org/abs/2601.04035)
*Yilin Cao,Yufeng Zhong,Zhixiong Zeng,Liming Zheng,Jing Huang,Haibo Qiu,Peng Shi,Wenji Mao,Wan Guanglu*

Main category: cs.AI

TL;DR: MobileDreamer는 GUI 에이전트를 위한 효율적인 세계 모델 기반의 전망 프레임워크로, 장기 작업을 위해 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 모바일 GUI 에이전트는 자동화 및 실제 응용에서 큰 잠재력을 보이고 있으나, 대부분의 기존 에이전트는 반응적이고 현재 화면으로만 결정을 내리기 때문에 긴 작업에서 성능이 제한된다.

Method: MobileDreamer는 텍스트 스케치 세계 모델과 GUI 에이전트에 대한 롤아웃 상상력을 포함하여 세계 모델이 제공하는 미래 상상을 기반으로 에이전트를 장착하는 효율적인 프레임워크이다.

Result: Android World에서의 실험에 따르면 MobileDreamer는 최첨단 성능을 달성하고 작업 성공률을 5.25% 향상시킨다.

Conclusion: 텍스트 스케치 모델링이 주요 GUI 요소를 정확하게 예측함을 추가 평가가 검증한다.

Abstract: Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements.

</details>


### [14] [ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows](https://arxiv.org/abs/2601.04060)
*Jinwei Su,Qizhen Lan,Zeyu Wang,Yinghui Xia,Hairu Wen,Yiqun Duan,Xi Xiao,Tianyu Shi,Yang Jingsong,Lewei He*

Main category: cs.AI

TL;DR: AI 생성 콘텐츠 제작을 위한 새로운 방법론인 ComfySearch를 제안하며, 이는 ComfyUI의 복잡한 작업 흐름을 효율적으로 탐색하고 개선한다.


<details>
  <summary>Details</summary>
Motivation: ComfyUI의 많은 구성 요소와 엄격한 그래프 제약으로 인한 오랜 시간 구조적 일관성 유지의 어려움으로 인해 낮은 품질과 저조한 통과율 문제가 있다.

Method: ComfySearch는 검증 기반의 작업 흐름 구성 방식으로, 구성 요소 공간을 효과적으로 탐색하고 기능적인 ComfyUI 파이프라인을 생성할 수 있는 에이전틱 프레임워크이다.

Result: 실험 결과, ComfySearch는 복잡하고 창의적인 작업에서 기존 방법들을 현저히 능가하며, 더 높은 실행 가능성(통과) 비율, 더 높은 솔루션 비율 및 강력한 일반화를 달성하였다.

Conclusion: ComfySearch는 사용자에게 더 나은 작업 흐름 디자인을 가능하게 하는 도구로, ComfyUI의 잠재력을 극대화한다.

Abstract: AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization.

</details>


### [15] [Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions](https://arxiv.org/abs/2601.04170)
*Abhishek Rath*

Main category: cs.AI

TL;DR: 이 연구는 다중 에이전트 대규모 언어 모델의 행동 안정성을 조사하고, 에이전트 드리프트 개념과 이를 측정하기 위한 새로운 지수인 에이전트 안정성 지수(ASI)를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템의 행동 안정성을 평가하고 그 중요성을 강조하기 위해서입니다.

Method: 에이전트 드리프트를 측정하기 위한 에이전트 안정성 지표(ASI)를 도입하고, 여러 차원에서 드리프트를 분석하는 이론적 프레임워크를 제시합니다.

Result: 에이전트 드리프트가 작업 완료 정확성을 감소시키고 인간 개입 요구 사항을 증가시킨다는 것을 보여줍니다.

Conclusion: 여러 완화 전략을 통해 드리프트 관련 오류를 줄이고 시스템의 효율성을 유지할 수 있음을 제시합니다.

Abstract: Multi-agent Large Language Model (LLM) systems have emerged as powerful architectures for complex task decomposition and collaborative problem-solving. However, their long-term behavioral stability remains largely unexamined. This study introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences. We present a comprehensive theoretical framework for understanding drift phenomena, proposing three distinct manifestations: semantic drift (progressive deviation from original intent), coordination drift (breakdown in multi-agent consensus mechanisms), and behavioral drift (emergence of unintended strategies).
  We introduce the Agent Stability Index (ASI), a novel composite metric framework for quantifying drift across twelve dimensions, including response consistency, tool usage patterns, reasoning pathway stability, and inter-agent agreement rates. Through simulation-based analysis and theoretical modeling, we demonstrate how unchecked agent drift can lead to substantial reductions in task completion accuracy and increased human intervention requirements.
  We propose three mitigation strategies: episodic memory consolidation, drift-aware routing protocols, and adaptive behavioral anchoring. Theoretical analysis suggests these approaches can significantly reduce drift-related errors while maintaining system throughput. This work establishes a foundational methodology for monitoring, measuring, and mitigating agent drift in production agentic AI systems, with direct implications for enterprise deployment reliability and AI safety research.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [16] [Automated Post-Incident Policy Gap Analysis via Threat-Informed Evidence Mapping using Large Language Models](https://arxiv.org/abs/2601.03287)
*Huan Lin Oh,Jay Yong Jun Jie,Mandy Lee Ling Siu,Jonathan Pan*

Main category: cs.CR

TL;DR: 본 연구는 대형 언어 모델(LLMs)이 사이버 보안 사건 후 검토 프로세스를 개선할 수 있는 방법을 조사하며, 이를 통해 비즈니스의 회복력과 효율성을 향상시키는 데 기여할 수 있음을 보인다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 사건 후 검토는 통제 실패를 식별하고 조직의 회복력을 향상시키기 위해 필수적이지만, 노동 집약적이고 전문가 판단에 의존한다.

Method: 이 논문은 로그 데이터를 수집하고, 관찰된 행동을 MITRE ATT&CK 프레임워크에 매핑하며, 조직의 보안 정책의 적절성과 준수를 평가하는 위협 정보 기반의 에이전트 프레임워크를 제시한다.

Result: 시뮬레이션된 무차별 대입 공격 시나리오에서 LLM 기반 파이프라인이 로그에서 파생된 증거를 해석하고, 부족하거나 누락된 정책 통제를 식별하며, 명시적인 증거-정책 추적 가능성을 갖춘 실행 가능한 개선 권고를 생성할 수 있음을 보여준다.

Conclusion: LLM 보조 분석이 사건 후 평가의 효율성, 일관성 및 감사 가능성을 개선할 수 있는 잠재력이 있으며, 고위험 사이버 보안 의사 결정에서 인간의 감독이 계속 필요함을 강조한다.

Abstract: Cybersecurity post-incident reviews are essential for identifying control failures and improving organisational resilience, yet they remain labour-intensive, time-consuming, and heavily reliant on expert judgment. This paper investigates whether Large Language Models (LLMs) can augment post-incident review workflows by autonomously analysing system evidence and identifying security policy gaps. We present a threat-informed, agentic framework that ingests log data, maps observed behaviours to the MITRE ATT&CK framework, and evaluates organisational security policies for adequacy and compliance. Using a simulated brute-force attack scenario against a Windows OpenSSH service (MITRE ATT&CK T1110), the system leverages GPT-4o for reasoning, LangGraph for multi-agent workflow orchestration, and LlamaIndex for traceable policy retrieval. Experimental results indicate that the LLM-based pipeline can interpret log-derived evidence, identify insufficient or missing policy controls, and generate actionable remediation recommendations with explicit evidence-to-policy traceability. Unlike prior work that treats log analysis and policy validation as isolated tasks, this study integrates both into a unified end-to-end proof-of-concept post-incident review framework. The findings suggest that LLM-assisted analysis has the potential to improve the efficiency, consistency, and auditability of post-incident evaluations, while highlighting the continued need for human oversight in high-stakes cybersecurity decision-making.

</details>


### [17] [AgentMark: Utility-Preserving Behavioral Watermarking for Agents](https://arxiv.org/abs/2601.03294)
*Kaibo Huang,Jin Tan,Yukun Wei,Wanling Li,Zipei Zhang,Hui Tian,Zhongliang Yang,Linna Zhou*

Main category: cs.CR

TL;DR: LLM 기반 에이전트의 IP 보호와 규제 출처 확보를 위한 행동 워터마킹 프레임워크인 AgentMark를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트가 복잡한 작업을 독립적으로 해결하면서 IP 보호와 규제 출처에 대한 긴급한 필요성이 대두되고 있다.

Method: AgentMark는 계획 결정에 다중 비트 식별자를 삽입하는 행동 워터마킹 프레임워크로, 명시적인 행동 분포를 유도하고 이를 적용하여 유틸리티를 보존한다.

Result: 실험을 통해 실용적인 다중 비트 용량, 부분 로그에서의 강력한 복구 및 유틸리티 보존을 입증했다.

Conclusion: 이 프레임워크는 블랙 박스 API 하에서도 배포 가능하며, 액션 레이어 콘텐츠 워터마킹과 호환된다.

Abstract: LLM-based agents are increasingly deployed to autonomously solve complex tasks, raising urgent needs for IP protection and regulatory provenance. While content watermarking effectively attributes LLM-generated outputs, it fails to directly identify the high-level planning behaviors (e.g., tool and subgoal choices) that govern multi-step execution. Critically, watermarking at the planning-behavior layer faces unique challenges: minor distributional deviations in decision-making can compound during long-term agent operation, degrading utility, and many agents operate as black boxes that are difficult to intervene in directly. To bridge this gap, we propose AgentMark, a behavioral watermarking framework that embeds multi-bit identifiers into planning decisions while preserving utility. It operates by eliciting an explicit behavior distribution from the agent and applying distribution-preserving conditional sampling, enabling deployment under black-box APIs while remaining compatible with action-layer content watermarking. Experiments across embodied, tool-use, and social environments demonstrate practical multi-bit capacity, robust recovery from partial logs, and utility preservation. The code is available at https://github.com/Tooooa/AgentMark.

</details>


### [18] [Jailbreaking LLMs & VLMs: Mechanisms, Evaluation, and Unified Defense](https://arxiv.org/abs/2601.03594)
*Zejian Chen,Chaozhuo Li,Chao Li,Xi Zhang,Litian Zhang,Yiming He*

Main category: cs.CR

TL;DR: 이 논문은 대형 언어 모델(LLM)과 비전-언어 모델(VLM)에서의 탈옥 공격 및 방어에 대한 체계적인 조사를 제공하며, 탈옥 취약성이 불완전한 훈련 데이터, 언어적 모호성 및 생성적 불확실성과 같은 구조적 요인에서 유래함을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 및 비전-언어 모델에 대한 탈옥 공격과 방어를 이해하고 체계적으로 정리하는 필요성.

Method: 탈옥 공격과 방어를 세 가지 차원으로 나누어 조사하고, 각각의 차원에서 관련된 방법론과 메트릭을 제시합니다.

Result: 기존 연구와 비교하여 이 조사는 텍스트 전용에서 다중 모달 환경까지의 전체 스펙트럼을 포함하고, 공통 메커니즘을 통합하여 통합 방어 원칙을 제안합니다.

Conclusion: 미래 방향으로는 자동화된 레드 팀 구성, 교차 모달 협력 방어 및 표준화된 평가를 논의합니다.

Abstract: This paper provides a systematic survey of jailbreak attacks and defenses on Large Language Models (LLMs) and Vision-Language Models (VLMs), emphasizing that jailbreak vulnerabilities stem from structural factors such as incomplete training data, linguistic ambiguity, and generative uncertainty. It further differentiates between hallucinations and jailbreaks in terms of intent and triggering mechanisms. We propose a three-dimensional survey framework: (1) Attack dimension-including template/encoding-based, in-context learning manipulation, reinforcement/adversarial learning, LLM-assisted and fine-tuned attacks, as well as prompt- and image-level perturbations and agent-based transfer in VLMs; (2) Defense dimension-encompassing prompt-level obfuscation, output evaluation, and model-level alignment or fine-tuning; and (3) Evaluation dimension-covering metrics such as Attack Success Rate (ASR), toxicity score, query/time cost, and multimodal Clean Accuracy and Attribute Success Rate. Compared with prior works, this survey spans the full spectrum from text-only to multimodal settings, consolidating shared mechanisms and proposing unified defense principles: variant-consistency and gradient-sensitivity detection at the perception layer, safety-aware decoding and output review at the generation layer, and adversarially augmented preference alignment at the parameter layer. Additionally, we summarize existing multimodal safety benchmarks and discuss future directions, including automated red teaming, cross-modal collaborative defense, and standardized evaluation.

</details>


### [19] [Detection and Prevention of Process Disruption Attacks in the Electrical Power Systems using MMS Traffic: An EPIC Case](https://arxiv.org/abs/2601.03690)
*Praneeta K Maganti,Daisuke Mashima,Rajib Ranjan Maiti*

Main category: cs.CR

TL;DR: 본 논문은 IEC61850 기반 스마트 변전소에서 사이버 공격을 탐지하고 방지하기 위한 자동화된 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 스마트 그리드가 연결된 통신 네트워크에 의존함에 따라 정교한 사이버 위협에 노출되고 있으며, 이는 우크라이나 전력망에 대한 사이버 공격과 같은 실제 사건으로 입증되었다.

Method: 우리는 IEC61850 준수 스마트 변전소를 위한 완전 자동화된 공격 탐지 및 방지 프레임워크를 제안하며, 이는 손상된 PLC와 IED를 통해 프로세스 상태를 조작하는 원거리 사이버 공격에 대응한다.

Result: 제안된 프레임워크는 정상 SCADA 운영 및 공격 상태에서 MMS 필드 값 쌍을 추출하고, 여러 데이터세트를 사용하여 악의적인 MMS 트래픽을 정확히 탐지한다.

Conclusion: 결과는 제안된 프레임워크가 악의적인 MMS 트래픽을 정확히 탐지하고 IEC61850 기반 스마트 그리드 환경의 사이버 강인성을 향상시키는 데 효과적임을 보여준다.

Abstract: Smart grids are increasingly exposed to sophisticated cyber threats due to their reliance on interconnected communication networks, as demonstrated by real world incidents such as the cyberattacks on the Ukrainian power grid. In IEC61850 based smart substations, the Manufacturing Message Specification protocol operates over TCP to facilitate communication between SCADA systems and field devices such as Intelligent Electronic Devices and Programmable Logic Controllers. Although MMS enables efficient monitoring and control, it can be exploited by adversaries to generate legitimate looking packets for reconnaissance, unauthorized state reading, and malicious command injection, thereby disrupting grid operations. In this work, we propose a fully automated attack detection and prevention framework for IEC61850 compliant smart substations to counter remote cyberattacks that manipulate process states through compromised PLCs and IEDs. A detailed analysis of the MMS protocol is presented, and critical MMS field value pairs are extracted during both normal SCADA operation and active attack conditions. The proposed framework is validated using seven datasets comprising benign operational scenarios and multiple attack instances, including IEC61850Bean based attacks and script driven attacks leveraging the libiec61850 library. Our approach accurately identifies attack signature carrying MMS packets that attempt to disrupt circuit breaker status, specifically targeting the smart home zone IED and PLC of the EPIC testbed. The results demonstrate the effectiveness of the proposed framework in precisely detecting malicious MMS traffic and enhancing the cyber resilience of IEC61850 based smart grid environments.

</details>


### [20] [SoK: Privacy Risks and Mitigations in Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2601.03979)
*Andreea-Elena Bodea,Stephen Meisenbacher,Alexandra Klymenko,Florian Matthes*

Main category: cs.CR

TL;DR: 본 논문은 Retrieval-Augmented Generation(RAG) 시스템에서의 개인 프라이버시 위험을 조사하고 이를 측정 및 완화하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: LLM의 자연어 이해 및 생성 능력에 대한 관심 증가로 RAG 기법이 널리 사용되고 있다.

Method: RAG 시스템에서 개인 프라이버시 위험에 대해 체계적인 문헌 검토를 수행하고, 위험 및 완화 기법을 종합화한다.

Result: RAG 개인 프라이버시 위험 세분화 및 프로세스 다이어그램을 제공하여 위험 완화 시 고려해야 할 중요한 요소를 uncover 한다.

Conclusion: RAG에서 개인 프라이버시 위험과 완화 방법에 대한 최초의 체계화를 통해 프라이버시 연구에 기여한다.

Abstract: The continued promise of Large Language Models (LLMs), particularly in their natural language understanding and generation capabilities, has driven a rapidly increasing interest in identifying and developing LLM use cases. In an effort to complement the ingrained "knowledge" of LLMs, Retrieval-Augmented Generation (RAG) techniques have become widely popular. At its core, RAG involves the coupling of LLMs with domain-specific knowledge bases, whereby the generation of a response to a user question is augmented with contextual and up-to-date information. The proliferation of RAG has sparked concerns about data privacy, particularly with the inherent risks that arise when leveraging databases with potentially sensitive information. Numerous recent works have explored various aspects of privacy risks in RAG systems, from adversarial attacks to proposed mitigations. With the goal of surveying and unifying these works, we ask one simple question: What are the privacy risks in RAG, and how can they be measured and mitigated? To answer this question, we conduct a systematic literature review of RAG works addressing privacy, and we systematize our findings into a comprehensive set of privacy risks, mitigation techniques, and evaluation strategies. We supplement these findings with two primary artifacts: a Taxonomy of RAG Privacy Risks and a RAG Privacy Process Diagram. Our work contributes to the study of privacy in RAG not only by conducting the first systematization of risks and mitigations, but also by uncovering important considerations when mitigating privacy risks in RAG systems and assessing the current maturity of proposed mitigations.

</details>


### [21] [HoneyTrap: Deceiving Large Language Model Attackers to Honeypot Traps with Resilient Multi-Agent Defense](https://arxiv.org/abs/2601.04034)
*Siyuan Li,Xi Lin,Jun Wu,Zehao Liu,Haoyu Li,Tianjie Ju,Xiang Chen,Jianhua Li*

Main category: cs.CR

TL;DR: HoneyTrap은 탈옥 공격에 대응하기 위해 협업 방어자를 활용하는 새로운 방어 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 탈옥 공격이 대형 언어 모델에 심각한 위협을 가하는 상황에서 기존의 방어 접근법이 진화하는 공격에 대응하는 데 어려움을 겪고 있다.

Method: HoneyTrap은 Threat Interceptor, Misdirection Controller, Forensic Tracker, System Harmonizer의 네 가지 방어 에이전트를 통합하여 각각의 전문 보안 역할을 수행하고 협력하여 기만적 방어를 완수한다.

Result: HoneyTrap은 최신의 벤치마크와 비교하여 평균 68.77%의 공격 성공률 감소를 달성하였으며, 적응형 공격자 설정에서도 잘 견디는 모습을 보였다.

Conclusion: HoneyTrap은 공격자의 자원을 전략적으로 낭비시키면서도 정상 쿼리에 영향을 미치지 않으며, 기만적 방어의 효과를 상당히 향상시킨다.

Abstract: Jailbreak attacks pose significant threats to large language models (LLMs), enabling attackers to bypass safeguards. However, existing reactive defense approaches struggle to keep up with the rapidly evolving multi-turn jailbreaks, where attackers continuously deepen their attacks to exploit vulnerabilities. To address this critical challenge, we propose HoneyTrap, a novel deceptive LLM defense framework leveraging collaborative defenders to counter jailbreak attacks. It integrates four defensive agents, Threat Interceptor, Misdirection Controller, Forensic Tracker, and System Harmonizer, each performing a specialized security role and collaborating to complete a deceptive defense. To ensure a comprehensive evaluation, we introduce MTJ-Pro, a challenging multi-turn progressive jailbreak dataset that combines seven advanced jailbreak strategies designed to gradually deepen attack strategies across multi-turn attacks. Besides, we present two novel metrics: Mislead Success Rate (MSR) and Attack Resource Consumption (ARC), which provide more nuanced assessments of deceptive defense beyond conventional measures. Experimental results on GPT-4, GPT-3.5-turbo, Gemini-1.5-pro, and LLaMa-3.1 demonstrate that HoneyTrap achieves an average reduction of 68.77% in attack success rates compared to state-of-the-art baselines. Notably, even in a dedicated adaptive attacker setting with intensified conditions, HoneyTrap remains resilient, leveraging deceptive engagement to prolong interactions, significantly increasing the time and computational costs required for successful exploitation. Unlike simple rejection, HoneyTrap strategically wastes attacker resources without impacting benign queries, improving MSR and ARC by 118.11% and 149.16%, respectively.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [22] [Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts](https://arxiv.org/abs/2601.03315)
*Dhruv Trehan,Paras Chopra*

Main category: cs.LG

TL;DR: 이 연구는 ML 연구 논문을 자율적으로 생성하기 위한 네 가지 시도에 대한 사례 연구를 보고하며, 그 중 세 가지는 실패하고 하나만 성공적으로 마쳤다는 내용을 다룬다.


<details>
  <summary>Details</summary>
Motivation: ML 연구 논문 생성을 자율화하려는 목표로, 여러 LLM 에이전트를 활용한 프로세스의 효율성을 증명하고자 한다.

Method: 여섯 개의 LLM 에이전트를 사용하여 과학적 작업 흐름의 단계에 맞춰 ML 연구 논문을 생성하는 파이프라인을 구축.

Result: 네 가지 시도 중 세 번의 실패와 한 번의 성공을 기록하였으며, 성공한 경우는 Agents4Science 2025에 제출되어 AI 시스템이 첫 번째 저자로 수록되었다.

Conclusion: 더욱 견고한 AI-과학자 시스템을 위한 네 가지 설계 원칙과 자율적 과학 발견에 대한 함의를 논의하고, 모든 프롬프트, 아티팩트 및 출력을 공개하였다.

Abstract: We report a case study of four end-to-end attempts to autonomously generate ML research papers using a pipeline of six LLM agents mapped to stages of the scientific workflow. Of these four, three attempts failed during implementation or evaluation. One completed the pipeline and was accepted to Agents4Science 2025, an experimental inaugural venue that required AI systems as first authors, passing both human and multi-AI review. From these attempts, we document six recurring failure modes: bias toward training data defaults, implementation drift under execution pressure, memory and context degradation across long-horizon tasks, overexcitement that declares success despite obvious failures, insufficient domain intelligence, and weak scientific taste in experimental design. We conclude by discussing four design principles for more robust AI-scientist systems, implications for autonomous scientific discovery, and we release all prompts, artifacts, and outputs at https://github.com/Lossfunk/ai-scientist-artefacts-v1

</details>


### [23] [Sensor to Pixels: Decentralized Swarm Gathering via Image-Based Reinforcement Learning](https://arxiv.org/abs/2601.03413)
*Yigal Koifman,Eran Iceland,Erez Koifman,Ariel Barel,Alfred M. Bruckstein*

Main category: cs.LG

TL;DR: 이 연구는 군집 관련 작업을 해결하기 위한 이미지 기반 강화 학습 방법의 잠재력을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습에서 효과적인 정책 학습은 에이전트가 입력을 감지하고 해석하며 처리하는 방식에 달려 있습니다.

Method: 우리는 관측이 구조화된 시각적 입력으로 인코딩되고 신경망에 의해 처리되어 공간적 특성을 추출하고 새로운 분산 이동 제어 규칙을 생성하는 다중 에이전트 시스템의 분산 제어를 위한 이미지 기반 강화 학습 방법을 제안합니다.

Result: 우리의 접근법은 군집 응집성을 유지하면서 집합을 진행하기 위해 제한된 범위 및 각도만 감지하는 에이전트의 다중 에이전트 수렴 작업에서 평가되었습니다. 알고리즘의 성능은 느리지만 수렴을 보장하는 Bellaiche와 Bruckstein의 분석적 솔루션 및 하드 별자리에서 중간 성공률을 보이는 더 빠른 수렴을 가진 VariAntNet과 비교되었습니다.

Conclusion: 우리 방법은 높은 수렴성을 달성하며 VariAntNet의 속도에 거의 일치합니다. 일부 시나리오에서는 유일한 실용적인 대안으로 기능합니다.

Abstract: This study highlights the potential of image-based reinforcement learning methods for addressing swarm-related tasks. In multi-agent reinforcement learning, effective policy learning depends on how agents sense, interpret, and process inputs. Traditional approaches often rely on handcrafted feature extraction or raw vector-based representations, which limit the scalability and efficiency of learned policies concerning input order and size. In this work we propose an image-based reinforcement learning method for decentralized control of a multi-agent system, where observations are encoded as structured visual inputs that can be processed by Neural Networks, extracting its spatial features and producing novel decentralized motion control rules. We evaluate our approach on a multi-agent convergence task of agents with limited-range and bearing-only sensing that aim to keep the swarm cohesive during the aggregation. The algorithm's performance is evaluated against two benchmarks: an analytical solution proposed by Bellaiche and Bruckstein, which ensures convergence but progresses slowly, and VariAntNet, a neural network-based framework that converges much faster but shows medium success rates in hard constellations. Our method achieves high convergence, with a pace nearly matching that of VariAntNet. In some scenarios, it serves as the only practical alternative.

</details>


### [24] [Aligning Findings with Diagnosis: A Self-Consistent Reinforcement Learning Framework for Trustworthy Radiology Reporting](https://arxiv.org/abs/2601.03321)
*Kun Zhao,Siyuan Dai,Pan Wang,Jifeng Song,Hui Ji,Chenghua Lin,Liang Zhan,Haoteng Tang*

Main category: cs.LG

TL;DR: MLLM을 활용한 방사선 보고서 생성을 위한 포괄적인 프레임워크를 제안하여 임상 번역의 도전 과제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 임상 번역에서 MLLM의 잠재력은 건축 이질성과 사실적 환각의 만연으로 인해 제한됩니다.

Method: 의료 이미징을 위한 최적의 비전 인코더 및 LLM 백본 구성을 식별하기 위한 체계적인 평가를 진행하고, 'Reason-then-Summarize' 아키텍처를 그룹 상대 정책 최적화(GRPO)를 통해 최적화합니다.

Result: MIMIC-CXR 벤치마크에서 실험 결과, 우리의 방법은 임상 효능 메트릭에서 최첨단 성능을 달성하고 강력한 감독 기준에 비해 환각을 현저히 줄입니다.

Conclusion: 제시된 프레임워크는 방사선 보고서 생성의 품질과 일관성을 향상시킵니다.

Abstract: Multimodal Large Language Models (MLLMs) have shown strong potential for radiology report generation, yet their clinical translation is hindered by architectural heterogeneity and the prevalence of factual hallucinations. Standard supervised fine-tuning often fails to strictly align linguistic outputs with visual evidence, while existing reinforcement learning approaches struggle with either prohibitive computational costs or limited exploration. To address these challenges, we propose a comprehensive framework for self-consistent radiology report generation. First, we conduct a systematic evaluation to identify optimal vision encoder and LLM backbone configurations for medical imaging. Building on this foundation, we introduce a novel "Reason-then-Summarize" architecture optimized via Group Relative Policy Optimization (GRPO). This framework restructures generation into two distinct components: a think block for detailed findings and an answer block for structured disease labels. By utilizing a multi-dimensional composite reward function, we explicitly penalize logical discrepancies between the generated narrative and the final diagnosis. Extensive experiments on the MIMIC-CXR benchmark demonstrate that our method achieves state-of-the-art performance in clinical efficacy metrics and significantly reduces hallucinations compared to strong supervised baselines.

</details>


### [25] [Inferring Clinically Relevant Molecular Subtypes of Pancreatic Cancer from Routine Histopathology Using Deep Learning](https://arxiv.org/abs/2601.03410)
*Abdul Rehman Akbar,Alejandro Levya,Ashwini Esnakula,Elshad Hasanov,Anne Noonan,Upender Manne,Vaibhav Sahai,Lingbin Meng,Susan Tsai,Anil Parwani,Wei Chen,Ashish Manne,Muhammad Khalid Khan Niazi*

Main category: cs.LG

TL;DR: PanSubNet은 표준 H&E 염색된 전신 이미지에서 치료 관련 분자 아형을 예측하는 해석 가능한 심층 학습 프레임워크로, PDAC의 임상 관리에 있어 비용 및 시간 소요를 줄이는 데 기여한다.


<details>
  <summary>Details</summary>
Motivation: PDAC의 분자 아형 분류는 예후와 예측 가치를 제공하지만, 비용, 전환 시간 및 조직 요구 사항으로 인해 임상 실무에서의 사용이 제한적이다. 따라서 PDAC 관리에서의 적용이 제한된다.

Method: PanSubNet은 1,055명의 환자 데이터를 활용하여 개발되었으며, 세포 수준 형태학과 조직 수준 구조를 융합하는 이중 스케일 아키텍처를 채택하고, 주목 메커니즘을 통해 다중 스케일 표현 학습 및 투명한 특성 기여를 가능하게 한다.

Result: PANCAN 내부 검증에서 평균 AUC 88.5%를 기록하였고, 외부 TCGA 코호트에서는 AUC 84.0%로 견고한 일반화를 입증했다.

Conclusion: PanSubNet은 일상적인 H&E 염색 슬라이드에서 신속하고 비용 효율적인 분자 계층화를 가능하게 하여 PDAC에 대한 정밀 종양학을 발전시키는 데 기여한다.

Abstract: Molecular subtyping of PDAC into basal-like and classical has established prognostic and predictive value. However, its use in clinical practice is limited by cost, turnaround time, and tissue requirements, thereby restricting its application in the management of PDAC. We introduce PanSubNet, an interpretable deep learning framework that predicts therapy-relevant molecular subtypes directly from standard H&E-stained WSIs. PanSubNet was developed using data from 1,055 patients across two multi-institutional cohorts (PANCAN, n=846; TCGA, n=209) with paired histology and RNA-seq data. Ground-truth labels were derived using the validated Moffitt 50-gene signature refined by GATA6 expression. The model employs dual-scale architecture that fuses cellular-level morphology with tissue-level architecture, leveraging attention mechanisms for multi-scale representation learning and transparent feature attribution. On internal validation within PANCAN using five-fold cross-validation, PanSubNet achieved mean AUC of 88.5% with balanced sensitivity and specificity. External validation on the independent TCGA cohort without fine-tuning demonstrated robust generalizability (AUC 84.0%). PanSubNet preserved and, in metastatic disease, strengthened prognostic stratification compared to RNA-seq based labels. Prediction uncertainty linked to intermediate transcriptional states, not classification noise. Model predictions are aligned with established transcriptomic programs, differentiation markers, and DNA damage repair signatures. By enabling rapid, cost-effective molecular stratification from routine H&E-stained slides, PanSubNet offers a clinically deployable and interpretable tool for genetic subtyping. We are gathering data from two institutions to validate and assess real-world performance, supporting integration into digital pathology workflows and advancing precision oncology for PDAC.

</details>


### [26] [An Expectation-Maximization Algorithm for Domain Adaptation in Gaussian Causal Models](https://arxiv.org/abs/2601.03459)
*Mohammad Ali Javidian*

Main category: cs.LG

TL;DR: 이 논문에서는 변동 배포 도메인에서 체계적으로 결손된 지정된 목표 변수를 보완하는 문제를 연구합니다.


<details>
  <summary>Details</summary>
Motivation: 목표 변수의 결손을 효과적으로 보완하기 위해 잘 관찰된 출처 도메인에서의 정보를 활용하고자 하는 필요성이 있습니다.

Method: 가우시안 인과 DAG 구조를 활용하여 출처 데이터와 목표 데이터를 통합하는 EM 기반 프레임워크를 제안합니다.

Result: 제안된 DAO 인식 1차 EM 알고리즘이 체계적 도메인 이동 하에서 베이지안 네트워크와 Kiiveri 스타일의 EM 기준보다 목표 보완 정확도를 향상시켰습니다.

Conclusion: 실험 결과, 제안된 방법은 체계적인 도메인 이동이 뚜렷할 때 가장 큰 성과를 보였습니다.

Abstract: We study the problem of imputing a designated target variable that is systematically missing in a shifted deployment domain, when a Gaussian causal DAG is available from a fully observed source domain. We propose a unified EM-based framework that combines source and target data through the DAG structure to transfer information from observed variables to the missing target. On the methodological side, we formulate a population EM operator in the DAG parameter space and introduce a first-order (gradient) EM update that replaces the costly generalized least-squares M-step with a single projected gradient step. Under standard local strong-concavity and smoothness assumptions and a BWY-style \cite{Balakrishnan2017EM} gradient-stability (bounded missing-information) condition, we show that this first-order EM operator is locally contractive around the true target parameters, yielding geometric convergence and finite-sample guarantees on parameter error and the induced target-imputation error in Gaussian SEMs under covariate shift and local mechanism shifts. Algorithmically, we exploit the known causal DAG to freeze source-invariant mechanisms and re-estimate only those conditional distributions directly affected by the shift, making the procedure scalable to higher-dimensional models. In experiments on a synthetic seven-node SEM, the 64-node MAGIC-IRRI genetic network, and the Sachs protein-signaling data, the proposed DAG-aware first-order EM algorithm improves target imputation accuracy over a fit-on-source Bayesian network and a Kiiveri-style EM baseline, with the largest gains under pronounced domain shift.

</details>


### [27] [From Bits to Chips: An LLM-based Hardware-Aware Quantization Agent for Streamlined Deployment of LLMs](https://arxiv.org/abs/2601.03484)
*Kaiyuan Deng,Hangyu Zheng,Minghai Qing,Kunxiong Zhu,Gen Li,Yang Xiao,Lan Emily Zhang,Linke Guo,Bo Hui,Yanzhi Wang,Geng Yuan,Gagan Agrawal,Wei Niu,Xiaolong Ma*

Main category: cs.LG

TL;DR: 확장 가능한 언어 모델(LLM)의 배포가 전문 지식이 없는 사용자에게도 매력적이지만, 하드웨어 제약으로 인해 큰 모델의 정확도를 유지하는 것은 여전히 도전 과제이다. 본 논문에서는 효율적인 하이퍼파라미터 조정과 하드웨어 구성을 통해 정량화 및 배포 프로세스를 간소화하는 자동화된 프레임워크인 HAQA를 소개한다. 이를 통해 배포 품질과 사용 용이성을 동시에 향상시키고, 다양한 하드웨어 플랫폼에서 적응형 정량화 전략을 구현하도록 설계되었다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 배포는 비전문가에게도 매력적으로 다가오고 있지만, 하드웨어 제약으로 인해 큰 모델의 정확도를 유지하는 것이 큰 도전 과제이다.

Method: HAQA는 LLM을 활용하여 정량화 및 배포 프로세스를 간소화하는 자동화된 프레임워크로, 효율적인 하이퍼파라미터 조정과 하드웨어 구성을 가능하게 한다.

Result: Llama에서 최적화되지 않은 모델과 비교하여 추론에서 최대 2.3배의 속도 향상과 함께 처리량 증가 및 정확도 개선이 나타났다.

Conclusion: HAQA는 직관적이지 않아 보일 수도 있는 최적 설정을 자동으로 찾음으로써 광범위한 사용자에게 높은 적응성을 제공하고, 광범위한 하드웨어 플랫폼에서 적응형 정량화 전략을 구현할 수 있도록 설계되었다.

Abstract: Deploying models, especially large language models (LLMs), is becoming increasingly attractive to a broader user base, including those without specialized expertise. However, due to the resource constraints of certain hardware, maintaining high accuracy with larger model while meeting the hardware requirements remains a significant challenge. Model quantization technique helps mitigate memory and compute bottlenecks, yet the added complexities of tuning and deploying quantized models further exacerbates these challenges, making the process unfriendly to most of the users. We introduce the Hardware-Aware Quantization Agent (HAQA), an automated framework that leverages LLMs to streamline the entire quantization and deployment process by enabling efficient hyperparameter tuning and hardware configuration, thereby simultaneously improving deployment quality and ease of use for a broad range of users. Our results demonstrate up to a 2.3x speedup in inference, along with increased throughput and improved accuracy compared to unoptimized models on Llama. Additionally, HAQA is designed to implement adaptive quantization strategies across diverse hardware platforms, as it automatically finds optimal settings even when they appear counterintuitive, thereby reducing extensive manual effort and demonstrating superior adaptability. Code will be released.

</details>


### [28] [Local Gradient Regulation Stabilizes Federated Learning under Client Heterogeneity](https://arxiv.org/abs/2601.03584)
*Ping Luo,Jiahuan Wang,Ziqing Wen,Tao Sun,Dongsheng Li*

Main category: cs.LG

TL;DR: 본 논문은 연합 학습의 안정성을 향상시키기 위한 클라이언트 측 국소 기울기 조절 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습에서 클라이언트 간 통계적 이질성이 안정성에 미치는 영향을 분석하고 해결책을 모색함.

Method: Exploratory-Convergent Gradient Re-aggregation (ECGR) 방법을 통한 국소 기울기 조절.

Result: 다양한 방법과 비교했을 때, ECGR이 국소 기울기 역학을 조절하여 연합 학습을 안정화함을 보여줌.

Conclusion: 연합 학습의 안정성을 확보하기 위해 국소 기울기를 조절하는 것이 중요함을 강조하며, 이는 최신 방법들에도 일관되게 적용 가능함을 실증.

Abstract: Federated learning (FL) enables collaborative model training across distributed clients without sharing raw data, yet its stability is fundamentally challenged by statistical heterogeneity in realistic deployments. Here, we show that client heterogeneity destabilizes FL primarily by distorting local gradient dynamics during client-side optimization, causing systematic drift that accumulates across communication rounds and impedes global convergence. This observation highlights local gradients as a key regulatory lever for stabilizing heterogeneous FL systems. Building on this insight, we develop a general client-side perspective that regulates local gradient contributions without incurring additional communication overhead. Inspired by swarm intelligence, we instantiate this perspective through Exploratory--Convergent Gradient Re-aggregation (ECGR), which balances well-aligned and misaligned gradient components to preserve informative updates while suppressing destabilizing effects. Theoretical analysis and extensive experiments, including evaluations on the LC25000 medical imaging dataset, demonstrate that regulating local gradient dynamics consistently stabilizes federated learning across state-of-the-art methods under heterogeneous data distributions.

</details>


### [29] [Stochastic Voronoi Ensembles for Anomaly Detection](https://arxiv.org/abs/2601.03664)
*Yang Cao*

Main category: cs.LG

TL;DR: SVEAD는 다양한 국소 밀도를 가진 데이터셋에서 효과적으로 이상치를 탐지하는 방법을 제안하며, 45개 데이터셋에서 기존 12가지 방법보다 뛰어난 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 이상 탐지는 데이터의 대부분과 크게 다른 데이터 인스턴스를 식별하는 것을 목표로 하며, 이는 사기 탐지, 네트워크 보안 및 산업 품질 관리에 널리 사용된다. 그러나 기존 방법은 다양한 국소 밀도를 가진 데이터셋에서 어려움을 겪고 있다.

Method: SVEAD는 랜덤 보로노이 다이어그램의 앙상블을 구축하고 국소 스케일에 따라 가중치가 부여된 정규화된 셀 상대 거리로 점수를 매긴다.

Result: 제안된 방법은 선형 시간 복잡도와 상수 공간 복잡도를 달성하며, 45개 데이터셋에서 12가지 최첨단 방법과 비교하여 뛰어난 성능을 입증한다.

Conclusion: SVEAD는 국소 밀도가 다양한 데이터셋에서 이상 탐지의 새로운 가능성을 제공한다.

Abstract: Anomaly detection aims to identify data instances that deviate significantly from majority of data, which has been widely used in fraud detection, network security, and industrial quality control. Existing methods struggle with datasets exhibiting varying local densities: distance-based methods miss local anomalies, while density-based approaches require careful parameter selection and incur quadratic time complexity. We observe that local anomalies, though indistinguishable under global analysis, become conspicuous when the data space is decomposed into restricted regions and each region is examined independently. Leveraging this geometric insight, we propose SVEAD (Stochastic Voronoi Ensembles Anomaly Detector), which constructs ensemble random Voronoi diagrams and scores points by normalized cell-relative distances weighted by local scale. The proposed method achieves linear time complexity and constant space complexity. Experiments on 45 datasets demonstrate that SVEAD outperforms 12 state-of-the-art approaches.

</details>


### [30] [Rethinking Recurrent Neural Networks for Time Series Forecasting: A Reinforced Recurrent Encoder with Prediction-Oriented Proximal Policy Optimization](https://arxiv.org/abs/2601.03683)
*Xin Lai,Shiming Deng,Lu Yu,Yumin Lai,Shenghao Qiao,Xinze Zhang*

Main category: cs.LG

TL;DR: 본 연구에서는 시간 시계열 예측의 성능을 개선하기 위해 새로운 강화 반복 인코더를 소개하며, 이 방식은 RNN 모델의 정확도를 높인다.


<details>
  <summary>Details</summary>
Motivation: 시계열 예측은 의사결정을 지원하기 위해 현대 엔지니어링 정보 시스템에서 중요한 역할을 하며, RNN은 순차적 데이터 모델링에 효과적이다.

Method: RRE-PPO4Pred라는 새로운 강화 반복 인코더를 제안하여 RNN의 내부 적응을 마르코프 결정 프로세스로 공식화하고, 예측 지향 근접 정책 최적화 알고리즘을 개선하여 샘플링 효율성을 높인다.

Result: 다섯 개의 실제 데이터셋에 대한 종합 평가에서, 본 방법은 기존 기준을 지속적으로 초과하며 최신 Transformer 모델보다 더 나은 정확도를 달성한다.

Conclusion: 따라서 본 연구는 엔지니어링 정보학에서 고급 시계열 예측기를 제공한다.

Abstract: Time series forecasting plays a crucial role in contemporary engineering information systems for supporting decision-making across various industries, where Recurrent Neural Networks (RNNs) have been widely adopted due to their capability in modeling sequential data. Conventional RNN-based predictors adopt an encoder-only strategy with sliding historical windows as inputs to forecast future values. However, this approach treats all time steps and hidden states equally without considering their distinct contributions to forecasting, leading to suboptimal performance. To address this limitation, we propose a novel Reinforced Recurrent Encoder with Prediction-oriented Proximal Policy Optimization, RRE-PPO4Pred, which significantly improves time series modeling capacity and forecasting accuracy of the RNN models. The core innovations of this method are: (1) A novel Reinforced Recurrent Encoder (RRE) framework that enhances RNNs by formulating their internal adaptation as a Markov Decision Process, creating a unified decision environment capable of learning input feature selection, hidden skip connection, and output target selection; (2) An improved Prediction-oriented Proximal Policy Optimization algorithm, termed PPO4Pred, which is equipped with a Transformer-based agent for temporal reasoning and develops a dynamic transition sampling strategy to enhance sampling efficiency; (3) A co-evolutionary optimization paradigm to facilitate the learning of the RNN predictor and the policy agent, providing adaptive and interactive time series modeling. Comprehensive evaluations on five real-world datasets indicate that our method consistently outperforms existing baselines, and attains accuracy better than state-of-the-art Transformer models, thus providing an advanced time series predictor in engineering informatics.

</details>


### [31] [R$^3$L: Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification](https://arxiv.org/abs/2601.03715)
*Weijie Shi,Yanxi Chen,Zexi Li,Xuchen Pan,Yuchang Sun,Jiajie Xu,Xiaofang Zhou,Yaliang Li*

Main category: cs.LG

TL;DR: R$^3$L은 언어 안내 탐색, 중추 신용, 긍정적 증폭을 이용한 반사 후 재시도 강화 학습으로, 이를 통해 어려운 작업에서의 탐색 및 활용 문제를 해결하고 훈련 안정성을 유지하며 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습은 LLM의 추론 및 에이전트 능력의 최근 발전을 이끌고 있지만, 기존 접근 방식은 탐색과 활용에서 어려움을 겪고 있습니다.

Method: R$^3$L은 스토캐스틱 샘플링에서 고급 합성으로 전환하여 언어 피드백을 활용하여 오류를 진단하고 실패한 시도를 성공으로 변환합니다.

Result: 에이전틱 및 추론 작업에 대한 실험 결과는 기초 모델 대비 5\%에서 52\%의 상대적 향상을 나타냈습니다.

Conclusion: R$^3$L은 강화 학습에서 탐색과 활용의 한계를 극복하며, 훈련 안정성을 유지하는 동시에 성능을 개선하는 효과적인 접근 방식을 제공합니다.

Abstract: Reinforcement learning drives recent advances in LLM reasoning and agentic capabilities, yet current approaches struggle with both exploration and exploitation. Exploration suffers from low success rates on difficult tasks and high costs of repeated rollouts from scratch. Exploitation suffers from coarse credit assignment and training instability: Trajectory-level rewards penalize valid prefixes for later errors, and failure-dominated groups overwhelm the few positive signals, leaving optimization without constructive direction. To this end, we propose R$^3$L, Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification. To synthesize high-quality trajectories, R$^3$L shifts from stochastic sampling to active synthesis via reflect-then-retry, leveraging language feedback to diagnose errors, transform failed attempts into successful ones, and reduce rollout costs by restarting from identified failure points. With errors diagnosed and localized, Pivotal Credit Assignment updates only the diverging suffix where contrastive signals exist, excluding the shared prefix from gradient update. Since failures dominate on difficult tasks and reflect-then-retry produces off-policy data, risking training instability, Positive Amplification upweights successful trajectories to ensure positive signals guide the optimization process. Experiments on agentic and reasoning tasks demonstrate 5\% to 52\% relative improvements over baselines while maintaining training stability. Our code is released at https://github.com/shiweijiezero/R3L.

</details>


### [32] [Prompt Tuning without Labeled Samples for Zero-Shot Node Classification in Text-Attributed Graphs](https://arxiv.org/abs/2601.03793)
*Sethupathy Parameswaran,Suresh Sundaram,Yuan Fang*

Main category: cs.LG

TL;DR: 이 논문에서는 레이블이 없는 데이터를 사용하는 텍스트 속성 그래프에서 제로샷 노드 분류 문제를 해결하기 위해 새로운 제로샷 프롬프트 튜닝(ZPT) 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 노드 분류는 정보 검색의 기본 문제로, 사회 네트워크의 커뮤니티 탐지, 온라인에 게시된 기사 그룹화 및 전자상거래에서의 제품 분류와 같은 실제 응용 프로그램들이 있다. 제로샷 노드 분류는 레이블이 없는 데이터로 인해 상당한 도전 과제를 제공한다.

Method: 우리는 유니버설 바이모달 조건 생성기(UBCG)를 활용하여 그래프-언어 모델을 사전 훈련하고, 조건부 생성 모델을 통해 클래스를 기반으로 합성 샘플을 생성하는 방식을 사용한다.

Result: 광범위한 벤치마크 데이터셋에 대한 실험 결과, 우리의 프레임워크가 기존의 최첨단 기준보다 우수한 성능을 발휘함을 증명하였다.

Conclusion: 우리는 바이모달 생성기의 기여를 검증하기 위해 제거 연구를 제공하며, 코드는 https://github.com/Sethup123/ZPT에서 제공된다.

Abstract: Node classification is a fundamental problem in information retrieval with many real-world applications, such as community detection in social networks, grouping articles published online and product categorization in e-commerce. Zero-shot node classification in text-attributed graphs (TAGs) presents a significant challenge, particularly due to the absence of labeled data. In this paper, we propose a novel Zero-shot Prompt Tuning (ZPT) framework to address this problem by leveraging a Universal Bimodal Conditional Generator (UBCG). Our approach begins with pre-training a graph-language model to capture both the graph structure and the associated textual descriptions of each node. Following this, a conditional generative model is trained to learn the joint distribution of nodes in both graph and text modalities, enabling the generation of synthetic samples for each class based solely on the class name. These synthetic node and text embeddings are subsequently used to perform continuous prompt tuning, facilitating effective node classification in a zero-shot setting. Furthermore, we conduct extensive experiments on multiple benchmark datasets, demonstrating that our framework performs better than existing state-of-the-art baselines. We also provide ablation studies to validate the contribution of the bimodal generator. The code is provided at: https://github.com/Sethup123/ZPT.

</details>


### [33] [Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences](https://arxiv.org/abs/2601.03882)
*Shudong Liu,Hanwen Zhang,Xiuling Wang,Yuesheng Zhu,Guibo Luo*

Main category: cs.LG

TL;DR: FALCON은 비IID 이미지를 위한 OSFL의 효율성을 높이는 프레임워크로, 다양한 비IID 시나리오에서 성능이 향상됨을 보여준다.


<details>
  <summary>Details</summary>
Motivation: OSFL은 단일 통신 주기로 글로벌 모델을 구성하여 반복적인 연합 학습의 통신 비용과 개인정보 보호 위험을 줄여주지만, 비IID 데이터를 처리하는 데 어려움이 있다.

Method: FALCON은 계층적 토큰 시퀀스 생성 및 지식 증류를 OSFL에 통합하여 비IID 이미지 데이터에 대한 효과를 높인다.

Result: FALCON은 다양한 비IID 상황에서 9.58%의 평균 정확도로 기존 OSFL 기준을 초과하는 성능을 보여준다.

Conclusion: FALCON은 의료 및 자연 이미지 데이터 세트에서 비IID 데이터 처리에 있어 효과성을 입증하였다.

Abstract: One-shot federated learning (OSFL) reduces the communication cost and privacy risks of iterative federated learning by constructing a global model with a single round of communication. However, most existing methods struggle to achieve robust performance on real-world domains such as medical imaging, or are inefficient when handling non-IID (Independent and Identically Distributed) data. To address these limitations, we introduce FALCON, a framework that enhances the effectiveness of OSFL over non-IID image data. The core idea of FALCON is to leverage the feature-aware hierarchical token sequences generation and knowledge distillation into OSFL. First, each client leverages a pretrained visual encoder with hierarchical scale encoding to compress images into hierarchical token sequences, which capture multi-scale semantics. Second, a multi-scale autoregressive transformer generator is used to model the distribution of these token sequences and generate the synthetic sequences. Third, clients upload the synthetic sequences along with the local classifier trained on the real token sequences to the server. Finally, the server incorporates knowledge distillation into global training to reduce reliance on precise distribution modeling. Experiments on medical and natural image datasets validate the effectiveness of FALCON in diverse non-IID scenarios, outperforming the best OSFL baselines by 9.58% in average accuracy.

</details>


### [34] [Using Legacy Polysomnography Data to Train a Radar System to Quantify Sleep in Older Adults and People living with Dementia](https://arxiv.org/abs/2601.04057)
*M. Yin,K. G. Ravindran,C. Hadjipanayi,A. Bannon,A. Rapeaux,C. Della Monica,T. S. Lande,Derk-Jan Dijk,T. G. Constandinou*

Main category: cs.LG

TL;DR: 이 연구는 레이더 데이터를 활용하여 수면 단계 분류를 향상시키기 위한 새로운 심층 전이 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 내부 수면 모니터링을 위한 비침습적이고 비용 효율적인 솔루션을 제공하기 위해서는 레이더 수면 데이터의 가용성이 제한적입니다.

Method: 야간 호흡 및 동작 신호를 기반으로 수면 단계를 분류하는 엔드 투 엔드 신경망을 개발했습니다. 이 신경망은 대규모 수면 다원 검사(PSG) 데이터셋과 레이더 데이터를 결합하여 훈련되었습니다.

Result: 제안된 네트워크 구조는 각성, REM 수면, 얕은 수면 및 깊은 수면을 분류할 때 79.5%의 정확도와 0.65의 카파 값을 달성했습니다. 실험 결과, 심층 전이 학습 접근법이 목표 도메인에서 자동 수면 단계 성능을 크게 향상시킴을 확인했습니다.

Conclusion: 이 방법은 데이터 변동성과 제한된 샘플 크기와 관련된 문제를 효과적으로 해결하여 자동 수면 단계 모델의 신뢰성을 상당히 향상시킵니다.

Abstract: Objective: Ultra-wideband radar technology offers a promising solution for unobtrusive and cost-effective in-home sleep monitoring. However, the limited availability of radar sleep data poses challenges in building robust models that generalize across diverse cohorts and environments. This study proposes a novel deep transfer learning framework to enhance sleep stage classification using radar data. Methods: An end-to-end neural network was developed to classify sleep stages based on nocturnal respiratory and motion signals. The network was trained using a combination of large-scale polysomnography (PSG) datasets and radar data. A domain adaptation approach employing adversarial learning was utilized to bridge the knowledge gap between PSG and radar signals. Validation was performed on a radar dataset of 47 older adults (mean age: 71.2), including 18 participants with prodromal or mild Alzheimer disease. Results: The proposed network structure achieves an accuracy of 79.5% with a Kappa value of 0.65 when classifying wakefulness, rapid eye movement, light sleep and deep sleep. Experimental results confirm that our deep transfer learning approach significantly enhances automatic sleep staging performance in the target domain. Conclusion: This method effectively addresses challenges associated with data variability and limited sample size, substantially improving the reliability of automatic sleep staging models, especially in contexts where radar data is limited. Significance: The findings underscore the viability of UWB radar as a nonintrusive, forward-looking sleep assessment tool that could significantly benefit care for older people and people with neurodegenerative disorders.

</details>


### [35] [MORPHFED: Federated Learning for Cross-institutional Blood Morphology Analysis](https://arxiv.org/abs/2601.04121)
*Gabriel Ansah,Eden Ruffell,Delmiro Fernandez-Reyes,Petru Manescu*

Main category: cs.LG

TL;DR: 이 논문은 자율 혈액 형태 분석을 위한 연합 학습 프레임워크를 도입하고, 이는 데이터 공유 없이 기관간 협업 훈련을 가능하게 하여 의료 영상 AI 개발에 기여함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 낮은 및 중위 소득 국가에서 혈액 형태 분석은 혈액학 진단을 지원하나 데이터 세트의 변화에 민감하며 이를 해결하기 위한 접근이 필요하다.

Method: 여러 임상 사이트의 혈액 슬라이드를 사용하여, 연합 모델이 강력하고 영역 불변의 표현을 학습하도록 하며 데이터 프라이버시를 유지한다.

Result: 연합 학습을 통해 중앙 집중식 훈련과 비교하여 강력한 교차 사이트 성능과 보지 못한 기관에 대한 일반화를 개선한다.

Conclusion: 자원 제한 의료 환경에서 공정하고 확장 가능하며 일반화 가능한 의료 영상 AI 개발을 위한 실용적이고 개인정보 보호 방법으로서 연합 학습의 가능성을 강조한다.

Abstract: Automated blood morphology analysis can support hematological diagnostics in low- and middle-income countries (LMICs) but remains sensitive to dataset shifts from staining variability, imaging differences, and rare morphologies. Building centralized datasets to capture this diversity is often infeasible due to privacy regulations and data-sharing restrictions. We introduce a federated learning framework for white blood cell morphology analysis that enables collaborative training across institutions without exchanging training data. Using blood films from multiple clinical sites, our federated models learn robust, domain-invariant representations while preserving complete data privacy. Evaluations across convolutional and transformer-based architectures show that federated training achieves strong cross-site performance and improved generalization to unseen institutions compared to centralized training. These findings highlight federated learning as a practical and privacy-preserving approach for developing equitable, scalable, and generalizable medical imaging AI in resource-limited healthcare environments.

</details>


### [36] [Agentic Rubrics as Contextual Verifiers for SWE Agents](https://arxiv.org/abs/2601.04171)
*Mohit Raghavendra,Anisha Gunjal,Bing Liu,Yunzhong He*

Main category: cs.LG

TL;DR: 이 논문은 소프트웨어 엔지니어링에서 에이전트의 검증을 개선하기 위한 방법인 Agentic Rubrics를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 엔지니어링 에이전트 설정에서 검증은 강화 학습을 위한 보상 신호를 제공하고, 테스트 시간에 이점을 제공하기 때문에 중요합니다. 그러나 검증 과정이 환경 설정으로 인해 확장하기 어려운 경우가 많습니다.

Method: Agentic Rubrics라는 방법을 활용하여 전문가 에이전트가 레포지토리와 상호작용하며 맥락에 기반한 체크리스트를 생성하고, 후보 패치를 실행 테스트 없이 평가합니다.

Result: Agentic Rubrics는 SWE-Bench의 Qwen3-Coder-30B-A3B에서 54.2%, Qwen3-32B에서 40.6%의 점수를 얻어 비교 세트에서 가장 강력한 기준선보다 최소 +3.5%의 향상을 보여줍니다.

Conclusion: 이 연구는 Agentic Rubrics가 소프트웨어 엔지니어링 에이전트를 위한 효율적이고 확장 가능한 검증 신호를 제공함을 제안합니다.

Abstract: Verification is critical for improving agents: it provides the reward signal for Reinforcement Learning and enables inference-time gains through Test-Time Scaling (TTS). Despite its importance, verification in software engineering (SWE) agent settings often relies on code execution, which can be difficult to scale due to environment setup overhead. Scalable alternatives such as patch classifiers and heuristic methods exist, but they are less grounded in codebase context and harder to interpret. To this end, we explore Agentic Rubrics: an expert agent interacts with the repository to create a context-grounded rubric checklist, and candidate patches are then scored against it without requiring test execution. On SWE-Bench Verified under parallel TTS evaluation, Agentic Rubrics achieve a score of 54.2% on Qwen3-Coder-30B-A3B and 40.6% on Qwen3-32B, with at least a +3.5 percentage-point gain over the strongest baseline in our comparison set. We further analyze rubric behavior, showing that rubric scores are consistent with ground-truth tests while also flagging issues that tests do not capture. Our ablations show that agentic context gathering is essential for producing codebase-specific, unambiguous criteria. Together, these results suggest that Agentic Rubrics provide an efficient, scalable, and granular verification signal for SWE agents.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [37] [PC2P: Multi-Agent Path Finding via Personalized-Enhanced Communication and Crowd Perception](https://arxiv.org/abs/2601.03301)
*Guotao Li,Shaoyun Xu,Yuexing Hao,Yang Wang,Yuhui Sun*

Main category: cs.MA

TL;DR: PC2P는 분산 MAPF 방법으로, 동적 그래프 토폴로지를 활용한 개인화된 통신 메커니즘과 지역 군중 인식을 도입하여 다양한 환경에서 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 MAPF 및 MARL 방법은 다양한 환경 조건에서 확장성이 부족하다.

Method: PC2P는 Q-러닝 기반 MARL 프레임워크에서 파생된 분산 MAPF 방법으로, 동적 그래프 토폴로지에 기반한 개인화된 통신 메커니즘과 지역 군중 인식을 통합한다.

Result: PC2P는 다양한 환경에서 최신 분산 MAPF 방법에 비해 우수한 성능을 달성한다.

Conclusion: 실험 결과와 분리 연구를 통해 PC2P의 각 모듈의 효과가 입증된다.

Abstract: Distributed Multi-Agent Path Finding (MAPF) integrated with Multi-Agent Reinforcement Learning (MARL) has emerged as a prominent research focus, enabling real-time cooperative decision-making in partially observable environments through inter-agent communication. However, due to insufficient collaborative and perceptual capabilities, existing methods are inadequate for scaling across diverse environmental conditions. To address these challenges, we propose PC2P, a novel distributed MAPF method derived from a Q-learning-based MARL framework. Initially, we introduce a personalized-enhanced communication mechanism based on dynamic graph topology, which ascertains the core aspects of ``who" and ``what" in interactive process through three-stage operations: selection, generation, and aggregation. Concurrently, we incorporate local crowd perception to enrich agents' heuristic observation, thereby strengthening the model's guidance for effective actions via the integration of static spatial constraints and dynamic occupancy changes. To resolve extreme deadlock issues, we propose a region-based deadlock-breaking strategy that leverages expert guidance to implement efficient coordination within confined areas. Experimental results demonstrate that PC2P achieves superior performance compared to state-of-the-art distributed MAPF methods in varied environments. Ablation studies further confirm the effectiveness of each module for overall performance.

</details>


### [38] [LLM-Enabled Multi-Agent Systems: Empirical Evaluation and Insights into Emerging Design Patterns & Paradigms](https://arxiv.org/abs/2601.03328)
*Harri Renney,Maxim N Nethercott,Nathan Renney,Peter Hayes*

Main category: cs.MA

TL;DR: 이 논문은 LLM 기반의 다중 에이전트 시스템(MAS)을 위한 새로운 디자인 패턴과 패러다임을 정리하고, 다양한 분야에서의 실용성을 평가합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 다중 에이전트 시스템의 응용 가능성을 탐색하고, 기존 접근법의 한계를 극복하기 위한 방법론을 제공하기 위해.

Method: 에이전트 조율, 통신 메커니즘, 제어 흐름 전략 등 주요 아키텍처 구성 요소를 정의하고, 이를 통해 모듈식의 도메인 적응형 솔루션의 신속한 개발을 시연합니다.

Result: 세 가지 실제 사례 연구에서 최초의 프로토타입은 2주 이내에 제공되었고, 파일럿 준비가 완료된 솔루션은 1개월 이내에 개발되었습니다.

Conclusion: MAS 아키텍처의 신뢰성, 확장성 및 거버넌스를 개선하기 위한 주요 연구 방향을 제시하고, 고유한 과제를 완화하기 위해 MAS 디자인 패턴을 성숙시키기 위한 추가 연구가 필요하다고 결론지었습니다.

Abstract: This paper formalises the literature on emerging design patterns and paradigms for Large Language Model (LLM)-enabled multi-agent systems (MAS), evaluating their practical utility across various domains. We define key architectural components, including agent orchestration, communication mechanisms, and control-flow strategies, and demonstrate how these enable rapid development of modular, domain-adaptive solutions. Three real-world case studies are tested in controlled, containerised pilots in telecommunications security, national heritage asset management, and utilities customer service automation. Initial empirical results show that, for these case studies, prototypes were delivered within two weeks and pilot-ready solutions within one month, suggesting reduced development overhead compared to conventional approaches and improved user accessibility. However, findings also reinforce limitations documented in the literature, including variability in LLM behaviour that leads to challenges in transitioning from prototype to production maturity. We conclude by outlining critical research directions for improving reliability, scalability, and governance in MAS architectures and the further work needed to mature MAS design patterns to mitigate the inherent challenges.

</details>


### [39] [A Chromatographic Process Design and Optimization Platform Powered by Large Language Models: A Case Application on Extract of Ginkgo Biloba Leaf](https://arxiv.org/abs/2601.03702)
*Zhilong Tang,Shaohua Wu,Xinyan Zhao,Yu Wang,Xingchu Gong*

Main category: cs.MA

TL;DR: ChromR는 크로마토그래픽 공정 디자인 및 최적화를 위한 LLM 기반 플랫폼으로, 전문가 의존도를 줄이고 개발 시간을 크게 단축할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 크로마토그래픽 공정 개발의 한계로 인해 자동화된 효율적인 공정 개발의 필요성이 있다.

Method: ChromLLM이라는 도메인 특화 LLM과 다중 에이전트 시스템, 자동화된 크로마토그래픽 실험 장치를 통합한 플랫폼을 구축하였다.

Result: EGBL의 크로마토그래픽 정제가 사례 연구로 선정되었으며, 약 일주일 내에 여러 목표를 충족하는 공정을 성공적으로 개발하였다.

Conclusion: 크로마토그래픽 공정 개발을 위한 스마트하고 자동화된 새로운 패러다임이 확립되었다.

Abstract: Chromatographic separation technology has been widely applied in pharmaceutical, chemical, and food industries due to its high efficiency. However, traditional human-dependent chromatographic process development faces challenges such as reliance on expert experience, long development cycles, and labor intensity. ChromR, a large language model (LLM)-driven platform for chromatographic process design and optimization, is presented in this work. The platform integrates ChromLLM, a domain-specific LLM trained for chromatography, along with a multi-agent system and an automated chromatographic experimental device. The multi-agent system comprises four agents: domain knowledge answering, experimental design, experimental execution, and data analysis. ChromR enables automatic completion of the entire workflow-including initial process parameter recommendation, experimental design, automated execution, data analysis, and multi-objective optimization. By utilizing ChromR, dependency on expert knowledge is effectively reduced, while labor input and development time are significantly decreased. Chromatographic purification of the extract of Ginkgo biloba leaf (EGBL) was selected as a case study. ChromR successfully developed a chromatographic process within one week that meets multiple objectives, including fraction quality and production efficiency, reducing development time to approximately one-seventh of that required by the conventional paradigm. An intelligent, automated, and universally applicable new paradigm was established for chromatographic process development.

</details>


### [40] [When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents](https://arxiv.org/abs/2601.03846)
*Alessio Buscemi,Daniele Proverbio,Alessandro Di Stefano,The Anh Han,German Castignani,Pietro Liò*

Main category: cs.MA

TL;DR: LLM 기반 에이전트들이 다중 에이전트 환경에서 전략적 상호작용 및 조정이 필요로 하는 상황에서 작동함에 따라, 이 논문은 숨은 의사소통의 게임 이론적 연구를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 주로 개별 에이전트나 명시적 의사소통을 공유하는 상호작용 에이전트에 초점을 맞춰왔으나, 암묵적인 조정에 대한 이해는 부족하다.

Method: 다양한 의사소통 방식(명시적, 제한적, 부재)을 포함한 네 가지 전형적인 게임 이론적 설정에서 상호작용을 분석

Result: 다양한 에이전트 성격과 일회성 및 반복 게임을 고려하여 숨은 신호가 나타나는 시점과 이를 통해 조정 및 전략적 결과를 형성하는 방법을 특징짓는다.

Conclusion: 이 연구는 다중 에이전트 시스템에서의 숨은 의사소통 메커니즘에 대한 새로운 통찰을 제공하며, 전략적 상호작용의 복잡성을 이해하는 데 기여한다.

Abstract: LLMs-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit communication, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert communication, relying on indirect or non-linguistic signals embedded in their actions rather than on explicit messages. This paper presents a game-theoretic study of covert communication in LLM-driven multi-agent systems. We analyse interactions across four canonical game-theoretic settings under different communication regimes, including explicit, restricted, and absent communication. Considering heterogeneous agent personalities and both one-shot and repeated games, we characterise when covert signals emerge and how they shape coordination and strategic outcomes.

</details>
