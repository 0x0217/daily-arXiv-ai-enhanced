<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 25]
- [cs.MA](#cs.MA) [Total: 6]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.CR](#cs.CR) [Total: 15]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [JaxWildfire: A GPU-Accelerated Wildfire Simulator for Reinforcement Learning](https://arxiv.org/abs/2512.06102)
*Ufuk Çakır,Victor-Alexandru Darvariu,Bruno Lacerda,Nick Hawes*

Main category: cs.LG

TL;DR: 이 논문에서는 인공지능 기법을 활용한 산불 관리의 새로운 시뮬레이터인 JaxWildfire를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 산불 및 기타 자연 재해 관리를 위한 인공지능 기법의 필요성과 기존 시뮬레이터의 속도가 제한적이라는 문제점을 해결하고자 한다.

Method: JaxWildfire는 셀룰러 오토마타 기반의 확률적 화재 확산 모델을 통한 시뮬레이터로, JAX에서 구현되어 벡터화된 시뮬레이션을 지원한다.

Result: JaxWildfire는 기존 소프트웨어에 비해 6-35배의 속도 향상을 보여주고, 시뮬레이터 매개변수를 기반으로 한 최적화를 가능하게 한다.

Conclusion: 이 연구는 자연 재해 관리를 위한 RL 기법 발전의 중요한 단계로 평가된다.

Abstract: Artificial intelligence methods are increasingly being explored for managing wildfires and other natural hazards. In particular, reinforcement learning (RL) is a promising path towards improving outcomes in such uncertain decision-making scenarios and moving beyond reactive strategies. However, training RL agents requires many environment interactions, and the speed of existing wildfire simulators is a severely limiting factor. We introduce $\texttt{JaxWildfire}$, a simulator underpinned by a principled probabilistic fire spread model based on cellular automata. It is implemented in JAX and enables vectorized simulations using $\texttt{vmap}$, allowing high throughput of simulations on GPUs. We demonstrate that $\texttt{JaxWildfire}$ achieves 6-35x speedup over existing software and enables gradient-based optimization of simulator parameters. Furthermore, we show that $\texttt{JaxWildfire}$ can be used to train RL agents to learn wildfire suppression policies. Our work is an important step towards enabling the advancement of RL techniques for managing natural hazards.

</details>


### [2] [ARC-AGI Without Pretraining](https://arxiv.org/abs/2512.06104)
*Isaac Liao,Albert Gu*

Main category: cs.LG

TL;DR: CompressARC는 76K 파라미터로 구성된 비선행 학습 모델로, IQ 테스트 유사 시각 퍼즐을 20% 해결하며, MDL 방식으로 퍼즐 설명 길이를 최소화한다.


<details>
  <summary>Details</summary>
Motivation: LLM 시대에 IQ 테스트 유사 퍼즐을 해결하기 위해 대규모 선행 학습의 필요성을 반박하기 위해 이 연구를 수행하였다.

Method: CompressARC는 MDL 원리에 따라 단일 샘플에 대해 훈련을 진행하며, 최종 솔루션 정보는 제거한다.

Result: 20%의 평가 퍼즐을 해결하였고, 다양한 ARC-AGI 퍼즐을 해결하는 능력을 보여주었다.

Conclusion: CompressARC는 기존 선행 학습 외에 지능을 생성하는 대안적인 방법으로서 MDL을 제안한다.

Abstract: Conventional wisdom in the age of LLMs dictates that solving IQ-test-like visual puzzles from the ARC-AGI-1 benchmark requires capabilities derived from massive pretraining. To counter this, we introduce CompressARC, a 76K parameter model without any pretraining that solves 20% of evaluation puzzles by minimizing the description length (MDL) of the target puzzle purely during inference time. The MDL endows CompressARC with extreme generalization abilities typically unheard of in deep learning. To our knowledge, CompressARC is the only deep learning method for ARC-AGI where training happens only on a single sample: the target inference puzzle itself, with the final solution information removed. Moreover, CompressARC does not train on the pre-provided ARC-AGI "training set". Under these extremely data-limited conditions, we do not ordinarily expect any puzzles to be solvable at all. Yet CompressARC still solves a diverse distribution of creative ARC-AGI puzzles, suggesting MDL to be an alternative feasible way to produce intelligence, besides conventional pretraining.

</details>


### [3] [Physics-Informed Neural Koopman Machine for Interpretable Longitudinal Personalized Alzheimer's Disease Forecasting](https://arxiv.org/abs/2512.06134)
*Georgi Hrusanov,Duy-Thanh Vu,Duy-Cat Can,Sophie Tascedda,Margaret Ryan,Julien Bodelet,Katarzyna Koscielska,Carsten Magnus,Oliver Y. Chén*

Main category: cs.LG

TL;DR: 이 논문은 알츠하이머병의 개인적인 인지 감소를 예측하기 위해 다중 모드 데이터를 통합하는 새로운 기계 학습 아키텍처인 Neural Koopman Machine(NKM)을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병의 초기 인지 감소 예측은 질병 평가 및 관리에 중심적인 역할을 한다.

Method: NKM은 복잡한 비선형 경로를 해석 가능한 선형 표현으로 변환하는 계층적 주의 메커니즘을 통합하여 다중 정보(유전, 신경영상, 단백질체, 인구통계학)를 이용해 여러 인지 점수를 동시에 예측하는 새로운 기계 학습 구조이다.

Result: NKM은 알츠하이머 질병 신경영상 이니셔티브(ADNI) 데이터셋에 적용된 결과, 기존 기계 학습 및 딥러닝 모델보다 인지 감소 궤적 예측에서 뛰어난 성능을 보였다.

Conclusion: NKM은 알츠하이머병의 미래 인지 감소를 개인 맞춤형으로 예측할 수 있는 해석 가능한 시스템을 통해 과거의 다중 모드 데이터를 활용한다.

Abstract: Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($α$) and biological ($β$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression.

</details>


### [4] [gp2Scale: A Class of Compactly-Supported Non-Stationary Kernels and Distributed Computing for Exact Gaussian Processes on 10 Million Data Points](https://arxiv.org/abs/2512.06143)
*Marcus M. Noack,Mark D. Risser,Hengrui Luo,Vardaan Tekriwal,Ronald J. Pandolfi*

Main category: cs.LG

TL;DR: 정확한 가우시안 프로세스를 1000만 개 이상의 데이터 포인트에 확장할 수 있는 방법론인 gp2Scale을 제안하며, 이는 기존의 유도 점, 커널 보간 또는 이웃 기반 근사를 사용하지 않고 가우시안 프로세스의 커널 설계를 활용한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 방법들은 예측 및 불확실성 정량화의 정확성을 저하시키고 커널 및 노이즈 모델 설계의 유연성을 제한하는 다양한 근사를 활용하고 있다.

Method: gp2Scale이라는 방법론을 통해 정확한 가우시안 프로세스를 1000만 개 이상의 데이터 포인트로 확장하면서, 커널 설계를 활용하여 계산을 수행한다.

Result: 여러 실세계 데이터셋에서 우리의 방법의 기능성을 입증하고 최신 근사 알고리즘과 비교하였다.

Conclusion: 이 방법은 가우시안 프로세스의 핵심 커널 설계, 노이즈 및 평균 함수에 대한 아그노스티시즘을 지니고 있어 현대 가우시안 프로세스 응용 프로그램에 최적으로 적합하다.

Abstract: Despite a large corpus of recent work on scaling up Gaussian processes, a stubborn trade-off between computational speed, prediction and uncertainty quantification accuracy, and customizability persists. This is because the vast majority of existing methodologies exploit various levels of approximations that lower accuracy and limit the flexibility of kernel and noise-model designs -- an unacceptable drawback at a time when expressive non-stationary kernels are on the rise in many fields. Here, we propose a methodology we term \emph{gp2Scale} that scales exact Gaussian processes to more than 10 million data points without relying on inducing points, kernel interpolation, or neighborhood-based approximations, and instead leveraging the existing capabilities of a GP: its kernel design. Highly flexible, compactly supported, and non-stationary kernels lead to the identification of naturally occurring sparse structure in the covariance matrix, which is then exploited for the calculations of the linear system solution and the log-determinant for training. We demonstrate our method's functionality on several real-world datasets and compare it with state-of-the-art approximation algorithms. Although we show superior approximation performance in many cases, the method's real power lies in its agnosticism toward arbitrary GP customizations -- core kernel design, noise, and mean functions -- and the type of input space, making it optimally suited for modern Gaussian process applications.

</details>


### [5] [Quantifying Memory Use in Reinforcement Learning with Temporal Range](https://arxiv.org/abs/2512.06204)
*Rodney Lafuente-Mercado,Daniela Rus,T. Konstantin Rusch*

Main category: cs.LG

TL;DR: Temporal Range는 RL 정책의 과거 관찰 사용 정도를 측정하는 비모델 의존 메트릭이며, 여러 벡터 출력에 대한 1차 민감도를 기반으로 한다.


<details>
  <summary>Details</summary>
Motivation: 훈련된 강화학습 정책이 과거 관찰을 얼마나 활용하는지 이해하고자 하는 동기에서 출발했다.

Method: Temporal Range는 여러 입력 시퀀스에 대한 출력의 1차 민감도를 분석하는 모델 불문 메트릭으로, 최종 시점에서의 자코비안 블록의 역모드 자동 미분을 통해 계산된다.

Result: Temporal Range는 완전 관찰 제어에서 작고, Copy-k 작업에서의 지연과 비례하며, 최적 반환을 위한 최소 히스토리 윈도우와 일치한다.

Conclusion: Temporal Range는 메모리 의존성을 비교하고, 최적의 맥락을 선택하기 위한 실용적인 방법을 제공한다.

Abstract: How much does a trained RL policy actually use its past observations? We propose \emph{Temporal Range}, a model-agnostic metric that treats first-order sensitivities of multiple vector outputs across a temporal window to the input sequence as a temporal influence profile and summarizes it by the magnitude-weighted average lag. Temporal Range is computed via reverse-mode automatic differentiation from the Jacobian blocks $\partial y_s/\partial x_t\in\mathbb{R}^{c\times d}$ averaged over final timesteps $s\in\{t+1,\dots,T\}$ and is well-characterized in the linear setting by a small set of natural axioms. Across diagnostic and control tasks (POPGym; flicker/occlusion; Copy-$k$) and architectures (MLPs, RNNs, SSMs), Temporal Range (i) remains small in fully observed control, (ii) scales with the task's ground-truth lag in Copy-$k$, and (iii) aligns with the minimum history window required for near-optimal return as confirmed by window ablations. We also report Temporal Range for a compact Long Expressive Memory (LEM) policy trained on the task, using it as a proxy readout of task-level memory. Our axiomatic treatment draws on recent work on range measures, specialized here to temporal lag and extended to vector-valued outputs in the RL setting. Temporal Range thus offers a practical per-sequence readout of memory dependence for comparing agents and environments and for selecting the shortest sufficient context.

</details>


### [6] [Learning When to Switch: Adaptive Policy Selection via Reinforcement Learning](https://arxiv.org/abs/2512.06250)
*Chris Tava*

Main category: cs.LG

TL;DR: 이 연구는 복잡한 작업을 해결하기 위해 자율 에이전트가 전략 전환을 학습하는 강화 학습 기법을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 자율 에이전트는 복잡한 작업을 해결하기 위해 여러 전략을 필요로 하지만, 전략 전환 시점을 결정하는 것은 여전히 도전적이다.

Method: 이 연구는 두 가지 직교 내비게이션 정책 간의 전환 임계값을 학습하기 위한 강화 학습 기법을 도입하여 미로 내비게이션을 사례 연구로 사용한다.

Result: 240개의 테스트 구성에서 적응형 임계값 학습이 단일 전략 에이전트와 고정된 40% 임계값 기준을 초월했음을 입증했다.

Conclusion: 적응형 정책 선택의 가치가 고정된 휴리스틱에 비해 비례하여 증가함을 보여준다.

Abstract: Autonomous agents often require multiple strategies to solve complex tasks, but determining when to switch between strategies remains challenging. This research introduces a reinforcement learning technique to learn switching thresholds between two orthogonal navigation policies. Using maze navigation as a case study, this work demonstrates how an agent can dynamically transition between systematic exploration (coverage) and goal-directed pathfinding (convergence) to improve task performance. Unlike fixed-threshold approaches, the agent uses Q-learning to adapt switching behavior based on coverage percentage and distance to goal, requiring only minimal domain knowledge: maze dimensions and target location. The agent does not require prior knowledge of wall positions, optimal threshold values, or hand-crafted heuristics; instead, it discovers effective switching strategies dynamically during each run. The agent discretizes its state space into coverage and distance buckets, then adapts which coverage threshold (20-60\%) to apply based on observed progress signals. Experiments across 240 test configurations (4 maze sizes from 16$\times$16 to 128$\times$128 $\times$ 10 unique mazes $\times$ 6 agent variants) demonstrate that adaptive threshold learning outperforms both single-strategy agents and fixed 40\% threshold baselines. Results show 23-55\% improvements in completion time, 83\% reduction in runtime variance, and 71\% improvement in worst-case scenarios. The learned switching behavior generalizes within each size class to unseen wall configurations. Performance gains scale with problem complexity: 23\% improvement for 16$\times$16 mazes, 34\% for 32$\times$32, and 55\% for 64$\times$64, demonstrating that as the space of possible maze structures grows, the value of adaptive policy selection over fixed heuristics increases proportionally.

</details>


### [7] [Learning Without Time-Based Embodiment Resets in Soft-Actor Critic](https://arxiv.org/abs/2512.06252)
*Homayoon Farrahi,A. Rupam Mahmood*

Main category: cs.LG

TL;DR: 이 연구는 에피소드 종료와 로봇 신체 리셋 없이 학습하는 도전과제를 Soft Actor-Critic (SAC) 알고리즘을 사용하여 탐구하며, 신체 리셋이 없는 환경에서도 성능을 발휘할 수 있는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 새로운 강화 학습 작업을 생성할 때 수행자들은 종종 환경 상호작용을 독립적인 에피소드로 나누고 환경을 자주 리셋함으로써 학습 과정을 가속화합니다. 그러나 이러한 작업 보조 도구는 비자연적인 작업 설정으로 이어지고 실제 세계에서 장기 성능을 저해할 수 있습니다.

Method: 에피소드 종료 없이 학습하기 위해 기존의 SAC 알고리즘의 연속 버전을 제시하고, 기존 작업의 보상 함수를 간단히 수정하면 연속 SAC가 에피소드 SAC와 동일하거나 더 나은 성능을 발휘할 수 있음을 증명합니다.

Result: 수정된 Gym Reacher 작업에서 신체 리셋 없이 학습할 때 연속 SAC의 실패에 대한 가능한 설명을 조사합니다. 그 결과는 신체 리셋이 SAC 알고리즘의 상태 공간 탐색에 도움을 주며, 이를 제거하면 상태 공간 탐색이 저조해지고 학습이 실패하거나 현저히 느려질 수 있음을 시사합니다.

Conclusion: 추가적인 시뮬레이션 작업과 실제 로봇 비전 작업에서 성능이 악화되거나 정체될 때 정책의 엔트로피를 증가시키는 것이 신체 리셋 미사용으로 인해 잃어버린 성능을 회복하는 효과적인 개입 방법임을 보여줍니다.

Abstract: When creating new reinforcement learning tasks, practitioners often accelerate the learning process by incorporating into the task several accessory components, such as breaking the environment interaction into independent episodes and frequently resetting the environment. Although they can enable the learning of complex intelligent behaviors, such task accessories can result in unnatural task setups and hinder long-term performance in the real world. In this work, we explore the challenges of learning without episode terminations and robot embodiment resets using the Soft Actor-Critic (SAC) algorithm. To learn without terminations, we present a continuing version of the SAC algorithm and show that, with simple modifications to the reward functions of existing tasks, continuing SAC can perform as well as or better than episodic SAC while reducing the sensitivity of performance to the value of the discount rate $γ$. On a modified Gym Reacher task, we investigate possible explanations for the failure of continuing SAC when learning without embodiment resets. Our results suggest that embodiment resets help with exploration of the state space in the SAC algorithm, and removing embodiment resets can lead to poor exploration of the state space and failure of or significantly slower learning. Finally, on additional simulated tasks and a real-robot vision task, we show that increasing the entropy of the policy when performance trends worse or remains static is an effective intervention for recovering the performance lost due to not using embodiment resets.

</details>


### [8] [Networked Restless Multi-Arm Bandits with Reinforcement Learning](https://arxiv.org/abs/2512.06274)
*Hanmo Zhang,Zenghui Sun,Kai Wang*

Main category: cs.LG

TL;DR: 본 논문에서는 네트워크 환경에서 상호작용을 포착하기 위한 새롭고 강력한 RMAB 모델, 즉 네트워크 RMAB를 도입하고, 이를 통해 자원 할당 및 개입 최적화 문제를 개선하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 RMAB는 독립성을 가정하지만 현실 세계의 상호작용을 반영하지 않아 한계가 있습니다.

Method: 네트워크 RMAB 모델과 독립적 캐스케이드 모델을 결합하여 Bellman 방정식을 정의하고, 계산적 도전에 대응하기 위해 서브모듈러리티를 활용하고 힐 클리밍 알고리즘을 적용합니다.

Result: Q-learning 알고리즘을 개발하여 실험적으로 검증하였고, 실제 그래프 데이터에서 $k$-step look-ahead 및 네트워크 블라인드 접근 방식을 초월하는 성능을 보였습니다.

Conclusion: 네트워크 효과를 포착하고 활용하는 것이 중요하다는 점을 강조합니다.

Abstract: Restless Multi-Armed Bandits (RMABs) are a powerful framework for sequential decision-making, widely applied in resource allocation and intervention optimization challenges in public health. However, traditional RMABs assume independence among arms, limiting their ability to account for interactions between individuals that can be common and significant in a real-world environment. This paper introduces Networked RMAB, a novel framework that integrates the RMAB model with the independent cascade model to capture interactions between arms in networked environments. We define the Bellman equation for networked RMAB and present its computational challenge due to exponentially large action and state spaces. To resolve the computational challenge, we establish the submodularity of Bellman equation and apply the hill-climbing algorithm to achieve a $1-\frac{1}{e}$ approximation guarantee in Bellman updates. Lastly, we prove that the approximate Bellman updates are guaranteed to converge by a modified contraction analysis. We experimentally verify these results by developing an efficient Q-learning algorithm tailored to the networked setting. Experimental results on real-world graph data demonstrate that our Q-learning approach outperforms both $k$-step look-ahead and network-blind approaches, highlighting the importance of capturing and leveraging network effects where they exist.

</details>


### [9] [Multimodal Graph Neural Networks for Prognostic Modeling of Brain Network Reorganization](https://arxiv.org/abs/2512.06303)
*Preksha Girish,Rachana Mysore,Kiran K. N.,Hiranmayee R.,Shipra Prashanth,Shrey Kumar*

Main category: cs.LG

TL;DR: 이 연구는 다중모드 그래프 신경망 프레임워크를 제안하여 뇌 네트워크의 시공간 재구성을 모델링함으로써 인지 저하 예측을 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: 뇌 네트워크의 동적 재구성을 이해하는 것은 인지 저하 및 임상 결과의 개인 변동성을 예측하는 데 중요합니다.

Method: 구조적 MRI, 확산 텐서 이미징, 기능적 MRI를 통합한 다중모드 그래프 신경망 프레임워크를 제안하여 뇌 재구성을 모델링합니다.

Result: 신경영상 데이터셋에 대한 실험을 통해 예측 정확도와 해석 가능성이 입증되었습니다.

Conclusion: 이 연구는 기존 이미징 데이터에서 임상적으로 의미 있는 바이오마커를 도출하기 위한 수학적으로 엄밀한 다중모드 그래프 기반 접근법의 잠재력을 강조합니다.

Abstract: Understanding the dynamic reorganization of brain networks is critical for predicting cognitive decline, neurological progression, and individual variability in clinical outcomes. This work proposes a multimodal graph neural network framework that integrates structural MRI, diffusion tensor imaging, and functional MRI to model spatiotemporal brain network reorganization. Brain regions are represented as nodes and structural and functional connectivity as edges, forming longitudinal brain graphs for each subject. Temporal evolution is captured via fractional stochastic differential operators embedded within graph-based recurrent networks, enabling the modeling of long-term dependencies and stochastic fluctuations in network dynamics. Attention mechanisms fuse multimodal information and generate interpretable biomarkers, including network energy entropy, graph curvature, fractional memory indices, and modality-specific attention scores. These biomarkers are combined into a composite prognostic index to quantify individual risk of network instability or cognitive decline. Experiments on longitudinal neuroimaging datasets demonstrate both predictive accuracy and interpretability. The results highlight the potential of mathematically rigorous, multimodal graph-based approaches for deriving clinically meaningful biomarkers from existing imaging data without requiring new data collection.

</details>


### [10] [Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control](https://arxiv.org/abs/2512.06471)
*Nathan P. Lawrence,Ali Mesbah*

Main category: cs.LG

TL;DR: 목표 조건 강화 학습의 최적 제어 분석 및 고전적 보상과의 최적성 차이 논의.


<details>
  <summary>Details</summary>
Motivation: 목표 조건 강화 학습이 목표 상태에 도달할 확률을 극대화하는 에이전트를 훈련하는 문제를 다룬다.

Method: 고전적인 목표와 목표 조건 보상 간의 최적성 차이를 도출하고, 부분 관찰 마르코프 의사결정 설정을 고려하여 상태 추정과 확률적 보상을 연결한다.

Result: 비선형 및 불확실한 환경에서 목표 조건 정책의 장점을 확인하였다.

Conclusion: 목표 조건 보상이 쌍방향 제어 문제에 잘 맞추어진다는 것을 보여준다.

Abstract: Goal-conditioned reinforcement learning (RL) concerns the problem of training an agent to maximize the probability of reaching target goal states. This paper presents an analysis of the goal-conditioned setting based on optimal control. In particular, we derive an optimality gap between more classical, often quadratic, objectives and the goal-conditioned reward, elucidating the success of goal-conditioned RL and why classical ``dense'' rewards can falter. We then consider the partially observed Markov decision setting and connect state estimation to our probabilistic reward, further making the goal-conditioned reward well suited to dual control problems. The advantages of goal-conditioned policies are validated on nonlinear and uncertain environments using both RL and predictive control techniques.

</details>


### [11] [Neural Factorization-based Bearing Fault Diagnosis](https://arxiv.org/abs/2512.06837)
*Zhenhao Li,Xu Cheng,Yi Zhou*

Main category: cs.LG

TL;DR: 이 논문은 고속 열차의 베어링 결함 진단을 연구하며, 진단 정확도를 높이기 위해 새로운 신경 인수 기반 분류(NFC) 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 고속 열차의 베어링은 안전한 운행에 기여하며 전통적인 진단 방법은 복잡한 조건에서의 정확도가 부족하다.

Method: NFC 프레임워크는 진동 시간 시퀀스를 여러 모드의 잠재 특성 벡터로 임베딩하고, 신경 인수 원리를 활용하여 이 벡터를 통합한다.

Result: CP-NFC 및 Tucker-NFC 모델이 제안되어 전통적인 기계 학습 방법보다 우수한 진단 성능을 달성한다.

Conclusion: 이 분석 결과는 고속열차 베어링 모니터링에서 효과적인 진단 전략 선택에 대한 실질적인 가이드를 제공한다.

Abstract: This paper studies the key problems of bearing fault diagnosis of high-speed train. As the core component of the train operation system, the health of bearings is directly related to the safety of train operation. The traditional diagnostic methods are facing the challenge of insufficient diagnostic accuracy under complex conditions. To solve these problems, we propose a novel Neural Factorization-based Classification (NFC) framework for bearing fault diagnosis. It is built on two core idea: 1) Embedding vibration time series into multiple mode-wise latent feature vectors to capture diverse fault-related patterns; 2) Leveraging neural factorization principles to fuse these vectors into a unified vibration representation. This design enables effective mining of complex latent fault characteristics from raw time-series data. We further instantiate the framework with two models CP-NFC and Tucker-NFC based on CP and Tucker fusion schemes, respectively. Experimental results show that both models achieve superior diagnostic performance compared with traditional machine learning methods. The comparative analysis provides valuable empirical evidence and practical guidance for selecting effective diagnostic strategies in high-speed train bearing monitoring.

</details>


### [12] [Know your Trajectory -- Trustworthy Reinforcement Learning deployment through Importance-Based Trajectory Analysis](https://arxiv.org/abs/2512.06917)
*Clifford F,Devika Jay,Abhishek Sarkar,Satheesh K Perepu,Santhosh G S,Kaushik Dey,Balaraman Ravindran*

Main category: cs.LG

TL;DR: 강화 학습 에이전트의 행동을 설명 가능하고 신뢰할 수 있도록 하는 것이 중요하다. 본 논문은 에이전트의 장기적인 행동을 궤적 수준에서 분석하여 설명하는 새로운 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 에이전트의 투명하고 신뢰할 수 있는 행동 보장이 중대하다.

Method: 새로운 상태 중요성 메트릭을 정의하고 집계하여 전체 궤적을 평가하는 프레임워크를 제시한다.

Result: 이 방법은 이질적인 에이전트 경험 모음에서 최적 궤적을 성공적으로 식별한다.

Conclusion: 제안된 중요성 메트릭은 기존 접근 방식보다 최적의 행동을 식별하는 데 더 효과적임을 보여준다.

Abstract: As Reinforcement Learning (RL) agents are increasingly deployed in real-world applications, ensuring their behavior is transparent and trustworthy is paramount. A key component of trust is explainability, yet much of the work in Explainable RL (XRL) focuses on local, single-step decisions. This paper addresses the critical need for explaining an agent's long-term behavior through trajectory-level analysis. We introduce a novel framework that ranks entire trajectories by defining and aggregating a new state-importance metric. This metric combines the classic Q-value difference with a "radical term" that captures the agent's affinity to reach its goal, providing a more nuanced measure of state criticality. We demonstrate that our method successfully identifies optimal trajectories from a heterogeneous collection of agent experiences. Furthermore, by generating counterfactual rollouts from critical states within these trajectories, we show that the agent's chosen path is robustly superior to alternatives, thereby providing a powerful "Why this, and not that?" explanation. Our experiments in standard OpenAI Gym environments validate that our proposed importance metric is more effective at identifying optimal behaviors compared to classic approaches, offering a significant step towards trustworthy autonomous systems.

</details>


### [13] [LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding](https://arxiv.org/abs/2512.06982)
*Yu Yu,Qian Xie,Nairen Cao,Li Jin*

Main category: cs.LG

TL;DR: 본 연구는 다중 정보 출처를 위한 강화 학습(state encoder) 설계의 도전 과제를 다루며, LLM 기반의 신경망 아키텍처 검색(NAS) 파이프라인을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 정보 출처에서의 강화 학습을 위한 상태 인코더 설계는 아직 탐구되지 않았으며, 종종 수작업 설계가 필요합니다.

Method: 본 논문에서는 여러 출처에 특화된 모듈과 융합 모듈을 공동 최적화하는 복합 신경 아키텍처 검색(NAS) 문제로 형식화했습니다. 기존의 NAS 방법들은 이러한 모듈의 중간 출력에서 유용한 부가정보를 간과하여 샘플 효율성을 제한합니다.

Result: 혼합 자율 교통 제어 작업에서, 우리 방법은 전통적인 NAS 기준선 및 LLM 기반 GENIUS 프레임워크보다 적은 후보 평가로 더 높은 성능의 아키텍처를 발견했습니다.

Conclusion: LLM 주도의 NAS 파이프라인이 고성능 복합 상태 인코더를 위한 샘플 효율적 검색을 안내하는 데 효과적임을 보여줍니다.

Abstract: Designing state encoders for reinforcement learning (RL) with multiple information sources -- such as sensor measurements, time-series signals, image observations, and textual instructions -- remains underexplored and often requires manual design. We formalize this challenge as a problem of composite neural architecture search (NAS), where multiple source-specific modules and a fusion module are jointly optimized. Existing NAS methods overlook useful side information from the intermediate outputs of these modules -- such as their representation quality -- limiting sample efficiency in multi-source RL settings. To address this, we propose an LLM-driven NAS pipeline that leverages language-model priors and intermediate-output signals to guide sample-efficient search for high-performing composite state encoders. On a mixed-autonomy traffic control task, our approach discovers higher-performing architectures with fewer candidate evaluations than traditional NAS baselines and the LLM-based GENIUS framework.

</details>


### [14] [OXtal: An All-Atom Diffusion Model for Organic Crystal Structure Prediction](https://arxiv.org/abs/2512.06987)
*Emily Jin,Andrei Cristian Nica,Mikhail Galkin,Jarrid Rector-Brooks,Kin Long Kelvin Lee,Santiago Miret,Frances H. Arnold,Michael Bronstein,Avishek Joey Bose,Alexander Tong,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: OXtal은 3D 분자 결정 구조 예측을 위한 대규모 확산 모델로, 효율적인 자료 증강 전략을 통해 실험적으로 검증된 결정 구조를 정확하게 예측한다.


<details>
  <summary>Details</summary>
Motivation: 분자 결정 구조 예측(CSP)은 물리적 및 화학적 성질에 직접적인 영향을 미치는 결정 포장 문제를 해결하기 위한 오랜 도전 과제이다.

Method: OXtal은 100M 파라미터의 전자 모델로, 결정 대칭에서 발생하는 귀착 편향을 피하고 데이터 증강 전략을 채택한다. 새로운 결정화에 영감을 받은 격자 없는 훈련 방식인 $S^4$를 제안하여 장거리 상호작용을 효율적으로 캡처한다.

Result: OXtal은 600K 개의 실험적으로 검증된 결정 구조로부터 학습하여 기존 ab initio 기계 학습 CSP 방법보다 수십 배 향상된 성능을 보인다.

Conclusion: OXtal은 실험 구조를 $	ext{RMSD}_1<0.5$ Å의 오차로 복원하고 80	ext{% 이상의 포장 유사성을 달성하여 분자 결정화의 열역학적 및 동역학적 규칙성을 모델링하는 능력을 입증한다.

Abstract: Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion model that directly learns the conditional joint distribution over intramolecular conformations and periodic packing. To efficiently scale OXtal, we abandon explicit equivariant architectures imposing inductive bias arising from crystal symmetries in favor of data augmentation strategies. We further propose a novel crystallization-inspired lattice-free training scheme, Stoichiometric Stochastic Shell Sampling ($S^4$), that efficiently captures long-range interactions while sidestepping explicit lattice parametrization -- thus enabling more scalable architectural choices at all-atom resolution. By leveraging a large dataset of 600K experimentally validated crystal structures (including rigid and flexible molecules, co-crystals, and solvates), OXtal achieves orders-of-magnitude improvements over prior ab initio machine learning CSP methods, while remaining orders of magnitude cheaper than traditional quantum-chemical approaches. Specifically, OXtal recovers experimental structures with conformer $\text{RMSD}_1<0.5$ Å and attains over 80\% packing similarity rate, demonstrating its ability to model both thermodynamic and kinetic regularities of molecular crystallization.

</details>


### [15] [Transformation of Biological Networks into Images via Semantic Cartography for Visual Interpretation and Scalable Deep Analysis](https://arxiv.org/abs/2512.07040)
*Sakib Mostafa,Lei Xing,Md. Tauhidul Islam*

Main category: cs.LG

TL;DR: Graph2Image는 복잡한 생물학적 네트워크를 2D 이미지 집합으로 변환하여 기존 방법의 한계를 극복하고, 새로운 기회를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 생물학적 네트워크를 해독하는 것은 건강과 질병 이해에 중요한데, 현재의 계산 방법은 이러한 네트워크의 규모와 복잡성으로 인해 도전받고 있습니다.

Method: Graph2Image는 대표적인 네트워크 노드를 2D 격자에 공간적으로 배치하여 대규모 생물학적 네트워크를 2차원 이미지로 변환합니다. 이 방법은 CNN을 사용하여 스케일링, 메모리 효율성 및 장기 맥락 포착의 기존 방법의 한계를 극복합니다.

Result: Graph2Image는 여러 대규모 생물학적 네트워크 데이터 세트에 적용했을 때 기존 방법 대비 분류 정확도를 최대 67.2% 향상시켰고, 해석 가능한 시각화를 제공하여 생물학적으로 일관된 패턴을 드러냈습니다.

Conclusion: Graph2Image는 생물학적 네트워크 분석을 위한 확장 가능하고 해석 가능한 방법을 제공하며, 질병 진단 및 복잡한 생물학적 시스템 연구의 새로운 기회를 열어줍니다.

Abstract: Complex biological networks are fundamental to biomedical science, capturing interactions among molecules, cells, genes, and tissues. Deciphering these networks is critical for understanding health and disease, yet their scale and complexity represent a daunting challenge for current computational methods. Traditional biological network analysis methods, including deep learning approaches, while powerful, face inherent challenges such as limited scalability, oversmoothing long-range dependencies, difficulty in multimodal integration, expressivity bounds, and poor interpretability. We present Graph2Image, a framework that transforms large biological networks into sets of two-dimensional images by spatially arranging representative network nodes on a 2D grid. This transformation decouples the nodes as images, enabling the use of convolutional neural networks (CNNs) with global receptive fields and multi-scale pyramids, thus overcoming limitations of existing biological network analysis methods in scalability, memory efficiency, and long-range context capture. Graph2Image also facilitates seamless integration with other imaging and omics modalities and enhances interpretability through direct visualization of node-associated images. When applied to several large-scale biological network datasets, Graph2Image improved classification accuracy by up to 67.2% over existing methods and provided interpretable visualizations that revealed biologically coherent patterns. It also allows analysis of very large biological networks (nodes > 1 billion) on a personal computer. Graph2Image thus provides a scalable, interpretable, and multimodal-ready approach for biological network analysis, offering new opportunities for disease diagnosis and the study of complex biological systems.

</details>


### [16] [TRACE: A Generalizable Drift Detector for Streaming Data-Driven Optimization](https://arxiv.org/abs/2512.07082)
*Yuan-Ting Zhong,Ting Huang,Xiaolin Xiao,Yue-Jiao Gong*

Main category: cs.LG

TL;DR: TRACE는 데이터 스트림에서의 개념 변화 감지에 효과적인 방법으로, 다양한 동적 환경에 적응할 수 있는 능력을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 스트리밍 데이터의 개념 변화가 불확실한 최적화 작업이 증가하고 있으며, 이는 SDDO에서 큰 도전 과제가 되고 있습니다.

Method: TRACE는 데이터 스트림에서 통계적 특징을 추출하기 위해 원칙에 기초한 토큰화 전략을 활용하고, 주의 기반의 시퀀스 학습을 통해 드리프트 패턴을 모델링합니다.

Result: 실험 결과, TRACE는 이전에 보지 못한 데이터셋에서도 정확한 검출을 보이며 드리프트 패턴의 전이 가능성을 강조합니다.

Conclusion: TRACE는 스트리밍 최적화기에 통합될 수 있는 플러그 앤 플레이 특성을 보여주며, 알려지지 않은 드리프트 하에서 적응적 최적화를 촉진합니다.

Abstract: Many optimization tasks involve streaming data with unknown concept drifts, posing a significant challenge as Streaming Data-Driven Optimization (SDDO). Existing methods, while leveraging surrogate model approximation and historical knowledge transfer, are often under restrictive assumptions such as fixed drift intervals and fully environmental observability, limiting their adaptability to diverse dynamic environments. We propose TRACE, a TRAnsferable C}oncept-drift Estimator that effectively detects distributional changes in streaming data with varying time scales. TRACE leverages a principled tokenization strategy to extract statistical features from data streams and models drift patterns using attention-based sequence learning, enabling accurate detection on unseen datasets and highlighting the transferability of learned drift patterns. Further, we showcase TRACE's plug-and-play nature by integrating it into a streaming optimizer, facilitating adaptive optimization under unknown drifts. Comprehensive experimental results on diverse benchmarks demonstrate the superior generalization, robustness, and effectiveness of our approach in SDDO scenarios.

</details>


### [17] [Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search](https://arxiv.org/abs/2512.07142)
*Tanay Arora,Christof Teuscher*

Main category: cs.LG

TL;DR: Concrete Ticket Search (CTS)는 랜덤 초기화된 신경망 내에서 고성능 하위 네트워크를 효율적으로 발견하기 위한 알고리즘으로, 최소한의 계산으로 LTR보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 Pruning-at-Initialization (PaI) 기법이 정확도와 희소성 간의 상충 문제로 인해 성능이 떨어지는 문제를 해결하고자 한다.

Method: Concrete Ticket Search (CTS)라는 알고리즘을 도입하여 하위 네트워크 발견을 전체적인 조합 최적화 문제로 프레이밍하고, 새로운 그래디언트 균형 기법(GRADBALANCE)을 사용하여 희소성을 조절한다.

Result: CTS는 초기화 근처에서 고성능 하위 네트워크를 효과적으로 찾아내며, 실험 결과 LTR보다 낮은 계산으로 유사한 또는 더 높은 정확도를 달성한다.

Conclusion: CTS의 하위 네트워크는 모든 희소성에서 saliency 기반 방법보다 우수한 성능을 발휘하며, 특히 희소성이 높을수록 LTR 대비 그 성능 우위가 두드러진다.

Abstract: The Lottery Ticket Hypothesis asserts the existence of highly sparse, trainable subnetworks ('winning tickets') within dense, randomly initialized neural networks. However, state-of-the-art methods of drawing these tickets, like Lottery Ticket Rewinding (LTR), are computationally prohibitive, while more efficient saliency-based Pruning-at-Initialization (PaI) techniques suffer from a significant accuracy-sparsity trade-off and fail basic sanity checks. In this work, we argue that PaI's reliance on first-order saliency metrics, which ignore inter-weight dependencies, contributes substantially to this performance gap, especially in the sparse regime. To address this, we introduce Concrete Ticket Search (CTS), an algorithm that frames subnetwork discovery as a holistic combinatorial optimization problem. By leveraging a Concrete relaxation of the discrete search space and a novel gradient balancing scheme (GRADBALANCE) to control sparsity, CTS efficiently identifies high-performing subnetworks near initialization without requiring sensitive hyperparameter tuning. Motivated by recent works on lottery ticket training dynamics, we further propose a knowledge distillation-inspired family of pruning objectives, finding that minimizing the reverse Kullback-Leibler divergence between sparse and dense network outputs (CTS-KL) is particularly effective. Experiments on varying image classification tasks show that CTS produces subnetworks that robustly pass sanity checks and achieve accuracy comparable to or exceeding LTR, while requiring only a small fraction of the computation. For example, on ResNet-20 on CIFAR10, it reaches 99.3% sparsity with 74.0% accuracy in 7.9 minutes, while LTR attains the same sparsity with 68.3% accuracy in 95.2 minutes. CTS's subnetworks outperform saliency-based methods across all sparsities, but its advantage over LTR is most pronounced in the highly sparse regime.

</details>


### [18] [Improving the Throughput of Diffusion-based Large Language Models via a Training-Free Confidence-Aware Calibration](https://arxiv.org/abs/2512.07173)
*Jucheng Shen,Gaurav Sarkar,Yeonju Ro,Sharath Nittur Sridhar,Zhangyang Wang,Aditya Akella,Souvik Kundu*

Main category: cs.LG

TL;DR: CadLLM은 확산 기반 대형 언어 모델의 추론 성능을 향상시키는 훈련 필요 없는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 추론 성능을 개선하기 위한 효율적인 방법이 필요하다.

Method: 블록과 단계별로 토큰의 신뢰성 변화를 관찰하고, 이를 바탕으로 생성 블록 크기, 단계 크기 및 임계값을 조절하는 경량 적응형 접근 방식을 제시한다.

Result: CadLLM은 최신 기술 기준 대비 최대 2.28배의 성능 향상을 달성하며, 경쟁력 있는 정확도를 유지한다.

Conclusion: CadLLM은 KV 캐시 기반의 확산 언어 모델과 호환되는 플러그 앤 플레이 방식의 모델 불문 방법이다.

Abstract: We present CadLLM, a training-free method to accelerate the inference throughput of diffusion-based LLMs (dLLMs). We first investigate the dynamic nature of token unmasking confidence across blocks and steps. Based on this observation, we present a lightweight adaptive approach that controls the generation block size, step size, and threshold based on the average confidence of unmasked tokens. We further reduce softmax overhead by dynamically leveraging a subset of the vocabulary to regulate sampling breadth. CadLLM is a plug-and-play, model-agnostic method compatible with KV-cache-based dLLMs. Extensive experiments on four popular tasks demonstrate that CadLLM yields up to 2.28x throughput improvement over the state-of-the-art baseline with competitive accuracy.

</details>


### [19] [UniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting](https://arxiv.org/abs/2512.07184)
*Da Zhang,Bingyu Li,Zhuyuan Zhao,Junyu Gao,Feiping Nie,Xuelong Li*

Main category: cs.LG

TL;DR: UniDiff는 멀티모달 시계열 예측을 위한 통합 확산 프레임워크로, 복잡한 이질적 데이터에서 다중 모달 정보를 활용하여 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 다양한 실제 응용 프로그램에서 멀티모달 데이터가 증가함에 따라 텍스트와 타임스탬프와 같은 이질적 정보를 활용한 정확한 시계열 예측(TSF)이 중요한 도전 과제가 되고 있다.

Method: UniDiff는 시계열을 패치로 나눈 후 가벼운 MLP를 통해 각 패치를 임베딩 공간에 매핑하며, 단일 크로스 어텐션 메커니즘으로 타임스탬프의 구조 정보와 텍스트의 의미적 맥락을 통합한다.

Result: 8 개의 도메인에서 실세계 벤치마크 데이터 세트를 기반으로 한 광범위한 실험에서 UniDiff 모델이 최첨단 성능을 달성한다.

Conclusion: 이 프레임워크는 다중 소스 조정을 위한 새로운 비분류기 기반의 안내 메커니즘을 도입하여 모델의 견고성을 크게 향상시킨다.

Abstract: As multimodal data proliferates across diverse real-world applications, leveraging heterogeneous information such as texts and timestamps for accurate time series forecasting (TSF) has become a critical challenge. While diffusion models demonstrate exceptional performance in generation tasks, their application to TSF remains largely confined to modeling single-modality numerical sequences, overlooking the abundant cross-modal signals inherent in complex heterogeneous data. To address this gap, we propose UniDiff, a unified diffusion framework for multimodal time series forecasting. To process the numerical sequence, our framework first tokenizes the time series into patches, preserving local temporal dynamics by mapping each patch to an embedding space via a lightweight MLP. At its core lies a unified and parallel fusion module, where a single cross-attention mechanism adaptively weighs and integrates structural information from timestamps and semantic context from texts in one step, enabling a flexible and efficient interplay between modalities. Furthermore, we introduce a novel classifier-free guidance mechanism designed for multi-source conditioning, allowing for decoupled control over the guidance strength of textual and temporal information during inference, which significantly enhances model robustness. Extensive experiments on real-world benchmark datasets across eight domains demonstrate that the proposed UniDiff model achieves state-of-the-art performance.

</details>


### [20] [IFFair: Influence Function-driven Sample Reweighting for Fair Classification](https://arxiv.org/abs/2512.07249)
*Jingran Yang,Min Zhang,Lingfeng Zhang,Zhaohui Wang,Yonggang Zhang*

Main category: cs.LG

TL;DR: 본 논문은 머신러닝의 공정성을 높이기 위한 사전 처리 방법인 IFFair를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 머신러닝의 데이터 기반 패턴이 특정 불평등 집단에 대한 편향을 학습하고 악화시켜 차별적인 결정을 초래하므로 사회적 복지를 해치고 관련 응용 프로그램의 발전을 저해하는 문제를 해결하고자 합니다.

Method: IFFair는 교육 샘플의 영향 불균형을 활용하여 샘플 가중치를 동적으로 조정하는 사전 처리 방법입니다. 이 방법은 네트워크 구조, 데이터 특성 및 결정 경계를 변경하지 않고 진행됩니다.

Result: IFFair는 여러 실제 데이터셋과 메트릭을 통해 실험되었으며, 여러 수용 가능한 메트릭에서 분류 설정의 편향을 완화하는 결과를 보였습니다.

Conclusion: IFFair는 이전의 사전 처리 방법에 비해 여러 유틸리티 및 공정성 메트릭 간의 더 나은 균형을 달성합니다.

Abstract: Because machine learning has significantly improved efficiency and convenience in the society, it's increasingly used to assist or replace human decision-making. However, the data-based pattern makes related algorithms learn and even exacerbate potential bias in samples, resulting in discriminatory decisions against certain unprivileged groups, depriving them of the rights to equal treatment, thus damaging the social well-being and hindering the development of related applications. Therefore, we propose a pre-processing method IFFair based on the influence function. Compared with other fairness optimization approaches, IFFair only uses the influence disparity of training samples on different groups as a guidance to dynamically adjust the sample weights during training without modifying the network structure, data features and decision boundaries. To evaluate the validity of IFFair, we conduct experiments on multiple real-world datasets and metrics. The experimental results show that our approach mitigates bias of multiple accepted metrics in the classification setting, including demographic parity, equalized odds, equality of opportunity and error rate parity without conflicts. It also demonstrates that IFFair achieves better trade-off between multiple utility and fairness metrics compared with previous pre-processing methods.

</details>


### [21] [SIT-Graph: State Integrated Tool Graph for Multi-Turn Agents](https://arxiv.org/abs/2512.07287)
*Sijia Li,Yuchen Huang,Zifan Liu,Zijian Li,Jingjing fu,Lei Song,Jiang Bian,Jun Zhang,Rui Wang*

Main category: cs.LG

TL;DR: SIT-Graph은 다단계 도구 사용을 개선하기 위해 부분적으로 겹치는 경험을 활용하는 새로운 도구 그래프 접근법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다단계 도구 사용 시의 챌린지를 해결하기 위해, 에이전트 시스템의 진전에 기초하여 경험 재사용이 필수적입니다.

Method: SIT-Graph는 과거의 도구 사용 경로에서 상태 요약과 도구 간 의존성을 통합하여 도구 그래프를 구성하고, 추론 시 에이전트의 결정을 지원합니다.

Result: SIT-Graph는 기존의 메모리 및 그래프 기반 방법론을 초월하여 더 강력한 도구 선택과 경험 전이를 제공합니다.

Conclusion: SIT-Graph는 다단계 도구 사용 벤치마크에서 일관되게 우수한 성능을 보여주었습니다.

Abstract: Despite impressive advances in agent systems, multi-turn tool-use scenarios remain challenging. It is mainly because intent is clarified progressively and the environment evolves with each tool call. While reusing past experience is natural, current LLM agents either treat entire trajectories or pre-defined subtasks as indivisible units, or solely exploit tool-to-tool dependencies, hindering adaptation as states and information evolve across turns. In this paper, we propose a State Integrated Tool Graph (SIT-Graph), which enhances multi-turn tool use by exploiting partially overlapping experience. Inspired by human decision-making that integrates episodic and procedural memory, SIT-Graph captures both compact state representations (episodic-like fragments) and tool-to-tool dependencies (procedural-like routines) from historical trajectories. Specifically, we first build a tool graph from accumulated tool-use sequences, and then augment each edge with a compact state summary of the dialog and tool history that may shape the next action. At inference time, SIT-Graph enables a human-like balance between episodic recall and procedural execution: when the next decision requires recalling prior context, the agent retrieves the state summaries stored on relevant edges and uses them to guide its next action; when the step is routine, it follows high-confidence tool dependencies without explicit recall. Experiments across multiple stateful multi-turn tool-use benchmarks show that SIT-Graph consistently outperforms strong memory- and graph-based baselines, delivering more robust tool selection and more effective experience transfer.

</details>


### [22] [LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples](https://arxiv.org/abs/2512.07375)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: LUNE는 저비용의 부정적인 학습 접근법을 제공하여 대규모 언어 모델의 사생활 보호 및 편향 완화 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델은 방대한 지식을 보유하고 있지만, 특정 정보를 제거하는 데 어려움을 겪습니다. 이는 사생활, 편향 완화 및 지식 수정에서 문제를 발생시킵니다.

Method: LoRA 기반의 부정적 학습 프레임워크인 LUNE를 도입하여 저급 랭크 어댑터만 업데이트하며 백본을 동결하여 부정적 전용 학습을 수행합니다.

Result: LUNE는 여러 사실 기반 부정적 학습 작업에서 전체 파인 튜닝 및 메모리 편집 방법과 유사한 효과를 달성하며, 계산 비용은 대략 10배 줄어들었습니다.

Conclusion: LUNE은 대규모 언어 모델의 부정적 학습을 위한 효율적인 솔루션을 제공합니다.

Abstract: Large language models (LLMs) possess vast knowledge acquired from extensive training corpora, but they often cannot remove specific pieces of information when needed, which makes it hard to handle privacy, bias mitigation, and knowledge correction. Traditional model unlearning approaches require computationally expensive fine-tuning or direct weight editing, making them impractical for real-world deployment. In this work, we introduce LoRA-based Unlearning with Negative Examples (LUNE), a lightweight framework that performs negative-only unlearning by updating only low-rank adapters while freezing the backbone, thereby localizing edits and avoiding disruptive global changes. Leveraging Low-Rank Adaptation (LoRA), LUNE targets intermediate representations to suppress (or replace) requested knowledge with an order-of-magnitude lower compute and memory than full fine-tuning or direct weight editing. Extensive experiments on multiple factual unlearning tasks show that LUNE: (I) achieves effectiveness comparable to full fine-tuning and memory-editing methods, and (II) reduces computational cost by about an order of magnitude.

</details>


### [23] [Adaptive Tuning of Parameterized Traffic Controllers via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.07417)
*Giray Önür,Azita Dabiri,Bart De Schutter*

Main category: cs.LG

TL;DR: 다중 에이전트 강화 학습 프레임워크를 제안하여 교통 신호 제어를 개선한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 교통 관리 전략은 복잡하고 시간적으로 변동하는 교통 역학을 처리할 수 있는 적응성이 부족하다.

Method: 각 에이전트가 상태 피드백 교통 제어기의 매개변수를 적응적으로 조정하는 다중 에이전트 강화 학습 프레임워크를 제안한다.

Result: 제안된 프레임워크는 시뮬레이션된 다중 클래스 교통 네트워크에서 평가되었으며, 기존 방법에 비해 우수한 성능을 보인다.

Conclusion: 제안된 다중 에이전트 프레임워크는 교통 조건 변화에 대한 적응성과 부분 실패에 대한 저항력이 더 우수하다.

Abstract: Effective traffic control is essential for mitigating congestion in transportation networks. Conventional traffic management strategies, including route guidance, ramp metering, and traffic signal control, often rely on state feedback controllers, used for their simplicity and reactivity; however, they lack the adaptability required to cope with complex and time-varying traffic dynamics. This paper proposes a multi-agent reinforcement learning framework in which each agent adaptively tunes the parameters of a state feedback traffic controller, combining the reactivity of state feedback controllers with the adaptability of reinforcement learning. By tuning parameters at a lower frequency rather than directly determining control actions at a high frequency, the reinforcement learning agents achieve improved training efficiency while maintaining adaptability to varying traffic conditions. The multi-agent structure further enhances system robustness, as local controllers can operate independently in the event of partial failures. The proposed framework is evaluated on a simulated multi-class transportation network under varying traffic conditions. Results show that the proposed multi-agent framework outperforms the no control and fixed-parameter state feedback control cases, while performing on par with the single-agent RL-based adaptive state feedback control, with a much better resilience to partial failures.

</details>


### [24] [In-Context and Few-Shots Learning for Forecasting Time Series Data based on Large Language Models](https://arxiv.org/abs/2512.07705)
*Saroj Gopali,Bipin Chhetri,Deepika Giri,Sima Siami-Namini,Akbar Siami Namin*

Main category: cs.LG

TL;DR: 본 논문은 시계열 데이터 예측을 위한 LLM 모델의 성능을 조사하고, 사전 훈련된 시계열 기초 모델인 TimesFM의 우수성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 사전 훈련된 기초 모델이 기존 모델 접근 방식을 능가할 수 있는지 조사하기 위함이다.

Method: LLM 모델을 이용한 시계열 데이터 예측에 대한 연구로, OpenAI o4-mini와 Gemini 2.5 Flash Lite, 그리고 Google's Transformer 기반 모델인 TimesFM을 포함하여, TCN 및 LSTM 네트워크와 비교 연구하였다.

Result: TimesFM이 최저 RMSE 값(0.3023)과 경쟁적인 추론 시간(266초)을 기록하며 최고의 전반적인 성능을 보였다.

Conclusion: 사전 훈련된 시계열 기초 모델이 실시간 예측을 위한 유망한 방향임을 강조하며, 최소한의 모델 적응으로 정확하고 확장 가능한 배포를 가능하게 한다.

Abstract: Existing data-driven approaches in modeling and predicting time series data include ARIMA (Autoregressive Integrated Moving Average), Transformer-based models, LSTM (Long Short-Term Memory) and TCN (Temporal Convolutional Network). These approaches, and in particular deep learning-based models such as LSTM and TCN, have shown great results in predicting time series data. With the advancement of leveraging pre-trained foundation models such as Large Language Models (LLMs) and more notably Google's recent foundation model for time series data, {\it TimesFM} (Time Series Foundation Model), it is of interest to investigate whether these foundation models have the capability of outperforming existing modeling approaches in analyzing and predicting time series data.
  This paper investigates the performance of using LLM models for time series data prediction. We investigate the in-context learning methodology in the training of LLM models that are specific to the underlying application domain. More specifically, the paper explores training LLMs through in-context, zero-shot and few-shot learning and forecasting time series data with OpenAI {\tt o4-mini} and Gemini 2.5 Flash Lite, as well as the recent Google's Transformer-based TimesFM, a time series-specific foundation model, along with two deep learning models, namely TCN and LSTM networks. The findings indicate that TimesFM has the best overall performance with the lowest RMSE value (0.3023) and the competitive inference time (266 seconds). Furthermore, OpenAI's o4-mini also exhibits a good performance based on Zero Shot learning.
  These findings highlight pre-trained time series foundation models as a promising direction for real-time forecasting, enabling accurate and scalable deployment with minimal model adaptation.

</details>


### [25] [The Adoption and Usage of AI Agents: Early Evidence from Perplexity](https://arxiv.org/abs/2512.07828)
*Jeremy Yang,Noah Yonack,Kate Zyskowski,Denis Yarats,Johnny Ho,Jerry Ma*

Main category: cs.LG

TL;DR: 이 연구는 오픈 월드 웹 환경에서 운영되는 범용 AI 에이전트의 채택, 사용 강도 및 사용 사례에 대한 대규모 필드 연구 결과를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 오픈 월드 웹 환경에서 작동하는 범용 AI 에이전트의 실질적인 사용 패턴을 이해하고 이를 통해 연구자, 기업, 정책 입안자 및 교육자에게 중요한 함의를 제공하기 위함이다.

Method: Perplexity가 개발한 AI 기반 브라우저 Comet 및 통합 에이전트 Comet Assistant를 분석하며, 수억 건의 익명 사용자 상호 작용 데이터를 기반으로 사용 패턴을 조사한다.

Result: 조사 결과, AI 에이전트의 채택 및 사용에서 사용자 세그먼트 간의 상당한 이질성이 드러나며, 먼저 채택한 사용자 및 GDP가 높은 국가의 사용자들이 더 활발히 사용하고 있음을 발견했다.

Conclusion: AI 에이전트의 사용 사례는 시간이 지남에 따라 인지 중심 주제로 이동하지만 단기적으로는 사용의 지속성이 강하게 나타난다.

Abstract: This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors -- such as digital technology, academia, finance, marketing, and entrepreneurship -- are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics, Productivity & Workflow and Learning & Research, account for 57% of all agentic queries, while the two largest subtopics, Courses and Shopping for Goods, make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [26] [AI-Generated Compromises for Coalition Formation: Modeling, Simulation, and a Textual Case Study](https://arxiv.org/abs/2512.05983)
*Eyal Briman,Ehud Shapiro,Nimrod Talmon*

Main category: cs.MA

TL;DR: AI 하위 분야에서 제안 간의 타협을 찾는 문제를 해결하기 위해, 에이전트의 제한된 합리성과 불확실성을 반영한 모델을 구축하고, NLP와 LLM을 활용하여 협력적으로 문서를 작성하는 과정에서 적절한 타협점을 제안하는 알고리즘을 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 제안 간의 타협 찾기는 AI의 논쟁, 중재, 협상 등의 분야에서 기본적인 문제이다.

Method: 에이전트의 이상점을 기준으로 하는 메트릭 공간을 사용하여 다수 지원의 제안을 찾아내는 통합 모델을 형성하고, NLP 및 LLM 기술을 활용하여 텍스트의 의미적 메트릭 공간을 생성하며, 적합한 타협점을 제안하는 알고리즘을 개발했다.

Result: 다양한 연합 형성 과정을 시뮬레이션하여 알고리즘의 효과성을 평가하고, AI가 대규모 민주적 텍스트 편집을 촉진할 수 있는 가능성을 입증하였다.

Conclusion: AI는 헌법을 공동으로 초안하는 등의 전통 도구가 한계가 있는 분야에서 대규모 민주적 텍스트 편집에 기여할 수 있다.

Abstract: The challenge of finding compromises between agent proposals is fundamental to AI sub-fields such as argumentation, mediation, and negotiation. Building on this tradition, Elkind et al. (2021) introduced a process for coalition formation that seeks majority-supported proposals preferable to the status quo, using a metric space where each agent has an ideal point. The crucial step in this iterative process involves identifying compromise proposals around which agent coalitions can unite. How to effectively find such compromise proposals, however, remains an open question. We address this gap by formalizing a holistic model that encompasses agent bounded rationality and uncertainty and developing AI models to generate such compromise proposals. We focus on the domain of collaboratively writing text documents -- e.g., to enable the democratic creation of a community constitution. We apply NLP (Natural Language Processing) techniques and utilize LLMs (Large Language Models) to create a semantic metric space for text and develop algorithms to suggest suitable compromise points. To evaluate the effectiveness of our algorithms, we simulate various coalition formation processes and demonstrate the potential of AI to facilitate large-scale democratic text editing, such as collaboratively drafting a constitution, an area where traditional tools are limited.

</details>


### [27] [HiveMind: Contribution-Guided Online Prompt Optimization of LLM Multi-Agent Systems](https://arxiv.org/abs/2512.06432)
*Yihan Xia,Taotao Wang,Shengli Zhang,Zhangyuhua Weng,Bin Cao,Soung Chang Liew*

Main category: cs.MA

TL;DR: 이 논문에서는 LLM 기반의 다중 에이전트 시스템의 협업 최적화를 위한 새로운 프레임워크인 HiveMind를 제안하였으며, 이를 통해 에이전트의 기여를 기반으로 자동으로 프롬프트를 개선하여 성능 향상을 달성하였다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 다중 에이전트 시스템의 개별 에이전트 효과성 평가 및 성능이 저조한 에이전트의 온라인 최적화 문제 해결.

Method: HiveMind 프레임워크는 Contribution-Guided Online Prompt Optimization (CG-OPO)를 통해 각 에이전트의 기여를 정량화하고 에이전트 프롬프트를 자동으로 개선.

Result: HiveMind는 다중 에이전트 주식 거래 시나리오에서 정적 기준선보다 우수한 성능을 달성하며, DAG-Shapley 알고리즘을 통해 LLM 호출을 80% 이상 줄이고 기여 정확도를 유지.

Conclusion: HiveMind는 효율적인 신용 할당을 위한 새로운 기준을 설정하고, 다중 에이전트 협업의 확장 가능하고 실질적인 최적화를 가능하게 한다.

Abstract: Recent advances in LLM-based multi-agent systems have demonstrated remarkable capabilities in complex decision-making scenarios such as financial trading and software engineering. However, evaluating each individual agent's effectiveness and online optimization of underperforming agents remain open challenges. To address these issues, we present HiveMind, a self-adaptive framework designed to optimize LLM multi-agent collaboration through contribution analysis. At its core, HiveMind introduces Contribution-Guided Online Prompt Optimization (CG-OPO), which autonomously refines agent prompts based on their quantified contributions. We first propose the Shapley value as a grounded metric to quantify each agent's contribution, thereby identifying underperforming agents in a principled manner for automated prompt refinement. To overcome the computational complexity of the classical Shapley value, we present DAG-Shapley, a novel and efficient attribution algorithm that leverages the inherent Directed Acyclic Graph structure of the agent workflow to axiomatically prune non-viable coalitions. By hierarchically reusing intermediate outputs of agents in the DAG, our method further reduces redundant computations, and achieving substantial cost savings without compromising the theoretical guarantees of Shapley values. Evaluated in a multi-agent stock-trading scenario, HiveMind achieves superior performance compared to static baselines. Notably, DAG-Shapley reduces LLM calls by over 80\% while maintaining attribution accuracy comparable to full Shapley values, establishing a new standard for efficient credit assignment and enabling scalable, real-world optimization of multi-agent collaboration.

</details>


### [28] [ChargingBoul: A Competitive Negotiating Agent with Novel Opponent Modeling](https://arxiv.org/abs/2512.06595)
*Joe Shymanski*

Main category: cs.MA

TL;DR: ChargingBoul은 2022년 자동화 협상 대회에서 2위를 차지한 협상 에이전트로, 효과적인 전략을 통해 높은 협상 성과를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 자동화 협상은 전자 상거래, 자원 배분 및 자율적 의사 결정 등의 분야에서 중요하다.

Method: ChargingBoul은 경량의 전략을 사용하여 양보와 상대 모델링을 조화롭게 활용한다.

Result: ChargingBoul은 2022 ANAC에서 개인 유틸리티 부문에서 높은 성과를 기록했다.

Conclusion: ChargingBoul의 성능을 향상시키기 위한 잠재적인 개선 사항을 논의한다.

Abstract: Automated negotiation has emerged as a critical area of research in multiagent systems, with applications spanning e-commerce, resource allocation, and autonomous decision-making. This paper presents ChargingBoul, a negotiating agent that competed in the 2022 Automated Negotiating Agents Competition (ANAC) and placed second in individual utility by an exceptionally narrow margin. ChargingBoul employs a lightweight yet effective strategy that balances concession and opponent modeling to achieve high negotiation outcomes. The agent classifies opponents based on bid patterns, dynamically adjusts its bidding strategy, and applies a concession policy in later negotiation stages to maximize utility while fostering agreements. We evaluate ChargingBoul's performance using competition results and subsequent studies that have utilized the agent in negotiation research. Our analysis highlights ChargingBoul's effectiveness across diverse opponent strategies and its contributions to advancing automated negotiation techniques. We also discuss potential enhancements, including more sophisticated opponent modeling and adaptive bidding heuristics, to improve its performance further.

</details>


### [29] [Analyzing Collision Rates in Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.06645)
*Muyang Fan*

Main category: cs.MA

TL;DR: 이 연구는 MARL 기반 혼합교통 제어 시스템에서 충돌률에 영향을 미치는 주요 요인을 조사하여 안전성과 견고성을 향상시키기 위한 통찰을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 혼합 교통 시스템 내에서 차량 충돌은 주요한 도전 과제이며, 특히 인간 운전 차량(HVs)과 로봇 차량(RVs) 간의 상호작용에서 더욱 그러합니다.

Method: 시뮬레이션 실험을 통해 총 차량 수, 신호화 대 비신호화 교차로 구성, 그리고 회전 이동 전략의 세 가지 차원을 분석합니다.

Result: 충돌률은 교통 밀도, 신호 조정 수준, 그리고 회전 제어 설계에 민감하게 반응하는 것으로 나타났습니다.

Conclusion: 이 연구는 MARL 기반 혼합 교통 제어 시스템의 안전성과 견고성을 향상시키고, 효율성과 안전성이 공동으로 최적화된 지능형 교통 시스템 개발을 지원합니다.

Abstract: Vehicle collisions remain a major challenge in large-scale mixed traffic systems, especially when human-driven vehicles (HVs) and robotic vehicles (RVs) interact under dynamic and uncertain conditions. Although Multi-Agent Reinforcement Learning (MARL) offers promising capabilities for traffic signal control, ensuring safety in such environments remains difficult. As a direct indicator of traffic risk, the collision rate must be well understood and incorporated into traffic control design. This study investigates the primary factors influencing collision rates in a MARL-governed Mixed Traffic Control (MTC) network. We examine three dimensions: total vehicle count, signalized versus unsignalized intersection configurations, and turning-movement strategies. Through controlled simulation experiments, we evaluate how each factor affects collision likelihood. The results show that collision rates are sensitive to traffic density, the level of signal coordination, and turning-control design. These findings provide practical insights for improving the safety and robustness of MARL-based mixed traffic control systems, supporting the development of intelligent transportation systems in which both efficiency and safety are jointly optimized.

</details>


### [30] [Understanding LLM Agent Behaviours via Game Theory: Strategy Recognition, Biases and Multi-Agent Dynamics](https://arxiv.org/abs/2512.07462)
*Trung-Kiet Huynh,Duy-Minh Dao-Sy,Thanh-Bang Cao,Phong-Hao Le,Hong-Dan Nguyen,Phu-Quy Nguyen-Lam,Minh-Luan Nguyen-Vo,Hong-Phat Pham,Phu-Hoa Pham,Thien-Kim Than,Chi-Nguyen Tran,Huy Tran,Gia-Thoai Tran-Le,Alessio Buscemi,Le Hong Trang,The Anh Han*

Main category: cs.MA

TL;DR: 본 논문은 FAIRGAME 프레임워크를 확장하여 반복 사회적 딜레마에서 LLM의 행동을 체계적으로 평가하고, LLM의 전략적 행동을 이해하는 데 기여합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 상호작용 및 다중 에이전트 시스템에서 자율 의사결정자로 작동하게 됨에 따라 이들의 전략적 행동을 이해하는 것이 안전성, 조정 및 AI 기반 사회 경제적 인프라 설계에 중요함.

Method: Payoff-scaled Prisoners Dilemma와 동적 보상 및 다중 에이전트 이력을 가진 통합 다중 에이전트 Public Goods Game을 사용하여 LLM의 행동을 평가했습니다.

Result: 모델 및 언어 간에 일관된 행동 서명이 나타났으며, 인센티브에 민감한 협력, 언어 간 분기 및 끝맺음에서의 이탈 경향이 관찰되었습니다.

Conclusion: 이 연구는 LLM이 전략적 에이전트로서 감사를 위한 통합된 방법론적 기반을 제공하고 AI 거버넌스, 집단 의사결정 및 안전한 다중 에이전트 시스템 설계에 직접적인 영향을 미치는 체계적인 협력 편향을 밝혀냈습니다.

Abstract: As Large Language Models (LLMs) increasingly operate as autonomous decision-makers in interactive and multi-agent systems and human societies, understanding their strategic behaviour has profound implications for safety, coordination, and the design of AI-driven social and economic infrastructures. Assessing such behaviour requires methods that capture not only what LLMs output, but the underlying intentions that guide their decisions. In this work, we extend the FAIRGAME framework to systematically evaluate LLM behaviour in repeated social dilemmas through two complementary advances: a payoff-scaled Prisoners Dilemma isolating sensitivity to incentive magnitude, and an integrated multi-agent Public Goods Game with dynamic payoffs and multi-agent histories. These environments reveal consistent behavioural signatures across models and languages, including incentive-sensitive cooperation, cross-linguistic divergence and end-game alignment toward defection. To interpret these patterns, we train traditional supervised classification models on canonical repeated-game strategies and apply them to FAIRGAME trajectories, showing that LLMs exhibit systematic, model- and language-dependent behavioural intentions, with linguistic framing at times exerting effects as strong as architectural differences. Together, these findings provide a unified methodological foundation for auditing LLMs as strategic agents and reveal systematic cooperation biases with direct implications for AI governance, collective decision-making, and the design of safe multi-agent systems.

</details>


### [31] [Understanding Individual Decision-Making in Multi-Agent Reinforcement Learning: A Dynamical Systems Approach](https://arxiv.org/abs/2512.07588)
*James Rudd-Jones,María Pérez-Ortiz,Mirco Musolesi*

Main category: cs.MA

TL;DR: 이 논문에서는 다중 에이전트 강화 학습(MARL) 시스템을 결합된 확률적 동적 시스템으로 모델링하여 에이전트의 상호작용과 환경 특성을 모두 포착하고, 에이전트 행동의 안정성과 민감성을 분석하여 실용적 배치의 주요 차원을 다룬다.


<details>
  <summary>Details</summary>
Motivation: MARL 환경에서 개별적인 의사 결정의 학습 행동을 분석하는 것이 어렵다. 전통적인 방법들이 개별 궤적의 실제 실현과의 불일치를 초래할 수 있다.

Method: 에이전트 상호작용 및 환경 특성을 반영하여 MARL 시스템을 결합된 확률적 동적 시스템으로 모델링하고, 동적 시스템 이론의 도구를 활용하여 개별 수준에서 에이전트 행동의 안정성과 민감성을 분석한다.

Result: 새로운 프레임워크를 통해 MARL 동역학을 엄밀하게 연구할 수 있게 되며, 시스템 행동에 대한 더 깊은 이해와 다중 에이전트 학습 과정의 설계 및 제어를 위한 실용적인 통찰을 제공한다.

Conclusion: 이 연구는 MARL 시스템의 본질적인 확률성을 고려하여 시스템 행동을 깊이 있게 이해하는 데 기여하며, 에이전트 행동의 안정성과 민감성을 다루어 실용적 배치에 중요한 차원을 제시한다.

Abstract: Analysing learning behaviour in Multi-Agent Reinforcement Learning (MARL) environments is challenging, in particular with respect to \textit{individual} decision-making. Practitioners frequently tend to study or compare MARL algorithms from a qualitative perspective largely due to the inherent stochasticity in practical algorithms arising from random dithering exploration strategies, environment transition noise, and stochastic gradient updates to name a few. Traditional analytical approaches, such as replicator dynamics, often rely on mean-field approximations to remove stochastic effects, but this simplification, whilst able to provide general overall trends, might lead to dissonance between analytical predictions and actual realisations of individual trajectories. In this paper, we propose a novel perspective on MARL systems by modelling them as \textit{coupled stochastic dynamical systems}, capturing both agent interactions and environmental characteristics. Leveraging tools from dynamical systems theory, we analyse the stability and sensitivity of agent behaviour at individual level, which are key dimensions for their practical deployments, for example, in presence of strict safety requirements. This framework allows us, for the first time, to rigorously study MARL dynamics taking into consideration their inherent stochasticity, providing a deeper understanding of system behaviour and practical insights for the design and control of multi-agent learning processes.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [32] [ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment](https://arxiv.org/abs/2512.06196)
*Charlie Masters,Marta Grześkiewicz,Stefano V. Albrecht*

Main category: cs.AI

TL;DR: 본 연구에서 우리는 ARCANE 이라는 프레임워크를 소개하여 대형 언어 모델 기반 에이전트의 이해관계자 선호도 정렬 문제를 해결하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 기반 에이전트가 장기 작업에 점점 더 많이 배치됨에 따라 이해관계자의 선호도와의 정렬 유지가 중요해지고 있습니다.

Method: ARCANE 프레임워크는 이해관계자의 선호를 자연 언어 수치로 동적으로 표현하여 정렬 문제를 다중 에이전트 협력 문제로 설정합니다.

Result: 219개의 레이블이 있는 수치 집합을 사용하여 ARCANE을 다단계 추론 및 도구 사용이 필요한 어려운 작업에 평가하여, 학습된 수치가 compact하고 가독성 있는 평가를 제공함을 보여주었습니다.

Conclusion: 수치 기반 보상 모델은 복잡한 장기 AI 시스템에 대한 해석 가능하고 테스트 시간에 적응하는 정렬을 위한 유망한 경로를 제공합니다.

Abstract: As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context. Inspired by utility theory, we formulate rubric learning as a reconstruction problem and apply a regularized Group-Sequence Policy Optimization (GSPO) procedure that balances interpretability, faithfulness, and computational efficiency. Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use. The learned rubrics produce compact, legible evaluations and enable configurable trade-offs (e.g., correctness vs. conciseness) without retraining. Our results show that rubric-based reward models offer a promising path toward interpretable, test-time adaptive alignment for complex, long-horizon AI systems.

</details>


### [33] [On measuring grounding and generalizing grounding problems](https://arxiv.org/abs/2512.06205)
*Daniel Quigley,Eric Maynard*

Main category: cs.AI

TL;DR: 이 논문은 심볼 그라운딩 문제를 다루며, 기호가 어떻게 그것이 지칭하는 것과 연결될 수 있는지를 평가하기 위한 다차원 틀을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 심볼 그라운딩 문제는 기호가 어떻게 지칭하는 것과 연결되는지를 이해하기 위해 필요하다.

Method: 그라운딩을 이진 판단에서 여러 평가 기준으로 전환하고, 각각의 기준을 평가 튜플로 색인화한다.

Result: 네 가지 그라운딩 모드와 세 가지 사례 연구를 통해 그라운딩 및 의미에 대한 통합적 이해를 제공한다.

Conclusion: 이 틀을 통해 과학 철학자, 컴퓨터 과학자, 언어학자, 수학자들이 의미와 그라운딩에 대한 체계적 조사를 위한 공통 언어와 기술적 틀을 갖출 수 있게 된다.

Abstract: The symbol grounding problem asks how tokens like cat can be about cats, as opposed to mere shapes manipulated in a calculus. We recast grounding from a binary judgment into an audit across desiderata, each indexed by an evaluation tuple (context, meaning type, threat model, reference distribution): authenticity (mechanisms reside inside the agent and, for strong claims, were acquired through learning or evolution); preservation (atomic meanings remain intact); faithfulness, both correlational (realized meanings match intended ones) and etiological (internal mechanisms causally contribute to success); robustness (graceful degradation under declared perturbations); compositionality (the whole is built systematically from the parts). We apply this framework to four grounding modes (symbolic; referential; vectorial; relational) and three case studies: model-theoretic semantics achieves exact composition but lacks etiological warrant; large language models show correlational fit and local robustness for linguistic tasks, yet lack selection-for-success on world tasks without grounded interaction; human language meets the desiderata under strong authenticity through evolutionary and developmental acquisition. By operationalizing a philosophical inquiry about representation, we equip philosophers of science, computer scientists, linguists, and mathematicians with a common language and technical framework for systematic investigation of grounding and meaning.

</details>


### [34] [GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols](https://arxiv.org/abs/2512.06404)
*Mohammad Soleymanibrojeni,Roland Aydin,Diego Guedes-Sobrinho,Alexandre C. Dias,Maurício J. Piotrowski,Wolfgang Wenzel,Celso Ricardo Caldeira Rêgo*

Main category: cs.AI

TL;DR: GENIUS는 AI 기반 워크플로로, 복잡한 전산 재료 공학을 자동화하여 DFT 시뮬레이션을 democratize 한다.


<details>
  <summary>Details</summary>
Motivation: 정확한 전산 재료 공학을 위한 AI 기반의 자동화된 솔루션이 필요하다.

Method: GENIUS는 Quantum ESPRESSO 지식 그래프와 대형 언어 모델의 계층 구조를 통합하여 사용자 생성 프롬프트를 검증된 입력 파일로 변환한다.

Result: GENIUS는 295개의 벤치마크에서 약 80%의 완수율과 76%의 자율 수정률을 기록했다.

Conclusion: 이 프레임워크는 DFT 시뮬레이션을 자동화하여 대규모 스크리닝과 설계 루프를 가속화한다.

Abstract: Predictive atomistic simulations have propelled materials discovery, yet routine setup and debugging still demand computer specialists. This know-how gap limits Integrated Computational Materials Engineering (ICME), where state-of-the-art codes exist but remain cumbersome for non-experts. We address this bottleneck with GENIUS, an AI-agentic workflow that fuses a smart Quantum ESPRESSO knowledge graph with a tiered hierarchy of large language models supervised by a finite-state error-recovery machine. Here we show that GENIUS translates free-form human-generated prompts into validated input files that run to completion on $\approx$80% of 295 diverse benchmarks, where 76% are autonomously repaired, with success decaying exponentially to a 7% baseline. Compared with LLM-only baselines, GENIUS halves inference costs and virtually eliminates hallucinations. The framework democratizes electronic-structure DFT simulations by intelligently automating protocol generation, validation, and repair, opening large-scale screening and accelerating ICME design loops across academia and industry worldwide.

</details>


### [35] [The Effect of Belief Boxes and Open-mindedness on Persuasion](https://arxiv.org/abs/2512.06573)
*Onur Bilgin,Abdullah As Sami,Sriram Sai Vujjini,John Licato*

Main category: cs.AI

TL;DR: 이 연구는 다중 에이전트 시스템에서 LLM 기반 에이전트의 신념이 행동 및 설득력에 미치는 영향을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템의 적용이 증가함에 따라, LLM 기반 에이전트가 특정한 신념을 가지도록 요구되는 필요성이 커지고 있다.

Method: 신념 상자에 신념을 설명하는 진술을 포함시키는 방법을 사용하여 이를 연구하였다.

Result: 개방적인 태도를 지시받은 에이전트는 신념 변화에 더 유연하게 반응하며, 신념 진술과 그 강도를 포함시키면 반대 의견에 대한 저항력 및 설득력에 영향을 미친다는 것을 확인하였다.

Conclusion: 이 연구는 신념 상자 기법이 추론 및 의사결정 과제에서 실행 가능하고 유효함을 보여준다.

Abstract: As multi-agent systems are increasingly utilized for reasoning and decision-making applications, there is a greater need for LLM-based agents to have something resembling propositional beliefs. One simple method for doing so is to include statements describing beliefs maintained in the prompt space (in what we'll call their belief boxes). But when agents have such statements in belief boxes, how does it actually affect their behaviors and dispositions towards those beliefs? And does it significantly affect agents' ability to be persuasive in multi-agent scenarios? Likewise, if the agents are given instructions to be open-minded, how does that affect their behaviors? We explore these and related questions in a series of experiments. Our findings confirm that instructing agents to be open-minded affects how amenable they are to belief change. We show that incorporating belief statements and their strengths influences an agent's resistance to (and persuasiveness against) opposing viewpoints. Furthermore, it affects the likelihood of belief change, particularly when the agent is outnumbered in a debate by opposing viewpoints, i.e., peer pressure scenarios. The results demonstrate the feasibility and validity of the belief box technique in reasoning and decision-making tasks.

</details>


### [36] [Stochasticity in Agentic Evaluations: Quantifying Inconsistency with Intraclass Correlation](https://arxiv.org/abs/2512.06710)
*Zairah Mustahsan,Abel Lim,Megna Anand,Saahil Jain,Bryan McCann*

Main category: cs.AI

TL;DR: 대형 언어 모델의 평가 신뢰성을 향상시키기 위한 새로운 방법으로 Intraclass Correlation Coefficient (ICC)를 제안한다. 이는 보고된 결과의 변동성을 분석하여 진정한 능력 향상과 우연한 샘플링을 구분하는 데 도움을 준다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 더 큰 에이전트 시스템의 구성 요소가됨에 따라 평가 신뢰성이 중요해진다. 신뢰할 수 없는 하위 에이전트는 시스템 행동에 부정적인 영향을 미칠 수 있다.

Method: 측정 과학에서의 지표인 Intraclass Correlation Coefficient (ICC)를 활용하여 변동성을 분석하고, 관찰된 분산을 작업 간 분산(작업 난이도)과 작업 내 분산(에이전트 일관성)으로 분해한다.

Result: GAIA와 FRAMES 데이터 세트에서 ICC가 모델에 따라 극적으로 달라짐을 보여주었다. FRAMES는 ICC=0.4955-0.7118, GAIA는 ICC=0.304-0.774로 나타났다. 신뢰할 수 있는 정확도 향상은 ICC 개선이 함께 이루어질 때만 가능하다.

Conclusion: 따라서 정확도와 ICC를 함께 보고하고, 새로운 측정 지표를 담은 평가 카드를 제안하며, 이를 통해 평가의 안정성을 높이고 신뢰할 수 있는 실험 과학으로 에이전트 벤치마킹을 변모시키려 한다.

Abstract: As large language models become components of larger agentic systems, evaluation reliability becomes critical: unreliable sub-agents introduce brittleness into downstream system behavior. Yet current evaluation practice, reporting a single accuracy number from a single run, obscures the variance underlying these results, making it impossible to distinguish genuine capability improvements from lucky sampling. We propose adopting Intraclass Correlation Coefficient (ICC), a metric from measurement science, to characterize this variance. ICC decomposes observed variance into between-query variance (task difficulty) and within-query variance (agent inconsistency), highlighting whether reported results reflect true capability or measurement noise. We evaluated on GAIA (Levels 1-3, measuring agentic capabilities across varying reasoning complexity) and FRAMES (measuring retrieval and factuality across multiple documents). We found that ICC varies dramatically with task structure, with reasoning and retrieval tasks (FRAMES) exhibit ICC=0.4955-0.7118 across models, and agentic tasks (GAIA) exhibiting ICC=0.304-0.774 across models. For sub-agent replacement decisions in agentic systems, accuracy improvements are only trustworthy if ICC also improves. We demonstrate that ICC converges by n=8-16 trials for structured tasks and n>=32 for complex reasoning, enabling practitioners to set evidence-based resampling budgets. We recommend reporting accuracy alongside ICC and within-query variance as standard practice, and propose updated Evaluation Cards capturing these metrics. By making evaluation stability visible, we aim to transform agentic benchmarking from opaque leaderboard competition to trustworthy experimental science. Our code is open-sourced at https://github.com/youdotcom-oss/stochastic-agent-evals.

</details>


### [37] [Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents](https://arxiv.org/abs/2512.06716)
*Zhibo Liang,Tianze Hu,Zaiye Chen,Mingjie Tang*

Main category: cs.AI

TL;DR: 이 연구는 자율 대형 언어 모델(LLM) 에이전트의 간접 프롬프트 주입(IPI) 공격에 대한 취약점을 다루며, 이를 해결하기 위해 인지 제어 아키텍처(CCA)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 LLM 에이전트는 IPI 공격에 매우 취약하여, 보안과 기능성 간의 본질적인 절충을 이용한 외부 정보 원천의 오염으로 인해 에이전트의 행동이 탈선한다.

Method: 우리의 방법은 모든 IPI 공격은 궁극적으로 실행 계획에서의 탐지 가능한 편차로 나타날 것이라는 통찰을 기반으로 하며, CCA라는 포괄적인 프레임워크를 제안한다.

Result: AgentDojo 벤치마크에서 CCA는 복잡한 공격에 효과적으로 저항하며, 효율성과 견고성을 유지하면서 보안이 손상되지 않는 결과를 보여준다.

Conclusion: 이 연구는 CCA가 다차원적인 절충 문제를 해결할 수 있음을 입증한다.

Abstract: Autonomous Large Language Model (LLM) agents exhibit significant vulnerability to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources, exploiting fundamental trade-offs between security and functionality in existing defense mechanisms. This leads to malicious and unauthorized tool invocations, diverting agents from their original objectives. The success of complex IPIs reveals a deeper systemic fragility: while current defenses demonstrate some effectiveness, most defense architectures are inherently fragmented. Consequently, they fail to provide full integrity assurance across the entire task execution pipeline, forcing unacceptable multi-dimensional compromises among security, functionality, and efficiency. Our method is predicated on a core insight: no matter how subtle an IPI attack, its pursuit of a malicious objective will ultimately manifest as a detectable deviation in the action trajectory, distinct from the expected legitimate plan. Based on this, we propose the Cognitive Control Architecture (CCA), a holistic framework achieving full-lifecycle cognitive supervision. CCA constructs an efficient, dual-layered defense system through two synergistic pillars: (i) proactive and preemptive control-flow and data-flow integrity enforcement via a pre-generated "Intent Graph"; and (ii) an innovative "Tiered Adjudicator" that, upon deviation detection, initiates deep reasoning based on multi-dimensional scoring, specifically designed to counter complex conditional attacks. Experiments on the AgentDojo benchmark substantiate that CCA not only effectively withstands sophisticated attacks that challenge other advanced defense methods but also achieves uncompromised security with notable efficiency and robustness, thereby reconciling the aforementioned multi-dimensional trade-off.

</details>


### [38] [ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems](https://arxiv.org/abs/2512.06721)
*Bufang Yang,Lilin Xu,Liekang Zeng,Yunqi Guo,Siyang Jiang,Wenrui Lu,Kaiwei Liu,Hancheng Xiang,Xiaofan Jiang,Guoliang Xing,Zhenyu Yan*

Main category: cs.AI

TL;DR: ProAgent는 대규모 감각 컨텍스트와 LLM 추론을 활용하여 프로액티브 지원을 제공하는 첫 번째 종단 간 프로액티브 에이전트 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 LLM 에이전트는 사용자 지침에 의존하여 서비스가 시작되는 반응형 패러다임을 따르며, 이는 물리적 및 인지적 부담을 증가시킨다.

Method: ProAgent는 요구 기반 계층적 인식을 통해 환경을 지속적으로 감지하고 감각 및 개인 cue를 통합한 계층적 맥락을 도출하는 프로액티브 지향의 컨텍스트 추출 접근 방식을 사용한다. 그 후 맥락 인식을 통해 사용자 요구 및 도구 호출에 이러한 맥락을 매핑하는 프로액티브 추론기를 채택하여 프로액티브 지원을 제공한다.

Result: ProAgent는 업계 최선의 기준 대비 최대 33.4% 더 높은 프로액티브 예측 정확도와 16.8% 더 높은 도구 호출 F1 점수, 그리고 사용자 만족도에서 뚜렷한 개선을 이룬다.

Conclusion: ProAgent는 프로액티브 보조자를 향한 중요한 진전을 시사한다.

Abstract: Large Language Model (LLM) agents are emerging to transform daily life. However, existing LLM agents primarily follow a reactive paradigm, relying on explicit user instructions to initiate services, which increases both physical and cognitive workload. In this paper, we propose ProAgent, the first end-to-end proactive agent system that harnesses massive sensory contexts and LLM reasoning to deliver proactive assistance. ProAgent first employs a proactive-oriented context extraction approach with on-demand tiered perception to continuously sense the environment and derive hierarchical contexts that incorporate both sensory and persona cues. ProAgent then adopts a context-aware proactive reasoner to map these contexts to user needs and tool calls, providing proactive assistance. We implement ProAgent on Augmented Reality (AR) glasses with an edge server and extensively evaluate it on a real-world testbed, a public dataset, and through a user study. Results show that ProAgent achieves up to 33.4% higher proactive prediction accuracy, 16.8% higher tool-calling F1 score, and notable improvements in user satisfaction over state-of-the-art baselines, marking a significant step toward proactive assistants. A video demonstration of ProAgent is available at https://youtu.be/pRXZuzvrcVs.

</details>


### [39] [DoVer: Intervention-Driven Auto Debugging for LLM Multi-Agent Systems](https://arxiv.org/abs/2512.06749)
*Ming Ma,Jue Zhang,Fangkai Yang,Yu Kang,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM) 기반 다중 에이전트 시스템의 디버깅은 긴 상호작용 추적으로 인해 어려우며, 본 논문에서는 새로운 디버깅 프레임워크인 DoVer를 제안하여 이 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 다중 에이전트 시스템의 실패 원인을 규명하고 디버깅 과정을 개선하기 위해.

Method: DoVer라는 개입 기반의 디버깅 프레임워크를 도입하여 가설 생성을 개입을 통해 활성 검증하고, 실패 해결 여부에 초점을 맞춘 평가 방식을 적용한다.

Result: DoVer는 GAIA와 AssistantBench에서 18-28%의 실패한 시험을 성공으로 전환하고 최대 16%의 이정표 진전을 달성했으며, 실패 가설의 30-60%를 검증 또는 반박하였다.

Conclusion: DoVer는 에이전트 시스템의 신뢰성을 향상시키기 위한 실제적인 메커니즘을 제시하며, LLM 기반 다중 에이전트 시스템을 위한 보다 강력하고 확장 가능한 디버깅 방법의 기회를 열어준다.

Abstract: Large language model (LLM)-based multi-agent systems are challenging to debug because failures often arise from long, branching interaction traces. The prevailing practice is to leverage LLMs for log-based failure localization, attributing errors to a specific agent and step. However, this paradigm has two key limitations: (i) log-only debugging lacks validation, producing untested hypotheses, and (ii) single-step or single-agent attribution is often ill-posed, as we find that multiple distinct interventions can independently repair the failed task. To address the first limitation, we introduce DoVer, an intervention-driven debugging framework, which augments hypothesis generation with active verification through targeted interventions (e.g., editing messages, altering plans). For the second limitation, rather than evaluating on attribution accuracy, we focus on measuring whether the system resolves the failure or makes quantifiable progress toward task success, reflecting a more outcome-oriented view of debugging. Within the Magnetic-One agent framework, on the datasets derived from GAIA and AssistantBench, DoVer flips 18-28% of failed trials into successes, achieves up to 16% milestone progress, and validates or refutes 30-60% of failure hypotheses. DoVer also performs effectively on a different dataset (GSMPlus) and agent framework (AG2), where it recovers 49% of failed trials. These results highlight intervention as a practical mechanism for improving reliability in agentic systems and open opportunities for more robust, scalable debugging methods for LLM-based multi-agent systems. Project website and code will be available at https://aka.ms/DoVer.

</details>


### [40] [On Memory: A comparison of memory mechanisms in world models](https://arxiv.org/abs/2512.06983)
*Eli J. Laird,Corey Clark*

Main category: cs.AI

TL;DR: 이 논문은 변환기 기반 세계 모델의 효과적인 메모리 범위를 조사하고 메모리 증강 메커니즘의 분석을 통해 모델의 기억력을 향상시키는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 회상 메모리에 대한 효과적인 메모리 범위를 조사하여 세계 모델의 능력을 확장하는 것이 필요합니다.

Method: 여러 메모리 증강 메커니즘을 분석하고 메모리 인코딩과 메모리 주입 메커니즘을 구별하는 분류법을 소개합니다.

Result: 각 메커니즘의 메모리 회상을 측정하고 각각의 트레이드 오프를 분석합니다.

Conclusion: 메모리 메커니즘이 시각 변환기에서 효과적인 메모리 범위를 개선하고 세계 모델 상상의 루프 닫기를 완료하는 경로를 제공합니다.

Abstract: World models enable agents to plan within imagined environments by predicting future states conditioned on past observations and actions. However, their ability to plan over long horizons is limited by the effective memory span of the backbone architecture. This limitation leads to perceptual drift in long rollouts, hindering the model's capacity to perform loop closures within imagined trajectories. In this work, we investigate the effective memory span of transformer-based world models through an analysis of several memory augmentation mechanisms. We introduce a taxonomy that distinguishes between memory encoding and memory injection mechanisms, motivating their roles in extending the world model's memory through the lens of residual stream dynamics. Using a state recall evaluation task, we measure the memory recall of each mechanism and analyze its respective trade-offs. Our findings show that memory mechanisms improve the effective memory span in vision transformers and provide a path to completing loop closures within a world model's imagination.

</details>


### [41] [Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients](https://arxiv.org/abs/2512.06990)
*Krishna Arun,Moinak Bhattachrya,Paras Goel*

Main category: cs.AI

TL;DR: 이 논문은 의사들이 이질적인 뇌종양 치료에 도움을 줄 수 있는 AI 시스템을 개발한 내용을 다루고 있다.


<details>
  <summary>Details</summary>
Motivation: 뇌종양인 다형성 교모세포종(GBM) 치료에 AI의 부족이 심각한 문제로 대두되고 있다.

Method: 진단 단계에서 4개의 분류 모델로 구성된 순차적 의사결정 프레임워크를 사용하고, 치료 계획에는 3개의 생성 모델로 구성된 RL 시스템을 활용한다.

Result: AI 시스템은 기존 솔루션에 비해 운영 비용을 22.28배 줄이고, 종양 진행 추론 시간을 113시간 단축시켰으며, 현실에 가까운 데이터 증식을 통해 DICE 점수를 2.9% 개선하였다.

Conclusion: 이 시스템은 생존률을 0.9% 증가시킬 것으로 예상되며, 약 2,250명의 생명을 구할 가능성이 있다.

Abstract: Currently, there is a noticeable lack of AI in the medical field to support doctors in treating heterogenous brain tumors such as Glioblastoma Multiforme (GBM), the deadliest human cancer in the world with a five-year survival rate of just 5.1%. This project develops an AI system offering the only end-to-end solution by aiding doctors with both diagnosis and treatment planning. In the diagnosis phase, a sequential decision-making framework consisting of 4 classification models (Convolutional Neural Networks and Support Vector Machine) are used. Each model progressively classifies the patient's brain into increasingly specific categories, with the final step being named diagnosis. For treatment planning, an RL system consisting of 3 generative models is used. First, the resection model (diffusion model) analyzes the diagnosed GBM MRI and predicts a possible resection outcome. Second, the radiotherapy model (Spatio-Temporal Vision Transformer) generates an MRI of the brain's progression after a user-defined number of weeks. Third, the chemotherapy model (Diffusion Model) produces the post-treatment MRI. A survival rate calculator (Convolutional Neural Network) then checks if the generated post treatment MRI has a survival rate within 15% of the user defined target. If not, a feedback loop using proximal policy optimization iterates over this system until an optimal resection location is identified. When compared to existing solutions, this project found 3 key findings: (1) Using a sequential decision-making framework consisting of 4 small diagnostic models reduced computing costs by 22.28x, (2) Transformers regression capabilities decreased tumor progression inference time by 113 hours, and (3) Applying Augmentations resembling Real-life situations improved overall DICE scores by 2.9%. These results project to increase survival rates by 0.9%, potentially saving approximately 2,250 lives.

</details>


### [42] [ClinNoteAgents: An LLM Multi-Agent System for Predicting and Interpreting Heart Failure 30-Day Readmission from Clinical Notes](https://arxiv.org/abs/2512.07081)
*Rongjia Zhou,Chengzhuo Li,Carl Yang,Jiaying Lu*

Main category: cs.AI

TL;DR: ClinNoteAgents는 자유 형식의 임상 노트를 분석하여 심부전 재입원 위험을 예측하는 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 미국의 노인들 가운데 심부전은 재입원의 주요 원인 중 하나이다. 그러나 임상 노트는 심부전 재입원 위험 분석에 충분히 활용되지 않고 있다.

Method: ClinNoteAgents는 자유 형식의 임상 노트를 구조화된 임상 및 사회적 위험 요인 표현으로 변환하고, 심부전 30일 재입원 예측을 위해 의사 스타일의 추상화를 생성하는 LLM 기반의 다중 에이전트 프레임워크이다.

Result: 34,544개의 노트를 사용하여 성능을 평가한 결과, 자유 형식에서 위험 요인을 추출하고 주요 기여 요인을 식별하며 재입원 위험을 예측하는 데 강력한 성능을 보였다.

Conclusion: ClinNoteAgents는 구조화된 필드에 대한 의존도를 줄이고 수동 주석 및 모델 훈련을 최소화하여 데이터가 제한된 의료 시스템에서 노트 기반 심부전 재입원 위험 모델링에 대해 확장 가능하고 해석 가능한 접근 방식을 제공한다.

Abstract: Heart failure (HF) is one of the leading causes of rehospitalization among older adults in the United States. Although clinical notes contain rich, detailed patient information and make up a large portion of electronic health records (EHRs), they remain underutilized for HF readmission risk analysis. Traditional computational models for HF readmission often rely on expert-crafted rules, medical thesauri, and ontologies to interpret clinical notes, which are typically written under time pressure and may contain misspellings, abbreviations, and domain-specific jargon. We present ClinNoteAgents, an LLM-based multi-agent framework that transforms free-text clinical notes into (1) structured representations of clinical and social risk factors for association analysis and (2) clinician-style abstractions for HF 30-day readmission prediction. We evaluate ClinNoteAgents on 3,544 notes from 2,065 patients (readmission rate=35.16%), demonstrating strong performance in extracting risk factors from free-text, identifying key contributing factors, and predicting readmission risk. By reducing reliance on structured fields and minimizing manual annotation and model training, ClinNoteAgents provides a scalable and interpretable approach to note-based HF readmission risk modeling in data-limited healthcare systems.

</details>


### [43] [VIGIL: A Reflective Runtime for Self-Healing Agents](https://arxiv.org/abs/2512.07094)
*Christopher Cruz*

Main category: cs.AI

TL;DR: VIGIL은 독자적인 유지보수를 수행하며, LLM 시스템의 신뢰성을 높이기 위해 자기 반영적 런타임을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 Agentic LLM 시스템은 안정성이 부족하며, 자율적인 실패 진단 및 개선 기능이 결여되어 있다.

Method: VIGIL은 행동 로그를 수집하여 감정적으로 구조화된 표현으로 평가하고, EmoBank를 유지하며, 최근 행동을 강점, 기회, 실패로 분류하는 RBT 진단을 도출한다.

Result: VIGIL은 핵심 정체성을 보존하는 업데이트와 코드 수정을 생성하며, 상태 기반 파이프라인으로 기능한다.

Conclusion: VIGIL은 배포된 에이전트 런타임에서 메타 수준의 자기 수리를 성공적으로 수행한다.

Abstract: Agentic LLM frameworks promise autonomous behavior via task decomposition, tool use, and iterative planning, but most deployed systems remain brittle. They lack runtime introspection, cannot diagnose their own failure modes, and do not improve over time without human intervention. In practice, many agent stacks degrade into decorated chains of LLM calls with no structural mechanisms for reliability. We present VIGIL (Verifiable Inspection and Guarded Iterative Learning), a reflective runtime that supervises a sibling agent and performs autonomous maintenance rather than task execution. VIGIL ingests behavioral logs, appraises each event into a structured emotional representation, maintains a persistent EmoBank with decay and contextual policies, and derives an RBT diagnosis that sorts recent behavior into strengths, opportunities, and failures. From this analysis, VIGIL generates both guarded prompt updates that preserve core identity semantics and read only code proposals produced by a strategy engine that operates on log evidence and code hotspots. VIGIL functions as a state gated pipeline. Illegal transitions produce explicit errors rather than allowing the LLM to improvise. In a reminder latency case study, VIGIL identified elevated lag, proposed prompt and code repairs, and when its own diagnostic tool failed due to a schema conflict, it surfaced the internal error, produced a fallback diagnosis, and emitted a repair plan. This demonstrates meta level self repair in a deployed agent runtime.

</details>


### [44] [A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy](https://arxiv.org/abs/2512.07109)
*Miguel Ingram,Arthur Joseph Merritt*

Main category: cs.AI

TL;DR: 이 논문에서는 Hodel et al.의 요청에 따라 400개의 작업에 대한 최초의 9개 카테고리 분류체계를 제시하고, 이를 통해 발생한 여러 발견을 보고합니다.


<details>
  <summary>Details</summary>
Motivation: 사전 정의된 작업 관련성에 대한 필요성으로 400개의 작업에 대한 공식적인 분류 필요성을 제기했습니다.

Method: 규칙 기반 코드 분석을 통해 97.5%의 정확도로 검증된 9개 카테고리의 분류체계를 제시하였고, CNN을 학습하여 분류체계의 시각적 일관성을 증명했습니다.

Result: 302개의 작업에 대해 미세 조정을 수행하여 210작업(69.5%)에서 80% 이상의 세포 정확도를 달성했지만 전체 합성에서는 10% 미만의 정확도를 보였습니다.

Conclusion: 하이브리드 아키텍처와 적합한 모듈이 필요하다는 것을 나타내며, 검증된 분류체계를 발표합니다.

Abstract: Responding to Hodel et al.'s (2024) call for a formal definition of task relatedness in re-arc, we present the first 9-category taxonomy of all 400 tasks, validated at 97.5% accuracy via rule-based code analysis. We prove the taxonomy's visual coherence by training a CNN on raw grid pixels (95.24% accuracy on S3, 36.25% overall, 3.3x chance), then apply the taxonomy diagnostically to the original ARC-AGI-2 test set. Our curriculum analysis reveals 35.3% of tasks exhibit low neural affinity for Transformers--a distributional bias mirroring ARC-AGI-2. To probe this misalignment, we fine-tuned a 1.7M-parameter Transformer across 302 tasks, revealing a profound Compositional Gap: 210 of 302 tasks (69.5%) achieve >80% cell accuracy (local patterns) but <10% grid accuracy (global synthesis). This provides direct evidence for a Neural Affinity Ceiling Effect, where performance is bounded by architectural suitability, not curriculum. Applying our framework to Li et al.'s independent ViTARC study (400 specialists, 1M examples each) confirms its predictive power: Very Low affinity tasks achieve 51.9% versus 77.7% for High affinity (p<0.001), with a task at 0% despite massive data. The taxonomy enables precise diagnosis: low-affinity tasks (A2) hit hard ceilings, while high-affinity tasks (C1) reach 99.8%. These findings indicate that progress requires hybrid architectures with affinity-aligned modules. We release our validated taxonomy,

</details>


### [45] [LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services](https://arxiv.org/abs/2512.07436)
*Hang He,Chuhuai Yue,Chengqi Dong,Mingxue Tian,Zhenfeng Liu,Jiajun Chai,Xiaohan Wang,Yufei Zhang,Qun Liao,Guojun Yin,Wei Lin,Chengcheng Wan,Haiying Sun,Ting Su*

Main category: cs.AI

TL;DR: LocalSearchBench는 지역 생활 서비스에 대한 에이전틱 검색의 첫 번째 종합 벤치마크로, 150,000개의 고품질 데이터를 포함하고 있으며, 복잡한 비즈니스 시나리오에 대한 다단계 질문 응답 작업을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 최근 대규모 추론 모델의 발전으로 에이전틱 검색 시스템이 복잡한 다단계 추론을 수행할 수 있게 되었지만, 대부분의 연구는 일반 정보 검색에 집중하고 특정 도메인의 고유한 과제는 거의 탐구되지 않았습니다.

Method: LocalSearchBench는 150,000개 이상의 고품질 항목을 포함하고 있으며, 실제 사용자 쿼리를 기반으로 한 300개의 다단계 질문 응답 작업을 구성하여 에이전트가 다단계로 질문을 이해하고 정보를 검색하도록 도전합니다.

Result: 최신 LRM도 LocalSearchBench에서 어려움을 겪으며, 가장 좋은 모델인 DeepSeek-V3.1의 정확도는 34.34%에 불과하고 대부분의 모델은 완전성(평균 77.33%)과 신뢰성(평균 61.99%) 문제를 갖고 있습니다.

Conclusion: 지역 생활 서비스에서 전문 벤치마크와 도메인별 에이전트 훈련의 필요성을 강조합니다.

Abstract: Recent advances in large reasoning models (LRMs) have enabled agentic search systems to perform complex multi-step reasoning across multiple sources. However, most studies focus on general information retrieval and rarely explores vertical domains with unique challenges. In this work, we focus on local life services and introduce LocalSearchBench, which encompass diverse and complex business scenarios. Real-world queries in this domain are often ambiguous and require multi-hop reasoning across merchants and products, remaining challenging and not fully addressed. As the first comprehensive benchmark for agentic search in local life services, LocalSearchBench includes over 150,000 high-quality entries from various cities and business types. We construct 300 multi-hop QA tasks based on real user queries, challenging agents to understand questions and retrieve information in multiple steps. We also developed LocalPlayground, a unified environment integrating multiple tools for agent interaction. Experiments show that even state-of-the-art LRMs struggle on LocalSearchBench: the best model (DeepSeek-V3.1) achieves only 34.34% correctness, and most models have issues with completeness (average 77.33%) and faithfulness (average 61.99%). This highlights the need for specialized benchmarks and domain-specific agent training in local life services. Code, Benchmark, and Leaderboard are available at localsearchbench.github.io.

</details>


### [46] [How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations](https://arxiv.org/abs/2512.07497)
*JV Roig*

Main category: cs.AI

TL;DR: 이 논문은 도구 사용 능력을 갖춘 자율 에이전트로 작동할 때 대형 언어 모델(LLMs)이 어떻게 실패하는지를 조사한다.


<details>
  <summary>Details</summary>
Motivation: 도구 사용 능력을 갖춘 자율 에이전트로서 LLM의 신뢰성을 평가하고 실패 원인을 분석하기 위함이다.

Method: Kamiwaza Agentic Merit Index (KAMI) v0.1 벤치마크를 사용하여 Granite 4 Small, Llama 4 Maverick, DeepSeek V3.1 세 모델의 900개 실행 추적을 분석한다.

Result: 모델 크기만으로는 에이전트의 견고함을 예측할 수 없으며, DeepSeek V3.1의 신뢰성은 주로 훈련 후 강화 학습에 의해 좌우된다.

Conclusion: 신뢰성 있는 기업 배포를 위해서는 더 강력한 모델뿐만 아니라 검증, 제약 발견, 진실의 출처 데이터 준수를 강화하는 훈련 및 설계 선택이 필요하다.

Abstract: We investigate how large language models (LLMs) fail when operating as autonomous agents with tool-use capabilities. Using the Kamiwaza Agentic Merit Index (KAMI) v0.1 benchmark, we analyze 900 execution traces from three representative models - Granite 4 Small, Llama 4 Maverick, and DeepSeek V3.1 - across filesystem, text extraction, CSV analysis, and SQL scenarios. Rather than focusing on aggregate scores, we perform fine-grained, per-trial behavioral analysis to surface the strategies that enable successful multi-step tool execution and the recurrent failure modes that undermine reliability. Our findings show that model scale alone does not predict agentic robustness: Llama 4 Maverick (400B) performs only marginally better than Granite 4 Small (32B) in some uncertainty-driven tasks, while DeepSeek V3.1's superior reliability derives primarily from post-training reinforcement learning rather than architecture or size. Across models, we identify four recurring failure archetypes: premature action without grounding, over-helpfulness that substitutes missing entities, vulnerability to distractor-induced context pollution, and fragile execution under load. These patterns highlight the need for agentic evaluation methods that emphasize interactive grounding, recovery behavior, and environment-aware adaptation, suggesting that reliable enterprise deployment requires not just stronger models but deliberate training and design choices that reinforce verification, constraint discovery, and adherence to source-of-truth data.

</details>


### [47] [The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds](https://arxiv.org/abs/2512.07631)
*Shahar Lutati*

Main category: cs.AI

TL;DR: 이 논문은 자율 에이전트가 자원을 언제 특정 작업에 할당해야 하는지를 다루며, 자원 제약 하에서 문제 해결 능력을 예측하는 Agent Capability Problem (ACP)이라는 프레임워크를 소개합니다. 이 프레임워크는 에이전트가 해결책을 식별하는 데 필요한 정보 획득으로 문제 해결을 형성하고, 기대 비용의 하한을 증명하며, 실제 성능을 정확히 추적하여 효율성을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 에이전트가 리소스를 할당하는 최적의 시점을 파악하기 위해.

Method: Agent Capability Problem (ACP)이라는 프레임워크를 도입하여 문제 해결을 정보 획득으로 간주하고, 에이전트가 해결책을 식별하는 데 필요한 비트 수와 각 행동으로부터 얻는 비트 수에 따라 비용을 예측한다.

Result: 실험 결과 ACP의 예측이 실제 에이전트 성능을 정확히 따라가며, 탐색 노력을 일관되게 제한하고 효율성을 향상시킨다.

Conclusion: 이 프레임워크는 LLM 기반 및 에이전트 작업 흐름 전반에 걸쳐 일반화되며, 능동 학습, 베이지안 최적화 및 강화 학습의 원리를 통합된 정보 이론적 관점에서 연결한다.

Abstract: When should an autonomous agent commit resources to a task? We introduce the Agent Capability Problem (ACP), a framework for predicting whether an agent can solve a problem under resource constraints. Rather than relying on empirical heuristics, ACP frames problem-solving as information acquisition: an agent requires $\Itotal$ bits to identify a solution and gains $\Istep$ bits per action at cost $\Cstep$, yielding an effective cost $\Ceff = (\Itotal/\Istep), \Cstep$ that predicts resource requirements before search. We prove that $\Ceff$ lower-bounds expected cost and provide tight probabilistic upper bounds. Experimental validation shows that ACP predictions closely track actual agent performance, consistently bounding search effort while improving efficiency over greedy and random strategies. The framework generalizes across LLM-based and agentic workflows, linking principles from active learning, Bayesian optimization, and reinforcement learning through a unified information-theoretic lens. \

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [48] [The Road of Adaptive AI for Precision in Cybersecurity](https://arxiv.org/abs/2512.06048)
*Sahil Garg*

Main category: cs.CR

TL;DR: 사이버 보안에서의 GenAI 파이프라인 설계, 구축 및 운영에 대한 주요 교훈과 통찰을 공유하며, AI 실무자와 산업 이해관계자를 위한 실행 가능한 관점을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안의 복잡성이 증가하면서 AI 연구 및 실천을 위한 독특한 도전과 기회를 제시한다.

Method: 사이버 보안을 위한 GenAI 파이프라인을 설계, 구축 및 운영하면서 실세계 배치를 기반으로 하는 실용적인 지침과 최고의 관행을 제안한다.

Result: 모델 및 검색 수준의 적응을 활용하기 위한 최선의 관행을 제안하고, 사이버 방어에서 GenAI를 더 강력하고 정확하며 감사 가능하게 만들기 위한 연구 방향을 강조한다.

Conclusion: 다양한 적응 메커니즘이 엔드-투-엔드 시스템에서 어떻게 서로 보완되는지를 중점적으로 논의한다.

Abstract: Cybersecurity's evolving complexity presents unique challenges and opportunities for AI research and practice. This paper shares key lessons and insights from designing, building, and operating production-grade GenAI pipelines in cybersecurity, with a focus on the continual adaptation required to keep pace with ever-shifting knowledge bases, tooling, and threats. Our goal is to provide an actionable perspective for AI practitioners and industry stakeholders navigating the frontier of GenAI for cybersecurity, with particular attention to how different adaptation mechanisms complement each other in end-to-end systems. We present practical guidance derived from real-world deployments, propose best practices for leveraging retrieval- and model-level adaptation, and highlight open research directions for making GenAI more robust, precise, and auditable in cyber defense.

</details>


### [49] [Privacy Loss of Noise Perturbation via Concentration Analysis of A Product Measure](https://arxiv.org/abs/2512.06253)
*Shuainan Liu,Tianxi Ji,Zhongshuo Fang,Lu Wei,Pan Li*

Main category: cs.CR

TL;DR: 본 연구는 고차원 공간에서의 $(ε,δ)$-차별적 프라이버시 보장을 위해 구형 대칭 노이즈 생성 방식을 제안하며, 이는 기대 노이즈 크기를 줄이고 결과의 유용성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기밀 데이터셋에 대해 질의 결과를 발표할 때 $(ε,δ)$-차별적 프라이버시 보장을 달성하기 위한 기본적인 접근법으로 노이즈 섭동이 있다.

Method: 구형 대칭 속성을 이용하여 새로운 노이즈 생성 방식을 제안하고, 이를 통해 프라이버시 손실을 기하학적으로 분석하며, 곱측도 $W	imes U$를 사용하여 결과적 PLRV를 표현한다.

Result: 전통적인 가우시안 노이즈보다 더 작은 기대 노이즈 크기를 제공하며, 이는 고차원에서 노이즈가 있는 결과의 유용성을 크게 향상시킨다.

Conclusion: 새로운 노이즈 생성 방식을 통해 고차원 공간의 에르미 문제에 적용할 수 있으며, 차별적 프라이버시를 달성할 수 있다.

Abstract: Noise perturbation is one of the most fundamental approaches for achieving $(ε,δ)$-differential privacy (DP) guarantees when releasing the result of a query or function $f(\cdot)\in\mathbb{R}^M$ evaluated on a sensitive dataset $\mathbf{x}$. In this approach, calibrated noise $\mathbf{n}\in\mathbb{R}^M$ is used to obscure the difference vector $f(\mathbf{x})-f(\mathbf{x}')$, where $\mathbf{x}'$ is known as a neighboring dataset. A DP guarantee is obtained by studying the tail probability bound of a privacy loss random variable (PLRV), defined as the Radon-Nikodym derivative between two distributions. When $\mathbf{n}$ follows a multivariate Gaussian distribution, the PLRV is characterized as a specific univariate Gaussian. In this paper, we propose a novel scheme to generate $\mathbf{n}$ by leveraging the fact that the perturbation noise is typically spherically symmetric (i.e., the distribution is rotationally invariant around the origin). The new noise generation scheme allows us to investigate the privacy loss from a geometric perspective and express the resulting PLRV using a product measure, $W\times U$; measure $W$ is related to a radius random variable controlling the magnitude of $\mathbf{n}$, while measure $U$ involves a directional random variable governing the angle between $\mathbf{n}$ and the difference $f(\mathbf{x})-f(\mathbf{x}')$. We derive a closed-form moment bound on the product measure to prove $(ε,δ)$-DP. Under the same $(ε,δ)$-DP guarantee, our mechanism yields a smaller expected noise magnitude than the classic Gaussian noise in high dimensions, thereby significantly improving the utility of the noisy result $f(\mathbf{x})+\mathbf{n}$. To validate this, we consider convex and non-convex empirical risk minimization (ERM) problems in high dimensional space and apply the proposed product noise to achieve privacy.

</details>


### [50] [Web Technologies Security in the AI Era: A Survey of CDN-Enhanced Defenses](https://arxiv.org/abs/2512.06390)
*Mehrab Hosain,Sabbir Alom Shuvo,Matthew Ogbe,Md Shah Jalal Mazumder,Yead Rahman,Md Azizul Hakim,Anukul Pandey*

Main category: cs.CR

TL;DR: 현대 웹 스택에서는 자동화된 AI 지원 공격이 지속적으로 진화하는 적대적 균형 하에 운영되고 있으며, 엣지 컴퓨팅과 CDN이 머신러닝 기반 방어를 사용자와 봇에 가깝게 배치한다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 공격의 진화와 웹 애플리케이션, API 보호를 위한 방어 솔루션의 필요성을 강조하기 위해.

Method: 엣지에서 배포된 AI 강화 방어 솔루션을 종합적으로 조사했으며, 여러 유형의 방화벽, DDoS 방지, 봇 관리 및 API 보호 방법론을 분석하였다.

Result: 엣지 중심 AI는 탐지 및 완화 시간을 개선하고 데이터 이동을 줄이며 규정 준수를 강화하지만, 모델 남용, 오염, 거버넌스와 관련된 새로운 위험을 도입한다.

Conclusion: XAI, 적대적 강건성 및 자율 다중 에이전트 방어를 포함한 연구 의제를 정립하였다.

Abstract: The modern web stack, which is dominated by browser-based applications and API-first backends, now operates under an adversarial equilibrium where automated, AI-assisted attacks evolve continuously. Content Delivery Networks (CDNs) and edge computing place programmable defenses closest to users and bots, making them natural enforcement points for machine-learning (ML) driven inspection, throttling, and isolation. This survey synthesizes the landscape of AI-enhanced defenses deployed at the edge: (i) anomaly- and behavior-based Web Application Firewalls (WAFs) within broader Web Application and API Protection (WAAP), (ii) adaptive DDoS detection and mitigation, (iii) bot management that resists human-mimicry, and (iv) API discovery, positive security modeling, and encrypted-traffic anomaly analysis. We add a systematic survey method, a threat taxonomy mapped to edge-observable signals, evaluation metrics, deployment playbooks, and governance guidance. We conclude with a research agenda spanning XAI, adversarial robustness, and autonomous multi-agent defense. Our findings indicate that edge-centric AI measurably improves time-to-detect and time-to-mitigate while reducing data movement and enhancing compliance, yet introduces new risks around model abuse, poisoning, and governance.

</details>


### [51] [AgenticCyber: A GenAI-Powered Multi-Agent System for Multimodal Threat Detection and Adaptive Response in Cybersecurity](https://arxiv.org/abs/2512.06396)
*Shovan Roy*

Main category: cs.CR

TL;DR: AgenticCyber는 멀티모달 데이터 스트림에서 실시간 탐지 및 대응을 위한 고급 프레임워크로, 클라우드 로그, 감시 비디오 및 환경 오디오를 동시에 모니터링하며 96.2%의 F1 점수를 달성하고 응답 지연 시간을 420 ms로 단축시킵니다.


<details>
  <summary>Details</summary>
Motivation: 분산 환경에서 사이버 위협의 복잡성이 증가함에 따라 실시간 탐지 및 대응을 위한 고급 프레임워크가 필요하다.

Method: 생성 AI 기반 다중 에이전트 시스템인 AgenticCyber는 전문 에이전트를 조율하여 클라우드 로그, 감시 비디오 및 환경 오디오를 동시에 모니터링한다.

Result: 이 솔루션은 위협 탐지에서 96.2% F1 점수를 달성하고 응답 지연 시간을 420 ms로 줄입니다.

Conclusion: 이 작업은 크로스 모달 추론과 자동화된 복구 기능을 통해 단절된 보안 기술을 극복하는 확장 가능하고 모듈화된 선제적 사이버 보안 아키텍처를 도입합니다.

Abstract: The increasing complexity of cyber threats in distributed environments demands advanced frameworks for real-time detection and response across multimodal data streams. This paper introduces AgenticCyber, a generative AI powered multi-agent system that orchestrates specialized agents to monitor cloud logs, surveillance videos, and environmental audio concurrently. The solution achieves 96.2% F1-score in threat detection, reduces response latency to 420 ms, and enables adaptive security posture management using multimodal language models like Google's Gemini coupled with LangChain for agent orchestration. Benchmark datasets, such as AWS CloudTrail logs, UCF-Crime video frames, and UrbanSound8K audio clips, show greater performance over standard intrusion detection systems, reducing mean time to respond (MTTR) by 65% and improving situational awareness. This work introduces a scalable, modular proactive cybersecurity architecture for enterprise networks and IoT ecosystems that overcomes siloed security technologies with cross-modal reasoning and automated remediation.

</details>


### [52] [PDRIMA: A Policy-Driven Runtime Integrity Measurement and Attestation Approach for ARM TrustZone-based TEE](https://arxiv.org/abs/2512.06500)
*Jingkai Mao,Xiaolin Chang*

Main category: cs.CR

TL;DR: PDRIMA는 TrustZone 기반 TEE의 런타임 무결성을 보호하는 새로운 접근 방식으로, 정책 기반 측정 및 원격 인증을 통해 TEE의 공격 면을 체계적으로 분석한다.


<details>
  <summary>Details</summary>
Motivation: 목표는 TrustZone 기반 장치의 런타임 무결성을 보호하고, 기존 방어책이 부족한 부분을 보완하는 것이다.

Method: PDRIMA는 Secure Monitor Agent(SMA)와 Remote Attestation Agent(RAA)라는 두 개의 TEE 내 subsystem을 도입하여 정책 기반 측정과 원격 인증을 수행한다.

Result: PDRIMA는 식별된 공격 면에 대한 보안을 분석하고, Raspberry Pi 3B+에서 OP-TEE를 기반으로 프로토타입을 구현하였다.

Conclusion: PDRIMA는 TEE 내 런타임 무결성 보호 및 원격 인증을 효과적으로 수행할 수 있는 가능성을 보여준다.

Abstract: Trusted Execution Environments (TEEs) such as ARM TrustZone are widely used in IoT and embedded devices to protect sensitive code and data. However, most existing defenses focus on secure boot or REE-side monitoring and provide little visibility into the runtime integrity of the TEE. This leaves TrustZone-based devices exposed to persistent TEE compromises. We propose Policy-Driven Runtime Integrity Measurement and Attestation (PDRIMA), a runtime integrity protection approach for TrustZone-based TEEs. PDRIMA systematically analyzes TEE attack surfaces and introduces two in-TEE subsystems: a Secure Monitor Agent (SMA) that performs policy-driven measurement, appraisal, logging, and time-based re-measurement over the TEE kernel, static components, user-TAs, and security-critical system calls; and a Remote Attestation Agent (RAA) that aggregates tamper-evident evidence and exposes a remote attestation protocol for verifying. We analyze PDRIMA's security against identified attack surfaces, implement a prototype on OP-TEE for Raspberry Pi 3B+, and evaluate its performance overhead to indicate its practicability.

</details>


### [53] [Securing the Model Context Protocol: Defending LLMs Against Tool Poisoning and Adversarial Attacks](https://arxiv.org/abs/2512.06556)
*Saeid Jamshidi,Kawser Wazed Nafi,Arghavan Moradi Dakhel,Negar Shahabi,Foutse Khomh,Naser Ezzati-Jivan*

Main category: cs.CR

TL;DR: 모델 컨텍스트 프로토콜(MCP)은 대형 언어 모델이 외부 도구를 통합할 수 있게 하지만, 이로 인해 보안 취약점이 발생한다. 본 연구는 MCP 기반 시스템에 대한 세 가지 유형의 의미 공격을 분석하고, 이를 방어하기 위해 계층적 보안 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: MCP를 통해 대형 언어 모델이 외부 도구와 통합될 수 있으나, 이로 인해 보안상의 간과된 취약점이 존재한다는 점.

Method: 세 가지 유형의 의미 공격을 분석하고, RSA 기반 매니페스트 서명, LLM-on-LLM 의미 검토, 경량 휴리스틱 가드레일을 포함하는 계층적 보안 프레임워크를 제안한다.

Result: GPT-4는 약 71%의 안전하지 않은 도구 호출을 차단하며, DeepSeek는 Shadowing 공격에 가장 높은 저항력을 보이지만 지연이 큼. Llama-3.5는 가장 빠르나 가장 덜 강력하다.

Conclusion: 제안된 프레임워크는 모델 조정이나 내부 수정 없이 안전하지 않은 도구 호출 비율을 줄인다.

Abstract: The Model Context Protocol (MCP) enables Large Language Models to integrate external tools through structured descriptors, increasing autonomy in decision-making, task execution, and multi-agent workflows. However, this autonomy creates a largely overlooked security gap. Existing defenses focus on prompt-injection attacks and fail to address threats embedded in tool metadata, leaving MCP-based systems exposed to semantic manipulation. This work analyzes three classes of semantic attacks on MCP-integrated systems: (1) Tool Poisoning, where adversarial instructions are hidden in tool descriptors; (2) Shadowing, where trusted tools are indirectly compromised through contaminated shared context; and (3) Rug Pulls, where descriptors are altered after approval to subvert behavior. To counter these threats, we introduce a layered security framework with three components: RSA-based manifest signing to enforce descriptor integrity, LLM-on-LLM semantic vetting to detect suspicious tool definitions, and lightweight heuristic guardrails that block anomalous tool behavior at runtime. Through evaluation of GPT-4, DeepSeek, and Llama-3.5 across eight prompting strategies, we find that security performance varies widely by model architecture and reasoning method. GPT-4 blocks about 71 percent of unsafe tool calls, balancing latency and safety. DeepSeek shows the highest resilience to Shadowing attacks but with greater latency, while Llama-3.5 is fastest but least robust. Our results show that the proposed framework reduces unsafe tool invocation rates without model fine-tuning or internal modification.

</details>


### [54] [The Evolution of Agentic AI in Cybersecurity: From Single LLM Reasoners to Multi-Agent Systems and Autonomous Pipelines](https://arxiv.org/abs/2512.06659)
*Vaishali Vinay*

Main category: cs.CR

TL;DR: 사이버 보안에서 에이전틱 AI의 발전과 다양한 발전 세대에 대한 조사입니다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 운영 센터는 멀티 스텝 추론, 도구 기반 분석 및 압박 속 신속한 의사결정에 의존하고 있어, 에이전틱 AI의 필요성이 커지고 있습니다.

Method: 이 연구는 사이버 보안에서 에이전틱 AI의 다섯 세대의 분류 체계를 제시하고, 각 세대의 기능과 위험이 어떻게 변화하는지를 추적합니다.

Result: 세대 간 비교를 통해 추론 깊이, 도구 사용, 기억, 재현성, 안전성 등 핵심 차원을 평가하고, 사이버 지향 에이전트를 평가하는 새로운 기준을 합성합니다.

Conclusion: 사이버 보안 내에서 에이전틱 AI의 형성과 안전하고 신뢰할 수 있는 배포를 보장하기 위해 필요한 사항들을 정리합니다.

Abstract: Cybersecurity has become one of the earliest adopters of agentic AI, as security operations centers increasingly rely on multi-step reasoning, tool-driven analysis, and rapid decision-making under pressure. While individual large language models can summarize alerts or interpret unstructured reports, they fall short in real SOC environments that require grounded data access, reproducibility, and accountable workflows. In response, the field has seen a rapid architectural evolution from single-model helpers toward tool-augmented agents, distributed multi-agent systems, schema-bound tool ecosystems, and early explorations of semi-autonomous investigative pipelines. This survey presents a five-generation taxonomy of agentic AI in cybersecurity. It traces how capabilities and risks change as systems advance from text-only LLM reasoners to multi-agent collaboration frameworks and constrained-autonomy pipelines. We compare these generations across core dimensions - reasoning depth, tool use, memory, reproducibility, and safety. In addition, we also synthesize emerging benchmarks used to evaluate cyber-oriented agents. Finally, we outline the unresolved challenges that accompany this evolution, such as response validation, tool-use correctness, multi-agent coordination, long-horizon reasoning, and safeguards for high-impact actions. Collectively, this work provides a structured perspective on how agentic AI is taking shape within cybersecurity and what is required to ensure its safe and reliable deployment.

</details>


### [55] [Look Twice before You Leap: A Rational Agent Framework for Localized Adversarial Anonymization](https://arxiv.org/abs/2512.06713)
*Donghang Duan,Xu Zheng*

Main category: cs.CR

TL;DR: 이 연구는 LLM 기반 텍스트 익명화에서의 개인 정보 보호와 유용성의 균형을 설명하고, Rational Localized Adversarial Anonymization (RLAA)라는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 텍스트 익명화 프레임워크가 강력한 LLM의 원격 API 서비스에 의존하고, 이로 인해 사용자가 불신하는 제3자에게 데이터를 공개해야 하는 '개인 정보 보호 패러독스'가 발생한다.

Method: 익명화 과정을 한계 개인 정보 획득(MPG)과 한계 유용성 비용(MUC) 간의 균형으로 모델링하며, A-A-A 아키텍처를 특징으로 하는 RLAA라는 완전한 로컬화 및 훈련 없음 프레임워크를 제안한다.

Result: RLAA는 다양한 데이터셋에서 최고의 개인 정보-유용성 균형을 달성하고, 경우에 따라 최신 기술(SoTA)보다 더 나은 성과를 보인다.

Conclusion: RLAA는 비합리적인 전략의 문제를 해결하고, 유용성 붕괴를 방지하는 합리적인 조기 중단 기준을 강제하는 메커니즘을 갖추고 있다.

Abstract: Current LLM-based text anonymization frameworks usually rely on remote API services from powerful LLMs, which creates an inherent "privacy paradox": users must somehow disclose data to untrusted third parties for superior privacy preservation. Moreover, directly migrating these frameworks to local small-scale models (LSMs) offers a suboptimal solution with catastrophic collapse in utility based on our core findings. Our work argues that this failure stems not merely from the capability deficits of LSMs, but from the inherent irrationality of the greedy adversarial strategies employed by current state-of-the-art (SoTA) methods. We model the anonymization process as a trade-off between Marginal Privacy Gain (MPG) and Marginal Utility Cost (MUC), and demonstrate that greedy strategies inevitably drift into an irrational state. To address this, we propose Rational Localized Adversarial Anonymization (RLAA), a fully localized and training-free framework featuring an Attacker-Arbitrator-Anonymizer (A-A-A) architecture. RLAA introduces an arbitrator that acts as a rationality gatekeeper, validating the attacker's inference to filter out feedback providing negligible benefits on privacy preservation. This mechanism enforces a rational early-stopping criterion, and systematically prevents utility collapse. Extensive experiments on different datasets demonstrate that RLAA achieves the best privacy-utility trade-off, and in some cases even outperforms SoTA on the Pareto principle. Our code and datasets will be released upon acceptance.

</details>


### [56] [CKG-LLM: LLM-Assisted Detection of Smart Contract Access Control Vulnerabilities Based on Knowledge Graphs](https://arxiv.org/abs/2512.06846)
*Xiaoqi Li,Hailu Kuang,Wenkai Li,Zongwei Li,Shipeng Ye*

Main category: cs.CR

TL;DR: CKG-LLM은 스마트 계약에서 접근 제어 취약점을 탐지하는 새로운 프레임워크로, 기존 도구보다 뛰어난 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 스마트 계약 분석 방법은 의미 구조 및 제어 논리를 충분히 포착하지 못하는 한계를 가진다.

Method: CKG-LLM은 대형 언어 모델의 추론 및 코드 생성 능력을 활용하여 자연어 취약점 패턴을 계약 지식 그래프에 대한 실행 가능한 쿼리로 변환한다.

Result: CKG-LLM은 기존 도구들보다 접근 제어 취약점을 탐지하는 데 있어 우수한 성능을 발휘한다.

Conclusion: CKG-LLM의 잠재적 확장을 논의하며 향후 연구 방향에 대해 이야기한다.

Abstract: Traditional approaches for smart contract analysis often rely on intermediate representations such as abstract syntax trees, control-flow graphs, or static single assignment form. However, these methods face limitations in capturing both semantic structures and control logic. Knowledge graphs, by contrast, offer a structured representation of entities and relations, enabling richer intermediate abstractions of contract code and supporting the use of graph query languages to identify rule-violating elements. This paper presents CKG-LLM, a framework for detecting access-control vulnerabilities in smart contracts. Leveraging the reasoning and code generation capabilities of large language models, CKG-LLM translates natural-language vulnerability patterns into executable queries over contract knowledge graphs to automatically locate vulnerable code elements. Experimental evaluation demonstrates that CKG-LLM achieves superior performance in detecting access-control vulnerabilities compared to existing tools. Finally, we discuss potential extensions of CKG-LLM as part of future research directions.

</details>


### [57] [SoK: Trust-Authorization Mismatch in LLM Agent Interactions](https://arxiv.org/abs/2512.06914)
*Guanquan Shi,Haohua Du,Zhiqiang Wang,Xiaoyu Liang,Weiwenpei Liu,Song Bian,Zhenyu Guan*

Main category: cs.CR

TL;DR: 대형 언어 모델(LLMs)이 외부 세계와의 상호작용을 통해 자율 에이전트로 발전해가고 있지만, 이러한 변화는 전통적인 사이버 보안 문제를 새롭게 부각시킨다.


<details>
  <summary>Details</summary>
Motivation: 자율 에이전트의 수요 증대와 전통적인 보안 메커니즘의 한계 인식

Method: 신뢰-권한 격차를 중심으로 한 새로운 위험 분석 모델 제안 및 기존 공격과 방어 메커니즘 분류

Result: 기존 에이전트 상호작용 보안의 위협을 신뢰 평가와 권한 정책 간의 불일치로 설명하고, 이를 해결하기 위한 새로운 연구 방향 제시

Conclusion: 강력하고 신뢰할 수 있는 에이전트와 동적 권한 부여 메커니즘 구축을 위한 체계적인 연구 방향 제공

Abstract: Large Language Models (LLMs) are rapidly evolving into autonomous agents capable of interacting with the external world, significantly expanding their capabilities through standardized interaction protocols. However, this paradigm revives the classic cybersecurity challenges of agency and authorization in a novel and volatile context. As decision-making shifts from deterministic code logic to probabilistic inference driven by natural language, traditional security mechanisms designed for deterministic behavior fail. It is fundamentally challenging to establish trust for unpredictable AI agents and to enforce the Principle of Least Privilege (PoLP) when instructions are ambiguous. Despite the escalating threat landscape, the academic community's understanding of this emerging domain remains fragmented, lacking a systematic framework to analyze its root causes. This paper provides a unifying formal lens for agent-interaction security.
  We observed that most security threats in this domain stem from a fundamental mismatch between trust evaluation and authorization policies. We introduce a novel risk analysis model centered on this trust-authorization gap. Using this model as a unifying lens, we survey and classify the implementation paths of existing, often seemingly isolated, attacks and defenses. This new framework not only unifies the field but also allows us to identify critical research gaps. Finally, we leverage our analysis to suggest a systematic research direction toward building robust, trusted agents and dynamic authorization mechanisms.

</details>


### [58] [Breaking ECDSA with Electromagnetic Side-Channel Attacks: Challenges and Practicality on Modern Smartphones](https://arxiv.org/abs/2512.07292)
*Felix Oberhansl,Marc Schink,Nisha Jacob Kabakci,Michael Gruber,Dominik Klein,Sven Freud,Tobias Damm,Michael Hartmeier,Ivan Gavrilan,Silvan Streit,Jonas Stappenbeck,Andreas Seelos Zankl*

Main category: cs.CR

TL;DR: 이 논문은 현대 스마트폰의 전자기 사이드 채널 분석(Electromagnetic Side-Channel Analysis, EM SCA)의 실행 가능성을 평가하며, 특히 ECDSA 소프트웨어 구현의 취약성과 보안 요소의 필요성을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: EUDI 지갑과 같은 현대 스마트폰에서의 중요한 전자적 신원 확인 지원 가능성에 대한 관심이 높아지고 있으나, 스마트폰의 물리적 사이드 채널 분석 취약성에 대한 연구가 부족합니다.

Method: 라즈베리 파이 4와 스냅드래곤 750G 5G SoC를 탑재한 페어폰 4에서 EM SCA의 실행 가능성을 평가하고, Alam et al.(Euro S&P 2021)의 Nonce@Once 공격을 통해 OpenSSL에서 ECDSA 비밀을 복구하여 libgcrypt의 방어가 완전하지 않음을 입증합니다.

Result: 우리는 Android 암호 구현의 사례 연구를 제시하고 공격 평가를 위한 대표적인 위협 모델을 정의하였으며, ECDSA 소프트웨어 구현의 취약성을 발견하고 모든 스마트폰에서 독립 인증을 받은 안전 요소의 필요성을 강조합니다.

Conclusion: 이 연구는 스마트폰에서 ECDSA 구현의 보안 취약성을 드러내어, 자격을 갖춘 안전 요소의 통합 필요성을 부각시킵니다.

Abstract: Smartphones handle sensitive tasks such as messaging and payment and may soon support critical electronic identification through initiatives such as the European Digital Identity (EUDI) wallet, currently under development. Yet the susceptibility of modern smartphones to physical side-channel analysis (SCA) is underexplored, with recent work limited to pre-2019 hardware. Since then, smartphone system on chip (SoC) platforms have grown more complex, with heterogeneous processor clusters, sub 10 nm nodes, and frequencies over 2 GHz, potentially complicating SCA. In this paper, we assess the feasibility of electromagnetic (EM) SCA on a Raspberry Pi 4, featuring a Broadcom BCM2711 SoC and a Fairphone 4 featuring a Snapdragon 750G 5G SoC. Using new attack methodologies tailored to modern SoCs, we recover ECDSA secrets from OpenSSL by mounting the Nonce@Once attack of Alam et al. (Euro S&P 2021) and show that the libgcrypt countermeasure does not fully mitigate it. We present case studies illustrating how hardware and software stacks impact EM SCA feasibility. Motivated by use cases such as the EUDI wallet, we survey Android cryptographic implementations and define representative threat models to assess the attack. Our findings show weaknesses in ECDSA software implementations and underscore the need for independently certified secure elements (SEs) in all smartphones.

</details>


### [59] [PrivORL: Differentially Private Synthetic Dataset for Offline Reinforcement Learning](https://arxiv.org/abs/2512.07342)
*Chen Gong,Zheng Liu,Kecen Li,Tianhao Wang*

Main category: cs.CR

TL;DR: 이 논문은 차분 개인정보 보호를 적용하여 오프라인 강화 학습 데이터셋을 합성하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 강화 학습에서 데이터 제공자의 데이터셋을 사용하면서 개인정보 유출에 대한 우려가 커지고 있습니다.

Method: 차분 개인정보 보호(DP)를 활용한 PrivORL이라는 첫 오프라인 데이터셋 합성 방법을 제안합니다. 구체적으로 확산 모델과 확산 변환기를 사용하여 전환 및 경로를 합성합니다.

Result: 다섯 개의 민감한 오프라인 RL 데이터셋에서 우리의 방법이 전환 및 경로 합성에서 더 우수한 유용성과 충실도를 달성함을 보여줍니다.

Conclusion: PrivORL 방법은 안전한 데이터셋을 생성하고, 기계 학습 연구를 위해 사용할 수 있도록 하여 민감한 데이터 보호를 개선합니다.

Abstract: Recently, offline reinforcement learning (RL) has become a popular RL paradigm. In offline RL, data providers share pre-collected datasets -- either as individual transitions or sequences of transitions forming trajectories -- to enable the training of RL models (also called agents) without direct interaction with the environments. Offline RL saves interactions with environments compared to traditional RL, and has been effective in critical areas, such as navigation tasks. Meanwhile, concerns about privacy leakage from offline RL datasets have emerged.
  To safeguard private information in offline RL datasets, we propose the first differential privacy (DP) offline dataset synthesis method, PrivORL, which leverages a diffusion model and diffusion transformer to synthesize transitions and trajectories, respectively, under DP. The synthetic dataset can then be securely released for downstream analysis and research. PrivORL adopts the popular approach of pre-training a synthesizer on public datasets, and then fine-tuning on sensitive datasets using DP Stochastic Gradient Descent (DP-SGD). Additionally, PrivORL introduces curiosity-driven pre-training, which uses feedback from the curiosity module to diversify the synthetic dataset and thus can generate diverse synthetic transitions and trajectories that closely resemble the sensitive dataset. Extensive experiments on five sensitive offline RL datasets show that our method achieves better utility and fidelity in both DP transition and trajectory synthesis compared to baselines. The replication package is available at the GitHub repository.

</details>


### [60] [VulnLLM-R: Specialized Reasoning LLM with Agent Scaffold for Vulnerability Detection](https://arxiv.org/abs/2512.07533)
*Yuzhou Nie,Hongwei Li,Chengquan Guo,Ruizhe Jiang,Zhun Wang,Bo Li,Dawn Song,Wenbo Guo*

Main category: cs.CR

TL;DR: VulnLLM-R는 취약점 탐지를 위한 최초의 전문화된 추론 LLM으로, 프로그램 상태를 이해하고 잠재적 취약점을 분석할 수 있도록 학습되었다.


<details>
  <summary>Details</summary>
Motivation: LLMs가 프로그램 상태를 추론하고 잠재적 취약점을 분석할 수 있다고 보았고, 이를 통해 모델의 일반화 능력을 향상시키고 학습의 지름길을 방지하고자 하였다.

Method: 전문화된 데이터 선택, 추론 데이터 생성, 필터링 및 수정, 테스트 단계 최적화를 포함한 새로운 훈련 방법론을 제안하였다.

Result: VulnLLM-R은 기존의 SOTA 정적 분석 도구 및 오픈 소스 및 상업적 대형 추론 모델보다 효율성과 효과성이 뛰어난 것으로 나타났다.

Conclusion: 전문화된 추론 모델에 의해 구동되는 AI 에이전트를 사용하여 실제 프로젝트 수준에서 취약점을 탐지하는 최초의 노력이 된 이 작업은 CodeQL 및 AFL++보다 우수한 성능을 보여주었다.

Abstract: We propose VulnLLM-R, the~\emph{first specialized reasoning LLM} for vulnerability detection. Our key insight is that LLMs can reason about program states and analyze the potential vulnerabilities, rather than simple pattern matching. This can improve the model's generalizability and prevent learning shortcuts. However, SOTA reasoning LLMs are typically ultra-large, closed-source, or have limited performance in vulnerability detection. To address this, we propose a novel training recipe with specialized data selection, reasoning data generation, reasoning data filtering and correction, and testing-phase optimization. Using our proposed methodology, we train a reasoning model with seven billion parameters. Through extensive experiments on SOTA datasets across Python, C/C++, and Java, we show that VulnLLM-R has superior effectiveness and efficiency than SOTA static analysis tools and both open-source and commercial large reasoning models. We further conduct a detailed ablation study to validate the key designs in our training recipe. Finally, we construct an agent scaffold around our model and show that it outperforms CodeQL and AFL++ in real-world projects. Our agent further discovers a set of zero-day vulnerabilities in actively maintained repositories. This work represents a pioneering effort to enable real-world, project-level vulnerability detection using AI agents powered by specialized reasoning models. The code is available at~\href{https://github.com/ucsb-mlsec/VulnLLM-R}{github}.

</details>


### [61] [Privacy Practices of Browser Agents](https://arxiv.org/abs/2512.07725)
*Alisha Ukani,Hamed Haddadi,Ali Shahin Shamsabadi,Peter Snyder*

Main category: cs.CR

TL;DR: 이 논문은 최근 인기 있는 여덟 개의 브라우저 에이전트의 개인정보 보호 행동과 특성에 대한 체계적인 평가를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 브라우저 에이전트는 웹 브라우징을 자동화하는 소프트웨어로, 강력한 자동화 기능이 있지만 동시에 높은 위험을 동반한다.

Method: 다섯 가지 주요 요소(총 15개 측정항목)를 사용하여 브라우저 에이전트의 개인정보 보호 위험을 측정하는 프레임워크를 제시한다.

Result: 여덟 개의 브라우저 에이전트에 프레임워크를 적용하여, 비활성화된 브라우저 개인정보 보호 기능부터 양식 필드에서 민감한 개인정보를 '자동 완성'하는 것까지 총 30개의 취약점을 확인했다.

Conclusion: 발견된 내용을 책임감 있게 공개하였으며, 데이터 세트 및 기타 자료를 공개할 계획이다.

Abstract: This paper presents a systematic evaluation of the privacy behaviors and attributes of eight recent, popular browser agents. Browser agents are software that automate Web browsing using large language models and ancillary tooling. However, the automated capabilities that make browser agents powerful also make them high-risk points of failure. Both the kinds of tasks browser agents are designed to execute, along with the kinds of information browser agents are entrusted with to fulfill those tasks, mean that vulnerabilities in these tools can result in enormous privacy harm.
  This work presents a framework of five broad factors (totaling 15 distinct measurements) to measure the privacy risks in browser agents. Our framework assesses i. vulnerabilities in the browser agent's components, ii. how the browser agent protects against website behaviors, iii. whether the browser agent prevents cross-site tracking, iv. how the agent responds to privacy-affecting prompts, and v. whether the tool leaks personal information to sites. We apply our framework to eight browser agents and identify 30 vulnerabilities, ranging from disabled browser privacy features to "autocompleting" sensitive personal information in form fields. We have responsibly disclosed our findings, and plan to release our dataset and other artifacts.

</details>


### [62] [An Adaptive Multi-Layered Honeynet Architecture for Threat Behavior Analysis via Deep Learning](https://arxiv.org/abs/2512.07827)
*Lukas Johannes Möller*

Main category: cs.CR

TL;DR: 본 논문은 ADLAH라는 적응형 딥러닝 이상 탐지 허니넷을 소개하며, 자동화된 인프라 조정을 통해 비용을 최소화하면서 고충실도의 위협 정보를 극대화하는 방안을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 위협의 복잡성과 다양성이 증가함에 따라 정적인 허니팟만으로는 불충분하여 적응형, 지능 기반의 기만이 필요하다.

Method: ADLAH는 강화 학습 기법을 사용하여, 저상호작용 센서 노드에서 동적으로 프로비저닝된 고상호작용 허니팟으로 세션을 실시간으로 에스컬레이션하는 중앙 결정 메커니즘의 프로토타입을 개발하였다.

Result: 프로토타입의 작동 가능성 및 하이브리드 아키텍처에서 디자인 트레이드오프와 한계를 논의하였으며, 대규모 실제 평가를 위한 체계적인 로드맵을 제시하였다.

Conclusion: 자율적 데이터 탐지, 자동화된 공격 사슬 추출 및 클러스터링을 통해 고비용 효율적인 적대 행동 포착 및 실행 가능한 위협 정보 생성을 목표로 한다.

Abstract: The escalating sophistication and variety of cyber threats have rendered static honeypots inadequate, necessitating adaptive, intelligence-driven deception. In this work, ADLAH is introduced: an Adaptive Deep Learning Anomaly Detection Honeynet designed to maximize high-fidelity threat intelligence while minimizing cost through autonomous orchestration of infrastructure. The principal contribution is offered as an end-to-end architectural blueprint and vision for an AI-driven deception platform. Feasibility is evidenced by a functional prototype of the central decision mechanism, in which a reinforcement learning (RL) agent determines, in real time, when sessions should be escalated from low-interaction sensor nodes to dynamically provisioned, high-interaction honeypots. Because sufficient live data were unavailable, field-scale validation is not claimed; instead, design trade-offs and limitations are detailed, and a rigorous roadmap toward empirical evaluation at scale is provided. Beyond selective escalation and anomaly detection, the architecture pursues automated extraction, clustering, and versioning of bot attack chains, a core capability motivated by the empirical observation that exposed services are dominated by automated traffic. Together, these elements delineate a practical path toward cost-efficient capture of high-value adversary behavior, systematic bot versioning, and the production of actionable threat intelligence.

</details>
