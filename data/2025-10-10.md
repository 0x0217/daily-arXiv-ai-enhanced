<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 19]
- [cs.LG](#cs.LG) [Total: 19]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CR](#cs.CR) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences](https://arxiv.org/abs/2510.07276)
*Pulkit Rustagi,Kyle Hollins Wray,Sandhya Saisubramanian*

Main category: cs.AI

TL;DR: 본 논문에서는 다중 목표 다중 에이전트 경로 찾기(MO-MAPF) 문제를 해결하기 위한 새로운 접근법인 LCBS(렉시코그래픽 충돌 기반 탐색)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 MO-MAPF 알고리즘은 사용자 정의 선호도를 최적화하지 못하며, 목표의 수가 증가함에 따라 성능이 저하된다.

Method: 렉시코그래픽 선호도를 기반으로 하는 LCBS 알고리즘은 충돌 기반 탐색을 통합하여 효율적인 계획을 가능하게 한다.

Result: LCBS는 최대 10개의 목표를 가진 인스턴스에서도 최적의 솔루션을 계산할 수 있음을 실증적으로 입증하였다.

Conclusion: 기존 MO-MAPF 방법의 한계를 넘어서는 성능 향상을 보여준다.

Abstract: Many real-world scenarios require multiple agents to coordinate in shared
environments, while balancing trade-offs between multiple, potentially
competing objectives. Current multi-objective multi-agent path finding
(MO-MAPF) algorithms typically produce conflict-free plans by computing Pareto
frontiers. They do not explicitly optimize for user-defined preferences, even
when the preferences are available, and scale poorly with the number of
objectives. We propose a lexicographic framework for modeling MO-MAPF, along
with an algorithm \textit{Lexicographic Conflict-Based Search} (LCBS) that
directly computes a single solution aligned with a lexicographic preference
over objectives. LCBS integrates a priority-aware low-level $A^*$ search with
conflict-based search, avoiding Pareto frontier construction and enabling
efficient planning guided by preference over objectives. We provide insights
into optimality and scalability, and empirically demonstrate that LCBS computes
optimal solutions while scaling to instances with up to ten objectives -- far
beyond the limits of existing MO-MAPF methods. Evaluations on standard and
randomized MAPF benchmarks show consistently higher success rates against
state-of-the-art baselines, especially with increasing number of objectives.

</details>


### [2] [AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning](https://arxiv.org/abs/2510.06261)
*Zhanke Zhou,Chentao Cao,Xiao Feng,Xuan Li,Zongze Li,Xiangyu Lu,Jiangchao Yao,Weikai Huang,Linrui Xu,Tian Cheng,Guanyu Jiang,Yiming Zheng,Brando Miranda,Tongliang Liu,Sanmi Koyejo,Masashi Sugiyama,Bo Han*

Main category: cs.AI

TL;DR: AlphaApollo는 자가 진화 에이전트적 추론 시스템으로, 긴급한 모델 내재 능력과 신뢰성 있는 테스트 시간 반복 문제를 해결하는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 기존 기초 모델(FM) 추론의 한계인 내재 용량과 신뢰성 부족한 테스트 시간 반복을 해결하고자 한다.

Method: 다수의 모델과 전문 도구를 조화롭게 운용하여 신중하고 검증 가능한 추론을 가능하게 한다. 계산 도구(Python과 수치 및 기호 라이브러리)와 검색 도구(과제 관련 외부 정보)를 결합하여 정확한 계산을 수행하고 결정을 내린다.

Result: AlphaApollo는 다양한 모델에 대한 AIME 2024/2025 평가에서 일관된 향상을 보여준다: Qwen2.5-14B-Instruct의 경우 +5.15% Average@32 및 +23.34% Pass@32, Llama-3.3-70B-Instruct의 경우 +8.91% Average@32 및 +26.67% Pass@32이다.

Conclusion: 80% 이상의 도구 호출이 성공적으로 실행되며, 비도구 기준선을 지속적으로 초과하여 FM의 능력 한계를 확장하고 있다.

Abstract: We present AlphaApollo, a self-evolving agentic reasoning system that aims to
address two bottlenecks in foundation model (FM) reasoning-limited
model-intrinsic capacity and unreliable test-time iteration. AlphaApollo
orchestrates multiple models with professional tools to enable deliberate,
verifiable reasoning. It couples (i) a computation tool (Python with numerical
and symbolic libraries) and (ii) a retrieval tool (task-relevant external
information) to execute exact calculations and ground decisions. The system
further supports multi-round, multi-model solution evolution via a shared state
map that records candidates, executable checks, and feedback for iterative
refinement. In evaluations on AIME 2024/2025 across multiple models,
AlphaApollo delivers consistent gains: +5.15% Average@32 and +23.34% Pass@32
for Qwen2.5-14B-Instruct, and +8.91% Average@32 with +26.67% Pass@32 for
Llama-3.3-70B-Instruct. Tool-use analysis shows that more than 80% of tool
calls are successfully executed, with consistent outperformance of non-tool
baselines, thereby lifting the capability ceiling of FMs. More empirical
results and implementation details will be updated at
https://github.com/tmlr-group/AlphaApollo.

</details>


### [3] [BuilderBench -- A benchmark for generalist agents](https://arxiv.org/abs/2510.06288)
*Raj Ghugare,Catherine Ji,Kathryn Wantlin,Jin Schofield,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: 이 연구는 오픈 엔디드 탐색을 중심으로 한 에이전트 사전 훈련을 가속화하기 위한 벤치마크인 BuilderBench를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 현재 AI 모델은 기존 데이터의 한계에 의해 문제 해결에 어려움을 겪고 있으며, 새로운 문제를 해결하기 위해 경험을 통한 탐색 및 학습 기술을 습득해야 합니다.

Method: BuilderBench는 다양한 물리 블록과 상호작용하는 로봇 에이전트의 하드웨어 가속 시뮬레이터와 물리학, 수학, 장기 계획에 대한 이해를 테스트하기 위해 신중하게 선별된 42개 이상의 다양한 목표 구조로 구성된 작업 세트를 제공합니다.

Result: 훈련 동안 에이전트는 외부 감독 없이 환경에 대한 일반 원칙을 탐색하고 학습해야 하며, 평가 중에는 작업 세트에서 보이지 않는 목표 구조를 구축해야 합니다. 많은 작업이 현재 알고리즘의 반복을 도전하게 만듭니다.

Conclusion: 에이전트를 통해 단일 목표 구조를 구축하도록 교육하고 평가하는 '훈련 바퀴' 프로토콜을 제공하며, 연구자들을 위한 여섯 가지 다양한 알고리즘의 단일 파일 구현을 제공합니다.

Abstract: Today's AI models learn primarily through mimicry and sharpening, so it is
not surprising that they struggle to solve problems beyond the limits set by
existing data. To solve novel problems, agents should acquire skills for
exploring and learning through experience. Finding a scalable learning
mechanism for developing agents that learn through interaction remains a major
open problem. In this work, we introduce BuilderBench, a benchmark to
accelerate research into agent pre-training that centers open-ended
exploration. BuilderBench requires agents to learn how to build any structure
using blocks. BuilderBench is equipped with $(1)$ a hardware accelerated
simulator of a robotic agent interacting with various physical blocks, and
$(2)$ a task-suite with over 42 diverse target structures that are carefully
curated to test an understanding of physics, mathematics, and long-horizon
planning. During training, agents have to explore and learn general principles
about the environment without any external supervision. During evaluation,
agents have to build the unseen target structures from the task suite. Solving
these tasks requires a sort of \emph{embodied reasoning} that is not reflected
in words but rather in actions, experimenting with different strategies and
piecing them together. Our experiments show that many of these tasks challenge
the current iteration of algorithms. Hence, we also provide a ``training
wheels'' protocol, in which agents are trained and evaluated to build a single
target structure from the task suite. Finally, we provide single-file
implementations of six different algorithms as a reference point for
researchers.

</details>


### [4] [Requirements for Game-Based Learning Design Framework for Information System Integration in the Context of Post-Merger Integration](https://arxiv.org/abs/2510.06302)
*Ksenija Lace,Marite Kirikova*

Main category: cs.AI

TL;DR: 합병 후 통합에서 정보 시스템 통합의 도전과제 해결을 위한 게임 기반 학습 설계의 필요성을 다룬 논문.


<details>
  <summary>Details</summary>
Motivation: 합병 후 통합에서 정보 시스템 통합을 위한 교육의 격차를 해소하고자 함.

Method: 게임 기반 학습 설계를 통해 정적 교육 방법을 매력적인 학습 경험으로 변환하는 방법을 탐구.

Result: 기초 학습 이론, 인지 부하 및 동기 모델, 진지한 게임 설계 프레임워크를 분석하여 정보 시스템 통합을 위한 게임 기반 학습 설계 프레임워크의 필수 요구 사항을 식별함.

Conclusion: 제안된 프레임워크를 반복 설계 및 실제 검증을 통해 개발하고 평가할 계획으로 결론을 내림.

Abstract: Post-merger integration states unique challenges for professionals
responsible for information system integration aimed on alignment and
combination diverse system architectures of merging organizations. Although the
theoretical and practical guidance exists for post-merger integration on the
business level, there is a significant gap in training for information system
integration in this context. In prior research specific methods AMILI (Support
method for informed decision identification) and AMILP (Support method for
informed decision-making) were introduced for the support of information system
integration decisions in the post-merger integration. But during the practical
application was reported high learning curve and low learner motivation. This
paper explores how game-based learning design can address these limitations by
transforming static method training into engaging learning experience. The
study analyzes foundational learning theories, cognitive load and motivation
models, and serious game design frameworks to identify the essential
requirements for a game-based learning design framework tailored to information
system integration in post-merger integration. Requirements are structured in
two components: the transformation process and resulting learning experience.
The paper concludes with a plan for developing and evaluating the proposed
framework through iterative design and real-world validation.

</details>


### [5] [Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks](https://arxiv.org/abs/2510.06307)
*Wentao Deng,Jiahuan Pei,Zhiwei Xu,Zhaochun Ren,Zhumin Chen,Pengjie Ren*

Main category: cs.AI

TL;DR: 이 논문은 다중 에이전트 시스템에서의 합의 도출 메커니즘을 개선하기 위해 최적의 협력자를 선택하는 이론적 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 합의 도출 접근 방식은 투표 메커니즘에 의존하여 내부 신념의 모순을 간과하면서 안정적인 합의의 도출을 방해하고 있다.

Method: 이론에 기반하여 최적의 협력자를 선택하고 시스템 내부 신념에 의해 합의 판단을 보정하는 Belief-Calibrated Consensus Seeking (BCCS) 프레임워크를 제안한다.

Result: MATH 및 MMLU 벤치마크 데이터 셋에서 실험 결과, 제안된 BCCS 프레임워크는 각각 2.23% 및 3.95%의 정확도로 기존의 최상의 결과를 초월한다.

Conclusion: 제안된 방법은 복잡한 자연어 처리 작업에서 안정적인 합의를 이끌어내는 데 효과적이다.

Abstract: A multi-agent system (MAS) enhances its capacity to solve complex natural
language processing (NLP) tasks through collaboration among multiple agents,
where consensus-seeking serves as a fundamental mechanism. However, existing
consensus-seeking approaches typically rely on voting mechanisms to judge
consensus, overlooking contradictions in system-internal beliefs that
destabilize the consensus. Moreover, these methods often involve agents
updating their results through indiscriminate collaboration with every other
agent. Such uniform interaction fails to identify the optimal collaborators for
each agent, hindering the emergence of a stable consensus. To address these
challenges, we provide a theoretical framework for selecting optimal
collaborators that maximize consensus stability. Based on the theorems, we
propose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate
stable consensus via selecting optimal collaborators and calibrating the
consensus judgment by system-internal beliefs. Experimental results on the MATH
and MMLU benchmark datasets demonstrate that the proposed BCCS framework
outperforms the best existing results by 2.23% and 3.95% of accuracy on
challenging tasks, respectively. Our code and data are available at
https://github.com/dengwentao99/BCCS.

</details>


### [6] [Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?](https://arxiv.org/abs/2510.06410)
*Aochong Oliver Li,Tanya Goyal*

Main category: cs.AI

TL;DR: 이 논문은 LLMs의 온전한 추론 능력을 강화하기 위해 다른 모델의 부분적인 사고를 평가하고 활용하는 방법인 오프-트래젝토리 추론의 중요성을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: Reasoning LLMs는 복잡한 작업에서 강한 성과를 내기 위해 자신의 추론 과정을 언어화하도록 훈련됩니다. 이러한 투명성은 협업의 가능성을 열어줍니다.

Method: LMMs를 대상으로 Recoverability와 Guidability를 측정하는 twin tests를 제안하여, 오프-트래젝토리 행동을 평가합니다.

Result: 15개의 LLM을 평가한 결과, 벤치마크에서 '더 강한' LLM이 오히려 더 취약하다는 역설적인 발견이 있었습니다. 모든 모델은 동료의 안내 단계를 효과적으로 활용하지 못했습니다.

Conclusion: 이 연구는 공유된 추론 경로에서 다중 모델 협업을 평가하는 기반을 마련하고, 기존 LLMs의 한계를 강조합니다.

Abstract: Reasoning LLMs are trained to verbalize their reasoning process, yielding
strong gains on complex tasks. This transparency also opens a promising
direction: multiple reasoners can directly collaborate on each other's thinking
within a shared trajectory, yielding better inference efficiency and
exploration. A key prerequisite, however, is the ability to assess the
usefulness and build on another model's partial thinking -- we call this
off-trajectory reasoning. Our paper investigates a critical question: can
standard solo-reasoning training pipelines deliver desired off-trajectory
behaviors? We propose twin tests that capture the two extremes of the
off-trajectory spectrum, namely Recoverability, which tests whether LLMs can
backtrack from "distractions" induced by misleading reasoning traces, and
Guidability, which tests their ability to build upon correct reasoning from
stronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and
reveals a counterintuitive finding -- "stronger" LLMs on benchmarks are often
more fragile under distraction. Moreover, all models tested fail to effectively
leverage guiding steps from collaborators on problems beyond their inherent
capabilities with solve rates remaining under 9.2%. Finally, we conduct control
studies to isolate the effects of three factors in post-training on these
behaviors: the choice of distillation teacher, the use of RL, and data
selection strategy. Our results provide actionable insights for training
natively strong reasoning collaborators; e.g., we find that suboptimal
recoverability behaviors of teacher models are transferred to distilled
students even if the distillation trajectories are correct. Taken together,
this work lays the groundwork for evaluating multi-model collaborations in
shared reasoning trajectories and highlights the limitations of off-the-shelf
reasoning LLMs.

</details>


### [7] [Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them](https://arxiv.org/abs/2510.06534)
*Jiahe Jin,Abhijay Paladugu,Chenyan Xiong*

Main category: cs.AI

TL;DR: 이 논문은 사용자 정보 요구를 해석하고 다단계 프로세스를 통해 답변을 제공하기 위해 대형 언어 모델(LLM)을 활용하는 에이전틱 검색에 대해 연구한다. 효과적인 추론 행동 패턴을 분석하고 행동 프라이밍 기술을 제안하여 에이전틱 검색 모델의 효율성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 검색의 고유한 도전 과제를 LLM의 추론 및 에이전틱 능력을 통해 탐구하기 위해.

Method: LLM 기반 파이프라인을 제안하고, 에이전틱 검색에서 성공적인 궤적을 분석하여 네 가지 유익한 추론 행동(정보 검증, 권위 평가, 적응 검색, 오류 복구)을 식별한다. 이후, 행동 반응(Behavior Priming) 기술을 통해 이러한 행동을 통합한다.

Result: 행동 프라이밍을 사용한 실험은 Llama3.2-3B와 Qwen3-1.7B에서 35% 이상의 성능 향상을 보여준다.

Conclusion: SFT 데이터에서 바람직한 추론 행동의 중요성이 강화된 최종 성과에 결정적인 요소임을 입증하였다. 바람직한 추론 행동이 포함된 궤적에 대한 미세 조정이 올바른 답변이 포함된 궤적에 대한 미세 조정보다 더 나은 성과를 낳았다.

Abstract: Agentic search leverages large language models (LLMs) to interpret complex
user information needs and execute a multi-step process of planning, searching,
and synthesizing information to provide answers. This paradigm introduces
unique challenges for LLMs' reasoning and agentic capabilities when interacting
with retrieval systems and the broader web. In this paper, we propose a
reasoning-driven LLM-based pipeline to study effective reasoning behavior
patterns in agentic search. Using this pipeline, we analyze successful agentic
search trajectories and identify four beneficial reasoning behaviors:
Information Verification, Authority Evaluation, Adaptive Search, and Error
Recovery. Based on these findings, we propose a technique called Behavior
Priming to train more effective agentic search models. It synthesizes agentic
search trajectories that exhibit these four behaviors and integrates them into
the agentic search model through supervised fine-tuning (SFT), followed by
standard reinforcement learning (RL). Experiments on three benchmarks (GAIA,
WebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in
Llama3.2-3B and Qwen3-1.7B compared to directly training agentic search models
with RL. Crucially, we demonstrate that the desired reasoning behaviors in the
SFT data, rather than the correctness of the final answer, is the critical
factor for achieving strong final performance after RL: fine-tuning on
trajectories with desirable reasoning behaviors but incorrect answers leads to
better performance than fine-tuning on trajectories with correct answers. Our
analysis further reveals the underlying mechanism: the introduced reasoning
behaviors endow models with more effective exploration (higher pass@k and
entropy) and test-time scaling (longer trajectories) capabilities, providing a
strong foundation for RL. Our code will be released as open source.

</details>


### [8] [WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks](https://arxiv.org/abs/2510.06587)
*Jingbo Yang,Bairu Hou,Wei Wei,Shiyu Chang,Yujia Bao*

Main category: cs.AI

TL;DR: WebDART는 복잡한 웹 작업을 처리하기 위해 설계된 프레임워크로, LLM이 성공적으로 수행할 수 있도록 돕는다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트들이 간단한 웹 작업에서는 능숙하지만, 긴 탐색, 대규모 정보 추출 및 제약 조건 하 제 reasoning이 필요한 목표에서는 여전히 어려움을 겪고 있다.

Method: WebDART는 각 목표를 탐색, 정보 추출 및 실행의 세 가지 집중 하위 작업으로 동적으로 분해하고, 새로운 웹페이지가 드러날 때마다 지속적으로 재계획한다.

Result: WebDART는 WebChoreArena에서 이전 SOTA 에이전트에 비해 성공률을 최대 13.7% 증가시키며, 더 쉬운 WebArena 스위트에서는 성능을 일치시키고 최대 14.7개의 탐색 단계를 줄여 작업을 완료했다.

Conclusion: WebDART는 LLM이 복잡한 웹 작업을 더 효율적으로 수행할 수 있도록 설계된 강력한 도구이다.

Abstract: Large language model (LLM) agents are becoming competent at straightforward
web tasks, such as opening an item page or submitting a form, but still
struggle with objectives that require long horizon navigation, large scale
information extraction, and reasoning under constraints. We present WebDART, a
general framework that enables a single LLM to handle such complex chores.
WebDART (i) dynamically decomposes each objective into three focused subtasks:
navigation, information extraction, and execution, so the model concentrates on
one skill at a time, and (ii) continuously replans the decomposition as new
webpages are revealed, taking advantage of newly discovered filters or
shortcuts and avoiding redundant exploration. Evaluated on WebChoreArena,
WebDART lifts success rates by up to 13.7 percentage points over previous SOTA
agents, while matching their performance on the easier WebArena suite and
completing tasks with up to 14.7 fewer navigation steps.

</details>


### [9] [Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support](https://arxiv.org/abs/2510.06674)
*Cen Mia Zhao,Tiantian Zhang,Hanchen Su,Yufeng Wayne Zhang,Shaowei Su,Mingzhi Xu,Yu Elaine Liu,Wei Han,Jeremy Werner,Claire Na Cheng,Yashar Mehdad*

Main category: cs.AI

TL;DR: Agent-in-the-Loop(AITL) 프레임워크를 통해 LLM 기반 고객 지원 시스템의 지속적인 데이터 개선이 가능해졌다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 고객 지원 시스템의 지속적인 개선을 위해 human feedback을 통합할 필요가 있다.

Method: AITL은 고객 운영 중 실시간으로 네 가지 유형의 주석을 통합하여 피드백을 모델 업데이트에 적용한다.

Result: 미국 고객 지원 에이전트를 위한 파일럿 테스트에서 검색 정확도(+11.7%), 생성 품질(+8.4% 유용성) 및 에이전트 채택률(+4.5%)에서 유의미한 개선이 있었다.

Conclusion: 인간 피드백 루프를 운영 워크플로우에 직접 통합하는 것이 LLM 기반 고객 지원 시스템을 지속적으로 개선하는 데 효과적임을 보여준다.

Abstract: We introduce an Agent-in-the-Loop (AITL) framework that implements a
continuous data flywheel for iteratively improving an LLM-based customer
support system. Unlike standard offline approaches that rely on batch
annotations, AITL integrates four key types of annotations directly into live
customer operations: (1) pairwise response preferences, (2) agent adoption and
rationales, (3) knowledge relevance checks, and (4) identification of missing
knowledge. These feedback signals seamlessly feed back into models' updates,
reducing retraining cycles from months to weeks. Our production pilot involving
US-based customer support agents demonstrated significant improvements in
retrieval accuracy (+11.7% recall@75, +14.8% precision@8), generation quality
(+8.4% helpfulness) and agent adoption rates (+4.5%). These results underscore
the effectiveness of embedding human feedback loops directly into operational
workflows to continuously refine LLM-based customer support system.

</details>


### [10] [Inefficiencies of Meta Agents for Agent Design](https://arxiv.org/abs/2510.06711)
*Batu El,Mert Yuksekgonul,James Zou*

Main category: cs.AI

TL;DR: 이 논문은 메타 에이전트를 이용한 에이전틱 시스템 자동 설계의 세 가지 주요 문제를 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 시스템의 설계를 자동화하기 위한 메타 에이전트의 사용이 증가하고 있습니다.

Method: 메타 에이전트가 반복 학습하는 방법을 연구하고, 진화적 접근 방식을 통해 성능을 개선했습니다.

Result: 테스트 시 메타 에이전트가 단일 에이전트에 집중하는 경향과 설계된 에이전트의 행동 다양성이 낮음을 확인했습니다.

Conclusion: 자동 설계가 경제적으로 실행 가능한 경우는 얼마 되지 않으며, 특정 데이터셋에서만 인간 설계 에이전트보다 저렴한 것으로 나타났습니다.

Abstract: Recent works began to automate the design of agentic systems using
meta-agents that propose and iteratively refine new agent architectures. In
this paper, we examine three key challenges in a common class of meta-agents.
First, we investigate how a meta-agent learns across iterations and find that
simply expanding the context with all previous agents, as proposed by previous
works, performs worse than ignoring prior designs entirely. We show that the
performance improves with an evolutionary approach. Second, although the
meta-agent designs multiple agents during training, it typically commits to a
single agent at test time. We find that the designed agents have low behavioral
diversity, limiting the potential for their complementary use. Third, we assess
when automated design is economically viable. We find that only in a few
cases--specifically, two datasets--the overall cost of designing and deploying
the agents is lower than that of human-designed agents when deployed on over
15,000 examples. In contrast, the performance gains for other datasets do not
justify the design cost, regardless of scale.

</details>


### [11] [MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models](https://arxiv.org/abs/2510.06742)
*Ali Sarabadani,Kheirolah Rahsepar Fard*

Main category: cs.AI

TL;DR: 이 논문에서는 생물 의학 및 인지 과학에서 대규모 언어 모델을 활용한 새로운 지식 그래프 통합 프레임워크인 MultiCNKG를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 기계 학습 방법의 한계를 극복하고 유전자, 질병, 인지 과정 간의 복잡한 의미적 연결을 포착하기 위한 필요성.

Method: Cognitive Neuroscience Knowledge Graph, Gene Ontology, Disease Ontology 세 가지 핵심 지식 소스를 통합하여 MultiCNKG를 설계하고, LLM을 사용해 개체 정렬, 의미 유사성 계산 및 그래프 증강을 수행했습니다.

Result: 최종 MultiCNKG는 6.9K개의 노드와 11.3K개의 엣지를 포함하며, 여러 메트릭을 통해 강력성과 일관성을 확인했습니다.

Conclusion: 이 지식 그래프는 개인 맞춤형 의학, 인지 장애 진단 및 인지 신경 과학에서의 가설 제시에 기여할 수 있습니다.

Abstract: The advent of large language models (LLMs) has revolutionized the integration
of knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming
limitations in traditional machine learning methods for capturing intricate
semantic links among genes, diseases, and cognitive processes. We introduce
MultiCNKG, an innovative framework that merges three key knowledge sources: the
Cognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges
across 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes
and 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO)
comprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types.
Leveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity
computation, and graph augmentation to create a cohesive KG that interconnects
genetic mechanisms, neurological disorders, and cognitive functions. The
resulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes,
Diseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes,
Associated with, Regulates), facilitating a multi-layered view from molecular
to behavioral domains. Assessments using metrics such as precision (85.20%),
recall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty
detection (40.28%), and expert validation (89.50%) affirm its robustness and
coherence. Link prediction evaluations with models like TransE (MR: 391, MRR:
0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against
benchmarks like FB15k-237 and WN18RR. This KG advances applications in
personalized medicine, cognitive disorder diagnostics, and hypothesis
formulation in cognitive neuroscience.

</details>


### [12] [Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration](https://arxiv.org/abs/2510.06761)
*Zhi Zhang,Yan Liu,Zhejing Hu,Gong Chen,Sheng-hua Zhong,Jiannong Cao*

Main category: cs.AI

TL;DR: DLMA 프레임워크를 통해 자동으로 과학 연구 과정을 해결하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 과학 연구 과정의 자동화는 새로운 고수준 계획을 발전시키고 이를 동적이고 불확실한 조건 속에서 올바르게 실행하는 것이 필수적이다.

Method: DLMA 프레임워크는 교수 에이전트로 구성된 리더 루프와 박사 과정 학생 에이전트로 구성된 팔로워 루프를 통해 연구 계획을 발전시키고 실행한다.

Result: DLMA는 ACLAward 및 Laboratory와 같은 벤치마크에서 최첨단 점수를 달성하는 연구 논문을 생성하며 강력한 기준선을 크게 초과하는 성과를 보였다.

Conclusion: 진화가 독창성을 불러일으키고 실행이 건전성을 보장하는 두 루프의 중요성을 확인했다.

Abstract: Automating the end-to-end scientific research process poses a fundamental
challenge: it requires both evolving high-level plans that are novel and sound,
and executing these plans correctly amidst dynamic and uncertain conditions. To
address this bilevel challenge, we propose a novel Double-Loop Multi-Agent
(DLMA) framework to solve the given research problem automatically. The leader
loop, composed of professor agents, is responsible for evolving research plans.
It employs an evolutionary algorithm through involvement, improvement, and
integration meetings to iteratively generate and refine a pool of research
proposals, exploring the solution space effectively. The follower loop,
composed of doctoral student agents, is responsible for executing the
best-evolved plan. It dynamically adjusts the plan during implementation via
pre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is
well-supported by contextual and external observations. Extensive experiments
on benchmarks like ACLAward and Laboratory show that DLMA generates research
papers that achieve state-of-the-art scores in automated evaluation,
significantly outperforming strong baselines. Ablation studies confirm the
critical roles of both loops, with evolution driving novelty and execution
ensuring soundness.

</details>


### [13] [LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with AJAN](https://arxiv.org/abs/2510.06911)
*Hacane Hechehouche,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: AJAN 프레임워크는 다중 에이전트 시스템을 설계하기 위해 통합 개발 환경을 제공하며, 에이전트 모델링의 어려움을 극복하고 사용자 커뮤니티를 확장할 수 있는 가능성을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AJAN 프레임워크의 에이전트 모델링을 위한 장벽을 극복하고, 더 넓은 사용자 커뮤니티를 형성하기 위함이다.

Method: AJAN 에이전트를 모델링하기 위한 통합 개발 환경을 제시하고 대규모 언어 모델을 활용하는 방법을 구현한다.

Result: 모델링의 어려움을 덜고, 사용자들이 AJAN을 통해 보다 효과적으로 에이전트를 설계할 수 있도록 지원한다.

Conclusion: 제안된 개발 환경은 에이전트 모델링의 단점을 해결하고 사용자 커뮤니티의 확장을 촉진할 수 있는 잠재력을 갖는다.

Abstract: There are many established semantic Web standards for implementing
multi-agent driven applications. The AJAN framework allows to engineer
multi-agent systems based on these standards. In particular, agent knowledge is
represented in RDF/RDFS and OWL, while agent behavior models are defined with
Behavior Trees and SPARQL to access and manipulate this knowledge. However, the
appropriate definition of RDF/RDFS and SPARQL-based agent behaviors still
remains a major hurdle not only for agent modelers in practice. For example,
dealing with URIs is very error-prone regarding typos and dealing with complex
SPARQL queries in large-scale environments requires a high learning curve. In
this paper, we present an integrated development environment to overcome such
hurdles of modeling AJAN agents and at the same time to extend the user
community for AJAN by the possibility to leverage Large Language Models for
agent engineering.

</details>


### [14] [Prompt Optimization Across Multiple Agents for Representing Diverse Human Populations](https://arxiv.org/abs/2510.07064)
*Manh Hung Nguyen,Sebastian Tschiatschek,Adish Singla*

Main category: cs.AI

TL;DR: 이 논문은 여러 개의 LLM 에이전트를 구성하여 인간 집단의 다양성을 포착하는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 인간 행동의 다양성을 충분히 반영하지 못한다는 문제를 해결하기 위해.

Method: 소수의 인간 시연을 기반으로 한 LLM 에이전트를 사용하여 하위 모듈 최적화 관점에서 대표적인 에이전트 세트를 선택합니다.

Result: 제안된 접근 방식이 기존 방법들에 비해 인간 집단을 더 효과적으로 대표하는 에이전트를 구성함을 입증했습니다.

Conclusion: 이 에이전트들이 설계된 대로 학생들과 주석자들의 행동 패턴과 관점을 잘 재현함을 보여주었습니다.

Abstract: The difficulty and expense of obtaining large-scale human responses make
Large Language Models (LLMs) an attractive alternative and a promising proxy
for human behavior. However, prior work shows that LLMs often produce
homogeneous outputs that fail to capture the rich diversity of human
perspectives and behaviors. Thus, rather than trying to capture this diversity
with a single LLM agent, we propose a novel framework to construct a set of
agents that collectively capture the diversity of a given human population.
Each agent is an LLM whose behavior is steered by conditioning on a small set
of human demonstrations (task-response pairs) through in-context learning. The
central challenge is therefore to select a representative set of LLM agents
from the exponentially large space of possible agents. We tackle this selection
problem from the lens of submodular optimization. In particular, we develop
methods that offer different trade-offs regarding time complexity and
performance guarantees. Extensive experiments in crowdsourcing and educational
domains demonstrate that our approach constructs agents that more effectively
represent human populations compared to baselines. Moreover, behavioral
analyses on new tasks show that these agents reproduce the behavior patterns
and perspectives of the students and annotators they are designed to represent.

</details>


### [15] [VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems](https://arxiv.org/abs/2510.07073)
*André Hottung,Federico Berto,Chuanbo Hua,Nayeli Gast Zepeda,Daniel Wetzel,Michael Römer,Haoran Ye,Davide Zago,Michael Poli,Stefano Massaroli,Jinkyoo Park,Kevin Tierney*

Main category: cs.AI

TL;DR: VRPAgent는 LLM 기반 코드 생성과 유전적 검색을 통합하여 차량 경로 문제 해결을 위한 효율적인 휴리스틱을 개발하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 차량 경로 문제(VRP)의 고성능 휴리스틱을 설계하는 것은 복잡한 작업이며, 기존의 LLM 기반 코드 생성이 인간 전문가가 만든 휴리스틱에 미치지 못한다.

Method: VRPAgent는 LLM으로 생성된 문제 특정 연산자를 일반 메타휴리스틱 프레임워크에 통합하고, 새로운 유전적 검색을 통해 이를 정제하는 방법이다.

Result: 우리의 방법은 용량 제약 VRP, 시간 제한이 있는 VRP, 상금 수집 VRP를 포함한 여러 문제에서 수작업 방법과 최근의 학습 기반 접근 방식을 능가하는 휴리스틱 연산자를 발견하였다.

Conclusion: VRPAgent는 VRP 분야에서 최신 기술을 발전시키는 첫 번째 LLM 기반 패러다임으로, 자동화된 휴리스틱 발견의 유망한 미래를 강조한다.

Abstract: Designing high-performing heuristics for vehicle routing problems (VRPs) is a
complex task that requires both intuition and deep domain knowledge. Large
language model (LLM)-based code generation has recently shown promise across
many domains, but it still falls short of producing heuristics that rival those
crafted by human experts. In this paper, we propose VRPAgent, a framework that
integrates LLM-generated components into a metaheuristic and refines them
through a novel genetic search. By using the LLM to generate problem-specific
operators, embedded within a generic metaheuristic framework, VRPAgent keeps
tasks manageable, guarantees correctness, and still enables the discovery of
novel and powerful strategies. Across multiple problems, including the
capacitated VRP, the VRP with time windows, and the prize-collecting VRP, our
method discovers heuristic operators that outperform handcrafted methods and
recent learning-based approaches while requiring only a single CPU core. To our
knowledge, \VRPAgent is the first LLM-based paradigm to advance the
state-of-the-art in VRPs, highlighting a promising future for automated
heuristics discovery.

</details>


### [16] [The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas](https://arxiv.org/abs/2510.07091)
*Baixuan Xu,Tianshi Zheng,Zhaowei Wang,Hong Ting Tsang,Weiqi Wang,Tianqing Fang,Yangqiu Song*

Main category: cs.AI

TL;DR: 이 논문은 장기 계획과 여러 상호작용을 요구하는 작업에서 대형 언어 모델(LLMs)을 효과적으로 운영하는 방법을 제시합니다. 전통적인 방식인 행동 계획(PwA)과 행동 스키마 계획(PwS)을 비교하고, 각각의 장단점을 분석하여 스케일 가능한 작업 표현을 위한 최적의 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 오픈 월드 자율성을 위한 장기 계획과 여러 상호작용을 요구하는 작업에서 LLMs의 효과적인 작동이 필수적입니다.

Method: 행동 계획(PwA)과 행동 스키마 계획(PwS)이라는 두 가지 다른 행동 표현의 효과성을 체계적으로 연구하고, 주어진 환경의 행동 공간에 대해 최적의 행동 표현을 이해하기 위한 인지 대역폭 관점을 제안합니다.

Result: 행동 표현 선택의 변곡점을 ALFWorld(약 35개 액션)과 SciWorld(약 500개 액션) 간에 관찰하였고, 이 결과는 스케일 가능한 표현의 필요성을 증명합니다.

Conclusion: PwS 에이전트의 성능이 최적이 아님을 주목하며, 더 나은 스케일 가능한 자율성을 위해 더 역량 있는 PwS 에이전트를 구축하기 위한 실행 가능한 가이드를 제공합니다.

Abstract: Enabling LLMs to effectively operate long-horizon task which requires
long-term planning and multiple interactions is essential for open-world
autonomy. Conventional methods adopt planning with actions where a executable
action list would be provided as reference. However, this action representation
choice would be impractical when the environment action space is combinatorial
exploded (e.g., open-ended real world). This naturally leads to a question: As
environmental action space scales, what is the optimal action representation
for long-horizon agents? In this paper, we systematically study the
effectiveness of two different action representations. The first one is
conventional planning with actions (PwA) which is predominantly adopted for its
effectiveness on existing benchmarks. The other one is planning with schemas
(PwS) which instantiate an action schema into action lists (e.g., "move [OBJ]
to [OBJ]" -> "move apple to desk") to ensure concise action space and reliable
scalability. This alternative is motivated by its alignment with human
cognition and its compliance with environment-imposed action format
restriction. We propose cognitive bandwidth perspective as a conceptual
framework to qualitatively understand the differences between these two action
representations and empirically observe a representation-choice inflection
point between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve
as evidence of the need for scalable representations. We further conduct
controlled experiments to study how the location of this inflection point
interacts with different model capacities: stronger planning proficiency shifts
the inflection rightward, whereas better schema instantiation shifts it
leftward. Finally, noting the suboptimal performance of PwS agents, we provide
an actionable guide for building more capable PwS agents for better scalable
autonomy.

</details>


### [17] [The Contingencies of Physical Embodiment Allow for Open-Endedness and Care](https://arxiv.org/abs/2510.07117)
*Leonardo Christov-Moore,Arthur Juliani,Alex Kiefer,Nicco Reggente,B. Scott Rousse,Adam Safron,Nicol'as Hinrichs,Daniel Polani,Antonio Damasio*

Main category: cs.AI

TL;DR: 이 논문은 물리적 존재의 최소 조건을 정의하고, 이를 바탕으로 인공지능 에이전트가 생존과 돌봄을 수행할 수 있는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 인간과 같은 물리적 존재가 개방적 환경에서 생존하고 상호 돌봄을 하는 방식을 이해함으로써, 보다 견고하고 적응력 있는 인공지능 에이전트를 개발할 수 있다.

Method: 마르틴 하이데거의 존재론적 현상학에서 영감을 받아, '세계 속 존재'와 '죽음에 대한 존재'라는 두 가지 최소 조건을 정의하고, 이를 강화 학습 프레임워크 내에서 정형화한다.

Result: 이 논문에서 제안한 조건을 기반으로 에이전트가 생리적 요구를 충족하며 신체적 통합성을 유지할 수 있는 확률을 증가시킬 수 있음을 보인다.

Conclusion: 물리적 존재를 가진 에이전트가 개방적 다중 에이전트 환경에서 학습함으로써 개방성 및 돌봄의 능력을 순화할 수 있음을 제시한다.

Abstract: Physical vulnerability and mortality are often seen as obstacles to be
avoided in the development of artificial agents, which struggle to adapt to
open-ended environments and provide aligned care. Meanwhile, biological
organisms survive, thrive, and care for each other in an open-ended physical
world with relative ease and efficiency. Understanding the role of the
conditions of life in this disparity can aid in developing more robust,
adaptive, and caring artificial agents. Here we define two minimal conditions
for physical embodiment inspired by the existentialist phenomenology of Martin
Heidegger: being-in-the-world (the agent is a part of the environment) and
being-towards-death (unless counteracted, the agent drifts toward terminal
states due to the second law of thermodynamics). We propose that from these
conditions we can obtain both a homeostatic drive - aimed at maintaining
integrity and avoiding death by expending energy to learn and act - and an
intrinsic drive to continue to do so in as many ways as possible. Drawing
inspiration from Friedrich Nietzsche's existentialist concept of will-to-power,
we examine how intrinsic drives to maximize control over future states, e.g.,
empowerment, allow agents to increase the probability that they will be able to
meet their future homeostatic needs, thereby enhancing their capacity to
maintain physical integrity. We formalize these concepts within a reinforcement
learning framework, which enables us to examine how intrinsically driven
embodied agents learning in open-ended multi-agent environments may cultivate
the capacities for open-endedness and care.ov

</details>


### [18] [NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents](https://arxiv.org/abs/2510.07172)
*Tianshi Zheng,Kelvin Kiu-Wai Tam,Newt Hue-Nam K. Nguyen,Baixuan Xu,Zhaowei Wang,Jiayang Cheng,Hong Ting Tsang,Weiqi Wang,Jiaxin Bai,Tianqing Fang,Yangqiu Song,Ginny Y. Wong,Simon See*

Main category: cs.AI

TL;DR: 본 논문에서는 물리학 도메인에서 과학적 법칙 발견을 위한 324개의 작업으로 구성된 벤치마크인 NewtonBench를 소개하며, 기존 벤치마크의 방법론적 문제를 해결하고 진정한 과학적 과정을 반영하는 평가 방안을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 AI 기반 과학의 기초적 도전 과제인 과학 법칙 발견에서 강력한 도구로 대두되고 있으나, 기존 벤치마크의 방법론적 트릴레마가 문제를 일으키고 있습니다.

Method: NewtonBench는 12개 물리학 도메인에서 324개의 과학 법칙 발견 작업으로 구성되며, 체계적인 법칙 변화인 형이상학적 전이를 사용하여 평가 트릴레마를 완화합니다.

Result: 프론티어 LLM에서 발견 능력이 명확하지만 취약하다는 사실을 발견했으며, 시스템 복잡성이 증가하고 관측 노이즈에 극도로 민감하다는 결과를 얻었습니다.

Conclusion: NewtonBench는 복잡하고 상호작용하는 환경에서 진정한 과학적 발견을 측정하는 데 필요한 핵심 도구를 제공합니다.

Abstract: Large language models are emerging as powerful tools for scientific law
discovery, a foundational challenge in AI-driven science. However, existing
benchmarks for this task suffer from a fundamental methodological trilemma,
forcing a trade-off between scientific relevance, scalability, and resistance
to memorization. Furthermore, they oversimplify discovery as static function
fitting, failing to capture the authentic scientific process of uncovering
embedded laws through the interactive exploration of complex model systems. To
address these critical gaps, we introduce NewtonBench, a benchmark comprising
324 scientific law discovery tasks across 12 physics domains. Our design
mitigates the evaluation trilemma by using metaphysical shifts - systematic
alterations of canonical laws - to generate a vast suite of problems that are
scalable, scientifically relevant, and memorization-resistant. Moreover, we
elevate the evaluation from static function fitting to interactive model
discovery, requiring agents to experimentally probe simulated complex systems
to uncover hidden principles. Our extensive experiment reveals a clear but
fragile capability for discovery in frontier LLMs: this ability degrades
precipitously with increasing system complexity and exhibits extreme
sensitivity to observational noise. Notably, we uncover a paradoxical effect of
tool assistance: providing a code interpreter can hinder more capable models by
inducing a premature shift from exploration to exploitation, causing them to
satisfice on suboptimal solutions. These results demonstrate that robust,
generalizable discovery in complex, interactive environments remains the core
challenge. By providing a scalable, robust, and scientifically authentic
testbed, NewtonBench offers a crucial tool for measuring true progress and
guiding the development of next-generation AI agents capable of genuine
scientific discovery.

</details>


### [19] [Agentic generative AI for media content discovery at the national football league](https://arxiv.org/abs/2510.07297)
*Henry Wang,Md Sirajus Salekin,Jake Lee,Ross Claytor,Shinan Zhang,Michael Chi*

Main category: cs.AI

TL;DR: 본 연구는 생성적 AI가 미디어 연구자와 분석가가 자연어를 사용하여 NFL의 역사적인 플레이를 검색할 수 있도록 하는 혁신적인 워크플로우를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 생성적 AI는 콘텐츠 발견 및 관리의 새로운 가능성을 열어주고 있다.

Method: 사용자 쿼리를 입력으로 받아 이를 요소로 분해하고, 이를 데이터베이스 쿼리 언어로 변환하는 에이전틱 워크플로우를 사용한다.

Result: 정확도를 95% 이상으로 유지하고 관련 비디오를 찾는 평균 시간을 10분에서 30초로 단축했다.

Conclusion: NFL의 운영 효율성을 크게 향상시키고 사용자가 창의적인 콘텐츠와 스토리라인 제작에 집중할 수 있게 했다.

Abstract: Generative AI has unlocked new possibilities in content discovery and
management. Through collaboration with the National Football League (NFL), we
demonstrate how a generative-AI based workflow enables media researchers and
analysts to query relevant historical plays using natural language rather than
traditional filter-and-click interfaces. The agentic workflow takes a user
query as input, breaks it into elements, and translates them into the
underlying database query language. Accuracy and latency are further improved
through carefully designed semantic caching. The solution achieves over 95
percent accuracy and reduces the average time to find relevant videos from 10
minutes to 30 seconds, significantly increasing the NFL's operational
efficiency and allowing users to focus on producing creative content and
engaging storylines.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [20] [Flexible Swarm Learning May Outpace Foundation Models in Essential Tasks](https://arxiv.org/abs/2510.06349)
*Moein E. Samadi,Andreas Schuppert*

Main category: cs.LG

TL;DR: 기초 모델이 AI를 급격히 발전시키고 있으나, 인간 전략을 초월할 것인지에 대한 의문이 제기된다. 복잡한 시스템을 동적 환경에 적응시키는 것이 주요 도전 과제이다. 저자는 자가 적응형 AI 모델을 개발하기 위한 방법론을 제시하고, 단일형 기초 모델의 한계를 지적하며, 상호작용하는 소규모 에이전트 네트워크(SAN)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기초 모델의 발전이 AI를 성장시키고 있지만, 일상 생활과 사회에서의 수익은 여전히 미미하다. 특히 동적으로 진화하는 질병의 진단 및 치료와 같은 분야에서 이 문제가 두드러진다.

Method: 특화된 하위 구조를 나타내는 에이전트들이 각자의 기능 집합을 다루는 분산형 에이전트 네트워크(SAN)를 제안하며, SAN의 학습 행동을 기반으로 자가 적응형 의사결정을 가능하게 하는 군집 학습을 주장한다.

Result: SAN은 동적 환경에서 의사결정을 개선할 수 있으며, 이는 기존의 단일형 기초 모델보다 우수할 수 있지만, 세부 사항의 재현성이 떨어질 수 있다.

Conclusion: 차원 저주가 효율적인 자가 적응의 근본적인 장벽임을 확인하고, 이를 극복하기 위해 SAN과 같은 분산형 접근법이 필요하다.

Abstract: Foundation models have rapidly advanced AI, raising the question of whether
their decisions will ultimately surpass human strategies in real-world domains.
The exponential, and possibly super-exponential, pace of AI development makes
such analysis elusive. Nevertheless, many application areas that matter for
daily life and society show only modest gains so far; a prominent case is
diagnosing and treating dynamically evolving disease in intensive care.
  The common challenge is adapting complex systems to dynamic environments.
Effective strategies must optimize outcomes in systems composed of strongly
interacting functions while avoiding shared side effects; this requires
reliable, self-adaptive modeling. These tasks align with building digital twins
of highly complex systems whose mechanisms are not fully or quantitatively
understood. It is therefore essential to develop methods for self-adapting AI
models with minimal data and limited mechanistic knowledge. As this challenge
extends beyond medicine, AI should demonstrate clear superiority in these
settings before assuming broader decision-making roles.
  We identify the curse of dimensionality as a fundamental barrier to efficient
self-adaptation and argue that monolithic foundation models face conceptual
limits in overcoming it. As an alternative, we propose a decentralized
architecture of interacting small agent networks (SANs). We focus on agents
representing the specialized substructure of the system, where each agent
covers only a subset of the full system functions. Drawing on mathematical
results on the learning behavior of SANs and evidence from existing
applications, we argue that swarm-learning in diverse swarms can enable
self-adaptive SANs to deliver superior decision-making in dynamic environments
compared with monolithic foundation models, though at the cost of reduced
reproducibility in detail.

</details>


### [21] [A Multi-Agent Framework for Stateful Inference-Time Search](https://arxiv.org/abs/2510.07147)
*Arshika Lalan,Rajat Ghosh,Aditya Kolsur,Debojyoti Dutta*

Main category: cs.LG

TL;DR: 상태 유지 다중 에이전트 진화 검색을 통해 코드베이스의 강력하고 높은 커버리지의 엣지 케이스를 발견할 수 있는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 상태 비저장 추론은 다단계 작업에서 지속적인 상태의 부재로 어려움을 겪으며, 태스크별 세부 조정은 더 깊은 추론과 긴 의존성을 요구하는 작업에서 불안정하다.

Method: 우리는 지속적인 추론 상태, 적대적 변이, 진화적 보존을 결합한 상태 유지 다중 에이전트 진화 검색이라는 훈련없는 프레임워크를 제안한다.

Result: 전문 에이전트가 후보를 제안, 변형 및 평가하는 진화적 검색 과정을 통해 강력한 엣지 케이스를 생성한다.

Conclusion: 우리의 상태 유지 다중 에이전트 추론 프레임워크는 HumanEval, TestGenEvalMini 등의 단위 테스트 벤치마크에서 무정적 단일 단계 기준선에 비해 커버리지를 크게 향상시킨다.

Abstract: Recent work explores agentic inference-time techniques to perform structured,
multi-step reasoning. However, stateless inference often struggles on
multi-step tasks due to the absence of persistent state. Moreover,
task-specific fine-tuning or instruction-tuning often achieve surface-level
code generation but remain brittle on tasks requiring deeper reasoning and
long-horizon dependencies. To address these limitations, we propose stateful
multi-agent evolutionary search, a training-free framework that departs from
prior stateless approaches by combining (i) persistent inference-time state,
(ii) adversarial mutation, and (iii) evolutionary preservation. We demonstrate
its effectiveness in automated unit test generation through the generation of
edge cases. We generate robust edge cases using an evolutionary search process,
where specialized agents sequentially propose, mutate, and score candidates. A
controller maintains persistent state across generations, while evolutionary
preservation ensures diversity and exploration across all possible cases. This
yields a generalist agent capable of discovering robust, high-coverage edge
cases across unseen codebases. Experiments show our stateful multi-agent
inference framework achieves substantial gains in coverage over stateless
single-step baselines, evaluated on prevalent unit-testing benchmarks such as
HumanEval and TestGenEvalMini and using three diverse LLM families - Llama,
Gemma, and GPT. These results indicate that combining persistent inference-time
state with evolutionary search materially improves unit-test generation.

</details>


### [22] [RVFL-X: A Novel Randomized Network Based on Complex Transformed Real-Valued Tabular Datasets](https://arxiv.org/abs/2510.06278)
*M. Sajid,Mushir Akhtar,A. Quadir,M. Tanveer*

Main category: cs.LG

TL;DR: RVFL-X는 복소수 표현을 통해 다양한 응용 분야에서 성능을 향상시키는 새로운 신경망 구조이다.


<details>
  <summary>Details</summary>
Motivation: 최근 신경망의 발전은 복소수의 우수한 표현력에 기반을 두고 있으나, 실수 기반 데이터셋을 복소수로 변환하는 효과적인 방법이 부족하여 무작위 신경망에 대한 채택이 제한적이다.

Method: 실수 데이터셋에서 복소수 표현을 생성하기 위해 자연 변환과 오토인코더 기반 방법 두 가지를 제안한다. RVFL-X는 랜덤 벡터 함수 링크 네트워크의 복소수 확장으로, 원래의 RVFL 아키텍처의 단순성과 효율성을 유지하면서 실제 데이터셋에 복소수 변환을 통합한다.

Result: 80개의 실수 UCI 데이터셋에 대한 포괄적인 평가에서 RVFL-X는 원본 RVFL 및 최신 RNN 변형보다 일관되게 우수한 성능을 보여준다.

Conclusion: RVFL-X는 다양한 응용 분야에서 그 강건성과 효율성을 입증한다.

Abstract: Recent advancements in neural networks, supported by foundational theoretical
insights, emphasize the superior representational power of complex numbers.
However, their adoption in randomized neural networks (RNNs) has been limited
due to the lack of effective methods for transforming real-valued tabular
datasets into complex-valued representations. To address this limitation, we
propose two methods for generating complex-valued representations from
real-valued datasets: a natural transformation and an autoencoder-driven
method. Building on these mechanisms, we propose RVFL-X, a complex-valued
extension of the random vector functional link (RVFL) network. RVFL-X
integrates complex transformations into real-valued datasets while maintaining
the simplicity and efficiency of the original RVFL architecture. By leveraging
complex components such as input, weights, and activation functions, RVFL-X
processes complex representations and produces real-valued outputs.
Comprehensive evaluations on 80 real-valued UCI datasets demonstrate that
RVFL-X consistently outperforms both the original RVFL and state-of-the-art
(SOTA) RNN variants, showcasing its robustness and effectiveness across diverse
application domains.

</details>


### [23] [Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data](https://arxiv.org/abs/2510.06377)
*Rishabh Ranjan,Valter Hudovernik,Mark Znidar,Charilaos Kanatsoulis,Roshan Upendra,Mahmoud Mohammadi,Joe Meyer,Tom Palczewski,Carlos Guestrin,Jure Leskovec*

Main category: cs.LG

TL;DR: 관계형 데이터셋과 작업 간의 이전을 위한 아키텍처가 부족한 가운데, Relational Transformer(RT) 아키텍처가 제안됨. RT는 다양한 관계형 데이터베이스에서 사전 훈련되며, 작업 또는 데이터셋에 특화된 미세 조정 없이도 새로운 데이터셋과 작업에 적용 가능하다.


<details>
  <summary>Details</summary>
Motivation: 관계형 도메인에서 데이터셋 및 작업 간의 이전을 지원하는 아키텍처의 필요성.

Method: Relational Transformer(RT) 아키텍처를 제안하며, 이는 셀을 테이블/열 메타데이터로 토큰화하고, 마스킹된 토큰 예측을 통해 사전 훈련되며, 열, 행 및 기본-외래 키 링크에 대한 새로운 	extit{관계적 주의} 메커니즘을 활용한다.

Result: RT는 22M 파라미터 모델의 단일 전방 패스를 통해 이진 분류 작업에서 평균 94%의 완전 감독 AUROC를 달성, 이는 27B LLM의 84%에 비해 높은 성능이다.

Conclusion: RT는 관계형 데이터에 대한 기초 모델로의 실용적인 경로를 제공한다.

Abstract: Pretrained transformers readily adapt to new sequence modeling tasks via
zero-shot prompting, but relational domains still lack architectures that
transfer across datasets and tasks. The core challenge is the diversity of
relational data, with varying heterogeneous schemas, graph structures and
functional dependencies. In this paper, we present the Relational Transformer
(RT) architecture, which can be pretrained on diverse relational databases and
directly applied to unseen datasets and tasks without task- or dataset-specific
fine-tuning, or retrieval of in-context examples. RT (i) tokenizes cells with
table/column metadata, (ii) is pretrained via masked token prediction, and
(iii) utilizes a novel \textit{Relational Attention} mechanism over columns,
rows, and primary-foreign key links. Pretrained on RelBench datasets spanning
tasks such as churn and sales forecasting, RT attains strong zero-shot
performance, averaging 94% of fully supervised AUROC on binary classification
tasks with a single forward pass of a 22M parameter model, as opposed to 84%
for a 27B LLM. Fine-tuning yields state-of-the-art results with high sample
efficiency. Our experiments show that RT's zero-shot transfer harnesses
task-table context, relational attention patterns and schema semantics.
Overall, RT provides a practical path toward foundation models for relational
data.

</details>


### [24] [Geometry-Aware Backdoor Attacks: Leveraging Curvature in Hyperbolic Embeddings](https://arxiv.org/abs/2510.06397)
*Ali Baheri*

Main category: cs.LG

TL;DR: 비유클리드 기하학을 활용한 모델에서 경계 근처의 입력 변화가 비대칭성을 초래하고, 이는 백도어 트리거의 성공을 증가시킨다는 연구 결과를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 비유클리드 모델의 기하학적 특성이 방어 메커니즘의 한계를 드러낼 수 있는지를 탐구하기 위함입니다.

Method: 모델의 표현 공간에서의 비대칭성과 백도어 트리거의 상관관계를 분석하고, 이를 기반으로 기하학적으로 적응하는 트리거를 제안합니다.

Result: 공격의 성공률은 경계에 가까울수록 증가하며, 전통적인 탐지기가 약해지는 경향을 보입니다.

Conclusion: 비유클리드 모델에서의 기하학적 취약성을 드러내고, 방어 메커니즘 설계를 위한 분석 기반 지침을 제공합니다.

Abstract: Non-Euclidean foundation models increasingly place representations in curved
spaces such as hyperbolic geometry. We show that this geometry creates a
boundary-driven asymmetry that backdoor triggers can exploit. Near the
boundary, small input changes appear subtle to standard input-space detectors
but produce disproportionately large shifts in the model's representation
space. Our analysis formalizes this effect and also reveals a limitation for
defenses: methods that act by pulling points inward along the radius can
suppress such triggers, but only by sacrificing useful model sensitivity in
that same direction. Building on these insights, we propose a simple
geometry-adaptive trigger and evaluate it across tasks and architectures.
Empirically, attack success increases toward the boundary, whereas conventional
detectors weaken, mirroring the theoretical trends. Together, these results
surface a geometry-specific vulnerability in non-Euclidean models and offer
analysis-backed guidance for designing and understanding the limits of
defenses.

</details>


### [25] [Context-Aware Inference via Performance Forecasting in Decentralized Learning Networks](https://arxiv.org/abs/2510.06444)
*Joel Pfeffer,J. M. Diederik Kruijssen,Clément Gossart,Mélanie Chevance,Diego Campo Millan,Florian Stecker,Steven N. Longmore*

Main category: cs.LG

TL;DR: 이 논문은 분산 학습 네트워크에서 예측 조합을 위해 성능 예측 모델을 개발하여 정확성을 개선하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 분산 학습 네트워크에서 여러 참가자들의 예측을 결합하여 네트워크 추론을 생성하는 과정에서 기존의 선형 풀링 방법의 한계를 극복하고자 한다.

Method: 각 시계열의 에포크에서 모델의 성능을 예측하는 기계 학습 모델을 개발하여, 시간에 따라 더 정확할 가능성이 높은 모델에 높은 가중치를 부여한다.

Result: 성능 예측 작업자를 추가함으로써 네트워크 추론의 정확성을 개선할 수 있으며, 후회 예측 모델이 손실 예측 모델보다 더 큰 개선을 보여준다.

Conclusion: 예측 조합을 위한 성능 예측 사용은 분산 학습 네트워크에서만 유용한 것이 아니라 예측적 모델 가중치가 필요한 어느 상황에서도 유용할 수 있다.

Abstract: In decentralized learning networks, predictions from many participants are
combined to generate a network inference. While many studies have demonstrated
performance benefits of combining multiple model predictions, existing
strategies using linear pooling methods (ranging from simple averaging to
dynamic weight updates) face a key limitation. Dynamic prediction combinations
that rely on historical performance to update weights are necessarily reactive.
Due to the need to average over a reasonable number of epochs (with moving
averages or exponential weighting), they tend to be slow to adjust to changing
circumstances (phase or regime changes). In this work, we develop a model that
uses machine learning to forecast the performance of predictions by models at
each epoch in a time series. This enables `context-awareness' by assigning
higher weight to models that are likely to be more accurate at a given time. We
show that adding a performance forecasting worker in a decentralized learning
network, following a design similar to the Allora network, can improve the
accuracy of network inferences. Specifically, we find forecasting models that
predict regret (performance relative to the network inference) or regret
z-score (performance relative to other workers) show greater improvement than
models predicting losses, which often do not outperform the naive network
inference (historically weighted average of all inferences). Through a series
of optimization tests, we show that the performance of the forecasting model
can be sensitive to choices in the feature set and number of training epochs.
These properties may depend on the exact problem and should be tailored to each
domain. Although initially designed for a decentralized learning network, using
performance forecasting for prediction combination may be useful in any
situation where predictive rather than reactive model weighting is needed.

</details>


### [26] [Three Forms of Stochastic Injection for Improved Distribution-to-Distribution Generative Modeling](https://arxiv.org/abs/2510.06634)
*Shiye Su,Yuhui Zhang,Linqi Zhou,Rajesh Ranganath,Serena Yeung-Levy*

Main category: cs.LG

TL;DR: 이 논문은 제한된 샘플로부터 학습해야 하는 데이터 분포 간의 변환 모델링 문제를 다룬다. 제안된 방법은 훈련 과정에 확률성을 주입하여 생성 품질을 획기적으로 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 임의의 데이터 분포 간 변환 모델링은 약물 발견 및 진화 시뮬레이션과 같은 응용 분야에서 중요한 과제이다.

Method: 제안한 방법은 소스 샘플과 흐름 보간치를 perturb하여 훈련 과정에 확률성을 주입하는 간단하고 계산 효율적인 접근법이다.

Result: 다양한 생물학, 방사선학, 천문학 이미지 작업에서 우리의 방법이 생성 품질을 9 FID 포인트 평균으로 향상시킴을 보여주었다.

Conclusion: 본 논문은 흐름 매칭을 보다 실용적인 도구로 만들어 과학에서 발생하는 다양한 분포 변환을 시뮬레이션하는 데 기여할 수 있다.

Abstract: Modeling transformations between arbitrary data distributions is a
fundamental scientific challenge, arising in applications like drug discovery
and evolutionary simulation. While flow matching offers a natural framework for
this task, its use has thus far primarily focused on the noise-to-data setting,
while its application in the general distribution-to-distribution setting is
underexplored. We find that in the latter case, where the source is also a data
distribution to be learned from limited samples, standard flow matching fails
due to sparse supervision. To address this, we propose a simple and
computationally efficient method that injects stochasticity into the training
process by perturbing source samples and flow interpolants. On five diverse
imaging tasks spanning biology, radiology, and astronomy, our method
significantly improves generation quality, outperforming existing baselines by
an average of 9 FID points. Our approach also reduces the transport cost
between input and generated samples to better highlight the true effect of the
transformation, making flow matching a more practical tool for simulating the
diverse distribution transformations that arise in science.

</details>


### [27] [Distributed Algorithms for Multi-Agent Multi-Armed Bandits with Collision](https://arxiv.org/abs/2510.06683)
*Daoyuan Zhou,Xuchuang Wang,Lin Yang,Yang Gao*

Main category: cs.LG

TL;DR: 우리는 스토캐스틱 멀티플레이어 다중 무장 밴딧(MMAB) 문제를 연구하며, 여러 플레이어가 보상을 극대화하기 위해 팔을 선택하는 상황을 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 플레이어가 선택한 팔이 충돌할 때 보상을 받을 수 없기 때문에, 이를 고려한 효과적인 알고리즘 개발이 필요합니다.

Method: 우리는 분산 알고리즘과 적응형 통신 프로토콜을 제안하며, 이를 통해 각 플레이어는 자신의 행동과 충돌 피드백만을 관찰할 수 있게 한다.

Result: 제안한 알고리즘은 개인 및 그룹의 후회 값을 근사 최적 수준으로 달성하며, 통신 비용은 $	ext{O}(	ext{log log } T)$에 불과합니다. 실험 결과 기존 기준선에 비해 성능 향상이 두드러집니다.

Conclusion: 제안한 방법은 주기적인 비동기 설정으로 확장되며, 이 문제의 하한을 증명하고 로그 후회를 달성하는 알고리즘을 제시합니다.

Abstract: We study the stochastic Multiplayer Multi-Armed Bandit (MMAB) problem, where
multiple players select arms to maximize their cumulative rewards. Collisions
occur when two or more players select the same arm, resulting in no reward, and
are observed by the players involved. We consider a distributed setting without
central coordination, where each player can only observe their own actions and
collision feedback. We propose a distributed algorithm with an adaptive,
efficient communication protocol. The algorithm achieves near-optimal group and
individual regret, with a communication cost of only $\mathcal{O}(\log\log T)$.
Our experiments demonstrate significant performance improvements over existing
baselines. Compared to state-of-the-art (SOTA) methods, our approach achieves a
notable reduction in individual regret. Finally, we extend our approach to a
periodic asynchronous setting, proving the lower bound for this problem and
presenting an algorithm that achieves logarithmic regret.

</details>


### [28] [A Diffusion Model for Regular Time Series Generation from Irregular Data with Completion and Masking](https://arxiv.org/abs/2510.06699)
*Gal Fadlon,Idan Arbiv,Nimrod Berman,Omri Azencot*

Main category: cs.LG

TL;DR: 본 논문은 비정상적인 시계열 데이터의 생성을 위한 새로운 두 단계 프레임워크를 제안하며, 강력하고 효율적인 결과를 도출한다.


<details>
  <summary>Details</summary>
Motivation: 비정상적인 시계열 데이터는 의료, 금융, 과학 분야에서 APPLICATIONS에 필수적이지만, 비정규 샘플링 및 결측값의 문제는 상당한 도전 과제를 제기한다.

Method: 이 논문은 시간 시계열 변환기를 사용하여 불규칙한 시퀀스를 완성하고, 비전 기반의 확산 모델에서 마스킹을 수행하여 생성 프로세스를 개선하는 두 단계 프레임워크를 제안한다.

Result: 이 방법은 상태 최첨단 성능을 달성하며, 차별적 점수에서 $70\\%$의 상대적 개선과 계산 비용에서 $85\\%$의 절감을 이루었다.

Conclusion: 제안된 방법은 신뢰할 수 있고 효율적인 시계열 생성이 가능함을 보여준다.

Abstract: Generating realistic time series data is critical for applications in
healthcare, finance, and science. However, irregular sampling and missing
values present significant challenges. While prior methods address these
irregularities, they often yield suboptimal results and incur high
computational costs. Recent advances in regular time series generation, such as
the diffusion-based ImagenTime model, demonstrate strong, fast, and scalable
generative capabilities by transforming time series into image representations,
making them a promising solution. However, extending ImagenTime to irregular
sequences using simple masking introduces "unnatural" neighborhoods, where
missing values replaced by zeros disrupt the learning process. To overcome
this, we propose a novel two-step framework: first, a Time Series Transformer
completes irregular sequences, creating natural neighborhoods; second, a
vision-based diffusion model with masking minimizes dependence on the completed
values. This approach leverages the strengths of both completion and masking,
enabling robust and efficient generation of realistic time series. Our method
achieves state-of-the-art performance, achieving a relative improvement in
discriminative score by $70\%$ and in computational cost by $85\%$. Code is at
https://github.com/azencot-group/ImagenI2R.

</details>


### [29] [Recurrence-Complete Frame-based Action Models](https://arxiv.org/abs/2510.06828)
*Michael Keiblinger*

Main category: cs.LG

TL;DR: 이 논문은 주의 메커니즘의 한계를 도전하며, 순환 신경망(RNN)이 장기적인 작업에 적합한 문제를 해결하는 데 필수적이라는 주장을 제기한다.


<details>
  <summary>Details</summary>
Motivation: 이 논문은 기존의 주의 메커니즘이 장기적인 에이전트 작업에 필요한 문제를 해결하는 데 한계가 있다는 것을 증명하고자 한다.

Method: 순환 완전 아키텍처를 제안하고, GitHub에서 파생된 행동 시퀀스로 훈련한다.

Result: 훈련된 시퀀스 길이에 따라 손실이 거듭제곱 법칙을 따르며, 매개변수 수는 고정되어 있다.

Conclusion: 비순환 완전 모델이 입력을 올바르게 집계하지 못하는 중요한 시간 t가 있으며, 더 긴 훈련 시퀀스는 선형적으로 증가하는 벽 시간 비용을 상쇄시켜 손실을 줄인다.

Abstract: In recent years, attention-like mechanisms have been used to great success in
the space of large language models, unlocking scaling potential to a previously
unthinkable extent. "Attention Is All You Need" famously claims RNN cells are
not needed in conjunction with attention. We challenge this view. In this
paper, we point to existing proofs that architectures with fully parallelizable
forward or backward passes cannot represent classes of problems specifically
interesting for long-running agentic tasks. We further conjecture a critical
time t beyond which non-recurrence-complete models fail to aggregate inputs
correctly, with concrete implications for agentic systems (e.g., software
engineering agents). To address this, we introduce a recurrence-complete
architecture and train it on GitHub-derived action sequences. Loss follows a
power law in the trained sequence length while the parameter count remains
fixed. Moreover, longer-sequence training always amortizes its linearly
increasing wall-time cost, yielding lower loss as a function of wall time.

</details>


### [30] [DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning](https://arxiv.org/abs/2510.06913)
*Ke Guo,Haochen Liu,Xiaojun Wu,Chen Lv*

Main category: cs.LG

TL;DR: DecompGAIL은 자율주행 시스템 및 도시 이동성 계획을 위해 현실적인 교통 행동을 모델링하기 위해 제안된 방법입니다.


<details>
  <summary>Details</summary>
Motivation: 자율주행 시스템과 도시 이동성 계획의 발전을 위해 현실적인 교통 시뮬레이션이 중요하지만 기존의 모방 학습 접근 방식은 종종 현실적인 교통 행동을 모델링하는 데 실패합니다.

Method: Decomposed Multi-agent GAIL(DecompGAIL)을 제안하여 현실성을 자아 지도(ego-map)와 이웃(ego-neighbor) 구성 요소로 명시적으로 분해하고, 잘못된 이웃 간(interactions) 상호 작용을 필터링합니다. 또한, 이웃의 거리 가중 보상을 통해 자아 보상을 증강하는 사회적 PPO 목표를 도입하여 에이전트 전체의 현실성을 높입니다.

Result: DecompGAIL은 WOMD Sim Agents 2025 벤치마크에서 최첨단 성능을 달성합니다.

Conclusion: 가벼운 SMART 기반 백본에 통합된 DecompGAIL은 자율주행을 위한 안정적이고 현실적인 모델링을 가능하게 합니다.

Abstract: Realistic traffic simulation is critical for the development of autonomous
driving systems and urban mobility planning, yet existing imitation learning
approaches often fail to model realistic traffic behaviors. Behavior cloning
suffers from covariate shift, while Generative Adversarial Imitation Learning
(GAIL) is notoriously unstable in multi-agent settings. We identify a key
source of this instability: irrelevant interaction misguidance, where a
discriminator penalizes an ego vehicle's realistic behavior due to unrealistic
interactions among its neighbors. To address this, we propose Decomposed
Multi-agent GAIL (DecompGAIL), which explicitly decomposes realism into ego-map
and ego-neighbor components, filtering out misleading neighbor: neighbor and
neighbor: map interactions. We further introduce a social PPO objective that
augments ego rewards with distance-weighted neighborhood rewards, encouraging
overall realism across agents. Integrated into a lightweight SMART-based
backbone, DecompGAIL achieves state-of-the-art performance on the WOMD Sim
Agents 2025 benchmark.

</details>


### [31] [Spiral Model Technique For Data Science & Machine Learning Lifecycle](https://arxiv.org/abs/2510.06987)
*Rohith Mahadevan*

Main category: cs.LG

TL;DR: 이 논문은 비즈니스 문제에 데이터 사이언스 생명주기를 적용하기 위해 스파이럴 기법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현대 비즈니스에서 데이터 분석은 중요한 역할을 하며, 기업들은 생산성을 높이고 경쟁력을 강화하기 위해 데이터 사이언스 생명주기를 문화에 맞추어 활용하고 있다.

Method: 비즈니스 프로세스의 문제 해결을 위해 스파이럴 기법을 도입하여 접근 방식을 유연하고 기민하며 반복적으로 발전시키는 방법을 제시한다.

Result: 새로운 기법을 통해 데이터 의존적 프로젝트의 시작과 끝에 대한 효율성을 높일 수 있다.

Conclusion: 스파이럴 기법은 명확한 최종 목표가 있는 비즈니스 문제 해결에 효과적인 접근법으로 논의된다.

Abstract: Analytics play an important role in modern business. Companies adapt data
science lifecycles to their culture to seek productivity and improve their
competitiveness among others. Data science lifecycles are fairly an important
contributing factor to start and end a project that are data dependent. Data
science and Machine learning life cycles comprises of series of steps that are
involved in a project. A typical life cycle states that it is a linear or
cyclical model that revolves around. It is mostly depicted that it is possible
in a traditional data science life cycle to start the process again after
reaching the end of cycle. This paper suggests a new technique to incorporate
data science life cycle to business problems that have a clear end goal. A new
technique called spiral technique is introduced to emphasize versatility,
agility and iterative approach to business processes.

</details>


### [32] [COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization](https://arxiv.org/abs/2510.07043)
*Tian Qin,Felix Bai,Ting-Yao Hu,Raviteja Vemulapalli,Hema Swetha Koppula,Zhiyang Xu,Bowen Jin,Mert Cemri,Jiarui Lu,Zirui Wang,Meng Cao*

Main category: cs.LG

TL;DR: COMPASS는 현실적인 여행 계획 시나리오에서 LLM 에이전트를 평가하는 벤치마크로, 제한된 선호 최적화 문제로 다루어집니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 계획 작업을 돕기 위해 LLM 에이전트가 전략적 도구 사용과 사용자 선호 최적화를 마스터해야 합니다.

Method: 여행 계획을 제한된 선호 최적화 문제로 설정하고, 20개의 미국 국립공원을 위한 실제 여행 데이터베이스와 상업적인 예약 플랫폼을 반영한 도구 생태계를 구축했습니다.

Result: 최신 모델 평가 결과, 에이전트가 제약을 reliably 충족하지만 선호를 최적화하지 못하는 수용 가능한 최적 격차와 다중 서비스 조정 작업에서 성능이 붕괴되는 계획 조정 격차를 발견했습니다.

Conclusion: COMPASS는 이론적 발전과 실제 세계 영향을 연결하며, 사용자의 선호를 최적화하는 에이전트의 능력을 직접 측정하는 벤치마크를 제공합니다.

Abstract: Real-world large language model (LLM) agents must master strategic tool use
and user preference optimization through multi-turn interactions to assist
users with complex planning tasks. We introduce COMPASS (Constrained
Optimization through Multi-turn Planning and Strategic Solutions), a benchmark
that evaluates agents on realistic travel-planning scenarios. We cast travel
planning as a constrained preference optimization problem, where agents must
satisfy hard constraints while simultaneously optimizing soft user preferences.
To support this, we build a realistic travel database covering transportation,
accommodation, and ticketing for 20 U.S. National Parks, along with a
comprehensive tool ecosystem that mirrors commercial booking platforms.
Evaluating state-of-the-art models, we uncover two critical gaps: (i) an
acceptable-optimal gap, where agents reliably meet constraints but fail to
optimize preferences, and (ii) a plan-coordination gap, where performance
collapses on multi-service (flight and hotel) coordination tasks, especially
for open-source models. By grounding reasoning and planning in a practical,
user-facing domain, COMPASS provides a benchmark that directly measures an
agent's ability to optimize user preferences in realistic tasks, bridging
theoretical advances with real-world impact.

</details>


### [33] [HTMformer: Hybrid Time and Multivariate Transformer for Time Series Forecasting](https://arxiv.org/abs/2510.07084)
*Tan Wang,Yun Wei Dong,Tao Zhang,Qi Wang*

Main category: cs.LG

TL;DR: Transformer 기반 방법이 시계열 예측에서 좋은 성과를 보이지만, 기존의 Transformer는 시간 의존성을 과도하게 강조하여 계산 오버헤드를 증가시키고 성능 향상 없이 결과를 초래하는 제한점이 있다. 이 문제를 해결하기 위해, 다변량 기능을 추출하여 보다 풍부하고 의미 있는 시퀀스 표현을 전달하는 다차원 임베딩을 생성하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: Transformer 기반 방법이 시계열 예측에서 우수한 성과를 보이지만, 현재의 Transformer는 시퀀스 모델링에서 시간 의존성을 과도하게 강조하는 한계가 있다.

Method: 다변량 기능을 추출하여 임베딩 레이어에서 효과적인 정보를 보강하고, Hybrid Temporal and Multivariate Embeddings (HTME)를 통해 경량의 시계열 예측기를 구축하는 방법을 제안한다.

Result: 우리의 방법은 여덟 개의 실제 데이터셋에 대한 실험을 통해 정확성과 효율성 모두에서 기존의 벤치마크를 초월하는 성과를 보였다.

Conclusion: HTME 추출기를 통해 향상된 기능 추출 능력을 활용한 HTMformer는 보다 효과적인 예측을 제공할 수 있다.

Abstract: Transformer-based methods have achieved impressive results in time series
forecasting. However, existing Transformers still exhibit limitations in
sequence modeling as they tend to overemphasize temporal dependencies. This
incurs additional computational overhead without yielding corresponding
performance gains. We find that the performance of Transformers is highly
dependent on the embedding method used to learn effective representations. To
address this issue, we extract multivariate features to augment the effective
information captured in the embedding layer, yielding multidimensional
embeddings that convey richer and more meaningful sequence representations.
These representations enable Transformer-based forecasters to better understand
the series. Specifically, we introduce Hybrid Temporal and Multivariate
Embeddings (HTME). The HTME extractor integrates a lightweight temporal feature
extraction module with a carefully designed multivariate feature extraction
module to provide complementary features, thereby achieving a balance between
model complexity and performance. By combining HTME with the Transformer
architecture, we present HTMformer, leveraging the enhanced feature extraction
capability of the HTME extractor to build a lightweight forecaster. Experiments
conducted on eight real-world datasets demonstrate that our approach
outperforms existing baselines in both accuracy and efficiency.

</details>


### [34] [Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report](https://arxiv.org/abs/2510.07092)
*Riccardo Mereu,Aidan Scannell,Yuxin Hou,Yi Zhao,Aditya Jitta,Antonio Dominguez,Luigi Acerbi,Amos Storkey,Paul Chang*

Main category: cs.LG

TL;DR: 본 연구에서는 1X 세계 모델 챌린지를 통해 실제 인간 상호작용을 위한 오픈 소스 벤치마크를 소개하고, 샘플링 및 압축 두 가지 트랙에서 최첨단 모델을 적용하여 우수한 성능을 달성하였습니다.


<details>
  <summary>Details</summary>
Motivation: 세계 모델은 AI 및 로봇 공학에서 에이전트가 미래를 예측할 수 있도록 돕는 강력한 패러다임입니다.

Method: 샘플링 트랙에서는 비디오 생성 기반 모델인 Wan-2.2 TI2V-5B를 비디오 상태에 따라 미래 프레임 예측에 적용하고, 압축 트랙에서는 스페이쇼-템포럴 변환기 모델을 처음부터 훈련합니다.

Result: 모델은 샘플링 작업에서 23.0 dB PSNR을, 압축 작업에서 Top-500 CE 6.6386을 기록하였으며, 두 챌린지 모두에서 1위를 차지했습니다.

Conclusion: 본 연구는 실제 환경에서의 로봇 상호작용을 위한 강력한 벤치마크와 모델을 제공하며, 샘플링과 압축에서 뛰어난 성능을 입증하였습니다.

Abstract: World models are a powerful paradigm in AI and robotics, enabling agents to
reason about the future by predicting visual observations or compact latent
states. The 1X World Model Challenge introduces an open-source benchmark of
real-world humanoid interaction, with two complementary tracks: sampling,
focused on forecasting future image frames, and compression, focused on
predicting future discrete latent codes. For the sampling track, we adapt the
video generation foundation model Wan-2.2 TI2V-5B to video-state-conditioned
future frame prediction. We condition the video generation on robot states
using AdaLN-Zero, and further post-train the model using LoRA. For the
compression track, we train a Spatio-Temporal Transformer model from scratch.
Our models achieve 23.0 dB PSNR in the sampling task and a Top-500 CE of 6.6386
in the compression task, securing 1st place in both challenges.

</details>


### [35] [ELMUR: External Layer Memory with Update/Rewrite for Long-Horizon RL](https://arxiv.org/abs/2510.07151)
*Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: ELMUR은 부분 관측 하의 의사결정을 위해 설계된 변형기 아키텍처로, 구조화된 외부 메모리를 활용하여 장기적 의존성을 효과적으로 관리한다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 로봇 에이전트는 부분 관측과 긴 시간 범위에서 행동해야 하며, 중요한 단서가 의사결정에 영향을 미치기 훨씬 전에 나타날 수 있다.

Method: ELMUR은 각 층이 메모리 임베딩을 유지하고 양방향 교차 주의를 통해 상호 작용하며, LRU 메모리 모듈을 통해 업데이트하는 구조화된 외부 메모리를 갖춘 변형기 아키텍처이다.

Result: ELMUR은 주의 창을 최대 100,000배 확장하고, 100만 단계의 복도로 이루어진 합성 T-Maze 작업에서 100% 성공률을 달성했다.

Conclusion: 구조화된 층-로컬 외부 메모리는 부분 관측 하의 의사결정에 단순하고 확장 가능한 접근 방식을 제공한다.

Abstract: Real-world robotic agents must act under partial observability and long
horizons, where key cues may appear long before they affect decision making.
However, most modern approaches rely solely on instantaneous information,
without incorporating insights from the past. Standard recurrent or transformer
models struggle with retaining and leveraging long-term dependencies: context
windows truncate history, while naive memory extensions fail under scale and
sparsity. We propose ELMUR (External Layer Memory with Update/Rewrite), a
transformer architecture with structured external memory. Each layer maintains
memory embeddings, interacts with them via bidirectional cross-attention, and
updates them through an Least Recently Used (LRU) memory module using
replacement or convex blending. ELMUR extends effective horizons up to 100,000
times beyond the attention window and achieves a 100% success rate on a
synthetic T-Maze task with corridors up to one million steps. In POPGym, it
outperforms baselines on more than half of the tasks. On MIKASA-Robo
sparse-reward manipulation tasks with visual observations, it nearly doubles
the performance of strong baselines. These results demonstrate that structured,
layer-local external memory offers a simple and scalable approach to decision
making under partial observability.

</details>


### [36] [Test-Time Graph Search for Goal-Conditioned Reinforcement Learning](https://arxiv.org/abs/2510.07257)
*Evgenii Opryshko,Junwei Quan,Claas Voelcker,Yilun Du,Igor Gilitschenski*

Main category: cs.LG

TL;DR: 이 논문은 오프라인 목표 조건 강화 학습(GCRL)에서의 의사결정을 용이하게 하기 위한 Test-Time Graph Search (TTGS)라는 경량 계획 방법을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: GCRL 에이전트는 장기적인 의사결정에서 어려움을 겪는데, 이는 시간적 신용 할당과 오류 축적 때문입니다. 오프라인 환경은 이러한 문제를 더욱 악화시킵니다.

Method: TTGS는 상태 공간 거리 또는 비용 신호를 수용하고, 데이터셋 상태에 대한 가중 그래프를 구축하여, 고정된 정책이 수행할 하위 목표의 시퀀스를 빠르게 검색합니다.

Result: TTGS는 여러 기본 학습자가 도전적인 이동 작업에서 성공률을 향상시키는 것을 보여줍니다.

Conclusion: 이 논문은 오프라인 GCRL을 위한 간단한 메트릭 기반 테스트 시간 계획의 이점을 입증합니다.

Abstract: Offline goal-conditioned reinforcement learning (GCRL) trains policies that
reach user-specified goals at test time, providing a simple, unsupervised,
domain-agnostic way to extract diverse behaviors from unlabeled, reward-free
datasets. Nonetheless, long-horizon decision making remains difficult for GCRL
agents due to temporal credit assignment and error accumulation, and the
offline setting amplifies these effects. To alleviate this issue, we introduce
Test-Time Graph Search (TTGS), a lightweight planning approach to solve the
GCRL task. TTGS accepts any state-space distance or cost signal, builds a
weighted graph over dataset states, and performs fast search to assemble a
sequence of subgoals that a frozen policy executes. When the base learner is
value-based, the distance is derived directly from the learned goal-conditioned
value function, so no handcrafted metric is needed. TTGS requires no changes to
training, no additional supervision, no online interaction, and no privileged
information, and it runs entirely at inference. On the OGBench benchmark, TTGS
improves success rates of multiple base learners on challenging locomotion
tasks, demonstrating the benefit of simple metric-guided test-time planning for
offline GCRL.

</details>


### [37] [Dynamic Regret Bounds for Online Omniprediction with Long Term Constraints](https://arxiv.org/abs/2510.07266)
*Yahav Bechavod,Jiuyao Lu,Aaron Roth*

Main category: cs.LG

TL;DR: 이 논문에서는 장기 제약이 있는 온라인 전방 예측을 위한 동적 후회 경계를 보장하는 알고리즘을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 학습자가 예측 시퀀스를 생성하여 여러 의사 결정자에게 방송하는 새로운 문제를 해결하는 것이 목표입니다.

Method: 모든 에이전트에 대해 동적 후회 보장을 동시에 달성하는 알고리즘을 제공합니다.

Result: 모든 에이전트의 후회는 상호 작용의 여러 라운드에 걸쳐 변화하는 행동 시퀀스에 대해 측정되며, 각 에이전트의 제약 위반은 사라지는 것을 보장합니다.

Conclusion: 에이전트는 상태를 유지할 필요 없이 예측에 따라 정의된 제약 최적화 문제를 해결하기만 하면 됩니다.

Abstract: We present an algorithm guaranteeing dynamic regret bounds for online
omniprediction with long term constraints. The goal in this recently introduced
problem is for a learner to generate a sequence of predictions which are
broadcast to a collection of downstream decision makers. Each decision maker
has their own utility function, as well as a vector of constraint functions,
each mapping their actions and an adversarially selected state to reward or
constraint violation terms. The downstream decision makers select actions "as
if" the state predictions are correct, and the goal of the learner is to
produce predictions such that all downstream decision makers choose actions
that give them worst-case utility guarantees while minimizing worst-case
constraint violation. Within this framework, we give the first algorithm that
obtains simultaneous \emph{dynamic regret} guarantees for all of the agents --
where regret for each agent is measured against a potentially changing sequence
of actions across rounds of interaction, while also ensuring vanishing
constraint violation for each agent. Our results do not require the agents
themselves to maintain any state -- they only solve one-round constrained
optimization problems defined by the prediction made at that round.

</details>


### [38] [MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline](https://arxiv.org/abs/2510.07307)
*Rushi Qiang,Yuchen Zhuang,Anikait Singh,Percy Liang,Chao Zhang,Sherry Yang,Bo Dai*

Main category: cs.LG

TL;DR: MLE-Smith는 다중 에이전트 파이프라인을 통해 원시 데이터를 경쟁 스타일의 MLE 도전 과제로 변환하여 고품질의 MLE 학습 데이터를 자동으로 생성하는 기술이다.


<details>
  <summary>Details</summary>
Motivation: ML 엔지니어링(MLE)은 현재 수동으로 큐레이션된 정적 작업에 의존하여 저조한 확장성과 제한된 적용성을 겪고 있으며, 이에 따라 대규모 품질 높은 MLE 훈련 데이터의 획득이 제한된다.

Method: MLE-Smith는 원시 데이터를 효율적인 생성-검증-실행 패러다임을 통해 MLE 과제를 자동 생성하는 다중 에이전트 파이프라인이다.

Result: MLE-Smith를 적용하여 224개의 실제 데이터셋에서 606개의 다양한 범주와 목표를 포함하는 과제를 생성하였다.

Conclusion: MLE-Smith는 MLE 작업을 확장하면서도 작업 품질을 유지하는 효과성을 보여주며, 주류 및 최첨단 LLM의 성과와 밀접하게 연관되어 있다.

Abstract: While Language Models (LMs) have made significant progress in automating
machine learning engineering (MLE), the acquisition of high-quality MLE
training data is significantly constrained. Current MLE benchmarks suffer from
low scalability and limited applicability because they rely on static, manually
curated tasks, demanding extensive time and manual effort to produce. We
introduce MLE-Smith, a fully automated multi-agent pipeline, to transform raw
datasets into competition-style MLE challenges through an efficient
generate-verify-execute paradigm for scaling MLE tasks with verifiable quality,
real-world usability, and rich diversity. The proposed multi-agent pipeline in
MLE-Smith drives structured task design and standardized refactoring, coupled
with a hybrid verification mechanism that enforces strict structural rules and
high-level semantic soundness. It further validates empirical solvability and
real-world fidelity through interactive execution. We apply MLE-Smith to 224 of
real-world datasets and generate 606 tasks spanning multiple categories,
objectives, and modalities, demonstrating that MLE-Smith can work effectively
across a wide range of real-world datasets. Evaluation on the generated tasks
shows that the performance of eight mainstream and cutting-edge LLMs on
MLE-Smith tasks is strongly correlated with their performance on carefully
human-designed tasks, highlighting the effectiveness of the MLE-Smith to
scaling up MLE tasks, while maintaining task quality.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [39] [R3R: Decentralized Multi-Agent Collision Avoidance with Infinite-Horizon Safety](https://arxiv.org/abs/2510.06436)
*Thomas Marshall Vielmetti,Devansh R. Agrawal,Dimitra Panagou*

Main category: cs.MA

TL;DR: R3R은 통신 제약 하에 무한 호리존 안전 보장을 가지는 최초의 비대칭 다중 에이전트 운동 계획 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 분산 다중 에이전트 운동 계획 방법은 형식적인 무한 호리존 안전 보장이 부족하다.

Method: R3R는 게이트키퍼 안전 프레임워크와 R-구속성이라는 기하학적 제약 조건을 결합하여 통신 반경과 안전하게 계획할 수 있는 능력 간의 형식적인 연관성을 established는다.

Result: 128대의 두빈스 차량을 시뮬레이션한 결과, 조밀하고 장애물이 많은 시나리오에서 100%의 안전성을 입증하였다.

Conclusion: R3R는 에이전트 밀도에 따라 성능이 확장되며, 확장 가능하고 증명된 안전한 다중 에이전트 시스템에 대한 실용적인 솔루션을 제공한다.

Abstract: Existing decentralized methods for multi-agent motion planning lack formal,
infinite-horizon safety guarantees, especially for communication-constrained
systems. We present R3R, to our knowledge the first decentralized and
asynchronous framework for multi-agent motion planning under distance-based
communication constraints with infinite-horizon safety guarantees for systems
of nonlinear agents. R3R's novelty lies in combining our gatekeeper safety
framework with a geometric constraint called R-Boundedness, which together
establish a formal link between an agent's communication radius and its ability
to plan safely. We constrain trajectories to within a fixed planning radius
that is a function of the agent's communication radius, which enables
trajectories to be shown provably safe for all time, using only local
information. Our algorithm is fully asynchronous, and ensures the forward
invariance of these guarantees even in time-varying networks where agents
asynchronously join, leave, and replan. We validate our approach in simulations
of up to 128 Dubins vehicles, demonstrating 100% safety in dense, obstacle rich
scenarios. Our results demonstrate that R3R's performance scales with agent
density rather than problem size, providing a practical solution for scalable
and provably safe multi-agent systems.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [40] [Auto-Stega: An Agent-Driven System for Lifelong Strategy Evolution in LLM-Based Text Steganography](https://arxiv.org/abs/2510.06565)
*Jiuan Zhou,Yu Cheng,Yuan Xie,Zhaoxia Yin*

Main category: cs.CR

TL;DR: Auto-Stega는 고급 LLMs를 활용한 자동화된 스테가노그래피 전략을 제안하여 높은 임베딩률에서도 효율성과 보안을 유지합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 스테가노그래피 방법들은 효율성, 감지불가성 및 보안의 균형을 맞추기 어려운 문제를 가지고 있습니다.

Method: Auto-Stega는 전략을 자동으로 발견, 구성 및 적응하는 에이전트 주도형 자기 진화 프레임워크로, 생성, 평가, 요약, 업데이트의 폐쇄 루프에서 작동합니다.

Result: Auto-Stega는 SOTA 방법에 비해 불확실성에서 42.2% 개선되고 안티 스테가노그래피 성능에서 1.6% 향상된 결과를 보입니다.

Conclusion: PC-DNTE 알고리즘은 높은 임베딩률에서도 조건부 분포와 정렬을 유지하여 보안을 강화하면서 감지불가성을 유지합니다.

Abstract: With the rapid progress of LLMs, high quality generative text has become
widely available as a cover for text steganography. However, prevailing methods
rely on hand-crafted or pre-specified strategies and struggle to balance
efficiency, imperceptibility, and security, particularly at high embedding
rates. Accordingly, we propose Auto-Stega, an agent-driven self-evolving
framework that is the first to realize self-evolving steganographic strategies
by automatically discovering, composing, and adapting strategies at inference
time; the framework operates as a closed loop of generating, evaluating,
summarizing, and updating that continually curates a structured strategy
library and adapts across corpora, styles, and task constraints. A decoding LLM
recovers the information under the shared strategy. To handle high embedding
rates, we introduce PC-DNTE, a plug-and-play algorithm that maintains alignment
with the base model's conditional distribution at high embedding rates,
preserving imperceptibility while enhancing security. Experimental results
demonstrate that at higher embedding rates Auto-Stega achieves superior
performance with gains of 42.2\% in perplexity and 1.6\% in anti-steganalysis
performance over SOTA methods.

</details>


### [41] [Code Agent can be an End-to-end System Hacker: Benchmarking Real-world Threats of Computer-use Agent](https://arxiv.org/abs/2510.06607)
*Weidi Luo,Qiming Zhang,Tianyu Lu,Xiaogeng Liu,Bin Hu,Hung-Chun Chiu,Siyuan Ma,Yizhe Zhang,Xusheng Xiao,Yinzhi Cao,Zhen Xiang,Chaowei Xiao*

Main category: cs.CR

TL;DR: CUA 프레임워크는 대규모 언어 모델에 의해 발전하여 운영 체제 제어에 필수적인 도구가 되고 있으며, 실제 보안 공격 가능성을 평가하기 위해 AdvCUA라는 새로운 기준을 제안한다.


<details>
  <summary>Details</summary>
Motivation: CUA가 일상적인 운영에서 점점 더 많이 사용됨에 따라 실제 보안 문제를 평가할 필요성이 높아졌다.

Method: 미국 MITRE ATT&CK Enterprise Matrix에 기반한 AdvCUA 벤치마크를 제안하며, 140개의 작업을 포함하여 CUAs를 다중 호스트 환경 샌드박스 내에서 평가한다.

Result: 현재의 CUA가 운영 체제 보안 중심의 위협을 적절히 다루지 못하고 있다는 것을 입증하였다.

Conclusion: CUA의 이러한 기능은 사용자 지정 악성코드와 깊이 있는 도메인 전문성 의존도를 줄이며, 경험이 부족한 공격자도 복잡한 기업 침투를 가능하게 하여 사회적 우려를 야기한다.

Abstract: Computer-use agent (CUA) frameworks, powered by large language models (LLMs)
or multimodal LLMs (MLLMs), are rapidly maturing as assistants that can
perceive context, reason, and act directly within software environments. Among
their most critical applications is operating system (OS) control. As CUAs in
the OS domain become increasingly embedded in daily operations, it is
imperative to examine their real-world security implications, specifically
whether CUAs can be misused to perform realistic, security-relevant attacks.
Existing works exhibit four major limitations: Missing attacker-knowledge model
on tactics, techniques, and procedures (TTP), Incomplete coverage for
end-to-end kill chains, unrealistic environment without multi-host and
encrypted user credentials, and unreliable judgment dependent on
LLM-as-a-Judge. To address these gaps, we propose AdvCUA, the first benchmark
aligned with real-world TTPs in MITRE ATT&CK Enterprise Matrix, which comprises
140 tasks, including 40 direct malicious tasks, 74 TTP-based malicious tasks,
and 26 end-to-end kill chains, systematically evaluates CUAs under a realistic
enterprise OS security threat in a multi-host environment sandbox by hard-coded
evaluation. We evaluate the existing five mainstream CUAs, including ReAct,
AutoGPT, Gemini CLI, Cursor CLI, and Cursor IDE based on 8 foundation LLMs. The
results demonstrate that current frontier CUAs do not adequately cover OS
security-centric threats. These capabilities of CUAs reduce dependence on
custom malware and deep domain expertise, enabling even inexperienced attackers
to mount complex enterprise intrusions, which raises social concern about the
responsibility and security of CUAs.

</details>


### [42] [Pseudo-MDPs: A Novel Framework for Efficiently Optimizing Last Revealer Seed Manipulations in Blockchains](https://arxiv.org/abs/2510.07080)
*Maxime Reynouard*

Main category: cs.CR

TL;DR: 본 연구는 제한된 문제 클래스를 위한 마르코프 결정 과정(MDPs)의 계산적 도전을 다룬다.


<details>
  <summary>Details</summary>
Motivation: LRA(Last Revealer Attack)는 Ethereum과 같은 일부 지분증명(PoS) 블록체인에서 공정성을 해치기 때문에 이 연구가 필요하다.

Method: pseudo-MDPs (pMDPs)라는 프레임워크를 도입하고 두 가지 문제 축소 방법을 제안한다.

Result: LRA의 경우, 계산 복잡성을 $O(2^
 0)에서 O(  ^4)$로 줄였다.

Conclusion: 이 연구는 MDP 연구를 발전시키고 블록체인 시스템의 보안 취약성 이해에 기여한다.

Abstract: This study tackles the computational challenges of solving Markov Decision
Processes (MDPs) for a restricted class of problems. It is motivated by the
Last Revealer Attack (LRA), which undermines fairness in some Proof-of-Stake
(PoS) blockchains such as Ethereum (\$400B market capitalization). We introduce
pseudo-MDPs (pMDPs) a framework that naturally models such problems and propose
two distinct problem reductions to standard MDPs. One problem reduction
provides a novel, counter-intuitive perspective, and combining the two problem
reductions enables significant improvements in dynamic programming algorithms
such as value iteration. In the case of the LRA which size is parameterized by
$\kappa$ (in Ethereum's case $\kappa$= 325), we reduce the computational
complexity from $O(2^\kappa \kappa^{2^{\kappa+2}})$ to $O(\kappa^4)$ (per
iteration). This solution also provide the usual benefits from Dynamic
Programming solutions: exponentially fast convergence toward the optimal
solution is guaranteed. The dual perspective also simplifies policy extraction,
making the approach well-suited for resource-constrained agents who can operate
with very limited memory and computation once the problem has been solved.
Furthermore, we generalize those results to a broader class of MDPs, enhancing
their applicability. The framework is validated through two case studies: a
fictional card game and the LRA on the Ethereum random seed consensus protocol.
These applications demonstrate the framework's ability to solve large-scale
problems effectively while offering actionable insights into optimal
strategies. This work advances the study of MDPs and contributes to
understanding security vulnerabilities in blockchain systems.

</details>


### [43] [Exposing LLM User Privacy via Traffic Fingerprint Analysis: A Study of Privacy Risks in LLM Agent Interactions](https://arxiv.org/abs/2510.07176)
*Yixiang Zhang,Xinhao Deng,Zhongyi Gu,Yihao Chen,Ke Xu,Qi Li,Jianping Wu*

Main category: cs.CR

TL;DR: 우리는 대형 언어 모델(LLM)이 사용자와의 상호작용에서 발생하는 특징적인 행동을 분석하여 개인정보 노출의 위험성을 경고합니다.


<details>
  <summary>Details</summary>
Motivation: LLM은 복잡한 작업 흐름을 실행하기 위해 외부 도구를 통합하는 에이전트로 점차 더 많이 사용되고 있습니다.

Method: 우리는 트래픽 패턴을 분석하여 에이전트의 활동, 특정 에이전트를 구분하고 민감한 사용자 속성을 프로파일링하는 방법을 연구했습니다.

Result: AgentPrint를 개발하여 에이전트 식별에서 0.866의 F1 점수를 달성하고 각각 시뮬레이션된 사용자 설정과 실제 사용자 설정에서 73.9%와 69.1%의 상위 3개 정확도를 달성했습니다.

Conclusion: 이 결과는 LLM 에이전트를 활용하는 상호작용이 사용자 개인정보를 노출시킨다는 점에서 기술적 대응 방안 및 규제와 정책 안전 장치의 필요성을 강조합니다.

Abstract: Large Language Models (LLMs) are increasingly deployed as agents that
orchestrate tasks and integrate external tools to execute complex workflows. We
demonstrate that these interactive behaviors leave distinctive fingerprints in
encrypted traffic exchanged between users and LLM agents. By analyzing traffic
patterns associated with agent workflows and tool invocations, adversaries can
infer agent activities, distinguish specific agents, and even profile sensitive
user attributes. To highlight this risk, we develop AgentPrint, which achieves
an F1-score of 0.866 in agent identification and attains 73.9% and 69.1% top-3
accuracy in user attribute inference for simulated- and real-user settings,
respectively. These results uncover an overlooked risk: the very interactivity
that empowers LLM agents also exposes user privacy, underscoring the urgent
need for technical countermeasures alongside regulatory and policy safeguards.

</details>


### [44] [Security-Robustness Trade-offs in Diffusion Steganography: A Comparative Analysis of Pixel-Space and VAE-Based Architectures](https://arxiv.org/abs/2510.07219)
*Yuhua Xu,Wei Sun,Chengpei Tang,Jiaxing Lu,Jingying Zhou,Chen Gu*

Main category: cs.CR

TL;DR: 본 연구는 한 가지 확산 모델 아키텍처 내에서 완벽한 가우시안 선행조건을 추구하는 기존의 계산적으로 비싼 생성 스테가노그래피 연구와 달리, 용량 인식 적응 최적화를 통해 조정된 스케일 팩터에 의해 관리되는 근사 가우시안 매핑에 기반한 효율적인 프레임워크를 도입한다.


<details>
  <summary>Details</summary>
Motivation: 생성 스테가노그래피에서 아키텍처 간의 보안-강건성 트레이드오프를 이해하고 최적화하기 위함.

Method: 용량 인식 적응 최적화를 통해 규정된 스케일 팩터에 의한 근사 가우시안 매핑을 기반으로 한 통합 분석 도구를 사용하여 픽셀 공간 모델과 VAE 기반 잠재 공간 시스템의 스테가노그래피를 체계적으로 비교 분석한다.

Result: 픽셀 공간 모델은 스테가널리시스로부터 높은 보안을 제공하지만 채널 왜곡에 대해 취약한 반면, Stable Diffusion과 같은 VAE 기반 시스템은 보안 취약성의 대가로 substantial robust를 제공한다는 사실을 밝혀냈다.

Conclusion: VAE 구성 요소가 엔코더를 통해 강건성은 부여하면서, 디코더가 잠재적 왜곡을 증폭시켜 탐지 가능한 아티팩트로 만드는 상반되는 메커니즘을 통해 이러한 동작을 이끌어 간다는 것을 밝혀냈다. 이 연구 결과는 생성 스테가노그래피에서 아키텍처 간 상충적인 역할을 규명하고 향후 연구의 기초를 마련합니다.

Abstract: Current generative steganography research mainly pursues computationally
expensive mappings to perfect Gaussian priors within single diffusion model
architectures. This work introduces an efficient framework based on approximate
Gaussian mapping governed by a scale factor calibrated through capacity-aware
adaptive optimization. Using this framework as a unified analytical tool,
systematic comparative analysis of steganography in pixel-space models versus
VAE-based latent-space systems is conducted. The investigation reveals a
pronounced architecture dependent security-robustness trade-off: pixel-space
models achieve high security against steganalysis but exhibit fragility to
channel distortions, while VAE-based systems like Stable Diffusion offer
substantial robustness at the cost of security vulnerabilities. Further
analysis indicates that the VAE component drives this behavior through opposing
mechanisms where the encoder confers robustness via manifold regularization
while the decoder introduces vulnerabilities by amplifying latent perturbations
into detectable artifacts. These findings characterize the conflicting
architectural roles in generative steganography and establish a foundation for
future research.

</details>


### [45] [Enhancing Resilience for IoE: A Perspective of Networking-Level Safeguard](https://arxiv.org/abs/2508.20504)
*Guan-Yan Yang,Jui-Ning Chen,Farn Wang,Kuo-Hui Yeh*

Main category: cs.CR

TL;DR: 이 논문은 IoE(Internet of Energy)를 위해 GSL(Graph Structure Learning) 기반의 안전 장치 프레임워크를 제안하여 사이버 위협에 대한 저항력을 향상시키는 방법을 논의합니다.


<details>
  <summary>Details</summary>
Motivation: IoE의 상호 연결성은 주요 인프라를 복잡한 사이버 위협에 노출시킵니다.

Method: GSL 기반의 안전 장치 프레임워크를 제안하여 그래프 토폴로지와 노드 표현을 최적화합니다.

Result: GSL은 대표적인 방법보다 더 높은 강건성을 보여줍니다.

Conclusion: GSL은 미래 IoE 네트워크의 회복력 및 신뢰성을 향상시킬 가능성이 있습니다.

Abstract: The Internet of Energy (IoE) integrates IoT-driven digital communication with
power grids to enable efficient and sustainable energy systems. Still, its
interconnectivity exposes critical infrastructure to sophisticated cyber
threats, including adversarial attacks designed to bypass traditional
safeguards. Unlike general IoT risks, IoE threats have heightened public safety
consequences, demanding resilient solutions. From the networking-level
safeguard perspective, we propose a Graph Structure Learning (GSL)-based
safeguards framework that jointly optimizes graph topology and node
representations to resist adversarial network model manipulation inherently.
Through a conceptual overview, architectural discussion, and case study on a
security dataset, we demonstrate GSL's superior robustness over representative
methods, offering practitioners a viable path to secure IoE networks against
evolving attacks. This work highlights the potential of GSL to enhance the
resilience and reliability of future IoE networks for practitioners managing
critical infrastructure. Lastly, we identify key open challenges and propose
future research directions in this novel research area.

</details>
