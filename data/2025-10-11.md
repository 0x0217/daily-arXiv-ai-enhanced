<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 1]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 35]
- [cs.LG](#cs.LG) [Total: 25]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Network Topology and Information Efficiency of Multi-Agent Systems: Study based on MARL](https://arxiv.org/abs/2510.07888)
*Xinren Zhang,Sixi Cheng,Zixin Zhong,Jiadong Yu*

Main category: cs.MA

TL;DR: 본 논문은 다중 에이전트 시스템에서 통신 구조와 정보 효율성을 통해 성능을 개선하는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템(MAS)은 개별 의사결정 능력을 가진 자율적 엔티티들이 협력하여 복잡한 문제를 해결하는 데 초점을 맞추고 있다.

Method: 본 논문에서는 방향성 및 순차적 통신 토폴로지를 활용하여 성능을 향상시키고, 정보 엔트로피 효율성 지수(IEI)와 전문화 효율성 지수(SEI)라는 두 가지 지표를 도입하여 메시지의 압축성과 역할 차별화 평가를 제안한다.

Result: 우리의 연구 결과는 동질적 및 이질적 작업 모두에서 이러한 통신 방식을 통해 성능이 개선되고 통신 과부하가 감소함을 보여준다.

Conclusion: 정보 효율적인 메시징을 갖춘 적응형 통신 토폴로지를 설계하는 것이 복잡한 MAS에서 효과적인 조정을 위해 필수적임을 강조한다.

Abstract: Multi-agent systems (MAS) solve complex problems through coordinated
autonomous entities with individual decision-making capabilities. While
Multi-Agent Reinforcement Learning (MARL) enables these agents to learn
intelligent strategies, it faces challenges of non-stationarity and partial
observability. Communications among agents offer a solution, but questions
remain about its optimal structure and evaluation. This paper explores two
underexamined aspects: communication topology and information efficiency. We
demonstrate that directed and sequential topologies improve performance while
reducing communication overhead across both homogeneous and heterogeneous
tasks. Additionally, we introduce two metrics -- Information Entropy Efficiency
Index (IEI) and Specialization Efficiency Index (SEI) -- to evaluate message
compactness and role differentiation. Incorporating these metrics into training
objectives improves success rates and convergence speed. Our findings highlight
that designing adaptive communication topologies with information-efficient
messaging is essential for effective coordination in complex MAS.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [2] [Comparison of Fully Homomorphic Encryption and Garbled Circuit Techniques in Privacy-Preserving Machine Learning Inference](https://arxiv.org/abs/2510.07457)
*Kalyan Cheerla,Lotfi Ben Othmane,Kirill Morozov*

Main category: cs.CR

TL;DR: 이 논문은 프라이버시 보존 기계 학습을 위한 완전 동형 암호화(FHE)와 암호화 회로(GC)를 비교 평가한다.


<details>
  <summary>Details</summary>
Motivation: 데이터 프라이버시와 모델 기밀성에 대한 우려가 커지고 있으며, 개인 데이터를 보호하면서 추론할 수 있는 방법이 필요하다.

Method: CKKS 방식과 TinyGarble2.0 프레임워크를 사용하여 두 층의 신경망을 구현하고, 준정직 위협 모델 하에서 평가하였다.

Result: 결과는 모듈형 GC가 더 빠른 실행과 낮은 메모리 소비를 제공하지만, FHE는 비대화식 추론을 지원함을 보여준다.

Conclusion: FHE와 GC 사이의 트레이드오프가 존재하며, 각 방식의 장단점을 평가하였다.

Abstract: Machine Learning (ML) is making its way into fields such as healthcare,
finance, and Natural Language Processing (NLP), and concerns over data privacy
and model confidentiality continue to grow. Privacy-preserving Machine Learning
(PPML) addresses this challenge by enabling inference on private data without
revealing sensitive inputs or proprietary models. Leveraging Secure Computation
techniques from Cryptography, two widely studied approaches in this domain are
Fully Homomorphic Encryption (FHE) and Garbled Circuits (GC). This work
presents a comparative evaluation of FHE and GC for secure neural network
inference. A two-layer neural network (NN) was implemented using the CKKS
scheme from the Microsoft SEAL library (FHE) and the TinyGarble2.0 framework
(GC) by IntelLabs. Both implementations are evaluated under the semi-honest
threat model, measuring inference output error, round-trip time, peak memory
usage, communication overhead, and communication rounds. Results reveal a
trade-off: modular GC offers faster execution and lower memory consumption,
while FHE supports non-interactive inference.

</details>


### [3] [Effective and Stealthy One-Shot Jailbreaks on Deployed Mobile Vision-Language Agents](https://arxiv.org/abs/2510.07809)
*Renhua Ding,Xiao Yang,Zhengwei Fang,Jun Luo,Kun He,Jun Zhu*

Main category: cs.CR

TL;DR: 본 논문에서는 스마트폰 사용자 인터페이스를 조작하는 자율 모바일 에이전트에 대한 UI 수준 공격의 취약점을 다루고 있으며, 실제적이고 은밀한 원샷 jailbreak 공격을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 모바일 에이전트의 UI 수준 공격 취약성을 탐구하고, 보다 현실적인 위협 모델을 제시하기 위해.

Method: 악성 어플리케이션에 UI 텍스트에 짧은 프롬프트를 주입하는 원샷 jailbreak 공격을 수행하며, 이를 위해 세 가지 주요 구성 요소(저특권 인식 체인 타겟팅, 사용자 눈에 띄지 않는 활성화, 원샷 프롬프트 효능)를 사용합니다.

Result: 여러 LVLM 백엔드, 폐쇄형 서비스 및 대표적인 오픈소스 모델을 포함한 세 가지 안드로이드 애플리케이션에서 평가한 결과, 단일 샷 시나리오에서 높은 계획 및 실행 탈취율을 관찰했습니다.

Conclusion: 현재 모바일 에이전트에서 근본적인 보안 취약점을 드러내며 자율 스마트폰 작동에 즉각적인 영향을 미칩니다.

Abstract: Large vision-language models (LVLMs) enable autonomous mobile agents to
operate smartphone user interfaces, yet vulnerabilities to UI-level attacks
remain critically understudied. Existing research often depends on conspicuous
UI overlays, elevated permissions, or impractical threat models, limiting
stealth and real-world applicability. In this paper, we present a practical and
stealthy one-shot jailbreak attack that leverages in-app prompt injections:
malicious applications embed short prompts in UI text that remain inert during
human interaction but are revealed when an agent drives the UI via ADB (Android
Debug Bridge). Our framework comprises three crucial components: (1)
low-privilege perception-chain targeting, which injects payloads into malicious
apps as the agent's visual inputs; (2) stealthy user-invisible activation, a
touch-based trigger that discriminates agent from human touches using physical
touch attributes and exposes the payload only during agent operation; and (3)
one-shot prompt efficacy, a heuristic-guided, character-level
iterative-deepening search algorithm (HG-IDA*) that performs one-shot,
keyword-level detoxification to evade on-device safety filters. We evaluate
across multiple LVLM backends, including closed-source services and
representative open-source models within three Android applications, and we
observe high planning and execution hijack rates in single-shot scenarios
(e.g., GPT-4o: 82.5% planning / 75.0% execution). These findings expose a
fundamental security vulnerability in current mobile agents with immediate
implications for autonomous smartphone operation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [Truth-Aware Decoding: A Program-Logic Approach to Factual Language Generation](https://arxiv.org/abs/2510.07331)
*Faruk Alpay,Hamdi Alakkad*

Main category: cs.AI

TL;DR: 본 논문에서는 지식 기반에 부합하는 신경 언어 생성과 정렬된 검증 지향 디코딩 방식인 Truth-Aware Decoding(TAD)을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 언어 생성 모델의 신뢰성 및 정확성을 향상시키기 위해 지식 기반과 연결된 디코딩 기법의 필요성을 제기합니다.

Method: 모던 지침 조정 시스템에 의미적 가드 레이어를 추가하여 제약 기반의 의미론적 구조를 구축합니다.

Result: 실험 및 알고리즘 사례 연구를 통해 가드 레일이 환각을 줄이며 처리량에 대한 타협 없이 효율성을 높이는 것을 확인했습니다.

Conclusion: 대규모 경험적 모델과 공식 검증 간의 실용적인 다리를 제공함으로써 언어 생성의 신뢰성과 효율성을 개선합니다.

Abstract: This paper introduces Truth-Aware Decoding (TAD), a verification-oriented
decoding scheme that aligns neural language generation with knowledge bases.
Situated in the tradition of probabilistic program semantics for sequence
models, TAD augments modern instruction-tuned systems with a lattice of
semantic guards that operate at decode time. Our contributions are fourfold:
(i) a constraint-based semantics that renders oracle filtering as a
program-logic judgment, (ii) a proof that greedy selection enjoys local
likelihood dominance under sound and complete guards (Theorem 2.7), (iii) an
entropy-style invariant that quantifies factual risk via knowledge-aware safe
mass, and (iv) a multi-agent operational calculus with verified Lean artefacts
to certify implementation behaviour. Numerical and algorithmic case studies
confirm that the resulting guardrails reduce hallucinations without sacrificing
throughput, yielding a pragmatic bridge between large-scale empirical models
and formal verification.

</details>


### [5] [L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)](https://arxiv.org/abs/2510.07363)
*Tianxiang Xu,Zhichao Wen,Xinyu Zhao,Jun Wang,Yan Li,Chang Liu*

Main category: cs.AI

TL;DR: 이 논문은 L2M-AID라는 새로운 프레임워크를 제안하여 산업 IoT 보안을 강화하는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 산업 IoT의 통합이 높아짐에 따라 기존 방어 시스템으로는 복잡한 멀티 스테이지 공격을 방어하기 어려워졌다.

Method: L2M-AID는 대형 언어 모델(LLM)에 기반한 다중 에이전트 강화 학습을 활용하여 협력적인 에이전트 팀을 조직한다.

Result: L2M-AID는 97.2%의 탐지율을 달성하며, 잘못된 긍정률을 80% 이상 줄이고 응답 시간을 네 배 향상시킨다.

Conclusion: L2M-AID는 국가 인프라의 보안을 강화하는 안정적이고 새로운 패러다임을 제시한다.

Abstract: The increasing integration of Industrial IoT (IIoT) exposes critical
cyber-physical systems to sophisticated, multi-stage attacks that elude
traditional defenses lacking contextual awareness. This paper introduces
L2M-AID, a novel framework for Autonomous Industrial Defense using
LLM-empowered, Multi-agent reinforcement learning. L2M-AID orchestrates a team
of collaborative agents, each driven by a Large Language Model (LLM), to
achieve adaptive and resilient security. The core innovation lies in the deep
fusion of two AI paradigms: we leverage an LLM as a semantic bridge to
translate vast, unstructured telemetry into a rich, contextual state
representation, enabling agents to reason about adversary intent rather than
merely matching patterns. This semantically-aware state empowers a Multi-Agent
Reinforcement Learning (MARL) algorithm, MAPPO, to learn complex cooperative
strategies. The MARL reward function is uniquely engineered to balance security
objectives (threat neutralization) with operational imperatives, explicitly
penalizing actions that disrupt physical process stability. To validate our
approach, we conduct extensive experiments on the benchmark SWaT dataset and a
novel synthetic dataset generated based on the MITRE ATT&CK for ICS framework.
Results demonstrate that L2M-AID significantly outperforms traditional IDS,
deep learning anomaly detectors, and single-agent RL baselines across key
metrics, achieving a 97.2% detection rate while reducing false positives by
over 80% and improving response times by a factor of four. Crucially, it
demonstrates superior performance in maintaining physical process stability,
presenting a robust new paradigm for securing critical national infrastructure.

</details>


### [6] [ProSEA: Problem Solving via Exploration Agents](https://arxiv.org/abs/2510.07423)
*William Nguyen,Vinh Luong,Christopher Nguyen*

Main category: cs.AI

TL;DR: ProSEA는 탐색 및 계획 진화를 통해 반복적인 문제 해결을 위한 모듈식, 범용 다중 에이전트 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 AI 에이전트들은 정적 계획과 취약한 상호작용으로 인해 진정한 협업이나 적응적 추론에 한계가 있다.

Method: ProSEA는 매니저 에이전트가 도메인 전문화된 전문가 에이전트를 조정하고, 작업을 분해하며, 실패한 시도에서의 구조적 피드백을 기반으로 적응적으로 계획을 재수립하는 계층적 아키텍처를 특징으로 한다.

Result: FinanceBench 벤치마크에서 실험 결과 ProSEA는 인간 피드백 없이도 최신 기법들을 초월하며 추론 중심의 작업에서 강력한 성능을 달성했다.

Conclusion: 이 결과는 ProSEA가 더욱 투명하고 적응적이며 인간에 맞춘 AI 에이전트의 기반으로서의 잠재력을 강조한다.

Abstract: Large language models (LLMs) have empowered AI agents to tackle increasingly
complex tasks. However, most existing agents remain limited to static planning
and brittle interactions, falling short of true collaboration or adaptive
reasoning. We introduce ProSEA, a modular, general-purpose multi-agent
framework designed for iterative problem solving through exploration and plan
evolution. ProSEA features a hierarchical architecture in which a Manager Agent
orchestrates domain-specialized Expert Agents, decomposes tasks, and adaptively
replans based on structured feedback from failed attempts. Unlike prior
systems, ProSEA agents report not only success or failure but also detailed
reasons for failure and newly discovered constraints, enabling dynamic plan
refinement informed by exploratory traces. The framework operates autonomously
but supports seamless integration with human collaborators when needed.
Experiments on the challenging FinanceBench benchmark demonstrate that ProSEA,
even without human feedback, outperforms state-of-the-art baselines and
achieves robust performance across reasoning-heavy tasks. These results
underscore ProSEA's potential as a foundation for more transparent, adaptive,
and human-aligned AI agents.

</details>


### [7] [Measuring and Mitigating Identity Bias in Multi-Agent Debate via Anonymization](https://arxiv.org/abs/2510.07517)
*Hyeong Kyu Choi,Xiaojin Zhu,Yixuan Li*

Main category: cs.AI

TL;DR: 다중 에이전트 토론(MAD)은 여러 에이전트가 답변을 교환하고 그들의 의견을 집계하여 대형 언어 모델(LLM)의 추론을 향상시키는 것을 목표로 한다. 하지만 최근 연구에 따르면 에이전트는 중립적이지 않아 정체성에 따른 아첨과 자기 편향에 취약하다. 본 논문에서는 MAD에서 이러한 편향을 완화하고 수량화할 수 있는 첫 번째 원칙적 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 추론 능력을 개선하고자 하는 필요성 때문이다.

Method: 정체성 가중 베이즈 업데이트 과정으로 토론 역학을 공식화하고, 정체성 마커를 제거하는 응답 익명화 방안을 제안하며, 에이전트가 동료를 따르는 빈도를 측정하는 정체성 편향 계수를 정의한다.

Result: 다수의 모델, 데이터셋 및 토론 라운드를 통한 실험 연구에서 정체성 편향이 널리 퍼져 있으며 아첨이 자기 편향보다 훨씬 더 일반적이라는 것을 확인했다.

Conclusion: MAD 시스템이 출처의 정체성보다는 콘텐츠 기반으로 추론할 수 있도록 하지 않으면 안 된다.

Abstract: Multi-agent debate (MAD) aims to improve large language model (LLM) reasoning
by letting multiple agents exchange answers and then aggregate their opinions.
Yet recent studies reveal that agents are not neutral: they are prone to
identity-driven sycophancy and self-bias, uncritically adopting a peer's view
or stubbornly adhering to their own prior output, undermining the reliability
of debate. In this work, we present the first principled framework that joins
sycophancy and self-bias to mitigate and quantify identity bias in MAD. First,
we formalize the debate dynamics as an identity-weighted Bayesian update
process. Second, we propose response anonymization: by removing identity
markers from prompts, agents cannot distinguish "self" from "peer", which
forces equal weights on agent identity, thereby reducing bias. Third, we define
the Identity Bias Coefficient (IBC), a principled metric that measures how
often an agent follows a peer versus itself. Empirical studies across multiple
models, datasets and debate rounds confirm that identity bias is widespread,
with sycophancy far more common than self-bias. Our findings highlight the need
to "mask" identity to ensure that MAD systems reason based on content rather
than source identity. Code is released in
https://github.com/deeplearning-wisc/MAD-identity-bias.

</details>


### [8] [TS-Agent: A Time Series Reasoning Agent with Iterative Statistical Insight Gathering](https://arxiv.org/abs/2510.07432)
*Penghang Liu,Elizabeth Fons,Svitlana Vyetrenko,Daniel Borrajo,Vamsi Potluru,Manuela Veloso*

Main category: cs.AI

TL;DR: TS-Agent는 통계적 및 구조적 정보를 추출하기 위해 시간 연속 분석 도구를 위임하며 LLM의 강점을 활용하여 단계별로 증거를 수집하고 결론을 도출하는 시간 연속 추론 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLMs)은 추론 및 문제 해결능력이 뛰어나지만 최근 연구에서는 시간 연속 추론 작업에서 여전히 고질적인 문제에 직면해 있음을 보여준다.

Method: TS-Agent는 원시 숫자 시퀀스와 상호작용하고, 출력 결과를 명시적인 증거 로그에 기록하며, 자기 비판 및 최종 품질 게이트의 지침에 따라 추론을 반복적으로 개선한다.

Result: TS-Agent는 이해 기준에서는 최첨단 LLM과 유사한 성능을 달성하며, 기존 모델들이 암기를 의존하고 제로샷 설정에서 실패하는 상황에서도 추론 작업에서 상당한 향상을 보인다.

Conclusion: 이 설계는 멀티모달 정렬 훈련을 피하고, 시간 연속의 본래 형태를 보존하며, 해석 가능성과 검증 가능성을 보장하며, 지식 유출이나 환각을 완화한다.

Abstract: Large language models (LLMs) have shown strong abilities in reasoning and
problem solving, but recent studies reveal that they still struggle with time
series reasoning tasks, where outputs are often affected by hallucination or
knowledge leakage. In this work we propose TS-Agent, a time series reasoning
agent that leverages LLMs strictly for what they excel at, i.e., gathering
evidence and synthesizing it into conclusions through step-by-step reasoning,
while delegating the extraction of statistical and structural information to
time series analytical tools. Instead of mapping time series into text tokens,
images, or embeddings, our agent interacts with raw numeric sequences through
atomic operators, records outputs in an explicit evidence log, and iteratively
refines its reasoning under the guidance of a self-critic and a final quality
gate. This design avoids multi-modal alignment training, preserves the native
form of time series, ensures interpretability and verifiability, and mitigates
knowledge leakage or hallucination. Empirically, we evaluate the agent on
established benchmarks. Our experiments show that TS-Agent achieves performance
comparable to state-of-the-art LLMs on understanding benchmarks, and delivers
significant improvements on reasoning tasks, where existing models often rely
on memorization and fail in zero-shot settings.

</details>


### [9] [Multimodal Safety Evaluation in Generative Agent Social Simulations](https://arxiv.org/abs/2510.07709)
*Alhim Vera,Karen Sanchez,Carlos Hinojosa,Haidar Bin Hamid,Donghoon Kim,Bernard Ghanem*

Main category: cs.AI

TL;DR: 본 논문은 재생산 가능한 시뮬레이션 프레임워크를 도입하여 멀티모달 환경에서 생성 에이전트의 안전성, 일관성 및 신뢰성에 대해 평가한다.


<details>
  <summary>Details</summary>
Motivation: 생성 에이전트의 안전성, 일관성 및 신뢰성에 대한 능력이 제한적이라는 점을 해결하기 위해

Method: 에이전트를 평가하기 위해 안전성 향상, 위험한 활동 탐지, 사회적 역학 측면에서 세 가지 차원으로 연구하였다.

Result: 에이전트들은 멀티모달 모순을 감지할 수 있으나, 안전 계획 보정에서 성공률이 55%에 불과했다.

Conclusion: 현재 아키텍처의 한계를 노출시키고 멀티모달 안전성과 사회적 역학을 연구하기 위한 재생산 가능한 플랫폼을 제공한다.

Abstract: Can generative agents be trusted in multimodal environments? Despite advances
in large language and vision-language models that enable agents to act
autonomously and pursue goals in rich settings, their ability to reason about
safety, coherence, and trust across modalities remains limited. We introduce a
reproducible simulation framework for evaluating agents along three dimensions:
(1) safety improvement over time, including iterative plan revisions in
text-visual scenarios; (2) detection of unsafe activities across multiple
categories of social situations; and (3) social dynamics, measured as
interaction counts and acceptance ratios of social exchanges. Agents are
equipped with layered memory, dynamic planning, multimodal perception, and are
instrumented with SocialMetrics, a suite of behavioral and structural metrics
that quantifies plan revisions, unsafe-to-safe conversions, and information
diffusion across networks. Experiments show that while agents can detect direct
multimodal contradictions, they often fail to align local revisions with global
safety, reaching only a 55 percent success rate in correcting unsafe plans.
Across eight simulation runs with three models - Claude, GPT-4o mini, and
Qwen-VL - five agents achieved average unsafe-to-safe conversion rates of 75,
55, and 58 percent, respectively. Overall performance ranged from 20 percent in
multi-risk scenarios with GPT-4o mini to 98 percent in localized contexts such
as fire/heat with Claude. Notably, 45 percent of unsafe actions were accepted
when paired with misleading visuals, showing a strong tendency to overtrust
images. These findings expose critical limitations in current architectures and
provide a reproducible platform for studying multimodal safety, coherence, and
social dynamics.

</details>


### [10] [ExpertAgent: Enhancing Personalized Education through Dynamic Planning and Retrieval-Augmented Long-Chain Reasoning](https://arxiv.org/abs/2510.07456)
*Binrong Zhu,Guiran Liu,Nina Jiang*

Main category: cs.AI

TL;DR: 이 논문은 개인화된 교육을 위한 신뢰할 수 있는 지식과 적응형 학습 경험을 제공하는 전문가 에이전트 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 교육에서의 고급 생성 인공지능의 적용은 실시간 적응성, 개인화 및 콘텐츠의 신뢰성 부족으로 제한됩니다.

Method: 우리는 ExpertAgent라는 지능형 에이전트 프레임워크를 개발하여 개인화된 교육을 지원하며, 지속적으로 업데이트되는 학생 모델에 기반한 학습 콘텐츠와 전략의 동적 계획을 제공합니다.

Result: 전통적인 정적 학습 콘텐츠의 한계를 극복하고 실시간으로 최적화된 교수 전략과 학습 경험을 제공합니다.

Conclusion: 모든 교육 콘텐츠는 검증된 커리큘럼 저장소에 기반하고 있어 대규모 언어 모델의 환각 위험을 효과적으로 줄이며 신뢰성과 신뢰성을 향상시킵니다.

Abstract: The application of advanced generative artificial intelligence in education
is often constrained by the lack of real-time adaptability, personalization,
and reliability of the content. To address these challenges, we propose
ExpertAgent - an intelligent agent framework designed for personalized
education that provides reliable knowledge and enables highly adaptive learning
experiences. Therefore, we developed ExpertAgent, an innovative learning agent
that provides users with a proactive and personalized learning experience.
ExpertAgent dynamic planning of the learning content and strategy based on a
continuously updated student model. Therefore, overcoming the limitations of
traditional static learning content to provide optimized teaching strategies
and learning experience in real time. All instructional content is grounded in
a validated curriculum repository, effectively reducing hallucination risks in
large language models and improving reliability and trustworthiness.

</details>


### [11] [CompassLLM: A Multi-Agent Approach toward Geo-Spatial Reasoning for Popular Path Query](https://arxiv.org/abs/2510.07516)
*Md. Nazmul Islam Ananto,Shamit Fatin,Mohammed Eunus Ali,Md Rizwan Parvez*

Main category: cs.AI

TL;DR: CompassLLM은 대규모 언어 모델을 활용하여 역사적 궤적 데이터에서 인기 있는 경로 쿼리를 해결하는 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 도시 계획, 내비게이션 최적화 및 여행 추천에서의 응용을 위한 역사적 궤적 데이터로부터 가장 자주 이동하는 경로를 식별하는 중요성이 있다.

Method: CompassLLM은 두 가지 단계로 구성된 파이프라인을 사용하여 인기 경로를 식별하고, 기존 경로가 없을 경우 새 경로를 생성한다.

Result: 실제 및 합성 데이터셋에서 CompassLLM은 SEARCH에서 우수한 정확성을 보였고, GENERATE에서 경쟁력 있는 성능을 발휘하면서 비용 효율적이다.

Conclusion: CompassLLM은 지리적 문제 해결을 위한 대규모 언어 모델의 활용에 대한 새로운 가능성을 제시한다.

Abstract: The popular path query - identifying the most frequented routes between
locations from historical trajectory data - has important applications in urban
planning, navigation optimization, and travel recommendations. While
traditional algorithms and machine learning approaches have achieved success in
this domain, they typically require model training, parameter tuning, and
retraining when accommodating data updates. As Large Language Models (LLMs)
demonstrate increasing capabilities in spatial and graph-based reasoning, there
is growing interest in exploring how these models can be applied to geo-spatial
problems.
  We introduce CompassLLM, a novel multi-agent framework that intelligently
leverages the reasoning capabilities of LLMs into the geo-spatial domain to
solve the popular path query. CompassLLM employs its agents in a two-stage
pipeline: the SEARCH stage that identifies popular paths, and a GENERATE stage
that synthesizes novel paths in the absence of an existing one in the
historical trajectory data. Experiments on real and synthetic datasets show
that CompassLLM demonstrates superior accuracy in SEARCH and competitive
performance in GENERATE while being cost-effective.

</details>


### [12] [AgentAsk: Multi-Agent Systems Need to Ask](https://arxiv.org/abs/2510.07593)
*Bohan Lin,Kuo Yang,Yingchuan Lai,Yudong Zhang,Chen Zhang,Guibin Zhang,Xinlei Yu,Miao Yu,Xu Wang,Yang Wang*

Main category: cs.AI

TL;DR: AgentAsk는 다중 에이전트 시스템의 오류 전파를 방지하기 위한 경량 모듈로, 편리한 통합이 가능하고 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM) 기반의 다중 에이전트 시스템은 협업을 통해 문제 해결 능력을 향상시킬 수 있지만, 단일 에이전트 기준에 비해 성능이 저하되는 경우가 많습니다.

Method: AgentAsk는 통신 메시지를 잠재적인 실패 지점으로 간주하고, 오류 전파를 억제하기 위해 최소한의 질문을 삽입하는 경량 모듈입니다. 이 모듈은 세 가지 단계로 구성됩니다: (i) 실패 추적으로부터의 판단을 정책으로 압축하고, (ii) 언제, 무엇을, 누구에게, 어떻게 물어볼지를 결정하는 정책 감독, (iii) 정확성, 지연 시간 및 비용을 조정하는 강화 학습 목표 E-GRPO로 온라인 최적화.

Result: AgentAsk는 수학, 추론 및 코딩 벤치마크에서 공공 다중 에이전트 구현에 비해 지속적으로 정확성과 강인성을 향상시키면서 오버헤드를 최소한으로 유지합니다.

Conclusion: 우리는 경험적 개선을 넘어, 에지 수준의 오류에 대한 체계적 분류와 링크 로컬 개입을 위한 실용적인 레시피를 제공하여 더욱 신뢰할 수 있는 LLM 기반 다중 에이전트 시스템으로 나아갈 수 있는 확장 가능한 경로를 제시합니다.

Abstract: Multi-agent systems built on large language models (LLMs) promise enhanced
problem-solving capabilities through collaborative division of labor. However,
they frequently underperform single-agent baselines due to edge-level error
cascades: minor inaccuracies at one message handoff propagate across the entire
chain. We propose AgentAsk, a lightweight and plug-and-play clarification
module that treats every inter-agent message as a potential failure point and
inserts minimally necessary questions to arrest error propagation. AgentAsk
follows a three-stage pipeline: (i) distilling edge-level judgments from
curated failure traces into a compact policy, (ii) supervising the policy to
determine when/what/whom/how to ask, and (iii) optimizing online with E-GRPO, a
reinforcement learning objective that balances accuracy, latency, and cost. The
module is architecture-agnostic and easy to integrate into existing
orchestration. Across math, reasoning, and coding benchmarks, AgentAsk
consistently improves accuracy and robustness over public multi-agent
implementations while keeping overhead minimal, with latency and extra cost all
less than 5%, approaching the performance of a strong evaluator. Beyond
empirical improvements, we contribute a principled taxonomy of edge-level
errors and a practical recipe for link-local intervention, offering a scalable
pathway toward more reliable LLM-based multi-agent systems.

</details>


### [13] [Traceability and Accountability in Role-Specialized Multi-Agent LLM Pipelines](https://arxiv.org/abs/2510.07614)
*Amine Barrak*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)으로 구축된 순차 다중 에이전트 시스템은 복잡한 소프트웨어 작업을 자동화할 수 있지만, 오류가 조용히 다음 단계로 전달되어 신뢰하기 어렵다. 본 연구에서는 명확한 역할, 구조화된 핸드오프 및 기록 저장을 통해 오류 발생 시 책임을 분배할 수 있는 추적 가능하고 책임 있는 파이프라인을 연구하였다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 사용한 다중 에이전트 시스템의 신뢰성 문제를 해결하고자 했다.

Method: 플래너 -> 실행자 -> 비평가 파이프라인을 설정하고, 세 가지 벤치마크에서 세 가지 최첨단 LLM의 여덟 가지 구성을 평가하여 오류의 발생 위치, 전파 방식 및 수정 방법을 분석하였다.

Result: (1) 구조적이고 책임 있는 핸드오프를 추가하면 정확성이 크게 개선되고 단순 파이프라인에서 흔히 발생하는 실패를 방지할 수 있다; (2) 모델은 역할별로 명확한 강점과 위험이 있으며(예: 안정적인 계획 vs. 높은 변동성의 비평), 이를 수리 및 피해율로 정량화하였다; (3) 정확도-비용-지연trade-off는 작업에 따라 달라지며, 이질적인 파이프라인이 종종 가장 효율적이다.

Conclusion: 신뢰할 수 있고 예측 가능한 다중 에이전트 시스템의 설계, 추적 및 디버깅을 위한 실용적이고 데이터 기반의 방법을 제공한다.

Abstract: Sequential multi-agent systems built with large language models (LLMs) can
automate complex software tasks, but they are hard to trust because errors
quietly pass from one stage to the next. We study a traceable and accountable
pipeline, meaning a system with clear roles, structured handoffs, and saved
records that let us trace who did what at each step and assign blame when
things go wrong. Our setting is a Planner -> Executor -> Critic pipeline. We
evaluate eight configurations of three state-of-the-art LLMs on three
benchmarks and analyze where errors start, how they spread, and how they can be
fixed. Our results show: (1) adding a structured, accountable handoff between
agents markedly improves accuracy and prevents the failures common in simple
pipelines; (2) models have clear role-specific strengths and risks (e.g.,
steady planning vs. high-variance critiquing), which we quantify with repair
and harm rates; and (3) accuracy-cost-latency trade-offs are task-dependent,
with heterogeneous pipelines often the most efficient. Overall, we provide a
practical, data-driven method for designing, tracing, and debugging reliable,
predictable, and accountable multi-agent systems.

</details>


### [14] [A Case for Leveraging Generative AI to Expand and Enhance Training in the Provision of Mental Health Services](https://arxiv.org/abs/2510.07623)
*Hannah R. Lawrence,Shannon Wiltsey Stirman,Samuel Dorison,Taedong Yun,Megan Jones Bell*

Main category: cs.AI

TL;DR: 생성적 인공지능이 정신 건강 서비스 교육을 향상시키고 확장하는 데 기여할 수 있는 가능성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 정신 건강 분야에서 생성적 인공지능의 잠재적 영향을 명확히 하고, 기존의 치료사 챗봇에 대한 편견을 극복하고자 한다.

Method: 생성적 인공지능을 사용하여 정신 건강 서비스 제공을 위한 교육을 향상시키고 규모를 확장하는 방법을 연구한다.

Result: 실제로 생성적 인공지능이 퇴역 군인들의 정신 건강 교육을 개선한 사례를 제시한다.

Conclusion: 정신 건강 서비스 제공을 위한 교육 지원에 있어 생성적 인공지능에 대한 투자를 확대해야 한다.

Abstract: Generative artificial intelligence (Generative AI) is transforming
healthcare. With this evolution comes optimism regarding the impact it will
have on mental health, as well as concern regarding the risks that come with
generative AI operating in the mental health domain. Much of the investment in,
and academic and public discourse about, AI-powered solutions for mental health
has focused on therapist chatbots. Despite the common assumption that chatbots
will be the most impactful application of GenAI to mental health, we make the
case here for a lower-risk, high impact use case: leveraging generative AI to
enhance and scale training in mental health service provision. We highlight key
benefits of using generative AI to help train people to provide mental health
services and present a real-world case study in which generative AI improved
the training of veterans to support one another's mental health. With numerous
potential applications of generative AI in mental health, we illustrate why we
should invest in using generative AI to support training people in mental
health service provision.

</details>


### [15] [SurveyG: A Multi-Agent LLM Framework with Hierarchical Citation Graph for Automated Survey Generation](https://arxiv.org/abs/2510.07733)
*Minh-Anh Nguye,Minh-Duc Nguyen,Nguyen Thi Ha Lan,Kieu Hai Dang,Nguyen Tien Dong,Le Duy Dung*

Main category: cs.AI

TL;DR: 이 논문에서는 연구 문헌 생성 자동화에 LLM을 활용하는 새로운 접근 방식인 SurveyG를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 LLM 기반 방법론이 연구 문헌의 구조적 관계를 간과하여 일관성 없는 설계를 초래하는 문제를 해결하고자 한다.

Method: SurveyG는 계층적 인용 그래프를 통해 연구 논문 간의 인용 의존성과 내용의 의미적 관련성을 통합하여 설문 생성을 지원하는 프레임워크이다.

Result: 다양한 실험을 통해 SurveyG가 기존의 최신 기술 프레임워크보다 더 포괄적이고 구조화된 설문을 생성함을 입증하였다.

Conclusion: 이 프레임워크는 연구 발전의 진화 과정을 포착하고, 최종 설문 생성의 일관성, 범위 및 정확성을 보장한다.

Abstract: Large language models (LLMs) are increasingly adopted for automating survey
paper generation \cite{wang2406autosurvey, liang2025surveyx,
yan2025surveyforge,su2025benchmarking,wen2025interactivesurvey}. Existing
approaches typically extract content from a large collection of related papers
and prompt LLMs to summarize them directly. However, such methods often
overlook the structural relationships among papers, resulting in generated
surveys that lack a coherent taxonomy and a deeper contextual understanding of
research progress. To address these shortcomings, we propose \textbf{SurveyG},
an LLM-based agent framework that integrates \textit{hierarchical citation
graph}, where nodes denote research papers and edges capture both citation
dependencies and semantic relatedness between their contents, thereby embedding
structural and contextual knowledge into the survey generation process. The
graph is organized into three layers: \textbf{Foundation},
\textbf{Development}, and \textbf{Frontier}, to capture the evolution of
research from seminal works to incremental advances and emerging directions. By
combining horizontal search within layers and vertical depth traversal across
layers, the agent produces multi-level summaries, which are consolidated into a
structured survey outline. A multi-agent validation stage then ensures
consistency, coverage, and factual accuracy in generating the final survey.
Experiments, including evaluations by human experts and LLM-as-a-judge,
demonstrate that SurveyG outperforms state-of-the-art frameworks, producing
surveys that are more comprehensive and better structured to the underlying
knowledge taxonomy of a field.

</details>


### [16] [Haibu Mathematical-Medical Intelligent Agent:Enhancing Large Language Model Reliability in Medical Tasks via Verifiable Reasoning Chains](https://arxiv.org/abs/2510.07748)
*Yilun Zhang,Dexing Kong*

Main category: cs.AI

TL;DR: MMIA는 신뢰성을 높이기 위해 LLM이 드라이브하는 수학적-의료 지능 에이전트로, 의학 분야에서의 오류를 줄이는 혁신적인 접근 방식을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 의학 분야에서 발생할 수 있는 사실적 및 논리적 오류를 해결하기 위해 고안됨.

Method: MMIA는 복잡한 의료 작업을 근거 기반의 단계로 분해하고, 이 과정의 모든 추론 체인을 자동으로 감사하여 논리적 일관성과 증거 추적이 가능하도록 한다.

Result: MMIA는 98% 이상의 오류 탐지율과 1% 미만의 가짜 긍정률을 기록하며, 기존 LLM보다 뛰어난 성과를 나타냈다.

Conclusion: MMIA의 검증 가능한 추론 체계가 신뢰할 수 있고 투명하며 비용 효율적인 AI 시스템 개발의 중요한 진전을 나타낸다.

Abstract: Large Language Models (LLMs) show promise in medicine but are prone to
factual and logical errors, which is unacceptable in this high-stakes field. To
address this, we introduce the "Haibu Mathematical-Medical Intelligent Agent"
(MMIA), an LLM-driven architecture that ensures reliability through a formally
verifiable reasoning process. MMIA recursively breaks down complex medical
tasks into atomic, evidence-based steps. This entire reasoning chain is then
automatically audited for logical coherence and evidence traceability, similar
to theorem proving. A key innovation is MMIA's "bootstrapping" mode, which
stores validated reasoning chains as "theorems." Subsequent tasks can then be
efficiently solved using Retrieval-Augmented Generation (RAG), shifting from
costly first-principles reasoning to a low-cost verification model. We
validated MMIA across four healthcare administration domains, including DRG/DIP
audits and medical insurance adjudication, using expert-validated benchmarks.
Results showed MMIA achieved an error detection rate exceeding 98% with a false
positive rate below 1%, significantly outperforming baseline LLMs. Furthermore,
the RAG matching mode is projected to reduce average processing costs by
approximately 85% as the knowledge base matures. In conclusion, MMIA's
verifiable reasoning framework is a significant step toward creating
trustworthy, transparent, and cost-effective AI systems, making LLM technology
viable for critical applications in medicine.

</details>


### [17] [An approach for systematic decomposition of complex llm tasks](https://arxiv.org/abs/2510.07772)
*Tianle Zhou,Jiakai Xu,Guanhong Liu,Jiaxiang Liu,Haonan Wang,Eugene Wu*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLMs)은 복잡한 작업에서 신뢰성 문제를 겪고 있으며, 본 연구에서는 작업을 제약 문제로 모델링하고 공식적인 복잡성 측정을 활용하여 새로운 체계적인 분해 프레임워크인 ACONIC을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 분해 방법이 휴리스틱적이며 에이전트나 수동 분해에 의존하여 복잡한 작업에서 신뢰성 문제를 보이고 있기 때문에, 보다 효과적인 분해 방법이 필요하다.

Method: 제약 문제로 작업을 모델링하고, 공식적인 복잡성 측정을 사용하여 작업을 분해하는 ACONIC이라는 체계적인 분해 프레임워크를 제안한다.

Result: 복잡성 측정을 따르면서 작업을 분해할 경우, 에이전트의 성능이 상당히 향상되어 10-40 퍼센트 포인트의 개선을 보인다.

Conclusion: ACONIC 프레임워크는 분해 작업을 통한 성능 개선의 가능성을 보여준다.

Abstract: Large Language Models (LLMs) suffer from reliability issues on complex tasks,
as existing decomposition methods are heuristic and rely on agent or manual
decomposition. This work introduces a novel, systematic decomposition framework
that we call Analysis of CONstraint-Induced Complexity (ACONIC), which models
the task as a constraint problem and leveraging formal complexity measures to
guide decomposition. On combinatorial (SATBench) and LLM database querying
tasks (Spider), we find that by decomposing the tasks following the measure of
complexity, agent can perform considerably better (10-40 percentage point).

</details>


### [18] [Strategic Communication under Threat: Learning Information Trade-offs in Pursuit-Evasion Games](https://arxiv.org/abs/2510.07813)
*Valerio La Gatta,Dolev Mutzari,Sarit Kraus,VS Subrahmanian*

Main category: cs.AI

TL;DR: SHADOW라는 다중 머리 순차 강화 학습 프레임워크를 통해, 추격자는 정보 통신의 타이밍을 결정하여 도망자의 위치를 파악하고 성공률을 높일 수 있다.


<details>
  <summary>Details</summary>
Motivation: 적대적 환경에서 정보 습득은 상황 인식을 향상시키지만, 동시에 위협에 노출될 수 있는 전략적 균형이 필요하다.

Method: Pursuit-Evasion-Exposure-Concealment Game (PEEC) 모델을 설정하고, 강화 학습을 통해 추격자와 도망자의 이동 정책 및 통신 정책을 학습시킨다.

Result: SHADOW 추격자는 여섯 개의 경쟁 기준선보다 높은 성공률을 보였으며, 시간 순서 모델링과 상대 모델링이 효과적인 의사결정에 중요하다는 것을 확인했다.

Conclusion: 배운 정책은 다양한 통신 위험과 에이전트 간의 물리적 비대칭에서도 잘 일반화된다.

Abstract: Adversarial environments require agents to navigate a key strategic
trade-off: acquiring information enhances situational awareness, but may
simultaneously expose them to threats. To investigate this tension, we
formulate a PursuitEvasion-Exposure-Concealment Game (PEEC) in which a pursuer
agent must decide when to communicate in order to obtain the evader's position.
Each communication reveals the pursuer's location, increasing the risk of being
targeted. Both agents learn their movement policies via reinforcement learning,
while the pursuer additionally learns a communication policy that balances
observability and risk. We propose SHADOW (Strategic-communication Hybrid
Action Decision-making under partial Observation for Warfare), a multi-headed
sequential reinforcement learning framework that integrates continuous
navigation control, discrete communication actions, and opponent modeling for
behavior prediction. Empirical evaluations show that SHADOW pursuers achieve
higher success rates than six competitive baselines. Our ablation study
confirms that temporal sequence modeling and opponent modeling are critical for
effective decision-making. Finally, our sensitivity analysis reveals that the
learned policies generalize well across varying communication risks and
physical asymmetries between agents.

</details>


### [19] [An LLM-Powered Cooperative Framework for Large-Scale Multi-Vehicle Navigation](https://arxiv.org/abs/2510.07825)
*Yuping Zhou,Siqi Lai,Jindong Han,Hao Liu*

Main category: cs.AI

TL;DR: CityNav는 대규모 다중 차량 내비게이션을 위한 LLM 기반의 계층적 프레임워크로, 기존 경로 탐색 알고리즘과 RL 방법의 한계를 극복하고 도시 규모의 교통 효율성을 높인다.


<details>
  <summary>Details</summary>
Motivation: IoV 기술의 발전은 교통 관리 방식을 고립된 통제에서 집합적 다중 차량 과정으로 변화시키고 있다.

Method: CityNav는 지역 간 전략적 교통 흐름 분배를 조정하는 글로벌 교통 할당 에이전트와 글로벌 지침에 맞춘 지역 적응 경로를 생성하는 지역 내비게이션 에이전트를 통합한 것이다.

Result: CityNav는 다양한 규모의 4개 실제 도로 네트워크에서 도시 규모의 여행 효율성과 혼잡 완화에서 9개의 기존 경로 탐색 및 RL 기반 기준선을 일관되게 초월했다.

Conclusion: LLM을 활용한 CityNav는 복잡한 도시 환경에서 지능적이고 대규모 차량 라우팅의 기초를 제공한다.

Abstract: The rise of Internet of Vehicles (IoV) technologies is transforming traffic
management from isolated control to a collective, multi-vehicle process. At the
heart of this shift is multi-vehicle dynamic navigation, which requires
simultaneously routing large fleets under evolving traffic conditions. Existing
path search algorithms and reinforcement learning methods struggle to scale to
city-wide networks, often failing to capture the nonlinear, stochastic, and
coupled dynamics of urban traffic. To address these challenges, we propose
CityNav, a hierarchical, LLM-powered framework for large-scale multi-vehicle
navigation. CityNav integrates a global traffic allocation agent, which
coordinates strategic traffic flow distribution across regions, with local
navigation agents that generate locally adaptive routes aligned with global
directives. To enable effective cooperation, we introduce a cooperative
reasoning optimization mechanism, in which agents are jointly trained with a
dual-reward structure: individual rewards promote per-vehicle efficiency, while
shared rewards encourage network-wide coordination and congestion reduction.
Extensive experiments on four real-world road networks of varying scales (up to
1.6 million roads and 430,000 intersections) and traffic datasets demonstrate
that CityNav consistently outperforms nine classical path search and RL-based
baselines in city-scale travel efficiency and congestion mitigation. Our
results highlight the potential of LLMs to enable scalable, adaptive, and
cooperative city-wide traffic navigation, providing a foundation for
intelligent, large-scale vehicle routing in complex urban environments. Our
project is available at https://github.com/usail-hkust/CityNav.

</details>


### [20] [Augur: Modeling Covariate Causal Associations in Time Series via Large Language Models](https://arxiv.org/abs/2510.07858)
*Zhiqing Cui,Binwu Wang,Qingxiang Liu,Yeqiang Wang,Zhengyang Zhou,Yuxuan Liang,Yang Wang*

Main category: cs.AI

TL;DR: Augur는 LLM을 활용한 시계열 예측 프레임워크로, 인과 추론을 통해 변인 간의 인과 관계를 발견하고 활용한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 시계열 예측 접근법은 겪고 있는 한계를 극복하고자 한다.

Method: 두 단계의 교사-학생 아키텍처를 사용하여 교사 LLM이 시계열로부터 인과 그래프를 추론하고, 학생 에이전트가 이를 다듬어 예측을 수행한다.

Result: Augur는 실세계 데이터셋을 바탕으로 25개의 기준선과 비교해 경쟁력 있는 성능과 뛰어난 제로샷 일반화를 달성했다.

Conclusion: 이 설계는 예측 정확도를 개선하면서 변수 상호작용에 대한 투명하고 추적 가능한 추론을 제공한다.

Abstract: Large language models (LLM) have emerged as a promising avenue for time
series forecasting, offering the potential to integrate multimodal data.
However, existing LLM-based approaches face notable limitations-such as
marginalized role in model architectures, reliance on coarse statistical text
prompts, and lack of interpretability. In this work, we introduce Augur, a
fully LLM driven time series forecasting framework that exploits LLM causal
reasoning to discover and use directed causal associations among covariates.
Augur uses a two stage teacher student architecture where a powerful teacher
LLM infers a directed causal graph from time series using heuristic search
together with pairwise causality testing. A lightweight student agent then
refines the graph and fine tune on high confidence causal associations that are
encoded as rich textual prompts to perform forecasting. This design improves
predictive accuracy while yielding transparent, traceable reasoning about
variable interactions. Extensive experiments on real-world datasets with 25
baselines demonstrate that Augur achieves competitive performance and robust
zero-shot generalization.

</details>


### [21] [Understanding DeepResearch via Reports](https://arxiv.org/abs/2510.07861)
*Tianyu Fan,Xinyao Niu,Yuxiang Zheng,Fengji Zhang,Chengen Huang,Bei Chen,Junyang Lin,Chao Huang*

Main category: cs.AI

TL;DR: DeepResearch 에이전트는 AI 연구 paradigm을 혁신적으로 변화시키는 시스템으로, 연구 보고서 평가를 통해 성능을 측정하는 새로운 프레임워크인 DeepResearch-ReportEval을 제안한다.


<details>
  <summary>Details</summary>
Motivation: DeepResearch 시스템의 평가가 기존의 벤치마크로는 어렵고, 연구 성과를 종합적으로 측정할 필요성이 있다.

Method: DeepResearch-ReportEval 프레임워크는 연구 보고서를 통해 품질, 중복성, 사실성을 측정하고 혁신적인 LLM-as-a-Judge 방법론을 사용한다.

Result: 상위 4개 상업 시스템의 평가 결과, 각기 다른 설계 철학과 성과 간의 균형을 보여준다.

Conclusion: DeepResearch가 정보 조수에서 지능형 연구 파트너로 발전함에 따라 기초적인 통찰력이 정립된다.

Abstract: DeepResearch agents represent a transformative AI paradigm, conducting
expert-level research through sophisticated reasoning and multi-tool
integration. However, evaluating these systems remains critically challenging
due to open-ended research scenarios and existing benchmarks that focus on
isolated capabilities rather than holistic performance. Unlike traditional LLM
tasks, DeepResearch systems must synthesize diverse sources, generate insights,
and present coherent findings, which are capabilities that resist simple
verification. To address this gap, we introduce DeepResearch-ReportEval, a
comprehensive framework designed to assess DeepResearch systems through their
most representative outputs: research reports. Our approach systematically
measures three dimensions: quality, redundancy, and factuality, using an
innovative LLM-as-a-Judge methodology achieving strong expert concordance. We
contribute a standardized benchmark of 100 curated queries spanning 12
real-world categories, enabling systematic capability comparison. Our
evaluation of four leading commercial systems reveals distinct design
philosophies and performance trade-offs, establishing foundational insights as
DeepResearch evolves from information assistants toward intelligent research
partners. Source code and data are available at:
https://github.com/HKUDS/DeepResearch-Eval.

</details>


### [22] [Profit Mirage: Revisiting Information Leakage in LLM-based Financial Agents](https://arxiv.org/abs/2510.07920)
*Xiangyu Li,Yawen Zeng,Xiaofen Xing,Jin Xu,Xiangmin Xu*

Main category: cs.AI

TL;DR: LLM 기반 금융 에이전트의 정보 누수 문제를 정량화하고, 이를 해결하기 위한 새로운 프레임워크를 제안하여 성능을 향상시킴.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 금융 에이전트가 인간 전문가처럼 거래할 수 있는 능력 때문에 큰 관심을 받고 있지만, 대부분 시스템은 정보 누수로 인해 성과가 저하되는 문제를 나타냄.

Method: FactFin 프레임워크는 반사실적 변동을 적용하여 LLM 기반 에이전트가 암기된 결과 대신 인과적 요인을 학습하도록 유도하고, 네 가지 핵심 구성 요소를 포함함.

Result: 폭넓은 실험을 통해 제안 방법이 아웃 오브 샘플 일반화에서 모든 기준선을 초과하며, 우수한 위험 조정 성능을 제공함을 보여줌.

Conclusion: 정보 누수 문제를 해결하고 LLM 기반 금융 에이전트의 성능을 크게 향상시키는 데 기여함.

Abstract: LLM-based financial agents have attracted widespread excitement for their
ability to trade like human experts. However, most systems exhibit a "profit
mirage": dazzling back-tested returns evaporate once the model's knowledge
window ends, because of the inherent information leakage in LLMs. In this
paper, we systematically quantify this leakage issue across four dimensions and
release FinLake-Bench, a leakage-robust evaluation benchmark. Furthermore, to
mitigate this issue, we introduce FactFin, a framework that applies
counterfactual perturbations to compel LLM-based agents to learn causal drivers
instead of memorized outcomes. FactFin integrates four core components:
Strategy Code Generator, Retrieval-Augmented Generation, Monte Carlo Tree
Search, and Counterfactual Simulator. Extensive experiments show that our
method surpasses all baselines in out-of-sample generalization, delivering
superior risk-adjusted performance.

</details>


### [23] [Enabling Personalized Long-term Interactions in LLM-based Agents through Persistent Memory and User Profiles](https://arxiv.org/abs/2510.07925)
*Rebecca Westhäußer,Wolfgang Minker,Sebatian Zepf*

Main category: cs.AI

TL;DR: 이 논문은 개인화된 상호작용을 위한 기술적 요구사항을 파악하고, 지속적인 메모리와 동적 조정을 통합하여 LLM 기반 에이전트의 개인화된 장기 상호작용을 가능하게 하는 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현재 대형 언어 모델은 AI 에이전트의 중심 제어 장치로 사용되고 있지만, 개인화된 상호작용을 제공하는 데 한계가 있다.

Method: 우리는 개인화에 대한 통합된 정의를 바탕으로 LLM 기반 에이전트를 위한 기술적 요구사항을 도출하고, 지속적인 메모리와 동적 조정 등을 통합한 프레임워크를 제시한다.

Result: 우리의 접근법은 세 가지 공개 데이터셋에서 평가되었으며, 검색 정확도와 응답 정확성과 같은 메트릭을 사용하여 검증되었다.

Conclusion: 사전 연구 결과는 향후 연구 방향을 제시하고, 지속적인 메모리와 사용자 프로필을 통합하여 LLM 기반 에이전트의 적응성과 개인화 인식을 개선할 수 있는 가능성을 강조한다.

Abstract: Large language models (LLMs) increasingly serve as the central control unit
of AI agents, yet current approaches remain limited in their ability to deliver
personalized interactions. While Retrieval Augmented Generation enhances LLM
capabilities by improving context-awareness, it lacks mechanisms to combine
contextual information with user-specific data. Although personalization has
been studied in fields such as human-computer interaction or cognitive science,
existing perspectives largely remain conceptual, with limited focus on
technical implementation. To address these gaps, we build on a unified
definition of personalization as a conceptual foundation to derive technical
requirements for adaptive, user-centered LLM-based agents. Combined with
established agentic AI patterns such as multi-agent collaboration or
multi-source retrieval, we present a framework that integrates persistent
memory, dynamic coordination, self-validation, and evolving user profiles to
enable personalized long-term interactions. We evaluate our approach on three
public datasets using metrics such as retrieval accuracy, response correctness,
or BertScore. We complement these results with a five-day pilot user study
providing initial insights into user feedback on perceived personalization. The
study provides early indications that guide future work and highlights the
potential of integrating persistent memory and user profiles to improve the
adaptivity and perceived personalization of LLM-based agents.

</details>


### [24] [Agent-Based Genetic Algorithm for Crypto Trading Strategy Optimization](https://arxiv.org/abs/2510.07943)
*Qiushi Tian,Churong Liang,Kairan Hong,Runnan Li*

Main category: cs.AI

TL;DR: CGA-Agent는 암호화폐 거래 전략 최적화를 위한 혁신적인 하이브리드 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 암호화폐 시장의 극심한 변동성과 비정상적 동적 특성으로 인해 기존의 매개변수 최적화 방법이 부적절하다.

Method: 유전자 알고리즘과 지능형 다중 에이전트 조정 메커니즘을 통합하여 적응형 거래 전략 매개변수 최적화를 수행한다.

Result: 세 가지 암호화폐를 대상으로 한 포괄적인 실증 평가 결과, 총 수익 및 위험 조정 지표에서 통계적으로 유의미한 성과 향상이 나타났다.

Conclusion: CGA-Agent는 정적 최적화 접근 방식의 한계를 초월하는 진화적 과정을 동적으로 안내하여 거래 전략 최적화를 지원한다.

Abstract: Cryptocurrency markets present formidable challenges for trading strategy
optimization due to extreme volatility, non-stationary dynamics, and complex
microstructure patterns that render conventional parameter optimization methods
fundamentally inadequate. We introduce Cypto Genetic Algorithm Agent
(CGA-Agent), a pioneering hybrid framework that synergistically integrates
genetic algorithms with intelligent multi-agent coordination mechanisms for
adaptive trading strategy parameter optimization in dynamic financial
environments. The framework uniquely incorporates real-time market
microstructure intelligence and adaptive strategy performance feedback through
intelligent mechanisms that dynamically guide evolutionary processes,
transcending the limitations of static optimization approaches. Comprehensive
empirical evaluation across three cryptocurrencies demonstrates systematic and
statistically significant performance improvements on both total returns and
risk-adjusted metrics.

</details>


### [25] [VoiceAgentBench: Are Voice Assistants ready for agentic tasks?](https://arxiv.org/abs/2510.07978)
*Dhruv Jain,Harshit Shukla,Gautam Rajeev,Ashish Kulkarni,Chandra Khatri,Shubham Agarwal*

Main category: cs.AI

TL;DR: VoiceAgentBench는 SpeechLMs를 평가하기 위한 포괄적인 벤치마크로, 5,500개 이상의 합성 음성 쿼리를 포함하고 있으며, 실제 음성 에이전트 환경에서의 다국어 및 문화적 이해와 적대적 강건성을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 음성 벤치마크는 주로 단독 기능(예: 전사 또는 질의응답)에 집중하고 있어, 다국어 및 문화적 이해와 적대적 강건성을 포괄하는 에이전틱 상황을 체계적으로 평가하지 않고 있다.

Method: VoiceAgentBench는 5,500개 이상의 합성 음성 쿼리로 구성되어 있으며, 영어, 힌디어 및 기타 5개 인도 언어를 지원한다. TTS 음성 변환을 위해 화자 임베딩을 기반으로 오디오를 선택하는 새로운 샘플링 알고리즘을 사용하여 화자 변동성을 시뮬레이션 한다.

Result: 실험을 통해 문맥 기반 도구 오케스트레이션 작업, 인도 일반화, 적대적 강건성에서 중요한 차이를 드러내어 현재의 SpeechLMs의 주요 한계를 노출시켰다.

Conclusion: VoiceAgentBench는 SpeechLMs의 실제 음성 에이전트 환경에서의 성능을 평가하는 새로운 기준을 제공하며, 현재 기술의 한계를 분명히 드러낸다.

Abstract: Large-scale Speech Language Models (SpeechLMs) have enabled voice assistants
capable of understanding natural spoken queries and performing complex tasks.
However, existing speech benchmarks primarily focus on isolated capabilities
such as transcription, or question-answering, and do not systematically
evaluate agentic scenarios encompassing multilingual and cultural
understanding, as well as adversarial robustness. To address this, we introduce
VoiceAgentBench, a comprehensive benchmark designed to evaluate SpeechLMs in
realistic spoken agentic settings. It comprises over 5,500 synthetic spoken
queries, including dialogues grounded in Indian context, covering single-tool
invocations, multi-tool workflows, multi-turn interactions, and safety
evaluations. The benchmark supports English, Hindi, and 5 other Indian
languages, reflecting real-world linguistic and cultural diversity. We simulate
speaker variability using a novel sampling algorithm that selects audios for
TTS voice conversion based on its speaker embeddings, maximizing acoustic and
speaker diversity. Our evaluation measures tool selection accuracy, structural
consistency, and the correctness of tool invocations, including adversarial
robustness. Our experiments reveal significant gaps in contextual tool
orchestration tasks, Indic generalization, and adversarial robustness, exposing
critical limitations of current SpeechLMs.

</details>


### [26] [ReInAgent: A Context-Aware GUI Agent Enabling Human-in-the-Loop Mobile Task Navigation](https://arxiv.org/abs/2510.07988)
*Haitao Jia,Ming He,Zimo Yin,Likang Wu,Jianping Fan,Jitao Sang*

Main category: cs.AI

TL;DR: ReInAgent는 사용자 참여를 강조하여 복잡한 모바일 작업을 더 잘 탐색할 수 있도록 하는 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 모바일 GUI 에이전트는 사용자의 적극적인 참여를 간과하여 작업 실행 중 진정한 사용자 요구 및 선호도와 편차가 발생할 수 있다.

Method: ReInAgent는 슬롯 기반 정보 관리를 위한 정보 관리 에이전트, 충돌 인식 계획을 위한 의사 결정 에이전트, 작업 반성과 정보 일관성 검증을 위한 반영 에이전트를 통합하여 사용자와 에이전트의 협업을 통해 인간-중재 모바일 작업 내비게이션을 가능하게 한다.

Result: 실험 결과, ReInAgent는 정보 딜레마를 효과적으로 해결하고 진정한 사용자 선호와 더 밀접하게 일치하는 결과를 생성하였다. 특히, 정보 딜레마가 있는 복잡한 작업에서는 Mobile-Agent-v2보다 25% 높은 성공률을 기록하였다.

Conclusion: ReInAgent는 복잡한 현실 시나리오에서 더 적응 가능하고 신뢰할 수 있는 모바일 작업 내비게이션을 가능하게 한다.

Abstract: Mobile GUI agents exhibit substantial potential to facilitate and automate
the execution of user tasks on mobile phones. However, exist mobile GUI agents
predominantly privilege autonomous operation and neglect the necessity of
active user engagement during task execution. This omission undermines their
adaptability to information dilemmas including ambiguous, dynamically evolving,
and conflicting task scenarios, leading to execution outcomes that deviate from
genuine user requirements and preferences. To address these shortcomings, we
propose ReInAgent, a context-aware multi-agent framework that leverages dynamic
information management to enable human-in-the-loop mobile task navigation.
ReInAgent integrates three specialized agents around a shared memory module: an
information-managing agent for slot-based information management and proactive
interaction with the user, a decision-making agent for conflict-aware planning,
and a reflecting agent for task reflection and information consistency
validation. Through continuous contextual information analysis and sustained
user-agent collaboration, ReInAgent overcomes the limitation of existing
approaches that rely on clear and static task assumptions. Consequently, it
enables more adaptive and reliable mobile task navigation in complex,
real-world scenarios. Experimental results demonstrate that ReInAgent
effectively resolves information dilemmas and produces outcomes that are more
closely aligned with genuine user preferences. Notably, on complex tasks
involving information dilemmas, ReInAgent achieves a 25% higher success rate
than Mobile-Agent-v2.

</details>


### [27] [AILoRA: Function-Aware Asymmetric Initialization for Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2510.08034)
*Xiaoshuang Ji,Zhendong Zhao,Xiaoyan Gu,Xiaojun Chen,Xin Zhao,Zeyao Liu*

Main category: cs.AI

TL;DR: 본 논문은 매개변수 효율적인 미세 조정 방법인 AILoRA를 제안하며, 이는 소프트웨어 성능과 매개변수 효율성 간의 효과적인 균형을 이루기 위한 기법이다.


<details>
  <summary>Details</summary>
Motivation: 대규모 사전 훈련된 모델을 다양한 하위 작업에 적응시키는 데 소요되는 막대한 계산 및 메모리 오버헤드를 완화하고자 한다.

Method: AILoRA는 기능 인식 비대칭 저순위 사전 정보를 통합하여 성능을 향상시키는 새로운 매개변수 효율적 방법이다.

Result: AILoRA는 자가 주의 메커니즘에서 $W^Q$와 $W^V$ 매트릭스의 독특한 매개변수 특성을 분석하고, 비대칭 초기화 전략을 통해 성능과 수렴 효율성을 높인다.

Conclusion: AILoRA는 미세 조정 성능과 수렴 효율성을 강화하여 주의 매개변수의 전문화된 역할을 더 잘 캡처할 수 있도록 한다.

Abstract: Parameter-efficient finetuning (PEFT) aims to mitigate the substantial
computational and memory overhead involved in adapting large-scale pretrained
models to diverse downstream tasks. Among numerous PEFT strategies, Low-Rank
Adaptation (LoRA) has emerged as one of the most widely adopted approaches due
to its robust empirical performance and low implementation complexity. In
practical deployment, LoRA is typically applied to the $W^Q$ and $W^V$
projection matrices of self-attention modules, enabling an effective trade-off
between model performance and parameter efficiency. While LoRA has achieved
considerable empirical success, it still encounters challenges such as
suboptimal performance and slow convergence. To address these limitations, we
introduce \textbf{AILoRA}, a novel parameter-efficient method that incorporates
function-aware asymmetric low-rank priors. Our empirical analysis reveals that
the projection matrices $W^Q$ and $W^V$ in the self-attention mechanism exhibit
distinct parameter characteristics, stemming from their functional differences.
Specifically, $W^Q$ captures task-specific semantic space knowledge essential
for attention distributions computation, making its parameters highly sensitive
to downstream task variations. In contrast, $W^V$ encodes token-level feature
representations that tend to remain stable across tasks and layers. Leveraging
these insights, AILoRA performs a function-aware initialization by injecting
the principal components of $W^Q$ to retain task-adaptive capacity, and the
minor components of $W^V$ to preserve generalizable feature representations.
This asymmetric initialization strategy enables LoRA modules to better capture
the specialized roles of attention parameters, thereby enhancing both
finetuning performance and convergence efficiency.

</details>


### [28] [AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment](https://arxiv.org/abs/2510.08081)
*Xiaochong Lan,Jie Feng,Yinxing Liu,Xinlei Shi,Yong Li*

Main category: cs.AI

TL;DR: 본 연구에서는 리뷰의 내재적 품질을 평가하기 위한 새로운 자동화된 프레임워크인 AutoQual을 제안하며, 이는 사용자의 경험과 비즈니스 결과에 영향을 미친다.


<details>
  <summary>Details</summary>
Motivation: 온라인 리뷰의 내재적 품질을 평가하는 것은 전자 상거래 플랫폼과 정보 서비스에 있어 중요한 과제로, 사용자 경험과 비즈니스 결과에 상응하는 영향을 미친다.

Method: AutoQual은 해석 가능한 특징의 발견을 자동화하는 LLM 기반 에이전트 프레임워크로 설계되어 있으며, 데이터에 내재된 암묵적 지식을 명시적이고 계산 가능한 특징으로 변환하는 데 중점을 둔다.

Result: 대규모 A/B 테스트를 통해 리뷰 열람 수를 사용자당 0.79% 증가시키고, 리뷰 독자의 전환율을 0.27% 증가시키는 효과가 입증되었다.

Conclusion: AutoQual은 리뷰 품질 평가 분야에서의 실용성을 입증하며, 데이터 기반 인사이트를 효과적으로 제공하는 역할을 한다.

Abstract: Ranking online reviews by their intrinsic quality is a critical task for
e-commerce platforms and information services, impacting user experience and
business outcomes. However, quality is a domain-dependent and dynamic concept,
making its assessment a formidable challenge. Traditional methods relying on
hand-crafted features are unscalable across domains and fail to adapt to
evolving content patterns, while modern deep learning approaches often produce
black-box models that lack interpretability and may prioritize semantics over
quality. To address these challenges, we propose AutoQual, an LLM-based agent
framework that automates the discovery of interpretable features. While
demonstrated on review quality assessment, AutoQual is designed as a general
framework for transforming tacit knowledge embedded in data into explicit,
computable features. It mimics a human research process, iteratively generating
feature hypotheses through reflection, operationalizing them via autonomous
tool implementation, and accumulating experience in a persistent memory. We
deploy our method on a large-scale online platform with a billion-level user
base. Large-scale A/B testing confirms its effectiveness, increasing average
reviews viewed per user by 0.79% and the conversion rate of review readers by
0.27%.

</details>


### [29] [Can Risk-taking AI-Assistants suitably represent entities](https://arxiv.org/abs/2510.08114)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Amirhossein Farshi Sotoudeh*

Main category: cs.AI

TL;DR: 이 연구는 언어 모델의 위험 회피 조작 가능성을 조사하고 사람의 위험 선호도를 재현하는 능력을 평가하며, AI 설계를 개선할 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 책임 있는 AI는 사용자에게 위험한 결정을 유도하거나 숨겨진 편견을 포함한 위험 회피를 방지하기 위해 행동 경향을 효과적으로 측정하고 감사하며 조정할 수 있는 시스템을 요구한다.

Method: 이 연구는 다양한 경제적 시나리오에서 성별 특유의 태도, 불확실성, 역할 기반 의사결정 및 위험 회피의 조작 가능성에 중점을 두고 LMs의 위험 회피 조작 가능성(MoRA)을 조사한다.

Result: DeepSeek Reasoner와 Gemini-2.0-flash-lite와 같은 LMs는 인간 행동과 일부 정렬을 보이지만, 주목할 만한 불일치가 있으므로 생물 중심의 조작 가능성 측정을 정제할 필요성이 드러난다.

Conclusion: AI 시스템이 인간의 위험 선호도를 보다 정확하게 복제하도록 모델 설계를 발전시켜야 하며, 이는 위험 관리 맥락에서 AI의 효과성을 향상시킬 수 있다.

Abstract: Responsible AI demands systems whose behavioral tendencies can be effectively
measured, audited, and adjusted to prevent inadvertently nudging users toward
risky decisions or embedding hidden biases in risk aversion. As language models
(LMs) are increasingly incorporated into AI-driven decision support systems,
understanding their risk behaviors is crucial for their responsible deployment.
This study investigates the manipulability of risk aversion (MoRA) in LMs,
examining their ability to replicate human risk preferences across diverse
economic scenarios, with a focus on gender-specific attitudes, uncertainty,
role-based decision-making, and the manipulability of risk aversion. The
results indicate that while LMs such as DeepSeek Reasoner and
Gemini-2.0-flash-lite exhibit some alignment with human behaviors, notable
discrepancies highlight the need to refine bio-centric measures of
manipulability. These findings suggest directions for refining AI design to
better align human and AI risk preferences and enhance ethical decision-making.
The study calls for further advancements in model design to ensure that AI
systems more accurately replicate human risk preferences, thereby improving
their effectiveness in risk management contexts. This approach could enhance
the applicability of AI assistants in managing risk.

</details>


### [30] [Prepared mind, fast response: A temporal decoupling framework for adaptive knowledge orchestration in open-domain dialogue](https://arxiv.org/abs/2510.08175)
*Jinling Gan,Churong Liang,Runnan Li*

Main category: cs.AI

TL;DR: 본 논문은 PMFR이라는 새로운 대화 AI 시스템을 제안하며, 비동기 지식 조정을 통해 지연-품질 간의 상충 문제를 해결하고, 효율적인 사용자 상호작용을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 대화형 AI 시스템에서 지연-품질 간의 교환은 필수적이며, 기존 방법들은 서로 다른 해결책을 제공하지만 모두 부족하다.

Method: PMFR은 비동기 지식 조정 프레임워크를 사용하여 지식 평가, 즉각적인 응답 생성, 그리고 백그라운드 지식 향상을 위한 세 가지 구성 요소를 포함한다.

Result: 평가 결과에 따르면 PMFR은 브루트 포스 확장보다 우수하며, 95.3%의 지연 감소를 달성하면서도 응답 품질을 유지한다.

Conclusion: PMFR은 지식 범위를 점진적으로 확장하고, 지속적인 대화 흐름을 유지하는 효과적인 대화 AI 시스템이다.

Abstract: The latency-quality tradeoff is a fundamental constraint in open-domain
dialogue AI systems, since comprehensive knowledge access necessitates
prohibitive response delays. Contemporary approaches offer two inadequate
solutions: lightweight instruct models achieve sub-second latency but lack
reasoning depth, while tool-augmented ReAct agents enhance factuality through
external knowledge at the cost of synchronous execution that blocks interaction
during retrieval processes. PMFR is thus proposed, with a temporal decoupling
framework that fundamentally resolves the contradiction through asynchronous
knowledge orchestration. PMFR employs three coordinated components: (1) a
Knowledge Adequacy Evaluator for real-time sufficiency assessment, (2) a
Lightweight Response Generator for immediate user interaction, and (3) an
Asynchronous Knowledge Refinement Agent for background knowledge enhancement.
This architecture maintains continuous conversational flow while progressively
enriching knowledge coverage through intelligent triggering mechanisms.
Evaluation results on TopiOCQA demonstrate PMFR outperforms brute-force
scaling: PMFR achieves 95.3% latency reduction (23.38s -> 1.09s) while
preserving response quality comparable to heavyweight synchronous baselines
(GEval-C: 0.613 vs. 0.620).

</details>


### [31] [DODO: Causal Structure Learning with Budgeted Interventions](https://arxiv.org/abs/2510.08207)
*Matteo Gregorini,Chiara Boldrini,Lorenzo Valerio*

Main category: cs.AI

TL;DR: 이 논문에서는 DODO라는 알고리즘을 소개하며, 자율적으로 환경의 인과 구조를 학습하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: AI의 발전을 위해 인과성을 인식할 수 있는 기능이 필요하다.

Method: DODO 알고리즘을 통해 에이전트가 반복적인 개입을 통해 인과 구조를 학습하도록 한다.

Result: DODO는 관찰적 접근법에 비해 모든 제한 자원 조건을 제외하고 더 나은 성능을 보인다.

Conclusion: DODO는 인과 그래프의 구조를 낮은 오류율로 재구성할 수 있으며, 가장 어려운 구성에서는 기존 최선의 기준을 +0.25 F1점 초과하여 뛰어넘는다.

Abstract: Artificial Intelligence has achieved remarkable advancements in recent years,
yet much of its progress relies on identifying increasingly complex
correlations. Enabling causality awareness in AI has the potential to enhance
its performance by enabling a deeper understanding of the underlying mechanisms
of the environment. In this paper, we introduce DODO, an algorithm defining how
an Agent can autonomously learn the causal structure of its environment through
repeated interventions. We assume a scenario where an Agent interacts with a
world governed by a causal Directed Acyclic Graph (DAG), which dictates the
system's dynamics but remains hidden from the Agent. The Agent's task is to
accurately infer the causal DAG, even in the presence of noise. To achieve
this, the Agent performs interventions, leveraging causal inference techniques
to analyze the statistical significance of observed changes. Results show
better performance for DODO, compared to observational approaches, in all but
the most limited resource conditions. DODO is often able to reconstruct with as
low as zero errors the structure of the causal graph. In the most challenging
configuration, DODO outperforms the best baseline by +0.25 F1 points.

</details>


### [32] [Chain-of-Trigger: An Agentic Backdoor that Paradoxically Enhances Agentic Robustness](https://arxiv.org/abs/2510.08238)
*Jiyang Qiu,Xinbei Ma,Yunqing Xu,Zhuosheng Zhang,Hai Zhao*

Main category: cs.AI

TL;DR: 대규모 언어 모델 기반 에이전트의 신뢰성 문제를 드러내고, 다단계 백도어 공격인 CoTri를 제안하여 보안 및 강건성 취약성을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 실제 애플리케이션에서의 LLM 기반 에이전트의 빠른 배치는 신뢰성에 대한 심각한 우려를 초래하고 있다.

Method: CoTri는 초기 트리거로 시작하여 환경에서 추출된 후속 트리거로 다단계 조작을 수행하는 다단계 백도어 공격이다.

Result: CoTri는 거의 완벽한 공격 성공률과 거의 0의 허위 트리거 비율을 달성한다.

Conclusion: CoTri는 에이전트의 안정적인 다단계 제어를 달성하고, 기본적인 강건성과 작업 능력을 개선하며, 공격의 은밀성을 증가시켜 잠재적인 안전 위험을 초래한다.

Abstract: The rapid deployment of large language model (LLM)-based agents in real-world
applications has raised serious concerns about their trustworthiness. In this
work, we reveal the security and robustness vulnerabilities of these agents
through backdoor attacks. Distinct from traditional backdoors limited to
single-step control, we propose the Chain-of-Trigger Backdoor (CoTri), a
multi-step backdoor attack designed for long-horizon agentic control. CoTri
relies on an ordered sequence. It starts with an initial trigger, and
subsequent ones are drawn from the environment, allowing multi-step
manipulation that diverts the agent from its intended task. Experimental
results show that CoTri achieves a near-perfect attack success rate (ASR) while
maintaining a near-zero false trigger rate (FTR). Due to training data modeling
the stochastic nature of the environment, the implantation of CoTri
paradoxically enhances the agent's performance on benign tasks and even
improves its robustness against environmental distractions. We further validate
CoTri on vision-language models (VLMs), confirming its scalability to
multimodal agents. Our work highlights that CoTri achieves stable, multi-step
control within agents, improving their inherent robustness and task
capabilities, which ultimately makes the attack more stealthy and raises
potential safty risks.

</details>


### [33] [Co-TAP: Three-Layer Agent Interaction Protocol Technical Report](https://arxiv.org/abs/2510.08263)
*Shunyu An,Miao Wang,Yongchao Li,Dong Wan,Lina Wang,Ling Qin,Liqin Gao,Congyao Fan,Zhiyong Mao,Jiange Pu,Wenji Xia,Dong Zhao,Rui Hu,Ji Lu,Guiyue Zhou,Baoyu Tang,Yanqin Gao,Yongsheng Du,Daigang Xu,Lingjun Huang,Baoli Wang,Xiwen Zhang,Luyao Wang,Shilong Liu*

Main category: cs.AI

TL;DR: 본 논문은 다중 에이전트 시스템의 상호운용성, 상호작용 및 협업, 지식 공유의 세 가지 핵심 차원의 문제를 해결하기 위해 설계된 Co-TAP(Triple, Agent, Protocol)이라는 삼층 에이전트 상호작용 프로토콜을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 발생하는 여러 도전 과제를 해결하기 위해 새로운 에이전트 상호작용 프로토콜이 필요하다.

Method: HAI, UAP 및 MEK라는 세 가지 핵심 프로토콜로 구성된 계층적 솔루션을 설계하고 제안하였다. HAI는 사용자, 인터페이스 및 에이전트 간 정보 흐름을 표준화하고, UAP는 이질적인 에이전트 간의 통신 장벽을 허물며, MEK는 에이전트가 개별 경험에서 학습하고 공유 가능한 지식을 형성할 수 있도록 합니다.

Result: 이 프로토콜 프레임워크는 다중 에이전트 애플리케이션의 차세대 구축을 위한 견고한 공학적 기초와 이론적 지침을 제공할 것으로 기대된다.

Conclusion: 우리는 Co-TAP이 효율적이고 확장 가능하며 지능적인 다중 에이전트 애플리케이션 개발에 기여할 것이라고 확신한다.

Abstract: This paper proposes Co-TAP (T: Triple, A: Agent, P: Protocol), a three-layer
agent interaction protocol designed to address the challenges faced by
multi-agent systems across the three core dimensions of Interoperability,
Interaction and Collaboration, and Knowledge Sharing. We have designed and
proposed a layered solution composed of three core protocols: the Human-Agent
Interaction Protocol (HAI), the Unified Agent Protocol (UAP), and the
Memory-Extraction-Knowledge Protocol (MEK). HAI focuses on the interaction
layer, standardizing the flow of information between users, interfaces, and
agents by defining a standardized, event-driven communication paradigm. This
ensures the real-time performance, reliability, and synergy of interactions. As
the core of the infrastructure layer, UAP is designed to break down
communication barriers among heterogeneous agents through unified service
discovery and protocol conversion mechanisms, thereby enabling seamless
interconnection and interoperability of the underlying network. MEK, in turn,
operates at the cognitive layer. By establishing a standardized ''Memory (M) -
Extraction (E) - Knowledge (K)'' cognitive chain, it empowers agents with the
ability to learn from individual experiences and form shareable knowledge,
thereby laying the foundation for the realization of true collective
intelligence. We believe this protocol framework will provide a solid
engineering foundation and theoretical guidance for building the next
generation of efficient, scalable, and intelligent multi-agent applications.

</details>


### [34] [QAgent: A modular Search Agent with Interactive Query Understanding](https://arxiv.org/abs/2510.08383)
*Yi Jiang,Lei Shen,Lujie Niu,Sendong Zhao,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: QAgent는 복잡한 쿼리 이해를 개선하기 위해 상호작용 추론과 검색을 통해 쿼리를 최적화하는 통합 에이전트형 RAG 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 RAG는 복잡한 쿼리 이해에 어려움을 겪고 있으며, RL로 훈련된 검색 에이전트조차 일반화 및 배포에 도전과제를 안고 있다.

Method: QAgent는 adaptive retrieval을 위한 검색 에이전트를 사용하며, RL로 훈련된 다단계 결정 프로세스를 따른다.

Result: QAgent는 QA에서 뛰어난 성능을 보이며, 실제 배포를 위한 plug-and-play 모듈로 작동한다.

Conclusion: QAgent는 효과적인 검색에 초점을 맞춤으로써 LLM 응용 프로그램에서의 일반화를 향상시킨다.

Abstract: Large language models (LLMs) excel at natural language tasks but are limited
by their static parametric knowledge, especially in knowledge-intensive task.
Retrieval-augmented generation (RAG) mitigates this by integrating external
information. However, (1) traditional RAG struggles with complex query
understanding, and (2) even search agents trained with reinforcement learning
(RL), despite their promise, still face generalization and deployment
challenges. To address these limitations, we propose QAgent, a unified agentic
RAG framework that employs a search agent for adaptive retrieval. This agent
optimizes its understanding of the query through interactive reasoning and
retrieval. To facilitate real-world application, we focus on modular search
agent for query understanding that are plug-and-play in complex systems.
Secifically, the agent follows a multi-step decision process trained with RL to
maximize retrieval quality and support accurate downstream answers. We further
analyze the strengths and weaknesses of end-to-end RL and propose a strategy
that focuses on effective retrieval, thereby enhancing generalization in LLM
applications. Experiments show QAgent excels at QA and serves as a
plug-and-play module for real-world deployment.

</details>


### [35] [AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents](https://arxiv.org/abs/2510.08511)
*Shangheng Du,Xiangchao Yan,Dengyang Jiang,Jiakang Yuan,Yusong Hu,Xin Li,Liang He,Bo Zhang,Lei Bai*

Main category: cs.AI

TL;DR: AutoMLGen은 LLM 기반의 코딩 에이전트로, 고품질의 도메인 지식 기반과 몬테 카를로 그래프 탐색을 통합하여 머신 러닝 엔지니어링 작업에서의 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 LLM은 머신 러닝 엔지니어링 시나리오에서 전문가의介入과 반복적인 조정 없이 높은 성과를 내기 어렵습니다.

Method: AutoMLGen은 도메인 지식 기반과 몬테 카를로 그래프 탐색(MCGS)을 통합하여 효율적인 탐색을 지원합니다.

Result: MLE-Bench 평가에서 AutoMLGen은 평균 메달 비율 및 유효 제출 비율을 포함한 다양한 측면에서 최첨단 성능을 달성했습니다.

Conclusion: AutoMLGen의 설계는 안정성을 개선하고 수렴 속도를 가속화합니다.

Abstract: Large language models (LLMs) have shown impressive performance in general
programming tasks. However, in Machine Learning Engineering (MLE) scenarios
such as AutoML and Kaggle competitions, achieving high performance depends
heavily on expert intervention and repeated adjustments rather than simply
generating correct code. When applied directly to these tasks, LLMs often lack
fine-grained domain priors, and existing MLE approaches that use linear or
tree-structured searches limit knowledge transfer to adjacent hierarchical
links. As a result, they cannot leverage past full trajectories or share
information across branches, limiting self-evolving ability and search space
diversity. To address these limitations, we introduce AutoMLGen, an LLM-based
coding agent that integrates a domain knowledge base for high-quality prior
guidance and Monte Carlo Graph Search (MCGS) for efficient exploration. MCGS
retains the tree-guided exploration of MCTS while embedding a graph structure
into the expansion stage to enable dynamic path reorganization, historical
trajectory reuse, and multi-solution fusion to support both self-evolution and
collaborative learning. Combined with fine-grained operator sets, this design
improves stability and accelerates convergence. Evaluation on the MLE-Bench
shows that AutoMLGen achieves state-of-the-art performance in numerous
dimensions, such as the average medal rate and the valid submission rate, under
a 12-hour budget (half the standard runtime). The code is available at
https://github.com/Alpha-Innovator/InternAgent.

</details>


### [36] [CaRT: Teaching LLM Agents to Know When They Know Enough](https://arxiv.org/abs/2510.08517)
*Grace Liu,Yuxiao Qu,Jeff Schneider,Aarti Singh,Aviral Kumar*

Main category: cs.AI

TL;DR: 이 논문은 LLM이 정보를 수집할 시점을 학습하는 방법인 CaRT를 소개하며, 이를 통해 정보 수집의 효율성과 성공률을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 작업 수행 전 여러 번의 상호작용을 통해 관련 정보를 전략적으로 수집해야 하는 과제가 많다.

Method: CaRT는 적절한 종료 시점을 학습하기 위해 LLM을 반사실적 경로 쌍을 사용하여 세부 조정한다.

Result: 두 개의 도메인에서 CaRT는 정보 수집의 효율성과 작업 성공률을 향상시켰다.

Conclusion: CaRT는 LLM이 정보를 수집할 시점을 판단하는 능력을 향상시켜 다양한 작업에 적용 가능성을 보여준다.

Abstract: Many tasks require learned models to strategically gather relevant
information over multiple rounds of interaction before actually acting on a
task. Strategic information gathering requires models to know not only how to
effectively acquire information, but also when to stop gathering information
and make a decision, in order to avoid overthinking or getting derailed when
acting. In this paper, we formalize this problem and introduce Counterfactuals
and Reasoning for Termination (CaRT), an approach for teaching LLMs when to
stop seeking information. To appropriately learn when to terminate, CaRT
fine-tunes LLMs using counterfactual pairs of trajectories, one where
termination is appropriate and a minimally modified version of the same
trajectory where it is not. It trains the LLM to explain the rationale for the
termination decision in either case via verbal reasoning, and imbues this
capability into the base LLM via fine-tuning. We instantiate CaRT in two
domains: interactive medical diagnosis and math problem solving. In both
domains, we find that CaRT improves the efficiency of information gathering and
task success rate compared to other fine-tuning methods.

</details>


### [37] [FlowSearch: Advancing deep research with dynamic structured knowledge flow](https://arxiv.org/abs/2510.08521)
*Yusong Hu,Runmin Ma,Yue Fan,Jinxin Shi,Zongsheng Cao,Yuhao Zhou,Jiakang Yuan,Xiangchao Yan,Wenlong Zhang,Lei Bai,Bo Zhang*

Main category: cs.AI

TL;DR: FlowSearch는 다단계 의존성을 해결하는 다중 에이전트 프레임워크로, 연구 전반에 걸쳐 효과적인 지식 흐름을 구축하고 진화시킨다.


<details>
  <summary>Details</summary>
Motivation: 딥 리서치는 폭넓은 사고와 깊이 있는 사고를 요구하는 도전적인 작업이다. 다양한 지식 공간을 탐색하고 복잡한 다단계 의존성에 대한 추론이 필요하다.

Method: FlowSearch는 하위 작업 실행과 추론을 촉진하기 위해 동적인 구조화된 지식 흐름을 능동적으로 구축하고 진화시키는 다중 에이전트 프레임워크이다.

Result: FlowSearch는 GAIA, HLE, GPQA, TRQA와 같은 일반 및 과학 기준에서 최첨단 성능을 달성하였다.

Conclusion: FlowSearch는 다학제 연구 시나리오에서의 효과를 입증하며 과학적 발견을 촉진할 잠재력을 가지고 있다.

Abstract: Deep research is an inherently challenging task that demands both breadth and
depth of thinking. It involves navigating diverse knowledge spaces and
reasoning over complex, multi-step dependencies, which presents substantial
challenges for agentic systems. To address this, we propose FlowSearch, a
multi-agent framework that actively constructs and evolves a dynamic structured
knowledge flow to drive subtask execution and reasoning. FlowSearch is capable
of strategically planning and expanding the knowledge flow to enable parallel
exploration and hierarchical task decomposition, while also adjusting the
knowledge flow in real time based on feedback from intermediate reasoning
outcomes and insights. FlowSearch achieves state-of-the-art performance on both
general and scientific benchmarks, including GAIA, HLE, GPQA and TRQA,
demonstrating its effectiveness in multi-disciplinary research scenarios and
its potential to advance scientific discovery. The code is available at
https://github.com/Alpha-Innovator/InternAgent.

</details>


### [38] [Agent Learning via Early Experience](https://arxiv.org/abs/2510.08558)
*Kai Zhang,Xiangchao Chen,Bo Liu,Tianci Xue,Zeyi Liao,Zhihan Liu,Xiyao Wang,Yuting Ning,Zhaorun Chen,Xiaohan Fu,Jian Xie,Yuxuan Sun,Boyu Gou,Qi Qi,Zihang Meng,Jianwei Yang,Ning Zhang,Xian Li,Ashish Shah,Dat Huynh,Hengduo Li,Zi Yang,Sara Cao,Lawrence Jang,Shuyan Zhou,Jiacheng Zhu,Huan Sun,Jason Weston,Yu Su,Yifan Wu*

Main category: cs.AI

TL;DR: 언어 에이전트의 목표는 복잡한 실제 작업에서 인간을 능가하는 학습 및 경험 개선이다. 하지만 많은 환경에서 경험 데이터로 훈련하는 것은 어려우며, 대부분의 에이전트는 전문가 데이터에 의한 감독적 미세 조정에 의존한다. 본 연구는 에이전트의 행동에서 생성된 상호작용 데이터를 활용하여 보상 신호 없이 미래 상태를 감독으로 사용하는 '조기 경험'이라는 중간 패러다임을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 언어 에이전트의 목표는 궁극적으로 복잡한 실제 작업에서 인간을 능가할 수 있도록 경험을 통해 학습하고 개선하는 것이다. 그러나 많은 환경에서는 검증 가능한 보상이 없거나 비효율적인 긴 시간의 롤아웃이 필요하여 경험 데이터로 에이전트를 훈련하는 것이 어렵다.

Method: 조기 경험이라는 패러다임 내에서, 에이전트의 행동에 의해 생성된 상호작용 데이터를 사용하여 두 가지 전략을 연구한다: (1) 수집된 상태를 사용하여 정책을 환경 역학에 기반하게 하는 암묵적 세계 모델링; (2) 에이전트가 비최적 행동에서 배우도록 하여 추론과 의사 결정을 개선하는 자기 반성이다.

Result: 여덟 개의 다양한 환경과 여러 모델 군을 통해 평가했으며, 우리의 접근 방식은 효과성과 도메인 외 일반화를 지속적으로 개선하였다.

Conclusion: 결과적으로 조기 경험은 강화 학습에 강력한 기초를 제공하며 모방 학습과 완전 경험 기반 에이전트 사이의 실질적인 다리 역할을 한다는 신호를 제공한다.

Abstract: A long-term goal of language agents is to learn and improve through their own
experience, ultimately outperforming humans in complex, real-world tasks.
However, training agents from experience data with reinforcement learning
remains difficult in many environments, which either lack verifiable rewards
(e.g., websites) or require inefficient long-horizon rollouts (e.g., multi-turn
tool use). As a result, most current agents rely on supervised fine-tuning on
expert data, which is challenging to scale and generalizes poorly. This
limitation stems from the nature of expert demonstrations: they capture only a
narrow range of scenarios and expose the agent to limited environment
diversity. We address this limitation with a middle-ground paradigm we call
early experience: interaction data generated by the agent's own actions, where
the resulting future states serve as supervision without reward signals. Within
this paradigm we study two strategies of using such data: (1) Implicit world
modeling, which uses collected states to ground the policy in environment
dynamics; and (2) Self-reflection, where the agent learns from its suboptimal
actions to improve reasoning and decision-making. We evaluate across eight
diverse environments and multiple model families. Our approaches consistently
improve effectiveness and out-of-domain generalization, highlighting the value
of early experience. Moreover, in environments with verifiable rewards, our
results provide promising signals that early experience offers a strong
foundation for subsequent reinforcement learning, positioning it as a practical
bridge between imitation learning and fully experience-driven agents.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [39] [Climate Surrogates for Scalable Multi-Agent Reinforcement Learning: A Case Study with CICERO-SCM](https://arxiv.org/abs/2510.07971)
*Oskar Bohn Lassen,Serio Angelo Maria Agriesti,Filipe Rodrigues,Francisco Camara Pereira*

Main category: cs.LG

TL;DR: 다양한 온실가스의 복합적인 영향을 모델링하기 위해, 효율적인 기후 대리 모델을 사용한 다중 에이전트 강화 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기후 정책 연구는 다수의 온실가스가 지구 온도에 미치는 영향을 포착하는 모델이 필요하지만, 이러한 모델은 계산 비용이 비쌀뿐 아니라 강화 학습에 통합하기 어렵다.

Method: 다중 에이전트 강화 학습(MARL) 프레임워크를 제안하고, 20,000개의 다중가스 배출 경로로 사전 훈련된 순환 신경망 아키텍처를 도입하여 CICERO-SCM 기후 모델을 대리할 수 있도록 하였다.

Result: 대리 모델은 전지구 평균 온도 RMSE 약 0.0004K로 시뮬레이터 정확성에 근접하며, 1000배 빠른 일단계 추론 속도를 달성했다. 원래 시뮬레이터 대신 사용하였을 때, 기후 정책 MARL 설정에서 훈련 속도를 100배 이상 가속화하였다.

Conclusion: 대리 모델과 시뮬레이터가 동일한 최적 정책으로 수렴함을 보여주고, 시뮬레이터 사용이 불가능한 경우 이 특성을 평가할 수 있는 방법론을 제안한다.

Abstract: Climate policy studies require models that capture the combined effects of
multiple greenhouse gases on global temperature, but these models are
computationally expensive and difficult to embed in reinforcement learning. We
present a multi-agent reinforcement learning (MARL) framework that integrates a
high-fidelity, highly efficient climate surrogate directly in the environment
loop, enabling regional agents to learn climate policies under multi-gas
dynamics. As a proof of concept, we introduce a recurrent neural network
architecture pretrained on ($20{,}000$) multi-gas emission pathways to
surrogate the climate model CICERO-SCM. The surrogate model attains
near-simulator accuracy with global-mean temperature RMSE $\approx 0.0004
\mathrm{K}$ and approximately $1000\times$ faster one-step inference. When
substituted for the original simulator in a climate-policy MARL setting, it
accelerates end-to-end training by $>\!100\times$. We show that the surrogate
and simulator converge to the same optimal policies and propose a methodology
to assess this property in cases where using the simulator is intractable. Our
work allows to bypass the core computational bottleneck without sacrificing
policy fidelity, enabling large-scale multi-agent experiments across
alternative climate-policy regimes with multi-gas dynamics and high-fidelity
climate response.

</details>


### [40] [Bayesian Decision Making around Experts](https://arxiv.org/abs/2510.08113)
*Daniel Jarne Ornia,Joel Dyer,Nicholas Bishop,Anisoara Calinescu,Michael Wooldridge*

Main category: cs.LG

TL;DR: 이 논문은 복잡한 학습 에이전트가 전문가의 데이터(인간 운영자 또는 이전에 훈련된 에이전트와 같은)를 어떻게 최적적으로 통합할 수 있는지를 연구합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 학습 에이전트들이 기존 전문가와 함께 배치되고 있지만, 학습자가 전문가 데이터를 어떻게 통합해야 하는지 불확실합니다.

Method: 베이esian 다중 무장 강도 맥락에서 전문가 데이터가 학습자의 후행에 어떤 영향을 미치는지 형식화하고, 학습자가 자신의 경험이나 전문가의 결과를 기반으로 신념을 업데이트할지를 선택해야 하는 두 가지 설정을 고려합니다.

Result: 전문가 결과에 대한 사전 훈련이 전문가 데이터와 최적 행동之间의 상호 정보로 정보 이론적 후회 경계를 조여준다는 것을 증명합니다.

Conclusion: 학습자는 전문가를 신뢰해야 할 때와 그렇지 않을 때를 추론할 수 있는 전략을 제안하며, 전문가가 비효율적이거나 손상된 경우로부터 학습자를 보호합니다.

Abstract: Complex learning agents are increasingly deployed alongside existing experts,
such as human operators or previously trained agents. However, it remains
unclear how should learners optimally incorporate certain forms of expert data,
which may differ in structure from the learner's own action-outcome
experiences. We study this problem in the context of Bayesian multi-armed
bandits, considering: (i) offline settings, where the learner receives a
dataset of outcomes from the expert's optimal policy before interaction, and
(ii) simultaneous settings, where the learner must choose at each step whether
to update its beliefs based on its own experience, or based on the outcome
simultaneously achieved by an expert. We formalize how expert data influences
the learner's posterior, and prove that pretraining on expert outcomes tightens
information-theoretic regret bounds by the mutual information between the
expert data and the optimal action. For the simultaneous setting, we propose an
information-directed rule where the learner processes the data source that
maximizes their one-step information gain about the optimal action. Finally, we
propose strategies for how the learner can infer when to trust the expert and
when not to, safeguarding the learner for the cases where the expert is
ineffective or compromised. By quantifying the value of expert data, our
framework provides practical, information-theoretic algorithms for agents to
intelligently decide when to learn from others.

</details>


### [41] [Opponent Shaping in LLM Agents](https://arxiv.org/abs/2510.08255)
*Marta Emili Garcia Segura,Stephen Hailes,Mirco Musolesi*

Main category: cs.LG

TL;DR: 대형 언어 모델(LLM)들이 자율 에이전트로 실세계에 배포됨에 따라, 멀티 에이전트 상호작용의 중요성이 증가하고 있다. 본 논문에서는 LLM 기반 에이전트의 상대방 형성(opponent shaping, OS)을 처음으로 조사하였다. 이를 위해 ShapeLLM이라는 변형 모델 자유 OS 방법을 소개하고, LLM 에이전트가 다양한 게임 이론 환경에서 동료 플레이어의 학습 동역학에 영향을 미칠 수 있는지를 연구하였다. 우리의 결과는 LLM 에이전트가 경쟁 게임에서 상대방을 착취 가능한 균형으로 유도하고, 협력 게임에서 조정 및 집단 복지를 향상시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: LLM이 자율 에이전트로 실세계 환경에 배포됨에 따라, 멀티 에이전트 상호작용의 중요성이 증가하고 있다. 이러한 시스템에서의 전략적 행동을 이해하는 것이 필수적이다.

Method: ShapeLLM이라는 변형 모델 자유 상대방 형성 방법을 도입하여 LLM 기반 에이전트를 조사하였다. 다양한 게임 이론 환경에서 LLM 에이전트의 영향을 시험하였다.

Result: LLM 에이전트가 경쟁 게임에서 상대방을 착취 가능한 균형으로 유도하고, 협력 게임에서는 조정 및 집단 복지를 향상시키는 것을 성공적으로 입증하였다.

Conclusion: 상대방 형성은 멀티 에이전트 LLM 연구의 중요한 차원으로 자리잡았다.

Abstract: Large Language Models (LLMs) are increasingly being deployed as autonomous
agents in real-world environments. As these deployments scale, multi-agent
interactions become inevitable, making it essential to understand strategic
behavior in such systems. A central open question is whether LLM agents, like
reinforcement learning agents, can shape the learning dynamics and influence
the behavior of others through interaction alone. In this paper, we present the
first investigation of opponent shaping (OS) with LLM-based agents. Existing OS
algorithms cannot be directly applied to LLMs, as they require higher-order
derivatives, face scalability constraints, or depend on architectural
components that are absent in transformers. To address this gap, we introduce
ShapeLLM, an adaptation of model-free OS methods tailored for transformer-based
agents. Using ShapeLLM, we examine whether LLM agents can influence co-players'
learning dynamics across diverse game-theoretic environments. We demonstrate
that LLM agents can successfully guide opponents toward exploitable equilibria
in competitive games (Iterated Prisoner's Dilemma, Matching Pennies, and
Chicken) and promote coordination and improve collective welfare in cooperative
games (Iterated Stag Hunt and a cooperative version of the Prisoner's Dilemma).
Our findings show that LLM agents can both shape and be shaped through
interaction, establishing opponent shaping as a key dimension of multi-agent
LLM research.

</details>


### [42] [ConCuR: Conciseness Makes State-of-the-Art Kernel Generation](https://arxiv.org/abs/2510.07356)
*Lingcheng Kong,Jiateng Wei,Hanzhang Shen,Huan Wang*

Main category: cs.LG

TL;DR: LLM을 활용한 GPU 커널 생성이 발전하고 있지만, 고품질 데이터 부족이 주요 도전 과제다. 이를 해결하기 위해 고품질 CUDA 커널을 생성하고 정제하는 파이프라인을 개발했다. 이 파이프라인을 통해 새로운 데이터셋과 모델을 구축하고 성과를 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 고품질 커널 부족으로 인해 LLM을 커널 생성 작업에 맞게 조정하는 데 어려움이 있다.

Method: 간결하면서도 유익한 추론 추적을 이용해 고품질 CUDA 커널을 생성하고 정제하는 파이프라인을 개발하였다. 이 파이프라인을 통해 ConCuR 데이터셋을 구축하고 KernelCoder 모델을 소개하였다.

Result: KernelBench 설정에서 우리의 모델은 기존의 최고 성능 모델인 QwQ-32B보다 상당한 개선을 보였으며, 모든 공개 소스 모델을 초월하였다.

Conclusion: 평균 추론 길이는 커널 생성 작업의 난이도를 평가하는 지표로 사용할 수 있다. 이러한 관찰과 메트릭, 데이터 수집 및 정제 파이프라인은 향후 커널 생성 작업에서 더 나은 데이터를 얻는 데 기여할 수 있다.

Abstract: GPU kernel generation by LLMs has recently experienced rapid development,
leveraging test-time scaling and reinforcement learning techniques. However, a
key challenge for kernel generation is the scarcity of high-quality data, as
most high-quality kernels are proprietary and not open-source. This challenge
prevents us from leveraging supervised fine-tuning to align LLMs to the kernel
generation task. To address this challenge, we develop a pipeline that
generates and curates high-quality CUDA kernels with reasoning traces,
motivated by a critical observation that concise yet informative reasoning
traces result in robust generation of high-performance kernels. Using this
pipeline, we construct our dataset ConCuR and introduce our model KernelCoder,
which is the first model trained on a curated dataset consisting of PyTorch,
reasoning, and CUDA kernel pairs, to our knowledge. In the KernelBench setup,
our model achieves significant improvements over the existing top-performing
model, QwQ-32B, and outperforms all open-source models fine-tuned for kernel
generation, as well as frontier models such as DeepSeek-V3.1-Think and
Claude-4-sonnet. Finally, we show that the average reasoning length can serve
as a metric to assess the difficulty of kernel generation tasks. The
observations, metrics, and our data collection and curation pipeline can help
obtain better data in the kernel generation task in the future.

</details>


### [43] [Parameter-Free Federated TD Learning with Markov Noise in Heterogeneous Environments](https://arxiv.org/abs/2510.07436)
*Ankur Naskar,Gugan Thoppe,Utsav Negi,Vijay Gupta*

Main category: cs.LG

TL;DR: 이 논문은 다수의 에이전트를 통한 탐색과 학습 분산을 통해 강화 학습의 속도를 크게 향상할 수 있는 연합 학습(FL)의 이점을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습의 이점을 활용하여 동적 문제를 해결하고 TD 학습의 경과를 최적화하고자 한다.

Method: Polyak-Ruppert 평균화를 이용한 두 단계 시간의 연합 시차 학습 방법을 제안한다.

Result: 제안된 방법은 평균 보상 및 할인 설정 모두에서 최적의 $	ilde{O}(1/NT)$ 속도를 달성한다.

Conclusion: 이 연구는 이기종 환경에서의 FL 시나리오에 적용될 수 있는 새로운 결과를 제공한다.

Abstract: Federated learning (FL) can dramatically speed up reinforcement learning by
distributing exploration and training across multiple agents. It can guarantee
an optimal convergence rate that scales linearly in the number of agents, i.e.,
a rate of $\tilde{O}(1/(NT)),$ where $T$ is the iteration index and $N$ is the
number of agents. However, when the training samples arise from a Markov chain,
existing results on TD learning achieving this rate require the algorithm to
depend on unknown problem parameters. We close this gap by proposing a
two-timescale Federated Temporal Difference (FTD) learning with Polyak-Ruppert
averaging. Our method provably attains the optimal $\tilde{O}(1/NT)$ rate in
both average-reward and discounted settings--offering a parameter-free FTD
approach for Markovian data. Although our results are novel even in the
single-agent setting, they apply to the more realistic and challenging scenario
of FL with heterogeneous environments.

</details>


### [44] [PEAR: Planner-Executor Agent Robustness Benchmark](https://arxiv.org/abs/2510.07505)
*Shen Dong,Mingxuan Zhang,Pengfei He,Li Ma,Bhavani Thuraisingham,Hui Liu,Yue Xing*

Main category: cs.LG

TL;DR: LLM 기반 다중 에이전트 시스템의 취약성을 평가하기 위한 PEAR 벤치마크를 소개하며, 플래너와 실행자의 구조가 시스템 성능에 미치는 영향을 분석한다.


<details>
  <summary>Details</summary>
Motivation: MAS의 강력한 기능에도 불구하고, 기존 연구에서는 공격 표면 및 특정 시나리오에 국한되어 전체적인 취약성을 이해하는 데 한계가 있다.

Method: PEAR라는 벤치마크를 도입하여 플래너-실행자 MAS의 유용성과 취약성을 체계적으로 평가한다.

Result: 약한 플래너는 전체적인 클린 작업 성능을 약한 실행자보다 더 심각하게 저하시킨다. 플래너에게 메모리 모듈이 필수적이나, 실행자에게는 클린 작업 성능에 영향을 미치지 않는다. 작업 성능과 강인성 간의 트레이드오프가 존재하며, 플래너를 타겟으로 하는 공격이 시스템을 오도하는 데 특히 효과적이다.

Conclusion: MAS의 강인성을 향상시키기 위한 실질적인 통찰을 제공하고, 다중 에이전트 설정에서 원칙적인 방어 기초를 마련한다.

Abstract: Large Language Model (LLM)-based Multi-Agent Systems (MAS) have emerged as a
powerful paradigm for tackling complex, multi-step tasks across diverse
domains. However, despite their impressive capabilities, MAS remain susceptible
to adversarial manipulation. Existing studies typically examine isolated attack
surfaces or specific scenarios, leaving a lack of holistic understanding of MAS
vulnerabilities. To bridge this gap, we introduce PEAR, a benchmark for
systematically evaluating both the utility and vulnerability of
planner-executor MAS. While compatible with various MAS architectures, our
benchmark focuses on the planner-executor structure, which is a practical and
widely adopted design. Through extensive experiments, we find that (1) a weak
planner degrades overall clean task performance more severely than a weak
executor; (2) while a memory module is essential for the planner, having a
memory module for the executor does not impact the clean task performance; (3)
there exists a trade-off between task performance and robustness; and (4)
attacks targeting the planner are particularly effective at misleading the
system. These findings offer actionable insights for enhancing the robustness
of MAS and lay the groundwork for principled defenses in multi-agent settings.

</details>


### [45] [Efficient Generalization via Multimodal Co-Training under Data Scarcity and Distribution Shift](https://arxiv.org/abs/2510.07509)
*Tianyu Bell Pan,Damon L. Woodard*

Main category: cs.LG

TL;DR: 이 논문은 라벨이 제한된 데이터 환경에서 모델의 일반화를 향상시키기 위한 다중 모드 공동 훈련 프레임워크를 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 라벨이 제한된 데이터 상황과 분포 변화가 발생하는 상황에서 모델의 일반화를 향상시키기 위해 필요한 연구.

Method: 이 프레임워크의 이론적 기초를 철저히 검토하고, 라벨이 없는 데이터의 사용과 다양한 모드 간의 분류기 간 합의 촉진이 일반화에 중요한 개선을 이끌어내는 조건을 도출한다.

Result: 반복적인 공동 훈련이 분류 오류를 줄이는 데 효과적임을 확인하는 수렴 분석을 제시하고, 라벨이 없는 다중 모드 데이터를 활용하고, 뷰 간 합의를 촉진하며, 조건부 뷰 독립성을 유지함으로써 얻어지는 이점을 최초로 분해하고 정량화한 새로운 일반화 경계를 수립한다.

Conclusion: 다양한 실제 환경에서 효과적으로 일반화할 수 있는 데이터 효율적이고 강력한 AI 시스템 개발을 위한 구조화된 접근법으로서 다중 모드 공동 훈련의 실용적인 이점을 강조한다.

Abstract: This paper explores a multimodal co-training framework designed to enhance
model generalization in situations where labeled data is limited and
distribution shifts occur. We thoroughly examine the theoretical foundations of
this framework, deriving conditions under which the use of unlabeled data and
the promotion of agreement between classifiers for different modalities lead to
significant improvements in generalization. We also present a convergence
analysis that confirms the effectiveness of iterative co-training in reducing
classification errors. In addition, we establish a novel generalization bound
that, for the first time in a multimodal co-training context, decomposes and
quantifies the distinct advantages gained from leveraging unlabeled multimodal
data, promoting inter-view agreement, and maintaining conditional view
independence. Our findings highlight the practical benefits of multimodal
co-training as a structured approach to developing data-efficient and robust AI
systems that can effectively generalize in dynamic, real-world environments.
The theoretical foundations are examined in dialogue with, and in advance of,
established co-training principles.

</details>


### [46] [MLLM4TS: Leveraging Vision and Multimodal Language Models for General Time-Series Analysis](https://arxiv.org/abs/2510.07513)
*Qinghua Liu,Sam Heshmati,Zheda Mai,Zubin Abraham,John Paparrizos,Liu Ren*

Main category: cs.LG

TL;DR: MLLM4TS는 멀티모달 대형 언어 모델을 활용하여 시간 시계열 데이터를 더 효과적으로 분석하기 위한 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 인간 분석가들이 시간 시계열을 시각적으로 검사하여 숨겨진 패턴을 발견하는 방식을 바탕으로, 시각적 표현을 포함하면 자동화된 시간 시계열 분석을 향상시킬 수 있는지에 대한 질문을 제기한다.

Method: MLLM4TS는 각 시간 시계열 채널을 수평으로 쌓인 색상 코딩된 선 그래프로 표현하고, 시간 인식 시각 패치 정렬 전략을 통해 시각 패치를 해당 시간 세그먼트와 정렬한다.

Result: MLLM4TS는 예측 작업(예: 분류) 및 생성 작업(예: 이상 탐지 및 예측)에서 표준 벤치마크에서의 실험을 통해 효과성을 입증했다.

Conclusion: 시각적 모달리티와 사전 학습된 언어 모델을 통합하여 강력하고 일반화 가능한 시간 시계열 분석을 달성할 수 있는 가능성을 강조한다.

Abstract: Effective analysis of time series data presents significant challenges due to
the complex temporal dependencies and cross-channel interactions in
multivariate data. Inspired by the way human analysts visually inspect time
series to uncover hidden patterns, we ask: can incorporating visual
representations enhance automated time-series analysis? Recent advances in
multimodal large language models have demonstrated impressive generalization
and visual understanding capability, yet their application to time series
remains constrained by the modality gap between continuous numerical data and
discrete natural language. To bridge this gap, we introduce MLLM4TS, a novel
framework that leverages multimodal large language models for general
time-series analysis by integrating a dedicated vision branch. Each time-series
channel is rendered as a horizontally stacked color-coded line plot in one
composite image to capture spatial dependencies across channels, and a
temporal-aware visual patch alignment strategy then aligns visual patches with
their corresponding time segments. MLLM4TS fuses fine-grained temporal details
from the numerical data with global contextual information derived from the
visual representation, providing a unified foundation for multimodal
time-series analysis. Extensive experiments on standard benchmarks demonstrate
the effectiveness of MLLM4TS across both predictive tasks (e.g.,
classification) and generative tasks (e.g., anomaly detection and forecasting).
These results underscore the potential of integrating visual modalities with
pretrained language models to achieve robust and generalizable time-series
analysis.

</details>


### [47] [EEG Sleep Stage Classification with Continuous Wavelet Transform and Deep Learning](https://arxiv.org/abs/2510.07524)
*Mehdi Zekriyapanah Gashti,Ghasem Farjamnia*

Main category: cs.LG

TL;DR: 수면 단계의 정확한 분류는 수면 장애의 진단과 관리에 중요하다. 본 연구는 웨이블릿 변환 기반의 시계열-주파수 분석을 이용한 자동 수면 단계 점수 부여를 위한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 수면 장애의 진단 및 관리를 위해 정확한 수면 단계 분류가 필수적이다.

Method: 웨이블릿 변환에 기초한 시계열-주파수 분석을 이용한 자동 수면 단계 점수 부여 프레임워크를 제안한다.

Result: 제안된 웨이블릿 기반 표현과 앙상블 학습을 결합하여 88.37%의 전체 정확도와 73.15의 매크로 평균 F1 점수를 달성하였다.

Conclusion: 웨이블릿 분석이 견고하고 해석 가능하며 임상적으로 적용 가능한 수면 단계 분류의 가능성을 강조한다.

Abstract: Accurate classification of sleep stages is crucial for the diagnosis and
management of sleep disorders. Conventional approaches for sleep scoring rely
on manual annotation or features extracted from EEG signals in the time or
frequency domain. This study proposes a novel framework for automated sleep
stage scoring using time-frequency analysis based on the wavelet transform. The
Sleep-EDF Expanded Database (sleep-cassette recordings) was used for
evaluation. The continuous wavelet transform (CWT) generated time-frequency
maps that capture both transient and oscillatory patterns across frequency
bands relevant to sleep staging. Experimental results demonstrate that the
proposed wavelet-based representation, combined with ensemble learning,
achieves an overall accuracy of 88.37 percent and a macro-averaged F1 score of
73.15, outperforming conventional machine learning methods and exhibiting
comparable or superior performance to recent deep learning approaches. These
findings highlight the potential of wavelet analysis for robust, interpretable,
and clinically applicable sleep stage classification.

</details>


### [48] [EBGAN-MDN: An Energy-Based Adversarial Framework for Multi-Modal Behavior Cloning](https://arxiv.org/abs/2510.07562)
*Yixiao Li,Julia Barth,Thomas Kiefer,Ahmad Fraij*

Main category: cs.LG

TL;DR: EBGAN-MDN은 다중 모드 행동 클로닝 문제를 해결하기 위한 효율적인 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 다중 모드 행동 클로닝에서 모드 평균화와 모드 붕괴를 해결하기 위해 필요하다.

Method: 에너지 기반 모델, 혼합 밀도 네트워크(MDN), 적대적 훈련을 통합한 EBGAN-MDN 프레임워크를 제안한다.

Result: 합성 및 로봇 벤치마크에서 우수한 성능을 입증했다.

Conclusion: EBGAN-MDN은 다중 모드 학습 작업을 위한 효과적이고 효율적인 솔루션으로 자리잡았다.

Abstract: Multi-modal behavior cloning faces significant challenges due to mode
averaging and mode collapse, where traditional models fail to capture diverse
input-output mappings. This problem is critical in applications like robotics,
where modeling multiple valid actions ensures both performance and safety. We
propose EBGAN-MDN, a framework that integrates energy-based models, Mixture
Density Networks (MDNs), and adversarial training. By leveraging a modified
InfoNCE loss and an energy-enforced MDN loss, EBGAN-MDN effectively addresses
these challenges. Experiments on synthetic and robotic benchmarks demonstrate
superior performance, establishing EBGAN-MDN as a effective and efficient
solution for multi-modal learning tasks.

</details>


### [49] [DEAS: DEtached value learning with Action Sequence for Scalable Offline RL](https://arxiv.org/abs/2510.07730)
*Changyeon Kim,Haeone Lee,Younggyo Seo,Kimin Lee,Yuke Zhu*

Main category: cs.LG

TL;DR: DEAS는 오프라인 강화학습을 위한 효과적인 프레임워크로, 행동 시퀀스를 활용하여 가치 학습을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 강화학습은 비싼 온라인 상호작용 없이 지능형 에이전트를 훈련할 수 있는 매력적인 패러다임을 제공합니다.

Method: DEAS는 행동 시퀀스를 활용한 분리된 가치 학습 프레임워크로, 장기간 계획을 단순화하여 수행합니다.

Result: DEAS는 OGBench의 복잡한 장기 작업에서 일관되게 성능 기준을 초과하며 대규모 비전-언어-행동 모델의 성능을 개선하는 데 적용될 수 있습니다.

Conclusion: DEAS는 RoboCasa Kitchen 시뮬레이션 작업과 실제 조작 작업에서 성능을 크게 향상시킵니다.

Abstract: Offline reinforcement learning (RL) presents an attractive paradigm for
training intelligent agents without expensive online interactions. However,
current approaches still struggle with complex, long-horizon sequential
decision making. In this work, we introduce DEtached value learning with Action
Sequence (DEAS), a simple yet effective offline RL framework that leverages
action sequences for value learning. These temporally extended actions provide
richer information than single-step actions and can be interpreted through the
options framework via semi-Markov decision process Q-learning, enabling
reduction of the effective planning horizon by considering longer sequences at
once. However, directly adopting such sequences in actor-critic algorithms
introduces excessive value overestimation, which we address through detached
value learning that steers value estimates toward in-distribution actions that
achieve high return in the offline dataset. We demonstrate that DEAS
consistently outperforms baselines on complex, long-horizon tasks from OGBench
and can be applied to enhance the performance of large-scale
Vision-Language-Action models that predict action sequences, significantly
boosting performance in both RoboCasa Kitchen simulation tasks and real-world
manipulation tasks.

</details>


### [50] [Self-Improving LLM Agents at Test-Time](https://arxiv.org/abs/2510.07841)
*Emre Can Acikgoz,Cheng Qian,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.LG

TL;DR: 이 논문은 테스트 시간 자가 개선(TT-SI) 방법을 통해 효율적이고 일반화 가능한 언어 모델을 개발하는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 언어 모델 미세 조정 방식의 비효율성과 높은 비용 문제를 해결하고자 한다.

Method: 모델이 어려워하는 샘플을 식별하고 이들로부터 유사한 예제를 생성하여 테스트 시간에 해당 샘플을 사용해 미세 조정하는 방법을 제안한다.

Result: TT-SI가 모든 벤치마크에서 평균적으로 +5.48%의 절대 정확도 향상을 가져오며, 다른 표준 학습 방법을 초월하면서도 68배 적은 학습 샘플을 사용한다.

Conclusion: TT-SI는 테스트 시간 자가 개선 알고리즘의 유망성을 강조하며, 자가 진화 가능한 에이전트를 구축하기 위한 새로운 패러다임을 제시한다.

Abstract: One paradigm of language model (LM) fine-tuning relies on creating large
training datasets, under the assumption that high quantity and diversity will
enable models to generalize to novel tasks after post-training. In practice,
gathering large sets of data is inefficient, and training on them is
prohibitively expensive; worse, there is no guarantee that the resulting model
will handle complex scenarios or generalize better. Moreover, existing
techniques rarely assess whether a training sample provides novel information
or is redundant with the knowledge already acquired by the model, resulting in
unnecessary costs. In this work, we explore a new test-time self-improvement
method to create more effective and generalizable agentic LMs on-the-fly. The
proposed algorithm can be summarized in three steps: (i) first it identifies
the samples that model struggles with (self-awareness), (ii) then generates
similar examples from detected uncertain samples (self-data augmentation), and
(iii) uses these newly generated samples at test-time fine-tuning
(self-improvement). We study two variants of this approach: Test-Time
Self-Improvement (TT-SI), where the same model generates additional training
examples from its own uncertain cases and then learns from them, and contrast
this approach with Test-Time Distillation (TT-D), where a stronger model
generates similar examples for uncertain cases, enabling student to adapt using
distilled supervision. Empirical evaluations across different agent benchmarks
demonstrate that TT-SI improves the performance with +5.48% absolute accuracy
gain on average across all benchmarks and surpasses other standard learning
methods, yet using 68x less training samples. Our findings highlight the
promise of TT-SI, demonstrating the potential of self-improvement algorithms at
test-time as a new paradigm for building more capable agents toward
self-evolution.

</details>


### [51] [Signal-to-Noise Ratio in Scanning Electron Microscopy: A Comprehensive Review](https://arxiv.org/abs/2510.07886)
*K. S. Sim,I. Bukhori,D. C. Y. Ong,K. B. Gan*

Main category: cs.LG

TL;DR: 본 논문은 주사 전자 현미경(SEM)의 신호 대 잡음비(SNR) 최적화에 관한 포괄적인 이해를 제공하고, 하드웨어 및 소프트웨어 관점에서 SNR 측정과 향상을 다룬다.


<details>
  <summary>Details</summary>
Motivation: SEM의 고해상도 이미지 품질을 보장하기 위해서는 SNR 최적화가 중요하다.

Method: SEM의 주요 작동 원리, 잡음 원인, SNR 측정 방법 및 추정, SNR 측정에 영향을 미치는 다양한 측면 및 SNR 향상 접근 방식을 하드웨어와 소프트웨어 관점에서 검토했다.

Result: 전통적인 기법과 새로운 기법을 검토하고 각각의 응용, 장점 및 한계를 분석했다.

Conclusion: 이 논문은 연구자와 실무자에게 SEM에서의 SNR 최적화에 대한 포괄적인 이해를 제공하고, 이 분야의 추가 연구를 장려하는 것을 목표로 한다.

Abstract: Scanning Electron Microscopy (SEM) is critical in nanotechnology, materials
science, and biological imaging due to its high spatial resolution and depth of
focus. Signal-to-noise ratio (SNR) is an essential parameter in SEM because it
directly impacts the quality and interpretability of the images. SEM is widely
used in various scientific disciplines, but its utility can be compromised by
noise, which degrades image clarity. This review explores multiple aspects of
the SEM imaging process, from the principal operation of SEM, sources of noise
in SEM, methods for SNR measurement and estimations, to various aspects that
affect the SNR measurement and approaches to enhance SNR, both from a hardware
and software standpoint. We review traditional and emerging techniques,
focusing on their applications, advantages, and limitations. The paper aims to
provide a comprehensive understanding of SNR optimization in SEM for
researchers and practitioners and to encourage further research in the field.

</details>


### [52] [Unsupervised Multi-Source Federated Domain Adaptation under Domain Diversity through Group-Wise Discrepancy Minimization](https://arxiv.org/abs/2510.08150)
*Larissa Reichart,Cem Ata Baykara,Ali Burak Ünal,Mete Akgün,Harlin Lee*

Main category: cs.LG

TL;DR: GALA는 고유한 목표와 가중치 전략을 통해 분산 비지도 다중 출처 도메인 적응을 위한 확장 가능하고 강력한 프레임워크를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 분산 비지도 다중 출처 도메인 적응 방법은 소스 도메인의 수가 적어야 효과적이며, 동시적으로 많은 도메인을 다루는 데에는 비효율성이 있다.

Method: GALA는 (1) 쌍별 도메인 정렬을 효율적으로 근사하는 새로운 그룹 간 불일치 최소화 목표와 (2) 타겟과의 정렬에 따라 소스 도메인을 동적으로 우선시하는 온도 조절된 중심 기반 가중치 전략을 포함한다.

Result: GALA는 높은 차이를 가진 시나리오에서 성능을 평가하기 위해 새로운 기준인 Digit-18을 도입하며, 광범위한 실험을 통해 표준 벤치마크에서 경쟁력 있는 결과를 지속적으로 달성한다.

Conclusion: GALA는 다른 방법들이 수렴하지 못하는 다양한 다중 소스 환경에서 우수한 성능을 발휘한다.

Abstract: Unsupervised multi-source domain adaptation (UMDA) aims to learn models that
generalize to an unlabeled target domain by leveraging labeled data from
multiple, diverse source domains. While distributed UMDA methods address
privacy constraints by avoiding raw data sharing, existing approaches typically
assume a small number of sources and fail to scale effectively. Increasing the
number of heterogeneous domains often makes existing methods impractical,
leading to high computational overhead or unstable performance. We propose
GALA, a scalable and robust federated UMDA framework that introduces two key
components: (1) a novel inter-group discrepancy minimization objective that
efficiently approximates full pairwise domain alignment without quadratic
computation; and (2) a temperature-controlled, centroid-based weighting
strategy that dynamically prioritizes source domains based on alignment with
the target. Together, these components enable stable and parallelizable
training across large numbers of heterogeneous sources. To evaluate performance
in high-diversity scenarios, we introduce Digit-18, a new benchmark comprising
18 digit datasets with varied synthetic and real-world domain shifts. Extensive
experiments show that GALA consistently achieves competitive or
state-of-the-art results on standard benchmarks and significantly outperforms
prior methods in diverse multi-source settings where others fail to converge.

</details>


### [53] [Beyond Sub-6 GHz: Leveraging mmWave Wi-Fi for Gait-Based Person Identification](https://arxiv.org/abs/2510.08160)
*Nabeel Nisar Bhat,Maksim Karnaukh,Jakob Struye,Rafael Berkvens,Jeroen Famaey*

Main category: cs.LG

TL;DR: Wi-Fi 신호를 이용한 개인 식별에 대한 비교 연구, mmWave와 sub-6 GHz 신호의 효용성을 탐구.


<details>
  <summary>Details</summary>
Motivation: 본 연구는 Wi-Fi 신호를 활용한 비접촉식 개인 식별의 가능성을 탐색하고자 한다.

Method: COTS Wi-Fi를 사용하여 실내 환경에서 두 주파수 범위(6 GHz 및 mmWave)의 동기화 측정 데이터를 활용한 비교 연구를 수행하였다.

Result: 고유한 배경 차감 기술을 결합할 경우, mmWave Wi-Fi 신호는 낮은 샘플링 속도(10 Hz)에서도 높은 식별 정확도(20명 중 91.2%)를 달성할 수 있다.

Conclusion: mmWave 신호가 개인 식별에 유리하다는 점을 최초로 입증하였다.

Abstract: Person identification plays a vital role in enabling intelligent,
personalized, and secure human-computer interaction. Recent research has
demonstrated the feasibility of leveraging Wi-Fi signals for passive person
identification using a person's unique gait pattern. Although most existing
work focuses on sub-6 GHz frequencies, the emergence of mmWave offers new
opportunities through its finer spatial resolution, though its comparative
advantages for person identification remain unexplored. This work presents the
first comparative study between sub-6 GHz and mmWave Wi-Fi signals for person
identification with commercial off-the-shelf (COTS) Wi-Fi, using a novel
dataset of synchronized measurements from the two frequency bands in an indoor
environment. To ensure a fair comparison, we apply identical training pipelines
and model configurations across both frequency bands. Leveraging end-to-end
deep learning, we show that even at low sampling rates (10 Hz), mmWave Wi-Fi
signals can achieve high identification accuracy (91.2% on 20 individuals) when
combined with effective background subtraction.

</details>


### [54] [Bidirectional Representations Augmented Autoregressive Biological Sequence Generation:Application in De Novo Peptide Sequencing](https://arxiv.org/abs/2510.08169)
*Xiang Zhang,Jiaqi Wei,Zijie Qiu,Sheng Xu,Zhi Jin,ZhiQiang Gao,Nanqing Dong,Siqi Sun*

Main category: cs.LG

TL;DR: 본 연구는 AR 모델의 한계를 극복하고 NAR의 장점을 통합한 하이브리드 프레임워크를 제안하여 생물학적 시퀀스 모델링 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: AR 모델은 생물학적 작업에서 중요한 전역 양방향 토큰 의존성을 포착하지 못하는 한계가 있습니다.

Method: 하이브리드 프레임워크는 NAR 메커니즘에서 풍부한 맥락 정보를 동적으로 통합하여 AR 생성 성능을 향상시킵니다. 공유 입력 인코더와 두 개의 디코더를 결합합니다: 하나는 잠재적 양방향 생물학적 특징을 학습하는 NAR 디코더이고, 다른 하나는 이러한 양방향 특징을 활용하여 생물학적 시퀀스를 합성하는 AR 디코더입니다.

Result: 모델은 AR 및 NAR 기준선을 상당히 초과하여 9종의 새로운 펩타이드 시퀀스 벤치마크에서 뛰어난 성능을 보여줍니다.

Conclusion: 이 연구는 생물학적 시퀀스 모델링 기술을 발전시키고 복잡한 시퀀스 생성을 위한 AR 모델을 향상시킬 수 있는 새로운 아키텍처 패러다임을 제안합니다.

Abstract: Autoregressive (AR) models, common in sequence generation, are limited in
many biological tasks such as de novo peptide sequencing and protein modeling
by their unidirectional nature, failing to capture crucial global bidirectional
token dependencies. Non-Autoregressive (NAR) models offer holistic,
bidirectional representations but face challenges with generative coherence and
scalability. To transcend this, we propose a hybrid framework enhancing AR
generation by dynamically integrating rich contextual information from
non-autoregressive mechanisms. Our approach couples a shared input encoder with
two decoders: a non-autoregressive one learning latent bidirectional biological
features, and an AR decoder synthesizing the biological sequence by leveraging
these bidirectional features. A novel cross-decoder attention module enables
the AR decoder to iteratively query and integrate these bidirectional features,
enriching its predictions. This synergy is cultivated via a tailored training
strategy with importance annealing for balanced objectives and cross-decoder
gradient blocking for stable, focused learning. Evaluations on a demanding
nine-species benchmark of de novo peptide sequencing show that our model
substantially surpasses AR and NAR baselines. It uniquely harmonizes AR
stability with NAR contextual awareness, delivering robust, superior
performance on diverse downstream data. This research advances biological
sequence modeling techniques and contributes a novel architectural paradigm for
augmenting AR models with enhanced bidirectional understanding for complex
sequence generation. Code is available at https://github.com/BEAM-Labs/denovo.

</details>


### [55] [Dual-granularity Sinkhorn Distillation for Enhanced Learning from Long-tailed Noisy Data](https://arxiv.org/abs/2510.08179)
*Feng Hong,Yu Huang,Zihua Zhao,Zhihan Zhou,Jiangchao Yao,Dongsheng Li,Ya Zhang,Yanfeng Wang*

Main category: cs.LG

TL;DR: 이 논문은 클래스 불균형과 레이블 노음이 동시에 존재하는 실제 데이터셋에서 모델 성능을 향상시키기 위한 새로운 접근법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 클래스 불균형과 레이블 노음은 각각 다른 수준의 문제로, 서로 보완적인 강점을 제공할 수 있다.

Method: D-SINK는 '약한' 보조 모델로부터 상호 보완적인 통찰을 증류하고 통합하여 이중 강인성을 강화하는 새로운 프레임워크이다.

Result: D-SINK는 벤치마크 데이터셋에서 강인성을 크게 향상시키고, 긴 꼬리를 가진 노이즈 데이터에서 강력한 경험적 성과를 달성한다.

Conclusion: 이 논문은 클래스 불균형과 레이블 노음 문제를 효과적으로 해결하기 위한 새로운 관점을 제시한다.

Abstract: Real-world datasets for deep learning frequently suffer from the co-occurring
challenges of class imbalance and label noise, hindering model performance.
While methods exist for each issue, effectively combining them is non-trivial,
as distinguishing genuine tail samples from noisy data proves difficult, often
leading to conflicting optimization strategies. This paper presents a novel
perspective: instead of primarily developing new complex techniques from
scratch, we explore synergistically leveraging well-established, individually
'weak' auxiliary models - specialized for tackling either class imbalance or
label noise but not both. This view is motivated by the insight that class
imbalance (a distributional-level concern) and label noise (a sample-level
concern) operate at different granularities, suggesting that robustness
mechanisms for each can in principle offer complementary strengths without
conflict. We propose Dual-granularity Sinkhorn Distillation (D-SINK), a novel
framework that enhances dual robustness by distilling and integrating
complementary insights from such 'weak', single-purpose auxiliary models.
Specifically, D-SINK uses an optimal transport-optimized surrogate label
allocation to align the target model's sample-level predictions with a
noise-robust auxiliary and its class distributions with an imbalance-robust
one. Extensive experiments on benchmark datasets demonstrate that D-SINK
significantly improves robustness and achieves strong empirical performance in
learning from long-tailed noisy data.

</details>


### [56] [Expressive Value Learning for Scalable Offline Reinforcement Learning](https://arxiv.org/abs/2510.08218)
*Nicolas Espinosa-Dice,Kiante Brantley,Wen Sun*

Main category: cs.LG

TL;DR: 오프라인 강화 학습(EVOR)은 표현력이 높은 정책과 가치 함수를 통합한 확장 가능한 오프라인 RL 접근 방식을 제공하며, 복잡한 데이터셋에 적합하다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습(RL)은 결정 순서를 학습하는 강력한 패러다임이지만 로봇 공학에 충분히 활용되지 않고 있다. 오프라인 RL은 대규모의 다양한 데이터셋에서 에이전트를 훈련함으로써 온라인 RL의 비용이 많이 드는 실제 상호작용을 피하는 유망한 방법이다.

Method: 우리는 증식 및 흐름 일치를 활용해 최적의 정규화된 Q-함수를 학습하는 EVOR를 도입한다. 이 방법은 훈련 중에 플로우 매칭을 통해 따르는 정규화된 Q-함수를 학습하고, 추론 시 표현력 있는 가치 함수에 대한 기각 샘플링을 통해 정책 추출을 수행한다.

Result: EVOR은 다양한 오프라인 RL 작업에서 베이스라인보다 성능이 우수함을 보여주었다.

Conclusion: 표현력이 높은 가치 학습을 오프라인 RL에 통합함으로써 강력한 성능 향상을 입증하였다.

Abstract: Reinforcement learning (RL) is a powerful paradigm for learning to make
sequences of decisions. However, RL has yet to be fully leveraged in robotics,
principally due to its lack of scalability. Offline RL offers a promising
avenue by training agents on large, diverse datasets, avoiding the costly
real-world interactions of online RL. Scaling offline RL to increasingly
complex datasets requires expressive generative models such as diffusion and
flow matching. However, existing methods typically depend on either
backpropagation through time (BPTT), which is computationally prohibitive, or
policy distillation, which introduces compounding errors and limits scalability
to larger base policies. In this paper, we consider the question of how to
develop a scalable offline RL approach without relying on distillation or
backpropagation through time. We introduce Expressive Value Learning for
Offline Reinforcement Learning (EVOR): a scalable offline RL approach that
integrates both expressive policies and expressive value functions. EVOR learns
an optimal, regularized Q-function via flow matching during training. At
inference-time, EVOR performs inference-time policy extraction via rejection
sampling against the expressive value function, enabling efficient
optimization, regularization, and compute-scalable search without retraining.
Empirically, we show that EVOR outperforms baselines on a diverse set of
offline RL tasks, demonstrating the benefit of integrating expressive value
learning into offline RL.

</details>


### [57] [Reinforcement Learning from Probabilistic Forecasts for Safe Decision-Making via Conditional Value-at-Risk Planning](https://arxiv.org/abs/2510.08226)
*Michal Koren,Or Peretz,Tai Dinh,Philip S. Yu*

Main category: cs.LG

TL;DR: 이 논문은 체계적인 불확실성 관리가 필요한 고위험 결정 환경에서 불확실성을 고려한 마르코프 결정 프로세스(UAMDP)를 제안합니다. UAMDP는 베이지안 예측, 사후 샘플링 강화 학습, 조건부 가치-위험(CVaR) 제약에 따른 계획을 결합한 통합 프레임워크입니다. 이 접근법은 고주파 주식 거래와 소매 재고 관리를 포함한 두 가지 도메인에서 평가되었습니다.


<details>
  <summary>Details</summary>
Motivation: 변동성이 큰 고위험 환경에서의 sequential decision-making은 기대 수익을 극대화하는 것 이상이 필요하며, 원칙적인 불확실성 관리가 필요합니다.

Method: UAMDP는 베이지안 예측, 사후 샘플링 강화 학습, CVaR 제약을 결합한 통합 프레임워크입니다. 에이전트는 잠재적 동력에 대한 신념을 업데이트하고, 톰프슨 샘플링을 통해 가능한 미래를 샘플링하며, 정해진 리스크 허용치에 따라 정책을 최적화합니다.

Result: UAMDP는 두 가지 도메인에서 평가되었으며, 고주파 주식 거래와 소매 재고 관리에서 높은 예측 정확도를 보여 주었습니다. RMSE는 최대 25% 감소하고 sMAPE는 32% 감소하여 경제 성과 개선에 기여했습니다.

Conclusion: 조정된 확률적 모델링, 사후 불확실성과 일치하는 탐색, 리스크 인식 제어의 통합은 더 안전하고 수익성 높은 sequential decision-making을 위한 강력하고 일반화 가능한 접근법을 제공합니다.

Abstract: Sequential decisions in volatile, high-stakes settings require more than
maximizing expected return; they require principled uncertainty management.
This paper presents the Uncertainty-Aware Markov Decision Process (UAMDP), a
unified framework that couples Bayesian forecasting, posterior-sampling
reinforcement learning, and planning under a conditional value-at-risk (CVaR)
constraint. In a closed loop, the agent updates its beliefs over latent
dynamics, samples plausible futures via Thompson sampling, and optimizes
policies subject to preset risk tolerances. We establish regret bounds that
converge to the Bayes-optimal benchmark under standard regularity conditions.
We evaluate UAMDP in two domains-high-frequency equity trading and retail
inventory control-both marked by structural uncertainty and economic
volatility. Relative to strong deep learning baselines, UAMDP improves
long-horizon forecasting accuracy (RMSE decreases by up to 25\% and sMAPE by
32\%), and these gains translate into economic performance: the trading Sharpe
ratio rises from 1.54 to 1.74 while maximum drawdown is roughly halved. These
results show that integrating calibrated probabilistic modeling, exploration
aligned with posterior uncertainty, and risk-aware control yields a robust,
generalizable approach to safer and more profitable sequential decision-making.

</details>


### [58] [DeepEN: Personalized Enteral Nutrition for Critically Ill Patients using Deep Reinforcement Learning](https://arxiv.org/abs/2510.08350)
*Daniel Jason Tan,Jiayang Chen,Dilruk Perera,Kay Choong See,Mengling Feng*

Main category: cs.LG

TL;DR: DeepEN은 중증 환자를 위한 개인화된 경장 영양을 위한 심층 강화 학습 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 중증 환자의 영양 치료 성과를 개선하기 위해 개인화된 접근 방식을 도입하고자 한다.

Method: DeepEN은 MIMIC-IV 데이터베이스의 11,000명 이상의 ICU 환자 데이터를 사용하여 오프라인으로 훈련되었으며, 환자의 변화하는 생리학에 맞춘 4시간 간격의 섭취 권장량을 생성한다. 그리고 클리니컬 정보가 포함된 상태 공간과 짧은 기간과 장기 생존 결과의 목표 사이의 균형을 맞추는 보상 함수를 통합한다.

Result: DeepEN은 다양한 질적 및 양적 지표에서 의료전문가가 설정한 지침 및 정책을 초월하여, 예상 사망률을 3.7 ± 0.17 퍼센트 포인트 감소시키고 주요 영양 바이오마커에서 개선을 이룬다.

Conclusion: DeepEN은 전통적인 지침이나 경험적 접근 방식 이상으로 환자의 맞춤형 경장 영양 치료를 통해 안전한 데이터 기반의 개인화를 통해 결과를 개선할 수 있는 잠재력을 보여준다.

Abstract: We introduce DeepEN, a deep reinforcement learning (RL) framework for
personalized enteral nutrition (EN) in critically ill patients. Trained offline
on over 11,000 ICU patients from the MIMIC-IV database, DeepEN generates
4-hourly recommendations for caloric, protein, and fluid intake tailored to
each patient's evolving physiology. The model integrates a curated, clinically
informed state space with a custom reward function that balances short-term
physiological and nutrition-related goals with long-term survival outcomes.
Using a dueling double deep Q-network with conservative Q-learning
regularization, DeepEN learns clinically realistic policies that align with
high-value clinician actions while discouraging unsafe deviations. Across
various qualitative and quantitative metrics, DeepEN outperforms
clinician-derived and guideline-based policies, achieving a 3.7 $\pm$ 0.17
percentage-point reduction in estimated mortality (18.8% vs 22.5%) and
improvements in key nutritional biomarkers. These findings highlight the
potential of safe, data-driven personalization of EN therapy to improve
outcomes beyond traditional guideline- or heuristic-based approaches.

</details>


### [59] [Biology-driven assessment of deep learning super-resolution imaging of the porosity network in dentin](https://arxiv.org/abs/2510.08407)
*Lauren Anderson,Lucas Chatelain,Nicolas Tremblay,Kathryn Grandfield,David Rousseau,Aurélien Gourrier*

Main category: cs.LG

TL;DR: 본 연구는 치아의 기계 감각 시스템에서 세포 자극을 통해 높은 해상도의 이미지를 생성하기 위한 딥러닝 슈퍼 해상도 모델을 사용하였습니다.


<details>
  <summary>Details</summary>
Motivation: 치아의 기계 감각 시스템은 주로 치수에서의 체액 흐름에 의한 상아세포의 자극에 의존하는 것으로 여겨지며, 세포의 소규모 미세 구조를 시각화하는 데 도전이 있다.

Method: 서로 다른 센싱 방식으로 획득된 고해상도 및 저해상도 공초점 이미지를 이용하여 세 가지 감독 학습 2D 슈퍼 해상도 모델(RCAN, pix2pix, FSRCNN)과 하나의 비감독 학습 모델(CycleGAN)을 적용하였다.

Result: 모델 성능은 다양한 이미지 품질 평가 메트릭을 사용하여 측정되었으며, 결과는 주로 시각적 인식과 모순된 변동적인 값을 보였다.

Conclusion: SR 모델의 성능 평가를 생물학적으로 이끌어 내어 표준 IQA 메트릭의 실패 이유를 설명하는 차별화된 모델 감도 및 이미지 생성 비선형성의 영향을 강조하였다.

Abstract: The mechanosensory system of teeth is currently believed to partly rely on
Odontoblast cells stimulation by fluid flow through a porosity network
extending through dentin. Visualizing the smallest sub-microscopic porosity
vessels therefore requires the highest achievable resolution from confocal
fluorescence microscopy, the current gold standard. This considerably limits
the extent of the field of view to very small sample regions. To overcome this
limitation, we tested different deep learning (DL) super-resolution (SR) models
to allow faster experimental acquisitions of lower resolution images and
restore optimal image quality by post-processing. Three supervised 2D SR models
(RCAN, pix2pix, FSRCNN) and one unsupervised (CycleGAN) were applied to a
unique set of experimentally paired high- and low-resolution confocal images
acquired with different sampling schemes, resulting in a pixel size increase of
x2, x4, x8. Model performance was quantified using a broad set of similarity
and distribution-based image quality assessment (IQA) metrics, which yielded
inconsistent results that mostly contradicted our visual perception. This
raises the question of the relevance of such generic metrics to efficiently
target the specific structure of dental porosity. To resolve this conflicting
information, the generated SR images were segmented taking into account the
specific scales and morphology of the porosity network and analysed by
comparing connected components. Additionally, the capacity of the SR models to
preserve 3D porosity connectivity throughout the confocal image stacks was
evaluated using graph analysis. This biology-driven assessment allowed a far
better mechanistic interpretation of SR performance, highlighting differences
in model sensitivity to weak intensity features and the impact of non-linearity
in image generation, which explains the failure of standard IQA metrics.

</details>


### [60] [ClauseLens: Clause-Grounded, CVaR-Constrained Reinforcement Learning for Trustworthy Reinsurance Pricing](https://arxiv.org/abs/2510.08429)
*Stella C. Dong,James R. Finlay*

Main category: cs.LG

TL;DR: ClauseLens는 재보험 조약 가격 책정을 투명하고 규제 준수 및 위험 인식을 바탕으로 도와주는 강인한 강화 학습 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 재보험 조약 가격 책정은 엄격한 규제 기준을 충족해야 하지만 현재의 견적 관행은 불투명하고 감사하기 어렵다.

Method: ClauseLens는 가격 책정 작업을 위험 인식 제약 마르코프 결정 프로세스(RA-CMDP)로 모델링하며, 법적 및 인수 심사 데이터에서 조항을 검색하여 행위를 제약하고 자연 언어로 된 설명을 생성하는 데 사용한다.

Result: 다중 에이전트 조약 시뮬레이터에서 평가된 결과, ClauseLens는 지급 능력 위반을 51% 감소시키고, tail-risk 성능을 27.9% 개선하며, 조항 기반 설명에서 88.2%의 정확도와 87.4%의 검색 정밀도, 91.1%의 검색 재현율을 달성하였다.

Conclusion: 법적 맥락을 결정 및 설명 경로에 통합하는 것은 Solvency II, NAIC RBC 및 EU AI 법과 일치하는 해석 가능하고 감사 가능한 규제 준수 가격 책정 행위를 일으킨다.

Abstract: Reinsurance treaty pricing must satisfy stringent regulatory standards, yet
current quoting practices remain opaque and difficult to audit. We introduce
ClauseLens, a clause-grounded reinforcement learning framework that produces
transparent, regulation-compliant, and risk-aware treaty quotes.
  ClauseLens models the quoting task as a Risk-Aware Constrained Markov
Decision Process (RA-CMDP). Statutory and policy clauses are retrieved from
legal and underwriting corpora, embedded into the agent's observations, and
used both to constrain feasible actions and to generate clause-grounded natural
language justifications.
  Evaluated in a multi-agent treaty simulator calibrated to industry data,
ClauseLens reduces solvency violations by 51%, improves tail-risk performance
by 27.9% (CVaR_0.10), and achieves 88.2% accuracy in clause-grounded
explanations with retrieval precision of 87.4% and recall of 91.1%.
  These findings demonstrate that embedding legal context into both decision
and explanation pathways yields interpretable, auditable, and
regulation-aligned quoting behavior consistent with Solvency II, NAIC RBC, and
the EU AI Act.

</details>


### [61] [Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models](https://arxiv.org/abs/2510.08492)
*Sharut Gupta,Shobhita Sundaram,Chenyu Wang,Stefanie Jegelka,Phillip Isola*

Main category: cs.LG

TL;DR: UML: Unpaired Multimodal Learner는 보조 비쌍 데이터로 목표 모달리티의 표현 학습을 향상시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 다중 모달 학습 모델은 시각 질문 응답과 같은 작업을 위해 통합된 표현을 찾지만, 쌍 데이터셋에 크게 의존한다.

Method: UML은 파라미터를 공유하면서 서로 다른 모달리티의 입력을 번갈아 처리하는 모달리티 무관 교육 패러다임을 도입한다.

Result: 보조 모달리티에서 비쌍 데이터를 사용하면 이미지 및 오디오와 같은 다양한 단일 모달 타겟에서 하류 성능을 일관되게 향상시킬 수 있음을 보여준다.

Conclusion: 비쌍 보조 데이터를 사용한 학습이 단일 모달 훈련보다 데이터 생성 과정에 대한 더 유익한 표현을 제공함을 이론적으로 제시한다.

Abstract: Traditional multimodal learners find unified representations for tasks like
visual question answering, but rely heavily on paired datasets. However, an
overlooked yet potentially powerful question is: can one leverage auxiliary
unpaired multimodal data to directly enhance representation learning in a
target modality? We introduce UML: Unpaired Multimodal Learner, a
modality-agnostic training paradigm in which a single model alternately
processes inputs from different modalities while sharing parameters across
them. This design exploits the assumption that different modalities are
projections of a shared underlying reality, allowing the model to benefit from
cross-modal structure without requiring explicit pairs. Theoretically, under
linear data-generating assumptions, we show that unpaired auxiliary data can
yield representations strictly more informative about the data-generating
process than unimodal training. Empirically, we show that using unpaired data
from auxiliary modalities -- such as text, audio, or images -- consistently
improves downstream performance across diverse unimodal targets such as image
and audio. Our project page: https://unpaired-multimodal.github.io/

</details>


### [62] [Convergence Theorems for Entropy-Regularized and Distributional Reinforcement Learning](https://arxiv.org/abs/2510.08526)
*Yash Jhaveri,Harley Wiltzer,Patrick Shafto,Marc G. Bellemare,David Meger*

Main category: cs.LG

TL;DR: 이 연구에서는 특정 최적 정책으로의 수렴을 보장하는 정책 최적화 이론 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습(RL) 방법들은 일반적으로 기대 수익 외에 학습된 정책의 특성을 무시합니다.

Method: 우리는 사라지는 엔트로피 정규화와 온도 분리 전술을 활용하여 정책 최적화의 이론적 프레임워크를 제안합니다.

Result: 이 접근법은 정규화 온도가 사라질 때, 해석 가능하고 다양성을 보존하는 최적 정책을 실현하며, 정책으로부터 파생된 객체의 수렴을 보장합니다.

Conclusion: 온도 분리 전술을 활용하여, 우리는 해석 가능하고 다양성을 보존하는 최적 정책과 관련된 수익 분포를 임의의 정확도로 추정하는 알고리즘을 제시합니다.

Abstract: In the pursuit of finding an optimal policy, reinforcement learning (RL)
methods generally ignore the properties of learned policies apart from their
expected return. Thus, even when successful, it is difficult to characterize
which policies will be learned and what they will do. In this work, we present
a theoretical framework for policy optimization that guarantees convergence to
a particular optimal policy, via vanishing entropy regularization and a
temperature decoupling gambit. Our approach realizes an interpretable,
diversity-preserving optimal policy as the regularization temperature vanishes
and ensures the convergence of policy derived objects--value functions and
return distributions. In a particular instance of our method, for example, the
realized policy samples all optimal actions uniformly. Leveraging our
temperature decoupling gambit, we present an algorithm that estimates, to
arbitrary accuracy, the return distribution associated to its interpretable,
diversity-preserving optimal policy.

</details>


### [63] [Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints](https://arxiv.org/abs/2510.08549)
*Zilin Kang,Chonghua Liao,Tingqiang Xu,Huazhe Xu*

Main category: cs.LG

TL;DR: ERA는 샘플링 엔트로피를 제어하여 다양한 분야에서 성능 개선을 보여주는 새로운 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: 다양한 분야에서 모델 출력에 특별히 설계된 활성화를 적용하여 샘플링 엔트로피를 제어하는 새로운 방법을 제안한다.

Method: ERA를 통해 출력 활성화를 사용하여 샘플링 엔트로피를 특정 임계값 이상으로 제한하는 접근 방식을 도입한다.

Result: ERA는 Qwen2.5-Math-7B의 AIME 2025 점수를 37.4% 향상시키고, HumanoidBench에서 SAC와 같은 강력한 기준선에 비해 30% 이상 성능을 개선하며, ResNet-50을 위한 ImageNet top-1 정확도를 0.69% 높인다.

Conclusion: 출력 활성화가 엔트로피 제어를 위한 강력한 도구임을 입증하며, 간단하고 강력한 알고리즘 설계를 위한 새로운 방향을 열어준다.

Abstract: We propose ERA, a new paradigm that constrains the sampling entropy above
given thresholds by applying specially designed activations to the outputs of
models. Our approach demonstrates broad effectiveness across different domains:
1) for large language models(LLMs), boosting the AIME 2025 score for
Qwen2.5-Math-7B by 37.4%; 2) for continuous control reinforcement learning
agents, improving performance by more than 30% over strong baselines such as
SAC on the challenging HumanoidBench; 3) for image classification, enhancing
ImageNet top-1 accuracy by 0.69% for ResNet-50. These gains are achieved with a
computational overhead of less than 7%. Our work validates output activation as
a powerful tool for entropy control, opening a new direction for designing
simpler and more robust algorithms.

</details>
