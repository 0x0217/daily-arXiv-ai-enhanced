<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 12]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [The AI Committee: A Multi-Agent Framework for Automated Validation and Remediation of Web-Sourced Data](https://arxiv.org/abs/2512.21481)
*Sunith Vallabhaneni,Thomas Berkane,Maimuna Majumder*

Main category: cs.MA

TL;DR: 웹에서 데이터 수집의 어려움과 자동화 필요성을 해결하기 위해 AI Committee라는 다중 에이전트 시스템을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 많은 연구 분야는 웹 데이터를 기반으로 통찰을 얻고 방법을 테스트하는 데 의존합니다. 하지만 연구 데이터셋을 수집하는 과정이 수작업으로 많은 웹 페이지를 검토해야 하므로 노동 집약적이며 오류에 취약합니다.

Method: AI Committee는 데이터 품질 보증 파이프라인에서 각기 다른 작업에 전문화된 에이전트들로 구성된 다중 에이전트 시스템입니다. 이 시스템은 특정 작업 훈련 없이 LLM의 다양한 기능을 활용하여 웹에서 수집된 데이터셋을 자동으로 검증하고 수정합니다.

Result: 우리 시스템을 세 가지 실세계 데이터셋에 적용한 결과, LLM을 통해 일반화되며 기준 접근 방식을 크게 초월하여 데이터 완전도 78.7% 및 정확도 100%를 달성했습니다.

Conclusion: 이 연구는 연구 커뮤니티를 위한 오픈 소스 도구로 배포됩니다.

Abstract: Many research areas rely on data from the web to gain insights and test their methods. However, collecting comprehensive research datasets often demands manually reviewing many web pages to identify and record relevant data points, which is labor-intensive and susceptible to error. While the emergence of large language models (LLM)-powered web agents has begun to automate parts of this process, they often struggle to ensure the validity of the data they collect. Indeed, these agents exhibit several recurring failure modes - including hallucinating or omitting values, misinterpreting page semantics, and failing to detect invalid information - which are subtle and difficult to detect and correct manually. To address this, we introduce the AI Committee, a novel model-agnostic multi-agent system that automates the process of validating and remediating web-sourced datasets. Each agent is specialized in a distinct task in the data quality assurance pipeline, from source scrutiny and fact-checking to data remediation and integrity validation. The AI Committee leverages various LLM capabilities - including in-context learning for dataset adaptation, chain-of-thought reasoning for complex semantic validation, and a self-correction loop for data remediation - all without task-specific training. We demonstrate the effectiveness of our system by applying it to three real-world datasets, showing that it generalizes across LLMs and significantly outperforms baseline approaches, achieving data completeness up to 78.7% and precision up to 100%. We additionally conduct an ablation study demonstrating the contribution of each agent to the Committee's performance. This work is released as an open-source tool for the research community.

</details>


### [2] [PERELMAN: Pipeline for scientific literature meta-analysis. Technical report](https://arxiv.org/abs/2512.21727)
*Daniil Sherki,Daniil Merkulov,Alexandra Savina,Ekaterina Muravleva*

Main category: cs.MA

TL;DR: PERELMAN 프레임워크는 대규모 문헌 리뷰 및 메타 분석을 지원하기 위해 과학 기사의 특정 정보를 추출하도록 설계되었습니다.


<details>
  <summary>Details</summary>
Motivation: PERELMAN은 과학 문헌의 동질적이지 않은 콘텐츠를 통합된 기계 판독 가능 표현으로 변환하는 신뢰할 수 있는 방법을 제공하기 위해 개발되었습니다.

Method: PERELMAN은 먼저 주제 전문가와의 구조화된 대화를 통해 목표 변수, 포함 기준, 단위 및 정규화 규칙을 포함한 도메인 지식을 이끌어냅니다.

Result: 이 도메인 지식은 파이프라인의 여러 단계에서 재사용되며, 서사 텍스트, 표, 그림에서 증거를 추출하는 데 필수적입니다.

Conclusion: 이 시스템은 메타 분석 준비에 걸리는 시간을 몇 달에서 몇 분으로 단축시킬 잠재력을 가지고 있습니다.

Abstract: We present PERELMAN (PipEline foR sciEntific Literature Meta-ANalysis), an agentic framework designed to extract specific information from a large corpus of scientific articles to support large-scale literature reviews and meta-analyses. Our central goal is to reliably transform heterogeneous article content into a unified, machine-readable representation. PERELMAN first elicits domain knowledge-including target variables, inclusion criteria, units, and normalization rules-through a structured dialogue with a subject-matter expert. This domain knowledge is then reused across multiple stages of the pipeline and guides coordinated agents in extracting evidence from narrative text, tables, and figures, enabling consistent aggregation across studies. In order to assess reproducibility and validate our implementation, we evaluate the system on the task of reproducing the meta-analysis of layered Li-ion cathode properties (NMC811 material). We describe our solution, which has the potential to reduce the time required to prepare meta-analyses from months to minutes.

</details>


### [3] [MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting](https://arxiv.org/abs/2512.21878)
*Marc S. Montalvo,Hamed Yaghoobian*

Main category: cs.MA

TL;DR: MASFIN은 LLM을 통합한 다중 에이전트 프레임워크로, 금융 예측에서 투명하고 재현 가능한 분석을 제공하며, 단기 성과를 최적화한 포트폴리오를 생성한다.


<details>
  <summary>Details</summary>
Motivation: 금융 분야에서 신뢰성 있고 재현 가능한 분석의 필요성을 해결하기 위해.

Method: LLM과 구조적 금융 지표 및 비구조적 뉴스를 통합하고, 편향 완화 프로토콜을 포함하는 모듈식 다중 에이전트 프레임워크인 MASFIN을 제안한다.

Result: MASFIN은 8주 평가에서 S&P 500, NASDAQ-100, 다우지수 벤치마크를 초과하는 7.33% 누적 수익을 달성하였다.

Conclusion: 편향 인식 생성 AI 프레임워크가 금융 예측에 대한 가능성을 보여주며, 정량적 금융의 실용적이고 투명하며 재현 가능한 접근 방식을 발전시킬 수 있는 모듈식 다중 에이전트 설계의 기회를 강조한다.

Abstract: Recent advances in large language models (LLMs) are transforming data-intensive domains, with finance representing a high-stakes environment where transparent and reproducible analysis of heterogeneous signals is essential. Traditional quantitative methods remain vulnerable to survivorship bias, while many AI-driven approaches struggle with signal integration, reproducibility, and computational efficiency. We introduce MASFIN, a modular multi-agent framework that integrates LLMs with structured financial metrics and unstructured news, while embedding explicit bias-mitigation protocols. The system leverages GPT-4.1-nano for reproducability and cost-efficient inference and generates weekly portfolios of 15-30 equities with allocation weights optimized for short-term performance. In an eight-week evaluation, MASFIN delivered a 7.33% cumulative return, outperforming the S&P 500, NASDAQ-100, and Dow Jones benchmarks in six of eight weeks, albeit with higher volatility. These findings demonstrate the promise of bias-aware, generative AI frameworks for financial forecasting and highlight opportunities for modular multi-agent design to advance practical, transparent, and reproducible approaches in quantitative finance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Physics-Informed Neural Solvers for Periodic Quantum Eigenproblems](https://arxiv.org/abs/2512.21349)
*Haaris Mian*

Main category: cs.LG

TL;DR: 본 논문은 2차원 주기적 포텐셜에 대한 Floquet-Bloch 고유값 문제를 해결하기 위한 물리 정보 기계 학습 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 특이한 밴드 위상과 그래핀과 같은 소재의 관련성으로 인해 벌집 격자 기하학을 중심으로 연구한다.

Method: 신경망을 활용하여 복잡한 블로흐 함수와 그에 연결된 고유값(에너지)을 동시에 학습하며, 감독 없이 조합 손실 함수를 통해 슈뢰딩거 방정식, 블로흐 주기성 및 정규화 제약을 강제하는 메쉬 없는 해법기를 개발한다.

Result: 브릴루앙 영역에서 모델을 훈련시켜 밴드 구조와 블로흐 모드를 복원하고, 전통적인 평면파 확장 방법과 수치적인 검증을 수행한다.

Conclusion: 전이 학습 기법을 탐색하여 거의 자유 전자 포텐셜에서 강하게 변화하는 포텐셜로 해법기를 조정하고, 밴드 구조 위상 변화 포착 능력을 보인다.

Abstract: This thesis presents a physics-informed machine learning framework for solving the Floquet-Bloch eigenvalue problem associated with particles in two-dimensional periodic potentials, with a focus on honeycomb lattice geometry, due to its distinctive band topology featuring Dirac points and its relevance to materials such as graphene. By leveraging neural networks to learn complex Bloch functions and their associated eigenvalues (energies) simultaneously, we develop a mesh-free solver enforcing the governing Schrödinger equation, Bloch periodicity, and normalization constraints through a composite loss function without supervision. The model is trained over the Brillouin zone to recover band structures and Bloch modes, with numerical validation against traditional plane-wave expansion methods. We further explore transfer learning techniques to adapt the solver from nearly-free electron potentials to strongly varying potentials, demonstrating its ability to capture changes in band structure topology. This work contributes to the growing field of physics-informed machine learning for quantum eigenproblems, providing insights into the interplay between symmetry, band structure, and neural architectures.

</details>


### [5] [A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning](https://arxiv.org/abs/2512.21412)
*Alimu Alibotaiken,Suyang Wang,Oluwaseun T. Ajayi,Yu Cheng*

Main category: cs.LG

TL;DR: 이 논문은 정보의 나이(AoI)와 강화를 통한 학습을 통합된 문제로 다루는 리서치를 진행한다.


<details>
  <summary>Details</summary>
Motivation: 물리적 환경에서의 데이터의 신선도를 최적화하기 위해 정보의 나이를 고려해야 한다는 필요성이 존재한다.

Method: 정보의 나이 및 그 변형을 고유, 기능 기반, 응용 지향으로 분류하고, 정책 중심의 분류법을 소개하여 다양한 RL 기술을 정리한다.

Result: 강화 학습에 기반한 신선도 제어 및 지연 결정 과정, 확률적 변동성, 크로스 레이어 설계와 관련된 문제를 강조한다.

Conclusion: 차세대 무선 네트워크에서 학습 기반의 신선도 최적화를 위한 통합된 기반을 세우는 것이 목표이다.

Abstract: The age of information (AoI) has become a central measure of data freshness in modern wireless systems, yet existing surveys either focus on classical AoI formulations or provide broad discussions of reinforcement learning (RL) in wireless networks without addressing freshness as a unified learning problem. Motivated by this gap, this survey examines RL specifically through the lens of AoI and generalized freshness optimization. We organize AoI and its variants into native, function-based, and application-oriented families, providing a clearer view of how freshness should be modeled in B5G and 6G systems. Building on this foundation, we introduce a policy-centric taxonomy that reflects the decisions most relevant to freshness, consisting of update-control RL, medium-access RL, risk-sensitive RL, and multi-agent RL. This structure provides a coherent framework for understanding how learning can support sampling, scheduling, trajectory planning, medium access, and distributed coordination. We further synthesize recent progress in RL-driven freshness control and highlight open challenges related to delayed decision processes, stochastic variability, and cross-layer design. The goal is to establish a unified foundation for learning-based freshness optimization in next-generation wireless networks.

</details>


### [6] [RLLaVA: An RL-central Framework for Language and Vision Assistants](https://arxiv.org/abs/2512.21450)
*Lei Zhao,Zihao Ma,Boyu Lin,Yuhe Liu,Wenjun Wu,Lei Huang*

Main category: cs.LG

TL;DR: 이 논문은 RL 알고리즘과 모델 아키텍처 및 분산 실행을 분리하는 RL-central 프레임워크인 RLLaVA를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 새로운 RL 알고리즘을 최소한의 코드로 구현하고 다양한 RL 방법과 비전-언어 모델을 쉽게 연결할 수 있도록 지원하기 위해.

Method: 마르코프 결정 과정(MDP)으로 구성된 RLLaVA를 통해 RL 알고리즘의 논리와 모델 아키텍처를 분리하여 개발한다.

Result: RLLaVA는 1B-7B 모델의 자원 효율적인 훈련을 가능하게 하며, 4B 규모 모델은 단일 24GB GPU에서 전체 매개변수 업데이트로 훈련될 수 있다.

Conclusion: RLLaVA로 훈련된 모델은 기본 모델에 비해 성능이 지속적으로 향상되며, 다른 특별히 설계된 RL 프레임워크와 경쟁력 있는 성능을 보인다.

Abstract: We present an RL-central framework for Language and Vision Assistants (RLLaVA) with its formulation of Markov decision process (MDP). RLLaVA decouples RL algorithmic logic from model architecture and distributed execution, supporting researchers in implementing new RL algorithms with minimal code, and to plug in a broad family of RL methods and vision-language models (VLMs) while remaining agnostic to specific training and inference engines. RLLaVA makes resource-efficient training of 1B--7B models feasible on common GPUs; notably, 4B-scale models can be trained end-to-end with full-parameter updates on a single 24GB GPU. Experiments on multi-modal and agentic tasks demonstrate that RLLaVA has task extensibility, and the models trained with it consistently improve performance over base models, competitive with other specially engineered RL frameworks. The code is available at https://github.com/TinyLoopX/RLLaVA.

</details>


### [7] [AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification](https://arxiv.org/abs/2512.21544)
*Xinru Wen,Weizhong Lin,Xuan Xiao*

Main category: cs.LG

TL;DR: AVP-Fusion은 항바이러스 펩타이드의 정확한 식별을 위한 새로운 딥러닝 프레임워크로, 복잡한 시퀀스 의존성을 포착하고 모호한 샘플을 효과적으로 처리한다.


<details>
  <summary>Details</summary>
Motivation: 항바이러스 펩타이드의 정확한 식별은 새로운 약물 개발을 촉진하는 데 중요하다.

Method: AVP-Fusion은 적응형 특징 융합과 대비 학습을 통합한 두 단계의 딥러닝 프레임워크이다.

Result: AVP-Fusion은 벤치마크 Set 1 데이터셋에서 0.9531의 정확도와 0.9064의 MCC를 기록하여 최첨단 방법을 크게 능가하였다.

Conclusion: AVP-Fusion은 고처리량 항바이러스 약물 선별을 위한 강력하고 해석 가능한 도구로 작용한다.

Abstract: Accurate identification of antiviral peptides (AVPs) is critical for accelerating novel drug development. However, current computational methods struggle to capture intricate sequence dependencies and effectively handle ambiguous, hard-to-classify samples. To address these challenges, we propose AVP-Fusion, a novel two-stage deep learning framework integrating adaptive feature fusion and contrastive learning. Unlike traditional static feature concatenation, we construct a panoramic feature space using 10 distinct descriptors and introduce an Adaptive Gating Mechanism.This mechanism dynamically regulates the weights of local motifs extracted by CNNs and global dependencies captured by BiLSTMs based on sequence context. Furthermore, to address data distribution challenges, we employ a contrastive learning strategy driven by Online Hard Example Mining (OHEM) and BLOSUM62-based data augmentation, which significantly sharpens the model's decision boundaries. Experimental results on the benchmark Set 1 dataset demonstrate that AVP-Fusion achieves an accuracy of 0.9531 and an MCC of 0.9064, significantly outperforming state-of-the-art methods. In the second stage, leveraging transfer learning, the model enables precise subclass prediction for six viral families and eight specific viruses, even under limited sample sizes. In summary, AVP-Fusion serves as a robust and interpretable tool for high-throughput antiviral drug screening.

</details>


### [8] [Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations](https://arxiv.org/abs/2512.21586)
*Xin Liu,Haoran Li,Dongbin Zhao*

Main category: cs.LG

TL;DR: 이 논문에서는 비디오로부터 모방 학습을 달성하기 위한 새로운 비지도 및 샘플 효율적인 프레임워크인 BCV-LR을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 비디오에서 지식 습득과 기술 학습을 하는 인간의 능력을 자율 에이전트가 복제하는 데 있어 큰 도전 과제가 있기 때문에.

Method: BCV-LR은 자가 지도 작업을 통해 고차원 비디오 입력에서 행동 관련 잠재적 특성을 추출하고, 연속 프레임 간의 잠재적 행동을 예측하기 위해 역학 기반의 비지도 목표를 활용한다.

Result: BCV-LR은 몇 가지 상호작용만으로도 효과적인 정책 성능을 가능하게 하여, 24/28 개 작업에서 샘플 효율성 측면에서 최첨단 ILV 기준 및 강화 학습 방법을 초월한다.

Conclusion: 비디오가 전문적인 감독 없이도 매우 샘플 효율적인 시각적 정책 학습을 지원할 수 있음을 처음으로 입증하였다.

Abstract: Humans can efficiently extract knowledge and learn skills from the videos within only a few trials and errors. However, it poses a big challenge to replicate this learning process for autonomous agents, due to the complexity of visual input, the absence of action or reward signals, and the limitations of interaction steps. In this paper, we propose a novel, unsupervised, and sample-efficient framework to achieve imitation learning from videos (ILV), named Behavior Cloning from Videos via Latent Representations (BCV-LR). BCV-LR extracts action-related latent features from high-dimensional video inputs through self-supervised tasks, and then leverages a dynamics-based unsupervised objective to predict latent actions between consecutive frames. The pre-trained latent actions are fine-tuned and efficiently aligned to the real action space online (with collected interactions) for policy behavior cloning. The cloned policy in turn enriches the agent experience for further latent action finetuning, resulting in an iterative policy improvement that is highly sample-efficient.
  We conduct extensive experiments on a set of challenging visual tasks, including both discrete control and continuous control. BCV-LR enables effective (even expert-level on some tasks) policy performance with only a few interactions, surpassing state-of-the-art ILV baselines and reinforcement learning methods (provided with environmental rewards) in terms of sample efficiency across 24/28 tasks. To the best of our knowledge, this work for the first time demonstrates that videos can support extremely sample-efficient visual policy learning, without the need to access any other expert supervision.

</details>


### [9] [Dictionary-Transform Generative Adversarial Networks](https://arxiv.org/abs/2512.21677)
*Angshul Majumdar*

Main category: cs.LG

TL;DR: DT-GAN은 전통적인 GAN의 한계를 극복할 수 있는 새로운 모델 기반 적대적 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 GAN은 이론적으로 불안정하고 해석 가능성이 제한되어 있어, 이를 개선할 필요가 있다.

Method: DT-GAN은 생성기와 판별기를 선형 연산자로 제약하여 적대적 게임을 수행하는 구조를 가진다.

Result: DT-GAN은 최소한 하나의 내쉬 균형을 보장하며, 실험적으로도 구조를 안정적으로 복원한다.

Conclusion: DT-GAN은 해석 가능하고 안정적인 적대적 학습이 가능하다는 것을 보여준다.

Abstract: Generative adversarial networks (GANs) are widely used for distribution learning, yet their classical formulations remain theoretically fragile, with ill-posed objectives, unstable training dynamics, and limited interpretability. In this work, we introduce \emph{Dictionary-Transform Generative Adversarial Networks} (DT-GAN), a fully model-based adversarial framework in which the generator is a sparse synthesis dictionary and the discriminator is an analysis transform acting as an energy model. By restricting both players to linear operators with explicit constraints, DT-GAN departs fundamentally from neural GAN architectures and admits rigorous theoretical analysis.
  We show that the DT-GAN adversarial game is well posed and admits at least one Nash equilibrium. Under a sparse generative model, equilibrium solutions are provably identifiable up to standard permutation and sign ambiguities and exhibit a precise geometric alignment between synthesis and analysis operators. We further establish finite-sample stability and consistency of empirical equilibria, demonstrating that DT-GAN training converges reliably under standard sampling assumptions and remains robust in heavy-tailed regimes.
  Experiments on mixture-structured synthetic data validate the theoretical predictions, showing that DT-GAN consistently recovers underlying structure and exhibits stable behavior under identical optimization budgets where a standard GAN degrades. DT-GAN is not proposed as a universal replacement for neural GANs, but as a principled adversarial alternative for data distributions that admit sparse synthesis structure. The results demonstrate that adversarial learning can be made interpretable, stable, and provably correct when grounded in classical sparse modeling.

</details>


### [10] [An Information Theoretic Perspective on Agentic System Design](https://arxiv.org/abs/2512.21720)
*Shizhe He,Avanika Narayan,Ishan S. Khare,Scott W. Linderman,Christopher Ré,Dan Biderman*

Main category: cs.LG

TL;DR: 이 논문은 압축기-예측기 시스템의 설계가 정보이론적이며, 압축기 LMs가 예측기 LMs와의 성능을 어떻게 연결하는지를 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 압축기-예측기 시스템의 설계에 대한 지침이 부족하고, 이로 인해 성능 향상을 위한 최적의 LM 조합을 찾기 어렵습니다.

Method: 압축기 LM을 노이즈 채널로 보고, 문맥과 그 압축 간의 상호 정보를 추정하여 압축 품질을 측정하는 방법을 제시합니다.

Result: 상호 정보가 하류 성능을 강하게 예측하며, 대규모 압축기가 더 정확하고 토큰 효율성이 높다는 것을 발견했습니다.

Conclusion: 압축기는 예측기보다 더 효과적인 성능을 제공하며, 로컬 압축기가 클라우드 예측기와 잘 결합될 수 있음을 보여줍니다.

Abstract: Agentic language model (LM) systems power modern applications like "Deep Research" and "Claude Code," and leverage multi-LM architectures to overcome context limitations. Beneath their apparent diversity lies a recurring pattern: smaller "compressor" LMs (that can even run locally) distill raw context into compact text that is then consumed by larger "predictor" LMs. Despite their popularity, the design of compressor-predictor systems remains largely ad hoc, with little guidance on how compressor and predictor choices shape downstream performance. In practice, attributing gains to compression versus prediction requires costly, task-specific pairwise sweeps. We argue that these agentic system design questions are, at root, information-theoretic. Viewing the compressor LM as a noisy channel, we introduce a simple estimator of mutual information between the context and its compression to quantify compression quality in a task-independent way. We show that mutual information strongly predicts downstream performance, independent of any specific task. Through an information-theoretic framework, we perform a comprehensive empirical analysis across five datasets and three model families. Results reveal that larger compressors not only are more accurate, but also more token-efficient, conveying more bits of information per token. A 7B Qwen-2.5 compressor, for instance, is $1.6\times$ more accurate, $4.6\times$ more concise, and conveys $5.5\times$ more bits of mutual information per token than its 1.5B sibling. Across datasets, scaling compressors is substantially more effective than scaling predictors, enabling larger on-device compressors to pair with smaller cloud predictors. Applied to a Deep Research system, these principles enable local compressors as small as 3B parameters to recover $99\%$ of frontier-LM accuracy at $26\%$ of API costs.

</details>


### [11] [Approximation Capabilities of Feedforward Neural Networks with GELU Activations](https://arxiv.org/abs/2512.21749)
*Konstantin Yakovlev,Nikita Puchkin*

Main category: cs.LG

TL;DR: 이 논문은 함수와 그 모든 도함수에 대한 근사 오차 경계에 대해 다룬다.


<details>
  <summary>Details</summary>
Motivation: 다양한 초등 함수에 대한 근사 정확도를 높이기 위함이다.

Method: 피드포워드 신경망과 가우시안 오차 선형 단위(GELU) 활성화를 사용하여 경계를 얻었다.

Result: 경계가 증가하는 크기의 도메인에서 동시에 유효함을 입증하였다.

Conclusion: 모든 고차 도함수가 전역적으로 제한되도록 보장하는 근사 보장을 얻었다.

Abstract: We derive an approximation error bound that holds simultaneously for a function and all its derivatives up to any prescribed order. The bounds apply to elementary functions, including multivariate polynomials, the exponential function, and the reciprocal function, and are obtained using feedforward neural networks with the Gaussian Error Linear Unit (GELU) activation. In addition, we report the network size, weight magnitudes, and behavior at infinity. Our analysis begins with a constructive approximation of multiplication, where we prove the simultaneous validity of error bounds over domains of increasing size for a given approximator. Leveraging this result, we obtain approximation guarantees for division and the exponential function, ensuring that all higher-order derivatives of the resulting approximators remain globally bounded.

</details>


### [12] [Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms](https://arxiv.org/abs/2512.21925)
*Kongchang Zhou,Tingyu Zhang,Wei Chen,Fang Kong*

Main category: cs.LG

TL;DR: 본 연구에서는 오프라인 데이터와 온라인 상호작용을 결합한 새로운 하이브리드 CMAB-T 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 온라인 및 오프라인 접근 방식의 한계를 극복하기 위해 상호 보완적인 장점을 날려주기 위한 것입니다.

Method: 하이브리드 CUCB 알고리즘을 통해 오프라인 데이터를 활용하여 탐색을 안내하고 수렴 속도를 높이며, 온라인 상호작용을 전략적으로 통합하여 오프라인 데이터셋의 부족한 범위나 분포 편향을 완화합니다.

Result: 하이브리드 CUCB 알고리즘은 고품질 오프라인 데이터가 제공될 때 순수한 온라인 접근 방식을 크게 능가하며, 데이터가 제한적이거나 정렬되지 않았을 때 오프라인 전용 方法의 편향을 효과적으로 수정합니다.

Conclusion: 우리의 알고리즘은 일관된 이점을 보여주는 경험적 결과를 제공합니다.

Abstract: The problem of combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) has been extensively studied. Prior work primarily focuses on either the online setting where an agent learns about the unknown environment through iterative interactions, or the offline setting where a policy is learned solely from logged data. However, each of these paradigms has inherent limitations: online algorithms suffer from high interaction costs and slow adaptation, while offline methods are constrained by dataset quality and lack of exploration capabilities. To address these complementary weaknesses, we propose hybrid CMAB-T, a new framework that integrates offline data with online interaction in a principled manner. Our proposed hybrid CUCB algorithm leverages offline data to guide exploration and accelerate convergence, while strategically incorporating online interactions to mitigate the insufficient coverage or distributional bias of the offline dataset. We provide theoretical guarantees on the algorithm's regret, demonstrating that hybrid CUCB significantly outperforms purely online approaches when high-quality offline data is available, and effectively corrects the bias inherent in offline-only methods when the data is limited or misaligned. Empirical results further demonstrate the consistent advantage of our algorithm.

</details>


### [13] [LibContinual: A Comprehensive Library towards Realistic Continual Learning](https://arxiv.org/abs/2512.22029)
*Wenbin Li,Shangge Liu,Borui Kang,Yiyang Chen,KaXuan Lew,Yang Chen,Yinghuan Shi,Lei Wang,Yang Gao,Jiebo Luo*

Main category: cs.LG

TL;DR: 지속적 학습에서의 재앙적 망각 문제를 해결하기 위해 LibContinual이라는 포괄적이고 재현 가능한 라이브러리를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 지속적 학습의 발전에도 불구하고, 다양한 방법론의 등장으로 인해 연구 환경이 단편화되었고, 일관된 비교 및 재현성이 어려워졌다.

Method: LibContinual은 높은 응집력과 낮은 결합도를 갖춘 모듈식 아키텍처를 기반으로 하여 19개의 대표 알고리즘을 통합하여 표준화된 실행 환경을 제공한다.

Result: 엄격한 온라인 CL 설정과 자원-aware, 의미론적으로 강건한 CL 전략의 필요성을 강조하며, 여러 대표 CL 방법에서 성능 저하를 드러낸다.

Conclusion: LibContinual을 미래의 지속적 학습 연구를 위한 기초 도구로 제공한다.

Abstract: A fundamental challenge in Continual Learning (CL) is catastrophic forgetting, where adapting to new tasks degrades the performance on previous ones. While the field has evolved with diverse methods, this rapid surge in diverse methodologies has culminated in a fragmented research landscape. The lack of a unified framework, including inconsistent implementations, conflicting dependencies, and varying evaluation protocols, makes fair comparison and reproducible research increasingly difficult. To address this challenge, we propose LibContinual, a comprehensive and reproducible library designed to serve as a foundational platform for realistic CL. Built upon a high-cohesion, low-coupling modular architecture, LibContinual integrates 19 representative algorithms across five major methodological categories, providing a standardized execution environment. Meanwhile, leveraging this unified framework, we systematically identify and investigate three implicit assumptions prevalent in mainstream evaluation: (1) offline data accessibility, (2) unregulated memory resources, and (3) intra-task semantic homogeneity. We argue that these assumptions often overestimate the real-world applicability of CL methods. Through our comprehensive analysis using strict online CL settings, a novel unified memory budget protocol, and a proposed category-randomized setting, we reveal significant performance drops in many representative CL methods when subjected to these real-world constraints. Our study underscores the necessity of resource-aware and semantically robust CL strategies, and offers LibContinual as a foundational toolkit for future research in realistic continual learning. The source code is available from \href{https://github.com/RL-VIG/LibContinual}{https://github.com/RL-VIG/LibContinual}.

</details>


### [14] [A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting](https://arxiv.org/abs/2512.22101)
*Shuyu Gan,Renxiang Wang,James Mooney,Dongyeop Kang*

Main category: cs.LG

TL;DR: A2P-Vis는 데이터 분석가와 발표자로 구성된 두 부분의 다중 에이전트 파이프라인으로, 원시 데이터를 고품질 데이터 시각화 보고서로 변환하는 시스템이다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트를 활용한 데이터 사이언스 파이프라인 자동화가 특히 시각적 증거 생성과 일관된 보고서 작성에서 격차가 발생하고 있다.

Method: 데이터 분석가는 프로파일링을 조정하고, 다양한 시각화 방향을 제안하며, 플로팅 코드를 생성 및 실행하고, 저품질 그림을 걸러내고, 깊이, 정확성, 구체성 및 실행 가능성을 기준으로 자동 점수를 매기는 후보 통찰력을 유도한다. 발표자는 주제를 정렬하고, 최고의 통찰력에서 차트 기반 서사를 구성하며, 정당화된 전환을 작성하고 문서를 명확성과 일관성을 위해 수정하여 일관된 출판 준비 보고서를 작성한다.

Result: 이 에이전트들은 원시 데이터를 검토된 통찰력과 차트로 구성된 자료로 전환하고 수동적인 작업 없이 읽기 쉬운 서사를 생성한다.

Conclusion: A2P-Vis는 품질 보증된 분석기와 서사 발표자를 결합하여 데이터 분석의 실용성을 개선하고, 자동화된 데이터 분석의 실용성에 기여한다.

Abstract: Automating end-to-end data science pipeline with AI agents still stalls on two gaps: generating insightful, diverse visual evidence and assembling it into a coherent, professional report. We present A2P-Vis, a two-part, multi-agent pipeline that turns raw datasets into a high-quality data-visualization report. The Data Analyzer orchestrates profiling, proposes diverse visualization directions, generates and executes plotting code, filters low-quality figures with a legibility checker, and elicits candidate insights that are automatically scored for depth, correctness, specificity, depth and actionability. The Presenter then orders topics, composes chart-grounded narratives from the top-ranked insights, writes justified transitions, and revises the document for clarity and consistency, yielding a coherent, publication-ready report. Together, these agents convert raw data into curated materials (charts + vetted insights) and into a readable narrative without manual glue work. We claim that by coupling a quality-assured Analyzer with a narrative Presenter, A2P-Vis operationalizes co-analysis end-to-end, improving the real-world usefulness of automated data analysis for practitioners. For the complete dataset report, please see: https://www.visagent.org/api/output/f2a3486d-2c3b-4825-98d4-5af25a819f56.

</details>


### [15] [Explainable Multimodal Regression via Information Decomposition](https://arxiv.org/abs/2512.22102)
*Zhaozhao Ma,Shujian Yu*

Main category: cs.LG

TL;DR: 본 논문에서는 다중 모달 회귀를 위한 새로운 프레임워크를 제안하며, PID를 기반으로 각 모달의 기여도를 명확히 하고 해석 가능성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 다중 모달 회귀는 이질적인 입력 소스로부터 연속적인 타겟을 예측하는 것을 목표로 하며, 기존 방법은 모달의 개별 기여와 상호작용을 명확히 할 수 있는 도구가 부족하다.

Method: Partial Information Decomposition (PID)에 기반한 새로운 다중 모달 회귀 프레임워크를 제안하며, 라틴 표현의 공동 분포에서 가우시안성을 강제하여 PID 용어의 분석적 계산을 가능하게 한다.

Result: 우리의 프레임워크는 6개의 실세계 데이터셋에서 최첨단 방법보다 예측 정확성과 해석 가능성 모두에서 우수한 성능을 보인다.

Conclusion: 제안된 방법은 효과적인 추론을 위한 정보 모달 선택도 가능하게 한다.

Abstract: Multimodal regression aims to predict a continuous target from heterogeneous input sources and typically relies on fusion strategies such as early or late fusion. However, existing methods lack principled tools to disentangle and quantify the individual contributions of each modality and their interactions, limiting the interpretability of multimodal fusion. We propose a novel multimodal regression framework grounded in Partial Information Decomposition (PID), which decomposes modality-specific representations into unique, redundant, and synergistic components. The basic PID framework is inherently underdetermined. To resolve this, we introduce inductive bias by enforcing Gaussianity in the joint distribution of latent representations and the transformed response variable (after inverse normal transformation), thereby enabling analytical computation of the PID terms. Additionally, we derive a closed-form conditional independence regularizer to promote the isolation of unique information within each modality. Experiments on six real-world datasets, including a case study on large-scale brain age prediction from multimodal neuroimaging data, demonstrate that our framework outperforms state-of-the-art methods in both predictive accuracy and interpretability, while also enabling informed modality selection for efficient inference. Implementation is available at https://github.com/zhaozhaoma/PIDReg.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [16] [Reflection-Driven Control for Trustworthy Code Agents](https://arxiv.org/abs/2512.21354)
*Bin Wang,Jiazheng Quan,Xingrui Yu,Hansen Hu,Yuhao,Ivor Tsang*

Main category: cs.CR

TL;DR: Reflection-Driven Control은 대규모 언어 모델 에이전트의 안전성을 높이기 위한 모듈로, 위험을 감지하고 이를 개선하기 위해 내부 반성 루프를 활용한다.


<details>
  <summary>Details</summary>
Motivation: 현대의 대규모 언어 모델 에이전트는 많은 능력을 가지고 있지만, 신뢰할 수 있는 안전 제어가 부족하고 예측할 수 없는 유해한 출력을 생성할 수 있다.

Method: 이 논문에서는 Reflection-Driven Control이라는 표준화되고 플러그 가능 한 제어 모듈을 제안하며, 이를 통해 에이전트의 추론 과정에서 '자기 반성'을 명시적인 단계로 끌어올린다. 생성 과정 중 에이전트는 자신의 결정 경로를 모니터링하고 평가하는 내부 반성 루프를 지속적으로 실행한다.

Result: 검증 결과, Reflection-Driven Control은 생성된 코드의 보안성과 정책 준수를 크게 개선하며 기능적 정확성을 보존하고 최소한의 런타임과 토큰 오버헤드를 유지한다.

Conclusion: 이러한 발견은 Reflection-Driven Control이 신뢰할 수 있는 AI 코드 에이전트를 위한 실용적인 경로임을 나타낸다. 이는 자율적이고 구조적으로 더 안전하며 감사 가능성이 있는 디자인을 지원하게 된다.

Abstract: Contemporary large language model (LLM) agents are remarkably capable, but they still lack reliable safety controls and can produce unconstrained, unpredictable, and even actively harmful outputs. To address this, we introduce Reflection-Driven Control, a standardized and pluggable control module that can be seamlessly integrated into general agent architectures. Reflection-Driven Control elevates "self-reflection" from a post hoc patch into an explicit step in the agent's own reasoning process: during generation, the agent continuously runs an internal reflection loop that monitors and evaluates its own decision path. When potential risks are detected, the system retrieves relevant repair examples and secure coding guidelines from an evolving reflective memory, injecting these evidence-based constraints directly into subsequent reasoning steps. We instantiate Reflection-Driven Control in the setting of secure code generation and systematically evaluate it across eight classes of security-critical programming tasks. Empirical results show that Reflection-Driven Control substantially improves the security and policy compliance of generated code while largely preserving functional correctness, with minimal runtime and token overhead. Taken together, these findings indicate that Reflection-Driven Control is a practical path toward trustworthy AI coding agents: it enables designs that are simultaneously autonomous, safer by construction, and auditable.

</details>


### [17] [The Imitation Game: Using Large Language Models as Chatbots to Combat Chat-Based Cybercrimes](https://arxiv.org/abs/2512.21371)
*Yifan Yao,Baojuan Wang,Jinhao Duan,Kaidi Xu,ChuanKai Guo,Zhibo Eric Sun,Yue Zhang*

Main category: cs.CR

TL;DR: 챗 기반 사이버 범죄는 신뢰 구축, 기만, 심리적 조작에 의존하는 사기를 수행하기 위해 실시간 메시징 플랫폼을 사용하는 광범위한 위협으로 떠올랐다. 본 연구에서는 기계가 인간 피해자로서 기만을 반전시킬 수 있는지에 대한 질문을 제기하며, LURE라는 시스템을 소개한다. 이 시스템은 적대적인 채팅 환경 내에서 능동적인 에이전트로 대규모 언어 모델(LLM)을 배치하여, 불법 비디오 채팅 사기에서 53명의 행동자와 상호작용하며 성공적으로 이모테이션 게임에서 승리했다.


<details>
  <summary>Details</summary>
Motivation: 사이버 범죄가 점점 더 교묘해지고 있으며, 전통적인 방어 메커니즘이 이러한 대화형 위협을 효과적으로 식별하지 못하는 문제를 해결하고자 한다.

Method: LURE는 대화형 인터랙션, 완전 자동 발견 및 이미지 내 결제 데이터에 대한 OCR 기반 분석을 결합하여 대규모 언어 모델을 능동적인 에이전트로 활용한다.

Result: 우리의 시스템은 Telegram에서 불법 비디오 채팅 사기를 대상으로 53명의 행동자와 상호작용하였고, 56% 이상의 상호작용에서 LLM이 봇으로 인식되지 않고 다수의 대화를 유지하는 데 성공하였다.

Conclusion: LURE는 사기 작전의 주요 행동 패턴을 밝혀냈으며, 이는 결제 흐름, 업셀링 전략 및 플랫폼 이동 전술을 포함한다.

Abstract: Chat-based cybercrime has emerged as a pervasive threat, with attackers leveraging real-time messaging platforms to conduct scams that rely on trust-building, deception, and psychological manipulation. Traditional defense mechanisms, which operate on static rules or shallow content filters, struggle to identify these conversational threats, especially when attackers use multimedia obfuscation and context-aware dialogue.
  In this work, we ask a provocative question inspired by the classic Imitation Game: Can machines convincingly pose as human victims to turn deception against cybercriminals? We present LURE (LLM-based User Response Engagement), the first system to deploy Large Language Models (LLMs) as active agents, not as passive classifiers, embedded within adversarial chat environments.
  LURE combines automated discovery, adversarial interaction, and OCR-based analysis of image-embedded payment data. Applied to the setting of illicit video chat scams on Telegram, our system engaged 53 actors across 98 groups. In over 56 percent of interactions, the LLM maintained multi-round conversations without being noticed as a bot, effectively "winning" the imitation game. Our findings reveal key behavioral patterns in scam operations, such as payment flows, upselling strategies, and platform migration tactics.

</details>


### [18] [LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors](https://arxiv.org/abs/2512.21404)
*Tianwei Lan,Farid Naït-Abdesselam*

Main category: cs.CR

TL;DR: 이 논문에서는 머신러닝 기반 안드로이드 맬웨어 탐지 시스템을 우회하는 새로운 적대적 공격 프레임워크 LAMLAD를 제시합니다. 이 프레임워크는 대형 언어 모델의 생성 및 추론 능력을 활용하여 보다 효과적이고 효율적인 공격을 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: 안드로이드 맬웨어의 규모와 복잡성이 급격히 증가함에 따라, 정확하고 확장 가능한 맬웨어 탐지를 위한 머신러닝 기법의 널리 사용되고 있습니다. 그러나 이러한 모델은 의도적으로 제작된 특성 수준의 변조에 취약하여 탐지를 피하면서도 악성 기능을 유지할 수 있습니다.

Method: LAMLAD는 리얼리스틱하고 기능을 유지하는 특성 변조를 생성하는 LLM 조작기와 변조 과정이 성공적인 회피로 유도되는 LLM 분석기로 구성된 이중 에이전트 아키텍처를 사용합니다. 또한, RAG를 LLM 파이프라인에 통합하여 효율성과 맥락 인식을 개선합니다.

Result: LAMLAD는 Drebin 스타일의 특성 표현에 초점을 맞추어 널리 배포된 안드로이드 맬웨어 탐지 시스템에 대해 은밀하고 높은 신뢰도의 공격을 가능하게 합니다. 실험 결과, LAMLAD는 공격 성공률(ASR) 97%를 달성하며, 평균적으로 적대적 샘플당 3회 만의 시도로 이를 가능하게 했습니다.

Conclusion: 추가로, LAMLAD 스타일 공격에 대한 모델의 탄력성을 크게 향상시키기 위해 ASR을 평균 30% 이상 줄이는 적대적 훈련 기반 방어 전략을 제안합니다.

Abstract: The rapid growth in both the scale and complexity of Android malware has driven the widespread adoption of machine learning (ML) techniques for scalable and accurate malware detection. Despite their effectiveness, these models remain vulnerable to adversarial attacks that introduce carefully crafted feature-level perturbations to evade detection while preserving malicious functionality. In this paper, we present LAMLAD, a novel adversarial attack framework that exploits the generative and reasoning capabilities of large language models (LLMs) to bypass ML-based Android malware classifiers. LAMLAD employs a dual-agent architecture composed of an LLM manipulator, which generates realistic and functionality-preserving feature perturbations, and an LLM analyzer, which guides the perturbation process toward successful evasion. To improve efficiency and contextual awareness, LAMLAD integrates retrieval-augmented generation (RAG) into the LLM pipeline. Focusing on Drebin-style feature representations, LAMLAD enables stealthy and high-confidence attacks against widely deployed Android malware detection systems. We evaluate LAMLAD against three representative ML-based Android malware detectors and compare its performance with two state-of-the-art adversarial attack methods. Experimental results demonstrate that LAMLAD achieves an attack success rate (ASR) of up to 97%, requiring on average only three attempts per adversarial sample, highlighting its effectiveness, efficiency, and adaptability in practical adversarial settings. Furthermore, we propose an adversarial training-based defense strategy that reduces the ASR by more than 30% on average, significantly enhancing model robustness against LAMLAD-style attacks.

</details>


### [19] [GoldenFuzz: Generative Golden Reference Hardware Fuzzing](https://arxiv.org/abs/2512.21524)
*Lichao Wu,Mohamadreza Rostami,Huimin Li,Nikhilesh Singh,Ahmad-Reza Sadeghi*

Main category: cs.CR

TL;DR: GoldenFuzz는 테스트 케이스 정제와 취약점 탐사를 부분적으로 분리하는 새로운 두 단계 하드웨어 퍼징 프레임워크로, RISC-V 프로세서의 테스트에서 기존 퍼저보다 높은 커버리지를 달성하며, 새로운 취약점도 발견한다.


<details>
  <summary>Details</summary>
Motivation: 하드웨어 시스템의 복잡성이 증가하면서 버그와 보안 취약점의 위험이 커지고 있으므로, 이러한 결점을 발견하기 위한 스케일 가능한 솔루션이 필요하다.

Method: GoldenFuzz는 빠른 ISA 준수 골든 레퍼런스 모델(GRM)을 사용하여 하드웨어 내 테스트 케이스 정제와 커버리지 탐사를 부분적으로 분리하는 두 단계의 퍼징 프레임워크를 제공한다.

Result: 세 가지 RISC-V 프로세서, RocketChip, BOOM, CVA6에 대한 평가 결과, GoldenFuzz가 기존 퍼저보다 높은 커버리지를 달성하고 최소의 테스트 케이스 길이와 계산 오버헤드로 성능이 우수함을 보여준다.

Conclusion: GoldenFuzz는 모든 알려진 취약점을 발견하고, CVSS v3 심각도 점수가 10점 중 7점을 초과하는 네 개의 심각한 새로운 취약점을 포함하여 총 다섯 개의 새로운 취약점을 발견하였다.

Abstract: Modern hardware systems, driven by demands for high performance and application-specific functionality, have grown increasingly complex, introducing large surfaces for bugs and security-critical vulnerabilities. Fuzzing has emerged as a scalable solution for discovering such flaws. Yet, existing hardware fuzzers suffer from limited semantic awareness, inefficient test refinement, and high computational overhead due to reliance on slow device simulation.
  In this paper, we present GoldenFuzz, a novel two-stage hardware fuzzing framework that partially decouples test case refinement from coverage and vulnerability exploration. GoldenFuzz leverages a fast, ISA-compliant Golden Reference Model (GRM) as a ``digital twin'' of the Device Under Test (DUT). It fuzzes the GRM first, enabling rapid, low-cost test case refinement, accelerating deep architectural exploration and vulnerability discovery on DUT. During the fuzzing pipeline, GoldenFuzz iteratively constructs test cases by concatenating carefully chosen instruction blocks that balance the subtle inter- and intra-instructions quality. A feedback-driven mechanism leveraging insights from both high- and low-coverage samples further enhances GoldenFuzz's capability in hardware state exploration. Our evaluation of three RISC-V processors, RocketChip, BOOM, and CVA6, demonstrates that GoldenFuzz significantly outperforms existing fuzzers in achieving the highest coverage with minimal test case length and computational overhead. GoldenFuzz uncovers all known vulnerabilities and discovers five new ones, four of which are classified as highly severe with CVSS v3 severity scores exceeding seven out of ten. It also identifies two previously unknown vulnerabilities in the commercial BA51-H core extension.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [20] [From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration](https://arxiv.org/abs/2512.21360)
*Shuide Wen,Yu Sun,Beier Ku,Zhi Gao,Lijun Ma,Yang Yang,Can Jiao*

Main category: cs.AI

TL;DR: 본 연구는 다중 모달 대형 언어 모델을 활용하여 하우스-트리-퍼슨(House-Tree-Person, HTP) 테스트의 고찰을 통해 심리 평가의 표준화 가능성을 제시한다.


<details>
  <summary>Details</summary>
Motivation: HTP 그리기 테스트는 임상 심리학에서 널리 사용되지만, 불균형한 채점 기준과 주관적인 경험에 의존하는 경향이 있다.

Method: 다양한 양적 실험을 통해 HTP 테스트 해석의 의미적 유사성을 평가하고, 다중 에이전트 시스템을 사용하여 심리적 맥락을 통합하였다.

Result: MLLM 해석과 전문가 해석 간의 평균 의미적 유사성이 약 0.75였으며, 구조적으로 지향된 전문가 데이터 세트에서는 이 유사성이 0.85로 상승하였다.

Conclusion: 다중 모달 대형 모델은 프로젝트 평가를 위한 표준화 도구로서의 가능성을 확인하였으며, 다중 에이전트 프레임워크는 역할 분담을 통해 새로운 디지털 정신 건강 서비스 패러다임을 제시한다.

Abstract: Background: The House-Tree-Person (HTP) drawing test, introduced by John Buck in 1948, remains a widely used projective technique in clinical psychology. However, it has long faced challenges such as heterogeneous scoring standards, reliance on examiners subjective experience, and a lack of a unified quantitative coding system.
  Results: Quantitative experiments showed that the mean semantic similarity between Multimodal Large Language Model (MLLM) interpretations and human expert interpretations was approximately 0.75 (standard deviation about 0.05). In structurally oriented expert data sets, this similarity rose to 0.85, indicating expert-level baseline comprehension. Qualitative analyses demonstrated that the multi-agent system, by integrating social-psychological perspectives and destigmatizing narratives, effectively corrected visual hallucinations and produced psychological reports with high ecological validity and internal coherence.
  Conclusions: The findings confirm the potential of multimodal large models as standardized tools for projective assessment. The proposed multi-agent framework, by dividing roles, decouples feature recognition from psychological inference and offers a new paradigm for digital mental-health services.
  Keywords: House-Tree-Person test; multimodal large language model; multi-agent collaboration; cosine similarity; computational psychology; artificial intelligence

</details>


### [21] [Three-way conflict analysis based on alliance and conflict functions](https://arxiv.org/abs/2512.21419)
*Junfang Luo,Mengjun Hu,Guangming Lang,Xin Yang,Keyun Qin*

Main category: cs.AI

TL;DR: 본 논문은 세 방향 갈등 분석에서 중요한 세 가지 요소인 에이전트, 이슈 및 에이전트 쌍을 분리하여 갈등 분석의 주요 질문을 해결하는 데 도움을 주기 위해 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트와 이슈 간의 관계를 명확히 하고 세 가지 방향 갈등 분석의 복잡성을 해결하기 위해.

Method: 보조 함수를 동맹과 갈등 함수로 분리하고, 에이전트, 이슈 및 에이전트 쌍을 세분화하여 갈등 분석에 적용.

Result: 동맹 +1과 갈등 -1의 관계가 중립 0의 관계와 동일한 결과를 내는 것을 방지하는 방법을 제시.

Conclusion: 제안된 모델을 통해 실세계의 갈등 문제를 더 효과적으로 해결할 수 있다.

Abstract: Trisecting agents, issues, and agent pairs are essential topics of three-way conflict analysis. They have been commonly studied based on either a rating or an auxiliary function. A rating function defines the positive, negative, or neutral ratings of agents on issues. An auxiliary function defines the alliance, conflict, and neutrality relations between agents. These functions measure two opposite aspects in a single function, leading to challenges in interpreting their aggregations over a group of issues or agents. For example, when studying agent relations regarding a set of issues, a standard aggregation takes the average of an auxiliary function concerning single issues. Therefore, a pair of alliance +1 and conflict -1 relations will produce the same result as a pair of neutrality 0 relations, although the attitudes represented by the two pairs are very different. To clarify semantics, we separate the two opposite aspects in an auxiliary function into a pair of alliance and conflict functions. Accordingly, we trisect the agents, issues, and agent pairs and investigate their applications in solving a few crucial questions in conflict analysis. Particularly, we explore the concepts of alliance sets and strategies. A real-world application is given to illustrate the proposed models.

</details>


### [22] [Feasible strategies in three-way conflict analysis with three-valued ratings](https://arxiv.org/abs/2512.21420)
*Jing Liu,Mengjun Hu,Guangming Lang*

Main category: cs.AI

TL;DR: 본 논문은 세 방향 갈등 분석에 있어 전략 형성의 부족을 해결하기 위한 연구를 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 세 방향 갈등 분석 연구는 갈등의 본질 이해에는 기여했으나, 갈등 해결에 대한 전략 형성을 충분히 다루지 못했습니다.

Method: 합의된 에이전트 집단의 전반적인 평가를 계산한 후, 에이전트와 이슈의 가중치를 고려하여 일관성과 비일관성을 측정하는 방법을 제안합니다.

Result: 제안된 모델을 NBA 노동 협상과 간쑤 성 개발 계획 사례에 적용하여 민감도 분석과 기존 갈등 분석 접근 방법과의 비교 분석을 수행했습니다.

Conclusion: 우리의 갈등 해결 모델은 기존 접근 방식보다 우수한 성능을 보이며, 이는 가중치 에이전트-이슈 평가와 일관성 및 비일관성 측정을 통합함으로써 달성됩니다.

Abstract: Most existing work on three-way conflict analysis has focused on trisecting agent pairs, agents, or issues, which contributes to understanding the nature of conflicts but falls short in addressing their resolution. Specifically, the formulation of feasible strategies, as an essential component of conflict resolution and mitigation, has received insufficient scholarly attention. Therefore, this paper aims to investigate feasible strategies from two perspectives of consistency and non-consistency. Particularly, we begin with computing the overall rating of a clique of agents based on positive and negative similarity degrees. Afterwards, considering the weights of both agents and issues, we propose weighted consistency and non-consistency measures, which are respectively used to identify the feasible strategies for a clique of agents. Algorithms are developed to identify feasible strategies, $L$-order feasible strategies, and the corresponding optimal ones. Finally, to demonstrate the practicality, effectiveness, and superiority of the proposed models, we apply them to two commonly used case studies on NBA labor negotiations and development plans for Gansu Province and conduct a sensitivity analysis on parameters and a comparative analysis with existing state-of-the-art conflict analysis approaches. The comparison results demonstrate that our conflict resolution models outperform the conventional approaches by unifying weighted agent-issue evaluation with consistency and non-consistency measures to enable the systematic identification of not only feasible strategies but also optimal solutions.

</details>


### [23] [LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis](https://arxiv.org/abs/2512.21482)
*Fanwei Zeng,Changtao Miao,Jing Huang,Zhiya Tan,Shutao Gong,Xiaoming Yu,Yang Wang,Huazhe Tan,Weibin Yao,Jianshu Li*

Main category: cs.AI

TL;DR: LogicLens는 시각-텍스트 공동 추론을 위한 통합 프레임워크로, 텍스트 중심 위조 분석의 성능을 향상시키는 데 기여합니다.


<details>
  <summary>Details</summary>
Motivation: 빠른 AIGC 발전으로 인한 정교한 텍스트 중심 위조가 사회 안전과 정보의 진위를 위협하고 있습니다.

Method: LogicLens는 시각적 단서와 텍스트 논리를 반복적으로 교차 검증하는 Cross-Cues-aware Chain of Thought (CCT) 메커니즘을 기반으로 한 통합 프레임워크를 제공합니다.

Result: 광범위한 실험을 통해 LogicLens가 여러 벤치마크에서 우수성을 입증하며, T-IC13에서 41.4% 및 GPT-4o에서 23.4% 높은 F1 점수를 기록했습니다.

Conclusion: 우리의 데이터셋과 모델, 코드는 공개될 예정입니다.

Abstract: Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis and lack the capacity for sophisticated reasoning. Moreover, they typically treat detection, grounding, and explanation as discrete sub-tasks, overlooking their intrinsic relationships for holistic performance enhancement. To address these challenges, we introduce LogicLens, a unified framework for Visual-Textual Co-reasoning that reformulates these objectives into a joint task. The deep reasoning of LogicLens is powered by our novel Cross-Cues-aware Chain of Thought (CCT) mechanism, which iteratively cross-validates visual cues against textual logic. To ensure robust alignment across all tasks, we further propose a weighted multi-task reward function for GRPO-based optimization. Complementing this framework, we first designed the PR$^2$ (Perceiver, Reasoner, Reviewer) pipeline, a hierarchical and iterative multi-agent system that generates high-quality, cognitively-aligned annotations. Then, we constructed RealText, a diverse dataset comprising 5,397 images with fine-grained annotations, including textual explanations, pixel-level segmentation, and authenticity labels for model training. Extensive experiments demonstrate the superiority of LogicLens across multiple benchmarks. In a zero-shot evaluation on T-IC13, it surpasses the specialized framework by 41.4% and GPT-4o by 23.4% in macro-average F1 score. Moreover, on the challenging dense-text T-SROIE dataset, it establishes a significant lead over other MLLM-based methods in mF1, CSS, and the macro-average F1. Our dataset, model, and code will be made publicly available.

</details>


### [24] [NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent](https://arxiv.org/abs/2512.21578)
*Ali Sahami,Sudhanshu Garg,Andrew Wang,Chaitanya Kulkarni,Farhad Farahani,Sean Yun-Shiuan Chuang,Jian Wan,Srinivasan Manoharan,Uma Kona,Nitin Sharma,Linsey Pang,Prakhar Mehrotra,Jessica Clark,Mark Moyou*

Main category: cs.AI

TL;DR: PayPal의 Commerce Agent 개발 및 최적화를 제시하며, 이를 통해 에이전트 상거래 혁신을 목표로 하고 있다.


<details>
  <summary>Details</summary>
Motivation: PayPal 플랫폼에서 에이전트 상거래를 혁신하기 위해, NEMO-4-PAYPAL에 의해 구동되는 다중 에이전트 시스템을 개발하고 최적화하였다.

Method: NeMo Framework를 활용해 LLM 모델 세밀 조정을 통해 에이전트 성능을 향상시켰으며, Nemotron 소형 언어 모델로 Search and Discovery 에이전트를 최적화하였다.

Result: llama3.1-nemotron-nano-8B-v1 아키텍처를 사용하여 종합 실험을 진행하며, LoRA 기반 모델을 학습률, 옵티마이저 및 LoRA 랭크에 대해 체계적으로 조정하였다.

Conclusion: 세심하게 조정된 Nemotron SLM이 검색 컴포넌트에서의 주요 성능 문제를 효과적으로 해결하였고, 전체 시스템 성능을 유지하거나 향상시켰음을 입증하였다.

Abstract: We present the development and optimization of PayPal's Commerce Agent, powered by NEMO-4-PAYPAL, a multi-agent system designed to revolutionize agentic commerce on the PayPal platform. Through our strategic partnership with NVIDIA, we leveraged the NeMo Framework for LLM model fine-tuning to enhance agent performance. Specifically, we optimized the Search and Discovery agent by replacing our base model with a fine-tuned Nemotron small language model (SLM).
  We conducted comprehensive experiments using the llama3.1-nemotron-nano-8B-v1 architecture, training LoRA-based models through systematic hyperparameter sweeps across learning rates, optimizers (Adam, AdamW), cosine annealing schedules, and LoRA ranks. Our contributions include: (1) the first application of NVIDIA's NeMo Framework to commerce-specific agent optimization, (2) LLM powered fine-tuning strategy for retrieval-focused commerce tasks, (3) demonstration of significant improvements in latency and cost while maintaining agent quality, and (4) a scalable framework for multi-agent system optimization in production e-commerce environments. Our results demonstrate that the fine-tuned Nemotron SLM effectively resolves the key performance issue in the retrieval component, which represents over 50\% of total agent response time, while maintaining or enhancing overall system performance.

</details>


### [25] [Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design](https://arxiv.org/abs/2512.21623)
*Takahide Suzuki,Kazuki Nakanishi,Takashi Fujiwara,Hideyuki Shimizu*

Main category: cs.AI

TL;DR: OrchestRA는 생물학, 화학, 약리학을 통합하여 자율 발견 엔진을 제공하는 플랫폼으로, 치료제 발견 과정을 혁신합니다.


<details>
  <summary>Details</summary>
Motivation: 치료제 발견은 전문 분야의 분화와 계산 설계와 생리학적 검증 간의 실행 격차로 인해 큰 도전 과제로 남아 있습니다.

Method: OrchestRA는 여러 에이전트가 함께 활동하여 시뮬레이션을 실행하고 결과를 이유 용기하기 위해 설계되었습니다. 이 플랫폼은 생물학자, 화학자, 약리학자 에이전트를 포함하여 각각의 역할에 따라 자율적으로 작동합니다.

Result: 생리학적 기반 약리학(PBPK) 시뮬레이션을 통해 후보 물질을 평가하며, 구조 재최적화를 직접 트리거하는 동적 피드백 루프를 구축합니다.

Conclusion: OrchestRA는 자율 실행과 인간의 지침을 통합하여 치료제 설계의 민주화를 이루며, 약물 발견 과정을 확률적 검색이 아닌 프로그래밍 가능한 증거 기반 공학 분야로 변화시킵니다.

Abstract: Therapeutic discovery remains a formidable challenge, impeded by the fragmentation of specialized domains and the execution gap between computational design and physiological validation. Although generative AI offers promise, current models often function as passive assistants rather than as autonomous executors. Here, we introduce OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine. Unlike static code generators, our agents actively execute simulations and reason the results to drive iterative optimization. Governed by an Orchestrator, a Biologist Agent leverages deep reasoning over a massive knowledge graph (>10 million associations) to pinpoint high-confidence targets; a Chemist Agent autonomously detects structural pockets for de novo design or drug repositioning; and a Pharmacologist Agent evaluates candidates via rigorous physiologically based pharmacokinetic (PBPK) simulations. This architecture establishes a dynamic feedback loop where pharmacokinetic and toxicity profiles directly trigger structural reoptimization. By seamlessly integrating autonomous execution with human guidance, OrchestRA democratizes therapeutic design, transforming drug discovery from a stochastic search to a programmable evidence-based engineering discipline.

</details>


### [26] [A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning](https://arxiv.org/abs/2512.21583)
*Zelin Zang,Wenyi Gu,Siqi Ma,Dan Yang,Yue Shen,Zhu Zhang,Guohui Fan,Wing-Kuen Ling,Fuji Yang*

Main category: cs.AI

TL;DR: 이 논문은 비전-언어 모델을 바탕으로 한 진단 프레임워크를 제안하며, 임상 신뢰성을 높이기 위해 논리 정규화 추론을 통합합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델과 비전-언어 모델의 급속한 성장으로 인해 임상 텍스트와 의료 이미지를 단순히 통합하는 것만으로는 신뢰할 수 있는 추론을 보장할 수 없습니다.

Method: LLaVA를 기반으로 한 진단 프레임워크를 제안하며, 비전-언어 정렬과 논리 정규화 추론을 결합합니다. 시스템은 입력 인코더, 크로스 모달 정렬을 위한 프로젝션 모듈, 진단 작업을 단계로 분해하는 추론 컨트롤러, 스텝별 전제들을 검증 가능한 결론으로 조립하는 논리 트리 생성기로 구성됩니다.

Result: MedXpertQA 및 기타 벤치마크에서의 평가 결과, 우리의 방법은 진단 정확도를 향상시키고 다중 모달 작업에서 더 해석 가능한 추론 흔적을 생성하는 것으로 나타났으며, 텍스트 전용 설정에서도 경쟁력을 유지하였습니다.

Conclusion: 이 결과는 신뢰할 수 있는 다중 모달 의료 AI를 향한 유망한 단계임을 시사합니다.

Abstract: With the rapid growth of large language models (LLMs) and vision-language models (VLMs) in medicine, simply integrating clinical text and medical imaging does not guarantee reliable reasoning. Existing multimodal models often produce hallucinations or inconsistent chains of thought, limiting clinical trust. We propose a diagnostic framework built upon LLaVA that combines vision-language alignment with logic-regularized reasoning. The system includes an input encoder for text and images, a projection module for cross-modal alignment, a reasoning controller that decomposes diagnostic tasks into steps, and a logic tree generator that assembles stepwise premises into verifiable conclusions. Evaluations on MedXpertQA and other benchmarks show that our method improves diagnostic accuracy and yields more interpretable reasoning traces on multimodal tasks, while remaining competitive on text-only settings. These results suggest a promising step toward trustworthy multimodal medical AI.

</details>


### [27] [AMS-IO-Bench and AMS-IO-Agent: Benchmarking and Structured Reasoning for Analog and Mixed-Signal Integrated Circuit Input/Output Design](https://arxiv.org/abs/2512.21613)
*Zhishuai Zhang,Xintian Li,Shilong Liu,Aodong Zhang,Lu Jie,Nan Sun*

Main category: cs.AI

TL;DR: AMS-IO-Agent는 아날로그 및 혼합 신호 집적 회로 설계를 위한 LLM 기반의 에이전트로, 자연어 설계 의도를 산업 수준의 AMS IC 설계 결과물과 연결하는 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: AMS IC 설계 과정에서의 자연어 설계 의도와 결과물 간의 연결 고리 필요성.

Method: 지식 기반과 JSON 및 Python을 통한 설계 의도 구조화 기능을 통합하여 사용자의 모호한 의도를 명확화.

Result: 70% 이상의 DRC+LVS 합격률과 설계 대기 시간을 몇 시간에서 몇 분으로 단축하여 기존 LLM을 능가하는 성과.

Conclusion: 28nm CMOS 테이프 아웃에서 실제 AMS IC 설계 흐름에 효과가 있음을 입증한 최초의 LLM 기반 인간-에이전트 협력 사례이다.

Abstract: In this paper, we propose AMS-IO-Agent, a domain-specialized LLM-based agent for structure-aware input/output (I/O) subsystem generation in analog and mixed-signal (AMS) integrated circuits (ICs). The central contribution of this work is a framework that connects natural language design intent with industrial-level AMS IC design deliverables. AMS-IO-Agent integrates two key capabilities: (1) a structured domain knowledge base that captures reusable constraints and design conventions; (2) design intent structuring, which converts ambiguous user intent into verifiable logic steps using JSON and Python as intermediate formats. We further introduce AMS-IO-Bench, a benchmark for wirebond-packaged AMS I/O ring automation. On this benchmark, AMS-IO-Agent achieves over 70\% DRC+LVS pass rate and reduces design turnaround time from hours to minutes, outperforming the baseline LLM. Furthermore, an agent-generated I/O ring was fabricated and validated in a 28 nm CMOS tape-out, demonstrating the practical effectiveness of the approach in real AMS IC design flows. To our knowledge, this is the first reported human-agent collaborative AMS IC design in which an LLM-based agent completes a nontrivial subtask with outputs directly used in silicon.

</details>


### [28] [Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning](https://arxiv.org/abs/2512.21699)
*Eranga Bandara,Tharaka Hewa,Ross Gore,Sachin Shetty,Ravi Mukkamala,Peter Foytik,Abdul Rahman,Safdar H. Bouk,Xueping Liang,Amin Hass,Sachini Rajapakse,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.AI

TL;DR: 이 논문에서는 다중 모델 합의 및 사고 계층 거버넌스를 기반으로 하는 책임 있는 AI 및 설명 가능한 AI 에이전트 아키텍처를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자동 시스템의 자율성이 증가함에 따라 설명 가능성, 책임, 견고함 및 거버넌스와 관련된 중요한 도전 과제가 발생하고 있습니다.

Method: 이 설계에서는 이질적인 LLM 및 VLM 에이전트의 컨소시엄이 공유 입력 컨텍스트로부터 후보 출력을 독립적으로 생성하며, 불확실성, 불일치 및 대체 해석을 명시적으로 노출합니다.

Result: 이 아키텍처의 평가는 다수의 실제 Agentic AI 워크플로우에서 수행되어 합의 기반 사고가 다양한 응용 분야에서 견고성, 투명성 및 운영 신뢰성을 향상시킨다는 것을 보여줍니다.

Conclusion: 이 작업은 자율적이고 확장 가능한 동시에 책임이 있고 설명 가능한 시스템 설계를 위한 실용적인 지침을 제공합니다.

Abstract: Agentic AI represents a major shift in how autonomous systems reason, plan, and execute multi-step tasks through the coordination of Large Language Models (LLMs), Vision Language Models (VLMs), tools, and external services. While these systems enable powerful new capabilities, increasing autonomy introduces critical challenges related to explainability, accountability, robustness, and governance, especially when agent outputs influence downstream actions or decisions. Existing agentic AI implementations often emphasize functionality and scalability, yet provide limited mechanisms for understanding decision rationale or enforcing responsibility across agent interactions. This paper presents a Responsible(RAI) and Explainable(XAI) AI Agent Architecture for production-grade agentic workflows based on multi-model consensus and reasoning-layer governance. In the proposed design, a consortium of heterogeneous LLM and VLM agents independently generates candidate outputs from a shared input context, explicitly exposing uncertainty, disagreement, and alternative interpretations. A dedicated reasoning agent then performs structured consolidation across these outputs, enforcing safety and policy constraints, mitigating hallucinations and bias, and producing auditable, evidence-backed decisions. Explainability is achieved through explicit cross-model comparison and preserved intermediate outputs, while responsibility is enforced through centralized reasoning-layer control and agent-level constraints. We evaluate the architecture across multiple real-world agentic AI workflows, demonstrating that consensus-driven reasoning improves robustness, transparency, and operational trust across diverse application domains. This work provides practical guidance for designing agentic AI systems that are autonomous and scalable, yet responsible and explainable by construction.

</details>


### [29] [Accelerating Scientific Discovery with Autonomous Goal-evolving Agents](https://arxiv.org/abs/2512.21782)
*Yuanqi Du,Botao Yu,Tianyu Liu,Tony Shen,Junwu Chen,Jan G. Rittig,Kunyang Sun,Yikun Zhang,Zhangde Song,Bo Zhou,Cassandra Masschelein,Yingze Wang,Haorui Wang,Haojun Jia,Chao Zhang,Hongyu Zhao,Martin Ester,Teresa Head-Gordon,Carla P. Gomes,Huan Sun,Chenru Duan,Philippe Schwaller,Wengong Jin*

Main category: cs.AI

TL;DR: 과학적 발견을 위한 자동 목표 함수 설계의 필요성을 강조하며, SAGA라는 새로운 에이전트를 통해 이 도전을 해결한다.


<details>
  <summary>Details</summary>
Motivation: 과학적 발견을 확장하는 에이전트를 개발하는 데 있어 목표 함수의 자동화가 중요하다.

Method: SAGA는 외부 LLM 에이전트와 내부 최적화 루프로 구성된 이중 구조를 이용하여 목표 변화를 탐색한다.

Result: 항생제 설계, 무기 재료 설계 등 다양한 응용을 통해 목표 공식을 자동화하면 과학적 발견 에이전트의 효과성을 높일 수 있음을 보여준다.

Conclusion: 목표 함수의 자동 설계는 과학적 발견의 효과성을 크게 향상시킬 수 있다.

Abstract: There has been unprecedented interest in developing agents that expand the boundary of scientific discovery, primarily by optimizing quantitative objective functions specified by scientists. However, for grand challenges in science , these objectives are only imperfect proxies. We argue that automating objective function design is a central, yet unmet requirement for scientific discovery agents. In this work, we introduce the Scientific Autonomous Goal-evolving Agent (SAGA) to amend this challenge. SAGA employs a bi-level architecture in which an outer loop of LLM agents analyzes optimization outcomes, proposes new objectives, and converts them into computable scoring functions, while an inner loop performs solution optimization under the current objectives. This bi-level design enables systematic exploration of the space of objectives and their trade-offs, rather than treating them as fixed inputs. We demonstrate the framework through a broad spectrum of applications, including antibiotic design, inorganic materials design, functional DNA sequence design, and chemical process design, showing that automating objective formulation can substantially improve the effectiveness of scientific discovery agents.

</details>


### [30] [SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?](https://arxiv.org/abs/2512.21907)
*Kenny Workman,Zhen Yang,Harihara Muralidharan,Hannah Le*

Main category: cs.AI

TL;DR: SpatialBench는 실용적 공간 분석 워크플로에서 파생된 146개의 검증 가능한 문제의 벤치마크로, 공간 전사체 분석에서 AI의 효용성을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 공간 전사체 분석의 증가하는 규모와 복잡도로 인해 생물학적 발견에서 컴퓨터 분석이 주요 병목 현상이 되고 있다.

Method: 공간 분석 워크플로에서 파생된 146개의 문제를 포함한 벤치마크 데이터 세트와 공간 기술 및 작업 범주 전반에 걸친 검증 가능한 분석 단계를 도입하였다.

Result: 프론티어 모델의 벤치마크 데이터에 따르면, 기본 모델의 정확성은 여전히 낮고(모델 계열 전반에 걸쳐 20-38%), 모델-작업 및 모델-플랫폼 간의 상호작용이 강한 것으로 나타났다.

Conclusion: SpatialBench는 실제 공간 데이터 세트와 상호작용할 수 있는 에이전트를 개발하기 위한 측정 도구이자 진단 렌즈 역할을 한다.

Abstract: Spatial transcriptomics assays are rapidly increasing in scale and complexity, making computational analysis a major bottleneck in biological discovery. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world spatial datasets. We introduce SpatialBench, a benchmark of 146 verifiable problems derived from practical spatial analysis workflows spanning five spatial technologies and seven task categories. Each problem provides a snapshot of experimental data immediately prior to an analysis step and a deterministic grader that evaluates recovery of a key biological result. Benchmark data on frontier models shows that base model accuracy remains low (20-38% across model families), with strong model-task and model-platform interactions. Harness design has a large empirical effect on performance, indicating that tools, prompts, control flow, and execution environment should be evaluated and improved as first-class objects. SpatialBench serves both as a measurement tool and a diagnostic lens for developing agents that can interact with real spatial datasets faithfully, transparently, and reproducibly.

</details>
