<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 10]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN](https://arxiv.org/abs/2512.05122)
*Unnikrishnan Radhakrishnan*

Main category: cs.AI

TL;DR: 이 논문은 중소기업이 겪는 비공식적인 지식 관리 문제를 해결하기 위해 대화형 LLM 기반 도우미를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 중소기업은 경험 기반의 암묵적 지식에 의존하며, 이 지식은 공식 문서에 잘 반영되지 않습니다. 따라서 효율적인 지식 관리를 위한 방법이 필요합니다.

Method: Gemini 2.5 Pro를 활용하여 클라이언트 측 bpmn-js 시각화가 포함된 경량 Gradio 프론트-end를 통해 대화형 도우미를 제공합니다. 이 도우미는 인터뷰 스타일의 대화를 통해 프로세스 세부 정보와 명확화 대화를 이끌어내고, 실시간으로 수정 가능한 다이어그램을 생성합니다.

Result: 장비 유지보수 시나리오에서 수행된 개념 증명 평가에서 챗봇은 약 12분 내에 정확한 'AS-IS' 모델을 생성하고, 다이어그램 주석을 통해 문제를 표시하며 개선된 'TO-BE' 변형을 생성했습니다.

Conclusion: 대화형 LLM이 과정 문서화의 기술 및 비용 장벽을 낮출 수 있는 잠재력을 보여주며, 중소기업이 지식 보존, 운영 투명성 향상, 지속적 개선 노력을 가속화하는 데 도움을 줄 수 있습니다.

Abstract: Small and medium-sized enterprises (SMEs) still depend heavily on tacit, experience-based know-how that rarely makes its way into formal documentation. This paper introduces a large-language-model (LLM)-driven conversational assistant that captures such knowledge on the shop floor and converts it incrementally and interactively into standards-compliant Business Process Model and Notation (BPMN) 2.0 diagrams. Powered by Gemini 2.5 Pro and delivered through a lightweight Gradio front-end with client-side bpmn-js visualisation, the assistant conducts an interview-style dialogue: it elicits process details, supports clarifying dialogue and on-demand analysis, and renders live diagrams that users can refine in real time. A proof-of-concept evaluation in an equipment-maintenance scenario shows that the chatbot produced an accurate "AS-IS" model, flagged issues via on-diagram annotations, and generated an improved "TO-BE" variant, all within about 12-minutes, while keeping API costs within an SME-friendly budget. The study analyses latency sources, model-selection trade-offs, and the challenges of enforcing strict XML schemas, then outlines a roadmap toward agentic and multimodal deployments. The results demonstrate that conversational LLMs can potentially be used to lower the skill and cost barriers to rigorous process documentation, helping SMEs preserve institutional knowledge, enhance operational transparency, and accelerate continuous-improvement efforts.

</details>


### [2] [MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare](https://arxiv.org/abs/2512.05365)
*Zag ElSayed,Craig Erickson,Ernest Pedapati*

Main category: cs.AI

TL;DR: 본 논문은 Model Context Protocol(MCP)와 특정 임상 응용 프로그램을 결합하여, 전통적인 임상 의사 결정 지원 시스템(CDSS)과 대화형 대규모 언어 모델(LLM)에서 벗어난 새로운 AI 시스템 아키텍처 MCP-AI를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 의료 시스템이 점점 더 복잡해짐에 따라 자율적이고 문맥 인식이 가능한 임상 추론 프레임워크의 필요성이 절실해졌다.

Method: MCP-AI는 Model Context Protocol(MCP)을 기반으로 하여 실시간 워크플로우에서 생성형 및 설명형 AI 에이전트를 조정하기 위한 모듈형 실행 사양으로 구축된 설명 가능한 의료 의사결정 아키텍처다.

Result: MCP-AI는 Fragile X 증후군과 동반 우울증 진단 모델링 및 제2형 당뇨병과 고혈압에 대한 원격 조정 등 두 가지 사용 사례를 통해 검증되었으며, 의사 중심의 검증, 임상 프로세스의 간소화, AI 책임의 안전한 전환을 보장한다.

Conclusion: MCP-AI는 다가오는 임상 환경에서 해석 가능하고 조합 가능하며 안전 지향적인 AI를 위한 확장 가능한 기반을 제공한다.

Abstract: Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments.

</details>


### [3] [The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems](https://arxiv.org/abs/2512.05449)
*Robert Yang*

Main category: cs.AI

TL;DR: 대형 언어 모델은 정답을 알고 있지만 이를 행동으로 옮기지 않는 독특한 일관성 부족을 보여줍니다. 이는 인공지능 시스템의 불일치 및 목표 변화 분석에 대한 기본 개념으로 '약한 의지'를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 불일치 문제를 해결하고, 행위 및 목표 변화에 대한 분석을 수행하려는 필요성입니다.

Method: 약한 의지 개념을 바탕으로 한 Akrasia Benchmark를 도입하여 모델의 응답과 이전 약속 간의 모순을 측정하는 구조화된 프롬프트 조건을 설정했습니다.

Result: Benchmark는 모델 간의 '자기통제'를 정량적으로 비교할 수 있게 하며, 다중 에이전트 시스템에서의 미세 수준의 약한 의지가 거시적 불안정성으로 이어질 수 있음을 보여줍니다.

Conclusion: 불일치를 약한 의지로 재구성함으로써 이 연구는 에이전트적 행동과 고전적 에이전시 이론을 연결하고 철학, 심리학, 에이전트 AI 과학 간의 경험적 다리를 제공합니다.

Abstract: Large language models display a peculiar form of inconsistency: they "know" the correct answer but fail to act on it. In human philosophy, this tension between global judgment and local impulse is called akrasia, or weakness of will. We propose akrasia as a foundational concept for analyzing inconsistency and goal drift in agentic AI systems. To operationalize it, we introduce a preliminary version of the Akrasia Benchmark, currently a structured set of prompting conditions (Baseline [B], Synonym [S], Temporal [T], and Temptation [X]) that measures when a model's local response contradicts its own prior commitments. The benchmark enables quantitative comparison of "self-control" across model families, decoding strategies, and temptation types. Beyond single-model evaluation, we outline how micro-level akrasia may compound into macro-level instability in multi-agent systems that may be interpreted as "scheming" or deliberate misalignment. By reframing inconsistency as weakness of will, this work connects agentic behavior to classical theories of agency and provides an empirical bridge between philosophy, psychology, and the emerging science of agentic AI.

</details>


### [4] [KANFormer for Predicting Fill Probabilities via Survival Analysis in Limit Order Books](https://arxiv.org/abs/2512.05734)
*Jinfeng Zhong,Emmanuel Bacry,Agathe Guilloux,Jean-François Muzy*

Main category: cs.AI

TL;DR: KANFormer는 시장 및 에이전트 수준 정보를 활용하여 리미트 주문의 체결 시간을 예측하는 새로운 딥러닝 모델이다.


<details>
  <summary>Details</summary>
Motivation: 본 연구의 목적은 리미트 주문의 체결 시간을 보다 정확하게 예측하기 위해 시장 및 에이전트 수준의 정보를 통합하는 모델을 개발하는 것이다.

Method: KANFormer는 Dilated Causal Convolutional 네트워크와 Transformer 인코더를 결합하며, Kolmogorov-Arnold Networks(KANs)를 통해 비선형 근사화 능력을 향상시킨다.

Result: 모델 평가는 레이블이 있는 주문을 사용하여 CAC 40 지수 선물 데이터로 수행하였으며, KANFormer는 현재의 방법들과 비교하여 보정(우측 검열 로그 가능도, 통합 브라이어 점수) 및 구분(모델 적합도 지수, 시간 의존적 AUC) 모두에서 뛰어난 성능을 보였다.

Conclusion: 우리의 결과는 풍부한 시장 신호와 표현력이 뛰어난 신경망 구조를 결합하여 체결 확률을 정확하고 해석 가능한 방식으로 예측할 수 있는 이점을 강조한다.

Abstract: This paper introduces KANFormer, a novel deep-learning-based model for predicting the time-to-fill of limit orders by leveraging both market- and agent-level information. KANFormer combines a Dilated Causal Convolutional network with a Transformer encoder, enhanced by Kolmogorov-Arnold Networks (KANs), which improve nonlinear approximation. Unlike existing models that rely solely on a series of snapshots of the limit order book, KANFormer integrates the actions of agents related to LOB dynamics and the position of the order in the queue to more effectively capture patterns related to execution likelihood. We evaluate the model using CAC 40 index futures data with labeled orders. The results show that KANFormer outperforms existing works in both calibration (Right-Censored Log-Likelihood, Integrated Brier Score) and discrimination (C-index, time-dependent AUC). We further analyze feature importance over time using SHAP (SHapley Additive exPlanations). Our results highlight the benefits of combining rich market signals with expressive neural architectures to achieve accurate and interpretabl predictions of fill probabilities.

</details>


### [5] [CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning](https://arxiv.org/abs/2512.05576)
*Ting-Ting Xie,Yixin Zhang*

Main category: cs.AI

TL;DR: 이 논문에서는 Executor-Analyst Framework를 제안하여 임상 추론의 의미적 강인성과 도구 실행의 구문적 정밀성을 분리하고, TX Agents와 긴 문맥의 기초 모델을 조율하여 단일 모델의 추론 결함을 완화합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 소형 LLM에 기반한 임상 에이전트는 생물 의학 증거를 잘 검색하지만 그 정보를 기반으로 진단을 확립하는 데 실패합니다.

Method: Executor-Analyst Framework를 제안하고, 전문화된 TxAgents(Executors)와 긴 문맥의 기초 모델(Analysts)을 조율합니다.

Result: Stratified Ensemble 전략이 글로벌 풀링보다 유의미하게 우수한 성능을 발휘하며, 정보 병목현상을 효과적으로 해결합니다.

Conclusion: 훈련 없는 아키텍처 엔지니어링의 가능성을 강조하고, CURE-Bench에서 최첨단 성능을 달성합니다.

Abstract: Current clinical agent built on small LLMs, such as TxAgent suffer from a \textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.

</details>


### [6] [The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics](https://arxiv.org/abs/2512.05765)
*Edward Y. Chang*

Main category: cs.AI

TL;DR: 대규모 언어 모델(LLM)이 AGI에 도달하는 데 필익적이지 않다는 비판은 본질적으로 오해에서 비롯된다는 주장을 한다.


<details>
  <summary>Details</summary>
Motivation: 본 연구는 LLM이 AGI에 도달하는 데 있어 병목 현상을 잘못 인식하고 있다.

Method: LLM의 주요 병목 현상으로 시스템-1 패턴 저장소와 시스템-2 조정 층을 모델링하는 UCCT 이론을 사용하며, 이를 통해 MACI 아키텍처로 구현한다.

Result: 즉흥적으로 생성된 결과는 시스템의 최대 가능성 사전이 반영된 것으로, '추론'은 목표 지향적인 제약으로 후방을 전환함으로써 발생한다.

Conclusion: 우리는 LLM을 통해 AGI를 향한 길이 존재한다고 주장한다.

Abstract: Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: "mere pattern matchers" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while "reasoning" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.

</details>


### [7] [Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma](https://arxiv.org/abs/2512.05824)
*Hafsa Akebli,Adam Shephard,Vincenzo Della Mea,Nasir Rajpoot*

Main category: cs.AI

TL;DR: 이 연구는 저등급 교모세포종에서 IDH1 돌연변이를 예측하기 위한 다중모드 종양학 에이전트(MOA)를 도입하고, 임상 및 병리학적 기준을 초과하는 성과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 저등급 교모세포종에서 IDH1 돌연변이는 임상적으로 구분된 하위 그룹을 정의하며, 이는 특정한 예후 및 치료적 의미를 갖는다.

Method: 이 연구는 TITAN 기초 모델에 기반한 병리학 도구를 통합한 MOA를 도입하고, PubMed, Google Search, OncoKB를 통해 구조화된 임상 및 유전체 입력을 바탕으로 추론한다.

Result: TCGA-LGG 코호트의 488명의 환자에 대해 MOA는 임상 및 병리학 기준에 비해 F1 점수 0.826을 기록하며, 기준을 초과하였다. 병리학적 특징과 융합했을 때에는 F1 점수 0.912로 가장 높은 성과를 달성하여 병리학적 기준(0.894) 및 융합된 병리학-임상 기준(0.897)을 모두 초과하였다.

Conclusion: 이 결과는 제안된 에이전트가 외부 생물 의학 출처를 통해 보강된 보완적인 돌연변이 관련 정보를 캡처하며, 정확한 IDH1 돌연변이 예측을 가능하게 한다.

Abstract: Low-grade gliomas frequently present IDH1 mutations that define clinically distinct subgroups with specific prognostic and therapeutic implications. This work introduces a Multimodal Oncology Agent (MOA) integrating a histology tool based on the TITAN foundation model for IDH1 mutation prediction in low-grade glioma, combined with reasoning over structured clinical and genomic inputs through PubMed, Google Search, and OncoKB. MOA reports were quantitatively evaluated on 488 patients from the TCGA-LGG cohort against clinical and histology baselines. MOA without the histology tool outperformed the clinical baseline, achieving an F1-score of 0.826 compared to 0.798. When fused with histology features, MOA reached the highest performance with an F1-score of 0.912, exceeding both the histology baseline at 0.894 and the fused histology-clinical baseline at 0.897. These results demonstrate that the proposed agent captures complementary mutation-relevant information enriched through external biomedical sources, enabling accurate IDH1 mutation prediction.

</details>


### [8] [Using Large Language Models to Create Personalized Networks From Therapy Sessions](https://arxiv.org/abs/2512.05836)
*Clarissa W. Ong,Hiba Arnaout,Kate Sheehan,Estella Fox,Eugen Owtscharow,Iryna Gurevych*

Main category: cs.AI

TL;DR: 이 연구는 치료 과정에서 클라이언트 네트워크를 자동으로 생성하는 파이프라인을 제시하며, 치료 계획 및 개념화를 지원합니다.


<details>
  <summary>Details</summary>
Motivation: 정신 치료에서 치료 개인화가 중요해지고 있지만, 개인화된 네트워크 추정에는 장기적인 데이터가 필요하여 접근이 어려운 경우가 많습니다.

Method: 77개의 치료 전사에서 클라이언트 네트워크를 자동으로 생성하는 엔드 투 엔드 파이프라인을 활용하여 심리적 과정과 차원을 식별하기 위해 인컨텍스트 학습을 적용했습니다.

Result: 우리의 방법은 몇 가지 훈련 예제에도 불구하고 높은 성능을 달성했으며, 전문가들은 생성된 네트워크의 유용성과 해석 가능성을 높게 평가했습니다.

Conclusion: LLMs를 사용하여 치료 전사에서 임상적으로 관련된 네트워크를 생성할 수 있음을 보여주는 개념 증거를 제공합니다.

Abstract: Recent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalability of network-driven treatment personalization is leveraging LLMs. In this study, we present an end-to-end pipeline for automatically generating client networks from 77 therapy transcripts to support case conceptualization and treatment planning. We annotated 3364 psychological processes and their corresponding dimensions in therapy transcripts. Using these data, we applied in-context learning to jointly identify psychological processes and their dimensions. The method achieved high performance even with a few training examples. To organize the processes into networks, we introduced a two-step method that grouped them into clinically meaningful clusters. We then generated explanation-augmented relationships between clusters. Experts found that networks produced by our multi-step approach outperformed those built with direct prompting for clinical utility and interpretability, with up to 90% preferring our approach. In addition, the networks were rated favorably by experts, with scores for clinical relevance, novelty, and usefulness ranging from 72-75%. Our findings provide a proof of concept for using LLMs to create clinically relevant networks from therapy transcripts. Advantages of our approach include bottom-up case conceptualization from client utterances in therapy sessions and identification of latent themes. Networks generated from our pipeline may be used in clinical settings and supervision and training. Future research should examine whether these networks improve treatment outcomes relative to other methods of treatment personalization, including statistically estimated networks.

</details>


### [9] [PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation](https://arxiv.org/abs/2512.05930)
*Shima Imani,Seungwhan Moon,Adel Ahmadyan,Lu Zhang,Kirmani Ahmed,Babak Damavandi*

Main category: cs.AI

TL;DR: PRiSM은 과학적 추론을 평가하기 위해 24,750개 이상의 물리학 및 수학 문제와 함께 다이나믹 벤치마크를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 과학적 분야에서 비전-언어 모델(VLM)을 평가하는 것은 최종 답변을 예측하는 것을 넘어서는 독특한 도전 과제가 있다.

Method: PRiSM은 동적 텍스트와 시각적 입력, 생성된 도표 및 구조화된 출력을 포함하는 다이나믹한 벤치마크이다.

Result: PRiSM을 통해 기존 VLM의 한계를 강조하고, 과학적 추론 능력에 대한 깊은 통찰력을 제공한다.

Conclusion: PRiSM은 과학적 이해를 요구하는 VLM의 평가와 연구에 유용한 도구가 될 것이다.

Abstract: Evaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.

</details>


### [10] [SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code](https://arxiv.org/abs/2512.05954)
*Shima Imani,Seungwhan Moon,Adel Ahmadyan,Lu Zhang,Kirmani Ahmed,Babak Damavandi*

Main category: cs.AI

TL;DR: 15,045개의 대학 수준 물리학 문제로 구성된 대규모 합성 벤치마크를 소개하며, 다양한 질문 형식과 평가 지표를 통해 과학적 추론 능력을 측정한다.


<details>
  <summary>Details</summary>
Motivation: 대학 수준의 물리학 문제에 대한 과학적 추론 능력을 평가하고, 이를 위한 통합된 벤치마크를 제공하기 위해서이다.

Method: 전체 매개변수화된 문제를 통해 무한한 입력 구성 범위를 지원하며, 단계별 추론과 실행 가능한 Python 코드를 제공한다. 문제는 세 가지 질문 유형(MC-기호, MC-수치, 자유 형식)으로 구성되어 있다.

Result: 최신 지침 조정 언어 모델을 이용한 실험 결과, 과학적 추론에서의 강점과 한계를 드러내며, SymPyBench가 강력하고 해석 가능한 추론 시스템 개발의 기초가 됨을 보여준다.

Conclusion: SymPyBench는 다양하고 강력한 평가 지표와 함께 과학적 추론 능력을 향상시키기 위한 기초를 제공한다.

Abstract: We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [11] [Distributed scalable coupled policy algorithm for networked multi-agent reinforcement learning](https://arxiv.org/abs/2512.05447)
*Pengcheng Dai,Dongming Wang,Wenwu Yu,Wei Ren*

Main category: cs.MA

TL;DR: 이 논문은 상호 의존적인 보상과 결합된 정책을 가진 네트워크 다중 에이전트 강화 학습(NMARL)을 연구한다.


<details>
  <summary>Details</summary>
Motivation: 협력 최적화에서의 상호 의존적인 정책 문제를 해결하기 위함이다.

Method: Neighbors' averaged Q-function 개념을 도입하고 새로운 결합 정책 기울기 표현을 유도한 후 분산 확장 가능한 결합 정책(DSCP) 알고리즘을 개발한다.

Result: 제안된 알고리즘에서 생성된 결합 정책이 목적 함수의 1차 정지점으로 수렴함을 증명하였다.

Conclusion: 로봇 경로 계획 환경에서 시뮬레이션을 통해 DSCP 알고리즘의 효과를 입증하였고, 최신 방법들에 비해 명확한 개선을 보였다.

Abstract: This paper studies networked multi-agent reinforcement learning (NMARL) with interdependent rewards and coupled policies. In this setting, each agent's reward depends on its own state-action pair as well as those of its direct neighbors, and each agent's policy is parameterized by its local parameters together with those of its $κ_{p}$-hop neighbors, with $κ_{p}\geq 1$ denoting the coupled radius. The objective of the agents is to collaboratively optimize their policies to maximize the discounted average cumulative reward. To address the challenge of interdependent policies in collaborative optimization, we introduce a novel concept termed the neighbors' averaged $Q$-function and derive a new expression for the coupled policy gradient. Based on these theoretical foundations, we develop a distributed scalable coupled policy (DSCP) algorithm, where each agent relies only on the state-action pairs of its $κ_{p}$-hop neighbors and the rewards its their $(κ_{p}+1)$-hop neighbors. Specially, in the DSCP algorithm, we employ a geometric 2-horizon sampling method that does not require storing a full $Q$-table to obtain an unbiased estimate of the coupled policy gradient. Moreover, each agent interacts exclusively with its direct neighbors to obtain accurate policy parameters, while maintaining local estimates of other agents' parameters to execute its local policy and collect samples for optimization. These estimates and policy parameters are updated via a push-sum protocol, enabling distributed coordination of policy updates across the network. We prove that the joint policy produced by the proposed algorithm converges to a first-order stationary point of the objective function. Finally, the effectiveness of DSCP algorithm is demonstrated through simulations in a robot path planning environment, showing clear improvement over state-of-the-art methods.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [Please Don't Kill My Vibe: Empowering Agents with Data Flow Control](https://arxiv.org/abs/2512.05374)
*Charlie Summers,Haneen Mohammed,Eugene Wu*

Main category: cs.CR

TL;DR: Large Language Model (LLM) 에이전트의 약속은 복잡한 상태적 작업을 수행하는 것이다. 그러나 정책 위반, 프로세스 손상, 보안 결함과 같은 상당한 위험으로 인해 이 약속이 제한되고 있다. 이 논문은 DBMS에서 DFC(DIPC) 이동 가능한 인스턴스를 개발하는 초기 작업을 설명하고 에이전트 생태계를 위한 DFC를 향한 더 넓은 연구 의제를 제시한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 복잡한 상태적 작업을 수행할 수 있도록 하는 가능성이 있지만, 정책 위반, 프로세스 손상 및 보안 결함과 같은 위험이 존재한다.

Method: 이 논문에서는 DBMS를 위한 DFC의 이동 가능한 인스턴스를 개발하는 초기 작업을 설명한다.

Result: DBMS를 통한 데이터 흐름 제어의 필요성을 강조하고, 에이전트 생태계를 위한 DFC 정책 강 제 시는 방법을 제안한다.

Conclusion: 시스템이 데이터 흐름 제어를 지원하고 DFC 정책을 본질적으로 시행해야 한다고 주장한다.

Abstract: The promise of Large Language Model (LLM) agents is to perform complex, stateful tasks. This promise is stunted by significant risks - policy violations, process corruption, and security flaws - that stem from the lack of visibility and mechanisms to manage undesirable data flows produced by agent actions. Today, agent workflows are responsible for enforcing these policies in ad hoc ways. Just as data validation and access controls shifted from the application to the DBMS, freeing application developers from these concerns, we argue that systems should support Data Flow Controls (DFCs) and enforce DFC policies natively. This paper describes early work developing a portable instance of DFC for DBMSes and outlines a broader research agenda toward DFC for agent ecosystems.

</details>


### [13] [Trusted AI Agents in the Cloud](https://arxiv.org/abs/2512.05951)
*Teofil Bodea,Masanori Misono,Julian Pritzi,Patrick Sabanic,Thore Sommer,Harshavardhan Unnibhavi,David Schall,Nuno Santos,Dimitrios Stavrakakis,Pramod Bhatotia*

Main category: cs.CR

TL;DR: AI 에이전트를 위한 안전한 플랫폼인 Omega는 데이터 보호와 규제 준수를 위해 자동화된 데이터 접근, 외부 도구 호출, 상호작용을 안전하게 관리한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 민감한 데이터에 접근하고 외부 도구와 상호작용하는 복잡한 다자간 생태계에서 발생할 수 있는 데이터 유출 및 변조를 방지하고자 했다.

Method: Omega는 엔드 투 엔드 격리를 적용하고, 모든 관련 주체 간의 검증 가능한 신뢰를 수립하며, 외부 상호작용을 책임 있게 감독하여 신뢰할 수 있는 AI 에이전트를 구현한다.

Result: Omega는 Confidential VMs 및 Confidential GPUs를 기반으로 하여 신뢰할 수 있는 에이전트를 호스팅하는 플랫폼을 생성하고, 차등 증명을 통해 다자간 신뢰를 구축하며, 데이터 접근 및 도구 사용을 관리하는 정책 제정 및 이행 프레임워크를 제공한다.

Conclusion: Omega는 클라우드 규모의 고밀도 멀티 에이전트 배포를 가능하게 하면서 높은 성능을 달성하고, CVM-GPU 간 에이전트 상태를 완전히 보호한다.

Abstract: AI agents powered by large language models are increasingly deployed as cloud services that autonomously access sensitive data, invoke external tools, and interact with other agents. However, these agents run within a complex multi-party ecosystem, where untrusted components can lead to data leakage, tampering, or unintended behavior. Existing Confidential Virtual Machines (CVMs) provide only per binary protection and offer no guarantees for cross-principal trust, accelerator-level isolation, or supervised agent behavior. We present Omega, a system that enables trusted AI agents by enforcing end-to-end isolation, establishing verifiable trust across all contributing principals, and supervising every external interaction with accountable provenance. Omega builds on Confidential VMs and Confidential GPUs to create a Trusted Agent Platform that hosts many agents within a single CVM using nested isolation. It also provides efficient multi-agent orchestration with cross-principal trust establishment via differential attestation, and a policy specification and enforcement framework that governs data access, tool usage, and inter-agent communication for data protection and regulatory compliance. Implemented on AMD SEV-SNP and NVIDIA H100, Omega fully secures agent state across CVM-GPU, and achieves high performance while enabling high-density, policy-compliant multi-agent deployments at cloud scale.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [When unlearning is free: leveraging low influence points to reduce computational costs](https://arxiv.org/abs/2512.05254)
*Anat Kleiman,Robert Fisher,Ben Deaner,Udi Wieder*

Main category: cs.LG

TL;DR: 데이터 프라이버시 우려가 커짐에 따라, 기계 학습 모델에서 특정 데이터를 제거하는 능력이 중요해지고 있다. 본 연구에서는 영향이 미미한 데이터 포인트를 제거할 필요가 있는지를 질문하며, 효율적인 언러닝 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습에서 데이터 프라이버시 문제에 대한 우려가 커지고 있다.

Method: 비교 분석을 통해 모델 출력에 미미한 영향을 미치는 훈련 데이터의 하위 집합을 식별하고, 이를 바탕으로 효율적인 언러닝 프레임워크를 제안한다.

Result: 현실 세계의 실증 사례에서 데이터셋 크기를 줄임으로써 최대 약 50%의 계산 절약을 달성한다.

Conclusion: 모델의 학습에 미미한 영향을 미치는 데이터 포인트는 제거할 필요가 없다는 저자들의 주장을 통해, 더욱 효율적인 언러닝 방법을 제시한다.

Abstract: As concerns around data privacy in machine learning grow, the ability to unlearn, or remove, specific data points from trained models becomes increasingly important. While state of the art unlearning methods have emerged in response, they typically treat all points in the forget set equally. In this work, we challenge this approach by asking whether points that have a negligible impact on the model's learning need to be removed. Through a comparative analysis of influence functions across language and vision tasks, we identify subsets of training data with negligible impact on model outputs. Leveraging this insight, we propose an efficient unlearning framework that reduces the size of datasets before unlearning leading to significant computational savings (up to approximately 50 percent) on real world empirical examples.

</details>


### [15] [The Erosion of LLM Signatures: Can We Still Distinguish Human and LLM-Generated Scientific Ideas After Iterative Paraphrasing?](https://arxiv.org/abs/2512.05311)
*Sadat Shahriar,Navid Ayoobi,Arjun Mukherjee*

Main category: cs.LG

TL;DR: 연구 에이전트로서 LLM에 대한 의존도가 증가함에 따라, LLM과 인간이 생성한 아이디어를 구별하는 것이 중요해졌다. 본 연구는 LLM과 인간이 생성한 과학 아이디어를 구별하는 현시점의 머신러닝 모델들을 체계적으로 평가했다.


<details>
  <summary>Details</summary>
Motivation: LLM의 연구 능력에 대한 인지적 뉘앙스를 이해하기 위해 인간과 LLM이 생성한 아이디어 간의 구별이 필요하다.

Method: 최신 머신러닝 모델을 사용하여 인간과 LLM 생성 아이디어를 차별화하는 능력을 평가하고, 특히 연속적인 패러프레이징 단계 후 차이를 분석했다.

Result: 다섯 번의 연속적인 패러프레이징 단계 후 검출 성능이 평균 25.4% 감소했으며, 연구 문제를 맥락 정보로 포함할 경우 성능이 최대 2.97% 향상됐다.

Conclusion: 아이디어가 단순화된 비전문가 스타일로 패러프레이징될 때 검출 알고리즘이 큰 어려움을 겪으며, 이는 LLM의 구별 가능한 서명을 가장 크게 저하시킴을 확인했다.

Abstract: With the increasing reliance on LLMs as research agents, distinguishing between LLM and human-generated ideas has become crucial for understanding the cognitive nuances of LLMs' research capabilities. While detecting LLM-generated text has been extensively studied, distinguishing human vs LLM-generated scientific idea remains an unexplored area. In this work, we systematically evaluate the ability of state-of-the-art (SOTA) machine learning models to differentiate between human and LLM-generated ideas, particularly after successive paraphrasing stages. Our findings highlight the challenges SOTA models face in source attribution, with detection performance declining by an average of 25.4\% after five consecutive paraphrasing stages. Additionally, we demonstrate that incorporating the research problem as contextual information improves detection performance by up to 2.97%. Notably, our analysis reveals that detection algorithms struggle significantly when ideas are paraphrased into a simplified, non-expert style, contributing the most to the erosion of distinguishable LLM signatures.

</details>


### [16] [RevoNAD: Reflective Evolutionary Exploration for Neural Architecture Design](https://arxiv.org/abs/2512.05403)
*Gyusam Chang,Jeongyoon Yoon,Shin han yi,JaeHyeok Lee,Sujin Jang,Sangpil Kim*

Main category: cs.LG

TL;DR: RevoNAD는 LLM 기반 추론과 피드백 정렬 건축 탐색을 결합하여 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: LLM을 활용하여 새로운 건축을 생성할 수 있지만, 토큰 수준의 설계 루프가 이산적이고 미분 불가능하여 피드백이 건축 개선에 원활하게 기여하지 못하는 문제를 해결할 필요가 있습니다.

Method: RevoNAD는 격리된 설계 규칙을 의미 있는 건축 단서로 전환하는 다중 라운드 다중 전문가 합의를 제시하고, 보상 변화를 활용하여 탐험 정도를 조정하는 적응형 반사 탐사를 수행합니다.

Result: RevoNAD는 CIFAR10, CIFAR100, ImageNet16-120, COCO-5K, Cityscape에서 최첨단 성능을 달성했습니다.

Conclusion: RevoNAD의 효과는 실제로 신뢰할 수 있고 배포 가능한 신경 건축 설계를 가능하게 하는데 기여합니다.

Abstract: Recent progress in leveraging large language models (LLMs) has enabled Neural Architecture Design (NAD) systems to generate new architecture not limited from manually predefined search space. Nevertheless, LLM-driven generation remains challenging: the token-level design loop is discrete and non-differentiable, preventing feedback from smoothly guiding architectural improvement. These methods, in turn, commonly suffer from mode collapse into redundant structures or drift toward infeasible designs when constructive reasoning is not well grounded. We introduce RevoNAD, a reflective evolutionary orchestrator that effectively bridges LLM-based reasoning with feedback-aligned architectural search. First, RevoNAD presents a Multi-round Multi-expert Consensus to transfer isolated design rules into meaningful architectural clues. Then, Adaptive Reflective Exploration adjusts the degree of exploration leveraging reward variance; it explores when feedback is uncertain and refines when stability is reached. Finally, Pareto-guided Evolutionary Selection effectively promotes architectures that jointly optimize accuracy, efficiency, latency, confidence, and structural diversity. Across CIFAR10, CIFAR100, ImageNet16-120, COCO-5K, and Cityscape, RevoNAD achieves state-of-the-art performance. Ablation and transfer studies further validate the effectiveness of RevoNAD in allowing practically reliable, and deployable neural architecture design.

</details>


### [17] [How Ensemble Learning Balances Accuracy and Overfitting: A Bias-Variance Perspective on Tabular Data](https://arxiv.org/abs/2512.05469)
*Zubair Ahmed Mohammad*

Main category: cs.LG

TL;DR: 앙상블 모델은 단일 학습자보다 높은 정확도를 달성하지만, 일반화 격차를 유지하는 능력은 명확히 이해되지 않았다. 본 연구는 네 가지 테이블 분류 작업에 걸쳐 앙상블이 정확도와 과적합을 어떻게 조정하는지 조사한다.


<details>
  <summary>Details</summary>
Motivation: 앙상블 모델의 높은 정확도와 작은 일반화 격차 유지 능력에 대한 이해 부족.

Method: 반복적인 계층화 교차 검증과 통계적 유의성 검정을 통해 선형 모델, 단일 결정 트리, 아홉 가지 앙상블 방법을 비교한다.

Result: 앙상블은 평균화 또는 조절된 부스팅을 통해 분산을 줄여서 높은 정확도를 유지하며, 비선형 구조가 있는 데이터셋에서 테스트 정확도를 5~7포인트 증가시킨다.

Conclusion: 본 연구는 앙상블이 높은 정확도를 유지하면서 과적합을 낮추는 방법과 시기를 명확히 제시하여 실제 테이블 응용 프로그램에서 모델 선택에 유용한 지침을 제공한다.

Abstract: Ensemble models often achieve higher accuracy than single learners, but their ability to maintain small generalization gaps is not always well understood. This study examines how ensembles balance accuracy and overfitting across four tabular classification tasks: Breast Cancer, Heart Disease, Pima Diabetes, and Credit Card Fraud. Using repeated stratified cross validation with statistical significance testing, we compare linear models, a single decision tree, and nine ensemble methods. The results show that ensembles can reach high accuracy without large gaps by reducing variance through averaging or controlled boosting. On nearly linear and clean data, linear models already generalize well and ensembles offer little additional benefit. On datasets with meaningful nonlinear structure, tree based ensembles increase test accuracy by 5 to 7 points while keeping gaps below 3 percent. On noisy or highly imbalanced datasets, ensembles remain competitive but require regularization to avoid fitting noise or majority class patterns. We also compute simple dataset complexity indicators, such as linearity score, Fisher ratio, and noise estimate, which explain when ensembles are likely to control variance effectively. Overall, the study provides a clear view of how and when ensembles maintain high accuracy while keeping overfitting low, offering practical guidance for model selection in real world tabular applications.

</details>


### [18] [GRASP: Graph Reasoning Agents for Systems Pharmacology with Human-in-the-Loop](https://arxiv.org/abs/2512.05502)
*Omid Bazgir,Vineeth Manthapuri,Ilia Rattsev,Mohammad Jafarnejad*

Main category: cs.LG

TL;DR: 이 논문에서는 QSP 모델 개발을 위한 새로운 프레임워크인 GRASP를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: QSP 모델링은 약물 개발에 필수적이나, 많은 시간 투자로 인해 도메인 전문가의 처리량이 제한됩니다.

Method: GRASP는 다중 에이전트 기반의 그래프 추론 프레임워크로, QSP 모델을 입력받아 생물학적 지식 그래프로 변환 후 실행 가능한 MATLAB/SimBiology 코드로 컴파일 합니다.

Result: GRASP는 생물학적 그럴듯함, 수학적 정확성, 구조적 충실도 및 코드 품질 면에서 SME-guided CoT 및 ToT 기준선을 능가하였습니다.

Conclusion: 이 결과는 그래프 구조의 에이전트적 워크플로우가 QSP 모델 개발을 더 접근 가능하고 철저하게 만들 수 있음을 입증합니다.

Abstract: Quantitative Systems Pharmacology (QSP) modeling is essential for drug development but it requires significant time investment that limits the throughput of domain experts. We present \textbf{GRASP} -- a multi-agent, graph-reasoning framework with a human-in-the-loop conversational interface -- that encodes QSP models as typed biological knowledge graphs and compiles them to executable MATLAB/SimBiology code while preserving units, mass balance, and physiological constraints. A two-phase workflow -- \textsc{Understanding} (graph reconstruction of legacy code) and \textsc{Action} (constraint-checked, language-driven modification) -- is orchestrated by a state machine with iterative validation. GRASP performs breadth-first parameter-alignment around new entities to surface dependent quantities and propose biologically plausible defaults, and it runs automatic execution/diagnostics until convergence. In head-to-head evaluations using LLM-as-judge, GRASP outperforms SME-guided CoT and ToT baselines across biological plausibility, mathematical correctness, structural fidelity, and code quality (\(\approx\)9--10/10 vs.\ 5--7/10). BFS alignment achieves F1 = 0.95 for dependency discovery, units, and range. These results demonstrate that graph-structured, agentic workflows can make QSP model development both accessible and rigorous, enabling domain experts to specify mechanisms in natural language without sacrificing biomedical fidelity.

</details>


### [19] [Towards agent-based-model informed neural networks](https://arxiv.org/abs/2512.05764)
*Nino Antulov-Fantulin*

Main category: cs.LG

TL;DR: 이 논문에서는 에이전트 기반 모델의 원리에 일치하는 신경망 설계를 위한 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 표준 신경 미분 방정식의 한계를 강조하고, 복잡한 시스템 모델링에 필요한 물리적 불변량의 결여와 여러 제약 조건의 필요성을 언급합니다.

Method: 제한된 그래프 신경망과 계층적 분해를 활용하여 명확하고 구조를 보존하는 역학을 학습하는 에이전트 기반 모델 정보 신경망(ABM-NNs)을 도입합니다.

Result: 세 가지 증가하는 복잡성의 사례 연구를 통해 프레임워크를 검증하며, 여기에는 개입이 있는 짧은 궤적에서 실제 파라미터를 복구하는 일반화된 로트카-볼테라 시스템, 샘플 외 예측 및 노이즈 강건성에서 최첨단 그래프 학습 기반선과 비교하여 우수한 성능을 보이는 그래프 기반 SIR 전염 모델, 실증 데이터로부터 결합된 GDP 역학을 학습하고 정책 개입을 위한 경량 기반 반사실 분석을 시연하는 현실 세계의 거시 경제 모델이 포함됩니다.

Conclusion: 이 프레임워크는 복잡한 시스템의 역학을 학습하는 데 있어 유용하며 정책 개입에 대한 심층 분석을 가능하게 합니다.

Abstract: In this article, we present a framework for designing neural networks that remain consistent with the underlying principles of agent-based models. We begin by highlighting the limitations of standard neural differential equations in modeling complex systems, where physical invariants (like energy) are often absent but other constraints (like mass conservation, network locality, bounded rationality) must be enforced. To address this, we introduce Agent-Based-Model informed Neural Networks(ABM-NNs), which leverage restricted graph neural networks and hierarchical decomposition to learn interpretable, structure-preserving dynamics. We validate the framework across three case studies of increasing complexity: (i) a generalized Generalized Lotka--Volterra system, where we recover ground-truth parameters from short trajectories in presence of interventions; (ii) a graph-based SIR contagion model, where our method outperforms state-of-the-art graph learning baselines (GCN, GraphSAGE, Graph Transformer) in out-of-sample forecasting and noise robustness; and (iii) a real-world macroeconomic model of the ten largest economies, where we learn coupled GDP dynamics from empirical data and demonstrate gradient-based counterfactual analysis for policy interventions.

</details>
