<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 18]
- [cs.CR](#cs.CR) [Total: 6]
- [cs.LG](#cs.LG) [Total: 13]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The High Cost of Incivility: Quantifying Interaction Inefficiency via Multi-Agent Monte Carlo Simulations](https://arxiv.org/abs/2512.08345)
*Benedikt Mangold*

Main category: cs.AI

TL;DR: 이 연구는 직장 내 독성이 운영 효율성에 미치는 영향을 측정하기 위해 대규모 언어 모델 기반의 다중 에이전트 시스템을 활용하여 1대1의 적대적 토론을 시뮬레이션합니다.


<details>
  <summary>Details</summary>
Motivation: 직장 내 독성이 조직 문화에 해롭지만, 인간 피험자에서 갈등을 재현하는 윤리적 및 실용적 어려움 때문에 그 직접적인 영향을 정량화하기가 어렵습니다.

Method: 대규모 언어 모델 기반의 다중 에이전트 시스템을 활용하여 1대1 적대적 토론을 시뮬레이션하고, 몬테카를로 방법을 사용하여 수백 개의 논의를 시뮬레이션합니다.

Result: 독성이 있는 참가자가 포함된 대화에서 약 25%의 지속 시간이 통계적으로 유의미하게 증가했습니다.

Conclusion: 이 '독성의 지연'이 기업 및 학술 환경에서 재정적 손상의 지표로 작용할 수 있음을 제안합니다. 또한, 에이전트 기반 모델링이 사회적 마찰의 메커니즘을 측정하기 위한 인간 피험자 연구의 재현 가능하고 윤리적인 대안을 제공함을 보여줍니다.

Abstract: Workplace toxicity is widely recognized as detrimental to organizational culture, yet quantifying its direct impact on operational efficiency remains methodologically challenging due to the ethical and practical difficulties of reproducing conflict in human subjects. This study leverages Large Language Model (LLM) based Multi-Agent Systems to simulate 1-on-1 adversarial debates, creating a controlled "sociological sandbox". We employ a Monte Carlo method to simulate hundrets of discussions, measuring the convergence time (defined as the number of arguments required to reach a conclusion) between a baseline control group and treatment groups involving agents with "toxic" system prompts. Our results demonstrate a statistically significant increase of approximately 25\% in the duration of conversations involving toxic participants. We propose that this "latency of toxicity" serves as a proxy for financial damage in corporate and academic settings. Furthermore, we demonstrate that agent-based modeling provides a reproducible, ethical alternative to human-subject research for measuring the mechanics of social friction.

</details>


### [2] [Multi-Agent Intelligence for Multidisciplinary Decision-Making in Gastrointestinal Oncology](https://arxiv.org/abs/2512.08674)
*Rongzhao Zhang,Junqiao Wang,Shuyun Yang,Mouxiao Bian,Chao Ding,Yuwei Bai,Chihao Zhang,Yuguang Shen,Lei Wang,Lei Zheng,Qiujuan Yan,Yun Zhong,Meiling Liu,Jiwei Yu,Zheng Wang,Jie Xu,Meng Luo*

Main category: cs.AI

TL;DR: 이 논문은 위장 관 지방종양 분야에서 다중 모드 임상 추론을 위한 새로운 계층적 다중 에이전트 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 의료 데이터의 통합 해석이 필요한 gastrointestinal oncology에서 다중 모드 임상 추론의 필요성이 제기됨.

Method: 인간 다학제 팀(MDT)의 협업 워크플로우를 모방한 계층적 Multi-Agent Framework를 제안함.

Result: 시스템은 4.60/5.00의 복합 전문가 평가 점수를 기록하며, 단일형 기준선을 크게 초과함.

Conclusion: 모방적인 에이전트 기반 협업이 종양학에서의 자동화된 의사 결정을 위한 확장 가능하고 해석 가능한 견고한 패러다임을 제공한다는 것을 발견함.

Abstract: Multimodal clinical reasoning in the field of gastrointestinal (GI) oncology necessitates the integrated interpretation of endoscopic imagery, radiological data, and biochemical markers. Despite the evident potential exhibited by Multimodal Large Language Models (MLLMs), they frequently encounter challenges such as context dilution and hallucination when confronted with intricate, heterogeneous medical histories. In order to address these limitations, a hierarchical Multi-Agent Framework is proposed, which emulates the collaborative workflow of a human Multidisciplinary Team (MDT). The system attained a composite expert evaluation score of 4.60/5.00, thereby demonstrating a substantial improvement over the monolithic baseline. It is noteworthy that the agent-based architecture yielded the most substantial enhancements in reasoning logic and medical accuracy. The findings indicate that mimetic, agent-based collaboration provides a scalable, interpretable, and clinically robust paradigm for automated decision support in oncology.

</details>


### [3] [Can AI autonomously build, operate, and use the entire data stack?](https://arxiv.org/abs/2512.07926)
*Arvind Agarwal,Lisa Amini,Sameep Mehta,Horst Samulowitz,Kavitha Srinivas*

Main category: cs.AI

TL;DR: 효율적인 데이터 관리를 위한 AI 주도의 자율 데이터 시스템을 강조.


<details>
  <summary>Details</summary>
Motivation: 현재 데이터 관리의 복잡성과 비효율성을 해결하기 위한 AI의 활용 가능성.

Method: 데이터 라이프 사이클의 각 단계를 지능적인 에이전트가 자율적으로 관리하는 방법 탐색.

Result: AI가 전체 데이터 라이프사이클을 자율적으로 다룰 수 있다는 주장과 함께 이를 가능하게 하는 방법 제시.

Conclusion: 데이터 시스템의 자율성을 향상시키기 위한 대화 촉진 및 협력적 접근 권장.

Abstract: Enterprise data management is a monumental task. It spans data architecture and systems, integration, quality, governance, and continuous improvement. While AI assistants can help specific persona, such as data engineers and stewards, to navigate and configure the data stack, they fall far short of full automation. However, as AI becomes increasingly capable of tackling tasks that have previously resisted automation due to inherent complexities, we believe there is an imminent opportunity to target fully autonomous data estates. Currently, AI is used in different parts of the data stack, but in this paper, we argue for a paradigm shift from the use of AI in independent data component operations towards a more holistic and autonomous handling of the entire data lifecycle. Towards that end, we explore how each stage of the modern data stack can be autonomously managed by intelligent agents to build self-sufficient systems that can be used not only by human end-users, but also by AI itself. We begin by describing the mounting forces and opportunities that demand this paradigm shift, examine how agents can streamline the data lifecycle, and highlight open questions and areas where additional research is needed. We hope this work will inspire lively debate, stimulate further research, motivate collaborative approaches, and facilitate a more autonomous future for data systems.

</details>


### [4] [Towards Foundation Models with Native Multi-Agent Intelligence](https://arxiv.org/abs/2512.08743)
*Shuyue Hu,Haoyang Yan,Yiqun Zhang,Yang Chen,Dongzhan Zhou,Lei Bai*

Main category: cs.AI

TL;DR: 기초 모델(FM)이 AI 에이전트의 '두뇌' 역할을 맡고 있으며, 다중 에이전트 지능을 내재화하는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트에 대한 FM의 능력 향상 필요성.

Method: 41개의 대형 언어 모델에 대한 실증적 증거 제공.

Result: 강력한 단일 에이전트 성능이 반드시 다중 에이전트 지능으로 이어지지 않음을 보여준다.

Conclusion: FM의 다중 에이전트 지능 구축을 위한 연구 방향 제시.

Abstract: Foundation models (FMs) are increasingly assuming the role of the "brain" of AI agents. While recent efforts have begun to equip FMs with native single-agent abilities -- such as GUI interaction or integrated tool use -- we argue that the next frontier is endowing FMs with native multi-agent intelligence. We identify four core capabilities of FMs in multi-agent contexts: understanding, planning, efficient communication, and adaptation. Contrary to assumptions about the spontaneous emergence of such abilities, we provide extensive empirical evidence across 41 large language models showing that strong single-agent performance alone does not automatically yield robust multi-agent intelligence. To address this gap, we outline key research directions -- spanning dataset construction, evaluation, training paradigms, and safety considerations -- for building FMs with native multi-agent intelligence.

</details>


### [5] [Toward an AI Reasoning-Enabled System for Patient-Clinical Trial Matching](https://arxiv.org/abs/2512.08026)
*Caroline N. Leach,Mitchell A. Klusty,Samuel E. Armstrong,Justine C. Pickarski,Kristen L. Hankins,Emily B. Collier,Maya Shah,Aaron D. Mullen,V. K. Cody Bumgardner*

Main category: cs.AI

TL;DR: AI를 활용한 임상 시험 자격 검사 시스템을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 임상 시험 자격 검사 과정이 수작업이며 시간 소모가 크고 자원을 많이 요구하기 때문에, 이를 개선할 필요가 있습니다.

Method: 이 시스템은 이질적인 전자 건강 기록(EHR) 데이터를 통합하고 전문가 검토를 용이하게 하며 엄격한 보안 기준을 유지하는 것을 목표로 합니다. 오픈 소스 대형 언어 모델을 활용하여, 이 시스템은 이진 분류를 넘어 구조화된 자격 평가를 생성합니다.

Result: 사람이 검토할 수 있도록 해석 가능한 추론 체인을 지원하며, 동적인 자격 상태를 나타내고 미래에 환자가 자격을 가질 수 있는 행동 가능한 권장 사항을 제공합니다.

Conclusion: 이 시스템은 코디네이터의 부담을 줄이고 각 환자에 대해 고려되는 시험의 범위를 지능적으로 넓히며 모든 AI 생성 출력의 포괄적인 감사 가능성을 보장합니다.

Abstract: Screening patients for clinical trial eligibility remains a manual, time-consuming, and resource-intensive process. We present a secure, scalable proof-of-concept system for Artificial Intelligence (AI)-augmented patient-trial matching that addresses key implementation challenges: integrating heterogeneous electronic health record (EHR) data, facilitating expert review, and maintaining rigorous security standards. Leveraging open-source, reasoning-enabled large language models (LLMs), the system moves beyond binary classification to generate structured eligibility assessments with interpretable reasoning chains that support human-in-the-loop review. This decision support tool represents eligibility as a dynamic state rather than a fixed determination, identifying matches when available and offering actionable recommendations that could render a patient eligible in the future. The system aims to reduce coordinator burden, intelligently broaden the set of trials considered for each patient and guarantee comprehensive auditability of all AI-generated outputs.

</details>


### [6] [Empowerment Gain and Causal Model Construction: Children and adults are sensitive to controllability and variability in their causal interventions](https://arxiv.org/abs/2512.08230)
*Eunice Yiu,Kelsey Allen,Shiry Ginosar,Alison Gopnik*

Main category: cs.AI

TL;DR: 이 연구는 '임파워먼트'라는 개념이 인간의 인과 학습과 기계 학습에서의 인과 관계 추론을 연결해 줄 수 있음을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인간의 인지에서 세계의 인과 구조를 이해하는 것은 기본적인 문제입니다.

Method: 아이들과 성인이 인과 관계를 추론하고 효과적인 인과 개입을 설계하는 데 있어 '임파워먼트'라는 신호를 어떻게 사용하는지 체계적으로 테스트했습니다.

Result: 임파워먼트가 인과 모델을 학습하고 인과 관계를 추론하는 데 있어 중요한 역할을 할 수 있음을 발견했습니다.

Conclusion: 임파워먼트는 고전적인 베이지안 인과 학습과 강화 학습 간의 중요한 연결고리가 될 수 있습니다.

Abstract: Learning about the causal structure of the world is a fundamental problem for human cognition. Causal models and especially causal learning have proved to be difficult for large pretrained models using standard techniques of deep learning. In contrast, cognitive scientists have applied advances in our formal understanding of causation in computer science, particularly within the Causal Bayes Net formalism, to understand human causal learning. In the very different tradition of reinforcement learning, researchers have described an intrinsic reward signal called "empowerment" which maximizes mutual information between actions and their outcomes. "Empowerment" may be an important bridge between classical Bayesian causal learning and reinforcement learning and may help to characterize causal learning in humans and enable it in machines. If an agent learns an accurate causal world model, they will necessarily increase their empowerment, and increasing empowerment will lead to a more accurate causal world model. Empowerment may also explain distinctive features of childrens causal learning, as well as providing a more tractable computational account of how that learning is possible. In an empirical study, we systematically test how children and adults use cues to empowerment to infer causal relations, and design effective causal interventions.

</details>


### [7] [AgentEval: Generative Agents as Reliable Proxies for Human Evaluation of AI-Generated Content](https://arxiv.org/abs/2512.08273)
*Thanh Vu,Richi Nayak,Thiru Balasubramaniam*

Main category: cs.AI

TL;DR: 이 연구는 Generative Agents를 소개하여 AI 생성 콘텐츠의 평가를 자동화하고 비용을 절감하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현대 기업들은 고품질 콘텐츠 생성과 평가에 소요되는 시간과 비용 문제에 직면해 있다.

Method: Generative Agents는 AI 생성 콘텐츠의 품질을 평가하기 위해 인간의 판단을 모사하여 일관성, 흥미로움, 명확성, 공정성 및 관련성과 같은 측면을 평가한다.

Result: 이 연구는 Generative Agents를 통해 기업이 자동화된 방식으로 효율적으로 콘텐츠를 생성하고 평가할 수 있는 방법을 제시한다.

Conclusion: 이 연구는 LLM을 개선하여 비즈니스에 적합한 고품질 콘텐츠를 생산하는 데 기여하며, 자동 콘텐츠 생성 및 평가에서 знач적 진전을 이룬다.

Abstract: Modern businesses are increasingly challenged by the time and expense required to generate and assess high-quality content. Human writers face time constraints, and extrinsic evaluations can be costly. While Large Language Models (LLMs) offer potential in content creation, concerns about the quality of AI-generated content persist. Traditional evaluation methods, like human surveys, further add operational costs, highlighting the need for efficient, automated solutions. This research introduces Generative Agents as a means to tackle these challenges. These agents can rapidly and cost-effectively evaluate AI-generated content, simulating human judgment by rating aspects such as coherence, interestingness, clarity, fairness, and relevance. By incorporating these agents, businesses can streamline content generation and ensure consistent, high-quality output while minimizing reliance on costly human evaluations. The study provides critical insights into enhancing LLMs for producing business-aligned, high-quality content, offering significant advancements in automated content generation and evaluation.

</details>


### [8] [Towards a Science of Scaling Agent Systems](https://arxiv.org/abs/2512.08296)
*Yubin Kim,Ken Gu,Chanwoo Park,Chunjong Park,Samuel Schmidgall,A. Ali Heydari,Yao Yan,Zhihan Zhang,Yuchen Zhuang,Mark Malhotra,Paul Pu Liang,Hae Won Park,Yuzhe Yang,Xuhai Xu,Yilun Du,Shwetak Patel,Tim Althoff,Daniel McDuff,Xin Liu*

Main category: cs.AI

TL;DR: 이 논문은 에이전트 시스템의 성능을 결정하는 원칙을 정량적으로 도출하여 다각적인 벤치마크에서 평가하고 최적 조정 전략을 예측하는 연구이다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 시스템의 성능 원칙이 충분히 탐구되지 않아 실무자들이 경험적 방법에 의존하고 있는 문제를 해결하고자 한다.

Method: 다섯 가지 전형적인 아키텍처(단일, 독립, 중앙집중, 분산, 하이브리드)를 활용하여 세 가지 LLM 패밀리에서 180개의 구성으로 통제된 평가를 수행한다.

Result: 도출된 예측 모델은 87%의 홀드아웃 구성에서 최적 조정 전략을 예측하며, 성능 개선 비율은 지정된 비율로 집계된다.

Conclusion: 정량적 스케일링 원칙을 제공하며, 이를 통해 측정 가능한 작업 특성에 기반한 에이전트 성능의 예측 원리를 제공한다.

Abstract: Agents, language model (LM)-based systems that are capable of reasoning, planning, and acting are becoming the dominant paradigm for real-world AI applications. Despite this widespread adoption, the principles that determine their performance remain underexplored, leaving practitioners to rely on heuristics rather than principled design choices. We address this gap by deriving quantitative scaling principles for agent systems. We evaluate this across four diverse benchmarks: Finance-Agent, BrowseComp-Plus, PlanCraft, and Workbench. Using five canonical architectures (Single, Independent, Centralized, Decentralized, Hybrid) instantiated across three LLM families, we perform a controlled evaluation spanning 180 configurations with standardized tools and token budgets. We derive a predictive model using empirical coordination metrics, including efficiency, overhead, error amplification, and redundancy, that achieves cross-validated R^2=0.513. We identify three dominant effects: (1) a tool-coordination trade-off: under fixed computational budgets, tool-heavy tasks suffer disproportionately from multi-agent overhead. (2) a capability saturation: coordination yields diminishing or negative returns (beta=-0.408, p<0.001) once single-agent baselines exceed ~45%. (3) topology-dependent error amplification: independent agents amplify errors 17.2x through unchecked propagation, while centralized coordination contains this to 4.4x. Centralized coordination improves performance by 80.9% on parallelizable tasks like financial reasoning, while decentralized coordination excels on dynamic web navigation (+9.2% vs. +0.2%). Yet for sequential reasoning tasks, all multi-agent variants degraded performance by 39-70%. The framework predicts the optimal coordination strategy for 87% of held-out configurations, providing a predictive principle of agentic scaling based on measurable task properties.

</details>


### [9] [rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection](https://arxiv.org/abs/2512.08300)
*Sijia Chen,Baochun Li,Di Niu*

Main category: cs.AI

TL;DR: 본 연구는 LLM을 RLM으로 발전시키기 위한 새로운 강화 전략 주입 메커니즘(rSIM)을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 LLM이 자아 반성과 깊은 사고 등 전략을 수행하는 순간인 ``aha'' 순간에 착안했다.

Method: rSIM 메커니즘은 소형 플래너를 사용해 LLM의 사고의 연쇄(CoT)를 유도하며, 리더-팔로워 구조와 간단한 규칙 기반 보상을 통해 협력적 다중 에이전트 강화 학습(MARL)으로 훈련된다.

Result: rSIM은 Qwen2.5-0.5B가 RLM으로 발전할 수 있게 하며, Qwen2.5-14B를 능가하는 성능을 보인다.

Conclusion: 플래너를 한 번만 훈련하면 기존 LLM의 추론 능력을 획기적으로 향상시키는 플러그인으로 사용할 수 있다.

Abstract: Large language models (LLMs) are post-trained through reinforcement learning (RL) to evolve into Reasoning Language Models (RLMs), where the hallmark of this advanced reasoning is ``aha'' moments when they start to perform strategies, such as self-reflection and deep thinking, within chain of thoughts (CoTs). Motivated by this, this paper proposes a novel reinforced strategy injection mechanism (rSIM), that enables any LLM to become an RLM by employing a small planner to guide the LLM's CoT through the adaptive injection of reasoning strategies. To achieve this, the planner (leader agent) is jointly trained with an LLM (follower agent) using multi-agent RL (MARL), based on a leader-follower framework and straightforward rule-based rewards. Experimental results show that rSIM enables Qwen2.5-0.5B to become an RLM and significantly outperform Qwen2.5-14B. Moreover, the planner is generalizable: it only needs to be trained once and can be applied as a plug-in to substantially improve the reasoning capabilities of existing LLMs. In addition, the planner supports continual learning across various tasks, allowing its planning abilities to gradually improve and generalize to a wider range of problems.

</details>


### [10] [Reflecting with Two Voices: A Co-Adaptive Dual-Strategy Framework for LLM-Based Agent Decision Making](https://arxiv.org/abs/2512.08366)
*Wentao Zhang,Qunbo Wang,Tao Zhang,Junsheng Wu,Hongping Gan,Yang Liu,Ling Dai,Shizhuang Deng,Shuntong Sun*

Main category: cs.AI

TL;DR: DuSAR는 외부 시연 없이 단일 LLM이 보완적인 두 가지 전략을 사용하여 공동 적응형 추론을 수행하도록하는 프레임워크로, ALFWorld와 Mind2Web에서 최첨단 성과를 달성했다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델은 종종 외부 시연이나 검색 증강 계획에 의존하여 취약성과 낮은 일반화, 높은 계산 오버헤드를 초래한다.

Method: DuSAR는 고수준의 전체 계획과 맥락 기반의 로컬 정책을 사용하는 두 가지 상보적 전략을 통해 단일의 고정 LLM이 공동 적응형 추론을 수행할 수 있도록 하는 시연 없는 프레임워크이다.

Result: ALFWorld에서는 37.1%의 성공률로 이전 최고 성과를 두 배 이상 초과했으며, Mind2Web에서도 가장 강력한 기준보다 두 배 이상 성과를 향상시켰다. 한 단계당 토큰 소비를 3-9배 줄이면서도 강력한 성능을 유지하는 것으로 나타났다.

Conclusion: DuSAR의 이중 전략 조정의 필요성이 확인되었으며, 전문가 시연의 선택적 통합이 결과를 더욱 향상시켜 DuSAR의 유연성과 외부 지식과의 호환성을 강조한다.

Abstract: Large language model (LLM) agents often rely on external demonstrations or retrieval-augmented planning, leading to brittleness, poor generalization, and high computational overhead. Inspired by human problem-solving, we propose DuSAR (Dual-Strategy Agent with Reflecting) - a demonstration-free framework that enables a single frozen LLM to perform co-adaptive reasoning via two complementary strategies: a high-level holistic plan and a context-grounded local policy. These strategies interact through a lightweight reflection mechanism, where the agent continuously assesses progress via a Strategy Fitness Score and dynamically revises its global plan when stuck or refines it upon meaningful advancement, mimicking human metacognitive behavior. On ALFWorld and Mind2Web, DuSAR achieves state-of-the-art performance with open-source LLMs (7B-70B), reaching 37.1% success on ALFWorld (Llama3.1-70B) - more than doubling the best prior result (13.0%) - and 4.02% on Mind2Web, also more than doubling the strongest baseline. Remarkably, it reduces per-step token consumption by 3-9X while maintaining strong performance. Ablation studies confirm the necessity of dual-strategy coordination. Moreover, optional integration of expert demonstrations further boosts results, highlighting DuSAR's flexibility and compatibility with external knowledge.

</details>


### [11] [Prismatic World Model: Learning Compositional Dynamics for Planning in Hybrid Systems](https://arxiv.org/abs/2512.08411)
*Mingwei Li,Xiaoyuan Zhang,Chengwei Yang,Zilong Zheng,Yaodong Yang*

Main category: cs.AI

TL;DR: PRISM-WM은 복잡한 하이브리드 역학을 구성 가능한 원시 요소로 분해하기 위해 설계된 새로운 모델 기반 계획 아키텍처이다.


<details>
  <summary>Details</summary>
Motivation: 로봇 도메인에서 물리적 역학의 하이브리드 특성이 모델 기반 계획에 도전 과제가 된다.

Method: PRISM-WM은 물리적 모드를 식별하는 게이팅 메커니즘을 활용하여 상호 작용하는 전문가들이 전이 역학을 예측하도록 구성된 컨텍스트 인식 혼합 전문가(MoE) 프레임워크를 사용한다.

Result: PRISM-WM은 시스템 역학의 급격한 모드 전이를 정확하게 모델링하여 롤아웃 드리프트를 크게 감소시킨다.

Conclusion: PRISM-WM은 다음 세대 모델 기반 에이전트를 위한 강력한 기초 모델로서의 잠재력을 입증하였다.

Abstract: Model-based planning in robotic domains is fundamentally challenged by the hybrid nature of physical dynamics, where continuous motion is punctuated by discrete events such as contacts and impacts. Conventional latent world models typically employ monolithic neural networks that enforce global continuity, inevitably over-smoothing the distinct dynamic modes (e.g., sticking vs. sliding, flight vs. stance). For a planner, this smoothing results in catastrophic compounding errors during long-horizon lookaheads, rendering the search process unreliable at physical boundaries. To address this, we introduce the Prismatic World Model (PRISM-WM), a structured architecture designed to decompose complex hybrid dynamics into composable primitives. PRISM-WM leverages a context-aware Mixture-of-Experts (MoE) framework where a gating mechanism implicitly identifies the current physical mode, and specialized experts predict the associated transition dynamics. We further introduce a latent orthogonalization objective to ensure expert diversity, effectively preventing mode collapse. By accurately modeling the sharp mode transitions in system dynamics, PRISM-WM significantly reduces rollout drift. Extensive experiments on challenging continuous control benchmarks, including high-dimensional humanoids and diverse multi-task settings, demonstrate that PRISM-WM provides a superior high-fidelity substrate for trajectory optimization algorithms (e.g., TD-MPC), proving its potential as a powerful foundational model for next-generation model-based agents.

</details>


### [12] [From Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change](https://arxiv.org/abs/2512.08449)
*Yong-Woon Kim*

Main category: cs.AI

TL;DR: 이 논문은 변화 이론(Theory of Change, ToC) 원칙을 현대 인공지능 시스템 설계와 통합한 새로운 구조적 방법론인 Impact-Driven AI Framework (IDAIF)를 소개한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 의료, 금융, 공공 정책 등의 고위험 분야에 미치는 영향이 증가함에 따라, AI 행동이 인간의 가치와 의도에 부합하도록 보장하는 정렬 문제는 매우 중요해졌다.

Method: IDAIF는 ToC의 다섯 단계 모델(투입-활동-산출-성과-영향)과 관련 AI 아키텍처 레이어(데이터 레이어-파이프라인 레이어-추론 레이어-행위적 레이어-규범적 레이어) 간의 체계적 매핑을 설정하여 이 격차를 해결한다.

Result: 각 레이어는 가치 정렬을 위한 다목적 파레토 최적화, 결과 달성을 위한 계층적 다중 에이전트 조정, 환각 완화를 위한 인과적 비순환 그래프(DAG), 공정성 보장을 위한 인류 피드백으로부터의 강화 학습(RLHF)을 포함한다.

Conclusion: 이 프레임워크는 모델 중심의 AI 개발에서 영향 중심의 AI 개발로의 패러다임 전환을 나타내며, 엔지니어들에게 윤리적이고 신뢰할 수 있으며 사회적으로 이로운 AI 시스템을 구축하기 위한 구체적인 아키텍처 패턴을 제공한다.

Abstract: This paper introduces the Impact-Driven AI Framework (IDAIF), a novel architectural methodology that integrates Theory of Change (ToC) principles with modern artificial intelligence system design. As AI systems increasingly influence high-stakes domains including healthcare, finance, and public policy, the alignment problem--ensuring AI behavior corresponds with human values and intentions--has become critical. Current approaches predominantly optimize technical performance metrics while neglecting the sociotechnical dimensions of AI deployment. IDAIF addresses this gap by establishing a systematic mapping between ToC's five-stage model (Inputs-Activities-Outputs-Outcomes-Impact) and corresponding AI architectural layers (Data Layer-Pipeline Layer-Inference Layer-Agentic Layer-Normative Layer). Each layer incorporates rigorous theoretical foundations: multi-objective Pareto optimization for value alignment, hierarchical multi-agent orchestration for outcome achievement, causal directed acyclic graphs (DAGs) for hallucination mitigation, and adversarial debiasing with Reinforcement Learning from Human Feedback (RLHF) for fairness assurance. We provide formal mathematical formulations for each component and introduce an Assurance Layer that manages assumption failures through guardian architectures. Three case studies demonstrate IDAIF application across healthcare, cybersecurity, and software engineering domains. This framework represents a paradigm shift from model-centric to impact-centric AI development, providing engineers with concrete architectural patterns for building ethical, trustworthy, and socially beneficial AI systems.

</details>


### [13] [Using reinforcement learning to probe the role of feedback in skill acquisition](https://arxiv.org/abs/2512.08463)
*Antonio Terpin,Raffaello D'Andrea*

Main category: cs.AI

TL;DR: 고성능 기술 습득 과정을 연구하기 위해, 인체 대신 일반화 강화학습 에이전트를 사용하여 드래그를 극대화하거나 최소화하는 물리적 시스템을 인터페이스합니다. 고차원 흐름 피드백을 통해 에이전트는 몇 분 만에 높은 성능의 드래그 제어 전략을 발견하고, 피드백 없이도 유사한 성능을 유지합니다. 학습 조건은 목표에 따라 다를 수 있습니다.


<details>
  <summary>Details</summary>
Motivation: 고성능 인간 활동의 기술 습득 과정을 연구하고자 하며, 이를 위해 인체 대신 물리적 시스템을 사용하는 방식을 제안합니다.

Method: 일반화 강화학습 에이전트를 회전하는 실린더와 연결하여 드래그를 극대화하거나 최소화하는 실험을 수행합니다.

Result: 고차원 흐름 피드백을 통해 에이전트는 몇 분 만에 높은 성능의 드래그 제어 전략을 발견하며, 나중에 같은 동작 시퀀스를 피드백 없이 반복해도 거의 동일한 성과를 얻습니다.

Conclusion: 고성능 기술을 학습하는 것은 이를 실행하는 것보다 더 풍부한 정보가 필요할 수 있으며, 학습 조건은 목표에 따라 다를 수 있습니다.

Abstract: Many high-performance human activities are executed with little or no external feedback: think of a figure skater landing a triple jump, a pitcher throwing a curveball for a strike, or a barista pouring latte art. To study the process of skill acquisition under fully controlled conditions, we bypass human subjects. Instead, we directly interface a generalist reinforcement learning agent with a spinning cylinder in a tabletop circulating water channel to maximize or minimize drag. This setup has several desirable properties. First, it is a physical system, with the rich interactions and complex dynamics that only the physical world has: the flow is highly chaotic and extremely difficult, if not impossible, to model or simulate accurately. Second, the objective -- drag minimization or maximization -- is easy to state and can be captured directly in the reward, yet good strategies are not obvious beforehand. Third, decades-old experimental studies provide recipes for simple, high-performance open-loop policies. Finally, the setup is inexpensive and far easier to reproduce than human studies. In our experiments we find that high-dimensional flow feedback lets the agent discover high-performance drag-control strategies with only minutes of real-world interaction. When we later replay the same action sequences without any feedback, we obtain almost identical performance. This shows that feedback, and in particular flow feedback, is not needed to execute the learned policy. Surprisingly, without flow feedback during training the agent fails to discover any well-performing policy in drag maximization, but still succeeds in drag minimization, albeit more slowly and less reliably. Our studies show that learning a high-performance skill can require richer information than executing it, and learning conditions can be kind or wicked depending solely on the goal, not on dynamics or policy complexity.

</details>


### [14] [Autonomous Issue Resolver: Towards Zero-Touch Code Maintenance](https://arxiv.org/abs/2512.08492)
*Aliaksei Kaliutau*

Main category: cs.AI

TL;DR: 대규모 언어 모델의 발전이 기능 수준 코드 생성을 혁신했지만, 저장소 규모의 자동 프로그램 수리는 여전히 큰 도전 과제입니다. 본 논문은 데이터 변환 그래프(DTG)라는 새로운 개념을 제안하여 데이터 상태를 노드로, 함수를 엣지로 모델링함으로써 논리 결함을 추적할 수 있도록 합니다.


<details>
  <summary>Details</summary>
Motivation: 저장소 규모의 자동 프로그램 수리가 여전히 큰 도전과제를 해결할 필요가 있다.

Method: 데이터 상태를 노드로, 함수를 엣지로 모델링한 데이터 변환 그래프(DTG) 개념을 통해 에이전트가 제어 흐름이 아닌 데이터 계보를 통해 논리 결함을 추적하도록 하는 다중 에이전트 프레임워크를 제안한다.

Result: 이 접근 방식은 표준 RAG 시스템에 내재된 '의미적 함정'을 해결하며, AIR라는 자율 문제 해결 시스템을 통해 구현되었다. 이 시스템은 87.1%의 해결률을 달성하였다.

Conclusion: 이 방법은 현재 AI 코드 보조 도구의 핵심 한계를 직접적으로 해결하고, 소프트웨어 의존 세상을 위한 더 강력한 기초의 필요성을 다룬다.

Abstract: Recent advances in Large Language Models have revolutionized function-level code generation; however, repository-scale Automated Program Repair (APR) remains a significant challenge. Current approaches typically employ a control-centric paradigm, forcing agents to navigate complex directory structures and irrelevant control logic. In this paper, we propose a paradigm shift from the standard Code Property Graphs (CPGs) to the concept of Data Transformation Graph (DTG) that inverts the topology by modeling data states as nodes and functions as edges, enabling agents to trace logic defects through data lineage rather than control flow. We introduce a multi-agent framework that reconciles data integrity navigation with control flow logic. Our theoretical analysis and case studies demonstrate that this approach resolves the "Semantic Trap" inherent in standard RAG systems in modern coding agents. We provide a comprehensive implementation in the form of Autonomous Issue Resolver (AIR), a self-improvement system for zero-touch code maintenance that utilizes neuro-symbolic reasoning and uses the DTG structure for scalable logic repair. Our approach has demonstrated good results on several SWE benchmarks, reaching a resolution rate of 87.1% on SWE-Verified benchmark. Our approach directly addresses the core limitations of current AI code-assistant tools and tackles the critical need for a more robust foundation for our increasingly software-dependent world.

</details>


### [15] [A Lightweight Transfer Learning-Based State-of-Health Monitoring with Application to Lithium-ion Batteries in Unmanned Air Vehicles](https://arxiv.org/abs/2512.08512)
*Jiang Liu,Yan Qin,Wei Dai,Chau Yuen*

Main category: cs.AI

TL;DR: 경량 TL 기반의 SOH 모니터링 방법이 UAV 배터리 데이터셋을 통해 기존 방법보다 성능이 우수함을 입증하였다.


<details>
  <summary>Details</summary>
Motivation: 리튬 이온 배터리를 사용하는 모바일 장치의 SOH 모니터링을 효율적으로 수행하기 위해서이다.

Method: CITL(Constructive Incremental Transfer Learning) 방법론에 기반하여 반지도 학습 메커니즘을 통해 SOH 모니터링의 오차를 최소화하고, 구조적 위험 최소화 및 전이 불일치 최소화를 통해 노드 매개변수의 도메인 간 학습 능력을 보장한다.

Result: CITL은 SOH 추정에서 기존 방법들보다 더 높은 성능을 보였으며, 각각의 방법과 비교하여 개선된 비율을 제시한다.

Conclusion: 제안한 방법은 실험을 통해 이론적 보증을 갖춘 경량화된 SOH 모니터링 접근법임을 증명하였다.

Abstract: Accurate and rapid state-of-health (SOH) monitoring plays an important role in indicating energy information for lithium-ion battery-powered portable mobile devices. To confront their variable working conditions, transfer learning (TL) emerges as a promising technique for leveraging knowledge from data-rich source working conditions, significantly reducing the training data required for SOH monitoring from target working conditions. However, traditional TL-based SOH monitoring is infeasible when applied in portable mobile devices since substantial computational resources are consumed during the TL stage and unexpectedly reduce the working endurance. To address these challenges, this paper proposes a lightweight TL-based SOH monitoring approach with constructive incremental transfer learning (CITL). First, taking advantage of the unlabeled data in the target domain, a semi-supervised TL mechanism is proposed to minimize the monitoring residual in a constructive way, through iteratively adding network nodes in the CITL. Second, the cross-domain learning ability of node parameters for CITL is comprehensively guaranteed through structural risk minimization, transfer mismatching minimization, and manifold consistency maximization. Moreover, the convergence analysis of the CITL is given, theoretically guaranteeing the efficacy of TL performance and network compactness. Finally, the proposed approach is verified through extensive experiments with a realistic unmanned air vehicles (UAV) battery dataset collected from dozens of flight missions. Specifically, the CITL outperforms SS-TCA, MMD-LSTM-DA, DDAN, BO-CNN-TL, and AS$^3$LSTM, in SOH estimation by 83.73%, 61.15%, 28.24%, 87.70%, and 57.34%, respectively, as evaluated using the index root mean square error.

</details>


### [16] [See-Control: A Multimodal Agent Framework for Smartphone Interaction with a Robotic Arm](https://arxiv.org/abs/2512.08629)
*Haoyu Zhao,Weizhong Ding,Yuhao Yang,Zheng Tian,Linyi Yang,Kun Shao,Jun Wang*

Main category: cs.AI

TL;DR: 본 연구는 스마트폰 작동을 위한 새로운 방법론을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법이 Android 장치에만 국한되어 있어 적용성이 제한됩니다.

Method: 우리는 ESO(Embodied Smartphone Operation) 작업과 ADB dependency 없이 로봇 제어 명령을 생성하는 MLLM 기반 에이전트를 포함한 See-Control 프레임워크를 소개합니다.

Result: See-Control은 155개의 작업과 평가 지표를 포함한 ESO 벤치마크, ADB 없이 로봇 제어 명령을 생성하는 에이전트, 작동 에피소드의 주석이 달린 데이터셋으로 구성되어 있습니다.

Conclusion: See-Control은 디지털 에이전트와 물리적 세계 사이의 간극을 좁혀 스마트폰 의존 작업을 수행할 수 있도록 도와줍니다.

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled their use as intelligent agents for smartphone operation. However, existing methods depend on the Android Debug Bridge (ADB) for data transmission and action execution, limiting their applicability to Android devices. In this work, we introduce the novel Embodied Smartphone Operation (ESO) task and present See-Control, a framework that enables smartphone operation via direct physical interaction with a low-DoF robotic arm, offering a platform-agnostic solution. See-Control comprises three key components: (1) an ESO benchmark with 155 tasks and corresponding evaluation metrics; (2) an MLLM-based embodied agent that generates robotic control commands without requiring ADB or system back-end access; and (3) a richly annotated dataset of operation episodes, offering valuable resources for future research. By bridging the gap between digital agents and the physical world, See-Control provides a concrete step toward enabling home robots to perform smartphone-dependent tasks in realistic environments.

</details>


### [17] [A Practical Guide for Designing, Developing, and Deploying Production-Grade Agentic AI Workflows](https://arxiv.org/abs/2512.08769)
*Eranga Bandara,Ross Gore,Peter Foytik,Sachin Shetty,Ravi Mukkamala,Abdul Rahman,Xueping Liang,Safdar H. Bouk,Amin Hass,Sachini Rajapakse,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.AI

TL;DR: 본 논문은 신뢰할 수 있고 관찰 가능하며 유지 보수 가능한 생산 등급의 에이전틱 AI 워크플로우를 설계하고 운영하는 방법에 대한 실용적인 가이드를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI는 자율 시스템이 다단계 작업을 추론, 계획 및 실행하는 방식을 크게 변화시키고 있으며, 이는 산업 및 연구에서의 채택이 가속화되고 있다.

Method: 워크플로우 분해, 다중 에이전트 설계 패턴, 모델 컨텍스트 프로토콜(MCP), 도구 통합, 결정론적 조율, 책임 있는 AI 고려 사항, 환경 인식 배포 전략을 포함하는 구조화된 엔지니어링 라이프사이클을 소개한다.

Result: 생산 품질의 에이전틱 AI 워크플로우 설계 및 구현을 위한 아홉 가지 핵심 모범 사례를 제시한다.

Conclusion: 견고하고 확장 가능하며 생산 준비가 된 에이전틱 AI 워크플로우를 구축하기 위한 기초적인 참조를 제공한다.

Abstract: Agentic AI marks a major shift in how autonomous systems reason, plan, and execute multi-step tasks. Unlike traditional single model prompting, agentic workflows integrate multiple specialized agents with different Large Language Models(LLMs), tool-augmented capabilities, orchestration logic, and external system interactions to form dynamic pipelines capable of autonomous decision-making and action. As adoption accelerates across industry and research, organizations face a central challenge: how to design, engineer, and operate production-grade agentic AI workflows that are reliable, observable, maintainable, and aligned with safety and governance requirements. This paper provides a practical, end-to-end guide for designing, developing, and deploying production-quality agentic AI systems. We introduce a structured engineering lifecycle encompassing workflow decomposition, multi-agent design patterns, Model Context Protocol(MCP), and tool integration, deterministic orchestration, Responsible-AI considerations, and environment-aware deployment strategies. We then present nine core best practices for engineering production-grade agentic AI workflows, including tool-first design over MCP, pure-function invocation, single-tool and single-responsibility agents, externalized prompt management, Responsible-AI-aligned model-consortium design, clean separation between workflow logic and MCP servers, containerized deployment for scalable operations, and adherence to the Keep it Simple, Stupid (KISS) principle to maintain simplicity and robustness. To demonstrate these principles in practice, we present a comprehensive case study: a multimodal news-analysis and media-generation workflow. By combining architectural guidance, operational patterns, and practical implementation insights, this paper offers a foundational reference to build robust, extensible, and production-ready agentic AI workflows.

</details>


### [18] [EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce](https://arxiv.org/abs/2512.08868)
*Rui Min,Zile Qiao,Ze Xu,Jiawen Zhai,Wenyu Gao,Xuanzhong Chen,Haozhen Sun,Zhen Zhang,Xinyu Wang,Hong Zhou,Wenbiao Yin,Xuan Zhou,Yong Jiang,Haicheng Liu,Liang Ding,Ling Zou,Yi R.,Fung,Yalong Li,Pengjun Xie*

Main category: cs.AI

TL;DR: EcomBench는 현실적인 전자상거래 환경에서 에이전트 성능을 평가하기 위한 종합 전자상거래 벤치마크이다.


<details>
  <summary>Details</summary>
Motivation: 에이전트의 핵심 능력을 평가하는 것이 중요해졌지만 많은 벤치마크가 학문적 환경이나 인공적으로 설계된 시나리오에 집중하고 실제 애플리케이션에서 발생하는 도전을 간과하고 있다.

Method: EcomBench는 실제 사용자의 요구를 바탕으로 글로벌 전자상거래 생태계에서 구성되었으며, 전문가들이 명확성, 정확성 및 도메인 관련성을 보장하기 위해 신중하게 주석을 달았다.

Result: 다양한 전자상거래 시나리오 내 여러 작업 범주를 포괄하고, 심층 정보 검색, 다단계 추론 및 교차 출처 지식 통합과 같은 핵심 능력에 대해 에이전트를 평가하는 세 가지 난이도 수준을 정의한다.

Conclusion: EcomBench는 실제 전자상거래 맥락에 기반하여 현대 전자상거래에서 에이전트의 실용적인 역량을 측정할 수 있는 엄격하고 역동적인 테스트베드를 제공한다.

Abstract: Foundation agents have rapidly advanced in their ability to reason and interact with real environments, making the evaluation of their core capabilities increasingly important. While many benchmarks have been developed to assess agent performance, most concentrate on academic settings or artificially designed scenarios while overlooking the challenges that arise in real applications. To address this issue, we focus on a highly practical real-world setting, the e-commerce domain, which involves a large volume of diverse user interactions, dynamic market conditions, and tasks directly tied to real decision-making processes. To this end, we introduce EcomBench, a holistic E-commerce Benchmark designed to evaluate agent performance in realistic e-commerce environments. EcomBench is built from genuine user demands embedded in leading global e-commerce ecosystems and is carefully curated and annotated through human experts to ensure clarity, accuracy, and domain relevance. It covers multiple task categories within e-commerce scenarios and defines three difficulty levels that evaluate agents on key capabilities such as deep information retrieval, multi-step reasoning, and cross-source knowledge integration. By grounding evaluation in real e-commerce contexts, EcomBench provides a rigorous and dynamic testbed for measuring the practical capabilities of agents in modern e-commerce.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [19] [Agentic Artificial Intelligence for Ethical Cybersecurity in Uganda: A Reinforcement Learning Framework for Threat Detection in Resource-Constrained Environments](https://arxiv.org/abs/2512.07909)
*Ibrahim Adabara,Bashir Olaniyi Sadiq,Aliyu Nuhu Shuaibu,Yale Ibrahim Danjuma,Venkateswarlu Maninti,Mutebi Joe*

Main category: cs.CR

TL;DR: 우간다의 디지털 전환은 사이버 위협과의 전투에서 효과적인 방안을 필요로 한다. 본 연구는 에이전틱 인공지능(AI) 프레임워크를 제안하여 탐지 능력을 향상시키고 윤리적 준수를 보장한다.


<details>
  <summary>Details</summary>
Motivation: 우간다는 국가 전략인 비전 2040과 디지털 전환 로드맵에 의존하여 디지털 전환을 빠르게 진행하고 있으며, 이로 인해 사이버 위협에 대한 노출이 증가하고 있다.

Method: 본 연구는 강화 학습, 명시적인 윤리적 거버넌스 계층, 인간의 감독이 통합된 에이전틱 AI 프레임워크를 제안한다.

Result: 제안된 프레임워크는 전통적인 규칙 기반 시스템에 비해 100% 탐지율, 0% 허위 긍정률 및 완전한 윤리적 준수를 달성하여 효과를 입증하였다.

Conclusion: 에이전틱, 윤리적으로 관리되는 강화 학습은 CPU만 사용하고 자원이 제한된 환경에서 사이버 보안의 효과와 공정성을 상당히 개선할 수 있음을 나타낸다.

Abstract: Uganda's rapid digital transformation, supported by national strategies such as Vision 2040 and the Digital Transformation Roadmap, has expanded reliance on networked services while simultaneously increasing exposure to sophisticated cyber threats. In resource-constrained settings, commonly deployed rule-based intrusion detection systems lack the adaptability and ethical safeguards needed to address evolving attack patterns, leading to undetected breaches and excessive blocking of legitimate traffic. This study proposes an Agentic Artificial Intelligence (AAI) framework that integrates reinforcement learning, an explicit ethical governance layer, and human oversight to deliver adaptive and trustworthy cybersecurity. A CPU-optimized simulation environment was developed using a five-node network topology that mirrors key elements of Uganda's critical digital infrastructure and generates both benign and malicious traffic, including phishing, ransomware, and distributed denial-of-service attacks. A Q-learning agent, operating within clearly defined ethical constraints and subject to human auditability, was trained and evaluated against a traditional rule-based baseline. The AAI framework achieved a 100 percent detection rate, zero false positives, and full ethical compliance, compared with 70 percent detection and 15 percent false positives for the baseline system. These results demonstrate that agentic, ethically governed reinforcement learning can substantially improve cybersecurity effectiveness and fairness in CPU-only, resource-constrained environments, offering a practical pathway for operationalizing responsible AI in Uganda's national cybersecurity strategy.

</details>


### [20] [AgentCrypt: Advancing Privacy and (Secure) Computation in AI Agent Collaboration](https://arxiv.org/abs/2512.08104)
*Harish Karthikeyan,Yue Guo,Leo de Castro,Antigoni Polychroniadou,Leo Ardon,Udari Madhushani Sehwag,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CR

TL;DR: AI 에이전트가 다중 에이전트 환경에서 작동함에 따라 에이전트 간의 신뢰할 수 있고 상황 인식적인 개인 정보 보호가 중요해졌다. 기존 접근 제어는 충분하지 않으며, AgentCrypt라는 네 단계의 프레임워크를 통해 이러한 개인 정보 보호 요구를 해결했다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 경우, 다중 에이전트 환경에서 신뢰할 수 있는 개인 정보 보호가 점점 더 중요해진다.

Method: AgentCrypt는 데이터의 사전 태그를 유지하는 것을 보장하며, 다양한 상호작용에서 개인 정보를 보호하는 네 단계의 프레임워크를 제공한다.

Result: AgentCrypt를 구현하고 Langgraph 및 Google ADK와 함께 테스트하여 다양한 플랫폼에서의 유연성을 입증했다.

Conclusion: AgentCrypt는 개인 정보를 보호하면서도 접근할 수 없는 데이터에 대한 계산을 가능하게 하여 안전한 에이전트 통신 및 계산을 위한 규제 가능한 머신 러닝 시스템 개발을 촉진한다.

Abstract: As AI agents increasingly operate in real-world, multi-agent environments, ensuring reliable and context-aware privacy in agent communication is critical, especially to comply with evolving regulatory requirements. Traditional access controls are insufficient, as privacy risks often arise after access is granted; agents may use information in ways that compromise privacy, such as messaging humans, sharing context with other agents, making tool calls, persisting data, or generating derived private information. Existing approaches often treat privacy as a binary constraint, whether data is shareable or not, overlooking nuanced, role-specific, and computation-dependent privacy needs essential for regulatory compliance.
  Agents, including those based on large language models, are inherently probabilistic and heuristic. There is no formal guarantee of how an agent will behave for any query, making them ill-suited for operations critical to security. To address this, we introduce AgentCrypt, a four-tiered framework for fine-grained, encrypted agent communication that adds a protection layer atop any AI agent platform. AgentCrypt spans unrestricted data exchange (Level 1) to fully encrypted computation using techniques such as homomorphic encryption (Level 4). Crucially, it guarantees the privacy of tagged data is always maintained, prioritizing privacy above correctness.
  AgentCrypt ensures privacy across diverse interactions and enables computation on otherwise inaccessible data, overcoming barriers such as data silos. We implemented and tested it with Langgraph and Google ADK, demonstrating versatility across platforms. We also introduce a benchmark dataset simulating privacy-critical tasks at all privacy levels, enabling systematic evaluation and fostering the development of regulatable machine learning systems for secure agent communication and computation.

</details>


### [21] [Systematization of Knowledge: Security and Safety in the Model Context Protocol Ecosystem](https://arxiv.org/abs/2512.08290)
*Shiva Gaire,Srijan Gyawali,Saroj Mishra,Suman Niroula,Dilip Thakur,Umesh Yadav*

Main category: cs.CR

TL;DR: 모델 컨텍스트 프로토콜(MCP)은 대형 언어 모델(LLM)을 외부 데이터 및 도구에 연결하는 사실상의 표준으로 떠올랐다. 그러나 이는 심각한 상호운용성 문제를 해결하는 동시에 새로운 위협 환경을 초래한다.


<details>
  <summary>Details</summary>
Motivation: LLM과 외부 자원 간의 연결 필요성이 커지고 있는 가운데, MCP의 중요성이 증가하고 있다.

Method: MCP 생태계 내 리스크의 포괄적인 분류 체계를 제공하고, 구조적 취약성을 분석하며, 최신 방어 방법을 조사한다.

Result: MCP의 구조적 취약성을 분석하고, 다중 에이전트 환경에서 비허가 작업을 유발할 수 있는 방법을 입증하였다.

Conclusion: 대화형 챗봇에서 자율 에이전틱 운영 시스템으로의 전환을 위한 보안 로드맵을 제안한다.

Abstract: The Model Context Protocol (MCP) has emerged as the de facto standard for connecting Large Language Models (LLMs) to external data and tools, effectively functioning as the "USB-C for Agentic AI." While this decoupling of context and execution solves critical interoperability challenges, it introduces a profound new threat landscape where the boundary between epistemic errors (hallucinations) and security breaches (unauthorized actions) dissolves. This Systematization of Knowledge (SoK) aims to provide a comprehensive taxonomy of risks in the MCP ecosystem, distinguishing between adversarial security threats (e.g., indirect prompt injection, tool poisoning) and epistemic safety hazards (e.g., alignment failures in distributed tool delegation). We analyze the structural vulnerabilities of MCP primitives, specifically Resources, Prompts, and Tools, and demonstrate how "context" can be weaponized to trigger unauthorized operations in multi-agent environments. Furthermore, we survey state-of-the-art defenses, ranging from cryptographic provenance (ETDI) to runtime intent verification, and conclude with a roadmap for securing the transition from conversational chatbots to autonomous agentic operating systems.

</details>


### [22] [Privacy-Preserving Identifier Checking in 5G](https://arxiv.org/abs/2512.08310)
*Marcel D. S. K. Gräfenstein,Stefan Köpsell,Maryam Zarezadeh*

Main category: cs.CR

TL;DR: 본 연구는 5G에서 개인 정보 보호를 위한 장치 식별자 검증 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 4G 및 5G 네트워크에서 장치 무결성을 보장하며 규정을 준수하기 위해 장치 식별자 공유의 필요성과 이로 인한 개인 정보 보호 위험을 해결할 필요가 있습니다.

Method: PEPSI 프로토콜을 수정하여 BFV 동형 암호화 방식으로 개인 집합 멤버십(PSM) 설정을 적용한 장치 식별자 검증 프로토콜을 제안합니다.

Result: 시스템은 온라인 검증을 5초 이내에 완료하고 세션당 약 15에서 16MB의 통신을 요구합니다.

Conclusion: 이 연구는 동형 암호화의 가능성을 보여주며, 5G에서 개인 정보를 보호하면서 식별자 관리에 대한 기초를 마련합니다.

Abstract: Device identifiers like the International Mobile Equipment Identity (IMEI) are crucial for ensuring device integrity and meeting regulations in 4G and 5G networks. However, sharing these identifiers with Mobile Network Operators (MNOs) brings significant privacy risks by enabling long-term tracking and linking of user activities across sessions. In this work, we propose a privacy-preserving identifier checking method in 5G. This paper introduces a protocol for verifying device identifiers without exposing them to the network while maintaining the same functions as the 3GPP-defined Equipment Identity Register (EIR) process. The proposed solution modifies the PEPSI protocol for a Private Set Membership (PSM) setting using the BFV homomorphic encryption scheme. This lets User Equipment (UE) prove that its identifier is not on an operator's blacklist or greylist while ensuring that the MNO only learns the outcome of the verification. The protocol allows controlled deanonymization through an authorized Law Enforcement (LE) hook, striking a balance between privacy and accountability. Implementation results show that the system can perform online verification within five seconds and requires about 15 to 16 MB of communication per session. This confirms its practical use under post-quantum security standards. The findings highlight the promise of homomorphic encryption for managing identifiers while preserving privacy in 5G, laying the groundwork for scalable and compliant verification systems in future 6G networks.

</details>


### [23] [Argus: A Multi-Agent Sensitive Information Leakage Detection Framework Based on Hierarchical Reference Relationships](https://arxiv.org/abs/2512.08326)
*Bin Wang,Hui Li,Liyang Zhang,Qijia Zhuang,Ao Yang,Dong Zhang,Xijun Luo,Bing Lin*

Main category: cs.CR

TL;DR: 민감한 정보 유출 탐지 문제를 해결하기 위한 다중 에이전트 협업 프레임워크 Argus를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 코드 리포지토리에서 민감한 정보 유출은 주요 보안 문제로 떠오르고 있으며, 전통적인 탐지 방법은 높은 오탐율로 효율성을 저하시키고 개발자의 수작업 부담을 증가시킨다.

Method: Argus는 주요 콘텐츠, 파일 맥락 및 프로젝트 참조 관계를 통합한 3단계 탐지 메커니즘을 사용하여 오탐을 줄이고 탐지 정확성을 높인다.

Result: Argus는 유출 탐지에서 최대 94.86%의 정확도를 달성하였으며, 정밀도는 96.36%, 재현율은 94.64%, F1 점수는 0.955이다.

Conclusion: Argus의 모든 코드 구현 및 관련 데이터 세트는 추가 연구 및 응용을 위해 공개적으로 제공된다.

Abstract: Sensitive information leakage in code repositories has emerged as a critical security challenge. Traditional detection methods that rely on regular expressions, fingerprint features, and high-entropy calculations often suffer from high false-positive rates. This not only reduces detection efficiency but also significantly increases the manual screening burden on developers. Recent advances in large language models (LLMs) and multi-agent collaborative architectures have demonstrated remarkable potential for tackling complex tasks, offering a novel technological perspective for sensitive information detection. In response to these challenges, we propose Argus, a multi-agent collaborative framework for detecting sensitive information. Argus employs a three-tier detection mechanism that integrates key content, file context, and project reference relationships to effectively reduce false positives and enhance overall detection accuracy. To comprehensively evaluate Argus in real-world repository environments, we developed two new benchmarks, one to assess genuine leak detection capabilities and another to evaluate false-positive filtering performance. Experimental results show that Argus achieves up to 94.86% accuracy in leak detection, with a precision of 96.36%, recall of 94.64%, and an F1 score of 0.955. Moreover, the analysis of 97 real repositories incurred a total cost of only 2.2$. All code implementations and related datasets are publicly available at https://github.com/TheBinKing/Argus-Guard for further research and application.

</details>


### [24] [Attention is All You Need to Defend Against Indirect Prompt Injection Attacks in LLMs](https://arxiv.org/abs/2512.08417)
*Yinan Zhong,Qianhao Miao,Yanjiao Chen,Jiangyi Deng,Yushi Cheng,Wenyuan Xu*

Main category: cs.CR

TL;DR: 이 논문은 Indirect Prompt Injection (IPI) 공격을 방지하기 위한 Rennervate 방어 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM(대형 언어 모델) 기반 응용 프로그램이 IPI 공격에 취약하다는 문제를 해결하고자 합니다.

Method: Rennervate는 주의 메커니즘을 활용하여 토큰 수준에서의 은밀한 주입을 감지하고, 2단계 주의 풀링 메커니즘으로 구현한 토큰 레벨 감지기를 사용합니다.

Result: Rennervate는 15개의 상업적 및 학술적 IPI 방어 방법을 능가하며, 5개의 LLM과 6개의 데이터셋에서 높은 정밀도를 달성하였습니다.

Conclusion: Rennervate는 새로운 공격에도 전이 가능하고, 적응형 적에 대해 강력함을 입증하였습니다.

Abstract: Large Language Models (LLMs) have been integrated into many applications (e.g., web agents) to perform more sophisticated tasks. However, LLM-empowered applications are vulnerable to Indirect Prompt Injection (IPI) attacks, where instructions are injected via untrustworthy external data sources. This paper presents Rennervate, a defense framework to detect and prevent IPI attacks. Rennervate leverages attention features to detect the covert injection at a fine-grained token level, enabling precise sanitization that neutralizes IPI attacks while maintaining LLM functionalities. Specifically, the token-level detector is materialized with a 2-step attentive pooling mechanism, which aggregates attention heads and response tokens for IPI detection and sanitization. Moreover, we establish a fine-grained IPI dataset, FIPI, to be open-sourced to support further research. Extensive experiments verify that Rennervate outperforms 15 commercial and academic IPI defense methods, achieving high precision on 5 LLMs and 6 datasets. We also demonstrate that Rennervate is transferable to unseen attacks and robust against adaptive adversaries.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [25] [SABER: Small Actions, Big Errors -- Safeguarding Mutating Steps in LLM Agents](https://arxiv.org/abs/2512.07850)
*Alejandro Cuadron,Pengfei Yu,Yang Liu,Arpit Gupta*

Main category: cs.LG

TL;DR: LLM 에이전트의 성능이 긴 기간과 도구 사용 작업에서 여전히 불안정함을 시사하는 연구


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 취약성을 이해하고자 하며, 모든 행동이 실패에 동일하게 기여하는지 질문한다.

Method: 행동 궤적을 변이(환경 변화) 단계와 비변이 단계로 분해하고 결정적 편차를 공식화하며, 로지스틱 회귀를 통해 변이 행동에서의 편차가 성공 확률에 미치는 영향을 분석한다.

Result: 변이 행동의 추가적인 편차는 항공사에서 최대 92%, 소매업에서 최대 96%까지 성공 확률을 감소시킨다. 반면, 비변이 행동의 편차는 거의 영향을 미치지 않는다.

Conclusion: 행동 수준 분석, 타겟 가드, 신뢰할 수 있는 평가가 강력한 다중 턴 에이전트를 위한 필수 조건임을 주장하며, 새로운 benchmark인 $τ$-Bench Verified를 제시한다.

Abstract: Despite rapid progress in LLM agents, performance on long-horizon, tool-using tasks remains fragile. To better understand this fragility, we ask a simple question: \emph{do all actions contribute equally to failure?} Analyzing execution traces on $τ$-Bench (Airline/Retail) and SWE-Bench Verified, we decompose trajectories into \emph{mutating} (environment-changing) vs.\ non-mutating steps and formalize \emph{decisive deviations}, earliest action, level divergences that flip success to failure. A logistic regression reveals that each additional deviation in a mutating action reduces the odds of success by upto $92\%$ on Airline and upto $96\%$ on Retail for SoTA models. In contrast, deviations in non-mutating actions have little to no effect. Errors also grow with context length as agents drift from role and act on stale constraints. Motivated by these observations, we introduce \cm{}, a model-agnostic, gradient-free, test-time safeguard that (i) adds mutation-gated verification, (ii) injects \emph{Targeted Reflection} before mutating steps, and (iii) performs block-based context cleaning. \cm{} delivers consistent gains, e.g., Qwen3-Thinking: +28\% \emph{relative} on Airline, +11\% on Retail, and +7\% on SWE-Bench Verified; Claude: +9\%/+7\%. We further identify ceiling effects in $τ$-Bench, where annotation errors and underspecified tasks artificially cap model performance. To address this, we release $τ$-Bench Verified, which restores benchmark headroom through targeted revisions. Our results argue for action-level analysis, targeted safeguards, and reliable evaluations as prerequisites for robust multi-turn agents.

</details>


### [26] [GPU Memory Prediction for Multimodal Model Training](https://arxiv.org/abs/2512.07853)
*Jinwoo Jeong,Minchul Kang,Younghun Go,Changyong Shin,Hyunho Lee,Junho Yoon,Gyeongsik Yang,Chuck Yoo*

Main category: cs.LG

TL;DR: 이 논문에서는 다중 모달 모델의 GPU 메모리 사용량 예측을 위한 프레임워크를 제안하고, 이를 통해 GPU 메모리 부족 문제를 해결하려고 한다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 모델이 증가함에 따라 GPU 메모리 요구 사항이 높아지고, 메모리 부족 오류(OoM)가 발생함.

Method: 모델 아키텍처와 훈련 행동을 분석하여 다중 모달 모델의 최대 GPU 메모리 사용량을 예측하는 프레임워크를 제안

Result: 우리 프레임워크는 약 8.7% 평균 MAPE로 높은 예측 정확도를 달성한다.

Conclusion: 따라서, 이 프레임워크는 다중 모달 모델의 GPU 메모리 사용량 예측을 개선하여 OoM 문제를 줄이는 데 기여할 수 있다.

Abstract: As deep learning models in agentic AI systems grow in scale and complexity, GPU memory requirements increase and often exceed the available GPU memory capacity, so that out-of-memory (OoM) errors occur. It is well known that OoM interrupts the whole training itself and wastes substantial computational resources. Therefore, to prevent OoM, accurate prediction of GPU memory usage is essential. However, previous studies focus only on unimodal architectures and fail to generalize to multimodal models, even though the multimodal models are a common choice in agentic AI systems. To address this limitation, we propose a framework that predicts the peak GPU memory usage by analyzing the model architecture and training behavior of multimodal models. Specifically, the framework decomposes the multimodal model into its constituent layers and applies factorization to estimate the memory usage of each layer. Our evaluation shows that our framework achieves high prediction accuracy of ~8.7% average MAPE.

</details>


### [27] [SetAD: Semi-Supervised Anomaly Learning in Contextual Sets](https://arxiv.org/abs/2512.07863)
*Jianling Gao,Chongyang Tao,Xuelian Lin,Junfeng Liu,Shuai Ma*

Main category: cs.LG

TL;DR: SetAD라는 새로운 프레임워크를 제안하여 반지도 비정상 탐지 문제를 집합 수준으로 재구성하고, 주목 기반의 집합 인코더를 이용하여 비정상성을 정량화한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 반지도 비정상 탐지 방법들은 포인트나 간단한 쌍에 집중되어 있어 비정상 현상의 맥락적인 특성을 간과하고, 집합의 조합으로부터 생성되는 감독 신호들을 활용하지 못한다.

Method: SetAD는 반지도 비정상 탐지를 집합 수준 비정상 탐지 작업으로 재구성하며, 평정된 학습 목표를 통해 훈련된 주목 기반 집합 인코더를 사용한다.

Result: 10개의 실제 데이터셋에서 SetAD가 최신의 모델들을 크게 초월하는 성능을 보였다.

Conclusion: 우리 모델은 집합 크기가 증가함에 따라 성능이 일관되게 향상되어, 비정상 탐지를 위한 집합 기반 공식화에 대한 강력한 경험적 지지를 제공한다.

Abstract: Semi-supervised anomaly detection (AD) has shown great promise by effectively leveraging limited labeled data. However, existing methods are typically structured around scoring individual points or simple pairs. Such {point- or pair-centric} view not only overlooks the contextual nature of anomalies, which are defined by their deviation from a collective group, but also fails to exploit the rich supervisory signals that can be generated from the combinatorial composition of sets. Consequently, such models struggle to exploit the high-order interactions within the data, which are critical for learning discriminative representations. To address these limitations, we propose SetAD, a novel framework that reframes semi-supervised AD as a Set-level Anomaly Detection task. SetAD employs an attention-based set encoder trained via a graded learning objective, where the model learns to quantify the degree of anomalousness within an entire set. This approach directly models the complex group-level interactions that define anomalies. Furthermore, to enhance robustness and score calibration, we propose a context-calibrated anomaly scoring mechanism, which assesses a point's anomaly score by aggregating its normalized deviations from peer behavior across multiple, diverse contextual sets. Extensive experiments on 10 real-world datasets demonstrate that SetAD significantly outperforms state-of-the-art models. Notably, we show that our model's performance consistently improves with increasing set size, providing strong empirical support for the set-based formulation of anomaly detection.

</details>


### [28] [Using Text-Based Life Trajectories from Swedish Register Data to Predict Residential Mobility with Pretrained Transformers](https://arxiv.org/abs/2512.07865)
*Philipp Stark,Alexandros Sopasakis,Ola Hall,Markus Grillitsch*

Main category: cs.LG

TL;DR: 이 논문은 스웨덴의 대규모 등록 데이터를 텍스트 형태의 삶의 경로로 변환하여 고차원 카테고리 변수와 코딩 방식의 일관성 문제를 해결하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 고차원 카테고리 변수와 시간에 따른 코딩 방식의 일관성 문제는 데이터 분석에서 오랫동안 제기된 두 가지 도전 과제입니다.

Method: 등록 데이터를 690만 개인의 동적 정보로 전환하고, 다양한 NLP 아키텍처를 비교하여 거주지 이동성을 예측합니다.

Result: 순차적 및 변환기 기반 모델이 시간적 및 의미적 구조를 더 효과적으로 캡처함을 발견했습니다.

Conclusion: 이 연구는 의미가 풍부한 등록 데이터를 현대 언어 모델과 결합하는 것이 사회 과학의 종적 분석을 상당히 발전시킬 수 있음을 보여줍니다.

Abstract: We transform large-scale Swedish register data into textual life trajectories to address two long-standing challenges in data analysis: high cardinality of categorical variables and inconsistencies in coding schemes over time. Leveraging this uniquely comprehensive population register, we convert register data from 6.9 million individuals (2001-2013) into semantically rich texts and predict individuals' residential mobility in later years (2013-2017). These life trajectories combine demographic information with annual changes in residence, work, education, income, and family circumstances, allowing us to assess how effectively such sequences support longitudinal prediction. We compare multiple NLP architectures (including LSTM, DistilBERT, BERT, and Qwen) and find that sequential and transformer-based models capture temporal and semantic structure more effectively than baseline models. The results show that textualized register data preserves meaningful information about individual pathways and supports complex, scalable modeling. Because few countries maintain longitudinal microdata with comparable coverage and precision, this dataset enables analyses and methodological tests that would be difficult or impossible elsewhere, offering a rigorous testbed for developing and evaluating new sequence-modeling approaches. Overall, our findings demonstrate that combining semantically rich register data with modern language models can substantially advance longitudinal analysis in social sciences.

</details>


### [29] [Advancing physiological time series reconstruction and imputation via mixture of receptive fields and experts fusion](https://arxiv.org/abs/2512.07873)
*Ci Zhang,Huayu Li,Changdi Yang,Jiangnan Xia,Yanzhi Wang,Xiaolong Ma,Jin Lu,Geng Yuan*

Main category: cs.LG

TL;DR: 의료 시계열 데이터에서 확산 모델을 활용한 신호 복원이 유망하나, 높은 노이즈와 변동성으로 인해 어려움이 있다. 우리는 새로운 Mixture of Experts (MoE) 기반 노이즈 추정기를 제안하며, 이 방식은 성능 향상과 계산 비용 절감을 동시에 달성한다.


<details>
  <summary>Details</summary>
Motivation: 의료 시계열 데이터에서 신호 복원의 가능성을 탐구하고, 높은 노이즈와 변동성 때문에 기존의 딥러닝 접근 방식이 어렵다는 점을 해결하고자 한다.

Method: RFAMoE 모듈을 사용하여 각 채널이 확산 과정에서 원하는 수용장을 선택하도록 하고, Fusion MoE 모듈을 통해 K개의 노이즈 신호를 동시에 생성하여 경량화된 방식으로 복원 작업을 수행한다.

Result: 제안된 프레임워크가 다양한 작업과 데이터세트에서 기존의 확산 기반 SOTA 기술보다 일관되게 우수한 성능을 보인다.

Conclusion: 이 방법은 계산 비용과 지연 시간을 줄이면서 기존 방법보다 향상된 성능을 제공한다.

Abstract: Recent studies show that using diffusion models for time series signal reconstruc- tion holds great promise. However, such approaches remain largely unexplored in the domain of medical time series. The unique characteristics of the physiological time series signals, such as multivariate, high temporal variability, highly noisy, and artifact-prone, make deep learning-based approaches still challenging for tasks such as imputation. Hence, we propose a novel Mixture of Experts (MoE)-based noise estimator within a score-based diffusion framework. Specifically, the Receptive Field Adaptive MoE (RFAMoE) module is designed to enable each channel to adap- tively select desired receptive fields throughout the diffusion process. Moreover, recent literature has found that when generating a physiological signal, performing multiple inferences and averaging the reconstructed signals can effectively reduce reconstruction errors, but at the cost of significant computational and latency over- head. We design a Fusion MoE module and innovatively leverage the nature of MoE module to generate K noise signals in parallel, fuse them using a routing mechanism, and complete signal reconstruction in a single inference step. This design not only improves performance over previous methods but also eliminates the substantial computational cost and latency associated with multiple inference processes. Extensive results demonstrate that our proposed framework consistently outperforms diffusion-based SOTA works on different tasks and datasets.

</details>


### [30] [Controllable risk scenario generation from human crash data for autonomous vehicle testing](https://arxiv.org/abs/2512.07874)
*Qiujing Lu,Xuanhan Wang,Runze Yuan,Wei Lu,Xinyi Gong,Shuo Feng*

Main category: cs.LG

TL;DR: CRAG는 자율주행차의 안전성을 보장하기 위한 위험 행동 생성 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 자율주행차의 안전성을 보장하기 위해서는 일상 주행과 드물지만 안전에 중요한 조건에서의 철저한 테스트가 필요하다.

Method: CRAG는 정상적 행동과 드문 안전-critical 행동의 모델링을 통합하는 프레임워크로, 구조화된 잠재 공간을 구성하여 정상 및 위험 행동을 분리한다.

Result: CRAG는 기존 기준선과 비교할 때 다양성을 개선하고 자율주행차의 강인성을 평가하기 위해 위험 시나리오의 제어 가능한 생성을 가능하게 한다.

Conclusion: CRAG는 향상된 데이터 사용과 위험 인지 잠재 표현 결합을 통해 자율주행차의 안전성 평가에서 효율적인 테스트를 가능하게 한다.

Abstract: Ensuring the safety of autonomous vehicles (AV) requires rigorous testing under both everyday driving and rare, safety-critical conditions. A key challenge lies in simulating environment agents, including background vehicles (BVs) and vulnerable road users (VRUs), that behave realistically in nominal traffic while also exhibiting risk-prone behaviors consistent with real-world accidents. We introduce Controllable Risk Agent Generation (CRAG), a framework designed to unify the modeling of dominant nominal behaviors and rare safety-critical behaviors. CRAG constructs a structured latent space that disentangles normal and risk-related behaviors, enabling efficient use of limited crash data. By combining risk-aware latent representations with optimization-based mode-transition mechanisms, the framework allows agents to shift smoothly and plausibly from safe to risk states over extended horizons, while maintaining high fidelity in both regimes. Extensive experiments show that CRAG improves diversity compared to existing baselines, while also enabling controllable generation of risk scenarios for targeted and efficient evaluation of AV robustness.

</details>


### [31] [Benchmarking Offline Multi-Objective Reinforcement Learning in Critical Care](https://arxiv.org/abs/2512.08012)
*Aryaman Bansal,Divya Sharma*

Main category: cs.LG

TL;DR: 이 연구는 의료 분야에서의 다목적 강화 학습(MORL) 알고리즘을 평가하여, 정적인 보상 기반 의사결정 모델보다 더 유연하고 개인화된 의사결정을 지원함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 중환자실과 같은 중증 치료 환경에서 의사들은 환자 생존율을 극대화하면서 자원 사용(예: 병원에 머무는 기간)을 최소화해야 하는 복잡한 문제에 직면해 있다.

Method: 세 가지 오프라인 MORL 알고리즘(CPQL, Adaptive CPQL, PEDA DT)을 MIMIC-IV 데이터셋을 사용하여 세 가지 스칼라 단일 목표 기준(BC, CQL, DDQN)과 비교 평가하였다.

Result: PEDA DT 알고리즘은 정적 스칼라 기준에 비해 우수한 유연성을 제공함을 Off-Policy Evaluation (OPE) 메트릭을 통해 입증하였다.

Conclusion: 오프라인 MORL은 중환자 치료에서 개인화되고 조정 가능한 의사결정을 지원하는 유망한 프레임워크임을 시사한다.

Abstract: In critical care settings such as the Intensive Care Unit, clinicians face the complex challenge of balancing conflicting objectives, primarily maximizing patient survival while minimizing resource utilization (e.g., length of stay). Single-objective Reinforcement Learning approaches typically address this by optimizing a fixed scalarized reward function, resulting in rigid policies that fail to adapt to varying clinical priorities. Multi-objective Reinforcement Learning (MORL) offers a solution by learning a set of optimal policies along the Pareto Frontier, allowing for dynamic preference selection at test time. However, applying MORL in healthcare necessitates strict offline learning from historical data.
  In this paper, we benchmark three offline MORL algorithms, Conditioned Conservative Pareto Q-Learning (CPQL), Adaptive CPQL, and a modified Pareto Efficient Decision Agent (PEDA) Decision Transformer (PEDA DT), against three scalarized single-objective baselines (BC, CQL, and DDQN) on the MIMIC-IV dataset. Using Off-Policy Evaluation (OPE) metrics, we demonstrate that PEDA DT algorithm offers superior flexibility compared to static scalarized baselines. Notably, our results extend previous findings on single-objective Decision Transformers in healthcare, confirming that sequence modeling architectures remain robust and effective when scaled to multi-objective conditioned generation. These findings suggest that offline MORL is a promising framework for enabling personalized, adjustable decision-making in critical care without the need for retraining.

</details>


### [32] [Scalable Offline Model-Based RL with Action Chunks](https://arxiv.org/abs/2512.08108)
*Kwanyoung Park,Seohong Park,Youngwoon Lee,Sergey Levine*

Main category: cs.LG

TL;DR: 본 연구에서는 오프라인 강화 학습에서 복잡하고 긴 범위의 작업을 해결하기 위한 확장 가능한 방법으로 모델 기반 가치 확장을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 모델 기반 강화 학습이 특히 복잡한 장기 과제를 처리하는데 효과적인지 확인하고자 합니다.

Method: 우리는 '액션 청크' 모델을 사용하여 단일 액션 대신 일련의 액션을 기반으로 미래 상태를 예측하며, 반응 샘플링을 활용하여 과거 행동을 바탕으로 정책을 향상시킵니다.

Result: 대규모 데이터셋을 통한 실험에서 모델 기반 RL 알고리즘 중 최고의 성능을 기록했습니다.

Conclusion: 마지막으로, 우리는 액션 청크를 활용한 모델 기반 RL이 특히 중첩 오류를 줄이면서도 장기적 과제를 보다 잘 해결할 수 있음을 보였습니다.

Abstract: In this paper, we study whether model-based reinforcement learning (RL), in particular model-based value expansion, can provide a scalable recipe for tackling complex, long-horizon tasks in offline RL. Model-based value expansion fits an on-policy value function using length-n imaginary rollouts generated by the current policy and a learned dynamics model. While larger n reduces bias in value bootstrapping, it amplifies accumulated model errors over long horizons, degrading future predictions. We address this trade-off with an \emph{action-chunk} model that predicts a future state from a sequence of actions (an "action chunk") instead of a single action, which reduces compounding errors. In addition, instead of directly training a policy to maximize rewards, we employ rejection sampling from an expressive behavioral action-chunk policy, which prevents model exploitation from out-of-distribution actions. We call this recipe \textbf{Model-Based RL with Action Chunks (MAC)}. Through experiments on highly challenging tasks with large-scale datasets of up to 100M transitions, we show that MAC achieves the best performance among offline model-based RL algorithms, especially on challenging long-horizon tasks.

</details>


### [33] [Improving the Sensitivity of Backdoor Detectors via Class Subspace Orthogonalization](https://arxiv.org/abs/2512.08129)
*Guangmingmei Yang,David J. Miller,George Kesidis*

Main category: cs.LG

TL;DR: 이 논문에서는 백도어 공격 탐지의 민감도를 높이기 위한 새로운 접근 방식으로 Class Subspace Orthogonalization (CSO)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 백도어 탐지 방법들은 공격받은 모델이 목표 클래스에 대해 극단적인 이상치 탐지 통계치를 보여야 한다는 가정에 의존하고 있으며, 이는 특정 상황에서 실패할 수 있다.

Method: 우리는 주어진 클래스에 대한 탐지 통계치를 최적화하는 동안 고유한 특성을 억제하는 제약 최적화 문제를 형성하고, 적은 수의 진정한 예제를 활용하여 이를 수행한다.

Result: 이 방법을 통해 목표 클래스는 백도어 트리거의 기여로 인해 여전히 중요한 탐지 통계치를 유지할 수 있으며, 비목표 클래스는 그 통계치가 크게 감소한다.

Conclusion: CSO 접근 방식은 혼합 라벨과 적응형 공격에 대한 강력한 평가를 통해 그 유효성을 입증하였다.

Abstract: Most post-training backdoor detection methods rely on attacked models exhibiting extreme outlier detection statistics for the target class of an attack, compared to non-target classes. However, these approaches may fail: (1) when some (non-target) classes are easily discriminable from all others, in which case they may naturally achieve extreme detection statistics (e.g., decision confidence); and (2) when the backdoor is subtle, i.e., with its features weak relative to intrinsic class-discriminative features. A key observation is that the backdoor target class has contributions to its detection statistic from both the backdoor trigger and from its intrinsic features, whereas non-target classes only have contributions from their intrinsic features. To achieve more sensitive detectors, we thus propose to suppress intrinsic features while optimizing the detection statistic for a given class. For non-target classes, such suppression will drastically reduce the achievable statistic, whereas for the target class the (significant) contribution from the backdoor trigger remains. In practice, we formulate a constrained optimization problem, leveraging a small set of clean examples from a given class, and optimizing the detection statistic while orthogonalizing with respect to the class's intrinsic features. We dub this plug-and-play approach Class Subspace Orthogonalization (CSO) and assess it against challenging mixed-label and adaptive attacks.

</details>


### [34] [Robust Agents in Open-Ended Worlds](https://arxiv.org/abs/2512.08139)
*Mikayel Samvelyan*

Main category: cs.LG

TL;DR: 이 논문은 AI 에이전트의 강력함과 일반화를 향상시키기 위한 다양한 방법론을 탐구하며, MiniHack과 Maestro를 통해 새로운 환경과 과제를 생성하고, 다중 에이전트 도메인에서의 강건성을 연구합니다.


<details>
  <summary>Details</summary>
Motivation: AI의 다양한 응용 프로그램에서의 증가하는 사용은 끊임없이 변화하는 환경에 성공적으로 적응할 수 있는 에이전트의 필요성을 강조하고 있습니다.

Method: MiniHack과 Maestro를 활용하여 RL 에이전트를 훈련시키고 평가하는 방법론을 사용합니다.

Result: MiniHack을 통해 새로운 과제를 생성하고, Maestro를 통해 RL 에이전트의 강건성과 일반성을 향상시키는 적대적 교육 과정을 생성했습니다.

Conclusion: 이 연구는 AI의 강건성 향상을 위한 새로운 방향성을 제시하며, 예기치 않은 도전과 상호작용에 직면했을 때에도 효과적으로 적응할 수 있는 에이전트의 개발을 가능하게 합니다.

Abstract: The growing prevalence of artificial intelligence (AI) in various applications underscores the need for agents that can successfully navigate and adapt to an ever-changing, open-ended world. A key challenge is ensuring these AI agents are robust, excelling not only in familiar settings observed during training but also effectively generalising to previously unseen and varied scenarios. In this thesis, we harness methodologies from open-endedness and multi-agent learning to train and evaluate robust AI agents capable of generalising to novel environments, out-of-distribution inputs, and interactions with other co-player agents. We begin by introducing MiniHack, a sandbox framework for creating diverse environments through procedural content generation. Based on the game of NetHack, MiniHack enables the construction of new tasks for reinforcement learning (RL) agents with a focus on generalisation. We then present Maestro, a novel approach for generating adversarial curricula that progressively enhance the robustness and generality of RL agents in two-player zero-sum games. We further probe robustness in multi-agent domains, utilising quality-diversity methods to systematically identify vulnerabilities in state-of-the-art, pre-trained RL policies within the complex video game football domain, characterised by intertwined cooperative and competitive dynamics. Finally, we extend our exploration of robustness to the domain of LLMs. Here, our focus is on diagnosing and enhancing the robustness of LLMs against adversarial prompts, employing evolutionary search to generate a diverse range of effective inputs that aim to elicit undesirable outputs from an LLM. This work collectively paves the way for future advancements in AI robustness, enabling the development of agents that not only adapt to an ever-evolving world but also thrive in the face of unforeseen challenges and interactions.

</details>


### [35] [Transformers for Multimodal Brain State Decoding: Integrating Functional Magnetic Resonance Imaging Data and Medical Metadata](https://arxiv.org/abs/2512.08462)
*Danial Jafarzadeh Jazi,Maryam Hajiesmaeili*

Main category: cs.LG

TL;DR: 본 논문은 DICOM 메타데이터와 fMRI 데이터를 통합한 새로운 변환기 기반 프레임워크를 제안하여 뇌 상태를 디코딩하는 방법을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: fMRI 데이터에서 뇌 상태를 디코딩하는 것은 신경과학 및 임상 응용 프로그램 발전에 필수적입니다.

Method: 변환기 기반 아키텍처와 DICOM 메타데이터를 포함한 다중 모달 입력을 통합한 새로운 프레임워크를 제안합니다.

Result: 제안된 방법은 주의 메커니즘을 사용하여 복잡한 공간-시간 패턴과 맥락적 관계를 포착하여 모델의 정확성, 해석 가능성 및 견고성을 향상시킵니다.

Conclusion: 이 프레임워크는 임상 진단, 인지 신경과학 및 개인 맞춤형 의학에서의 응용 가능성을 가지고 있으며, 메타데이터 변동성과 계산 요구 사항 등의 한계를 다루고 앞으로의 확장성과 일반화 가능성을 최적화하기 위한 방향성을 논의합니다.

Abstract: Decoding brain states from functional magnetic resonance imaging (fMRI) data is vital for advancing neuroscience and clinical applications. While traditional machine learning and deep learning approaches have made strides in leveraging the high-dimensional and complex nature of fMRI data, they often fail to utilize the contextual richness provided by Digital Imaging and Communications in Medicine (DICOM) metadata. This paper presents a novel framework integrating transformer-based architectures with multimodal inputs, including fMRI data and DICOM metadata. By employing attention mechanisms, the proposed method captures intricate spatial-temporal patterns and contextual relationships, enhancing model accuracy, interpretability, and robustness. The potential of this framework spans applications in clinical diagnostics, cognitive neuroscience, and personalized medicine. Limitations, such as metadata variability and computational demands, are addressed, and future directions for optimizing scalability and generalizability are discussed.

</details>


### [36] [Optimal Perturbation Budget Allocation for Data Poisoning in Offline Reinforcement Learning](https://arxiv.org/abs/2512.08485)
*Junnan Qiu,Jie Li*

Main category: cs.LG

TL;DR: 오프라인 강화 학습은 정적 데이터셋에서 정책 최적화를 가능하게 하지만 데이터 변조 공격에 취약하다. 본 논문에서는 글로벌 예산 할당 공격 전략을 제안하며, 샘플의 TD 오류에 비례하는 영향을 활용하여 글로벌 자원 할당 문제로 공격을 공식화한다. 실험 결과, 우리의 방법이 기존 전략보다 유의미하게 성능을 향상시킨다는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존의 데이터 변조 공격 전략이 비효율적이고 은밀하지 않다는 문제를 해결하고자 한다.

Method: 샘플의 TD 오류 민감도를 기반으로 글로벌 L2 제약 하에 변조 크기를 할당하는 폐쇄형 솔루션을 도출한다.

Result: D4RL 벤치마크에서 우리의 방법이 기존 전략 대비 최대 80% 성능 저하를 기록하며, 최소한의 변조로 고급 통계 및 스펙트럼 방어를 회피한다는 것을 보여준다.

Conclusion: 본 논문은 데이터 변조 공격에 대한 효과적인 접근법을 제시하며, 이를 통해 오프라인 강화 학습의 취약성을 개선할 가능성을 제시한다.

Abstract: Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to data poisoning attacks. Existing attack strategies typically rely on locally uniform perturbations, which treat all samples indiscriminately. This approach is inefficient, as it wastes the perturbation budget on low-impact samples, and lacks stealthiness due to significant statistical deviations. In this paper, we propose a novel Global Budget Allocation attack strategy. Leveraging the theoretical insight that a sample's influence on value function convergence is proportional to its Temporal Difference (TD) error, we formulate the attack as a global resource allocation problem. We derive a closed-form solution where perturbation magnitudes are assigned proportional to the TD-error sensitivity under a global L2 constraint. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms baseline strategies, achieving up to 80% performance degradation with minimal perturbations that evade detection by state-of-the-art statistical and spectral defenses.

</details>


### [37] [Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents](https://arxiv.org/abs/2512.08870)
*Xiang Chen,Yuling Shi,Qizhen Lan,Yuchao Qiu,Xiaodong Gu*

Main category: cs.LG

TL;DR: LLM 에이전트의 자가 진화를 위한 연합 학습 프레임워크인 Fed-SE를 제안하며, 이는 다양한 환경에서의 성과 향상을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트는 복잡한 상호작용 작업에서 널리 사용되지만, 개인 정보 보호 제한 때문에 중앙 집중식 최적화와 동적 환경에서의 공진화가 어려워진다.

Method: Fed-SE는 필터링 된 고수익 궤적에서 매개변수 효율적인 미세 조정을 사용하여 안정적인 그래디언트 업데이트를 달성하는 로컬 진화-글로벌 집계 패러다임을 수립한다.

Result: 다섯 개의 이종 환경에서 실험한 결과, Fed-SE는 연합 기준선보다 평균 작업 성공률을 약 18% 향상시켰다.

Conclusion: Fed-SE는 개인 정보 보호가 요구되는 배치에서 강력한 환경 간 지식 전이를 지원하는 효율성을 입증했다.

Abstract: LLM agents are widely deployed in complex interactive tasks, yet privacy constraints often preclude centralized optimization and co-evolution across dynamic environments. While Federated Learning (FL) has proven effective on static datasets, its extension to the open-ended self-evolution of agents remains underexplored. Directly applying standard FL is challenging: heterogeneous tasks and sparse, trajectory-level rewards introduce severe gradient conflicts, destabilizing the global optimization process. To bridge this gap, we propose Fed-SE, a Federated Self-Evolution framework for LLM agents. Fed-SE establishes a local evolution-global aggregation paradigm. Locally, agents employ parameter-efficient fine-tuning on filtered, high-return trajectories to achieve stable gradient updates. Globally, Fed-SE aggregates updates within a low-rank subspace that disentangles environment-specific dynamics, effectively reducing negative transfer across clients. Experiments across five heterogeneous environments demonstrate that Fed-SE improves average task success rates by approximately 18% over federated baselines, validating its effectiveness in robust cross-environment knowledge transfer in privacy-constrained deployments.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [38] [MARINE: Theoretical Optimization and Design for Multi-Agent Recursive IN-context Enhancement](https://arxiv.org/abs/2512.07898)
*Hongwei Zhang,Ji Lu,Yongsheng Du,Yanqin Gao,Lingjun Huang,Baoli Wang,Fang Tan,Peng Zou*

Main category: cs.MA

TL;DR: MARINE 프레임워크는 LLM 기반 에이전트의 추론 능력을 향상시키기 위해 테스트 시간 추론을 반복적인 개선으로 재구성하며, 685B 매개변수를 사용하는 구현이 46.0% pass@1 정확도를 기록하였다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트는 고급 추론 능력을 보여주지만, 실제 제약으로 인해 단일 응답으로 제한되며 성능 잠재력이 실현되지 않는다.

Method: MARINE(다중 에이전트 재귀적 맥락 강화)는 기존의 일회성 또는 다중 샘플 패러다임과 근본적으로 차별화되는 이론적으로 근거 있는 프레임워크로, 참조 경로의 지속적인 반복 개선을 통해 추론을 재구성한다.

Result: BrowserComp-ZH 벤치마크에서의 포괄적인 평가 결과, 685B 매개변수가 46.0%의 pass@1 정확도를 기록하며 최신 성과를 달성했다.

Conclusion: 고정된 계산 예산 내에서 MARINE은 기존의 샘플링 및 정렬 전략보다 높은 품질의 샘플을 제공하며, 후속 훈련 효율성을 높일 수 있는 큰 잠재력을 가지고 있다.

Abstract: Large Language Model (LLM)-based agents demonstrate advanced reasoning capabilities, yet practical constraints frequently limit outputs to single responses, leaving significant performance potential unrealized. This paper introduces MARINE (Multi-Agent Recursive IN-context Enhancement), a theoretically grounded framework that reconceptualizes test-time reasoning as iterative refinement of a persistent reference trajectory, fundamentally departing from conventional one-shot or multi-sample paradigms. The MARINE refinement operator systematically converts a base model's pass@N capabilities into near-optimal pass@1 performance. Rigorous theoretical analysis establishes that minimal feasible batches maximize expected performance gains under fixed invocation budgets, while logarithmically growing batch schedules ensure continuous improvement without computational constraints. Comprehensive evaluation on the BrowserComp-ZH benchmark demonstrates state-of-the-art results, with a 685B-parameter implementation achieving 46.0% pass@1 accuracy. Meanwhile, MARINE establishes a new paradigm for parameter-efficient reasoning: an 80B-parameter model augmented with MARINE matches the performance of standalone 1000B-parameter agents, reducing parameter requirements by over an order of magnitude. Notably, within a fixed computational budget, the proposed MARINE delivers higher-quality samples to alignment and optimization processes than traditional sampling-and-ranking strategies. Consequently, it has great potential to boost post-training efficiency.

</details>


### [39] [Probabilistic Multi-Agent Aircraft Landing Time Prediction](https://arxiv.org/abs/2512.08281)
*Kyungmin Kim,Seokbin Yoon,Keumjin Lee*

Main category: cs.MA

TL;DR: 항공기 착륙 시간 예측의 정확성과 신뢰성이 중요하지만, 항공기 궤적과 교통 흐름의 불확실성이 예측의 정확성과 신뢰성에 도전 과제를 제기한다. 본 연구에서는 다중 항공기를 위한 확률적 착륙 시간 예측 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 항공기 착륙 시간 예측의 정확성과 신뢰성은 항공 교통 관리에서 효과적인 자원 배분을 위해 필수적이다.

Method: 확률적 다중 에이전트 항공기 착륙 시간 예측 프레임워크를 제안하여 여러 항공기의 착륙 시간을 분포로 제공한다.

Result: 제안한 모델이 베이스라인보다 높은 예측 정확성을 달성하고 결과의 불확실성을 정량화함을 보여준다.

Conclusion: 모델은 주의 점수를 통해 항공 교통 관제의 기본 패턴을 밝혀내어 설명 가능성을 향상시킨다.

Abstract: Accurate and reliable aircraft landing time prediction is essential for effective resource allocation in air traffic management. However, the inherent uncertainty of aircraft trajectories and traffic flows poses significant challenges to both prediction accuracy and trustworthiness. Therefore, prediction models should not only provide point estimates of aircraft landing times but also the uncertainties associated with these predictions. Furthermore, aircraft trajectories are frequently influenced by the presence of nearby aircraft through air traffic control interventions such as radar vectoring. Consequently, landing time prediction models must account for multi-agent interactions in the airspace. In this work, we propose a probabilistic multi-agent aircraft landing time prediction framework that provides the landing times of multiple aircraft as distributions. We evaluate the proposed framework using an air traffic surveillance dataset collected from the terminal airspace of the Incheon International Airport in South Korea. The results demonstrate that the proposed model achieves higher prediction accuracy than the baselines and quantifies the associated uncertainties of its outcomes. In addition, the model uncovered underlying patterns in air traffic control through its attention scores, thereby enhancing explainability.

</details>
