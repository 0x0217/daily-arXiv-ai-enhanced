<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 21]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CR](#cs.CR) [Total: 4]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Variational Quantum Circuit-Based Reinforcement Learning for Dynamic Portfolio Optimization](https://arxiv.org/abs/2601.18811)
*Vincent Gurgul,Ying Chen,Stefan Lessmann*

Main category: cs.LG

TL;DR: 이 논문은 변분 양자 회로에 기반한 동적 포트폴리오 최적화 문제에 대한 양자 강화 학습(QRL) 솔루션을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 양자 강화 학습의 가능성과 기존의 고전적인 강화 학습 모델과의 비교를 통해 포트폴리오 최적화를 개선하고자 한다.

Method: 고전 신경망 기반의 심층 결정적 정책 기울기 및 심층 Q 네트워크 알고리즘의 양자 아날로그로 QRL 접근 방식을 구현한다.

Result: 실제 금융 데이터를 통해 양자 에이전트가 위험 조정 성과에서 고전적인 심층 강화 학습 모델과 비교해 동등하거나, 경우에 따라 초과하는 성과를 달성함을 보여준다.

Conclusion: QRL은 이론적으로 첨단 고전 강화 학습과 경쟁력을 가지며, 배포 오버헤드가 줄어들면 실질적인 이점을 가질 수 있다.

Abstract: This paper presents a Quantum Reinforcement Learning (QRL) solution to the dynamic portfolio optimization problem based on Variational Quantum Circuits. The implemented QRL approaches are quantum analogues of the classical neural-network-based Deep Deterministic Policy Gradient and Deep Q-Network algorithms. Through an empirical evaluation on real-world financial data, we show that our quantum agents achieve risk-adjusted performance comparable to, and in some cases exceeding, that of classical Deep RL models with several orders of magnitude more parameters. In addition to improved parameter efficiency, quantum agents exhibit reduced variability across market regimes, indicating robust behaviour under changing conditions. However, while quantum circuit execution is inherently fast at the hardware level, practical deployment on cloud-based quantum systems introduces substantial latency, making end-to-end runtime currently dominated by infrastructural overhead and limiting practical applicability. Taken together, our results suggest that QRL is theoretically competitive with state-of-the-art classical reinforcement learning and may become practically advantageous as deployment overheads diminish. This positions QRL as a promising paradigm for dynamic decision-making in complex, high-dimensional, and non-stationary environments such as financial markets. The complete codebase is released as open source at: https://github.com/VincentGurgul/qrl-dpo-public

</details>


### [2] [From Internal Diagnosis to External Auditing: A VLM-Driven Paradigm for Online Test-Time Backdoor Defense](https://arxiv.org/abs/2601.19448)
*Binyan Xu,Fan Yang,Xilin Dai,Di Tang,Kehuan Zhang*

Main category: cs.LG

TL;DR: 딥 뉴럴 네트워크는 백도어 공격에 취약하다. 기존의 방어 방법은 모델 수리나 입력 강건성과 같은 내부 진단 방법에 의존하나, 이러한 방법은 복잡한 공격에 취약하다. 우리는 외부 의미 감사로의 패러다임 전환을 제안하며, 효과적인 방어는 독립적인 감사자를 통해 피해 모델과의 안전성을 분리해야 한다고 주장한다. 이 목적을 위해 보편적인 비전-언어 모델(VLM)을 활용하는 프레임워크, PRISM을 제시하고, 이는 두 가지 주요 메커니즘을 통해 일반 VLM의 도메인 간 갭을 극복한다. PRISM은 17개의 데이터셋과 11개의 공격 유형을 통해 최첨단 성능을 달성하며, CIFAR-10에 대한 공격 성공률을 <1%로 억제하고 깨끗한 정확도를 향상시켜 모델 비전의 외부 보안 기준을 세운다.


<details>
  <summary>Details</summary>
Motivation: 딥 뉴럴 네트워크는 백도어 공격에 취약하며 기존 방어 방법은 효과적이지 않다.

Method: PRISM은 일반 비전-언어 모델을 변화하는 의미의 게이트키퍼로 활용하고, 하이브리드 VLM 교사와 적응형 라우터를 통해 기능한다.

Result: PRISM은 17개 데이터셋과 11개 공격 유형에서 최첨단 성능을 발휘하며, CIFAR-10에서 공격 성공률을 <1%로 억제하고 깨끗한 정확도를 향상시킨다.

Conclusion: PRISM은 모델 비특정적인 외부 보안의 새로운 기준을 설정한다.

Abstract: Deep Neural Networks remain inherently vulnerable to backdoor attacks. Traditional test-time defenses largely operate under the paradigm of internal diagnosis methods like model repairing or input robustness, yet these approaches are often fragile under advanced attacks as they remain entangled with the victim model's corrupted parameters. We propose a paradigm shift from Internal Diagnosis to External Semantic Auditing, arguing that effective defense requires decoupling safety from the victim model via an independent, semantically grounded auditor. To this end, we present a framework harnessing Universal Vision-Language Models (VLMs) as evolving semantic gatekeepers. We introduce PRISM (Prototype Refinement & Inspection via Statistical Monitoring), which overcomes the domain gap of general VLMs through two key mechanisms: a Hybrid VLM Teacher that dynamically refines visual prototypes online, and an Adaptive Router powered by statistical margin monitoring to calibrate gating thresholds in real-time. Extensive evaluation across 17 datasets and 11 attack types demonstrates that PRISM achieves state-of-the-art performance, suppressing Attack Success Rate to <1% on CIFAR-10 while improving clean accuracy, establishing a new standard for model-agnostic, externalized security.

</details>


### [3] [Time series forecasting with Hahn Kolmogorov-Arnold networks](https://arxiv.org/abs/2601.18837)
*Md Zahidul Hasan,A. Ben Hamza,Nizar Bouguila*

Main category: cs.LG

TL;DR: HaKAN은 다변량 시계열 예측을 위한 새로운 모델로, 최근의 Transformer 및 MLP 모델보다 우수한 성능을 발휘한다.


<details>
  <summary>Details</summary>
Motivation: Transformer와 MLP 모델이 긴 시계열 예측에서 뛰어난 성능을 보이지만, Transformer는 제곱 복잡성과 순열 변환 주의(attention)로 제한되며, MLP는 스펙트럼 편향(spectral bias)을 보인다.

Method: HaKAN은 Kolmogorov-Arnold Networks(KAN)를 기반으로 한 다목적 모델로, Hahn 다항식 기반의 학습 가능한 활성화 함수를 활용하고, 경량화 및 해석 가능성이 뛰어난 다변량 시계열 예측 대안을 제공한다.

Result: 우리 모델은 다양한 예측 벤치마크에서 최근 최첨단 방법들을 일관되게 능가하며, 구성 요소들의 효과를 검증하는 ablation 연구도 실시했다.

Conclusion: HaKAN은 글로벌 및 로컬 시간 패턴을 효과적으로 캡쳐할 수 있으며, 잔여 연결을 가진 Hahn-KAN 블록 쌓기로 구성되어 있다.

Abstract: Recent Transformer- and MLP-based models have demonstrated strong performance in long-term time series forecasting, yet Transformers remain limited by their quadratic complexity and permutation-equivariant attention, while MLPs exhibit spectral bias. We propose HaKAN, a versatile model based on Kolmogorov-Arnold Networks (KANs), leveraging Hahn polynomial-based learnable activation functions and providing a lightweight and interpretable alternative for multivariate time series forecasting. Our model integrates channel independence, patching, a stack of Hahn-KAN blocks with residual connections, and a bottleneck structure comprised of two fully connected layers. The Hahn-KAN block consists of inter- and intra-patch KAN layers to effectively capture both global and local temporal patterns. Extensive experiments on various forecasting benchmarks demonstrate that our model consistently outperforms recent state-of-the-art methods, with ablation studies validating the effectiveness of its core components.

</details>


### [4] [How Is Uncertainty Propagated in Knowledge Distillation?](https://arxiv.org/abs/2601.18909)
*Ziyao Cui,Jian Pei*

Main category: cs.LG

TL;DR: 이 논문은 지식 증류 과정에서의 불확실성 전파를 체계적으로 연구하고, 단일 응답의 지식 증류가 내부 학생 분산을 억제하고 지속적인 학생 변동성을 남기는 한계를 해결하기 위한 간단한 보정 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 지식 증류의 불확실성을 이해하고 이를 보정하는 것이 중요하다.

Method: 학생 모델의 훈련과 추론 과정에서의 불확실성을 체계적으로 분석하고, 두 가지 분산 인지 전략을 도입한다.

Result: 제안된 방법을 통해 신경망에서의 검증 및 LLM 증류에서의 경험적 향상을 이끌어냈다.

Conclusion: 분산 인지 증류는 지식 증류를 불확실성 변환으로 재구성하고, 더 안정적인 학생 모델을 생성하여 교사 불확실성을 더 잘 반영한다.

Abstract: Knowledge distillation transfers behavior from a teacher to a student model, but the process is inherently stochastic: teacher outputs, student training, and student inference can all be random. Collapsing these uncertainties to a single point estimate can distort what is learned. We systematically study how uncertainty propagates through knowledge distillation across three representative model classes--linear regression, feed-forward neural networks, and large language models (LLMs)--and propose simple corrections. We distinguish inter-student uncertainty (variance across independently distilled students) from intra-student uncertainty (variance of a single student's predictive distribution), showing that standard single-response knowledge distillation suppresses intra-student variance while leaving substantial inter-student variability. To address these mismatches, we introduce two variance-aware strategies: averaging multiple teacher responses, which reduces noise at rate $O(1/k)$, and variance-weighting, which combines teacher and student estimates via inverse-variance weighting to yield a minimum-variance estimator. We provide formal guarantees in linear regression, validate the methods in neural networks, and demonstrate empirical gains in LLM distillation, including reduced systematic noise and hallucination. These results reframe knowledge distillation as an uncertainty transformation and show that variance-aware distillation produces more stable students that better reflect teacher uncertainty.

</details>


### [5] [GraIP: A Benchmarking Framework For Neural Graph Inverse Problems](https://arxiv.org/abs/2601.18917)
*Semih Cantürk,Andrei Manolache,Arman Mielke,Chendi Qian,Antoine Siraudin,Christopher Morris,Mathias Niepert,Guy Wolf*

Main category: cs.LG

TL;DR: 이 논문은 Neural Graph Inverse Problem (GraIP) 개념적 프레임워크를 제안하여 다양한 그래프 학습 작업을 역문제로 재구성하고 이를 통해 그래프 구조 학습의 통일된 이론적 기초를 마련하는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 그래프 구조를 데이터로부터 유추하는 그래프 학습 작업은 많이 존재하지만, 이러한 작업을 해결하기 위한 방법이 개별적으로 개발되어 통합된 이론적 기반이 부족하다.

Method: Neural Graph Inverse Problem (GraIP) 프레임워크를 도입하여 다양한 그래프 학습 작업을 역문제로 재구성하고 이를 통해 근본적인 그래프 구조를 회복하는 방법을 제시한다.

Result: GraIP는 리와이어링, 인과 발견, 신경 관계 추론 등 다양한 그래프 학습 작업에서 그 다재다능성을 입증하였고, 각각의 GraIP 도메인에 대한 벤치마크 데이터 세트와 지표를 제안하였다.

Conclusion: 우리는 GraIP를 통해 기존의 다양한 방법이 서로 교류할 수 있도록 하여 제약된 조합 설정에서 구조적 학습에 대한 원칙적인 접근 방식을 제공하며, 서로 다른 응용 기법들을 연결하는 통일된 관점을 제시한다.

Abstract: A wide range of graph learning tasks, such as structure discovery, temporal graph analysis, and combinatorial optimization, focus on inferring graph structures from data, rather than making predictions on given graphs. However, the respective methods to solve such problems are often developed in an isolated, task-specific manner and thus lack a unifying theoretical foundation. Here, we provide a stepping stone towards the formation of such a foundation and further development by introducing the Neural Graph Inverse Problem (GraIP) conceptual framework, which formalizes and reframes a broad class of graph learning tasks as inverse problems. Unlike discriminative approaches that directly predict target variables from given graph inputs, the GraIP paradigm addresses inverse problems, i.e., it relies on observational data and aims to recover the underlying graph structure by reversing the forward process, such as message passing or network dynamics, that produced the observed outputs. We demonstrate the versatility of GraIP across various graph learning tasks, including rewiring, causal discovery, and neural relational inference. We also propose benchmark datasets and metrics for each GraIP domain considered, and characterize and empirically evaluate existing baseline methods used to solve them. Overall, our unifying perspective bridges seemingly disparate applications and provides a principled approach to structural learning in constrained and combinatorial settings while encouraging cross-pollination of existing methods across graph inverse problems.

</details>


### [6] [Toward Learning POMDPs Beyond Full-Rank Actions and State Observability](https://arxiv.org/abs/2601.18930)
*Seiji Shaw,Travis Manderson,Chad Kessens,Nicholas Roy*

Main category: cs.LG

TL;DR: 이 논문은 숨겨진 상태를 가진 시스템에 대한 독립적인 에이전트의 학습 및 추론 가능성을 다룬다. 우리는 이 문제를 이산 부분 관찰 마르코프 결정 과정(POMDP)의 매개변수를 학습하는 것으로 설정하고, PSR(예측 상태 표현)을 통한 방법과 텐서 분해 방법을 결합하여 숨겨진 상태에 대한 전이 및 관찰 가능성을 추정하는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 숨겨진 잠금 메커니즘과 같은 숨겨진 상태를 가진 시스템에 대해 독립적인 에이전트가 학습하고 추론할 수 있도록 하는 것에 관심이 있다.

Method: POMDP의 행동 및 관찰 공간에 대한 지식을 가지고 시작하되, 상태 공간, 전이 또는 관찰 모델에 대한 지식은 없다. 우리의 방법은 PSR을 통해 학습하고, 텐서 방법을 활용하여 상태의 파티션에 맞게 전이 및 관찰 행렬을 학습한다.

Result: 우리의 방법으로 학습된 파티션 수준의 전이 모델은 충분한 데이터 양으로 PSR의 성능에 부합한다.

Conclusion: 모델이 학습된 후에는 명시적인 관찰 및 전이 가능성을 활용하여 계획자 행동을 지정할 수 있다.

Abstract: We are interested in enabling autonomous agents to learn and reason about systems with hidden states, such as furniture with hidden locking mechanisms. We cast this problem as learning the parameters of a discrete Partially Observable Markov Decision Process (POMDP). The agent begins with knowledge of the POMDP's actions and observation spaces, but not its state space, transitions, or observation models. These properties must be constructed from action-observation sequences. Spectral approaches to learning models of partially observable domains, such as learning Predictive State Representations (PSRs), are known to directly estimate the number of hidden states. These methods cannot, however, yield direct estimates of transition and observation likelihoods, which are important for many downstream reasoning tasks. Other approaches leverage tensor decompositions to estimate transition and observation likelihoods but often assume full state observability and full-rank transition matrices for all actions. To relax these assumptions, we study how PSRs learn transition and observation matrices up to a similarity transform, which may be estimated via tensor methods. Our method learns observation matrices and transition matrices up to a partition of states, where the states in a single partition have the same observation distributions corresponding to actions whose transition matrices are full-rank. Our experiments suggest that these partition-level transition models learned by our method, with a sufficient amount of data, meets the performance of PSRs as models to be used by standard sampling-based POMDP solvers. Furthermore, the explicit observation and transition likelihoods can be leveraged to specify planner behavior after the model has been learned.

</details>


### [7] [XIMP: Cross Graph Inter-Message Passing for Molecular Property Prediction](https://arxiv.org/abs/2601.19037)
*Anatol Ehrlich,Lorenz Kummer,Vojtech Voracek,Franka Bause,Nils M. Kriege*

Main category: cs.LG

TL;DR: 본 논문에서는 XIMP라는 새로운 메시지 전달 기법을 통해 그래프 뉴럴 네트워크의 성능을 향상시키는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 약물 발견에 있어 정확한 분자 속성 예측의 중요성.

Method: XIMP는 여러 관련 그래프 표현 내외부에서 메시지 전달을 수행하며, 특정한 작은 분자의 경우 분자 그래프를 스캐폴드 인식 정점 트리 및 약물 작용기 인코딩 확장 축소 그래프와 결합합니다.

Result: XIMP는 10개의 다양한 분자 속성 예측 작업에서 대부분의 경우 최신 기술 수준의 기준을 초월하는 성능을 보였습니다.

Conclusion: XIMP는 해석 가능한 추상화를 유도적 편향으로 활용하여 학습을 강화하고 저데이터 환경에서의 일반화를 향상시킵니다.

Abstract: Accurate molecular property prediction is central to drug discovery, yet graph neural networks often underperform in data-scarce regimes and fail to surpass traditional fingerprints. We introduce cross-graph inter-message passing (XIMP), which performs message passing both within and across multiple related graph representations. For small molecules, we combine the molecular graph with scaffold-aware junction trees and pharmacophore-encoding extended reduced graphs, integrating complementary abstractions. While prior work is either limited to a single abstraction or non-iterative communication across graphs, XIMP supports an arbitrary number of abstractions and both direct and indirect communication between them in each layer. Across ten diverse molecular property prediction tasks, XIMP outperforms state-of-the-art baselines in most cases, leveraging interpretable abstractions as an inductive bias that guides learning toward established chemical concepts, enhancing generalization in low-data settings.

</details>


### [8] [Principled Fine-tuning of LLMs from User-Edits: A Medley of Preference, Supervision, and Reward](https://arxiv.org/abs/2601.19055)
*Dipendra Misra,Aldo Pacchiano,Ta-Chung Chi,Ge Gao*

Main category: cs.LG

TL;DR: 사용자 편집 배포 데이터를 사용하여 LLM을 미세 조정하는 방법을 연구합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 작성 도우미 및 코딩 에이전트와 같은 애플리케이션에서 생성된 사용자 편집 데이터는 LLM을 적응시키고 개인화하는 데 유용한 소스입니다.

Method: 사용자 편집에서 학습하는 다양한 피드백 유형(선호도, 감독 레이블 및 비용)을 통합하는 이론적 조사를 진행하고, 단순한 앙상블 절차를 제안하여 이러한 피드백 유형에서 공동으로 학습합니다.

Result: 제안된 앙상블 절차는 개별 피드백에서 학습하는 방법보다 우수하다는 것을 보여줍니다.

Conclusion: 제안한 절차는 테스트 시 다양한 사용자 편집 분포에 강력하게 적응할 수 있습니다.

Abstract: We study how to fine-tune LLMs using user-edit deployment data consisting of a set of context, an agent's response, and user edits. This deployment data is naturally generated by users in applications such as LLMs-based writing assistants and coding agents. The _natural_ origin of user edits makes it a desired source for adapting and personalizing LLMs. In this setup, there emerges a unification of various feedback types namely preferences, supervised labels, and cost that are typically studied separately in the literature. In this paper, we initiate the theoretical investigation of learning from user edits. We first derive bounds for learning algorithms that learn from each of these feedback types. We prove that these algorithms have different trade-offs depending upon the user, data distribution, and model class. We then propose a simple ensembling procedure to jointly learn from these feedback types. On two domains adapted from Gao et al. 2024, we show our ensembling procedure outperforms these methods that learn from individual feedback. Further, we show that our proposed procedure can robustly adapt to different user-edit distributions at test time.

</details>


### [9] [Speed is Confidence](https://arxiv.org/abs/2601.19085)
*Joshua V. Dillon*

Main category: cs.LG

TL;DR: 본 연구는 에너지 제약이 있는 생물학적 신경 시스템의 원리에 따라, 최초 신호에 기반한 예측을 통해 Sudoku-Extreme에서 97.2%의 퍼즐 정확도를 달성하며, 테스트 시간의 증강 방식보다 훨씬 적은 계산력을 사용함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 생물학적 신경 시스템은 빠르게 반응해야 하지만 에너지 제약이 있다.

Method: Tiny Recursive Models (TRM)의 앙상블 예측을 최초로 정지한 신호에 기반하여 수행하고, K=4의 병렬 잠재 상태를 유지하며 훈련을 수행한다.

Result: Sudoku-Extreme에서 97.2%의 퍼즐 정확도 달성, 단일 모델이 96.9%±0.6%의 정확도를 기록하고, 테스트 시간 증강 없이 TTA 성능과 일치하는 결과 도출.

Conclusion: 효율성을 요구하는 실험 환경에서도, 새로운 방식의 SwiGLU를 도입하여 Muon의 실현 가능성을 높였으며, 특정 훈련 단계에서 뛰어난 성능을 달성하였다.

Abstract: Biological neural systems must be fast but are energy-constrained. Evolution's solution: act on the first signal. Winner-take-all circuits and time-to-first-spike coding implicitly treat when a neuron fires as an expression of confidence. We apply this principle to ensembles of Tiny Recursive Models (TRM). By basing the ensemble prediction solely on the first to halt rather than averaging predictions, we achieve 97.2% puzzle accuracy on Sudoku-Extreme while using 10x less compute than test-time augmentation (the baseline achieves 86.1% single-pass, 97.3% with TTA). Inference speed is an implicit indication of confidence. But can this capability be manifested as a training-only cost? Evidently yes: by maintaining K = 4 parallel latent states during training but backpropping only through the lowest-loss "winner," a single model achieves 96.9% +/- 0.6% puzzle accuracy with a single forward pass-matching TTA performance without any test-time augmentation. As in nature, this work was also resource constrained: all experimentation used a single RTX 5090. This necessitated efficiency and compelled our invention of a modified SwiGLU which made Muon viable. With Muon and K = 1 training, we exceed TRM baseline performance in 7k steps (40 min). Higher accuracy requires 36k steps: 1.5 hours for K = 1, 6 hours for K = 4.

</details>


### [10] [Contrast-Source-Based Physics-Driven Neural Network for Inverse Scattering Problems](https://arxiv.org/abs/2601.19243)
*Yutong Du,Zicheng Liu*

Main category: cs.LG

TL;DR: 이 논문은 대조원 기반 물리학 구동 신경망(CSPDNN)을 제안하여 비선형 매핑 문제를 해결하고, 변화하는 대조와 잡음 조건에서 강인한 복원을 위한 적응형 총 변동 손실을 통합함으로써 효율성을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 감독형 DNN 솔버는 대규모 데이터 세트를 필요로 하여 실제 응용에서 일반화가 제한됩니다. 비훈련 신경망(UNN)은 전기장 측정과 기존 물리 지식을 활용하여 가중치를 업데이트함으로써 이 문제를 해결하고자 합니다.

Method: 이 논문은 유도 전류 분포를 예측하는 대조원 기반 물리학 구동 신경망(CSPDNN)을 제안하여 효율성을 높이고 변화하는 대조 및 잡음 조건에서 강인한 복원을 위한 적응형 총 변동 손실을 통합합니다.

Result: 개선된 이미징 성능은 포괄적인 수치 시뮬레이션 및 실험 데이터를 통해 검증되었습니다.

Conclusion: CSPDNN은 기존 UNN 솔버의 긴 추론 시간을 극복하고 효율성을 높이며, 다양한 조건에서도 유용한 결과를 제공합니다.

Abstract: Deep neural networks (DNNs) have recently been applied to inverse scattering problems (ISPs) due to their strong nonlinear mapping capabilities. However, supervised DNN solvers require large-scale datasets, which limits their generalization in practical applications. Untrained neural networks (UNNs) address this issue by updating weights from measured electric fields and prior physical knowledge, but existing UNN solvers suffer from long inference time. To overcome these limitations, this paper proposes a contrast-source-based physics-driven neural network (CSPDNN), which predicts the induced current distribution to improve efficiency and incorporates an adaptive total variation loss for robust reconstruction under varying contrast and noise conditions. The improved imaging performance is validated through comprehensive numerical simulations and experimental data.

</details>


### [11] [Smoothing the Score Function for Generalization in Diffusion Models: An Optimization-based Explanation Framework](https://arxiv.org/abs/2601.19285)
*Xinyu Zhou,Jiawei Zhang,Stephen J. Wright*

Main category: cs.LG

TL;DR: 확산 모델은 탁월한 생성 품질을 달성하지만 학습 샘플을 정확히 복제하는 '기억' 문제에 직면해 있습니다. 이 논문은 이 현상을 설명하는 이론적 틀을 개발하고, 신경망을 사용하여 이 문제를 부분적으로 완화하고 일반화를 개선할 수 있는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 확산 모델의 생성 품질을 높이기 위해 메모리 문제를 해결하고자 함.

Method: 신뢰할 수 있는 이론적 틀을 제공하고 두 가지 새로운 방법, 즉 Noise Unconditioning과 Temperature Smoothing을 제안하여 일반화를 향상시킴.

Result: 신경망을 사용해 경험적 점수 함수의 근사를 통해 더 높은 일반화를 달성하며, 제안된 방법들이 효과적임을 보여줌.

Conclusion: 제안된 방법들이 생성 품질을 유지하면서 일반화를 향상시킨다는 것을 실험을 통해 검증.

Abstract: Diffusion models achieve remarkable generation quality, yet face a fundamental challenge known as memorization, where generated samples can replicate training samples exactly. We develop a theoretical framework to explain this phenomenon by showing that the empirical score function (the score function corresponding to the empirical distribution) is a weighted sum of the score functions of Gaussian distributions, in which the weights are sharp softmax functions. This structure causes individual training samples to dominate the score function, resulting in sampling collapse. In practice, approximating the empirical score function with a neural network can partially alleviate this issue and improve generalization. Our theoretical framework explains why: In training, the neural network learns a smoother approximation of the weighted sum, allowing the sampling process to be influenced by local manifolds rather than single points. Leveraging this insight, we propose two novel methods to further enhance generalization: (1) Noise Unconditioning enables each training sample to adaptively determine its score function weight to increase the effect of more training samples, thereby preventing single-point dominance and mitigating collapse. (2) Temperature Smoothing introduces an explicit parameter to control the smoothness. By increasing the temperature in the softmax weights, we naturally reduce the dominance of any single training sample and mitigate memorization. Experiments across multiple datasets validate our theoretical analysis and demonstrate the effectiveness of the proposed methods in improving generalization while maintaining high generation quality.

</details>


### [12] [Queue Length Regret Bounds for Contextual Queueing Bandits](https://arxiv.org/abs/2601.19300)
*Seoungbin Bae,Garyeong Kang,Dabeen Lee*

Main category: cs.LG

TL;DR: 이 논문에서는 서비스 요금을 학습하면서 작업 스케줄링을 수행하는 새로운 맥락 인식 프레임워크인 컨텍스추얼 큐잉 밴딧을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 서비스 요금을 실시간으로 학습하고 최적화된 작업 스케줄링을 수행하기 위한 방법론 개발.

Method: 작업의 특성과 서버의 매칭을 통해 출발률을 극대화하는 새로운 큐잉 모델을 제안하고, 정책 간의 큐 길이 손실을 분석합니다.

Result: 제안된 알고리즘 CQB-$/4$는 $	ilde{	heta}(T^{-1/4})$의 손실 상한을 달성하며, CQB-Opt는 적대적 상황에서 $	heta(	ext{log}^2 T)$의 손실 상한을 달성합니다.

Conclusion: 이론적 발견을 검증하는 실험 결과를 제공합니다.

Abstract: We introduce contextual queueing bandits, a new context-aware framework for scheduling while simultaneously learning unknown service rates. Individual jobs carry heterogeneous contextual features, based on which the agent chooses a job and matches it with a server to maximize the departure rate. The service/departure rate is governed by a logistic model of the contextual feature with an unknown server-specific parameter. To evaluate the performance of a policy, we consider queue length regret, defined as the difference in queue length between the policy and the optimal policy. The main challenge in the analysis is that the lists of remaining job features in the queue may differ under our policy versus the optimal policy for a given time step, since they may process jobs in different orders. To address this, we propose the idea of policy-switching queues equipped with a sophisticated coupling argument. This leads to a novel queue length regret decomposition framework, allowing us to understand the short-term effect of choosing a suboptimal job-server pair and its long-term effect on queue state differences. We show that our algorithm, CQB-$\varepsilon$, achieves a regret upper bound of $\widetilde{\mathcal{O}}(T^{-1/4})$. We also consider the setting of adversarially chosen contexts, for which our second algorithm, CQB-Opt, achieves a regret upper bound of $\mathcal{O}(\log^2 T)$. Lastly, we provide experimental results that validate our theoretical findings.

</details>


### [13] [Robust Uncertainty Estimation under Distribution Shift via Difference Reconstruction](https://arxiv.org/abs/2601.19341)
*Xinran Xu,Li Rong Wang,Xiuyi Fan*

Main category: cs.LG

TL;DR: 본 연구에서는 딥러닝 모델의 불확실성을 추정하기 위한 DRUE라는 방법을 제안하며, 이는 중간 레이어로부터의 재구성을 활용하여 불확실성을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 고위험 애플리케이션에서 신뢰할 수 있는 의사 결정을 위해 딥러닝 모델의 불확실성 추정이 중요하다.

Method: 입력 샘플을 두 개의 중간 레이어로부터 재구성하고, 그 출력 간의 차이를 불확실성 점수로 사용하는 DRUE 방법을 제안한다.

Result: 글로코마 탐지를 ID 작업으로 하여 여러 OOD 데이터셋에서 DRUE가 지속적으로 우수한 AUC 및 AUPR을 달성함을 입증하였다.

Conclusion: 이 연구는 불확실한 환경에서 모델의 신뢰성을 향상시키기 위한 원칙적이고 효과적인 프레임워크를 제공한다.

Abstract: Estimating uncertainty in deep learning models is critical for reliable decision-making in high-stakes applications such as medical imaging. Prior research has established that the difference between an input sample and its reconstructed version produced by an auxiliary model can serve as a useful proxy for uncertainty. However, directly comparing reconstructions with the original input is degraded by information loss and sensitivity to superficial details, which limits its effectiveness. In this work, we propose Difference Reconstruction Uncertainty Estimation (DRUE), a method that mitigates this limitation by reconstructing inputs from two intermediate layers and measuring the discrepancy between their outputs as the uncertainty score. To evaluate uncertainty estimation in practice, we follow the widely used out-of-distribution (OOD) detection paradigm, where in-distribution (ID) training data are compared against datasets with increasing domain shift. Using glaucoma detection as the ID task, we demonstrate that DRUE consistently achieves superior AUC and AUPR across multiple OOD datasets, highlighting its robustness and reliability under distribution shift. This work provides a principled and effective framework for enhancing model reliability in uncertain environments.

</details>


### [14] [APC-RL: Exceeding Data-Driven Behavior Priors with Adaptive Policy Composition](https://arxiv.org/abs/2601.19452)
*Finn Rietz,Pedro Zuidberg dos Martires,Johannes Andreas Stork*

Main category: cs.LG

TL;DR: 본 연구에서는 강화 학습(RL)에서 시연 데이터를 효과적으로 통합하기 위한 적응형 정책 구성(APC) 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습에서 시연 데이터를 통합하면 학습 속도를 크게 향상시킬 수 있지만, 기존 접근 방식은 시연이 최적이고 목표 작업과 완전히 일치한다고 가정한다.

Method: 적응형 정책 구성(APC)이라는 계층적 모델을 통해 여러 데이터 기반의 정규화 흐름(NF) 사전 정보를 적응적으로 구성한다.

Result: APC는 다양한 기준에서 시연이 일치할 때 학습을 가속화하고, 심각한 불일치에서도 강건성을 유지하며, 하위 최적의 시연을 활용해 탐색을 부트스트랩한다.

Conclusion: APC는 하위 최적의 시연 데이터를 사용할 때 성능 저하를 피하며, 불일치한 사전을 피할 수 있도록 한다.

Abstract: Incorporating demonstration data into reinforcement learning (RL) can greatly accelerate learning, but existing approaches often assume demonstrations are optimal and fully aligned with the target task. In practice, demonstrations are frequently sparse, suboptimal, or misaligned, which can degrade performance when these demonstrations are integrated into RL. We propose Adaptive Policy Composition (APC), a hierarchical model that adaptively composes multiple data-driven Normalizing Flow (NF) priors. Instead of enforcing strict adherence to the priors, APC estimates each prior's applicability to the target task while leveraging them for exploration. Moreover, APC either refines useful priors, or sidesteps misaligned ones when necessary to optimize downstream reward. Across diverse benchmarks, APC accelerates learning when demonstrations are aligned, remains robust under severe misalignment, and leverages suboptimal demonstrations to bootstrap exploration while avoiding performance degradation caused by overly strict adherence to suboptimal demonstrations.

</details>


### [15] [Explicit Multi-head Attention for Inter-head Interaction in Large Language Models](https://arxiv.org/abs/2601.19611)
*Runyu Peng,Yunhua Zhou,Demin Song,Kai Lv,Bo Wang,Qipeng Guo,Xipeng Qiu*

Main category: cs.LG

TL;DR: 이 논문에서는 다중 헤드 명시적 주의(MEA)를 제안하여 대형 언어 모델의 주의 성능을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 변압기 아키텍처 기반 대형 언어 모델에서 헤드 간의 상호작용이 주의 성능을 향상시킬 수 있음에 동기를 부여받았습니다.

Method: MEA는 리니어 조합 모듈과 헤드 수준 그룹 정규화 레이어를 포함하여 교차 헤드 상호작용을 명시적으로 모델링합니다.

Result: MEA는 사전 학습에서 강력한 견고성을 보여주어 더 큰 학습률을 사용할 수 있게 하고, 이로 인해 더 빠른 수렴과 낮은 검증 손실을 달성합니다.

Conclusion: 신뢰할 수 있는 성과를 발휘하며, KV 캐시 메모리 사용을 50% 줄이는 효과를 보여줍니다.

Abstract: In large language models built upon the Transformer architecture, recent studies have shown that inter-head interaction can enhance attention performance. Motivated by this, we propose Multi-head Explicit Attention (MEA), a simple yet effective attention variant that explicitly models cross-head interaction. MEA consists of two key components: a Head-level Linear Composition (HLC) module that separately applies learnable linear combinations to the key and value vectors across heads, thereby enabling rich inter-head communication; and a head-level Group Normalization layer that aligns the statistical properties of the recombined heads. MEA shows strong robustness in pretraining, which allows the use of larger learning rates that lead to faster convergence, ultimately resulting in lower validation loss and improved performance across a range of tasks. Furthermore, we explore the parameter efficiency of MEA by reducing the number of attention heads and leveraging HLC to reconstruct them using low-rank "virtual heads". This enables a practical key-value cache compression strategy that reduces KV-cache memory usage by 50% with negligible performance loss on knowledge-intensive and scientific reasoning tasks, and only a 3.59% accuracy drop for Olympiad-level mathematical benchmarks.

</details>


### [16] [Safe Exploration via Policy Priors](https://arxiv.org/abs/2601.19612)
*Manuel Wendl,Yarden As,Manish Prajapat,Anton Pollak,Stelian Coros,Andreas Krause*

Main category: cs.LG

TL;DR: 이 논문에서는 안전한 탐색 문제를 해결하기 위해 온라인 학습에서의 강화 학습 에이전트의 새로운 접근법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 에이전트가 제어된 환경을 넘어 온라인에서 학습하고 적응하기 위해 필요한 안전한 탐색.

Method: SOOPER라는 접근법은 비관적 정책을 우선시하면서 확률론적 동역학 모델을 활용하여 낙관적으로 탐색합니다.

Result: 실험 결과, SOOPER는 기존 최첨단 기법을 초과 성능을 나타내고 이론적 보장을 검증했습니다.

Conclusion: SOOPER는 학습 과정 전반에 걸쳐 안전성을 보장하며 최적 정책으로의 수렴을 설정합니다.

Abstract: Safe exploration is a key requirement for reinforcement learning (RL) agents to learn and adapt online, beyond controlled (e.g. simulated) environments. In this work, we tackle this challenge by utilizing suboptimal yet conservative policies (e.g., obtained from offline data or simulators) as priors. Our approach, SOOPER, uses probabilistic dynamics models to optimistically explore, yet pessimistically fall back to the conservative policy prior if needed. We prove that SOOPER guarantees safety throughout learning, and establish convergence to an optimal policy by bounding its cumulative regret. Extensive experiments on key safe RL benchmarks and real-world hardware demonstrate that SOOPER is scalable, outperforms the state-of-the-art and validate our theoretical guarantees in practice.

</details>


### [17] [R^3: Replay, Reflection, and Ranking Rewards for LLM Reinforcement Learning](https://arxiv.org/abs/2601.19620)
*Zhizheng Jiang,Kang Zhao,Weikai Xu,Xinkui Lin,Wei Liu,Jian Luan,Shuo Shang,Peng Han*

Main category: cs.LG

TL;DR: 본 논문에서는 LRM의 안정적인 이득 추정을 위한 R^3 강화 학습 메커니즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 문제 해결을 위한 LRM의 안정성과 효율성을 개선하기 위해.

Method: 세 가지 방향으로 진행되는 R^3 메커니즘을 제안: 1) 과거 경로에서의 유용한 사례를 기억하는 크로스 컨텍스트 리플레이 전략, 2) 과거 실패를 활용하여 출력을 정제하는 인컨텍스트 셀프 리플렉션 메커니즘, 3) 토큰 레벨 엔트로피 패턴을 기반으로 응답을 순위화하여 트렁크된 샘플에 상대 보상을 부여하는 구조적 엔트로피 순위 보상.

Result: 제안된 방법이 여러 수학 기준에서 SoTA 성능을 달성함을 입증.

Conclusion: 제안된 방법은 기저 모델에 비해 상당한 개선과 적은 추론 토큰을 나타낸다.

Abstract: Large reasoning models (LRMs) aim to solve diverse and complex problems through structured reasoning. Recent advances in group-based policy optimization methods have shown promise in enabling stable advantage estimation without reliance on process-level annotations. However, these methods rely on advantage gaps induced by high-quality samples within the same batch, which makes the training process fragile and inefficient when intra-group advantages collapse under challenging tasks. To address these problems, we propose a reinforcement learning mechanism named \emph{\textbf{R^3}} that along three directions: (1) a \emph{cross-context \underline{\textbf{R}}eplay} strategy that maintains the intra-group advantage by recalling valuable examples from historical trajectories of the same query, (2) an \emph{in-context self-\underline{\textbf{R}}eflection} mechanism enabling models to refine outputs by leveraging past failures, and (3) a \emph{structural entropy \underline{\textbf{R}}anking reward}, which assigns relative rewards to truncated or failed samples by ranking responses based on token-level entropy patterns, capturing both local exploration and global stability. We implement our method on Deepseek-R1-Distill-Qwen-1.5B and train it on the DeepscaleR-40k in the math domain. Experiments demonstrate our method achieves SoTA performance on several math benchmarks, representing significant improvements and fewer reasoning tokens over the base models. Code and model will be released.

</details>


### [18] [Scalable Exploration for High-Dimensional Continuous Control via Value-Guided Flow](https://arxiv.org/abs/2601.19707)
*Yunyue Wei,Chenhui Zuo,Yanan Sui*

Main category: cs.LG

TL;DR: 이 논문은 생물학적 및 로봇 응용 분야의 고차원 시스템 제어에서의 탐색 문제를 해결하기 위한 Q-guided Flow Exploration(Qflex) 방법을 제안합니다. Qflex는 고차원 액션 공간에서 직접 탐색을 수행하며, 학습된 가치 함수에 의해 유도된 확률 흐름에 따라 행동을 전이합니다.


<details>
  <summary>Details</summary>
Motivation: 생물학적 및 로봇 응용 분야에서 고차원 시스템을 제어하는 것은 방대한 상태-행동 공간 때문입니다. 효과적인 탐색이 매우 중요합니다.

Method: Q-guided Flow Exploration(Qflex)은 학습된 가치 함수에 의해 유도된 확률 흐름을 따라 학습 가능한 소스 분포로부터 행동을 탐색하는 강화 학습 방법입니다.

Result: Qflex는 다양한 고차원 연속 제어 벤치마크에서 대표적인 온라인 강화 학습 기준선을 크게 초월하여 성능을 발휘합니다.

Conclusion: 우리의 결과는 가치 중심 흐름이 대규모 탐색에 대한 원칙적이고 실용적인 경로를 제공함을 나타냅니다.

Abstract: Controlling high-dimensional systems in biological and robotic applications is challenging due to expansive state-action spaces, where effective exploration is critical. Commonly used exploration strategies in reinforcement learning are largely undirected with sharp degradation as action dimensionality grows. Many existing methods resort to dimensionality reduction, which constrains policy expressiveness and forfeits system flexibility. We introduce Q-guided Flow Exploration (Qflex), a scalable reinforcement learning method that conducts exploration directly in the native high-dimensional action space. During training, Qflex traverses actions from a learnable source distribution along a probability flow induced by the learned value function, aligning exploration with task-relevant gradients rather than isotropic noise. Our proposed method substantially outperforms representative online reinforcement learning baselines across diverse high-dimensional continuous-control benchmarks. Qflex also successfully controls a full-body human musculoskeletal model to perform agile, complex movements, demonstrating superior scalability and sample efficiency in very high-dimensional settings. Our results indicate that value-guided flows offer a principled and practical route to exploration at scale.

</details>


### [19] [Component-Aware Pruning Framework for Neural Network Controllers via Gradient-Based Importance Estimation](https://arxiv.org/abs/2601.19794)
*Ganesh Sundaram,Jonas Ulmen,Daniel Görges*

Main category: cs.LG

TL;DR: 이 논문은 신경망 컨트롤러의 복잡성을 줄이기 위해 구성 요소 인식 프루닝 프레임워크를 제안하며, 이는 훈련 중에 세 가지 중요성 지표를 계산하는 데 그래디언트 정보를 활용합니다.


<details>
  <summary>Details</summary>
Motivation: 모놀리식 신경망에서 다중 구성 요소 신경망 아키텍처로의 전환은 높은 계산 복잡도 때문에 상당한 도전을 제기합니다.

Method: 이 논문은 그래디언트 정보를 활용하여 훈련 중에 세 가지 별도의 중요성 지표를 계산하는 구성 요소 인식 프루닝 프레임워크를 도입합니다: 그래디언트 축적, 피셔 정보, 그리고 베이esian 불확실성.

Result: 자동 인코더와 TD-MPC 에이전트에 대한 실험 결과는 제안된 프레임워크가 정적 휴리스틱이 종종 놓치는 중요한 구조적 의존성과 중요성의 동적 변화를 드러냄을 보여줍니다.

Conclusion: 이 프레임워크는 보다 정보에 기반한 압축 결정을 지원합니다.

Abstract: The transition from monolithic to multi-component neural architectures in advanced neural network controllers poses substantial challenges due to the high computational complexity of the latter. Conventional model compression techniques for complexity reduction, such as structured pruning based on norm-based metrics to estimate the relative importance of distinct parameter groups, often fail to capture functional significance. This paper introduces a component-aware pruning framework that utilizes gradient information to compute three distinct importance metrics during training: Gradient Accumulation, Fisher Information, and Bayesian Uncertainty. Experimental results with an autoencoder and a TD-MPC agent demonstrate that the proposed framework reveals critical structural dependencies and dynamic shifts in importance that static heuristics often miss, supporting more informed compression decisions.

</details>


### [20] [Unsupervised Learning of Efficient Exploration: Pre-training Adaptive Policies via Self-Imposed Goals](https://arxiv.org/abs/2601.19810)
*Octavio Pappalardo*

Main category: cs.LG

TL;DR: 이 논문은 강화 학습 에이전트가 자신의 목표를 설정하고 추구하여 학습하는 방법을 제안하며, meta-learning 프레임워크 내에서 효율적인 다중 에피소드 탐색 및 적응을 최적화하고, 훈련 커리큘럼을 에이전트의 적응 후 성능의 진화하는 추정으로 안내한다. ULEE라는 비지도 메타 학습 방법을 제시하여 에이전트의 능력의 경계를 유지하면서 목표 생성 전략과 맥락 내 학습자를 결합한다. 결과적으로 ULEE는 새로운 목표와 환경 동역학, 지도 구조에 대한 일반화된 탐색 및 적응 능력을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 비지도 사전 학습은 강화 학습 에이전트에 사전 지식을 제공하고 다운스트림 작업의 학습을 가속화할 수 있다. 인간 발전에 뿌리를 둔 이 연구 방향은 에이전트가 자신의 목표를 설정하고 추구하여 학습하는 방법을 탐구한다.

Method: 우리는 메타 학습 프레임워크 내에서 효율적인 다중 에피소드 탐색 및 적응을 최적화하고, 에이전트의 적응 후 성능의 진화하는 추정으로 훈련 커리큘럼을 안내하는 방법을 제시한다.

Result: XLand-MiniGrid 벤치마크에서 ULEE의 사전 학습은 새로운 목표와 환경 동역학 및 지도 구조에 일반화되는 탐색 및 적응 능력을 향상시킨다.

Conclusion: ULL의 정책은 향상된 제로 샷 및 소수 샷 성능을 달성하고, 더 긴 미세 조정 프로세스를 위한 강력한 초기화를 제공하며, scratch에서 학습하거나 DIAYN 사전 학습 및 대안 커리큘럼 보다 우수한 결과를 나타낸다.

Abstract: Unsupervised pre-training can equip reinforcement learning agents with prior knowledge and accelerate learning in downstream tasks. A promising direction, grounded in human development, investigates agents that learn by setting and pursuing their own goals. The core challenge lies in how to effectively generate, select, and learn from such goals. Our focus is on broad distributions of downstream tasks where solving every task zero-shot is infeasible. Such settings naturally arise when the target tasks lie outside of the pre-training distribution or when their identities are unknown to the agent. In this work, we (i) optimize for efficient multi-episode exploration and adaptation within a meta-learning framework, and (ii) guide the training curriculum with evolving estimates of the agent's post-adaptation performance. We present ULEE, an unsupervised meta-learning method that combines an in-context learner with an adversarial goal-generation strategy that maintains training at the frontier of the agent's capabilities. On XLand-MiniGrid benchmarks, ULEE pre-training yields improved exploration and adaptation abilities that generalize to novel objectives, environment dynamics, and map structures. The resulting policy attains improved zero-shot and few-shot performance, and provides a strong initialization for longer fine-tuning processes. It outperforms learning from scratch, DIAYN pre-training, and alternative curricula.

</details>


### [21] [Neural Neural Scaling Laws](https://arxiv.org/abs/2601.19831)
*Michael Y. Hu,Jane Pan,Ayush Rajesh Jhaveri,Nicholas Lourie,Kyunghyun Cho*

Main category: cs.LG

TL;DR: 신경스케일법칙(Neural scaling laws)은 언어 모델 성능이 연산 증가에 따라 어떻게 향상되는지를 예측한다. 그러나 각기 다른 다운스트림 작업들은 다채로운 스케일링 행동을 보인다. 이 논문에서는 시계열 외삽을 통한 스케일링 법칙 예측을 제안한 신경망 모델인 NeuNeu를 소개하며, 경험적으로 높은 정확도를 달성했다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 다운스트림 성능을 예측하는 기존 방법들은 두 가지 한계가 있다. 첫째, 평균화된 토큰 레벨 손실이 신호를 모호하게 하고, 둘째, 단순한 파라메트릭 모델로는 모든 스케일링 행동을 포착할 수 없다.

Method: NeuNeu는 관측된 정확도 경로의 시간적 맥락과 토큰 레벨의 검증 손실을 결합하여 미래 성능을 예측하는 신경망이다. 이는 병목 현상이나 기능적 형태를 가정하지 않고 학습한다.

Result: NeuNeu는 HuggingFace의 오픈 소스 모델 체크포인트로 전적으로 훈련되어 66개의 다운스트림 작업에서 모델 정확도 예측 시 2.04%의 평균 절대 오차를 달성했으며, 이는 로지스틱 스케일링법칙에 비해 38% 향상된 수치이다.

Conclusion: 데이터로부터 직접 다운스트림 스케일링 법칙을 예측하는 것이 파라메트릭 대안을 초월함을 시사한다.

Abstract: Neural scaling laws predict how language model performance improves with increased compute. While aggregate metrics like validation loss can follow smooth power-law curves, individual downstream tasks exhibit diverse scaling behaviors: some improve monotonically, others plateau, and some even degrade with scale. We argue that predicting downstream performance from validation perplexity suffers from two limitations: averaging token-level losses obscures signal, and no simple parametric family can capture the full spectrum of scaling behaviors. To address this, we propose Neural Neural Scaling Laws (NeuNeu), a neural network that frames scaling law prediction as time-series extrapolation. NeuNeu combines temporal context from observed accuracy trajectories with token-level validation losses, learning to predict future performance without assuming any bottleneck or functional form. Trained entirely on open-source model checkpoints from HuggingFace, NeuNeu achieves 2.04% mean absolute error in predicting model accuracy on 66 downstream tasks -- a 38% reduction compared to logistic scaling laws (3.29% MAE). Furthermore, NeuNeu generalizes zero-shot to unseen model families, parameter counts, and downstream tasks. Our work suggests that predicting downstream scaling laws directly from data outperforms parametric alternatives.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [22] [Agentic Business Process Management Systems](https://arxiv.org/abs/2601.18833)
*Marlon Dumas,Fredrik Milani,David Chapela-Campa*

Main category: cs.AI

TL;DR: 이 논문은 비즈니스 프로세스 관리(BPM) 분야에서 생성적 및 에이전틱 인공지능(AI)의 역할을 강조하며, 데이터 기반 관리를 통해 프로세스 성능을 최적화하는 새로운 아키텍처 비전을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 비즈니스 프로세스 관리(BPM) 분야의 발전과 최신 자동화 기술의 진화를 통해 AI의 등장으로 인해 자율성에 초점을 맞춘 새로운 가능성을 탐구합니다.

Method: 프로세스 마이닝 기술을 활용하여 프로세스 상태를 감지하고, 개선 기회를 분석하며, 성능을 유지 및 최적화하기 위한 에이전트의 행동 개념을 제시합니다.

Result: 에이전틱 비즈니스 프로세스 관리 시스템(A-BPMS)이라는 새로운 플랫폼 클래스를 제안하며, 자율성, 추론, 학습을 통합합니다.

Conclusion: 이 시스템은 사람 중심에서 완전 자율에 이르는 다양한 프로세스를 지원해야 하며, 프로세스 자동화와 거버넌스의 경계를 재정의할 필요성이 있습니다.

Abstract: Since the early 90s, the evolution of the Business Process Management (BPM) discipline has been punctuated by successive waves of automation technologies. Some of these technologies enable the automation of individual tasks, while others focus on orchestrating the execution of end-to-end processes. The rise of Generative and Agentic Artificial Intelligence (AI) is opening the way for another such wave. However, this wave is poised to be different because it shifts the focus from automation to autonomy and from design-driven management of business processes to data-driven management, leveraging process mining techniques. This position paper, based on a keynote talk at the 2025 Workshop on AI for BPM, outlines how process mining has laid the foundations on top of which agents can sense process states, reason about improvement opportunities, and act to maintain and optimize performance. The paper proposes an architectural vision for Agentic Business Process Management Systems (A-BPMS): a new class of platforms that integrate autonomy, reasoning, and learning into process management and execution. The paper contends that such systems must support a continuum of processes, spanning from human-driven to fully autonomous, thus redefining the boundaries of process automation and governance.

</details>


### [23] [More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas](https://arxiv.org/abs/2601.19082)
*Trung-Kiet Huynh,Dao-Sy Duy-Minh,Thanh-Bang Cao,Phong-Hao Le,Hong-Dan Nguyen,Nguyen Lam Phu Quy,Minh-Luan Nguyen-Vo,Hong-Phat Pham,Pham Phu Hoa,Thien-Kim Than,Chi-Nguyen Tran,Huy Tran,Gia-Thoai Tran-Le,Alessio Buscemi,Le Hong Trang,The Anh Han*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델(LLM)의 전략적 행동을 이해하는 것이 안전성, 조정, AI 기반 사회 및 경제 시스템에 중요하다는 점을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 대화형 및 다중 에이전트 환경에서 자율 에이전트로 작용함에 따라 그들의 전략적 행동을 이해하는 것이 필요합니다.

Method: 수익이 조정된 죄수의 딜레마를 사용하여 인센티브 강도에 대한 민감도를 격리하고 반복적인 사회적 딜레마에서 LLM 전략을 조사합니다.

Result: 모델과 언어에 걸쳐 일관된 행동 패턴을 관찰했으며, 인센티브에 민감한 조건부 전략과 언어 간 차이를 발견했습니다.

Conclusion: LLM을 전략적 에이전트로 감사하는 통합 프레임워크를 제공하고 AI 거버넌스 및 다중 에이전트 시스템 설계에 대한 직접적인 시사점을 강조합니다.

Abstract: As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems. We investigate how payoff magnitude and linguistic context shape LLM strategies in repeated social dilemmas, using a payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength. Across models and languages, we observe consistent behavioral patterns, including incentive-sensitive conditional strategies and cross-linguistic divergence. To interpret these dynamics, we train supervised classifiers on canonical repeated-game strategies and apply them to LLM decisions, revealing systematic, model- and language-dependent behavioral intentions, with linguistic framing sometimes matching or exceeding architectural effects. Our results provide a unified framework for auditing LLMs as strategic agents and highlight cooperation biases with direct implications for AI governance and multi-agent system design.

</details>


### [24] [RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures](https://arxiv.org/abs/2601.18924)
*Andrew Jaffe,Noah Reicin,Jinho D. Choi*

Main category: cs.AI

TL;DR: 대형 언어 모델의 지침 수행 능력은 아직 충분히 탐구되지 않았다. RIFT라는 새 테스트 환경을 통해 지침의 구조가 성능에 미치는 영향을 평가하였다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 워크플로우에서 대형 언어 모델의 효율성을 높이기 위해.

Method: 재구성된 Jeopardy! 질문-답변 쌍을 사용해 두 가지 프롬프트 구조(순차적 진행의 선형 프롬프트와 비순차적 탐색의 점핑 프롬프트)에서 LLM을 평가하였다.

Result: 10,000회 평가에서 점핑 조건에서 정확도가 최대 72% 감소하였으며, 이는 정서적 연속성에 강한 의존성을 드러냈다.

Conclusion: 현재 아키텍처의 구조적 민감성이 비순차적 제어 흐름이 필요한 응용 프로그램에서 근본적인 제한점으로 드러났다.

Abstract: Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.

</details>


### [25] [TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning](https://arxiv.org/abs/2601.19151)
*Patara Trirat,Jin Myung Kwak,Jay Heo,Heejun Lee,Sung Ju Hwang*

Main category: cs.AI

TL;DR: TS-Debate는 제로샷 시계열 추론을 위한 다중 에이전트 협력 토론 프레임워크로, 각 모드에 전문화된 에이전트를 통해 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델과 시계열 분석의 발전을 통해 약점과 가능성이 드러났다.

Method: TS-Debate는 텍스트, 시각 패턴, 숫자 신호에 전념하는 전문가 에이전트를 부여하고, 명시적인 도메인 지식 추출을 선행한 후, 구조화된 토론 프로토콜을 통해 상호작용을 조정합니다.

Result: TS-Debate는 20개의 작업에서 강력한 기준선에 비해 일관되고 상당한 성능 향상을 이루었습니다.

Conclusion: 모드 충실성을 유지하며, 갈등 증거를 드러내고, 작업 특정 세밀 조정 없이 숫자 환각을 완화합니다.

Abstract: Recent progress at the intersection of large language models (LLMs) and time series (TS) analysis has revealed both promise and fragility. While LLMs can reason over temporal structure given carefully engineered context, they often struggle with numeric fidelity, modality interference, and principled cross-modal integration. We present TS-Debate, a modality-specialized, collaborative multi-agent debate framework for zero-shot time series reasoning. TS-Debate assigns dedicated expert agents to textual context, visual patterns, and numerical signals, preceded by explicit domain knowledge elicitation, and coordinates their interaction via a structured debate protocol. Reviewer agents evaluate agent claims using a verification-conflict-calibration mechanism, supported by lightweight code execution and numerical lookup for programmatic verification. This architecture preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning. Across 20 tasks spanning three public benchmarks, TS-Debate achieves consistent and significant performance improvements over strong baselines, including standard multimodal debate in which all agents observe all inputs.

</details>


### [26] [LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge](https://arxiv.org/abs/2601.19155)
*Qiujun Li,Zijin Xiao,Xulin Wang,Zhidan Ma,Cheng Yang,Haifeng Li*

Main category: cs.AI

TL;DR: 본 연구에서는 시각적 내용을 기반으로 촬영 위치를 추론하는 이미지 지리적 위치 추정 문제를 다루며, 기존의 방법의 한계를 극복하기 위해 계층적 추론 로직을 유지하면서도 외부 도구에 지리적 증거 검증을 오프로드하는 LocationAgent라는 새로운 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 이미지 지리적 위치 추정의 최신 방법은 사실적 환각과 일반화 병목 현상을 겪고 있다. 이를 해결하기 위해 보다 향상된 방법이 필요하다.

Method: 계층적 추론을 구현하기 위해 RER 아키텍처(Reasoner-Executor-Recorder)를 설계하고, 다양한 증거를 제공하기 위해 클루 탐색 도구를 구축하였다.

Result: LocationAgent는 기존 방법에 비해 제로샷 환경에서 최소 30% 더 뛰어난 성능을 보였다.

Conclusion: 이러한 접근 방식은 이미지 지리적 위치 추정의 정확성을 크게 향상시킨다.

Abstract: Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\% in zero-shot settings.

</details>


### [27] [Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement](https://arxiv.org/abs/2601.19170)
*Wangyang Ying,Yanchi Liu,Xujiang Zhao,Wei Cheng,Zhengzhang Chen,Wenchao Yu,Yanjie Fu,Haifeng Chen*

Main category: cs.AI

TL;DR: 이 논문에서는 자연어에서 절차적 그래프를 자동으로 추출하기 위한 다중 에이전트 프레임워크 model{}을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자연어에서 절차적 그래프를 자동으로 추출하는 것은 유망하지만 구조적 유효성과 논리적 정렬을 동시에 요구하는 미개척 영역입니다.

Method: model{}는 절차적 그래프 추출을 다중 라운드 추론 과정으로 형성하며, 구조적 및 논리적 개선을 전담하는 에이전트를 포함합니다.

Result: 실험 결과, model{}은 강력한 기준 대비 구조적 정확성과 논리적 일관성 모두에서 상당한 개선을 달성했습니다.

Conclusion: 이 모듈식 설계는 에이전트가 감독이나 매개변수 업데이트 없이도 독특한 오류 유형을 타겟으로 삼을 수 있게 합니다.

Abstract: Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.

</details>


### [28] [CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning](https://arxiv.org/abs/2601.19193)
*Van-Quang Nguyen,Takayuki Okatani*

Main category: cs.AI

TL;DR: CoReTab는 다단계 추론과 실행 가능한 Python 코드를 결합하여 멀티모달 테이블 이해를 위한 재현 가능하고 해석 가능한 주석을 자동 생성하는 코드 기반 추론 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 멀티모달 테이블 이해 데이터셋은 명확한 다단계 추론 감독 없이 짧은 사실 기반 답변을 제공해, 모델이 최종 답변에 도달하는 방식을 해석하기 어려웠습니다.

Method: CoReTab 프레임워크를 사용하여 115K 검증된 샘플로 구성된 데이터셋을 수집하고, 오픈 소스 MLLM을 3단계 파이프라인을 통해 미세 조정했습니다.

Result: CoReTab에서 훈련된 모델은 17개의 MMTab 벤치마크에 대해 각각 +6.2%, +5.7%, +25.6%의 유의미한 이득을 달성했습니다.

Conclusion: 이 결과는 CoReTab가 멀티모달 테이블 이해에서 다단계 추론을 개선하기 위한 강력하고 일반화 가능한 감독 프레임워크임을 입증합니다.

Abstract: Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.

</details>


### [29] [MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution](https://arxiv.org/abs/2601.19199)
*Libo Sun,Jiwen Zhang,Siyuan Wang,Zhongyu Wei*

Main category: cs.AI

TL;DR: MAGNET은 안정적인 기능 의미와 작업 의도를 기반으로 한 메모리 구동 적응형 에이전트 프레임워크로, 사용자 인터페이스 변경에도 성능을 유지합니다.


<details>
  <summary>Details</summary>
Motivation: 사용자 인터페이스의 잦은 변경으로 역사적 데이터에 기반해 훈련된 에이전트들이 실패하는 문제를 해결하고자 했습니다.

Method: MAGNET는 다양한 시각적 특성을 안정적인 기능 의미와 연결하는 고정 메모리와 변동하는 작업 흐름에 걸쳐 안정적인 작업 의도를 포착하는 절차적 메모리로 구성된 이중 메모리 체계를 활용합니다. 이 메커니즘은 자주 접근되는 지식을 우선시하여 두 메모리를 지속적으로 다듬습니다.

Result: 온라인 벤치마크 AndroidWorld 평가에서 기준 대비 상당한 개선이 있었고, 오프라인 벤치마크에서도 분포 변화 하에서 일관된 성과를 확인했습니다.

Conclusion: 인터페이스 변화에 걸쳐 안정적인 구조를 활용하면 진화하는 소프트웨어 환경에서 에이전트의 성능과 일반화가 향상됨을 입증했습니다.

Abstract: Mobile GUI agents powered by large foundation models enable autonomous task execution, but frequent updates altering UI appearance and reorganizing workflows cause agents trained on historical data to fail. Despite surface changes, functional semantics and task intents remain fundamentally stable. Building on this insight, we introduce MAGNET, a memory-driven adaptive agent framework with dual-level memory: stationary memory linking diverse visual features to stable functional semantics for robust action grounding and procedural memory capturing stable task intents across varying workflows. We propose a dynamic memory evolution mechanism that continuously refines both memories by prioritizing frequently accessed knowledge. Online benchmark AndroidWorld evaluations show substantial improvements over baselines, while offline benchmarks confirm consistent gains under distribution shifts. These results validate that leveraging stable structures across interface changes improves agent performance and generalization in evolving software environments.

</details>


### [30] [MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning](https://arxiv.org/abs/2601.19204)
*Zhixi Cai,Fucai Ke,Kevin Leo,Sukai Huang,Maria Garcia de la Banda,Peter J. Stuckey,Hamid Rezatofighi*

Main category: cs.AI

TL;DR: MATA는 다중 에이전트 시스템으로 시각적 추론을 위한 계층적 유한 상태 오토마톤을 제공하며, 최상위 전이는 학습 가능한 하이퍼 에이전트에 의해 선택된다.


<details>
  <summary>Details</summary>
Motivation: 최근의 비전-언어 모델은 강력한 지각 능력을 가지고 있지만, 그들의 암묵적 추론은 설명하기 어렵고 복잡한 쿼리에서 환각을 쉽게 생성한다.

Method: MATA는 다중 에이전트 시스템으로 각 에이전트가 하이퍼 오토마톤 내의 상태와 연결되고, 신뢰할 수 있는 마이크로 제어를 위해 작은 규칙 기반 서브 오토마톤을 실행한다. 모든 에이전트는 공유 메모리를 읽고 쓰며, 투명한 실행 이력을 산출한다.

Result: MATA는 모놀리식 및 조합 기준과 비교하여 여러 시각적 추론 벤치마크에서 최첨단 결과를 달성한다.

Conclusion: MATA는 작업 해결을 위해 최적의 에이전트를 효율적으로 선택할 수 있으며, 학습된 LLM이 쿼리와 에이전트의 능력을 이해한다.

Abstract: Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.

</details>


### [31] [GLOVE: Global Verifier for LLM Memory-Environment Realignment](https://arxiv.org/abs/2601.19249)
*Xingkun Yin,Hongyang Du*

Main category: cs.AI

TL;DR: GLOVE는 LLM 메모리 시스템의 새로운 설계 차원을 도입하여 메모리의 일관성을 검증하고 업데이트함으로써 에이전트의 성공률을 크게 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 메모리 강화 LLM 접근 방식은 메모리 유효성이 동적인 환경에서 종종 무너질 수 있음을 시사합니다.

Method: GLOVE는 메모리와 새로운 관찰 간의 불일치를 탐지하기 위한 적극적인 탐사를 통해 메모리-환경 재정렬을 가능하게 합니다.

Result: 우리는 GLOVE가 다양한 벤치마크에서 에이전트의 성공률을 크게 향상시킬 수 있음을 보여줍니다.

Conclusion: 이 연구는 자가 진화하는 인지 에이전트로 나아가는 강력한 경로를 제안합니다.

Abstract: Most existing memory-enhanced Large Language Model (LLM) approaches implicitly assume that memory validity can be established either through external evaluators that provide task-specific success signals or through internal model cognition, such as reflection, for editing memory entries. However, these assumptions often break down in practical environments with dynamic drifts. We propose the Global Verifier (GLOVE), a framework that introduces a new design dimension for LLM memory systems by establishing a relative notion of truth. Through active probing to detect inconsistencies between retrieved memories and fresh observations, GLOVE enables memory-environment realignment by verifying and updating memory without access to ground-truth supervision or strong reliance on model introspection. We evaluate GLOVE on diverse benchmarks spanning web navigation, planning, and control, augmented with controlled environmental drifts that introduce non-stationarity beyond the original benchmark settings. Our results show that GLOVE substantially improves agent success rates, suggesting a robust pathway to cognitive agents capable of self-evolving.

</details>


### [32] [Curiosity Driven Knowledge Retrieval for Mobile Agents](https://arxiv.org/abs/2601.19306)
*Sijia Li,Xiaoyu Tan,Shahir Ali,Niels Schmidt,Gengchen Ma,Xihe Qiu*

Main category: cs.AI

TL;DR: 호기심 기반 지식 검색 프레임워크를 통해 스마트폰 자동화에서의 지식 맹점을 보완하고 계획 신뢰성을 향상시킴.


<details>
  <summary>Details</summary>
Motivation: 복잡한 애플리케이션에서 스마트폰 자동화의 성능 한계를 극복하고자 함.

Method: 호기심 점수가 임계값을 초과할 때 외부 정보를 검색하여 AppCards 형식으로 조직하고, 이를 실행 중에 에이전트가 통합하도록 함.

Result: 평가 결과, 평균 6%의 성장을 보여주었고, GPT-5와 함께 사용할 때 88.8%의 새로운 최고 성공률을 기록함.

Conclusion: AppCards는 특히 다단계 및 교차 애플리케이션 작업에 효과적이며, 모형에 따라 성능 개선이 달라짐을 확인함.

Abstract: Mobile agents have made progress toward reliable smartphone automation, yet performance in complex applications remains limited by incomplete knowledge and weak generalization to unseen environments. We introduce a curiosity driven knowledge retrieval framework that formalizes uncertainty during execution as a curiosity score. When this score exceeds a threshold, the system retrieves external information from documentation, code repositories, and historical trajectories. Retrieved content is organized into structured AppCards, which encode functional semantics, parameter conventions, interface mappings, and interaction patterns. During execution, an enhanced agent selectively integrates relevant AppCards into its reasoning process, thereby compensating for knowledge blind spots and improving planning reliability. Evaluation on the AndroidWorld benchmark shows consistent improvements across backbones, with an average gain of six percentage points and a new state of the art success rate of 88.8\% when combined with GPT-5. Analysis indicates that AppCards are particularly effective for multi step and cross application tasks, while improvements depend on the backbone model. Case studies further confirm that AppCards reduce ambiguity, shorten exploration, and support stable execution trajectories. Task trajectories are publicly available at https://lisalsj.github.io/Droidrun-appcard/.

</details>


### [33] [Balancing Sustainability And Performance: The Role Of Small-Scale Llms In Agentic Artificial Intelligence Systems](https://arxiv.org/abs/2601.19311)
*Anh Khoa Ngo Ho,Martin Chauvin,Simon Gosset,Philippe Cordier,Boris Gamazaychikov*

Main category: cs.AI

TL;DR: 이 연구는 소규모 언어 모델이 다중 에이전트 실제 환경에서 에너지 소비를 줄일 수 있는지 조사한다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 인공지능 시스템에서 대형 언어 모델의 에너지 요구량이 지속 가능성에 도전이 될 수 있다.

Method: 다양한 규모의 언어 모델을 비교 분석하여 효율성과 성능 간의 균형을 정량화한다.

Result: 소규모 오픈 웨이트 모델은 작업 품질을 유지하면서 에너지 사용량을 줄일 수 있음을 보여준다.

Conclusion: 효율적인 인공지능 설계를 위한 현실적인 지침을 제안하며, 이는 환경을 고려한 인공지능 시스템 개발을 위한 실행 가능한 전략을 제공한다.

Abstract: As large language models become integral to agentic artificial intelligence systems, their energy demands during inference may pose significant sustainability challenges. This study investigates whether deploying smaller-scale language models can reduce energy consumption without compromising responsiveness and output quality in a multi-agent, real-world environments. We conduct a comparative analysis across language models of varying scales to quantify trade-offs between efficiency and performance. Results show that smaller open-weights models can lower energy usage while preserving task quality. Building on these findings, we propose practical guidelines for sustainable artificial intelligence design, including optimal batch size configuration and computation resource allocation. These insights offer actionable strategies for developing scalable, environmentally responsible artificial intelligence systems.

</details>


### [34] [Learning Adaptive Parallel Execution for Efficient Code Localization](https://arxiv.org/abs/2601.19568)
*Ke Xu,Siyang Xiao,Ming Liang,Yichen Yu,Zhixiang Wang,Jingxuan Xu,Dajun Chen,Wei Jiang,Yong Li*

Main category: cs.AI

TL;DR: FuseSearch는 코드 로컬라이제이션 과정을 효율성과 품질 최적화 작업으로 재구성하여 자동화된 소프트웨어 개발 파이프라인의 병목 현상을 해결한다.


<details>
  <summary>Details</summary>
Motivation: 코드 로컬라이제이션은 자동화된 소프트웨어 개발 파이프라인에서 중요한 병목 현상이다.

Method: FuseSearch는 도구 효율성의 정의를 통해 적응형 병렬 전략을 학습하기 위한 두 단계의 SFT 및 RL 훈련 접근 방식을 사용하여 병렬 코드 로컬라이제이션을 공동 품질-효율성 최적화 작업으로 재구성한다.

Result: FuseSearch-4B는 84.7	ext{% 파일 수준} 및 56.4	ext{% 함수 수준} F1 점수로 SOTA 수준의 성능을 달성하며, 93.6	ext{% 속도 향상}과 함께 67.7	ext{% 적은 턴}과 68.9	ext{% 적은 토큰}을 사용한다.

Conclusion: 효율성을 고려한 훈련은 자연스럽게 품질을 개선하여 고성능 비용 효율적인 로컬라이제이션 에이전트를 가능하게 한다.

Abstract: Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\% redundant invocation rate, which negates parallelism benefits. We propose \textbf{FuseSearch}, reformulating parallel code localization as a \textbf{joint quality-efficiency optimization} task. Through defining \textbf{tool efficiency} -- the ratio of unique information gain to invocation count -- we utilize a two-phase SFT and RL training approach for learning adaptive parallel strategies. Different from fixed-breadth approaches, FuseSearch dynamically modulates search breadth according to task context, evolving from exploration phases to refinement stages. Evaluated on SWE-bench Verified, FuseSearch-4B achieves SOTA-level performance (84.7\% file-level and 56.4\% function-level $F_1$ scores) with 93.6\% speedup, utilizing 67.7\% fewer turns and 68.9\% fewer tokens. Results indicate that efficiency-aware training naturally improves quality through eliminating noisy redundant signals, enabling high-performance cost-effective localization agents.

</details>


### [35] [ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks](https://arxiv.org/abs/2601.19607)
*Haoyun Li,Ming Xiao,Kezhi Wang,Robert Schober,Dong In Kim,Yong Liang Guan*

Main category: cs.AI

TL;DR: ComAgent는 복잡한 6G 네트워크 최적화를 위해 멀티-LLM 기반의 자율 AI 프레임워크로, 사용자 의도를 해결 가능한 형식으로 변환한다.


<details>
  <summary>Details</summary>
Motivation: 6G 네트워크의 복잡한 크로스 레이어 최적화를 수동으로 처리하는 것은 병목 현상이다.

Method: ComAgent는 폐쇄 루프 인지-계획-행동-반성 사이클을 이용해 문헌 검색, 코딩, 점수를 매기는 전문 에이전트를 조정한다.

Result: ComAgent는 복잡한 빔포밍 최적화에서 전문가에 필적하는 성능을 달성하며 기타 무선 작업에서도 모놀리틱 LLM보다 우수하다.

Conclusion: ComAgent는 신흥 무선 네트워크 설계를 자동화할 수 있는 잠재력을 지닌다.

Abstract: Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.

</details>


### [36] [Agentic Design Patterns: A System-Theoretic Framework](https://arxiv.org/abs/2601.19752)
*Minh-Dung Dao,Quy Minh Le,Hoang Thanh Lam,Duc-Trong Le,Quoc-Viet Pham,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: 이 논문은 강력한 AI 에이전트 설계를 위한 체계적인 방법론을 제시하고, 12가지 에이전틱 디자인 패턴을 도출한다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI 시스템의 설계에서 신뢰성을 높이기 위해 체계적 이론에 기반한 접근이 필요하다.

Method: 시스템 이론적 프레임워크를 통해 에이전틱 AI 시스템을 다섯 개의 핵심 하위 시스템으로 분해하고, 12가지 디자인 패턴을 제안하였다.

Result: ReAct 프레임워크에 대한 사례 연구를 통해 제안된 패턴이 시스템 아키텍처의 결함을 수정할 수 있음을 보여준다.

Conclusion: 이 연구는 에이전틱 디자인 커뮤니케이션을 표준화하기 위한 기초 언어와 구조화된 방법론을 제공한다.

Abstract: With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.

</details>


### [37] [CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing](https://arxiv.org/abs/2601.19793)
*Shanyv Liu,Xuyang Yuan,Tao Chen,Zijun Zhan,Zhu Han,Danyang Zheng,Weishan Zhang,Shaohua Cao*

Main category: cs.AI

TL;DR: 그래프 기반 다중 에이전트 시스템에서 효율적인 동적 모델 선택을 위한 라우터인 CASTER를 제안합니다. CASTER는 작업 난이도를 추정하기 위해 의미 임베딩과 구조적 메타 특징을 결합한 이중 신호 라우터를 사용하며, 자기 최적화를 통해 라우팅 실패로부터 학습합니다. 실험 결과, CASTER는 강력한 모델 기준과 비교하여 추론 비용을 최대 72.4% 줄이면서 성공률을 유지하고, 모든 도메인에서 휴리스틱 라우팅 및 FrugalGPT를 일관되게 초월합니다.


<details>
  <summary>Details</summary>
Motivation: 그래프 기반 다중 에이전트 시스템은 복잡한 순환 워크플로우를 가능하게 하지만, 강력한 모델을 균일하게 배포하는 비효율적인 정적 모델 할당으로 인한 문제점이 있습니다.

Method: CASTER(맥락 인식 전략을 통한 작업 효율적 라우팅)는 작업 난이도를 추정하기 위해 의미 임베딩과 구조적 메타 특징을 결합한 이중 신호 라우터를 사용합니다. 라우터는 Cold Start to Iterative Evolution 패러다임을 통해 자기 최적화를 수행하며, 정책 기반의 부정적인 피드백을 통해 라우팅 실패에서 학습합니다.

Result: 소프트웨어 공학, 데이터 분석, 과학적 발견, 사이버 보안 분야에서 LLM-as-a-Judge 평가를 사용한 실험에서 CASTER는 강력한 모델 기준과 비교할 때 추론 비용을 최대 72.4% 줄이면서 성공률을 유지했습니다.

Conclusion: CASTER는 모든 도메인에서 휴리스틱 라우팅과 FrugalGPT를 일관되게 초월하며, 효율적인 동적 모델 선택을 가능하게 합니다.

Abstract: Graph-based Multi-Agent Systems (MAS) enable complex cyclic workflows but suffer from inefficient static model allocation, where deploying strong models uniformly wastes computation on trivial sub-tasks. We propose CASTER (Context-Aware Strategy for Task Efficient Routing), a lightweight router for dynamic model selection in graph-based MAS. CASTER employs a Dual-Signal Router that combines semantic embeddings with structural meta-features to estimate task difficulty. During training, the router self-optimizes through a Cold Start to Iterative Evolution paradigm, learning from its own routing failures via on-policy negative feedback. Experiments using LLM-as-a-Judge evaluation across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity demonstrate that CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while matching their success rates, and consistently outperforms both heuristic routing and FrugalGPT across all domains.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [38] [Reimagining Peer Review Process Through Multi-Agent Mechanism Design](https://arxiv.org/abs/2601.19778)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.MA

TL;DR: 소프트웨어 공학 연구 커뮤니티는 동료 검토 시스템의 고질적인 문제에 직면해 있다. 이 논문은 이러한 문제들이 계산적 해결책을 통해 해결될 수 있는 메커니즘 설계 실패라고 주장하며, 연구 커뮤니티를 확률적 다중 에이전트 시스템으로 모델링하고 다중 에이전트 강화 학습을 적용하여 인센티브 호환 프로토콜을 설계할 것을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 연구자들은 동료 검토 과정이 "고장났다"고 인식하고 있으며, 이는 점점 증가하는 제출 수와 비효율적인 인센티브, 리뷰어의 피로도에 기인한 문제이다.

Method: 연구 커뮤니티를 확률적 다중 에이전트 시스템으로 모델링하고, 다중 에이전트 강화 학습을 적용하여 인센티브가 호환되는 프로토콜을 설계한다.

Result: 신용 기반 제출 경제, MARL 최적화된 리뷰어 배정 및 검토 일관성의 혼합 검증 등 세 가지 개입 방안을 제시한다.

Conclusion: 이 비전은 지속 가능한 동료 검토를 위한 연구 의제를 제시한다.

Abstract: The software engineering research community faces a systemic crisis: peer review is failing under growing submissions, misaligned incentives, and reviewer fatigue. Community surveys reveal that researchers perceive the process as "broken." This position paper argues that these dysfunctions are mechanism design failures amenable to computational solutions. We propose modeling the research community as a stochastic multi-agent system and applying multi-agent reinforcement learning to design incentive-compatible protocols. We outline three interventions: a credit-based submission economy, MARL-optimized reviewer assignment, and hybrid verification of review consistency. We present threat models, equity considerations, and phased pilot metrics. This vision charts a research agenda toward sustainable peer review.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [39] [GUIGuard: Toward a General Framework for Privacy-Preserving GUI Agents](https://arxiv.org/abs/2601.18842)
*Yanxi Wang,Zhiling Zhang,Wenbo Zhou,Weiming Zhang,Jie Zhang,Qiannan Zhu,Yu Shi,Shuxin Zheng,Jiyan He*

Main category: cs.CR

TL;DR: GUI 에이전트는 화면 인터페이스와의 직접적인 인식 및 상호작용을 통해 엔드투엔드 자동화를 가능하게 하지만, 개인 정보가 포함된 인터페이스에 접근하여 프라이버시 위험을 초래한다. 이를 해결하기 위해 GUIGuard라는 세 단계를 제안하고, GUIGuard-Bench라는 벤치마크를 개발하여 프라이버시 인식 문제를 분석하였다.


<details>
  <summary>Details</summary>
Motivation: GUI 에이전트가 개인 정보에 접근할 때의 프라이버시 위험을 완화하기 위한 필요성.

Method: GUIGuard라는 세 단계로 구성된 프라이버시 보호 프레임워크를 제안하고, GUIGuard-Bench라는 크로스 플랫폼 벤치마크를 구축하여 다양한 인터랙션 경로를 분석하였다.

Result: 기존의 에이전트는 한정된 프라이버시 인식을 보였으며, 최신 모델은 Android에서 13.3%, PC에서 1.4%의 정확도를 기록했다. 프라이버시 보호 하에서도 태스크 플래닝 의미를 유지할 수 있었고, 폐쇄형 모델이 오픈 소스 모델보다 더 강한 의미 일관성을 보였다.

Conclusion: 프라이버시 인식은 실제 GUI 에이전트를 위한 중요한 병목 현상임을 강조한다.

Abstract: GUI agents enable end-to-end automation through direct perception of and interaction with on-screen interfaces. However, these agents frequently access interfaces containing sensitive personal information, and screenshots are often transmitted to remote models, creating substantial privacy risks. These risks are particularly severe in GUI workflows: GUIs expose richer, more accessible private information, and privacy risks depend on interaction trajectories across sequential scenes. We propose GUIGuard, a three-stage framework for privacy-preserving GUI agents: (1) privacy recognition, (2) privacy protection, and (3) task execution under protection. We further construct GUIGuard-Bench, a cross-platform benchmark with 630 trajectories and 13,830 screenshots, annotated with region-level privacy grounding and fine-grained labels of risk level, privacy category, and task necessity. Evaluations reveal that existing agents exhibit limited privacy recognition, with state-of-the-art models achieving only 13.3% accuracy on Android and 1.4% on PC. Under privacy protection, task-planning semantics can still be maintained, with closed-source models showing stronger semantic consistency than open-source ones. Case studies on MobileWorld show that carefully designed protection strategies achieve higher task accuracy while preserving privacy. Our results highlight privacy recognition as a critical bottleneck for practical GUI agents. Project: https://futuresis.github.io/GUIGuard-page/

</details>


### [40] [AgenticSCR: An Autonomous Agentic Secure Code Review for Immature Vulnerabilities Detection](https://arxiv.org/abs/2601.19138)
*Wachiraphan Charoenwet,Kla Tantithamthavorn,Patanamon Thongtanunam,Hong Yi Lin,Minwoo Jeong,Ming Wu*

Main category: cs.CR

TL;DR: AgenticSCR은 사전 커밋 단계에서 미성숙 취약점을 탐지하기 위해 설계된 에이전틱 AI로, 보안 중심의 의미적 기억을 활용하여 기존 도구들을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 사전 커밋 단계에서 취약점을 조기에 발견하는 것이 중요하지만, 기존 SAST 기반 체크는 정확성이 부족하고 많은 취약점을 놓치는 경향이 있다.

Method: AgenticSCR은 LLM과 자율적 의사결정, 도구 호출 및 코드 내비게이션을 결합하여 미성숙 취약점을 탐지하기 위한 에이전틱 AI를 도입한다.

Result: AgenticSCR은 정적 LLM 기반 기준보다 최소 153% 높은 정확도를 보였으며, SAST 도구보다 상당히 우수한 성능을 기록했다.

Conclusion: 이 연구는 미성숙 취약점 탐지 연구 분야의 발전을 촉진하고, 에이전틱 보안 코드 리뷰의 중요성을 강조한다.

Abstract: Secure code review is critical at the pre-commit stage, where vulnerabilities must be caught early under tight latency and limited-context constraints. Existing SAST-based checks are noisy and often miss immature, context-dependent vulnerabilities, while standalone Large Language Models (LLMs) are constrained by context windows and lack explicit tool use. Agentic AI, which combine LLMs with autonomous decision-making, tool invocation, and code navigation, offer a promising alternative, but their effectiveness for pre-commit secure code review is not yet well understood. In this work, we introduce AgenticSCR, an agentic AI for secure code review for detecting immature vulnerabilities during the pre-commit stage, augmented by security-focused semantic memories. Using our own curated benchmark of immature vulnerabilities, tailored to the pre-commit secure code review, we empirically evaluate how accurate is our AgenticSCR for localizing, detecting, and explaining immature vulnerabilities. Our results show that AgenticSCR achieves at least 153% relatively higher percentage of correct code review comments than the static LLM-based baseline, and also substantially surpasses SAST tools. Moreover, AgenticSCR generates more correct comments in four out of five vulnerability types, consistently and significantly outperforming all other baselines. These findings highlight the importance of Agentic Secure Code Review, paving the way towards an emerging research area of immature vulnerability detection.

</details>


### [41] [SHIELD: An Auto-Healing Agentic Defense Framework for LLM Resource Exhaustion Attacks](https://arxiv.org/abs/2601.19174)
*Nirhoshan Sivaroopan,Kanchana Thilakarathna,Albert Zomaya,Manu,Yi Guo,Jo Plested,Tim Lynar,Jack Yang,Wangli Yang*

Main category: cs.CR

TL;DR: SHIELD는 Multi-Agent 기반의 자가 치유 방어 프레임워크로, 공격 전략의 변화에 잘 적응하는 방어 체계를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 스펀지 공격은 LLM 시스템에 대한 위협을 증가시키고 있으며, 기존 방어책은 효과적이지 않음.

Method: SHIELD는 세 단계의 방어 에이전트를 중심으로 하여 의미 유사성 검색, 패턴 매칭, LLM 기반 추론을 통합합니다.

Result: SHIELD는 비단어 의미적 및 의미적 스펀지 공격 모두에서 높은 F1 점수를 기록하며 기존 방어책보다 일관되게 우수한 성능을 보입니다.

Conclusion: SHIELD는 변화하는 리소스 소모 위협에 대한 효과적인 자가 치유를 보여줍니다.

Abstract: Sponge attacks increasingly threaten LLM systems by inducing excessive computation and DoS. Existing defenses either rely on statistical filters that fail on semantically meaningful attacks or use static LLM-based detectors that struggle to adapt as attack strategies evolve. We introduce SHIELD, a multi-agent, auto-healing defense framework centered on a three-stage Defense Agent that integrates semantic similarity retrieval, pattern matching, and LLM-based reasoning. Two auxiliary agents, a Knowledge Updating Agent and a Prompt Optimization Agent, form a closed self-healing loop, when an attack bypasses detection, the system updates an evolving knowledgebase, and refines defense instructions. Extensive experiments show that SHIELD consistently outperforms perplexity-based and standalone LLM defenses, achieving high F1 scores across both non-semantic and semantic sponge attacks, demonstrating the effectiveness of agentic self-healing against evolving resource-exhaustion threats.

</details>


### [42] [CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations](https://arxiv.org/abs/2601.19367)
*Bilel Sefsaf,Abderraouf Dandani,Abdessamed Seddiki,Arab Mohammed,Eduardo Chielle,Michail Maniatakos,Riyadh Baghdadi*

Main category: cs.CR

TL;DR: 본 논문은 딥 강화 학습을 활용하여 완전 동형 암호화(FHE) 코드 최적화를 자동화하는 CHEHAB RL 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: FHE의 높은 계산 비용이 중요한 장벽이며, 효율적인 코드 작성을 위한 암호학적 전문 지식이 필요합니다.

Method: 딥 강화 학습을 이용하여 FHE 코드의 rewriting 규칙을 자동으로 적용하는 효과적인 정책을 학습하는 RL 에이전트를 훈련시킵니다.

Result: 제안된 방법은 실행 속도가 $5.3	imes$ 빠르고, 노이즈 증가가 $2.54	imes$ 적으며, Coyote보다 컴파일 과정이 $27.9	imes$ 빠릅니다.

Conclusion: 제안된 접근 방식은 구조적 및 비구조적 코드 최적화를 지원하여 FHE 코드를 효과적으로 개선합니다.

Abstract: Fully Homomorphic Encryption (FHE) enables computations directly on encrypted data, but its high computational cost remains a significant barrier. Writing efficient FHE code is a complex task requiring cryptographic expertise, and finding the optimal sequence of program transformations is often intractable. In this paper, we propose CHEHAB RL, a novel framework that leverages deep reinforcement learning (RL) to automate FHE code optimization. Instead of relying on predefined heuristics or combinatorial search, our method trains an RL agent to learn an effective policy for applying a sequence of rewriting rules to automatically vectorize scalar FHE code while reducing instruction latency and noise growth. The proposed approach supports the optimization of both structured and unstructured code. To train the agent, we synthesize a diverse dataset of computations using a large language model (LLM). We integrate our proposed approach into the CHEHAB FHE compiler and evaluate it on a suite of benchmarks, comparing its performance against Coyote, a state-of-the-art vectorizing FHE compiler. The results show that our approach generates code that is $5.3\times$ faster in execution, accumulates $2.54\times$ less noise, while the compilation process itself is $27.9\times$ faster than Coyote (geometric means).

</details>
