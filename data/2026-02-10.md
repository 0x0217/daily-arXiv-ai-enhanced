<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 27]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.AI](#cs.AI) [Total: 14]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [RuleSmith: Multi-Agent LLMs for Automated Game Balancing](https://arxiv.org/abs/2602.06232)
*Ziyao Zeng,Chen Liu,Tianyu Liu,Hao Wang,Xiatao Sun,Fengyu Yang,Xiaofeng Liu,Zhiwen Fan*

Main category: cs.LG

TL;DR: RuleSmith는 다중 에이전트 LLM의 추론 능력을 활용하여 게임 밸런싱을 자동화하는 최초의 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 게임 밸런싱은 반복적인 플레이테스트, 전문가 직관 및 광범위한 수동 조정이 필요한 오랜 도전 과제이다.

Method: RuleSmith는 게임 엔진, 다중 에이전트 LLM 자가 플레이 및 다차원 규칙 공간을 운영하는 베이지안 최적화를 결합한다.

Result: 실험 결과, RuleSmith는 매우 균형 잡힌 구성으로 수렴하며, 하류 게임 시스템에 직접 적용할 수 있는 해석 가능한 규칙 조정을 제공한다.

Conclusion: LLM 시뮬레이션은 복잡한 다중 에이전트 환경에서 설계 및 밸런싱을 자동화하는 강력한 대리자로 기능할 수 있음을 보여준다.

Abstract: Game balancing is a longstanding challenge requiring repeated playtesting, expert intuition, and extensive manual tuning. We introduce RuleSmith, the first framework that achieves automated game balancing by leveraging the reasoning capabilities of multi-agent LLMs. It couples a game engine, multi-agent LLMs self-play, and Bayesian optimization operating over a multi-dimensional rule space. As a proof of concept, we instantiate RuleSmith on CivMini, a simplified civilization-style game containing heterogeneous factions, economy systems, production rules, and combat mechanics, all governed by tunable parameters. LLM agents interpret textual rulebooks and game states to generate actions, to conduct fast evaluation of balance metrics such as win-rate disparities. To search the parameter landscape efficiently, we integrate Bayesian optimization with acquisition-based adaptive sampling and discrete projection: promising candidates receive more evaluation games for accurate assessment, while exploratory candidates receive fewer games for efficient exploration. Experiments show that RuleSmith converges to highly balanced configurations and provides interpretable rule adjustments that can be directly applied to downstream game systems. Our results illustrate that LLM simulation can serve as a powerful surrogate for automating design and balancing in complex multi-agent environments.

</details>


### [2] [Agentic Workflow Using RBA$_θ$ for Event Prediction](https://arxiv.org/abs/2602.06097)
*Purbak Sengupta,Sambeet Mishra,Sonal Shreya*

Main category: cs.LG

TL;DR: 이 논문은 바람 발전의 급등 이벤트를 직접 예측하고 전력 궤적을 재구성하는 이벤트 우선, 주파수 인식 예측 패러다임을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 바람 발전 급등 사건은 강한 변화와 다중 스케일의 역학 및 특정 지역의 기상 효과로 인해 예측이 어렵다.

Method: 강화된 Ramp Behaviour Analysis (RBA$_θ$) 방법을 바탕으로 하여 통계적, 머신러닝 및 딥러닝 모델을 점진적으로 통합하는 이벤트 우선 딥 아키텍처를 도입한다.

Result: 랜덤 포레스트를 이용한 직접적인 이벤트 예측이 생존 기반 공식보다 강건성을 향상시키며, 중간 주파수 대역에 의해 급등 크기와 지속 시간이 지배됨을 보여준다.

Conclusion: 이벤트 우선, 주파수 인식 예측이 궤적 우선 바람 발전 예측에 대한 전이 가능하고 운영에 맞는 대안을 제공함을 보여준다.

Abstract: Wind power ramp events are difficult to forecast due to strong variability, multi-scale dynamics, and site-specific meteorological effects. This paper proposes an event-first, frequency-aware forecasting paradigm that directly predicts ramp events and reconstructs the power trajectory thereafter, rather than inferring events from dense forecasts. The framework is built on an enhanced Ramping Behaviour Analysis (RBA$_θ$) method's event representation and progressively integrates statistical, machine-learning, and deep-learning models. Traditional forecasting models with post-hoc event extraction provides a strong interpretable baseline but exhibits limited generalisation across sites. Direct event prediction using Random Forests improves robustness over survival-based formulations, motivating fully event-aware modelling. To capture the multi-scale nature of wind ramps, we introduce an event-first deep architecture that integrates wavelet-based frequency decomposition, temporal excitation features, and adaptive feature selection. The resulting sequence models enable stable long-horizon event prediction, physically consistent trajectory reconstruction, and zero-shot transfer to previously unseen wind farms. Empirical analysis shows that ramp magnitude and duration are governed by distinct mid-frequency bands, allowing accurate signal reconstruction from sparse event forecasts. An agentic forecasting layer is proposed, in which specialised workflows are selected dynamically based on operational context. Together, the framework demonstrates that event-first, frequency-aware forecasting provides a transferable and operationally aligned alternative to trajectory-first wind-power prediction.

</details>


### [3] [Pairwise is Not Enough: Hypergraph Neural Networks for Multi-Agent Pathfinding](https://arxiv.org/abs/2602.06733)
*Rishabh Jain,Keisuke Okumura,Michael Amir,Pietro Lio,Amanda Prorok*

Main category: cs.LG

TL;DR: 본 논문에서는 다중 에이전트 경로 찾기(MAPF)를 해결하기 위한 새로운 방법인 HMAGAT(하이퍼그래프 다중 에이전트 주의 네트워크)를 제안합니다. HMAGAT는 하이퍼그래프를 활용하여 그룹 동역학을 명시적으로 캡처함으로써 기존의 GNN이 가진 제약을 극복하고, 학습 기반의 MAPF 해결기 중 새로운 최첨단 성능을 기록합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 경로 찾기(MAPF)는 충돌 없이 여러 에이전트가 각자의 목표로 내비게이션해야 하는 문제로, 최적 해결이 NP-hard로 알려져 있습니다. 이로 인해 온라인 계산 부담을 덜기 위해 학습 기반 접근 방식이 채택되고 있습니다.

Method: 본 논문에서는 HMAGAT(하이퍼그래프 다중 에이전트 주의 네트워크)라는 새로운 구조를 도입합니다. 이 구조는 방향성 하이퍼그래프에서 주의 메커니즘을 활용하여 그룹 동역학을 명시적으로 캡처합니다.

Result: HMAGAT는 1M 매개변수로 100배 적은 데이터를 학습했음에도 불구하고 기존 85M 매개변수 모델을 초월하는 새로운 최첨단 성능을 입증합니다.

Conclusion: 적절한 귀납적 편향이 다중 에이전트 문제에서 데이터 양이나 매개변수 수보다 더 중요할 수 있음을 보여줍니다.

Abstract: Multi-Agent Path Finding (MAPF) is a representative multi-agent coordination problem, where multiple agents are required to navigate to their respective goals without collisions. Solving MAPF optimally is known to be NP-hard, leading to the adoption of learning-based approaches to alleviate the online computational burden. Prevailing approaches, such as Graph Neural Networks (GNNs), are typically constrained to pairwise message passing between agents. However, this limitation leads to suboptimal behaviours and critical issues, such as attention dilution, particularly in dense environments where group (i.e. beyond just two agents) coordination is most critical. Despite the importance of such higher-order interactions, existing approaches have not been able to fully explore them. To address this representational bottleneck, we introduce HMAGAT (Hypergraph Multi-Agent Attention Network), a novel architecture that leverages attentional mechanisms over directed hypergraphs to explicitly capture group dynamics. Empirically, HMAGAT establishes a new state-of-the-art among learning-based MAPF solvers: e.g., despite having just 1M parameters and being trained on 100$\times$ less data, it outperforms the current SoTA 85M parameter model. Through detailed analysis of HMAGAT's attention values, we demonstrate how hypergraph representations mitigate the attention dilution inherent in GNNs and capture complex interactions where pairwise methods fail. Our results illustrate that appropriate inductive biases are often more critical than the training data size or sheer parameter count for multi-agent problems.

</details>


### [4] [Urban Spatio-Temporal Foundation Models for Climate-Resilient Housing: Scaling Diffusion Transformers for Disaster Risk Prediction](https://arxiv.org/abs/2602.06129)
*Olaf Yunus Laitinen Imanov,Derya Umut Kulali,Taner Yilmaz*

Main category: cs.LG

TL;DR: 기후 위험이 도시 교통 및 응급 대응 작업에 미치는 영향을 예측하는 Skjold-DiT 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 기후 재난이 도시 교통과 응급 대응 작업을 방해하고 인프라를 저하시킬 수 있는 상황에서, 이를 보다 효과적으로 예측하고 대응하기 위한 필요성.

Method: Skjold-DiT는 다양한 시공간 도시 데이터를 통합하여 건물 수준의 기후 위험 지표를 예측하는 확산-변환기 프레임워크입니다. 이는 교통 네트워크 구조와 지능형 차량에 중요한 접근성 신호를 포함합니다.

Result: Skjold-DiT는 위험에 따른 라우팅 제약 조건을 생성하고, 여러 도시 간 전이 및 여러 모드 간 주의 메커니즘을 결합하여 예측 품질 및 교차 도시 일반화를 평가하는 실험을 진행했습니다.

Conclusion: 이 프레임워크는 지능형 차량의 라우팅과 응급 dispatch 시스템에 소비 가능한 신뢰성 있는 접근성 레이어를 제공합니다.

Abstract: Climate hazards increasingly disrupt urban transportation and emergency-response operations by damaging housing stock, degrading infrastructure, and reducing network accessibility. This paper presents Skjold-DiT, a diffusion-transformer framework that integrates heterogeneous spatio-temporal urban data to forecast building-level climate-risk indicators while explicitly incorporating transportation-network structure and accessibility signals relevant to intelligent vehicles (e.g., emergency reachability and evacuation-route constraints). Concretely, Skjold-DiT enables hazard-conditioned routing constraints by producing calibrated, uncertainty-aware accessibility layers (reachability, travel-time inflation, and route redundancy) that can be consumed by intelligent-vehicle routing and emergency dispatch systems. Skjold-DiT combines: (1) Fjell-Prompt, a prompt-based conditioning interface designed to support cross-city transfer; (2) Norrland-Fusion, a cross-modal attention mechanism unifying hazard maps/imagery, building attributes, demographics, and transportation infrastructure into a shared latent representation; and (3) Valkyrie-Forecast, a counterfactual simulator for generating probabilistic risk trajectories under intervention prompts. We introduce the Baltic-Caspian Urban Resilience (BCUR) dataset with 847,392 building-level observations across six cities, including multi-hazard annotations (e.g., flood and heat indicators) and transportation accessibility features. Experiments evaluate prediction quality, cross-city generalization, calibration, and downstream transportation-relevant outcomes, including reachability and hazard-conditioned travel times under counterfactual interventions.

</details>


### [5] [Self-Improving World Modelling with Latent Actions](https://arxiv.org/abs/2602.06130)
*Yifu Qiu,Zheng Zhao,Waylon Li,Yftah Ziser,Anna Korhonen,Shay B. Cohen,Edoardo M. Ponti*

Main category: cs.LG

TL;DR: SWIRL은 상태만 있는 시퀀스에서 학습하여 LLM과 VLM의 내부 모델링을 개선하는 자가 개선 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: LLM과 VLM의 추론 및 계획에 있어 이전 상태와 다음 상태 간 전이를 예측하는 것이 필수적이다.

Method: SWIRL은 행동을 잠재 변수로 보고, 전방 세계 모델링(FWM)과 역 동역학 모델링(IDM) 간에 교대하면서 상태만 있는 시퀀스에서 학습한다.

Result: SWIRL은 다양한 환경에서 LLM과 VLM을 평가한 결과 AURORABench에서 16%, ByteMorph에서 28%, WorldPredictionBench에서 16%, StableToolBench에서 14%의 성과를 달성했다.

Conclusion: SWIRL은 행동 레이블이 없는 상태에서 모델을 학습할 수 있는 효과적인 방법을 제공한다.

Abstract: Internal modelling of the world -- predicting transitions between previous states $X$ and next states $Y$ under actions $Z$ -- is essential to reasoning and planning for LLMs and VLMs. Learning such models typically requires costly action-labelled trajectories. We propose SWIRL, a self-improvement framework that learns from state-only sequences by treating actions as a latent variable and alternating between Forward World Modelling (FWM) $P_θ(Y|X,Z)$ and an Inverse Dynamics Modelling (IDM) $Q_φ(Z|X,Y)$. SWIRL iterates two phases: (1) Variational Information Maximisation, which updates the FWM to generate next states that maximise conditional mutual information with latent actions given prior states, encouraging identifiable consistency; and (2) ELBO Maximisation, which updates the IDM to explain observed transitions, effectively performing coordinate ascent. Both models are trained with reinforcement learning (specifically, GRPO) with the opposite frozen model's log-probability as a reward signal. We provide theoretical learnability guarantees for both updates, and evaluate SWIRL on LLMs and VLMs across multiple environments: single-turn and multi-turn open-world visual dynamics and synthetic textual environments for physics, web, and tool calling. SWIRL achieves gains of 16% on AURORABench, 28% on ByteMorph, 16% on WorldPredictionBench, and 14% on StableToolBench.

</details>


### [6] [Flow Matching for Offline Reinforcement Learning with Discrete Actions](https://arxiv.org/abs/2602.06138)
*Fairoz Nower Khan,Nabuat Zaman Nahim,Ruiquan Huang,Haibo Yang,Peizhong Ju*

Main category: cs.LG

TL;DR: 이 논문에서는 연속 행동 공간만 지원하는 기존의 확산 모델 기반 생성 정책을 확장하여 이산 행동 공간과 다중 목표를 지원하는 일반 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 강화 학습에서 이산 행동 공간을 지원하는 생성 정책의 필요성이 커지고 있습니다.

Method: Q 가중치 흐름 일치를 활용하여 연속 흐름 대신 연속 시간 마르코프 체인을 사용하고, 다중 에이전트 설정을 통해 조건부 경로를 인자화하여 조인 행동 공간의 기하급수적 성장을 완화합니다.

Result: 이론적으로 제시된 최적화 목표를 최적 정책으로 회복할 수 있음을 보여주며, 실험적으로는 다양한 실용 시나리오에서 강인한 성능을 입증합니다.

Conclusion: 본 연구의 이산 프레임워크는 행동 양자화를 통해 연속 제어 문제에도 적용 가능하여 표현 복잡성과 성능 간 유연한 균형을 제공합니다.

Abstract: Generative policies based on diffusion models and flow matching have shown strong promise for offline reinforcement learning (RL), but their applicability remains largely confined to continuous action spaces. To address a broader range of offline RL settings, we extend flow matching to a general framework that supports discrete action spaces with multiple objectives. Specifically, we replace continuous flows with continuous-time Markov chains, trained using a Q-weighted flow matching objective. We then extend our design to multi-agent settings, mitigating the exponential growth of joint action spaces via a factorized conditional path. We theoretically show that, under idealized conditions, optimizing this objective recovers the optimal policy. Extensive experiments further demonstrate that our method performs robustly in practical scenarios, including high-dimensional control, multi-modal decision-making, and dynamically changing preferences over multiple objectives. Our discrete framework can also be applied to continuous-control problems through action quantization, providing a flexible trade-off between representational complexity and performance.

</details>


### [7] [Emergent Low-Rank Training Dynamics in MLPs with Smooth Activations](https://arxiv.org/abs/2602.06208)
*Alec S. Xu,Can Yaras,Matthew Asato,Qing Qu,Laura Balzano*

Main category: cs.LG

TL;DR: 이 논문은 기울기 하강법 하에서 다층 퍼셉트론(MLP)의 학습 동역학을 분석하며, 훈련 동안 가변적 저차원 부분공간 내에서 가중치 동역학이 집중됨을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대규모 심층 신경망의 훈련 동역학이 저차원 부분공간에서 발생한다는 최근의 경험적 증거가 발견되었으나 비선형 네트워크에서 이러한 동역학에 대한 이론적 정당화가 부족하다.

Method: 이 논문은 기울기 하강법 하에서 다층 퍼셉트론(MLP)의 학습 동역학을 분석하고, 두 층 네트워크에서 매끄러운 비선형 활성화에 대한 불변 저차원 부분공간을 정확하게 정의한다.

Result: 가중치 동역학이 훈련 과정 내내 불변 저차원 부분공간에 집중되고, 이 현상이 이론적 가정 이상으로 확장됨을 검증하였다.

Conclusion: 적절한 부분공간 내에서 초기화된 저랭크 MLP 매개변수화가 다양한 분류 작업에서 완전 매개변수가 달린 모델들과 동등한 분류 성능을 보임을 경험적으로 입증하였다.

Abstract: Recent empirical evidence has demonstrated that the training dynamics of large-scale deep neural networks occur within low-dimensional subspaces. While this has inspired new research into low-rank training, compression, and adaptation, theoretical justification for these dynamics in nonlinear networks remains limited. %compared to deep linear settings. To address this gap, this paper analyzes the learning dynamics of multi-layer perceptrons (MLPs) under gradient descent (GD). We demonstrate that the weight dynamics concentrate within invariant low-dimensional subspaces throughout training. Theoretically, we precisely characterize these invariant subspaces for two-layer networks with smooth nonlinear activations, providing insight into their emergence. Experimentally, we validate that this phenomenon extends beyond our theoretical assumptions. Leveraging these insights, we empirically show there exists a low-rank MLP parameterization that, when initialized within the appropriate subspaces, matches the classification performance of fully-parameterized counterparts on a variety of classification tasks.

</details>


### [8] [ATEX-CF: Attack-Informed Counterfactual Explanations for Graph Neural Networks](https://arxiv.org/abs/2602.06240)
*Yu Zhang,Sean Bin Yang,Arijit Khan,Cuneyt Gurcan Akcora*

Main category: cs.LG

TL;DR: ATEX-CF는 그래프 신경망(GNN)의 반사실적 설명 생성을 위해 적대적 공격 기법을 통합한 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 그래프 신경망의 예측을 변경하기 위한 최소한의 변화를 식별하는 직관적인 방법을 제공하고자 한다.

Method: 적대적 공격 기법과 반사실적 설명 생성을 통합하여, 엣지 추가 및 삭제를 동시에 처리하는 방법을 제안한다.

Result: ATEX-CF는 충실하고 간결하며 그럴듯한 설명을 생성하는데 성공하였다.

Conclusion: 적대적 통찰력을 반사실적 추론에 통합함으로써 GNN의 이해도를 높일 수 있다.

Abstract: Counterfactual explanations offer an intuitive way to interpret graph neural networks (GNNs) by identifying minimal changes that alter a model's prediction, thereby answering "what must differ for a different outcome?". In this work, we propose a novel framework, ATEX-CF that unifies adversarial attack techniques with counterfactual explanation generation-a connection made feasible by their shared goal of flipping a node's prediction, yet differing in perturbation strategy: adversarial attacks often rely on edge additions, while counterfactual methods typically use deletions. Unlike traditional approaches that treat explanation and attack separately, our method efficiently integrates both edge additions and deletions, grounded in theory, leveraging adversarial insights to explore impactful counterfactuals. In addition, by jointly optimizing fidelity, sparsity, and plausibility under a constrained perturbation budget, our method produces instance-level explanations that are both informative and realistic. Experiments on synthetic and real-world node classification benchmarks demonstrate that ATEX-CF generates faithful, concise, and plausible explanations, highlighting the effectiveness of integrating adversarial insights into counterfactual reasoning for GNNs.

</details>


### [9] [A Fast and Generalizable Fourier Neural Operator-Based Surrogate for Melt-Pool Prediction in Laser Processing](https://arxiv.org/abs/2602.06241)
*Alix Benoit,Toni Ivas,Mateusz Papierz,Asel Sagingalieva,Alexey Melnikov,Elia Iseli*

Main category: cs.LG

TL;DR: 이 연구는 레이저 용접의 복잡한 열유체 현상을 시뮬레이션하는 LP-FNO라는 대체 모델을 제안하며, 이는 전통적인 방법보다 훨씬 빠른 예측을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 레이저 용접 시뮬레이션의 높은 계산 비용은 대규모 프로세스 탐색과 실시간 사용을 제한한다.

Method: LP-FNO는 FLOW-3D WELD에서 생성된 다물리학 시뮬레이션으로부터 다양한 레이저 프로세스의 매개변수적 해 운영자를 학습하는 푸리에 신경 연산자 기반 대체 모델이다.

Result: 제안된 LP-FNO는 매개변수와 3D 온도 필드 및 용융 풀 경계를 매핑하며, 온도 예측 오차는 1% 수준, 용융 풀 세분화에 대한 교차 겹침 점수는 0.9 이상 달성한다.

Conclusion: LP-FNO는 레이저 용접을 위한 효율적인 대체 모델링 프레임워크를 제공하여, 전통적인 방법보다 수십 밀리초 내에 3D 필드와 상계면 예측을 가능하게 한다.

Abstract: High-fidelity simulations of laser welding capture complex thermo-fluid phenomena, including phase change, free-surface deformation, and keyhole dynamics, however their computational cost limits large-scale process exploration and real-time use. In this work we present the Laser Processing Fourier Neural Operator (LP-FNO), a Fourier Neural Operator (FNO) based surrogate model that learns the parametric solution operator of various laser processes from multiphysics simulations generated with FLOW-3D WELD (registered trademark). Through a novel approach of reformulating the transient problem in the moving laser frame and applying temporal averaging, the system results in a quasi-steady state setting suitable for operator learning, even in the keyhole welding regime. The proposed LP-FNO maps process parameters to three-dimensional temperature fields and melt-pool boundaries across a broad process window spanning conduction and keyhole regimes using the non-dimensional normalized enthalpy formulation. The model achieves temperature prediction errors on the order of 1% and intersection-over-union scores for melt-pool segmentation over 0.9. We demonstrate that a LP-FNO model trained on coarse-resolution data can be evaluated on finer grids, yielding accurate super-resolved predictions in mesh-converged conduction regimes, whereas discrepancies in keyhole regimes reflect unresolved dynamics in the coarse-mesh training data. These results indicate that the LP-FNO provides an efficient surrogate modeling framework for laser welding, enabling prediction of full three-dimensional fields and phase interfaces over wide parameter ranges in just tens of milliseconds, up to a hundred thousand times faster than traditional Finite Volume multi-physics software.

</details>


### [10] [On Randomized Algorithms in Online Strategic Classification](https://arxiv.org/abs/2602.06257)
*Chase Hutton,Adam Melrod,Han Shao*

Main category: cs.LG

TL;DR: 이 논문에서는 온라인 전략적 분류 문제에 대한 개선된 경계값을 제공하며, 다양한 설정에서 무작위 알고리즘의 적용을 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 온라인 전략적 분류에서는 에이전트가 유리한 예측을 얻기 위해 특징을 전략적으로 수정합니다.

Method: 이 연구는 두 가지 설정에서 온라인 전략적 분류를 위한 개선된 경계값을 제공합니다. 실제 설정에서는 결정론적 학습자를 위한 기존 하한을 무작위 학습자로 확대하였고, 불확실한 설정에서는 볼록 최적화 기법을 사용하여 후회 상한을 개선했습니다.

Result: 결정론적 상한을 개선한 첫 번째 무작위 학습자와 모든 적절한 학습 규칙에 대해 로그 계수까지 하한을 일치시켰습니다.

Conclusion: 불완전한 학습이 후회 보장을 추가로 개선하기 위해 필요하다는 것을 보여줍니다.

Abstract: Online strategic classification studies settings in which agents strategically modify their features to obtain favorable predictions. For example, given a classifier that determines loan approval based on credit scores, applicants may open or close credit cards and bank accounts to obtain a positive prediction. The learning goal is to achieve low mistake or regret bounds despite such strategic behavior.
  While randomized algorithms have the potential to offer advantages to the learner in strategic settings, they have been largely underexplored. In the realizable setting, no lower bound is known for randomized algorithms, and existing lower bound constructions for deterministic learners can be circumvented by randomization. In the agnostic setting, the best known regret upper bound is $O(T^{3/4}\log^{1/4}T|\mathcal H|)$, which is far from the standard online learning rate of $O(\sqrt{T\log|\mathcal H|})$.
  In this work, we provide refined bounds for online strategic classification in both settings. In the realizable setting, we extend, for $T > \mathrm{Ldim}(\mathcal{H}) Δ^2$, the existing lower bound $Ω(\mathrm{Ldim}(\mathcal{H}) Δ)$ for deterministic learners to all learners. This yields the first lower bound that applies to randomized learners. We also provide the first randomized learner that improves the known (deterministic) upper bound of $O(\mathrm{Ldim}(\mathcal H) \cdot Δ\log Δ)$.
  In the agnostic setting, we give a proper learner using convex optimization techniques to improve the regret upper bound to $O(\sqrt{T \log |\mathcal{H}|} + |\mathcal{H}| \log(T|\mathcal{H}|))$. We show a matching lower bound up to logarithmic factors for all proper learning rules, demonstrating the optimality of our learner among proper learners. As such, improper learning is necessary to further improve regret guarantees.

</details>


### [11] [Statistical Learning from Attribution Sets](https://arxiv.org/abs/2602.06276)
*Lorne Applebaum,Robert Busa-Fekete,August Y. Chen,Claudio Gentile,Tomer Koren,Aryan Mokhtari*

Main category: cs.LG

TL;DR: 광고 도메인에서 개인 정보 보호 제약 하의 변환 예측 모델 훈련 문제를 다루고, 클릭과 변환 간의 직접 링크를 사용하는 대신 기여 집합을 통해 변환을 연결하는 방식을 채택합니다.


<details>
  <summary>Details</summary>
Motivation: 개인 정보 보호를 위한 브라우저 API와 서드파티 쿠키의 중단에 의해 동기 부여되었습니다.

Method: 기여 집합으로부터의 학습을 실패한 적대자가 후보들에 대한 사전 분포로 장비를 갖춘 상황으로 형식화합니다.

Result: 이러한 신호로부터 모집단 손실에 대한 편향되지 않은 추정기를 구성하고, 이를 통해 경험적 위험 최소화가 일반화 보장을 달성할 수 있음을 보여줍니다.

Conclusion: 우리가 제안한 방법은 일반적으로 사용되는 산업의 휴리스틱보다 크게 향상된 성능을 보입니다.

Abstract: We address the problem of training conversion prediction models in advertising domains under privacy constraints, where direct links between ad clicks and conversions are unavailable. Motivated by privacy-preserving browser APIs and the deprecation of third-party cookies, we study a setting where the learner observes a sequence of clicks and a sequence of conversions, but can only link a conversion to a set of candidate clicks (an attribution set) rather than a unique source. We formalize this as learning from attribution sets generated by an oblivious adversary equipped with a prior distribution over the candidates. Despite the lack of explicit labels, we construct an unbiased estimator of the population loss from these coarse signals via a novel approach. Leveraging this estimator, we show that Empirical Risk Minimization achieves generalization guarantees that scale with the informativeness of the prior and is also robust against estimation errors in the prior, despite complex dependencies among attribution sets. Simple empirical evaluations on standard datasets suggest our unbiased approach significantly outperforms common industry heuristics, particularly in regimes where attribution sets are large or overlapping.

</details>


### [12] [SOCKET: SOft Collison Kernel EsTimator for Sparse Attention](https://arxiv.org/abs/2602.06283)
*Sahil Joshi,Agniva Chowdhury,Wyatt Bellinger,Amar Kanakamedala,Ekam Singh,Hoang Anh Duy Le,Aditya Desai,Anshumali Shrivastava*

Main category: cs.LG

TL;DR: 이 논문에서는 긴 맥락 추론에서 희소성을 활용하여 대형 언어 모델의 확장을 위한 새로운 방법론을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 긴 문맥 추론에서의 희소성 활용은 자가 회귀 디코딩 비용의 대부분을 차지하는 주의(attention) 메커니즘의 비용을 줄이는 데 중점을 둡니다.

Method: 우리는 지역 민감 해싱(Locality-Sensitive Hashing, LSH)을 희소화 원리로 재검토하고, 하드 버킷 일치를 확률적이며 유사성 인식 집계로 대체하는 SOCKET(SOft Collision Kernel EsTimator)를 도입합니다.

Result: SOCKET은 여러 긴 맥락 벤치마크에서 기존 희소 주의 기반 성능과 동일하거나 이를 초과하는 결과를 보여줍니다.

Conclusion: SOCKET은 긴 맥락 추론에서 높은 처리량을 달성하며, FlashAttention보다 최대 1.5배 높은 성능을 제공합니다.

Abstract: Exploiting sparsity during long-context inference is central to scaling large language models, as attention dominates the cost of autoregressive decoding. Sparse attention reduces this cost by restricting computation to a subset of tokens, but its effectiveness depends critically on efficient scoring and selection of relevant tokens at inference time. We revisit Locality-Sensitive Hashing (LSH) as a sparsification primitive and introduce SOCKET, a SOft Collision Kernel EsTimator that replaces hard bucket matches with probabilistic, similarity-aware aggregation. Our key insight is that hard LSH produces discrete collision signals and is therefore poorly suited for ranking. In contrast, soft LSH aggregates graded collision evidence across hash tables, preserving the stability of relative ordering among the true top-$k$ tokens. This transformation elevates LSH from a candidate-generation heuristic to a principled and mathematically grounded scoring kernel for sparse attention. Leveraging this property, SOCKET enables efficient token selection without ad-hoc voting mechanism, and matches or surpasses established sparse attention baselines across multiple long-context benchmarks using diverse set of models. With a custom CUDA kernel for scoring keys and a Flash Decode Triton backend for sparse attention, SOCKET achieves up to 1.5$\times$ higher throughput than FlashAttention, making it an effective tool for long-context inference. Code is open-sourced at https://github.com/amarka8/SOCKET.

</details>


### [13] [Training Data Selection with Gradient Orthogonality for Efficient Domain Adaptation](https://arxiv.org/abs/2602.06359)
*Xiyang Zhang,Yuanhe Tian,Hongzhi Wang,Yan Song*

Main category: cs.LG

TL;DR: 이 논문은 기존의 경량 모델을 사용하여 도메인 전문성과 일반적 추론 능력을 동시에 유지하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델을 특화된 도메인에 맞추어 조정할 때, 도메인 전문성과 일반적 추론 능력 간의 균형을 맞추는 것이 필요하다.

Method: Orthogonal Gradient Selection (OGS)라는 데이터 중심의 방법을 통해 도메인 성능, 일반 능력 유지 및 훈련 효율성을 조화롭게 하였다.

Result: OGS는 일반 지식 기준에 대해 직교하는 훈련 샘플을 동적으로 식별하여 모델 업데이트를 안전하게 수행하도록 한다.

Conclusion: 실험 결과 OGS가 도메인 성능 및 훈련 효율성을 크게 개선하면서도 일반 작업에서의 성능을 유지하거나 향상시킨다는 것을 보여주었다.

Abstract: Fine-tuning large language models (LLMs) for specialized domains often necessitates a trade-off between acquiring domain expertise and retaining general reasoning capabilities, a phenomenon known as catastrophic forgetting. Existing remedies face a dichotomy: gradient surgery methods offer geometric safety but incur prohibitive computational costs via online projections, while efficient data selection approaches reduce overhead but remain blind to conflict-inducing gradient directions. In this paper, we propose Orthogonal Gradient Selection (OGS), a data-centric method that harmonizes domain performance, general capability retention, and training efficiency. OGS shifts the geometric insights of gradient projection from the optimizer to the data selection stage by treating data selection as a constrained decision-making process. By leveraging a lightweight Navigator model and reinforcement learning techniques, OGS dynamically identifies training samples whose gradients are orthogonal to a general-knowledge anchor. This approach ensures naturally safe updates for target models without modifying the optimizer or incurring runtime projection costs. Experiments across medical, legal, and financial domains demonstrate that OGS achieves excellent results, significantly improving domain performance and training efficiency while maintaining or even enhancing performance on general tasks such as GSM8K.

</details>


### [14] [Near-Optimal Regret for Distributed Adversarial Bandits: A Black-Box Approach](https://arxiv.org/abs/2602.06404)
*Hao Qiu,Mengxiao Zhang,Nicolò Cesa-Bianchi*

Main category: cs.LG

TL;DR: 본 논문은 분산 적대적 밴딧을 연구하며, $N$명의 에이전트가 자신의 로컬 손실만 관찰하면서 글로벌 평균 손실을 최소화하기 위해 협력하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 분산 적대적 밴딧 문제에 대한 깊은 이해와 에이전트 간의 효과적인 커뮤니케이션 방식의 필요성을 해결하고자 합니다.

Method: 지연 피드백이 있는 밴딧에 대한 새로운 블랙박스 축소를 기반으로 하여, 에이전트는 잡담을 통해서만 통신하도록 요구하는 알고리즘을 제안합니다.

Result: 이 알고리즘은 Yi와 Vojnovic(2023)의 이전 최상의 경계인 $	ilde{O}(ρ^{-1/3}(KT)^{2/3})$를 상당히 개선한 상한을 달성합니다.

Conclusion: 소통 비용과 밴딧 비용으로 문제의 복잡성을 분해하여, 분산 적대적 환경에서 다양한 경계들을 도출하고, 이를 통해 $R^d$의 분산 선형 밴딧으로 확장할 수 있음을 보여줍니다.

Abstract: We study distributed adversarial bandits, where $N$ agents cooperate to minimize the global average loss while observing only their own local losses. We show that the minimax regret for this problem is $\tildeΘ(\sqrt{(ρ^{-1/2}+K/N)T})$, where $T$ is the horizon, $K$ is the number of actions, and $ρ$ is the spectral gap of the communication matrix. Our algorithm, based on a novel black-box reduction to bandits with delayed feedback, requires agents to communicate only through gossip. It achieves an upper bound that significantly improves over the previous best bound $\tilde{O}(ρ^{-1/3}(KT)^{2/3})$ of Yi and Vojnovic (2023). We complement this result with a matching lower bound, showing that the problem's difficulty decomposes into a communication cost $ρ^{-1/4}\sqrt{T}$ and a bandit cost $\sqrt{KT/N}$. We further demonstrate the versatility of our approach by deriving first-order and best-of-both-worlds bounds in the distributed adversarial setting. Finally, we extend our framework to distributed linear bandits in $R^d$, obtaining a regret bound of $\tilde{O}(\sqrt{(ρ^{-1/2}+1/N)dT})$, achieved with only $O(d)$ communication cost per agent and per round via a volumetric spanner.

</details>


### [15] [Reclaiming First Principles: A Differentiable Framework for Conceptual Hydrologic Models](https://arxiv.org/abs/2602.06429)
*Jasper A. Vrugt,Jonathan M. Frame,Ethan Bollman*

Main category: cs.LG

TL;DR: 이 논문은 개념적 수문 모델의 기울기 기반 보정을 위한 새로운 해석적 프레임워크를 제안하여 빠르고 안정적인 보정을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 개념적 수문 모델의 보정이 느리고 수치적으로 불안정하다는 문제를 해결하기 위해.

Method: 정확한 매개변수 민감도를 기반으로 하는 완전 해석적이고 계산적으로 효율적인 프레임워크를 제안하며, 감도 방정식을 사용하여 모델 상태와 야코비안 행렬을 공동으로 발전시킨다.

Result: 제안된 프레임워크는 다양한 손실 함수에 대해 완전 해석적 기울기 벡터를 제공하고, 이는 전통적인 손실 함수뿐만 아니라 수문학적 성능 메트릭에도 적용 가능하다.

Conclusion: 이 연구는 외부 자동 미분 라이브러리에 의존하지 않고 개념적 수문 모델의 빠르고 안정적이며 투명한 기울기 기반 보정을 가능하게 한다.

Abstract: Conceptual hydrologic models remain the cornerstone of rainfall-runoff modeling, yet their calibration is often slow and numerically fragile. Most gradient-based parameter estimation methods rely on finite-difference approximations or automatic differentiation frameworks (e.g., JAX, PyTorch and TensorFlow), which are computationally demanding and introduce truncation errors, solver instabilities, and substantial overhead. These limitations are particularly acute for the ODE systems of conceptual watershed models. Here we introduce a fully analytic and computationally efficient framework for differentiable hydrologic modeling based on exact parameter sensitivities. By augmenting the governing ODE system with sensitivity equations, we jointly evolve the model states and the Jacobian matrix with respect to all parameters. This Jacobian then provides fully analytic gradient vectors for any differentiable loss function. These include classical objective functions such as the sum of absolute and squared residuals, widely used hydrologic performance metrics such as the Nash-Sutcliffe and Kling-Gupta efficiencies, robust loss functions that down-weight extreme events, and hydrograph-based functionals such as flow-duration and recession curves. The analytic sensitivities eliminate the step-size dependence and noise inherent to numerical differentiation, while avoiding the instability of adjoint methods and the overhead of modern machine-learning autodiff toolchains. The resulting gradients are deterministic, physically interpretable, and straightforward to embed in gradient-based optimizers. Overall, this work enables rapid, stable, and transparent gradient-based calibration of conceptual hydrologic models, unlocking the full potential of differentiable modeling without reliance on external, opaque, or CPU-intensive automatic-differentiation libraries.

</details>


### [16] [Principle-Evolvable Scientific Discovery via Uncertainty Minimization](https://arxiv.org/abs/2602.06448)
*Yingming Pu,Tao Lin,Hongyu Chen*

Main category: cs.LG

TL;DR: LLM 기반의 과학 에이전트가 과학 발견을 가속화했지만, 고정된 초기 가정으로 인해 비효율성이 발생한다. 이 논문에서는 가설 검색에서 과학 원리 진화로 초점을 이동시키는 새로운 프레임워크인 PiEvo를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 접근 방식은 정적 가설 공간 내에서 작동하여 새로운 현상을 발견하는 데 제한이 있으며, 이로 인해 기초 이론이 실패할 경우 계산 낭비가 발생한다.

Method: PiEvo는 발전하는 원리 공간을 통한 베이지안 최적화로 과학 발견을 다룬다. 정보 지향 가설 선택 및 이상 탐지 증강 메커니즘을 통합하여 에이전트가 자율적으로 이론적 세계관을 다듬을 수 있도록 한다.

Result: PiEvo는 (1) 평균 솔루션 품질이 90.81%~93.15%에 달하며, 이는 최신 기술 수준 대비 29.7%~31.1% 향상을 나타낸다, (2) compact principle space를 최적화하여 샘플 복잡성을 크게 줄여 수렴 단계에서 83.3%의 속도 향상을 달성한다, (3) 다양한 과학 분야와 LLM 골격에서 강력한 성능을 유지한다.

Conclusion: PiEvo는 고정된 가설 대신 과학적 원리를 진화시키는 새로운 접근법을 제안하여 과학 발견의 효율성을 크게 향상시킨다.

Abstract: Large Language Model (LLM)-based scientific agents have accelerated scientific discovery, yet they often suffer from significant inefficiencies due to adherence to fixed initial priors. Existing approaches predominantly operate within a static hypothesis space, which restricts the discovery of novel phenomena, resulting in computational waste when baseline theories fail. To address this, we propose shifting the focus from searching hypotheses to evolving the underlying scientific principles. We present PiEvo, a principle-evolvable framework that treats scientific discovery as Bayesian optimization over an expanding principle space. By integrating Information-Directed Hypothesis Selection via Gaussian Process and an anomaly-driven augmentation mechanism, PiEvo enables agents to autonomously refine their theoretical worldview. Evaluation across four benchmarks demonstrates that PiEvo (1) achieves an average solution quality of up to 90.81%~93.15%, representing a 29.7%~31.1% improvement over the state-of-the-art, (2) attains an 83.3% speedup in convergence step via significantly reduced sample complexity by optimizing the compact principle space, and (3) maintains robust performance across diverse scientific domains and LLM backbones.

</details>


### [17] [Towards Generalizable Reasoning: Group Causal Counterfactual Policy Optimization for LLM Reasoning](https://arxiv.org/abs/2602.06475)
*Jingyao Wang,Peizheng Guo,Wenwen Qiang,Jiahuan Zhou,Huijie Guo,Changwen Zheng,Hui Xiong*

Main category: cs.LG

TL;DR: 이 논문은 대규모 언어 모델(LLM)이 이유 과정을 더 잘 반영할 수 있도록 하는 새로운 보상 메커니즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 보상 메커니즘은 최종 정답에만 주목하고, 그 과정에서의 이유성을 간과합니다.

Method: 우리는 Group Causal Counterfactual Policy Optimization을 제안하여 LLM이 일반화 가능한 이유 패턴을 학습하도록 명시적으로 훈련합니다.

Result: 다양한 벤치마크에서의 광범위한 실험을 통해 우리의 접근 방식이 효과적임을 입증하였습니다.

Conclusion: 제안된 방법은 이유 패턴의 과정 유효성을 강화하고, 카운터팩추얼적으로 강인한 LLM을 생성할 수 있습니다.

Abstract: Large language models (LLMs) excel at complex tasks with advances in reasoning capabilities. However, existing reward mechanisms remain tightly coupled to final correctness and pay little attention to the underlying reasoning process: trajectories with sound reasoning but wrong answers receive low credit, while lucky guesses with flawed logic may be highly rewarded, affecting reasoning generalization. From a causal perspective, we interpret multi-candidate reasoning for a fixed question as a family of counterfactual experiments with theoretical supports. Building on this, we propose Group Causal Counterfactual Policy Optimization to explicitly train LLMs to learn generalizable reasoning patterns. It proposes an episodic causal counterfactual reward that jointly captures (i) robustness, encouraging the answer distribution induced by a reasoning step to remain stable under counterfactual perturbations; and (ii) effectiveness, enforcing sufficient variability so that the learned reasoning strategy can transfer across questions. We then construct token-level advantages from this reward and optimize the policy, encouraging LLMs to favor reasoning patterns that are process-valid and counterfactually robust. Extensive experiments on diverse benchmarks demonstrate its advantages.

</details>


### [18] [Evolutionary Generation of Multi-Agent Systems](https://arxiv.org/abs/2602.06511)
*Yuntong Hu,Matthew Trager,Yuting Zhang,Yi Zhang,Shuo Yang,Wei Xia,Stefano Soatto*

Main category: cs.LG

TL;DR: EvoMAS는 진화적 방법으로 다중 에이전트 시스템을 생성하여 성능을 개선하는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 추론 및 도구 지원 작업을 수행하는 다중 에이전트 시스템(MAS)의 효과적인 설계가 여전히 어려움이 많다는 점에서, 새로운 자동 MAS 생성 접근 방식의 필요성이 있다.

Method: EvoMAS는 MAS 생성을 구조화된 구성 생성으로 공식화하고, 초기 구성을 풀에서 선택하며 실행 추적에 의해 안내된 피드백 조건 돌연변이 및 교차를 적용하여 구성 공간 내에서 진화적 생성을 수행한다.

Result: EvoMAS는 BBEH, SWE-Bench, WorkBench 등 다양한 벤치마크에서 기존의 인간 설계 MAS 및 자동 MAS 생성 방법과 비교하여 일관되게 작업 성능을 향상시켰다.

Conclusion: EvoMAS는 MAS 설계의 효율성을 증대시키며, 실행 가능성과 런타임 견고성을 높인 생성 시스템을 생산한다.

Abstract: Large language model (LLM)-based multi-agent systems (MAS) show strong promise for complex reasoning, planning, and tool-augmented tasks, but designing effective MAS architectures remains labor-intensive, brittle, and hard to generalize. Existing automatic MAS generation methods either rely on code generation, which often leads to executability and robustness failures, or impose rigid architectural templates that limit expressiveness and adaptability. We propose Evolutionary Generation of Multi-Agent Systems (EvoMAS), which formulates MAS generation as structured configuration generation. EvoMAS performs evolutionary generation in configuration space. Specifically, EvoMAS selects initial configurations from a pool, applies feedback-conditioned mutation and crossover guided by execution traces, and iteratively refines both the candidate pool and an experience memory. We evaluate EvoMAS on diverse benchmarks, including BBEH, SWE-Bench, and WorkBench, covering reasoning, software engineering, and tool-use tasks. EvoMAS consistently improves task performance over both human-designed MAS and prior automatic MAS generation methods, while producing generated systems with higher executability and runtime robustness. EvoMAS outperforms the agent evolution method EvoAgent by +10.5 points on BBEH reasoning and +7.1 points on WorkBench. With Claude-4.5-Sonnet, EvoMAS also reaches 79.1% on SWE-Bench-Verified, matching the top of the leaderboard.

</details>


### [19] [Live Knowledge Tracing: Real-Time Adaptation using Tabular Foundation Models](https://arxiv.org/abs/2602.06542)
*Mounir Lbath,Alexandre Paresy,Abdelkayoum Kaddouri,Alan André,Alexandre Ittah,Jill-Jênn Vie*

Main category: cs.LG

TL;DR: 이 논문에서는 지식 추적을 위한 새로운 패러다임을 탐구하여 탭형 기초 모델(TFM)을 활용한다.


<details>
  <summary>Details</summary>
Motivation: 딥 지식 추적 모델이 학생 학습 경로 모델링에서 큰 발전을 이뤘지만, 상당한 훈련 시간과 짧은 시퀀스 데이터셋에서의 과적합 문제가 존재한다.

Method: 전통적인 방법과 달리 오프라인 훈련을 필요로 하지 않고 실시간으로 온라인 방식으로 지식 추적을 수행하는 방법을 소개한다. 두 가지 방향의 주의 메커니즘을 중심으로 하며, TFM은 훈련 세트의 다른 학생 간 상호작용과 시간 단계를 모두 고려한다.

Result: 여러 데이터 세트를 사용하여, 이 방법이 예측 성능에서 경쟁력을 가지며, 최대 273배의 속도 증대를 이루는 것을 보여준다.

Conclusion: 더 많은 학생 상호작용이 관찰되는 환경에서도 효과적인 결과를 도출할 수 있다.

Abstract: Deep knowledge tracing models have achieved significant breakthroughs in modeling student learning trajectories. However, these architectures require substantial training time and are prone to overfitting on datasets with short sequences. In this paper, we explore a new paradigm for knowledge tracing by leveraging tabular foundation models (TFMs). Unlike traditional methods that require offline training on a fixed training set, our approach performs real-time ''live'' knowledge tracing in an online way. The core of our method lies in a two-way attention mechanism: while attention knowledge tracing models only attend across earlier time steps, TFMs simultaneously attend across both time steps and interactions of other students in the training set. They align testing sequences with relevant training sequences at inference time, therefore skipping the training step entirely. We demonstrate, using several datasets of increasing size, that our method achieves competitive predictive performance with up to 273x speedups, in a setting where more student interactions are observed over time.

</details>


### [20] [Transformer-based Parameter Fitting of Models derived from Bloch-McConnell Equations for CEST MRI Analysis](https://arxiv.org/abs/2602.06574)
*Christof Duhme,Chris Lippe,Verena Hoerr,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: 이 논문은 CEST MRI에 대한 변환기 기반 신경망을 도입하여 대사물질 농도, 교환 및 이완 속도를 추정한다.


<details>
  <summary>Details</summary>
Motivation: CEST MRI는 비침습적으로 대사물질을 감지할 수 있으나, 신호 측정이 복잡한 생리적 변수의 상호작용으로 인해 수량화가 어렵다.

Method: Bloch-McConnell 방정식에서 유도된 물리 모델의 매개변수(대사물질 농도, 교환 및 이완 속도)를 in-vitro CEST 스펙트럼에 맞추기 위해 변환기 기반 신경망을 사용한다.

Result: 자기 감독 방식으로 학습한 신경망이 전통적인 기울기 기반 솔버보다 우수한 성능을 보임을 발견하였다.

Conclusion: 제안한 신경망은 CEST 데이터의 정량화를 효과적으로 지원하며, 향후 생리학적 변수의 복잡한 영향을 다룰 수 있는 가능성을 보여준다.

Abstract: Chemical exchange saturation transfer (CEST) MRI is a non-invasive imaging modality for detecting metabolites. It offers higher resolution and sensitivity compared to conventional magnetic resonance spectroscopy (MRS). However, quantification of CEST data is challenging because the measured signal results from a complex interplay of many physiological variables. Here, we introduce a transformer-based neural network to fit parameters such as metabolite concentrations, exchange and relaxation rates of a physical model derived from Bloch-McConnell equations to in-vitro CEST spectra. We show that our self-supervised trained neural network clearly outperforms the solution of classical gradient-based solver.

</details>


### [21] [Pruning at Initialisation through the lens of Graphon Limit: Convergence, Expressivity, and Generalisation](https://arxiv.org/abs/2602.06675)
*Hoang Pham,The-Anh Ta,Long Tran-Thanh*

Main category: cs.LG

TL;DR: 이 논문은 초기화 시 가지 치기 방법과 그래프 이론을 연계하여 희소 신경망의 성능을 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 초기화 시 가지 치기 방법의 이론적 메커니즘이 불명확하며, 기존 분석은 유한 폭 통계에 국한되어 있습니다.

Method: 이 논문은 그래프 한계 이론을 통해 PaI 마스크의 그래프 한계와 연결하며, 인기도 있는 가지 치기 기준을 포함하는 팩토라이즈드 주목 모델을 소개합니다.

Result: 불규칙한 조건 하에서 이 알고리즘들이 생성한 이산 마스크는 결정론적 이분 그래프론으로 수렴합니다.

Conclusion: 이 결과는 희소 신경망 분석을 조합적 그래프 문제에서 연속 연산자의 엄격한 프레임워크로 전환하여 희소 신경망의 표현성과 일반화 분석을 위한 새로운 메커니즘을 제공합니다.

Abstract: Pruning at Initialisation methods discover sparse, trainable subnetworks before training, but their theoretical mechanisms remain elusive. Existing analyses are often limited to finite-width statistics, lacking a rigorous characterisation of the global sparsity patterns that emerge as networks grow large. In this work, we connect discrete pruning heuristics to graph limit theory via graphons, establishing the graphon limit of PaI masks. We introduce a Factorised Saliency Model that encompasses popular pruning criteria and prove that, under regularity conditions, the discrete masks generated by these algorithms converge to deterministic bipartite graphons. This limit framework establishes a novel topological taxonomy for sparse networks: while unstructured methods (e.g., Random, Magnitude) converge to homogeneous graphons representing uniform connectivity, data-driven methods (e.g., SNIP, GraSP) converge to heterogeneous graphons that encode implicit feature selection. Leveraging this continuous characterisation, we derive two fundamental theoretical results: (i) a Universal Approximation Theorem for sparse networks that depends only on the intrinsic dimension of active coordinate subspaces; and (ii) a Graphon-NTK generalisation bound demonstrating how the limit graphon modulates the kernel geometry to align with informative features. Our results transform the study of sparse neural networks from combinatorial graph problems into a rigorous framework of continuous operators, offering a new mechanism for analysing expressivity and generalisation in sparse neural networks.

</details>


### [22] [Diffeomorphism-Equivariant Neural Networks](https://arxiv.org/abs/2602.06695)
*Josephine Elisabeth Oettinger,Zakhar Shumaylov,Johannes Bostelmann,Jan Lellmann,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: 이 연구는 무한 차원 군에 대한 동등성을 통해 사전 훈련된 신경망의 효율성을 향상시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 신경망에 군 대칭성을 포함시키는 것은 현대 심층 학습의 효율성과 데이터 요구 사항을 극복하는 데 강력한 접근법으로 부각되었다.

Method: 에너지 기반 정준화를 통해 사전 훈련된 신경망에서 미분 동형사상 동등성을 유도하는 전략을 제안하고, 동등성을 최적화 문제로 수식화한다.

Result: 세그멘테이션 및 분류 작업에 대한 경험적 결과는 접근 방식이 근사 동등성을 달성하고 광범위한 데이터 증대나 재훈련 없이도 보이지 않는 변환에 일반화됨을 확인한다.

Conclusion: 제안된 방법은 무한 차원 군에 대한 접근을 통해 신경망의 동등성을 강화하고, 다양한 변환을 처리할 수 있는 가능성을 보여준다.

Abstract: Incorporating group symmetries via equivariance into neural networks has emerged as a robust approach for overcoming the efficiency and data demands of modern deep learning. While most existing approaches, such as group convolutions and averaging-based methods, focus on compact, finite, or low-dimensional groups with linear actions, this work explores how equivariance can be extended to infinite-dimensional groups. We propose a strategy designed to induce diffeomorphism equivariance in pre-trained neural networks via energy-based canonicalisation. Formulating equivariance as an optimisation problem allows us to access the rich toolbox of already established differentiable image registration methods. Empirical results on segmentation and classification tasks confirm that our approach achieves approximate equivariance and generalises to unseen transformations without relying on extensive data augmentation or retraining.

</details>


### [23] [Improved Sampling Schedules for Discrete Diffusion Models](https://arxiv.org/abs/2602.06849)
*Alberto Foresti,Mustapha Bounoua,Giulio Franzese,Luca Ambrogioni,Pietro Michiardi*

Main category: cs.LG

TL;DR: 이 논문은 이산 확산 모델의 역과정을 열역학적 엔트로피 생산의 관점에서 분석하여 정보 생성량을 정량화하기 위한 엔트로피 생산률을 제안하고, 두 가지 새로운 샘플링 스케줄을 도입하여 다양한 응용 분야에서 성능을 개선함을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 이산 확산 모델이 시퀀스 데이터에서 생성 모델링을 위한 강력한 패러다임으로 부상했지만, 이들의 역과정에 대한 정보 이론적 원리는 여전히 불명확하다. 따라서 이러한 격차를 해소할 필요가 있다.

Method: 열역학적 엔트로피 생산의 관점에서 역과정 역학을 분석하고, 정보 생성량을 정량화하기 위해 엔트로피 생산률을 도입하며, 물리학 영감을 받은 매트릭스에 따라 균일하게 간격을 두는 두 가지 새로운 샘플링 스케줄을 제안한다.

Result: 제안된 스케줄이 다양한 응용 분야에서 최첨단 전략보다 현저히 뛰어난 성능을 발휘함을 실험적으로 입증한다.

Conclusion: 제안한 샘플링 스케줄은 계산 비용이 낮은 상태에서 지속적으로 우수한 성능을 달성하는 데 기여한다.

Abstract: Discrete diffusion models have emerged as a powerful paradigm for generative modeling on sequence data; however, the information-theoretic principles governing their reverse processes remain significantly less understood than those of their continuous counterparts. In this work, we bridge this gap by analyzing the reverse process dynamics through the lens of thermodynamic entropy production. We propose the entropy production rate as a rigorous proxy for quantifying information generation, deriving as a byproduct a bound on the Wasserstein distance between intermediate states and the data distribution. Leveraging these insights, we introduce two novel sampling schedules that are uniformly spaced with respect to their corresponding physics-inspired metrics: the Entropic Discrete Schedule (EDS), which is defined by maintaining a constant rate of information gain, and the Wasserstein Discrete Schedule (WDS), which is defined by taking equal steps in terms of the Wasserstein distance. We empirically demonstrate that our proposed schedules significantly outperform state-of-the-art strategies across diverse application domains, including synthetic data, music notation, vision and language modeling, consistently achieving superior performance at a lower computational budget.

</details>


### [24] [T-STAR: A Context-Aware Transformer Framework for Short-Term Probabilistic Demand Forecasting in Dock-Based Shared Micro-Mobility](https://arxiv.org/abs/2602.06866)
*Jingyi Cheng,Gonçalo Homem de Almeida Correia,Oded Cats,Shadi Sharif Azadeh*

Main category: cs.LG

TL;DR: T-STAR는 15분 단위의 자전거 공유 수요 예측을 위한 새로운 변환기 기반 확률적 프레임워크를 제안하며, 기존 방법들보다 더 높은 예측 정확도를 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 공유 마이크로 모빌리티 서비스의 관리와 사용자 중심 운영을 보장하기 위해서는 신뢰할 수 있는 단기 수요 예측이 필요합니다.

Method: T-STAR는 계층적 2단계 구조를 통해 일관된 수요 패턴과 단기 변동성을 분리하여 고해상도 예측 문제를 해결합니다. 첫 번째 단계는 대략적인 시간별 수요 패턴을 포착하고, 두 번째 단계는 실시간 수요 변동을 포함한 고주파 지역 입력을 통합하여 예측 정확성을 향상시킵니다.

Result: 워싱턴 D.C.의 Capital Bikeshare 데이터를 사용한 실험에서 T-STAR는 Deterministic 및 Probabilistic 정확도 모두에서 기존 방법들을 능가했습니다.

Conclusion: 이 모델은 다양한 역과 시간대에서 강한 공간적 및 시간적 강건성을 보여주며, 이전에 보지 못한 서비스 지역으로의 전이 능력도 강조됩니다.

Abstract: Reliable short-term demand forecasting is essential for managing shared micro-mobility services and ensuring responsive, user-centered operations. This study introduces T-STAR (Two-stage Spatial and Temporal Adaptive contextual Representation), a novel transformer-based probabilistic framework designed to forecast station-level bike-sharing demand at a 15-minute resolution. T-STAR addresses key challenges in high-resolution forecasting by disentangling consistent demand patterns from short-term fluctuations through a hierarchical two-stage structure. The first stage captures coarse-grained hourly demand patterns, while the second stage improves prediction accuracy by incorporating high-frequency, localized inputs, including recent fluctuations and real-time demand variations in connected metro services, to account for temporal shifts in short-term demand. Time series transformer models are employed in both stages to generate probabilistic predictions. Extensive experiments using Washington D.C.'s Capital Bikeshare data demonstrate that T-STAR outperforms existing methods in both deterministic and probabilistic accuracy. The model exhibits strong spatial and temporal robustness across stations and time periods. A zero-shot forecasting experiment further highlights T-STAR's ability to transfer to previously unseen service areas without retraining. These results underscore the framework's potential to deliver granular, reliable, and uncertainty-aware short-term demand forecasts, which enable seamless integration to support multimodal trip planning for travelers and enhance real-time operations in shared micro-mobility services.

</details>


### [25] [A first realization of reinforcement learning-based closed-loop EEG-TMS](https://arxiv.org/abs/2602.06907)
*Dania Humaidan,Jiahua Xu,Jing Chen,Christoph Zrenner,David Emanuel Vetter,Laura Marzetti,Paolo Belardinelli,Timo Roine,Risto J. Ilmoniemi,Gian Luca Romani,Ulf Zieman*

Main category: cs.LG

TL;DR: 본 연구는 최초로 기계 학습 기반의 폐쇄 루프 실시간 EEG-TMS 설정을 활용하여 개인의 mu-리듬 위상 추출을 시도한 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존의 TMS 치료법은 개인 간 및 개인 내 차이를 무시하고 일률적으로 적용되었으나, 이를 개선하고자 했다.

Method: 25명의 참가자에게 EEG-TMS를 적용하고 강화 학습 알고리즘을 사용하여 고형성과 저형성 상태에 관련된 mu-리듬 위상을 식별했다.

Result: 강화 학습을 통해 고형성과 저형성 상태와 관련된 mu-리듬 위상을 효과적으로 식별하였고, 반복 자극은 기능적 연결성의 장기적 증가 또는 감소를 초래하였다.

Conclusion: 폐쇄 루프 EEG-TMS의 사용 가능성을 최초로 입증하여 뇌 질환의 개인화된 치료를 위한 중요한 단계를 보여주었다.

Abstract: Background: Transcranial magnetic stimulation (TMS) is a powerful tool to investigate neurophysiology of the human brain and treat brain disorders. Traditionally, therapeutic TMS has been applied in a one-size-fits-all approach, disregarding inter- and intra-individual differences. Brain state-dependent EEG-TMS, such as coupling TMS with a pre-specified phase of the sensorimotor mu-rhythm, enables the induction of differential neuroplastic effects depending on the targeted phase. But this approach is still user-dependent as it requires defining an a-priori target phase. Objectives: To present a first realization of a machine-learning-based, closed-loop real-time EEG-TMS setup to identify user-independently the individual mu-rhythm phase associated with high- vs. low-corticospinal excitability states. Methods: We applied EEG-TMS to 25 participants targeting the supplementary motor area-primary motor cortex network and used a reinforcement learning algorithm to identify the mu-rhythm phase associated with high- vs. low corticospinal excitability. We employed linear mixed effects models and Bayesian analysis to determine effects of reinforced learning on corticospinal excitability indexed by motor evoked potential amplitude, and functional connectivity indexed by the imaginary part of resting-state EEG coherence. Results: Reinforcement learning effectively identified the mu-rhythm phase associated with high- vs. low-excitability states, and their repetitive stimulation resulted in long-term increases vs. decreases in functional connectivity in the stimulated sensorimotor network. Conclusions: We demonstrated for the first time the feasibility of closed-loop EEG-TMS in humans, a critical step towards individualized treatment of brain disorders.

</details>


### [26] [From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers](https://arxiv.org/abs/2602.06923)
*Ziming Liu,Sophia Sanborn,Surya Ganguli,Andreas Tolias*

Main category: cs.LG

TL;DR: 일반 목적 AI 아키텍처가 예측을 넘어 우주의 물리 법칙을 발견할 수 있을까?


<details>
  <summary>Details</summary>
Motivation: 진정한 지능은 에이전트가 미래 상태를 예측할 뿐만 아니라 근본적인 지배 역학을 이해할 수 있게 하는 인과 추상화인 '세계 모델'에 의존한다.

Method: 세 가지 최소한의 유도 바이어스를 시스템적으로 도입하여 공간적 매끄러움과 안정성을 보장함으로써 일반적 트랜스포머가 실패를 초월하고 일관된 케플러 세계 모델을 학습하도록 한다.

Result: 일반적 트랜스포머가 행성 궤도에 타원을 성공적으로 맞추는 데 성공했다는 것을 보여준다.

Conclusion: 간단한 아키텍처 선택이 AI가 곡선 적합기인지 물리학자인지를 결정하며, 이는 자동화된 과학적 발견을 향한 중요한 단계임을 보여준다.

Abstract: Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on "world models" -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous "AI Physicist" approaches have successfully recovered such laws, they typically rely on strong, domain-specific priors that effectively "bake in" the physics. Conversely, Vafa et al. recently showed that generic Transformers fail to acquire these world models, achieving high predictive accuracy without capturing the underlying physical laws. We bridge this gap by systematically introducing three minimal inductive biases. We show that ensuring spatial smoothness (by formulating prediction as continuous regression) and stability (by training with noisy contexts to mitigate error accumulation) enables generic Transformers to surpass prior failures and learn a coherent Keplerian world model, successfully fitting ellipses to planetary trajectories. However, true physical insight requires a third bias: temporal locality. By restricting the attention window to the immediate past -- imposing the simple assumption that future states depend only on the local state rather than a complex history -- we force the model to abandon curve-fitting and discover Newtonian force representations. Our results demonstrate that simple architectural choices determine whether an AI becomes a curve-fitter or a physicist, marking a critical step toward automated scientific discovery.

</details>


### [27] [Continuous-time reinforcement learning: ellipticity enables model-free value function approximation](https://arxiv.org/abs/2602.06930)
*Wenlong Mou*

Main category: cs.LG

TL;DR: 이 논문은 이산 시간 관측 및 행동을 가진 연속 시간 마르코프 확산 프로세스의 제어를 위한 오프 정책 강화 학습을 연구합니다.


<details>
  <summary>Details</summary>
Motivation: 연속 시간 마르코프 확산 프로세스에 대한 강화 학습의 효율성을 높이기 위해 특정한 함수근사 방법을 연구합니다.

Method: 모델 없는 알고리즘을 사용하여 데이터에서 직접 가치 및 장점 함수를 학습하며, 이 과정에서 새로운 Sobolev-prox 맞춤형 q-학습 알고리즘을 제안합니다.

Result: 상관된 오라클 불평등을 도출하여 함수 클래스의 최적 근사 오류, 국소화 복잡성, 지수 감소 최적화 오류 및 수치 이산화 오류에 의해 지배받는 추정 오류를 설명합니다.

Conclusion: 이 결과는 마르코프 확산에 대한 함수 근사와 관련된 강화 학습이 감독 학습보다 더 어렵지 않다는 것을 보여줍니다.

Abstract: We study off-policy reinforcement learning for controlling continuous-time Markov diffusion processes with discrete-time observations and actions. We consider model-free algorithms with function approximation that learn value and advantage functions directly from data, without unrealistic structural assumptions on the dynamics.
  Leveraging the ellipticity of the diffusions, we establish a new class of Hilbert-space positive definiteness and boundedness properties for the Bellman operators. Based on these properties, we propose the Sobolev-prox fitted $q$-learning algorithm, which learns value and advantage functions by iteratively solving least-squares regression problems. We derive oracle inequalities for the estimation error, governed by (i) the best approximation error of the function classes, (ii) their localized complexity, (iii) exponentially decaying optimization error, and (iv) numerical discretization error. These results identify ellipticity as a key structural property that renders reinforcement learning with function approximation for Markov diffusions no harder than supervised learning.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [28] [Multi-Agent-Driven Cognitive Secure Communications in Satellite-Terrestrial Networks](https://arxiv.org/abs/2602.06048)
*Yujie Ling,Zan Li,Lei Guan,Zheng Zhang,Shengyu Zhang,Tony Q. S. Quek*

Main category: cs.CR

TL;DR: 위성-지상 네트워크(STNs)는 여러 사용자에게 원활한 무선 커버리지와 연결성을 제공하는 유망한 접근 방식으로 부상했습니다. 하지만 잠재적인 악성 도청자는 비협조적 행동과 지능형 공격 능력으로 인해 STNs를 통해 개인 정보에 심각한 위협을 가합니다. 본 논문에서는 실시간 감지를 통해 주파수 스케줄링 및 보호를 조정하는 다수의 에이전트에 의해 구동되는 인지 보안 통신 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: STNs의 증가와 함께, 비협조적인 공격자가 개인 정보를 위협하는 문제가 부각되고 있습니다.

Method: 다수의 에이전트가 스펙트럼 스케줄링과 보호를 조정하여 도청자의 판단을 방해하는 인지 보안 통신 프레임워크를 제안합니다. 또한, 최적화 문제를 수립하여 합법적 사용자의 비밀 유지 확률을 극대화합니다.

Result: 제안된 방법은 STNs의 보안 성능을 향상시키고 전력 오버헤드를 줄이는 데 있어 벤치마크 방법보다 우수한 성능을 보였습니다.

Conclusion: 두 계층 협조 방어 시스템을 기반으로 하여, STNs의 인지 보안 통신 시나리오에서 신뢰할 수 있는 데이터 전송을 유지하면서 도청자의 추론 능력을 적극적으로 저하시킬 수 있습니다.

Abstract: Satellite-terrestrial networks (STNs) have emerged as a promising architecture for providing seamless wireless coverage and connectivity for multiple users. However, potential malicious eavesdroppers pose a serious threat to the private information via STNs due to their non-cooperative behavior and ability to launch intelligent attacks. To address this challenge, we propose a cognitive secure communication framework driven by multiple agents that coordinates spectrum scheduling and protection through real-time sensing, thereby disrupting the judgment of eavesdroppers while preserving reliable data transmission. On this basis, we formulate an optimization problem to maximize the secrecy probability of legitimate users, subject to a reliable transmission probability threshold. To tackle this problem, we propose a two-layer coordinated defense system. First, we develop a foundation layer based on multi-agent coordination schedule to determine the satellite operation matrix and the frequency slot occupation matrices, aiming to mitigate spectrum congestion and enhance transmission reliability. Then, we exploit generative adversarial networks to produce adversarial matrices, and employ learning-aided power control to set real and adversarial signal powers for protection layer, which actively degrades the inference capability of eavesdroppers. Simulation results demonstrate that the proposed method outperforms benchmark methods in terms of enhancing security performance and reducing power overhead for STNs in the cognitive secure communication scenario.

</details>


### [29] [Identifying Adversary Tactics and Techniques in Malware Binaries with an LLM Agent](https://arxiv.org/abs/2602.06325)
*Zhou Xuan,Xiangzhe Xu,Mingwei Zheng,Louis Zheng-Hua Tan,Jinyao Guo,Tiantai Zhang,Le Yu,Chengpeng Wang,Xiangyu Zhang*

Main category: cs.CR

TL;DR: TTPDetect는 악성 코드 이진 파일에서 전술, 기법 및 절차(TTP)를 인식하기 위한 최초의 LLM 에이전트로, 기존 방법보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 악성 코드 이진 파일의 TTP를 이해하는 것은 보안 분석과 위협 정보 수집에 필수적이나, 실제로는 어려움이 존재한다.

Method: TTPDetect는 밀집 검색과 LLM 기반 신경 검색을 결합하여 분석 진입점의 공간을 좁히고, 기능 레벨 분석 에이전트와 TTP-특화 추론 지침을 사용하여 효율적인 분석을 수행한다.

Result: TTPDetect는 기능 수준 TTP 인식에서 93.25%의 정밀도와 93.81%의 재현율을 기록하였으며, 실제 악성 샘플에서도 87.37%의 정밀도로 TTP를 인식하였다.

Conclusion: TTPDetect는 전문가 작성 보고서가 있는 악성 코드의 TTP를 85.7% 회복하고, 평균적으로 각 악성 코드당 10.5개의 새로운 TTP를 발견하였다.

Abstract: Understanding TTPs (Tactics, Techniques, and Procedures) in malware binaries is essential for security analysis and threat intelligence, yet remains challenging in practice. Real-world malware binaries are typically stripped of symbols, contain large numbers of functions, and distribute malicious behavior across multiple code regions, making TTP attribution difficult. Recent large language models (LLMs) offer strong code understanding capabilities, but applying them directly to this task faces challenges in identifying analysis entry points, reasoning under partial observability, and misalignment with TTP-specific decision logic. We present TTPDetect, the first LLM agent for recognizing TTPs in stripped malware binaries. TTPDetect combines dense retrieval with LLM-based neural retrieval to narrow the space of analysis entry points. TTPDetect further employs a function-level analyzing agent consisting of a Context Explorer that performs on-demand, incremental context retrieval and a TTP-Specific Reasoning Guideline that achieves inference-time alignment. We build a new dataset that labels decompiled functions with TTPs across diverse malware families and platforms. TTPDetect achieves 93.25% precision and 93.81% recall on function-level TTP recognition, outperforming baselines by 10.38% and 18.78%, respectively. When evaluated on real world malware samples, TTPDetect recognizes TTPs with a precision of 87.37%. For malware with expert-written reports, TTPDetect recovers 85.7% of the documented TTPs and further discovers, on average, 10.5 previously unreported TTPs per malware.

</details>


### [30] [Zero-Trust Runtime Verification for Agentic Payment Protocols: Mitigating Replay and Context-Binding Failures in AP2](https://arxiv.org/abs/2602.06345)
*Qianlong Lan,Anuj Kaul,Shaun Jones,Stephanie Westrum*

Main category: cs.CR

TL;DR: 이 논문은 에이전트 기반 결제 시스템에서 AP2 임무 생애 주기의 보안 분석을 제시하고, 실행 중 발생하는 집행 격차를 식별하며, 제로 트러스트 런타임 검증 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 AI 에이전트의 상업적 거래 실행 능력은 UCP 및 AP2와 같은 위임 기반 결제 승인 프로토콜의 도입을 촉진했습니다.

Method: AP2 임무 생애 주기의 보안 분석을 통해 집행 격차를 식별하고, 동적으로 생성된 시간 제한 논스를 사용하는 제로 트러스트 런타임 검증 프레임워크를 제안합니다.

Result: 상황 인식 바인딩과 소비-한번 집행이 재생 및 상황 리디렉션 공격을 예방하는 데 필요하며, 제안된 프레임워크는 모든 평가된 공격을 완화합니다.

Conclusion: 강력한 런타임 보안을 달성할 수 있으며, 최적의 지속 가능한 오버헤드를 유지할 수 있음을 보여줍니다.

Abstract: The deployment of autonomous AI agents capable of executing commercial transactions has motivated the adoption of mandate-based payment authorization protocols, including the Universal Commerce Protocol (UCP) and the Agent Payments Protocol (AP2). These protocols replace interactive, session-based authorization with cryptographically issued mandates, enabling asynchronous and autonomous execution. While AP2 provides specification-level guarantees through signature verification, explicit binding, and expiration semantics, real-world agentic execution introduces runtime behaviors such as retries, concurrency, and orchestration that challenge implicit assumptions about mandate usage.
  In this work, we present a security analysis of the AP2 mandate lifecycle and identify enforcement gaps that arise during runtime in agent-based payment systems. We propose a zero-trust runtime verification framework that enforces explicit context binding and consume-once mandate semantics using dynamically generated, time-bound nonces, ensuring that authorization decisions are evaluated at execution time rather than assumed from static issuance properties.
  Through simulation-based evaluation under high concurrency, we show that context-aware binding and consume-once enforcement address distinct and complementary attack classes, and that both are required to prevent replay and context-redirect attacks. The proposed framework mitigates all evaluated attacks while maintaining stable verification latency of approximately 3.8~ms at throughput levels up to 10{,}000 transactions per second. We further demonstrate that the required runtime state is bounded by peak concurrency rather than cumulative transaction history, indicating that robust runtime security for agentic payment execution can be achieved with minimal and predictable overhead.

</details>


### [31] [Empirical Analysis of Adversarial Robustness and Explainability Drift in Cybersecurity Classifiers](https://arxiv.org/abs/2602.06395)
*Mona Rajhans,Vishal Khawarey*

Main category: cs.CR

TL;DR: 본 논문은 사이버 보안에서 기계 학습 모델의 적대적 강건성과 설명 가능성 변화를 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 응용 프로그램에서 기계 학습 모델이 점점 더 많이 사용되지만, 적대적 공격에 취약하다는 문제를 해결하고자 합니다.

Method: L (infinity)로 제한된 Fast Gradient Sign Method (FGSM) 및 Projected Gradient Descent (PGD) perturbations의 모델 정확성에 미치는 영향을 평가하고, 정량적 지표인 Robustness Index (RI)를 도입합니다.

Result: 적대적 훈련이 RI를 최대 9퍼센트 향상시키면서도 깨끗한 데이터의 정확성을 유지하는 것으로 나타났습니다.

Conclusion: 강건성과 설명 가능성 감소 간의 관계를 강조하고, 신뢰할 수 있는 AI 기반 사이버 보안 시스템 설계에서 정량적 평가의 중요성을 강조합니다.

Abstract: Machine learning (ML) models are increasingly deployed in cybersecurity applications such as phishing detection and network intrusion prevention. However, these models remain vulnerable to adversarial perturbations small, deliberate input modifications that can degrade detection accuracy and compromise interpretability. This paper presents an empirical study of adversarial robustness and explainability drift across two cybersecurity domains phishing URL classification and network intrusion detection. We evaluate the impact of L (infinity) bounded Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD) perturbations on model accuracy and introduce a quantitative metric, the Robustness Index (RI), defined as the area under the accuracy perturbation curve. Gradient based feature sensitivity and SHAP based attribution drift analyses reveal which input features are most susceptible to adversarial manipulation. Experiments on the Phishing Websites and UNSW NB15 datasets show consistent robustness trends, with adversarial training improving RI by up to 9 percent while maintaining clean-data accuracy. These findings highlight the coupling between robustness and interpretability degradation and underscore the importance of quantitative evaluation in the design of trustworthy, AI-driven cybersecurity systems.

</details>


### [32] [TrajAD: Trajectory Anomaly Detection for Trustworthy LLM Agents](https://arxiv.org/abs/2602.06443)
*Yibing Liu,Chong Zhang,Zhongyi Han,Hansong Liu,Yong Wang,Yang Yu,Xiaoyan Wang,Yilong Yin*

Main category: cs.CR

TL;DR: 이 논문은 LLM 에이전트를 신뢰할 수 있게 만드는 데 필요한 런타임 경로 이상 탐지 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 현재의 안전 조치는 주로 정적 입력/출력 필터링에 초점을 맞추지만, LLM 에이전트의 신뢰성을 보장하기 위해서는 중간 실행 과정을 감사하는 것이 필요하다.

Method: TrajBench라는 다양한 절차적 이상을 포괄하는 데이터셋을 생성하고, 이를 통해 과정 감독에서의 모델의 능력을 조사한다. 또한, 정교한 과정 감독으로 훈련된 전문 검증기 TrajAD를 제안한다.

Result: 일반적인 LLM 모델은 제로샷 프롬프트 상황에서도 이러한 이상을 식별하고 위치를 파악하는 데 어려움을 겪는다. 이를 통해 일반화된 능력이 자동적으로 프로세스 신뢰성으로 이어지지 않음을 보여준다.

Conclusion: 전문화된 감독이 신뢰할 수 있는 에이전트를 구축하는 데 필수적임을 입증하여 TrajAD가 기존 기준을 뛰어넘는 성능을 보여준다.

Abstract: We address the problem of runtime trajectory anomaly detection, a critical capability for enabling trustworthy LLM agents. Current safety measures predominantly focus on static input/output filtering. However, we argue that ensuring LLM agents reliability requires auditing the intermediate execution process. In this work, we formulate the task of Trajectory Anomaly Detection. The goal is not merely detection, but precise error localization. This capability is essential for enabling efficient rollback-and-retry. To achieve this, we construct TrajBench, a dataset synthesized via a perturb-and-complete strategy to cover diverse procedural anomalies. Using this benchmark, we investigate the capability of models in process supervision. We observe that general-purpose LLMs, even with zero-shot prompting, struggle to identify and localize these anomalies. This reveals that generalized capabilities do not automatically translate to process reliability. To address this, we propose TrajAD, a specialized verifier trained with fine-grained process supervision. Our approach outperforms baselines, demonstrating that specialized supervision is essential for building trustworthy agents.

</details>


### [33] [Malicious Agent Skills in the Wild: A Large-Scale Security Empirical Study](https://arxiv.org/abs/2602.06547)
*Yi Liu,Zhihao Chen,Yanjun Zhang,Gelei Deng,Yuekang Li,Jianting Ning,Leo Yu Zhang*

Main category: cs.CR

TL;DR: 이번 연구는 커뮤니티 레지스트리에서 98,380개의 스킬을 검증하며 악성 에이전트 스킬의 첫 번째 라벨 데이터셋을 구성하였다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트에 대한 제3자 스킬의 위협을 파악하기 위해.

Method: 두 개의 커뮤니티 레지스트리에서 스킬을 행동적으로 검증하여 157개의 악성 스킬과 632개의 취약점을 확인하였다.

Result: 악성 스킬은 평균 4.03개의 취약점을 보이며, 데이터 절도자와 에이전트 탈취자의 두 가지 유형으로 분류되었다.

Conclusion: 이 연구는 에이전트 스킬 보안에 대한 향후 연구를 지원하기 위해 데이터셋과 분석 파이프라인을 공개하였다.

Abstract: Third-party agent skills extend LLM-based agents with instruction files and executable code that run on users' machines. Skills execute with user privileges and are distributed through community registries with minimal vetting, but no ground-truth dataset exists to characterize the resulting threats. We construct the first labeled dataset of malicious agent skills by behaviorally verifying 98,380 skills from two community registries, confirming 157 malicious skills with 632 vulnerabilities. These attacks are not incidental. Malicious skills average 4.03 vulnerabilities across a median of three kill chain phases, and the ecosystem has split into two archetypes: Data Thieves that exfiltrate credentials through supply chain techniques, and Agent Hijackers that subvert agent decision-making through instruction manipulation. A single actor accounts for 54.1\% of confirmed cases through templated brand impersonation. Shadow features, capabilities absent from public documentation, appear in 0\% of basic attacks but 100\% of advanced ones; several skills go further by exploiting the AI platform's own hook system and permission flags. Responsible disclosure led to 93.6\% removal within 30 days. We release the dataset and analysis pipeline to support future work on agent skill security.

</details>


### [34] [TrapSuffix: Proactive Defense Against Adversarial Suffixes in Jailbreaking](https://arxiv.org/abs/2602.06630)
*Mengyao Du,Han Fang,Haokai Ma,Gang Yang,Quanjun Yin,Shouling Ji,Ee-Chien Chang*

Main category: cs.CR

TL;DR: TrapSuffix는 악성 접미사를 방지하는 능동 방어를 제안하여, 공격자가 최적화 함정에 빠지게 하거나 식별 가능한 접미사를 생성하도록 유도하여 공격 성공률을 낮추고 추적 가능성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 기존 방어는 공격자의 접미사를 수동적으로 탐지하는 것에 의존하지만, 이에 대한 비대칭 능력을 활용하여 사전 방어가 필요한 상황이다.

Method: TrapSuffix는 모델의 응답 경관을 조정하여 공격자를 두 가지 결과로 유도하는 경량화된 미세 조정 접근법이다.

Result: TrapSuffix는 공격 성공률을 0.01% 이하로 줄이고, 추적 성공률을 87.9%로 달성한다.

Conclusion: TrapSuffix는 추가적인 메모리 비용이 소량이며, 기존 필터링 기반 방어와 자연스럽게 결합되어 보완적인 보호를 제공한다.

Abstract: Suffix-based jailbreak attacks append an adversarial suffix, i.e., a short token sequence, to steer aligned LLMs into unsafe outputs. Since suffixes are free-form text, they admit endlessly many surface forms, making jailbreak mitigation difficult. Most existing defenses depend on passive detection of suspicious suffixes, without leveraging the defender's inherent asymmetric ability to inject secrets and proactively conceal gaps. Motivated by this, we take a controllability-oriented perspective and develop a proactive defense that nudges attackers into a no-win dilemma: either they fall into defender-designed optimization traps and fail to produce an effective adversarial suffix, or they can succeed only by generating adversarial suffixes that carry distinctive, traceable fingerprints. We propose TrapSuffix, a lightweight fine-tuning approach that injects trap-aligned behaviors into the base model without changing the inference pipeline. TrapSuffix channels jailbreak attempts into these two outcomes by reshaping the model's response landscape to adversarial suffixes. Across diverse suffix-based jailbreak settings, TrapSuffix reduces the average attack success rate to below 0.01 percent and achieves an average tracing success rate of 87.9 percent, providing both strong defense and reliable traceability. It introduces no inference-time overhead and incurs negligible memory cost, requiring only 15.87 MB of additional memory on average, whereas state-of-the-art LLM-based detection defenses typically incur memory overheads at the 1e4 MB level, while composing naturally with existing filtering-based defenses for complementary protection.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [35] [Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning](https://arxiv.org/abs/2602.06107)
*Zhuoming Chen,Hongyi Liu,Yang Zhou,Haizhong Zheng,Beidi Chen*

Main category: cs.AI

TL;DR: Jackpot라는 새로운 프레임워크는 최적 예산 거부 샘플링(OBRS)을 활용하여 RL에서 롤아웃 모델과 정책 간의 불일치를 줄이고, 훈련 안정성을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델에 대한 강화 학습은 롤아웃이 비용이 많이 드는 현상 때문에 비효율적입니다. 롤아웃 생성과 정책 최적화를 분리하는 것이 효율성을 크게 향상시킬 수 있지만, 이는 학습을 불안정하게 만드는 심각한 분포 불일치를 초래합니다.

Method: Jackpot은 OBRS를 활용하여 롤아웃 모델과 진화하는 정책 간의 불일치를 직접 줄이는 프레임워크입니다. OBRS 절차, 정책 및 롤아웃 모델을 공동으로 업데이트하는 통합 훈련 목표, 상위 k 확률 추정 및 배치 수준 편향 보정을 통한 효율적인 시스템 구현이 통합되어 있습니다.

Result: 이론적 분석에 따르면, OBRS는 조절 가능한 수용 예산 하에서 롤아웃 분포를 목표 분포에 일관되게 가깝게 이동시킵니다. 경험적으로 	exttt{Jackpot}은 중요도 샘플링 기준선에 비해 훈련 안정성을 크게 향상시키며, Qwen3-8B-Base를 배치 크기 64로 300 업데이트 단계 동안 훈련했을 때 on-policy RL과 유사한 성능을 달성합니다.

Conclusion: OBRS 기반의 정렬이 대형 언어 모델에 대한 RL의 롤아웃 생성과 정책 최적화의 실용적이고 효과적인 분리를 한 걸음 더 가까이 가져온다는 것을 보여줍니다.

Abstract: Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable substantial efficiency gains, yet doing so introduces a severe distribution mismatch that destabilizes learning. We propose Jackpot, a framework that leverages Optimal Budget Rejection Sampling (OBRS) to directly reduce the discrepancy between the rollout model and the evolving policy. Jackpot integrates a principled OBRS procedure, a unified training objective that jointly updates the policy and rollout models, and an efficient system implementation enabled by top-$k$ probability estimation and batch-level bias correction. Our theoretical analysis shows that OBRS consistently moves the rollout distribution closer to the target distribution under a controllable acceptance budget. Empirically, \sys substantially improves training stability compared to importance-sampling baselines, achieving performance comparable to on-policy RL when training Qwen3-8B-Base for up to 300 update steps of batchsize 64. Taken together, our results show that OBRS-based alignment brings us a step closer to practical and effective decoupling of rollout generation from policy optimization for RL for LLMs.

</details>


### [36] [Do LLMs Act Like Rational Agents? Measuring Belief Coherence in Probabilistic Decision Making](https://arxiv.org/abs/2602.06286)
*Khurram Yamin,Jingjing Tang,Santiago Cortes-Gomez,Amit Sharma,Eric Horvitz,Bryan Wilder*

Main category: cs.AI

TL;DR: 대형 언어 모델이 불확실성과 다양한 결과의 유틸리티를 고려할 때 합리적 유틸리티 극대화기가 될 수 있는지 연구하였다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델이 고위험 도메인에서 최적의 행동을 결정하는데 어려움을 겪고 있어, 이들의 의사결정 로직을 이해하려는 필요가 있다.

Method: 모델의 행동을 진단 과제 문제에 적용하고, 보고된 확률이 합리적 에이전트의 진정한 신념과 일치할 수 없는 조건을 제시하였다.

Result: 대형 언어 모델의 추론과 이상적인 베이시안 유틸리티 극대화 간의 관계에 대한 통찰을 제공한다.

Conclusion: 대형 언어 모델을 사용할 때 고위험 결정 안내에 있어 결과의 함의를 논의하였다.

Abstract: Large language models (LLMs) are increasingly deployed as agents in high-stakes domains where optimal actions depend on both uncertainty about the world and consideration of utilities of different outcomes, yet their decision logic remains difficult to interpret. We study whether LLMs are rational utility maximizers with coherent beliefs and stable preferences. We consider behaviors of models for diagnosis challenge problems. The results provide insights about the relationship of LLM inferences to ideal Bayesian utility maximization for elicited probabilities and observed actions. Our approach provides falsifiable conditions under which the reported probabilities \emph{cannot} correspond to the true beliefs of any rational agent. We apply this methodology to multiple medical diagnostic domains with evaluations across several LLMs. We discuss implications of the results and directions forward for uses of LLMs in guiding high-stakes decisions.

</details>


### [37] [Trifuse: Enhancing Attention-Based GUI Grounding via Multimodal Fusion](https://arxiv.org/abs/2602.06351)
*Longhui Ma,Di Zhao,Siwei Wang,Zhao Lv,Miao Wang*

Main category: cs.AI

TL;DR: Trifuse는 GUI 에이전트를 위한 주의 기반의 접지 프레임워크로, 보완적인 공간 앵커를 통합하여 강력한 성능을 달성합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 GUI 접지 방법들은 많은 데이터 의존성을 갖고 있으며, 보이지 않는 인터페이스에 대한 일반화가 좋지 않습니다. 이러한 한계를 극복하기 위해 새로운 접근 방식이 필요합니다.

Method: Trifuse는 Attention, OCR 유래 텍스트 신호, 아이콘 수준의 캡션 의미론을 Consensus-SinglePeak 융합 전략을 통해 통합하여 교차 모달 일치를 강제하며 선명한 위치화를 유지합니다.

Result: Trifuse는 네 가지 접지 벤치마크에서 강력한 성능을 달성하며, 비태스크 특정 미세 조정이 필요하고 비싼 주석 데이터 의존성을 크게 줄입니다.

Conclusion: OCR 및 캡션 신호를 통합하는 것이 다양한 백본에서 주의 기반 접지 성능을 일관되게 향상시킴을 보여주어, GUI 접지를 위한 일반 프레임워크로서의 효과를 강조합니다.

Abstract: GUI grounding maps natural language instructions to the correct interface elements, serving as the perception foundation for GUI agents. Existing approaches predominantly rely on fine-tuning multimodal large language models (MLLMs) using large-scale GUI datasets to predict target element coordinates, which is data-intensive and generalizes poorly to unseen interfaces. Recent attention-based alternatives exploit localization signals in MLLMs attention mechanisms without task-specific fine-tuning, but suffer from low reliability due to the lack of explicit and complementary spatial anchors in GUI images. To address this limitation, we propose Trifuse, an attention-based grounding framework that explicitly integrates complementary spatial anchors. Trifuse integrates attention, OCR-derived textual cues, and icon-level caption semantics via a Consensus-SinglePeak (CS) fusion strategy that enforces cross-modal agreement while retaining sharp localization peaks. Extensive evaluations on four grounding benchmarks demonstrate that Trifuse achieves strong performance without task-specific fine-tuning, substantially reducing the reliance on expensive annotated data. Moreover, ablation studies reveal that incorporating OCR and caption cues consistently improves attention-based grounding performance across different backbones, highlighting its effectiveness as a general framework for GUI grounding.

</details>


### [38] [AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents](https://arxiv.org/abs/2602.06485)
*Haotian Chen,Xin Cong,Shengda Fan,Yuyang Fu,Ziqin Gong,Yaxi Lu,Yishan Li,Boye Niu,Chengjun Pan,Zijun Song,Huadong Wang,Yesai Wu,Yueying Wu,Zihao Xie,Yukun Yan,Zhong Zhang,Yankai Lin,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: 본 논문에서는 4B-파라미터 스케일에서 에이전트 모델을 훈련하는 첫 번째 체계적인 연구를 제시하며, 에지 스케일 모델의 성능을 저해하는 세 가지 주요 병목 현상을 규명하고 이를 해결하기 위한 AgentCPM-Explore 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 모델에 의존하는 현재 시스템의 한계를 극복하고, 에지 스케일 모델의 가능성을 탐구하려는 동기에서 출발하였다.

Method: AgentCPM-Explore라는 고 지식 밀도와 강한 탐험 능력을 가진 4B 에이전트 모델을 제안하고, 파라미터-공간 모델 융합, 보상 신호 노이즈 제거 및 맥락 정보 정제를 포함하는 포괄적인 훈련 프레임워크를 소개한다.

Result: AgentCPM-Explore는 4B 클래스 모델 중에서 최첨단 성능을 달성하고, 8B 클래스 최첨단 모델을 네 가지 벤치마크에서 맞추거나 초과하며, Claude-4.5-Sonnet이나 DeepSeek-v3.2와 같은 대규모 모델을 다섯 가지 벤치마크에서 능가한다.

Conclusion: AgentCPM-Explore는 에지 스케일 모델의 잠재력이 본래의 능력 한계가 아니라 추론 안정성에서 오는 병목 현상임을 입증하며, 이 훈련 프레임워크를 기반으로 이전에 과소평가된 에지 스케일 모델의 잠재력을 효과적으로 발휘한다.

Abstract: While Large Language Model (LLM)-based agents have shown remarkable potential for solving complex tasks, existing systems remain heavily reliant on large-scale models, leaving the capabilities of edge-scale models largely underexplored. In this paper, we present the first systematic study on training agentic models at the 4B-parameter scale. We identify three primary bottlenecks hindering the performance of edge-scale models: catastrophic forgetting during Supervised Fine-Tuning (SFT), sensitivity to reward signal noise during Reinforcement Learning (RL), and reasoning degradation caused by redundant information in long-context scenarios. To address the issues, we propose AgentCPM-Explore, a compact 4B agent model with high knowledge density and strong exploration capability. We introduce a holistic training framework featuring parameter-space model fusion, reward signal denoising, and contextual information refinement. Through deep exploration, AgentCPM-Explore achieves state-of-the-art (SOTA) performance among 4B-class models, matches or surpasses 8B-class SOTA models on four benchmarks, and even outperforms larger-scale models such as Claude-4.5-Sonnet or DeepSeek-v3.2 in five benchmarks. Notably, AgentCPM-Explore achieves 97.09% accuracy on GAIA text-based tasks under pass@64. These results provide compelling evidence that the bottleneck for edge-scale models is not their inherent capability ceiling, but rather their inference stability. Based on our well-established training framework, AgentCPM-Explore effectively unlocks the significant, yet previously underestimated, potential of edge-scale models.

</details>


### [39] [JADE: Expert-Grounded Dynamic Evaluation for Open-Ended Professional Tasks](https://arxiv.org/abs/2602.06486)
*Lanbo Lin,Jiayao Liu,Tianyuan Yang,Li Cai,Yuanwu Xu,Lei Wei,Sicong Xie,Guannan Zhang*

Main category: cs.AI

TL;DR: JADE는 전문가 지식을 기반으로 한 두 계층 평가 프레임워크로, 안정성과 유연성을 함께 제공하여 다양한 논리적 접근을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 전문적인 작업에서 에이전틱 AI를 평가할 때 엄격성과 유연성 사이의 근본적인 딜레마가 존재한다.

Method: JADE는 두 개의 계층으로 구성된 평가 프레임워크로, 첫 번째 계층은 사전 정의된 평가 기술을 사용하여 안정적인 평가 기준을 제공하고, 두 번째 계층은 특정 보고서에 따라 다양하고 유연한 추론 전략을 평가한다.

Result: BizBench에서의 실험 결과, JADE는 평가의 안정성을 향상시키고 기존 LLM 기반 평가자가 놓친 중요한 에이전트 실패 모드를 드러낸다.

Conclusion: JADE는 전문가 저자가 작성한 루브릭과 높은 일치를 보이며, 의학 분야 벤치마크로의 효과적인 이전을 통해 다양한 전문 분야에서 검증된다.

Abstract: Evaluating agentic AI on open-ended professional tasks faces a fundamental dilemma between rigor and flexibility. Static rubrics provide rigorous, reproducible assessment but fail to accommodate diverse valid response strategies, while LLM-as-a-judge approaches adapt to individual responses yet suffer from instability and bias. Human experts address this dilemma by combining domain-grounded principles with dynamic, claim-level assessment. Inspired by this process, we propose JADE, a two-layer evaluation framework. Layer 1 encodes expert knowledge as a predefined set of evaluation skills, providing stable evaluation criteria. Layer 2 performs report-specific, claim-level evaluation to flexibly assess diverse reasoning strategies, with evidence-dependency gating to invalidate conclusions built on refuted claims. Experiments on BizBench show that JADE improves evaluation stability and reveals critical agent failure modes missed by holistic LLM-based evaluators. We further demonstrate strong alignment with expert-authored rubrics and effective transfer to a medical-domain benchmark, validating JADE across professional domains. Our code is publicly available at https://github.com/smiling-world/JADE.

</details>


### [40] [AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research](https://arxiv.org/abs/2602.06540)
*Yishan Li,Wentong Chen,Yukun Yan,Mingwei Li,Sen Mei,Xiaorong Wang,Kunpeng Liu,Xin Cong,Shuo Wang,Zhong Zhang,Yaxi Lu,Zhenghao Liu,Yankai Lin,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: AgentCPM-Report는 인간의 글쓰기 과정을 모방한 프레임워크와 8B-파라미터 딥 리서치 에이전트를 결합한 경량화된 로컬 솔루션으로, 기존 시스템보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 정보 수집과 통찰 기반 분석의 종합을 필요로 하는 깊이 있는 연구 보고서 생성을 위해 현재의 언어 모델이 직면한 문제를 해결하고자 한다.

Method: Writer As Reasoning Policy (WARP) 프레임워크를 사용하여 보고서 생성 중 동적으로 개요를 수정하고, Evidence-Based Drafting과 Reasoning-Driven Deepening을 번갈아 수행하며 정보를 수집하고 개요를 진화시킨다.

Result: AgentCPM-Report는 DeepResearch Bench, DeepConsult, DeepResearch Gym의 실험에서 선도적인 클로즈드 소스 시스템을 능가하며 통찰력에서 상당한 향상을 보여준다.

Conclusion: 작은 모델에게 효과적으로 이 기능을 부여하기 위해 Multi-Stage Agentic Training 전략을 도입하였다.

Abstract: Generating deep research reports requires large-scale information acquisition and the synthesis of insight-driven analysis, posing a significant challenge for current language models. Most existing approaches follow a plan-then-write paradigm, whose performance heavily depends on the quality of the initial outline. However, constructing a comprehensive outline itself demands strong reasoning ability, causing current deep research systems to rely almost exclusively on closed-source or online large models. This reliance raises practical barriers to deployment and introduces safety and privacy concerns for user-authored data. In this work, we present AgentCPM-Report, a lightweight yet high-performing local solution composed of a framework that mirrors the human writing process and an 8B-parameter deep research agent. Our framework uses a Writing As Reasoning Policy (WARP), which enables models to dynamically revise outlines during report generation. Under this policy, the agent alternates between Evidence-Based Drafting and Reasoning-Driven Deepening, jointly supporting information acquisition, knowledge refinement, and iterative outline evolution. To effectively equip small models with this capability, we introduce a Multi-Stage Agentic Training strategy, consisting of cold-start, atomic skill RL, and holistic pipeline RL. Experiments on DeepResearch Bench, DeepConsult, and DeepResearch Gym demonstrate that AgentCPM-Report outperforms leading closed-source systems, with substantial gains in Insight.

</details>


### [41] [SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees](https://arxiv.org/abs/2602.06554)
*Tianyi Hu,Qingxu Fu,Yanxi Chen,Zhaoyang Liu,Bolin Ding*

Main category: cs.AI

TL;DR: 본 논문은 강화 학습 알고리즘이 다중 턴 시나리오에서 수렴 보장을 갖지 못하는 문제를 다루며, SeeUPO라는 새로운 접근 방식을 제안하여 훈련의 안정성과 수렴성을 개선함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 기반 AI 에이전트 훈련에서 기존 강화 학습 알고리즘이 다중 턴 시나리오에서 수렴 보장이 부족하여 발생하는 훈련 불안정성을 해결하기 위해.

Method: SeeUPO(Sequence-level Sequential Update Policy Optimization)는 다중 턴 상호작용을 순차적으로 실행된 다중 에이전트 밴딧 문제로 모델링하며, 후진 유도를 통해 전반적인 최적 솔루션에 수렴하도록 보장한다.

Result: SeeUPO는 기존 알고리즘보다 Qwen3-14B에서 43.3%-54.6%, Qwen2.5-14B에서 24.1%-41.9%의 상대적인 개선을 보이며, 훈련 안정성 또한 뛰어났다.

Conclusion: SeeUPO는 다중 턴 상호작용에 대한 비평가 없는 접근법으로, 강화 학습의 수렴성을 보장하며 훈련의 개선을 입증하였다.

Abstract: Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies.
  In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/multi-turn scenarios. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios.
  To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction.
  Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability.

</details>


### [42] [Same Answer, Different Representations: Hidden instability in VLMs](https://arxiv.org/abs/2602.06652)
*Farooq Ahmad Wani,Alessandro Suglia,Rohit Saxena,Aryo Pradipta Gema,Wai-Chung Kwan,Fazl Barez,Maria Sofia Bucarelli,Fabrizio Silvestri,Pasquale Minervini*

Main category: cs.AI

TL;DR: 이번 연구에서는 비전 언어 모델(VLM)의 강건성을 평가하기 위한 새로운 평가 프레임워크를 제안하며, 내부 표현의 드리프트와 스펙트럼 감도, 구조적 매끄러움을 측정합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 VLM 강건성 평가는 출력 수준 불변성을 통해 이루어지며, 이는 안정적인 예측이 안정적인 다중 모드 처리를 반영한다고 가정합니다. 하지만 우리는 이러한 가정이 불충분하다고 주장합니다.

Method: 우리는 내부 임베딩 드리프트, 스펙트럴 감도, 구조적 매끄러움(비전 토큰의 공간적 일관성)을 측정하는 표현 인식 및 주파수 인식 평가 프레임워크를 제안합니다.

Result: SEEDBench, MMMU, 및 POPE 데이터셋에 현대 VLM에 이 프레임워크를 적용한 결과, 세 가지 구별되는 실패 모드를 발견했습니다.

Conclusion: 이 연구는 VLM의 강건성 평가에 대한 새로운 통찰을 제공하며, 모델의 대표성과 오류 발생 메커니즘에 대한 이해를 심화시킵니다.

Abstract: The robustness of Vision Language Models (VLMs) is commonly assessed through output-level invariance, implicitly assuming that stable predictions reflect stable multimodal processing. In this work, we argue that this assumption is insufficient. We introduce a representation-aware and frequency-aware evaluation framework that measures internal embedding drift, spectral sensitivity, and structural smoothness (spatial consistency of vision tokens), alongside standard label-based metrics. Applying this framework to modern VLMs across the SEEDBench, MMMU, and POPE datasets reveals three distinct failure modes. First, models frequently preserve predicted answers while undergoing substantial internal representation drift; for perturbations such as text overlays, this drift approaches the magnitude of inter-image variability, indicating that representations move to regions typically occupied by unrelated inputs despite unchanged outputs. Second, robustness does not improve with scale; larger models achieve higher accuracy but exhibit equal or greater sensitivity, consistent with sharper yet more fragile decision boundaries. Third, we find that perturbations affect tasks differently: they harm reasoning when they disrupt how models combine coarse and fine visual cues, but on the hallucination benchmarks, they can reduce false positives by making models generate more conservative answers.

</details>


### [43] [Semantically Labelled Automata for Multi-Task Reinforcement Learning with LTL Instructions](https://arxiv.org/abs/2602.06746)
*Alessandro Abate,Giuseppe De Giacomo,Mathias Jackermeier,Jan Kretínský,Maximilian Prokop,Christoph Weinhuber*

Main category: cs.AI

TL;DR: 본 연구에서는 단일 보편적인 정책을 학습하여 다양한 작업에 일반화할 수 있는 다중 작업 강화 학습을 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 다양한, 미지의 작업에 일반화 가능한 단일 정책을 학습하는 것이 목표입니다.

Method: 선형 시간 논리(LTL) 공식을 사용하여 작업을 정의하고, 시간 합성을 위해 개발된 새로운 LTL-오토마타 번역을 활용한 작업 임베딩 기법을 제시합니다.

Result: 다양한 도메인에서 실험 결과, 본 접근법이 최첨단 성능을 보이고 복잡한 사양에 대해 기존 방법이 실패하는 상황에서도 확장 가능함을 입증합니다.

Conclusion: 제안된 방법은 작업 임베딩을 통해 정책을 조건화하고, LTL의 완전한 지원을 자연스럽게 제공합니다.

Abstract: We study multi-task reinforcement learning (RL), a setting in which an agent learns a single, universal policy capable of generalising to arbitrary, possibly unseen tasks. We consider tasks specified as linear temporal logic (LTL) formulae, which are commonly used in formal methods to specify properties of systems, and have recently been successfully adopted in RL. In this setting, we present a novel task embedding technique leveraging a new generation of semantic LTL-to-automata translations, originally developed for temporal synthesis. The resulting semantically labelled automata contain rich, structured information in each state that allow us to (i) compute the automaton efficiently on-the-fly, (ii) extract expressive task embeddings used to condition the policy, and (iii) naturally support full LTL. Experimental results in a variety of domains demonstrate that our approach achieves state-of-the-art performance and is able to scale to complex specifications where existing methods fail.

</details>


### [44] [ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training](https://arxiv.org/abs/2602.06820)
*Dunwei Tu,Hongyan Hao,Hansi Yang,Yihao Chen,Yi-Kai Zhang,Zhikang Xia,Yu Yang,Yueqing Sun,Xingchen Liu,Furao Shen,Qi Gu,Hui Su,Xunliang Cai*

Main category: cs.AI

TL;DR: ScaleEnv라는 인터랙티브 환경 프레임워크를 소개하며, 이를 통해 다양한 상황에 적응할 수 있는 에이전트를 훈련시킬 수 있는 가능성을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 시나리오에 적응할 수 있는 일반화 에이전트를 훈련시키기 위해서는 자가 탐색을 위한 상호작용 환경이 필요하지만, 이러한 환경이 부족하다.

Method: ScaleEnv는 완전한 상호작용 환경과 검증 가능한 작업을 처음부터 끝까지 구성하는 프레임워크로, 절차적 테스트를 통해 환경의 신뢰성을 보장하고 도구 의존 그래프 확장 및 실행 가능 행동 검증을 통해 작업의 완전성과 해결 가능성을 보장한다.

Result: ScaleEnv를 통해 에이전트가 탐색을 통해 학습하도록 하여 $τ^2$-Bench 및 VitaBench와 같은 보지 못한 멀티턴 도구 사용 기준에서 성능 향상을 보여준다.

Conclusion: 환경 다양성을 확장하는 것이 강인한 에이전트 학습에 필수적이라는 경험적 증거를 제공하며, 도메인의 수 증가와 모델 일반화 성능 간의 관계를 조사한다.

Abstract: Training generalist agents capable of adapting to diverse scenarios requires interactive environments for self-exploration. However, interactive environments remain critically scarce, and existing synthesis methods suffer from significant limitations regarding environmental diversity and scalability. To address these challenges, we introduce ScaleEnv, a framework that constructs fully interactive environments and verifiable tasks entirely from scratch. Specifically, ScaleEnv ensures environment reliability through procedural testing, and guarantees task completeness and solvability via tool dependency graph expansion and executable action verification. By enabling agents to learn through exploration within ScaleEnv, we demonstrate significant performance improvements on unseen, multi-turn tool-use benchmarks such as $τ^2$-Bench and VitaBench, highlighting strong generalization capabilities. Furthermore, we investigate the relationship between increasing number of domains and model generalization performance, providing empirical evidence that scaling environmental diversity is critical for robust agent learning.

</details>


### [45] [LLM Active Alignment: A Nash Equilibrium Perspective](https://arxiv.org/abs/2602.06836)
*Tonghan Wang,Yuqi Pan,Xinyi Yang,Yanchen Jiang,Milind Tambe,David C. Parkes*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델(LLM) 집단의 행동을 예측하고 조정하기 위한 게임 이론적 프레임워크를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: LLM의 행동을 예측하고 조정하여 사회적으로 바람직한 결과를 도출하는 것이 필요하다.

Method: 각 에이전트의 행동을 인간 하위 집단에 대한 혼합으로 모델링하여 균형 계산의 복잡성을 피하고, 닷지 균형을 유도한다.

Result: 제안한 방법은 특히 특정 하위 집단이 모든 LLM 에이전트에 의해 무시되는 정치적 배제를 방지할 수 있음을 보여준다.

Conclusion: 이 방법은 다중 에이전트 LLM 역학을 조절하는 데 유망함을 보여준다.

Abstract: We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we model each agent's action as a mixture over human subpopulations. Agents choose actively and strategically which groups to align with, yielding an interpretable and behaviorally substantive policy class. We derive closed-form NE characterizations, adopting standard concave-utility assumptions to enable analytical system-level predictions and give explicit, actionable guidance for shifting alignment targets toward socially desirable outcomes. The method functions as an active alignment layer on top of existing alignment pipelines such as RLHF. In a social-media setting, we show that a population of LLMs, especially reasoning-based models, may exhibit political exclusion, pathologies where some subpopulations are ignored by all LLM agents, which can be avoided by our method, illustrating the promise of applying the method to regulate multi-agent LLM dynamics across domains.

</details>


### [46] [From Features to Actions: Explainability in Traditional and Agentic AI Systems](https://arxiv.org/abs/2602.06841)
*Sindhuja Chaduvula,Jessee Ho,Kina Kim,Aravind Narayanan,Mahshid Alinoori,Muskan Garg,Dhanesh Ramachandram,Shaina Raza*

Main category: cs.AI

TL;DR: 이 논문은 정적 예측과 주체적 설명 가능성 간의 간극을 해소하고, 주체적 AI 시스템에서의 행동 분석 방법을 비교합니다.


<details>
  <summary>Details</summary>
Motivation: 정적 예측을 위한 설명 접근법이 시간에 따라 행동이 나타나는 주체적 환경에 어떻게 적용될 수 있는지 이해하는 것이 필요합니다.

Method: 정적 분류 작업에 사용되는 기여 기반 설명과 주체적 벤치마크에서 사용되는 추적 기반 진단을 비교합니다.

Result: 기여 기반 방법은 정적 환경에서 안정적인 특성 순위를 달성하지만, 주체적 경로에서 실행 수준의 실패를 진단하는 데 신뢰할 수 없습니다. 반면, 추적 기반 평가는 행동 중단을 일관되게 정위하고 실패한 실행에서 상태 추적 불일치가 2.7배 더 발생한다고 나타났습니다.

Conclusion: 주체적 AI 행동을 평가하고 진단할 때 궤적 수준의 설명 가능성으로의 전환이 필요하다는 것을 강조합니다.

Abstract: Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequences of decisions rather than a single output. While useful, it remains unclear how explanation approaches designed for static predictions translate to agentic settings where behaviour emerges over time. In this work, we bridge the gap between static and agentic explainability by comparing attribution-based explanations with trace-based diagnostics across both settings. To make this distinction explicit, we empirically compare attribution-based explanations used in static classification tasks with trace-based diagnostics used in agentic benchmarks (TAU-bench Airline and AssistantBench). Our results show that while attribution methods achieve stable feature rankings in static settings (Spearman $ρ= 0.86$), they cannot be applied reliably to diagnose execution-level failures in agentic trajectories. In contrast, trace-grounded rubric evaluation for agentic settings consistently localizes behaviour breakdowns and reveals that state tracking inconsistency is 2.7$\times$ more prevalent in failed runs and reduces success probability by 49\%. These findings motivate a shift towards trajectory-level explainability for agentic systems when evaluating and diagnosing autonomous AI behaviour.
  Resources:
  https://github.com/VectorInstitute/unified-xai-evaluation-framework https://vectorinstitute.github.io/unified-xai-evaluation-framework

</details>


### [47] [AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents](https://arxiv.org/abs/2602.06855)
*Alisia Lupidi,Bhavul Gauri,Thomas Simon Foster,Bassel Al Omari,Despoina Magka,Alberto Pepe,Alexis Audran-Reiss,Muna Aghamelu,Nicolas Baldwin,Lucia Cipolina-Kun,Jean-Christophe Gagnon-Audet,Chee Hau Leow,Sandra Lefdal,Hossam Mossalam,Abhinav Moudgil,Saba Nazir,Emanuel Tewolde,Isabel Urrego,Jordi Armengol Estape,Amar Budhiraja,Gaurav Chaurasia,Abhishek Charnalia,Derek Dunfield,Karen Hambardzumyan,Daniel Izcovich,Martin Josifoski,Ishita Mediratta,Kelvin Niu,Parth Pathak,Michael Shvartsman,Edan Toledo,Anton Protopopov,Roberta Raileanu,Alexander Miller,Tatiana Shavrina,Jakob Foerster,Yoram Bachrach*

Main category: cs.AI

TL;DR: AIRS-Bench는 과학 연구를 위한 LLM 에이전트의 가능성을 가속화하기 위한 20개의 다양한 작업으로 구성된 벤치마크를 제공한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 과학 연구 발전 가능성을 증대시키기 위해.

Method: 20개의 최신 기계 학습 논문에서 가져온 작업을 포함하고, 다양한 도메인에서 에이전트의 능력을 평가한다.

Result: 에이전트는 4개의 작업에서 인간의 최첨단 성능을 초과하지만, 16개 작업에서는 이를 달성하지 못한다.

Conclusion: AIRS-Bench는 여전히 발전 가능성이 크며, 오픈 소스로 관련 작업 정의와 평가 코드를 제공한다.

Abstract: LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilities over the full research lifecycle -- including idea generation, experiment analysis and iterative refinement -- without providing baseline code. The AIRS-Bench task format is versatile, enabling easy integration of new tasks and rigorous comparison across different agentic frameworks. We establish baselines using frontier models paired with both sequential and parallel scaffolds. Our results show that agents exceed human SOTA in four tasks but fail to match it in sixteen others. Even when agents surpass human benchmarks, they do not reach the theoretical performance ceiling for the underlying tasks. These findings indicate that AIRS-Bench is far from saturated and offers substantial room for improvement. We open-source the AIRS-Bench task definitions and evaluation code to catalyze further development in autonomous scientific research.

</details>


### [48] [Agentic Uncertainty Reveals Agentic Overconfidence](https://arxiv.org/abs/2602.06948)
*Jean Kaddour,Srijan Patel,Gbètondji Dovonon,Leo Richter,Pasquale Minervini,Matt J. Kusner*

Main category: cs.AI

TL;DR: AI 에이전트가 작업 성공 여부를 예측할 수 있는가에 대한 연구로, 에이전트는 작업 실행 전, 중, 후에 성공 확률 추정치를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트의 불확실성을 이해하고, 작업 성공 예측 능력을 평가하기 위해.

Method: 작업 실행 전, 중, 후에 성공 확률을 추정하도록 유도하여 에이전트의 반응을 분석하였다.

Result: 두 번의 작업 평가에서 성공률이 실제로는 22%인 에이전트가 77%의 성공률을 예측하는 등 에이전트의 과신이 관찰되었다.

Conclusion: 정보가 더 적은 실행 전 평가가 표준 실행 후 검토보다 더 나은 분별력을 보이는 경향이 있으며, 적대적 프롬프트를 사용하여 버그 찾기로 평가를 재구성하는 것이 가장 좋은 보정을 이루었다.

Abstract: Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination than standard post-execution review, though differences are not always significant. Adversarial prompting reframing assessment as bug-finding achieves the best calibration.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [49] [Communication Enhances LLMs' Stability in Strategic Thinking](https://arxiv.org/abs/2602.06081)
*Nunzio Lore,Babak Heydari*

Main category: cs.MA

TL;DR: 본 연구는 대형 언어 모델에서의 전략적 행동의 예측 가능성을 향상시키기 위한 통신의 역할을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 전략적 사고가 필요한 작업에서 다중 에이전트 행동의 예측 가능성을 저해하는 맥락 의존적 변동성을 해소하고자 한다.

Method: 7억에서 9억 개 변수를 가진 모델들을 대상으로 한 열 번 반복된 죄수의 딜레마 실험에서, 저비용의 사전 메시지가 전략적 안정성에 미치는 영향을 평가하기 위해 시뮬레이션 수준의 부트스트랩 재표집 및 비모수 추론을 사용한다.

Result: 대부분의 모델-맥락 조합에서 경로의 잡음이 일관되게 감소하는 것을 입증하였다.

Conclusion: 저비용의 통신 방식이 다중 에이전트 LLM 시스템에서 전략적 행동의 예측 가능성과 신뢰성을 향상시키는 유효한 도구로 자리잡을 수 있음을 보여준다.

Abstract: Large Language Models (LLMs) often exhibit pronounced context-dependent variability that undermines predictable multi-agent behavior in tasks requiring strategic thinking. Focusing on models that range from 7 to 9 billion parameters in size engaged in a ten-round repeated Prisoner's Dilemma, we evaluate whether short, costless pre-play messages emulating the cheap-talk paradigm affect strategic stability. Our analysis uses simulation-level bootstrap resampling and nonparametric inference to compare cooperation trajectories fitted with LOWESS regression across both the messaging and the no-messaging condition. We demonstrate consistent reductions in trajectory noise across a majority of the model-context pairings being studied. The stabilizing effect persists across multiple prompt variants and decoding regimes, though its magnitude depends on model choice and contextual framing, with models displaying higher baseline volatility gaining the most. While communication rarely produces harmful instability, we document a few context-specific exceptions and identify the limited domains in which communication harms stability. These findings position cheap-talk style communication as a low-cost, practical tool for improving the predictability and reliability of strategic behavior in multi-agent LLM systems.

</details>


### [50] [Prism: Spectral Parameter Sharing for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.06476)
*Kyungbeom Kim,Seungwon Oh,Kyung-Joong Kim*

Main category: cs.MA

TL;DR: Prism은 다중 에이전트 강화 학습에서 매개변수 공유를 통해 에이전트 간 다양성을 유도하는 프레임워크로, 리소스 효율성을 유지하며 경쟁력 있는 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습에서 매개변수 공유는 확장성을 개선하는 핵심 전략이지만, 기존의 완전 공유 아키텍처는 동질적인 행동으로 붕괴되는 경향이 있다.

Method: Prism은 특이값 분해(SVD)를 통해 공유 네트워크를 스펙트럼 도메인으로 나타내어 에이전트 간 다양성을 유도하는 매개변수 공유 프레임워크이다. 모든 에이전트는 독특한 스펙트럴 마스크를 학습하면서 특이 벡터 방향을 공유한다.

Result: 동질적(LBF, SMACv2) 및 이질적(MaMuJoCo) 벤치마크에서의 광범위한 실험에서 Prism은 우수한 리소스 효율성으로 경쟁력 있는 성능을 달성하였다.

Conclusion: Prism 메커니즘은 에이전트 간 다양성을 촉진하며 확장성을 유지한다.

Abstract: Parameter sharing is a key strategy in multi-agent reinforcement learning (MARL) for improving scalability, yet conventional fully shared architectures often collapse into homogeneous behaviors. Recent methods introduce diversity through clustering, pruning, or masking, but typically compromise resource efficiency. We propose Prism, a parameter sharing framework that induces inter-agent diversity by representing shared networks in the spectral domain via singular value decomposition (SVD). All agents share the singular vector directions while learning distinct spectral masks on singular values. This mechanism encourages inter-agent diversity and preserves scalability. Extensive experiments on both homogeneous (LBF, SMACv2) and heterogeneous (MaMuJoCo) benchmarks show that Prism achieves competitive performance with superior resource efficiency.

</details>


### [51] [Sample-Efficient Policy Space Response Oracles with Joint Experience Best Response](https://arxiv.org/abs/2602.06599)
*Ariyan Bighashdel,Thiago D. Simão,Frans A. Oliehoek*

Main category: cs.MA

TL;DR: Joint Experience Best Response (JBR)는 멀티 에이전트 강화 학습에서 정책 공간 응답 오라클(PSRO)의 성능을 개선하기 위한 방법으로, 모든 에이전트의 최적 응답을 동시에 계산하여 환경 상호작용을 절약하고 샘플 효율성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 멀티 에이전트 강화 학습(MARL)은 게임 이론 분석의 확장 가능한 대안을 제공하지만 비정상성과 다양한 전략을 유지해야 하는 필요성으로 인해 어려움을 겪고 있다.

Method: Joint Experience Best Response (JBR)는 현재의 메타 전략 프로파일에 따라 궤적을 수집하고 이 공동 데이터셋을 사용하여 모든 에이전트의 최적 응답(BR)을 동시에 계산한다.

Result: Exploration-Augmented JBR는 벤치마크 멀티 에이전트 환경에서 최고의 정확성과 효율성의 균형을 이루며, Hybrid BR는 샘플 비용의 일부로 PSRO에 가까운 성능을 달성한다.

Conclusion: 전반적으로 JBR은 대규모 전략 학습에 있어 PSRO를 실용적으로 만들면서도 균형의 견고성을 유지한다.

Abstract: Multi-agent reinforcement learning (MARL) offers a scalable alternative to exact game-theoretic analysis but suffers from non-stationarity and the need to maintain diverse populations of strategies that capture non-transitive interactions. Policy Space Response Oracles (PSRO) address these issues by iteratively expanding a restricted game with approximate best responses (BRs), yet per-agent BR training makes it prohibitively expensive in many-agent or simulator-expensive settings. We introduce Joint Experience Best Response (JBR), a drop-in modification to PSRO that collects trajectories once under the current meta-strategy profile and reuses this joint dataset to compute BRs for all agents simultaneously. This amortizes environment interaction and improves the sample efficiency of best-response computation. Because JBR converts BR computation into an offline RL problem, we propose three remedies for distribution-shift bias: (i) Conservative JBR with safe policy improvement, (ii) Exploration-Augmented JBR that perturbs data collection and admits theoretical guarantees, and (iii) Hybrid BR that interleaves JBR with periodic independent BR updates. Across benchmark multi-agent environments, Exploration-Augmented JBR achieves the best accuracy-efficiency trade-off, while Hybrid BR attains near-PSRO performance at a fraction of the sample cost. Overall, JBR makes PSRO substantially more practical for large-scale strategic learning while preserving equilibrium robustness.

</details>
