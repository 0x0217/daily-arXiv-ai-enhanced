<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 11]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2509.09135)
*Xuefeng Wang,Lei Zhang,Henglin Pu,Ahmed H. Qureshi,Husheng Li*

Main category: cs.LG

TL;DR: 본 논문은 연속시간 강화 학습(CTRL) 방법으로 다중 요인 환경에서의 가치 함수 근사를 제안하여 정책 훈련의 안정성 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 강화 학습 방법은 고주파 또는 불규칙한 시간 간격에서의 상호작용이 필요한 복잡한 동적 시스템에서 어려움을 겪고 있습니다.

Method: 우리는 물리 정보 신경망(PINNs)을 사용하여 HJB 기반의 가치 함수를 대규모로 근사하는 CT-MARL 프레임워크를 제안합니다. 가치 학습과 가치 기울기 학습을 정렬하기 위해 Value Gradient Iteration(VGI) 모듈을 도입하여 경로를 따라 가치 기울기를 반복적으로 개선합니다.

Result: 우리의 방법은 다중 요인 입자 환경(MPE)과 다중 요인 MuJoCo를 포함한 표준 벤치마크의 연속 시간 변형을 사용하여 평가되었습니다.

Conclusion: 결과는 우리 접근 방식이 기존의 연속 시간 RL 기준을 일관되게 초과하며 복잡한 다중 에이전트 동적 시스템에 확장 가능함을 보여줍니다.

Abstract: Existing reinforcement learning (RL) methods struggle with complex dynamical
systems that demand interactions at high frequencies or irregular time
intervals. Continuous-time RL (CTRL) has emerged as a promising alternative by
replacing discrete-time Bellman recursion with differential value functions
defined as viscosity solutions of the Hamilton--Jacobi--Bellman (HJB) equation.
While CTRL has shown promise, its applications have been largely limited to the
single-agent domain. This limitation stems from two key challenges: (i)
conventional solution methods for HJB equations suffer from the curse of
dimensionality (CoD), making them intractable in high-dimensional systems; and
(ii) even with HJB-based learning approaches, accurately approximating
centralized value functions in multi-agent settings remains difficult, which in
turn destabilizes policy training. In this paper, we propose a CT-MARL
framework that uses physics-informed neural networks (PINNs) to approximate
HJB-based value functions at scale. To ensure the value is consistent with its
differential structure, we align value learning with value-gradient learning by
introducing a Value Gradient Iteration (VGI) module that iteratively refines
value gradients along trajectories. This improves gradient fidelity, in turn
yielding more accurate values and stronger policy learning. We evaluate our
method using continuous-time variants of standard benchmarks, including
multi-agent particle environment (MPE) and multi-agent MuJoCo. Our results
demonstrate that our approach consistently outperforms existing continuous-time
RL baselines and scales to complex multi-agent dynamics.

</details>


### [2] [Instance-Optimal Matrix Multiplicative Weight Update and Its Quantum Applications](https://arxiv.org/abs/2509.08911)
*Weiyuan Gong,Tongyang Li,Xinzhao Wang,Zhiyu Zhang*

Main category: cs.LG

TL;DR: MMWU 알고리즘의 향상된 버전을 제시하며, 최적의 후회 경계를 달성함.


<details>
  <summary>Details</summary>
Motivation: MMWU는 여러 응용 분야에서 사용되는 온라인 학습 알고리즘으로, LEA 문제에 효과적이다.

Method: 일반적인 잠재 기반 프레임워크를 개발하고, 새로운 '편향된' Jensen의 추적 불평등을 적용하였다.

Result: 향상된 최적 후회 경계인 O(√(T⋅S(X||d⁻¹Iₕ)))을 달성하며, 메모리 하한과 양자 학습 이론에서의 응용을 탐구하였다.

Conclusion: 우리는 다양한 양자 상태 학습 문제에서 MMWU 알고리즘 보다 더 나은 성능을 보여준다.

Abstract: The Matrix Multiplicative Weight Update (MMWU) is a seminal online learning
algorithm with numerous applications. Applied to the matrix version of the
Learning from Expert Advice (LEA) problem on the $d$-dimensional spectraplex,
it is well known that MMWU achieves the minimax-optimal regret bound of
$O(\sqrt{T\log d})$, where $T$ is the time horizon. In this paper, we present
an improved algorithm achieving the instance-optimal regret bound of
$O(\sqrt{T\cdot S(X||d^{-1}I_d)})$, where $X$ is the comparator in the regret,
$I_d$ is the identity matrix, and $S(\cdot||\cdot)$ denotes the quantum
relative entropy. Furthermore, our algorithm has the same computational
complexity as MMWU, indicating that the improvement in the regret bound is
``free''.
  Technically, we first develop a general potential-based framework for matrix
LEA, with MMWU being its special case induced by the standard exponential
potential. Then, the crux of our analysis is a new ``one-sided'' Jensen's trace
inequality built on a Laplace transform technique, which allows the application
of general potential functions beyond exponential to matrix LEA. Our algorithm
is finally induced by an optimal potential function from the vector LEA
problem, based on the imaginary error function.
  Complementing the above, we provide a memory lower bound for matrix LEA, and
explore the applications of our algorithm in quantum learning theory. We show
that it outperforms the state of the art for learning quantum states corrupted
by depolarization noise, random quantum states, and Gibbs states. In addition,
applying our algorithm to linearized convex losses enables predicting nonlinear
quantum properties, such as purity, quantum virtual cooling, and R\'{e}nyi-$2$
correlation.

</details>


### [3] [Data Driven Discovery of Emergent Dynamics in Reaction Diffusion Systems from Sparse and Noisy Observations](https://arxiv.org/abs/2509.09278)
*Saumitra Dwivedi,Ricardo da Silva Torres,Ibrahim A. Hameed,Gunnar Tufte,Anniken Susanne T. Karlsen*

Main category: cs.LG

TL;DR: 데이터 기반의 긴 급변 동역학 발견에 대한 연구는 특히 반응-확산 시스템에서 인기를 얻고 있다. 본 논문은 관찰된 데이터를 통해 반응-확산 시스템의 긴 급변 동역학을 정확하게 표현하는 소프트 인공 생명 규칙 집합을 학습하는 DRSALife 모델의 적용 가능성에 대한 연구 결과를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 반응-확산 시스템과 관련하여 기본 물리학에 대한 사전 지식 없이 시스템 식별과 같은 발견 과정에서의 현재의 도전 과제를 해결하는 것

Method: 소프트 인공 생명 모델, 즉 에이전트 기반 모델과 셀룰러 오토마타(CA) 모델을 관찰된 데이터로부터 학습하는 접근 방식을 사용

Result: 소프트 ALife 규칙 집합은 Elementary CA Rule 30, 생명의 게임, Vicsek 군집 문제에 대해 유망한 결과를 보여주었다.

Conclusion: 학습한 모델은 긴 급변 동역학을 74%의 좋은 정확도로 예측할 수 있으며, 가우시안 노이즈와 시간적 희소성에 대해 강력한 성능을 나타낸다.

Abstract: Data-driven discovery of emergent dynamics is gaining popularity,
particularly in the context of reaction-diffusion systems. These systems are
widely studied across various fields, including neuroscience, ecology,
epidemiology, and several other subject areas that deal with emergent dynamics.
A current challenge in the discovery process relates to system identification
when there is no prior knowledge of the underlying physics. We attempt to
address this challenge by learning Soft Artificial Life (Soft ALife) models,
such as Agent-based and Cellular Automata (CA) models, from observed data for
reaction-diffusion systems. In this paper, we present findings on the
applicability of a conceptual framework, the Data-driven Rulesets for Soft
Artificial Life (DRSALife) model, to learn Soft ALife rulesets that accurately
represent emergent dynamics in a reaction-diffusion system from observed data.
This model has demonstrated promising results for Elementary CA Rule 30, Game
of Life, and Vicsek Flocking problems in recent work. To our knowledge, this is
one of the few studies that explore machine-based Soft ALife ruleset learning
and system identification for reaction-diffusion dynamics without any prior
knowledge of the underlying physics. Moreover, we provide comprehensive
findings from experiments investigating the potential effects of using noisy
and sparse observed datasets on learning emergent dynamics. Additionally, we
successfully identify the structure and parameters of the underlying partial
differential equations (PDEs) representing these dynamics. Experimental results
demonstrate that the learned models are able to predict the emergent dynamics
with good accuracy (74%) and exhibit quite robust performance when subjected to
Gaussian noise and temporal sparsity.

</details>


### [4] [Learning What Matters: Causal Time Series Modeling for Arctic Sea Ice Prediction](https://arxiv.org/abs/2509.09128)
*Emam Hossain,Md Osman Gani*

Main category: cs.LG

TL;DR: 기존의 기계 학습 모델은 인과 관계를 혼동하여 해석 가능성과 일반화 능력이 제한된다. 본 연구에서는 인과 관계를 인식하는 딥 러닝 프레임워크를 제안하여 인과적 특징 선택을 수행하고 예측 정확성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 모델의 인과 관계 구분 한계를 극복하여 보다 견고하고 해석 가능한 예측 모델을 개발하고자 함.

Method: 인과 관계 인식 딥 러닝 프레임워크를 도입하고, Multivariate Granger Causality (MVGC) 및 PCMCI+를 결합하여 인과적 특징 선택을 수행.

Result: 43년간의 북극 해빙 데이터와 관련 변수들을 활용하여 인과적 영향을 미치는 예측 변수를 식별하고, SIE 동역학의 직접적 원인을 우선시하며, 필요 없는 특징을 줄이고 계산 효율성을 향상시킴.

Conclusion: 북극 해빙 예측에 대한 실행 가능성을 입증하며, 다른 동적 고차원 분야에도 적용할 수 있는 확장 가능한 접근 방식을 제공함.

Abstract: Conventional machine learning and deep learning models typically rely on
correlation-based learning, which often fails to distinguish genuine causal
relationships from spurious associations, limiting their robustness,
interpretability, and ability to generalize. To overcome these limitations, we
introduce a causality-aware deep learning framework that integrates
Multivariate Granger Causality (MVGC) and PCMCI+ for causal feature selection
within a hybrid neural architecture. Leveraging 43 years (1979-2021) of Arctic
Sea Ice Extent (SIE) data and associated ocean-atmospheric variables at daily
and monthly resolutions, the proposed method identifies causally influential
predictors, prioritizes direct causes of SIE dynamics, reduces unnecessary
features, and enhances computational efficiency. Experimental results show that
incorporating causal inputs leads to improved prediction accuracy and
interpretability across varying lead times. While demonstrated on Arctic SIE
forecasting, the framework is broadly applicable to other dynamic,
high-dimensional domains, offering a scalable approach that advances both the
theoretical foundations and practical performance of causality-informed
predictive modeling.

</details>


### [5] [Quantum Machine Learning, Quantitative Trading, Reinforcement Learning, Deep Learning](https://arxiv.org/abs/2509.09176)
*Jun-Hao Chen,Yu-Chien Huang,Yun-Cheng Tsai,Samuel Yen-Chi Chen*

Main category: cs.LG

TL;DR: 양자 영감을 받은 신경망과 심층 강화 학습의 융합은 금융 거래에서 유망한 경로를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 양자 영감을 받은 신경망과 심층 강화 학습을 결합하여 금융 거래의 성과를 개선할 수 있는 가능성 탐색.

Method: 단기 트렌드 예측을 위한 양자 장단기 메모리(QLSTM)와 고전적인 A3C의 양자 강화 변형인 양자 비동기 이점 액터-비평가(QA3C)를 통합하여 USD/TWD 거래 에이전트를 구현.

Result: 2000년 1월 1일부터 2025년 4월 30일까지의 데이터(80% 훈련, 20% 테스트)로 훈련된 장기 전용 에이전트는 약 5년 동안 11.87%의 수익을 기록했으며, 최대 0.92%의 하락폭을 보이며 여러 통화 ETF를 초월.

Conclusion: 하이브리드 모델은 경쟁력 있는 외환 거래 성과를 낳으며, QLSTM이 작은 이익 거래와 엄격한 리스크 관리를 위한 효과를 보여줍니다.

Abstract: The convergence of quantum-inspired neural networks and deep reinforcement
learning offers a promising avenue for financial trading. We implemented a
trading agent for USD/TWD by integrating Quantum Long Short-Term Memory (QLSTM)
for short-term trend prediction with Quantum Asynchronous Advantage
Actor-Critic (QA3C), a quantum-enhanced variant of the classical A3C. Trained
on data from 2000-01-01 to 2025-04-30 (80\% training, 20\% testing), the
long-only agent achieves 11.87\% return over around 5 years with 0.92\% max
drawdown, outperforming several currency ETFs. We detail state design (QLSTM
features and indicators), reward function for trend-following/risk control, and
multi-core training. Results show hybrid models yield competitive FX trading
performance. Implications include QLSTM's effectiveness for small-profit trades
with tight risk and future enhancements. Key hyperparameters: QLSTM sequence
length$=$4, QA3C workers$=$8. Limitations: classical quantum simulation and
simplified strategy. \footnote{The views expressed in this article are those of
the authors and do not represent the views of Wells Fargo. This article is for
informational purposes only. Nothing contained in this article should be
construed as investment advice. Wells Fargo makes no express or implied
warranties and expressly disclaims all legal, tax, and accounting implications
related to this article.

</details>


### [6] [Incentivizing Safer Actions in Policy Optimization for Constrained Reinforcement Learning](https://arxiv.org/abs/2509.09208)
*Somnath Hazra,Pallab Dasgupta,Soumyajit Dey*

Main category: cs.LG

TL;DR: 제한 조건 강화 학습(RL)은 사전 정의된 제약 한계를 준수하면서 수익을 극대화하는 것을 목표로 하며, 이는 도메인 특화 안전 요구 사항을 나타낸다. 본 논문에서는 제약 경계에 접근하기 전에 제약 한계 내에서 유지하기 위해 보상 구조와 함께 적응형 인센티브 메커니즘을 통합한 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 제한 조건을 지키면서도 보상을 최대화해야 하는 강화 학습의 근본적인 도전 과제를 해결하기 위해.

Method: 적응형 인센티브 메커니즘을 추가하여 제약 경계에 접근하기 전에 안정적인 훈련 동력을 유지하도록 하기 위한 Incrementally Penalized Proximal Policy Optimization (IP3O) 알고리즘을 제안한다.

Result: IP3O는 기존의 최첨단 안전 RL 알고리즘과 비교하여 벤치마크 환경에서의 성능 평가에서 효과성을 입증하였다. 또한 알고리즘이 달성한 최적성에 대한 최악의 경우 오류의 경계를 유도하여 이론적 보장을 제공한다.

Conclusion: IP3O 알고리즘이 훈련 동력을 안정화하고 수익을 극대화하는 동시에 제약 조건을 준수하는 데 효과적임을 보였다.

Abstract: Constrained Reinforcement Learning (RL) aims to maximize the return while
adhering to predefined constraint limits, which represent domain-specific
safety requirements. In continuous control settings, where learning agents
govern system actions, balancing the trade-off between reward maximization and
constraint satisfaction remains a significant challenge. Policy optimization
methods often exhibit instability near constraint boundaries, resulting in
suboptimal training performance. To address this issue, we introduce a novel
approach that integrates an adaptive incentive mechanism in addition to the
reward structure to stay within the constraint bound before approaching the
constraint boundary. Building on this insight, we propose Incrementally
Penalized Proximal Policy Optimization (IP3O), a practical algorithm that
enforces a progressively increasing penalty to stabilize training dynamics.
Through empirical evaluation on benchmark environments, we demonstrate the
efficacy of IP3O compared to the performance of state-of-the-art Safe RL
algorithms. Furthermore, we provide theoretical guarantees by deriving a bound
on the worst-case error of the optimality achieved by our algorithm.

</details>


### [7] [Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement](https://arxiv.org/abs/2509.09219)
*Jakob Nyberg,Pontus Johnson*

Main category: cs.LG

TL;DR: Vejde라는 프레임워크를 소개하며, 이는 데이터 추상화, 그래프 신경망 및 강화 학습을 결합하여 객체 클래스 및 관계와 같은 복잡한 구조의 상태를 가진 의사결정 문제에 대한 유도 정책 함수를 생성한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 구조의 상태를 가진 의사결정 문제 해결을 위한 효율적인 방법론을 제시하기 위해.

Method: 상태를 사실 데이터베이스로 표현하고, 이를 이분 그래프로 변환하여 신경 메시지 전달을 통해 잠재 상태로 맵핑한다.

Result: Vejde 에이전트는 테스트에서 평균적으로 정책을 일반화하고, 특정 인스턴스에 대한 MLP 에이전트와 유사한 성능을 보인다.

Conclusion: Vejde 에이전트는 다양한 크기와 구조의 문제를 처리할 수 있으며, 강건한 일반화 성능을 보여준다.

Abstract: We present and evaluate Vejde; a framework which combines data abstraction,
graph neural networks and reinforcement learning to produce inductive policy
functions for decision problems with richly structured states, such as object
classes and relations. MDP states are represented as data bases of facts about
entities, and Vejde converts each state to a bipartite graph, which is mapped
to latent states through neural message passing. The factored representation of
both states and actions allows Vejde agents to handle problems of varying size
and structure. We tested Vejde agents on eight problem domains defined in RDDL,
with ten problem instances each, where policies were trained using both
supervised and reinforcement learning. To test policy generalization, we
separate problem instances in two sets, one for training and the other solely
for testing. Test results on unseen instances for the Vejde agents were
compared to MLP agents trained on each problem instance, as well as the online
planning algorithm Prost. Our results show that Vejde policies in average
generalize to the test instances without a significant loss in score.
Additionally, the inductive agents received scores on unseen test instances
that on average were close to the instance-specific MLP agents.

</details>


### [8] [Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents](https://arxiv.org/abs/2509.09265)
*Jiawei Wang,Jiacai Liu,Yuqian Fu,Yingru Li,Xintao Wang,Yuan Lin,Yu Yue,Lin Zhang,Yang Wang,Ke Wang*

Main category: cs.LG

TL;DR: 이 논문에서는 LLM(대형 언어 모델) 기반 에이전트가 긴 작업에서 직면하는 희소 보상 문제를 해결하기 위해 엔트로피 조절 정책 경량화(EMPG) 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 긴 작업에서 에이전트가 희소 보상으로 인해 중간 단계에 대한 크레딧 할당이 어려워진다는 문제를 해결하기 위해.

Method: 본 논문에서 제안하는 EMPG는 단계별 불확실성과 최종 작업 결과를 기반으로 학습 신호를 재조정하는 프레임워크이다.

Result: EMPG는 올바른 확신 행동에 대한 업데이트를 증대시키고, 확신 있는 오류를 처벌하며, 불확실한 단계의 업데이트를 감소시켜 탐색을 안정화한다.

Conclusion: 세 가지 도전적인 에이전트 작업(WebShop, ALFWorld, Deep Search)에서의 실험을 통해 EMPG가 상당한 성능 향상을 이루고, 강력한 정책 경량화 기준보다 뛰어난 결과를 보임을 입증했다.

Abstract: In long-horizon tasks, recent agents based on Large Language Models (LLMs)
face a significant challenge that sparse, outcome-based rewards make it
difficult to assign credit to intermediate steps. Previous methods mainly focus
on creating dense reward signals to guide learning, either through traditional
reinforcement learning techniques like inverse reinforcement learning or by
using Process Reward Models for step-by-step feedback. In this paper, we
identify a fundamental problem in the learning dynamics of LLMs: the magnitude
of policy gradients is inherently coupled with the entropy, which leads to
inefficient small updates for confident correct actions and potentially
destabilizes large updates for uncertain ones. To resolve this, we propose
Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the
learning signal based on step-wise uncertainty and the final task outcome. EMPG
amplifies updates for confident correct actions, penalizes confident errors,
and attenuates updates from uncertain steps to stabilize exploration. We
further introduce a bonus term for future clarity that encourages agents to
find more predictable solution paths. Through comprehensive experiments on
three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we
demonstrate that EMPG achieves substantial performance gains and significantly
outperforms strong policy gradient baselines. Project page is at
https://empgseed-seed.github.io/

</details>


### [9] [MetaLLMix : An XAI Aided LLM-Meta-learning Based Approach for Hyper-parameters Optimization](https://arxiv.org/abs/2509.09387)
*Mohammed Tiouti,Mohamed Bal-Ghaoui*

Main category: cs.LG

TL;DR: MetaLLMiX는 메타 학습과 설명 가능한 AI를 활용하여 하이퍼파라미터 최적화를 자동화하는 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝에서 효과적인 모델 및 하이퍼파라미터 선택은 여전히 주요 도전 과제로, 많은 전문 지식과 계산을 요구합니다.

Method: MetaLLMiX는 메타 학습, 설명 가능한 AI 및 효율적인 LLM 추론을 결합하여 제로샷 하이퍼파라미터 최적화 프레임워크를 제공합니다.

Result: 8개의 의료 이미지 데이터셋을 사용한 실험에서 MetaLLMiX는 전통적인 하이퍼파라미터 최적화 방법보다 경쟁력 있거나 우수한 성능을 달성하며 계산 비용을 대폭 줄입니다.

Conclusion: MetaLLMiX는 우수한 성능을 유지하면서도 응답 시간 단축과 빠른 교육 시간을 제공합니다.

Abstract: Effective model and hyperparameter selection remains a major challenge in
deep learning, often requiring extensive expertise and computation. While
AutoML and large language models (LLMs) promise automation, current LLM-based
approaches rely on trial and error and expensive APIs, which provide limited
interpretability and generalizability. We propose MetaLLMiX, a zero-shot
hyperparameter optimization framework combining meta-learning, explainable AI,
and efficient LLM reasoning. By leveraging historical experiment outcomes with
SHAP explanations, MetaLLMiX recommends optimal hyperparameters and pretrained
models without additional trials. We further employ an LLM-as-judge evaluation
to control output format, accuracy, and completeness. Experiments on eight
medical imaging datasets using nine open-source lightweight LLMs show that
MetaLLMiX achieves competitive or superior performance to traditional HPO
methods while drastically reducing computational cost. Our local deployment
outperforms prior API-based approaches, achieving optimal results on 5 of 8
tasks, response time reductions of 99.6-99.9%, and the fastest training times
on 6 datasets (2.4-15.7x faster), maintaining accuracy within 1-5% of
best-performing baselines.

</details>


### [10] [AEGIS: An Agent for Extraction and Geographic Identification in Scholarly Proceedings](https://arxiv.org/abs/2509.09470)
*Om Vishesh,Harshad Khadilkar,Deepak Akkil*

Main category: cs.LG

TL;DR: 연구자와 학계의 어려움을 해결하기 위해, 자동화된 시스템을 통한 논문 검색 및 작업 수행을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 학술 문헌의 급격한 성장 속도를 따라가는 것은 연구자, 자금 지원 기관 그리고 학술 단체에 큰 도전 과제가 되고 있다.

Method: 전문 AI 에이전트 'Agent-E'를 이용하여 특정 지역의 발표 논문을 식별하고, 정의된 작업(예: 추천서 제출)을 완료하기 위한 로봇 프로세스 자동화(RPA)를 실행하는 시스템을 제안한다.

Result: 5개의 다른 회의에서 586개의 논문을 검증한 결과, 모든 겨냥 논문을 100% 재현율과 99.4%의 정확도로 성공적으로 식별하였다.

Conclusion: 태스크 지향 AI 에이전트가 정보를 필터링할 뿐만 아니라 학술 커뮤니티의 워크플로우에 능동적으로 참여하고 가속화할 가능성을 강조한다.

Abstract: Keeping pace with the rapid growth of academia literature presents a
significant challenge for researchers, funding bodies, and academic societies.
To address the time-consuming manual effort required for scholarly discovery,
we present a novel, fully automated system that transitions from data discovery
to direct action. Our pipeline demonstrates how a specialized AI agent,
'Agent-E', can be tasked with identifying papers from specific geographic
regions within conference proceedings and then executing a Robotic Process
Automation (RPA) to complete a predefined action, such as submitting a
nomination form. We validated our system on 586 papers from five different
conferences, where it successfully identified every target paper with a recall
of 100% and a near perfect accuracy of 99.4%. This demonstration highlights the
potential of task-oriented AI agents to not only filter information but also to
actively participate in and accelerate the workflows of the academic community.

</details>


### [11] [Functional Groups are All you Need for Chemically Interpretable Molecular Property Prediction](https://arxiv.org/abs/2509.09619)
*Roshan Balaji,Joe Bobby,Nirav Pravinbhai Bhatt*

Main category: cs.LG

TL;DR: 이 연구는 분자 속성 예측을 위한 기능 그룹 기반의 새로운 딥러닝 프레임워크인 FGR을 제안하고, 이는 화학적 해석 가능성을 제공하면서도 뛰어난 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 분자 속성 예측에 있어 딥러닝 모델의 해석 가능성이 부족하여 화학자들의 채택이 어려워지는 문제를 해결하고자 한다.

Method: FGR 프레임워크를 통해 기존의 화학 지식으로부터 추출한 기능 그룹과 대규모 분자 데이터에서 파생한 기능 그룹을 통합하여 분자를 저차원 잠재 공간으로 인코딩한다.

Result: FGR 프레임워크는 물리 화학, 생물물리학, 양자역학, 생물학적 활성 및 약물동태학을 포함한 33개의 벤치마크 데이터셋에서 최첨단 성능을 달성하였다.

Conclusion: FGR 프레임워크는 화학적으로 해석 가능한 고성능 딥러닝 모델을 개발하는 방향으로 중요한 발전을 가져왔다.

Abstract: Molecular property prediction using deep learning (DL) models has accelerated
drug and materials discovery, but the resulting DL models often lack
interpretability, hindering their adoption by chemists. This work proposes
developing molecule representations using the concept of Functional Groups (FG)
in chemistry. We introduce the Functional Group Representation (FGR) framework,
a novel approach to encoding molecules based on their fundamental chemical
substructures. Our method integrates two types of functional groups: those
curated from established chemical knowledge (FG), and those mined from a large
molecular corpus using sequential pattern mining (MFG). The resulting FGR
framework encodes molecules into a lower-dimensional latent space by leveraging
pre-training on a large dataset of unlabeled molecules. Furthermore, the
proposed framework allows the inclusion of 2D structure-based descriptors of
molecules. We demonstrate that the FGR framework achieves state-of-the-art
performance on a diverse range of 33 benchmark datasets spanning physical
chemistry, biophysics, quantum mechanics, biological activity, and
pharmacokinetics while enabling chemical interpretability. Crucially, the
model's representations are intrinsically aligned with established chemical
principles, allowing chemists to directly link predicted properties to specific
functional groups and facilitating novel insights into structure-property
relationships. Our work presents a significant step toward developing
high-performing, chemically interpretable DL models for molecular discovery.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [AgriSentinel: Privacy-Enhanced Embedded-LLM Crop Disease Alerting System](https://arxiv.org/abs/2509.09103)
*Chanti Raju Mylay,Bobin Deng,Zhipeng Cai,Honghui Xu*

Main category: cs.CR

TL;DR: AgriSentinel은 농작물 질병 관리에서 데이터 프라이버시와 사용성을 개선한 AI 기반 경고 시스템으로, 농민들에게 안전하고 실용적인 솔루션을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 농작물 질병은 글로벌 식량 안전과 농업 생산성에 위협이 되며, 실효성 있는 관리 방법의 필요성이 커지고 있습니다.

Method: AgriSentinel은 차등 프라이버시 메커니즘을 통합하여 민감한 농작물 이미지 데이터를 보호하며, 모바일 기기에 최적화된 경량의 딥 러닝 기반 농작물 질병 분류 모델과 특화된 온디바이스 대형 언어 모델(LLM)을 포함합니다.

Result: AgriSentinel은 데이터 프라이버시를 보호하고 높은 분류 성능을 유지하며 실용적인 농작물 질병 관리 전략을 제공합니다.

Conclusion: AgriSentinel은 농작물 질병 경고 및 관리 자동화에 대한 강력하고 농민 친화적인 솔루션을 제공하여, 농업 의사결정 개선과 농작물 생산성 향상에 기여합니다.

Abstract: Crop diseases pose significant threats to global food security, agricultural
productivity, and sustainable farming practices, directly affecting farmers'
livelihoods and economic stability. To address the growing need for effective
crop disease management, AI-based disease alerting systems have emerged as
promising tools by providing early detection and actionable insights for timely
intervention. However, existing systems often overlook critical aspects such as
data privacy, market pricing power, and farmer-friendly usability, leaving
farmers vulnerable to privacy breaches and economic exploitation. To bridge
these gaps, we propose AgriSentinel, the first Privacy-Enhanced Embedded-LLM
Crop Disease Alerting System. AgriSentinel incorporates a differential privacy
mechanism to protect sensitive crop image data while maintaining classification
accuracy. Its lightweight deep learning-based crop disease classification model
is optimized for mobile devices, ensuring accessibility and usability for
farmers. Additionally, the system includes a fine-tuned, on-device large
language model (LLM) that leverages a curated knowledge pool to provide farmers
with specific, actionable suggestions for managing crop diseases, going beyond
simple alerting. Comprehensive experiments validate the effectiveness of
AgriSentinel, demonstrating its ability to safeguard data privacy, maintain
high classification performance, and deliver practical, actionable disease
management strategies. AgriSentinel offers a robust, farmer-friendly solution
for automating crop disease alerting and management, ultimately contributing to
improved agricultural decision-making and enhanced crop productivity.

</details>


### [13] [IoTFuzzSentry: A Protocol Guided Mutation Based Fuzzer for Automatic Vulnerability Testing in Commercial IoT Devices](https://arxiv.org/abs/2509.09158)
*Priyanka Rushikesh Chaudhary,Rajib Ranjan Maiti*

Main category: cs.CR

TL;DR: IoTFuzzSentry라는 변이 기반 퍼징 도구를 사용하여 상용 IoT 장치에서 비트리비얼 취약점을 발견하고 이를 악용하는 방법을 보여준다.


<details>
  <summary>Details</summary>
Motivation: IoT 장치의 보안 취약점을 식별하기 위해 프로토콜 퍼징 기법을 활용한다.

Method: IoT 통신에 조작된 전송 및 응용 계층 패킷을 주입하는 퍼징 기법을 적용하여 취약점을 탐지하는 툴을 개발한다.

Result: 상용 IoT 장치에서 4종의 취약점을 발견 및 이를 통해 각각의 취약점에 대한 악용 사례를 제시한다.

Conclusion: IoTFuzzSentry는 IoT 장치의 보안을 강화할 수 있는 가능성을 가진 도구로, 추가 장치에서도 유사한 취약점이 존재할 수 있음을 보인다.

Abstract: Protocol fuzzing is a scalable and cost-effective technique for identifying
security vulnerabilities in deployed Internet of Things devices. During their
operational phase, IoT devices often run lightweight servers to handle user
interactions, such as video streaming or image capture in smart cameras.
Implementation flaws in transport or application-layer security mechanisms can
expose IoT devices to a range of threats, including unauthorized access and
data leakage. This paper addresses the challenge of uncovering such
vulnerabilities by leveraging protocol fuzzing techniques that inject crafted
transport and application-layer packets into IoT communications. We present a
mutation-based fuzzing tool, named IoTFuzzSentry, to identify specific
non-trivial vulnerabilities in commercial IoT devices. We further demonstrate
how these vulnerabilities can be exploited in real-world scenarios. We
integrated our fuzzing tool into a well-known testing tool Cotopaxi and
evaluated it with commercial-off-the-shelf IoT devices such as IP cameras and
Smart Plug. Our evaluation revealed vulnerabilities categorized into 4 types
(IoT Access Credential Leakage, Sneak IoT Live Video Stream, Creep IoT Live
Image, IoT Command Injection) and we show their exploits using three IoT
devices. We have responsibly disclosed all these vulnerabilities to the
respective vendors. So far, we have published two CVEs, CVE-2024-41623 and
CVE-2024-42531, and one is awaiting. To extend the applicability, we have
investigated the traffic of six additional IoT devices and our analysis shows
that these devices can have similar vulnerabilities, due to the presence of a
similar set of application protocols. We believe that IoTFuzzSentry has the
potential to discover unconventional security threats and allow IoT vendors to
strengthen the security of their commercialized IoT devices automatically with
negligible overhead.

</details>


### [14] [Shell or Nothing: Real-World Benchmarks and Memory-Activated Agents for Automated Penetration Testing](https://arxiv.org/abs/2509.09207)
*Wuyuao Mai,Geng Hong,Qi Liu,Jinsong Chen,Jiarun Dai,Xudong Pan,Yuan Zhang,Min Yang*

Main category: cs.CR

TL;DR: 이 논문은 첫 번째 실제 환경 기반의 에이전트 지향 침투 테스트 벤치마크인 TermiBench를 소개하며, TermiAgent라는 다중 에이전트 침투 테스트 프레임워크를 제안한다. 이 연구는 기존 시스템이 현실적인 조건에서 거의 시스템 Shell을 확보하지 못한다는 것을 보여주고, TermiAgent는 긴 문맥 기억 상실 문제를 해결하고 신뢰할 수 있는 익스플로잇 무기를 구축한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 침투 테스트 방법이 비효율적이고 전문가의 노동에 의존하는 문제를 해결하고 AI 기반의 침투 테스트의 실제 환경에서의 성능을 평가하기 위해.

Method: TermiBench라는 실제 환경 기반의 침투 테스트 벤치마크와 TermiAgent라는 다중 에이전트 프레임워크를 도입하여 기존 시스템의 한계를 극복하고 침투 테스트 능력을 향상시킨다.

Result: TermiAgent는 기존의 최첨단 에이전트보다 더 강력한 침투 테스트 능력을 보이며, 실행 시간과 비용을 줄이고, 노트북 규모 배포에서도 실용성을 입증한다.

Conclusion: 이 연구는 실제 환경에서의 자율 침투 테스트를 위한 첫 번째 오픈 소스 벤치마크와 AI 기반 침투 테스트의 이정표를 세운 새로운 에이전트 프레임워크를 제공한다.

Abstract: Penetration testing is critical for identifying and mitigating security
vulnerabilities, yet traditional approaches remain expensive, time-consuming,
and dependent on expert human labor. Recent work has explored AI-driven
pentesting agents, but their evaluation relies on oversimplified
capture-the-flag (CTF) settings that embed prior knowledge and reduce
complexity, leading to performance estimates far from real-world practice. We
close this gap by introducing the first real-world, agent-oriented pentesting
benchmark, TermiBench, which shifts the goal from 'flag finding' to achieving
full system control. The benchmark spans 510 hosts across 25 services and 30
CVEs, with realistic environments that require autonomous reconnaissance,
discrimination between benign and exploitable services, and robust exploit
execution. Using this benchmark, we find that existing systems can hardly
obtain system shells under realistic conditions.
  To address these challenges, we propose TermiAgent, a multi-agent penetration
testing framework. TermiAgent mitigates long-context forgetting with a Located
Memory Activation mechanism and builds a reliable exploit arsenal via
structured code understanding rather than naive retrieval. In evaluations, our
work outperforms state-of-the-art agents, exhibiting stronger penetration
testing capability, reducing execution time and financial cost, and
demonstrating practicality even on laptop-scale deployments. Our work delivers
both the first open-source benchmark for real-world autonomous pentesting and a
novel agent framework that establishes a milestone for AI-driven penetration
testing.

</details>


### [15] [ENSI: Efficient Non-Interactive Secure Inference for Large Language Models](https://arxiv.org/abs/2509.09424)
*Zhiyu He,Maojiang Wang,Xinwen Gao,Yuchuan Luo,Lin Liu,Shaojing Fu*

Main category: cs.CR

TL;DR: ENSI라는 비대면 보안 추론 프레임워크를 제안하여 암호화된 데이터에 대한 기계 학습의 실제 사용성을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습의 프라이버시 보호를 위한 보안 추론의 필요성은 커지고 있으며, 특히 대규모 언어 모델과 암호화 프로토콜의 통합이 도전적이다.

Method: ENSI는 암호화 프로토콜과 LLM 아키텍처를 공동 설계하는 원칙을 기반으로 하며, CKKS 스킴과 BitNet을 결합하여 암호화된 행렬 곱셈의 계산 복잡성을 줄인다.

Result: 실험 결과, ENSI는 최신 기법에 비해 행렬 곱셈에서 약 8배, 소프트맥스 추론에서 CPU에서 2.6배의 속도 향상을 보였다.

Conclusion: 부트스트래핑 호출 빈도를 단 1%로 줄이며, 효율적인 암호텍스트 갱신 및 소프트맥스 대체로 성능 향상을 이루었다.

Abstract: Secure inference enables privacy-preserving machine learning by leveraging
cryptographic protocols that support computations on sensitive user data
without exposing it. However, integrating cryptographic protocols with large
language models (LLMs) presents significant challenges, as the inherent
complexity of these protocols, together with LLMs' massive parameter scale and
sophisticated architectures, severely limits practical usability. In this work,
we propose ENSI, a novel non-interactive secure inference framework for LLMs,
based on the principle of co-designing the cryptographic protocols and LLM
architecture. ENSI employs an optimized encoding strategy that seamlessly
integrates CKKS scheme with a lightweight LLM variant, BitNet, significantly
reducing the computational complexity of encrypted matrix multiplications. In
response to the prohibitive computational demands of softmax under homomorphic
encryption (HE), we pioneer the integration of the sigmoid attention mechanism
with HE as a seamless, retraining-free alternative. Furthermore, by embedding
the Bootstrapping operation within the RMSNorm process, we efficiently refresh
ciphertexts while markedly decreasing the frequency of costly bootstrapping
invocations. Experimental evaluations demonstrate that ENSI achieves
approximately an 8x acceleration in matrix multiplications and a 2.6x speedup
in softmax inference on CPU compared to state-of-the-art method, with the
proportion of bootstrapping is reduced to just 1%.

</details>


### [16] [Prompt Pirates Need a Map: Stealing Seeds helps Stealing Prompts](https://arxiv.org/abs/2509.09488)
*Felix Mächtle,Ashwath Shetty,Jonas Sander,Nils Loose,Sören Pirk,Thomas Eisenbarth*

Main category: cs.CR

TL;DR: 이 논문은 텍스트-이미지 생성에서의 프롬프트 도용 공격을 조사하고, 이에 대한 효과적인 반대책을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 프롬프트 도용은 보안과 프라이버시의 중요한 문제입니다.

Method: 우리는 프롬프트 도용 공격을 조사하고, 피로치의 시드 값 제한으로 인해 발생하는 노이즈 생성 취약점을 이용한 SeedSnitch 도구와 PromptPirate 최적화 방법을 제안합니다.

Result: 대규모 분석을 통해 CivitAI에서 공유된 이미지의 약 95%의 시드 값을 140분 내에 복구할 수 있음을 입증했습니다.

Conclusion: 우리는 프롬프트 도용에 대한 효과적인 반대책을 제시하고, 개발자와 협력하여 이 취약점을 해결하기 위한 노력을 시작했습니다.

Abstract: Diffusion models have significantly advanced text-to-image generation,
enabling the creation of highly realistic images conditioned on textual prompts
and seeds. Given the considerable intellectual and economic value embedded in
such prompts, prompt theft poses a critical security and privacy concern. In
this paper, we investigate prompt-stealing attacks targeting diffusion models.
We reveal that numerical optimization-based prompt recovery methods are
fundamentally limited as they do not account for the initial random noise used
during image generation. We identify and exploit a noise-generation
vulnerability (CWE-339), prevalent in major image-generation frameworks,
originating from PyTorch's restriction of seed values to a range of $2^{32}$
when generating the initial random noise on CPUs. Through a large-scale
empirical analysis conducted on images shared via the popular platform CivitAI,
we demonstrate that approximately 95% of these images' seed values can be
effectively brute-forced in 140 minutes per seed using our seed-recovery tool,
SeedSnitch. Leveraging the recovered seed, we propose PromptPirate, a genetic
algorithm-based optimization method explicitly designed for prompt stealing.
PromptPirate surpasses state-of-the-art methods, i.e., PromptStealer, P2HP, and
CLIP-Interrogator, achieving an 8-11% improvement in LPIPS similarity.
Furthermore, we introduce straightforward and effective countermeasures that
render seed stealing, and thus optimization-based prompt stealing, ineffective.
We have disclosed our findings responsibly and initiated coordinated mitigation
efforts with the developers to address this critical vulnerability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [Global Constraint LLM Agents for Text-to-Model Translation](https://arxiv.org/abs/2509.08970)
*Junyang Cai,Serdar Kadioglu,Bistra Dilkina*

Main category: cs.AI

TL;DR: 이 논문은 최적화 또는 만족 문제를 MiniZinc 모델로 번역하는 데 있어 챌린지를 다루는 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자연어 서술을 MiniZinc 모델로 정확하게 변환하는 것은 논리적 추론과 제약 프로그래밍 전문성을 요구하는 복잡한 작업입니다.

Method: 여러 전문화된 대형 언어 모델(LLM) 에이전트를 사용하여 모델링 작업을 전역 제약 유형에 따라 분리한 후 각 에이전트가 특정 클래스의 전역 제약을 감지하고 코드를 생성합니다.

Result: 여러 LLM을 사용한 초기 실험을 통해 원샷 프롬프트 및 생각의 연쇄 프롬프트와 같은 기준선 대비 더 나은 성능을 보여줍니다.

Conclusion: 향후 작업에 대한 포괄적인 로드맵을 제시하며, 잠재적인 향상 및 개선 방향을 강조합니다.

Abstract: Natural language descriptions of optimization or satisfaction problems are
challenging to translate into correct MiniZinc models, as this process demands
both logical reasoning and constraint programming expertise. We introduce a
framework that addresses this challenge with an agentic approach: multiple
specialized large language model (LLM) agents decompose the modeling task by
global constraint type. Each agent is dedicated to detecting and generating
code for a specific class of global constraint, while a final assembler agent
integrates these constraint snippets into a complete MiniZinc model. By
dividing the problem into smaller, well-defined sub-tasks, each LLM handles a
simpler reasoning challenge, potentially reducing overall complexity. We
conduct initial experiments with several LLMs and show better performance
against baselines such as one-shot prompting and chain-of-thought prompting.
Finally, we outline a comprehensive roadmap for future work, highlighting
potential enhancements and directions for improvement.

</details>


### [18] [Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games](https://arxiv.org/abs/2509.09071)
*Crystal Qian,Kehang Zhu,John Horton,Benjamin S. Manning,Vivian Tsai,James Wexler,Nithum Thain*

Main category: cs.AI

TL;DR: 이 연구는 인간, 대형 언어 모델(LLM), 베이esian 에이전트의 동적 협상 환경에서의 성능과 행동을 비교한다.


<details>
  <summary>Details</summary>
Motivation: 자율 에이전트의 성능과 다중 에이전트 환경에서의 협상 과정을 평가하는 것이 중요하다.

Method: 인간, LLM(GPT-4o, Gemini 1.5 Pro) 및 Bayesian 에이전트를 동적 협상 환경에서 비교 분석한다.

Result: Bayesian 에이전트는 공격적인 최적화를 통해 가장 높은 잔여 이익을 추출하고, 인간과 LLM은 비슷한 전체 잔여 이익을 달성하지만 서로 다른 행동을 나타낸다.

Conclusion: 성능의 동등성은 실제 협조 작업을 위한 프로세스와 정렬에서의 근본적인 차이를 숨길 수 있다.

Abstract: Coordination tasks traditionally performed by humans are increasingly being
delegated to autonomous agents. As this pattern progresses, it becomes critical
to evaluate not only these agents' performance but also the processes through
which they negotiate in dynamic, multi-agent environments. Furthermore,
different agents exhibit distinct advantages: traditional statistical agents,
such as Bayesian models, may excel under well-specified conditions, whereas
large language models (LLMs) can generalize across contexts. In this work, we
compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in
a dynamic negotiation setting that enables direct, identical-condition
comparisons across populations, capturing both outcomes and behavioral
dynamics. Bayesian agents extract the highest surplus through aggressive
optimization, at the cost of frequent trade rejections. Humans and LLMs can
achieve similar overall surplus, but through distinct behaviors: LLMs favor
conservative, concessionary trades with few rejections, while humans employ
more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find
that performance parity -- a common benchmark in agent evaluation -- can
conceal fundamental differences in process and alignment, which are critical
for practical deployment in real-world coordination tasks.

</details>


### [19] [Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions](https://arxiv.org/abs/2509.09215)
*Qinnan Hu,Yuntao Wang,Yuan Gao,Zhou Su,Linkang Du*

Main category: cs.AI

TL;DR: 본 논문은 대규모 에이전트 생태계에서 신뢰할 수 있고 탄력적이며 확장 가능한 규제 메커니즘을 위한 블록체인 기반의 계층 구조를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 에이전트의 불확실한 행동과 이질적인 능력으로 인해 거버넌스와 책임에 대한 도전 과제가 발생하고 있다.

Method: 에이전트 계층, 블록체인 데이터 계층, 규제 애플리케이션 계층으로 구성된 블록체인 기반 계층 구조를 제안하고, 자동 계정을 위한 에이전트 행동 추적 및 중재 모듈, 협력 시나리오에서의 신뢰 평가를 위한 동적 평판 평가 모듈, 적대적 활동의 조기 탐지를 위한 악의적 행동 예측 모듈을 설계하였다.

Result: 제안된 접근 방식은 신뢰할 수 있고 탄력적이며 확장 가능한 규제 메커니즘을 위한 체계적인 기초를 확립한다.

Conclusion: 향후 다중 에이전트 시스템에서 블록체인 기반 규제 프레임워크에 대한 연구 방향을 논의한다.

Abstract: Large language models (LLMs)-empowered autonomous agents are transforming
both digital and physical environments by enabling adaptive, multi-agent
collaboration. While these agents offer significant opportunities across
domains such as finance, healthcare, and smart manufacturing, their
unpredictable behaviors and heterogeneous capabilities pose substantial
governance and accountability challenges. In this paper, we propose a
blockchain-enabled layered architecture for regulatory agent collaboration,
comprising an agent layer, a blockchain data layer, and a regulatory
application layer. Within this framework, we design three key modules: (i) an
agent behavior tracing and arbitration module for automated accountability,
(ii) a dynamic reputation evaluation module for trust assessment in
collaborative scenarios, and (iii) a malicious behavior forecasting module for
early detection of adversarial activities. Our approach establishes a
systematic foundation for trustworthy, resilient, and scalable regulatory
mechanisms in large-scale agent ecosystems. Finally, we discuss the future
research directions for blockchain-enabled regulatory frameworks in multi-agent
systems.

</details>


### [20] [Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective](https://arxiv.org/abs/2509.09154)
*Bui Duc Manh,Soumyaratna Debnath,Zetong Zhang,Shriram Damodaran,Arvind Kumar,Yueyi Zhang,Lu Mi,Erik Cambria,Lin Wang*

Main category: cs.AI

TL;DR: 에이전틱 AI의 발전에도 불구하고, 이들의 공간 추론 능력은 여전히 제한적이다. 우리의 연구는 뇌 과학 원칙에 기반한 새로운 계산 프레임워크를 제시하고, 이를 통해 아젠틱 공간 지능의 발전에 기여하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI 시스템은 자율적으로 작업을 수행하고 언어 기반 추론이 가능하지만, 공간 추론 능력은 여전히 제한적이다. 인간의 공간 지능은 통합된 다감각적 인식과 인지 지도를 기반으로 하며, 이는 복잡한 환경에서의 유연한 의사 결정을 가능하게 한다.

Method: 신경 과학에서 연구된 공간 신경 모델을 분석하고, 이를 통해 생물학적 기능을 여섯 가지 필수 계산 모듈로 매핑하는 새로운 계산 프레임워크를 도입하였다. 이 모듈들은 생체 영감을 받은 다중 모드 감지, 다감각 통합, 자기 중심-타기 중심 변환, 인공지능 인지 지도, 공간 기억 및 공간 추론을 포함한다.

Result: 최근 방법에 대한 프레임워크 기반 분석을 수행하였고, 각 모듈과의 관련성을 평가하며, 신경 과학에 기반한 공간 추론 모듈의 개발을 방해하는 주요 갭을 식별하였다.

Conclusion: 우리는 연구 커뮤니티에 신경 과학 기반의 관점과 구조화된 경로를 제공하고자 하며, 다양한 응용 분야에서 공간 추론을 일반화할 수 있는 유망한 연구 방향을 제시하였다.

Abstract: Recent advances in agentic AI have led to systems capable of autonomous task
execution and language-based reasoning, yet their spatial reasoning abilities
remain limited and underexplored, largely constrained to symbolic and
sequential processing. In contrast, human spatial intelligence, rooted in
integrated multisensory perception, spatial memory, and cognitive maps, enables
flexible, context-aware decision-making in unstructured environments.
Therefore, bridging this gap is critical for advancing Agentic Spatial
Intelligence toward better interaction with the physical 3D world. To this end,
we first start from scrutinizing the spatial neural models as studied in
computational neuroscience, and accordingly introduce a novel computational
framework grounded in neuroscience principles. This framework maps core
biological functions to six essential computation modules: bio-inspired
multimodal sensing, multi-sensory integration, egocentric-allocentric
conversion, an artificial cognitive map, spatial memory, and spatial reasoning.
Together, these modules form a perspective landscape for agentic spatial
reasoning capability across both virtual and physical environments. On top, we
conduct a framework-guided analysis of recent methods, evaluating their
relevance to each module and identifying critical gaps that hinder the
development of more neuroscience-grounded spatial reasoning modules. We further
examine emerging benchmarks and datasets and explore potential application
domains ranging from virtual to embodied systems, such as robotics. Finally, we
outline potential research directions, emphasizing the promising roadmap that
can generalize spatial reasoning across dynamic or unstructured environments.
We hope this work will benefit the research community with a
neuroscience-grounded perspective and a structured pathway. Our project page
can be found at Github.

</details>


### [21] [ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting](https://arxiv.org/abs/2509.09210)
*Xing Gao,Zherui Huang,Weiyao Lin,Xiao Sun*

Main category: cs.AI

TL;DR: 주변 에이전트의 정확한 동작 예측은 자율 주행 차량의 안전한 계획에 필수적이다. 본 논문에서는 복잡한 상호작용을 포착하기 위해 동적 이종 그래프를 활용한 새로운 다단계 디코딩 전략인 ProgD를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 주행 차량의 안전한 계획을 위해 주변 에이전트의 정확한 동작 예측이 필요하다.

Method: 동적 이종 그래프 기반 시나리오 모델링을 활용한 점진적 다중 스케일 디코딩 전략인 ProgD를 설계하였다.

Result: 제안하는 ProgD는 INTERACTION 멀티 에이전트 예측 벤치마크에서 1위, Argoverse 2 다중 세계 예측 벤치마크에서 최첨단 성능을 달성하였다.

Conclusion: 이 접근법은 미래 에이전트의 동작 예측에서 불확실성을 점진적으로 제거하며, 에이전트 간의 사회적 상호작용을 포괄적으로 포착하는 데 기여한다.

Abstract: Accurate motion prediction of surrounding agents is crucial for the safe
planning of autonomous vehicles. Recent advancements have extended prediction
techniques from individual agents to joint predictions of multiple interacting
agents, with various strategies to address complex interactions within future
motions of agents. However, these methods overlook the evolving nature of these
interactions. To address this limitation, we propose a novel progressive
multi-scale decoding strategy, termed ProgD, with the help of dynamic
heterogeneous graph-based scenario modeling. In particular, to explicitly and
comprehensively capture the evolving social interactions in future scenarios,
given their inherent uncertainty, we design a progressive modeling of scenarios
with dynamic heterogeneous graphs. With the unfolding of such dynamic
heterogeneous graphs, a factorized architecture is designed to process the
spatio-temporal dependencies within future scenarios and progressively
eliminate uncertainty in future motions of multiple agents. Furthermore, a
multi-scale decoding procedure is incorporated to improve on the future
scenario modeling and consistent prediction of agents' future motion. The
proposed ProgD achieves state-of-the-art performance on the INTERACTION
multi-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2
multi-world forecasting benchmark.

</details>


### [22] [Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search](https://arxiv.org/abs/2509.09245)
*Shuocheng Li,Yihao Liu,Silin Du,Wenxuan Zeng,Zhe Xu,Mengyu Zhou,Yeye He,Haoyu Dong,Shi Han,Dongmei Zhang*

Main category: cs.AI

TL;DR: 이 논문에서는 대규모 언어 모델이 데이터 과학 작업을 자동화하는 데 효과적이지 못한 문제를 해결하기 위해 고품질 도구 기반 데이터 분석 작업과 실행 가능한 다단계 솔루션을 추출하는 파이프라인을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델이 복잡한 데이터 분석 작업에서의 다단계 추론 및 도구 사용에서 어려움을 겪고 있어 그 효율성이 제한되고 있다.

Method: Jupyter 노트북과 관련 데이터 파일로부터 고품질의 도구 기반 데이터 분석 작업과 실행 가능한 다단계 솔루션을 추출하는 확장 가능한 파이프라인을 제안하고, 이를 통해 NbQA라는 대규모의 표준화된 작업-해결 쌍 데이터셋을 소개하며, 데이터 분석을 검색 문제로 공식화하여 몬테 카를로 트리 검색을 적용하는 Jupiter 프레임워크를 제시한다.

Result: 실험 결과, Qwen2.5-7B 및 14B-Instruct 모델은 NbQA에서 InfiAgent-DABench의 작업을 각각 77.82% 및 86.38% 해결하여 GPT-4o 및 고급 에이전트 프레임워크와 비슷하거나 이를 초과한 성과를 보였다.

Conclusion: 다양한 다단계 추론 작업에서 개선된 일반화 및 강력한 도구 사용 추론이 입증되었다.

Abstract: Large language models (LLMs) have shown great promise in automating data
science workflows, but existing models still struggle with multi-step reasoning
and tool use, which limits their effectiveness on complex data analysis tasks.
To address this, we propose a scalable pipeline that extracts high-quality,
tool-based data analysis tasks and their executable multi-step solutions from
real-world Jupyter notebooks and associated data files. Using this pipeline, we
introduce NbQA, a large-scale dataset of standardized task-solution pairs that
reflect authentic tool-use patterns in practical data science scenarios. To
further enhance multi-step reasoning, we present Jupiter, a framework that
formulates data analysis as a search problem and applies Monte Carlo Tree
Search (MCTS) to generate diverse solution trajectories for value model
learning. During inference, Jupiter combines the value model and node visit
counts to efficiently collect executable multi-step plans with minimal search
steps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on
NbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench,
respectively-matching or surpassing GPT-4o and advanced agent frameworks.
Further evaluations demonstrate improved generalization and stronger tool-use
reasoning across diverse multi-step reasoning tasks.

</details>


### [23] [Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs](https://arxiv.org/abs/2509.09272)
*Vaibhav Chaudhary,Neha Soni,Narotam Singh,Amita Kapoor*

Main category: cs.AI

TL;DR: 지식 그래프는 질문-답변 시스템을 향상시키는 데 중요한 역할을 하며, 이 논문에서는 세 가지 방법론을 비교하여 LLM과 통합하는 방법을 분석하였다.


<details>
  <summary>Details</summary>
Motivation: 지식 그래프는 정보 구조화의 강력한 도구로, 복잡하고 광범위한 텍스트에 대한 주제 및 전반적인 이해를 요구한다.

Method: spaCy, Stanford CoreNLP-OpenIE, GraphRAG의 세 가지 방법론을 비교하여 지식 그래프 트리플렛을 구성하고 LLM과 통합하는 방법을 연구하였다.

Result: OpenIE는 가장 포괄적인 트리플렛을 제공하지만, GraphRAG는 더 우수한 추론 능력을 보여준다.

Conclusion: 각 방법의 강점과 한계를 논의하고, 지식 그래프 기반 질문 응답 개선을 위한 미래 방향에 대한 통찰을 제공한다.

Abstract: Knowledge graphs, a powerful tool for structuring information through
relational triplets, have recently become the new front-runner in enhancing
question-answering systems. While traditional Retrieval Augmented Generation
(RAG) approaches are proficient in fact-based and local context-based
extraction from concise texts, they encounter limitations when addressing the
thematic and holistic understanding of complex, extensive texts, requiring a
deeper analysis of both text and context. This paper presents a comprehensive
technical comparative study of three different methodologies for constructing
knowledge graph triplets and integrating them with Large Language Models (LLMs)
for question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all
leveraging open source technologies. We evaluate the effectiveness,
feasibility, and adaptability of these methods by analyzing their capabilities,
state of development, and their impact on the performance of LLM-based question
answering. Experimental results indicate that while OpenIE provides the most
comprehensive coverage of triplets, GraphRAG demonstrates superior reasoning
abilities among the three. We conclude with a discussion on the strengths and
limitations of each method and provide insights into future directions for
improving knowledge graph-based question answering.

</details>


### [24] [LightAgent: Production-level Open-source Agentic AI Framework](https://arxiv.org/abs/2509.09292)
*Weige Cai,Tong Zhu,Jinyi Niu,Ruiqi Hu,Lingyao Li,Tenglong Wang,Xiaowu Dai,Weining Shen,Liwen Zhang*

Main category: cs.AI

TL;DR: LightAgent는 경량이면서도 강력한 에이전트 프레임워크로, 기존 프레임워크의 유연성과 단순성 간의 균형을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)의 빠른 발전과 함께 다중 에이전트 시스템(MAS)에서도 많은 진전을 이루었으나, 에이전트 배치를 위한 다재다능하고 견고하며 효율적인 플랫폼 설계에는 여전히 많은 도전 과제가 남아 있습니다.

Method: LightAgent는 Memory, Tools 및 Tree of Thought (ToT)와 같은 핵심 기능을 통합하며, 매우 가벼운 구조를 유지합니다.

Result: LightAgent는 주요 채팅 플랫폼과 원활하게 통합되어 개발자들이 쉽게 자체 학습 에이전트를 구축할 수 있도록 합니다.

Conclusion: 우리는 LightAgent를 오픈 소스로 발표하였으며, 이는 다양한 애플리케이션 시나리오에서의 활용을 가능하게 합니다.

Abstract: With the rapid advancement of large language models (LLMs), Multi-agent
Systems (MAS) have achieved significant progress in various application
scenarios. However, substantial challenges remain in designing versatile,
robust, and efficient platforms for agent deployment. To address these
limitations, we propose \textbf{LightAgent}, a lightweight yet powerful agentic
framework, effectively resolving the trade-off between flexibility and
simplicity found in existing frameworks. LightAgent integrates core
functionalities such as Memory (mem0), Tools, and Tree of Thought (ToT), while
maintaining an extremely lightweight structure. As a fully open-source
solution, it seamlessly integrates with mainstream chat platforms, enabling
developers to easily build self-learning agents. We have released LightAgent at
\href{https://github.com/wxai-space/LightAgent}{https://github.com/wxai-space/LightAgent}

</details>


### [25] [Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization](https://arxiv.org/abs/2509.09321)
*Hangyi Jia,Yuxi Qian,Hanwen Tong,Xinhui Wu,Lin Chen,Feng Wei*

Main category: cs.AI

TL;DR: TAM Bench는 LLM 기반 에이전트를 평가하기 위한 구조화된 벤치마크로, 다양한 ML 작업에 대한 자동화된 솔루션을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 발전으로 end-to-end 기계 학습 워크플로우 자동화가 가능해졌으나, 기존 벤치마크는 이들을 효과적으로 평가하지 못하고 있습니다.

Method: TAM Bench는 브라우저 자동화 및 LLM 기반 작업 수집 시스템, 참가자 수 및 점수 분산에 따른 난이도 모델링 기구, 다양한 평가 차원을 통합한 평가 프레임워크를 갖추고 있습니다.

Result: 150개의 선별된 AutoML 작업을 기반으로 세 가지 크기의 벤치마크 하위 집합을 구성하였습니다.

Conclusion: Lite 버전은 18개 작업을 포함하여 매일 벤치마킹 및 비교 연구에 적합한 테스트베드 역할을 합니다.

Abstract: Recent advances in large language models (LLMs) have enabled the emergence of
general-purpose agents for automating end-to-end machine learning (ML)
workflows, including data analysis, feature engineering, model training, and
competition solving. However, existing benchmarks remain limited in task
coverage, domain diversity, difficulty modeling, and evaluation rigor, failing
to capture the full capabilities of such agents in realistic settings. We
present TAM Bench, a diverse, realistic, and structured benchmark for
evaluating LLM-based agents on end-to-end ML tasks. TAM Bench features three
key innovations: (1) A browser automation and LLM-based task acquisition system
that automatically collects and structures ML challenges from platforms such as
Kaggle, AIcrowd, and Biendata, spanning multiple task types and data modalities
(e.g., tabular, text, image, graph, audio); (2) A leaderboard-driven difficulty
modeling mechanism that estimates task complexity using participant counts and
score dispersion, enabling scalable and objective task calibration; (3) A
multi-dimensional evaluation framework incorporating performance, format
compliance, constraint adherence, and task generalization. Based on 150 curated
AutoML tasks, we construct three benchmark subsets of different sizes -- Lite,
Medium, and Full -- designed for varying evaluation scenarios. The Lite
version, with 18 tasks and balanced coverage across modalities and difficulty
levels, serves as a practical testbed for daily benchmarking and comparative
studies.

</details>


### [26] [Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning](https://arxiv.org/abs/2509.09356)
*Abdel Hakim Drid,Vincenzo Suriani,Daniele Nardi,Abderrezzak Debilou*

Main category: cs.AI

TL;DR: 이 논문은 자율 에이전트의 효율적인 의미 탐색을 위한 새로운 심층 강화 학습 구조를 제안하며, 이를 통해 객체 발견률을 높이고 복잡한 환경에서 효율적으로 탐색하는 능력을 개발한다.


<details>
  <summary>Details</summary>
Motivation: 복잡하고 알려지지 않은 환경을 자율적으로 탐색하고 이해하기 위해서는 단순한 인식 및 이동 이상의 고급 인지 능력이 필요하다.

Method: 자원 효율적인 의미 탐색을 위해 특별히 설계된 심층 강화 학습 아키텍처를 제안하고, 비전-언어 모델(VLM)의 상식 통합을 계층 보상 함수로 구현한다.

Result: 에이전트는 객체 발견률을 크게 향상시키며 의미적으로 풍부한 지역을 효과적으로 탐색하는 학습된 능력을 개발한다.

Conclusion: 이 연구는 자율 에이전트와의 상식적인 의미 추론을 결합하는 실용적이고 확장 가능한 방법을 제시하여 로봇 공학에서 완전한 지능과 자율 탐색을 추구하는 새로운 접근 방식을 제공한다.

Abstract: Navigating and understanding complex and unknown environments autonomously
demands more than just basic perception and movement from embodied agents.
Truly effective exploration requires agents to possess higher-level cognitive
abilities, the ability to reason about their surroundings, and make more
informed decisions regarding exploration strategies. However, traditional RL
approaches struggle to balance efficient exploration and semantic understanding
due to limited cognitive capabilities embedded in the small policies for the
agents, leading often to human drivers when dealing with semantic exploration.
In this paper, we address this challenge by presenting a novel Deep
Reinforcement Learning (DRL) architecture that is specifically designed for
resource efficient semantic exploration. A key methodological contribution is
the integration of a Vision-Language Model (VLM) common-sense through a layered
reward function. The VLM query is modeled as a dedicated action, allowing the
agent to strategically query the VLM only when deemed necessary for gaining
external guidance, thereby conserving resources. This mechanism is combined
with a curriculum learning strategy designed to guide learning at different
levels of complexity to ensure robust and stable learning. Our experimental
evaluation results convincingly demonstrate that our agent achieves
significantly enhanced object discovery rates and develops a learned capability
to effectively navigate towards semantically rich regions. Furthermore, it also
shows a strategic mastery of when to prompt for external environmental
information. By demonstrating a practical and scalable method for embedding
common-sense semantic reasoning with autonomous agents, this research provides
a novel approach to pursuing a fully intelligent and self-guided exploration in
robotics.

</details>


### [27] [SEDM: Scalable Self-Evolving Distributed Memory for Agents](https://arxiv.org/abs/2509.09498)
*Haoran Xu,Jiacong Hu,Ke Zhang,Lei Yu,Yuxin Tang,Xinyuan Song,Yiqun Duan,Lynn Ai,Bill Shi*

Main category: cs.AI

TL;DR: SEDM은 능동적이고 자기 최적화되는 메모리 구성 요소로 메모리를 변화시키는 분산 메모리 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 장기 다중 에이전트 시스템은 방대한 양의 경로 및 이력 상호작용을 생성하므로 성능과 확장성을 위한 효율적인 메모리 관리가 필수적이다.

Method: SEDM은 재현 가능한 재생을 기반으로 한 검증 가능한 쓰기 수락, 경험적 유틸리티에 따라 동적으로 항목을 순위 매기고 통합하는 자기 일정 메모리 컨트롤러, 이질적 작업 간 전이를 지원하기 위한 재사용 가능한 통찰력을 추상화하는 교차 도메인 지식 확산을 통합한다.

Result: 벤치마크 데이터 세트에 대한 평가 결과, SEDM은 강력한 메모리 기준선에 비해 토큰 오버헤드를 줄이면서 추론 정확도를 향상시켰다.

Conclusion: SEDM은 개방형 다중 에이전트 협업을 위한 확장 가능하고 지속 가능한 메모리 메커니즘으로 강조된다.

Abstract: Long-term multi-agent systems inevitably generate vast amounts of
trajectories and historical interactions, which makes efficient memory
management essential for both performance and scalability. Existing methods
typically depend on vector retrieval and hierarchical storage, yet they are
prone to noise accumulation, uncontrolled memory expansion, and limited
generalization across domains. To address these challenges, we present SEDM,
Self-Evolving Distributed Memory, a verifiable and adaptive framework that
transforms memory from a passive repository into an active, self-optimizing
component. SEDM integrates verifiable write admission based on reproducible
replay, a self-scheduling memory controller that dynamically ranks and
consolidates entries according to empirical utility, and cross-domain knowledge
diffusion that abstracts reusable insights to support transfer across
heterogeneous tasks. Evaluations on benchmark datasets demonstrate that SEDM
improves reasoning accuracy while reducing token overhead compared with strong
memory baselines, and further enables knowledge distilled from fact
verification to enhance multi-hop reasoning. The results highlight SEDM as a
scalable and sustainable memory mechanism for open-ended multi-agent
collaboration. The code will be released in the later stage of this project.

</details>


### [28] [Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution](https://arxiv.org/abs/2509.09560)
*Shulai Zhang,Ao Xu,Quan Chen,Han Zhao,Weihao Cui,Ningxin Zheng,Haibin Lin,Xin Liu,Minyi Guo*

Main category: cs.AI

TL;DR: Auras는 구현된 AI 에이전트의 추론 주파수를 최적화하기 위해 개발된 알고리즘-시스템 협업 추론 프레임워크로, 이를 통해 높은 처리량과 정확성을 동시에 달성한다.


<details>
  <summary>Details</summary>
Motivation: 구현된 AI 시스템은 동적 환경에서 운영되며, 고주파 입력과 출력 요구를 처리하기 위한 지각 및 생성 모듈의 원활한 통합이 필요하다.

Method: Auras는 지각과 생성을 분리하고, 이를 위한 제어된 파이프라인 병렬성을 제공하여 높은 안정적인 처리량을 달성한다.

Result: Auras는 평균적으로 처리량을 2.54배 향상시키고, 원래 정확도의 102.7%를 달성하였다.

Conclusion: 이는 순차적 계산의 한계를 극복하고 높은 처리량을 제공하는 데 있어 Auras의 효율성을 입증한다.

Abstract: Embodied AI systems operate in dynamic environments, requiring seamless
integration of perception and generation modules to process high-frequency
input and output demands. Traditional sequential computation patterns, while
effective in ensuring accuracy, face significant limitations in achieving the
necessary "thinking" frequency for real-world applications. In this work, we
present Auras, an algorithm-system co-designed inference framework to optimize
the inference frequency of embodied AI agents. Auras disaggregates the
perception and generation and provides controlled pipeline parallelism for them
to achieve high and stable throughput. Faced with the data staleness problem
that appears when the parallelism is increased, Auras establishes a public
context for perception and generation to share, thereby promising the accuracy
of embodied agents. Experimental results show that Auras improves throughput by
2.54x on average while achieving 102.7% of the original accuracy, demonstrating
its efficacy in overcoming the constraints of sequential computation and
providing high throughput.

</details>


### [29] [The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs](https://arxiv.org/abs/2509.09677)
*Akshit Sinha,Arvindh Arun,Shashwat Goel,Steffen Staab,Jonas Geiping*

Main category: cs.AI

TL;DR: 대형 언어 모델의 크기를 계속 늘리는 것이 수익 감소로 이어지는가? 단일 단계에서의 정확도가 임계적이며, 모델의 실행 능력에 집중함으로써 복잡한 문제 해결과 단순 작업의 실패 간의 논쟁을 조화시키려 한다.


<details>
  <summary>Details</summary>
Motivation: 모델의 작업 완료 길이에 따른 실제 가치의 증가를 탐구하기 위해 시작한다.

Method: 단순 작업의 길이를 늘릴 때 LLM의 실행 실수에서의 실패를 해결하기 위해 필요한 지식과 계획을 명시적으로 제공한다.

Result: 더 큰 모델이 작은 모델보다 더 많은 턴을 정확히 실행할 수 있음을 발견하였다.

Conclusion: 프론티어 사고 모델의 벤치마크를 통해 단일 턴에서 수행할 수 있는 작업의 길이를 평가한다.

Abstract: Does continued scaling of large language models (LLMs) yield diminishing
returns? Real-world value often stems from the length of task an agent can
complete. We start this work by observing the simple but counterintuitive fact
that marginal gains in single-step accuracy can compound into exponential
improvements in the length of a task a model can successfully complete. Then,
we argue that failures of LLMs when simple tasks are made longer arise from
mistakes in execution, rather than an inability to reason. We propose isolating
execution capability, by explicitly providing the knowledge and plan needed to
solve a long-horizon task. We find that larger models can correctly execute
significantly more turns even when small models have 100\% single-turn
accuracy. We observe that the per-step accuracy of models degrades as the
number of steps increases. This is not just due to long-context limitations --
curiously, we observe a self-conditioning effect -- models become more likely
to make mistakes when the context contains their errors from prior turns.
Self-conditioning does not reduce by just scaling the model size. In contrast,
recent thinking models do not self-condition, and can also execute much longer
tasks in a single turn. We conclude by benchmarking frontier thinking models on
the length of task they can execute in a single turn. Overall, by focusing on
the ability to execute, we hope to reconcile debates on how LLMs can solve
complex reasoning problems yet fail at simple tasks when made longer, and
highlight the massive benefits of scaling model size and sequential test-time
compute for long-horizon tasks.

</details>
