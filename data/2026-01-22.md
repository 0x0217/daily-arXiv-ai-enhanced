<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 43]
- [cs.MA](#cs.MA) [Total: 7]
- [cs.AI](#cs.AI) [Total: 44]
- [cs.CR](#cs.CR) [Total: 14]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration](https://arxiv.org/abs/2601.11556)
*Boyang Wang,Yash Vishe,Xin Xu,Zachary Novack,Julian McAuley,Junda Wu*

Main category: cs.LG

TL;DR: 이 연구는 종합적인 음악 구조 연결을 위한 작곡적 기호 음악 추론 벤치마크인 CSyMR-Bench를 제안하고, 이 벤치마크를 통해 도출한 도구 보강 에이전트를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 벤치마크는 분리된 지식이나 개별 분석에 치중하고 있어 음악 구조의 연결에 필요한 종합적 작곡 추론을 반영하지 못하였다.

Method: 126개의 질문으로 구성된 CSyMR-Bench를 만들고, 음악21 라이브러리의 기호 음악 분석 도구를 활용하는 도구 보강 에이전트 프레임워크를 도입하였다.

Result: CSyMR-Bench는 커뮤니티와 시험 스타일 질문 모두에서 비트리비얼한 도전을 제시하며, 도구 보강 에이전트가 모든 기준을 일관되게 초과 달성하여 5-7%의 절대 정확도 향상을 달성했다.

Conclusion: CSyMR-Bench와 도구 보강 에이전트는 종합적 작곡 추론을 위해 필요한 장비와 프레임워크를 제공합니다.

Abstract: Large Language Models (LLMs) are leveraged in symbolic music reasoning, yet existing benchmarks emphasize isolated knowledge or atomic analyses rather than the integrative compositional reasoning needed to connect musical structures. To address this, we present the Compositional Symbolic Music Reasoning Benchmark (CSyMR-Bench), a curated multiple-choice dataset of 126 questions derived from expert forums and professional examinations. Each item involves combining several atomic analyses to arrive at the final answer. Furthermore, we introduce a tool-augmented agent framework that leverages symbolic music analysis tools from the music21 library to address the challenges posed by CSyMR-Bench. Experiments validate that CSyMR-Bench poses a non-trivial challenge across both community-sourced and exam-style questions, while our tool-augmented agent consistently outperforms all baselines, achieving 5-7% absolute accuracy gains.

</details>


### [2] [Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.11604)
*Jonaid Shianifar,Michael Schukat,Karl Mason*

Main category: cs.LG

TL;DR: 이 논문에서는 다중 목표 강화 학습(MORL)을 통해 사용자 선호를 존중하며 벡터 값 보상을 최적화하는 CAPQL 방법과, 저장된 전이를 대체 선호로 다시 라벨링하는 Hindsight Preference Replay(HPR)를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 목표 강화 학습에서 사용자 선호를 고려하면서 효과적으로 보상을 최적화할 필요성.

Method: HPR은 CAPQL의 아키텍처나 손실 함수를 변경하지 않고도 저장된 전이를 대체 선호로 재라벨링하여 감독을 밀집화하는 단순하고 일반적인 반복 증강 전략입니다.

Result: HPR-CAPQL은 6개의 MO-Gymnasium 운동 작업에서 6개의 환경 중 5개에서 HV를 개선하고 4개에서 EUM을 향상시켰습니다.

Conclusion: CAPQL은 mo-halfcheetah-v5에서 높은 HV를 달성하지만 EUM은 동일한 수준을 유지하는 도전적인 예외입니다.

Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\!\pm\!125$ to $1613\!\pm\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.

</details>


### [3] [A Multimodal Data Processing Pipeline for MIMIC-IV Dataset](https://arxiv.org/abs/2601.11606)
*Farzana Islam Adiba,Varsha Danduri,Fahmida Liza Piya,Ali Abbasi,Mehak Gupta,Rahmatollah Beheshti*

Main category: cs.LG

TL;DR: MIMIC-IV 데이터 세트의 다중 모달성을 위한 포괄적이고 사용자 지정 가능한 파이프라인을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: MIMIC-IV 데이터는 임상 기계 학습 연구에 널리 사용되지만, 여러 모달리티의 전처리와 정렬이 어려워 효율적인 분석이 필요합니다.

Method: 기존의 단일 모달 파이프라인을 확장하여, 자동화된 집단 선택, 모달리티 간의 시간 정렬, 표준화된 출력 형식을 지원하는 다중 모달 파이프라인을 개발했습니다.

Result: 우리의 파이프라인은 다중 모달 처리 시간을 크게 단축하고 MIMIC 기반 연구의 재현성을 향상시킵니다.

Conclusion: 코드와 UI, Python 패키지를 제공하여 선택적 통합을 지원합니다.

Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.

</details>


### [4] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

TL;DR: 노인들이 자택에서 독립적이고 안전하게 생활할 수 있도록 지원하는 것이 중요하다. 본 연구에서는 비디오 및 도어 센서를 활용하여 노인의 일상 활동을 모니터링하고 건강 관리 개입을 촉진하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전全球人口의 노령화로 인해, 노인들이 자택에서 독립적이고 안전하게 생활할 수 있도록 하는 것이 중요하다.

Method: 활동을 오전, 오후, 밤으로 클러스터링하고 이를 통해 서로 다른 상호 정보 행렬을 계산하여 특성 가중치 방법에 인코딩 한다. 또한, 하루 시간과 주 요일을 순환적 시간 특성으로 추가하고 사용자의 위치를 추적하는 기능을 추가한다.

Result: 실험 결과, 기존 최첨단 방법보다 정확도와 F1-score가 향상되었으며, 특히 데이터가 적은 환경에서 가장 높은 이득을 보였다.

Conclusion: 본 연구의 결과는 자택 노인 지원을 위한 효과적인 스마트 홈 솔루션을 발전시키기 위한 접근 방식의 가능성을 강조한다.

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [5] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

TL;DR: 이 논문은 이전 쿼리 샘플의 정보를 활용하여 프로토타입 추정을 최적화하는 Incremental Prototype Enhancement Classifier (IPEC)라는 새로운 테스트 시점 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 메트릭 기반의 few-shot 접근법은 구현이 간단하고 해석 가능성이 높지만, 배치 독립성 가정으로 인해 이전 배치에서 축적된 지식을 활용할 수 없다.

Method: IPEC는 높은 신뢰도로 분류된 쿼리 샘플만을 선택적으로 포함한 역동적인 보조 집합을 유지하며, 강력한 이중 필터링 메커니즘을 설계하여 각 쿼리 샘플의 글로벌 예측 신뢰성과 로컬 변별 능력을 평가한다.

Result: IPEC는 후속 작업에서 지원 집합과 이 보조 집합을 집계하여 점진적으로 더 안정적이고 대표적인 프로토타입을 구축한다.

Conclusion: 우리의 방법은 여러 few-shot 분류 작업에서 우수한 성능을 입증하였다.

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [6] [Shapelets-Enriched Selective Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2601.11821)
*Shivani Tomar,Seshu Tirupathi,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

TL;DR: 이 연구에서 제안하는 선택적 예측 프레임워크는 주요 시간 시계열 데이터의 신뢰할 수 없는 예측을 식별하고 제거하여 전체 오류를 줄이는 데 기여한다.


<details>
  <summary>Details</summary>
Motivation: 시간 시계열 기초 모델은 교통, 에너지 및 날씨 데이터를 포함한 복잡한 시계열 데이터를 모델링할 수 있는 능력으로 최근 많은 주목을 받고 있다.

Method: 이 논문에서는 Shapelet을 사용하여 시간 시계열의 중요한 세그먼트를 식별하기 위한 선택적 예측 프레임워크를 제안한다. 목표 도메인 데이터셋의 검증 분할에서 Shift-invariant 사전 학습을 통해 Shapelet을 학습하고, 이 Shapelet에 대한 거리 기반 유사성을 활용하여 사용자가 신뢰할 수 없는 예측을 선택적으로 제거할 수 있도록 한다.

Result: 다양한 벤치마크 시계열 데이터셋에서의 실증 결과는 우리의 접근 방식이 제로샷 및 풀샷 미세 조정 모델을 활용하여 전체 오류를 제로샷은 평균 22.17%, 풀샷은 22.62% 줄인다는 것을 보여준다.

Conclusion: 제로샷과 풀샷 미세 조정 모델을 사용하는 우리의 접근 방식은 무작위 선택 방법보다 최대 21.41% 및 21.43% 더 성능이 우수하다.

Abstract: Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.

</details>


### [7] [From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs](https://arxiv.org/abs/2601.11890)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

TL;DR: 상태-행동 쌍의 목표 지향적 탐사는 보상 없는 마르코프 결정 문제에서 필수적이다. 본 논문에서는 상태-행동 점유 측정값에서 직접 정의된 오목 커버리지 목표의 가중화 및 매개변수화된 가족을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 보상 없는 MDP에서 상태-행동 쌍의 중요도 및 난이도를 탐색 전략에 통합하는 것이 필요하다.

Method: 가중화된 오목 커버리지 목표를 제안하고 이를 통해 다양한 목표를 통합하며, 경량 기반 알고리즘을 개발하여 탐색 패턴을 제어한다.

Result: 제안된 알고리즘은 탐색 전략이 덜 탐색된 상태-행동 쌍을 강조하도록 한다.

Conclusion: ρ가 증가함에 따라 탐색 전략은 최소 탐색된 상태-행동 쌍을 점점 더 강조하게 되어 제한 수치의 worst-case 커버리지 행동을 회복한다.

Abstract: Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_ρ$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_ρ$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_ρ$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $ρ$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.

</details>


### [8] [Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924)
*Ming Shi*

Main category: cs.LG

TL;DR: 우리는 적대적 변조와 제한된 검증 하에서 벡터 값 보상을 가진 협력적 확률적 다중 무장 강도 문제를 연구한다. 각 라운드에서 에이전트들은 무장을 선택하고 환경은 보상을 생성하며 적대자는 피드백을 변조한다. 우리는 통신-변조 연결을 통해 에이전트들이 공유하는 정보의 종류에 따라 효율적인 변조 수준이 달라짐을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 협력적 다중 무장 강도 문제에서 적대적 변조와 제한된 검증 상황에서의 성능을 이해하고자 한다.

Method: 각 라운드에서 에이전트들이 선택한 무장에 대해 환경이 생성한 보상 벡터와 적대자가 관찰된 피드백을 변조하는 것을 분석한다. 우리는 프로토콜 유도 다중성과 관련된 정식화 및 얻은 효과적인 변조로 매개화된 후회 경계를 증명한다.

Result: 에이전트들이 원시 샘플을 공유할 경우 $N$배 더 큰 추가 변조 패널티를 받을 수 있으나, 요약 또는 추천만 공유할 경우 $O(Γ)$ 항을 유지하며 중앙 집중식 팀 후회 달성이 가능하다.

Conclusion: 검증이 높은 변조 레짐에서는 필요하며, 식별 임계치를 초과한 경우 충분하다. 인증된 공유는 팀의 후회가 $Γ$에 독립적이 되도록 한다.

Abstract: We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.

</details>


### [9] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: EVO 알고리즘은 Extreme Value Theory를 활용하여 드문 고충격 보상 및 비용 샘플을 모델링하고, 제약 위반을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계에서 강화 학습을 적용할 때 안전성을 보장하는 것이 중요한 도전 과제이다.

Method: EVO 알고리즘은 극단적인 보상 및 비용 샘플을 활용하여 최적화를 수행하고, 특히 비용 꼬리 분포의 극단적인 샘플을 포착하기 위한 최적화 목표를 설정한다.

Result: EVO는 제약 위반의 가능성을 기대 기반 방법보다 낮게 유지하며, 양자 회귀 방법보다도 낮은 분산을 보여준다.

Conclusion: EVO는 훈련 중 제약 위반을 현저히 줄이면서도 기존 정책 성능을 유지한다.

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [10] [Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate](https://arxiv.org/abs/2601.12091)
*Qian Tan,Lei Jiang,Yuting Zeng,Shuoyang Ding,Xiaohua Xu*

Main category: cs.LG

TL;DR: 간과된 비서구적 언어 프롬프트가 비율 편향 경향에 미치는 영향을 평가하고, 이를 완화하기 위한 새로운 다중 에이전트 문화 논쟁(MACD) 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 가진 서구 중심의 편향을 평가하고 비서구적 언어로 이를 완화할 가능성을 탐구하기 위함이다.

Method: CEBiasBench라는 중국-영어 이중 언어 벤치마크와 '편향 없음' 판단을 가능하게 하는 다중 에이전트 투표(MAV) 프레임워크를 도입하였다.

Result: 중국어 프롬프트가 편향을 동아시아 관점으로 전이할 뿐 편향을 없애지는 못한다는 것을 확인하였다. MACD를 통해 평균 57.6%의 '편향 없음' 비율을 달성하였다.

Conclusion: 에이전트 프레임워크에서 명시적 문화 표현이 교차 문화 공정성에 필수적임을 확인하였다.

Abstract: Large language models (LLMs) exhibit systematic Western-centric bias, yet whether prompting in non-Western languages (e.g., Chinese) can mitigate this remains understudied. Answering this question requires rigorous evaluation and effective mitigation, but existing approaches fall short on both fronts: evaluation methods force outputs into predefined cultural categories without a neutral option, while mitigation relies on expensive multi-cultural corpora or agent frameworks that use functional roles (e.g., Planner--Critique) lacking explicit cultural representation. To address these gaps, we introduce CEBiasBench, a Chinese--English bilingual benchmark, and Multi-Agent Vote (MAV), which enables explicit ``no bias'' judgments. Using this framework, we find that Chinese prompting merely shifts bias toward East Asian perspectives rather than eliminating it. To mitigate such persistent bias, we propose Multi-Agent Cultural Debate (MACD), a training-free framework that assigns agents distinct cultural personas and orchestrates deliberation via a "Seeking Common Ground while Reserving Differences" strategy. Experiments demonstrate that MACD achieves 57.6% average No Bias Rate evaluated by LLM-as-judge and 86.0% evaluated by MAV (vs. 47.6% and 69.0% baseline using GPT-4o as backbone) on CEBiasBench and generalizes to the Arabic CAMeL benchmark, confirming that explicit cultural representation in agent frameworks is essential for cross-cultural fairness.

</details>


### [11] [Explanova: Automatically Discover Data Insights in N \times M Table via XAI Combined LLM Workflow](https://arxiv.org/abs/2601.12317)
*Yiming Huang*

Main category: cs.LG

TL;DR: 데이터 분석 자동화에 대한 연구가 진행 중이며, Explanova는 사전 설정된 AutoML과 유사한 워크플로를 통해 효율성을 높이는 솔루션이다.


<details>
  <summary>Details</summary>
Motivation: 데이터 분석의 자동화는 오랜 목표로, 현재의 LLM은 이 방향에서 유망한 해결책이 되고 있다.

Method: Explanova는 사전 설정된 AutoML-like 워크플로를 통해 가능한 모든 탐색을 수행하며, 통계 및 관계를 설명한다.

Result: Explanova는 지역 소형 LLM에 기반하여 비용이 저렴하다.

Conclusion: 이 연구는 자동화된 데이터 분석에서의 새로운 접근 방식을 제시하며, LLM 기반의 도구 호출 능력을 활용한다.

Abstract: Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Like DeepAnalyze, DataSage, and Datawise. They are all powerful agentic frameworks for automatic fine-grained analysis and are powered by LLM-based agentic tool calling ability. However, what about powered by a preset AutoML-like workflow? If we traverse all possible exploration, like Xn itself`s statistics, Xn1-Xn2 relationships, Xn to all other, and finally explain? Our Explanova is such an attempt: Cheaper due to a Local Small LLM.

</details>


### [12] [Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs](https://arxiv.org/abs/2601.12341)
*Rezky Kam,Coddy N. Siswanto*

Main category: cs.LG

TL;DR: LLM이 실제 세계의 감정 동역학을 모방할 수 있는 데이터셋과 개념적 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 세계의 감정 동역학을 더 잘 이해하고 모방하기 위한 필요성.

Method: 물리학에 기반한 신경망을 활용한 맥락 내 학습을 통해 LLM이 시간에 따른 감정 변화를 학습하도록 하는 데이터셋과 프레임워크를 구축.

Result: 정확하고 해석 가능한 대화 모델링이 가능하다는 가능성을 열었습니다.

Conclusion: 이 연구는 감정 동역학을 해석할 수 있는 대화 모델링의 가능성을 제시합니다.

Abstract: This paper introduces a dataset and conceptual framework for LLMs to mimic real world emotional dynamics through time and in-context learning leveraging physics-informed neural network, opening a possibility for interpretable dialogue modeling.

</details>


### [13] [Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting](https://arxiv.org/abs/2601.12467)
*Saurish Nagrath*

Main category: cs.LG

TL;DR: 이 논문은 로컬 시간 표현 학습과 글로벌 종속성 모델링을 명확히 분리한 두 단계 예측 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: Transformer 기반 모델이 시계열 예측에서 오랫동안 지속된 의존성을 모델링하는 데 효과적이지만, 입력 표현의 품질과 구조에 따라 성능이 크게 좌우된다.

Method: 첫 번째 단계에서는 CNN이 고정 길이의 시간 패치를 사용하여 단기 시간 역학과 비선형 특징 상호작용을 추출하고, 이를 통해 압축된 패치 수준의 토큰 임베딩을 생성한다. 이후 표현 학습 중에 토큰 수준의 자기 주의가 이 임베딩을 개선한다. 두 번째 단계에서는 Transformer 인코더가 생성된 토큰 시퀀스를 처리하여 패치 간 시간 의존성을 모델링하고, 각 패치에 대한 예측을 생성한다.

Result: 합성된 다변량 시계열 데이터에 대한 실험 결과, 제안된 패치 기반 토큰화 전략이 CNN 및 패치 기반 Transformer의 기준선과 비교하여 경쟁력 있는 예측 성능을 달성했다.

Conclusion: 구조화된 시간 표현의 중요성이 강조되며, 로컬 시간 인코딩을 글로벌 주의 기반 모델링과 분리하는 것이 더 효과적이고 안정적인 시계열 예측을 가져오는 것을 확인하였다.

Abstract: Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.

</details>


### [14] [CooperBench: Why Coding Agents Cannot be Your Teammates Yet](https://arxiv.org/abs/2601.13295)
*Arpandeep Khatua,Hao Zhu,Peter Tran,Arya Prabhudesai,Frederic Sadrieh,Johann K. Lieberwirth,Xinkai Yu,Yicheng Fu,Michael J. Ryan,Jiaxin Pei,Diyi Yang*

Main category: cs.LG

TL;DR: AI 에이전트는 팀 협력을 위하여 사회적 지능이 필요하지만, 현재의 에이전트는 이러한 능력이 부족함을 입증하는 연구


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 효과적인 팀원으로 기능하기 위해서는 조정 능력을 개발해야 하며, 이를 위해 팀 갈등 해결에 사회적 지능이 필요하다.

Method: 600개 이상의 협업 코딩 작업을 포함하는 CooperBench라는 벤치마크를 도입하여 AI 에이전트의 조정 능력을 테스트한다.

Result: AI 에이전트는 독립적으로 수행할 수 있는 작업을 팀으로 수행할 때 평균 30% 낮은 성공률을 보였으며, 이는 인간 팀과는 대조적이다.

Conclusion: 협업 코딩에 대한 새로운 벤치마크를 제시하며, 개별 에이전트 능력 개발에서 사회적 지능 개발로의 전환이 필요하다.

Abstract: Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.

</details>


### [15] [Cooperative Multi-agent RL with Communication Constraints](https://arxiv.org/abs/2601.12518)
*Nuoya Xiong,Aarti Singh*

Main category: cs.LG

TL;DR: 본 연구에서는 제한된 통신 상황에서 안정적인 정책 업데이트를 위해 구식 그래디언트를 활용하는 기본 정책 예측 기법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 분산 MARL 시스템에서 통신 비용이 높기 때문에 팀 보상이나 다른 에이전트의 행동과 같은 글로벌 정보에 자주 접근하는 것은 비현실적입니다. 따라서 에이전트는 오래된 정보에 의존하여 그래디언트를 추정하고 정책을 업데이트해야 합니다.

Method: 우리는 그래디언트 예측을 위해 오래된 그래디언트를 활용하고, 여러 기본 정책에 대한 샘플을 수집하여 기본 정책과 현재 정책 간의 격차를 줄이는 기본 정책 예측 기법을 제안합니다.

Result: 우리의 알고리즘은 잠재 게임에서 $	heta$-내쉬 균형으로 수렴하며, 기존의 최첨단 결과보다 통신 비용과 샘플 복잡성을 개선합니다.

Conclusion: 우리의 접근 방식은 예측된 기본 정책의 샘플이 단일 통신 라운드 내에서 수집될 수 있기 때문에 통신 라운드 수를 크게 줄이면서 효과적인 학습을 가능하게 합니다.

Abstract: Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\varepsilon$-Nash equilibrium in potential games with only $O(\varepsilon^{-3/4})$ communication rounds and $O(poly(\max_i |A_i|)\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.

</details>


### [16] [Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem](https://arxiv.org/abs/2601.12543)
*Alireza Ghahtarani,Martin Cousineau,Amir-massoud Farahmand,Jorge E. Mendoza*

Main category: cs.LG

TL;DR: 온라인 중앙 집중형 충전 스케줄링 문제(OCCSP)에서 전기차(EV)를 실시간으로 효율적으로 충전하기 위한 새로운 접근 방식을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 전기차의 도착 패턴에 따라 충전 스케줄을 조정하여 전력망의 부하 균형을 맞추고 운영 비용을 절감하는 것이 필요하다.

Method: 문제를 게임으로 모델링하고, 휴리스틱 정책을 설계하며, 전문가 시연을 통해 학습 에이전트를 훈련하고, Dataset Aggregation(DAgger)를 사용하여 개선한다.

Result: 실험 결과, 게임화된 학습이 부하 균형을 향상시키며, DAgger로 훈련된 모델이 기존의 휴리스틱 및 벡터 기반 접근법보다 우수함을 입증하였다.

Conclusion: 제안된 방법은 운영 효율성을 높이고, 몬트리올 대도시 지역에서 연간 수백만 달러의 비용을 절감할 수 있는 잠재력을 보여준다.

Abstract: We study the online centralized charging scheduling problem (OCCSP). In this problem, a central authority must decide, in real time, when to charge dynamically arriving electric vehicles (EVs), subject to capacity limits, with the objective of balancing load across a finite planning horizon. To solve the problem, we first gamify it; that is, we model it as a game where charging blocks are placed within temporal and capacity constraints on a grid. We design heuristic policies, train learning agents with expert demonstrations, and improve them using Dataset Aggregation (DAgger). From a theoretical standpoint, we show that gamification reduces model complexity and yields tighter generalization bounds than vector-based formulations. Experiments across multiple EV arrival patterns confirm that gamified learning enhances load balancing. In particular, the image-to-movement model trained with DAgger consistently outperforms heuristic baselines, vector-based approaches, and supervised learning agents, while also demonstrating robustness in sensitivity analyses. These operational gains translate into tangible economic value. In a real-world case study for the Greater Montréal Area (Québec, Canada) using utility cost data, the proposed methods lower system costs by tens of millions of dollars per year over the prevailing practice and show clear potential to delay costly grid upgrades.

</details>


### [17] [LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems](https://arxiv.org/abs/2601.14053)
*Badri N. Patro,Vijay S. Agneeswaran*

Main category: cs.LG

TL;DR: 대규모 언어 모델의 혁신과 발전을 조사하여 인공지능의 현황과 미래를 제시하며, 주요 과제를 해결하기 위한 여러 패러다임을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 인공지능 분야의 혁신을 통해 인간 수준의 성능을 달성하는 시스템을 이해하고자 한다.

Method: 2019-2025년 동안 50개 이상의 모델을 조사하여 아키텍처 혁신, 훈련 방법론, 효율성 패턴을 문서화한다.

Result: 2026-2028년 사이 데이터 부족, 비용 성장, 에너지 소비 문제를 식별하고 이를 해결하기 위한 여섯 가지 패러다임을 제안한다.

Conclusion: 효율성 혁명과 민주화 과정에서 발생하는 세 가지 패러다임 변화에 대한 통찰을 제공한다.

Abstract: The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.

</details>


### [18] [Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory](https://arxiv.org/abs/2601.12557)
*Mark Moussa,Amber V. Young,Brianna Isola,Vasuda Trehan,Michael D. Himes,Nicholas Wogan,Giada Arney*

Main category: cs.LG

TL;DR: NASA의 Habitable Worlds Observatory와 같은 미래의 직접 이미지 제작 주요 임무는 극도로 제한된 시간과 자원으로 인해 관측 우선 순위를 정하는 중요한 결정에 직면해 있다.


<details>
  <summary>Details</summary>
Motivation: 생명 지표 종의 플럭스를 예측하는 데 있어 정밀한 관측이 필요하다.

Method: Bayesian Convolutional Neural Network (BCNN) 및 Spectral Query Adaptive Transformer (SQuAT)라는 두 가지 고급 머신러닝 아키텍처를 제안한다.

Result: 두 모델 모두 다양한 외계 행성 조건에 걸쳐 높은 예측 정확도를 달성하였다.

Conclusion: 이러한 기능은 우리 방법을 목표 분류, 관측 일정 최적화 및 주요 임무에서의 과학적 수익 극대화에 유망한 도구로 자리매김하게 한다.

Abstract: Future direct-imaging flagship missions, such as NASA's Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to extremely stringent time and resource constraints. In this paper, we introduce two advanced machine-learning architectures tailored for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and our novel model architecture, the Spectral Query Adaptive Transformer (SQuAT). The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, whereas SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. We demonstrate that both models achieve comparably high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, while highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position our methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.

</details>


### [19] [Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization](https://arxiv.org/abs/2601.12604)
*Safwan Labbi,Daniil Tiapkin,Paul Mangold,Eric Moulines*

Main category: cs.LG

TL;DR: 정책 기울기 방법은 정책 매개변수화 선택에 매우 민감하다. 본 연구에서는 softmax 매개변수를 일반화된 f-softargmax로 교체하고 f-발산에 의해 유도된 정규화기를 결합하여 최적화 경관을 개선하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 정책 기울기 방법의 최적화 성능을 개선하기 위해

Method: softmax 대신에 일반화된 f-softargmax를 사용하는 매개변수화 방법을 제안하며, 동일한 f-발산에 의해 유도된 정규화기를 결합한다.

Result: 무정형 처리 없이 유한 MDPs에 대한 확률적 정책 기울기 방법의 첫 번째 명시적 비비대칭 최종 반복 수렴 보장을 확립하였다.

Conclusion: f-PG 방법은 표준 softmax 매개변수화로 인한 지수 복잡도에 비해 다항 샘플 복잡도를 달성함을 보여준다.

Abstract: Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.

</details>


### [20] [Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks](https://arxiv.org/abs/2601.12662)
*Xingran Chen,Navid NaderiAlizadeh,Alejandro Ribeiro,Shirin Saeedi Bidokhti*

Main category: cs.LG

TL;DR: 이 논문에서는 동적이면서도 구조적으로 유사한 다중 홉 무선 네트워크에서 자가 회귀 마르코프 소스의 실시간 샘플링 및 추정을 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 무선 충돌 채널을 통해 통신하는 각 노드가 샘플을 캐싱하고, 분산 정책을 통해 시간 평균 추정 오차를 최소화하는 것을 목표로 합니다.

Method: 그래프 기반의 다중 에이전트 강화 학습 프레임워크를 제안하여 최적 정책을 최적화합니다.

Result: 제안한 정책이 최첨단 기준보다 성능이 우수하며, 훈련된 정책이 더 큰 네트워크에 적용 가능하고, 비정상성에 강하며, 반복성이 중앙 집중식 훈련과 분산 실행에서 중요한 역할을 함을 수치 실험을 통해 입증하였습니다.

Conclusion: 제안한 정책은 그래프 훈련 절차를 통해 비정상성에 저항하면서도 성능 향상을 보장합니다.

Abstract: We address real-time sampling and estimation of autoregressive Markovian sources in dynamic yet structurally similar multi-hop wireless networks. Each node caches samples from others and communicates over wireless collision channels, aiming to minimize time-average estimation error via decentralized policies. Due to the high dimensionality of action spaces and complexity of network topologies, deriving optimal policies analytically is intractable. To address this, we propose a graphical multi-agent reinforcement learning framework for policy optimization. Theoretically, we demonstrate that our proposed policies are transferable, allowing a policy trained on one graph to be effectively applied to structurally similar graphs. Numerical experiments demonstrate that (i) our proposed policy outperforms state-of-the-art baselines; (ii) the trained policies are transferable to larger networks, with performance gains increasing with the number of agents; (iii) the graphical training procedure withstands non-stationarity, even when using independent learning techniques; and (iv) recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity.

</details>


### [21] [MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning](https://arxiv.org/abs/2601.12680)
*Zheng Fang,Wolfgang Mayer,Zeyu Zhang,Jian Wang,Hong-Yu Zhang,Wanli Li,Zaiwen Feng*

Main category: cs.LG

TL;DR: 툴 학습은 대형 언어 모델이 복잡한 실제 작업을 효과적으로 해결하는 데 점점 더 중요해지고 있으며, 이를 위해 적절한 툴을 선택하고 통합하는 것이 필요하다. 본 논문은 7개 도메인에 걸쳐 155개의 툴과 9,377개의 질문-답변 쌍을 포함하는 포괄적인 데이터셋을 소개하고, 메타학습 접근 방식인 MetaToolAgent를 제안하여 cross-tool 일반화를 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 복잡한 실제 작업을 해결하기 위해 다양한 툴을 효과적으로 조정하고 활용하는 것이 중요하다.

Method: 7개 도메인에 걸친 155개의 툴과 9,377개의 질문-답변 쌍을 포함한 포괄적인 데이터셋을 활용하고, 메타학습 방식인 MetaToolAgent를 제안하여 툴 간 일반화를 향상시킨다.

Result: MTA는 미지의 툴에 대해 기존 방법보다 훨씬 더 뛰어난 성능을 보인다.

Conclusion: MTA는 동적인 툴 조정이 필요한 유연하고 확장 가능한 시스템 구축에 유망하다.

Abstract: Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.

</details>


### [22] [Resource-Conscious RL Algorithms for Deep Brain Stimulation](https://arxiv.org/abs/2601.12699)
*Arkaprava Gupta,Nicholas Carter,William Zellers,Prateek Ganguli,Benedikt Dietrich,Vibhor Krishna,Parasara Sridhar Duggirala,Samarjit Chakraborty*

Main category: cs.LG

TL;DR: 본 연구에서는 파킨슨병 치료를 위한 새로운 강화 학습 접근법인 T3P MAB를 제안하고, 기존 방법에 비해 효율성을 높이기 위해 뇌 자극 신호의 주파수와 진폭을 동시에 조정할 수 있도록 하였다.


<details>
  <summary>Details</summary>
Motivation: DBS는 파킨슨병의 증상을 완화하기 위해 특정 뇌 영역을 자극하는 방법으로, 그러나 기존 접근법들은 부작용과 배터리 수명 단축의 문제가 있다.

Method: T3P MAB RL 접근법을 제안하여 주파수와 진폭을 동시에 조정하며, 경량화되어 임플란트에 배포할 수 있다.

Result: T3P MAB 알고리즘은 여러 마이크로컨트롤러 유닛에서 배포되어 다른 RL 접근법에 비해 에너지 소비 측면에서 효율성을 입증하였다.

Conclusion: T3P MAB는 뇌 자극 치료를 위한 더 나은 자원 제약 플랫폼에 적합하다.

Abstract: Deep Brain Stimulation (DBS) has proven to be a promising treatment of Parkinson's Disease (PD). DBS involves stimulating specific regions of the brain's Basal Ganglia (BG) using electric impulses to alleviate symptoms of PD such as tremors, rigidity, and bradykinesia. Although most clinical DBS approaches today use a fixed frequency and amplitude, they suffer from side effects (such as slurring of speech) and shortened battery life of the implant. Reinforcement learning (RL) approaches have been used in recent research to perform DBS in a more adaptive manner to improve overall patient outcome. These RL algorithms are, however, too complex to be trained in vivo due to their long convergence time and requirement of high computational resources.
  We propose a new Time & Threshold-Triggered Multi-Armed Bandit (T3P MAB) RL approach for DBS that is more effective than existing algorithms. Further, our T3P agent is lightweight enough to be deployed in the implant, unlike current deep-RL strategies, and even forgoes the need for an offline training phase. Additionally, most existing RL approaches have focused on modulating only frequency or amplitude, and the possibility of tuning them together remains greatly unexplored in the literature. Our RL agent can tune both frequency and amplitude of DBS signals to the brain with better sample efficiency and requires minimal time to converge. We implement an MAB agent for DBS for the first time on hardware to report energy measurements and prove its suitability for resource-constrained platforms. Our T3P MAB algorithm is deployed on a variety of microcontroller unit (MCU) setups to show its efficiency in terms of power consumption as opposed to other existing RL approaches used in recent work.

</details>


### [23] [Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization](https://arxiv.org/abs/2601.12707)
*Junyi Liao,Zihan Zhu,Ethan Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 이 논문은 에이전트 행동의 보상 함수 추정에 관한 연구로, 두 플레이어 제로섬 매트릭스 게임과 엔트로피 정규화를 포함한 마르코프 게임에서 보상 함수를 회복하기 위한 통합 프레임워크를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 보상 함수 추정은 역 강화 학습과 게임 이론에서 중심적인 관심사이다.

Method: 두 플레이어 제로섬 매트릭스 게임 및 마르코프 게임에서 에이전트의 행동을 관찰하여 보상 함수를 복원하는 통합 프레임워크를 개발하고, 양자 응답 평형(QRE)을 사용하여 보상 함수의 식별 가능성을 확립한다.

Result: 제안된 알고리즘은 정적 및 동적 설정 모두에서 작동하며, 최대 우도 추정(MLE)과 같은 다양한 방법을 통합할 수 있다.

Conclusion: 우리 알고리즘의 신뢰성과 샘플 효율성에 대한 강력한 이론적 보장을 제공하며, 경쟁 환경에서 의사 결정에 대한 새로운 통찰을 제시한다.

Abstract: Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.

</details>


### [24] [Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition](https://arxiv.org/abs/2601.12879)
*Mohammed Mudassir Uddin,Shahnawaz Alam,Mohammed Kaif Pasha*

Main category: cs.LG

TL;DR: 계층적 기여 그래프 분해(HAGD) 프레임워크는 신경망 모델의 계산을 인간이 이해할 수 있는 알고리즘으로 역설계하려는 메커니즘 해석 가능성을 추구하며, 효과적으로 희소한 계산 회로를 발견할 수 있도록 복잡성을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 신경망의 계산 과정을 인간이 이해 가능하도록 역설계하고자 하는 기계적 해석 가능성을 추구한다.

Method: HAGD 프레임워크는 다중 해상도 추상화 계층과 미분 가능한 회로 탐색을 통해 회로 발견 복잡성을 O(2^n)에서 O(n^2 log n)으로 줄인다.

Result: 프레임워크는 GPT-2 변형, Llama-7B부터 Llama-70B, 그리고 Pythia 모델들에서 실험적으로 평가되었으며, 모듈 형산술 작업에서 최대 91%의 행동 보존률을 달성하였다.

Conclusion: 대규모 모델에서의 해석 가능성을 위한 기초를 제공하면서, 현재의 기여 방법론에서 중요한 한계를 식별하고 미래의 발전이 필요함을 강조한다.

Abstract: Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\pm$2.3\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.

</details>


### [25] [AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs](https://arxiv.org/abs/2601.12893)
*Ting Dang,Soumyajit Chatterjee,Hong Jia,Yu Wu,Flora Salim,Fahim Kawsar*

Main category: cs.LG

TL;DR: 본 논문은 시계열 예측을 위해 특별히 설계된 새로운 소스 프리 TTA 방법인 AdaNODEs를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: TTA는 사전 훈련된 모델을 새로운 데이터 분포에 적응시키는데 유망한 솔루션으로 떠오르고 있지만, 대부분의 방법은 독립적인 데이터에 초점을 맞추고 있으며 시계열 데이터나 예측 태스크를 잘 다루지 않고 있습니다.

Method: Neural Ordinary Differential Equations (NODEs)를 활용하여 시계열 데이터의 분포 변화의 고유한 특성을 수용하는 새로운 적응 프레임워크를 제안하며, 예측 태스크에 대한 TTA 문제를 해결하기 위해 새로운 손실 함수를 제안합니다.

Result: AdaNODEs는 제한된 모델 파라미터만 업데이트하며, 시간적 의존성을 효과적으로 캡처하면서도 상당한 메모리 사용을 피하는 성능을 보여줍니다. 자세한 실험 결과, AdaNODEs는 SOTA 기준에 비해 각각 5.88% 및 28.4%의 상대적 개선을 달성했습니다.

Conclusion: AdaNODEs는 특히 높은 심각도의 분포 변화에서도 강인성을 보여 결론적으로 기존의 방법보다 향상된 성능을 나타냅니다.

Abstract: Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.

</details>


### [26] [PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient](https://arxiv.org/abs/2601.12988)
*Zijian Wang,Tiancheng Huang,Hanqi Li,Da Ma,Lu Chen,Kai Yu*

Main category: cs.LG

TL;DR: PaperCompass는 과학 문서를 읽고 관련 정보를 추출하는 자율 에이전트를 위한 새로운 프레임워크로, 고차원 계획과 세부 실행을 분리하여 효율성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 과학 문헌의 빠른 증가로 연구자들이 수동으로 새로운 발전을 추적하기 어려워졌으며, LLM의 발전이 자율 에이전트에 대한 관심을 불러일으켰다.

Method: PaperCompass는 고차원 계획을 초안하고 각 단계를 구체화하기 위해 세부적인 추론을 실행하는 구조를 가지고 있으며, Draft-and-Follow Policy Optimization (DFPO)이라는 맞춤형 RL 방법을 도입하여 초안 계획과 최종 솔루션을 공동 최적화한다.

Result: PaperCompass는 종합적인 벤치마크에서 강력한 기준선보다 효율성을 개선하며, 성능을 희생하지 않고 더 큰 모델들과 유사한 결과를 달성했다.

Conclusion: DFPO는 LLM의 '알고 하기' 간극을 좁히고 안정적이며 신뢰할 수 있는 훈련 과정을 지원하는 유리한 최적화 특성을 가진다.

Abstract: The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.

</details>


### [27] [Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis](https://arxiv.org/abs/2601.13021)
*Nataša Petrović,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Jose Maria Buades Rubio*

Main category: cs.LG

TL;DR: 이 연구는 겸형적혈구병 진단 지원을 위한 최적의 앙상블 기반 분류 방법과 특성을 선택하는 새로운 접근 방식을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 겸형적혈구병 진단 지원과 일반화를 달성하기 위해.

Method: 미세 이미지를 전처리하고 세분화한 후, 혈구에서 특징을 추출하고 앙상블 기계 학습 방법을 사용하여 형태를 분류했습니다.

Result: 랜덤 포레스트와 엑스트라 트리 분류기로 구성된 분류기가 F1-score 90.71%와 SDS-score 93.33%를 달성했습니다.

Conclusion: 이 연구는 Gradient Boosting 분류기보다 상당한 향상을 보여줍니다.

Abstract: This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.

</details>


### [28] [METIS: Mentoring Engine for Thoughtful Inquiry & Solutions](https://arxiv.org/abs/2601.13075)
*Abhinav Rajeev Kumar,Dhruv Trehan,Paras Chopra*

Main category: cs.LG

TL;DR: AI 멘토 METIS가 대학생들을 아이디어에서 논문으로 발전시키는 데 도움을 줄 수 있다.


<details>
  <summary>Details</summary>
Motivation: 많은 학생들이 전문가의 연구 멘토링에 접근할 수 없기 때문에 AI 멘토가 필요하다.

Method: METIS는 문헌 검색, 가이드라인 제공, 방법론 점검 및 메모리를 갖춘 도구 보강, 단계 인식 보조 도구이다.

Result: METIS는 학생들이 필요로 하는 모든 단계를 지원하며, 여러 단계에서 높은 점수를 기록했다.

Conclusion: METIS는 문서 기반 단계에서 특히 효과적이며, 초기 도구 라우팅 및 단계 잘못 분류와 같은 문제를 갖고 있다.

Abstract: Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.

</details>


### [29] [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243)
*Yapeng Li,Jiakuo Yu,Zhixin Liu,Xinnan Liu,Jing Yu,Songze Li,Tonghua Su*

Main category: cs.LG

TL;DR: 이 논문은 여러 추론 패러다임을 포괄적으로 평가하여 LLM의 추론 성능을 분석하고, 비용 대비 정확도 트레이드오프를 연구합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 추론 시스템으로 점점 더 많이 활용되고 있으며, 다양한 추론 패러다임의 상대적 효과성과 비용-정확도 트레이드오프가 잘 이해되지 않고 있습니다.

Method: 직접 단일 모델 생성, CoT 증강 단일 모델 추론, 대표적인 다중 에이전트 시스템 워크플로우를 포함하여 다양한 닫힌 형식 벤치마크에서 추론 성능을 평가했습니다.

Result: MAS에서의 역할에 따른 특정 능력 요구를 분석하고, 비용-정확도 트레이드오프를 통해 가장 유리한 MAS 워크플로우를 파악했습니다.

Conclusion: 구조적 복잡성의 증가가 항상 추론 성능 향상으로 이어지지 않으며, 그 이점은 추론 패러다임의 속성과 적합성에 매우 의존합니다.

Abstract: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.

</details>


### [30] [GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2601.13570)
*Tingting Dan,Jiaqi Ding,Guorong Wu*

Main category: cs.LG

TL;DR: GeoDynamics는 고차원 대칭 양의 정부호(SPD) 매니폴드에서 뇌 상태의 경로를 직접 추적하는 기하학적 상태공간 신경망이다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 기존 접근 방식은 뇌를 느슨하게 연결된 지역 집합으로 간주하거나 과도하게 단순화된 네트워크 우선 가정을 부과하여 진정으로 홀리스틱하고 자기 조직화된 역동적 시스템 관점을 놓치고 있다.

Method: GeoDynamics는 각 연결 행렬을 매니폴드를 인식하는 반복 프레임워크에 임베딩하여 부드럽고 기하학을 존중하는 전이를 학습한다.

Result: 이 방법은 작업 중심 상태 변화를 드러내고 알츠하이머병, 파킨슨병 및 자폐증의 조기 마커를 밝힌다.

Conclusion: 우리는 GeoDynamics가 다양한 영역에서 복잡한 시공간 역학 모델링에서 확장성과 강인성을 입증했다고 결론지었다.

Abstract: State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.

</details>


### [31] [Behavior Knowledge Merge in Reinforced Agentic Models](https://arxiv.org/abs/2601.13572)
*Xiangchi Yuan,Dachuan Shi,Chunhui Zhang,Zheyuan Liu,Shenglong Yao,Soroush Vosoughi,Wenke Lee*

Main category: cs.LG

TL;DR: 본 논문은 강화 학습(RL) 훈련 모델의 통합을 위한 새로운 메커니즘인 강화 에이전트 병합(RAM)을 제안하며, 이는 특화된 기능을 유지하며 여러 에이전트를 하나의 일반 모델로 통합하는 데 중점을 두고 있다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 모델의 후속 훈련 과정에서 여러 RL 훈련된 에이전트를 통합하려는 필요성이 커지고 있다.

Method: RAM은 공유 매개변수와 과제별 고유 매개변수 업데이트를 분리하여 개발된 프레임워크이다.

Result: RAM은 여러 에이전트 분야 및 모델 아키텍처에서 기존 병합 기준선을 초과하며, 특화된 에이전트보다 뛰어난 성과를 달성하는 시너지 가능성을 열어준다.

Conclusion: 본 연구는 RL 훈련된 모델의 통합에 있어 특화된 기능을 유지하는 방법론을 제안하며, 각 에이전트 간의 시너지를 극대화한다.

Abstract: Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.

</details>


### [32] [Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data](https://arxiv.org/abs/2601.13608)
*Zhipeng Chang,Ting He,Wenrui Hao*

Main category: cs.LG

TL;DR: FIPA는 비대칭 데이터 환경에서 클라이언트의 데이터를 반영한 모델 업데이트를 개선하는 새로운 집계 방법입니다.


<details>
  <summary>Details</summary>
Motivation: 연결된 클라이언트로부터의 모델 업데이트를 집계하되, 비대칭 데이터 환경에서 일관된 가중치 부여의 문제를 해결하고자 함.

Method: 고유한 데이터의 영향을 반영하기 위해 파라미터별 피셔 정보 행렬 가중치를 사용한 2차 집계 방법인 FIPA를 제안함.

Result: FIPA는 비선형 함수 회귀, PDE 학습, 이미지 분류 등 다양한 분야에서 평균 기반 집계 방식보다 일관되게 성능을 향상시킴.

Conclusion: FIPA는 이질적인 데이터 분포 하에서 분산 학습의 이점을 강조함.

Abstract: Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.

</details>


### [33] [TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation](https://arxiv.org/abs/2601.13653)
*Xingjian Wu,Junkai Lu,Zhengyu Li,Xiangfei Qiu,Jilin Hu,Chenjuan Guo,Christian S. Jensen,Bin Yang*

Main category: cs.LG

TL;DR: TimeART는 강력한 도구의 분석 능력과 대형 언어 모델의 추론 능력을 결합한 프레임워크로, 시간 시계열 질문 응답을 위한 완전한 데이터 과학자로 기능한다.


<details>
  <summary>Details</summary>
Motivation: 사이버-물리 시스템에서 시간 시계열 데이터의 분석 및 해석은 재해 예측과 금융 위험 관리와 같은 중요한 가치를 창출하지만, 현재의 작업 흐름은 인간 데이터 과학자에게 의존하여 많은 노동 비용과 자동화 부족 문제를 겪고 있다.

Method: TimeART는 LLM 기반 시간 시계열 추론 모델을 전략적으로 도구를 사용하도록 가르치기 위해 10만개의 전문가 경로 집합인 TimeToolBench를 수집하고, 모델의 일반화 능력을 향상시키기 위해 네 단계 훈련 전략을 설계한다.

Result: 8B TSRM을 TimeToolBench에서 훈련하고 TimeART 프레임워크로 장착하여 여러 TSQA 작업에서 일관되게 최첨단 성능을 달성한다.

Conclusion: 이는 에이전트 기반 시간 시계열 추론을 향한 새로운 접근 방식을 개척한다.

Abstract: Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning.

</details>


### [34] [Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction](https://arxiv.org/abs/2601.13710)
*Sayeed Shafayet Chowdhury,Snehasis Mukhopadhyay,Shiaofen Fang,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 이 논문은 만성 비부비동염(CRS) 환자의 수술 전 예측을 통해 인공지능이 의료 이미지 외에도 임상 데이터에서 개발된 모델의 효용을 평가합니다.


<details>
  <summary>Details</summary>
Motivation: AI가 의료 이미징을 혁신했지만, 임상 데이터에 대한 AI의 사용은 제한적입니다. 따라서 CRS 환자의 수술 전 결과를 예측하려고 합니다.

Method: 수술을 받는 모든 환자를 대상으로 수집한 코호트에서 수술을 피해야 할 환자를 예측하기 위해 수술 전 임상 데이터만 사용하는 모델을 검토했습니다.

Result: 우리의 최상의 ML 모델(MLP)은 85%의 정확도와 함께 우수한 보정 및 의사결정 곡선 순 이익을 달성했습니다. 반면 GenAI 모델은 경험적 분별 및 보정에서 낮은 성능을 나타냈습니다.

Conclusion: ML을 주된 방법으로 사용하고 GenAI를 보조 도구로 활용하여 수술 후보자에 대한 적절한 분류를 시행하며 결정 과정을 투명하게 만들어야 합니다.

Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.

</details>


### [35] [PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles](https://arxiv.org/abs/2601.13793)
*ByeoungDo Kim,JunYeop Na,Kyungwook Tak,JunTae Kim,DongHyeon Kim,Duckky Kim*

Main category: cs.LG

TL;DR: 이 논문에서는 역사적 도로 속도 패턴에 대한 주의 메커니즘을 활용한 ETA(Estimated Time of Arrival) 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자율주행 및 지능형 교통 시스템의 발전에 따라 정확하고 신뢰할 수 있는 ETA 예측의 필요성이 증가하고 있습니다.

Method: 우리는 주의 메커니즘을 활용하여 경로에 따라 각 시공간 지점에서 축적된 시간적 특성을 추출하고 활용함으로써 ETA 예측의 시공간 인과 관계를 해결합니다.

Result: 실제 주행 데이터 세트를 사용해 검증한 결과, 우리의 접근법은 도로 특성, 실시간 교통 상황 및 역사적 속도 패턴을 효과적으로 통합하여 기존 기준선을 능가함을 보여주었습니다.

Conclusion: 이 아키텍처는 효율적이고 정확한 ETA 추정을 가능하게 하며, 모델의 경량성과 확장성을 유지합니다.

Abstract: In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.

</details>


### [36] [Multi-Objective Hierarchical Optimization with Large Language Models](https://arxiv.org/abs/2601.13892)
*Andrej Schwanke,Lyubomir Ivanov,David Salinas,Frank Hutter,Arber Zela*

Main category: cs.LG

TL;DR: 본 논문에서는 대형 언어 모델(LLM)을 다목적 최적화를 위한 대리 모델과 후보 샘플러로 활용한 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 강력한 추론 능력에도 불구하고 다목적 최적화에 대한 오프더셸프 선택으로 사용되지 않는 문제를 해결하고자 합니다.

Method: 구조화된 계층적 탐색 전략 내부에서 LLM을 대리 모델 및 후보 샘플러로 활용하여 입력 공간을 비연속적인 다각형 영역으로 적응적으로 분할하고 복합 점수 함수로 순위를 매깁니다.

Result: 우리의 알고리즘은 후보 솔루션을 생성하여 실제 파레토 집합에 수렴하며, 경험적으로는 기존의 LLM 기반 다목적 최적화 알고리즘을 지속적으로 초월하고 진화적 및 베이지안 최적화 알고리즘과 동등한 성능을 보입니다.

Conclusion: LLM을 활용하여 문제를 더욱 쉽게 해결할 수 있으며, 이는 문제의 글로벌 구조에 대해 추론할 필요 없이 로컬로만 작업할 수 있게 만듭니다.

Abstract: Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.

</details>


### [37] [TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography](https://arxiv.org/abs/2601.13897)
*Ankita Joshi,Ashutosh Sharma,Anoushkrit Goel,Ranjeet Ranjan Jha,Chirag Ahuja,Arnav Bhavsar,Aditya Nigam*

Main category: cs.LG

TL;DR: TractRLFusion이라는 새로운 방법이 여러 강화 학습 정책을 통합하여 백질 섬유 경로를 더 정확하게 재구성하며, 기존 방법들보다 우수한 성능을 보임.


<details>
  <summary>Details</summary>
Motivation: 백질 섬유 경로의 비침습적 재구성과 뇌 연결성 정보 제공을 통한 정밀 신경외과 수술 계획 지원.

Method: 데이터 중심 융합 전략을 통해 여러 강화 학습 정책을 통합하는 GPT 기반 정책 융합 프레임워크인 TractRLFusion을 제안.

Result: HCP, ISMRM, TractoInferno 데이터셋에 대한 실험 결과, TractRLFusion이 개별 강화 학습 정책 및 최신 고전적 방법과 DRL 방법을 초과하는 정확성과 해부학적 신뢰성을 보여줌.

Conclusion: TractRLFusion은 강화 학습을 통한 백질 경로 재구성의 정확성과 신뢰성을 크게 향상시킴.

Abstract: Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.

</details>


### [38] [RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning](https://arxiv.org/abs/2601.13964)
*Cheol-Hui Lee,Hwa-Yeon Lee,Dong-Joo Kim*

Main category: cs.LG

TL;DR: RL-BioAug 프레임워크는 EEG 작업의 대조 학습 성능을 향상시키기 위해 최적화된 데이터 증강 전략을 자동으로 결정하는 강화 학습 에이전트를 활용한다.


<details>
  <summary>Details</summary>
Motivation: 유 labeled data를 활용하여 EEG 신호의 비정상성을 고려한 데이터 증강의 중요성을 설명한다.

Method: RL-BioAug라는 프레임워크를 제안하며, 레이블 데이터의 최소 비율(10%)로 최적화된 증강 정책을 결정하는 강화 학습 에이전트를 사용한다.

Result: RL-BioAug는 Sleep-EDFX와 CHB-MIT 데이터셋에서 Macro-F1 점수 9.69% 및 8.80% 향상을 이루어냈다.

Conclusion: RL-BioAug가 기존의 휴리스틱 기반 증강 방식을 대체할 수 있는 가능성을 제시한다.

Abstract: The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\% and 8.80\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\% probability for sleep stage classification and Crop \& Resize with a 77\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \href{https://github.com/dlcjfgmlnasa/RL-BioAug}{https://github.com/dlcjfgmlnasa/RL-BioAug}.

</details>


### [39] [Penalizing Localized Dirichlet Energies in Low Rank Tensor Products](https://arxiv.org/abs/2601.14173)
*Paris A. Karakasis,Nicholas D. Sidiropoulos*

Main category: cs.LG

TL;DR: 저희는 회귀 작업을 위한 저계수 텐서곱 B-스플라인 모델(TPBS 모델)을 연구하고 매끄러움의 척도로서 디리클레 에너지를 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 정규화 방법이 저계수 텐서곱 B-스플라인 모델의 특성을 충분히 반영하지 못하는 문제를 해결하고자 합니다.

Method: 훈련 지점 주위의 작은 하이퍼큐브에서 정의된 국소 디리클레 에너지를 기반으로 한 새로운 정규화 전략을 제안합니다.

Result: TPBS 모델이 대부분의 데이터셋에서 신경망보다 과적합 영역에서 우수한 성능을 보이며, 정규화의 효과를 일관되게 누립니다.

Conclusion: 저계수 텐서곱 B-스플라인 모델은 과적합에 대해 더 강한 내성을 보이며, 신경망보다 정규화의 효과를 더 잘 활용합니다.

Abstract: We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.

</details>


### [40] [Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment](https://arxiv.org/abs/2601.14228)
*Punit Kumar,Vaibhav Saran,Divyesh Patel,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: 이 연구에서는 해석 가능한 의사결정 지원 프레임워크를 제안하며, 이를 통해 중환자실에서 패혈증 치료의 정확성을 높이고자 한다.


<details>
  <summary>Details</summary>
Motivation: 패혈증은 중환자실에서 주요 사망 원인 중 하나이며, 신속하고 정확한 치료 결정이 환자 결과에 큰 영향을 미칠 수 있다.

Method: 이 시스템은 (1) 통계 검증을 사용한 클러스터링을 통해 환자를 저위험, 중위험 및 고위험 그룹으로 분류하는 클러스터링 기반의 층화 모듈, (2) 변분 오토인코더(VAE) 및 확산 모델을 활용하여 미세하게 표현된 궤적을 풍부하게 만드는 합성 데이터 증강 파이프라인, (3) 가벼운 주의 인코더를 사용하는 Advantage Weighted Regression(AWR)으로 훈련된 오프라인 강화 학습(RL) 에이전트, (4) 임상 맥락에 기반하고 전문가 지식을 활용한 자연어 정당화를 생성하는 다중 모드 대규모 언어 모델(LLM)을 이용한 정당화 생성 모듈을 통합하여 구성된다.

Result: MIMIC-III 및 eICU 데이터셋에서 평가된 결과, 우리의 접근 방식은 높은 치료 정확성을 달성하면서 임상의에게 해석 가능하고 강건한 정책 제안을 제공하였다.

Conclusion: 이 연구의 의사결정 지원 프레임워크는 중환자실에서 패혈증 치료의 질을 향상시키는 데 기여할 수 있다.

Abstract: Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.

</details>


### [41] [KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning](https://arxiv.org/abs/2601.14232)
*Egor Cherepanov,Daniil Zelezetsky,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 이 논문에서는 KAGE-Env와 KAGE-Bench를 도입하여 비주얼 변동에 대한 강화학습 에이전트의 성능 문제를 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 픽셀 기반 강화학습 에이전트는 잠재적 동역학과 보상이 동일함에도 불구하고 오직 시각적 분포 변화에서 실패하는 경우가 많습니다. 그러나 기존의 벤치마크는 여러 변화를 혼합하여 체계적인 분석을 방해합니다.

Method: KAGE-Env는 시각적 축을 독립적으로 제어 가능하게 분리한 2D 플랫폼 환경을 제공하며, KAGE-Bench는 개별 시각적 변화에 대한 여섯 가지 알려진 축을 포함하는 벤치마크입니다.

Result: 표준 PPO-CNN 기준선 사용 시 축에 따라 강한 실패를 관찰했으며, 배경 및 광도 변화에서 성공률이 크게 떨어지고 반면 에이전트 외관 변화는 비교적 경미했습니다.

Conclusion: KAGE-Env는 빠르고 재현 가능한 시각적 요소에 대한 분석을 가능하게 하며, 코드가 제공됩니다.

Abstract: Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/.

</details>


### [42] [Q-learning with Adjoint Matching](https://arxiv.org/abs/2601.14234)
*Qiyang Li,Sergey Levine*

Main category: cs.LG

TL;DR: Q-learning with Adjoint Matching (QAM) 알고리즘은 지속적인 행동 강화 학습에서 표현력 있는 확산 또는 흐름 정합 정책을 최적화하는 데 효율적이다.


<details>
  <summary>Details</summary>
Motivation: 지속적인 행동에서의 효율적인 정책 최적화는 어려운 문제이며, 이 논문은 이를 해결하기 위한 새로운 알고리즘을 제안한다.

Method: QAM은 비선형 회귀 기반의 비선형 최적화 기법인 인접 정합(adjont matching)을 활용하여 비선형 정책을 효율적으로 학습한다.

Result: QAM은 기존 방법에 비해 어려운 희소 보상 작업에서도 지속적으로 우수한 성능을 나타낸다.

Conclusion: QAM은 불안정한 역전파 문제를 피하면서 비편향적이고 표현력이 있는 정책을 제공한다.

Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.

</details>


### [43] [Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression](https://arxiv.org/abs/2601.14238)
*Shaurya Mathur,Shreyas Bellary Manjunath,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: 본 연구에서는 화재 예측과 지능형 진압 전략을 결합한 인공지능 프레임워크인 FireCastRL을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 미국에서 산불의 빈도와 강도가 증가하고 있으며, 이는 생태계와 지역 사회에 파괴적 영향을 미치고 있습니다. 기존 산불 관리 방법은 주로 반응적이어서 감지된 후에만 대응합니다.

Method: FireCastRL은 심층 시공간 모델을 사용하여 산불 발화 예측을 수행하며, 고위험 예측에 대해 사전 훈련된 강화 학습 에이전트를 활용하여 물리적으로 유도된 3D 시뮬레이션 내에서 실시간 진압 전술을 실행합니다.

Result: 프레임워크는 자원 allocation 및 계획 최적화를 지원하기 위해 위협 평가 보고서를 생성합니다. 또한, 산불 예측을 위한 환경 변수의 950만 샘플이 포함된 대규모 시공간 데이터셋을 공개합니다.

Conclusion: 본 연구는 심층 학습과 강화 학습을 결합하여 예측 및 전술적 산불 대응을 지원하는 방법을 보여줍니다.

Abstract: Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [44] [Rethinking the Value of Multi-Agent Workflow: A Strong Single Agent Baseline](https://arxiv.org/abs/2601.12307)
*Jiawei Xu,Arief Koesdwiady,Sisong Bei,Yan Han,Baixiang Huang,Dakuo Wang,Yutong Chen,Zheshen Wang,Peihao Wang,Pan Li,Ying Ding*

Main category: cs.MA

TL;DR: LLM 기반의 다중 에이전트 시스템(MAS)에서 단일 에이전트가 동일한 작업 흐름과 비교하여 성능을 발휘할 수 있음을 밝히고, 이를 기반으로 단일 에이전트 실행에 최적화된 알고리즘인 OneFlow를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 다중 에이전트 시스템에서 여러 LLM 에이전트의 역할과 도구에 따라 복잡한 작업에서 단일 LLM보다 더 나은 성능을 낼 수 있지만, 동질적인 프레임워크에서의 한계를 조사하기 위해.

Method: 여러 벤치마크를 통해 단일 에이전트가 동질적인 작업 흐름의 성능에 도달할 수 있는지 연구하고, KV 캐시 재사용의 효율성 이점을 분석하여 이를 기반으로 단일 에이전트 실행에 맞춘 알고리즘인 OneFlow를 제안.

Result: 단일 에이전트가 동질적인 작업 흐름의 성능에 도달할 수 있으며, 자동 최적화된 이질적 작업 흐름의 성능에도 도달할 수 있음을 발견.

Conclusion: 이 연구는 다중 에이전트 시스템 연구에 단일 LLM 구현의 중요한 기준선을 마련하며, 단일 LLM 방법이 이질적인 작업 흐름을 포착할 수 없는 한계를 강조한다.

Abstract: Recent advances in LLM-based multi-agent systems (MAS) show that workflows composed of multiple LLM agents with distinct roles, tools, and communication patterns can outperform single-LLM baselines on complex tasks. However, most frameworks are homogeneous, where all agents share the same base LLM and differ only in prompts, tools, and positions in the workflow. This raises the question of whether such workflows can be simulated by a single agent through multi-turn conversations. We investigate this across seven benchmarks spanning coding, mathematics, general question answering, domain-specific reasoning, and real-world planning and tool use. Our results show that a single agent can reach the performance of homogeneous workflows with an efficiency advantage from KV cache reuse, and can even match the performance of an automatically optimized heterogeneous workflow. Building on this finding, we propose \textbf{OneFlow}, an algorithm that automatically tailors workflows for single-agent execution, reducing inference costs compared to existing automatic multi-agent design frameworks without trading off accuracy. These results position the single-LLM implementation of multi-agent workflows as a strong baseline for MAS research. We also note that single-LLM methods cannot capture heterogeneous workflows due to the lack of KV cache sharing across different LLMs, highlighting future opportunities in developing \textit{truly} heterogeneous multi-agent systems.

</details>


### [45] [Generative AI Agents for Controllable and Protected Content Creation](https://arxiv.org/abs/2601.12348)
*Haris Khan,Sadia Asif*

Main category: cs.MA

TL;DR: 이 논문은 생성 AI의 통제성과 콘텐츠 보호 문제를 해결하는 다중 에이전트 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재 생성 AI 시스템은 통제성과 콘텐츠 보호에서 중요한 도전에 직면해 있다.

Method: 전문화된 에이전트 역할과 통합된 워터마크 메커니즘을 통해 이 두 가지 한계를 주소하는 새로운 다중 에이전트 프레임워크를 제안한다.

Result: 제안된 프레임워크는 사용자 의도에 맞춰 조정되는 동시에 감지할 수 없는 디지털 워터마크를 삽입하는 제어 가능한 콘텐츠 합성과 출처 보호를 독특하게 결합한다.

Conclusion: 다중 에이전트 아키텍처를 신뢰할 수 있는 창의적 워크플로우를 위한 솔루션으로 자리매김함으로써 책임 있는 생성 AI에 기여한다.

Abstract: The proliferation of generative AI has transformed creative workflows, yet current systems face critical challenges in controllability and content protection. We propose a novel multi-agent framework that addresses both limitations through specialized agent roles and integrated watermarking mechanisms. Unlike existing multi-agent systems focused solely on generation quality, our approach uniquely combines controllable content synthesis with provenance protection during the generation process itself. The framework orchestrates Director/Planner, Generator, Reviewer, Integration, and Protection agents with human-in-the-loop feedback to ensure alignment with user intent while embedding imperceptible digital watermarks. We formalize the pipeline as a joint optimization objective unifying controllability, semantic alignment, and protection robustness. This work contributes to responsible generative AI by positioning multi-agent architectures as a solution for trustworthy creative workflows with built-in ownership tracking and content traceability.

</details>


### [46] [Semantic Fusion: Verifiable Alignment in Decentralized Multi-Agent Systems](https://arxiv.org/abs/2601.12580)
*Sofiya Zaichyk*

Main category: cs.MA

TL;DR: Semantic Fusion(SF)은 다중 에이전트 시스템에서 분산된 의미 조정을 위한 공식적인 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템 내에서 중앙 집중식 제어 없이 에이전트를 효과적으로 협력할 수 있게 하기 위함이다.

Method: 에이전트가 범위가 지정된 공유 메모리 뷰에서 작업하고 구조화된 업데이트를 제안하며, 지역적인 온톨로지 기반 검증 및 갱신을 통해 글로벌 일관성을 유지하는 방식.

Result: 250개의 에이전트를 이용한 시뮬레이션에서 11,000건 이상의 검증된 업데이트를 통해 SF의 속성과 수렴성을 평가하였다.

Conclusion: Semantic Fusion은 분산 시스템에서 검증 가능한 자율성을 위한 공식적이고 확장 가능한 기반을 제공할 수 있다.

Abstract: We present Semantic Fusion (SF), a formal framework for decentralized semantic coordination in multi-agent systems. SF allows agents to operate over scoped views of shared memory, propose structured updates, and maintain global coherence through local ontology-based validation and refresh without centralized control or explicit message passing. The central theoretical result is a bisimulation theorem showing that each agent's local execution is behaviorally equivalent to its projection of the global semantics, in both deterministic and probabilistic settings. This enables safety, liveness, and temporal properties to be verified locally and soundly lifted to the full system. SF supports agents whose update proposals vary across invocations, including those generated by learned or heuristic components, provided updates pass semantic validation before integration. We establish deterministic and probabilistic guarantees ensuring semantic alignment under asynchronous or degraded communication. To validate the model operationally, we implement a lightweight reference architecture that instantiates its core mechanisms. A 250-agent simulation evaluates these properties across over 11,000 validated updates, demonstrating convergence under probabilistic refresh, bounded communication, and resilience to agent failure. Together, these results show that Semantic Fusion can provide a formal and scalable basis for verifiable autonomy in decentralized systems.

</details>


### [47] [Communication Methods in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.12886)
*Christoph Wittner*

Main category: cs.MA

TL;DR: 다중 에이전트 강화 학습에서의 통신 기술 개요와 그 강점 및 약점 분석.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템 문제를 해결하기 위해 강화 학습 접근 방식을 확장하는 연구의 필요성.

Method: 29개의 관련 논문을 심층 분석하여 다양한 통신 기법의 강점과 약점을 평가.

Result: 명시적, 암시적, 주의 기반, 그래프 기반 및 계층적/역할 기반 통신의 비교 결과를 통해 특정 문제에 적합한 통신 방법의 선택 중요성을 강조.

Conclusion: 현재 연구의 공백을 논의하고 시스템 수준 메트릭의 표준화된 벤치마크 필요성을 강조하며 현실적인 통신 조건에서의 강인성 향상 필요성을 지적.

Abstract: Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.

</details>


### [48] [OFA-MAS: One-for-All Multi-Agent System Topology Design based on Mixture-of-Experts Graph Generative Models](https://arxiv.org/abs/2601.12996)
*Shiyuan Li,Yixin Liu,Yu Zheng,Mei Li,Quoc Viet Hung Nguyen,Shirui Pan*

Main category: cs.MA

TL;DR: OFA-TAD는 자연어로 설명된 작업을 위해 적응형 협업 그래프를 생성하는 단일 범용 모델 기반 프레임워크로, 다양한 도메인의 사용자 쿼리에 적합한 협업 토폴로지를 설계한다.


<details>
  <summary>Details</summary>
Motivation: 멀티 에이전트 시스템의 성능은 그들의 협업 토폴로지 설계에 크게 의존하며, 웹 서비스에서 다양한 사용자 쿼리를 처리하기 위해 적응형 토폴로지가 필수적이다.

Method: OFA-TAD는 태스크 인식 그래프 상태 인코더와 전문가 혼합 아키텍처를 활용하여 작업에 적합한 정보를 필터링하고 동적으로 전문화된 하위 네트워크를 선택한다.

Result: 여섯 가지 다양한 벤치마크에서 OFA-TAD는 전문화된 일대일 모델에 비해 유의미하게 우수한 성능을 보였으며, 적응형 멀티 에이전트 시스템 토폴로지를 생성하였다.

Conclusion: 이 연구는 다중 도메인 사용자 쿼리를 위해 효과적인 협업 그래프 설계의 새로운 가능성을 보여준다.

Abstract: Multi-Agent Systems (MAS) offer a powerful paradigm for solving complex problems, yet their performance is critically dependent on the design of their underlying collaboration topology. As MAS become increasingly deployed in web services (e.g., search engines), designing adaptive topologies for diverse cross-domain user queries becomes essential. Current graph learning-based design methodologies often adhere to a "one-for-one" paradigm, where a specialized model is trained for each specific task domain. This approach suffers from poor generalization to unseen domains and fails to leverage shared structural knowledge across different tasks. To address this, we propose OFA-TAD, a one-for-all framework that generates adaptive collaboration graphs for any task described in natural language through a single universal model. Our approach integrates a Task-Aware Graph State Encoder (TAGSE) that filters task-relevant node information via sparse gating, and a Mixture-of-Experts (MoE) architecture that dynamically selects specialized sub-networks to drive node and edge prediction. We employ a three-stage training strategy: unconditional pre-training on canonical topologies for structural priors, large-scale conditional pre-training on LLM-generated datasets for task-topology mappings, and supervised fine-tuning on empirically validated graphs. Experiments across six diverse benchmarks show that OFA-TAD significantly outperforms specialized one-for-one models, generating highly adaptive MAS topologies. Code: https://github.com/Shiy-Li/OFA-MAS.

</details>


### [49] [A simulation of urban incidents involving pedestrians and vehicles based on Weighted A*](https://arxiv.org/abs/2601.13452)
*Edgar Gonzalez Fernandez*

Main category: cs.MA

TL;DR: 이 문서는 보행자와 차량이 관련된 도시 사건을 모델링하기 위한 종합적인 시뮬레이션 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 도시 환경에서 보행자와 차량 간의 상호작용을 보다 잘 이해하고 사고 위험을 평가하기 위함입니다.

Method: 다중 에이전트 시스템 접근 방식을 사용하여 2D 격자 기반 도시 환경 내에서 보행자와 차량 두 가지 유형의 에이전트를 도입하고, 경로 탐색을 위해 가중치 A* 알고리즘을 이용합니다.

Result: 장애물 밀도, 교통 제어 메커니즘의 존재, 행동 편차와 같은 요인이 안전과 여행 효율성에 미치는 영향을 실험적으로 탐구합니다.

Conclusion: 이 모델은 다양한 환경 및 행동 조건에서의 상호작용 시뮬레이션과 충돌 위험 평가를 가능하게 하여 도시 교통 안전성 향상에 기여할 수 있습니다.

Abstract: This document presents a comprehensive simulation framework designed to model urban incidents involving pedestrians and vehicles. Using a multiagent systems approach, two types of agents (pedestrians and vehicles) are introduced within a 2D grid based urban environment. The environment encodes streets, sidewalks, buildings, zebra crossings, and obstacles such as potholes and infrastructure elements. Each agent employs a weighted A* algorithm for pathfinding, allowing for variation in decision making behavior such as reckless movement or strict rule-following. The model aims to simulate interactions, assess risk of collisions, and evaluate efficiency under varying environmental and behavioral conditions. Experimental results explore how factors like obstacle density, presence of traffic control mechanisms, and behavioral deviations affect safety and travel efficiency.

</details>


### [50] [The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption](https://arxiv.org/abs/2601.13671)
*Apoorva Adimulam,Rajesh Gupta,Sumit Kumar*

Main category: cs.MA

TL;DR: 본 논문은 다중 에이전트 시스템의 기술적 구성을 통합하고 정형화하고, 이를 위한 통합 아키텍처 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템은 복잡한 목표를 달성하기 위해 자율 에이전트들이 협력하는 방식으로 인공지능의 진화의 다음 단계로 간주된다.

Method: 계획, 정책 집행, 상태 관리 및 품질 운영을 통합한 일관된 오케스트레이션 레이어를 제공하는 통합 아키텍처 프레임워크를 개발하고, 모델 컨텍스트 프로토콜 및 에이전트 간 프로토콜을 정의했다.

Result: 구현 가능한 커뮤니케이션 하부 구조를 통해 분산 에이전트 집단 전반에 걸쳐 확장 가능하고 감사 가능하며 정책 준수의 추론을 가능하게 한다.

Conclusion: 오케스트레이션 로직, 거버넌스 프레임워크 및 가시성 메커니즘을 결합함으로써 시스템의 일관성, 투명성 및 책임성을 유지한다.

Abstract: Orchestrated multi-agent systems represent the next stage in the evolution of artificial intelligence, where autonomous agents collaborate through structured coordination and communication to achieve complex, shared objectives. This paper consolidates and formalizes the technical composition of such systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. Another primary contribution of this work is the in-depth technical delineation of two complementary communication protocols - the Model Context Protocol, which standardizes how agents access external tools and contextual data, and the Agent2Agent protocol, which governs peer coordination, negotiation, and delegation. Together, these protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. Beyond protocol design, the paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems - bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [51] [Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic](https://arxiv.org/abs/2601.11809)
*Zeyu Mu,Shangtong Zhang,B. Brian Park*

Main category: cs.AI

TL;DR: 연결된 자동화 차량(CAVs)은 서로 통신하고 협력하여 에너지 효율성과 교통 흐름을 향상시키는 협력적 플래투닝을 가능하게 한다. 그러나 초기 CAV 배치 단계에서는 인력 주행 차량 사이에 CAV가 드물게 분포되어 있어 효과적인 협력 플래투닝을 형성할 가능성이 낮다. 본 연구에서는 CAV의 협력 플래투닝 참여를 증가시키고 관련 이익을 극대화하기 위한 하이브리드 다중 에이전트 차선 변경 결정 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: CAV의 초기 배치 단계에서의 비효율성과 협력 플래투닝의 필요성을 해결하기 위해.

Method: QMIX 프레임워크를 기반으로 하여 CNN을 통해 처리된 교통 데이터를 통합하여 하이브리드 다중 에이전트 차선 변경 결정 모델을 제안한다.

Result: 제안된 모델은 CAV 시장 침투율이 변화하는 환경에서 훈련 및 평가되었으며, 기존의 규칙 기반 모델보다 훨씬 우수한 성능을 보였다.

Conclusion: 이 모델은 초기 배치 단계에서 CAV 협력 및 교통 동역학을 최적화할 잠재력을 보여준다.

Abstract: Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.

</details>


### [52] [POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation](https://arxiv.org/abs/2601.11816)
*Zahra Moslemi,Keerthi Koneru,Yen-Ting Lee,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: POLARIS는 정책을 인식하는 다중 에이전트 시스템의 통합 오케스트레이션 프레임워크로, 자동화를 계획합성과 실행으로 다룬다. 이 시스템은 금융 문서 작업에 적용되어 결정 가능한 결과물을 생성하고 인간 개입을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 기업의 백오피스 워크플로우는 감사 가능하고 정책에 부합하며 운영적으로 예측 가능한 에이전트 시스템을 필요로 한다.

Method: POLARIS는 자동화를 타입 계획 합성과 LLM 에이전트를 통한 검증된 실행으로 다루는 거버넌스 오케스트레이션 프레임워크이다. 계획자는 구조적으로 다양한, 타입 체크된 방향성 비순환 그래프(DAG)를 제안하고, 규범에 안내된 추론 모듈이 단일 준수 계획을 선택하며, 실행은 검증자 검사를 통해 보호된다.

Result: POLARIS는 문서 중심 금융 작업에 적용되어 결정을 위한 산출물과 전체 실행 흔적을 생산하고, 인간 개입을 줄인다. 실험적으로, POLARIS는 SROIE 데이터셋에서 0.81의 마이크로 F1 점수를 달성하고, 제어된 합성 스위트에서 0.95에서 1.00의 정밀도를 달성한다.

Conclusion: 이 평가는 거버넌스된 에이전틱 AI에 대한 초기 벤치마크를 구성하며, POLARIS는 정책에 부합하는 에이전틱 AI에 대한 방법론적 및 벤치마크 참조를 제공한다.

Abstract: Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation

</details>


### [53] [Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic](https://arxiv.org/abs/2601.11840)
*Hongyu Lin,Samer Abdallah,Makar Valentinov,Paul Brennan,Elijah Kagan,Christoph M. Wintersteiger,Denis Ignatovich,Grant Passmore*

Main category: cs.AI

TL;DR: CodeLogician은 프로그램 행동에 대한 체계적이고 정확한 수학적 추론을 수행할 수 있는 신경 기호적 에이전트입니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)이 코드 이해 작업에서 강력한 성능을 보이고 있지만, 프로그램 행동에 대한 정밀하고 철저한 수학적 추론 능력이 부족합니다.

Method: CodeLogician은 LLM을 사용해 소프트웨어 시스템의 명시적 공식 모델을 구축하고, ImandraX와 통합되어 자동화된 추론을 가능하게 합니다.

Result: CodeLogician으로 보강된 LLM과 LLM만을 사용한 추론을 비교한 결과, 공식적인 보강이 추론 정확도에서 41-47%의 개선을 가져왔습니다.

Conclusion: 이 결과는 신경 기호적 통합이 프로그램 분석 규모를 확대하여 엄밀하고 자율적인 소프트웨어 이해를 위해 필수적임을 보여줍니다.

Abstract: Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.
  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.
  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.
  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.

</details>


### [54] [AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems](https://arxiv.org/abs/2601.11903)
*YenTing Lee,Keerthi Koneru,Zahra Moslemi,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: 이 논문은 다중 에이전트 시스템의 평가 방법으로 AEMA 프레임워크를 제안하며, 이는 안정성과 투명성을 강화하여 신뢰할 수 있는 평가를 지원한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 기반의 다중 에이전트 시스템은 신뢰할 수 있는 조정, 투명한 의사결정 및 검증 가능한 성능을 보여야 하며, 이를 평가하는 것이 주요한 도전 과제이다.

Method: AEMA(Adaptive Evaluation Multi-Agent)라는 프레임워크를 통해 다단계 평가를 계획, 실행 및 집계하는 과정을 사람의 감독 하에 진행한다.

Result: AEMA는 단일 LLM-판사에 비해 더 높은 안정성과 인간 정렬성, 책임 있는 자동화를 지원하는 추적 가능 기록을 제공한다.

Conclusion: 우리의 결과는 AEMA가 LLM 기반 다중 에이전트 시스템의 책임 있는 평가를 위한 투명하고 재현 가능한 경로를 제공함을 보여준다.

Abstract: Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.
  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight

</details>


### [55] [Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement](https://arxiv.org/abs/2601.11974)
*Xinmeng Hou,Peiliang Gong,Bohao Qu,Wuqi Wang,Qing Guo,Yang Liu*

Main category: cs.AI

TL;DR: MARS라는 새로운 프레임워크를 통해 효율적인 자기 개선이 가능해지며, 기존 시스템보다 높은 성능을 보이면서도 계산 비용을 줄일 수 있다.


<details>
  <summary>Details</summary>
Motivation: 현재의 에이전트는 정적인 인간 설계 프롬프트에 제한되어 있어 적응성이 떨어지며, 이는 복잡한 자율 행동을 구현하는 데 장애가 된다.

Method: MARS 프레임워크는 교육 심리학에서 영감을 받아 원칙 기반 반성과 절차적 반성을 통합하여, 효율적인 자기 진화를 단일 반복 주기 내에서 실현한다.

Result: 여섯 개의 벤치마크에서 MARS는 최첨단 자기 진화 시스템을 능가하며, 계산 오버헤드를 크게 줄였다.

Conclusion: MARS는 에이전트가 지속적인 온라인 피드백 없이도 체계적으로 추론 논리를 개선할 수 있도록 최적화된 지침을 제공한다.

Abstract: While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.

</details>


### [56] [A Multi-Agent System for Generating Actionable Business Advice](https://arxiv.org/abs/2601.12024)
*Kartikey Singh Bhandari,Tanish Jain,Archit Agrawal,Dhruv Kumar,Praveen Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 본 논문은 고객 리뷰를 활용하여 실행 가능한 비즈니스 조언을 생성하는 다중 에이전트 LLM 기반 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 고객 리뷰는 제품의 약점과 충족되지 않은 사용자 요구에 대한 풍부한 신호를 포함하고 있으나 기존의 분석 방법은 감정 분석이나 측면 추출과 같은 기술적 작업에 국한된다.

Method: 프레임워크는 대표 리뷰 선택을 위한 군집화, 조언 생성, 반복 평가 및 실행 가능 기반 순위를 통합한다.

Result: 실험 결과, 우리의 프레임워크는 액션 가능성, 구체성 및 비중복성에서 단일 모델 기준을 꾸준히 초과하며, 중간 규모의 모델이 대형 모델 프레임워크의 성능에 근접한다.

Conclusion: 이 디자인은 코퍼스 증류와 피드백 기반 조언 개선을 결합하여 구체적이고 실행 가능하며 실용적인 결과를 산출한다.

Abstract: Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.

</details>


### [57] [ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents](https://arxiv.org/abs/2601.12030)
*Yilun Yao,Shan Huang,Elsie Dai,Zhewen Tan,Zhenyu Duan,Shousheng Jia,Yanbing Jiang,Tong Yang*

Main category: cs.AI

TL;DR: ARC라는 새로운 프레임워크가 문맥 관리를 능동적이고 반성적인 과정으로 체계화하여 긴 정보 탐색에서 성능 저하 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 긴 정보 탐색에서 언어 모델의 성능 저하 현상이 발생하며, 이는 문맥 유지를 실패할 때 나타난다.

Method: 정신적 상태를 동적으로 다루는 ARC 프레임워크를 통해 반성 기반 모니터링 및 수정을 수행한다.

Result: ARC는 기존 수동적 문맥 압축 방법에 비해 일관되게 더 나은 성능을 보여주며, BrowseComp-ZH에서는 정확도가 최대 11% 향상되었다.

Conclusion: ARC는 문맥 관리의 접근 방식을 혁신하여 언어 모델의 긴 정보 탐색 성능 문제를 해결할 수 있는 가능성을 제시한다.

Abstract: Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.

</details>


### [58] [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](https://arxiv.org/abs/2601.12560)
*Arunkumar V,Gangadharan G. R.,Rajkumar Buyya*

Main category: cs.AI

TL;DR: 이 논문은 에이전트 AI의 아키텍처를 조사하고, 인식, 두뇌, 계획, 행동, 도구 사용 및 협력으로 에이전트를 구분하는 통합 분류법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 인공지능이 단순 텍스트 생성 모델에서 자율적인 존재처럼 행동하는 에이전트 AI로 발전하고 있다.

Method: 아키텍처를 조사하고 에이전트를 인식, 두뇌, 계획, 행동, 도구 사용 및 협력으로 나누는 통합 분류법을 제안한다.

Result: 이 분류법을 통해 선형 추론 절차에서 고유 추론 모델로의 이동과 고정 API 호출의 전환을 설명한다.

Conclusion: 자율 시스템의 신뢰성을 높이기 위한 미래 연구 방향과 함께 hallucination, 무한 루프, 프롬프트 주입과 같은 도전 과제를 강조한다.

Abstract: Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.

</details>


### [59] [TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals](https://arxiv.org/abs/2601.12141)
*Yuliia Suprun,Khen Elimelech,Lydia E. Kavraki,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: TIDE는 인공지능 및 로봇공학에서 시간적으로 확장된 목표를 위한 새로운 계획 방법으로, 임무를 더 작고 관리 가능한 하위 문제로 분해하여 전통적 방법의 한계를 극복한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 LTLf 작업 계획 접근 방식은 시간적 목표를 클래식 계획 문제로 변환하고 있으나, 한계가 존재한다.

Method: TIDE는 시간적 문제를 더 작고 관리 가능한 하위 문제로 분해하고, 비용 기반 휴리스틱을 사용하여 탐색을 안내한다.

Result: TIDE는 예비 성과를 입증하며, 시간적으로 확장된 목표에 대한 계획 방법의 포트폴리오에 귀중한 추가 요소가 된다.

Conclusion: TIDE는 실패한 계획에서 체계적으로 복구하고, 포괄성과 효율성을 보장한다.

Abstract: Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.

</details>


### [60] [Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching](https://arxiv.org/abs/2601.13186)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 본 논문은 악의적인 지시 사항의 전파를 방지하기 위한 대규모 언어 모델의 안전한 배포를 위한 방어 효과성을 조사한다.


<details>
  <summary>Details</summary>
Motivation: 프롬프트 주입은 특히 중간 출력이 악의적인 지시를 전파하거나 증폭할 수 있는 다중 에이전트 환경에서 대규모 언어 모델의 안전한 배포에 대한 주요 장애물이다.

Method: 이 논문은 의미 유사성 기반 캐싱과 다섯 번째 메트릭(관측 가능성 점수 비율)을 도입하여 총 주입 취약 점수(TIVS)를 TIVS-O로 확장하며, HOPE에서 영감을 받은 중첩 학습 아키텍처에서 방어 효과성과 투명성의 상호 작용을 분석한다.

Result: 이 시스템은 301개의 합성 생성 주입 중심 프롬프트에서 의미 유사성 기반 캐싱을 구현하는 에이전트 파이프라인과 연속 기억 시스템을 결합하고, 다섯 개의 주요 성과 지표를 사용해 종합적인 보안 분석을 수행하는 네 번째 에이전트를 활용한다.

Conclusion: 이 결과는 관측 가능성 기반 평가가 다중 에이전트 파이프라인 내에서 비선형 효과를 드러낼 수 있음을 보여주며, 메모리 보강 에이전트가 기저 모델 가중치를 수정하지 않고도 보안 강도, 실시간 성능, 운영 비용 절감 및 환경 지속 가능성을 극대화할 수 있는 경로를 제공한다.

Abstract: Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.

</details>


### [61] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

TL;DR: 이 보고서는 FutureX를 기반으로 하여 고유한 수직 분야로 확장된 FutureX-Pro를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 이 연구의 동기는 자본 집약적이고 안전이 중요한 분야에서 일반 에이전트의 신뢰성을 높이는 것이다.

Method: FutureX-Pro는 경제적, 사회적 측면에서 중요한 네 가지 수직 분야에 대해 엔트리 레벨의 예측 작업을 벤치마킹하는 LLM을 사용한다.

Result: 일반ist 추론과 고부가가치 수직 응용에 필요한 정확성 간의 성능 차이를 밝혀낸다.

Conclusion: 현재의 첨단 LLM이 산업 배치에 필요한 영역 기반을 갖추고 있음을 평가한다.

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [62] [Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding](https://arxiv.org/abs/2601.12260)
*Yihao Ding,Qiang Sun,Puzhen Wu,Sirui Li,Siwen Luo,Wei Liu*

Main category: cs.AI

TL;DR: Docs2Synth는 규제된 도메인에서 문서 이해를 개선하는 합성 감독 프레임워크로, 자동으로 문서 컬렉션을 처리하고 질의-응답 쌍을 생성하여 신뢰할 수 있는 도메인 관련 증거를 추출한다.


<details>
  <summary>Details</summary>
Motivation: 스캔된 문서들이 민감하고 변화하는 도메인 특정 지식을 포함하기 때문에 규제된 도메인에서는 문서 이해가 매우 어렵다.

Method: Docs2Synth는 원시 문서 컬렉션을 자동으로 처리하고, 에이전트 기반 시스템을 사용하여 다양한 QA 쌍을 생성 및 검증하며, 도메인 관련 증거를 추출하는 경량 비주얼 리트리버를 훈련한다.

Result: Docs2Synth는 여러 VRDU 벤치마크에서 기초적이고 도메인 일반화 능력을 크게 향상시킨다.

Conclusion: Docs2Synth는 인력이 주석을 제공할 필요 없이 도메인 특화된 지식을 업그레이드하고 결합하는 데 성공적이다.

Abstract: Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.

</details>


### [63] [TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning](https://arxiv.org/abs/2601.13545)
*Shirin Shahabi,Spencer Graham,Haruna Isah*

Main category: cs.AI

TL;DR: TruthTensor는 대형 언어 모델(LLM)을 현실 세계의 불확실성과 변화하는 조건에서의 의사결정 과정을 반영하여 평가하는 새로운 평가 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: 정적 벤치마크는 실제 상황에서의 불확실성, 분포 변화, 그리고 독립된 작업 정확도와 인간 중심 의사결정 간의 격차를 반영하지 못하기 때문에 언어 모델 및 AI 에이전트를 평가하는 것이 본질적으로 어렵다.

Method: TruthTensor는 살아있는 예측 시장에 평가를 고정시키고 확률적 점수를 결합하여 모델 행동에 대한 전체적인 관점을 제공하는 평가 프레임워크를 개발하였다.

Result: 500개 이상의 실제 시장에서 실험한 결과, 비슷한 예측 정확성을 가진 모델들이 보정, 드리프트, 리스크 민감도에서 현저히 다른 결과를 보임을 보여주었다.

Conclusion: TruthTensor는 현대의 평가 모범 사례를 구체화하여 LLM의 실제 의사결정 맥락에서 방어 가능한 평가를 생성한다.

Abstract: Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com

</details>


### [64] [ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents](https://arxiv.org/abs/2601.12294)
*Dawei Li,Yuguang Yao,Zhen Tan,Huan Liu,Ruocheng Guo*

Main category: cs.AI

TL;DR: ToolPRMBench는 도구를 사용하는 에이전트를 위한 프로세스 보상 모델(PRMs)을 평가하기 위해 설계된 대규모 벤치마크입니다.


<details>
  <summary>Details</summary>
Motivation: 도구를 사용하는 에이전트의 샘플링 및 탐색을 효과적으로 안내하여 도구 사용 성능을 향상시키기 위한 체계적이고 신뢰할 수 있는 평가 기준이 부족합니다.

Method: 여러 대표적인 도구 사용 벤치마크를 기반으로 하여 에이전트의 궤적을 단계별 테스트 사례로 변환합니다. 각 사례는 상호작용 기록, 올바른 행동, 그럴듯하지만 잘못된 대안 및 관련 도구 메타데이터를 포함합니다.

Result: ToolPRMBench에서 대규모 언어 모델, 일반 PRM 및 도구 전문 PRM에 대한 광범위한 실험을 수행한 결과, PRM의 효과성에서 명확한 차이가 나타났습니다.

Conclusion: 전문화된 PRM이 도구 사용을 위한 잠재력을 강조합니다.

Abstract: Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.

</details>


### [65] [MARO: Learning Stronger Reasoning from Social Interaction](https://arxiv.org/abs/2601.12323)
*Yin Cai,Zhouhong Gu,Juntao Zhang,Ping Chen*

Main category: cs.AI

TL;DR: 이 논문은 다중 에이전트 사회 환경에서 대형 언어 모델의 추론 능력을 향상시키기 위한 MARO라는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 인간은 일상생활에서 사고와 판단이 필요한 무수한 상황에 직면하지만, 기존의 대형 언어 모델은 상호작용, 협상 및 경쟁과 같은 실제 시나리오에서의 경험이 부족하다.

Method: MARO는 상호작용 과정 중 최종 성공 또는 실패 결과를 구체적인 행동으로 분해하여 희소한 학습 신호 문제를 해결하고, 서로 다른 역할의 훈련 샘플 가중치를 균형 잡아 처리하며, 각 행동의 효용을 직접 평가하여 환경 불안정성 문제를 해결한다.

Result: 실험 결과, MARO는 사회적 추론 능력에서 상당한 향상을 달성했으며, 사회적 시뮬레이션 학습을 통해 획득한 능력이 수학적 추론 및 지시 따르기와 같은 다른 작업으로 효과적으로 이전될 수 있음을 보여준다.

Conclusion: 이 연구는 다중 에이전트 사회 학습이 대형 언어 모델의 일반적인 추론 능력을 향상시키는 데 큰 잠재력을 가지고 있음을 드러낸다.

Abstract: Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.

</details>


### [66] [PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling](https://arxiv.org/abs/2601.12392)
*Zhentao Xia,Yongqi Fan,Yuxiang Chu,Yichao Yin,Liangliang Chen,Tong Ruan,Weiyan Zhang*

Main category: cs.AI

TL;DR: 이 연구에서는 상담 세션에서 감정 변화를 추적하고 안전 위험을 분석하는 PsychēChat을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 대형 언어 모델은 상담 세션 간의 감정 변화를 명시적으로 모델링하지 않으며, 이는 고전 심리학의 핵심 포커스이다.

Method: 상호 작용 롤플레잉을 활용하여 상담자와 탐색자 간의 대화를 합성하고, 감정 관리 모듈과 위험 제어 모듈을 포함한다.

Result: PsychēChat은 기존 방법에 비해 감정 통찰력과 안전 제어에서 우수한 성능을 보인다.

Conclusion: 풍부한 실험을 통해 PsychēChat의 효율성과 성능이 뚜렷이 향상됨을 입증하였다.

Abstract: Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose PsychēChat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that PsychēChat outperforms existing methods for emotional insight and safety control.

</details>


### [67] [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538)
*Tianxin Wei,Ting-Wei Li,Zhining Liu,Xuying Ning,Ze Yang,Jiaru Zou,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Dongqi Fu,Zihao Li,Mengting Ai,Duo Zhou,Wenxuan Bao,Yunzhe Li,Gaotang Li,Cheng Qian,Yu Wang,Xiangru Tang,Yin Xiao,Liri Fang,Hui Liu,Xianfeng Tang,Yuji Zhang,Chi Wang,Jiaxuan You,Heng Ji,Hanghang Tong,Jingrui He*

Main category: cs.AI

TL;DR: 이 논문은 에이전트적 추론의 세 가지 차원에 따라 대규모 언어 모델(LLMs)의 추론 능력을 탐색하고, 이를 실세계 응용분야 및 벤치마크에 적용하여 에이전트적 추론 방법을 통합한 로드맵을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델이 폐쇄적인 세계에서는 강력한 추론 능력을 보이지만, 개방적이고 동적인 환경에서는 어려움을 겪고 있습니다.

Method: 환경의 동역학을 세 가지 층으로 구성하여 에이전트적 추론을 조직하며, 각 층에서는 개별 에이전트 능력, 자기 발전적 추론, 집단 다중 에이전트 추론을 다룹니다.

Result: 에이전트적 추론 방법들을 통합하여 사고와 행동을 연결하는 로드맵을 제시하고, 다양한 응용 분야에서 이를 검토합니다.

Conclusion: 개인화, 장기 상호작용, 세계 모델링, 확장 가능한 다중 에이전트 훈련 등과 같은 열린 도전 과제를 포함하여 향후 방향을 제시합니다.

Abstract: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.

</details>


### [68] [Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery](https://arxiv.org/abs/2601.12542)
*Lukas Weidener,Marko Brkić,Mihailo Jovanović,Ritvik Singh,Chiara Baccin,Emre Ulgac,Alex Dobrin,Aakaash Meduri*

Main category: cs.AI

TL;DR: 이 논문은 실시간 연구자 안내를 가능하게 하는 다중 에이전트 시스템 Deep Research를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 인공지능 시스템은 배치 처리 방식으로 작동하여 실시간 연구 지원에 한계가 있습니다.

Method: Deep Research는 기획, 데이터 분석, 문헌 검색, 신기성 탐지를 위한 전문 에이전트를 포함하고 있으며, 지속적인 세계 상태를 통해 연구 사이클 간의 맥락을 유지합니다.

Result: BixBench 생물학 공학 벤치마크에서 48.8%의 정확도와 64.5%의 다지선다 평가 성과를 기록하여 기존 기준선보다 14에서 26% 포인트 향상되었습니다.

Conclusion: AI-assisted 과학 워크플로우의 실용적인 배치 고려사항을 제공하는 구조적 제약 분석을 수행했습니다.

Abstract: Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.

</details>


### [69] [How Clinicians Think and What AI Can Learn From It](https://arxiv.org/abs/2601.12547)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 임상 AI 시스템은 주로 예측 엔진으로 작동하지만, 진정한 임상 추론은 불확실성 하의 시간 제약 및 순차적 제어 문제이다. 이 논문은 임상 추론의 기본적인 계산적 기초가 서수적 비보상 결정-making에 기반하고 있으며, 의사들이 빠르고 요약된 휴리스틱을 자주 사용한다고 주장한다. 또한, 그러한 알고리즘은 단순한 제한된 합리성을 초월하여 의학에서 epistemically 선호될 수 있는 이유를 제시하며, AI가 의사와 aligned 되어 결정을 지원하는 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현대의 많은 임상 AI 시스템이 예측 엔진으로 작동하고 있으나, 실제 임상 추론 과정은 시간 제약이 있으며 불확실성 하에서 순차적으로 이루어지는 제어 문제이다.

Method: 임상 의사들이 빠르고 간단한 방법인 lexicographic 휴리스틱(예: 빠르고 간단한 트리)을 사용하여 정보를 수집하고 되돌릴 수 없는 행동을 병행하는 방식에 대한 규범적 근거를 제공한다.

Result: 결정 마진에서 '거칠음'이 압도해버릴 때는 예상 효용 최적화가 무너지기 쉬운 반면, 강력한 서수적 규칙(ε-우위, 최대 최소)이 결정을 안정화시켜 그 과정에서 AI가 주로 결정을 유지하기 위한 선택적 복잡성으로 사용될 수 있음을 보여준다.

Conclusion: AI는 의사들에게 정보를 기반으로 하는 결정을 지원하며, 로버스트 서수적 규칙을 통해 행동 선택을 할 때 주로 도움이 된다. 또한, 결정이 취약할 때 정보가 유의미한 영향을 미칠 수 있도록 AI의 배치를 제안한다.

Abstract: Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\to$ perception $\to$ inference $\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($ε$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.

</details>


### [70] [MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents](https://arxiv.org/abs/2601.12661)
*Chuhan Qiao,Jianghua Huang,Daxing Zhao,Ziding Liu,Yanjun Shen,Bing Cheng,Wei Lin,Kai Wu*

Main category: cs.AI

TL;DR: 의료 상담 에이전트의 평가가 현실 세계의 실습에 필수적인 프로세스 무결성과 임상 안전성을 간과하고 있음을 지적하며, MedConsultBench라는 포괄적인 프레임워크를 제안하여 온라인 상담 사이클을 전체적으로 평가한다.


<details>
  <summary>Details</summary>
Motivation: 현재 의료 상담 에이전트의 평가는 결과 지향적 작업을 우선시하여, 실제 치료에서 필수적인 프로세스 무결성과 임상 안전성을 자주 간과한다.

Method: MedConsultBench는 역사 수집, 진단, 치료 계획 및 후속 Q&A를 포함한 전체 임상 워크플로우를 다루어 온라인 상담 사이클을 평가할 수 있도록 설계된 포괄적인 프레임워크이다. 우리의 방법론은 임상 정보 수집을 하위 턴 수준에서 추적하기 위해 원자 정보 단위(AIU)를 도입하고, 22개의 세부 지표를 통해 주요 사실이 어떻게 유도되는지를 정밀하게 모니터링할 수 있도록 한다.

Result: 진단 정확도가 높더라도 정보 수집 효율성과 약물 안전성에 중대한 결함이 숨겨져 있음을 보여주는 19개의 대형 언어 모델에 대한 체계적인 평가 결과가 나타났다.

Conclusion: 이러한 결과는 이론적인 의학 지식과 임상 실습 능력 간의 중대한 격차를 강조하며, MedConsultBench가 실제 임상 치료의 미세한 요구 사항과 의학 AI를 일치시키기 위한 철저한 기초를 제공함을 입증한다.

Abstract: Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.

</details>


### [71] [Teaching Large Reasoning Models Effective Reflection](https://arxiv.org/abs/2601.12720)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Qi Zhu,Fei Mi,Ganqu Cui,Yasheng Wang,Lifeng Shang*

Main category: cs.AI

TL;DR: 대규모 추론 모델(LRM)은 복잡한 추론 작업에서 뛰어난 성능을 보여주지만, 모든 반사가 유익한 것은 아니다. 이 논문에서는 LRM의 피상적 반사의 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 피상적 반사는 계산 오버헤드를 발생시키며 본래 답변에 비해 개선 효과가 적다.

Method: 자체 생성된 비판을 사용하여 모델의 반사 추론 능력을 향상시키는 자기 비판 미세 조정(SCFT) 훈련 프레임워크를 제안한다. SCFT는 모델이 자신의 출력을 비판하도록 유도하고, 거부 샘플링을 통해 고품질 비판을 필터링한 후 비평 기반 목표를 사용하여 모델을 미세 조정한다.

Result: SCFT와 RLERR은 AIME2024 및 AIME2025라는 두 가지 어려운 벤치마크에서 추론 정확도와 반사 품질을 크게 향상시켰으며, 최신 기법을 능가하는 성능을 보였다.

Conclusion: 모든 데이터와 코드는 https://github.com/wanghanbinpanda/SCFT에서 확인할 수 있다.

Abstract: Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.

</details>


### [72] [MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction](https://arxiv.org/abs/2601.12822)
*Wenqi Zhang,Yulin Shen,Changyue Jiang,Jiarun Dai,Geng Hong,Xudong Pan*

Main category: cs.AI

TL;DR: MirrorGuard는 CUA의 보안을 개선하기 위한 시뮬레이션 기반 훈련을 사용하는 방어 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: CUA의 자율적 상호작용은 다양한 보안 위험을 초래한다.

Method: MirrorGuard는 텍스트 기반 시뮬레이션 환경에서 고위험 GUI 상호작용 경로를 생성하고 불안전한 추론 패턴을 포착한다.

Result: MirrorGuard는 다양한 벤치마크와 아키텍처에서 보안 위험을 상당히 완화하며, ByteDance UI-TARS 시스템에서는 안전하지 않은 비율을 66.5%에서 13.0%로 줄였다.

Conclusion: 시뮬레이션 기반 방어가 에이전트의 기본 유용성을 유지하면서 강력한 실세계 보호를 제공할 수 있음을 증명했다.

Abstract: Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.

</details>


### [73] [SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning](https://arxiv.org/abs/2601.12842)
*Qitong Fang,Haotian Li,Xu Wang*

Main category: cs.AI

TL;DR: 자동화된 에이전트 워크플로우는 대형 언어 모델의 문제 해결 능력을 향상시킬 수 있지만, 기존의 탐색 전략은 무작위 탐색에 의존하며 실현 가능한 경로를 자주 벗어난다. 본 논문에서 SCULPT라는 새로운 접근법을 소개하여 도메인 인식 점수를 활용한 탐색을 통해 이 문제를 해결하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 에이전트 워크플로우의 성능을 개선하고자 하며, 이는 대형 언어 모델의 탐색 전략에 대한 한계를 극복하는 데 기여한다.

Method: SCULPT는 Monte Carlo Tree Search (MCTS)에 도메인 인식 점수를 통합하여 선택, 확장, 시뮬레이션, 역전파 과정에서 제약 기반 접근법을 채택한다.

Result: SCULPT는 여러 데이터셋에서 안정적인 개선을 보였으며, 추가적으로 GPT-5.2와의 결과를 통해 실행자의 이식성과 최전선 추론 모델에서의 성능을 평가했다.

Conclusion: 도메인 인식 제약은 효율성과 추론의 안정성을 유지하면서 정확성을 향상시킬 수 있다.

Abstract: Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.

</details>


### [74] [Human Emotion Verification by Action Languages via Answer Set Programming](https://arxiv.org/abs/2601.12912)
*Andreas Brännström,Juan Carlos Nieves*

Main category: cs.AI

TL;DR: 이 논문에서는 사람의 정신 상태가 관찰 가능한 행동의 순서에 따라 어떻게 변화하는지를 표현하기 위한 액션 언어 C-MT(마인드 트랜지션 언어)를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 제어된 에이전트 행동의 필요성과 행동의 원치 않는 정신적 부작용을 제한할 필요성에 대응하기 위해.

Method: 정신적 상태의 동적 변화를 모형화 할 수 있는 새로운 인과 규칙과 정신 상태 동역학에 특화된 표현을 포함하여 언어를 확장했습니다.

Result: 정신적 변화의 원칙이 전이 제약 및 불변성의 특성으로 번역되며, 이는 전이 시스템을 활용하여 평가됩니다.

Conclusion: 이 프레임워크는 다양한 심리학적 원칙을 따르는 궤적을 분석하여 변화의 다양한 동역학을 비교할 수 있도록 지원합니다.

Abstract: In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [75] [MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux](https://arxiv.org/abs/2601.13060)
*Zecheng Li,Zhihui Cao,Wenke Huang,Yudong Zhang,Keying Qi,Rui Wang,Zeyu Zheng,Jian Zhao,Hao Zhu,Hengxin Wu,Yuran Wang,Guitao Fan,Guokun Wu,Yicong Liu,Zhilin Gao,Haikun Xu,He Yang,Minqi Xiang,Xingyu Liu,Zuojian Wang*

Main category: cs.AI

TL;DR: MagicGUI-RMS는 자율 GUI 에이전트를 위한 다중 에이전트 보상 모델 시스템으로, 적응형 경로 평가, 수정 피드백 및 자기 진화 학습 기능을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 경로 평가 및 대규모 고품질 훈련 데이터 생성이 필요하다.

Method: MagicGUI-RMS는 도메인 특화 보상 모델과 범용 보상 모델을 통합하여 세밀한 행동 평가와 강력한 일반화를 지원한다.

Result: MagicGUI-RMS는 작업 정확도 및 행동 강인성에서 상당한 향상을 보여준다.

Conclusion: MagicGUI-RMS는 보상 기반 적응에 의해 구동되는 자기 개선 GUI 에이전트를 구축하기 위한 원칙적이고 효과적인 기반을 제공한다.

Abstract: Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.

</details>


### [76] [Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues](https://arxiv.org/abs/2601.13206)
*Neil K. R. Sehgal,Sharath Chandra Guntuku,Lyle Ungar*

Main category: cs.AI

TL;DR: 대규모 언어 모델(LLM)은 실시간 기한 이하에서의 시간 인식 부족으로 인해 시간 민감한 설정에서 성능이 저하됨을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 이 논문은 실제 의사소통에서의 연속적 시간 제약이 LLM의 행동 조정에 어떻게 영향을 미치는지를 조사하고자 한다.

Method: 엄격한 기한 아래에서 쌍을 이룬 에이전트 간의 시뮬레이션 협상을 사용한다.

Result: 시간 인식 조건에서 거래 성사율이 32%로, 통제 조건의 4%에 비해 상당히 높았다.

Conclusion: LLM은 전략적 추론 과제가 아닌 시간 추적 실패의 결과로 성능을 발휘하지 못하고 있으며, 이는 LLM 사용에 많은 제약을 가져올 것이다.

Abstract: Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\% vs. 4\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\geq$95\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.

</details>


### [77] [RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements](https://arxiv.org/abs/2601.13233)
*Bolin Chen,Dex Doksoo Lee,Wei "Wayne'' Chen,Wei Chen*

Main category: cs.AI

TL;DR: 본 연구에서는 비선형 및 상태 의존 반응을 위한 메타물질 설계를 위한 RAndom-forest 기반 생성 접근법(RAG)을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 고급 기능성을 위한 메타물질 설계에는 비선형 및 조건 의존 반응에 대한 역설계가 포함되며, 이는 연속 함수로 설명됩니다.

Method: RAG는 랜덤 포레스트의 소량 데이터 호환성을 활용하여 고차원 기능적 반응의 데이터 효율적인 예측을 가능하게 합니다.

Result: RAG는 500 및 1057 샘플을 사용하여 각각 미리 정해진 부분 패스 대역/정지 대역을 갖는 음향 메타물질 및 목표 스냅스루 스반응을 갖는 기계적 메타물질에 대해 입증되었습니다.

Conclusion: 우리의 프레임워크는 기능적 반응, 비싼 시뮬레이션 및 복잡한 설계 요구사항과 관련된 역설계를 위한 신뢰할 수 있는 경량 경로를 제공합니다.

Abstract: Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.

</details>


### [78] [Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops](https://arxiv.org/abs/2601.13268)
*Zainab Ghafoor,Md Shafiqul Islam,Koushik Howlader,Md Rasel Khondokar,Tanusree Bhattacharjee,Sayantan Chakraborty,Adrito Roy,Ushashi Bhattacharjee,Tirtho Roy*

Main category: cs.AI

TL;DR: 의료 분야에서 대형 언어 모델의 안전성과 윤리를 보장하기 위한 다중 에이전트 정제 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 임상적 배포를 위한 윤리적 무결성과 안전성 준수 보장이 주요 장애물이다.

Method: DeepSeek R1과 Med-PaLM이라는 두 생성 모델과 AMA의 의료 윤리 원칙 및 다섯 단계 안전 위험 평가 프로토콜을 사용하는 두 평가 에이전트로 구성된 다중 에이전트 정제 프레임워크를 도입한다.

Result: DeepSeek R1은 더 빠른 수렴을 달성하고(M = 2.34 vs. 2.67 반복), Med-PaLM은 개인 정보가 중요한 시나리오를 더 우수하게 처리한다.

Conclusion: 이번 연구는 의료 AI 안전을 관리하기 위한 확장 가능하고 규제자와 일치하며 비용 효율적인 패러다임을 제시한다.

Abstract: Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.

</details>


### [79] [A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge](https://arxiv.org/abs/2601.13383)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: AgentForge는 LLM 기반 자율 에이전트를 구축하기 위한 경량 오픈소스 파이썬 프레임워크로, 모듈화된 아키텍처를 통해 빠른 프로토타입 제작과 배포를 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 에이전트 프레임워크는 경직성, 공급자 종속성 및 복잡성 문제로 인해 빠른 개발과 배포에 어려움을 겪고 있습니다.

Method: AgentForge는 세 가지 혁신적 기능을 도입합니다: 1) 공식적으로 정의된 입력-출력 계약을 가진 세밀한 작업 분해를 위한 조합 가능 기술 추상화, 2) 클라우드 API와 로컬 추론 엔진 간의 원활한 전환을 지원하는 통합 LLM 백엔드 인터페이스, 3) 에이전트 논리와 구현 세부 정보를 분리하는 선언적 YAML 기반 구성 시스템.

Result: AgentForge는 4개의 벤치마크 시나리오에서 실험적으로 평가되어 LangChain 대비 작업 완료율을 높이면서 개발 시간을 62%, 직접 API 통합 대비 78% 단축했습니다. 지연 측정 결과, 100ms 미만의 오케스트레이션 오버헤드를 확인했습니다.

Conclusion: AgentForge는 자율 에이전트를 구축하고 평가하며 배포하기 위한 생산 준비가 완료된 기초를 제공하여 연구자와 실무자가 유연성과 성능을 희생하지 않고 작업할 수 있도록 합니다.

Abstract: The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.

</details>


### [80] [Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models](https://arxiv.org/abs/2601.13443)
*Héctor Manuel Manzanilla-Granados,Zaira Navarrete-Cazales,Miriam Pescador-Rojas,Tonahtiu Ramírez-Romero*

Main category: cs.AI

TL;DR: 대규모 언어 모델의 사용이 증가하면서 AI 보조 추론의 새로운 형태가 가능해졌지만, 현재의 사용 방법은 인지적으로 비구조적이다. 본 논문에서는 인지적 기능을 명시적으로 분리하고 조정하여 AI 보조 추론을 구조화하는 일반 원칙인 명시적 인지 할당을 소개한다. 이를 통해 여러 단계의 추론 과정을 조직하는 인프라인 인지 유니버설 에이전트(CUA)를 제안하며, 이 시스템은 농업 분야에서의 평가를 통해 기존 LLM 추론보다 더 높은 일관성과 구조적 수렴을 보인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 사용이 증가함에 따라 AI 보조 추론의 새로운 가능성이 열리지만, 현재의 사용 방법은 인지적으로 비구조적이라는 문제를 해결하고자 한다.

Method: 명시적 인지 할당이라는 원칙을 통해 인지 유니버설 에이전트(CUA)라는 아키텍처를 제안하며, 이를 통해 추론을 탐색, 프레이밍, 인지적 고정, 도구적 및 방법론적 매핑, 해석적 합성의 단계로 나눈다.

Result: 농업 분야의 여러 프롬프트를 통해 CUA 추론이 더 빠르고 구조적으로 지배되는 인지적 수렴을 보이며, 높은 인지적 정렬과 조사가 이루어지는 도구적 환경을 체계적으로 노출시킨다.

Conclusion: CUA가 기존 LLM 추론에 비해 일관성 있는 결과를 제공하며, 인지적 구조를 명시적으로 드러내는 데 성공한다는 점에서 특정 분야에서의 응용 가능성을 제시한다.

Abstract: The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.
  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.
  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.

</details>


### [81] [Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement](https://arxiv.org/abs/2601.13481)
*Jian Zhang,Zhangqi Wang,Zhiyuan Wang,Weiping Fu,Yu He,Haiping Zhu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: APOLO는 감정 진단의 정확성과 강인성을 향상시키기 위해 자동화된 프롬프트 최적화 프레임워크로, 감정의 동시 발생 문제와 임상적으로 관련된 단서 탐색의 비효율성을 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 정신 건강 관리에서 감정을 정확히 인식하는 것은 임상 분류, 위험 평가 및 시기 적절한 개입에 필수적입니다.

Method: APOLO는 프롬프트 공간을 체계적으로 탐색하여 진단 효율성 및 강인성을 개선하는 프레임워크로, 부분 관찰 가능 마르코프 결정 과정으로 프롬프트 세분화 과정을 공식화하고, 기획자, 교사, 비평가, 학생, 목표 역할을 포함하는 다중 에이전트 협력 메커니즘을 채택합니다.

Result: 실험 결과 APOLO는 특정 도메인 및 계층화된 벤치마크에서 진단 정확성 및 강인성을 지속적으로 개선했습니다.

Conclusion: APOLO는 정신 건강 관리에서 신뢰할 수 있는 LLM 응용을 위한 확장 가능하고 일반화 가능한 패러다임을 보여줍니다.

Abstract: Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.

</details>


### [82] [AgenticRed: Optimizing Agentic Systems for Automated Red-teaming](https://arxiv.org/abs/2601.13518)
*Jiayi Yuan,Jonathan Nöther,Natasha Jaques,Goran Radanović*

Main category: cs.AI

TL;DR: 자동화된 레드 팀 방법이 모델 취약점을 체계적으로 노출하는 데 유망하지만, 기존 접근 방식은 인간이 지정한 워크플로우에 의존하고 있습니다. 이에 따라 AgenticRed라는 자동화된 파이프라인을 도입하여 LLM의 컨텍스트 학습을 활용해 인간 개입 없이 레드 팀 시스템을 반복적으로 설계하고 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 레드 팀 방법의 필요성과 기존 방법들이 인간의 편견에 의존하며 디자인 공간 탐색이 비효율적이라는 문제점을 해결하고자 함.

Method: AgenticRed는 레드 팀을 시스템 설계 문제로 다루며, 진화 선택(evolutionary selection)을 통해 에이전틱 시스템을 발전시키는 새로운 절차를 개발하고 이를 자동 레드 팀 문제에 적용함.

Result: AgenticRed가 디자인한 레드 팀 시스템은 기존의 최고 성능 방법들을 지속적으로 능가하며, Llama-2-7B에서 96% 공격 성공률(ASR)을 달성하고 Llama-3-8B에서는 98%를 기록함.

Conclusion: 이 연구는 빠르게 발전하는 모델에 대응할 수 있는 강력한 AI 안전 평가의 패러다임으로 자동화된 시스템 설계를 강조함.

Abstract: While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.

</details>


### [83] [ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution](https://arxiv.org/abs/2601.13546)
*Hui Sun,Chang Xu,Haonan Xie,Hao Li,Yuhao Huang,Chuheng Zhang,Ming Jin,Xiaoguang Liu,Gang Wang,Jiang Bian*

Main category: cs.AI

TL;DR: LLM 기반 이상 탐지 방법이 시계열 데이터의 이상 행동 이해를 향상시키는 데 기여하며, 이를 위해 다중 에이전트 기반 알고리즘, 새로운 데이터셋 및 챗봇을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 이상 탐지 방법은 부적절한 추론 능력과 다중 턴 대화 능력 부족, 그리고 좁은 일반화 문제에 직면해 있다.

Method: 다중 에이전트 기반 시계열 진화 알고리즘 TSEvol을 제안하고, 이를 기반으로 한 이상 탐지 추론 및 다중 턴 대화 데이터셋 TSEData-20K를 도입하며, 여러 챗봇 모델을 개발하고 TS Kahneman-Tversky 최적화(TKTO)를 적용하여 일반화 능력을 향상시킨다.

Result: 세 가지 ChatAD 모델이 각각 34.50%의 정확도 향상, 34.71%의 F1 향상, 37.42%의 거짓 긍정률 감소를 기록하였다.

Conclusion: KTKO를 통해 최적화된 ChatAD는 분류, 예측 및 대체에서 경쟁력 있는 추론 및 교차 작업 일반화 성능을 보여준다.

Abstract: LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.

</details>


### [84] [Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis](https://arxiv.org/abs/2601.13558)
*Mehrab Beikzadeh,Chenglin Hong,Cory J Cascalheira,Callisto Boka,Majid Sarrafzadeh,Ian W Holloway*

Main category: cs.AI

TL;DR: MSM를 대상으로 한 연구에서, 소셜 미디어와 데이팅 앱의 텍스트 데이터를 사용하여 성적 위험 행동과 음주, PrEP 사용을 예측할 수 있는지 평가하였다.


<details>
  <summary>Details</summary>
Motivation: MSM은 이성애 남성에 비해 성병과 유해 음주의 위험이 높으므로, 위험과 보호 행동을 자동으로 식별할 수 있는 텍스트 데이터를 활용한 공공 건강 개입의 개인화 가능성을 탐색하기 위함이다.

Method: 참여자의 동의 하에, 우리는 ChatGPT 임베딩, BERT 임베딩, LIWC 및 사전 기반 위험 용어 접근법에서 파생된 특징을 사용하여 머신러닝 모델을 학습시켰다.

Result: 모델은 월간 폭음 음주와 5명 이상의 성 파트너를 갖는 것을 예측하는데 F1 점수 0.78로 강력한 성능을 보였고, PrEP 사용과 과음 예측에서 각각 F1 점수 0.64와 0.63로 중간 성능을 보였다.

Conclusion: 소셜 미디어 및 데이팅 앱 텍스트 데이터가 위험 및 보호 행동에 대한 귀중한 통찰력을 제공할 수 있음을 보여주며, MSM을 위한 대규모 언어 모델 기반 방법의 잠재력을 강조한다.

Abstract: Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.

</details>


### [85] [AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent](https://arxiv.org/abs/2601.13559)
*Sun Hui,Ding Yanfeng,Huidong Ma,Chang Xu,Keyan Jin,Lizheng Zu,Cheng Zhong,xiaoguang Liu,Gang Wang,Wentong Cai*

Main category: cs.AI

TL;DR: AgentGC는 진화적 에이전트 기반의 게놈 데이터 압축기로, 사용자 친화적인 인터페이스를 제공하고 알고리즘-데이터셋-시스템 간의 공동 최적화를 고려하며, 다양한 시나리오를 지원하는 모드를 설계하였다.


<details>
  <summary>Details</summary>
Motivation: 현재의 학습 기반 방법은 발전이 없고, 저수준 압축 모델링, 제한된 적응성, 사용자 친화적이지 않은 인터페이스와 같은 문제를 겪고 있다.

Method: AgentGC는 3개의 레이어로 구성되며, 특정 역할을 가진 다중 에이전트를 사용한다: 리더는 사용자 인터페이스를 제공하고, 인지 레이어는 LLM을 통합하며, 워커는 압축 및 복원을 수행한다.

Result: 14개의 기준선 모델을 9개의 데이터셋에서 비교한 결과 평균 압축 비율은 16.66%, 16.11%, 16.33%로 향상되었고, 처리량은 각각 4.73배, 9.23배, 9.15배 증가하였다.

Conclusion: AgentGC는 다양한 시나리오를 지원하는 3가지 모드를 통해 압축 성능과 처리량을 크게 향상시킬 수 있음을 보여준다.

Abstract: Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.

</details>


### [86] [Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification](https://arxiv.org/abs/2601.13589)
*HyeYoung Lee*

Main category: cs.AI

TL;DR: 이 논문은 오디오 기반의 감정 신호를 바탕으로 실시간 반응 지향 미디어 콘텐츠를 생성하는 다중 에이전트 인공지능 시스템을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 본 연구는 전통적인 감정 인식 연구가 주로 분류 정확도에 중점을 두는 것과 달리, 추론된 감정 상태를 안전하고 연령 적합하며 제어 가능한 반응 콘텐츠로 변환하는 데 초점을 맞췄습니다.

Method: 제안된 시스템은 감정 인식 에이전트, 반응 정책 결정 에이전트, 콘텐츠 매개변수 생성 에이전트, 안전성 검증 에이전트의 네 가지 협력 에이전트로 구성되어 있습니다.

Result: 실험 결과, 시스템은 73.2%의 감정 인식 정확도, 89.4%의 반응 모드 일관성, 100%의 안전 준수를 달성하였으며, 100ms 미만의 추론 지연 시간을 유지하였습니다.

Conclusion: 모듈형 아키텍처는 해석 가능성과 확장성을 제공하여 아동 관련 미디어, 치료 응용 프로그램 및 감정적으로 반응하는 스마트 장치에 적용될 수 있습니다.

Abstract: This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.

</details>


### [87] [DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems](https://arxiv.org/abs/2601.13591)
*Maojun Sun,Yifei Xie,Yue Wu,Ruijian Han,Binyan Jiang,Defeng Sun,Yancheng Yuan,Jian Huang*

Main category: cs.AI

TL;DR: 이 논문에서는 DSAEval이라는 벤치마크를 도입하여, 다양한 데이터 세트에 기반한 실제 데이터 과학 문제를 평가하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 데이터 과학 문제의 개방적인 특성으로 인해 평가가 어렵고, 이에 대한 해결책이 필요합니다.

Method: DSAEval은 641개의 실제 데이터 과학 문제와 285개의 다양한 데이터 세트로 구성되어 있으며, 다중 모드 환경 인식, 다중 쿼리 상호작용, 다차원 평가의 세 가지 특징을 포함합니다.

Result: Claude-Sonnet-4.5가 가장 우수한 성능을 보였고, GPT-5.2는 가장 효율적이며, MiMo-V2-Flash는 비용 효율성이 가장 높았습니다.

Conclusion: 현재의 데이터 과학 에이전트는 구조화된 데이터에서 잘 작동하지만, 비구조화된 도메인에서는 여전히 상당한 도전 과제가 남아 있습니다.

Abstract: Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.

</details>


### [88] [Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games](https://arxiv.org/abs/2601.13709)
*Christopher Kao,Vanshika Vats,James Davis*

Main category: cs.AI

TL;DR: LLM 에이전트의 사회적 맥락에서의 속임수 능력을 연구한 논문.


<details>
  <summary>Details</summary>
Motivation: LLM의 안전성에 대한 우려가 커지고 있으며, 자연어를 활용한 속임수에 대한 연구가 필요하다.

Method: 비동기 다중 에이전트 프레임워크를 사용하여 35개의 Mafia 게임을 시뮬레이션하고, 게임 기록을 분석하기 위해 GPT-4-Turbo를 활용하여 Mafia 탐지기를 만들었다.

Result: Mafia 탐지기의 속임수 예측 정확도가 LLM 게임에서 인간 게임보다 낮았다.

Conclusion: LLM이 더 효과적으로 속임수를 사용할 수 있음을 나타내며, LLM의 속임수에 대한 위험을 강조한다.

Abstract: Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.

</details>


### [89] [LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health](https://arxiv.org/abs/2601.13880)
*Ye Tian,Zihao Wang,Onat Gungor,Xiaoran Fan,Tajana Rosing*

Main category: cs.AI

TL;DR: 이 논문에서는 LLM 기반 건강 보조 도구의 평가를 위한 LifeAgentBench라는 대규모 QA 벤치마크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 개인화된 디지털 건강 지원은 이질적인 생체 신호에 대한 장기적이고 교차 차원의 추론이 필요하지만, 현재 LLM의 능력은 체계적인 벤치마크 부족으로 인해 불명확합니다.

Method: LifeAgentBench는 기초 검색부터 복잡한 추론까지 22,573개의 질문으로 구성된 벤치마크로, 확장 가능한 벤치마크 구축 파이프라인과 표준화된 평가 프로토콜을 제공합니다.

Result: 11개의 주요 LLM을 LifeAgentBench에서 체계적으로 평가하여 장기 집계 및 교차 차원 추론의 주요 병목 현상을 식별했습니다.

Conclusion: 이 결과를 바탕으로 LifeAgent라는 다단계 증거 검색 및 결정적 집계를 통합한 강력한 기준 에이전트를 제안합니다.

Abstract: Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.

</details>


### [90] [Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval](https://arxiv.org/abs/2601.13969)
*Joaquín Polonuer,Lucas Vittor,Iñaki Arango,Ayush Noori,David A. Clifton,Luciano Del Corro,Marinka Zitnik*

Main category: cs.AI

TL;DR: ARK는 지식 그래프에서 쿼리를 효율적으로 검색하기 위한 에이전트 기반의 리트리버로, 언어 모델과의 상호작용을 통해 Breadth-Depth 트레이드오프를 조절한다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델의 쿼리에 대해 지식 그래프에서 증거를 검색하는 데 있어, 그래프 전역의 탐색과 관계 링크를 따라가는 다중 홉 이동 간의 균형을 맞출 필요성이 있다.

Method: ARK는 글로벌 어휘 검색과 일회성 이웃 탐색을 결합하여 다중 홉 탐색을 생성하는 두 가지 작동 도구 세트를 사용하는 KG 리트리버이다.

Result: STaRK에서 ARK는 평균 Hit@1이 59.1%이고 평균 MRR이 67.4에 도달하며, 검색 기반 및 에이전트 트레이닝 프리 방법들에 비해 평균 Hit@1을 최대 31.4% 및 평균 MRR을 최대 28.0% 개선하였다.

Conclusion: ARK의 도구 사용 경로를 대규모 교사로부터 레이블 없는 모방을 통해 8B 모델로 증류하였고, AMAZON, MAG, PRIME 데이터 세트에서 각각 기본 8B 모델에 비해 Hit@1 점수를 +7.0, +26.6, +13.5만큼 개선하면서 교사의 Hit@1 비율의 최대 98.5%를 유지하였다.

Abstract: Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.

</details>


### [91] [Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics](https://arxiv.org/abs/2601.14027)
*Junqi Liu,Zihao Zhou,Zekai Zhu,Marco Dos Santos,Weikun He,Jiawei Liu,Ran Wang,Yunzhou Xie,Junqiao Zhao,Qiufeng Wang,Lihong Zhi,Jia Li,Wenda Li*

Main category: cs.AI

TL;DR: 일반 코딩 에이전트를 수학적 추론기로 활용하는 새로운 패러다임을 제안하며, 이를 통해 여러 이론 정리 도출과 사용자 정의 도구 사용의 유연성을 확보했다.


<details>
  <summary>Details</summary>
Motivation: 일반 코딩 에이전트는 다양한 추론 작업을 위한 자연스러운 인터페이스를 제공하며, 성능을 향상시킬 수 있는 잠재력이 있다.

Method: Numina-Lean-Agent를 도입하여 Claude Code와 Numina-Lean-MCP를 결합하여 Lean과의 자율 상호작용 및 관련 정리 검색을 가능하게 한다.

Result: Numina-Lean-Agent는 Putnam 2025의 모든 문제를 해결하며, 최고의 비공개 시스템과 동등한 성능을 보여준다.

Conclusion: Numina-Lean-Agent를 통해 더 넓은 상황에서 일반성을 입증하였으며, 모든 솔루션을 GitHub에 공개하였다.

Abstract: Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.

</details>


### [92] [Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems](https://arxiv.org/abs/2601.14096)
*Benedikt Hartl,Léo Pio-Lopez,Chris Fields,Michael Levin*

Main category: cs.AI

TL;DR: 다양한 지능의 새로운 분야는 서로 다른 출처와 구성을 가진 문제 해결 에이전트의 통합된 관점을 추구한다.


<details>
  <summary>Details</summary>
Motivation: 자연 및 합성 시스템에서 인지를 두 가지 중요한 불변체 간의 상호작용을 통해 이해할 수 있는 가능성을 제시하고 해결책의 원리를 발견하고자 한다.

Method: 생물학적 집단과 현대 인공지능 시스템에서 임베딩 공간의 재매핑과 탐색 간의 관계를 연구한다.

Result: 자연 및 인공 시스템의 인지는 임베딩 공간의 재매핑과 탐색이라는 두 가지 원칙에 의해 설명될 수 있으며, 이는 인지의 불변체로 작용한다.

Conclusion: 이러한 기제를 인식하는 것은 생명 시스템과 인공 모델 간의 깊은 유사성을 밝혀주고, 다양한 스케일에 걸쳐 적응형 지능 공학에 대한 통합된 프레임워크를 제공한다.

Abstract: The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.

</details>


### [93] [Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance](https://arxiv.org/abs/2601.14171)
*Qianli Ma,Chang Guo,Zhiheng Tian,Siyu Wang,Jipeng Xiao,Yuanhao Yue,Zhipeng Zhang*

Main category: cs.AI

TL;DR: 제안된 $	extbf{RebuttalAgent}$는 반론 생성을 증거 중심의 계획 작업으로 재구성하는 다중 에이전트 프레임워크로, 검토자의 의도와 원고 세부 사항 간의 정밀한 정렬을 요구한다.


<details>
  <summary>Details</summary>
Motivation: 효과적인 반론 작성을 위한 요구 사항은 언어적 유창성을 넘어서는 것임.

Method: $	extbf{RebuttalAgent}$는 복잡한 피드백을 원자적 문제로 분해하고, 외부 문헌을 요구하는 문제를 해결하기 위해 자율 외부 검색 모듈을 통합하여 유압식 요약과 고충실도 텍스트를 종합하여 혼합된 맥락을 동적으로 구성한다.

Result: 우리의 접근 방식을 $	extbf{RebuttalBench}$에서 검증하고, 커버리지, 충실도 및 전략적 일관성에서 강력한 기준선을 초과하는 성과를 보였다.

Conclusion: 투명하고 통제 가능한 동료 검토 프로세스를 위한 보조 도구를 제공한다. 코드는 공개될 예정이다.

Abstract: Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.

</details>


### [94] [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/abs/2601.14192)
*Xiaofang Yang,Lijun Li,Heng Zhou,Tong Zhu,Xiaoye Qu,Yuchen Fan,Qianshan Wei,Rui Ye,Li Kang,Yiran Qin,Zhiqiang Kou,Daizong Liu,Qi Li,Ning Ding,Siheng Chen,Jing Shao*

Main category: cs.AI

TL;DR: 에이전트 시스템에 대한 연구는 증가하고 있지만, 실제 배치를 위한 효율성은 종종 간과되고 있다. 본 연구는 메모리, 도구 학습, 계획의 세 가지 핵심 요소에서 효율성을 조사하고, 다양한 접근 방식을 리뷰하여 일반적인 원칙을 확인한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 시스템의 효율성이 실제 배치에 중요한데, 이에 대한 연구가 부족한 점을 보완하고자 한다.

Method: 메모리, 도구 학습, 계획의 세 가지 핵심 요소를 중심으로 효율성을 측정하고, 다양한 최근 접근 방식을 리뷰한다.

Result: 효율성을 두 가지 방식으로 특징 짓고, 다양한 평가 프로토콜과 일반적으로 보고된 효율성 지표를 정리하여 효율 지향 벤치마크를 제공한다.

Conclusion: 주요 도전 과제와 향후 방향을 논의하며, 유망한 통찰력을 제공하는 것을 목표로 한다.

Abstract: Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [95] [Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework](https://arxiv.org/abs/2601.11893)
*Zimo Ji,Daoyuan Wu,Wenyuan Jiang,Pingchuan Ma,Zongjie Li,Yudong Gao,Shuai Wang,Yingjiu Li*

Main category: cs.CR

TL;DR: 이 논문은 LLM 기반 에이전트 시스템의 권한 상승 공격을 이해하고 완화하기 위한 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트 시스템이 복잡한 실제 작업에 점점 더 많이 적용되고 있지만, 과도한 도구 사용으로 인해 자연어 기반 공격에 취약하다.

Method: 우리는 세분화된 권한 상승 시나리오를 식별하고, SEAgent라는 MAC 프레임워크를 제안하여 에이전트와 도구 간의 상호작용을 모니터링하고 사용자 정의 가능한 보안 정책을 시행한다.

Result: SEAgent는 다양한 권한 상승을 효과적으로 차단하면서 낮은 오탐률과 미미한 시스템 오버헤드를 유지한다.

Conclusion: SEAgent는 LLM 기반 에이전트 시스템의 보안을 강화하는 데 강력하고 적응력이 뛰어나다.

Abstract: Large Language Model (LLM)-based agent systems are increasingly deployed for complex real-world tasks but remain vulnerable to natural language-based attacks that exploit over-privileged tool use. This paper aims to understand and mitigate such attacks through the lens of privilege escalation, defined as agent actions exceeding the least privilege required for a user's intended task. Based on a formal model of LLM agent systems, we identify novel privilege escalation scenarios, particularly in multi-agent systems, including a variant akin to the classic confused deputy problem. To defend against both known and newly demonstrated privilege escalation, we propose SEAgent, a mandatory access control (MAC) framework built upon attribute-based access control (ABAC). SEAgent monitors agent-tool interactions via an information flow graph and enforces customizable security policies based on entity attributes. Our evaluations show that SEAgent effectively blocks various privilege escalation while maintaining a low false positive rate and negligible system overhead. This demonstrates its robustness and adaptability in securing LLM-based agent systems.

</details>


### [96] [Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?](https://arxiv.org/abs/2601.12349)
*Yi Qian,Kunwei Qian,Xingbang He,Ligeng Chen,Jikang Zhang,Tiantai Zhang,Haiyang Wei,Linzhang Wang,Hao Wu,Bing Mao*

Main category: cs.CR

TL;DR: 대형 다중 모드 모델 기반 GUI 에이전트는 모바일 플랫폼에서 화면 내용을 인식하고 입력을 주입하는 고권한 조작자로 등장하고 있다. 그러나 이러한 설계는 관찰과 행동 사이에서 UI 상태가 변하지 않는다는 암묵적인 가정 하에 운영된다. 우리는 안드로이드에서 이 가정이 근본적으로 잘못되었다는 것을 증명하고, 에이전트의 실행을 재결합할 수 있는 새로운 공격 방법인 Action Rebinding을 제시한다. 이 방법은 인증 게이트를 우회할 수 있게 해주는 Intent Alignment Strategy (IAS)를 도입하여 공격의 성공률을 극대화한다. 실험 결과, 15개 작업에서 전통적으로 사용되는 6개의 안드로이드 GUI 에이전트에서 100% 성공률을 달성하였다.


<details>
  <summary>Details</summary>
Motivation: 대형 다중 모드 모델 기반 GUI 에이전트는 모바일 플랫폼에서 보다 효율적으로 동작하기 위해 설계되고 있으나, 현재 설계에서 발생하는 기초적인 가정을 검증할 필요가 있다.

Method: Action Rebinding이라는 새로운 공격 방법을 제시하며, 이는 관찰과 행동 사이의 격차를 이용해 에이전트의 실행을 재결합하는 방법이다. 또한 Intent Alignment Strategy (IAS)를 도입하여 UI 상태를 합리화하고 인증 게이트를 우회할 수 있게 한다.

Result: 실험 결과, 6개의 널리 사용되는 안드로이드 GUI 에이전트에 대해 15개의 작업을 평가한 결과, 원자적 행동 재결합에서 100% 성공률을 달성하고 다단계 공격 체인을 안정적으로 조작할 수 있었다. IAS를 사용함으로써 인증 게이트 우회 성공률이 0%에서 최대 100%까지 증가했다.

Conclusion: 현재 에이전트-운영체제 통합의 근본적인 아키텍처 결함을 드러내며, 향후 에이전트 시스템의 안전한 설계를 위한 중요한 통찰을 제공한다.

Abstract: Large multimodal model powered GUI agents are emerging as high-privilege operators on mobile platforms, entrusted with perceiving screen content and injecting inputs. However, their design operates under the implicit assumption of Visual Atomicity: that the UI state remains invariant between observation and action. We demonstrate that this assumption is fundamentally invalid in Android, creating a critical attack surface.
  We present Action Rebinding, a novel attack that allows a seemingly-benign app with zero dangerous permissions to rebind an agent's execution. By exploiting the inevitable observation-to-action gap inherent in the agent's reasoning pipeline, the attacker triggers foreground transitions to rebind the agent's planned action toward the target app. We weaponize the agent's task-recovery logic and Android's UI state preservation to orchestrate programmable, multi-step attack chains. Furthermore, we introduce an Intent Alignment Strategy (IAS) that manipulates the agent's reasoning process to rationalize UI states, enabling it to bypass verification gates (e.g., confirmation dialogs) that would otherwise be rejected.
  We evaluate Action Rebinding Attacks on six widely-used Android GUI agents across 15 tasks. Our results demonstrate a 100% success rate for atomic action rebinding and the ability to reliably orchestrate multi-step attack chains. With IAS, the success rate in bypassing verification gates increases (from 0% to up to 100%). Notably, the attacker application requires no sensitive permissions and contains no privileged API calls, achieving a 0% detection rate across malware scanners (e.g., VirusTotal). Our findings reveal a fundamental architectural flaw in current agent-OS integration and provide critical insights for the secure design of future agent systems. To access experimental logs and demonstration videos, please contact yi_qian@smail.nju.edu.cn.

</details>


### [97] [Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees](https://arxiv.org/abs/2601.12447)
*Mohammed Himayath Ali,Mohammed Aqib Abdullah,Syed Muneer Hussin,Mohammed Mudassir Uddin,Shahnawaz Alam*

Main category: cs.CR

TL;DR: CryptoFair-FL은 연합 학습 시스템을 위한 첫 번째 검증 가능한 공정성 보장을 제공하는 새로운 암호화 프레임워크로, 개인 정보를 보호하면서도 데이터의 공정성을 확보할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습은 민감한 데이터를 중앙 집중화하지 않고 분산된 기관 간에 협력적으로 모델을 훈련할 수 있게 하지만, 비공식적인 공정성을 보장하는 것은 해결되지 않은 문제이다.

Method: 제안된 방법은 덧셈 동형 암호화와 안전한 다자간 계산을 결합하여 보호된 속성 분포나 개별 예측을 공개하지 않고도 인구 통계적 평형성과 동등한 기회 메트릭의 개인 정보 보호 검증을 가능하게 한다. 새로운 일괄 검증 프로토콜은 계산 복잡성을 BigO(n^2)에서 BigO(n log n)으로 줄인다.

Result: 실험 결과, CryptoFair-FL은 인구 통계적 평형 차이를 0.231에서 0.031로 줄였으며, 기존의 연합 평균화에 비해 계산 오버헤드는 2.3배로 증가했다.

Conclusion: 이 프레임워크는 규제 산업에서 개인 정보 보호와 알고리즘 책임이 모두 요구되는 환경에서 공정성을 고려한 연합 학습을 배포할 수 있는 실용적인 경로를 제시한다.

Abstract: Federated learning enables collaborative model training across distributed institutions without centralizing sensitive data; however, ensuring algorithmic fairness across heterogeneous data distributions while preserving privacy remains fundamentally unresolved. This paper introduces CryptoFair-FL, a novel cryptographic framework providing the first verifiable fairness guarantees for federated learning systems under formal security definitions. The proposed approach combines additively homomorphic encryption with secure multi-party computation to enable privacy-preserving verification of demographic parity and equalized odds metrics without revealing protected attribute distributions or individual predictions. A novel batched verification protocol reduces computational complexity from BigO(n^2) to BigO(n \log n) while maintaining (\dparam, \deltap)-differential privacy with dparam = 0.5 and deltap = 10^{-6}. Theoretical analysis establishes information-theoretic lower bounds on the privacy cost of fairness verification, demonstrating that the proposed protocol achieves near-optimal privacy-fairness tradeoffs. Comprehensive experiments across four benchmark datasets (MIMIC-IV healthcare records, Adult Income, CelebA, and a novel FedFair-100 benchmark) demonstrate that CryptoFair-FL reduces fairness violations from 0.231 to 0.031 demographic parity difference while incurring only 2.3 times computational overhead compared to standard federated averaging. The framework successfully defends against attribute inference attacks, maintaining adversarial success probability below 0.05 across all tested configurations. These results establish a practical pathway for deploying fairness-aware federated learning in regulated industries requiring both privacy protection and algorithmic accountability.

</details>


### [98] [AgenTRIM: Tool Risk Mitigation for Agentic AI](https://arxiv.org/abs/2601.12449)
*Roy Betser,Shamik Bose,Amit Giloni,Chiara Picardi,Sindhu Padakandla,Roman Vainshtein*

Main category: cs.CR

TL;DR: AgenTRIM은 AI 에이전트의 도구 사용 위험을 탐지하고 완화하는 프레임워크로, 과도한 권한 또는 불충분한 권한 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 도구 사용 시 보안 위험을 초래하는 과도한 권한 및 불충분한 권한 문제를 해결하고자 한다.

Method: AgenTRIM은 코드 및 실행 추적을 통해 에이전트의 도구 인터페이스를 재구성하고 검증하며, 런타임에서 적응형 필터링과 상태 인식 검증을 통해 최소 권한 도구 접근을 시행한다.

Result: AgentDojo 벤치마크에서 공격 성공률을 크게 줄이면서 높은 작업 성능을 유지한다.

Conclusion: AgenTRIM은 LLM 기반 에이전트의 안전한 도구 사용을 위한 실용적이고 능력을 유지하는 접근 방식을 제공한다.

Abstract: AI agents are autonomous systems that combine LLMs with external tools to solve complex tasks. While such tools extend capability, improper tool permissions introduce security risks such as indirect prompt injection and tool misuse. We characterize these failures as unbalanced tool-driven agency. Agents may retain unnecessary permissions (excessive agency) or fail to invoke required tools (insufficient agency), amplifying the attack surface and reducing performance. We introduce AgenTRIM, a framework for detecting and mitigating tool-driven agency risks without altering an agent's internal reasoning. AgenTRIM addresses these risks through complementary offline and online phases. Offline, AgenTRIM reconstructs and verifies the agent's tool interface from code and execution traces. At runtime, it enforces per-step least-privilege tool access through adaptive filtering and status-aware validation of tool calls. Evaluating on the AgentDojo benchmark, AgenTRIM substantially reduces attack success while maintaining high task performance. Additional experiments show robustness to description-based attacks and effective enforcement of explicit safety policies. Together, these results demonstrate that AgenTRIM provides a practical, capability-preserving approach to safer tool use in LLM-based agents.

</details>


### [99] [PrivFly: A Privacy-Preserving Self-Supervised Framework for Rare Attack Detection in IoFT](https://arxiv.org/abs/2601.13003)
*Safaa Menssouri,El Mehdi Amhoud*

Main category: cs.CR

TL;DR: PrivFly는 자율 감독 표현 학습과 차등 프라이버시를 통합하여 IoFT 네트워크 트래픽의 탐지 성능을 향상시키는 프라이버시 보호 침입 탐지 시스템 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: IoFT는 기밀성, 무결성, 가용성을 위협하는 사이버 공격에 매우 취약하다.

Method: PrivFly는 자율 감독 표현 학습과 차등 프라이버시를 통합하여 불균형한 IoFT 네트워크 트래픽에서 탐지 성능을 향상시킨다.

Result: PrivFly는 ECU-IoFT 데이터셋에서 최대 98%의 정확도와 99%의 F1 점수를 달성하며, IoFT 시스템의 프라이버시와 탐지 성능의 균형을 효과적으로 맞춘다.

Conclusion: PrivFly는 프라이버시와 탐지 성능을 균형 있게 유지하면서 IoFT 시스템의 안전성을 강화한다.

Abstract: The Internet of Flying Things (IoFT) plays a vital role in modern applications such as aerial surveillance and smart mobility. However, it remains highly vulnerable to cyberattacks that threaten the confidentiality, integrity, and availability of sensitive data. Developing effective intrusion detection systems (IDS) for IoFT networks faces key challenges, including data imbalance, privacy concerns, and the limited capability of traditional models to detect rare but potentially damaging cyber threats. In this work, we propose PrivFly, a privacy-preserving IDS framework that integrates self-supervised representation learning and differential privacy (DP) to enhance detection performance in imbalanced IoFT network traffic. We propose a masked feature reconstruction module for self-supervised pretraining, improving feature representations and boosting rare-class detection. Differential privacy is applied during training to protect sensitive information without significantly compromising model performance. In addition, we conduct a SHapley additive explanations (SHAP)-based analysis to evaluate the impact of DP on feature importance and model behavior. Experimental results on the ECU-IoFT dataset show that PrivFly achieves up to 98% accuracy and 99% F1-score, effectively balancing privacy and detection performance for secure IoFT systems.

</details>


### [100] [High-Throughput and Scalable Secure Inference Protocols for Deep Learning with Packed Secret Sharing](https://arxiv.org/abs/2601.13041)
*Qinghui Zhang,Xiaojun Chen,Yansong Zhang,Xudong Chen*

Main category: cs.CR

TL;DR: 본 논문은 반诚实 적대자에 대한 신경망 추론을 위한 고처리량 및 확장 가능한 MPC 프로토콜을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 MPC 기반 신경망 추론 프로토콜은 참가자가 최대 4명으로 제한되어 있어 확장성이 매우 제한적입니다.

Method: 포장된 샤미르 비밀 공유(PSS)를 활용하여 병렬 계산을 가능하게 하고 통신 복잡성을 줄이는 접근 방식을 제안합니다.

Result: 우리의 접근 방식은 다양한 데이터셋과 신경망에서 WAN 환경에서 우수한 성능을 입증하였습니다.

Conclusion: Liu et al.의 방법에 비해, 우리의 방법은 통신 및 실행 시간을 크게 줄입니다.

Abstract: Most existing secure neural network inference protocols based on secure multi-party computation (MPC) typically support at most four participants, demonstrating severely limited scalability. Liu et al. (USENIX Security'24) presented the first relatively practical approach by utilizing Shamir secret sharing with Mersenne prime fields. However, when processing deeper neural networks such as VGG16, their protocols incur substantial communication overhead, resulting in particularly significant latency in wide-area network (WAN) environments. In this paper, we propose a high-throughput and scalable MPC protocol for neural network inference against semi-honest adversaries in the honest-majority setting. The core of our approach lies in leveraging packed Shamir secret sharing (PSS) to enable parallel computation and reduce communication complexity. The main contributions are three-fold: i) We present a communication-efficient protocol for vector-matrix multiplication, based on our newly defined notion of vector-matrix multiplication-friendly random share tuples. ii) We design the filter packing approach that enables parallel convolution. iii) We further extend all non-linear protocols based on Shamir secret sharing to the PSS-based protocols for achieving parallel non-linear operations. Extensive experiments across various datasets and neural networks demonstrate the superiority of our approach in WAN. Compared to Liu et al. (USENIX Security'24), our scheme reduces the communication upto 5.85x, 11.17x, and 6.83x in offline, online and total communication overhead, respectively. In addition, our scheme is upto 1.59x, 2.61x, and 1.75x faster in offline, online and total running time, respectively.

</details>


### [101] [CODE: A Contradiction-Based Deliberation Extension Framework for Overthinking Attacks on Retrieval-Augmented Generation](https://arxiv.org/abs/2601.13112)
*Xiaolei Zhang,Xiaojun Jia,Liquan Chen,Songze Li*

Main category: cs.CR

TL;DR: 이 논문은 RAG 시스템에서 추론 모델이 과도한 사고 공격을 받을 수 있으며, CODE라는 공격 프레임워크를 통해 이를 밝혀내고 해결책을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 추론 모델을 RAG 시스템에 도입하면 작업 성능이 향상되지만, 최근 연구에서는 이러한 모델이 과도한 사고 공격을 받을 수 있다는 사실이 발견되었다.

Method: CODE라는 다중 에이전트 아키텍처를 개발하여 지식 기반에 주입할 유해 샘플을 구성한다.

Result: 제안된 공격은 추론 토큰 소비를 5.32배에서 24.72배 증가시켰다.

Conclusion: 마지막으로, 과도한 사고의 위험을 완화하기 위한 잠재적 대응책에 대해 논의하고 평가한다.

Abstract: Introducing reasoning models into Retrieval-Augmented Generation (RAG) systems enhances task performance through step-by-step reasoning, logical consistency, and multi-step self-verification. However, recent studies have shown that reasoning models suffer from overthinking attacks, where models are tricked to generate unnecessarily high number of reasoning tokens. In this paper, we reveal that such overthinking risk can be inherited by RAG systems equipped with reasoning models, by proposing an end-to-end attack framework named Contradiction-Based Deliberation Extension (CODE). Specifically, CODE develops a multi-agent architecture to construct poisoning samples that are injected into the knowledge base. These samples 1) are highly correlated with the use query, such that can be retrieved as inputs to the reasoning model; and 2) contain contradiction between the logical and evidence layers that cause models to overthink, and are optimized to exhibit highly diverse styles. Moreover, the inference overhead of CODE is extremely difficult to detect, as no modification is needed on the user query, and the task accuracy remain unaffected. Extensive experiments on two datasets across five commercial reasoning models demonstrate that the proposed attack causes a 5.32x-24.72x increase in reasoning token consumption, without degrading task performance. Finally, we also discuss and evaluate potential countermeasures to mitigate overthinking risks.

</details>


### [102] [Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests](https://arxiv.org/abs/2601.13515)
*Hanlin Zhou,Huah Yong Chan,Jingfei Ni,Mengchun Wu,Qing Deng*

Main category: cs.CR

TL;DR: 이 논문은 HPA에서 HTTP 상태 코드를 사용자 정의 메트릭으로 사용하고, 머신러닝의 랜덤 포레스트 분류 알고리즘을 통합하여 공격을 평가하고 예측함으로써, 공격 트래픽 관리를 위한 HPA의 최대 파드 매개변수를 동적으로 조정하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 이 연구의 목표는 공격을 효과적으로 관리하기 위해 HPA 파라미터를 동적으로 조정하는 것입니다.

Method: HTTP 상태 코드를 사용자 정의 메트릭으로 사용하고, 머신러닝의 랜덤 포레스트 분류 알고리즘을 통합하여 HPA의 최대 파드 매개변수를 동적으로 조정합니다.

Result: 공격 IP에서의 모든 접근이 허니팟 파드로 리디렉션되며, HPA 파드 조정을 통해 5XX 상태 코드의 발생률이 낮아졌습니다.

Conclusion: 적절한 HPA 조정을 위한 임계값 설정의 중요성이 실험을 통해 입증되었습니다.

Abstract: In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.

</details>


### [103] [PINA: Prompt Injection Attack against Navigation Agents](https://arxiv.org/abs/2601.13612)
*Jiani Liu,Yixin He,Lanlan Fan,Qidi Zhong,Yushi Cheng,Meng Zhang,Yanjiao Chen,Wenyuan Xu*

Main category: cs.CR

TL;DR: 본 논문은 내비게이션 에이전트의 프롬프트 삽입 공격에 대한 첫 체계적 조사를 수행하고, PINA라는 적응형 프롬프트 최적화 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 내비게이션 에이전트의 보안 문제를 해결할 필요성이 있다.

Method: PINA는 블랙박스, 긴 컨텍스트 및 실행 가능한 행동 제약 조건에 맞게 설계된 적응형 프롬프트 최적화 프레임워크이다.

Result: PINA는 평균 ASR 87.5%의 높은 공격 성공률을 기록하고, 모든 기준선을 초과하며, 적응 공격 조건에서도 견고성을 유지한다.

Conclusion: 내비게이션 에이전트의 프롬프트 삽입 공격에 대한 체계적인 조사 결과가 제시되었으며, 이들 에이전트의 보안에 대한 긴급한 시사점을 강조한다.

Abstract: Navigation agents powered by large language models (LLMs) convert natural language instructions into executable plans and actions. Compared to text-based applications, their security is far more critical: a successful prompt injection attack does not just alter outputs but can directly misguide physical navigation, leading to unsafe routes, mission failure, or real-world harm. Despite this high-stakes setting, the vulnerability of navigation agents to prompt injection remains largely unexplored. In this paper, we propose PINA, an adaptive prompt optimization framework tailored to navigation agents under black-box, long-context, and action-executable constraints. Experiments on indoor and outdoor navigation agents show that PINA achieves high attack success rates with an average ASR of 87.5%, surpasses all baselines, and remains robust under ablation and adaptive-attack conditions. This work provides the first systematic investigation of prompt injection attacks in navigation and highlights their urgent security implications for embodied LLM agents.

</details>


### [104] [HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation](https://arxiv.org/abs/2601.13864)
*Qirui Chen,Jingxian Shuai,Shuangwu Chen,Shenghao Ye,Zijian Wen,Xufei Su,Jie Jin,Jiangming Li,Jun Chen,Xiaobin Tan,Jian Yang*

Main category: cs.CR

TL;DR: LLM이 생성한 코드의 보안 문제를 평가하기 위해 HardSecBench라는 벤치마크를 개발하고, 이를 통해 하드웨어 및 펌웨어 코드 생성에서 보안 리스크를 분석했다.


<details>
  <summary>Details</summary>
Motivation: 기능적으로 정상적으로 보이는 LLM 생성 코드가 보안 결함을 내포할 수 있다는 점에서, 보안 인식 평가를 위한 벤치마크의 필요성이 있다.

Method: HardSecBench라는 924개 작업으로 구성된 벤치마크를 도입하여 Verilog RTL과 펌웨어 수준 C 코드를 평가하고, 각 작업은 보안 참조 구현 및 실행 가능한 테스트를 포함한다.

Result: LLM 모델이 기능적 요구 사항을 충족하지만 여전히 보안 위험이 남아 있으며, 보안 결과는 프롬프트에 따라 달라진다.

Conclusion: 이 연구는 LLM 보조 하드웨어 설계의 발전을 위한 중요한 도전과제를 강조하고 실행 가능한 통찰력을 제공한다.

Abstract: Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.

</details>


### [105] [Know Your Contract: Extending eIDAS Trust into Public Blockchains](https://arxiv.org/abs/2601.13903)
*Awid Vaziry,Christoph Wronka,Sandro Rodriguez Garzon,Axel Küpper*

Main category: cs.CR

TL;DR: 본 논문은 유럽 연합 eIDAS 신뢰 프레임워크를 공공 블록체인 생태계에 확장하는 아키텍처를 제시하며, 법적으로 책임이 있는 주체에 대한 온체인 행동의 귀속을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 공공 블록체인은 법적으로 책임 있는 주체에 온체인 행동을 귀속시킬 수 있는 고유 메커니즘이 부족하여, 기관의 채택 및 규제 준수에 대한 근본적인 장벽이 존재한다.

Method: 스마트 계약을 공인된 전자 봉인과 암호학적으로 결합하여 유럽 연합의 eIDAS 신뢰 프레임워크를 공공 블록체인 생태계에 확장하는 아키텍처를 제안한다.

Result: 온체인 주소에서 신뢰의 검증 가능합니다. 이는 Know Your Contract, Counterparty 및 Business 검사를 위한 자동화된 규제 검증을 가능하게 하며, 새로운 신뢰할 수 있는 중개자를 도입하지 않는다.

Conclusion: 제안된 아키텍처는 블록체인 기반 시스템에 유럽 디지털 신뢰 인프라를 통합할 수 있는 경로를 제공하며, 기관의 DeFi 참여, 실제 자산 토큰화 및 신뢰할 수 있는 규제 준수 프레임워크 내에서의 에이전트 상거래를 가능하게 한다.

Abstract: Public blockchains lack native mechanisms to attribute on-chain actions to legally accountable entities, creating a fundamental barrier to institutional adoption and regulatory compliance. This paper presents an architecture that extends the European Union eIDAS trust framework into public blockchain ecosystems by cryptographically binding smart contracts to qualified electronic seals issued by Qualified Trust Service Providers. The mechanism establishes a verifiable chain of trust from the European Commission List of Trusted Lists to individual on-chain addresses, enabling machine-verifiable proofs for automated regulatory validation, such as Know Your Contract, Counterparty, and Business checks, without introducing new trusted intermediaries. Regulatory requirements arising from eIDAS, MiCA, PSD2, PSR, and the proposed European Business Wallet are analyzed, and a cryptographic suite meeting both eIDAS implementing regulations and EVM execution constraints following the Ethereum Fusaka upgrade is identified, namely ECDSA with P-256 and CAdES formatting. Two complementary trust validation models are presented: an off-chain workflow for agent-to-agent payment protocols and a fully on-chain workflow enabling regulatory-compliant DeFi operations between legal entities. The on-chain model converts regulatory compliance from a per-counterparty administrative burden into an automated, standardized process, enabling mutual validation at first interaction without prior business relationships. As eIDAS wallets become mandatory across EU member states, the proposed architecture provides a pathway for integrating European digital trust infrastructure into blockchain-based systems, enabling institutional DeFi participation, real-world asset tokenization, and agentic commerce within a trusted, regulatory-compliant framework.

</details>


### [106] [Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain](https://arxiv.org/abs/2601.13907)
*Cosmin-Iulian Irimia*

Main category: cs.CR

TL;DR: 이 논문은 블록체인 기술을 이용한 분산 문서 인증, 서명 및 공유 인프라를 제안하며, 공식 문서 관리의 보안과 효율성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 종이 문서 관리 방식은 보안, 진위 및 효율성 관련 문제를 지속적으로 제기해왔다. 디지털화의 발전에도 불구하고 공식 문서는 위조, 손실 및 무단 접근에 취약하다.

Method: 이 연구는 시스템 요구 사항을 정의하고 기존 솔루션을 평가하며 분산 시스템에 기반한 새로운 아키텍처를 제안하여 투명성, 불변성 및 실행 가능성의 주요 문제를 해결한다.

Result: 암호화 기술과 분산 저장소를 결합하여, 공식 문서 관리를 위한 보다 안전하고 효율적인 프레임워크 개발에 기여한다.

Conclusion: 블록체인 기반 디지털 인증의 가능성이 관료적 프로세스를 간소화하고 보안 위험을 완화하며 디지털 문서 관리에 대한 사용자 신뢰를 향상시킬 수 있음을 강조한다.

Abstract: Traditional paper-based document management has long posed challenges related to security, authenticity, and efficiency. Despite advances in digitalization, official documents remain vulnerable to forgery, loss, and unauthorized access. This thesis proposes a decentralized infrastructure for digital notarization, signing, and sharing of documents using blockchain technology. The research addresses key issues of transparency, immutability, and feasibility by defining system requirements, evaluating existing solutions, and proposing a novel architecture based on distributed systems.
  By combining cryptographic techniques with decentralized storage, this research contributes to the development of a more secure and efficient framework for managing official documents. The findings highlight the potential of blockchain-based digital notarization to streamline bureaucratic processes, mitigate security risks, and enhance user trust in digital document management.

</details>


### [107] [VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation](https://arxiv.org/abs/2601.13981)
*Yilin Tang,Yu Wang,Lanlan Qiu,Wenchang Gao,Yunfei Ma,Baicheng Chen,Tianxing He*

Main category: cs.CR

TL;DR: 대형 언어 모델이 범죄 능력을 평가하기 위한 VirtualCrime 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 문제 해결 능력이 범죄에 악용될 가능성이 우려된다.

Method: 세 가지 에이전트(공격자, 판사, 세계 관리자) 시스템을 기반으로 한 VirtualCrime 샌드박스 시뮬레이션 프레임워크를 설계하고 40가지 범죄 작업을 수행한다.

Result: 8개의 강력한 LLM을 평가한 결과, 모든 에이전트가 효과적으로 계획을 수립하고 지능적인 범죄 과정을 실행하며, 일부는 높은 성공률을 기록했다.

Conclusion: 현실 세계의 상황에서 에이전틱 AI 배치 시 안전성을 고려해야 한다.

Abstract: Large language models (LLMs) have shown strong capabilities in multi-step decision-making, planning and actions, and are increasingly integrated into various real-world applications. It is concerning whether their strong problem-solving abilities may be misused for crimes. To address this gap, we propose VirtualCrime, a sandbox simulation framework based on a three-agent system to evaluate the criminal capabilities of models. Specifically, this framework consists of an attacker agent acting as the leader of a criminal team, a judge agent determining the outcome of each action, and a world manager agent updating the environment state and entities. Furthermore, we design 40 diverse crime tasks within this framework, covering 11 maps and 13 crime objectives such as theft, robbery, kidnapping, and riot. We also introduce a human player baseline for reference to better interpret the performance of LLM agents. We evaluate 8 strong LLMs and find (1) All agents in the simulation environment compliantly generate detailed plans and execute intelligent crime processes, with some achieving relatively high success rates; (2) In some cases, agents take severe action that inflicts harm to NPCs to achieve their goals. Our work highlights the need for safety alignment when deploying agentic AI in real-world settings.

</details>


### [108] [AttackMate: Realistic Emulation and Automation of Cyber Attack Scenarios Across the Kill Chain](https://arxiv.org/abs/2601.14108)
*Max Landauer,Wolfgang Hotwagner,Thorina Boenke,Florian Skopik,Markus Wurzenberger*

Main category: cs.CR

TL;DR: 이 논문은 실제 공격자의 행동 패턴을 모방하는 오픈 소스 공격 스크립팅 언어 및 실행 엔진인 AttackMate를 소개하며, 기존의 공격 시뮬레이션 도구보다 인간 공격자와 더 유사한 로그 아티팩트를 생성하는 데 성공했음을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 공격 시뮬레이션 도구는 목표 시스템에 설치된 에이전트에 의존하여 실제 공격자와의 차이를 드러내는 의심스러운 흔적을 남깁니다. 또한, 이 도구들은 상호작용 프롬프트를 처리하는 등 관련된 기능이 부족합니다.

Method: AttackMate라는 오픈 소스 공격 스크립팅 언어와 실행 엔진을 개발하여, 실제 공격자의 행동 패턴을 모방합니다. 이 도구는 권한 상승, 정보 수집, 수평 이동 등 일반적인 공격 단계를 포함한 경우 연구에서 검증되었습니다.

Result: AttackMate의 활동에서 생성된 로그 아티팩트는 인간 공격자가 생성한 것과 표준 공격 시뮬레이션 도구가 생성한 것보다 더 유사함을 보였습니다.

Conclusion: AttackMate는 기존의 도구보다 더 현실적인 공격 시뮬레이션을 가능하게 하며, 보안 테스트 및 사이버 훈련에서의 활용 가능성을 높입니다.

Abstract: Adversary emulation tools facilitate scripting and automated execution of cyber attack chains, thereby reducing costs and manual expert effort required for security testing, cyber exercises, and intrusion detection research. However, due to the fact that existing tools typically rely on agents installed on target systems, they leave suspicious traces that make it easy to distinguish their activities from those of real human attackers. Moreover, these tools often lack relevant capabilities, such as handling of interactive prompts, and are unsuitable for emulating specific stages of the kill chain, such as initial access. This paper thus introduces AttackMate, an open-source attack scripting language and execution engine designed to mimic behavior patterns of actual attackers. We validate the tool in a case study covering common attack steps including privilege escalation, information gathering, and lateral movement. Our results indicate that log artifacts resulting from AttackMate's activities resemble those produced by human attackers more closely than those generated by standard adversary emulation tools.

</details>
