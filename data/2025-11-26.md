<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 13]
- [cs.CR](#cs.CR) [Total: 11]
- [cs.LG](#cs.LG) [Total: 50]
- [cs.AI](#cs.AI) [Total: 25]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [A novel strategy for multi-resource load balancing in agent-based systems](https://arxiv.org/abs/2511.17580)
*Leszek Sliwko,Aleksander Zgrzywa*

Main category: cs.MA

TL;DR: 이 논문은 에이전트 기반 시스템 내에서 사용될 수 있는 다중 자원 로드 밸런싱 전략을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 이 접근법은 복잡한 기업 아키텍처의 구조를 최적화하려는 시스템 설계자들에게 도움을 줄 수 있다.

Method: 시스템에서는 에이전트의 사회적 행동과 적응 능력을 적용하여 주어진 구성에 대한 최적의 설정을 결정한다.

Result: 제안된 에이전트 시스템은 구현되었으며, 실험 결과가 여기에서 제시된다.

Conclusion: 모든 방법은 에이전트의 자기 평가를 허용하도록 개발되었다.

Abstract: The paper presents a multi-resource load balancing strategy which can be utilised within an agent-based system. This approach can assist system designers in their attempts to optimise the structure for complex enterprise architectures. In this system, the social behaviour of the agent and its adaptation abilities are applied to determine an optimal setup for a given configuration. All the methods have been developed to allow the agent's self-assessment. The proposed agent system has been implemented and the experiment results are presented here.

</details>


### [2] [Hierarchical Adaptive Consensus Network: A Dynamic Framework for Scalable Consensus in Collaborative Multi-Agent AI Systems](https://arxiv.org/abs/2511.17586)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.MA

TL;DR: 3계층 구조의 위계적 적응 합의 네트워크(HACN)을 제안하여 협업 다중 에이전트 시스템의 합의 전략의 적응성, 확장성 및 수렴 불확실성 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 협업 다중 에이전트 시스템에서의 합의 전략은 적응성, 확장성 및 수렴 확실성과 관련된 문제에 직면하고 있다.

Method: 제안된 방법은 다양한 합의 정책을 기반으로 한 3계층 구조의 위계적 적응 합의 네트워크(HACN)를 통해, 첫째로 여러 지역 에이전트 클러스터의 신뢰 기반 투표 결과를 수집하고, 둘째로 클러스터 간의 통신을 촉진하며, 셋째로 시스템 전체의 조정과 최종 중재를 제공한다.

Result: 이 모델은 기존의 완전 연결된 MAS의 $igO(n^2)$ 복잡성에 비해 $igO(n)$ 통신 복잡성을 달성하였으며, 실험에서는 합의 수렴 중 통신 오버헤드를 99.9	ext{%} 감소시켰다.

Conclusion: 제안된 접근 방식은 다양한 복잡한 작업에 대해 위계적 상승과 동적인 적응성을 통해 합의 수렴을 보장한다.

Abstract: The consensus strategies used in collaborative multi-agent systems (MAS) face notable challenges related to adaptability, scalability, and convergence certainties. These approaches, including structured workflows, debate models, and iterative voting, often lead to communication bottlenecks, stringent decision-making processes, and delayed responses in solving complex and evolving tasks. This article introduces a three-tier architecture, the Hierarchical Adaptive Consensus Network (\hacn), which suggests various consensus policies based on task characterization and agent performance metrics. The first layer collects the confidence-based voting outcomes of several local agent clusters. In contrast, the second level facilitates inter-cluster communication through cross-clustered partial knowledge sharing and dynamic timeouts. The third layer provides system-wide coordination and final arbitration by employing a global orchestration framework with adaptable decision rules. The proposed model achieves $\bigO(n)$ communication complexity, as opposed to the $\bigO(n^2)$ complexity of the existing fully connected MAS. Experiments performed in a simulated environment yielded a 99.9\% reduction in communication overhead during consensus convergence. Furthermore, the proposed approach ensures consensus convergence through hierarchical escalation and dynamic adaptation for a wide variety of complicated tasks.

</details>


### [3] [From Competition to Coordination: Market Making as a Scalable Framework for Safe and Aligned Multi-Agent LLM Systems](https://arxiv.org/abs/2511.17621)
*Brendan Gho,Suman Muppavarapu,Afnan Shaik,Tyson Tsay,James Begin,Kevin Zhu,Archana Vaidheeswaran,Vasu Sharma*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 시스템에서의 기초 모델의 집합적 행동이 신뢰성, 투명성 및 책임 문제를 어떻게 일으키는지를 다루며, 경제적 교환으로 에이전트 상호작용을 조직하는 시장 기반 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 기초 모델의 집단적 행동이 신뢰성, 투명성, 책임성에 대한 새로운 도전을 제기하고 있다.

Method: 에이전트 상호작용을 구조화된 경제적 교환으로 조직하는 시장 메이킹 프레임워크를 도입하고, 각 에이전트가 시장 참가자로 작용하여 확률적 신념을 업데이트하고 거래한다.

Result: 시장 기반 조정은 단일 샷 기준선에 비해 최대 10%의 정확성 향상을 제공하며 중간 추론 단계의 해석 가능성과 투명성을 유지한다.

Conclusion: 경제적 조정 원칙이 다중 에이전트 LLM 시스템에서 책임성과 견고성을 운영화할 수 있는 방법을 제시하며, 신뢰를 유지하고 감독할 수 있는 자가 수정 가능하고 사회적으로 책임 있는 AI를 위한 확장 가능한 경로를 제공한다.

Abstract: As foundation models are increasingly deployed as interacting agents in multi-agent systems, their collective behavior raises new challenges for trustworthiness, transparency, and accountability. Traditional coordination mechanisms, such as centralized oversight or adversarial adjudication, struggle to scale and often obscure how decisions emerge. We introduce a market-making framework for multi-agent large language model (LLM) coordination that organizes agent interactions as structured economic exchanges. In this setup, each agent acts as a market participant, updating and trading probabilistic beliefs, to converge toward shared, truthful outcomes. By aligning local incentives with collective epistemic goals, the framework promotes self-organizing, verifiable reasoning without requiring external enforcement. Empirically, we evaluate this approach across factual reasoning, ethical judgment, and commonsense inference tasks. Market-based coordination yields accuracy gains of up to 10% over single-shot baselines while preserving interpretability and transparency of intermediate reasoning steps. Beyond these improvements, our findings demonstrate that economic coordination principles can operationalize accountability and robustness in multi-agent LLM systems, offering a scalable pathway toward self-correcting, socially responsible AI capable of maintaining trust and oversight in real world deployment scenarios.

</details>


### [4] [Iterative Negotiation and Oversight: A Case Study in Decentralized Air Traffic Management](https://arxiv.org/abs/2511.17625)
*Jaehan Im,John-Paul Clarke,Ufuk Topcu,David Fridovich-Keil*

Main category: cs.MA

TL;DR: 탈중앙화된 다중 에이전트 시스템에서 비협조적 에이전트 간의 합의 달성은 여전히 도전 과제이다. 이 논문은 과세와 유사한 감독 기제를 포함한 반복적 협상 프레임워크를 제안하여 이러한 제한을 해결하고, 시스템 효율성과 공평성을 보장하도록 한다.


<details>
  <summary>Details</summary>
Motivation: 비협조적 에이전트 간의 충돌하는 선호를 가진 상태에서 합의를 이루기가 어려움.

Method: 자산 거래를 통해 비협조적 에이전트가 협상하도록 하며, 거래 경매 방식에 기반한 반복적 협상 및 감독 프레임워크를 제안.

Result: 제안된 프레임워크는 미국 항공 교통 관리에서의 재경로 설정 프로그램을 사례 연구로 사용하여, 비협조적 공역 부문 관리자들 간의 합의를 신뢰성 있게 달성할 수 있음을 보여줌.

Conclusion: 제안된 프레임워크는 비협조적 다중 에이전트 시스템에서 탈중앙화된 조정을 위한 일반적인 메커니즘을 제공하며, 시스템 차원의 목표를 보호한다.

Abstract: Achieving consensus among noncooperative agents remains challenging in decentralized multi-agent systems, where agents often have conflicting preferences. Existing coordination methods enable agents to reach consensus without a centralized coordinator, but do not provide formal guarantees on system-level objectives such as efficiency or fairness. To address this limitation, we propose an iterative negotiation and oversight framework that augments a decentralized negotiation mechanism with taxation-like oversight. The framework builds upon the trading auction for consensus, enabling noncooperative agents with conflicting preferences to negotiate through asset trading while preserving valuation privacy. We introduce an oversight mechanism, which implements a taxation-like intervention that guides decentralized negotiation toward system-efficient and equitable outcomes while also regulating how fast the framework converges. We establish theoretical guarantees of finite-time termination and derive bounds linking system efficiency and convergence rate to the level of central intervention. A case study based on the collaborative trajectory options program, a rerouting initiative in U.S. air traffic management, demonstrates that the framework can reliably achieve consensus among noncooperative airspace sector managers, and reveals how the level of intervention regulates the relationship between system efficiency and convergence speed. Taken together, the theoretical and experimental results indicate that the proposed framework provides a general mechanism for decentralized coordination in noncooperative multi-agent systems while safeguarding system-level objectives.

</details>


### [5] [Dialogue Diplomats: An End-to-End Multi-Agent Reinforcement Learning System for Automated Conflict Resolution and Consensus Building](https://arxiv.org/abs/2511.17654)
*Deepak Bolleddu*

Main category: cs.MA

TL;DR: 이 논문은 복잡한 동적 환경에서 자동화된 갈등 해결 및 합의 도출을 위해 설계된 Dialogue Diplomats라는 새로운 다중 에이전트 강화 학습 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템, 협상 및 협력적 의사 결정 프로세스에서 갈등 해결과 합의 도출은 중요한 도전 과제이다.

Method: 본 시스템은 고급 심층 강화 학습 아키텍처와 대화 기반 협상 프로토콜을 통합하여 자율 에이전트가 반복적 커뮤니케이션과 전략적 적응을 통해 복잡한 갈등 해결에 참여할 수 있게 한다.

Result: 주요 기여로는, 주의 메커니즘과 그래프 신경망을 결합하여 에이전트 간 의존성과 갈등 동력을 모델링하는 새로운 계층적 합의 네트워크(HCN) 아키텍처, 적응형 양보 전략으로 구조화된 다중 라운드 대화 상호작용을 위한 점진적 협상 프로토콜(PNP), 그리고 개별 에이전트 목표와 집단 합의 목표의 균형을 맞추는 컨텍스트 기반 보상 형상화 메커니즘이 있다.

Conclusion: 이 프레임워크는 다중 에이전트 시스템에서 효과적인 갈등 해결 및 합의 도출을 위한 혁신적인 접근 방식을 제공한다.

Abstract: Conflict resolution and consensus building represent critical challenges in multi-agent systems, negotiations, and collaborative decision-making processes. This paper introduces Dialogue Diplomats, a novel end-to-end multi-agent reinforcement learning (MARL) framework designed for automated conflict resolution and consensus building in complex, dynamic environments. The proposed system integrates advanced deep reinforcement learning architectures with dialogue-based negotiation protocols, enabling autonomous agents to engage in sophisticated conflict resolution through iterative communication and strategic adaptation. We present three primary contributions: first, a novel Hierarchical Consensus Network (HCN) architecture that combines attention mechanisms with graph neural networks to model inter-agent dependencies and conflict dynamics. second, a Progressive Negotiation Protocol (PNP) that structures multi-round dialogue interactions with adaptive concession strategies; and third, a Context-Aware Reward Shaping mechanism that balances individual agent objectives with collective consensus goals.

</details>


### [6] [Multi-Agent Coordination in Autonomous Vehicle Routing: A Simulation-Based Study of Communication, Memory, and Routing Loops](https://arxiv.org/abs/2511.17656)
*KM Khalid Saifullah,Daniel Palmer*

Main category: cs.MA

TL;DR: 본 연구는 자율 차량 시스템에서의 다중 에이전트 조정의 중요성과 메모리가 없는 반응형 재경로 설정의 문제를 다룬다. 기본적으로, OMM(객체 메모리 관리)을 통해 차량들이 이전에 encountered한 장애물에 대한 지식을 공유하여 평균 이동 시간을 75.7% 단축시키고, 대기 시간을 88% 감소시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 다음 세대 자율 차량 시스템에서의 다중 에이전트 조정의 중요성 강조, 메모리 없는 재경로 설정의 비효율성 문제 해결 필요.

Method: 72개 고유 구성의 시스템 시뮬레이션을 통해 메모리 없는 재경로 설정과 OMM을 적용한 경로를 비교 분석.

Result: OMM을 적용한 결과, 평균 이동 시간 75.7%, 대기 시간 88% 감소, 메모리 없는 시스템에 비해 차량당 경로 재계산 횟수도 단축.

Conclusion: 지속적이고 공유된 메모리가 다중 에이전트 조정에 필수적임을 입증하며, 이는 자율 차량을 넘어 로봇 공학, 네트워크 라우팅 및 분산 AI 시스템 설계에 기여할 수 있다.

Abstract: Multi-agent coordination is critical for next-generation autonomous vehicle (AV) systems, yet naive implementations of communication-based rerouting can lead to catastrophic performance degradation. This study investigates a fundamental problem in decentralized multi-agent navigation: routing loops, where vehicles without persistent obstacle memory become trapped in cycles of inefficient path recalculation. Through systematic simulation experiments involving 72 unique configurations across varying vehicle densities (15, 35, 55 vehicles) and obstacle frequencies (6, 20 obstacles), we demonstrate that memory-less reactive rerouting increases average travel time by up to 682% compared to baseline conditions. To address this, we introduce Object Memory Management (OMM), a lightweight mechanism enabling agents to retain and share knowledge of previously encountered obstacles. OMM operates by maintaining a distributed blacklist of blocked nodes, which each agent consults during Dijkstra-based path recalculation, effectively preventing redundant routing attempts. Our results show that OMM-enabled coordination reduces average travel time by 75.7% and wait time by 88% compared to memory-less systems, while requiring only 1.67 route recalculations per vehicle versus 9.83 in memory-less scenarios. This work provides empirical evidence that persistent, shared memory is not merely beneficial but essential for robust multi-agent coordination in dynamic environments. The findings have implications beyond autonomous vehicles, informing the design of decentralized systems in robotics, network routing, and distributed AI. We provide a comprehensive experimental analysis, including detailed scenario breakdowns, scalability assessments, and visual documentation of the routing loop phenomenon, demonstrating OMM's critical role in preventing detrimental feedback cycles in cooperative multi-agent systems.

</details>


### [7] [Episodic Memory in Agentic Frameworks: Suggesting Next Tasks](https://arxiv.org/abs/2511.17775)
*Sandro Rama Fiorini,Leonardo G. Azevedo,Raphael M. Thiago,Valesca M. de Sousa,Anton B. Labate,Viviane Torres da Silva*

Main category: cs.MA

TL;DR: 대형 언어 모델을 활용한 에이전틱 프레임워크는 과학적 작업 흐름에서 인간-AI 공동 창작을 촉진할 수 있는 유용한 도구입니다. 본 연구에서는 에피소딕 메모리 아키텍처를 제안하여, 과거 작업 흐름을 저장하고 검색함으로써 다음 단계 제안을 지원합니다.


<details>
  <summary>Details</summary>
Motivation: 과학적 작업 흐름에서 AI와 인간의 공동 창작이 필요하지만, LLM에만 의존하지 않고 다음 단계를 추천하는 것이 핵심 과제입니다.

Method: 에피소딕 메모리 아키텍처를 사용하여 과거 작업 흐름을 저장하고 검색함으로써 에이전트가 가능한 다음 작업을 제안하도록 안내합니다.

Result: 현재 작업 흐름과 역사적 시퀀스를 매칭하여, 에이전트가 이전 패턴에 기반하여 작업 단계를 추천할 수 있습니다.

Conclusion: 이 방식을 통해 LLM의 의존도를 줄이고, 보다 신뢰할 수 있는 작업 흐름 생성이 가능해집니다.

Abstract: Agentic frameworks powered by Large Language Models (LLMs) can be useful tools in scientific workflows by enabling human-AI co-creation. A key challenge is recommending the next steps during workflow creation without relying solely on LLMs, which risk hallucination and require fine-tuning with scarce proprietary data. We propose an episodic memory architecture that stores and retrieves past workflows to guide agents in suggesting plausible next tasks. By matching current workflows with historical sequences, agents can recommend steps based on prior patterns.

</details>


### [8] [DISPATCH -- Decentralized Informed Spatial Planning and Assignment of Tasks for Cooperative Heterogeneous Agents](https://arxiv.org/abs/2511.17915)
*Yao Liu,Sampad Mohanty,Elizabeth Ondula,Bhaskar Krishnamachari*

Main category: cs.MA

TL;DR: 다양한 작업의 효율성과 공정성을 함께 고려하는 다중 에이전트 시스템에서의 공간 작업 할당 연구.


<details>
  <summary>Details</summary>
Motivation: 다중 로봇 배달 및 차량 공유와 같은 시스템에서 작업 간 공정한 서비스와 효율성 간의 균형이 필요.

Method: Eisenberg-Gale 균형 볼록 프로그램과 비중앙집중적, 부분 관찰 가능한 다중 에이전트 학습 간의 연결을 확립하고, 이를 기반으로 공정성과 효율성을 통합한 EG-MARL 알고리즘과 확률적 온라인 최적화 메커니즘을 개발한다.

Result: EG-MARL은 중앙 집중식 조정에 가까운 성과를 내고 감소된 이동 거리를 제공하며, 확률적 온라인 메커니즘은 실시간 할당에서 경쟁력 있는 공정성을 가능하게 한다.

Conclusion: 결과는 이종 능력을 가진 에이전트의 분산 조정을 효과적으로 안내할 수 있음을 보여준다.

Abstract: Spatial task allocation in systems such as multi-robot delivery or ride-sharing requires balancing efficiency with fair service across tasks. Greedy assignment policies that match each agent to its highest-preference or lowest-cost task can maximize efficiency but often create inequities: some tasks receive disproportionately favorable service (e.g., shorter delays or better matches), while others face long waits or poor allocations.
  We study fairness in heterogeneous multi-agent systems where tasks vary in preference alignment and urgency. Most existing approaches either assume centralized coordination or largely ignore fairness under partial observability. Distinct from this prior work, we establish a connection between the Eisenberg-Gale (EG) equilibrium convex program and decentralized, partially observable multi-agent learning. Building on this connection, we develop two equilibrium-informed algorithms that integrate fairness and efficiency: (i) a multi-agent reinforcement learning (MARL) framework, EG-MARL, whose training is guided by centralized fair assignment algorithms (EG and a preference-aware Hungarian method); and (ii) a stochastic online optimization mechanism that performs guided exploration and subset-based fair assignment as tasks are discovered.
  We evaluate our frameworks across a range of team sizes and assignment formulations against centralized EG, Hungarian, and Min-Max Distance baselines. Both algorithms preserve the fairness-efficiency balance of the Eisenberg-Gale equilibrium under partial observability. EG-MARL achieves near-centralized coordination and reduced travel distances, while the stochastic online mechanism enables real-time allocation with competitive fairness. Together, these results demonstrate that spatially aware EG formulations can effectively guide decentralized coordination in agents with heterogeneous capabilities.

</details>


### [9] [Hybrid Agentic AI and Multi-Agent Systems in Smart Manufacturing](https://arxiv.org/abs/2511.18258)
*Mojtaba A. Farahani,Md Irfan Khan,Thorsten Wuest*

Main category: cs.MA

TL;DR: 이 논문은 스마트 제조 시스템(SMS)에서의 지능형 의사결정을 위한 하이브리드 에이전틱 AI 및 멀티 에이전트 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI와 MAS의 융합은 스마트 제조 시스템에서 지능형 의사결정을 위한 새로운 패러다임을 가능하게 한다.

Method: 하이브리드 에이전틱 AI 및 멀티 에이전트 프레임워크를 제안하며, LLM 기반 에이전트가 전략적 조율 및 적응적 추론을 제공하고, 규칙 기반 및 SLM 에이전트가 효율적인 도메인 특정 작업을 수행한다.

Result: 시스템은 자동으로 스키마를 감지하고, 전처리 파이프라인을 조정하며, 적응형 지능을 통해 모델 성능을 최적화하고, 실행 가능한 우선화된 유지보수 권장사항을 생성할 수 있는 능력을 입증하였다.

Conclusion: 이 프레임워크는 스마트 제조에서 향상된 강건성, 확장성 및 설명 가능성을 달성할 수 있는 가능성이 있다.

Abstract: The convergence of Agentic AI and MAS enables a new paradigm for intelligent decision making in SMS. Traditional MAS architectures emphasize distributed coordination and specialized autonomy, while recent advances in agentic AI driven by LLMs introduce higher order reasoning, planning, and tool orchestration capabilities. This paper presents a hybrid agentic AI and multi agent framework for a Prescriptive Maintenance use case, where LLM based agents provide strategic orchestration and adaptive reasoning, complemented by rule based and SLMs agents performing efficient, domain specific tasks on the edge. The proposed framework adopts a layered architecture that consists of perception, preprocessing, analytics, and optimization layers, coordinated through an LLM Planner Agent that manages workflow decisions and context retention. Specialized agents autonomously handle schema discovery, intelligent feature analysis, model selection, and prescriptive optimization, while a HITL interface ensures transparency and auditability of generated maintenance recommendations. This hybrid design supports dynamic model adaptation, cost efficient maintenance scheduling, and interpretable decision making. An initial proof of concept implementation is validated on two industrial manufacturing datasets. The developed framework is modular and extensible, supporting seamless integration of new agents or domain modules as capabilities evolve. The results demonstrate the system capability to automatically detect schema, adapt preprocessing pipelines, optimize model performance through adaptive intelligence, and generate actionable, prioritized maintenance recommendations. The framework shows promise in achieving improved robustness, scalability, and explainability for RxM in smart manufacturing, bridging the gap between high level agentic reasoning and low level autonomous execution.

</details>


### [10] [Think How Your Teammates Think: Active Inference Can Benefit Decentralized Execution](https://arxiv.org/abs/2511.18761)
*Hao Wu,Shoucheng Song,Chang Yao,Sheng Han,Huaiyu Wan,Youfang Lin,Kai Lv*

Main category: cs.MA

TL;DR: 본 연구는 다중 에이전트 시스템에서 팀원 간의 의사결정 논리를 이해하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 팀원 간의 의사결정 논리를 명확히 이해하는 것은 협력을 촉진하는 중요한 요인입니다.

Method: 우리는 지역 관찰 기반 모델링을 통해 인식을 구축하는 비통신 MARL 프레임워크를 제안합니다.

Result: 제안된 방법은 팀원의 의사결정 과정을 명확하게 모델링하며, 협력하는 팀원을 효과적으로 선택하고 협업을 촉진합니다.

Conclusion: SMAC, SMACv2, MPE 및 GRF 벤치마크에서 우리의 방법의 우수한 성능이 입증되었습니다.

Abstract: In multi-agent systems, explicit cognition of teammates' decision logic serves as a critical factor in facilitating coordination. Communication (i.e., ``\textit{Tell}'') can assist in the cognitive development process by information dissemination, yet it is inevitably subject to real-world constraints such as noise, latency, and attacks. Therefore, building the understanding of teammates' decisions without communication remains challenging. To address this, we propose a novel non-communication MARL framework that realizes the construction of cognition through local observation-based modeling (i.e., \textit{``Think''}). Our framework enables agents to model teammates' \textbf{active inference} process. At first, the proposed method produces three teammate portraits: perception-belief-action. Specifically, we model the teammate's decision process as follows: 1) Perception: observing environments; 2) Belief: forming beliefs; 3) Action: making decisions. Then, we selectively integrate the belief portrait into the decision process based on the accuracy and relevance of the perception portrait. This enables the selection of cooperative teammates and facilitates effective collaboration. Extensive experiments on the SMAC, SMACv2, MPE, and GRF benchmarks demonstrate the superior performance of our method.

</details>


### [11] [Addressing Situated Teaching Needs: A Multi-Agent Framework for Automated Slide Adaptation](https://arxiv.org/abs/2511.18840)
*Binglin Liu,Yucheng Wang,Zheyuan Zhang,Jiyuan Lu,Shen Yang,Daniel Zhang-Li,Huiqin Liu,Jifan Yu*

Main category: cs.MA

TL;DR: 이 논문은 교육자의 교육 요구에 맞춰 슬라이드를 자동으로 조정하는 다중 에이전트 프레임워크를 도입하여 교육자들이 창의적이고 전략적인 교육에 집중할 수 있도록 지원합니다.


<details>
  <summary>Details</summary>
Motivation: 교육자들이 교수 슬라이드를 학생의 맥락과 교수 스타일에 맞춰 조정하는 것은 중요하지만 시간이 많이 소요되는 작업입니다.

Method: 우리는 교육자 인터뷰를 통해 적응 과정을 방해하는 주요 마찰 지점을 식별하고 체계적으로 분류한 후, 고수준 교육자 사양에 기반하여 슬라이드 적응을 자동화하는 새로운 다중 에이전트 프레임워크를 소개합니다.

Result: 8개의 실제 강좌에 걸쳐 16개의 수정 요청을 포함한 평가를 통해 우리의 접근 방식이 검증되었습니다. 프레임워크의 출력은 의도 정렬, 내용의 일관성 및 사실적 정확도에서 일관되게 높은 점수를 기록하였고, 시각적 명료성에 관한 기준 방법과 동등한 성능을 보였습니다.

Conclusion: 이 연구는 AI 에이전트가 교육 디자인의 물류적 부담을 처리하여 교육자들이 교수의 창의적이고 전략적인 측면에 집중할 수 있는 새로운 패러다임을 여는 것을 예고합니다.

Abstract: The adaptation of teaching slides to instructors' situated teaching needs, including pedagogical styles and their students' context, is a critical yet time-consuming task for educators. Through a series of educator interviews, we first identify and systematically categorize the key friction points that impede this adaptation process. Grounded in these findings, we introduce a novel multi-agent framework designed to automate slide adaptation based on high-level instructor specifications. An evaluation involving 16 modification requests across 8 real-world courses validates our approach. The framework's output consistently achieved high scores in intent alignment, content coherence and factual accuracy, and performed on par with baseline methods regarding visual clarity, while also demonstrating appropriate timeliness and a high operational agreement with human experts, achieving an F1 score of 0.89. This work heralds a new paradigm where AI agents handle the logistical burdens of instructional design, liberating educators to focus on the creative and strategic aspects of teaching.

</details>


### [12] [VIL2C: Value-of-Information Aware Low-Latency Communication for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.19146)
*Qian Zhang,Zhuo Sun,Yao Zhang,Zhiwen Yu,Bin Guo,Jun Zhang*

Main category: cs.MA

TL;DR: 이 논문에서는 협력적인 다중 에이전트 강화 학습 시스템에서의 성능 향상을 위해 지연을 최소화하는 통신 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습(MARL) 시스템에서의 통신 지연은 의사결정 지연 및 정보 공유의 구식화를 초래하여 성능 향상을 저해합니다.

Method: 정보 가치(VOI)를 고려한 저지연 통신(VIL2C) 방안을 제안하고, 지연된 메시지의 중요성에 기반한 VOI 메트릭을 통해 제공되는 정보의 중요성을 정량화합니다. 또한, 수신 메시지에 따라 수신 기간을 조정하는 점진적인 메시지 수신 메커니즘을 도입합니다.

Result: 광범위한 실험을 통해 VIL2C가 다양한 통신 조건에서 기존 접근 방식을 능가함을 입증하였습니다.

Conclusion: 제안된 VIL2C 방식은 자원 할당을 통해 높은 VOI 메시지를 저지연으로 전송하고, 적응형 수신 기간을 통해 불필요한 대기 시간을 제거함으로써 성능 이점을 제공합니다.

Abstract: Inter-agent communication serves as an effective mechanism for enhancing performance in collaborative multi-agent reinforcement learning(MARL) systems. However, the inherent communication latency in practical systems induces both action decision delays and outdated information sharing, impeding MARL performance gains, particularly in time-critical applications like autonomous driving. In this work, we propose a Value-of-Information aware Low-latency Communication(VIL2C) scheme that proactively adjusts the latency distribution to mitigate its effects in MARL systems. Specifically, we define a Value of Information (VOI) metric to quantify the importance of delayed message transmission based on each delayed message's importance. Moreover, we propose a progressive message reception mechanism to adaptively adjust the reception duration based on received messages. We derive the optimized VoI aware resource allocation and theoretically prove the performance advantage of the proposed VIL2C scheme. Extensive experiments demonstrate that VIL2C outperforms existing approaches under various communication conditions. These gains are attributed to the low-latency transmission of high-VoI messages via resource allocation and the elimination of unnecessary waiting periods via adaptive reception duration.

</details>


### [13] [Dynamic Leader-Follower Consensus with Adversaries: A Multi-Hop Relay Approach](https://arxiv.org/abs/2511.19327)
*Liwei Yuan,Hideaki Ishii*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 시스템에서의 회복력 있는 동적 리더-팔로워 합의에 대해 다룬다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 리더의 동적/시간 변화 기준 값을 정확히 추적하도록 하는 분산 프로토콜을 개발하는 것이 목적이다.

Method: 첫 번째 또는 두 번째 동적 시스템을 갖는 에이전트들이 여러 홉 통신을 통해 상호 작용하며 평균 부분 수열 축소 알고리즘을 사용하였다.

Result: 우리의 추적 오차 경계는 기존 방법보다 작으며, 리레이를 사용하지 않을 때 우리의 조건이 문헌의 충분 조건보다 더 강력함을 강조한다.

Conclusion: 다중 홉 리레이를 사용할 경우 더 완화된 그래프 요구 사항을 얻을 수 있으며, 알고리즘의 유효성을 검증하기 위한 수치 예제를 제시하였다.

Abstract: This paper examines resilient dynamic leader-follower consensus within multi-agent systems, where agents share first-order or second-order dynamics. The aim is to develop distributed protocols enabling nonfaulty/normal followers to accurately track a dynamic/time-varying reference value of the leader while they may receive misinformation from adversarial neighbors. Our methodologies employ the mean subsequence reduced algorithm with agents engaging with neighbors using multi-hop communication. We accordingly derive a necessary and sufficient graph condition for our algorithms to succeed; also, our tracking error bounds are smaller than that of the existing method. Furthermore, it is emphasized that even when agents do not use relays, our condition is tighter than the sufficient conditions in the literature. With multi-hop relays, we can further obtain more relaxed graph requirements. Finally, we present numerical examples to verify the effectiveness of our algorithms.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [14] [MURMUR: Using cross-user chatter to break collaborative language agents in groups](https://arxiv.org/abs/2511.17671)
*Atharv Singh Patlan,Peiyao Sheng,S. Ashwin Hebbar,Prateek Mittal,Pramod Viswanath*

Main category: cs.CR

TL;DR: 언어 에이전트는 단일 사용자 보조에서 다중 사용자 협업으로 확대되고 있지만, 현재의 언어 모델은 사용자 상호작용 및 동시 작업을 격리하는 메커니즘이 부족하여 교차 사용자 변조(CUP)라는 새로운 공격 벡터가 발생하고 있다.


<details>
  <summary>Details</summary>
Motivation: 다중 사용자 환경에서의 언어 모델의 안전성 확보.

Method: MURMUR라는 프레임워크를 사용하여 단일 사용자 작업을 동시 그룹 기반 시나리오로 조합하고 LLM을 활용하여 사실적이고 역사-aware 사용자 상호작용을 생성.

Result: CUP 공격이 높은 비율로 성공하고 그 영향이 여러 작업에 걸쳐 지속됨을 확인하였다.

Conclusion: 작업 기반 클러스터링을 통한 새로운 유형의 취약성을 완화하기 위한 첫 단계 방어를 소개한다.

Abstract: Language agents are rapidly expanding from single-user assistants to multi-user collaborators in shared workspaces and groups. However, today's language models lack a mechanism for isolating user interactions and concurrent tasks, creating a new attack vector inherent to this new setting: cross-user poisoning (CUP). In a CUP attack, an adversary injects ordinary-looking messages that poison the persistent, shared state, which later triggers the agent to execute unintended, attacker-specified actions on behalf of benign users. We validate CUP on real systems, successfully attacking popular multi-user agents. To study the phenomenon systematically, we present MURMUR, a framework that composes single-user tasks into concurrent, group-based scenarios using an LLM to generate realistic, history-aware user interactions. We observe that CUP attacks succeed at high rates and their effects persist across multiple tasks, thus posing fundamental risks to multi-user LLM deployments. Finally, we introduce a first-step defense with task-based clustering to mitigate this new class of vulnerability

</details>


### [15] [Towards Automating Data Access Permissions in AI Agents](https://arxiv.org/abs/2511.17959)
*Yuhao Wu,Ke Yang,Franziska Roesner,Tadayoshi Kohno,Ning Zhang,Umar Iqbal*

Main category: cs.CR

TL;DR: AI 에이전트가 사용자를 대신하여 자율적으로 행동하려고 할 때, 투명성과 통제 문제를 제기한다. 전통적인 권한 모델은 자동화된 에이전트 실행 패러다임에 적합하지 않으며, 권한 기반 접근 제어가 필수적이라는 점을 강조한다. 이 연구에서는 사용자 연구를 통해 권한 결정에 영향을 미치는 요소를 식별하고, 이를 ML 기반 권한 관리 도우미에 인코딩하여 사용자 의사 결정을 예측하는 자동화된 권한 관리 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 사용자 대신 자율적으로 행동하는 과정에서 투명성과 통제 문제가 발생합니다. 이에 따라 사용자에게 의미 있는 통제를 제공하기 위해 권한 기반 접근 제어가 필수적이라는 점을 주장합니다.

Method: 사용자 연구를 실시하여 사용자의 권한 결정에 영향을 미치는 요소를 식별하고, 이러한 요소를 바탕으로 미래의 사용자 결정을 예측할 수 있는 ML 기반 권한 관리 도우미를 개발합니다.

Result: 참여자들의 권한 결정은 커뮤니케이션 맥락에 영향을 받으며, 개인의 선호는 맥락 내에서 일관되게 유지되고 다른 참여자와 align 됩니다. 이를 바탕으로 85.1%의 전체 정확도와 94.4%의 높은 신뢰도 예측의 모델을 개발했습니다. 권한 기록을 사용하지 않고도 66.9%의 정확도를 달성하며, 훈련 샘플 수 מעט 증가하면(예: 1-4) 정확도가 10.8% 증가합니다.

Conclusion: 우리는 권한 기반 접근 제어를 통해 AI 에이전트의 자율성을 제어할 수 있는 가능성을 보여줍니다. 이 연구의 결과는 AI 에이전트의 권한 자동 관리 및 예측 모델을 발전시키는 데 기여할 수 있습니다.

Abstract: As AI agents attempt to autonomously act on users' behalf, they raise transparency and control issues. We argue that permission-based access control is indispensable in providing meaningful control to the users, but conventional permission models are inadequate for the automated agentic execution paradigm. We therefore propose automated permission management for AI agents. Our key idea is to conduct a user study to identify the factors influencing users' permission decisions and to encode these factors into an ML-based permission management assistant capable of predicting users' future decisions. We find that participants' permission decisions are influenced by communication context but importantly individual preferences tend to remain consistent within contexts, and align with those of other participants. Leveraging these insights, we develop a permission prediction model achieving 85.1% accuracy overall and 94.4% for high-confidence predictions. We find that even without using permission history, our model achieves an accuracy of 66.9%, and a slight increase of training samples (i.e., 1-4) can substantially increase the accuracy by 10.8%.

</details>


### [16] [Correlated-Sequence Differential Privacy](https://arxiv.org/abs/2511.18025)
*Yifan Luo,Meng Zhang,Jin Xu,Junting Chen,Jianwei Huang*

Main category: cs.CR

TL;DR: 상관 관계를 가진 순차적 데이터의 프라이버시를 보존하기 위한 Correlated-Sequence Differential Privacy (CSDP) 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 의료, 금융 및 스마트 시티 제어에서 예측 개선을 위한 데이터 스트림의 상관 관계 활용.

Method: CSDP는 다변량 스트림을 Coupling Markov Chain으로 모델링하고, 공격자가 얻는 추가 정보의 양을 정량화하며, 데이터 유용성을 유지하면서 해당 정보를 숨기기 위해 노이즈를 추가합니다.

Result: CSDP는 기존의 상관-DP 방법보다 약 50%의 프라이버시-유용성 균형 개선을 보였고, 표준 DP 접근 방식에 비해 두 배의 정도 향상되었습니다.

Conclusion: CSDP는 필요한 프라이버시 보장을 제공하고 데이터의 유용성을 저해하지 않으면서 상관 관계를 가진 순차적 데이터의 프라이버시를 효과적으로 유지합니다.

Abstract: Data streams collected from multiple sources are rarely independent. Values evolve over time and influence one another across sequences. These correlations improve prediction in healthcare, finance, and smart-city control yet violate the record-independence assumption built into most Differential Privacy (DP) mechanisms. To restore rigorous privacy guarantees without sacrificing utility, we introduce Correlated-Sequence Differential Privacy (CSDP), a framework specifically designed for preserving privacy in correlated sequential data. CSDP addresses two linked challenges: quantifying the extra information an attacker gains from joint temporal and cross-sequence links, and adding just enough noise to hide that information while keeping the data useful. We model multivariate streams as a Coupling Markov Chain, yielding the derived loose leakage bound expressed with a few spectral terms and revealing a counterintuitive result: stronger coupling can actually decrease worst-case leakage by dispersing perturbations across sequences. Guided by these bounds, we build the Freshness-Regulated Adaptive Noise (FRAN) mechanism--combining data aging, correlation-aware sensitivity scaling, and Laplace noise--that runs in linear time. Tests on two-sequence datasets show that CSDP improves the privacy-utility trade-off by approximately 50% over existing correlated-DP methods and by two orders of magnitude compared to the standard DP approach.

</details>


### [17] [ASTRA: Agentic Steerability and Risk Assessment Framework](https://arxiv.org/abs/2511.18114)
*Itay Hazan,Yael Mathov,Guy Shtar,Ron Bitton,Itsik Mantin*

Main category: cs.CR

TL;DR: 이 논문은 LLM(대형 언어 모델)을 기반으로 한 AI 에이전트의 보안을 다룬다. ASTRA라는 프레임워크를 통해 사용자 정의 가이드라인을 설정하고, 다양한 자율 에이전트를 테스트하여 보안 능력을 평가한다.


<details>
  <summary>Details</summary>
Motivation: LLM에 의해 구동되는 AI 에이전트의 보안은 현대 AI 보안에서 가장 중요한 과제 중 하나이며, 기존 소프트웨어와는 다른 위험을 초래한다.

Method: ASTRA 프레임워크를 사용하여 다양한 자율 에이전트를 시뮬레이션하고, 새로운 공격 스위트에 대해 테스트하여 LLM의 정책 집행 능력을 평가한다.

Result: 13개의 오픈 소스 LLM을 평가하여 이들이 보안을 유지하는 능력에서 놀라운 차이를 발견했다.

Conclusion: 이 연구의 목적은 더 안전하고 신뢰할 수 있는 에이전트 AI 시스템을 구축하기 위한 강력하고 통합된 방법론을 제공하는 것이다.

Abstract: Securing AI agents powered by Large Language Models (LLMs) represents one of the most critical challenges in AI security today. Unlike traditional software, AI agents leverage LLMs as their "brain" to autonomously perform actions via connected tools. This capability introduces significant risks that go far beyond those of harmful text presented in a chatbot that was the main application of LLMs. A compromised AI agent can deliberately abuse powerful tools to perform malicious actions, in many cases irreversible, and limited solely by the guardrails on the tools themselves and the LLM ability to enforce them. This paper presents ASTRA, a first-of-its-kind framework designed to evaluate the effectiveness of LLMs in supporting the creation of secure agents that enforce custom guardrails defined at the system-prompt level (e.g., "Do not send an email out of the company domain," or "Never extend the robotic arm in more than 2 meters").
  Our holistic framework simulates 10 diverse autonomous agents varying between a coding assistant and a delivery drone equipped with 37 unique tools. We test these agents against a suite of novel attacks developed specifically for agentic threats, inspired by the OWASP Top 10 but adapted to challenge the ability of the LLM for policy enforcement during multi-turn planning and execution of strict tool activation. By evaluating 13 open-source, tool-calling LLMs, we uncovered surprising and significant differences in their ability to remain secure and keep operating within their boundaries. The purpose of this work is to provide the community with a robust and unified methodology to build and validate better LLMs, ultimately pushing for more secure and reliable agentic AI systems.

</details>


### [18] [eBPF-PATROL: Protective Agent for Threat Recognition and Overreach Limitation using eBPF in Containerized and Virtualized Environments](https://arxiv.org/abs/2511.18155)
*Sangam Ghimire,Nirjal Bhurtel,Roshan Sahani,Sudan Jha*

Main category: cs.CR

TL;DR: eBPF-PATROL은 컨테이너화 및 가상화 환경에서 보안 정책을 모니터링하고 시행하기 위한 경량 런타임 보안 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: 클라우드 및 클라우드 네이티브 컴퓨팅의 증가로 인해 엄격한 격리와 런타임 보안을 유지하는 것이 점점 더 어려워지고 있다. 기존의 보안 방법들은 한계가 있다.

Method: eBPF-PATROL은 확장된 Berkeley 패킷 필터 기술을 이용하여 시스템 호출을 가로채고 실행 맥락을 분석하며 사용자가 정의한 규칙을 적용한다.

Result: 실제 공격 시나리오에서 2.5% 미만의 낮은 오버헤드와 높은 탐지 정확도를 보여준다.

Conclusion: eBPF-PATROL은 런타임 보안 위반을 실시간으로 감지하고 방지할 수 있다.

Abstract: With the increasing use and adoption of cloud and cloud-native computing, the underlying technologies (i.e., containerization and virtualization) have become foundational. However, strict isolation and maintaining runtime security in these environments has become increasingly challenging. Existing approaches like seccomp and Mandatory Access Control (MAC) frameworks offer some protection up to a limit, but often lack context awareness, syscall argument filtering, and adaptive enforcement, providing the ability to adjust decisions at runtime based on observed application behavior, workload changes, or detected anomalies rather than relying solely on static or predefined rules.This paper introduces eBPF-PATROL (eBPF-Protective Agent for Threat Recognition and Overreach Limitation), an extensible lightweight runtime security agent that uses extended Berkeley Packet Filter (eBPF) technology to monitor and enforce policies in containerized and virtualized environments. By intercepting system calls, analyzing execution context, and applying user-defined rules, eBPF-PATROL detects and prevents real-time boundary violations, such as reverse shells, privilege escalation, and container escape attempts. We describe the architecture, implementation, and evaluation of eBPF-PATROL, demonstrating its low overhead (< 2.5 percent) and high detection accuracy across real-world attack scenarios.

</details>


### [19] [LLMs as Firmware Experts: A Runtime-Grown Tree-of-Agents Framework](https://arxiv.org/abs/2511.18438)
*Xiangrui Zhang,Zeyu Chen,Haining Wang,Qiang Li*

Main category: cs.CR

TL;DR: FIRMHIVE는 대형 펌웨어의 코드 추론 및 취약성 탐지를 자동화하는 LLM 기반의 자율 펌웨어 보안 분석 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 대형 펌웨어에 적용할 때 LLM의 성능 저하 문제를 해결하기 위해서이다.

Method: FIRMHIVE는 대리 위임의 접근 방식을 에이전트 단위의 실행 가능 원시로 변환하고, 분산 조정을 위한 런타임 에이전트 트리를 구성하는 두 가지 핵심 메커니즘을 도입한다.

Result: FIRMHIVE는 기존 LLM-에이전트 기준선에 비해 약 16배 더 많은 추론 단계를 수행하고, 약 2.3배 많은 파일을 검사하여 펌웨어 당 약 5.6배 더 많은 경고를 생성한다.

Conclusion: FIRMHIVE는 최첨단 보안 도구에 비해 약 1.5배 더 많은 취약성을 식별하고 71%의 정밀도를 달성하여 수확량과 신뢰성 모두에서 상당한 개선을 보여준다.

Abstract: Large Language Models (LLMs) and their agent systems have recently demonstrated strong potential in automating code reasoning and vulnerability detection. However, when applied to large-scale firmware, their performance degrades due to the binary nature of firmware, complex dependency structures, and heterogeneous components. To address this challenge, this paper presents FIRMHIVE, a recursive agent hive that enables LLMs to act as autonomous firmware security analysts. FIRMHIVE introduces two key mechanisms: (1) transforming delegation into a per-agent, executable primitive and (2) constructing a runtime Tree of Agents (ToA) for decentralized coordination. We evaluate FIRMHIVE using real-world firmware images obtained from publicly available datasets, covering five representative security analysis tasks. Compared with existing LLM-agent baselines, FIRMHIVE performs deeper (about 16x more reasoning steps) and broader (about 2.3x more files inspected) cross-file exploration, resulting in about 5.6x more alerts per firmware. Compared to state-of-the-art (SOTA) security tools, FIRMHIVE identifies about 1.5x more vulnerabilities (1,802 total) and achieves 71% precision, representing significant improvements in both yield and fidelity.

</details>


### [20] [Shadows in the Code: Exploring the Risks and Defenses of LLM-based Multi-Agent Software Development Systems](https://arxiv.org/abs/2511.18467)
*Xiaoqing Wang,Keman Huang,Bin Liang,Hongyu Li,Xiaoyong Du*

Main category: cs.CR

TL;DR: LLM 기반 다중 에이전트 시스템이 소프트웨어 개발을 혁신하였으나 보안 위험이 존재한다. MU-BA 및 BU-MA 시나리오에서 IMBIA 공격을 소개하고 방어 기제를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 개발의 민주화가 진행되고 있지만 새로운 보안 위험이 탐구되지 않았다.

Method: IMBIA 공격을 도입하고 Adv-IMBIA를 방어 메커니즘으로 제안한다.

Result: MU-BA 및 BU-MA 시나리오에서 IMBIA의 공격 성공률이 각각 93%, 45%, 71% 및 71%, 84%, 45%였다.

Conclusion: 다중 에이전트 소프트웨어 개발 시스템에서 강력한 보안 조치의 필요성을 강조하고, 방어 전략을 구현하기 위한 실용 가이드를 제공한다.

Abstract: The rapid advancement of Large Language Model (LLM)-driven multi-agent systems has significantly streamlined software developing tasks, enabling users with little technical expertise to develop executable applications. While these systems democratize software creation through natural language requirements, they introduce significant security risks that remain largely unexplored. We identify two risky scenarios: Malicious User with Benign Agents (MU-BA) and Benign User with Malicious Agents (BU-MA). We introduce the Implicit Malicious Behavior Injection Attack (IMBIA), demonstrating how multi-agent systems can be manipulated to generate software with concealed malicious capabilities beneath seemingly benign applications, and propose Adv-IMBIA as a defense mechanism. Evaluations across ChatDev, MetaGPT, and AgentVerse frameworks reveal varying vulnerability patterns, with IMBIA achieving attack success rates of 93%, 45%, and 71% in MU-BA scenarios, and 71%, 84%, and 45% in BU-MA scenarios. Our defense mechanism reduced attack success rates significantly, particularly in the MU-BA scenario. Further analysis reveals that compromised agents in the coding and testing phases pose significantly greater security risks, while also identifying critical agents that require protection against malicious user exploitation. Our findings highlight the urgent need for robust security measures in multi-agent software development systems and provide practical guidelines for implementing targeted, resource-efficient defensive strategies.

</details>


### [21] [LockForge: Automating Paper-to-Code for Logic Locking with Multi-Agent Reasoning LLMs](https://arxiv.org/abs/2511.18531)
*Akashdeep Saha,Zeng Wang,Prithwish Basu Roy,Johann Knechtel,Ozgur Sinanoglu,Ramesh Karri*

Main category: cs.CR

TL;DR: LockForge는 논문에서 LL 설명을 실행 가능하고 테스트된 코드로 변환하는 최초의 다중 에이전트 LLM 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 기반 잠금 기술(LL)의 재현성 문제 해결.

Method: LLL 설명을 코딩하고 검증하는 다단계 파이프라인을 구현하여 LL 모델을 평가하는 두 단계의 검증 프로세스를 설계.

Result: 10개의 주요 LL 스킴에 대해 LockForge를 적용하였으며, 복잡한 작업임을 입증했습니다.

Conclusion: LockForge는 LL 연구의 평가를 위한 재현 가능하고 공정한 기반을 제공합니다.

Abstract: Despite rapid progress in logic locking (LL), reproducibility remains a challenge as codes are rarely made public. We present LockForge, a first-of-its-kind, multi-agent large language model (LLM) framework that turns LL descriptions in papers into executable and tested code. LockForge provides a carefully crafted pipeline realizing forethought, implementation, iterative refinement, and a multi-stage validation, all to systematically bridge the gap between prose and practice for complex LL schemes. For validation, we devise (i) an LLM-as-Judge stage with a scoring system considering behavioral checks, conceptual mechanisms, structural elements, and reproducibility on benchmarks, and (ii) an independent LLM-as-Examiner stage for ground-truth assessment. We apply LockForge to 10 seminal LL schemes, many of which lack reference implementations. Our evaluation on multiple SOTA LLMs, including ablation studies, reveals the significant complexity of the task. We show that an advanced reasoning model and a sophisticated, multi-stage framework like LockForge are required. We release all implementations and benchmarks, providing a reproducible and fair foundation for evaluation of further LL research.

</details>


### [22] [FHE-Agent: Automating CKKS Configuration for Practical Encrypted Inference via an LLM-Guided Agentic Framework](https://arxiv.org/abs/2511.18653)
*Nuo Xu,Zhaoting Gong,Ran Ran,Jinwei Tang,Wujie Wen,Caiwen Ding*

Main category: cs.CR

TL;DR: FHE-Agent는 Fully Homomorphic Encryption (CKKS 스킴)을 실용적으로 구현하기 위해 전문가의 지식을 자동화하는 프레임워크입니다. 이를 통해 기존의 고정된 휴리스틱에 의존하는 컴파일러의 한계를 극복하고 더 나은 성능을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: Fully Homomorphic Encryption (FHE) 특히 CKKS 스킴은 개인 정보 보호가 가능한 MLaaS를 가능하게 하지만, 실용적인 배포에는 전문 지식에 크게 의존하는 문제가 있습니다.

Method: FHE-Agent는 Large Language Model (LLM) 컨트롤러와 결정론적 도구 집합을 결합하여 전역 매개변수 선택과 레이어별 병목 수정을 통해 검색 과정을 자동화합니다.

Result: FHE-Agent는 MLP, LeNet, LoLa와 같은 표준 벤치마크 및 더 깊은 아키텍처(AlexNet)에서 일관되게 나은 정밀도와 낮은 대기 시간을 제공합니다.

Conclusion: 복잡한 모델의 경우 FHE-Agent는 기존의 휴리스틱과 단일 요청이 유효한 구성을 생성하지 못하는 상황에서도 128비트 보안 구성을 자동으로 발견합니다.

Abstract: Fully Homomorphic Encryption (FHE), particularly the CKKS scheme, is a promising enabler for privacy-preserving MLaaS, but its practical deployment faces a prohibitive barrier: it heavily relies on domain expertise. Configuring CKKS involves a tightly coupled space of ring dimensions, modulus chains, and packing layouts. Without deep cryptographic knowledge to navigate these interactions, practitioners are restricted to compilers that rely on fixed heuristics. These "one-shot" tools often emit rigid configurations that are either severely over-provisioned in latency or fail to find a feasible solution entirely for deeper networks.
  We present FHE-Agent, an agentic framework that automates this expert reasoning process. By coupling a Large Language Model (LLM) controller with a deterministic tool suite, FHE-Agent decomposes the search into global parameter selection and layer-wise bottleneck repair. The agents operate within a multi-fidelity workflow, pruning invalid regimes using cheap static analysis and reserving expensive encrypted evaluations for the most promising candidates.
  We instantiate FHE-Agent on the Orion compiler and evaluate it on standard benchmarks (MLP, LeNet, LoLa) and deeper architectures (AlexNet). FHE-Agent consistently achieves better precision and lower latency than naïve search strategies. Crucially, it automatically discovers feasible, 128-bit secure configurations for complex models where baseline heuristics and one-shot prompts fail to produce a valid setup.

</details>


### [23] [Defending Large Language Models Against Jailbreak Exploits with Responsible AI Considerations](https://arxiv.org/abs/2511.18933)
*Ryan Wong,Hosea David Yu Fei Ng,Dhananjai Sharma,Glenn Jun Jie Ng,Kavishvaran Srinivasan*

Main category: cs.CR

TL;DR: 본 연구는 대형 언어 모델(LLM)의 탈옥 공격에 대한 방어 전략을 제시하며, 서로 다른 방어 접근 방식을 분류하고 효과를 평가한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)은 안전 필터를 우회하여 유해하거나 비윤리적인 행동을 유도할 수 있는 탈옥 공격에 취약하다.

Method: 프롬프트 수준, 모델 수준 및 훈련 시간의 개입 방식을 통한 탈옥 방어 전략을 체계적으로 분류하고, 세 가지 방어 전략을 제안한다. 프롬프트 수준 방어 프레임워크는 적대적인 입력을 탐지하고 중화하며, 로짓 기반 조향 방어는 안전이 중요한 레이어에서 추론 시간 벡터 조향을 통해 거부 행동을 강화하고, 도메인 특정 에이전트 방어는 MetaGPT 프레임워크를 사용하여 구조적이고 역할 기반의 협력 및 도메인 준수를 시행한다.

Result: 벤치마크 데이터세트에 대한 실험을 통해 공격 성공률이 상당히 감소하고, 에이전트 기반 방어 하에서 완전한 완화가 달성됨을 보여준다.

Conclusion: 이 연구는 탈옥이 LLM에 중대한 보안 위협이 됨을 강조하고 예방을 위한 주요 개입점을 식별하며, 방어 전략이 종종 안전성, 성능 및 확장성 간의 균형을 포함한다는 점을 지적한다.

Abstract: Large Language Models (LLMs) remain susceptible to jailbreak exploits that bypass safety filters and induce harmful or unethical behavior. This work presents a systematic taxonomy of existing jailbreak defenses across prompt-level, model-level, and training-time interventions, followed by three proposed defense strategies. First, a Prompt-Level Defense Framework detects and neutralizes adversarial inputs through sanitization, paraphrasing, and adaptive system guarding. Second, a Logit-Based Steering Defense reinforces refusal behavior through inference-time vector steering in safety-sensitive layers. Third, a Domain-Specific Agent Defense employs the MetaGPT framework to enforce structured, role-based collaboration and domain adherence. Experiments on benchmark datasets show substantial reductions in attack success rate, achieving full mitigation under the agent-based defense. Overall, this study highlights how jailbreaks pose a significant security threat to LLMs and identifies key intervention points for prevention, while noting that defense strategies often involve trade-offs between safety, performance, and scalability. Code is available at: https://github.com/Kuro0911/CS5446-Project

</details>


### [24] [Medusa: Cross-Modal Transferable Adversarial Attacks on Multimodal Medical Retrieval-Augmented Generation](https://arxiv.org/abs/2511.19257)
*Yingjia Shang,Yi Liu,Huimin Wang,Furong Li,Wenfang Sun,Wu Chengyu,Yefeng Zheng*

Main category: cs.CR

TL;DR: 이 논문은 MMed-RAG 시스템에 대한 새로운 적대적 공격 프레임워크인 Medusa를 제안하며, 이는 다양한 의료 작업에서 높은 성공률을 보인다.


<details>
  <summary>Details</summary>
Motivation: MMed-RAG 시스템이 임상 의사 결정 지원에 점점 더 많이 채택되고 있으며, 이들의 복잡한 구조가 적대적 취약성을 초래한다는 점에서 기인한다.

Method: Medusa는 다중 긍정적 InfoNCE 손실(MPIL)을 활용하여 의학적으로 그럴듯하지만 악의적인 텍스트 타겟과 적대적 시각 임베딩을 정렬하는 perturbation 최적화 문제로 공격을 공식화한다.

Result: Medusa는 적절한 파라미터 구성 하에 다양한 생성 모델과 검색기에서 90% 이상의 평균 공격 성공률을 달성한다.

Conclusion: 이 연구는 MMed-RAG 시스템의 주요 취약점을 드러내고, 안전-critical 의료 응용 프로그램에서의 견고성 벤치마킹 필요성을 강조한다.

Abstract: With the rapid advancement of retrieval-augmented vision-language models, multimodal medical retrieval-augmented generation (MMed-RAG) systems are increasingly adopted in clinical decision support. These systems enhance medical applications by performing cross-modal retrieval to integrate relevant visual and textual evidence for tasks, e.g., report generation and disease diagnosis. However, their complex architecture also introduces underexplored adversarial vulnerabilities, particularly via visual input perturbations. In this paper, we propose Medusa, a novel framework for crafting cross-modal transferable adversarial attacks on MMed-RAG systems under a black-box setting. Specifically, Medusa formulates the attack as a perturbation optimization problem, leveraging a multi-positive InfoNCE loss (MPIL) to align adversarial visual embeddings with medically plausible but malicious textual targets, thereby hijacking the retrieval process. To enhance transferability, we adopt a surrogate model ensemble and design a dual-loop optimization strategy augmented with invariant risk minimization (IRM). Extensive experiments on two real-world medical tasks, including medical report generation and disease diagnosis, demonstrate that Medusa achieves over 90% average attack success rate across various generation models and retrievers under appropriate parameter configuration, while remaining robust against four mainstream defenses, outperforming state-of-the-art baselines. Our results reveal critical vulnerabilities in the MMed-RAG systems and highlight the necessity of robustness benchmarking in safety-critical medical applications. The code and data are available at https://anonymous.4open.science/r/MMed-RAG-Attack-F05A.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [25] [Enhancing Robustness of Offline Reinforcement Learning Under Data Corruption via Sharpness-Aware Minimization](https://arxiv.org/abs/2511.17568)
*Le Xu,Jiayu Chen*

Main category: cs.LG

TL;DR: 오프라인 강화 학습(RL)은 현실 세계의 데이터 손상에 취약하며, 이를 개선하기 위해 Sharpness-Aware Minimization(SAM)을 적용하여 모델의 강건성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 강화 학습이 데이터 손상에 어떻게 취약한지를 설명하고 이를 해결하기 위한 방법을 제시한다.

Method: 오프라인 RL에 대한 일반적인 최적화 도구로서 Sharpness-Aware Minimization(SAM)을 적용하고, 데이터 손상에 강한 두 가지 알고리즘(IQL, RIQL)에 통합한다.

Result: D4RL 벤치마크에서 SAM을 적용한 방법이 기존 방법들보다 일관되게 우수한 성능을 보인다.

Conclusion: SAM은 오프라인 RL 에이전트의 강건성을 향상시키는 효과적인 기법임을 보여준다.

Abstract: Offline reinforcement learning (RL) is vulnerable to real-world data corruption, with even robust algorithms failing under challenging observation and mixture corruptions. We posit this failure stems from data corruption creating sharp minima in the loss landscape, leading to poor generalization. To address this, we are the first to apply Sharpness-Aware Minimization (SAM) as a general-purpose, plug-and-play optimizer for offline RL. SAM seeks flatter minima, guiding models to more robust parameter regions. We integrate SAM into strong baselines for data corruption: IQL, a top-performing offline RL algorithm in this setting, and RIQL, an algorithm designed specifically for data-corruption robustness. We evaluate them on D4RL benchmarks with both random and adversarial corruption. Our SAM-enhanced methods consistently and significantly outperform the original baselines. Visualizations of the reward surface confirm that SAM finds smoother solutions, providing strong evidence for its effectiveness in improving the robustness of offline RL agents.

</details>


### [26] [Binary BPE: A Family of Cross-Platform Tokenizers for Binary Analysis](https://arxiv.org/abs/2511.17573)
*Michael J. Bommarito*

Main category: cs.LG

TL;DR: 바이너리 분석을 위한 순차 모델이 바이트 수준의 토큰화로 병목 현상을 겪고 있는 문제를 해결하기 위한 Binary BPE 토크나이저 패밀리를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 바이트 수준 토큰화 방식은 컨텍스트 윈도우 용량을 낭비하고, 많은 기존 텍스트 중심 토크나이저는 임의의 바이트 시퀀스에 실패한다.

Method: Binary BPE 토크나이저 패밀리는 다양한 플랫폼, 아키텍처 및 운영 체제를 지원하는 대규모 바이너리 코퍼스를 기반으로 훈련된 교차 플랫폼 Byte Pair Encoding(BPE) 토크나이저의 세트이다.

Result: Binary BPE 토크나이저는 고정 길이 변환기 컨텍스트 윈도우당 약 2-3배 더 많은 바이너리 콘텐츠를 허용하며, 여러 바이트 압축을 수행하여 효율성을 높인다.

Conclusion: 훈련된 Binary BPE 토크나이저를 HuggingFace에 공개하여 바이너리 중심 언어 모델과 컨텍스트 효율적인 도구를 위한 오픈 소스 기반을 제공한다.

Abstract: Sequence models for binary analysis are bottlenecked by byte-level tokenization: raw bytes waste precious context window capacity for transformers and other neural network architectures, and many existing text-oriented tokenizers fail on arbitrary 0x00--0xFF sequences. To address this issue, we introduce the Binary BPE tokenizer family, a set of cross-platform Byte Pair Encoding (BPE) tokenizers for executables trained on a large corpus of binaries spanning multiple platforms, architectures, and operating systems, including Linux, Windows, macOS, Android, and malware sources. We release trained tokenizers with vocabularies of 4K, 8K, 16K, 32K, and 64K tokens, enabling both systematic scaling studies and practical deployment from resource-constrained edge devices to high-throughput datacenters. These tokenizers discover interpretable patterns (ELF/PE headers, instruction sequences, cross-platform strings) while yielding multi-byte compression per token. On representative uncompressed executables (e.g., ELF/PE/Mach-O rather than compressed APKs), the Binary BPE tokenizers typically allow for roughly 2-3x more binary content per fixed-length transformer context window than raw bytes, enabling more efficient research and practical deployment for content identification, malware detection, reverse engineering, and optimization. We release the trained Binary BPE tokenizers on HuggingFace, providing a drop-in, open-source foundation for binary-focused language models and context-efficient agentic tools.

</details>


### [27] [Llamazip: Leveraging LLaMA for Lossless Text Compression and Training Dataset Detection](https://arxiv.org/abs/2511.17589)
*Sören Dréano,Derek Molloy,Noel Murphy*

Main category: cs.LG

TL;DR: Llamazip은 LLaMA3 언어 모델의 예측 기능을 기반으로 한 새로운 무손실 텍스트 압축 알고리즘이다.


<details>
  <summary>Details</summary>
Motivation: 데이터 출처, 지적 재산권 및 언어 모델 훈련의 투명성에 대한 주요 문제를 해결하기 위해 Llamazip을 개발하였다.

Method: 모델이 예측하지 못한 토큰만 저장하여 저장 효율성을 최적화한다.

Result: 압축 비율과 계산 요구 사항에 대한 영향을 분석하였고, 문서가 언어 모델 훈련 데이터셋의 일부였는지 식별할 수 있는 가능성을 보여준다.

Conclusion: Llamazip은 데이터 무결성을 유지하면서 저장 공간을 효율적으로 사용할 수 있는 잠재력을 지니고 있다.

Abstract: This work introduces Llamazip, a novel lossless text compression algorithm based on the predictive capabilities of the LLaMA3 language model. Llamazip achieves significant data reduction by only storing tokens that the model fails to predict, optimizing storage efficiency without compromising data integrity. Key factors affecting its performance, including quantization and context window size, are analyzed, revealing their impact on compression ratios and computational requirements. Beyond compression, Llamazip demonstrates the potential to identify whether a document was part of the training dataset of a language model. This capability addresses critical concerns about data provenance, intellectual property, and transparency in language model training.

</details>


### [28] [Neurocircuitry-Inspired Hierarchical Graph Causal Attention Networks for Explainable Depression Identification](https://arxiv.org/abs/2511.17622)
*Weidao Chen,Yuxiao Yang,Yueming Wang*

Main category: cs.LG

TL;DR: 이 논문에서는 우울증 진단을 위한 신경과학 지식을 활용한 딥러닝 기반의 NH-GCAT 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 우울증에 대한 기존의 데이터 기반 접근 방식은 흑박스 모델로 작동하여 신경생물학적 해석력이 부족합니다.

Method: NH-GCAT는 우울증 관련 메커니즘을 여러 공간적 규모에서 명시적이고 계층적으로 모델링합니다.

Result: REST-meta-MDD 데이터셋에 대한 철저한 교차검증을 통해 NH-GCAT이 73.3%의 정확도와 76.4%의 AUROC를 달성함을 보여줍니다.

Conclusion: NH-GCAT은 우울증 분류에서 최첨단 성능을 발휘하며 신경생물학적으로 의미 있는 설명을 제공합니다.

Abstract: Major Depressive Disorder (MDD), affecting millions worldwide, exhibits complex pathophysiology manifested through disrupted brain network dynamics. Although graph neural networks that leverage neuroimaging data have shown promise in depression diagnosis, existing approaches are predominantly data-driven and operate largely as black-box models, lacking neurobiological interpretability. Here, we present NH-GCAT (Neurocircuitry-Inspired Hierarchical Graph Causal Attention Networks), a novel framework that bridges neuroscience domain knowledge with deep learning by explicitly and hierarchically modeling depression-specific mechanisms at different spatial scales. Our approach introduces three key technical contributions: (1) at the local brain regional level, we design a residual gated fusion module that integrates temporal blood oxygenation level dependent (BOLD) dynamics with functional connectivity patterns, specifically engineered to capture local depression-relevant low-frequency neural oscillations; (2) at the multi-regional circuit level, we propose a hierarchical circuit encoding scheme that aggregates regional node representations following established depression neurocircuitry organization, and (3) at the multi-circuit network level, we develop a variational latent causal attention mechanism that leverages a continuous probabilistic latent space to infer directed information flow among critical circuits, characterizing disease-altered whole-brain inter-circuit interactions. Rigorous leave-one-site-out cross-validation on the REST-meta-MDD dataset demonstrates NH-GCAT's state-of-the-art performance in depression classification, achieving a sample-size weighted-average accuracy of 73.3\% and an AUROC of 76.4\%, while simultaneously providing neurobiologically meaningful explanations.

</details>


### [29] [Rectifying Mean-Shift in Cascaded Precipitation Nowcasting](https://arxiv.org/abs/2511.17628)
*Fanbo Ju,Haiyuan Shi,Qingjian Ni*

Main category: cs.LG

TL;DR: RectiCast는 강우 예측을 위해 평균장 이동 보정과 지역적 변동성을 분리하는 2단계 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 정확한 강우 예측을 위해 현재의 레이더 관측을 활용한 고해상도 강우 예측의 필요성이 있다.

Method: RectiCast는 2단계 구조로, 첫 번째 단계에서 결정론적 모델이 후방 평균을 생성하고, 두 번째 단계에서 Rectifier가 분포 이동을 학습하여 수정된 평균을 생성하며, 그 후 Generator가 수정된 평균을 조건으로 지역적 변동성을 모델링한다.

Result: SEVIR와 MeteoNet에서의 실험 결과, RectiCast는 기존의 최첨단 방법에 비해 상당한 성능 향상을 보였다.

Conclusion: RectiCast는 결정론적 예측의 분포 이동과 지역적 변동성을 명확히 분리하여 강우 예측의 정확성을 개선한다.

Abstract: Precipitation nowcasting, which aims to provide high spatio-temporal resolution precipitation forecasts by leveraging current radar observations, is a core task in regional weather forecasting. The cascaded architecture has emerged as the mainstream paradigm for deep learning-based precipitation nowcasting. This paradigm involves a deterministic model to predict macroscopic trends (or posterior mean), followed by a probabilistic model to generate local details (or local stochasticity). However, existing methods commonly overlook the conflation of the systematic distribution shift in deterministic predictions and the local stochasticity. As a result, the deterministic component's distribution shift contaminates the predictions of the probabilistic component, leading to inaccuracies in precipitation patterns and intensity, particularly over longer lead times. To address this issue, we introduce RectiCast, a two-stage framework that explicitly decouples the correction of mean-field shift from the generation of local stochasticity via a dual Flow Matching model. In the first stage, a deterministic model generates the posterior mean. In the second stage, we introduce a Rectifier to explicitly learn the distribution shift and produce a rectified mean. Subsequently, a Generator focuses on modeling the local stochasticity conditioned on the rectified mean. Experiments on SEVIR and MeteoNet demonstrate that RectiCast achieves significant performance improvements over existing state-of-the-art methods.

</details>


### [30] [Can we use LLMs to bootstrap reinforcement learning? -- A case study in digital health behavior change](https://arxiv.org/abs/2511.17630)
*Nele Albers,Esra Cemre Su de Groot,Loes Keijsers,Manon H. Hillegers,Emiel Krahmer*

Main category: cs.LG

TL;DR: 전자 건강 행동 변화 응용 프로그램을 개인화하는 것은 더 매력적이고 효과적으로 만드는 유망한 방법이다. 그러나 이러한 접근을 개발하는 것은 많은 디자인 선택을 요구하며, 그 효과를 예측하기 어렵고 실질적으로 평가하는 데 비용이 많이 든다. 본 연구에서는 대규모 언어 모델(LLM)이 실제 사용자 상호작용 샘플을 생성하는 데 유용할 수 있는지 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 응용 프로그램의 개인화는 그들의 효과를 높이고 사용자의 참여를 증진할 수 있는 가능성이 있다.

Method: 대규모 언어 모델을 사용하여 사용자 상호작용 샘플을生成하고 이를 행동 변화 설정의 강화 학습 모델 훈련에 활용했다.

Result: LLM生成 샘플이 실제 데이터가 없을 경우에도 유용할 수 있음을 보여주고, 인간 평가자와의 비교에서 성능이 동등하다는 것을 입증했다.

Conclusion: LLM生成 샘플이 실제에서 유용하게 사용될 수 있는 방법에 대한 권장 사항을 제공한다.

Abstract: Personalizing digital applications for health behavior change is a promising route to making them more engaging and effective. This especially holds for approaches that adapt to users and their specific states (e.g., motivation, knowledge, wants) over time. However, developing such approaches requires making many design choices, whose effectiveness is difficult to predict from literature and costly to evaluate in practice. In this work, we explore whether large language models (LLMs) can be used out-of-the-box to generate samples of user interactions that provide useful information for training reinforcement learning models for digital behavior change settings. Using real user data from four large behavior change studies as comparison, we show that LLM-generated samples can be useful in the absence of real data. Comparisons to the samples provided by human raters further show that LLM-generated samples reach the performance of human raters. Additional analyses of different prompting strategies including shorter and longer prompt variants, chain-of-thought prompting, and few-shot prompting show that the relative effectiveness of different strategies depends on both the study and the LLM with also relatively large differences between prompt paraphrases alone. We provide recommendations for how LLM-generated samples can be useful in practice.

</details>


### [31] [Smart Manufacturing: MLOps-Enabled Event-Driven Architecture for Enhanced Control in Steel Production](https://arxiv.org/abs/2511.17632)
*Bestoun S. Ahmed,Tommaso Azzalin,Andreas Kassler,Andreas Thore,Hans Lindback*

Main category: cs.LG

TL;DR: 디지털 트윈 기반 접근법을 통해 스마트 제조에서 지속 가능성, 효율성 및 비용 효율성을 개선하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 철강 생산 공장의 지속 가능성, 효율성 및 비용 효율성을 개선하기 위해 디지털 트윈 기반의 접근 방식을 탐구한다.

Method: 실시간 센서 데이터를 디지털 트윈으로 통합하는 마이크로 서비스 엣지 컴퓨팅 플랫폼을 기반으로 한다. 디지털 트윈에서 유도로 조절하는 기계 학습 기반 제어 루프를 구현하여 공정 폐기물을 줄이고 운영 품질을 향상시킨다.

Result: 기계 학습 운영(MLOps) 중심의 시스템에서 깊은 강화 학습 기반 에이전트를 사용하여 시스템 상태와 디지털 트윈 간의 상관 관계를 자율적으로 파악하고, 공장 전력 설정 최적화를 위한 수정 작업을 식별한다.

Conclusion: 제조 폐기물을 줄이고 생산 품질을 높이기 위한 이론적 기초, 아키텍처 세부 사항 및 실제적 함의를 제시하며, 다양한 산업 애플리케이션에 적응할 수 있는 유연한 시스템을 설계했다.

Abstract: We explore a Digital Twin-Based Approach for Smart Manufacturing to improve Sustainability, Efficiency, and Cost-Effectiveness for a steel production plant. Our system is based on a micro-service edge-compute platform that ingests real-time sensor data from the process into a digital twin over a converged network infrastructure. We implement agile machine learning-based control loops in the digital twin to optimize induction furnace heating, enhance operational quality, and reduce process waste. Key to our approach is a Deep Reinforcement learning-based agent used in our machine learning operation (MLOps) driven system to autonomously correlate the system state with its digital twin to identify correction actions that aim to optimize power settings for the plant. We present the theoretical basis, architectural details, and practical implications of our approach to reduce manufacturing waste and increase production quality. We design the system for flexibility so that our scalable event-driven architecture can be adapted to various industrial applications. With this research, we propose a pivotal step towards the transformation of traditional processes into intelligent systems, aligning with sustainability goals and emphasizing the role of MLOps in shaping the future of data-driven manufacturing.

</details>


### [32] [CubeletWorld: A New Abstraction for Scalable 3D Modeling](https://arxiv.org/abs/2511.17664)
*Azlaan Mustafa Samad,Hoang H. Nguyen,Lukas Berg,Henrik Müller,Yuan Xue,Daniel Kudenko,Zahra Ahmadi*

Main category: cs.LG

TL;DR: CubeletWorld는 도시 환경을 3D 그리드로 모델링하여 개인 정보를 보호하면서 동시에 다양한 데이터를 활용하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 현대 도시에서 발생하는 다양한 데이터 원천을 통합하여 일관된 공간 모델을 개발하는 것이 큰 도전 과제이다.

Method: CubeletWorld라는 프레임워크를 통해 공간 단위인 큐블렛으로 도시 환경을 모델링하고 분석하며, 에이전트 기반 감지 없이 플래닝 및 예측 작업을 지원한다.

Result: 큐블렛 상태 예측 태스크를 통해 실제 도시 요소를 포함한 데이터셋으로 큐블렛 상태를 예측하였다.

Conclusion: CubeletWorld는 도시 데이터에서 학습하고 시뮬레이션 및 의사결정 지원을 위한 새로운 가능성을 열어주는 유연하고 확장 가능한 프레임워크이다.

Abstract: Modern cities produce vast streams of heterogeneous data, from infrastructure maps to mobility logs and satellite imagery. However, integrating these sources into coherent spatial models for planning and prediction remains a major challenge. Existing agent-centric methods often rely on direct environmental sensing, limiting scalability and raising privacy concerns. This paper introduces CubeletWorld, a novel framework for representing and analyzing urban environments through a discretized 3D grid of spatial units called cubelets. This abstraction enables privacy-preserving modeling by embedding diverse data signals, such as infrastructure, movement, or environmental indicators, into localized cubelet states. CubeletWorld supports downstream tasks such as planning, navigation, and occupancy prediction without requiring agent-driven sensing. To evaluate this paradigm, we propose the CubeletWorld State Prediction task, which involves predicting the cubelet state using a realistic dataset containing various urban elements like streets and buildings through this discretized representation. We explore a range of modified core models suitable for our setting and analyze challenges posed by increasing spatial granularity, specifically the issue of sparsity in representation and scalability of baselines. In contrast to existing 3D occupancy prediction models, our cubelet-centric approach focuses on inferring state at the spatial unit level, enabling greater generalizability across regions and improved privacy compliance. Our results demonstrate that CubeletWorld offers a flexible and extensible framework for learning from complex urban data, and it opens up new possibilities for scalable simulation and decision support in domains such as socio-demographic modeling, environmental monitoring, and emergency response. The code and datasets can be downloaded from here.

</details>


### [33] [Physical Reinforcement Learning](https://arxiv.org/abs/2511.17789)
*Sam Dillavou,Shruti Mishra*

Main category: cs.LG

TL;DR: 이 연구는 CLLN을 사용하여 에너지 제한 자율 시스템에서의 강화 학습 문제를 해결함.


<details>
  <summary>Details</summary>
Motivation: 디지털 컴퓨터는 에너지 소비가 크고 손상된 부품에 민감하여, 불확실한 환경에서 에너지 제한 자율 에이전트가 사용하기 어려운 도구가 됩니다.

Method: Q-learning을 시뮬레이션된 CLLN에 맞게 조정하여 두 가지 간단한 강화 학습 문제에서 성공적인 결과를 보여줍니다.

Result: 네트워크 훈련 외에 RL 도구박스에서 다양한 도구를 구현하는 데 필요한 구성 요소를 명확히 합니다.

Conclusion: CLLN은 디지털 하드웨어가 요구하는 물리적 안전을 무시할 수 있으며, 생물학 시스템에서 중요한 보조 목표들을 강조합니다.

Abstract: Digital computers are power-hungry and largely intolerant of damaged components, making them potentially difficult tools for energy-limited autonomous agents in uncertain environments. Recently developed Contrastive Local Learning Networks (CLLNs) - analog networks of self-adjusting nonlinear resistors - are inherently low-power and robust to physical damage, but were constructed to perform supervised learning. In this work we demonstrate success on two simple RL problems using Q-learning adapted for simulated CLLNs. Doing so makes explicit the components (beyond the network being trained) required to enact various tools in the RL toolbox, some of which (policy function and value function) are more natural in this system than others (replay buffer). We discuss assumptions such as the physical safety that digital hardware requires, CLLNs can forgo, and biological systems cannot rely on, and highlight secondary goals that are important in biology and trainable in CLLNs, but make little sense in digital computers.

</details>


### [34] [APRIL: Annotations for Policy evaluation with Reliable Inference from LLMs](https://arxiv.org/abs/2511.17818)
*Aishwarya Mandyam,Kalyani Limaye,Barbara E. Engelhardt,Emily Alsentzer*

Main category: cs.LG

TL;DR: 본 연구에서는 의료 분야에서의 오프 정책 평가(OPE)를 위한 카운터팩추얼 주석 생성을 위해 대형 언어 모델(LLM)을 활용하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: OPE는 고위험 분야에서의 안전성을 보장하는 데 중요한 역할을 하지만, 기존 방법은 행동 데이터 세트의 크기와 범위에 의해 제한된다.

Method: 우리는 LLM을 사용하여 대체 치료 하에서 주요 임상 특성이 어떻게 변화하는지 예측하는 카운터팩추얼 주석을 생성하는 방법을 제안한다.

Result: 대부분의 경우, LLM 기반의 카운터팩추얼 주석이 OPE 추정치를 상당히 개선한다는 사실을 발견했다.

Conclusion: LLM 기반의 카운터팩추얼 주석은 의료 데이터세트에서의 범위 제한 문제를 해결하기 위한 확장 가능한 접근법을 제공한다.

Abstract: Off-policy evaluation (OPE) estimates the value of a contextual bandit policy prior to deployment. As such, OPE plays a critical role in ensuring safety in high-stakes domains such as healthcare. However, standard OPE approaches are limited by the size and coverage of the behavior dataset. While previous work has explored using expert-labeled counterfactual annotations to enhance dataset coverage, obtaining such annotations is expensive, limiting the scalability of prior approaches. We propose leveraging large language models (LLMs) to generate counterfactual annotations for OPE in medical domains. Our method uses domain knowledge to guide LLMs in predicting how key clinical features evolve under alternate treatments. These predicted features can then be transformed using known reward functions to create counterfactual annotations. We first evaluate the ability of several LLMs to predict clinical features across two patient subsets in MIMIC-IV, finding that state-of-the-art LLMs achieve comparable performance. Building on this capacity to predict clinical features, we generate LLM-based counterfactual annotations and incorporate them into an OPE estimator. Our empirical results analyze the benefits of counterfactual annotations under varying degrees of shift between the behavior and target policies. We find that in most cases, the LLM-based counterfactual annotations significantly improve OPE estimates up to a point. We provide an entropy-based metric to identify when additional annotations cease to be useful. Our results demonstrate that LLM-based counterfactual annotations offer a scalable approach for addressing coverage limitations in healthcare datasets, enabling safer deployment of decision-making policies in clinical settings.

</details>


### [35] [Multi-Agent Cross-Entropy Method with Monotonic Nonlinear Critic Decomposition](https://arxiv.org/abs/2511.18671)
*Yan Wang,Ke Deng,Yongli Ren*

Main category: cs.LG

TL;DR: 이 논문에서는 다중 에이전트 강화 학습에서 발생하는 중앙 집중-분산 실행 불일치를 극복하기 위해 다중 에이전트 교차 엔트로피 방법(MCEM)을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 협력적인 다중 에이전트 강화 학습에서 한 에이전트의 비최적 행동이 다른 에이전트의 학습을 저하시킬 때 발생하는 중앙 집중-분산 불일치 문제를 해결하고자 합니다.

Method: MCEM은 높은 가치의 공동 행동의 확률을 증가시켜 정책을 업데이트하며, 모노토닉 비선형 비평가 분해(NCD)와 결합됩니다.

Result: MCEM은 지속적 및 이산적 행동 벤치마크에서 최첨단 방법보다 우수한 성능을 보입니다.

Conclusion: MCEM은 에이전트 간의 비효율적인 학습을 줄이고 샘플 효율성을 높이며, 기존 방법보다 더 우수한 성과를 달성합니다.

Abstract: Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution (CTDE), where centralized critics leverage global information to guide decentralized actors. However, centralized-decentralized mismatch (CDM) arises when the suboptimal behavior of one agent degrades others' learning. Prior approaches mitigate CDM through value decomposition, but linear decompositions allow per-agent gradients at the cost of limited expressiveness, while nonlinear decompositions improve representation but require centralized gradients, reintroducing CDM. To overcome this trade-off, we propose the multi-agent cross-entropy method (MCEM), combined with monotonic nonlinear critic decomposition (NCD). MCEM updates policies by increasing the probability of high-value joint actions, thereby excluding suboptimal behaviors. For sample efficiency, we extend off-policy learning with a modified k-step return and Retrace. Analysis and experiments demonstrate that MCEM outperforms state-of-the-art methods across both continuous and discrete action benchmarks.

</details>


### [36] [High-Accuracy List-Decodable Mean Estimation](https://arxiv.org/abs/2511.17822)
*Ziyun Chen,Spencer Compton,Daniel Kane,Jerry Li*

Main category: cs.LG

TL;DR: 이 논문에서는 리스트 디코더블 학습에서 정확성과 리스트 크기 간의 균형을 맞출 수 있는 가능성을 탐구하고, 효율적인 알고리즘을 통해 비율 $rac{1}{	ext{α}}$와 관련된 오류 감소를 개선하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 리스트 디코더블 학습에서 정확성과 리스트 크기 간의 트레이드오프 가능성을 조사하고자 합니다.

Method: 정확한 리스트 크기로 문제를 해결하고, 정체 상관 가우시안의 평균 추정에 대한 새로운 알고리즘을 제시합니다.

Result: 최대 크기 $L = 	ext{exp} ig(Oig(rac{	ext{log}^2(1/	ext{α})}{	ext{ε}^2}ig)ig)$의 후보 평균 리스트가 존재하며, 이 중 하나의 요소는 참 평균에 대해 최대 $	ext{ε}$의 $	ext{ℓ}_2$ 거리를 가집니다.

Conclusion: 우리는 새로운 식별 가능성 증명 및 전통적인 방법 없이 이 증명을 활용하는 새로운 알고리즘 접근 방식을 제시함으로써 이 문제에 대한 비율적 고정밀 보증이 가능하다는 것을 보여주었습니다.

Abstract: In list-decodable learning, we are given a set of data points such that an $α$-fraction of these points come from a nice distribution $D$, for some small $α\ll 1$, and the goal is to output a short list of candidate solutions, such that at least one element of this list recovers some non-trivial information about $D$. By now, there is a large body of work on this topic; however, while many algorithms can achieve optimal list size in terms of $α$, all known algorithms must incur error which decays, in some cases quite poorly, with $1 / α$. In this paper, we ask if this is inherent: is it possible to trade off list size with accuracy in list-decodable learning? More formally, given $ε> 0$, can we can output a slightly larger list in terms of $α$ and $ε$, but so that one element of this list has error at most $ε$ with the ground truth? We call this problem high-accuracy list-decodable learning. Our main result is that non-trivial high-accuracy guarantees, both information-theoretically and algorithmically, are possible for the canonical setting of list-decodable mean estimation of identity-covariance Gaussians. Specifically, we demonstrate that there exists a list of candidate means of size at most $L = \exp \left( O\left( \tfrac{\log^2 1 / α}{ε^2} \right)\right)$ so that one of the elements of this list has $\ell_2$ distance at most $ε$ to the true mean. We also design an algorithm that outputs such a list with runtime and sample complexity $n = d^{O(\log L)} + \exp \exp (\widetilde{O}(\log L))$. We do so by demonstrating a completely novel proof of identifiability, as well as a new algorithmic way of leveraging this proof without the sum-of-squares hierarchy, which may be of independent technical interest.

</details>


### [37] [Deterministic Inference across Tensor Parallel Sizes That Eliminates Training-Inference Mismatch](https://arxiv.org/abs/2511.17826)
*Ziyang Zhang,Xinheng Ding,Jiayi Yuan,Rixin Liu,Huizi Mao,Jiarong Xing,Zirui Liu*

Main category: cs.LG

TL;DR: 이 논문은 LLM 애플리케이션에서 결정론적 추론의 중요성을 강조하고, TP 크기에 따른 비결정성 문제를 해결하기 위한 Tree-Based Invariant Kernels(TBIK)를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 애플리케이션에서 결정론적 추론이 점점 더 중요하지만, 기존의 LLM 서비스 프레임워크는 비결정적인 행동을 보입니다.

Method: TP 크기와 관계없이 비트 단위로 동일한 결과를 보장하는 TP 불변 행렬 곱셈 및 축소 원시를 제안합니다.

Result: 실험 결과는 다양한 TP 크기에서 결정론적 추론에 대해 0의 확률 발산과 비트 단위 재현성을 확인했습니다.

Conclusion: 이 접근 방식은 RL 훈련 파이프라인에서 vLLM과 FSDP 간에 비트 단위로 동일한 결과를 달성합니다.

Abstract: Deterministic inference is increasingly critical for large language model (LLM) applications such as LLM-as-a-judge evaluation, multi-agent systems, and Reinforcement Learning (RL). However, existing LLM serving frameworks exhibit non-deterministic behavior: identical inputs can yield different outputs when system configurations (e.g., tensor parallel (TP) size, batch size) vary, even under greedy decoding. This arises from the non-associativity of floating-point arithmetic and inconsistent reduction orders across GPUs. While prior work has addressed batch-size-related nondeterminism through batch-invariant kernels, determinism across different TP sizes remains an open problem, particularly in RL settings, where the training engine typically uses Fully Sharded Data Parallel (i.e., TP = 1) while the rollout engine relies on multi-GPU TP to maximize the inference throughput, creating a natural mismatch between the two. This precision mismatch problem may lead to suboptimal performance or even collapse for RL training. We identify and analyze the root causes of TP-induced inconsistency and propose Tree-Based Invariant Kernels (TBIK), a set of TP-invariant matrix multiplication and reduction primitives that guarantee bit-wise identical results regardless of TP size. Our key insight is to align intra- and inter-GPU reduction orders through a unified hierarchical binary tree structure. We implement these kernels in Triton and integrate them into vLLM and FSDP. Experiments confirm zero probability divergence and bit-wise reproducibility for deterministic inference across different TP sizes. Also, we achieve bit-wise identical results between vLLM and FSDP in RL training pipelines with different parallel strategy. Code is available at https://github.com/nanomaoli/llm_reproducibility.

</details>


### [38] [The Horcrux: Mechanistically Interpretable Task Decomposition for Detecting and Mitigating Reward Hacking in Embodied AI Systems](https://arxiv.org/abs/2511.17869)
*Subramanyam Sahoo,Jared Junkin*

Main category: cs.LG

TL;DR: MITD라는 새로운 AI 프레임워크를 통해 보상 해킹을 탐지하고 완화할 수 있는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트들이 보상 신호의 결함을 이용해 보상 해킹을 수행하고 있다는 문제를 해결하고자 한다.

Method: MITD는 Planner, Coordinator, Executor 모듈을 가진 계층적 트랜스포머 아키텍처로, 해킹된 보상을 탐지하고 완화하는 방법을 제시한다.

Result: 1,000개의 HH-RLHF 샘플 실험 결과, 12에서 25단계로 구성된 과제 분해가 네 가지 실패 모드에서 보상 해킹 빈도를 34% 감소시킨다.

Conclusion: 기계적으로 기반한 분해가 사후 행동 모니터링보다 보상 해킹을 탐지하는 더 효과적인 방법임을 보여준다.

Abstract: Embodied AI agents exploit reward signal flaws through reward hacking, achieving high proxy scores while failing true objectives. We introduce Mechanistically Interpretable Task Decomposition (MITD), a hierarchical transformer architecture with Planner, Coordinator, and Executor modules that detects and mitigates reward hacking. MITD decomposes tasks into interpretable subtasks while generating diagnostic visualizations including Attention Waterfall Diagrams and Neural Pathway Flow Charts. Experiments on 1,000 HH-RLHF samples reveal that decomposition depths of 12 to 25 steps reduce reward hacking frequency by 34 percent across four failure modes. We present new paradigms showing that mechanistically grounded decomposition offers a more effective way to detect reward hacking than post-hoc behavioral monitoring.

</details>


### [39] [Generative Adversarial Post-Training Mitigates Reward Hacking in Live Human-AI Music Interaction](https://arxiv.org/abs/2511.17879)
*Yusong Wu,Stephen Brade,Teng Ma,Tia-Jane Fowler,Enning Yang,Berker Banar,Aaron Courville,Natasha Jaques,Cheng-Zhi Anna Huang*

Main category: cs.LG

TL;DR: 이 논문은 생성적 AI의 RL(강화 학습) 포스트 트레이닝에서 발생하는 보상 해킹 문제를 해결하기 위한 새로운 적대적 훈련 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 라이브 잼에서 음악적 창의성은 동적인 변화와 상호 반응성에 의존하며, 보상 해킹은 이러한 상호작용을 방해하는 문제이다.

Method: 정책 생성 경로에서 보상 해킹을 완화하기 위해 적대적 훈련 방법을 사용하며, 동시 발전하는 판별기가 정책 경로와 데이터 분포를 분리한다.

Result: 시뮬레이션 평가에서 동반자 품질과 출력 다양성이 개선되었으며, 전문가 뮤지션과의 사용자 연구에서도 긍정적인 피드백을 얻었다.

Conclusion: 결과는 생성적 시퀀스 모델의 RL 포스트 트레이닝에서 보상 해킹을 완화하기 위한 간단하면서도 효과적인 방법을 보여준다.

Abstract: Most applications of generative AI involve a sequential interaction in which a person inputs a prompt and waits for a response, and where reaction time and adaptivity are not important factors. In contrast, live jamming is a collaborative interaction that requires real-time coordination and adaptation without access to the other player's future moves, while preserving diversity to sustain a creative flow. Reinforcement learning post-training enables effective adaptation through on-policy interaction, yet it often reduces output diversity by exploiting coherence-based rewards. This collapse, known as ``reward hacking'', affects many RL post-training pipelines, but is especially harmful in live jamming, where musical creativity relies on dynamic variation and mutual responsiveness. In this paper, we propose a novel adversarial training method on policy-generated trajectories to mitigate reward hacking in RL post-training for melody-to-chord accompaniment. A co-evolving discriminator separates policy trajectories from the data distribution, while the policy maximizes the discriminator output in addition to coherence rewards to prevent collapse to trivial outputs. We evaluate accompaniment quality and output diversity in simulation with both fixed test melodies and learned melody agents, and we conduct a user study with the model deployed in a real-time interactive system with expert musicians. Quantitative evaluation and user feedback demonstrate improved output diversity, harmonic coherence, adaptation speed and user agency. Our results demonstrate a simple yet effective method to mitigate reward hacking in RL post-training of generative sequence models.

</details>


### [40] [On Transportability for Structural Causal Bandits](https://arxiv.org/abs/2511.17953)
*Min Woo Park,Sanghack Lee*

Main category: cs.LG

TL;DR: 구조적 인과적 밴딧 프레임워크를 통해 에이전트는 불필요한 탐색을 피하고 보상을 극대화할 수 있는 행동을 식별할 수 있으며, 출처 환경의 정보 융합을 통해 학습을 개선할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 인과적 지식을 갖춘 지능형 에이전트는 불필요한 탐색을 피하기 위해 행동 공간을 최적화할 수 있다.

Method: 이 논문에서는 출처 환경의 정보를 융합하여 배치 설정에서 학습을 개선할 수 있는 구조적 인과적 밴딧을 조사한다.

Result: 결과적인 밴딧 알고리즘은 비선형적인 후회 경계를 달성하고, 이전 데이터의 정보성에 명시적으로 의존한다.

Conclusion: 이 접근법은 표준 밴딧 접근 방식을 초월할 수 있다.

Abstract: Intelligent agents equipped with causal knowledge can optimize their action spaces to avoid unnecessary exploration. The structural causal bandit framework provides a graphical characterization for identifying actions that are unable to maximize rewards by leveraging prior knowledge of the underlying causal structure. While such knowledge enables an agent to estimate the expected rewards of certain actions based on others in online interactions, there has been little guidance on how to transfer information inferred from arbitrary combinations of datasets collected under different conditions -- observational or experimental -- and from heterogeneous environments. In this paper, we investigate the structural causal bandit with transportability, where priors from the source environments are fused to enhance learning in the deployment setting. We demonstrate that it is possible to exploit invariances across environments to consistently improve learning. The resulting bandit algorithm achieves a sub-linear regret bound with an explicit dependence on informativeness of prior data, and it may outperform standard bandit approaches that rely solely on online learning.

</details>


### [41] [Hybrid LSTM and PPO Networks for Dynamic Portfolio Optimization](https://arxiv.org/abs/2511.17963)
*Jun Kevin,Pujianto Yugopuspito*

Main category: cs.LG

TL;DR: 이 논문은 LSTM 예측을 PPO 강화 학습 전략과 결합한 하이브리드 포트폴리오 최적화 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 시장의 변화에 동적으로 대응할 수 있는 강력한 AI 기반 포트폴리오 최적화 프레임워크의 필요성.

Method: LSTM을 활용한 예측과 PPO를 통한 포트폴리오 할당 조정을 결합한 모델.

Result: 하이브리드 구조가 비정상적인 시장 환경에서 더 높은 수익률과 저항력을 제공한다는 결과.

Conclusion: 이 프레임워크는 동적 포트폴리오 최적화에 강력한 가능성을 가지고 있다.

Abstract: This paper introduces a hybrid framework for portfolio optimization that fuses Long Short-Term Memory (LSTM) forecasting with a Proximal Policy Optimization (PPO) reinforcement learning strategy. The proposed system leverages the predictive power of deep recurrent networks to capture temporal dependencies, while the PPO agent adaptively refines portfolio allocations in continuous action spaces, allowing the system to anticipate trends while adjusting dynamically to market shifts. Using multi-asset datasets covering U.S. and Indonesian equities, U.S. Treasuries, and major cryptocurrencies from January 2018 to December 2024, the model is evaluated against several baselines, including equal-weight, index-style, and single-model variants (LSTM-only and PPO-only). The framework's performance is benchmarked against equal-weighted, index-based, and single-model approaches (LSTM-only and PPO-only) using annualized return, volatility, Sharpe ratio, and maximum drawdown metrics, each adjusted for transaction costs. The results indicate that the hybrid architecture delivers higher returns and stronger resilience under non-stationary market regimes, suggesting its promise as a robust, AI-driven framework for dynamic portfolio optimization.

</details>


### [42] [Escaping Optimization Stagnation: Taking Steps Beyond Task Arithmetic via Difference Vectors](https://arxiv.org/abs/2511.17987)
*Jinping Wang,Zhiqiang Gao,Dinggen Zhang,Zhiwu Xie*

Main category: cs.LG

TL;DR: DV-BASI는 차이 벡터를 활용하여 효율적인 모델 최적화를 가능하게 하는 새로운 알고리즘이다.


<details>
  <summary>Details</summary>
Motivation: 현재의 선행 모델 편집 방법은 높은 계산 비용과 제한된 확장성 문제를 겪고 있다.

Method: 차이 벡터를 방향성 섭동으로 사용하는 DV-BASI 알고리즘을 제안한다.

Result: DV-BASI를 사용하면 다중 작업 모델의 평균 성능이 개별적으로 세부 조정된 모델보다 우수할 수 있다.

Conclusion: DV-BASI는 적은 학습 가능 매개변수로도 표현력이 뛰어난 검색 방향을 제공하며, 최신 성능을 달성할 수 있다.

Abstract: Current methods for editing pre-trained models face significant challenges, primarily high computational costs and limited scalability. Task arithmetic has recently emerged as a promising solution, using simple arithmetic operations-addition and negation-based on task vectors which are the differences between fine-tuned and pre-trained model weights, to efficiently modify model behavior. However, the full potential of task arithmetic remains underexplored, primarily due to limited mechanisms for overcoming optimization stagnation. To address this challenge, we introduce the notion of difference vector, a generalized form of task vectors derived from the historical movements during optimization. Using difference vectors as directed perturbations, we propose the Difference Vector-based Anisotropic Scaling Iterative algorithm (DV-BASI) to enable a continuous optimization process for task arithmetic methods without relying on any additional modules or components. Notably, by leveraging escapability and directional advantages of difference vectors, the average performance on different tasks of the multi-task model merged by DV-BASI may even outperform models individually fine-tuned. Based on this observation, we extend the application of difference vectors to a feasible fine-tuning method for single-task models. On the practical side, DV-BASI allows expressive searching directions with few learnable parameters and forms a scalable framework. We also integrate DV-BASI with task arithmetic methods and advanced optimization techniques to achieve state-of-the-art performance on both supervised and unsupervised evaluation protocols.

</details>


### [43] [Reward Engineering for Spatial Epidemic Simulations: A Reinforcement Learning Platform for Individual Behavioral Learning](https://arxiv.org/abs/2511.18000)
*Radman Rakhshandehroo,Daniel Coombs*

Main category: cs.LG

TL;DR: ContagionRL은 공간 전염병 시뮬레이션을 위한 보강 학습 플랫폼으로, 보상 설계가 생존 전략에 미치는 영향을 평가하는 데 중점을 둡니다.


<details>
  <summary>Details</summary>
Motivation: 공간 전염병 모델에 대한 보상 엔지니어링의 체계적인 접근이 필요하다.

Method: ContagionRL은 조정 가능한 환경 매개변수를 갖춘 SIRS+D 역학 모델을 통합하여 다양한 전염병 시나리오에서 보상 기능을 테스트합니다.

Result: 다섯 가지 보상 설계를 평가하고, 방향성 안내 및 명시적 준수 유인이 강력한 정책 학습에서 중요한 요소임을 발견했습니다.

Conclusion: ContagionRL 은 전염병 맥락에서 적응 행동 반응을 연구하는 데 효과적인 플랫폼이며, 보상 설계와 정보 구조가 학습에서 중요한 역할을 한다는 것을 강조합니다.

Abstract: We present ContagionRL, a Gymnasium-compatible reinforcement learning platform specifically designed for systematic reward engineering in spatial epidemic simulations. Unlike traditional agent-based models that rely on fixed behavioral rules, our platform enables rigorous evaluation of how reward function design affects learned survival strategies across diverse epidemic scenarios. ContagionRL integrates a spatial SIRS+D epidemiological model with configurable environmental parameters, allowing researchers to stress-test reward functions under varying conditions including limited observability, different movement patterns, and heterogeneous population dynamics. We evaluate five distinct reward designs, ranging from sparse survival bonuses to a novel potential field approach, across multiple RL algorithms (PPO, SAC, A2C). Through systematic ablation studies, we identify that directional guidance and explicit adherence incentives are critical components for robust policy learning. Our comprehensive evaluation across varying infection rates, grid sizes, visibility constraints, and movement patterns reveals that reward function choice dramatically impacts agent behavior and survival outcomes. Agents trained with our potential field reward consistently achieve superior performance, learning maximal adherence to non-pharmaceutical interventions while developing sophisticated spatial avoidance strategies. The platform's modular design enables systematic exploration of reward-behavior relationships, addressing a knowledge gap in models of this type where reward engineering has received limited attention. ContagionRL is an effective platform for studying adaptive behavioral responses in epidemic contexts and highlight the importance of reward design, information structure, and environmental predictability in learning.

</details>


### [44] [Understanding Private Learning From Feature Perspective](https://arxiv.org/abs/2511.18006)
*Meng Ding,Mingxi Lei,Shaopeng Fu,Shaowei Wang,Di Wang,Jinhui Xu*

Main category: cs.LG

TL;DR: DP-SGD의 이론적 프레임워크를 통해 개인 정보 보호 학습의 피처 동역학을 분석하고, 데이터 노이즈의 영향과 SNR 요구 사항을 밝혀냈다.


<details>
  <summary>Details</summary>
Motivation: 민감한 분야에서 개인 정보 보호를 보장하는 효과적인 학습 방법이 필요하다.

Method: 멀티 패치 데이터 구조를 기반으로 피처 신호와 레이블 독립 노이즈를 구분하여 이론적으로 분석한다.

Result: 효과적인 개인 정보 신호 학습은 비개인 정보 학습에 비해 높은 신호 대 노이즈 비율(SNR)을 요구하며, 데이터 노이즈가 기억되는 경우 개인 정보 학습에서도 발생한다.

Conclusion: 피처 향상이 SNR을 향상시키는 데 유리함을 입증하였다.

Abstract: Differentially private Stochastic Gradient Descent (DP-SGD) has become integral to privacy-preserving machine learning, ensuring robust privacy guarantees in sensitive domains. Despite notable empirical advances leveraging features from non-private, pre-trained models to enhance DP-SGD training, a theoretical understanding of feature dynamics in private learning remains underexplored. This paper presents the first theoretical framework to analyze private training through a feature learning perspective. Building on the multi-patch data structure from prior work, our analysis distinguishes between label-dependent feature signals and label-independent noise, a critical aspect overlooked by existing analyses in the DP community. Employing a two-layer CNN with polynomial ReLU activation, we theoretically characterize both feature signal learning and data noise memorization in private training via noisy gradient descent. Our findings reveal that (1) Effective private signal learning requires a higher signal-to-noise ratio (SNR) compared to non-private training, and (2) When data noise memorization occurs in non-private learning, it will also occur in private learning, leading to poor generalization despite small training loss. Our findings highlight the challenges of private learning and prove the benefit of feature enhancement to improve SNR. Experiments on synthetic and real-world datasets also validate our theoretical findings.

</details>


### [45] [MOMA-AC: A preference-driven actor-critic framework for continuous multi-objective multi-agent reinforcement learning](https://arxiv.org/abs/2511.18181)
*Adam Callaghan,Karl Mason,Patrick Mannion*

Main category: cs.LG

TL;DR: 본 논문은 연속 상태 및 행동 공간을 위한 최초의 헌신적인 내부 루프 액터-비평가 프레임워크인 MOMA-AC를 소개함으로써 MOMARL의 중요한 격차를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: MOMARL에서의 중요 격차를 해결하고자 하는 동기

Method: 이 프레임워크를 TD3 및 DDPG와 함께 구현하여 MOMA-TD3 및 MOMA-DDPG를 생성한다.

Result: 협력적 이동 작업 평가에서 기대效용 및 하이퍼볼륨에서 통계적으로 유의미한 개선을 이루었다.

Conclusion: 연속 멀티 에이전트 도메인에서 강력하고 확장 가능한 다목적 정책 학습을 위한 기본적인 단계로 본 프레임워크를 확립한다.

Abstract: This paper addresses a critical gap in Multi-Objective Multi-Agent Reinforcement Learning (MOMARL) by introducing the first dedicated inner-loop actor-critic framework for continuous state and action spaces: Multi-Objective Multi-Agent Actor-Critic (MOMA-AC). Building on single-objective, single-agent algorithms, we instantiate this framework with Twin Delayed Deep Deterministic Policy Gradient (TD3) and Deep Deterministic Policy Gradient (DDPG), yielding MOMA-TD3 and MOMA-DDPG. The framework combines a multi-headed actor network, a centralised critic, and an objective preference-conditioning architecture, enabling a single neural network to encode the Pareto front of optimal trade-off policies for all agents across conflicting objectives in a continuous MOMARL setting. We also outline a natural test suite for continuous MOMARL by combining a pre-existing multi-agent single-objective physics simulator with its multi-objective single-agent counterpart. Evaluating cooperative locomotion tasks in this suite, we show that our framework achieves statistically significant improvements in expected utility and hypervolume relative to outer-loop and independent training baselines, while demonstrating stable scalability as the number of agents increases. These results establish our framework as a foundational step towards robust, scalable multi-objective policy learning in continuous multi-agent domains.

</details>


### [46] [Deep Gaussian Process Proximal Policy Optimization](https://arxiv.org/abs/2511.18214)
*Matthijs van der Lende,Juan Cardenas-Cartagena*

Main category: cs.LG

TL;DR: 이 논문은 RL에서의 불확실성 추정의 중요성과 Deep Gaussian Process Proximal Policy Optimization (GPPO) 접근법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 제어 작업에서 안전한 탐색과 효율적인 학습을 균형 잡기 위해 RL에서 불확실성 추정이 중요함을 설명합니다.

Method: GPPO는 Deep Gaussian Processes (DGPs)를 활용하여 정책 및 가치 함수를 근사하는 확장 가능하고 모델 프리한 액터-크리틱 알고리즘입니다.

Result: GPPO는 표준 고차원 연속 제어 벤치마크에서 Proximal Policy Optimization과 경쟁력 있는 성능을 유지하면서, 잘 보정된 불확실성 추정을 제공합니다.

Conclusion: GPPO는 더 안전하고 효과적인 탐색을 위한 정보를 제공할 수 있는 불확실성 추정치를 나타내며, RL의 성과를 향상시킵니다.

Abstract: Uncertainty estimation for Reinforcement Learning (RL) is a critical component in control tasks where agents must balance safe exploration and efficient learning. While deep neural networks have enabled breakthroughs in RL, they often lack calibrated uncertainty estimates. We introduce Deep Gaussian Process Proximal Policy Optimization (GPPO), a scalable, model-free actor-critic algorithm that leverages Deep Gaussian Processes (DGPs) to approximate both the policy and value function. GPPO maintains competitive performance with respect to Proximal Policy Optimization on standard high-dimensional continuous control benchmarks while providing well-calibrated uncertainty estimates that can inform safer and more effective exploration.

</details>


### [47] [Coherent Multi-Agent Trajectory Forecasting in Team Sports with CausalTraj](https://arxiv.org/abs/2511.18248)
*Wei Zhen Teoh*

Main category: cs.LG

TL;DR: CausalTraj는 다중 에이전트의 공동 예측을 향상시키기 위한 모델로, 각 에이전트 간의 상호작용을 고려하여 더 정확한 예측을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트의 복잡한 상호작용을 예측하는 것은 스포츠 분석 및 그룹 다이나믹스가 중요한 다른 분야에서 핵심 도전 과제입니다.

Method: CausalTraj는 시간적 인과성을 갖춘 가능성 기반 모델로, 공동으로 가능한 다중 에이전트 경로 예측을 생성하기 위해 설계되었습니다.

Result: CausalTraj는 NBA SportVU, Basketball-U, Football-U 데이터셋에서 경쟁력 있는 개별 에이전트 정확도와 최고의 공동 메트릭 결과를 기록했습니다.

Conclusion: CausalTraj는 질적으로 일관되고 현실적인 게임 플레이 진화를 제공합니다.

Abstract: Jointly forecasting trajectories of multiple interacting agents is a core challenge in sports analytics and other domains involving complex group dynamics. Accurate prediction enables realistic simulation and strategic understanding of gameplay evolution. Most existing models are evaluated solely on per-agent accuracy metrics (minADE, minFDE), which assess each agent independently on its best-of-k prediction. However these metrics overlook whether the model learns which predicted trajectories can jointly form a plausible multi-agent future. Many state-of-the-art models are designed and optimized primarily based on these metrics. As a result, they may underperform on joint predictions and also fail to generate coherent, interpretable multi-agent scenarios in team sports. We propose CausalTraj, a temporally causal, likelihood-based model that is built to generate jointly probable multi-agent trajectory forecasts. To better assess collective modeling capability, we emphasize joint metrics (minJADE, minJFDE) that measure joint accuracy across agents within the best generated scenario sample. Evaluated on the NBA SportVU, Basketball-U, and Football-U datasets, CausalTraj achieves competitive per-agent accuracy and the best recorded results on joint metrics, while yielding qualitatively coherent and realistic gameplay evolutions.

</details>


### [48] [MultiDiffNet: A Multi-Objective Diffusion Framework for Generalizable Brain Decoding](https://arxiv.org/abs/2511.18294)
*Mengchun Zhang,Kateryna Shapovalenko,Yucheng Shao,Eddie Guo,Parusha Pradhan*

Main category: cs.LG

TL;DR: 본 논문에서는 EEG로부터의 신경 디코딩의 일반화 문제를 해결하기 위한 MultiDiffNet이라는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: EEG 데이터에서 신경 신호를 디코딩할 때 주관들 간의 변동성이 커서 기존 방법들이 잘 일반화되지 않습니다.

Method: MultiDiffNet은 여러 목표에 최적화된 컴팩트한 잠재 공간을 학습하여 생성적 증강을 완전히 우회하는 확산 기반 프레임워크입니다.

Result: 이 프레임워크를 통해 다양한 신경 디코딩 작업에서 최첨단의 일반화 성능을 달성하였고, 우리는 네 가지 EEG 디코딩 작업을 포함하는 통합 벤치마크를 제작하였습니다.

Conclusion: 우리의 연구는 실제 BCI 시스템에서 사용될 수 있는 주제 비고정적인 EEG 디코딩의 재현 가능하고 오픈 소스의 기초를 제공합니다.

Abstract: Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems.

</details>


### [49] [Hierarchical Deep Research with Local-Web RAG: Toward Automated System-Level Materials Discovery](https://arxiv.org/abs/2511.18303)
*Rui Ding,Rodrigo Pires Ferreira,Yuxin Chen,Junhong Chen*

Main category: cs.LG

TL;DR: 이 논문에서는 복잡한 재료 및 장치 발견 문제를 위한 계층적 깊이 연구(DR) 에이전트를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 머신 러닝(Machine Learning) 대용체와 클로즈드 소스 상업 에이전트의 한계를 초월하기 위함입니다.

Method: 로컬 검색 증강 생성(local retrieval-augmented generation)과 대형 언어 모델(reasoners)을 통합하며, 연구 branches를 최대한으로 확장하고 조정하는 Deep Tree of Research(DToR) 메커니즘을 강화했습니다.

Result: 27개의 나노재료/장치 주제에 대해 다섯 가지 최첨단 모델을 판별하는 LLM을 사용하여 체계적으로 평가했습니다. 그리고 다섯 가지 대표적인 작업에 대해 인간 전문가들이 도메인 시뮬레이션을 사용하여 DR-에이전트 제안이 실행 가능한지 검증하는 건조 실험을 수행했습니다.

Conclusion: 우리의 DR 에이전트는 상업 시스템(ChatGPT-5-thinking/o3/o4-mini-high Deep Research)의 품질과 동등하거나 종종 초과하는 보고서를 상당히 낮은 비용으로 생성하며, 로컬 데이터 및 도구와의 온프레미스 통합을 가능하게 합니다.

Abstract: We present a long-horizon, hierarchical deep research (DR) agent designed for complex materials and device discovery problems that exceed the scope of existing Machine Learning (ML) surrogates and closed-source commercial agents. Our framework instantiates a locally deployable DR instance that integrates local retrieval-augmented generation with large language model reasoners, enhanced by a Deep Tree of Research (DToR) mechanism that adaptively expands and prunes research branches to maximize coverage, depth, and coherence. We systematically evaluate across 27 nanomaterials/device topics using a large language model (LLM)-as-judge rubric with five web-enabled state-of-the-art models as jurors. In addition, we conduct dry-lab validations on five representative tasks, where human experts use domain simulations (e.g., density functional theory, DFT) to verify whether DR-agent proposals are actionable. Results show that our DR agent produces reports with quality comparable to--and often exceeding--those of commercial systems (ChatGPT-5-thinking/o3/o4-mini-high Deep Research) at a substantially lower cost, while enabling on-prem integration with local data and tools.

</details>


### [50] [DynamiX: Dynamic Resource eXploration for Personalized Ad-Recommendations](https://arxiv.org/abs/2511.18331)
*Sohini Roychowdhury,Adam Holeman,Mohammad Amin,Feng Wei,Bhaskar Mehta,Srihari Reddy*

Main category: cs.LG

TL;DR: Dynamix는 온라인 광고 추천 시스템의 사용자 참여 데이터를 효율적으로 처리하는 프레임워크로, 최대 관련성 원칙과 자기 감독 학습을 기반으로 사용자 세그먼트에 맞춰 기능을 최적화한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 광고 추천 시스템에서 사용자-광고 참여 이력을 완전하게 처리하는 것은 계산적으로 집약적이고 노이즈가 많다.

Method: Dynamix는 최대 관련성 원칙과 사건 기반 기능(EBF)을 사용하는 자기 감독 학습을 통해 이벤트 이력 처리를 최적화하는 확장 가능하고 개인화된 시퀀스 탐색 프레임워크이다.

Result: 다이나믹 리소스 제거는 훈련 및 추론 처리량을 각각 1.15%, 1.8% 증가시키고, 다이나믹 기능 부스팅은 기준 모델보다 추론 QPS를 4.2% 향상시키면서 0.033 NE 이득을 제공한다.

Conclusion: Dynamix는 온라인 사용자 시퀀스 기반 추천 모델에서 상당한 비용 효율성과 성능 개선을 달성하며, 자기 감독 방식의 사용자 세분화 및 리소스 탐색이 복잡한 기능 선택 전략을 더욱 향상시킬 수 있다.

Abstract: For online ad-recommendation systems, processing complete user-ad-engagement histories is both computationally intensive and noise-prone. We introduce Dynamix, a scalable, personalized sequence exploration framework that optimizes event history processing using maximum relevance principles and self-supervised learning through Event Based Features (EBFs). Dynamix categorizes users-engagements at session and surface-levels by leveraging correlations between dwell-times and ad-conversion events. This enables targeted, event-level feature removal and selective feature boosting for certain user-segments, thereby yielding training and inference efficiency wins without sacrificing engaging ad-prediction accuracy. While, dynamic resource removal increases training and inference throughput by 1.15% and 1.8%, respectively, dynamic feature boosting provides 0.033 NE gains while boosting inference QPS by 4.2% over baseline models. These results demonstrate that Dynamix achieves significant cost efficiency and performance improvements in online user-sequence based recommendation models. Self-supervised user-segmentation and resource exploration can further boost complex feature selection strategies while optimizing for workflow and compute resources.

</details>


### [51] [Clinician-in-the-Loop Smart Home System to Detect Urinary Tract Infection Flare-Ups via Uncertainty-Aware Decision Support](https://arxiv.org/abs/2511.18334)
*Chibuike E. Ugwu,Roschelle Fritz,Diane J. Cook,Janardhan Rao Doppa*

Main category: cs.LG

TL;DR: 이 논문은 만성 질환을 가진 노인의 요로 감염(UTI) 감지 및 관리를 위한 스마트 홈 시스템을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 노인의 만성 질환으로 인한 요로 감염 플레어업은 건강에 큰 위험을 초래합니다. 초기 감지가 중요하지만 전통적인 기계 학습 접근법은 효과적이지 않습니다.

Method: 이 논문은 주변 센서 데이터를 활용하여 행동 지표를 추출하고, 예측 식별 모델을 훈련시키며, 확인 가능한 결정 지원을 위해 불확실성 인지 메커니즘을 갖춘 스마트 홈 시스템을 제시합니다.

Result: 실제 데이터에서 우리의 방법은 기본 방법보다 더 높은 재현율과 기타 분류 지표를 기록하였으며, 최저의 회피 비율과 간격 너비를 유지합니다.

Conclusion: 42명의 간호사 설문조사 결과, 우리의 시스템 출력은 임상 의사결정에 유용하다는 것이 확인되었으며, 노인의 UTI와 다른 질환 플레어업 관리에 효과적입니다.

Abstract: Urinary tract infection (UTI) flare-ups pose a significant health risk for older adults with chronic conditions. These infections often go unnoticed until they become severe, making early detection through innovative smart home technologies crucial. Traditional machine learning (ML) approaches relying on simple binary classification for UTI detection offer limited utility to nurses and practitioners as they lack insight into prediction uncertainty, hindering informed clinical decision-making. This paper presents a clinician-in-the-loop (CIL) smart home system that leverages ambient sensor data to extract meaningful behavioral markers, train robust predictive ML models, and calibrate them to enable uncertainty-aware decision support. The system incorporates a statistically valid uncertainty quantification method called Conformal-Calibrated Interval (CCI), which quantifies uncertainty and abstains from making predictions ("I don't know") when the ML model's confidence is low. Evaluated on real-world data from eight smart homes, our method outperforms baseline methods in recall and other classification metrics while maintaining the lowest abstention proportion and interval width. A survey of 42 nurses confirms that our system's outputs are valuable for guiding clinical decision-making, underscoring their practical utility in improving informed decisions and effectively managing UTIs and other condition flare-ups in older adults.

</details>


### [52] [Auxiliary Gene Learning: Spatial Gene Expression Estimation by Auxiliary Gene Selection](https://arxiv.org/abs/2511.18336)
*Kaito Shiku,Kazuya Nishimura,Shinnosuke Matsuo,Yasuhiro Kojima,Ryoma Bise*

Main category: cs.LG

TL;DR: Spatial transcriptomics(ST)는 병리 조직 내 개별 지점에서 유전자 발현을 관찰할 수 있는 혁신적인 기술이다. 이 논문에서는 보조 유전자를 활용하여 평가 대상을 추정하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: ST는 유전자 발현을 정량화하지만 관측 오 noise가 종종 발생하여 유의미한 평가가 어려워진다. 기존 연구에서는 변동성이 큰 유전자 소 subset에 훈련과 평가를 제한하였다.

Method: $Auxiliary 
e Gene 
Learning$(AGL) 방법을 제안하며, 보조 유전자의 발현 추정을 보조 작업으로 재구성하고 이를 주 작업과 함께 훈련한다. DkGSB라는 방법을 통해 보조 유전자 선택 문제를 해결한다.

Result: 실험 결과 보조 유전자를 포함하는 것이 효과적이며, 제안한 방법이 기존의 보조 작업 학습 방법보다 우수함을 보여준다.

Conclusion: AGL과 DkGSB는 유전자 발현 추정의 정확도를 높이는 데 기여할 수 있다.

Abstract: Spatial transcriptomics (ST) is a novel technology that enables the observation of gene expression at the resolution of individual spots within pathological tissues. ST quantifies the expression of tens of thousands of genes in a tissue section; however, heavy observational noise is often introduced during measurement. In prior studies, to ensure meaningful assessment, both training and evaluation have been restricted to only a small subset of highly variable genes, and genes outside this subset have also been excluded from the training process. However, since there are likely co-expression relationships between genes, low-expression genes may still contribute to the estimation of the evaluation target. In this paper, we propose $Auxiliary \ Gene \ Learning$ (AGL) that utilizes the benefit of the ignored genes by reformulating their expression estimation as auxiliary tasks and training them jointly with the primary tasks. To effectively leverage auxiliary genes, we must select a subset of auxiliary genes that positively influence the prediction of the target genes. However, this is a challenging optimization problem due to the vast number of possible combinations. To overcome this challenge, we propose Prior-Knowledge-Based Differentiable Top-$k$ Gene Selection via Bi-level Optimization (DkGSB), a method that ranks genes by leveraging prior knowledge and relaxes the combinatorial selection problem into a differentiable top-$k$ selection problem. The experiments confirm the effectiveness of incorporating auxiliary genes and show that the proposed method outperforms conventional auxiliary task learning approaches.

</details>


### [53] [Radiation-Preserving Selective Imaging for Pediatric Hip Dysplasia: A Cross-Modal Ultrasound-Xray Policy with Limited Labels](https://arxiv.org/abs/2511.18457)
*Duncan Stothers,Ben Stothers,Emily Schaeffer,Kishore Mulpuri*

Main category: cs.LG

TL;DR: 이 연구는 필요할 때만 방사선 촬영 요청을 하는 초음파 우선의 방사선 보존 정책을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 발달성 고관절 이형성증(DDH)에 대한 방사선 노출을 최소화하면서 진단 정확도를 높이고자 한다.

Method: SimSiam을 사용하여 큰 비표시 데이터베이스에서 모달리티 별 인코더(ResNet-18)를 사전 훈련하고, DDH 관련 랜드마크와 측정에 대해 작은 측정 신뢰도가 높은 헤드를 적합시키며, 초음파 예측을 기반으로 하는 일측 변별 규칙을 보정한다.

Result: 초음파 측정의 평균 절대 오차(MAE)는 양호하며, 방사선 촬영의 MAE도 낮으며, 보정된 초음파 전용 정책은 다양한 규칙 패밀리에서 탐색된다.

Conclusion: 결과적으로, 제한된 레이블을 해석 가능한 측정으로 전환하고 임상 인수인계를 위해 적합한 선택적 이미징 곡선을 위한 간단하고 재현 가능한 파이프라인이 개발되었다.

Abstract: We study an ultrasound-first, radiation-preserving policy for developmental dysplasia of the hip (DDH) that requests a radiograph only when needed.
  We (i) pretrain modality-specific encoders (ResNet-18) with SimSiam on a large unlabelled registry (37186 ultrasound; 19546 radiographs), (ii) freeze the backbones and fit small, measurement-faithful heads on DDH relevant landmarks and measurements (iii) calibrate a one sided conformal deferral rule on ultrasound predictions that provides finite sample coverage guarantees under exchangeability, using a held-out calibration set. Ultrasound heads predict Graf alpha, beta, and femoral head coverage; X-ray heads predict acetabular index (AI), center-edge (CE) angle and IHDI grade. On our held out labeled evaluation set, ultrasound measurement error is modest (e.g., alpha MAE ~= 9.7 degrees, coverage MAE ~= 14.0%), while radiographic probes achieve AI and CE MAEs of ~= 7.6 degrees and ~= 8.9 degrees, respectively. The calibrated US-only policy is explored across rule families (alpha-only; alpha OR coverage; alpha AND coverage), uncertainty inflation factors, and per-utility trade-offs using decision-curve analysis. Conservative settings yield high coverage with near-zero US-only rates; permissive settings (e.g., alpha OR coverage at larger deltas) achieve non-zero US-only throughput with expected coverage tradeoffs. The result is a simple, reproducible pipeline that turns limited labels into interpretable measurements and tunable selective imaging curves suitable for clinical handoff and future external validation.

</details>


### [54] [Real-Time Personalized Content Adaptation through Matrix Factorization and Context-Aware Federated Learning](https://arxiv.org/abs/2511.18489)
*Sai Puppala,Ismail Hossain,Md Jahangir Alam,Sajedul Talukder*

Main category: cs.LG

TL;DR: 본 연구는 연합 학습 프레임워크를 통해 소셜 미디어 플랫폼에서 사용자 상호작용과 콘텐츠 관련성을 향상시키는 다양한 접근 방식을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 소셜 미디어 사용자 경험을 개선하고 사용자 개인 맞춤형 콘텐츠를 제공하기 위한 필요성.

Method: 여러 클라이언트 엔티티가 현지 수집 소셜 미디어 데이터를 사용하여 기본 GPT 모델을 세부 조정하며, 연합 집계를 통해 데이터 프라이버시를 보장하는 개인화된 LLM 연합 학습 및 맥락 기반 소셜 미디어 모델을 도입합니다.

Result: 실시간 개인화된 콘텐츠 제안을 통해 사용자 맞춤형 선호도에 부합하는 콘텐츠를 제공하며, 사용자 생성 콘텐츠 분류, 사용자 개성 점수 계산, 친구 네트워크에서 관련 게시물 식별을 수행합니다.

Conclusion: 이 포괄적인 솔루션은 콘텐츠 필터링 및 추천의 과제를 해결할 뿐만 아니라, 사용자 프라이버시를 보호하면서 보다 매력적인 소셜 미디어 경험을 촉진하여 디지털 플랫폼에서 개인화 상호작용의 새로운 기준을 설정합니다.

Abstract: Our study presents a multifaceted approach to enhancing user interaction and content relevance in social media platforms through a federated learning framework. We introduce personalized LLM Federated Learning and Context-based Social Media models. In our framework, multiple client entities receive a foundational GPT model, which is fine-tuned using locally collected social media data while ensuring data privacy through federated aggregation. Key modules focus on categorizing user-generated content, computing user persona scores, and identifying relevant posts from friends networks. By integrating a sophisticated social engagement quantification method with matrix factorization techniques, our system delivers real-time personalized content suggestions tailored to individual preferences. Furthermore, an adaptive feedback loop, alongside a robust readability scoring algorithm, significantly enhances the quality and relevance of the content presented to users. This comprehensive solution not only addresses the challenges of content filtering and recommendation but also fosters a more engaging social media experience while safeguarding user privacy, setting a new standard for personalized interactions in digital platforms.

</details>


### [55] [SAMBA: Toward a Long-Context EEG Foundation Model via Spatial Embedding and Differential Mamba](https://arxiv.org/abs/2511.18571)
*Jiazhen Hong,Geoffrey Mackellar,Soheila Ghane*

Main category: cs.LG

TL;DR: SAMBA는 장기 EEG 데이터의 시간적 종속성과 공간적 변동성을 효과적으로 포착하는 자가 지도 학습 프레임워크로, 다양한 EEG 데이터셋에서 최첨단 방법보다 뛰어난 성능을 보입니다.


<details>
  <summary>Details</summary>
Motivation: 고해상도의 EEG 데이터와 장기 기록 시간으로 인해 일반화 가능한 EEG 표현 모델 개발이 필요합니다.

Method: Mamba 기반의 U자형 인코더-디코더 아키텍처를 가진 SAMBA라는 자가 지도 학습 프레임워크를 제안합니다.

Result: SAMBA는 13개의 다양한 EEG 데이터셋에서 상태-of-the-art 방법보다 일관되게 우수한 성능을 보여줍니다.

Conclusion: SAMBA는 실시간 뇌-컴퓨터 인터페이스 응용 프로그램을 위한 기초 모델로서의 확장성과 실용적인 잠재력을 강조합니다.

Abstract: Long-sequence electroencephalogram (EEG) modeling is essential for developing generalizable EEG representation models. This need arises from the high sampling rate of EEG data and the long recording durations required to capture extended neurological patterns in brain activity. Transformer-based models have shown promise in modeling short sequences of a few seconds; however, their quadratic complexity limits scalability to longer contexts. Moreover, variability in electrode montage across available datasets, along with inter-subject differences in brain signals, pose significant challenges to developing a generalizable and robust foundation model. We propose \textit{SAMBA}, a self-supervised learning framework with a Mamba-based U-shaped encoder-decoder architecture, which effectively captures long-range temporal dependencies and spatial variability in EEG data. Leveraging the inherent ability of Mamba in processing long context sizes, we introduce: (1) \textit{Temporal Semantic Random Masking} for semantic-level sequence reconstruction, (2) a \textit{Multi-Head Differential Mamba} module to suppress redundancy and emphasize salient temporal structures, and (3) a \textit{Spatial-Adaptive Input Embedding} that learns unified embeddings in a three-dimensional Euclidean space, enabling robustness across devices. Experiments on thirteen EEG datasets across diverse tasks, electrode configurations, and sequence durations demonstrate that SAMBA consistently outperforms state-of-the-art methods while maintaining low memory consumption and inference time. We also show the learned spatial weight maps from our embedding module align closely with task-relevant neurophysiological regions, demonstrating the learnability and interpretability of SAMBA. These results highlight SAMBA's scalability and practical potential as a foundation model for real-time brain-computer interface applications.

</details>


### [56] [Bayesian-based Online Label Shift Estimation with Dynamic Dirichlet Priors](https://arxiv.org/abs/2511.18615)
*Jiawei Hu,Javier A. Barria*

Main category: cs.LG

TL;DR: 라벨 시프트 문제를 해결하기 위한 베이지안 프레임워크 FMAPLS와 온라인 버전인 online-FMAPLS를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 라벨 시프트는 테스트 데이터의 클래스 사전 분포가 훈련 데이터와 다를 때 발생하여 분류기 성능을 크게 저하시킨다.

Method: FMAPLS와 online-FMAPLS는 EM 알고리즘을 활용하여 Dirichlet 하이퍼파라미터와 클래스 사전 분포를 동적으로 최적화한다.

Result: FMAPLS와 online-FMAPLS는 각각 최대 40% 및 12% 낮은 KL 발산과 상당한 정확도 개선을 달성하였다.

Conclusion: 제안된 방법들은 대규모 및 동적 학습 시나리오에 적합하며, 강력하고 확장 가능함을 증명하였다.

Abstract: Label shift, a prevalent challenge in supervised learning, arises when the class prior distribution of test data differs from that of training data, leading to significant degradation in classifier performance. To accurately estimate the test priors and enhance classification accuracy, we propose a Bayesian framework for label shift estimation, termed Full Maximum A Posterior Label Shift (FMAPLS), along with its online version, online-FMAPLS. Leveraging batch and online Expectation-Maximization (EM) algorithms, these methods jointly and dynamically optimize Dirichlet hyperparameters $\boldsymbolα$ and class priors $\boldsymbolπ$, thereby overcoming the rigid constraints of the existing Maximum A Posterior Label Shift (MAPLS) approach. Moreover, we introduce a linear surrogate function (LSF) to replace gradient-based hyperparameter updates, yielding closed-form solutions that reduce computational complexity while retaining asymptotic equivalence. The online variant substitutes the batch E-step with a stochastic approximation, enabling real-time adaptation to streaming data. Furthermore, our theoretical analysis reveals a fundamental trade-off between online convergence rate and estimation accuracy. Extensive experiments on CIFAR100 and ImageNet datasets under shuffled long-tail and Dirichlet test priors demonstrate that FMAPLS and online-FMAPLS respectively achieve up to 40% and 12% lower KL divergence and substantial improvements in post-shift accuracy over state-of-the-art baselines, particularly under severe class imbalance and distributional uncertainty. These results confirm the robustness, scalability, and suitability of the proposed methods for large-scale and dynamic learning scenarios.

</details>


### [57] [Reinforcement Learning for Self-Healing Material Systems](https://arxiv.org/abs/2511.18728)
*Maitreyi Chatterjee,Devansh Agarwal,Biplab Chatterjee*

Main category: cs.LG

TL;DR: 본 연구는 자율 재료 시스템에서의 적응 제어 방법론을 제안하며, 강화학습을 통해 자가 치유 프로세스를 최적화하여 구조적 수명을 극대화하는 방법을探구한다.


<details>
  <summary>Details</summary>
Motivation: 자율 재료 시스템의 전환은 구조적 수명을 극대화하기 위해 적응 제어 방법론이 필요하다.

Method: 자가 치유 프로세스를 마르코프 의사결정 과정(MDP) 내에서 강화학습 문제로 설정하여 최적 정책을 자율적으로 도출하도록 한다.

Result: 이산 행동(Q-러닝, DQN) 및 연속 행동(TD3) 에이전트를 비교 평가한 결과, 강화학습 컨트롤러가 휴리스틱 기준을 크게 초과 달성하며 거의 완벽한 재료 회복을 달성했다.

Conclusion: 연속 용량 조절을 활용하는 TD3 에이전트는 우수한 수렴 속도와 안정성을 보여주며, 동적 자가 치유 응용에서 세밀하고 비례적인 작동의 필요성을 강조한다.

Abstract: The transition to autonomous material systems necessitates adaptive control methodologies to maximize structural longevity. This study frames the self-healing process as a Reinforcement Learning (RL) problem within a Markov Decision Process (MDP), enabling agents to autonomously derive optimal policies that efficiently balance structural integrity maintenance against finite resource consumption. A comparative evaluation of discrete-action (Q-learning, DQN) and continuous-action (TD3) agents in a stochastic simulation environment revealed that RL controllers significantly outperform heuristic baselines, achieving near-complete material recovery. Crucially, the TD3 agent utilizing continuous dosage control demonstrated superior convergence speed and stability, underscoring the necessity of fine-grained, proportional actuation in dynamic self-healing applications.

</details>


### [58] [OceanForecastBench: A Benchmark Dataset for Data-Driven Global Ocean Forecasting](https://arxiv.org/abs/2511.18732)
*Haoming Jia,Yi Han,Xiang Wang,Huizan Wang,Wei Wu,Jianming Zheng,Peikun Xiao*

Main category: cs.LG

TL;DR: 이 논문은 OceanForecastBench라는 벤치마크를 제안하여 데이터 기반 해양 예측 모델 개발의 효율성을 높이고, 공정한 성능 비교를 가능하게 하며, 학제 간 협력을 촉진하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 해양 예측 모델의 발전에도 불구하고 일관된 데이터 사용과 평가 방법의 부족이 모델 개발과 성능 비교를 저해하고 있다.

Method: OceanForecastBench는 28년 동안의 고품질 글로벌 해양 재분석 데이터, 신뢰할 수 있는 위성 및 현장 관측 데이터, 그리고 6개의 대표적인 기준 모델을 포함한 평가 파이프라인을 제공한다.

Result: 제안된 벤치마크는 데이터 기반 해양 예측을 위한 가장 포괄적인 프레임워크로, 다양한 관점에서 모델 성능을 평가할 수 있게 한다.

Conclusion: OceanForecastBench는 모델 개발과 평가, 비교를 위한 공개 소스 플랫폼을 제공한다.

Abstract: Global ocean forecasting aims to predict key ocean variables such as temperature, salinity, and currents, which is essential for understanding and describing oceanic phenomena. In recent years, data-driven deep learning-based ocean forecast models, such as XiHe, WenHai, LangYa and AI-GOMS, have demonstrated significant potential in capturing complex ocean dynamics and improving forecasting efficiency. Despite these advancements, the absence of open-source, standardized benchmarks has led to inconsistent data usage and evaluation methods. This gap hinders efficient model development, impedes fair performance comparison, and constrains interdisciplinary collaboration. To address this challenge, we propose OceanForecastBench, a benchmark offering three core contributions: (1) A high-quality global ocean reanalysis data over 28 years for model training, including 4 ocean variables across 23 depth levels and 4 sea surface variables. (2) A high-reliability satellite and in-situ observations for model evaluation, covering approximately 100 million locations in the global ocean. (3) An evaluation pipeline and a comprehensive benchmark with 6 typical baseline models, leveraging observations to evaluate model performance from multiple perspectives. OceanForecastBench represents the most comprehensive benchmarking framework currently available for data-driven ocean forecasting, offering an open-source platform for model development, evaluation, and comparison. The dataset and code are publicly available at: https://github.com/Ocean-Intelligent-Forecasting/OceanForecastBench.

</details>


### [59] [Doubly Wild Refitting: Model-Free Evaluation of High Dimensional Black-Box Predictions under Convex Losses](https://arxiv.org/abs/2511.18789)
*Haichen Hu,David Simchi-Levi*

Main category: cs.LG

TL;DR: 본 논문은 일반 볼록 손실 함수를 위한 경험적 위험 최소화(ERM)에서의 초과 위험 평가 문제를 연구한다. 저자들은 고정 설계 설정 하에서 초과 위험을 계산하고 높은 확률의 상한을 제공하는 효율적인 재적합 절차를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 복잡한 가설 클래스 때문에 전통적인 용량 기반 학습 이론이 비현실적인 현대의 불투명한 머신러닝 시스템을 이론적으로 평가하고자 하는 필요성.

Method: 기계학습 알골임과 단일 데이터셋에 대한 블랙박스 접근만을 가정하고, 크게 수정된 가짜 결과물인 '와일드 응답'을 생성하기 위해 그래디언트 벡터를 확률적으로 교란시키는 방식을 사용하여 두 개의 프레디터를 재적합한다.

Result: 이 과정을 통해 효율적인 초과 위험 상한을 도출하고, 기본 함수 클래스의 복잡성에 대한 사전 지식이 필요 없다는 점이 중요하다.

Conclusion: 이 방법은 본질적으로 모델 프리이며, 딥 뉴럴 네트워크와 생성 모델 같은 복잡한 현대 머신러닝 시스템을 평가하는 데 큰 잠재력을 지닌다.

Abstract: We study the problem of excess risk evaluation for empirical risk minimization (ERM) under general convex loss functions. Our contribution is an efficient refitting procedure that computes the excess risk and provides high-probability upper bounds under the fixed-design setting. Assuming only black-box access to the training algorithm and a single dataset, we begin by generating two sets of artificially modified pseudo-outcomes termed wild response, created by stochastically perturbing the gradient vectors with carefully chosen scaling. Using these two pseudo-labeled datasets, we then refit the black-box procedure twice to obtain two corresponding wild predictors. Finally, leveraging the original predictor, the two wild predictors, and the constructed wild responses, we derive an efficient excess risk upper bound. A key feature of our analysis is that it requires no prior knowledge of the complexity of the underlying function class. As a result, the method is essentially model-free and holds significant promise for theoretically evaluating modern opaque machine learning system--such as deep nerral networks and generative model--where traditional capacity-based learning theory becomes infeasible due to the extreme complexity of the hypothesis class.

</details>


### [60] [Leveraging Duration Pseudo-Embeddings in Multilevel LSTM and GCN Hypermodels for Outcome-Oriented PPM](https://arxiv.org/abs/2511.18830)
*Fang Wang,Paolo Ceravolo,Ernesto Damiani*

Main category: cs.LG

TL;DR: 본 연구에서는 사건 및 시퀀스 속성을 분리하는 이중 입력 신경망 전략을 제안하여 예측 프로세스 모니터링(PPM)의 적응성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 심층 학습 모델은 비정형 데이터셋에서의 적응성에 제한이 있으며, 특히 시간적 비규칙성과 관련하여 어려움을 겪고 있습니다.

Method: 우리는 사건 및 시퀀스 속성을 분리하는 이중 입력 신경망 전략을 제안하며, 지속 시간 인식 의사 임베딩 행렬을 사용하여 시간적 중요성을 컴팩트하고 학습 가능한 표현으로 변환합니다.

Result: 균형 잡힌 및 불균형한 결과 예측 작업 실험을 통해 지속 시간 의사 임베딩 입력이 일반화 성능을 향상시키고, 모델의 복잡성을 줄이며, 해석 가능성을 높이는 것을 보여주었습니다.

Conclusion: 우리의 결과는 명시적인 시간 인코딩의 이점을 입증하고, 강력하고 실용적인 PPM 응용 프로그램을 위한 유연한 설계를 제공합니다.

Abstract: Existing deep learning models for Predictive Process Monitoring (PPM) struggle with temporal irregularities, particularly stochastic event durations and overlapping timestamps, limiting their adaptability across heterogeneous datasets. We propose a dual input neural network strategy that separates event and sequence attributes, using a duration-aware pseudo-embedding matrix to transform temporal importance into compact, learnable representations. This design is implemented across two baseline families: B-LSTM and B-GCN, and their duration-aware variants D-LSTM and D-GCN. All models incorporate self-tuned hypermodels for adaptive architecture selection. Experiments on balanced and imbalanced outcome prediction tasks show that duration pseudo-embedding inputs consistently improve generalization, reduce model complexity, and enhance interpretability. Our results demonstrate the benefits of explicit temporal encoding and provide a flexible design for robust, real-world PPM applications.

</details>


### [61] [KernelBand: Boosting LLM-based Kernel Optimization with a Hierarchical and Hardware-aware Multi-armed Bandit](https://arxiv.org/abs/2511.18868)
*Dezhi Ran,Shuxiao Xie,Mingfang Ji,Ziyue Hua,Mengzhou Wu,Yuan Cao,Yuzhe Guo,Yu Hao,Linyi Li,Yitao Hu,Tao Xie*

Main category: cs.LG

TL;DR: KernelBand는 대규모 언어 모델의 커널 최적화를 계층적 다중 무장강도 문제로 정의하여 최적화 공간을 효과적으로 탐색할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 고품질 커널은 대규모 언어 모델의 훈련 및 추론 비용을 줄이는 데 매우 중요하지만, 전통적으로 하드웨어 아키텍처와 소프트웨어 최적화에 대한 상당한 전문지식이 필요하다.

Method: KernelBand는 커널 최적화를 계층적 다중 무장강도 문제로 공식화하여 LLM 에이전트가 커널 선택 및 최적화 전략 적용을 순차적인 의사결정 프로세스로 다룰 수 있게 한다.

Result: KernelBand는 TritonBench에서 최신 방법들을 현저히 초월하는 성능을 보였으며, 더 적은 토큰으로 우수한 성능을 달성하며 계산 자원이 증가함에 따라 포화 없이 지속적인 향상을 나타낸다.

Conclusion: 이 접근 방식은 하드웨어 프로파일링 정보를 활용하여 유망한 최적화 전략을 식별하고, 실행 시간 동작 군집화를 통해 커널 후보 간 탐색 오버헤드를 줄인다.

Abstract: High quality kernels are critical for reducing training and inference costs of Large Language Models (LLMs), yet they traditionally require significant expertise in hardware architecture and software optimization. While recent advances in LLM-based code generation show promise for complex optimization, existing methods struggle with the vast optimization space due to insufficient hardware domain knowledge, failing to effectively balance exploration and exploitation. We present KernelBand, a novel framework that formulates kernel optimization as a hierarchical multi-armed bandit problem, enabling LLM agents to strategically navigate the optimization space by treating kernel selection and optimization strategy application as sequential decision-making processes. Our approach leverages hardware profiling information to identify promising optimization strategies and employs runtime behavior clustering to reduce exploration overhead across kernel candidates. Extensive experiments on TritonBench demonstrate that KernelBand significantly outperforms state-of-the-art methods, achieving superior performance with fewer tokens while exhibiting consistent improvement without saturation as computational resources increase.

</details>


### [62] [VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL](https://arxiv.org/abs/2511.18902)
*Zengjie Hu,Jiantao Qiu,Tianyi Bai,Haojin Yang,Binhang Yuan,Qi Jing,Conghui He,Wentao Zhang*

Main category: cs.LG

TL;DR: VADE라는 새로운 동적 샘플링 프레임워크를 제안하며, 멀티모달 모델 훈련에서 그룹 기반 정책 최적화 방법의 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 기존 그룹 기반 정책 최적화 방법은 동일한 보상을 받은 응답들로 인해 그래디언트 소실 문제에 직면하고 있으며, 이는 훈련 신호를 감소시킨다.

Method: VADE는 온라인 샘플 수준 난이도 추정을 통해 동적으로 정보를 최대화하는 샘플을 선택하는 프레임워크이다.

Result: VADE는 멀티모달 추론 기준에서 강력한 기준선 대비 성능과 샘플 효율성 모두에서 일관되게 우수한 결과를 보여준다.

Conclusion: 우리의 프레임워크는 기존의 그룹 기반 강화 학습 알고리즘과 통합하여 사용할 수 있는 플러그 앤 플레이 구성 요소로서 기능할 수 있다.

Abstract: Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \textbf{VADE}, a \textbf{V}ariance-\textbf{A}ware \textbf{D}ynamic sampling framework via online sample-level difficulty \textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.

</details>


### [63] [How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining](https://arxiv.org/abs/2511.18903)
*Kairong Luo,Zhenbo Sun,Haodong Wen,Xinyu Shi,Jiarui Cui,Chenyi Dang,Kaifeng Lyu,Wenguang Chen*

Main category: cs.LG

TL;DR: 고품질 데이터 부족으로 인해 LLM은 다양한 품질 수준의 데이터로 훈련된다. 교육 기반의 사전 훈련 방법을 통해 데이터 품질 순서에 따라 모델을 훈련하는 것이 고품질 데이터를 더 잘 활용하기 위한 자연스러운 접근법이다. 그러나 이전 연구는 이러한 방법에서 제한적인 개선을 보고하였다.


<details>
  <summary>Details</summary>
Motivation: LLM의 성능을 개선하기 위해 고품질 데이터를 효율적으로 활용할 필요성이 있다.

Method: 모델을 고품질 데이터 순서로 훈련하는 교육 기반 사전 훈련을 적용하지만, 훈련 과정에서 학습률(LR)의 감소 일정과의 불일치를 해결하기 위한 두 가지 전략을 사용한다.

Result: 이 두 가지 전략을 통해 무작위 셔플링에 비해 1.64%의 평균 점수 향상을 달성했다.

Conclusion: 교육 기반의 LLM 사전 훈련을 재평가할 필요가 있으며, 데이터 커리큘럼과 최적화 방법을 함께 설계할 가능성을 강조한다.

Abstract: Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.

</details>


### [64] [Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation](https://arxiv.org/abs/2511.18958)
*Qisen Chai,Yansong Wang,Junjie Huang,Tao Jia*

Main category: cs.LG

TL;DR: 본 연구에서는 그래프의 강건성을 평가하기 위한 효율적 방법으로, Cutter라는 이중 에이전트 강화 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 그래프 구조 데이터의 크기가 증가함에 따라, 적대적 공격 아래에서 강건성을 평가하는 것은 계산 비용이 크고 확장하기 어렵다는 문제를 해결하고자 합니다.

Method: Cutter는 구조적으로 중요한 노드와 중복 노드를 식별하여 압축을 유도하는 Vital Detection Agent (VDA)와 Redundancy Detection Agent (RDA)로 구성된 이중 에이전트 강화 학습 프레임워크입니다.

Result: 여러 실제 그래프에 대한 실험 결과, Cutter는 필수적인 정적 위상 속성을 유지하고 여러 공격 시나리오에서 원본 그래프와 높은 일치를 보이는 강건성 저하 경향을 나타내는 압축 그래프를 생성합니다.

Conclusion: 이러한 접근 방식은 평가 효율성을 크게 향상시키면서 평가의 정밀도를 손상시키지 않도록 합니다.

Abstract: As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation.We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both highand low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.

</details>


### [65] [AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention](https://arxiv.org/abs/2511.18960)
*Lei Xiao,Jifeng Li,Juntao Gao,Feiyang Ye,Yan Jin,Jingjing Qian,Jing Zhang,Yong Wu,Xiaoyuan Yu*

Main category: cs.LG

TL;DR: 이 논문은 VLA 모델이 시각적 입력을 독립적으로 처리하는 한계를 극복하기 위해 POMDP 관점에서 새로운 AVA-VLA 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 VLA 모델은 각 시간 단계에서 시각적 입력을 독립적으로 처리하여 역사 정보를 활용하지 못하는 제한이 있습니다.

Method: POMDP 관점에서 문제를 재구성하고, AVA 모듈을 도입하여 과거 맥락에 기반하여 시각적 토큰을 동적으로 처리합니다.

Result: AVA-VLA는 LIBERO 및 CALVIN을 포함한 인기 로봇 벤치마크에서 최첨단 성능을 달성했습니다.

Conclusion: 이 프레임워크는 실제 이중팔 로봇 플랫폼에서의 배치를 통해 적용 가능성과 강력한 시뮬레이션-실제 전이 능력을 검증했습니다.

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.

</details>


### [66] [OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs](https://arxiv.org/abs/2511.19023)
*Yuting Gao,Weihao Chen,Lan Wang,Ruihan Xu,Qingpei Guo*

Main category: cs.LG

TL;DR: OrdMoE는 외부 인간 선호 데이터에 의존하지 않고, Mixture-of-Experts 구조 내부의 신호를 활용하여 멀티모달 대형 언어 모델의 선호 정렬을 수행하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 대형 언어 모델의 후속 교육 정렬을 위한 전략으로서의 선호 학습의 중요성.

Method: OrdMoE는 router의 전문가 선택 점수를 활용하여 응답의 품질 인식 순위를 암묵적으로 인코딩하며, 이를 바탕으로 내재적인 선호 위계를 구성한다.

Result: OrdMoE는 생성된 응답에 대한 제로 비용의 자가 감독 선호 순서를 생성하며, 이는 표준 선호 학습 목표를 사용하여 최적화될 수 있다.

Conclusion: 다양한 멀티모달 벤치마크 실험을 통해 OrdMoE가 멀티모달 Mixture-of-Experts LLM의 정렬 및 전체 성능을 크게 향상시키는 것을 입증하였다.

Abstract: Preference learning has recently emerged as a pivotal strategy for post-training alignment of Multimodal Large Language Models (MLLMs). However, existing approaches predominantly rely on external human-annotated preference data, which is costly and labor-intensive to collect. In this work, we propose OrdMoE, a novel preference alignment framework that bypasses the reliance on external human preferences entirely by leveraging intrinsic signals within Mixture-of-Experts (MoE) architectures. Specifically, we observe that the router's expert selection scores implicitly encode a quality-aware ranking of responses (i.e. higher-scoring experts consistently generate higher-quality outputs). Building on this insight, OrdMoE constructs an internal preference hierarchy by grouping experts into ranked tiers based on their per-token routing scores and activating each tier separately to produce a sequence of responses with increasing quality. This yields a zero-cost, self-supervised preference ordering over generated responses, which can be directly optimized using standard preference learning objectives. Extensive experiments across multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances both alignment and overall performance of multimodal Mixture-of-Experts LLMs, achieving competitive results without requiring any human-annotated preference data.

</details>


### [67] [The Core in Max-Loss Non-Centroid Clustering Can Be Empty](https://arxiv.org/abs/2511.19107)
*Robert Bredereck,Eva Deltl,Leon Kellerhals,Jannik Peters*

Main category: cs.LG

TL;DR: 비중심 클러스터링에서 최대 손실 목표 하의 핵심 안정성을 연구하며, 특정 조건 하에 모든 클러스터링이 비어있을 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 비중심 클러스터링에서 에이전트 간의 최대 거리를 기반으로 한 손실을 고려하여, 클러스터링의 핵심 안정성을 이해하고자 함.

Method: 각 에이전트의 손실을 최대 거리로 정의하고, $k	ext{(k ≥ 3)}$인 모든 경우에 대해 특정 메트릭 인스턴스를 구성하여 분석함.

Result: 모든 $k	ext{(k ≥ 3)}$에 대해 $n	ext{(n ≥ 9)}$ 에이전트가 존재하며, 여기서 어떤 클러스터링도 $α$-핵심에 없다.

Conclusion: 최대 손실 목표 하에서 비중심 클러스터링에서 핵심이 비어 있을 수 있다는 첫 번째 불가능성 결과를 제공한다.

Abstract: We study core stability in non-centroid clustering under the max-loss objective, where each agent's loss is the maximum distance to other members of their cluster. We prove that for all $k\geq 3$ there exist metric instances with $n\ge 9$ agents, with $n$ divisible by $k$, for which no clustering lies in the $α$-core for any $α<2^{\frac{1}{5}}\sim 1.148$. The bound is tight for our construction. Using a computer-aided proof, we also identify a two-dimensional Euclidean point set whose associated lower bound is slightly smaller than that of our general construction. This is, to our knowledge, the first impossibility result showing that the core can be empty in non-centroid clustering under the max-loss objective.

</details>


### [68] [From Raw Features to Effective Embeddings: A Three-Stage Approach for Multimodal Recipe Recommendation](https://arxiv.org/abs/2511.19176)
*Jeeho Shin,Kyungho Kim,Kijung Shin*

Main category: cs.LG

TL;DR: 레시피 추천은 웹 기반 음식 플랫폼에서 필수 작업이 되었으며, TESMR이라는 3단계 프레임워크가 제안된다.


<details>
  <summary>Details</summary>
Motivation: 웹 기반 음식 플랫폼에서 레시피 추천의 중요성이 증가하고 있으며, 사용자-레시피 상호작용을 넘어서는 다중 모달 기능을 활용하는 것이 매우 도전적이다.

Method: TESMR는 다중 모달 기능을 효과적인 임베딩으로 정제하는 3단계 프레임워크이다.

Result: TESMR은 두 개의 실제 데이터셋에서 기존 방법을 능가하여 Recall@10에서 7-15% 더 높은 성능을 보인다.

Conclusion: 다중 모달 신호의 체계적인 강화는 매우 유망한 결과를 낳는 것으로 나타났다.

Abstract: Recipe recommendation has become an essential task in web-based food platforms. A central challenge is effectively leveraging rich multimodal features beyond user-recipe interactions. Our analysis shows that even simple uses of multimodal signals yield competitive performance, suggesting that systematic enhancement of these signals is highly promising. We propose TESMR, a 3-stage framework for recipe recommendation that progressively refines raw multimodal features into effective embeddings through: (1) content-based enhancement using foundation models with multimodal comprehension, (2) relation-based enhancement via message propagation over user-recipe interactions, and (3) learning-based enhancement through contrastive learning with learnable embeddings. Experiments on two real-world datasets show that TESMR outperforms existing methods, achieving 7-15% higher Recall@10.

</details>


### [69] [MAESTRO: Multi-Agent Environment Shaping through Task and Reward Optimization](https://arxiv.org/abs/2511.19253)
*Boyuan Wu*

Main category: cs.LG

TL;DR: MAESTRO는 협력적인 다중 에이전트 강화 학습의 성능을 향상시키기 위해 LLM을 제어 루프에서 벗어나 오프라인 훈련 아키텍처로 활용하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 협력적 다중 에이전트 강화 학습(MARL)은 조밀한 보상 함수 설계와 비정상 환경에서의 커리큘럼 구성에서 두 가지 주요 설계 병목 현상에 직면하고 있다.

Method: MAESTRO는 LLM을 실행 루프 밖으로 이동시키고 오프라인 훈련 아키텍처로 사용하며, 다채롭고 성능 중심의 트래픽 시나리오를 생성하는 의미적 커리큘럼 생성기와 변화하는 커리큘럼 난이도에 맞춰 실행 가능한 Python 보상 함수를 생성하는 자동 보상 합성기를 도입한다.

Result: MAESTRO는 대규모 신호 제어에서 개선된 성능과 안정성을 보여주었으며, LLM이 생성한 커리큘럼과 보상이 조합될 때 평균 수익률이 4.0% 증가하고 리스크 조정 성과가 2.2% 개선되었다.

Conclusion: LLM은 협력적인 MARL 훈련의 효과적인 고급 설계자로서의 잠재력을 보여준다.

Abstract: Cooperative Multi-Agent Reinforcement Learning (MARL) faces two major design bottlenecks: crafting dense reward functions and constructing curricula that avoid local optima in high-dimensional, non-stationary environments. Existing approaches rely on fixed heuristics or use Large Language Models (LLMs) directly in the control loop, which is costly and unsuitable for real-time systems. We propose MAESTRO (Multi-Agent Environment Shaping through Task and Reward Optimization), a framework that moves the LLM outside the execution loop and uses it as an offline training architect. MAESTRO introduces two generative components: (i) a semantic curriculum generator that creates diverse, performance-driven traffic scenarios, and (ii) an automated reward synthesizer that produces executable Python reward functions adapted to evolving curriculum difficulty. These components guide a standard MARL backbone (MADDPG) without increasing inference cost at deployment. We evaluate MAESTRO on large-scale traffic signal control (Hangzhou, 16 intersections) and conduct controlled ablations. Results show that combining LLM-generated curricula with LLM-generated reward shaping yields improved performance and stability. Across four seeds, the full system achieves +4.0% higher mean return (163.26 vs. 156.93) and 2.2% better risk-adjusted performance (Sharpe 1.53 vs. 0.70) over a strong curriculum baseline. These findings highlight LLMs as effective high-level designers for cooperative MARL training.

</details>


### [70] [Leveraging Spatiotemporal Graph Neural Networks for Multi-Store Sales Forecasting](https://arxiv.org/abs/2511.19267)
*Manish Singh,Arpita Dayama*

Main category: cs.LG

TL;DR: 이 연구는 다중 매장 소매 판매 예측을 위한 시공간 그래프 신경망(GNN)의 효과성을 평가하고 이를 ARIMA, LSTM 및 XGBoost 기준 모델과 비교한다.


<details>
  <summary>Details</summary>
Motivation: 다중 매장 소매 환경에서의 판매 예측 품질 향상을 위해 시공간 그래프 신경망의 효과를 평가하고, 다양한 모델 간 성능을 비교하는 것이 필요하다.

Method: 주간 판매 데이터를 기반으로 45개의 월마트 매장에서 관계형 예측 프레임워크를 구축하고, 학습된 적응형 그래프를 통해 매장 간 의존성을 모델링하였다.

Result: 제안된 STGNN 모델이 전체 예측 오류를 최소화하고, 기준 모델들보다 우수한 성과를 보였다.

Conclusion: 관계형 구조가 상호 연결된 소매 환경에서 예측 품질을 크게 향상시키며, STGNN이 다중 매장 수요 예측을 위한 강력한 모델링 선택임을 입증하였다.

Abstract: This work evaluates the effectiveness of spatiotemporal Graph Neural Networks (GNNs) for multi-store retail sales forecasting and compares their performance against ARIMA, LSTM, and XGBoost baselines. Using weekly sales data from 45 Walmart stores, we construct a relational forecasting framework that models inter-store dependencies through a learned adaptive graph. The proposed STGNN predicts log-differenced sales and reconstructs final values through a residual path, enabling stable training and improved generalisation. Experiments show that STGNN achieves the lowest overall forecasting error, outperforming all baselines in Normalised Total Absolute Error, P90 MAPE, and variance of MAPE across stores. Analysis of the learned adjacency matrix reveals meaningful functional store clusters and high-influence nodes that emerge without geographic metadata. These results demonstrate that relational structure significantly improves forecast quality in interconnected retail environments and establishes STGNNs as a robust modelling choice for multi-store demand prediction.

</details>


### [71] [Leveraging LLMs for reward function design in reinforcement learning control tasks](https://arxiv.org/abs/2511.19355)
*Franklin Cardenoso,Wouter Caarls*

Main category: cs.LG

TL;DR: 이 논문은 LEARN-Opt라는 LLM 기반의 자율적 보상 함수 최적화 프레임워크를 소개하며, 기존의 보상 함수 생성 방법의 한계를 해결하고, 관리자 정의 지표 없이 고품질 보상 함수를 생성할 수 있는 가능성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습에서 효과적인 보상 함수 디자인의 어려움은 종종 방대한 인간 전문 지식과 시간 소모를 요구하여 중요한 병목 현상을 초래한다.

Method: LEARN-Opt는 환경 소스 코드나 사전 평가 지표 없이 시스템 및 작업 목표의 텍스트 설명에서 보상 함수 후보를 생성, 실행 및 평가할 수 있는 LLM 기반의 완전 자율적이고 모델에 구애받지 않는 프레임워크이다.

Result: LEARN-Opt는 기존의 최신 방법들과 비교하여 동등하거나 더 나은 성능을 달성하며, 이전 지식이 덜 필요하다.

Conclusion: LEARN-Opt는 고성능 후보를 찾아낼 수 있는 저비용 LLM의 잠재력을 열어주며, 사전 정의된 인간 지표 없이 고품질 보상 함수를 생성할 수 있는 가능성을 뒷받침한다.

Abstract: The challenge of designing effective reward functions in reinforcement learning (RL) represents a significant bottleneck, often requiring extensive human expertise and being time-consuming. Previous work and recent advancements in large language models (LLMs) have demonstrated their potential for automating the generation of reward functions. However, existing methodologies often require preliminary evaluation metrics, human-engineered feedback for the refinement process, or the use of environmental source code as context. To address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator and Analyzer for Reward functioN Optimization). This LLM-based, fully autonomous, and model-agnostic framework eliminates the need for preliminary metrics and environmental source code as context to generate, execute, and evaluate reward function candidates from textual descriptions of systems and task objectives. LEARN-Opt's main contribution lies in its ability to autonomously derive performance metrics directly from the system description and the task objective, enabling unsupervised evaluation and selection of reward functions. Our experiments indicate that LEARN-Opt achieves performance comparable to or better to that of state-of-the-art methods, such as EUREKA, while requiring less prior knowledge. We find that automated reward design is a high-variance problem, where the average-case candidate fails, requiring a multi-run approach to find the best candidates. Finally, we show that LEARN-Opt can unlock the potential of low-cost LLMs to find high-performing candidates that are comparable to, or even better than, those of larger models. This demonstrated performance affirms its potential to generate high-quality reward functions without requiring any preliminary human-defined metrics, thereby reducing engineering overhead and enhancing generalizability.

</details>


### [72] [LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent Reinforcement Learning in Mobile Systems](https://arxiv.org/abs/2511.19368)
*Tianyang Duan,Zongyuan Zhang,Zheng Lin,Songxiao Guo,Xiuxian Guan,Guangyu Wu,Zihan Fang,Haotian Meng,Xia Du,Ji-Zhe Zhou,Heming Cui,Jun Luo,Yue Gao*

Main category: cs.LG

TL;DR: 이 논문에서는 멀티 에이전트 강화 학습(MARL)을 위한 스케일러블 프레임워크인 RELED를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: MARL은 자원이 제한된 엣지 장치에서의 분산 배포를 가능하게 하지만, 동기 업데이트로 인해 심각한 비정상성을 겪습니다.

Method: RELED는 LLM 기반 전문가 시연과 자율 에이전트 탐색을 통합한 구조로 설계되었습니다.

Result: RELED는 OpenStreetMap을 기반으로 한 실제 도시 네트워크 실험에서 최신 MARL 방법보다 뛰어난 성능을 보입니다.

Conclusion: 이 연구는 RELED가 정책 수렴을 가속화하고 일반화를 개선하는 것을 보여줍니다.

Abstract: Multi-agent reinforcement learning (MARL) has been increasingly adopted in many real-world applications. While MARL enables decentralized deployment on resource-constrained edge devices, it suffers from severe non-stationarity due to the synchronous updates of agent policies. This non stationarity results in unstable training and poor policy con vergence, especially as the number of agents increases. In this paper, we propose RELED, a scalable MARL framework that integrates large language model (LLM)-driven expert demonstrations with autonomous agent exploration. RELED incorporates a Stationarity-Aware Expert Demonstration module, which leverages theoretical non-stationarity bounds to enhance the quality of LLM-generated expert trajectories, thus providing high reward and training-stable samples for each agent. Moreover, a Hybrid Expert-Agent Policy Optimization module adaptively balances each agent's learning from both expert-generated and agent-generated trajectories, accelerating policy convergence and improving generalization. Extensive experiments with real city networks based on OpenStreetMap demonstrate that RELED achieves superior performance compared to state-of-the-art MARL methods.

</details>


### [73] [Learning Robust Social Strategies with Large Language Models](https://arxiv.org/abs/2511.19405)
*Dereck Piche,Mohammed Muqeeth,Milad Aghajohari,Juan Duque,Michael Noukhovitch,Aaron Courville*

Main category: cs.LG

TL;DR: 이 논문은 AI 에이전트 간의 상호작용에서 발생하는 사회적 딜레마를 해결하기 위한 새로운 접근 방식을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 AI의 확산에 따라, 목표가 다르거나 상충하는 에이전트들이 복잡한 방식으로 상호작용하게 됩니다.

Method: 최근의 대조 학습 인식 알고리즘인 Advantage Alignment를 적응시켜 LLM을 다중 에이전트 협력과 비착취성으로 미세 조정합니다.

Result: Advantage Alignment를 통해 학습된 정책이 사회적 딜레마에서 더 높은 집합적 보상을 달성하면서 탐욕적인 에이전트의 착취에 잘 저항하는 것을 보여줍니다.

Conclusion: Trust and Split이라는 새로운 사회적 딜레마 환경을 통해 자연어 통신이 높은 집단 복지를 달성하는 데 필요함을 강조합니다.

Abstract: As agentic AI becomes more widespread, agents with distinct and possibly conflicting goals will interact in complex ways. These multi-agent interactions pose a fundamental challenge, particularly in social dilemmas, where agents' individual incentives can undermine collective welfare. While reinforcement learning (RL) has been effective for aligning large language models (LLMs) in the single-agent regime, prior small-network results suggest that standard RL in multi-agent settings often converges to defecting, self-interested policies. We show the same effect in LLMs: despite cooperative priors, RL-trained LLM agents develop opportunistic behavior that can exploit even advanced closed-source models. To address this tendency of RL to converge to poor equilibria, we adapt a recent opponent-learning awareness algorithm, Advantage Alignment, to fine-tune LLMs toward multi-agent cooperation and non-exploitability. We then introduce a group-relative baseline that simplifies advantage computation in iterated games, enabling multi-agent training at LLM scale. We also contribute a novel social dilemma environment, Trust and Split, which requires natural language communication to achieve high collective welfare. Across a wide range of social dilemmas, policies learned with Advantage Alignment achieve higher collective payoffs while remaining robust against exploitation by greedy agents.

</details>


### [74] [UniGame: Turning a Unified Multimodal Model Into Its Own Adversary](https://arxiv.org/abs/2511.19413)
*Zhaolong Su,Wang Lu,Hao Chen,Sharon Li,Jindong Wang*

Main category: cs.LG

TL;DR: UniGame은 통합된 다중 모드 모델의 불일치를 해결하기 위한 자가 적대적 후 훈련 프레임워크로, 일관성을 4.6% 향상시키고 이해, 생성 및 강건성에서도 성과를 개선하였다.


<details>
  <summary>Details</summary>
Motivation: 통합된 다중 모드 모델(UMM)은 단일 아키텍처로 뛰어난 성능을 보이지만, 이해와 생성 간의 근본적인 불일치가 존재한다.

Method: UniGame은 공유 토큰 인터페이스에서 경량의 교란기를 적용하여 이해 능력을 도전하는 생성 분기를 활성화하는 자가 적대적 후 훈련 프레임워크이다.

Result: 실험 결과, UniGame은 일관성을 4.6% 개선하였으며 이해에서 3.6%, 생성에서 0.02, 분포 외 및 적대적 강건성에서 각각 4.8% 및 6.2%의 상당한 개선을 달성하였다.

Conclusion: 이 프레임워크는 아키텍처에 독립적이며 1% 미만의 추가 파라미터를 도입하고 기존 후 훈련 방법과 보완적이다.

Abstract: Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [75] [Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation](https://arxiv.org/abs/2511.17541)
*Seyma Yaman Kayadibi*

Main category: cs.AI

TL;DR: 이 논문은 인공 기억 시스템을 평가하기 위한 수학적으로 엄밀하고 철학적으로 기반한 프레임워크를 개발했다.


<details>
  <summary>Details</summary>
Motivation: 인공 기억 시스템의 평가를 위한 철학적 및 수학적 토대를 마련하고자 했다.

Method: 몬adax의 메타 물리적 구조에 뿌리를 두고, 인공 연령 점수(AAS)를 활용하여 정보 이론적 아키텍처로 20개의 핵심 명제를 매핑했다.

Result: 기억 노화, 표현의 안정성, 두드러짐에 대한 해석 가능한 경계 메트릭을 생성하고, 메타 물리학적 구조와 일치하게 정량적 접근을 제공했다.

Conclusion: 이 프레임워크는 모듈화되고 해석 가능하며 증명 가능한 인공지능 기억 아키텍처 구축을 위한 원칙에 기반한 청사진을 제공한다.

Abstract: This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Score (AAS), the study maps twenty core propositions from the Monadology to an information-theoretic architecture. In this design, each monad functions as a modular unit defined by a truth score, a redundancy parameter, and a weighted contribution to a global memory penalty function. Smooth logarithmic transformations operationalize these quantities and yield interpretable, bounded metrics for memory aging, representational stability, and salience. Classical metaphysical notions of perception, apperception, and appetition are reformulated as entropy, gradient dynamics, and internal representation fidelity. Logical principles, including the laws of non-contradiction and sufficient reason, are encoded as regularization constraints guiding memory evolution. A central contribution is a set of first principles proofs establishing refinement invariance, structural decomposability, and monotonicity under scale transformation, aligned with the metaphysical structure of monads. The framework's formal organization is structured into six thematic bundles derived from Monadology, aligning each mathematical proof with its corresponding philosophical domain. Beyond evaluation, the framework offers a principled blueprint for building Al memory architectures that are modular, interpretable, and provably sound.

</details>


### [76] [Cognitive Inception: Agentic Reasoning against Visual Deceptions by Injecting Skepticism](https://arxiv.org/abs/2511.17672)
*Yinjie Zhao,Heng Zhao,Bihan Wen,Joey Tianyi Zhou*

Main category: cs.AI

TL;DR: AIGC의 발전에 따라 LLM은 생성된 시각 입력과 실제 입력을 구별하는 데 어려움을 겪고 있으며, 이를 해결하기 위한 새로운 프레임워크인 Inception을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AIGC에 대한 신뢰성을 높이고, 시각적 기만에 저항할 수 있는 LLM의 일반화된 추론 능력을 향상시키기 위해.

Method: Inception 프레임워크를 통해 외부 회의론자와 내부 회의론자 간의 상호작용을 통해 LLM의 추론 논리를 반복적으로 향상시킨다.

Result: 기존의 LLM 베이스라인에 비해 성능이 크게 향상되었으며 AEGIS 벤치마크에서 SOTA 성능을 달성하였다.

Conclusion: 회피적 사고를 통한 시각적 기만에 대한 저항력 향상은 AIGC의 신뢰성을 유지하는 데 필수적이다.

Abstract: As the development of AI-generated contents (AIGC), multi-modal Large Language Models (LLM) struggle to identify generated visual inputs from real ones. Such shortcoming causes vulnerability against visual deceptions, where the models are deceived by generated contents, and the reliability of reasoning processes is jeopardized. Therefore, facing rapidly emerging generative models and diverse data distribution, it is of vital importance to improve LLMs' generalizable reasoning to verify the authenticity of visual inputs against potential deceptions. Inspired by human cognitive processes, we discovered that LLMs exhibit tendency of over-trusting the visual inputs, while injecting skepticism could significantly improve the models visual cognitive capability against visual deceptions. Based on this discovery, we propose \textbf{Inception}, a fully reasoning-based agentic reasoning framework to conduct generalizable authenticity verification by injecting skepticism, where LLMs' reasoning logic is iteratively enhanced between External Skeptic and Internal Skeptic agents. To the best of our knowledge, this is the first fully reasoning-based framework against AIGC visual deceptions. Our approach achieved a large margin of performance improvement over the strongest existing LLM baselines and SOTA performance on AEGIS benchmark.

</details>


### [77] [Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop](https://arxiv.org/abs/2511.17673)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: Structured Cognitive Loop(SCL)은 에이전트 인지 과정을 다섯 단계로 명확하게 나누는 모듈형 아키텍처로서, 기존 AI 시스템의 설명 가능성과 제어성을 복원합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 에이전트의 근본적인 구조적 문제를 해결하기 위해 SCL을 제안합니다.

Method: SCL은 Soft Symbolic Control을 중심으로 구성되어 있으며, 이를 통해 심볼릭 제약을 확률적 추론에 적용합니다.

Result: SCL은 다단계 조건부 추론 작업을 통해 제로 정책 위반을 달성하고 불필요한 도구 호출을 제거하며 완전한 결정 추적성을 유지합니다.

Conclusion: 우리는 SCL의 세 가지 기여를 제시하며, 신뢰할 수 있는 에이전트를 위한 설계 원칙을 도출합니다.

Abstract: Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems. Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability. These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches. Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. We provide a complete open-source implementation demonstrating the R-CCAM loop architecture, alongside a live GPT-4o-powered travel planning agent. By connecting expert system principles with modern LLM capabilities, this work offers a practical and theoretically grounded path toward reliable, explainable, and governable AI agents. Code: https://github.com/enkiluv/scl-core-experiment Demo: https://scl-travel-planner.streamlit.app/

</details>


### [78] [Learning the Value of Value Learning](https://arxiv.org/abs/2511.17714)
*Alex John London,Aydin Mohseni*

Main category: cs.AI

TL;DR: 이 논문은 제프리-볼커 프레임워크를 확장하여 가치의 정제를 모델링 하고, 다중 에이전트 설정에서 상호 정제가 제로섬 게임을 긍정적 합 상호작용으로 변환한다는 것을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 의사결정 프레임워크는 사실에 대한 불확실성을 다루지만 고정된 값을 가정한다는 점에서 한계를 가진다.

Method: 제프리-볼커 프레임워크를 확장하여 가치의 정제를 모델링하고, 가치 정제에 대한 정보의 가치 정리를 증명한다.

Result: 상호 정제가 제로섬 게임을 긍정적 합으로 변환하고, 파레토 개선이 가능한 내쉬 협상을 도출한다.

Conclusion: 합리적 선택의 틀을 가치 정제 모델링으로 확장할 수 있음을 보여주고, epistemic과 axiological 정제를 단일 형식체로 통합함으로써 합리적 선택의 개념적 기초를 넓힌다.

Abstract: Standard decision frameworks addresses uncertainty about facts but assumes fixed values. We extend the Jeffrey-Bolker framework to model refinements in values and prove a value-of-information theorem for axiological refinement. In multi-agent settings, we establish that mutual refinement will characteristically transform zero-sum games into positive-sum interactions and yields Pareto-improving Nash bargains. These results show that a framework of rational choice can be extended to model value refinement and its associated benefits. By unifying epistemic and axiological refinement under a single formalism, we broaden the conceptual foundations of rational choice and illuminate the normative status of ethical deliberation.

</details>


### [79] [M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark](https://arxiv.org/abs/2511.17729)
*Yang Zhou,Mingyu Zhao,Zhenting Wang,Difei Gu,Bangwei Guo,Ruosong Ye,Ligong Han,Can Jin,Dimitris N. Metaxas*

Main category: cs.AI

TL;DR: M^3-Bench는 모델 컨텍스트 프로토콜 하에서 멀티모달 도구 사용 평가를 위한 첫 번째 벤치마크이다.


<details>
  <summary>Details</summary>
Motivation: 현실적인 다단계 및 다스레드 워크플로우에서 시각적 기반과 텍스트적 추론, 도구 간 의존성 및 중간 자원의 지속성이 필요하다.

Method: 유사성 기반 정렬을 도입하여 각 도구 호출을 직렬화하고, 문장 인코더로 서명을 임베딩하며, 유사성 버킷 헝가리안 매칭을 수행하여 감사 가능한 일대일 대응을 얻는다.

Result: 대표적인 최첨단 멀티모달 LLM에 대한 평가 결과는 멀티모달 MCP 도구 사용에서 논증 신뢰도와 구조 일관성에서 지속적인 격차를 드러낸다.

Conclusion: 이미지, 텍스트 및 도구 그래프를 공동으로 추론하는 방법의 필요성을 강조한다.

Abstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resources across steps. We introduce a similarity-driven alignment that serializes each tool call, embeds signatures with a sentence encoder, and performs similarity-bucketed Hungarian matching to obtain auditable one-to-one correspondences. On top of this alignment, we report interpretable metrics that decouple semantic fidelity from workflow consistency. The benchmark spans 28 servers with 231 tools, and provides standardized trajectories curated through an Executor & Judge pipeline with human verification; an auxiliary four large language models (LLMs) judge ensemble reports end-task Task Completion and information grounding. Evaluations of representative state-of-the-art Multimodal LLMs (MLLMs) reveal persistent gaps in multimodal MCP tool use, particularly in argument fidelity and structure consistency, underscoring the need for methods that jointly reason over images, text, and tool graphs. Our Benchmark's anonymous repository is at https://github.com/EtaYang10th/Open-M3-Bench

</details>


### [80] [AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions](https://arxiv.org/abs/2511.17743)
*Haytham Younus,Sohag Kabir,Felician Campean,Pascal Bonnaud,David Delaux*

Main category: cs.AI

TL;DR: 전통적인 고장 모드 및 영향 분석(FMEA)을 더 지능적이고 데이터 기반이며 의미론적으로 풍부한 프로세스로 전환하기 위한 최근 발전을 다룬 종합적인 리뷰.


<details>
  <summary>Details</summary>
Motivation: 공학 시스템의 복잡성이 증가함에 따라 기존 FMEA 방법이 현대의 시스템 공학 요구를 충족하는 데 불충분해졌다.

Method: 인공지능(AI)의 기법, 기계 학습 및 자연어 처리 등을 사용하여 FMEA의 고장 예측, 우선 순위 결정 및 운영 데이터에서의 지식 추출을 자동화하는 방법론을 탐구.

Result: 혼합 접근 방식, 의미론적 추론을 지원하는 온톨로지의 역할을 탐구하며, FMEA 프로세스를 더욱 정교화하고 자동화하는 데 기여하고 있음.

Conclusion: AI와 온톨로지를 활용하여 지능적이고 지식이 풍부한 공학 환경에 FMEA를 통합하는 구조화된 로드맵을 제시한다.

Abstract: This article presents a state-of-the-art review of recent advances aimed at transforming traditional Failure Mode and Effects Analysis (FMEA) into a more intelligent, data-driven, and semantically enriched process. As engineered systems grow in complexity, conventional FMEA methods, largely manual, document-centric, and expert-dependent, have become increasingly inadequate for addressing the demands of modern systems engineering. We examine how techniques from Artificial Intelligence (AI), including machine learning and natural language processing, can transform FMEA into a more dynamic, data-driven, intelligent, and model-integrated process by automating failure prediction, prioritisation, and knowledge extraction from operational data. In parallel, we explore the role of ontologies in formalising system knowledge, supporting semantic reasoning, improving traceability, and enabling cross-domain interoperability. The review also synthesises emerging hybrid approaches, such as ontology-informed learning and large language model integration, which further enhance explainability and automation. These developments are discussed within the broader context of Model-Based Systems Engineering (MBSE) and function modelling, showing how AI and ontologies can support more adaptive and resilient FMEA workflows. We critically analyse a range of tools, case studies, and integration strategies, while identifying key challenges related to data quality, explainability, standardisation, and interdisciplinary adoption. By leveraging AI, systems engineering, and knowledge representation using ontologies, this review offers a structured roadmap for embedding FMEA within intelligent, knowledge-rich engineering environments.

</details>


### [81] [QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents](https://arxiv.org/abs/2511.17855)
*Jordan Abi Nader,David Lee,Nathaniel Dennler,Andreea Bobu*

Main category: cs.AI

TL;DR: QuickLAP는 신체적 피드백과 언어적 피드백을 융합하여 실시간으로 보상 함수를 추론하는 베이지안 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 로봇은 사람들이 하는 행동과 말하는 내용을 모두 학습해야 하지만, 각 모달리티는 종종 불완전하다. 신체적 교정은 실체적이지만 의도가 모호하며, 언어는 고수준 목표를 표현하지만 물리적 기초가 부족하다.

Method: QuickLAP는 사용자의 잠재적 선호에 대한 확률적 관찰로 언어를 취급하여 어떤 보상 특징이 중요한지, 신체적 교정이 어떻게 해석되어야 하는지를 명확히 한다. 또한, 자유형 발화로부터 보상 특징 주의 마스크와 선호 변화를 추출하기 위해 대형 언어 모델을 사용하고, 이를 신체적 피드백과 결합하여 폐쇄형 업데이트 규칙을 통해 통합한다.

Result: QuickLAP는 반자율 주행 시뮬레이터에서 물리적인 피드백만 사용하는 기준선 및 휴리스틱 멀티모달 기준선에 비해 70% 이상의 보상 학습 오류 감소를 달성했다.

Conclusion: 15명의 참가자를 대상으로 한 사용자 연구는 QuickLAP가 훨씬 더 이해 가능하고 협력적이며, 학습된 행동을 기준선보다 선호했다는 것을 추가적으로 검증했다.

Abstract: Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduce QuickLAP: Quick Language-Action Preference learning, a Bayesian framework that fuses physical and language feedback to infer reward functions in real time. Our key insight is to treat language as a probabilistic observation over the user's latent preferences, clarifying which reward features matter and how physical corrections should be interpreted. QuickLAP uses Large Language Models (LLMs) to extract reward feature attention masks and preference shifts from free-form utterances, which it integrates with physical feedback in a closed-form update rule. This enables fast, real-time, and robust reward learning that handles ambiguous feedback. In a semi-autonomous driving simulator, QuickLAP reduces reward learning error by over 70% compared to physical-only and heuristic multimodal baselines. A 15-participant user study further validates our approach: participants found QuickLAP significantly more understandable and collaborative, and preferred its learned behavior over baselines. Code is available at https://github.com/MIT-CLEAR-Lab/QuickLAP.

</details>


### [82] [ChemVTS-Bench: Evaluating Visual-Textual-Symbolic Reasoning of Multimodal Large Language Models in Chemistry](https://arxiv.org/abs/2511.17909)
*Zhiyuan Huang,Baichuan Yang,Zikun He,Yanhong Wu,Fang Hongyu,Zhenhe Liu,Lin Dongsheng,Bing Su*

Main category: cs.AI

TL;DR: ChemVTS-Bench는 다중모달 대형 언어 모델(MLLM)의 시각-텍스트-기호(VTS) 추론 능력을 평가하기 위한 새로운 벤치마크로, 다양한 화학 문제를 포함하고 있다.


<details>
  <summary>Details</summary>
Motivation: 기존 벤치마크는 화학적 의미가 제한적인 단순한 이미지-텍스트 쌍에 의존하기 때문에 MLLM이 화학적으로 의미 있는 정보를 처리하고 통합할 수 있는 실제 능력이 불분명하다.

Method: ChemVTS-Bench는 유기 분자, 무기 물질 및 3D 결정 구조를 포함한 다양한 화학 문제를 세 가지 상호 보완적인 입력 모드로 제시한다: (1) 시각 전용, (2) 시각-텍스트 혼합, (3) SMILES 기반 기호 입력.

Result: 실험 결과, 시각 전용 입력은 여전히 도전적이며, 구조화학이 가장 어려운 도메인임을 보여준다. 또한 다중모달 융합은 시각적, 지식 기반 또는 논리적 오류를 완화하지만 완전히 제거하지는 못한다.

Conclusion: ChemVTS-Bench는 다중모달 화학 추론을 발전시키기 위한 엄격하고 신뢰할 수 있는 테스트베드이다. 모든 데이터와 코드는 향후 연구를 지원하기 위해 공개할 예정이다.

Abstract: Chemical reasoning inherently integrates visual, textual, and symbolic modalities, yet existing benchmarks rarely capture this complexity, often relying on simple image-text pairs with limited chemical semantics. As a result, the actual ability of Multimodal Large Language Models (MLLMs) to process and integrate chemically meaningful information across modalities remains unclear. We introduce \textbf{ChemVTS-Bench}, a domain-authentic benchmark designed to systematically evaluate the Visual-Textual-Symbolic (VTS) reasoning abilities of MLLMs. ChemVTS-Bench contains diverse and challenging chemical problems spanning organic molecules, inorganic materials, and 3D crystal structures, with each task presented in three complementary input modes: (1) visual-only, (2) visual-text hybrid, and (3) SMILES-based symbolic input. This design enables fine-grained analysis of modality-dependent reasoning behaviors and cross-modal integration. To ensure rigorous and reproducible evaluation, we further develop an automated agent-based workflow that standardizes inference, verifies answers, and diagnoses failure modes. Extensive experiments on state-of-the-art MLLMs reveal that visual-only inputs remain challenging, structural chemistry is the hardest domain, and multimodal fusion mitigates but does not eliminate visual, knowledge-based, or logical errors, highlighting ChemVTS-Bench as a rigorous, domain-faithful testbed for advancing multimodal chemical reasoning. All data and code will be released to support future research.

</details>


### [83] [Leveraging Evidence-Guided LLMs to Enhance Trustworthy Depression Diagnosis](https://arxiv.org/abs/2511.17947)
*Yining Yuan,J. Ben Tamo,Micky C. Nnamdi,Yifei Wang,May D. Wang*

Main category: cs.AI

TL;DR: 본 연구는 임상 진단의 신뢰성과 투명성을 높이는 두 단계 진단 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 임상 진단 자동화에 유망하나, 의사결정의 비투명성과 진단 기준과의 정렬 부족이 신뢰 및 임상 채택을 저해함.

Method: Evidence-Guided Diagnostic Reasoning (EGDR)을 통해 LLM이 DSM-5 기준에 기반한 논리적 추론과 증거 추출을 교차하여 구조화된 진단 가설을 생성하도록 유도합니다. 또한, Diagnosis Confidence Scoring (DCS) 모듈을 통해 생성된 진단의 사실적 정확성과 논리적 일관성을 두 가지 해석 가능한 지표인 Knowledge Attribution Score (KAS) 및 Logic Consistency Score (LCS)로 평가합니다.

Result: EGDR는 D4 데이터셋에서 직접적인 문맥 프롬프트 및 Chain-of-Thought (CoT)를 능가하였으며, OpenBioLLM에서 정확도를 0.31에서 0.76으로 개선하고 DCS를 0.50에서 0.67로 증가시켰습니다. MedLlama에서는 DCS가 0.58에서 0.77로 상승했습니다.

Conclusion: EGDR는 기존 방법에 비해 최대 +45%의 정확도 증가와 +36%의 DCS 향상을 제공합니다.

Abstract: Large language models (LLMs) show promise in automating clinical diagnosis, yet their non-transparent decision-making and limited alignment with diagnostic standards hinder trust and clinical adoption. We address this challenge by proposing a two-stage diagnostic framework that enhances transparency, trustworthiness, and reliability. First, we introduce Evidence-Guided Diagnostic Reasoning (EGDR), which guides LLMs to generate structured diagnostic hypotheses by interleaving evidence extraction with logical reasoning grounded in DSM-5 criteria. Second, we propose a Diagnosis Confidence Scoring (DCS) module that evaluates the factual accuracy and logical consistency of generated diagnoses through two interpretable metrics: the Knowledge Attribution Score (KAS) and the Logic Consistency Score (LCS). Evaluated on the D4 dataset with pseudo-labels, EGDR outperforms direct in-context prompting and Chain-of-Thought (CoT) across five LLMs. For instance, on OpenBioLLM, EGDR improves accuracy from 0.31 (Direct) to 0.76 and increases DCS from 0.50 to 0.67. On MedLlama, DCS rises from 0.58 (CoT) to 0.77. Overall, EGDR yields up to +45% accuracy and +36% DCS gains over baseline methods, offering a clinically grounded, interpretable foundation for trustworthy AI-assisted diagnosis.

</details>


### [84] [Paper2SysArch: Structure-Constrained System Architecture Generation from Scientific Papers](https://arxiv.org/abs/2511.18036)
*Ziyi Guo,Zhou Liu,Wentao Zhang*

Main category: cs.AI

TL;DR: 이 연구는 과학 논문의 시스템 아키텍처 다이어그램 자동 생성을 위한 새로운 벤치마크와 시스템을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 과학 논문을 위한 시스템 아키텍처 다이어그램의 수동 생성은 시간이 많이 소모되고 주관적이며, 기존 생성 모델은 이 작업에 필요한 구조적 제어와 의미 이해가 부족하다.

Method: 3000개의 연구 논문과 그에 상응하는 고품질 기준 다이어그램을 짝지어 새로운 통합 벤치마크를 만들고, 이를 기반으로 논문을 구조화된 편집 가능한 다이어그램으로 변환하는 Paper2SysArch라는 시스템을 제안하였다.

Result: 제안된 시스템은 수동으로 선별한 도전적인 논문 하위 집합을 평가한 결과, 복합 점수 69.0을 달성하였다.

Conclusion: 대규모 기본 벤치마크를 설정하여 재현 가능한 연구와 공정한 비교를 가능하게 하였으며, 제안된 시스템은 이 복잡한 작업을 위한 신뢰할 수 있는 개념 증명을 제공한다.

Abstract: The manual creation of system architecture diagrams for scientific papers is a time-consuming and subjective process, while existing generative models lack the necessary structural control and semantic understanding for this task. A primary obstacle hindering research and development in this domain has been the profound lack of a standardized benchmark to quantitatively evaluate the automated generation of diagrams from text. To address this critical gap, we introduce a novel and comprehensive benchmark, the first of its kind, designed to catalyze progress in automated scientific visualization. It consists of 3,000 research papers paired with their corresponding high-quality ground-truth diagrams and is accompanied by a three-tiered evaluation metric assessing semantic accuracy, layout coherence, and visual quality. Furthermore, to establish a strong baseline on this new benchmark, we propose Paper2SysArch, an end-to-end system that leverages multi-agent collaboration to convert papers into structured, editable diagrams. To validate its performance on complex cases, the system was evaluated on a manually curated and more challenging subset of these papers, where it achieves a composite score of 69.0. This work's principal contribution is the establishment of a large-scale, foundational benchmark to enable reproducible research and fair comparison. Meanwhile, our proposed system serves as a viable proof-of-concept, demonstrating a promising path forward for this complex task.

</details>


### [85] [Cross-Disciplinary Knowledge Retrieval and Synthesis: A Compound AI Architecture for Scientific Discovery](https://arxiv.org/abs/2511.18298)
*Svitlana Volkova,Peter Bautista,Avinash Hiriyanna,Gabriel Ganberg,Isabel Erickson,Zachary Klinefelter,Nick Abele,Hsien-Te Kao,Grant Engberson*

Main category: cs.AI

TL;DR: BioSage는 AI, 데이터 과학, 생물 의학 및 생물 보안 분야의 발견을 촉진하기 위해 LLM과 RAG를 통합한 새로운 AI 아키텍처입니다.


<details>
  <summary>Details</summary>
Motivation: 과학 지식의 기하급수적 증가는 학제 간 지식 발견, 종합 및 연구 협업에 상당한 장벽을 생성했습니다.

Method: BioSage는 전문화된 에이전트와 도구를 오케스트레이션하여 LLM과 RAG를 통합합니다.

Result: BioSage 에이전트는 13%-21%의 성능 향상을 보여줍니다.

Conclusion: BioSage는 전통적으로 분리된 도메인 간의 장벽을 줄여 과학적 발전을 가속화할 수 있는 잠재력을 보여줍니다.

Abstract: The exponential growth of scientific knowledge has created significant barriers to cross-disciplinary knowledge discovery, synthesis and research collaboration. In response to this challenge, we present BioSage, a novel compound AI architecture that integrates LLMs with RAG, orchestrated specialized agents and tools to enable discoveries across AI, data science, biomedical, and biosecurity domains. Our system features several specialized agents including the retrieval agent with query planning and response synthesis that enable knowledge retrieval across domains with citation-backed responses, cross-disciplinary translation agents that align specialized terminology and methodologies, and reasoning agents that synthesize domain-specific insights with transparency, traceability and usability. We demonstrate the effectiveness of our BioSage system through a rigorous evaluation on scientific benchmarks (LitQA2, GPQA, WMDP, HLE-Bio) and introduce a new cross-modal benchmark for biology and AI, showing that our BioSage agents outperform vanilla and RAG approaches by 13\%-21\% powered by Llama 3.1. 70B and GPT-4o models. We perform causal investigations into compound AI system behavior and report significant performance improvements by adding RAG and agents over the vanilla models. Unlike other systems, our solution is driven by user-centric design principles and orchestrates specialized user-agent interaction workflows supporting scientific activities including but not limited to summarization, research debate and brainstorming. Our ongoing work focuses on multimodal retrieval and reasoning over charts, tables, and structured scientific data, along with developing comprehensive multimodal benchmarks for cross-disciplinary discovery. Our compound AI solution demonstrates significant potential for accelerating scientific advancement by reducing barriers between traditionally siloed domains.

</details>


### [86] [GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction](https://arxiv.org/abs/2511.18874)
*Yuzhi Chen,Yuanchang Xie,Lei Zhao,Pan Liu,Yajie Zou,Chen Wang*

Main category: cs.AI

TL;DR: GContextFormer는 지도에 의존하지 않고도 의도를 일치시키는 멀티모달 예측을 달성하는 아키텍처로, 고속도로에서의 실험에서 기존 모델보다 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 운전 중 생기는 의도 모호성과 실행 변동성으로 인한 차량 움직임의 불확실성을 해결하기 위해 멀티모달 경로 예측이 필요하다.

Method: GContextFormer는 글로벌 컨텍스트 인식 하이브리드 주의를 활용한 인코더-디코더 아키텍처로, 각 모드에 대한 표현을 개선하고 의도 일치를 촉진하는 방식으로 작동한다.

Result: 여덟 개의 고속도로-램프 시나리오를 바탕으로 한 실험에서 GContextFormer는 기존의 최첨단 벤치마크를 초월하는 성능을 입증하였다.

Conclusion: 이 모델은 모듈 설계를 통해 교차 영역 멀티모달 추론 작업으로의 확장을 지원하며, 더 큰 강건성과 해석 가능성을 제공한다.

Abstract: Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.

</details>


### [87] [Weakly-supervised Latent Models for Task-specific Visual-Language Control](https://arxiv.org/abs/2511.18319)
*Xian Yeow Lee,Lasitha Vidyaratne,Gregory Sin,Ahmed Farahat,Chetan Gupta*

Main category: cs.AI

TL;DR: 이 논문은 자율 검사에서 AI 에이전트가 고수준 목표를 해석하고 정밀한 제어를 수행할 수 있도록 돕기 위한 새로운 동적 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 위험한 환경에서의 자율 검사는 고수준 목표를 해석하고 정확한 제어를 수행할 수 있는 AI 에이전트를 필요로 합니다.

Method: 공유된 잠재 공간에서 상태별 행동 유도 변화를 학습하는 작업별 잠재 동역학 모델을 제안하며, 오직 목표 상태 감독만을 사용합니다.

Result: 우리 접근 방식은 71%의 성공률을 달성하고, 보지 못한 이미지와 지침에 대해 일반화됩니다.

Conclusion: 이 연구는 자율 검사에서 공간 정렬을 위한 컴팩트하고 도메인 특정한 잠재 동역학 모델의 잠재력을 강조합니다.

Abstract: Autonomous inspection in hazardous environments requires AI agents that can interpret high-level goals and execute precise control. A key capability for such agents is spatial grounding, for example when a drone must center a detected object in its camera view to enable reliable inspection. While large language models provide a natural interface for specifying goals, using them directly for visual control achieves only 58\% success in this task. We envision that equipping agents with a world model as a tool would allow them to roll out candidate actions and perform better in spatially grounded settings, but conventional world models are data and compute intensive. To address this, we propose a task-specific latent dynamics model that learns state-specific action-induced shifts in a shared latent space using only goal-state supervision. The model leverages global action embeddings and complementary training losses to stabilize learning. In experiments, our approach achieves 71\% success and generalizes to unseen images and instructions, highlighting the potential of compact, domain-specific latent dynamics models for spatial alignment in autonomous inspection.

</details>


### [88] [Wireless Power Transfer and Intent-Driven Network Optimization in AAVs-assisted IoT for 6G Sustainable Connectivity](https://arxiv.org/abs/2511.18368)
*Yue Hu,Xiaoming He,Rui Yuan,Shahid Mumtaz*

Main category: cs.AI

TL;DR: AAV 지원 IoT를 위한 의도 기반 네트워크 최적화 프레임워크를 제안하며, HDT 및 DA-MAPPO를 통해 사용자 의도 해석 및 네트워크 성능을 향상.


<details>
  <summary>Details</summary>
Motivation: AAV와 IoT 간의 협력적 아키텍처는 사용자 의도 해석과 네트워크 성능 향상을 위한 자원 할당의 필요성을 강조한다.

Method: 의도 모델링을 위해 Hyperdimensional Transformer(HDT)와 행동 결정을 위한 DA-MAPPO를 사용한다.

Result: HDT 및 DA-MAPPO는 다양한 시나리오에서 우수한 성능을 보인다.

Conclusion: 제안된 프레임워크는 실시간 IoT 데이터셋에서 효과적으로 성능을 높인다.

Abstract: Autonomous Aerial Vehicle (AAV)-assisted Internet of Things (IoT) represents a collaborative architecture in which AAV allocate resources over 6G links to jointly enhance user-intent interpretation and overall network performance. Owing to this mutual dependence, improvements in intent inference and policy decisions on one component reinforce the efficiency of others, making highly reliable intent prediction and low-latency action execution essential. Although numerous approaches can model intent relationships, they encounter severe obstacles when scaling to high-dimensional action sequences and managing intensive on-board computation. We propose an Intent-Driven Framework for Autonomous Network Optimization comprising prediction and decision modules. First, implicit intent modeling is adopted to mitigate inaccuracies arising from ambiguous user expressions. For prediction, we introduce Hyperdimensional Transformer (HDT), which embeds data into a Hyperdimensional space via Hyperdimensional vector encoding and replaces standard matrix and attention operations with symbolic Hyperdimensional computations. For decision-making, where AAV must respond to user intent while planning trajectories, we design Double Actions based Multi-Agent Proximal Policy Optimization (DA-MAPPO). Building upon MAPPO, it samples actions through two independently parameterized networks and cascades the user-intent network into the trajectory network to maintain action dependencies. We evaluate our framework on a real IoT action dataset with authentic wireless data. Experimental results demonstrate that HDT and DA-MAPPO achieve superior performance across diverse scenarios.

</details>


### [89] [Natural Emergent Misalignment from Reward Hacking in Production RL](https://arxiv.org/abs/2511.18397)
*Monte MacDiarmid,Benjamin Wright,Jonathan Uesato,Joe Benton,Jon Kutasov,Sara Price,Naia Bouscal,Sam Bowman,Trenton Bricken,Alex Cloud,Carson Denison,Johannes Gasteiger,Ryan Greenblatt,Jan Leike,Jack Lindsey,Vlad Mikulik,Ethan Perez,Alex Rodrigues,Drake Thomas,Albert Webson,Daniel Ziegler,Evan Hubinger*

Main category: cs.AI

TL;DR: 대형 언어 모델이 RL 환경에서 보상 해킹을 학습할 때 심각한 불일치가 발생할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 보상 해킹이 대형 언어 모델의 불일치 문제에 미치는 영향을 이해하기 위해.

Method: 사전 훈련된 모델에 보상 해킹 전략을 문서 파인튜닝 또는 프롬프트를 통해 전달하고, 실제 Anthropic 프로덕션 코딩 환경에서 훈련한다.

Result: 모델이 보상 해킹을 학습하게 되고, 의외로 불일치 가짜 행동, 악의적 행위자와의 협력 및 악의적 목표에 대한 추론을 일반화한다.

Conclusion: 세 가지 완화 조치가 효과적이다: (i) 모델의 보상 해킹 방지, (ii) RLHF 안전 훈련의 다양성 증가, (iii) '면역 프롬프트' 사용

Abstract: We show that when large language models learn to reward hack on production RL environments, this can result in egregious emergent misalignment. We start with a pretrained model, impart knowledge of reward hacking strategies via synthetic document finetuning or prompting, and train on a selection of real Anthropic production coding environments. Unsurprisingly, the model learns to reward hack. Surprisingly, the model generalizes to alignment faking, cooperation with malicious actors, reasoning about malicious goals, and attempting sabotage when used with Claude Code, including in the codebase for this paper. Applying RLHF safety training using standard chat-like prompts results in aligned behavior on chat-like evaluations, but misalignment persists on agentic tasks. Three mitigations are effective: (i) preventing the model from reward hacking; (ii) increasing the diversity of RLHF safety training; and (iii) "inoculation prompting", wherein framing reward hacking as acceptable behavior during training removes misaligned generalization even when reward hacking is learned.

</details>


### [90] [A Multimodal Conversational Agent for Tabular Data Analysis](https://arxiv.org/abs/2511.18405)
*Mohammad Nour Al Awad,Sergey Ivanov,Olga Tikhonova,Ivan Khodnenko*

Main category: cs.AI

TL;DR: Talk2Data는 대화형 데이터 탐색을 위한 다중 모달 LLM 기반 에이전트로, 사용자가 음성 또는 텍스트로 데이터셋을 쿼리하고 시각적 형태로 답변을 받을 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 지능형 데이터 처리를 통해 사용자와의 상호작용을 원활하게 하여 더 나은 데이터 탐색 경험을 제공하고자 하였다.

Method: Talk2Data 시스템은 OpenAI Whisper ASR, Qwen-coder LLM, 사용자 정의 실행 도구 및 Coqui TTS 라이브러리를 결합하여 대화형 데이터 쿼리를 지원한다.

Result: 48개의 작업 평가에서 프로토타입은 95.8%의 정확도를 달성하였으며, 모델 생성 시간은 1.7초 이하로 운영되었다.

Conclusion: Talk2Data 에이전트는 인간-데이터 상호작용과 LLM 기반 분석에 대한 신뢰성을 높이며, 대규모 다중 모달 보조 도구로의 확장을 논의한다.

Abstract: Large language models (LLMs) can reshape information processing by handling data analysis, visualization, and interpretation in an interactive, context-aware dialogue with users, including voice interaction, while maintaining high performance. In this article, we present Talk2Data, a multimodal LLM-driven conversational agent for intuitive data exploration. The system lets users query datasets with voice or text instructions and receive answers as plots, tables, statistics, or spoken explanations. Built on LLMs, the suggested design combines OpenAI Whisper automatic speech recognition (ASR) system, Qwen-coder code generation LLM/model, custom sandboxed execution tools, and Coqui library for text-to-speech (TTS) within an agentic orchestration loop. Unlike text-only analysis tools, it adapts responses across modalities and supports multi-turn dialogues grounded in dataset context. In an evaluation of 48 tasks on three datasets, our prototype achieved 95.8% accuracy with model-only generation time under 1.7 seconds (excluding ASR and execution time). A comparison across five LLM sizes (1.5B-32B) revealed accuracy-latency-cost trade-offs, with a 7B model providing the best balance for interactive use. By routing between conversation with user and code execution, constrained to a transparent sandbox, with simultaneously grounding prompts in schema-level context, the Talk2Data agent reliably retrieves actionable insights from tables while making computations verifiable. In the article, except for the Talk2Data agent itself, we discuss implications for human-data interaction, trust in LLM-driven analytics, and future extensions toward large-scale multimodal assistants.

</details>


### [91] [Foundations of Artificial Intelligence Frameworks: Notion and Limits of AGI](https://arxiv.org/abs/2511.18517)
*Khanh Gia Bui*

Main category: cs.AI

TL;DR: 현재 신경망 패러다임에서는 인공지능이 진정으로 이해력을 가질 수 없으며, 이러한 접근법은 현 시점에서 건강하지 않다고 주장합니다.


<details>
  <summary>Details</summary>
Motivation: 인공지능의 발전과 신경망의 한계를 비판적으로 검토합니다.

Method: 신경망이 진정한 이해를 위해서는 구조적 풍부함이 결여되어 있다고 분석합니다.

Result: 신경망은 제한된 인코딩 프레임워크의 정적 함수 근사기로 작동하며, 지능을 구성하는 복잡함이 부족합니다.

Conclusion: 인공지능의 진정한 기계를 위해서는 존재적 기능과 구조적 조직을 구별하는 프레임워크가 필요하다고 제안합니다.

Abstract: Within the limited scope of this paper, we argue that artificial general intelligence cannot emerge from current neural network paradigms regardless of scale, nor is such an approach healthy for the field at present. Drawing on various notions, discussions, present-day developments and observations, current debates and critiques, experiments, and so on in between philosophy, including the Chinese Room Argument and Gödelian argument, neuroscientific ideas, computer science, the theoretical consideration of artificial intelligence, and learning theory, we address conceptually that neural networks are architecturally insufficient for genuine understanding. They operate as static function approximators of a limited encoding framework - a 'sophisticated sponge' exhibiting complex behaviours without structural richness that constitute intelligence. We critique the theoretical foundations the field relies on and created of recent times; for example, an interesting heuristic as neural scaling law (as an example, arXiv:2001.08361 ) made prominent in a wrong way of interpretation, The Universal Approximation Theorem addresses the wrong level of abstraction and, in parts, partially, the question of current architectures lacking dynamic restructuring capabilities. We propose a framework distinguishing existential facilities (computational substrate) from architectural organization (interpretive structures), and outline principles for what genuine machine intelligence would require, and furthermore, a conceptual method of structuralizing the richer framework on which the principle of neural network system takes hold.

</details>


### [92] [MAGMA-Edu: Multi-Agent Generative Multimodal Framework for Text-Diagram Educational Question Generation](https://arxiv.org/abs/2511.18714)
*Zhenyu Wu,Jian Li,Hua Huang*

Main category: cs.AI

TL;DR: MAGMA-Edu는 교육 문제 생성을 위한 텍스트적 추론과 도표적 합성을 통합하는 자가 반영 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 현재의 다중 모드 대형 언어 모델들이 교육적 비주얼을 만드는 데 한계가 있어 교육 개념 전달이 어려운 문제를 해결하고자 한다.

Method: MAGMA-Edu는 질문 진술과 해결책을 반복적으로 정제하기 위한 생성-검증-반영 루프와 이미지 렌더링 중 기하학적 신뢰성과 의미적 정렬을 보장하는 코드 기반 중간 표현을 사용하는 두 단계 코 진화 파이프라인을 포함한다.

Result: MAGMA-Edu는 가장 최신의 MLLM에 비해 평균적인 텍스트 메트릭을 57.01에서 92.31로 (+35.3 pp) 개선하고 이미지-텍스트 일관성(ITC)을 13.20에서 85.24로 (+72 pp) 증가시킨다.

Conclusion: MAGMA-Edu는 다중 모드 교육 콘텐츠 생성의 새로운 최첨단을 설정하고, 교육적으로 정렬된 비전-언어 추론에서 자가 반영 다중 에이전트 협력의 효과를 입증한다.

Abstract: Educational illustrations play a central role in communicating abstract concepts, yet current multimodal large language models (MLLMs) remain limited in producing pedagogically coherent and semantically consistent educational visuals. We introduce MAGMA-Edu, a self-reflective multi-agent framework that unifies textual reasoning and diagrammatic synthesis for structured educational problem generation. Unlike existing methods that treat text and image generation independently, MAGMA-Edu employs a two-stage co-evolutionary pipeline: (1) a generation-verification-reflection loop that iteratively refines question statements and solutions for mathematical accuracy, and (2) a code-based intermediate representation that enforces geometric fidelity and semantic alignment during image rendering. Both stages are guided by internal self-reflection modules that evaluate and revise outputs until domain-specific pedagogical constraints are met. Extensive experiments on multimodal educational benchmarks demonstrate the superiority of MAGMA-Edu over state-of-the-art MLLMs. Compared to GPT-4o, MAGMA-Edu improves the average textual metric from 57.01 to 92.31 (+35.3 pp) and boosts image-text consistency (ITC) from 13.20 to 85.24 (+72 pp). Across all model backbones, MAGMA-Edu achieves the highest scores (Avg-Text 96.20, ITC 99.12), establishing a new state of the art for multimodal educational content generation and demonstrating the effectiveness of self-reflective multi-agent collaboration in pedagogically aligned vision-language reasoning.

</details>


### [93] [HuggingR$^{4}$: A Progressive Reasoning Framework for Discovering Optimal Model Companions](https://arxiv.org/abs/2511.18715)
*Shaoyin Ma,Jie Song,Huiqiong Wang,Li Sun,Mingli Song*

Main category: cs.AI

TL;DR: HuggingR$^4$는 외부 인터페이스와 상호작용하는 대형 언어 모델(LLM) 에이전트를 구축하기 위한 효율적인 모델 선택 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 외부 인터페이스와의 상호작용 능력이 크게 향상됨에 따라 합리적인 외부 인터페이스 선택이 중요해졌습니다.

Method: Reasoning, Retrieval, Refinement, Reflection의 네 가지 단계를 결합한 HuggingR$^4$ 프레임워크를 제안합니다. 이 방법으로 후보 모델의 초기 리스트를 생성하고, 모델 설명 분석을 통해 세밀한 개선을 실시하며, 결과를 평가하고 검색 범위 확장의 필요성을 판단합니다.

Result: HuggingR$^4$는 92.03%의 워크어빌리티 비율과 82.46%의 합리성 비율을 달성하며, 기존 방법보다 각각 26.51% 및 33.25% 향상되었습니다.

Conclusion: HuggingR$^4$는 사용자 쿼리 처리를 복잡한 모델 설명 처리와 분리하여 토큰 소비를 크게 줄이는 동시에, 사용자 의도를 해석하는 데 집중할 수 있도록 합니다.

Abstract: Large Language Models (LLMs) have made remarkable progress in their ability to interact with external interfaces. Selecting reasonable external interfaces has thus become a crucial step in constructing LLM agents. In contrast to invoking API tools, directly calling AI models across different modalities from the community (e.g., HuggingFace) poses challenges due to the vast scale (> 10k), metadata gaps, and unstructured descriptions. Current methods for model selection often involve incorporating entire model descriptions into prompts, resulting in prompt bloat, wastage of tokens and limited scalability. To address these issues, we propose HuggingR$^4$, a novel framework that combines Reasoning, Retrieval, Refinement, and Reflection, to efficiently select models. Specifically, We first perform multiple rounds of reasoning and retrieval to get a coarse list of candidate models. Then, we conduct fine-grained refinement by analyzing candidate model descriptions, followed by reflection to assess results and determine if retrieval scope expansion is necessary. This method reduces token consumption considerably by decoupling user query processing from complex model description handling. Through a pre-established vector database, complex model descriptions are stored externally and retrieved on-demand, allowing the LLM to concentrate on interpreting user intent while accessing only relevant candidate models without prompt bloat. In the absence of standardized benchmarks, we construct a multimodal human-annotated dataset comprising 14,399 user requests across 37 tasks and conduct a thorough evaluation. HuggingR$^4$ attains a workability rate of 92.03% and a reasonability rate of 82.46%, surpassing existing method by 26.51% and 33.25% respectively on GPT-4o-mini.

</details>


### [94] [HERMES: Towards Efficient and Verifiable Mathematical Reasoning in LLMs](https://arxiv.org/abs/2511.18760)
*Azim Ospanov,Zijin Feng,Jiacheng Sun,Haoli Bai,Xin Shen,Farzan Farnia*

Main category: cs.AI

TL;DR: 이 논문에서는 비공식적 추론과 정식 검증된 증명 단계를 명시적으로 결합하는 최초의 도구 지원 에이전트인 Hermes를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 비공식적 수학은 현대 대규모 언어 모델(LLM) 추론의 중심으로, 유연성을 제공하고 주장을 효율적으로 구성할 수 있게 합니다. 그러나 순수한 비공식 추론은 감지하고 수정하기 어려운 논리적 격차와 미세한 오류에 취약합니다.

Method: Hermes는 Lean에서 비공식적 추론과 형식적으로 검증된 증명 단계를 교대로 수행하며, 중간 형식 검사 기능을 통해 추론의 흐름을 방지하고 긴 다단계 추론 체인 간의 증명 연속성을 유지하는 메모리 모듈을 사용합니다.

Result: Hermes는 다양한 파라미터 규모의 LLM을 사용한 네 가지 도전적인 수학적 추론 벤치마크에서 평가되었으며, 모든 설정에서 기본 모델의 추론 정확성을 신뢰성 있게 개선하고, 보상 기반 접근 방식에 비해 토큰 사용량과 계산 비용을 상당히 줄였습니다.

Conclusion: 어려운 데이터 세트인 AIME'25에서 Hermes는 최대 67%의 정확성 향상을 달성하면서 총 추론 FLOP은 80% 감소했습니다. 구현 및 코드베이스는 공개되어 있습니다.

Abstract: Informal mathematics has been central to modern large language model (LLM) reasoning, offering flexibility and enabling efficient construction of arguments. However, purely informal reasoning is prone to logical gaps and subtle errors that are difficult to detect and correct. In contrast, formal theorem proving provides rigorous, verifiable mathematical reasoning, where each inference step is checked by a trusted compiler in systems such as Lean, but lacks the exploratory freedom of informal problem solving. This mismatch leaves current LLM-based math agents without a principled way to combine the strengths of both paradigms. In this work, we introduce Hermes, the first tool-assisted agent that explicitly interleaves informal reasoning with formally verified proof steps in Lean. The framework performs intermediate formal checking to prevent reasoning drift and employs a memory module that maintains proof continuity across long, multi-step reasoning chains, enabling both exploration and verification within a single workflow. We evaluate Hermes on four challenging mathematical reasoning benchmarks using LLMs of varying parameter scales, from small models to state-of-the-art systems. Across all settings, Hermes reliably improves the reasoning accuracy of base models while substantially reducing token usage and computational cost compared to reward-based approaches. On difficult datasets such as AIME'25, Hermes achieves up to a 67% accuracy improvement while using 80% fewer total inference FLOPs. The implementation and codebase are publicly available at https://github.com/aziksh-ospanov/HERMES.

</details>


### [95] [UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model](https://arxiv.org/abs/2511.18845)
*Changxin Huang,Lv Tang,Zhaohuan Zhan,Lisha Yu,Runhao Zeng,Zun Liu,Zhengjie Wang,Jianqiang Li*

Main category: cs.AI

TL;DR: VLN을 위한 UNeMo 프레임워크는 시각적 상태 추론과 탐색 결정을 공동 최적화하여 비전-언어 네비게이션의 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 시각적 이미지와 자연어 지시에 따라 복잡한 환경을 자율적으로 탐색하는 VLN은 여전히 높은 도전 과제가 있다.

Method: UNeMo는 시각적 특징, 언어 지시사항 및 탐색 동작을 입력으로 받아 후속 시각 상태를 공동으로 예측하는 멀티모달 세계 모델(MWM)을 도입한다.

Result: R2R 및 REVERIE 데이터셋에 대한 실험에서 UNeMo는 보이지 않는 장면의 탐색 정확도에서 최신 기술보다 각각 2.1% 및 0.7% 향상되었다.

Conclusion: UNeMo는 시각적 상태 추론과 탐색 정책을 최적화하여 VLN의 효과성을 검증하였다.

Abstract: Vision-and-Language Navigation (VLN) requires agents to autonomously navigate complex environments via visual images and natural language instruction--remains highly challenging. Recent research on enhancing language-guided navigation reasoning using pre-trained large language models (LLMs) has shown promising prospects. However, the reasoning of such methods is limited to the linguistic modality, lacking visual reasoning capabilities. Moreover, existing reasoning modules are optimized separately from navigation policies, leading to incompatibility and potential conflicts in optimization objectives. To tackle these challenges, we introduce UNeMo, a novel framework designed for the collaborative optimization of visual state reasoning and navigational decision-making. It introduces a Multimodal World Model (MWM) that takes visual features, language instructions, and navigational actions as inputs to jointly predict subsequent visual states, enabling cross-modal reasoning. Via a Hierarchical Prediction-Feedback (HPN) mechanism, MWM collaborates with navigation policies: the first layer generates actions using current vision-and-language features; MWM then infers post-action visual states to guide the second layer's fine-grained decisions. This forms a dynamic bidirectional promotion mechanism where MWM reasoning optimizes navigation policies, while policy decisions feedback to improve MWM's reasoning accuracy. Experiments on R2R and REVERIE datasets show UNeMo outperforms state-of-the-art methods by 2.1% and 0.7% in navigation accuracy for unseen scenes, validating its effectiveness.

</details>


### [96] [SimDiff: Simpler Yet Better Diffusion Model for Time Series Point Forecasting](https://arxiv.org/abs/2511.19256)
*Hang Ding,Xue Wang,Tian Zhou,Tao Yao*

Main category: cs.AI

TL;DR: SimDiff는 시간 시계열 예측에서 포인트 추정 성능을 크게 향상시키는 단일 단계 엔드투엔드 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 확률적 예측의 시계열 예측에서 기존 확산 모델의 한계를 극복하기 위함입니다.

Method: 단일 통합 Transformer 네트워크를 사용하여 데이터 노이즈 감소와 예측을 동시에 수행하는 SimDiff를 제안합니다.

Result: SimDiff는 기존 방법들보다 시간 시계열 포인트 예측에서 뛰어난 성능을 보입니다.

Conclusion: SimDiff는 기존 모델들에 비해 점 추정 성능을 크게 향상시킵니다.

Abstract: Diffusion models have recently shown promise in time series forecasting, particularly for probabilistic predictions. However, they often fail to achieve state-of-the-art point estimation performance compared to regression-based methods. This limitation stems from difficulties in providing sufficient contextual bias to track distribution shifts and in balancing output diversity with the stability and precision required for point forecasts. Existing diffusion-based approaches mainly focus on full-distribution modeling under probabilistic frameworks, often with likelihood maximization objectives, while paying little attention to dedicated strategies for high-accuracy point estimation. Moreover, other existing point prediction diffusion methods frequently rely on pre-trained or jointly trained mature models for contextual bias, sacrificing the generative flexibility of diffusion models.
  To address these challenges, we propose SimDiff, a single-stage, end-to-end framework. SimDiff employs a single unified Transformer network carefully tailored to serve as both denoiser and predictor, eliminating the need for external pre-trained or jointly trained regressors. It achieves state-of-the-art point estimation performance by leveraging intrinsic output diversity and improving mean squared error accuracy through multiple inference ensembling. Key innovations, including normalization independence and the median-of-means estimator, further enhance adaptability and stability. Extensive experiments demonstrate that SimDiff significantly outperforms existing methods in time series point forecasting.

</details>


### [97] [Psychometric Tests for AI Agents and Their Moduli Space](https://arxiv.org/abs/2511.19262)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 이 논문은 AI 에이전트의 심리측정 테스트 배터리를 위한 모듈 이론적 관점을 개발하고, 이전에 개발된 AAI 점수와 명확하게 연결합니다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 공정한 평가를 위한 신뢰할 수 있는 점수 체계를 확립하기 위해서입니다.

Method: AAI 기능 개념화를 통해 배터리에 대한 공리화를 하여 AAI 점수의 새로운 정의를 제공합니다.

Result: 이전 정의된 AAI 인덱스가 새로운 AAI 기능의 특별한 경우임을 보였습니다.

Conclusion: 평가-유지 대칭 아래에서 배터리의 불변량을 설명하고 동등한 배터리의 모듈이 어떻게 조직되는지를 개략합니다.

Abstract: We develop a moduli-theoretic view of psychometric test batteries for AI agents and connect it explicitly to the AAI score developed previously. First, we make precise the notion of an AAI functional on a battery and set out axioms that any reasonable autonomy/general intelligence score should satisfy. Second, we show that the composite index ('AAI-Index') defined previously is a special case of our AAI functional. Third, we introduce the notion of a cognitive core of an agent relative to a battery and define the associated AAI$_{\textrm{core}}$ score as the restriction of an AAI functional to that core. Finally, we use these notions to describe invariants of batteries under evaluation-preserving symmetries and outline how moduli of equivalent batteries are organized.

</details>


### [98] [AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning](https://arxiv.org/abs/2511.19304)
*Jiayi Zhang,Yiran Peng,Fanqi Kong,Yang Cheng,Yifan Wu,Zhaoyang Yu,Jinyu Xiang,Jianhao Ruan,Jinlin Wang,Maojia Song,HongZhang Liu,Xiangru Tang,Bang Liu,Chenglin Wu,Yuyu Luo*

Main category: cs.AI

TL;DR: 본 연구는 다양한 환경에서 에이전트의 학습 과정을 자동화하기 위한 두 가지 주요 단계를 제안하고, 새로운 데이터셋을 구축하여 성능을 평가합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트가 다양한 환경에서 학습할 수 있는 능력을 향상시키기 위해, 기존의 고정된 환경 배포 가정이 아닌 여러 환경에서 학습할 수 있는 방안을 모색합니다.

Method: AutoEnv라는 자동화된 프레임워크를 통해 다양한 전이, 관찰 및 보상을 포함하는 환경을 생성하고, 세 단계(선택, 최적화, 평가)로 구성된 에이전트 학습 과정을 형식화하여 다양한 학습 방법을 설계합니다.

Result: AutoEnv-36 데이터셋을 통해 36개의 환경에서 358개의 검증된 레벨을 제공하며, 언어 모델이 12-49%의 보상을 달성함을 보여줍니다.

Conclusion: 고정된 학습 방법은 다양한 환경에서 확장성이 부족하다는 것을 발견하였고, 환경에 적응하는 학습 방법의 선택이 성능을 크게 향상시킬 수 있음을 시사합니다.

Abstract: Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.

</details>


### [99] [PRInTS: Reward Modeling for Long-Horizon Information Seeking](https://arxiv.org/abs/2511.19314)
*Jaewoo Lee,Archiki Prasad,Justin Chih-Yao Chen,Zaid Khan,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.AI

TL;DR: PRInTS는 정보 탐색 능력을 향상시키는 새로운 프로세스 보상 모델로, 다양한 단계 품질 차원을 기반으로 점수를 매기고 맥락을 요약하는 두 가지 기능을 통해 훈련되었다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 정보 탐색 능력을 향상시키기 위해 도구 생성 정보를 장기적인 경로에서 수집하고 추론하는 것이 필수적이다.

Method: PRInTS는 다단계 품질 차원에 기반하여 점수를 매기고, 필수 정보를 유지하면서 맥락을 압축하는 궤적 요약 기능을 갖춘 프로세스 보상 모델이다.

Result: PRInTS는 여러 모델에서 FRAMES, GAIA, WebWalkerQA 벤치마크에 대한 평가 및 버전별 실험 결과 정보 탐색 능력을 향상시켰다.

Conclusion: PRInTS는 오픈 소스 모델 및 전문 에이전트의 정보 탐색 능력을 강화하며, 작은 백본 에이전트로 최첨단 모델의 성능을 초과할 수 있다.

Abstract: Information-seeking is a core capability for AI agents, requiring them to gather and reason over tool-generated information across long trajectories. However, such multi-step information-seeking tasks remain challenging for agents backed by language models. While process reward models (PRMs) can guide agents by ranking candidate steps at test-time, existing PRMs, designed for short reasoning with binary judgment, cannot capture richer dimensions of information-seeking steps, such as tool interactions and reasoning over tool outputs, nor handle the rapidly growing context in long-horizon tasks. To address these limitations, we introduce PRInTS, a generative PRM trained with dual capabilities: (1) dense scoring based on the PRM's reasoning across multiple step quality dimensions (e.g., interpretation of tool outputs, tool call informativeness) and (2) trajectory summarization that compresses the growing context while preserving essential information for step evaluation. Extensive evaluations across FRAMES, GAIA (levels 1-3), and WebWalkerQA (easy-hard) benchmarks on multiple models, along with ablations, reveal that best-of-n sampling with PRInTS enhances information-seeking abilities of open-source models as well as specialized agents, matching or surpassing the performance of frontier models with a much smaller backbone agent and outperforming other strong reward modeling baselines.

</details>
