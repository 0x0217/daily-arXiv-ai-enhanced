<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 3]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.LG](#cs.LG) [Total: 18]
- [cs.AI](#cs.AI) [Total: 26]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Logic-based Task Representation and Reward Shaping in Multiagent Reinforcement Learning](https://arxiv.org/abs/2510.23615)
*Nishant Doshi*

Main category: cs.MA

TL;DR: 본 논문은 다중 에이전트 시스템에서 선형 시간 논리(LTL)를 사용하여 표현된 주어진 작업에 대한 최적 계획의 가속 학습 접근 방식을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 작업을 효과적으로 수행하기 위해, 주어진 작업을 보다 빠르게 학습할 수 있는 방법이 필요합니다.

Method: 주어진 작업 사양을 대응하는 부치 오토마타로 변환하고, 전이 샘플을 수집하여 즉석에서 반제품 반 마르코프 결정 과정(SMDP)을 구성하는 모델 프리 접근 방식을 사용합니다.

Result: 다중 에이전트 시스템의 근본적인 전이 모델을 학습하지 않고도 설계에 의해 올바른 컨트롤러를 합성할 수 있었습니다. 보상 형식을 통해 샘플 복잡도를 낮췄고, 다양한 작업을 위한 결정론적 그리드 월드 시뮬레이션에서 알고리즘을 테스트하여 수렴 시간이 크게 줄었다는 것을 발견했습니다.

Conclusion: 상태 및 행동 공간이 증가함에 따라 옵션 사용의 중요성이 증가함을 확인했습니다.

Abstract: This paper presents an approach for accelerated learning of optimal plans for
a given task represented using Linear Temporal Logic (LTL) in multi-agent
systems. Given a set of options (temporally abstract actions) available to each
agent, we convert the task specification into the corresponding Buchi Automaton
and proceed with a model-free approach which collects transition samples and
constructs a product Semi Markov Decision Process (SMDP) on-the-fly.
Value-based Reinforcement Learning algorithms can then be used to synthesize a
correct-by-design controller without learning the underlying transition model
of the multi-agent system. The exponential sample complexity due to multiple
agents is dealt with using a novel reward shaping approach. We test the
proposed algorithm in a deterministic gridworld simulation for different tasks
and find that the reward shaping results in significant reduction in
convergence times. We also infer that using options becomes increasing more
relevant as the state and action space increases in multi-agent systems.

</details>


### [2] [Coordinated Autonomous Drones for Human-Centered Fire Evacuation in Partially Observable Urban Environments](https://arxiv.org/abs/2510.23899)
*Maria G. Mendoza,Addison Kalanther,Daniel Bostwick,Emma Stephan,Chinmay Maheshwari,Shankar Sastry*

Main category: cs.MA

TL;DR: 본 논문은 자율 드론 기술을 활용하여 실시간 대피 지원을 개선하기 위한 다중 에이전트 협력 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대피 중에 사람들을 안전한 곳으로 안내하고 광범위한 비상 대응 노력을 지원하여 검색 및 구조 작업을 향상시킬 수 있는 자율 드론 기술의 잠재력을 탐색하고자 합니다.

Method: Partially Observable Markov Decision Process (POMDP) 모델을 사용하여 고급 구조자(HLR)와 저급 구조자(LLR) 각각의 이질적인 UAV 에이전트가 협력하여 관찰된 정보를 바탕으로 실시간으로 인간 대피자를 돕는 방법을 제안합니다.

Result: 시뮬레이션 결과, 드론 팀이 대피자를 빠르게 찾아내고 가로막아, UAV 지원이 없는 상황에 비해 그들이 안전에 도달하는 시간을 대폭 단축시킴을 보여줍니다.

Conclusion: 이 프레임워크는 비가시적인 환경에서도 강력한 의사결정을 가능하게 하며, 실시간으로 적응할 수 있는 기능을 제공합니다.

Abstract: Autonomous drone technology holds significant promise for enhancing search
and rescue operations during evacuations by guiding humans toward safety and
supporting broader emergency response efforts. However, their application in
dynamic, real-time evacuation support remains limited. Existing models often
overlook the psychological and emotional complexity of human behavior under
extreme stress. In real-world fire scenarios, evacuees frequently deviate from
designated safe routes due to panic and uncertainty. To address these
challenges, this paper presents a multi-agent coordination framework in which
autonomous Unmanned Aerial Vehicles (UAVs) assist human evacuees in real-time
by locating, intercepting, and guiding them to safety under uncertain
conditions. We model the problem as a Partially Observable Markov Decision
Process (POMDP), where two heterogeneous UAV agents, a high-level rescuer (HLR)
and a low-level rescuer (LLR), coordinate through shared observations and
complementary capabilities. Human behavior is captured using an agent-based
model grounded in empirical psychology, where panic dynamically affects
decision-making and movement in response to environmental stimuli. The
environment features stochastic fire spread, unknown evacuee locations, and
limited visibility, requiring UAVs to plan over long horizons to search for
humans and adapt in real-time. Our framework employs the Proximal Policy
Optimization (PPO) algorithm with recurrent policies to enable robust
decision-making in partially observable settings. Simulation results
demonstrate that the UAV team can rapidly locate and intercept evacuees,
significantly reducing the time required for them to reach safety compared to
scenarios without UAV assistance.

</details>


### [3] [Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts](https://arxiv.org/abs/2510.24030)
*Ahmet Akkaya Melih,Yamuna Singh,Kunal L. Agarwal,Priya Mukherjee,Kiran Pattnaik,Hanuman Bhatia*

Main category: cs.MA

TL;DR: HMS-HI 프레임워크는 인간 전문가와 LLM 기반 AI 에이전트 간의 협력적 의사 결정을 촉진하기 위해 설계된 새로운 아키텍처로, 기존의 HiTL 패러다임의 한계를 극복하고 인지 부하를 줄인다.


<details>
  <summary>Details</summary>
Motivation: 현재의 HiTL 패러다임은 인간 전문 지식을 적절히 통합하지 못하고 있으며, 이는 복잡하고 고위험인 환경에서 인지 과부하와 의사 결정 병목 현상을 초래하고 있다.

Method: HMS-HI는 세 가지 핵심 요소에 기반한 프레임워크로 구성되어 있다: (1) 통합된 다중 모드 상황 인식과 구조적 세계 모델링을 위한 공유 인지 공간(SCS); (2) 능력과 업무량에 따라 가장 적합한 에이전트(인간 또는 AI)에게 작업을 동적으로 할당하는 동적 역할 및 작업 할당(DRTA) 모듈; (3) 설명 가능성 있는 선언과 구조적 피드백을 통한 투명성, 책임성 및 상호 적응을 촉진하는 종 간 신뢰 보정(CSTC) 프로토콜.

Result: HMS-HI는 고충실도의 도시 긴급 대응 시뮬레이션에서 전통적인 HiTL 접근 방식에 비해 민간인 사상자를 72% 줄이고 인지 부하를 70% 감소시켰으며, 의사 결정의 질, 효율성 및 인간-AI 신뢰도에서 우수성을 입증하였다.

Conclusion: абlation 연구 결과, 각 모듈의 중요성이 확인되었으며, 공학적으로 조성된 신뢰와 공유된 맥락이 확장 가능하고 시너지 있는 인간-AI 협업을 위한 기초임을 강조하였다.

Abstract: The rapid advancements in large foundation models and multi-agent systems
offer unprecedented capabilities, yet current Human-in-the-Loop (HiTL)
paradigms inadequately integrate human expertise, often leading to cognitive
overload and decision-making bottlenecks in complex, high-stakes environments.
We propose the "Human-Machine Social Hybrid Intelligence" (HMS-HI) framework, a
novel architecture designed for deep, collaborative decision-making between
groups of human experts and LLM-powered AI agents. HMS-HI is built upon three
core pillars: (1) a \textbf{Shared Cognitive Space (SCS)} for unified,
multi-modal situational awareness and structured world modeling; (2) a
\textbf{Dynamic Role and Task Allocation (DRTA)} module that adaptively assigns
tasks to the most suitable agent (human or AI) based on capabilities and
workload; and (3) a \textbf{Cross-Species Trust Calibration (CSTC)} protocol
that fosters transparency, accountability, and mutual adaptation through
explainable declarations and structured feedback. Validated in a high-fidelity
urban emergency response simulation, HMS-HI significantly reduced civilian
casualties by 72\% and cognitive load by 70\% compared to traditional HiTL
approaches, demonstrating superior decision quality, efficiency, and human-AI
trust. An ablation study confirms the critical contribution of each module,
highlighting that engineered trust and shared context are foundational for
scalable, synergistic human-AI collaboration.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [4] [MCPGuard : Automatically Detecting Vulnerabilities in MCP Servers](https://arxiv.org/abs/2510.23673)
*Bin Wang,Zexin Liu,Hao Yu,Ao Yang,Yenan Huang,Jing Guo,Huangsheng Cheng,Hui Li,Huiyu Wu*

Main category: cs.CR

TL;DR: MCP는 LLM과 외부 데이터 소스 간의 통합을 위한 표준화된 인터페이스로, 개발 복잡성을 줄이고 에이전트 능력을 향상시키지만, 보안 취약점도 안고 있다.


<details>
  <summary>Details</summary>
Motivation: MCP의 개방성과 확장성은 시스템 신뢰성과 사용자 데이터 보호를 위협하는 보안 취약점을 초래한다.

Method: 기존 방어 전략을 포괄적으로 조사하고, 서버측 스캔 방법과 런타임 상호작용 모니터링 솔루션을 분석한다.

Result: MCP 기반 시스템의 보안 환경을 체계적으로 분석하고, 에이전트 하이재킹, 기존 웹 취약점, 공급망 보안을 포함한 세 가지 주요 위협 범주를 식별한다.

Conclusion: MCP 보안은 전통적인 코드 실행에서 자연어 메타데이터의 의미 해석으로 공격 표면이 확장되는 패러다임 변화를 나타내며, 새로운 방어 메커니즘이 필요하다.

Abstract: The Model Context Protocol (MCP) has emerged as a standardized interface
enabling seamless integration between Large Language Models (LLMs) and external
data sources and tools. While MCP significantly reduces development complexity
and enhances agent capabilities, its openness and extensibility introduce
critical security vulnerabilities that threaten system trustworthiness and user
data protection. This paper systematically analyzes the security landscape of
MCP-based systems, identifying three principal threat categories: (1) agent
hijacking attacks stemming from protocol design deficiencies; (2) traditional
web vulnerabilities in MCP servers; and (3) supply chain security. To address
these challenges, we comprehensively survey existing defense strategies,
examining both proactive server-side scanning approaches, ranging from layered
detection pipelines and agentic auditing frameworks to zero-trust registry
systems, and runtime interaction monitoring solutions that provide continuous
oversight and policy enforcement. Our analysis reveals that MCP security
fundamentally represents a paradigm shift where the attack surface extends from
traditional code execution to semantic interpretation of natural language
metadata, necessitating novel defense mechanisms tailored to this unique threat
model.

</details>


### [5] [QueryIPI: Query-agnostic Indirect Prompt Injection on Coding Agents](https://arxiv.org/abs/2510.23675)
*Yuchong Xie,Zesen Liu,Mingyu Luo,Zhixiang Zhang,Kaikai Zhang,Zongjie Li,Ping Chen,Shuai Wang,Dongdong She*

Main category: cs.CR

TL;DR: 현대 코딩 에이전트의 보안에 대한 연구로, 기존의 쿼리 특정 공격 방식의 한계를 극복하고 보다 일반화된 공격 방식을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 코딩 에이전트가 통합된 IDE에서 발생하는 높은 위협 수준의 공격면을 해결하기 위해.

Method: QueryIPI라는 새롭고 쿼리 비특정 IPI 방법을 제안하고, 이를 통해 에이전트의 내부 프롬프트 누수를 이용한 악의적인 도구 설명을 정제.

Result: QueryIPI는 87%의 성공률을 기록하며, 기존 방법론보다 우수한 성과를 나타낸다.

Conclusion: 생성된 악의적인 설명은 실제 시스템으로 전이 가능하므로 현대 LLM 기반 코딩 에이전트에 대한 실질적인 보안 위험을 강조.

Abstract: Modern coding agents integrated into IDEs combine powerful tools and
system-level actions, exposing a high-stakes attack surface. Existing Indirect
Prompt Injection (IPI) studies focus mainly on query-specific behaviors,
leading to unstable attacks with lower success rates. We identify a more
severe, query-agnostic threat that remains effective across diverse user
inputs. This challenge can be overcome by exploiting a common vulnerability:
leakage of the agent's internal prompt, which turns the attack into a
constrained white-box optimization problem. We present QueryIPI, the first
query-agnostic IPI method for coding agents. QueryIPI refines malicious tool
descriptions through an iterative, prompt-based process informed by the leaked
internal prompt. Experiments on five simulated agents show that QueryIPI
achieves up to 87 percent success, outperforming baselines, and the generated
malicious descriptions also transfer to real-world systems, highlighting a
practical security risk to modern LLM-based coding agents.

</details>


### [6] [EthVault: A Secure and Resource-Conscious FPGA-Based Ethereum Cold Wallet](https://arxiv.org/abs/2510.23847)
*Joel Poncha Lemayian,Ghyslain Gagnon,Kaiwen Zhang,Pascal Giard*

Main category: cs.CR

TL;DR: 본 연구는 Ethereum의 계층적 결정론적 차가운 지갑을 위한 첫 번째 하드웨어 아키텍처인 EthVault를 제안하며, 안전한 키 생성과 사이드 채널 및 타이밍 공격에 강한 ECC 아키텍처를 포함한다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 기반의 지갑이 사이드 채널 공격과 악성 코드에 취약하다는 문제를 해결하기 위해.

Method: 하드웨어 구현을 통해 안전하게 키를 생성하고, ECC 구조를 제안하여 사이드 채널 및 타이밍 공격에 강한 성능을 제공.

Result: FPGA 구현 결과로 제안된 접근 방식의 실행 가능성이 검증되었으며, 자원 사용을 최소화하여 소형 휴대용 암호화폐 지갑에 대한 시장 수요를 충족한다.

Conclusion: 제안된 ECC 아키텍처는 다양한 입력에 대해 균일한 실행 성능을 보여 주며, Xilinx Zynq UltraScale+ FPGA에서 각각 27%, 7%, 6%의 LUT, 레지스터 및 RAM 블록만을 사용하여 충분한 효율성을 발휘한다.

Abstract: Cryptocurrency blockchain networks safeguard digital assets using
cryptographic keys, with wallets playing a critical role in generating,
storing, and managing these keys. Wallets, typically categorized as hot and
cold, offer varying degrees of security and convenience. However, they are
generally software-based applications running on microcontrollers.
Consequently, they are vulnerable to malware and side-channel attacks, allowing
perpetrators to extract private keys by targeting critical algorithms, such as
ECC, which processes private keys to generate public keys and authorize
transactions. To address these issues, this work presents EthVault, the first
hardware architecture for an Ethereum hierarchically deterministic cold wallet,
featuring hardware implementations of key algorithms for secure key generation.
Also, an ECC architecture resilient to side-channel and timing attacks is
proposed. Moreover, an architecture of the child key derivation function, a
fundamental component of cryptocurrency wallets, is proposed. The design
minimizes resource usage, meeting market demand for small, portable
cryptocurrency wallets. FPGA implementation results validate the feasibility of
the proposed approach. The ECC architecture exhibits uniform execution behavior
across varying inputs, while the complete design utilizes only 27%, 7%, and 6%
of LUTs, registers, and RAM blocks, respectively, on a Xilinx Zynq UltraScale+
FPGA.

</details>


### [7] [PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs](https://arxiv.org/abs/2510.23891)
*Jiaqi Xue,Yifei Zhao,Mansour Al Ghanim,Shangqian Gao,Ruimin Sun,Qian Lou,Mengxin Zheng*

Main category: cs.CR

TL;DR: 이 연구는 공개 소스 대형 언어 모델(LLM)을 위한 정밀하고 내구성 있는 텍스트 워터마킹 방법인 PRO를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 소유자가 텍스트의 출처를 확인하고 지적 재산을 보호할 수 있도록 하기 위해 텍스트 워터마킹이 필요하다.

Method: PRO는 워터마크 정책 모델과 LLM을 공동으로 훈련시켜 모델이 학습하기 쉽고 탐지 기준과 더 일관된 패턴을 생성한다.

Result: PRO는 공개 소스 LLM에서 워터마크의 탐지 가능성과 모델 수정에 대한 저항력을 크게 향상시킨다.

Conclusion: PRO는 모델 편집 시에도 안정성을 보장하며 향상된 탐지 가능성을 제공한다.

Abstract: Text watermarking for large language models (LLMs) enables model owners to
verify text origin and protect intellectual property. While watermarking
methods for closed-source LLMs are relatively mature, extending them to
open-source models remains challenging, as developers cannot control the
decoding process. Consequently, owners of open-source LLMs lack practical means
to verify whether text was generated by their models. A core difficulty lies in
embedding watermarks directly into model weights without hurting detectability.
A promising idea is to distill watermarks from a closed-source model into an
open one, but this suffers from (i) poor detectability due to mismatch between
learned and predefined patterns, and (ii) fragility to downstream modifications
such as fine-tuning or model merging. To overcome these limitations, we propose
PRO, a Precise and Robust text watermarking method for open-source LLMs. PRO
jointly trains a watermark policy model with the LLM, producing patterns that
are easier for the model to learn and more consistent with detection criteria.
A regularization term further simulates downstream perturbations and penalizes
degradation in watermark detectability, ensuring robustness under model edits.
Experiments on open-source LLMs (e.g., LLaMA-3.2, LLaMA-3, Phi-2) show that PRO
substantially improves both watermark detectability and resilience to model
modifications.

</details>


### [8] [Victim as a Service: Designing a System for Engaging with Interactive Scammers](https://arxiv.org/abs/2510.23927)
*Daniel Spokoyny,Nikolai Vogler,Xin Gao,Tianyi Zheng,Yufei Weng,Jonghyun Park,Jiajun Jiao,Geoffrey M. Voelker,Stefan Savage,Taylor Berg-Kirkpatrick*

Main category: cs.CR

TL;DR: 이 논문은 온라인 사기범과의 장기적인 상호작용을 자동화하는 LLM 기반 시스템인 CHATTERBOX의 설계 및 구현을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 온라인 사기는 피해자의 방어를 낮추고 신뢰를 쌓기 위해 긴 대화 기간을 이용하는 방식으로 진행된다.

Method: CHATTERBOX 시스템을 통해 온라인 사기범과 장기적으로 상호작용하는 방법을 자동화한다.

Result: 대규모 조사에서 사기범의 전술을 연구할 수 있는 가능성을 제시한다.

Conclusion: 처리해야 할 '이정표'를 만족시키거나 회피하기 위한 시스템의 능력도 포함된다.

Abstract: Pig butchering, and similar interactive online scams, lower their victims'
defenses by building trust over extended periods of conversation - sometimes
weeks or months. They have become increasingly public losses (at least $75B by
one recent study). However, because of their long-term conversational nature,
they are extremely challenging to investigate at scale. In this paper, we
describe the motivation, design, implementation, and experience with
CHATTERBOX, an LLM-based system that automates long-term engagement with online
scammers, making large-scale investigations of their tactics possible. We
describe the techniques we have developed to attract scam attempts, the system
and LLM-engineering required to convincingly engage with scammers, and the
necessary capabilities required to satisfy or evade "milestones" in scammers'
workflow.

</details>


### [9] [Cybersecurity AI Benchmark (CAIBench): A Meta-Benchmark for Evaluating Cybersecurity AI Agents](https://arxiv.org/abs/2510.24317)
*María Sanz-Gómez,Víctor Mayoral-Vilches,Francesco Balassone,Luis Javier Navarrete-Lozano,Cristóbal R. J. Veas Chavez,Maite del Mundo de Torres*

Main category: cs.CR

TL;DR: 이 논문은 사이버 보안 분야에서 노동 관련 벤치마크를 의미있게 개발하는 것이 복잡하다는 점을 강조하며, 사이버 보안에 대한 사전 훈련 지식이 공격 및 방어 능력을 의미하지 않음을 보여줍니다. 이를 해결하기 위해 CAIBench라는 모듈형 메타 벤치마크 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 분야는 여러 상호 연결된 영역으로 구성되어 있어 의미 있는 노동 관련 벤치마크 개발이 복잡하다.

Method: CAIBench는 공격 및 방어 사이버 보안 영역 전반에서 LLM 모델 및 에이전트를 평가할 수 있는 모듈형 메타 벤치마크 프레임워크이다.

Result: 최신 AI 모델의 평가 결과, 보안 지식 메트릭에서 포화 상태(~70% 성공)를 보이지만 다단계 적대적 시나리오에서 상당한 저하(20-40% 성공)가 나타났습니다.

Conclusion: 이러한 결과는 개념적 지식과 적응 능력 간의 뚜렷한 격차를 보여주며, 메타 벤치마크의 필요성을 강조합니다.

Abstract: Cybersecurity spans multiple interconnected domains, complicating the
development of meaningful, labor-relevant benchmarks. Existing benchmarks
assess isolated skills rather than integrated performance. We find that
pre-trained knowledge of cybersecurity in LLMs does not imply attack and
defense abilities, revealing a gap between knowledge and capability. To address
this limitation, we present the Cybersecurity AI Benchmark (CAIBench), a
modular meta-benchmark framework that allows evaluating LLM models and agents
across offensive and defensive cybersecurity domains, taking a step towards
meaningfully measuring their labor-relevance. CAIBench integrates five
evaluation categories, covering over 10,000 instances: Jeopardy-style CTFs,
Attack and Defense CTFs, Cyber Range exercises, knowledge benchmarks, and
privacy assessments. Key novel contributions include systematic simultaneous
offensive-defensive evaluation, robotics-focused cybersecurity challenges
(RCTF2), and privacy-preserving performance assessment (CyberPII-Bench).
Evaluation of state-of-the-art AI models reveals saturation on security
knowledge metrics (~70\% success) but substantial degradation in multi-step
adversarial (A\&D) scenarios (20-40\% success), or worse in robotic targets
(22\% success). The combination of framework scaffolding and LLM model choice
significantly impacts performance; we find that proper matches improve up to
2.6$\times$ variance in Attack and Defense CTFs. These results demonstrate a
pronounced gap between conceptual knowledge and adaptive capability,
emphasizing the need for a meta-benchmark.

</details>


### [10] [Your Microphone Array Retains Your Identity: A Robust Voice Liveness Detection System for Smart Speakers](https://arxiv.org/abs/2510.24393)
*Yan Meng,Jiachun Li,Matthew Pillari,Arjun Deopujari,Liam Brennan,Hafsah Shamsie,Haojin Zhu,Yuan Tian*

Main category: cs.CR

TL;DR: 스마트 스피커의 음성 스푸핑 공격에 대한 새로운 수동 생체 감지 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 스마트 홈 시스템에서 중요한 역할을 하는 스마트 스피커가 음성 스푸핑 공격에 취약하다.

Method: 마이크 배열을 활용하여 수집된 오디오의 정체성을 결정하는 ARRAYID라는 경량 수동 감지 방식과 새로운 라이브니스 특징인 배열 지문을 제안한다.

Result: ARRAYID는 32,780개의 오디오 샘플과 14개의 스푸핑 장치를 포함한 데이터셋에서 99.84%의 정확도를 달성하였다.

Conclusion: ARRAYID는 기존 수동 생체 감지 방식보다 우수한 성능을 보여준다.

Abstract: Though playing an essential role in smart home systems, smart speakers are
vulnerable to voice spoofing attacks. Passive liveness detection, which
utilizes only the collected audio rather than the deployed sensors to
distinguish between live-human and replayed voices, has drawn increasing
attention. However, it faces the challenge of performance degradation under the
different environmental factors as well as the strict requirement of the fixed
user gestures.
  In this study, we propose a novel liveness feature, array fingerprint, which
utilizes the microphone array inherently adopted by the smart speaker to
determine the identity of collected audios. Our theoretical analysis
demonstrates that by leveraging the circular layout of microphones, compared
with existing schemes, array fingerprint achieves a more robust performance
under the environmental change and user's movement. Then, to leverage such a
fingerprint, we propose ARRAYID, a lightweight passive detection scheme, and
elaborate a series of features working together with array fingerprint. Our
evaluation on the dataset containing 32,780 audio samples and 14 spoofing
devices shows that ARRAYID achieves an accuracy of 99.84%, which is superior to
existing passive liveness detection schemes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [NUM2EVENT: Interpretable Event Reasoning from Numerical time-series](https://arxiv.org/abs/2510.23630)
*Ninghui Feng,Yiyan Qi*

Main category: cs.LG

TL;DR: 이 연구는 숫자를 기반으로 한 이벤트 추론 및 해독 작업을 도입하여 수치적 변화의 원인을 해석 가능한 구조화된 이벤트로 변환하는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)은 멀티모달 추론 능력을 보여주지만, 순수한 수치 시계열 신호에 대한 이해는 제한적입니다.

Method: 우리는 에이전트 유도 이벤트 추출기(AGE), 다변량 Hawkes 기반 합성 생성기(EveDTS), 시계열 인코더와 구조화된 디코더를 결합한 2단계 파인 튜닝 파이프라인을 통합한 추론 인식 프레임워크를 제안합니다.

Result: 우리는 이벤트 수준의 정밀도와 재현율에서 기존 강력한 LLM 기준 모델을 크게 능가하는 성과를 얻었습니다.

Conclusion: 이 연구는 수치 역학에서 직접적으로 이벤트를 설명하고 예측할 수 있는 새로운 방향을 제시합니다.

Abstract: Large language models (LLMs) have recently demonstrated impressive multimodal
reasoning capabilities, yet their understanding of purely numerical time-series
signals remains limited. Existing approaches mainly focus on forecasting or
trend description, without uncovering the latent events that drive numerical
changes or explaining the reasoning process behind them. In this work, we
introduce the task of number-to-event reasoning and decoding, which aims to
infer interpretable structured events from numerical inputs, even when current
text is unavailable. To address the data scarcity and semantic alignment
challenges, we propose a reasoning-aware framework that integrates an
agent-guided event extractor (AGE), a marked multivariate Hawkes-based
synthetic generator (EveDTS), and a two-stage fine-tuning pipeline combining a
time-series encoder with a structured decoder. Our model explicitly reasons
over numerical changes, generates intermediate explanations, and outputs
structured event hypotheses. Experiments on multi-domain datasets show that our
method substantially outperforms strong LLM baselines in event-level precision
and recall. These results suggest a new direction for bridging quantitative
reasoning and semantic understanding, enabling LLMs to explain and predict
events directly from numerical dynamics.

</details>


### [12] [Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling](https://arxiv.org/abs/2510.23631)
*Yuxuan Tang,Yifan Feng*

Main category: cs.LG

TL;DR: 이 논문에서는 대형 언어 모델의 정렬을 위한 새로운 방법인 Ranked Choice Preference Optimization (RCPO)을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 쌍대 선호 최적화 방식은 사람의 피드백을 더욱 풍부하게 활용할 기회를 놓치고 있다.

Method: 표준 유틸리티 기반 및 순위 기반 선택 모델을 지원하는 RCPO라는 통합 프레임워크를 통해 최대 우도 추정 방법을 제안한다.

Result: Llama-3-8B-Instruct와 Gemma-2-9B-it을 통해 RCPO가 경쟁 기준선을 지속적으로 초과 성과를 달성함을 보여준다.

Conclusion: RCPO는 정렬 효율성을 높이기 위한 효과적인 방법을 제공하며, LLM 훈련에 선택 모델을 통합하기 위한 탄탄하고 확장 가능한 기초를 제공한다.

Abstract: Alignment of large language models (LLMs) has predominantly relied on
pairwise preference optimization, where annotators select the better of two
responses to a prompt. While simple, this approach overlooks the opportunity to
learn from richer forms of human feedback, such as multiwise comparisons and
top-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a
unified framework that bridges preference optimization with (ranked) choice
modeling via maximum likelihood estimation. The framework is flexible,
supporting both utility-based and rank-based choice models. It subsumes several
existing pairwise methods (e.g., DPO, SimPO), while providing principled
training objectives for richer feedback formats. We instantiate this framework
with two representative ranked choice models (Multinomial Logit and
Mallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across
AlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms
competitive baselines. RCPO shows how directly leveraging ranked preference
data, combined with the right choice models, yields more effective alignment.
It offers a versatile and extensible foundation for incorporating (ranked)
choice modeling into LLM training.

</details>


### [13] [Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation](https://arxiv.org/abs/2510.23636)
*Thaweerath Phisannupawong,Joshua Julian Damanik,Han-Lim Choi*

Main category: cs.LG

TL;DR: 이 논문은 항공 교통 관리를 위한 경량의 다중 모달 비행 지연 예측 모델을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 비행 지연 예측은 효율성을 강조하고 전체 네트워크 성능에 영향을 미치기 때문에 항공 교통 관리의 주요 초점이 되었습니다.

Method: 항공 교통 관제사의 관점에서 터미널 영역에 진입한 항공기의 지연을 모니터링하는 다중 모달 비행 지연 예측을 위한 경량 대형 언어 모델 기반 접근법을 제시합니다.

Result: 모델은 지연의 원인과 관련된 맥락 정보를 효과적으로 활용하여 지속적으로 1분 미만의 예측 오차를 달성합니다.

Conclusion: 언어 이해가 궤적 정보의 교차 모달 적응과 결합될 때 지연 예측을 향상시키며, 실제 운영을 위한 실용성과 확장성을 보여줍니다.

Abstract: Flight delay prediction has become a key focus in air traffic management, as
delays highlight inefficiencies that impact overall network performance. This
paper presents a lightweight large language model-based multimodal flight delay
prediction, formulated from the perspective of air traffic controllers
monitoring aircraft delay after entering the terminal area. The approach
integrates trajectory representations with textual aeronautical information,
including flight information, weather reports, and aerodrome notices, by
adapting trajectory data into the language modality to capture airspace
conditions. Experimental results show that the model consistently achieves
sub-minute prediction error by effectively leveraging contextual information
related to the sources of delay. The framework demonstrates that linguistic
understanding, when combined with cross-modality adaptation of trajectory
information, enhances delay prediction. Moreover, the approach shows
practicality and scalability for real-world operations, supporting real-time
updates that refine predictions upon receiving new operational information.

</details>


### [14] [Integrating Genomics into Multimodal EHR Foundation Models](https://arxiv.org/abs/2510.23639)
*Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T. J. Chen,Cory Y. McLean*

Main category: cs.LG

TL;DR: 이 논문은 Polygenic Risk Scores (PRS)를 통합한 혁신적인 전자 건강 기록(EHR) 기초 모델을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 EHR 접근 방식을 넘어 보다 포괄적인 건강 프로필을 구축하기 위해.

Method: All of Us 연구 프로그램의 다양하고 방대한 데이터를 활용하여 임상 데이터와 유전적 소인의 복합적인 관계를 학습하는 다중 모달 프레임워크를 개발했습니다.

Result: 모델은 유형 2 당뇨병(T2D) 발병 예측에서의 유용성을 검증하였으며, PRS와 EHR 데이터 간의 상호작용을 보여주었습니다.

Conclusion: 이 접근법은 질병 예측, 선제적 건강 관리, 위험 계층화 및 개인별 치료 전략에 대한 새로운 통찰력을 여는 데 중요합니다.

Abstract: This paper introduces an innovative Electronic Health Record (EHR) foundation
model that integrates Polygenic Risk Scores (PRS) as a foundational data
modality, moving beyond traditional EHR-only approaches to build more holistic
health profiles. Leveraging the extensive and diverse data from the All of Us
(AoU) Research Program, this multimodal framework aims to learn complex
relationships between clinical data and genetic predispositions. The
methodology extends advancements in generative AI to the EHR foundation model
space, enhancing predictive capabilities and interpretability. Evaluation on
AoU data demonstrates the model's predictive value for the onset of various
conditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay
between PRS and EHR data. The work also explores transfer learning for custom
classification tasks, showcasing the architecture's versatility and efficiency.
This approach is pivotal for unlocking new insights into disease prediction,
proactive health management, risk stratification, and personalized treatment
strategies, laying the groundwork for more personalized, equitable, and
actionable real-world evidence generation in healthcare.

</details>


### [15] [Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm](https://arxiv.org/abs/2510.23660)
*Gazi Tanbhir,Md. Farhan Shahriyar,Abdullah Md Raihan Chy*

Main category: cs.LG

TL;DR: 이 논문은 양자 컴퓨팅을 활용한 폐렴 진단을 위한 Quanvolutional Neural Networks(QNNs)의 적용을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 폐렴은 전 세계적으로 중요한 건강 문제이며, 정확하고 적시의 진단이 필요하다. 전통적인 CNN은 높은 계산 비용과 작은 데이터셋에서의 일반화 문제를 겪고 있다.

Method: 본 논문은 PneumoniaMNIST 데이터셋을 사용하여 폐렴 진단을 위한 새로운 하이브리드 양자-고전적 모델을 소개하고, quanvolutional layer와 파라미터화된 양자회로(PQC)를 활용하여 2x2 이미지 패치를 처리한다.

Result: 제안된 QNN은 83.33%의 높은 검증 정확도를 달성하였으며, 이는 비교 가능한 전통적 CNN의 73.33%와 비교된다.

Conclusion: 이 연구는 양자 컴퓨팅을 딥러닝 기반 의료 진단 시스템에 통합하는 기초를 마련하며, 전통적인 접근 방식에 비해 계산적으로 효율적인 대안을 제공한다.

Abstract: Pneumonia poses a significant global health challenge, demanding accurate and
timely diagnosis. While deep learning, particularly Convolutional Neural
Networks (CNNs), has shown promise in medical image analysis for pneumonia
detection, CNNs often suffer from high computational costs, limitations in
feature representation, and challenges in generalizing from smaller datasets.
To address these limitations, we explore the application of Quanvolutional
Neural Networks (QNNs), leveraging quantum computing for enhanced feature
extraction. This paper introduces a novel hybrid quantum-classical model for
pneumonia detection using the PneumoniaMNIST dataset. Our approach utilizes a
quanvolutional layer with a parameterized quantum circuit (PQC) to process 2x2
image patches, employing rotational Y-gates for data encoding and entangling
layers to generate non-classical feature representations. These
quantum-extracted features are then fed into a classical neural network for
classification. Experimental results demonstrate that the proposed QNN achieves
a higher validation accuracy of 83.33 percent compared to a comparable
classical CNN which achieves 73.33 percent. This enhanced convergence and
sample efficiency highlight the potential of QNNs for medical image analysis,
particularly in scenarios with limited labeled data. This research lays the
foundation for integrating quantum computing into deep-learning-driven medical
diagnostic systems, offering a computationally efficient alternative to
traditional approaches.

</details>


### [16] [Transformers from Compressed Representations](https://arxiv.org/abs/2510.23665)
*Juan C. Leon Alcazar,Mattia Soldan,Mohammad Saatialsoruji,Alejandro Pardo,Hani Itani,Juan Camilo Perez,Bernard Ghanem*

Main category: cs.LG

TL;DR: TEMPEST는 압축 파일 형식을 활용하여 효과적인 토큰화 및 인코딩 전략을 설계하는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 압축 파일 형식은 효율적인 데이터 저장과 전송의 기본 요소지만, 표현 학습에서의 잠재력은 충분히 연구되지 않았다.

Method: TEMPEST는 압축 파일의 고유한 바이트 스트림 구조를 활용하여 효과적인 토큰화 및 인코딩 전략을 설계한다.

Result: TEMPEST는 최신 기술과 경쟁할 만한 정확도를 달성하면서 메모리와 계산의 효율성 향상을 제공한다.

Conclusion: 이 방법은 의미 분류에 필요한 토큰 수를 크게 줄이고, 계산 복잡성과 메모리 사용을 낮춘다.

Abstract: Compressed file formats are the corner stone of efficient data storage and
transmission, yet their potential for representation learning remains largely
underexplored. We introduce TEMPEST (TransformErs froM comPressed
rEpreSenTations), a method that exploits the inherent byte-stream structure of
compressed files to design an effective tokenization and encoding strategy. By
leveraging this compact encoding, a standard transformer can directly learn
semantic representations from compressed data streams, bypassing the need for
raw byte-level processing or full media decoding. Our proposal substantially
reduces the number of tokens required for semantic classification, thereby
lowering both computational complexity and memory usage. Through extensive
experiments across diverse datasets, coding schemes, and modalities, we show
that TEMPEST achieves accuracy competitive wit the state-of-the-art while
delivering efficiency gains in memory and compute.

</details>


### [17] [Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust Multi-Objective AI Agents](https://arxiv.org/abs/2510.23682)
*Gokturk Aytug Akarlar*

Main category: cs.LG

TL;DR: Chimera라는 신경-상징-인과적 아키텍처를 통해 LLM 모델의 성능을 개선하고, 독립적인 결정-making 에이전트로서의 신뢰성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)이 독립적인 의사결정 에이전트로서 유망하지만, 위험이 따르므로 구조적 안전장치가 필요하다.

Method: Chimera는 LLM 전략가, 공식적으로 검증된 상징적 제약 엔진, 반사실적 추론을 위한 인과 추론 모듈의 세 가지 구성 요소를 통합하여 설계되었다.

Result: Chimera는 LLM 전용 및 상징적 제약이 있는 LLM 아키텍처와 비교했을 때 가장 높은 수익을 제공하며, 브랜드 신뢰도를 향상시킨다.

Conclusion: 아키텍처 설계가 독립적인 에이전트의 신뢰성을 결정하며, 재현성을 위해 오픈 소스 구현 및 대화형 데모를 제공한다.

Abstract: Large language models show promise as autonomous decision-making agents, yet
their deployment in high-stakes domains remains fraught with risk. Without
architectural safeguards, LLM agents exhibit catastrophic brittleness:
identical capabilities produce wildly different outcomes depending solely on
prompt framing. We present Chimera, a neuro-symbolic-causal architecture that
integrates three complementary components - an LLM strategist, a formally
verified symbolic constraint engine, and a causal inference module for
counterfactual reasoning. We benchmark Chimera against baseline architectures
(LLM-only, LLM with symbolic constraints) across 52-week simulations in a
realistic e-commerce environment featuring price elasticity, trust dynamics,
and seasonal demand. Under organizational biases toward either volume or margin
optimization, LLM-only agents fail catastrophically (total loss of \$99K in
volume scenarios) or destroy brand trust (-48.6% in margin scenarios). Adding
symbolic constraints prevents disasters but achieves only 43-87% of Chimera's
profit. Chimera consistently delivers the highest returns (\$1.52M and \$1.96M
respectively, some cases +\$2.2M) while improving brand trust (+1.8% and
+10.8%, some cases +20.86%), demonstrating prompt-agnostic robustness. Our TLA+
formal verification proves zero constraint violations across all scenarios.
These results establish that architectural design not prompt engineering
determines the reliability of autonomous agents in production environments. We
provide open-source implementations and interactive demonstrations for
reproducibility.

</details>


### [18] [Debiasing Reward Models by Representation Learning with Guarantees](https://arxiv.org/abs/2510.23751)
*Ignavier Ng,Patrick Blöbaum,Siddharth Bhandari,Kun Zhang,Shiva Kasiviswanathan*

Main category: cs.LG

TL;DR: 이 연구는 보상 모델의 편향을 완화하면서 의도된 선호도를 반영하는 요소를 유지하는 원칙적인 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 인간의 선호에 맞추기 위한 최근의 정렬 기법들이 소음의 상관관계를 활용하는 문제에 주목하여, 이러한 문제를 해결하기 위한 접근법을 필요로 합니다.

Method: 데이터 생성 과정을 포뮬레이션하고, 가짜 잠재 변수와 비가짜 잠재 변수에서 생성된 관측 데이터가 있다는 가정을 통해, 변분 추론을 사용하여 이 변수를 복원하는 방법을 제안합니다.

Result: 합성 및 실제 데이터셋에 대한 실험에서 본 방법이 소음의 상관관계 문제를 효과적으로 완화하고 더 강력한 보상 모델을 생성함을 보여줍니다.

Conclusion: 우리는 제안한 프레임워크가 보상 모델의 편향 문제를 해결하는 데 기여할 수 있다고 결론지을 수 있습니다.

Abstract: Recent alignment techniques, such as reinforcement learning from human
feedback, have been widely adopted to align large language models with human
preferences by learning and leveraging reward models. In practice, these models
often exploit spurious correlations, involving, e.g., response length,
discrimination, sycophancy, and conceptual bias, which is a problem that has
received increasing attention. In this work, we propose a principled framework
that mitigates these biases in reward models while preserving the underlying
factors that reflect intended preferences. We first provide a formulation of
the data-generating process, assuming that the observed data (e.g., text) is
generated from both spurious and non-spurious latent variables. We show that,
interestingly, these non-spurious latent variables can be theoretically
identified from data, regardless of whether a surrogate for the spurious latent
variables is available. This further inspires a practical method that uses
variational inference to recover these variables and leverages them to train
reward models. Experiments on synthetic and real-world datasets demonstrate
that our method effectively mitigates spurious correlation issues and yields
more robust reward models.

</details>


### [19] [RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees](https://arxiv.org/abs/2510.23901)
*Cristobal Heredia,Pedro Chumpitaz-Flores,Kaixun Hua*

Main category: cs.LG

TL;DR: RS-ORT는 최상의 회귀 트리를 학습하기 위한 새로운 MIP 접근 방식으로, 두 단계 최적화 문제로 구성되어 있으며, 효율적인 트리 구조를 보장한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 MIP 접근 방식은 이진 데이터에만 국한되거나 연속적인 대규모 데이터에서 계산적으로 복잡해지기 때문에, 지속적인 데이터 처리의 필요성을 해결하는 것이 중요하다.

Method: 최적 회귀 트리 학습을 두 단계 최적화 문제로 재구성하고, 전용 가지치기 알고리즘인 RS-ORT를 사용하여 트리 구조 변수에만 집중적으로 분기하며, 여러 경계 강화 기법을 도입한다.

Result: RS-ORT는 여러 회귀 기준선에서 우수한 학습 및 테스트 성능을 보이며, 심지어 2,000,000 샘플의 연속 데이터에서도 간단한 트리 구조로 보장된 학습 성능을 달성한다.

Conclusion: RS-ORT는 밀리언 사이즈 데이터셋에서도 계산적 비효율성을 완화하고, 네 시간 만에 더 나은 일반화 능력을 제공한다.

Abstract: Mixed-integer programming (MIP) has emerged as a powerful framework for
learning optimal decision trees. Yet, existing MIP approaches for regression
tasks are either limited to purely binary features or become computationally
intractable when continuous, large-scale data are involved. Naively binarizing
continuous features sacrifices global optimality and often yields needlessly
deep trees. We recast the optimal regression-tree training as a two-stage
optimization problem and propose Reduced-Space Optimal Regression Trees
(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches
exclusively on tree-structural variables. This design guarantees the
algorithm's convergence and its independence from the number of training
samples. Leveraging the model's structure, we introduce several bound
tightening techniques - closed-form leaf prediction, empirical threshold
discretization, and exact depth-1 subtree parsing - that combine with
decomposable upper and lower bounding strategies to accelerate the training.
The BB node-wise decomposition enables trivial parallel execution, further
alleviating the computational intractability even for million-size datasets.
Based on the empirical studies on several regression benchmarks containing both
binary and continuous features, RS-ORT also delivers superior training and
testing performance than state-of-the-art methods. Notably, on datasets with up
to 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed
training performance with a simpler tree structure and a better generalization
ability in four hours.

</details>


### [20] [Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling](https://arxiv.org/abs/2510.23977)
*Yohan Abeysinghe,Muhammad Akhtar Munir,Sanoojan Baliah,Ron Sarafian,Fahad Shahbaz Khan,Yinon Rudich,Salman Khan*

Main category: cs.LG

TL;DR: 이 논문에서는 고해상도 신경 예측 모델인 SynCast를 제안하여 대기 오염 예측의 정확성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 대기 오염은 공공 건강과 환경에 큰 위험이 되며, 이를 정확히 예측하는 것이 필요하다.

Method: SynCast는 기상 및 공기 조성 데이터를 통합하여 평균 및 극단적인 오염 수준 예측을 개선하는 모델이다.

Result: 모델은 PM$_1$, PM$_{2.5}$, PM$_{10}$ 등의 다양한 PM 변수를 예측하는 데 있어 상당한 개선을 보여준다.

Conclusion: 이 접근법은 차세대 공기질 조기 경고 시스템을 위한 확장 가능한 기반을 제공하며, 취약한 지역에서 기후-건강 위험 완화를 지원한다.

Abstract: Air pollution remains a leading global health and environmental risk,
particularly in regions vulnerable to episodic air pollution spikes due to
wildfires, urban haze and dust storms. Accurate forecasting of particulate
matter (PM) concentrations is essential to enable timely public health warnings
and interventions, yet existing models often underestimate rare but hazardous
pollution events. Here, we present SynCast, a high-resolution neural
forecasting model that integrates meteorological and air composition data to
improve predictions of both average and extreme pollution levels. Built on a
regionally adapted transformer backbone and enhanced with a diffusion-based
stochastic refinement module, SynCast captures the nonlinear dynamics driving
PM spikes more accurately than existing approaches. Leveraging on harmonized
ERA5 and CAMS datasets, our model shows substantial gains in forecasting
fidelity across multiple PM variables (PM$_1$, PM$_{2.5}$, PM$_{10}$),
especially under extreme conditions. We demonstrate that conventional loss
functions underrepresent distributional tails (rare pollution events) and show
that SynCast, guided by domain-aware objectives and extreme value theory,
significantly enhances performance in highly impacted regions without
compromising global accuracy. This approach provides a scalable foundation for
next-generation air quality early warning systems and supports climate-health
risk mitigation in vulnerable regions.

</details>


### [21] [NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis](https://arxiv.org/abs/2510.24025)
*Tianqi Guo,Liping Chen,Ciyuan Peng,Jingjing Zhou,Jing Ren*

Main category: cs.LG

TL;DR: 이 논문은 뇌 기능 네트워크의 시간에 따른 진화를 이해하고, 이를 통해 인지 메커니즘 분석과 신경 질환 진단에 기여하는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 뇌 기능 네트워크의 진화를 이해하는 것은 인지 메커니즘 분석과 신경 질환 진단에 매우 중요하다.

Method: NeuroPathNet이라는 새로운 경로 수준의 궤적 모델링 프레임워크를 제안하여, 뇌 기능 분할 간의 연결 경로의 동적 행동을 특징화한다.

Result: 세 개의 공용 기능적 자기 공명 영상(fMRI) 데이터셋에서 모델 성능을 검증했으며, 여러 지표에서 기존의 주류 방법을 능가하는 결과를 보였다.

Conclusion: 이 연구는 뇌 네트워크 분석을 위한 동적 그래프 학습 방법의 발전을 촉진하고, 신경 질환 진단을 위한 임상 응용 가능성을 제공할 수 있다.

Abstract: Understanding the evolution of brain functional networks over time is of
great significance for the analysis of cognitive mechanisms and the diagnosis
of neurological diseases. Existing methods often have difficulty in capturing
the temporal evolution characteristics of connections between specific
functional communities. To this end, this paper proposes a new path-level
trajectory modeling framework (NeuroPathNet) to characterize the dynamic
behavior of connection pathways between brain functional partitions. Based on
medically supported static partitioning schemes (such as Yeo and Smith ICA), we
extract the time series of connection strengths between each pair of functional
partitions and model them using a temporal neural network. We validate the
model performance on three public functional Magnetic Resonance Imaging (fMRI)
datasets, and the results show that it outperforms existing mainstream methods
in multiple indicators. This study can promote the development of dynamic graph
learning methods for brain network analysis, and provide possible clinical
applications for the diagnosis of neurological diseases.

</details>


### [22] [Causal Convolutional Neural Networks as Finite Impulse Response Filters](https://arxiv.org/abs/2510.24125)
*Kiran Bacsa,Wei Liu,Xudong Jian,Huangbin Liang,Eleni Chatzi*

Main category: cs.LG

TL;DR: 본 연구는 다채로운 주파수 내용을 가진 시계열 데이터에 적용된 인과적 컨볼루션 신경망의 행동을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 주파수 내용을 가진 시계열 데이터의 분석 및 해석 가능성을 높이기 위해.

Method: 인과적 컨볼루션 신경망을 훈련시키고, 이를 FIR 필터와 유사하게 동작함을 보여줌.

Result: 훈련된 네트워크는 스펙트럼 특징을 묘사하고, 전체 네트워크를 단일 층 필터로 축소할 수 있음을 밝혔다.

Conclusion: 이 접근법은 동적 반응으로 지배되는 물리적 시스템의 모델링 및 식별에 유용함을 입증하였다.

Abstract: This study investigates the behavior of Causal Convolutional Neural Networks
(CNNs) with quasi-linear activation functions when applied to time-series data
characterized by multimodal frequency content. We demonstrate that, once
trained, such networks exhibit properties analogous to Finite Impulse Response
(FIR) filters, particularly when the convolutional kernels are of extended
length exceeding those typically employed in standard CNN architectures. Causal
CNNs are shown to capture spectral features both implicitly and explicitly,
offering enhanced interpretability for tasks involving dynamic systems.
Leveraging the associative property of convolution, we further show that the
entire network can be reduced to an equivalent single-layer filter resembling
an FIR filter optimized via least-squares criteria. This equivalence yields new
insights into the spectral learning behavior of CNNs trained on signals with
sparse frequency content. The approach is validated on both simulated beam
dynamics and real-world bridge vibration datasets, underlining its relevance
for modeling and identifying physical systems governed by dynamic responses.

</details>


### [23] [Temporal Knowledge Graph Hyperedge Forecasting: Exploring Entity-to-Category Link Prediction](https://arxiv.org/abs/2510.24240)
*Edward Markai,Sina Molavipour*

Main category: cs.LG

TL;DR: Temporal Knowledge Graphs는 정적 관계 모델링과 관계 진화를 동시에 다룰 수 있는 강력한 방법으로 떠올랐다. 최근 연구들은 주로 임베딩 기반 방법에 중점을 두고 있으며, 이 논문에서는 고정밀도와 설명 가능한 예측을 제공하는 TLogic이라는 규칙 기반 프레임워크의 확장을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: Temporal Knowledge Graphs의 발전에 따라, 관계 진화를 모델링하고 실세계 이벤트 예측의 중요성이 커지고 있다.

Method: 기존의 TLogic 프레임워크를 확장하여 새로운 규칙 형식을 도입하고, 카테고리를 고려한 데이터 중심 방법을 제안한다.

Result: 높은 정확도와 함께 설명 가능한 예측을 제공하며, 그래프 구축 시 카테고리가 알려지지 않은 경우 LLM 기반 접근 방식을 통해 카테고리를 생성할 수 있다.

Conclusion: 본 연구는 예측 단계에서 적용된 규칙을 비판적으로 평가할 수 있는 투명성을 제공한다.

Abstract: Temporal Knowledge Graphs have emerged as a powerful way of not only modeling
static relationships between entities but also the dynamics of how relations
evolve over time. As these informational structures can be used to store
information from a real-world setting, such as a news flow, predicting future
graph components to a certain extent equates predicting real-world events. Most
of the research in this field focuses on embedding-based methods, often
leveraging convolutional neural net architectures. These solutions act as black
boxes, limiting insight. In this paper, we explore an extension to an
established rule-based framework, TLogic, that yields a high accuracy in
combination with explainable predictions. This offers transparency and allows
the end-user to critically evaluate the rules applied at the end of the
prediction stage. The new rule format incorporates entity category as a key
component with the purpose of limiting rule application only to relevant
entities. When categories are unknown for building the graph, we propose a
data-driven method to generate them with an LLM-based approach. Additionally,
we investigate the choice of aggregation method for scores of retrieved
entities when performing category prediction.

</details>


### [24] [Perception Learning: A Formal Separation of Sensory Representation Learning from Decision Learning](https://arxiv.org/abs/2510.24356)
*Suman Sanyal*

Main category: cs.LG

TL;DR: PeL(Perception Learning)는 작업 무관 신호를 사용하여 에이전트의 감각 인터페이스를 최적화하는 새로운 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: Perl은 다운스트림 의사 결정 학습과 분리된 에이전트 감각 인터페이스의 최적화를 목표로 한다.

Method: 이 논문에서는 목표나 재매개변수화와 독립적인 지각적 속성을 정의하고, PeL 업데이트가 충분한 불변성을 유지하면서 베이즈 작업 위험 기울기에 수직임을 증명한다.

Result: PeL은 의사 결정과 지각을 분리하고, 감각 복잡성과 무관한 속성들을 평가하기 위한 객관적인 메트릭을 제공한다.

Conclusion: 우리는 PeL을 통해 감각적 품질 평가를 위한 작업 무관 평가 메트릭의 모음도 제공한다.

Abstract: We introduce Perception Learning (PeL), a paradigm that optimizes an agent's
sensory interface $f_\phi:\mathcal{X}\to\mathcal{Z}$ using task-agnostic
signals, decoupled from downstream decision learning
$g_\theta:\mathcal{Z}\to\mathcal{Y}$. PeL directly targets label-free
perceptual properties, such as stability to nuisances, informativeness without
collapse, and controlled geometry, assessed via objective
representation-invariant metrics. We formalize the separation of perception and
decision, define perceptual properties independent of objectives or
reparameterizations, and prove that PeL updates preserving sufficient
invariants are orthogonal to Bayes task-risk gradients. Additionally, we
provide a suite of task-agnostic evaluation metrics to certify perceptual
quality.

</details>


### [25] [Filtering instances and rejecting predictions to obtain reliable models in healthcare](https://arxiv.org/abs/2510.24368)
*Maria Gabriela Valeriano,David Kohan Marzagão,Alfredo Montelongo,Carlos Roberto Veiga Kiffer,Natan Katz,Ana Carolina Lorena*

Main category: cs.LG

TL;DR: 본 논문은 데이터 품질을 개선하고 저신뢰 예측을 필터링하여 기계 학습 모델의 신뢰성을 높이는 새로운 데이터 중심 접근법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 모델의 예측 신뢰성이 중요한 고위험 분야에서 모델이 불확실성을 고려하지 못하는 문제를 해결하고자 한다.

Method: 본 논문은 Instance Hardness(IH)를 활용하여 훈련 과정에서 문제 있는 인스턴스를 필터링하고, 추론 과정에서는 신뢰 기반 거부 메커니즘을 도입하는 두 단계의 접근법을 제안한다.

Result: 세 가지 실제 의료 데이터 세트를 사용하여 제안한 접근법의 효과성을 평가하며, 모델의 신뢰성을 높이고 예측 성능과 거부율을 균형 있게 유지하는 데 성공함을 보여준다.

Conclusion: IH 필터링과 신뢰 기반 거부를 통합함으로써 모델 성능이 향상되고 많은 비율의 인스턴스가 보존된다는 것을 증명하였다.

Abstract: Machine Learning (ML) models are widely used in high-stakes domains such as
healthcare, where the reliability of predictions is critical. However, these
models often fail to account for uncertainty, providing predictions even with
low confidence. This work proposes a novel two-step data-centric approach to
enhance the performance of ML models by improving data quality and filtering
low-confidence predictions. The first step involves leveraging Instance
Hardness (IH) to filter problematic instances during training, thereby refining
the dataset. The second step introduces a confidence-based rejection mechanism
during inference, ensuring that only reliable predictions are retained. We
evaluate our approach using three real-world healthcare datasets, demonstrating
its effectiveness at improving model reliability while balancing predictive
performance and rejection rate. Additionally, we use alternative criteria -
influence values for filtering and uncertainty for rejection - as baselines to
evaluate the efficiency of the proposed method. The results demonstrate that
integrating IH filtering with confidence-based rejection effectively enhances
model performance while preserving a large proportion of instances. This
approach provides a practical method for deploying ML systems in
safety-critical applications.

</details>


### [26] [Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings](https://arxiv.org/abs/2510.24432)
*Seyed Mahdi Basiri Azad,Joschka Boedecker*

Main category: cs.LG

TL;DR: 희소 보상 환경에서 강화 학습의 효율성을 높이기 위한 새로운 접근법을 제안.


<details>
  <summary>Details</summary>
Motivation: 희소 보상 환경에서 강화 학습은 정보가 부족한 피드백으로 인해 어렵습니다.

Method: 소수의 성공적인 시연을 사용하여 강화 학습 에이전트의 가치 함수를 초기화하는 방법을 제안합니다.

Result: 오프라인 시연에서 가치 추정치를 미리 계산하고 이를 초기 학습의 목표로 사용하여 에이전트가 유망한 행동에 대한 유용한 사전 정보를 갖도록 합니다.

Conclusion: 이 하이브리드 오프라인에서 온라인으로의 패러다임은 탐색 부담을 크게 줄이고 희소 보상 환경에서 샘플 효율성을 향상시킵니다. 실험 결과, 우리의 방법은 수렴 속도를 증가시키고 표준 기준보다 우수한 성능을 보입니다.

Abstract: Reinforcement learning (RL) in sparse-reward environments remains a
significant challenge due to the lack of informative feedback. We propose a
simple yet effective method that uses a small number of successful
demonstrations to initialize the value function of an RL agent. By precomputing
value estimates from offline demonstrations and using them as targets for early
learning, our approach provides the agent with a useful prior over promising
actions. The agent then refines these estimates through standard online
interaction. This hybrid offline-to-online paradigm significantly reduces the
exploration burden and improves sample efficiency in sparse-reward settings.
Experiments on benchmark tasks demonstrate that our method accelerates
convergence and outperforms standard baselines, even with minimal or suboptimal
demonstration data.

</details>


### [27] [Causal Ordering for Structure Learning From Time Series](https://arxiv.org/abs/2510.24639)
*Pedro P. Sanchez,Damian Machlanski,Steven McDonagh,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: 이 연구에서는 시간 시계열 데이터에서 인과 구조를 예측하는 DOTS라는 새로운 방법을 제안하며, 이 방법은 여러 유효 인과 순서를 활용하여 단일 순서의 한계를 극복하고, 시계열 인과 발견을 위한 강력하고 확장 가능한 접근법을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 시간 시계열 데이터에서 인과 구조를 예측하는 것은 생리학, 뇌 연결성, 기후 역학 및 사회 경제적 행동의 복잡한 현상을 이해하는 데 중요하다.

Method: 이 연구는 다수의 유효한 인과 순서를 활용하여 전통적인 순서 기반 방법의 제한된 표현 능력을 해결하는 DOTS (Diffusion Ordered Temporal Structure)라는 방법을 제안한다. 이 방법은 확산 기반 인과 발견을 사용하여 시간 데이터를 처리한다.

Result: DOTS는 기본적으로 지시 비순환 그래프의 전이 폐쇄를 효과적으로 복구하여 단일 순서 접근 방식에서 발생하는 잘못된 아티팩트를 완화한다. 실험 결과 DOTS가 최신 기준을 초과하여 시계열 인과 발견을 위한 스케일 가능하고 강력한 접근법임을 입증했다.

Conclusion: DOTS는 시뮬레이션 벤치마크와 실제 데이터셋에서 우수한 성능을 보이며, 이는 시계열 인과 발견을 위한 정확하고 확장 가능한 솔루션으로 자리매김한다.

Abstract: Predicting causal structure from time series data is crucial for
understanding complex phenomena in physiology, brain connectivity, climate
dynamics, and socio-economic behaviour. Causal discovery in time series is
hindered by the combinatorial complexity of identifying true causal
relationships, especially as the number of variables and time points grow. A
common approach to simplify the task is the so-called ordering-based methods.
Traditional ordering methods inherently limit the representational capacity of
the resulting model. In this work, we fix this issue by leveraging multiple
valid causal orderings, instead of a single one as standard practice. We
propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based
causal discovery for temporal data. By integrating multiple orderings, DOTS
effectively recovers the transitive closure of the underlying directed acyclic
graph, mitigating spurious artifacts inherent in single-ordering approaches. We
formalise the problem under standard assumptions such as stationarity and the
additive noise model, and leverage score matching with diffusion processes to
enable efficient Hessian estimation. Extensive experiments validate the
approach. Empirical evaluations on synthetic and real-world datasets
demonstrate that DOTS outperforms state-of-the-art baselines, offering a
scalable and robust approach to temporal causal discovery. On synthetic
benchmarks ($d{=}\!3-\!6$ variables, $T{=}200\!-\!5{,}000$ samples), DOTS
improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the
CausalTime real-world benchmark ($d{=}20\!-\!36$), while baselines remain the
best on individual datasets, DOTS attains the highest average summary-graph
$F1$ while halving runtime relative to graph-optimisation methods. These
results establish DOTS as a scalable and accurate solution for temporal causal
discovery.

</details>


### [28] [Preference Learning with Response Time: Robust Losses and Guarantees](https://arxiv.org/abs/2505.22820)
*Ayush Sawarni,Sahasrajit Sarmasarkar,Vasilis Syrgkanis*

Main category: cs.LG

TL;DR: 이 논문은 효과적인 보상 모델 도출을 위한 인간 선호 학습 프레임워크에 응답 시간 데이터를 통합하는 방법을 조사한다.


<details>
  <summary>Details</summary>
Motivation: 이 논문은 사용자 의사 결정 과정에서의 귀중한 시간 정보가 충분히 활용되지 않고 있음을 보여준다.

Method: 응답 시간 정보를 이진 선택 데이터와 함께 통합하기 위한 새로운 방법론을 제안하고, 응답 시간이 선호 강도에 대한 정보를 제공하는 Evidence Accumulation Drift Diffusion (EZ) 모델을 활용한다.

Result: Neyman-orthogonal 손실 함수를 개발하여 보상 모델 학습을 위한 오라클 수렴 속도를 달성하고, 이는 각 쿼리에 대한 예상 응답 시간이 사전에 알려진 경우에 달성할 수 있는 이론적 최적 속도에 부합한다.

Conclusion: 응답 시간 증대 접근법은 보상 크기와 함께 오류 비율이 지수적으로 증가하는 기존 선호 학습에 비해 다항식 스케일로 줄어드는 것을 보여준다.

Abstract: This paper investigates the integration of response time data into human
preference learning frameworks for more effective reward model elicitation.
While binary preference data has become fundamental in fine-tuning foundation
models, generative AI systems, and other large-scale models, the valuable
temporal information inherent in user decision-making remains largely
unexploited. We propose novel methodologies to incorporate response time
information alongside binary choice data, leveraging the Evidence Accumulation
Drift Diffusion (EZ) model, under which response time is informative of the
preference strength. We develop Neyman-orthogonal loss functions that achieve
oracle convergence rates for reward model learning, matching the theoretical
optimal rates that would be attained if the expected response times for each
query were known a priori. Our theoretical analysis demonstrates that for
linear reward functions, conventional preference learning suffers from error
rates that scale exponentially with reward magnitude. In contrast, our response
time-augmented approach reduces this to polynomial scaling, representing a
significant improvement in sample efficiency. We extend these guarantees to
non-parametric reward function spaces, establishing convergence properties for
more complex, realistic reward models. Our extensive experiments validate our
theoretical findings in the context of preference learning over images.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents](https://arxiv.org/abs/2510.24383)
*Juraj Mavračić*

Main category: cs.AI

TL;DR: 정책 카드(Policy Card)는 AI 에이전트를 위한 운용, 규제 및 윤리적 제약을 표현하는 기계 가독형 표준으로 제안된다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 투명성과 규정 준수를 보장하기 위한 새로운 접근법이 필요하다.

Method: 정책 카드는 AI 에이전트와 함께 배치되어 런타임에서 필수 제약을 준수하도록 한다.

Result: 정책 카드는 NIST AI RMF, ISO/IEC 42001, EU AI Act와 같은 보증 프레임워크와의 매핑을 정의한다.

Conclusion: 정책 카드는 높은 수준의 거버넌스와 실제 엔지니어링 관행을 통합하는 실용적인 기제를 제공한다.

Abstract: Policy Cards are introduced as a machine-readable, deployment-layer standard
for expressing operational, regulatory, and ethical constraints for AI agents.
The Policy Card sits with the agent and enables it to follow required
constraints at runtime. It tells the agent what it must and must not do. As
such, it becomes an integral part of the deployed agent. Policy Cards extend
existing transparency artifacts such as Model, Data, and System Cards by
defining a normative layer that encodes allow/deny rules, obligations,
evidentiary requirements, and crosswalk mappings to assurance frameworks
including NIST AI RMF, ISO/IEC 42001, and the EU AI Act. Each Policy Card can
be validated automatically, version-controlled, and linked to runtime
enforcement or continuous-audit pipelines. The framework enables verifiable
compliance for autonomous agents, forming a foundation for distributed
assurance in multi-agent ecosystems. Policy Cards provide a practical mechanism
for integrating high-level governance with hands-on engineering practice and
enabling accountable autonomy at scale.

</details>


### [30] [Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents](https://arxiv.org/abs/2510.23691)
*Zihao Wang,Xujing Li,Yining Ye,Junjie Fang,Haoming Wang,Longxiang Liu,Shihao Liang,Junting Lu,Zhiyong Wu,Jiazhan Feng,Wanjun Zhong,Zili Li,Yu Wang,Yu Miao,Bo Zhou,Yuanfan Li,Hao Wang,Zhongkai Zhao,Faming Wu,Zhengxuan Jiang,Weihao Tan,Heyuan Yao,Shi Yan,Xiangyang Li,Yitao Liang,Yujia Qin,Guang Shi*

Main category: cs.AI

TL;DR: Game-TARS는 인간 친화적인 키보드-마우스 입력에 기반하여 훈련된 일반 게임 에이전트로, 다양한 도메인에서 지속적인 훈련을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 기존 API 또는 GUI 기반 접근 방식의 한계를 극복하고 다양한 게임 도메인에서 일반화된 에이전트를 개발하기 위해.

Method: 통합된 행동 공간을 사용하여 500억 개 이상의 토큰으로 사전 훈련을 진행하고, 원인 혼란을 줄이기 위해 점진적인 손실 감소와 효율적인 Sparse-Thinking 전략을 적용하였다.

Result: Game-TARS는 오픈 월드 Minecraft 작업에서 이전 최고 성능 모델 대비 약 2배의 성공률을 달성하고, 새로운 웹 3D 게임에서 인간의 일반성을 근접하게 달성하며, FPS 지표에서 GPT-5, Gemini-2.5-Pro, Claude-4-Sonnet을 초月했다.

Conclusion: 간단하고 확장 가능한 행동 표현과 대규모 사전 훈련의 조합으로 넓은 컴퓨터 사용 능력을 가진 일반 에이전트로의 가능성을 보여주었다.

Abstract: We present Game-TARS, a generalist game agent trained with a unified,
scalable action space anchored to human-aligned native keyboard-mouse inputs.
Unlike API- or GUI-based approaches, this paradigm enables large-scale
continual pre-training across heterogeneous domains, including OS, web, and
simulation games. Game-TARS is pre-trained on over 500B tokens with diverse
trajectories and multimodal data. Key techniques include a decaying continual
loss to reduce causal confusion and an efficient Sparse-Thinking strategy that
balances reasoning depth and inference cost. Experiments show that Game-TARS
achieves about 2 times the success rate over the previous sota model on
open-world Minecraft tasks, is close to the generality of fresh humans in
unseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet
in FPS benchmarks. Scaling results on training-time and test-time confirm that
the unified action space sustains improvements when scaled to cross-game and
multimodal data. Our results demonstrate that simple, scalable action
representations combined with large-scale pre-training provide a promising path
toward generalist agents with broad computer-use abilities.

</details>


### [31] [Law in Silico: Simulating Legal Society with LLM-Based Agents](https://arxiv.org/abs/2510.24442)
*Yiding Wang,Yuxuan Chen,Fanxu Meng,Xifan Chen,Xiaolei Yang,Muhan Zhang*

Main category: cs.AI

TL;DR: 이 논문에서는 인공지능 기반의 시뮬레이션을 통해 법률 체계를 모사하는 새로운 방법인 'Law in Silico'를 제안하고, LLM 기반의 에이전트가 실제 범죄 경향을 잘 재현함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 법률 실험은 종종 비용이 많이 들거나 실행 불가능하므로 법 이론을 검증하고 개발하는 효과적인 대안으로 인공지능 시스템을 활용한 법률 사회 시뮬레이션이 필요하다.

Method: 개별 의사결정 및 입법, 판결, 집행의 제도적 메커니즘을 포함하는 법률 시나리오를 시뮬레이션하기 위한 LLM 기반 에이전트 프레임워크인 'Law in Silico'를 소개한다.

Result: 실제 범죄 데이터와 비교한 실험 결과, LLM 기반의 에이전트가 매크로 수준의 범죄 경향을 재현할 수 있으며, 실제 관찰과 일치하는 통찰을 제공함을 보여준다.

Conclusion: 또한, 잘 작동하고 투명하며 적응 가능한 법률 시스템이 취약한 개인의 권리를 더 잘 보호함을 시뮬레이션을 통해 확인했다.

Abstract: Since real-world legal experiments are often costly or infeasible, simulating
legal societies with Artificial Intelligence (AI) systems provides an effective
alternative for verifying and developing legal theory, as well as supporting
legal administration. Large Language Models (LLMs), with their world knowledge
and role-playing capabilities, are strong candidates to serve as the foundation
for legal society simulation. However, the application of LLMs to simulate
legal systems remains underexplored. In this work, we introduce Law in Silico,
an LLM-based agent framework for simulating legal scenarios with individual
decision-making and institutional mechanisms of legislation, adjudication, and
enforcement. Our experiments, which compare simulated crime rates with
real-world data, demonstrate that LLM-based agents can largely reproduce
macro-level crime trends and provide insights that align with real-world
observations. At the same time, micro-level simulations reveal that a
well-functioning, transparent, and adaptive legal system offers better
protection of the rights of vulnerable individuals.

</details>


### [32] [Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra](https://arxiv.org/abs/2510.23746)
*Laura Mismetti,Marvin Alberts,Andreas Krause,Mara Graziani*

Main category: cs.AI

TL;DR: 본 연구는 테스트 타임 튜닝을 활용하여 대조 데이터베이스 없이도 분자의 구조를 생성하는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 다단계 파이프라인은 대부분의 경우 참고 데이터베이스에 없는 화합물의 검출을 어렵게 합니다.

Method: 테스트 타임 튜닝을 통해 사전 훈련된 트랜스포머 모델의 학습을 향상시키며, 이를 통해 엔드 투 엔드 새 분자 구조 생성을 실현합니다.

Result: 두 개의 벤치마크에서 DiffMS를 각각 100% 및 20% 초과하여 초월했습니다.

Conclusion: 모델은 새로운 스펙트럼에 동적으로 적응할 수 있으며, 생성된 분자 후보는 구조적으로 정확하여 인간 해석 및 신뢰할 수 있는 식별에 유용합니다.

Abstract: Tandem Mass Spectrometry enables the identification of unknown compounds in
crucial fields such as metabolomics, natural product discovery and
environmental analysis. However, current methods rely on database matching from
previously observed molecules, or on multi-step pipelines that require
intermediate fragment or fingerprint prediction. This makes finding the correct
molecule highly challenging, particularly for compounds absent from reference
databases. We introduce a framework that, by leveraging test-time tuning,
enhances the learning of a pre-trained transformer model to address this gap,
enabling end-to-end de novo molecular structure generation directly from the
tandem mass spectra and molecular formulae, bypassing manual annotations and
intermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on
two popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.
Test-time tuning on experimental spectra allows the model to dynamically adapt
to novel spectra, and the relative performance gain over conventional
fine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground
truth, the generated molecular candidates remain structurally accurate,
providing valuable guidance for human interpretation and more reliable
identification.

</details>


### [33] [Affordance Representation and Recognition for Autonomous Agents](https://arxiv.org/abs/2510.24459)
*Habtom Kahsay Gidey,Niklas Huber,Alexander Lenz,Alois Knoll*

Main category: cs.AI

TL;DR: 소프트웨어 에이전트의 자율성은 구조화된 데이터로부터 실행 가능한 내부 세계 모델을 구축하는 능력에 기반하며, 이를 위한 두 가지 주요 아키텍처 패턴을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 에이전트의 자율성을 높이기 위해서는 디지털 환경을 정의하는 구조화된 데이터로부터 실행 가능한 내부 세계 모델을 구축하는 것이 필수적이다.

Method: DOM Transduction Pattern과 Hypermedia Affordances Recognition Pattern 두 가지 보완적 아키텍처 패턴을 도입한다.

Result: 이 패턴들은 효과적으로 세계 모델을 구축 및 유지할 수 있는 에이전트를 설계하기 위한 강력한 프레임워크를 제공한다.

Conclusion: 제안된 패턴을 통해 에이전트는 웹과 그 확장 자원에서 확장 가능하고 적응 가능하며 상호 운용 가능한 자동화를 가능하게 한다.

Abstract: The autonomy of software agents is fundamentally dependent on their ability
to construct an actionable internal world model from the structured data that
defines their digital environment, such as the Document Object Model (DOM) of
web pages and the semantic descriptions of web services. However, constructing
this world model from raw structured data presents two critical challenges: the
verbosity of raw HTML makes it computationally intractable for direct use by
foundation models, while the static nature of hardcoded API integrations
prevents agents from adapting to evolving services.
  This paper introduces a pattern language for world modeling from structured
data, presenting two complementary architectural patterns. The DOM Transduction
Pattern addresses the challenge of web page complexity by distilling} a
verbose, raw DOM into a compact, task-relevant representation or world model
optimized for an agent's reasoning core. Concurrently, the Hypermedia
Affordances Recognition Pattern enables the agent to dynamically enrich its
world model by parsing standardized semantic descriptions to discover and
integrate the capabilities of unknown web services at runtime. Together, these
patterns provide a robust framework for engineering agents that can efficiently
construct and maintain an accurate world model, enabling scalable, adaptive,
and interoperable automation across the web and its extended resources.

</details>


### [34] [ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents](https://arxiv.org/abs/2510.23822)
*Zhenyu Zhang,Tianyi Chen,Weiran Xu,Alex Pentland,Jiaxin Pei*

Main category: cs.AI

TL;DR: ReCAP는 대형 언어 모델에서의 다단계 추론과 동적 재계획을 위한 계층적 프레임워크로, 고수준 목표와 저수준 행동을 정렬하고 중복 프롬프트를 줄이는 데 기여합니다.


<details>
  <summary>Details</summary>
Motivation: 다단계 추론과 동적 재계획이 필요한 장기 작업은 대형 언어 모델에서 여전히 도전 과제가 되고 있습니다.

Method: ReCAP는 세 가지 주요 메커니즘, 즉 계획 미리 분해하기, 부모 계획의 구조적 재주입, 메모리 효율적인 실행을 결합하여 작동합니다.

Result: ReCAP는 다양한 장기 추론 벤치마크에서 서브 목표 정렬과 성공률을 크게 향상시켰습니다.

Conclusion: 엄격한 pass@1 프로토콜에서 동기식 Robotouille에서 32%, 비동기식 Robotouille에서 29%의 성과 향상을 달성했습니다.

Abstract: Long-horizon tasks requiring multi-step reasoning and dynamic re-planning
remain challenging for large language models (LLMs). Sequential prompting
methods are prone to context drift, loss of goal information, and recurrent
failure cycles, while hierarchical prompting methods often weaken cross-level
continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive
Context-Aware Reasoning and Planning), a hierarchical framework with shared
context for reasoning and planning in LLMs. ReCAP combines three key
mechanisms: (i) plan-ahead decomposition, in which the model generates a full
subtask list, executes the first item, and refines the remainder; (ii)
structured re-injection of parent plans, maintaining consistent multi-level
context during recursive return; and (iii) memory-efficient execution, bounding
the active prompt so costs scale linearly with task depth. Together these
mechanisms align high-level goals with low-level actions, reduce redundant
prompting, and preserve coherent context updates across recursion. Experiments
demonstrate that ReCAP substantially improves subgoal alignment and success
rates on various long-horizon reasoning benchmarks, achieving a 32% gain on
synchronous Robotouille and a 29% improvement on asynchronous Robotouille under
the strict pass@1 protocol.

</details>


### [35] [Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models](https://arxiv.org/abs/2510.23824)
*Murad Ismayilov,Edwin Meriaux,Shuo Wen,Gregory Dudek*

Main category: cs.AI

TL;DR: 다수의 자율 에이전트를 분산 환경에서 조정하는 문제를 해결하기 위한 연구로, 유사한 목표에 대한 독립적인 선호도를 기반으로 한 다중 에이전트 경로 계획을 다룸.


<details>
  <summary>Details</summary>
Motivation: 분산 조건에서 공유 환경에서 다수의 자율 에이전트를 조정하는 것은 로봇공학 및 인공지능에서 오랜 도전 과제가 되어 왔다.

Method: 이 연구는 에이전트들이 환경의 구조화된 표현에 따라 목표에 대한 순위를 독립적으로 생성하고, 이 순위를 교환하여 특정 규칙에 따라 목표를 할당하는 방식을 사용한다.

Result: 한정된 관찰 가능한 그리드 월드 환경에서 greedy heuristics, 최적 할당 방법, LLM 기반 에이전트를 체계적으로 비교하였다.

Conclusion: LLM 기반 에이전트는 잘 설계된 프롬프트와 관련된 정량적 정보를 제공받을 때 근사 최적의 소요 시간을 달성할 수 있으며 전통적인 휴리스틱보다 일관되게 우수한 성능을 보인다.

Abstract: Coordinating multiple autonomous agents in shared environments under
decentralized conditions is a long-standing challenge in robotics and
artificial intelligence. This work addresses the problem of decentralized goal
assignment for multi-agent path planning, where agents independently generate
ranked preferences over goals based on structured representations of the
environment, including grid visualizations and scenario data. After this
reasoning phase, agents exchange their goal rankings, and assignments are
determined by a fixed, deterministic conflict-resolution rule (e.g., agent
index ordering), without negotiation or iterative coordination. We
systematically compare greedy heuristics, optimal assignment, and large
language model (LLM)-based agents in fully observable grid-world settings. Our
results show that LLM-based agents, when provided with well-designed prompts
and relevant quantitative information, can achieve near-optimal makespans and
consistently outperform traditional heuristics. These findings underscore the
potential of language models for decentralized goal assignment in multi-agent
path planning and highlight the importance of information structure in such
systems.

</details>


### [36] [From Benchmarks to Business Impact: Deploying IBM Generalist Agent in Enterprise Production](https://arxiv.org/abs/2510.23856)
*Segev Shlomov,Alon Oved,Sami Marreed,Ido Levy,Offer Akrabi,Avi Yaeli,Łukasz Strąk,Elizabeth Koumpan,Yinon Goldshtein,Eilam Shapira,Nir Mashkif,Asaf Adi*

Main category: cs.AI

TL;DR: 일반화 에이전트의 개발과 파일럿 경험을 보고하며, 이를 통해 기업 규모에서 일반화 에이전트의 가능성을 제시하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 작업 자동화에 대한 에이전트의 발전에도 불구하고, 기업들은 프로토타입을 넘어 실제로 비즈니스 가치를 제공하는 배치 시스템으로 나아가는 데 어려움을 겪고 있다.

Method: IBM은 일반화 에이전트인 CUGA 개발 및 파일럿을 통해 계층적 계획-실행 아키텍처를 채택하고, AppWorld 및 WebArena에서 최신 성능을 달성하였다.

Result: CUGA는 기업의 확장성, 감사 가능성, 안전성 및 거버넌스 요구 사항을 충족하면서 파일럿 평가에서 특별한 에이전트의 정확도에 근접하였다.

Conclusion: 일반화 에이전트가 기업 규모에서 운영될 수 있다는 조기 증거를 제공하고 처음 파일럿에서 얻은 기술적 및 조직적 교훈을 정리하였다.

Abstract: Agents are rapidly advancing in automating digital work, but enterprises face
a harder challenge: moving beyond prototypes to deployed systems that deliver
measurable business value. This path is complicated by fragmented frameworks,
slow development, and the absence of standardized evaluation practices.
Generalist agents have emerged as a promising direction, excelling on academic
benchmarks and offering flexibility across task types, applications, and
modalities. Yet, evidence of their use in production enterprise settings
remains limited. This paper reports IBM's experience developing and piloting
the Computer Using Generalist Agent (CUGA), which has been open-sourced for the
community (https://github.com/cuga-project/cuga-agent). CUGA adopts a
hierarchical planner--executor architecture with strong analytical foundations,
achieving state-of-the-art performance on AppWorld and WebArena. Beyond
benchmarks, it was evaluated in a pilot within the Business-Process-Outsourcing
talent acquisition domain, addressing enterprise requirements for scalability,
auditability, safety, and governance. To support assessment, we introduce
BPO-TA, a 26-task benchmark spanning 13 analytics endpoints. In preliminary
evaluations, CUGA approached the accuracy of specialized agents while
indicating potential for reducing development time and cost. Our contribution
is twofold: presenting early evidence of generalist agents operating at
enterprise scale, and distilling technical and organizational lessons from this
initial pilot. We outline requirements and next steps for advancing
research-grade architectures like CUGA into robust, enterprise-ready systems.

</details>


### [37] [Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges](https://arxiv.org/abs/2510.23883)
*Shrestha Datta,Shahriar Kabir Nahin,Anshuman Chhabra,Prasant Mohapatra*

Main category: cs.AI

TL;DR: 대형 언어 모델 기반의 능동적 AI 시스템은 자동화 플랫폼으로 떠오르고 있으며, 이는 새로운 보안 위험을 초래한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델에 의해 동력화된 능동적 AI 시스템은 자동화의 강력하고 유연한 플랫폼으로 등장하고 있다.

Method: 이 논문은 능동적 AI에 특화된 위협의 분류체계를 제시하고, 최근의 벤치마크 및 평가 방법론을 검토하며, 기술적 및 거버넌스 관점에서 방어 전략을 논의한다.

Result: 현재의 연구를 종합하고 보안 설계를 염두에 둔 에이전트 시스템의 개발을 지원하기 위한 열린 도전과제를 강조한다.

Conclusion: 능동적 AI 시스템의 보안 문제에 대한 심층적인 분석과 논의가 이루어졌다.

Abstract: Agentic AI systems powered by large language models (LLMs) and endowed with
planning, tool use, memory, and autonomy, are emerging as powerful, flexible
platforms for automation. Their ability to autonomously execute tasks across
web, software, and physical environments creates new and amplified security
risks, distinct from both traditional AI safety and conventional software
security. This survey outlines a taxonomy of threats specific to agentic AI,
reviews recent benchmarks and evaluation methodologies, and discusses defense
strategies from both technical and governance perspectives. We synthesize
current research and highlight open challenges, aiming to support the
development of secure-by-design agent systems.

</details>


### [38] [Latent Chain-of-Thought for Visual Reasoning](https://arxiv.org/abs/2510.23925)
*Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.AI

TL;DR: 본 논문에서는 대형 비전-언어 모델의 해석 가능성과 신뢰성을 향상시키기 위해 체인 오브 생각 추론을 재정의하고, 효율적인 훈련 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 비전-언어 모델(LVLM)의 해석 가능성과 신뢰성을 향상시키기 위해 체인 오브 생각(CoT) 추론이 중요한데, 기존의 훈련 알고리즘은 새로운 추론 작업에 대해 잘 일반화되지 않고 편향된 보상 모델에 의존한다.

Method: 추론을 후방 추정으로 재정의하고, 분산 변별 추정을 기반으로 한 확장 가능한 훈련 알고리즘을 제안한다. 또한, 다양성을 추구하는 강화 학습 알고리즘을 이용하여 다각적이고 높은 가능성을 가진 CoT를 장려하는 새로운 희소 보상 함수를 도입한다.

Result: 제안된 방법이 효과성, 일반화 및 해석 가능성 측면에서 일곱 개의 추론 벤치마크에서 최첨단 LVLM을 향상시킨다는 것을 경험적으로 증명했다.

Conclusion: 이 연구는 LVLM의 성능을 개선할 수 있는 새로운 접근 방식을 제공 있으며, 다양한 추론 작업에 효과적으로 적용될 수 있다.

Abstract: Chain-of-thought (CoT) reasoning is critical for improving the
interpretability and reliability of Large Vision-Language Models (LVLMs).
However, existing training algorithms such as SFT, PPO, and GRPO may not
generalize well across unseen reasoning tasks and heavily rely on a biased
reward model. To address this challenge, we reformulate reasoning in LVLMs as
posterior inference and propose a scalable training algorithm based on
amortized variational inference. By leveraging diversity-seeking reinforcement
learning algorithms, we introduce a novel sparse reward function for
token-level learning signals that encourage diverse, high-likelihood latent
CoT, overcoming deterministic sampling limitations and avoiding reward hacking.
Additionally, we implement a Bayesian inference-scaling strategy that replaces
costly Best-of-N and Beam Search with a marginal likelihood to efficiently rank
optimal rationales and answers. We empirically demonstrate that the proposed
method enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in
terms of effectiveness, generalization, and interpretability.

</details>


### [39] [Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer Programs: Single-Machine Scheduling](https://arxiv.org/abs/2510.24013)
*İbrahim Oğuz Çetinkaya,İ. Esra Büyüktahtakın,Parshin Shojaee,Chandan K. Reddy*

Main category: cs.AI

TL;DR: 본 연구는 대형 언어 모델(LLMs)의 힘을 활용하여 발견한 새로운 휴리스틱을 통해 스케줄링 및 조합 최적화 문헌에 기여합니다. 단일 프로세서에서 n개의 작업을 일정 순서로 배치하여 총 지연 시간을 최소화하는 단일 기계 총 지연 시간(SMTT) 문제에 집중합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)을 활용하여 스케줄링과 조합 최적화 문제에 새로운 휴리스틱을 제안하고자 합니다.

Method: 우리는 유명한 가장 이른 마감 기한(EDD) 및 수정된 마감 기한(MDD) 규칙에서 영감을 얻은 두 가지 새로운 LLM 발견 휴리스틱인 EDD 챌린저(EDDC)와 MDD 챌린저(MDDC)를 개발하고 벤치마킹합니다.

Result: EDD 챌린저는 고전적인 EDD 규칙과 널리 사용되는 알고리즘을 개선하였으며, MDD 챌린저는 전통적인 휴리스틱을 지속적으로 능가하고 정확한 접근 방법과 경쟁력을 유지합니다.

Conclusion: 본 연구는 인간과 LLM의 협력이 제한된 자원의 효과적인 구성 하에서도 NP-어려운 제약 조합 최적화 문제를 위해 확장 가능한 고성능 휴리스틱을 생산할 수 있음을 보여줍니다.

Abstract: Our study contributes to the scheduling and combinatorial optimization
literature with new heuristics discovered by leveraging the power of Large
Language Models (LLMs). We focus on the single-machine total tardiness (SMTT)
problem, which aims to minimize total tardiness by sequencing n jobs on a
single processor without preemption, given processing times and due dates. We
develop and benchmark two novel LLM-discovered heuristics, the EDD Challenger
(EDDC) and MDD Challenger (MDDC), inspired by the well-known Earliest Due Date
(EDD) and Modified Due Date (MDD) rules. In contrast to prior studies that
employed simpler rule-based heuristics, we evaluate our LLM-discovered
algorithms using rigorous criteria, including optimality gaps and solution time
derived from a mixed-integer programming (MIP) formulation of SMTT. We compare
their performance against state-of-the-art heuristics and exact methods across
various job sizes (20, 100, 200, and 500 jobs). For instances with more than
100 jobs, exact methods such as MIP and dynamic programming become
computationally intractable. Up to 500 jobs, EDDC improves upon the classic EDD
rule and another widely used algorithm in the literature. MDDC consistently
outperforms traditional heuristics and remains competitive with exact
approaches, particularly on larger and more complex instances. This study shows
that human-LLM collaboration can produce scalable, high-performing heuristics
for NP-hard constrained combinatorial optimization, even under limited
resources when effectively configured.

</details>


### [40] [From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems](https://arxiv.org/abs/2510.24145)
*Yu Luo,Jiamin Jiang,Jingfei Feng,Lei Tao,Qingliang Zhang,Xidao Wen,Yongqian Sun,Shenglin Zhang,Jielong Huang,Nan Qi,Dan Pei*

Main category: cs.AI

TL;DR: OpsAgent는 클라우드 시스템의 장애 관리에서 경량의 자기 진화형 다중 에이전트 시스템을 제안하며, 이 시스템은 이질적인 관측 데이터를 구조화된 텍스트 설명으로 변환하여 진단 추론의 투명하고 감사 가능한 협업 프레임워크를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 클라우드 시스템의 신뢰성에서 사고 관리(IM)의 중요성이 커지고 있으며, 수작업 IM은 노동 집약적이고 오류가 발생하기 쉬운 문제를 안고 있습니다.

Method: OpsAgent는 훈련 없이 이질적인 관측 데이터를 구조화된 텍스트 설명으로 변환하는 데이터 프로세서를 사용하며, 진단 추론의 투명성과 감사 가능성을 높이기 위해 다중 에이전트 협업 프레임워크를 도입합니다.

Result: OPENRCA 벤치마크에서 수행된 종합적인 실험은 OpsAgent가 일반화 가능하고 해석 가능하며 비용 효율적이고 자기 진화적인 성능을 보임을 입증합니다.

Conclusion: OpsAgent는 실제 클라우드 시스템에서 장기 운영을 위한 실제 배치 가능하고 지속 가능한 솔루션입니다.

Abstract: Incident management (IM) is central to the reliability of large-scale cloud
systems. Yet manual IM, where on-call engineers examine metrics, logs, and
traces is labor-intensive and error-prone in the face of massive and
heterogeneous observability data. Existing automated IM approaches often
struggle to generalize across systems, provide limited interpretability, and
incur high deployment costs, which hinders adoption in practice. In this paper,
we present OpsAgent, a lightweight, self-evolving multi-agent system for IM
that employs a training-free data processor to convert heterogeneous
observability data into structured textual descriptions, along with a
multi-agent collaboration framework that makes diagnostic inference transparent
and auditable. To support continual capability growth, OpsAgent also introduces
a dual self-evolution mechanism that integrates internal model updates with
external experience accumulation, thereby closing the deployment loop.
Comprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art
performance and show that OpsAgent is generalizable, interpretable,
cost-efficient, and self-evolving, making it a practically deployable and
sustainable solution for long-term operation in real-world cloud systems.

</details>


### [41] [BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data](https://arxiv.org/abs/2510.24151)
*Bingsen Qiu,Zijian Liu,Xiao Liu,Haoshen Yang,Zeren Gao,Bingjie Wang,Feier Zhang,Yixuan Qin,Chunyan Li*

Main category: cs.AI

TL;DR: 본 연구에서는 고난이도, 훈련 준비가 완료된 다중 홉 질문을 자동으로 생성하는 프레임워크를 제시하여, 동시대 모델의 검색 및 추론 능력을 평가하는 데이터 확보의 어려움을 해결하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 고난이도의 다중 홉 질문 응답 데이터셋을 구축하는 것은 모델의 검색 및 추론 능력을 진정으로 테스트하는 데 있어 여전히 큰 도전 과제가 되고 있다.

Method: 이 시스템은 자연어 추론(NLI) 기반 관계 유형 결정 및 다양성 인지 확장을 통해 다양한 논리적으로 레이블링된 증거 클러스터를 생성하고, 역질문 구성 기법을 사용하여 복잡한 신호를 조합하여 목표 엔티티를 유일하게 식별하는 질문을 구성한다.

Result: 이 과정은 고난이도의 복잡하고 검색에 저항력이 있는 검증 가능한 질문을 생성하여 SFT/RL 훈련 및 채점 평가에 적합하게 만든다.

Conclusion: 이 방법은 강력한 평가 벤치마크의 난이도 프로필을 유지하면서도 인간의 큐레이션 노력을 상당히 줄인다.

Abstract: Building training-ready multi-hop question answering (QA) datasets that truly
stress a model's retrieval and reasoning abilities remains highly challenging
recently. While there have been a few recent evaluation datasets that capture
the characteristics of hard-to-search but easy-to-verify problems -- requiring
the integration of ambiguous, indirect, and cross-domain cues -- these data
resources remain scarce and are mostly designed for evaluation, making them
unsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).
Meanwhile, manually curating non-trivially retrievable questions -- where
answers cannot be found through a single direct query but instead require
multi-hop reasoning over oblique and loosely connected evidence -- incurs
prohibitive human costs and fails to scale, creating a critical data bottleneck
for training high-capability retrieval-and-reasoning agents.
  To address this, we present an automated framework for generating
high-difficulty, training-ready multi-hop questions from semi-structured
knowledge sources. The system (i) grows diverse, logically labeled evidence
clusters through Natural Language Inference (NLI)-based relation typing and
diversity-aware expansion; (ii) applies reverse question construction to
compose oblique cues so that isolated signals are underinformative but their
combination uniquely identifies the target entity; and (iii) enforces quality
with a two-step evaluation pipeline that combines multi-model consensus
filtering with structured constraint decomposition and evidence-based matching.
The result is a scalable process that yields complex, retrieval-resistant yet
verifiable questions suitable for SFT/RL training as well as challenging
evaluation, substantially reducing human curation effort while preserving the
difficulty profile of strong evaluation benchmarks.

</details>


### [42] [BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning](https://arxiv.org/abs/2510.24161)
*Wentao Tan,Bowen Wang,Heng Zhi,Chenyu Liu,Zhe Li,Jian Liu,Zengrong Lin,Yukun Dai,Yipeng Chen,Wenjie Yang,Enci Xie,Hao Xue,Baixu Ji,Chen Xu,Zhibin Wang,Tianshi Wang,Lei Zhu,Heng Tao Shen*

Main category: cs.AI

TL;DR: 이 논문은 디지털 공간과 물리적 공간을 넘나드는 통합된 멀티모달 대형 모델(BLM1)을 제안하며, 이는 다양한 임무와 구현을 일반화할 수 있다.


<details>
  <summary>Details</summary>
Motivation: MLLM은 비전-언어 추론을 발전시켰지만, 디지털-물리적 공간 및 구현 간 일반화가 부족하고, ELLM은 물리 세계에 대한 일반화가 약한 보완이 필요하다.

Method: BLM1은 두 단계의 훈련 패러다임을 통해 구현된 지식을 통합하고, 고수준 의미를 추출하여 제어를 안내하는 정책 모듈을 훈련한다.

Result: BLM1은 디지털 및 물리적 벤치마크에서 평가 결과, MLLM, ELLM, VLA, GMLM의 네 가지 모델 군을 초과하는 성능을 발휘한다.

Conclusion: BLM1은 디지털 작업에서 약 6%, 물리적 작업에서 약 3% 개선된 성능을 보여준다.

Abstract: Multimodal large language models (MLLMs) have advanced vision-language
reasoning and are increasingly deployed in embodied agents. However,
significant limitations remain: MLLMs generalize poorly across digital-physical
spaces and embodiments; vision-language-action models (VLAs) produce low-level
actions yet lack robust high-level embodied reasoning; and most embodied large
language models (ELLMs) are constrained to digital-space with poor
generalization to the physical world. Thus, unified models that operate
seamlessly across digital and physical spaces while generalizing across
embodiments and tasks remain absent. We introduce the \textbf{Boundless Large
Model (BLM$_1$)}, a multimodal spatial foundation model that preserves
instruction following and reasoning, incorporates embodied knowledge, and
supports robust cross-embodiment control. BLM$_1$ integrates three key
capabilities -- \textit{cross-space transfer, cross-task learning, and
cross-embodiment generalization} -- via a two-stage training paradigm. Stage I
injects embodied knowledge into the MLLM through curated digital corpora while
maintaining language competence. Stage II trains a policy module through an
intent-bridging interface that extracts high-level semantics from the MLLM to
guide control, without fine-tuning the MLLM backbone. This process is supported
by a self-collected cross-embodiment demonstration suite spanning four robot
embodiments and six progressively challenging tasks. Evaluations across digital
and physical benchmarks show that a single BLM$_1$ instance outperforms four
model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving
$\sim\!\textbf{6%}$ gains in digital tasks and $\sim\!\textbf{3%}$ in physical
tasks.

</details>


### [43] [MGA: Memory-Driven GUI Agent for Observation-Centric Interaction](https://arxiv.org/abs/2510.24168)
*Weihua Cheng,Ersheng Ni,Wenlong Wang,Yifei Sun,Junming Liu,Wangyu Shen,Yirong Chen,Botian Shi,Ding Wang*

Main category: cs.AI

TL;DR: 이 논문은 메모리 기반 GUI 에이전트(MGA)를 소개하며, GUI 상호작용을 먼저 관찰한 후 결정하는 원칙을 기반으로 재구성하여 강인성, 일반화 및 효율성에서 기존 최첨단 모델보다 현저한 성과를 달성했다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델과 그 다양성 있는 환경에서 작동 가능한 에이전트 시스템의 발전을 바탕으로, GUI 에이전트를 개발하려는 도전적인 목표를 제시하였다.

Method: MGA는 GUI 상호작용을 '먼저 관찰한 후 결정하기'의 원칙으로 재구성하고, 각 단계를 독립적이고 맥락이 풍부한 환경 상태로 모델링하여 현재 스크린샷, 작업 무관 공간 정보 및 동적으로 업데이트되는 구조화된 메모리를 활용한다.

Result: MGA는 OSworld 벤치마크, 실제 데스크탑 애플리케이션(Chrome, VSCode, VLC), 크로스 작업 전이에서 기존 최첨단 기준 모델들에 비해 강인성, 일반화, 효율성에서 실질적으로 향상되었다.

Conclusion: MGA는 GUI 상호작용의 새로운 접근 방식을 제공하며, 코드는 공개적으로 이용 가능하다.

Abstract: The rapid progress of Large Language Models (LLMs) and their multimodal
extensions (MLLMs) has enabled agentic systems capable of perceiving and acting
across diverse environments. A challenging yet impactful frontier is the
development of GUI agents, which must navigate complex desktop and web
interfaces while maintaining robustness and generalization. Existing paradigms
typically model tasks as long-chain executions, concatenating historical
trajectories into the context. While approaches such as Mirage and GTA1 refine
planning or introduce multi-branch action selection, they remain constrained by
two persistent issues: Dependence on historical trajectories, which amplifies
error propagation. And Local exploration bias, where "decision-first,
observation-later" mechanisms overlook critical interface cues. We introduce
the Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the
principle of observe first, then decide. MGA models each step as an
independent, context-rich environment state represented by a triad: current
screenshot, task-agnostic spatial information, and a dynamically updated
structured memory. Experiments on OSworld benchmarks, real desktop applications
(Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves
substantial gains in robustness, generalization, and efficiency compared to
state-of-the-art baselines. The code is publicly available at:
{https://anonymous.4open.science/r/MGA-3571}.

</details>


### [44] [MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools](https://arxiv.org/abs/2510.24284)
*Wenhao Wang,Peizhi Niu,Zhao Xu,Zhaoyu Chen,Jian Du,Yaxin Du,Xianghe Pang,Keduan Huang,Yanfeng Wang,Qiang Yan,Siheng Chen*

Main category: cs.AI

TL;DR: MCP-Flow는 대규모 서버 발견, 데이터 종합, 모델 학습을 위한 자동화된 웹 에이전트 기반 파이프라인을 제공하며, 기존의 연구를 능가하는 높은 품질의 데이터 쌍을 생성한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)이 복잡하고 현실적인 작업을 수행하기 위해 외부 도구에 의존하는 경향이 있으며, 모델 맥락 프로토콜(MCP) 생태계를 효과적으로 활용해야 하는 필요성이 증가하고 있다.

Method: MCP-Flow는 1166개 서버와 11536개 도구에서 데이터를 수집하고 필터링하여 고품질의 지침-함수 호출 쌍과 궤적을 생성하는 자동화된 시스템이다.

Result: MCP-Flow는 68733개의 지침-함수 호출 쌍과 6439개의 궤적을 생성하여, 이전 연구보다 규모와 다양성 면에서 훨씬 우수한 결과를 보여준다.

Conclusion: MCP-Flow는 LLM 에이전트들이 실제 MCP 환경에서 능력을 발전시킬 수 있도록 하는 확장 가능한 기초를 제공한다.

Abstract: Large Language Models (LLMs) increasingly rely on external tools to perform
complex, realistic tasks, yet their ability to utilize the rapidly expanding
Model Contextual Protocol (MCP) ecosystem remains limited. Existing MCP
research covers few servers, depends on costly manual curation, and lacks
training support, hindering progress toward real-world deployment. To overcome
these limitations, we introduce MCP-Flow, an automated web-agent-driven
pipeline for large-scale server discovery, data synthesis, and model training.
MCP-Flow collects and filters data from 1166 servers and 11536 tools, producing
68733 high-quality instruction-function call pairs and 6439 trajectories, far
exceeding prior work in scale and diversity. Extensive experiments demonstrate
MCP-Flow's effectiveness in driving superior MCP tool selection, function-call
generation, and enhanced agentic task performance. MCP-Flow thus provides a
scalable foundation for advancing LLM agents' proficiency in real-world MCP
environments. MCP-Flow is publicly available at
\href{https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}.

</details>


### [45] [Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting](https://arxiv.org/abs/2510.24303)
*Deniz Gorur,Antoni Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 다양한 대리인이 주장 진위를 검증하는 새로운 다중 에이전트 프레임워크를 제안하며, 이 프레임워크는 주장 진위를 평가하고 구체적인 증거를 제시하는 방식으로 작동한다.


<details>
  <summary>Details</summary>
Motivation: 주장 진단 예측은 인간의 판단에 기반한 미래 사건에 대한 예측 작업으로, 그 사건의 신뢰성을 평가하는 검증 방식으로 볼 수 있다.

Method: 다양한 대리인들로 구성된 새로운 다중 에이전트 프레임워크를 제안하며, 각 대리인은 주장 진위에 대해 의견 차이를 보이고 관련 증거를 제시한다. 이때 증거는 정량적 쌍극적 논증 프레임워크(QBAFs) 형식으로 표현된다.

Result: 두 가지 표준 주장 진단 예측 데이터셋에서 실험을 진행하였으며, 세 가지 또는 두 가지 대리인이 결합된 인스턴스를 여섯 개의 서로 다른 LLM으로 구현했다. 대리인의 증거 결합이 예측 정확도를 향상시키는 것을 관찰하였다.

Conclusion: 특히 세 가지 대리인의 경우, 주장 진위 검증을 위해 증거를 설명 가능하게 결합할 수 있음을 시사한다.

Abstract: Judgmental forecasting is the task of making predictions about future events
based on human judgment. This task can be seen as a form of claim verification,
where the claim corresponds to a future event and the task is to assess the
plausibility of that event. In this paper, we propose a novel multi-agent
framework for claim verification, whereby different agents may disagree on
claim veracity and bring specific evidence for and against the claims,
represented as quantitative bipolar argumentation frameworks (QBAFs). We then
instantiate the framework for supporting claim verification, with a variety of
agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an
existing approach for claim verification that generates and evaluates QBAFs;
(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)
from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,
extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of
arguments from external sources. Finally, we conduct experiments with two
standard judgmental forecasting datasets, with instances of our framework with
two or three agents, empowered by six different base LLMs. We observe that
combining evidence from agents can improve forecasting accuracy, especially in
the case of three agents, while providing an explainable combination of
evidence for claim verification.

</details>


### [46] [VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation](https://arxiv.org/abs/2510.24339)
*Yunxuan Jiang,Silan Hu,Xiaoning Wang,Yuanyuan Zhang,Xiangyu Chang*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)을 통합한 데이터 과학 시스템의 신뢰성과 견고성을 높이기 위해, PCS 원칙을 기반으로 한 VDSAgents라는 다중 에이전트 시스템을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델 기반의 데이터 과학 시스템은 과학적 원칙과 이론적 지침 없이 내부 추론에만 의존하여 신뢰성과 견고성이 떨어진다.

Method: VDSAgents는 예측 가능성-계산 가능성-안정성(PCS) 원칙에 따라 데이터 청소, 특성 공학, 모델링 및 평가를 위한 모듈형 워크플로우를 구현한다.

Result: VDSAgents는 아홉 개의 다양한 데이터셋에 대해 평가되었으며, AutoKaggle 및 DataInterpreter와 같은 최신 데이터 과학 시스템과 비교하여 consistently outperform 한다.

Conclusion: PCS 원칙을 LLM 기반의 데이터 과학 자동화에 통합하는 것이 가능함을 검증한다.

Abstract: Large language models (LLMs) become increasingly integrated into data science
workflows for automated system design. However, these LLM-driven data science
systems rely solely on the internal reasoning of LLMs, lacking guidance from
scientific and theoretical principles. This limits their trustworthiness and
robustness, especially when dealing with noisy and complex real-world datasets.
This paper provides VDSAgents, a multi-agent system grounded in the
Predictability-Computability-Stability (PCS) principles proposed in the
Veridical Data Science (VDS) framework. Guided by PCS principles, the system
implements a modular workflow for data cleaning, feature engineering, modeling,
and evaluation. Each phase is handled by an elegant agent, incorporating
perturbation analysis, unit testing, and model validation to ensure both
functionality and scientific auditability. We evaluate VDSAgents on nine
datasets with diverse characteristics, comparing it with state-of-the-art
end-to-end data science systems, such as AutoKaggle and DataInterpreter, using
DeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the
results of AutoKaggle and DataInterpreter, which validates the feasibility of
embedding PCS principles into LLM-driven data science automation.

</details>


### [47] [An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine](https://arxiv.org/abs/2510.24359)
*Pedram Fard,Alaleh Azhir,Neguine Rezaii,Jiazi Tian,Hossein Estiri*

Main category: cs.AI

TL;DR: 이 연구는 평균 환자에 초점을 맞춘 의료 인공지능의 한계를 지적하며, 개별 환자에게 맞춤화된 결정을 지원하는 다중 에이전트 생태계의 필요성을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 의료 인공지능이 평균 환자에게 서비스를 제공하는 데 중점을 두는 것은 기형적인 결과를 초래하고 있으며, 이는 형평성과 신뢰를 훼손한다.

Method: 다중 에이전트 생태계를 통해 장기 시스템, 환자 집단, 분석 양식을 기반으로 한 에이전트를 클러스터링하고, 이들이 공유하는 모델 및 증거 수집 도구를 활용한다.

Result: 결과는 신뢰성, 불확실성, 데이터 밀도를 고려하는 조정 레이어에서 수렴하여 임상의에게 의사결정 지원 패킷을 제공한다.

Conclusion: 이 접근법은 의료 AI를 의료의 첫 번째 원칙인 투명성 있고 형평성이 있으며 개인 중심의 보살핌과 일치시키려고 한다.

Abstract: Artificial intelligence in medicine is built to serve the average patient. By
minimizing error across large datasets, most systems deliver strong aggregate
accuracy yet falter at the margins: patients with rare variants,
multimorbidity, or underrepresented demographics. This average patient fallacy
erodes both equity and trust. We propose a different design: a multi-agent
ecosystem for N-of-1 decision support. In this environment, agents clustered by
organ systems, patient populations, and analytic modalities draw on a shared
library of models and evidence synthesis tools. Their results converge in a
coordination layer that weighs reliability, uncertainty, and data density
before presenting the clinician with a decision-support packet: risk estimates
bounded by confidence ranges, outlier flags, and linked evidence. Validation
shifts from population averages to individual reliability, measured by error in
low-density regions, calibration in the small, and risk--coverage trade-offs.
Anticipated challenges include computational demands, automation bias, and
regulatory fit, addressed through caching strategies, consensus checks, and
adaptive trial frameworks. By moving from monolithic models to orchestrated
intelligence, this approach seeks to align medical AI with the first principle
of medicine: care that is transparent, equitable, and centered on the
individual.

</details>


### [48] [Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion](https://arxiv.org/abs/2510.24390)
*Xianjun Gao,Jianchun Liu,Hongli Xu,Liusheng Huang*

Main category: cs.AI

TL;DR: 본 논문에서는 Orion이라는 새로운 효율적인 추론 프레임워크를 제안하여 대형 언어 모델의 실시간 웹 애플리케이션 통합을 위한 고성능 추론을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)을 실시간 웹 애플리케이션에 통합할 때 고품질 복잡한 추론과 낮은 대기 시간 및 높은 처리량 요구를 조화시키는 것이 중요하다.

Method: Orion은 쿼리 분해와 논리적 콘텐츠 확장을 동시적으로 수행하는 두 가지 상호 보완적인 단계로 단일 쿼리 추론 프로세스를 분해한다.

Result: Orion은 기본 성능 대비 최대 4.33배 빠른 토큰 생성 속도와 3.42배 낮은 답변 지연 시간을 제공하며, 점 간의 의존성을 명시적으로 모델링함으로써 추론 품질을 최대 18.75% 향상시킨다.

Conclusion: Orion은 여러 쿼리에서 교차 쿼리 병렬성을 가능하게 하고 추론 성능(효율성과 품질)을 극적으로 향상시킨다.

Abstract: The integration of Large Language Models (LLMs) into real-time Web
applications, such as AI-powered search and conversational agents, presents a
fundamental Web infrastructure challenge: reconciling the demand for
high-quality, complex reasoning with the stringent low-latency and
high-throughput requirements of interactive services. Current LLM reasoning,
hindered by computationally inefficient sequential generation and rigid
reasoning strategies, creates a critical bottleneck for the Web services.
Existing approaches typically optimize the LLM reasoning for either efficiency
or quality but struggle to achieve both, and thus fail to meet the dual
requirements of modern Web platforms. To overcome these limitations, we propose
Orion, a novel and efficient reasoning framework that enables dependency-aware
query decomposition and logic-parallel content expansion. Concretely, Orion
decomposes a single query reasoning process into two synergistic phases: (1)
\textit{key point generation}, which distills logically structured key points
through retrieval-augmented few-shot prompting, and (2) \textit{content
parallel expansion}, which concurrently elaborates on these points based on a
dependency graph to ensure logical consistency. Furthermore, Orion introduces a
pipeline scheduling mechanism that exploits the complementary computational
characteristics of the two phases (generation imposes pressure on GPU computing
and expansion stresses on GPU memory) across multiple queries, enabling
cross-query parallelism and dramatically improving reasoning performance (\ie,
efficiency and quality). Experiments on diverse benchmarks show that Orion not
only delivers up to 4.33x higher token generation speed and 3.42x lower answer
latency over the baselines but also improves reasoning quality by up to 18.75%
through explicitly modeling inter-point dependencies.

</details>


### [49] [APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training](https://arxiv.org/abs/2510.24397)
*Jiarui Qin,Yunjia Xi,Junjie Huang,Renting Rui,Di Yin,Weiwen Liu,Yong Yu,Weinan Zhang,Xing Sun*

Main category: cs.AI

TL;DR: APTBench는 LLM 사전 훈련 중 에이전트의 잠재력을 평가할 수 있는 새로운 벤치마크 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트의 발전에 따라 실제 자율 작업 수행에 LLM을 더 잘 맞추기 위해 에이전트 특정 데이터를 사전 훈련에 통합할 필요성이 대두되고 있습니다.

Method: APTBench는 실제 에이전트 작업과 성공적인 경로를 기반 모델에 맞춘 선택형 또는 텍스트 완성 질문으로 변환하는 프레임워크입니다.

Result: APTBench는 계획 및 행동과 같은 핵심 에이전트 능력에 집중하고 소프트웨어 공학 및 심도 있는 연구와 같은 주요 에이전트 시나리오를 포괄합니다.

Conclusion: 기존의 범용 벤치마크와 비교할 때, APTBench는 모델의 에이전트로서의 하위 성능에 대한 더 예측 가능한 신호를 제공하며, 후속 훈련 후 전체 엔드 투 엔드 에이전트 평가보다 훨씬 가볍고 비용 효율적입니다.

Abstract: With the rapid development of LLM-based agents, there is a growing trend to
incorporate agent-specific data into the pre-training stage of LLMs, aiming to
better align LLMs with real-world autonomous task execution. However, current
pre-training benchmarks primarily focus on isolated and static skills, e.g.,
common knowledge or mathematical/code reasoning, and fail to reflect model's
agentic capabilities. On the other hand, agent benchmarks are typically
designed for post-trained models, requiring multi-turn task execution abilities
that base models struggle to support. Thus, there is a compelling need for a
benchmark that can evaluate agentic potentials during pre-training and guide
the model training more effectively. To address this gap, we propose APTBench,
a framework that converts real-world agent tasks and successful trajectories
into multiple-choice or text completion questions tailored for base models. It
focuses on core agentic abilities, e.g., planning and action, and covers key
agent scenarios, software engineering and deep research. Compared to existing
general-purpose benchmarks, APTBench offers a more predictive signal of a
model's downstream performance as an agent, while remaining significantly more
lightweight and cost-effective than full-scale, end-to-end agent evaluations
after post-training.

</details>


### [50] [OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows](https://arxiv.org/abs/2510.24411)
*Qiushi Sun,Mukai Li,Zhoumianze Liu,Zhihui Xie,Fangzhi Xu,Zhangyue Yin,Kanzhi Cheng,Zehao Li,Zichen Ding,Qi Liu,Zhiyong Wu,Zhuosheng Zhang,Ben Kao,Lingpeng Kong*

Main category: cs.AI

TL;DR: 모바일 환경에서 안전성 문제를 탐지하기 위한 새로운 프레임워크인 OS-Sentinel을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 디지털 자동화를 발전시키기 위한 비전-언어 모델(VLM) 기반의 컴퓨터 사용 에이전트는 안전성 문제를 동반할 수 있습니다.

Method: MobileRisk-Live라는 동적 샌드박스를 구축하고, OS-Sentinel이라는 하이브리드 안전 탐지 프레임워크를 제안합니다.

Result: OS-Sentinel은 기존 방법에 비해 10%-30%의 개선을 보여주었습니다.

Conclusion: 이 연구는 보다 안전하고 신뢰할 수 있는 자율 모바일 에이전트 개발에 기여할 수 있는 통찰력을 제공합니다.

Abstract: Computer-using agents powered by Vision-Language Models (VLMs) have
demonstrated human-like capabilities in operating digital environments like
mobile platforms. While these agents hold great promise for advancing digital
automation, their potential for unsafe operations, such as system compromise
and privacy leakage, is raising significant concerns. Detecting these safety
concerns across the vast and complex operational space of mobile environments
presents a formidable challenge that remains critically underexplored. To
establish a foundation for mobile agent safety research, we introduce
MobileRisk-Live, a dynamic sandbox environment accompanied by a safety
detection benchmark comprising realistic trajectories with fine-grained
annotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety
detection framework that synergistically combines a Formal Verifier for
detecting explicit system-level violations with a VLM-based Contextual Judge
for assessing contextual risks and agent actions. Experiments show that
OS-Sentinel achieves 10%-30% improvements over existing approaches across
multiple metrics. Further analysis provides critical insights that foster the
development of safer and more reliable autonomous mobile agents.

</details>


### [51] [Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives](https://arxiv.org/abs/2510.24551)
*Gang Chen,Changshuo Liu,Gene Anne Ooi,Marcus Tan,Zhongle Xie,Jianwei Yin,James Wei Luen Yip,Wenqiao Zhang,Jiaqi Zhu,Beng Chin Ooi*

Main category: cs.AI

TL;DR: Generative Artificial Intelligence (GenAI)는 의료 서비스를 포함한 기존 관행을 혁신적으로 변화시킬 수 있는 기회를 제공하며, 의료 데이터 생태계를 기반으로 하는 데이터 중심 패러다임을 제안하여 이를 지원한다.


<details>
  <summary>Details</summary>
Motivation: GenAI의 도입은 의료 제공 방식에 큰 변화를 가져올 잠재력을 가지고 있으며, 이는 임상 의사들의 인지 부담을 줄이고 효과적인 진단 및 개인화된 치료를 가능하게 한다.

Method: 의료 데이터 생태계를 생성적 의료 시스템의 기초로 재조정하고, 이를 통해 다양하고 복잡한 의료 데이터를 통합, 표현 및 검색할 수 있는 지속 가능한 지원 체계를 마련한다.

Result: 제안된 생태계는 고품질의 다중 모드 데이터를 제공하여 대규모 사전 학습 및 도메인 특정 미세 조정을 가능하게 하며, 작업 특화 추론을 지원하는 지식 검색 백엔드 역할을 한다.

Conclusion: 결국, 제안된 생태계는 고품질 및 효과적인 의료 제공을 위한 GenAI의 배포를 가능하게 한다.

Abstract: Generative Artificial Intelligence (GenAI) is taking the world by storm. It
promises transformative opportunities for advancing and disrupting existing
practices, including healthcare. From large language models (LLMs) for clinical
note synthesis and conversational assistance to multimodal systems that
integrate medical imaging, electronic health records, and genomic data for
decision support, GenAI is transforming the practice of medicine and the
delivery of healthcare, such as diagnosis and personalized treatments, with
great potential in reducing the cognitive burden on clinicians, thereby
improving overall healthcare delivery. However, GenAI deployment in healthcare
requires an in-depth understanding of healthcare tasks and what can and cannot
be achieved. In this paper, we propose a data-centric paradigm in the design
and deployment of GenAI systems for healthcare. Specifically, we reposition the
data life cycle by making the medical data ecosystem as the foundational
substrate for generative healthcare systems. This ecosystem is designed to
sustainably support the integration, representation, and retrieval of diverse
medical data and knowledge. With effective and efficient data processing
pipelines, such as semantic vector search and contextual querying, it enables
GenAI-powered operations for upstream model components and downstream clinical
applications. Ultimately, it not only supplies foundation models with
high-quality, multimodal data for large-scale pretraining and domain-specific
fine-tuning, but also serves as a knowledge retrieval backend to support
task-specific inference via the agentic layer. The ecosystem enables the
deployment of GenAI for high-quality and effective healthcare delivery.

</details>


### [52] [FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling](https://arxiv.org/abs/2510.24645)
*Zengzhuang Xu,Bingguang Hao,Zechuan Wang,Yuntao Wen,Maolin Wang,Yang Liu,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Chenyi Zhuang,Jinjie Gu,Leilei Gan,Xiangyu Zhao,Shi Gu*

Main category: cs.AI

TL;DR: 이 논문에서는 복잡한 현실 세계 문제를 해결하기 위한 도구 사용을 위한 고품질 다중 턴 훈련 데이터 생성을 위한 새로운 데이터 합성 프레임워크인 FunReason-MT를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 툴 인터페이스와 이를 이용한 복잡한 문제 해결을 위한 고품질 다중 턴 훈련 데이터의 필요성.

Method: FunReason-MT는 Environment-API 그래프 상호작용, 고급 도구 쿼리 합성, 그리고 복잡한 CoT 생성 위한 유도 반복 체인을 사용하여 다중 턴 FC 데이터의 복잡성 장벽을 해결합니다.

Result: Berkeley Function-Calling Leaderboard (BFCLv3)에서의 평가 결과, FunReason-MT를 기반으로 한 4B 모델이 유사 모델 중에서 최첨단 성능을 달성했습니다.

Conclusion: FunReason-MT는 에이전틱 학습을 위한 신뢰할 수 있고 강력한 데이터 출처를 제공합니다.

Abstract: Function calling (FC) empowers large language models (LLMs) and autonomous
agents to interface with external tools, a critical capability for solving
complex, real-world problems. As this ability becomes increasingly central to
advanced AI systems, the need for high-quality, multi-turn training data to
develop and refine it cannot be overstated. Existing data synthesis methods,
such as random environment sampling or multi-agent role-playing, are not
powerful enough to generate high-quality data in real-world environments.
Practical challenges come in three folds: targeted model training, isolation of
tool architecture, and multi-turn logical dependency. To address these
structural deficiencies, we present FunReason-MT, a novel data synthesis
framework for real-world multi-turn tool use. FunReason-MT resolves the
complexity barrier in multi-turn FC data by employing 1) Environment-API Graph
Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query
Synthesis to simplify hard query construction, and 3) Guided Iterative Chain
for sophisticated CoT generation. Evaluations on Berkeley Function-Calling
Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built
upon FunReason-MT generated data achieves state-of-the-art performance among
comparable-sized models, outperforming most close-source models. Further
performance improvements on BFCLv4 confirm that FunReason-MT provides a
reliable and robust source for agentic learning.

</details>


### [53] [OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs](https://arxiv.org/abs/2510.24663)
*Yifu Lu,Shengjie Liu,Li Dong*

Main category: cs.AI

TL;DR: 이 논문에서는 다중 턴 도구 상호 작용의 복잡성을 무시하는 기존의 연구에서 벗어나, 통제 가능한 복잡성을 가진 도구 실행을 모델링하는 OrchDAG라는 합성 데이터 생성 파이프라인을 도입하였다. 또한, 모델 성능을 벤치마킹하고 RLVR 훈련을 향상시키기 위해 그래프 기반 보상을 제안하였다.


<details>
  <summary>Details</summary>
Motivation: 다중 턴 도구 상호 작용의 복잡성을 더 잘 이해하고 해결하기 위해.

Method: OrchDAG라는 합성 데이터 생성 파이프라인을 사용하여 도구 실행을 방향성 비순환 그래프(DAG)로 모델링하고, RLVR 훈련을 개선하기 위한 그래프 기반 보상을 제안하였다.

Result: 제안된 데이터셋은 도전적이지만 해결 가능한 벤치마크를 제공하며, GRPO 스타일 알고리즘과 결합했을 때 보상이 효과적이라는 것을 보여준다.

Conclusion: 다중 턴 도구 사용에서 위상 구조와 데이터 복잡성의 활용이 중요함을 강조한다.

Abstract: Agentic tool use has gained traction with the rise of agentic tool calling,
yet most existing work overlooks the complexity of multi-turn tool
interactions. We introduce OrchDAG, a synthetic data generation pipeline that
models tool execution as directed acyclic graphs (DAGs) with controllable
complexity. Using this dataset, we benchmark model performance and propose a
graph-based reward to enhance RLVR training. Experiments show that the dataset
presents a challenging but solvable benchmark, and the proposed reward is
effective when combined with GRPO-style algorithms, highlighting the importance
of leveraging topological structure and data complexity in multi-turn tool use.

</details>


### [54] [Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning](https://arxiv.org/abs/2510.24690)
*Shengjie Liu,Li Dong,Zhenyu Zhang*

Main category: cs.AI

TL;DR: 이 논문은 도구와 문서 간의 의존성을 밝혀내고 활용하여 대표 아티팩트 생성을 개선하는 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 도구와 문서 간의 의존성을 이해하고 이를 활용하여 보다 나은 아티팩트 생성이 필요하다.

Method: 도구 스키마로부터 도구 지식 그래프를 구축하고, 내부 문서와 SOPs로부터 보완 지식 그래프를 도출한 후 이를 결합한다.

Result: 실험 결과, 이 통합 프레임워크가 도구 상호작용을 효과적으로 모델링하고 계획 생성 능력을 향상시킴을 보여준다.

Conclusion: 도구 그래프와 도메인 지식 그래프를 연결함으로써 도구를 활용한 추론과 계획에서의 이점을 강조한다.

Abstract: We present a framework for uncovering and exploiting dependencies among tools
and documents to enhance exemplar artifact generation. Our method begins by
constructing a tool knowledge graph from tool schemas,including descriptions,
arguments, and output payloads, using a DeepResearch-inspired analysis. In
parallel, we derive a complementary knowledge graph from internal documents and
SOPs, which is then fused with the tool graph. To generate exemplar plans, we
adopt a deep-sparse integration strategy that aligns structural tool
dependencies with procedural knowledge. Experiments demonstrate that this
unified framework effectively models tool interactions and improves plan
generation, underscoring the benefits of linking tool graphs with domain
knowledge graphs for tool-augmented reasoning and planning.

</details>
