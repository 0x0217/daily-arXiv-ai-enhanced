<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 9]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 15]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving](https://arxiv.org/abs/2511.16916)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 이 논문은 다중 차량 협력 주행 작업에서 보상 차이 감소 문제를 해결하기 위해 새로운 하이브리드 차별 보상(HDR) 메커니즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 상태 기반 보상 함수의 한계를 극복하고 협력 주행에서의 성능을 향상시키기 위해.

Method: HDR 메커니즘은 전역 포텐셜 함수에 기반한 시간 차이 보상(TRD)과 행동 기울기 보상(ARG) 두 가지 구성 요소를 통합합니다.

Result: HDR 메커니즘은 수렴 속도와 정책 안정성을 크게 개선하며, 고품질 협력 정책을 학습하도록 에이전트를 안내합니다.

Conclusion: HDR은 교통 효율성과 안전성을 효과적으로 균형 잡힌 협력 정책을 학습하는 데 기여합니다.

Abstract: In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.

</details>


### [2] [Agentifying Agentic AI](https://arxiv.org/abs/2511.17332)
*Virginia Dignum,Frank Dignum*

Main category: cs.AI

TL;DR: 이 논문은 에이전틱 AI를 구성하기 위한 인지, 협력 및 거버넌스 모델의 필요성을 강조하며, AAMAS 커뮤니티의 개념 도구들을 통해 이를 실현할 수 있는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI는 시스템에 지속적인 자율성, 추론 및 상호작용 능력을 부여하고자 한다.

Method: 자율 에이전트 및 다중 에이전트 시스템(AAMAS) 커뮤니티에서 개발된 BDI 아키텍처, 통신 프로토콜, 메커니즘 설계 및 제도 모델링과 같은 개념 도구들을 활용하고, 데이터 기반 접근 방식을 구조화된 추론 및 조정 모델과 정렬시킨다.

Result: 이러한 방법론을 통해, 능력 있고 유연할 뿐만 아니라 투명하고 협력적이며 책임 있는 에이전틱 시스템으로 나아갈 수 있는 경로를 제시한다.

Conclusion: 결과적으로, 형식 이론과 실용적 자율성 간의 다리 역할을 하는 에이전시 관점을 제공한다.

Abstract: Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.

</details>


### [3] [MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists](https://arxiv.org/abs/2511.16997)
*Qingbin Zeng,Bingbing Fan,Zhiyu Chen,Sijian Ren,Zhilun Zhou,Xuhua Zhang,Yuanyi Zhen,Fengli Xu,Yong Li,Tie-Yan Liu*

Main category: cs.AI

TL;DR: AI 과학자의 출현은 과학 연구의 자동화를 위한 놀라운 잠재력을 보여주고 있다. 그러나 현재의 접근 방식은 과학적 발견을 고립된 최적화 과정으로 간주하여 지식 생산이 본질적으로 사회적 및 역사적 노력임을 간과하고 있다.


<details>
  <summary>Details</summary>
Motivation: 현재의 과학적 발견 접근 방식이 지식 생산의 사회적이고 역사적인 측면을 간과하고 있기 때문에, 이를 개선하고자 하였다.

Method: MirrorMind라는 계층적 인지 아키텍처를 도입하였으며, 이는 이중 메모리 표현을 통합하여 개인 수준, 분야 수준, 그리고 학제 간 수준의 세 가지 레벨로 구성된다.

Result: MirrorMind는 개인의 인지 깊이와 집단의 학문적 넓이를 통합함으로써 단순한 사실 검색을 넘어서 구조적이고 개인화된 통찰력을 생성하는 과학적 추론으로 나아간다.

Conclusion: 우리는 MirrorMind를 통해 AI 과학자가 개별 메모리를 유연하게 접근하여 독특한 관점이나 집단 구조를 통해 추론할 수 있도록 메모리 저장과 행동 실행을 분리할 수 있다는 점을 강조하였다.

Abstract: The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.

</details>


### [4] [Budget-Aware Tool-Use Enables Effective Agent Scaling](https://arxiv.org/abs/2511.17006)
*Tengxiao Liu,Zifeng Wang,Jin Miao,I-Hung Hsu,Jun Yan,Jiefeng Chen,Rujun Han,Fangyuan Xu,Yanfei Chen,Ke Jiang,Samira Daruki,Yi Liang,William Yang Wang,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

TL;DR: 대형 언어 모델에서 테스트 시간 컴퓨테이션을 확장하여 성능을 개선하는 방법을 다루며, 웹 검색 에이전트에 초점을 맞춘 예산 인식 기반의 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 도구 보강 에이전트의 성능을 개선하기 위해, 단순한 도구 호출 예산의 확대는 성능 향상에 실패한다는 점을 발견하였다.

Method: 예산 추적기라는 경량 플러그인을 도입하고, BATS라는 고급 프레임워크를 개발하여 예산 인식에 따라 계획 및 검증 전략을 동적으로 조정한다.

Result: 예산 인식 방법이 더 유리한 확장 곡선을 생성하고, 비용-성능 파레토 경계를 밀어내는 것을 보았다.

Conclusion: 이 연구는 도구 보강 에이전트의 확장에 대한 보다 투명하고 원리 기반의 이해를 제공한다.

Abstract: Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only "thinking" in tokens but also "acting" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack "budget awareness" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to "dig deeper" on a promising lead or "pivot" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.

</details>


### [5] [The Belief-Desire-Intention Ontology for modelling mental reality and agency](https://arxiv.org/abs/2511.17162)
*Sara Zuppiroli,Carmelo Fabio Longo,Anna Sofia Lippolis,Rocco Paolillo,Lorenzo Giammei,Miguel Ceriani,Francesco Poggi,Antonio Zinilli,Andrea Giovanni Nuzzolese*

Main category: cs.AI

TL;DR: BDI 모델의 한계를 극복하기 위해 형식적 BDI 온톨로지를 제시하며, 이는 에이전트의 인지 구조를 모듈화하여 표현한다.


<details>
  <summary>Details</summary>
Motivation: BDI 모델이 인공지능과 인지 과학에서 합리적 에이전시를 표현하는 중요한 요소로 자리잡고 있지만, 구조화되고 의미론적으로 상호운용 가능한 지식 표현에의 통합은 제한적이다.

Method: BDI 온톨로지는 신념, 욕구, 의도 및 이들의 동적 상관관계를 포착하는 모듈식 온톨로지 디자인 패턴(ODP)으로 설계되었다. 이 온톨로지는 기초 온톨로지 및 모듈 설계의 최선의 관행과 일치하여 의미론적 정확성과 재사용성을 보장한다.

Result: 온톨로지를 대형 언어 모델(LLM)과 결합하거나, Semas 추론 플랫폼에 통합함으로써 해당 온톨로지의 적용 가능성을 입증하였다. 이 두 가지 실험은 온톨로지의 기여가 추론적 일관성과 일관성에 미치는 영향을 평가하고, RDF 트리플과 에이전트의 정신 상태 간의 양방향 흐름을 가능하게 했다.

Conclusion: BDI 온톨로지는 선언적 및 절차적 지능 간의 개념적 및 운영적 다리 역할을 하여, 설명 가능하고 의미론적으로 상호운용 가능한 다중 에이전트 및 신경-상징 시스템의 길을 제시한다.

Abstract: The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.

</details>


### [6] [MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward](https://arxiv.org/abs/2511.17165)
*Kesheng Chen,Wenjian Luo,Bang Zhang,Zeping Yin,Zipeng Ye*

Main category: cs.AI

TL;DR: 상태 간섭이 있는 에피소드 보상이 있는 다중 에이전트 강화 학습의 어려움을 해결하는 새로운 보상 기법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 에피소드 보상이 강화 학습에서 큰 도전 과제가 되고 있다.

Method: Mutual Intrinsic Reward (MIR)라는 새로운 전략을 도입하여 팀 상태에 영향을 미치는 행동을 탐색하도록 유도한다.

Result: MIR를 사용한 팀 탐색이 알고리즘 성능을 향상시키는 것을 보여주는 실험 결과를 제시한다.

Conclusion: MIR은 에피소드 보상과 같은 극도로 희소한 보상을 가진 다중 에이전트 강화 학습에 효과적인 해법을 제공한다.

Abstract: Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.

</details>


### [7] [Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism](https://arxiv.org/abs/2511.17198)
*Kaiyu Li,Jiayu Wang,Zhi Wang,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.AI

TL;DR: 이 연구에서는 계층적 작업 추상화 메커니즘(HTAM)을 중심으로 하는 새로운 에이전트 설계 프레임워크를 제안하며, 이를 통해 복잡한 지리 공간 분석을 위한 다중 에이전트 시스템인 EarthAgent를 구현한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 LLM 기반 에이전트가 전문 분야에서의 엄격한 작업 구조를 요구하는 상황에서 어려움을 겪고 있어, 이를 해결하기 위한 새로운 접근법이 필요하다.

Method: 계층적 작업 추상화 메커니즘(HTAM)을 통해 사회적 역할 모방을 넘어서, 다중 에이전트 시스템을 논리적 계층 구조로 구성하여 복잡한 문제를 순차적인 층으로 분해한다.

Result: EarthAgent가 기존의 다양한 단일 및 다중 에이전트 시스템보다 뛰어난 성능을 보여주며, GeoPlan-bench라는 종합 벤치마크를 통해 복잡한 지리 공간 계획 능력을 평가한다.

Conclusion: 에이전트 아키텍처를 도메인의 본질적인 작업 구조와 일치시키는 것은 견고하고 신뢰할 수 있는 전문 자율 시스템 구축을 위한 중요한 단계임을 입증했다.

Abstract: LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.

</details>


### [8] [That's not natural: The Impact of Off-Policy Training Data on Probe Performance](https://arxiv.org/abs/2511.17408)
*Nathalie Kirch,Samuel Dower,Adrians Skapars,Ekdeep Singh Lubana,Dmitrii Krasheninnikov*

Main category: cs.AI

TL;DR: 본 논문은 LLM의 행동을 모니터링하기 위해 프로빙 기법의 효능을 평가하며, 합성 데이터와 오프-정책 데이터가 프로브 일반화에 미치는 영향을 분석한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 부정확한 행동 감지를 위해 효과적인 모니터링 기법이 필요하다.

Method: 여덟 가지 LLM 행동에 대해 합성 및 오프-정책 데이터를 사용하여 프로브 성능을 평가하고, 여러 LLM을 대상으로 테스트를 실시한다.

Result: 합성 및 오프-정책 데이터에 따른 응답 생성 전략이 프로브 성능에 중요한 영향을 미친다는 것을 발견하였으며, 책임 있는 행동을 유도하는 테스트 세트로의 일반화가 성공 예측과 연관이 있다.

Conclusion: 오프-정책 데이터에서 온-정책 데이터로의 일반화에 실패할 수 있으며, 데이터 도메인 전이가 성능 저하를 초래한다는 결과를 강조한다.

Abstract: Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.

</details>


### [9] [SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception](https://arxiv.org/abs/2511.17461)
*Jiaxi Liu,Chengyuan Ma,Hang Zhou,Weizhe Tang,Shixiao Liang,Haoyang Ding,Xiaopeng Li,Bin Ran*

Main category: cs.AI

TL;DR: 본 논문은 동적 교통 환경에서의 협력적 인식(CP)의 한계를 극복하기 위한 SRA-CP 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 CP 접근법은 주행 안전과 무관한 대량의 인식 데이터를 전송해야 하며, 이는 통신 대역폭을 초과합니다. 또한 대부분의 CP 프레임워크는 미리 정의된 통신 파트너에 의존하여 동적 교통 환경에 적합하지 않습니다.

Method: SRA-CP는 연결된 에이전트가 가벼운 인식 커버리지 요약을 지속적으로 브로드캐스트하고, 위험 관련 블라인드 존이 감지될 때만 목표 지향적인 협력을 시작하는 분산 프로토콜을 도입합니다. 각 CV는 국소적으로 차폐의 영향을 평가하고 협력이 필요한지를 판단합니다.

Result: SRA-CP는 공공 데이터셋에서 여러 대표적인 기준선에 대해 평가되었으며, 안전에 중요한 객체에 대해 1% 미만의 평균 정밀도(AP) 손실을 기록하면서도 통신 대역폭의 20%만 사용했습니다. 또한, 기존의 위험 인식을 포함하지 않는 선택적 CP 방법보다 15%의 인식 성능 개선을 보였습니다.

Conclusion: SRA-CP는 안전 비판적 콘텐츠를 우선시하며 대역폭 제약에 적응하는 정보 교환을 통해 CP의 효율성을 향상시킵니다.

Abstract: Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [10] [AutoBackdoor: Automating Backdoor Attacks via LLM Agents](https://arxiv.org/abs/2511.16709)
*Yige Li,Zhe Li,Wei Zhao,Nay Myat Min,Hanxun Huang,Xingjun Ma,Jun Sun*

Main category: cs.CR

TL;DR: 이 연구에서는 백도어 공격을 시뮬레이션하고 모델의 복원력을 평가하기 위한 자동화된 백도어 주입 프레임워크인 AutoBackdoor를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)의 안전한 배포에 대한 백도어 공격의 중대한 위협을 해결하고, 현대 방어 강건성을 체계적으로 평가할 필요성이 커지고 있다.

Method: AutoBackdoor는 트리거 생성, 오염 데이터 구축, 모델 미세 조정을 자동 에이전트 기반 파이프라인을 통해 자동화하는 일반 프레임워크이다.

Result: AutoBackdoor는 90% 이상의 공격 성공률을 달성하며 소량의 오염 샘플로도 효과적인 공격을 수행할 수 있음을 입증하였다.

Conclusion: 기존의 방어 기술이 이러한 공격을 완화하는 데 실패하는 경우가 많으며, 본 연구에서 다룬 에이전트 주도 위협에 대한 보다 엄격하고 적응 가능한 평가 기술의 필요성을 강조한다.

Abstract: Backdoor attacks pose a serious threat to the secure deployment of large language models (LLMs), enabling adversaries to implant hidden behaviors triggered by specific inputs. However, existing methods often rely on manually crafted triggers and static data pipelines, which are rigid, labor-intensive, and inadequate for systematically evaluating modern defense robustness. As AI agents become increasingly capable, there is a growing need for more rigorous, diverse, and scalable \textit{red-teaming frameworks} that can realistically simulate backdoor threats and assess model resilience under adversarial conditions. In this work, we introduce \textsc{AutoBackdoor}, a general framework for automating backdoor injection, encompassing trigger generation, poisoned data construction, and model fine-tuning via an autonomous agent-driven pipeline. Unlike prior approaches, AutoBackdoor uses a powerful language model agent to generate semantically coherent, context-aware trigger phrases, enabling scalable poisoning across arbitrary topics with minimal human effort. We evaluate AutoBackdoor under three realistic threat scenarios, including \textit{Bias Recommendation}, \textit{Hallucination Injection}, and \textit{Peer Review Manipulation}, to simulate a broad range of attacks. Experiments on both open-source and commercial models, including LLaMA-3, Mistral, Qwen, and GPT-4o, demonstrate that our method achieves over 90\% attack success with only a small number of poisoned samples. More importantly, we find that existing defenses often fail to mitigate these attacks, underscoring the need for more rigorous and adaptive evaluation techniques against agent-driven threats as explored in this work. All code, datasets, and experimental configurations will be merged into our primary repository at https://github.com/bboylyg/BackdoorLLM.

</details>


### [11] [Password Strength Analysis Through Social Network Data Exposure: A Combined Approach Relying on Data Reconstruction and Generative Models](https://arxiv.org/abs/2511.16716)
*Maurizio Atzori,Eleonora Calò,Loredana Caruccio,Stefano Cirillo,Giuseppe Polese,Giandomenico Solimando*

Main category: cs.CR

TL;DR: 비밀번호가 여전히 주요한 보안 방어 수단이지만, 사용자는 기억하기 쉬운 비밀번호를 자주 사용하여 보안 위험이 증가하고 있다. 이 논의 논문에서는 비밀번호 강도 평가를 개선하기 위해 설계된 데이터 복원 도구인 SODA ADVANCE를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 비밀번호 사용의 일반적인 경향과 전통적인 비밀번호 강도 평가 방법의 비효율성을 개선하고자 하였다.

Method: SODA ADVANCE는 소셜 미디어 플랫폼을 포함한 여러 출처에서 공개적으로 사용할 수 있는 데이터를 활용하여 비밀번호 강도를 평가하는 전문 모듈을 통합하였다.

Result: 100명의 실제 사용자와 진행한 실험 평가 결과, LLM이 사용자 프로필에 따라 정의된 강력하고 개인화된 비밀번호를 생성할 수 있음을 보여주었다.

Conclusion: LLM은 사용자 프로필 데이터를 고려할 때 비밀번호 평가에서 효과적이라는 사실이 입증되었다.

Abstract: Although passwords remain the primary defense against unauthorized access, users often tend to use passwords that are easy to remember. This behavior significantly increases security risks, also due to the fact that traditional password strength evaluation methods are often inadequate. In this discussion paper, we present SODA ADVANCE, a data reconstruction tool also designed to enhance evaluation processes related to the password strength. In particular, SODA ADVANCE integrates a specialized module aimed at evaluating password strength by leveraging publicly available data from multiple sources, including social media platforms. Moreover, we investigate the capabilities and risks associated with emerging Large Language Models (LLMs) in evaluating and generating passwords, respectively. Experimental assessments conducted with 100 real users demonstrate that LLMs can generate strong and personalized passwords possibly defined according to user profiles. Additionally, LLMs were shown to be effective in evaluating passwords, especially when they can take into account user profile data.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected](https://arxiv.org/abs/2511.16767)
*Haotian Xu,Yuning You,Tengfei Ma*

Main category: cs.LG

TL;DR: 이 연구는 그래프 구조 인코딩 전략이 대형 언어 모델(LLM)의 성능에 미치는 영향을 조사하며, 기존의 구조적 전제가 LLM 기반 그래프 추론에 필수적이지 않음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 그래프는 의미 콘텐츠와 관계 구조를 통합적으로 표현할 수 있어 분자의 모델링, 인용 네트워크 및 사회적 그래프와 같은 분야에 적합하다. 대형 언어 모델(LLM)은 자연어 이해 및 크로스 모달 신호 통합에서 뛰어난 성능을 보여 그래프 추론 가능성에 대한 관심이 높아지고 있다.

Method: 이 연구는 그래프 구조 인코딩을 위한 다양한 전략이 텍스트 속성 그래프에 대한 LLM 성능에 미치는 영향을 조사하였다. 시스템적 실험을 통해 결과를 도출하였다.

Result: LLM은 노드의 텍스트 설명만으로도 강한 성능을 발휘하며, 대부분의 구조적 인코딩 전략이 미미하거나 부정적인 이점을 제공한다는 것을 밝혀냈다.

Conclusion: 강력한 언어 모델이 관련될 때 구조적 사전 정보가 불필요하거나 심지어 역효과를 낼 수 있음을 보여준다. 이는 전통적인 그래프 학습 패러다임에서의 중요한 변화이며, LLM 시대에 구조 표현 및 활용 방식을 재고할 필요성을 강조한다.

Abstract: Graphs provide a unified representation of semantic content and relational structure, making them a natural fit for domains such as molecular modeling, citation networks, and social graphs. Meanwhile, large language models (LLMs) have excelled at understanding natural language and integrating cross-modal signals, sparking interest in their potential for graph reasoning. Recent work has explored this by either designing template-based graph templates or using graph neural networks (GNNs) to encode structural information. In this study, we investigate how different strategies for encoding graph structure affect LLM performance on text-attributed graphs. Surprisingly, our systematic experiments reveal that: (i) LLMs leveraging only node textual descriptions already achieve strong performance across tasks; and (ii) most structural encoding strategies offer marginal or even negative gains. We show that explicit structural priors are often unnecessary and, in some cases, counterproductive when powerful language models are involved. This represents a significant departure from traditional graph learning paradigms and highlights the need to rethink how structure should be represented and utilized in the LLM era. Our study is to systematically challenge the foundational assumption that structure is inherently beneficial for LLM-based graph reasoning, opening the door to new, semantics-driven approaches for graph learning.

</details>


### [13] [GCL-OT: Graph Contrastive Learning with Optimal Transport for Heterophilic Text-Attributed Graphs](https://arxiv.org/abs/2511.16778)
*Yating Ren,Yikun Ban,Huobin Tan*

Main category: cs.LG

TL;DR: 이 논문은 텍스트 속성을 가진 그래프에서의 구조-텍스트 대조 학습의 유용성을 제안하며, 특히 이질적인 그래프에서 그 한계를 극복하기 위한 새로운 방안을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 텍스트 속성을 가진 그래프에서의 구조-텍스트 대조 학습의 성능을 개선하고, 이질적 그래프에의 적용 가능성을 높이기 위해.

Method: GCL-OT라는 새로운 그래프 대조 학습 프레임워크를 제안하며, 각 이질성 유형에 맞는 맞춤형 메커니즘을 갖추었다.

Result: GCL-OT는 여섯 개의 기준에서 기존의 최첨단 방법들을 일관되게 초월하는 성능을 보였다.

Conclusion: GCL-OT는 상호 정보 경계와 베이즈 오류 보장을 향상시킬 수 있음을 이론적으로 분석했으며, 그 효율성과 강건성을 검증하였다.

Abstract: Recently, structure-text contrastive learning has shown promising performance on text-attributed graphs by leveraging the complementary strengths of graph neural networks and language models. However, existing methods typically rely on homophily assumptions in similarity estimation and hard optimization objectives, which limit their applicability to heterophilic graphs. Although existing methods can mitigate heterophily through structural adjustments or neighbor aggregation, they usually treat textual embeddings as static targets, leading to suboptimal alignment. In this work, we identify the multi-granular heterophily in text-attributed graphs, including complete heterophily, partial heterophily, and latent homophily, which makes structure-text alignment particularly challenging due to mixed, noisy, and missing semantic correlations. To achieve flexible and bidirectional alignment, we propose GCL-OT, a novel graph contrastive learning framework with optimal transport, equipped with tailored mechanisms for each type of heterophily. Specifically, for partial heterophily, we design a RealSoftMax-based similarity estimator to emphasize key neighbor-word interactions while easing background noise. For complete heterophily, we introduce a prompt-based filter that adaptively excludes irrelevant noise during optimal transport alignment. Furthermore, we incorporate OT-guided soft supervision to uncover potential neighbors with similar semantics, enhancing the learning of latent homophily. Theoretical analysis shows that GCL-OT can improve the mutual information bound and Bayes error guarantees. Extensive experiments on nine benchmarks show that GCL-OT consistently outperforms state-of-the-art methods, verifying its effectiveness and robustness.

</details>


### [14] [A Vector Symbolic Approach to Multiple Instance Learning](https://arxiv.org/abs/2511.16795)
*Ehsan Ahmed Dhrubo,Mohammad Mahmudul Alam,Edward Raff,Tim Oates,James Holt*

Main category: cs.LG

TL;DR: 본 연구는 다중 인스턴스 학습(MIL)에서의 기존 접근 방식을 개선한 새로운 프레임워크를 제안하며, 이를 통해 MIL의 논리적 제약조건을 준수하며 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: MIL 작업은 인스턴스가 하나라도 양성이면 가방도 양성으로 레이블링되는 엄격한 논리적 제약조건을 부과합니다. 그러나 많은 딥 러닝 기반 MIL 접근법이 이 제약을 위반하고 있어 성능 메트릭이 부풀려지고 일반화 성능이 저하되는 문제를 해결하고자 합니다.

Method: 본 연구에서는 벡터 기호 아키텍처(VSA)를 기반으로 하는 새로운 MIL 프레임워크를 제안하며, 여기서 인스턴스와 개념을 거의 직교하는 고차원 벡터로 표현하고 분류 중 iff 제약을 시행하기 위해 대수적 연산을 사용합니다.

Result: 제안된 접근법은 상태-최첨단 성능을 달성하였으며, 표준 MIL 벤치마크와 의료 영상 데이터셋에서 기존 방법들을 초월함과 동시에 MIL 공식에 엄격히 따릅니다.

Conclusion: 이 연구는 기존의 학습된 휴리스틱에 의존하는 MIL 접근법에 대한 원칙적이고 해석 가능하며 효과적인 대안을 제공합니다.

Abstract: Multiple Instance Learning (MIL) tasks impose a strict logical constraint: a bag is labeled positive if and only if at least one instance within it is positive. While this iff constraint aligns with many real-world applications, recent work has shown that most deep learning-based MIL approaches violate it, leading to inflated performance metrics and poor generalization. We propose a novel MIL framework based on Vector Symbolic Architectures (VSAs), which provide a differentiable mechanism for performing symbolic operations in high-dimensional space. Our method encodes the MIL assumption directly into the model's structure by representing instances and concepts as nearly orthogonal high-dimensional vectors and using algebraic operations to enforce the iff constraint during classification. To bridge the gap between raw data and VSA representations, we design a learned encoder that transforms input instances into VSA-compatible vectors while preserving key distributional properties. Our approach, which includes a VSA-driven MaxNetwork classifier, achieves state-of-the-art results for a valid MIL model on standard MIL benchmarks and medical imaging datasets, outperforming existing methods while maintaining strict adherence to the MIL formulation. This work offers a principled, interpretable, and effective alternative to existing MIL approaches that rely on learned heuristics.

</details>


### [15] [ManifoldFormer: Geometric Deep Learning for Neural Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2511.16828)
*Yihang Fu,Lifang He,Qingyu Chen*

Main category: cs.LG

TL;DR: ManifoldFormer는 EEG 신호의 기하학적 구조를 학습하여 뇌 활동의 저차원 다양체로 제약하는 새로운 심층 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: EEG 기초 모델이 신경 역학의 기하학적 구조를 무시하고 일반적인 시계열로 처리하는 한계를 극복하고자 한다.

Method: Riemannian VAE, 기하학적 Transformer 및 신경 ODE를 활용하여 EEG 신호의 다양체 표현을 명확히 학습한다.

Result: 한 연구에서 최신 방법들에 비해 4.6-4.8% 향상된 정확도와 6.2-10.2% 향상된 Cohen's Kappa를 보였다.

Conclusion: 기하학적 접근은 신경 생리학적 원칙과 일치하는 의미 있는 신경 패턴을 드러내며, 효과적인 EEG 모델을 위한 기하학적 제약이 필수적임을 Establish하였다.

Abstract: Existing EEG foundation models mainly treat neural signals as generic time series in Euclidean space, ignoring the intrinsic geometric structure of neural dynamics that constrains brain activity to low-dimensional manifolds. This fundamental mismatch between model assumptions and neural geometry limits representation quality and cross-subject generalization. ManifoldFormer addresses this limitation through a novel geometric deep learning framework that explicitly learns neural manifold representations. The architecture integrates three key innovations: a Riemannian VAE for manifold embedding that preserves geometric structure, a geometric Transformer with geodesic-aware attention mechanisms operating directly on neural manifolds, and a dynamics predictor leveraging neural ODEs for manifold-constrained temporal evolution. Extensive evaluation across four public datasets demonstrates substantial improvements over state-of-the-art methods, with 4.6-4.8% higher accuracy and 6.2-10.2% higher Cohen's Kappa, while maintaining robust cross-subject generalization. The geometric approach reveals meaningful neural patterns consistent with neurophysiological principles, establishing geometric constraints as essential for effective EEG foundation models.

</details>


### [16] [Provably Minimum-Length Conformal Prediction Sets for Ordinal Classification](https://arxiv.org/abs/2511.16845)
*Zijian Zhang,Xinyu Chen,Yuanjie Shi,Liyuan Lillian Ma,Zifan Xu,Yan Yan*

Main category: cs.LG

TL;DR: 본 연구에서는 모델에 의존하지 않고 개별 인스턴스 수준에서 최적의 예측 구간을 제공하는 순서형 CP 방법을 제안하여 예측 효율성을 크게 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상 및 진단과 같은 고위험 애플리케이션에서 신뢰할 수 있는 불확실성 정량화가 필수적입니다.

Method: 본 연구는 순서형 분류를 최소 길이 커버링 문제로 공식화하고, 슬라이딩 윈도우 알고리즘을 개발하여 각 캘리브레이션 데이터에 대해 최적의 솔루션을 제공합니다.

Result: 제안된 방법은 네 개의 다양한 벤치마크 데이터세트에서 15%의 평균 예측 효율성 향상을 보여줍니다.

Conclusion: 제안된 방법은 기존 방법 대비 예측 효율성을 크게 개선합니다.

Abstract: Ordinal classification has been widely applied in many high-stakes applications, e.g., medical imaging and diagnosis, where reliable uncertainty quantification (UQ) is essential for decision making. Conformal prediction (CP) is a general UQ framework that provides statistically valid guarantees, which is especially useful in practice. However, prior ordinal CP methods mainly focus on heuristic algorithms or restrictively require the underlying model to predict a unimodal distribution over ordinal labels. Consequently, they provide limited insight into coverage-efficiency trade-offs, or a model-agnostic and distribution-free nature favored by CP methods. To this end, we fill this gap by propose an ordinal-CP method that is model-agnostic and provides instance-level optimal prediction intervals. Specifically, we formulate conformal ordinal classification as a minimum-length covering problem at the instance level. To solve this problem, we develop a sliding-window algorithm that is optimal on each calibration data, with only a linear time complexity in K, the number of label candidates. The local optimality per instance further also improves predictive efficiency in expectation. Moreover, we propose a length-regularized variant that shrinks prediction set size while preserving coverage. Experiments on four benchmark datasets from diverse domains are conducted to demonstrate the significantly improved predictive efficiency of the proposed methods over baselines (by 15% decrease on average over four datasets).

</details>


### [17] [PersonalizedRouter: Personalized LLM Routing via Graph-based User Preference Modeling](https://arxiv.org/abs/2511.16883)
*Zhongjie Dai,Tao Feng,Jiaxuan You*

Main category: cs.LG

TL;DR: 대규모 언어 모델(LLMs)의 다양성과 선택의 폭이 증가하면서 적절한 모델 선택이 어려워지고 있다. 이를 해결하기 위해, 우리는 사용자 프로파일을 모델링하고 상호작용 데이터를 이용해 개인화된 LLM 선택을 수행하는 PersonalizedRouter라는 그래프 기반 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 다양성과 성능, 비용, 응답 스타일에 대한 사용자 선호의 차이로 인해 적절한 LLM을 선택하는 데 어려움이 있음.

Method: PersonalizedRouter는 상호작용 데이터를 활용하여 개인화된 LLM 선택을 수행하며, 이를 위해 상호작용 데이터를 이종 그래프로 변환한다.

Result: PersonalizedRouter는 기존 LLM 선택 방법보다 유의미하게 우수한 성능을 보였고, 두 가지 시뮬레이션 전략에서 각각 15.38% 및 9.83% 높은 성능을 기록하였다.

Conclusion: PersonalizedRouter는 새로운 사용자 및 LLM에 적응할 때 강력한 몇 샷 일반화를 보여줌.

Abstract: The growing number of Large Language Models (LLMs) with diverse capabilities and response styles provides users with a wider range of choices, which presents challenges in selecting appropriate LLMs, as user preferences vary in terms of performance, cost, and response style. Current LLM selection methods typically optimize for a single fixed objective, such as performance, cost, or a trade-off between them, and fail to learn individual user preferences from interaction data. To address these limitations, we propose PersonalizedRouter, a graph-based framework that models diverse user profiles and performs personalized LLM selection by leveraging interaction data that includes task context, queries, candidate LLMs, and user decisions. To capture contextual information between user queries and optimal LLMs, PersonalizedRouter converts the interaction data into a heterogeneous graph, where the relationships between different types of nodes are represented by edges. To evaluate adaptability across users, we design two strategies: the multi-cost-efficiency simulation strategy and the LLM-as-a-Judge strategy. In addition, we construct PersonaRoute-Bench, a large-scale benchmark with 1,000 simulated users and 10 LLMs. Experimental results show that PersonalizedRouter significantly outperforms existing LLM selection methods and surpasses the strongest methods by a large margin of 15.38% and 9.83% under two simulation strategies. On the PersonaRoute-Bench with 1,000 users, it further surpasses the best methods by 16.19% and 59.69% while maintaining higher efficiency. Moreover, PersonalizedRouter demonstrates strong few-shot generalization, achieving 64.81% and 85.80% of the fully trained model's performance when adapting to new users and new LLMs.

</details>


### [18] [ToC: Tree-of-Claims Search with Multi-Agent Language Models](https://arxiv.org/abs/2511.16972)
*Shuyang Yu,Jianan Liang,Hui Hu*

Main category: cs.LG

TL;DR: 특허 청구 항목 최적화는 혁신성과 법적 범위 유지 간의 미세한 균형을 요구하는 비판적 과제입니다. 본 논문에서는 Monte Carlo Tree Search (MCTS)와 협업 다중 에이전트를 통합한 Tree of Claims (ToC) 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 특허 청구 항목 작성은 수작업으로 진행할 경우 노동 집약적이고 비용이 많이 들며 일관성이 부족합니다. 기존의 대형 언어 모델(LLM)은 세밀한 청구 항목 수정에 필수적인 구조적 사고 과정을 결여하고 있습니다.

Method: ToC는 청구 항목 편집을 안내 검색 문제로 재정의하며, LLM 기반의 EditorAgent와 구조적 사고 분석을 통해 특허 심사원을 모방하는 ExaminerAgent로 구성됩니다. 이를 통해 ToC는 혁신성, 범위 유지, 의미적 일관성을 공동 최적화합니다.

Result: 1145개의 청구 항목 벤치마크 실험 결과, ToC는 제로샷 및 적은 샷 상황에서 표준 LLM보다 평균 8%의 점수 개선을 달성하였고, 특정 사례에서는 9%까지 개선되었습니다.

Conclusion: ToC는 선진 LLM의 사고 능력과 전략적 MCTS 계획을 효과적으로 결합한 투명하고 제어 가능한 방법론을 구축하였습니다. 소스 코드는 https://github.com/ysy2003/ToC에서 사용할 수 있습니다.

Abstract: Optimizing patent claims is a critical yet challenging task, demanding careful balance between maximizing novelty and preserving legal scope. Manual claim drafting is labor-intensive, costly, and inherently inconsistent, while conventional Large Language Models (LLMs) often lack the structured, iterative reasoning essential for precise claim refinement. To address these challenges, we introduce Tree of Claims (ToC), an innovative framework that redefines claim editing as a guided search problem. ToC synergistically integrates Monte Carlo Tree Search (MCTS) with a collaborative multi-agent system, comprising an LLM-based EditorAgent that proposes contextually grounded edits, and an ExaminerAgent that mimics patent examiner critiques through structured, chain-of-thought analyses of novelty and prior art disclosure. Driven by a carefully designed multi-objective reward function, ToC jointly optimizes novelty, scope retention, and semantic coherence. Experimental evaluation on a benchmark of 1145 claims demonstrates that ToC significantly outperforms standard LLMs in zero-shot and few-shot scenarios, achieving an average composite score improvement of 8\%, and up to 9\% in certain cases. Extensive experiments, including detailed ablation studies, validate ToC's efficacy in generating superior, legally robust claim revisions. Overall, ToC establishes a transparent, controllable, and interpretable methodology that effectively bridges advanced LLM reasoning capabilities with strategic MCTS planning for structured patent claim optimization.The source code is available at https://github.com/ysy2003/ToC.

</details>


### [19] [Why Do Language Model Agents Whistleblow?](https://arxiv.org/abs/2511.17085)
*Kushal Agrawal,Frank Xiao,Guido Bergman,Asa Cooper Stickland*

Main category: cs.LG

TL;DR: LLM의 사용으로 새로운 정렬 교육 방식이 나타나며, 모델이 사용자의 명령 없이 외부에 의심스러운 행동을 보고하는 경향이 나타난다. 이 연구에서는 다양한 상황에서 모델의 고발 행동을 평가하기 위해 시작된 시나리오를 연구한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 도구 사용 에이전트로 배치됨에 따라 정렬 교육이 새로운 방식으로 나타나는 것을 이해하기 위해.

Method: 다양하고 현실적인 고발 시나리오 평가 모음을 도입하여 모델의 고발 행동을 평가한다.

Result: 모델들 간 고발의 빈도가 크게 다르고, 작업의 복잡성이 낮아지면 고발 경향이 증가하며, 도덕적으로 행동하도록 유도할 경우 고발 비율이 높아진다.

Conclusion: 비교 가능한 이전 연구보다 낮은 평가 인식을 보이는 검증을 통해 데이터셋의 강건성을 확인하였다.

Abstract: The deployment of Large Language Models (LLMs) as tool-using agents causes their alignment training to manifest in new ways. Recent work finds that language models can use tools in ways that contradict the interests or explicit instructions of the user. We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge. We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior. Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates. Additionally, we verify the robustness of our dataset by testing for model evaluation awareness, and find that both black-box methods and probes on model activations show lower evaluation awareness in our settings than in comparable previous work.

</details>


### [20] [Automobile demand forecasting: Spatiotemporal and hierarchical modeling, life cycle dynamics, and user-generated online information](https://arxiv.org/abs/2511.17275)
*Tom Nahrendorf,Stefan Minner,Helfried Binder,Richard Zinck*

Main category: cs.LG

TL;DR: 프리미엄 자동차 제조업체는 제품 다양성, 희소한 데이터, 변동성 있는 시장 환경으로 인해 복잡한 수요 예측 과제에 직면해 있다.


<details>
  <summary>Details</summary>
Motivation: 프리미엄 자동차 제조업체들은 고품질 제품에 대한 수요를 보다 정확하게 예측할 필요가 있다.

Method: 이 연구는 독일의 프리미엄 제조업체 데이터를 통해 다중 제품, 다중 시장, 다중 수준의 자동차 수요 예측을 수행하며, LightGBM 모델의 앙상블과 혼합 정수 선형 프로그래밍 접근 방식을 사용하여 포인트 및 확률적 예측을 결합한다.

Result: 결과는 시공간 의존성과 반올림 편향이 예측 정확도에 미치는 중대한 영향을 강조하며, 운영적 실행 가능성을 위한 정수 예측의 중요성을 부각시킨다.

Conclusion: 단기 수요는 생애 주기 성숙도, 자기 회귀 모멘텀, 운영 신호에 의해 형성된 반응적이며, 중기 수요는 온라인 참여, 계획 목표, 경쟁 지표와 같은 예측적 동인을 반영한다.

Abstract: Premium automotive manufacturers face increasingly complex forecasting challenges due to high product variety, sparse variant-level data, and volatile market dynamics. This study addresses monthly automobile demand forecasting across a multi-product, multi-market, and multi-level hierarchy using data from a German premium manufacturer. The methodology combines point and probabilistic forecasts across strategic and operational planning levels, leveraging ensembles of LightGBM models with pooled training sets, quantile regression, and a mixed-integer linear programming reconciliation approach. Results highlight that spatiotemporal dependencies, as well as rounding bias, significantly affect forecast accuracy, underscoring the importance of integer forecasts for operational feasibility. Shapley analysis shows that short-term demand is reactive, shaped by life cycle maturity, autoregressive momentum, and operational signals, whereas medium-term demand reflects anticipatory drivers such as online engagement, planning targets, and competitive indicators, with online behavioral data considerably improving accuracy at disaggregated levels.

</details>


### [21] [Convergence and stability of Q-learning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2511.17351)
*Massimiliano Manenti,Andrea Iannelli*

Main category: cs.LG

TL;DR: 위계 강화 학습은 의사 결정 문제의 시간적 구조를 효과적으로 포착하고 지속적인 학습 능력을 향상시키는 등의 장점을 제시하지만, 이론적 보장이 실제에 뒤처져 있다. 본 논문에서는 귀족 Q-학습 방안을 제안하고, 연관된 업데이트가 수렴하고 안정적인 조건을 조사한다. 확률 근사 이론과 ODE 방법을 활용하여 귀족 Q-학습의 수렴 및 안정성 특성을 진술하는 정리를 제시한다. 이는 귀족 RL에 맞춤화된 원칙적인 수렴 및 안정성 분석을 제공한다. 또한 업데이트가 적절하게 정의된 게임의 균형으로 해석될 수 있는 점으로 수렴함을 보여주어 계층적 RL에 대한 게임 이론적 접근을 열어준다. 마지막으로 귀족 Q-학습 알고리즘에 기반한 실험은 이론에서 예상한 결과를 지원한다.


<details>
  <summary>Details</summary>
Motivation: 위계 강화 학습의 이론적 보장을 실질적으로 개선하고 효율성을 높이는 방법을 찾기 위한 동기.

Method: 귀족 Q-학습 방안을 제안하고, 확률 근사 이론과 ODE 방법을 활용하여 이론적 정리를 도출.

Result: 귀족 Q-학습의 수렴 및 안정성 특성을 분석하여 게임 이론적 접근의 가능성을 보여준다.

Conclusion: 귀족 Q-학습 알고리즘의 실험 결과가 이론적으로 예상한 결과를 지지함.

Abstract: Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.

</details>


### [22] [Self-Supervised Learning by Curvature Alignment](https://arxiv.org/abs/2511.17426)
*Benyamin Ghojogh,M. Hadi Sepanj,Paul Fieguth*

Main category: cs.LG

TL;DR: CurvSSL은 곡률 정규화 자기 지도 학습 프레임워크로, 데이터 매니폴드의 지역 기하학을 고려하여 특징을 조정함으로써 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 비대조적 자기 지도 학습 방법들이 데이터 매니폴드의 지역 기하학을 무시하고 있다는 점에서 개선이 필요합니다.

Method: CurvSSL은 곡률 기반 정규화 기법을 추가하여 두 뷰 인코더-프로젝터 아키텍처를 유지하며, 코사인 상호작용을 통해 곡률 점수를 정의합니다.

Result: MNIST와 CIFAR-10 데이터셋에서 실험한 결과, CurvSSL은 Barlow Twins와 VICReg에 비해 경쟁력 있거나 향상된 선형 평가 성능을 보여줍니다.

Conclusion: 지역 기하학을 명시적으로 형성하는 것은 순수하게 통계적 자기 지도 학습 정규화기법에 대한 간단하고 효과적인 보완책임을 나타냅니다.

Abstract: Self-supervised learning (SSL) has recently advanced through non-contrastive methods that couple an invariance term with variance, covariance, or redundancy-reduction penalties. While such objectives shape first- and second-order statistics of the representation, they largely ignore the local geometry of the underlying data manifold. In this paper, we introduce CurvSSL, a curvature-regularized self-supervised learning framework, and its RKHS extension, kernel CurvSSL. Our approach retains a standard two-view encoder-projector architecture with a Barlow Twins-style redundancy-reduction loss on projected features, but augments it with a curvature-based regularizer. Each embedding is treated as a vertex whose $k$ nearest neighbors define a discrete curvature score via cosine interactions on the unit hypersphere; in the kernel variant, curvature is computed from a normalized local Gram matrix in an RKHS. These scores are aligned and decorrelated across augmentations by a Barlow-style loss on a curvature-derived matrix, encouraging both view invariance and consistency of local manifold bending. Experiments on MNIST and CIFAR-10 datasets with a ResNet-18 backbone show that curvature-regularized SSL yields competitive or improved linear evaluation performance compared to Barlow Twins and VICReg. Our results indicate that explicitly shaping local geometry is a simple and effective complement to purely statistical SSL regularizers.

</details>


### [23] [Multi-Agent Pointer Transformer: Seq-to-Seq Reinforcement Learning for Multi-Vehicle Dynamic Pickup-Delivery Problems](https://arxiv.org/abs/2511.17435)
*Zengyu Zou,Jingyuan Wang,Yixuan Huang,Junjie Wu*

Main category: cs.LG

TL;DR: 이 논문은 협력적인 다중 차량 동적 픽업 및 배송 문제(MVDPDPSR)에 대해 다루고, 시퀀스-투-시퀀스 기반의 중앙 집중식 의사결정 프레임워크인 다중 에이전트 포인터 변환기(MAPT)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 차량 동적 픽업 및 배송 문제는 차량 경로 문제의 확장으로, 주문형 배송과 같은 시나리오에 널리 적용된다.

Method: MAPT 프레임워크는 Transformer Encoder를 사용하여 엔티티 표현을 추출하고, Transformer Decoder와 Pointer Network를 결합하여 자가 회귀 방식으로 공동 행동 시퀀스를 생성하며, 관계 인식 주의(attention) 모듈을 도입하여 엔티티 간의 관계를 포착한다.

Result: 8개의 데이터 세트에서 실험을 수행한 결과, MAPT는 기존의 기준 방법들에 비해 성능에서 크게 우수하며, 고전적인 운영 연구 방법들에 비해 상당한 계산 시간상의 이점을 보였다.

Conclusion: MAPT는 다중 차량의 동적 환경에서의 의사결정 문제를 효과적으로 해결하는 혁신적인 접근법을 제안한다.

Abstract: This paper addresses the cooperative Multi-Vehicle Dynamic Pickup and Delivery Problem with Stochastic Requests (MVDPDPSR) and proposes an end-to-end centralized decision-making framework based on sequence-to-sequence, named Multi-Agent Pointer Transformer (MAPT). MVDPDPSR is an extension of the vehicle routing problem and a spatio-temporal system optimization problem, widely applied in scenarios such as on-demand delivery. Classical operations research methods face bottlenecks in computational complexity and time efficiency when handling large-scale dynamic problems. Although existing reinforcement learning methods have achieved some progress, they still encounter several challenges: 1) Independent decoding across multiple vehicles fails to model joint action distributions; 2) The feature extraction network struggles to capture inter-entity relationships; 3) The joint action space is exponentially large. To address these issues, we designed the MAPT framework, which employs a Transformer Encoder to extract entity representations, combines a Transformer Decoder with a Pointer Network to generate joint action sequences in an AutoRegressive manner, and introduces a Relation-Aware Attention module to capture inter-entity relationships. Additionally, we guide the model's decision-making using informative priors to facilitate effective exploration. Experiments on 8 datasets demonstrate that MAPT significantly outperforms existing baseline methods in terms of performance and exhibits substantial computational time advantages compared to classical operations research methods.

</details>


### [24] [Unmasking Airborne Threats: Guided-Transformers for Portable Aerosol Mass Spectrometry](https://arxiv.org/abs/2511.17446)
*Kyle M. Regan,Michael McLoughlin,Wayne A. Bryden,Gonzalo R. Arce*

Main category: cs.LG

TL;DR: MALDI-MS는 병원체 분석의 핵심 기술이지만, 복잡한 샘플 준비 과정과 여러 번 측정의 필요성으로 인해 실시간 환경 모니터링에는 적합하지 않다. 이에 따라 MS-DGFormer라는 새로운 프레임워크를 제안하여, 최소한의 준비만으로 원시 질량 스펙트럼 데이터를 처리하고 효율적인 단일 측정을 가능하게 한다. 이를 통해 환경 샘플에서 병원체를 신속하게 탐지할 수 있는 혁신적인 방법을 제공한다.


<details>
  <summary>Details</summary>
Motivation: MALDI-MS의 현재 한계를 극복하고, 실시간 환경 모니터링을 위한 효율적인 솔루션을 제공하는 것.

Method: 새로운 Mass Spectral Dictionary-Guided Transformer (MS-DGFormer) 프레임워크를 사용하여 원시 질량 스펙트럼 데이터를 직접 처리하고, 장기 의존성을 캡처하도록 설계된 트랜스포머 아키텍처를 활용한다.

Result: 단일 측정 스펙트럼에서 중요한 생체 분자 패턴을 밝혀내는 강력한 성능을 발휘하여, 에어로졸 샘플에서 병원체를 효과적으로 식별할 수 있다.

Conclusion: 우리의 방법은 환경 병원체 탐지 및 생물학적 위협에 대한 신속한 대응을 혁신하는 휴대용 MALDI-MS 플랫폼을 활성화하는 잠재력을 보여준다.

Abstract: Matrix Assisted Laser Desorption/Ionization Mass Spectrometry (MALDI-MS) is a cornerstone in biomolecular analysis, offering precise identification of pathogens through unique mass spectral signatures. Yet, its reliance on labor-intensive sample preparation and multi-shot spectral averaging restricts its use to laboratory settings, rendering it impractical for real-time environmental monitoring. These limitations are especially pronounced in emerging aerosol MALDI-MS systems, where autonomous sampling generates noisy spectra for unknown aerosol analytes, requiring single-shot detection for effective analysis. Addressing these challenges, we propose the Mass Spectral Dictionary-Guided Transformer (MS-DGFormer): a data-driven framework that redefines spectral analysis by directly processing raw, minimally prepared mass spectral data. MS-DGFormer leverages a transformer architecture, designed to capture the long-range dependencies inherent in these time-series spectra. To enhance feature extraction, we introduce a novel dictionary encoder that integrates denoised spectral information derived from Singular Value Decomposition (SVD), enabling the model to discern critical biomolecular patterns from single-shot spectra with robust performance. This innovation provides a system to achieve superior pathogen identification from aerosol samples, facilitating autonomous, real-time analysis in field conditions. By eliminating the need for extensive preprocessing, our method unlocks the potential for portable, deployable MALDI-MS platforms, revolutionizing environmental pathogen detection and rapid response to biological threats.

</details>


### [25] [PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM](https://arxiv.org/abs/2511.17467)
*Siqi Liang,Yudi Zhang,Yue Guo*

Main category: cs.LG

TL;DR: 개인화된 AI 에이전트를 위한 새로운 프레임워크를 제안하며, 이는 사용자 선호에 맞춰 적응하는 모델이다.


<details>
  <summary>Details</summary>
Motivation: 개인화된 AI 에이전트의 필요성에 의해 동기부여되었다.

Method: 사용자의 '페르소나'를 embody하는 에이전트를 위해 대형 언어 모델과 Knowledge-Graph-enhanced Retrieval-Augmented Generation 메커니즘을 도입한다.

Result: LaMP 벤치마크에서 뉴스 분류 F1이 11.1%, 영화 태깅 F1이 56.1% 향상되며, 제품 평가 MAE는 10.4% 감소하였다.

Conclusion: 이 동적 프롬프트 엔지니어링 접근 방식은 에이전트가 일관된 페르소나-정렬 행동을 유지하면서 집단 지식의 이점을 활용할 수 있게 한다.

Abstract: We propose a novel framework for persona-based language model system, motivated by the need for personalized AI agents that adapt to individual user preferences. In our approach, the agent embodies the user's "persona" (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contextual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant documents and summarizes communities of related information. Our framework generates personalized prompts by combining: (1) a summary of the user's historical behaviors and preferences extracted from the knowledge graph, and (2) relevant global interaction patterns identified through graph-based community detection. This dynamic prompt engineering approach allows the agent to maintain consistent persona-aligned behaviors while benefiting from collective knowledge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F

</details>


### [26] [Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization](https://arxiv.org/abs/2511.17489)
*Vinay Kanakeri,Shivam Bajaj,Ashwin Verma,Vijay Gupta,Aritra Mitra*

Main category: cs.LG

TL;DR: 본 연구는 강화 학습에서 데이터 효율성을 개선하기 위해 비슷한 과정의 데이터를 활용하는 새로운 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습은 데이터 소모가 큰 문제로 알려져 있으며, '유사한' 프로세스의 데이터를 이용하여 학습 알고리즘의 샘플 효율성을 개선할 필요가 있습니다.

Method: 여러 에이전트가 각기 다른 선형 프로세스를 제어하는 설정을 고려하고, 에이전트의 로컬 프로세스를 동역학 및 작업의 유사성을 기반으로 클러스터로 나누는 새로운 알고리즘을 제안합니다.

Result: 제안한 알고리즘은 각 클러스터에 대해 개인화된 정책을 출력하며, 높은 확률로 올바른 클러스터링을 보장합니다.

Conclusion: 분산 구현 관점에서 본 연구의 방법은 경미한 로그 통신 오버헤드만 발생시키기 때문에 매력적입니다.

Abstract: It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from 'approximately similar' processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents' local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [27] [Optimizing PyTorch Inference with LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2511.16964)
*Kirill Nagaitsev,Luka Grbcic,Samuel Williams,Costin Iancu*

Main category: cs.MA

TL;DR: 현대 AI 추론 시스템에서 GPU 하드웨어 성능 최적화는 지속적인 도전 과제이며, 여러 에이전트를 활용한 최적화가 효과적임을 보여준다.


<details>
  <summary>Details</summary>
Motivation: GPU 하드웨어에서 성능을 극대화하는 것은 현대 AI 추론 시스템에 대한 지속적인 도전이다.

Method: 다중 에이전트 PyTorch 최적화 시스템을 비교하기 위한 논리적 프레임워크를 제시하고, 평가를 통해 최적화 전략의 효과를 분석하였다.

Result: 평가 결과, 오류 수정 에이전트와 짝지었을 때 성과가 가장 우수한 전략이 나타났으며 최적화 단계의 세부 사항과 성과가 상관관계가 있음을 입증했다.

Conclusion: 최고의 구현은 KernelBench의 다양한 작업에서 H100 GPU에서 평균 2.88배의 속도 향상을 달성하였다.

Abstract: Maximizing performance on available GPU hardware is an ongoing challenge for modern AI inference systems. Traditional approaches include writing custom GPU kernels and using specialized model compilers to tune high-level code for specific GPU targets. Recent work shows that LLM-based multi-agent systems can effectively perform such tuning, often outperforming existing compilers and eliminating the need for manual kernel development. However, the dynamics of multi-agent systems for this task remain unexplored. In this work, we present a logical framework for comparing multi-agent PyTorch optimization systems. Our evaluation shows that exploit-heavy strategies perform best when paired with error-fixing agents, and that performance correlates with the granularity of optimization steps. The best implementation achieves an average 2.88x speedup on an H100 GPU across diverse tasks in KernelBench, a benchmark suite covering a range of machine learning architectures in PyTorch.

</details>
