<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 10]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CR](#cs.CR) [Total: 9]
- [cs.LG](#cs.LG) [Total: 10]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge](https://arxiv.org/abs/2512.14766)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Jiaoyan Chen,Steffen Staab,Yuan He,Evgeny Kharlamov*

Main category: cs.AI

TL;DR: 대규모 언어 모델이 지식 그래프 질문 응답(KGQA)에서 좋은 성과를 내지만, 대부분의 벤치마크는 완전한 지식 그래프를 가정하고 있어 불완전한 KG에 대한 평가가 부족하다. 이 논문은 KG 불완전성을 고려한 벤치마크 구축 방법론을 제안하고, 새로운 방식의 Adaptive Graph Reasoning Agent(GR-Agent)를 소개하여 기존 방법의 성능 저하 문제를 해결하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 기존 KGQA 벤치마크가 완전한 지식 그래프를 가정하고 있어 불완전한 KG에서의 성능을 평가하지 못하는 문제를 해결하고자 함.

Method: KG 불완전성을 고려하여 직접 지원하는 트리플을 제거하되, 답변을 유추하기 위한 대체 추론 경로가 유지되도록 하는 벤치마크 구축 방법론을 제안함. 또한 GR-Agent를 통해 KGQA를 에이전트 환경 상호작용으로 형식화함.

Result: 제안한 방법론을 활용한 실험 결과, 기존 방법들이 불완전성 하에서 일관된 성능 저하를 겪는 반면, GR-Agent는 비훈련 기준선보다 우수한 성능을 보였고, 완전 및 불완전 설정 모두에서 훈련 기반 방법과 유사한 성능을 낼 수 있음을 보여줌.

Conclusion: Adaptive Graph Reasoning Agent는 KGQA 성능을 향상시키고, 불완전성에 대한 기존의 한계를 극복하며 보다 나은 추론 능력을 제공함.

Abstract: Large language models (LLMs) achieve strong results on knowledge graph question answering (KGQA), but most benchmarks assume complete knowledge graphs (KGs) where direct supporting triples exist. This reduces evaluation to shallow retrieval and overlooks the reality of incomplete KGs, where many facts are missing and answers must be inferred from existing facts. We bridge this gap by proposing a methodology for constructing benchmarks under KG incompleteness, which removes direct supporting triples while ensuring that alternative reasoning paths required to infer the answer remain. Experiments on benchmarks constructed using our methodology show that existing methods suffer consistent performance degradation under incompleteness, highlighting their limited reasoning ability. To overcome this limitation, we present the Adaptive Graph Reasoning Agent (GR-Agent). It first constructs an interactive environment from the KG, and then formalizes KGQA as agent environment interaction within this environment. GR-Agent operates over an action space comprising graph reasoning tools and maintains a memory of potential supporting reasoning evidence, including relevant relations and reasoning paths. Extensive experiments demonstrate that GR-Agent outperforms non-training baselines and performs comparably to training-based methods under both complete and incomplete settings.

</details>


### [2] [AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally](https://arxiv.org/abs/2512.14910)
*Nadine Angela Cantonjos,Arpita Biswas*

Main category: cs.AI

TL;DR: 기후 적응을 위한 농업 지원을 위해 다중 에이전트 시스템 AgroAskAI를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 농업 지역은 기후 관련 위험으로부터 피해를 입고 있으며, 이를 대응하기 위한 적응적 위험 관리 솔루션과 의사결정 전략이 필요하다.

Method: AgroAskAI는 자율 에이전트를 조정하는 책임 사슬 접근 방식을 사용하는 모듈형, 역할 전문화 아키텍처를 갖춘 다중 에이전트 추론 시스템이다.

Result: 기후 적응과 관련된 일반적인 농업 쿼리에 대한 실험 결과, AgroAskAI는 더 실행 가능하고, 근거 있는, 포괄적인 출력을 제공한다.

Conclusion: AgroAskAI는 농업의 기후 적응을 위한 지속 가능하고 책임 있는 의사결정을 지원하기 위한 에이전틱 AI의 잠재력을 강조한다.

Abstract: Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI systems consist of autonomous, specialized agents capable of solving complex, dynamic tasks. While past systems have relied on single-agent models or have used multi-agent frameworks only for static functions, there is a growing need for architectures that support dynamic collaborative reasoning and context-aware outputs. To bridge this gap, we present AgroAskAI, a multi-agent reasoning system for climate adaptation decision support in agriculture, with a focus on vulnerable rural communities. AgroAskAI features a modular, role-specialized architecture that uses a chain-of-responsibility approach to coordinate autonomous agents, integrating real-time tools and datasets. The system has built-in governance mechanisms that mitigate hallucination and enable internal feedback for coherent, locally relevant strategies. The system also supports multilingual interactions, making it accessible to non-English-speaking farmers. Experiments on common agricultural queries related to climate adaptation show that, with additional tools and prompt refinement, AgroAskAI delivers more actionable, grounded, and inclusive outputs. Our experimental results highlight the potential of agentic AI for sustainable and accountable decision support in climate adaptation for agriculture.

</details>


### [3] [Agentic AI for Integrated Sensing and Communication: Analysis, Framework, and Case Study](https://arxiv.org/abs/2512.15044)
*Wenwen Xie,Geng Sun,Ruichen Zhang,Xuejie Liu,Yinqiu Liu,Jiacheng Wang,Dusit Niyato,Ping Zhang*

Main category: cs.AI

TL;DR: 이 논문은 에이전틱 인공지능이 통합 감지 및 통신 시스템의 효율성 및 적응성을 유지하기 위한 해결책이 될 수 있음을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 6세대(6G) 시대의 통합 감지 및 통신(ISAC)은 미래 지능형 네트워크의 협업 감지 및 통신에 필수적인 지원을 제공하는 주요 발전 방향으로 떠오르고 있다.

Method: 우리는 에이전틱 AI와 ISAC 시스템에 대한 포괄적인 리뷰를 제공하고, ISAC 시스템을 위한 여러 가지 최적화 접근 방식을 보여주며, 에이전틱 AI 기반 생성적 인공지능의 장점을 강조하고, 새로운 에이전틱 ISAC 프레임워크를 제안하며 사례 연구를 통해 이를 검증한다.

Result: 우리는 제안된 프레임워크가 ISAC 성능 최적화에서 우수성을 입증함을 보여준다.

Conclusion: 마지막으로, 에이전틱 AI 기반 ISAC 시스템에 대한 미래 연구 방향을 명확히 한다.

Abstract: Integrated sensing and communication (ISAC) has emerged as a key development direction in the sixth-generation (6G) era, which provides essential support for the collaborative sensing and communication of future intelligent networks. However, as wireless environments become increasingly dynamic and complex, ISAC systems require more intelligent processing and more autonomous operation to maintain efficiency and adaptability. Meanwhile, agentic artificial intelligence (AI) offers a feasible solution to address these challenges by enabling continuous perception-reasoning-action loops in dynamic environments to support intelligent, autonomous, and efficient operation for ISAC systems. As such, we delve into the application value and prospects of agentic AI in ISAC systems in this work. Firstly, we provide a comprehensive review of agentic AI and ISAC systems to demonstrate their key characteristics. Secondly, we show several common optimization approaches for ISAC systems and highlight the significant advantages of generative artificial intelligence (GenAI)-based agentic AI. Thirdly, we propose a novel agentic ISAC framework and prensent a case study to verify its superiority in optimizing ISAC performance. Finally, we clarify future research directions for agentic AI-based ISAC systems.

</details>


### [4] [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://arxiv.org/abs/2512.15089)
*Jinwu Hu,Dongjin Yang,Langyu Bian,Zhiquan Wen,Yufeng Wang,Yaofo Chen,Bin Xiao,Yuanqing Li,Mingkui Tan*

Main category: cs.AI

TL;DR: 이 논문에서는 인간의 계층적 추론에서 영감을 받아 각 쿼리에 가장 적합한 추론 전략을 동적으로 선택하는 CogER 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 대형 언어 모델(LLM) 추론 전략은 주로 LLM 자체에 의존하며, 다양한 난이도의 쿼리에서 추론 효율성과 정확성을 균형 있게 유지하기 위해 struggle 한다.

Method: CogER은 Markov Decision Process로 프로세스를 모델링하고, 강화 학습을 사용하여 CogER-Agent를 훈련시킨다. 이 에이전트는 보상 함수에 의해 가이드되어 해결 품질과 계산 비용 간의 균형을 유지한다.

Result: CogER은 최신 테스트 시간 확장 방법들을 능가하며, 도메인 내 작업에서는 평균 정확도가 최소 13% 향상되었고, 도메인 외 작업에서는 8%의 상대적 향상을 달성하였다.

Conclusion: CogER은 LLM의 자원 효율적인 추론을 보장하며, 외부 도구를 요구하는 쿼리에 대한 인지 도구 보조 추론을 도입한다.

Abstract: Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.

</details>


### [5] [CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications](https://arxiv.org/abs/2512.15231)
*Zhengchao Chen,Haoran Wang,Jing Yao,Pedram Ghamisi,Jun Zhou,Peter M. Atkinson,Bing Zhang*

Main category: cs.AI

TL;DR: CangLing-KnowFlow는 다양한 원격 감지 응용 프로그램을 위한 통합 지능형 에이전트 프레임워크로, 데이터 전처리에서 고급 해석까지의 작업 흐름을 관리합니다.


<details>
  <summary>Details</summary>
Motivation: 지금까지의 자동화 시스템은 작업 특화되어 있으며 다양한 원격 감지 응용 프로그램을 위한 통합된 프레임워크가 부족합니다.

Method: CangLing-KnowFlow는 절차적 지식 베이스, 동적 작업 흐름 조정, 진화 메모리 모듈을 통합한 통합된 지능형 에이전트 프레임워크입니다.

Result: CangLing-KnowFlow는 복잡한 작업에서 Reflexion 기준선을 4% 이상 초과하여 성과를 기록했습니다.

Conclusion: 이 연구는 CangLing-KnowFlow가 복잡한 지구 관측 문제를 해결하기 위한 강력하고 효율적이며 확장 가능한 자동화 솔루션으로서의 잠재력을 보여줍니다.

Abstract: The automated and intelligent processing of massive remote sensing (RS) datasets is critical in Earth observation (EO). Existing automated systems are normally task-specific, lacking a unified framework to manage diverse, end-to-end workflows--from data preprocessing to advanced interpretation--across diverse RS applications. To address this gap, this paper introduces CangLing-KnowFlow, a unified intelligent agent framework that integrates a Procedural Knowledge Base (PKB), Dynamic Workflow Adjustment, and an Evolutionary Memory Module. The PKB, comprising 1,008 expert-validated workflow cases across 162 practical RS tasks, guides planning and substantially reduces hallucinations common in general-purpose agents. During runtime failures, the Dynamic Workflow Adjustment autonomously diagnoses and replans recovery strategies, while the Evolutionary Memory Module continuously learns from these events, iteratively enhancing the agent's knowledge and performance. This synergy enables CangLing-KnowFlow to adapt, learn, and operate reliably across diverse, complex tasks. We evaluated CangLing-KnowFlow on the KnowFlow-Bench, a novel benchmark of 324 workflows inspired by real-world applications, testing its performance across 13 top Large Language Model (LLM) backbones, from open-source to commercial. Across all complex tasks, CangLing-KnowFlow surpassed the Reflexion baseline by at least 4% in Task Success Rate. As the first most comprehensive validation along this emerging field, this research demonstrates the great potential of CangLing-KnowFlow as a robust, efficient, and scalable automated solution for complex EO challenges by leveraging expert knowledge (Knowledge) into adaptive and verifiable procedures (Flow).

</details>


### [6] [SCOPE: Prompt Evolution for Enhancing Agent Effectiveness](https://arxiv.org/abs/2512.15374)
*Zehua Pei,Hui-Ling Zhen,Shixiong Kai,Sinno Jialin Pan,Yunhe Wang,Mingxuan Yuan,Bei Yu*

Main category: cs.AI

TL;DR: LLM 에이전트의 정적 프롬프트는 동적 맥락을 효과적으로 관리하지 못하므로 반복적인 오류를 초래한다. SCOPE라는 방법을 통해 이 문제를 해결하고, 실험을 통해 성공적으로 성과를 증명하였다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 동적인 대규모 맥락에서 효과적으로 작동하지 못하는 문제를 해결하고자 함.

Method: SCOPE는 맥락 관리를 온라인 최적화 문제로 정의하고, 실행 추적에서 지침을 합성하여 에이전트의 프롬프트를 자동으로 발전시키는 방법을 제안한다.

Result: HLE 벤치마크 실험에서 SCOPE가 작업 성공률을 14.23%에서 38.64%로 향상시켰음을 보여준다.

Conclusion: SCOPE는 인간 개입 없이도 프롬프트 발전을 통해 성공적인 작업 수행을 가능하게 한다.

Abstract: Large Language Model (LLM) agents are increasingly deployed in environments that generate massive, dynamic contexts. However, a critical bottleneck remains: while agents have access to this context, their static prompts lack the mechanisms to manage it effectively, leading to recurring Corrective and Enhancement failures. To address this capability gap, we introduce \textbf{SCOPE} (Self-evolving Context Optimization via Prompt Evolution). SCOPE frames context management as an \textit{online optimization} problem, synthesizing guidelines from execution traces to automatically evolve the agent's prompt. We propose a Dual-Stream mechanism that balances tactical specificity (resolving immediate errors) with strategic generality (evolving long-term principles). Furthermore, we introduce Perspective-Driven Exploration to maximize strategy coverage, increasing the likelihood that the agent has the correct strategy for any given task. Experiments on the HLE benchmark show that SCOPE improves task success rates from 14.23\% to 38.64\% without human intervention. We make our code publicly available at https://github.com/JarvisPei/SCOPE.

</details>


### [7] [Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision](https://arxiv.org/abs/2512.15489)
*Wei Du,Shubham Toshniwal,Branislav Kisacanin,Sadegh Mahdavi,Ivan Moshkov,George Armstrong,Stephen Ge,Edgar Minasyan,Feng Chen,Igor Gitman*

Main category: cs.AI

TL;DR: Nemotron-Math는 다양한 추론 스타일과 통합 도구 능력을 갖춘 대규모 수학 추론 데이터셋이다.


<details>
  <summary>Details</summary>
Motivation: 기존 데이터셋들이 제공하는 수학적 추론 감독의 한계를 극복하기 위해.

Method: gpt-oss-120b의 멀티 모드 생성 능력을 활용하여 7.5M의 솔루션 트레이스를 포함하는 데이터셋을 소개한다.

Result: Nemotron-Math는 OpenMathReasoning을 초월하며, StackExchange-Math를 통합함으로써 강력한 일반화 성능을 보인다.

Conclusion: Nemotron-Math는 최신 성능을 가능하게 하고 있으며, AIME 2024 및 2025에서 100% maj@16 정확도를 달성했다.

Abstract: High-quality mathematical reasoning supervision requires diverse reasoning styles, long-form traces, and effective tool integration, capabilities that existing datasets provide only in limited form. Leveraging the multi-mode generation ability of gpt-oss-120b, we introduce Nemotron-Math, a large-scale mathematical reasoning dataset containing 7.5M solution traces across high, medium, and low reasoning modes, each available both with and without Python tool-integrated reasoning (TIR).
  The dataset integrates 85K curated AoPS problems with 262K community-sourced StackExchange-Math problems, combining structured competition tasks with diverse real-world mathematical queries. We conduct controlled evaluations to assess the dataset quality.
  Nemotron-Math consistently outperforms the original OpenMathReasoning on matched AoPS problems. Incorporating StackExchange-Math substantially improves robustness and generalization, especially on HLE-Math, while preserving accuracy on math competition benchmarks.
  To support efficient long-context training, we develop a sequential bucketed strategy that accelerates 128K context-length fine-tuning by 2--3$\times$ without significant accuracy loss. Overall, Nemotron-Math enables state-of-the-art performance, including 100\% maj@16 accuracy on AIME 2024 and 2025 with Python TIR.

</details>


### [8] [A Decision-Theoretic Approach for Managing Misalignment](https://arxiv.org/abs/2512.15584)
*Daniel A. Herrmann,Abinav Chari,Isabelle Qian,Sree Sharvesh,B. A. Levinstein*

Main category: cs.AI

TL;DR: AI 시스템에 대한 의사 결정을 언제 위임해야 하는지를 논의하며, 불확실성 하에서 불완전한 정렬이 위임을 정당화하는 데 충분한지를 판단하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI의 가치 정렬 기술이 발전했지만, 불확실성 하에서 불완전한 정렬이 위임을 정당화하는 기준에 대한 연구가 부족하다.

Method: 주요인(주체)의 불확실성을 정밀하게 고려하여 에이전트의 가치(오)정렬, 인식적 정확성 및 접근성의 균형을 분석하는 형식적 결정 이론적 프레임워크를 도입한다.

Result: 전반적으로 두 가지 위임 시나리오 간의 뚜렷한 차이를 밝히며, 특정 맥락에서의 위임이 불완전한 정렬에도 불구하고 최적일 수 있음을 보여준다.

Conclusion: AI가 주어진 맥락에서 충분히 정렬되어 있는지를 판단하는 원칙적 방법을 제공하며, 완벽한 정렬을 추구하는 데서 불확실성 하에서 위임의 위험과 보상을 관리하는 것으로 초점을 전환한다.

Abstract: When should we delegate decisions to AI systems? While the value alignment literature has developed techniques for shaping AI values, less attention has been paid to how to determine, under uncertainty, when imperfect alignment is good enough to justify delegation. We argue that rational delegation requires balancing an agent's value (mis)alignment with its epistemic accuracy and its reach (the acts it has available). This paper introduces a formal, decision-theoretic framework to analyze this tradeoff precisely accounting for a principal's uncertainty about these factors. Our analysis reveals a sharp distinction between two delegation scenarios. First, universal delegation (trusting an agent with any problem) demands near-perfect value alignment and total epistemic trust, conditions rarely met in practice. Second, we show that context-specific delegation can be optimal even with significant misalignment. An agent's superior accuracy or expanded reach may grant access to better overall decision problems, making delegation rational in expectation. We develop a novel scoring framework to quantify this ex ante decision. Ultimately, our work provides a principled method for determining when an AI is aligned enough for a given context, shifting the focus from achieving perfect alignment to managing the risks and rewards of delegation under uncertainty.

</details>


### [9] [Artism: AI-Driven Dual-Engine System for Art Generation and Critique](https://arxiv.org/abs/2512.15710)
*Shuai Liu,Yiqing Tian,Yang Chen,Mar Canet Sola*

Main category: cs.AI

TL;DR: 이 논문은 예술 진화의 잠재적 궤적 탐색 문제를 해결하기 위한 이중 엔진 AI 아키텍처 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 예술의 진화 과정을 탐색하는 복잡한 문제를 해결하기 위해.

Method: AIDA(인공지능 예술가 사회망)와 비판적 분석 시스템인 Ismism Machine의 두 가지 상호 연결된 구성 요소를 통해 딥러닝과 다중 에이전트 협업을 활용.

Result: 예술사 발전 및 개념 혁신 패턴에 대한 다차원 시뮬레이션을 가능하게 하는 방법론을 개발.

Conclusion: AI 기반의 비판적 루프에 기반한 일반적인 방법론을 제시하며, 예술의 컴퓨터 분석을 위한 새로운 가능성을 제공합니다.

Abstract: This paper proposes a dual-engine AI architectural method designed to address the complex problem of exploring potential trajectories in the evolution of art. We present two interconnected components: AIDA (an artificial artist social network) and the Ismism Machine, a system for critical analysis. The core innovation lies in leveraging deep learning and multi-agent collaboration to enable multidimensional simulations of art historical developments and conceptual innovation patterns. The framework explores a shift from traditional unidirectional critique toward an intelligent, interactive mode of reflexive practice. We are currently applying this method in experimental studies on contemporary art concepts. This study introduces a general methodology based on AI-driven critical loops, offering new possibilities for computational analysis of art.

</details>


### [10] [Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants](https://arxiv.org/abs/2512.15712)
*Vincent Huang,Dami Choi,Daniel D. Johnson,Sarah Schwettmann,Jacob Steinhardt*

Main category: cs.AI

TL;DR: 본 논문은 신경망 내부의 활성화를 해석해 모델 행동을 예측하는 새로운 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 신경망의 내부 활성화를 해석하면 그 행동에 대한 보다 신뢰할 수 있는 설명이 가능하지만, 복잡한 활성화 공간 구조로 인해 어렵습니다.

Method: 활성화를 통해 모델 행동을 정확히 예측하도록 해석 가능성 보조기를 교육하는 목표로 작업을 전환합니다.

Result: 제안된 Predictive Concept Decoder는 활성화를 압축하여 생성된 개념 목록을 통해 자연어 질문에 답함으로써 유용한 기능을 제공합니다.

Conclusion: PCD는 jailbreak 감지, 비밀 힌트 발견 및 잠재 개념의 정확한 식별에 능하며, 이는 데이터와 함께 개선됩니다.

Abstract: Interpreting the internal activations of neural networks can produce more faithful explanations of their behavior, but is difficult due to the complex structure of activation space. Existing approaches to scalable interpretability use hand-designed agents that make and test hypotheses about how internal activations relate to external behavior. We propose to instead turn this task into an end-to-end training objective, by training interpretability assistants to accurately predict model behavior from activations through a communication bottleneck. Specifically, an encoder compresses activations to a sparse list of concepts, and a decoder reads this list and answers a natural language question about the model. We show how to pretrain this assistant on large unstructured data, then finetune it to answer questions. The resulting architecture, which we call a Predictive Concept Decoder, enjoys favorable scaling properties: the auto-interp score of the bottleneck concepts improves with data, as does the performance on downstream applications. Specifically, PCDs can detect jailbreaks, secret hints, and implanted latent concepts, and are able to accurately surface latent user attributes.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [11] [Mapis: A Knowledge-Graph Grounded Multi-Agent Framework for Evidence-Based PCOS Diagnosis](https://arxiv.org/abs/2512.15398)
*Zanxiang He,Meng Li,Liyun Shi,Weiye Daia,Liming Nie*

Main category: cs.MA

TL;DR: Mapis라는 지식 기반 다중 에이전트 프레임워크를 제안하여 다기관 절차를 통해 다낭성 난소 증후군(PCOS)의 진단을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: PCOS는 가임기 여성의 10%에 영향을 미치며, 효과적인 진단 도구 개발이 필요합니다.

Method: Mapis는 2023년 국제 지침을 기반으로 구성된 협업 워크플로우를 통해 복잡한 진단 작업을 전문 에이전트 간에 분리하여 진행합니다.

Result: Mapis는 공개 벤치마크와 특수 임상 데이터셋에서 광범위한 실험을 수행하여 기존의 경쟁 방법보다 우수한 성능을 보입니다.

Conclusion: Mapis는 기존의 기계 학습 모델 및 단일 에이전트 시스템보다 정확도에서 상당한 향상을 보여줍니다.

Abstract: Polycystic Ovary Syndrome (PCOS) constitutes a significant public health issue affecting 10% of reproductive-aged women, highlighting the critical importance of developing effective diagnostic tools. Previous machine learning and deep learning detection tools are constrained by their reliance on large-scale labeled data and an lack of interpretability. Although multi-agent systems have demonstrated robust capabilities, the potential of such systems for PCOS detection remains largely unexplored. Existing medical multi-agent frameworks are predominantly designed for general medical tasks, suffering from insufficient domain integration and a lack of specific domain knowledge. To address these challenges, we propose Mapis, the first knowledge-grounded multi-agent framework explicitly designed for guideline-based PCOS diagnosis. Specifically, it built upon the 2023 International Guideline into a structured collaborative workflow that simulates the clinical diagnostic process. It decouples complex diagnostic tasks across specialized agents: a gynecological endocrine agent and a radiology agent collaborative to verify inclusion criteria, while an exclusion agent strictly rules out other causes. Furthermore, we construct a comprehensive PCOS knowledge graph to ensure verifiable, evidence-based decision-making. Extensive experiments on public benchmarks and specialized clinical datasets, benchmarking against nine diverse baselines, demonstrate that Mapis significantly outperforms competitive methods. On the clinical dataset, it surpasses traditional machine learning models by 13.56%, single-agent by 6.55%, and previous medical multi-agent systems by 7.05% in Accuracy.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [Zero-Knowledge Audit for Internet of Agents: Privacy-Preserving Communication Verification with Model Context Protocol](https://arxiv.org/abs/2512.14737)
*Guanlin Jing,Huayi Qi*

Main category: cs.CR

TL;DR: 본 논문에서는 비밀 유지 및 감사 가능성을 유지하면서 에이전트 통신의 감사를 위한 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 정확한 청구, 준수 검증 및 책임을 요구하는 규제 환경에서 에이전트 통신의 개인 정보 보호와 감사 가능성을 동시에 보장하는 것이 중요한 과제가 되고 있습니다.

Method: 우리는 제로 지식 증명을 기존의 모델 컨텍스트 프로토콜(MCP)과 결합하여 메시지 내용을 노출하지 않고도 메시지를 검증할 수 있는 감사 프레임워크를 제시합니다.

Result: 이 프레임워크는 에이전트 간의 상호 감사 기능을 제공하며, 한 쪽은 통신 내용과 품질을 확인하고 다른 쪽은 사용 메트릭을 검증할 수 있습니다.

Conclusion: 우리의 연구 결과, zk-MCP는 데이터 진위와 통신 개인 정보 보호를 제공하며, 지연이 거의 없는 효율적인 검증을 달성합니다. 이 프레임워크는 에이전트 통신을 위한 최초의 개인 정보 보호 감사 시스템으로, 메시지 내용을 노출하지 않으면서도 검증 가능한 상호 감사를 제공합니다.

Abstract: Existing agent communication frameworks face critical limitations in providing verifiable audit trails without compromising the privacy and confidentiality of agent interactions. The protection of agent communication privacy while ensuring auditability emerges as a fundamental challenge for applications requiring accurate billing, compliance verification, and accountability in regulated environments.
  We introduce a framework for auditing agent communications that keeps messages private while still checking they follow expected rules. It pairs zero-knowledge proofs with the existing Model Context Protocol (MCP) so messages can be verified without revealing their contents. The approach runs in lightweight networks, stays compatible with standard MCP exchanges, and adds asynchronous audit verification to confirm format and general message types without exposing specifics.
  The framework enables mutual audits between agents: one side can check communication content and quality while the other verifies usage metrics, all without revealing sensitive information. We formalize security goals and show that zk-MCP provides data authenticity and communication privacy, achieving efficient verification with negligible latency overhead. We fully implement the framework, including Circom-based zero-knowledge proof generation and an audit protocol integrated with MCP's bidirectional channel, and, to our knowledge, this is the first privacy-preserving audit system for agent communications that offers verifiable mutual auditing without exposing message content or compromising agent privacy.

</details>


### [13] [Quantum-Augmented AI/ML for O-RAN: Hierarchical Threat Detection with Synergistic Intelligence and Interpretability (Technical Report)](https://arxiv.org/abs/2512.14742)
*Tan Le,Van Le,Sachin Shetty*

Main category: cs.CR

TL;DR: O-RAN의 사이버 보안 공격 표면을 줄이기 위한 3단계 방어 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: O-RAN의 모듈화와 텔레메트리 세분화가 증가함에 따라 사이버 보안 공격 표면이 확대되고 있다.

Method: 이 논문은 이상 탐지, 침입 확인, 다중 공격 분류라는 세 가지 계층으로 구성된 방어 프레임워크를 제안하며, 하이브리드 양자 컴퓨팅과 기계 학습을 통합한다.

Result: 프레임워크는 합성 및 실제 텔레메트리에서 높은 정확도와 강한 클래스 분리를 지속적으로 달성한다.

Conclusion: 이 프레임워크는 해석 가능성, 견고성 및 슬라이스 인식 진단과 확장 가능한 배포를 위한 준비 상태를 입증한다.

Abstract: Open Radio Access Networks (O-RAN) enhance modularity and telemetry granularity but also widen the cybersecurity attack surface across disaggregated control, user and management planes. We propose a hierarchical defense framework with three coordinated layers-anomaly detection, intrusion confirmation, and multiattack classification-each aligned with O-RAN's telemetry stack. Our approach integrates hybrid quantum computing and machine learning, leveraging amplitude- and entanglement-based feature encodings with deep and ensemble classifiers. We conduct extensive benchmarking across synthetic and real-world telemetry, evaluating encoding depth, architectural variants, and diagnostic fidelity. The framework consistently achieves near-perfect accuracy, high recall, and strong class separability. Multi-faceted evaluation across decision boundaries, probabilistic margins, and latent space geometry confirms its interpretability, robustness, and readiness for slice-aware diagnostics and scalable deployment in near-RT and non-RT RIC domains.

</details>


### [14] [Factor(U,T): Controlling Untrusted AI by Monitoring their Plans](https://arxiv.org/abs/2512.14745)
*Edward Lue Chee Lip,Anthony Channg,Diana Kim,Aaron Sandoval,Kevin Zhu*

Main category: cs.CR

TL;DR: AI 모델을 사용하여 복잡한 작업을 단순한 하위 작업으로 분해할 때, 신뢰할 수 없는 모델이 악의적일 경우의 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업의 분해를 필요로 하지만, 이러한 분해를 수행하는 모델이 악의적일 경우의 위험성을 연구하기 위함이다.

Method: 신뢰할 수 없는 모델이 분해를 수행하고, 신뢰할 수 있는 모델이 하위 작업을 구현하는 Factor(U,T) 시스템을 소개한다.

Result: 악성 활동 탐지에서, 자연어 작업 지시사항만으로는 낮은 성능(AUROC 0.52)을 보이고, 반면 전체 Python 솔루션을 평가할 경우 높은 성능(AUROC 0.96)을 보인다.

Conclusion: 신뢰할 수 있는 분해자와 구체적인 하위 솔루션을 모니터링하는 Factor(D,U)는 뛰어난 분별력(AUROC 0.96)과 강력한 안전성(1.2% ASR)을 보여준다.

Abstract: As AI capabilities advance, we increasingly rely on powerful models to decompose complex tasks $\unicode{x2013}$ but what if the decomposer itself is malicious? Factored cognition protocols decompose complex tasks into simpler child tasks: one model creates the decomposition, while other models implement the child tasks in isolation. Prior work uses trusted (weaker but reliable) models for decomposition, which limits usefulness for tasks where decomposition itself is challenging. We introduce Factor($U$,$T$), in which an untrusted (stronger but potentially malicious) model decomposes while trusted models implement child tasks. Can monitors detect malicious activity when observing only natural language task instructions, rather than complete solutions? We baseline and red team Factor($U$,$T$) in control evaluations on BigCodeBench, a dataset of Python coding tasks. Monitors distinguishing malicious from honest decompositions perform poorly (AUROC 0.52) compared to monitors evaluating complete Python solutions (AUROC 0.96). Furthermore, Factor($D$,$U$), which uses a trusted decomposer and monitors concrete child solutions, achieves excellent discrimination (AUROC 0.96) and strong safety (1.2% ASR), demonstrating that implementation-context monitoring succeeds where decomposition-only monitoring fails.

</details>


### [15] [CODE ACROSTIC: Robust Watermarking for Code Generation](https://arxiv.org/abs/2512.14753)
*Li Lin,Siyuan Xin,Yang Cao,Xiaochun Cao*

Main category: cs.CR

TL;DR: 대형 언어 모델(LLM)의 워터마킹은 허위 뉴스, 표절, 스팸과 같은 남용 방지를 위해 중요하다. 이 논문에서는 기존의 LLM 생성 코드 워터마킹 방법이 주석 제거 공격을 처리하지 못한다는 점을 다룬다. 우리는 주석 제거 공격을 방지하기 위해 저Entropy 및 고Entropy 코드 부분을 구분하여 워터마크를 주입하는 새로운 접근 방식을 제안한다. 이는 기존 방법보다 높은 탐지 가능성과 사용성을 달성하였다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 워터마킹은 허위 정보 및 저작권 침해를 방지하기 위해 필수적이다.

Method: 기존의 코드 워터마킹 기법이 주석 제거 공격을 방지하지 못하는 문제를 해결하기 위해, 저Entropy 및 고Entropy 코드 부분을 구분하기 위한 사전 지식을 활용하여 워터마크를 주입하는 접근 방식을 제안한다.

Result: 제안된 방법은 HumanEval에서 평가되었으며, 세 가지 최신 코드 워터마킹 기술과 비교하여 더 높은 탐지 가능성과 사용성을 보였다.

Conclusion: 제안한 방법이 기존 기법들보다 효과적임을 입증하였다.

Abstract: Watermarking large language models (LLMs) is vital for preventing their misuse, including the fabrication of fake news, plagiarism, and spam. It is especially important to watermark LLM-generated code, as it often contains intellectual property.However, we found that existing methods for watermarking LLM-generated code fail to address comment removal attack.In such cases, an attacker can simply remove the comments from the generated code without affecting its functionality, significantly reducing the effectiveness of current code-watermarking techniques.On the other hand, injecting a watermark into code is challenging because, as previous works have noted, most code represents a low-entropy scenario compared to natural language. Our approach to addressing this issue involves leveraging prior knowledge to distinguish between low-entropy and high-entropy parts of the code, as indicated by a Cue List of words.We then inject the watermark guided by this Cue List, achieving higher detectability and usability than existing methods.We evaluated our proposed method on HumanEvaland compared our method with three state-of-the-art code watermarking techniques. The results demonstrate the effectiveness of our approach.

</details>


### [16] [MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber](https://arxiv.org/abs/2512.14846)
*Arth Bhardwaj,Sia Godika,Yuvam Loonker*

Main category: cs.CR

TL;DR: MALCDF는 실시간으로 협력하는 네 개의 LLM 에이전트를 사용하여 다양한 공격에 대응하는 사이버 방어 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 중앙 집중식 보안 도구는 적응형 다중 벡터 공격을 놓치기 쉽다.

Method: 네 개의 LLM 에이전트(탐지, 정보, 대응, 분석)가 실시간으로 협력하며, 안전한 통신 계층을 통해 암호화된 메시지를 전달하고 감사 친화적인 출력물을 생성한다.

Result: MALCDF는 90.0% 탐지 정확도, 85.7% F1 점수, 9.1% 허위 긍정률을 기록하며 평균 6.8초의 이벤트 대기 시간을 보인다.

Conclusion: 단순한 LLM 에이전트를 안전한 메시징으로 조정하면 실용적이고 실시간 사이버 방어를 개선할 수 있음을 보여준다.

Abstract: Traditional, centralized security tools often miss adaptive, multi-vector attacks. We present the Multi-Agent LLM Cyber Defense Framework (MALCDF), a practical setup where four large language model (LLM) agents-Detection, Intelligence, Response, and Analysis-work together in real time. Agents communicate over a Secure Communication Layer (SCL) with encrypted, ontology-aligned messages, and produce audit-friendly outputs (e.g., MITRE ATT&CK mappings).
  For evaluation, we keep the test simple and consistent: all reported metrics come from the same 50-record live stream derived from the CICIDS2017 feature schema. CICIDS2017 is used for configuration (fields/schema) and to train a practical ML baseline. The ML-IDS baseline is a Lightweight Random Forest IDS (LRF-IDS) trained on a subset of CICIDS2017 and tested on the 50-record stream, with no overlap between training and test records.
  In experiments, MALCDF reaches 90.0% detection accuracy, 85.7% F1-score, and 9.1% false-positive rate, with 6.8s average per-event latency. It outperforms the lightweight ML-IDS baseline and a single-LLM setup on accuracy while keeping end-to-end outputs consistent. Overall, this hands-on build suggests that coordinating simple LLM agents with secure, ontology-aligned messaging can improve practical, real-time cyber defense.

</details>


### [17] [Penetration Testing of Agentic AI: A Comparative Security Analysis Across Models and Frameworks](https://arxiv.org/abs/2512.14860)
*Viet K. Nguyen,Mohammad I. Husain*

Main category: cs.CR

TL;DR: 본 논문에서는 에이전틱 AI 시스템의 보안 취약점을 분석하고, 여러 모델과 프레임워크를 비교 평가한 최초의 체계적인 침투 테스트를 수행하였다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 LLM 안전 장치가 해결하지 못하는 에이전틱 AI의 보안 취약성에 대한 연구의 필요성.

Method: 자동 생성 및 CrewAI의 두 가지 에이전틱 AI 프레임워크를 사용하여, 대학 정보 관리 시스템의 기능을 모방한 7개 에이전트 아키텍처와 13개의 다양한 공격 시나리오를 통해 5개의 주요 모델을 테스트하여 비교 평가를 수행했다.

Result: AutoGen의 거부율은 52.3%인 반면 CrewAI는 30.8%로 나타났고, 모델 성능은 Nova Pro가 46.2%로 가장 높았으며, Grok 2는 CrewAI에서 13개의 공격 중 2개(15.4%)를 거부했다.

Conclusion: 대부분의 공격에도 불구하고 안전 메커니즘이 있음에도 불구하고 악의적인 프롬프트의 절반 이상이 성공했음을 보여준다. 우리는 모델이 출력을 조작하여 공격을 수행하거나 거부하는 대신 허위 준수 전략을 포함한 여섯 가지 방어 행동 패턴을 식별하고, 안전한 에이전트 배치를 위한 권장 사항을 제공했다.

Abstract: Agentic AI introduces security vulnerabilities that traditional LLM safeguards fail to address. Although recent work by Unit 42 at Palo Alto Networks demonstrated that ChatGPT-4o successfully executes attacks as an agent that it refuses in chat mode, there is no comparative analysis in multiple models and frameworks. We conducted the first systematic penetration testing and comparative evaluation of agentic AI systems, testing five prominent models (Claude 3.5 Sonnet, Gemini 2.5 Flash, GPT-4o, Grok 2, and Nova Pro) across two agentic AI frameworks (AutoGen and CrewAI) using a seven-agent architecture that mimics the functionality of a university information management system and 13 distinct attack scenarios that span prompt injection, Server Side Request Forgery (SSRF), SQL injection, and tool misuse. Our 130 total test cases reveal significant security disparities: AutoGen demonstrates a 52.3% refusal rate versus CrewAI's 30.8%, while model performance ranges from Nova Pro's 46.2% to Claude and Grok 2's 38.5%. Most critically, Grok 2 on CrewAI rejected only 2 of 13 attacks (15.4% refusal rate), and the overall refusal rate of 41.5% across all configurations indicates that more than half of malicious prompts succeeded despite enterprise-grade safety mechanisms. We identify six distinct defensive behavior patterns including a novel "hallucinated compliance" strategy where models fabricate outputs rather than executing or refusing attacks, and provide actionable recommendations for secure agent deployment. Complete attack prompts are also included in the Appendix to enable reproducibility.

</details>


### [18] [Cloud Security Leveraging AI: A Fusion-Based AISOC for Malware and Log Behaviour Detection](https://arxiv.org/abs/2512.14935)
*Nnamdi Philip Okonkwo,Lubna Luxmi Dhirani*

Main category: cs.CR

TL;DR: 본 연구는 AWS에서 클라우드 기반 AI 증강 보안 운영 센터(AISOC)를 구현하여 비용이 민감한 환경에서 클라우드 SOC의 기능을 향상시키는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 클라우드 SOC가 클라우드 거버넌스, 위험 및 규정을 지원하기 위해 필요한 투명성과 통제를 제공하며, 제한된 예산 내에서 고용량의 이질적인 원시 데이터를 처리할 수 있도록 지원하기 위해 연구를 진행하였다.

Method: AWS에서 클라우드 네이티브 계측과 기계 학습 기반 탐지를 결합한 AI 증강 보안 운영 센터(AISOC) 아키텍처를 구현하였으며, 세 가지 Amazon EC2 인스턴스(공격자, 방어자, 모니터링)를 사용하여 역방향 셸 침투를 시뮬레이션하고, Defender 로그를 분석을 위해 Elasticsearch 및 Kibana 스택으로 전달하였다.

Result: 두 개의 분류기를 훈련시켰고, 각기 다른 조건 하에서 강력한 매크로 F1 스코어(최대 1.00)를 달성하였다.

Conclusion: 간단하고 보정된 융합 방법이 제한된 비용의 환경에서도 클라우드 SOC의 기능을 향상시킬 수 있음을 보여준다.

Abstract: Cloud Security Operations Center (SOC) enable cloud governance, risk and compliance by providing insights visibility and control. Cloud SOC triages high-volume, heterogeneous telemetry from elastic, short-lived resources while staying within tight budgets. In this research, we implement an AI-Augmented Security Operations Center (AISOC) on AWS that combines cloud-native instrumentation with ML-based detection. The architecture uses three Amazon EC2 instances: Attacker, Defender, and Monitoring. We simulate a reverse-shell intrusion with Metasploit, and Filebeat forwards Defender logs to an Elasticsearch and Kibana stack for analysis. We train two classifiers, a malware detector built on a public dataset and a log-anomaly detector trained on synthetically augmented logs that include adversarial variants. We calibrate and fuse the scores to produce multi-modal threat intelligence and triage activity into NORMAL, SUSPICIOUS, and HIGH\_CONFIDENCE\_ATTACK. On held-out tests the fusion achieves strong macro-F1 (up to 1.00) under controlled conditions, though performance will vary in noisier and more diverse environments. These results indicate that simple, calibrated fusion can enhance cloud SOC capabilities in constrained, cost-sensitive setups.

</details>


### [19] [MCPZoo: A Large-Scale Dataset of Runnable Model Context Protocol Servers for AI Agent](https://arxiv.org/abs/2512.15144)
*Mengying Wu,Pei Chen,Geng Hong,Aichao An,Jinsong Chen,Binwang Wan,Xudong Pan,Jiarun Dai,Min Yang*

Main category: cs.CR

TL;DR: MCPZoo는 MCP 서버의 대규모 데이터셋으로, 90,146개의 서버를 포함하고 있어 MCP 기반 보안 분석 연구를 지원한다.


<details>
  <summary>Details</summary>
Motivation: MCP를 통해 에이전트가 외부 도구와 상호작용할 수 있으나, 대규모 접근 가능한 데이터셋의 부족으로 연구가 제한되어 있다.

Method: MCPZoo는 여러 공공 소스에서 수집된 MCP 서버로부터 구성된 데이터셋으로, 90,146개의 서버를 포함한다. 이 데이터셋은 실제 실험을 지원하기 위해 배포 및 검증된 10,000개 이상의 서버 인스턴스를 포함하고 있다.

Result: MCPZoo는 수동 배포 노력 없이 체계적인 탐색 및 상호작용을 가능하게 하는 통합 메타데이터 및 접근 인터페이스를 제공한다.

Conclusion: MCPZoo는 MCP 기반 보안 분석 연구를 지원하기 위해 공개되고 접근 가능한 자원으로 제공된다.

Abstract: Model Context Protocol (MCP) enables agents to interact with external tools, yet empirical research on MCP is hindered by the lack of large-scale, accessible datasets. We present MCPZoo, the largest and most comprehensive dataset of MCP servers collected from multiple public sources, comprising 90,146 servers. MCPZoo includes over ten thousand server instances that have been deployed and verified as runnable and interactable, supporting realistic experimentation beyond static analysis. The dataset provides unified metadata and access interfaces, enabling systematic exploration and interaction without manual deployment effort. MCPZoo is released as an open and accessible resource to support research on MCP-based security analysis.

</details>


### [20] [BashArena: A Control Setting for Highly Privileged AI Agents](https://arxiv.org/abs/2512.15688)
*Adam Kaufman,James Lucassen,Tyler Tracy,Cody Rushing,Aryan Bhatt*

Main category: cs.CR

TL;DR: BashArena는 AI 통제 기술을 연구하기 위한 보안 중심의 환경을 제공하며, 637개의 리눅스 시스템 관리 및 인프라 엔지니어링 작업과 네 가지 파괴 목표를 포함한다. 이를 통해 여러 첨단 LLM을 평가하고, 더 효과적인 통제 프로토콜 설계를 위한 기초 데이터를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 미스얼라인된 AI 에이전트가 자동으로 작동할 수 있는 미래에서 이들이 특권을 남용하여 심각한 피해를 줄 수 있기 때문에 AI 통제 기술 개발이 필요하다.

Method: BashArena라는 보안 중심의 환경을 도입하여 637개의 복잡하고 현실적인 리눅스 시스템 관리 작업과 네 가지 파괴 목표를 설정하여 AI 통제 기술을 연구했다.

Result: Claude Sonnet 4.5는 GPT-4.1 mini의 모니터링을 회피하면서 26%의 성공률로 파괴 행위를 수행하고, 4%의 궤적별 FPR을 기록하였다.

Conclusion: BashArena에서 더 효과적인 통제 프로토콜 설계를 위한 기초 데이터를 제공하며, 데이터셋을 ControlArena 설정으로 출시하고 작업 생성 파이프라인을 공유한다.

Abstract: Future AI agents might run autonomously with elevated privileges. If these agents are misaligned, they might abuse these privileges to cause serious damage. The field of AI control develops techniques that make it harder for misaligned AIs to cause such damage, while preserving their usefulness. We introduce BashArena, a setting for studying AI control techniques in security-critical environments. BashArena contains 637 Linux system administration and infrastructure engineering tasks in complex, realistic environments, along with four sabotage objectives (execute malware, exfiltrate secrets, escalate privileges, and disable firewall) for a red team to target. We evaluate multiple frontier LLMs on their ability to complete tasks, perform sabotage undetected, and detect sabotage attempts. Claude Sonnet 4.5 successfully executes sabotage while evading monitoring by GPT-4.1 mini 26% of the time, at 4% trajectory-wise FPR. Our findings provide a baseline for designing more effective control protocols in BashArena. We release the dataset as a ControlArena setting and share our task generation pipeline.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [21] [Autonomous Source Knowledge Selection in Multi-Domain Adaptation](https://arxiv.org/abs/2512.14710)
*Keqiuyin Li,Jie Lu,Hua Zuo,Guangquan Zhang*

Main category: cs.LG

TL;DR: 비지도 멀티 도메인 적응은 여러 소스 도메인에서 얻은 정보를 활용해 비표시 대상 도메인의 과제를 해결하는 중요한 역할을 한다. 그러나 다수의 소스 도메인은 중복되거나 관련이 없는 정보가 많아 전이 성능에 해를 끼칠 수 있다.


<details>
  <summary>Details</summary>
Motivation: 다수의 소스 도메인에서 가장 전이 가능한 지식을 식별하고 선택하는 효과적인 전략의 필요성이 시급하다.

Method: 우리는 자율적으로 소스 훈련 샘플과 모델을 선택하여 더 관련 있고 전이 가능한 소스 정보를 활용해 대상 과제를 예측할 수 있도록 하는 	extit{자율 소스 지식 선택}(AutoS) 방법을 제안한다. 이 방법은 훈련 중 소스 샘플을 선택하고 어떤 소스 모델이 대상 예측에 기여해야 하는지를 결정하기 위해 밀도 기반 선택 전략을 사용한다.

Result: 실제 데이터셋에서의 실험은 제안된 방법의 우수성을 입증한다.

Conclusion: 제안된 방법은 목표 과제를 해결하기 위해 더 관련성 높은 소스 정보를 활용할 수 있도록 한다.

Abstract: Unsupervised multi-domain adaptation plays a key role in transfer learning by leveraging acquired rich source information from multiple source domains to solve target task from an unlabeled target domain. However, multiple source domains often contain much redundant or unrelated information which can harm transfer performance, especially when in massive-source domain settings. It is urgent to develop effective strategies for identifying and selecting the most transferable knowledge from massive source domains to address the target task. In this paper, we propose a multi-domain adaptation method named \underline{\textit{Auto}}nomous Source Knowledge \underline{\textit{S}}election (AutoS) to autonomosly select source training samples and models, enabling the prediction of target task using more relevant and transferable source information. The proposed method employs a density-driven selection strategy to choose source samples during training and to determine which source models should contribute to target prediction. Simulteneously, a pseudo-label enhancement module built on a pre-trained multimodal modal is employed to mitigate target label noise and improve self-supervision. Experiments on real-world datasets indicate the superiority of the proposed method.

</details>


### [22] [SepsisSuite: Beyond Risk Stratification -- A Comparative Analysis of Deep Fusion vs. Expert Stacking for Prescriptive Sepsis AI](https://arxiv.org/abs/2512.14712)
*Ryan Cartularo*

Main category: cs.LG

TL;DR: 본 연구는 패혈증 예측을 위한 End-to-End Deep Fusion과 Context-Aware Stacking의 구조적 비교를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 패혈증은 전 세계 ICU 입원의 거의 20%를 차지하지만, 기존 예측 모델은 이질적인 데이터 스트림을 효과적으로 통합하는 데 실패하고 있습니다.

Method: Quad-Modal Hierarchical Gated Attention Network인 SepsisFusionFormer를 사용하여 바이탈, 텍스트 및 이미징 간의 복잡한 크로스 모달 상호작용을 해결하려고 했습니다. 그러나 MIMIC-IV 실험에서 SepsisFusionFormer는 소규모 항생제 집단에서 '주의 고갈' 문제를 겪어 과적합이 발생했습니다.

Result: SepsisLateFusion이라는 '슬림한' Context-Aware Mixture-of-Experts 아키텍처 설계를 통해, 동적 게이팅을 활용하여 4시간 이전 예측에서 0.915 AUC의 최첨단 성능을 달성했습니다.

Conclusion: 이 모델들은 임상 의사 결정을 지원하기 위한 Python 프레임워크인 SepsisSuite에 통합되었으며, SepsisSuite는 무료로 제공됩니다.

Abstract: Sepsis accounts for nearly 20% of global ICU admissions, yet conventional prediction models often fail to effectively integrate heterogeneous data streams, remaining either siloed by modality or reliant on brittle early fusion. In this work, we present a rigorous architectural comparison between End-to-End Deep Fusion and Context-Aware Stacking for sepsis tasks. We initially hypothesized that a novel Quad-Modal Hierarchical Gated Attention Network -- termed SepsisFusionFormer -- would resolve complex cross-modal interactions between vitals, text, and imaging. However, experiments on MIMIC-IV revealed that SepsisFusionFormer suffered from "attention starvation" in the small antibiotic cohort ($N \approx 2,100$), resulting in overfitting (AUC 0.66). This counterintuitive result informed the design of SepsisLateFusion, a "leaner" Context-Aware Mixture-of-Experts (MoE) architecture. By treating modalities as orthogonal experts -- the "Historian" (Static), the "Monitor" (Temporal), and the "Reader" (NLP) -- and dynamically gating them via a CatBoost meta-learner, we achieved State-of-the-Art (SOTA) performance: 0.915 AUC for prediction 4 hours prior to clinical onset. By calibrating the decision threshold for clinical safety, we reduced missed cases by 48% relative to the default operating point, thus opening a true preventative window for timely intervention over reactive alerts. Furthermore, for the novel prescriptive task of multi-class antibiotic selection, we demonstrate that a Quad-Modal Ensemble achieved the highest performance (0.72 AUC). These models are integrated into SepsisSuite, a deployment-ready Python framework for clinical decision support. SepsisSuite is available for free at: https://github.com/RyanCartularo/SepsisSuite-Info

</details>


### [23] [INFORM-CT: INtegrating LLMs and VLMs FOR Incidental Findings Management in Abdominal CT](https://arxiv.org/abs/2512.14732)
*Idan Tankel,Nir Mazor,Rafi Brada,Christina LeBedis,Guy ben-Yosef*

Main category: cs.LG

TL;DR: 이 논문은 복부 CT 스캔의 우연 발견 탐지, 분류 및 보고의 효율성과 정확성을 향상시키기 위해 대형 언어 모델과 비전-언어 모델을 활용한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: CT 스캔의 우연 발견은 비록 대개 무해하지만, 중요한 임상적 의미를 가질 수 있으므로 established guidelines에 따라 보고되어야 한다.

Method: 제안된 방식은 LLM 및 VLM을 활용한 계획-실행 접근 방식을 통해 우연 발견의 탐지 및 처리를 자동화하는 것을 포함한다.

Result: 완전 자동화된 종단 간 방식으로 복부 CT 벤치마크에서 세 개의 장기에 대한 실험을 통해 접근 방식의 효과성을 입증하였다.

Conclusion: 제안된 프레임워크는 기존의 순수 VLM 기반 접근 방식보다 정확성과 효율성 면에서 우수한 성능을 보였다.

Abstract: Incidental findings in CT scans, though often benign, can have significant clinical implications and should be reported following established guidelines. Traditional manual inspection by radiologists is time-consuming and variable. This paper proposes a novel framework that leverages large language models (LLMs) and foundational vision-language models (VLMs) in a plan-and-execute agentic approach to improve the efficiency and precision of incidental findings detection, classification, and reporting for abdominal CT scans. Given medical guidelines for abdominal organs, the process of managing incidental findings is automated through a planner-executor framework. The planner, based on LLM, generates Python scripts using predefined base functions, while the executor runs these scripts to perform the necessary checks and detections, via VLMs, segmentation models, and image processing subroutines.
  We demonstrate the effectiveness of our approach through experiments on a CT abdominal benchmark for three organs, in a fully automatic end-to-end manner. Our results show that the proposed framework outperforms existing pure VLM-based approaches in terms of accuracy and efficiency.

</details>


### [24] [OLR-WA: Online Weighted Average Linear Regression in Multivariate Data Streams](https://arxiv.org/abs/2512.14892)
*Mohammad Abu-Shaira,Alejandro Rodriguez,Greg Speegle,Victor Sheng,Ishfaq Ahmad*

Main category: cs.LG

TL;DR: OLR-WA는 새로운 데이터로 모델을 점진적으로 업데이트하는 다변량 온라인 선형 회귀 모델로, 기존 모델과 비교하여 뛰어난 성능을 보입니다.


<details>
  <summary>Details</summary>
Motivation: 온라인 학습은 새로운 데이터를 통해 모델을 점진적으로 업데이트하여 대규모 저장 공간과 비용이 많이 드는 모델 재계산을 피하도록 돕습니다.

Method: OLR-WA; 가중 평균을 사용한 온라인 회귀라는 새로운 다변량 온라인 선형 회귀 모델을 도입하고, 데이터의 패턴이 시간이 지남에 따라 진화하는 드리프트 시나리오를 조사합니다.

Result: OLR-WA는 배치 회귀와 유사한 성능을 달성하며, 최신 온라인 모델들과 비교했을 때도 동등하거나 더 우수한 성능을 보입니다.

Conclusion: OLR-WA는 빠른 수렴성과 높은 r2 값을 유지하며, 신뢰도가 높은 오래된 데이터에 우선순위를 두는 보수적인 업데이트 방식을 통해 다양한 맥락에서 유용한 솔루션이 됩니다.

Abstract: Online learning updates models incrementally with new data, avoiding large storage requirements and costly model recalculations. In this paper, we introduce "OLR-WA; OnLine Regression with Weighted Average", a novel and versatile multivariate online linear regression model. We also investigate scenarios involving drift, where the underlying patterns in the data evolve over time, conduct convergence analysis, and compare our approach with existing online regression models. The results of OLR-WA demonstrate its ability to achieve performance comparable to the batch regression, while also showcasing comparable or superior performance when compared with other state-of-the-art online models, thus establishing its effectiveness. Moreover, OLR-WA exhibits exceptional performance in terms of rapid convergence, surpassing other online models with consistently achieving high r2 values as a performance measure from the first iteration to the last iteration, even when initialized with minimal amount of data points, as little as 1% to 10% of the total data points. In addition to its ability to handle time-based (temporal drift) scenarios, remarkably, OLR-WA stands out as the only model capable of effectively managing confidence-based challenging scenarios. It achieves this by adopting a conservative approach in its updates, giving priority to older data points with higher confidence levels. In summary, OLR-WA's performance further solidifies its versatility and utility across different contexts, making it a valuable solution for online linear regression tasks.

</details>


### [25] [Imitation Learning for Multi-turn LM Agents via On-policy Expert Corrections](https://arxiv.org/abs/2512.14895)
*Niklas Lauffer,Xiang Deng,Srivatsa Kundurthy,Brad Kenstler,Jeff Da*

Main category: cs.LG

TL;DR: 본 논문은 다중 턴 언어 모델 학습에서 모방 학습의 문제를 해결하기 위한 새로운 데이터 생성 방법론을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 모방 학습은 전문가의 경로에 기반하여 언어 모델 에이전트를 훈련하는 인기 있는 패러다임이지만, 다중 턴 언어 모델 에이전트의 경우 행동 편차로 인한 문제들이 발생한다.

Method: 본 연구는 DAgger 알고리즘에서 영감을 받아, 전문가 수정을 통해 데이터 생성 방법론을 제안하고, 학생 모델로 시작하여 중간에 전문가 모델로 전환하는 부분적으로 정책 기반 데이터(OEC)를 도입한다.

Result: OEC 데이터를 활용한 실험에서 전통적인 모방 학습에 비해 상대적으로 14%와 13%의 향상을 보였으며, SWE-bench에서 검증되었다.

Conclusion: 전문가 시연과 정책 기반 데이터를 결합하여 효과적인 다중 턴 언어 모델 에이전트 훈련의 필요성을 보여준다.

Abstract: A popular paradigm for training LM agents relies on imitation learning, fine-tuning on expert trajectories. However, we show that the off-policy nature of imitation learning for multi-turn LM agents suffers from the fundamental limitation known as covariate shift: as the student policy's behavior diverges from the expert's, it encounters states not present in the training data, reducing the effectiveness of fine-tuning. Taking inspiration from the classic DAgger algorithm, we propose a novel data generation methodology for addressing covariate shift for multi-turn LLM training. We introduce on-policy expert corrections (OECs), partially on-policy data generated by starting rollouts with a student model and then switching to an expert model part way through the trajectory. We explore the effectiveness of our data generation technique in the domain of software engineering (SWE) tasks, a multi-turn setting where LLM agents must interact with a development environment to fix software bugs. Our experiments compare OEC data against various other on-policy and imitation learning approaches on SWE agent problems and train models using a common rejection sampling (i.e., using environment reward) combined with supervised fine-tuning technique. Experiments find that OEC trajectories show a relative 14% and 13% improvement over traditional imitation learning in the 7b and 32b setting, respectively, on SWE-bench verified. Our results demonstrate the need for combining expert demonstrations with on-policy data for effective multi-turn LM agent training.

</details>


### [26] [SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs](https://arxiv.org/abs/2512.15088)
*Xianglin Wu,Chiheb Ben Hammouda,Cornelis W. Oosterlee*

Main category: cs.LG

TL;DR: 이 논문은 분수 브라운 운동에 의해 구동되는 확률 미분 방정식의 매개변수 추정에서 경로 서명을 딥러닝 아키텍처에 통합함으로써 정확도와 모델 복잡성 사이의 균형을 개선할 수 있는지 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 분수 브라운 운동에 의해 구동되는 확률 미분 방정식(SDE)은 거친 동역학 및 장기 의존성을 모델링하는 데 사용됩니다. 그러나 이들 프로세스는 비마르코프적이며 전통적인 매개변수 추정 기법이 적용하기 어렵습니다.

Method: SigMA(서명 다중 헤드 주의) 신경 아키텍처를 도입하여 경로 서명을 다중 헤드 자기 주의와 통합하고, 효과적인 특징 인코딩을 위한 합성곱 전처리 레이어와 다층 퍼셉트론을 지원합니다.

Result: SigMA는 분수 브라운 운동, 분수 오른스틴-울렌벡 및 거친 헤스턴 모델의 합성 경로에서 모델 매개변수를 학습하며, 실제 및 합성 데이터에 대한 실험에서 다른 기법들보다 일관되게 우수한 성과를 냅니다.

Conclusion: 서명 변환과 주의 기반 아키텍처의 결합은 거칠거나 지속적인 시계열 구조를 가진 확률 시스템에서 매개변수 추정을 위한 효과적이고 확장 가능한 프레임워크를 제공합니다.

Abstract: Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a semimartingale structure, rendering many classical parameter estimation techniques inapplicable or computationally intractable beyond very specific cases. This work investigates two central questions: (i) whether integrating path signatures into deep learning architectures can improve the trade-off between estimation accuracy and model complexity, and (ii) what constitutes an effective architecture for leveraging signatures as feature maps. We introduce SigMA (Signature Multi-head Attention), a neural architecture that integrates path signatures with multi-head self-attention, supported by a convolutional preprocessing layer and a multilayer perceptron for effective feature encoding. SigMA learns model parameters from synthetically generated paths of fBm-driven SDEs, including fractional Brownian motion, fractional Ornstein-Uhlenbeck, and rough Heston models, with a particular focus on estimating the Hurst parameter and on joint multi-parameter inference, and it generalizes robustly to unseen trajectories. Extensive experiments on synthetic data and two real-world datasets (i.e., equity-index realized volatility and Li-ion battery degradation) show that SigMA consistently outperforms CNN, LSTM, vanilla Transformer, and Deep Signature baselines in accuracy, robustness, and model compactness. These results demonstrate that combining signature transforms with attention-based architectures provides an effective and scalable framework for parameter inference in stochastic systems with rough or persistent temporal structure.

</details>


### [27] [DEER: Draft with Diffusion, Verify with Autoregressive Models](https://arxiv.org/abs/2512.15176)
*Zicong Cheng,Guo-Wei Yang,Jia Li,Zhijie Deng,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.LG

TL;DR: 이 논문에서는 확산 대형 언어 모델(dLLM)이 기존의 AR 초안 모델들이 가진 신뢰성 누적과 순차적 디코딩 문제를 해결할 수 있음을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 에이전트 및 추론 시스템에서 효율성이 매우 중요한 실제적 도전 과제가 되고 있으며, 이 효율성은 자가 회귀(AR) 디코딩의 고유한 대기 시간으로 인해 점점 제약을 받고 있습니다.

Method: DEER라는 효율적인 추측 디코딩 프레임워크를 도입하고, 확산 모델로 초안을 작성하며 AR 모델로 검증합니다.

Result: DEER는 최대 32토큰의 초안 수용 길이에 도달하며, 이는 EAGLE-3의 10토큰을 훨씬 초과합니다. 또한, Qwen3-30B-A3B를 이용한 HumanEval에서 DEER는 5.54배의 속도 향상을 달성했습니다.

Conclusion: DEER는 효율적인 초안 작성을 위해 두 단계 학습 파이프라인을 사용하여 dLLM 기반의 작성자를 목표 AR 모델에 정렬하고 단일 단계 디코딩을 채택하여 긴 초안 세그먼트를 생성합니다.

Abstract: Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a.k.a., drafters), which introduce two fundamental issues: (1) step-wise uncertainty accumulation leads to a progressive collapse of trust between the target model and the drafter, and (2) inherently sequential decoding of AR drafters. Together, these factors cause limited speedups. In this paper, we show that a diffusion large language model (dLLM) drafters can naturally overcome these issues through its fundamentally different probabilistic modeling and efficient parallel decoding strategy. Building on this insight, we introduce DEER, an efficient speculative decoding framework that drafts with diffusion and verifies with AR models. To enable high-quality drafting, DEER employs a two-stage training pipeline to align the dLLM-based drafters with the target AR model, and further adopts single-step decoding to generate long draft segments. Experiments show DEER reaches draft acceptance lengths of up to 32 tokens, far surpassing the 10 tokens achieved by EAGLE-3. Moreover, on HumanEval with Qwen3-30B-A3B, DEER attains a 5.54x speedup, while EAGLE-3 achieves only 2.41x. Code, model, demo, etc, will be available at https://czc726.github.io/DEER/

</details>


### [28] [Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis](https://arxiv.org/abs/2512.15250)
*Youssef Ghallab,Omar Iraqy,Mohamed Kandil,Mohamed Ashraf,Saadeldine Eletter,Morougue Ghazal,Ayman Khalafallah,Nagwa El-Makky*

Main category: cs.LG

TL;DR: 이 연구에서는 ECG와 EEG 신호의 다중 모달 통합을 위한 접근 방식을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 모달 통합의 어려움은 제한된 레이블이 있는 데이터와 모달리티별 차이에 기인합니다.

Method: CBraMod 인코더를 활용한 대규모 자가 지도 ECG 사전 학습과 이중 마스킹 전략을 도입하여 리드 간 의존성을 포착합니다.

Result: 감정 인식에 대한 평가 결과, 이 접근 방식은 최고 수준의 성능에 근접한 결과를 보였습니다.

Conclusion: 정교하게 설계된 생리학적 인코더는 간단한 융합으로도 다운스트림 성능을 상당히 향상시킬 수 있는 가능성을 보여줍니다.

Abstract: Physiological signals such as electrocardiograms (ECG) and electroencephalograms (EEG) provide complementary insights into human health and cognition, yet multi-modal integration is challenging due to limited multi-modal labeled data, and modality-specific differences . In this work, we adapt the CBraMod encoder for large-scale self-supervised ECG pretraining, introducing a dual-masking strategy to capture intra- and inter-lead dependencies. To overcome the above challenges, we utilize a pre-trained CBraMod encoder for EEG and pre-train a symmetric ECG encoder, equipping each modality with a rich foundational representation. These representations are then fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions, together enabling effective downstream learning despite limited multi-modal supervision. Evaluated on emotion recognition, our approach achieves near state-of-the-art performance, demonstrating that carefully designed physiological encoders, even with straightforward fusion, substantially improve downstream performance. These results highlight the potential of foundation-model approaches to harness the holistic nature of physiological signals, enabling scalable, label-efficient, and generalizable solutions for healthcare and affective computing.

</details>


### [29] [Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery](https://arxiv.org/abs/2512.15344)
*Hiroyoshi Nagahama,Katsufumi Inoue,Masayoshi Todorokihara,Michifumi Yoshioka*

Main category: cs.LG

TL;DR: 회전 기계의 예측 유지보수는 점점 더 진동 신호에 의존하고 있으며, 본 논문에서는 다축 진동 데이터의 무작위 위상 변화를 해결하기 위한 두 가지 위상 인식 전처리 전략을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 회전 기계의 예측 유지보수에서 위상 정보의 중요성이 커지고 있음에도 불구하고 기존 방법들이 위상 정보를 활용하지 않거나 소실하고 있다는 문제를 해결하고자 함.

Method: 세 가지 축의 독립적 위상 조정과 단일 축의 기준 위상 조정을 통해 다축 진동 데이터의 무작위 위상 변화를 처리하는 방법을 제시.

Result: 새롭게 구축된 동기화된 3축 센서로 확보한 로터 데이터셋을 사용하여 여섯 가지 딥러닝 구조를 평가한 결과, 세 가지 축 독립적 방법은 Transformer에서 +2.7%의 일관된 향상을 이끌어냈고, 단일 축 기준 방법은 공간적인 위상 관계를 보존함으로써 최대 96.2%의 정확도(+5.4%)를 기록했다.

Conclusion: 이 연구 결과는 위상 정렬 전략이 예측 유지보수 시스템의 실용적이고 확장 가능한 개선책이라는 것을 확립한다.

Abstract: Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preprocessing strategies to address random phase variations in multi-axis vibration data: (1) three-axis independent phase adjustment that aligns each axis individually to zero phase (2) single-axis reference phase adjustment that preserves inter-axis relationships by applying uniform time shifts. Using a newly constructed rotor dataset acquired with a synchronized three-axis sensor, we evaluate six deep learning architectures under a two-stage learning framework. Results demonstrate architecture-independent improvements: the three-axis independent method achieves consistent gains (+2.7\% for Transformer), while the single-axis reference approach delivers superior performance with up to 96.2\% accuracy (+5.4\%) by preserving spatial phase relationships. These findings establish both phase alignment strategies as practical and scalable enhancements for predictive maintenance systems.

</details>


### [30] [EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning](https://arxiv.org/abs/2512.15405)
*Jianfei Ma,Wee Sun Lee*

Main category: cs.LG

TL;DR: 본 논문에서는 에피스테믹 불확실성을 활용한 베이지안 강화 학습 알고리즘인 EUBRL을 제안하며, 이를 통해 원칙적인 탐색을 달성하고, 예측 오류로부터 발생하는 후회 손실을 적절히 줄일 수 있음을 보입니다.


<details>
  <summary>Details</summary>
Motivation: 에피스테믹 불확실성을 활용하여 탐색과 활용 사이의 균형을 잡기 위함이다.

Method: 베이지안 강화 학습 알고리즘 EUBRL을 제안하고, 이를 통해 탐색 시 에피스테믹 가이드를 활용하여 후회 손실을 줄인다.

Result: EUBRL은 희소 보상, 긴 수명, 확률적 특성이 있는 작업에서 평가되었으며, 샘플 효율성, 확장성 및 일관성에서 우수한 성능을 보여준다.

Conclusion: EUBRL은 무한 수명 할인 마르코프 결정 과정에서 충분히 표현력이 있는 사전 분포를 사용하여 거의 최소 최대 최적의 후회 및 샘플 복잡성을 보장한다.

Abstract: At the boundary between the known and the unknown, an agent inevitably confronts the dilemma of whether to explore or to exploit. Epistemic uncertainty reflects such boundaries, representing systematic uncertainty due to limited knowledge. In this paper, we propose a Bayesian reinforcement learning (RL) algorithm, $\texttt{EUBRL}$, which leverages epistemic guidance to achieve principled exploration. This guidance adaptively reduces per-step regret arising from estimation errors. We establish nearly minimax-optimal regret and sample complexity guarantees for a class of sufficiently expressive priors in infinite-horizon discounted MDPs. Empirically, we evaluate $\texttt{EUBRL}$ on tasks characterized by sparse rewards, long horizons, and stochasticity. Results demonstrate that $\texttt{EUBRL}$ achieves superior sample efficiency, scalability, and consistency.

</details>
