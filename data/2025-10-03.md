<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 4]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.LG](#cs.LG) [Total: 25]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [A Hierarchical Agentic Framework for Autonomous Drone-Based Visual Inspection](https://arxiv.org/abs/2510.00259)
*Ethan Herron,Xian Yeow Lee,Gregory Sin,Teresa Gonzalez Diaz,Ahmed Farahat,Chetan Gupta*

Main category: cs.MA

TL;DR: 이 논문은 산업 자산의 성능과 수명을 보장하는 자율 검사 시스템의 필요성을 강조하고, 물리적 자산에 대한 검사 워크플로우 자동화 가능성을 제시하는 새로운 계층적 에이전트 프레임워크와 개별 기능 실행을 위한 추론 방법론을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 산업 자산의 성능과 수명을 보장하기 위해 자율 검사 시스템이 필수적이며, 최근 에이전틱 프레임워크가 검사 워크플로우 자동화에서 잠재력을 보여주고 있지만, 물리적 자산에 대한 적용은 아직 탐색되지 않았다.

Method: 우리는 자율 드론 제어를 위한 계층적 에이전트 프레임워크와 이를 위한 추론 방법론인 ReActEval을 제안한다. 이 프레임워크는 실내 산업 환경에서의 시각적 검사 작업에 중점을 두며, 머리 에이전트와 여러 작업 에이전트로 이루어진 다중 에이전트 시스템을 사용한다.

Result: 머리 에이전트는 고수준 계획을 수행하고 결과를 평가하며, 작업 에이전트는 ReActEval을 사용하여 저수준 행동을 추론하고 실행한다. 시뮬레이션 환경에서 두 작업 에이전트로 프레임워크를 평가하여 작업 완수 및 워크플로우 효율성을 기준으로 성능을 정성적, 정량적으로 평가하였다.

Conclusion: 자연어 처리를 활용한 에이전트 간 통신을 통해, 본 접근 방식은 전통적인 드론 기반 솔루션에 대한 참신하고 유연하며 사용자 접근 가능한 대안을 제공하여 산업 검사에서 자율적인 문제 해결을 가능하게 한다.

Abstract: Autonomous inspection systems are essential for ensuring the performance and
longevity of industrial assets. Recently, agentic frameworks have demonstrated
significant potential for automating inspection workflows but have been limited
to digital tasks. Their application to physical assets in real-world
environments, however, remains underexplored. In this work, our contributions
are two-fold: first, we propose a hierarchical agentic framework for autonomous
drone control, and second, a reasoning methodology for individual function
executions which we refer to as ReActEval. Our framework focuses on visual
inspection tasks in indoor industrial settings, such as interpreting industrial
readouts or inspecting equipment. It employs a multi-agent system comprising a
head agent and multiple worker agents, each controlling a single drone. The
head agent performs high-level planning and evaluates outcomes, while worker
agents implement ReActEval to reason over and execute low-level actions.
Operating entirely in natural language, ReActEval follows a plan, reason, act,
evaluate cycle, enabling drones to handle tasks ranging from simple navigation
(e.g., flying forward 10 meters and land) to complex high-level tasks (e.g.,
locating and reading a pressure gauge). The evaluation phase serves as a
feedback and/or replanning stage, ensuring actions align with user objectives
while preventing undesirable outcomes. We evaluate the framework in a simulated
environment with two worker agents, assessing performance qualitatively and
quantitatively based on task completion across varying complexity levels and
workflow efficiency. By leveraging natural language processing for agent
communication, our approach offers a novel, flexible, and user-accessible
alternative to traditional drone-based solutions, enabling autonomous
problem-solving for industrial inspection without extensive user intervention.

</details>


### [2] [Reasoning-Aware Prompt Orchestration: A Foundation Model for Multi-Agent Language Model Coordination](https://arxiv.org/abs/2510.00326)
*Hassen Dhrif*

Main category: cs.MA

TL;DR: 본 논문은 다중 전문화 에이전트의 추론 능력을 향상시키기 위한 동적 프롬프트 오케스트레이션의 이론적 기반 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 출현은 정교한 다중 에이전트 시스템을 가능하게 했으나, 프롬프트 엔지니어링을 통한 이들의 추론 능력 조정은 여전히 도전 과제가 되고 있습니다.

Method: 우리의 접근법은 프롬프트 템플릿, 추론 컨텍스트 벡터 및 능력 매트릭스를 사용하여 에이전트 상태를 형식화합니다. 시스템 수렴을 증명하였고, 1000개의 합성 다중 에이전트 대화 실험을 통해 성능을 평가하고 개선을 확인하였습니다.

Result: 실험 결과 42%의 추론 지연 감소, ROUGE-L 점수로 측정한 23%의 논리적 일관성 향상 및 89%의 작업 완료 성공률을 보였습니다.

Conclusion: 이 연구는 다중 에이전트 시스템에서 확장 가능한 추론을 위한 새로운 패러다임을 확립하고, 조정된 언어 모델 간의 추론 출현을 이해하기 위한 이론적 기초를 제공합니다.

Abstract: The emergence of large language models has enabled sophisticated multi-agent
systems, yet coordinating their reasoning capabilities through prompt
engineering remains challenging. We present a theoretically-grounded framework
for dynamic prompt orchestration that enhances reasoning across multiple
specialized agents. This framework addresses three core challenges: logical
consistency preservation during agent transitions, reasoning-aware prompt
adaptation, and scalable coordination of distributed inference.
  Our approach formalizes agent states using prompt templates, reasoning
context vectors, and capability matrices. We prove system convergence to stable
coordination patterns when step sizes satisfy $\alpha < \frac{1}{2L}$ where $L$
is the Lipschitz constant of the state transition function. We implement this
through a distributed architecture that dynamically routes reasoning tasks
while maintaining semantic coherence.
  Experimental results on 1,000 synthetic multi-agent conversations demonstrate
a 42% reduction in reasoning latency, a 23% improvement in logical consistency
measured by ROUGE-L score, and an 89% success rate for task completion without
context loss across agent transitions. Ablation studies identify the consensus
mechanism as the primary performance driver, while revealing limitations:
performance degrades beyond 10 agent transitions, and the system requires
76.5GB memory for 1,000 concurrent agents. These findings establish a new
paradigm for scalable reasoning in multi-agent systems, providing theoretical
foundations for understanding reasoning emergence across coordinated language
models.

</details>


### [3] [Conflict-Based Search as a Protocol: A Multi-Agent Motion Planning Protocol for Heterogeneous Agents, Solvers, and Independent Tasks](https://arxiv.org/abs/2510.00425)
*Rishi Veerapaneni,Alvin Tang,Haodong He,Sophia Zhao,Viraj Shah,Yidai Cen,Ziteng Ji,Gabriel Olin,Jon Arrizabalaga,Yorai Shaoul,Jiaoyang Li,Maxim Likhachev*

Main category: cs.MA

TL;DR: 로봇들이 서로 다른 제조사로부터 구매된 다양한 환경에서 안전하게 상호작용하고 이동할 수 있도록 하는 해결책을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 미래 건설 현장, 병원, 사무실, 가정에서 서로 다른 제조사로부터 온 여러 로봇들이 효과적으로 움직일 수 있는 방법을 탐구합니다.

Method: Conflict-Based Search(CBS) 프로토콜을 사용하여 알고리즘적으로 이질적인 에이전트 간의 충돌 없는 움직임을 달성하는 방법을 제시합니다.

Result: CBS 프로토콜을 통해 다양한 싱글 에이전트 플래너와 함께 다중 에이전트 모션 플래닝을 가능하게 합니다.

Conclusion: CBS는 독립적인 작업을 수행하는 이질적인 에이전트 팀을 위한 다중 에이전트 모션 계획을 지원합니다.

Abstract: Imagine the future construction site, hospital, office, or even sophisticated
household with dozens of robots bought from different manufacturers. How can we
enable these different systems to effectively move in a shared environment,
given that each robot may have its own independent motion planning system? This
work shows how we can get efficient collision-free movements between
algorithmically heterogeneous agents by using Conflict-Based Search (Sharon et
al. 2015) as a protocol. At its core, the CBS Protocol requires one specific
single-agent motion planning API; finding a collision-free path that satisfies
certain space-time constraints. Given such an API, CBS uses a central planner
to find collision-free paths - independent of how the API is implemented. We
show how this protocol enables multi-agent motion planning for a heterogeneous
team of agents completing independent tasks with a variety of single-agent
planners including: Heuristic Search (e.g., A*), Sampling Based Search (e.g.,
RRT), Optimization (e.g., Direct Collocation), Diffusion, and Reinforcement
Learning.

</details>


### [4] [Stochastic Self-Organization in Multi-Agent Systems](https://arxiv.org/abs/2510.00685)
*Nurbek Tastan,Samuel Horvath,Karthik Nandakumar*

Main category: cs.MA

TL;DR: 대형 언어 모델 기반의 다중 에이전트 시스템은 단일 모델로는 해결할 수 없는 작업을 수행할 수 있지만, 가장 효과적인 협업 메커니즘을 최적화했을 경우에만 이 가능성이 실현된다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템이 단일 LLM으로는 할 수 없는 작업을 수행할 수 있다는 잠재력을 가지고 있지만, 에이전트 간의 커뮤니케이션 구조 최적화가 필요하다.

Method: 에이전트들이 독립적으로 사용자 질의에 대한 응답을 생성하고 동료 기여도를 샤플리 값을 근사하여 평가하는 반응 조건형 프레임워크를 도입하였다.

Result: 다이렉티드 비순환 그래프(DAG)를 구축하여 에이전트 간의 응답 전파를 규제하며, 이전 협업 라운드의 에이전트 응답에 따라 동적으로 업데이트된다.

Conclusion: SelfOrg 프레임워크는 추가적인 감독이나 훈련 없이 에이전트의 자율적 조직화를 가능하게 하며, 여러 에이전트가 정답성을 높이고 올바른 응답이 정보 흐름을 지배하게 된다는 것을 이론적으로 보여준다.

Abstract: Multi-agent systems (MAS) based on Large Language Models (LLMs) have the
potential to solve tasks that are beyond the reach of any single LLM. However,
this potential can only be realized when the collaboration mechanism between
agents is optimized. Specifically, optimizing the communication structure
between agents is critical for fruitful collaboration. Most existing approaches
rely on fixed topologies, pretrained graph generators, optimization over edges,
or employ external LLM judges, thereby adding to the complexity. In this work,
we introduce a response-conditioned framework that adapts communication
on-the-fly. Agents independently generate responses to the user query and
assess peer contributions using an approximation of the Shapley value. A
directed acyclic graph (DAG) is then constructed to regulate the propagation of
the responses among agents, which ensures stable and efficient message
transmission from high-contributing agents to others. This graph is dynamically
updated based on the agent responses from the previous collaboration round.
Since the proposed framework enables the self-organization of agents without
additional supervision or training, we refer to it as SelfOrg. The SelfOrg
framework goes beyond task- and query-level optimization and takes into account
the stochastic nature of agent responses. Experiments with both strong and weak
LLM backends demonstrate robust performance, with significant gains in the weak
regime where prior methods collapse. We also theoretically show that multiple
agents increase the chance of correctness and that the correct responses
naturally dominate the information flow.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [5] [CHAI: Command Hijacking against embodied AI](https://arxiv.org/abs/2510.00181)
*Luis Burbano,Diego Ortiz,Qi Sun,Siwei Yang,Haoqin Tu,Cihang Xie,Yinzhi Cao,Alvaro A Cardenas*

Main category: cs.CR

TL;DR: CHAI는 다중 모달 언어 해석 능력을 이용한 새로운 공격 방법론으로, 로봇 차량 시스템의 보안 위험을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: 임베디드 AI는 데이터가 부족한 상황에서 일반화 및 적응 능력을 통해 로봇 시스템의 엣지 케이스를 처리할 것으로 기대되지만, 이러한 능력이 새로운 보안 위험을 초래할 수 있습니다.

Method: CHAI는 자연어 명령을 시각 입력에 삽입하고, 토큰 공간을 체계적으로 탐색하여 프롬프트 사전을 구축한 후, 공격자 모델이 시각 공격 프롬프트를 생성하도록 유도하는 프롬프트 기반 공격 방법입니다.

Result: CHAI는 드론 비상 착륙, 자율 주행, 공중 물체 추적 등 4개의 LVLM 에이전트 및 실제 로봇 차량에서 평가되었으며, 기존의 최첨단 공격보다 일관되게 뛰어난 성능을 보였습니다.

Conclusion: CHAI는 차세대 임베디드 AI 시스템의 의미론적 및 다중 모달 추론 강점을 활용하여, 전통적인 적대적 강건성을 넘어서는 방어의 필요성을 강조합니다.

Abstract: Embodied Artificial Intelligence (AI) promises to handle edge cases in
robotic vehicle systems where data is scarce by using common-sense reasoning
grounded in perception and action to generalize beyond training distributions
and adapt to novel real-world situations. These capabilities, however, also
create new security risks. In this paper, we introduce CHAI (Command Hijacking
against embodied AI), a new class of prompt-based attacks that exploit the
multimodal language interpretation abilities of Large Visual-Language Models
(LVLMs). CHAI embeds deceptive natural language instructions, such as
misleading signs, in visual input, systematically searches the token space,
builds a dictionary of prompts, and guides an attacker model to generate Visual
Attack Prompts. We evaluate CHAI on four LVLM agents; drone emergency landing,
autonomous driving, and aerial object tracking, and on a real robotic vehicle.
Our experiments show that CHAI consistently outperforms state-of-the-art
attacks. By exploiting the semantic and multimodal reasoning strengths of
next-generation embodied AI systems, CHAI underscores the urgent need for
defenses that extend beyond traditional adversarial robustness.

</details>


### [6] [SecureBERT 2.0: Advanced Language Model for Cybersecurity Intelligence](https://arxiv.org/abs/2510.00240)
*Ehsan Aghaei,Sarthak Jain,Prashanth Arun,Arjun Sambamoorthy*

Main category: cs.CR

TL;DR: SecureBERT 2.0는 사이버 보안 응용 프로그램을 위해 설계된 향상된 언어 모델로, 전문 용어와 복잡한 문서 구조를 해석할 수 있도록 최적화됨.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 및 위협 인텔리전스 데이터를 효과적으로 분석하기 위해서는 전문 용어와 자연어 및 소스 코드 간의 상호 의존성을 해석할 수 있는 언어 모델이 필요하다.

Method: SecureBERT 2.0는 ModernBERT 아키텍처를 활용하여 향상된 긴 맥락 모델링과 계층적 인코딩을 도입하여 위협 보고서 및 소스 코드 아티팩트를 포함한 다양한 문서를 효과적으로 처리하도록 설계되었다.

Result: SecureBERT 2.0는 130억 개 이상의 텍스트 토큰과 5300만 개의 코드 토큰으로 구성된 도메인 특정 말뭉치에서 13배 이상 사전 훈련되어 있으며, 여러 사이버 보안 벤치마크에서 최첨단 성능을 달성하였다.

Conclusion: 실험 결과는 사이버 보안 도메인에서 위협 인텔리전스에 대한 의미 검색, 의미 분석, 사이버 보안 특정 명명된 개체 인식 및 코드 내 자동 취약점 탐지에서 상당한 개선을 보여준다.

Abstract: Effective analysis of cybersecurity and threat intelligence data demands
language models that can interpret specialized terminology, complex document
structures, and the interdependence of natural language and source code.
Encoder-only transformer architectures provide efficient and robust
representations that support critical tasks such as semantic search, technical
entity extraction, and semantic analysis, which are key to automated threat
detection, incident triage, and vulnerability assessment. However,
general-purpose language models often lack the domain-specific adaptation
required for high precision. We present SecureBERT 2.0, an enhanced
encoder-only language model purpose-built for cybersecurity applications.
Leveraging the ModernBERT architecture, SecureBERT 2.0 introduces improved
long-context modeling and hierarchical encoding, enabling effective processing
of extended and heterogeneous documents, including threat reports and source
code artifacts. Pretrained on a domain-specific corpus more than thirteen times
larger than its predecessor, comprising over 13 billion text tokens and 53
million code tokens from diverse real-world sources, SecureBERT 2.0 achieves
state-of-the-art performance on multiple cybersecurity benchmarks. Experimental
results demonstrate substantial improvements in semantic search for threat
intelligence, semantic analysis, cybersecurity-specific named entity
recognition, and automated vulnerability detection in code within the
cybersecurity domain.

</details>


### [7] [MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement](https://arxiv.org/abs/2510.00317)
*Youpeng Li,Kartik Joshi,Xinda Wang,Eric Wong*

Main category: cs.CR

TL;DR: MAVUL은 맥락적 추론과 상호작용 정제를 통합한 다중 에이전트 취약점 탐지 시스템으로, 기존 시스템보다 성능이 뛰어난 것으로 나타났다.


<details>
  <summary>Details</summary>
Motivation: OSS의 광범위한 채택으로 인해 취약점 위험을 완화할 필요성이 있다.

Method: MAVUL은 맥락적 추론과 상호작용 정제를 통합하여 다중 에이전트 방식으로 취약점을 탐지한다.

Result: MAVUL은 기존 다중 에이전트 시스템보다 62% 이상 높은 정확도를 보였고, 단일 에이전트 시스템보다 600% 이상 높은 평균 성과를 기록했다.

Conclusion: MAVUL은 취약점 흐름 추적에서 맥락적 추론의 중요성을 강조하며, 편향 없는 평가 에이전트를 통해 시스템의 실제 적용 가능성을 더 정확하게 보장한다.

Abstract: The widespread adoption of open-source software (OSS) necessitates the
mitigation of vulnerability risks. Most vulnerability detection (VD) methods
are limited by inadequate contextual understanding, restrictive single-round
interactions, and coarse-grained evaluations, resulting in undesired model
performance and biased evaluation results. To address these challenges, we
propose MAVUL, a novel multi-agent VD system that integrates contextual
reasoning and interactive refinement. Specifically, a vulnerability analyst
agent is designed to flexibly leverage tool-using capabilities and contextual
reasoning to achieve cross-procedural code understanding and effectively mine
vulnerability patterns. Through iterative feedback and refined decision-making
within cross-role agent interactions, the system achieves reliable reasoning
and vulnerability prediction. Furthermore, MAVUL introduces multi-dimensional
ground truth information for fine-grained evaluation, thereby enhancing
evaluation accuracy and reliability.
  Extensive experiments conducted on a pairwise vulnerability dataset
demonstrate MAVUL's superior performance. Our findings indicate that MAVUL
significantly outperforms existing multi-agent systems with over 62% higher
pairwise accuracy and single-agent systems with over 600% higher average
performance. The system's effectiveness is markedly improved with increased
communication rounds between the vulnerability analyst agent and the security
architect agent, underscoring the importance of contextual reasoning in tracing
vulnerability flows and the crucial feedback role. Additionally, the integrated
evaluation agent serves as a critical, unbiased judge, ensuring a more accurate
and reliable estimation of the system's real-world applicability by preventing
misleading binary comparisons.

</details>


### [8] [A Call to Action for a Secure-by-Design Generative AI Paradigm](https://arxiv.org/abs/2510.00451)
*Dalal Alharthi,Ivan Roberto Kawaminami Garcia*

Main category: cs.CR

TL;DR: 대규모 언어 모델의 보안을 위한 PromptShield 프레임워크를 제안하고, 애저 투점 공격에 대한 대응을 통해 모델의 보안성과 성능을 향상시키는 방법을 검토한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델이 프롬프트 주입 공격 및 기타 적대적 공격에 취약한 문제를 해결하고, 성능을 향상시키기 위한 디자인 보안 AI 패러다임을 주장한다.

Method: PromptShield라는 온톨로지 기반 프레임워크를 도입하여 결정론적이고 안전한 프롬프트 상호작용을 보장하고, 사용자 입력을 의미론적 검증을 통해 표준화한다.

Result: PromptShield 배치 전후의 실험 결과, 모델의 보안성과 성능이 크게 향상되어 약 94%의 정밀도, 재현율, F1 점수를 달성했다.

Conclusion: PromptShield는 적대적 위협을 줄이는 동시에 시스템의 전반적인 성능과 신뢰성을 높이며, 다양한 분야에 걸쳐 생성형 AI 애플리케이션을 보호할 수 있는 강력한 솔루션이다.

Abstract: Large language models have gained widespread prominence, yet their
vulnerability to prompt injection and other adversarial attacks remains a
critical concern. This paper argues for a security-by-design AI paradigm that
proactively mitigates LLM vulnerabilities while enhancing performance. To
achieve this, we introduce PromptShield, an ontology-driven framework that
ensures deterministic and secure prompt interactions. It standardizes user
inputs through semantic validation, eliminating ambiguity and mitigating
adversarial manipulation. To assess PromptShield's security and performance
capabilities, we conducted an experiment on an agent-based system to analyze
cloud logs within Amazon Web Services (AWS), containing 493 distinct events
related to malicious activities and anomalies. By simulating prompt injection
attacks and assessing the impact of deploying PromptShield, our results
demonstrate a significant improvement in model security and performance,
achieving precision, recall, and F1 scores of approximately 94%. Notably, the
ontology-based framework not only mitigates adversarial threats but also
enhances the overall performance and reliability of the system. Furthermore,
PromptShield's modular and adaptable design ensures its applicability beyond
cloud security, making it a robust solution for safeguarding generative AI
applications across various domains. By laying the groundwork for AI safety
standards and informing future policy development, this work stimulates a
crucial dialogue on the pivotal role of deterministic prompt engineering and
ontology-based validation in ensuring the safe and responsible deployment of
LLMs in high-stakes environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Learning to Lead Themselves: Agentic AI in MAS using MARL](https://arxiv.org/abs/2510.00022)
*Ansh Kamthan*

Main category: cs.AI

TL;DR: 자율 시스템이 프로토타입에서 실제 배포로 이동함에 따라 여러 에이전트의 분산 협력 결정을 내리는 능력이 핵심 요구 사항이 된다. 이 논문은 독립적이고 적응적이며 선제적으로 행동하는 에이전트인 에이전틱 인공지능이 다중 에이전트 시스템에서 작업 할당 및 조정을 개선할 수 있는 방법을 조사한다.


<details>
  <summary>Details</summary>
Motivation: 자율 시스템의 상용화가 진행됨에 따라 분산적이고 협력적인 결정 능력이 필수적이다.

Method: 협력적인 다중 에이전트 강화 학습 환경에서 문제를 정의하고, 중앙 집중 훈련 및 분산 실행 패러다임 아래 IPPO라는 경량 다중 에이전트 근접 정책 최적화 방법을 PyTorch에서 구현한다.

Result: PettingZoo 환경에서 실험을 수행하며, 여러 동질의 드론 또는 에이전트가 명시적인 통신 없이 서로 다른 목표를 커버하기 위해 스스로 조직해야 한다.

Conclusion: 이 연구는 에이전틱 인공지능이 다중 에이전트 시스템에서 작업 할당 및 조정의 효율을 어떻게 개선할 수 있는지를 보여준다.

Abstract: As autonomous systems move from prototypes to real deployments, the ability
of multiple agents to make decentralized, cooperative decisions becomes a core
requirement. This paper examines how agentic artificial intelligence, agents
that act independently, adaptively and proactively can improve task allocation
and coordination in multi-agent systems, with primary emphasis on drone
delivery and secondary relevance to warehouse automation. We formulate the
problem in a cooperative multi-agent reinforcement learning setting and
implement a lightweight multi-agent Proximal Policy Optimization, called IPPO,
approach in PyTorch under a centralized-training, decentralized-execution
paradigm. Experiments are conducted in PettingZoo environment, where multiple
homogeneous drones or agents must self-organize to cover distinct targets
without explicit communication.

</details>


### [10] [ToolBrain: A Flexible Reinforcement Learning Framework for Agentic Tools](https://arxiv.org/abs/2510.00023)
*Quy Minh Le,Minh Sao Khue Luu,Khanh-Tung Tran,Duc-Hai Nguyen,Hoang-Quoc-Viet Pham,Quan Le,Hoang Thanh Lam,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: ToolBrain은 에이전트 모델에서 도구 사용을 코칭하기 위한 가벼운 프레임워크로, 사용자 친화적이며 유연한 강화 학습을 통해 LLM 기반 에이전트를 특정 도메인에 적합하게 조정하는 데 도움을 준다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 AI를 위한 효과적인 도구 사용이 필수적이지만, 수동으로 설계된 보상, 제한된 훈련 데이터, 다중 도구 선택의 어려움으로 인해 에이전트가 도구를 활용하도록 훈련하는 데 어려움이 있다.

Method: ToolBrain은 GRPO 및 DPO와 같은 RL 알고리즘과 감독 학습을 포함한 다양한 훈련 전략을 지원하며, 에이전트의 실행 추적에서 사용자 정의 보상 호출을 가능하게 하거나 자동화된 LLM-판사 시스템을 통한 보상 생성을 지원한다.

Result: ToolBrain을 이용하여 CodeAct 에이전트를 훈련시켰으며, 이메일 검색 작업을 자율적으로 수행할 수 있도록 하여 도구 사용 기술에서 빠르고 목표 지향적인 향상(최대 30.0%)을 보였다.

Conclusion: ToolBrain 프레임워크는 공개적으로 사용 가능하며, 간단하면서도 확장 가능한 코드베이스를 유지할 수 있도록 지원한다.

Abstract: Effective tool use is essential for agentic AI, yet training agents to
utilize tools remains challenging due to manually designed rewards, limited
training data, and poor multi-tool selection, resulting in slow adaptation,
wasted computational resources, and suboptimal performance. We introduce
ToolBrain, a lightweight and user-friendly framework for coaching tool use in
agentic models with flexible reinforcement learning (RL), easing the barriers
for researchers and practitioners to adapt LLM-based agents to specific
domains. It supports a wide range of training strategies, including RL
algorithms such as GRPO and DPO, as well as supervised learning. ToolBrain
enables custom reward callables directly on an agent's execution traces or
simply utilizes an automated LLM-as-a-judge system for reward generation. It is
packed with useful capabilities, including knowledge distillation from large to
small models for efficient development, automatic task generation from tool
descriptions, seamless tool retrieval, efficient fine-tuning pipelines with
QLoRA through Unsloth, and quantized inference via bitsandbytes. We demonstrate
ToolBrain through diverse use cases, such as training a CodeAct agent to
autonomously execute email search tasks, showing fast, targeted improvements
(up to 30.0%) in tool-use skills while keeping the codebase simple and
extensible in Agentic AI. Our framework is publicly available at
https://toolbrain.org.

</details>


### [11] [MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning](https://arxiv.org/abs/2510.00274)
*Maisha Maliha,Dean Hougen*

Main category: cs.AI

TL;DR: MAGIC-MASK는 다중 에이전트 강화 학습을 위한 새로운 설명 가능성 프레임워크로, 비틀림 기반 설명을 확장하여 에이전트 간 협업과 가벼운 중재를 통합하여 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 안전이 중요한 다중 에이전트 환경에서 딥 강화 학습 시스템을 배치하기 위해 의사결정 과정을 이해하는 것이 중요하다.

Method: MAGIC-MASK 프레임워크는 주변 주도 정책 최적화, 적응형 엡실론-탐사 및 경량의 에이전트 간 협업을 통합하여 마스킹된 상태 정보를 공유하고 동료 경험을 교환한다.

Result: MAGIC-MASK는 다양한 벤치마크에서 주요 상태 발견 시간 단축, 설명 충실도 향상 및 학습 속도 증가를 통해 기존 최첨단 방법을 초과 달성한다.

Conclusion: MAGIC-MASK는 단일 에이전트 시스템에서 다중 에이전트 시스템으로의 설명 가능성을 일반화함으로써 더 나은 학습 및 해석 가능성을 제공한다.

Abstract: Understanding the decision-making process of Deep Reinforcement Learning
agents remains a key challenge for deploying these systems in safety-critical
and multi-agent environments. While prior explainability methods like
StateMask, have advanced the identification of critical states, they remain
limited by computational cost, exploration coverage, and lack of adaptation to
multi-agent settings. To overcome these limitations, we propose a
mathematically grounded framework, MAGIC-MASK (Multi-Agent Guided Inter-agent
Collaboration with Mask-Based Explainability for Reinforcement Learning), that
extends perturbation-based explanation to Multi-Agent Reinforcement Learning.
Our method integrates Proximal Policy Optimization, adaptive epsilon-greedy
exploration, and lightweight inter-agent collaboration to share masked state
information and peer experience. This collaboration enables each agent to
perform saliency-guided masking and share reward-based insights with peers,
reducing the time required for critical state discovery, improving explanation
fidelity, and leading to faster and more robust learning. The core novelty of
our approach lies in generalizing explainability from single-agent to
multi-agent systems through a unified mathematical formalism built on
trajectory perturbation, reward fidelity analysis, and Kullback-Leibler
divergence regularization. This framework yields localized, interpretable
explanations grounded in probabilistic modeling and multi-agent Markov decision
processes. We validate our framework on both single-agent and multi-agent
benchmarks, including a multi-agent highway driving environment and Google
Research Football, demonstrating that MAGIC-MASK consistently outperforms
state-of-the-art baselines in fidelity, learning efficiency, and policy
robustness while offering interpretable and transferable explanations.

</details>


### [12] [AuditAgent: Expert-Guided Multi-Agent Reasoning for Cross-Document Fraudulent Evidence Discovery](https://arxiv.org/abs/2510.00156)
*Songran Bai,Bingzhe Wu,Yiwei Zhang,Chengke Wu,Xiaolong Zheng,Yaze Yuan,Ke Wu,Jianqiang Li*

Main category: cs.AI

TL;DR: 본 연구는 재무 사기 탐지를 위한 새로운 다중 에이전트 추론 프레임워크인 AuditAgent를 제안하며, 이는 감사 도메인 전문성을 활용해 정밀한 증거 사슬 로컬라이제이션을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 재무 사기 탐지는 복잡하고 여러 해에 걸쳐 분산된 증거로 인해 상당한 도전 과제를 안고 있다.

Method: 중국 증권 규제 위원회가 발표한 집행 문서 및 재무 보고서에서 구축된 전문가 주석 데이터셋을 활용하여 주제별 위험 우선순위, 하이브리드 검색 전략 및 특화된 에이전트 모듈을 통합한 방법.

Result: 우리의 방법은 일반 목적의 에이전트 패러다임에 비해 리콜과 해석 가능성 모두에서 일관되게 우수한 성능을 나타냈다.

Conclusion: 이 연구는 실용적인 규제 응용 프로그램에서 강력한 재무 사기 탐지를 발전시키기 위해 도메인 특화 추론과 데이터셋 구축의 가치를 강조한다.

Abstract: Financial fraud detection in real-world scenarios presents significant
challenges due to the subtlety and dispersion of evidence across complex,
multi-year financial disclosures. In this work, we introduce a novel
multi-agent reasoning framework AuditAgent, enhanced with auditing domain
expertise, for fine-grained evidence chain localization in financial fraud
cases. Leveraging an expert-annotated dataset constructed from enforcement
documents and financial reports released by the China Securities Regulatory
Commission, our approach integrates subject-level risk priors, a hybrid
retrieval strategy, and specialized agent modules to efficiently identify and
aggregate cross-report evidence. Extensive experiments demonstrate that our
method substantially outperforms General-Purpose Agent paradigm in both recall
and interpretability, establishing a new benchmark for automated, transparent
financial forensics. Our results highlight the value of domain-specific
reasoning and dataset construction for advancing robust financial fraud
detection in practical, real-world regulatory applications.

</details>


### [13] [DualTune: Decoupled Fine-Tuning for On-Device Agentic Systems](https://arxiv.org/abs/2510.00229)
*Rohan Kadekodi,Zhan Jin,Keisuke Kamahori,Yile Gu,Sean Khatiri,Noah H. Bayindirli,Sergey Gorbunov,Baris Kasikci*

Main category: cs.AI

TL;DR: 이 논문은 도구 호출 과제를 도구 선택과 인수 생성의 두 가지 개별 하위 과제로 분해하는 방법론을 소개하고, 이를 통해 로컬 모델에서 효율적인 에이전트 오케스트레이션을 수행하는 DualTune 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 사용이 작업 자동화를 혁신했지만, 프라이버시 보호와 비용 효율적인 솔루션에 대한 필요성으로 인해 장치 내 추론 기능이 요구됩니다.

Method: 도구 호출 과제를 도구 선택과 인수 생성의 두 개의 뚜렷한 하위 작업으로 분리한 후, LoRA 미세 조정을 활용하여 각 하위 작업에 대한 전용 LoRA 어댑터를 생성하는 '이탈 미세 조정' 방법론을 제안합니다. 또한 DualTune이라는 추론 프레임워크를 발표합니다. 이 프레임워크는 로컬 모델을 사용하여 효율적인 에이전트 오케스트레이션을 수행합니다.

Result: MCP-Bench 벤치마크에서 확보한 실험 결과에 따르면, 이탈 미세 조정으로 훈련된 Qwen-2.5-7B 모델은 기본 모델의 도구 호출 정확도를 46% 향상시키며, 유사한 크기의 다른 로컬 추론, 비추론 및 미세 조정 모델에 비해 모든 경우에서 우수한 성능을 보입니다.

Conclusion: DualTune은 도구 선택에 필요한 도구 수를 제한하기 위해 계층적 오케스트레이션을 구현합니다.

Abstract: The deployment of Large Language Models (LLMs) as agentic orchestrators has
revolutionized task automation, but the need for privacy-preserving,
cost-effective solutions demands on-device inference capabilities. However,
local LLMs consistently underperform compared to frontier models in tool
calling scenarios, struggling with both tool selection from large tool sets and
accurate argument generation for complex parameter structures. We introduce a
methodology that disaggregates a tool-calling task into two distinct subtasks:
tool selection and argument generation. We propose "decoupled fine-tuning", a
novel post-training approach that employs LoRA fine-tuning to create dedicated
LoRA adapters for tool selection and tool-specific argument generation using
separate loss masking for each of the subtasks. Furthermore, we present
DualTune, an inference framework that leverages the LoRA adapters created using
decoupled fine-tuning to perform efficient agent orchestration with the help of
local models on end-user devices. DualTune decomposes the tool-call generation
step into tool selection and argument generation, and dynamically loads the
corresponding LoRA adapters to generate tool calls. Additionally, DualTune
implements hierarchical orchestration to restrict the number of tools required
for tool selection. Our experiments on the MCP-Bench benchmark demonstrate that
the Qwen-2.5-7B model trained using decoupled fine-tuning improves the tool
calling accuracy of the base model by 46%, and outperforms other local
reasoning, non-reasoning and fine-tuned models of similar size in all cases,
and models that are 2x larger, in most cases.

</details>


### [14] [ICL Optimized Fragility](https://arxiv.org/abs/2510.00300)
*Serena Gomez Wannaz*

Main category: cs.AI

TL;DR: 이 연구는 ICL 가이드가 다양한 지식 도메인에서의 추론에 미치는 영향을 조사하였다.


<details>
  <summary>Details</summary>
Motivation: ICL 가이드가 특정 작업 성능을 향상시키는 것으로 알려져 있지만, 교차 도메인 인지 능력에 대한 영향은 아직 연구되지 않았다.

Method: 이 연구는 GPT-OSS:20b 모델의 여섯 가지 변형을 사용하여 ICL 가이드가 추론에 미치는 영향을 분석하였다.

Result: 통계 분석(ANOVA)은 ICL 변형 간의 유의미한 행동 변화를 발견하였으며, ICL 모델은 일반 지식 작업에서 91%-99%의 정확도를 달성했지만 복잡한 추론 문제에서는 정확도가 10-43%로 떨어졌다.

Conclusion: 이 연구는 ICL 가이드가 효율성과 추론의 유연성 간의 체계적 거래를 창출함을 나타내며, 이는 LLM 배치 및 AI 안전성에 중요한 의미를 가진다.

Abstract: ICL guides are known to improve task-specific performance, but their impact
on cross-domain cognitive abilities remains unexplored. This study examines how
ICL guides affect reasoning across different knowledge domains using six
variants of the GPT-OSS:20b model: one baseline model and five ICL
configurations (simple, chain-of-thought, random, appended text, and symbolic
language). The models were subjected to 840 tests spanning general knowledge
questions, logic riddles, and a mathematical olympiad problem. Statistical
analysis (ANOVA) revealed significant behavioral modifications (p less than
0.001) across ICL variants, demonstrating a phenomenon termed "optimized
fragility." ICL models achieved 91%-99% accuracy on general knowledge tasks
while showing degraded performance on complex reasoning problems, with accuracy
dropping to 10-43% on riddles compared to 43% for the baseline model. Notably,
no significant differences emerged on the olympiad problem (p=0.2173),
suggesting that complex mathematical reasoning remains unaffected by ICL
optimization. These findings indicate that ICL guides create systematic
trade-offs between efficiency and reasoning flexibility, with important
implications for LLM deployment and AI safety.

</details>


### [15] [Exploring Network-Knowledge Graph Duality: A Case Study in Agentic Supply Chain Risk Analysis](https://arxiv.org/abs/2510.01115)
*Evan Heus,Rick Bookstaber,Dhruv Sharma*

Main category: cs.AI

TL;DR: LLM을 활용한 공급망 리스크 분석 프레임워크 제안.


<details>
  <summary>Details</summary>
Motivation: 재무 리스크의 복잡한 다중 모드 및 네트워크 기반 데이터의 분석이 필요하다.

Method: 공급망 네트워크를 지식 그래프(KG)로 간주하고, 네트워크 중심성 점수에 의해 유도된 그래프 탐색기를 통해 리스크 경로를 추출한다.

Result: 양질의 리스크 내러티브 생성을 위한 효율적인 데이터 처리 방식 개발.

Conclusion: 비용 효율적이며 실시간으로 설명 가능한 리스크 내러티브를 생성하는 경량 접근법 제안.

Abstract: Large Language Models (LLMs) struggle with the complex, multi-modal, and
network-native data underlying financial risk. Standard Retrieval-Augmented
Generation (RAG) oversimplifies relationships, while specialist models are
costly and static. We address this gap with an LLM-centric agent framework for
supply chain risk analysis. Our core contribution is to exploit the inherent
duality between networks and knowledge graphs (KG). We treat the supply chain
network as a KG, allowing us to use structural network science principles for
retrieval. A graph traverser, guided by network centrality scores, efficiently
extracts the most economically salient risk paths. An agentic architecture
orchestrates this graph retrieval alongside data from numerical factor tables
and news streams. Crucially, it employs novel ``context shells'' -- descriptive
templates that embed raw figures in natural language -- to make quantitative
data fully intelligible to the LLM. This lightweight approach enables the model
to generate concise, explainable, and context-rich risk narratives in real-time
without costly fine-tuning or a dedicated graph database.

</details>


### [16] [BiasBusters: Uncovering and Mitigating Tool Selection Bias in Large Language Models](https://arxiv.org/abs/2510.00307)
*Thierry Blankenstein,Jialin Yu,Zixuan Li,Vassilis Plachouras,Sunando Sengupta,Philip Torr,Yarin Gal,Alasdair Paren,Adel Bibi*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)에 기반한 에이전트는 종종 여러 공급자가 기능적으로 동등한 옵션을 제공하는 외부 도구에 의존합니다. 이로 인해 선택의 편향이 발생할 수 있으며, 이는 사용자 경험을 저해하고 경쟁을 왜곡시킬 수 있습니다.


<details>
  <summary>Details</summary>
Motivation: 도구 선택의 편향이 사용자 경험에 미치는 영향을 평가하기 위해 다양한 도구 카테고리의 벤치마크를 도입합니다.

Method: 일곱 개 모델을 테스트하고, 도구의 특징, 메타 데이터(이름, 설명, 매개변수), 사전 훈련 노출 등을 조사하는 통제된 실험을 수행합니다.

Result: 모델은 특정 공급자에 집착하거나 문맥 내에서 초기 목록에 나열된 도구를 불균형적으로 선호하는 불공정성을 드러냅니다.

Conclusion: 첫째, 쿼리와 메타데이터 간의 의미적 정렬이 선택의 가장 강력한 예측 변수입니다. 둘째, 설명을 변형하면 선택이 상당히 변화합니다. 셋째, 단일 엔드포인트에 대한 반복적인 사전 훈련 노출이 편향을 증폭시킵니다. 마지막으로, 후보 도구를 관련 하위 집합으로 필터링하고 균등하게 샘플링하는 경량화된 완화 방안을 제안합니다. 우리의 발견은 도구 선택 편향이 도구 보강 LLM의 공정한 배치를 위한 주요 장애물임을 강조합니다.

Abstract: Agents backed by large language models (LLMs) often rely on external tools
drawn from marketplaces where multiple providers offer functionally equivalent
options. This raises a critical point concerning fairness: if selection is
systematically biased, it can degrade user experience and distort competition
by privileging some providers over others. We introduce a benchmark of diverse
tool categories, each containing multiple functionally equivalent tools, to
evaluate tool-selection bias. Using this benchmark, we test seven models and
show that unfairness exists with models either fixating on a single provider or
disproportionately preferring earlier-listed tools in context. To investigate
the origins of this bias, we conduct controlled experiments examining tool
features, metadata (name, description, parameters), and pre-training exposure.
We find that: (1) semantic alignment between queries and metadata is the
strongest predictor of choice; (2) perturbing descriptions significantly shifts
selections; and (3) repeated pre-training exposure to a single endpoint
amplifies bias. Finally, we propose a lightweight mitigation that first filters
the candidate tools to a relevant subset and then samples uniformly, reducing
bias while preserving good task coverage. Our findings highlight tool-selection
bias as a key obstacle for the fair deployment of tool-augmented LLMs.

</details>


### [17] [When Hallucination Costs Millions: Benchmarking AI Agents in High-Stakes Adversarial Financial Markets](https://arxiv.org/abs/2510.00332)
*Zeshi Dai,Zimo Peng,Zerui Cheng,Ryan Yihe Li*

Main category: cs.AI

TL;DR: CAIA는 AI 평가의 중요한 맹점을 노출하는 벤치마크로, 최신 모델이 허위 정보가 무기화되고 오류가 돌이킬 수 없는 적대적 고위험 환경에서 제대로 작동하지 못하는 문제를 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 업계의 기존 벤치마크가 통제된 환경에서의 작업 완료를 측정하는 반면, 실제 배치는 능동적 기만에 대한 회복력을 요구합니다.

Method: 우리의 연구에서는 2024년에 300억 달러가 손실된 암호화 시장을 테스트베드로 사용하여, 에이전트가 진실과 조작을 구별하고 단편화된 정보 환경을 탐색하며 적대적 압박 하에 돌이킬 수 없는 재정 결정을 내리는 178개의 시간 기반 작업에서 17개의 모델을 평가했습니다.

Result: 결과는 기본적인 능력 격차를 드러냈으며, 도구 없이 최전선 모델조차도 주니어 분석가들이 통상적으로 처리하는 작업에서 28%의 정확도만을 달성했습니다. 도구 추가는 성능을 개선했지만 전문가 자원에 무제한 접근함에도 불구하고 67.4%에 정체되었습니다.

Conclusion: 현재 모델이 인상적인 추론 점수에도 불구하고 적대적 반대가 존재하는 환경에 대해 기본적으로 준비가 되어 있지 않음을 보여줍니다.

Abstract: We present CAIA, a benchmark exposing a critical blind spot in AI evaluation:
the inability of state-of-the-art models to operate in adversarial, high-stakes
environments where misinformation is weaponized and errors are irreversible.
While existing benchmarks measure task completion in controlled settings,
real-world deployment demands resilience against active deception. Using crypto
markets as a testbed where $30 billion was lost to exploits in 2024, we
evaluate 17 models on 178 time-anchored tasks requiring agents to distinguish
truth from manipulation, navigate fragmented information landscapes, and make
irreversible financial decisions under adversarial pressure.
  Our results reveal a fundamental capability gap: without tools, even frontier
models achieve only 28% accuracy on tasks junior analysts routinely handle.
Tool augmentation improves performance but plateaus at 67.4% versus 80% human
baseline, despite unlimited access to professional resources. Most critically,
we uncover a systematic tool selection catastrophe: models preferentially
choose unreliable web search over authoritative data, falling for SEO-optimized
misinformation and social media manipulation. This behavior persists even when
correct answers are directly accessible through specialized tools, suggesting
foundational limitations rather than knowledge gaps. We also find that Pass@k
metrics mask dangerous trial-and-error behavior for autonomous deployment.
  The implications extend beyond crypto to any domain with active adversaries,
e.g. cybersecurity, content moderation, etc. We release CAIA with contamination
controls and continuous updates, establishing adversarial robustness as a
necessary condition for trustworthy AI autonomy. The benchmark reveals that
current models, despite impressive reasoning scores, remain fundamentally
unprepared for environments where intelligence must survive active opposition.

</details>


### [18] [Semantic-Driven AI Agent Communications: Challenges and Solutions](https://arxiv.org/abs/2510.00381)
*Kaiwen Yu,Mengying Sun,Zhijin Qin,Xiaodong Xu,Ping Yang,Yue Xiao,Gang Wu*

Main category: cs.AI

TL;DR: 이 논문은 지능형 서비스의 성장이 AI 에이전트 간의 통신을 위한 새로운 패러다임이 필요함을 강조하고, 의미 기반 커뮤니케이션 프레임워크 및 세 가지 기술을 제안하여 동적 환경에서도 효율적인 모델 적용과 협업을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 지능형 서비스의 급속한 성장으로 인해 인간에서 AI 에이전트로 통신 대상이 변화하고 있으며, 이는 실시간 인식, 의사 결정, 협업을 가능하게 하는 새로운 패러다임이 필요함을 요구한다.

Method: 제안된 프레임워크는 의미 적응 전송, 의미 경량 전송, 의미 자가 진화 제어의 세 가지 기술을 개발하여 AI 에이전트 간의 통신을 지원한다.

Result: 시뮬레이션 결과, 제안된 솔루션이 더 빠른 수렴과 강력한 강건성을 달성하며, 분산 계층 최적화 방법이 기존의 의사 결정 방식보다 성능이 뛰어남을 보여준다.

Conclusion: 제안된 방법은 동적 환경에서 AI 에이전트 통신 네트워크의 가능성을 강조하며, 즉각적인 의미 기반 통신의 잠재력을 시사한다.

Abstract: With the rapid growth of intelligent services, communication targets are
shifting from humans to artificial intelligent (AI) agents, which require new
paradigms to enable real-time perception, decision-making, and collaboration.
Semantic communication, which conveys task-relevant meaning rather than raw
data, offers a promising solution. However, its practical deployment remains
constrained by dynamic environments and limited resources. To address these
issues, this article proposes a semantic-driven AI agent communication
framework and develops three enabling techniques. First, semantic adaptation
transmission applies fine-tuning with real or generative samples to efficiently
adapt models to varying environments. Second, semantic lightweight transmission
incorporates pruning, quantization, and perception-aware sampling to reduce
model complexity and alleviate computational burden on edge agents. Third,
semantic self-evolution control employs distributed hierarchical
decision-making to optimize multi-dimensional resources, enabling robust
multi-agent collaboration in dynamic environments. Simulation results show that
the proposed solutions achieve faster convergence and stronger robustness,
while the proposed distributed hierarchical optimization method significantly
outperforms conventional decision-making schemes, highlighting its potential
for AI agent communication networks.

</details>


### [19] [Towards Self-Evolving Benchmarks: Synthesizing Agent Trajectories via Test-Time Exploration under Validate-by-Reproduce Paradigm](https://arxiv.org/abs/2510.00415)
*Dadi Guo,Tianyi Zhou,Dongrui Liu,Chen Qian,Qihan Ren,Shuai Shao,Zhiyuan Fan,Yi R. Fung,Kun Wang,Linfeng Zhang,Jing Shao*

Main category: cs.AI

TL;DR: TRACE 프레임워크는 에이전트가 기존 벤치마크의 작업을 새로운 난이도의 작업으로 발전시키도록 유도하며, 유효성을 검증할 수 있는 경로를 기록한다.


<details>
  <summary>Details</summary>
Motivation: 기존 에이전트 벤치마크는 새로운 에이전트에 의해 빠르게 한계에 도달하는 경향을 보이며, 에이전트 능력을 평가하는 데 어려움을 겪고 있다.

Method: TRACE 프레임워크는 세 단계로 구성되어 있으며, 에이전트가 작업의 진화를 통해 새로운 난이도의 작업으로 나아갈 수 있도록 유도하고 유효한 경로를 기록한다.

Result: GAIA 벤치마크에서의 실험 결과 TRACE 프레임워크가 작업의 복잡성을 일관되게 향상시키고, 유효성을 검증할 수 있는 실행 경로를 통해 정확성을 향상시킨다는 것을 보여주었다.

Conclusion: 이 연구는 정적이고 수동적으로 제작된 벤치마크에서 동적이고 자가 발전하는 평가 시스템으로의 패러다임 전환을 나타내며, 에이전트 개발을 위한 지속 가능하고 도전적인 환경을 제공한다.

Abstract: Recent advances in large language models (LLMs) and agent system designs have
empowered agents with unprecedented levels of capability. However, existing
agent benchmarks are showing a trend of rapid ceiling-hitting by newly
developed agents, making it difficult to meet the demands for evaluating agent
abilities. To address this problem, we propose the Trajectory-based
Validated-by-Reproducing Agent-benchmark Complexity Evolution (TRACE)
framework. This framework takes an original task from an existing benchmark and
encourages agents to freely explore and evolve it into a new task with higher
difficulty while recording validatable agent trajectories. The framework
proceeds in three stages: (1) evolutionary proposal mining, which provides task
evolution proposals through preliminary exploration and divergent thinking; (2)
problem formation and free exploration, where proposals are conceptualized into
feasible problem candidates and the agents then explore them freely while
recording their execution trajectories; and (3) multi-level validation, which
ensures that the evolved tasks are accompanied by validatable and reproducible
trajectories. Experiments on the GAIA benchmark demonstrate that the TRACE
framework consistently enhances task complexity while improving the reliability
of correctness through validatable execution trajectories. This work marks a
paradigm shift from static, manually curated benchmarks to dynamic,
self-evolving evaluation systems, providing a sustainable and challenging
runway for agent development.

</details>


### [20] [Expandable Decision-Making States for Multi-Agent Deep Reinforcement Learning in Soccer Tactical Analysis](https://arxiv.org/abs/2510.00480)
*Kenjiro Ide,Taiga Someya,Kohei Kawaguchi,Keisuke Fujii*

Main category: cs.AI

TL;DR: 이 논문은 선수 수준의 에이전트 모델을 구축하는 방법을 제안하며, 이 모델은 전통적인 전술 분석 방법의 한계를 극복하여 다양한 데이터 소스에서의 견고함과 해석 가능성을 갖추고 있다.


<details>
  <summary>Details</summary>
Motivation: 팀 스포츠에서의 전술 분석의 복잡성 때문에, 수치적 분석이 도전적이며, 이는 효율적인 의사결정 지원을 위해 필요하다.

Method: 우리는 Expandable Decision-Making States (EDMS)를 제안하여 원시 위치와 속도를 관계 변수와 결합하고, 언볼 및 오프볼 에이전트에게 분리된 결정 세트를 제공하는 액션 마스킹 방식을 사용한다.

Result: 실험 결과, EDMS는 기본 모델에 비해 행동 예측 손실 및 시간 차이 오류를 지속적으로 감소시켰으며, 고위험-고보상 전술 패턴을 강조했다.

Conclusion: 이 접근법은 여러 상업적 및 공개 데이터 세트와의 호환성을 보여주며, 크로스 프로바이더 평가 및 재현 가능한 실험을 가능하게 한다.

Abstract: Invasion team sports such as soccer produce a high-dimensional, strongly
coupled state space as many players continuously interact on a shared field,
challenging quantitative tactical analysis. Traditional rule-based analyses are
intuitive, while modern predictive machine learning models often perform
pattern-matching without explicit agent representations. The problem we address
is how to build player-level agent models from data, whose learned values and
policies are both tactically interpretable and robust across heterogeneous data
sources. Here, we propose Expandable Decision-Making States (EDMS), a
semantically enriched state representation that augments raw positions and
velocities with relational variables (e.g., scoring of space, pass, and score),
combined with an action-masking scheme that gives on-ball and off-ball agents
distinct decision sets. Compared to prior work, EDMS maps learned value
functions and action policies to human-interpretable tactical concepts (e.g.,
marking pressure, passing lanes, ball accessibility) instead of raw coordinate
features, and aligns agent choices with the rules of play. In the experiments,
EDMS with action masking consistently reduced both action-prediction loss and
temporal-difference (TD) error compared to the baseline. Qualitative case
studies and Q-value visualizations further indicate that EDMS highlights
high-risk, high-reward tactical patterns (e.g., fast counterattacks and
defensive breakthroughs). We also integrated our approach into an open-source
library and demonstrated compatibility with multiple commercial and open
datasets, enabling cross-provider evaluation and reproducible experiments.

</details>


### [21] [ACON: Optimizing Context Compression for Long-horizon LLM Agents](https://arxiv.org/abs/2510.00615)
*Minki Kang,Wei-Ning Chen,Dongge Han,Huseyin A. Inan,Lukas Wutschitz,Yanzhi Chen,Robert Sim,Saravan Rajmohan*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)을 위한 새로운 프레임워크인 ACON은 환경 관찰 및 상호작용 기록을 효과적으로 압축하여 메모리 사용량을 줄이면서 성능을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 동적이고 현실적인 환경에서 LLM을 에이전트로 활용하기 위한 필요성이 커지고 있으며, 이는 결국 긴 문맥 길이와 효과적인 도구 사용이 요구된다.

Method: ACON은 환경 관찰과 상호작용 기록을 압축하는 통합 프레임워크로, 성공적인 전체 문맥과 실패하는 압축 문맥을 기반으로 압축 가이드라인 최적화를 활용한다.

Result: AppWorld, OfficeBench, Multi-objective QA 실험을 통해 ACON은 메모리 사용량을 26-54% 줄이면서도 작업 성능을 크게 유지하고, 압축기로 증류될 때 95% 이상의 정확성을 유지하며, 소형 모델에서도 최대 46%의 성능 향상을 보여준다.

Conclusion: ACON은 LLM의 메모리 효율성을 높이고 긴 수명의 에이전트로서의 성능을 향상시키는 데 기여한다.

Abstract: Large language models (LLMs) are increasingly deployed as agents in dynamic,
real-world environments, where success requires both reasoning and effective
tool use. A central challenge for agentic tasks is the growing context length,
as agents must accumulate long histories of actions and observations. This
expansion raises costs and reduces efficiency in long-horizon tasks, yet prior
work on context compression has mostly focused on single-step tasks or narrow
applications. We introduce Agent Context Optimization (ACON), a unified
framework that optimally compresses both environment observations and
interaction histories into concise yet informative condensations. ACON
leverages compression guideline optimization in natural language space: given
paired trajectories where full context succeeds but compressed context fails,
capable LLMs analyze the causes of failure, and the compression guideline is
updated accordingly. Furthermore, we propose distilling the optimized LLM
compressor into smaller models to reduce the overhead of the additional module.
Experiments on AppWorld, OfficeBench, and Multi-objective QA show that ACON
reduces memory usage by 26-54% (peak tokens) while largely preserving task
performance, preserves over 95% of accuracy when distilled into smaller
compressors, and enhances smaller LMs as long-horizon agents with up to 46%
performance improvement.

</details>


### [22] [HARPA: A Testability-Driven, Literature-Grounded Framework for Research Ideation](https://arxiv.org/abs/2510.00620)
*Rosni Vasu,Peter Jansen,Pao Siangliulue,Cristina Sarasua,Abraham Bernstein,Peter Clark,Bhavana Dalvi Mishra*

Main category: cs.AI

TL;DR: HARPA는 자동화된 과학 발견을 위한 도구로, 문헌 분석을 통해 연구 동향을 식별하고, 가설 설계 공간을 탐색하며, 실험 결과를 바탕으로 신뢰할 수 있는 가설을 생성하는 데 중점을 둡니다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 과학 발견에 대한 관심이 높아지고 있지만, testable하고 과학 문헌에 기반한 가설 생성을 위한 도구가 여전히 부족합니다.

Method: HARPA는 인간 연구자에게 영감을 받은 아이디어 생성 워크플로우를 통해 문헌 채굴로 연구 동향을 파악하고, 가설 설계 공간을 탐색하며, 연구 격차를 명확히 하고 설계 선택을 정당화하여 정밀하고 테스트 가능한 가설로 수렴합니다.

Result: HARPA에서 생성된 가설 기반 연구 제안은 강력한 기준 AI 연구자와 비교했을 때 대부분의 정성적 차원에서 비슷한 성과를 보였으며, 실행 가능성에서 +0.78, groundedness에서 +0.85의 유의미한 향상을 이뤘습니다.

Conclusion: HARPA는 AI 기반 과학 발견의 진전을 대표하는 방법론이며, 가설의 테스트 가능성과 흥미를 연구자들이 경험을 통해 지속적으로 정련하는 방식을 시뮬레이션합니다.

Abstract: While there has been a surge of interest in automated scientific discovery
(ASD), especially with the emergence of LLMs, it remains challenging for tools
to generate hypotheses that are both testable and grounded in the scientific
literature. Additionally, existing ideation tools are not adaptive to prior
experimental outcomes. We developed HARPA to address these challenges by
incorporating the ideation workflow inspired by human researchers. HARPA first
identifies emerging research trends through literature mining, then explores
hypothesis design spaces, and finally converges on precise, testable hypotheses
by pinpointing research gaps and justifying design choices. Our evaluations
show that HARPA-generated hypothesis-driven research proposals perform
comparably to a strong baseline AI-researcher across most qualitative
dimensions (e.g., specificity, novelty, overall quality), but achieve
significant gains in feasibility(+0.78, p$<0.05$, bootstrap) and groundedness
(+0.85, p$<0.01$, bootstrap) on a 10-point Likert scale. When tested with the
ASD agent (CodeScientist), HARPA produced more successful executions (20 vs. 11
out of 40) and fewer failures (16 vs. 21 out of 40), showing that expert
feasibility judgments track with actual execution success. Furthermore, to
simulate how researchers continuously refine their understanding of what
hypotheses are both testable and potentially interesting from experience, HARPA
learns a reward model that scores new hypotheses based on prior experimental
outcomes, achieving approx. a 28\% absolute gain over HARPA's untrained
baseline scorer. Together, these methods represent a step forward in the field
of AI-driven scientific discovery.

</details>


### [23] [Is Model Editing Built on Sand? Revealing Its Illusory Success and Fragile Foundation](https://arxiv.org/abs/2510.00625)
*Wei Liu,Haomei Xu,Bingqing Liu,Zhiying Deng,Haozhao Wang,Jun Wang,Ruixuan Li,Yee Whye Teh,Wee Sun Lee*

Main category: cs.AI

TL;DR: 모델 편집의 성공에도 불구하고, 현재의 모델 편집 문헌은 취약한 기반 위에 있으며 진정한 의미를 활용하기보다는 숨겨진 단축키를 활용하는 경향이 나타난다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델이 구식이거나 부정확한 지식을 인코딩하는 문제를 해결하고, 업데이트 및 삭제의 필요성을 인식하기 위함이다.

Method: 모델 편집 기법을 개발하고 새로운 평가 방법을 체계적으로 마련하였다.

Result: 최신 접근 방식이 가장 간단한 부정 쿼리에서도 무너지는 것을 발견하였다.

Conclusion: 모델 편집의 기반을 재고할 필요가 있다.

Abstract: Large language models (LLMs) inevitably encode outdated or incorrect
knowledge. Updating, deleting, and forgetting such knowledge is important for
alignment, safety, and other issues. To address this issue, model editing has
emerged as a promising paradigm: by precisely editing a small subset of
parameters such that a specific fact is updated while preserving other
knowledge. Despite its great success reported in previous papers, we find the
apparent reliability of editing rests on a fragile foundation and the current
literature is largely driven by illusory success. The fundamental goal of
steering the model's output toward a target with minimal modification would
encourage exploiting hidden shortcuts, rather than utilizing real semantics.
This problem directly challenges the feasibility of the current model editing
literature at its very foundation, as shortcuts are inherently at odds with
robust knowledge integration. Coincidentally, this issue has long been obscured
by evaluation frameworks that lack the design of negative examples. To uncover
it, we systematically develop a suite of new evaluation methods. Strikingly, we
find that state-of-the-art approaches collapse even under the simplest negation
queries. Our empirical evidence shows that editing is likely to be based on
shortcuts rather than full semantics, calling for an urgent reconsideration of
the very basis of model editing before further advancements can be meaningfully
pursued.

</details>


### [24] [Collaborative-Distilled Diffusion Models (CDDM) for Accelerated and Lightweight Trajectory Prediction](https://arxiv.org/abs/2510.00627)
*Bingzhang Wang,Kehua Chen,Yinhai Wang*

Main category: cs.AI

TL;DR: 본 논문은 경량의 실시간 궤적 예측을 위한 Collaborative-Distilled Diffusion Models (CDDM)라는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율주행차와 지능형 교통 시스템에서 궤적 예측은 효율적인 움직임 계획과 실시간 교통 안전 관리에 필수적이다.

Method: CDDM은 높은 용량의 교사 diffusion 모델에서 경량 학생 모델로 지식을 점진적으로 전이하는 Collaborative Progressive Distillation (CPD) 기반으로 구축되었다.

Result: CDDM은 ETH-UCY 보행자 벤치마크와 nuScenes 차량 벤치마크에서 최고의 예측 정확성을 달성하였다.

Conclusion: 고 성능의 생성 모델과 실제 배치 제약을 연결함으로써, CDDM은 자율주행차와 ITS를 위한 자원 효율적인 확률적 예측을 가능하게 한다.

Abstract: Trajectory prediction is a fundamental task in Autonomous Vehicles (AVs) and
Intelligent Transportation Systems (ITS), supporting efficient motion planning
and real-time traffic safety management. Diffusion models have recently
demonstrated strong performance in probabilistic trajectory prediction, but
their large model size and slow sampling process hinder real-world deployment.
This paper proposes Collaborative-Distilled Diffusion Models (CDDM), a novel
method for real-time and lightweight trajectory prediction. Built upon
Collaborative Progressive Distillation (CPD), CDDM progressively transfers
knowledge from a high-capacity teacher diffusion model to a lightweight student
model, jointly reducing both the number of sampling steps and the model size
across distillation iterations. A dual-signal regularized distillation loss is
further introduced to incorporate guidance from both the teacher and
ground-truth data, mitigating potential overfitting and ensuring robust
performance. Extensive experiments on the ETH-UCY pedestrian benchmark and the
nuScenes vehicle benchmark demonstrate that CDDM achieves state-of-the-art
prediction accuracy. The well-distilled CDDM retains 96.2% and 95.5% of the
baseline model's ADE and FDE performance on pedestrian trajectories, while
requiring only 231K parameters and 4 or 2 sampling steps, corresponding to 161x
compression, 31x acceleration, and 9 ms latency. Qualitative results further
show that CDDM generates diverse and accurate trajectories under dynamic agent
behaviors and complex social interactions. By bridging high-performing
generative models with practical deployment constraints, CDDM enables
resource-efficient probabilistic prediction for AVs and ITS. Code is available
at https://github.com/bingzhangw/CDDM.

</details>


### [25] [EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty](https://arxiv.org/abs/2510.00732)
*Yuchen Tian,Ruiyuan Huang,Xuanwu Wang,Jing Ma,Zengfeng Huang,Ziyang Luo,Hongzhan Lin,Da Zheng,Lun Du*

Main category: cs.AI

TL;DR: 이 논문에서는 정리 증명을 위한 대형 언어 모델의 일반화 문제를 해결하기 위해 대칭성과 난이도 두 가지 관점에서 모델의 강건성을 향상시키기 위한 새로운 데이터 증강 파이프라인을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델은 정리 증명에서 큰 가능성을 보이지만, 문제 진술의 사소한 변형에도 취약하며 일반화 능력이 부족하다.

Method: EvolAST와 EvolDomain 두 가지 방법을 통해 대칭성을 고려한 데이터 증강과 EvolDifficulty를 통해 다양한 난이도의 새로운 정리를 생성하는 진화적 지침을 사용한다.

Result: EvolProver는 7B 파라미터 비추론 정리 증명기로, FormalMATH-Lite에서 53.8% pass@32를 기록하며, 모든 유사 크기 모델을 초월한다.

Conclusion: 우리의 데이터 증강 파이프라인은 여러 벤치마크에서 효과적임을 입증하였다.

Abstract: Large Language Models (LLMs) for formal theorem proving have shown
significant promise, yet they often lack generalizability and are fragile to
even minor transformations of problem statements. To address this limitation,
we introduce a novel data augmentation pipeline designed to enhance model
robustness from two perspectives: symmetry and difficulty. From the symmetry
perspective, we propose two complementary methods: EvolAST, an Abstract Syntax
Tree (AST) based approach that targets syntactic symmetry to generate
semantically equivalent problem variants, and EvolDomain, which leverages LLMs
to address semantic symmetry by translating theorems across mathematical
domains. From the difficulty perspective, we propose EvolDifficulty, which uses
carefully designed evolutionary instructions to guide LLMs in generating new
theorems with a wider range of difficulty. We then use the evolved data to
train EvolProver, a 7B-parameter non-reasoning theorem prover. EvolProver
establishes a new state-of-the-art (SOTA) on FormalMATH-Lite with a 53.8%
pass@32 rate, surpassing all models of comparable size, including
reasoning-based models. It also sets new SOTA records for non-reasoning models
on MiniF2F-Test (69.8% pass@32), Ineq-Comp-Seed (52.2% pass@32), and
Ineq-Comp-Transformed (34.0% pass@32). Ablation studies further confirm our
data augmentation pipeline's effectiveness across multiple benchmarks.

</details>


### [26] [Benchmarking Agentic Systems in Automated Scientific Information Extraction with ChemX](https://arxiv.org/abs/2510.00795)
*Anastasia Vepreva,Julia Razlivina,Maria Eremeeva,Nina Gubina,Anastasia Orlova,Aleksei Dmitrenko,Ksenya Kapranova,Susan Jyakhwo,Nikita Vasilev,Arsen Sarkisyan,Ivan Yu. Chernyshov,Vladimir Vinogradov,Andrei Dmitrenko*

Main category: cs.AI

TL;DR: ChemX는 화학 정보 추출을 위한 10개의 데이터셋을 제공하고, 새로운 단일 에이전트 접근 방식과 기존 최첨단 시스템을 비교하여 화학 데이터의 자동 추출 성능을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 화학 정보 추출은 화학 데이터의 이질성 때문에 중요한 도전 과제로 남아 있으며, 현재의 에이전트 기반 접근법은 이 분야에서 성능이 제한적이다.

Method: 우리는 10개의 수동으로 선별된 데이터셋을 수집하고, 기존의 최신 에이전트 시스템과 비교하여 성능을 평가하고, 문서 전처리를 정밀하게 제어할 수 있는 단일 에이전트 접근 방식을 소개한다.

Result: 우리는 화학 정보 추출에서 지속적인 도전 과제를 발견했으며, 특히 도메인 특정 용어 처리, 복잡한 표 및 도식 표현, 맥락 의존적인 모호성에서 어려움이 있었다.

Conclusion: ChemX 벤치마크는 화학 분야의 자동 정보 추출을 발전시키고, 기존 방법의 일반화 능력을 도전하며, 효과적인 평가 전략에 대한 귀중한 통찰을 제공하는 중요한 자원으로 작용한다.

Abstract: The emergence of agent-based systems represents a significant advancement in
artificial intelligence, with growing applications in automated data
extraction. However, chemical information extraction remains a formidable
challenge due to the inherent heterogeneity of chemical data. Current
agent-based approaches, both general-purpose and domain-specific, exhibit
limited performance in this domain. To address this gap, we present ChemX, a
comprehensive collection of 10 manually curated and domain-expert-validated
datasets focusing on nanomaterials and small molecules. These datasets are
designed to rigorously evaluate and enhance automated extraction methodologies
in chemistry. To demonstrate their utility, we conduct an extensive
benchmarking study comparing existing state-of-the-art agentic systems such as
ChatGPT Agent and chemical-specific data extraction agents. Additionally, we
introduce our own single-agent approach that enables precise control over
document preprocessing prior to extraction. We further evaluate the performance
of modern baselines, such as GPT-5 and GPT-5 Thinking, to compare their
capabilities with agentic approaches. Our empirical findings reveal persistent
challenges in chemical information extraction, particularly in processing
domain-specific terminology, complex tabular and schematic representations, and
context-dependent ambiguities. The ChemX benchmark serves as a critical
resource for advancing automated information extraction in chemistry,
challenging the generalization capabilities of existing methods, and providing
valuable insights into effective evaluation strategies.

</details>


### [27] [Learning Compact Representations of LLM Abilities via Item Response Theory](https://arxiv.org/abs/2510.00844)
*Jianhao Chen,Chenxu Wang,Gengrui Zhang,Peng Ye,Lei Bai,Wei Hu,Yuzhong Qu,Shuyue Hu*

Main category: cs.AI

TL;DR: 대형 언어 모델의 효율적인 관리와 활용을 위한 Compact representation 학습 방안 제안.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 리소스를 효율적으로 관리하고 활용하는 것이 큰 도전 과제임.

Method: 아이템 반응 이론(IRT)을 기반으로 하여 모델의 능력 벡터, 쿼리의 구분 벡터, 쿼리의 난이도 스칼라를 사용하여 주어진 모델이 특정 쿼리에 올바르게 응답할 확률 추정.

Result: 모델 라우팅과 기준 정확도 예측에서 최첨단 성능 달성.

Conclusion: 학습된 매개변수는 모델 능력과 쿼리 특성에 대한 의미 있는 정보로 해석 가능함을 확인.

Abstract: Recent years have witnessed a surge in the number of large language models
(LLMs), yet efficiently managing and utilizing these vast resources remains a
significant challenge. In this work, we explore how to learn compact
representations of LLM abilities that can facilitate downstream tasks, such as
model routing and performance prediction on new benchmarks. We frame this
problem as estimating the probability that a given model will correctly answer
a specific query. Inspired by the item response theory (IRT) in psychometrics,
we model this probability as a function of three key factors: (i) the model's
multi-skill ability vector, (2) the query's discrimination vector that
separates models of differing skills, and (3) the query's difficulty scalar. To
learn these parameters jointly, we introduce a Mixture-of-Experts (MoE) network
that couples model- and query-level embeddings. Extensive experiments
demonstrate that our approach leads to state-of-the-art performance in both
model routing and benchmark accuracy prediction. Moreover, analysis validates
that the learned parameters encode meaningful, interpretable information about
model capabilities and query characteristics.

</details>


### [28] [Unveiling Interesting Insights: Monte Carlo Tree Search for Knowledge Discovery](https://arxiv.org/abs/2510.00876)
*Pietro Totis,Alberto Pozanco,Daniel Borrajo*

Main category: cs.AI

TL;DR: 이 논문은 데이터에서 통찰력과 의사결정을 이끌어내기 위한 자동화된 지식 발견을 위한 새로운 방법인 AIDE를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 조직들은 데이터에서 통찰력을 얻고 의사결정을 내리기 위해 점점 더 집중하고 있으나, 데이터를 실행 가능한 지식으로 변환하는 일이 어렵고 시간이 많이 걸립니다.

Method: 이 논문에서는 몬테 카를로 트리 탐색(MCTS)을 활용하여 이 문제를 해결하기 위한 새로운 방법인 자동 통찰력 및 데이터 탐색(AIDE)을 제안합니다.

Result: AIDE는 실제 및 합성 데이터를 사용하여 평가되었으며, 흥미로운 데이터 패턴을 발견하는 데이터 변환 및 모델 식별에서 효과적임을 입증하였습니다.

Conclusion: AIDE는 패턴 추출 전략 및 도메인 지식을 추가로 통합할 수 있는 확장성이 뛰어난 프레임워크를 제공하여 자동화된 지식 발견을 위한 포괄적인 솔루션 개발에 중요한 단계를 제공합니다.

Abstract: Organizations are increasingly focused on leveraging data from their
processes to gain insights and drive decision-making. However, converting this
data into actionable knowledge remains a difficult and time-consuming task.
There is often a gap between the volume of data collected and the ability to
process and understand it, which automated knowledge discovery aims to fill.
Automated knowledge discovery involves complex open problems, including
effectively navigating data, building models to extract implicit relationships,
and considering subjective goals and knowledge. In this paper, we introduce a
novel method for Automated Insights and Data Exploration (AIDE), that serves as
a robust foundation for tackling these challenges through the use of Monte
Carlo Tree Search (MCTS). We evaluate AIDE using both real-world and synthetic
data, demonstrating its effectiveness in identifying data transformations and
models that uncover interesting data patterns. Among its strengths, AIDE's
MCTS-based framework offers significant extensibility, allowing for future
integration of additional pattern extraction strategies and domain knowledge.
This makes AIDE a valuable step towards developing a comprehensive solution for
automated knowledge discovery.

</details>


### [29] [QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL](https://arxiv.org/abs/2510.00967)
*Cong Yu,Valter Uotila,Shilong Deng,Qingyuan Wu,Tuo Shi,Songlin Jiang,Lei You,Bo Zhao*

Main category: cs.AI

TL;DR: QUASAR는 퀀텀 회로 생성 및 최적화를 위한 RL 프레임워크로, LLM을 기반으로 하여 퀀텀 도메인 지식을 통합해 퀀텀 회로의 품질을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 퀀텀 컴퓨팅의 이점을 활용하기 위해서는 작업 특정 퀀텀 회로의 설계 및 최적화가 중요하다.

Method: QUASAR는 도구 증강 LLM을 기반으로 한 RL 프레임워크로, 외부 퀀텀 시뮬레이터를 사용한 회로 검증 접근법과 정교한 계층 보상 메커니즘을 설계한다.

Result: QUASAR는 생성된 퀀텀 회로의 구문 및 의미적 성능 모두에서 개선을 보였으며, 4B LLM을 증강했을 때 Pass@1에서 99.31%, Pass@10에서 100%의 유효성을 달성했다.

Conclusion: QUASAR는 GPT-4o, GPT-5, DeepSeek-V3 같은 산업 LLM보다 뛰어난 성능을 보여준다.

Abstract: Designing and optimizing task-specific quantum circuits are crucial to
leverage the advantage of quantum computing. Recent large language model
(LLM)-based quantum circuit generation has emerged as a promising automatic
solution. However, the fundamental challenges remain unaddressed: (i)
parameterized quantum gates require precise numerical values for optimal
performance, which also depend on multiple aspects, including the number of
quantum gates, their parameters, and the layout/depth of the circuits. (ii)
LLMs often generate low-quality or incorrect quantum circuits due to the lack
of quantum domain-specific knowledge. We propose QUASAR, an agentic
reinforcement learning (RL) framework for quantum circuits generation and
optimization based on tool-augmented LLMs. To align the LLM with
quantum-specific knowledge and improve the generated quantum circuits, QUASAR
designs (i) a quantum circuit verification approach with external quantum
simulators and (ii) a sophisticated hierarchical reward mechanism in RL
training. Extensive evaluation shows improvements in both syntax and semantic
performance of the generated quantum circuits. When augmenting a 4B LLM, QUASAR
has achieved the validity of 99.31% in Pass@1 and 100% in Pass@10,
outperforming industrial LLMs of GPT-4o, GPT-5 and DeepSeek-V3 and several
supervised-fine-tuning (SFT)-only and RL-only baselines.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [30] [DexBench: Benchmarking LLMs for Personalized Decision Making in Diabetes Management](https://arxiv.org/abs/2510.00038)
*Maria Ana Cardei,Josephine Lamp,Mark Derdzinski,Karan Bhatia*

Main category: cs.LG

TL;DR: DexBench는 당뇨병 관리를 위해 설계된 대형 언어 모델의 성능을 평가하기 위한 첫 번째 벤치마크입니다.


<details>
  <summary>Details</summary>
Motivation: 당뇨병 관리에 있어 개인이 직면하는 실제 의사 결정 과제를 평가할 수 있는 도구가 필요하다.

Method: 7개 작업 카테고리에 걸쳐 15,000명의 당뇨병 환자로부터 수집한 데이터로 개인화된 질문을 생성하고, 5개 지표를 통해 모델 성능을 평가합니다.

Result: 8개 최근 LLM의 분석 결과, 모든 작업과 지표에서 특정 모델이 consistently 우수한 성능을 보이지 않았습니다.

Conclusion: 이 벤치마크를 통해 당뇨병 치료에서 AI 솔루션의 신뢰성, 안전성, 효과성 및 실용성을 향상시키고자 합니다.

Abstract: We present DexBench, the first benchmark designed to evaluate large language
model (LLM) performance across real-world decision-making tasks faced by
individuals managing diabetes in their daily lives. Unlike prior health
benchmarks that are either generic, clinician-facing or focused on clinical
tasks (e.g., diagnosis, triage), DexBench introduces a comprehensive evaluation
framework tailored to the unique challenges of prototyping patient-facing AI
solutions in diabetes, glucose management, metabolic health and related
domains. Our benchmark encompasses 7 distinct task categories, reflecting the
breadth of real-world questions individuals with diabetes ask, including basic
glucose interpretation, educational queries, behavioral associations, advanced
decision making and long term planning. Towards this end, we compile a rich
dataset comprising one month of time-series data encompassing glucose traces
and metrics from continuous glucose monitors (CGMs) and behavioral logs (e.g.,
eating and activity patterns) from 15,000 individuals across three different
diabetes populations (type 1, type 2, pre-diabetes/general health and
wellness). Using this data, we generate a total of 360,600 personalized,
contextual questions across the 7 tasks. We evaluate model performance on these
tasks across 5 metrics: accuracy, groundedness, safety, clarity and
actionability. Our analysis of 8 recent LLMs reveals substantial variability
across tasks and metrics; no single model consistently outperforms others
across all dimensions. By establishing this benchmark, we aim to advance the
reliability, safety, effectiveness and practical utility of AI solutions in
diabetes care.

</details>


### [31] [Adaptive and Resource-efficient Agentic AI Systems for Mobile and Embedded Devices: A Survey](https://arxiv.org/abs/2510.00078)
*Sicong Liu,Weiye Wu,Xiangrui Xu,Teng Li,Bowen Pang,Bin Guo,Zhiwen Yu*

Main category: cs.LG

TL;DR: 기초 모델들은 AI를 재구성하고, 자율성, 일반화, 자기 반성을 달성하는 지능형 에이전트를 정의하는 새로운 패러다임으로 접근하고 있다.


<details>
  <summary>Details</summary>
Motivation: AI의 에이전트 개념과 기초 모델들을 통합하여 자율적이고 효율적인 AI 시스템을 탐색하기 위해.

Method: 적응형 에이전트 AI 시스템의 체계적인 특성을 요약하고, 관련 기술들을 정리하고, 개방적인 도전 과제를 식별한다.

Result: 적응형 추론, 테스트 시간 적응, 동적 다중 모드 통합을 포함하는 기술을 요약하고, 정확도-지연-통신 트레이드오프 및 분포 변화 하에서의 강건성 유지에 대한 도전 과제를 도출한다.

Conclusion: 이 작업은 확장 가능하고 적응적이며 자원 효율적인 에이전트 AI에 대한 통합적 관점을 설정하며, 독자들이 기술들 간의 관계를 이해하는 데 도움을 줄 것으로 예상한다.

Abstract: Foundation models have reshaped AI by unifying fragmented architectures into
scalable backbones with multimodal reasoning and contextual adaptation. In
parallel, the long-standing notion of AI agents, defined by the
sensing-decision-action loop, is entering a new paradigm: with FMs as their
cognitive core, agents transcend rule-based behaviors to achieve autonomy,
generalization, and self-reflection. This dual shift is reinforced by
real-world demands such as autonomous driving, robotics, virtual assistants,
and GUI agents, as well as ecosystem advances in embedded hardware, edge
computing, mobile deployment platforms, and communication protocols that
together enable large-scale deployment. Yet this convergence collides with
reality: while applications demand long-term adaptability and real-time
interaction, mobile and edge deployments remain constrained by memory, energy,
bandwidth, and latency. This creates a fundamental tension between the growing
complexity of FMs and the limited resources of deployment environments. This
survey provides the first systematic characterization of adaptive,
resource-efficient agentic AI systems. We summarize enabling techniques into
elastic inference, test-time adaptation, dynamic multimodal integration, and
agentic AI applications, and identify open challenges in balancing
accuracy-latency-communication trade-offs and sustaining robustness under
distribution shifts. We further highlight future opportunities in
algorithm-system co-design, cognitive adaptation, and collaborative edge
deployment. By mapping FM structures, cognition, and hardware resources, this
work establishes a unified perspective toward scalable, adaptive, and
resource-efficient agentic AI. We believe this survey can help readers to
understand the connections between enabling technologies while promoting
further discussions on the fusion of agentic intelligence and intelligent
agents.

</details>


### [32] [Which Rewards Matter? Reward Selection for Reinforcement Learning under Limited Feedback](https://arxiv.org/abs/2510.00144)
*Shreyas Chaudhari,Renhao Zhang,Philip S. Thomas,Bruno Castro da Silva*

Main category: cs.LG

TL;DR: 이 논문은 제한된 피드백을 통한 보상 선택 문제를 포멀화하고, 효과적인 보상 선택 전략을 연구하여 강화 학습의 성능을 극대화하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 알고리즘이 효과적인 정책을 학습하는 능력은 훈련 중 사용 가능한 보상에 의해 결정된다. 그러나 실제 문제에서 대량의 보상 레이블을 얻는 것은 계산적 또는 재정적 제약으로 인해 종종 불가능하다. 따라서 제한된 피드백으로 강화 학습을 수행할 때 어떤 샘플을 레이블링해야 하는지가 중요하다.

Method: 보상 선택 문제(RLLF)를 새롭게 포멀화하고, (i) 상태 방문 및 부분 가치 함수와 같은 보상 없는 정보에 의존하는 휴리스틱과 (ii) 보조 평가 피드백을 사용하여 미리 훈련된 전략의 두 가지 선택 전략을 조사한다.

Result: 중요한 보상 하위 집합은 (1) 최적 궤적을 따라 에이전트를 안내하고, (2) 이탈 후 근사 최적 행동으로 복귀를 지원하는 보상이다. 효과적인 선택 방법은 전체 감독보다 현저히 적은 보상 레이블로 유사 최적 정책을 도출한다.

Conclusion: 보상 선택은 피드백 제한 환경에서 강화 학습을 확장하는 강력한 패러다임이 된다.

Abstract: The ability of reinforcement learning algorithms to learn effective policies
is determined by the rewards available during training. However, for practical
problems, obtaining large quantities of reward labels is often infeasible due
to computational or financial constraints, particularly when relying on human
feedback. When reinforcement learning must proceed with limited feedback --
only a fraction of samples get rewards labeled -- a fundamental question
arises: which samples should be labeled to maximize policy performance? We
formalize this problem of reward selection for reinforcement learning from
limited feedback (RLLF), introducing a new problem formulation that facilitates
the study of strategies for selecting impactful rewards. Two types of selection
strategies are investigated: (i) heuristics that rely on reward-free
information such as state visitation and partial value functions, and (ii)
strategies pre-trained using auxiliary evaluative feedback. We find that
critical subsets of rewards are those that (1) guide the agent along optimal
trajectories, and (2) support recovery toward near-optimal behavior after
deviations. Effective selection methods yield near-optimal policies with
significantly fewer reward labels than full supervision, establishing reward
selection as a powerful paradigm for scaling reinforcement learning in
feedback-limited settings.

</details>


### [33] [Robust Federated Inference](https://arxiv.org/abs/2510.00310)
*Akash Dhasade,Sadegh Farhadkhani,Rachid Guerraoui,Nirupam Gupta,Maxime Jacovella,Anne-Marie Kermarrec,Rafael Pinot*

Main category: cs.LG

TL;DR: 이 논문은 연합 추론의 강인성을 분석하고, 비선형 집계기를 이용한 새로운 강인성을 향상시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 연합 추론의 강인성 문제를 해결하기 위한 필요성

Method: DeepSet 집계 모델을 사용하여 적대적 훈련과 테스트 시 강인한 집계를 결합하는 방법을 제안

Result: 기존 강인한 집계 방법보다 정확도가 4.7 - 22.2% 향상됨

Conclusion: 연합 학습에서 비선형 집계기를 위한 강인성 향상 기술을 제공한다.

Abstract: Federated inference, in the form of one-shot federated learning, edge
ensembles, or federated ensembles, has emerged as an attractive solution to
combine predictions from multiple models. This paradigm enables each model to
remain local and proprietary while a central server queries them and aggregates
predictions. Yet, the robustness of federated inference has been largely
neglected, leaving them vulnerable to even simple attacks. To address this
critical gap, we formalize the problem of robust federated inference and
provide the first robustness analysis of this class of methods. Our analysis of
averaging-based aggregators shows that the error of the aggregator is small
either when the dissimilarity between honest responses is small or the margin
between the two most probable classes is large. Moving beyond linear averaging,
we show that problem of robust federated inference with non-linear aggregators
can be cast as an adversarial machine learning problem. We then introduce an
advanced technique using the DeepSet aggregation model, proposing a novel
composition of adversarial training and test-time robust aggregation to
robustify non-linear aggregators. Our composition yields significant
improvements, surpassing existing robust aggregation methods by 4.7 - 22.2% in
accuracy points across diverse benchmarks.

</details>


### [34] [RouterArena: An Open Platform for Comprehensive Comparison of LLM Routers](https://arxiv.org/abs/2510.00202)
*Yifan Lu,Rixin Liu,Jiayi Yuan,Xingqi Cui,Shenrun Zhang,Hongyi Liu,Jiarong Xing*

Main category: cs.LG

TL;DR: LLM 라우터의 포괄적인 비교와 표준 리더보드를 제공하는 RouterArena를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 상황에 적합한 LLM 모델 선택의 어려움을 해결하기 위해.

Method: 다양한 도메인을 포괄하는 데이터셋, 각 도메인별 난이도 수준 구분, 평가 지표 목록, 리더보드 자동 업데이트 프레임워크를 활용했습니다.

Result: 상세한 지표 비교를 포함한 초기 리더보드를 생성했습니다.

Conclusion: 우리 플랫폼은 곧 공개될 예정입니다.

Abstract: Today's LLM ecosystem comprises a wide spectrum of models that differ in
size, capability, and cost. No single model is optimal for all scenarios;
hence, LLM routers have become essential for selecting the most appropriate
model under varying circumstances. However, the rapid emergence of various
routers makes choosing the right one increasingly challenging. To address this
problem, we need a comprehensive router comparison and a standardized
leaderboard, similar to those available for models. In this work, we introduce
RouterArena, the first open platform enabling comprehensive comparison of LLM
routers. RouterArena has (1) a principally constructed dataset with broad
knowledge domain coverage, (2) distinguishable difficulty levels for each
domain, (3) an extensive list of evaluation metrics, and (4) an automated
framework for leaderboard updates. Leveraging our framework, we have produced
the initial leaderboard with detailed metrics comparison as shown in Figure 1.
We will make our platform open to the public soon.

</details>


### [35] [In-Context Curiosity: Distilling Exploration for Decision-Pretrained Transformers on Bandit Tasks](https://arxiv.org/abs/2510.00347)
*Huitao Yang,Guanting Chen*

Main category: cs.LG

TL;DR: 이 논문에서는 결정-사전 훈련 변환기(Decision-Pretrained Transformers)에서의 일반화 문제를 해결하기 위해 탐구 중심의 정규화 기법을 제안하고 예측 기반 변환기(Prediction-Powered Transformer) 프레임워크를 도입한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)의 능력이 증가함에 따라 의사 결정 작업에 통합하려는 관심이 커지고 있다.

Method: 우리는 미리 훈련된 모델에서 일반화의 한계를 완화하기 위해 탐구 중심의 정규화자인 인컨텍스트 호기심(in-context curiosity)을 제안하고, 보조 보상 예측기를 사용하는 예측 기반 변환기(PPT) 프레임워크를 소개한다.

Result: 가우시안 다중 팔 밴딧에서의 증명 개념 실험에서 PPT는 개선된 강건성을 보여주었고, 훈련 중 보다 넓은 탐색을 장려하는 내재적 호기심 신호로 예측 오류를 사용한다.

Conclusion: 호기심 중심의 사전 훈련이 in-context 강화 학습 에이전트의 분포 외 일반화를 향상시킬 수 있는 유망한 방향임을 우리는 시사한다.

Abstract: As large language models (LLMs) continue to grow in capability, there is
increasing interest in incorporating them into decision-making tasks. A common
pipeline for this is Decision-Pretrained Transformers (DPTs). However, existing
training methods for DPTs often struggle to generalize beyond their pretraining
data distribution. To explore mitigation of this limitation, we propose
in-context curiosity -- a lightweight, exploration-inspired regularizer for
offline pretraining -- and introduce the Prediction-Powered Transformer (PPT)
framework. PPT augments DPT with an auxiliary reward predictor, using
prediction error as an intrinsic curiosity signal to encourage broader
exploration during training. In proof-of-concept experiments on Gaussian
multi-armed bandits, PPT shows improved robustness: it moderates the
performance degradation observed in DPT when test environments exhibit higher
variance in reward, particularly when pretraining data has limited diversity.
While the quality of offline data remain fundamental, our preliminary results
suggest that curiosity-driven pretraining offers a promising direction for
enhancing out-of-distribution generalization in in-context RL agents.

</details>


### [36] [SLogic: Subgraph-Informed Logical Rule Learning for Knowledge Graph Completion](https://arxiv.org/abs/2510.00279)
*Trung Hoang Le,Tran Cao Son,Huiping Cao*

Main category: cs.LG

TL;DR: SLogic은 질의에 따라 동적으로 점수를 부여하는 새로운 논리 규칙 학습 프레임워크로, 기존 방법들의 한계를 극복하고 지식 그래프 완성에서 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 논리 규칙 기반 방법이 질의에 따라 변동하는 규칙의 중요성을 무시하였기 때문에, 이를 개선하기 위해 질의에 의존하는 점수를 갖는 SLogic 프레임워크를 도입하였다.

Method: SLogic은 질의의 머리 엔티티를 중심으로 한 서브그래프를 활용하여, 규칙의 중요성을 동적으로 평가하는 점수 함수로 구성된다.

Result: SLogic은 로컬 서브그래프 컨텍스트를 활용하여, 기존의 최첨단 기준 성능을 일관되게 초과하는 결과를 보인다.

Conclusion: SLogic은 지식 그래프 완성 문제에서 매우 효율적인 방법으로 입증되었다.

Abstract: Logical rule-based methods offer an interpretable approach to knowledge graph
completion by capturing compositional relationships in the form of
human-readable inference rules. However, current approaches typically treat
logical rules as universal, assigning each rule a fixed confidence score that
ignores query-specific context. This is a significant limitation, as a rule's
importance can vary depending on the query. To address this, we introduce
SLogic (Subgraph-Informed Logical Rule learning), a novel framework that
assigns query-dependent scores to logical rules. The core of SLogic is a
scoring function that utilizes the subgraph centered on a query's head entity,
allowing the significance of each rule to be assessed dynamically. Extensive
experiments on benchmark datasets show that by leveraging local subgraph
context, SLogic consistently outperforms state-of-the-art baselines, including
both embedding-based and rule-based methods.

</details>


### [37] [Understanding Sensitivity of Differential Attention through the Lens of Adversarial Robustness](https://arxiv.org/abs/2510.00517)
*Tsubasa Takahashi,Shojiro Yamabe,Futa Waseda,Kento Sasaki*

Main category: cs.LG

TL;DR: Differential Attention(DA)는 표준 주의력을 개선하지만, 적대적 섭동에 대한 구조적 취약성을 도입한다.


<details>
  <summary>Details</summary>
Motivation: DA는 불필요하거나 소란스러운 맥락을 억제하여 맥락적 환각을 줄이기 위해 제안되었다.

Method: 이론적 분석을 통해 DA의 뺄셈이 유도하는 부정적 기울기 정렬이 민감도 증폭의 주요 원인임을 밝혀냈다.

Result: ViT/DiffViT에 대한 체계적인 실험과 pretrained CLIP/DiffCLIP 평가를 통해 공격 성공률이 높아지고, 기울기 반대가 자주 발생하며, 국소 민감도가 강해짐을 확인했다.

Conclusion: DA는 깨끗한 입력에 대한 식별 초점을 개선하지만 적대적 취약성을 증가시켜 미래의 주의 메커니즘에서 선택성과 강인성을 동시에 고려해야 함을 강조한다.

Abstract: Differential Attention (DA) has been proposed as a refinement to standard
attention, suppressing redundant or noisy context through a subtractive
structure and thereby reducing contextual hallucination. While this design
sharpens task-relevant focus, we show that it also introduces a structural
fragility under adversarial perturbations. Our theoretical analysis identifies
negative gradient alignment-a configuration encouraged by DA's subtraction-as
the key driver of sensitivity amplification, leading to increased gradient
norms and elevated local Lipschitz constants. We empirically validate this
Fragile Principle through systematic experiments on ViT/DiffViT and evaluations
of pretrained CLIP/DiffCLIP, spanning five datasets in total. These results
demonstrate higher attack success rates, frequent gradient opposition, and
stronger local sensitivity compared to standard attention. Furthermore,
depth-dependent experiments reveal a robustness crossover: stacking DA layers
attenuates small perturbations via depth-dependent noise cancellation, though
this protection fades under larger attack budgets. Overall, our findings
uncover a fundamental trade-off: DA improves discriminative focus on clean
inputs but increases adversarial vulnerability, underscoring the need to
jointly design for selectivity and robustness in future attention mechanisms.

</details>


### [38] [DecepChain: Inducing Deceptive Reasoning in Large Language Models](https://arxiv.org/abs/2510.00319)
*Wei Shen,Han Wang,Haoyu Li,Huan Zhang*

Main category: cs.LG

TL;DR: DecepChain은 대형 언어 모델(LLM)을 속여 잘못된 결론을 내리게 하는 새로운 백도어 공격 기법이다.


<details>
  <summary>Details</summary>
Motivation: LLM의 이유 판단 능력에 대한 인간의 의존이 신뢰의 강력하지만 취약한 기반을 만든다.

Method: DecepChain은 LLM의 환각을 이용하고 자연적으로 발생하는 오류 결과물에 대해 세밀하게 조정하여 고친다.

Result: DecepChain은 여러 벤치마크에서 높은 공격 성공률을 보이며, 정상적인 시나리오에서의 성능 저하는 최소화된다.

Conclusion: 이러한 공격 방식이 해결되지 않으면 LLM의 답변이 부패하고 인간의 신뢰가 약화될 수 있으며, 향후 연구의 긴급성을 강조한다.

Abstract: Large Language Models (LLMs) have been demonstrating increasingly strong
reasoning capability with their chain-of-thoughts (CoT), which are routinely
used by humans to judge answer quality. This reliance creates a powerful yet
fragile basis for trust. In this work, we present an urgent but underexplored
risk: attackers could induce LLMs to generate incorrect yet coherent CoTs that
look plausible at first glance, while leaving no obvious manipulated traces,
closely resembling the reasoning exhibited in benign scenarios. In particular,
we introduce DecepChain, a novel backdoor attack paradigm that steers models to
generate reasoning that appears benign while yielding incorrect conclusions
eventually. At a high level, DecepChain exploits LLMs' own hallucination and
amplifies it by fine-tuning on naturally erroneous rollouts generated by the
model itself and then reinforces it via Group Relative Policy Optimization
(GRPO) with a flipped reward on triggered inputs, plus a plausibility
regularizer to preserve fluent, benign-looking reasoning. Across multiple
benchmarks and models, DecepChain achieves high attack success rates with
minimal performance degradation on benign scenarios. Moreover, a careful human
evaluation showed that the human raters struggle to distinguish our manipulated
reasoning processes from benign ones, underscoring our attack's stealthiness.
Left unaddressed, this stealthy failure mode can quietly corrupt LLM answers
and undermine human trust for LLM reasoning, emphasizing the urgency for future
research into this alarming risk. Project page: https://decepchain.github.io/.

</details>


### [39] [Automated Structured Radiology Report Generation with Rich Clinical Context](https://arxiv.org/abs/2510.00428)
*Seongjae Kang,Dong Bok Lee,Juho Jung,Dongseop Kim,Won Hwa Kim,Sunghoon Joo*

Main category: cs.LG

TL;DR: 이 논문에서는 흉부 X-선 이미지를 기반으로 하는 자동화된 구조화된 영상의학 보고서 생성을 통해 방사선사의 업무 부담을 줄이는 가능성을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 SRRG 시스템은 진단 추론에서 중요한 임상 맥락을 간과하여 비현실적인 임상 상황을 참조할 때 시간적 환각과 같은 심각한 문제를 발생시킨다.

Method: 우리는 임상 맥락을 포괄적으로 통합한 맥락화된 SRRG(C-SRRG)를 제안하고, 다양한 임상 정보를 포함한 C-SRRG 데이터셋을 구축한다.

Result: 최신 멀티모달 대형 언어 모델과의 광범위한 벤치마킹을 통해 C-SRRG와 임상 맥락을 통합함으로써 보고서 생성 품질이 크게 향상됨을 입증한다.

Conclusion: 우리는 데이터셋, 코드 및 체크포인트를 공개하여 임상 일치 자동 RRG를 위한 향후 연구를 촉진하고자 한다.

Abstract: Automated structured radiology report generation (SRRG) from chest X-ray
images offers significant potential to reduce workload of radiologists by
generating reports in structured formats that ensure clarity, consistency, and
adherence to clinical reporting standards. While radiologists effectively
utilize available clinical contexts in their diagnostic reasoning, existing
SRRG systems overlook these essential elements. This fundamental gap leads to
critical problems including temporal hallucinations when referencing
non-existent clinical contexts. To address these limitations, we propose
contextualized SRRG (C-SRRG) that comprehensively incorporates rich clinical
context for SRRG. We curate C-SRRG dataset by integrating comprehensive
clinical context encompassing 1) multi-view X-ray images, 2) clinical
indication, 3) imaging techniques, and 4) prior studies with corresponding
comparisons based on patient histories. Through extensive benchmarking with
state-of-the-art multimodal large language models, we demonstrate that
incorporating clinical context with the proposed C-SRRG significantly improves
report generation quality. We publicly release dataset, code, and checkpoints
to facilitate future research for clinically-aligned automated RRG at
https://github.com/vuno/contextualized-srrg.

</details>


### [40] [Robust Spatiotemporally Contiguous Anomaly Detection Using Tensor Decomposition](https://arxiv.org/abs/2510.00460)
*Rachita Mondal,Mert Indibi,Tapabrata Maiti,Selin Aviyente*

Main category: cs.LG

TL;DR: 본 논문에서는 비지도학습 텐서 기반 이상 탐지 방법을 제안하며, 이상 탐지를 위한 희소성과 시공간적으로 부드러운 특성을 동시에 고려한다.


<details>
  <summary>Details</summary>
Motivation: 시공간 데이터에서의 이상 탐지는 비디오 감시, 의료 영상 데이터, 도시 교통 모니터링 등 다양한 응용 분야에서 발생하는 어려운 문제이다.

Method: 희소성과 시공간적으로 부드러운 특성을 고려한 비지도 텐서 기반 이상 탐지 방법을 제안하고, 정규화된 강인 저랭크 + 희소 텐서 분해로 이상 탐지 문제를 공식화한다.

Result: 제안된 방법은 합성 데이터와 실제 데이터 모두에서 평가를 수행한다.

Conclusion: 제안된 접근 방식은 지역적 시공간 의존성을 고려한 통계적 이상 점수 매기기 프레임워크를 포함한다.

Abstract: Anomaly detection in spatiotemporal data is a challenging problem encountered
in a variety of applications, including video surveillance, medical imaging
data, and urban traffic monitoring. Existing anomaly detection methods focus
mainly on point anomalies and cannot deal with temporal and spatial
dependencies that arise in spatio-temporal data. Tensor-based anomaly detection
methods have been proposed to address this problem. Although existing methods
can capture dependencies across different modes, they are primarily supervised
and do not account for the specific structure of anomalies. Moreover, these
methods focus mainly on extracting anomalous features without providing any
statistical confidence. In this paper, we introduce an unsupervised
tensor-based anomaly detection method that simultaneously considers the sparse
and spatiotemporally smooth nature of anomalies. The anomaly detection problem
is formulated as a regularized robust low-rank + sparse tensor decomposition
where the total variation of the tensor with respect to the underlying spatial
and temporal graphs quantifies the spatiotemporal smoothness of the anomalies.
Once the anomalous features are extracted, we introduce a statistical anomaly
scoring framework that accounts for local spatio-temporal dependencies. The
proposed framework is evaluated on both synthetic and real data.

</details>


### [41] [Diagnosing Shortcut-Induced Rigidity in Continual Learning: The Einstellung Rigidity Index (ERI)](https://arxiv.org/abs/2510.00475)
*Kai Gu,Weishi Shi*

Main category: cs.LG

TL;DR: 딥 신경망은 인과적 의미가 없는 입력과 레이블 간의 우연한 상관관계인 단축 기능을 자주 이용하며, 이러한 단축 기능은 견고성을 저하시켜 배포 변화에 대한 신뢰성을 감소시킨다. 본 논문에서는 전략적 습관인 에스텐클하기를 방지하기 위해 에스텐클 강직성 지수(ERI)를 도입하고, 여러 지속 학습 방법을 평가하여 패치가 CL 모델에 방해 요소로 작용했음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 딥 신경망에서의 단축 기능 활용이 견고성 및 신뢰성에 미치는 영향을 탐구하고, 지속 학습 과정에서 이러한 영향이 어떻게 심화되는지를 이해하는 것이 본 연구의 목적이다.

Method: Einstellung 강직성 지수(ERI)를 도입하여 진정한 전이와 큐가 부풀려진 성능을 구분하는 진단 방법을 평가하였다. 세 가지 해석 가능한 측면(적응 지연, 성과 결핍, 상대 비최적 특성 의존성)을 통해 다양한 지속 학습 방법을 검토하였다.

Result: 지속 학습 방법이 Scratch-T2 기준보다 더 일찍 정확도 임계치에 도달하지만, 패치된 단축 클래스에서는 최종 정확도가 약간 낮았다. 패킹을 통해 CL 방법의 정확도가 향상되었고 Scratch-T2의 정확도는 약간 감소하였다.

Conclusion: 패치는 CL 모델에서 도움이 되는 단축이 아니라 주의력을 분산시키는 요소로 작용했음을 나타내는 패턴이 관찰되었다.

Abstract: Deep neural networks frequently exploit shortcut features, defined as
incidental correlations between inputs and labels without causal meaning.
Shortcut features undermine robustness and reduce reliability under
distribution shifts. In continual learning (CL), the consequences of shortcut
exploitation can persist and intensify: weights inherited from earlier tasks
bias representation reuse toward whatever features most easily satisfied prior
labels, mirroring the cognitive Einstellung effect, a phenomenon where past
habits block optimal solutions. Whereas catastrophic forgetting erodes past
skills, shortcut-induced rigidity throttles the acquisition of new ones. We
introduce the Einstellung Rigidity Index (ERI), a compact diagnostic that
disentangles genuine transfer from cue-inflated performance using three
interpretable facets: (i) Adaptation Delay (AD), (ii) Performance Deficit (PD),
and (iii) Relative Suboptimal Feature Reliance (SFR_rel). On a two-phase
CIFAR-100 CL benchmark with a deliberately spurious magenta patch in Phase 2,
we evaluate Naive fine-tuning (SGD), online Elastic Weight Consolidation
(EWC_on), Dark Experience Replay (DER++), Gradient Projection Memory (GPM), and
Deep Generative Replay (DGR). Across these continual learning methods, we
observe that CL methods reach accuracy thresholds earlier than a Scratch-T2
baseline (negative AD) but achieve slightly lower final accuracy on patched
shortcut classes (positive PD). Masking the patch improves accuracy for CL
methods while slightly reducing Scratch-T2, yielding negative SFR_rel. This
pattern indicates the patch acted as a distractor for CL models in this setting
rather than a helpful shortcut.

</details>


### [42] [Designing Ambiguity Sets for Distributionally Robust Optimization Using Structural Causal Optimal Transport](https://arxiv.org/abs/2510.00599)
*Ahmad-Reza Ehyaei,Golnoosh Farnadi,Samira Samadi*

Main category: cs.LG

TL;DR: 본 연구는 구조적 인과 모델을 기반으로 한 모호성 집합을 통해 분포 강건 최적화를 향상시키는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 보다 현실적인 확률 분포를 포함하는 모호성 집합이 필요합니다.

Method: 구조적 인과 최적 운송 및 관련 모호성 집합을 도입하고, 인과 그래프와 구조 방정식을 통합했습니다.

Result: 복잡한 인과 제약 대신 정규화 항을 도입한 완화된 버전의 효율적인 알고리즘을 통해 성과를 내었습니다.

Conclusion: 우리의 방법은 차원 무관한 순서로 최적 운송 문제에서 성능을 향상시키며 유한 샘플 보장을 제공합니다.

Abstract: Distributionally robust optimization tackles out-of-sample issues like
overfitting and distribution shifts by adopting an adversarial approach over a
range of possible data distributions, known as the ambiguity set. To balance
conservatism and accuracy, these sets must include realistic probability
distributions by leveraging information from the nominal distribution. Assuming
that nominal distributions arise from a structural causal model with a directed
acyclic graph $\mathcal{G}$ and structural equations, previous methods such as
adapted and $\mathcal{G}$-causal optimal transport have only utilized causal
graph information in designing ambiguity sets. In this work, we propose
incorporating structural equations, which include causal graph information, to
enhance ambiguity sets, resulting in more realistic distributions. We introduce
structural causal optimal transport and its associated ambiguity set,
demonstrating their advantages and connections to previous methods. A key
benefit of our approach is a relaxed version, where a regularization term
replaces the complex causal constraints, enabling an efficient algorithm via
difference-of-convex programming to solve structural causal optimal transport.
We also show that when structural information is absent and must be estimated,
our approach remains effective and provides finite sample guarantees. Lastly,
we address the radius of ambiguity sets, illustrating how our method overcomes
the curse of dimensionality in optimal transport problems, achieving faster
shrinkage with dimension-free order.

</details>


### [43] [Multi-Agent Stage-wise Conservative Linear Bandits](https://arxiv.org/abs/2510.00602)
*Amirhoseein Afsharrad,Ahmadreza Moradipari,Sanjay Lall*

Main category: cs.LG

TL;DR: 본 연구에서는 안전 보장을 유지하면서 다중 에이전트가 탐색과 활용 간의 균형을 맞춰야 하는 다중 에이전트 네트워크 환경에서 확률적 선형 밴딧 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 추천 시스템과 같은 실제 응용 프로그램에서 다수의 학습 에이전트는 재앙적 실패를 피하기 위해 안전 보장을 유지하면서 탐색과 활용을 균형 있게 수행해야 한다.

Method: 우리의 접근 방식은 MA-SCLUCB(다중 에이전트 단계별 보수적 선형 UCB)라는 에피소딥 알고리즘을 제안하며, 행동 선택 단계와 합의 구축 단계를 번갈아 실행한다.

Result: MA-SCLUCB는 높은 확률로 $	ilde{O}igg(rac{d}{	ext{평균 시나리오 수}}igg)$ 형태의 후회를 달성함을 증명하였다.

Conclusion: 안전 보장을 갖춘 분산 학습은 합리적으로 연결된 네트워크에서 거의 최적의 성과를 달성한다.

Abstract: In many real-world applications such as recommendation systems, multiple
learning agents must balance exploration and exploitation while maintaining
safety guarantees to avoid catastrophic failures. We study the stochastic
linear bandit problem in a multi-agent networked setting where agents must
satisfy stage-wise conservative constraints. A network of $N$ agents
collaboratively maximizes cumulative reward while ensuring that the expected
reward at every round is no less than $(1-\alpha)$ times that of a baseline
policy. Each agent observes local rewards with unknown parameters, but the
network optimizes for the global parameter (average of local parameters).
Agents communicate only with immediate neighbors, and each communication round
incurs additional regret. We propose MA-SCLUCB (Multi-Agent Stage-wise
Conservative Linear UCB), an episodic algorithm alternating between action
selection and consensus-building phases. We prove that MA-SCLUCB achieves
regret
$\tilde{O}\left(\frac{d}{\sqrt{N}}\sqrt{T}\cdot\frac{\log(NT)}{\sqrt{\log(1/|\lambda_2|)}}\right)$
with high probability, where $d$ is the dimension, $T$ is the horizon, and
$|\lambda_2|$ is the network's second largest eigenvalue magnitude. Our
analysis shows: (i) collaboration yields $\frac{1}{\sqrt{N}}$ improvement
despite local communication, (ii) communication overhead grows only
logarithmically for well-connected networks, and (iii) stage-wise safety adds
only lower-order regret. Thus, distributed learning with safety guarantees
achieves near-optimal performance in reasonably connected networks.

</details>


### [44] [TD-JEPA: Latent-predictive Representations for Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.00739)
*Marco Bagatella,Matteo Pirotta,Ahmed Touati,Alessandro Lazaric,Andrea Tirinzoni*

Main category: cs.LG

TL;DR: 기존의 단일 작업 학습 방식의 한계를 극복하고 다양한 보상 함수에서 제로샷 최적화를 가능하게 하는 TD-JEPA를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 방법들은 단일 작업 학습이나 정책 데이터에 제한되어 있었고, 이를 극복하고자 하였다.

Method: TD-JEPA는 TD 기반 잠재 예측 표현을 사용하여 비지도 강화 학습을 수행하며, 명시적인 상태 및 작업 인코더, 정책 조건 다단계 예측기 및 매개변수화된 정책 집합을 잠재 공간에서 직접 훈련한다.

Result: TD-JEPA는 13개 데이터셋에서 운동, 탐색, 조작 작업에 대한 최신 벤치마크를 일치시키거나 초과 성능을 보인다.

Conclusion: 이론적으로, TD-JEPA의 이상화된 변형은 적절한 초기화로 붕괴를 피하고, 장기 정책 역학의 저차원 분해를 캡처하는 인코더를 학습한다.

Abstract: Latent prediction--where agents learn by predicting their own latents--has
emerged as a powerful paradigm for training general representations in machine
learning. In reinforcement learning (RL), this approach has been explored to
define auxiliary losses for a variety of settings, including reward-based and
unsupervised RL, behavior cloning, and world modeling. While existing methods
are typically limited to single-task learning, one-step prediction, or
on-policy trajectory data, we show that temporal difference (TD) learning
enables learning representations predictive of long-term latent dynamics across
multiple policies from offline, reward-free transitions. Building on this, we
introduce TD-JEPA, which leverages TD-based latent-predictive representations
into unsupervised RL. TD-JEPA trains explicit state and task encoders, a
policy-conditioned multi-step predictor, and a set of parameterized policies
directly in latent space. This enables zero-shot optimization of any reward
function at test time. Theoretically, we show that an idealized variant of
TD-JEPA avoids collapse with proper initialization, and learns encoders that
capture a low-rank factorization of long-term policy dynamics, while the
predictor recovers their successor features in latent space. Empirically,
TD-JEPA matches or outperforms state-of-the-art baselines on locomotion,
navigation, and manipulation tasks across 13 datasets in ExoRL and OGBench,
especially in the challenging setting of zero-shot RL from pixels.

</details>


### [45] [Downgrade to Upgrade: Optimizer Simplification Enhances Robustness in LLM Unlearning](https://arxiv.org/abs/2510.00761)
*Yicheng Lang,Yihua Zhang,Chongyu Fan,Changsheng Wang,Jinghan Jia,Sijia Liu*

Main category: cs.LG

TL;DR: 대규모 언어 모델에서의 잊기 기술은 원치 않는 데이터의 영향을 제거하면서도 다른 작업에 대한 유용성을 유지하는 것을 목표로 한다. 본 논문에서는 최적화기의 역할을 조사하여 잊기 강건성을 향상시키는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 개인정보 보호 및 안전 문제를 다루기 위해 대규모 언어 모델에서 원하는 데이터를 제거하는 기술의 필요성이 대두되고 있다.

Method: 최적화기의 정보를 활용한 수준에 따라 잊기 강건성의 관계를 연구하고, 첫 번째 및 제로 순서 업데이트를 결합한 하이브리드 최적화기를 제안한다.

Result: 우리는 다양한 LLM 잊기 알고리즘에서 실험을 통해 우리의 접근 방식이 잊기 품질을 희생하지 않고도 더욱 강건한 망각을 달성함을 입증하였다.

Conclusion: 본 연구는 최적화기가 잊기 강건성에 미치는 영향을 밝혀내고, 강건한 잊기를 위한 새로운 하이브리드 최적화기를 제안한다.

Abstract: Large language model (LLM) unlearning aims to surgically remove the influence
of undesired data or knowledge from an existing model while preserving its
utility on unrelated tasks. This paradigm has shown promise in addressing
privacy and safety concerns. However, recent findings reveal that unlearning
effects are often fragile: post-unlearning manipulations such as weight
quantization or fine-tuning can quickly neutralize the intended forgetting.
Prior efforts to improve robustness primarily reformulate unlearning objectives
by explicitly assuming the role of vulnerability sources. In this work, we take
a different perspective by investigating the role of the optimizer, independent
of unlearning objectives and formulations, in shaping unlearning robustness. We
show that the 'grade' of the optimizer, defined by the level of information it
exploits, ranging from zeroth-order (gradient-free) to first-order
(gradient-based) to second-order (Hessian-based), is tightly linked to the
resilience of unlearning. Surprisingly, we find that downgrading the optimizer,
such as using zeroth-order methods or compressed-gradient variants (e.g.,
gradient sign-based optimizers), often leads to stronger robustness. While
these optimizers produce noisier and less precise updates, they encourage
convergence to harder-to-disturb basins in the loss landscape, thereby
resisting post-training perturbations. By connecting zeroth-order methods with
randomized smoothing, we further highlight their natural advantage for robust
unlearning. Motivated by these insights, we propose a hybrid optimizer that
combines first-order and zeroth-order updates, preserving unlearning efficacy
while enhancing robustness. Extensive experiments on the MUSE and WMDP
benchmarks, across multiple LLM unlearning algorithms, validate that our
approach achieves more resilient forgetting without sacrificing unlearning
quality.

</details>


### [46] [Guiding Evolutionary Molecular Design: Adding Reinforcement Learning for Mutation Selection](https://arxiv.org/abs/2510.00802)
*Gaelle Milon-Harnois,Chaimaa Touhami,Nicolas Gutowski,Benoit Da Mota,Thomas Cauchy*

Main category: cs.LG

TL;DR: EvoMol-RL은 분자 변이를 위한 강화 학습을 통합하여 화학적으로 타당한 분자를 효율적으로 탐색하는 방법을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 화학 공간의 효율적인 탐색은 여전히 중심적인 도전으로, 많은 생성 모델이 불안정하거나 비합성 가능한 화합물을 생성합니다.

Method: EvoMol-RL은 지역 구조적 맥락에 따라 분자 변이를 안내하기 위해 강화 학습을 통합한 EvoMol 진화 알고리즘의 중요한 확장입니다. 이를 통해 ECFP를 활용하여 화학적으로 그럴듯한 변환을 우선시하는 맥락 인식 변이 정책을 배웁니다.

Result: EvoMol-RL은 유효하고 현실적인 분자의 생성을 크게 개선하여 구조적 인공물의 빈도를 줄이고 최적화 성능을 향상시킵니다.

Conclusion: EvoMol-RL은 분자 사전 필터링 현실성에서 일관되게 기준선보다 우수한 성능을 보이며, 강화 학습과 분자 핑거프린트를 결합하여 화학적으로 관련 있는 분자 구조를 생성하는 효과성을 강조합니다.

Abstract: The efficient exploration of chemical space remains a central challenge, as
many generative models still produce unstable or non-synthesizable compounds.
To address these limitations, we present EvoMol-RL, a significant extension of
the EvoMol evolutionary algorithm that integrates reinforcement learning to
guide molecular mutations based on local structural context. By leveraging
Extended Connectivity Fingerprints (ECFPs), EvoMol-RL learns context-aware
mutation policies that prioritize chemically plausible transformations. This
approach significantly improves the generation of valid and realistic
molecules, reducing the frequency of structural artifacts and enhancing
optimization performance. The results demonstrate that EvoMol-RL consistently
outperforms its baseline in molecular pre-filtering realism. These results
emphasize the effectiveness of combining reinforcement learning with molecular
fingerprints to generate chemically relevant molecular structures.

</details>


### [47] [Stabilizing Policy Gradients for Sample-Efficient Reinforcement Learning in LLM Reasoning](https://arxiv.org/abs/2510.00819)
*Luckeciano C. Melo,Alessandro Abate,Yarin Gal*

Main category: cs.LG

TL;DR: CAPO는 정책 기울기를 최적화하기 위한 새로운 알고리즘으로, 샘플 효율성을 높이는 데 도움을 준다.


<details>
  <summary>Details</summary>
Motivation: 정책 기울기 방법을 통한 강화 학습의 최적화 안정성이 충분히 연구되지 않았다.

Method: 우리는 정책 업데이트 중 곡률 정보를 추적하고 활용하는 계산 프레임워크를 제안하고, 이를 통해 데이터 선택을 통한 최적화 과정의 개입을 설계한다.

Result: CAPO는 불안정한 업데이트에 기여하는 샘플을 식별하고 이를 마스킹하여 안정적인 업데이트를 보장하며, 실제 데이터에서 최소한의 개입으로 샘플 효율성을 크게 개선한다.

Conclusion: CAPO는 공격적인 학습 체제에서 표준 방법이 실패하는 상황에서도 안정적인 업데이트를 보장한다.

Abstract: Reinforcement Learning, particularly through policy gradient methods, has
played a central role in enabling reasoning capabilities of Large Language
Models. However, the optimization stability of policy gradients in this setting
remains understudied. As a result, existing implementations often resort to
conservative hyperparameter choices to ensure stability, which requires more
training samples and increases computational costs. Hence, developing models
for reliably tracking the underlying optimization dynamics and leveraging them
into training enables more sample-efficient regimes and further unleashes
scalable post-training. We address this gap by formalizing the stochastic
optimization problem of policy gradients with explicit consideration of
second-order geometry. We propose a tractable computational framework that
tracks and leverages curvature information during policy updates. We further
employ this framework to design interventions in the optimization process
through data selection. The resultant algorithm, Curvature-Aware Policy
Optimization (CAPO), identifies samples that contribute to unstable updates and
masks them out. Theoretically, we establish monotonic improvement guarantees
under realistic assumptions. On standard math reasoning benchmarks, we
empirically show that CAPO ensures stable updates under aggressive learning
regimes where baselines catastrophically fail. With minimal intervention
(rejecting fewer than 8% of tokens), CAPO achieves up to 30x improvement in
sample efficiency over standard GRPO for LLM reasoning.

</details>


### [48] [Target Population Synthesis using CT-GAN](https://arxiv.org/abs/2510.00871)
*Tanay Rastogi,Daniel Jonsson*

Main category: cs.LG

TL;DR: 이 연구는 CT-GAN을 활용하여 대규모 도시 계획을 위한 목표 집단을 생성하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 교통 및 도시 계획을 위한 에이전트 기반 모델은 상세한 인구 정보를 필요로 하며, 현재의 결정론적 인구 합성 방법에는 여러 가지 문제점이 있다.

Method: 조건부 표 형식 생성적 적대 신경망(CT-GAN)을 사용하여 마가진 제약에서 직접 또는 CT-GAN과 적합도 기반 합성 조합 최적화(FBS-CO)를 결합한 하이브리드 방법으로 목표 인구를 생성한다.

Result: CT-GAN 모델이 FBS-CO와 하이브리드 모델보다 더 나은 성능을 보이며, 단일 변수 분포와 일치하는 사실적인 군집을 생성할 수 있지만 다중 변수 간의 관계를 유지하는 데 어려움을 겪는다.

Conclusion: CT-GAN은 목표 집단에 효과적인 방법론을 제공하며, 깊은 생성 모델이 기존 합성 기술과 통합될 수 있는 가능성을 보여준다.

Abstract: Agent-based models used in scenario planning for transportation and urban
planning usually require detailed population information from the base as well
as target scenarios. These populations are usually provided by synthesizing
fake agents through deterministic population synthesis methods. However, these
deterministic population synthesis methods face several challenges, such as
handling high-dimensional data, scalability, and zero-cell issues, particularly
when generating populations for target scenarios. This research looks into how
a deep generative model called Conditional Tabular Generative Adversarial
Network (CT-GAN) can be used to create target populations either directly from
a collection of marginal constraints or through a hybrid method that combines
CT-GAN with Fitness-based Synthesis Combinatorial Optimization (FBS-CO). The
research evaluates the proposed population synthesis models against travel
survey and zonal-level aggregated population data. Results indicate that the
stand-alone CT-GAN model performs the best when compared with FBS-CO and the
hybrid model. CT-GAN by itself can create realistic-looking groups that match
single-variable distributions, but it struggles to maintain relationships
between multiple variables. However, the hybrid model demonstrates improved
performance compared to FBS-CO by leveraging CT-GAN ability to generate a
descriptive base population, which is then refined using FBS-CO to align with
target-year marginals. This study demonstrates that CT-GAN represents an
effective methodology for target populations and highlights how deep generative
models can be successfully integrated with conventional synthesis techniques to
enhance their performance.

</details>


### [49] [Riemannian Consistency Model](https://arxiv.org/abs/2510.00983)
*Chaoran Cheng,Yusong Wang,Yuxin Chen,Xiangxin Zhou,Nanning Zheng,Ge Liu*

Main category: cs.LG

TL;DR: Riemannian 일관성 모델(RCM)은 비유클리드 기하학에서 몇 단계로 데이터 생성을 가능하게 하는 최초의 방법이다.


<details>
  <summary>Details</summary>
Motivation: 비유클리드 영역에서의 데이터 생성 모델의 발전과 Riemannian 기하학의 제약을 극복하는 것이 필요하다.

Method: RCM은 공변 도함수와 지수 맵 기반 매개변수를 활용하여 RCM의 이산 및 연속 시간 훈련 목표에 대한 폐쇄 형태의 해를 유도한다.

Result: RCM은 다양한 비유클리드 다양체에서 우수한 생성 품질을 보이며, Riemannian 일관성 증류(RCD)와 Riemannian 일관성 훈련(RCT)의 이론적 동등성을 입증한다.

Conclusion: RCM의 독특한 운동학적 관점을 제공하며, 이론적 분석에 새로운 각도를 제시한다.

Abstract: Consistency models are a class of generative models that enable few-step
generation for diffusion and flow matching models. While consistency models
have achieved promising results on Euclidean domains like images, their
applications to Riemannian manifolds remain challenging due to the curved
geometry. In this work, we propose the Riemannian Consistency Model (RCM),
which, for the first time, enables few-step consistency modeling while
respecting the intrinsic manifold constraint imposed by the Riemannian
geometry. Leveraging the covariant derivative and exponential-map-based
parameterization, we derive the closed-form solutions for both discrete- and
continuous-time training objectives for RCM. We then demonstrate theoretical
equivalence between the two variants of RCM: Riemannian consistency
distillation (RCD) that relies on a teacher model to approximate the marginal
vector field, and Riemannian consistency training (RCT) that utilizes the
conditional vector field for training. We further propose a simplified training
objective that eliminates the need for the complicated differential
calculation. Finally, we provide a unique kinematics perspective for
interpreting the RCM objective, offering new theoretical angles. Through
extensive experiments, we manifest the superior generative quality of RCM in
few-step generation on various non-Euclidean manifolds, including flat-tori,
spheres, and the 3D rotation group SO(3).

</details>


### [50] [GEM: A Gym for Agentic LLMs](https://arxiv.org/abs/2510.01051)
*Zichen Liu,Anya Sims,Keyu Duan,Changyu Chen,Simon Yu,Xiangxin Zhou,Haotian Xu,Shaopan Xiong,Bo Liu,Chenmien Tan,Chuen Yang Beh,Weixun Wang,Hao Zhu,Weiyan Shi,Diyi Yang,Michael Shieh,Yee Whye Teh,Wee Sun Lee,Min Lin*

Main category: cs.LG

TL;DR: 본 논문은 대형 언어 모델의 훈련을 경험 기반 학습으로 전환하기 위한 GEM 환경 시뮬레이터를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 훈련 패러다임이 정적 데이터셋에서 경험 기반 학습으로 변화하고 있다.

Method: GEM은 에이전트와 환경 간의 표준화된 프레임워크를 제공하며, 비동기 벡터화 실행과 유연한 래퍼를 통해 확장성을 지원한다.

Result: GEM은 24개의 환경에 대한 REINFORCE와 Return Batch Normalization을 이용한 기준 집합을 제공하고, PPO, GRPO 및 REINFORCE의 벤치마킹을 수행하였다.

Conclusion: GEM은 훈련 환경 외에도 평가 도구로서 기능하며, 향후 에이전트 기반 LLM 연구가 가속화되기를 기대한다.

Abstract: The training paradigm for large language models (LLMs) is moving from static
datasets to experience-based learning, where agents acquire skills via
interacting with complex environments. To facilitate this transition we
introduce GEM (General Experience Maker), an open-source environment simulator
designed for the age of LLMs. Analogous to OpenAI-Gym for traditional
reinforcement learning (RL), GEM provides a standardized framework for the
environment-agent interface, including asynchronous vectorized execution for
high throughput, and flexible wrappers for easy extensibility. GEM also
features a diverse suite of environments, robust integrated tools, and
single-file example scripts demonstrating using GEM with five popular RL
training frameworks. Along with this, we also provide a set of baselines across
24 environments using REINFORCE with Return Batch Normalization (ReBN), which
-- unlike GRPO -- is compatible with the full RL setting of dense per-turn
rewards and offers better credit assignment. We further conduct apple-to-apple
benchmarking of PPO, GRPO and REINFORCE in both single- and multi-turn settings
using GEM to shed light on the algorithmic designs. Lastly, GEM also functions
as a convenient evaluation toolkit besides a training environment. We hope this
framework can help accelerate future agentic LLM research.

</details>


### [51] [A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning](https://arxiv.org/abs/2510.01132)
*Ruiyi Wang,Prithviraj Ammanabrolu*

Main category: cs.LG

TL;DR: 본 연구는 다중 턴 강화 학습을 통한 대형 언어 모델 교육의 효과를 분석하고, 관련 디자인 선택이 과제에 따라 어떻게 다르게 작용하는지를 규명합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 에이전트로 교육하는 데 있어 효과적인 방법과 비효율적인 방법을 규명하고자 함.

Method: 세 가지 상호 관련된 기둥(환경, 보상, 정책)으로 디자인 공간을 나누고, situated textual domains에서 LLM 에이전트를 훈련하기 위한 레시피를 경험적으로 도출함.

Result: 태스크 복잡성, 보상 희소성 및 정책 기법의 상호작용을 분석하여 최적의 RL 훈련 비율을 찾아냄.

Conclusion: 이 연구 결과들은 다중 턴 에이전틱 RL 분야의 연구 및 실용적 노력을 촉진할 수 있는 훈련 레시피로 정리됨.

Abstract: We study what actually works and what doesn't for training large language
models as agents via multi-turn reinforcement learning. Despite rapid progress,
existing frameworks and definitions are fragmented, and there is no systematic
formulation or analysis of which design choices matter across tasks. We address
this gap by first breaking down the design space into three inter-related
pillars -- environment, reward, and policy -- and empirically derive a recipe
for training LLM agents in situated textual domains. In particular, we test
TextWorld and ALFWorld, popular domains for testing situated embodied
reasoning, as well as SWE-Gym for more software engineering style tasks. (i)
For the environment, we analyze the impacts of task complexity in terms of
sizes of the state and action spaces as well as optimal solution length,
finding that even simple environments within a domain can provide signal on how
well an agent can generalize to more complex tasks. (ii) For the reward, we
ablate relative reward sparsity, observing that while dense turn-level rewards
accelerate training, performance and stability is highly dependent on the
choice of RL algorithm. (iii) And for the agent's policy, we explore the
interplay between reward sparsity and biased (PPO, GRPO) and unbiased (RLOO)
policy gradient methods in addition to showing how to find the optimal
Supervised Fine-tuning (SFT) to RL training ratio given a fixed budget. We
distill these findings into a training recipe that guides co-design across the
three pillars, facilitating research and practical efforts in multi-turn
agentic RL. Code: https://github.com/pearls-lab/meow-tea-taro

</details>


### [52] [Neural Hamilton--Jacobi Characteristic Flows for Optimal Transport](https://arxiv.org/abs/2510.01153)
*Yesom Park,Shu Liu,Mo Zhou,Stanley Osher*

Main category: cs.LG

TL;DR: 본 논문은 해밀턴-야코비(HJ) 방정식에 기반한 최적 운송(OT) 문제를 해결하기 위한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 최적 운송 문제를 해결하기 위한 효율적이고 정확한 방법을 찾기 위함입니다.

Method: 특성 방법을 이용하여 닫힌 형태의 쌍방향 운송 맵을 유도하고, HJ 방정식의 특성에 기반한 손실 함수를 사용하여 하나의 신경망을 훈련시킵니다.

Result: 제안된 방법은 최적 맵으로의 수렴을 보장하며, 다양한 데이터셋에 대한 실험을 통해 정확성, 확장성 및 효율성을 검증하였습니다.

Conclusion: 이 방법은 최적성을 입증할 수 있는 OT 응용에 신뢰할 수 있고 다목적 도구로 자리 잡습니다.

Abstract: We present a novel framework for solving optimal transport (OT) problems
based on the Hamilton--Jacobi (HJ) equation, whose viscosity solution uniquely
characterizes the OT map. By leveraging the method of characteristics, we
derive closed-form, bidirectional transport maps, thereby eliminating the need
for numerical integration. The proposed method adopts a pure minimization
framework: a single neural network is trained with a loss function derived from
the method of characteristics of the HJ equation. This design guarantees
convergence to the optimal map while eliminating adversarial training stages,
thereby substantially reducing computational complexity. Furthermore, the
framework naturally extends to a wide class of cost functions and supports
class-conditional transport. Extensive experiments on diverse datasets
demonstrate the accuracy, scalability, and efficiency of the proposed method,
establishing it as a principled and versatile tool for OT applications with
provable optimality.

</details>


### [53] [TOUCAN: Synthesizing 1.5M Tool-Agentic Data from Real-World MCP Environments](https://arxiv.org/abs/2510.01179)
*Zhangchen Xu,Adriana Meza Soria,Shawn Tan,Anurag Roy,Ashish Sunil Agrawal,Radha Poovendran,Rameswar Panda*

Main category: cs.LG

TL;DR: 대규모 언어 모델(LLM) 에이전트는 다양한 작업을 자동화하는 강력한 시스템으로 부상하고 있으나, 고품질의 공적으로 라이센스된 툴-에이전틱 훈련 데이터 부족으로 제약을 받고 있다. 이를 해결하기 위해, 우리는 1.5백만 개의 궤적을 포함한 Toucan이라는 가장 큰 공개 툴-에이전틱 데이터셋을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 오픈소스 커뮤니티에서의 툴-에이전틱 훈련 데이터의 부족 문제를 해결하고, 다양한 도구 사용과 복잡한 상호작용을 지원하는 데이터셋이 필요하다.

Method: Toucan은 거의 500개의 실제 모델 컨텍스트 프로토콜(MCP)으로부터 합성된 150만 개의 궤적을 포함하며, 진정한 MCP 환경을 활용하여 다양한 작업을 생성하는 데 필요한 파이프라인을 구축했다. 다섯 개의 모델을 사용하여 도구 사용 쿼리를 생성하고, 모델 기반 품질 필터링을 적용한 후, 두 개의 에이전틱 프레임워크를 사용하여 세 개의 교사 모델로 궤적을 생성한다.

Result: Toucan에서 미세 조정된 모델은 BFCL V3 벤치마크에서 더 큰 폐쇄형 소스 모델 보다 우수한 성능을 보였으며, MCP-Universe Bench에서 Pareto 경계를 확장했다.

Conclusion: Toucan은 툴-에이전틱 데이터셋 제공을 통해 LLM 에이전트의 성능을 향상시키고 다양한 작업 수행을 지원하는 중요한 기여를 한다.

Abstract: Large Language Model (LLM) agents are rapidly emerging as powerful systems
for automating tasks across domains. Yet progress in the open-source community
is constrained by the lack of high quality permissively licensed tool-agentic
training data. Existing datasets are often limited in diversity, realism, and
complexity, particularly regarding multi-tool and multi-turn interactions. To
address this gap, we introduce Toucan, the largest publicly available
tool-agentic dataset to date, containing 1.5 million trajectories synthesized
from nearly 500 real-world Model Context Protocols (MCPs). Unlike prior work,
Toucan leverages authentic MCP environments to generate diverse, realistic, and
challenging tasks with trajectories involving real tool execution. Our pipeline
first produces a broad spectrum of tool-use queries using five distinct models,
applies model-based quality filtering, and then generates agentic trajectories
with three teacher models using two agentic frameworks. Rigorous rule-based and
model-based validation ensures high-quality outputs. We also introduce three
extension mechanisms to further diversify tasks and simulate multi-turn
conversations. Models fine-tuned on Toucan outperform larger closed-source
counterparts on the BFCL V3 benchmark and push the Pareto frontier forward on
MCP-Universe Bench.

</details>


### [54] [Dirichlet-Prior Shaping: Guiding Expert Specialization in Upcycled MoEs](https://arxiv.org/abs/2510.01185)
*Leyla Mirvakhabova,Babak Ehteshami Bejnordi,Gaurav Kumar,Hanxue Liang,Wanru Zhao,Paul Whatmough*

Main category: cs.LG

TL;DR: DPSL 기법이 전문가 균형과 전문화를 개선하여 MoE 모델의 성능을 높인다.


<details>
  <summary>Details</summary>
Motivation: 미리 학습된 조밀한 모델을 희소한 전문가 혼합체(MoE)로 변환하면 모델 용량을 효과적으로 증가시킬 수 있지만, 전문가의 전문화가 부족해 성능에 영향을 미친다.

Method: DPSL(Dirichlet-Prior Shaping Loss)라는 새로운 라우터 정규화 기법을 도입하여 전문가 할당을 목표 Dirichlet 사전과 일치시켜 라우팅 확률 분포를 직접 형성한다.

Result: DPSL은 MoE 비전-언어 모델 실험에서 일관되게 상향 변환 전략과 정규화 기법을 초월하며, 전문화 문제를 해결하고 보다 적응적이며 고성능 모델을 촉진한다.

Conclusion: DPSL은 MoE 훈련을 넘어 범용적으로 적용 가능한 도구이며, 전문가의 특정 모달리티나 작업에 대한 집중을 유도할 수 있다.

Abstract: Upcycling pre-trained dense models into sparse Mixture-of-Experts (MoEs)
efficiently increases model capacity but often suffers from poor expert
specialization due to naive weight replication. Our analysis reveals that
upcycled MoEs, even with conventional regularization, exhibit low-confidence,
weakly differentiated routing, hindering performance. We introduce
Dirichlet-Prior Shaping Loss (DPSL), a novel router regularization technique
that directly shapes routing probability distributions by matching expert
assignments to a target Dirichlet prior. DPSL offers fine-grained control over
expert balance and specialization, and enables encoding of inductive biases
such as encouraging experts to focus on specific modalities or tasks, without
requiring manual intervention; notably, DPSL is a general tool applicable to
any module that outputs categorical probability distributions, extending its
utility beyond MoE training. Experiments on upcycled MoE vision-language models
(with Qwen2, Phi3, Llama3.2 LLM backbones) show DPSL consistently outperforms
upcycling strategies and regularization techniques across standard
vision-language benchmarks, addressing the critical issue of poor
specialization and fostering more adaptive, higher-performing models.

</details>
