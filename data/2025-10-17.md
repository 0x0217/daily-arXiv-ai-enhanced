<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 5]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.LG](#cs.LG) [Total: 19]
- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Semantic knowledge guides innovation and drives cultural evolution](https://arxiv.org/abs/2510.12837)
*Anil Yaman,Shen Tian,Björn Lindström*

Main category: cs.MA

TL;DR: 문화적 진화는 인간 사회가 세대를 거쳐 점점 더 복잡한 지식과 기술을 생성하도록 한다. 이 논문에서는 개념과 그 기능 간의 의미론적 지식 구조가 누적 혁신을 위한 인지적 지지대 역할을 한다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 인간 사회에서 혁신이 어떻게 발생하는지를 이해하고자 하며, 특히 사회적 학습과 인지적 과정 간의 관계를 명확히 하려는 목적이다.

Method: 문화적 진화 에이전트 기반 모델과 대규모 행동 실험(N=1,243)을 사용하여 가설을 검증하였다.

Result: 의미론적 지식과 사회적 학습이 결합하여 혁신을 증가시킴을 보여주었다. 의미론적 지식이 없는 참가자들은 사회적 학습이 가능한 경우에도 우연한 성과에 그쳤다.

Conclusion: 의미론적 지식은 인간의 누적 문화 형성을 가능하게 하는 중요한 인지적 과정이다.

Abstract: Cumulative cultural evolution enables human societies to generate
increasingly complex knowledge and technology over generations. While social
learning transmits innovations between individuals and generations, the
cognitive processes that generate these innovations remain poorly understood.
Here, we demonstrate that semantic knowledge-structured associations between
concepts and their functions-provides cognitive scaffolding for cumulative
innovation by guiding exploration toward plausible and meaningful actions. We
tested this hypothesis using a cultural evolutionary agent-based model and a
large-scale behavioural experiment (N = 1,243), in which individuals performed
a task requiring the combination of items into novel innovations. Across both
approaches, semantic knowledge and social learning interact synergistically to
enhance innovation. Behaviorally, participants without access to semantic
knowledge performed no better than chance, even when social learning was
available, and relied on shallow exploration strategies. These findings suggest
that semantic knowledge is a key cognitive process enabling human cumulative
culture.

</details>


### [2] [KVCOMM: Online Cross-context KV-cache Communication for Efficient LLM-based Multi-agent Systems](https://arxiv.org/abs/2510.12872)
*Hancheng Ye,Zhengqi Gao,Mingyuan Ma,Qinsi Wang,Yuzhe Fu,Ming-Yu Chung,Yueqian Lin,Zhijian Liu,Jianyi Zhang,Danyang Zhuo,Yiran Chen*

Main category: cs.MA

TL;DR: 이 논문은 멀티 에이전트 LLM 시스템에서의 비효율적인 프로세싱 문제를 해결하기 위한 KVCOMM 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 멀티 에이전트 LLM 시스템은 언어 처리 작업의 효율성을 높이기 위해 사용되지만, 에이전트 간의 중복된 컨텍스트 재처리로 인한 오버헤드 문제에 직면해 있습니다.

Method: KVCOMM은 KV-캐시를 재활용하고 겹치는 컨텍스트의 캐시 오프셋을 정렬하여 효율적인 프리필링을 가능하게 하는 훈련 없는 프레임워크입니다.

Result: KVCOMM은 다양한 멀티 에이전트 작업에서 70% 이상의 재사용률을 달성하며, 품질 저하 없이 속도를 크게 향상시킵니다.

Conclusion: KVCOMM은 5-agent 설정에서 표준 프리필 파이프라인에 비해 최대 7.8배의 속도 향상을 이루며, TTFT를 약 430ms에서 55ms로 감소시킵니다.

Abstract: Multi-agent large language model (LLM) systems are increasingly adopted for
complex language processing tasks that require communication and coordination
among agents. However, these systems often suffer substantial overhead from
repeated reprocessing of overlapping contexts across agents. In typical
pipelines, once an agent receives a message from its predecessor, the full
context-including prior turns-must be reprocessed from scratch, leading to
inefficient processing. While key-value (KV) caching is an effective solution
for avoiding redundant computation in single-agent settings where prefixes
remain unchanged, it cannot be directly reused in multi-agent scenarios due to
diverging prefixes introduced by agent-specific context extensions. We identify
that the core challenge lies in the offset variance of KV-caches across agents.
To address this, we propose KVCOMM, a training-free framework that enables
efficient prefilling in multi-agent inference by reusing KV-caches and aligning
cache offsets of overlapping contexts under diverse prefix contexts. KVCOMM
estimates and adjusts KV-caches for shared content by referencing a pool of
cached examples-termed anchors-that store observed cache deviations under
varying prefixes. The anchor pool is maintained and updated online, allowing
dynamic adaptation to distinct user requests and context structures. KVCOMM
achieves over 70% reuse rate across diverse multi-agent workloads, including
retrieval-augmented generation, math reasoning, and collaborative coding tasks,
all without quality degradation. Particularly, when each fully-connected agent
receives 1K input tokens with 512 prefix tokens and 512 output tokens under a
five-agent setting, KVCOMM achieves up to 7.8x speedup compared to the standard
prefill pipeline, reducing TTFT from ~430 ms to ~55 ms.

</details>


### [3] [Agentic Discovery: Closing the Loop with Cooperative Agents](https://arxiv.org/abs/2510.13081)
*J. Gregory Pauloski,Kyle Chard,Ian T. Foster*

Main category: cs.MA

TL;DR: 이 논문은 과학적 작업에서 인간의 결정 과정을 지원할 협력적 에이전트의 필요성을 제안하고 있습니다.


<details>
  <summary>Details</summary>
Motivation: 과학적 작업에서 데이터 기반 방법과 인공지능(AI), 자동화된 워크플로우의 발전이 발견 속도를 제약하는 주된 요소가 인간의 의사결정임을 인식하고 있습니다.

Method: 협력적 에이전트를 통해 인간의 역할을 보완하고 자율적 발견을 가능하게 하는 필요성을 주장합니다.

Result: 이러한 에이전트를 실현하기 위해 AI와 인프라 모두에서의 발전이 필요합니다.

Conclusion: 협력적 에이전트의 개발은 과학적 발견을 가속화할 수 있는 잠재력을 가지고 있습니다.

Abstract: As data-driven methods, artificial intelligence (AI), and automated workflows
accelerate scientific tasks, we see the rate of discovery increasingly limited
by human decision-making tasks such as setting objectives, generating
hypotheses, and designing experiments. We postulate that cooperative agents are
needed to augment the role of humans and enable autonomous discovery. Realizing
such agents will require progress in both AI and infrastructure.

</details>


### [4] [Altruistic Ride Sharing: A Community-Driven Approach to Short-Distance Mobility](https://arxiv.org/abs/2510.13227)
*Divyanshu Singh,Ashman Mehra,Snehanshu Saha,Santonu Sarkar*

Main category: cs.MA

TL;DR: 알트루이즘 중심의 라이드쉐어링(ARS) 시스템이 교통 혼잡 및 연료 소비 문제를 해결하고, 공정성과 지속 가능성을 증진 시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 도시 이동의 혼잡과 연료 소비 문제 해결 및 공정성과 지속 가능성을 추구하기 위해.

Method: 참여자들이 금전적 유인 대신 이타주의 포인트를 기반으로 운전사와 탑승자의 역할을 번갈아 수행하는 분산형 동료 간 이동 프레임워크를 제안하고, 동적 라이드 매칭을 위해 다중 에이전트 강화 학습(MADDPG) 및 게임 이론적 균형 보장을 통합.

Result: ARS는 실제 뉴욕시 택시 데이터를 활용하여 이동 거리와 배출가스를 줄이고, 차량 이용률을 높이며, 공정한 참여를 촉진함을 보여준다.

Conclusion: ARS는 기존의 라이드쉐어링에 대한 확장 가능한 커뮤니티 기반 대안으로, 개인의 행동을 집단적인 도시 지속 가능성 목표와 일치시킨다.

Abstract: Urban mobility faces persistent challenges of congestion and fuel
consumption, specifically when people choose a private, point-to-point commute
option. Profit-driven ride-sharing platforms prioritize revenue over fairness
and sustainability. This paper introduces Altruistic Ride-Sharing (ARS), a
decentralized, peer-to-peer mobility framework where participants alternate
between driver and rider roles based on altruism points rather than monetary
incentives. The system integrates multi-agent reinforcement learning (MADDPG)
for dynamic ride-matching, game-theoretic equilibrium guarantees for fairness,
and a population model to sustain long-term balance. Using real-world New York
City taxi data, we demonstrate that ARS reduces travel distance and emissions,
increases vehicle utilization, and promotes equitable participation compared to
both no-sharing and optimization-based baselines. These results establish ARS
as a scalable, community-driven alternative to conventional ride-sharing,
aligning individual behavior with collective urban sustainability goals.

</details>


### [5] [AOAD-MAT: Transformer-based multi-agent deep reinforcement learning model considering agents' order of action decisions](https://arxiv.org/abs/2510.13343)
*Shota Takayama,Katsuhide Fujita*

Main category: cs.MA

TL;DR: 본 연구에서는 행동 결정 순서를 고려한 새로운 다중 에이전트 강화 학습 모델 AOAD-MAT를 제안하며, 이 모델은 기존 모델보다 성능이 우수함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습(MARL) 모델들이 에이전트의 행동 순서를 명시적으로 고려하지 않음에 따라 성능 개선의 한계를 드러내고 있다.

Method: AOAD-MAT는 에이전트의 행동 결정 순서를 학습 과정에 통합해 최적의 행동 순서를 예측하도록 설계된 혁신적인 Transformer 기반의 액터-비평가 구조를 활용한다.

Result: 제안된 AOAD-MAT 모델은 StarCraft Multi-Agent Challenge 및 Multi-Agent MuJoCo 벤치마크에서 광범위한 실험을 통해 기존 MAT 및 다른 기초 모델보다 우수한 성능을 보였다.

Conclusion: 결과적으로 AOAD-MAT 모델은 다중 에이전트 강화 학습에서 행동 순서를 조정하는 것의 효과성을 입증하였다.

Abstract: Multi-agent reinforcement learning focuses on training the behaviors of
multiple learning agents that coexist in a shared environment. Recently, MARL
models, such as the Multi-Agent Transformer (MAT) and ACtion dEpendent deep
Q-learning (ACE), have significantly improved performance by leveraging
sequential decision-making processes. Although these models can enhance
performance, they do not explicitly consider the importance of the order in
which agents make decisions. In this paper, we propose an Agent Order of Action
Decisions-MAT (AOAD-MAT), a novel MAT model that considers the order in which
agents make decisions. The proposed model explicitly incorporates the sequence
of action decisions into the learning process, allowing the model to learn and
predict the optimal order of agent actions. The AOAD-MAT model leverages a
Transformer-based actor-critic architecture that dynamically adjusts the
sequence of agent actions. To achieve this, we introduce a novel MARL
architecture that cooperates with a subtask focused on predicting the next
agent to act, integrated into a Proximal Policy Optimization based loss
function to synergistically maximize the advantage of the sequential
decision-making. The proposed method was validated through extensive
experiments on the StarCraft Multi-Agent Challenge and Multi-Agent MuJoCo
benchmarks. The experimental results show that the proposed AOAD-MAT model
outperforms existing MAT and other baseline models, demonstrating the
effectiveness of adjusting the AOAD order in MARL.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [6] [ShuffleV: A Microarchitectural Defense Strategy against Electromagnetic Side-Channel Attacks in Microprocessors](https://arxiv.org/abs/2510.13111)
*Nuntipat Narkthong,Yukui Luo,Xiaolin Xu*

Main category: cs.CR

TL;DR: ShuffleV는 마이크로프로세서의 전자기 방출을 방어하기 위한 전략으로, 실행 순서를 무작위로 섞어 통계적 공격을 무력화한다.


<details>
  <summary>Details</summary>
Motivation: 마이크로프로세서의 실행 중 전자기 방출은 애플리케이션의 기밀을 유출하는 사이드 채널을 형성하며, 이에 대한 공격이 증가하고 있다.

Method: ShuffleV는 프로그램 명령의 실행 순서를 무작위로 섞고 더미 명령을 삽입하여 반복 실행에서 공격자의 통계적 관찰을 무효화하는 이동 표적 방어(MTD) 전략을 채택한다.

Result: ShuffleV는 Xilinx PYNQ-Z2 FPGA에 구현되었으며, AES 암호화와 신경망 추론을 통해 EM 사이드 채널 공격에 대한 성능을 검증하였다.

Conclusion: ShuffleV는 사용자 개입이나 소프트웨어 수정 없이도 이러한 애플리케이션에 대한 자동 보호를 제공한다.

Abstract: The run-time electromagnetic (EM) emanation of microprocessors presents a
side-channel that leaks the confidentiality of the applications running on
them. Many recent works have demonstrated successful attacks leveraging such
side-channels to extract the confidentiality of diverse applications, such as
the key of cryptographic algorithms and the hyperparameter of neural network
models. This paper proposes ShuffleV, a microarchitecture defense strategy
against EM Side-Channel Attacks (SCAs). ShuffleV adopts the moving target
defense (MTD) philosophy, by integrating hardware units to randomly shuffle the
execution order of program instructions and optionally insert dummy
instructions, to nullify the statistical observation by attackers across
repetitive runs. We build ShuffleV on the open-source RISC-V core and provide
six design options, to suit different application scenarios. To enable rapid
evaluation, we develop a ShuffleV simulator that can help users to (1) simulate
the performance overhead for each design option and (2) generate an execution
trace to validate the randomness of execution on their workload. We implement
ShuffleV on a Xilinx PYNQ-Z2 FPGA and validate its performance with two
representative victim applications against EM SCAs, AES encryption, and neural
network inference. The experimental results demonstrate that ShuffleV can
provide automatic protection for these applications, without any user
intervention or software modification.

</details>


### [7] [GRIDAI: Generating and Repairing Intrusion Detection Rules via Collaboration among Multiple LLM-based Agents](https://arxiv.org/abs/2510.13257)
*Jiarui Li,Yuhan Chai,Lei Du,Chenyun Duan,Hao Yan,Zhaoquan Gu*

Main category: cs.CR

TL;DR: GRIDAI는 여러 LLM 기반 에이전트 간의 협업을 통해 침입 탐지 규칙을 자동으로 생성하고 수정하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 규칙 기반 네트워크 침입 탐지 시스템은 새로운 공격에 대한 탐지 규칙의 자동 생성에 주로 중점을 두어 새로운 공격과 기존 규칙 간의 관계를 간과하여 규칙 세트 내의 중복이 발생하는 문제를 해결하고자 한다.

Method: GRIDAI는 공격 샘플의 특성을 평가하고, 새로운 유형의 공격이면 새로운 규칙을 생성하며, 기존 규칙에 의해 이미 다 covered된 변형 공격이면 해당 규칙을 수정하여 서명을 업데이트하는 시스템이다. 또한, LLM 홀로그램으로 인한 구문 및 의미 오류를 완화하기 위해 실시간 검증 메커니즘과 각 규칙을 위한 대표 샘플을 도입한다.

Result: GRIDAI는 새로운 공격 샘플과 기존 규칙 간의 관계를 정확히 파악하고, 새로운 공격 및 변형을 처리하기 위해 규칙을 효율적으로 생성 및 수정하며, LLM의 홀로그램 영향 또한 효과적으로 완화하는 결과를 보인다.

Conclusion: GRIDAI는 자동화된 규칙 생성 및 수정을 통해 침입 탐지의 효율성을 높이고 있다.

Abstract: Rule-based network intrusion detection systems play a crucial role in the
real-time detection of Web attacks. However, most existing works primarily
focus on automatically generating detection rules for new attacks, often
overlooking the relationships between new attacks and existing rules, which
leads to significant redundancy within the ever-expanding ruleset. To address
this issue, we propose GRIDAI, a novel end-to-end framework for the automated
Generation and Repair of Intrusion Detection rules through collaboration among
multiple LLM-based agents. Unlike traditional methods, GRIDAI first assesses
the nature of incoming attack samples. If the sample represents a new attack
type, it is used to generate a new rule. Otherwise, the sample is identified as
a variant of an attack already covered by an existing rule and used to repair
the rule by updating the corresponding signature, thereby enhancing its
generalization capability. Additionally, to mitigate syntactic and semantic
errors in rules caused by LLM hallucinations, we incorporate a tool-based
real-time validation mechanism and a representative attack sample maintained
for each rule, enabling fully automated rule generation and repair.
Comprehensive experiments were conducted on a public dataset containing seven
types of attacks and a private dataset with 43 attack types. The results
demonstrate that GRIDAI accurately identifies the relationships between new
attack samples and existing rules, efficiently generates and repairs rules to
handle new attacks and variants, and effectively mitigates the impact of LLM
hallucinations.

</details>


### [8] [Injection, Attack and Erasure: Revocable Backdoor Attacks via Machine Unlearning](https://arxiv.org/abs/2510.13322)
*Baogang Song,Dongdong Zhao,Jianwen Xiang,Qiben Xu,Zizhuo Yu*

Main category: cs.CR

TL;DR: 회귀 가능한 백도어 공격의 새로운 패러다임을 소개하며, 공격 목표 달성 후 백도어를 효과적으로 제거할 수 있는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 딥 뉴럴 네트워크(DNN)에 대한 백도어 공격의 보안 취약성을 해결하고, 공격 후에 백도어를 비활성화할 수 있는 방법을 탐색하기 위함이다.

Method: 회귀 가능한 백도어 공격을 위해 이중 최적화 문제를 설정하고, 백도어 주입 및 비학습 과정을 시뮬레이션하여 트리거 생성기를 최적화한다.

Result: CIFAR-10 및 ImageNet에서 실험을 통해 우리의 방법이 최첨단 백도어 공격과 비슷한 공격 성공률을 유지하며, 비학습 이후 백도어 행동의 효과적인 제거를 달성함을 보여준다.

Conclusion: 이 연구는 백도어 공격 연구를 위한 새로운 방향을 열고, 머신 러닝 시스템의 보안에 대한 새로운 도전 과제를 제시한다.

Abstract: Backdoor attacks pose a persistent security risk to deep neural networks
(DNNs) due to their stealth and durability. While recent research has explored
leveraging model unlearning mechanisms to enhance backdoor concealment,
existing attack strategies still leave persistent traces that may be detected
through static analysis. In this work, we introduce the first paradigm of
revocable backdoor attacks, where the backdoor can be proactively and
thoroughly removed after the attack objective is achieved. We formulate the
trigger optimization in revocable backdoor attacks as a bilevel optimization
problem: by simulating both backdoor injection and unlearning processes, the
trigger generator is optimized to achieve a high attack success rate (ASR)
while ensuring that the backdoor can be easily erased through unlearning. To
mitigate the optimization conflict between injection and removal objectives, we
employ a deterministic partition of poisoning and unlearning samples to reduce
sampling-induced variance, and further apply the Projected Conflicting Gradient
(PCGrad) technique to resolve the remaining gradient conflicts. Experiments on
CIFAR-10 and ImageNet demonstrate that our method maintains ASR comparable to
state-of-the-art backdoor attacks, while enabling effective removal of backdoor
behavior after unlearning. This work opens a new direction for backdoor attack
research and presents new challenges for the security of machine learning
systems.

</details>


### [9] [How Blind and Low-Vision Users Manage Their Passwords](https://arxiv.org/abs/2510.13538)
*Alexander Ponticello,Filipo Sharevski,Simon Anell,Katharina Krombholz*

Main category: cs.CR

TL;DR: 시각 장애인 사용자의 비밀번호 관리 문제를 조사하고, 비밀번호 관리자가 제공할 수 있는 도움을 연구하였다.


<details>
  <summary>Details</summary>
Motivation: 비밀번호를 안전하고 편리하게 관리하는 문제는 여전히 많은 사용자에게 어려운 과제로 남아 있다.

Method: 33명의 시각 장애인 참가자를 대상으로 정성적 인터뷰 연구를 수행하였다.

Result: 모든 참가자가 비밀번호 관리자를 어느 정도 사용하며, 사용의 편리함이 주된 원인으로 발견되었다. 보안의 이점은 실질적인 접근성 부족으로 회피되었다.

Conclusion: 비밀번호 관리자에 대한 접근성과 사용성 개선이 필요하며, 이를 통해 신뢰를 구축하고 사용자 에이전시를 유지하는 안전한 관행을 확립해야 한다.

Abstract: Managing passwords securely and conveniently is still an open problem for
many users. Existing research has examined users' password management
strategies and identified pain points, such as security concerns, leading to
insecure practices. We investigate how Blind and Low-Vision (BLV) users tackle
this problem and how password managers can assist them. This paper presents the
results of a qualitative interview study with N = 33 BLV participants. We found
that all participants utilize password managers to some extent, which they
perceive as fairly accessible. However, the adoption is mainly driven by the
convenience of storing and retrieving passwords. The security advantages -
generating strong, random passwords - were avoided mainly due to the absence of
practical accessibility. Password managers do not adhere to BLV users'
underlying needs for agency, which stem from experiences with inaccessible
software and vendors who deprioritize accessibility issues. Underutilization of
password managers leads BLV users to adopt insecure practices, such as reusing
predictable passwords or resorting to 'security through obscurity' by writing
important credentials in braille. We conclude our analysis by discussing the
need to implement practical accessibility and usability improvements for
password managers as a way of establishing trust and secure practices while
maintaining BLV users' agency.

</details>


### [10] [In-Browser LLM-Guided Fuzzing for Real-Time Prompt Injection Testing in Agentic AI Browsers](https://arxiv.org/abs/2510.13543)
*Avihay Cohen*

Main category: cs.CR

TL;DR: 웹 브라우저에 통합된 대형 언어 모델 기반 에이전트는 웹 작업을 자동화하지만 간접 프롬프트 주입 공격에 취약하다. 본 논문에서는 브라우저에서 완전히 작동하며 실시간으로 이러한 취약점을 자동으로 발견하는 새로운 퍼징 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM) 기반 에이전트가 웹 작업을 자동화하면서도 간접 프롬프트 주입 공격에 취약하다는 점을 해결하고자 한다.

Method: 브라우저에서 완전히 실행되고 LLM에 의해 안내되는 퍼징 프레임워크를 개발하였다.

Result: 이 프레임워크를 통해 자동으로 프롬프트 주입 취약점을 실시간으로 발견할 수 있다.

Conclusion: 제안하는 접근 방식은 웹 브라우저 내 에이전트의 보안을 향상시킬 수 있는 기반이 된다.

Abstract: Large Language Model (LLM) based agents integrated into web browsers (often
called agentic AI browsers) offer powerful automation of web tasks. However,
they are vulnerable to indirect prompt injection attacks, where malicious
instructions hidden in a webpage deceive the agent into unwanted actions. These
attacks can bypass traditional web security boundaries, as the AI agent
operates with the user privileges across sites. In this paper, we present a
novel fuzzing framework that runs entirely in the browser and is guided by an
LLM to automatically discover such prompt injection vulnerabilities in real
time.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [Pruning Cannot Hurt Robustness: Certified Trade-offs in Reinforcement Learning](https://arxiv.org/abs/2510.12939)
*James Pedley,Benjamin Etheridge,Stephen J. Roberts,Francesco Quinzan*

Main category: cs.LG

TL;DR: RL 정책은 적대적 간섭에도 신뢰성을 유지해야 하며, 이 과정에서 가지치기는 성능과 강건성을 동시에 향상시킬 수 있다.


<details>
  <summary>Details</summary>
Motivation: 실제 환경에서 배포되는 강화 학습 정책은 적대적 간섭에 대해 신뢰성을 유지해야 합니다.

Method: 상태-적대적 마르코프 결정 과정(SA-MDP)에서 가지치기 하에 인증된 강건성을 위한 최초의 이론적 프레임워크를 개발했습니다.

Result: 가우시안 및 범주형 정책에 대해, 요소별 가지치기가 인증된 강건성 경계를 더욱 강화할 수 있음을 증명했습니다.

Conclusion: 가지치기는 단순한 압축 도구가 아닌 강건한 강화 학습을 위한 구조적 개입으로 자리매김합니다.

Abstract: Reinforcement learning (RL) policies deployed in real-world environments must
remain reliable under adversarial perturbations. At the same time, modern deep
RL agents are heavily over-parameterized, raising costs and fragility concerns.
While pruning has been shown to improve robustness in supervised learning, its
role in adversarial RL remains poorly understood. We develop the first
theoretical framework for certified robustness under pruning in
state-adversarial Markov decision processes (SA-MDPs). For Gaussian and
categorical policies with Lipschitz networks, we prove that element-wise
pruning can only tighten certified robustness bounds; pruning never makes the
policy less robust. Building on this, we derive a novel three-term regret
decomposition that disentangles clean-task performance, pruning-induced
performance loss, and robustness gains, exposing a fundamental
performance--robustness frontier. Empirically, we evaluate magnitude and
micro-pruning schedules on continuous-control benchmarks with strong
policy-aware adversaries. Across tasks, pruning consistently uncovers
reproducible ``sweet spots'' at moderate sparsity levels, where robustness
improves substantially without harming - and sometimes even enhancing - clean
performance. These results position pruning not merely as a compression tool
but as a structural intervention for robust RL.

</details>


### [12] [Escaping Local Optima in the Waddington Landscape: A Multi-Stage TRPO-PPO Approach for Single-Cell Perturbation Analysis](https://arxiv.org/abs/2510.13018)
*Francis Boabang,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 이 논문은 단일 세포 교란 모델링을 위한 다단계 강화 학습 알고리즘을 소개하며, 초기화 방법을 개선하여 국소 최적점에서 벗어나고 적절한 계통으로 수렴하도록 한다.


<details>
  <summary>Details</summary>
Motivation: 세포의 유전적 및 화학적 교란에 대한 반응 모델링은 단일 세포 생물학의 중앙 문제이다.

Method: 다단계 강화 학습 알고리즘을 활용하여, 피셔 벡터 곱과 공액 기울기 솔버를 사용하여 자연 기울기 업데이트를 계산하고, Kullback-Leibler 신뢰 구역 제약에 의해 스케일된 매개변수를 사용한 정책 최적화를 수행한다.

Result: 이 초기화 방법은 단일 세포 RNA 시퀀싱(scRNA-seq) 및 단일 세포 ATAC 시퀀싱(scATAC-seq) 교란 분석에서 일반화를 크게 개선한다.

Conclusion: 제안된 알고리즘은 데이터에 기반하고 잘 설계된 초기화를 통해 물리적 의미를 갖는 계통으로 수렴할 수 있게 한다.

Abstract: Modeling cellular responses to genetic and chemical perturbations remains a
central challenge in single-cell biology. Existing data-driven framework have
advanced perturbation prediction through variational autoencoders, chemically
conditioned autoencoders, and large-scale transformer pretraining. However,
these models are prone to local optima in the nonconvex Waddington landscape of
cell fate decisions, where poor initialization can trap trajectories in
spurious lineages or implausible differentiation outcomes. While executable
gene regulatory networks complement these approaches, automated design
frameworks incorporate biological priors through multi-agent optimization. Yet,
an approach that is completely data-driven with well-designed initialization to
escape local optima and converge to a proper lineage remains elusive. In this
work, we introduce a multistage reinforcement learning algorithm tailored for
single-cell perturbation modeling. We first compute an explicit natural
gradient update using Fisher-vector products and a conjugate gradient solver,
scaled by a KL trust-region constraint to provide a safe, curvature-aware the
first step for the policy. Starting with these preconditioned parameters, we
then apply a second phase of proximal policy optimization (PPO) with clipped
surrogates, exploiting minibatch efficiency to refine the policy. We
demonstrate that this initialization substantially improves generalization on
Single-cell RNA sequencing (scRNA-seq) and Single-cell ATAC sequencing
(scATAC-seq) pertubation analysis.

</details>


### [13] [Bridging Idealized and Operational Models: An Explainable AI Framework for Earth System Emulators](https://arxiv.org/abs/2510.13030)
*Pouria Behnoudfar,Charlotte Moser,Marc Bocquet,Sibo Cheng,Nan Chen*

Main category: cs.LG

TL;DR: 본 연구는 지구 시스템 시뮬레이터를 위한 설명 가능한 AI 프레임워크를 개발하여 고해상도 모델과 이상화된 모델의 강점을 결합합니다.


<details>
  <summary>Details</summary>
Motivation: 지구 시스템을 이해하기 위해 컴퓨터 모델이 필수적이며, 고해상도 운영 모델은 극단 사건과 통계 분포를 시뮬레이션하는 데 지속적인 편향을 보입니다.

Method: 고유한 데이터 동화 기법을 통해 다양한 복잡성 모델의 강점을 활용하여 모델 계층을 연결합니다.

Result: 결과적으로, 이 모델은 고해상도와 포괄적인 변수들을 상속하면서 이상화된 모델의 타겟 개선을 통해 글로벌 정확도를 향상시킵니다.

Conclusion: AI의 메커니즘은 물리적 통찰력을 제공하며, 이는 효과적인 물리학 기반 디지털 트윈과 불확실성 정량화를 가능하게 합니다.

Abstract: Computer models are indispensable tools for understanding the Earth system.
While high-resolution operational models have achieved many successes, they
exhibit persistent biases, particularly in simulating extreme events and
statistical distributions. In contrast, coarse-grained idealized models isolate
fundamental processes and can be precisely calibrated to excel in
characterizing specific dynamical and statistical features. However, different
models remain siloed by disciplinary boundaries. By leveraging the
complementary strengths of models of varying complexity, we develop an
explainable AI framework for Earth system emulators. It bridges the model
hierarchy through a reconfigured latent data assimilation technique, uniquely
suited to exploit the sparse output from the idealized models. The resulting
bridging model inherits the high resolution and comprehensive variables of
operational models while achieving global accuracy enhancements through
targeted improvements from idealized models. Crucially, the mechanism of AI
provides a clear rationale for these advancements, moving beyond black-box
correction to physically insightful understanding in a computationally
efficient framework that enables effective physics-assisted digital twins and
uncertainty quantification. We demonstrate its power by significantly
correcting biases in CMIP6 simulations of El Ni\~no spatiotemporal patterns,
leveraging statistically accurate idealized models. This work also highlights
the importance of pushing idealized model development and advancing
communication between modeling communities.

</details>


### [14] [Time-Varying Optimization for Streaming Data Via Temporal Weighting](https://arxiv.org/abs/2510.13052)
*Muhammad Faraz Ul Abrar,Nicolò Michelusi,Erik G. Larsson*

Main category: cs.LG

TL;DR: 이 논문은 동적 환경에서의 의사결정을 위한 시간 변동 최적화 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 시간 변동 최적화는 동적 환경에서 의사결정에 중요한 주제로 부상했다.

Method: 우리는 스트리밍 데이터를 통한 학습 문제를 시간 변동 최적화 관점에서 접근하며, 다양한 가중치를 기반으로 한 구조적 최적화 공식을 도입하였다.

Result: 균일 가중치 하에서는 추적 오차가 $	ext{O}(1/t)$의 감소율로 점점 사라지지만, 할인 가중치 하에서는 비제로의 오차 바닥이 존재한다.

Conclusion: 이론적 결과는 수치 시뮬레이션을 통해 검증되었다.

Abstract: Classical optimization theory deals with fixed, time-invariant objective
functions. However, time-varying optimization has emerged as an important
subject for decision-making in dynamic environments. In this work, we study the
problem of learning from streaming data through a time-varying optimization
lens. Unlike prior works that focus on generic formulations, we introduce a
structured, \emph{weight-based} formulation that explicitly captures the
streaming-data origin of the time-varying objective, where at each time step,
an agent aims to minimize a weighted average loss over all the past data
samples. We focus on two specific weighting strategies: (1) uniform weights,
which treat all samples equally, and (2) discounted weights, which
geometrically decay the influence of older data. For both schemes, we derive
tight bounds on the ``tracking error'' (TE), defined as the deviation between
the model parameter and the time-varying optimum at a given time step, under
gradient descent (GD) updates. We show that under uniform weighting, the TE
vanishes asymptotically with a $\mathcal{O}(1/t)$ decay rate, whereas
discounted weighting incurs a nonzero error floor controlled by the discount
factor and the number of gradient updates performed at each time step. Our
theoretical findings are validated through numerical simulations.

</details>


### [15] [Convergence, design and training of continuous-time dropout as a random batch method](https://arxiv.org/abs/2510.13134)
*Antonio Álvarez-López,Martín Hernández*

Main category: cs.LG

TL;DR: 이 논문에서는 랜덤 배치 방법을 통해 연속 시간 모델에서 드롭아웃 정규화를 연구하며, 편향 없는 추정기를 구축하고 수렴 속도를 정량화합니다.


<details>
  <summary>Details</summary>
Motivation: 연속 시간 모델에서 드롭아웃 정규화를 이해하고 최적의 배치 샘플링 방법을 설계하기 위해.

Method: 랜덤 배치 방법을 사용하여 드롭아웃을 가장하는 편향 없는 추정기를 구성하고, 기댓값 균일 오차에 대한 선형 속도의 수렴을 확립합니다.

Result: 드롭아웃의 효과를 검증하기 위해 단층 신경 ODE를 전문화하고, 분류 및 흐름 매칭에서 이론을 검증하며, 예측된 속도와 정규화 효과를 관찰합니다.

Conclusion: 드롭아웃 정규화의 이론적 기반과 실행적 이점을 제시하며, 최적의 배치 크기를 도출합니다.

Abstract: We study dropout regularization in continuous-time models through the lens of
random-batch methods -- a family of stochastic sampling schemes originally
devised to reduce the computational cost of interacting particle systems. We
construct an unbiased, well-posed estimator that mimics dropout by sampling
neuron batches over time intervals of length $h$. Trajectory-wise convergence
is established with linear rate in $h$ for the expected uniform error. At the
distribution level, we establish stability for the associated continuity
equation, with total-variation error of order $h^{1/2}$ under mild moment
assumptions. During training with fixed batch sampling across epochs, a
Pontryagin-based adjoint analysis bounds deviations in the optimal cost and
control, as well as in gradient-descent iterates. On the design side, we
compare convergence rates for canonical batch sampling schemes, recover
standard Bernoulli dropout as a special case, and derive a cost--accuracy
trade-off yielding a closed-form optimal $h$. We then specialize to a
single-layer neural ODE and validate the theory on classification and flow
matching, observing the predicted rates, regularization effects, and favorable
runtime and memory profiles.

</details>


### [16] [Universally Invariant Learning in Equivariant GNNs](https://arxiv.org/abs/2510.13169)
*Jiacheng Cen,Anyi Li,Ning Lin,Tingyang Xu,Yu Rong,Deli Zhao,Zihe Wang,Wenbing Huang*

Main category: cs.LG

TL;DR: 본 논문에서는 효율적이고 실용적인 완전 등변 그래프 신경망(GNN) 구축을 위한 이론적 틀을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 등변 GNN은 다양한 응용 분야에서 큰 성공을 거두었으며, 완전성을 확보하기 위해서는 노드 간의 복잡한 다체 상호작용을 효과적으로 포착해야 합니다.

Method: 완전한 스칼라 함수와 전체 랭크 스티어러블 기저 집합을 사용하여 완전한 등변 GNN을 구축하는 방법을 제안합니다.

Result: 우리의 모델은 우수한 완전성을 보여주며, 몇 개의 레이어만으로도 우수한 성능을 발휘합니다.

Conclusion: 이는 계산 오버헤드를 크게 줄이면서도 강력한 실용적 효능을 유지합니다.

Abstract: Equivariant Graph Neural Networks (GNNs) have demonstrated significant
success across various applications. To achieve completeness -- that is, the
universal approximation property over the space of equivariant functions -- the
network must effectively capture the intricate multi-body interactions among
different nodes. Prior methods attain this via deeper architectures, augmented
body orders, or increased degrees of steerable features, often at high
computational cost and without polynomial-time solutions. In this work, we
present a theoretically grounded framework for constructing complete
equivariant GNNs that is both efficient and practical. We prove that a complete
equivariant GNN can be achieved through two key components: 1) a complete
scalar function, referred to as the canonical form of the geometric graph; and
2) a full-rank steerable basis set. Leveraging this finding, we propose an
efficient algorithm for constructing complete equivariant GNNs based on two
common models: EGNN and TFN. Empirical results demonstrate that our model
demonstrates superior completeness and excellent performance with only a few
layers, thereby significantly reducing computational overhead while maintaining
strong practical efficacy.

</details>


### [17] [RockNet: Distributed Learning on Ultra-Low-Power Devices](https://arxiv.org/abs/2510.13320)
*Alexander Gräfe,Fabian Mager,Marco Zimmerling,Sebastian Trimpe*

Main category: cs.LG

TL;DR: 이 논문은 초저전력 하드웨어를 위한 새로운 TinyML 방법인 RockNet을 제시하며, 일반적인 신경망 마이크로컨트롤러 훈련 방식보다 최대 2배 향상된 정확도로 시간적 분류 작업을 성공적으로 수행합니다.


<details>
  <summary>Details</summary>
Motivation: 사이버 물리 시스템에서 머신러닝의 필요성이 증가하고 있으며, 개인 정보 보호와 지연 문제로 인해 전통적인 클라우드 기반 훈련을 디바이스 처리로 전환하려는 관심이 높아지고 있다.

Method: RockNet은 초저전력 하드웨어에 맞춰 설계된 새로운 TinyML 방법으로, 다수의 디바이스로 분산 학습을 통해 최소한의 통신 오버헤드로 효율적인 분류기를 훈련한다.

Result: 20개의 초저전력 장치에서 하드웨어 실험을 통해 RockNet의 효과성을 검증하였으며, 최신 신경망 마이크로컨트롤러 훈련 방식보다 최대 2배 향상된 정확도로 시간적 분류 작업을 학습했다.

Conclusion: RockNet의 분산 ML 아키텍처는 20개의 장치로 확장할 때 기기당 메모리, 지연 및 에너지를 최대 90%까지 절감하며, 고급 정확도로 초저전력 하드웨어에서의 훈련을 가능하게 한다.

Abstract: As Machine Learning (ML) becomes integral to Cyber-Physical Systems (CPS),
there is growing interest in shifting training from traditional cloud-based to
on-device processing (TinyML), for example, due to privacy and latency
concerns. However, CPS often comprise ultra-low-power microcontrollers, whose
limited compute resources make training challenging. This paper presents
RockNet, a new TinyML method tailored for ultra-low-power hardware that
achieves state-of-the-art accuracy in timeseries classification, such as fault
or malware detection, without requiring offline pretraining. By leveraging that
CPS consist of multiple devices, we design a distributed learning method that
integrates ML and wireless communication. RockNet leverages all devices for
distributed training of specialized compute efficient classifiers that need
minimal communication overhead for parallelization. Combined with tailored and
efficient wireless multi-hop communication protocols, our approach overcomes
the communication bottleneck that often occurs in distributed learning.
Hardware experiments on a testbed with 20 ultra-low-power devices demonstrate
RockNet's effectiveness. It successfully learns timeseries classification tasks
from scratch, surpassing the accuracy of the latest approach for neural network
microcontroller training by up to 2x. RockNet's distributed ML architecture
reduces memory, latency and energy consumption per device by up to 90 % when
scaling from one central device to 20 devices. Our results show that a tight
integration of distributed ML, distributed computing, and communication
enables, for the first time, training on ultra-low-power hardware with
state-of-the-art accuracy.

</details>


### [18] [When In Doubt, Abstain: The Impact of Abstention on Strategic Classification](https://arxiv.org/abs/2510.13327)
*Lina Alkarmi,Ziyuan Huang,Mingyan Liu*

Main category: cs.LG

TL;DR: 알고리즘 기반 의사결정에서 분류기 차단이 전략적 조작의 영향을 줄이고 정확성을 높일 수 있음을 연구한다.


<details>
  <summary>Details</summary>
Motivation: 알고리즘적 의사결정이 보편화됨에 따라, 전략적인 조작에 대한 취약성이 증가하고 있다.

Method: 이 연구에서는 스택켈버그 게임 모델을 사용하여 분류기의 결정 정책을 발표하는 주체와 그 정책에 따라 자신의 특성을 조작하는 전략적 대리인을 다룬다.

Result: 최적의 차단은 전략적 대리인이 존재하는 경우에도 주체의 효용이 차단이 없는 경우보다 나쁘지 않음을 보인다.

Conclusion: 차단은 의사결정 시스템에서 전략적 행동의 부정적인 영향을 줄이는 중요한 도구로 기능할 수 있다.

Abstract: Algorithmic decision making is increasingly prevalent, but often vulnerable
to strategic manipulation by agents seeking a favorable outcome. Prior research
has shown that classifier abstention (allowing a classifier to decline making a
decision due to insufficient confidence) can significantly increase classifier
accuracy. This paper studies abstention within a strategic classification
context, exploring how its introduction impacts strategic agents' responses and
how principals should optimally leverage it. We model this interaction as a
Stackelberg game where a principal, acting as the classifier, first announces
its decision policy, and then strategic agents, acting as followers, manipulate
their features to receive a desired outcome. Here, we focus on binary
classifiers where agents manipulate observable features rather than their true
features, and show that optimal abstention ensures that the principal's utility
(or loss) is no worse than in a non-abstention setting, even in the presence of
strategic agents. We also show that beyond improving accuracy, abstention can
also serve as a deterrent to manipulation, making it costlier for agents,
especially those less qualified, to manipulate to achieve a positive outcome
when manipulation costs are significant enough to affect agent behavior. These
results highlight abstention as a valuable tool for reducing the negative
effects of strategic behavior in algorithmic decision making systems.

</details>


### [19] [Prediction Markets with Intermittent Contributions](https://arxiv.org/abs/2510.13385)
*Michael Vitali,Pierre Pinson*

Main category: cs.LG

TL;DR: 데이터 가용성과 정확한 예측 수요가 증가하고 있지만, 이해관계자 간의 협력은 데이터 소유와 경쟁적 이익에 의해 제약받고 있습니다. 본 논문에서는 예측 시장에 기반한 일반적인 프레임워크를 제안하며, 독립 에이전트가 불확실한 미래 사건에 대한 예측을 거래하는 방법을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 데이터 가용성과 예측의 정확성 필요성이 증가하고 있지만, 이해관계자 간의 협력은 데이터 소유권과 경쟁적 이익에 의해 종종 제한됩니다.

Method: 우리는 (i) 에이전트의 역사적 성과를 고려하고, (ii) 시간에 따라 변하는 조건에 적응하며, (iii) 에이전트가 시장에 자유롭게 진입하고 퇴출할 수 있는 예측 시장을 추천합니다. 제안된 설계는 누락된 제출을 처리하면서 최적의 예측 조합을 학습하기 위해 강건 회귀 모델을 사용합니다.

Result: 사례 연구에서 모의 및 실제 데이터를 사용하여 제안된 시장 디자인의 효과성과 적응성을 입증하였습니다.

Conclusion: 우리는 샘플 내부 및 외부 성과를 고려하는 보상 배분 메커니즘을 도입하며, 여러 경제적 특성을 만족시킵니다.

Abstract: Although both data availability and the demand for accurate forecasts are
increasing, collaboration between stakeholders is often constrained by data
ownership and competitive interests. In contrast to recent proposals within
cooperative game-theoretical frameworks, we place ourselves in a more general
framework, based on prediction markets. There, independent agents trade
forecasts of uncertain future events in exchange for rewards. We introduce and
analyse a prediction market that (i) accounts for the historical performance of
the agents, (ii) adapts to time-varying conditions, while (iii) permitting
agents to enter and exit the market at will. The proposed design employs robust
regression models to learn the optimal forecasts' combination whilst handling
missing submissions. Moreover, we introduce a pay-off allocation mechanism that
considers both in-sample and out-of-sample performance while satisfying several
desirable economic properties. Case-studies using simulated and real-world data
allow demonstrating the effectiveness and adaptability of the proposed market
design.

</details>


### [20] [Going with the Flow: Approximating Banzhaf Values via Graph Neural Networks](https://arxiv.org/abs/2510.13391)
*Benjamin Kempinski,Tal Kachman*

Main category: cs.LG

TL;DR: 본 논문은 다중 에이전트 시스템에서 에이전트의 영향을 정량화하기 위한 Banzhaf 값을 근사하기 위해 그래프 신경망(GNN)을 활용한 새로운 학습 기반 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: Banzhaf 값을 계산하는 것은 다중 에이전트 시스템에서 에이전트의 영향을 정량화하는 데 중요하다.

Method: 문제를 그래프 수준의 예측 작업으로 설정하여, 네트워크 토폴로지와 제어 구조에서 에이전트 영향의 일반화 가능한 패턴을 학습하는 방법을 사용한다.

Result: GNN 모델이 정확한 방법 및 샘플링 기반 방법에 비해 고충실도의 Banzhaf 값 근사를 달성하고, 특정 크기와 토폴로지의 그래프에서 훈련된 모델이 전혀 다른 구조적 특성을 가진 네트워크에 대해 Banzhaf 값을 정확하게 예측한다는 것을 보여준다.

Conclusion: 이 연구는 GNN이 복잡한 네트워크 시스템의 확장 가능 협동 게임 이론 분석을 위한 실용적인 도구로 자리매김하게 한다.

Abstract: Computing the Banzhaf value in network flow games is fundamental for
quantifying agent influence in multi-agent systems, with applications ranging
from cybersecurity to infrastructure planning. However, exact computation is
intractable for systems with more than $\sim20$ agents due to exponential
complexity $\mathcal{O}(2^m)$. While Monte Carlo sampling methods provide
statistical estimates, they suffer from high sample complexity and cannot
transfer knowledge across different network configurations, making them
impractical for large-scale or dynamic systems. We present a novel
learning-based approach using Graph Neural Networks (GNNs) to approximate
Banzhaf values in cardinal network flow games. By framing the problem as a
graph-level prediction task, our method learns generalisable patterns of agent
influence directly from network topology and control structure. We conduct a
comprehensive empirical study comparing three state-of-the-art GNN
architectures-Graph Attention Networks (GAT), Graph Isomorphism Networks with
Edge features (GINE), and EdgeConv-on a large-scale synthetic dataset of
200,000 graphs per configuration, varying in size (20-100 nodes), agent count
(5-20), and edge probability (0.5-1.0). Our results demonstrate that trained
GNN models achieve high-fidelity Banzhaf value approximation with
order-of-magnitude speedups compared to exact and sampling-based methods. Most
significantly, we show strong zero-shot generalisation: models trained on
graphs of a specific size and topology accurately predict Banzhaf values for
entirely new networks with different structural properties, without requiring
retraining. This work establishes GNNs as a practical tool for scalable
cooperative game-theoretic analysis of complex networked systems.

</details>


### [21] [SWIR-LightFusion: Multi-spectral Semantic Fusion of Synthetic SWIR with {Thermal} IR {(LWIR/MWIR)} and RGB](https://arxiv.org/abs/2510.13404)
*Muhammad Ishfaq Hussain,Ma Van Linh,Zubia Naz,Unse Fatima,Yeongmin Ko,Moongu Jeon*

Main category: cs.LG

TL;DR: 이 논문은 가시성이 좋지 않은 조건에서의 장면 이해를 향상시키기 위한 SWIR 기반의 융합 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 악화된 가시성 조건에서 장면 이해를 개선하는 것은 감시 시스템 및 자율 내비게이션 시스템에 있어 중요한 도전 과제이다.

Method: 상대적으로 접근 가능한 LWIR 데이터를 이용하여 합성 SWIR 구조/대비 신호를 생성하고, 이를 사용할 수 있는 다중 모드 융합 프레임워크를 제안한다.

Result: 우리의 합성 SWIR 기반 융합 프레임워크는 이미지 품질(대비, 에지 정의, 구조적 충실도)을 개선하고 실시간 성능을 유지한다.

Conclusion: 실제 감시 및 자율 시스템 응용 프로그램에서 상당한 잠재력을 강조한다.

Abstract: Enhancing scene understanding in adverse visibility conditions remains a
critical challenge for surveillance and autonomous navigation systems.
Conventional imaging modalities, such as RGB and thermal infrared (MWIR /
LWIR), when fused, often struggle to deliver comprehensive scene information,
particularly under conditions of atmospheric interference or inadequate
illumination. To address these limitations, Short-Wave Infrared (SWIR) imaging
has emerged as a promising modality due to its ability to penetrate atmospheric
disturbances and differentiate materials with improved clarity. However, the
advancement and widespread implementation of SWIR-based systems face
significant hurdles, primarily due to the scarcity of publicly accessible SWIR
datasets. In response to this challenge, our research introduces an approach to
synthetically generate SWIR-like structural/contrast cues (without claiming
spectral reproduction) images from existing LWIR data using advanced contrast
enhancement techniques. We then propose a multimodal fusion framework
integrating synthetic SWIR, LWIR, and RGB modalities, employing an optimized
encoder-decoder neural network architecture with modality-specific encoders and
a softmax-gated fusion head. Comprehensive experiments on public {RGB-LWIR
benchmarks (M3FD, TNO, CAMEL, MSRS, RoadScene) and an additional private real
RGB-MWIR-SWIR dataset} demonstrate that our synthetic-SWIR-enhanced fusion
framework improves fused-image quality (contrast, edge definition, structural
fidelity) while maintaining real-time performance. We also add fair trimodal
baselines (LP, LatLRR, GFF) and cascaded trimodal variants of
U2Fusion/SwinFusion under a unified protocol. The outcomes highlight
substantial potential for real-world applications in surveillance and
autonomous systems.

</details>


### [22] [Modeling Adoptive Cell Therapy in Bladder Cancer from Sparse Biological Data using PINNs](https://arxiv.org/abs/2510.13431)
*Kayode Olumoyin,Katarzyna Rejniak*

Main category: cs.LG

TL;DR: 이 논문에서는 종양 미세환경에서 조합 요법으로 인한 시간에 따른 상호작용을 학습하기 위한 물리정보 신경망(PINN) 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 종양학에서 실험 데이터는 종종 희소하며 몇 개의 종양 부피 시간 점으로 구성됩니다. 따라서 prior 정보를 기반으로 한 귀납적 편향을 포함하여 PINN을 확장할 필요가 있습니다.

Method: 우리는 생물학적 제약 조건을 정규화 요인으로 포함한 수정된 PINN 알고리즘을 사용하여 일반적인 ODE 모델에서 간헐적으로 적용된 치료의 역학을 학습합니다.

Result: 알고리즘은 ODE 솔루션과 ODE 모델 매개변수의 시간에 따라 변하는 형태를 제공합니다. MSE, MAE 및 MAPE와 같은 지표를 사용하여 강력한 수렴성을 입증합니다.

Conclusion: 이 연구는 PINN이 종양학 데이터와 결합되어 높은 성능과 일반화 능력을 갖출 수 있음을 보여줍니다.

Abstract: Physics-informed neural networks (PINNs) are neural networks that embed the
laws of dynamical systems modeled by differential equations into their loss
function as constraints. In this work, we present a PINN framework applied to
oncology. Here, we seek to learn time-varying interactions due to a combination
therapy in a tumor microenvironment. In oncology, experimental data are often
sparse and composed of a few time points of tumor volume. By embedding
inductive biases derived from prior information about a dynamical system, we
extend the physics-informed neural networks (PINN) and incorporate observed
biological constraints as regularization agents. The modified PINN algorithm is
able to steer itself to a reasonable solution and can generalize well with only
a few training examples. We demonstrate the merit of our approach by learning
the dynamics of treatment applied intermittently in an ordinary differential
equation (ODE) model of a combination therapy. The algorithm yields a solution
to the ODE and time-varying forms of some of the ODE model parameters. We
demonstrate a strong convergence using metrics such as the mean squared error
(MSE), mean absolute error (MAE), and mean absolute percentage error (MAPE).

</details>


### [23] [Hybrid Interval Type-2 Mamdani-TSK Fuzzy System for Regression Analysis](https://arxiv.org/abs/2510.13437)
*Ashish Bhatia,Renato Cordeiro de Amorim,Vito De Feo*

Main category: cs.LG

TL;DR: 이 논문은 Mamdani 시스템의 해석 가능성과 TSK 모델의 정밀성을 결합한 새로운 퍼지 회귀 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 회귀 분석 방법은 불확실성과 모호성을 포함한 실제 데이터의 복잡성 문제에 직면해 있습니다.

Method: 본 연구는 퍼지와 정량적 요소를 결합한 혼합 규칙 구조를 도입하여 Mamdani 시스템의 해석 가능성과 TSK 모델의 정밀성을 통합하는 퍼지 회귀 방법을 제안합니다.

Result: 제안된 방법은 여러 벤치마크 데이터 세트에서 최신 성능을 입증했고, 전통적인 Mamdani 시스템에 유사한 요소를 유지하면서 규칙 출력을 개선하였습니다.

Conclusion: 이 혼합 방법론은 퍼지 시스템의 해석 가능성과 정확성 간의 균형을 제공하며, 6개의 데이터 세트 중 4개 데이터 세트에서 최상의 퍼지 방법론 점수를 기록했습니다.

Abstract: Regression analysis is employed to examine and quantify the relationships
between input variables and a dependent and continuous output variable. It is
widely used for predictive modelling in fields such as finance, healthcare, and
engineering. However, traditional methods often struggle with real-world data
complexities, including uncertainty and ambiguity. While deep learning
approaches excel at capturing complex non-linear relationships, they lack
interpretability and risk over-fitting on small datasets. Fuzzy systems provide
an alternative framework for handling uncertainty and imprecision, with Mamdani
and Takagi-Sugeno-Kang (TSK) systems offering complementary strengths:
interpretability versus accuracy. This paper presents a novel fuzzy regression
method that combines the interpretability of Mamdani systems with the precision
of TSK models. The proposed approach introduces a hybrid rule structure with
fuzzy and crisp components and dual dominance types, enhancing both accuracy
and explainability. Evaluations on benchmark datasets demonstrate
state-of-the-art performance in several cases, with rules maintaining a
component similar to traditional Mamdani systems while improving precision
through improved rule outputs. This hybrid methodology offers a balanced and
versatile tool for predictive modelling, addressing the trade-off between
interpretability and accuracy inherent in fuzzy systems. In the 6 datasets
tested, the proposed approach gave the best fuzzy methodology score in 4
datasets, out-performed the opaque models in 2 datasets and produced the best
overall score in 1 dataset with the improvements in RMSE ranging from 0.4% to
19%.

</details>


### [24] [Physics-augmented Multi-task Gaussian Process for Modeling Spatiotemporal Dynamics](https://arxiv.org/abs/2510.13601)
*Xizhuo Zhang,Bing Yao*

Main category: cs.LG

TL;DR: 다차원 시공간 데이터를 효과적으로 모델링하기 위한 P-M-GP 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 기하학적 도메인에서 시공간 데이터를 효과적으로 모델링하는 것이 도전 과제가 되고 있다.

Method: 기하학을 고려한 다중 작업 가우시안 프로세스 모델을 개발하고, 물리법칙을 통해 예측을 제어하는 방식으로 모델의 충실도를 향상시킨다.

Result: 제안된 P-M-GP 프레임워크의 검증을 3D 심장 전기역학 모델링 작업에서 수행했고, 예측 정확성이 기존 방법들보다 크게 향상됨을 보였다.

Conclusion: 제안한 방법은 도메인 특정 물리 제한과 기하학적 정보를 효과적으로 통합하여 높은 예측 정확도를 달성한다.

Abstract: Recent advances in sensing and imaging technologies have enabled the
collection of high-dimensional spatiotemporal data across complex geometric
domains. However, effective modeling of such data remains challenging due to
irregular spatial structures, rapid temporal dynamics, and the need to jointly
predict multiple interrelated physical variables. This paper presents a
physics-augmented multi-task Gaussian Process (P-M-GP) framework tailored for
spatiotemporal dynamic systems. Specifically, we develop a geometry-aware,
multi-task Gaussian Process (M-GP) model to effectively capture intrinsic
spatiotemporal structure and inter-task dependencies. To further enhance the
model fidelity and robustness, we incorporate governing physical laws through a
physics-based regularization scheme, thereby constraining predictions to be
consistent with governing dynamical principles. We validate the proposed P-M-GP
framework on a 3D cardiac electrodynamics modeling task. Numerical experiments
demonstrate that our method significantly improves prediction accuracy over
existing methods by effectively incorporating domain-specific physical
constraints and geometric prior.

</details>


### [25] [Rebalancing with Calibrated Sub-classes (RCS): An Enhanced Approach for Robust Imbalanced Classification](https://arxiv.org/abs/2510.13656)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: 본 논문에서는 분포 보정 기반의 새로운 방법인 RCS를 제안하며, 이는 소수 클래스의 분포 매개변수를 추정함으로써 불균형 분류 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 소수 클래스의 데이터 부족으로 인해 분류기가 대다수 클래스에 편향되는 문제를 해결하고자 한다.

Method: RCS는 대다수 및 중간 클래스에서 파생된 가중치 매개변수를 사용하여 소수 클래스의 분포 매개변수를 추정하는 방법이다. 인코더-디코더 네트워크가 훈련되어 불균형 데이터의 구조를 보존하고 얽힘을 방지한다.

Result: 본 방법은 인코더에서 추출된 특징 벡터를 사용하여 분포 보정 전략을 통해 합성 샘플을 생성함으로써 불균형 데이터 문제를 효과적으로 완화한다.

Conclusion: 실험 결과, 제안한 방법이 다양한 이미지, 텍스트 및 표 형식 데이터 세트에서 여러 기준 및 최첨단 기술보다 우수한 분류 성능을 보임을 입증한다.

Abstract: The class imbalance problem refers to the insufficiency of data in certain
classes, which causes a classifier to be biased toward the majority class.
Distribution calibration is a technique that seeks to estimate a more accurate
class distribution based on an observed or estimated one. To address this
issue, we propose a distribution calibration-based method-Rebalancing with
Calibrated Sub-classes (RCS): An Enhanced Approach for Robust Imbalanced
Classification, which estimates the distribution parameters of the minority
classes using weighted parameters derived from a mixture of Gaussian components
from both the majority and intermediate classes. An encoder-decoder network is
trained to preserve the structure of the imbalanced data and prevent
disentanglement. After training, feature vectors extracted from the encoder are
used to generate synthetic samples through our distribution calibration
strategy. This approach effectively mitigates the overgeneralization problem
that arises when only the distribution of the majority class is used to
approximate the minority class statistics. Instead, our method calibrates the
parameters by leveraging the distribution of data points in neighboring
regions. Experimental results demonstrate that the proposed method achieves
superior classification performance compared to several baseline and
state-of-the-art techniques across a diverse range of image, text, and tabular
datasets.

</details>


### [26] [Simplicial Embeddings Improve Sample Efficiency in Actor-Critic Agents](https://arxiv.org/abs/2510.13704)
*Johan Obando-Ceron,Walter Mayor,Samuel Lavoie,Scott Fujimoto,Aaron Courville,Pablo Samuel Castro*

Main category: cs.LG

TL;DR: 이 논문은 액터-비평가 방법의 훈련 시간을 단축시키기 위해 단순 다각형 임베딩을 사용하여 샘플 효율성과 성능을 개선하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 액터-비평가 방법의 훈련 시간을 줄이고 성능을 개선하기 위해 고안됨.

Method: 단순 다각형 임베딩을 사용하는 접근 방식을 제안하며, 이는 임베딩을 단순 다각형 구조로 제한하는 경량 표현 레이어를 포함한다.

Result: FastTD3, FastSAC 및 PPO에 적용했을 때, 단순 다각형 임베딩은 다양한 연속 및 이산 제어 환경에서 샘플 효율성과 최종 성능을 일관되게 개선하였다.

Conclusion: 러닝 속도를 유지하면서 성능 향상 및 샘플 효율의 개선을 이루었다.

Abstract: Recent works have proposed accelerating the wall-clock training time of
actor-critic methods via the use of large-scale environment parallelization;
unfortunately, these can sometimes still require large number of environment
interactions to achieve a desired level of performance. Noting that
well-structured representations can improve the generalization and sample
efficiency of deep reinforcement learning (RL) agents, we propose the use of
simplicial embeddings: lightweight representation layers that constrain
embeddings to simplicial structures. This geometric inductive bias results in
sparse and discrete features that stabilize critic bootstrapping and strengthen
policy gradients. When applied to FastTD3, FastSAC, and PPO, simplicial
embeddings consistently improve sample efficiency and final performance across
a variety of continuous- and discrete-control environments, without any loss in
runtime speed.

</details>


### [27] [Assessing the Geographic Generalization and Physical Consistency of Generative Models for Climate Downscaling](https://arxiv.org/abs/2510.13722)
*Carlo Saccardi,Maximilian Pierzyna,Haitz Sáez de Ocáriz Borde,Simone Monaco,Cristian Meo,Pietro Liò,Rudolf Saathof,Geethu Joseph,Justin Dauwels*

Main category: cs.LG

TL;DR: 본 논문에서는 전통적인 날씨 시뮬레이션보다 빠른 대안인 딥러닝 모델을 사용하여 기후 다운스케일링을 수행하지만, 물리적 일관성과 지리적 일반화의 관점에서 성능과 신뢰성을 평가하기 위해 물리학에서 영감을 받은 진단 방법을 도입한다.


<details>
  <summary>Details</summary>
Motivation: 킬로미터 규모의 날씨 데이터는 현실 세계 응용에 필수적이지만 전통적인 날씨 시뮬레이션으로 생성하기에는 계산 집약적이다. 딥러닝 모델을 사용한 새로운 해결책이 등장하고 있지만, 신뢰성은 아직 의문시되고 있다.

Method: 최신의 최첨단 딥러닝 모델을 벤치마킹하고, 성능과 신뢰성을 평가하기 위해 물리적 진단을 도입하여 지리적 일반화와 물리적 일관성에 중점을 둔다.

Result: 모델들이 제한된 유럽 지리에 대해 훈련될 때는 강력한 성능을 보이지만, 이베리아나 북유럽의 스칸디나비아와 같은 다른 지역으로 일반화하기에는 어려움을 겪고 있다. 예측된 속도 필드에서 유도된 발산과 소용돌이와 같은 2차 변수를 정확하게 포착하지 못한다.

Conclusion: 지리적 일반화를 개선하기 위한 초기 해결책으로 소규모 물리적 구조의 재구성을 촉진하는 전력 스펙트럼 밀도 손실 함수를 도입할 것을 제안한다.

Abstract: Kilometer-scale weather data is crucial for real-world applications but
remains computationally intensive to produce using traditional weather
simulations. An emerging solution is to use deep learning models, which offer a
faster alternative for climate downscaling. However, their reliability is still
in question, as they are often evaluated using standard machine learning
metrics rather than insights from atmospheric and weather physics. This paper
benchmarks recent state-of-the-art deep learning models and introduces
physics-inspired diagnostics to evaluate their performance and reliability,
with a particular focus on geographic generalization and physical consistency.
Our experiments show that, despite the seemingly strong performance of models
such as CorrDiff, when trained on a limited set of European geographies (e.g.,
central Europe), they struggle to generalize to other regions such as Iberia,
Morocco in the south, or Scandinavia in the north. They also fail to accurately
capture second-order variables such as divergence and vorticity derived from
predicted velocity fields. These deficiencies appear even in in-distribution
geographies, indicating challenges in producing physically consistent
predictions. We propose a simple initial solution: introducing a power spectral
density loss function that empirically improves geographic generalization by
encouraging the reconstruction of small-scale physical structures. The code for
reproducing the experimental results can be found at
https://github.com/CarloSaccardi/PSD-Downscaling

</details>


### [28] [Progressive multi-fidelity learning for physical system predictions](https://arxiv.org/abs/2510.13762)
*Paolo Conti,Mengwu Guo,Attilio Frangi,Andrea Manzoni*

Main category: cs.LG

TL;DR: 본 연구는 다양한 데이터 유형을 통합하여 예측 능력을 향상시키는 점진적 다중 신뢰도 대체 모델을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 정확한 데이터셋을 얻는 것은 비쌀 뿐만 아니라 시간이 많이 소요되며, 이는 정확한 평가를 요구하는 애플리케이션에 큰 도전 과제가 된다.

Method: 맞춤형 인코더를 사용하여 다양한 데이터 유형을 순차적으로 통합하고, 신경망을 통해 인코딩된 입력에서 관심 있는 목표 수량으로의 다중 신뢰도 회귀를 수행한다.

Result: 이 모델은 데이터 수준 간의 상관관계를 활용할 수 있으며, 입력 데이터가 추가됨에 따라 성능 저하를 방지한다.

Conclusion: 모델은 실제 사례 연구와 수치 기준에서 효과적임을 입증하며, 다중 모드 데이터를 신뢰성 있게 통합하고 예측을 정확하게 유지한다.

Abstract: Highly accurate datasets from numerical or physical experiments are often
expensive and time-consuming to acquire, posing a significant challenge for
applications that require precise evaluations, potentially across multiple
scenarios and in real-time. Even building sufficiently accurate surrogate
models can be extremely challenging with limited high-fidelity data.
Conversely, less expensive, low-fidelity data can be computed more easily and
encompass a broader range of scenarios. By leveraging multi-fidelity
information, prediction capabilities of surrogates can be improved. However, in
practical situations, data may be different in types, come from sources of
different modalities, and not be concurrently available, further complicating
the modeling process. To address these challenges, we introduce a progressive
multi-fidelity surrogate model. This model can sequentially incorporate diverse
data types using tailored encoders. Multi-fidelity regression from the encoded
inputs to the target quantities of interest is then performed using neural
networks. Input information progressively flows from lower to higher fidelity
levels through two sets of connections: concatenations among all the encoded
inputs, and additive connections among the final outputs. This dual connection
system enables the model to exploit correlations among different datasets while
ensuring that each level makes an additive correction to the previous level
without altering it. This approach prevents performance degradation as new
input data are integrated into the model and automatically adapts predictions
based on the available inputs. We demonstrate the effectiveness of the approach
on numerical benchmarks and a real-world case study, showing that it reliably
integrates multi-modal data and provides accurate predictions, maintaining
performance when generalizing across time and parameter variations.

</details>


### [29] [Provably Invincible Adversarial Attacks on Reinforcement Learning Systems: A Rate-Distortion Information-Theoretic Approach](https://arxiv.org/abs/2510.13792)
*Ziqing Lu,Lifeng Lai,Weiyu Xu*

Main category: cs.LG

TL;DR: RL 시스템의 내성을 강화하기 위해 새로운 유형의 적대적 공격 전략을 제안한다.


<details>
  <summary>Details</summary>
Motivation: RL 시스템의 보안을 강화하고 적대적 공격에 대한 방어능력을 높이기 위해.

Method: 정보 이론적 접근 방식으로 에이전트의 관찰을 무작위로 변경하여 최고의 보상으로 이어지지 않도록 한다.

Result: 주어진 정보의 저하가 RL 에이전트의 보상 후회에 미치는 영향을 정량적으로 분석하여, 기존의 모델 기반 및 비모델 기반 알고리즘에 대한 공격의 영향을 보여준다.

Conclusion: 제안된 공격 전략은 에이전트가 진실의 커널에 대한 정보를 거의 얻지 못하게 하여, RL 시스템의 보안을 저하시키는 중요한 기법이다.

Abstract: Reinforcement learning (RL) for the Markov Decision Process (MDP) has emerged
in many security-related applications, such as autonomous driving, financial
decisions, and drone/robot algorithms. In order to improve the
robustness/defense of RL systems against adversaries, studying various
adversarial attacks on RL systems is very important. Most previous work
considered deterministic adversarial attack strategies in MDP, which the
recipient (victim) agent can defeat by reversing the deterministic attacks. In
this paper, we propose a provably ``invincible'' or ``uncounterable'' type of
adversarial attack on RL. The attackers apply a rate-distortion
information-theoretic approach to randomly change agents' observations of the
transition kernel (or other properties) so that the agent gains zero or very
limited information about the ground-truth kernel (or other properties) during
the training. We derive an information-theoretic lower bound on the recipient
agent's reward regret and show the impact of rate-distortion attacks on
state-of-the-art model-based and model-free algorithms. We also extend this
notion of an information-theoretic approach to other types of adversarial
attack, such as state observation attacks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [30] [From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models](https://arxiv.org/abs/2510.12864)
*Imran Khan*

Main category: cs.AI

TL;DR: 이 논문은 LLM이 인간의 상식과 의도와 불일치하게 결정하는 문제를 해결하기 위한 RID 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 인간의 상식과 의도와 맞지 않는 결정으로 이어지는 규칙을 엄격히 따르는 문제가 있다는 점을 인식하여, 신뢰할 수 있는 자율 에이전트를 구축하는 데 모델의 유연성을 향상하는 필요성이 제기되었습니다.

Method: RID 프레임워크는 LLM에서 인간과 일치하는 예외 처리를 이끌어내기 위해 설계된 새로운 저비용 메타 프롬프트 기술입니다.

Result: RID 프레임워크는 검증된 성능 향상을 보여주며, 20개의 다양한 시나리오에 대해 95%의 인간 정렬 점수를 달성했습니다.

Conclusion: 이 연구는 LLM을 문자 그대로의 지침 준수에서 목표 지향적 추론으로 이끄는 실용적이고 접근 가능한 방법을 제시합니다.

Abstract: Large Language Models (LLMs) are increasingly being deployed as the reasoning
engines for agentic AI systems, yet they exhibit a critical flaw: a rigid
adherence to explicit rules that leads to decisions misaligned with human
common sense and intent. This "rule-rigidity" is a significant barrier to
building trustworthy autonomous agents. While prior work has shown that
supervised fine-tuning (SFT) with human explanations can mitigate this issue,
SFT is computationally expensive and inaccessible to many practitioners. To
address this gap, we introduce the Rule-Intent Distinction (RID) Framework, a
novel, low-compute meta-prompting technique designed to elicit human-aligned
exception handling in LLMs in a zero-shot manner. The RID framework provides
the model with a structured cognitive schema for deconstructing tasks,
classifying rules, weighing conflicting outcomes, and justifying its final
decision. We evaluated the RID framework against baseline and Chain-of-Thought
(CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced
judgment across diverse domains. Our human-verified results demonstrate that
the RID framework significantly improves performance, achieving a 95% Human
Alignment Score (HAS), compared to 80% for the baseline and 75% for CoT.
Furthermore, it consistently produces higher-quality, intent-driven reasoning.
This work presents a practical, accessible, and effective method for steering
LLMs from literal instruction-following to liberal, goal-oriented reasoning,
paving the way for more reliable and pragmatic AI agents.

</details>


### [31] [DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping](https://arxiv.org/abs/2510.12979)
*Wei Fan,Wenlin Yao,Zheng Li,Feng Yao,Xin Liu,Liang Qiu,Qingyu Yin,Yangqiu Song,Bing Yin*

Main category: cs.AI

TL;DR: DeepPlanner는 깊은 연구 에이전트의 계획 능력을 향상시키기 위한 end-to-end RL 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업 해결을 위한 외부 도구 활용의 잠재력이 존재하지만, 기존 접근법은 계획 단계 최적화를 체계적으로 다루지 않음.

Method: DeepPlanner는 엔트로피 기반의 항목을 통해 높은 엔트로피 토큰에 더 큰 업데이트를 할당하고, 계획 집약적 롤아웃을 위해 샘플 수준의 이점을 선택적으로 강화.

Result: DeepPlanner는 7개의 깊은 연구 벤치마크에서 계획 품질을 개선하고, 더 낮은 훈련 예산으로 최신 기술 수준의 결과를 달성함.

Conclusion: DeepPlanner는 계획 능력을 효과적으로 향상시켜 레인포스먼트 러닝의 한계를 극복한다.

Abstract: Large language models (LLMs) augmented with multi-step reasoning and action
generation abilities have shown promise in leveraging external tools to tackle
complex tasks that require long-horizon planning. However, existing approaches
either rely on implicit planning in the reasoning stage or introduce explicit
planners without systematically addressing how to optimize the planning stage.
As evidence, we observe that under vanilla reinforcement learning (RL),
planning tokens exhibit significantly higher entropy than other action tokens,
revealing uncertain decision points that remain under-optimized. To address
this, we propose DeepPlanner, an end-to-end RL framework that effectively
enhances the planning capabilities of deep research agents. Our approach shapes
token-level advantage with an entropy-based term to allocate larger updates to
high entropy tokens, and selectively upweights sample-level advantages for
planning-intensive rollouts. Extensive experiments across seven deep research
benchmarks demonstrate that DeepPlanner improves planning quality and achieves
state-of-the-art results under a substantially lower training budget.

</details>


### [32] [SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents](https://arxiv.org/abs/2510.12985)
*Simon Sinong Zhan,Yao Liu,Philip Wang,Zinan Wang,Qineng Wang,Zhian Ruan,Xiangyu Shi,Xinyu Cao,Frank Yang,Kangrui Wang,Huajie Shao,Manling Li,Qi Zhu*

Main category: cs.AI

TL;DR: Sentinel은 LLM 기반의 구체적 에이전트의 물리적 안전성을 공식적으로 평가하기 위한 첫 번째 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 물리적 안전성을 정확하게 평가할 필요성이 있으며, 기존 방법들이 주관적인 판단에 의존하지 않도록 하기 위해.

Method: Sentinel은 형식적 시간 논리(TL) 의미론을 기반으로 안전 요구 사항을 정의하고, 다단계 검증 파이프라인을 통해 구체적 안전 조건을 평가한다.

Result: Sentinel은 VirtualHome과 ALFRED에서 여러 LLM 기반 에이전트를 평가하였고, 다양한 안전 요구 사항에 대해 실험을 수행했다.

Conclusion: Sentinel은 물리적 환경에서 LLM 기반 에이전트를 체계적으로 평가할 수 있는 엄격한 기반을 제공하며, 이전 방법들이 간과한 안전 위반을 드러내고 실패 모드에 대한 통찰력을 제공한다.

Abstract: We present Sentinel, the first framework for formally evaluating the physical
safety of Large Language Model(LLM-based) embodied agents across the semantic,
plan, and trajectory levels. Unlike prior methods that rely on heuristic rules
or subjective LLM judgments, Sentinel grounds practical safety requirements in
formal temporal logic (TL) semantics that can precisely specify state
invariants, temporal dependencies, and timing constraints. It then employs a
multi-level verification pipeline where (i) at the semantic level, intuitive
natural language safety requirements are formalized into TL formulas and the
LLM agent's understanding of these requirements is probed for alignment with
the TL formulas; (ii) at the plan level, high-level action plans and subgoals
generated by the LLM agent are verified against the TL formulas to detect
unsafe plans before execution; and (iii) at the trajectory level, multiple
execution trajectories are merged into a computation tree and efficiently
verified against physically-detailed TL specifications for a final safety
check. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate
multiple LLM-based embodied agents against diverse safety requirements. Our
experiments show that by grounding physical safety in temporal logic and
applying verification methods across multiple levels, Sentinel provides a
rigorous foundation for systematically evaluating LLM-based embodied agents in
physical environments, exposing safety violations overlooked by previous
methods and offering insights into their failure modes.

</details>


### [33] [Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking](https://arxiv.org/abs/2510.13036)
*Stephane Hatgis-Kessell,Logan Mondal Bhamidipaty,Emma Brunskill*

Main category: cs.AI

TL;DR: PBRR(Preference-Based Reward Repair)는 인간이 설정한 보상 함수의 한계를 극복하기 위해 인간 선호를 통해 보상 함수의 수정항을 학습하는 자동화된 반복 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 인간 설계의 보상 함수가 인간의 진정한 목표와 일치하지 않아 보상 해킹이 발생할 수 있다.

Method: PBRR는 인간 선호로부터 전이 의존적인 수정항을 학습하여 보상 함수를 개선하는 반복적 접근 방식을 사용한다.

Result: PBRR는 이전의 선호 기반 RL 방법들과 비교하여 누적 후회를 일치시킨다. 그리고 보상 해킹 벤치마크에서 일관되게 우수한 성과를 낸다.

Conclusion: PBRR은 상대적으로 적은 선호로 높은 성능 정책을 학습할 수 있도록 하여, 인간 정의의 보상 함수가 최적이 아닐 때도 효과적인 성능을 나타낸다.

Abstract: Human-designed reward functions for reinforcement learning (RL) agents are
frequently misaligned with the humans' true, unobservable objectives, and thus
act only as proxies. Optimizing for a misspecified proxy reward function often
induces reward hacking, resulting in a policy misaligned with the human's true
objectives. An alternative is to perform RL from human feedback, which involves
learning a reward function from scratch by collecting human preferences over
pairs of trajectories. However, building such datasets is costly. To address
the limitations of both approaches, we propose Preference-Based Reward Repair
(PBRR): an automated iterative framework that repairs a human-specified proxy
reward function by learning an additive, transition-dependent correction term
from preferences. A manually specified reward function can yield policies that
are highly suboptimal under the ground-truth objective, yet corrections on only
a few transitions may suffice to recover optimal performance. To identify and
correct for those transitions, PBRR uses a targeted exploration strategy and a
new preference-learning objective. We prove in tabular domains PBRR has a
cumulative regret that matches, up to constants, that of prior preference-based
RL methods. In addition, on a suite of reward-hacking benchmarks, PBRR
consistently outperforms baselines that learn a reward function from scratch
from preferences or modify the proxy reward function using other approaches,
requiring substantially fewer preferences to learn high performing policies.

</details>


### [34] [Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation](https://arxiv.org/abs/2510.13195)
*Qun Ma,Xiao Xue,Xuwen Zhang,Zihan Zhao,Yuwei Guo,Ming Zhang*

Main category: cs.AI

TL;DR: 본 연구는 감정 인식을 통한 LLM 기반 에이전트의 의사결정 프로세스를 개선하는 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 에이전트는 정서적 인지가 제한적이며, 가상과 실제 서비스 간의 연결에 필요한 bounded rationality를 시뮬레이션하지 못한다.

Method: 이 논문은 욕구 생성과 목표 관리를 통합한 감정 인식 프레임워크를 구축하여 LLM 기반 에이전트와 인간 간의 감정 정합을 달성하는 것을 목표로 한다.

Result: 제안된 프레임워크를 구현한 실험 결과, 에이전트는 감정 상태와 일치하는 행동을 보였으며, 다른 에이전트 유형과 비교했을 때 생태적 타당성이 뛰어나고 의사 결정 결과가 인간의 행동 패턴과 더 밀접하게 일치함을 보여주었다.

Conclusion: 본 연구는 감정 인식 프레임워크가 LLM 기반 에이전트의 의사결정 개선에 기여할 수 있음을 입증하였다.

Abstract: The advent of large language models (LLMs) has enabled agents to represent
virtual humans in societal simulations, facilitating diverse interactions
within complex social systems. However, existing LLM-based agents exhibit
severe limitations in affective cognition: They fail to simulate the bounded
rationality essential for bridging virtual and real-world services; They lack
empirically validated integration mechanisms embedding emotions within agent
decision architectures. This paper constructs an emotional cognition framework
incorporating desire generation and objective management, designed to achieve
emotion alignment between LLM-based agents and humans, modeling the complete
decision-making process of LLM-based agents, encompassing state evolution,
desire generation, objective optimization, decision generation, and action
execution. This study implements the proposed framework within our proprietary
multi-agent interaction environment. Experimental results demonstrate that
agents governed by our framework not only exhibit behaviors congruent with
their emotional states but also, in comparative assessments against other agent
types, demonstrate superior ecological validity and generate decision outcomes
that significantly more closely approximate human behavioral patterns.

</details>


### [35] [Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning](https://arxiv.org/abs/2510.13214)
*Zehui Ling,Deshu Chen,Yichi Zhang,Yuchen Liu,Xigui Li,Xin Guo,Yuan Cheng*

Main category: cs.AI

TL;DR: 이 논문은 작은 LLM과 큰 LLM을 통합한 보완적인 에이전트 시스템을 제안하여 계산 비용을 줄이고 성능을 향상시키는 방법을 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 최근의 대규모 언어 모델(LLM) 발전으로 인한 복잡한 작업에 대한 성능 향상을 보여주고, 이러한 모델의 논쟁을 가능하게 하는 다중 에이전트 시스템이 정확성을 더욱 높일 수 있음을 알게 되었습니다. 그러나 모든 문제에 깊은 추론을 적용하는 것은 계산 비용이 많이 듭니다.

Method: 작은 LLM이 초깃값을 생성한 후, 큰 LLM이 이를 검증합니다. 정답이면 그대로 채택하고, 그렇지 않으면 큰 LLM이 심층 추론을 수행합니다.

Result: 간단한 문제에 대해 이 접근법은 큰 LLM의 계산 비용을 50% 이상 줄이면서도 정확도 손실은 미미하고, 복잡한 작업에서도 일관된 성능을 유지함을 보여줍니다.

Conclusion: 작은 LLM과 큰 LLM을 통합한 보완적인 접근 방식이 성능과 비용을 동시에 향상시킬 수 있음을 입증했습니다.

Abstract: Recent advances in Large Language Models (LLMs) demonstrate that
chain-of-thought prompting and deep reasoning substantially enhance performance
on complex tasks, and multi-agent systems can further improve accuracy by
enabling model debates. However, applying deep reasoning to all problems is
computationally expensive. To mitigate these costs, we propose a complementary
agent system integrating small and large LLMs. The small LLM first generates an
initial answer, which is then verified by the large LLM. If correct, the answer
is adopted directly; otherwise, the large LLM performs in-depth reasoning.
Experimental results show that, for simple problems, our approach reduces the
computational cost of the large LLM by more than 50% with negligible accuracy
loss, while consistently maintaining robust performance on complex tasks.

</details>


### [36] [EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems](https://arxiv.org/abs/2510.13220)
*Yufei He,Juncheng Liu,Yue Liu,Yibo Li,Tri Cao,Zhiyuan Hu,Xinxing Xu,Bryan Hooi*

Main category: cs.AI

TL;DR: EvoTest는 J-TTL 벤치마크에서 AI 에이전트의 성능을 개선하기 위한 혁신적인 진화적 학습 프레임워크로, 기존의 적응 방식보다 우수한 성과를 기록합니다.


<details>
  <summary>Details</summary>
Motivation: 현재 AI 에이전트는 새로운 환경에서 복잡한 기술을 즉석에서 학습하지 못하는 한계를 가지고 있습니다.

Method: EvoTest는 에이전트를 미세 조정이나 그래디언트 없이 전체 시스템을 진화시켜 성능을 개선하는 진화적 학습 프레임워크입니다.

Result: EvoTest는 J-TTL 벤치마크에서 성능을 지속적으로 향상시켜 기존의 적응 방법들보다 우수한 결과를 냅니다.

Conclusion: EvoTest는 두 게임에서 승리할 수 있는 유일한 방법으로, 모든 기준선은 승리하지 못했습니다.

Abstract: A fundamental limitation of current AI agents is their inability to learn
complex skills on the fly at test time, often behaving like "clever but
clueless interns" in novel environments. This severely limits their practical
utility. To systematically measure and drive progress on this challenge, we
first introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a
new evaluation setup where an agent must play the same game for several
consecutive episodes, attempting to improve its performance from one episode to
the next. On J-TTL, we find that existing adaptation methods like reflection,
memory, or reinforcement learning struggle. To address the challenges posed by
our benchmark, we present EvoTest, an evolutionary test-time learning framework
that improves an agent without any fine-tuning or gradients-by evolving the
entire agentic system after every episode. EvoTest has two roles: the Actor
Agent, which plays the game, and the Evolver Agent, which analyzes the episode
transcript to propose a revised configuration for the next run. This
configuration rewrites the prompt, updates memory by logging effective
state-action choices, tunes hyperparameters, and learns the tool-use routines.
On our J-TTL benchmark, EvoTest consistently increases performance,
outperforming not only reflection and memory-only baselines but also more
complex online fine-tuning methods. Notably, our method is the only one capable
of winning two games (Detective and Library), while all baselines fail to win
any.

</details>


### [37] [SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2510.13262)
*Weiqi Guo,Guanjun Liu,Ziyuan Zhou*

Main category: cs.AI

TL;DR: SAJA 프레임워크는 다중 에이전트 심층 강화 학습 모델에 대한 새로운 공격 방법을 제안하며, 상태와 행동의 합동 공격에서 효과적인 시너지 효과를 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: MADRL 모델은 적대적 교란에 취약하므로, 이러한 모델의 강인성을 공격 관점에서 조사하는 것이 필수적입니다.

Method: SAJA 프레임워크는 다단계 그래디언트 상승 방법을 사용하여 적대적 상태를 계산하고, 교란된 상태에 따라 최종 적대 행동을 생성하는 두 가지 주요 단계를 포함합니다.

Result: SAJA는 다중 에이전트 입자 환경(MPE)에서 평가되었으며, 상태 전용 또는 행동 전용 공격보다 뛰어나고 은밀하다는 것을 입증합니다.

Conclusion: 기존의 상태 또는 행동 방어 방법으로는 이 공격을 방어할 수 없습니다.

Abstract: Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for
cooperative and competitive tasks such as autonomous driving and strategic
gaming. However, models trained by MADRL are vulnerable to adversarial
perturbations on states and actions. Therefore, it is essential to investigate
the robustness of MADRL models from an attack perspective. Existing studies
focus on either state-only attacks or action-only attacks, but do not consider
how to effectively joint them. Simply combining state and action perturbations
such as randomly perturbing states and actions does not exploit their potential
synergistic effects. In this paper, we propose the State-Action Joint Attack
(SAJA) framework that has a good synergistic effects. SAJA consists of two
important phases: (1) In the state attack phase, a multi-step gradient ascent
method utilizes both the actor network and the critic network to compute an
adversarial state, and (2) in the action attack phase, based on the perturbed
state, a second gradient ascent uses the critic network to craft the final
adversarial action. Additionally, a heuristic regularizer measuring the
distance between the perturbed actions and the original clean ones is added
into the loss function to enhance the effectiveness of the critic's guidance.
We evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating
that (1) it outperforms and is more stealthy than state-only or action-only
attacks, and (2) existing state or action defense methods cannot defend its
attacks.

</details>


### [38] [Tandem Training for Language Models](https://arxiv.org/abs/2510.13551)
*Robert West,Ashton Anderson,Ece Kamar,Eric Horvitz*

Main category: cs.AI

TL;DR: 언어 모델의 해석 가능성과 감독을 강화하기 위해, 본 연구는 약한 협력자들에게 이해 가능한 솔루션을 생성하도록 모델을 유도하는 방법을 모색합니다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델의 발전이 빠르게 이루어짐에 따라, 그들의 행동과 추론이 약한 에이전트와 인간에게는 이해하기 어렵거나 불가능하게 될 것으로 예상되므로 해석 가능성과 감독이 훼손될 수 있습니다.

Method: 우리는 언어 모델을 위한 텐덤 훈련(tandem training)을 도입합니다. 이는 강화 학습(RL) 패러다임으로, 강한 모델이 아닌 얼음 상태의 약한 모델에서 간헐적으로 랜덤으로 롤아웃 토큰을 샘플링합니다.

Result: 텐덤 훈련은 모델들이 전문 용어를 버리고 약한 파트너에 맞춰 언어를 조정하는 것을 reliably 가르칩니다.

Conclusion: 우리의 결과는 약한 에이전트에 의해 감사 가능성을 유지하는 AI 시스템을 구축하는 유망한 경로를 보여주며, 인간-인공지능 협업 및 다중 에이전트 통신에 대한 시사점을 갖습니다.

Abstract: As language models continue to rapidly improve, we can expect their actions
and reasoning to become difficult or impossible for weaker agents and humans to
follow, undermining interpretability and oversight. With an eye on long-term
futures, we pursue methods that encourage models to produce solutions that
remain intelligible to weaker collaborators. We formalize intelligibility as
handoff robustness: a strong model's solution is intelligible to a weaker model
if randomly handing off control to the weaker model along the solution path
does not cause failure. Building on this criterion, we introduce tandem
training for language models, a reinforcement learning (RL) paradigm in which
rollout tokens are intermittently and randomly sampled from a frozen weak model
rather than the strong model being trained. Because rollouts succeed only when
the strong model's actions and reasoning process can be continued by the weak
model -- when the two can co-construct a successful solution -- optimizing
standard RL objectives with tandem training implicitly incentivizes both
correctness and intelligibility. In the GSM8K math reasoning task, tandem
training reliably teaches models to abandon jargon and adapt their language to
weaker partners while keeping task accuracy high. Our results demonstrate a
promising route to building AI systems that remain auditable by weaker agents,
with implications for human--AI collaboration and multi-agent communication.

</details>


### [39] [Training LLM Agents to Empower Humans](https://arxiv.org/abs/2510.13709)
*Evan Ellis,Vivek Myers,Jens Tuyls,Sergey Levine,Anca Dragan,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: 본 논문은 인간의 역량 극대화를 기반으로 하는 보조 언어 모델 튜닝을 제안하며, 이는 오프라인 텍스트 데이터만 필요하다. 실제 사용자 연구를 통해 제안된 방법의 유효성을 검증하였다.


<details>
  <summary>Details</summary>
Motivation: 보조 에이전트가 인간의 의사 결정 과정에서 통제권을 넘기고 도움을 주어야 한다는 필요성.

Method: 인간의 환경에 대한 영향력을 극대화하는 새로운 방법인 Empower를 제안하며, 이는 오프라인 텍스트 데이터만으로 작동한다.

Result: 사용자 연구에서 Empower를 사용하는 보조 에이전트가 강력한 기준선과 비교하여 선호도가 78%였으며, 수용률이 31% 높고 제안이 38% 적었다.

Conclusion: Empower 목표를 통해 오프라인 데이터만으로도 유용한 정렬된 AI 에이전트를 대규모로 구현할 수 있는 프레임워크를 제공한다.

Abstract: Assistive agents should not only take actions on behalf of a human, but also
step out of the way and cede control when there are important decisions to be
made. However, current methods for building assistive agents, whether via
mimicking expert humans or via RL finetuning on an inferred reward, often
encourage agents to complete tasks on their own rather than truly assisting the
human attain their objectives. Additionally, these methods often require costly
explicit human feedback to provide a training signal. We propose a new approach
to tuning assistive language models based on maximizing the human's
empowerment, their ability to effect desired changes in the environment. Our
empowerment-maximizing method, Empower, only requires offline text data,
providing a self-supervised method for fine-tuning language models to better
assist humans. To study the efficacy of our approach, we conducted an 18-person
user study comparing our empowerment assistant with a strong baseline.
Participants preferred our assistant 78% of the time (p=0.015), with a 31%
higher acceptance rate and 38% fewer suggestions. Additionally, we introduce a
new environment for evaluating multi-turn code assistance using simulated
humans. Using this environment, we show that agents trained with Empower
increase the success rate of a simulated human programmer on challenging coding
questions by an average of 192% over an SFT baseline. With this empowerment
objective, we provide a framework for useful aligned AI agents at scale using
only offline data without the need for any additional human feedback or
verifiable rewards.

</details>


### [40] [From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails](https://arxiv.org/abs/2510.13727)
*Ravi Pandya,Madison Bland,Duy P. Nguyen,Changliu Liu,Jaime Fernández Fisac,Andrea Bajcsy*

Main category: cs.AI

TL;DR: 본 논문은 AI 시스템의 안전성을 위한 새로운 접근 방식을 제안하며, 위험한 출력을 실시간으로 모니터링하고 안전한 출력으로 수정하는 예측적 가드레일을 구축하는 방법을 설명한다.


<details>
  <summary>Details</summary>
Motivation: Generative AI 시스템이 점점 더 사용자에게 도움을 주고 있다는 점에서, 안전성이 단순히 유해한 콘텐츠를 차단하는 것을 넘어서 다운스트림 위험을 예방하는 방향으로 나아가야 한다.

Method: 안전 중요 제어 이론의 관점에서 AI 시스템의 잠재적 세계 표현을 통해 AI 시스템의 출력을 실시간으로 모니터링하고 위험한 출력을 안전한 것으로 사전 수정하는 예측적 가드레일을 구축하는 방법을 제안한다.

Result: 시뮬레이션된 운전 및 전자 상거래 환경에서의 실험을 통해, 제어 이론 기반의 가드레일이 LLM 에이전트를 파국적 결과에서 안전하게 유도하면서도 작업 성능을 유지할 수 있음을 입증하였다.

Conclusion: 오늘날의 플래그 및 차단 가드레일에 대한 원칙적인 동적 대안을 제공하며, 이를 통해 AI 시스템의 안전성을 한층 강화할 수 있다.

Abstract: Generative AI systems are increasingly assisting and acting on behalf of end
users in practical settings, from digital shopping assistants to
next-generation autonomous cars. In this context, safety is no longer about
blocking harmful content, but about preempting downstream hazards like
financial or physical harm. Yet, most AI guardrails continue to rely on output
classification based on labeled datasets and human-specified criteria,making
them brittle to new hazardous situations. Even when unsafe conditions are
flagged, this detection offers no path to recovery: typically, the AI system
simply refuses to act--which is not always a safe choice. In this work, we
argue that agentic AI safety is fundamentally a sequential decision problem:
harmful outcomes arise from the AI system's continually evolving interactions
and their downstream consequences on the world. We formalize this through the
lens of safety-critical control theory, but within the AI model's latent
representation of the world. This enables us to build predictive guardrails
that (i) monitor an AI system's outputs (actions) in real time and (ii)
proactively correct risky outputs to safe ones, all in a model-agnostic manner
so the same guardrail can be wrapped around any AI model. We also offer a
practical training recipe for computing such guardrails at scale via
safety-critical reinforcement learning. Our experiments in simulated driving
and e-commerce settings demonstrate that control-theoretic guardrails can
reliably steer LLM agents clear of catastrophic outcomes (from collisions to
bankruptcy) while preserving task performance, offering a principled dynamic
alternative to today's flag-and-block guardrails.

</details>
