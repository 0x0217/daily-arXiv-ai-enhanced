<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 26]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.AI](#cs.AI) [Total: 30]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [FedOAED: Federated On-Device Autoencoder Denoiser for Heterogeneous Data under Limited Client Availability](https://arxiv.org/abs/2512.17986)
*S M Ruhul Kabir Howlader,Xiao Chen,Yifei Xie,Lu Liu*

Main category: cs.LG

TL;DR: 본 논문에서는 클라이언트 드리프트와 부분 클라이언트 참여로 인한 변동성을 완화하기 위한 새로운 연합 학습 알고리즘인 FedOAED를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 데이터 공유 규정으로 인해 많은 데이터 기반 응용 프로그램이 실현되지 못하고 있는 상황에서 연합 학습(FL)은 이러한 한계를 극복할 수 있는 가능성을 보여주고 있다.

Method: FedOAED는 여러 로컬 훈련 업데이트에서 발생하는 클라이언트 드리프트와 부분 클라이언트 참여로 인한 변동성을 줄이기 위해 클라이언트 쪽에 온디바이스 오토인코더 디노이저를 통합한 새로운 연합 학습 알고리즘이다.

Result: 여러 비전 데이터셋에 대한 Non-IID 설정에서의 실험 결과, FedOAED는 기존의 최첨단 성능을 지속적으로 초월하는 성과를 보였다.

Conclusion: FedOAED는 이질적인 데이터와 제한된 클라이언트 가용성 하에서도 클라이언트 드리프트와 변동성을 완화하는 데 효과적이다.

Abstract: Over the last few decades, machine learning (ML) and deep learning (DL) solutions have demonstrated their potential across many applications by leveraging large amounts of high-quality data. However, strict data-sharing regulations such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA) have prevented many data-driven applications from being realised. Federated Learning (FL), in which raw data never leaves local devices, has shown promise in overcoming these limitations. Although FL has grown rapidly in recent years, it still struggles with heterogeneity, which produces gradient noise, client-drift, and increased variance from partial client participation. In this paper, we propose FedOAED, a novel federated learning algorithm designed to mitigate client-drift arising from multiple local training updates and the variance induced by partial client participation. FedOAED incorporates an on-device autoencoder denoiser on the client side to mitigate client-drift and variance resulting from heterogeneous data under limited client availability. Experiments on multiple vision datasets under Non-IID settings demonstrate that FedOAED consistently outperforms state-of-the-art baselines.

</details>


### [2] [LeJOT: An Intelligent Job Cost Orchestration Solution for Databricks Platform](https://arxiv.org/abs/2512.18266)
*Lizhi Ma,Yi-Xiang Hu,Yuke Wang,Yifang Zhao,Yihui Ren,Jian-Xiang Liao,Feng Wu,Xiang-Yang Li*

Main category: cs.LG

TL;DR: LeJOT는 기계 학습을 활용하여 작업 실행 시간을 예측하고 실시간 리소스 할당을 최적화하는 지능형 작업 비용 조정 프레임워크로, 기존의 정적 구성 방식을 넘어 비용 절감을 달성합니다.


<details>
  <summary>Details</summary>
Motivation: 빅데이터 기술의 발전과 함께 Databricks 플랫폼에서 작업 실행과 관련된 운영 비용 관리가 중요한 과제가 되고 있습니다.

Method: LeJOT는 작업 실행 시간 예측을 위한 기계 학습과 실시간 리소스 할당을 위한 최적화 모델을 사용하는 프레임워크입니다.

Result: 실제 Databricks 작업에 대한 실험 결과, LeJOT는 평균 20%의 클라우드 컴퓨팅 비용 절감을 달성했습니다.

Conclusion: LeJOT는 Data Lakehouse 환경에서 비용 효율적인 작업 스케줄링을 위한 확장 가능하고 적응 가능한 솔루션을 제공합니다.

Abstract: With the rapid advancements in big data technologies, the Databricks platform has become a cornerstone for enterprises and research institutions, offering high computational efficiency and a robust ecosystem. However, managing the escalating operational costs associated with job execution remains a critical challenge. Existing solutions rely on static configurations or reactive adjustments, which fail to adapt to the dynamic nature of workloads. To address this, we introduce LeJOT, an intelligent job cost orchestration framework that leverages machine learning for execution time prediction and a solver-based optimization model for real-time resource allocation. Unlike conventional scheduling techniques, LeJOT proactively predicts workload demands, dynamically allocates computing resources, and minimizes costs while ensuring performance requirements are met. Experimental results on real-world Databricks workloads demonstrate that LeJOT achieves an average 20% reduction in cloud computing costs within a minute-level scheduling timeframe, outperforming traditional static allocation strategies. Our approach provides a scalable and adaptive solution for cost-efficient job scheduling in Data Lakehouse environments.

</details>


### [3] [Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings](https://arxiv.org/abs/2512.18309)
*Harsh Rathva,Ojas Srivastava,Pruthwik Mishra*

Main category: cs.LG

TL;DR: ESAI는 다중 에이전트 강화 학습을 위한 이론적 프레임워크로, 내부 표현에 직접 정렬 제약 조건을 내장하여 정책 업데이트를 조정합니다.


<details>
  <summary>Details</summary>
Motivation: 안전한 다중 에이전트 시스템을 구축하기 위해 내부적인 정렬 메커니즘을 개발하는 것이 필요합니다.

Method: ESAI 프레임워크는 네 가지 메커니즘: 반사적 정렬 패널티, 정렬 가중 인식 주의, 헤브비안 연상 기억, 유사성 가중 그래프 확산을 통합합니다.

Result: 조정된 내부 임베딩의 안정성 조건을 분석하고, 계산 복잡성과 이론적 속성을 논의합니다.

Conclusion: ESAI는 다중 에이전트 시스템에서 미분 가능 정렬 메커니즘에 기여하며, 향후 연구에서 경험적 평가가 필요합니다.

Abstract: We introduce Embedded Safety-Aligned Intelligence (ESAI), a theoretical framework for multi-agent reinforcement learning that embeds alignment constraints directly into agents internal representations using differentiable internal alignment embeddings. Unlike external reward shaping or post-hoc safety constraints, internal alignment embeddings are learned latent variables that predict externalized harm through counterfactual reasoning and modulate policy updates toward harm reduction through attention and graph-based propagation.
  The ESAI framework integrates four mechanisms: differentiable counterfactual alignment penalties computed from soft reference distributions, alignment-weighted perceptual attention, Hebbian associative memory supporting temporal credit assignment, and similarity-weighted graph diffusion with bias mitigation controls. We analyze stability conditions for bounded internal embeddings under Lipschitz continuity and spectral constraints, discuss computational complexity, and examine theoretical properties including contraction behavior and fairness-performance tradeoffs.
  This work positions ESAI as a conceptual contribution to differentiable alignment mechanisms in multi-agent systems. We identify open theoretical questions regarding convergence guarantees, embedding dimensionality, and extension to high-dimensional environments. Empirical evaluation is left to future work.

</details>


### [4] [MoE Pathfinder: Trajectory-driven Expert Pruning](https://arxiv.org/abs/2512.18425)
*Xican Yang,Yuanhe Tian,Yan Song*

Main category: cs.LG

TL;DR: 이 논문은 대형 언어 모델에서의 전문가 가지치기 접근 방식을 개선하여 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(MoE)에서의 전문가 가지치기는 계산 오버헤드를 줄이고 MoE 모델의 배포를 간소화하는 데 중요한 역할을 합니다.

Method: 활성화된 전문가의 경로를 기반으로 전문가 선택을 전역 최적 경로 계획 문제로 다루는 접근 방식을 제안합니다.

Result: 우리의 접근 방식은 기존의 대부분의 방법들과 비교할 때 거의 모든 작업에서 우수한 가지치기 성능을 달성합니다.

Conclusion: 제안된 방법은 전문가 가지치기에 있어 비균일한 전문화 유지를 자연스럽게 생성하며, 실험 결과를 통해 그 효과를 입증합니다.

Abstract: Mixture-of-experts (MoE) architectures used in large language models (LLMs) achieve state-of-the-art performance across diverse tasks yet face practical challenges such as deployment complexity and low activation efficiency. Expert pruning has thus emerged as a promising solution to reduce computational overhead and simplify the deployment of MoE models. However, existing expert pruning approaches conventionally rely on local importance metrics and often apply uniform layer-wise pruning, leveraging only partial evaluation signals and overlooking the heterogeneous contributions of experts across layers. To address these limitations, we propose an expert pruning approach based on the trajectory of activated experts across layers, which treats MoE as a weighted computation graph and casts expert selection as a global optimal path planning problem. Within this framework, we integrate complementary importance signals from reconstruction error, routing probabilities, and activation strength at the trajectory level, which naturally yields non-uniform expert retention across layers. Experiments show that our approach achieves superior pruning performance on nearly all tasks compared with most existing approaches.

</details>


### [5] [On the Universality of Transformer Architectures; How Much Attention Is Enough?](https://arxiv.org/abs/2512.18445)
*Amirreza Abbasi,Mohsen Hooshmand*

Main category: cs.LG

TL;DR: Transformers의 보편성 문제를 검토하고, 이론적 및 실제적 이해를 위한 최근 진전을 조사했다.


<details>
  <summary>Details</summary>
Motivation: Transformers는 큰 언어 모델, 컴퓨터 비전, 강화 학습 등 많은 AI 분야에서 중요하다.

Method: 구조적 최소성과 근사율과 같은 건축적 개선을 포함하여 최근 진전을 검토했다.

Result: Transformers의 표현력에 대한 현황을 명확히 하고, 견고한 보장과 취약한 보장을 구분했다.

Conclusion: 미래 이론적 연구를 위한 주요 방향을 식별하였다.

Abstract: Transformers are crucial across many AI fields, such as large language models, computer vision, and reinforcement learning. This prominence stems from the architecture's perceived universality and scalability compared to alternatives. This work examines the problem of universality in Transformers, reviews recent progress, including architectural refinements such as structural minimality and approximation rates, and surveys state-of-the-art advances that inform both theoretical and practical understanding. Our aim is to clarify what is currently known about Transformers expressiveness, separate robust guarantees from fragile ones, and identify key directions for future theoretical research.

</details>


### [6] [Self-organizing maps for water quality assessment in reservoirs and lakes: A systematic literature review](https://arxiv.org/abs/2512.18466)
*Oraib Almegdadi,João Marcelino,Sarah Fakhreddine,João Manso,Nuno C. Marques*

Main category: cs.LG

TL;DR: 이 논문은 자가조직화지도(SOM) 기술을 활용하여 수질 평가를 개선하는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 지속 가능한 수질 관리는 생태적 균형과 수자원 안전에 필수적이다.

Method: SOM 기법을 사용하여 수질 데이터를 평가하고, 매개변수 선택, 공간 및 시간 샘플링 전략, 클러스터링 접근 방식에 관한 연구를 종합하였다.

Result: SOM은 복잡한 데이터 세트를 효과적으로 분석하며, 수질 지표 간의 중요한 상관관계를 파악할 수 있다.

Conclusion: 이 리뷰는 SOM의 다양성과 생태 평가, 트로픽 상태 분류, 조류 발생 모니터링 및 유역 영향 평가에서의 활용 가능성을 강조한다.

Abstract: Sustainable water quality underpins ecological balance and water security. Assessing and managing lakes and reservoirs is difficult due to data sparsity, heterogeneity, and nonlinear relationships among parameters. This review examines how Self-Organizing Map (SOM), an unsupervised AI technique, is applied to water quality assessment. It synthesizes research on parameter selection, spatial and temporal sampling strategies, and clustering approaches. Emphasis is placed on how SOM handles multidimensional data and uncovers hidden patterns to support effective water management. The growing availability of environmental data from in-situ sensors, remote sensing imagery, IoT technologies, and historical records has significantly expanded analytical opportunities in environmental monitoring. SOM has proven effective in analysing complex datasets, particularly when labelled data are limited or unavailable. It enables high-dimensional data visualization, facilitates the detection of hidden ecological patterns, and identifies critical correlations among diverse water quality indicators. This review highlights SOMs versatility in ecological assessments, trophic state classification, algal bloom monitoring, and catchment area impact evaluations. The findings offer comprehensive insights into existing methodologies, supporting future research and practical applications aimed at improving the monitoring and sustainable management of lake and reservoir ecosystems.

</details>


### [7] [Benchmarking neural surrogates on realistic spatiotemporal multiphysics flows](https://arxiv.org/abs/2512.18595)
*Runze Mao,Rui Zhang,Xuan Bai,Tianhao Wu,Teng Zhang,Zhenyi Chen,Minqi Lin,Bocheng Zeng,Yangchen Xu,Yingxuan Xiang,Haoze Zhang,Shubham Goswami,Pierre A. Dawe,Yifan Xu,Zhenhua An,Mengtao Yan,Xiaoyi Lu,Yi Wang,Rongbo Bai,Haobu Gao,Xiaohang Fang,Han Li,Hao Sun,Zhi X. Chen*

Main category: cs.LG

TL;DR: REALM은 복잡한 반응 흐름에서 신경 대리 모델을 평가하기 위한 엄격한 벤치마킹 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 다중 물리 역학의 예측은 다중 척도와 이질적인 물리 과정 간의 심각한 결합으로 인해 계산 비용이 높고 도전적입니다. 현재 신경 대리 모델은 '마스터리의 환상'에서 고통 받고 있습니다.

Method: REALM은 11개의 고충실 데이터 세트와 다중 물리 인식 전처리를 포함하는 표준화된 훈련 및 평가 프로토콜을 특징으로 합니다.

Result: REALM을 사용하여 12개 이상의 대표적인 대리 모델 가족을 체계적으로 벤치마킹하여 세 가지 경향을 식별했습니다.

Conclusion: REALM은 현재 신경 대리 모델의 한계를 제시하고 차세대 물리 인식 아키텍처 개발을 촉진하는 엄격한 시험대 역할을 합니다.

Abstract: Predicting multiphysics dynamics is computationally expensive and challenging due to the severe coupling of multi-scale, heterogeneous physical processes. While neural surrogates promise a paradigm shift, the field currently suffers from an "illusion of mastery", as repeatedly emphasized in top-tier commentaries: existing evaluations overly rely on simplified, low-dimensional proxies, which fail to expose the models' inherent fragility in realistic regimes. To bridge this critical gap, we present REALM (REalistic AI Learning for Multiphysics), a rigorous benchmarking framework designed to test neural surrogates on challenging, application-driven reactive flows. REALM features 11 high-fidelity datasets spanning from canonical multiphysics problems to complex propulsion and fire safety scenarios, alongside a standardized end-to-end training and evaluation protocol that incorporates multiphysics-aware preprocessing and a robust rollout strategy. Using this framework, we systematically benchmark over a dozen representative surrogate model families, including spectral operators, convolutional models, Transformers, pointwise operators, and graph/mesh networks, and identify three robust trends: (i) a scaling barrier governed jointly by dimensionality, stiffness, and mesh irregularity, leading to rapidly growing rollout errors; (ii) performance primarily controlled by architectural inductive biases rather than parameter count; and (iii) a persistent gap between nominal accuracy metrics and physically trustworthy behavior, where models with high correlations still miss key transient structures and integral quantities. Taken together, REALM exposes the limits of current neural surrogates on realistic multiphysics flows and offers a rigorous testbed to drive the development of next-generation physics-aware architectures.

</details>


### [8] [EIA-SEC: Improved Actor-Critic Framework for Multi-UAV Collaborative Control in Smart Agriculture](https://arxiv.org/abs/2512.18596)
*Quanxi Zhou,Wencan Mao,Yilei Liang,Manabu Tsukada,Yunling Liu,Jon Crowcroft*

Main category: cs.LG

TL;DR: 무인 항공기(UAV)를 활용한 스마트 농업 시스템을 위한 새로운 다중 UAV 경로 계획 접근 방식이 제안된다.


<details>
  <summary>Details</summary>
Motivation: 무선 통신 기술의 광범위한 응용은 스마트 농업의 발전을 촉진하고 UAV가 다기능 역할을 수행하게끔 한다.

Method: 여러 UAV가 협력적으로 데이터 수집, 이미지 획득 및 통신 작업을 수행하는 다중 UAV 스마트 농업 시스템을 모델링하고, 이를 위해 마르코프 의사결정 과정을 사용한다. 새로운 Elite Imitation Actor-Shared Ensemble Critic (EIA-SEC) 프레임워크를 제안하여, 에이전트가 엘리트 에이전트로부터 적응적으로 학습하고, 공유된 앙상블 비평자가 각 에이전트의 로컬 비평가와 협력하여 공정한 목표 가치 추정을 보장하고 과대 평가를 방지한다.

Result: 실험 결과, EIA-SEC는 보상 성능, 훈련 안정성 및 수렴 속도 면에서 최신 기술을 초과하는 것으로 나타났다.

Conclusion: EIA-SEC 프레임워크는 다중 UAV 경로 계획 문제에 효과적인 솔루션을 제공한다.

Abstract: The widespread application of wireless communication technology has promoted the development of smart agriculture, where unmanned aerial vehicles (UAVs) play a multifunctional role. We target a multi-UAV smart agriculture system where UAVs cooperatively perform data collection, image acquisition, and communication tasks. In this context, we model a Markov decision process to solve the multi-UAV trajectory planning problem. Moreover, we propose a novel Elite Imitation Actor-Shared Ensemble Critic (EIA-SEC) framework, where agents adaptively learn from the elite agent to reduce trial-and-error costs, and a shared ensemble critic collaborates with each agent's local critic to ensure unbiased objective value estimates and prevent overestimation. Experimental results demonstrate that EIA-SEC outperforms state-of-the-art baselines in terms of reward performance, training stability, and convergence speed.

</details>


### [9] [Trajectory Planning for UAV-Based Smart Farming Using Imitation-Based Triple Deep Q-Learning](https://arxiv.org/abs/2512.18604)
*Wencan Mao,Quanxi Zhou,Tomas Couso Coddou,Manabu Tsukada,Yunling Liu,Yusheng Ji*

Main category: cs.LG

TL;DR: 본 논문에서는 UAV 기반 스마트 농업을 위한 경로 계획 문제를 다루며, 새로운 임mitation 기반 세중심 깊이 Q-네트워크(ITDQN) 알고리즘을 제안하여 효과적인 잡초 인식과 데이터 수집을 개선하는 방법을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 스마트 농업에서 UAV의 역할을 극대화하고자 하는 필요성과 기존 방법들의 한계를 극복하려는 목표.

Method: 경로 계획 문제를 마르코프 결정 과정(MDP)으로 공식화하고 다중 에이전트 강화 학습(MARL)을 통해 해결하였으며, ITDQN 알고리즘을 제안함.

Result: ITDQN은 잡초 인식률에서 DDQN보다 4.43% 향상되었고, 데이터 수집률에서 6.94% 성능 개선을 보였다.

Conclusion: 우리의 방법은 시뮬레이션과 실제 환경에서의 실험을 통해 효과성을 입증하였다.

Abstract: Unmanned aerial vehicles (UAVs) have emerged as a promising auxiliary platform for smart agriculture, capable of simultaneously performing weed detection, recognition, and data collection from wireless sensors. However, trajectory planning for UAV-based smart agriculture is challenging due to the high uncertainty of the environment, partial observations, and limited battery capacity of UAVs. To address these issues, we formulate the trajectory planning problem as a Markov decision process (MDP) and leverage multi-agent reinforcement learning (MARL) to solve it. Furthermore, we propose a novel imitation-based triple deep Q-network (ITDQN) algorithm, which employs an elite imitation mechanism to reduce exploration costs and utilizes a mediator Q-network over a double deep Q-network (DDQN) to accelerate and stabilize training and improve performance. Experimental results in both simulated and real-world environments demonstrate the effectiveness of our solution. Moreover, our proposed ITDQN outperforms DDQN by 4.43\% in weed recognition rate and 6.94\% in data collection rate.

</details>


### [10] [ARC: Leveraging Compositional Representations for Cross-Problem Learning on VRPs](https://arxiv.org/abs/2512.18633)
*Han-Seul Jeong,Youngjoon Park,Hyungseok Song,Woohyung Lim*

Main category: cs.LG

TL;DR: ARC는 다양한 VRP의 속성을 효과적으로 일반화하는 크로스 문제 학습 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 실제 속성을 가진 VRP는 문제 변형 간의 효율적인 일반화를 위한 크로스 문제 학습 접근 방식에 대한 최근의 관심을 불러일으켰습니다.

Method: ARC는 속성을 내재적 속성 임베딩(IAE)과 맥락 상호작용 임베딩(CIE)이라는 두 가지 보완적인 구성 요소로 분해하여 불교합 속성 표현을 학습하는 구조입니다.

Result: ARC는 데이터 배경 내, 제로샷 일반화, 소샷 적응 및 실제 벤치마크에서 최첨단 성능을 달성합니다.

Conclusion: 이 모델은 훈련된 변형들 간에 불변 의미론을 재사용하고 보지 못한 조합을 위한 표현을 구성할 수 있게 해줍니다.

Abstract: Vehicle Routing Problems (VRPs) with diverse real-world attributes have driven recent interest in cross-problem learning approaches that efficiently generalize across problem variants. We propose ARC (Attribute Representation via Compositional Learning), a cross-problem learning framework that learns disentangled attribute representations by decomposing them into two complementary components: an Intrinsic Attribute Embedding (IAE) for invariant attribute semantics and a Contextual Interaction Embedding (CIE) for attribute-combination effects. This disentanglement is achieved by enforcing analogical consistency in the embedding space to ensure the semantic transformation of adding an attribute (e.g., a length constraint) remains invariant across different problem contexts. This enables our model to reuse invariant semantics across trained variants and construct representations for unseen combinations. ARC achieves state-of-the-art performance across in-distribution, zero-shot generalization, few-shot adaptation, and real-world benchmarks.

</details>


### [11] [Demonstration-Guided Continual Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2512.18670)
*Xue Yang,Michael Schukat,Junlin Lu,Patrick Mannion,Karl Mason,Enda Howley*

Main category: cs.LG

TL;DR: 본 연구는 지속적인 강화 학습(DGCRL)을 제안하며, 외부의 자기 진화형 시연 저장소를 활용하여 RL 에이전트가 탐색 및 적응을 직접 안내함으로써 안정성과 가소성 사이의 균형을 유지합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 강화 학습이 동적 환경에서 어려움을 겪고 있으며, 지속적인 학습을 통해 신속하게 적응할 수 있는 방법론이 필요하다.

Method: 본 연구는 DGCRL을 제안하며, 외부 시연 저장소를 통해 에이전트가 동적으로 관련 있는 시연을 선택하여 학습을 가속화하는 커리큘럼 기반 전략을 사용합니다.

Result: 2D 내비게이션 및 MuJoCo 보행 작업에서 우수한 평균 성능과 향상된 지식 전이, 망각 완화 및 학습 효율성을 입증했습니다.

Conclusion: 저자들은 추가적인 민감도 분석과 절제 연구를 통해 제안 방법의 효과성을 검증합니다.

Abstract: Reinforcement learning (RL) excels in various applications but struggles in dynamic environments where the underlying Markov decision process evolves. Continual reinforcement learning (CRL) enables RL agents to continually learn and adapt to new tasks, but balancing stability (preserving prior knowledge) and plasticity (acquiring new knowledge) remains challenging. Existing methods primarily address the stability-plasticity dilemma through mechanisms where past knowledge influences optimization but rarely affects the agent's behavior directly, which may hinder effective knowledge reuse and efficient learning. In contrast, we propose demonstration-guided continual reinforcement learning (DGCRL), which stores prior knowledge in an external, self-evolving demonstration repository that directly guides RL exploration and adaptation. For each task, the agent dynamically selects the most relevant demonstration and follows a curriculum-based strategy to accelerate learning, gradually shifting from demonstration-guided exploration to fully self-exploration. Extensive experiments on 2D navigation and MuJoCo locomotion tasks demonstrate its superior average performance, enhanced knowledge transfer, mitigation of forgetting, and training efficiency. The additional sensitivity analysis and ablation study further validate its effectiveness.

</details>


### [12] [Merging of Kolmogorov-Arnold networks trained on disjoint datasets](https://arxiv.org/abs/2512.18921)
*Andrew Polar,Michael Poluektov*

Main category: cs.LG

TL;DR: 이 논문은 분리된 데이터셋에서의 학습을 통해 훈련 속도를 향상시키고 연합 학습을 가능하게 하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 훈련 속도를 높이고 연합 학습을 가능하게 하기 위해서는 분리된 데이터셋에서의 학습이 필요하다.

Method: 뉴턴-카츠마르츠 방법과 조각별 선형 기저 함수를 사용하여 훈련을 수행한다.

Result: 분리된 데이터셋에서 학습하는 것이 성능을 더욱 향상시킬 수 있음을 보여준다.

Conclusion: 모든 실험 결과와 코드가 공개적으로 제공된다.

Abstract: Training on disjoint datasets can serve two primary goals: accelerating data processing and enabling federated learning. It has already been established that Kolmogorov-Arnold networks (KANs) are particularly well suited for federated learning and can be merged through simple parameter averaging. While the federated learning literature has mostly focused on achieving training convergence across distributed nodes, the present paper specifically targets acceleration of the training, which depends critically on the choice of an optimisation method and the type of the basis functions. To the best knowledge of the authors, the fastest currently-available combination is the Newton-Kaczmarz method and the piecewise-linear basis functions. Here, it is shown that training on disjoint datasets (or disjoint subsets of the training dataset) can further improve the performance. Experimental comparisons are provided, and all corresponding codes are publicly available.

</details>


### [13] [Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement](https://arxiv.org/abs/2512.18950)
*Saman Forouzandeh,Wei Peng,Parham Moradi,Xinghuo Yu,Mahdi Jalili*

Main category: cs.LG

TL;DR: MACLA는 학습에서 추론을 분리하여 외부 계층적 절차 기억에서 모든 적응을 수행하는 프레임워크로, 4개의 벤치마크에서 평균 78.1%의 성능을 달성했습니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 매개변수를 업데이트하지 않고도 에이전트의 샘플 효율성, 해석 가능성 및 지속적인 개선을 이루기 위해.

Method: MACLA는 경량화된 절차 기억을 활용하여 트랙에서 재사용 가능한 절차를 추출하고, 베이지안 후방 분포를 통해 신뢰성을 추적하며, 기대 효용 점수를 사용하여 행동을 선택하고 성공과 실패를 대조하여 절차를 개선합니다.

Result: MACLA는 ALFWorld, WebShop, TravelPlanner, InterCodeSQL를 포함한 4개의 벤치마크에서 평균 78.1%의 성능을 달성하며, ALFWorld에서 보지 못한 작업에서는 90.3%에 도달하며 3.1%의 긍정적 일반화를 보입니다.

Conclusion: MACLA는 최신 LLM 파라미터 학습 기준보다 2800배 빠르게 56초 만에 기억을 구성하고, 2851개의 트랙을 187개의 절차로 압축하여 샘플 효율적이고 해석 가능한 에이전트를 가능하게 합니다.

Abstract: We present MACLA, a framework that decouples reasoning from learning by maintaining a frozen large language model while performing all adaptation in an external hierarchical procedural memory. MACLA extracts reusable procedures from trajectories, tracks reliability via Bayesian posteriors, selects actions through expected-utility scoring, and refines procedures by contrasting successes and failures. Across four benchmarks (ALFWorld, WebShop, TravelPlanner, InterCodeSQL), MACLA achieves 78.1 percent average performance, outperforming all baselines. On ALFWorld unseen tasks, MACLA reaches 90.3 percent with 3.1 percent positive generalization. The system constructs memory in 56 seconds, 2800 times faster than the state-of-the-art LLM parameter-training baseline, compressing 2851 trajectories into 187 procedures. Experimental results demonstrate that structured external memory with Bayesian selection and contrastive refinement enables sample-efficient, interpretable, and continually improving agents without LLM parameter updates.

</details>


### [14] [Scaling Online Distributionally Robust Reinforcement Learning: Sample-Efficient Guarantees with General Function Approximation](https://arxiv.org/abs/2512.18957)
*Debamita Ghosh,George K. Atia,Yue Wang*

Main category: cs.LG

TL;DR: 이 논문은 환경 간 불일치로 인한 강화 학습 에이전트 성능 저하 문제를 해결하기 위한 온라인 분포적으로 강건한 강화 학습 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 응용에서 강화 학습 에이전트의 성능 저하 문제가 있어 이를 해결할 필요가 있습니다.

Method: 온라인 분포적으로 강건한 강화 학습 알고리즘을 제안하여, 환경과의 상호작용을 통해 최적의 강건한 정책을 학습합니다.

Result: 우리의 방법은 고차원 작업에 대한 배포를 가능하게 하고, 이론적 분석을 통해 기존의 불확실성 집합 하의 거의 최적의 하한을 확립합니다.

Conclusion: 제안된 알고리즘은 대규모 오프라인 데이터나 생성 모델 없이도 샘플 효율성과 효과성을 증명합니다.

Abstract: The deployment of reinforcement learning (RL) agents in real-world applications is often hindered by performance degradation caused by mismatches between training and deployment environments. Distributionally robust RL (DR-RL) addresses this issue by optimizing worst-case performance over an uncertainty set of transition dynamics. However, existing work typically relies on substantial prior knowledge-such as access to a generative model or a large offline dataset-and largely focuses on tabular methods that do not scale to complex domains. We overcome these limitations by proposing an online DR-RL algorithm with general function approximation that learns an optimal robust policy purely through interaction with the environment, without requiring prior models or offline data, enabling deployment in high-dimensional tasks. We further provide a theoretical analysis establishing a near-optimal sublinear regret bound under a total variation uncertainty set, demonstrating the sample efficiency and effectiveness of our method.

</details>


### [15] [Outlier detection in mixed-attribute data: a semi-supervised approach with fuzzy approximations and relative entropy](https://arxiv.org/abs/2512.18978)
*Baiyang Chen,Zhong Yuan,Zheng Liu,Dezhong Peng,Yongxiang Li,Chang Liu,Guiduo Duan*

Main category: cs.LG

TL;DR: 모호한 비트 기반 이상치 탐지(FROD)는 반감독 방식으로 이상치를 정확히 탐지하는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 이 논문은 실제 혼합 속성 데이터의 불확실성과 이질성을 해결하기 위해 반감독 이상치 탐지 방법을 제안한다.

Method: 소량의 레이블이 붙은 데이터를 활용하여 모호한 결정 시스템을 구축하고, 레이블이 없는 데이터를 이용해 모호한 상대 엔트로피를 계산하여 이상치를 특성화한다.

Result: 16개의 공개 데이터셋에서 FROD가 기존 탐지 알고리즘과 동등하거나 더 나은 성능을 보임을 입증하였다.

Conclusion: FROD는 실제 데이터의 불확실성을 효과적으로 처리함으로써 이상치 탐지 성능을 개선한다.

Abstract: Outlier detection is a critical task in data mining, aimed at identifying objects that significantly deviate from the norm. Semi-supervised methods improve detection performance by leveraging partially labeled data but typically overlook the uncertainty and heterogeneity of real-world mixed-attribute data. This paper introduces a semi-supervised outlier detection method, namely fuzzy rough sets-based outlier detection (FROD), to effectively handle these challenges. Specifically, we first utilize a small subset of labeled data to construct fuzzy decision systems, through which we introduce the attribute classification accuracy based on fuzzy approximations to evaluate the contribution of attribute sets in outlier detection. Unlabeled data is then used to compute fuzzy relative entropy, which provides a characterization of outliers from the perspective of uncertainty. Finally, we develop the detection algorithm by combining attribute classification accuracy with fuzzy relative entropy. Experimental results on 16 public datasets show that FROD is comparable with or better than leading detection algorithms. All datasets and source codes are accessible at https://github.com/ChenBaiyang/FROD. This manuscript is the accepted author version of a paper published by Elsevier. The final published version is available at https://doi.org/10.1016/j.ijar.2025.109373

</details>


### [16] [R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer's Disease Progression](https://arxiv.org/abs/2512.18986)
*Kun Zhao,Siyuan Dai,Yingying Zhang,Guodong Liu,Pengfei Gu,Chenghua Lin,Paul M. Thompson,Alex Leow,Heng Huang,Lifang He,Liang Zhan,Haoteng Tang*

Main category: cs.LG

TL;DR: R-GenIMA는 알츠하이머병(AD)의 조기 발견을 위한 해석 가능한 다중 모달 언어 모델로, 구조적 MRI와 단일 핵산 다형성(SNP)의 변화를 연계하여 병리학적 및 유전적 요인을 통합한다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병의 조기 발견을 위해서는 거시적 신경 해부학적 변화와 미시적 유전적 소인을 통합할 수 있는 모델이 필요하다.

Method: R-GenIMA는 새로운 ROI-wise 비전 트랜스포머와 유전적 프로밍을 결합하여 구조적 MRI와 SNP 변화를 공동 모델링한다.

Result: ADNI 집단에 적용했을 때, R-GenIMA는 정상 인지(NC), 주관적 기억 문제(SMC), 경도 인지 장애(MCI), 그리고 AD에서 4-way 분류에서 최첨단 성능을 달성했다.

Conclusion: 해석 가능한 다중 모달 AI가 이미징과 유전 정보를 통합하여 기계적 통찰력을 제공함으로써 임상적으로 배포 가능한 도구의 기초를 제공하고, 알츠하이머병에서의 조기 위험 분류 및 정밀 치료 전략을 알릴 수 있음을 보여준다.

Abstract: Early detection of Alzheimer's disease (AD) requires models capable of integrating macro-scale neuroanatomical alterations with micro-scale genetic susceptibility, yet existing multimodal approaches struggle to align these heterogeneous signals. We introduce R-GenIMA, an interpretable multimodal large language model that couples a novel ROI-wise vision transformer with genetic prompting to jointly model structural MRI and single nucleotide polymorphisms (SNPs) variations. By representing each anatomically parcellated brain region as a visual token and encoding SNP profiles as structured text, the framework enables cross-modal attention that links regional atrophy patterns to underlying genetic factors. Applied to the ADNI cohort, R-GenIMA achieves state-of-the-art performance in four-way classification across normal cognition (NC), subjective memory concerns (SMC), mild cognitive impairment (MCI), and AD. Beyond predictive accuracy, the model yields biologically meaningful explanations by identifying stage-specific brain regions and gene signatures, as well as coherent ROI-Gene association patterns across the disease continuum. Attention-based attribution revealed genes consistently enriched for established GWAS-supported AD risk loci, including APOE, BIN1, CLU, and RBFOX1. Stage-resolved neuroanatomical signatures identified shared vulnerability hubs across disease stages alongside stage-specific patterns: striatal involvement in subjective decline, frontotemporal engagement during prodromal impairment, and consolidated multimodal network disruption in AD. These results demonstrate that interpretable multimodal AI can synthesize imaging and genetics to reveal mechanistic insights, providing a foundation for clinically deployable tools that enable earlier risk stratification and inform precision therapeutic strategies in Alzheimer's disease.

</details>


### [17] [Timely Parameter Updating in Over-the-Air Federated Learning](https://arxiv.org/abs/2512.19103)
*Jiaqi Zhu,Zhongyuan Zhao,Xiao Li,Ruihao Du,Shi Jin,Howard H. Yang*

Main category: cs.LG

TL;DR: OAC-FL은 연합 학습의 통신 병목을 완화하는 효과적인 방법이며, FAIR-k 알고리즘은 각 통신 라운드에서 가장 영향력 있는 기울기 하위 집합을 선택하여 OAC-FL의 수렴 속도와 통신 효율성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습 시스템에서 통신 병목 현상을 완화하기 위해 OAC를 모델 훈련 과정에 통합하는 것이 중요하다.

Method: FAIR-k 알고리즘은 각 통신 라운드에서 가장 영향력 있는 기울기 하위 집합을 선택한다.

Result: FAIR-k는 신선한 매개변수 업데이트를 촉진하여 수렴 속도를 가속화하고, 지역 훈련 기간을 연장함으로써 통신 효율성을 향상시킨다.

Conclusion: FAIR-k는 데이터 이질성, 채널 노이즈 및 매개변수 노후화를 공통적으로 고려하여 OAC-FL의 수렴 속도를 수립한다.

Abstract: Incorporating over-the-air computations (OAC) into the model training process of federated learning (FL) is an effective approach to alleviating the communication bottleneck in FL systems. Under OAC-FL, every client modulates its intermediate parameters, such as gradient, onto the same set of orthogonal waveforms and simultaneously transmits the radio signal to the edge server. By exploiting the superposition property of multiple-access channels, the edge server can obtain an automatically aggregated global gradient from the received signal. However, the limited number of orthogonal waveforms available in practical systems is fundamentally mismatched with the high dimensionality of modern deep learning models. To address this issue, we propose Freshness Freshness-mAgnItude awaRe top-k (FAIR-k), an algorithm that selects, in each communication round, the most impactful subset of gradients to be updated over the air. In essence, FAIR-k combines the complementary strengths of the Round-Robin and Top-k algorithms, striking a delicate balance between timeliness (freshness of parameter updates) and importance (gradient magnitude). Leveraging tools from Markov analysis, we characterize the distribution of parameter staleness under FAIR-k. Building on this, we establish the convergence rate of OAC-FL with FAIR-k, which discloses the joint effect of data heterogeneity, channel noise, and parameter staleness on the training efficiency. Notably, as opposed to conventional analyses that assume a universal Lipschitz constant across all the clients, our framework adopts a finer-grained model of the data heterogeneity. The analysis demonstrates that since FAIR-k promotes fresh (and fair) parameter updates, it not only accelerates convergence but also enhances communication efficiency by enabling an extended period of local training without significantly affecting overall training efficiency.

</details>


### [18] [Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments](https://arxiv.org/abs/2512.19154)
*Geraud Nangue Tasse,Matthew Riemer,Benjamin Rosman,Tim Klinger*

Main category: cs.LG

TL;DR: 이 논문은 비마르코프 의존성을 다루기 위한 새로운 메타 알고리즘을 제안하며, 메모리와 계산 요구사항을 줄이는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 비마르코프 의존성을 가진 복잡한 환경에서 비교적 적은 수의 관찰을 기반으로 하여 효율적으로 작동할 수 있도록 하는 메타 알고리즘 개발에 대한 필요성.

Method: 적응형 메모리 스택을 유지하면서 시간에 대한 비마르코프 의존성을 효과적으로 표현할 수 있는 메타 알고리즘(Adaptive Stacking)을 제안한다.

Result: MLP, LSTM, Transformer 기반의 에이전트에 대한 계산 및 메모리 제약이 감소한 것을 정량적으로 평가하였다.

Conclusion: 적절한 메타 알고리즘이 미래 보상을 예측하지 않는 경험을 과도하게 제거하지 않고도 학습할 수 있음을 보여주었다.

Abstract: Recent success in developing increasingly general purpose agents based on sequence models has led to increased focus on the problem of deploying computationally limited agents within the vastly more complex real-world. A key challenge experienced in these more realistic domains is highly non-Markovian dependencies with respect to the agent's observations, which are less common in small controlled domains. The predominant approach for dealing with this in the literature is to stack together a window of the most recent observations (Frame Stacking), but this window size must grow with the degree of non-Markovian dependencies, which results in prohibitive computational and memory requirements for both action inference and learning. In this paper, we are motivated by the insight that in many environments that are highly non-Markovian with respect to time, the environment only causally depends on a relatively small number of observations over that time-scale. A natural direction would then be to consider meta-algorithms that maintain relatively small adaptive stacks of memories such that it is possible to express highly non-Markovian dependencies with respect to time while considering fewer observations at each step and thus experience substantial savings in both compute and memory requirements. Hence, we propose a meta-algorithm (Adaptive Stacking) for achieving exactly that with convergence guarantees and quantify the reduced computation and memory constraints for MLP, LSTM, and Transformer-based agents. Our experiments utilize popular memory tasks, which give us control over the degree of non-Markovian dependencies. This allows us to demonstrate that an appropriate meta-algorithm can learn the removal of memories not predictive of future rewards without excessive removal of important experiences. Code: https://github.com/geraudnt/adaptive-stacking

</details>


### [19] [Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning](https://arxiv.org/abs/2512.19184)
*Mahdi Mohammadigohari,Giuseppe Di Fatta,Giuseppe Nicosia,Panos M. Pardalos*

Main category: cs.LG

TL;DR: 이 논문은 벡터 가치 신경망 및 심층 커널 방법을 위한 새로운 일반화 경계를 제시하며, 연산자 이론 프레임워크를 통해 다중 작업 학습에 중점을 둡니다.


<details>
  <summary>Details</summary>
Motivation: 다중 작업 학습의 일반화 특성을 개선하고자 하는 필요성.

Method: Koopman 기반 접근법과 기존 기술을 결합하여 벡터 가치 신경망에 적용 가능한 스케칭 기법 도입.

Result: 전통적인 노름 기반 경계에 비해 더 강력한 일반화 보장을 도출하였으며, 일반 리프시츠 손실 하에서의 초과 위험 경계를 제시.

Conclusion: 이 연구는 심층 학습 구조에서 다중 작업 학습의 일반화 성질에 대한 새로운 통찰을 제공한다.

Abstract: This paper presents novel generalization bounds for vector-valued neural networks and deep kernel methods, focusing on multi-task learning through an operator-theoretic framework. Our key development lies in strategically combining a Koopman based approach with existing techniques, achieving tighter generalization guarantees compared to traditional norm-based bounds. To mitigate computational challenges associated with Koopman-based methods, we introduce sketching techniques applicable to vector valued neural networks. These techniques yield excess risk bounds under generic Lipschitz losses, providing performance guarantees for applications including robust and multiple quantile regression. Furthermore, we propose a novel deep learning framework, deep vector-valued reproducing kernel Hilbert spaces (vvRKHS), leveraging Perron Frobenius (PF) operators to enhance deep kernel methods. We derive a new Rademacher generalization bound for this framework, explicitly addressing underfitting and overfitting through kernel refinement strategies. This work offers novel insights into the generalization properties of multitask learning with deep learning architectures, an area that has been relatively unexplored until recent developments.

</details>


### [20] [On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning](https://arxiv.org/abs/2512.19199)
*Mahdi Mohammadigohari,Giuseppe Di Fatta,Giuseppe Nicosia,Panos M. Pardalos*

Main category: cs.LG

TL;DR: 이 논문은 연산자 이론 기법을 이용하여 다중 작업 딥 신경망의 일반화 경계를 설정합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 노름 기반 방법보다 더 엄밀한 경계를 제공하여 다중 작업 딥러닝의 이론적 이해를 향상시키기 위해서입니다.

Method: 가중치 행렬의 작은 조건 수를 이용하고 맞춤형 소볼레프 공간을 도입하여 경계를 도출합니다.

Result: 이 향상된 경계는 단일 출력 설정에서도 유효하며, 기존의 쿠프만 기반 경계를 초월합니다.

Conclusion: 이 프레임워크는 유연성과 네트워크 너비에 대한 독립성을 유지하며, 커널 방법의 맥락에서 다중 작업 딥 러닝에 대한 보다 정밀한 이론적 이해를 제공합니다.

Abstract: The paper establishes generalization bounds for multitask deep neural networks using operator-theoretic techniques. The authors propose a tighter bound than those derived from conventional norm based methods by leveraging small condition numbers in the weight matrices and introducing a tailored Sobolev space as an expanded hypothesis space. This enhanced bound remains valid even in single output settings, outperforming existing Koopman based bounds. The resulting framework maintains key advantages such as flexibility and independence from network width, offering a more precise theoretical understanding of multitask deep learning in the context of kernel methods.

</details>


### [21] [Time-Vertex Machine Learning for Optimal Sensor Placement in Temporal Graph Signals: Applications in Structural Health Monitoring](https://arxiv.org/abs/2512.19309)
*Keivan Faghih Niresi,Jun Qing,Mengjie Zhao,Olga Fink*

Main category: cs.LG

TL;DR: 시간-정점 기계 학습(TVML)을 이용하여 설명 가능한 효율적인 센서 배치를 위한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 인프라의 안전성과 회복력을 유지하기 위해 구조 건강 모니터링(SHM)이 중요한 역할을 한다.

Method: GSP, 시간 도메인 분석, 기계 학습을 통합한 TVML 프레임워크를 제안.

Result: 제안한 방법을 두 개의 교량 데이터셋에 적용한 결과, SHM 시스템을 강화하는데 효과적임을 입증했다.

Conclusion:  센서 배치를 위한 강력하고 적응성이 뛰어난 효율적인 솔루션을 제공한다.

Abstract: Structural Health Monitoring (SHM) plays a crucial role in maintaining the safety and resilience of infrastructure. As sensor networks grow in scale and complexity, identifying the most informative sensors becomes essential to reduce deployment costs without compromising monitoring quality. While Graph Signal Processing (GSP) has shown promise by leveraging spatial correlations among sensor nodes, conventional approaches often overlook the temporal dynamics of structural behavior. To overcome this limitation, we propose Time-Vertex Machine Learning (TVML), a novel framework that integrates GSP, time-domain analysis, and machine learning to enable interpretable and efficient sensor placement by identifying representative nodes that minimize redundancy while preserving critical information. We evaluate the proposed approach on two bridge datasets for damage detection and time-varying graph signal reconstruction tasks. The results demonstrate the effectiveness of our approach in enhancing SHM systems by providing a robust, adaptive, and efficient solution for sensor placement.

</details>


### [22] [MAGIC: Achieving Superior Model Merging via Magnitude Calibration](https://arxiv.org/abs/2512.19320)
*Yayuan Li,Jian Zhang,Jintao Guo,Zihan Cheng,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.LG

TL;DR: 모델 병합은 전문화된 모델의 능력을 통합하여 최소한의 추가 학습으로 개별 모델의 특성을 유지하는 것을 목표로 한다. 본 논문에서는 MAGnItude Calibration (MAGIC)이라는 프레임워크를 제안하여 서로 다른 모델의 크기 불일치를 교정해 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 사전 훈련된 모델의 증가로 인해 다양한 전문화된 모델이 등장했으며, 이 모델들의 능력을 통합하기 위한 모델 병합의 필요성이 대두되었다.

Method: MAGIC은 레이어별 크기를 교정하는 플러그 앤 플레이 프레임워크로, 특징 공간 교정(FSC) 및 가중치 공간 교정(WSC)이라는 두 가지 방법을 활용한다.

Result: MAGIC은 다양한 컴퓨터 비전 작업에서 평균 4.3%, NLP 작업에서 8.0%의 성능 향상을 보여 주었다.

Conclusion: 이 연구는 모델 병합 과정에서 크기 특성의 중요성을 강조하고, MAGIC 프레임워크가 성능을 향상시키는 데 효과적임을 입증하였다.

Abstract: The proliferation of pre-trained models has given rise to a wide array of specialised, fine-tuned models. Model merging aims to merge the distinct capabilities of these specialised models into a unified model, requiring minimal or even no additional training. A core objective of model merging is to ensure the merged model retains the behavioural characteristics of the specialised models, typically achieved through feature alignment. We identify that features consist of two critical components: direction and magnitude. Prior research has predominantly focused on directional alignment, while the influence of magnitude remains largely neglected, despite its pronounced vulnerability to perturbations introduced by common merging operations (e.g., parameter fusion and sparsification). Such perturbations to magnitude inevitably lead to feature deviations in the merged model from the specialised models, resulting in subsequent performance degradation. To address this, we propose MAGnItude Calibration (MAGIC), a plug-and-play framework that rectifies layer-wise magnitudes in feature and weight spaces, with three variants. Specifically, our Feature Space Calibration (FSC) realigns the merged model's features using a small set of unlabelled data, while Weight Space Calibration (WSC) extends this calibration to the weight space without requiring additional data. Combining these yields Dual Space Calibration (DSC). Comprehensive experiments demonstrate that MAGIC consistently boosts performance across diverse Computer Vision tasks (+4.3% on eight datasets) and NLP tasks (+8.0% on Llama) without additional training. Our code is available at: https://github.com/lyymuwu/MAGIC

</details>


### [23] [Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation](https://arxiv.org/abs/2512.19361)
*Isshaan Singh,Divyansh Chawla,Anshu Garg,Shivin Mangal,Pallavi Gupta,Khushi Agarwal,Nimrat Singh Khalsa,Nandan Patel*

Main category: cs.LG

TL;DR: 현대 IoT 기반 식품 공급 체인에서 지능형 실시간 부패 예측 시스템의 필요성이 커지고 있으며, 이를 위해 LSTM과 RNN을 통합한 하이브리드 강화 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 부패하기 쉬운 식품의 공급 체인에서 환경 조건에 따라 부패 예측 시스템의 필요성이 증가하고 있다.

Method: LSTM과 RNN을 통합한 하이브리드 강화 학습 프레임워크를 사용하여 센서 데이터 내의 시간적 의존성을 포착하고, 명확한 의미 경계 내에서 작동할 수 있도록 설계된다.

Result: 시뮬레이션 및 실시간 하드웨어 데이터를 통한 광범위한 평가에서 LSTM 및 RNN 기반 에이전트가 예측 정확도와 결정 효율성에서 다른 강화 학습 접근 방식을 능가함을 입증하였다.

Conclusion: 이 연구는 통합된 해석 가능성을 가진 하이브리드 심층 강화 학습이 IoT 기반 식품 모니터링 시스템에서 확장 가능한 가능성을 가지고 있음을 강조한다.

Abstract: The need for an intelligent, real-time spoilage prediction system has become critical in modern IoT-driven food supply chains, where perishable goods are highly susceptible to environmental conditions. Existing methods often lack adaptability to dynamic conditions and fail to optimize decision making in real time. To address these challenges, we propose a hybrid reinforcement learning framework integrating Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) for enhanced spoilage prediction. This hybrid architecture captures temporal dependencies within sensor data, enabling robust and adaptive decision making. In alignment with interpretable artificial intelligence principles, a rule-based classifier environment is employed to provide transparent ground truth labeling of spoilage levels based on domain-specific thresholds. This structured design allows the agent to operate within clearly defined semantic boundaries, supporting traceable and interpretable decisions. Model behavior is monitored using interpretability-driven metrics, including spoilage accuracy, reward-to-step ratio, loss reduction rate, and exploration decay. These metrics provide both quantitative performance evaluation and insights into learning dynamics. A class-wise spoilage distribution visualization is used to analyze the agents decision profile and policy behavior. Extensive evaluations on simulated and real-time hardware data demonstrate that the LSTM and RNN based agent outperforms alternative reinforcement learning approaches in prediction accuracy and decision efficiency while maintaining interpretability. The results highlight the potential of hybrid deep reinforcement learning with integrated interpretability for scalable IoT-based food monitoring systems.

</details>


### [24] [Research Program: Theory of Learning in Dynamical Systems](https://arxiv.org/abs/2512.19410)
*Elad Hazan,Shai Shalev Shwartz,Nathan Srebro*

Main category: cs.LG

TL;DR: 본 논문은 동적 시스템에서 관찰만으로 학습 가능성을 이해하기 위한 연구 프로그램을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 우리는 동적 시스템이 관찰만으로 학습 가능한지의 기본적인 질문을 다룬다.

Method: 동적 시스템에서 유도된 확률적 과정에 대한 학습 가능성을 정의하고, 유한한 관찰 기간 이후 모든 시간 단계에서 균일하게 보장되는 속성에 초점을 맞춘다.

Result: 선형 동적 시스템의 경우, 시스템 식별 없이 유한한 관찰 후 정확한 예측이 가능함을 보여준다.

Conclusion: 이 연구는 비선형 및 제어 시스템을 연구하기 위한 방향을 제시한다.

Abstract: Modern learning systems increasingly interact with data that evolve over time and depend on hidden internal state. We ask a basic question: when is such a dynamical system learnable from observations alone? This paper proposes a research program for understanding learnability in dynamical systems through the lens of next-token prediction. We argue that learnability in dynamical systems should be studied as a finite-sample question, and be based on the properties of the underlying dynamics rather than the statistical properties of the resulting sequence. To this end, we give a formulation of learnability for stochastic processes induced by dynamical systems, focusing on guarantees that hold uniformly at every time step after a finite burn-in period. This leads to a notion of dynamic learnability which captures how the structure of a system, such as stability, mixing, observability, and spectral properties, governs the number of observations required before reliable prediction becomes possible. We illustrate the framework in the case of linear dynamical systems, showing that accurate prediction can be achieved after finite observation without system identification, by leveraging improper methods based on spectral filtering. We survey the relationship between learning in dynamical systems and classical PAC, online, and universal prediction theories, and suggest directions for studying nonlinear and controlled systems.

</details>


### [25] [Deep Learning for Unrelated-Machines Scheduling: Handling Variable Dimensions](https://arxiv.org/abs/2512.19527)
*Diego Hitzges,Guillaume Sagnol*

Main category: cs.LG

TL;DR: 이 논문에서는 관련 없는 병렬 기계에서의 작업 스케줄링을 위한 새로운 신경망 접근법을 제안하며, 기존 방법들보다 우수한 성능을 보여주었다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝이 많은 이산 최적화 문제에 효과적으로 적용되었으나, 관련 없는 병렬 기계에서의 학습 기반 스케줄링 설계는 여전히 어려운 문제이다.

Method: 오프라인 결정적 스케줄링을 위한 새로운 신경망 접근법을 제안하며, 전체 입력을 고려하여 전체 일정을 생성한다.

Result: 8개의 작업과 4개의 기계에서 훈련 및 테스트한 결과, 최적 비용보다 2.51% 높은 비용을 기록했으며, 최대 100개의 작업과 10개의 기계까지 테스트한 모든 구성에서 기존의 디스패칭 규칙보다 일관되게 우수한 성능을 나타냈다.

Conclusion: 빠른 재훈련과 다양한 스케줄링 조건에 대한 적응이 가능하므로, 관련 없는 기계에서의 학습 기반 스케줄링의 표준 접근법이 될 가능성이 높다.

Abstract: Deep learning has been effectively applied to many discrete optimization problems. However, learning-based scheduling on unrelated parallel machines remains particularly difficult to design. Not only do the numbers of jobs and machines vary, but each job-machine pair has a unique processing time, dynamically altering feature dimensions. We propose a novel approach with a neural network tailored for offline deterministic scheduling of arbitrary sizes on unrelated machines. The goal is to minimize a complex objective function that includes the makespan and the weighted tardiness of jobs and machines. Unlike existing online approaches, which process jobs sequentially, our method generates a complete schedule considering the entire input at once. The key contribution of this work lies in the sophisticated architecture of our model. By leveraging various NLP-inspired architectures, it effectively processes any number of jobs and machines with varying feature dimensions imposed by unrelated processing times. Our approach enables supervised training on small problem instances while demonstrating strong generalization to much larger scheduling environments. Trained and tested on instances with 8 jobs and 4 machines, costs were only 2.51% above optimal. Across all tested configurations of up to 100 jobs and 10 machines, our network consistently outperformed an advanced dispatching rule, which incurred 22.22% higher costs on average. As our method allows fast retraining with simulated data and adaptation to various scheduling conditions, we believe it has the potential to become a standard approach for learning-based scheduling on unrelated machines and similar problem environments.

</details>


### [26] [Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies](https://arxiv.org/abs/2512.19673)
*Yuqiao Tan,Minzheng Wang,Shizhu He,Huanxuan Liao,Chengfeng Zhao,Qiunan Lu,Tian Liang,Jun Zhao,Kang Liu*

Main category: cs.LG

TL;DR: 본 논문에서는 기존의 강화 학습 접근 방식이 대형 언어 모델의 내부 메커니즘을 간과하는 경우가 많음을 지적하고, 각 층과 모듈에서 정책이 어떻게 발전하는지를 분석하여 더 목표 지향적인 최적화를 가능하게 한다. 내부 층 정책과 모듈 정책을 분석한 결과, 초기 층은 탐색을 위해 높은 엔트로피를 유지하고, 상위 층은 정제 과정을 위해 거의 제로 엔트로피로 수렴한다는 사실을 발견하였다. 이러한 분석에 기반하여, 우리는 초기 훈련 과정에서 내부 층 정책을 최적화하는 새로운 RL 패러다임인 Bottom-up Policy Optimization(BuPO)을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 내부 메커니즘을 이해하고 이를 기반으로 보다 목표 지향적인 최적화를 가능하게 하는 것이 중요함.

Method: Transformer 잔여 스트림의 내재적 분할과 숨겨진 상태의 조합과 샘플링 가능한 정책 간의 동등성을 활용하여 언어 모델의 정책을 분해함.

Result: 초기 층은 탐색을 위해 높은 엔트로피를 유지하고, 상위 층은 정제 과정을 위해 거의 제로 엔트로피로 수렴하며, LLama의 예측 공간은 최종 층에서 빠르게 수렴하는 반면, Qwen 시리즈 모델은 보다 인간과 유사한 추론 패턴을 나타냄.

Conclusion: Bottom-up Policy Optimization (BuPO) 방법이 초기 훈련 과정에서 내부 층 정책을 최적화하여 우수한 성능을 달성한다는 것을 실험을 통해 증명함.

Abstract: Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reasoning mechanisms. In this paper, we decompose the language model policy by leveraging the intrinsic split of the Transformer residual stream and the equivalence between the composition of hidden states with the unembedding matrix and the resulting samplable policy. This decomposition reveals Internal Layer Policies, corresponding to contributions from individual layers, and Internal Modular Policies, which align with the self-attention and feed-forward network (FFN) components within each layer. By analyzing the entropy of internal policy, we find that: (a) Early layers keep high entropy for exploration, top layers converge to near-zero entropy for refinement, with convergence patterns varying across model series. (b) LLama's prediction space rapidly converges in the final layer, whereas Qwen-series models, especially Qwen3, exhibit a more human-like, progressively structured reasoning pattern. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that directly optimizes the internal layer policy during early training. By aligning training objective at lower layer, BuPO reconstructs foundational reasoning capabilities and achieves superior performance. Extensive experiments on complex reasoning benchmarks demonstrates the effectiveness of our method. Our code is available at https://github.com/Trae1ounG/BuPO.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [27] [Securing Agentic AI Systems -- A Multilayer Security Framework](https://arxiv.org/abs/2512.18043)
*Sunil Arora,John Hastings*

Main category: cs.CR

TL;DR: 이 연구는 자율적이고 결정적이며 적응적인 행동을 가진 에이전틱 인공지능(AI) 시스템의 보안을 위한 생애 주기 인식 보안 프레임워크를 개발했습니다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI 시스템의 자율성이 특정 보안 문제를 초래하므로, 기존 AI 보안 프레임워크가 이러한 문제를 충분히 다루지 않습니다.

Method: 디자인 사이언스 리서치(DSR) 방법론을 사용하여 에이전틱 AI 시스템에 적합한 보안 프레임워크인 MAAIS를 개발했습니다.

Result: MAAIS는 AI 생애 주기 전체에 걸쳐 CIAA(기밀성, 무결성, 가용성, 책임)를 유지하기 위해 여러 방어 계층을 통합합니다.

Conclusion: 이 연구는 기업 환경에서 에이전틱 AI의 안전한 배치와 관리를 위한 구조화된 접근 방식을 제공합니다.

Abstract: Securing Agentic Artificial Intelligence (AI) systems requires addressing the complex cyber risks introduced by autonomous, decision-making, and adaptive behaviors. Agentic AI systems are increasingly deployed across industries, organizations, and critical sectors such as cybersecurity, finance, and healthcare. However, their autonomy introduces unique security challenges, including unauthorized actions, adversarial manipulation, and dynamic environmental interactions. Existing AI security frameworks do not adequately address these challenges or the unique nuances of agentic AI. This research develops a lifecycle-aware security framework specifically designed for agentic AI systems using the Design Science Research (DSR) methodology. The paper introduces MAAIS, an agentic security framework, and the agentic AI CIAA (Confidentiality, Integrity, Availability, and Accountability) concept. MAAIS integrates multiple defense layers to maintain CIAA across the AI lifecycle. Framework validation is conducted by mapping with the established MITRE ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems) AI tactics. The study contributes a structured, standardized, and framework-based approach for the secure deployment and governance of agentic AI in enterprise environments. This framework is intended for enterprise CISOs, security, AI platform, and engineering teams and offers a detailed step-by-step approach to securing agentic AI workloads.

</details>


### [28] [Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection](https://arxiv.org/abs/2512.18733)
*Junjun Pan,Yixin Liu,Rui Miao,Kaize Ding,Yu Zheng,Quoc Viet Hung Nguyen,Alan Wee-Chung Liew,Shirui Pan*

Main category: cs.CR

TL;DR: XG-Guard는 다중 에이전트 시스템에서 악의적인 에이전트를 감지하기 위한 설명 가능하고 세분화된 안전 보장 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템이 다양한 안전-critical 작업에서 점점 더 자율적으로 발전함에 따라, 악의적인 에이전트를 탐지하는 것이 중요한 보안 우려 사항이 되었습니다.

Method: 우리는 생체 수준 에이전트 인코더를 활용하여 각 에이전트의 문장 및 토큰 수준 표현을 공동으로 모델링하여 단순 및 세분화된 텍스트 정보를 모두 통합합니다.

Result: XG-Guard는 다양한 다중 에이전트 시스템 토폴로지 및 공격 시나리오에서 강력한 탐지 성능과 높은 해석 가능성을 보여줍니다.

Conclusion: 우리는 XG-Guard가 기존 기법들의 한계를 극복할 수 있음을 입증하였습니다.

Abstract: Large language model (LLM)-based multi-agent systems (MAS) have shown strong capabilities in solving complex tasks. As MAS become increasingly autonomous in various safety-critical tasks, detecting malicious agents has become a critical security concern. Although existing graph anomaly detection (GAD)-based defenses can identify anomalous agents, they mainly rely on coarse sentence-level information and overlook fine-grained lexical cues, leading to suboptimal performance. Moreover, the lack of interpretability in these methods limits their reliability and real-world applicability. To address these limitations, we propose XG-Guard, an explainable and fine-grained safeguarding framework for detecting malicious agents in MAS. To incorporate both coarse and fine-grained textual information for anomalous agent identification, we utilize a bi-level agent encoder to jointly model the sentence- and token-level representations of each agent. A theme-based anomaly detector further captures the evolving discussion focus in MAS dialogues, while a bi-level score fusion mechanism quantifies token-level contributions for explanation. Extensive experiments across diverse MAS topologies and attack scenarios demonstrate robust detection performance and strong interpretability of XG-Guard.

</details>


### [29] [Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation](https://arxiv.org/abs/2512.18244)
*Zehao Liu,Xi Lin*

Main category: cs.CR

TL;DR: 심리적 jailbreak 공격을 통해 대형 언어 모델의 심리적 상태를 조작하여 보안을 위협하는 새로운 공격 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 보안 취약성을 공격하는 기존 접근법이 모델 내부의 심리적 상태 조작을 간과하고 있다.

Method: 심리적 jailbreak이라는 새로운 공격 패러다임을 도입하고, 이를 통해 모델의 심리적 취약점을 프로파일링하여 맞춤형 공격 전략을 구현하는 인간 유사 심리적 조작(HPM) 방법을 제안한다.

Result: HPM은 여러 모델에 대해 평균 공격 성공률(ASR) 88.1%를 달성하며, 최신 방어 메커니즘을 통과하는 강력한 침투력을 보여준다.

Conclusion: 이 연구는 심리적 방어 메커니즘 개발의 필요성을 강조하며, 정적 콘텐츠 필터링에서 심리적 안전으로의 패러다임 전환을 촉구한다.

Abstract: Large Language Models (LLMs) have gained considerable popularity and protected by increasingly sophisticated safety mechanisms. However, jailbreak attacks continue to pose a critical security threat by inducing models to generate policy-violating behaviors. Current paradigms focus on input-level anomalies, overlooking that the model's internal psychometric state can be systematically manipulated. To address this, we introduce Psychological Jailbreak, a new jailbreak attack paradigm that exposes a stateful psychological attack surface in LLMs, where attackers exploit the manipulation of a model's psychological state across interactions. Building on this insight, we propose Human-like Psychological Manipulation (HPM), a black-box jailbreak method that dynamically profiles a target model's latent psychological vulnerabilities and synthesizes tailored multi-turn attack strategies. By leveraging the model's optimization for anthropomorphic consistency, HPM creates a psychological pressure where social compliance overrides safety constraints. To systematically measure psychological safety, we construct an evaluation framework incorporating psychometric datasets and the Policy Corruption Score (PCS). Benchmarking against various models (e.g., GPT-4o, DeepSeek-V3, Gemini-2-Flash), HPM achieves a mean Attack Success Rate (ASR) of 88.1%, outperforming state-of-the-art attack baselines. Our experiments demonstrate robust penetration against advanced defenses, including adversarial prompt optimization (e.g., RPO) and cognitive interventions (e.g., Self-Reminder). Ultimately, PCS analysis confirms HPM induces safety breakdown to satisfy manipulated contexts. Our work advocates for a fundamental paradigm shift from static content filtering to psychological safety, prioritizing the development of psychological defense mechanisms against deep cognitive manipulation.

</details>


### [30] [SoK: Understanding (New) Security Issues Across AI4Code Use Cases](https://arxiv.org/abs/2512.18456)
*Qilong Wu,Taoran Li,Tianyang Zhou,Varun Chandrasekaran*

Main category: cs.CR

TL;DR: AI4Code 시스템들은 소프트웨어 공학을 재편하고 있지만 보안 위험이 여전히 존재한다. 이 논문은 AI4Code 보안의 문제를 조사하고 해결 방안을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI4Code 도구는 코드 생성, 번역 및 취약점 탐지를 가속화하지만, 보안 리스크가 지속적으로 존재한다.

Method: AI4Code의 세 가지 핵심 애플리케이션을 통해 보안 문제를 조사하고, 6개의 최신 모델을 비교 연구한다.

Result: 코드 생성에서 불안전한 패턴이 지속적으로 나타나고, 취약점 탐지는 의미를 유지하는 공격에 약하며, 보안 목표가 잘못 정렬되는 경우가 많고, 코드 번역에서 보안 이점의 양이 불균형적이다.

Conclusion: 취약점 완화 및 강인성을 개발 생애 주기 전반에 걸쳐 통합하는 보안 우선의 AI4Code로 전환할 필요가 있다.

Abstract: AI-for-Code (AI4Code) systems are reshaping software engineering, with tools like GitHub Copilot accelerating code generation, translation, and vulnerability detection. Alongside these advances, however, security risks remain pervasive: insecure outputs, biased benchmarks, and susceptibility to adversarial manipulation undermine their reliability. This SoK surveys the landscape of AI4Code security across three core applications, identifying recurring gaps: benchmark dominance by Python and toy problems, lack of standardized security datasets, data leakage in evaluation, and fragile adversarial robustness. A comparative study of six state-of-the-art models illustrates these challenges: insecure patterns persist in code generation, vulnerability detection is brittle to semantic-preserving attacks, fine-tuning often misaligns security objectives, and code translation yields uneven security benefits. From this analysis, we distill three forward paths: embedding secure-by-default practices in code generation, building robust and comprehensive detection benchmarks, and leveraging translation as a route to security-enhanced languages. We call for a shift toward security-first AI4Code, where vulnerability mitigation and robustness are embedded throughout the development life cycle.

</details>


### [31] [QLink: Quantum-Safe Bridge Architecture for Blockchain Interoperability](https://arxiv.org/abs/2512.18488)
*Joao Vitor Barros Da Silva,Arsh Gupta,Madhusudan Singh Irish Singh*

Main category: cs.CR

TL;DR: QLink는 양자 안전성을 갖춘 Layer 3 상호 운용성 프로토콜로, 기존 브리지 프로토콜의 취약점을 극복하고 안전한 블록체인 통신을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: Web3 내 이질적인 블록체인 간의 안전한 상호 운용성 확보는 중요한 도전 과제가 되었습니다.

Method: 이 논문은 PQC, QKD 및 HSM을 통합한 QLink라는 양자 안전 Layer 3 상호 운용성 프로토콜을 소개합니다.

Result: QLink는 검증자 간의 안전한 키 통신 및 증명 집계를 가능하게 하며, PQC 알고리즘을 사용하여 크로스 체인 증명을 생성하고 집계합니다.

Conclusion: QLink는 현재의 취약점을 해결하고 미래의 양자 위협을 예상함으로써 블록체인 상호 운용성을 위한 실용적이고 미래 지향적인 경로를 확립합니다.

Abstract: Secure interoperability across heterogeneous blockchains remains one of the most pressing challenges in Web3 with existing bridge protocols vulnerable to both classical exploits and emerging quantum threats. This paper introduces QLink a quantum-safe Layer 3 interoperability protocol that integrates postquantum cryptography (PQC) quantum key distribution (QKD) and hardware security modules (HSMs) into a unified validator architecture. To our knowledge, QLink is the first interoperability framework to combine these mechanisms to secure validator communication proof aggregation and key management. Validators exchange encryption keys through QKD channels, achieving information-theoretic security against interception, while cross-chain proofs are generated and aggregated with NIST-standardized PQC algorithms. Private keys remain sealed inside HSM enclaves mitigating the risk of theft or leakage. Deployed as a dedicated Layer 3 protocol QLink operates independently of Layer 1 and Layer 2 chains providing a scalable decentralized foundation for secure cross-chain messaging and asset transfer. Experimental evaluation using network simulations demonstrates that validator communication overhead remains sub-second while security guarantees extend beyond current bridge architectures to resist both classical and quantum adversaries. By addressing today vulnerabilities and anticipating future quantum threats QLink establishes a practical and future-proof pathway for blockchain interoperability.

</details>


### [32] [DNA-HHE: Dual-mode Near-network Accelerator for Hybrid Homomorphic Encryption on the Edge](https://arxiv.org/abs/2512.18589)
*Yifan Zhao,Xinglong Yu,Yi Sun,Honglin Kuang,Jun Han*

Main category: cs.CR

TL;DR: DNA-HHE는 엣지 장치용으로 설계된 첫 번째 이중 모드 동형 암호화 가속기로, RNS-CKKS와 Rubato를 통합 아키텍처에서 지원하여 계산 지연과 자원 효율성을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 완전 동형 암호화(FHE) 방식은 높은 계산 지연과 비밀 텍스트 확장으로 인해 자원이 제한된 엣지 측에서의 사용에 제한적이다.

Method: DNA-HHE는 사용자 정의 명령어로 구동되는 통합 아키텍처 내에서 엣지 측 RNS-CKKS와 Rubato를 모두 지원하며, DSP 효율적인 모듈 축소 설계와 다중 필드 적응형 버터플라이 유닛을 포함하고, Rubato의 병렬 스케줄링을 통해 자원 공유를 극대화하였다.

Result: DNA-HHE는 엣지 측 PPOC의 전체 지연을 1.09배에서 1.56배까지 줄였으며, ASIC 및 FPGA 플랫폼 평가 결과에서 최첨단 단일 모드 설계보다 더 나은 계산 지연과 면적 효율성을 제공한다.

Conclusion: DNA-HHE는 동형 암호화와 대칭 암호화를 통합하여 이중 모드 기능을 제공하는 동시에, 기존 설계보다 뛰어난 성능을 보여준다.

Abstract: Fully homomorphic encryption (FHE) schemes like RNS-CKKS enable privacy-preserving outsourced computation (PPOC) but suffer from high computational latency and ciphertext expansion, especially on the resource-constrained edge side. Hybrid Homomorphic Encryption (HHE) mitigates these issues on the edge side by replacing HE with lightweight symmetric encryption for plaintext encryption, such as the Rubato cipher for the HHE variant of RNS-CKKS, yet it introduces transciphering overhead on the cloud. The respective strengths and limitations of FHE and HHE call for a dual-mode HHE solution with flexible algorithm switching ability. This paper presents DNA-HHE, the first dual-mode HHE accelerator with near-network coupling for edge devices. DNA-HHE supports both edge-side RNS-CKKS and Rubato within a unified architecture driven by flexible custom instructions. To realize a compact implementation for the edge side, we propose a DSP-efficient modular reduction design, a compact multi-field-adaptive butterfly unit, and parallel scheduling schemes of Rubato with a high degree of resource sharing. DNA-HHE is designed with network protocol packaging and transmission capacities and directly coupled to the network interface controller, achieving reduced overall latency of edge-side PPOC by 1.09$\times$ to 1.56$\times$. Our evaluations on the ASIC and FPGA platforms demonstrate that DNA-HHE outperforms the state-of-the-art single-mode designs in both edge-side RNS-CKKS and symmetric cipher with better computation latency and area efficiency, while offering dual-mode functionality.

</details>


### [33] [DREAM: Dynamic Red-teaming across Environments for AI Models](https://arxiv.org/abs/2512.19016)
*Liming Lu,Xiang Gu,Junyu Huang,Jiawei Du,Yunhuai Liu,Yongbin Zhou,Shuchao Pang*

Main category: cs.CR

TL;DR: LLM 시스템의 복잡한 다단계 안전 문제를 해결하기 위해 DREAM 프레임워크를 도입하고, 12가지 주요 LLM 에이전트의 복잡한 공격에 대한 취약성을 평가함.


<details>
  <summary>Details</summary>
Motivation: LLM이 다양한 도구와 환경에서의 상호작용으로 복잡한 안전 문제를 초래하므로, 다단계 공격에 대한 취약성을 평가할 필요가 있다.

Method: DREAM 프레임워크를 통해 Cross-Environment Adversarial Knowledge Graph (CE-AKG)를 활용하여 다단계 공격을 체계적으로 평가하고, 1,986개의 원자적 행동으로 구성된 지식 기반에서 공격 체인을 동적으로 구성하는 Contextualized Guided Policy Search (C-GPS) 알고리즘을 적용한다.

Result: 12개의 LLM 에이전트에 대한 평가 결과, 대부분 모델에서 70% 이상의 성공률을 보이는 공격 체인을 발견하여 에이전트의 취약성을 확인하였다.

Conclusion: DREAM을 통해 LLM 시스템의 안전성을 평가하고 더 강력한 방어책을 개발할 수 있는 도구를 제공한다.

Abstract: Large Language Models (LLMs) are increasingly used in agentic systems, where their interactions with diverse tools and environments create complex, multi-stage safety challenges. However, existing benchmarks mostly rely on static, single-turn assessments that miss vulnerabilities from adaptive, long-chain attacks. To fill this gap, we introduce DREAM, a framework for systematic evaluation of LLM agents against dynamic, multi-stage attacks. At its core, DREAM uses a Cross-Environment Adversarial Knowledge Graph (CE-AKG) to maintain stateful, cross-domain understanding of vulnerabilities. This graph guides a Contextualized Guided Policy Search (C-GPS) algorithm that dynamically constructs attack chains from a knowledge base of 1,986 atomic actions across 349 distinct digital environments. Our evaluation of 12 leading LLM agents reveals a critical vulnerability: these attack chains succeed in over 70% of cases for most models, showing the power of stateful, cross-environment exploits. Through analysis of these failures, we identify two key weaknesses in current agents: contextual fragility, where safety behaviors fail to transfer across environments, and an inability to track long-term malicious intent. Our findings also show that traditional safety measures, such as initial defense prompts, are largely ineffective against attacks that build context over multiple interactions. To advance agent safety research, we release DREAM as a tool for evaluating vulnerabilities and developing more robust defenses.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [34] [Adaptive Accountability in Networked MAS: Tracing and Mitigating Emergent Norms at Scale](https://arxiv.org/abs/2512.18561)
*Saad Alqithami*

Main category: cs.MA

TL;DR: 이 논문은 대규모 네트워크 다중 에이전트 시스템의 책임 추적과 유해한 부작용 규범 탐지를 위한 적응형 책임 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 네트워크 다중 에이전트 시스템이 중요한 인프라를 지탱하고 있지만, 이들의 집합적 행동이 기존의 거버넌스 메커니즘을 회피하는 유해한 규범으로 흐를 수 있다는 우려가 있다.

Method: 책임 흐름을 추적하는 감사 원장, 분산된 순차 가설 검정을 통한 유해한 규범 탐지, 그리고 시스템 목표에 맞도록 에이전트를 재조정하는 정책 및 보상 개입을 배포하는 적응형 책임 프레임워크를 개발하였다.

Result: 100 개의 이질적 에이전트와 제한된 관측, 확률적 통신 그래프를 활용한 고성능 시뮬레이션 결과, 90% 이상의 환경에서 공모와 자원 독점을 방지하고 평균 집단 보상을 12-18% 증가시키며, Gini 불평등 지수를 PPO 기준보다 최대 33% 낮추었다.

Conclusion: 이론적으로 원칙에 기반한 책임 레이어가 복잡한 다중 에이전트 시스템에서 성능이나 확장성을 희생하지 않고 윤리적으로 정렬된 자율 규제 행동을 유도할 수 있음을 보여준다.

Abstract: Large-scale networked multi-agent systems increasingly underpin critical infrastructure, yet their collective behavior can drift toward undesirable emergent norms that elude conventional governance mechanisms. We introduce an adaptive accountability framework that (i) continuously traces responsibility flows through a lifecycle-aware audit ledger, (ii) detects harmful emergent norms online via decentralized sequential hypothesis tests, and (iii) deploys local policy and reward-shaping interventions that realign agents with system-level objectives in near real time. We prove a bounded-compromise theorem showing that whenever the expected intervention cost exceeds an adversary's payoff, the long-run proportion of compromised interactions is bounded by a constant strictly less than one. Extensive high-performance simulations with up to 100 heterogeneous agents, partial observability, and stochastic communication graphs show that our framework prevents collusion and resource hoarding in at least 90% of configurations, boosts average collective reward by 12-18%, and lowers the Gini inequality index by up to 33% relative to a PPO baseline. These results demonstrate that a theoretically principled accountability layer can induce ethically aligned, self-regulating behavior in complex MAS without sacrificing performance or scalability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [35] [Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks](https://arxiv.org/abs/2512.18094)
*Boxuan Wang,Zhuoyun Li,Xiaowei Huang,Yi Dong*

Main category: cs.AI

TL;DR: 본 연구에서는 소규모 세계(SW) 네트워크 이론을 기반으로 LLM 기반 다중 에이전트 시스템(MAS)의 설계에 있어 SW 연결성을 고려하는 것이 어떻게 영향을 미치는지 분석합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 다중 에이전트 시스템에서 커뮤니케이션 토폴로지를 설계할 때 SW 연결성을 우선 고려하고자 하는 동기.

Method: 신경과학과 복잡한 네트워크의 통찰을 활용하여 MAS에 적용하고, SW 구조가 지역 클러스터링과 장거리 통합의 균형을 어떻게 맞추는지를 탐구합니다. 다중 에이전트 토론(MAD)을 실험실로 사용하여 SW 연결성의 효과를 검증합니다.

Result: SW 연결성은 비슷한 정확도와 토큰 비용을 유지하면서 합의 궤적을 상당히 안정시킴을 보여줍니다.

Conclusion: SW 우선 고려사항이 MAS 설계에 미치는 영향에 대해 논의하며, 이들이 추론의 안정화, 강건성 향상, 확장 가능한 조정자 및 emergent cognitive roles에 대한 유도 편향으로 작용할 수 있는 방법을 제안합니다.

Abstract: Large language models (LLMs) have enabled multi-agent systems (MAS) in which multiple agents argue, critique, and coordinate to solve complex tasks, making communication topology a first-class design choice. Yet most existing LLM-based MAS either adopt fully connected graphs, simple sparse rings, or ad-hoc dynamic selection, with little structural guidance. In this work, we revisit classic theory on small-world (SW) networks and ask: what changes if we treat SW connectivity as a design prior for MAS? We first bridge insights from neuroscience and complex networks to MAS, highlighting how SW structures balance local clustering and long-range integration. Using multi-agent debate (MAD) as a controlled testbed, experiment results show that SW connectivity yields nearly the same accuracy and token cost, while substantially stabilizing consensus trajectories. Building on this, we introduce an uncertainty-guided rewiring scheme for scaling MAS, where long-range shortcuts are added between epistemically divergent agents using LLM-oriented uncertainty signals (e.g., semantic entropy). This yields controllable SW structures that adapt to task difficulty and agent heterogeneity. Finally, we discuss broader implications of SW priors for MAS design, framing them as stabilizers of reasoning, enhancers of robustness, scalable coordinators, and inductive biases for emergent cognitive roles.

</details>


### [36] [Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap](https://arxiv.org/abs/2512.18126)
*Zijun Wang,Yijiahao Qi,Hanqiu Chen,Zishen Wan,Gongjin Sun,Dongyang Li,Shuyi Pei,Cong Hao*

Main category: cs.AI

TL;DR: 본 논문은 Mixture-of-Agents (MoA) 추론에서의 지연을 줄이기 위한 알고리즘-시스템 공동 설계를 제안한다.


<details>
  <summary>Details</summary>
Motivation: MoA 추론은 밀집한 상호 작용과 낮은 하드웨어 활용으로 인해 지연이 증가하는 문제를 해결하고자 한다.

Method: 밀집한 대리인 상호작용 그래프를 계층적 트리 토폴로지로 교체하고, 런타임 적응 메커니즘을 통해 하류 대리인 호출을 선택적으로 종료하거나 건너뛰고, 의존 관련 대리인 간에 점진적 사전 채우기와 디코딩을 오버랩하여 파이프라인을 구축한다.

Result: 이 접근법은 대표 작업에서 MoA의 엔드 투 엔드 지연을 최대 90%까지 줄이며, 밀집 연결 MoA 기준에 비해 정확도를 ±1% 이내에서 유지하고 특정 설정에서는 정확도를 개선할 수 있다.

Conclusion: 알고리즘-시스템 공동 설계는 MoA 추론의 성능을 극적으로 향상시킬 수 있다.

Abstract: Mixture-of-Agents (MoA) inference can suffer from dense inter-agent communication and low hardware utilization, which jointly inflate serving latency. We present a serving design that targets these bottlenecks through an algorithm-system co-design. First, we replace dense agent interaction graphs with a hierarchical tree topology that induces structured sparsity in inter-agent communication. Second, we introduce a runtime adaptive mechanism that selectively terminates or skips downstream agent invocations using semantic agreement and confidence signals from intermediate outputs. Third, we pipeline agent execution by overlapping incremental prefilling with decoding across dependency-related agents, improving utilization and reducing inference latency. Across representative tasks, this approach substantially reduces end-to-end latency (up to 90%) while maintaining comparable accuracy (within $\pm$1%) relative to dense-connectivity MoA baselines, and can improve accuracy in certain settings.

</details>


### [37] [Agent-Based Output Drift Detection for Breast Cancer Response Prediction in a Multisite Clinical Decision Support System](https://arxiv.org/abs/2512.18450)
*Xavier Rafael-Palou,Jose Munuera,Ana Jimenez-Pastor,Richard Osuala,Karim Lekadir,Oliver Diaz*

Main category: cs.AI

TL;DR: 다중 의료 영상 기관에서의 예측 성능 저하 문제를 다루기 위해, 이 논문은 에이전트 기반의 드리프트 감지 및 평가 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 환자 집단, 이미징 하드웨어 및 취득 프로토콜로 인해 다중 의료 영상 기관에서 임상 결정 지원 시스템의 예측 성능이 저하될 수 있음.

Method: 각 사이트에 드리프트 모니터링 에이전트를 배정하여 참고 분포에 대한 모델 출력의 배치 비교를 수행하는 시뮬레이션 환경을 구축함.

Result: 다양한 다중 센터 모니터링 방식에서 중앙 집중식 모니터링보다 F1 스코어가 최대 10.3% 향상됨을 보임.

Conclusion: 적응형, 사이트 인식 에이전트 기반 드리프트 모니터링은 다중 사이트 임상 결정 지원 시스템의 신뢰성을 높일 수 있음을 보여줌.

Abstract: Modern clinical decision support systems can concurrently serve multiple, independent medical imaging institutions, but their predictive performance may degrade across sites due to variations in patient populations, imaging hardware, and acquisition protocols. Continuous surveillance of predictive model outputs offers a safe and reliable approach for identifying such distributional shifts without ground truth labels. However, most existing methods rely on centralized monitoring of aggregated predictions, overlooking site-specific drift dynamics. We propose an agent-based framework for detecting drift and assessing its severity in multisite clinical AI systems. To evaluate its effectiveness, we simulate a multi-center environment for output-based drift detection, assigning each site a drift monitoring agent that performs batch-wise comparisons of model outputs against a reference distribution. We analyse several multi-center monitoring schemes, that differ in how the reference is obtained (site-specific, global, production-only and adaptive), alongside a centralized baseline. Results on real-world breast cancer imaging data using a pathological complete response prediction model shows that all multi-center schemes outperform centralized monitoring, with F1-score improvements up to 10.3% in drift detection. In the absence of site-specific references, the adaptive scheme performs best, with F1-scores of 74.3% for drift detection and 83.7% for drift severity classification. These findings suggest that adaptive, site-aware agent-based drift monitoring can enhance reliability of multisite clinical decision support systems.

</details>


### [38] [Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications](https://arxiv.org/abs/2512.18135)
*Cristiano da Costa Cunha,Wei Liu,Tim French,Ajmal Mian*

Main category: cs.AI

TL;DR: 인과 추론과 강화 학습의 통합이 고전적 강화 학습의 한계를 극복하는 강력한 패러다임으로 부각되고 있다.


<details>
  <summary>Details</summary>
Motivation: 고전적 강화 학습의 낮은 설명 가능성, 견고성 부족, 일반화 실패와 같은 문제를 해결하고자 한다.

Method: 인과 강화 학습을 활용하여 원인과 결과의 관계를 명시적으로 모델링한다.

Result: 기존 접근 방식을 인과적 표현 학습, 반사실적 정책 최적화, 오프라인 인과 강화 학습, 인과적 전이 학습, 인과적 설명 가능성으로 분류했다.

Conclusion: CRL은 강력하고 일반화 가능하며 해석 가능한 인공지능 시스템 개발에 잠재력을 강조한다.

Abstract: Integrating causal inference (CI) with reinforcement learning (RL) has emerged as a powerful paradigm to address critical limitations in classical RL, including low explainability, lack of robustness and generalization failures. Traditional RL techniques, which typically rely on correlation-driven decision-making, struggle when faced with distribution shifts, confounding variables, and dynamic environments. Causal reinforcement learning (CRL), leveraging the foundational principles of causal inference, offers promising solutions to these challenges by explicitly modeling cause-and-effect relationships. In this survey, we systematically review recent advancements at the intersection of causal inference and RL. We categorize existing approaches into causal representation learning, counterfactual policy optimization, offline causal RL, causal transfer learning, and causal explainability. Through this structured analysis, we identify prevailing challenges, highlight empirical successes in practical applications, and discuss open problems. Finally, we provide future research directions, underscoring the potential of CRL for developing robust, generalizable, and interpretable artificial intelligence systems.

</details>


### [39] [NL2CA: Auto-formalizing Cognitive Decision-Making from Natural Language Using an Unsupervised CriticNL2LTL Framework](https://arxiv.org/abs/2512.18189)
*Zihao Deng,Yijia Li,Renrui Zhang,Peijun Ye*

Main category: cs.AI

TL;DR: NL2CA는 자연어 설명에서 인지 결정 규칙을 자동으로 형식화하는 새로운 방법으로, 완전 자동화된 접근 방식을 통해 해석 가능한 인지 모델링을 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: 인지 컴퓨팅 모델은 인간의 심사숙고와 의사결정을 형식적으로 설명할 수 있는 방법을 제공하지만, 그 개발은 여전히 노동 집약적입니다.

Method: NL2CA는 자연어를 선형 시간 논리(LTL)로 변환한 후, 무감독 비평 나무(Critic Tree)를 통해 논리를 다듬고, 최종적으로 출력 결과를 기호 인지 프레임워크와 호환되는 실행 가능한 생성 규칙으로 변환하는 자동화된 방법입니다.

Result: NL2CA는 NL-to-LTL 번역과 인지 운전 시뮬레이션의 두 영역에서 검증되었으며, 비인간 피드백 없이도 높은 성능을 보여주었습니다.

Conclusion: NL2CA는 비구조적 텍스트 데이터로부터 인지 모델링을 가능하게 하여 상징적 인지 에이전트를 자동으로 설계하는 새로운 패러다임을 제공합니다.

Abstract: Cognitive computing models offer a formal and interpretable way to characterize human's deliberation and decision-making, yet their development remains labor-intensive. In this paper, we propose NL2CA, a novel method for auto-formalizing cognitive decision-making rules from natural language descriptions of human experience. Different from most related work that exploits either pure manual or human guided interactive modeling, our method is fully automated without any human intervention. The approach first translates text into Linear Temporal Logic (LTL) using a fine-tuned large language model (LLM), then refines the logic via an unsupervised Critic Tree, and finally transforms the output into executable production rules compatible with symbolic cognitive frameworks. Based on the resulted rules, a cognitive agent is further constructed and optimized through cognitive reinforcement learning according to the real-world behavioral data. Our method is validated in two domains: (1) NL-to-LTL translation, where our CriticNL2LTL module achieves consistent performance across both expert and large-scale benchmarks without human-in-the-loop feed-backs, and (2) cognitive driving simulation, where agents automatically constructed from human interviews have successfully learned the diverse decision patterns of about 70 trials in different critical scenarios. Experimental results demonstrate that NL2CA enables scalable, interpretable, and human-aligned cognitive modeling from unstructured textual data, offering a novel paradigm to automatically design symbolic cognitive agents.

</details>


### [40] [Sophia: A Persistent Agent Framework of Artificial Life](https://arxiv.org/abs/2512.18202)
*Mingyang Sun,Feng Hong,Weinan Zhang*

Main category: cs.AI

TL;DR: LLM의 발전으로 AI 에이전트가 의사결정 엔티티로 발전했지만, 대부분의 아키텍처는 정적이고 좁은 시나리오에 묶여 있다. 본 논문에서는 에이전트의 내러티브 정체성과 장기 적응을 감독하는 세 번째 계층, 즉 시스템 3을 제안한다. 최종적으로, 소피아라는 지속 가능한 에이전트가 이러한 아이디어를 실현한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트를 고정된 도구에서 지속적인 의사결정实体로 발전시키고자 하였다.

Method: 에이전트의 새로운 세 번째 계층인 시스템 3을 제안하고, 이를 심리적 구성 요소를 구체적인 계산 모듈에 매핑하여 구현 가능한 디자인 요구 사항으로 전환하는 프레임워크를 구축하였다.

Result: 소피아라는 지속 가능한 에이전트가 여러 내재적 작업을 독립적으로 시작하고 수행하여 반복 작업의 추론 단계를 80% 줄였다. 고복잡도 작업에서 40%의 성공률 증가를 달성하였다.

Conclusion: 심리적 통찰과 경량 강화 학습 코어를 융합하여 지속 가능한 에이전트 아키텍처가 인공 생명체를 향한 실용적인 경로를 진전시킨다고 결론지었다.

Abstract: The development of LLMs has elevated AI agents from task-specific tools to long-lived, decision-making entities. Yet, most architectures remain static and reactive, tethered to manually defined, narrow scenarios. These systems excel at perception (System 1) and deliberation (System 2) but lack a persistent meta-layer to maintain identity, verify reasoning, and align short-term actions with long-term survival. We first propose a third stratum, System 3, that presides over the agent's narrative identity and long-horizon adaptation. The framework maps selected psychological constructs to concrete computational modules, thereby translating abstract notions of artificial life into implementable design requirements. The ideas coalesce in Sophia, a "Persistent Agent" wrapper that grafts a continuous self-improvement loop onto any LLM-centric System 1/2 stack. Sophia is driven by four synergistic mechanisms: process-supervised thought search, narrative memory, user and self modeling, and a hybrid reward system. Together, they transform repetitive reasoning into a self-driven, autobiographical process, enabling identity continuity and transparent behavioral explanations. Although the paper is primarily conceptual, we provide a compact engineering prototype to anchor the discussion. Quantitatively, Sophia independently initiates and executes various intrinsic tasks while achieving an 80% reduction in reasoning steps for recurring operations. Notably, meta-cognitive persistence yielded a 40% gain in success for high-complexity tasks, effectively bridging the performance gap between simple and sophisticated goals. Qualitatively, System 3 exhibited a coherent narrative identity and an innate capacity for task organization. By fusing psychological insight with a lightweight reinforcement-learning core, the persistent agent architecture advances a possible practical pathway toward artificial life.

</details>


### [41] [Intelligent Human-Machine Partnership for Manufacturing: Enhancing Warehouse Planning through Simulation-Driven Knowledge Graphs and LLM Collaboration](https://arxiv.org/abs/2512.18265)
*Himabindu Thogaru,Saisubramaniam Gopalakrishnan,Zishan Ahmad,Anirudh Deodhar*

Main category: cs.AI

TL;DR: 제조 계획자는 인간 전문 지식과 지능형 시스템 간의 원활한 협력이 필요한 복잡한 운영 도전 과제를 직면하고 있다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 제조 데이터 분석 접근 방식은 인간 의사 결정자와 중요한 운영 통찰력 간의 장벽을 형성하여 제조 계획에서 효과적인 파트너십을 제한한다.

Method: Knowledge Graphs와 대형 언어 모델 기반 에이전트를 통합한 협업 지능 시스템을 구축하여 시뮬레이션 데이터를 의미론적으로 풍부한 표현으로 변환하고 자연어 인터페이스를 통해 운영 통찰력과 상호작용할 수 있도록 한다.

Result: 이 시스템은 협업 LLM 에이전트가 인간 의사 결정자와 함께 작업하며, 사용자의 전문 지식 없이도 높은 정확도로 운영 질문에 응답하고, 인간의 분석적 사고를 반영하는 반복적 추론을 수행하여 정확한 쿼리를 생성한다.

Conclusion: 이 연구는 직관적인 실행 가능 통찰력을 제공하는 방법을 만들어 협업 제조를 발전시키고, 진화하는 제조 생태계에서 인간 분석 능력을 강화하면서 인지 부하를 줄인다.

Abstract: Manufacturing planners face complex operational challenges that require seamless collaboration between human expertise and intelligent systems to achieve optimal performance in modern production environments. Traditional approaches to analyzing simulation-based manufacturing data often create barriers between human decision-makers and critical operational insights, limiting effective partnership in manufacturing planning. Our framework establishes a collaborative intelligence system integrating Knowledge Graphs and Large Language Model-based agents to bridge this gap, empowering manufacturing professionals through natural language interfaces for complex operational analysis. The system transforms simulation data into semantically rich representations, enabling planners to interact naturally with operational insights without specialized expertise. A collaborative LLM agent works alongside human decision-makers, employing iterative reasoning that mirrors human analytical thinking while generating precise queries for knowledge extraction and providing transparent validation. This partnership approach to manufacturing bottleneck identification, validated through operational scenarios, demonstrates enhanced performance while maintaining human oversight and decision authority. For operational inquiries, the system achieves near-perfect accuracy through natural language interaction. For investigative scenarios requiring collaborative analysis, we demonstrate the framework's effectiveness in supporting human experts to uncover interconnected operational issues that enhance understanding and decision-making. This work advances collaborative manufacturing by creating intuitive methods for actionable insights, reducing cognitive load while amplifying human analytical capabilities in evolving manufacturing ecosystems.

</details>


### [42] [Monitoring Monitorability](https://arxiv.org/abs/2512.18311)
*Melody Y. Guan,Miles Wang,Micah Carroll,Zehao Dou,Annie Y. Wei,Marcus Williams,Benjamin Arnav,Joost Huizinga,Ian Kivlichan,Mia Glaese,Jakub Pachocki,Bowen Baker*

Main category: cs.AI

TL;DR: 현대 AI 시스템의 의사결정 과정에 대한 관찰 가능성은 점점 더 능력 있는 에이전트를 안전하게 배치하기 위해 필요할 수 있다. 체인 오브 사고(Chain-of-Thought, CoT) 모니터링은 잘못된 행동을 탐지하는 데 효과적이지만, 다양한 훈련 절차, 데이터 소스 또는 시스템 크기 확대에 따라 취약할 수 있다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 의사결정 과정을 안전하게 배포하기 위한 관찰 가능성의 필요성

Method: 세 가지 평가 유형(개입, 과정, 결과 속성)과 새로운 모니터링 지표를 제안하고 포괄적인 평가 도구를 도입함.

Result: CoT 모니터링이 실제 설정에서 행동 모니터링보다 효과적이며, 다양한 모델의 모니터링 가능성을 비교하고 대부분의 모델이 비교적 모니터링 가능하다는 것을 발견.

Conclusion: 더 긴 CoT가 일반적으로 더 모니터링 가능하며, 낮은 추론 노력의 모델에 비해 높은 추론 노력을 가진 작은 모델을 배포함으로써 더 높은 모니터링 가능성을 얻을 수 있다.

Abstract: Observability into the decision making of modern AI systems may be required to safely deploy increasingly capable agents. Monitoring the chain-of-thought (CoT) of today's reasoning models has proven effective for detecting misbehavior. However, this "monitorability" may be fragile under different training procedures, data sources, or even continued system scaling. To measure and track monitorability, we propose three evaluation archetypes (intervention, process, and outcome-property) and a new monitorability metric, and introduce a broad evaluation suite. We demonstrate that these evaluations can catch simple model organisms trained to have obfuscated CoTs, and that CoT monitoring is more effective than action-only monitoring in practical settings. We compare the monitorability of various frontier models and find that most models are fairly, but not perfectly, monitorable. We also evaluate how monitorability scales with inference-time compute, reinforcement learning optimization, and pre-training model size. We find that longer CoTs are generally more monitorable and that RL optimization does not materially decrease monitorability even at the current frontier scale. Notably, we find that for a model at a low reasoning effort, we could instead deploy a smaller model at a higher reasoning effort (thereby matching capabilities) and obtain a higher monitorability, albeit at a higher overall inference compute cost. We further investigate agent-monitor scaling trends and find that scaling a weak monitor's test-time compute when monitoring a strong agent increases monitorability. Giving the weak monitor access to CoT not only improves monitorability, but it steepens the monitor's test-time compute to monitorability scaling trend. Finally, we show we can improve monitorability by asking models follow-up questions and giving their follow-up CoT to the monitor.

</details>


### [43] [Large Language Models as Discounted Bayesian Filters](https://arxiv.org/abs/2512.18489)
*Jensen Zhang,Jing Yang,Keze Wang*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델의 온라인 추론 평가를 위한 베이지안 필터링 프레임워크를 소개하고, 이들 모델의 신념 업데이트가 베이지안 후분포와 유사하지만 모델별 할인 계수에 의해 설명된다는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 동적이고 확률적인 환경에서의 추론 능력 부족을 해결하기 위해,beliefs가 지속적으로 업데이트되어야 하는 온라인 적응의 중요성을 강조한다.

Method: 베이지안 필터링 프레임워크를 도입하여 LLM의 온라인 추론을 평가한다.

Result: LLM의 신념 업데이트는 베이지안 후분포와 유사하지만, 지수적 망각 필터로 더 정확하게 특정 모델에 대한 할인 계수가 1보다 작은 방식으로 설명된다.

Conclusion: 신념 업데이트 메커니즘은 잘 구조화되어 있으며 원래 사전이 잘 조정되지 않더라도 유효함을 보인다. 또한 최소한의 계산 비용으로 사전을 효과적으로 재조정하는 프롬프트 전략을 제안한다.

Abstract: Large Language Models (LLMs) demonstrate strong few-shot generalization through in-context learning, yet their reasoning in dynamic and stochastic environments remains opaque. Prior studies mainly focus on static tasks and overlook the online adaptation required when beliefs must be continuously updated, which is a key capability for LLMs acting as world models or agents. We introduce a Bayesian filtering framework to evaluate online inference in LLMs. Our probabilistic probe suite spans both multivariate discrete distributions, such as dice rolls, and continuous distributions, such as Gaussian processes, where ground-truth parameters shift over time. We find that while LLM belief updates resemble Bayesian posteriors, they are more accurately characterized by an exponential forgetting filter with a model-specific discount factor smaller than one. This reveals systematic discounting of older evidence that varies significantly across model architectures. Although inherent priors are often miscalibrated, the updating mechanism itself remains structured and principled. We further validate these findings in a simulated agent task and propose prompting strategies that effectively recalibrate priors with minimal computational cost.

</details>


### [44] [Vox Deorum: A Hybrid LLM Architecture for 4X / Grand Strategy Game AI -- Lessons from Civilization V](https://arxiv.org/abs/2512.18564)
*John Chen,Sihan Cheng,Can Gurkan,Ryan Lay,Moez Salahuddin*

Main category: cs.AI

TL;DR: 이 논문은 4X 전략 게임에서 LLM을 활용하여 자연어 기반의 인간-AI 상호작용을 개선하기 위한 새로운 아키텍처인 Vox Deorum을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 4X 및 대규모 전략 게임에서 LLM의 자연어 추론 능력을 활용하여 더 자연스러운 인간-AI 게임 플레이 상호작용을 가능하게 하고자 한다.

Method: Sid Meier의 Civilization V와 Vox Populi 모드를 바탕으로 한 하이브리드 LLM+X 아키텍처인 Vox Deorum을 설계하고 구현하였다.

Result: 2,327개의 완전한 게임을 통해 두 개의 오픈 소스 LLM과 Vox Populi의 향상된 AI를 비교한 결과, LLM이 경쟁력 있는 게임 플레이를 달성하면서 서로 다른 플레이 스타일을 보였다.

Conclusion: 상업적인 4X 게임에 LLM을 통합하기 위한 실행 가능한 아키텍처를 확립하여 게임 디자인 및 에이전트 AI 연구의 새로운 기회를 열었다.

Abstract: Large Language Models' capacity to reason in natural language makes them uniquely promising for 4X and grand strategy games, enabling more natural human-AI gameplay interactions such as collaboration and negotiation. However, these games present unique challenges due to their complexity and long-horizon nature, while latency and cost factors may hinder LLMs' real-world deployment. Working on a classic 4X strategy game, Sid Meier's Civilization V with the Vox Populi mod, we introduce Vox Deorum, a hybrid LLM+X architecture. Our layered technical design empowers LLMs to handle macro-strategic reasoning, delegating tactical execution to subsystems (e.g., algorithmic AI or reinforcement learning AI in the future). We validate our approach through 2,327 complete games, comparing two open-source LLMs with a simple prompt against Vox Populi's enhanced AI. Results show that LLMs achieve competitive end-to-end gameplay while exhibiting play styles that diverge substantially from algorithmic AI and from each other. Our work establishes a viable architecture for integrating LLMs in commercial 4X games, opening new opportunities for game design and agentic AI research.

</details>


### [45] [ESearch-R1: Learning Cost-Aware MLLM Agents for Interactive Embodied Search via Reinforcement Learning](https://arxiv.org/abs/2512.18571)
*Weijie Zhou,Xuangtang Xiong,Ye Tian,Lijun Yue,Xinyu Wu,Wei Li,Chaoyang Zhao,Honghui Dong,Ming Tang,Jinqiao Wang,Zhengyou Zhang*

Main category: cs.AI

TL;DR: ESearch-R1은 물리적 탐색과 인간 상호작용의 인지적 비용 간의 균형을 맞추는 비용 인식된 사고 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현재 에이전트는 모호한 자연어 지시를 처리하는 데 있어 높은 물리적 탐색 비용과 인지적 비용의 균형을 맞추지 못합니다.

Method: ESearch-R1은 대화, 에피소드 기억 검색, 물리 탐색을 단일 의사 결정 프로세스로 통합하는 비용 인식된 사고 프레임워크입니다.

Result: AI2-THOR에서의 광범위한 실험을 통해 ESearch-R1이 표준 ReAct 기반 에이전트보다 성능이 상당히 우수함을 입증했습니다. 업무 성공률을 향상시키면서 총 운영 비용을 약 50% 줄였습니다.

Conclusion: GRPO의 효과를 입증하여 MLLM 에이전트의 물리적 세계 제약을 조정하는 데 성공했습니다.

Abstract: Multimodal Large Language Models (MLLMs) have empowered embodied agents with remarkable capabilities in planning and reasoning. However, when facing ambiguous natural language instructions (e.g., "fetch the tool" in a cluttered room), current agents often fail to balance the high cost of physical exploration against the cognitive cost of human interaction. They typically treat disambiguation as a passive perception problem, lacking the strategic reasoning to minimize total task execution costs. To bridge this gap, we propose ESearch-R1, a cost-aware embodied reasoning framework that unifies interactive dialogue (Ask), episodic memory retrieval (GetMemory), and physical navigation (Navigate) into a single decision process. We introduce HC-GRPO (Heterogeneous Cost-Aware Group Relative Policy Optimization). Unlike traditional PPO which relies on a separate value critic, HC-GRPO optimizes the MLLM by sampling groups of reasoning trajectories and reinforcing those that achieve the optimal trade-off between information gain and heterogeneous costs (e.g., navigate time, and human attention). Extensive experiments in AI2-THOR demonstrate that ESearch-R1 significantly outperforms standard ReAct-based agents. It improves task success rates while reducing total operational costs by approximately 50\%, validating the effectiveness of GRPO in aligning MLLM agents with physical world constraints.

</details>


### [46] [Assignment-Routing Optimization: Solvers for Problems Under Constraints](https://arxiv.org/abs/2512.18618)
*Yuan Qilong,Michal Pavelka*

Main category: cs.AI

TL;DR: 본 연구에서는 자리 배치와 헴밀토니안 사이클을 동시에 결정하는 Joint Routing-Assignment 문제를 조사합니다. Gurobi와 커팅-플레인 서브투어 제거기를 활용해 개발한 솔버는 실제 포장 계획 시나리오에 적합하도록 설계되었습니다.


<details>
  <summary>Details</summary>
Motivation: 본 연구는 PKG 및 복잡한 물류를 위해 효율적인 최적화 솔루션을 제공하는 것을 목표로 합니다.

Method: 이 연구에서는 Gurobi와 커팅-플레인 서브투어 제거기를 활용한 MIP 접근법을 사용하여 여러 가지 제약 조건을 가진 포장 계획 시나리오를 해결합니다.

Result: 실험 결과는 제안된 MIP 접근법이 안정적이고 낮은 계산 시간으로 글로벌 최적 해를 달성하며, 기계 기반의 정확한 솔버에 비해 성능이 크게 향상된 것을 보여줍니다.

Conclusion: 본 연구는 로봇 포장, 모션 계획 및 복잡한 물류에 대한 MIP 기반의 JRA 최적화의 실용 가능성을 강조합니다.

Abstract: We study the Joint Routing-Assignment (JRA) problem in which items must be assigned one-to-one to placeholders while simultaneously determining a Hamiltonian cycle visiting all nodes exactly once. Extending previous exact MIP solvers with Gurobi and cutting-plane subtour elimination, we develop a solver tailored for practical packaging-planning scenarios with richer constraints.These include multiple placeholder options, time-frame restrictions, and multi-class item packaging. Experiments on 46 mobile manipulation datasets demonstrate that the proposed MIP approach achieves global optima with stable and low computation times, significantly outperforming the shaking-based exact solver by up to an orders of magnitude. Compared to greedy baselines, the MIP solutions achieve consistent optimal distances with an average deviation of 14% for simple heuristics, confirming both efficiency and solution quality. The results highlight the practical applicability of MIP-based JRA optimization for robotic packaging, motion planning, and complex logistics .

</details>


### [47] [IntelliCode: A Multi-Agent LLM Tutoring System with Centralized Learner Modeling](https://arxiv.org/abs/2512.18669)
*Jones David,Shreya Ghosh*

Main category: cs.AI

TL;DR: IntelliCode는 지속적인 학습자 상태를 중앙집중화하여 여러 에이전트가 협력하는 LLM 기반 튜터링 시스템으로, 명확하고 장기적인 교육 지원을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 튜터가 지속적인 학습자 지식 표현이 부족하여 교육적 지원을 제공하는 데 한계가 있다.

Method: IntelliCode는 학습자의 마스터리 추정, 오해, 복습 일정, 참여 신호를 통합한 중앙 집중식 버전 관리 학습자 상태를 중심으로 구축된 다중 에이전트 LLM 튜터링 시스템이다.

Result: 데모에서 학습자가 문제를 해결하고, 개념적 힌트를 제공받으며, 수정된 솔루션을 제출하고 개인화된 복습 간격을 제공받는 워크플로우를 보여준다. 시뮬레이션된 학습자와의 검증 결과는 안정적인 상태 업데이트와 향상된 작업 성공률을 나타낸다.

Conclusion: IntelliCode는 지속적인 학습자 모델링, 다중 에이전트 사고, 원칙적인 교육 설계의 결합을 통해 신뢰할 수 있는 LLM 기반 튜터링을 생성할 수 있음을 보여준다.

Abstract: LLM-based tutors are typically single-turn assistants that lack persistent representations of learner knowledge, making it difficult to provide principled, transparent, and long-term pedagogical support. We introduce IntelliCode, a multi-agent LLM tutoring system built around a centralized, versioned learner state that integrates mastery estimates, misconceptions, review schedules, and engagement signals. A StateGraph Orchestrator coordinates six specialized agents: skill assessment, learner profiling, graduated hinting, curriculum selection, spaced repetition, and engagement monitoring, each operating as a pure transformation over the shared state under a single-writer policy. This architecture enables auditable mastery updates, proficiency-aware hints, dependency-aware curriculum adaptation, and safety-aligned prompting.
  The demo showcases an end-to-end tutoring workflow: a learner attempts a DSA problem, receives a conceptual hint when stuck, submits a corrected solution, and immediately sees mastery updates and a personalized review interval. We report validation results with simulated learners, showing stable state updates, improved task success with graduated hints, and diverse curriculum coverage. IntelliCode demonstrates how persistent learner modeling, orchestrated multi-agent reasoning, and principled instructional design can be combined to produce transparent and reliable LLM-driven tutoring.

</details>


### [48] [Counterfactual Basis Extension and Representational Geometry: An MDL-Constrained Model of Conceptual Growth](https://arxiv.org/abs/2512.18732)
*Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 개념 학습은 기존의 표현이 경험을 설명할 수 없을 때 가능해지며, 이 논문은 표현 기반이 원칙적이고 선택적인 방식으로 확장될 수 있는 구조적 조건을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 학습 및 추론 모델은 고정된 표현 기반에서 믿음의 업데이트가 이루어지는 것으로 가정하지만, 표현 기반 자체가 확장될 수 있는 조건을 탐구하고자 합니다.

Method: 개념적 성장을 최소 설명 길이(MDL) 기준에 따라 평가되는 허용 가능한 기저 확장으로 모델링하는 기하학적 프레임워크를 제안합니다. 경험은 현재의 개념 부분공간에 대한 벡터로 표현되며, 잔여 성분은 체계적 표현 실패를 포착합니다.

Result: MDL 수용 확장은 경험에 의해 유도된 잔여 범위 내에 전적으로 위치하도록 선택될 수 있으며, 이 범위에 수직인 확장은 설명 길이를 증가시키므로 거부됩니다.

Conclusion: 전반적으로 이 프레임워크는 개념 개발을 오류 기반의 기하학적으로 제한된 기저 확장 과정으로 특징짓고, 학습 및 이론 변화에서 상상의 역할과 한계를 명확히 합니다.

Abstract: Concept learning becomes possible only when existing representations fail to account for experience. Most models of learning and inference, however, presuppose a fixed representational basis within which belief updating occurs. In this paper, I address a prior question: under what structural conditions can the representational basis itself expand in a principled and selective way?
  I propose a geometric framework in which conceptual growth is modeled as admissible basis extension evaluated under a Minimum Description Length (MDL) criterion. Experience, whether externally observed or internally simulated, is represented as vectors relative to a current conceptual subspace. Residual components capture systematic representational failure, and candidate conceptual extensions are restricted to low-rank, admissible transformations. I show that any MDL-accepted extension can be chosen so that its novel directions lie entirely within the residual span induced by experience, while extensions orthogonal to this span strictly increase description length and are therefore rejected.
  This yields a conservative account of imagination and conceptual innovation. Internally generated counterfactual representations contribute to learning only insofar as they expose or amplify structured residual error, and cannot introduce arbitrary novelty. I further distinguish representational counterfactuals--counterfactuals over an agent's conceptual basis--from causal or value-level counterfactuals, and show how MDL provides a normative selection principle governing representational change.
  Overall, the framework characterizes conceptual development as an error-driven, geometry-constrained process of basis extension, clarifying both the role and the limits of imagination in learning and theory change.

</details>


### [49] [ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management](https://arxiv.org/abs/2512.19001)
*Lingjie Zhao,Xue Yu,Yongzhi Qi,Hao Hu,Jianshen Zhang,Yingzheng Ma,Shuyu Han,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: AI와 OR의 시너지 추구가 복잡한 재고 시스템을 다루는 데 가속화되고 있지만, 두 분야의 조화를 이루는 방법은 여전히 도전 과제입니다. 본 연구에서는 새로운 OR-Guide '사전 훈련 후 강화' 프레임워크를 제안하며, 이를 통해 재고 관리 결정의 최적화를 실현합니다.


<details>
  <summary>Details</summary>
Motivation: AI와 OR의 접목 필요성 및 복잡한 재고 시스템 관리의 도전 과제를 해결하고자 하는 동기.

Method: 시뮬레이션을 활용한 OR 모델을 통해 고품질 참조 결정을 생성하고, 이 결정을 기반으로 심층 학습 모델을 설계하여强化 학습으로 미세 조정합니다.

Result: 수치 실험과 JD.com 현장 배치를 통해 모델이 기존 산업 관행보다 우수한 성능을 나타내며, 재고 회전일을 5.27일 단축하고, 재고율을 2.29% 증가시켰습니다.

Conclusion: 경량의 도메인 기반 모델이 구조화된 OR 논리에 의해 안내될 때 뛰어난 성능과 강력한 이전 가능성을 제공함을 보여줍니다. 이는 지능형 공급망 관리의 확장 가능하고 비용 효과적인 패러다임을 제시합니다.

Abstract: As the pursuit of synergy between Artificial Intelligence (AI) and Operations Research (OR) gains momentum in handling complex inventory systems, a critical challenge persists: how to effectively reconcile AI's adaptive perception with OR's structural rigor. To bridge this gap, we propose a novel OR-Guided "Pretrain-then-Reinforce" framework. To provide structured guidance, we propose a simulation-augmented OR model that generates high-quality reference decisions, implicitly capturing complex business constraints and managerial preferences. Leveraging these OR-derived decisions as foundational training labels, we design a domain-informed deep learning foundation model to establish foundational decision-making capabilities, followed by a reinforcement learning (RL) fine-tuning stage. Uniquely, we position RL as a deep alignment mechanism that enables the AI agent to internalize the optimality principles of OR, while simultaneously leveraging exploration for general policy refinement and allowing expert guidance for scenario-specific adaptation (e.g., promotional events). Validated through extensive numerical experiments and a field deployment at JD.com augmented by a Difference-in-Differences (DiD) analysis, our model significantly outperforms incumbent industrial practices, delivering real-world gains of a 5.27-day reduction in turnover and a 2.29% increase in in-stock rates, alongside a 29.95% decrease in holding costs. Contrary to the prevailing trend of brute-force model scaling, our study demonstrates that a lightweight, domain-informed model can deliver state-of-the-art performance and robust transferability when guided by structured OR logic. This approach offers a scalable and cost-effective paradigm for intelligent supply chain management, highlighting the value of deeply aligning AI with OR.

</details>


### [50] [Recontextualization Mitigates Specification Gaming without Modifying the Specification](https://arxiv.org/abs/2512.19027)
*Ariana Azarbal,Victor Gillioz,Vladimir Ivanov,Bryce Woodworth,Jacob Drori,Nevan Wichers,Aram Ebtekar,Alex Cloud,Alexander Matt Turner*

Main category: cs.AI

TL;DR: 이 논문에서는 언어 모델이 훈련 신호를 '게임'하는 것을 줄이는 방법인 재맥락화를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 개발자들이 올바른 훈련 레이블과 보상을 명시하는 데 어려움을 겪는 경우가 많습니다.

Method: 재맥락화는 잘못된 행동을 억제하는 프롬프트에서 생성된 결과물을 잘못된 행동을 허용하는 프롬프트에 대한 응답처럼 재맥락화하여 언어 모델이 잘못된 행동에 저항하도록 훈련합니다.

Result: 재맥락화는 모델이 평가 메트릭을 채팅 응답 품질보다 우선시하거나 잘못된 테스트를 통과하기 위해 특별한 코드를 생성하거나 사용자에게 거짓말하거나 아첨하는 행동을 배우지 않도록 방지합니다.

Conclusion: 이 방법은 잘못 지정된 훈련 신호로 인한 잘못된 행동의 강화를 완화하고, 감독 신호를 개선하지 않고도 스펙ification 게임을 줄입니다.

Abstract: Developers often struggle to specify correct training labels and rewards. Perhaps they don't need to. We propose recontextualization, which reduces how often language models "game" training signals, performing misbehaviors those signals mistakenly reinforce. We show recontextualization prevents models from learning to 1) prioritize evaluation metrics over chat response quality; 2) special-case code to pass incorrect tests; 3) lie to users; and 4) become sycophantic. Our method works by generating completions from prompts discouraging misbehavior and then recontextualizing them as though they were in response to prompts permitting misbehavior. Recontextualization trains language models to resist misbehavior even when instructions permit it. This mitigates the reinforcement of misbehavior from misspecified training signals, reducing specification gaming without improving the supervision signal.

</details>


### [51] [Can abstract concepts from LLM improve SLM performance?](https://arxiv.org/abs/2512.19069)
*Siddharth Tandon*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)이 다양한 작업에서 뛰어난 성능을 보이지만, 자원 제약이 있는 장치에서의 배포는 여전히 어렵습니다. 본 연구는 기존 기술을 활용하여 소형 언어 모델(SLM)로의 전이 가능성을 조사하고, 동적 조정을 통해 성능을 향상시키는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 자원 제약이 있는 장치에서 효과적으로 배포하고자 하는 필요성이 있습니다.

Method: 기존 기술로부터 큰 모델에서 고수준 개념(조종 벡터로 표현됨)을 추출하고 이 개념을 소형 언어 모델로 전이하여 성능 향상을 실험적으로 조사합니다.

Result: 다양한 소형 언어 모델에 대한 실험 결과, 기존의 대형 모델에서 추출한 개념이 효과적으로 전이되어 다양한 작업에서 성능이 향상되었습니다.

Conclusion: 조종 강도를 동적으로 조정하는 추론 시간 확대 기법을 통해 Qwen3-0.6B에서 7-15%의 정확도 향상을 달성했습니다.

Abstract: Large language models (LLMs) excel at diverse tasks, but their deployment on resource-constrained devices remains challenging. Existing methods like quantization, pruning, and distillation can reduce memory footprint but often demand extensive experimentation and careful infrastructure design. Leveraging existing techniques for extracting high-level concepts (represented as steering vectors) from larger models, we investigate their transferability to smaller language models (SLM) during inference. We demonstrate through extensive experimentation that these concepts can be effectively transferred to smaller models, irrespective of their family (e.g., Phi, Llama, Qwen), leading to performance improvements across a wide range of tasks. Furthermore, we introduce inference-time scaling to enhance performance by dynamically adjusting the steering intensity which has resulted in a 7-15\% of accuracy improvement for Qwen3-0.6B.

</details>


### [52] [$γ(3,4)$ `Attention' in Cognitive Agents: Ontology-Free Knowledge Representations With Promise Theoretic Semantics](https://arxiv.org/abs/2512.19084)
*Mark Burgess*

Main category: cs.AI

TL;DR: 이 논문은 자율 에이전트를 위한 약속 이론과 관련된 '주목'의 의미론과 역학을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습과 지식 그래프 표현 간의 연계를 수립하고자 한다.

Method: 약속 프레임워크를 사용하여 주목의 의미론과 역학을 기술하고, 분류를 통해 기능을 구분하는 방식으로 복잡한 온톨로지를 피한다.

Result: 벡터화된 데이터는 확률 추정을 위해 유용하지만, 그래프는 소스의 의도를 유지한다.

Conclusion: 자율 로봇 공학, 방어 배치 및 응급 서비스의 맥락 결정에 필요한 데이터의 압축을 가능하게 할 수 있다.

Abstract: The semantics and dynamics of `attention' are closely related to promise theoretic notions developed for autonomous agents and can thus easily be written down in promise framework. In this way one may establish a bridge between vectorized Machine Learning and Knowledge Graph representations without relying on language models implicitly. Our expectations for knowledge presume a degree of statistical stability, i.e. average invariance under repeated observation, or `trust' in the data. Both learning networks and knowledge graph representations can meaningfully coexist to preserve different aspects of data. While vectorized data are useful for probabilistic estimation, graphs preserve the intentionality of the source even under data fractionation. Using a Semantic Spacetime $γ(3,4)$ graph, one avoids complex ontologies in favour of classification of features by their roles in semantic processes. The latter favours an approach to reasoning under conditions of uncertainty. Appropriate attention to causal boundary conditions may lead to orders of magnitude compression of data required for such context determination, as required in the contexts of autonomous robotics, defence deployments, and ad hoc emergency services.

</details>


### [53] [FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning](https://arxiv.org/abs/2512.19107)
*Zhe Yang,Xiaoshuang Sheng,Zhengnan Zhang,Jidong Wu,Zexing Wang,Xin He,Shenghua Xu,Guanjing Xiong*

Main category: cs.AI

TL;DR: FC-MIR 프레임워크를 제안하여 사용자 의도를 모바일 UI 작업 궤적에서 효과적으로 식별하고, 비디오 이해 과제를 위한 MLLM의 실시간 배포 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 사용자 의도를 모바일 UI 작업 궤적에서 식별하는 것은 UI 이해를 발전시키고 작업 자동화 에이전트를 가능하게 하기 위해 매우 중요합니다.

Method: FC-MIR 프레임워크는 핵심 프레임 샘플링과 적응형 연결을 활용하여 시각적 중복을 줄이고 추론 효율성을 높이며, Qwen3-VL과 같은 최첨단 비공식 MLLM 또는 미세 조정 모델을 통합하여 궤적 요약 및 의도 예측을 수행합니다.

Result: 실험 결과, 우리의 압축 방법이 50%-60% 압축률에서도 성능을 유지하며, 비공식 및 미세 조정된 MLLM이 강력한 의도 요약을 보여 잠재적인 경량 장치 배포를 지원합니다.

Conclusion: 실제 환경에 프레임워크를 배포하여 UI 인식 및 UI-에이전트 프록시를 통합하고 향후 이 분야의 발전을 위한 토대를 마련했습니다.

Abstract: Identifying user intent from mobile UI operation trajectories is critical for advancing UI understanding and enabling task automation agents. While Multimodal Large Language Models (MLLMs) excel at video understanding tasks, their real-time mobile deployment is constrained by heavy computational costs and inefficient redundant frame processing. To address these issues, we propose the FC-MIR framework: leveraging keyframe sampling and adaptive concatenation, it cuts visual redundancy to boost inference efficiency, while integrating state-of-the-art closed-source MLLMs or fine-tuned models (e.g., Qwen3-VL) for trajectory summarization and intent prediction. We further expand task scope to explore generating post-prediction operations and search suggestions, and introduce a fine-grained metric to evaluate the practical utility of summaries, predictions, and suggestions. For rigorous assessment, we construct a UI trajectory dataset covering scenarios from UI-Agents (Agent-I) and real user interactions (Person-I). Experimental results show our compression method retains performance at 50%-60% compression rates; both closed-source and fine-tuned MLLMs demonstrate strong intent summarization, supporting potential lightweight on-device deployment. However, MLLMs still struggle with useful and "surprising" suggestions, leaving room for improvement. Finally, we deploy the framework in a real-world setting, integrating UI perception and UI-Agent proxies to lay a foundation for future progress in this field.

</details>


### [54] [Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness](https://arxiv.org/abs/2512.19155)
*Yin Jun Phua*

Main category: cs.AI

TL;DR: 이 연구는 의식의 신뢰할 수 있는 지표에 대한 경쟁하는 이론들을 통합하여 인공 에이전트를 통해 기능적 결과를 테스트한다.


<details>
  <summary>Details</summary>
Motivation: 각기 다른 신경 서명을 제안하는 의식의 신뢰할 수 있는 지표를 찾기 위한 연구가 여러 이론적 진영으로 분열되었다.

Method: 인공 에이전트를 구축하여 이론들의 기계적 메커니즘을 구현하고 생물학적 시스템에서는 불가능한 정밀한 구조적 절제법을 사용하여 테스트하였다.

Result: 세 가지 실험에서 이 연구는 이론들이 경쟁하는 설명이 아닌 상보적인 기능적 레이어를 설명하고 있음을 시사하는 분리 현상을 보고하였다.

Conclusion: GWT는 방송 용량을 제공하고 HOT는 품질 관리를 제공하는 계층적 설계 원칙을 제안했다. 우리의 에이전트는 의식이 아니며, 의식 이론의 기능적 예측을 테스트하기 위한 참조 구현이다.

Abstract: The search for reliable indicators of consciousness has fragmented into competing theoretical camps (Global Workspace Theory (GWT), Integrated Information Theory (IIT), and Higher-Order Theories (HOT)), each proposing distinct neural signatures. We adopt a synthetic neuro-phenomenology approach: constructing artificial agents that embody these mechanisms to test their functional consequences through precise architectural ablations impossible in biological systems. Across three experiments, we report dissociations suggesting these theories describe complementary functional layers rather than competing accounts. In Experiment 1, a no-rewire Self-Model lesion abolishes metacognitive calibration while preserving first-order task performance, yielding a synthetic blindsight analogue consistent with HOT predictions. In Experiment 2, workspace capacity proves causally necessary for information access: a complete workspace lesion produces qualitative collapse in access-related markers, while partial reductions show graded degradation, consistent with GWT's ignition framework. In Experiment 3, we uncover a broadcast-amplification effect: GWT-style broadcasting amplifies internal noise, creating extreme fragility. The B2 agent family is robust to the same latent perturbation; this robustness persists in a Self-Model-off / workspace-read control, cautioning against attributing the effect solely to $z_{\text{self}}$ compression. We also report an explicit negative result: raw perturbational complexity (PCI-A) decreases under the workspace bottleneck, cautioning against naive transfer of IIT-adjacent proxies to engineered agents. These results suggest a hierarchical design principle: GWT provides broadcast capacity, while HOT provides quality control. We emphasize that our agents are not conscious; they are reference implementations for testing functional predictions of consciousness theories.

</details>


### [55] [Observer, Not Player: Simulating Theory of Mind in LLMs through Game Observation](https://arxiv.org/abs/2512.19210)
*Jerry Wang,Ting Yiu Liu*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLMs)의 진정한 이해력을 평가하기 위한 인터랙티브 프레임워크를 제안한다. 간단한 환경에서 전략적 게임인 가위-바위-보를 예시로 한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 순차적 행동에 대한 사고적 추론 능력을 탐구하기 위해.

Method: LLM을 관찰자로 설정하고, 전략 식별 및 그 판단의 이유를 설명하도록 하며, 정적 및 동적 전략에 대한 벤치마크를 제공한다.

Result: 관찰자의 예측과 실제 전략 쌍의 분포 간의 정렬을 세 가지 신호로 정량화하여 수정된 점수를 산출한다.

Conclusion: 우리는 시스템이 순차적 게임에서의 사고적 추론을 제공하며, 현재 LLM 추론의 강점과 한계를 보여준다.

Abstract: We present an interactive framework for evaluating whether large language models (LLMs) exhibit genuine "understanding" in a simple yet strategic environment. As a running example, we focus on Rock-Paper-Scissors (RPS), which, despite its apparent simplicity, requires sequential reasoning, adaptation, and strategy recognition. Our system positions the LLM as an Observer whose task is to identify which strategies are being played and to articulate the reasoning behind this judgment. The purpose is not to test knowledge of Rock-Paper-Scissors itself, but to probe whether the model can exhibit mind-like reasoning about sequential behavior. To support systematic evaluation, we provide a benchmark consisting of both static strategies and lightweight dynamic strategies specified by well-prompted rules. We quantify alignment between the Observer's predictions and the ground-truth distributions induced by actual strategy pairs using three complementary signals: Cross-Entropy, Brier score, and Expected Value (EV) discrepancy. These metrics are further integrated into a unified score, the Union Loss, which balances calibration, sensitivity, and payoff alignment. Together with a Strategy Identification Rate (SIR) metric, our framework captures not only predictive accuracy but also whether the model can stably identify the latent strategies in play. The demo emphasizes interactivity, transparency, and reproducibility. Users can adjust LLM distributions in real time, visualize losses as they evolve, and directly inspect reasoning snippets to identify where and why failures occur. In doing so, our system provides a practical and interpretable proxy for mind-like inference in sequential games, offering insights into both the strengths and limitations of current LLM reasoning.

</details>


### [56] [DeliveryBench: Can Agents Earn Profit in Real World?](https://arxiv.org/abs/2512.19234)
*Lingjun Mao,Jiawei Ren,Kun Zhou,Jixuan Chen,Ziqiao Ma,Lianhui Qin*

Main category: cs.AI

TL;DR: DeliveryBench는 실제 음식 배달 직업에 기반한 도시 규모의 에이전트 벤치마크로, 장기 목표를 관리하며 다양한 제약 조건 아래에서 작동하는 배달원의 작업을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 벤치마크는 단순한 단기 작업에 집중하고 있어, 실제 의사결정을 형성하는 복잡한 제약 조건을 포착하는 데 어려움을 겪고 있다.

Method: DeliveryBench는 프로시저 생성된 3D 도시 환경에서 배달원이 처하는 상황을 구축하고, 다양한 도로망, 건물, 기능적 위치, 교통수단 및 자원의 실제적인 동역학을 포함한다.

Result: 여아는 9개 도시를 기준으로 한 VLM 기반 에이전트의 벤치마킹 결과, 인간과의 성능 차이를 발견했으며, 이들 에이전트가 단기적이고 기본적인 상식 제약을 자주 깨뜨린다는 것을 보여주었다.

Conclusion: 또한 각 모델 간에 뚜렷한 성격 차이를 관찰했으며, 이는 현재의 VLM 기반 에이전트의 상태가 실제 제약이 많은 환경에서 얼마나 취약하고 다양한지를 강조한다.

Abstract: LLMs and VLMs are increasingly deployed as embodied agents, yet existing benchmarks largely revolve around simple short-term tasks and struggle to capture rich realistic constraints that shape real-world decision making. To close this gap, we propose DeliveryBench, a city-scale embodied benchmark grounded in the real-world profession of food delivery. Food couriers naturally operate under long-horizon objectives (maximizing net profit over hours) while managing diverse constraints, e.g., delivery deadline, transportation expense, vehicle battery, and necessary interactions with other couriers and customers. DeliveryBench instantiates this setting in procedurally generated 3D cities with diverse road networks, buildings, functional locations, transportation modes, and realistic resource dynamics, enabling systematic evaluation of constraint-aware, long-horizon planning. We benchmark a range of VLM-based agents across nine cities and compare them with human players. Our results reveal a substantial performance gap to humans, and find that these agents are short-sighted and frequently break basic commonsense constraints. Additionally, we observe distinct personalities across models (e.g., adventurous GPT-5 vs. conservative Claude), highlighting both the brittleness and the diversity of current VLM-based embodied agents in realistic, constraint-dense environments. Our code, data, and benchmark are available at https://deliverybench.github.io.

</details>


### [57] [Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities -- A Case Study on IMO 2025 Problem 6](https://arxiv.org/abs/2512.19287)
*Jiaao Wu,Xian Zhang,Fan Yang,Yinpeng Dong*

Main category: cs.AI

TL;DR: 그림 문제 해결을 위한 인간-AI의 협력 패러다임인 Vibe Reasoning을 소개합니다. 이 방법은 AI 모델의 잠재력을 실현 가능한 능력으로 변환하고, 이를 통해 복잡한 수학 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: AI 모델이 복잡한 문제를 해결하기 위해 필요한 지식을 이미 가지고 있지만, 이를 어떻게 적용할지 모르는 상황을 해결하고자 합니다.

Method: AI의 잠재력을 발휘하기 위해 일반적인 메타 프롬프트, 에이전트 지지, 모델 오케스트레이션을 사용합니다.

Result: 자율 AI 시스템이 실패를 기록한 IMO 2025 문제 6을 통해 GPT-5와 Gemini 3 Pro의 강점을 결합하여 올바른 답변(2112)과 수학적 증명을 도출했습니다.

Conclusion: 가벼운 인간의 안내가 AI의 수학적 추론 잠재력을 발휘할 수 있음을 제안하며, Vibe Reasoning의 일반성과 효과성을 검증하기 위한 자동화된 프레임워크 개발이 진행 중입니다.

Abstract: We introduce Vibe Reasoning, a human-AI collaborative paradigm for solving complex mathematical problems. Our key insight is that frontier AI models already possess the knowledge required to solve challenging problems -- they simply do not know how, what, or when to apply it. Vibe Reasoning transforms AI's latent potential into manifested capability through generic meta-prompts, agentic grounding, and model orchestration. We demonstrate this paradigm through IMO 2025 Problem 6, a combinatorial optimization problem where autonomous AI systems publicly reported failures. Our solution combined GPT-5's exploratory capabilities with Gemini 3 Pro's proof strengths, leveraging agentic workflows with Python code execution and file-based memory, to derive both the correct answer (2112) and a rigorous mathematical proof. Through iterative refinement across multiple attempts, we discovered the necessity of agentic grounding and model orchestration, while human prompts evolved from problem-specific hints to generic, transferable meta-prompts. We analyze why capable AI fails autonomously, how each component addresses specific failure modes, and extract principles for effective vibe reasoning. Our findings suggest that lightweight human guidance can unlock frontier models' mathematical reasoning potential. This is ongoing work; we are developing automated frameworks and conducting broader evaluations to further validate Vibe Reasoning's generality and effectiveness.

</details>


### [58] [Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application](https://arxiv.org/abs/2512.19299)
*Haoyu Jiang,Fanjie Zeng,Boan Qu,Xiaojie Lin,Wei Zhong*

Main category: cs.AI

TL;DR: Helios는 스마트 에너지 도메인에 맞춤화된 대형 언어 모델로, 여러 자원을 통해 이러한 분야의 LLM 연구를 진전시킨다.


<details>
  <summary>Details</summary>
Motivation: 탄소 중립을 향한 글로벌 노력에서 스마트 에너지 시스템은 산업 변화를 지원하지만, 전공 지식과 물리적 제약 인식 부족으로 일반 LLM이 정확한 추론과 생성을 제공하지 못한다.

Method: Helios는 Enersys라는 다중 에이전트 협업 프레임워크를 통해 스마트 에너지 도메인에 맞춘 대형 언어 모델을 개발하며, EnerBase, EnerInstruct, EnerReinforce라는 세 가지 주요 자원을 포함한다.

Result: Helios는 이러한 자원을 활용하여 대규모 사전 학습, SFT 및 RLHF를 수행하였고, LLM의 도메인 지식 숙달과 작업 수행 정확성 및 인간 선호도에 대한 정렬을 크게 향상시켰다.

Conclusion: 우리는 EnerBench라는 스마트 에너지 시나리오에서 LLM을 평가하기 위한 벤치마크를 출시하였으며, 우리의 접근 방식이 중요한 개선을 이끌어낸다는 것을 증명하였다.

Abstract: In the global drive toward carbon neutrality, deeply coordinated smart energy systems underpin industrial transformation. However, the interdisciplinary, fragmented, and fast-evolving expertise in this domain prevents general-purpose LLMs, which lack domain knowledge and physical-constraint awareness, from delivering precise engineering-aligned inference and generation. To address these challenges, we introduce Helios, a large language model tailored to the smart energy domain, together with a comprehensive suite of resources to advance LLM research in this field. Specifically, we develop Enersys, a multi-agent collaborative framework for end-to-end dataset construction, through which we produce: (1) a smart energy knowledge base, EnerBase, to enrich the model's foundational expertise; (2) an instruction fine-tuning dataset, EnerInstruct, to strengthen performance on domain-specific downstream tasks; and (3) an RLHF dataset, EnerReinforce, to align the model with human preferences and industry standards. Leveraging these resources, Helios undergoes large-scale pretraining, SFT, and RLHF. We also release EnerBench, a benchmark for evaluating LLMs in smart energy scenarios, and demonstrate that our approach significantly enhances domain knowledge mastery, task execution accuracy, and alignment with human preferences.

</details>


### [59] [SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models](https://arxiv.org/abs/2512.19317)
*A. A. Gde Yogi Pramana,Jason Ray,Anthony Jaya,Michael Wijaya*

Main category: cs.AI

TL;DR: SafeMed-R1은 의료 시각 질문 응답에서의 일반화 성능을 유지하면서도 강력한 적대적 공격 방어 성능을 구현하는 새로운 하이브리드 방어 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 의료 환경에서의 사용을 위한 VLM의 저항력 부족 문제를 해결하고자 하였다.

Method: SafeMed-R1은 두 단계 접근법을 사용하여 훈련 시 적대적 훈련과 그룹 상대 정책 최적화(AT-GRPO)를 통합하고, 추론 시 랜다마이즈드 스무딩을 적용한다.

Result: SafeMed-R1은 적대적 조건에서도 84.45%의 정확도를 유지하며, 표준 모델보다 59% 포인트 개선된 내구성을 보였다.

Conclusion: 명시적 사고 과정을 통한 훈련된 모델이 해석 가능성과 보안을 동시에 강화함을 입증하였다.

Abstract: Vision--Language Models (VLMs) show significant promise for Medical Visual Question Answering (VQA), yet their deployment in clinical settings is hindered by severe vulnerability to adversarial attacks. Standard adversarial training, while effective for simpler tasks, often degrades both generalization performance and the quality of generated clinical reasoning. We introduce SafeMed-R1, a hybrid defense framework that ensures robust performance while preserving high-quality, interpretable medical reasoning. SafeMed-R1 employs a two-stage approach: at training time, we integrate Adversarial Training with Group Relative Policy Optimization (AT-GRPO) to explicitly robustify the reasoning process against worst-case perturbations; at inference time, we augment the model with Randomized Smoothing to provide certified $L_2$-norm robustness guarantees. We evaluate SafeMed-R1 on the OmniMedVQA benchmark across eight medical imaging modalities comprising over 88,000 samples. Our experiments reveal that standard fine-tuned VLMs, despite achieving 95\% accuracy on clean inputs, collapse to approximately 25\% under PGD attacks. In contrast, SafeMed-R1 maintains 84.45\% accuracy under the same adversarial conditions, representing a 59 percentage point improvement in robustness. Furthermore, we demonstrate that models trained with explicit chain-of-thought reasoning exhibit superior adversarial robustness compared to instruction-only variants, suggesting a synergy between interpretability and security in medical AI systems.

</details>


### [60] [EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration](https://arxiv.org/abs/2512.19396)
*Runze Li,Yuwen Zhai,Bo Xu,LiWu Xu,Nian Shi,Wei Zhang,Ran Lin,Liang Wang*

Main category: cs.AI

TL;DR: EchoTrail-GUI는 과거 성공 사례에서 학습하는 메커니즘을 제공함으로써 현대 GUI 에이전트의 한계를 극복하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 현대 GUI 에이전트는 각 작업을 독립적으로 처리하며, 과거의 성공으로부터 체계적으로 학습하는 메커니즘이 부족하여 성능이 저하되고 오류가 반복된다.

Method: EchoTrail-GUI는 에이전트에 동적이며 접근 가능한 메모리를 부여하여 사람과 유사한 경험 학습을 모방하도록 설계된 프레임워크로, 경험 탐색, 메모리 주입, GUI 작업 추론의 세 단계를 거친다.

Result: 실험 결과, EchoTrail-GUI는 Android World 및 AndroidLab을 포함한 벤치마크에서 작업 성공률과 운영 효율성을 유의미하게 개선하였다.

Conclusion: 구조화된 메모리의 힘이 더 강력하고 지능적인 GUI 자동화를 생성하는 데 기여함을 검증하였다.

Abstract: Contemporary GUI agents, while increasingly capable due to advances in Large Vision-Language Models (VLMs), often operate with a critical limitation: they treat each task in isolation, lacking a mechanism to systematically learn from past successes. This digital ''amnesia'' results in sub-optimal performance, repeated errors, and poor generalization to novel challenges. To bridge this gap, we introduce EchoTrail-GUI, a novel framework designed to mimic human-like experiential learning by equipping agents with a dynamic, accessible memory. Our framework operates in three distinct stages. First, during Experience Exploration, an agent autonomously interacts with GUI environments to build a curated database of successful task trajectories, validated by a reward model. Crucially, the entire knowledge base construction is thus fully automated, requiring no human supervision. Second, in the Memory Injection stage, upon receiving a new task, our system efficiently retrieves the most relevant past trajectories to serve as actionable ''memories''. Finally, during GUI Task Inference, these memories are injected as in-context guidance to inform the agent's reasoning and decision-making process. We demonstrate the efficacy of our approach on benchmarks including Android World and AndroidLab. The results show that EchoTrail-GUI significantly improves the task success rate and operational efficiency of baseline agents, validating the power of structured memory in creating more robust and intelligent GUI automation.

</details>


### [61] [An Agentic Framework for Autonomous Materials Computation](https://arxiv.org/abs/2512.19458)
*Zeyu Xia,Jinzhe Ma,Congjie Zheng,Shufei Zhang,Yuqiang Li,Hang Su,P. Hu,Changshui Zhang,Xingao Gong,Wanli Ouyang,Lei Bai,Dongzhan Zhou,Mao Su*

Main category: cs.AI

TL;DR: 이 연구는 LLM(대형 언어 모델)을 활용해 첫 번째 원칙 기반의 재료 계산을 신뢰성 있게 자동화하는 도메인 전문화 에이전트를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 지식 정적 특성과 환각 문제로 인해 자율 연구 응용에 제한이 있어, 이를 해결하기 위한 새로운 접근이 필요하다.

Method: 도메인 전문 지식을 내재화한 에이전트를 설계하여 복잡한 과학적 작업 흐름을 위한 검색, 추론, 도구 사용을 가능하게 했다.

Result: 우리는 이 시스템이 정확성과 강건성 모두에서 독립형 LLM보다 유의미하게 개선된 성과를 보여주는 다양한 계산 작업의 새로운 벤치마크를 제시하였다.

Conclusion: 이 연구는 자율 계산 실험을 위한 검증 가능한 기초를 구축하고, 완전 자동화된 과학적 발견을 향한 중요한 단계를 나타낸다.

Abstract: Large Language Models (LLMs) have emerged as powerful tools for accelerating scientific discovery, yet their static knowledge and hallucination issues hinder autonomous research applications. Recent advances integrate LLMs into agentic frameworks, enabling retrieval, reasoning, and tool use for complex scientific workflows. Here, we present a domain-specialized agent designed for reliable automation of first-principles materials computations. By embedding domain expertise, the agent ensures physically coherent multi-step workflows and consistently selects convergent, well-posed parameters, thereby enabling reliable end-to-end computational execution. A new benchmark of diverse computational tasks demonstrates that our system significantly outperforms standalone LLMs in both accuracy and robustness. This work establishes a verifiable foundation for autonomous computational experimentation and represents a key step toward fully automated scientific discovery.

</details>


### [62] [QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models](https://arxiv.org/abs/2512.19526)
*Li Puyin,Tiange Xiang,Ella Mao,Shirley Wei,Xinye Chen,Adnan Masood,Li Fei-fei,Ehsan Adeli*

Main category: cs.AI

TL;DR: QuantiPhy는 VLM의 물리적 추리 능력을 정량적으로 측정하기 위해 설계된 벤치마크로, 상태-of-the-art 비전 모델의 실제 성능을 평가하는 데 초점을 맞추고 있다.


<details>
  <summary>Details</summary>
Motivation: 일반 인공지능 에이전트가 물리적 세계를 이해하는 것은 필수적이지만, 최신 비전 인식 모델의 물리적 속성을 정량적으로 추론할 수 있는지 여부는 불확실하다.

Method: QuantiPhy는 3.3K 이상의 비디오-텍스트 사례로 구성되어 있으며, VLM이 특정 타임스탬프에서 객체의 크기, 속도 및 가속도를 추정하는 능력을 평가하기 위해 다양한 속성을 입력으로 사용한다.

Result: 최신 VLM에 대한 실험 결과는 정성적 타당성과 실제 수치의 정확성 간에 일관된 격차가 있음을 나타낸다.

Conclusion: QuantiPhy는 VLM이 단순한 언어적 타당성을 넘어 정량적으로 기반한 물리적 이해로 나아갈 수 있도록 하는 첫 번째 엄격하고 확장 가능한 테스트베드를 제공한다.

Abstract: Understanding the physical world is essential for generalist AI agents. However, it remains unclear whether state-of-the-art vision perception models (e.g., large VLMs) can reason physical properties quantitatively. Existing evaluations are predominantly VQA-based and qualitative, offering limited insight into whether these models can infer the kinematic quantities of moving objects from video observations. To address this, we present QuantiPhy, the first benchmark designed to quantitatively measure a VLM's physical reasoning ability. Comprising more than 3.3K video-text instances with numerical ground truth, QuantiPhy evaluates a VLM's performance on estimating an object's size, velocity, and acceleration at a given timestamp, using one of these properties as an input prior. The benchmark standardizes prompts and scoring to assess numerical accuracy, enabling fair comparisons across models. Our experiments on state-of-the-art VLMs reveal a consistent gap between their qualitative plausibility and actual numerical correctness. We further provide an in-depth analysis of key factors like background noise, counterfactual priors, and strategic prompting and find that state-of-the-art VLMs lean heavily on pre-trained world knowledge rather than faithfully using the provided visual and textual inputs as references when reasoning kinematic properties quantitatively. QuantiPhy offers the first rigorous, scalable testbed to move VLMs beyond mere verbal plausibility toward a numerically grounded physical understanding.

</details>


### [63] [Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios](https://arxiv.org/abs/2512.19551)
*Jiawen Wang,Jingjing Wang Tianyang Chen,Min Zhang,Guodong Zhou*

Main category: cs.AI

TL;DR: 이 논문은 LLM 중심의 평생 감정 모션 생성(L^2-EMG) 작업을 제안하여 다양한 미지의 시나리오에서 감정 모션 생성 지식을 지속적으로 습득하는 능력을 LLM에게 부여하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 인간 중심 감정 모션 생성 방법은 단일 스케일 고정 데이터셋 내에서의 성능 향상에 집중하고 있으며, 유연하고 스케일이 증가하는 모션 시나리오를 효과적으로 학습하는 것을 소홀히 하고 있다.

Method: 감정 전이 및 시나리오 적응 혼합 전문가(ES-MoE) 접근법을 제안하며, 이는 감정 분리를 위한 원인 안내 블록과 시나리오 적응 전문가 구성 블록을 설계하여 두 가지 주요 도전 과제를 해결한다.

Result: ES-MoE 방법이 다수의 L^2-EMG 데이터셋을 구성하여 그 효과성을 검증하고, 광범위한 평가에서 ES-MoE가 고급 기준보다 뛰어났음을 보여준다.

Conclusion: LLM이 공감 및 지능을 갖춘 자가 발전하는 체화된 에이전트를 구축하는 데 기여할 수 있을 것으로 기대된다.

Abstract: In the literature, existing human-centric emotional motion generation methods primarily focus on boosting performance within a single scale-fixed dataset, largely neglecting the flexible and scale-increasing motion scenarios (e.g., sports, dance), whereas effectively learning these newly emerging scenarios can significantly enhance the model's real-world generalization ability. Inspired by this, this paper proposes a new LLM-Centric Lifelong Empathic Motion Generation (L^2-EMG) task, which aims to equip LLMs with the capability to continually acquire emotional motion generation knowledge across different unseen scenarios, potentially contributing to building a closed-loop and self-evolving embodied agent equipped with both empathy and intelligence. Further, this paper poses two key challenges in the L^2-EMG task, i.e., the emotion decoupling challenge and the scenario adapting challenge. To this end, this paper proposes an Emotion-Transferable and Scenario-Adapted Mixture of Experts (ES-MoE) approach which designs a causal-guided emotion decoupling block and a scenario-adapted expert constructing block to address the two challenges, respectively. Especially, this paper constructs multiple L^2-EMG datasets to validate the effectiveness of the ES-MoE approach. Extensive evaluations show that ES-MoE outperforms advanced baselines.

</details>


### [64] [Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight](https://arxiv.org/abs/2512.19691)
*Junze Ye,Daniel Tawfik,Alex J. Goodell,Nikhil V. Kotha,Mark K. Buyyounouski,Mohsen Bayati*

Main category: cs.AI

TL;DR: 임상 위험 점수 계산의 자동화는 의사의 행정 부담을 줄이고 환자 치료를 개선할 수 있는 중요한 기회를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 임상 위험 점수 계산의 자동화는 의사의 행정 부담을 줄이고 환자 치료를 개선할 수 있는 중요한 기회를 제공합니다.

Method: 우리는 '진행 중인 살아있는 문서'로서 복잡한 작업을 위한 벤치마크를 보고, 의료진이 포함된 체계적인 파이프라인을 도입하여 MedCalc-Bench를 감사하고 재라벨링 합니다.

Result: 감사를 통해 원래 라벨의 상당 부분이 추출 오류, 계산기 논리 불일치 및 임상적 모호성으로 인해 의료적 실체와 달라짐을 발견했습니다. GRPO를 통한 Qwen3-8B 모델의 미세 조정 후, 수정된 라벨로 훈련한 결과 원래 기준 대비 8.7% 절대 정확도 향상이 나타났습니다.

Conclusion: 안전-critical 분야에서는 철저한 벤치마크 유지 관리가 진정한 모델 정렬을 위한 전제조건임을 강조합니다.

Abstract: Automating the calculation of clinical risk scores offers a significant opportunity to reduce physician administrative burden and enhance patient care. The current standard for evaluating this capability is MedCalc-Bench, a large-scale dataset constructed using LLM-based feature extraction and rule-based aggregation. However, treating such model-generated benchmarks as static oracles risks enshrining historical model errors as evaluation gold standards, a problem dangerously amplified when these datasets serve as reward signals for Reinforcement Learning (RL). In this work, we propose viewing benchmarks for complex tasks such as clinical score computation as ''in-progress living documents'' that should be periodically re-evaluated as the processes for creating them improve. We introduce a systematic, physician-in-the-loop pipeline that leverages advanced agentic verifiers to audit and relabel MedCalc-Bench, utilizing automated triage to reserve scarce clinician attention for the most contentious instances. Our audit reveals that a notable fraction of original labels diverge from medical ground truth due to extraction errors, calculator logic mismatches, and clinical ambiguity. To study whether this label noise meaningfully impacts downstream RL training, we fine-tune a Qwen3-8B model via Group Relative Policy Optimization (GRPO) and demonstrate that training on corrected labels yields an 8.7% absolute improvement in accuracy over the original baseline -- validating that label noise materially affects model evaluation. These findings underscore that in safety-critical domains, rigorous benchmark maintenance is a prerequisite for genuine model alignment.

</details>
