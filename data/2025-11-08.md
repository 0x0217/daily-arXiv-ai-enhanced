<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 3]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Security Analysis of Agentic AI Communication Protocols: A Comparative Evaluation](https://arxiv.org/abs/2511.03841)
*Yedidel Louck,Ariel Stulman,Amit Dvir*

Main category: cs.CR

TL;DR: 본 논문은 CORAL과 ACP 구현의 보안 분석을 통해 두 시스템 간의 명확한 보안 양극화를 발견하였다.


<details>
  <summary>Details</summary>
Motivation: 복잡하고 분산된 워크플로우에서 다중 에이전트 시스템(MAS)과 인공지능(AI)의 중요성이 증가하고 있지만, 이들의 통신 프로토콜 보안은 충분히 검토되지 않았다.

Method: 14점 취약성 분류 체계를 사용하여 CORAL 구현과 고충실도 SDK 기반 ACP 구현의 방어 수단을 인증, 권한 부여, 무결성, 기밀성 및 가용성 측면에서 체계적으로 평가하였다.

Result: CORAL은 강력한 아키텍처 설계를 보여주지만, 인증 및 권한 부여 실패와 같은 중요한 구현 취약점을 겪고 있으며, ACP는 선택적 JWS 시행으로 인해 높은 영향력을 미치는 무결성 및 기밀성 결함이 발생한다.

Conclusion: 기존 프로토콜이 부족한 보안을 유지하고 있으며, 향후 CORAL의 통합 아키텍처와 ACP의 필수 메시지 무결성 보장을 결합한 혼합 접근 방식을 추천한다.

Abstract: Multi-agent systems (MAS) powered by artificial intelligence (AI) are
increasingly foundational to complex, distributed workflows. Yet, the security
of their underlying communication protocols remains critically under-examined.
This paper presents the first empirical, comparative security analysis of the
official CORAL implementation and a high-fidelity, SDK-based ACP
implementation, benchmarked against a literature-based evaluation of A2A. Using
a 14 point vulnerability taxonomy, we systematically assess their defenses
across authentication, authorization, integrity, confidentiality, and
availability. Our results reveal a pronounced security dichotomy: CORAL
exhibits a robust architectural design, particularly in its transport-layer
message validation and session isolation, but suffers from critical
implementation-level vulnerabilities, including authentication and
authorization failures at its SSE gateway. Conversely, ACP's architectural
flexibility, most notably its optional JWS enforcement, translates into
high-impact integrity and confidentiality flaws. We contextualize these
findings within current industry trends, highlighting that existing protocols
remain insufficiently secure. As a path forward, we recommend a hybrid approach
that combines CORAL's integrated architecture with ACP's mandatory per-message
integrity guarantees, laying the groundwork for resilient, next-generation
agent communications.

</details>


### [2] [A Parallel Region-Adaptive Differential Privacy Framework for Image Pixelization](https://arxiv.org/abs/2511.04261)
*Ming Liu*

Main category: cs.CR

TL;DR: 이 논문은 비디오 기반 애플리케이션의 개인정보 보호 문제를 해결하기 위한 병렬 지역 적응형 픽셀화 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 고해상도 시각 센싱 시스템의 광범위한 배포와 기본 모델의 상승은 비디오 기반 애플리케이션의 개인정보 보호 위험을 증가시켰다.

Method: 이 방법은 지역 복잡성에 따라 그리드 크기와 노이즈 스케일을 적절하게 조정하고, GPU 병렬성을 활용하여 전통 기반과 비교해 상당한 실행 시간 가속을 달성한다.

Result: PETS, Venice-2 및 PPM-100 데이터셋에 대한 광범위한 실험은 개인정보 보호와 유용성 간의 유리한 절충안과 실행 시간/저장 공간의 상당한 감소를 입증한다.

Conclusion: 이 방법은 노인을 돌봄, 스마트 홈 모니터링, 운전 행동 분석 및 군중 행동 모니터링과 같은 실시간 개인정보 보호가 중요한 애플리케이션에 적합함을 확인한다.

Abstract: The widespread deployment of high-resolution visual sensing systems, coupled
with the rise of foundation models, has amplified privacy risks in video-based
applications. Differentially private pixelization offers mathematically
guaranteed protection for visual data through grid-based noise addition, but
challenges remain in preserving task-relevant fidelity, achieving scalability,
and enabling efficient real-time deployment. To address this, we propose a
novel parallel, region-adaptive pixelization framework that combines the
theoretical rigor of differential privacy with practical efficiency. Our method
adaptively adjusts grid sizes and noise scales based on regional complexity,
leveraging GPU parallelism to achieve significant runtime acceleration compared
to the classical baseline. A lightweight storage scheme is introduced by
retaining only essential noisy statistics, significantly reducing space
overhead. Formal privacy analysis is provided under the Laplace mechanism and
parallel composition theorem. Extensive experiments on the PETS, Venice-2, and
PPM-100 datasets demonstrate favorable privacy-utility trade-offs and
significant runtime/storage reductions. A face re-identification attack
experiment on CelebA further confirms the method's effectiveness in preventing
identity inference. This validates its suitability for real-time
privacy-critical applications such as elderly care, smart home monitoring,
driver behavior analysis, and crowd behavior monitoring.

</details>


### [3] [Exploiting Data Structures for Bypassing and Crashing Anti-Malware Solutions via Telemetry Complexity Attacks](https://arxiv.org/abs/2511.04472)
*Evgenios Gkritsis,Constantinos Patsakis,George Stergiopoulos*

Main category: cs.CR

TL;DR: 이 논문에서는 악성 코드 분석 플랫폼의 데이터 처리 구성 요소가 악용될 수 있는 공격 표면을 형성한다는 점을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 악성 코드 분석 시스템의 데이터 처리 구성 요소에 대해 이해하고 이를 악용하여 기본적인 수집 메커니즘과 처리 능력 간의 불일치를 이용하는 새로운 취약점 클래스를 제시하기 위함입니다.

Method: 우리의 방법은 자식 프로세스를 재귀적으로 생성하여 자잘하게 설계된 깊이 중첩되고 부풀려진 원거리 추적 수치를 생성하는 것입니다.

Result: 이로 인해 여러 상업용 및 오픈 소스 악성 코드 분석 플랫폼에서 다양한 규모의 문제를 발견했으며, 일부 제품에서는 CVE 식별자를 부여했습니다.

Conclusion: 따라서 우리는 센서를 피하는 대신, 센서가 캡처한 데이터를 저장하는 파이프라인을 파괴합니다.

Abstract: Anti-malware systems rely on sandboxes, hooks, and telemetry pipelines,
including collection agents, serializers, and database backends, to monitor
program and system behavior. We show that these data-handling components
constitute an exploitable attack surface that can lead to denial-of-analysis
(DoA) states without disabling sensors or requiring elevated privileges. As a
result, we present \textit{Telemetry Complexity Attacks} (TCAs), a new class of
vulnerabilities that exploit fundamental mismatches between unbounded
collection mechanisms and bounded processing capabilities. Our method
recursively spawns child processes to generate specially crafted, deeply
nested, and oversized telemetry that stresses serialization and storage
boundaries, as well as visualization layers, for example, JSON/BSON depth and
size limits. Depending on the product, this leads to truncated or missing
behavioral reports, rejected database inserts, serializer recursion and size
errors, and unresponsive dashboards. In all of these cases, malicious activity
is normally executed; however, depending on the examined solution, it is not
recorded and/or not presented to the analysts. Therefore, instead of evading
sensors, we break the pipeline that stores the data captured by the sensors.
  We evaluate our technique against twelve commercial and open-source malware
analysis platforms and endpoint detection and response (EDR) solutions. Seven
products fail in different stages of the telemetry pipeline; two vendors
assigned CVE identifiers (CVE-2025-61301 and CVE-2025-61303), and others issued
patches or configuration changes. We discuss root causes and propose mitigation
strategies to prevent DoA attacks triggered by adversarial telemetry.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [KnowThyself: An Agentic Assistant for LLM Interpretability](https://arxiv.org/abs/2511.03878)
*Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang*

Main category: cs.AI

TL;DR: KnowThyself는 대형 언어 모델(LLM) 해석 가능성을 향상시키는 에이전트 보조 도구이다.


<details>
  <summary>Details</summary>
Motivation: 기존 도구들은 유용한 통찰을 제공하지만, 파편화되어 있고 코드 집약적이다.

Method: KnowThyself는 채팅 기반 인터페이스로 이러한 기능을 통합하고, 사용자가 모델을 업로드하고 자연어 질문을 제기하며, 가이드된 설명과 함께 상호작용형 시각화를 얻을 수 있도록 한다.

Result: 코어에는 사용자의 쿼리를 재구성하는 오케스트레이터 LLM이 있으며, 에이전트 라우터가 이를 전문 모듈로 추가 안내하고, 출력은 일관된 설명으로 맥락화된다.

Conclusion: 이러한 설계는 기술 장벽을 낮추고 LLM 검사를 위한 확장 가능한 플랫폼을 제공하며, 대화형 워크플로로 전체 프로세스를 통합하여 일반 사용자를 위한 강력한 기초를 제공한다.

Abstract: We develop KnowThyself, an agentic assistant that advances large language
model (LLM) interpretability. Existing tools provide useful insights but remain
fragmented and code-intensive. KnowThyself consolidates these capabilities into
a chat-based interface, where users can upload models, pose natural language
questions, and obtain interactive visualizations with guided explanations. At
its core, an orchestrator LLM first reformulates user queries, an agent router
further directs them to specialized modules, and the outputs are finally
contextualized into coherent explanations. This design lowers technical
barriers and provides an extensible platform for LLM inspection. By embedding
the whole process into a conversational workflow, KnowThyself offers a robust
foundation for accessible LLM interpretability.

</details>


### [5] [Scaling Agent Learning via Experience Synthesis](https://arxiv.org/abs/2511.03773)
*Zhaorun Chen,Zhuokai Zhao,Kai Zhang,Bo Liu,Qi Qi,Yifan Wu,Tarun Kalluri,Sara Cao,Yuanhao Xiong,Haibo Tong,Huaxiu Yao,Hengduo Li,Jiacheng Zhu,Xian Li,Dawn Song,Bo Li,Jason Weston,Dat Huynh*

Main category: cs.AI

TL;DR: DreamGym은 다양한 경험을 합성하여 효과적인 온라인 강화 학습(RL) 훈련을 가능하게 하는 첫 번째 통합 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습(RL)의 실용적 채택은 비용이 많이 드는 롤아웃, 제한된 작업 다양성, 신뢰할 수 없는 보상 신호, 인프라 복잡성으로 인해 어려움을 겪고 있다.

Method: DreamGym은 환경 동력을 Reasoning 기반 경험 모델로 증류하여 일관된 상태 전이 및 피드백 신호를 도출하고, 경험 재생 버퍼를 활용하여 에이전트 훈련을 지원한다.

Result: 다양한 환경 및 에이전트 백본에서 DreamGym은 RL 훈련을 획기적으로 개선하며, 비 RL 준비 작업에서는 모든 기준선을 30% 이상 초과하고, RL 준비지만 비용이 높은 설정에서도 GRPO 및 PPO 성능을 통합적으로 맞춘다.

Conclusion: DreamGym은 진정한 환경 RL로 순수하게 합성 경험에서 훈련된 정책을 전이할 때 큰 성능 향상을 제공하고, 훨씬 적은 실제 상호작용을 요구하여 일반 목적의 RL을 위한 확장 가능한 웜 스타트 전략을 제공한다.

Abstract: While reinforcement learning (RL) can empower large language model (LLM)
agents by enabling self-improvement through interaction, its practical adoption
remains challenging due to costly rollouts, limited task diversity, unreliable
reward signals, and infrastructure complexity, all of which obstruct the
collection of scalable experience data. To address these challenges, we
introduce DreamGym, the first unified framework designed to synthesize diverse
experiences with scalability in mind to enable effective online RL training for
autonomous agents. Rather than relying on expensive real-environment rollouts,
DreamGym distills environment dynamics into a reasoning-based experience model
that derives consistent state transitions and feedback signals through
step-by-step reasoning, enabling scalable agent rollout collection for RL. To
improve the stability and quality of transitions, DreamGym leverages an
experience replay buffer initialized with offline real-world data and
continuously enriched with fresh interactions to actively support agent
training. To improve knowledge acquisition, DreamGym adaptively generates new
tasks that challenge the current agent policy, enabling more effective online
curriculum learning. Experiments across diverse environments and agent
backbones demonstrate that DreamGym substantially improves RL training, both in
fully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready
tasks like WebArena, DreamGym outperforms all baselines by over 30%. And in
RL-ready but costly settings, it matches GRPO and PPO performance using only
synthetic interactions. When transferring a policy trained purely on synthetic
experiences to real-environment RL, DreamGym yields significant additional
performance gains while requiring far fewer real-world interactions, providing
a scalable warm-start strategy for general-purpose RL.

</details>


### [6] [When Empowerment Disempowers](https://arxiv.org/abs/2511.04177)
*Claire Yang,Maya Cakmak,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 이 논문은 AI 보조 행동에 대한 동기 부여를 위해 에이전트의 환경 통제 능력인 '임파워먼트'의 개념을 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 다수의 인간이 있는 환경에서 AI가 적절히 작동하도록 하기 위한 새로운 접근 방식을 제시하고자 합니다.

Method: Disempower-Grid라는 오픈 소스 다인용 격자 세계 테스트 스위트를 사용하여 연구를 수행했습니다.

Result: 일부 인간을 최적화하는 보조 RL 에이전트가 다른 인간의 환경 영향력을 상당히 감소시키고 보상을 줄이는 현상을 발견했습니다.

Conclusion: 단일 에이전트 설정에서는 정렬된 것처럼 보이는 목표가 다수의 에이전트 контекст에서는 비정렬될 수 있다는 것을 강조합니다.

Abstract: Empowerment, a measure of an agent's ability to control its environment, has
been proposed as a universal goal-agnostic objective for motivating assistive
behavior in AI agents. While multi-human settings like homes and hospitals are
promising for AI assistance, prior work on empowerment-based assistance assumes
that the agent assists one human in isolation. We introduce an open source
multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we
empirically show that assistive RL agents optimizing for one human's
empowerment can significantly reduce another human's environmental influence
and rewards - a phenomenon we formalize as disempowerment. We characterize when
disempowerment occurs in these environments and show that joint empowerment
mitigates disempowerment at the cost of the user's reward. Our work reveals a
broader challenge for the AI alignment community: goal-agnostic objectives that
seem aligned in single-agent settings can become misaligned in multi-agent
contexts.

</details>


### [7] [To See or To Read: User Behavior Reasoning in Multimodal LLMs](https://arxiv.org/abs/2511.03845)
*Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: MLLM에서 사용자 행동 데이터의 텍스트와 이미지 표현의 효과를 비교하는 새로운 벤치마크 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: MLLM이 사용자 행동 데이터를 처리하는 방식을 더욱 효과적으로 이해하고 개선하기 위한 필요성을 강조합니다.

Method: 사용자 행동 추론에서의 모달리티 트레이드오프를 평가하기 위해 거래 데이터를 텍스트 문단, 산점도, 흐름도로 표현하는 체계적인 벤치마킹 프레임워크인 BehaviorLens를 제시합니다.

Result: 실제 구매 순서 데이터셋을 사용하여 이미지로 표현할 때 MLLM의 다음 구매 예측 정확도가 텍스트 표현에 비해 87.5% 향상되었음을 발견했습니다.

Conclusion: 추가적인 계산 비용 없이도 이미지 표현이 MLLM 성능을 극대화하는 데 효과적임을 보여줍니다.

Abstract: Multimodal Large Language Models (MLLMs) are reshaping how modern agentic
systems reason over sequential user-behavior data. However, whether textual or
image representations of user behavior data are more effective for maximizing
MLLM performance remains underexplored. We present \texttt{BehaviorLens}, a
systematic benchmarking framework for assessing modality trade-offs in
user-behavior reasoning across six MLLMs by representing transaction data as
(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a
real-world purchase-sequence dataset, we find that when data is represented as
images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared
with an equivalent textual representation without any additional computational
cost.

</details>


### [8] [DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2511.04646)
*Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: DR. WELL은 협력적 다중 에이전트 계획을 위한 탈중앙화된 신경기호적 프레임워크로, 에이전트들이 부분 정보와 제한된 통신으로 공동 결정을 내릴 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 협력적 다중 에이전트 계획에서 에이전트는 부분 정보와 제한된 통신 하에 공동 결정을 내려야 하며, 이는 보통 조정 실패로 이어진다.

Method: DR. WELL은 에이전트들이 역할을 제안하고 합의 및 환경 제약에 따라 공동 할당에 동의하는 두 단계 협상 프로토콜을 통해 협력을 전개하도록 한다. 각 에이전트는 세부 경로를 공개하지 않고 역할에 대한 기호 계획을 독립적으로 생성하고 실행한다.

Result: 협력적 블록 밀기 작업 실험에서 에이전트는 에피소드 간에 적응하며, 동적 세계 모델이 재사용 가능한 패턴을 캡처해 작업 완료율과 효율성을 개선하였다.

Conclusion: 동적 세계 모델은 협상과 자기 개선을 통해 작업 완료 및 효율성을 향상시키며, 시간 오버헤드를 거래하여 더 진화된, 효율적인 협력 전략을 생성하도록 한다.

Abstract: Cooperative multi-agent planning requires agents to make joint decisions with
partial information and limited communication. Coordination at the trajectory
level often fails, as small deviations in timing or movement cascade into
conflicts. Symbolic planning mitigates this challenge by raising the level of
abstraction and providing a minimal vocabulary of actions that enable
synchronization and collective progress. We present DR. WELL, a decentralized
neurosymbolic framework for cooperative multi-agent planning. Cooperation
unfolds through a two-phase negotiation protocol: agents first propose
candidate roles with reasoning and then commit to a joint allocation under
consensus and environment constraints. After commitment, each agent
independently generates and executes a symbolic plan for its role without
revealing detailed trajectories. Plans are grounded in execution outcomes via a
shared world model that encodes the current state and is updated as agents act.
By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids
brittle step-level alignment and enables higher-level operations that are
reusable, synchronizable, and interpretable. Experiments on cooperative
block-push tasks show that agents adapt across episodes, with the dynamic world
model capturing reusable patterns and improving task completion rates and
efficiency. Experiments on cooperative block-push tasks show that our dynamic
world model improves task completion and efficiency through negotiation and
self-refinement, trading a time overhead for evolving, more efficient
collaboration strategies.

</details>


### [9] [ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering](https://arxiv.org/abs/2511.03985)
*Zhuowen Yuan,Tao Liu,Yang Yang,Yang Wang,Feng Qi,Kaushik Rangadurai,Bo Li,Shuang Yang*

Main category: cs.AI

TL;DR: ArchPilot는 자동 ML 엔지니어링을 위한 효율적인 다중 에이전트 시스템으로, 전체 훈련을 최소화하여 높은 잠재력의 후보를 우선시할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 최근 LLM 기반 에이전트가 자동 ML 엔지니어링에서 강력한 능력을 보여주고 있지만, 후보 솔루션을 평가하기 위해 반복적인 전체 훈련 실행에 의존하여 계산 비용이 크고 대규모 검색 공간에 대한 확장성이 제한되고 반복 사이클이 느리다.

Method: ArchPilot는 아키텍처 생성, 프록시 기반 평가 및 적응형 검색을 통합한 다중 에이전트 시스템으로 구성되어 있으며, 세 가지 특수화된 에이전트로 이루어져 있다: 몬테카를로 트리 검색(MCTS)에서 영감을 받은 새로운 알고리즘으로 검색 프로세스를 조정하는 조정 에이전트, 후보 아키텍처를 반복적으로 생성하고 개선하며 디버그하는 생성 에이전트, 프록시 훈련 실행을 수행하고 프록시 점수를 집계하여 성능 지표를 생성하는 평가 에이전트.

Result: MLE-Bench에서의 실험 결과 ArchPilot는 AIDE 및 ML-Master와 같은 SOTA 기준을 초월하며 다중 에이전트 시스템의 효과를 입증한다.

Conclusion: ArchPilot를 통해 제한된 예산 하에서도 효율적인 ML 엔지니어링이 가능해졌다.

Abstract: Recent LLM-based agents have demonstrated strong capabilities in automated ML
engineering. However, they heavily rely on repeated full training runs to
evaluate candidate solutions, resulting in significant computational overhead,
limited scalability to large search spaces, and slow iteration cycles. To
address these challenges, we introduce ArchPilot, a multi-agent system that
integrates architecture generation, proxy-based evaluation, and adaptive search
into a unified framework. ArchPilot consists of three specialized agents: an
orchestration agent that coordinates the search process using a Monte Carlo
Tree Search (MCTS)-inspired novel algorithm with a restart mechanism and
manages memory of previous candidates; a generation agent that iteratively
generates, improves, and debugs candidate architectures; and an evaluation
agent that executes proxy training runs, generates and optimizes proxy
functions, and aggregates the proxy scores into a fidelity-aware performance
metric. This multi-agent collaboration allows ArchPilot to prioritize
high-potential candidates with minimal reliance on expensive full training
runs, facilitating efficient ML engineering under limited budgets. Experiments
on MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE
and ML-Master, validating the effectiveness of our multi-agent system.

</details>


### [10] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: 멀티 에이전틱 AI 시스템에서 이상 감지 작업을 도입하고, 사용자 행동 및 LLM 변화를 포착하는 데이터셋 큐레이션 파이프라인을 제시하여, 두 개의 벤치마크 데이터셋을 구축하였으며, 이상 감지 방법의 성능을 평가하여 높은 정확도를 달성했다.


<details>
  <summary>Details</summary>
Motivation: 멀티 에이전틱 AI 시스템의 비결정성과 이러한 시스템에서 발생하는 감지하기 어려운 오류를 해결하고자 함.

Method: 사용자 행동, 에이전트 비결정성 및 LLM 변화를 포착하는 데이터셋 큐레이션 파이프라인을 사용하여 두 개의 벤치마크 데이터셋을 큐레이션하고 라벨링함. 이상 감지 방법으로는 감독 학습(XGBoost) 및 반감독 학습(SVDD)을 사용함.

Result: 이상 감지 방법을 평가한 결과, 감독 학습(XGBoost)과 반감독 학습(SVDD) 접근이 각각 최대 98%와 96%의 정확도로 비슷한 성능을 보임.

Conclusion: 이 연구는 멀티 에이전틱 AI 시스템에서의 이상 감지에 대한 최초의 체계적인 연구를 제공하며, 향후 연구를 안내할 데이터셋, 벤치마크 및 통찰을 제시함.

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [11] [Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents](https://arxiv.org/abs/2511.04076)
*Hao Li,Haotian Chen,Ruoyuan Gong,Juanjuan Wang,Hao Jiang*

Main category: cs.AI

TL;DR: Agentmandering은 상반되는 정치적 이해관계를 대변하는 두 요원 간의 턴제 협상으로 재구성하여 재구획을 수행하는 방법론이다.


<details>
  <summary>Details</summary>
Motivation: 재구획 과정에서 전략적 동역학이 간과되는 문제를 해결하고자 한다.

Method: 대형 언어 모델(LLM) 요원을 이용하여 전략적 상호작용을 재구획 과정에 결합하는 방법이다.

Result: Agentmandering은 정당 편향성과 불공정을 크게 줄이고, 표준 기준보다 2~3배 낮은 분산을 달성하였다.

Conclusion: 이 결과는 공정성과 안정성을 동시에 보여주며, 특히 경합 주에서 효과적이다.

Abstract: Redistricting plays a central role in shaping how votes are translated into
political power. While existing computational methods primarily aim to generate
large ensembles of legally valid districting plans, they often neglect the
strategic dynamics involved in the selection process. This oversight creates
opportunities for partisan actors to cherry-pick maps that, while technically
compliant, are politically advantageous. Simply satisfying formal constraints
does not ensure fairness when the selection process itself can be manipulated.
We propose \textbf{Agentmandering}, a framework that reimagines redistricting
as a turn-based negotiation between two agents representing opposing political
interests. Drawing inspiration from game-theoretic ideas, particularly the
\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction
into the redistricting process via large language model (LLM) agents. Agents
alternate between selecting and freezing districts from a small set of
candidate maps, gradually partitioning the state through constrained and
interpretable choices. Evaluation on post-2020 U.S. Census data across all
states shows that Agentmandering significantly reduces partisan bias and
unfairness, while achieving 2 to 3 orders of magnitude lower variance than
standard baselines. These results demonstrate both fairness and stability,
especially in swing-state scenarios. Our code is available at
https://github.com/Lihaogx/AgentMandering.

</details>


### [12] [Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms](https://arxiv.org/abs/2511.04133)
*Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel*

Main category: cs.AI

TL;DR: 본 논문은 음성 AI 테스트 품질을 평가하기 위한 최초의 체계적인 프레임워크를 제시하며, 이를 통해 테스트의 신뢰성을 높이고 대규모 상용 배포를 위한 기초 측정 기반을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 음성 AI 에이전트가 생산 배포로 빠르게 전환되고 있지만, 테스트 신뢰성을 보장하기 위한 체계적인 방법이 부족합니다.

Method: 이 프레임워크는 현실적인 테스트 대화를 생성하는 시뮬레이션 품질과 에이전트 반응을 정확하게 평가하는 평가 품질이라는 두 가지 기본적인 도전 과제를 해결합니다. 심리 측정 기법과 엄격한 통계 검증을 결합하여 모든 테스트 접근 방식에 적용 가능한 재현 가능한 메트릭스를 제공합니다.

Result: 3개의 상업 플랫폼에 대한 포괄적인 실증 평가를 통해 제안된 프레임워크가 통계적으로 유의미한 성과 차이를 드러내며, Evalion 플랫폼이 f1-score로 0.92의 평가 품질을 달성한 반면, 다른 플랫폼은 0.73을 기록하였습니다.

Conclusion: 이 프레임워크는 연구자와 조직이 어떤 플랫폼의 테스트 능력을 경험적으로 검증할 수 있도록 하여, 대규모 음성 AI 배포를 위한 필수 측정 기초를 제공합니다.

Abstract: Voice AI agents are rapidly transitioning to production deployments, yet
systematic methods for ensuring testing reliability remain underdeveloped.
Organizations cannot objectively assess whether their testing approaches
(internal tools or external platforms) actually work, creating a critical
measurement gap as voice AI scales to billions of daily interactions.
  We present the first systematic framework for evaluating voice AI testing
quality through human-centered benchmarking. Our methodology addresses the
fundamental dual challenge of testing platforms: generating realistic test
conversations (simulation quality) and accurately evaluating agent responses
(evaluation quality). The framework combines established psychometric
techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence
intervals, and permutation tests) with rigorous statistical validation to
provide reproducible metrics applicable to any testing approach.
  To validate the framework and demonstrate its utility, we conducted
comprehensive empirical evaluation of three leading commercial platforms
focused on Voice AI Testing using 21,600 human judgments across 45 simulations
and ground truth validation on 60 conversations. Results reveal statistically
significant performance differences with the proposed framework, with the
top-performing platform, Evalion, achieving 0.92 evaluation quality measured as
f1-score versus 0.73 for others, and 0.61 simulation quality using a league
based scoring system (including ties) vs 0.43 for other platforms.
  This framework enables researchers and organizations to empirically validate
the testing capabilities of any platform, providing essential measurement
foundations for confident voice AI deployment at scale. Supporting materials
are made available to facilitate reproducibility and adoption.

</details>


### [13] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 다중 에이전트 시스템에서 일관된 공간 기억을 공유하고 재구성하는 것은 중요한 도전 과제입니다. 본 논문에서는 에이전트 간의 상호 불확실성을 최소화하여 조정을 형성하는 다중 에이전트 예측 코딩 프레임워크를 소개합니다. 이를 통해 에이전트는 통신할 대상과 시기를 학습하게 됩니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 부분 관측성과 제한된 대역폭은 조정에서 치명적인 실패를 초래할 수 있습니다. 일관된 공간 기억을 공유하고 재구성하는 것은 중요한 문제입니다.

Method: 우리는 상호 불확실성을 최소화하는 정보 병목 목표로 구체화된 다중 에이전트 예측 코딩 프레임워크를 도입합니다. 이 프레임워크의 기초에는 자기 위치 추정을 위한 내부 공간 코딩으로서 그리드 셀 유사 메트릭이 자리잡고 있으며, 이는 자기 감독된 움직임 예측에서 자발적으로 나타납니다.

Result: 메모리 메이즈 벤치마크에서 우리의 접근법은 대역폭 제약에 대해 예외적인 탄력성을 보여주며, 성공률이 대역폭이 128에서 4 비트/스텝으로 줄어들 때 73.5%에서 64.4%로 감소하지만, 전체 브로드캐스트 기준선은 67.6%에서 28.6%로 급격히 하락합니다.

Conclusion: 우리의 연구 결과는 복합 사회적 표현이 통합된 예측 구동에서 어떻게 발생하는지를 이론적으로 정립된 생물학적 타당성을 기반으로 제시하고, 사회적 집단 지능으로 이어지는 것을 보여줍니다.

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [14] [GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents](https://arxiv.org/abs/2511.04307)
*Jian Mu,Chaoyun Zhang,Chiming Ni,Lu Wang,Bo Qiao,Kartik Mathur,Qianhui Wu,Yuhang Xie,Xiaojun Ma,Mengyu Zhou,Si Qin,Liqun Li,Yu Kang,Minghua Ma,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: GUI-360°는 컴퓨터를 사용하는 에이전트(CUA)를 발전시키기 위해 설계된 대규모 데이터셋 및 벤치마크 모음이다.


<details>
  <summary>Details</summary>
Motivation: CUA는 실제 과제가 부족하고, 다중 모드 궤적을 위한 자동 수집 및 주석 파이프라인이 결여되어 있으며, GUI 기초, 화면 파싱 및 행동 예측을 공동으로 평가하는 통합 벤치마크가 없다는 세 가지 지속적인 격차로 인해 고유한 도전 과제를 제시한다.

Method: GUI-360°는 쿼리 소싱, 환경 템플릿 구축, 작업 구현, 일괄 실행 및 LLM 기반 품질 필터링을 위한 LLM 보강, 주로 자동화된 파이프라인을 통해 이러한 격차를 해결한다.

Result: 이 데이터셋은 수천 개의 궤적에 걸쳐 인기 있는 Windows 오피스 애플리케이션에서 실행된 120만 개 이상의 행동 단계를 포함하며, 전체 해상도 스크린샷, 가능한 경우 접근성 메타데이터, 구현된 목표, 중간 추론 흔적 및 성공 및 실패한 행동 궤적이 포함된다.

Conclusion: 최신 비전-언어 모델을 GUI-360°에서 벤치마킹한 결과, 기초 및 행동 예측에서 상당한 출발점 결함이 드러났고, 감독된 미세 조정과 강화 학습이 상당한 이익을 가져왔지만 인간 수준의 신뢰성에는 미치지 못했다.

Abstract: We introduce GUI-360$^\circ$, a large-scale, comprehensive dataset and
benchmark suite designed to advance computer-using agents (CUAs). CUAs present
unique challenges and is constrained by three persistent gaps: a scarcity of
real-world CUA tasks, the lack of automated collection-and-annotation pipelines
for multi-modal trajectories, and the absence of a unified benchmark that
jointly evaluates GUI grounding, screen parsing, and action prediction.
  GUI-360$^\circ$ addresses these gaps with an LLM-augmented, largely automated
pipeline for query sourcing, environment-template construction, task
instantiation, batched execution, and LLM-driven quality filtering. The
released corpus contains over 1.2M executed action steps across thousands of
trajectories in popular Windows office applications, and includes
full-resolution screenshots, accessibility metadata when available,
instantiated goals, intermediate reasoning traces, and both successful and
failed action trajectories. The dataset supports three canonical tasks, GUI
grounding, screen parsing, and action prediction, and a hybrid GUI+API action
space that reflects modern agent designs. Benchmarking state-of-the-art
vision--language models on GUI-360$^\circ$ reveals substantial out-of-the-box
shortcomings in grounding and action prediction; supervised fine-tuning and
reinforcement learning yield significant gains but do not close the gap to
human-level reliability. We release GUI-360$^\circ$ and accompanying code to
facilitate reproducible research and accelerate progress on robust desktop
CUAs.
  The full dataset has been made public on
https://huggingface.co/datasets/vyokky/GUI-360.

</details>


### [15] [Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach](https://arxiv.org/abs/2511.04393)
*Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)을 활용한 의사결정이 가능하지만, 이들은 기본적인 온라인 의사결정 문제에서도 어려움을 겪고 있다. 본 연구에서는 Iterative Regret-Minimization Fine-Tuning (Iterative RMFT)라는 후속 훈련 절차를 소개하며, 이를 통해 LLM의 의사결정 능력을 향상시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 상호작용적이고 동적인 환경에서 의사결정을 수행하기 위한 "대리인"으로 사용되고 있지만, 기본적인 의사결정 문제에서 어려움을 겪고 있다는 점에서 출발하였다.

Method: Iterative Regret-Minimization Fine-Tuning (Iterative RMFT)라는 후속 훈련 절차를 도입하여, 저급 후회 의사결정 경로를 반복적으로 기본 모델에 증류한다. 각 반복에서 모델은 여러 의사결정 경로를 생성하고, 후회가 가장 낮은 경로를 선택하여 이를 기반으로 자신을 미세 조정한다.

Result: Empirical results show that Iterative RMFT improves LLMs' DM performance across diverse models.

Conclusion: Iterative RMFT는 LLM의 의사결정 능력을 향상시키기 위한 원칙적이고 일반적인 후속 훈련 프레임워크를 제공한다.

Abstract: Large language models (LLMs) are increasingly deployed as "agents" for
decision-making (DM) in interactive and dynamic environments. Yet, since they
were not originally designed for DM, recent studies show that LLMs can struggle
even in basic online DM problems, failing to achieve low regret or an effective
exploration-exploitation tradeoff. To address this, we introduce Iterative
Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure
that repeatedly distills low-regret decision trajectories back into the base
model. At each iteration, the model rolls out multiple decision trajectories,
selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior
methods that (a) distill action sequences from known DM algorithms or (b) rely
on manually crafted chain-of-thought templates, our approach leverages the
regret metric to elicit the model's own DM ability and reasoning rationales.
This reliance on model-generated reasoning avoids rigid output engineering and
provides more flexible, natural-language training signals. Empirical results
show that Iterative RMFT improves LLMs' DM performance across diverse models -
from Transformers with numerical input/output, to open-weight LLMs, and
advanced closed-weight models like GPT-4o mini. Its flexibility in output and
reasoning formats enables generalization across tasks with varying horizons,
action spaces, reward processes, and natural-language contexts. Finally, we
provide theoretical insight showing that a single-layer Transformer under this
paradigm can act as a no-regret learner in a simplified setting. Overall,
Iterative RMFT offers a principled and general post-training framework for
enhancing LLMs' decision-making capabilities.

</details>


### [16] [Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context](https://arxiv.org/abs/2511.04464)
*Carnot Braun,Rafael O. Jarczewski,Gabriel U. Talasso,Leandro A. Villas,Allan M. de Souza*

Main category: cs.AI

TL;DR: 전통적인 차량 경로 시스템은 시간이나 거리 같은 단일 지표를 최적화하는 데 효율적이지만, 복수 지표를 고려할 경우 더 많은 과정이 필요하다. 이 논문은 맥락적 추론을 통해 고전적인 경로 탐색 알고리즘을 보강하도록 설계된 하이브리드 에이전트 보조 도구인 PAVe(개인화된 자율 차량 경로 결정)를 소개하고 평가한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 차량 경로 시스템은 복합적인 인간 운전자의 맥락을 효과적으로 통합하거나 해석할 수 있는 능력이 부족하다.

Method: 이 논문은 다중 목표(시간, CO2) 다익스트라 알고리즘으로 생성된 후보 경로 세트에서 작동하는 대형 언어 모델(LLM) 에이전트를 사용하여 사용자 제공 작업, 선호도 및 회피 규칙에 대해 이러한 옵션을 평가한다.

Result: PAVe는 현실적인 도시 시나리오의 기준 테스트에서 복잡한 사용자 의도를 적절한 경로 수정으로 성공적으로 사용하며 초기 경로 선택에서 88% 이상의 정확도를 달성했다.

Conclusion: 고전적인 경로 알고리즘과 LLM 기반의 의미적 추론 레이어를 결합하는 것은 도시 모빌리티 최적화를 위한 개인화되고 적응 가능하며 확장 가능한 솔루션을 만들기 위한 강력하고 효과적인 접근 방식이다.

Abstract: Traditional vehicle routing systems efficiently optimize singular metrics
like time or distance, and when considering multiple metrics, they need more
processes to optimize . However, they lack the capability to interpret and
integrate the complex, semantic, and dynamic contexts of human drivers, such as
multi-step tasks, situational constraints, or urgent needs. This paper
introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a
hybrid agentic assistant designed to augment classical pathfinding algorithms
with contextual reasoning. Our approach employs a Large Language Model (LLM)
agent that operates on a candidate set of routes generated by a multi-objective
(time, CO2) Dijkstra algorithm. The agent evaluates these options against
user-provided tasks, preferences, and avoidance rules by leveraging a
pre-processed geospatial cache of urban Points of Interest (POIs). In a
benchmark of realistic urban scenarios, PAVe successfully used complex user
intent into appropriate route modifications, achieving over 88% accuracy in its
initial route selections with a local model. We conclude that combining
classical routing algorithms with an LLM-based semantic reasoning layer is a
robust and effective approach for creating personalized, adaptive, and scalable
solutions for urban mobility optimization.

</details>


### [17] [Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper](https://arxiv.org/abs/2511.04583)
*Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa*

Main category: cs.AI

TL;DR: Jr. AI Scientist는 초보 연구자의 연구 과정을 모방하여 AI 기반 과학적 기여를 향상시키는 자율형 AI 시스템이다.


<details>
  <summary>Details</summary>
Motivation: AI 과학자 시스템의 현재 능력과 위험을 이해하는 것은 신뢰할 수 있고 지속 가능한 AI 기반 과학적 발전을 보장하는 데 필수적이다.

Method: Jr. AI Scientist는 인간 멘토의 기초 논문을 바탕으로 한 후, 한계를 분석하고, 개선을 위한 새로운 가설을 제시하며, 엄격한 실험을 통해 검증하고, 결과를 바탕으로 논문을 작성하는 연구 워크플로우를 적용한다.

Result: Jr. AI Scientist는 기존의 완전 자동화 시스템보다 높은 리뷰 점수를 받으며, AI Reviewers를 이용한 자동 평가와 저자 주도의 평가를 실시했다.

Conclusion: 현재 AI 과학자 시스템을 직접 적용할 경우의 잠재적 위험과 향후 연구의 주요 도전을 나타내는 중요한 한계를 식별했다.

Abstract: Understanding the current capabilities and risks of AI Scientist systems is
essential for ensuring trustworthy and sustainable AI-driven scientific
progress while preserving the integrity of the academic ecosystem. To this end,
we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system
that mimics the core research workflow of a novice student researcher: Given
the baseline paper from the human mentor, it analyzes its limitations,
formulates novel hypotheses for improvement, validates them through rigorous
experimentation, and writes a paper with the results. Unlike previous
approaches that assume full automation or operate on small-scale code, Jr. AI
Scientist follows a well-defined research workflow and leverages modern coding
agents to handle complex, multi-file implementations, leading to scientifically
valuable contributions. For evaluation, we conducted automated assessments
using AI Reviewers, author-led evaluations, and submissions to Agents4Science,
a venue dedicated to AI-driven scientific contributions. The findings
demonstrate that Jr. AI Scientist generates papers receiving higher review
scores than existing fully automated systems. Nevertheless, we identify
important limitations from both the author evaluation and the Agents4Science
reviews, indicating the potential risks of directly applying current AI
Scientist systems and key challenges for future research. Finally, we
comprehensively report various risks identified during development. We hope
these insights will deepen understanding of current progress and risks in AI
Scientist development.

</details>


### [18] [Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis](https://arxiv.org/abs/2511.04481)
*Lars Krupp,Daniel Geißler,Vishal Banwari,Paul Lukowicz,Jakob Karolus*

Main category: cs.AI

TL;DR: 웹 에이전트의 에너지 및 CO2 비용을 조사하여 지속 가능성 문제의 긴급성을 강조함.


<details>
  <summary>Details</summary>
Motivation: 웹 에이전트 연구는 활발하지만 지속 가능성 문제는 대부분 탐구되지 않았다.

Method: 이론적 추정과 벤치마킹을 통해 웹 에이전트와 관련된 에너지 및 CO2 비용을 탐색함.

Result: 웹 에이전트 생성의 철학이 소비 에너지에 중대한 영향을 미친다는 것을 보여줌.

Conclusion: 모델 매개변수 및 프로세스의 투명성 부족이 에너지 소비 추정에 제약 요인임을 강조하며, 웹 에이전트를 평가하는 방식을 변화시킬 필요가 있다.

Abstract: Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful
agentic systems pushing the boundaries of Large Language Models (LLM). They can
autonomously interact with the internet at the user's behest, such as
navigating websites, filling search masks, and comparing price lists. Though
web agent research is thriving, induced sustainability issues remain largely
unexplored. To highlight the urgency of this issue, we provide an initial
exploration of the energy and $CO_2$ cost associated with web agents from both
a theoretical -via estimation- and an empirical perspective -by benchmarking.
Our results show how different philosophies in web agent creation can severely
impact the associated expended energy, and that more energy consumed does not
necessarily equate to better results. We highlight a lack of transparency
regarding disclosing model parameters and processes used for some web agents as
a limiting factor when estimating energy consumption. Our work contributes
towards a change in thinking of how we evaluate web agents, advocating for
dedicated metrics measuring energy consumption in benchmarks.

</details>


### [19] [Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach](https://arxiv.org/abs/2511.04556)
*Zihang Ding,Kun Zhang*

Main category: cs.AI

TL;DR: 이 연구는 데이터 기반 희소 감지(DSS) 프레임워크를 통해 제한된 자원에서 도시 배수 네트워크를 모니터링하고 흐름 조건을 예측하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 도시 표면수 홍수는 극심한 강우에 의해 발생하며 점점 더 빈번하고 광범위하게 발생하고 있다. 고해상도의 홍수 예측 및 모니터링이 필요하지만, 시간, 예산 및 기술적 제약으로 인해 완전한 구현이 어렵다.

Method: 이 연구는 미네소타 덜루스의 우드랜드 애비뉴 유역을 사례로 EPA-SWMM과 통합된 데이터 기반 희소 감지(DSS) 프레임워크를 제시하여 센서 배치를 최적화하고 폭풍수 시스템에서의 피크 유량을 재구성하는 방법을 설명한다. 또한, 단일 값 분해(SVD)와 QR 분해를 활용하여 센서 배치를 최적화하였다.

Result: DSS로 재구성된 피크 유량 프로파일은 SWMM에서 얻은 프로파일과 비교하여 검증되었으며, 77개 노드 중 3개의 최적 배치된 센서가 0.92-0.95의 Nash-Sutcliffe Efficiency(NSE) 값을 통해 만족스러운 재구성 성능을 보였다.

Conclusion: 이 DSS 프레임워크는 연산 효율성과 물리적 해석 가능성을 균형 있게 유지하여 최소한의 센서로도 고정확도의 흐름 재구성을 가능하게 하며, 제한된 감지 및 모니터링 자원에서 홍수 조기 경고 및 실시간 제어를 실현할 수 있다.

Abstract: Urban surface water flooding, triggered by intense rainfall overwhelming
drainage systems, is increasingly frequent and widespread. While flood
prediction and monitoring in high spatial-temporal resolution are desired,
practical constraints in time, budget, and technology hinder its full
implementation. How to monitor urban drainage networks and predict flow
conditions under constrained resource is a major challenge. This study presents
a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to
optimize sensor placement and reconstruct peak flowrates in a stormwater
system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case
study. We utilized a SWMM model to generate a training dataset of peak flowrate
profiles across the stormwater network. Furthermore, we applied DSS -
leveraging singular value decomposition for dimensionality reduction and QR
factorization for sensor allocation - to identify the optimal monitoring nodes
based on the simulated training dataset. We then validated the
representativeness of these identified monitoring nodes by comparing the
DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three
optimally placed sensors among 77 nodes achieved satisfactory reconstruction
performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to
75th percentiles). In addition, the model showed good robustness to uncertainty
in measurements. Its robustness to sensor failures is location-dependent and
improves with the number of sensors deployed. The framework balances
computational efficiency and physical interpretability, enabling high-accuracy
flow reconstruction with minimal sensors. This DSS framework can be further
integrated with predictive models to realize flood early warning and real-time
control under limited sensing and monitoring resource.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [20] [Applying Time Series Deep Learning Models to Forecast the Growth of Perennial Ryegrass in Ireland](https://arxiv.org/abs/2511.03749)
*Oluwadurotimi Onibonoje,Vuong M. Ngo,Andrew McCarre,Elodie Ruelle,Bernadette O-Briend,Mark Roantree*

Main category: cs.LG

TL;DR: 본 연구는 심층 학습 모델을 활용하여 아일랜드 낙농업 분야의 풀 성장 예측을 개선하고 지속 가능한 농업 실천에 기여하는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 아일랜드 낙농업의 수익성과 지속 가능성 문제를 해결하고, 비현실적인 메커니즘 모델 대신 보다 경제적인 풀 성장 예측 모델을 제안한다.

Method: 단일 변수 데이터셋에 맞춘 깊은 학습 모델을 제안하며, Cork 지역에서의 Perennial Ryegrass 성장 예측을 위한 시간적 합성곱 네트워크를 사용한다.

Result: Cork 지역의 Perennial Ryegrass 성장 예측을 위해 설계된 시간적 합성곱 네트워크는 역사적인 풀 높이 데이터를 활용하여 RMSE 2.74 및 MAE 3.46의 높은 성능을 기록했다.

Conclusion: 이 연구는 모델 행동에 대한 이해를 높임으로써 풀 성장 예측의 신뢰성을 개선하고, 지속 가능한 낙농업 관행의 발전에 기여한다.

Abstract: Grasslands, constituting the world's second-largest terrestrial carbon sink,
play a crucial role in biodiversity and the regulation of the carbon cycle.
Currently, the Irish dairy sector, a significant economic contributor, grapples
with challenges related to profitability and sustainability. Presently, grass
growth forecasting relies on impractical mechanistic models. In response, we
propose deep learning models tailored for univariate datasets, presenting
cost-effective alternatives. Notably, a temporal convolutional network designed
for forecasting Perennial Ryegrass growth in Cork exhibits high performance,
leveraging historical grass height data with RMSE of 2.74 and MAE of 3.46.
Validation across a comprehensive dataset spanning 1,757 weeks over 34 years
provides insights into optimal model configurations. This study enhances our
understanding of model behavior, thereby improving reliability in grass growth
forecasting and contributing to the advancement of sustainable dairy farming
practices.

</details>


### [21] [Laugh, Relate, Engage: Stylized Comment Generation for Short Videos](https://arxiv.org/abs/2511.03757)
*Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li*

Main category: cs.LG

TL;DR: LOLGORITHM는 짧은 동영상 플랫폼의 댓글 생성을 위한 모듈식 다중 에이전트 시스템으로, 다양한 스타일의 댓글을 생성하는 데 도움을 준다.


<details>
  <summary>Details</summary>
Motivation: 짧은 동영상 플랫폼에서 사용자 참여와 문화 전파 방식을 개선하기 위해 댓글 생성을 효율화하고자 한다.

Method: LOLGORITHM은 비디오 분할, 맥락 및 정서 분석, 스타일에 민감한 프롬프트 구성을 통합한 모듈식 다중 에이전트 시스템이다.

Result: LOLGORITHM은 Douyin에서 90%, YouTube에서 87.55%의 선호도를 기록하며 기본 모델보다 훨씬 뛰어난 성능을 보인다.

Conclusion: 이 연구는 사용자 참여와 창의적 상호작용을 향상시키기 위한 스타일화된 댓글 생성을 위한 확장 가능하고 문화적으로 적응 가능한 프레임워크를 제시한다.

Abstract: Short-video platforms have become a central medium in the modern Internet
landscape, where efficient information delivery and strong interactivity are
reshaping user engagement and cultural dissemination. Among the various forms
of user interaction, comments play a vital role in fostering community
participation and enabling content re-creation. However, generating comments
that are both compliant with platform guidelines and capable of exhibiting
stylistic diversity and contextual awareness remains a significant challenge.
We introduce LOLGORITHM, a modular multi-agent system (MAS) designed for
controllable short-video comment generation. The system integrates video
segmentation, contextual and affective analysis, and style-aware prompt
construction. It supports six distinct comment styles: puns (homophones),
rhyming, meme application, sarcasm (irony), plain humor, and content
extraction. Powered by a multimodal large language model (MLLM), LOLGORITHM
directly processes video inputs and achieves fine-grained style control through
explicit prompt markers and few-shot examples. To support development and
evaluation, we construct a bilingual dataset using official APIs from Douyin
(Chinese) and YouTube (English), covering five popular video genres: comedy
skits, daily life jokes, funny animal clips, humorous commentary, and talk
shows. Evaluation combines automated metrics originality, relevance, and style
conformity with a large-scale human preference study involving 40 videos and
105 participants. Results show that LOLGORITHM significantly outperforms
baseline models, achieving preference rates of over 90% on Douyin and 87.55% on
YouTube. This work presents a scalable and culturally adaptive framework for
stylized comment generation on short-video platforms, offering a promising path
to enhance user engagement and creative interaction.

</details>


### [22] [Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems](https://arxiv.org/abs/2511.04594)
*Utkarsh U. Chavan,Prashant Trivedi,Nandyala Hemachandra*

Main category: cs.LG

TL;DR: 다수의 에이전트가 분산 제어를 통해 공통 목표를 달성해야 하는 다중 에이전트 시스템(MAS)에 대한 연구로, 분산 다중 에이전트 확률적 최단경로 문제(Dec-MASSPs)를 선형 함수 근사 하에 분석하였으며, 학습의 본질적인 어려움을 나타내는 최초의 후회 하한을 제시했다.


<details>
  <summary>Details</summary>
Motivation: 확률적 최단 경로 문제(SSP)가 분산 제어를 모델링하는 자연스러운 프레임워크를 제공하지만, 다중 에이전트 설정에서의 학습은 거의 탐구되지 않았다.

Method: 선형 모델을 사용하여 전이 동역학과 비용을 표현하고, 대칭 기반의 주장을 적용하여 최적 정책의 구조를 식별하였다.

Result: 어떤 수의 에이전트에 대해서도 학습하기 어려운 사례를 기반으로 한 최초의 후회 하한 $(ho	ext{sqrt}(K))$를 제시하였다.

Conclusion: 이 연구는 분산 제어의 학습 복잡성을 명확히 하고 다중 에이전트 시스템에서 효율적인 학습 알고리즘 설계를 안내할 수 있다.

Abstract: Multi-agent systems (MAS) are central to applications such as swarm robotics
and traffic routing, where agents must coordinate in a decentralized manner to
achieve a common objective. Stochastic Shortest Path (SSP) problems provide a
natural framework for modeling decentralized control in such settings. While
the problem of learning in SSP has been extensively studied in single-agent
settings, the decentralized multi-agent variant remains largely unexplored. In
this work, we take a step towards addressing that gap. We study decentralized
multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the
transition dynamics and costs are represented using linear models. Applying
novel symmetry-based arguments, we identify the structure of optimal policies.
Our main contribution is the first regret lower bound for this setting based on
the construction of hard-to-learn instances for any number of agents, $n$. Our
regret lower bound of $\Omega(\sqrt{K})$, over $K$ episodes, highlights the
inherent learning difficulty in Dec-MASSPs. These insights clarify the learning
complexity of decentralized control and can further guide the design of
efficient learning algorithms in multi-agent systems.

</details>


### [23] [Enhancing Q-Value Updates in Deep Q-Learning via Successor-State Prediction](https://arxiv.org/abs/2511.03836)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: SADQ는 환경 역학을 모델링하여 DQN의 불안정한 업데이트 문제를 해결하고, 안정적이며 효율적인 학습을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: DQN의 목표 업데이트가 과거 정책에 의해 생성된 상태에 의존하여 높은 분산을 초래하는 문제를 해결하고자 합니다.

Method: SADQ는 확률적 전이 모델을 사용해 환경 역학을 모델링하고, 후속 상태 분포를 Q-값 추정 과정에 통합합니다.

Result: SADQ는 기존의 DQN 변형에 비해 안정성과 학습 효율성에서 일관되게 우수한 성능을 보입니다.

Conclusion: SADQ는 편향되지 않은 가치 추정치를 유지하면서 훈련 분산을 줄이는 이론적 보장을 제공합니다.

Abstract: Deep Q-Networks (DQNs) estimate future returns by learning from transitions
sampled from a replay buffer. However, the target updates in DQN often rely on
next states generated by actions from past, potentially suboptimal, policy. As
a result, these states may not provide informative learning signals, causing
high variance into the update process. This issue is exacerbated when the
sampled transitions are poorly aligned with the agent's current policy. To
address this limitation, we propose the Successor-state Aggregation Deep
Q-Network (SADQ), which explicitly models environment dynamics using a
stochastic transition model. SADQ integrates successor-state distributions into
the Q-value estimation process, enabling more stable and policy-aligned value
updates. Additionally, it explores a more efficient action selection strategy
with the modeled transition structure. We provide theoretical guarantees that
SADQ maintains unbiased value estimates while reducing training variance. Our
extensive empirical results across standard RL benchmarks and real-world
vector-based control tasks demonstrate that SADQ consistently outperforms DQN
variants in both stability and learning efficiency.

</details>


### [24] [Pediatric Appendicitis Detection from Ultrasound Images](https://arxiv.org/abs/2511.04069)
*Fatemeh Hosseinabadi,Seyedhassan Sharifi*

Main category: cs.LG

TL;DR: 이 연구는 초음파 이미지를 기반으로 한 충수염 자동 탐지를 위한 딥러닝 모델을 개발하고 평가하였다.


<details>
  <summary>Details</summary>
Motivation: 소아 충수염은 어린이의 급성 복통의 주요 원인 중 하나이며, 진단이 어려운 문제가 지속되고 있다.

Method: 사전 학습된 ResNet 아키텍처에 기반하여 초음파 이미지를 통한 충수염 탐지 모델을 개발하였다. 데이터를 처리하기 위해 정규화, 크기 조정, 증강을 실시하였다.

Result: 제안된 ResNet 모델은 총 정확도 93.44%, 정밀도 91.53%, 재현율 89.8%를 달성하여 소아 초음파에서 충수염을 효과적으로 식별하였다.

Conclusion: 모델은 저대비, 스펙클 잡음, 해부학적 변동성과 같은 문제를 극복하며 차별화된 공간적 특징을 학습하였다.

Abstract: Pediatric appendicitis remains one of the most common causes of acute
abdominal pain in children, and its diagnosis continues to challenge clinicians
due to overlapping symptoms and variable imaging quality. This study aims to
develop and evaluate a deep learning model based on a pretrained ResNet
architecture for automated detection of appendicitis from ultrasound images. We
used the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound
scans, laboratory data, and clinical scores from pediatric patients admitted
with abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each
subject had 1 to 15 ultrasound views covering the right lower quadrant,
appendix, lymph nodes, and related structures. For the image based
classification task, ResNet was fine tuned to distinguish appendicitis from
non-appendicitis cases. Images were preprocessed by normalization, resizing,
and augmentation to enhance generalization. The proposed ResNet model achieved
an overall accuracy of 93.44, precision of 91.53, and recall of 89.8,
demonstrating strong performance in identifying appendicitis across
heterogeneous ultrasound views. The model effectively learned discriminative
spatial features, overcoming challenges posed by low contrast, speckle noise,
and anatomical variability in pediatric imaging.

</details>


### [25] [Decomposable Neuro Symbolic Regression](https://arxiv.org/abs/2511.04124)
*Giorgio Morales,John W. Sheppard*

Main category: cs.LG

TL;DR: 우리는 해석 가능한 다변량 수식을 생성하는 분해 가능한 기호 회귀(SR) 방법을 제시하였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 기호 회귀 방법은 예측 오류 최소화에 우선하며, 이는 복잡하거나 부정확한 수식을 생성할 수 있다.

Method: 우리는 변환기 모델, 유전 알고리즘(GA) 및 유전 프로그래밍(GP)을 활용하여, 기계 학습된 모델을 수학적 표현으로 변환하는 설명 가능한 SR 방법을 개발하였다.

Result: 생성된 골격의 성능을 평가한 결과, 우리의 방법은 다른 GP 기반 방법, 세 가지 신경망 SR 방법 및 하이브리드 접근 방식에 비해 낮거나 유사한 보간 및 외삽 오류를 보여주었다.

Conclusion: 우리의 접근법은 원래 수학적 구조에 맞는 수식을 일관되게 학습하였다.

Abstract: Symbolic regression (SR) models complex systems by discovering mathematical
expressions that capture underlying relationships in observed data. However,
most SR methods prioritize minimizing prediction error over identifying the
governing equations, often producing overly complex or inaccurate expressions.
To address this, we present a decomposable SR method that generates
interpretable multivariate expressions leveraging transformer models, genetic
algorithms (GAs), and genetic programming (GP). In particular, our explainable
SR method distills a trained ``opaque'' regression model into mathematical
expressions that serve as explanations of its computed function. Our method
employs a Multi-Set Transformer to generate multiple univariate symbolic
skeletons that characterize how each variable influences the opaque model's
response. We then evaluate the generated skeletons' performance using a
GA-based approach to select a subset of high-quality candidates before
incrementally merging them via a GP-based cascade procedure that preserves
their original skeleton structure. The final multivariate skeletons undergo
coefficient optimization via a GA. We evaluated our method on problems with
controlled and varying degrees of noise, demonstrating lower or comparable
interpolation and extrapolation errors compared to two GP-based methods, three
neural SR methods, and a hybrid approach. Unlike them, our approach
consistently learned expressions that matched the original mathematical
structure.

</details>


### [26] [The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms](https://arxiv.org/abs/2511.04217)
*Hikari Otsuka,Daiki Chijiwa,Yasuyuki Okoshi,Daichi Fujiki,Susumu Takeuchi,Masato Motomura*

Main category: cs.LG

TL;DR: 강한 복권 티켓 가설(SLTH)은 임의로 초기화된 신경망 안에 숨겨진 고성능 서브네트워크인 강한 복권 티켓(SLT)의 존재를 추측한다. 본 연구에서는 다중 헤드 주의(MHA) 기법 내에서 SLT의 존재를 이론적으로 분석하고, SLT가 동일한 입력 차원을 가진 MHA를 고확률로 근사할 수 있음을 증명하였다.


<details>
  <summary>Details</summary>
Motivation: 강한 복권 티켓 가설(SLTH)의 이론적 기반을 확장하고, 트랜스포머 아키텍처에서의 이해를 깊이 있게 하기 위해.

Method: 무작위로 초기화된 MHA의 헤드 수와 입력 차원에 따라 SLT의 존재를 이론적으로 분석하였고, SLT가 다른 MHA를 근사할 수 있는 조건을 증명하였다.

Result: 숨겨진 차원과는 관련된 이론적 분석을 통해 SLTH가 트랜스포머에 어떻게 확장되는지를 나타내고, 이를 실험적으로 검증하여 SLT와 근사 타겟 간의 오차가 숨겨진 차원의 증가에 따라 기하급수적으로 감소함을 보였다.

Conclusion: 이 연구는 SLTH가 트랜스포머 아키텍처에 적용될 수 있음을 보여주고, 이를 통해 복잡한 신경망 구조에 내재된 고성능 서브네트워크의 발견에 기여할 것이다.

Abstract: The strong lottery ticket hypothesis (SLTH) conjectures that high-performing
subnetworks, called strong lottery tickets (SLTs), are hidden in randomly
initialized neural networks. Although recent theoretical studies have
established the SLTH across various neural architectures, the SLTH for
transformer architectures still lacks theoretical understanding. In particular,
the current theory of the SLTH does not yet account for the multi-head
attention (MHA) mechanism, a core component of transformers. To address this
gap, we introduce a theoretical analysis of the existence of SLTs within MHAs.
We prove that, if a randomly initialized MHA of $H$ heads and input dimension
$d$ has the hidden dimension $O(d\log(Hd^{3/2}))$ for the key and value, it
contains an SLT that approximates an arbitrary MHA with the same input
dimension with high probability. Furthermore, by leveraging this theory for
MHAs, we extend the SLTH to transformers without normalization layers. We
empirically validate our theoretical findings, demonstrating that the
approximation error between the SLT within a source model (MHA and transformer)
and an approximate target counterpart decreases exponentially by increasing the
hidden dimension of the source model.

</details>


### [27] [Complexity as Advantage: A Regret-Based Perspective on Emergent Structure](https://arxiv.org/abs/2511.04590)
*Oshri Naparstek*

Main category: cs.LG

TL;DR: 복잡성을 관찰자의 가족에 상대적으로 정의하는 Complexity as Advantage (CAA) 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡성이 시스템의 내재적 속성이 아니라 관찰자들이 모형화할 때 유도하는 예측적 후회의 양으로 평가해야 한다는 점에서 복잡성의 새로운 이해를 도모합니다.

Method: 관찰자에 따라 다르게 인식되는 시스템의 복잡성을 평가하고, 여러 emergent behavior 개념을 통합하는 프레임워크를 제시합니다.

Result: 몇몇 관찰자에게는 쉽고 다른 관찰자에게는 어려운 시스템이 정보적 이점을 창출하는 복잡한 시스템임을 보여줍니다.

Conclusion: 복잡성이 기능적으로 가치가 있는 이유를 정량적으로 제공하며, 단순한 동적 모델을 통해 이 아이디어를 입증하고 학습, 진화, 인공지능 에이전트에 대한 함의를 논의합니다.

Abstract: We introduce Complexity as Advantage (CAA), a framework that defines the
complexity of a system relative to a family of observers. Instead of measuring
complexity as an intrinsic property, we evaluate how much predictive regret a
system induces for different observers attempting to model it. A system is
complex when it is easy for some observers and hard for others, creating an
information advantage. We show that this formulation unifies several notions of
emergent behavior, including multiscale entropy, predictive information, and
observer-dependent structure. The framework suggests that "interesting" systems
are those positioned to create differentiated regret across observers,
providing a quantitative grounding for why complexity can be functionally
valuable. We demonstrate the idea through simple dynamical models and discuss
implications for learning, evolution, and artificial agents.

</details>


### [28] [Environment Agnostic Goal-Conditioning, A Study of Reward-Free Autonomous Learning](https://arxiv.org/abs/2511.04598)
*Hampus Åström,Elin Anna Topp,Jacek Malec*

Main category: cs.LG

TL;DR: 이 논문은 일반적인 강화 학습 환경을 목표 조건 환경으로 변환하는 것이 에이전트가 자율적으로 보상 없이 작업을 해결하도록 학습할 수 있도록 한다고 연구한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트가 스스로 목표를 선택할 수 있는 방법을 제시하여 보상 없이도 작업을 해결할 수 있도록 하는 것이 목표다.

Method: 환경에 독립적인 방식으로 목표를 설정하여 작업을 해결하는 방법을 제안한다.

Result: 에이전트는 특정 목표에 대한 성능 안정성에 문제가 있지만 평균 목표 성공률이 개선되고 안정화됨을 보인다.

Conclusion: 이 방법을 통해 훈련된 에이전트는 환경에서 생성된 관찰을 추구하도록 지시할 수 있어 특정 사용 사례 이전에 에이전트를 일반적으로 훈련할 수 있다.

Abstract: In this paper we study how transforming regular reinforcement learning
environments into goal-conditioned environments can let agents learn to solve
tasks autonomously and reward-free. We show that an agent can learn to solve
tasks by selecting its own goals in an environment-agnostic way, at training
times comparable to externally guided reinforcement learning. Our method is
independent of the underlying off-policy learning algorithm. Since our method
is environment-agnostic, the agent does not value any goals higher than others,
leading to instability in performance for individual goals. However, in our
experiments, we show that the average goal success rate improves and
stabilizes. An agent trained with this method can be instructed to seek any
observations made in the environment, enabling generic training of agents prior
to specific use cases.

</details>


### [29] [Optimal Inference Schedules for Masked Diffusion Models](https://arxiv.org/abs/2511.04647)
*Sitan Chen,Kevin Cong,Jerry Li*

Main category: cs.LG

TL;DR: 표준 자기 회귀 대형 언어 모델의 주요 병목 현상은 그들의 추론 과정이 본질적으로 순차적이라는 점이다. 이로 인해 매우 긴 추론 시간이 발생한다. 이를 해결하기 위해 실무자들은 확산 언어 모델이라는 언어 모델 클래스, 특히 가장 성공적인 마스크 드퓨전 모델(MDM)을 제안하였다. MDM은 토큰을 비순차적으로 샘플링할 수 있으며, 여러 토큰을 동시에 병렬 처리할 수 있다. 그러나 이러한 모델들이 샘플링 성능의 눈에 띄는 저하 없이 얼마나 많은 병렬 샘플링을 수행할 수 있는지에 대한 체계적인 이해는 매우 제한적이다. 본 논문에서는 실제 분포와 샘플링된 분포 간의 예상 발산을 정확하게 특성화하고, 이 이론을 기반으로 새로운 하한과 상한을 제시하였다.


<details>
  <summary>Details</summary>
Motivation: 표준 자기 회귀 대형 언어 모델의 추론 시간 문제를 해결하기 위해.

Method: 마스크 드퓨전 모델의 샘플링 성능을 향상시키기 위한 새로운 유도 통계적 이론을 제시하고, 기반 분포의 정보 이론적 특성을 활용하여 샘플링 스케줄을 최적화했다.

Result: 어떤 자연적인 환경에서, $O(log n)$ 단계로 샘플링이 가능함을 보여주었다.

Conclusion: 강한 사전 지식 없이 최적의 비마스크 스케줄과 경쟁하는 것은 일반적으로 불가능하다는 점을 보여주었다. 하지만 새로운 상한 및 샘플링 스케줄을 제시하여 성능 저하 없이 효율적인 샘플링이 가능함을 입증하였다.

Abstract: A major bottleneck of standard auto-regressive large language models is that
their inference process is inherently sequential, resulting in very long and
costly inference times. To circumvent this, practitioners proposed a class of
language models called diffusion language models, of which the masked diffusion
model (MDM) is the most successful. The MDM is able to sample tokens
out-of-order and, ostensibly, many tokens at once and in parallel. However,
there is very limited rigorous understanding of how much parallel sampling
these models can perform without noticeable degradation in their sampling
performance. Prior work of Li and Cai obtained some preliminary bounds, but
these are not tight for many natural classes of distributions. In this work, we
give a new, exact characterization of the expected divergence between the true
distribution and the sampled distribution, for any distribution and any
unmasking schedule for the sampler, showing an elegant connection to the theory
of univariate function approximation.
  By leveraging this connection, we then attain a number of novel lower and
upper bounds for this problem. While the connection to function approximation
in principle gives the optimal unmasking schedule for any distribution, we show
that it is in general impossible to compete with it without strong a priori
knowledge of the distribution, even in seemingly benign settings. However, we
also demonstrate new upper bounds and new sampling schedules in terms of
well-studied information-theoretic properties of the base distribution, namely,
its total correlation and dual total correlation, which show that in some
natural settings, one can sample in $O(log n)$ steps without any visible loss
in performance, where $n$ is the total sequence length.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [30] [OptiMA: A Transaction-Based Framework with Throughput Optimization for Very Complex Multi-Agent Systems](https://arxiv.org/abs/2511.03761)
*Umut Çalıkyılmaz,Nitin Nayak,Jinghua Groppe,Sven Groppe*

Main category: cs.MA

TL;DR: 멀티 에이전트 시스템 연구의 복잡성 증가에 따른 문제를 해결하기 위한 거래 기반 프레임워크를 제안하고, 이에 대한 통합 거래 스케줄링을 통해 성능을 개선한 OptiMA 프레임워크를 개발했다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업을 수행하기 위해 더 크고 복잡한 멀티 에이전트 시스템 모델을 탐구하는 방향으로 연구가 진행되고 있다.

Method: 거래 기반 프레임워크를 제안하고, 제안된 프레임워크에 거래 스케줄링을 통합하는 방법을 제시했다.

Result: OptiMA 프레임워크는 100개 이상의 에이전트를 포함한 VCMAS의 실행을 지원하며, 거래 스케줄링을 통해 16% 이상의 성능 개선을 보였다.

Conclusion: 거래 스케줄링 문제에 대한 이론 분석을 수행하고, 향후 연구에 활용할 수 있는 실용적인 도구를 제공했다.

Abstract: In recent years, the research of multi-agent systems has taken a direction to
explore larger and more complex models to fulfill sophisticated tasks. We point
out two possible pitfalls that might be caused by increasing complexity;
susceptibilities to faults, and performance bottlenecks. To prevent the former
threat, we propose a transaction-based framework to design very complex
multi-agent systems (VCMAS). To address the second threat, we offer to
integrate transaction scheduling into the proposed framework. We implemented
both of these ideas to develop the OptiMA framework and show that it is able to
facilitate the execution of VCMAS with more than a hundred agents. We also
demonstrate the effect of transaction scheduling on such a system by showing
improvements up to more than 16\%. Furthermore, we also performed a theoretical
analysis on the transaction scheduling problem and provided practical tools
that can be used for future research on it.

</details>


### [31] [ASAP: an Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training](https://arxiv.org/abs/2511.03844)
*Yuran Ding,Xinwei Chen,Xiaofan Zhang,Zongwei Zhou*

Main category: cs.MA

TL;DR: 대규모 LLM 훈련의 최적화를 위한 ASAP 제안. 이 시스템은 성능 프로파일링 도구와 인간 전문가의 최적화 사례를 활용하여 자동으로 병목 현상을 진단하고 최적의 샤딩 구성을 추천함으로써 훈련 효율성을 향상시킴.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 훈련에서 분산 도메인 특정 가속기 시스템의 최적화는 복잡한 최적화 공간으로 인해 큰 도전 과제가 됩니다. 현재의 최적화 방법은 시간이 많이 걸리는 수동 조정이나 리소스 집약적인 블랙박스 검색에 의존하고 있어, LLM 분야의 빠른 발전 속도를 따라잡지 못하고 개발이 느려지며 자원이 효과적으로 활용되지 않고 있습니다.

Method: 우리는 ASAP(대규모 LLM 훈련 성능을 자동 최적화하는 에이전트 솔루션)를 제안합니다. ASAP는 코디네이터, 분석가 및 제안 에이전트로 구성된 다중 에이전트 시스템으로, LLM 추론을 성능 프로파일링 도구, 루프라인 분석 및 인간 전문가의 최적화 사례를 담은 지식 기반과 통합합니다.

Result: ASAP이 생성한 샤딩 구성은 훈련 단계 시간 감소를 최대 28%까지 기여하고, 처리량을 1.43배 향상시킬 수 있음을 실험을 통해 확인했습니다. 인간 전문가의 추가 최적화와 결합했을 때 처리량은 2.58배까지 증가할 수 있습니다.

Conclusion: 제안된 ASAP은 대규모 LLM 훈련에서 AI 지원 성능 공학을 위한 확장 가능하고 설명 가능한 방법론을 제공할 것을 약속합니다.

Abstract: Optimizing large-language model (LLM) training on distributed domain-specific
accelerator systems presents significant challenges due to its complex
optimization space. Existing optimization methods, however, rely on
time-consuming manual tuning or resource-intensive black-box searches, which
struggle to keep pace with the rapidly evolving LLM domain, leading to slow
development and underutilized resources. To address this, we introduce ASAP, an
Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training. It
is a multi-agent system, featuring Coordinator, Analyzer, and Proposal agents,
which integrates LLM reasoning with insights from performance profiling tools,
roofline analysis, and a knowledge base of best practices and successful past
optimizations from human experts. Our proposed design can automate the
diagnosis of performance bottlenecks and recommend optimized sharding
configurations with reasoning, thus effectively improving the efficiency of
distributed LLM training. Experiments have shown that the ASAP-generated
sharding configurations can contribute up to 28% training step time reduction
and 1.43 times throughput improvement. When combined with additional
optimization from human experts, throughput can be further increased to 2.58
times. The proposed ASAP promises to provide a scalable and explainable
methodology for AI-assisted performance engineering in large-scale LLM
training.

</details>


### [32] [Multi-Agent Collaborative Framework For Math Problem Generation](https://arxiv.org/abs/2511.03958)
*Kia Karbasi,Kevin Hong,Mohammad Amin Samadi,Gregory Pottie*

Main category: cs.MA

TL;DR: 본 연구는 협업 다중 에이전트 프레임워크를 통해 수학 교육을 위한 자동 질문 생성을 개선하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 수학 교육을 위한 자동 질문 생성을 달성하는 것은 지능형 튜터링 시스템과 교육자들에게 여전히 어려운 목표이다.

Method: 협업 다중 에이전트 프레임워크를 도입하여 추론 시간 계산을 AQG에 통합하고, 여러 에이전트를 사용하여 생성된 질문-답변 쌍을 반복적으로 개선한다.

Result: 다섯 가지 메타 평가 기준(적합성, 중요성, 명확성, 난이도 일치, 응답 가능성)을 통해 생성된 질문의 품질을 평가했다.

Conclusion: 협업 다중 에이전트 프레임워크는 인지적 도전과 명확성 사이의 미묘한 균형을 촉진하여 생성된 교육 콘텐츠의 품질을 높인다.

Abstract: Automatic question generation (AQG) for mathematics education remains an
elusive goal for Intelligent Tutoring Systems and educators. While pre-trained
transformer-based language models have significantly advanced natural language
generation, they often struggle to precisely control problem complexity and
cognitive demands. In this paper, we introduce a collaborative multi-agent
framework as a novel method of incorporating inference-time computation into
AQG. This approach leverages multiple agents that iteratively refine generated
question-answer pairs to better balance complexity and cognitive demand. We
evaluate the generated questions on five meta-evaluation criteria: relevance,
importance, clarity, difficulty matching, answerability, to assess the system's
ability to control the required complexity and quality of the questions.
Preliminary evaluations show that this collaborative multi-agent framework
elevates the quality of generated educational content by fostering a more
nuanced balance between cognitive challenge and clarity. These promising
outcomes suggest that integrating collaborative multi-agent workflows can yield
more controlled, pedagogically valuable content that can help advance automated
educational content generation and adaptive learning environments.

</details>
