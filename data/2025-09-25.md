<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 25]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.CR](#cs.CR) [Total: 5]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Solve it with EASE](https://arxiv.org/abs/2509.18108)
*Adam Viktorin,Tomas Kadavy,Jozef Kovac,Michal Pluhacek,Roman Senkerik*

Main category: cs.LG

TL;DR: EASE는 대형 언어 모델을 활용한 알고리즘 솔루션 생성의 반복적 프로세스를 위한 개방형 및 완전 모듈형 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 연구자와 실무자가 다양한 도메인에서 알고리즘과 기타 생성 솔루션을 공동 설계할 수 있는 투명하고 확장 가능한 플랫폼을 제공하기 위해서이다.

Method: EASE는 생성, 테스트, 분석 및 평가를 통합하여 재현 가능한 피드백 루프를 형성하며, 여러 LLM의 역할을 조율할 수 있는 아키텍처를 지원한다.

Result: 사용자는 오류 처리, 분석, 품질 평가에 대한 완전한 제어를 가질 수 있다.

Conclusion: EASE는 프롬프트 설계 및 모델 관리의 복잡성을 추상화하여 편리한 알고리즘 솔루션 진화를 가능하게 한다.

Abstract: This paper presents EASE (Effortless Algorithmic Solution Evolution), an
open-source and fully modular framework for iterative algorithmic solution
generation leveraging large language models (LLMs). EASE integrates generation,
testing, analysis, and evaluation into a reproducible feedback loop, giving
users full control over error handling, analysis, and quality assessment. Its
architecture supports the orchestration of multiple LLMs in complementary
roles-such as generator, analyst, and evaluator. By abstracting the complexity
of prompt design and model management, EASE provides a transparent and
extensible platform for researchers and practitioners to co-design algorithms
and other generative solutions across diverse domains.

</details>


### [2] [MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents](https://arxiv.org/abs/2509.18119)
*Yifan Xu,Xiao Liu,Xinghan Liu,Jiaqi Fu,Hanchen Zhang,Bohao Jing,Shudan Zhang,Yuting Wang,Wenyi Zhao,Yuxiao Dong*

Main category: cs.LG

TL;DR: 본 연구는 모바일 환경에서 GUI 에이전트를 향상시키기 위한 온라인 에이전틱 강화 학습 프레임워크인 MOBILERL을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 비전 언어 모델의 발전과 함께 범용 그래픽 사용자 인터페이스(GUI) 에이전트를 구축하는 것이 점점 더 유망해지고 있지만, 모바일 GUI 에이전트를 효과적으로 개발하는 것은 여전히 도전적이다.

Method: MOBILERL 프레임워크는 ADAGRPO 알고리즘을 핵심 요소로 두고, 긍정적 리플레이와 실패 커리큘럼 필터링을 통해 모델을 다양한 작업 난이도에 적응시킨다.

Result: MOBILERL-9B 모델은 AndroidWorld(75.8%) 및 AndroidLab(46.8%)에서 성공률 측면에서 최첨단 결과를 달성하였다.

Conclusion: MOBILERL 프레임워크는 AutoGLM 제품에 채택되었으며, https://github.com/THUDM/MobileRL에서 오픈 소스로 제공된다.

Abstract: Building general-purpose graphical user interface (GUI) agents has become
increasingly promising with the progress in vision language models. However,
developing effective mobile GUI agents with reinforcement learning (RL) remains
challenging due to the heavy-tailed distribution of task difficulty and the
inefficiency of large-scale environment sampling. We present an online agentic
reinforcement learning framework MOBILERL to enhance GUI agents in mobile
environments. Its core component is the Difficulty-Adaptive GRPO (ADAGRPO)
algorithm. In ADAGRPO, we design difficulty-adaptive positive replay and
failure curriculum filtering to adapt the model to different task difficulties.
We introduce the shortest path reward adjustment strategy to reshape rewards
concerning the task length in multi-turn agentic tasks. Those strategies
jointly stabilize RL training, improve sample efficiency, and generate strong
performance across diverse mobile apps and tasks. We apply MOBILERL to two open
models (Qwen2.5-VL-7B-Instruct and GLM-4.1V-9B-Base). The resultant MOBILERL-9B
model achieves state-of-the-art results in terms of success rates on both
AndroidWorld (75.8%) and AndroidLab (46.8%). The MOBILERL framework is adopted
in the AutoGLM products, and also open-sourced at
https://github.com/THUDM/MobileRL.

</details>


### [3] [A Coopetitive-Compatible Data Generation Framework for Cross-silo Federated Learning](https://arxiv.org/abs/2509.18120)
*Thanh Linh Nguyen,Quoc-Viet Pham*

Main category: cs.LG

TL;DR: 본 논문에서는 협동적 학습 시스템에서의 경제적 경쟁과 통계적 이질성을 고려하여 CoCoGen이라는 데이터 생성 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 조직 간 데이터 프라이버시를 유지하면서 인공지능 모델을 공동으로 교육하는 것은 데이터 소유자가 경제적 경쟁 때문에 조심스럽게 접근해야 하는 문제입니다.

Method: CoCoGen은 생성적 AI와 잠재적 게임 이론을 활용하여 협동적 학습을 모델링하고 분석하며 최적화합니다.

Result: Fashion-MNIST 데이터 세트에서의 실험 결과는 다양한 이질성과 경쟁 수준이 조직 행동에 미치는 영향을 보여주며 CoCoGen이 일관되게 기준 방법들을 능가하는 것을 입증합니다.

Conclusion: CoCoGen은 협동 학습의 사회적 복지를 극대화할 수 있는 전략을 제공합니다.

Abstract: Cross-silo federated learning (CFL) enables organizations (e.g., hospitals or
banks) to collaboratively train artificial intelligence (AI) models while
preserving data privacy by keeping data local. While prior work has primarily
addressed statistical heterogeneity across organizations, a critical challenge
arises from economic competition, where organizations may act as market rivals,
making them hesitant to participate in joint training due to potential utility
loss (i.e., reduced net benefit). Furthermore, the combined effects of
statistical heterogeneity and inter-organizational competition on
organizational behavior and system-wide social welfare remain underexplored. In
this paper, we propose CoCoGen, a coopetitive-compatible data generation
framework, leveraging generative AI (GenAI) and potential game theory to model,
analyze, and optimize collaborative learning under heterogeneous and
competitive settings. Specifically, CoCoGen characterizes competition and
statistical heterogeneity through learning performance and utility-based
formulations and models each training round as a weighted potential game. We
then derive GenAI-based data generation strategies that maximize social
welfare. Experimental results on the Fashion-MNIST dataset reveal how varying
heterogeneity and competition levels affect organizational behavior and
demonstrate that CoCoGen consistently outperforms baseline methods.

</details>


### [4] [Model-Based Transfer Learning for Real-Time Damage Assessment of Bridge Networks](https://arxiv.org/abs/2509.18106)
*Elisa Tomassini,Enrique García-Macías,Filippo Ubertini*

Main category: cs.LG

TL;DR: 본 연구는 유사한 특성을 가진 구조물 간의 지식 전이를 통해 교량 네트워크의 손상 평가를 향상시키는 모델 기반 전이 학습 접근법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 영구 모니터링 시스템의 증가로 데이터 가용성이 높아졌지만, 대규모 교량 네트워크에서 확장성 문제도 발생했다.

Method: 신경망 대리 모델을 사용하여 한 교량에 대해 훈련된 모델을 유사한 특성을 가진 다른 교량에 적응시킬 수 있는 모델 기반 전이 학습 접근법을 제안한다.

Result: 실제 두 개의 교량 데이터를 사용하여 검증된 이 방법은 손상 위치, 심각도 및 범위에 대한 높은 민감도를 보였다.

Conclusion: 이 접근법은 실시간 모니터링을 향상시키고 구조 간 지식 전이를 가능하게 하여 스마트 모니터링 전략과 네트워크 수준의 복원력 향상을 촉진한다.

Abstract: The growing use of permanent monitoring systems has increased data
availability, offering new opportunities for structural assessment but also
posing scalability challenges, especially across large bridge networks.
Managing multiple structures requires tracking and comparing long-term
behaviour efficiently. To address this, knowledge transfer between similar
structures becomes essential. This study proposes a model-based transfer
learning approach using neural network surrogate models, enabling a model
trained on one bridge to be adapted to another with similar characteristics.
These models capture shared damage mechanisms, supporting a scalable and
generalizable monitoring framework. The method was validated using real data
from two bridges. The transferred model was integrated into a Bayesian
inference framework for continuous damage assessment based on modal features
from monitoring data. Results showed high sensitivity to damage location,
severity, and extent. This approach enhances real-time monitoring and enables
cross-structure knowledge transfer, promoting smart monitoring strategies and
improved resilience at the network level.

</details>


### [5] [From Parameters to Performance: A Data-Driven Study on LLM Structure and Development](https://arxiv.org/abs/2509.18136)
*Suqing Wang,Zuchao Li,Luohe Shi,Bo Du,Hai Zhao,Yun Li,Qianren Wang*

Main category: cs.LG

TL;DR: 본 연구는 언어 모델의 구조적 구성이 성능에 미치는 영향을 체계적으로 분석하고 데이터 기반 통찰을 제공하여 미래 모델 개발을 지원하는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델의 규모와 능력이 급격히 성장하고 있으나, 구조적 구성이 성능에 미치는 영향을 다룬 체계적인 데이터 기반 연구는 부족하다.

Method: 다양한 오픈소스 언어 모델 구조와 그 성능을 포함하는 대규모 데이터셋을 활용하여, 구조적 구성과 성능 간의 관계를 검증하고 정량화하는 데이터 마이닝 기반 분석을 수행하였다.

Result: 구조적 선택이 성능에 미치는 영향을 다양한 벤치마크에서 분석하고, 기계적 해석 가능성 기법을 활용하여 결과를 입증하였다.

Conclusion: 데이터 기반 통찰을 제공함으로써 언어 모델 최적화에 기여하고, 미래 모델의 발전과 응용 방향을 안내하는 것을 목표로 한다.

Abstract: Large language models (LLMs) have achieved remarkable success across various
domains, driving significant technological advancements and innovations.
Despite the rapid growth in model scale and capability, systematic, data-driven
research on how structural configurations affect performance remains scarce. To
address this gap, we present a large-scale dataset encompassing diverse
open-source LLM structures and their performance across multiple benchmarks.
Leveraging this dataset, we conduct a systematic, data mining-driven analysis
to validate and quantify the relationship between structural configurations and
performance. Our study begins with a review of the historical development of
LLMs and an exploration of potential future trends. We then analyze how various
structural choices impact performance across benchmarks and further corroborate
our findings using mechanistic interpretability techniques. By providing
data-driven insights into LLM optimization, our work aims to guide the targeted
development and application of future models. We will release our dataset at
https://huggingface.co/datasets/DX0369/LLM-Structure-Performance-Dataset

</details>


### [6] [KM-GPT: An Automated Pipeline for Reconstructing Individual Patient Data from Kaplan-Meier Plots](https://arxiv.org/abs/2509.18141)
*Yao Zhao,Haoyue Sun,Yantian Ding,Yanxun Xu*

Main category: cs.LG

TL;DR: KM-GPT는 Kaplan-Meier 플롯에서 개인 환자 데이터를 자동으로 재구성하는 인공지능 기반의 최초의 파이프라인으로, 정확도와 재현성을 높입니다.


<details>
  <summary>Details</summary>
Motivation: 개인 환자 데이터(IPD)를 KM 플롯에서 재구성함으로써 임상 연구의 증거 합성을 위한 귀중한 통찰력을 제공합니다. 그러나 기존 방법은 수동 디지털화에 의존하여 오류가 발생하고 확장성이 부족했습니다.

Method: KM-GPT는 고급 이미지 전처리, GPT-5 기반의 다중 모달 추론, 반복 재구성 알고리즘을 통합하여 수동 입력이나 개입 없이 고품질 IPD를 생성합니다.

Result: KM-GPT는 합성 및 실제 데이터세트에서 엄격하게 평가되어 지속적으로 뛰어난 정확성을 보여주었습니다.

Conclusion: KM-GPT는 전통적인 수동 프로세스를 자동화하고 확장 가능한 웹 기반 솔루션을 제공하여 임상 연구를 혁신하고, 재구성된 IPD를 활용하여 보다 정보에 기반한 후속 분석을 가능하게 하여 증거 기반 의사 결정을 지원합니다.

Abstract: Reconstructing individual patient data (IPD) from Kaplan-Meier (KM) plots
provides valuable insights for evidence synthesis in clinical research.
However, existing approaches often rely on manual digitization, which is
error-prone and lacks scalability. To address these limitations, we develop
KM-GPT, the first fully automated, AI-powered pipeline for reconstructing IPD
directly from KM plots with high accuracy, robustness, and reproducibility.
KM-GPT integrates advanced image preprocessing, multi-modal reasoning powered
by GPT-5, and iterative reconstruction algorithms to generate high-quality IPD
without manual input or intervention. Its hybrid reasoning architecture
automates the conversion of unstructured information into structured data flows
and validates data extraction from complex KM plots. To improve accessibility,
KM-GPT is equipped with a user-friendly web interface and an integrated AI
assistant, enabling researchers to reconstruct IPD without requiring
programming expertise. KM-GPT was rigorously evaluated on synthetic and
real-world datasets, consistently demonstrating superior accuracy. To
illustrate its utility, we applied KM-GPT to a meta-analysis of gastric cancer
immunotherapy trials, reconstructing IPD to facilitate evidence synthesis and
biomarker-based subgroup analyses. By automating traditionally manual processes
and providing a scalable, web-based solution, KM-GPT transforms clinical
research by leveraging reconstructed IPD to enable more informed downstream
analyses, supporting evidence-based decision-making.

</details>


### [7] [Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought](https://arxiv.org/abs/2509.18200)
*Yu Ti Huang*

Main category: cs.LG

TL;DR: 대화형 에이전트는 자아 중심의 발화를 할락 중심으로 변환해야 하며, 특히 GPS 신호가 약한 실내 환경에서 중요하다. 본 논문에서는 전통 중국어 대화 항법을 위한 새로운 벤치마크인 Conversational Orientation Reasoning (COR)을 소개하고, 다중 모드 체인 오브 사고(MCoT) 프레임워크를 제안한다. 실험 결과 MCoT는 높은 방향 정확도를 보여주며, 복잡한 대화 조건에서도 견고한 성능을 발휘한다.


<details>
  <summary>Details</summary>
Motivation: 대화형 에이전트가 자아 중심 발화를 할락 중심으로 변환하는 것은 복잡한 내부 환경에서 중요하다.

Method: Conversational Orientation Reasoning (COR)이라는 새로운 벤치마크를 설계하고, ASR로 전사된 음성과 랜드마크 좌표를 통합하는 다중 모드 체인 오브 사고(MCoT) 프레임워크를 제안한다.

Result: MCoT는 깨끗한 전사에서 100% 방향 정확도를, ASR 전사에서 98.1%의 정확도를 달성하며 비구조적 기준을 크게 능가한다.

Conclusion: 구조화된 MCoT 공간 추론의 잠재력은 해석 가능하고 자원 효율적인 구현 내비게이션으로 이어질 수 있다.

Abstract: Conversational agents must translate egocentric utterances (e.g., "on my
right") into allocentric orientations (N/E/S/W). This challenge is particularly
critical in indoor or complex facilities where GPS signals are weak and
detailed maps are unavailable. While chain-of-thought (CoT) prompting has
advanced reasoning in language and vision tasks, its application to multimodal
spatial orientation remains underexplored. We introduce Conversational
Orientation Reasoning (COR), a new benchmark designed for Traditional Chinese
conversational navigation projected from real-world environments, addressing
egocentric-to-allocentric reasoning in non-English and ASR-transcribed
scenarios. We propose a multimodal chain-of-thought (MCoT) framework, which
integrates ASR-transcribed speech with landmark coordinates through a
structured three-step reasoning process: (1) extracting spatial relations, (2)
mapping coordinates to absolute directions, and (3) inferring user orientation.
A curriculum learning strategy progressively builds these capabilities on
Taiwan-LLM-13B-v2.0-Chat, a mid-sized model representative of
resource-constrained settings. Experiments show that MCoT achieves 100%
orientation accuracy on clean transcripts and 98.1% with ASR transcripts,
substantially outperforming unimodal and non-structured baselines. Moreover,
MCoT demonstrates robustness under noisy conversational conditions, including
ASR recognition errors and multilingual code-switching. The model also
maintains high accuracy in cross-domain evaluation and resilience to linguistic
variation, domain shift, and referential ambiguity. These findings highlight
the potential of structured MCoT spatial reasoning as a path toward
interpretable and resource-efficient embodied navigation.

</details>


### [8] [Variational Task Vector Composition](https://arxiv.org/abs/2509.18208)
*Boyuan Zhang,Yingjun Du,Xiantong Zhen,Ling Shao*

Main category: cs.LG

TL;DR: 이 논문에서는 변량적 작업 벡터 조합 방식을 제안하며, 이 방법은 작업 벡터의 불필요한 구조적 중복을 줄이고 신뢰할 수 있는 작업 요소를 선택함으로써 안정성과 해석 가능성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 작업 벡터에서 구조적 중복이 관찰됨에 따라, 불필요한 작업 요소를 줄이고 신뢰할 수 있는 요소에 집중할 필요성이 대두되었다.

Method: 변량적 작업 벡터 조합을 통해 조합 계수를 잠재 변수로 취급하고, 베이지안 추론 프레임워크 내에서 추정한다. 또한 불확실성과 중요성에 따라 조합 계수를 필터링하는 게이티드 샘플링 메커니즘을 개발하여 제어 가능한 사후확률을 구축하였다.

Result: 실험 결과, 우리 방법은 모든 데이터 세트에서 기존 접근 방식을 지속적으로 초월하며, 작업 벡터의 가장 신뢰할 수 있고 유익한 요소를 선택적으로 활용함으로써 높은 성능을 달성하였다.

Conclusion: 우리의 접근법은 작업 벡터 조합에 대한 새로운 기준을 설정하며, 효율적이고 효과적인 작업 벡터 조합의 실용적 가치를 강조한다.

Abstract: Task vectors capture how a model changes during fine-tuning by recording the
difference between pre-trained and task-specific weights. The composition of
task vectors, a key operator in task arithmetic, enables models to integrate
knowledge from multiple tasks without incurring additional inference costs. In
this paper, we propose variational task vector composition, where composition
coefficients are taken as latent variables and estimated in a Bayesian
inference framework. Unlike previous methods that operate at the task level,
our framework focuses on sample-specific composition. Motivated by the
observation of structural redundancy in task vectors, we introduce a
Spike-and-Slab prior that promotes sparsity and preserves only the most
informative components. To further address the high variance and sampling
inefficiency in sparse, high-dimensional spaces, we develop a gated sampling
mechanism that constructs a controllable posterior by filtering the composition
coefficients based on both uncertainty and importance. This yields a more
stable and interpretable variational framework by deterministically selecting
reliable task components, reducing sampling variance while improving
transparency and generalization. Experimental results demonstrate that our
method consistently outperforms existing approaches across all datasets by
selectively leveraging the most reliable and informative components in task
vectors. These findings highlight the practical value of our approach,
establishing a new standard for efficient and effective task vector
composition.

</details>


### [9] [A Weighted Gradient Tracking Privacy-Preserving Method for Distributed Optimization](https://arxiv.org/abs/2509.18134)
*Furan Xie,Bing Liu,Li Chai*

Main category: cs.LG

TL;DR: 프라이버시를 보호하는 분산 최적화 문제를 연구하며, 최적화 과정 중 개인 정보를 보호하는 데 중점을 둡니다.


<details>
  <summary>Details</summary>
Motivation: 개인 정보가 공격자에게 노출될 위험을 줄이기 위해, 분산 최적화 과정에서의 개인 정보 보호 문제를 조사합니다.

Method: 가중된 그래디언트 추적 분산 프라이버시 보호 알고리즘을 제안하며, 이는 감소하는 가중치 요소를 사용하여 그래디언트 추적의 개인 정보 유출 위험을 제거합니다.

Result: 제안된 알고리즘이 느슨한 가정 하에서도 최적 해로 수렴함을 증명하고, 다양한 이질적 스텝 사이즈에서 수렴 특성을 규명합니다.

Conclusion: 수치 시뮬레이션을 통해 고전적인 분산 추정 문제 및 합성곱 신경망의 분산 훈련을 통한 알고리즘의 효과성을 검증합니다.

Abstract: This paper investigates the privacy-preserving distributed optimization
problem, aiming to protect agents' private information from potential attackers
during the optimization process. Gradient tracking, an advanced technique for
improving the convergence rate in distributed optimization, has been applied to
most first-order algorithms in recent years. We first reveal the inherent
privacy leakage risk associated with gradient tracking. Building upon this
insight, we propose a weighted gradient tracking distributed privacy-preserving
algorithm, eliminating the privacy leakage risk in gradient tracking using
decaying weight factors. Then, we characterize the convergence of the proposed
algorithm under time-varying heterogeneous step sizes. We prove the proposed
algorithm converges precisely to the optimal solution under mild assumptions.
Finally, numerical simulations validate the algorithm's effectiveness through a
classical distributed estimation problem and the distributed training of a
convolutional neural network.

</details>


### [10] [A Generalized Bisimulation Metric of State Similarity between Markov Decision Processes: From Theoretical Propositions to Applications](https://arxiv.org/abs/2509.18714)
*Zhenyu Tao,Wei Xu,Xiaohu You*

Main category: cs.LG

TL;DR: 이 연구에서는 쌍 MDP 간의 일반화된 비모사 측정기(GBSM)를 수립하고, 이를 통해 정책 전이, 상태 집계 및 샘플링 기반 추정의 이론적 분석을 수행합니다.


<details>
  <summary>Details</summary>
Motivation: BSM의 다수 MDP 시나리오에 대한 적용을 넓히고자 함.

Method: 일반화된 비모사 측정기(GBSM)를 수립하고, GBSM의 수학적 속성을 rigorously 증명함.

Result: 정책 전이, 상태 집계 및 샘플링 기반 추정에서 GBSM을 활용하여 BSM보다 엄격히 타이트한 경계값을 제공.

Conclusion: GBSM은 다수 MDP 시나리오에서의 유효성을 입증하며 이론적 발견을 수치적으로 검증합니다.

Abstract: The bisimulation metric (BSM) is a powerful tool for computing state
similarities within a Markov decision process (MDP), revealing that states
closer in BSM have more similar optimal value functions. While BSM has been
successfully utilized in reinforcement learning (RL) for tasks like state
representation learning and policy exploration, its application to multiple-MDP
scenarios, such as policy transfer, remains challenging. Prior work has
attempted to generalize BSM to pairs of MDPs, but a lack of rigorous analysis
of its mathematical properties has limited further theoretical progress. In
this work, we formally establish a generalized bisimulation metric (GBSM)
between pairs of MDPs, which is rigorously proven with the three fundamental
properties: GBSM symmetry, inter-MDP triangle inequality, and the distance
bound on identical state spaces. Leveraging these properties, we theoretically
analyse policy transfer, state aggregation, and sampling-based estimation in
MDPs, obtaining explicit bounds that are strictly tighter than those derived
from the standard BSM. Additionally, GBSM provides a closed-form sample
complexity for estimation, improving upon existing asymptotic results based on
BSM. Numerical results validate our theoretical findings and demonstrate the
effectiveness of GBSM in multi-MDP scenarios.

</details>


### [11] [PiMoE: Token-Level Routing for Integrating High-Precision Computation and Reasoning](https://arxiv.org/abs/2509.18169)
*Hengbo Xiao,Jingyuan Fan,Xin Tong,Jingzhao Zhang,Chao Lu,Guannan He*

Main category: cs.LG

TL;DR: PiMoE는 연산 및 추론을 통합하기 위한 훈련 및 추론 아키텍처로, 신경망에 계산 능력을 내재화하여 효율적이고 해석 가능한 시스템을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 고차원 복합 시스템의 결정 지원을 위해 고정밀 수치 계산이 필요하지만, 현재의 대형 언어 모델은 이러한 계산을 효과적으로 통합할 수 없습니다.

Method: PiMoE는 전문가, 텍스트-계산 모듈 및 라우터를 별도로 훈련한 후 신경망에 계산 능력을 통합하는 아키텍처입니다. 추론 시 라우터는 토큰 수준에서 계산 및 추론을 관리하여 사고의 흐름을 반복적으로 전환할 수 있게 합니다.

Result: PiMoE는 LLM 미세 조정 및 다중 에이전트 시스템 접근 방식과 비교하여 높은 정확도를 달성했으며, 응답 지연 시간, 토큰 사용량 및 GPU 에너지 소비에서 유의미한 개선을 보였습니다.

Conclusion: PiMoE는 차세대 과학적 또는 산업 지능 시스템을 위한 효율적이고 해석 가능한 스케일러블 패러다임을 제공합니다.

Abstract: Complex systems typically rely on high-precision numerical computation to
support decisions, but current large language models (LLMs) cannot yet
incorporate such computations as an intrinsic and interpretable capability with
existing architectures. Mainstream multi-agent approaches can leverage external
experts, but inevitably introduce communication overhead and suffer from
inefficient multimodal emergent capability and limited scalability. To this
end, we propose PiMoE (Physically-isolated Mixture of Experts), a training and
inference architecture for integrating computation and reasoning. Instead of
the workflow paradigm of tool invocation, PiMoE endogenously integrates
computational capabilities into neural networks after separately training
experts, a text-to-computation module, and a router. At inference, the router
directs computation and reasoning at the token level, thereby enabling
iterative alternation within a single chain of thought. We evaluate PiMoE on
two reasoning-computation tasks against LLM finetuning and the multi-agent
system approaches. Results show that the PiMoE architecture achieves not only
higher accuracy than directly finetuning LLMs but also significant improvements
in response latency, token usage, and GPU energy consumption compared with
mainstream multi-agent approaches. PiMoE offers an efficient, interpretable,
and scalable paradigm for next-generation scientific or industrial intelligent
systems.

</details>


### [12] [Tackling GNARLy Problems: Graph Neural Algorithmic Reasoning Reimagined through Reinforcement Learning](https://arxiv.org/abs/2509.18930)
*Alex Schutz,Victor-Alexandru Darvariu,Efimia Panagiotaki,Bruno Lacerda,Nick Hawes*

Main category: cs.LG

TL;DR: 본 논문은 신경 알고리즘 추론(NAR)의 한계를 극복하기 위해 알고리즘 경로 학습 문제를 마르코프 결정 과정으로 재구성하고, GNARL 프레임워크를 통해 다양한 그래프 기반 문제에 적합한 학습 아키텍처를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 신경 알고리즘 추론(NAR)은 신경망이 고전 알고리즘을 수행하도록 감독 학습을 통해 훈련하는 패러다임이지만, 여러 중요한 한계가 존재한다.

Method: 이 논문에서는 알고리즘 경로 학습 문제를 마르코프 결정 과정으로 재구성하여 해결책 구축 절차에 구조를 부여하고 모방 및 강화 학습의 강력한 도구를 활용하는 GNARL 프레임워크를 제안한다.

Result: 여러 CLRS-30 문제에서 매우 높은 그래프 정확도 결과를 달성했으며, NP-hard 문제에 대해서는 기존의 더 좁은 NAR 접근 방식의 성능을 초과하거나 일치하는 성과를 보였다.

Conclusion: 이 방법은 전문가 알고리즘이 부족한 경우에도 적용 가능하다는 점에서 주목할 만하다.

Abstract: Neural Algorithmic Reasoning (NAR) is a paradigm that trains neural networks
to execute classic algorithms by supervised learning. Despite its successes,
important limitations remain: inability to construct valid solutions without
post-processing and to reason about multiple correct ones, poor performance on
combinatorial NP-hard problems, and inapplicability to problems for which
strong algorithms are not yet known. To address these limitations, we reframe
the problem of learning algorithm trajectories as a Markov Decision Process,
which imposes structure on the solution construction procedure and unlocks the
powerful tools of imitation and reinforcement learning (RL). We propose the
GNARL framework, encompassing the methodology to translate problem formulations
from NAR to RL and a learning architecture suitable for a wide range of
graph-based problems. We achieve very high graph accuracy results on several
CLRS-30 problems, performance matching or exceeding much narrower NAR
approaches for NP-hard problems and, remarkably, applicability even when
lacking an expert algorithm.

</details>


### [13] [Fully Learnable Neural Reward Machines](https://arxiv.org/abs/2509.19017)
*Hazem Dewidar,Elena Umili*

Main category: cs.LG

TL;DR: 비마르코프 강화 학습 작업은 최적 결정을 내리기 위해 상태-행동 쌍의 전체 경로를 추론해야 하므로 상당한 도전 과제를 제시합니다. 본 연구에서는 고급 기호 표현으로 매핑하는 사전 정의된 기호 근거(SG) 함수나 시간적 작업에 대한 사전 지식 의존성을 제거한 완전 학습 가능한 신경 보상 기계(NRM)를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 비마르코프 강화 학습에서 에이전트는 최적의 결정을 내리기 위해 상태-행동 쌍의 전체 경로를 추론해야 하며, 이는 큰 도전 과제입니다.

Method: 신경 보상 기계(NRM)의 완전 학습 가능한 버전을 제안하여, 사전 지식에 의존하지 않고 SG 함수와 자동자를 엔드 투 엔드로 학습할 수 있습니다.

Result: 우리의 방법은 고전적인 심층 강화 학습(DRL) 접근 방식처럼 쉽게 적용 가능하면서도, 자동자의 유한하고 컴팩트한 특성 덕분에 훨씬 더 설명 가능해집니다.

Conclusion: 완전 학습 가능한 보상 기계(FLNRM)를 DRL과 통합하면, 우리의 방법이 이전의 순환 신경망(RNN) 기반 접근 방식을 능가함을 보여줍니다.

Abstract: Non-Markovian Reinforcement Learning (RL) tasks present significant
challenges, as agents must reason over entire trajectories of state-action
pairs to make optimal decisions. A common strategy to address this is through
symbolic formalisms, such as Linear Temporal Logic (LTL) or automata, which
provide a structured way to express temporally extended objectives. However,
these approaches often rely on restrictive assumptions -- such as the
availability of a predefined Symbol Grounding (SG) function mapping raw
observations to high-level symbolic representations, or prior knowledge of the
temporal task. In this work, we propose a fully learnable version of Neural
Reward Machines (NRM), which can learn both the SG function and the automaton
end-to-end, removing any reliance on prior knowledge. Our approach is therefore
as easily applicable as classic deep RL (DRL) approaches, while being far more
explainable, because of the finite and compact nature of automata. Furthermore,
we show that by integrating Fully Learnable Reward Machines (FLNRM) with DRL,
our method outperforms previous approaches based on Recurrent Neural Networks
(RNNs).

</details>


### [14] [Algorithms for Adversarially Robust Deep Learning](https://arxiv.org/abs/2509.19100)
*Alexander Robey*

Main category: cs.LG

TL;DR: 딥러닝 모델의 안전성 향상을 위한 알고리즘 설계의 최근 진행 상황을 논의한다.


<details>
  <summary>Details</summary>
Motivation: 안전 비판적 응용 분야에서의 딥러닝 모델 사용이 증가함에 따라, 모델의 결정이 적대적 이용에 대해 견고해지는 것이 중요하다.

Method: 적대적 예제 문제, 도메인 일반화 문제, 그리고 대형 언어 모델의 탈옥 설정을 위한 알고리즘을 설계하고 새로운 공격 및 방어 기법을 제안한다.

Result: 의료 이미지, 분자 식별, 이미지 분류에서 최첨단 일반화를 달성하는 새로운 알고리즘을 제시한다.

Conclusion: 강력한 언어 기반 에이전트를 설계하기 위한 최신의 진전을 나타내는 새로운 공격 및 방어를 제안한다.

Abstract: Given the widespread use of deep learning models in safety-critical
applications, ensuring that the decisions of such models are robust against
adversarial exploitation is of fundamental importance. In this thesis, we
discuss recent progress toward designing algorithms that exhibit desirable
robustness properties. First, we discuss the problem of adversarial examples in
computer vision, for which we introduce new technical results, training
paradigms, and certification algorithms. Next, we consider the problem of
domain generalization, wherein the task is to train neural networks to
generalize from a family of training distributions to unseen test
distributions. We present new algorithms that achieve state-of-the-art
generalization in medical imaging, molecular identification, and image
classification. Finally, we study the setting of jailbreaking large language
models (LLMs), wherein an adversarial user attempts to design prompts that
elicit objectionable content from an LLM. We propose new attacks and defenses,
which represent the frontier of progress toward designing robust language-based
agents.

</details>


### [15] [Towards Provable Emergence of In-Context Reinforcement Learning](https://arxiv.org/abs/2509.18389)
*Jiuqi Wang,Rohan Chandra,Shangtong Zhang*

Main category: cs.LG

TL;DR: 이 논문은 강화 학습 에이전트가 사전 훈련 후 새로운 작업에서 파라미터 업데이트 없이도 작업을 수행할 수 있는 이유를 조사한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 에이전트가 사전 훈련 중 학습한 파라미터로 새로운 작업 수행이 가능하다는 점.

Method: 사전 훈련 손실의 글로벌 최소값에 대한 이론적 분석을 통해, Transformer가 정책 평가를 위해 사전 훈련될 때 in-context temporal difference learning이 가능하다는 것을 보임.

Result: 사전 훈련 손실의 글로벌 최소값 중 하나가 ICRL을 가능하게 함을 증명함.

Conclusion: 이러한 발견은 ICRL 현상을 이해하는 데 중요한 기초 자료를 제공한다.

Abstract: Typically, a modern reinforcement learning (RL) agent solves a task by
updating its neural network parameters to adapt its policy to the task.
Recently, it has been observed that some RL agents can solve a wide range of
new out-of-distribution tasks without parameter updates after pretraining on
some task distribution. When evaluated in a new task, instead of making
parameter updates, the pretrained agent conditions its policy on additional
input called the context, e.g., the agent's interaction history in the new
task. The agent's performance increases as the information in the context
increases, with the agent's parameters fixed. This phenomenon is typically
called in-context RL (ICRL). The pretrained parameters of the agent network
enable the remarkable ICRL phenomenon. However, many ICRL works perform the
pretraining with standard RL algorithms. This raises the central question this
paper aims to address: Why can the RL pretraining algorithm generate network
parameters that enable ICRL? We hypothesize that the parameters capable of ICRL
are minimizers of the pretraining loss. This work provides initial support for
this hypothesis through a case study. In particular, we prove that when a
Transformer is pretrained for policy evaluation, one of the global minimizers
of the pretraining loss can enable in-context temporal difference learning.

</details>


### [16] [FedFiTS: Fitness-Selected, Slotted Client Scheduling for Trustworthy Federated Learning in Healthcare AI](https://arxiv.org/abs/2509.19120)
*Ferdinand Kahenga,Antoine Bagula,Sajal K. Das,Patrick Sello*

Main category: cs.LG

TL;DR: FedFiTS는 신뢰와 공정성을 고려한 선택적 연합 학습 프레임워크로, 의료와 같은 민감한 분야에서의 비IID 데이터 문제와 클라이언트 신뢰성 문제를 해결하기 위해 설계되었습니다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습은 개인 정보 보호를 위한 모델 훈련의 강력한 패러다임으로 떠오르고 있으나, 의료와 같은 민감한 분야에서 비IID 데이터, 클라이언트의 신뢰성 부족, 적대적 조작 등의 지속적인 도전 과제가 있습니다.

Method: FedFiTS는 피트니스 기반 클라이언트 선출과 슬롯 집계를 결합하여 FedFaSt 라인을 발전시키는 신뢰와 공정성을 인식하는 선택적 FL 프레임워크입니다. 세 가지 단계의 참여 전략을 구현하며, 동적 클라이언트 스코어링, 적응형 임계값 설정, 코호트 기반 스케줄링을 통해 수렴 효율성과 강건성을 균형 있게 조화합니다.

Result: 다양한 데이터셋에 대한 실험(의료 영상, 전원 표준 데이터셋, 농업 데이터) 결과, FedFiTS가 정확도, 목표 도달 시간 및 중독 공격에 대한 회복력에서 FedAvg, FedRand 및 FedPow를 일관되게 초월함을 보여주었습니다.

Conclusion: 신뢰 인식 집계와 공정성을 고려한 클라이언트 선택을 통합함으로써 FedFiTS는 확장 가능하고 안전한 연합 학습을 향상시켜 실제 의료 및 교차 도메인 배치에 적합합니다.

Abstract: Federated Learning (FL) has emerged as a powerful paradigm for
privacy-preserving model training, yet deployments in sensitive domains such as
healthcare face persistent challenges from non-IID data, client unreliability,
and adversarial manipulation. This paper introduces FedFiTS, a trust and
fairness-aware selective FL framework that advances the FedFaSt line by
combining fitness-based client election with slotted aggregation. FedFiTS
implements a three-phase participation strategy-free-for-all training, natural
selection, and slotted team participation-augmented with dynamic client
scoring, adaptive thresholding, and cohort-based scheduling to balance
convergence efficiency with robustness. A theoretical convergence analysis
establishes bounds for both convex and non-convex objectives under standard
assumptions, while a communication-complexity analysis shows reductions
relative to FedAvg and other baselines. Experiments on diverse datasets-medical
imaging (X-ray pneumonia), vision benchmarks (MNIST, FMNIST), and tabular
agricultural data (Crop Recommendation)-demonstrate that FedFiTS consistently
outperforms FedAvg, FedRand, and FedPow in accuracy, time-to-target, and
resilience to poisoning attacks. By integrating trust-aware aggregation with
fairness-oriented client selection, FedFiTS advances scalable and secure FL,
making it well suited for real-world healthcare and cross-domain deployments.

</details>


### [17] [Diffusion Policies with Offline and Inverse Reinforcement Learning for Promoting Physical Activity in Older Adults Using Wearable Sensors](https://arxiv.org/abs/2509.18433)
*Chang Liu,Ladda Thiamwong,Yanjie Fu,Rui Xie*

Main category: cs.LG

TL;DR: 본 논문은 오프라인 강화 학습을 이용하여 낙상 위험이 높은 노인을 위한 신체 활동 촉진에 대응하기 위한 KANDI(코르모고로프-아놀드 네트워크 및 오프라인 역 강화 학습을 위한 확산 정책)를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 임상 데이터를 활용한 오프라인 강화 학습은 헬스케어 AI에서 점점 더 많은 주목을 받고 있지만, 직접적인 보상을 정의하는 것이 어렵고, 복잡한 환경에서 전문가 행동으로부터 정확한 보상 함수를 추론하는 것이 어려움이 있다는 도전 과제를 가지고 있습니다.

Method: KANDI는 코르모고로프-아놀드 네트워크의 유연한 함수 근사화를 활용하여 낮은 낙상 위험의 노인(전문가)으로부터 자유적인 환경 행동을 학습하여 보상 함수를 추정하며, 액터-크리틱 프레임워크 내의 확산 기반 정책을 통해 오프라인 RL에서 행동 정제 및 효율성을 위한 생성적 접근을 제공합니다.

Result: KANDI는 PEER 연구에서의 이중 팔 임상 시험 데이터로 평가되었으며, 노인의 신체 활동을 촉진하기 위한 낙상 위험 개입 프로그램에서의 실제 응용을 강조합니다. 또한 KANDI는 D4RL 벤치마크에서 최첨단 방법보다 우수한 성능을 보였습니다.

Conclusion: 이 결과는 KANDI가 헬스케어 응용을 위한 오프라인 RL에서 주요 도전 과제를 해결할 수 있는 잠재력을 강조하며, 헬스케어에서의 활동 촉진 개입 전략에 효과적인 솔루션을 제공합니다.

Abstract: Utilizing offline reinforcement learning (RL) with real-world clinical data
is getting increasing attention in AI for healthcare. However, implementation
poses significant challenges. Defining direct rewards is difficult, and inverse
RL (IRL) struggles to infer accurate reward functions from expert behavior in
complex environments. Offline RL also encounters challenges in aligning learned
policies with observed human behavior in healthcare applications. To address
challenges in applying offline RL to physical activity promotion for older
adults at high risk of falls, based on wearable sensor activity monitoring, we
introduce Kolmogorov-Arnold Networks and Diffusion Policies for Offline Inverse
Reinforcement Learning (KANDI). By leveraging the flexible function
approximation in Kolmogorov-Arnold Networks, we estimate reward functions by
learning free-living environment behavior from low-fall-risk older adults
(experts), while diffusion-based policies within an Actor-Critic framework
provide a generative approach for action refinement and efficiency in offline
RL. We evaluate KANDI using wearable activity monitoring data in a two-arm
clinical trial from our Physio-feedback Exercise Program (PEER) study,
emphasizing its practical application in a fall-risk intervention program to
promote physical activity among older adults. Additionally, KANDI outperforms
state-of-the-art methods on the D4RL benchmark. These results underscore
KANDI's potential to address key challenges in offline RL for healthcare
applications, offering an effective solution for activity promotion
intervention strategies in healthcare.

</details>


### [18] [FedFusion: Federated Learning with Diversity- and Cluster-Aware Encoders for Robust Adaptation under Label Scarcity](https://arxiv.org/abs/2509.19220)
*Ferdinand Kahenga,Antoine Bagula,Patrick Sello,Sajal K. Das*

Main category: cs.LG

TL;DR: FedFusion은 비동질적인 특성 공간, 심각한 비IID 데이터 및 클라이언트 간 부족한 레이블 문제에 대처하기 위한 연합 전이 학습 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습에서의 개인화, 도메인 적응 및 레이블 효율성을 조화롭게 하는 것이 실제 세계의 제약 하에서 강력한 연합 학습을 위한 효과적인 방법임을 보여준다.

Method: FedFusion은 도메인 적응과 절약형 레이블링을 통합하는 다이버시티-클러스터 인식 인코더를 사용하고, 레이블이 지정된 teacher 클라이언트가 learner 클라이언트를 안내하며 클라이언트는 로컬 데이터에 맞춰 개인화된 인코더를 유지한다.

Result: FedFusion은 IID, 비IID 및 레이블이 부족한 환경에서 정확성, 강건성 및 공정성 측면에서 최첨단 기준을 지속적으로 초과한다.

Conclusion: 이러한 결과는 개인화, 도메인 적응 및 레이블 효율성을 조화시키는 것이 실제 세계의 제약 하에서 강력한 연합 학습을 위한 효과적인 레시피임을 보여준다.

Abstract: Federated learning in practice must contend with heterogeneous feature
spaces, severe non-IID data, and scarce labels across clients. We present
FedFusion, a federated transfer-learning framework that unifies domain
adaptation and frugal labelling with diversity-/cluster-aware encoders (DivEn,
DivEn-mix, DivEn-c). Labelled teacher clients guide learner clients via
confidence-filtered pseudo-labels and domain-adaptive transfer, while clients
maintain personalised encoders tailored to local data. To preserve global
coherence under heterogeneity, FedFusion employs similarity-weighted classifier
coupling (with optional cluster-wise averaging), mitigating dominance by
data-rich sites and improving minority-client performance. The frugal-labelling
pipeline combines self-/semi-supervised pretext training with selective
fine-tuning, reducing annotation demands without sharing raw data. Across
tabular and imaging benchmarks under IID, non-IID, and label-scarce regimes,
FedFusion consistently outperforms state-of-the-art baselines in accuracy,
robustness, and fairness while maintaining comparable communication and
computation budgets. These results show that harmonising personalisation,
domain adaptation, and label efficiency is an effective recipe for robust
federated learning under real-world constraints.

</details>


### [19] [Reverse-Complement Consistency for DNA Language Models](https://arxiv.org/abs/2509.18529)
*Mingqian Ma*

Main category: cs.LG

TL;DR: DNA의 기본 속성 중 하나는 서열의 리버스 컴플리먼트(RC)가 종종 동일한 생물학적 의미를 갖는다는 것이다. 그러나 최신 DNA 언어 모델은 이러한 대칭성을 포착하는 데 실패하여 서열과 그 RC에 대한 예측의 일관성이 결여된다. 본 연구에서는 모델이 서열에 대한 예측과 그 리버스 컴플리먼트에 대한 정렬된 예측 간의 발산을 직접적으로 패널화하는 Reverse-Complement Consistency Regularization(RCCR)을 소개한다. RCCR은 다양한 생물학적 작업에서 RC 강건성을 크게 개선하며, 모델의 정확성을 유지하거나 개선한다.


<details>
  <summary>Details</summary>
Motivation: DNA의 리버스 컴플리먼트가 종종 동일한 생물학적 의미를 갖지만, 기존의 DNA 언어 모델은 이러한 대칭성을 포착하지 못하고 있다.

Method: Reverse-Complement Consistency Regularization(RCCR)이라는 모델 불문 최적화 목표를 도입하여 서열의 예측과 그 리버스 컴플리먼트의 정렬된 예측 간의 발산을 패널화한다.

Result: RCCR은 RC 강건성을 크게 개선하며 예측 전환 및 오류를 줄이고, 기존 방법들보다 작업 정확성을 유지하거나 개선한다.

Conclusion: RCCR을 통해 생물학적 사전 지식을 학습 과정에 직접적으로 통합함으로써 다양하고 효율적인 모델 조정 방법을 제공한다.

Abstract: A fundamental property of DNA is that the reverse complement (RC) of a
sequence often carries identical biological meaning. However, state-of-the-art
DNA language models frequently fail to capture this symmetry, producing
inconsistent predictions for a sequence and its RC counterpart, which
undermines their reliability. In this work, we introduce Reverse-Complement
Consistency Regularization (RCCR), a simple and model-agnostic fine-tuning
objective that directly penalizes the divergence between a model's prediction
on a sequence and the aligned prediction on its reverse complement. We evaluate
RCCR across three diverse backbones (Nucleotide Transformer, HyenaDNA,
DNABERT-2) on a wide range of genomic tasks, including sequence classification,
scalar regression, and profile prediction. Our experiments show that RCCR
substantially improves RC robustness by dramatically reducing prediction flips
and errors, all while maintaining or improving task accuracy compared to
baselines such as RC data augmentation and test-time averaging. By integrating
a key biological prior directly into the learning process, RCCR produces a
single, intrinsically robust, and computationally efficient model fine-tuning
recipe for diverse biology tasks.

</details>


### [20] [DS-Diffusion: Data Style-Guided Diffusion Model for Time-Series Generation](https://arxiv.org/abs/2509.18584)
*Mingchun Sun,Rongqiang Zhao,Hengrui Hu,Songyu Ding,Jie Liu*

Main category: cs.LG

TL;DR: 본 논문에서는 시간 시계열 생성을 위한 데이터 스타일 가이드 확산 모델(DS-Diffusion)을 제안하여 훈련 재조정 없이도 조건부 가이드를 도입하고 생성 데이터와 실제 데이터 간의 분포 편향을 줄이며, 해석 가능한 추론 과정을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 시간 시계열 생성용 확산 모델은 조건부 가이드를 도입하기 위해 전체 프레임워크를 재훈련해야 하고, 생성된 데이터와 실제 데이터 간의 분포 편향이 존재하여 downstream 작업에서 모델 편향이 발생할 수 있습니다. 또한, 확산 모델과 잠재 공간의 복잡성으로 인해 추론 과정이 해석 불가능합니다.

Method: DS-Diffusion에서는 스타일 가이드 커널을 기반으로 하는 확산 프레임워크를 개발하여 특정 조건을 위한 훈련 재조정 없이 해결합니다. 또한, 시간 정보 기반의 계층적 노이즈 제거 메커니즘(THD)을 개발하여 생성 데이터와 실제 데이터 간의 분포 편향을 줄입니다.

Result: 비교 평가 결과, 최첨단 모델인 ImagenTime에 비해 예측 점수는 5.56%, 구별 점수는 61.55% 감소하였으며, 생성 데이터와 실제 데이터 간의 분포 편향이 더욱 줄어들고 추론 과정이 더 해석 가능해졌습니다.

Conclusion: 확산 모델의 재훈련 필요성을 제거함으로써 특정 조건에 대한 모델의 유연성과 적응성을 향상시켰습니다.

Abstract: Diffusion models are the mainstream approach for time series generation
tasks. However, existing diffusion models for time series generation require
retraining the entire framework to introduce specific conditional guidance.
There also exists a certain degree of distributional bias between the generated
data and the real data, which leads to potential model biases in downstream
tasks. Additionally, the complexity of diffusion models and the latent spaces
leads to an uninterpretable inference process. To address these issues, we
propose the data style-guided diffusion model (DS-Diffusion). In the
DS-Diffusion, a diffusion framework based on style-guided kernels is developed
to avoid retraining for specific conditions. The time-information based
hierarchical denoising mechanism (THD) is developed to reduce the
distributional bias between the generated data and the real data. Furthermore,
the generated samples can clearly indicate the data style from which they
originate. We conduct comprehensive evaluations using multiple public datasets
to validate our approach. Experimental results show that, compared to the
state-of-the-art model such as ImagenTime, the predictive score and the
discriminative score decrease by 5.56% and 61.55%, respectively. The
distributional bias between the generated data and the real data is further
reduced, the inference process is also more interpretable. Moreover, by
eliminating the need to retrain the diffusion model, the flexibility and
adaptability of the model to specific conditions are also enhanced.

</details>


### [21] [Subspace Clustering of Subspaces: Unifying Canonical Correlation Analysis and Subspace Clustering](https://arxiv.org/abs/2509.18653)
*Paris A. Karakasis,Nicholas D. Sidiropoulos*

Main category: cs.LG

TL;DR: 본 논문은 열 행렬 집합의 클러스터링을 위한 새로운 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 고차원 데이터에서 구조가 개별 데이터 벡터를 초과하는 경우에 대한 클러스터링의 필요성.

Method: 데이터 샘플을 행렬로 모델링하고, 이를 구간 클러스터링으로 접근하며, BTD를 기반으로 하여 클러스터 멤버십과 부분적으로 공유된 서브스페이스를 공동 추정하는 방법.

Result: 실제 하이퍼스펙트럼 이미지 데이터셋에 대한 실험 결과, 기존 클러스터링 기술보다 우수한 클러스터링 정확도 및 견고성을 보임.

Conclusion: 제안된 프레임워크는 고차원 애플리케이션에서 개별 데이터 벡터를 넘어서는 구조를 찾는데 잠재력이 있음을 강조합니다.

Abstract: We introduce a novel framework for clustering a collection of tall matrices
based on their column spaces, a problem we term Subspace Clustering of
Subspaces (SCoS). Unlike traditional subspace clustering methods that assume
vectorized data, our formulation directly models each data sample as a matrix
and clusters them according to their underlying subspaces. We establish
conceptual links to Subspace Clustering and Generalized Canonical Correlation
Analysis (GCCA), and clarify key differences that arise in this more general
setting. Our approach is based on a Block Term Decomposition (BTD) of a
third-order tensor constructed from the input matrices, enabling joint
estimation of cluster memberships and partially shared subspaces. We provide
the first identifiability results for this formulation and propose scalable
optimization algorithms tailored to large datasets. Experiments on real-world
hyperspectral imaging datasets demonstrate that our method achieves superior
clustering accuracy and robustness, especially under high noise and
interference, compared to existing subspace clustering techniques. These
results highlight the potential of the proposed framework in challenging
high-dimensional applications where structure exists beyond individual data
vectors.

</details>


### [22] [Lift What You Can: Green Online Learning with Heterogeneous Ensembles](https://arxiv.org/abs/2509.18962)
*Kirsten Köbschall,Sebastian Buschjäger,Raphael Fischer,Lisa Hartung,Stefan Kramer*

Main category: cs.LG

TL;DR: HEROS는 지속 가능성을 고려한 이형 온라인 앙상블 기법을 제안하며, 자원 제약 속에서 다양한 모델을 선택하여 훈련한다.


<details>
  <summary>Details</summary>
Motivation: 기존 앙상블 방법들은 예측 능력에만 집중하고 계산 비용을 고려하지 않아 지속 가능성 요구에 부합하지 않는다.

Method: HEROS는 다양한 하이퍼파라미터 선택으로 초기화된 모델 풀에서 자원 제약 하에 모델의 하위 집합을 선택하여 훈련한다.

Result: 실험을 통해 $eta$-정책이 자원 사용을 줄이면서도 거의 최적의 성능을 달성한다는 것을 이론적으로 입증하였다.

Conclusion: HEROS는 자원 친화적이며, 기존 최상의 정책과 비교해도 뛰어난 성능을 보인다.

Abstract: Ensemble methods for stream mining necessitate managing multiple models and
updating them as data distributions evolve. Considering the calls for more
sustainability, established methods are however not sufficiently considerate of
ensemble members' computational expenses and instead overly focus on predictive
capabilities. To address these challenges and enable green online learning, we
propose heterogeneous online ensembles (HEROS). For every training step, HEROS
chooses a subset of models from a pool of models initialized with diverse
hyperparameter choices under resource constraints to train. We introduce a
Markov decision process to theoretically capture the trade-offs between
predictive performance and sustainability constraints. Based on this framework,
we present different policies for choosing which models to train on incoming
data. Most notably, we propose the novel $\zeta$-policy, which focuses on
training near-optimal models at reduced costs. Using a stochastic model, we
theoretically prove that our $\zeta$-policy achieves near optimal performance
while using fewer resources compared to the best performing policy. In our
experiments across 11 benchmark datasets, we find empiric evidence that our
$\zeta$-policy is a strong contribution to the state-of-the-art, demonstrating
highly accurate performance, in some cases even outperforming competitors, and
simultaneously being much more resource-friendly.

</details>


### [23] [Latent Danger Zone: Distilling Unified Attention for Cross-Architecture Black-box Attacks](https://arxiv.org/abs/2509.19044)
*Yang Li,Chenyu Wang,Tingrui Wang,Yongwei Wang,Haonan Li,Zhunga Liu,Quan Pan*

Main category: cs.LG

TL;DR: JAD는 흑상자 적대적 공격을 위해 제안된 잠재적 확산 모델 프레임워크로, 다양한 모델 간의 일반화 및 효율성을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 흑상자 적대적 공격에서는 모델 내부에 대한 접근이 제한되어 있어 기존 방법들이 특정 네트워크 아키텍처에 의존하거나 많은 쿼리를 요구하는 등 제한적인 전이 가능성과 높은 쿼리 비용이라는 한계가 있다.

Method: JAD는 CNN과 ViT 모델에서 추출한 주의 맵에 의해 안내되는 잠재적 확산 모델을 활용하여 적대적 사례를 생성한다.

Result: 실험 결과, JAD는 기존 방법들에 비해 공격 일반화, 생성 효율성 및 아키텍처 간 전이 가능성을 개선한 것으로 나타났다.

Conclusion: JAD는 흑상자 적대적 공격을 위한 유망하고 효과적인 패러다임을 제공한다.

Abstract: Black-box adversarial attacks remain challenging due to limited access to
model internals. Existing methods often depend on specific network
architectures or require numerous queries, resulting in limited
cross-architecture transferability and high query costs. To address these
limitations, we propose JAD, a latent diffusion model framework for black-box
adversarial attacks. JAD generates adversarial examples by leveraging a latent
diffusion model guided by attention maps distilled from both a convolutional
neural network (CNN) and a Vision Transformer (ViT) models. By focusing on
image regions that are commonly sensitive across architectures, this approach
crafts adversarial perturbations that transfer effectively between different
model types. This joint attention distillation strategy enables JAD to be
architecture-agnostic, achieving superior attack generalization across diverse
models. Moreover, the generative nature of the diffusion framework yields high
adversarial sample generation efficiency by reducing reliance on iterative
queries. Experiments demonstrate that JAD offers improved attack
generalization, generation efficiency, and cross-architecture transferability
compared to existing methods, providing a promising and effective paradigm for
black-box adversarial attacks.

</details>


### [24] [Unveiling the Role of Learning Rate Schedules via Functional Scaling Laws](https://arxiv.org/abs/2509.19189)
*Binghui Li,Fengling Chen,Zixun Huang,Lean Wang,Lei Wu*

Main category: cs.LG

TL;DR: 대형 언어 모델(LLM)의 훈련을 안내하는 스케일링 법칙에 관한 연구가 이루어졌다. 본 논문에서는 학습 속도 일정(LRS)의 영향을 다루며, 기능적 스케일링 법칙(FSL)을 도입하여 LRS에 따른 훈련 과정에서의 위험 진화를 특성화했다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 훈련 과정에서의 손실 동역학 및 학습 속도 일정의 영향을 이해하고자 함.

Method: 온라인 확률적 경사 하강법(SGD)으로 훈련된 교사-학생 커널 회귀 설정을 통해 기능적 스케일링 법칙(FSL)을 도입.

Result: 세 가지 LRS(상수, 지수 감소, 웜업-안정-감소)를 분석하여 이론적 정당화를 제공하고, 모델 크기에 따라 손실 곡선 예측 및 최적화 실험을 수행했다.

Conclusion: FSL 프레임워크는 LLM의 사전 훈련 동역학을 깊이 이해하고 대규모 모델 훈련 개선을 위한 통찰력을 제공할 것으로 기대한다.

Abstract: Scaling laws have played a cornerstone role in guiding the training of large
language models (LLMs). However, most existing works on scaling laws primarily
focus on the final-step loss, overlooking the loss dynamics during the training
process and, crucially, the impact of learning rate schedule (LRS). In this
paper, we aim to bridge this gap by studying a teacher-student kernel
regression setup trained via online stochastic gradient descent (SGD).
Leveraging a novel intrinsic time viewpoint and stochastic differential
equation (SDE) modeling of SGD, we introduce the Functional Scaling Law (FSL),
which characterizes the evolution of population risk during the training
process for general LRSs. Remarkably, the impact of the LRSs is captured
through an explicit convolution-type functional term, making their effects
fully tractable. To illustrate the utility of FSL, we analyze three widely used
LRSs -- constant, exponential decay, and warmup-stable-decay (WSD) -- under
both data-limited and compute-limited regimes. We provide theoretical
justification for widely adopted empirical practices in LLMs pre-training such
as (i) higher-capacity models are more data- and compute-efficient; (ii)
learning rate decay can improve training efficiency; (iii) WSD-like schedules
can outperform direct-decay schedules. Lastly, we explore the practical
relevance of FSL as a surrogate model for fitting, predicting and optimizing
the loss curves in LLM pre-training, with experiments conducted across model
sizes ranging from 0.1B to 1B parameters. We hope our FSL framework can deepen
the understanding of LLM pre-training dynamics and provide insights for
improving large-scale model training.

</details>


### [25] [Stability and Generalization of Adversarial Diffusion Training](https://arxiv.org/abs/2509.19234)
*Hesam Hosseini,Ying Cao,Ali H. Sayed*

Main category: cs.LG

TL;DR: 이 연구는 분산 네트워크에서의 적대적 훈련의 일반화 성질을 안정성 기반으로 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 적대적 훈련이 모델의 견고성을 향상시키지만, 과적합과 일반화 격차의 확대 문제를 겪고 있다는 점에서 연구의 필요성이 있습니다.

Method: 다각적 손실에 대한 확산 전략 하의 적대적 훈련에 대한 안정성 기반 일반화 분석을 수행합니다.

Result: 적대적 섭동 강도와 훈련 단계 수에 따라 일반화 오류가 증가한다는 경계를 도출하였습니다.

Conclusion: 이는 단일 에이전트 경우와 일관되나, 분산 환경에서는 새로운 발견입니다.

Abstract: Algorithmic stability is an established tool for analyzing generalization.
While adversarial training enhances model robustness, it often suffers from
robust overfitting and an enlarged generalization gap. Although recent work has
established the convergence of adversarial training in decentralized networks,
its generalization properties remain unexplored. This work presents a
stability-based generalization analysis of adversarial training under the
diffusion strategy for convex losses. We derive a bound showing that the
generalization error grows with both the adversarial perturbation strength and
the number of training steps, a finding consistent with single-agent case but
novel for decentralized settings. Numerical experiments on logistic regression
validate these theoretical predictions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation](https://arxiv.org/abs/2509.18198)
*Rui Liu,Zikang Wang,Peng Gao,Yu Shen,Pratap Tokekar,Ming Lin*

Main category: cs.AI

TL;DR: 자율 시스템은 상당한 발전을 이루었지만, 사고가 발생하기 쉬운 환경에서의 강력한 의사 결정이 여전히 도전 과제로 남아 있습니다. 이 연구는 제한된 센서 범위와 시야 장애로 인해 발생하는 사고의 가능성을 줄이기 위한 다중 차량 연결 시스템과 다중 모달 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 시스템은 사고 발생 가능성이 높은 환경에서 강력한 의사 결정을 필요로 하기 때문에 보다 안전한 자율 주행을 위한 새로운 해결책이 필요합니다.

Method: MMCD(다중 모달 협력 의사 결정) 프레임워크를 도입하여 자율 차량과 협력 차량의 다중 모달 관측치를 융합하고, 특정 데이터 모달이 테스트 중에 사용 불가능할 때에도 강력한 성능을 보장하기 위해 교차 모달 지식 증류 방식을 제안합니다.

Result: 우리는 연결된 자율 주행 및 공중-지상 차량 협업에 대한 실험에서 20.7%까지 운전 안전성을 향상시켰습니다.

Conclusion: 제안된 방법은 잠재적 사고를 감지하고 안전한 운전 결정을 내리는 데 있어 기존의 최선 성능 기준을 초과했습니다.

Abstract: Autonomous systems have advanced significantly, but challenges persist in
accident-prone environments where robust decision-making is crucial. A single
vehicle's limited sensor range and obstructed views increase the likelihood of
accidents. Multi-vehicle connected systems and multi-modal approaches,
leveraging RGB images and LiDAR point clouds, have emerged as promising
solutions. However, existing methods often assume the availability of all data
modalities and connected vehicles during both training and testing, which is
impractical due to potential sensor failures or missing connected vehicles. To
address these challenges, we introduce a novel framework MMCD (Multi-Modal
Collaborative Decision-making) for connected autonomy. Our framework fuses
multi-modal observations from ego and collaborative vehicles to enhance
decision-making under challenging conditions. To ensure robust performance when
certain data modalities are unavailable during testing, we propose an approach
based on cross-modal knowledge distillation with a teacher-student model
structure. The teacher model is trained with multiple data modalities, while
the student model is designed to operate effectively with reduced modalities.
In experiments on $\textit{connected autonomous driving with ground vehicles}$
and $\textit{aerial-ground vehicles collaboration}$, our method improves
driving safety by up to ${\it 20.7}\%$, surpassing the best-existing baseline
in detecting potential accidents and making safe driving decisions. More
information can be found on our website https://ruiiu.github.io/mmcd.

</details>


### [27] [Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM](https://arxiv.org/abs/2509.18178)
*Ling Yue,Nithin Somasekharan,Tingwen Zhang,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TL;DR: Foam-Agent는 자연어 프롬프트 하나로 OpenFOAM 워크플로우를 자동화하는 다중 에이전트 프레임워크로, CFD의 장벽을 낮추는 데 기여한다.


<details>
  <summary>Details</summary>
Motivation: CFD의 복잡한 수동 설정과 높은 학습 곡선으로 인한 진입 장벽을 극복하기 위해.

Method: Foam-Agent는 전체 시뮬레이션 파이프라인을 관리하며, 다양한 기능을 가진 에이전트를 통해 자동 처리한다.

Result: 110개의 벤치마크 시뮬레이션 작업에서 88.2%의 성공률을 기록하며 기존 프레임워크보다 높은 성과를 보인다.

Conclusion: Foam-Agent는 CFD의 전문성 장벽을 크게 낮추고, 복잡한 과학 컴퓨팅을 민주화할 수 있는 잠재력을 보여준다.

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in
engineering, yet its steep learning curve and complex manual setup create
significant barriers. To address these challenges, we introduce Foam-Agent, a
multi-agent framework that automates the entire end-to-end OpenFOAM workflow
from a single natural language prompt. Our key innovations address critical
gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:
Foam-Agent is the first system to manage the full simulation pipeline,
including advanced pre-processing with a versatile Meshing Agent capable of
handling external mesh files and generating new geometries via Gmsh, automatic
generation of HPC submission scripts, and post-simulation visualization via
ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,
the framework uses Model Context Protocol (MCP) to expose its core functions as
discrete, callable tools. This allows for flexible integration and use by other
agentic systems, such as Claude-code, for more exploratory workflows. 3.
High-Fidelity Configuration Generation: We achieve superior accuracy through a
Hierarchical Multi-Index RAG for precise context retrieval and a
dependency-aware generation process that ensures configuration consistency.
Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%
success rate with Claude 3.5 Sonnet, significantly outperforming existing
frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the
expertise barrier for CFD, demonstrating how specialized multi-agent systems
can democratize complex scientific computing. The code is public at
https://github.com/csml-rpi/Foam-Agent.

</details>


### [28] [Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models](https://arxiv.org/abs/2509.18221)
*Dingxin Lu,Shurui Wu,Xinyi Huang*

Main category: cs.AI

TL;DR: VL-RiskFormer는 다중 모드 AI 프레임워크로, 개인의 건강 위험을 예측하기 위한 혁신적인 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 만성 질환의 전 세계적인 부담 증가와 다양한 형태의 임상 데이터에 대한 수요를 충족시키기 위해 통합된 다중 모드 AI 프레임워크의 필요성이 절실합니다.

Method: VL-RiskFormer는 시각-언어 다중 모달 변환기로, 상위 레이어에 대형 언어 모델 추론 헤드를 내장합니다. 이 시스템은 기존의 시각-언어 모델의 이중 스트림 아키텍처를 기반으로 하며, 여러 가지 혁신이 포함됩니다.

Result: MIMIC-IV 장기 코호트에서 VL-RiskFormer는 0.90의 평균 AUROC와 2.7%의 기대 보정 오류를 달성했습니다.

Conclusion: 이러한 결과는 VL-RiskFormer가 건강 위험을 예측하는 데 효과적임을 나타냅니다.

Abstract: With the rising global burden of chronic diseases and the multimodal and
heterogeneous clinical data (medical imaging, free-text recordings, wearable
sensor streams, etc.), there is an urgent need for a unified multimodal AI
framework that can proactively predict individual health risks. We propose
VL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer
with a large language model (LLM) inference head embedded in its top layer. The
system builds on the dual-stream architecture of existing visual-linguistic
models (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with
cross-modal comparison and fine-grained alignment of radiological images,
fundus maps, and wearable device photos with corresponding clinical narratives
using momentum update encoders and debiased InfoNCE losses; (ii) a time fusion
block that integrates irregular visit sequences into the causal Transformer
decoder through adaptive time interval position coding; (iii) a disease
ontology map adapter that injects ICD-10 codes into visual and textual channels
in layers and infers comorbid patterns with the help of a graph attention
mechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an
average AUROC of 0.90 with an expected calibration error of 2.7 percent.

</details>


### [29] [An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems](https://arxiv.org/abs/2509.18229)
*Anthony Patera,Rohan Abeyaratne*

Main category: cs.AI

TL;DR: 본 연구에서는 GPT를 활용한 기계 공학 문제 분석의 신뢰성을 향상시키기 위한 N-Plus-1 GPT 에이전시를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 기계 공학 분석의 문제 해결에 있어 GPT의 불확실성 때문에 교육 및 엔지니어링 실무에서 직접 사용하기에 적합하지 않음.

Method: N 개의 Agent Solve 인스턴스를 사용하여 독립적인 문제 해결안을 도출하고, Agent Compare를 통해 이를 요약 및 비교하여 추천된 해결안을 제공함.

Result: N개의 제안된 문제 해결안 중에서 주된 제안이 올바른 해답일 확률이 50%를 초과할 경우 높아짐을 보임.

Conclusion: 저희의 에이전시는 투명성과 교육적 가치를 중시하며, 기존의 상업적 모델과 중요한 설계 및 성능에서 차별점을 나타남.

Abstract: Generative AI, and specifically GPT, can produce a remarkable solution to a
mechanical engineering analysis problem - but also, on occasion, a flawed
solution. For example, an elementary mechanics problem is solved flawlessly in
one GPT instance and incorrectly in a subsequent GPT instance, with a success
probability of only 85%. This unreliability renders "out-of-the-box" GPT
unsuitable for deployment in education or engineering practice. We introduce an
"N-Plus-1" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering
Problem Statements. Agency first launches N instantiations of Agent Solve to
yield N independent Proposed Problem Solution Realizations; Agency then invokes
Agent Compare to summarize and compare the N Proposed Problem Solution
Realizations and to provide a Recommended Problem Solution. We argue from
Condorcet's Jury Theorem that, for a Problem Statement characterized by
per-Solve success probability greater than 1/2 (and N sufficiently large), the
Predominant (Agent Compare) Proposed Problem Solution will, with high
probability, correspond to a Correct Proposed Problem Solution. Furthermore,
Agent Compare can also incorporate aspects of Secondary (Agent Compare)
Proposed Problem Solutions, in particular when the latter represent alternative
Problem Statement interpretations - different Mathematical Models - or
alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a
commercial multi-agent model, show similarities in design and performance, but
also important differences in emphasis: our Agency focuses on transparency and
pedagogical value.

</details>


### [30] [Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces](https://arxiv.org/abs/2509.18230)
*Zihan Dong,Xinyu Fan,Zixiang Tang,Yunqing Li*

Main category: cs.AI

TL;DR: ComputerAgent라는 경량의 계층 강화 학습 프레임워크를 통해 데스크탑 애플리케이션 제어 문제를 해결하고, 다양한 작업과 맥락을 처리하는 데 효과적이다.


<details>
  <summary>Details</summary>
Motivation: 데스크탑 애플리케이션을 소프트웨어를 통해 제어하는 문제는 여전히 해결되지 않은 중요한 문제이다.

Method: ComputerAgent는 OS 제어를 두 단계의 옵션 프로세스(관리자 및 서브정책)로 구성하며, 스크린샷, 작업 ID, 숫자 상태를 처리하기 위한 세 가지 모달 상태 인코더를 사용한다. 메타 액션과 조기 중지 메커니즘을 통합하여 낭비된 상호작용을 줄이고, compact vision backbone과 작은 정책 네트워크를 사용하여 기기 내 추론을 위해 1500만 개의 매개변수를 활용한다.

Result: 135개의 실제 데스크탑 작업에서 ComputerAgent는 간단한 작업(<8단계)에서 92.1%, 어려운 작업(>=8단계)에서 58.8%의 성공률을 달성하였다.

Conclusion: 계층 강화 학습은 컴퓨터 제어를 위한 모놀리식 MLLM 기반 자동화의 실용적이고 확장 가능한 대안을 제공한다.

Abstract: Controlling desktop applications via software remains a fundamental yet
under-served problem. Existing multi-modal large language models (MLLMs) ingest
screenshots and task instructions to generate keystrokes and mouse events, but
they suffer from prohibitive inference latency, poor sample efficiency on
long-horizon sparse-reward tasks, and infeasible on-device deployment. We
introduce a lightweight hierarchical reinforcement learning framework,
ComputerAgent, that formulates OS control as a two-level option process
(manager and subpolicy), employs a triple-modal state encoder (screenshot, task
ID, numeric state) to handle visual and contextual diversity, integrates
meta-actions with an early-stop mechanism to reduce wasted interactions, and
uses a compact vision backbone plus small policy networks for on-device
inference (15M parameters). On a suite of 135 real-world desktop tasks,
ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on
hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on
simple scenarios while reducing model size by over four orders of magnitude and
halving inference time. These results demonstrate that hierarchical RL offers a
practical, scalable alternative to monolithic MLLM-based automation for
computer control.

</details>


### [31] [Instruction-Following Evaluation in Function Calling for Large Language Models](https://arxiv.org/abs/2509.18420)
*Nikolai Skripko*

Main category: cs.AI

TL;DR: IFEval-FC는 함수 호출에서 정확한 지침 준수를 평가하는 새로운 벤치마크입니다.


<details>
  <summary>Details</summary>
Motivation: 기존 벤치마크는 인수의 정확성을 평가하지만, 매개변수 설명에 명시된 형식 지침 준수를 테스트하지 않습니다.

Method: IFEval-FC는 JSON 스키마 설명 내에 검증 가능한 형식을 인코딩하여 특정 값을 제시합니다.

Result: 최신 모델들도 기본 형식 규칙을 준수하지 못하는 경우가 많습니다.

Conclusion: IFEval-FC는 함수 호출에서의 형식 준수를 평가하는 데 중요한 역할을 하며, 실용적인 한계를 강조합니다.

Abstract: Function calling is a core capability of large language models, essential for
AI agents. Existing benchmarks such as the Berkeley Function Calling
Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench
(arXiv:2501.12851) evaluate argument correctness but do not test adherence to
format instructions embedded in parameter descriptions, such as enclosing
values in double quotes or using ISO date formats.
  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911)
that assesses precise instruction following in function calling. IFEval-FC
encodes verifiable formats directly within JSON schema descriptions, for
example specifying that a value must not contain punctuation. It includes 750
test cases, each consisting of a function with an embedded format for one of
its input parameters and a corresponding user query. Evaluation is fully
algorithmic, ensuring objectivity, reproducibility, and scalability.
  Our results show that even state-of-the-art proprietary models, including
GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules,
highlighting a practical limitation for real-world agent systems. The complete
codebase and data are publicly available at
https://github.com/Skripkon/IFEval-FC.

</details>


### [32] [LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs](https://arxiv.org/abs/2509.18557)
*Tom Pawelek,Raj Patel,Charlotte Crowell,Noorbakhsh Amiri,Sudip Mittal,Shahram Rahimi,Andy Perkins*

Main category: cs.AI

TL;DR: 본 논문에서는 기존의 탐지 기반 접근법을 넘어서는 LLMZ+ 접근법을 제안하며, 이를 통해 에이전틱 LLM과의 상호작용에서 안전한 메시지만 허용하도록 합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI는 데이터 소스와 API 툴에 대한 특권적 접근 권한을 가지고 있어 공격자에게 높은 가치를 제공하여 보안 위험이 증가합니다.

Method: LLMZ+는 프롬프트 화이트리스트를 구현하여 전통적인 탐지 기반 접근법을 넘어서며, 맥락에 적합하고 안전한 메시지만 에이전틱 LLM과 상호작용하도록 허용합니다.

Result: LLMZ+는 가장 일반적인 탈옥 프롬프트에 대해 강력한 저항력을 제공하며, 정당한 비즈니스 커뮤니케이션이 방해받지 않고 사용자는 에이전틱 LLM과 원활하게 소통할 수 있도록 합니다.

Conclusion: 우리의 실험적 평가 결과, LLMZ+는 오탐지율과 미탐지율을 모두 0으로 줄일 수 있음을 보여 줍니다.

Abstract: Compared to traditional models, agentic AI represents a highly valuable
target for potential attackers as they possess privileged access to data
sources and API tools, which are traditionally not incorporated into classical
agents. Unlike a typical software application residing in a Demilitarized Zone
(DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI
(only defining a final goal, leaving the path selection to LLM). This
characteristic introduces substantial security risk to both operational
security and information security. Most common existing defense mechanism rely
on detection of malicious intent and preventing it from reaching the LLM agent,
thus protecting against jailbreak attacks such as prompt injection. In this
paper, we present an alternative approach, LLMZ+, which moves beyond
traditional detection-based approaches by implementing prompt whitelisting.
Through this method, only contextually appropriate and safe messages are
permitted to interact with the agentic LLM. By leveraging the specificity of
context, LLMZ+ guarantees that all exchanges between external users and the LLM
conform to predefined use cases and operational boundaries. Our approach
streamlines the security framework, enhances its long-term resilience, and
reduces the resources required for sustaining LLM information security. Our
empirical evaluation demonstrates that LLMZ+ provides strong resilience against
the most common jailbreak prompts. At the same time, legitimate business
communications are not disrupted, and authorized traffic flows seamlessly
between users and the agentic LLM. We measure the effectiveness of approach
using false positive and false negative rates, both of which can be reduced to
0 in our experimental setting.

</details>


### [33] [Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents](https://arxiv.org/abs/2509.18633)
*Yara Mohajerani*

Main category: cs.AI

TL;DR: 이 논문은 기후 위험 평가를 위한 새로운 지리정보 기반 에이전트 모델을 제시하며, 이는 경제적 에이전트의 진화 학습을 통합하여 기후 해저드와 경제 시스템 간의 복잡한 상호작용을 모델링한다.


<details>
  <summary>Details</summary>
Motivation: 기후 위험 평가를 위해 공간적으로 이질적인 해저드와 적응 경제 시스템 간의 복잡한 상호작용을 모델링할 필요가 있다.

Method: Mesa 기반 공간 모델링과 CLIMADA 기후 영향 평가를 결합한 새로운 에이전트 기반 모델을 제시하며, 적응 학습 행동을 도입하여 기업이 예산 배분, 가격, 임금 및 위험 적응 전략을 진화시킬 수 있도록 한다.

Result: 2100년까지 RCP8.5 하의 강 우식 예측을 사용하여 이 프레임워크를 입증하였고, 진화적 적응을 통해 기업들이 기후 스트레스로 인한 수십 년의 혼란 후에도 기준 생산 수준에 수렴할 수 있음을 보여주었다.

Conclusion: 결과는 홍수에 직접 노출되지 않은 에이전트 조차도 공급망 중단을 통해 영향을 받음을 확인하였으며, RCP8.5 하에서 상품의 평균 가격이 기준선보다 5.6% 높아짐을 나타낸다. 이 오픈 소스 프레임워크는 금융 기관과 기업이 직접적 및 연쇄적 기후 위험을 정량화할 수 있는 도구를 제공한다.

Abstract: Climate risk assessment requires modelling complex interactions between
spatially heterogeneous hazards and adaptive economic systems. We present a
novel geospatial agent-based model that integrates climate hazard data with
evolutionary learning for economic agents. Our framework combines Mesa-based
spatial modelling with CLIMADA climate impact assessment, introducing adaptive
learning behaviours that allow firms to evolve strategies for budget
allocation, pricing, wages, and risk adaptation through fitness-based selection
and mutation. We demonstrate the framework using riverine flood projections
under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to
converge with baseline (no hazard) production levels after decades of
disruption due to climate stress. Our results reveal systemic risks where even
agents that are not directly exposed to floods face impacts through supply
chain disruptions, with the end-of-century average price of goods 5.6% higher
under RCP8.5 compared to the baseline. This open-source framework provides
financial institutions and companies with tools to quantify both direct and
cascading climate risks while evaluating cost-effective adaptation strategies.

</details>


### [34] [Autonomous Data Agents: A New Opportunity for Smart Data](https://arxiv.org/abs/2509.18710)
*Yanjie Fu,Dongjie Wang,Wangyang Ying,Xiangliang Zhang,Huan Liu,Jian Pei*

Main category: cs.AI

TL;DR: 자율 데이터 에이전트(DataAgents)는 복잡하고 비구조적인 데이터를 실행 가능하고 일관된 지식으로 변환합니다.


<details>
  <summary>Details</summary>
Motivation: 데이터의 규모와 복잡성이 계속 증가함에 따라 데이터 준비, 변환 및 분석 과정이 노동 집약적이고 반복적이며 확장하기 어려운 상황입니다. AI와 데이터 간의 정렬이 필수적입니다.

Method: 자율 데이터 에이전트는 LLM 추론과 작업 분해, 행동 추론 및 도구 호출을 통합하여 데이터 작업 설명을 해석하고, 작업을 하위 작업으로 분해하며, 행동을 추론하고, 이를 파이썬 코드나 도구 호출로 변환하여 운영을 실행합니다.

Result: DataAgents는 데이터 수집, 통합, 전처리, 선택, 변환, 재가중, 증강, 재프로그래밍, 수리 및 검색을 처리할 수 있습니다. 이러한 기능을 통해 복잡하고 비구조적인 데이터를 일관되고 실행 가능한 지식으로 변환합니다.

Conclusion: 우리는 에이전틱 AI와 데이터-지식 시스템의 융합이 중요한 트렌드로 떠오른 이유를 살펴본 후, 데이터 에이전트의 개념을 정의하고 그 구조 디자인, 훈련 전략, 새로운 기술 및 기능을 논의합니다. 마지막으로 악의적인 행동을 방지하기 위한 신뢰할 수 있는 데이터 에이전트 가드레일을 개발하고, 작업 흐름 최적화 및 개방형 데이터셋, 벤치마크 생태계 구축을 위한 공동의 노력을 촉구합니다.

Abstract: As data continues to grow in scale and complexity, preparing, transforming,
and analyzing it remains labor-intensive, repetitive, and difficult to scale.
Since data contains knowledge and AI learns knowledge from it, the alignment
between AI and data is essential. However, data is often not structured in ways
that are optimal for AI utilization. Moreover, an important question arises:
how much knowledge can we pack into data through intensive data operations?
Autonomous data agents (DataAgents), which integrate LLM reasoning with task
decomposition, action reasoning and grounding, and tool calling, can
autonomously interpret data task descriptions, decompose tasks into subtasks,
reason over actions, ground actions into python code or tool calling, and
execute operations. Unlike traditional data management and engineering tools,
DataAgents dynamically plan workflows, call powerful tools, and adapt to
diverse data tasks at scale. This report argues that DataAgents represent a
paradigm shift toward autonomous data-to-knowledge systems. DataAgents are
capable of handling collection, integration, preprocessing, selection,
transformation, reweighing, augmentation, reprogramming, repairs, and
retrieval. Through these capabilities, DataAgents transform complex and
unstructured data into coherent and actionable knowledge. We first examine why
the convergence of agentic AI and data-to-knowledge systems has emerged as a
critical trend. We then define the concept of DataAgents and discuss their
architectural design, training strategies, as well as the new skills and
capabilities they enable. Finally, we call for concerted efforts to advance
action workflow optimization, establish open datasets and benchmark ecosystems,
safeguard privacy, balance efficiency with scalability, and develop trustworthy
DataAgent guardrails to prevent malicious actions.

</details>


### [35] [The AGNTCY Agent Directory Service: Architecture and Implementation](https://arxiv.org/abs/2509.18787)
*Luca Muscariello,Vijoy Pandey,Ramiz Polic*

Main category: cs.AI

TL;DR: ADS는 AI 에이전트의 기능과 메타데이터를 발견하기 위한 분산 디렉토리 서비스이다.


<details>
  <summary>Details</summary>
Motivation: 다양한 Multi-Agent Systems에서 AI 에이전트의 기능을 효율적이고 입증 가능한 방식으로 발견하기 위해 필요하다.

Method: ADS는 Kademlia 기반의 분산 해시 테이블을 이용한 이중 매핑을 통해 기능 인덱싱과 콘텐츠 위치를 분리하여 구축된다.

Result: ADS는 성숙한 OCI/ORAS 인프라를 재사용하고, provenance를 위해 Sigstore를 통합하며, 에이전트 모달리티에 대한 스키마 기반 확장성을 지원한다.

Conclusion: 이 논문은 ADS의 아키텍처 모델을 공식화하고, 저장 및 발견 계층을 설명하며, 보안 및 성능 속성을 설명하고, emergent agent registry와 상호 운용성 이니셔티브의 broader landscape에서 ADS의 위치를 확인한다.

Abstract: The Agent Directory Service (ADS) is a distributed directory for the
discovery of AI agent capabilities, metadata, and provenance. It leverages
content-addressed storage, hierarchical taxonomies, and cryptographic signing
to enable efficient, verifiable, and multi-dimensional discovery across
heterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema
Framework (OASF), ADS decouples capability indexing from content location
through a two-level mapping realized over a Kademlia-based Distributed Hash
Table (DHT). It reuses mature OCI / ORAS infrastructure for artifact
distribution, integrates Sigstore for provenance, and supports schema-driven
extensibility for emerging agent modalities (LLM prompt agents, MCP servers,
A2A-enabled components). This paper formalizes the architectural model,
describes storage and discovery layers, explains security and performance
properties, and positions ADS within the broader landscape of emerging agent
registry and interoperability initiatives.

</details>


### [36] [Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling](https://arxiv.org/abs/2509.18864)
*Yingxin Li,Jianbo Zhao,Xueyu Ren,Jie Tang,Wangjie You,Xu Chen,Kan Zhou,Chao Feng,Jiao Ran,Yuan Meng,Zhi Wang*

Main category: cs.AI

TL;DR: 사용자 프로파일링을 위한 새로운 벤치마크 ProfileBench와 이를 통해 개발된 Conf-Profile 프레임워크를 제안하며, 두 단계의 훈련 과정을 통해 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 사용자 이해를 위한 핵심 기술로서 사용자 프로파일링의 필요성을 강조하고, 대규모 언어 모델(LLM)을 활용한 사용자 프로파일링의 발전 여지를 탐구합니다.

Method: Confidence-driven Profile reasoning framework인 Conf-Profile을 제안하며, 고품질 라벨을 합성하고 신뢰도 기반 투표 및 신뢰도 보정을 통해 프로파일링의 품질을 개선하는 두 단계의 패러다임을 활용합니다.

Result: Conf-Profile은 Qwen3-8B에서 F1 점수를 13.97 향상시키며 실험 결과에서 상당한 성능 향상을 보여줍니다.

Conclusion: Conf-Profile이 라벨 없는 신뢰할 수 있는 사용자 프로파일링을 달성할 수 있는 가능성을 제시합니다.

Abstract: User profiling, as a core technique for user understanding, aims to infer
structural attributes from user information. Large Language Models (LLMs)
provide a promising avenue for user profiling, yet the progress is hindered by
the lack of comprehensive benchmarks. To bridge this gap, we propose
ProfileBench, an industrial benchmark derived from a real-world video platform,
encompassing heterogeneous user data and a well-structured profiling taxonomy.
However, the profiling task remains challenging due to the difficulty of
collecting large-scale ground-truth labels, and the heterogeneous and noisy
user information can compromise the reliability of LLMs. To approach label-free
and reliable user profiling, we propose a Confidence-driven Profile reasoning
framework Conf-Profile, featuring a two-stage paradigm. We first synthesize
high-quality labels by leveraging advanced LLMs with confidence hints, followed
by confidence-weighted voting for accuracy improvement and confidence
calibration for a balanced distribution. The multiple profile results,
rationales, and confidence scores are aggregated and distilled into a
lightweight LLM. We further enhance the reasoning ability via confidence-guided
unsupervised reinforcement learning, which exploits confidence for difficulty
filtering, quasi-ground truth voting, and reward weighting. Experimental
results demonstrate that Conf-Profile delivers substantial performance through
the two-stage training, improving F1 by 13.97 on Qwen3-8B.

</details>


### [37] [LongCat-Flash-Thinking Technical Report](https://arxiv.org/abs/2509.18883)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chengcheng Han,Chenhui Yang,Chi Zhang,Chong Peng,Chuyu Zhang,Cong Chen,Fengcun Li,Gang Xu,Guoyuan Lin,Hao Jiang,Hao Liang,Haomin Fu,Haoxiang Ma,Hong Liu,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiahao Liu,Jiahuan Li,Jialin Liu,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiaqi Sun,Jiaqi Zhang,Jiarong Shi,Jiawei Yang,Jingang Wang,Jinrui Ding,Jun Kuang,Jun Xu,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Li Wei,Liang Shi,Lin Qiu,Lingbin Kong,Lingchuan Liu,Linsen Guo,Longfei An,Mai Xia,Meng Zhou,Mengshen Zhu,Peng Pei,Pengcheng Jia,Qi Gu,Qi Guo,Qiong Huang,Quan Chen,Quanchi Weng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shanglin Lei,Shuai Du,Shuaikang Liu,Shuang Zhou,Shuhao Hu,Siyu Xu,Songshan Gong,Tao Liang,Tianhao Hu,Wei He,Wei Shi,Wei Wang,Wei Wu,Wei Zhuo,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Xi Su,Xiangcheng Liu,Xiangyu Xi,Xiangzhou Huang,Xiao Liu,Xiaochen Jiang,Xiaowei Shi,Xiaowen Shi,Xiaoyu Li,Xin Chen,Xinyue Zhao,Xuan Huang,Xuemiao Zhang,Xuezhi Cao,Xunliang Cai,Yajie Zhang,Yang Chen,Yang Liu,Yang Liu,Yang Zheng,Yaoming Wang,Yaqi Huo,Yerui Sun,Yifan Lu,Yiyang Li,Youshao Xiao,Yuanzhe Lei,Yuchen Xie,Yueqing Sun,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunke Zhao,Yuqing Ding,Yuwei Jiang,Zhaohua Yang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhongda Su,Ziran Li,Ziwen Wang,Ziyuan Zhuang,Zongyu Wang,Zunyuan Yang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking은 5600억 개의 매개변수를 가진 효율적인 오픈소스 혼합 전문가 모델로, 효율적인 훈련 과정을 통해 고급 기능을 발휘한다.


<details>
  <summary>Details</summary>
Motivation: 효율적인 추론 모델을 개발하고 추가적인 연구의 발전을 촉진하기 위해.

Method: 긴 Chain-of-Thought 데이터를 이용한 초기 훈련과 대규모 강화 학습을 결합한 훈련 과정을 통해 모델을 훈련시킨다.

Result: 모델은 AIME-25에서 평균 토큰 소비를 64.5% 줄이며 뛰어난 효율성을 보여주고, 오픈소스 모델 중에서 최첨단 성능을 기록한다.

Conclusion: LongCat-Flash-Thinking은 추론 시스템 및 에이전트 AI 연구에서의 발전을 촉진하기 위해 공개된다.

Abstract: We present LongCat-Flash-Thinking, an efficient 560-billion-parameter
open-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities
are cultivated through a meticulously crafted training process, beginning with
long Chain-of-Thought (CoT) data cold-start and culminating in large-scale
Reinforcement Learning (RL). We first employ a well-designed cold-start
training strategy, which significantly enhances the reasoning potential and
equips the model with specialized skills in both formal and agentic reasoning.
Then, a core innovation is our domain-parallel training scheme, which decouples
optimization across distinct domains (e.g., STEM, Code, Agentic) and
subsequently fuses the resulting expert models into a single, nearly
Pareto-optimal model. This entire process is powered by our Dynamic
ORchestration for Asynchronous rollout (DORA) system, a large-scale RL
framework that delivers a greater than threefold training speedup over
synchronous methods on tens of thousands of accelerators. As a result,
LongCat-Flash-Thinking achieves state-of-the-art performance among open-source
models on a suite of complex reasoning tasks. The model exhibits exceptional
efficiency in agentic reasoning, reducing average token consumption by 64.5%
(from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We
release LongCat-Flash-Thinking to promote further advances in reasoning systems
and agentic AI research.

</details>


### [38] [How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective](https://arxiv.org/abs/2509.18905)
*Songsong Yu,Yuxin Chen,Hao Ju,Lianjie Jia,Fuxi Zhang,Shaofei Huang,Yuhan Wu,Rundi Cui,Binghao Ran,Zaibin Zhang,Zhedong Zheng,Zhipeng Zhang,Yifan Wang,Lin Song,Lijun Wang,Yanwei Li,Ying Shan,Huchuan Lu*

Main category: cs.AI

TL;DR: 본 연구에서는 비전-언어 모델(VLM)에서의 시각적 공간 추론(VSR)을 체계적으로 조사하였다. 우리는 공간 지능을 3가지 능력 수준으로 분류하고, 20개의 오픈 소스 데이터셋을 포함한 SIBench라는 벤치마크를 구축하였다. 실험 결과, 모델들은 기본적인 지각 작업에는 능숙하지만, 이해 및 계획 작업에서는 지속적으로 성과가 떨어지는 것으로 나타났다.


<details>
  <summary>Details</summary>
Motivation: 인간의 인지 능력인 시각적 공간 추론은 구현된 지능과 자율 시스템의 발전에 중요한 요소이다.

Method: 기존의 방법론을 검토하고, 공간 지능을 기본 지각, 공간 이해, 공간 계획의 세 가지 능력 수준으로 분류하였다. 또한 23개의 작업 설정에 걸쳐 20개의 오픈 소스 데이터셋을 포함하는 벤치마크인 SIBench를 마련하였다.

Result: 최신 VLM을 사용한 실험에서 모델들은 기본적인 지각 작업에서는 뛰어난 성능을 보였으나, 이해 및 계획 작업에서는 성과가 부족함을 보여주었다.

Conclusion: 이 연구는 공간 지능을 달성하기 위한 상당한 도전 과제를 강조하며, 향후 연구를 위한 체계적인 로드맵과 포괄적인 벤치마크를 제공한다.

Abstract: Visual Spatial Reasoning (VSR) is a core human cognitive ability and a
critical requirement for advancing embodied intelligence and autonomous
systems. Despite recent progress in Vision-Language Models (VLMs), achieving
human-level VSR remains highly challenging due to the complexity of
representing and reasoning over three-dimensional space. In this paper, we
present a systematic investigation of VSR in VLMs, encompassing a review of
existing methodologies across input modalities, model architectures, training
strategies, and reasoning mechanisms. Furthermore, we categorize spatial
intelligence into three levels of capability, ie, basic perception, spatial
understanding, spatial planning, and curate SIBench, a spatial intelligence
benchmark encompassing nearly 20 open-source datasets across 23 task settings.
Experiments with state-of-the-art VLMs reveal a pronounced gap between
perception and reasoning, as models show competence in basic perceptual tasks
but consistently underperform in understanding and planning tasks, particularly
in numerical estimation, multi-view reasoning, temporal dynamics, and spatial
imagination. These findings underscore the substantial challenges that remain
in achieving spatial intelligence, while providing both a systematic roadmap
and a comprehensive benchmark to drive future research in the field. The
related resources of this study are accessible at
https://sibench.github.io/Awesome-Visual-Spatial-Reasoning/.

</details>


### [39] [LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions](https://arxiv.org/abs/2509.18970)
*Xixun Lin,Yucheng Ning,Jingwen Zhang,Yan Dong,Yilong Liu,Yongxuan Wu,Xiaohua Qi,Nan Sun,Yanmin Shang,Pengfei Cao,Lixin Zou,Xu Chen,Chuan Zhou,Jia Wu,Shirui Pan,Bin Wang,Yanan Cao,Kai Chen,Songlin Hu,Li Guo*

Main category: cs.AI

TL;DR: 본 연구는 LLM 기반 에이전트의 환각 문제를 다룬 최초의 포괄적인 조사로, 환각의 유형과 원인을 분석하고, 이를 완화 및 탐지하기 위한 방법을 요약합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트는 잠재력에도 불구하고 환각 문제에 취약하며, 이는 시스템 신뢰성에 영향을 미칠 수 있습니다.

Method: 에이전트의 완전한 작업 흐름을 분석하고, 환각의 다양한 유형을 식별하는 새로운 분류체계를 제안합니다. 또한, 환각의 발생 원인에 대한 심층 조사를 실시합니다.

Result: 18가지 환각 유발 원인을 분석하고, 환각 완화 및 탐지 방법을 요약하였습니다.

Conclusion: 이 조사를 통해 LLM 기반 에이전트의 환각 문제 해결에 대한 동기 부여가 이루어지기를 희망합니다.

Abstract: Driven by the rapid advancements of Large Language Models (LLMs), LLM-based
agents have emerged as powerful intelligent systems capable of human-like
cognition, reasoning, and interaction. These agents are increasingly being
deployed across diverse real-world applications, including student education,
scientific research, and financial analysis. However, despite their remarkable
potential, LLM-based agents remain vulnerable to hallucination issues, which
can result in erroneous task execution and undermine the reliability of the
overall system design. Addressing this critical challenge requires a deep
understanding and a systematic consolidation of recent advances on LLM-based
agents. To this end, we present the first comprehensive survey of
hallucinations in LLM-based agents. By carefully analyzing the complete
workflow of agents, we propose a new taxonomy that identifies different types
of agent hallucinations occurring at different stages. Furthermore, we conduct
an in-depth examination of eighteen triggering causes underlying the emergence
of agent hallucinations. Through a detailed review of a large number of
existing studies, we summarize approaches for hallucination mitigation and
detection, and highlight promising directions for future research. We hope this
survey will inspire further efforts toward addressing hallucinations in
LLM-based agents, ultimately contributing to the development of more robust and
reliable agent systems.

</details>


### [40] [Code Driven Planning with Domain-Adaptive Critic](https://arxiv.org/abs/2509.19077)
*Zikang Tian,Shaohui Peng,Du Huang,Jiaming Guo,Ruizhi Chen,Rui Zhang,Xishan Zhang,Yuxuan Guo,Zidong Du,Qi Guo,Ling Li,Yewen Pu,Xing Hu,Yunji Chen*

Main category: cs.AI

TL;DR: CoPiC는 LLM을 이용하여 다양한 고수준 계획 프로그램을 생성하고 장기 보상에 맞는 계획을 선택하여 실행하는 방법이다. 이는 쿼리 비용을 크게 줄이면서 계획 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존의 접근 방식은 환경에 대한 즉각적인 피드백을 바탕으로 계획을 반복적으로 수정하기 위해 LLM에 대한 빈번한 쿼리에 의존하여 비용이 많이 드는 쿼리 비용을 초래한다.

Method: CoPiC는 LLM을 사용하여 다양한 고수준 계획 프로그램을 생성하고 이 후보 계획을 반복적으로 생성 및 수정하는 방식을 사용한다. 훈련된 도메인 적응 비평가는 이러한 후보를 평가하고 장기 보상에 가장 aligned된 것을 선택하여 실행한다.

Result: ALFWorld, NetHack, StarCraft II Unit Building에서 CoPiC는 AdaPlanner 및 Reflexion과 같은 고급 LLM 기반 기준선보다 우수한 성능을 보였으며, 평균적으로 (1) 23.33%의 성공률 향상 및 (2) 91.27%의 쿼리 비용 절감을 달성했다.

Conclusion: CoPiC는 계획 성능을 향상시키면서도 쿼리 비용을 현저히 줄이는 혁신적인 접근 방식이다.

Abstract: Large Language Models (LLMs) have been widely adopted as task planners for AI
agents in sequential decision-making problems, leveraging their extensive world
knowledge. However, the gap between their general knowledge and
environment-specific requirements often leads to inaccurate plans. To address
this, existing approaches rely on frequent LLM queries to iteratively refine
plans based on immediate environmental feedback, which incurs substantial query
costs. However, this refinement is typically guided by short-term environmental
feedback, limiting LLMs from developing plans aligned with long-term rewards.
We propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of
relying on frequent queries, CoPiC employs LLMs to generate a diverse set of
high-level planning programs, which iteratively produce and refine candidate
plans. A trained domain-adaptive critic then evaluates these candidates and
selects the one most aligned with long-term rewards for execution. Using
high-level planning programs as planner and domain-adaptive critic as
estimator, CoPiC improves planning while significantly reducing query costs.
Results in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC
outperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving
an average (1) 23.33% improvement in success rate and (2) 91.27% reduction in
query costs.

</details>


### [41] [AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration](https://arxiv.org/abs/2509.19236)
*Chunhao Tian,Yutong Wang,Xuebo Liu,Zhexuan Wang,Liang Ding,Miao Zhang,Min Zhang*

Main category: cs.AI

TL;DR: AgentInit는 다중 에이전트 시스템의 초기화를 최적화하여 시스템 성능을 향상시키는 새로운 방법이다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템의 초기화는 시스템의 효율성과 효과성을 결정짓는 중요한 요소이다.

Method: AgentInit는 에이전트의 생성 중 다중 라운드 상호작용과 반사를 포함하고, 자연어를 포맷으로 변환하는 메커니즘을 사용하여 일관성과 표준화를 보장한다.

Result: AgentInit는 다양한 프레임워크와 작업에서 최첨단 초기화 방법 및 사전 정의된 전략을 일관되게 초월하며 성능 개선을 이룬다.

Conclusion: AgentInit는 다중 에이전트 시스템 초기화 방법으로서 우수한 성능과 적응성을 입증하였다.

Abstract: Proper initialization is crucial for any system, particularly in multi-agent
systems (MAS), where it plays a pivotal role in determining both the system's
efficiency and effectiveness. However, existing MAS initialization methods do
not fully account for the collaborative needs of the generated agents in
subsequent stages. Inspired by the principles of effective team composition, we
propose AgentInit, which aims to optimize the structure of agent teams.
Specifically, in addition to multi-round interactions and reflections between
agents during agent generation, AgentInit incorporates a Natural Language to
Format mechanism to ensure consistency and standardization. Balanced team
selection strategies using Pareto principles are subsequently applied to
jointly consider agent team diversity and task relevance to promote effective
and efficient collaboration and enhance overall system performance. Experiments
show that AgentInit consistently outperforms state-of-the-art initialization
methods and pre-defined strategies across various frameworks and tasks,
achieving an overall performance improvement of up to 1.2 and 1.6,
respectively, while also significantly reducing token consumption. Further
analysis confirms its strong transferability to similar tasks and verifies the
effectiveness of its key components, demonstrating its capability and
adaptability as a reliable MAS initialization method. Source code and models
are available at https://github.com/1737423697/AgentInit.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [42] [Context Lineage Assurance for Non-Human Identities in Critical Multi-Agent Systems](https://arxiv.org/abs/2509.18415)
*Sumana Malkapuram,Sameera Gangavarapu,Kailashnath Reddy Kavalakuntla,Ananya Gangavarapu*

Main category: cs.CR

TL;DR: 이 논문에서는 자율 소프트웨어 에이전트 간의 상호작용을 안전하게 만들기 위한 암호학적으로 기반한 계보 검증 메커니즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 소프트웨어 에이전트의 확산은 안전하고 검증 가능한 에이전트 간 상호작용을 위한 엄격한 프레임워크의 필요성을 강조한다.

Method: 비인간 정체성(NHI)의 계보와 진화를 증명하기 위해 인증 투명성(CT) 로그를 모델로 한 추가 전용 머클 트리 구조에 기반한 메커니즘을 도입한다.

Result: 우리의 접근 방식은 에이전트와 외부 검증자가 다단계 계보를 암호학적으로 검증할 수 있게 하여 전체 호출 체인의 무결성을 보장한다.

Conclusion: 이러한 기여들은 정체성 증명, 계보 검증, 독립적인 증명 감사 기능을 통합하는 일관된 모델을 확립하여 에이전트 간 생태계의 보안 태세를 향상시키고 규제 환경에서 NHI의 강력한 거버넌스를 위한 기반을 제공한다.

Abstract: The proliferation of autonomous software agents necessitates rigorous
frameworks for establishing secure and verifiable agent-to-agent (A2A)
interactions, particularly when such agents are instantiated as non-human
identities(NHIs). We extend the A2A paradigm [1 , 2] by introducing a
cryptographically grounded mechanism for lineage verification, wherein the
provenance and evolution of NHIs are anchored in append-only Merkle tree
structures modeled after Certificate Transparency (CT) logs. Unlike traditional
A2A models that primarily secure point-to-point interactions, our approach
enables both agents and external verifiers to cryptographically validate
multi-hop provenance, thereby ensuring the integrity of the entire call chain.
  A federated proof server acts as an auditor across one or more Merkle logs,
aggregating inclusion proofs and consistency checks into compact, signed
attestations that external parties can verify without access to the full
execution trace. In parallel, we augment the A2A agent card to incorporate
explicit identity verification primitives, enabling both peer agents and human
approvers to authenticate the legitimacy of NHI representations in a
standardized manner. Together, these contributions establish a cohesive model
that integrates identity attestation, lineage verification, and independent
proof auditing, thereby advancing the security posture of inter-agent
ecosystems and providing a foundation for robust governance of NHIs in
regulated environments such as FedRAMP.

</details>


### [43] [Examining I2P Resilience: Effect of Centrality-based Attack](https://arxiv.org/abs/2509.18572)
*Kemi Akanbi,Sunkanmi Oluwadare,Jess Kropczynski,Jacques Bou Abdo*

Main category: cs.CR

TL;DR: 이 연구는 익명성과 기밀성을 보장하는 I2P 네트워크의 견고성을 분석한다.


<details>
  <summary>Details</summary>
Motivation: I2P의 회복력에 대한 연구는 상대적으로 적으며, 이는 TOR에 비해 적은 관심을 받고 있다.

Method: 네트워크 분석을 통해 I2P의 적대적 침투에 대한 취약성을 평가했다.

Result: 네트워크의 밀도가 약 10% 감소하고 평균 경로 길이가 33% 증가하여 효율성과 연결성의 감소가 나타났다.

Conclusion: I2P와 같은 분산 네트워크도 목표 공격 아래에서 구조적 취약성을 드러내며, 적대적 disruptions에 대한 회복력을 향상시킬 필요가 있음을 강조한다.

Abstract: This study examines the robustness of I2P, a well-regarded anonymous and
decentralized peer-to-peer network designed to ensure anonymity,
confidentiality, and circumvention of censorship. Unlike its more widely
researched counterpart, TOR, I2P's resilience has received less scholarly
attention. Employing network analysis, this research evaluates I2P's
susceptibility to adversarial percolation. By utilizing the degree centrality
as a measure of nodes' influence in the network, the finding suggests the
network is vulnerable to targeted disruptions. Before percolation, the network
exhibited a density of 0.01065443 and an average path length of 6.842194. At
the end of the percolation process, the density decreased by approximately 10%,
and the average path length increased by 33%, indicating a decline in
efficiency and connectivity. These results highlight that even decentralized
networks, such as I2P, exhibit structural fragility under targeted attacks,
emphasizing the need for improved design strategies to enhance resilience
against adversarial disruptions.

</details>


### [44] [Detection of security smells in IaC scripts through semantics-aware code and language processing](https://arxiv.org/abs/2509.18790)
*Aicha War,Adnan A. Rawass,Abdoul K. Kabore,Jordan Samhi,Jacques Klein,Tegawende F. Bissyande*

Main category: cs.CR

TL;DR: 정적 분석에 자연어 및 코드 표현을 결합하여 IaC의 보안 구성 오류를 탐지하는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: IaC 스크립트에는 보안 misconfiguration이 자주 발생하며, 이를 탐지하고 완화하기 위한 접근 방식들이 제안되었다.

Method: CodeBERT와 LongFormer라는 두 개의 상보적인 ML 모델을 통해 코드 및 텍스트의 의미를 포착하고 긴 IaC 스크립트를 표현한다.

Result: 두 개의 IaC 도구인 Ansible과 Puppet의 misconfiguration 데이터셋에서 평가한 결과, 정적 분석에 의미론적 강화가 미치는 긍정적인 영향을 확인했다.

Conclusion: 의미론적 강화는 탐지 성능을 현저히 향상시켜, Ansible과 Puppet에서 각각 0.92와 0.88, 그리고 0.87과 0.75로 정밀도와 재현율을 높였다.

Abstract: Infrastructure as Code (IaC) automates the provisioning and management of IT
infrastructure through scripts and tools, streamlining software deployment.
Prior studies have shown that IaC scripts often contain recurring security
misconfigurations, and several detection and mitigation approaches have been
proposed. Most of these rely on static analysis, using statistical code
representations or Machine Learning (ML) classifiers to distinguish insecure
configurations from safe code.
  In this work, we introduce a novel approach that enhances static analysis
with semantic understanding by jointly leveraging natural language and code
representations. Our method builds on two complementary ML models: CodeBERT, to
capture semantics across code and text, and LongFormer, to represent long IaC
scripts without losing contextual information. We evaluate our approach on
misconfiguration datasets from two widely used IaC tools, Ansible and Puppet.
To validate its effectiveness, we conduct two ablation studies (removing code
text from the natural language input and truncating scripts to reduce context)
and compare against four large language models (LLMs) and prior work. Results
show that semantic enrichment substantially improves detection, raising
precision and recall from 0.46 and 0.79 to 0.92 and 0.88 on Ansible, and from
0.55 and 0.97 to 0.87 and 0.75 on Puppet, respectively.

</details>


### [45] [R-CONV++: Uncovering Privacy Vulnerabilities through Analytical Gradient Inversion Attacks](https://arxiv.org/abs/2509.18871)
*Tamer Ahmed Eltaras,Qutaibah Malluhi,Alessandro Savino,Stefano Di Carlo,Adnan Qayyum*

Main category: cs.CR

TL;DR: 연합 학습은 원시 데이터를 공유하는 대신 경량화된 데이터 집합을 활용하기 위한 프라이버시 보호 기술로 부상했지만, 최근 연구에서는 경량화된 데이터가 여전히 공격에 노출될 수 있음을 보여주고 있습니다. 이 논문은 경량화 공격의 적용 가능성을 확장하기 위한 세 가지 고급 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습에서 경량화 데이터 공격의 가능성을 확장하여 프라이버시 보호 기술의 안전성을 높이고자 합니다.

Method: 세 가지 알고리즘을 제안합니다. 첫 번째 알고리즘은 비가역 활성화 함수를 사용해도 경량화를 통해 샘플을 재구성할 수 있는 데이터 유출 방식을 제시합니다. 두 번째 알고리즘은 고차원 입력 데이터를 지원하는 분석적 접근 방식을 확장합니다. 세 번째 알고리즘은 미니 배치를 재구성하기 위한 혁신적인 분석 방법을 도입합니다.

Result: 제안한 알고리즘을 통해 복잡한 데이터 세트에서 입력 데이터를 효과적으로 재구성할 수 있습니다.

Conclusion: 전반적으로 경량화 공격에서 경량화 제약의 중요성을 강조하며, 더 적은 수의 제약으로도 성공적인 공격이 가능하다는 것을 보여줍니다.

Abstract: Federated learning has emerged as a prominent privacy-preserving technique
for leveraging large-scale distributed datasets by sharing gradients instead of
raw data. However, recent studies indicate that private training data can still
be exposed through gradient inversion attacks. While earlier analytical methods
have demonstrated success in reconstructing input data from fully connected
layers, their effectiveness significantly diminishes when applied to
convolutional layers, high-dimensional inputs, and scenarios involving multiple
training examples. This paper extends our previous work \cite{eltaras2024r} and
proposes three advanced algorithms to broaden the applicability of gradient
inversion attacks. The first algorithm presents a novel data leakage method
that efficiently exploits convolutional layer gradients, demonstrating that
even with non-fully invertible activation functions, such as ReLU, training
samples can be analytically reconstructed directly from gradients without the
need to reconstruct intermediate layer outputs. Building on this foundation,
the second algorithm extends this analytical approach to support
high-dimensional input data, substantially enhancing its utility across complex
real-world datasets. The third algorithm introduces an innovative analytical
method for reconstructing mini-batches, addressing a critical gap in current
research that predominantly focuses on reconstructing only a single training
example. Unlike previous studies that focused mainly on the weight constraints
of convolutional layers, our approach emphasizes the pivotal role of gradient
constraints, revealing that successful attacks can be executed with fewer than
5\% of the constraints previously deemed necessary in certain layers.

</details>


### [46] [LLM-based Vulnerability Discovery through the Lens of Code Metrics](https://arxiv.org/abs/2509.19117)
*Felix Weissberg,Lukas Pirch,Erik Imgrund,Jonas Möller,Thorsten Eisenhofer,Konrad Rieck*

Main category: cs.CR

TL;DR: 대규모 언어 모델(LLMs)은 소프트웨어 공학에서 많은 작업을 잘 수행하지만, 최근 몇 년 동안 취약성 발견에서의 활용이 정체되었습니다. 본 연구에서는 전통적인 코드 메트릭을 통해 LLM을 조사하고, 그 결과로 LLM이 복잡한 패턴을 파악하는 능력이 제한적임을 확인하였습니다. 이에 따라 연구가 이러한 문제를 보다 효과적으로 해결하는 방법에 대한 권장 사항을 도출하였습니다.


<details>
  <summary>Details</summary>
Motivation: LLM을 활용한 취약성 발견의 정체 현상 이해

Method: 전통적인 코드 메트릭을 통한 LLM 분석 및 비교

Result: 메트릭을 기반으로 한 분류기가 최신 LLM과 유사한 성능을 보임과 동시에 LLM과 코드 메트릭 간의 강한 상관관계 및 인과 관계를 발견

Conclusion: LLM이 복잡한 패턴을 파악하는 능력이 제한적이며, 이후 연구에 대한 권장 사항을 도출

Abstract: Large language models (LLMs) excel in many tasks of software engineering, yet
progress in leveraging them for vulnerability discovery has stalled in recent
years. To understand this phenomenon, we investigate LLMs through the lens of
classic code metrics. Surprisingly, we find that a classifier trained solely on
these metrics performs on par with state-of-the-art LLMs for vulnerability
discovery. A root-cause analysis reveals a strong correlation and a causal
effect between LLMs and code metrics: When the value of a metric is changed,
LLM predictions tend to shift by a corresponding magnitude. This dependency
suggests that LLMs operate at a similarly shallow level as code metrics,
limiting their ability to grasp complex patterns and fully realize their
potential in vulnerability discovery. Based on these findings, we derive
recommendations on how research should more effectively address this challenge.

</details>
