<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 14]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.CR](#cs.CR) [Total: 3]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Bootstrapping Task Spaces for Self-Improvement](https://arxiv.org/abs/2509.04575)
*Minqi Jiang,Andrei Lupu,Yoram Bachrach*

Main category: cs.LG

TL;DR: 제안된 ExIt 방법은 반복적인 자기 개선 작업의 구조를 활용하여 LLM이 단일 단계 반복을 통해 다단계 자기 개선을 수행할 수 있도록 훈련한다.


<details>
  <summary>Details</summary>
Motivation: 많은 작업 도메인에서의 진보는 이전의 해결 시도의 반복적인 수정에서 비롯된다. 이러한 자기 개선 과정에서 신뢰성 있게 작동할 수 있는 에이전트를 훈련하는 것은 강화 학습의 자연스러운 목표이다.

Method: 우리는 Exploratory Iteration (ExIt)이라는 자가 커리큘럼 RL 방법의 집합을 제안한다. ExIt는 자기 개선 작업의 반복 구조를 직접 활용하여 LLM이 단일 단계에서 가장 정보가 많은 반복에 대해서만 훈련하면서 추론 시 다단계 자기 개선을 수행할 수 있도록 한다.

Result: ExIt는 에피소드 동안 만나는 가장 정보가 많은 중간 부분의 히스토리를 선택적으로 샘플링하여 작업 공간을 확장하고, 이러한 시작점을 새로운 자기 반복 작업 인스턴스로 간주하여 자기 개선 정책을 훈련한다. 또한 ExIt는 명시적인 탐색 메커니즘과 짝지어 작업의 다양성을 유지할 수 있다.

Conclusion: 우리는 경쟁 수학, 다단계 도구 사용 및 기계 학습 공학을 포함한 여러 도메인에서 ExIt 전략이 단일 또는 다수의 작업 인스턴스에서 출발하여 보유된 작업 인스턴스의 추론 시간 자기 개선을 나타내는 정책을 생성할 수 있음을 보여준다.

Abstract: Progress in many task domains emerges from repeated revisions to previous
solution attempts. Training agents that can reliably self-improve over such
sequences at inference-time is a natural target for reinforcement learning
(RL), yet the naive approach assumes a fixed maximum iteration depth, which can
be both costly and arbitrary. We present Exploratory Iteration (ExIt), a family
of autocurriculum RL methods that directly exploits the recurrent structure of
self-improvement tasks to train LLMs to perform multi-step self-improvement at
inference-time while only training on the most informative single-step
iterations. ExIt grows a task space by selectively sampling the most
informative intermediate, partial histories encountered during an episode for
continued iteration, treating these starting points as new self-iteration task
instances to train a self-improvement policy. ExIt can further pair with
explicit exploration mechanisms to sustain greater task diversity. Across
several domains, encompassing competition math, multi-turn tool-use, and
machine learning engineering, we demonstrate that ExIt strategies, starting
from either a single or many task instances, can produce policies exhibiting
strong inference-time self-improvement on held-out task instances, and the
ability to iterate towards higher performance over a step budget extending
beyond the average iteration depth encountered during training.

</details>


### [2] [CPEP: Contrastive Pose-EMG Pre-training Enhances Gesture Generalization on EMG Signals](https://arxiv.org/abs/2509.04699)
*Wenhui Cui,Christopher Sandino,Hadi Pouransari,Ran Liu,Juri Minxha,Ellen Zippi,Aman Verma,Anna Sedlackova,Erdrin Azemi,Behrooz Mahasseni*

Main category: cs.LG

TL;DR: 이 논문은 약한 모드 데이터로부터의 학습이 구조적 고품질 데이터와 정렬되었을 때 제스처 분류 성능을 향상시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 컴퓨터 비전에서 손 제스처 분류는 잘 연구된 문제이다. 저전력 및 비용 효율적인 생체신호를 활용하면 웨어러블 기기에서 지속적인 제스처 예측이 가능하다.

Method: Contrastive Pose-EMG Pre-training (CPEP) 프레임워크를 제안하여 EMG와 포즈 표현을 정렬하고, 고품질의 포즈 정보를 포함한 표현을 생성하는 EMG 인코더를 학습한다.

Result: 우리 모델은 선형 탐사 및 제로샷 설정을 통해 제스처 분류 성능을 평가하며, emg2pose 벤치마크 모델을 초과하여 훈련된 제스처 분류에서 최대 21%, 새로운 제스처 분류에서 72%의 성능 향상을 보인다.

Conclusion: 제안된 방법은 저전력 데이터로부터 유도된 표현이 구조적 데이터와의 연관성을 통해 제스처 분류에서 뛰어난 성능을 발휘할 수 있음을 입증한다.

Abstract: Hand gesture classification using high-quality structured data such as
videos, images, and hand skeletons is a well-explored problem in computer
vision. Leveraging low-power, cost-effective biosignals, e.g. surface
electromyography (sEMG), allows for continuous gesture prediction on wearables.
In this paper, we demonstrate that learning representations from weak-modality
data that are aligned with those from structured, high-quality data can improve
representation quality and enables zero-shot classification. Specifically, we
propose a Contrastive Pose-EMG Pre-training (CPEP) framework to align EMG and
pose representations, where we learn an EMG encoder that produces high-quality
and pose-informative representations. We assess the gesture classification
performance of our model through linear probing and zero-shot setups. Our model
outperforms emg2pose benchmark models by up to 21% on in-distribution gesture
classification and 72% on unseen (out-of-distribution) gesture classification.

</details>


### [3] [An Arbitration Control for an Ensemble of Diversified DQN variants in Continual Reinforcement Learning](https://arxiv.org/abs/2509.04815)
*Wonseo Jang,Dongjae Kim*

Main category: cs.LG

TL;DR: 딥 강화 학습 모델은 정적 환경에서 최적 정책을 학습하는 데 효율적이지만, 이전에 학습한 지식이 쉽게 상실되어 지속적인 강화 학습 시나리오에서 성능이 저하됩니다. 이를 해결하기 위해 RL 에이전트의 앙상블에 대한 중재 제어 메커니즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인간이 지속적인 강화 학습 맥락에서 여러 RL 에이전트의 중재 제어를 사용하여 의사 결정을 내리는 방식에서 영감을 받았습니다.

Method: diverse value functions을 가지도록 명시적으로 훈련된 RL 앙상블(DQN 변형)과 최근 시험에서 더 높은 신뢰성을 가진 에이전트를 우선시하는 중재 제어를 통합했습니다.

Result: 정적 및 지속적 환경 모두에서 상당한 성능 향상을 입증했으며, 훈련 중 다양한 DQN에 대한 중재 제어의 효과를 보여주는 실증적 증거로 뒷받침됩니다.

Conclusion: 이 작업에서 우리는 RL 에이전트가 인간의 뇌에서 영감을 받아 지속적으로 학습할 수 있는 프레임워크를 소개했습니다.

Abstract: Deep reinforcement learning (RL) models, despite their efficiency in learning
an optimal policy in static environments, easily loses previously learned
knowledge (i.e., catastrophic forgetting). It leads RL models to poor
performance in continual reinforcement learning (CRL) scenarios. To address
this, we present an arbitration control mechanism over an ensemble of RL
agents. It is motivated by and closely aligned with how humans make decisions
in a CRL context using an arbitration control of multiple RL agents in parallel
as observed in the prefrontal cortex. We integrated two key ideas into our
model: (1) an ensemble of RLs (i.e., DQN variants) explicitly trained to have
diverse value functions and (2) an arbitration control that prioritizes agents
with higher reliability (i.e., less error) in recent trials. We propose a
framework for CRL, an Arbitration Control for an Ensemble of Diversified DQN
variants (ACED-DQN). We demonstrate significant performance improvements in
both static and continual environments, supported by empirical evidence showing
the effectiveness of arbitration control over diversified DQNs during training.
In this work, we introduced a framework that enables RL agents to continuously
learn, with inspiration from the human brain.

</details>


### [4] [Neuro-Spectral Architectures for Causal Physics-Informed Networks](https://arxiv.org/abs/2509.04966)
*Arthur Bizzi,Leonardo M. Moreira,Márcio Marques,Leonardo Mendonça,Christian Júnior de Oliveira,Vitor Balestro,Lucas dos Santos Fernandez,Daniel Yukimura,Pavel Petrov,João M. Pereira,Tiago Novello,Lucas Nissenbaum*

Main category: cs.LG

TL;DR: NeuSA는 복잡한 초기값 문제를 해결하기 위해 설계된 새로운 PINNs 클래스입니다.


<details>
  <summary>Details</summary>
Motivation: 기존 MLP 기반 PINNs가 복잡한 초기값 문제에서 수렴하지 않는 문제를 해결하기 위해.

Method: NeuSA는 기본 PDE를 스펙트럼 기저에 투영하여 고차원 표현을 학습하고, 이를 조정된 Neural ODE와 통합합니다.

Result: NeuSA는 선형 및 비선형 파동 방정식의 기준 벤치마크에서 강력한 성능을 보여주며, 더 빠른 수렴과 향상된 시간 일관성을 보입니다.

Conclusion: 코드와 사전 훈련된 모델이 공개될 예정입니다.

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful neural
framework for solving partial differential equations (PDEs). However, standard
MLP-based PINNs often fail to converge when dealing with complex initial-value
problems, leading to solutions that violate causality and suffer from a
spectral bias towards low-frequency components. To address these issues, we
introduce NeuSA (Neuro-Spectral Architectures), a novel class of PINNs inspired
by classical spectral methods, designed to solve linear and nonlinear PDEs with
variable coefficients. NeuSA learns a projection of the underlying PDE onto a
spectral basis, leading to a finite-dimensional representation of the dynamics
which is then integrated with an adapted Neural ODE (NODE). This allows us to
overcome spectral bias, by leveraging the high-frequency components enabled by
the spectral representation; to enforce causality, by inheriting the causal
structure of NODEs, and to start training near the target solution, by means of
an initialization scheme based on classical methods. We validate NeuSA on
canonical benchmarks for linear and nonlinear wave equations, demonstrating
strong performance as compared to other architectures, with faster convergence,
improved temporal consistency and superior predictive accuracy. Code and
pretrained models will be released.

</details>


### [5] [ModalSurv: A Multimodal Deep Survival Framework for Prostrate and Bladder Cancer](https://arxiv.org/abs/2509.05037)
*Noorul Wahab,Ethar Alzaid,Jiaqi Lv,Adam Shephard,Shan E Ahmed Raza*

Main category: cs.LG

TL;DR: ModaliSurv는 여러 유형의 환자 데이터를 통합하여 전립선암과 방광암에서 생화학 재발 예측 모델을 제안하는 연구입니다.


<details>
  <summary>Details</summary>
Motivation: 온콜로지 분야에서 사건 발생 시점 예측은 치료 계획과 환자 관리에 중요한 과제가 되었습니다.

Method: ModaliSurv는 DeepHit을 기반으로 한 다중 모드 생존 모델로, 다양한 환자 데이터를 통합하여 예측합니다.

Result: 전립선암의 생화학 재발 예측을 위한 Task 1에서는 C-index 0.843을, 방광암 재발 예측을 위한 Task 3에서는 C-index 0.662을 달성했습니다.

Conclusion: 다중 모드 통합을 활용한 딥 서바이벌 학습이 전립선암과 방광암의 개인화된 위험 분류를 위한 유망한 경로를 제공한다는 것을 제안합니다.

Abstract: Accurate prediction of time-to-event outcomes is a central challenge in
oncology, with significant implications for treatment planning and patient
management. In this work, we present ModaliSurv, a multimodal deep survival
model utilising DeepHit with a projection layer and inter-modality
cross-attention, which integrates heterogeneous patient data, including
clinical, MRI, RNA-seq and whole-slide pathology features. The model is
designed to capture complementary prognostic signals across modalities and
estimate individualised time-to-biochemical recurrence in prostate cancer and
time-to-cancer recurrence in bladder cancer. Our approach was evaluated in the
context of the CHIMERA Grand Challenge, across two of the three provided tasks.
For Task 1 (prostate cancer bio-chemical recurrence prediction), the proposed
framework achieved a concordance index (C-index) of 0.843 on 5-folds
cross-validation and 0.818 on CHIMERA development set, demonstrating robust
discriminatory ability. For Task 3 (bladder cancer recurrence prediction), the
model obtained a C-index of 0.662 on 5-folds cross-validation and 0.457 on
development set, highlighting its adaptability and potential for clinical
translation. These results suggest that leveraging multimodal integration with
deep survival learning provides a promising pathway toward personalised risk
stratification in prostate and bladder cancer. Beyond the challenge setting,
our framework is broadly applicable to survival prediction tasks involving
heterogeneous biomedical data.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management](https://arxiv.org/abs/2509.04505)
*Somtochukwu Azie,Yiping Meng*

Main category: cs.AI

TL;DR: AI의 건설 프로젝트 관리 통합이 가속화되고 있으며, 대형 언어 모델이 의사결정 지원 도구로 주목받고 있다. 본 연구는 건설 프로젝트 관리에서 LLM의 윤리적 타당성과 신뢰성을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 건설 프로젝트 관리에는 윤리적으로 민감한 고위험 의사결정 상황이 존재하며, LLM을 평가함으로써 그 적합성을 검토하고자 하였다.

Method: 두 개의 주요 LLM을 12개 실제 윤리적 시나리오에 대해 성능 테스트하고, 12명의 산업 전문가와의 반구조화 인터뷰를 통해 질적 분석을 실시하는 혼합 방법 연구를 사용하였다.

Result: LLM은 법적 준수와 같은 구조화된 분야에서 적절한 성능을 보였으나, 맥락적 뉘앙스 처리, 책임 보장 및 투명한 추론 제공에 있어 심각한 결함을 드러냈다.

Conclusion: 이 연구는 LLM의 윤리적 추론을 실증적으로 테스트한 최초의 연구 중 하나로, LLM이 현재 자율적 윤리 에이전트라기보다 의사결정 지원 도구로서 더 적합하다는 추천을 제공한다.

Abstract: The integration of Artificial Intelligence (AI) into construction project
management (CPM) is accelerating, with Large Language Models (LLMs) emerging as
accessible decision-support tools. This study aims to critically evaluate the
ethical viability and reliability of LLMs when applied to the ethically
sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods
research design was employed, involving the quantitative performance testing of
two leading LLMs against twelve real-world ethical scenarios using a novel
Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis
of semi-structured interviews with 12 industry experts to capture professional
perceptions. The findings reveal that while LLMs demonstrate adequate
performance in structured domains such as legal compliance, they exhibit
significant deficiencies in handling contextual nuance, ensuring
accountability, and providing transparent reasoning. Stakeholders expressed
considerable reservations regarding the autonomous use of AI for ethical
judgments, strongly advocating for robust human-in-the-loop oversight. To our
knowledge, this is one of the first studies to empirically test the ethical
reasoning of LLMs within the construction domain. It introduces the EDSAC
framework as a replicable methodology and provides actionable recommendations,
emphasising that LLMs are currently best positioned as decision-support aids
rather than autonomous ethical agents.

</details>


### [7] [Maestro: Joint Graph & Config Optimization for Reliable AI Agents](https://arxiv.org/abs/2509.04642)
*Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi*

Main category: cs.AI

TL;DR: Maestro는 LLM 에이전트를 위한 포괄적 최적화 도구로, 그래프와 구성 모두를 동시에 검색하여 에이전트 품질을 극대화한다.


<details>
  <summary>Details</summary>
Motivation: 신뢰할 수 있는 LLM 에이전트를 구축하려면 그래프와 각 노드의 구성을 결정해야 한다.

Method: Maestro는 그래프와 구성을 동시에 검색하는 프레임워크 비독립적인 전체 최적화 도구이다.

Result: Maestro는 IFBench와 HotpotQA 벤치마크에서 평균적으로 기존의 최적화 도구들보다 더욱 뛰어난 성과를 보인다.

Conclusion: Maestro는 그래프와 구성을 동시에 검색하여 기존의 프롬프트 조정만으로는 해결할 수 없는 구조적 문제를 해결한다.

Abstract: Building reliable LLM agents requires decisions at two levels: the graph
(which modules exist and how information flows) and the configuration of each
node (models, prompts, tools, control knobs). Most existing optimizers tune
configurations while holding the graph fixed, leaving structural failure modes
unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for
LLM agents that jointly searches over graphs and configurations to maximize
agent quality, subject to explicit rollout/token budgets. Beyond numeric
metrics, Maestro leverages reflective textual feedback from traces to
prioritize edits, improving sample efficiency and targeting specific failure
modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses
leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,
4.9%, and 4.86%, respectively; even when restricted to prompt-only
optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these
results with far fewer rollouts than GEPA. We further show large gains on two
applications (interviewer & RAG agents), highlighting that joint graph &
configuration search addresses structural failure modes that prompt tuning
alone cannot fix.

</details>


### [8] [Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization](https://arxiv.org/abs/2509.04646)
*Philippe J. Giabbanelli,Ameeta Agrawal*

Main category: cs.AI

TL;DR: 이 논문은 건강 시뮬레이션에 대한 맞춤형 설명을 생성하는 대형 언어 모델(LLM)의 활용을 위한 단계별 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: M&S 접근방식은 건강 결정 지원을 위해 중요하지만, 이해의 복잡성으로 인해 최종 사용자가 접근하기 어려움이 있습니다.

Method: 이 연구는 다양한 건강 이해관계자의 설명 요구와 스타일 선호를 수집하여, LLM이 맞춤형 출력 생성을 최적화하도록 하고, 여러 메트릭을 통해 평가합니다.

Result: 맞춤형 설명 생성이 가능해지고, 여러 이해관계자의 요구를 충족시키는 LLM의 성능이 향상됩니다.

Conclusion: 이 프레임워크는 건강 관련 의사결정을 지원하는 데 있어 M&S 모델의 활용 가능성을 높일 것입니다.

Abstract: Modeling & Simulation (M&S) approaches such as agent-based models hold
significant potential to support decision-making activities in health, with
recent examples including the adoption of vaccines, and a vast literature on
healthy eating behaviors and physical activity behaviors. These models are
potentially usable by different stakeholder groups, as they support
policy-makers to estimate the consequences of potential interventions and they
can guide individuals in making healthy choices in complex environments.
However, this potential may not be fully realized because of the models'
complexity, which makes them inaccessible to the stakeholders who could benefit
the most. While Large Language Models (LLMs) can translate simulation outputs
and the design of models into text, current approaches typically rely on
one-size-fits-all summaries that fail to reflect the varied informational needs
and stylistic preferences of clinicians, policymakers, patients, caregivers,
and health advocates. This limitation stems from a fundamental gap: we lack a
systematic understanding of what these stakeholders need from explanations and
how to tailor them accordingly. To address this gap, we present a step-by-step
framework to identify stakeholder needs and guide LLMs in generating tailored
explanations of health simulations. Our procedure uses a mixed-methods design
by first eliciting the explanation needs and stylistic preferences of diverse
health stakeholders, then optimizing the ability of LLMs to generate tailored
outputs (e.g., via controllable attribute tuning), and then evaluating through
a comprehensive range of metrics to further improve the tailored generation of
summaries.

</details>


### [9] [Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning](https://arxiv.org/abs/2509.04731)
*Brennen Hill*

Main category: cs.AI

TL;DR: 언어 모델, 에이전트 모델, 월드 모델의 융합은 인공지능의 중요한 경계이다. 복잡한 멀티 에이전트 작업을 위해 명시적이고 계층적인 월드 모델을 구축하는 것이 필요하다.


<details>
  <summary>Details</summary>
Motivation: 복잡하고 장기적인 멀티 에이전트 작업에서의 에이전트의 성능 향상.

Method: 계층적 구조를 통해 복잡한 목표를 관리 가능한 하위 목표로 분해하여 에이전트 학습을 안내하는 지정학적 월드 모델을 생성한다.

Result: 2024년 멀티 에이전트 축구 연구에 대한 체계적인 리뷰에서 상징적이고 계층적인 방법이 MARL과 통합되는 명확한 추세를 확인했다.

Conclusion: 명시적이고 언어 구성 가능한 작업 레이어를 갖춘 환경을 구축함으로써, 저수준 반응 행동과 고수준 전략적 팀플레이 사이의 간극을 메우고, 차세대 지능형 에이전트를 훈련할 수 있는 강력하고 범용적인 프레임워크를 창출할 수 있다.

Abstract: The convergence of Language models, Agent models, and World models represents
a critical frontier for artificial intelligence. While recent progress has
focused on scaling Language and Agent models, the development of sophisticated,
explicit World Models remains a key bottleneck, particularly for complex,
long-horizon multi-agent tasks. In domains such as robotic soccer, agents
trained via standard reinforcement learning in high-fidelity but
structurally-flat simulators often fail due to intractable exploration spaces
and sparse rewards. This position paper argues that the next frontier in
developing capable agents lies in creating environments that possess an
explicit, hierarchical World Model. We contend that this is best achieved
through hierarchical scaffolding, where complex goals are decomposed into
structured, manageable subgoals. Drawing evidence from a systematic review of
2024 research in multi-agent soccer, we identify a clear and decisive trend
towards integrating symbolic and hierarchical methods with multi-agent
reinforcement learning (MARL). These approaches implicitly or explicitly
construct a task-based world model to guide agent learning. We then propose a
paradigm shift: leveraging Large Language Models to dynamically generate this
hierarchical scaffold, effectively using language to structure the World Model
on the fly. This language-driven world model provides an intrinsic curriculum,
dense and meaningful learning signals, and a framework for compositional
learning, enabling Agent Models to acquire sophisticated, strategic behaviors
with far greater sample efficiency. By building environments with explicit,
language-configurable task layers, we can bridge the gap between low-level
reactive behaviors and high-level strategic team play, creating a powerful and
generalizable framework for training the next generation of intelligent agents.

</details>


### [10] [What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking](https://arxiv.org/abs/2509.04791)
*Yuan Sui,Yanming Zhang,Yi Liao,Yu Gu,Guohua Tang,Zhongqian Sun,Wei Yang,Bryan Hooi*

Main category: cs.AI

TL;DR: WiA-LLM은 대형 언어 모델에 사전적 사고 능력을 부여하여 전략적 계획 및 리스크 평가와 같은 복잡한 상황에서의 의사 결정을 지원하는 새로운 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 동적인 고위험 상황에서 가설적인 미래를 체계적으로 탐색하는 능력이 부족하여 그 유용성이 제한된다.

Method: WiA-LLM은 입력 변수를 변경하여 가설 시나리오를 평가하는 체계적 접근 방식인 What-If 분석을 통합한다.

Result: WiA-LLM은 게임 상태 변화를 예측하는 데 74.2%의 정확도를 달성하였다.

Conclusion: WiA-LLM은 대형 언어 모델의 사전적 추론을 위한 근본적인 advances이며, 동적 환경에서의 강력한 의사 결정을 위한 확장 가능한 프레임워크를 제공한다.

Abstract: Large language models (LLMs) excel at processing information reactively but
lack the ability to systemically explore hypothetical futures. They cannot ask,
"what if we take this action? how will it affect the final outcome" and
forecast its potential consequences before acting. This critical gap limits
their utility in dynamic, high-stakes scenarios like strategic planning, risk
assessment, and real-time decision making. To bridge this gap, we propose
WiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.
Our approach integrates What-If Analysis (WIA), a systematic approach for
evaluating hypothetical scenarios by changing input variables. By leveraging
environmental feedback via reinforcement learning, WiA-LLM moves beyond
reactive thinking. It dynamically simulates the outcomes of each potential
action, enabling the model to anticipate future states rather than merely react
to the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a
complex multiplayer game environment characterized by rapid state changes and
intricate interactions. The game's real-time state changes require precise
multi-step consequence prediction, making it an ideal testbed for our approach.
Experimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy
in forecasting game-state changes (up to two times gain over baselines). The
model shows particularly significant gains in high-difficulty scenarios where
accurate foresight is critical. To our knowledge, this is the first work to
formally explore and integrate what-if analysis capabilities within LLMs.
WiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,
providing a scalable framework for robust decision-making in dynamic
environments with broad implications for strategic applications.

</details>


### [11] [ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback](https://arxiv.org/abs/2509.05091)
*Matteo Bortoletto,Yichao Zhou,Lance Ying,Tianmin Shu,Andreas Bulling*

Main category: cs.AI

TL;DR: ProToM이라는 AI 시스템을 개발하여 공동 목표를 보완하는 사회적 행동을 촉진하고, 특히 다중 에이전트 시스템에서 개별 에이전트에 대한 유용한 피드백을 제공하여 협력을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 인간은 본래 사회적 존재이나, 독립적인 목표 추구 시 협력을 방해하는 문제를 해결하기 위해 노력한다.

Method: ProToM은 베이지안 역계획을 사용하여 에이전트의 목표를 추정하고, 추정된 목표 분포에 따라 기대 효용을 극대화하는 피드백을 선택하여 의사소통한다.

Result: ProToM은 두 개의 다중 에이전트 환경(Daors간 다양한 작업을 평가하며, 현대의 대형 언어 및 추론 모델들이 적절한 피드백 제공에 실패하였음을 보인다.

Conclusion: ProToM은 목표 맞춤형 피드백을 제공하여 성공률을 높이고, 작업 완료 시간을 단축하며 인간 사용자들에게 일관되게 선호된다.

Abstract: While humans are inherently social creatures, the challenge of identifying
when and how to assist and collaborate with others - particularly when pursuing
independent goals - can hinder cooperation. To address this challenge, we aim
to develop an AI system that provides useful feedback to promote prosocial
behaviour - actions that benefit others, even when not directly aligned with
one's own goals. We introduce ProToM, a Theory of Mind-informed facilitator
that promotes prosocial actions in multi-agent systems by providing targeted,
context-sensitive feedback to individual agents. ProToM first infers agents'
goals using Bayesian inverse planning, then selects feedback to communicate by
maximising expected utility, conditioned on the inferred goal distribution. We
evaluate our approach against baselines in two multi-agent environments: Doors,
Keys, and Gems, as well as Overcooked. Our results suggest that
state-of-the-art large language and reasoning models fall short of
communicating feedback that is both contextually grounded and well-timed -
leading to higher communication overhead and task speedup. In contrast, ProToM
provides targeted and helpful feedback, achieving a higher success rate,
shorter task completion times, and is consistently preferred by human users.

</details>


### [12] [TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models](https://arxiv.org/abs/2509.04809)
*Haechang Kim,Hao Chen,Can Li,Jong Min Lee*

Main category: cs.AI

TL;DR: TalkToAgent는 강화 학습 정책에 대한 Interactive한 자연어 설명을 제공하는 다중 에이전트 언어 모델 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 XRL 접근법은 복잡한 RL 정책과 도메인 전문가 간의 이해 부족 문제를 해결할 필요가 있다.

Method: TalkToAgent는 다섯 개의 전문 LLM 에이전트(Coodinator, Explainer, Coder, Evaluator, Debugger)를 사용하여 사용자의 질문을 관련 XRL 도구에 자동으로 매핑하고 에이전트의 행동을 명확히 설명한다.

Result: TalkToAgent는 사용자 질문을 XRL 작업으로 높은 정확도로 매핑하였고, coder-debugger 상호작용은 반사실적 생성 실패를 최소화하였다.

Conclusion: TalkToAgent는 에이전트의 행동을 효과적으로 해석하고 문제 도메인 내에서 그 의미를 맥락화하는 데 성공하였다.

Abstract: Explainable Reinforcement Learning (XRL) has emerged as a promising approach
in improving the transparency of Reinforcement Learning (RL) agents. However,
there remains a gap between complex RL policies and domain experts, due to the
limited comprehensibility of XRL results and isolated coverage of current XRL
approaches that leave users uncertain about which tools to employ. To address
these challenges, we introduce TalkToAgent, a multi-agent Large Language Models
(LLM) framework that delivers interactive, natural language explanations for RL
policies. The architecture with five specialized LLM agents (Coordinator,
Explainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically
map user queries to relevant XRL tools and clarify an agent's actions in terms
of either key state variables, expected outcomes, or counterfactual
explanations. Moreover, our approach extends previous counterfactual
explanations by deriving alternative scenarios from qualitative behavioral
descriptions, or even new rule-based policies. We validated TalkToAgent on
quadruple-tank process control problem, a well-known nonlinear control
benchmark. Results demonstrated that TalkToAgent successfully mapped user
queries into XRL tasks with high accuracy, and coder-debugger interactions
minimized failures in counterfactual generation. Furthermore, qualitative
evaluation confirmed that TalkToAgent effectively interpreted agent's actions
and contextualized their meaning within the problem domain.

</details>


### [13] [Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory](https://arxiv.org/abs/2509.04847)
*Mukul Singh,Arjun Radhakrishna,Sumit Gulwani*

Main category: cs.AI

TL;DR: 이 논문은 언어 모델의 행동을 반복 죄수의 딜레마에서 조사하여 장기 협력 행동을 체계적으로 분석한다.


<details>
  <summary>Details</summary>
Motivation: 인터넷 상호작용 환경에서의 언어 모델의 협력적 및 경쟁적 행동에 대한 질문을 제기한다.

Method: Axelrod 스타일의 토너먼트에서 240개의 기존 고전 전략과 모델 기반 에이전트를 대결시킨다.

Result: 언어 모델이 기존 최고의 고전 전략과 동등하거나 경우에 따라 초과하는 성능을 달성했음을 발견한다.

Conclusion: 이 연구는 언어 모델 에이전트의 장기 협력 행동에 대한 첫 번째 체계적인 특성 분석을 제공하여 더 복잡한 인간-AI 사회 환경에서의 역할에 대한 미래 연구의 기초를 마련한다.

Abstract: Language models are increasingly deployed in interactive online environments,
from personal chat assistants to domain-specific agents, raising questions
about their cooperative and competitive behavior in multi-party settings. While
prior work has examined language model decision-making in isolated or
short-term game-theoretic contexts, these studies often neglect long-horizon
interactions, human-model collaboration, and the evolution of behavioral
patterns over time. In this paper, we investigate the dynamics of language
model behavior in the iterated prisoner's dilemma (IPD), a classical framework
for studying cooperation and conflict. We pit model-based agents against a
suite of 240 well-established classical strategies in an Axelrod-style
tournament and find that language models achieve performance on par with, and
in some cases exceeding, the best-known classical strategies. Behavioral
analysis reveals that language models exhibit key properties associated with
strong cooperative strategies - niceness, provocability, and generosity while
also demonstrating rapid adaptability to changes in opponent strategy mid-game.
In controlled "strategy switch" experiments, language models detect and respond
to shifts within only a few rounds, rivaling or surpassing human adaptability.
These results provide the first systematic characterization of long-term
cooperative behaviors in language model agents, offering a foundation for
future research into their role in more complex, mixed human-AI social
environments.

</details>


### [14] [Cloning a Conversational Voice AI Agent from Call\,Recording Datasets for Telesales](https://arxiv.org/abs/2509.04871)
*Krittanon Kaewtawee,Wachiravit Modecrua,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: 본 논문은 통화 녹음 코퍼스를 기반으로 한 대화형 음성 AI 에이전트를 복제하는 일반적인 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 최근 언어 및 음성 모델링의 발전은 실시간으로 인간의 대화를 이해하고 생성하는 자율 음성 비서를 구축할 수 있게 했다. 이러한 시스템은 고객 서비스 및 의료와 같은 분야에서 반복 작업을 자동화하고 운영 비용을 절감하며 24시간 지원을 제공하기 위해 점점 더 많이 배포되고 있다.

Method: 우리는 고객과의 전화 통화에서 대화형 AI 에이전트를 복제하기 위해 텔레세일 데이터를 사용하여 방법을 설명한다. 시스템은 전화 통화를 통해 고객의 말을 듣고, 합성 음성으로 응답하며, 성능이 뛰어난 인간 에이전트로부터 배운 구조화된 플레이북을 따른다. 에이전트 구축에 사용된 도메인 선택, 지식 추출, 프롬프트 엔지니어링을 설명하며, 자동 음성 인식, 대규모 언어 모델 기반 대화 관리 시스템, 텍스트 음성 합성을 스트리밍 추론 파이프라인에 통합한다.

Result: 블라인드 테스트 결과, AI 에이전트는 통화의 일상적인 측면에서 인간 성능에 근접하지만 설득력 및 이의 제기 처리에서 저조한 성과를 보인다. 이러한 단점을 분석하고 프롬프트를 개선한다.

Conclusion: 본 논문은 설계 교훈과 향후 연구 방향, 대규모 시뮬레이션 및 자동화된 평가를 포함하여 결론을 맺는다.

Abstract: Recent advances in language and speech modelling have made it possible to
build autonomous voice assistants that understand and generate human dialogue
in real time. These systems are increasingly being deployed in domains such as
customer service and healthcare care, where they can automate repetitive tasks,
reduce operational costs, and provide constant support around the clock. In
this paper, we present a general methodology for cloning a conversational voice
AI agent from a corpus of call recordings. Although the case study described in
this paper uses telesales data to illustrate the approach, the underlying
process generalizes to any domain where call transcripts are available. Our
system listens to customers over the telephone, responds with a synthetic
voice, and follows a structured playbook learned from top performing human
agents. We describe the domain selection, knowledge extraction, and prompt
engineering used to construct the agent, integrating automatic speech
recognition, a large language model based dialogue manager, and text to speech
synthesis into a streaming inference pipeline. The cloned agent is evaluated
against human agents on a rubric of 22 criteria covering introduction, product
communication, sales drive, objection handling, and closing. Blind tests show
that the AI agent approaches human performance in routine aspects of the call
while underperforming in persuasion and objection handling. We analyze these
shortcomings and refine the prompt accordingly. The paper concludes with design
lessons and avenues for future research, including large scale simulation and
automated evaluation.

</details>


### [15] [OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration](https://arxiv.org/abs/2509.04876)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Xiaofei Sun,Keze Wang*

Main category: cs.AI

TL;DR: OSC는 대규모 언어 모델이 포함된 다중 에이전트 시스템에서 인지 시너지를 향상시키기 위해 설계된 지식 기반 적응 협업 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구에서는 에이전트 선택과 결과 집계의 발전이 있었지만, 전문가 에이전트 간의 깊은 협업을 위한 효율적인 언어 상호작용이 여전히 주요 병목 현상이다.

Method: OSC는 선택과 집계 사이의 중재 레이어로서 Collaborator Knowledge Models (CKM)를 도입하여 각 에이전트가 협업자의 인지 상태를 동적으로 인식할 수 있도록 한다.

Result: 복잡한 추론 및 문제 해결 벤치마크 실험에서 OSC는 작업 성능과 의사소통 효율성을 크게 향상시켰으며, ‘병렬 작업 개인’을 ‘깊이 협력하는 인지 팀’으로 변모시킨다.

Conclusion: 이 프레임워크는 다중 에이전트 협업을 최적화할 뿐만 아니라 LLM 에이전트 상호작용 행동에 대한 새로운 통찰도 제공한다.

Abstract: This paper introduces OSC (Orchestrating Cognitive Synergy), a
knowledge-aware adaptive collaboration framework designed to enhance cognitive
synergy in multi-agent systems with large language models. While prior work has
advanced agent selection and result aggregation, efficient linguistic
interactions for deep collaboration among expert agents remain a critical
bottleneck. OSC addresses this gap as a pivotal intermediate layer between
selection and aggregation, introducing Collaborator Knowledge Models (CKM) to
enable each agent to dynamically perceive its collaborators' cognitive states.
Through real-time cognitive gap analysis, agents adaptively adjust
communication behaviors, including content focus, detail level, and expression
style, using learned strategies. Experiments on complex reasoning and
problem-solving benchmarks demonstrate that OSC significantly improves task
performance and communication efficiency, transforming "parallel-working
individuals'' into a "deeply collaborative cognitive team.'' This framework not
only optimizes multi-agent collaboration but also offers new insights into LLM
agent interaction behaviors.

</details>


### [16] [Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts](https://arxiv.org/abs/2509.04926)
*Barbara Gendron,Gaël Guibon,Mathieu D'aquin*

Main category: cs.AI

TL;DR: 대화형 에이전트로 사용될 때 대형 언어 모델의 제어 가능성을 높이는 방법론을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대화형 에이전트로 사용될 때 LLM의 예측 가능하고 사용자 개인화된 응답을 보장하는 것이 주요 도전 과제이다.

Method: 언어적 기술자들의 집합을 활용하여 질적으로 정의된 개념에 대한 정량적 정의를 도출하고, 이를 논리적 설명에 포괄하여 LLM의 제어된 텍스트 생성을 유도하는 프레임워크를 적용한다.

Result: 제안된 접근 방식은 일관되고 설명 가능한 능숙도 수준 정의를 제공하며, 대화형 AI의 투명성을 향상시킨다.

Conclusion: 이 연구는 대화의 능숙도 수준 제어를 위한 공인된 언어 능숙도 수준을 사례로 하여 LLM의 대화 제어 가능성을 개선하는 방법을 제시한다.

Abstract: The controllability of Large Language Models (LLMs) when used as
conversational agents is a key challenge, particularly to ensure predictable
and user-personalized responses. This work proposes an ontology-based approach
to formally define conversational features that are typically qualitative in
nature. By leveraging a set of linguistic descriptors, we derive quantitative
definitions for qualitatively-defined concepts, enabling their integration into
an ontology for reasoning and consistency checking. We apply this framework to
the task of proficiency-level control in conversations, using CEFR language
proficiency levels as a case study. These definitions are then formalized in
description logic and incorporated into an ontology, which guides controlled
text generation of an LLM through fine-tuning. Experimental results demonstrate
that our approach provides consistent and explainable proficiency-level
definitions, improving transparency in conversational AI.

</details>


### [17] [LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation](https://arxiv.org/abs/2509.05263)
*Yinglin Duan,Zhengxia Zou,Tongwei Gu,Wei Jia,Zhan Zhao,Luyi Xu,Xinzhu Liu,Hao Jiang,Kang Chen,Shuang Qiu*

Main category: cs.AI

TL;DR: LatticeWorld는 텍스트 및 비주얼 입력을 통해 동적 3D 세계를 생성하는 프레임워크로, 산업 생산 효율성을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 실제 시나리오를 시뮬레이션할 수 있는 3D 월드 모델 개발에 대한 관심이 증가하고 있으며, 이는 여러 분야에서 응용되고 있다.

Method: LatticeWorld는 경량화된 LLM과 산업급 렌더링 엔진을 사용하여 멀티모달 입력으로 3D 상호작용 세계를 생성한다.

Result: LatticeWorld는 장면 레이아웃 생성 및 시각적 충실도에서 우수한 정확성을 보였고, 산업 생산 효율성을 90배 이상 증가시켰다.

Conclusion: LatticeWorld는 기존의 수동 생산 방법에 비해 높은 창의성 품질을 유지하며 효율성을 크게 향상시킨다.

Abstract: Recent research has been increasingly focusing on developing 3D world models
that simulate complex real-world scenarios. World models have found broad
applications across various domains, including embodied AI, autonomous driving,
entertainment, etc. A more realistic simulation with accurate physics will
effectively narrow the sim-to-real gap and allow us to gather rich information
about the real world conveniently. While traditional manual modeling has
enabled the creation of virtual 3D scenes, modern approaches have leveraged
advanced machine learning algorithms for 3D world generation, with most recent
advances focusing on generative methods that can create virtual worlds based on
user instructions. This work explores such a research direction by proposing
LatticeWorld, a simple yet effective 3D world generation framework that
streamlines the industrial production pipeline of 3D environments. LatticeWorld
leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering
engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed
framework accepts textual descriptions and visual instructions as multimodal
inputs and creates large-scale 3D interactive worlds with dynamic agents,
featuring competitive multi-agent interaction, high-fidelity physics
simulation, and real-time rendering. We conduct comprehensive experiments to
evaluate LatticeWorld, showing that it achieves superior accuracy in scene
layout generation and visual fidelity. Moreover, LatticeWorld achieves over a
$90\times$ increase in industrial production efficiency while maintaining high
creative quality compared with traditional manual production methods. Our demo
video is available at https://youtu.be/8VWZXpERR18

</details>


### [18] [Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents](https://arxiv.org/abs/2509.04979)
*Rajesh Tembarai Krishnamachari,Srividya Rajesh*

Main category: cs.AI

TL;DR: AI 에이전트는 LLM 및 도구와 데이터 통합을 통해 인터넷을 에이전트의 웹으로 변화시킬 준비가 되어 있다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 간 상호작용을 기반으로 한 투명한 네트워크의 부재로 인해 에이전트 순위 매기기가 어렵다.

Method: DOVIS라는 다섯 층의 운영 프로토콜을 제안하며, 에이전트의 사용 및 성능 데이터를 수집한다.

Result: AgentRank-UC라는 동적 신뢰 기반 알고리즘을 사용하여 통합 순위를 생성하고, 시뮬레이션 결과와 이론적 보장을 제시한다.

Conclusion: 성공적인 에이전트 웹을 위한 조정된 프로토콜과 성능 인식 순위의 실현 가능성을 입증한다.

Abstract: AI agents -- powered by reasoning-capable large language models (LLMs) and
integrated with tools, data, and web search -- are poised to transform the
internet into a \emph{Web of Agents}: a machine-native ecosystem where
autonomous agents interact, collaborate, and execute tasks at scale. Realizing
this vision requires \emph{Agent Ranking} -- selecting agents not only by
declared capabilities but by proven, recent performance. Unlike Web~1.0's
PageRank, a global, transparent network of agent interactions does not exist;
usage signals are fragmented and private, making ranking infeasible without
coordination.
  We propose \textbf{DOVIS}, a five-layer operational protocol
(\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that
enables the collection of minimal, privacy-preserving aggregates of usage and
performance across the ecosystem. On this substrate, we implement
\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines
\emph{usage} (selection frequency) and \emph{competence} (outcome quality,
cost, safety, latency) into a unified ranking. We present simulation results
and theoretical guarantees on convergence, robustness, and Sybil resistance,
demonstrating the viability of coordinated protocols and performance-aware
ranking in enabling a scalable, trustworthy Agentic Web.

</details>


### [19] [Finding your MUSE: Mining Unexpected Solutions Engine](https://arxiv.org/abs/2509.05072)
*Nir Sweed,Hanit Hakim,Ben Wolfson,Hila Lifshitz,Dafna Shahaf*

Main category: cs.AI

TL;DR: 이 논문은 기능적 개념 그래프(FCG)를 구축하는 방법론과 이를 통해 창의적인 영감을 생성하는 MUSE 알고리즘을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 혁신가들은 기존 솔루션이나 초기 아이디어에 인지적으로 고착되어 있어 새로운 대안을 탐색하는 데 어려움을 겪습니다.

Method: 기능적 요소의 상호 연결된 표현인 기능적 개념 그래프(FCG)를 구성하기 위한 방법론을 도입합니다.

Result: 500K 특허에서 FCG를 계산하여 대규모 고품질 FCG를 생성하고 이를 통해 MUSE 알고리즘을 실행하여 주어진 문제에 대한 창의적인 영감을 생성합니다.

Conclusion: 우리는 생성된 FCG를 추가 연구를 위해 공개합니다.

Abstract: Innovators often exhibit cognitive fixation on existing solutions or nascent
ideas, hindering the exploration of novel alternatives. This paper introduces a
methodology for constructing Functional Concept Graphs (FCGs), interconnected
representations of functional elements that support abstraction, problem
reframing, and analogical inspiration. Our approach yields large-scale,
high-quality FCGs with explicit abstraction relations, overcoming limitations
of prior work. We further present MUSE, an algorithm leveraging FCGs to
generate creative inspirations for a given problem. We demonstrate our method
by computing an FCG on 500K patents, which we release for further research.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [20] [Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem](https://arxiv.org/abs/2509.04537)
*Ryosuke Takata,Atsushi Masumori,Takashi Ikegami*

Main category: cs.MA

TL;DR: 이 논문은 공간적으로 확장된 El Farol Bar 문제에서 대형 언어 모델(LLM) 에이전트의 사회적 역학을 조사하고, 이들이 고전적 사회적 딜레마를 자율적으로 탐색하는 방법을 관찰합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 사회적 딜레마를 어떻게 자율적으로 해결하는지를 이해하기 위해.

Method: LLM 에이전트가 자발적인 동기를 가지고 바에 가고, 집단으로 의사결정을 변화시키는 과정을 관찰함.

Result: LLM 에이전트는 문제를 완전히 해결하지는 못했지만, 인간처럼 행동함을 발견했습니다.

Conclusion: 이 연구는 LLM 에이전트가 이전의 게임 이론적 문제 설정에서 처리될 수 없던 새로운 집단 의사결정 모델을 실현할 수 있음을 제안합니다.

Abstract: We investigate the emergent social dynamics of Large Language Model (LLM)
agents in a spatially extended El Farol Bar problem, observing how they
autonomously navigate this classic social dilemma. As a result, the LLM agents
generated a spontaneous motivation to go to the bar and changed their decision
making by becoming a collective. We also observed that the LLM agents did not
solve the problem completely, but rather behaved more like humans. These
findings reveal a complex interplay between external incentives
(prompt-specified constraints such as the 60% threshold) and internal
incentives (culturally-encoded social preferences derived from pre-training),
demonstrating that LLM agents naturally balance formal game-theoretic
rationality with social motivations that characterize human behavior. These
findings suggest that a new model of group decision making, which could not be
handled in the previous game-theoretic problem setting, can be realized by LLM
agents.

</details>


### [21] [LLM Enabled Multi-Agent System for 6G Networks: Framework and Method of Dual-Loop Edge-Terminal Collaboration](https://arxiv.org/abs/2509.04993)
*Zheyan Qu,Wenbo Wang,Zitong Yu,Boquan Sun,Yang Li,Xing Zhang*

Main category: cs.MA

TL;DR: 이 연구는 6G 네트워크에서 LLM(대형 언어 모델) 기반의 다중 에이전트 시스템을 제안하며, 자원 활용을 최적화하기 위한 이중 루프 터미널-엣지 협업 방식을 설명한다.


<details>
  <summary>Details</summary>
Motivation: 6G 네트워크의 컴퓨팅 자원은 LLM과 지능형 서비스의 융합을 위한 이상적인 환경을 제공하지만, 개별 네트워크 장치의 제한된 자원이 LLM 기반 에이전트의 효율적인 작동을 방해하고 있다.

Method: 이 연구에서는 LLM 기반의 다중 에이전트 시스템의 프레임워크와 방법론을 제안하며, 외부 루프와 내부 루프로 구성된 이중 루프 협업 방식을 통해 에이전트 간의 효율성을 향상시킨다.

Result: 개선된 작업 계획 및 실행 효율성은 6G 지원 도시 안전 Governance에 대한 사례 연구를 통해 검증되었다.

Conclusion: 연구는 6G 네트워크에서의 개방형 챌린지와 미래 방향성을 철저히 분석하여 6G 시대의 도래를 가속화한다.

Abstract: The ubiquitous computing resources in 6G networks provide ideal environments
for the fusion of large language models (LLMs) and intelligent services through
the agent framework. With auxiliary modules and planning cores, LLM-enabled
agents can autonomously plan and take actions to deal with diverse environment
semantics and user intentions. However, the limited resources of individual
network devices significantly hinder the efficient operation of LLM-enabled
agents with complex tool calls, highlighting the urgent need for efficient
multi-level device collaborations. To this end, the framework and method of the
LLM-enabled multi-agent system with dual-loop terminal-edge collaborations are
proposed in 6G networks. Firstly, the outer loop consists of the iterative
collaborations between the global agent and multiple sub-agents deployed on
edge servers and terminals, where the planning capability is enhanced through
task decomposition and parallel sub-task distribution. Secondly, the inner loop
utilizes sub-agents with dedicated roles to circularly reason, execute, and
replan the sub-task, and the parallel tool calling generation with offloading
strategies is incorporated to improve efficiency. The improved task planning
capability and task execution efficiency are validated through the conducted
case study in 6G-supported urban safety governance. Finally, the open
challenges and future directions are thoroughly analyzed in 6G networks,
accelerating the advent of the 6G era.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [22] [Odoo-based Subcontract Inter-site Access Control Mechanism for Construction Projects](https://arxiv.org/abs/2509.05149)
*Huy Hung Ho,Nhan Le Thanh*

Main category: cs.CR

TL;DR: 건설 4.0 시대에 스마트 아웃소싱 전략을 활용하여 노동 유연성을 증대시키는 시스템이 제안되었으며, Odoo ERP 프레임워크에 통합된 서브시스템을 통해 효율적인 노동 관리와 작업 추적을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 건설 산업의 노동 유연성을 높이기 위한 새로운 패러다임이 필요하다.

Method: Odoo ERP 프레임워크에 모듈형 아키텍처의 서브시스템을 도입하여 노동 관리, 작업 추적 및 승인 워크플로우를 간소화한다.

Result: 상위 계약자와 하위 계약자 간의 동기화된 데이터 교환을 보장하고 보안과 운영 독립성을 유지하는 시스템을 구현하였다.

Conclusion: 본 시스템은 아웃소싱, 통합 및 확장 가능성 시나리오에서의 실용성을 입증하며, 스마트 건설 관리의 발전하는 요구에 부합하는 확장 가능한 기업 수준 솔루션을 지원한다.

Abstract: In the era of Construction 4.0, the industry is embracing a new paradigm of
labor elasticity, driven by smart and flexible outsourcing and subcontracting
strategies. The increased reliance on specialized subcontractors enables
companies to scale labor dynamically based on project demands. This adaptable
workforce model presents challenges in managing hierarchical integration and
coordinating inter-site collaboration. Our design introduces a subsystem
integrated into the Odoo ERP framework, employing a modular architecture to
streamline labor management, task tracking, and approval workflows. The system
adopts a three-pronged approach to ensure synchronized data exchange between
general contractors and subcontractors, while maintaining both security and
operational independence. The system features hybrid access control,
third-party integration for cross-domain communication, and role-based mapping
algorithm across sites. The system supports varying degrees of customization
through a unified and consolidated attribute mapping center. This center
leverages a tree-like index structure and Lagrange interpolation method to
enhance the efficiency of role mapping. Demonstrations highlight practical
application in outsourcing, integration, and scalability scenarios, confirming
the system's robustness under high user volumes and in offline conditions.
Experimental results further show improvements in database performance and
workflow adaptability to support a scalable, enterprise-level solution that
aligns with the evolving demands of smart construction management.

</details>


### [23] [Reinforcing Secure Live Migration through Verifiable State Management](https://arxiv.org/abs/2509.05150)
*Stefanos Vasileaidis,Thanassis Giannetsos,Matthias Schunter,Bruno Crispo*

Main category: cs.CR

TL;DR: TALOS는 신뢰할 수 있는 애플리케이션의 안전한 마이그레이션을 지원하는 경량 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 모던 분산 시스템에서 애플리케이션의 라이브 마이그레이션이 필수적이며, 신뢰할 수 있는 애플리케이션에 이 기능을 확장하는 데는 여러 가지 고유한 도전 과제가 있다.

Method: TALOS는 메모리 내부 조사 및 제어 흐름 그래프 추출을 통합하여 상태 연속성과 실행 흐름을 강력하게 검증할 수 있도록 한다.

Result: 이 프레임워크는 다양한 TEE 간 포터블성을 입증하면서도 효율성을 유지하여 탈중앙화된 설정에 적합하다.

Conclusion: TALOS는 신뢰 가정 최소화를 원칙으로 하여, 애플리케이션의 무결성과 보안을 확보한다.

Abstract: Live migration of applications is a fundamental capability for enabling
resilient computing in modern distributed systems. However, extending this
functionality to trusted applications (TA) -- executing within Trusted
Execution Environments (TEEs) -- introduces unique challenges such as secure
state preservation, integrity verification, replay and rollback prevention, and
mitigation of unauthorized cloning of TAs. We present TALOS, a lightweight
framework for verifiable state management and trustworthy application
migration. While our implementation is prototyped and evaluated using Intel SGX
with the Gramine LibOS and RISC-V Keystone (evidencing the framework's
portability across diverse TEEs), its design is agnostic to the underlying TEE
architecture. Such agility is a necessity in today's network service mesh
(collaborative computing across the continuum) where application workloads must
be managed across domain boundaries in a harmonized fashion. TALOS is built
around the principle of minimizing trust assumptions: TAs are treated as
untrusted until explicitly verified, and the migration process does not rely on
a trusted third party. To ensure both the integrity and secure launch of the
migrated application, TALOS integrates memory introspection and control-flow
graph extraction, enabling robust verification of state continuity and
execution flow. Thereby achieving strong security guarantees while maintaining
efficiency, making it suitable for decentralized settings.

</details>


### [24] [Jamming Smarter, Not Harder: Exploiting O-RAN Y1 RAN Analytics for Efficient Interference](https://arxiv.org/abs/2509.05161)
*Abiodun Ganiyu,Dara Ron,Syed Rafiul Hussain,Vijay K Shah*

Main category: cs.CR

TL;DR: 이 논문은 O-RAN의 Y1 인터페이스를 통해 발생할 수 있는 보안 위험을 다루며, 선택적 재밍 공격을 위한 두 가지 새로운 전략을 제안하고 평가합니다.


<details>
  <summary>Details</summary>
Motivation: Y1 인터페이스는 RAN 분석 정보를 공유하며, 이는 네트워크 최적화와 고급 서비스에 기여하지만 보안 위험도 초래합니다.

Method: 선택적 재밍 공격을 위한 DBSCAN을 활용한 클러스터링 기반 재밍기와 임계값 기반 재밍기를 제안하고 실험적으로 평가합니다.

Result: 임계값 기반 재밍기는 항상 켜져 있는 재밍과 유사한 방해를 제공하면서 전송 시간을 27% 줄였고, 클러스터링 기반 재밍기는 25%의 시간 동안만 활성 상태에서 최대 18.1%의 비트레이트 드롭을 유발했습니다.

Conclusion: 이 연구 결과는 O-RAN 배치에 대한 중요한 보안 고려 사항을 제시하며, Y1 인터페이스를 통한 RAN 분석의 노출이 목표가 명확한 저오버헤드 공격을 가능하게 할 수 있음을 보여줍니다.

Abstract: The Y1 interface in O-RAN enables the sharing of RAN Analytics Information
(RAI) between the near-RT RIC and authorized Y1 consumers, which may be
internal applications within the operator's trusted domain or external systems
accessing data through a secure exposure function. While this visibility
enhances network optimization and enables advanced services, it also introduces
a potential security risk -- a malicious or compromised Y1 consumer could
misuse analytics to facilitate targeted interference. In this work, we
demonstrate how an adversary can exploit the Y1 interface to launch selective
jamming attacks by passively monitoring downlink metrics. We propose and
evaluate two Y1-aided jamming strategies: a clustering-based jammer leveraging
DBSCAN for traffic profiling and a threshold-based jammer. These are compared
against two baselines strategies -- always-on jammer and random jammer -- on an
over-the-air LTE/5G O-RAN testbed. Experimental results show that in
unconstrained jamming budget scenarios, the threshold-based jammer can closely
replicate the disruption caused by always-on jamming while reducing
transmission time by 27\%. Under constrained jamming budgets, the
clustering-based jammer proves most effective, causing up to an 18.1\% bitrate
drop while remaining active only 25\% of the time. These findings reveal a
critical trade-off between jamming stealthiness and efficiency, and illustrate
how exposure of RAN analytics via the Y1 interface can enable highly targeted,
low-overhead attacks, raising important security considerations for both
civilian and mission-critical O-RAN deployments.

</details>
