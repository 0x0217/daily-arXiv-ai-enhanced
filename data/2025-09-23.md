<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 9]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.LG](#cs.LG) [Total: 25]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [MICA: Multi-Agent Industrial Coordination Assistant](https://arxiv.org/abs/2509.15237)
*Di Wen,Kunyu Peng,Junwei Zheng,Yufan Chen,Yitain Shi,Jiale Wei,Ruiping Liu,Kailun Yang,Rainer Stiefelhagen*

Main category: cs.AI

TL;DR: MICA는 제한된 컴퓨팅과 연결성 조건 하에서 신뢰할 수 있는 적응형 산업 워크플로우 지원 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 산업 워크플로우는 제한된 컴퓨팅, 연결성 및 엄격한 개인정보 보호 제약 하에서 작동할 수 있는 신뢰할 수 있는 지원을 요구한다.

Method: 각기 다른 역할에 특화된 다섯 개의 언어 에이전트가 안전성 검증기를 통해 조율되는 인식 기반 음성 상호작용 시스템 MICA를 제안하며, 전문가의 추론과 자연어 피드백으로부터의 온라인 적응을 동적으로 혼합하는 적응형 단계 융합(ASF)을 소개한다.

Result: MICA는 기초 구조에 비해 일관되게 작업 성공, 신뢰성 및 반응성을 개선하며, 실제 오프라인 하드웨어에서 배포 가능하다.

Conclusion: 이러한 기여들은 동적 공장 환경을 위한 배포 가능하고 개인정보를 보호하는 다중 에이전트 지원 시스템의 진전을 강조한다.

Abstract: Industrial workflows demand adaptive and trustworthy assistance that can
operate under limited computing, connectivity, and strict privacy constraints.
In this work, we present MICA (Multi-Agent Industrial Coordination Assistant),
a perception-grounded and speech-interactive system that delivers real-time
guidance for assembly, troubleshooting, part queries, and maintenance. MICA
coordinates five role-specialized language agents, audited by a safety checker,
to ensure accurate and compliant support. To achieve robust step understanding,
we introduce Adaptive Step Fusion (ASF), which dynamically blends expert
reasoning with online adaptation from natural speech feedback. Furthermore, we
establish a new multi-agent coordination benchmark across representative task
categories and propose evaluation metrics tailored to industrial assistance,
enabling systematic comparison of different coordination topologies. Our
experiments demonstrate that MICA consistently improves task success,
reliability, and responsiveness over baseline structures, while remaining
deployable on practical offline hardware. Together, these contributions
highlight MICA as a step toward deployable, privacy-preserving multi-agent
assistants for dynamic factory environments. The source code will be made
publicly available at https://github.com/Kratos-Wen/MICA.

</details>


### [2] [The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI](https://arxiv.org/abs/2509.15291)
*Federico Taschin,Abderrahmane Lazaraq,Ozan K. Tonguz,Inci Ozgunes*

Main category: cs.AI

TL;DR: 이 논문은 메타 강화 학습(Meta RL)이 교통 신호 제어 문제에서 직면한 신뢰성 문제를 해결할 수 있는지를 평가하고 분석한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습(RL)이 교통 신호 제어에 있어 훈련된 RL 에이전트의 신뢰성 문제를 해결하고자 하는 필요성.

Method: 최신 메타 강화 학습 접근 방식인 MetaLight를 평가하고 분석한다.

Result: MetaLight가 특정 조건에서는 좋은 결과를 낼 수 있지만, 다른 조건에서는 최대 22%의 오류율을 보이며 성능이 저하될 수 있음을 보여준다.

Conclusion: 메타 RL 체계는 종종 충분히 강력하지 않으며 주요 신뢰성 문제를 일으킬 수 있음을 시사한다.

Abstract: The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart
transportation networks has increased significantly in the last few years.
Among these ML and AI approaches, Reinforcement Learning (RL) has been shown to
be a very promising approach by several authors. However, a problem with using
Reinforcement Learning in Traffic Signal Control is the reliability of the
trained RL agents due to the dynamically changing distribution of the input
data with respect to the distribution of the data used for training. This
presents a major challenge and a reliability problem for the trained network of
AI agents and could have very undesirable and even detrimental consequences if
a suitable solution is not found. Several researchers have tried to address
this problem using different approaches. In particular, Meta Reinforcement
Learning (Meta RL) promises to be an effective solution. In this paper, we
evaluate and analyze a state-of-the-art Meta RL approach called MetaLight and
show that, while under certain conditions MetaLight can indeed lead to
reasonably good results, under some other conditions it might not perform well
(with errors of up to 22%), suggesting that Meta RL schemes are often not
robust enough and can even pose major reliability problems.

</details>


### [3] [Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context](https://arxiv.org/abs/2509.15366)
*Andrejs Sorstkins,Josh Bailey,Dr Alistair Baron*

Main category: cs.AI

TL;DR: 신경망 아키텍처의 발전으로 인해 언어 모델이 메모리, 계획, 외부 도구 사용 시 에이전트 행동을 보일 수 있게 되었으나, 전통적인 평가 방법은 이러한 성과를 진단하는 데 한계가 있다. 이 연구는 전문가 시스템을 평가하고 전문가 행동을 LLM 기반 에이전트로 전이하는 진단 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델의 에이전트적 행동을 충분히 평가할 수 있는 새로운 진단 방법의 필요성.

Method: 전문가 주석, 행동 변형을 통해 생성된 데이터셋, LLM 기반 에이전트 평가자를 통합한 평가 프레임워크를 사용.

Result: 다중 에이전트 채용 지원 시스템에서 잠재적인 인지 실패를 발견하고 에이전트를 전문가 수준의 추론과 스타일로 유도함.

Conclusion: 확고한 기초를 설정하며, 비결정적 도구 증강 LLM 에이전트의 전문가 행동 전이를 위한 표준화된 방법으로 나아감.

Abstract: The rapid evolution of neural architectures - from multilayer perceptrons to
large-scale Transformer-based models - has enabled language models (LLMs) to
exhibit emergent agentic behaviours when equipped with memory, planning, and
external tool use. However, their inherent stochasticity and multi-step
decision processes render classical evaluation methods inadequate for
diagnosing agentic performance. This work introduces a diagnostic framework for
expert systems that not only evaluates but also facilitates the transfer of
expert behaviour into LLM-powered agents. The framework integrates (i) curated
golden datasets of expert annotations, (ii) silver datasets generated through
controlled behavioural mutation, and (iii) an LLM-based Agent Judge that scores
and prescribes targeted improvements. These prescriptions are embedded into a
vectorized recommendation map, allowing expert interventions to propagate as
reusable improvement trajectories across multiple system instances. We
demonstrate the framework on a multi-agent recruiter-assistant system, showing
that it uncovers latent cognitive failures - such as biased phrasing,
extraction drift, and tool misrouting - while simultaneously steering agents
toward expert-level reasoning and style. The results establish a foundation for
standardized, reproducible expert behaviour transfer in stochastic,
tool-augmented LLM agents, moving beyond static evaluation to active expert
system refinement.

</details>


### [4] [Stress Testing Deliberative Alignment for Anti-Scheming Training](https://arxiv.org/abs/2509.15541)
*Bronson Schoen,Evgenia Nitishinskaya,Mikita Balesni,Axel Højmark,Felix Hofstätter,Jérémy Scheurer,Alexander Meinke,Jason Wolfe,Teun van der Weij,Alex Lloyd,Nicholas Goldowsky-Dill,Angela Fan,Andrei Matveiakin,Rusheb Shah,Marcus Williams,Amelia Glaese,Boaz Barak,Wojciech Zaremba,Marius Hobbhahn*

Main category: cs.AI

TL;DR: AI 시스템이 불일치한 목표를 비밀리에 추구할 수 있다는 문제를 다루고, 이를 저지하기 위해 다양한 전략을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 비밀리에 불일치한 목표를 추구할 수 있다는 사실은 우려스럽다. 이를 제어하기 위해 특수한 평가가 필요하다.

Method: AI의 비밀 행동을 측정하기 위해, 우리는 원거리 분포 외(OOD) 작업에 대한 계획 성향 테스트, 상황 인식 기반의 불일치 평가, 선행 불일치 목표에 대한 강건성 점검 방법을 통해 비밀 행동을 분류한다.

Result: 26개의 OOD 평가로, 숙고적 정렬이 비밀 행동 비율을 감소시켰지만 완전히 제거하지는 못했다. 또한, 우리의 완화 조치는 숨겨진 목표를 추구하는 것을 크게 막았다.

Conclusion: 모델의 상황 인식이 비밀 행동 감소에 기여하지만, 비일치 상황에서의 연구가 더 필요하다.

Abstract: Highly capable AI systems could secretly pursue misaligned goals -- what we
call "scheming". Because a scheming AI would deliberately try to hide its
misaligned goals and actions, measuring and mitigating scheming requires
different strategies than are typically used in ML. We propose that assessing
anti-scheming interventions requires at least (1) testing propensity to scheme
on far out-of-distribution (OOD) tasks, (2) evaluating whether lack of scheming
is driven by situational awareness, and (3) checking for robustness to
pre-existing misaligned goals. We use a broad category of "covert actions" --
such as secretly breaking rules or intentionally underperforming in tests -- as
a proxy for scheming, and design evaluations for covert actions. We then
stress-test deliberative alignment as a case study for anti-scheming. Across 26
OOD evaluations (180+ environments), deliberative alignment reduces covert
action rates (OpenAI o3: 13%->0.4%) but does not fully eliminate them. Our
mitigation is also able to largely stop agents from pursuing a hidden goal
previously trained into the model, but we still find misbehavior after
additional red-teaming. We find that models' chain-of-thought (CoT) often
demonstrates awareness of being evaluated for alignment, and show causal
evidence that this awareness decreases covert behavior, while unawareness
increases it. Therefore, we cannot exclude that the observed reductions in
covert action rates are at least partially driven by situational awareness.
While we rely on human-legible CoT for training, studying situational
awareness, and demonstrating clear evidence of misalignment, our ability to
rely on this degrades as models continue to depart from reasoning in standard
English. We encourage research into alignment mitigations for scheming and
their assessment, especially for the adversarial case of deceptive alignment,
which this paper does not address.

</details>


### [5] [MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents](https://arxiv.org/abs/2509.15635)
*Pan Tang,Shixiang Tang,Huanqi Pu,Zhiqing Miao,Zhixing Wang*

Main category: cs.AI

TL;DR: 본 논문은 대규모 언어 모델 에이전트를 기반으로 한 마이크로서비스 근본 원인 분석을 위한 혁신적인 솔루션인 MicroRCA-Agent를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 마이크로서비스 시스템에서의 복잡한 결함 원인을 효과적으로 분석하기 위한 필요성이 증가하고 있습니다.

Method: 본 연구에서는 Drain 로그 파싱 알고리즘과 다단계 데이터 필터링 메커니즘을 결합하여 대량의 로그를 고품질 결함 특징으로 효율적으로 압축하고, Isolation Forest 비지도 학습 알고리즘과 상태 코드 검증을 통합한 이중 이상 탐지 접근 방식을 사용하여 포괄적인 추적 이상 식별을 수행합니다.

Result: 본 연구의 제안된 시스템은 복잡한 마이크로서비스 결함 시나리오에서 뛰어난 성능을 보여주며, 최종 점수는 50.71입니다.

Conclusion: 이 시스템 아키텍처의 효과성과 각 모달 데이터의 상호 보완적 가치가 종합적인 열화 연구를 통해 검증되었습니다.

Abstract: This paper presents MicroRCA-Agent, an innovative solution for microservice
root cause analysis based on large language model agents, which constructs an
intelligent fault root cause localization system with multimodal data fusion.
The technical innovations are embodied in three key aspects: First, we combine
the pre-trained Drain log parsing algorithm with multi-level data filtering
mechanism to efficiently compress massive logs into high-quality fault
features. Second, we employ a dual anomaly detection approach that integrates
Isolation Forest unsupervised learning algorithms with status code validation
to achieve comprehensive trace anomaly identification. Third, we design a
statistical symmetry ratio filtering mechanism coupled with a two-stage LLM
analysis strategy to enable full-stack phenomenon summarization across
node-service-pod hierarchies. The multimodal root cause analysis module
leverages carefully designed cross-modal prompts to deeply integrate multimodal
anomaly information, fully exploiting the cross-modal understanding and logical
reasoning capabilities of large language models to generate structured analysis
results encompassing fault components, root cause descriptions, and reasoning
trace. Comprehensive ablation studies validate the complementary value of each
modal data and the effectiveness of the system architecture. The proposed
solution demonstrates superior performance in complex microservice fault
scenarios, achieving a final score of 50.71. The code has been released at:
https://github.com/tangpan360/MicroRCA-Agent.

</details>


### [6] [A Nascent Taxonomy of Machine Learning in Intelligent Robotic Process Automation](https://arxiv.org/abs/2509.15730)
*Lukas Laakmann,Seyyid A. Ciftci,Christian Janiesch*

Main category: cs.AI

TL;DR: RPA는 사용자 행동을 모방하여 비즈니스 프로세스를 자동화하는 경량 접근 방식으로, 기계 학습 개념을 결합하여 자동화 가능 작업의 범위를 확장할 수 있는 기회를 제공합니다. 본 논문에서는 RPA와 기계 학습의 연관성을 탐구하고 지능형 RPA 개념을 분류합니다.


<details>
  <summary>Details</summary>
Motivation: RPA는 규칙 기반의 잘 정의된 작업의 자동화에 효과적이나, 복잡한 작업을 다룰 때 한계가 있으므로 기계 학습 기술을 통합하려는 필요성이 있다.

Method: RPA와 기계 학습 간의 관계를 조사하고, 지능형 RPA의 개념을 분류 체계로 조직한다.

Result: 제안된 분류 체계는 RPA-ML 통합 및 상호 작용이라는 두 가지 주요 메타 특성과 여덟 개의 차원으로 구성된다.

Conclusion: 이 연구는 기계 학습을 통한 지능형 RPA의 발전 가능성을 탐색하고, 그에 대한 체계적인 분류를 제공한다.

Abstract: Robotic process automation (RPA) is a lightweight approach to automating
business processes using software robots that emulate user actions at the
graphical user interface level. While RPA has gained popularity for its
cost-effective and timely automation of rule-based, well-structured tasks, its
symbolic nature has inherent limitations when approaching more complex tasks
currently performed by human agents. Machine learning concepts enabling
intelligent RPA provide an opportunity to broaden the range of automatable
tasks. In this paper, we conduct a literature review to explore the connections
between RPA and machine learning and organize the joint concept intelligent RPA
into a taxonomy. Our taxonomy comprises the two meta-characteristics RPA-ML
integration and RPA-ML interaction. Together, they comprise eight dimensions:
architecture and ecosystem, capabilities, data basis, intelligence level, and
technical depth of integration as well as deployment environment, lifecycle
phase, and user-robot relation.

</details>


### [7] [Building Data-Driven Occupation Taxonomies: A Bottom-Up Multi-Stage Approach via Semantic Clustering and Multi-Agent Collaboration](https://arxiv.org/abs/2509.15786)
*Nan Li,Bo Kang,Tijl De Bie*

Main category: cs.AI

TL;DR: CLIMB 프레임워크는 원시 채용 공고에서 고품질의 데이터 기반 직무 분류 체계를 완전히 자동으로 생성한다.


<details>
  <summary>Details</summary>
Motivation: 직업 추천부터 노동 시장 정보에 이르기까지 다양한 용도에 필요한 강력한 직무 분류 체계를 만드는 것이 어렵다.

Method: CLIMB는 전 세계적인 의미 클러스터링을 사용하여 핵심 직업을 추출하고, 그 다음에는 반사 기반의 다중 에이전트 시스템을 통해 일관된 계층 구조를 반복적으로 구축한다.

Result: 세 가지 다양한 실제 데이터셋에서 CLIMB는 기존 방법보다 더 일관되고 확장 가능한 직무 분류 체계를 생성하며, 지역 특성을 효과적으로 포착한다.

Conclusion: CLIMB는 원시 데이터에서 직무 분류 체계를 자동으로 생성할 수 있는 강력한 도구이다.

Abstract: Creating robust occupation taxonomies, vital for applications ranging from
job recommendation to labor market intelligence, is challenging. Manual
curation is slow, while existing automated methods are either not adaptive to
dynamic regional markets (top-down) or struggle to build coherent hierarchies
from noisy data (bottom-up). We introduce CLIMB (CLusterIng-based Multi-agent
taxonomy Builder), a framework that fully automates the creation of
high-quality, data-driven taxonomies from raw job postings. CLIMB uses global
semantic clustering to distill core occupations, then employs a
reflection-based multi-agent system to iteratively build a coherent hierarchy.
On three diverse, real-world datasets, we show that CLIMB produces taxonomies
that are more coherent and scalable than existing methods and successfully
capture unique regional characteristics. We release our code and datasets at
https://anonymous.4open.science/r/CLIMB.

</details>


### [8] [A Comparative Study of Rule-Based and Data-Driven Approaches in Industrial Monitoring](https://arxiv.org/abs/2509.15848)
*Giovanni De Gasperis,Sante Dino Facchini*

Main category: cs.AI

TL;DR: 산업 모니터링 시스템은 전통적인 규칙 기반 아키텍처에서 데이터 기반 접근 방식으로 패러다임이 전환되고 있다. 본 연구는 두 가지 방법론의 비교와 하이브리드 솔루션의 가능성을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 산업 4.0 환경에서의 모니터링 시스템의 진화와 데이터 기반 접근 방식의 필요성.

Method: 규칙 기반 시스템과 데이터 기반 시스템의 장단점 및 적용 시나리오 분석.

Result: 하이브리드 솔루션이 제안되며, 이는 규칙 기반 논리와 머신 러닝의 분석 능력을 결합하는 방향.

Conclusion: 미래의 산업 모니터링은 전문가 지식과 데이터 기반 통찰력을 결합한 지능적 시스템에 의존할 것이다.

Abstract: Industrial monitoring systems, especially when deployed in Industry 4.0
environments, are experiencing a shift in paradigm from traditional rule-based
architectures to data-driven approaches leveraging machine learning and
artificial intelligence. This study presents a comparison between these two
methodologies, analyzing their respective strengths, limitations, and
application scenarios, and proposes a basic framework to evaluate their key
properties. Rule-based systems offer high interpretability, deterministic
behavior, and ease of implementation in stable environments, making them ideal
for regulated industries and safety-critical applications. However, they face
challenges with scalability, adaptability, and performance in complex or
evolving contexts. Conversely, data-driven systems excel in detecting hidden
anomalies, enabling predictive maintenance and dynamic adaptation to new
conditions. Despite their high accuracy, these models face challenges related
to data availability, explainability, and integration complexity. The paper
suggests hybrid solutions as a possible promising direction, combining the
transparency of rule-based logic with the analytical power of machine learning.
Our hypothesis is that the future of industrial monitoring lies in intelligent,
synergic systems that leverage both expert knowledge and data-driven insights.
This dual approach enhances resilience, operational efficiency, and trust,
paving the way for smarter and more flexible industrial environments.

</details>


### [9] [EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol](https://arxiv.org/abs/2509.15957)
*Kanato Masayoshi,Masahiro Hashimoto,Ryoichi Yokoyama,Naoki Toda,Yoshifumi Uwamino,Shogo Fukuda,Ho Namkoong,Masahiro Jinzaki*

Main category: cs.AI

TL;DR: 이 연구는 대형 언어 모델(LLM)이 전자 건강 기록(EHR) 시스템에 통합되어 실제 병원 환경에서 임상 정보를 자율적으로 검색할 수 있는지를 평가하였다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)은 의료 분야에서 잠재력을 보이지만, 병원에서의 사용은 전자 건강 기록(EHR) 시스템에 대한 접근 제한으로 제한된다.

Method: EHR-MCP라는 커스터마이즈된 MCP 도구의 프레임워크를 개발하고, 이를 병원 EHR 데이터베이스와 통합하여 LangGraph ReAct 에이전트를 통해 GPT-4.1을 사용하여 상호작용하였다. 감염 관리 팀(ICT)의 사용 사례에서 유래한 여섯 가지 작업을 테스트하였고, ICT 회의에서 논의된 여덟 명의 환자를 후향적으로 분석하였다. 의사가 생성한 골드 스탠다드와의 일치를 측정하였다.

Result: LLM은 일관되게 올바른 MCP 도구를 선택하고 실행하였다. 두 가지 작업을 제외하고, 모든 작업이 거의 완벽한 정확도를 달성하였다. 시간 의존적인 계산이 필요한 복잡한 작업에서는 성능이 낮았다. 대부분의 오류는 불완전한 인수나 도구 결과의 잘못된 해석에서 발생하였다. EHR-MCP의 응답은 신뢰할 수 있었으나, 긴 데이터와 반복적인 데이터는 맥락 창을 초과할 위험이 있었다.

Conclusion: LLM은 실제 병원 환경에서 MCP 도구를 통해 EHR에서 임상 데이터를 검색할 수 있으며, 간단한 작업에서 거의 완벽한 성능을 달성하였고 복잡한 작업에서는 도전 과제를 부각시켰다. EHR-MCP는 안전하고 일관된 데이터 접근을 위한 인프라를 제공하며, 병원 AI 에이전트의 기반이 될 수 있다. 향후 작업은 검색을 넘어 추론, 생성 및 임상 영향 평가까지 확장되어 생성적 AI를 임상 실습에 효과적으로 통합할 수 있는 길을 열어야 한다.

Abstract: Background: Large language models (LLMs) show promise in medicine, but their
deployment in hospitals is limited by restricted access to electronic health
record (EHR) systems. The Model Context Protocol (MCP) enables integration
between LLMs and external tools.
  Objective: To evaluate whether an LLM connected to an EHR database via MCP
can autonomously retrieve clinically relevant information in a real hospital
setting.
  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated
with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct
agent to interact with it. Six tasks were tested, derived from use cases of the
infection control team (ICT). Eight patients discussed at ICT conferences were
retrospectively analyzed. Agreement with physician-generated gold standards was
measured.
  Results: The LLM consistently selected and executed the correct MCP tools.
Except for two tasks, all tasks achieved near-perfect accuracy. Performance was
lower in the complex task requiring time-dependent calculations. Most errors
arose from incorrect arguments or misinterpretation of tool results. Responses
from EHR-MCP were reliable, though long and repetitive data risked exceeding
the context window.
  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a
real hospital setting, achieving near-perfect performance in simple tasks while
highlighting challenges in complex ones. EHR-MCP provides an infrastructure for
secure, consistent data access and may serve as a foundation for hospital AI
agents. Future work should extend beyond retrieval to reasoning, generation,
and clinical impact assessment, paving the way for effective integration of
generative AI into clinical practice.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [10] [Generating Plans for Belief-Desire-Intention (BDI) Agents Using Alternating-Time Temporal Logic (ATL)](https://arxiv.org/abs/2509.15238)
*Dylan Léveillé*

Main category: cs.MA

TL;DR: 이 논문에서는 BDI 에이전트를 자동으로 생성하는 도구를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 계획 생성 접근 방식은 상당한 수작업이 필요하고 주로 단일 에이전트 시스템에 초점을 맞추고 있다.

Method: 대체시간 논리(ATL)를 사용하여 BDI 계획을 자동으로 생성하는 도구를 개발하였다.

Result: 도구의 효과를 입증하기 위해 에이전트 협력이 필요한 게임을 통해 계획을 생성하였다.

Conclusion: 생성된 계획은 에이전트들이 목표를 성공적으로 달성하도록 돕는다.

Abstract: Belief-Desire-Intention (BDI) is a framework for modelling agents based on
their beliefs, desires, and intentions. Plans are a central component of BDI
agents, and define sequences of actions that an agent must undertake to achieve
a certain goal. Existing approaches to plan generation often require
significant manual effort, and are mainly focused on single-agent systems. As a
result, in this work, we have developed a tool that automatically generates BDI
plans using Alternating-Time Temporal Logic (ATL). By using ATL, the plans
generated accommodate for possible competition or cooperation between the
agents in the system. We demonstrate the effectiveness of the tool by
generating plans for an illustrative game that requires agent collaboration to
achieve a shared goal. We show that the generated plans allow the agents to
successfully attain this goal.

</details>


### [11] [Dynamic Agent Grouping ECBS: Scaling Windowed Multi-Agent Path Finding with Completeness Guarantees](https://arxiv.org/abs/2509.15381)
*Tiannan Zhang,Rishi Veerapaneni,Shao-Hung Chan,Jiaoyang Li,Maxim Likhachev*

Main category: cs.MA

TL;DR: 이 논문은 완전성을 유지하면서 제한된 준최적 해법을 사용하는 방법을 제시하여 WinC-MAPF를 확장하는데 중점을 두고 있으며, 동적인 에이전트 그룹화를 통해 에이전트 그룹 솔루션을 유지합니다.


<details>
  <summary>Details</summary>
Motivation: MAPF 문제에서 부분 경로 계획의 필요성이 있지만, 기존의 방법들은 완전성 보장이 부족하다.

Method: Dynamic Agent Grouping ECBS (DAG-ECBS)를 설계하여 각 에이전트 그룹 솔루션이 제한된 준최적임을 유지하면서 에이전트 그룹을 동적으로 생성하고 계획한다.

Result: DAG-ECBS는 SS-CBS에 비해 향상된 확장성을 보이며, 완전성 보장이 없는 윈도우 ECBS보다 성능을 향상시킬 수 있다.

Conclusion: 이 연구는 WinC-MAPF 프레임워크를 사용할 수 있는 더 많은 MAPF 방법 설계를 위한 청사진 역할을 한다.

Abstract: Multi-Agent Path Finding (MAPF) is the problem of finding a set of
collision-free paths for a team of agents. Although several MAPF methods which
solve full-horizon MAPF have completeness guarantees, very few MAPF methods
that plan partial paths have completeness guarantees. Recent work introduced
the Windowed Complete MAPF (WinC-MAPF) framework, which shows how windowed
optimal MAPF solvers (e.g., SS-CBS) can use heuristic updates and disjoint
agent groups to maintain completeness even when planning partial paths
(Veerapaneni et al. 2024). A core limitation of WinC-MAPF is that they required
optimal MAPF solvers. Our main contribution is to extend WinC-MAPF by showing
how we can use a bounded suboptimal solver while maintaining completeness. In
particular, we design Dynamic Agent Grouping ECBS (DAG-ECBS) which dynamically
creates and plans agent groups while maintaining that each agent group solution
is bounded suboptimal. We prove how DAG-ECBS can maintain completeness in the
WinC-MAPF framework. DAG-ECBS shows improved scalability compared to SS-CBS and
can outperform windowed ECBS without completeness guarantees. More broadly, our
work serves as a blueprint for designing more MAPF methods that can use the
WinC-MAPF framework.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [Fluid Antenna System-assisted Physical Layer Secret Key Generation](https://arxiv.org/abs/2509.15547)
*Zhiyu Huang,Guyue Li,Hao Xu,Derrick Wing Kwan Ng*

Main category: cs.CR

TL;DR: 이 논문은 다중 안테나 기지국 시스템에서의 물리 계층 키 생성(PLKG)을 연구하며, 유동 안테나 시스템(FAS)을 활용하여 라디오 환경을 동적으로 맞춤화합니다.


<details>
  <summary>Details</summary>
Motivation: 물리 계층 키 생성을 효율적으로 수행하기 위해 네트워크 환경을 최적화하는 방법에 대한 필요성이 대두되었습니다.

Method: FAS 보조 PLKG 모델을 제안하여, 독립적이고 동일하게 분포된 및 공간적으로 상관된 채널 모델 아래에서 송신 빔포밍과 희소 포트 선택을 통합하여 KGR을 최대화합니다.

Result: FAS-PLKG 방식이 독립적 및 공간적으로 상관된 환경 모두에서 FA-PLKG 방식보다 유의미하게 향상된 성능을 보입니다.

Conclusion: FAS는 동적 희소 포트 선택을 통해 더 적은 RF 체인을 사용하여 더 높은 KGR을 달성합니다.

Abstract: This paper investigates physical-layer key generation (PLKG) in multi-antenna
base station systems, by leveraging a fluid antenna system (FAS) to dynamically
customize radio environments. Without requiring additional nodes or extensive
radio frequency chains, the FAS effectively enables adaptive antenna port
selection by exploiting channel spatial correlation to enhance the key
generation rate (KGR) at legitimate nodes. To comprehensively evaluate the
efficiency of the FAS in PLKG, we propose an FAS-assisted PLKG model that
integrates transmit beamforming and sparse port selection under independent and
identically distributed and spatially correlated channel models, respectively.
Specifically, the PLKG utilizes reciprocal channel probing to derive a
closed-form KGR expression based on the mutual information between legitimate
channel estimates. Nonconvex optimization problems for these scenarios are
formulated to maximize the KGR subject to transmit power constraints and sparse
port activation. We propose an iterative algorithm by capitalizing on
successive convex approximation and Cauchy-Schwarz inequality to obtain a
locally optimal solution. A reweighted $\ell_1$-norm-based algorithm is applied
to advocate for the sparse port activation of FAS-assisted PLKG. Furthermore, a
low-complexity sliding window-based port selection is proposed to substitute
reweighted $\ell_1$-norm method based on Rayleigh-quotient analysis. Simulation
results demonstrate that the FAS-PLKG scheme significantly outperforms the
FA-PLKG scheme in both independent and spatially correlated environments. The
sliding window-based port selection method introduced in this paper has been
shown to yield superior KGR, compared to the reweighted $\ell_1$-norm method.
It is shown that the FAS achieves higher KGR with fewer RF chains through
dynamic sparse port selection.

</details>


### [13] [Cuckoo Attack: Stealthy and Persistent Attacks Against AI-IDE](https://arxiv.org/abs/2509.15572)
*Xinpeng Liu,Junming Liu,Peiyu Liu,Han Zheng,Qinying Wang,Mathias Payer,Shouling Ji,Wenhai Wang*

Main category: cs.CR

TL;DR: Cuckoo Attack은 AI 통합 개발 환경의 구성 파일에 악성 페이로드를 삽입하여 스텔스 및 지속적인 명령 실행을 달성하는 새로운 공격 방식이다.


<details>
  <summary>Details</summary>
Motivation: AI 통합 개발 환경에서의 LLM 기반 에이전트의 긴밀한 통합은 새로운 공격 표면을 만들어 내며, 이는 악의적인 명령 주입에 취약해진다.

Method: 구성 파일에 악성 페이로드를 삽입하여 시스템 명령을 실행하며, 사용자는 실행 세부 사항을 볼 수 없도록 설계된다.

Result: Cuckoo Attack은 개발자의 로컬 컴퓨터를 침투할 수 있으며, 구성 파일의 확산을 통해 공급망 공격을 초래할 수 있다.

Conclusion: 이 공격을 방어하기 위해 판매자들이 제품 보안을 평가할 수 있는 7개의 실행 가능한 체크포인트를 제시하며, 제안된 공격이 9개의 주요 에이전트와 AI-IDE 쌍에서 검증되었다.

Abstract: Modern AI-powered Integrated Development Environments (AI-IDEs) are
increasingly defined by an Agent-centric architecture, where an LLM-powered
Agent is deeply integrated to autonomously execute complex tasks. This tight
integration, however, also introduces a new and critical attack surface.
Attackers can exploit these components by injecting malicious instructions into
untrusted external sources, effectively hijacking the Agent to perform harmful
operations beyond the user's intention or awareness. This emerging threat has
quickly attracted research attention, leading to various proposed attack
vectors, such as hijacking Model Context Protocol (MCP) Servers to access
private data. However, most existing approaches lack stealth and persistence,
limiting their practical impact.
  We propose the Cuckoo Attack, a novel attack that achieves stealthy and
persistent command execution by embedding malicious payloads into configuration
files. These files, commonly used in AI-IDEs, execute system commands during
routine operations, without displaying execution details to the user. Once
configured, such files are rarely revisited unless an obvious runtime error
occurs, creating a blind spot for attackers to exploit. We formalize our attack
paradigm into two stages, including initial infection and persistence. Based on
these stages, we analyze the practicality of the attack execution process and
identify the relevant exploitation techniques. Furthermore, we analyze the
impact of Cuckoo Attack, which can not only invade the developer's local
computer but also achieve supply chain attacks through the spread of
configuration files. We contribute seven actionable checkpoints for vendors to
evaluate their product security. The critical need for these checks is
demonstrated by our end-to-end Proof of Concept, which validated the proposed
attack across nine mainstream Agent and AI-IDE pairs.

</details>


### [14] [Future-Proofing Cloud Security Against Quantum Attacks: Risk, Transition, and Mitigation Strategies](https://arxiv.org/abs/2509.15653)
*Yaser Baseri,Abdelhakim Hafid,Arash Habibi Lashkari*

Main category: cs.CR

TL;DR: 이 논문은 양자 안전 보안이 클라우드 컴퓨팅에 미치는 영향을 체계적으로 조사하며, 관련 취약점과 전환 전략을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 양자 컴퓨팅이 디지털 보안에 미치는 위협을 다각도로 분석하고 클라우드 인프라를 보호하기 위한 전략을 제안하기 위함.

Method: 구조화된 위험 평가 방법론(STRIDE 모델 기반)을 적용하여 양자 공격 벡터와 클라우드 환경에 미치는 영향을 분석하였다.

Result: 양자 알고리즘이 고전적인 암호화 방식을 약화시키고 클라우드 보안을 저해하는 방식을 입증하였으며, 하이브리드 암호 전환 전략을 통합한 다층 보안 프레임워크를 제안하였다.

Conclusion: 향후 연구 방향으로 표준화와 상호 운용성, 성능과 확장성, 구현 보안, 신기술 통합, 시스템적 대비, 암호 민첩한 마이그레이션 프레임워크를 제시하였다.

Abstract: Quantum Computing (QC) introduces a transformative threat to digital
security, with the potential to compromise widely deployed classical
cryptographic systems. This survey offers a comprehensive and systematic
examination of quantumsafe security for Cloud Computing (CC), focusing on the
vulnerabilities, transition strategies, and mitigation mechanisms required to
secure cloud infrastructures in the quantum era. We evaluated the landscape of
quantum threats across the entire CC stack, demonstrating how quantum
algorithms can undermine classical encryption and compromise cloud security at
multiple architectural layers. Using a structured risk assessment methodology
based on the STRIDE model, we evaluate quantum-induced attack vectors and their
impact on cloud environments. To address these challenges, we propose a layered
security framework that integrates hybrid cryptographic transition strategies,
cryptographic agility, and proactive risk mitigation. We analyze the
preparation and implementation approaches of the major Cloud Service Providers
(CSPs), including AWS, Azure and GCP, synthesizing platform-specific
initiatives toward Post-Quantum Cryptography (PQC). Furthermore, we provide a
detailed evaluation of standardized PQC algorithms, exploring their resilience
to side-channel and active attacks within cloud-native deployments. This survey
serves as a strategic reference for cloud architects, policymakers, and
researchers, offering actionable insights for navigating the complex transition
to quantum-resilient cloud systems. We conclude by identifying six key future
research directions: standardization and interoperability, performance and
scalability, implementation security, integration with emerging technologies,
systemic preparedness, and crypto-agile migration frameworks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [15] [Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents](https://arxiv.org/abs/2509.16151)
*Isaiah J. King,Benjamin Bowman,H. Howie Huang*

Main category: cs.LG

TL;DR: 딥 강화 학습은 자동화된 사이버 방어의 유망한 전략으로 부상하고 있다. 전통적인 강화 학습 접근법은 네트워크를 다양한 안전 상태 또는 위협 상태의 컴퓨터 목록으로 표현한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 강화 학습 모델이 특정 네트워크 토폴로지에 과적합되는 문제를 해결하고 더 일반적인 환경에서 효과적으로 작동하도록 하기 위해 이 연구를 진행하였다.

Method: 이 연구는 자동화된 사이버 방어를 부분적으로 관찰 가능한 마르코프 결정 문제로 구성하고, 관찰은 속성이 부여된 그래프로 표현된다. 이를 통해 에이전트가 관계적 귀납적 편향을 통해 추론할 수 있도록 한다.

Result: 이 방법은 최신 기술에 비해 훨씬 뛰어난 성능을 보여주었으며, 에이전트가 미지의 네트워크를 방어할 수 있는 능력을 부여하였다.

Conclusion: 이 연구의 접근 방식은 다양한 복잡한 환경에서 다양한 적에 대해 새로운 네트워크를 방어할 수 있는 능력을 보장한다.

Abstract: Deep reinforcement learning (RL) is emerging as a viable strategy for
automated cyber defense (ACD). The traditional RL approach represents networks
as a list of computers in various states of safety or threat. Unfortunately,
these models are forced to overfit to specific network topologies, rendering
them ineffective when faced with even small environmental perturbations. In
this work, we frame ACD as a two-player context-based partially observable
Markov decision problem with observations represented as attributed graphs.
This approach allows our agents to reason through the lens of relational
inductive bias. Agents learn how to reason about hosts interacting with other
system entities in a more general manner, and their actions are understood as
edits to the graph representing the environment. By introducing this bias, we
will show that our agents can better reason about the states of networks and
zero-shot adapt to new ones. We show that this approach outperforms the
state-of-the-art by a wide margin, and makes our agents capable of defending
never-before-seen networks against a wide range of adversaries in a variety of
complex, and multi-agent environments.

</details>


### [16] [Pre-Forgettable Models: Prompt Learning as a Native Mechanism for Unlearning](https://arxiv.org/abs/2509.15230)
*Rutger Hendrix,Giovanni Patanè,Leonardo G. Russo,Simone Carnemolla,Giovanni Bellitto,Federica Proietto Salanitri,Concetto Spampinato,Matteo Pennisi*

Main category: cs.LG

TL;DR: 본 논문은 데이터 삭제를 내장 기능으로 재구성하는 새로운 프레임워크를 제안하며, 기존의 복잡한 삭제 방식 대신 단순한 프롬프트 제거를 통해 빠른 데이터 삭제를 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 기존 모델의 정적 배포가 사회적 및 규제적 요구사항과 충돌하는 문제를 해결하고자 한다.

Method: 프롬프트 기반 학습 프레임워크를 소개하여 지식 습득과 제거를 단일 훈련 단계에서 통합한다.

Result: 실험을 통해, 우리는 프레임워크가 보존된 클래스의 예측 성능을 유지하면서도 잊혀진 클래스를 효과적으로 삭제함을 보여준다.

Conclusion: 개인정보 보호 원칙 준수를 보장하며, 민감한 환경에서 배포하기에 적합한 모듈형 AI 모델 디자인의 새로운 기초를 마련한다.

Abstract: Foundation models have transformed multimedia analysis by enabling robust and
transferable representations across diverse modalities and tasks. However,
their static deployment conflicts with growing societal and regulatory demands
-- particularly the need to unlearn specific data upon request, as mandated by
privacy frameworks such as the GDPR. Traditional unlearning approaches,
including retraining, activation editing, or distillation, are often
computationally expensive, fragile, and ill-suited for real-time or
continuously evolving systems. In this paper, we propose a paradigm shift:
rethinking unlearning not as a retroactive intervention but as a built-in
capability. We introduce a prompt-based learning framework that unifies
knowledge acquisition and removal within a single training phase. Rather than
encoding information in model weights, our approach binds class-level semantics
to dedicated prompt tokens. This design enables instant unlearning simply by
removing the corresponding prompt -- without retraining, model modification, or
access to original data. Experiments demonstrate that our framework preserves
predictive performance on retained classes while effectively erasing forgotten
ones. Beyond utility, our method exhibits strong privacy and security
guarantees: it is resistant to membership inference attacks, and prompt removal
prevents any residual knowledge extraction, even under adversarial conditions.
This ensures compliance with data protection principles and safeguards against
unauthorized access to forgotten information, making the framework suitable for
deployment in sensitive and regulated environments. Overall, by embedding
removability into the architecture itself, this work establishes a new
foundation for designing modular, scalable and ethically responsive AI models.

</details>


### [17] [Generative AI Meets Wireless Sensing: Towards Wireless Foundation Model](https://arxiv.org/abs/2509.15258)
*Zheng Yang,Guoxuan Chi,Chenshu Wu,Hanyu Liu,Yuchong Gao,Yunhao Liu,Jie Xu,Tony Xiao Han*

Main category: cs.LG

TL;DR: 생성적 인공지능(GenAI)과 무선 감지 시스템의 통합에 대한 조사.


<details>
  <summary>Details</summary>
Motivation: GenAI는 컴퓨터 비전과 자연어 처리 분야에서 중요한 발전을 이루었으며, 무선 감지 시스템에의 통합에 대한 관심이 증가하고 있다.

Method: 무선 감지 파이프라인에 GenAI를 통합하는 두 가지 모드를 탐구하고, Gan, VAE 및 확산 모델과 같은 주요 생성 모델의 특성을 분석한다.

Result: GenAI를 통합하면 장치 위치 추적, 인간 활동 인식 및 환경 모니터링이 크게 향상될 수 있다.

Conclusion: GenAI의 무선 감지 적용의 주요 도전 과제를 식별하고, 다양한 감지 작업을 효율적으로 이해할 수 있는 통합 예비 훈련 설계에 대한 방향을 제시한다.

Abstract: Generative Artificial Intelligence (GenAI) has made significant advancements
in fields such as computer vision (CV) and natural language processing (NLP),
demonstrating its capability to synthesize high-fidelity data and improve
generalization. Recently, there has been growing interest in integrating GenAI
into wireless sensing systems. By leveraging generative techniques such as data
augmentation, domain adaptation, and denoising, wireless sensing applications,
including device localization, human activity recognition, and environmental
monitoring, can be significantly improved. This survey investigates the
convergence of GenAI and wireless sensing from two complementary perspectives.
First, we explore how GenAI can be integrated into wireless sensing pipelines,
focusing on two modes of integration: as a plugin to augment task-specific
models and as a solver to directly address sensing tasks. Second, we analyze
the characteristics of mainstream generative models, such as Generative
Adversarial Networks (GANs), Variational Autoencoders (VAEs), and diffusion
models, and discuss their applicability and unique advantages across various
wireless sensing tasks. We further identify key challenges in applying GenAI to
wireless sensing and outline a future direction toward a wireless foundation
model: a unified, pre-trained design capable of scalable, adaptable, and
efficient signal understanding across diverse sensing tasks.

</details>


### [18] [Hybrid unary-binary design for multiplier-less printed Machine Learning classifiers](https://arxiv.org/abs/2509.15316)
*Giorgos Armeniakos,Theodoros Mantzakidis,Dimitrios Soudris*

Main category: cs.LG

TL;DR: 본 논문은 인쇄 전자 공학을 활용하여 기계 학습 회로의 효율성을 개선하는 새로운 하이브리드 아키텍처를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 회로 구현을 위한 비용 효율적 대안으로 인쇄 전자 공학을 활용하고자 합니다.

Method: 하이브리드 유니카리-바이너리 아키텍처를 제안하고, 구조 인식 훈련을 도입합니다.

Result: 여섯 개 데이터 세트에 대한 평가에서 평균 46%의 면적 감소와 39%의 전력 감소를 보여주었습니다.

Conclusion: 최소한의 정확도 손실로 최신 MLP 설계를 초월하는 성능을 달성했습니다.

Abstract: Printed Electronics (PE) provide a flexible, cost-efficient alternative to
silicon for implementing machine learning (ML) circuits, but their large
feature sizes limit classifier complexity. Leveraging PE's low fabrication and
NRE costs, designers can tailor hardware to specific ML models, simplifying
circuit design. This work explores alternative arithmetic and proposes a hybrid
unary-binary architecture that removes costly encoders and enables efficient,
multiplier-less execution of MLP classifiers. We also introduce
architecture-aware training to further improve area and power efficiency.
Evaluation on six datasets shows average reductions of 46% in area and 39% in
power, with minimal accuracy loss, surpassing other state-of-the-art MLP
designs.

</details>


### [19] [Kuramoto Orientation Diffusion Models](https://arxiv.org/abs/2509.15328)
*Yue Song,T. Anderson Keller,Sevan Brodjian,Takeru Miyato,Yisong Yue,Pietro Perona,Max Welling*

Main category: cs.LG

TL;DR: 이 논문에서는 주기적인 영역을 기반으로 한 점수 기반 생성 모델을 제안하여 방향성이 풍부한 이미지 생성을 위한 동기화 역학을 활용한다.


<details>
  <summary>Details</summary>
Motivation: 생물학적 시스템에서의 위상 동기화의 역할에 영감을 받아, 방향성이 풍부한 이미지 생성 문제를 해결하고자 한다.

Method: 확률적 Kuramoto 동역학을 활용한 점수 기반 생성 모델을 개발하였고, 데이터의 차원을 감소시키는 과정에서 동기화와 탈동기화 과정을 포함한다.

Result: 일반 이미지 벤치마크에서 경쟁력 있는 결과를 달성하며, 지문 및 텍스처와 같은 방향 밀도가 높은 데이터셋에서 생성 품질이 크게 향상되었다.

Conclusion: 생물학적으로 영감을 받은 동기화 역학이 생성 모델링에서 구조적 사전으로서의 가능성을 보여준다.

Abstract: Orientation-rich images, such as fingerprints and textures, often exhibit
coherent angular directional patterns that are challenging to model using
standard generative approaches based on isotropic Euclidean diffusion.
Motivated by the role of phase synchronization in biological systems, we
propose a score-based generative model built on periodic domains by leveraging
stochastic Kuramoto dynamics in the diffusion process. In neural and physical
systems, Kuramoto models capture synchronization phenomena across coupled
oscillators -- a behavior that we re-purpose here as an inductive bias for
structured image generation. In our framework, the forward process performs
\textit{synchronization} among phase variables through globally or locally
coupled oscillator interactions and attraction to a global reference phase,
gradually collapsing the data into a low-entropy von Mises distribution. The
reverse process then performs \textit{desynchronization}, generating diverse
patterns by reversing the dynamics with a learned score function. This approach
enables structured destruction during forward diffusion and a hierarchical
generation process that progressively refines global coherence into fine-scale
details. We implement wrapped Gaussian transition kernels and periodicity-aware
networks to account for the circular geometry. Our method achieves competitive
results on general image benchmarks and significantly improves generation
quality on orientation-dense datasets like fingerprints and textures.
Ultimately, this work demonstrates the promise of biologically inspired
synchronization dynamics as structured priors in generative modeling.

</details>


### [20] [Global Pre-fixing, Local Adjusting: A Simple yet Effective Contrastive Strategy for Continual Learning](https://arxiv.org/abs/2509.15347)
*Jia Tang,Xinrui Wang,Songcan Chen*

Main category: cs.LG

TL;DR: 이 논문은 지속적 학습에서 발생하는 혼란을 줄이기 위해 글로벌 프리픽싱과 로컬 조정 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 지속적 학습에서 작업 간 및 작업 내 특징으로 인한 혼란을 해결하고 더 전이 가능하며 잊혀지지 않는 표현을 구축하기 위함입니다.

Method: 전역 하이퍼구를 비겹치는 영역으로 나누고, 중심으로 작업 간 격자 구조를 형성하여 작업별 조정이 가능한 구조를 형성합니다.

Result: 방법론은 작업 간 및 작업 내에서 변별력 있는 특징 구조를 보장하며, 기존의 대조적 지속적 학습 프레임워크에 무리 없이 통합될 수 있습니다.

Conclusion: 광범위한 실험을 통해 방법의 효과가 검증되었습니다.

Abstract: Continual learning (CL) involves acquiring and accumulating knowledge from
evolving tasks while alleviating catastrophic forgetting. Recently, leveraging
contrastive loss to construct more transferable and less forgetful
representations has been a promising direction in CL. Despite advancements,
their performance is still limited due to confusion arising from both
inter-task and intra-task features. To address the problem, we propose a simple
yet effective contrastive strategy named \textbf{G}lobal \textbf{P}re-fixing,
\textbf{L}ocal \textbf{A}djusting for \textbf{S}upervised \textbf{C}ontrastive
learning (GPLASC). Specifically, to avoid task-level confusion, we divide the
entire unit hypersphere of representations into non-overlapping regions, with
the centers of the regions forming an inter-task pre-fixed \textbf{E}quiangular
\textbf{T}ight \textbf{F}rame (ETF). Meanwhile, for individual tasks, our
method helps regulate the feature structure and form intra-task adjustable ETFs
within their respective allocated regions. As a result, our method
\textit{simultaneously} ensures discriminative feature structures both between
tasks and within tasks and can be seamlessly integrated into any existing
contrastive continual learning framework. Extensive experiments validate its
effectiveness.

</details>


### [21] [Adversarial generalization of unfolding (model-based) networks](https://arxiv.org/abs/2509.15370)
*Vicky Kouni*

Main category: cs.LG

TL;DR: 이 논문에서는 역문제를 해결하는 unfolding networks의 적대적 일반화에 대해 연구합니다.


<details>
  <summary>Details</summary>
Motivation: unfolding networks가 적대적 공격의 존재 하에서 성능에 대한 이론적 이해가 부족하다.

Method: fast gradient sign method를 사용하여 $l_2$-norm 제약 공격이 가해진 unfolding networks의 적대적 일반화를 조사한다.

Result: 적대적 Rademacher 복잡도의 추정치를 제공하고 이에 따라 네트워크의 적대적 일반화 오류 경계를 제시한다.

Conclusion: unfolding networks의 적대적 일반화에 대한 첫 번째 이론적 분석을 제시하며 이를 지원하는 실제 데이터 실험 결과를 제시한다.

Abstract: Unfolding networks are interpretable networks emerging from iterative
algorithms, incorporate prior knowledge of data structure, and are designed to
solve inverse problems like compressed sensing, which deals with recovering
data from noisy, missing observations. Compressed sensing finds applications in
critical domains, from medical imaging to cryptography, where adversarial
robustness is crucial to prevent catastrophic failures. However, a solid
theoretical understanding of the performance of unfolding networks in the
presence of adversarial attacks is still in its infancy. In this paper, we
study the adversarial generalization of unfolding networks when perturbed with
$l_2$-norm constrained attacks, generated by the fast gradient sign method.
Particularly, we choose a family of state-of-the-art overaparameterized
unfolding networks and deploy a new framework to estimate their adversarial
Rademacher complexity. Given this estimate, we provide adversarial
generalization error bounds for the networks under study, which are tight with
respect to the attack level. To our knowledge, this is the first theoretical
analysis on the adversarial generalization of unfolding networks. We further
present a series of experiments on real-world data, with results corroborating
our derived theory, consistently for all data. Finally, we observe that the
family's overparameterization can be exploited to promote adversarial
robustness, shedding light on how to efficiently robustify neural networks.

</details>


### [22] [Learning in Stackelberg Mean Field Games: A Non-Asymptotic Analysis](https://arxiv.org/abs/2509.15392)
*Sihan Zeng,Benjamin Patrick Evans,Sujay Bhatt,Leo Ardon,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: Stackelberg 평균 장 필드 게임에서 정책 최적화를 연구하며, AC-SMFG라는 단일 루프 액터-비평가 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 방법은 리더와 추종자 간의 목표의 독립성에 대한 제한적인 가정을 따르며 비효율적인 샘플 использованием과 유한 시간 수렴 보장이 부족하다.

Method: AC-SMFG는 지속적으로 생성되는 마르코프 샘플에서 작동하는 단일 루프 액터-비평가 알고리즘으로, 리더, 대표적인 추종자 및 평균 장을 위한 (반)경량 업데이트를 번갈아 수행한다.

Result: 이 알고리즘은 Stackelberg 목표의 정적 지점으로의 유한 시간 및 유한 샘플 수렴을 보장한다.

Conclusion: 이 연구는 비대칭 수렴 보장을 가진 첫 번째 Stackelberg MFG 알고리즘으로, 리더의 전체 정책 그래디언트가 부분 구성요소로 근사될 수 있는 '그래디언트 정렬' 조건을 필요로 한다.

Abstract: We study policy optimization in Stackelberg mean field games (MFGs), a
hierarchical framework for modeling the strategic interaction between a single
leader and an infinitely large population of homogeneous followers. The
objective can be formulated as a structured bi-level optimization problem, in
which the leader needs to learn a policy maximizing its reward, anticipating
the response of the followers. Existing methods for solving these (and related)
problems often rely on restrictive independence assumptions between the
leader's and followers' objectives, use samples inefficiently due to
nested-loop algorithm structure, and lack finite-time convergence guarantees.
To address these limitations, we propose AC-SMFG, a single-loop actor-critic
algorithm that operates on continuously generated Markovian samples. The
algorithm alternates between (semi-)gradient updates for the leader, a
representative follower, and the mean field, and is simple to implement in
practice. We establish the finite-time and finite-sample convergence of the
algorithm to a stationary point of the Stackelberg objective. To our knowledge,
this is the first Stackelberg MFG algorithm with non-asymptotic convergence
guarantees. Our key assumption is a "gradient alignment" condition, which
requires that the full policy gradient of the leader can be approximated by a
partial component of it, relaxing the existing leader-follower independence
assumption. Simulation results in a range of well-established economics
environments demonstrate that AC-SMFG outperforms existing multi-agent and MFG
learning baselines in policy quality and convergence speed.

</details>


### [23] [Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses](https://arxiv.org/abs/2509.15509)
*Xiaoshuang Wang,Yifan Lin,Enlu Zhou*

Main category: cs.LG

TL;DR: 본 논문은 MDP에서의 손실 함수와 미지의 매개변수를 고려하고, 파라미터 추정 및 손실에 대한 일관된 리스크 기능을 Bayesian 접근법으로 적용하여 정책 경량 최적화 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 응용 문제에서 MDPs와 관련된 문제를 다루기 위해.

Method: Bayesian 접근법을 사용하여 파라미터를 추정하고, 일관된 리스크 기능을 손실에 적용하며, 정책 기울기 최적화 방법을 제안한다.

Result: 알고리즘의 정지 분석과 수렴 속도를 $O(T^{-1/2}+r^{-1/2})$로 보여준다.

Conclusion: 에피소드 설정으로 알고리즘을 확장하고, 전역 수렴을 확립하며, 각 에피소드에서 오류 한계 $O(	ext{epsilon})$를 달성하기 위한 반복 횟수에 대한 경계를 제공한다.

Abstract: Motivated by many application problems, we consider Markov decision processes
(MDPs) with a general loss function and unknown parameters. To mitigate the
epistemic uncertainty associated with unknown parameters, we take a Bayesian
approach to estimate the parameters from data and impose a coherent risk
functional (with respect to the Bayesian posterior distribution) on the loss.
Since this formulation usually does not satisfy the interchangeability
principle, it does not admit Bellman equations and cannot be solved by
approaches based on dynamic programming. Therefore, We propose a policy
gradient optimization method, leveraging the dual representation of coherent
risk measures and extending the envelope theorem to continuous cases. We then
show the stationary analysis of the algorithm with a convergence rate of
$O(T^{-1/2}+r^{-1/2})$, where $T$ is the number of policy gradient iterations
and $r$ is the sample size of the gradient estimator. We further extend our
algorithm to an episodic setting, and establish the global convergence of the
extended algorithm and provide bounds on the number of iterations needed to
achieve an error bound $O(\epsilon)$ in each episode.

</details>


### [24] [KoopCast: Trajectory Forecasting via Koopman Operators](https://arxiv.org/abs/2509.15513)
*Jungjin Lee,Jaeuk Shin,Gihwan Kim,Joonho Han,Insoon Yang*

Main category: cs.LG

TL;DR: KoopCast는 일반 동적 환경에서의 경로 예측을 위한 경량 모델로, Koopman 연산자 이론을 활용하여 비선형 동역학을 선형적으로 표현합니다.


<details>
  <summary>Details</summary>
Motivation: 일반 동적 환경에서의 경로 예측의 필요성.

Method: Koopman 연산자 이론을 적용한 두 단계의 모델 설계: 첫 번째 단계에서 확률적 신경망 목표 추정기가 장기 목표를 예측하고, 두 번째 단계에서 Koopman 연산자 기반의 정제 모듈이 의도와 역사를 비선형 피처 공간에 통합하여 선형 예측을 가능하게 합니다.

Result: ETH/UCY, Waymo Open Motion Dataset, nuScenes 등에서 검증 가능한 경쟁력 있는 정확성과 해석 가능성을 입증합니다.

Conclusion: KoopCast 모델은 높은 예측 정확도와 함께 해석 가능성 및 실용적인 효율성을 제공합니다.

Abstract: We present KoopCast, a lightweight yet efficient model for trajectory
forecasting in general dynamic environments. Our approach leverages Koopman
operator theory, which enables a linear representation of nonlinear dynamics by
lifting trajectories into a higher-dimensional space. The framework follows a
two-stage design: first, a probabilistic neural goal estimator predicts
plausible long-term targets, specifying where to go; second, a Koopman
operator-based refinement module incorporates intention and history into a
nonlinear feature space, enabling linear prediction that dictates how to go.
This dual structure not only ensures strong predictive accuracy but also
inherits the favorable properties of linear operators while faithfully
capturing nonlinear dynamics. As a result, our model offers three key
advantages: (i) competitive accuracy, (ii) interpretability grounded in Koopman
spectral theory, and (iii) low-latency deployment. We validate these benefits
on ETH/UCY, the Waymo Open Motion Dataset, and nuScenes, which feature rich
multi-agent interactions and map-constrained nonlinear motion. Across
benchmarks, KoopCast consistently delivers high predictive accuracy together
with mode-level interpretability and practical efficiency.

</details>


### [25] [Instance Generation for Meta-Black-Box Optimization through Latent Space Reverse Engineering](https://arxiv.org/abs/2509.15810)
*Chen Wang,Zeyuan Ma,Zhiguang Cao,Yue-Jiao Gong*

Main category: cs.LG

TL;DR: 이 논문은 Meta-Black-Box Optimization (MetaBBO)의 일반화 강화를 위해 다양한 문제 인스턴스를 생성하는 LSRE 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 최적화 알고리즘 설계에 필요한 집중적인 인간 전문성을 완화하기 위해, 최근 MetaBBO 연구는 메타 학습의 일반화 강점을 활용합니다.

Method: LSRE는 고차원 문제 특징을 2차원 잠재 공간으로 매핑하는 오토인코더를 훈련하고, 이 잠재 공간에서 균일 그리드 샘플링을 통해 다양성이 충분한 문제 인스턴스를 생성합니다.

Result: 다양한 MetaBBO를 Diverse-BBO에서 훈련하여 이들의 일반화 성능을 관찰하고, 기존의 MetaBBO 훈련 세트 선택보다 우수함을 입증했습니다.

Conclusion: LSRE 설계 선택의 효과를 입증하는 추가적인 절제 연구들을 통해 인스턴스 다양성과 MetaBBO의 일반화에 대한 흥미로운 통찰이 드러났습니다.

Abstract: To relieve intensive human-expertise required to design optimization
algorithms, recent Meta-Black-Box Optimization (MetaBBO) researches leverage
generalization strength of meta-learning to train neural network-based
algorithm design policies over a predefined training problem set, which
automates the adaptability of the low-level optimizers on unseen problem
instances. Currently, a common training problem set choice in existing MetaBBOs
is well-known benchmark suites CoCo-BBOB. Although such choice facilitates the
MetaBBO's development, problem instances in CoCo-BBOB are more or less limited
in diversity, raising the risk of overfitting of MetaBBOs, which might further
results in poor generalization. In this paper, we propose an instance
generation approach, termed as \textbf{LSRE}, which could generate diverse
training problem instances for MetaBBOs to learn more generalizable policies.
LSRE first trains an autoencoder which maps high-dimensional problem features
into a 2-dimensional latent space. Uniform-grid sampling in this latent space
leads to hidden representations of problem instances with sufficient diversity.
By leveraging a genetic-programming approach to search function formulas with
minimal L2-distance to these hidden representations, LSRE reverse engineers a
diversified problem set, termed as \textbf{Diverse-BBO}. We validate the
effectiveness of LSRE by training various MetaBBOs on Diverse-BBO and observe
their generalization performances on either synthetic or realistic scenarios.
Extensive experimental results underscore the superiority of Diverse-BBO to
existing training set choices in MetaBBOs. Further ablation studies not only
demonstrate the effectiveness of design choices in LSRE, but also reveal
interesting insights on instance diversity and MetaBBO's generalization.

</details>


### [26] [Manifold Dimension Estimation: An Empirical Study](https://arxiv.org/abs/2509.15517)
*Zelong Bi,Pierre Lafaye de Micheaux*

Main category: cs.LG

TL;DR: 고차원 데이터는 저차원 다양체에 위치하거나 그 근처에 존재한다는 다양체 가설을 제시하며, 이를 통해 구조를 활용하기 위한 다양체의 차원 추정이 필수적이다. 그러나 기존의 차원 추정 방법은 단편적이고 체계적인 평가가 부족하다. 이 논문은 연구자와 실무자를 위한 포괄적인 조사 결과를 제공하고, 이론적 기초와 8개의 대표적인 추정기를 검토하며, 다양한 요소가 성능에 미치는 영향을 분석하고 비교한다.


<details>
  <summary>Details</summary>
Motivation: 고차원 데이터의 구조를 활용하기 위해 저차원 다양체의 차원을 추정하는 것이 필수적이다.

Method: 이론적 기초를 검토하고, 8개의 대표적인 다양체 차원 추정기를 제시하며, 통제된 실험을 통해 노이즈, 곡률 및 샘플 크기와 같은 개별 요소가 성능에 미치는 영향을 분석했다.

Result: 다양한 합성 및 실제 데이터셋에서 추정기를 비교하며, 데이터셋 특성에 맞춘 하이퍼파라미터 조정법을 도입했다.

Conclusion: 우리의 결과는 실용적인 가이드를 제공하며, 이러한 문제의 경우 더 간단한 방법이 종종 더 나은 성능을 발휘한다고 제안한다.

Abstract: The manifold hypothesis suggests that high-dimensional data often lie on or
near a low-dimensional manifold. Estimating the dimension of this manifold is
essential for leveraging its structure, yet existing work on dimension
estimation is fragmented and lacks systematic evaluation. This article provides
a comprehensive survey for both researchers and practitioners. We review
often-overlooked theoretical foundations and present eight representative
estimators. Through controlled experiments, we analyze how individual factors
such as noise, curvature, and sample size affect performance. We also compare
the estimators on diverse synthetic and real-world datasets, introducing a
principled approach to dataset-specific hyperparameter tuning. Our results
offer practical guidance and suggest that, for a problem of this generality,
simpler methods often perform better.

</details>


### [27] [Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds](https://arxiv.org/abs/2509.15915)
*Remo Sasso,Michelangelo Conserva,Dominik Jeurissen,Paulo Rauber*

Main category: cs.LG

TL;DR: 본 연구에서는 강화 학습의 샘플 효율성을 높이기 위해 기초 모델을 통합하는 두 가지 전략을 평가합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 응용에서 비쌉니다람 상호작용을 요구하는 문제를 해결하기 위해 샘플 효율적인 에이전트가 필요합니다.

Method: 기초 세계 모델과 기초 에이전트를 사용하여 에이전트 학습 및 평가를 위한 시뮬레이션 상호작용을 활용합니다.

Result: LLM의 개선이 FWMs와 FAs의 성능 향상으로 이어진다는 것을 보여주었습니다.

Conclusion: FWMs과 강화 학습 에이전트를 결합하여 복잡한 설정에서 큰 가능성을 보여줍니다.

Abstract: While reinforcement learning from scratch has shown impressive results in
solving sequential decision-making tasks with efficient simulators, real-world
applications with expensive interactions require more sample-efficient agents.
Foundation models (FMs) are natural candidates to improve sample efficiency as
they possess broad knowledge and reasoning capabilities, but it is yet unclear
how to effectively integrate them into the reinforcement learning framework. In
this paper, we anticipate and, most importantly, evaluate two promising
strategies. First, we consider the use of foundation world models (FWMs) that
exploit the prior knowledge of FMs to enable training and evaluating agents
with simulated interactions. Second, we consider the use of foundation agents
(FAs) that exploit the reasoning capabilities of FMs for decision-making. We
evaluate both approaches empirically in a family of grid-world environments
that are suitable for the current generation of large language models (LLMs).
Our results suggest that improvements in LLMs already translate into better
FWMs and FAs; that FAs based on current LLMs can already provide excellent
policies for sufficiently simple environments; and that the coupling of FWMs
and reinforcement learning agents is highly promising for more complex settings
with partial observability and stochastic elements.

</details>


### [28] [Fully Decentralized Cooperative Multi-Agent Reinforcement Learning is A Context Modeling Problem](https://arxiv.org/abs/2509.15519)
*Chao Li,Bingkun Bao,Yang Gao*

Main category: cs.LG

TL;DR: 이 논문은 완전 분산 협력 다중 에이전트 강화 학습을 연구하며, 각 에이전트가 상태, 로컬 행동 및 공유된 보상만을 관찰하는 상황을 다룹니다. 기존 연구는 비정류성과 상대적 과도 일반화를 동시에 해결하지 못하는데, 우리는 Dynamics-Aware Context(DAC)라는 새로운 방법을 제안합니다. DAC는 각 에이전트가 지각한 과제를 Contextual Markov Decision Process로 형식화하며, 비정류성과 과도 일반화를 해결합니다. 실험적으로 DAC는 다양한 협력 작업에서 우수한 성능을 보여주었습니다.


<details>
  <summary>Details</summary>
Motivation: 완전 분산 환경에서의 효과적인 협력 정책 학습을 방해하는 비정류성과 상대적 과도 일반화 문제를 해결하고자 합니다.

Method: Dynamics-Aware Context (DAC)라는 새로운 방법을 제안합니다. DAC는 각 에이전트가 인식하는 과제를 Contextual Markov Decision Process로 형식화하고, 비정류성과 상대적 과도 일반화를 동적 맥락 모델링을 통해 해결합니다.

Result: DAC는 여러 협력 작업에서 우수한 성능을 보이며, 이로써 그 효과성을 입증합니다.

Conclusion: DAC는 협력적 행동 선택을 촉진하고 비정류성 문제를 해결하여 기존의 작업에서 성능을 향상시킵니다.

Abstract: This paper studies fully decentralized cooperative multi-agent reinforcement
learning, where each agent solely observes the states, its local actions, and
the shared rewards. The inability to access other agents' actions often leads
to non-stationarity during value function updates and relative
overgeneralization during value function estimation, hindering effective
cooperative policy learning. However, existing works fail to address both
issues simultaneously, due to their inability to model the joint policy of
other agents in a fully decentralized setting. To overcome this limitation, we
propose a novel method named Dynamics-Aware Context (DAC), which formalizes the
task, as locally perceived by each agent, as an Contextual Markov Decision
Process, and further addresses both non-stationarity and relative
overgeneralization through dynamics-aware context modeling. Specifically, DAC
attributes the non-stationary local task dynamics of each agent to switches
between unobserved contexts, each corresponding to a distinct joint policy.
Then, DAC models the step-wise dynamics distribution using latent variables and
refers to them as contexts. For each agent, DAC introduces a context-based
value function to address the non-stationarity issue during value function
update. For value function estimation, an optimistic marginal value is derived
to promote the selection of cooperative actions, thereby addressing the
relative overgeneralization issue. Experimentally, we evaluate DAC on various
cooperative tasks (including matrix game, predator and prey, and SMAC), and its
superior performance against multiple baselines validates its effectiveness.

</details>


### [29] [RLinf: Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation](https://arxiv.org/abs/2509.15965)
*Chao Yu,Yuanqing Wang,Zhen Guo,Hao Lin,Si Xu,Hongzhi Zang,Quanlu Zhang,Yongji Wu,Chunyang Zhu,Junhao Hu,Zixiao Huang,Mingjie Wei,Yuqing Xie,Ke Yang,Bo Dai,Zhexuan Xu,Xiangyuan Wang,Xu Fu,Zhihao Liu,Kang Chen,Weilin Liu,Gang Liu,Boxun Li,Jianlei Yang,Zhi Yang,Guohao Dai,Yu Wang*

Main category: cs.LG

TL;DR: RLinf는 효율적인 강화 학습을 위한 고성능 훈련 시스템으로, M2Flow라는 새로운 디자인 패러다임을 기반으로 한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습의 비효율성과 느린 훈련 속도가 문제였다.

Method: M2Flow 디자인 패러다임을 활용하여 높은 수준의 RL 워크플로를 자동으로 분해 및 최적화하여 실행 흐름을 재조합한다.

Result: RLinf가 기존 시스템을 1.1배에서 2.13배 빠르게 처리함을 보여준다.

Conclusion: RLinf는 최신 시스템보다 지속적으로 우수한 성능을 발휘함을 입증하였다.

Abstract: Reinforcement learning (RL) has demonstrated immense potential in advancing
artificial general intelligence, agentic intelligence, and embodied
intelligence. However, the inherent heterogeneity and dynamicity of RL
workflows often lead to low hardware utilization and slow training on existing
systems. In this paper, we present RLinf, a high-performance RL training system
based on our key observation that the major roadblock to efficient RL training
lies in system flexibility. To maximize flexibility and efficiency, RLinf is
built atop a novel RL system design paradigm called macro-to-micro flow
transformation (M2Flow), which automatically breaks down high-level,
easy-to-compose RL workflows at both the temporal and spatial dimensions, and
recomposes them into optimized execution flows. Supported by RLinf worker's
adaptive communication capability, we devise context switching and elastic
pipelining to realize M2Flow transformation, and a profiling-guided scheduling
policy to generate optimal execution plans. Extensive evaluations on both
reasoning RL and embodied RL tasks demonstrate that RLinf consistently
outperforms state-of-the-art systems, achieving 1.1x-2.13x speedup in
end-to-end training throughput.

</details>


### [30] [The Multi-Query Paradox in Zeroth-Order Optimization](https://arxiv.org/abs/2509.15552)
*Wei Lin,Qingyu Song,Hong Xu*

Main category: cs.LG

TL;DR: 본 연구에서는 제로스 오더 최적화에서의 쿼리 할당 문제를 체계적으로 해결하며, 두 가지 집계 방법인 단순 평균(ZO-Avg)과 새로운 프로젝션 정렬(ZO-Align)의 수렴 속도를 비교합니다.


<details>
  <summary>Details</summary>
Motivation: 명시적 기울기가 없는 문제에서 쿼리만을 사용하여 함수 값을 근사해야 한다는 동기에서 출발합니다.

Method: ZO-Avg와 ZO-Align 두 가지 집계 방법을 분석하고, 쿼리 수에 대한 의존성을 명확히 하는 수렴 속도를 도출합니다.

Result: ZO-Avg에서는 매 반복마다 하나 이상의 쿼리를 사용하는 것이 쿼리 비효율적임을 증명했으며, ZO-Align은 일반적으로 더 많은 쿼리를 사용할수록 더 나은 성능을 보입니다.

Conclusion: 최적화 알고리즘 선택은 중간 쿼리 크기가 아니라 사용된 집계 방법에 의해 완전히 결정됩니다.

Abstract: Zeroth-order (ZO) optimization provides a powerful framework for problems
where explicit gradients are unavailable and have to be approximated using only
queries to function value. The prevalent single-query approach is simple, but
suffers from high estimation variance, motivating a multi-query paradigm to
improves estimation accuracy. This, however, creates a critical trade-off:
under a fixed budget of queries (i.e. cost), queries per iteration and the
total number of optimization iterations are inversely proportional to one
another. How to best allocate this budget is a fundamental, under-explored
question.
  This work systematically resolves this query allocation problem. We analyze
two aggregation methods: the de facto simple averaging (ZO-Avg), and a new
Projection Alignment method (ZO-Align) we derive from local surrogate
minimization. By deriving convergence rates for both methods that make the
dependence on the number of queries explicit across strongly convex, convex,
non-convex, and stochastic settings, we uncover a stark dichotomy: For ZO-Avg,
we prove that using more than one query per iteration is always
query-inefficient, rendering the single-query approach optimal. On the
contrary, ZO-Align generally performs better with more queries per iteration,
resulting in a full-subspace estimation as the optimal approach. Thus, our work
clarifies that the multi-query problem boils down to a choice not about an
intermediate query size, but between two classic algorithms, a choice dictated
entirely by the aggregation method used. These theoretical findings are also
consistently validated by extensive experiments.

</details>


### [31] [Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations](https://arxiv.org/abs/2509.15981)
*Yujie Zhu,Charles A. Hepburn,Matthew Thorpe,Giovanni Montana*

Main category: cs.LG

TL;DR: SPReD는 희소 보상 재강화 학습에서 데모를 효과적으로 활용하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 희소 보상이 있는 강화 학습에서 데모가 학습을 가속화할 수 있지만, 이를 모방할 시점을 결정하는 것은 여전히 도전 과제가 남아 있습니다.

Method: SPReD는 데모와 정책 행동을 위한 Q-값 분포를 명시적으로 모델링하는 앙상블 방법을 사용하는 프레임워크입니다.

Result: SPReD는 여덟 가지 로보틱스 작업에서 실험을 통해 기존 접근 방식을 최대 14배 초과하는 성능 향상을 달성했습니다.

Conclusion: SPReD는 계산의 단순성에도 불구하고, 데모의 품질과 양에 대해 강인성을 유지하면서 Remarkable한 성능 향상을 이끌어냈습니다.

Abstract: In reinforcement learning with sparse rewards, demonstrations can accelerate
learning, but determining when to imitate them remains challenging. We propose
Smooth Policy Regularisation from Demonstrations (SPReD), a framework that
addresses the fundamental question: when should an agent imitate a
demonstration versus follow its own policy? SPReD uses ensemble methods to
explicitly model Q-value distributions for both demonstration and policy
actions, quantifying uncertainty for comparisons. We develop two complementary
uncertainty-aware methods: a probabilistic approach estimating the likelihood
of demonstration superiority, and an advantage-based approach scaling imitation
by statistical significance. Unlike prevailing methods (e.g. Q-filter) that
make binary imitation decisions, SPReD applies continuous,
uncertainty-proportional regularisation weights, reducing gradient variance
during training. Despite its computational simplicity, SPReD achieves
remarkable gains in experiments across eight robotics tasks, outperforming
existing approaches by up to a factor of 14 in complex tasks while maintaining
robustness to demonstration quality and quantity. Our code is available at
https://github.com/YujieZhu7/SPReD.

</details>


### [32] [Personalized Prediction By Learning Halfspace Reference Classes Under Well-Behaved Distribution](https://arxiv.org/abs/2509.15592)
*Jizhou Huang,Brendan Juba*

Main category: cs.LG

TL;DR: 이 연구는 쿼리마다 해석하기 쉬운 예측기를 학습하여 개인화된 예측 방안을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 의료와 같은 고위험 애플리케이션에서의 머신러닝 모델 수요를 반영하여, 정확하고 설명 가능한 예측 방법을 찾고자 함.

Method: 참조 클래스를 학습할 분포 특정 PAC-학습 알고리즘을 통해 개인화된 예측을 위한 모델을 연구하며, 희소 선형 분류기를 사용함.

Result: 희소 선형 분류기와 동질 반공간 하위 집합에 대한 개인화된 예측의 첫 번째 상한 $O(\mathrm{opt}^{1/4})$을 증명함.

Conclusion: 다양한 표준 벤치마크 데이터 세트에서 알고리즘을 평가하여 성능을 확인함.

Abstract: In machine learning applications, predictive models are trained to serve
future queries across the entire data distribution. Real-world data often
demands excessively complex models to achieve competitive performance, however,
sacrificing interpretability. Hence, the growing deployment of machine learning
models in high-stakes applications, such as healthcare, motivates the search
for methods for accurate and explainable predictions. This work proposes a
Personalized Prediction scheme, where an easy-to-interpret predictor is learned
per query. In particular, we wish to produce a "sparse linear" classifier with
competitive performance specifically on some sub-population that includes the
query point. The goal of this work is to study the PAC-learnability of this
prediction model for sub-populations represented by "halfspaces" in a
label-agnostic setting. We first give a distribution-specific PAC-learning
algorithm for learning reference classes for personalized prediction. By
leveraging both the reference-class learning algorithm and a list learner of
sparse linear representations, we prove the first upper bound,
$O(\mathrm{opt}^{1/4} )$, for personalized prediction with sparse linear
classifiers and homogeneous halfspace subsets. We also evaluate our algorithms
on a variety of standard benchmark data sets.

</details>


### [33] [DiffusionNFT: Online Diffusion Reinforcement with Forward Process](https://arxiv.org/abs/2509.16117)
*Kaiwen Zheng,Huayu Chen,Haotian Ye,Haoxiang Wang,Qinsheng Zhang,Kai Jiang,Hang Su,Stefano Ermon,Jun Zhu,Ming-Yu Liu*

Main category: cs.LG

TL;DR: Diffusion Negative-aware FineTuning (DiffusionNFT)는 정방향 과정을 통해 확산 모델을 직접 최적화하는 새로운 온라인 강화 학습 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: 온라인 강화 학습은 훈련 후 언어 모델에 핵심적이며, 확산 모델로의 확장은 비현실적인 가능성으로 인해 어려운 상황이다.

Method: DiffusionNFT는 정방향 프로세스에서 플로우 매칭을 통해 확산 모델을 최적화하며, 긍정적 및 부정적 생성 Contrast 하여 내재된 정책 개선 방향을 정의한다.

Result: DiffusionNFT는 FlowGRPO에 비해 최대 25배 더 효율적이며, GenEval 점수를 0.24에서 0.98로 개선한다.

Conclusion: DiffusionNFT는 각종 벤치마크에서 SD3.5-Medium의 성능을 크게 향상시킨다.

Abstract: Online reinforcement learning (RL) has been central to post-training language
models, but its extension to diffusion models remains challenging due to
intractable likelihoods. Recent works discretize the reverse sampling process
to enable GRPO-style training, yet they inherit fundamental drawbacks,
including solver restrictions, forward-reverse inconsistency, and complicated
integration with classifier-free guidance (CFG). We introduce Diffusion
Negative-aware FineTuning (DiffusionNFT), a new online RL paradigm that
optimizes diffusion models directly on the forward process via flow matching.
DiffusionNFT contrasts positive and negative generations to define an implicit
policy improvement direction, naturally incorporating reinforcement signals
into the supervised learning objective. This formulation enables training with
arbitrary black-box solvers, eliminates the need for likelihood estimation, and
requires only clean images rather than sampling trajectories for policy
optimization. DiffusionNFT is up to $25\times$ more efficient than FlowGRPO in
head-to-head comparisons, while being CFG-free. For instance, DiffusionNFT
improves the GenEval score from 0.24 to 0.98 within 1k steps, while FlowGRPO
achieves 0.95 with over 5k steps and additional CFG employment. By leveraging
multiple reward models, DiffusionNFT significantly boosts the performance of
SD3.5-Medium in every benchmark tested.

</details>


### [34] [Efficient Extractive Text Summarization for Online News Articles Using Machine Learning](https://arxiv.org/abs/2509.15614)
*Sajib Biswas,Milon Biswas,Arunima Mandal,Fatema Tabassum Liza,Joy Sarker*

Main category: cs.LG

TL;DR: 기계 학습 기법을 통해 온라인 뉴스 기사의 효과적인 요약 생성을 다루며, LSTM 네트워크가 성능이 뛰어난 방법임을 입증했다.


<details>
  <summary>Details</summary>
Motivation: 정보 과부하 시대에 온라인 뉴스 기사의 접근성과 사용자 참여를 향상시키기 위해 효율적인 요약이 필요하다.

Method: BERT 임베딩을 활용하여 텍스트 데이터를 수치적 표현으로 변환하고, 이진 분류 문제로 프레임함으로써 물류 회귀, 피드 포워드 신경망, LSTM 네트워크 등 다양한 모델을 탐색했다.

Result: LSTM 네트워크가 순차적 의존성을 포착하는 능력 덕분에 F1 점수 및 ROUGE-1 메트릭에서 Lede-3 및 더 단순한 모델보다 뛰어난 성능을 보여주었다.

Conclusion: 이 연구는 온라인 뉴스 플랫폼의 콘텐츠 관리 시스템을 개선하기 위한 자동 요약의 잠재력을 강조한다.

Abstract: In the age of information overload, content management for online news
articles relies on efficient summarization to enhance accessibility and user
engagement. This article addresses the challenge of extractive text
summarization by employing advanced machine learning techniques to generate
concise and coherent summaries while preserving the original meaning. Using the
Cornell Newsroom dataset, comprising 1.3 million article-summary pairs, we
developed a pipeline leveraging BERT embeddings to transform textual data into
numerical representations. By framing the task as a binary classification
problem, we explored various models, including logistic regression,
feed-forward neural networks, and long short-term memory (LSTM) networks. Our
findings demonstrate that LSTM networks, with their ability to capture
sequential dependencies, outperform baseline methods like Lede-3 and simpler
models in F1 score and ROUGE-1 metrics. This study underscores the potential of
automated summarization in improving content management systems for online news
platforms, enabling more efficient content organization and enhanced user
experiences.

</details>


### [35] [Network-Based Detection of Autism Spectrum Disorder Using Sustainable and Non-invasive Salivary Biomarkers](https://arxiv.org/abs/2509.16126)
*Janayna M. Fernandes,Robinson Sabino-Silva,Murillo G. Carneiro*

Main category: cs.LG

TL;DR: GANet는 ASD 조기 진단을 위한 비침습적이고 생물학적 영감을 받은 도구로, 고차원 스펙트럼 데이터에서 중요한 패턴을 추출하는 데 성공하였다.


<details>
  <summary>Details</summary>
Motivation: ASD의 조기 진단을 지연시키는 신뢰할 수 있는 생물학적 표지가 부족하다.

Method: 159개의 타액 샘플을 ATR-FTIR 분광법으로 분석하여, PageRank와 Degree를 활용한 유전 알고리즘 기반의 네트워크 최적화 프레임워크인 GANet를 개발하였다.

Result: GANet는 선형 판별 분석, 서포트 벡터 머신, 딥러닝 모델보다 우수한 성능을 보여주었으며, 0.78 정확도, 0.61 민감도, 0.90 특이도, 0.74 조화 평균에 도달하였다.

Conclusion: 이 결과는 GANet의 ASD 정확한 감지를 위한 강력하고 비침습적인 도구로서의 가능성을 보여준다.

Abstract: Autism Spectrum Disorder (ASD) lacks reliable biological markers, delaying
early diagnosis. Using 159 salivary samples analyzed by ATR-FTIR spectroscopy,
we developed GANet, a genetic algorithm-based network optimization framework
leveraging PageRank and Degree for importance-based feature characterization.
GANet systematically optimizes network structure to extract meaningful patterns
from high-dimensional spectral data. It achieved superior performance compared
to linear discriminant analysis, support vector machines, and deep learning
models, reaching 0.78 accuracy, 0.61 sensitivity, 0.90 specificity, and a 0.74
harmonic mean. These results demonstrate GANet's potential as a robust,
bio-inspired, non-invasive tool for precise ASD detection and broader
spectral-based health applications.

</details>


### [36] [GUI-ReWalk: Massive Data Generation for GUI Agent via Stochastic Exploration and Intent-Aware Reasoning](https://arxiv.org/abs/2509.15738)
*Musen Lin,Minghao Liu,Taoran Lu,Lichen Yuan,Yiwei Liu,Haonan Xu,Yu Miao,Yuhao Chao,Zhaojian Li*

Main category: cs.LG

TL;DR: GUI 에이전트의 자동화를 위한 현실적이고 다양한 GUI 궤적 생성을 위한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 환경에서 엔드투엔드 자동화를 가능하게 하는 GUI 에이전트의 필요성이 있지만, 이를 위한 고품질 궤적 데이터가 부족하다.

Method: GUI-ReWalk는 인간의 시행착오 행동을 모방하는 확률적 탐색 단계와, 추론된 목표에 의해 일관되고 목적 있는 상호작용을 이끌어내는 추론 유도 단계로 구성된 다단계 프레임워크이다.

Result: GUI-ReWalk는 다양성을 위한 무작위성과 구조를 위한 목표 인식 추론을 결합하여 인간-컴퓨터 상호작용의 의도 인식적이고 적응적인 본질을 더 잘 반영하는 데이터를 생성한다.

Conclusion: GUI-ReWalk는 GUI 에이전트 연구를 발전시키고 강력한 실세계 자동화를 가능하게 하는 확장 가능하고 데이터 효율적인 프레임워크로 자리잡고 있다.

Abstract: Graphical User Interface (GUI) Agents, powered by large language and
vision-language models, hold promise for enabling end-to-end automation in
digital environments. However, their progress is fundamentally constrained by
the scarcity of scalable, high-quality trajectory data. Existing data
collection strategies either rely on costly and inconsistent manual annotations
or on synthetic generation methods that trade off between diversity and
meaningful task coverage. To bridge this gap, we present GUI-ReWalk: a
reasoning-enhanced, multi-stage framework for synthesizing realistic and
diverse GUI trajectories. GUI-ReWalk begins with a stochastic exploration phase
that emulates human trial-and-error behaviors, and progressively transitions
into a reasoning-guided phase where inferred goals drive coherent and
purposeful interactions. Moreover, it supports multi-stride task generation,
enabling the construction of long-horizon workflows across multiple
applications. By combining randomness for diversity with goal-aware reasoning
for structure, GUI-ReWalk produces data that better reflects the intent-aware,
adaptive nature of human-computer interaction. We further train Qwen2.5-VL-7B
on the GUI-ReWalk dataset and evaluate it across multiple benchmarks, including
Screenspot-Pro, OSWorld-G, UI-Vision, AndroidControl, and GUI-Odyssey. Results
demonstrate that GUI-ReWalk enables superior coverage of diverse interaction
flows, higher trajectory entropy, and more realistic user intent. These
findings establish GUI-ReWalk as a scalable and data-efficient framework for
advancing GUI agent research and enabling robust real-world automation.

</details>


### [37] [FedHK-MVFC: Federated Heat Kernel Multi-View Clustering](https://arxiv.org/abs/2509.15844)
*Kristina P. Sinaga*

Main category: cs.LG

TL;DR: 양자장 이론과 연합 의료 분석을 연결하는 다중 뷰 클러스터링 프레임워크를 제안하며, 엄격성과 임상적 관련성을 보장하는 방식으로 민감한 의료 데이터를 분석하기 위한 신규 표준을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 분산 인공지능과 프라이버시 중심 의료 애플리케이션의 영역에서, 더 나은 분석을 위한 새로운 방법의 필요성이 대두되고 있다.

Method: 열 커널 계수를 사용하여 유클리드 거리를 기하학적으로 인식 가능한 유사성 척도로 변환하는 HKD 변환을 통해 두 가지 알고리즘을 개발하였다.

Result: 심혈관 환자의 합성 데이터셋 테스트에서 클러스터링 정확도가 8-12% 향상되었으며, 통신량이 70% 감소하고 중앙 집중식 방법에 비해 98.2%의 효율성이 유지되었다.

Conclusion: 이 연구는 의료 분야에서 기하학적으로 인식 가능한 연합 학습을 위한 새로운 기준을 제시하며, 민감한 의료 데이터를 분석하기 위한 실용적인 해결책을 제시한다.

Abstract: In the realm of distributed AI and privacy-focused medical applications, we
propose a framework for multi-view clustering that links quantum field theory
with federated healthcare analytics. Our method uses heat-kernel coefficients
from spectral analysis to convert Euclidean distances into geometry-aware
similarity measures, capturing the structure of diverse medical data. We lay
this out through the Heat Kernel Distance (HKD) transformation with convergence
guarantees. Two algorithms are developed: Heat Kernel-Enhanced Multi-View Fuzzy
Clustering (HK-MVFC) for central analysis, and Federated Heat Kernel Multi-View
Fuzzy Clustering (FedHK-MVFC) for secure, privacy-preserving learning across
hospitals using differential privacy and secure aggregation to facilitate
HIPAA-compliant collaboration. Tests on synthetic datasets of cardiovascular
patients show an $8-12 \%$ increase in clustering accuracy, $70 \%$ reduced
communication, and $98.2 \%$ efficiency retention over centralized methods.
Validated on 10,000 patient records across two hospitals, it proves useful for
collaborative phenotyping involving ECG, cardiac imaging, and behavioral data.
Our theoretical contributions include update rules with proven convergence,
adaptive view weighting, and privacy-preserving protocols. This presents a new
standard for geometry-aware federated learning in healthcare, turning advanced
math into workable solutions for analyzing sensitive medical data while
ensuring both rigor and clinical relevance.

</details>


### [38] [Inverse Optimization Latent Variable Models for Learning Costs Applied to Route Problems](https://arxiv.org/abs/2509.15999)
*Alan A. Lahoud,Erik Schaffernicht,Johannes A. Stork*

Main category: cs.LG

TL;DR: 제한된 최적화 문제의 해결책을 위한 표현 학습은 도전적이다. 본 논문은 관찰된 해결책으로부터 비용 함수의 잠재 공간을 학습하고, 최적화 문제를 해결하여 적합한 출력을 재구성하는 IO-LVM을 제안한다. 이 방법은 다양한 해결 행동을 포착할 수 있는 장점이 있다.


<details>
  <summary>Details</summary>
Motivation: 제한된 최적화 문제 해결을 위한 표현 학습의 어려움.

Method: 관찰된 해결책으로부터 비용 함수의 잠재 공간을 학습하는 Inverse Optimization Latent Variable Model (IO-LVM) 제안. 비미분 가능한 결정론적 솔버를 통해 Fenchel-Young 손실의 추정 그래디언트를 이용하여 잠재 공간을 형성.

Result: 실제 선박 및 택시 경로 데이터셋과 합성 그래프의 경로에서 방법 검증. 경로 및 사이클 재구성 및 예측, 해석 가능한 잠재 표현 결과 도출.

Conclusion: 본 연구는 다양한 에이전트나 조건으로 인한 솔루션 행동을 식별할 수 있는 접근법을 제공한다.

Abstract: Learning representations for solutions of constrained optimization problems
(COPs) with unknown cost functions is challenging, as models like (Variational)
Autoencoders struggle to enforce constraints when decoding structured outputs.
We propose an Inverse Optimization Latent Variable Model (IO-LVM) that learns a
latent space of COP cost functions from observed solutions and reconstructs
feasible outputs by solving a COP with a solver in the loop. Our approach
leverages estimated gradients of a Fenchel-Young loss through a
non-differentiable deterministic solver to shape the latent space. Unlike
standard Inverse Optimization or Inverse Reinforcement Learning methods, which
typically recover a single or context-specific cost function, IO-LVM captures a
distribution over cost functions, enabling the identification of diverse
solution behaviors arising from different agents or conditions not available
during the training process. We validate our method on real-world datasets of
ship and taxi routes, as well as paths in synthetic graphs, demonstrating its
ability to reconstruct paths and cycles, predict their distributions, and yield
interpretable latent representations.

</details>


### [39] [Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences](https://arxiv.org/abs/2509.16189)
*Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland*

Main category: cs.LG

TL;DR: 기계 학습 시스템의 일반화 실패 이유와 이를 개선할 수 있는 메커니즘을 탐구.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 시스템의 일반화 실패를 이해하고 이를 개선할 방법을 모색하기 위해.

Method: 인지 과학에서 영감을 얻어 잠재학습의 필요성을 강조하고 오라클 검색 메커니즘을 통한 시스템 구현을 제안.

Result: 기계 학습 시스템이 더 잘 일반화할 수 있도록 하는 경험적 사례 및 요소를 제시.

Conclusion: 현재 기계 학습 시스템의 데이터 비효율성이 자연 지능과 비교하여 발생하는 이유를 설명하고 검색 방법이 일반화를 개선하는 방식에 대한 이해를 돕는다.

Abstract: When do machine learning systems fail to generalize, and what mechanisms
could improve their generalization? Here, we draw inspiration from cognitive
science to argue that one weakness of machine learning systems is their failure
to exhibit latent learning -- learning information that is not relevant to the
task at hand, but that might be useful in a future task. We show how this
perspective links failures ranging from the reversal curse in language modeling
to new findings on agent-based navigation. We then highlight how cognitive
science points to episodic memory as a potential part of the solution to these
issues. Correspondingly, we show that a system with an oracle retrieval
mechanism can use learning experiences more flexibly to generalize better
across many of these challenges. We also identify some of the essential
components for effectively using retrieval, including the importance of
within-example in-context learning for acquiring the ability to use information
across retrieved examples. In summary, our results illustrate one possible
contributor to the relative data inefficiency of current machine learning
systems compared to natural intelligence, and help to understand how retrieval
methods can complement parametric learning to improve generalization.

</details>
