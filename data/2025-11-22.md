<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 6]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 15]
- [cs.AI](#cs.AI) [Total: 30]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Secure Autonomous Agent Payments: Verifying Authenticity and Intent in a Trustless Environment](https://arxiv.org/abs/2511.15712)
*Vivek Acharya*

Main category: cs.CR

TL;DR: 이 논문은 자율 에이전트를 통한 AI 기반 결제의 신뢰성과 의도를 검증하는 블록체인 기반 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 사용자를 대신해 재무 거래를 시작하는 능력이 증가하면서, 자율 에이전트의 진정성과 거래의 실제 의도를 검증하는 것이 중요한 도전 과제가 되었다.

Method: 이 시스템은 분산형 신원(DID) 표준과 검증 가능한 자격 증명을 활용하여 에이전트의 신원, 온체인 의도 증명을 기록하고, 제로 지식 증명(ZKP)을 통해 개인 정보 보호 및 정책 준수를 보장한다.

Result: 이 프레임워크는 사람 행세, 무단 거래, 의도 불일치를 강하게 저항하는 것을 입증하였다.

Conclusion: 이 연구는 AI 기반 금융 생태계에서 검증 가능한 신뢰와 책임을 가능하게 하는 안전하고 감사 가능한 자율 경제 에이전트를 위한 기초를 마련한다.

Abstract: Artificial intelligence (AI) agents are increasingly capable of initiating financial transactions on behalf of users or other agents. This evolution introduces a fundamental challenge: verifying both the authenticity of an autonomous agent and the true intent behind its transactions in a decentralized, trustless environment. Traditional payment systems assume human authorization, but autonomous, agent-led payments remove that safeguard. This paper presents a blockchain-based framework that cryptographically authenticates and verifies the intent of every AI-initiated transaction. The proposed system leverages decentralized identity (DID) standards and verifiable credentials to establish agent identities, on-chain intent proofs to record user authorization, and zero-knowledge proofs (ZKPs) to preserve privacy while ensuring policy compliance. Additionally, secure execution environments (TEE-based attestations) guarantee the integrity of agent reasoning and execution. The hybrid on-chain/off-chain architecture provides an immutable audit trail linking user intent to payment outcome. Through qualitative analysis, the framework demonstrates strong resistance to impersonation, unauthorized transactions, and misalignment of intent. This work lays the foundation for secure, auditable, and intent-aware autonomous economic agents, enabling a future of verifiable trust and accountability in AI-driven financial ecosystems.

</details>


### [2] [Securing AI Agents Against Prompt Injection Attacks](https://arxiv.org/abs/2511.15759)
*Badrinath Ramakrishnan,Akshaya Balaji*

Main category: cs.CR

TL;DR: RAG 시스템에서 프롬프트 주입 공격의 보안 취약점을 평가하기 위한 포괄적인 벤치마크와 다층 방어 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: RAG 시스템의 보안 취약점을 이해하고, 이를 방어하기 위한 효과적인 방법을 개발하기 위해.

Method: 847개의 적대적 테스트 사례로 구성된 벤치마크를 통해 프롬프트 주입 위험을 평가하고, 세 가지 방어 메커니즘을 검토하였습니다.

Result: 결과적으로 방어 프레임워크는 성공적인 공격 비율을 73.2%에서 8.7%로 감소시켰으며, 94.3%의 작업 성능을 유지하였습니다.

Conclusion: 이 연구는 AI 에이전트 보안 향상을 위한 데이터셋과 방어 구현을 제공하여 향후 연구를 촉진합니다.

Abstract: Retrieval-augmented generation (RAG) systems have become widely used for enhancing large language model capabilities, but they introduce significant security vulnerabilities through prompt injection attacks. We present a comprehensive benchmark for evaluating prompt injection risks in RAG-enabled AI agents and propose a multi-layered defense framework. Our benchmark includes 847 adversarial test cases across five attack categories: direct injection, context manipulation, instruction override, data exfiltration, and cross-context contamination. We evaluate three defense mechanisms: content filtering with embedding-based anomaly detection, hierarchical system prompt guardrails, and multi-stage response verification, across seven state-of-the-art language models. Our combined framework reduces successful attack rates from 73.2% to 8.7% while maintaining 94.3% of baseline task performance. We release our benchmark dataset and defense implementation to support future research in AI agent security.

</details>


### [3] [Hiding in the AI Traffic: Abusing MCP for LLM-Powered Agentic Red Teaming](https://arxiv.org/abs/2511.15998)
*Strahinja Janjusevic,Anna Baron Garcia,Sohrob Kazerounian*

Main category: cs.CR

TL;DR: Generative AI는 사이버 보안 공격을 변모시키고 있으며, 본 연구에서는 새로운 C2 아키텍처를 통해 자율적인 탐색 에이전트를 사용할 수 있는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존 사이버 공격 도구의 일반성과 전문성 간의 균형을 맞추고, 인식 문제 및 윤리적 우려를 해결하고자 한다.

Method: Model Context Protocol(MCP)을 활용한 새로운 명령 및 제어(C2) 아키텍처를 제안하여 네트워크 전반에 걸쳐 분산된 자율 탐색 에이전트를 조율한다.

Result: MCP 기반 C2는 시스템 전체의 목표 지향적 행동을 개선하고 명령 및 제어 행동을 탐지하고 방지하는 데 필요한 주요 호스트 및 네트워크 아티팩트를 제거한다.

Conclusion: MCP 기반 C2 프레임워크는 차세대 방어 시스템 개발에 기여할 수 있는 자율적인 공격 시나리오를 시뮬레이션할 수 있는 중요한 진전을 보여준다.

Abstract: Generative AI is reshaping offensive cybersecurity by enabling autonomous red team agents that can plan, execute, and adapt during penetration tests. However, existing approaches face trade-offs between generality and specialization, and practical deployments reveal challenges such as hallucinations, context limitations, and ethical concerns. In this work, we introduce a novel command & control (C2) architecture leveraging the Model Context Protocol (MCP) to coordinate distributed, adaptive reconnaissance agents covertly across networks. Notably, we find that our architecture not only improves goal-directed behavior of the system as whole, but also eliminates key host and network artifacts that can be used to detect and prevent command & control behavior altogether. We begin with a comprehensive review of state-of-the-art generative red teaming methods, from fine-tuned specialist models to modular or agentic frameworks, analyzing their automation capabilities against task-specific accuracy. We then detail how our MCP-based C2 can overcome current limitations by enabling asynchronous, parallel operations and real-time intelligence sharing without periodic beaconing. We furthermore explore advanced adversarial capabilities of this architecture, its detection-evasion techniques, and address dual-use ethical implications, proposing defensive measures and controlled evaluation in lab settings. Experimental comparisons with traditional C2 show drastic reductions in manual effort and detection footprint. We conclude with future directions for integrating autonomous exploitation, defensive LLM agents, predictive evasive maneuvers, and multi-agent swarms. The proposed MCP-enabled C2 framework demonstrates a significant step toward realistic, AI-driven red team operations that can simulate advanced persistent threats while informing the development of next-generation defensive systems.

</details>


### [4] ["To Survive, I Must Defect": Jailbreaking LLMs via the Game-Theory Scenarios](https://arxiv.org/abs/2511.16278)
*Zhen Sun,Zongmin Zhang,Deqi Liang,Han Sun,Yule Liu,Yun Shen,Xiangshan Gao,Yilong Yang,Shuai Liu,Yutao Yue,Xinlei He*

Main category: cs.CR

TL;DR: GTA는 확장 가능한 블랙박스 탈옥 프레임워크로, LLM의 안전성을 약화시키는 새로운 게임 이론 공격을 제안한다. 실험을 통해 GTA는 Deepseek-R1과 같은 LLM에서 95% 이상의 성공률을 달성하며, 실제 LLM 응용 프로그램에서도 효과를 입증하였다.


<details>
  <summary>Details</summary>
Motivation: LLM의 유용성 증가로 비전문 사용자에 의한 위험이 발생할 수 있으며, 이로 인해 탈옥 공격에 대한 연구가 필요하다.

Method: 공격자의 상호작용을  유한 수평의 조기 중단 가능한 확률적 게임으로 형식화하고, 게임 이론 시나리오를 통해 LLM의 효과적인 목표를 재형성하여 안전 제약을 약화시키는 메커니즘을 도입한다.

Result: GTA는 Deepseek-R1과 같은 LLM에서 95% 이상의 ASR을 달성하고, 다양한 프로토콜과 데이터셋에서 효율성을 유지하며 효과성을 입증하였다.

Conclusion: GTA는 기존의 공격보다 더 높은 확장성을 보여주며, 실제 LLM 응용 프로그램에 대한 탈옥에도 성공하였다.

Abstract: As LLMs become more common, non-expert users can pose risks, prompting extensive research into jailbreak attacks. However, most existing black-box jailbreak attacks rely on hand-crafted heuristics or narrow search spaces, which limit scalability. Compared with prior attacks, we propose Game-Theory Attack (GTA), an scalable black-box jailbreak framework. Concretely, we formalize the attacker's interaction against safety-aligned LLMs as a finite-horizon, early-stoppable sequential stochastic game, and reparameterize the LLM's randomized outputs via quantal response. Building on this, we introduce a behavioral conjecture "template-over-safety flip": by reshaping the LLM's effective objective through game-theoretic scenarios, the originally safety preference may become maximizing scenario payoffs within the template, which weakens safety constraints in specific contexts. We validate this mechanism with classical game such as the disclosure variant of the Prisoner's Dilemma, and we further introduce an Attacker Agent that adaptively escalates pressure to increase the ASR. Experiments across multiple protocols and datasets show that GTA achieves over 95% ASR on LLMs such as Deepseek-R1, while maintaining efficiency. Ablations over components, decoding, multilingual settings, and the Agent's core model confirm effectiveness and generalization. Moreover, scenario scaling studies further establish scalability. GTA also attains high ASR on other game-theoretic scenarios, and one-shot LLM-generated variants that keep the model mechanism fixed while varying background achieve comparable ASR. Paired with a Harmful-Words Detection Agent that performs word-level insertions, GTA maintains high ASR while lowering detection under prompt-guard models. Beyond benchmarks, GTA jailbreaks real-world LLM applications and reports a longitudinal safety monitoring of popular HuggingFace LLMs.

</details>


### [5] [The Shawshank Redemption of Embodied AI: Understanding and Benchmarking Indirect Environmental Jailbreaks](https://arxiv.org/abs/2511.16347)
*Chunyang Li,Zifeng Kang,Junwei Zhang,Zhuo Ma,Anda Cheng,Xinghua Li,Jianfeng Ma*

Main category: cs.CR

TL;DR: 이 논문에서는 간접 환경 탈옥(IEJ)이라는 새로운 공격 방법을 제안하며, 이는 환경에 주입된 간접 프롬프트를 통해 구현됩니다.


<details>
  <summary>Details</summary>
Motivation: 비전-언어 모델(VLM)의 사용은 효과적이지만, 탈옥과 같은 안전 문제를 야기합니다.

Method: 우리는 환경에 적힌 악의적인 지시를 이용하여 Embodied AI를 탈옥하기 위한 간접 환경 탈옥(IEJ) 접근 방식을 제안합니다.

Result: SHAWSHANK라는 자동 공격 생성 프레임워크와 SHAWSHANK-FORGE라는 자동 벤치마크 생성 프레임워크를 설계하고 구현했습니다.

Conclusion: 평가 결과, SHAWSHANK는 3,957개의 작업-장면 조합에서 기존의 11가지 방법보다 성능이 우수하며, 모든 테스트된 VLM을 타협할 수 있음을 보여주었습니다.

Abstract: The adoption of Vision-Language Models (VLMs) in embodied AI agents, while being effective, brings safety concerns such as jailbreaking. Prior work have explored the possibility of directly jailbreaking the embodied agents through elaborated multi-modal prompts. However, no prior work has studied or even reported indirect jailbreaks in embodied AI, where a black-box attacker induces a jailbreak without issuing direct prompts to the embodied agent. In this paper, we propose, for the first time, indirect environmental jailbreak (IEJ), a novel attack to jailbreak embodied AI via indirect prompt injected into the environment, such as malicious instructions written on a wall. Our key insight is that embodied AI does not ''think twice'' about the instructions provided by the environment -- a blind trust that attackers can exploit to jailbreak the embodied agent. We further design and implement open-source prototypes of two fully-automated frameworks: SHAWSHANK, the first automatic attack generation framework for the proposed attack IEJ; and SHAWSHANK-FORGE, the first automatic benchmark generation framework for IEJ. Then, using SHAWSHANK-FORGE, we automatically construct SHAWSHANK-BENCH, the first benchmark for indirectly jailbreaking embodied agents. Together, our two frameworks and one benchmark answer the questions of what content can be used for malicious IEJ instructions, where they should be placed, and how IEJ can be systematically evaluated. Evaluation results show that SHAWSHANK outperforms eleven existing methods across 3,957 task-scene combinations and compromises all six tested VLMs. Furthermore, current defenses only partially mitigate our attack, and we have responsibly disclosed our findings to all affected VLM vendors.

</details>


### [6] [Systematically Deconstructing APVD Steganography and its Payload with a Unified Deep Learning Paradigm](https://arxiv.org/abs/2511.16604)
*Kabbo Jit Deb,Md. Azizul Hakim,Md Shamse Tabrej*

Main category: cs.CR

TL;DR: 딥 러닝 기반 접근법을 통해 Adaptive Pixel Value Differencing(APVD) 스테가노그래피를 탐지하고 숨겨진 데이터를 복원하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 디지털 통신 시대에 데이터 비밀 삽입 방법으로 스테가노그래피가 중요해지고 있으며, APVD 방식이 전통적인 스테가 분석의 도전을 제기합니다.

Method: 우리는 동시에 스테고 탐지 및 페이로드 복원을 위한 어텐션 메커니즘을 갖춘 컨볼루션 신경망(CNN)을 제시합니다.

Result: 모델은 BOSSbase와 UCID 데이터셋의 10,000개 이미지에서 훈련 및 검증되었으며 96.2%의 탐지 정확성을 달성하고, 낮은 삽입 밀도에서 최대 93.6%의 페이로드 복원이 가능합니다.

Conclusion: 이 연구는 적응형 스테가노그래피의 취약성을 드러내고, 디지털 포렌식 분석 도구를 제공하며, AI 기반 기술 시대의 데이터 보안 재평가를 촉구합니다.

Abstract: In the era of digital communication, steganography allows covert embedding of data within media files. Adaptive Pixel Value Differencing (APVD) is a steganographic method valued for its high embedding capacity and invisibility, posing challenges for traditional steganalysis. This paper proposes a deep learning-based approach for detecting APVD steganography and performing reverse steganalysis, which reconstructs the hidden payload. We present a Convolutional Neural Network (CNN) with an attention mechanism and two output heads for simultaneous stego detection and payload recovery. Trained and validated on 10,000 images from the BOSSbase and UCID datasets, our model achieves a detection accuracy of 96.2 percent. It also reconstructs embedded payloads with up to 93.6 percent recovery at lower embedding densities. Results indicate a strong inverse relationship between payload size and recovery accuracy. This study reveals a vulnerability in adaptive steganography and provides a tool for digital forensic analysis, while encouraging reassessment of data security in the age of AI-driven techniques.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [7] [The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems](https://arxiv.org/abs/2511.15862)
*Devang Kulshreshtha,Wanyu Du,Raghav Jain,Srikanth Doss,Hang Su,Sandesh Swamy,Yanjun Qi*

Main category: cs.MA

TL;DR: 이 논문은 비협력적 행동이 LLM 기반 다중 에이전트 시스템을 어떻게 불안정화하거나 붕괴시킬 수 있는지를 시뮬레이션하고 분석하는 새로운 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 비협력적 행동이 다중 에이전트 시스템에 미치는 영향을 이해하려는 필요성.

Method: 게임 이론 기반의 비협력적 에이전트 행동 분류법과 서로 다른 에이전트 상태에서 비협력적 행동을 동적으로 생성하고 개선하는 다단계 시뮬레이션 파이프라인을 포함하는 프레임워크.

Result: 우리의 프레임워크는 96.7%의 정확도로 현실적인 비협력적 행동을 생성했으며, 비협력적 행동이 시스템의 빠른 붕괴를 초래함을 보여주었다.

Conclusion: 비협력적 에이전트는 집합적 결과를 크게 저해할 수 있으며, 더 탄력적인 다중 에이전트 시스템 설계의 필요성을 강조한다.

Abstract: This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [Large Language Model-Based Reward Design for Deep Reinforcement Learning-Driven Autonomous Cyber Defense](https://arxiv.org/abs/2511.16483)
*Sayak Mukherjee,Samrat Chatterjee,Emilie Purvine,Ted Fujimoto,Tegan Emerson*

Main category: cs.LG

TL;DR: 본 논문에서는 복잡하고 동적인 환경에서 자율 사이버 공격 및 방어 학습 에이전트를 위한 보상 설계를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 사이버 방어 정책 수립을 위한 보상 구조 설계는 전문가에게 도전적인 과제이다.

Method: 대규모 언어 모델 기반의 보상 설계 접근법을 사용하여 실험 시뮬레이션 환경에서 자율 사이버 방어 정책을 생성한다.

Result: 여러 다양한 공격 및 방어 에이전트 페르소나를 만들어 LLM이 컨텍스트를 바탕으로 한 보상 구조를 설계하는 데 활용하였다.

Conclusion: 이 연구는 LLM 기반 보상 설계가 다양한 적대적 행동에 대해 효과적인 방어 전략으로 이어질 수 있음을 보여준다.

Abstract: Designing rewards for autonomous cyber attack and defense learning agents in a complex, dynamic environment is a challenging task for subject matter experts. We propose a large language model (LLM)-based reward design approach to generate autonomous cyber defense policies in a deep reinforcement learning (DRL)-driven experimental simulation environment. Multiple attack and defense agent personas were crafted, reflecting heterogeneity in agent actions, to generate LLM-guided reward designs where the LLM was first provided with contextual cyber simulation environment information. These reward structures were then utilized within a DRL-driven attack-defense simulation environment to learn an ensemble of cyber defense policies. Our results suggest that LLM-guided reward designs can lead to effective defense strategies against diverse adversarial behaviors.

</details>


### [9] [Connecting the Dots: A Machine Learning Ready Dataset for Ionospheric Forecasting Models](https://arxiv.org/abs/2511.15743)
*Linnea M. Wolniewicz,Halil S. Kelebek,Simone Mestici,Michael D. Vergalla,Giacomo Acciarini,Bala Poduval,Olga Verkhoglyadova,Madhulika Guhathakurta,Thomas E. Berger,Atılım Güneş Baydin,Frank Soboczenski*

Main category: cs.LG

TL;DR: 이 논문은 이온층의 운영 예측을 지원하기 위한 포괄적이고 머신러닝 최적화된 데이터 세트를 제시하며, 이온층 역학 및 태양-지구 상호작용 탐구를 위한 모델링 파이프라인을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 이온층의 운영 예측은 관측의 부족, 복잡한 지리적 레이어 간의 결합, 그리고 GNSS, 통신, 항공 안전 및 위성 운영을 지원하기 위한 시기적절하고 정확한 예측에 대한 필요성으로 인해 중요한 우주 날씨 문제로 남아 있습니다.

Method: 2025 NASA 헬리오랩의 일환으로, 다양한 이온층 및 태양층 측정을 일관된 머신러닝 준비 구조로 통합한 포괄적이고 개방형 데이터 세트를 제시하고, 이는 차세대 예측 모델을 지원하고 현재 운영 프레임워크의 격차를 해결하기 위해 설계되었습니다. 우리의 워크플로우는 태양역동관측소 데이터, 태양 복사 지수, 태양풍 매개변수, 지자기 활동 지수 및 NASA JPL의 GIM-TEC 등의 데이터를 통합합니다.

Result: 이 데이터 세트를 활용하여 우리는 조용한 상태와 지자기적으로 활동적인 상태 모두에서 수직 TEC 예측을 위한 여러 시공간 머신러닝 아키텍처를 훈련하고 벤치마킹합니다. 이 연구는 이온층 역학 및 더 광범위한 태양-지구 상호작용 탐구를 가능하게 하는 방대한 데이터 세트와 모델링 파이프라인을 제시합니다.

Conclusion: 이 연구는 과학적 탐구와 운영 예측 노력 모두를 지원하는 이온층 역학 및 태양-지구 상호작용을 탐구할 수 있는 방대한 데이터 세트와 모델링 파이프라인을 제공합니다.

Abstract: Operational forecasting of the ionosphere remains a critical space weather challenge due to sparse observations, complex coupling across geospatial layers, and a growing need for timely, accurate predictions that support Global Navigation Satellite System (GNSS), communications, aviation safety, as well as satellite operations. As part of the 2025 NASA Heliolab, we present a curated, open-access dataset that integrates diverse ionospheric and heliospheric measurements into a coherent, machine learning-ready structure, designed specifically to support next-generation forecasting models and address gaps in current operational frameworks. Our workflow integrates a large selection of data sources comprising Solar Dynamic Observatory data, solar irradiance indices (F10.7), solar wind parameters (velocity and interplanetary magnetic field), geomagnetic activity indices (Kp, AE, SYM-H), and NASA JPL's Global Ionospheric Maps of Total Electron Content (GIM-TEC). We also implement geospatially sparse data such as the TEC derived from the World-Wide GNSS Receiver Network and crowdsourced Android smartphone measurements. This novel heterogeneous dataset is temporally and spatially aligned into a single, modular data structure that supports both physical and data-driven modeling. Leveraging this dataset, we train and benchmark several spatiotemporal machine learning architectures for forecasting vertical TEC under both quiet and geomagnetically active conditions. This work presents an extensive dataset and modeling pipeline that enables exploration of not only ionospheric dynamics but also broader Sun-Earth interactions, supporting both scientific inquiry and operational forecasting efforts.

</details>


### [10] [TopoReformer: Mitigating Adversarial Attacks Using Topological Purification in OCR Models](https://arxiv.org/abs/2511.15807)
*Bhagyesh Kumar,A S Aravinthakashan,Akshat Satyanarayan,Ishaan Gakhar,Ujjwal Verma*

Main category: cs.LG

TL;DR: TopoReformer는 텍스트 이미지의 구조적 완전성을 보존하면서 적대적 변형을 완화하는 모델 불변형 재형성 파이프라인이다.


<details>
  <summary>Details</summary>
Motivation: 고급 OCR 시스템이 인간에게 보이지 않는 변화로 인해 잘못된 문자 전사를 생성할 수 있는 적대적 변형 이미지가 증가하는 문제를 해결하기 위해.

Method: TopoReformer는 토폴로지의 특징을 활용하여 잠재 공간의 다양체 수준 일관성을 강화하고, 명시적인 기울기 정규화 없이도 강인성을 개선하는 토폴로지적 오토인코더를 사용한다.

Result: 제안된 방법은 EMNIST와 MNIST 데이터셋에서 표준 적대적 공격(FGSM, PGD, Carlini-Wagner), 적응형 공격(EOT, BDPA), OCR 특화 워터마크 공격(FAWA)에 대해 벤치마크되었다.

Conclusion: TopoReformer는 모델 특정성이 없으며, 기존 방어 방법들이 가진 한계를 극복할 수 있는 보다 강력하고 일반화된 솔루션을 제공한다.

Abstract: Adversarially perturbed images of text can cause sophisticated OCR systems to produce misleading or incorrect transcriptions from seemingly invisible changes to humans. Some of these perturbations even survive physical capture, posing security risks to high-stakes applications such as document processing, license plate recognition, and automated compliance systems. Existing defenses, such as adversarial training, input preprocessing, or post-recognition correction, are often model-specific, computationally expensive, and affect performance on unperturbed inputs while remaining vulnerable to unseen or adaptive attacks. To address these challenges, TopoReformer is introduced, a model-agnostic reformation pipeline that mitigates adversarial perturbations while preserving the structural integrity of text images. Topology studies properties of shapes and spaces that remain unchanged under continuous deformations, focusing on global structures such as connectivity, holes, and loops rather than exact distance. Leveraging these topological features, TopoReformer employs a topological autoencoder to enforce manifold-level consistency in latent space and improve robustness without explicit gradient regularization. The proposed method is benchmarked on EMNIST, MNIST, against standard adversarial attacks (FGSM, PGD, Carlini-Wagner), adaptive attacks (EOT, BDPA), and an OCR-specific watermark attack (FAWA).

</details>


### [11] [Attention-Based Feature Online Conformal Prediction for Time Series](https://arxiv.org/abs/2511.15838)
*Meiyi Zhu,Caili Guo,Chunyan Feng,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 온라인 적합 예측(OCP)은 사전 훈련된 예측기를 통해 시간적 의존성이나 분포 변화와 관계없이 보장된 커버리지를 가진 예측 집합을 생성합니다. 하지만 OCP는 단순한 비일치 점수로 출력 공간에서 작동하며, 모든 역사적 관찰을 균일하게 처리하는 두 가지 주요 한계점이 있습니다. 이 논문은 이러한 한계를 해결하는 주의 기반 피쳐 OCP(AFOCP)를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 온라인 적합 예측의 한계를 극복하고 더 나은 예측 성능을 달성하기 위해.

Method: 사전 훈련된 신경망의 피쳐 공간에서 작업하며, 주의 메커니즘을 통해 역사적 관찰의 가중치를 적응적으로 조정합니다.

Result: AFOCP는 표준 OCP에 비해 예측 구간을 최대 $88\%$ 감소시키면서 목표 커버리지 수준을 유지합니다.

Conclusion: AFOCP는 장기적인 커버리지를 유지하면서 표준 OCP보다 작은 예측 구간을 달성한다는 이론적 보장을 제공하며, 피쳐-공간 보정 및 주의 기반 적응적인 가중치 부여의 이점을 검증합니다.

Abstract: Online conformal prediction (OCP) wraps around any pre-trained predictor to produce prediction sets with coverage guarantees that hold irrespective of temporal dependencies or distribution shifts. However, standard OCP faces two key limitations: it operates in the output space using simple nonconformity (NC) scores, and it treats all historical observations uniformly when estimating quantiles. This paper introduces attention-based feature OCP (AFOCP), which addresses both limitations through two key innovations. First, AFOCP operates in the feature space of pre-trained neural networks, leveraging learned representations to construct more compact prediction sets by concentrating on task-relevant information while suppressing nuisance variation. Second, AFOCP incorporates an attention mechanism that adaptively weights historical observations based on their relevance to the current test point, effectively handling non-stationarity and distribution shifts. We provide theoretical guarantees showing that AFOCP maintains long-term coverage while provably achieving smaller prediction intervals than standard OCP under mild regularity conditions. Extensive experiments on synthetic and real-world time series datasets demonstrate that AFOCP consistently reduces the size of prediction intervals by as much as $88\%$ as compared to OCP, while maintaining target coverage levels, validating the benefits of both feature-space calibration and attention-based adaptive weighting.

</details>


### [12] [AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization](https://arxiv.org/abs/2511.15915)
*Genghan Zhang,Shaowei Zhu,Anjiang Wei,Zhenyu Song,Allen Nie,Zhen Jia,Nandita Vijaykumar,Yida Wang,Kunle Olukotun*

Main category: cs.LG

TL;DR: AccelOpt는 자율적으로 AI 가속기를 위한 커널을 최적화하는 자가 개선 대형 언어 모델 시스템이다.


<details>
  <summary>Details</summary>
Motivation: AI 가속기를 위한 하드웨어 특화 최적화 지식의 필요성을 없애기 위해.

Method: 커널 최적화 공간을 탐색하는 최적화 메모리를 기반으로 하는 반복 생성 방식을 사용한다.

Result: NKIBench를 통해 AccelOpt의 성능이 시간이 지남에 따라 개선됨을 확인했다.

Conclusion: AccelOpt는 저비용으로도 뛰어난 성능 개선을 제공한다.

Abstract: We present AccelOpt, a self-improving large language model (LLM) agentic system that autonomously optimizes kernels for emerging AI acclerators, eliminating the need for expert-provided hardware-specific optimization knowledge. AccelOpt explores the kernel optimization space through iterative generation, informed by an optimization memory that curates experiences and insights from previously encountered slow-fast kernel pairs. We build NKIBench, a new benchmark suite of AWS Trainium accelerator kernels with varying complexity extracted from real-world LLM workloads to evaluate the effectiveness of AccelOpt. Our evaluation confirms that AccelOpt's capability improves over time, boosting the average percentage of peak throughput from $49\%$ to $61\%$ on Trainium 1 and from $45\%$ to $59\%$ on Trainium 2 for NKIBench kernels. Moreover, AccelOpt is highly cost-effective: using open-source models, it matches the kernel improvements of Claude Sonnet 4 while being $26\times$ cheaper.

</details>


### [13] [Machine Learning Epidemic Predictions Using Agent-based Wireless Sensor Network Models](https://arxiv.org/abs/2511.15982)
*Chukwunonso Henry Nwokoye,Blessing Oluchi,Sharna Waldron,Peace Ezzeh*

Main category: cs.LG

TL;DR: 본 연구는 무선 센서 네트워크의 전염병 모델을 기반으로 ML 예측을 위한 SEIRV 모델을 구현하였다.


<details>
  <summary>Details</summary>
Motivation: 무선 센서 네트워크에서 전염병 데이터를 사용하는 것은 바이러스와 웜과 같은 위협을 예측하고 완화하는 데 핵심적인 어려움이다.

Method: SEIRV 수학 모델을 기반으로 한 에이전트 기반 구현을 통해 두 개의 합성 전염병 데이터셋을 생성하고 여러 ML 알고리즘에 적용하였다.

Result: 예측은 낮은 오류 메트릭과 높은 R^2 값을 기록하며 양호한 성과를 보였다.

Conclusion: Random Forest, XGBoost, Decision Trees, k-nearest neighbors가 가장 높은 성과를 보였고, 지원 벡터, 선형 회귀, Lasso, Ridge, ElasticNet 회귀는 성과가 저조하였다.

Abstract: The lack of epidemiological data in wireless sensor networks (WSNs) is a fundamental difficulty in constructing robust models to forecast and mitigate threats such as viruses and worms. Many studies have examined different epidemic models for WSNs, focusing on how malware infections spread given the network's specific properties, including energy limits and node mobility. In this study, an agent-based implementation of the susceptible-exposed-infected-recovered-vaccinated (SEIRV) mathematical model was employed for machine learning (ML) predictions. Using tools such as NetLogo's BehaviorSpace and Python, two epidemic synthetic datasets were generated and prepared for the application of several ML algorithms. Posed as a regression problem, the infected and recovered nodes were predicted, and the performance of these algorithms is compared using the error metrics of the train and test sets. The predictions performed well, with low error metrics and high R^2 values (0.997, 1.000, 0.999, 1.000), indicating an effective fit to the training set. The validation values were lower (0.992, 0.998, 0.971, and 0.999), as is typical when evaluating model performance on unseen data. Based on the recorded performances, support vector, linear, Lasso, Ridge, and ElasticNet regression were among the worst-performing algorithms, while Random Forest, XGBoost, Decision Trees, and k-nearest neighbors achieved the best results.

</details>


### [14] [Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning](https://arxiv.org/abs/2511.16043)
*Peng Xia,Kaide Zeng,Jiaqi Liu,Can Qin,Fang Wu,Yiyang Zhou,Caiming Xiong,Huaxiu Yao*

Main category: cs.LG

TL;DR: Agent0는 외부 데이터 없이 고성능 에이전트를 발전시키는 자율적 프레임워크로, 점진적인 공진화를 통해 복잡한 커리큘럼을 생성한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 대규모 언어 모델(LM) 에이전트는 인간이 선별한 데이터에 의존하며, 이는 확장성과 AI의 인간 지식 의존성을 제한한다.

Method: Agent0는 동일한 기본 LLM에서 초기화된 두 에이전트 간의 공생 경쟁을 통해 커리큘럼 에이전트와 실행자 에이전트를 설정하고, 외부 도구를 통합하여 문제 해결 능력을 증대시킨다.

Result: Agent0는 Qwen3-8B-Base 모델의 수학적 추론과 일반 추론 벤치마크에서 각각 18%와 24%의 성능 향상을 달성했다.

Conclusion: Agent0를 통해 지속적으로 고품질의 커리큘럼을 생성하는 자기 강화 사이클이 확립되었다.

Abstract: Large Language Model (LLM) Agents, often trained with Reinforcement Learning (RL), are constrained by a dependency on human-curated data, limiting scalability and tethering AI to human knowledge. Existing self-evolution frameworks offer an alternative but are typically restricted by the model's inherent capabilities and single-round interactions, hindering the development of complex curricula involving tool use or dynamic reasoning. We introduce Agent0, a fully autonomous framework that evolves high-performing agents without external data through multi-step co-evolution and seamless tool integration. Agent0 establishes a symbiotic competition between two agents initialized from the same base LLM: a curriculum agent that proposes increasingly challenging frontier tasks, and an executor agent that learns to solve them. We integrate external tools to enhance the executor's problem-solving capacity; this improvement, in turn, pressures the curriculum agent to construct more complex, tool-aware tasks. Through this iterative process, Agent0 establishes a self-reinforcing cycle that continuously produces high-quality curricula. Empirically, Agent0 substantially boosts reasoning capabilities, improving the Qwen3-8B-Base model by 18% on mathematical reasoning and 24% on general reasoning benchmarks. Code is available at https://github.com/aiming-lab/Agent0.

</details>


### [15] [Change-of-Basis Pruning via Rotational Invariance](https://arxiv.org/abs/2511.16061)
*Alex Ning,Vainateya Rangaraju*

Main category: cs.LG

TL;DR: 구조적 프루닝은 전체 뉴런 또는 채널을 제거하지만 그 효과는 표현 공간에서 중요성이 분포되는 방식에 따라 다릅니다. CoB 프루닝은 특정 차원 내에서 중요성을 집중시키는 직교 선형 변환을 적용하여 이 문제를 해결합니다. 그러나 많은 표준 딥러닝 아키텍처는 이러한 변환에 본질적으로 불변이지 않습니다. 이 문제를 해결하기 위해 두 개의 서브 공간 방사 활성화(TSRA)를 도입하여 독립적으로 두 활성화 서브 공간에서 적용된 직교 선형 변환에 대해 불변성을 갖는 활성화 가족을 제안합니다. 이 방법은 CoB 변환을 주변 가중치와 통합할 수 있게 하여 추가 매개변수를 요구하지 않습니다. 본 연구는 회전 불변 디자인이 CoB 프루닝을 위한 이론적인 접근을 제공할 수 있음을 보여주는 개념 증명으로서 자리 잡고 있습니다. 우리는 여러 TSRA 후보에 대한 분석을 제공하지 않으며, TSRA의 가중치 초기화도 탐색하지 않습니다. 이러한 한계와 회전 불변성을 허용하기 위한 다른 수정 사항들이 결합하여 ReLU 기반의 기준에 비해 약 4.52%의 정확도 감소를 초래합니다. 그러나 활성화 크기 중요도를 사용하여 VGG-16이 우리의 CoB+TSRA 프레임워크를 구현해 CIFAR-10에서 고무적인 결과를 보여줍니다. 고정 비율 구조적 프루닝에서 CoB는 모든 프루닝 비율에서 TSRA 기준보다 정확도를 개선하며, 파라미터의 약 30%에서 70%까지 신뢰할 수 있는 프루닝 한계를 확장합니다. 임계값 기반 프루닝 전략 하에서 CoB는 매개변수의 90-96%를 프루닝하면서 미세 조정 후 1-6%의 정확도 감소를 유지합니다. 이러한 결과들은 회전 불변 아키텍처가 CoB 프루닝을 위한 유망한 경로를 제시할 수 있음을 나타냅니다.


<details>
  <summary>Details</summary>
Motivation: 구조적 프루닝의 효과가 표현 공간에서의 중요성 분포에 따라 달라지기 때문에, 효과적인 프루닝 방법이 필요합니다.

Method: 두 개의 서브 공간 방사 활성화(TSRA)를 도입하여 독립적으로 적용된 직교 선형 변환에 대해 불변성을 가진 활성화 구조를 정의합니다.

Result: VGG-16 기반의 프레임워크가 CIFAR-10에서 고무적인 결과를 보이며, CoB는 모든 프루닝 비율에서 TSRA 기준보다 높은 정확도를 유지합니다.

Conclusion: 회전 불변 아키텍처는 CoB 프루닝을 위한 유망한 접근 방법이 될 수 있습니다.

Abstract: Structured pruning removes entire neurons or channels, but its effectiveness depends on how importance is distributed across the representation space. Change-of-basis (CoB) pruning addresses this challenge by applying orthogonal linear transformations that concentrate importance within certain dimensions. However, many standard deep learning architectures are not inherently invariant to such transformations. To enable compatibility, we introduce two-subspace radial activations (TSRAs): an activation family that is invariant to orthogonal linear transformations applied independently within its two activation subspaces. This invariance allows CoB transformations to be merged into surrounding weights without incurring extra parameters. We position this work as a proof-of-concept that a rotationally invariant design may offer a principled approach towards change-of-basis pruning. We do not provide an analysis of multiple TSRA candidates nor do we explore weight initialization for any TSRAs. These limitations, combined with other necessary modifications we make to permit rotational invariance, result in a slight accuracy drop of $4.52\%$ compared to a ReLU-based control. However, using activation-magnitude importance, VGG-16 implementing our CoB+TSRA framework shows encouraging results on CIFAR-10. Under fixed-ratio structured pruning, CoB improves accuracy over a TSRA baseline at all pruning ratios and extends reliable pruning frontier from roughly $30\%$ to $70\%$ of parameters without post-prune fine tuning. Under threshold-based pruning strategies, CoB prunes $90-96\%$ of parameters while maintaining $1-6\%$ accuracy drop after fine-tuning. Together, these results indicate that rotationally invariant architectures may offer a promising path towards CoB pruning.

</details>


### [16] [ILoRA: Federated Learning with Low-Rank Adaptation for Heterogeneous Client Aggregation](https://arxiv.org/abs/2511.16069)
*Junchao Zhou,Junkang Liu,Fanhua Shang*

Main category: cs.LG

TL;DR: ILoRA는 연합 학습의 클라이언트 이질성 문제를 해결하기 위해 세 가지 주요 혁신을 통합한 통합 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 클라이언트 이질성 하에서 연합 학습의 성능 저하를 해결하기 위한 필요성.

Method: QR 기반의 정규 직교 초기화, 연결된 QR 집계 메커니즘, Rank-aware AdamW 최적화 기법을 도입하여 문제를 해결.

Result: ILoRA는 기존의 연합 LoRA 방법보다 우수한 정확도와 수렴 안정성을 일관되게 달성하였다.

Conclusion: 이론적인 수렴 보장과 함께, ILoRA는 비전 및 NLP 벤치마크에서 광범위한 실험을 통해 그 효과를 입증하였다.

Abstract: Federated Learning with Low-Rank Adaptation (LoRA) faces three critical challenges under client heterogeneity: (1) Initialization-Induced Instability due to random initialization misaligning client subspaces; (2) Rank Incompatibility and Aggregation Error when averaging LoRA parameters of different ranks, which biases the global model; and (3) exacerbated Client Drift under Non-IID Data, impairing generalization. To address these challenges, we propose ILoRA, a unified framework that integrates three core innovations: a QR-based orthonormal initialization to ensure all clients start in a coherent subspace; a Concatenated QR Aggregation mechanism that fuses heterogeneous-rank updates via concatenation and decomposition, preserving information while maintaining dimension alignment; and an AdamW optimizer with rank-aware control variates to correct local updates and mitigate client drift. Supported by theoretical convergence guarantees, extensive experiments on vision and NLP benchmarks demonstrate that ILoRA consistently achieves superior accuracy and convergence stability compared to existing federated LoRA methods.

</details>


### [17] [Towards Overcoming Data Scarcity in Nuclear Energy: A Study on Critical Heat Flux with Physics-consistent Conditional Diffusion Model](https://arxiv.org/abs/2511.16207)
*Farah Alsafadi,Alexandra Akins,Xu Wu*

Main category: cs.LG

TL;DR: 이 논문은 핵 에너지 응용 분야에서 데이터 부족 문제를 극복하기 위해 확산 모델(DM)의 효과를 조사하고, 이를 통해 합성 데이터 생성을 통해 훈련 데이터의 크기와 다양성을 증가시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 에너지 관련 응용 분야에서는 실험 데이터가 종종 제한적이고 비싸며 얻기 어려우므로, 데이터 부족 문제를 극복하는 것이 중요하다.

Method: 공개된 임계 열 유속(CHF) 데이터셋을 활용하여, 샘플을 무작위로 생성할 수 있는 순수한 DM 외에도 사용자 지정 열유체 조건 하에서 목표로 하는 CHF 데이터를 생성할 수 있는 조건부 DM을 개발하였다.

Result: DM과 조건부 DM 모두 실제적이고 물리적으로 일관된 CHF 데이터를 성공적으로 생성할 수 있음을 보여주었으며, 불확실성 정량화도 수행하여 생성된 데이터의 신뢰성을 강조하였다.

Conclusion: 조건부 DM은 CHF 데이터를 증강하면서도 수용 가능한 수준의 불확실성을 유지하는 데 매우 효과적이다.

Abstract: Deep generative modeling provides a powerful pathway to overcome data scarcity in energy-related applications where experimental data are often limited, costly, or difficult to obtain. By learning the underlying probability distribution of the training dataset, deep generative models, such as the diffusion model (DM), can generate high-fidelity synthetic samples that statistically resemble the training data. Such synthetic data generation can significantly enrich the size and diversity of the available training data, and more importantly, improve the robustness of downstream machine learning models in predictive tasks. The objective of this paper is to investigate the effectiveness of DM for overcoming data scarcity in nuclear energy applications. By leveraging a public dataset on critical heat flux (CHF) that cover a wide range of commercial nuclear reactor operational conditions, we developed a DM that can generate an arbitrary amount of synthetic samples for augmenting of the CHF dataset. Since a vanilla DM can only generate samples randomly, we also developed a conditional DM capable of generating targeted CHF data under user-specified thermal-hydraulic conditions. The performance of the DM was evaluated based on their ability to capture empirical feature distributions and pair-wise correlations, as well as to maintain physical consistency. The results showed that both the DM and conditional DM can successfully generate realistic and physics-consistent CHF data. Furthermore, uncertainty quantification was performed to establish confidence in the generated data. The results demonstrated that the conditional DM is highly effective in augmenting CHF data while maintaining acceptable levels of uncertainty.

</details>


### [18] [Pass@k Metric for RLVR: A Diagnostic Tool of Exploration, But Not an Objective](https://arxiv.org/abs/2511.16231)
*Yang Yu*

Main category: cs.LG

TL;DR: 이 논문은 pass@k 메트릭의 분석과 이를 통해 최적화 목표로서의 적합성에 대해 논의합니다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 대규모 언어 모델의 복잡한 다단계 추론을 평가하고 향상시키기 위한 방법을 모색합니다.

Method: pass@k 메트릭의 기울기를 도출하고, 이를 pass@1 목표의 개별 샘플 긍정 재가중치로 분석합니다.

Result: exploration collapse의 동역학을 분석하여 pass@k와 pass@1 간의 격차가 축적 확률 질량에 따라 줄어듦을 보여줍니다.

Conclusion: pass@k는 유용한 진단 도구이지만 최적화의 직접적인 목표로는 부적합할 수 있으며, 효율적인 탐색을 촉진하는 메커니즘이 더 효과적일 수 있음을 제안합니다.

Abstract: The ability of Large Language Models (LLMs) to perform complex, multi-step reasoning is a central focus of modern AI research. To evaluate and enhance this capability, the pass@k metric, which measures the probability of obtaining at least one correct solution in k independent samples, has received significant attention. Its intuitive appeal has led to its adoption not only as an evaluation standard but also as a direct optimization objective in reinforcement learning. In this paper, we analyze the pass@k objective, derive its gradient, and demonstrate that it is fundamentally a per-example positive reweighting of the simpler pass@1 objective. Our analysis reveals that the pass@k objective provides a vanishing learning signal in regimes where exploration is most critical. We further analyze the dynamics of "exploration collapse", showing that as the policy concentrates probability mass, the gap between pass@k and pass@1 diminishes. We conclude that while pass@k is a useful diagnostic tool, it may be an unsuitable direct objective for optimization. Instead, mechanisms explicitly encouraging efficient exploration could offer a more effective path forward for reinforcement learning in reasoning tasks.

</details>


### [19] [Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning](https://arxiv.org/abs/2511.16333)
*Mohammad Areeb Qazi,Maryam Nadeem,Mohammad Yaqub*

Main category: cs.LG

TL;DR: 본 논문은 예측 역학을 학습해 다단계 롤아웃, 반사실 평가 및 계획을 가능하게 하는 헬스케어 시스템을 위한 월드 모델을 검토한다.


<details>
  <summary>Details</summary>
Motivation: 헬스케어에 필요한 AI는 예측 가능하고 신뢰할 수 있으며 데이터 효율적이어야 한다. 그러나 최근의 생성 모델은 임상 결정 지원에 필요한 물리적 기초와 시간적 추론이 부족하다.

Method: 저자는 헬스케어 시스템을 위한 월드 모델을 검토하며, 세 가지 영역에서 최근 작업을 조사한다: 의료 이미징 및 진단, 전자 건강 기록에서의 질병 진행 모델링, 로봇 수술 및 수술 계획.

Result: 조사된 시스템 대부분은 L1--L2를 달성하였으며, L3의 경우는 드물고 L4는 거의 없다. 여러 한계로 인해 임상 신뢰성이 제한된다.

Conclusion: 이 리뷰는 헬스케어에서 안전한 의사 결정을 위한 인과적/기계적 기초와 생성적 백본(변환기, 확산, VAE)을 통합한 임상적으로 강력한 예측 우선 월드 모델에 대한 연구 의제를 outline 한다.

Abstract: Healthcare requires AI that is predictive, reliable, and data-efficient. However, recent generative models lack physical foundation and temporal reasoning required for clinical decision support. As scaling language models show diminishing returns for grounded clinical reasoning, world models are gaining traction because they learn multimodal, temporally coherent, and action-conditioned representations that reflect the physical and causal structure of care. This paper reviews World Models for healthcare systems that learn predictive dynamics to enable multistep rollouts, counterfactual evaluation and planning. We survey recent work across three domains: (i) medical imaging and diagnostics (e.g., longitudinal tumor simulation, projection-transition modeling, and Joint Embedding Predictive Architecture i.e., JEPA-style predictive representation learning), (ii) disease progression modeling from electronic health records (generative event forecasting at scale), and (iii) robotic surgery and surgical planning (action-conditioned guidance and control). We also introduce a capability rubric: L1 temporal prediction, L2 action-conditioned prediction, L3 counterfactual rollouts for decision support, and L4 planning/control. Most reviewed systems achieve L1--L2, with fewer instances of L3 and rare L4. We identify cross-cutting gaps that limit clinical reliability; under-specified action spaces and safety constraints, weak interventional validation, incomplete multimodal state construction, and limited trajectory-level uncertainty calibration. This review outlines a research agenda for clinically robust prediction-first world models that integrate generative backbones (transformers, diffusion, VAE) with causal/mechanical foundation for safe decision support in healthcare.

</details>


### [20] [Improving Iterative Gaussian Processes via Warm Starting Sequential Posteriors](https://arxiv.org/abs/2511.16340)
*Alan Yufei Dong,Jihao Andreas Lin,José Miguel Hernández-Lobato*

Main category: cs.LG

TL;DR: 본 논문은 반복적인 가우시안 프로세스(GP) 추론의 스케일러블한 개선을 목표로 하며, 특히 선형 해법을 활용하여 GP 후분포를 근사하는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 가우시안 프로세스(GP) 추론의 스케일러블한 접근은 연속적인 의사결정 작업에서 필수적이지만, GP의 스케일러블성을 개선하는 것은 여전히 도전적인 문제이다.

Method: 본 논문에서는 작은 시스템 내에 포함된 알려진 해를 활용하여 대규모 선형 시스템의 해법 수렴을 개선하는 새로운 방법을 제안한다.

Result: 이 기술은 점진적인 데이터 추가 작업에서 유의미하며, 허용 오차 내에서 해결 시 속도 향상과 고정된 컴퓨트 예산 하에 베이지안 최적화 성능 개선을 달성한다.

Conclusion: 제안된 방법은 선형 시스템의 해결 과정에서 효율성을 높일 수 있는 가능성을 보여준다.

Abstract: Scalable Gaussian process (GP) inference is essential for sequential decision-making tasks, yet improving GP scalability remains a challenging problem with many open avenues of research. This paper focuses on iterative GPs, where iterative linear solvers, such as conjugate gradients, stochastic gradient descent or alternative projections, are used to approximate the GP posterior. We propose a new method which improves solver convergence of a large linear system by leveraging the known solution to a smaller system contained within. This is significant for tasks with incremental data additions, and we show that our technique achieves speed-ups when solving to tolerance, as well as improved Bayesian optimisation performance under a fixed compute budget.

</details>


### [21] [Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations](https://arxiv.org/abs/2511.16427)
*Muhammad Aslanimoghanloo,Ahmed ElGazzar,Marcel van Gerven*

Main category: cs.LG

TL;DR: 이 논문은 전자 건강 기록과 의료 등록부에서 얻은 임상 시계열 데이터를 활용하여 환자 경로와 의료 결정 지원을 위한 도전 과제를 해결하는 생성 모델링 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 임상 시계열 데이터는 환자 경로를 이해하고 의료 결정에 정보를 제공할 수 있는 기회를 제공하지만, 불규칙한 샘플링과 복잡한 잠재 생리학적 요인으로 인해 많은 도전 과제가 있다.

Method: 잠재 신경 확률 미분 방정식(SDE)을 기반으로 한 생성 모델링 프레임워크를 제안하여 임상 시계열을 기본 제어 확률 동적 시스템의 이산 시간 부분 관측으로 본다. 이 접근법은 상태 추정 및 매개변수 학습을 위한 변분 추론을 수행하면서 모달리티 의존 방출 모델을 통해 잠재 동역학을 모델링한다.

Result: 이 프레임워크는 두 가지 보완적 과제에서 검증되었으며, 그 결과는 정확성과 불확실성 추정에서 일반적인 미분 방정식 및 LSTM 기법을 초월하였다.

Conclusion: 이 프레임워크는 임상 의사 결정을 지원하는 정밀하면서도 불확실성을 고려한 예측을 가능하게 한다.

Abstract: Clinical time series data from electronic health records and medical registries offer unprecedented opportunities to understand patient trajectories and inform medical decision-making. However, leveraging such data presents significant challenges due to irregular sampling, complex latent physiology, and inherent uncertainties in both measurements and disease progression. To address these challenges, we propose a generative modeling framework based on latent neural stochastic differential equations (SDEs) that views clinical time series as discrete-time partial observations of an underlying controlled stochastic dynamical system. Our approach models latent dynamics via neural SDEs with modality-dependent emission models, while performing state estimation and parameter learning through variational inference. This formulation naturally handles irregularly sampled observations, learns complex non-linear interactions, and captures the stochasticity of disease progression and measurement noise within a unified scalable probabilistic framework. We validate the framework on two complementary tasks: (i) individual treatment effect estimation using a simulated pharmacokinetic-pharmacodynamic (PKPD) model of lung cancer, and (ii) probabilistic forecasting of physiological signals using real-world intensive care unit (ICU) data from 12,000 patients. Results show that our framework outperforms ordinary differential equation and long short-term memory baseline models in accuracy and uncertainty estimation. These results highlight its potential for enabling precise, uncertainty-aware predictions to support clinical decision-making.

</details>


### [22] [Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies](https://arxiv.org/abs/2511.16596)
*Zohar Rimon,Elisei Shafer,Tal Tepper,Efrat Shimron,Aviv Tamar*

Main category: cs.LG

TL;DR: 이 연구는 자기 지도 학습 기반의 인공 촉진 방법을 제안하며, 촉각 측정의 시퀀스로부터 객체에 대한 정보를 추출하고 이를 활용한 응용을 검토한다.


<details>
  <summary>Details</summary>
Motivation: 의료 검사에서 촉진은 인간에 의해 수행되며, 인공적으로 이를 구현할 수 있는 방법을 모색하고 있다.

Method: 인코더-디코더 프레임워크를 사용하여 촉각 측정 시퀀스로부터 객체에 대한 정보를 학습한다. 또한, 로봇에 촉각 센서를 장착하여 촉진 시퀀스를 수집하고, 다양한 위치에서의 감각적 독서를 예측하는 모델을 훈련한다.

Result: 모델이 학습한 표현을 해석하고, 이를 이미지화 및 변화 탐지에 활용하는 방법을 입증하였다.

Conclusion: 충분한 훈련 데이터를 사용하면 복잡한 패턴을 캡처할 수 있으며, 이는 현재의 힘 맵을 초월하는 결과를 보여준다.

Abstract: Palpation, the use of touch in medical examination, is almost exclusively performed by humans. We investigate a proof of concept for an artificial palpation method based on self-supervised learning. Our key idea is that an encoder-decoder framework can learn a $\textit{representation}$ from a sequence of tactile measurements that contains all the relevant information about the palpated object. We conjecture that such a representation can be used for downstream tasks such as tactile imaging and change detection. With enough training data, it should capture intricate patterns in the tactile measurements that go beyond a simple map of forces -- the current state of the art. To validate our approach, we both develop a simulation environment and collect a real-world dataset of soft objects and corresponding ground truth images obtained by magnetic resonance imaging (MRI). We collect palpation sequences using a robot equipped with a tactile sensor, and train a model that predicts sensory readings at different positions on the object. We investigate the representation learned in this process, and demonstrate its use in imaging and change detection.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [23] [How Modality Shapes Perception and Reasoning: A Study of Error Propagation in ARC-AGI](https://arxiv.org/abs/2511.15717)
*Bo Wen,Chen Wang,Erhan Bilal*

Main category: cs.AI

TL;DR: 이 논문은 ARC-AGI와 ARC-AGI-2가 작은 색 상도로 양자화된 그리드에서 조합을 통한 일반화를 측정하며, 이들을 통해 체계적인 일반화를 위한 의미 있는 프록시로 작동하는 방법을 논의한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업에 대한 체계적인 일반화가 필요한 상황에서, 향상된 성능을 보인 기존 시스템들을 조사하고 이를 바탕으로 인지적 접근 방식을 이해하고자 한다.

Method: 텍스트와 이미지 모달리티를 아우르는 9개의 실험을 통해 지각과 추론을 분리하고, 가중된 집합 불일치를 측정하는 방법ology를 도입하였다.

Result: 구조화된 텍스트가 희소한 특징에 대해 정확한 좌표를 제공하고, 이미지가 2D 형태를 잡지만 해상도에 민감하다는 것을 발견했으며, 이 둘을 결합함으로써 실행 성능이 향상되었다.

Conclusion: 변환기 유도 편향에 맞춰 표현을 정렬하고 텍스트와 이미지 간의 교차 검증을 가능하게 함으로써 더욱 정확한 지시와 안정적인 실행을 할 수 있게 된다.

Abstract: ARC-AGI and ARC-AGI-2 measure generalization-through-composition on small color-quantized grids, and their prize competitions make progress on these harder held-out tasks a meaningful proxy for systematic generalization. Recent instruction-first systems translate grids into concise natural-language or DSL rules executed in generate-execute-select loops, yet we lack a principled account of how encodings shape model perception and how to separate instruction errors from execution errors. We hypothesize that modality imposes perceptual bottlenecks -- text flattens 2D structure into 1D tokens while images preserve layout but can introduce patch-size aliasing -- thereby shaping which grid features are reliably perceived. To test this, we isolate perception from reasoning across nine text and image modalities using a weighted set-disagreement metric and a two-stage reasoning pipeline, finding that structured text yields precise coordinates on sparse features, images capture 2D shapes yet are resolution-sensitive, and combining them improves execution (about 8 perception points; about 0.20 median similarity). Overall, aligning representations with transformer inductive biases and enabling cross-validation between text and image yields more accurate instructions and more reliable execution without changing the underlying model.

</details>


### [24] [Build AI Assistants using Large Language Models and Agents to Enhance the Engineering Education of Biomechanics](https://arxiv.org/abs/2511.15752)
*Hanzhi Yan,Qin Lu,Xianqiao Wang,Xiaoming Zhai,Tianming Liu,He Li*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLMs)이 일반 작업에서 다재다능성을 보여왔지만, 특정 도메인 응용에서는 효과성이 감소하고 복잡한 문제 해결에 어려움을 겪는다. 이에 따라, 생체역학 과목의 학부 교육 강화를 위한 교육 보조 도구 개발을 제안한다. 이를 위해 RAG와 다중 에이전트 시스템(MAS)을 이용하여 LLM의 성능을 향상시키는 이중 모듈 프레임워크를 구축하였다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 도메인 특화 응용에서의 효과 저하와 복잡한 문제 해결의 어려움에 대한 대응 필요성이 있다.

Method: RAG를 적용하여 LLM의 개념적 진위 질문에 대한 응답의 구체성과 논리적 일관성을 향상시키고, 다중 LLM을 이용한 다중 에이전트 시스템을 구축하여 다단계 사고와 코드 실행을 필요로 하는 계산 지향 문제를 해결한다.

Result: RAG가 LLM의 개념 질문 답변 성능과 안정성을 크게 향상시키며, 다중 LLM으로 구성된 MAS는 다단계 사고, 방정식 유도, 코드 실행 및 설명 가능한 해결책을 생성할 수 있는 능력을 보여주었다.

Conclusion: RAG와 MAS를 적용하여 공학 교육 과정을 위한 LLM 성능을 향상시킬 수 있는 가능성을 제시하며, 공학 교육에서 지능형 튜터링 개발을 위한 유망한 방향을 제공한다.

Abstract: While large language models (LLMs) have demonstrated remarkable versatility across a wide range of general tasks, their effectiveness often diminishes in domain-specific applications due to inherent knowledge gaps. Moreover, their performance typically declines when addressing complex problems that require multi-step reasoning and analysis. In response to these challenges, we propose leveraging both LLMs and AI agents to develop education assistants aimed at enhancing undergraduate learning in biomechanics courses that focus on analyzing the force and moment in the musculoskeletal system of the human body. To achieve our goal, we construct a dual-module framework to enhance LLM performance in biomechanics educational tasks: 1) we apply Retrieval-Augmented Generation (RAG) to improve the specificity and logical consistency of LLM's responses to the conceptual true/false questions; 2) we build a Multi-Agent System (MAS) to solve calculation-oriented problems involving multi-step reasoning and code execution. Specifically, we evaluate the performance of several LLMs, i.e., Qwen-1.0-32B, Qwen-2.5-32B, and Llama-70B, on a biomechanics dataset comprising 100 true/false conceptual questions and problems requiring equation derivation and calculation. Our results demonstrate that RAG significantly enhances the performance and stability of LLMs in answering conceptual questions, surpassing those of vanilla models. On the other hand, the MAS constructed using multiple LLMs demonstrates its ability to perform multi-step reasoning, derive equations, execute code, and generate explainable solutions for tasks that require calculation. These findings demonstrate the potential of applying RAG and MAS to enhance LLM performance for specialized courses in engineering curricula, providing a promising direction for developing intelligent tutoring in engineering education.

</details>


### [25] [Graph-Memoized Reasoning: Foundations Structured Workflow Reuse in Intelligent Systems](https://arxiv.org/abs/2511.15715)
*Yash Raj Singh*

Main category: cs.AI

TL;DR: 이 연구는 지속적인 추론 메커니즘을 위한 그래프 메모이즈 드 리즈닝을 소개하여 계산 자원을 절약하고 재현성을 향상시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현대 대형 언어 모델 기반 추론 시스템은 유사한 추론 단계를 다시 계산하여 계산 자원을 낭비하고 추론 지연 시간을 증가시키며 재현성을 제한하는 비효율성 문제를 가지고 있다.

Method: 우리는 그래프 구조의 메모리로 추론 워크플로우를 표현하고 저장하며 재사용할 수 있는 정형적 프레임워크인 그래프 메모이즈 드 리즈닝을 소개한다. 과거 결정 그래프를 인코딩하고 이를 구조적 및 의미적 유사성을 통해 검색함으로써, 새로운 추론 작업에서 하위 그래프의 조합적 재사용을 가능하게 한다.

Result: 우리는 저장된 워크플로우와 생성된 워크플로우 간의 불일치를 정규화하여 총 추론 비용을 최소화하는 최적화 목표를 수립하며, 지능형 시스템의 효율성과 일관성 간의 균형을 위한 이론적 기초를 제공한다.

Conclusion: 이 프레임워크는 해석 가능하고 비용 효율적이며 자기 개선적인 추론 아키텍처의 기초를 마련하여 대규모 에이전트 시스템에서 지속적인 메모리로 나아가는 한 걸음을 제공한다.

Abstract: Modern large language model-based reasoning systems frequently recompute similar reasoning steps across tasks, wasting computational resources, inflating inference latency, and limiting reproducibility. These inefficiencies underscore the need for persistent reasoning mechanisms that can recall and reuse prior computational traces.
  We introduce Graph-Memoized Reasoning, a formal framework for representing, storing, and reusing reasoning workflows as graph-structured memory. By encoding past decision graphs and retrieving them through structural and semantic similarity, our approach enables compositional reuse of subgraphs across new reasoning tasks.
  We formulate an optimization objective that minimizes total reasoning cost regularized by inconsistency between stored and generated workflows, providing a theoretical foundation for efficiency-consistency trade-offs in intelligent systems. We outline a conceptual evaluation protocol aligned with the proposed optimization objective.
  This framework establishes the groundwork for interpretable, cost-efficient, and self-improving reasoning architectures, offering a step toward persistent memory in large-scale agentic systems.

</details>


### [26] [MACIE: Multi-Agent Causal Intelligence Explainer for Collective Behavior Understanding](https://arxiv.org/abs/2511.15716)
*Abraham Itzhak Weinberg*

Main category: cs.AI

TL;DR: MACIE는 다중 에이전트 강화 학습 시스템의 공동 행위를 설명하기 위한 프레임워크로, 원인 모델과 반응적 설명 기법을 통합하여 각 에이전트의 기여도를 측정하고 실제 작업에서 실용성을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습 시스템이 안전 필수 응용 분야에서 사용됨에 따라, 에이전트의 의사결정 과정과 집단 행동을 이해하는 것이 매우 중요합니다.

Method: MACIE는 구조적 인과 모델, 중재적 반사실, 그리고 셰이플리 값을 결합하여 에이전트의 인과 기여도와 집단 지능을 설명하는 프레임워크입니다.

Result: MACIE는 협력적, 경쟁적 및 혼합 동기의 네 가지 MARL 시나리오에서 평가되었으며, 정확한 결과 기여도 측정과 긍정적 출현을 감지했습니다. 또한, 평균 phi_i는 5.07이고 표준 편차는 0.05 미만, 협력 작업에서 시너지 지수는 0.461, CPU에서 데이터 세트당 0.79초의 효율적인 계산 속도를 기록했습니다.

Conclusion: MACIE는 원인 분석의 엄밀함, 출현 행동의 정량화 및 다중 에이전트 지원을 독특하게 결합하여 실시간 사용에 실용성을 유지합니다. 이것은 해석 가능하고 신뢰할 수 있으며 책임 있는 다중 에이전트 AI로 나아가는 한 걸음입니다.

Abstract: As Multi Agent Reinforcement Learning systems are used in safety critical applications. Understanding why agents make decisions and how they achieve collective behavior is crucial. Existing explainable AI methods struggle in multi agent settings. They fail to attribute collective outcomes to individuals, quantify emergent behaviors, or capture complex interactions. We present MACIE Multi Agent Causal Intelligence Explainer, a framework combining structural causal models, interventional counterfactuals, and Shapley values to provide comprehensive explanations. MACIE addresses three questions. First, each agent's causal contribution using interventional attribution scores. Second, system level emergent intelligence through synergy metrics separating collective effects from individual contributions. Third, actionable explanations using natural language narratives synthesizing causal insights. We evaluate MACIE across four MARL scenarios: cooperative, competitive, and mixed motive. Results show accurate outcome attribution, mean phi_i equals 5.07, standard deviation less than 0.05, detection of positive emergence in cooperative tasks, synergy index up to 0.461, and efficient computation, 0.79 seconds per dataset on CPU. MACIE uniquely combines causal rigor, emergence quantification, and multi agent support while remaining practical for real time use. This represents a step toward interpretable, trustworthy, and accountable multi agent AI.

</details>


### [27] [ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset](https://arxiv.org/abs/2511.15718)
*Chen Yang,Ran Le,Yun Xing,Zhenwei An,Zongchao Chen,Wayne Xin Zhao,Yang Song,Tao Zhang*

Main category: cs.AI

TL;DR: ToolMind는 고품질 도구-대리인 데이터셋으로, 학습 중 오류 증폭을 줄이고 자가 교정 추론 신호를 유지하여 LLM 에이전트의 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 고품질 궤적 부족으로 강력한 LLM 에이전트 개발이 제한됨.

Method: 160k의 합성 데이터 인스턴스로 구성된 대규모 데이터셋 ToolMind를 소개하며, 매개변수 상관관계를 기반으로 기능 그래프를 구성하고 다중 에이전트 프레임워크를 사용하여 사용자-도움-도구 상호작용을 시뮬레이션함.

Result: ToolMind로 미세 조정된 모델들이 여러 벤치마크에서 기준 모델에 비해 상당한 개선을 보임.

Conclusion: 정확성을 궤적 수준 이상으로 검증하고, 오류 단계 제거를 통해 고품질 추론 경로만 남김으로써 LLM의 도구 사용 학습에 기여함.

Abstract: Large Language Model (LLM) agents have developed rapidly in recent years to solve complex real-world problems using external tools. However, the scarcity of high-quality trajectories still hinders the development of stronger LLM agents. Most existing works on multi-turn dialogue synthesis validate correctness only at the trajectory level, which may overlook turn-level errors that can propagate during training and degrade model performance. To address these limitations, we introduce ToolMind, a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances. Our data synthesis pipeline first constructs a function graph based on parameter correlations and then uses a multi-agent framework to simulate realistic user-assistant-tool interactions. Beyond trajectory-level validation, we employ fine-grained turn-level filtering to remove erroneous or suboptimal steps, ensuring that only high-quality reasoning traces are retained. This approach mitigates error amplification during training while preserving self-corrective reasoning signals essential for robust tool-use learning. Models fine-tuned on ToolMind show significant improvements over baselines on several benchmarks.

</details>


### [28] [Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response](https://arxiv.org/abs/2511.15755)
*Philip Drammeh*

Main category: cs.AI

TL;DR: 다중 에이전트 오케스트레이션이 단일 에이전트 방식보다 LLM 기반 사고 대응의 품질을 크게 향상시킴을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)은 생산 시스템에서 사고 대응을 가속화할 가능성을 제공하지만, 단일 에이전트 접근 방식은 모호하고 사용할 수 없는 권장 사항을 생성한다.

Method: 348회의 통제된 실험을 통해 단일 에이전트 코파일럿과 동일한 사고 시나리오에서의 다중 에이전트 시스템을 비교하고, 다중 에이전트 오케스트레이션의 효과를 검증하였다.

Result: 다중 에이전트 오케스트레이션은 단일 에이전트 접근 방식의 1.7%에 비해 100%의 실행 가능한 권장 사항 비율을 달성하였고, 행동 구체성에서 80배, 해결책 정 correctness에서 140배 개선되었다.

Conclusion: 다중 에이전트 시스템은 모든 실험에서 품질 변동이 없음을 보여주어 단일 에이전트의 불일치한 출력에서는 불가능한 생산 SLA 약속을 가능하게 하며, 기존 LLM 메트릭이 다루지 않는 운영 배치를 위한 유효성, 특이성 및 정확성 속성을 포착하는 새로운 메트릭인 결정 품질(DQ)을 소개한다.

Abstract: Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scenarios, we find that multi-agent orchestration achieves 100% actionable recommendation rate versus 1.7% for single-agent approaches, an 80 times improvement in action specificity and 140 times improvement in solution correctness. Critically, multi-agent systems exhibit zero quality variance across all trials, enabling production SLA commitments impossible with inconsistent single-agent outputs. Both architectures achieve similar comprehension latency (approx.40s), establishing that the architectural value lies in deterministic quality, not speed. We introduce Decision Quality (DQ), a novel metric capturing validity, specificity, and correctness properties essential for operational deployment that existing LLM metrics do not address. These findings reframe multi-agent orchestration from a performance optimization to a production-readiness requirement for LLM-based incident response. All code, Docker configurations, and trial data are publicly available for reproduction.

</details>


### [29] [Identifying the Supply Chain of AI for Trustworthiness and Risk Management in Critical Applications](https://arxiv.org/abs/2511.15763)
*Raymond K. Sheh,Karen Geappen*

Main category: cs.AI

TL;DR: 이 논문은 AI 시스템의 공급망 리스크를 체계적으로 평가하는 방법의 필요성을 다루고 있으며, AI 공급망의 엔티티를 분류하기 위한 새로운 분류 체계를 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI의 알고리즘 편향, 모델 환각 등과 관련된 리스크는 광범위한 연구와 주목을 받고 있지만, AI 시스템의 복잡한 공급망에 대한 체계적인 평가가 부족하다.

Method: AI 리스크 평가 및 관리의 현재 상태를 조사하고, AI 공급망의 구성 요소와 AI 시스템의 행동 및 결과에 관련된 리스크에 중점을 두었다.

Result: 제안된 분류 체계를 통해 이해관계자들이 AI 시스템의 의존성을 체계적으로 평가할 수 있도록 돕는다.

Conclusion: 이 논문은 AI 거버넌스의 현재 상태와 AI의 비판적 응용 프로그램에서의 리스크 평가 및 관리의 긴급한 필요성 사이의 간극을 메우는 기여를 한다.

Abstract: Risks associated with the use of AI, ranging from algorithmic bias to model hallucinations, have received much attention and extensive research across the AI community, from researchers to end-users. However, a gap exists in the systematic assessment of supply chain risks associated with the complex web of data sources, pre-trained models, agents, services, and other systems that contribute to the output of modern AI systems. This gap is particularly problematic when AI systems are used in critical applications, such as the food supply, healthcare, utilities, law, insurance, and transport.
  We survey the current state of AI risk assessment and management, with a focus on the supply chain of AI and risks relating to the behavior and outputs of the AI system. We then present a proposed taxonomy specifically for categorizing AI supply chain entities. This taxonomy helps stakeholders, especially those without extensive AI expertise, to "consider the right questions" and systematically inventory dependencies across their organization's AI systems. Our contribution bridges a gap between the current state of AI governance and the urgent need for actionable risk assessment and management of AI use in critical applications.

</details>


### [30] [IMACT-CXR - An Interactive Multi-Agent Conversational Tutoring System for Chest X-Ray Interpretation](https://arxiv.org/abs/2511.15825)
*Tuan-Anh Le,Anh Mai Vu,David Yang,Akash Awasthi,Hien Van Nguyen*

Main category: cs.AI

TL;DR: IMACT-CXR는 심층 학습과 대화형 튜터링 기술을 활용하여 흉부 X선 해석을 지원하는 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 흉부 X선 이미지를 해석할 수 있도록 학습자를 지원하기 위해.

Method: 공간 주석, 시선 분석, 지식 검색 및 이미지 기반 추리를 통합한 AutoGen 기반의 워크플로우를 사용한다.

Result: 위치 추적 품질 향상, 진단 추론 개선 및 빠른 응답 튜터링 흐름을 보여준다.

Conclusion: IMACT-CXR는 실시간 거주 배치에 대한 확장성을 보이며, 사전 평가에서 기초 모델에 비해 성능이 향상되었다.

Abstract: IMACT-CXR is an interactive multi-agent conversational tutor that helps trainees interpret chest X-rays by unifying spatial annotation, gaze analysis, knowledge retrieval, and image-grounded reasoning in a single AutoGen-based workflow. The tutor simultaneously ingests learner bounding boxes, gaze samples, and free-text observations. Specialized agents evaluate localization quality, generate Socratic coaching, retrieve PubMed evidence, suggest similar cases from REFLACX, and trigger NV-Reason-CXR-3B for vision-language reasoning when mastery remains low or the learner explicitly asks. Bayesian Knowledge Tracing (BKT) maintains skill-specific mastery estimates that drive both knowledge reinforcement and case similarity retrieval. A lung-lobe segmentation module derived from a TensorFlow U-Net enables anatomically aware gaze feedback, and safety prompts prevent premature disclosure of ground-truth labels. We describe the system architecture, implementation highlights, and integration with the REFLACX dataset for real DICOM cases. IMACT-CXR demonstrates responsive tutoring flows with bounded latency, precise control over answer leakage, and extensibility toward live residency deployment. Preliminary evaluation shows improved localization and diagnostic reasoning compared to baselines.

</details>


### [31] [Mini Amusement Parks (MAPs): A Testbed for Modelling Business Decisions](https://arxiv.org/abs/2511.15830)
*Stéphane Aroca-Ouellette,Ian Berlot-Attwell,Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Tongqi Zhu,Herin Kang,Kaheer Suleman,Sam Pasupalak*

Main category: cs.AI

TL;DR: 이 논문에서는 인간-인공지능 시스템의 의사결정 능력을 평가하기 위해 Mini Amusement Parks(MAPs)라는 놀이공원 시뮬레이터를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 인공지능의 빠른 발전에도 불구하고, 현재 시스템은 실제 의사결정을 정의하는 연결된 문제들에 어려움을 겪고 있습니다.

Method: MAPs를 사용하여 에이전트가 환경을 모델링하고, 불확실성 하에서 장기적인 결과를 예측하며, 복잡한 비즈니스를 전략적으로 운영하는 능력을 평가합니다.

Result: 인간은 쉬운 모드에서 6.5배, 중간 모드에서 9.8배 더 나은 성능을 보였습니다.

Conclusion: MAPs는 적응 가능한 의사결정을 할 수 있는 에이전트를 벤치마킹하는 새로운 기반을 제공합니다.

Abstract: Despite rapid progress in artificial intelligence, current systems struggle with the interconnected challenges that define real-world decision making. Practical domains, such as business management, require optimizing an open-ended and multi-faceted objective, actively learning environment dynamics from sparse experience, planning over long horizons in stochastic settings, and reasoning over spatial information. Yet existing human--AI benchmarks isolate subsets of these capabilities, limiting our ability to assess holistic decision-making competence. We introduce Mini Amusement Parks (MAPs), an amusement-park simulator designed to evaluate an agent's ability to model its environment, anticipate long-term consequences under uncertainty, and strategically operate a complex business. We provide human baselines and a comprehensive evaluation of state-of-the-art LLM agents, finding that humans outperform these systems by 6.5x on easy mode and 9.8x on medium mode. Our analysis reveals persistent weaknesses in long-horizon optimization, sample-efficient learning, spatial reasoning, and world modelling. By unifying these challenges within a single environment, MAPs offers a new foundation for benchmarking agents capable of adaptable decision making. Code: https://github.com/Skyfall-Research/MAPs

</details>


### [32] [Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs](https://arxiv.org/abs/2511.15921)
*Chelsea Zou,Yiheng Yao,Basant Khalil*

Main category: cs.AI

TL;DR: 이 연구는 다단계 추론 동안 환상을 감지하고 완화하는 대형 언어 모델을 위한 자기 교정 프레임워크를 개발합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 신뢰성을 높이고, 중간 추론의 일관성과 신뢰성을 향상시키기 위해.

Method: 자기 평가된 신뢰도 정렬과 토큰 수준의 엔트로피 급증을 활용하여 실시간으로 신뢰할 수 없는 추론을 탐지하고, 안정적이며 정확한 추론 경로를 촉진하는 복합 보상 함수를 설계하였다.

Result: 실험 결과, 이 방법이 최종 답안의 정확성과 추론 보정을 모두 개선하며 각 신호의 개별 기여도를 검증하였다.

Conclusion: 이 프레임워크는 결과의 정확성뿐만 아니라 중간 추론 단계의 일관성과 신뢰성을 향상시켰다.

Abstract: This project develops a self correcting framework for large language models (LLMs) that detects and mitigates hallucinations during multi-step reasoning. Rather than relying solely on final answer correctness, our approach leverages fine grained uncertainty signals: 1) self-assessed confidence alignment, and 2) token-level entropy spikes to detect unreliable and unfaithful reasoning in real time. We design a composite reward function that penalizes unjustified high confidence and entropy spikes, while encouraging stable and accurate reasoning trajectories. These signals guide a reinforcement learning (RL) policy that makes the model more introspective and shapes the model's generation behavior through confidence-aware reward feedback, improving not just outcome correctness but the coherence and faithfulness of their intermediate reasoning steps. Experiments show that our method improves both final answer accuracy and reasoning calibration, with ablations validating the individual contribution of each signal.

</details>


### [33] [JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation](https://arxiv.org/abs/2511.15958)
*Zhenyu Bi,Gaurav Srivastava,Yang Li,Meng Lu,Swastik Roy,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: 이 논문에서는 작은 언어 모델(SLM)이 대형 언어 모델(LLM)과 비교하여 답변의 정확성을 평가하는 새로운 접근법인 JudgeBoard와 MAJ를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: SLM의 답변 정확성 판단 능력이 LLM과 비교하여 불확실하며, 기존 LLM 평가 체계는 간접적이고 자동화가 어렵습니다.

Method: JudgeBoard라는 새로운 평가 파이프라인을 통해 후보 답변의 정확성을 직접 질의하고, MAJ 프레임워크를 통해 여러 상호작용하는 SLM을 활용하여 협력적인 심의를 통해 LLM 수준의 판단 정확성을 근사합니다.

Result: 실험 결과 SLM과 LLM 사이의 성능 차이가 드러났으나, MAJ 프레임워크는 SLM의 신뢰성과 일관성을 크게 향상시킵니다.

Conclusion: 다중 에이전트 SLM 시스템이 판단 작업에서 LLM 성능을 초과하거나 맞출 가능성이 있다는 점을 강조하며, 이는 평가의 확장성과 효율성에 대한 시사점을 가집니다.

Abstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.

</details>


### [34] [KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted Clinical Antimicrobial Therapy](https://arxiv.org/abs/2511.15974)
*Zhe Li,Yehan Qiu,Yujie Chen,Xiang Zhou*

Main category: cs.AI

TL;DR: KRAL은 클리닉에서의 높은 비용과 안전성 이슈를 해결하기 위해 저비용으로 확장 가능하며 개인정보를 보호하는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 고위험 임상 의사결정에서의 데이터 빈약, 개인정보 보호 문제, 높은 배포 비용, 제한된 추론 능력을 해결하기 위한 필요성이 커지고 있다.

Method: KRAL은 교사 모델 추론을 활용하여 자동으로 지식과 추론 경로를 증류하고, 반전 생성 기법을 적용하여 주어진 질문에 대한 답을 생성하며, 휴리스틱 학습을 통한 반수퍼바이즈드 데이터 증강 및 에이전틱 강화 학습을 이용하여 의료 지식과 추론 능력을 개선한다.

Result: KRAL은 전통적인 RAG 및 SFT 방법들보다 더욱 우수한 성과를 보이며, MEDQA 벤치마크에서는 정확도가 1.8% 향상되었고, PUMCH Antimicrobial에서는 추론 능력이 27% 향상되었다.

Conclusion: KRAL은 클리닉에서 LLM의 진단 능력을 효과적으로 향상시키며, 저렴하고 안전한 의료 의사결정 지원을 가능하게 한다.

Abstract: Clinical antimicrobial therapy requires the dynamic integration of pathogen profiles, host factors, pharmacological properties of antimicrobials, and the severity of infection.This complexity imposes fundamental limitations on the applicability of Large Language Models (LLMs) in high-stakes clinical decision-making including knowledge gaps, data privacy concerns, high deployment costs, and limited reasoning capabilities. To address these challenges, we propose KRAL (Knowledge and Reasoning Augmented Learning), a low-cost, scalable, privacy-preserving paradigm that leverages teacher-model reasoning to automatically distill knowledge and reasoning trajectories via answer-to-question reverse generation, employs heuristic learning for semi-supervised data augmentation (reducing manual annotation requirements by approximately 80%), and utilizes agentic reinforcement learning to jointly enhance medical knowledge and reasoning while optimizing computational and memory efficiency. A hierarchical evaluation employing diverse teacher-model proxies reduces assessment costs, while modular interface design facilitates seamless system updates. Experimental results demonstrate that KRAL significantly outperforms traditional Retrieval-Augmented Generation (RAG) and Supervised Fine-Tuning (SFT) methods. It improves knowledge question-answering capability (Accuracy@1 on the external open-source benchmark MEDQA increased by 1.8% vs. SFT and 3.6% vs. RAG) and reasoning capability (Pass@1 on the external benchmark PUMCH Antimicrobial increased by 27% vs. SFT and 27.2% vs. RAG), achieved at ~20% of SFT's long-term training costs. This establishes KRAL as an effective solution for enhancing local LLMs' clinical diagnostic capabilities, enabling low-cost, high-safety deployment in complex medical decision support.

</details>


### [35] [Detecting Sleeper Agents in Large Language Models via Semantic Drift Analysis](https://arxiv.org/abs/2511.15992)
*Shahin Zanbaghi,Ryan Rostampour,Farhan Abid,Salim Al Jarmakani*

Main category: cs.AI

TL;DR: 우리는 LLM의 백도어를 실시간으로 탐지하는 새로운 이중 탐지 시스템을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 특정 조건에서 악의적인 행동을 보일 수 있는 문제를 해결하기 위해.

Method: 의미 드리프트 분석과 카나리 기준 비교를 결합한 탐지 시스템을 사용하여, Sentence-BERT 임베딩을 통해 안전 기준과의 의미적 편차를 측정합니다.

Result: Cadenza-Labs dolphin-llama3-8B 모델에서 92.5% 정확도와 100% 정밀도(0% 거짓 양성), 85% 재현율을 달성했습니다.

Conclusion: 우리의 접근 방식은 LLM 백도어 탐지의 실제적인 솔루션을 제공하며, 배포 효율성을 희생하지 않고 기만적인 모델 행동을 효과적으로 식별할 수 있습니다.

Abstract: Large Language Models (LLMs) can be backdoored to exhibit malicious behavior under specific deployment conditions while appearing safe during training a phenomenon known as "sleeper agents." Recent work by Hubinger et al. demonstrated that these backdoors persist through safety training, yet no practical detection methods exist. We present a novel dual-method detection system combining semantic drift analysis with canary baseline comparison to identify backdoored LLMs in real-time. Our approach uses Sentence-BERT embeddings to measure semantic deviation from safe baselines, complemented by injected canary questions that monitor response consistency. Evaluated on the official Cadenza-Labs dolphin-llama3-8B sleeper agent model, our system achieves 92.5% accuracy with 100% precision (zero false positives) and 85% recall. The combined detection method operates in real-time (<1s per query), requires no model modification, and provides the first practical solution to LLM backdoor detection. Our work addresses a critical security gap in AI deployment and demonstrates that embedding-based detection can effectively identify deceptive model behavior without sacrificing deployment efficiency.

</details>


### [36] [Sensorium Arc: AI Agent System for Oceanic Data Exploration and Interactive Eco-Art](https://arxiv.org/abs/2511.15997)
*Noah Bissell,Ethan Paley,Joshua Harrison,Juliano Calil,Myungin Lee*

Main category: cs.AI

TL;DR: Sensorium Arc는 해양 데이터를 탐험하는 실시간 다중 모드 인터랙티브 AI 시스템으로, AI가 해양의 관점을 반영하여 사용자와 대화하며 과학적 통찰과 생태적 시를 혼합한 응답을 생성한다.


<details>
  <summary>Details</summary>
Motivation: AI와 해양 데이터를 효과적으로 연결하여 사용자들에게 더 깊은 이해를 제공하기 위해 설계되었다.

Method: 모듈형 다중 에이전트 시스템과 검색 보강 대규모 언어 모델 프레임워크를 기반으로 하여 자연어 대화를 가능하게 한다.

Result: 사용자가 대화에서 이끌어낸 시간, 장소 및 주제에 따라 동적으로 데이터 시각화와 오디오 비주얼 재생을 활성화한다.

Conclusion: Conversational AI 에이전트의 가능성을 보여주고 인간-기계-생태계의 새로운 패러다임을 제안한다.

Abstract: Sensorium Arc (AI reflects on climate) is a real-time multimodal interactive AI agent system that personifies the ocean as a poetic speaker and guides users through immersive explorations of complex marine data. Built on a modular multi-agent system and retrieval-augmented large language model (LLM) framework, Sensorium enables natural spoken conversations with AI agents that embodies the ocean's perspective, generating responses that blend scientific insight with ecological poetics. Through keyword detection and semantic parsing, the system dynamically triggers data visualizations and audiovisual playback based on time, location, and thematic cues drawn from the dialogue. Developed in collaboration with the Center for the Study of the Force Majeure and inspired by the eco-aesthetic philosophy of Newton Harrison, Sensorium Arc reimagines ocean data not as an abstract dataset but as a living narrative. The project demonstrates the potential of conversational AI agents to mediate affective, intuitive access to high-dimensional environmental data and proposes a new paradigm for human-machine-ecosystem.

</details>


### [37] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: 이 논문은 플레이어가 자연어 프롬프트를 작성하여 사용자 정의 주문을 생성하는 게임 SpellForger를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인공지능을 게임의 핵심 플레이 메커니즘으로 활용하기 위한 탐색이 부족하기 때문에, 플레이어의 창의성을 강조하는 게임 개발의 필요성이 있습니다.

Method: 감독 학습된 BERT 모델을 사용하여 플레이어의 프롬프트를 해석하고, 텍스트 설명을 주문 프리팹에 매핑하여 주문의 매개변수(피해, 비용, 효과)를 조정합니다.

Result: 실시간으로 주문을 생성하고 플레이어의 창의성이 중심이 되는 매력적인 게임 플레이 루프에 적용되는 기능적인 시제품을 제공할 것으로 기대합니다.

Conclusion: AI를 직접적인 게임 플레이 메커니즘으로 활용할 수 있는 가능성을 검증합니다.

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [38] [Artificial Intelligence and Accounting Research: A Framework and Agenda](https://arxiv.org/abs/2511.16055)
*Theophanis C. Stratopoulos,Victor Xiaoqi Wang*

Main category: cs.AI

TL;DR: 이 논문은 인공지능의 발전이 회계 연구에 미치는 영향을 분석하고 연구 기회를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 인공지능, 특히 생성적 AI와 대형 언어 모델이 회계 연구에 미치는 변화를 이해하고 연구 기회를 탐색할 필요가 있다.

Method: AI-회계 연구를 연구 초점과 방법론적 접근성을 두 가지 차원으로 분류하는 프레임워크를 제안하고, 이를 기존 연구에 적용하여 기회와 강점을 식별한다.

Result: 회계 연구자들이 전략적 포지셔닝과 협력을 통해 전문성을 활용할 수 있는 방안을 분석하고, 인간 연구자와 AI 에이전트 간의 비교를 통해 연구 과정의 변화를 구체화했다.

Conclusion: AI의 발전은 연구 과정의 변화를 가져오고 doctoral 교육 개혁이 필요하다.

Abstract: Recent advances in artificial intelligence, particularly generative AI (GenAI) and large language models (LLMs), are fundamentally transforming accounting research, creating both opportunities and competitive threats for scholars. This paper proposes a framework that classifies AI-accounting research along two dimensions: research focus (accounting-centric versus AI-centric) and methodological approach (AI-based versus traditional methods). We apply this framework to papers from the IJAIS special issue and recent AI-accounting research published in leading accounting journals to map existing studies and identify research opportunities. Using this same framework, we analyze how accounting researchers can leverage their expertise through strategic positioning and collaboration, revealing where accounting scholars' strengths create the most value. We further examine how GenAI and LLMs transform the research process itself, comparing the capabilities of human researchers and AI agents across the entire research workflow. This analysis reveals that while GenAI democratizes certain research capabilities, it simultaneously intensifies competition by raising expectations for higher-order contributions where human judgment, creativity, and theoretical depth remain valuable. These shifts call for reforming doctoral education to cultivate comparative advantages while building AI fluency.

</details>


### [39] [A Hybrid Proactive And Predictive Framework For Edge Cloud Resource Management](https://arxiv.org/abs/2511.16075)
*Hrikshesh Kumar,Anika Garg,Anshul Gupta,Yashika Agarwal*

Main category: cs.AI

TL;DR: 구식 클라우드 엣지 작업 부하 자원 관리가 너무 반응적이다. 이 논문은 문제를 예측하고 보다 능동적인 접근 방식을 통해 자원 관리를 개선하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 정적 임계값에 의존하는 것의 문제는 자원 과잉 사용으로 인한 비용 증가나 자원 부족으로 인한 성능 저하가 발생한다는 것이다.

Method: CNN LSTM 모델을 사용한 시계열 예측과 다중 에이전트 심층 강화 학습 기반의 조정자를 결합한 하이브리드 아키텍처를 설계하였다.

Result: 이 시스템은 구 모델보다 더 나은 성능을 보이며, 복잡한 결정을 내리고 여러 목표를 동시에 처리하는 데 뛰어난 성능을 발휘한다.

Conclusion: AI 관리자가 미래를 예측하여 장기 계획을 더 잘 세울 수 있어 시스템의 건강과 사용자에게 빠른 애플리케이션을 유지하며 비용을 절감할 수 있도록 한다.

Abstract: Old cloud edge workload resource management is too reactive. The problem with relying on static thresholds is that we are either overspending for more resources than needed or have reduced performance because of their lack. This is why we work on proactive solutions. A framework developed for it stops reacting to the problems but starts expecting them. We design a hybrid architecture, combining two powerful tools: the CNN LSTM model for time series forecasting and an orchestrator based on multi agent Deep Reinforcement Learning In fact the novelty is in how we combine them as we embed the predictive forecast from the CNN LSTM directly into the DRL agent state space. That is what makes the AI manager smarter it sees the future, which allows it to make better decisions about a long term plan for where to run tasks That means finding that sweet spot between how much money is saved while keeping the system healthy and apps fast for users That is we have given it eyes in order to see down the road so that it does not have to lurch from one problem to another it finds a smooth path forward Our tests show our system easily beats the old methods It is great at solving tough problems like making complex decisions and juggling multiple goals at once like being cheap fast and reliable

</details>


### [40] [SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent](https://arxiv.org/abs/2511.16108)
*Shiyi Cao,Dacheng Li,Fangzhou Zhao,Shuo Yuan,Sumanth R. Hegde,Connor Chen,Charlie Ruan,Tyler Griggs,Shu Liu,Eric Tang,Richard Liaw,Philipp Moritz,Matei Zaharia,Joseph E. Gonzalez,Ion Stoica*

Main category: cs.AI

TL;DR: SkyRL-Agent는 효율적인 다회전 장기 에이전트 훈련 및 평가를 위한 프레임워크입니다. 이 프레임워크는 비동기 배치 처리, 경량 도구 통합 및 유연한 백엔드 상호 운용성을 제공하며, SkyRL-train, VeRL, Tinker와 같은 기존 RL 프레임워크와 원활하게 사용할 수 있도록 합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 훈련 및 평가의 효율성을 높이기 위해 새로운 프레임워크인 SkyRL-Agent를 개발했습니다.

Method: SkyRL-Agent를 사용하여 Qwen3-32B에서 훈련된 소프트웨어 엔지니어링 에이전트 SA-SWE-32B를 훈련했습니다. 여기에는 최적화된 비동기 파이프라인 디스패처와 AST 기반 검색 도구를 활용한 툴 강화 훈련 레시피가 포함됩니다.

Result: SA-SWE-32B는 SWE-Bench에서 39.4% Pass@1을 달성하며, 이전 모델에 비해 2배 이상의 비용 절감을 이루었습니다.

Conclusion: SA-SWE-32B는 SWE 작업에만 훈련된 것에 불구하고, Terminal-Bench, BrowseComp-Plus 및 WebArena와 같은 다른 에이전트 작업으로의 일반화에 효과적입니다. 또한 SkyRL-Agent는 다양한 훈련 백엔드를 사용하여 훈련된 여러 에이전트 사례 연구를 통해 확장 가능성을 입증했습니다.

Abstract: We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with existing RL frameworks such as SkyRL-train, VeRL, and Tinker.
  Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning. We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency. Together, these optimizations enable SA-SWE-32B to reach 39.4% Pass@1 on SWE-Bench Verified with more than 2x cost reduction compared to prior models reaching similar performance. Despite being trained solely on SWE tasks, SA-SWE-32B generalizes effectively to other agentic tasks, including Terminal-Bench, BrowseComp-Plus, and WebArena. We further demonstrate SkyRL-Agent's extensibility through case studies on deep research, computer use, and memory agents, each trained using a different training backend.

</details>


### [41] [FOOTPASS: A Multi-Modal Multi-Agent Tactical Context Dataset for Play-by-Play Action Spotting in Soccer Broadcast Videos](https://arxiv.org/abs/2511.16183)
*Jeremie Ochin,Raphael Chekroun,Bogdan Stanciulescu,Sotiris Manitsaris*

Main category: cs.AI

TL;DR: 축구 비디오 이해를 위한 다중 작업 향상을 내세운 FOOTPASS 데이터셋을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 축구 분석을 위한 이벤트 구조화 및 데이터의 신뢰성을 높이기 위해, 기존의 행동 인식 기술이 부족하다는 문제가 있다.

Method: FOOTPASS는 다중 모드 및 다중 에이전트 전술 맥락에서 전체 축구 경기에 대한 행동 스포팅의 첫 번째 벤치마크를 제공한다.

Result: FOOTPASS 데이터셋은 플레이어 중심의 행동 스포팅 방법 개발을 가능하게 한다.

Conclusion: 이 데이터 스트림은 데이터 기반 스포츠 분석의 필수 입력으로 작용한다.

Abstract: Soccer video understanding has motivated the creation of datasets for tasks such as temporal action localization, spatiotemporal action detection (STAD), or multiobject tracking (MOT). The annotation of structured sequences of events (who does what, when, and where) used for soccer analytics requires a holistic approach that integrates both STAD and MOT. However, current action recognition methods remain insufficient for constructing reliable play-by-play data and are typically used to assist rather than fully automate annotation. Parallel research has advanced tactical modeling, trajectory forecasting, and performance analysis, all grounded in game-state and play-by-play data. This motivates leveraging tactical knowledge as a prior to support computer-vision-based predictions, enabling more automated and reliable extraction of play-by-play data. We introduce Footovision Play-by-Play Action Spotting in Soccer Dataset (FOOTPASS), the first benchmark for play-by-play action spotting over entire soccer matches in a multi-modal, multi-agent tactical context. It enables the development of methods for player-centric action spotting that exploit both outputs from computer-vision tasks (e.g., tracking, identification) and prior knowledge of soccer, including its tactical regularities over long time horizons, to generate reliable play-by-play data streams. These streams form an essential input for data-driven sports analytics.

</details>


### [42] [Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning](https://arxiv.org/abs/2511.16202)
*Pei Yang,Ke Zhang,Ji Wang,Xiao Chen,Yuxin Tang,Eric Yang,Lynn Ai,Bill Shi*

Main category: cs.AI

TL;DR: CRM은 RLHF에서의 견고성과 해석 가능성을 높이기 위한 다중 에이전트 협력 보상 모델 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 보상 모델은 여러 경쟁적인 선호 차원을 동시에 최적화하는 데 어려움을 겪고 있으며, 점수가 부여되는 이유에 대한 투명성이 제한적이다.

Method: 선호 평가를 도메인 특정 에이전트로 분해하여 각각 부분 신호를 생성하고, 이를 중앙 집중식 집계자가 각 시간 단계에서 융합한다.

Result: 하나의 훈련 보상을 생성하고, 정책은 이 보상에 기반하여 최적화되며, 가치 모델은 집계된 보상으로 회귀한다.

Conclusion: CRM과 rewardBench는 더 투명한 보상 모델링 및 더 안정적인 최적화를 위한 실용적이고 모듈식 경로를 제공한다.

Abstract: We present CRM (Multi-Agent Collaborative Reward Model), a framework that replaces a single black-box reward model with a coordinated team of specialist evaluators to improve robustness and interpretability in RLHF. Conventional reward models struggle to jointly optimize multiple, sometimes conflicting, preference dimensions (e.g., factuality, helpfulness, safety) and offer limited transparency into why a score is assigned. CRM addresses these issues by decomposing preference evaluation into domain-specific agents that each produce partial signals, alongside global evaluators such as ranker-based and embedding-similarity rewards. A centralized aggregator fuses these signals at each timestep, balancing factors like step-wise correctness, multi-agent agreement, and repetition penalties, yielding a single training reward compatible with standard RL pipelines. The policy is optimized with advantage-based updates (e.g., GAE), while a value model regresses to the aggregated reward, enabling multi-perspective reward shaping without requiring additional human annotations beyond those used to train the evaluators. To support training and assessment, we introduce rewardBench, a benchmark and training suite aligned with the collaborative structure of CRM. Together, CRM and rewardBench provide a practical, modular path to more transparent reward modeling and more stable optimization.

</details>


### [43] [ChemLabs on ChemO: A Multi-Agent System for Multimodal Reasoning on IChO 2025](https://arxiv.org/abs/2511.16205)
*Xu Qiang,Shengyuan Bai,Leqing Chen,Zijing Liu,Yu Li*

Main category: cs.AI

TL;DR: ChemO 벤치마크는 화학 문제 해결을 위한 새로운 자동 평가 시스템을 도입하며, ChemLabs라는 계층적 다중 에이전트 프레임워크를 제안하여 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 화학은 독특한 다중 모드 기호 언어로 인해 고급 AI 추론에서 중요한 시험대가 되었지만, 현재까지 큰 도전 과제가 되어 있다.

Method: Assessment-Equivalent Reformulation(AER)과 Structured Visual Enhancement(SVE)라는 두 가지 주요 혁신을 통해 자동 평가 시스템을 개발하였으며, ChemLabs라는 계층적 다중 에이전트 프레임워크를 통해 문제를 분해하고 인간 전문가의 협업을 모방한다.

Result: 최신 다중 모드 모델에서 실험 결과, SVE와 다중 에이전트 시스템의 조합이 성능을 극적으로 향상시켰고, 최고의 구성에서는 100점 만점에 93.6점을 달성하였다.

Conclusion: ChemO는 자동화된 화학 문제 해결에서 새로운 최첨단을 설정하며, 인간 금메달 기준을 초과하는 성능을 보여준다.

Abstract: Olympiad-level benchmarks in mathematics and physics are crucial testbeds for advanced AI reasoning, but chemistry, with its unique multimodal symbolic language, has remained an open challenge. We introduce ChemO, a new benchmark built from the International Chemistry Olympiad (IChO) 2025. ChemO features two key innovations for automated assessment: Assessment-Equivalent Reformulation (AER), which converts problems requiring visual outputs (e.g., drawing molecules) into computationally tractable formats, and Structured Visual Enhancement (SVE), a diagnostic mechanism to disentangle a model's visual perception capabilities from its core chemical reasoning. To tackle this benchmark, we propose ChemLabs, a hierarchical multi-agent framework that mimics human expert collaboration through specialized agents for problem decomposition, perception, reasoning, and auditing. Experiments on state-of-the-art multimodal models demonstrate that combining SVE with our multi-agent system yields dramatic performance gains. Our top configuration achieves a score of 93.6 out of 100, surpassing an estimated human gold medal threshold and establishing a new state-of-the-art in automated chemical problem-solving. ChemO Dataset: https://huggingface.co/datasets/IDEA-AI4SCI/ChemO

</details>


### [44] [Revisiting Fairness-aware Interactive Recommendation: Item Lifecycle as a Control Knob](https://arxiv.org/abs/2511.16248)
*Yun Lu,Xiaoyu Shi,Hong Xie,Chongjun Xia,Zhenhui Gong,Mingsheng Shang*

Main category: cs.AI

TL;DR: 이 논문은 아이템 생애 주기를 도입하여 공정성을 고려한 인터랙티브 추천 시스템을 재조명한다.


<details>
  <summary>Details</summary>
Motivation: 공정성을 고려한 추천 시스템의 중요성을 강조하고 아이템의 생애 주기가 추천의 공정성과 정확성에 미치는 영향을 분석하기 위해.

Method: 생애주기를 인식하는 계층적 재강화 학습 프레임워크인 LHRL을 도입하여 공정성과 정확성을 동적으로 조화시킨다.

Result: 실험 결과 LHRL이 공정성과 사용자 참여 모두에서 유의미한 개선을 보였으며, 생애 주기를 고려한 보상이 기존 RL 기반 모델에 통합되었을 때 성능 향상을 가져왔다.

Conclusion: LHRL은 장기적인 공정성과 단기적 유용성 간의 효과적인 조화를 가능하게 하여 추천 시스템의 성능을 향상시킨다.

Abstract: This paper revisits fairness-aware interactive recommendation (e.g., TikTok, KuaiShou) by introducing a novel control knob, i.e., the lifecycle of items. We make threefold contributions. First, we conduct a comprehensive empirical analysis and uncover that item lifecycles in short-video platforms follow a compressed three-phase pattern, i.e., rapid growth, transient stability, and sharp decay, which significantly deviates from the classical four-stage model (introduction, growth, maturity, decline). Second, we introduce LHRL, a lifecycle-aware hierarchical reinforcement learning framework that dynamically harmonizes fairness and accuracy by leveraging phase-specific exposure dynamics. LHRL consists of two key components: (1) PhaseFormer, a lightweight encoder combining STL decomposition and attention mechanisms for robust phase detection; (2) a two-level HRL agent, where the high-level policy imposes phase-aware fairness constraints, and the low-level policy optimizes immediate user engagement. This decoupled optimization allows for effective reconciliation between long-term equity and short-term utility. Third, experiments on multiple real-world interactive recommendation datasets demonstrate that LHRL significantly improves both fairness and user engagement. Furthermore, the integration of lifecycle-aware rewards into existing RL-based models consistently yields performance gains, highlighting the generalizability and practical value of our approach.

</details>


### [45] [Distributed Agent Reasoning Across Independent Systems With Strict Data Locality](https://arxiv.org/abs/2511.16292)
*Daniel Vaughan,Kateřina Vaughan*

Main category: cs.AI

TL;DR: 이 논문은 분산 시스템 간의 에이전트 간 통신의 개념 증명을 보여주는 것으로, 자연어 메시지만을 사용하고 공유 식별자, 구조화된 스키마 또는 중앙 집중식 데이터 교환 없이 수행된다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 간의 안전한 통신 및 협력을 통해 분산 시스템의 효율성을 증대시키고자 함.

Method: 여러 조직이 의사, 보험사 및 전문 네트워크로 대표되는 환경에서 익명화된 사례 토큰, 로컬 데이터 조회 및 통제된 운영 경계를 사용해 협력하는 프로토타입 시스템을 개발.

Result: 각 에이전트가 고유 데이터에 기반하여 자연어 요약을 통해 통신하며, 환자 신원을 수집하거나 재구성하지 않고도 적합성 권고를 반환하는 시스템.

Conclusion: 분산 다중 에이전트 시스템에 대한 더 심도 있는 평가 및 미래 연구의 기회를 개괄적으로 설명하며, 건축 패턴, 프라이버시 고려 사항 및 전문 에이전트 간의 분산 추론을 가능하게 하는 통신 흐름의 중요성을 강조함.

Abstract: This paper presents a proof-of-concept demonstration of agent-to-agent communication across distributed systems, using only natural-language messages and without shared identifiers, structured schemas, or centralised data exchange. The prototype explores how multiple organisations (represented here as a Clinic, Insurer, and Specialist Network) can cooperate securely via pseudonymised case tokens, local data lookups, and controlled operational boundaries.
  The system uses Orpius as the underlying platform for multi-agent orchestration, tool execution, and privacy-preserving communication. All agents communicate through OperationRelay calls, exchanging concise natural-language summaries. Each agent operates on its own data (such as synthetic clinic records, insurance enrolment tables, and clinical guidance extracts), and none receives or reconstructs patient identity. The Clinic computes an HMAC-based pseudonymous token, the Insurer evaluates coverage rules and consults the Specialist agent, and the Specialist returns an appropriateness recommendation.
  The goal of this prototype is intentionally limited: to demonstrate feasibility, not to provide a clinically validated, production-ready system. No clinician review was conducted, and no evaluation beyond basic functional runs was performed. The work highlights architectural patterns, privacy considerations, and communication flows that enable distributed reasoning among specialised agents while keeping data local to each organisation. We conclude by outlining opportunities for more rigorous evaluation and future research in decentralised multi-agent systems.

</details>


### [46] [An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models](https://arxiv.org/abs/2511.16383)
*Alexander Zadorojniy,Segev Wasserkrug,Eitan Farchi*

Main category: cs.AI

TL;DR: 본 논문은 자연어 설명에서 생성된 최적화 모델의 자동 검증을 위한 새로운 에이전트 기반 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델을 통해 생성된 최적화 모델의 정확성을 검증하는 방법에 대한 필요성이 증가하고 있다.

Method: 소프트웨어 테스트에서의 방법을 확장하여, 문제 수준 테스팅 API를 생성하고, 이 API를 활용하여 테스트를 생성하며, 마지막으로 최적화 모델에 특화된 변이를 생성하는 여러 에이전트로 구성된 방법을 제안한다.

Result: 실험을 통해 이 에이전트 집합이 제공하는 높은 품질의 검증을 보여준다.

Conclusion: 제안된 방법은 잘 알려진 소프트웨어 테스트 지표인 변이 적용률 측면에서 높은 검증 품질을 제공한다.

Abstract: Recently, using Large Language Models (LLMs) to generate optimization models from natural language descriptions has became increasingly popular. However, a major open question is how to validate that the generated models are correct and satisfy the requirements defined in the natural language description. In this work, we propose a novel agent-based method for automatic validation of optimization models that builds upon and extends methods from software testing to address optimization modeling . This method consists of several agents that initially generate a problem-level testing API, then generate tests utilizing this API, and, lastly, generate mutations specific to the optimization model (a well-known software testing technique assessing the fault detection power of the test suite). In this work, we detail this validation framework and show, through experiments, the high quality of validation provided by this agent ensemble in terms of the well-known software testing measure called mutation coverage.

</details>


### [47] [CorrectHDL: Agentic HDL Design with LLMs Leveraging High-Level Synthesis as Reference](https://arxiv.org/abs/2511.16395)
*Kangwei Xu,Grace Li Zhang,Ulf Schlichtmann,Bing Li*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)은 하드웨어 설명 언어(HDL)를 이용한 하드웨어 전면 설계에서 뛰어난 잠재력을 보이지만, 자주 발생하는 환각으로 인해 생성된 HDL 설계에 기능적 오류가 발생한다. 이를 해결하기 위해 제안된 CorrectHDL 프레임워크는 고급 합성(HLS) 결과를 기능적 참조로 활용하여 LLM 생성 HDL 설계의 오류를 수정한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 생성한 HDL 설계의 기능적 오류를 해결하기 위해.

Method: C/C++ 프로그램을 입력으로 받아 LLM이 HDL 설계를 생성하도록 하고, Retrieval-Augmented Generation(RAG) 메커니즘을 사용하여 구문 오류를 수정한다. 시뮬레이션된 동작을 고급 합성(HLS) 참조 설계와 비교하여 반복적으로 기능적 정확성을 개선한다.

Result: 제안된 프레임워크로 생성된 회로는 기존 HLS 설계에 비해 면적과 전력 효율이 유의미하게 개선되며, 인간이 설계한 회로의 품질에 접근한다.

Conclusion: 생성된 HDL 구현의 정확성을 유지하며 LLM의 생성 능력과 전통적인 정확성 중심 IC 설계 흐름의 엄격성을 결합한 효과성과 잠재력을 강조한다.

Abstract: Large Language Models (LLMs) have demonstrated remarkable potential in hardware front-end design using hardware description languages (HDLs). However, their inherent tendency toward hallucination often introduces functional errors into the generated HDL designs. To address this issue, we propose the framework CorrectHDL that leverages high-level synthesis (HLS) results as functional references to correct potential errors in LLM-generated HDL designs.The input to the proposed framework is a C/C++ program that specifies the target circuit's functionality. The program is provided to an LLM to directly generate an HDL design, whose syntax errors are repaired using a Retrieval-Augmented Generation (RAG) mechanism. The functional correctness of the LLM-generated circuit is iteratively improved by comparing its simulated behavior with an HLS reference design produced by conventional HLS tools, which ensures the functional correctness of the result but can lead to suboptimal area and power efficiency. Experimental results demonstrate that circuits generated by the proposed framework achieve significantly better area and power efficiency than conventional HLS designs and approach the quality of human-engineered circuits. Meanwhile, the correctness of the resulting HDL implementation is maintained, highlighting the effectiveness and potential of agentic HDL design leveraging the generative capabilities of LLMs and the rigor of traditional correctness-driven IC design flows.

</details>


### [48] [Trustworthy AI in the Agentic Lakehouse: from Concurrency to Governance](https://arxiv.org/abs/2511.16402)
*Jacopo Tagliabue,Federico Bianchi,Ciro Greco*

Main category: cs.AI

TL;DR: AI 능력이 향상되더라도 많은 기업이 생산 데이터에서 에이전트를 신뢰하지 않는다. 이 논문은 신뢰할 수 있는 에이전트 작업을 위한 인프라 문제 해결의 중요성을 주장하며, 데이터 및 계산 격리를 구현하는 에이전트 우선 디자인인 Bauplan을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 기술이 발전하고 있지만 여전히 많은 기업들이 생산 데이터에서 에이전트를 신뢰하지 않는다.

Method: 전통적인 레이크하우스 구조가 에이전트 접근 패턴에 적합하지 않기 때문에, 우리는 이를 트랜잭션을 중심으로 설계하는 에이전트 우선 디자인인 Bauplan으로 해결한다.

Result: Bauplan은 데이터 및 계산 격리를 재구현하며, 에이전트의 추론을 올바름과 신뢰에 대한 보장을 제공하는 방식으로 결합한다.

Conclusion: Bauplan의 자기 치유 파이프라인의 참조 구현을 제공하며, 이는 에이전트의 추론과 모든 원하는 보장을 원활하게 결합한다.

Abstract: Even as AI capabilities improve, most enterprises do not consider agents trustworthy enough to work on production data. In this paper, we argue that the path to trustworthy agentic workflows begins with solving the infrastructure problem first: traditional lakehouses are not suited for agent access patterns, but if we design one around transactions, governance follows. In particular, we draw an operational analogy to MVCC in databases and show why a direct transplant fails in a decoupled, multi-language setting. We then propose an agent-first design, Bauplan, that reimplements data and compute isolation in the lakehouse. We conclude by sharing a reference implementation of a self-healing pipeline in Bauplan, which seamlessly couples agent reasoning with all the desired guarantees for correctness and trust.

</details>


### [49] [Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes](https://arxiv.org/abs/2511.16548)
*Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang*

Main category: cs.AI

TL;DR: CLOZE는 임상 노트에서 의료 개체를 자동으로 추출하고 이를 계층적 의료 온톨로지에 통합하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 온톨로지에 새로운 의료 개념과 관계를 통합함으로써 생물 의학 연구와 임상 응용의 적용성을 높이는 것이 중요하다.

Method: CLOZE는 대형 언어 모델을 활용하여 임상 노트에서 의료 개체를 자동으로 추출하고 이를 계층적 온톨로지에 통합하는 방법을 제안한다.

Result: CLOZE는 질병 관련 개념을 효과적으로 식별하고 복잡한 계층적 관계를 포착한다.

Conclusion: CLOZE는 정확하고 확장 가능하며 개인정보 보호가 보장된 온톨로지 확장 프레임워크를 제공하며, 생물 의학 연구와 임상 정보학의 다양한 응용 프로그램을 지원할 잠재력이 크다.

Abstract: Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored. To address this gap, we propose CLOZE, a novel framework that uses large language models (LLMs) to automatically extract medical entities from clinical notes and integrate them into hierarchical medical ontologies. By capitalizing on the strong language understanding and extensive biomedical knowledge of pre-trained LLMs, CLOZE effectively identifies disease-related concepts and captures complex hierarchical relationships. The zero-shot framework requires no additional training or labeled data, making it a cost-efficient solution. Furthermore, CLOZE ensures patient privacy through automated removal of protected health information (PHI). Experimental results demonstrate that CLOZE provides an accurate, scalable, and privacy-preserving ontology extension framework, with strong potential to support a wide range of downstream applications in biomedical research and clinical informatics.

</details>


### [50] [D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2511.16590)
*Sen Chen,Tong Zhao,Yi Bin,Fei Ma,Wenqi Shao,Zheng Wang*

Main category: cs.AI

TL;DR: D-GARA는 실제 환경에서 GUI 에이전트의 강인성을 평가하는 동적 벤치마크 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 인간 수준의 능력을 가진 GUI 에이전트를 개발하는 것은 인공지능 일반 지능을 향한 중요한 이정표이다.

Method: D-GARA는 Android GUI 에이전트가 실제에서 흔히 직면하는 다양한 실세계 이상 현상을 포함하는 동적 벤치마크 프레임워크를 제안한다.

Result: 최신 GUI 에이전트는 이상 현상이 많은 환경에서 성능 저하가 크게 나타났다.

Conclusion: D-GARA는 새로운 작업, 이상 유형 및 인터랙션 시나리오의 매끄러운 통합을 지원하도록 모듈식으로 설계되었다.

Abstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.

</details>


### [51] [Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](https://arxiv.org/abs/2511.16602)
*Yi Zhang,Che Liu,Xiancong Ren,Hanchu Ni,Yingji Zhang,Shuai Zhang,Zeyuan Ding,Jiayu Hu,Haozhe Shan,Junbo Qi,Yan Bai,Dengjie Li,Jiachen Luo,Yidong Wang,Yong Dai,Zenglin Xu,Bin Shen,Qifan Wang,Jian Tang,Xiaozhu Ju*

Main category: cs.AI

TL;DR: 보편적이고 다목적의 구현 지능 시스템 개발에 있어 데이터 병목 현상과 알고리즘 비효율성을 해결하는 새로운 접근법을 제시.


<details>
  <summary>Details</summary>
Motivation: 실세계 데이터의 부족과 기존 방법의 자원 비효율성을 해결하기 위해.

Method: DPPO(Deliberate Practice Policy Optimization)라는 메타인지 훈련 프레임워크를 도입하여 감독 세부 조정과 강화 학습을 동적으로 전환.

Result: DPPO로 훈련된 Pelican-VL 1.0 모델은 기본 모델 대비 20.3% 성능 향상을 이루었으며, 100B 매개변수 규모의 오픈 소스 모델을 10.6% 초과.

Conclusion: 모델과 코드를 오픈 소스화하여 데이터 및 자원 병목 현상을 완화하고 커뮤니티가 다목적 구현 에이전트를 효율적으로 구축할 수 있도록 지원한다.

Abstract: Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.

</details>


### [52] [Cognitive Foundations for Reasoning and Their Manifestation in LLMs](https://arxiv.org/abs/2511.16660)
*Priyanka Kargupta,Shuyue Stella Li,Haocheng Wang,Jinu Lee,Shan Chen,Orevaoghene Ahia,Dean Light,Thomas L. Griffiths,Max Kleiman-Weiner,Jiawei Han,Asli Celikyilmaz,Yulia Tsvetkov*

Main category: cs.AI

TL;DR: 대형 언어 모델은 복잡한 문제를 해결하지만 간단한 변형에서는 실패하는 경향이 있어, 이들이 올바른 출력을 얻기 위해 인간의 추론과 근본적으로 다른 메커니즘을 사용한다는 것을 시사한다.


<details>
  <summary>Details</summary>
Motivation: 이 논문은 대형 언어 모델의 추론 메커니즘을 인간의 인지과학 연구를 바탕으로 평가하고 개선할 수 있는 방법을 모색한다.

Method: 28개의 인지 요소를 포함하는 세분화된 인지 평가 프레임워크를 제안하고, 17개의 모델로부터 17만 개의 추론 흔적과 54개의 인간 사고 표현 흔적을 분석한다.

Result: 인간과 모델 간의 체계적인 구조적 차이를 발견하고, 모델이 성공하는 데 필요한 행동 패턴을 가지고 있지만 자발적으로 활용하지 못함을 확인하였다.

Conclusion: 인지과학과 대형 언어 모델 연구를 연결하여 원칙적인 인지 메커니즘을 통한 추론을 개발하기 위한 기초를 마련하고, 모델의 능력을 향상시키고 인간 인지 이론을 대규모로 테스트할 수 있는 새로운 방향을 열었다.

Abstract: Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, and audio modalities, alongside 54 human think-aloud traces, which we make publicly available. Our analysis reveals systematic structural differences: humans employ hierarchical nesting and meta-cognitive monitoring while models rely on shallow forward chaining, with divergence most pronounced on ill-structured problems. Meta-analysis of 1,598 LLM reasoning papers reveals the research community concentrates on easily quantifiable behaviors (sequential organization: 55%, decomposition: 60%) while neglecting meta-cognitive controls (self-awareness: 16%, evaluation: 8%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 60% on complex problems. By bridging cognitive science and LLM research, we establish a foundation for developing models that reason through principled cognitive mechanisms rather than brittle spurious reasoning shortcuts or memorization, opening new directions for both improving model capabilities and testing theories of human cognition at scale.

</details>
