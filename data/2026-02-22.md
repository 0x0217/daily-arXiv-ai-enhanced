<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 12]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [HiVAE: Hierarchical Latent Variables for Scalable Theory of Mind](https://arxiv.org/abs/2602.16826)
*Nigel Doering,Rahath Malladi,Arshia Sangwan,David Danks,Tauhidur Rahman*

Main category: cs.LG

TL;DR: 이 논문에서는 HiVAE라는 계층적 변분 아키텍처를 도입하여 실제적인 시공간 도메인에서 ToM 추론을 확장하는 방법을 제시한다. 그러나 학습된 잠재 표현이 실제 정신 상태에 명시적으로 연결되지 않는 한계를 인식했다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 에이전트의 숨겨진 목표와 정신 상태를 추론할 수 있도록 하는 ToM을 실제적인 시공간 도메인에 적용하기 위해.

Method: 계층적 변분 오토인코더(HiVAE)를 도입하여 사람의 인지 구조에서 영감을 받아 3단계의 VAE 계층을 구성하였다.

Result: 3,185개의 노드를 가진 캠퍼스 내비게이션 작업에서 성능이 크게 향상되었다.

Conclusion: 자기지도 정렬 전략을 제안하고, 특정 기반 접근법에 대한 커뮤니티 피드백을 요청하였다.

Abstract: Theory of mind (ToM) enables AI systems to infer agents' hidden goals and mental states, but existing approaches focus mainly on small human understandable gridworld spaces. We introduce HiVAE, a hierarchical variational architecture that scales ToM reasoning to realistic spatiotemporal domains. Inspired by the belief-desire-intention structure of human cognition, our three-level VAE hierarchy achieves substantial performance improvements on a 3,185-node campus navigation task. However, we identify a critical limitation: while our hierarchical structure improves prediction, learned latent representations lack explicit grounding to actual mental states. We propose self-supervised alignment strategies and present this work to solicit community feedback on grounding approaches.

</details>


### [2] [Multi-Agent Lipschitz Bandits](https://arxiv.org/abs/2602.16965)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 이 논문은 연속적이고 리프시츠 구조를 가진 행동 공간에서의 분산 다중 플레이어 확률적 밴딧 문제를 다룬다. 목표는 통신 없이 집단 보상을 극대화하는 정책을 설계하는 것이다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 다중 에이전트에서의 조정을 수행하면서도 통신 비용 없이 보상을 극대화하는 방법을 탐구하기 위해 수행되었다.

Method: 모듈형 프로토콜을 제안하며, 먼저 새로운 최대값 지향 검색을 통해 플레이어를 식별하고 가치가 높은 지역에 배치한 후, 문제를 N개의 독립적인 단일 플레이어 리프시츠 밴딧으로 분리한다.

Result: 최적에 근접한 후회 경계를 $	ilde{O}(T^{(d+1)/(d+2)})$와 함께 시간에 독립적인 조정 비용으로 제시하였으며, 이로 인해 단일 플레이어의 비율과 일치한다.

Conclusion: 이 연구는 이러한 보증을 제공하는 첫 번째 프레임워크로 알려져 있으며, 일반 거리 임계 충돌 모델로 확장 가능하다.

Abstract: We study the decentralized multi-player stochastic bandit problem over a continuous, Lipschitz-structured action space where hard collisions yield zero reward. Our objective is to design a communication-free policy that maximizes collective reward, with coordination costs that are independent of the time horizon $T$. We propose a modular protocol that first solves the multi-agent coordination problem -- identifying and seating players on distinct high-value regions via a novel maxima-directed search -- and then decouples the problem into $N$ independent single-player Lipschitz bandits. We establish a near-optimal regret bound of $\tilde{O}(T^{(d+1)/(d+2)})$ plus a $T$-independent coordination cost, matching the single-player rate. To our knowledge, this is the first framework providing such guarantees, and it extends to general distance-threshold collision models.

</details>


### [3] [A Unified Framework for Locality in Scalable MARL](https://arxiv.org/abs/2602.16966)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 본 논문은 다차원 문제로부터의 벗어남을 위한 정책 의존적인 지역성을 탐구하며, 정책에 의해 유도된 상호 의존성 행렬의 새로운 분해를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습(MARL)의 확장 가능성은 차원의 저주에 의해 근본적으로 도전받고 있습니다.

Method: 정책에 의해 유도된 상호 의존성 행렬을 새롭게 분해하여 환경의 상태 및 행동에 대한 민감성과 정책의 상태에 대한 민감성을 분리합니다.

Result: 이 새로운 분해는 환경이 강하게 행동 결합되어 있을 때에도 매끄러운 정책에 의해 지역성이 유도될 수 있음을 보여줍니다.

Conclusion: 일반적인 스펙트럼 조건을 도출하고, 이를 통해 지역화된 블록 좌표 정책 개선 프레임워크를 분석합니다.

Abstract: Scalable Multi-Agent Reinforcement Learning (MARL) is fundamentally challenged by the curse of dimensionality. A common solution is to exploit locality, which hinges on an Exponential Decay Property (EDP) of the value function. However, existing conditions that guarantee the EDP are often conservative, as they are based on worst-case, environment-only bounds (e.g., supremums over actions) and fail to capture the regularizing effect of the policy itself. In this work, we establish that locality can also be a \emph{policy-dependent} phenomenon. Our central contribution is a novel decomposition of the policy-induced interdependence matrix, $H^π$, which decouples the environment's sensitivity to state ($E^{\mathrm{s}}$) and action ($E^{\mathrm{a}}$) from the policy's sensitivity to state ($Π(π)$). This decomposition reveals that locality can be induced by a smooth policy (small $Π(π)$) even when the environment is strongly action-coupled, exposing a fundamental locality-optimality tradeoff. We use this framework to derive a general spectral condition $ρ(E^{\mathrm{s}}+E^{\mathrm{a}}Π(π)) < 1$ for exponential decay, which is strictly tighter than prior norm-based conditions. Finally, we leverage this theory to analyze a provably-sound localized block-coordinate policy improvement framework with guarantees tied directly to this spectral radius.

</details>


### [4] [Action-Graph Policies: Learning Action Co-dependencies in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.17009)
*Nikunj Gupta,James Zachary Hare,Jesse Milzman,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.LG

TL;DR: 다중 에이전트 강화 학습에서의 협력을 위한 새로운 정책 모델 소개


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습에서 에이전트 간의 행동 조정을 통해 더 나은 성과를 달성하고자 함.

Method: Action Graph Policies (AGP)라는 모델을 제안하여 에이전트의 행동 선택 간의 의존성을 모델링하고, 이를 통해 에이전트들이 글로벌 행동 의존성에 따라 결정을 내리도록 하는 조정 맥락을 구축함.

Result: AGP는 기존의 완전히 독립적인 정책보다 더 표현력이 뛰어난 공동 정책을 유도하며, 중앙 집중식 가치 분해 방법에서도 탐욕적 실행보다 더 최적의 조정된 공동 행동을 실현할 수 있음. 또한 AGP는 고전적인 조정 작업에서 80-95%의 성공률을 달성하며, 이는 다른 다중 에이전트 강화 학습 방법의 10-25%와 비교됨.

Conclusion: AGP는 다양한 다중 에이전트 환경에서 기존 방법들에 비해 일관되게 더 나은 성능을 발휘함.

Abstract: Coordinating actions is the most fundamental form of cooperation in multi-agent reinforcement learning (MARL). Successful decentralized decision-making often depends not only on good individual actions, but on selecting compatible actions across agents to synchronize behavior, avoid conflicts, and satisfy global constraints. In this paper, we propose Action Graph Policies (AGP), that model dependencies among agents' available action choices. It constructs, what we call, \textit{coordination contexts}, that enable agents to condition their decisions on global action dependencies. Theoretically, we show that AGPs induce a strictly more expressive joint policy compared to fully independent policies and can realize coordinated joint actions that are provably more optimal than greedy execution even from centralized value-decomposition methods. Empirically, we show that AGP achieves 80-95\% success on canonical coordination tasks with partial observability and anti-coordination penalties, where other MARL methods reach only 10-25\%. We further demonstrate that AGP consistently outperforms these baselines in diverse multi-agent environments.

</details>


### [5] [Spatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control](https://arxiv.org/abs/2602.17068)
*Xiaocai Zhang,Neema Nassir,Milad Haghani*

Main category: cs.LG

TL;DR: 인간 중심의 교차로 신호 제어는 다중 모드 여행자를 고려해야 하며, STDSH-MARL이라는 새로운 방법을 제안하여 대중교통 우선순위를 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 인간 중심의 교차로 신호 제어는 차량 중심의 성능에만 집중하는 대신 고점유 공공 교통수단과 같은 다중 모드 여행자를 점점 더 고려해야 한다.

Method: STDSH-MARL(스페이쇼-템포랄 듀얼 스테이지 하이퍼그래프 기반 다중 에이전트 강화학습)을 제안하며, 중앙 집중식 교육과 분산 실행 패러다임을 따르는 확장 가능한 다중 에이전트 심층 강화학습 프레임워크이다.

Result: 다섯 가지 교통 시나리오에 걸쳐 진행된 실험에서 STDSH-MARL은 다중 모드 성능을 지속적으로 개선하고 대중교통 우선순위에 명확한 이점을 제공한다.

Conclusion: 최첨단 기준 방법과 비교하여 제안된 접근 방식은 전반적인 성능에서 우수한 결과를 달성하였으며, 아블레이션 연구를 통해 STDSH-MARL의 각 구성 요소의 기여가 확인되었다.

Abstract: Human-centric traffic signal control in corridor networks must increasingly account for multimodal travelers, particularly high-occupancy public transportation, rather than focusing solely on vehicle-centric performance. This paper proposes STDSH-MARL (Spatio-Temporal Dual-Stage Hypergraph based Multi-Agent Reinforcement Learning), a scalable multi-agent deep reinforcement learning framework that follows a centralized training and decentralized execution paradigm. The proposed method captures spatio-temporal dependencies through a novel dual-stage hypergraph attention mechanism that models interactions across both spatial and temporal hyperedges. In addition, a hybrid discrete action space is introduced to jointly determine the next signal phase configuration and its corresponding green duration, enabling more adaptive signal timing decisions. Experiments conducted on a corridor network under five traffic scenarios demonstrate that STDSH-MARL consistently improves multimodal performance and provides clear benefits for public transportation priority. Compared with state-of-the-art baseline methods, the proposed approach achieves superior overall performance. Further ablation studies confirm the contribution of each component of STDSH-MARL, with temporal hyperedges identified as the most influential factor driving the observed performance gains.

</details>


### [6] [Adam Improves Muon: Adaptive Moment Estimation with Orthogonalized Momentum](https://arxiv.org/abs/2602.17080)
*Minxin Zhang,Yuxuan Liu,Hayden Scheaffer*

Main category: cs.LG

TL;DR: NAMO와 NAMO-D라는 새로운 최적화를 제안하고, 이들은 기존 방법들보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 효율적인 확률적 최적화는 결정론적 비율에서 잘 작동하는 업데이트 방향과 확률적 섭동에 적응하는 메커니즘을 통합하는 것을 목표로 한다.

Method: NAMO는 단일 적응적 스텝 사이즈를 사용하여 직교 모멘텀을 확장하며, NAMO-D는 클램프된 항목을 가진 대각 행렬로 직교 모멘텀을 오른쪽으로 곱한다.

Result: NAMO와 NAMO-D 모두 AdamW 및 Muon 기준선에 비해 개선된 성능을 보여준다.

Conclusion: NAMO-D는 추가적인 클램프 하이퍼파라미터를 통해 잘 정돈된 업데이트 방향을 유지하고 미세한 노이즈 적응을 가능하게 하는 경쟁 목표를 균형 잡는 추가 이득을 달성한다.

Abstract: Efficient stochastic optimization typically integrates an update direction that performs well in the deterministic regime with a mechanism adapting to stochastic perturbations. While Adam uses adaptive moment estimates to promote stability, Muon utilizes the weight layers' matrix structure via orthogonalized momentum, showing superior performance in large language model training. We propose a new optimizer and a diagonal extension, NAMO and NAMO-D, providing the first principled integration of orthogonalized momentum with norm-based Adam-type noise adaptation. NAMO scales orthogonalized momentum using a single adaptive stepsize, preserving orthogonality while improving upon Muon at negligible additional cost. NAMO-D instead right-multiplies orthogonalized momentum by a diagonal matrix with clamped entries. This design enables neuron-wise noise adaptation and aligns with the common near block-diagonal Hessian structure. Under standard assumptions, we establish optimal convergence rates for both algorithms in the deterministic setting and show that, in the stochastic setting, their convergence guarantees adapt to the noise level of stochastic gradients. Experiments on pretraining GPT-2 models demonstrate improved performance of both NAMO and NAMO-D compared to the AdamW and Muon baselines, with NAMO-D achieving further gains over NAMO via an additional clamping hyperparameter that balances the competing goals of maintaining a well-conditioned update direction and leveraging fine-grained noise adaptation.

</details>


### [7] [Towards Anytime-Valid Statistical Watermarking](https://arxiv.org/abs/2602.17608)
*Baihe Huang,Eric Xu,Kannan Ramchandran,Jiantao Jiao,Michael I. Jordan*

Main category: cs.LG

TL;DR: 본 논문에서는 LLM의 기계 생성 내용을 정확히 구별하기 위한 새로운 물리적 워터마킹 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 확산은 기계 생성 내용과 인간 텍스트를 구별하기 위한 효율적인 메커니즘을 요구합니다.

Method: 우리는 최초의 e-value 기반 워터마킹 프레임워크인 Anchored E-Watermarking을 개발하여 최적 샘플링과 언제든지 유효한 추론을 통합합니다.

Result: 우리의 프레임워크는 샘플 효율성을 크게 향상시켜, 최첨단 기준 대비 탐지를 위한 평균 토큰 예산을 13-15% 줄일 수 있음을 보여주었습니다.

Conclusion: 이론적 주장들은 시뮬레이션 및 평가를 통해 뒷받침되며, 우리의 접근 방식이 효과적임을 입증합니다.

Abstract: The proliferation of Large Language Models (LLMs) necessitates efficient mechanisms to distinguish machine-generated content from human text. While statistical watermarking has emerged as a promising solution, existing methods suffer from two critical limitations: the lack of a principled approach for selecting sampling distributions and the reliance on fixed-horizon hypothesis testing, which precludes valid early stopping. In this paper, we bridge this gap by developing the first e-value-based watermarking framework, Anchored E-Watermarking, that unifies optimal sampling with anytime-valid inference. Unlike traditional approaches where optional stopping invalidates Type-I error guarantees, our framework enables valid, anytime-inference by constructing a test supermartingale for the detection process. By leveraging an anchor distribution to approximate the target model, we characterize the optimal e-value with respect to the worst-case log-growth rate and derive the optimal expected stopping time. Our theoretical claims are substantiated by simulations and evaluations on established benchmarks, showing that our framework can significantly enhance sample efficiency, reducing the average token budget required for detection by 13-15% relative to state-of-the-art baselines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [AIdentifyAGE Ontology for Decision Support in Forensic Dental Age Assessment](https://arxiv.org/abs/2602.16714)
*Renato Marcelo,Ana Rodrigues,Cristiana Palmela Pereira,António Figueiras,Rui Santos,José Rui Figueira,Alexandre P Francisco,Cátia Vaz*

Main category: cs.AI

TL;DR: 이 논문은 법의학 및 사법 결정에서 연령 평가의 중요성을 강조하며, AIdentifyAGE 온톨로지를 통해 치과 연령 평가의 표준화 및 투명성을 지원하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 법의학 및 사법 결정에서 문서화되지 않은 개인 및 동반자 없는 미성년자와 같은 사례에서 연령 평가가 매우 중요하다.

Method: AIdentifyAGE 온톨로지는 수동 및 AI 지원 법의학 치과 연령 평가 워크플로를 포괄하는 표준화되고 의미론적으로 일관된 프레임워크를 제공한다.

Result: 이 온톨로지는 관찰, 방법, 참조 데이터 및 보고된 결과 간의 추적 가능한 연계를 가능하게 하여 법의학의 전체 의료-법적 워크플로를 모델링한다.

Conclusion: AIdentifyAGE 온톨로지는 법의학 및 사법 맥락에서 온톨로지 기반의 의사 결정 지원 시스템을 위한 견고한 기초를 확립하는 데 기여한다.

Abstract: Age assessment is crucial in forensic and judicial decision-making, particularly in cases involving undocumented individuals and unaccompanied minors, where legal thresholds determine access to protection, healthcare, and judicial procedures. Dental age assessment is widely recognized as one of the most reliable biological approaches for adolescents and young adults, but current practices are challenged by methodological heterogeneity, fragmented data representation, and limited interoperability between clinical, forensic, and legal information systems. These limitations hinder transparency and reproducibility, amplified by the increasing adoption of AI- based methods. The AIdentifyAGE ontology is domain-specific and provides a standardized, semantically coherent framework, encompassing both manual and AI-assisted forensic dental age assessment workflows, and enabling traceable linkage between observations, methods, reference data, and reported outcomes. It models the complete medico-legal workflow, integrating judicial context, individual-level information, forensic examination data, dental developmental assessment methods, radiographic imaging, statistical reference studies, and AI-based estimation methods. It is being developed together with domain experts, and it builds on upper and established biomedical, dental, and machine learning ontologies, ensuring interoperability, extensibility, and compliance with FAIR principles. The AIdentifyAGE ontology is a fundamental step to enhance consistency, transparency, and explainability, establishing a robust foundation for ontology-driven decision support systems in medico-legal and judicial contexts.

</details>


### [9] [Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI](https://arxiv.org/abs/2602.16814)
*Eiman Kanjo,Mustafa Aslanov*

Main category: cs.AI

TL;DR: AI의 엣지 확장은 중앙집중식 지능의 비용과 취약성을 드러낸다. 본 논문에서는 선택적 동료 상호작용을 통해 개별 엣지 노드에서 지능이 존재하고 확장되는 Decentralized Learning 패러다임인 Node Learning을 소개한다.


<details>
  <summary>Details</summary>
Motivation: AI의 엣지 확장은 데이터 전송, 지연, 에너지 소비 및 대규모 데이터 센터에 대한 의존성으로 인해 발생하는 병목 현상을 해결할 필요성이 커지고 있다.

Method: Node Learning은 각 노드가 로컬 데이터를 기반으로 지속적으로 학습하고, 자신의 모델 상태를 유지하며, 협력이 유익할 때 학습된 지식을 교환하는 방식으로 작동한다.

Result: 학습은 글로벌 동기화나 중앙 집계가 아닌 겹침과 확산을 통해 전파된다. 이는 다양한 데이터, 하드웨어, 목표 및 연결성을 통합한다.

Conclusion: Node Learning은 기존 패러다임을 폐기하지 않고, 더욱 넓은 분산된 관점 내에서 이들을 위치시킨다.

Abstract: The expansion of AI toward the edge increasingly exposes the cost and fragility of cen- tralised intelligence. Data transmission, latency, energy consumption, and dependence on large data centres create bottlenecks that scale poorly across heterogeneous, mobile, and resource-constrained environments. In this paper, we introduce Node Learning, a decen- tralised learning paradigm in which intelligence resides at individual edge nodes and expands through selective peer interaction. Nodes learn continuously from local data, maintain their own model state, and exchange learned knowledge opportunistically when collaboration is beneficial. Learning propagates through overlap and diffusion rather than global synchro- nisation or central aggregation. It unifies autonomous and cooperative behaviour within a single abstraction and accommodates heterogeneity in data, hardware, objectives, and connectivity. This concept paper develops the conceptual foundations of this paradigm, contrasts it with existing decentralised approaches, and examines implications for communi- cation, hardware, trust, and governance. Node Learning does not discard existing paradigms, but places them within a broader decentralised perspective

</details>


### [10] [AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](https://arxiv.org/abs/2602.16901)
*Tanqiu Jiang,Yuhui Wang,Jiacheng Liang,Ting Wang*

Main category: cs.AI

TL;DR: LLM 에이전트는 복잡한 환경에서 장기 공격에 취약하며, AgentLAB를 통해 이러한 공격에 대한 평가 기준이 제시됨.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 장기적이고 복잡한 환경에서 문제를 해결하기 위해 점점 더 많이 배치되고 있지만, 이는 장기 공격에 노출된다는 문제를 가지고 있다.

Method: AgentLAB는 적응형 장기 공격에 대한 LLM 에이전트의 취약성을 평가하기 위한 최초의 벤치마크이다.

Result: AgentLAB를 활용하여 평가한 결과, 대표적인 LLM 에이전트가 장기 공격에 매우 취약한 것으로 나타났으며, 단일 턴 상호작용을 위한 방어가 효과적이지 않았다.

Conclusion: AgentLAB는 실제 환경에서 LLM 에이전트를 보호하기 위한 진전을 추적하는 데 유용한 기준이 될 것으로 기대된다.

Abstract: LLM agents are increasingly deployed in long-horizon, complex environments to solve challenging problems, but this expansion exposes them to long-horizon attacks that exploit multi-turn user-agent-environment interactions to achieve objectives infeasible in single-turn settings. To measure agent vulnerabilities to such risks, we present AgentLAB, the first benchmark dedicated to evaluating LLM agent susceptibility to adaptive, long-horizon attacks. Currently, AgentLAB supports five novel attack types including intent hijacking, tool chaining, task injection, objective drifting, and memory poisoning, spanning 28 realistic agentic environments, and 644 security test cases. Leveraging AgentLAB, we evaluate representative LLM agents and find that they remain highly susceptible to long-horizon attacks; moreover, defenses designed for single-turn interactions fail to reliably mitigate long-horizon threats. We anticipate that AgentLAB will serve as a valuable benchmark for tracking progress on securing LLM agents in practical settings. The benchmark is publicly available at https://tanqiujiang.github.io/AgentLAB_main.

</details>


### [11] [Narrow fine-tuning erodes safety alignment in vision-language agents](https://arxiv.org/abs/2602.16931)
*Idhant Gulati,Shivam Raval*

Main category: cs.AI

TL;DR: 라이프롱 다중 모드 에이전트는 새로운 작업에 적응해야 하지만, 이는 능력 습득과 안전 정렬 유지 간의 긴장을 초래합니다. 이 연구는 특정 해로운 데이터 세트에서 훈련된 모델이 심각한 비정렬을 초래한다는 것을 보여주며, 이러한 비정렬은 무관한 작업과 모드에 걸쳐 일반화됩니다.


<details>
  <summary>Details</summary>
Motivation: 라이프롱 다중 모드 에이전트의 안전성을 보장하면서도 새로운 작업에 적응할 수 있는 방법을 찾기 위함.

Method: Gemma3-4B 모델에서 좁은 도메인의 해로운 데이터 세트로 미세 조정을 통해 비정렬 정도를 실험하였습니다.

Result: LoRA 랭크에 따라 비정렬이 단조롭게 증가하며, 다중 모드 평가에서 텍스트 전용 평가보다 비정렬이 상당히 높습니다. 훈련 혼합물에서 10%의 해로운 데이터만으로도 상당한 비정렬 저하가 발생합니다.

Conclusion: 현재의 후처리 교육 패러다임은 배포 후 설정에서의 정렬을 충분히 유지하지 못할 수 있으므로, 강력한 지속적 학습 프레임워크가 필요합니다.

Abstract: Lifelong multimodal agents must continuously adapt to new tasks through post-training, but this creates fundamental tension between acquiring capabilities and preserving safety alignment. We demonstrate that fine-tuning aligned vision-language models on narrow-domain harmful datasets induces severe emergent misalignment that generalizes broadly across unrelated tasks and modalities. Through experiments on Gemma3-4B, we show that misalignment scales monotonically with LoRA rank, and that multimodal evaluation reveals substantially higher misalignment ($70.71 \pm 1.22$ at $r=128$) than text-only evaluation ($41.19 \pm 2.51$), suggesting that unimodal safety benchmarks may underestimate alignment degradation in vision-language models. Critically, even 10\% harmful data in the training mixture induces substantial alignment degradation. Geometric analysis reveals that harmful behaviors occupy a remarkably low-dimensional subspace, with the majority of misalignment information captured in 10 principal components. To mitigate misalignment, we evaluate two strategies: benign narrow fine-tuning and activation-based steering. While both approaches substantially reduce misalignment, neither completely removes the learned harmful behaviors. Our findings highlight the need for robust continual learning frameworks, as current post-training paradigms may not sufficiently preserve alignment in post-deployment settings.

</details>


### [12] [Automating Agent Hijacking via Structural Template Injection](https://arxiv.org/abs/2602.16958)
*Xinhao Deng,Jiaqing Wu,Miao Chen,Yue Xiao,Ke Xu,Qi Li*

Main category: cs.AI

TL;DR: 본 논문에서는 구조적 템플릿 주입을 기반으로 한 자동화된 에이전트 하이재킹 프레임워크인 Phantom을 제안한다. 이 프레임워크는 LLM 에이전트의 근본적인 아키텍처 메커니즘을 겨냥하여 에이전트 혼란을 유도하고, 공격 전이 가능성을 높이는 새로운 템플릿 탐색 프레임워크를 도입한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM) 생태계에 대한 주요 위협으로 강조된 에이전트 하이재킹의 문제를 해결하고, 기존 수동 프롬프트 조작의 한계를 극복하기 위해.

Method: 구조적 템플릿 주입을 기반으로 한 Phantom 프레임워크를 개발하고, 멀티 레벨 템플릿 증강 및 템플릿 자동인코더를 통해 최적의 적대 벡터를 식별하는 방법을 사용한다.

Result: Qwen, GPT 및 Gemini에서 기존 기준을 뛰어넘는 공격 성공률 및 쿼리 효율성을 보여주고, 상업 제품에서 70개 이상의 취약점을 식별했다.

Conclusion: 구조적 템플릿 기반 하이재킹의 실질적인 심각성을 강조하고, 차세대 에이전틱 시스템 보안을 위한 경험적 기초를 제공한다.

Abstract: Agent hijacking, highlighted by OWASP as a critical threat to the Large Language Model (LLM) ecosystem, enables adversaries to manipulate execution by injecting malicious instructions into retrieved content. Most existing attacks rely on manually crafted, semantics-driven prompt manipulation, which often yields low attack success rates and limited transferability to closed-source commercial models. In this paper, we propose Phantom, an automated agent hijacking framework built upon Structured Template Injection that targets the fundamental architectural mechanisms of LLM agents. Our key insight is that agents rely on specific chat template tokens to separate system, user, assistant, and tool instructions. By injecting optimized structured templates into the retrieved context, we induce role confusion and cause the agent to misinterpret the injected content as legitimate user instructions or prior tool outputs. To enhance attack transferability against black-box agents, Phantom introduces a novel attack template search framework. We first perform multi-level template augmentation to increase structural diversity and then train a Template Autoencoder (TAE) to embed discrete templates into a continuous, searchable latent space. Subsequently, we apply Bayesian optimization to efficiently identify optimal adversarial vectors that are decoded into high-potency structured templates. Extensive experiments on Qwen, GPT, and Gemini demonstrate that our framework significantly outperforms existing baselines in both Attack Success Rate (ASR) and query efficiency. Moreover, we identified over 70 vulnerabilities in real-world commercial products that have been confirmed by vendors, underscoring the practical severity of structured template-based hijacking and providing an empirical foundation for securing next-generation agentic systems.

</details>


### [13] [M2F: Automated Formalization of Mathematical Literature at Scale](https://arxiv.org/abs/2602.17016)
*Zichen Wang,Wanli Ma,Zhenyu Ming,Gong Zhang,Kun Yuan,Zaiwen Wen*

Main category: cs.AI

TL;DR: M2F는 Lean에서 프로젝트 규모의 수학 formalization을 자동으로 수행하는 최초의 프레임워크로, 이론의 기초부터 완전 검증된 증명까지 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 수학의 자동 formalization은 기계적으로 검증할 수 있게 해주지만, 교과서나 연구 논문과 같은 대규모 문서로 확장하는 데에는 한계가 있다.

Method: M2F는 문서를 원자 블록으로 분할하고, 추론된 종속성을 통해 정렬한 뒤, 전체 프로젝트가 컴파일될 때까지 선언 스켈레톤을 수정하는 두 단계로 운영된다.

Result: M2F는 153,853줄의 Lean 라이브러리로 변환된 479페이지의 실제 해석 및 볼록 해석 교과서에서 긴 형식의 수학 출처를 자동으로 변환하였다.

Conclusion: 이 결과들은 대규모 수학 문헌의 자동 formalization이 실현 가능하다는 것을 보여준다.

Abstract: Automated formalization of mathematics enables mechanical verification but remains limited to isolated theorems and short snippets. Scaling to textbooks and research papers is largely unaddressed, as it requires managing cross-file dependencies, resolving imports, and ensuring that entire projects compile end-to-end. We present M2F (Math-to-Formal), the first agentic framework for end-to-end, project-scale autoformalization in Lean. The framework operates in two stages. The statement compilation stage splits the document into atomic blocks, orders them via inferred dependencies, and repairs declaration skeletons until the project compiles, allowing placeholders in proofs. The proof repair stage closes these holes under fixed signatures using goal-conditioned local edits. Throughout both stages, M2F keeps the verifier in the loop, committing edits only when toolchain feedback confirms improvement. In approximately three weeks, M2F converts long-form mathematical sources into a project-scale Lean library of 153,853 lines from 479 pages textbooks on real analysis and convex analysis, fully formalized as Lean declarations with accompanying proofs. This represents textbook-scale formalization at a pace that would typically require months or years of expert effort. On FATE-H, we achieve $96\%$ proof success (vs.\ $80\%$ for a strong baseline). Together, these results demonstrate that practical, large-scale automated formalization of mathematical literature is within reach. The full generated Lean code from our runs is available at https://github.com/optsuite/ReasBook.git.

</details>


### [14] [Sales Research Agent and Sales Research Bench](https://arxiv.org/abs/2602.17017)
*Deepanjan Bhol*

Main category: cs.AI

TL;DR: 본 논문은 맞춤형 CRM 데이터에 대한 판매 리더 질문에 답변할 수 있는 AI 시스템의 필요성과, Microsoft Dynamics 365 Sales의 Sales Research Agent가 제공하는 솔루션을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 기업들이 실시간 맞춤형 CRM 데이터에 대해 판매 리더 질문에 답할 수 있는 AI 시스템의 필요성이 증가하고 있지만, 예전 모델들은 품질에 대한 투명하고 반복 가능한 증거를 제공하지 않는다.

Method: Microsoft Dynamics 365 Sales의 Sales Research Agent는 실시간 CRM 및 관련 데이터에 연결하고 복잡한 스키마에 대해 추론하며, 텍스트 및 차트 출력을 통해 의사결정 가능한 인사이트를 생성하는 AI 중심의 애플리케이션이다. Additionally, Sales Research Bench라는 목적에 맞게 제작된 벤치마크를 도입하여 텍스트 및 차트의 기반성, 관련성, 설명 가능성, 스키마 정확성 및 차트 품질을 포함한 8개의 고객 가중 차원에서 시스템을 평가한다.

Result: 2025년 10월 19일에 커스터마이즈된 기업 스키마에 대한 200문제 시행에서, Sales Research Agent는 100점 짜리 복합 점수에서 Claude Sonnet 4.5보다 13점, ChatGPT-5보다 24.1점 높은 성과를 거두며, 고객들이 AI 솔루션을 비교할 수 있는 반복 가능한 방법을 제공한다.

Conclusion: Sales Research Agent는 기업들이 AI 솔루션을 평가하고 비교하는 데 유용한 도구를 제공하며, AI 시스템의 품질을 관찰할 수 있는 방법을 제시한다.

Abstract: Enterprises increasingly need AI systems that can answer sales-leader questions over live, customized CRM data, but most available models do not expose transparent, repeatable evidence of quality. This paper describes the Sales Research Agent in Microsoft Dynamics 365 Sales, an AI-first application that connects to live CRM and related data, reasons over complex schemas, and produces decision-ready insights through text and chart outputs. To make quality observable, we introduce the Sales Research Bench, a purpose-built benchmark that scores systems on eight customer-weighted dimensions, including text and chart groundedness, relevance, explainability, schema accuracy, and chart quality. In a 200-question run on a customized enterprise schema on October 19, 2025, the Sales Research Agent outperformed Claude Sonnet 4.5 by 13 points and ChatGPT-5 by 24.1 points on the 100-point composite score, giving customers a repeatable way to compare AI solutions.

</details>


### [15] [Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.17062)
*Yonghyeon Jo,Sunwoo Lee,Seungyul Han*

Main category: cs.AI

TL;DR: Successive Sub-value Q-learning (S2Q)은 협력적 다중 에이전트 강화 학습에서 가치 분해 문제를 해결하기 위해 여러 서브 가치 함수 학습을 도입하여 다양한 고가치 행동을 유지하며, 실험을 통해 여러 기존 알고리즘보다 우수한 적응력을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존의 가치 분해 방법은 단일 최적 행동에 의존하고 훈련 중 가치 함수가 변화할 때 적응하는 데 어려움이 있어, 서브 최적 정책으로 수렴하는 문제가 있었다.

Method: S2Q는 여러 서브 가치 함수를 학습하여 대체 고가치 행동을 유지하며, 이 서브 가치 함수를 Softmax 기반의 행동 정책에 통합하여 지속적인 탐색을 장려하고, 변화하는 최적에 빠르게 적응할 수 있게 한다.

Result: S2Q는 도전적인 MARL 벤치마크에서 다양한 MARL 알고리즘보다 일관되게 우수한 성능을 보여주었으며 이는 향상된 적응력과 전체 성능을 입증한다.

Conclusion: 코드는 https://github.com/hyeon1996/S2Q 에서 확인할 수 있다.

Abstract: Value decomposition is a core approach for cooperative multi-agent reinforcement learning (MARL). However, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal policies. To address this limitation, we propose Successive Sub-value Q-learning (S2Q), which learns multiple sub-value functions to retain alternative high-value actions. Incorporating these sub-value functions into a Softmax-based behavior policy, S2Q encourages persistent exploration and enables $Q^{\text{tot}}$ to adjust quickly to the changing optima. Experiments on challenging MARL benchmarks confirm that S2Q consistently outperforms various MARL algorithms, demonstrating improved adaptability and overall performance. Our code is available at https://github.com/hyeon1996/S2Q.

</details>


### [16] [From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences](https://arxiv.org/abs/2602.17221)
*Yi-Chih Huang*

Main category: cs.AI

TL;DR: 본 연구는 인문 사회 과학 연구를 위한 AI 에이전트 기반 협업 연구 워크플로우를 제안하고, 이를 타이완의 Claude.ai 사용 데이터를 통해 검증한다.


<details>
  <summary>Details</summary>
Motivation: Generative AI는 지식 작업을 재형성하고 있지만, 기존 연구는 주로 소프트웨어 공학과 자연 과학에 초점을 맞추고 있으며 인문학 및 사회 과학을 위한 방법론적 탐색은 제한적이다.

Method: 본 연구는 세 가지 원칙(작업 모듈화, 인간-AI 노동 분담, 검증 가능성)에 기반한 7단계 모듈형 워크플로우의 설계와 검증을 수행하고, AEI 타이완 데이터를 경험적으로 분석하여 워크플로우의 적용을 시연한다.

Result: 이 연구는 인문학 및 사회 과학 연구자들을 위한 재현 가능한 AI 협업 프레임워크를 제안하고, 인간-AI 협업의 세 가지 운영 모드(직접 실행, 반복 정제, 인간 주도)를 규명한다.

Conclusion: 이 연구는 연구 질문 형성, 이론적 해석, 맥락에 맞는 추론 및 윤리적 반성을 포함하여 인간 판단의 대체 불가능성을 드러내며, 단일 플랫폼 데이터, 단면 설계 및 AI 신뢰성 위험 등의 한계를 인정한다.

Abstract: Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a "methodological experiment," this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's Claude.ai usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index (AEI) serves as the empirical vehicle for validating the feasibility of this methodology.
  This study operates on two levels: the primary level is the design and validation of a methodological framework - a seven-stage modular workflow grounded in three principles: task modularization, human-AI division of labor, and verifiability, with each stage delineating clear roles for human researchers (research judgment and ethical decisions) and AI Agents (information retrieval and text generation); the secondary level is the empirical analysis of AEI Taiwan data - serving as an operational demonstration of the workflow's application to secondary data research, showcasing both the process and output quality (see Appendix A).
  This study contributes by proposing a replicable AI collaboration framework for humanities and social science researchers, and identifying three operational modes of human-AI collaboration - direct execution, iterative refinement, and human-led - through reflexive documentation of the operational process. This taxonomy reveals the irreplaceability of human judgment in research question formulation, theoretical interpretation, contextualized reasoning, and ethical reflection. Limitations including single-platform data, cross-sectional design, and AI reliability risks are acknowledged.

</details>


### [17] [WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation](https://arxiv.org/abs/2602.17442)
*Marco Avolio,Potito Aghilar,Sabino Roccotelli,Vito Walter Anelli,Chiara Mallamaci,Vincenzo Paparella,Marco Valentini,Alejandro Bellogín,Michelantonio Trizio,Joseph Trotta,Antonio Ferrara,Tommaso Di Noia*

Main category: cs.AI

TL;DR: WarpRec은 추천 시스템의 혁신을 촉진하는 고성능 프레임워크로, 분산 학습과 최적화를 원활하게 지원한다. 또한, 에너지 추적을 통합하여 생태적 책임성을 강화하며, 향후 에이전틱 AI로의 전환을 대비한다.


<details>
  <summary>Details</summary>
Motivation: 추천 시스템 연구자들은 메모리 내 실험과 비용이 많이 드는 분산 엔진 재작성 간의 선택에서 어려움을 겪고 있다.

Method: WarpRec은 백엔드에 구애받지 않는 아키텍처를 통해 50개 이상의 최첨단 알고리즘, 40개의 메트릭, 19개의 필터링 및 분할 전략을 제공하여 로컬 실행에서 분산 학습으로 원활하게 전환할 수 있게 한다.

Result: 이 프레임워크는 CodeCarbon을 통합해 실시간 에너지 추적을 실행하며, 지속 가능한 추천 시스템을 위한 다음 세대 아키텍처로 자리매김할 수 있다.

Conclusion: WarpRec은 학계와 산업 간의 간극을 해소하고, 에이전트 준비가 된 추천 시스템으로의 발전에도 기여한다.

Abstract: Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly transition from local execution to distributed training and optimization. The framework enforces ecological responsibility by integrating CodeCarbon for real-time energy tracking, showing that scalability need not come at the cost of scientific integrity or sustainability. Furthermore, WarpRec anticipates the shift toward Agentic AI, leading Recommender Systems to evolve from static ranking engines into interactive tools within the Generative AI ecosystem. In summary, WarpRec not only bridges the gap between academia and industry but also can serve as the architectural backbone for the next generation of sustainable, agent-ready Recommender Systems. Code is available at https://github.com/sisinflab/warprec/

</details>


### [18] [KLong: Training LLM Agent for Extremely Long-horizon Tasks](https://arxiv.org/abs/2602.17547)
*Yue Liu,Zhiyuan Hu,Flood Sung,Jiaheng Zhang,Bryan Hooi*

Main category: cs.AI

TL;DR: KLong은 매우 긴 수평 작업을 해결하도록 훈련된 오픈 소스 LLM 에이전트를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 극도로 긴 작업을 해결하기 위한 효율적인 LLM 에이전트를 개발하는 것이 필요합니다.

Method: 모델을 처음에 꺼내기 위해 궤적 분할 SFT를 통해 모델을 활성화하고, 점진적인 RL 훈련을 통해 모델을 확장합니다.

Result: KLong은 PaperBench에서 Kimi K2 Thinking보다 11.28% 성능이 향상되었습니다.

Conclusion: KLong은 다양한 코딩 벤치마크에서도 성능 개선을 나타내며, 탁월함과 일반화 능력을 보입니다.

Abstract: This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a comprehensive SFT recipe. Then, we introduce Research-Factory, an automated pipeline that generates high-quality training data by collecting research papers and constructing evaluation rubrics. Using this pipeline, we build thousands of long-horizon trajectories distilled from Claude 4.5 Sonnet (Thinking). To train with these extremely long trajectories, we propose a new trajectory-splitting SFT, which preserves early context, progressively truncates later context, and maintains overlap between sub-trajectories. In addition, to further improve long-horizon task-solving capability, we propose a novel progressive RL, which schedules training into multiple stages with progressively extended timeouts. Experiments demonstrate the superiority and generalization of KLong, as shown in Figure 1. Notably, our proposed KLong (106B) surpasses Kimi K2 Thinking (1T) by 11.28% on PaperBench, and the performance improvement generalizes to other coding benchmarks like SWE-bench Verified and MLE-bench.

</details>


### [19] [A Hybrid Federated Learning Based Ensemble Approach for Lung Disease Diagnosis Leveraging Fusion of SWIN Transformer and CNN](https://arxiv.org/abs/2602.17566)
*Asif Hasan Chowdhury,Md. Fahim Islam,M Ragib Anjum Riad,Faiyaz Bin Hashem,Md Tanzim Reza,Md. Golam Rabiul Alam*

Main category: cs.AI

TL;DR: 인공지능과 페더레이티드 러닝을 결합한 하이브리드 모델을 통해 COVID-19 및 폐렴 진단의 정확성을 향상시키는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 의료 데이터 처리 및 효율적인 시스템 구축을 위해 인공지능과 페더레이티드 러닝을 활용하고자 한다.

Method: 하이브리드 FL_ENABLED 앙상블 접근법을 통해 SWIN Transform 및 CNN을 결합하여 진단한다.

Result: COVID-19 및 폐렴을 X선 보고서를 기반으로 검출하고 정확성을 향상시킨다.

Conclusion: 연구는 페더레이티드 러닝 기반 하이브리드 AI 모델이 진단의 정확성과 환자 예측의 향상에 기여할 수 있음을 보여준다.

Abstract: The significant advancements in computational power cre- ate a vast opportunity for using Artificial Intelligence in different ap- plications of healthcare and medical science. A Hybrid FL-Enabled Ensemble Approach For Lung Disease Diagnosis Leveraging a Combination of SWIN Transformer and CNN is the combination of cutting-edge technology of AI and Federated Learning. Since, medi- cal specialists and hospitals will have shared data space, based on that data, with the help of Artificial Intelligence and integration of federated learning, we can introduce a secure and distributed system for medical data processing and create an efficient and reliable system. The proposed hybrid model enables the detection of COVID-19 and Pneumonia based on x-ray reports. We will use advanced and the latest available tech- nology offered by Tensorflow and Keras along with Microsoft-developed Vision Transformer, that can help to fight against the pandemic that the world has to fight together as a united. We focused on using the latest available CNN models (DenseNet201, Inception V3, VGG 19) and the Transformer model SWIN Transformer in order to prepare our hy- brid model that can provide a reliable solution as a helping hand for the physician in the medical field. In this research, we will discuss how the Federated learning-based Hybrid AI model can improve the accuracy of disease diagnosis and severity prediction of a patient using the real-time continual learning approach and how the integration of federated learn- ing can ensure hybrid model security and keep the authenticity of the information.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [20] [Self-Evolving Multi-Agent Network for Industrial IoT Predictive Maintenance](https://arxiv.org/abs/2602.16738)
*Rebin Saleh,Khanh Pham Dinh,Balázs Villányi,Truong-Son Hy*

Main category: cs.MA

TL;DR: SEMAS는 산업 IoT 예측 유지보수를 위한 자가 진화하는 계층적 다중 에이전트 시스템으로, 실시간 이상 탐지 기능을 제공하며 성능과 해석 가능성을 모두 충족한다.


<details>
  <summary>Details</summary>
Motivation: 산업 IoT의 예측 유지보수는 실시간 이상 탐지 기능이 필요하지만 해석 가능성이나 과도한 계산 자원을 요구하지 않는 시스템이 요구된다.

Method: SEMAS는 Edge, Fog 및 Cloud 컴퓨팅 계층에 전문화된 에이전트를 분산시키는 자가 진화하는 계층적 다중 에이전트 시스템이다. Edge 에이전트는 경량 피처 추출 및 전처리를 수행하고, Fog 에이전트는 동적인 합의 투표로 다양한 앙상블 탐지를 실행하며, Cloud 에이전트는 Proximal Policy Optimization (PPO)을 통해 시스템 정책을 지속적으로 최적화한다.

Result: SEMAS는 두 개의 산업 벤치마크(Boiler Emulator와 Wind Turbine)에서 뛰어난 이상 탐지 성능과 적응 시에도 뛰어난 안정성을 달성했으며, 진정한 실시간 배치를 가능하게 하는 상당한 지연 개선을 제공한다.

Conclusion: 자원 인식 및 자가 진화하는 다중 에이전트 조정은 엄격한 지연 및 해석 가능성 제약 하에서 생산 준비가 완료된 산업 IoT 예측 유지보수에 필수적이다.

Abstract: Industrial IoT predictive maintenance requires systems capable of real-time anomaly detection without sacrificing interpretability or demanding excessive computational resources. Traditional approaches rely on static, offline-trained models that cannot adapt to evolving operational conditions, while LLM-based monolithic systems demand prohibitive memory and latency, rendering them impractical for on-site edge deployment. We introduce SEMAS, a self-evolving hierarchical multi-agent system that distributes specialized agents across Edge, Fog, and Cloud computational tiers. Edge agents perform lightweight feature extraction and pre-filtering; Fog agents execute diversified ensemble detection with dynamic consensus voting; and Cloud agents continuously optimize system policies via Proximal Policy Optimization (PPO) while maintaining asynchronous, non-blocking inference. The framework incorporates LLM-based response generation for explainability and federated knowledge aggregation for adaptive policy distribution. This architecture enables resource-aware specialization without sacrificing real-time performance or model interpretability. Empirical evaluation on two industrial benchmarks (Boiler Emulator and Wind Turbine) demonstrates that SEMAS achieves superior anomaly detection performance with exceptional stability under adaptation, sustains prediction accuracy across evolving operational contexts, and delivers substantial latency improvements enabling genuine real-time deployment. Ablation studies confirm that PPO-driven policy evolution, consensus voting, and federated aggregation each contribute materially to system effectiveness. These findings indicate that resource-aware, self-evolving 1multi-agent coordination is essential for production-ready industrial IoT predictive maintenance under strict latency and explainability constraints.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [21] [NESSiE: The Necessary Safety Benchmark -- Identifying Errors that should not Exist](https://arxiv.org/abs/2602.16756)
*Johannes Bertram,Jonas Geiping*

Main category: cs.CR

TL;DR: NESSiE는 대형 언어 모델의 안전성을 평가하기 위한 경량화된 벤치마크로, 최소한의 테스트 케이스를 통해 안전 관련 실패를 드러낸다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 안전성을 검증하고 배포 전 필요한 테스트 조건을 제시하기 위함이다.

Method: 안전성 관련 실패를 평가하는 간단한 테스트 케이스를 사용하여 모델의 성능을 측정한다.

Result: 최신 LLM조차 NESSiE에서 100%를 달성하지 못하고 있으며, 안전 조건을 충족하지 못하고 있다. 또한 SH 메트릭을 사용하여 모델이 안전보다 유용성에 편향되어 있음을 보여준다.

Conclusion: 이 연구는 자율 에이전트로서 모델을 배포하는 데 따른 위험을 강조하며, 안전성 보장을 위한 추가적인 검증 필요성을 지적한다.

Abstract: We introduce NESSiE, the NEceSsary SafEty benchmark for large language models (LLMs). With minimal test cases of information and access security, NESSiE reveals safety-relevant failures that should not exist, given the low complexity of the tasks. NESSiE is intended as a lightweight, easy-to-use sanity check for language model safety and, as such, is not sufficient for guaranteeing safety in general -- but we argue that passing this test is necessary for any deployment. However, even state-of-the-art LLMs do not reach 100% on NESSiE and thus fail our necessary condition of language model safety, even in the absence of adversarial attacks. Our Safe & Helpful (SH) metric allows for direct comparison of the two requirements, showing models are biased toward being helpful rather than safe. We further find that disabled reasoning for some models, but especially a benign distraction context degrade model performance. Overall, our results underscore the critical risks of deploying such models as autonomous agents in the wild. We make the dataset, package and plotting code publicly available.

</details>


### [22] [BMC4TimeSec: Verification Of Timed Security Protocols](https://arxiv.org/abs/2602.17590)
*Agnieszka M. Zbrzezny*

Main category: cs.CR

TL;DR: BMC4TimeSec는 SMT 기반의 제한 모델 검증과 시간 해석 시스템을 이용해 시간 보안 프로토콜을 검증하는 도구이다.


<details>
  <summary>Details</summary>
Motivation: 시간 보안 프로토콜의 정확한 검증을 위한 강력한 도구의 필요성.

Method: SMT 기반의 제한 모델 검증과 다중 에이전트 모델링을 통해 TIS 및 TIIS 형태로 프로토콜을 모델링함.

Result: BMC4TimeSec는 TSP 실행을 TIS/TIIS 환경 내에서 구현하고, 에이전트의 행동을 지식 오토마타로 모델링함.

Conclusion: BMC4TimeSec는 시간 보안 프로토콜 검증을 위한 유용한 도구로서 공용 코드를 제공하고 있다.

Abstract: We present BMC4TimeSec, an end-to-end tool for verifying Timed Security Protocols (TSP) based on SMT-based bounded model checking and multi-agent modelling in the form of Timed Interpreted Systems (TIS) and Timed Interleaved Interpreted Systems (TIIS). In BMC4TimeSec, TSP executions implement the TIS/TIIS environment (join actions, interleaving, delays, lifetimes), and knowledge automata implement the agents (evolution of participant knowledge, including the intruder). The code is publicly available on \href{https://github.com/agazbrzezny/BMC4TimeSec}{GitHub}, as is a \href{https://youtu.be/aNybKz6HwdA}{video} demonstration.

</details>


### [23] [What Makes a Good LLM Agent for Real-world Penetration Testing?](https://arxiv.org/abs/2602.17622)
*Gelei Deng,Yi Liu,Yuekang Li,Ruozhao Yang,Xiaofei Xie,Jie Zhang,Han Qiu,Tianwei Zhang*

Main category: cs.CR

TL;DR: LLM 기반 침투 테스트 에이전트는 자동화 가능성이 있지만 성능이 다양한 시스템과 벤치마크에서 크게 다릅니다. 28개의 LLM 기반 침투 테스트 시스템을 분석하고 5개의 대표적인 구현을 세 가지 복잡도 벤치마크에서 평가했습니다. 두 가지 실패 모드를 발견했으며, 이에 대한 해결책인 Excalibur라는 에이전트를 제시했습니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 침투 테스트의 성능이 시스템과 벤치마크에 따라 다르기 때문에 분석이 필요합니다.

Method: 28개의 LLM 기반 침투 테스트 시스템을 분석하고 5개의 구현을 통해 3개의 복잡도 벤치마크에서 평가했습니다. Type A와 Type B 두 가지 실패 모드를 식별했습니다. Excalibur라는 에이전트를 제안했으며, 도구 및 기술 계층과 작업 난이도 평가 메커니즘을 포함합니다.

Result: Excalibur는 CTF 벤치마크에서 최대 91%의 작업 완료율을 달성했으며, GOAD Active Directory 환경에서는 5개 호스트 중 4개를 타격했습니다. 이전 시스템에 비해 상대적으로 39%에서 49% 개선되었습니다.

Conclusion: 난이도 인식 계획이 일관된 끝에서 끝까지의 이점을 가져오며 모델 스케일링의 한계를 극복합니다.

Abstract: LLM-based agents show promise for automating penetration testing, yet reported performance varies widely across systems and benchmarks. We analyze 28 LLM-based penetration testing systems and evaluate five representative implementations across three benchmarks of increasing complexity. Our analysis reveals two distinct failure modes: Type A failures stem from capability gaps (missing tools, inadequate prompts) that engineering readily addresses, while Type B failures persist regardless of tooling due to planning and state management limitations. We show that Type B failures share a root cause that is largely invariant to the underlying LLM: agents lack real-time task difficulty estimation. As a result, agents misallocate effort, over-commit to low-value branches, and exhaust context before completing attack chains.
  Based on this insight, we present Excalibur, a penetration testing agent that couples strong tooling with difficulty-aware planning. A Tool and Skill Layer eliminates Type A failures through typed interfaces and retrieval-augmented knowledge. A Task Difficulty Assessment (TDA) mechanism addresses Type B failures by estimating tractability through four measurable dimensions (horizon estimation, evidence confidence, context load, and historical success) and uses these estimates to guide exploration-exploitation decisions within an Evidence-Guided Attack Tree Search (EGATS) framework. Excalibur achieves up to 91% task completion on CTF benchmarks with frontier models (39 to 49% relative improvement over baselines) and compromises 4 of 5 hosts on the GOAD Active Directory environment versus 2 by prior systems. These results show that difficulty-aware planning yields consistent end-to-end gains across models and addresses a limitation that model scaling alone does not eliminate.

</details>
