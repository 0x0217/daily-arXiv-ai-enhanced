<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 19]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 17]
- [cs.CR](#cs.CR) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Human-AI Co-Embodied Intelligence for Scientific Experimentation and Manufacturing](https://arxiv.org/abs/2511.02071)
*Xinyi Lin,Yuyang Zhang,Yuanhang Gan,Juntao Chen,Hao Shen,Yichun He,Lijun Li,Ze Yuan,Shuang Wang,Chaohao Wang,Rui Zhang,Na Li,Jia Liu*

Main category: cs.AI

TL;DR: 인간과 AI가 결합된 새로운 물리적 AI 형태인 인간-AI 공동 지능을 소개하며, 이는 과학 실험 및 제조에 있어 인간의 전문성과 AI의 인지 능력을 통합하는 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 기계 학습 및 자동화가 현실 세계의 실험 및 제조에서 여전히 인간의 감독과 전문성을 필요로 하고 있기 때문에, 이 간극이 재현성, 확장성, 접근성을 제한한다.

Method: 인간-AI 공동 지능 시스템을 통해 인간은 정밀한 실행과 제어를 제공하고, 에이전틱 AI는 메모리, 맥락적 추론, 적응적 계획 및 실시간 피드백을 제공한다.

Result: APEX 시스템은 인간의 행동을 관찰 및 해석하고, 표준 운영 절차에 맞춰 정렬하며, 3D 시각적 안내를 제공하고 각 단계를 분석한다. 이 시스템은 유연한 전자 제조를 위한 클린룸에 구현되어 정확한 맥락 인식을 달성한다.

Conclusion: 이 결과는 에이전틱 추론을 계산을 넘어 물리적 영역으로 확장시키는 새로운 클래스의 에이전틱-물리적-인간 지능을 확립하여 과학 연구와 제조를 자율적이고 추적 가능하며 해석 가능하고 확장 가능한 프로세스로 변화시킨다.

Abstract: Scientific experiment and manufacture rely on complex, multi-step procedures
that demand continuous human expertise for precise execution and
decision-making. Despite advances in machine learning and automation,
conventional models remain confined to virtual domains, while real-world
experiment and manufacture still rely on human supervision and expertise. This
gap between machine intelligence and physical execution limits reproducibility,
scalability, and accessibility across scientific and manufacture workflows.
Here, we introduce human-AI co-embodied intelligence, a new form of physical AI
that unites human users, agentic AI, and wearable hardware into an integrated
system for real-world experiment and intelligent manufacture. In this paradigm,
humans provide precise execution and control, while agentic AI contributes
memory, contextual reasoning, adaptive planning, and real-time feedback. The
wearable interface continuously captures the experimental and manufacture
processes, facilitates seamless communication between humans and AI for
corrective guidance and interpretable collaboration. As a demonstration, we
present Agentic-Physical Experimentation (APEX) system, coupling agentic
reasoning with physical execution through mixed-reality. APEX observes and
interprets human actions, aligns them with standard operating procedures,
provides 3D visual guidance, and analyzes every step. Implemented in a
cleanroom for flexible electronics fabrication, APEX system achieves
context-aware reasoning with accuracy exceeding general multimodal large
language models, corrects errors in real time, and transfers expertise to
beginners. These results establish a new class of agentic-physical-human
intelligence that extends agentic reasoning beyond computation into the
physical domain, transforming scientific research and manufacturing into
autonomous, traceable, interpretable, and scalable processes.

</details>


### [2] [Automated Reward Design for Gran Turismo](https://arxiv.org/abs/2511.02094)
*Michel Ma,Takuma Seno,Kaushik Subramanian,Peter R. Wurman,Peter Stone,Craig Sherstan*

Main category: cs.AI

TL;DR: 이 논문에서는 Gran Turismo 7 레이싱 게임을 위해 텍스트 기반 지침만으로 바람직한 RL 에이전트를 생성하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습(RL) 에이전트를 설계할 때, 보상 함수의 정의를 통해 원하는 에이전트 행동을 전달하는 것이 필요하다.

Method: 기존의 기초 모델을 사용하여 보상 함수의 공간을 효과적으로 탐색하고, LLM 기반 보상 생성, VLM 선호 기반 평가 및 인간 피드백의 조합을 통해 RL 에이전트를 생성한다.

Result: 시스템을 사용하여 챔피언 수준의 RL 레이싱 에이전트인 GT Sophy와 경쟁할 수 있는 레이싱 에이전트를 생성하고, 새로운 행동을 창출할 수 있음을 보여준다.

Conclusion: 현실 세계 애플리케이션에서의 자동화된 보상 디자인을 위한 새로운 가능성을 열어준다.

Abstract: When designing reinforcement learning (RL) agents, a designer communicates
the desired agent behavior through the definition of reward functions -
numerical feedback given to the agent as reward or punishment for its actions.
However, mapping desired behaviors to reward functions can be a difficult
process, especially in complex environments such as autonomous racing. In this
paper, we demonstrate how current foundation models can effectively search over
a space of reward functions to produce desirable RL agents for the Gran Turismo
7 racing game, given only text-based instructions. Through a combination of
LLM-based reward generation, VLM preference-based evaluation, and human
feedback we demonstrate how our system can be used to produce racing agents
competitive with GT Sophy, a champion-level RL racing agent, as well as
generate novel behaviors, paving the way for practical automated reward design
in real world applications.

</details>


### [3] [InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance](https://arxiv.org/abs/2511.02119)
*Ziheng Geng,Jiachen Liu,Ran Cao,Lu Cheng,Dan M. Frangopol,Minghui Cheng*

Main category: cs.AI

TL;DR: 홍수 보험은 재해로 인한 손실을 줄이기 위한 효과적인 전략이지만, 미국의 위험군 인구에서 참여율이 낮다. 본 연구는 보험 결정의 행동 메커니즘을 이해하고 모델링할 필요성을 강조하며, 대형 언어 모델(LLM)을 활용해 보험 구매 확률을 추정하고, 이를 위한 InsurAgent라는 LLM 기반 에이전트를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 재해 관련 손실을 완화하기 위한 개인의 홍수 보험 참여율이 낮아지는 문제를 해결하기 위해, 보험 결정의 행동 메커니즘을 이해하고 모델링할 필요가 있다.

Method: 유형적 이해는 있지만 정량적 확률 추정에서 부족한 LLM의 한계를 극복하기 위해, 인식, 검색, 추론, 행동 및 기억의 다섯 가지 모듈로 구성된 LLM 지원 에이전트 InsurAgent를 제안한다. 검색 모듈은 실증 조사 데이터를 기반으로 결정을 내리기 위해 검색 증강 생성(RAG)을 활용하여 한계 및 이변량 확률을 정확하게 추정한다.

Result: InsurAgent는 LLM의 일반 상식을 활용하여 조사 데이터를 넘어서는 추론을 가능하게 하며, 전통적인 모델로는 포착할 수 없는 맥락 정보를 포착한다.

Conclusion: 전반적으로 InsurAgent는 행동 모델링 및 정책 분석을 위한 귀중한 도구를 제공한다.

Abstract: Flood insurance is an effective strategy for individuals to mitigate
disaster-related losses. However, participation rates among at-risk populations
in the United States remain strikingly low. This gap underscores the need to
understand and model the behavioral mechanisms underlying insurance decisions.
Large language models (LLMs) have recently exhibited human-like intelligence
across wide-ranging tasks, offering promising tools for simulating human
decision-making. This study constructs a benchmark dataset to capture insurance
purchase probabilities across factors. Using this dataset, the capacity of LLMs
is evaluated: while LLMs exhibit a qualitative understanding of factors, they
fall short in estimating quantitative probabilities. To address this
limitation, InsurAgent, an LLM-empowered agent comprising five modules
including perception, retrieval, reasoning, action, and memory, is proposed.
The retrieval module leverages retrieval-augmented generation (RAG) to ground
decisions in empirical survey data, achieving accurate estimation of marginal
and bivariate probabilities. The reasoning module leverages LLM common sense to
extrapolate beyond survey data, capturing contextual information that is
intractable for traditional models. The memory module supports the simulation
of temporal decision evolutions, illustrated through a roller coaster life
trajectory. Overall, InsurAgent provides a valuable tool for behavioral
modeling and policy analysis.

</details>


### [4] [Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning](https://arxiv.org/abs/2511.02194)
*Yibo Zhao,Yang Zhao,Hongru Du,Hao Frank Yang*

Main category: cs.AI

TL;DR: ATHENA는 개인의 의사결정을 최적화하기 위한 새로운 프레임워크로, 전체 집단의 유틸리티 기능과 개인의 의미적 적응을 결합하여 예측 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 개인 의사결정 모델이 집단 최적 예측과 차이를 보이는 이유를 분석하고 개선하고자 한다.

Method: 유틸리티 이론을 바탕으로 LLM의 텍스트 추론 능력을 활용하여 두 단계를 통합한 ATHENA 프레임워크를 제안한다.

Result: ATHENA는 실제 여행 방식 및 백신 선택 작업에서 기존 모델보다 F1 점수를 최소 6.5% 향상시킨다.

Conclusion: ATHENA는 상징적 유틸리티 모델링과 의미적 적응을 유기적으로 통합하여 인간 중심의 의사결정을 모델링하는 새로운 방안을 제시한다.

Abstract: Decision-making models for individuals, particularly in high-stakes scenarios
like vaccine uptake, often diverge from population optimal predictions. This
gap arises from the uniqueness of the individual decision-making process,
shaped by numerical attributes (e.g., cost, time) and linguistic influences
(e.g., personal preferences and constraints). Developing upon Utility Theory
and leveraging the textual-reasoning capabilities of Large Language Models
(LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric
Reasoning framework (ATHENA) to address the optimal information integration.
ATHENA uniquely integrates two stages: First, it discovers robust, group-level
symbolic utility functions via LLM-augmented symbolic discovery; Second, it
implements individual-level semantic adaptation, creating personalized semantic
templates guided by the optimal utility to model personalized choices.
Validated on real-world travel mode and vaccine choice tasks, ATHENA
consistently outperforms utility-based, machine learning, and other LLM-based
models, lifting F1 score by at least 6.5% over the strongest cutting-edge
models. Further, ablation studies confirm that both stages of ATHENA are
critical and complementary, as removing either clearly degrades overall
predictive performance. By organically integrating symbolic utility modeling
and semantic adaptation, ATHENA provides a new scheme for modeling
human-centric decisions. The project page can be found at
https://yibozh.github.io/Athena.

</details>


### [5] [Optimal-Agent-Selection: State-Aware Routing Framework for Efficient Multi-Agent Collaboration](https://arxiv.org/abs/2511.02200)
*Jingbo Wang,Sendong Zhao,Haochun Wang,Yuzheng Fan,Lizhe Zhang,Yan Liu,Ting Liu*

Main category: cs.AI

TL;DR: 이 논문에서는 다중 에이전트 시스템의 효율적인 협업을 위한 상태 인식 라우팅 프레임워크인 STRMAC을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM으로 구동되는 다중 에이전트 시스템의 잠재력을 극대화하고자 함.

Method: 상호작용 기록과 에이전트 지식을 별도로 인코딩하여 라우터를 구동하고, 각 단계에서 가장 적합한 에이전트를 선택하는 방식으로 협업을 수행.

Result: 실험 결과, 우리 방법이 최첨단 성능을 달성했으며, 기초 성능 대비 최대 23.8% 향상과 데이터 수집 오버헤드를 최대 90.1% 감소시켰습니다.

Conclusion: 우리의 방법은 복잡한 협력적 추론 과제에서 효율성과 효과성을 크게 개선합니다.

Abstract: The emergence of multi-agent systems powered by large language models (LLMs)
has unlocked new frontiers in complex task-solving, enabling diverse agents to
integrate unique expertise, collaborate flexibly, and address challenges
unattainable for individual models. However, the full potential of such systems
is hindered by rigid agent scheduling and inefficient coordination strategies
that fail to adapt to evolving task requirements. In this paper, we propose
STRMAC, a state-aware routing framework designed for efficient collaboration in
multi-agent systems. Our method separately encodes interaction history and
agent knowledge to power the router, which adaptively selects the most suitable
single agent at each step for efficient and effective collaboration.
Furthermore, we introduce a self-evolving data generation approach that
accelerates the collection of high-quality execution paths for efficient system
training. Experiments on challenging collaborative reasoning benchmarks
demonstrate that our method achieves state-of-the-art performance, achieving up
to 23.8% improvement over baselines and reducing data collection overhead by up
to 90.1% compared to exhaustive search.

</details>


### [6] [Training Proactive and Personalized LLM Agents](https://arxiv.org/abs/2511.02208)
*Weiwei Sun,Xuhui Zhou,Weihua Du,Xingyao Wang,Sean Welleck,Graham Neubig,Maarten Sap,Yiming Yang*

Main category: cs.AI

TL;DR: 이 논문은 태스크 성공을 넘어서 생산성, 적극성, 개인화의 세 가지 차원을 최적화하는 것이 효과적인 실제 세계 에이전트에 중요하다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 주로 태스크 성공에 초점을 맞추고 있지만, 효과적인 AI 에이전트를 위해서는 생산성, 적극성 및 개인화의 세 가지 차원을 최적화해야 함을 제안한다.

Method: UserVille이라는 대화형 환경을 소개하고, PPP라는 다중 목표 강화 학습 접근법을 제안하여 생산성, 적극성 및 개인화를 동시에 최적화한다.

Result: 소프트웨어 공학 및 심층 연구 과제에 대한 실험 결과, PPP로 훈련된 에이전트가 GPT-5와 같은 강력한 기준선에 비해 평균 21.6%의 상당한 개선을 달성하였다.

Conclusion: 사용자 중심의 상호작용을 명시적으로 최적화하는 것이 실용적이고 효과적인 AI 에이전트를 구축하는 데 중요하다는 것을 보여준다.

Abstract: While existing work focuses primarily on task success, we argue that
effective real-world agents require optimizing three dimensions: productivity
(task completion), proactivity (asking essential questions), and
personalization (adapting to diverse user preferences). We introduce UserVille,
an interactive environment with LLM-based user simulators enabling diverse,
configurable user preferences. Leveraging UserVille, we introduce PPP, a
multi-objective reinforcement learning approach that jointly optimizes all
three dimensions: Productivity, Proactivity, and Personalization. Experiments
on software engineering and deep research tasks show that agents trained with
PPP achieve substantial improvements over strong baselines such as GPT-5 (+21.6
on average), demonstrating the ability to ask strategic clarifying questions,
adapt to unseen user preferences, and improve task success through better
interaction. This work demonstrates that explicitly optimizing for
user-centered interaction is critical for building practical and effective AI
agents.

</details>


### [7] [Deep Ideation: Designing LLM Agents to Generate Novel Research Ideas on Scientific Concept Network](https://arxiv.org/abs/2511.02238)
*Keyu Zhao,Weiquan Lin,Qirui Zheng,Fengli Xu,Yong Li*

Main category: cs.AI

TL;DR: 이 논문은 Large Language Models (LLMs)를 활용해 연구 아이디어를 생성하는 새로운 방법인 Deep Ideation 프레임워크를 제안하며, 과학적 네트워크를 통합하여 기존 아이디어 생성 방법보다 더 높은 품질의 연구 아이디어를 도출한다.


<details>
  <summary>Details</summary>
Motivation: 새로운 연구 아이디어는 과학적 탐구를 발전시키는 데 중요한 역할을 한다. LLM의 발전은 대규모 과학 문헌을 활용하여 새로운 연구 아이디어를 생성할 잠재력을 보여주었다.

Method: Deep Ideation 프레임워크를 제안하여 키워드 동시 발생 및 맥락적 관계를 캡처하는 과학적 네트워크를 통합하고, Idea Stack을 사용하여 연구 아이디어를 반복적으로 다듬는 explore-expand-evolve 워크플로우를 도입한다.

Result: 이 방법은 다른 방법들과 비교하여 생성된 아이디어의 품질을 10.67% 향상시키며, 아이디어는 최고 학회 수용 수준을 초과한다.

Conclusion: 인간 평가에서 과학적 연구에서의 실제 가치를 강조하며, 아블레이션 연구를 통해 워크플로우의 각 구성 요소의 효과를 확인하였다.

Abstract: Novel research ideas play a critical role in advancing scientific inquiries.
Recent advancements in Large Language Models (LLMs) have demonstrated their
potential to generate novel research ideas by leveraging large-scale scientific
literature. However, previous work in research ideation has primarily relied on
simplistic methods, such as keyword co-occurrence or semantic similarity. These
approaches focus on identifying statistical associations in the literature but
overlook the complex, contextual relationships between scientific concepts,
which are essential to effectively leverage knowledge embedded in human
literature. For instance, papers that simultaneously mention "keyword A" and
"keyword B" often present research ideas that integrate both concepts.
Additionally, some LLM-driven methods propose and refine research ideas using
the model's internal knowledge, but they fail to effectively utilize the
scientific concept network, limiting the grounding of ideas in established
research. To address these challenges, we propose the Deep Ideation framework
to address these challenges, integrating a scientific network that captures
keyword co-occurrence and contextual relationships, enriching LLM-driven
ideation. The framework introduces an explore-expand-evolve workflow to
iteratively refine research ideas, using an Idea Stack to track progress. A
critic engine, trained on real-world reviewer feedback, guides the process by
providing continuous feedback on the novelty and feasibility of ideas. Our
experiments show that our approach improves the quality of generated ideas by
10.67% compared to other methods, with ideas surpassing top conference
acceptance levels. Human evaluation highlights their practical value in
scientific research, and ablation studies confirm the effectiveness of each
component in the workflow. Code repo is available at
https://github.com/kyZhao-1/Deep-Ideation.

</details>


### [8] [When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal Reasoning](https://arxiv.org/abs/2511.02794)
*Chenyu Zhang,Minsol Kim,Shohreh Ghorbani,Jingyao Wu,Rosalind Picard,Patricia Maes,Paul Pu Liang*

Main category: cs.AI

TL;DR: 멀티모달 대형 언어 모델(MLLMs)의 추론 과정이 불투명한 가운데, 본 논문에서는 높은 신뢰도의 단일 모달 오류가 다른 증거를 압도하여 잘못된 결과를 초래하는 "모달리티 사보타주"를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 대형 언어 모델의 예측 과정에서 각 모달이 어떻게 작용하는지를 이해하기 위한 필요성이 있습니다.

Method: 각 모달을 에이전트로 취급하여 후보 레이블과 감사에 사용되는 간단한 자기 평가를 생성하는 경량 모델 비독립적 평가 레이어를 제안합니다. 간단한 융합 메커니즘이 이러한 출력을 집계하여 올바른 결과를 지원하는 기여자와 잘못된 안내를 하는 사보타주를 노출합니다.

Result: 멀티모달 감정 인식 기준에 대한 사례 연구에서 진단 레이어를 적용한 결과, 체계적인 신뢰성 프로필이 드러났습니다.

Conclusion: 우리의 프레임워크는 멀티모달 추론에 대한 진단 구조를 제공하여 융합 역학의 원칙적인 감사를 지원하고 가능한 개입에 대한 정보를 제공할 수 있습니다.

Abstract: Despite rapid growth in multimodal large language models (MLLMs), their
reasoning traces remain opaque: it is often unclear which modality drives a
prediction, how conflicts are resolved, or when one stream dominates. In this
paper, we introduce modality sabotage, a diagnostic failure mode in which a
high-confidence unimodal error overrides other evidence and misleads the fused
result. To analyze such dynamics, we propose a lightweight, model-agnostic
evaluation layer that treats each modality as an agent, producing candidate
labels and a brief self-assessment used for auditing. A simple fusion mechanism
aggregates these outputs, exposing contributors (modalities supporting correct
outcomes) and saboteurs (modalities that mislead). Applying our diagnostic
layer in a case study on multimodal emotion recognition benchmarks with
foundation models revealed systematic reliability profiles, providing insight
into whether failures may arise from dataset artifacts or model limitations.
More broadly, our framework offers a diagnostic scaffold for multimodal
reasoning, supporting principled auditing of fusion dynamics and informing
possible interventions.

</details>


### [9] [Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation](https://arxiv.org/abs/2511.02303)
*Zhiwei Zhang,Xiaomin Li,Yudi Lin,Hui Liu,Ramraj Chandradevan,Linlin Wu,Minhua Lin,Fali Wang,Xianfeng Tang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: 본 논문에서는 다중 에이전트 환경에서 발생하는 게으른 에이전트 행동을 해결하고, 복잡한 추론 작업에 대한 다중 에이전트 프레임워크의 잠재력을 최대한 발휘하기 위한 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 설정에서 협력적인 작업 수행의 중요성과 그 과정에서 발생하는 게으른 행동의 문제를 해결하고자 함.

Method: 원인 영향 측정을 위한 안정적이고 효율적인 방법을 도입하고, 소음 출력 폐기 및 추론 프로세스의 재시작을 허용하는 검증 가능한 보상 메커니즘을 제안.

Result: 제안된 프레임워크가 게으른 에이전트 행동을 완화하고, 복잡한 추론 작업을 위한 다중 에이전트 설정의 전체 잠재력을 발휘함을 보여주는 광범위한 실험 결과 제공.

Conclusion: 본 연구는 다중 에이전트 학습에서 협력의 질을 향상시키기 위한 새로운 방법론을 제시함.

Abstract: Large Language Models (LLMs) trained with reinforcement learning and
verifiable rewards have achieved strong results on complex reasoning tasks.
Recent work extends this paradigm to a multi-agent setting, where a
meta-thinking agent proposes plans and monitors progress while a reasoning
agent executes subtasks through sequential conversational turns. Despite
promising performance, we identify a critical limitation: lazy agent behavior,
in which one agent dominates while the other contributes little, undermining
collaboration and collapsing the setup to an ineffective single agent. In this
paper, we first provide a theoretical analysis showing why lazy behavior
naturally arises in multi-agent reasoning. We then introduce a stable and
efficient method for measuring causal influence, helping mitigate this issue.
Finally, as collaboration intensifies, the reasoning agent risks getting lost
in multi-turn interactions and trapped by previous noisy responses. To counter
this, we propose a verifiable reward mechanism that encourages deliberation by
allowing the reasoning agent to discard noisy outputs, consolidate
instructions, and restart its reasoning process when necessary. Extensive
experiments demonstrate that our framework alleviates lazy agent behavior and
unlocks the full potential of multi-agent framework for complex reasoning
tasks.

</details>


### [10] [ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning](https://arxiv.org/abs/2511.02424)
*Jae-Woo Choi,Hyungmin Kim,Hyobin Ong,Minsu Jang,Dohyung Kim,Jaehong Kim,Youngwoo Yoon*

Main category: cs.AI

TL;DR: ReAcTree는 복잡한 목표를 다룰 수 있는 계층적 작업 계획 방법입니다.


<details>
  <summary>Details</summary>
Motivation: 자동화된 에이전트의 의사결정 및 작업 계획을 개선하기 위해

Method: 복잡한 목표를 하위 목표로 분해하는 계층적 작업 계획 메서드와 메모리 시스템 통합

Result: ReAcTree가 다양한 LLM에서 ReAct 등 기존 작업 계획 방법보다 우수하다는 것을 입증

Conclusion: WAH-NL 데이터셋에서 ReAcTree가 ReAct보다 두 배 가까이 높은 목표 성공률을 보여줌

Abstract: Recent advancements in large language models (LLMs) have enabled significant
progress in decision-making and task planning for embodied autonomous agents.
However, most existing methods still struggle with complex, long-horizon tasks
because they rely on a monolithic trajectory that entangles all past decisions
and observations, attempting to solve the entire task in a single unified
process. To address this limitation, we propose ReAcTree, a hierarchical
task-planning method that decomposes a complex goal into more manageable
subgoals within a dynamically constructed agent tree. Each subgoal is handled
by an LLM agent node capable of reasoning, acting, and further expanding the
tree, while control flow nodes coordinate the execution strategies of agent
nodes. In addition, we integrate two complementary memory systems: each agent
node retrieves goal-specific, subgoal-level examples from episodic memory and
shares environment-specific observations through working memory. Experiments on
the WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently
outperforms strong task-planning baselines such as ReAct across diverse LLMs.
Notably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5
72B, nearly doubling ReAct's 31%.

</details>


### [11] [Agentic AI for Mobile Network RAN Management and Optimization](https://arxiv.org/abs/2511.02532)
*Jorge Pellejero,Luis A. Hernández Gómez,Luis Mendo Tomás,Zoraida Frias Barroso*

Main category: cs.AI

TL;DR: 이 논문은 5G 및 6G 네트워크에서 Agentic AI의 핵심 개념을 설명하고 이를 RAN 최적화에 적용하는 실용적인 사용 사례를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: Agentic AI는 복잡한 시스템 자동화를 위한 새로운 패러다임으로, 인간 수준의 인지 능력을 가진 LAMs를 활용합니다. 5G와 다가오는 6G 네트워크의 복잡성 때문에 수동 최적화가 비효율적이므로 Agentic AI는 역동적인 RAN 환경에서 결정 자동화를 위한 방법으로 주목받고 있습니다.

Method: 이 논문에서는 Agentic AI의 진화를 고전 에이전트에서 시작하여 단순 AI 에이전트 및 Agentic AI로의 발전을 추적하고 핵심 설계 패턴인 반영, 계획, 도구 사용 및 다중 에이전트 협업을 설명합니다.

Result: 실용적인 5G RAN 사례 연구를 통해 시간 시계열 분석과 LAM 기반 에이전트가 KPI 기반 자율 의사결정을 위해 협업하는 방법을 보여줍니다.

Conclusion: 이 연구는 5G 및 6G 네트워크에서 Agentic AI의 이론적 기초 및 실용적 응용 가능성을 증명합니다.

Abstract: Agentic AI represents a new paradigm for automating complex systems by using
Large AI Models (LAMs) to provide human-level cognitive abilities with
multimodal perception, planning, memory, and reasoning capabilities. This will
lead to a new generation of AI systems that autonomously decompose goals,
retain context over time, learn continuously, operate across tools and
environments, and adapt dynamically. The complexity of 5G and upcoming 6G
networks renders manual optimization ineffective, pointing to Agentic AI as a
method for automating decisions in dynamic RAN environments. However, despite
its rapid advances, there is no established framework outlining the
foundational components and operational principles of Agentic AI systems nor a
universally accepted definition.
  This paper contributes to ongoing research on Agentic AI in 5G and 6G
networks by outlining its core concepts and then proposing a practical use case
that applies Agentic principles to RAN optimization. We first introduce Agentic
AI, tracing its evolution from classical agents and discussing the progress
from workflows and simple AI agents to Agentic AI. Core design
patterns-reflection, planning, tool use, and multi-agent collaboration-are then
described to illustrate how intelligent behaviors are orchestrated. These
theorical concepts are grounded in the context of mobile networks, with a focus
on RAN management and optimization. A practical 5G RAN case study shows how
time-series analytics and LAM-driven agents collaborate for KPI-based
autonomous decision-making.

</details>


### [12] [Adaptive GR(1) Specification Repair for Liveness-Preserving Shielding in Reinforcement Learning](https://arxiv.org/abs/2511.02605)
*Tiberiu-Andrei Georgescu,Alexander W. Goodall,Dalal Alrajeh,Francesco Belardinelli,Sebastian Uchitel*

Main category: cs.AI

TL;DR: 이 논문은 RL 에이전트를 위한 첫 번째 적응형 보호 프레임워크를 개발하며, 환경 가정 위반을 실시간으로 탐지하고 GR(1) 규격을 자동으로 수정한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습에서 안전성을 보장하기 위해 동적 환경에서도 적응 가능한 보호 메커니즘이 필요하다.

Method: 일반화 반응성 GR(1) 규격 기반의 적응형 보호 프레임워크를 개발하고, ILP(유도 논리 프로그래밍)를 사용하여 온라인에서 GR(1) 규격을 자동으로 수정한다.

Result: 정적 심볼릭 제어기보다 보조 보상을 최적화할 때 성능이 크게 향상되며, 적응형 보호 장치를 장착한 RL 에이전트는 정적 보호 장치와 비교하여 근접 최적 보상과 완벽한 논리적 준수를 유지한다.

Conclusion: 적응형 보호 메커니즘은 RL 시스템의 안전성과 효율성을 크게 향상시킬 수 있다.

Abstract: Shielding is widely used to enforce safety in reinforcement learning (RL),
ensuring that an agent's actions remain compliant with formal specifications.
Classical shielding approaches, however, are often static, in the sense that
they assume fixed logical specifications and hand-crafted abstractions. While
these static shields provide safety under nominal assumptions, they fail to
adapt when environment assumptions are violated. In this paper, we develop the
first adaptive shielding framework - to the best of our knowledge - based on
Generalized Reactivity of rank 1 (GR(1)) specifications, a tractable and
expressive fragment of Linear Temporal Logic (LTL) that captures both safety
and liveness properties. Our method detects environment assumption violations
at runtime and employs Inductive Logic Programming (ILP) to automatically
repair GR(1) specifications online, in a systematic and interpretable way. This
ensures that the shield evolves gracefully, ensuring liveness is achievable and
weakening goals only when necessary. We consider two case studies: Minepump and
Atari Seaquest; showing that (i) static symbolic controllers are often severely
suboptimal when optimizing for auxiliary rewards, and (ii) RL agents equipped
with our adaptive shield maintain near-optimal reward and perfect logical
compliance compared with static shields.

</details>


### [13] [A Multi-Agent Psychological Simulation System for Human Behavior Modeling](https://arxiv.org/abs/2511.02606)
*Xiangen Hu,Jiarui Tong,Sheng Xu*

Main category: cs.AI

TL;DR: 인간 중심 분야의 교육과 훈련을 위한 심리학적 다중 에이전트 시뮬레이션 시스템을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 인간 행동의 현실적인 시뮬레이션이 부족한 상황에서, 인간 중심 분야의 훈련과 교육을 위한 진정한 연습의 필요성이 커지고 있다.

Method: 기존의 심리학 이론에 기반한 다중 에이전트 시스템으로, 직원 심리적 요인에 상응하는 에이전트들이 상호작용하여 인간 행동을 시뮬레이션한다.

Result: 이 시스템은 투명성을 높이고 인간 심리학과의 일치를 가능하게 한다.

Conclusion: 교사 교육 및 연구에 이 시스템을 활용하며, 사회적 학습, 인지적 견습, 의도적 연습 및 메타 인지 원칙을 구현한다.

Abstract: Training and education in human-centered fields require authentic practice,
yet realistic simulations of human behavior have remained limited. We present a
multi-agent psychological simulation system that models internal
cognitive-affective processes to generate believable human behaviors. In
contrast to black-box neural models, this system is grounded in established
psychological theories (e.g., self-efficacy, mindset, social constructivism)
and explicitly simulates an ``inner parliament'' of agents corresponding to key
psychological factors. These agents deliberate and interact to determine the
system's output behavior, enabling unprecedented transparency and alignment
with human psychology. We describe the system's architecture and theoretical
foundations, illustrate its use in teacher training and research, and discuss
how it embodies principles of social learning, cognitive apprenticeship,
deliberate practice, and meta-cognition.

</details>


### [14] [The Collaboration Gap](https://arxiv.org/abs/2511.02687)
*Tim R. Davidson,Adam Fourney,Saleema Amershi,Robert West,Eric Horvitz,Ece Kamar*

Main category: cs.AI

TL;DR: AI 발전의 경로는 점점 더 다양한 정보와 도구를 가진 독립적으로 개발된 에이전트들로 구성된 에이전트 기반 시스템에 의존하게 될 것을 시사한다. 이런 시스템의 성공은 부분 관찰 가능성 하에서도 이들 이질적 에이전트 간의 효과적인 협력에 크게 의존한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 협력 능력 평가 필요성.

Method: 협력형 미로 해결 벤치마크를 제안하여 협력 능력을 격리하고 문제 복잡도를 조절하며 자동 채점이 가능하고 출력 형식 제약 없이 생태학적 타당성을 유지하는 프레임워크를 사용하였다.

Result: 32개의 선도적인 모델을 평가한 결과, '협력 격차'가 발견되었으며, 단독 수행이 우수한 모델이 협력 시 상당히 성능이 저하되는 경향이 있다.

Conclusion: 협력 인식을 고려한 평가, 협력 능력을 강화하기 위한 훈련 전략, 에이전트의 잠재적 스킬을 끌어내는 상호작용 디자인의 필요성을 주장한다.

Abstract: The trajectory of AI development suggests that we will increasingly rely on
agent-based systems composed of independently developed agents with different
information, privileges, and tools. The success of these systems will
critically depend on effective collaboration among these heterogeneous agents,
even under partial observability. Despite intense interest, few empirical
studies have evaluated such agent-agent collaboration at scale. We propose a
collaborative maze-solving benchmark that (i) isolates collaborative
capabilities, (ii) modulates problem complexity, (iii) enables scalable
automated grading, and (iv) imposes no output-format constraints, preserving
ecological plausibility. Using this framework, we evaluate 32 leading open- and
closed-source models in solo, homogeneous, and heterogeneous pairings. Our
results reveal a "collaboration gap": models that perform well solo often
degrade substantially when required to collaborate. Collaboration can break
down dramatically; for instance, small distilled models that solve mazes well
alone may fail almost completely in certain pairings. We find that starting
with the stronger agent often improves outcomes, motivating a "relay inference"
approach where the stronger agent leads before handing off to the weaker one,
closing much of the gap. Our findings argue for (1) collaboration-aware
evaluation, (2) training strategies developed to enhance collaborative
capabilities, and (3) interaction design that reliably elicits agents' latent
skills, guidance that applies to AI-AI and human-AI collaboration.

</details>


### [15] [CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents](https://arxiv.org/abs/2511.02734)
*Jiayu Liu,Cheng Qian,Zhaochen Su,Qing Zong,Shijue Huang,Bingxiang He,Yi R. Fung*

Main category: cs.AI

TL;DR: LLM 에이전트의 평가가 주로 작업 완료에 중점을 두는데, 이는 자원 효율성과 적응성을 간과하고 있다. 이를 해결하기 위해 CostBench라는 비용 중심의 벤치를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 현재 LLM 에이전트의 평가가 작업 완료에만 초점을 맞추고 있어 자원 효율성과 적응력이 간과되고 있다.

Method: CostBench는 비용 중심의 벤치마크로, 에이전트의 경제적 추론 및 재계획 능력을 평가하기 위해 여행 계획 도메인에서 다양한 비용으로 해결할 수 있는 작업을 포함한다.

Result: 주요 오픈소스 및 독점 모델들을 CostBench에서 평가한 결과, 비용 인식 계획에서 상당한 격차가 있음이 드러났다. 에이전트들은 정적 설정에서 비용 최적의 솔루션을 자주 식별하지 못하며, GPT-5는 가장 어려운 작업에서 정확도가 75% 미만을 기록하고, 동적 조건에서는 성능이 약 40% 감소했다.

Conclusion: CostBench는 경제적으로 합리적이고 강력한 미래 에이전트를 개발하기 위한 기초를 놓았다.

Abstract: Current evaluations of Large Language Model (LLM) agents primarily emphasize
task completion, often overlooking resource efficiency and adaptability. This
neglects a crucial capability: agents' ability to devise and adjust
cost-optimal plans in response to changing environments. To bridge this gap, we
introduce CostBench, a scalable, cost-centric benchmark designed to evaluate
agents' economic reasoning and replanning abilities. Situated in the
travel-planning domain, CostBench comprises tasks solvable via multiple
sequences of atomic and composite tools with diverse, customizable costs. It
also supports four types of dynamic blocking events, such as tool failures and
cost changes, to simulate real-world unpredictability and necessitate agents to
adapt in real time. Evaluating leading open-sourced and proprietary models on
CostBench reveals a substantial gap in cost-aware planning: agents frequently
fail to identify cost-optimal solutions in static settings, with even GPT-5
achieving less than 75% exact match rate on the hardest tasks, and performance
further dropping by around 40% under dynamic conditions. By diagnosing these
weaknesses, CostBench lays the groundwork for developing future agents that are
both economically rational and robust.

</details>


### [16] [Using Span Queries to Optimize for Cache and Attention Locality](https://arxiv.org/abs/2511.02749)
*Paul Castro,Nick Mitchell,Nathan Ordonez,Thomas Parnell,Mudhakar Srivatsa,Antoni Viros i Martin*

Main category: cs.AI

TL;DR: 이 논문에서는 인퍼런스 서버의 인터페이스를 일반화하기 위한 스팬 쿼리를 도입하고, 다양한 작업 부하들을 스팬 쿼리로 표현할 수 있음을 보여준다. 이를 통해 KV 캐시의 효율성을 높이고, 인퍼런스 성능을 크게 향상시킬 수 있는 방안을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 클라이언트는 채팅 완료를 넘어서 다양한 혁신적인 추론 시간 스케일링 및 깊은 추론 기술을 포함하게 되었다. 그러나 인퍼런스 서버는 여전히 채팅 완료에 최적화되어 있다.

Method: 스팬 쿼리를 도입하여 인퍼런스 서버의 인터페이스를 일반화하고, 이를 통해 채팅, RAG, 추론 시간 스케일링 및 에이전틱 작업 부하를 모두 표현할 수 있음을 보여준다.

Result: 스팬 쿼리를 사용해 KV 캐시 로컬리티를 개선할 수 있는 자동 최적화 방법을 제시하며, 두 가지 비채팅 사용 사례에 대해 TTFT를 10-20배 줄일 수 있음을 입증한다.

Conclusion: 스팬 쿼리는 주의 로컬리티를 개선하여 '중간에 잃어버리는 문제'를 피할 수 있으며, 2b 매개변수 모델에서 주의 최적화된 스팬 쿼리가 8b 모델을 사용하는 표준 인퍼런스 서버보다 정확도가 훨씬 뛰어남을 보여준다.

Abstract: Clients are evolving beyond chat completion, and now include a variety of
innovative inference-time scaling and deep reasoning techniques. At the same
time, inference servers remain heavily optimized for chat completion. Prior
work has shown that large improvements to KV cache hit rate are possible if
inference servers evolve towards these non-chat use cases. However, they offer
solutions that are also optimized for a single use case, RAG. In this paper, we
introduce the span query to generalize the interface to the inference server.
We demonstrate that chat, RAG, inference-time scaling, and agentic workloads
can all be expressed as span queries. We show how the critical distinction that
had been assumed by prior work lies in whether the order of the inputs matter
-- do they commute? In chat, they do not. In RAG, they often do. This paper
introduces span queries, which are expression trees of inference calls, linked
together with commutativity constraints. We describe span query syntax and
semantics. We show how they can be automatically optimized to improve KV cache
locality. We show how a small change to vLLM (affecting only 492 lines) can
enable high-performance execution of span queries. Using this stack, we
demonstrate that span queries can achieve 10-20x reductions in TTFT for two
distinct non-chat use cases. Finally, we show that span queries can also be
optimized to improve attention locality, so as to avoid the so-called
lost-in-the-middle problem. We demonstrate that an attention-optimized span
query on a 2b parameter model vastly outperforms the accuracy of a stock
inference server using an 8b model.

</details>


### [17] [Optimizing AI Agent Attacks With Synthetic Data](https://arxiv.org/abs/2511.02823)
*Chloe Loughridge,Paul Colognese,Avery Griffin,Tyler Tracy,Jon Kutasov,Joe Benton*

Main category: cs.AI

TL;DR: AI 배포의 위험을 추정하는 것이 점점 더 중요해지고 있으며, SHADE-Arena에서 공격 정책을 최적화하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI 배포가 복잡하고 고위험 상황이 될수록 그 위험을 추정하는 것이 중요해진다.

Method: 공격 능력을 다섯 가지 구성 기술(의심 모델링, 공격 선택, 계획 합성, 실행 및 미세함)으로 분해하고 각 구성 요소를 개별적으로 최적화한다.

Result: 공격 동역학의 확률적 모델을 개발하여 공격 하이퍼파라미터를 최적화하고, 결과가 SHADE-Arena에 전달되는 것을 보여준다. 이로 인해 공격 강도가 크게 개선되어 안전성 점수가 0.87에서 0.41로 감소한다.

Conclusion: 제시된 방법으로 AI 통제 환경에서 공격 정책의 강도를 크게 향상시킬 수 있다.

Abstract: As AI deployments become more complex and high-stakes, it becomes
increasingly important to be able to estimate their risk. AI control is one
framework for doing so. However, good control evaluations require eliciting
strong attack policies. This can be challenging in complex agentic environments
where compute constraints leave us data-poor. In this work, we show how to
optimize attack policies in SHADE-Arena, a dataset of diverse realistic control
environments. We do this by decomposing attack capability into five constituent
skills -- suspicion modeling, attack selection, plan synthesis, execution and
subtlety -- and optimizing each component individually. To get around the
constraint of limited data, we develop a probabilistic model of attack
dynamics, optimize our attack hyperparameters using this simulation, and then
show that the results transfer to SHADE-Arena. This results in a substantial
improvement in attack strength, reducing safety score from a baseline of 0.87
to 0.41 using our scaffold.

</details>


### [18] [Kosmos: An AI Scientist for Autonomous Discovery](https://arxiv.org/abs/2511.02824)
*Ludovico Mitchener,Angela Yiu,Benjamin Chang,Mathieu Bourdenx,Tyler Nadolski,Arvis Sulovari,Eric C. Landsness,Daniel L. Barabasi,Siddharth Narayanan,Nicky Evans,Shriya Reddy,Martha Foiani,Aizad Kamal,Leah P. Shriver,Fang Cao,Asmamaw T. Wassie,Jon M. Laurent,Edwin Melville-Green,Mayk Caldas,Albert Bou,Kaleigh F. Roberts,Sladjana Zagorac,Timothy C. Orr,Miranda E. Orr,Kevin J. Zwezdaryk,Ali E. Ghareeb,Laurie McCoy,Bruna Gomes,Euan A. Ashley,Karen E. Duff,Tonio Buonassisi,Tom Rainforth,Randall J. Bateman,Michael Skarlinski,Samuel G. Rodriques,Michaela M. Hinks,Andrew D. White*

Main category: cs.AI

TL;DR: Kosmos는 데이터 기반 발견을 자동화하는 AI 과학자로, 문헌 검색, 가설 생성, 데이터 분석 사이클을 수행한다.


<details>
  <summary>Details</summary>
Motivation: 데이터 기반 과학 발견은 문헌 검색, 가설 생성 및 데이터 분석의 반복적인 사이클을 필요로 한다.

Method: Kosmos는 구조화된 세계 모델을 이용하여 데이터 분석 에이전트와 문헌 검색 에이전트 간의 정보를 공유하며, 최대 12시간 동안 병렬 데이터 분석 사이클을 수행한다.

Result: Kosmos 보고서의 79.4%의 진술이 정확하며, 협력자들은 평균적으로 6개월의 연구 시간에 해당하는 결과를 생성했다고 보고했다.

Conclusion: Kosmos는 대사체학, 재료 과학, 신경 과학 및 통계 유전학 분야의 발견을 포함하여 과학 문헌에 새로운 기여를 한다.

Abstract: Data-driven scientific discovery requires iterative cycles of literature
search, hypothesis generation, and data analysis. Substantial progress has been
made towards AI agents that can automate scientific research, but all such
agents remain limited in the number of actions they can take before losing
coherence, thus limiting the depth of their findings. Here we present Kosmos,
an AI scientist that automates data-driven discovery. Given an open-ended
objective and a dataset, Kosmos runs for up to 12 hours performing cycles of
parallel data analysis, literature search, and hypothesis generation before
synthesizing discoveries into scientific reports. Unlike prior systems, Kosmos
uses a structured world model to share information between a data analysis
agent and a literature search agent. The world model enables Kosmos to
coherently pursue the specified objective over 200 agent rollouts, collectively
executing an average of 42,000 lines of code and reading 1,500 papers per run.
Kosmos cites all statements in its reports with code or primary literature,
ensuring its reasoning is traceable. Independent scientists found 79.4% of
statements in Kosmos reports to be accurate, and collaborators reported that a
single 20-cycle Kosmos run performed the equivalent of 6 months of their own
research time on average. Furthermore, collaborators reported that the number
of valuable scientific findings generated scales linearly with Kosmos cycles
(tested up to 20 cycles). We highlight seven discoveries made by Kosmos that
span metabolomics, materials science, neuroscience, and statistical genetics.
Three discoveries independently reproduce findings from preprinted or
unpublished manuscripts that were not accessed by Kosmos at runtime, while four
make novel contributions to the scientific literature.

</details>


### [19] [Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for Understanding Anything](https://arxiv.org/abs/2511.02834)
*Huawei Lin,Yunzhi Shi,Tong Geng,Weijie Zhao,Wei Wang,Ravender Pal Singh*

Main category: cs.AI

TL;DR: 이 논문에서는 고정된 모달리티 쌍에 제한된 멀티모달 대형 언어 모델의 한계를 극복하기 위해 Agent-Omni 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 멀티모달 모델은 텍스트, 이미지, 오디오, 비디오를 아우르는 통합 능력이 부족하고, 대규모 정렬 데이터셋으로 비싼 파인튜닝이 필요하다.

Method: Agent-Omni 프레임워크는 마스터-에이전트 시스템을 통해 기존의 기초 모델을 조정하며, 재교육 없이 유연한 멀티모달 추론을 가능하게 한다.

Result: 대규모 실험 결과, Agent-Omni는 복잡한 크로스 모달 추론이 필요한 작업에서 특히 뛰어난 성능을 보였다.

Conclusion: 이 프레임워크는 모듈화되어 있고 쉽게 확장 가능하여 향후 더 강력한 모델이 등장할 경우 개선할 수 있는 가능성을 갖는다.

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities but
remain limited to fixed modality pairs and require costly fine-tuning with
large aligned datasets. Building fully omni-capable models that can integrate
text, images, audio, and video remains impractical and lacks robust reasoning
support. In this paper, we propose an Agent-Omni framework that coordinates
existing foundation models through a master-agent system, enabling flexible
multimodal reasoning without retraining. The master agent interprets user
intent, delegates subtasks to modality-specific agents, and integrates their
outputs into coherent responses. Extensive experiments across text, image,
audio, video, and omni benchmarks show that Agent-Omni consistently achieves
state-of-the-art performance, particularly on tasks requiring complex
cross-modal reasoning. Its agent-based design enables seamless integration of
specialized foundation models, ensuring adaptability to diverse inputs while
maintaining transparency and interpretability. In addition, the framework is
modular and easily extensible, allowing future improvements as stronger models
become available. %We release an open-source implementation to support
continued research on scalable and reliable omni-modal reasoning.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [20] [EvoMem: Improving Multi-Agent Planning with Dual-Evolving Memory](https://arxiv.org/abs/2511.01912)
*Wenzhe Fan,Ning Yan,Masood Mortazavi*

Main category: cs.MA

TL;DR: EvoMem은 다중 에이전트 프레임워크로, 인간과 유사한 기억을 통해 자연어 계획을 지원하며, 메모리의 중요성을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: 인공지능에서 복잡한 문제를 해결하는 데 있어 계획 수립의 중요성이 있으며, 최신 LLM 기반 다중 에이전트 프레임워크는 이러한 능력을 확장하기 시작했습니다. 그러나 인간과 유사한 메모리의 역할은 아직 탐구되지 않았습니다.

Method: EvoMem은 이중 진화 메모리 메커니즘에 기반한 다중 에이전트 프레임워크로, Constraint Extractor, Verifier, Actor의 세 가지 에이전트와 두 개의 메모리 모듈(CMem, QMem)을 포함합니다. CMem은 쿼리 내에서는 고정되어 있지만 작업-specific 규칙과 제약을 저장하며 쿼리 간에 진화하고, QMem은 반복 간 피드백을 축적하여 쿼리 내에서 진화합니다.

Result: 여행 계획, 회의 계획 및 캘린더 스케줄링에 대한 평가 결과, 일관된 성능 향상이 나타나 EvoMem의 효율성을 강조합니다.

Conclusion: 이러한 성공은 다중 에이전트 계획을 향상시키는 데 있어 메모리의 중요성을 부각시킵니다.

Abstract: Planning has been a cornerstone of artificial intelligence for solving
complex problems, and recent progress in LLM-based multi-agent frameworks have
begun to extend this capability. However, the role of human-like memory within
these frameworks remains largely unexplored. Understanding how agents
coordinate through memory is critical for natural language planning, where
iterative reasoning, constraint tracking, and error correction drive the
success. Inspired by working memory model in cognitive psychology, we present
EvoMem, a multi-agent framework built on a dual-evolving memory mechanism. The
framework consists of three agents (Constraint Extractor, Verifier, and Actor)
and two memory modules: Constraint Memory (CMem), which evolves across queries
by storing task-specific rules and constraints while remains fixed within a
query, and Query-feedback Memory (QMem), which evolves within a query by
accumulating feedback across iterations for solution refinement. Both memory
modules are reset at the end of each query session. Evaluations on trip
planning, meeting planning, and calendar scheduling show consistent performance
improvements, highlighting the effectiveness of EvoMem. This success
underscores the importance of memory in enhancing multi-agent planning.

</details>


### [21] [Optimizing Multi-Lane Intersection Performance in Mixed Autonomy Environments](https://arxiv.org/abs/2511.02217)
*Manonmani Sekar,Nasim Nezamoddini*

Main category: cs.MA

TL;DR: HDV와 CAV의 원활한 조정을 위한 새로운 교통 신호 제어 프레임워크를 제안하고, GAT와 SAC를 결합한 성과를 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 다중 차선 교차로에서 HDV와 CAV 간의 원활한 조정 보장이 필요합니다.

Method: Graph Attention Networks (GAT)와 Soft Actor-Critic (SAC) 강화 학습을 결합한 새로운 교통 신호 제어 프레임워크를 제안합니다.

Result: 전통적인 방법에 비해 평균 지연이 24.1% 감소하고 교통 위반이 최대 29.2% 감소했습니다.

Conclusion: GAT-SAC 프레임워크는 혼합 자율 교통 시스템의 실제 배치에 대한 중요한 가능성을 제시합니다.

Abstract: One of the main challenges in managing traffic at multilane intersections is
ensuring smooth coordination between human-driven vehicles (HDVs) and connected
autonomous vehicles (CAVs). This paper presents a novel traffic signal control
framework that combines Graph Attention Networks (GAT) with Soft Actor-Critic
(SAC) reinforcement learning to address this challenge. GATs are used to model
the dynamic graph- structured nature of traffic flow to capture spatial and
temporal dependencies between lanes and signal phases. The proposed SAC is a
robust off-policy reinforcement learning algorithm that enables adaptive signal
control through entropy-optimized decision making. This design allows the
system to coordinate the signal timing and vehicle movement simultaneously with
objectives focused on minimizing travel time, enhancing performance, ensuring
safety, and improving fairness between HDVs and CAVs. The model is evaluated
using a SUMO-based simulation of a four-way intersection and incorporating
different traffic densities and CAV penetration rates. The experimental results
demonstrate the effectiveness of the GAT-SAC approach by achieving a 24.1%
reduction in average delay and up to 29.2% fewer traffic violations compared to
traditional methods. Additionally, the fairness ratio between HDVs and CAVs
improved to 1.59, indicating more equitable treatment across vehicle types.
These findings suggest that the GAT-SAC framework holds significant promise for
real-world deployment in mixed-autonomy traffic systems.

</details>


### [22] [Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.02304)
*Beyazit Yalcinkaya,Marcell Vazquez-Chanlatte,Ameesh Shah,Hanna Krasowski,Sanjit A. Seshia*

Main category: cs.MA

TL;DR: ACC-MARL 프레임워크는 중앙 집중식 훈련과 분산 실행 하에 멀티태스크, 멀티 에이전트 정책을 학습하는 문제를 다루며, 복잡한 작업을 더 간단한 하위 작업으로 분해할 수 있도록 오토마타를 활용한다.


<details>
  <summary>Details</summary>
Motivation: 다중 작업 및 다중 에이전트를 위한 정책 학습 문제를 해결하고자 한다.

Method: ACC-MARL 프레임워크를 제안하고, 주어진 작업 조건에 따라 분산된 팀 정책을 학습한다.

Result: 실험을 통해 에이전트 간 다단계 조정 및 작업 인식을 보여준다.

Conclusion: 우리는 ACC-MARL의 실행 가능성에 대한 주요 도전 과제를 식별하고, 솔루션을 제안하며, 학습된 정책의 가치 함수가 테스트 시 작업을 최적으로 할당하는 데 사용될 수 있음을 보여주었다.

Abstract: We study the problem of learning multi-task, multi-agent policies for
cooperative, temporal objectives, under centralized training, decentralized
execution. In this setting, using automata to represent tasks enables the
decomposition of complex tasks into simpler sub-tasks that can be assigned to
agents. However, existing approaches remain sample-inefficient and are limited
to the single-task case. In this work, we present Automata-Conditioned
Cooperative Multi-Agent Reinforcement Learning (ACC-MARL), a framework for
learning task-conditioned, decentralized team policies. We identify the main
challenges to ACC-MARL's feasibility in practice, propose solutions, and prove
the correctness of our approach. We further show that the value functions of
learned policies can be used to assign tasks optimally at test time.
Experiments show emergent task-aware, multi-step coordination among agents,
e.g., pressing a button to unlock a door, holding the door, and
short-circuiting tasks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [23] [CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel Optimization](https://arxiv.org/abs/2511.01884)
*Zijian Zhang,Rong Wang,Shiyang Li,Yuebo Luo,Mingyi Hong,Caiwen Ding*

Main category: cs.LG

TL;DR: CudaForge는 자동 CUDA 커널 생성을 위한 훈련이 필요 없는 멀티 에이전트 워크플로우를 제안하며, 기존 방법들보다 높은 효율성과 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 효율적인 CUDA 커널 개발은 대규모 LLM 훈련과 같은 AI 응용 프로그램에 점점 더 중요해지고 있으며, 수동 커널 설계는 비용과 시간이 많이 소요된다.

Method: CudaForge는 두 개의 LLM 에이전트인 Coder와 Judge를 사용해 자율적으로 CUDA 커널을 생성하고, 수정하며 최적화하는 반복 워크플로우를 따른다.

Result: CudaForge는 생성된 커널의 97.6% 정확도와 PyTorch 기준 대비 평균 1.68배의 속도 향상을 보여준다.

Conclusion: 멀티 에이전트, 훈련 없이 수행되는 워크플로우는 비용 효율적이고 일반화 가능하며 고성능의 CUDA 커널 최적화를 가능하게 한다.

Abstract: Developing efficient CUDA kernels is increasingly critical for AI
applications such as large-scale LLM training. However, manual kernel design is
both costly and time-consuming, motivating automatic approaches that leverage
LLMs for code generation. Existing methods for automatic kernel generation,
however, often produce low-efficiency kernels, incur high computational
overhead, and fail to generalize across settings. In this work, we propose
CudaForge, a training-free multi-agent workflow for CUDA kernel generation and
optimization. Our workflow is inspired by the iterative workflow of human
experts, which contains steps such as developing initial kernels, testing
correctness, analyzing hardware feedback, and iterative improvement. More
specifically, CudaForge employs two LLM agents: a Coder and a Judge, that
iteratively generate, correct, and optimize CUDA kernels, while integrating
hardware feedback such as Nsight Compute (NCU) metrics. In extensive
evaluations, we show that CudaForge, by leveraging base models like OpenAI-o3,
achieves 97.6\% correctness of generated kernels and an average 1.68$\times$
speedup over PyTorch baselines, substantially surpassing state-of-the-art
models including OpenAI-o3 and Kevin on KernelBench.Beyond accuracy and speed,
CudaForge demonstrates strong generalization across GPUs (A100, RTX 6000, 4090,
3090) and base models (OpenAI-o3, GPT-5, gpt-oss-120B, Claude-Sonnet-4,
QwQ-32B), while maintaining high efficiency. In particular, generating an
optimized kernel takes about 26.5 minutes on one RTX6000 and incurs about \$
0.3 API cost, which is significantly cheaper than existing agentic work that
costs 6 H100 hours and \$ 5 API cost per kernel. Our results highlight that
multi-agent, training-free workflows can enable cost-effective, generalizable,
and high-performance CUDA kernel optimization. Code available at
https://github.com/OptimAI-Lab/CudaForge

</details>


### [24] [Superpositional Gradient Descent: Harnessing Quantum Principles for Model Training](https://arxiv.org/abs/2511.01918)
*Ahmet Erdem Pamuk,Emir Kaan Özdemir,Şuayp Talha Kocabay*

Main category: cs.LG

TL;DR: 본 논문은 양자 영감을 받은 방법이 고전적인 학습을 향상시키는 메커니즘을 탐구하며, 양자 회로의 섭동을 주입한 새로운 최적화 기법인 Superpositional Gradient Descent(SGD)를 도입합니다.


<details>
  <summary>Details</summary>
Motivation: 고전적인 최적화 기법의 한계를 극복하고 LLM의 수렴성과 일반화를 향상시키기 위한 양자 영감 방법의 필요성.

Method: 양자 회로의 섭동을 주입하여 그래디언트 업데이트와 양자 중첩을 연결하는 새로운 최적화 기법인 Superpositional Gradient Descent(SGD)를 수학적 프레임워크로 소개하고, 이를 PyTorch 및 Qiskit에서 구현.

Result: 합성 시퀀스 분류 및 대규모 LLM 미세 조정에서 SGD는 AdamW보다 더 빠르게 수렴하고 최종 손실이 낮았다.

Conclusion: 이 연구는 양자 컴퓨팅과 딥러닝의 교차점에 대한 새로운 통찰을 제공하며, 양자 원칙을 활용하여 모델 행동을 제어하고 향상시키는 실용적인 경로를 제시한다.

Abstract: Large language models (LLMs) are increasingly trained with classical
optimization techniques like AdamW to improve convergence and generalization.
However, the mechanisms by which quantum-inspired methods enhance classical
training remain underexplored. We introduce Superpositional Gradient Descent
(SGD), a novel optimizer linking gradient updates with quantum superposition by
injecting quantum circuit perturbations. We present a mathematical framework
and implement hybrid quantum-classical circuits in PyTorch and Qiskit. On
synthetic sequence classification and large-scale LLM fine-tuning, SGD
converges faster and yields lower final loss than AdamW. Despite promising
results, scalability and hardware constraints limit adoption. Overall, this
work provides new insights into the intersection of quantum computing and deep
learning, suggesting practical pathways for leveraging quantum principles to
control and enhance model behavior.

</details>


### [25] [From Solo to Symphony: Orchestrating Multi-Agent Collaboration with Single-Agent Demos](https://arxiv.org/abs/2511.02762)
*Xun Wang,Zhuoran Li,Yanshan Lin,Hai Zhong,Longbo Huang*

Main category: cs.LG

TL;DR: SoCo는 단독 경험을 협력 학습에 전이하여 다중 에이전트 강화 학습의 효율성과 성능을 크게 향상시키는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습에서 에이전트 팀을 처음부터 훈련하는 것은 매우 비효율적이며, 기존 방법도 비용이 많이 드는 다중 에이전트 데이터를 필요로 한다.

Method: SoCo는 단독 증명으로부터 공유 단독 정책을 사전 훈련한 후, 정책 융합 메커니즘을 통해 다중 에이전트 훈련 중 협력을 위해 이를 조정한다.

Result: 다양한 협력 작업에서 SoCo는 기본 알고리즘의 훈련 효율성과 성능을 크게 향상시킨다.

Conclusion: 단독 증명은 다중 에이전트 데이터에 대한 확장 가능하고 효과적인 보완물이 되어 협력 학습을 보다 실용적이고 널리 적용 가능하게 만든다.

Abstract: Training a team of agents from scratch in multi-agent reinforcement learning
(MARL) is highly inefficient, much like asking beginners to play a symphony
together without first practicing solo. Existing methods, such as offline or
transferable MARL, can ease this burden, but they still rely on costly
multi-agent data, which often becomes the bottleneck. In contrast, solo
experiences are far easier to obtain in many important scenarios, e.g.,
collaborative coding, household cooperation, and search-and-rescue. To unlock
their potential, we propose Solo-to-Collaborative RL (SoCo), a framework that
transfers solo knowledge into cooperative learning. SoCo first pretrains a
shared solo policy from solo demonstrations, then adapts it for cooperation
during multi-agent training through a policy fusion mechanism that combines an
MoE-like gating selector and an action editor. Experiments across diverse
cooperative tasks show that SoCo significantly boosts the training efficiency
and performance of backbone algorithms. These results demonstrate that solo
demonstrations provide a scalable and effective complement to multi-agent data,
making cooperative learning more practical and broadly applicable.

</details>


### [26] [Predicting Microbial Interactions Using Graph Neural Networks](https://arxiv.org/abs/2511.02038)
*Elham Gholamzadeh,Kajal Singla,Nico Scherf*

Main category: cs.LG

TL;DR: 미생물 생태학에서 종 간 상호작용을 예측하는 것은 중요한 도전 과제이다. 본 연구에서는 그래프 신경망(GNN)을 활용하여 20종의 미생물 간의 상호작용을 예측하였다.


<details>
  <summary>Details</summary>
Motivation: 미생물 군집의 구조와 활동을 결정하는 데 중요한 종 간 상호작용을 예측하는 필요성.

Method: 우리는 40개의 구별된 탄소 조건에서 동배양된 20종의 미생물 간의 7,500개 이상의 상호작용 데이터셋을 사용하여 GNN을 통해 상호작용 효과의 방향성을 예측했다.

Result: 모델은 F1-score 80.44%를 달성하여 기존의 XGBoost 모델보다 우수한 성과를 보였다.

Conclusion: GNN을 사용한 접근 방식이 미생물 간의 상호작용 예측에 효과적임을 나타낸다.

Abstract: Predicting interspecies interactions is a key challenge in microbial ecology,
as these interactions are critical to determining the structure and activity of
microbial communities. In this work, we used data on monoculture growth
capabilities, interactions with other species, and phylogeny to predict a
negative or positive effect of interactions. More precisely, we used one of the
largest available pairwise interaction datasets to train our models, comprising
over 7,500 interactions be- tween 20 species from two taxonomic groups
co-cultured under 40 distinct carbon conditions, with a primary focus on the
work of Nestor et al.[28 ]. In this work, we propose Graph Neural Networks
(GNNs) as a powerful classifier to predict the direction of the effect. We
construct edge-graphs of pairwise microbial interactions in order to leverage
shared information across individual co-culture experiments, and use GNNs to
predict modes of interaction. Our model can not only predict binary
interactions (positive/negative) but also classify more complex interaction
types such as mutualism, competition, and parasitism. Our initial results were
encouraging, achieving an F1-score of 80.44%. This significantly outperforms
comparable methods in the literature, including conventional Extreme Gradient
Boosting (XGBoost) models, which reported an F1-score of 72.76%.

</details>


### [27] [A Dual-Use Framework for Clinical Gait Analysis: Attention-Based Sensor Optimization and Automated Dataset Auditing](https://arxiv.org/abs/2511.02047)
*Hamidreza Sadeghsalehi*

Main category: cs.LG

TL;DR: 웨어러블 센서와 AI를 이용한 보행 분석은 신경학적 및 정형외과적 질환 관리에 중요하지만 모델이 숨겨진 데이터셋 편향에 취약하다. 본 논문에서는 센서 최적화 및 자동 데이터 감사 기능을 갖춘 다중 스트림 주의 기반 딥러닝 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 신경학적 및 정형외과적 질환 관리를 위해 정확한 보행 분석이 필요하지만, 기존 모델들이 데이터셋의 숨겨진 편향에 취약한 문제를 해결할 필요가 있다.

Method: 다중 스트림 주의 기반 딥러닝 프레임워크를 적용하여 Voisard et al. (2025)의 다중 집단 보행 데이터셋에서 임상 작업에 대한 분석을 수행한다.

Result: 모델의 주의 메커니즘이 심각한 데이터셋 혼동을 정량적으로 발견하였으며, 특히 OA와 CVA 검진 임상 작업에서 우측 발에 70% 이상의 주의를 할당하고 좌측 발은 0.1% 미만으로 무시했다.

Conclusion: 이 연구의 주요 기여는 해석 가능한 프레임워크를 통해 데이터셋의 무결성을 자동으로 감사할 수 있음을 보여주는 방법론적 발견이며, 또한 데이터 기반 센서 시너지에 대한 새로운 가설을 제안한다.

Abstract: Objective gait analysis using wearable sensors and AI is critical for
managing neurological and orthopedic conditions. However, models are vulnerable
to hidden dataset biases, and task-specific sensor optimization remains a
challenge. We propose a multi-stream attention-based deep learning framework
that functions as both a sensor optimizer and an automated data auditor.
Applied to the Voisard et al. (2025) multi-cohort gait dataset on four clinical
tasks (PD, OA, CVA screening; PD vs CVA differential), the model's attention
mechanism quantitatively discovered a severe dataset confound. For OA and CVA
screening, tasks where bilateral assessment is clinically essential, the model
assigned more than 70 percent attention to the Right Foot while statistically
ignoring the Left Foot (less than 0.1 percent attention, 95 percent CI
[0.0-0.1]). This was not a clinical finding but a direct reflection of a severe
laterality bias (for example, 15 of 15 right-sided OA) in the public dataset.
The primary contribution of this work is methodological, demonstrating that an
interpretable framework can automatically audit dataset integrity. As a
secondary finding, the model proposes novel, data-driven sensor synergies (for
example, Head plus Foot for PD screening) as hypotheses for future optimized
protocols.

</details>


### [28] [Energy Loss Functions for Physical Systems](https://arxiv.org/abs/2511.02087)
*Sékou-Oumar Kaba,Kusha Sareen,Daniel Levy,Siamak Ravanbakhsh*

Main category: cs.LG

TL;DR: 물리학적 정보를 손실 함수에 직접 활용하는 프레임워크를 제안하여 예측 및 생성 모델 작업에서 성능을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습을 과학 분야에 적용하기 위해 시스템 물리학에 대한 선행 지식을 효과적으로 활용하는 것이 중요하다.

Method: 데이터 샘플이 대략적인 에너지 풍경에 대해 열 평형에 있다는 가정을 통해 에너지 손실 함수를 도출하였다. 데이터 주위의 볼츠만 분포를 기반으로 하는 역 KL 발산을 사용하여 손실을 데이터와 모델 예측 간의 에너지 차이로 얻었다.

Result: 우리의 접근 방식을 분자 생성 및 스핀 바닥 상태 예측에 적용한 결과, 기존 기법들에 비해 상당한 성능 개선을 보고하였다.

Conclusion: 제안된 에너지 손실 함수는 물리적 대칭성을 존중하며, 건축에 구애받지 않고 계산적으로 효율적이다.

Abstract: Effectively leveraging prior knowledge of a system's physics is crucial for
applications of machine learning to scientific domains. Previous approaches
mostly focused on incorporating physical insights at the architectural level.
In this paper, we propose a framework to leverage physical information directly
into the loss function for prediction and generative modeling tasks on systems
like molecules and spins. We derive energy loss functions assuming that each
data sample is in thermal equilibrium with respect to an approximate energy
landscape. By using the reverse KL divergence with a Boltzmann distribution
around the data, we obtain the loss as an energy difference between the data
and the model predictions. This perspective also recasts traditional objectives
like MSE as energy-based, but with a physically meaningless energy. In
contrast, our formulation yields physically grounded loss functions with
gradients that better align with valid configurations, while being
architecture-agnostic and computationally efficient. The energy loss functions
also inherently respect physical symmetries. We demonstrate our approach on
molecular generation and spin ground-state prediction and report significant
improvements over baselines.

</details>


### [29] [Learning Interactive World Model for Object-Centric Reinforcement Learning](https://arxiv.org/abs/2511.02225)
*Fan Feng,Phillip Lippe,Sara Magliacane*

Main category: cs.LG

TL;DR: FIOC-WM은 객체와 그 상호작용을 구조적으로 학습하는 통합 프레임워크로, 정책 학습의 샘플 효율성 및 일반화 능력을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 객체 및 상호작용을 이해하는 에이전트는 더 강력하고 전이 가능한 정책을 학습할 수 있습니다.

Method: FIOC-WM은 객체 중심의 잠재 변수 및 픽셀로부터 직접 상호작용 구조를 학습합니다. 학습된 세계 모델은 작업을 조합 가능한 상호작용 원시로 분해하고, 계층 정책이 이를 통해 학습됩니다.

Result: FIOC-WM은 로봇 및 구체적 AI 벤치마크에서 정책 학습의 샘플 효율성과 일반화 능력을 개선합니다.

Conclusion: 명시적이고 모듈화된 상호작용 학습이 강력한 제어를 위해 중요함을 나타냅니다.

Abstract: Agents that understand objects and their interactions can learn policies that
are more robust and transferable. However, most object-centric RL methods
factor state by individual objects while leaving interactions implicit. We
introduce the Factored Interactive Object-Centric World Model (FIOC-WM), a
unified framework that learns structured representations of both objects and
their interactions within a world model. FIOC-WM captures environment dynamics
with disentangled and modular representations of object interactions, improving
sample efficiency and generalization for policy learning. Concretely, FIOC-WM
first learns object-centric latents and an interaction structure directly from
pixels, leveraging pre-trained vision encoders. The learned world model then
decomposes tasks into composable interaction primitives, and a hierarchical
policy is trained on top: a high level selects the type and order of
interactions, while a low level executes them. On simulated robotic and
embodied-AI benchmarks, FIOC-WM improves policy-learning sample efficiency and
generalization over world-model baselines, indicating that explicit, modular
interaction learning is crucial for robust control.

</details>


### [30] [Large-scale automatic carbon ion treatment planning for head and neck cancers via parallel multi-agent reinforcement learning](https://arxiv.org/abs/2511.02314)
*Jueye Zhang,Chao Yang,Youfang Lai,Kai-Wen Li,Wenting Yan,Yunzhou Xia,Haimei Zhang,Jingjing Zhou,Gen Yang,Chen Lin,Tian Li,Yibao Zhang*

Main category: cs.LG

TL;DR: 이 논문은 다중 에이전트 강화 학습 프레임워크를 제안하여 IMCT에서 45개의 치료 계획 매개변수를 동시에 조정하여 전문가의 수동 계획과 비교 가능한 결과를 도출하였다.


<details>
  <summary>Details</summary>
Motivation: 두개안면 암 치료에서 임상 목표에 가까운 여러 장기들이 있어 치료 계획이 어렵다. IMCT는 탁월한 선량 일치와 장기 보존을 제공하지만, RBE 모델링으로 인해 느리며, 치료 계획 매개변수 조정은 경험에 기반하여 비효율적일 수 있다.

Method: 다중 에이전트 강화 학습 프레임워크(MARL)를 제안하여 IMCT의 45개 치료 계획 매개변수를 중앙 집합 교육과 분산 실행을 사용하는 방법으로 조정한다.

Result: 제안된 방법은 헤드-앤-넥 데이터셋에서 45개 매개변수를 동시에 조정하였고, 전문가의 수동 계획보다 더 나은 또는 동등한 계획을 생성하였다.

Conclusion: 이 프레임워크는 비선형 치료 계획 매개변수 공간을 효율적으로 탐색하고, 장기 보존을 현저히 개선하며 급속한 데이터 수집을 통해 IMCT 계획의 임상 경쟁력을 높인다.

Abstract: Head-and-neck cancer (HNC) planning is difficult because multiple critical
organs-at-risk (OARs) are close to complex targets. Intensity-modulated
carbon-ion therapy (IMCT) offers superior dose conformity and OAR sparing but
remains slow due to relative biological effectiveness (RBE) modeling, leading
to laborious, experience-based, and often suboptimal tuning of many
treatment-planning parameters (TPPs). Recent deep learning (DL) methods are
limited by data bias and plan feasibility, while reinforcement learning (RL)
struggles to efficiently explore the exponentially large TPP search space. We
propose a scalable multi-agent RL (MARL) framework for parallel tuning of 45
TPPs in IMCT. It uses a centralized-training decentralized-execution (CTDE)
QMIX backbone with Double DQN, Dueling DQN, and recurrent encoding (DRQN) for
stable learning in a high-dimensional, non-stationary environment. To enhance
efficiency, we (1) use compact historical DVH vectors as state inputs, (2)
apply a linear action-to-value transform mapping small discrete actions to
uniform parameter adjustments, and (3) design an absolute, clinically informed
piecewise reward aligned with plan scores. A synchronous multi-process worker
system interfaces with the PHOENIX TPS for parallel optimization and
accelerated data collection. On a head-and-neck dataset (10 training, 10
testing), the method tuned 45 parameters simultaneously and produced plans
comparable to or better than expert manual ones (relative plan score: RL
$85.93\pm7.85%$ vs Manual $85.02\pm6.92%$), with significant (p-value $<$ 0.05)
improvements for five OARs. The framework efficiently explores high-dimensional
TPP spaces and generates clinically competitive IMCT plans through direct TPS
interaction, notably improving OAR sparing.

</details>


### [31] [RoME: Domain-Robust Mixture-of-Experts for MILP Solution Prediction across Domains](https://arxiv.org/abs/2511.02331)
*Tianle Pu,Zijie Geng,Haoyang Liu,Shixuan Liu,Jie Wang,Li Zeng,Chao Chen,Changjun Fan*

Main category: cs.LG

TL;DR: RoME는 다양한 도메인에서 MILP 솔루션을 예측하기 위한 도메인 강건 혼합 전문가 프레임워크로, 문제 인스턴스를 전문 전문가에게 동적으로 라우팅하여 일반화 능력을 높인다.


<details>
  <summary>Details</summary>
Motivation: 기존 MILP 솔버를 가속화하기 위한 학습 기반 방법들이 보편적인 문제 분포에 대한 일반화 능력이 부족하다.

Method: RoME는 학습된 작업 임베딩에 따라 문제 인스턴스를 전문 전문가에게 동적으로 라우팅하는 방식을 사용하며, 두 단계의 분포 강건 최적화 전략으로 훈련된다.

Result: 세 가지 도메인에서 훈련된 RoME 모델은 다섯 가지 다양한 도메인에서 평균 67.7% 향상된 성능을 달성했다.

Conclusion: cross-domain 훈련은 모델의 일반화 능력을 높일 뿐만 아니라 각 도메인 내 성능도 개선한다.

Abstract: Mixed-Integer Linear Programming (MILP) is a fundamental and powerful
framework for modeling complex optimization problems across diverse domains.
Recently, learning-based methods have shown great promise in accelerating MILP
solvers by predicting high-quality solutions. However, most existing approaches
are developed and evaluated in single-domain settings, limiting their ability
to generalize to unseen problem distributions. This limitation poses a major
obstacle to building scalable and general-purpose learning-based solvers. To
address this challenge, we introduce RoME, a domain-Robust Mixture-of-Experts
framework for predicting MILP solutions across domains. RoME dynamically routes
problem instances to specialized experts based on learned task embeddings. The
model is trained using a two-level distributionally robust optimization
strategy: inter-domain to mitigate global shifts across domains, and
intra-domain to enhance local robustness by introducing perturbations on task
embeddings. We reveal that cross-domain training not only enhances the model's
generalization capability to unseen domains but also improves performance
within each individual domain by encouraging the model to capture more general
intrinsic combinatorial patterns. Specifically, a single RoME model trained on
three domains achieves an average improvement of 67.7% then evaluated on five
diverse domains. We further test the pretrained model on MIPLIB in a zero-shot
setting, demonstrating its ability to deliver measurable performance gains on
challenging real-world instances where existing learning-based approaches often
struggle to generalize.

</details>


### [32] [Human-Machine Ritual: Synergic Performance through Real-Time Motion Recognition](https://arxiv.org/abs/2511.02351)
*Zhuodi Cai,Ziyu Xu,Juan Pampin*

Main category: cs.LG

TL;DR: 이 논문에서는 착용 가능한 IMU 센서 데이터를 활용한 경량의 실시간 동작 인식 시스템을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 무선 IMU 센서 데이터를 통해 인간-기계 성능의 시너지를 실현하고, 무용가의 움직임을 사운드와 연계하는 대안적 접근 방식을 제안합니다.

Method: MiniRocket 시간 시리즈 분류 및 반응형 멀티미디어 제어를 사용하여 동작을 인식합니다.

Result: 높은 정확도 분류(<50 ms 지연)을 지원하는 인간 중심 설계의 효과를 입증하였습니다.

Conclusion: 이 프레임워크는 춤을 이해하는 기계를 창의적이고 교육적이며 라이브 공연 맥락에 통합할 수 있는 재현 가능한 방법을 제공합니다.

Abstract: We introduce a lightweight, real-time motion recognition system that enables
synergic human-machine performance through wearable IMU sensor data, MiniRocket
time-series classification, and responsive multimedia control. By mapping
dancer-specific movement to sound through somatic memory and association, we
propose an alternative approach to human-machine collaboration, one that
preserves the expressive depth of the performing body while leveraging machine
learning for attentive observation and responsiveness. We demonstrate that this
human-centered design reliably supports high accuracy classification (<50 ms
latency), offering a replicable framework to integrate dance-literate machines
into creative, educational, and live performance contexts.

</details>


### [33] [LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming Alignment](https://arxiv.org/abs/2511.02371)
*Rohan Wandre,Yash Gajewar,Namrata Patel,Vivek Dhalkari*

Main category: cs.LG

TL;DR: LUMA-RAG는 다중 모달 증거 기반 대규모 언어 모델 출력을 위한 혁신적인 아키텍처로, 지속적인 인덱스 유지 및 다양한 임베딩 공간 간 의미 일관성 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 모던 AI 에이전트는 정적 지식 기반에서 텍스트, 이미지, 비디오, 오디오를 포함한 지속적인 다중 모달 스트림으로 전환되고 있으며, 이 과정에서 인덱스 신선도 유지와 다중 모달 의미 일관성 문제를 해결할 필요성이 있다.

Method: LUMA-RAG는 세 가지 주요 혁신을 특징으로 하는 평생 다중 모달 에이전트 아키텍처로 구성되어 있다: (i) 메모리 예산에 따라 동적으로 HNSW 계층의 임베딩을 IVFPQ 계층으로 쏟아내는 스트리밍 다중 계층 메모리 시스템; (ii) 점진적 직교 프로크루스테스 업데이트를 통해 다중 모달 일관성을 유지하는 스트리밍 CLAP->CLIP 정렬 브리지; (iii) 정렬 드리프트와 양자화 오류를 공동으로 제한하여 Safe@k 보장을 제공하는 안정성 인식 검색 텔레메트리.

Result: 실험 결과, LUMA-RAG는 강력한 텍스트-이미지 검색 성능(Recall@10 = 0.94), 제품 양자화 이탈 아래에서도 부드러운 성능 저하, 확실히 안정적인 오디오-이미지 순위(Safe@1 = 1.0)를 보여주었다.

Conclusion: LUMA-RAG는 실제 생산 다중 모달 RAG 시스템을 위한 실용적인 프레임워크로 자리잡았다.

Abstract: Retrieval-Augmented Generation (RAG) has emerged as the dominant paradigm for
grounding large language model outputs in verifiable evidence. However, as
modern AI agents transition from static knowledge bases to continuous
multimodal streams encompassing text, images, video, and audio, two critical
challenges arise: maintaining index freshness without prohibitive re-indexing
costs, and preserving cross-modal semantic consistency across heterogeneous
embedding spaces. We present LUMA-RAG, a lifelong multimodal agent architecture
featuring three key innovations: (i) a streaming, multi-tier memory system that
dynamically spills embeddings from a hot HNSW tier to a compressed IVFPQ tier
under strict memory budgets; (ii) a streaming CLAP->CLIP alignment bridge that
maintains cross-modal consistency through incremental orthogonal Procrustes
updates; and (iii) stability-aware retrieval telemetry providing Safe@k
guarantees by jointly bounding alignment drift and quantization error.
Experiments demonstrate robust text-to-image retrieval (Recall@10 = 0.94),
graceful performance degradation under product quantization offloading, and
provably stable audio-to-image rankings (Safe@1 = 1.0), establishing LUMA-RAG
as a practical framework for production multimodal RAG systems.

</details>


### [34] [A Spatially Informed Gaussian Process UCB Method for Decentralized Coverage Control](https://arxiv.org/abs/2511.02398)
*Gennaro Guidone,Luca Monegaglia,Elia Raimondi,Han Wang,Mattia Bianchi,Florian Dörfler*

Main category: cs.LG

TL;DR: 본 논문에서는 가우시안 프로세스(GP)로 모델링된 미지의 공간 환경에서의 커버리지 제어를 위한 새로운 분산 알고리즘을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 우리는 탐사와 활용 간의 균형을 맞추기 위한 접근 방식이 필요하다는 점에서 이 연구의 동기가 출발합니다.

Method: 각 에이전트는 국소 비용 함수를 최소화하여 자율적으로 궤적을 결정합니다. GP-UCB 기능에서 영감을 받아, 제안된 비용 함수는 예상 위치 비용과 분산 기반 탐사 항을 결합합니다.

Result: 우리는 알고리즘의 효과를 시뮬레이션을 통해 입증합니다.

Conclusion: 이 알고리즘은 이전 연구와 비교하여 완전히 분산된 방식으로 운영되며, 지역 관측 및 이웃 에이전트와의 통신에 의존합니다.

Abstract: We present a novel decentralized algorithm for coverage control in unknown
spatial environments modeled by Gaussian Processes (GPs). To trade-off between
exploration and exploitation, each agent autonomously determines its trajectory
by minimizing a local cost function. Inspired by the GP-UCB (Upper Confidence
Bound for GPs) acquisition function, the proposed cost combines the expected
locational cost with a variance-based exploration term, guiding agents toward
regions that are both high in predicted density and model uncertainty. Compared
to previous work, our algorithm operates in a fully decentralized fashion,
relying only on local observations and communication with neighboring agents.
In particular, agents periodically update their inducing points using a greedy
selection strategy, enabling scalable online GP updates. We demonstrate the
effectiveness of our algorithm in simulation.

</details>


### [35] [Accounting for Underspecification in Statistical Claims of Model Superiority](https://arxiv.org/abs/2511.02453)
*Thomas Sanchez,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: cs.LG

TL;DR: 의료 영상에서 기계 학습 방법의 성과가 종종 통계적으로 견고하지 않으며, 최근 연구는 작은 성과 향상이 거짓 긍정일 가능성이 높다는 점을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상에서의 기계 학습 적용 증가에도 불구하고, 보고된 성과 향상이 통계적 견고성이 부족합니다.

Method: 최근의 통계적 프레임워크를 확장하여 underspecification을 추가적인 분산 요소로 포함하는 방법론을 제시합니다.

Result: 모든 실험에서 작은 초기(seed) 변동성($	ilde{1	ext{%}}$)이 우수성 주장에 필요한 증거를 상당히 증가시킴을 보여줍니다.

Conclusion: 의료 영상 시스템 검증 시 훈련 분산에 대한 명확한 모델링의 필요성을 강조합니다.

Abstract: Machine learning methods are increasingly applied in medical imaging, yet
many reported improvements lack statistical robustness: recent works have
highlighted that small but significant performance gains are highly likely to
be false positives. However, these analyses do not take
\emph{underspecification} into account -- the fact that models achieving
similar validation scores may behave differently on unseen data due to random
initialization or training dynamics. Here, we extend a recent statistical
framework modeling false outperformance claims to include underspecification as
an additional variance component. Our simulations demonstrate that even modest
seed variability ($\sim1\%$) substantially increases the evidence required to
support superiority claims. Our findings underscore the need for explicit
modeling of training variance when validating medical imaging systems.

</details>


### [36] [BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring](https://arxiv.org/abs/2511.02490)
*Rajan Das Gupta,Md Kishor Morol,Nafiz Fahad,Md Tanzib Hosain,Sumaya Binte Zilani Choya,Md Jakir Hossen*

Main category: cs.LG

TL;DR: BRAINS는 알츠하이머 질병의 조기 탐지와 모니터링을 위한 새로운 시스템으로, 대규모 언어 모델의 추론 능력을 활용하여 구조화된 평가를 수행하고 사례 검색을 통해 유사한 환자 사례를 추출하여 인지 약화 초기 신호를 식별하는 데 효과적이다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병의 글로벌 부담이 증가함에 따라, 특히 고급 진단 도구에 대한 접근이 제한된 지역에서 조기 및 정확한 탐지가 점점 더 중요해지고 있다.

Method: BRAINS는 인지 진단 모듈과 사례 검색 모듈의 두 가지 모듈 구조를 특징으로 하며, 인지 및 신경 영상 데이터 세트에 대해 미세 조정된 LLM을 활용하여 알츠하이머 위험에 대한 구조화된 평가를 수행한다.

Result: 실제 데이터 세트에 대한 평가에서 BRAINS는 질병의 중증도를 분류하고 인지 저하의 조기 징후를 식별하는 데 효과적이다.

Conclusion: 이 시스템은 확장 가능하고 설명 가능한 조기 알츠하이머 질병 탐지를 위한 보조 도구로서 강력한 잠재력을 보여줄 뿐만 아니라, 향후 이 분야의 응용 가능성에 대한 희망을 제공한다.

Abstract: As the global burden of Alzheimer's disease (AD) continues to grow, early and
accurate detection has become increasingly critical, especially in regions with
limited access to advanced diagnostic tools. We propose BRAINS (Biomedical
Retrieval-Augmented Intelligence for Neurodegeneration Screening) to address
this challenge. This novel system harnesses the powerful reasoning capabilities
of Large Language Models (LLMs) for Alzheimer's detection and monitoring.
BRAINS features a dual-module architecture: a cognitive diagnostic module and a
case-retrieval module. The Diagnostic Module utilizes LLMs fine-tuned on
cognitive and neuroimaging datasets -- including MMSE, CDR scores, and brain
volume metrics -- to perform structured assessments of Alzheimer's risk.
Meanwhile, the Case Retrieval Module encodes patient profiles into latent
representations and retrieves similar cases from a curated knowledge base.
These auxiliary cases are fused with the input profile via a Case Fusion Layer
to enhance contextual understanding. The combined representation is then
processed with clinical prompts for inference. Evaluations on real-world
datasets demonstrate BRAINS effectiveness in classifying disease severity and
identifying early signs of cognitive decline. This system not only shows strong
potential as an assistive tool for scalable, explainable, and early-stage
Alzheimer's disease detection, but also offers hope for future applications in
the field.

</details>


### [37] [Dynamic Priors in Bayesian Optimization for Hyperparameter Optimization](https://arxiv.org/abs/2511.02570)
*Lukas Fehring,Marcel Wever,Maximilian Spliethöver,Leona Hennig,Henning Wachsmuth,Marius Lindauer*

Main category: cs.LG

TL;DR: 이 논문은 전문가의 지식을 활용하여 베이지안 최적화(Bayesian Optimization, BO)를 초기화하고 사용자 입력에 따라 온라인으로 이를 조절할 수 있는 새로운 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 머신러닝 전문가들이 하이퍼파라미터 최적화(HPO)를 수용하지 않는 이유를 해결하고자 한다.

Method: 전문가 지식 및 사용자 선호를 사전 분포 형태로 사용하여 BO를 조정할 수 있는 방법을 제안하기 위해 기존의 $C0$BO 방법을 일반화한다.

Result: 여러 사전 정보를 효과적으로 통합하고, 잘못된 사전 정보를 신뢰성 있게 거부하거나 극복함을 입증한다.

Conclusion: 우리는 우리의 방법이 방해받지 않은 BO와 경쟁력을 갖출 수 있음을 보여준다.

Abstract: Hyperparameter optimization (HPO), for example, based on Bayesian
optimization (BO), supports users in designing models well-suited for a given
dataset. HPO has proven its effectiveness on several applications, ranging from
classical machine learning for tabular data to deep neural networks for
computer vision and transformers for natural language processing. However, HPO
still sometimes lacks acceptance by machine learning experts due to its
black-box nature and limited user control. Addressing this, first approaches
have been proposed to initialize BO methods with expert knowledge. However,
these approaches do not allow for online steering during the optimization
process. In this paper, we introduce a novel method that enables repeated
interventions to steer BO via user input, specifying expert knowledge and user
preferences at runtime of the HPO process in the form of prior distributions.
To this end, we generalize an existing method, $\pi$BO, preserving theoretical
guarantees. We also introduce a misleading prior detection scheme, which allows
protection against harmful user inputs. In our experimental evaluation, we
demonstrate that our method can effectively incorporate multiple priors,
leveraging informative priors, whereas misleading priors are reliably rejected
or overcome. Thereby, we achieve competitiveness to unperturbed BO.

</details>


### [38] [Apriel-H1: Towards Efficient Enterprise Reasoning Models](https://arxiv.org/abs/2511.02651)
*Oleksiy Ostapenko,Luke Kumar,Raymond Li,Denis Kocetkov,Joel Lamy-Poirier,Shruthan Radhakrishna,Soham Parikh,Shambhavi Mishra,Sebastien Paquet,Srinivas Sunkara,Valérie Bécaert,Sathwik Tejaswi Madhusudhan,Torsten Scholak*

Main category: cs.LG

TL;DR: 이 논문에서는 15B 모델 크기로 효율적인 추론을 위해 트랜스포머 관심 메커니즘과 상태 공간 모델(SSM) 시퀀스 믹서를 결합한 혼합 대형 언어 모델(Apriel-H1)을 소개한다. 이 모델은 사전 훈련된 추론 트랜스포머로부터 점진적으로 주의를 덜 받는 층을 선형 Mamba 블록으로 대체하는 방식으로 얻어졌다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 추론 능력을 높이기 위해 MHA의 복잡성을 해결할 필요가 있다.

Method: 트랜스포머와 SSM 시퀀스 믹서를 결합하여 혼합 LLM인 Apriel-H1 패밀리를 소개하고, 이를 통해 추론 성능을 높인다.

Result: 최종적으로 2배 이상의 추론 처리량 상승을 달성하며, 추론 성능의 기본적인 저하를 최소화했다.

Conclusion: 사전 훈련된 트랜스포머와 비교하여 혼합 SSM-트랜스포머 아키텍처는 상당한 효율성 향상을 보여준다.

Abstract: Large Language Models (LLMs) achieve remarkable reasoning capabilities
through transformer architectures with attention mechanisms. However,
transformers suffer from quadratic time and memory complexity in the attention
module (MHA) and require caching key-value states during inference, which
severely limits throughput and scalability. High inference throughput is
critical for agentic tasks, long-context reasoning, efficient deployment under
high request loads, and more efficient test-time compute scaling.
  State Space Models (SSMs) such as Mamba offer a promising alternative with
linear inference complexity and a constant memory footprint via recurrent
computation with fixed-size hidden states. In this technical report we
introduce the Apriel-H1 family of hybrid LLMs that combine transformer
attention and SSM sequence mixers for efficient reasoning at 15B model size.
These models are obtained through incremental distillation from a pretrained
reasoning transformer, Apriel-Nemotron-15B-Thinker, progressively replacing
less critical attention layers with linear Mamba blocks.
  We release multiple post-distillation variants of Apriel-H1-15B-Thinker with
different SSM-to-MHA ratios and analyse how reasoning performance degrades as
more Mamba layers replace MHA. Additionally, we release a 30/50 hybrid variant
of Apriel-H1, further fine-tuned on a supervised dataset of reasoning traces,
achieving over 2x higher inference throughput when deployed in the
production-ready vLLM environment, with minimal degradation in reasoning
performance. This shows that distilled hybrid SSM-Transformer architectures can
deliver substantial efficiency gains over the pretrained transformer equivalent
without substantially compromising the reasoning quality.

</details>


### [39] [Curriculum Design for Trajectory-Constrained Agent: Compressing Chain-of-Thought Tokens in LLMs](https://arxiv.org/abs/2511.02690)
*Georgios Tzannetos,Parameswaran Kamalaruban,Adish Singla*

Main category: cs.LG

TL;DR: 제한된 환경에서 작동하는 에이전트를 훈련시키는 것이 복잡한 도전 과제를 제시하며, 본 연구는 점진적으로 제한을 강화하여 에이전트가 배치 요건을 습득하도록 돕는 커리큘럼 학습 전략을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 엄격한 제한 조건 하에서 작동하는 에이전트를 훈련시키는 것은 큰 도전 과제를 제공한다.

Method: 제한을 점진적으로 강화하는 커리큘럼 학습 전략을 제안하며, 초기에는 간소화된 버전으로 훈련하고 점차 전체 배치 조건을 도입한다.

Result: 이론 분석을 통해 우리 커리큘럼 전략이 기본 방법에 비해 훈련을 가속화할 수 있음을 시연하며, 다양한 환경에서 우리의 방법의 효과성을 실증적으로 검증한다.

Conclusion: 커리큘럼 디자인은 복잡한 궤적 제약 하에서 작동하는 에이전트의 효율성과 성능을 향상하는 데 잠재력을 가지고 있으며, 자원 제한 배치에 효과적이다.

Abstract: Training agents to operate under strict constraints during deployment, such
as limited resource budgets or stringent safety requirements, presents
significant challenges, especially when these constraints render the task
complex. In this work, we propose a curriculum learning strategy that gradually
tightens constraints during training, enabling the agent to incrementally
master the deployment requirements. Inspired by self-paced learning techniques
in unconstrained reinforcement learning (RL), our approach facilitates a
smoother transition to challenging environments by initially training on
simplified versions of the constraints and progressively introducing the full
deployment conditions. We provide a theoretical analysis using an RL agent in a
binary-tree Markov Decision Process (MDP) to demonstrate that our curriculum
strategy can accelerate training relative to a baseline approach that imposes
the trajectory constraints from the outset. Moreover, we empirically validate
the effectiveness and generality of our method across both RL and large
language model (LLM) agents in diverse settings, including a binary-tree MDP, a
multi-task navigation domain, and a math reasoning task with two benchmarks.
These results highlight the potential of curriculum design in enhancing the
efficiency and performance of agents operating under complex trajectory
constraints during deployment. Moreover, when applied to LLMs, our strategy
enables compression of output chain-of-thought tokens, achieving a substantial
inference speedup on consumer hardware, demonstrating its effectiveness for
resource-constrained deployment.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [40] [1 PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts](https://arxiv.org/abs/2511.02780)
*Vivi Andersson,Sofia Bobadilla,Harald Hobbelhagen,Martin Monperrus*

Main category: cs.CR

TL;DR: POCO는 감사자가 작성한 자연어 취약성 설명으로부터 자동으로 실행 가능한 PoC 익스플로잇을 생성하는 에이전틱 프레임워크로, 스마트 계약 감사에서 높은 품질의 PoC 작업의 노력을 크게 줄인다.


<details>
  <summary>Details</summary>
Motivation: 스마트 계약의 취약점은 막대한 금융 손실을 초래할 수 있으므로 보안 감사가 필요하다.

Method: POCO는 Reason-Act-Observe 루프를 통해 코드 실행 도구 세트와 상호 작용하여 에이전틱 방식으로 PoC 익스플로잇을 자동 생성한다.

Result: POCO는 23개의 실제 취약성 보고서 데이터 세트에서 일관되게 기존 방법보다 우수한 성능을 보이며, 잘 형성된 논리적으로 올바른 PoC를 생성하였다.

Conclusion: 에이전틱 프레임워크는 스마트 계약 감사에서 고품질 PoC를 위한 노력을 획기적으로 줄일 수 있음을 입증한다.

Abstract: Smart contracts operate in a highly adversarial environment, where
vulnerabilities can lead to substantial financial losses. Thus, smart contracts
are subject to security audits. In auditing, proof-of-concept (PoC) exploits
play a critical role by demonstrating to the stakeholders that the reported
vulnerabilities are genuine, reproducible, and actionable. However, manually
creating PoCs is time-consuming, error-prone, and often constrained by tight
audit schedules. We introduce POCO, an agentic framework that automatically
generates executable PoC exploits from natural-language vulnerability
descriptions written by auditors. POCO autonomously generates PoC exploits in
an agentic manner by interacting with a set of code-execution tools in a
Reason-Act-Observe loop. It produces fully executable exploits compatible with
the Foundry testing framework, ready for integration into audit reports and
other security tools. We evaluate POCO on a dataset of 23 real-world
vulnerability reports. POCO consistently outperforms the prompting and workflow
baselines, generating well-formed and logically correct PoCs. Our results
demonstrate that agentic frameworks can significantly reduce the effort
required for high-quality PoCs in smart contract audits. Our contribution
provides readily actionable knowledge for the smart contract security
community.

</details>
