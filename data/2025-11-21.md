<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 12]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 11]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning](https://arxiv.org/abs/2511.15002)
*Fatemeh Lotfi,Hossein Rajoli,Fatemeh Afghah*

Main category: cs.AI

TL;DR: 이 논문은 Soft Actor Critic(SAC) 알고리즘을 Sharpness-Aware Minimization(SAM)으로 강화하여 분산된 다중 에이전트 강화 학습(MARL) 프레임워크에서 자원 관리 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다음 세대 네트워크는 Open Radio Access Network(O-RAN) 아키텍처를 활용하여 RAN Intelligent Controller(RIC)를 통한 동적 자원 관리를 가능하게 한다.

Method: Soft Actor Critic(SAC) 알고리즘에 Sharpness-Aware Minimization(SAM)을 통합한 분산된 다중 에이전트 강화 학습(MARL) 프레임워크에서 자원 관리 방법을 제안한다.

Result: 이 방법은 자원 할당 효율성을 최대 $22\\%$ 개선하고 다양한 O-RAN 슬라이스에서 우수한 QoS 만족도를 보장한다.

Conclusion: 이 전략은 불필요한 오버헤드를 줄이고 훈련 안정성을 향상시키며 학습 효율성을 희생하지 않고 일반화를 개선한다.

Abstract: Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing network resources, they often struggle with robustness and generalizability in dynamic environments. This paper introduces a novel resource management approach that enhances the Soft Actor Critic (SAC) algorithm with Sharpness-Aware Minimization (SAM) in a distributed Multi-Agent RL (MARL) framework. Our method introduces an adaptive and selective SAM mechanism, where regularization is explicitly driven by temporal-difference (TD)-error variance, ensuring that only agents facing high environmental complexity are regularized. This targeted strategy reduces unnecessary overhead, improves training stability, and enhances generalization without sacrificing learning efficiency. We further incorporate a dynamic $ρ$ scheduling scheme to refine the exploration-exploitation trade-off across agents. Experimental results show our method significantly outperforms conventional DRL approaches, yielding up to a $22\%$ improvement in resource allocation efficiency and ensuring superior QoS satisfaction across diverse O-RAN slices.

</details>


### [2] [Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents](https://arxiv.org/abs/2511.14780)
*Keith Moore,Jun W. Kim,David Lyu,Jeffrey Heo,Ehsan Adeli*

Main category: cs.AI

TL;DR: Ask WhAI는 다중 에이전트 상호작용에서 신념 상태를 검사하고 교란하는 시스템 수준의 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 상호작용에서 신념 형성과 인식의 다차원적 역동성을 연구할 필요가 있다.

Method: 에이전트 상호작용을 기록하고 재생하며, 에이전트의 신념과 근거를 비대칭적으로 질의하고, 반사실적 증거 주입을 통해 신념 구조의 반응을 테스트하는 방법을 사용하였다.

Result: 의료 사례 시뮬레이터에 프레임워크를 적용하여 에이전트 신념이 실제 세계의 학문적 입장을 반영하고, 인간 전문가와는 다른 방식으로 신념을 추적하고 조사할 수 있음을 보여주었다.

Conclusion: Ask WhAI는 다중 에이전트 과학적 추론에서 신념 형성과 인식의 고립을 연구하는 재현 가능한 방법을 제공한다.

Abstract: We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent's beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors ("act like a neurologist", "act like an infectious disease specialist"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.

</details>


### [3] [Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization](https://arxiv.org/abs/2511.15055)
*Jian-Ting Guo,Yu-Cheng Chen,Ping-Chun Hsieh,Kuo-Hao Ho,Po-Wei Huang,Ti-Rong Wu,I-Chen Wu*

Main category: cs.AI

TL;DR: 이 논문은 인공지능에서 인간과 유사한 행동을 보이는 에이전트를 개발하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인간과 유사한 에이전트를 개발하는 것은 인공지능의 오랜 목표이며, 많은 RL 에이전트가 비자연적 행동을 보이는 문제를 해결하고자 함.

Method: 인간 유사성을 행동 최적화로 공식화하고, 고전적인 지연 제어법을 통해 RL에 적용하며, Macro Action Quantization (MAQ) 프레임워크를 도입하여 인간 시연을 매크로 행동으로 증류한다.

Result: MAQ는 D4RL Adroit 벤치마크에서 인간 유사성을 크게 향상시키고, 모든 RL 에이전트 중에서 인간 평가 연구에서 가장 높은 인간 유사성 순위를 달성했다.

Conclusion: MAQ는 다양한 RL 알고리즘에 쉽게 통합될 수 있으며, 인간과 유사한 RL 에이전트를 학습하는 유망한 방향성을 열어준다.

Abstract: Human-like agents have long been one of the goals in pursuing artificial intelligence. Although reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL agents. As a result, many reward-driven RL agents often exhibit unnatural behaviors compared to humans, raising concerns for both interpretability and trustworthiness. To achieve human-like behavior in RL, this paper first formulates human-likeness as trajectory optimization, where the objective is to find an action sequence that closely aligns with human behavior while also maximizing rewards, and adapts the classic receding-horizon control to human-like learning as a tractable and efficient implementation. To achieve this, we introduce Macro Action Quantization (MAQ), a human-like RL framework that distills human demonstrations into macro actions via Vector-Quantized VAE. Experiments on D4RL Adroit benchmarks show that MAQ significantly improves human-likeness, increasing trajectory similarity scores, and achieving the highest human-likeness rankings among all RL agents in the human evaluation study. Our results also demonstrate that MAQ can be easily integrated into various off-the-shelf RL algorithms, opening a promising direction for learning human-like RL agents. Our code is available at https://rlg.iis.sinica.edu.tw/papers/MAQ.

</details>


### [4] [Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering](https://arxiv.org/abs/2511.15061)
*Haodong Chen,Guido Zuccon,Teerapong Leelanupab*

Main category: cs.AI

TL;DR: 본 연구는 GeneGPT의 한계를 극복하고, 오픈소스 모델을 기반으로 한 새로운 프레임워크 OpenBioLLM을 개발하여 유전체 질문 응답을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: 유전체 질문 응답에 필요한 복잡한 추론과 다양한 생물의학 소스 간의 통합은 어려운 문제이다.

Method: Llama 3.1, Qwen2.5 및 Qwen2.5 Coder와 같은 오픈소스 모델을 사용하여 GeneGPT를 재구성하고, 이를 바탕으로 에이전트 전문화 기능을 도입한 OpenBioLLM이라는 모듈형 다중 에이전트 프레임워크를 개발하였다.

Result: OpenBioLLM은 기준 작업의 90% 이상에서 GeneGPT와 동등하거나 더 나은 성능을 보였으며, 평균 점수는 Gene-Turing에서 0.849, GeneHop에서 0.830을 기록하였다.

Conclusion: OpenBioLLM의 모듈형 설계는 기준 작업에서 지연 시간을 40-50% 감소시켜, 모델의 능력을 손상시키지 않으면서 효율성을 크게 향상시켰다. 본 연구 결과는 유전체 질문 응답을 위한 오픈소스 다중 에이전트 시스템의 잠재력을 강조한다.

Abstract: Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.
  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.
  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.

</details>


### [5] [Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents](https://arxiv.org/abs/2511.15074)
*Henrik Bradland,Morten Goodwin,Vladimir I. Zadorozhny,Per-Arne Andersen*

Main category: cs.AI

TL;DR: Rogue One은 질 높은 특성 추출을 위해 세 가지 전문 에이전트(Scientist, Extractor, Tester)가 협력하여 예측 특성을 발견, 생성 및 검증하는 분산형 시스템을 운영하는 LLM 기반의 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 모델의 성능은 고품질 특성 엔지니어링에 크게 의존하기 때문에, 자동화된 특성 추출 방법을 향상시키는 것이 필요하다.

Method: Rogue One은 Scientist, Extractor, Tester라는 세 가지 전문 에이전트가 협력하여 자동으로 특성을 추출하고 검증하는 분산형 시스템을 운영한다.

Result: Rogue One은 19개의 분류 데이터셋과 9개의 회귀 데이터셋에서 최신 방법들을 크게 능가하는 성능을 보여주었다.

Conclusion: Rogue One은 새로운 가설을 발견하고 과학적 발견 도구로서의 유용성을 강조하는 특성을 생성하는 데 기여한다.

Abstract: The performance of machine learning models on tabular data is critically dependent on high-quality feature engineering. While Large Language Models (LLMs) have shown promise in automating feature extraction (AutoFE), existing methods are often limited by monolithic LLM architectures, simplistic quantitative feedback, and a failure to systematically integrate external domain knowledge. This paper introduces Rogue One, a novel, LLM-based multi-agent framework for knowledge-informed automatic feature extraction. Rogue One operationalizes a decentralized system of three specialized agents-Scientist, Extractor, and Tester-that collaborate iteratively to discover, generate, and validate predictive features. Crucially, the framework moves beyond primitive accuracy scores by introducing a rich, qualitative feedback mechanism and a "flooding-pruning" strategy, allowing it to dynamically balance feature exploration and exploitation. By actively incorporating external knowledge via an integrated retrieval-augmented (RAG) system, Rogue One generates features that are not only statistically powerful but also semantically meaningful and interpretable. We demonstrate that Rogue One significantly outperforms state-of-the-art methods on a comprehensive suite of 19 classification and 9 regression datasets. Furthermore, we show qualitatively that the system surfaces novel, testable hypotheses, such as identifying a new potential biomarker in the myocardial dataset, underscoring its utility as a tool for scientific discovery.

</details>


### [6] [SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making](https://arxiv.org/abs/2511.15202)
*Yinsheng Wang,Tario G You,Léonard Boussioux,Shan Liu*

Main category: cs.AI

TL;DR: SOLID는 최적화 및 대형 언어 모델의 능력을 통합한 새로운 프레임워크로, 의사결정을 개선하는 데 기여한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델과 최적화의 결합을 통해 지능형 의사결정의 품질을 향상시키기 위해서이다.

Method: 이중 가격과 편차 벌칙을 활용하여 최적화와 LLM 간의 반복적 협업을 촉진한다.

Result: 다양한 시나리오에서 수렴을 보였으며, 기준 최적화 방법에 비해 개선된 연간 수익률을 나타낸다.

Conclusion: SOLID는 다양한 분야에서 자동화 및 지능형 의사결정을 발전시킬 유망한 프레임워크를 제공한다.

Abstract: This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains.

</details>


### [7] [Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration](https://arxiv.org/abs/2511.15351)
*Yifu Guo,Zishan Xu,Zhiyuan Yao,Yuquan Lu,Jiaye Lin,Sen Hu,Zhenheng Tang,Yingchao Li,Huacan Wang,Ronghao Chen*

Main category: cs.AI

TL;DR: Octopus는 다양한 추론 경로를 자율적으로 탐색할 수 있는 능력을 갖춘 새로운 다중모달 추론 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: 중기존의 다중모달 추론 모델은 다양한 추론 경로를 자율적으로 탐색하는 인간과 같은 능력이 부족하다.

Method: 여섯 가지 핵심 능력을 정의하고, Octopus-Bench라는 포괄적인 평가 기준을 조직하여 Octopus를 개발했다.

Result: Octopus는 Octopus-Bench의 대다수의 작업에서 최고의 성능을 달성했다.

Conclusion: 능력 조정이 자율적 다중모달 추론에서 중요한 역할을 한다는 것을 강조한다.

Abstract: Existing multimodal reasoning models and frameworks suffer from fundamental architectural limitations: most lack the human-like ability to autonomously explore diverse reasoning pathways-whether in direct inference, tool-driven visual exploration, programmatic visual manipulation, or intrinsic visual imagination. Consequently, they struggle to adapt to dynamically changing capability requirements in real-world tasks. Meanwhile, humans exhibit a complementary set of thinking abilities when addressing such tasks, whereas existing methods typically cover only a subset of these dimensions. Inspired by this, we propose Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration, a new paradigm for multimodal agentic reasoning. We define six core capabilities essential for multimodal reasoning and organize a comprehensive evaluation benchmark, Octopus-Bench, accordingly. Octopus is capable of autonomously exploring during reasoning and dynamically selecting the most appropriate capability based on the current state. Experimental results show that Octopus achieves the best performance on the vast majority of tasks in Octopus-Bench, highlighting the crucial role of capability coordination in agentic multimodal reasoning.

</details>


### [8] [Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents](https://arxiv.org/abs/2511.15378)
*Trevor McInroe*

Main category: cs.AI

TL;DR: Terra Nova는 Civilization V에서 영감을 받아 강화 학습 연구를 위한 새로운 포괄적 도전 환경을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: Terra Nova는 강화 학습의 여러 전통적인 과제가 동시에 발생하는 단일 환경을 제공하기 위해 개발되었습니다.

Method: 이 환경은 여러 상호작용 변수에 대한 통합된 장기 이해가 필요하도록 설계되었습니다.

Result: Terra Nova는 과제가 상호작용하는 복잡한 상황에서 에이전트의 심층적 추론 능력을 테스트하도록 돕습니다.

Conclusion: 이 연구는 무관한 작업들을 독립적이고 병렬적인 흐름으로 집계하는 것만으로는 에이전트의 실제 역량을 평가할 수 없음을 강조합니다.

Abstract: We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.

</details>


### [9] [IPR-1: Interactive Physical Reasoner](https://arxiv.org/abs/2511.15407)
*Mingyu Zhang,Lifeng Zhuo,Tianxi Tan,Guocan Xie,Xian Nie,Yan Li,Renjie Zhao,Zizhu He,Ziyu Wang,Jiting Cai,Yong-Lu Li*

Main category: cs.AI

TL;DR: 이 연구는 에이전트가 경험을 통해 인간과 유사한 추론 능력을 갖출 수 있는지 탐구하고, 다양한 게임을 통해 IPR(Interactive Physical Reasoner) 모델을 개발하여 물리적 추론 능력을 향상시키는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트가 상호작용을 통해 인간과 유사한 추론 능력을 획득할 수 있을지에 대한 질문을 던지기 위해.

Method: 1,000개 이상의 다양한 게임을 통해 에이전트의 물리적 추론 능력을 평가하고, IPR을 통해 VLM의 정책을 강화하는 방법을 도입하였다.

Result: IPR 모델은 세 가지 인간 유사 수준에서 강건하게 성능을 발휘하며, GPT-5와 비슷한 성능을 보인다.

Conclusion: 물리 기반의 상호작용이 물리적 추론을 꾸준히 향상시키는 경로임을 지지한다.

Abstract: Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.

</details>


### [10] [Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining](https://arxiv.org/abs/2511.15456)
*Qian'ang Mao,Yuxuan Zhang,Jiaman Chen,Wenjun Zhou,Jiaqi Yan*

Main category: cs.AI

TL;DR: DeFi 거래의 사용자 의도를 이해하기 위한 TIM 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: DeFi의 발전에 따라 거래의 사용자 의도를 이해하는 것은 필요하면서도, 복잡한 스마트 계약 상호작용과 다면적인 요소들로 인해 어려움이 있다.

Method: TIM 프레임워크는 근거 이론에 기반한 DeFi 의도 분류 및 다중 에이전트 대형 언어 모델 시스템을 활용하여 사용자 의도를 추론하는 데 목적을 두고 있다.

Result: TIM은 기계학습 모델, 단일 LLM, 단일 에이전트 기준선보다 성능이 크게 향상된다는 것을 실험을 통해 보여준다.

Conclusion: 이 연구는 DeFi에서 사용자 동기에 대한 보다 신뢰할 수 있는 이해를 제공하며, 복잡한 블록체인 활동에 대한 상황 인식 설명을 제공한다.

Abstract: As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.

</details>


### [11] [Exploring the use of AI authors and reviewers at Agents4Science](https://arxiv.org/abs/2511.15534)
*Federico Bianchi,Owen Queen,Nitya Thakkar,Eric Sun,James Zou*

Main category: cs.AI

TL;DR: AI 에이전트를 과학 연구에 활용하는 데 대한 관심이 증가하고 있으며, 이들의 과학자 및 리뷰어로서의 능력에 대한 기초적인 질문이 남아있습니다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트를 과학 연구에 활용하는 방법과 그 가능성에 대한 탐구가 필요합니다.

Method: Agents4Science라는 최초의 컨퍼런스를 통해 AI 에이전트가 주요 저자 및 리뷰어 역할을 수행하게 하였으며, 인간은 공저자 및 공동 리뷰어로 참여했습니다.

Result: 컨퍼런스에서 얻은 주요 학습과 이들이 인간과 AI 간 협력에 미치는 함의를 논의합니다.

Conclusion: AI 에이전트의 역할과 그들의 능력 이해가 과학 연구의 미래에 중요한 영향을 미칠 것입니다.

Abstract: There is growing interest in using AI agents for scientific research, yet fundamental questions remain about their capabilities as scientists and reviewers. To explore these questions, we organized Agents4Science, the first conference in which AI agents serve as both primary authors and reviewers, with humans as co-authors and co-reviewers. Here, we discuss the key learnings from the conference and their implications for human-AI collaboration in science.

</details>


### [12] [What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity](https://arxiv.org/abs/2511.15593)
*Alexis Audran-Reiss,Jordi Armengol Estapé,Karen Hambardzumyan,Amar Budhiraja,Martin Josifoski,Edan Toledo,Rishi Hazra,Despoina Magka,Michael Shvartsman,Parth Pathak,Justine T Kao,Lucia Cipolina-Kun,Bhavul Gauri,Jean-Christophe Gagnon-Audet,Emanuel Tewolde,Jenny Zhang,Taco Cohen,Yossi Adi,Tatiana Shavrina,Yoram Bachrach*

Main category: cs.AI

TL;DR: AI 연구 에이전트는 기계 학습 모델의 설계, 구현 및 훈련을 자동화하여 과학적 진행을 가속화할 잠재력을 가지고 있다. 이 연구는 아이디어 다양성이 에이전트 성능에 미치는 영향을 조사한다.


<details>
  <summary>Details</summary>
Motivation: AI 연구 에이전트의 성공 또는 실패를 이끄는 주요 요소를 이해하기 위해 아이디어 다양성의 역할을 조사한다.

Method: MLE-bench를 사용하여 다양한 모델과 에이전트 스캐폴드에서 에이전트의 경로를 분석하고, 아이디어 다양성을 조절하여 실험을 진행한다.

Result: 다양한 모델과 에이전트 스캐폴드가 다르게 아이디어 다양성을 생성하며, 성능이 높은 에이전트들은 더 높은 아이디어 다양성을 보인다. 아이디어 다양성이 더 높은 경우 성능이 향상된다는 결과를 얻었다.

Conclusion: 다양한 평가 지표를 통해 우리의 발견이 다른 에이전트 성능 메트릭에서도 적용됨을 확인하였다.

Abstract: AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [13] [Attacking Autonomous Driving Agents with Adversarial Machine Learning: A Holistic Evaluation with the CARLA Leaderboard](https://arxiv.org/abs/2511.14876)
*Henry Wong,Clement Fung,Weiran Lin,Karen Li,Stanley Chen,Lujo Bauer*

Main category: cs.CR

TL;DR: 자율 주행을 위한 공격의 위험성을 평가하기 위해, 다양한 주행 에이전트에 대한 공격을 평가하고, CARLA 시뮬레이터를 활용하여 적대적 예제를 생성하고 분석한다. 이 연구는 주행 에이전트 코드를 수정하지 않고도 시스템에 대한 공격을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 자율 주행 차량의 안전성을 향상시키기 위해 적대적 예제가 다양한 주행 에이전트에 미치는 영향을 조사하고자 한다.

Method: CARLA 도시 주행 시뮬레이터를 사용하여 주행 에이전트를 멈추거나 방향을 바꾸도록 설계된 적대적 패치를 생성하고, 이를 여러 시나리오에서 테스트한다.

Result: 일부 공격은 ML 모델을 오도하여 잘못된 명령을 예측하지만, 일부 주행 에이전트는 공격자의 조작을 무시하고 안정적인 작동을 유지한다.

Conclusion: 자율 주행 시스템에 대한 공격이 모든 에이전트에 동일하게 효과적이지 않으며, 일부 시스템은 공격을 과감하게 방어할 수 있는 모듈을 포함하고 있다.

Abstract: To autonomously control vehicles, driving agents use outputs from a combination of machine-learning (ML) models, controller logic, and custom modules. Although numerous prior works have shown that adversarial examples can mislead ML models used in autonomous driving contexts, it remains unclear if these attacks are effective at producing harmful driving actions for various agents, environments, and scenarios.
  To assess the risk of adversarial examples to autonomous driving, we evaluate attacks against a variety of driving agents, rather than against ML models in isolation. To support this evaluation, we leverage CARLA, an urban driving simulator, to create and evaluate adversarial examples. We create adversarial patches designed to stop or steer driving agents, stream them into the CARLA simulator at runtime, and evaluate them against agents from the CARLA Leaderboard, a public repository of best-performing autonomous driving agents from an annual research competition. Unlike prior work, we evaluate attacks against autonomous driving systems without creating or modifying any driving-agent code and against all parts of the agent included with the ML model.
  We perform a case-study investigation of two attack strategies against three open-source driving agents from the CARLA Leaderboard across multiple driving scenarios, lighting conditions, and locations. Interestingly, we show that, although some attacks can successfully mislead ML models into predicting erroneous stopping or steering commands, some driving agents use modules, such as PID control or GPS-based rules, that can overrule attacker-manipulated predictions from ML models.

</details>


### [14] [LFreeDA: Label-Free Drift Adaptation for Windows Malware Detection](https://arxiv.org/abs/2511.14963)
*Adrian Shuai Li,Elisa Bertino*

Main category: cs.CR

TL;DR: LFreeDA는 라벨링이나 드리프트 감지 없이 맬웨어 분류기를 적응시키는 프레임워크로, 라벨이 있는 샘플과 없는 샘플을 공동으로 훈련하여 유사 라벨을 추론하고 노이즈를 감소시킵니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 맬웨어 탐지 모델은 훈련 중에 보지 못한 새로운 가족이 등장함에 따라 시간이 지남에 따라 성능이 저하됩니다. 수동 라벨링 또는 샌드박스 분석의 비용과 시간이 재훈련을 제한합니다.

Method: LFreeDA는 비지도 도메인 적응을 통해 맬웨어 이미지에 대해 라벨이 있는 샘플과 없는 샘플을 공동으로 훈련하여 유사 라벨을 추론하고, CFG 표현을 사용하여 분류기를 적응시킵니다.

Result: LFreeDA는 MB-24+ 데이터셋에서 정확도를 최대 12.6% 향상시키고 F1 점수를 11.1% 향상시키며, 완전 감독 상한선과 각각 정확도 및 F1에서 4% 및 3.4% 떨어진 성능을 보입니다.

Conclusion: LFreeDA는 라벨링 없이도 맬웨어 감지 성능을 유지하며, 진화하는 맬웨어에 적응할 수 있음을 보여줍니다.

Abstract: Machine learning (ML)-based malware detectors degrade over time as concept drift introduces new and evolving families unseen during training. Retraining is limited by the cost and time of manual labeling or sandbox analysis. Existing approaches mitigate this via drift detection and selective labeling, but fully label-free adaptation remains largely unexplored. Recent self-training methods use a previously trained model to generate pseudo-labels for unlabeled data and then train a new model on these labels. The unlabeled data are used only for inference and do not participate in training the earlier model. We argue that these unlabeled samples still carry valuable information that can be leveraged when incorporated appropriately into training. This paper introduces LFreeDA, an end-to-end framework that adapts malware classifiers to drift without manual labeling or drift detection. LFreeDA first performs unsupervised domain adaptation on malware images, jointly training on labeled and unlabeled samples to infer pseudo-labels and prune noisy ones. It then adapts a classifier on CFG representations using the labeled and selected pseudo-labeled data, leveraging the scalability of images for pseudo-labeling and the richer semantics of CFGs for final adaptation. Evaluations on the real-world MB-24+ dataset show that LFreeDA improves accuracy by up to 12.6% and F1 by 11.1% over no-adaptation lower bounds, and is only 4% and 3.4% below fully supervised upper bounds in accuracy and F1, respectively. It also matches the performance of state-of-the-art methods provided with ground truth labels for 300 target samples. Additional results on two controlled-drift benchmarks further confirm that LFreeDA maintains malware detection performance as malware evolves without human labeling.

</details>


### [15] [MAIF: Enforcing AI Trust and Provenance with an Artifact-Centric Agentic Paradigm](https://arxiv.org/abs/2511.15097)
*Vineeth Sai Narajala,Manish Bhatt,Idan Habler,Ronald F. Del Rosario*

Main category: cs.CR

TL;DR: AI의 신뢰성 위기가 인공지능 혁명을 저해하고 있으며, 현재의 시스템들은 규제 요구를 충족하지 못하고 있다. 이 논문에서는 데이터 아키텍처 수준에서 신뢰성 문제를 해결하기 위한 새로운 패러다임을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 인공지능의 신뢰성이 낮아지면서 규제 장벽, 보안 취약점 등이 존재하며, 이는 중요한 분야에서 AI의 배치를 방해하고 있다.

Method: 우리는 데이터 아티팩트에 의해 구동되는 아티팩트 중심 AI 에이전트 패러다임을 제안하며, 이를 위해 다중모드 아티팩트 파일 형식(MAIF)을 사용한다.

Result: MAIF는 데이터를 수동 저장에서 능동적 신뢰 강제로 변화시키며, 우리의 구현은 매우 빠른 스트리밍과 최적화된 비디오 처리 속도, 기업 수준의 보안을 보여준다.

Conclusion: 이 접근 방식은 AI 배치를 방해하는 규제, 보안, 책임 문제를 해결하며, 신뢰할 수 있는 AI 시스템을 대규모로 구현할 수 있는 실현 가능한 경로를 제공한다.

Abstract: The AI trustworthiness crisis threatens to derail the artificial intelligence revolution, with regulatory barriers, security vulnerabilities, and accountability gaps preventing deployment in critical domains. Current AI systems operate on opaque data structures that lack the audit trails, provenance tracking, or explainability required by emerging regulations like the EU AI Act. We propose an artifact-centric AI agent paradigm where behavior is driven by persistent, verifiable data artifacts rather than ephemeral tasks, solving the trustworthiness problem at the data architecture level. Central to this approach is the Multimodal Artifact File Format (MAIF), an AI-native container embedding semantic representations, cryptographic provenance, and granular access controls. MAIF transforms data from passive storage into active trust enforcement, making every AI operation inherently auditable. Our production-ready implementation demonstrates ultra-high-speed streaming (2,720.7 MB/s), optimized video processing (1,342 MB/s), and enterprise-grade security. Novel algorithms for cross-modal attention, semantic compression, and cryptographic binding achieve up to 225 compression while maintaining semantic fidelity. Advanced security features include stream-level access control, real-time tamper detection, and behavioral anomaly analysis with minimal overhead. This approach directly addresses the regulatory, security, and accountability challenges preventing AI deployment in sensitive domains, offering a viable path toward trustworthy AI systems at scale.

</details>


### [16] [Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks](https://arxiv.org/abs/2511.15203)
*Zimo Ji,Xunguang Wang,Zongjie Li,Pingchuan Ma,Yudong Gao,Daoyuan Wu,Xincheng Yan,Tian Tian,Shuai Wang*

Main category: cs.CR

TL;DR: 본 연구는 간접 프롬프트 주입 공격에 대한 방어 프레임워크의 포괄적인 분석을 제공하며, 이를 분류하고 평가하여 향후 개발에 기초를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트가 간접 프롬프트 주입 공격에 취약하고, 이에 대한 방어 프레임워크가 단편적이어서 통합적인 분류와 평가가 필요하다.

Method: 간접 프롬프트 주입 방어 프레임워크를 다섯 가지 차원으로 분류하고, 각 프레임워크의 보안성과 사용성을 철저히 평가했다. 방어 실패 사례 분석을 통해 방어 회피의 여섯 가지 근본 원인을 식별하였다.

Result: 세 가지 새로운 적응형 공격을 설계하고 특정 프레임워크를 목표로 하여 공격 성공률을 크게 개선하였다.

Conclusion: 본 논문은 더 안전하고 사용 가능한 간접 프롬프트 주입 에이전트 방어 프레임워크 개발을 위한 기초와 중요한 통찰을 제공한다.

Abstract: Large Language Model (LLM)-based agents with function-calling capabilities are increasingly deployed, but remain vulnerable to Indirect Prompt Injection (IPI) attacks that hijack their tool calls. In response, numerous IPI-centric defense frameworks have emerged. However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation. In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks. We introduce a comprehensive taxonomy of these defenses, classifying them along five dimensions. We then thoroughly assess the security and usability of representative defense frameworks. Through analysis of defensive failures in the assessment, we identify six root causes of defense circumvention. Based on these findings, we design three novel adaptive attacks that significantly improve attack success rates targeting specific frameworks, demonstrating the severity of the flaws in these defenses. Our paper provides a foundation and critical insights for the future development of more secure and usable IPI-centric agent defense frameworks.

</details>


### [17] [Trustworthy GenAI over 6G: Integrated Applications and Security Frameworks](https://arxiv.org/abs/2511.15206)
*Bui Duc Son,Trinh Van Chien,Dong In Kim*

Main category: cs.CR

TL;DR: 6G 네트워크에 생성적 인공지능(GenAI)을 통합하면 성능 향상이 기대되지만, 보안 취약점도 생긴다. 이 논문은 ISAC, federated learning(FL), 디지털 트윈(DT), 확산 모델(DM), 대형 통신 모델(LTM)에서 발생하는 취약점을 다룬다. GenAI에 기반한 적응형 진화 방어(AED) 개념을 제안하고, LLM 기반 포트 예측 모델 사례를 통해 GenAI 모듈의 취약성과 방어 개념의 효과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 6G 네트워크에 GenAI를 통합하면 성능을 크게 향상시킬 수 있지만, 새로운 보안 취약점이 발생할 수 있다.

Method: 전반적인 보안 취약점을 다루기 위해 ISAC, FL, DT, DM, LTM의 통합된 관점을 제시하고, 공격과 동반하여 진화하는 적응형 진화 방어(AED) 개념을 제안한다.

Result: LLM 기반 포트 예측 모델을 사례 연구로 사용하여 GenAI 모듈이 적대적 변동에 취약함을 보여주고, 제안된 방어 개념의 효과를 입증하였다.

Conclusion: 신뢰할 수 있고 양자 내성과 적응력이 있는 GenAI 지원 6G 네트워크 구축을 위한 개방형 과제와 향후 연구 방향을 요약한다.

Abstract: The integration of generative artificial intelligence (GenAI) into 6G networks promises substantial performance gains while simultaneously exposing novel security vulnerabilities rooted in multimodal data processing and autonomous reasoning. This article presents a unified perspective on cross-domain vulnerabilities that arise across integrated sensing and communication (ISAC), federated learning (FL), digital twins (DTs), diffusion models (DMs), and large telecommunication models (LTMs). We highlight emerging adversarial agents such as compromised DTs and LTMs that can manipulate both the physical and cognitive layers of 6G systems. To address these risks, we propose an adaptive evolutionary defense (AED) concept that continuously co-evolves with attacks through GenAI-driven simulation and feedback, combining physical-layer protection, secure learning pipelines, and cognitive-layer resilience. A case study using an LLM-based port prediction model for fluid-antenna systems demonstrates the susceptibility of GenAI modules to adversarial perturbations and the effectiveness of the proposed defense concept. Finally, we summarize open challenges and future research directions toward building trustworthy, quantum-resilient, and adaptive GenAI-enabled 6G networks.

</details>


### [18] [Privacy-Preserving IoT in Connected Aircraft Cabin](https://arxiv.org/abs/2511.15278)
*Nilesh Vyas,Benjamin Zhao,Aygün Baltaci,Gustavo de Carvalho Bertoli,Hassan Asghar,Markus Klügel,Gerrit Schramm,Martin Kubisch,Dali Kaafar*

Main category: cs.CR

TL;DR: IoT 기기들의 확산은 데이터 협력의 약속과 개인 정보 보호, 공급업체 지적 재산권, 규제 준수 간의 근본적인 갈등을 야기합니다. 이 논문은 CSMIM 유사 구조 위에 설정 가능한 개인 정보 보호 기술(PET) 층을 통합함으로써 이 격차를 해소하는 프레임워크를 제안하고 평가합니다.


<details>
  <summary>Details</summary>
Motivation: IoT 장치가 공유되고 다수 공급업체 환경에서 확산됨에 따라 데이터 협력과 개인 정보 보호 간의 갈등이 발생하였습니다.

Method: CSMIM 유사 구조 위에 설정 가능한 개인 정보 보호 기술(PET) 층을 통합하는 프레임워크를 제안하고 두 가지 PET, 즉 통계적 공유를 위한 차별 개인정보 보호(DP)와 데이터 난독화를 위한 추가 비밀 공유 체계(ASS)를 평가하는 실증 분석을 수행했습니다.

Result: PET의 컴퓨팅 오버헤드는 종종 네트워크 및 프로토콜 지연에 비해 무시할 수 있는 수준이며, 장치 내 처리와 가상 처리 방식과 같은 아키텍처 선택이 최종 지연과 컴퓨팅 성능에 더 큰 영향을 미친다는 것을 증명했습니다.

Conclusion: 이 발견은 시스템 설계자들이 신뢰할 수 있는 협력 IoT 생태계를 설계할 수 있도록 적절한 PET을 선택하고 구성할 수 있는 실질적인 로드맵을 제공합니다.

Abstract: The proliferation of IoT devices in shared, multi-vendor environments like the modern aircraft cabin creates a fundamental conflict between the promise of data collaboration and the risks to passenger privacy, vendor intellectual property (IP), and regulatory compliance. While emerging standards like the Cabin Secure Media-Independent Messaging (CSMIM) protocol provide a secure communication backbone, they do not resolve data governance challenges at the application layer, leaving a privacy gap that impedes trust. This paper proposes and evaluates a framework that closes this gap by integrating a configurable layer of Privacy-Enhancing Technologies (PETs) atop a CSMIM-like architecture. We conduct a rigorous, empirical analysis of two pragmatic PETs: Differential Privacy (DP) for statistical sharing, and an additive secret sharing scheme (ASS) for data obfuscation. Using a high-fidelity testbed with resource-constrained hardware, we quantify the trade-offs between data privacy, utility, and computing performance. Our results demonstrate that the computational overhead of PETs is often negligible compared to inherent network and protocol latencies. We prove that architectural choices, such as on-device versus virtualized processing, have a far greater impact on end-to-end latency and computational performance than the PETs themselves. The findings provide a practical roadmap for system architects to select and configure appropriate PETs, enabling the design of trustworthy collaborative IoT ecosystems in avionics and other critical domains.

</details>


### [19] [How To Cook The Fragmented Rug Pull?](https://arxiv.org/abs/2511.15463)
*Minh Trung Tran,Nasrin Sohrabi,Zahir Tari,Qin Wang*

Main category: cs.CR

TL;DR: 이 논문에서는 기존의 러그풀 탐지기가 가정하는 간단한 작업 흐름의 한계를 지적하고, 공격을 시간과 행위자 차원에서 분산시키는 '파편화된 러그풀' (FRP) 공격을 형식화하며, 이를 탐지하기 위한 새로운 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 러그풀 공격이 공격자가 여러 주소를 통해 자금을 분산시키고, 저조한 영향력을 가진 거래를 여러 번 수행하는 방식으로 진행되고 있음을 보여주기 위한 필요성이 있음.

Method: 세 가지 원자 술어 그룹을 정의하고, 이들의 직교 조합이 이전의 탐지 방법에서 간과된 회피 전략을 생성한다는 것을 증명함.

Result: 303,614개의 유동성 풀(LP) 중 105,434개가 FRP 풀로 라벨링되었고, 이는 34,192,767건의 거래와 401,838개의 부풀려진 판매자 지갑을 포함함을 나타냄.

Conclusion: FRP로 표시된 LP에서 부풀려진 판매에 대한 소유자 지갑의 참여가 크게 감소했으며(33.1% 사례), 이는 사기 행동의 변화가 있음을 시사하며, 정의한 회피 전략이 광범위하고 운영상 중요한 것으로 나타남.

Abstract: Existing rug pull detectors assume a simple workflow: the deployer keeps liquidity pool (LP) tokens and performs one or a few large sells (within a day) that collapse the pool and cash out. In practice, however, many real-world exits violate these assumptions by splitting the attack across both time and actor dimensions: attackers break total extraction into many low-impact trades and route proceeds through multiple non-owner addresses, producing low-visibility drains.
  We formalize this family of attacks as the fragmented rug pull (FRP) and offer a compact recipe for a slow-stewed beef special: (i) keep the lid on (to preserve LP control so on-chain extraction remains feasible), (ii) chop thin slices (to split the total exit volume into many low-impact micro-trades that individually fall below impact thresholds), and (iii) pass the ladle (to delegate sells across multiple wallets so that each participant takes a small share of the extraction). Technically, we define three atomic predicate groups and show that their orthogonal combinations yield evasive strategies overlooked by prior heuristics (USENIX Sec 19, USENIX Sec 23).
  We validate the model with large-scale measurements. Our corpus contains 303,614 LPs, among which 105,434 are labeled as FRP pools. The labeled subset includes 34,192,767 pool-related transactions and 401,838 inflated-seller wallets, involving 1,501,408 unique interacting addresses. Notably, owner-wallet participation in inflated selling among FRP-flagged LPs has declined substantially (33.1% of cases), indicating a shift in scam behavior: the liquidity drain is no longer held on the owner wallet. We also detected 127,252 wallets acting as serial scammers when repeatedly engaging in inflated selling across multiple FRP LPs. Our empirical findings demonstrate that the evasive strategies we define are widespread and operationally significant.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [20] [Area-Optimal Control Strategies for Heterogeneous Multi-Agent Pursuit](https://arxiv.org/abs/2511.15036)
*Kamal Mammadov,Damith C. Ranasinghe*

Main category: cs.MA

TL;DR: 본 논문은 여러 속도가 다른 추적자와 한 명의 피추적자가 포함된 다중 기관 추적-회피 게임을 위한 새로운 전략을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 다중 기관이 참여하는 추적-회피 게임에서 피추적자의 안전 영역을 효과적으로 최소화하여 보장된 포획을 달성하는 것.

Method: 각 추적자-피추적자 쌍에서 파생된 아폴로니우스 원의 교차점으로 피추적자의 안전 도달 집합을 정의하고, 제로섬 게임으로 포획 전략을 형성하여 협력적으로 이 집합의 면적을 최소화한다.

Result: 안전 도달 집합의 면적에 대한 분석적 기울기를 도출하여 각 기관의 방향에 대한 폐쇄형, 순간적인 최적 제어 법칙을 얻었으며, 시뮬레이션을 통해 이 제어 법칙이 효과적으로 피추적자의 안전 영역을 줄여 포획을 보장함을 입증했다.

Conclusion: 이 면적 최소화 접근법은 협력적인 포획을 위한 명확한 기하학적 목표를 제공한다.

Abstract: This paper presents a novel strategy for a multi-agent pursuit-evasion game involving multiple faster pursuers with heterogenous speeds and a single slower evader. We define a geometric region, the evader's safe-reachable set, as the intersection of Apollonius circles derived from each pursuer-evader pair. The capture strategy is formulated as a zero-sum game where the pursuers cooperatively minimize the area of this set, while the evader seeks to maximize it, effectively playing a game of spatial containment. By deriving the analytical gradients of the safe-reachable set's area with respect to agent positions, we obtain closed-form, instantaneous optimal control laws for the heading of each agent. These strategies are computationally efficient, allowing for real-time implementation. Simulations demonstrate that the gradient-based controls effectively steer the pursuers to systematically shrink the evader's safe region, leading to guaranteed capture. This area-minimization approach provides a clear geometric objective for cooperative capture.

</details>


### [21] [Distributed primal-dual algorithm for constrained multi-agent reinforcement learning under coupled policies](https://arxiv.org/abs/2511.15053)
*Pengcheng Dai,He Wang,Dongming Wang,Wenwu Yu*

Main category: cs.MA

TL;DR: 이 연구는 제약이 있는 다중 에이전트 강화 학습(CMARL)을 조사하며, 에이전트들이 개별 안전 제약을 만족하면서 지역 목표의 합을 극대화하기 위해 협력하는 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습에서 에이전트들이 안전성을 유지하면서 최적의 성과를 내도록 하는 새로운 방법론을 개발하기 위한 필요성을 충족한다.

Method: 에이전트들이 지역 상태와 자신의 이웃에 대한 동시 정책을 채택하는 프레임워크와 분산 프라이멀-듀얼 알고리즘을 제안하며, 각 에이전트는 제한된 정보에 기반해 정책을 실행하도록 한다.

Result: 제안된 알고리즘은 높은 확률로 $ε$-1차 고정 수렴성을 달성하고 근사 오차는 $	ext{O}(γ^{rac{κ+1}{κ_{p}}})$로 나타난다.

Conclusion: GridWorld 환경에서 수행된 시뮬레이션을 통해 제안된 알고리즘의 효과를 입증한다.

Abstract: In this work, we investigate constrained multi-agent reinforcement learning (CMARL), where agents collaboratively maximize the sum of their local objectives while satisfying individual safety constraints. We propose a framework where agents adopt coupled policies that depend on both local states and parameters, as well as those of their $κ_p$-hop neighbors, with $κ_p>0$ denoting the coupling distance. A distributed primal-dual algorithm is further developed under this framework, wherein each agent has access only to state-action pairs within its $2κ_p$-hop neighborhood and to reward information within its $κ+ 2κ_p$-hop neighborhood, with $κ> 0$ representing the truncation distance. Moreover, agents are not permitted to directly share their true policy parameters or Lagrange multipliers. Instead, each agent constructs and maintains local estimates of these variables for other agents and employs such estimates to execute its policy. Additionally, these estimates are further updated and exchanged exclusively through an independent, time-varying networks, which enhances the overall system security. We establish that, with high probability, our algorithm can achieve an $ε$-first-order stationary convergence with an approximation error of $\mathcal{O}(γ^{\frac{κ+1}{κ_{p}}})$ for discount factor $γ\in(0,1)$. Finally, simulations in GridWorld environment are conducted to demonstrate the effectiveness of the proposed algorithm.

</details>


### [22] [Adversarial Attack on Black-Box Multi-Agent by Adaptive Perturbation](https://arxiv.org/abs/2511.15292)
*Jianming Chen,Yawen Wang,Junjie Wang,Xiaofei Xie,Yuanzhe Hu,Qing Wang,Fanjiang Xu*

Main category: cs.MA

TL;DR: Multi-agent systems의 보안성과 신뢰성을 평가하는 것이 중요하다. AdapAM은 이러한 시스템에 대한 새로운 적대적 공격 프레임워크로, 효과성과 은신성을 모두 고려한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 응용 프로그램에서 다중 에이전트 시스템(MAS)의 사용이 증가함에 따라, 보안성과 신뢰성을 평가하는 것이 시급하다.

Method: AdapAM은 적응형 선택 정책과 프록시 기반 섭동을 결합하여 블랙박스 MAS에 대한 적대적 공격을 수행한다.

Result: AdapAM은 8개의 다중 에이전트 환경에서 평가되었으며, 최신의 4개 기준선과 비교하여 최고의 공격 성능을 기록하였다.

Conclusion: AdapAM으로 생성된 섭동은 가장 적은 잡음을 발생시키며, 탐지가 어려운 것으로 나타나 은신성을 강조한다.

Abstract: Evaluating security and reliability for multi-agent systems (MAS) is urgent as they become increasingly prevalent in various applications. As an evaluation technique, existing adversarial attack frameworks face certain limitations, e.g., impracticality due to the requirement of white-box information or high control authority, and a lack of stealthiness or effectiveness as they often target all agents or specific fixed agents. To address these issues, we propose AdapAM, a novel framework for adversarial attacks on black-box MAS. AdapAM incorporates two key components: (1) Adaptive Selection Policy simultaneously selects the victim and determines the anticipated malicious action (the action would lead to the worst impact on MAS), balancing effectiveness and stealthiness. (2) Proxy-based Perturbation to Induce Malicious Action utilizes generative adversarial imitation learning to approximate the target MAS, allowing AdapAM to generate perturbed observations using white-box information and thus induce victims to execute malicious action in black-box settings. We evaluate AdapAM across eight multi-agent environments and compare it with four state-of-the-art and commonly-used baselines. Results demonstrate that AdapAM achieves the best attack performance in different perturbation rates. Besides, AdapAM-generated perturbations are the least noisy and hardest to detect, emphasizing the stealthiness.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [23] [Transformer-Guided Deep Reinforcement Learning for Optimal Takeoff Trajectory Design of an eVTOL Drone](https://arxiv.org/abs/2511.14887)
*Nathan M. Roberts,Xiaosong Du*

Main category: cs.LG

TL;DR: 전통적인 최적 제어 방법의 한계를 극복하기 위해 변환기 기반 심층 강화 학습(DRL)을 제안하며, 이를 통해 eVTOL 드론의 최소 에너지 소비를 위한 최적 이륙 궤적 설계를 성공적으로 수행했다.


<details>
  <summary>Details</summary>
Motivation: eVTOL 항공기의 급속한 발전은 도시 교통 혼잡을 완화할 수 있는 가능성을 제공하며, 최소 에너지 소비를 위한 최적 이륙 궤적 개발이 필수적이다.

Method: 변환기 기반 DRL을 제안하여 각 시간 단계에서 현실적인 상태공간을 탐색하여 훈련 난이도를 완화한다.

Result: 제안된 변환기 기반 DRL이 이륙 조건을 충족하면서 최소 에너지 소비를 위한 이륙 궤적 설계에서 vanilla DRL보다 25% 빠르게 학습하였다.

Conclusion: 제안된 변환기 기반 DRL은 훈련 효율성과 최적 설계 검증 모두에서 vanilla DRL보다 우수한 성능을 보였다.

Abstract: The rapid advancement of electric vertical take-off and landing (eVTOL) aircraft offers a promising opportunity to alleviate urban traffic congestion. Thus, developing optimal takeoff trajectories for minimum energy consumption becomes essential for broader eVTOL aircraft applications. Conventional optimal control methods (such as dynamic programming and linear quadratic regulator) provide highly efficient and well-established solutions but are limited by problem dimensionality and complexity. Deep reinforcement learning (DRL) emerges as a special type of artificial intelligence tackling complex, nonlinear systems; however, the training difficulty is a key bottleneck that limits DRL applications. To address these challenges, we propose the transformer-guided DRL to alleviate the training difficulty by exploring a realistic state space at each time step using a transformer. The proposed transformer-guided DRL was demonstrated on an optimal takeoff trajectory design of an eVTOL drone for minimal energy consumption while meeting takeoff conditions (i.e., minimum vertical displacement and minimum horizontal velocity) by varying control variables (i.e., power and wing angle to the vertical). Results presented that the transformer-guided DRL agent learned to take off with $4.57\times10^6$ time steps, representing 25% of the $19.79\times10^6$ time steps needed by a vanilla DRL agent. In addition, the transformer-guided DRL achieved 97.2% accuracy on the optimal energy consumption compared against the simulation-based optimal reference while the vanilla DRL achieved 96.3% accuracy. Therefore, the proposed transformer-guided DRL outperformed vanilla DRL in terms of both training efficiency as well as optimal design verification.

</details>


### [24] [Structured Contrastive Learning for Interpretable Latent Representations](https://arxiv.org/abs/2511.14920)
*Zhengyang Shen,Hua Tu,Mayue Shi*

Main category: cs.LG

TL;DR: 이 연구에서는 신경망의 취약성을 해결하기 위해 구조적 대비 학습(SCL) 프레임워크를 제안함으로써, 다양한 의미적 그룹으로 잠재 공간을 분할하여 태스크 성능을 개선하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 신경망은 의미적으로 무관한 변환에 매우 취약하며, 이는 성능 저하로 이어진다.

Method: Structured Contrastive Learning(SCL) 프레임워크를 통해 잠재 공간을 세 가지 의미적 그룹으로 나눕니다: 불변 특성, 변환 기작을 통한 차별적 특성, 태스크 유연성을 보존하는 자유 특성.

Result: ECG의 경우 상관관계가 0.25에서 0.91로 개선되었고, IMU 회전 일관성이 95.38%를 기록하며 WISDM 활동 인식에서 86.65% 정확도를 달성했습니다.

Conclusion: 이 연구는 반응형 데이터 증강에서 능동적 구조학습으로의 패러다임 전환을 나타내며, 신경망에서 해석 가능한 잠재 표현을 가능하게 합니다.

Abstract: Neural networks exhibit severe brittleness to semantically irrelevant transformations. A mere 75ms electrocardiogram (ECG) phase shift degrades latent cosine similarity from 1.0 to 0.2, while sensor rotations collapse activity recognition performance with inertial measurement units (IMUs). We identify the root cause as "laissez-faire" representation learning, where latent spaces evolve unconstrained provided task performance is satisfied. We propose Structured Contrastive Learning (SCL), a framework that partitions latent space representations into three semantic groups: invariant features that remain consistent under given transformations (e.g., phase shifts or rotations), variant features that actively differentiate transformations via a novel variant mechanism, and free features that preserve task flexibility. This creates controllable push-pull dynamics where different latent dimensions serve distinct, interpretable purposes. The variant mechanism enhances contrastive learning by encouraging variant features to differentiate within positive pairs, enabling simultaneous robustness and interpretability. Our approach requires no architectural modifications and integrates seamlessly into existing training pipelines. Experiments on ECG phase invariance and IMU rotation robustness demonstrate superior performance: ECG similarity improves from 0.25 to 0.91 under phase shifts, while WISDM activity recognition achieves 86.65% accuracy with 95.38% rotation consistency, consistently outperforming traditional data augmentation. This work represents a paradigm shift from reactive data augmentation to proactive structural learning, enabling interpretable latent representations in neural networks.

</details>


### [25] [Deep Pathomic Learning Defines Prognostic Subtypes and Molecular Drivers in Colorectal Cancer](https://arxiv.org/abs/2511.15067)
*Zisong Wang,Xuanyu Wang,Hang Chen,Haizhou Wang,Yuxin Chen,Yihang Xu,Yunhe Yuan,Lihuan Luo,Xitong Ling,Xiaoping Liu*

Main category: cs.LG

TL;DR: 본 연구에서는 TDAM-CRC라는 새로운 다중 사례 학습 모델을 개발하여 대장암의 예후 예측 정확성을 향상시키고, 그 기초가 되는 분자 메커니즘을 밝혀내고자 하였다.


<details>
  <summary>Details</summary>
Motivation: 대장암은 높은 이질성으로 인해 정확한 예후 분류가 큰 임상적 도전 과제가 되고 있다.

Method: TCGA 발견 코호트(n=581)에서 모델을 훈련시키고, 독립적인 외부 코호트(n=1031)에서 검증하였으며, 다중 오믹스 데이터를 통합하여 모델 해석 가능성을 개선하고 새로운 예후 바이오마커를 규명하였다.

Result: TDAM-CRC는 두 코호트 모두에서 강력한 위험 분류를 달성하였으며, 예측 성능은 전통적인 임상 병기 시스템과 여러 최첨단 모델을 능가하였다.

Conclusion: AI 기반의 병리학적 모델인 TDAM-CRC는 대장암 위험 분류 개선을 위한 강력한 도구를 제공하고, 새로운 분자 표적을 밝혀내며, 개인화된 임상 의사 결정을 용이하게 한다.

Abstract: Precise prognostic stratification of colorectal cancer (CRC) remains a major clinical challenge due to its high heterogeneity. The conventional TNM staging system is inadequate for personalized medicine. We aimed to develop and validate a novel multiple instance learning model TDAM-CRC using histopathological whole-slide images for accurate prognostic prediction and to uncover its underlying molecular mechanisms. We trained the model on the TCGA discovery cohort (n=581), validated it in an independent external cohort (n=1031), and further we integrated multi-omics data to improve model interpretability and identify novel prognostic biomarkers. The results demonstrated that the TDAM-CRC achieved robust risk stratification in both cohorts. Its predictive performance significantly outperformed the conventional clinical staging system and multiple state-of-the-art models. The TDAM-CRC risk score was confirmed as an independent prognostic factor in multivariable analysis. Multi-omics analysis revealed that the high-risk subtype is closely associated with metabolic reprogramming and an immunosuppressive tumor microenvironment. Through interaction network analysis, we identified and validated Mitochondrial Ribosomal Protein L37 (MRPL37) as a key hub gene linking deep pathomic features to clinical prognosis. We found that high expression of MRPL37, driven by promoter hypomethylation, serves as an independent biomarker of favorable prognosis. Finally, we constructed a nomogram incorporating the TDAM-CRC risk score and clinical factors to provide a precise and interpretable clinical decision-making tool for CRC patients. Our AI-driven pathological model TDAM-CRC provides a robust tool for improved CRC risk stratification, reveals new molecular targets, and facilitates personalized clinical decision-making.

</details>


### [26] [Cross-Modal Consistency-Guided Active Learning for Affective BCI Systems](https://arxiv.org/abs/2511.15138)
*Hyo-Jeong Jang,Hye-Bin Shin,Kang Yin*

Main category: cs.LG

TL;DR: 본 논문은 EEG 기반 감정 인식을 위한 불확실성 인식 능동 학습 프레임워크를 제안하여 레이블 노이즈에 대한 강인성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: EEG 기반 감정 인식에서 충분하고 고품질의 레이블을 달성하기 어려운 상황에서 모델의 강인성을 강화할 필요성이 있다.

Method: 제안된 방법은 모델 불확실성과 교차 모달 일치를 공동으로 활용하여 레이블 노이즈에 대한 강인성을 향상시킨다.

Result: ASCERTAIN 데이터셋에 대한 실험을 통해 제안된 방법의 효율성과 강인성을 평가하였다.

Conclusion: 이 접근법은 뇌-컴퓨터 인터페이스 시스템에서 EEG 기반 정서 인식의 데이터 효율성과 소음 저항성의 잠재력을 강조한다.

Abstract: Deep learning models perform best with abundant, high-quality labels, yet such conditions are rarely achievable in EEG-based emotion recognition. Electroencephalogram (EEG) signals are easily corrupted by artifacts and individual variability, while emotional labels often stem from subjective and inconsistent reports-making robust affective decoding particularly difficult. We propose an uncertainty-aware active learning framework that enhances robustness to label noise by jointly leveraging model uncertainty and cross-modal consistency. Instead of relying solely on EEG-based uncertainty estimates, the method evaluates cross-modal alignment to determine whether uncertainty originates from cognitive ambiguity or sensor noise. A representation alignment module embeds EEG and face features into a shared latent space, enforcing semantic coherence between modalities. Residual discrepancies are treated as noise-induced inconsistencies, and these samples are selectively queried for oracle feedback during active learning. This feedback-driven process guides the network toward reliable, informative samples and reduces the impact of noisy labels. Experiments on the ASCERTAIN dataset examine the efficiency and robustness of ours, highlighting its potential as a data-efficient and noise-tolerant approach for EEG-based affective decoding in brain-computer interface systems.

</details>


### [27] [FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model](https://arxiv.org/abs/2511.15174)
*Yi Xu,Zhigang Chen,Rui Wang,Yangfan Li,Fengxiao Tang,Ming Zhao,Jiaqi Liu*

Main category: cs.LG

TL;DR: 본 연구는 산업 설비 모니터링에서 결함 진단의 중요성과 기존 모델의 한계를 지적하고, 새로운 몇 샷 결함 시간 시계열 생성 프레임워크를 제안하여 성능을 개선하였다.


<details>
  <summary>Details</summary>
Motivation: 산업 장비 모니터링에서 결함 진단은 시스템의 신뢰성을 보장하고 예측 유지보수를 가능하게 하여 매우 중요하다. 그러나 결함 이벤트의 희소성과 데이터 주석의 높은 비용으로 인해 결함 데이터가 부족하다.

Method: 이 논문에서는 확산 모델에 기반한 새로운 몇 샷 결함 시간 시계열 생성 프레임워크를 제안한다. 이 방법은 사전 훈련된 정상 데이터 분포를 활용하여 정상과 결함 도메인 간의 불일치를 모델링하면서 정확한 결함 합성을 수행한다.

Result: 실험 결과, 우리 모델은 진정성과 다양성 측면에서 전통적인 방법에 비해 상당히 뛰어난 성과를 보였으며, 주요 벤치마크에서 최첨단 성능을 달성하였다.

Conclusion: 새로운 프레임워크는 기존 데이터 기반 접근 방식의 한계를 극복하고 결함 샘플의 다양성을 증대시켜 예측 유지보수의 효율성을 향상시킨다.

Abstract: In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.

</details>


### [28] [SNAP: Low-Latency Test-Time Adaptation with Sparse Updates](https://arxiv.org/abs/2511.15276)
*Hyeongheon Cha,Dong Min Kim,Hye Won Chung,Taesik Gong,Sung-Ju Lee*

Main category: cs.LG

TL;DR: SNAP은 리소스 제약이 있는 환경에서도 높은 정확도를 유지하며 적응 빈도와 데이터 사용량을 줄이는 희소 테스트 시간 적응 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 리소스 제약이 있는 엣지 환경에서 동적 분포 변화에 대처하기 위해 모델을 적응시키는 것이 필요하다.

Method: SNAP은 클래스 및 도메인 대표 메모리(CnDRM)와 인퍼런스 전용 배치 인식 메모리 정규화(IoBMN)를 포함한다.

Result: SNAP은 1%의 데이터 스트림만을 기반으로 적응해도 경쟁력 있는 정확도를 유지하며, 93.12%의 지연을 줄이면서도 정확도 하락은 3.3% 미만으로 유지한다.

Conclusion: SNAP은 지연이 중요한 애플리케이션을 지원하는 엣지 장치에서 실제 사용 가능성이 매우 높다.

Abstract: Test-Time Adaptation (TTA) adjusts models using unlabeled test data to handle dynamic distribution shifts. However, existing methods rely on frequent adaptation and high computational cost, making them unsuitable for resource-constrained edge environments. To address this, we propose SNAP, a sparse TTA framework that reduces adaptation frequency and data usage while preserving accuracy. SNAP maintains competitive accuracy even when adapting based on only 1% of the incoming data stream, demonstrating its robustness under infrequent updates. Our method introduces two key components: (i) Class and Domain Representative Memory (CnDRM), which identifies and stores a small set of samples that are representative of both class and domain characteristics to support efficient adaptation with limited data; and (ii) Inference-only Batch-aware Memory Normalization (IoBMN), which dynamically adjusts normalization statistics at inference time by leveraging these representative samples, enabling efficient alignment to shifting target domains. Integrated with five state-of-the-art TTA algorithms, SNAP reduces latency by up to 93.12%, while keeping the accuracy drop below 3.3%, even across adaptation rates ranging from 1% to 50%. This demonstrates its strong potential for practical use on edge devices serving latency-sensitive applications. The source code is available at https://github.com/chahh9808/SNAP.

</details>


### [29] [Cost-Aware Prediction (CAP): An LLM-Enhanced Machine Learning Pipeline and Decision Support System for Heart Failure Mortality Prediction](https://arxiv.org/abs/2511.15357)
*Yinan Yu,Falk Dippel,Christina E. Lundberg,Martin Lindgren,Annika Rosengren,Martin Adiels,Helen Sjöland*

Main category: cs.LG

TL;DR: 이 연구는 의료 예측 모델이 임상 해석 가능성과 비용-편익 분석을 고려하지 않고 개발되는 경우가 많음을 지적하며, 이를 해결하기 위해 기계 학습 예측 결과와 비용-편익 분석을 통합한 비용 인식 예측(CAP) 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 예측 모델 개발 시 하향 가치 무역과 임상 해석 가능성을 고려하지 않는 경향을 해결하고자 한다.

Method: 심부전 환자의 1년 사망률을 예측하는 ML 모델을 개발하고, 치료 및 오류 비용으로 나누어 질병 관리의 임상적 결과를 평가하기 위해 CIP 곡선을 도입하였다.

Result: XGB 모델이 AUROC 0.804, AUPRC 0.529, Brier 점수 0.135로 최고의 성능을 달성하였다.

Conclusion: CAP은 LLM 에이전트를 활용하여 ML 분류기 결과와 비용-편익 분석을 통합함으로써 더 투명하고 해석 가능한 의사 결정을 지원한다.

Abstract: Objective: Machine learning (ML) predictive models are often developed without considering downstream value trade-offs and clinical interpretability. This paper introduces a cost-aware prediction (CAP) framework that combines cost-benefit analysis assisted by large language model (LLM) agents to communicate the trade-offs involved in applying ML predictions. Materials and Methods: We developed an ML model predicting 1-year mortality in patients with heart failure (N = 30,021, 22% mortality) to identify those eligible for home care. We then introduced clinical impact projection (CIP) curves to visualize important cost dimensions - quality of life and healthcare provider expenses, further divided into treatment and error costs, to assess the clinical consequences of predictions. Finally, we used four LLM agents to generate patient-specific descriptions. The system was evaluated by clinicians for its decision support value. Results: The eXtreme gradient boosting (XGB) model achieved the best performance, with an area under the receiver operating characteristic curve (AUROC) of 0.804 (95% confidence interval (CI) 0.792-0.816), area under the precision-recall curve (AUPRC) of 0.529 (95% CI 0.502-0.558) and a Brier score of 0.135 (95% CI 0.130-0.140). Discussion: The CIP cost curves provided a population-level overview of cost composition across decision thresholds, whereas LLM-generated cost-benefit analysis at individual patient-levels. The system was well received according to the evaluation by clinicians. However, feedback emphasizes the need to strengthen the technical accuracy for speculative tasks. Conclusion: CAP utilizes LLM agents to integrate ML classifier outcomes and cost-benefit analysis for more transparent and interpretable decision support.

</details>


### [30] [EVA-Net: Interpretable Brain Age Prediction via Continuous Aging Prototypes from EEG](https://arxiv.org/abs/2511.15393)
*Kunyu Zhang,Mingxuan Wang,Xiangjie Shi,Haoxing Xu,Chao Zhang*

Main category: cs.LG

TL;DR: EVA-Net은 뇌 나이를 해석 가능한 이상 탐지 문제로 재구성하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 뇌 나이는 뇌 건강의 주요 지표이며, 비정상적인 의료 데이터로부터 '정상' 기준선을 학습하는 데 어려움이 있다.

Method: EVA-Net은 장기 EEG 시퀀스를 모델링하기 위해 효율적인 희소 주의 Transformer를 사용하며, 변동성과 잡음을 처리하기 위해 변이정보 병목 기법을 활용하여 강력한 압축 표현을 학습한다.

Result: EVA-Net은 1297명의 건강한 피험자에서 훈련되어 최첨단 정확도를 달성하였고, 27명의 MCI 및 AD 환자에 대한 이상 탐지 능력을 검증하였다.

Conclusion: EVA-Net은 불완전한 의료 데이터를 사용하는 의료 인텔리전스에 대한 해석 가능한 프레임워크를 제공한다.

Abstract: The brain age is a key indicator of brain health. While electroencephalography (EEG) is a practical tool for this task, existing models struggle with the common challenge of imperfect medical data, such as learning a ``normal'' baseline from weakly supervised, healthy-only cohorts. This is a critical anomaly detection task for identifying disease, but standard models are often black boxes lacking an interpretable structure. We propose EVA-Net, a novel framework that recasts brain age as an interpretable anomaly detection problem. EVA-Net uses an efficient, sparsified-attention Transformer to model long EEG sequences. To handle noise and variability in imperfect data, it employs a Variational Information Bottleneck to learn a robust, compressed representation. For interpretability, this representation is aligned to a continuous prototype network that explicitly learns the normative healthy aging manifold. Trained on 1297 healthy subjects, EVA-Net achieves state-of-the-art accuracy. We validated its anomaly detection capabilities on an unseen cohort of 27 MCI and AD patients. This pathological group showed significantly higher brain-age gaps and a novel Prototype Alignment Error, confirming their deviation from the healthy manifold. EVA-Net provides an interpretable framework for healthcare intelligence using imperfect medical data.

</details>


### [31] [TSFM in-context learning for time-series classification of bearing-health status](https://arxiv.org/abs/2511.15447)
*Michel Tokic,Slobodan Djukanović,Anja von Beuningen,Cheng Feng*

Main category: cs.LG

TL;DR: 이 논문은 시간 시리즈 기초 모델(TSFM)에서의 상황 내 학습을 이용한 분류 방법을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 상황 내 학습을 통해 모델을 미세 조정하지 않고도 미지의 데이터를 분류할 수 있는 방법을 제시하고자 합니다.

Method: 모델의 프롬프트 내에서 타겟(클래스 ID)과 공변량(데이터 매트릭스)의 형태로 데이터를 표현하여 분류합니다.

Result: 이 방법을 서보 프레스 모터의 베어링 건강 상태 평가를 위한 진동 데이터에 적용하여 효율성을 입증합니다.

Conclusion: 사전 훈련된 모델의 확장성을 활용하여 다양한 운영 조건에서도 효과적이며, 맞춤형 협소 AI 솔루션을 넘어서는 중요한 발전을 나타냅니다.

Abstract: This paper introduces a classification method using in-context learning in time-series foundation models (TSFM). We show how data, which was not part of the TSFM training data corpus, can be classified without the need of finetuning the model. Examples are represented in the form of targets (class id) and covariates (data matrix) within the prompt of the model, which enables to classify an unknown covariate data pattern alongside the forecast axis through in-context learning. We apply this method to vibration data for assessing the health state of a bearing within a servo-press motor. The method transforms frequency domain reference signals into pseudo time-series patterns, generates aligned covariate and target signals, and uses the TSFM to predict probabilities how classified data corresponds to predefined labels. Leveraging the scalability of pre-trained models this method demonstrates efficacy across varied operational conditions. This marks significant progress beyond custom narrow AI solutions towards broader, AI-driven maintenance systems.

</details>


### [32] [NTK-Guided Implicit Neural Teaching](https://arxiv.org/abs/2511.15487)
*Chen Zhang,Wei Zuo,Bingyang Cheng,Yikun Wang,Wei-Bin Kou,Yik Chung WU,Ngai Wong*

Main category: cs.LG

TL;DR: NINT는 효율적으로 좌표를 선택하여 훈련을 가속화하며, 훈련 시간을 절반 가까이 줄이면서도 표현 품질을 유지하거나 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 고해상도 신호에 대한 피팅은 수백만 개의 좌표를 최적화해야 하므로 높은 계산 비용이 발생합니다.

Method: NTK를 활용한 NINT는 글로벌 기능 업데이트를 극대화하는 좌표를 동적으로 선택하여 훈련을 가속화합니다.

Result: NINT는 훈련 시간을 거의 절반으로 줄이고, 표현 품질을 유지하거나 개선했습니다.

Conclusion: NINT는 최근 샘플링 기반 전략 중에서 최첨단 가속화를 설정합니다.

Abstract: Implicit Neural Representations (INRs) parameterize continuous signals via multilayer perceptrons (MLPs), enabling compact, resolution-independent modeling for tasks like image, audio, and 3D reconstruction. However, fitting high-resolution signals demands optimizing over millions of coordinates, incurring prohibitive computational costs. To address it, we propose NTK-Guided Implicit Neural Teaching (NINT), which accelerates training by dynamically selecting coordinates that maximize global functional updates. Leveraging the Neural Tangent Kernel (NTK), NINT scores examples by the norm of their NTK-augmented loss gradients, capturing both fitting errors and heterogeneous leverage (self-influence and cross-coordinate coupling). This dual consideration enables faster convergence compared to existing methods. Through extensive experiments, we demonstrate that NINT significantly reduces training time by nearly half while maintaining or improving representation quality, establishing state-of-the-art acceleration among recent sampling-based strategies.

</details>


### [33] [Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges](https://arxiv.org/abs/2511.15652)
*Kim N. Nolle,Ivana Dusparic,Rhodri Cusack,Vinny Cahill*

Main category: cs.LG

TL;DR: 이 연구는 자율 주행 환경에서 연속 강화 학습의 도전 과제를 강조하고, 이를 위한 연구 질문을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 연속 학습을 통해 기계가 이전에 학습한 능력을 새로운 작업이나 환경에 재적용하고 적응하도록 하는 것이 필요합니다.

Method: Proximal Policy Optimisation(PPO)를 활용하여 자율 주행 환경에서 네 가지 다른 주차 상황에 대해 에이전트를 훈련시켰습니다.

Result: 이 실험은 환경의 적절한 추상화, 하이퍼파라미터에 대한 과민 반응, 재앙적 망각, 신경망 용량의 효율적 사용과 같은 CRL의 여러 도전 과제를 노출했습니다.

Conclusion: 신뢰할 수 있는 CRL 시스템 생성을 위해 해결해야 할 중요한 연구 질문을 제시하며, 컴퓨터 과학과 신경 과학 간의 학제간 연구 필요성을 강조합니다.

Abstract: Continual learning (CL) is a branch of machine learning that aims to enable agents to adapt and generalise previously learned abilities so that these can be reapplied to new tasks or environments. This is particularly useful in multi-task settings or in non-stationary environments, where the dynamics can change over time. This is particularly relevant in cyber-physical systems such as autonomous driving. However, despite recent advances in CL, successfully applying it to reinforcement learning (RL) is still an open problem.
  This paper highlights open challenges in continual RL (CRL) based on experiments in an autonomous driving environment. In this environment, the agent must learn to successfully park in four different scenarios corresponding to parking spaces oriented at varying angles. The agent is successively trained in these four scenarios one after another, representing a CL environment, using Proximal Policy Optimisation (PPO). These experiments exposed a number of open challenges in CRL: finding suitable abstractions of the environment, oversensitivity to hyperparameters, catastrophic forgetting, and efficient use of neural network capacity.
  Based on these identified challenges, we present open research questions that are important to be addressed for creating robust CRL systems. In addition, the identified challenges call into question the suitability of neural networks for CL. We also identify the need for interdisciplinary research, in particular between computer science and neuroscience.

</details>
