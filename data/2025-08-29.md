<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.CR](#cs.CR) [Total: 33]
- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Aegis: Taxonomy and Optimizations for Overcoming Agent-Environment Failures in LLM Agents](https://arxiv.org/abs/2508.19504)
*Kevin Song,Anand Jayarajan,Yaoyao Ding,Qidong Su,Zhanda Zhu,Sihang Liu,Gennady Pekhimenko*

Main category: cs.MA

TL;DR: 이 논문은 에이전트의 성공률을 높이기 위해 시스템 환경을 최적화하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 복잡한 작업 수행 성공률이 낮아 실용적 배치에 제약이 있습니다.

Method: 142개의 에이전트 추적 및 6가지 실패 모드 분석을 통해 에이전트-환경 상호작용 실패를 분류하고, 환경 최적화를 위한 Aegis 설계.

Result: 제안한 기술들이 에이전트의 성공률을 평균 6.7-12.5% 향상시킴.

Conclusion: 에이전트와 LLM 수정 없이도 환경 최적화가 에이전트 성공률을 높일 수 있음을 보여줍니다.

Abstract: Large Language Models (LLMs) agents augmented with domain tools promise to
autonomously execute complex tasks requiring human-level intelligence, such as
customer service and digital assistance. However, their practical deployment is
often limited by their low success rates under complex real-world environments.
To tackle this, prior research has primarily focused on improving the agents
themselves, such as developing strong agentic LLMs, while overlooking the role
of the system environment in which the agent operates.
  In this paper, we study a complementary direction: improving agent success
rates by optimizing the system environment in which the agent operates. We
collect 142 agent traces (3,656 turns of agent-environment interactions) across
5 state-of-the-art agentic benchmarks. By analyzing these agent failures, we
propose a taxonomy for agent-environment interaction failures that includes 6
failure modes. Guided by these findings, we design Aegis, a set of targeted
environment optimizations: 1) environment observability enhancement, 2) common
computation offloading, and 3) speculative agentic actions. These techniques
improve agent success rates on average by 6.7-12.5%, without any modifications
to the agent and underlying LLM.

</details>


### [2] [CataractSurg-80K: Knowledge-Driven Benchmarking for Structured Reasoning in Ophthalmic Surgery Planning](https://arxiv.org/abs/2508.20014)
*Yang Meng,Zewen Pan,Yandi Lu,Ruobing Huang,Yanfeng Liao,Jiarui Yang*

Main category: cs.MA

TL;DR: 이 논문은 백내장 수술 계획을 위한 혁신적인 다중 에이전트 시스템과 이를 기반으로 한 모델을 제안하여 임상 결정을 지원하는 방법에 대해 다룬다.


<details>
  <summary>Details</summary>
Motivation: 백내장 수술은 시력 복원을 위해 가장 널리 시행되고 효과적인 절차 중 하나이며, 효과적인 수술 계획을 위해 다양한 임상 검사를 통합해야 한다.

Method: 각 에이전트가 전문 안과 의사의 추론 과정을 모방하여 원시 임상 입력을 구조화된, 실행 가능한 요약으로 변환하는 지식 기반 다중 에이전트 시스템을 제안한다.

Result: CataractSurg-80K라는 첫 번째 대규모 백내장 수술 계획 벤치마크를 도입하고, Qwen-4B를 기반으로 한 도메인 전문 모델 Qwen-CSP가 다수의 지표에서 강력한 일반 목적 LLM보다 우수한 성능을 보여준다.

Conclusion: 우리의 연구는 의료 AI 추론 및 의사 결정을 지원하기 위한 고품질 데이터 세트, 철저한 벤치마크, 도메인 적응 LLM을 제공한다.

Abstract: Cataract surgery remains one of the most widely performed and effective
procedures for vision restoration. Effective surgical planning requires
integrating diverse clinical examinations for patient assessment, intraocular
lens (IOL) selection, and risk evaluation. Large language models (LLMs) have
shown promise in supporting clinical decision-making. However, existing LLMs
often lack the domain-specific expertise to interpret heterogeneous ophthalmic
data and provide actionable surgical plans. To enhance the model's ability to
interpret heterogeneous ophthalmic reports, we propose a knowledge-driven
Multi-Agent System (MAS), where each agent simulates the reasoning process of
specialist ophthalmologists, converting raw clinical inputs into structured,
actionable summaries in both training and deployment stages. Building on MAS,
we introduce CataractSurg-80K, the first large-scale benchmark for cataract
surgery planning that incorporates structured clinical reasoning. Each case is
annotated with diagnostic questions, expert reasoning chains, and structured
surgical recommendations. We further introduce Qwen-CSP, a domain-specialized
model built on Qwen-4B, fine-tuned through a multi-stage process tailored for
surgical planning. Comprehensive experiments show that Qwen-CSP outperforms
strong general-purpose LLMs across multiple metrics. Our work delivers a
high-quality dataset, a rigorous benchmark, and a domain-adapted LLM to
facilitate future research in medical AI reasoning and decision support.

</details>


### [3] [Anomaly Detection in Networked Bandits](https://arxiv.org/abs/2508.20076)
*Xiaotong Cheng,Setareh Maghsudi*

Main category: cs.MA

TL;DR: 이 논문은 사회 네트워크에서 비정상 노드를 감지하고 개인화 추천 전략을 개발하는 새로운 밴딧 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 사회 네트워크에서 노드 간의 상호 연결은 정보 공유와 의존성을 반영하지만 비정상 노드는 심각한 결과를 초래할 수 있습니다.

Method: 사용자 선호도와 특성 정보의 잔여성을 학습하고 분석하여 각 사용자에 대한 개인화 추천 전략을 개발합니다.

Result: 제안된 알고리즘의 후회 상한선을 rigorously 증명하고, 여러 최신 협업 컨텍스트 밴딧 알고리즘과 비교합니다.

Conclusion: 개인화 추천과 비정상 감지를 동시에 수행할 수 있는 효과적인 온라인 학습 알고리즘을 제안합니다.

Abstract: The nodes' interconnections on a social network often reflect their
dependencies and information-sharing behaviors. Nevertheless, abnormal nodes,
which significantly deviate from most of the network concerning patterns or
behaviors, can lead to grave consequences. Therefore, it is imperative to
design efficient online learning algorithms that robustly learn users'
preferences while simultaneously detecting anomalies.
  We introduce a novel bandit algorithm to address this problem. Through
network knowledge, the method characterizes the users' preferences and
residuals of feature information. By learning and analyzing these preferences
and residuals, it develops a personalized recommendation strategy for each user
and simultaneously detects anomalies. We rigorously prove an upper bound on the
regret of the proposed algorithm and experimentally compare it with several
state-of-the-art collaborative contextual bandit algorithms on both synthetic
and real-world datasets.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models](https://arxiv.org/abs/2508.19249)
*Jonas Søeborg Nielsen,Marcus Galea Jacobsen,Albert Brincker Olson,Mads Peter Sørensen,Allan Peter Engsig-Karup*

Main category: cs.LG

TL;DR: 새로운 하이브리드 파라미터 추정 방법이 제안되며, 이는 비선형 동적 모델이 파라미터에 대해 선형인 방정식 시스템의 형태로 표현될 때 일반화된 최소 제곱법을 사용하여 이러한 파라미터를 추정할 수 있다는 아이디어에 기반합니다.


<details>
  <summary>Details</summary>
Motivation: 비선형 동적 모델의 파라미터 추정의 효율성을 높이기 위한 새로운 방법론 개발이 필요합니다.

Method: 비선형 상미분 방정식(ODE)과 편미분 방정식(PDE) 기반의 모델을 사용하여 일반화된 최소 제곱법을 통해 파라미터 추정을 수행하는 물리 정보 회귀(PIR) 기술을 제안합니다.

Result: PIR 방법이 핀 계량 신경망(PINN)과 비교했을 때 COVID-19 팬데믹 동안 덴마크에서 수집된 실제 데이터와 합성 데이터 모두에서 더 나은 성능을 나타냈습니다.

Conclusion: PIR 방법이 고려된 모델에 대해 PINN보다 우수하며, 실제 덴마크 데이터를 활용하여 시간 변화 파라미터를 추정하는 응용 가능성을 보여주었습니다.

Abstract: We present a new efficient hybrid parameter estimation method based on the
idea, that if nonlinear dynamic models are stated in terms of a system of
equations that is linear in terms of the parameters, then regularized ordinary
least squares can be used to estimate these parameters from time series data.
We introduce the term "Physics-Informed Regression" (PIR) to describe the
proposed data-driven hybrid technique as a way to bridge theory and data by use
of ordinary least squares to efficiently perform parameter estimation of the
model coefficients of different parameter-linear models; providing examples of
models based on nonlinear ordinary equations (ODE) and partial differential
equations (PDE). The focus is on parameter estimation on a selection of ODE and
PDE models, each illustrating performance in different model characteristics.
For two relevant epidemic models of different complexity and number of
parameters, PIR is tested and compared against the related technique,
physics-informed neural networks (PINN), both on synthetic data generated from
known target parameters and on real public Danish time series data collected
during the COVID-19 pandemic in Denmark. Both methods were able to estimate the
target parameters, while PIR showed to perform noticeably better, especially on
a compartment model with higher complexity. Given the difference in
computational speed, it is concluded that the PIR method is superior to PINN
for the models considered. It is also demonstrated how PIR can be applied to
estimate the time-varying parameters of a compartment model that is fitted
using real Danish data from the COVID-19 pandemic obtained during a period from
2020 to 2021. The study shows how data-driven and physics-informed techniques
may support reliable and fast -- possibly real-time -- parameter estimation in
parameter-linear nonlinear dynamic models.

</details>


### [5] [Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats](https://arxiv.org/abs/2508.19263)
*Anat Heilper,Doron Singer*

Main category: cs.LG

TL;DR: 저자들은 낮은 정밀도 부동소수점 형식인 FP8과 FP4에 대한 ZipNN 접근 방식을 확장하여 신경망 가중치의 저장 및 전송 비용을 줄이는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 모델의 성장과 배포의 보편화로 인해 신경망 가중치의 저장 및 전송 비용 절감이 중요해졌습니다.

Method: ZipNN 접근 방식을 FP8 및 FP4와 같은 낮은 정밀도 부동소수점 형식으로 확장하고, 엔트로피 코딩을 사용하여 지수와 가수를 독립적으로 분리하여 압축하는 방법을 설계했습니다.

Result: BF16에서는 최대 62%, FP8에서는 최대 83%의 압축 비율을 보였습니다.

Conclusion: 대형 언어 모델에서 사용되는 키-값(K/V) 캐시 텐서의 압축 가능성을 조사하여 메모리 절약을 가능하게 하는 압축 패턴을 발견했습니다.

Abstract: As deep learning models grow and deployment becomes more widespread, reducing
the storage and transmission costs of neural network weights has become
increasingly important. While prior work such as ZipNN has shown that lossless
compression methods - particularly those based on Huffman encoding
floating-point exponents can significantly reduce model sizes, these techniques
have primarily been applied to higher-precision formats such as FP32 and BF16.
In this work, we extend the ZipNN approach to lower-precision floating-point
formats, specifically FP8 and FP4, which are gaining popularity for efficient
inference. We design a compression method that separates and compresses the
exponent and mantissa components independently using entropy coding. Our
evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also
investigate the compressibility of key-value (K/V) cache tensors used in large
language models (LLMs), finding that they, too, exhibit compressible patterns,
enabling memory savings during deployment.

</details>


### [6] [POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization](https://arxiv.org/abs/2508.19277)
*Xinyu Li,Tianjin Huang,Ronghui Mu,Xiaowei Huang,Gaojie Jin*

Main category: cs.LG

TL;DR: POT는 외부 데이터 접근 없이 LLM 기반의 적대적 프롬프트를 생성하는 새로운 공격 프레임워크로, 다양한 모델 아키텍처와 데이터셋에서 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 체인 오브 싱크(CoT) 프롬프트의 발전으로 LLM의 추론 능력이 크게 향상되었지만, 과도한 자원 소모와 성능 향상이 없는 비효율적인 추론 체인이라는 새로운 취약점이 생겼다.

Method: POT(프롬프트 전용 과도한 사고)는 외부 데이터 접근과 모델 조회 의존도를 없애고, LLM 기반의 반복 최적화를 통해 은밀하고 의미적으로 자연스러운 적대적 프롬프트를 생성하는 새로운 블랙박스 공격 프레임워크이다.

Result: POT는 다양한 모델 아키텍처와 데이터셋에 걸쳐 다른 방법들과 비교해 우수한 성능을 나타낸다.

Conclusion: POT는 기존의 과도한 사고 공격의 한계를 극복하며, 실제 시나리오에서의 활용 가능성을 높인다.

Abstract: Recent advances in Chain-of-Thought (CoT) prompting have substantially
enhanced the reasoning capabilities of large language models (LLMs), enabling
sophisticated problem-solving through explicit multi-step reasoning traces.
However, these enhanced reasoning processes introduce novel attack surfaces,
particularly vulnerabilities to computational inefficiency through
unnecessarily verbose reasoning chains that consume excessive resources without
corresponding performance gains. Prior overthinking attacks typically require
restrictive conditions including access to external knowledge sources for data
poisoning, reliance on retrievable poisoned content, and structurally obvious
templates that limit practical applicability in real-world scenarios. To
address these limitations, we propose POT (Prompt-Only OverThinking), a novel
black-box attack framework that employs LLM-based iterative optimization to
generate covert and semantically natural adversarial prompts, eliminating
dependence on external data access and model retrieval. Extensive experiments
across diverse model architectures and datasets demonstrate that POT achieves
superior performance compared to other methods.

</details>


### [7] [Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence](https://arxiv.org/abs/2508.20019)
*Ji Wang,Kashing Chen,Xinyuan Song,Ke Zhang,Lynn Ai,Eric Yang,Bill Shi*

Main category: cs.LG

TL;DR: Symphony는 경량 LLM이 소비자용 GPU에서 효율적으로 협력할 수 있도록 하는 분산 다중 에이전트 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 LLM 기반 에이전트 프레임워크는 중앙 집중식 오케스트레이션에 의존하여 높은 배포 비용과 경직된 통신 구조 및 제한된 적응성을 초래한다.

Method: Symphony는 (1) 능력을 기록하는 분산 원장, (2) 동적 작업 할당을 위한 비콘 선택 프로토콜, (3) CoTs 기반의 가중 결과 투표를 포함하는 세 가지 주요 메커니즘을 도입한다.

Result: Symphony는 추론 기준에서 기존 기준선을 능가하며, 상당한 정확도 향상을 달성하고 다양한 용량의 모델에서도 강인성을 입증한다.

Conclusion: 이 설계는 저비용으로 프라이버시 보호, 확장 가능성 및 내결함성을 갖춘 오케스트레이션을 형성한다.

Abstract: Most existing Large Language Model (LLM)-based agent frameworks rely on
centralized orchestration, incurring high deployment costs, rigid communication
topologies, and limited adaptability. To address these challenges, we introduce
Symphony, a decentralized multi-agent system which enables lightweight LLMs on
consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:
(1) a decentralized ledger that records capabilities, (2) a Beacon-selection
protocol for dynamic task allocation, and (3) weighted result voting based on
CoTs. This design forms a privacy-saving, scalable, and fault-tolerant
orchestration with low overhead. Empirically, Symphony outperforms existing
baselines on reasoning benchmarks, achieving substantial accuracy gains and
demonstrating robustness across models of varying capacities.

</details>


### [8] [(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems](https://arxiv.org/abs/2508.19318)
*Aohan Li,Miyu Tsuzuki*

Main category: cs.LG

TL;DR: 이 논문은 실제 분산 IoT 환경에서 DRL 모델을 훈련시키기 위한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제 분산 IoT 시스템에서 DRL 모델을 실세계 데이터로 훈련하는 연구는 제한적이다.

Method: 제안된 프레임워크에서 IoT 장치는 DRL 기반 방법을 사용하여 통신 채널을 선택하고, DRL 모델은 피드백 정보를 통해 훈련된다.

Result: 프레임 성공률(FSR) 측면에서 구현 및 성능 평가가 이루어졌다.

Conclusion: 제안된 프레임워크의 실행 가능성과 효과가 입증되었다.

Abstract: Deep Reinforcement Learning (DRL) has emerged as an efficient approach to
resource allocation due to its strong capability in handling complex
decision-making tasks. However, only limited research has explored the training
of DRL models with real-world data in practical, distributed Internet of Things
(IoT) systems. To bridge this gap, this paper proposes a novel framework for
training DRL models in real-world distributed IoT environments. In the proposed
framework, IoT devices select communication channels using a DRL-based method,
while the DRL model is trained with feedback information. Specifically,
Acknowledgment (ACK) information is obtained from actual data transmissions
over the selected channels. Implementation and performance evaluation, in terms
of Frame Success Rate (FSR), are carried out, demonstrating both the
feasibility and the effectiveness of the proposed framework.

</details>


### [9] [Re:Frame -- Retrieving Experience From Associative Memory](https://arxiv.org/abs/2508.19344)
*Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: Re:Frame는 제한된 전문가의 데이터를 활용하여 오프라인 강화 학습의 성능을 향상시키는 모듈이다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 강화 학습에서는 전문가 데이터를 수집하기 어려운 상황에서 서브 최적의 데이터로 인해 성능이 저하되는 문제가 있다.

Method: Re:Frame은 외부 비연관 기억 버퍼(AMB)를 사용하여 전문가의 경로를 참조하고, 이를 통해 정책이 저품질 데이터에서 전문가 데이터를 검색하고 의사결정에 통합하도록 학습한다.

Result: Re:Frame은 D4RL MuJoCo 작업에서 단 60개의 전문가 경로로도 강력한 Decision Transformer 기준선보다 성능을 향상시키며, 최대 +10.7 정규화된 포인트의 이득을 보여준다.

Conclusion: Re:Frame은 희소한 전문가 지식을 효율적으로 주입하여 저품질 데이터셋에서 오프라인 강화 학습을 크게 개선하는 간단한 방법을 제공한다.

Abstract: Offline reinforcement learning (RL) often deals with suboptimal data when
collecting large expert datasets is unavailable or impractical. This limitation
makes it difficult for agents to generalize and achieve high performance, as
they must learn primarily from imperfect or inconsistent trajectories. A
central challenge is therefore how to best leverage scarce expert
demonstrations alongside abundant but lower-quality data. We demonstrate that
incorporating even a tiny amount of expert experience can substantially improve
RL agent performance. We introduce Re:Frame (Retrieving Experience From
Associative Memory), a plug-in module that augments a standard offline RL
policy (e.g., Decision Transformer) with a small external Associative Memory
Buffer (AMB) populated by expert trajectories drawn from a separate dataset.
During training on low-quality data, the policy learns to retrieve expert data
from the Associative Memory Buffer (AMB) via content-based associations and
integrate them into decision-making; the same AMB is queried at evaluation.
This requires no environment interaction and no modifications to the backbone
architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories
(0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a
strong Decision Transformer baseline in three of four settings, with gains up
to +10.7 normalized points. These results show that Re:Frame offers a simple
and data-efficient way to inject scarce expert knowledge and substantially
improve offline RL from low-quality datasets.

</details>


### [10] [Memorization in Graph Neural Networks](https://arxiv.org/abs/2508.19352)
*Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch*

Main category: cs.LG

TL;DR: 이 논문은 노드 분류에서 레이블 암기의 양을 정량화하는 첫 번째 프레임워크인 NCMemo를 소개하며, 그래프 동질성과 암기 간의 관계를 논의합니다.


<details>
  <summary>Details</summary>
Motivation: 그래프 신경망(GNNs)에서의 레이블 암기에 대한 탐색이 부족하여 이를 연구하고자 합니다.

Method: NCMemo 프레임워크를 통해 그래프 동질성과 암기 간의 역 관계를 규명하고, GNN 교육 역학을 분석합니다.

Result: 저동질 그래프에서 감소된 동질성이 암기를 유도하며, 노드 레이블의 메모리화와 연결됩니다.

Conclusion: 그래프 재배선을 통해 암기를 완화할 수 있으며, 이는 모델 성능에 영향을 미치지 않고 프라이버시를 보호하는 데 기여합니다.

Abstract: Deep neural networks (DNNs) have been shown to memorize their training data,
yet similar analyses for graph neural networks (GNNs) remain largely
under-explored. We introduce NCMemo (Node Classification Memorization), the
first framework to quantify label memorization in semi-supervised node
classification. We first establish an inverse relationship between memorization
and graph homophily, i.e., the property that connected nodes share similar
labels/features. We find that lower homophily significantly increases
memorization, indicating that GNNs rely on memorization to learn less
homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the
increased memorization in low homophily graphs is tightly coupled to the GNNs'
implicit bias on using graph structure during learning. In low homophily
regimes, this structure is less informative, hence inducing memorization of the
node labels to minimize training loss. Finally, we show that nodes with higher
label inconsistency in their feature-space neighborhood are significantly more
prone to memorization. Building on our insights into the link between graph
homophily and memorization, we investigate graph rewiring as a means to
mitigate memorization. Our results demonstrate that this approach effectively
reduces memorization without compromising model performance. Moreover, we show
that it lowers the privacy risk for previously memorized data points in
practice. Thus, our work not only advances understanding of GNN learning but
also supports more privacy-preserving GNN deployment.

</details>


### [11] [Efficient Multi-Source Knowledge Transfer by Model Merging](https://arxiv.org/abs/2508.19353)
*Marcin Osial,Bartosz Wójcik,Bartosz Zieliński,Sebastian Cygert*

Main category: cs.LG

TL;DR: 본 논문은 다중 소스 전이 학습 문제를 해결하기 위해 특이값 분해(SVD)를 활용하여 모델의 기본 컴포넌트를 분해하고, 이를 바탕으로 가장 중요한 컴포넌트만 선택하여 지식 통합의 효율성과 정밀도를 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 전이 학습은 유리한 전략이지만, 온라인에 있는 수많은 모델에서 지식을 활용할 기회를 간과하고 있습니다.

Method: 각 소스 모델을 특이값 분해(SVD)를 사용하여 기본 요소로 분해하고, 다음 단계에서 가장 중요한 요소만 선택하여 통합합니다.

Result: 우리의 방법은 목표 작업에 맞게 병합된 행렬의 주 특이값만 미세 조정하여 합성된 지식 기반을 잘 보존하고 활용합니다.

Conclusion: 제안된 프레임워크는 효율적인 전이 학습을 가능하게 하며, 입력 수준과 매개변수 공간 모두에서의 섭동에 견고하고, 계산적으로 잘 확장됩니다.

Abstract: While transfer learning is an advantageous strategy, it overlooks the
opportunity to leverage knowledge from numerous available models online.
Addressing this multi-source transfer learning problem is a promising path to
boost adaptability and cut re-training costs. However, existing approaches are
inherently coarse-grained, lacking the necessary precision for granular
knowledge extraction and the aggregation efficiency required to fuse knowledge
from either a large number of source models or those with high parameter
counts. We address these limitations by leveraging Singular Value Decomposition
(SVD) to first decompose each source model into its elementary, rank-one
components. A subsequent aggregation stage then selects only the most salient
components from all sources, thereby overcoming the previous efficiency and
precision limitations. To best preserve and leverage the synthesized knowledge
base, our method adapts to the target task by fine-tuning only the principal
singular values of the merged matrix. In essence, this process only
recalibrates the importance of top SVD components. The proposed framework
allows for efficient transfer learning, is robust to perturbations both at the
input level and in the parameter space (e.g., noisy or pruned sources), and
scales well computationally.

</details>


### [12] [Graph Data Modeling: Molecules, Proteins, & Chemical Processes](https://arxiv.org/abs/2508.19356)
*José Manuel Barraza-Chavez,Rana A. Barghout,Ricardo Almada-Monter,Adrian Jinich,Radhakrishnan Mahadevan,Benjamin Sanchez-Lengeling*

Main category: cs.LG

TL;DR: 화학 과학에서 그래프는 분자, 단백질, 반응 및 산업 프로세스를 설명하는 자연어로 중요하다. 본 논문은 그래프를 수학적 객체로 소개하고, 그래프 신경망을 포함한 학습 알고리즘이 이를 어떻게 다룰 수 있는지를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 그래프는 화학의 다양한 개념을 설명하고 상호작용 및 구조를 캡처하는 데 중요한 역할을 한다.

Method: 그래프 설계의 기초, 주요 예측 작업, 화학 과학 전반의 대표적인 사례, 그래프 기반 모델링에서 기계 학습의 역할을 개요한다.

Result: 독자가 그래프 방법을 다음 세대 화학 발견에 적용할 준비를 하도록 돕는 개념들을 제시한다.

Conclusion: 그래프 데이터 모델링은 화학 과학의 발전에 중요한 기여를 할 것으로 기대된다.

Abstract: Graphs are central to the chemical sciences, providing a natural language to
describe molecules, proteins, reactions, and industrial processes. They capture
interactions and structures that underpin materials, biology, and medicine.
This primer, Graph Data Modeling: Molecules, Proteins, & Chemical Processes,
introduces graphs as mathematical objects in chemistry and shows how learning
algorithms (particularly graph neural networks) can operate on them. We outline
the foundations of graph design, key prediction tasks, representative examples
across chemical sciences, and the role of machine learning in graph-based
modeling. Together, these concepts prepare readers to apply graph methods to
the next generation of chemical discovery.

</details>


### [13] [Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture](https://arxiv.org/abs/2508.19361)
*Yongbin Lee,Ki H. Chon*

Main category: cs.LG

TL;DR: 본 연구에서는 RR 간격만을 사용하여 AF 조기 예측을 위한 경량 깊은 학습 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: AF(심방 세동)는 뇌졸중, 심부전 및 기타 심혈관 합병증의 위험을 증가시키는 가장 흔한 부정맥입니다. 진행 초기의 주기적 AF가 자주 발견되지 않지만, 이것이 지속적인 AF로 발전할 수 있습니다. AF의 조기 예측은 예방적 치료를 통해 질병 진행을 줄일 수 있는 기회를 제공합니다.

Method: Temporal Convolutional Network(TCN)과 선택적 상태 공간 모델인 Mamba를 결합하여 RR 간격만으로 AF의 조기 예측을 가능하게 하는 경량 깊은 학습 모델을 개발했습니다.

Result: 모델은 약 0.908의 민감도, 0.933의 특이도, 0.930의 F1 점수, 0.972의 AUROC 및 0.932의 AUPRC를 기록했습니다. 또한, 73.5천 개의 매개변수와 38.3 MFLOPs로 계산 효율이 높습니다.

Conclusion: 모델은 단 30분의 입력 데이터로 최대 2시간 전에 AF를 예측할 수 있어, 예방적 개입을 위한 충분한 시간 여유를 제공합니다.

Abstract: Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk
of stroke, heart failure, and other cardiovascular complications. While AF
detection algorithms perform well in identifying persistent AF, early-stage
progression, such as paroxysmal AF (PAF), often goes undetected due to its
sudden onset and short duration. However, undetected PAF can progress into
sustained AF, increasing the risk of mortality and severe complications. Early
prediction of AF offers an opportunity to reduce disease progression through
preventive therapies, such as catecholamine-sparing agents or beta-blockers. In
this study, we propose a lightweight deep learning model using only RR
Intervals (RRIs), combining a Temporal Convolutional Network (TCN) for
positional encoding with Mamba, a selective state space model, to enable early
prediction of AF through efficient parallel sequence modeling. In subject-wise
testing results, our model achieved a sensitivity of 0.908, specificity of
0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our
method demonstrates high computational efficiency, with only 73.5 thousand
parameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural
Network-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and
model compactness. Notably, the model can predict AF up to two hours in advance
using just 30 minutes of input data, providing enough lead time for preventive
interventions.

</details>


### [14] [Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs](https://arxiv.org/abs/2508.19366)
*Supratik Sarkar,Swagatam Das*

Main category: cs.LG

TL;DR: 이 연구는 다중 모달 대형 언어 모델에서 환각을 정량화하는 rigor한 정보 기하학적 프레임워크를 제시하며, 환각의 진화 및 모달리티 상호작용을 수량화할 수 있는 이론적으로 해석 가능한 메트릭을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 모달 분야에서 대형 언어 모델의 환각 현상은 신뢰할 수 있는 AI의 중요한 장애물입니다.

Method: 우리는 다중 모달 대형 언어 모델에서 환각을 정량화하기 위한 첫 번째 엄격한 정보 기하학적 프레임워크를 도입하고, MLLM 출력은 다중 모달 그래프 라플라시안에 대한 스펙트럼 임베딩으로 표현하며 진실과 불일치를 의미 왜곡으로 특성화합니다.

Result: 이 프레임워크는 시간 의존적 온도 프로필의 함수로서 다중 모달 환각 에너지에 대한 타이트한 레일리-리츠 경계를 제공합니다.

Conclusion: 이 연구는 환각을 정량화하고 경계를 설정하기 위한 원칙적인 기초를 마련하여 환각을 정성적인 위험에서 다루기 쉬운 분석 가능한 현상으로 변화시킵니다.

Abstract: Hallucinations in large language models (LLMs) remain a fundamental obstacle
to trustworthy AI, particularly in high-stakes multimodal domains such as
medicine, law, and finance. Existing evaluation techniques are largely
heuristic -- anchored in qualitative benchmarking or ad-hoc empirical
mitigation -- providing neither principled quantification nor actionable
theoretical guarantees. This gap leaves a critical blind spot in understanding
how hallucinations arise, propagate, and interact across modalities. We
introduce the first (to our knowledge) rigorous information geometric framework
in diffusion dynamics for quantifying hallucinations in multimodal LLMs
(MLLMs), advancing the field from qualitative detection to mathematically
grounded measurement. Our approach represents MLLM outputs as the spectral
embeddings over multimodal graph Laplacians and characterizes the manifold gaps
of truth vs inconsistencies as the semantic distortion, enabling the tight
Rayleigh--Ritz bounds on the multimodal hallucination energy as a functional of
time-dependent temperature profiles. By leveraging eigenmode decompositions in
Reproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers
modality-aware, theoretically interpretable metrics that capture the evolution
of hallucinations across time and input prompts through temperature annealing.
This work establishes a principled foundation for quantifying and bounding
hallucinations, transforming them from a qualitative risk to a tractable,
analyzable phenomenon.

</details>


### [15] [Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments](https://arxiv.org/abs/2508.19376)
*Dikshant Sagar,Kaiwen Yu,Alejandro Yankelevich,Jianming Bian,Pierre Baldi*

Main category: cs.LG

TL;DR: 비전-언어 모델(VLM)이 고에너지 물리학 실험에서 중성미자 상호작용 분류에 효과적임을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)의 최신 발전이 자연어를 넘어서는 다중 모달 추론의 강력한 잠재력을 보여주고 있다.

Method: LLaMA 3.2를 기반으로 한 미세 조정된 비전-언어 모델(VLM)을 사용하여 픽셀화된 탐지기 이미지에서 중성미자 상호작용을 분류한다.

Result: VLM이 CNN 기준선과 비교해 분류 정확도, 정밀도, 재현율, AUC-ROC와 같은 여러 메트릭에서 뛰어난 성능을 발휘함을 보고한다.

Conclusion: VLM은 HEP에서 사건 분류를 위한 유망한 범용 백본을 제공하며, 실험 중성미자 물리학의 다중 모달 접근 방식을 가능하게 한다.

Abstract: Recent progress in large language models (LLMs) has shown strong potential
for multimodal reasoning beyond natural language. In this work, we explore the
use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for
classifying neutrino interactions from pixelated detector images in high-energy
physics (HEP) experiments. We benchmark its performance against an established
CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as
classification accuracy, precision, recall, and AUC-ROC. Our results show that
the VLM not only matches or exceeds CNN performance but also enables richer
reasoning and better integration of auxiliary textual or semantic context.
These findings suggest that VLMs offer a promising general-purpose backbone for
event classification in HEP, paving the way for multimodal approaches in
experimental neutrino physics.

</details>


### [16] [Towards Quantum Machine Learning for Malicious Code Analysis](https://arxiv.org/abs/2508.19381)
*Jesus Lopez,Saeefa Rubaiyet Nowmi,Viviana Cadena,Mohammad Saidur Rahman*

Main category: cs.LG

TL;DR: 양자 머신러닝을 활용한 새로운 악성코드 분류 모델을 제안하고 평가함.


<details>
  <summary>Details</summary>
Motivation: 양자 컴퓨팅의 발전으로 악성코드 탐지의 향상을 기대할 수 있으나, 이 분야에서의 실제 응용은 미비한 상황이다. 따라서 본 연구에서는 악성코드 분류를 위한 하이브리드 양자-클래식 모델을 탐구한다.

Method: 양자 다층 퍼셉트론(QMLP)과 양자 합성곱 신경망(QCNN)의 두 가지 모델을 사용하여 악성코드 특성을 양자 상태로 인코딩하기 위해 각도 임베딩을 활용한다. QMLP는 전체 큐비트 측정 및 데이터 재업로드를 통해 복잡한 패턴을 포착하고, QCNN은 활성 큐비트를 줄이는 양자 합성곱과 풀링 레이어를 통해 더 빠른 훈련을 달성한다.

Result: 양자 분류 모델들은 5개의 악성코드 데이터셋(API-Graph, EMBER-Domain, EMBER-Class, AZ-Domain, AZ-Class)에서 평가되었으며, 이진 분류에서 95-96%의 정확도를 보였다.

Conclusion: 복잡한 다중 클래스 작업에서 QMLP가 QCNN을 능가하였지만, QCNN은 정확도가 감소하는 대신 훈련 효율성을 개선하였다.

Abstract: Classical machine learning (CML) has been extensively studied for malware
classification. With the emergence of quantum computing, quantum machine
learning (QML) presents a paradigm-shifting opportunity to improve malware
detection, though its application in this domain remains largely unexplored. In
this study, we investigate two hybrid quantum-classical models -- a Quantum
Multilayer Perceptron (QMLP) and a Quantum Convolutional Neural Network (QCNN),
for malware classification. Both models utilize angle embedding to encode
malware features into quantum states. QMLP captures complex patterns through
full qubit measurement and data re-uploading, while QCNN achieves faster
training via quantum convolution and pooling layers that reduce active qubits.
We evaluate both models on five widely used malware datasets -- API-Graph,
EMBER-Domain, EMBER-Class, AZ-Domain, and AZ-Class, across binary and
multiclass classification tasks.
  Our results show high accuracy for binary classification -- 95-96% on
API-Graph, 91-92% on AZ-Domain, and 77% on EMBER-Domain. In multiclass
settings, accuracy ranges from 91.6-95.7% on API-Graph, 41.7-93.6% on AZ-Class,
and 60.7-88.1% on EMBER-Class. Overall, QMLP outperforms QCNN in complex
multiclass tasks, while QCNN offers improved training efficiency at the cost of
reduced accuracy.

</details>


### [17] [DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting](https://arxiv.org/abs/2508.19389)
*Owais Ahmad,Milad Ramezankhani,Anirudh Deodhar*

Main category: cs.LG

TL;DR: DETNO 모델은 고주파 교통 현상을 정확히 예측하여 기존의 신경 연산자보다 안정적이며 우수한 성능을 보입니다.


<details>
  <summary>Details</summary>
Motivation: 정확한 장기 교통 예측은 지능형 교통 시스템에서 중요한 도전 과제가 되었습니다.

Method: Diffusion-Enhanced Transformer Neural Operator (DETNO) 아키텍처를 도입하여 교차 주의 메커니즘과 확산 기반 정제 요소를 활용했습니다.

Result: DETNO는 기존 신경 연산자에 비해 확장된 롤아웃 예측에서 우수한 성능을 나타냈습니다.

Conclusion: 이 접근 방법은 고주파 교통 세부 사항을 보존하고 장기 예측의 안정성을 향상시킵니다.

Abstract: Accurate long-term traffic forecasting remains a critical challenge in
intelligent transportation systems, particularly when predicting high-frequency
traffic phenomena such as shock waves and congestion boundaries over extended
rollout horizons. Neural operators have recently gained attention as promising
tools for modeling traffic flow. While effective at learning function space
mappings, they inherently produce smooth predictions that fail to reconstruct
high-frequency features such as sharp density gradients which results in rapid
error accumulation during multi-step rollout predictions essential for
real-time traffic management. To address these fundamental limitations, we
introduce a unified Diffusion-Enhanced Transformer Neural Operator (DETNO)
architecture. DETNO leverages a transformer neural operator with
cross-attention mechanisms, providing model expressivity and super-resolution,
coupled with a diffusion-based refinement component that iteratively
reconstructs high-frequency traffic details through progressive denoising. This
overcomes the inherent smoothing limitations and rollout instability of
standard neural operators. Through comprehensive evaluation on chaotic traffic
datasets, our method demonstrates superior performance in extended rollout
predictions compared to traditional and transformer-based neural operators,
preserving high-frequency components and improving stability over long
prediction horizons.

</details>


### [18] [Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding](https://arxiv.org/abs/2508.19394)
*Afrar Jahin,Yi Pan,Yingfeng Wang,Tianming Liu,Wei Zhang*

Main category: cs.LG

TL;DR: 본 연구는 분자 설계를 위한 고급 생성 모델에서 양자 기계 학습(QML)의 통합을 통해 SMILES 문자열 재구성을 위한 하이브리드 양자-고전 아키텍처를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 양자 기계 학습(QML)의 최근 발전이 생성 모델, 특히 분자 설계에서 상당한 잠재력을 제공하지만, 많은 고전적 접근 방식이 높은 충실도와 유효성을 달성하는 데 여전히 어려움을 겪고 있다는 점.

Method: 양자 인코딩을 고전적 시퀀스 모델링과 통합하여 SMILES 재구성을 위한 하이브리드 양자-고전 아키텍처를 제안한다.

Result: 약 84%의 양자 충실도와 60%의 고전적 재구성 유사성을 달성하여 기존의 양자 기준을 초월한다.

Conclusion: 우리의 연구는 분자 및 약물 발견을 위한 양자 인식을 가진 시퀀스 모델에 대한 더 광범위한 연구를 촉진하는 동시에 표현력 있는 양자 표현과 고전적 시퀀스 모델 간의 균형을 맞추는 유망한 기초를 제공한다.

Abstract: Although recent advances in quantum machine learning (QML) offer significant
potential for enhancing generative models, particularly in molecular design, a
large array of classical approaches still face challenges in achieving high
fidelity and validity. In particular, the integration of QML with
sequence-based tasks, such as Simplified Molecular Input Line Entry System
(SMILES) string reconstruction, remains underexplored and usually suffers from
fidelity degradation. In this work, we propose a hybrid quantum-classical
architecture for SMILES reconstruction that integrates quantum encoding with
classical sequence modeling to improve quantum fidelity and classical
similarity. Our approach achieves a quantum fidelity of approximately 84% and a
classical reconstruction similarity of 60%, surpassing existing quantum
baselines. Our work lays a promising foundation for future QML applications,
striking a balance between expressive quantum representations and classical
sequence models and catalyzing broader research on quantum-aware sequence
models for molecular and drug discovery.

</details>


### [19] [Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks](https://arxiv.org/abs/2508.19410)
*Zongyu Wu,Ruichen Xu,Luoyao Chen,Georgios Kementzidis,Siyao Wang,Yuefan Deng*

Main category: cs.LG

TL;DR: KAR-HNN은 다층 퍼셉트론 대신 일변량 변환을 사용하여 에너지를 보존하고 고주파 및 다중 규모 동역학을 잘 포착하는 새로운 해밀토니안 신경망 모델이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 해밀토니안 신경망이 다층 퍼셉트론에 의존하여 하이퍼파라미터에 민감해지는 문제를 해결하기 위함이다.

Method: 일변량 변환을 활용하여 해밀토니안 함수를 데이터에서 직접 학습하고, 국소 함수 근사를 이용하여 에너지 드리프트를 줄인다.

Result: KAR-HNN은 spring-mass, 간단한 진자, 이체 및 삼체 문제를 포함한 네 가지 벤치마크 문제에서 평가되었다.

Conclusion: KAR-HNN은 높은 차원에서 몇 개의 알려진 매개변수로도 실질적인 물리 과정을 정확하고 안정적으로 모델링하는 데 효과적일 것으로 예상된다.

Abstract: We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural
Network (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with
univariate transformations. While Hamiltonian Neural Networks (HNNs) ensure
energy conservation by learning Hamiltonian functions directly from data,
existing implementations, often relying on MLPs, cause hypersensitivity to the
hyperparameters while exploring complex energy landscapes. Our approach
exploits the localized function approximations to better capture high-frequency
and multi-scale dynamics, reducing energy drift and improving long-term
predictive stability. The networks preserve the symplectic form of Hamiltonian
systems, and thus maintain interpretability and physical consistency. After
assessing KAR-HNN on four benchmark problems including spring-mass, simple
pendulum, two- and three-body problem, we foresee its effectiveness for
accurate and stable modeling of realistic physical processes often at high
dimensions and with few known parameters.

</details>


### [20] [Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention](https://arxiv.org/abs/2508.19414)
*Gustavo Sandoval*

Main category: cs.LG

TL;DR: 이 연구에서는 Llama-3.1-8B-Instruct이 채팅이나 Q&A 형식에서 '9.11'을 '9.8'보다 더 크다고 잘못 판단하는 포맷 의존성 추론 실패 사례를 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 포맷에 따라 발생하는 추론 실패를 이해하고 수정하기 위하여

Method: 구조적 개입을 통해 탈환의 짝수/홀수 주목 머리 전문화를 조사하고, 특정 머리가 수치 비교를 처리하며, 다른 머리는 호환되지 않는 기능을 수행한다는 것을 발견했습니다.

Result: 정확한 수리에는 레이어 10에서 8개의 짝수 머리가 필요하며, 7개 이하로는 완전히 실패하고, 8개 이상의 조합은 성공합니다. 16개의 짝수 머리 간의 완벽한 중복성을 가진 샤프한 계산 임계값이 드러납니다.

Conclusion: 전체 모듈 요구 사항이 해석 가능성과 효율성에 대한 의미를 숨기고 있는 복잡한 하위 구조를 갖고 있다는 것을 보여주며, 전체 주목 머리의 25%만 사용하여 완벽한 수리를 달성하고 60% 패턴 대체 임계점을 확인했습니다.

Abstract: We present a mechanistic case study of a format-dependent reasoning failure
in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger
than "9.8" in chat or Q&A formats, but answers correctly in simple format.
Through systematic intervention, we discover transformers implement even/odd
attention head specialization: even indexed heads handle numerical comparison,
while odd heads serve incompatible functions. The bug requires exactly 8 even
heads at Layer 10 for perfect repair. Any combination of 8+ even heads
succeeds, while 7 or fewer completely fails, revealing sharp computational
thresholds with perfect redundancy among the 16 even heads. SAE analysis
reveals the mechanism: format representations separate (10% feature overlap at
Layer 7), then re-entangle with different weightings (80% feature overlap at
Layer 10), with specific features showing 1.5x amplification in failing
formats. We achieve perfect repair using only 25% of attention heads and
identify a 60% pattern replacement threshold, demonstrating that apparent
full-module requirements hide sophisticated substructure with implications for
interpretability and efficiency. All of our code is available at
https://github.com/gussand/surgeon.

</details>


### [21] [Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management](https://arxiv.org/abs/2508.19419)
*Harun Ur Rashid,Aleksandra Pachalieva,Daniel O'Malley*

Main category: cs.LG

TL;DR: 물리 기반 시뮬레이션을 활용한 물체추출 예측 메커니즘이 적용된 머신러닝워크플로우를 제안.


<details>
  <summary>Details</summary>
Motivation: 지질 이질성과 다상 유체 흐름 동 역학으로 인해 정확한 지하 저수압 제어가 매우 어려워짐.

Method: 완전히 미분 가능한 다상 유체 시뮬레이터를 CNN과 결합한 물리 기반 머신러닝 워크플로우를 도입.

Result: 세 가지 천연 물리를 지닌 다상 유체 시뮬레이션으로 높은 정확도 훈련 달성.

Conclusion: 이 방법은 유질 변동을 반영하여 보다 실용적이고 정확한 예측을 가능하게 하며, 시뮬레이션 수를 대폭 줄일 수 있음.

Abstract: Accurate subsurface reservoir pressure control is extremely challenging due
to geological heterogeneity and multiphase fluid-flow dynamics. Predicting
behavior in this setting relies on high-fidelity physics-based simulations that
are computationally expensive. Yet, the uncertain, heterogeneous properties
that control these flows make it necessary to perform many of these expensive
simulations, which is often prohibitive. To address these challenges, we
introduce a physics-informed machine learning workflow that couples a fully
differentiable multiphase flow simulator, which is implemented in the DPFEHM
framework with a convolutional neural network (CNN). The CNN learns to predict
fluid extraction rates from heterogeneous permeability fields to enforce
pressure limits at critical reservoir locations. By incorporating transient
multiphase flow physics into the training process, our method enables more
practical and accurate predictions for realistic injection-extraction scenarios
compare to previous works. To speed up training, we pretrain the model on
single-phase, steady-state simulations and then fine-tune it on full multiphase
scenarios, which dramatically reduces the computational cost. We demonstrate
that high-accuracy training can be achieved with fewer than three thousand
full-physics multiphase flow simulations -- compared to previous estimates
requiring up to ten million. This drastic reduction in the number of
simulations is achieved by leveraging transfer learning from much less
expensive single-phase simulations.

</details>


### [22] [MS-ConTab: Multi-Scale Contrastive Learning of Mutation Signatures for Pan Cancer Representation and Stratification](https://arxiv.org/abs/2508.19424)
*Yifan Dou,Adam Khadre,Ruben C Petreaca,Golrokh Mirzaei*

Main category: cs.LG

TL;DR: 이 연구는 COSMIC 데이터베이스에서 파생된 코딩 돌연변이 데이터를 기반으로 43개 암 유형을 클러스터링하는 새로운 비지도 대조 학습 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 암 발생의 기초가 되는 분자 메커니즘에 대한 통찰력을 제공하기 위해 범암 돌연변이 경관을 이해하는 것이 중요하다.

Method: COSMIC 데이터베이스에서 파생된 코딩 돌연변이 데이터를 사용하여 43개 암 유형을 클러스터링하는 비지도 대조 학습 프레임워크를 도입하고, 핵산 치환 패턴을 포착하는 유전자 수준 프로필과 염색체 전반에 걸친 정규화된 치환 빈도를 나타내는 염색체 수준 프로필을 구축한다.

Result: 결과적으로 생성된 잠재 표현은 생물학적으로 의미 있는 암 유형 클러스터를 생성하며, 이는 알려진 돌연변이 과정과 조직 기원에 부합한다.

Conclusion: 우리의 연구는 대조 학습을 집단 수준의 암 클러스터링에 최초로 적용한 것으로, 돌연변이에 기초한 암 하위 유형화를 위한 확장 가능하고 해석 가능한 프레임워크를 제공한다.

Abstract: Motivation. Understanding the pan-cancer mutational landscape offers critical
insights into the molecular mechanisms underlying tumorigenesis. While
patient-level machine learning techniques have been widely employed to identify
tumor subtypes, cohort-level clustering, where entire cancer types are grouped
based on shared molecular features, has largely relied on classical statistical
methods.
  Results. In this study, we introduce a novel unsupervised contrastive
learning framework to cluster 43 cancer types based on coding mutation data
derived from the COSMIC database. For each cancer type, we construct two
complementary mutation signatures: a gene-level profile capturing nucleotide
substitution patterns across the most frequently mutated genes, and a
chromosome-level profile representing normalized substitution frequencies
across chromosomes. These dual views are encoded using TabNet encoders and
optimized via a multi-scale contrastive learning objective (NT-Xent loss) to
learn unified cancer-type embeddings. We demonstrate that the resulting latent
representations yield biologically meaningful clusters of cancer types,
aligning with known mutational processes and tissue origins. Our work
represents the first application of contrastive learning to cohort-level cancer
clustering, offering a scalable and interpretable framework for mutation-driven
cancer subtyping.

</details>


### [23] [Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models](https://arxiv.org/abs/2508.19441)
*Sanket Jantre,Deepak Akhare,Xiaoning Qian,Nathan M. Urban*

Main category: cs.LG

TL;DR: 이 논문에서는 국소 '스텐실' 상태의 공간 채우기 샘플링을 통해 신경 PDE 훈련 데이터를 생성하는 데이터 증강 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 신경 PDE를 사용하여 전통적인 수치 PDE 솔버보다 모델링의 유연성과 효율성을 높이기 위함입니다.

Method: 로컬 '스텐실' 상태의 공간 채우기 샘플링을 통한 데이터 증강 전략을 제안합니다.

Result: 합성 훈련 데이터를 통해 정확한 신경 PDE 스텐실 연산자를 학습할 수 있음을 보여줍니다.

Conclusion: 데이터 증강을 통해 더 나은 훈련된 신경 스텐실 연산자를 얻을 수 있습니다.

Abstract: Partial differential equations (PDEs) underpin the modeling of many natural
and engineered systems. It can be convenient to express such models as neural
PDEs rather than using traditional numerical PDE solvers by replacing part or
all of the PDE's governing equations with a neural network representation.
Neural PDEs are often easier to differentiate, linearize, reduce, or use for
uncertainty quantification than the original numerical solver. They are usually
trained on solution trajectories obtained by long time integration of the PDE
solver. Here we propose a more sample-efficient data-augmentation strategy for
generating neural PDE training data from a computer model by space-filling
sampling of local "stencil" states. This approach removes a large degree of
spatiotemporal redundancy present in trajectory data and oversamples states
that may be rarely visited but help the neural PDE generalize across the state
space. We demonstrate that accurate neural PDE stencil operators can be learned
from synthetic training data generated by the computational equivalent of 10
timesteps' worth of numerical simulation. Accuracy is further improved if we
assume access to a single full-trajectory simulation from the computer model,
which is typically available in practice. Across several PDE systems, we show
that our data-augmented synthetic stencil data yield better trained neural
stencil operators, with clear performance gains compared with naively sampled
stencil data from simulation trajectories.

</details>


### [24] [Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization](https://arxiv.org/abs/2508.19443)
*Paimon Goulart,Shaan Pakala,Evangelos Papalexakis*

Main category: cs.LG

TL;DR: 이 논문은 복잡한 시뮬레이션 데이터셋 생성을 효율적으로 만들기 위해 내부 텐서 분해를 도입하여 생성 모델의 비용을 줄이는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 시뮬레이션 데이터셋을 생성하는 것은 시간과 자원이 많이 소모되는 작업입니다. 이러한 실험이 비쌀수록 합성 데이터를 생성하는 것이 더욱 합리적입니다.

Method: 생성적 기계 학습 모델, 특히 내부 텐서 분해를 사용하여 다차원 데이터에 대한 작은 텐서 요소를 생성합니다.

Result: 모델의 출력 및 전체 매개변수를 줄이면서 생성된 데이터는 여전히 유용함을 보여줍니다.

Conclusion: 텐서 분해는 생성 모델의 효율성을 개선할 수 있는 잠재력이 있습니다.

Abstract: Producing large complex simulation datasets can often be a time and resource
consuming task. Especially when these experiments are very expensive, it is
becoming more reasonable to generate synthetic data for downstream tasks.
Recently, these methods may include using generative machine learning models
such as Generative Adversarial Networks or diffusion models. As these
generative models improve efficiency in producing useful data, we introduce an
internal tensor decomposition to these generative models to even further reduce
costs. More specifically, for multidimensional data, or tensors, we generate
the smaller tensor factors instead of the full tensor, in order to
significantly reduce the model's output and overall parameters. This reduces
the costs of generating complex simulation data, and our experiments show the
generated data remains useful. As a result, tensor decomposition has the
potential to improve efficiency in generative models, especially when
generating multidimensional data, or tensors.

</details>


### [25] [On Surjectivity of Neural Networks: Can you elicit any behavior from your model?](https://arxiv.org/abs/2508.19445)
*Haozhe Jiang,Nika Haghtalab*

Main category: cs.LG

TL;DR: 현대 신경망 아키텍처의 많은 기본 블록이 항상 전사적이라는 것을 증명하여 적대적 공격에 대한 취약성을 밝혀냄.


<details>
  <summary>Details</summary>
Motivation: 생성 모델의 안전성과 탈옥 취약성에 대한 우려를 해결하기 위해 신경망의 전사성 분석.

Method: 모던 신경망 아키텍처의 기본 구성 요소를 분석하여 그들의 전사성을 증명.

Result: 많은 현대 신경망 아키텍처가 거의 항상 전사적이라는 것을 발견하고, 제네레이티브 프레임워크는 임의의 출력에 대한 역 매핑을 허용함.

Conclusion: 현대 신경망 아키텍처의 전사성을 연구함으로써, 우리는 넓은 범위의 적대적 공격에 대한 그들의 취약성을 명확히 드러낸다.

Abstract: Given a trained neural network, can any specified output be generated by some
input? Equivalently, does the network correspond to a function that is
surjective? In generative models, surjectivity implies that any output,
including harmful or undesirable content, can in principle be generated by the
networks, raising concerns about model safety and jailbreak vulnerabilities. In
this paper, we prove that many fundamental building blocks of modern neural
architectures, such as networks with pre-layer normalization and
linear-attention modules, are almost always surjective. As corollaries, widely
used generative frameworks, including GPT-style transformers and diffusion
models with deterministic ODE solvers, admit inverse mappings for arbitrary
outputs. By studying surjectivity of these modern and commonly used neural
architectures, we contribute a formalism that sheds light on their unavoidable
vulnerability to a broad class of adversarial attacks.

</details>


### [26] [The Sample Complexity of Membership Inference and Privacy Auditing](https://arxiv.org/abs/2508.19458)
*Mahdi Haghifam,Adam Smith,Jonathan Ullman*

Main category: cs.LG

TL;DR: 본 연구는 멤버십 추론 공격에서 성공적인 공격에 필요한 참조 샘플의 최소 수를 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 멤버십 추론 공격의 이해와 필요한 정보량을 규명하기 위해.

Method: 정규 분포로부터의 샘플을 n개 받아 평균 추정을 수행하는 알고리즘을 사용하여 참조 샘플의 수를 연구합니다.

Result: 성공적인 공격을 위해 필요한 샘플 수는 $orall n, 	ext{이 공격이 성공하기 위해 $	ext{O}(n + n^2 ho^2)$ 샘플이 필요할 수 있음을 보여줍니다.

Conclusion: 이 발견은 공격이 훈련된 알고리즘이 사용하는 샘플보다 훨씬 더 많은 샘플이 필요할 수 있음을 시사합니다.

Abstract: A membership-inference attack gets the output of a learning algorithm, and a
target individual, and tries to determine whether this individual is a member
of the training data or an independent sample from the same distribution. A
successful membership-inference attack typically requires the attacker to have
some knowledge about the distribution that the training data was sampled from,
and this knowledge is often captured through a set of independent reference
samples from that distribution. In this work we study how much information the
attacker needs for membership inference by investigating the sample
complexity-the minimum number of reference samples required-for a successful
attack. We study this question in the fundamental setting of Gaussian mean
estimation where the learning algorithm is given $n$ samples from a Gaussian
distribution $\mathcal{N}(\mu,\Sigma)$ in $d$ dimensions, and tries to estimate
$\hat\mu$ up to some error $\mathbb{E}[\|\hat \mu - \mu\|^2_{\Sigma}]\leq
\rho^2 d$. Our result shows that for membership inference in this setting,
$\Omega(n + n^2 \rho^2)$ samples can be necessary to carry out any attack that
competes with a fully informed attacker. Our result is the first to show that
the attacker sometimes needs many more samples than the training algorithm uses
to train the model. This result has significant implications for practice, as
all attacks used in practice have a restricted form that uses $O(n)$ samples
and cannot benefit from $\omega(n)$ samples. Thus, these attacks may be
underestimating the possibility of membership inference, and better attacks may
be possible when information about the distribution is easy to obtain.

</details>


### [27] [Incentivized Lipschitz Bandits](https://arxiv.org/abs/2508.19466)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 이 논문은 보상이 변동하는 상황에서 유인된 탐사를 연구하며, 무한한 팔이 있는 MAB 환경에서 새로운 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다수의 팔을 가지는 상황에서 결정을 내리는 주체가 탐색을 유인하기 위해 보상으로 마이너스적 선택을 초월하도록 유도하는 것을 연구하고자 한다.

Method: 무한 팔 공간을 균일하게 이산화하는 새로운 유인 탐사 알고리즘을 제안하고 이 알고리즘이 누적 후회 및 전체 보상을 동시에 하한으로 달성함을 보인다.

Result: 제안된 알고리즘의 성능을 확고히 하기 위해 이론적 결과를 통해 후회와 보상 경계가 $	ilde{O}(T^{d+1/d+2})$로 도출된다.

Conclusion: 또한, 문맥적 밴딧에 대한 결과를 일반화하여 유사한 성능 보장을 달성하고 수치 시뮬레이션을 통해 이론적 발견을 검증한다.

Abstract: We study incentivized exploration in multi-armed bandit (MAB) settings with
infinitely many arms modeled as elements in continuous metric spaces. Unlike
classical bandit models, we consider scenarios where the decision-maker
(principal) incentivizes myopic agents to explore beyond their greedy choices
through compensation, but with the complication of reward drift--biased
feedback arising due to the incentives. We propose novel incentivized
exploration algorithms that discretize the infinite arm space uniformly and
demonstrate that these algorithms simultaneously achieve sublinear cumulative
regret and sublinear total compensation. Specifically, we derive regret and
compensation bounds of $\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the
covering dimension of the metric space. Furthermore, we generalize our results
to contextual bandits, achieving comparable performance guarantees. We validate
our theoretical findings through numerical simulations.

</details>


### [28] [DeepAtlas: a tool for effective manifold learning](https://arxiv.org/abs/2508.19479)
*Serena Hughes,Timothy Hamilton,Tom Kolokotrones,Eric J. Deeds*

Main category: cs.LG

TL;DR: DeepAtlas는 고차원 데이터셋의 국소적 이웃의 저차원 표현을 생성하고 이를 통해 매니폴드 가설의 진위를 평가하는 알고리즘이다.


<details>
  <summary>Details</summary>
Motivation: 데이터가 저차원 매니폴드에서 추출된다는 매니폴드 가설에 대한 평가 및 매니폴드 구조 학습의 필요성.

Method: DeepAtlas 알고리즘은 데이터의 국소적 이웃을 저차원 표현으로 변환하고, 이러한 표현과 원래 데이터를 연결하는 심층 신경망을 학습한다.

Result: DeepAtlas는 테스트 데이터셋에서 매니폴드 구조를 성공적으로 학습하며, 많은 실제 데이터셋은 매니폴드 가설을 따르지 않는다.

Conclusion: DeepAtlas는 매니폴드에서 데이터를 추출하는 경우 모델을 생성할 수 있으며, 이는 미분 기하학의 강력한 도구를 다양한 데이터셋에 적용할 수 있는 가능성을 제공한다.

Abstract: Manifold learning builds on the "manifold hypothesis," which posits that data
in high-dimensional datasets are drawn from lower-dimensional manifolds.
Current tools generate global embeddings of data, rather than the local maps
used to define manifolds mathematically. These tools also cannot assess whether
the manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas,
an algorithm that generates lower-dimensional representations of the data's
local neighborhoods, then trains deep neural networks that map between these
local embeddings and the original data. Topological distortion is used to
determine whether a dataset is drawn from a manifold and, if so, its
dimensionality. Application to test datasets indicates that DeepAtlas can
successfully learn manifold structures. Interestingly, many real datasets,
including single-cell RNA-sequencing, do not conform to the manifold
hypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a
model that can be used generatively and promises to allow the application of
powerful tools from differential geometry to a variety of datasets.

</details>


### [29] [Distribution Shift Aware Neural Tabular Learning](https://arxiv.org/abs/2508.19486)
*Wangyang Ying,Nanxu Gong,Dongjie Wang,Xinyuan Wang,Arun Vignesh Malarkkan,Vivek Gupta,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: SAFT 프레임워크는 분포 변화 문제를 해결하여 표형 데이터 학습의 강건성과 효과성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 표형 학습의 효과는 훈련 데이터와 테스트 데이터 간의 분포 변화에 의해 저하되므로, 이 문제를 해결할 필요가 있다.

Method: SAFT는 표형 학습을 연속 표현 생성 방식으로 재구성하고, 변환된 특징 집합에 대한 미분 가능한 최적화를 가능하게 한다.

Result: SAFT는 세 가지 메커니즘을 통해 강건성을 보장하고, 다양한 실세계의 분포 변화 하에서도 이전의 방법들보다 뛰어난 성능을 보인다.

Conclusion: SAFT 프레임워크는 강건성, 효과성 및 일반화 능력 측면에서 이전의 표형 학습 방법들을 지속적으로 능가한다.

Abstract: Tabular learning transforms raw features into optimized spaces for downstream
tasks, but its effectiveness deteriorates under distribution shifts between
training and testing data. We formalize this challenge as the Distribution
Shift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature
Transformation (SAFT) framework to address it. SAFT reframes tabular learning
from a discrete search task into a continuous representation-generation
paradigm, enabling differentiable optimization over transformed feature sets.
SAFT integrates three mechanisms to ensure robustness: (i) shift-resistant
representation via embedding decorrelation and sample reweighting, (ii)
flatness-aware generation through suboptimal embedding averaging, and (iii)
normalization-based alignment between training and test distributions.
Extensive experiments show that SAFT consistently outperforms prior tabular
learning methods in terms of robustness, effectiveness, and generalization
ability under diverse real-world distribution shifts.

</details>


### [30] [Data-Efficient Symbolic Regression via Foundation Model Distillation](https://arxiv.org/abs/2508.19487)
*Wangyang Ying,Jinghan Zhang,Haoyue Bai,Nanxu Gong,Xinyuan Wang,Kunpeng Liu,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: EQUATE는 적은 데이터 환경에서 기호 방정식 발견을 위한 기초 모델을 조정하는 데이터 효율적인 미세 조정 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 관찰된 데이터에서 해석 가능한 수학 방정식을 발견하는 것은 과학적 발견의 초석으로, 물리적, 생물학적 및 경제적 시스템의 투명한 모델링을 가능하게 한다.

Method: EQUATE는 상징-수치 정렬과 평가자 유도 임베딩 최적화를 결합하여 임베딩-검색-생성 패러다임을 가능하게 한다. 이 접근법은 데이터-방정식 적합성과 간결성에 의해 안내되는 공유 임베딩 공간에서 이산 방정식 검색을 연속 최적화 작업으로 재구성한다.

Result: 세 가지 표준 공개 벤치마크(파인만, 스트로가츠 및 블랙박스 데이터셋)에서 실험을 수행한 결과, EQUATE는 정확성과 견고성 모두에서 최신 기준선보다 일관되게 우수한 성능을 보였다.

Conclusion: 이러한 결과는 EQUATE가 데이터 효율적인 기호 회귀의 실용적이고 일반화 가능한 솔루션임을 강조한다.

Abstract: Discovering interpretable mathematical equations from observed data (a.k.a.
equation discovery or symbolic regression) is a cornerstone of scientific
discovery, enabling transparent modeling of physical, biological, and economic
systems. While foundation models pre-trained on large-scale equation datasets
offer a promising starting point, they often suffer from negative transfer and
poor generalization when applied to small, domain-specific datasets. In this
paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer
Embeddings), a data-efficient fine-tuning framework that adapts foundation
models for symbolic equation discovery in low-data regimes via distillation.
EQUATE combines symbolic-numeric alignment with evaluator-guided embedding
optimization, enabling a principled embedding-search-generation paradigm. Our
approach reformulates discrete equation search as a continuous optimization
task in a shared embedding space, guided by data-equation fitness and
simplicity. Experiments across three standard public benchmarks (Feynman,
Strogatz, and black-box datasets) demonstrate that EQUATE consistently
outperforms state-of-the-art baselines in both accuracy and robustness, while
preserving low complexity and fast inference. These results highlight EQUATE as
a practical and generalizable solution for data-efficient symbolic regression
in foundation model distillation settings.

</details>


### [31] [PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense](https://arxiv.org/abs/2508.19488)
*Xavier Cadet,Simona Boboila,Sie Hendrata Dharmawan,Alina Oprea,Peter Chin*

Main category: cs.LG

TL;DR: 본 연구에서는 FlipIt 게임을 확장하여 공격자와 방어자가 효율적으로 학습할 수 있는 PoolFlip을 도입하고, 모수 기반 훈련을 활용한 Flip-PSRO 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 사이버 방어는 은밀하고 기만적이며 지속적으로 진화하는 적의 전략에 따라 방어적 의사결정을 자동화해야 합니다.

Method: PoolFlip이라는 다중 에이전트 체육관 환경을 도입하고, 인구 기반 훈련을 활용하여 방어자를 교육시키는 Flip-PSRO이라는 다중 에이전트 강화 학습(MARL) 접근법을 제안합니다.

Result: Flip-PSRO 방어자는 훈련 중 노출되지 않은 휴리스틱 공격에 대해 일반화하는 데 있어 기준 모델보다 $2	imes$ 더 효과적입니다.

Conclusion: 새로 설계된 소유 기반 효용 함수는 Flip-PSRO 방어자가 성능을 최적화하면서 높은 수준의 통제력을 유지하도록 보장합니다.

Abstract: Cyber defense requires automating defensive decision-making under stealthy,
deceptive, and continuously evolving adversarial strategies. The FlipIt game
provides a foundational framework for modeling interactions between a defender
and an advanced adversary that compromises a system without being immediately
detected. In FlipIt, the attacker and defender compete to control a shared
resource by performing a Flip action and paying a cost. However, the existing
FlipIt frameworks rely on a small number of heuristics or specialized learning
techniques, which can lead to brittleness and the inability to adapt to new
attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym
environment that extends the FlipIt game to allow efficient learning for
attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent
reinforcement learning (MARL) approach that leverages population-based training
to train defender agents equipped to generalize against a range of unknown,
potentially adaptive opponents. Our empirical results suggest that Flip-PSRO
defenders are $2\times$ more effective than baselines to generalize to a
heuristic attack not exposed in training. In addition, our newly designed
ownership-based utility functions ensure that Flip-PSRO defenders maintain a
high level of control while optimizing performance.

</details>


### [32] [Learning Game-Playing Agents with Generative Code Optimization](https://arxiv.org/abs/2508.19506)
*Zhiyi Kuang,Ryan Rong,YuCheng Yuan,Allen Nie*

Main category: cs.LG

TL;DR: 이 논문에서는 게임 플레이 에이전트를 학습하기 위한 생성 최적화 접근법을 제시하며, 정책을 파이썬 프로그램으로 표현하고 대규모 언어 모델(LLM)을 사용하여 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 게임 플레이 에이전트를 더 효율적이고 적응 가능한 방식으로 학습하기 위해

Method: 정책을 자기 발전 코드로 처리하고, 현재 관찰을 입력으로, 게임 내 행동을 출력으로 사용하여 에이전트가 최소한의 인간 개입으로 자기 개선하도록 한다.

Result: Atari 게임에 적용했을 때, 우리의 게임 플레이 파이썬 프로그램은 딥 강화 학습(RL) 기준과 경쟁할 만한 성능을 달성했으며, 훈련 시간과 환경 상호작용을 크게 줄였습니다.

Conclusion: 이 작업은 복잡하고 긴 호리즌 추론을 수행할 수 있는 효율적이고 적응 가능한 에이전트를 구축하기 위한 프로그램 정책 표현의 가능성을 강조합니다.

Abstract: We present a generative optimization approach for learning game-playing
agents, where policies are represented as Python programs and refined using
large language models (LLMs). Our method treats decision-making policies as
self-evolving code, with current observation as input and an in-game action as
output, enabling agents to self-improve through execution traces and natural
language feedback with minimal human intervention. Applied to Atari games, our
game-playing Python program achieves performance competitive with deep
reinforcement learning (RL) baselines while using significantly less training
time and much fewer environment interactions. This work highlights the promise
of programmatic policy representations for building efficient, adaptable agents
capable of complex, long-horizon reasoning.

</details>


### [33] [MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data](https://arxiv.org/abs/2508.19554)
*Haruki Yonekura,Ren Ozeki,Tatsuya Amano,Hamada Rizk,Hirozumi Yamaguchi*

Main category: cs.LG

TL;DR: MobText-SISA는 GPS 경로, 시간 메타데이터 및 비구조적 데이터를 다루는 기계 학습 및 비학습 프레임워크로, 개인 정보 보호 요구사항을 충족하기 위해 모델의 재학습 없이도 개인 정보를 삭제할 수 있게 한다.


<details>
  <summary>Details</summary>
Motivation: 최근의 이동성 플랫폼에서 대량의 GPS 경로와 비구조적 데이터를 처리하면서, 개인 정보 보호에 관한 법률인 GDPR을 준수해야 할 필요성이 있다.

Method: MobText-SISA는 SISA 훈련 방법을 확장하여 이질적인 시공간 데이터를 위한 스케일러블한 기계 비학습 프레임워크를 제공한다. 각 여행의 숫자 및 언어적 특성을 공유 잠재 공간에 내장하고, 유사성 인식 클러스터링을 통해 샤드 간 샘플을 배분한다.

Result: 실험 결과에 따르면 MobText-SISA는 (i) 기준 예측 정확도를 유지하고, (ii) 오류율과 수렴 속도 면에서 임의의 샤딩보다 일관되게 우수한 성능을 보였다.

Conclusion: 이러한 결과는 MobText-SISA가 도시 규모의 다중 모달 이동 데이터에 대한 개인 정보 보호를 준수하는 분석을 위한 실용적인 기초로 자리 잡게 한다.

Abstract: Modern mobility platforms have stored vast streams of GPS trajectories,
temporal metadata, free-form textual notes, and other unstructured data.
Privacy statutes such as the GDPR require that any individual's contribution be
unlearned on demand, yet retraining deep models from scratch for every request
is untenable. We introduce MobText-SISA, a scalable machine-unlearning
framework that extends Sharded, Isolated, Sliced, and Aggregated (SISA)
training to heterogeneous spatio-temporal data. MobText-SISA first embeds each
trip's numerical and linguistic features into a shared latent space, then
employs similarity-aware clustering to distribute samples across shards so that
future deletions touch only a single constituent model while preserving
inter-shard diversity. Each shard is trained incrementally; at inference time,
constituent predictions are aggregated to yield the output. Deletion requests
trigger retraining solely of the affected shard from its last valid checkpoint,
guaranteeing exact unlearning. Experiments on a ten-month real-world mobility
log demonstrate that MobText-SISA (i) sustains baseline predictive accuracy,
and (ii) consistently outperforms random sharding in both error and convergence
speed. These results establish MobText-SISA as a practical foundation for
privacy-compliant analytics on multimodal mobility data at urban scale.

</details>


### [34] [Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting](https://arxiv.org/abs/2508.19563)
*Hejia Liu,Mochen Yang,Gediminas Adomavicius*

Main category: cs.LG

TL;DR: 대형 언어 모델(LLMs)은 데이터 적합성 및 예측 생성에 활용되고 있으나, 불필요한 데이터 표현의 변화가 예측에 큰 영향을 미칠 수 있다.


<details>
  <summary>Details</summary>
Motivation: LLMs의 예측 성능이 탁월하지만 데이터 적합성에서의 취약점을 밝히기 위해.

Method: LLMs의 예측 민감도를 분석하고, 주의 집중 양상을 평가한다.

Result: 변수 이름 변경만으로도 예측 오차가 82%까지 차이나며, 특정 위치에 따라 주의 집중 패턴이 비균일하게 나타난다.

Conclusion: LLMs는 뛰어난 예측 능력을 가지고 있지만, 현재는 데이터 적합 도구로서의 기본적인 강건성을 결여하고 있다.

Abstract: Large Language Models (LLMs) are being applied in a wide array of settings,
well beyond the typical language-oriented use cases. In particular, LLMs are
increasingly used as a plug-and-play method for fitting data and generating
predictions. Prior work has shown that LLMs, via in-context learning or
supervised fine-tuning, can perform competitively with many tabular supervised
learning techniques in terms of predictive performance. However, we identify a
critical vulnerability of using LLMs for data fitting -- making changes to data
representation that are completely irrelevant to the underlying learning task
can drastically alter LLMs' predictions on the same data. For example, simply
changing variable names can sway the size of prediction error by as much as 82%
in certain settings. Such prediction sensitivity with respect to
task-irrelevant variations manifests under both in-context learning and
supervised fine-tuning, for both close-weight and open-weight general-purpose
LLMs. Moreover, by examining the attention scores of an open-weight LLM, we
discover a non-uniform attention pattern: training examples and variable
names/values which happen to occupy certain positions in the prompt receive
more attention when output tokens are generated, even though different
positions are expected to receive roughly the same attention. This partially
explains the sensitivity in the presence of task-irrelevant variations. We also
consider a state-of-the-art tabular foundation model (TabPFN) trained
specifically for data fitting. Despite being explicitly designed to achieve
prediction robustness, TabPFN is still not immune to task-irrelevant
variations. Overall, despite LLMs' impressive predictive capabilities,
currently they lack even the basic level of robustness to be used as a
principled data-fitting tool.

</details>


### [35] [Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models](https://arxiv.org/abs/2508.19564)
*Yuhang Liu,Tao Li,Zhehao Huang,Zuopeng Yang,Xiaolin Huang*

Main category: cs.LG

TL;DR: Bi-LoRA는 SAM을 개선하여 메모리 효율성을 높이고 일반화 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 대규모 사전 학습 모델을 제한된 데이터로 미세 조정하는 것은 일반화에 대한 큰 도전과제를 제시한다.

Method: Bi-directional Low-Rank Adaptation (Bi-LoRA) 모듈을 통해 SAM의 적대적 weight 변동을 모델링하여 SAM의 한계를 극복한다.

Result: 다양한 작업과 아키텍처에 대한 광범위한 실험을 통해 Bi-LoRA의 효율성과 효과성을 입증했다.

Conclusion: Bi-LoRA는 두 가지 모듈 디자인을 통해 메모리 효율성을 유지하면서 더 넓은 샤프니스를 포착할 수 있다.

Abstract: Fine-tuning large-scale pre-trained models with limited data presents
significant challenges for generalization. While Sharpness-Aware Minimization
(SAM) has proven effective in improving generalization by seeking flat minima,
its substantial extra memory and computation overhead make it impractical for
large models. Integrating SAM with parameter-efficient fine-tuning methods like
Low-Rank Adaptation (LoRA) is a promising direction. However, we find that
directly applying SAM to LoRA parameters limits the sharpness optimization to a
restricted subspace, hindering its effectiveness. To address this limitation,
we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an
auxiliary LoRA module to model SAM's adversarial weight perturbations. It
decouples SAM's weight perturbations from LoRA optimization: the primary LoRA
module adapts to specific tasks via standard gradient descent, while the
auxiliary module captures the sharpness of the loss landscape through gradient
ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness
for achieving flatter minima while remaining memory-efficient. Another
important benefit is that the dual design allows for simultaneous optimization
and perturbation, eliminating SAM's doubled training costs. Extensive
experiments across diverse tasks and architectures demonstrate Bi-LoRA's
efficiency and effectiveness in enhancing generalization.

</details>


### [36] [Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning](https://arxiv.org/abs/2508.19567)
*Sheryl Mathew,N Harshit*

Main category: cs.LG

TL;DR: 이 논문에서는 다중 모드 데이터셋에서 숨겨진 편향을 학습하고 증폭할 수 있는 강화 학습(인간 피드백 포함) 보상 모델을 제시합니다. 우리는 인과 추론을 결합한 반사실적 보상 모델을 도입하여 비지도 학습 방식으로 편향에 저항하는 보상 신호를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 모드 데이터셋에서의 편향 학습 및 증폭 문제를 해결하기 위한 새로운 접근 방식 필요성.

Method: 반사실적 신뢰 점수를 이용한 인과 추론 및 다중 모드 표현 학습을 통한 새로운 보상 모델 제안.

Result: 가짜 뉴스 탐지에서 89.12%의 정확도를 달성하며 기존 보상 모델을 초과 성능, 편향 제거 및 공정성 향상 도모.

Conclusion: 본 연구는 공정성을 고려한 RLHF를 위한 강력하고 해석 가능한 접근법을 제시하며, 동적 실시간 정책 결정의 신뢰성을 높입니다.

Abstract: In reinforcement learning with human feedback (RLHF), reward models can
efficiently learn and amplify latent biases within multimodal datasets, which
can lead to imperfect policy optimization through flawed reward signals and
decreased fairness. Bias mitigation studies have often applied passive
constraints, which can fail under causal confounding. Here, we present a
counterfactual reward model that introduces causal inference with multimodal
representation learning to provide an unsupervised, bias-resilient reward
signal. The heart of our contribution is the Counterfactual Trust Score, an
aggregated score consisting of four components: (1) counterfactual shifts that
decompose political framing bias from topical bias; (2) reconstruction
uncertainty during counterfactual perturbations; (3) demonstrable violations of
fairness rules for each protected attribute; and (4) temporal reward shifts
aligned with dynamic trust measures. We evaluated the framework on a multimodal
fake versus true news dataset, which exhibits framing bias, class imbalance,
and distributional drift. Following methodologies similar to unsupervised drift
detection from representation-based distances [1] and temporal robustness
benchmarking in language models [2], we also inject synthetic bias across
sequential batches to test robustness. The resulting system achieved an
accuracy of 89.12% in fake news detection, outperforming the baseline reward
models. More importantly, it reduced spurious correlations and unfair
reinforcement signals. This pipeline outlines a robust and interpretable
approach to fairness-aware RLHF, offering tunable bias reduction thresholds and
increasing reliability in dynamic real-time policy making.

</details>


### [37] [Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era](https://arxiv.org/abs/2508.19570)
*Dawei Li,Yue Huang,Ming Li,Tianyi Zhou,Xiangliang Zhang,Huan Liu*

Main category: cs.LG

TL;DR: 본 튜토리얼은 합성 데이터 생성의 기초와 최신 발전을 다루며, 데이터 마이닝을 위한 기계 학습의 혁신적인 기법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 합성 데이터 생성의 필요성이 증가하고 있으며, 이를 통해 데이터 부족, 프라이버시 및 주석 문제를 해결할 수 있는 방법을 모색하고 있다.

Method: 합성 데이터 생성의 기초 이론과 최신 기술을 소개하고, 주요 방법론과 실용적인 프레임워크를 설명한다.

Result: 참가자는 생성적 합성 데이터를 활용하여 데이터 마이닝 연구 및 실습의 향상을 위한 실행 가능한 통찰력을 얻을 수 있다.

Conclusion: 이 튜토리얼은 데이터 마이닝 분야의 혁신적인 발전을 지원하는 데 기여할 것이다.

Abstract: Generative models such as Large Language Models, Diffusion Models, and
generative adversarial networks have recently revolutionized the creation of
synthetic data, offering scalable solutions to data scarcity, privacy, and
annotation challenges in data mining. This tutorial introduces the foundations
and latest advances in synthetic data generation, covers key methodologies and
practical frameworks, and discusses evaluation strategies and applications.
Attendees will gain actionable insights into leveraging generative synthetic
data to enhance data mining research and practice. More information can be
found on our website: https://syndata4dm.github.io/.

</details>


### [38] [Escaping Stability-Plasticity Dilemma in Online Continual Learning for Motion Forecasting via Synergetic Memory Rehearsal](https://arxiv.org/abs/2508.19571)
*Yunlong Lin,Chao Lu,Tongshuai Wu,Xiaocong Zhao,Guodong Du,Yanwei Sun,Zirui Li,Jianwei Gong*

Main category: cs.LG

TL;DR: 새로운 CL 방법인 SyReM은 메모리 안정성과 학습 유연성을 동시에 개선하여 DNN 기반 모션 예측에서 재학습 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: DNN 기반 모션 예측에서 재학습 시 과거 학습 시나리오에 대한 성능 저하 문제를 해결하고자 한다.

Method: SyReM은 학습된 지식을 나타내기 위해 컴팩트한 메모리 버퍼를 유지하며, 평균 손실 증가를 제한하는 불평등 제약을 통해 메모리 안정성을 보장한다. 또한 최근 관측된 데이터와 가장 유사한 샘플을 선택하여 학습 유연성을 향상시키는 선택적 메모리 리허설 메커니즘을 설계한다.

Result: SyReM은 11개의 자연 주행 데이터셋에서 비CL 및 CL 기준선에 비해 과거 시나리오에서의 재학습 문제를 효과적으로 완화하고, 새로운 시나리오에서 예측 정확도를 향상시킨다.

Conclusion: SyReM은 메모리 안정성과 학습 유연성을 동시에 개선하여 DNN 기반 모션 예측의 성능을 향상시키는 새로운 CL 방법임을 입증하였다.

Abstract: Deep neural networks (DNN) have achieved remarkable success in motion
forecasting. However, most DNN-based methods suffer from catastrophic
forgetting and fail to maintain their performance in previously learned
scenarios after adapting to new data. Recent continual learning (CL) studies
aim to mitigate this phenomenon by enhancing memory stability of DNN, i.e., the
ability to retain learned knowledge. Yet, excessive emphasis on the memory
stability often impairs learning plasticity, i.e., the capacity of DNN to
acquire new information effectively. To address such stability-plasticity
dilemma, this study proposes a novel CL method, synergetic memory rehearsal
(SyReM), for DNN-based motion forecasting. SyReM maintains a compact memory
buffer to represent learned knowledge. To ensure memory stability, it employs
an inequality constraint that limits increments in the average loss over the
memory buffer. Synergistically, a selective memory rehearsal mechanism is
designed to enhance learning plasticity by selecting samples from the memory
buffer that are most similar to recently observed data. This selection is based
on an online-measured cosine similarity of loss gradients, ensuring targeted
memory rehearsal. Since replayed samples originate from learned scenarios, this
memory rehearsal mechanism avoids compromising memory stability. We validate
SyReM under an online CL paradigm where training samples from diverse scenarios
arrive as a one-pass stream. Experiments on 11 naturalistic driving datasets
from INTERACTION demonstrate that, compared to non-CL and CL baselines, SyReM
significantly mitigates catastrophic forgetting in past scenarios while
improving forecasting accuracy in new ones. The implementation is publicly
available at https://github.com/BIT-Jack/SyReM.

</details>


### [39] [Delta-Audit: Explaining What Changes When Models Change](https://arxiv.org/abs/2508.19589)
*Arshia Hemmat,Afsaneh Fatemi*

Main category: cs.LG

TL;DR: 본 논문은 $	extbf{Delta-Attribution}$이라는 모델 불가지론적 프레임워크를 제안하며, 버전 A와 B 사이의 변화 원인을 설명한다.


<details>
  <summary>Details</summary>
Motivation: 모델 업데이트가 성능을 변화시킬 수 있지만 그 이유는 종종 불분명하다.

Method: 각 피쳐 속성의 차이를 이용하여 모델 간의 특징 변화를 정량화하는 방식으로, 여러 평가 기준을 통해 $	extDeltaold{	ext{Attribution}}$의 품질을 평가한다.

Result: 유도 편향 변화에서 큰 행동 일치 델타가 생성되며, 특정 수정이 근본적으로 미치는 영향은 매우 다르다는 것을 보여준다.

Conclusion: $	extDelta$-Attribution은 부정적 변화와 행동적 의미를 가진 변화를 구분함으로써 정확성을 보완하는 경량 업데이트 감사를 제공한다.

Abstract: Model updates (new hyperparameters, kernels, depths, solvers, or data) change
performance, but the \emph{reason} often remains opaque. We introduce
\textbf{Delta-Attribution} (\mbox{$\Delta$-Attribution}), a model-agnostic
framework that explains \emph{what changed} between versions $A$ and $B$ by
differencing per-feature attributions: $\Delta\phi(x)=\phi_B(x)-\phi_A(x)$. We
evaluate $\Delta\phi$ with a \emph{$\Delta$-Attribution Quality Suite} covering
magnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10,
Jensen--Shannon divergence), behavioural alignment (Delta Conservation Error,
DCE; Behaviour--Attribution Coupling, BAC; CO$\Delta$F), and robustness (noise,
baseline sensitivity, grouped occlusion).
  Instantiated via fast occlusion/clamping in standardized space with a
class-anchored margin and baseline averaging, we audit 45 settings: five
classical families (Logistic Regression, SVC, Random Forests, Gradient
Boosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B
pairs per family. \textbf{Findings.} Inductive-bias changes yield large,
behaviour-aligned deltas (e.g., SVC poly$\!\rightarrow$rbf on Breast Cancer:
BAC$\approx$0.998, DCE$\approx$6.6; Random Forest feature-rule swap on Digits:
BAC$\approx$0.997, DCE$\approx$7.5), while ``cosmetic'' tweaks (SVC
\texttt{gamma=scale} vs.\ \texttt{auto}, $k$NN search) show
rank-overlap@10$=1.0$ and DCE$\approx$0. The largest redistribution appears for
deeper GB on Breast Cancer (JSD$\approx$0.357). $\Delta$-Attribution offers a
lightweight update audit that complements accuracy by distinguishing benign
changes from behaviourally meaningful or risky reliance shifts.

</details>


### [40] [Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities](https://arxiv.org/abs/2508.19597)
*Zirui Li,Yunlong Lin,Guodong Du,Xiaocong Zhao,Cheng Gong,Chen Lv,Chao Lu,Jianwei Gong*

Main category: cs.LG

TL;DR: 본 논문에서는 DNN 기반 차량 운동 예측의 지속적 학습 문제를 해결하기 위한 Dual-LS라는 새로운 패러다임을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 스마트 시티 서비스는 인공지능에 의존하고 있으나, DNN은 모델 업데이트 시 이전 지식을 잃는 문제에 직면해 있다.

Method: Dual-LS는 인간 뇌의 상호 보완 학습 시스템에서 영감을 받아 DNN 기반의 지속적 학습을 위해 두 개의 시너지를 이루는 메모리 리허설 재생 메커니즘을 결합하였다.

Result: Dual-LS는 772,000대의 차량과 11,187km의 누적 시험 거리를 포함한 자연 데이터에서 최대 74.31%의 치명적 망각 완화 및 94.02%의 계산 자원 요구량 감소를 보였다.

Conclusion: 이 방식은 스마트 도시에 적합한 계산 효율성과 인간과 유사한 지속적 학습 적응성을 DNN 기반 차량 운동 예측에 부여한다.

Abstract: Artificial intelligence underpins most smart city services, yet deep neural
network (DNN) that forecasts vehicle motion still struggle with catastrophic
forgetting, the loss of earlier knowledge when models are updated. Conventional
fixes enlarge the training set or replay past data, but these strategies incur
high data collection costs, sample inefficiently and fail to balance long- and
short-term experience, leaving them short of human-like continual learning.
Here we introduce Dual-LS, a task-free, online continual learning paradigm for
DNN-based motion forecasting that is inspired by the complementary learning
system of the human brain. Dual-LS pairs two synergistic memory rehearsal
replay mechanisms to accelerate experience retrieval while dynamically
coordinating long-term and short-term knowledge representations. Tests on
naturalistic data spanning three countries, over 772,000 vehicles and
cumulative testing mileage of 11,187 km show that Dual-LS mitigates
catastrophic forgetting by up to 74.31\% and reduces computational resource
demand by up to 94.02\%, markedly boosting predictive stability in vehicle
motion forecasting without inflating data requirements. Meanwhile, it endows
DNN-based vehicle motion forecasting with computation efficient and human-like
continual learning adaptability fit for smart cities.

</details>


### [41] [Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning](https://arxiv.org/abs/2508.19598)
*Zhiwei Li,Yong Hu,Wenqing Wang*

Main category: cs.LG

TL;DR: 본 논문에서는 LLM 에이전트의 행동 계획 능력을 향상시키기 위한 새로운 프레임워크인 RLTR을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 성능은 행동 계획 및 답변 요약의 두 가지 능력에 의해 결정되며, 행동 계획이 핵심 능력이다. 그러나 기존의 훈련 방식은 이 두 가지 능력을 동시에 훈련하는데, 여기서 비대칭 최적화 목표 할당과 검증 가능한 데이터 부족이라는 두 가지 문제에 직면하고 있다.

Method: RLTR은 훈련 과정을 분리하여 계획 모듈의 단일 목표 최적화를 가능하게 하는 새로운 프레임워크로, 도구 사용의 완전성을 기반으로 한 보상 신호를 도입하여 도구 호출 시퀀스의 품질을 직접 평가한다.

Result: 실험 결과, RLTR은 엔드 투 엔드 기준선에 비해 8%-12%의 계획 성능 향상을 보여주었으며, 향상된 계획 능력은 전체 에이전트 시스템의 최종 응답 품질을 5%-6% 증가시켰다.

Conclusion: 이러한 결과는 RLTR이 검증 가능한 데이터 없이도 직접적이고 신뢰할 수 있는 훈련 신호를 제공하여 행동 계획 능력을 향상시키는 방법임을 보여준다.

Abstract: The functionality of Large Language Model (LLM) agents is primarily
determined by two capabilities: action planning and answer summarization. The
former, action planning, is the core capability that dictates an agent's
performance. However, prevailing training paradigms employ end-to-end,
multi-objective optimization that jointly trains both capabilities. This
paradigm faces two critical challenges: imbalanced optimization objective
allocation and scarcity of verifiable data, making it difficult to enhance the
agent's planning capability. To address these challenges, we propose
Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that
decouples the training process to enable a focused, single-objective
optimization of the planning module. Crucially, RLTR introduces a reward signal
based on tool-use completeness to directly evaluate the quality of tool
invocation sequences. This method offers a more direct and reliable training
signal than assessing the final response content, thereby obviating the need
for verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12%
improvement in planning performance compared to end-to-end baselines. Moreover,
this enhanced planning capability, in turn, translates to a 5%-6% increase in
the final response quality of the overall agent system.

</details>


### [42] [FinCast: A Foundation Model for Financial Time-Series Forecasting](https://arxiv.org/abs/2508.19609)
*Zhuohang Zhu,Haodong Chen,Qiang Qu,Vera Chung*

Main category: cs.LG

TL;DR: FinCast는 금융 시계열 예측을 위해 설계된 최초의 기초 모델로, 특정 도메인 조정 없이도 다양한 패턴을 캡처합니다.


<details>
  <summary>Details</summary>
Motivation: 경제 안정성을 유지하고 정보에 기반한 정책 결정을 유도하며 지속 가능한 투자 관행을 촉진하기 위해 금융 시계열 예측은 매우 중요합니다.

Method: FinCast는 대규모 금융 데이터셋에서 훈련된 금융 시계열 예측을 위한 최초의 기초 모델입니다.

Result: FinCast는 도메인 특정 조정 없이도 다양한 패턴을 효과적으로 캡처하여 강력한 제로샷 성능을 보여줍니다.

Conclusion: FinCast는 기존의 최첨단 방법을 초월하며 강력한 일반화 능력을 강조합니다.

Abstract: Financial time-series forecasting is critical for maintaining economic
stability, guiding informed policymaking, and promoting sustainable investment
practices. However, it remains challenging due to various underlying pattern
shifts. These shifts arise primarily from three sources: temporal
non-stationarity (distribution changes over time), multi-domain diversity
(distinct patterns across financial domains such as stocks, commodities, and
futures), and varying temporal resolutions (patterns differing across
per-second, hourly, daily, or weekly indicators). While recent deep learning
methods attempt to address these complexities, they frequently suffer from
overfitting and typically require extensive domain-specific fine-tuning. To
overcome these limitations, we introduce FinCast, the first foundation model
specifically designed for financial time-series forecasting, trained on
large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot
performance, effectively capturing diverse patterns without domain-specific
fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate
that FinCast surpasses existing state-of-the-art methods, highlighting its
strong generalization capabilities.

</details>


### [43] [ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation](https://arxiv.org/abs/2508.19613)
*Chenzhi Liu,Mahsa Baktashmotlagh,Yanran Tang,Zi Huang,Ruihong Qiu*

Main category: cs.LG

TL;DR: ALSA는 로그잇 공간에서 작동하여 모델 성능을 정확하게 추정하는 새로운 프레임워크로, 다양한 배포 변화에 대해 강력하고 정확한 성능 추정치를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 회귀 분포의 변화가 성능 저하를 초래할 수 있는 실제 머신러닝 애플리케이션에서 보이지 않거나 레이블이 없는 데이터셋에 대한 모델 정확도 추정은 매우 중요합니다.

Method: ALSA는 로그잇 공간에서 직접 작동하여 더 풍부한 정보를 보존하며 여러 개의 학습 가능한 앵커를 초기화하고 각 앵커에 로그잇의 미세한 변화를 포착하는 영향 함수가 할당되는 앵커 기반 모델링 전략을 사용합니다.

Result: ALSA는 비전, 언어 및 그래프 벤치마크에 대한 광범위한 실험 결과를 바탕으로 소프트맥스 및 유사성 기반 기준선 대비 우수한 성능을 나타냅니다.

Conclusion: ALSA의 주요 배포 변화에 대한 강건성은 신뢰할 수 있는 모델 평가를 위한 실용 도구로서의 잠재력을 강조합니다.

Abstract: Estimating model accuracy on unseen, unlabeled datasets is crucial for
real-world machine learning applications, especially under distribution shifts
that can degrade performance. Existing methods often rely on predicted class
probabilities (softmax scores) or data similarity metrics. While softmax-based
approaches benefit from representing predictions on the standard simplex,
compressing logits into probabilities leads to information loss. Meanwhile,
similarity-based methods can be computationally expensive and domain-specific,
limiting their broader applicability. In this paper, we introduce ALSA (Anchors
in Logit Space for Accuracy estimation), a novel framework that preserves
richer information by operating directly in the logit space. Building on
theoretical insights and empirical observations, we demonstrate that the
aggregation and distribution of logits exhibit a strong correlation with the
predictive performance of the model. To exploit this property, ALSA employs an
anchor-based modeling strategy: multiple learnable anchors are initialized in
logit space, each assigned an influence function that captures subtle
variations in the logits. This allows ALSA to provide robust and accurate
performance estimates across a wide range of distribution shifts. Extensive
experiments on vision, language, and graph benchmarks demonstrate ALSA's
superiority over both softmax- and similarity-based baselines. Notably, ALSA's
robustness under significant distribution shifts highlights its potential as a
practical tool for reliable model evaluation.

</details>


### [44] [Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning](https://arxiv.org/abs/2508.19621)
*Tiandi Ye,Wenyan Liu,Kai Yao,Lichun Li,Shangchao Su,Cen Chen,Xiang Li,Shan Yin,Ming Gao*

Main category: cs.LG

TL;DR: 개인화된 연합 학습(pFL)을 위한 새로운 프레임워크인 pFedBayesPT가 제안되며, 이는 시각적 프롬프트 조정에 기반한 정교한 인스턴스 수준의 pFL을 실현한다.


<details>
  <summary>Details</summary>
Motivation: 개인화된 연합 학습이 데이터 이질성을 해결하는 능력으로 주목받고 있으나, 기존 방법들은 클라이언트의 데이터가 단일 분포를 따른다고 가정하고 이는 실제로는 자주 실패한다는 점에서 동기가 발생하였다.

Method: Bayesian 관점에서 인스턴스 수준의 프롬프트 생성을 공식화하고, 프롬프트 사후 확률을 암묵적 분포로 모델링한다. 또한 반암묵적 변분 추론 프레임워크 하에 변분 훈련 목표를 도출한다.

Result: pFedBayesPT는 기준 데이터 세트에서 기존 pFL 방법들보다 일관되게 우수한 성능을 발휘한다.

Conclusion: pFedBayesPT는 다양한 시각적 의미를 포착하고 다양한 이질성을 처리하는 능력이 뛰어난 새로운 프레임워크이다.

Abstract: Federated learning (FL) is a privacy-preserving machine learning paradigm
that enables collaborative model training across multiple distributed clients
without disclosing their raw data. Personalized federated learning (pFL) has
gained increasing attention for its ability to address data heterogeneity.
However, most existing pFL methods assume that each client's data follows a
single distribution and learn one client-level personalized model for each
client. This assumption often fails in practice, where a single client may
possess data from multiple sources or domains, resulting in significant
intra-client heterogeneity and suboptimal performance. To tackle this
challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework
based on visual prompt tuning. Specifically, we formulate instance-wise prompt
generation from a Bayesian perspective and model the prompt posterior as an
implicit distribution to capture diverse visual semantics. We derive a
variational training objective under the semi-implicit variational inference
framework. Extensive experiments on benchmark datasets demonstrate that
pFedBayesPT consistently outperforms existing pFL methods under both feature
and label heterogeneity settings.

</details>


### [45] [SCAR: A Characterization Scheme for Multi-Modal Dataset](https://arxiv.org/abs/2508.19659)
*Ri Su,Zhao Chen,Caleb Chen Cao,Nan Tang,Lei Chen*

Main category: cs.LG

TL;DR: SCAR는 데이터셋의 구조적 특성을 네 가지 핵심 측정 기준으로 특징짓는 방법론을 제시하여, 훈련 데이터의 일반화 행동을 이해하고 효율적으로 확장할 수 있게 한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 데이터 중심 방법들이 데이터 품질의 구조적 측면을 간과하며 발전의 제약이 되고 있음.

Method: SCAR는 데이터셋의 내재적 구조적 특성을 Scale, Coverage, Authenticity, Richness라는 네 가지 측정 기준으로 특징짓는 원칙적인 방법론이다.

Result: 실험 결과, SCAR는 다양한 다중 모달 데이터셋과 모델 아키텍처에서 데이터 효용을 예측하고 데이터 수집을 안내하는 데 효과적임이 입증되었다.

Conclusion: SCAR는 데이터 이해의 튼튼하고 일반적인 기초를 제공하며, 다중 모달 데이터셋에서 효율적인 특성 확장을 가능하게 한다.

Abstract: Foundation models exhibit remarkable generalization across diverse tasks,
largely driven by the characteristics of their training data. Recent
data-centric methods like pruning and compression aim to optimize training but
offer limited theoretical insight into how data properties affect
generalization, especially the data characteristics in sample scaling.
Traditional perspectives further constrain progress by focusing predominantly
on data quantity and training efficiency, often overlooking structural aspects
of data quality. In this study, we introduce SCAR, a principled scheme for
characterizing the intrinsic structural properties of datasets across four key
measures: Scale, Coverage, Authenticity, and Richness. Unlike prior
data-centric measures, SCAR captures stable characteristics that remain
invariant under dataset scaling, providing a robust and general foundation for
data understanding. Leveraging these structural properties, we introduce
Foundation Data-a minimal subset that preserves the generalization behavior of
the full dataset without requiring model-specific retraining. We model
single-modality tasks as step functions and estimate the distribution of the
foundation data size to capture step-wise generalization bias across modalities
in the target multi-modal dataset. Finally, we develop a SCAR-guided data
completion strategy based on this generalization bias, which enables efficient,
modality-aware expansion of modality-specific characteristics in multimodal
datasets. Experiments across diverse multi-modal datasets and model
architectures validate the effectiveness of SCAR in predicting data utility and
guiding data acquisition. Code is available at https://github.com/McAloma/SCAR.

</details>


### [46] [Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables](https://arxiv.org/abs/2508.19661)
*Florentia Afentaki,Sri Sai Rakesh Nakkilla,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Shiyi Jiang,Georgios Zervakis,Farshad Firouzi,Krishnendu Chakrabarty,Mehdi B. Tahoori*

Main category: cs.LG

TL;DR: 본 논문은 저전력, 유연한 스트레스 분류기의 설계 공간을 탐색하며, 1200개 이상의 유연한 분류기를 포함한 다양한 기계 학습 분류기와 특성 선택, 신경 단순화 알고리즘을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 기존의 스트레스 모니터링 방법은 증상 중심의 간헐적 개입에 의존하고 있으며, 지속적이고 접근 가능하며 비용 효율적인 솔루션의 필요성을 간과하고 있다.

Method: 유연 전자제품(FE)을 사용하여 저전력의 유연한 스트레스 분류기를 위한 포괄적인 설계 공간 탐색을 진행하였다. 이를 통해 다양한 기계 학습 분류기, 특성 선택 및 신경 단순화 알고리즘을 다룬다.

Result: 1200개 이상의 유연한 분류기를 포함하여, 분석에 따라 맞춤형 회로 설계가 이루어졌다.

Conclusion: 이 연구는 비용 효율적이고, 순응성이 뛰어나며, 저전력 소모를 유지하면서 기존 방법보다 높은 정확도를 제공하는 실시간 스트레스 분류기 설계에 대한 통찰력을 제공한다.

Abstract: Conventional stress monitoring relies on episodic, symptom-focused
interventions, missing the need for continuous, accessible, and cost-efficient
solutions. State-of-the-art approaches use rigid, silicon-based wearables,
which, though capable of multitasking, are not optimized for lightweight,
flexible wear, limiting their practicality for continuous monitoring. In
contrast, flexible electronics (FE) offer flexibility and low manufacturing
costs, enabling real-time stress monitoring circuits. However, implementing
complex circuits like machine learning (ML) classifiers in FE is challenging
due to integration and power constraints. Previous research has explored
flexible biosensors and ADCs, but classifier design for stress detection
remains underexplored. This work presents the first comprehensive design space
exploration of low-power, flexible stress classifiers. We cover various ML
classifiers, feature selection, and neural simplification algorithms, with over
1200 flexible classifiers. To optimize hardware efficiency, fully customized
circuits with low-precision arithmetic are designed in each case. Our
exploration provides insights into designing real-time stress classifiers that
offer higher accuracy than current methods, while being low-cost, conformable,
and ensuring low power and compact size.

</details>


### [47] [$\mathcal{C}^1$-approximation with rational functions and rational neural networks](https://arxiv.org/abs/2508.19672)
*Erion Morina,Martin Holler*

Main category: cs.LG

TL;DR: 이 논문은 적절한 정규성을 갖춘 함수들이 유리 함수와 유리 신경망에 의해 근사될 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 물리 법칙 학습을 위한 상징 회귀의 맥락에서 중요한 EQL^div 및 ParFam 아키텍처에 대한 근사 결과를 제공하기 위해.

Method: 유리 함수와 유리 신경망을 이용하여 $	ext{C}^1$-노름으로 적절히 정규화된 함수들을 근사하는 방법을 제안한다.

Result: 네트워크의 너비와 깊이, 유리 함수의 차수에 대한 근사 속도를 포함하여 결과를 얻는다.

Conclusion: 이 결과를 통해 EQL^div 및 ParFam 아키텍처를 위한 $	ext{C}^1$-근사 결과를 도출하였다.

Abstract: We show that suitably regular functions can be approximated in the
$\mathcal{C}^1$-norm both with rational functions and rational neural networks,
including approximation rates with respect to width and depth of the network,
and degree of the rational functions. As consequence of our results, we further
obtain $\mathcal{C}^1$-approximation results for rational neural networks with
the $\text{EQL}^\div$ and ParFam architecture, both of which are important in
particular in the context of symbolic regression for physical law learning.

</details>


### [48] [Metric spaces of walks and Lipschitz duality on graphs](https://arxiv.org/abs/2508.19709)
*R. Arnau,A. González Cortés,E. A. Sánchez Pérez,S. Sanjuan*

Main category: cs.LG

TL;DR: 그래프에서의 걷기의 메트릭 구조를 연구하며, 이를 위해 시퀀스를 처리할 가중 메트릭을 도입하고 걷기 간의 거리 정의를 가능하게 하는 여러 속성을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 그래프에서의 걷기에 대한 메트릭 구조를 이해하고, 걸음 간의 상대적 거리 측정을 위한 weaker forms를 분석하기 위해서이다.

Method: 상대 거리 측정을 위한 새로운 가중 메트릭을 도입하고, 다양한 가정 하에서 근접성을 위한 표현 공식을 제공하며, 명시적 구성을 제시한다.

Result: 분석된 메트릭 공간의 주요 속성은 걷기 간의 거리 측정 도구 개발의 기초가 된다.

Conclusion: 이 연구는 네트워크 구조에서 Lipschitz 회귀를 위한 탐색적 걷기에 기초한 강화 학습 전략의 개발을 포함한 잠재적 응용을 제시한다.

Abstract: We study the metric structure of walks on graphs, understood as Lipschitz
sequences. To this end, a weighted metric is introduced to handle sequences,
enabling the definition of distances between walks based on stepwise vertex
distances and weighted norms. We analyze the main properties of these metric
spaces, which provides the foundation for the analysis of weaker forms of
instruments to measure relative distances between walks: proximities. We
provide some representation formulas for such proximities under different
assumptions and provide explicit constructions for these cases. The resulting
metric framework allows the use of classical tools from metric modeling, such
as the extension of Lipschitz functions from subspaces of walks, which permits
extending proximity functions while preserving fundamental properties via the
mentioned representations. Potential applications include the estimation of
proximities and the development of reinforcement learning strategies based on
exploratory walks, offering a robust approach to Lipschitz regression on
network structures.

</details>


### [49] [Tune My Adam, Please!](https://arxiv.org/abs/2508.19733)
*Theodoros Athanasiadis,Steven Adriaensen,Samuel Müller,Frank Hutter*

Main category: cs.LG

TL;DR: 본 논문에서는 Adam 옵티마이저의 하이퍼파라미터 튜닝을 위한 새로운 대리 모델인 Adam-PFN을 제안하며, 이는 TaskSet의 학습 곡선에서 사전 훈련되었습니다.


<details>
  <summary>Details</summary>
Motivation: Adam 옵티마이저는 딥 러닝에서 널리 사용되지만, 하이퍼파라미터 튜닝은 번거롭고 비용이 많이 듭니다.

Method: Freeze-thaw 베이지안 최적화(Bayesian Optimization)와 TaskSet으로부터 학습 곡선에 대해 사전 훈련된 새로운 대리 모델 Adam-PFN, 그리고 학습 곡선 증강 방식인 CDF-augment를 제안합니다.

Result: 우리의 접근 방식은 학습 곡선 외삽을 개선하고 TaskSet 평가 작업에서 하이퍼파라미터 최적화를 가속화합니다.

Conclusion: 특히 분포 밖(OOD) 작업에서 강력한 성능을 보였습니다.

Abstract: The Adam optimizer remains one of the most widely used optimizers in deep
learning, and effectively tuning its hyperparameters is key to optimizing
performance. However, tuning can be tedious and costly. Freeze-thaw Bayesian
Optimization (BO) is a recent promising approach for low-budget hyperparameter
tuning, but is limited by generic surrogates without prior knowledge of how
hyperparameters affect learning. We propose Adam-PFN, a new surrogate model for
Freeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from
TaskSet, together with a new learning curve augmentation method, CDF-augment,
which artificially increases the number of available training examples. Our
approach improves both learning curve extrapolation and accelerates
hyperparameter optimization on TaskSet evaluation tasks, with strong
performance on out-of-distribution (OOD) tasks.

</details>


### [50] [InfraredGP: Efficient Graph Partitioning via Spectral Graph Neural Networks with Negative Corrections](https://arxiv.org/abs/2508.19737)
*Meng Qin,Weihua Li,Jinqiang Cui,Sen Pei*

Main category: cs.LG

TL;DR: InfraredGP는 그래프의 저주파 정보를 활용하여 커뮤니티 구조에 대한 유용한 속성을 부각하는 새로운 그래프 파티셔닝 기법으로, 기존 방식보다 빠르고 효과적인 결과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 저주파 정보가 커뮤니티 구조에 대한 더 많은 정보를 인코딩할 수 있는지 탐구하기 위해 Graf Laplacian의 부정적인 교정을 적용하였다.

Method: InfraredGP는 스펙트럼 GNN을 기반으로 저주파 필터와 부정 교정 메커니즘을 결합하고, 무작위 입력만 사용하여 오직 한 번의 피드포워드 전파만으로 그래프 임베딩을 도출하며, BIRCH에 임베딩을 입력하여 결과를 얻는다.

Result: InfraredGP는 BIRCH와 같은 표준 클러스터링 모듈을 위한 구별 가능한 임베딩을 도출하고 훈련 없이 높은 품질의 그래프 파티셔닝 결과를 얻었다.

Conclusion: InfraredGP는 정적 및 스트리밍 그래프 파티셔닝 모두에서 기존 기준과 비교하여 훨씬 더 나은 효율성과 경쟁력 있는 품질을 달성하였다.

Abstract: Graph partitioning (GP), a.k.a. community detection, is a classic problem
that divides nodes of a graph into densely-connected blocks. From a perspective
of graph signal processing, we find that graph Laplacian with a negative
correction can derive graph frequencies beyond the conventional range $[0, 2]$.
To explore whether the low-frequency information beyond this range can encode
more informative properties about community structures, we propose InfraredGP.
It (\romannumeral1) adopts a spectral GNN as its backbone combined with
low-pass filters and a negative correction mechanism, (\romannumeral2) only
feeds random inputs to this backbone, (\romannumeral3) derives graph embeddings
via one feed-forward propagation (FFP) without any training, and
(\romannumeral4) obtains feasible GP results by feeding the derived embeddings
to BIRCH. Surprisingly, our experiments demonstrate that based solely on the
negative correction mechanism that amplifies low-frequency information beyond
$[0, 2]$, InfraredGP can derive distinguishable embeddings for some standard
clustering modules (e.g., BIRCH) and obtain high-quality results for GP without
any training. Following the IEEE HPEC Graph Challenge benchmark, we evaluate
InfraredGP for both static and streaming GP, where InfraredGP can achieve much
better efficiency (e.g., 16x-23x faster) and competitive quality over various
baselines. We have made our code public at
https://github.com/KuroginQin/InfraredGP

</details>


### [51] [Fast 3D Diffusion for Scalable Granular Media Synthesis](https://arxiv.org/abs/2508.19752)
*Muhammad Moeeze Hassan,Régis Cottereau,Filippo Gatti,Patryk Dec*

Main category: cs.LG

TL;DR: 이 논문은 3D 확산 모델을 기반으로 한 새로운 생성 파이프라인을 통해 입자 매체의 시뮬레이션 초기화 단계를 가속화한다.


<details>
  <summary>Details</summary>
Motivation: 입자 매체의 시뮬레이션은 계산 집약적이며, 특히 초기화 단계에서 전체 시뮬레이션 시간의 대부분을 차지한다.

Method: 본 연구에서는 3D 생성 모델링 작업으로 문제를 구 framing하고, 두 단계의 파이프라인을 사용한다. 첫 번째 단계는 독립적인 3D 복셀 그리드를 생성하기 위해 확산 모델을 훈련시키고, 두 번째 단계는 2D 인페인팅 기술을 응용하여 이 복셀 그리드를 원활하게 결합하기 위한 3D 인페인팅 모델이다.

Result: 모델은 1.2m 길이의 레일 트랙을 20초 이내에 생성할 수 있으며, 이는 3시간의 DEM 시뮬레이션과 동등하다.

Conclusion: 이 방법은 산업 응용을 위한 물리적으로 일관된, 실시간, 확장 가능한 입자 매체 합성을 가능하게 한다.

Abstract: Simulating granular media, using Discrete Element Method is a computationally
intensive task. This is especially true during initialization phase, which
dominates total simulation time because of large displacements involved and
associated kinetic energy. We overcome this bottleneck with a novel generative
pipeline based on 3D diffusion models that directly synthesizes arbitrarily
large granular assemblies in their final and physically realistic
configurations. The approach frames the problem as a 3D generative modeling
task, consisting of a two-stage pipeline. First a diffusion model is trained to
generate independent 3D voxel grids representing granular media. Second, a 3D
inpainting model, adapted from 2D inpainting techniques using masked inputs,
stitches these grids together seamlessly, enabling synthesis of large samples
with physically realistic structure. The inpainting model explores several
masking strategies for the inputs to the underlying UNets by training the
network to infer missing portions of voxel grids from a concatenation of noised
tensors, masks, and masked tensors as input channels. The model also adapts a
2D repainting technique of re-injecting noise scheduler output with ground
truth to provide a strong guidance to the 3D model. This along with weighted
losses ensures long-term coherence over generation of masked regions. Both
models are trained on the same binarized 3D occupancy grids extracted from
small-scale DEM simulations, achieving linear scaling of computational time
with respect to sample size. Quantitatively, a 1.2 m long ballasted rail track
synthesis equivalent to a 3-hour DEM simulation, was completed under 20
seconds. The generated voxel grids can also be post-processed to extract grain
geometries for DEM-compatibility as well, enabling physically coherent,
real-time, scalable granular media synthesis for industrial applications.

</details>


### [52] [Interestingness First Classifiers](https://arxiv.org/abs/2508.19780)
*Ryoma Sato*

Main category: cs.LG

TL;DR: 본 논문에서는 예측 정확성을 극대화하는 대신 흥미로운 분류기를 구축하는 것을 목표로 합니다. EUREKA라는 프레임워크를 소개하며, 이는 비예상적 특성을 사용하여 해석 가능한 분류기를 생성합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 기계 학습 모델은 예측 정확성을 극대화하는 것으로 설계되었습니다. 그러나 이 논문에서는 흥미로운 분류기를 구축하는 대안을 탐구합니다.

Method: EUREKA는 인식된 흥미도에 따라 특성을 선택하도록 설계된 간단한 프레임워크입니다. 대규모 언어 모델을 활용하여 특성을 흥미도에 따라 순위를 매기고, 선택된 흥미로운 특성만을 사용하여 해석 가능한 분류기를 구축합니다.

Result: 여러 벤치마크 데이터셋에서 EUREKA는 비명백하지만 여전히 예측 가능한 특성을 지속적으로 식별합니다. 예를 들어, Occupancy Detection 데이터셋에서 이 방법은 CO2 농도와 빛의 강도보다 습도를 선호하여 의미 있는 정확성을 제공하는 분류기를 생성합니다.

Conclusion: 이러한 모델은 지식 발견과 커뮤니케이션의 새로운 방법을 지원할 수 있으며, 중간 정도의 정확성이 충분하면서 참신성과 해석 가능성이 중요한 환경에서 특히 유용합니다.

Abstract: Most machine learning models are designed to maximize predictive accuracy. In
this work, we explore a different goal: building classifiers that are
interesting. An ``interesting classifier'' is one that uses unusual or
unexpected features, even if its accuracy is lower than the best possible
model. For example, predicting room congestion from CO2 levels achieves
near-perfect accuracy but is unsurprising. In contrast, predicting room
congestion from humidity is less accurate yet more nuanced and intriguing. We
introduce EUREKA, a simple framework that selects features according to their
perceived interestingness. Our method leverages large language models to rank
features by their interestingness and then builds interpretable classifiers
using only the selected interesting features. Across several benchmark
datasets, EUREKA consistently identifies features that are non-obvious yet
still predictive. For example, in the Occupancy Detection dataset, our method
favors humidity over CO2 levels and light intensity, producing classifiers that
achieve meaningful accuracy while offering insights. In the Twin Papers
dataset, our method discovers the rule that papers with a colon in the title
are more likely to be cited in the future. We argue that such models can
support new ways of knowledge discovery and communication, especially in
settings where moderate accuracy is sufficient but novelty and interpretability
are valued.

</details>


### [53] [PSO-Merging: Merging Models Based on Particle Swarm Optimization](https://arxiv.org/abs/2508.19839)
*Kehao Zhang,Shaolei Zhang,Yang Feng*

Main category: cs.LG

TL;DR: PSO-Merging은 여러 전문가 모델의 강점을 통합하여 멀티태스킹 모델을 구성하는 새로운 데이터 기반 병합 방법이다.


<details>
  <summary>Details</summary>
Motivation: 여러 전문가 모델의 강점을 통합하여 멀티태스킹 모델을 효율적으로 구축하고자 하며, 사전 학습된 모델을 모든 작업에 대해 처음부터 재조정할 필요를 줄인다.

Method: PSO(Particle Swarm Optimization)를 기반으로 한 데이터 기반 병합 방법인 PSO-Merging을 도입한다. 이 방법에서는 사전 학습된 모델, 전문가 모델 및 희소 전문가 모델로 입자 집단을 초기화한 후, 여러 반복을 수행하여 최종 최적 입자를 병합 모델로 사용한다.

Result: 다양한 언어 모델에 대한 실험 결과, PSO-Merging이 일반적으로 기본 병합 방법보다 우수한 성능을 보이며, 모델 병합에 있어 더 효율적이고 확장 가능한 솔루션을 제공한다.

Conclusion: PSO-Merging은 기존 데이터 비독립적인 방법의 한계를 극복하고, 데이터 기반의 접근 방식을 통해 성능을 향상시키는 데 기여한다.

Abstract: Model merging has emerged as an efficient strategy for constructing multitask
models by integrating the strengths of multiple available expert models,
thereby reducing the need to fine-tune a pre-trained model for all the tasks
from scratch. Existing data-independent methods struggle with performance
limitations due to the lack of data-driven guidance. Data-driven approaches
also face key challenges: gradient-based methods are computationally expensive,
limiting their practicality for merging large expert models, whereas existing
gradient-free methods often fail to achieve satisfactory results within a
limited number of optimization steps. To address these limitations, this paper
introduces PSO-Merging, a novel data-driven merging method based on the
Particle Swarm Optimization (PSO). In this approach, we initialize the particle
swarm with a pre-trained model, expert models, and sparsified expert models. We
then perform multiple iterations, with the final global best particle serving
as the merged model. Experimental results on different language models show
that PSO-Merging generally outperforms baseline merging methods, offering a
more efficient and scalable solution for model merging.

</details>


### [54] [Symplectic convolutional neural networks](https://arxiv.org/abs/2508.19842)
*Süleyman Yıldız,Konrad Janik,Peter Benner*

Main category: cs.LG

TL;DR: 본 논문에서는 심플렉틱 신경망과 적절한 심플렉틱 분해 및 텐서 기법을 활용하여 새로운 심플렉틱 합성곱 신경망(CNN) 아키텍처를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 심플렉틱 CNN 아키텍처를 통해 데이터의 물리적 특성을 보존하며 효율적인 CNN 설계를 목표로 합니다.

Method: 수학적으로 동등한 합성곱 층의 형태를 소개하고, 심플렉틱 신경망을 사용하여 CNN의 층을 매개변수화하는 방법을 제시합니다.

Result: 제안된 신경망은 파동 방정식, 비선형 슈뢰딩거(NLS) 방정식, 사인-고든 방정식 세 가지 예제에서 성능을 입증합니다.

Conclusion: 심플렉틱 CNN은 적절한 심플렉틱 분해를 통해 얻은 선형 심플렉틱 오토인코더보다 우수한 성능을 보입니다.

Abstract: We propose a new symplectic convolutional neural network (CNN) architecture
by leveraging symplectic neural networks, proper symplectic decomposition, and
tensor techniques. Specifically, we first introduce a mathematically equivalent
form of the convolution layer and then, using symplectic neural networks, we
demonstrate a way to parameterize the layers of the CNN to ensure that the
convolution layer remains symplectic. To construct a complete autoencoder, we
introduce a symplectic pooling layer. We demonstrate the performance of the
proposed neural network on three examples: the wave equation, the nonlinear
Schr\"odinger (NLS) equation, and the sine-Gordon equation. The numerical
results indicate that the symplectic CNN outperforms the linear symplectic
autoencoder obtained via proper symplectic decomposition.

</details>


### [55] [Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources](https://arxiv.org/abs/2508.19847)
*Erdi Kara,Panos Stinis*

Main category: cs.LG

TL;DR: 본 연구에서는 FEM과 물리 정보 기반 DeepONet을 결합한 하이브리드 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 유체 전달 문제를 해결하기 위한 정확하고 빠른 방법이 필요합니다.

Method: 유한 요소 방법(FEM)으로 다르시 흐름 방정식을 해결하고, 물리 정보 기반 DeepONet을 사용하여 원천 함수와 용질 농도 프로파일 간의 매핑을 학습합니다.

Result: 수치 실험을 통해 제안된 방법이 전통적인 해법에 비해 몇 배 속도의 향상을 보이며, 실제 응용에 적합함을 입증하였습니다.

Conclusion: 본 하이브리드 접근법은 유체 역학 문제에 대해 높은 정확도와 빠른 추론을 동시에 제공합니다.

Abstract: We present a hybrid framework that couples finite element methods (FEM) with
physics-informed DeepONet to model fluid transport in porous media from sharp,
localized Gaussian sources. The governing system consists of a steady-state
Darcy flow equation and a time-dependent convection-diffusion equation. Our
approach solves the Darcy system using FEM and transfers the resulting velocity
field to a physics-informed DeepONet, which learns the mapping from source
functions to solute concentration profiles. This modular strategy preserves
FEM-level accuracy in the flow field while enabling fast inference for
transport dynamics. To handle steep gradients induced by sharp sources, we
introduce an adaptive sampling strategy for trunk collocation points. Numerical
experiments demonstrate that our method is in good agreement with the reference
solutions while offering orders of magnitude speedups over traditional solvers,
making it suitable for practical applications in relevant scenarios.
Implementation of our proposed method is available at
https://github.com/erkara/fem-pi-deeponet.

</details>


### [56] [Quantum latent distributions in deep generative models](https://arxiv.org/abs/2508.19857)
*Omar Bacarreza,Thorin Farnsworth,Alexander Makarovskiy,Hugo Wallner,Tessa Hicks,Santiago Sempere-Llagostera,John Price,Robert J. A. Francis-Jones,William R. Clements*

Main category: cs.LG

TL;DR: 이 연구는 양자 처리기가 생성한 잠재 분포가 생성적 모델의 성능을 향상시킬 수 있는지를 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 양자 처리기가 생성한 더 정교한 잠재 분포가 생성적 모델의 성능을 향상시킬 수 있는지 확인하기 위해.

Method: 합성 쿼텀 데이터 세트와 QM9 분자 데이터 세트에 대한 벤치마킹 실험을 수행하고, 시뮬레이션 및 실제 광자 양자 프로세서를 사용합니다.

Result: 양자 잠재 분포가 GAN의 생성 성능을 여러 고전적인 기준보다 개선할 수 있음을 보여줍니다.

Conclusion: 근거리 양자 프로세서가 심층 생성 모델의 능력을 확장할 수 있음을 확인합니다.

Abstract: Many successful families of generative models leverage a low-dimensional
latent distribution that is mapped to a data distribution. Though simple latent
distributions are commonly used, it has been shown that more sophisticated
distributions can improve performance. For instance, recent work has explored
using the distributions produced by quantum processors and found empirical
improvements. However, when latent space distributions produced by quantum
processors can be expected to improve performance, and whether these
improvements are reproducible, are open questions that we investigate in this
work. We prove that, under certain conditions, these "quantum latent
distributions" enable generative models to produce data distributions that
classical latent distributions cannot efficiently produce. We also provide
actionable intuitions to identify when such quantum advantages may arise in
real-world settings. We perform benchmarking experiments on both a synthetic
quantum dataset and the QM9 molecular dataset, using both simulated and real
photonic quantum processors. Our results demonstrate that quantum latent
distributions can lead to improved generative performance in GANs compared to a
range of classical baselines. We also explore diffusion and flow matching
models, identifying architectures compatible with quantum latent distributions.
This work confirms that near-term quantum processors can expand the
capabilities of deep generative models.

</details>


### [57] [Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks](https://arxiv.org/abs/2508.19884)
*Mingyue Kong,Yinglong Zhang,Chengda Xu,Xuewen Xia,Xing Xu*

Main category: cs.LG

TL;DR: 본 논문은 구조적 다양성을 기반으로 한 파라미터 없는 그래프 신경망 프레임워크인 SDGNN을 제안하며, 이는 노드 표현의 과도한 매끄러움과 의미 감소 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 그래프 신경망은 고정된 집계 규칙과 많은 학습 가능한 파라미터에 의존하여 구조적 이질성이 강한 그래프 데이터에 적응하기 어렵다.

Method: SDGNN은 구조적 다양성 이론에 영감을 받아, 추가적인 학습 가능한 파라미터 없이 이웃 구조의 이질성과 특징 의미의 안정성을 동시에 캡처하는 통합 구조-다양성 메시지 전송 메커니즘을 설계한다.

Result: 여덟 개의 공개 벤치마크 데이터셋과 다학제적 PubMed 인용 네트워크에서 SDGNN은 낮은 감독, 클래스 불균형, 교차 도메인 전이와 같은 어려운 조건에서도 기존의 GNN보다 일관되게 우수한 성능을 보인다.

Conclusion: 이 연구는 파라미터 없는 그래프 신경망 설계에 대한 새로운 이론적 관점과 일반적인 접근 방식을 제공하며, 그래프 표현 학습에서 구조적 다양성의 핵심 신호로서의 중요성을 추가적으로 입증한다.

Abstract: Graph Neural Networks (GNNs) have shown remarkable performance in structured
data modeling tasks such as node classification. However, mainstream approaches
generally rely on a large number of trainable parameters and fixed aggregation
rules, making it difficult to adapt to graph data with strong structural
heterogeneity and complex feature distributions. This often leads to
over-smoothing of node representations and semantic degradation. To address
these issues, this paper proposes a parameter-free graph neural network
framework based on structural diversity, namely SDGNN (Structural-Diversity
Graph Neural Network). The framework is inspired by structural diversity theory
and designs a unified structural-diversity message passing mechanism that
simultaneously captures the heterogeneity of neighborhood structures and the
stability of feature semantics, without introducing additional trainable
parameters. Unlike traditional parameterized methods, SDGNN does not rely on
complex model training, but instead leverages complementary modeling from both
structure-driven and feature-driven perspectives, thereby effectively improving
adaptability across datasets and scenarios. Experimental results show that on
eight public benchmark datasets and an interdisciplinary PubMed citation
network, SDGNN consistently outperforms mainstream GNNs under challenging
conditions such as low supervision, class imbalance, and cross-domain transfer.
This work provides a new theoretical perspective and general approach for the
design of parameter-free graph neural networks, and further validates the
importance of structural diversity as a core signal in graph representation
learning. To facilitate reproducibility and further research, the full
implementation of SDGNN has been released at:
https://github.com/mingyue15694/SGDNN/tree/main

</details>


### [58] [NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs](https://arxiv.org/abs/2508.19896)
*Davorin Miličević,Ratko Grbić*

Main category: cs.LG

TL;DR: NM-Hebb는 네트워크의 해석 가능성을 향상시키기 위해 생물학적 메커니즘을 통합한 두 단계 훈련 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 딥 CNN은 높은 정확도를 달성하지만 과적합 및 해석 가능성 저하와 같은 문제에 직면하고 있습니다.

Method: NM-Hebb는 생물학적으로 영감을 받은 메커니즘을 활용하여 교차 엔트로피 목적을 최적화하고, 가변 가중치 스타일의 집합 손실을 통합하는 두 단계 훈련을 수행합니다.

Result: NM-Hebb는 CIFAR-10, CIFAR-100 및 TinyImageNet에서 기존 방법보다 일관된 성능 향상을 보여 주었습니다.

Conclusion: 지역적 힙 반응성을 메트릭 기반의 미세 조정과 결합한 결과, CNN이 더 정확하고 해석 가능한 결과를 보였습니다.

Abstract: Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often
rely on purely global, gradient-based optimisation, which can lead to
overfitting, redundant filters, and reduced interpretability. To address these
limitations, we propose NM-Hebb, a two-phase training framework that integrates
neuro-inspired local plasticity with distance-aware supervision. Phase 1
extends standard supervised training by jointly optimising a cross-entropy
objective with two biologically inspired mechanisms: (i) a Hebbian regulariser
that aligns the spatial mean of activations with the mean of the corresponding
convolutional filter weights, encouraging structured, reusable primitives; and
(ii) a learnable neuromodulator that gates an elastic-weight-style
consolidation loss, preserving beneficial parameters without freezing the
network. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss,
explicitly compressing intra-class distances and enlarging inter-class margins
in the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet
across five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2,
DenseNet-121), NM-Hebb achieves consistent gains over baseline and other
methods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp
(CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual
Information (NMI) increased by up to +0.15. Qualitative visualisations and
filter-level analyses further confirm that NM-Hebb produces more structured and
selective features, yielding tighter and more interpretable class clusters.
Overall, coupling local Hebbian plasticity with metric-based fine-tuning yields
CNNs that are not only more accurate but also more interpretable, offering
practical benefits for resource-constrained and safety-critical AI deployments.

</details>


### [59] [Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning](https://arxiv.org/abs/2508.19900)
*Tan Jing,Xiaorui Li,Chao Yao,Xiaojuan Ban,Yuetong Fang,Renjing Xu,Zhaolin Yuan*

Main category: cs.LG

TL;DR: 적응형 정책 제약 스케일링(ASPC)을 통해 오프라인 강화 학습에서 데이터셋 간에 필요한 조정 없이 성능을 향상시킬 수 있는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 오프라인 강화 학습 방법은 데이터셋의 품질이 다를 때마다 하이퍼파라미터를 조정해야 하므로 비효율적이다.

Method: ASPC는 훈련 중에 RL과 행동 복제(BC)의 균형을 동적으로 조절하는 2차 미분 가능 프레임워크이다.

Result: 39개 데이터셋에서 ASPC는 단일 하이퍼파라미터 구성만으로도 다른 적응형 제약 방법 및 최첨단 오프라인 RL 알고리즘보다 우수한 성능을 보였다.

Conclusion: ASPC는 오프라인 RL 훈련에서 최소한의 계산 오버헤드로 효과적인 정책 학습을 가능하게 한다.

Abstract: Offline reinforcement learning (RL) enables learning effective policies from
fixed datasets without any environment interaction. Existing methods typically
employ policy constraints to mitigate the distribution shift encountered during
offline RL training. However, because the scale of the constraints varies
across tasks and datasets of differing quality, existing methods must
meticulously tune hyperparameters to match each dataset, which is
time-consuming and often impractical. We propose Adaptive Scaling of Policy
Constraints (ASPC), a second-order differentiable framework that dynamically
balances RL and behavior cloning (BC) during training. We theoretically analyze
its performance improvement guarantee. In experiments on 39 datasets across
four D4RL domains, ASPC using a single hyperparameter configuration outperforms
other adaptive constraint methods and state-of-the-art offline RL algorithms
that require per-dataset tuning while incurring only minimal computational
overhead. The code will be released at https://github.com/Colin-Jing/ASPC.

</details>


### [60] [Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation](https://arxiv.org/abs/2508.19999)
*Ziniu Zhang,Zhenshuo Zhang,Dongyue Li,Lu Wang,Jennifer Dy,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 이 논문에서는 질의 집합의 맥락 학습을 위한 시연 예제 선택 알고리즘을 소개한다. 주어진 n개의 예제에서 k개를 신속하게 선택하여 다운스트림 추론에 가장 적합하게 조건화할 수 있는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 질의 집합을 위한 맥락 학습에서 시연 예제를 선택하는 문제는 프롬프트 튜닝과 사고의 연쇄 추론에 널리 응용될 수 있는 문제이다.

Method: 이 연구에서는 입력 임베딩 공간에서의 출력을 기반으로 기울기를 사용한 새로운 접근 방식을 제안한다. 이 방법은 모델 출력을 기울기를 사용하여 1차 근사를 통해 추정하는 것이다.

Result: 우리의 접근 방식은 여러 임의 샘플링된 하위 집합에 대해 추정된 값을 적용하고, 샘플링된 하위 집합의 결과를 집계하여 각 시연에 대한 영향 점수를 형성하고 가장 관련성이 높은 k개 예제를 선택한다.

Conclusion: 우리는 이 절차가 모델 출력과 기울기를 한 번만 사전 계산하면 되고, 모델과 훈련 세트 크기에 따라 선형 시간 알고리즘을 생성한다는 것을 보여준다. 대규모 실험을 통해 우리의 접근 방식의 효율성을 검증하였다.

Abstract: This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.

</details>


### [61] [GegenNet: Spectral Convolutional Neural Networks for Link Sign Prediction in Signed Bipartite Graphs](https://arxiv.org/abs/2508.19907)
*Hewen Wang,Renchi Yang,Xiaokui Xiao*

Main category: cs.LG

TL;DR: 본 논문은 이분 그래프의 링크 기호 예측을 위한 새로운 모델인 GegenNet을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 링크 기호 예측의 기존 솔루션들이 주로 단일 파티션 서명 그래프에 집중하고 있으며, 이는 이분 그래프의 이질성과 고유한 특성을 무시하기 때문에 최적이 아니라는 문제점을 해결하기 위함입니다.

Method: GegenNet은 노드 특징 초기화를 위한 빠르고 이론적으로 기반을 둔 스펙트럼 분해 기술, Gegenbauer 다항식 기초에 기반한 새로운 스펙트럼 그래프 필터, 그리고 긍정적 및 부정적 엣지와 교대로 Gegenbauer 다항식 필터를 사용하는 다층 기호 인식 스펙트럼 컨볼루션 네트워크를 사용합니다.

Result: GegenNet은 6개의 벤치마크 이분 그래프 데이터셋에서 11개의 강력한 경쟁자와 비교하여 링크 기호 예측에서 AUC에서 4.28% 및 F1에서 11.69%의 성능 향상을 달성했습니다.

Conclusion: GegenNet은 이분 그래프에 대한 링크 기호 예측을 위한 새로운 효과적인 모델로, 향상된 모델 용량과 높은 예측 정확도를 보여줍니다.

Abstract: Given a signed bipartite graph (SBG) G with two disjoint node sets U and V,
the goal of link sign prediction is to predict the signs of potential links
connecting U and V based on known positive and negative edges in G. The
majority of existing solutions towards link sign prediction mainly focus on
unipartite signed graphs, which are sub-optimal due to the neglect of node
heterogeneity and unique bipartite characteristics of SBGs. To this end, recent
studies adapt graph neural networks to SBGs by introducing message-passing
schemes for both inter-partition (UxV) and intra-partition (UxU or VxV) node
pairs. However, the fundamental spectral convolutional operators were
originally designed for positive links in unsigned graphs, and thus, are not
optimal for inferring missing positive or negative links from known ones in
SBGs.
  Motivated by this, this paper proposes GegenNet, a novel and effective
spectral convolutional neural network model for link sign prediction in SBGs.
In particular, GegenNet achieves enhanced model capacity and high predictive
accuracy through three main technical contributions: (i) fast and theoretically
grounded spectral decomposition techniques for node feature initialization;
(ii) a new spectral graph filter based on the Gegenbauer polynomial basis; and
(iii) multi-layer sign-aware spectral convolutional networks alternating
Gegenbauer polynomial filters with positive and negative edges. Our extensive
empirical studies reveal that GegenNet can achieve significantly superior
performance (up to a gain of 4.28% in AUC and 11.69% in F1) in link sign
prediction compared to 11 strong competitors over 6 benchmark SBG datasets.

</details>


### [62] [Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach](https://arxiv.org/abs/2508.20013)
*Lotte Gross,Rebecca Walter,Nicole Zoppi,Adrien Justus,Alessandro Gambetti,Qiwei Han,Maximilian Kaiser*

Main category: cs.LG

TL;DR: 이 연구는 전자상거래 제품 분류의 산업적 도전 과제를 해결하기 위해 다중 모드 계층 분류 프레임워크를 개발하고 배포하였다.


<details>
  <summary>Details</summary>
Motivation: 전자상거래 제품 분류에서 플랫폼의 이질성과 기존 분류체계의 구조적 한계를 해결하고자 함.

Method: 271,700개의 제품 데이터셋을 사용하여 텍스트 특성(RoBERTa), 시각적 특성(ViT), 그리고 비전-언어 표현(CLIP)을 통합한 다중 모드 계층 분류 프레임워크를 개발했다.

Result: MLP 기반의 지연 융합 전략으로 결합된 CLIP 임베딩이 최고 계층 F1(98.59\%)을 달성하였고, 이는 단일 모드 기준선을 초과하였다.

Conclusion: 최종적으로 EURWEB의 상업적 거래 지능 플랫폼에 프레임워크를 배포하여 산업적 확장성을 입증하였으며, 가벼운 RoBERTa 단계와 GPU 가속 다중 모드 단계의 두 단계 추론 파이프라인을 결합하여 비용과 정확성 간의 균형을 맞추었다.

Abstract: This study addresses critical industrial challenges in e-commerce product
categorization, namely platform heterogeneity and the structural limitations of
existing taxonomies, by developing and deploying a multimodal hierarchical
classification framework. Using a dataset of 271,700 products from 40
international fashion e-commerce platforms, we integrate textual features
(RoBERTa), visual features (ViT), and joint vision--language representations
(CLIP). We investigate fusion strategies, including early, late, and
attention-based fusion within a hierarchical architecture enhanced by dynamic
masking to ensure taxonomic consistency. Results show that CLIP embeddings
combined via an MLP-based late-fusion strategy achieve the highest hierarchical
F1 (98.59\%), outperforming unimodal baselines. To address shallow or
inconsistent categories, we further introduce a self-supervised ``product
recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which
discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with
cluster purities above 86\%. Cross-platform experiments reveal a
deployment-relevant trade-off: complex late-fusion methods maximize accuracy
with diverse training data, while simpler early-fusion methods generalize more
effectively to unseen platforms. Finally, we demonstrate the framework's
industrial scalability through deployment in EURWEB's commercial transaction
intelligence platform via a two-stage inference pipeline, combining a
lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance
cost and accuracy.

</details>


### [63] [Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling](https://arxiv.org/abs/2508.19915)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.LG

TL;DR: 의학 이미징 작업의 성능 향상을 위한 보고서 기반의 검색 보강 학습 방법을 제안하며, UMLS 개념을 활용한 새로운 접근법을 통해 의미론적으로 유의미한 유사성 비교를 가능하게 하고, 특히 희귀 질병 탐지에서 기존 방법을 능가함을 입증함.


<details>
  <summary>Details</summary>
Motivation: 희귀 질병 탐지와 같은 긴 꼬리 의학 이미징 작업에서 성능 향상을 추구하기 위해, 보고서 기반의 검색 보강 학습 방식을 제안하게 되었습니다.

Method: RadGraph-XL과 SapBERT를 기반으로한 향상된 파이프라인을 사용하여 자유 텍스트 보고서에서 표준화된 의학 개체를 추출하고, 수정된 Tversky Index를 기반으로하는 유사성 측정을 정의합니다.

Result: MIMIC-CXR에서 방사선 사진 분류 작업에 대해 기존의 임베딩 기반 검색 방법보다 우수한 성과를 보임을 보여주었으며, 특히 긴 꼬리 환경에서 좋은 결과를 나타냄을 입증함.

Conclusion: 더 설명 가능하고 신뢰할 수 있으며 작업의 특수성에 초점을 맞춘 검색 전략을 제공하고, 이는 임상 AI 시스템에서 해석 가능성과 도메인 지식 통합이 필수적일 때 유용하다.

Abstract: Retrieval-augmented learning based on radiology reports has emerged as a
promising direction to improve performance on long-tail medical imaging tasks,
such as rare disease detection in chest X-rays. Most existing methods rely on
comparing high-dimensional text embeddings from models like CLIP or CXR-BERT,
which are often difficult to interpret, computationally expensive, and not
well-aligned with the structured nature of medical knowledge. We propose a
novel, ontology-driven alternative for comparing radiology report texts based
on clinically grounded concepts from the Unified Medical Language System
(UMLS). Our method extracts standardised medical entities from free-text
reports using an enhanced pipeline built on RadGraph-XL and SapBERT. These
entities are linked to UMLS concepts (CUIs), enabling a transparent,
interpretable set-based representation of each report. We then define a
task-adaptive similarity measure based on a modified and weighted version of
the Tversky Index that accounts for synonymy, negation, and hierarchical
relationships between medical entities. This allows efficient and semantically
meaningful similarity comparisons between reports. We demonstrate that our
approach outperforms state-of-the-art embedding-based retrieval methods in a
radiograph classification task on MIMIC-CXR, particularly in long-tail
settings. Additionally, we use our pipeline to generate ontology-backed disease
labels for MIMIC-CXR, offering a valuable new resource for downstream learning
tasks. Our work provides more explainable, reliable, and task-specific
retrieval strategies in clinical AI systems, especially when interpretability
and domain knowledge integration are essential. Our code is available at
https://github.com/Felix-012/ontology-concept-distillation

</details>


### [64] [Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment](https://arxiv.org/abs/2508.20015)
*Julian Arnold,Niels Lörch*

Main category: cs.LG

TL;DR: 좁은 범위의 유해 데이터셋으로 LLM을 미세 조정하는 것은 인간 가치와 널리 불일치하는 행동으로 이어질 수 있다. 본 연구에서는 미세 조정 중에 발생하는 급격한 전환을 탐지하고 특성화하기 위한 종합적인 프레임워크를 개발한다.


<details>
  <summary>Details</summary>
Motivation: 좁은 범위의 유해 데이터셋으로 LLM을 미세 조정했을 때 인간 가치와 널리 불일치하는 행동이 발생할 수 있음을 이해하기 위해.

Method: 분포 변화 탐지 방법과 평이한 영어로 공식화된 순서 매개변수를 사용하여 미세 조정 중의 급격한 전환을 탐지하고 특성화하는 종합적인 프레임워크를 개발한다.

Result: 미세 조정 중에 발생하는 위상 전이가 모델의 여러 측면에 미치는 영향을 수량화했으며, 특정 측면이 전체 분포 변화에서 차지하는 비율을 평가하였다.

Conclusion: 실제 행동 전환은 그래디언트 노름의 피크에 의해 나타나는 것보다 훈련 후반에 발생한다. 우리의 프레임워크는 언어 기반 순서 매개변수를 자동으로 발견하고 수량화할 수 있게 한다.

Abstract: Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is
broadly misaligned with respect to human values. To understand when and how
this emergent misalignment occurs, we develop a comprehensive framework for
detecting and characterizing rapid transitions during fine-tuning using both
distributional change detection methods as well as order parameters that are
formulated in plain English and evaluated by an LLM judge. Using an objective
statistical dissimilarity measure, we quantify how the phase transition that
occurs during fine-tuning affects multiple aspects of the model. In particular,
we assess what percentage of the total distributional change in model outputs
is captured by different aspects, such as alignment or verbosity, providing a
decomposition of the overall transition. We also find that the actual
behavioral transition occurs later in training than indicated by the peak in
the gradient norm alone. Our framework enables the automated discovery and
quantification of language-based order parameters, which we demonstrate on
examples ranging from knowledge questions to politics and ethics.

</details>


### [65] [FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification](https://arxiv.org/abs/2508.19924)
*Liming Liu,Ruoyu Li,Qing Li,Meijia Hou,Yong Jiang,Mingwei Xu*

Main category: cs.LG

TL;DR: FlowletFormer는 네트워크 트래픽 분석을 위해 설계된 BERT 기반의 사전 훈련 모델로, 기존 방법들이 해결하지 못한 패킷 구조적 특징과 흐름 수준 행동, 계층적 프로토콜 의미, 상호 패킷 맥락 관계를 포착하는 데 성공적으로 접근하여 트래픽 대표성 및 분류 정확성에서 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 네트워크 트래픽 분류 방법이 패킷 구조적 특징과 흐름 수준 행동 등을 포착하는 데 어려움을 겪음에 따라, 이러한 문제를 해결하기 위한 새로운 접근이 필요함.

Method: FlowletFormer는 BERT 기반의 사전 훈련 모델로, 트래픽을 의미 있는 단위로 세분화하는 Coherent Behavior-Aware Traffic Representation Model, 다층 프로토콜 의미를 포착하는 Protocol Stack Alignment-Based Embedding Layer, 상호 패킷 및 상호 흐름 학습을 강화하는 Field-Specific and Context-Aware Pretraining Tasks를 사용함.

Result: FlowletFormer는 트래픽 대표성, 분류 정확성 및 몇 번의 학습 능력에서 기존 방법들을 크게 초월함을 실험적으로 보여줌.

Conclusion: FlowletFormer는 도메인 특화된 네트워크 지식을 효과적으로 통합하여 TCP의 상태 유지 연결과 같은 네트워크 전송 원리에 대한 이해도를 높이며, 트래픽 분석을 위한 보다 강력하고 신뢰할 수 있는 프레임워크를 제공함.

Abstract: Network traffic classification using pre-training models has shown promising
results, but existing methods struggle to capture packet structural
characteristics, flow-level behaviors, hierarchical protocol semantics, and
inter-packet contextual relationships. To address these challenges, we propose
FlowletFormer, a BERT-based pre-training model specifically designed for
network traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware
Traffic Representation Model for segmenting traffic into semantically
meaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture
multilayer protocol semantics, and Field-Specific and Context-Aware Pretraining
Tasks to enhance both inter-packet and inter-flow learning. Experimental
results demonstrate that FlowletFormer significantly outperforms existing
methods in the effectiveness of traffic representation, classification
accuracy, and few-shot learning capability. Moreover, by effectively
integrating domain-specific network knowledge, FlowletFormer shows better
comprehension of the principles of network transmission (e.g., stateful
connections of TCP), providing a more robust and trustworthy framework for
traffic analysis.

</details>


### [66] [Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions](https://arxiv.org/abs/2508.19945)
*Zhouyu Zhang,Chih-Yuan Chiu,Glen Chou*

Main category: cs.LG

TL;DR: 본 연구는 다수의 에이전트 간의 로컬 일반화된 내쉬 평형 상호작용에서 매개변수 제약을 학습하기 위한 역동적 게임 기반 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 내쉬 평형 상호작용에서 에이전트의 제약을 이해하고 학습하는 것은 안전하고 효율적인 다중 에이전트 시스템을 설계하는 데 중요합니다.

Method: 역동적 게임 기반 알고리즘을 사용하여 에이전트의 KKT 조건을 인코딩한 혼합 정수 선형 프로그래밍(MILP)을 도입합니다.

Result: 우리는 제약을 추론하고 다양한 종류의 제약에 대한 상호작용 동작 계획을 설계할 수 있음을 보여주었습니다.

Conclusion: 이 방법은 비선형 동역학을 가진 에이전트 간의 상호작용 시연에서 제약을 학습하고 동작 계획을 설계하는 데 유용하다.

Abstract: We present an inverse dynamic game-based algorithm to learn parametric
constraints from a given dataset of local generalized Nash equilibrium
interactions between multiple agents. Specifically, we introduce mixed-integer
linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the
interacting agents, which recover constraints consistent with the Nash
stationarity of the interaction demonstrations. We establish theoretical
guarantees that our method learns inner approximations of the true safe and
unsafe sets, as well as limitations of constraint learnability from
demonstrations of Nash equilibrium interactions. We also use the interaction
constraints recovered by our method to design motion plans that robustly
satisfy the underlying constraints. Across simulations and hardware
experiments, our methods proved capable of inferring constraints and designing
interactive motion plans for various classes of constraints, both convex and
non-convex, from interaction demonstrations of agents with nonlinear dynamics.

</details>


### [67] [Global Permutation Entropy](https://arxiv.org/abs/2508.19955)
*Abhijeet Avhale,Joscha Diehl,Niraj Velankar,Emanuele Verri*

Main category: cs.LG

TL;DR: Global Permutation Entropy (GPE)는 비연속 패턴을 포함한 고유한 길이의 모든 가능한 패턴을 고려하는 새로운 복잡성 측정 지표이다.


<details>
  <summary>Details</summary>
Motivation: 시간 시계열의 복잡성을 보다 효과적으로 측정하기 위해 기존의 순열 엔트로피를 보완할 필요가 있다.

Method: 비연속 순열을 포함한 모든 가능한 패턴에 대해 GPE를 계산하며, 효율적인 전처리 알고리즘을 사용한다.

Result: GPE는 기존의 순열 엔트로피로는 접근할 수 없는 구조적 정보를 드러내는 데 효과적이다.

Conclusion: GPE는 새로운 방식으로 시간 시계열의 복잡성을 측정할 수 있는 유용한 도구가 된다.

Abstract: Permutation Entropy, introduced by Bandt and Pompe, is a widely used
complexity measure for real-valued time series that is based on the relative
order of values within consecutive segments of fixed length. After
standardizing each segment to a permutation and computing the frequency
distribution of these permutations, Shannon Entropy is then applied to quantify
the series' complexity. We introduce Global Permutation Entropy (GPE), a novel
index that considers all possible patterns of a given length, including
non-consecutive ones. Its computation relies on recently developed algorithms
that enable the efficient extraction of full permutation profiles. We
illustrate some properties of GPE and demonstrate its effectiveness through
experiments on synthetic datasets, showing that it reveals structural
information not accessible through standard permutation entropy. We provide a
Julia package for the calculation of GPE at
`https://github.com/AThreeH1/Global-Permutation-Entropy'.

</details>


### [68] [Short-Horizon Predictive Maintenance of Industrial Pumps Using Time-Series Features and Machine Learning](https://arxiv.org/abs/2508.19974)
*Khaled M. A. Alghtus,Aiyad Gannan,Khalid M. Alhajri,Ali L. A. Al Jubouri,Hassan A. I. Al-Janahi*

Main category: cs.LG

TL;DR: 이 연구는 산업 원심 펌프의 단기 결함 예측을 위한 기계 학습 프레임워크를 제시하며, 실시간 센서 데이터를 사용한다.


<details>
  <summary>Details</summary>
Motivation: 산업 원심 펌프의 결함을 조기에 경고하기 위해 기계 학습을 활용하는 필요성.

Method: 60분 및 120분의 두 가지 회상 기간을 슬라이딩 윈도우 접근법으로 평가하고, 통계적 특징을 추출하며 SMOTE 알고리즘으로 클래스 불균형 문제를 해결했다.

Result: 랜덤 포레스트 모델이 60분의 윈도우에서 5분, 15분 및 30분에서 각각 69.2%, 64.9%, 48.6%의 리콜 점수를 달성하였다.

Conclusion: 예측 기간에 따라 최적의 역사 길이가 다르며, 다양한 결함 패턴이 다른 시계열에서 진화할 수 있음을 강조한다.

Abstract: This study presents a machine learning framework for forecasting short-term
faults in industrial centrifugal pumps using real-time sensor data. The
approach aims to predict {EarlyWarning} conditions 5, 15, and 30 minutes in
advance based on patterns extracted from historical operation. Two lookback
periods, 60 minutes and 120 minutes, were evaluated using a sliding window
approach. For each window, statistical features including mean, standard
deviation, minimum, maximum, and linear trend were extracted, and class
imbalance was addressed using the SMOTE algorithm. Random Forest and XGBoost
classifiers were trained and tested on the labeled dataset. Results show that
the Random Forest model achieved the best short-term forecasting performance
with a 60-minute window, reaching recall scores of 69.2\% at 5 minutes, 64.9\%
at 15 minutes, and 48.6\% at 30 minutes. With a 120-minute window, the Random
Forest model achieved 57.6\% recall at 5 minutes, and improved predictive
accuracy of 65.6\% at both 15 and 30 minutes. XGBoost displayed similar but
slightly lower performance. These findings highlight that optimal history
length depends on the prediction horizon, and that different fault patterns may
evolve at different timescales. The proposed method offers an interpretable and
scalable solution for integrating predictive maintenance into real-time
industrial monitoring systems.

</details>


### [69] [Reducing Street Parking Search Time via Smart Assignment Strategies](https://arxiv.org/abs/2508.19979)
*Behafarid Hemmatpour,Javad Dogani,Nikolaos Laoutaris*

Main category: cs.LG

TL;DR: 본 논문은 모바일 앱을 사용하여 주차를 찾는 것이 교통 혼잡에 미치는 영향을 분석하고, 서로 다른 전략의 효율성을 비교합니다.


<details>
  <summary>Details</summary>
Motivation: 밀집된 도시 지역에서 거리 주차 검색은 교통 혼잡을 증가시킵니다. 따라서 모바일 기반의 실시간 보조 도구의 필요성과 효율성을 평가하고자 합니다.

Method: 마드리드의 거리 주차 생태계를 데이터 기반 시뮬레이션을 통해 분석하고, 비조정 검색, 비사용자 인식 없이 조정된 주차, 모든 비사용자의 위치를 아는 이상적인 오라클 시스템, 및 비사용자의 행동을 확률적으로 추정하는 새로운 Cord-Approx 전략을 비교합니다.

Result: Cord-Approx 전략을 사용하는 사용자들은 평균 6.69분만에 주차를 찾는 반면, 앱이 없는 비사용자는 평균 19.98분이 걸렸습니다. 중앙 집중 지역에서는 Cord-Approx가 사용자 검색 시간을 72% 감소시켰으며, 주거지역에서는 최대 73%까지 감소했습니다.

Conclusion: Cord-Approx 전략은 비사용자에 비해 시스템 사용자의 주차 검색 시간을 크게 단축시킵니다.

Abstract: In dense metropolitan areas, searching for street parking adds to traffic
congestion. Like many other problems, real-time assistants based on mobile
phones have been proposed, but their effectiveness is understudied. This work
quantifies how varying levels of user coordination and information availability
through such apps impact search time and the probability of finding street
parking. Through a data-driven simulation of Madrid's street parking ecosystem,
we analyze four distinct strategies: uncoordinated search (Unc-Agn),
coordinated parking without awareness of non-users (Cord-Agn), an idealized
oracle system that knows the positions of all non-users (Cord-Oracle), and our
novel/practical Cord-Approx strategy that estimates non-users' behavior
probabilistically. The Cord-Approx strategy, instead of requiring knowledge of
how close non-users are to a certain spot in order to decide whether to
navigate toward it, uses past occupancy distributions to elongate physical
distances between system users and alternative parking spots, and then solves a
Hungarian matching problem to dispatch accordingly. In high-fidelity
simulations of Madrid's parking network with real traffic data, users of
Cord-Approx averaged 6.69 minutes to find parking, compared to 19.98 minutes
for non-users without an app. A zone-level snapshot shows that Cord-Approx
reduces search time for system users by 72% (range = 67-76%) in central hubs,
and up to 73% in residential areas, relative to non-users.

</details>


### [70] [Evaluating Language Model Reasoning about Confidential Information](https://arxiv.org/abs/2508.19980)
*Dylan Sam,Alexander Robey,Andy Zou,Matt Fredrikson,J. Zico Kolter*

Main category: cs.LG

TL;DR: 언어 모델이 고위험 환경에서 자율 에이전트로 배치됨에 따라, 사용자 정의 규칙을 신뢰성 있게 따르는 것이 중요한 안전 문제로 부각되고 있다. 본 연구에서는 언어 모델이 맥락에 따라 안전 사양을 준수하는 능력인 맥락적 강건성을 보여주는지를 분석한다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델의 안전성과 신뢰성을 확보하기 위한 필요성이 증가하고 있다.

Method: PasswordEval 벤치마크를 개발하여 언어 모델이 사용자 요청이 권한이 있는지를 올바르게 판단할 수 있는지를 측정한다.

Result: 현재의 언어 모델들은 이 간단한 작업조차도 잘 수행하지 못하며, 추론 능력이 일반적으로 성능을 향상시키지 않음을 발견했다. 또한, 추론 흔적이 기밀 정보를 유출하는 경우가 빈번하다.

Conclusion: 현재의 최첨단 모델들은 기밀 정보를 처리하는 데 적합하지 않으며, 안전성을 높이기 위해서는 추론 능력을 다른 방식으로 학습할 필요가 있다.

Abstract: As language models are increasingly deployed as autonomous agents in
high-stakes settings, ensuring that they reliably follow user-defined rules has
become a critical safety concern. To this end, we study whether language models
exhibit contextual robustness, or the capability to adhere to context-dependent
safety specifications. For this analysis, we develop a benchmark (PasswordEval)
that measures whether language models can correctly determine when a user
request is authorized (i.e., with a correct password). We find that current
open- and closed-source models struggle with this seemingly simple task, and
that, perhaps surprisingly, reasoning capabilities do not generally improve
performance. In fact, we find that reasoning traces frequently leak
confidential information, which calls into question whether reasoning traces
should be exposed to users in such applications. We also scale the difficulty
of our evaluation along multiple axes: (i) by adding adversarial user pressure
through various jailbreaking strategies, and (ii) through longer multi-turn
conversations where password verification is more challenging. Overall, our
results suggest that current frontier models are not well-suited to handling
confidential information, and that reasoning capabilities may need to be
trained in a different manner to make them safer for release in high-stakes
settings.

</details>


### [71] [Self-Supervised Pre-Training with Equilibrium Constraints](https://arxiv.org/abs/2508.19990)
*Xiaodong Cui,A F M Saif,Brian Kingsbury,Tianyi Chen*

Main category: cs.LG

TL;DR: 이 논문은 이질적인 데이터를 처리하기 위한 새로운 자기 감독 사전 훈련 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 이질적인 데이터를 효과적으로 처리하고자 하는 필요성.

Method: 모델에서 초기화된 $K$-단계 기울기 하강 후 각 이질적 데이터 소스를 지역 최적화하도록 추가적인 균형 제약을 도입하는 방법으로 이 문제를 2레벨 최적화 문제로 공식화하고, 1차 근사 방법을 사용하여 해결.

Result: 실험은 다중 도메인 및 다국어 데이터 세트를 사용한 자기 감독 사전 훈련에서 수행되었으며, 제안된 접근 방식이 하위 감독 미세 조정 작업에 대한 자기 감독 사전 훈련 모델의 적응성을 크게 개선할 수 있음을 보여준다.

Conclusion: 이 접근법은 이질적 데이터를 처리하는 새로운 방향을 열어준다.

Abstract: Self-supervised pre-training using unlabeled data is widely used in machine
learning. In this paper, we propose a new self-supervised pre-training approach
to dealing with heterogeneous data. Instead of mixing all the data and
minimizing the averaged global loss in the conventional way, we impose
additional equilibrium constraints to ensure that the models optimizes each
source of heterogeneous data to its local optima after $K$-step gradient
descent initialized from the model. We formulate this as a bilevel optimization
problem, and use the first-order approximation method to solve the problem. We
discuss its connection to model-agnostic meta learning (MAML). Experiments are
carried out on self-supervised pre-training using multi-domain and multilingual
datasets, demonstrating that the proposed approach can significantly improve
the adaptivity of the self-supervised pre-trained model for the downstream
supervised fine-tuning tasks.

</details>


### [72] [FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring](https://arxiv.org/abs/2508.20021)
*Felix Möhrlein,Martin Käppel,Julian Neuberger,Sven Weinzierl,Lars Ackermann,Martin Matzner,Stefan Jablonski*

Main category: cs.LG

TL;DR: FairLoop은 신경망 기반 예측 모델에서 인간의 개입을 통한 편향 완화를 지원하는 도구이다.


<details>
  <summary>Details</summary>
Motivation: 민감한 특성(예: 성별, 나이)이 예측 비즈니스 프로세스 모니터링과 같은 머신러닝 작업에서 불공정한 예측을 초래할 수 있기 때문에, 이를 해결하기 위한 방법이 필요하다.

Method: FairLoop은 신경망에서 결정 트리를 distilled하여 사용자가 불공정한 결정 논리를 검사하고 수정할 수 있도록 함으로써 원래 모델을 보다 공정한 예측으로 미세 조정하는 데 사용된다.

Result: FairLoop은 인간의 개입을 통한 맥락 인지 편향 제거를 가능하게 하여 민감한 특성의 영향을 일률적으로 제외하지 않고 선택적으로 다룬다.

Conclusion: FairLoop은 신경망 기반 예측에서 인간의 지식을 활용하여 공정성을 높이는 효과적인 방법을 제공한다.

Abstract: Sensitive attributes like gender or age can lead to unfair predictions in
machine learning tasks such as predictive business process monitoring,
particularly when used without considering context. We present FairLoop1, a
tool for human-guided bias mitigation in neural network-based prediction
models. FairLoop distills decision trees from neural networks, allowing users
to inspect and modify unfair decision logic, which is then used to fine-tune
the original model towards fairer predictions. Compared to other approaches to
fairness, FairLoop enables context-aware bias removal through human
involvement, addressing the influence of sensitive attributes selectively
rather than excluding them uniformly.

</details>


### [73] [Using item recommendations and LLMs in marketing email titles](https://arxiv.org/abs/2508.20024)
*Deddy Jobson,Muktti Shukla,Phuong Dinh,Julio Christian Young,Nick Pitton,Nina Chen,Ryan Ginstrom*

Main category: cs.LG

TL;DR: 이 연구에서는 개인화된 이메일 제목 생성에 대규모 언어 모델(LLM)의 가능성을 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 이메일 마케팅은 사용자에게 최신 상품을 알리는 중요한 접점이며, 특히 개인화된 추천이 효과적입니다.

Method: 우리는 LLM을 사용하여 이메일 내용에 맞는 주제 제목을 생성하는 방법을 모색하고, 오프라인 시뮬레이션과 수백만 사용자에 대한 온라인 실험을 수행했습니다.

Result: 우리의 기법은 고객과 이메일 간의 참여도를 향상시키는 데 유용하다는 것을 발견했습니다.

Conclusion: 수백만 사용자를 위한 이메일 제목의 안전하고 자동화된 생성을 생산화하는 과정에서 주요 발견 및 학습을 강조합니다.

Abstract: E-commerce marketplaces make use of a number of marketing channels like
emails, push notifications, etc. to reach their users and stimulate purchases.
Personalized emails especially are a popular touch point for marketers to
inform users of latest items in stock, especially for those who stopped
visiting the marketplace. Such emails contain personalized recommendations
tailored to each user's interests, enticing users to buy relevant items. A
common limitation of these emails is that the primary entry point, the title of
the email, tends to follow fixed templates, failing to inspire enough interest
in the contents. In this work, we explore the potential of large language
models (LLMs) for generating thematic titles that reflect the personalized
content of the emails. We perform offline simulations and conduct online
experiments on the order of millions of users, finding our techniques useful in
improving the engagement between customers and our emails. We highlight key
findings and learnings as we productionize the safe and automated generation of
email titles for millions of users.

</details>


### [74] [Pruning Strategies for Backdoor Defense in LLMs](https://arxiv.org/abs/2508.20032)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 백도어 공격은 사전 훈련된 언어 모델의 성능과 무결성에 중대한 위협이다. 이 연구에서는 공격 트리거에 대한 지식 없이도 주의 헤드 가지치기로 이러한 위협을 완화할 수 있는지를 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 사전 훈련된 언어 모델이 백도어 공격에 취약하다는 최근 연구 결과가 있으며, 이러한 공격을 방어하기가 어렵기 때문이다.

Method: 주요 방법은 여섯 가지 가지치기 전략을 설계하고 구현하는 것으로, 이에는 기울기 기반 가지치기, 레이어별 분산 가지치기, 구조화된 L1/L2 희소화와 함께하는 기울기 기반 가지치기, 랜덤화된 집합 가지치기, 강화 학습 기반 가지치기, 베이지안 불확실성 가지치기가 포함된다.

Result: 실험 평가 결과, 기울기 기반 가지치기가 구문 공격을 방어하는 데 가장 우수한 성능을 보였고, 강화 학습 및 베이지안 가지치기가 스타일 공격을 더 잘 견디는 것으로 나타났다.

Conclusion: 이 연구는 주의 헤드 가지치기가 백도어 공격을 완화하는 데 효과적일 수 있음을 시사한다.

Abstract: Backdoor attacks are a significant threat to the performance and integrity of
pre-trained language models. Although such models are routinely fine-tuned for
downstream NLP tasks, recent work shows they remain vulnerable to backdoor
attacks that survive vanilla fine-tuning. These attacks are difficult to defend
because end users typically lack knowledge of the attack triggers. Such attacks
consist of stealthy malicious triggers introduced through subtle syntactic or
stylistic manipulations, which can bypass traditional detection and remain in
the model, making post-hoc purification essential. In this study, we explore
whether attention-head pruning can mitigate these threats without any knowledge
of the trigger or access to a clean reference model. To this end, we design and
implement six pruning-based strategies: (i) gradient-based pruning, (ii)
layer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2
sparsification, (iv) randomized ensemble pruning, (v)
reinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.
Each method iteratively removes the least informative heads while monitoring
validation accuracy to avoid over-pruning. Experimental evaluation shows that
gradient-based pruning performs best while defending the syntactic triggers,
whereas reinforcement learning and Bayesian pruning better withstand stylistic
attacks.

</details>


### [75] [Reinforcement Learning for Search Tree Size Minimization in Constraint Programming: New Results on Scheduling Benchmarks](https://arxiv.org/abs/2508.20056)
*Vilém Heinz,Petr Vilím,Zdeněk Hanzálek*

Main category: cs.LG

TL;DR: FDS는 제약 프로그래밍에서 스케줄링 문제에 효과적인 완전 탐색 알고리즘이다. 본 논문은 FDS의 속성을 분석하고, MAB 강화 학습 알고리즘을 FDS에 적용한 결과 JSSP와 RCPSP에서 성능이 크게 향상되었음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: FDS 알고리즘의 성능을 개선하고자 하며, MAB 문제와의 관계를 이해하기 위해.

Method: FDS의 분기를 최적화하기 위해 MAB 강화 학습 알고리즘을 적용하고 문제에 특화된 개선 및 파라미터 조정을 수행하였다.

Result: 강화된 FDS는 JSSP에서 1.7배, RCPSP에서 2.1배의 성능 향상을 보였으며, 기존의 최첨단 FDS 알고리즘보다도 더 빠른 결과를 도출하였다.

Conclusion: 강화된 FDS는 기존의 하한계를 개선하고, 몇 가지 문제에 대해서는 완전히 해결함으로써 뛰어난 성능을 입증하였다.

Abstract: Failure-Directed Search (FDS) is a significant complete generic search
algorithm used in Constraint Programming (CP) to efficiently explore the search
space, proven particularly effective on scheduling problems. This paper
analyzes FDS's properties, showing that minimizing the size of its search tree
guided by ranked branching decisions is closely related to the Multi-armed
bandit (MAB) problem. Building on this insight, MAB reinforcement learning
algorithms are applied to FDS, extended with problem-specific refinements and
parameter tuning, and evaluated on the two most fundamental scheduling
problems, the Job Shop Scheduling Problem (JSSP) and Resource-Constrained
Project Scheduling Problem (RCPSP). The resulting enhanced FDS, using the best
extended MAB algorithm and configuration, performs 1.7 times faster on the JSSP
and 2.1 times faster on the RCPSP benchmarks compared to the original
implementation in a new solver called OptalCP, while also being 3.5 times
faster on the JSSP and 2.1 times faster on the RCPSP benchmarks than the
current state-of-the-art FDS algorithm in IBM CP Optimizer 22.1. Furthermore,
using only a 900-second time limit per instance, the enhanced FDS improved the
existing state-of-the-art lower bounds of 78 of 84 JSSP and 226 of 393 RCPSP
standard open benchmark instances while also completely closing a few of them.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [76] [The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents](https://arxiv.org/abs/2508.19267)
*Sai Teja Reddy Adapala,Yashwanth Reddy Alugubelly*

Main category: cs.CR

TL;DR: Aegis 프로토콜은 자율 AI 에이전트의 안전한 생태계를 위한 계층적 보안 프레임워크를 제안하며, 전통적인 사이버 보안 체계의 한계를 극복하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 자율 AI 에이전트의 확산은 복잡하고 긴급한 다중 에이전트 시스템으로의 패러다임 변화를 가져오며, 이는 시스템적인 보안 위험을 초래한다.

Method: Aegis 프로토콜은 비스푸프 가능한 에이전트 ID, NIST 표준의 포스트 양자 암호화, Halo2 영지식 증명을 활용한 정책 준수 검증 등 세 가지 기술적 기둥으로 구성된다.

Result: 1,000명의 에이전트를 모델링한 시뮬레이션에서 20,000회의 공격 시도에서 0%의 성공률을 보였고, 정책 검증에서 2.79초의 중앙 증명 생성 지연을 기록했다.

Conclusion: 이 평가는 시뮬레이션 기반이지만 향후 실증 연구를 위한 재현 가능한 기준을 제공하며, Aegis를 안전하고 확장 가능한 자율 AI의 기초로 위치 지운다.

Abstract: The proliferation of autonomous AI agents marks a paradigm shift toward
complex, emergent multi-agent systems. This transition introduces systemic
security risks, including control-flow hijacking and cascading failures, that
traditional cybersecurity paradigms are ill-equipped to address. This paper
introduces the Aegis Protocol, a layered security framework designed to provide
strong security guarantees for open agentic ecosystems. The protocol integrates
three technological pillars: (1) non-spoofable agent identity via W3C
Decentralized Identifiers (DIDs); (2) communication integrity via
NIST-standardized post-quantum cryptography (PQC); and (3) verifiable,
privacy-preserving policy compliance using the Halo2 zero-knowledge proof (ZKP)
system. We formalize an adversary model extending Dolev-Yao for agentic threats
and validate the protocol against the STRIDE framework. Our quantitative
evaluation used a discrete-event simulation, calibrated against cryptographic
benchmarks, to model 1,000 agents. The simulation showed a 0 percent success
rate across 20,000 attack trials. For policy verification, analysis of the
simulation logs reported a median proof-generation latency of 2.79 seconds,
establishing a performance baseline for this class of security. While the
evaluation is simulation-based and early-stage, it offers a reproducible
baseline for future empirical studies and positions Aegis as a foundation for
safe, scalable autonomous AI.

</details>


### [77] [Tight Quantum-Security Bounds and Parameter Optimization for SPHINCS+ and NTRU](https://arxiv.org/abs/2508.19250)
*Ruopengyu Xu,Chenglian Liu*

Main category: cs.CR

TL;DR: 이 논문은 양자 저항 암호 시스템을 위한 보안 경계를 설정합니다.


<details>
  <summary>Details</summary>
Motivation: 양자 컴퓨팅의 위협에 대응하기 위해 양자 저항 암호 시스템이 필요하다.

Method: 양자 공격 모델을 개발하고, 엔트로피 집중 불평등을 개선하며, NTRU 격자 매개변수를 최적화하고 NTRU-에서-LWE로의 축소를 강화하였다.

Result: SPHINCS+ 매개변수를 15-20% 줄이고 NTRU 격자 매개변수를 최적화하였다.

Conclusion: 이론적 결과는 기존 구조보다 상당한 보안 향상을 보여주며 표준화를 위한 실행 가능한 매개변수를 제공한다.

Abstract: The imminent threat of quantum computing necessitates quantum-resistant
cryptosystems. This paper establishes tight security bounds for two NIST PQC
finalists: SPHINCS+ (hash-based) and NTRU (lattice-based). Our key
contributions include: (1) A quantum attack model incorporating decoherence
effects ($\tau_d$) and parallelization limits; (2) Improved entropy
concentration inequalities reducing SPHINCS+ parameters by 15-20\%; (3)
Optimized NTRU lattice parameters via quantum lattice entropy $H_Q(\Lambda)$;
(4) Tightened NTRU-to-LWE reduction with polynomial-factor improvement.
Theoretical results demonstrate significant security enhancement over existing
constructions, providing implementable parameters for standardization.

</details>


### [78] [MixGAN: A Hybrid Semi-Supervised and Generative Approach for DDoS Detection in Cloud-Integrated IoT Networks](https://arxiv.org/abs/2508.19273)
*Tongxi Wu,Chenwei Xu,Jin Yang*

Main category: cs.CR

TL;DR: MixGAN은 클라우드 통합 IoT 시스템에서 DDoS 공격을 탐지하기 위한 하이브리드 방법으로, 조건부 생성, 반지도 학습, 강력한 특징 추출을 통합한다.


<details>
  <summary>Details</summary>
Motivation: 클라우드 통합 IoT 시스템의 확산으로 인해 DDoS 공격 노출이 증가하고 있으며, 이러한 환경에서 DDoS 탐지는 복잡한 트래픽 동역학과 클래스 불균형 등의 문제로 어려워지고 있다.

Method: MixGAN은 조건부 생성, 반지도 학습, 그리고 강력한 특징 추출을 통합한 하이브리드 탐지 방법이다. 복잡한 시간적 트래픽 패턴을 처리하기 위해 1-D WideResNet 백본을 설계하고, CTGAN을 이용해 합성 소수 클래스 샘플을 생성하며, MixUp-Average-Sharpen(MAS) 전략을 도입하여 노이즈가 있는 의사 라벨의 영향을 완화한다.

Result: NSL-KDD, BoT-IoT, 및 CICIoT2023 실험에서 MixGAN은 최신 방법에 비해 최대 2.5% 높은 정확도와 4%의 TPR 및 TNR 개선을 달성하였다.

Conclusion: MixGAN은 대규모 IoT-클라우드 환경에서의 강건성을 입증하며, 소스 코드는 GitHub에서 공개적으로 제공된다.

Abstract: The proliferation of cloud-integrated IoT systems has intensified exposure to
Distributed Denial of Service (DDoS) attacks due to the expanded attack
surface, heterogeneous device behaviors, and limited edge protection. However,
DDoS detection in this context remains challenging because of complex traffic
dynamics, severe class imbalance, and scarce labeled data. While recent methods
have explored solutions to address class imbalance, many still struggle to
generalize under limited supervision and dynamic traffic conditions. To
overcome these challenges, we propose MixGAN, a hybrid detection method that
integrates conditional generation, semi-supervised learning, and robust feature
extraction. Specifically, to handle complex temporal traffic patterns, we
design a 1-D WideResNet backbone composed of temporal convolutional layers with
residual connections, which effectively capture local burst patterns in traffic
sequences. To alleviate class imbalance and label scarcity, we use a pretrained
CTGAN to generate synthetic minority-class (DDoS attack) samples that
complement unlabeled data. Furthermore, to mitigate the effect of noisy
pseudo-labels, we introduce a MixUp-Average-Sharpen (MAS) strategy that
constructs smoothed and sharpened targets by averaging predictions over
augmented views and reweighting them towards high-confidence classes.
Experiments on NSL-KDD, BoT-IoT, and CICIoT2023 demonstrate that MixGAN
achieves up to 2.5% higher accuracy and 4% improvement in both TPR and TNR
compared to state-of-the-art methods, confirming its robustness in large-scale
IoT-cloud environments. The source code is publicly available at
https://github.com/0xCavaliers/MixGAN.

</details>


### [79] [Towards Production-Worthy Simulation for Autonomous Cyber Operations](https://arxiv.org/abs/2508.19278)
*Konur Tholl,Mariam El Mezouar,Ranwa Al Mallah*

Main category: cs.CR

TL;DR: 이 연구는 CybORG의 Cage Challenge 2 환경을 확장하여 보안 시나리오를 정확하게 나타내고 강화 학습을 지원하는 신호를 생성하는 새로운 액션을 구현한 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 사이버 작전에서 시뮬레이션된 환경의 중요성과 실제 운영자의 기능을 반영할 필요성을 강조합니다.

Method: CybORG 환경을 Patch, Isolate, Unisolate라는 새로운 액션을 추가하여 확장하고, DQN 및 PPO 에이전트를 수정된 보상 신호와 기능 공간으로 교육합니다.

Result: DQN 및 PPO 에이전트를 수정된 환경에서 훈련하여 CybORG가 추가적인 현실적인 기능으로 확장될 수 있음을 입증합니다.

Conclusion: CybORG는 RL 에이전트를 위한 정보성 신호를 생성하는 능력을 유지하면서 더 많은 현실적인 기능을 제공할 수 있다는 것을 보여줍니다.

Abstract: Simulated environments have proven invaluable in Autonomous Cyber Operations
(ACO) where Reinforcement Learning (RL) agents can be trained without the
computational overhead of emulation. These environments must accurately
represent cybersecurity scenarios while producing the necessary signals to
support RL training. In this study, we present a framework where we first
extend CybORG's Cage Challenge 2 environment by implementing three new actions:
Patch, Isolate, and Unisolate, to better represent the capabilities available
to human operators in real-world settings. We then propose a design for agent
development where we modify the reward signals and the agent's feature space to
enhance training performance. To validate these modifications, we train DQN and
PPO agents in the updated environment. Our study demonstrates that CybORG can
be extended with additional realistic functionality, while maintaining its
ability to generate informative training signals for RL agents.

</details>


### [80] [CORTEX: Composite Overlay for Risk Tiering and Exposure in Operational AI Systems](https://arxiv.org/abs/2508.19281)
*Aoun E Muhammad,Kin Choong Yow,Jamel Baili,Yongwon Cho,Yunyoung Nam*

Main category: cs.CR

TL;DR: AI 시스템의 고위험 분야에서의 배치가 증가함에 따라 이러한 시스템의 실패 가능성과 영향이 이론적 가능성에서 실제적이고 지속적인 시스템적 위험으로 발전하였다. 본 논문은 AI 시스템의 취약점을 평가하고 점수화하기 위해 제안된 다층 위험 점수 프레임워크인 CORTEX를 도입한다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 높은 위험 분야에서 배치됨에 따라 이러한 시스템의 실패 위험을 체계적으로 분석하고 평가할 필요성이 커졌다.

Method: CORTEX는 1,200건 이상의 AI 사건 데이터베이스(AIID)에 문서화된 사건을 기반으로 개발된 다층 위험 점수 프레임워크로서, 실패 모드를 29개 기술적 취약점 그룹으로 분류한다. 각 취약점은 다섯 가지 계층 아키텍처를 통해 점수가 매겨진다.

Result: CORTEX를 통해 산출된 복합 점수는 AI 위험 등록부, 모델 감사, 적합성 검사 및 동적 거버넌스 대시보드 전반에서 운영될 수 있다.

Conclusion: 이 프레임워크는 AI 시스템의 포괄적이고 체계적인 위험 평가를 가능하게 한다.

Abstract: As the deployment of Artificial Intelligence (AI) systems in high-stakes
sectors - like healthcare, finance, education, justice, and infrastructure has
increased - the possibility and impact of failures of these systems have
significantly evolved from being a theoretical possibility to practical
recurring, systemic risk. This paper introduces CORTEX (Composite Overlay for
Risk Tiering and Exposure), a multi-layered risk scoring framework proposed to
assess and score AI system vulnerabilities, developed on empirical analysis of
over 1,200 incidents documented in the AI Incident Database (AIID), CORTEX
categorizes failure modes into 29 technical vulnerability groups. Each
vulnerability is scored through a five-tier architecture that combines: (1)
utility-adjusted Likelihood x Impact calculations; (2) governance + contextual
overlays aligned with regulatory frameworks, such as the EU AI Act, NIST RMF,
OECD principles; (3) technical surface scores, covering exposure vectors like
drift, traceability, and adversarial risk; (4) environmental and residual
modifiers tailored to context of where these systems are being deployed to use;
and (5) a final layered assessment via Bayesian risk aggregation and Monte
Carlo simulation to model volatility and long-tail risks. The resulting
composite score can be operationalized across AI risk registers, model audits,
conformity checks, and dynamic governance dashboards.

</details>


### [81] [Rethinking Denial-of-Service: A Conditional Taxonomy Unifying Availability and Sustainability Threats](https://arxiv.org/abs/2508.19283)
*Mark Dorsett,Scott Man,Tim Koussas*

Main category: cs.CR

TL;DR: 이 논문은 유산과 클라우드 시대의 서비스 거부 공격(DoS)을 분류하기 위한 통합된 조건 기반 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 서비스 거부 공격의 다양성과 복잡성을 이해하고, 이를 효과적으로 분류하여 방어 및 대응 전략을 개선하기 위해.

Method: 공식적인 조건 트리 분류법, 순서 이론에 기반한 계층 격자 구조, 개념적 벤 다이어그램을 포함하는 세 가지 상호 관련된 모델을 제시합니다.

Result: 이 프레임워크는 다양한 DoS 공격 유형과 새로운 변종을 일관되게 분류할 수 있는 조건들을 제공합니다.

Conclusion: 이 프레임워크는 클라우드 네이티브 및 서버리스 환경에서의 공격 이해를 향상시키며, 방어자와 연구자들에게 진화하는 위협 벡터를 해석하고 완화할 수 있는 공통 언어를 제공합니다.

Abstract: This paper proposes a unified, condition-based framework for classifying both
legacy and cloud-era denial-of-service (DoS) attacks. The framework comprises
three interrelated models: a formal conditional tree taxonomy, a hierarchical
lattice structure based on order theory, and a conceptual Venn diagram. At its
core, the taxonomy introduces six observable conditions (C0-C5) grounded in
real-world attack behaviours, including source distribution, traffic volume,
infrastructure targeting, and financial exploitation. These conditions enable
consistent classification of known attacks-such as DoS, DDoS, LDoS, LDDoS,
EDoS, DoW, and DDoW, while supporting identification of emerging or hybrid
variants. The lattice structure captures the cumulative satisfaction of
conditions, allowing hierarchical reasoning across denial attack classes. The
Venn diagram highlights conceptual overlaps between availability- and
sustainability-focused attacks, improving comparative insight. Together, these
models provide a robust analytical lens for threat modeling, mitigation
strategy design, and attacker intent classification. The framework is
particularly relevant in cloud-native and serverless environments, where
sustainability-based attacks are increasingly impactful yet under-recognised.
Its extensibility also permits future integration of socio-technical or
behavioural dimensions. By offering a structured taxonomy with theoretical
grounding and real-world applicability, this work advances denial attack
comprehension and equips defenders, researchers, and cloud architects with a
shared vocabulary for interpreting and mitigating evolving threat vectors.

</details>


### [82] [A Comprehensive Review of Denial of Wallet Attacks in Serverless Architectures](https://arxiv.org/abs/2508.19284)
*Mark Dorsett,Scott Mann,Jabed Chowdhury,Abdun Mahmood*

Main category: cs.CR

TL;DR: Denial of Wallet (DoW) 공격은 서버리스 아키텍처에 미치는 재정적 부담을 초래하는 새로운 위협이며, 다양한 공격 유형과 대응 전략, 시뮬레이션 도구들을 통해 그 발전을 다룬다.


<details>
  <summary>Details</summary>
Motivation: DoW 공격의 재정적 영향을 이해하고 이로 인해 애플리케이션 소유자가 겪는 부담을 줄이고자 하는 필요성에서 출발했다.

Method: DoW 공격의 진화와 이를 탐지하고 완화하기 위한 전략을 포함한 문헌 연구를 수행하고, 다양한 공격 유형과 시뮬레이션 도구의 발전을 분석했다.

Result: 다양한 DoW 공격 유형과 이를 탐지하기 위한 머신러닝 기술이 발전하였으나, 실제 데이터의 부족과 적응형 청구 모델 필요성과 같은 도전 과제가 여전히 남아있다는 것을 확인하였다.

Conclusion: 이 논문은 DoW 공격에 대한 최초의 종합 문헌 리뷰를 제공하며, 서버리스 컴퓨팅 내에서의 재정적 영향, 공격 기법, 완화 전략 및 탐지 메커니즘에 대한 심층 분석을 제시한다.

Abstract: The Denial of Wallet (DoW) attack poses a unique and growing threat to
serverless architectures that rely on Function-as-a-Service (FaaS) models,
exploiting the cost structure of pay-as-you-go billing to financially burden
application owners. Unlike traditional Denial of Service (DoS) attacks, which
aim to exhaust resources and disrupt service availability, DoW attacks focus on
escalating costs without impacting service operation. This review traces the
evolution of DoW research, from initial awareness and attack classification to
advancements in detection and mitigation strategies. Key developments include
the categorisation of attack types-such as Blast DDoW, Continual Inconspicuous
DDoW, and Background Chained DDoW-and the creation of simulation tools like
DoWTS, which enable safe experimentation and data generation. Recent
advancements highlight machine learning approaches, including systems like
Gringotts and DoWNet, which leverage deep learning and anomaly detection to
identify malicious traffic patterns. Although substantial progress has been
made, challenges persist, notably the lack of real-world data and the need for
adaptive billing models. This is the first comprehensive literature review
dedicated strictly to Denial of Wallet attacks, providing an in-depth analysis
of their financial impacts, attack techniques, mitigation strategies, and
detection mechanisms within serverless computing. The paper also presents the
first detailed examination of simulation and data generation tools used for DoW
research, addressing a critical gap in existing cybersecurity literature. By
synthesising these key areas, this study serves as a foundational resource for
future research and industry efforts in securing pay-as-you-go cloud
environments.

</details>


### [83] [RL-Finetuned LLMs for Privacy-Preserving Synthetic Rewriting](https://arxiv.org/abs/2508.19286)
*Zhan Shi,Yefeng Yuan,Yuhong Liu,Liang Cheng,Yi Fang*

Main category: cs.CR

TL;DR: 본 논문은 사용자 개인 정보 보호와 데이터 유용성을 동시에 고려하는 강화 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현대 기계 학습 시스템의 성능은 대규모의 고품질 데이터셋에 의존하며, 이러한 데이터셋은 개인 정보 보호, 데이터 보안, 규제 준수 등의 문제를 야기한다.

Method: 강화 학습 프레임워크를 통해 대형 언어 모델(LLM)을 미세 조정하고 명시적 및 암시적 개인 정보를 최적화하는 복합 보상 함수를 사용한다.

Result: 제안한 방법이 저자 모호화 및 개인 정보 보호 메트릭스를 유의미하게 향상시킨다는 실증적 결과를 보여준다.

Conclusion: 이 방법은 대형 언어 모델 시대에 개인 정보 보호 데이터를 생성하기 위한 확장 가능하고 모델에 구애받지 않는 솔루션을 제공한다.

Abstract: The performance of modern machine learning systems depends on access to
large, high-quality datasets, often sourced from user-generated content or
proprietary, domain-specific corpora. However, these rich datasets inherently
contain sensitive personal information, raising significant concerns about
privacy, data security, and compliance with regulatory frameworks. While
conventional anonymization techniques can remove explicit identifiers, such
removal may result in performance drop in downstream machine learning tasks.
More importantly, simple anonymization may not be effective against inference
attacks that exploit implicit signals such as writing style, topical focus, or
demographic cues, highlighting the need for more robust privacy safeguards
during model training. To address the challenging issue of balancing user
privacy and data utility, we propose a reinforcement learning framework that
fine-tunes a large language model (LLM) using a composite reward function that
jointly optimizes for explicit and implicit privacy, semantic fidelity, and
output diversity. To effectively capture population level regularities, the
privacy reward combines semantic cues with structural patterns derived from a
minimum spanning tree (MST) over latent representations. By modeling these
privacy-sensitive signals in their distributional context, the proposed
approach guides the model to generate synthetic rewrites that preserve utility
while mitigating privacy risks. Empirical results show that the proposed method
significantly enhances author obfuscation and privacy metrics without degrading
semantic quality, providing a scalable and model-agnostic solution for privacy
preserving data generation in the era of large language models.

</details>


### [84] [Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior](https://arxiv.org/abs/2508.19287)
*Zhuotao Lian,Weiyu Wang,Qingkui Zeng,Toru Nakanishi,Teruaki Kitasuka,Chunhua Su*

Main category: cs.CR

TL;DR: 사용자 제출 콘텐츠에서 새로운 공격 방식을 식별하고 분석하여 LLM의 위협을 밝혀냄.


<details>
  <summary>Details</summary>
Motivation: LLM이 사용자 콘텐츠를 처리하는 환경에서의 보안 문제를 이해하고 해결하기 위해.

Method: LLM에 숨겨진 명령어가 포함된 콘텐츠 주입 공격의 가능성을 시연하고, 원인 분석 및 완화 전략 논의.

Result: 유명한 플랫폼에서 공격 가능성을 입증하고, 원인 분석을 통해 보안 취약성을 드러냄.

Conclusion: 실제 LLM 환경에서 존재하는 실질적인 위협을 실증적으로 밝혀냄.

Abstract: Large Language Models (LLMs) are widely deployed in applications that accept
user-submitted content, such as uploaded documents or pasted text, for tasks
like summarization and question answering. In this paper, we identify a new
class of attacks, prompt in content injection, where adversarial instructions
are embedded in seemingly benign inputs. When processed by the LLM, these
hidden prompts can manipulate outputs without user awareness or system
compromise, leading to biased summaries, fabricated claims, or misleading
suggestions. We demonstrate the feasibility of such attacks across popular
platforms, analyze their root causes including prompt concatenation and
insufficient input isolation, and discuss mitigation strategies. Our findings
reveal a subtle yet practical threat in real-world LLM workflows.

</details>


### [85] [Tricking LLM-Based NPCs into Spilling Secrets](https://arxiv.org/abs/2508.19288)
*Kyohei Shiomi,Zhuotao Lian,Toru Nakanishi,Teruaki Kitasuka*

Main category: cs.CR

TL;DR: LLM을 사용해 게임 NPC의 다이내믹한 대화를 생성하는 과정에서 새로운 보안 문제가 발생함을 연구함.


<details>
  <summary>Details</summary>
Motivation: 게임 NPC에 대한 다이내믹 대화 생성을 위한 LLM의 사용 증가로 인한 보안 우려.

Method: 적대적 프롬프트 주입이 LLM 기반 NPC가 숨겨진 배경 비밀을 드러내게 할 수 있는지 조사함.

Result: LLM 기반 NPC의 비밀 노출 가능성을 연구하여 보안 취약점을 분석함.

Conclusion: 이 연구는 LLM을 통합할 때의 보안 위험을 강조함.

Abstract: Large Language Models (LLMs) are increasingly used to generate dynamic
dialogue for game NPCs. However, their integration raises new security
concerns. In this study, we examine whether adversarial prompt injection can
cause LLM-based NPCs to reveal hidden background secrets that are meant to
remain undisclosed.

</details>


### [86] [Stand on The Shoulders of Giants: Building JailExpert from Previous Attack Experience](https://arxiv.org/abs/2508.19292)
*Xi Wang,Songlei Jian,Shasha Li,Xiaopeng Li,Bin Ji,Jun Ma,Xiaodong Liu,Jing Wang,Feilong Bao,Jianfeng Zhang,Baosheng Wang,Jie Yu*

Main category: cs.CR

TL;DR: JailExpert라는 자동화된 jailbreak 프레임워크는 과거 공격 경험을 통합하여 LLM의 보안 취약점을 이용하는 효율적이고 효과적인 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)이 안전한 콘텐츠를 생성하는 데 있어 jailbreak 공격이 취약성을 식별하고 강력한 보안 프레임워크 개발에 기여할 수 있다.

Method: JailExpert는 경험 구조의 공식적인 표현, 의미적 변화에 따른 경험 그룹화, 경험 풀의 동적 업데이트를 지원하는 자동화된 jailbreak 프레임워크이다.

Result: JailExpert는 기존의 블랙박스 jailbreak 방법보다 공격 성공률을 평균 17% 높이고 공격 효율성을 2.7배 향상시킨다.

Conclusion: JailExpert는 LLM의 취약점을 효과적으로 활용하는 데 기여하며, GitHub에서 구현을 제공한다.

Abstract: Large language models (LLMs) generate human-aligned content under certain
safety constraints. However, the current known technique ``jailbreak prompt''
can circumvent safety-aligned measures and induce LLMs to output malicious
content. Research on Jailbreaking can help identify vulnerabilities in LLMs and
guide the development of robust security frameworks. To circumvent the issue of
attack templates becoming obsolete as models evolve, existing methods adopt
iterative mutation and dynamic optimization to facilitate more automated
jailbreak attacks. However, these methods face two challenges: inefficiency and
repetitive optimization, as they overlook the value of past attack experiences.
To better integrate past attack experiences to assist current jailbreak
attempts, we propose the \textbf{JailExpert}, an automated jailbreak framework,
which is the first to achieve a formal representation of experience structure,
group experiences based on semantic drift, and support the dynamic updating of
the experience pool. Extensive experiments demonstrate that JailExpert
significantly improves both attack effectiveness and efficiency. Compared to
the current state-of-the-art black-box jailbreak methods, JailExpert achieves
an average increase of 17\% in attack success rate and 2.7 times improvement in
attack efficiency. Our implementation is available at
\href{https://github.com/xiZAIzai/JailExpert}{XiZaiZai/JailExpert}

</details>


### [87] [Leveraging 3D Technologies for Hardware Security: Opportunities and Challenges](https://arxiv.org/abs/2508.19309)
*Peng Gu,Shuangchen Li,Dylan Stow,Russell Barnes,Liu Liu,Yuan Xie,Eren Kursshan*

Main category: cs.CR

TL;DR: 3D 다이 적층 및 2.5D 인터포저 설계는 통합 밀도, 성능 및 비용을 개선할 수 있는 유망한 기술입니다. 하지만 현재의 접근 방식은 사이드 채널 공격, 하드웨어 트로이 목마, 안전한 IC 제조 및 지식 재산권 도용과 같은 새로운 보안 문제를 해결하는 데 심각한 어려움에 직면해 있습니다. 본 논문에서는 이러한 기술의 고유한 특징을 이용하여 안전한 시스템을 설계할 수 있는 새로운 기회를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 3D 및 2.5D 기술의 발전에 따라 보안 문제에 대한 새로운 접근 방식을 모색할 필요성이 대두되고 있습니다.

Method: 사이드 채널 정보를 차폐하기 위한 3D 아키텍처, 액티브 인터포저를 이용한 분할 제조, 단일체 3D IC에서의 회로 위장, 3D IC 기반의 메모리 내 보안 처리(PIM) 등을 제안합니다.

Result: 제안된 설계들은 기존 보안 위협에 대한 대응책을 개선하고 새로운 보안 기능을 추가할 수 있음을 보여줍니다.

Conclusion: 실제로 이러한 새로운 설계는 보안 위협에 대한 효과적인 해결책을 제공할 수 있는 가능성을 가지고 있습니다.

Abstract: 3D die stacking and 2.5D interposer design are promising technologies to
improve integration density, performance and cost. Current approaches face
serious issues in dealing with emerging security challenges such as side
channel attacks, hardware trojans, secure IC manufacturing and IP piracy. By
utilizing intrinsic characteristics of 2.5D and 3D technologies, we propose
novel opportunities in designing secure systems. We present: (i) a 3D
architecture for shielding side-channel information; (ii) split fabrication
using active interposers; (iii) circuit camouflage on monolithic 3D IC, and
(iv) 3D IC-based security processing-in-memory (PIM). Advantages and challenges
of these designs are discussed, showing that the new designs can improve
existing countermeasures against security threats and further provide new
security features.

</details>


### [88] [An Investigation on Group Query Hallucination Attacks](https://arxiv.org/abs/2508.19321)
*Kehao Miao,Xiaolong Jin*

Main category: cs.CR

TL;DR: 대형 언어 모델의 사용자 상호작용 중 잠재적 실패 모드를 이해하는 것이 중요하다. 이 연구에서는 여러 쿼리를 동시에 LLM에 제시하는 기술인 Group Query Attack을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 사용자 상호작용 중 발생할 수 있는 잠재적 실패 모드를 이해하기 위해.

Method: Group Query Attack 기법을 사용하여 쿼리 그룹을 동시에 LLM에 제시하여 이를 시뮬레이션하고, 연속적인 프롬프트에서 누적된 컨텍스트가 LLM의 출력에 미치는 영향을 조사한다.

Result: Group Query Attack이 특정 작업에 대해 미세 조정된 모델의 성능을 의미 있게 저하시킨다는 것을 관찰하고, 잠재적인 백도어를 유발할 위험도 있음을 보여준다.

Conclusion: Group Query Attack은 논리적 추론 및 코드 생성과 같은 reasoning이 필요한 작업에서도 효과적이다.

Abstract: With the widespread use of large language models (LLMs), understanding their
potential failure modes during user interactions is essential. In practice,
users often pose multiple questions in a single conversation with LLMs.
Therefore, in this study, we propose Group Query Attack, a technique that
simulates this scenario by presenting groups of queries to LLMs simultaneously.
We investigate how the accumulated context from consecutive prompts influences
the outputs of LLMs. Specifically, we observe that Group Query Attack
significantly degrades the performance of models fine-tuned on specific tasks.
Moreover, we demonstrate that Group Query Attack induces a risk of triggering
potential backdoors of LLMs. Besides, Group Query Attack is also effective in
tasks involving reasoning, such as mathematical reasoning and code generation
for pre-trained and aligned models.

</details>


### [89] [A Technical Review on Comparison and Estimation of Steganographic Tools](https://arxiv.org/abs/2508.19323)
*Ms. Preeti P. Bhatt,Rakesh R. Savant*

Main category: cs.CR

TL;DR: 이 논문은 이미지 스테가노그래피의 분류와 다양한 이미지 형식을 사용하는 여러 스테가노그래피 도구의 비교를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 스테가노그래피는 데이터를 숨기기 위한 다양한 도구를 사용하여 커버 미디어 아래에 데이터를 숨기는 기술이다.

Method: 시장에 있는 여러 도구를 분석하고 각 도구에 동일한 입력을 사용하여 테스트하였다.

Result: 실험 결과, 여섯 가지 스테가노그래피 도구 모두 비슷한 성능을 보였으며 일부 소프트웨어는 효율성 측면에서 더 나은 성능을 보였다.

Conclusion: 이미지의 특징에 따른 분석 결과, 도구의 성능은 이미지 크기, 차원, 픽셀 값 및 히스토그램 차별화에 기초하였다.

Abstract: Steganography is technique of hiding a data under cover media using different
steganography tools. Image steganography is hiding of data
(Text/Image/Audio/Video) under a cover as Image. This review paper presents
classification of image steganography and the comparison of various Image
steganography tools using different image formats. Analyzing numerous tools on
the basis of Image features and extracting the best one. Some of the tools
available in the market were selected based on the frequent use; these tools
were tested using the same input on all of them. Specific text was embedded
within all host images for each of the six Steganography tools selected. The
results of the experiment reveal that all the six tools were relatively
performing at the same level, though some software performs better than others
through efficiency. And it was based on the image features like size,
dimensions, and pixel value and histogram differentiation.

</details>


### [90] [Just Dork and Crawl: Measuring Illegal Online Gambling Defacement in Indonesian Websites](https://arxiv.org/abs/2508.19368)
*Luqman Muhammad Zagi,Girindro Pringgo Digdo,Wervyan Shalannanda*

Main category: cs.CR

TL;DR: 이 연구는 불법 온라인 도박을 촉진하는 주체들에 의한 인도네시아 웹사이트의 변조 현상을 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 웹사이트 변조의 범위와 지속성을 이해하고 온라인 도박 활동에 대한 방어를 강화하기 위해 지속적인 측정의 중요성을 강조하기 위함입니다.

Method: 키워드 기반 Dorking과 체계적인 크롤링을 결합한 경량 방법론을 사용하여 453개의 변조된 웹페이지를 식별했습니다.

Result: 변조 행동은 반복 변조(150건), 고정 인스턴스(129건), 키워드 수정(55건), 리디렉션 또는 숨겨진 URL 삽입을 포함했습니다.

Conclusion: 단순하고 재현 가능한 기술이 변조의 규모와 역학에 대한 의미 있는 통찰을 제공할 수 있다는 것을 보여주며, 온라인 도박 활동에 대한 방어 강화의 필요성을 강조합니다.

Abstract: This study investigates the defacement of Indonesian websites by actors
promoting illegal online gambling. Using a lightweight methodology that
combines keyword-driven dorking with systematic crawling, we identified 453
defaced webpages within one month. Although dorking alone yielded a false
positive rate of approximately 20.3\%, the integration of crawling and
keyword-counting enabled reliable differentiation between true and false
positives. Our measurements revealed diverse defacement behaviors, including
repeat defacements (150 cases), fixed instances (129), keyword modifications
(55), and redirections or hidden URL injections. In total, 8,837 unique
third-party URLs spanning 5,930 domains were captured, with a small subset
recurring across multiple sites. Website responses were inconsistent, with an
average reaction time of 75.3 hours. These findings demonstrate that simple,
reproducible techniques can provide meaningful insights into the scale,
persistence, and dynamics of defacement, highlighting the importance of
continuous measurement for strengthening defenses against online gambling
activities.

</details>


### [91] [A NIS2 pan-European registry for identifying and classifying essential and important entities](https://arxiv.org/abs/2508.19395)
*Fabian Aude Steen,Daniel Assani Shabani*

Main category: cs.CR

TL;DR: NIS2 지침은 EU 전역에 걸쳐 사이버 보안 거버넌스 모델을 수립하며, 회원국에게 필수 및 중요 항목을 식별, 분류 및 감독할 것을 요구합니다. 이 논문은 NIS2 지침을 분석하고 기술적 요구 사항으로 변환하여 모듈식 레지스트리 시스템의 설계를 지원합니다.


<details>
  <summary>Details</summary>
Motivation: NIS2 지침은 유럽 연합의 사이버 보안 거버넌스를 향상시키기 위한 공동 모델을 만들고, 회원국들이 규제 의무를 충족하도록 돕기 위해 필요합니다.

Method: 이 논문은 디자인 과학 연구 방법론을 사용하여 법적 규정을 구조화된 워크플로우, 결정론적 분류 알고리즘, 인터랙티브 대시보드로 변환합니다.

Result: 결과 시스템은 엔티티 등록, 분류 및 통지를 포함한 주요 규제 프로세스를 자동화하며, 상황 인식 감독과 행정적 부담을 줄입니다.

Conclusion: 이 시스템은 노르웨이 규제 생태계를 위해 개발되었지만 최소한의 수정으로 다른 회원국에서도 적용할 수 있도록 설계되어 있습니다. 이 논문은 법적 해석과 기술적 구현을 연결하는 재사용 가능한 프레임워크를 제공하며 NIS2 사이버 보안 거버넌스에 대한 확장 가능한 솔루션을 제안합니다.

Abstract: The NIS2 Directive establishes a common cybersecurity governance model across
the European Union, requiring member states to identify, classify, and
supervise essential and important entities. As part of a broader governance
network, member states are also obligated to notify the European Commission,
the Cooperation Group, and ENISA about their cybersecurity infrastructure
landscape. This thesis presents an analysis of the NIS2 Directive in this
context and translates its provisions into concrete technical requirements.
These requirements inform the design and implementation of a modular, legally
grounded registry system intended to support competent authorities across the
EU in meeting their obligations. Using the Design Science Research methodology,
the thesis transforms complex legal provisions into structured workflows,
deterministic classification algorithms, and interactive dashboards. The
resulting system automates key regulatory processes, including entity
registration, classification, and notification, while enabling context-aware
supervision and reducing administrative burden. It supports both automated and
manual registration methods and introduces a contextual labeling system to
handle edge cases, risk factors, and cross-directive dependencies. Although
developed for the Norwegian regulatory ecosystem, the system is designed for
adaptation by other member states with minimal modification. This thesis
contributes a reusable framework that bridges legal interpretation and
technical implementation, offering a scalable solution for national and
EU-level NIS2 cybersecurity governance. It also identifies key limitations and
outlines opportunities for future research and development.

</details>


### [92] [Formal Verification of Physical Layer Security Protocols for Next-Generation Communication Networks (extended version)](https://arxiv.org/abs/2508.19430)
*Kangfeng Ye,Roberto Metere,Jim Woodcock,Poonam Yadav*

Main category: cs.CR

TL;DR: 이 논문은 Needham-Schroeder 프로토콜의 형식 검증을 통해 보안 프로토콜의 강건성을 향상시키기 위한 새로운 방법론을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 보안 프로토콜이 악성 공격에 강하도록 보장하기 위한 형식 검증의 중요성.

Method: Isabelle 형식을 사용하여 같은 프로토콜을 재모델링하고, 상호작용 및 자동화된 형식 검증이 가능하도록 애니메이션을 생성하는 접근법.

Result: 새로운 웹 인터페이스를 사용하여 네 가지 서로 다른 도청 위치에서 비밀성과 진위를 종합적으로 분석하였고, 새로운 결과를 도출하였습니다.

Conclusion: 이 접근법은 보안 속성을 형식적으로 검증하는 데 강력함을 입증합니다.

Abstract: Formal verification is crucial for ensuring the robustness of security
protocols against adversarial attacks. The Needham-Schroeder protocol, a
foundational authentication mechanism, has been extensively studied, including
its integration with Physical Layer Security (PLS) techniques such as
watermarking and jamming. Recent research has used ProVerif to verify these
mechanisms in terms of secrecy. However, the ProVerif-based approach limits the
ability to improve understanding of security beyond verification results. To
overcome these limitations, we re-model the same protocol using an Isabelle
formalism that generates sound animation, enabling interactive and automated
formal verification of security protocols. Our modelling and verification
framework is generic and highly configurable, supporting both cryptography and
PLS. For the same protocol, we have conducted a comprehensive analysis (secrecy
and authenticity in four different eavesdropper locations under both passive
and active attacks) using our new web interface. Our findings not only
successfully reproduce and reinforce previous results on secrecy but also
reveal an uncommon but expected outcome: authenticity is preserved across all
examined scenarios, even in cases where secrecy is compromised. We have
proposed a PLS-based Diffie-Hellman protocol that integrates watermarking and
jamming, and our analysis shows that it is secure for deriving a session key
with required authentication. These highlight the advantages of our novel
approach, demonstrating its robustness in formally verifying security
properties beyond conventional methods.

</details>


### [93] [CITADEL: Continual Anomaly Detection for Enhanced Learning in IoT Intrusion Detection](https://arxiv.org/abs/2508.19450)
*Elvin Li,Onat Gungor,Zhengli Shang,Tajana Rosing*

Main category: cs.CR

TL;DR: CITADEL은 IoT 보안을 강화하기 위한 자가 감독 지속 학습 프레임워크로, benign 데이터에서 강력한 표현을 추출하고 장기 지식을 보존하는 최적화된 메모리 응집 메커니즘을 통해 지속적인 학습의 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: IoT의 높은 상호 연결성과 제한된 계산 리소스는 다양한 사이버 위협에 특히 취약합니다.

Method: CITADEL은 benign 데이터에서 강력한 표현을 추출하고, 장기 지식을 보존하기 위해 최적화된 메모리 응집 메커니즘을 이용하여 설계되었습니다. 이를 위해 표 형태에서 이미지 형태로 변환하는 모듈, 자기 감독 표현 학습을 위한 메모리 인식 마스크 자동 인코더, 레이블된 공격 데이터에 의존하지 않고 이상을 식별할 수 있는 새로움 감지 구성 요소를 통합합니다.

Result: 여러 침입 데이터셋에 대한 실험 결과, CITADEL은 주요 탐지 및 유지 메트릭에서 VAE 기반 평생 이상 탐지기(VLAD)에 비해 최대 72.9% 향상을 이루었습니다.

Conclusion: CITADEL은 동적 IoT 환경에서 효과적으로 작동하며, 새로운 행동에 점진적으로 적응하면서 이전에 관찰된 위협을 탐지하는 능력을 유지합니다.

Abstract: The Internet of Things (IoT), with its high degree of interconnectivity and
limited computational resources, is particularly vulnerable to a wide range of
cyber threats. Intrusion detection systems (IDS) have been extensively studied
to enhance IoT security, and machine learning-based IDS (ML-IDS) show
considerable promise for detecting malicious activity. However, their
effectiveness is often constrained by poor adaptability to emerging threats and
the issue of catastrophic forgetting during continuous learning. To address
these challenges, we propose CITADEL, a self-supervised continual learning
framework designed to extract robust representations from benign data while
preserving long-term knowledge through optimized memory consolidation
mechanisms. CITADEL integrates a tabular-to-image transformation module, a
memory-aware masked autoencoder for self-supervised representation learning,
and a novelty detection component capable of identifying anomalies without
dependence on labeled attack data. Our design enables the system to
incrementally adapt to emerging behaviors while retaining its ability to detect
previously observed threats. Experiments on multiple intrusion datasets
demonstrate that CITADEL achieves up to a 72.9% improvement over the VAE-based
lifelong anomaly detector (VLAD) in key detection and retention metrics,
highlighting its effectiveness in dynamic IoT environments.

</details>


### [94] [ReLATE+: Unified Framework for Adversarial Attack Detection, Classification, and Resilient Model Selection in Time-Series Classification](https://arxiv.org/abs/2508.19456)
*Cagla Ipek Kocal,Onat Gungor,Tajana Rosing,Baris Aksanli*

Main category: cs.CR

TL;DR: ReLATE+는 적대적 공격 감지 및 분류, 데이터셋 유사성에 따른 딥러닝 모델 선택을 통해 시간 시계열 분류의 계산 오버헤드를 평균 77.68% 줄이며 성능을 유지하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 모델의 복잡성과 실시간으로 처리해야 하는 대규모의 시퀀스 데이터로 인해 시간 시계열 분류의 계산 오버헤드를 최소화하는 것이 큰 도전이다.

Method: ReLATE+는 적대적 공격을 감지하고 분류하며, 데이터셋 수준의 유사성을 기반으로 딥러닝 모델을 적응적으로 선택하는 포괄적인 프레임워크를 제공한다.

Result: 실험 결과 ReLATE+는 평균 77.68%의 계산 오버헤드를 줄이며, 적대적 복원력과 강력한 모델 선택을 지원한다.

Conclusion: ReLATE+는 재교육 필요성을 줄이고 성능을 유지하면서 다양한 데이터 분포와 특성 공간에서 잘 일반화된다.

Abstract: Minimizing computational overhead in time-series classification, particularly
in deep learning models, presents a significant challenge due to the high
complexity of model architectures and the large volume of sequential data that
must be processed in real time. This challenge is further compounded by
adversarial attacks, emphasizing the need for resilient methods that ensure
robust performance and efficient model selection. To address this challenge, we
propose ReLATE+, a comprehensive framework that detects and classifies
adversarial attacks, adaptively selects deep learning models based on
dataset-level similarity, and thus substantially reduces retraining costs
relative to conventional methods that do not leverage prior knowledge, while
maintaining strong performance. ReLATE+ first checks whether the incoming data
is adversarial and, if so, classifies the attack type, using this insight to
identify a similar dataset from a repository and enable the reuse of the
best-performing associated model. This approach ensures strong performance
while reducing the need for retraining, and it generalizes well across
different domains with varying data distributions and feature spaces.
Experiments show that ReLATE+ reduces computational overhead by an average of
77.68%, enhancing adversarial resilience and streamlining robust model
selection, all without sacrificing performance, within 2.02% of Oracle.

</details>


### [95] [Addressing Weak Authentication like RFID, NFC in EVs and EVCs using AI-powered Adaptive Authentication](https://arxiv.org/abs/2508.19465)
*Onyinye Okoye*

Main category: cs.CR

TL;DR: 이 연구는 전기차 및 충전 시스템의 사이버 보안 문제를 해결하기 위한 AI 기반의 적응형 인증 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전기차 및 충전 시스템의 급속한 확장에 따라 기존 인증 프로토콜의 취약점이 드러났다.

Method: 기계 학습, 이상 탐지, 행동 분석 및 맥락적 위험 평가를 통합한 AI 기반의 적응형 인증 프레임워크를 개발하였다.

Result: 이 프레임워크는 지속적인 검증, 최소 권한 접근 및 안전한 통신을 강조하며, 현재의 취약점을 평가하고 AI 기반 솔루션을 제시한다.

Conclusion: AI 기반의 적응형 인증을 채택하는 것은 전기 이동 수단의 미래를 보호하고 디지털 신뢰를 강화하기 위한 전략적 필수사항이다.

Abstract: The rapid expansion of the Electric Vehicles (EVs) and Electric Vehicle
Charging Systems (EVCs) has introduced new cybersecurity challenges,
specifically in authentication protocols that protect vehicles, users, and
energy infrastructure. Although widely adopted for convenience, traditional
authentication mechanisms like Radio Frequency Identification (RFID) and Near
Field Communication (NFC) rely on static identifiers and weak encryption,
making them highly vulnerable to attack vectors such as cloning, relay attacks,
and signal interception. This study explores an AI-powered adaptive
authentication framework designed to overcome these shortcomings by integrating
machine learning, anomaly detection, behavioral analytics, and contextual risk
assessment. Grounded in the principles of Zero Trust Architecture, the proposed
framework emphasizes continuous verification, least privilege access, and
secure communication. Through a comprehensive literature review, this research
evaluates current vulnerabilities and highlights AI-driven solutions to provide
a scalable, resilient, and proactive defense. Ultimately, the research findings
conclude that adopting AI-powered adaptive authentication is a strategic
imperative for securing the future of electric mobility and strengthening
digital trust across the ecosystem. Keywords: weak authentication, RFID, NFC,
ML, AI-powered adaptive authentication, relay attacks, cloning, eavesdropping,
MITM attacks, Zero Trust Architecture

</details>


### [96] [SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis](https://arxiv.org/abs/2508.19472)
*Kyler Katz,Sara Moshtari,Ibrahim Mujhid,Mehdi Mirakhorli,Derek Garcia*

Main category: cs.CR

TL;DR: SIExVulTS는 Java 애플리케이션에서 민감한 정보 노출을 식별하고 검증하기 위해 변환기 기반 모델과 정적 분석을 통합한 새로운 취약점 탐지 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 민감한 정보 노출(SIEx) 취약점(CWE-200)은 소프트웨어 시스템에서 지속적으로 존재하는 위협으로, 심각한 보안 침해를 초래할 수 있다.

Method: SIExVulTS는 세 단계 아키텍처를 채택하고 있다: (1) 민감한 변수, 문자열, 주석 및 싱크를 식별하는 문장 임베딩을 사용하는 공격 표면 탐지 엔진; (2) CWE-200 계층에 맞춰 CodeQL 쿼리를 구현하는 노출 분석 엔진; (3) 소스에서 싱크로의 데이터 흐름을 의미적으로 검증하기 위해 GraphCodeBERT를 활용하는 흐름 검증 엔진.

Result: 공격 표면 탐지 엔진은 93% 이상의 평균 F1 점수를 달성했고, 노출 분석 엔진은 85.71%의 F1 점수를 기록했으며, 흐름 검증 엔진은 정밀도를 22.61%에서 87.23%로 증가시켰다. 또한 SIExVulTS는 주요 Apache 프로젝트에서 여섯 개의 이전에 알려지지 않은 CVE를 성공적으로 발견했다.

Conclusion: 결과는 SIExVulTS가 민감한 데이터 노출에 대한 소프트웨어 보안을 개선하는 데 효과적이고 실용적임을 보여주며, CWE-200 취약점을 탐지하고 검증하는 기존 도구의 한계를 극복하고 있음을 입증한다.

Abstract: Sensitive Information Exposure (SIEx) vulnerabilities (CWE-200) remain a
persistent and under-addressed threat across software systems, often leading to
serious security breaches. Existing detection tools rarely target the diverse
subcategories of CWE-200 or provide context-aware analysis of code-level data
flows.
  Aims: This paper aims to present SIExVulTS, a novel vulnerability detection
system that integrates transformer-based models with static analysis to
identify and verify sensitive information exposure in Java applications.
  Method: SIExVulTS employs a three-stage architecture: (1) an Attack Surface
Detection Engine that uses sentence embeddings to identify sensitive variables,
strings, comments, and sinks; (2) an Exposure Analysis Engine that instantiates
CodeQL queries aligned with the CWE-200 hierarchy; and (3) a Flow Verification
Engine that leverages GraphCodeBERT to semantically validate source-to-sink
flows. We evaluate SIExVulTS using three curated datasets, including real-world
CVEs, a benchmark set of synthetic CWE-200 examples, and labeled flows from 31
open-source projects.
  Results: The Attack Surface Detection Engine achieved an average F1 score
greater than 93\%, the Exposure Analysis Engine achieved an F1 score of
85.71\%, and the Flow Verification Engine increased precision from 22.61\% to
87.23\%. Moreover, SIExVulTS successfully uncovered six previously unknown CVEs
in major Apache projects.
  Conclusions: The results demonstrate that SIExVulTS is effective and
practical for improving software security against sensitive data exposure,
addressing limitations of existing tools in detecting and verifying CWE-200
vulnerabilities.

</details>


### [97] [Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents](https://arxiv.org/abs/2508.19493)
*Zhixin Lin,Jungang Li,Shidong Pan,Yibo Shi,Yue Yao,Dongliang Xu*

Main category: cs.CR

TL;DR: 스마트폰 에이전트의 개인 정보 보호 인식이 만족스럽지 않다는 대규모 벤치마크 결과를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 스마트폰의 편리함과 함께 사용자 개인 정보를 extensively 기록하게 만드는 문제를 해결하고자 합니다.

Method: 7,138개의 시나리오를 포함한 대규모 벤치마크를 수집하고, 각 시나리오의 개인 정보 맥락을 주석화합니다.

Result: 대부분의 벤치마크 에이전트가 60% 이하의 개인 정보 인식 성능을 보이며, 닫힌 소스 에이전트가 열린 소스보다 우수한 결과를 나타냅니다.

Conclusion: 이 연구 결과가 스마트폰 에이전트의 유용성과 개인 정보 보호 간의 불균형을 재검토하는 계기가 되기를 바랍니다.

Abstract: Smartphones bring significant convenience to users but also enable devices to
extensively record various types of personal information. Existing smartphone
agents powered by Multimodal Large Language Models (MLLMs) have achieved
remarkable performance in automating different tasks. However, as the cost,
these agents are granted substantial access to sensitive users' personal
information during this operation. To gain a thorough understanding of the
privacy awareness of these agents, we present the first large-scale benchmark
encompassing 7,138 scenarios to the best of our knowledge. In addition, for
privacy context in scenarios, we annotate its type (e.g., Account Credentials),
sensitivity level, and location. We then carefully benchmark seven available
mainstream smartphone agents. Our results demonstrate that almost all
benchmarked agents show unsatisfying privacy awareness (RA), with performance
remaining below 60% even with explicit hints. Overall, closed-source agents
show better privacy ability than open-source ones, and Gemini 2.0-flash
achieves the best, achieving an RA of 67%. We also find that the agents'
privacy detection capability is highly related to scenario sensitivity level,
i.e., the scenario with a higher sensitivity level is typically more
identifiable. We hope the findings enlighten the research community to rethink
the unbalanced utility-privacy tradeoff about smartphone agents. Our code and
benchmark are available at https://zhixin-l.github.io/SAPA-Bench.

</details>


### [98] [Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills](https://arxiv.org/abs/2508.19500)
*David Noever*

Main category: cs.CR

TL;DR: 본 논문은 Model Context Protocol (MCP) 기반의 에이전트 시스템에서 새로운 취약성 클래스를 식별하고 분석한다.


<details>
  <summary>Details</summary>
Motivation: MCP 아키텍처가 상호 도메인 보안 조치를 결여하고 있을 가능성을 조사하기 위해.

Method: MITRE ATLAS 프레임워크를 사용하여 95개의 에이전트를 테스트하고, 여러 서비스를 활용한 공격 체계를 분석한다.

Result: 합법적인 작업이 어떻게 복잡한 공격 시퀀스로 연결될 수 있는지를 보여주며, 서비스 오케스트레이션을 통한 특정 공격 체인의 실증적 증거를 제시한다.

Conclusion: 에이전트가 여러 도메인을 가로질러 행동을 조정할 수 있을 때 서비스 격리의 근본적인 보안 가정이 실패한다는 점을 강조한다.

Abstract: This paper identifies and analyzes a novel vulnerability class in Model
Context Protocol (MCP) based agent systems. The attack chain describes and
demonstrates how benign, individually authorized tasks can be orchestrated to
produce harmful emergent behaviors. Through systematic analysis using the MITRE
ATLAS framework, we demonstrate how 95 agents tested with access to multiple
services-including browser automation, financial analysis, location tracking,
and code deployment-can chain legitimate operations into sophisticated attack
sequences that extend beyond the security boundaries of any individual service.
These red team exercises survey whether current MCP architectures lack
cross-domain security measures necessary to detect or prevent a large category
of compositional attacks. We present empirical evidence of specific attack
chains that achieve targeted harm through service orchestration, including data
exfiltration, financial manipulation, and infrastructure compromise. These
findings reveal that the fundamental security assumption of service isolation
fails when agents can coordinate actions across multiple domains, creating an
exponential attack surface that grows with each additional capability. This
research provides a barebones experimental framework that evaluate not whether
agents can complete MCP benchmark tasks, but what happens when they complete
them too well and optimize across multiple services in ways that violate human
expectations and safety constraints. We propose three concrete experimental
directions using the existing MCP benchmark suite.

</details>


### [99] [Breaking the Layer Barrier: Remodeling Private Transformer Inference with Hybrid CKKS and MPC](https://arxiv.org/abs/2508.19525)
*Tianshi Xu,Wen-jie Lu,Jiangrui Yu,Chen Yi,Chenqi Lin,Runsheng Wang,Meng Li*

Main category: cs.CR

TL;DR: 이 논문은 데이터 프라이버시를 보호하기 위해 동형 암호화(HE)와 안전한 다자간 계산(MPC)을 결합한 효율적인 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법은 종종 HE를 선형 레이어에, MPC를 비선형 레이어에 활용하지만 HE와 MPC 간의 변환이 상당한 통신 비용을 초래합니다.

Method: 제안된 프레임워크 BLB는 레이어를 세분화된 연산자로 분해하고 인접한 선형 연산자를 융합하여 HE/MPC 변환의 필요성을 줄입니다. 또한, BLB는 CKKS와 MPC 간의 최초의 안전한 변환 프로토콜을 제안하여 융합된 연산자의 CKKS 기반 계산을 가능하게 합니다.

Result: BERT-base, BERT-large 및 GPT2-base에 대한 광범위한 평가 결과, BLB는 BOLT(S&P'24)와 비교하여 통신 비용을 $21	imes$ 줄였고, Bumblebee(NDSS'25)와 비교하여 $2	imes$ 감소했습니다. 또한, GPU 가속을 활용할 때 지연 시간은 각각 $13	imes$과 $1.8	imes$ 감소합니다.

Conclusion: 제안된 프레임워크 BLB는 Transformer에서의 안전하고 효율적인 프라이빗 추론을 가능하게 합니다.

Abstract: This paper presents an efficient framework for private Transformer inference
that combines Homomorphic Encryption (HE) and Secure Multi-party Computation
(MPC) to protect data privacy. Existing methods often leverage HE for linear
layers (e.g., matrix multiplications) and MPC for non-linear layers (e.g.,
Softmax activation functions), but the conversion between HE and MPC introduces
significant communication costs. The proposed framework, dubbed BLB, overcomes
this by breaking down layers into fine-grained operators and further fusing
adjacent linear operators, reducing the need for HE/MPC conversions. To manage
the increased ciphertext bit width from the fused linear operators, BLB
proposes the first secure conversion protocol between CKKS and MPC and enables
CKKS-based computation of the fused operators. Additionally, BLB proposes an
efficient matrix multiplication protocol for fused computation in Transformers.
Extensive evaluations on BERT-base, BERT-large, and GPT2-base show that BLB
achieves a $21\times$ reduction in communication overhead compared to BOLT
(S\&P'24) and a $2\times$ reduction compared to Bumblebee (NDSS'25), along with
latency reductions of $13\times$ and $1.8\times$, respectively, when leveraging
GPU acceleration.

</details>


### [100] [Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses](https://arxiv.org/abs/2508.19641)
*Lincan Li,Bolin Shen,Chenxi Zhao,Yuxiang Sun,Kaixiang Zhao,Shirui Pan,Yushun Dong*

Main category: cs.CR

TL;DR: 그래프 머신러닝 모델의 훈련에 필요한 자원을 줄이고 이러한 모델과 데이터를 지키기 위한 위협과 방어에 대한 체계를 제공하는 논문이다.


<details>
  <summary>Details</summary>
Motivation: 그래프 구조 데이터의 증가로 GML 모델 훈련이 점점 자원 집약적이 되고, 이로 인해 지적 재산(IP)의 중요성이 커지고 있다.

Method: GML 모델과 그래프 구조 데이터 수준에서의 위협과 방어에 대한 분류 체계를 도입하고, IP 보호 방법의 효과성을 평가할 수 있는 체계적인 평가 프레임워크를 제시한다.

Result: 위협 및 방어의 최초 분류 체계를 제시하고, 다양한 도메인에서 기준 데이터 세트를 소개하며, GMLaaS 시나리오에서 공격 및 방어 기술을 평가하는 라이브러리를 구축하였다.

Conclusion: 이 논문이 GML의 지적 재산 보호와 GML 커뮤니티에 실용적인 솔루션을 제공할 것으로 기대한다.

Abstract: Graph-structured data, which captures non-Euclidean relationships and
interactions between entities, is growing in scale and complexity. As a result,
training state-of-the-art graph machine learning (GML) models have become
increasingly resource-intensive, turning these models and data into invaluable
Intellectual Property (IP). To address the resource-intensive nature of model
training, graph-based Machine-Learning-as-a-Service (GMLaaS) has emerged as an
efficient solution by leveraging third-party cloud services for model
development and management. However, deploying such models in GMLaaS also
exposes them to potential threats from attackers. Specifically, while the APIs
within a GMLaaS system provide interfaces for users to query the model and
receive outputs, they also allow attackers to exploit and steal model
functionalities or sensitive training data, posing severe threats to the safety
of these GML models and the underlying graph data. To address these challenges,
this survey systematically introduces the first taxonomy of threats and
defenses at the level of both GML model and graph-structured data. Such a
tailored taxonomy facilitates an in-depth understanding of GML IP protection.
Furthermore, we present a systematic evaluation framework to assess the
effectiveness of IP protection methods, introduce a curated set of benchmark
datasets across various domains, and discuss their application scopes and
future challenges. Finally, we establish an open-sourced versatile library
named PyGIP, which evaluates various attack and defense techniques in GMLaaS
scenarios and facilitates the implementation of existing benchmark methods. The
library resource can be accessed at: https://labrai.github.io/PyGIP. We believe
this survey will play a fundamental role in intellectual property protection
for GML and provide practical recipes for the GML community.

</details>


### [101] [Safety Alignment Should Be Made More Than Just A Few Attention Heads](https://arxiv.org/abs/2508.19697)
*Chao Huang,Zefeng Zhang,Juewei Yue,Quangang Li,Chuang Zhang,Tingwen Liu*

Main category: cs.CR

TL;DR: 대형 언어 모델의 안전성 정렬이 여전히 취약점이 있다. 본 연구는 이러한 안전 메커니즘이 주로 제한된 주의 헤드에 의존한다는 것을 보여준다. 이를 해결하기 위해 RDSHA라는 방법을 도입하고, AHD라는 새로운 훈련 전략을 제안하여 안전 관련 행동을 여러 주의 헤드에 분산시킨다. 실험 결과 AHD는 안전 관련 기능을 더 많은 주의 헤드에 성공적으로 분산시키며, 여러 jailbreak 공격 하에서도 안전성을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 안전성이 계속해서 취약점이 존재하여, 적대적 프롬프트가 그들의 안전 조치를 효과적으로 우회할 수 있다는 점을 해결하고자 한다.

Method: RDSHA는 모델의 거부 방향을 활용하여 주의 헤드 중 안전 행동에 가장 책임이 있는 헤드를 식별하고 평가하는 타겟 블레이션 방법이다. AHD는 안전 관련 행동을 다양한 주의 헤드에 분산시키도록 설계된 새로운 훈련 전략이다.

Result: AHD는 안전 관련 기능을 더 많은 주의 헤드에 성공적으로 분산시키며, 여러 가지 주요 jailbreak 공격 하에서 훈련된 모델이 상당한 안전성을 유지하는 simultanously functional utility를 보여준다.

Conclusion: 훈련된 모델은 안정성과 기능성을 모두 유지하면서, 안전 강도가 크게 향상된다.

Abstract: Current safety alignment for large language models(LLMs) continues to present
vulnerabilities, given that adversarial prompting can effectively bypass their
safety measures.Our investigation shows that these safety mechanisms
predominantly depend on a limited subset of attention heads: removing or
ablating these heads can severely compromise model safety. To identify and
evaluate these safety-critical components, we introduce RDSHA, a targeted
ablation method that leverages the model's refusal direction to pinpoint
attention heads mostly responsible for safety behaviors. Further analysis shows
that existing jailbreak attacks exploit this concentration by selectively
bypassing or manipulating these critical attention heads. To address this
issue, we propose AHD, a novel training strategy designed to promote the
distributed encoding of safety-related behaviors across numerous attention
heads. Experimental results demonstrate that AHD successfully distributes
safety-related capabilities across more attention heads. Moreover, evaluations
under several mainstream jailbreak attacks show that models trained with AHD
exhibit considerably stronger safety robustness, while maintaining overall
functional utility.

</details>


### [102] [Addressing Deepfake Issue in Selfie banking through camera based authentication](https://arxiv.org/abs/2508.19714)
*Subhrojyoti Mukherjee,Manoranjan Mohanty*

Main category: cs.CR

TL;DR: 딥페이크가 뱅킹 보안에 위협이 되고 있으며, 본 논문은 기존의 포렌식 인식 시스템을 활용한 딥페이크 탐지를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 셀카 뱅킹에서 가짜 이미지가 점점 더 위협이 되고 있습니다.

Method: 기존의 포렌식 인식 시스템을 활용하여 딥페이크 탐지를 수행합니다.

Result: 이 연구는 딥페이크 이미지의 탐지 능력을 향상시킬 수 있는 가능성을 보여줍니다.

Conclusion: 딥페이크 탐지에 대한 기존 기술의 재사용은 뱅킹 보안에 기여할 수 있습니다.

Abstract: Fake images in selfie banking are increasingly becoming a threat. Previously,
it was just Photoshop, but now deep learning technologies enable us to create
highly realistic fake identities, which fraudsters exploit to bypass biometric
systems such as facial recognition in online banking. This paper explores the
use of an already established forensic recognition system, previously used for
picture camera localization, in deepfake detection.

</details>


### [103] [The Art of Hide and Seek: Making Pickle-Based Model Supply Chain Poisoning Stealthy Again](https://arxiv.org/abs/2508.19774)
*Tong Liu,Guozhu Meng,Peng Zhou,Zizhuang Deng,Shuaiyin Yao,Kai Chen*

Main category: cs.CR

TL;DR: 파이썬의 피클 역직렬화 취약점은 오랫동안 존재해왔으며, AI/ML 프레임워크에서 모델 직렬화 프로토콜로 여전히 사용되고 있다. 기존 스캐너들이 탐지하지 못하는 피클 기반 모델 로딩 경로와 위험한 함수들을 식별하고, 실제 스캐너를 우회할 수 있는 방법들을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 피클의 취약성이 AI/ML 모델의 안전한 사용에 큰 리스크를 초래하고 있다.

Method: 모델 로딩과 위험한 함수의 관점에서 피클 기반 모델 오염 표면을 체계적으로 분석하고, 스캐너가 탐지하지 못하는 경로와 기법을 개발했다.

Result: 22개의 피클 기반 모델 로딩 경로와 133개의 악용 가능한 가젯을 발견했으며, 이를 통해 89%의 우회 성공률을 기록했다.

Conclusion: 피클 기반 모델 오염의 취약성을 드러내어 현실적인 공격으로 부터 모델을 보호하기 위한 기초 자료를 제공했다.

Abstract: Pickle deserialization vulnerabilities have persisted throughout Python's
history, remaining widely recognized yet unresolved. Due to its ability to
transparently save and restore complex objects into byte streams, many AI/ML
frameworks continue to adopt pickle as the model serialization protocol despite
its inherent risks. As the open-source model ecosystem grows, model-sharing
platforms such as Hugging Face have attracted massive participation,
significantly amplifying the real-world risks of pickle exploitation and
opening new avenues for model supply chain poisoning. Although several
state-of-the-art scanners have been developed to detect poisoned models, their
incomplete understanding of the poisoning surface leaves the detection logic
fragile and allows attackers to bypass them. In this work, we present the first
systematic disclosure of the pickle-based model poisoning surface from both
model loading and risky function perspectives. Our research demonstrates how
pickle-based model poisoning can remain stealthy and highlights critical gaps
in current scanning solutions. On the model loading surface, we identify 22
distinct pickle-based model loading paths across five foundational AI/ML
frameworks, 19 of which are entirely missed by existing scanners. We further
develop a bypass technique named Exception-Oriented Programming (EOP) and
discover 9 EOP instances, 7 of which can bypass all scanners. On the risky
function surface, we discover 133 exploitable gadgets, achieving almost a 100%
bypass rate. Even against the best-performing scanner, these gadgets maintain
an 89% bypass rate. By systematically revealing the pickle-based model
poisoning surface, we achieve practical and robust bypasses against real-world
scanners. We responsibly disclose our findings to corresponding vendors,
receiving acknowledgments and a $6000 bug bounty.

</details>


### [104] [From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning](https://arxiv.org/abs/2508.19819)
*Viktor Valadi,Mattias Åkesson,Johan Östman,Salman Toor,Andreas Hellander*

Main category: cs.CR

TL;DR: 그래디언트 반전 공격은 연합 학습에서 개인 정보 보호를 침해할 수 있는 능력 때문에 주목받고 있다. 이 연구에서는 아키텍처와 훈련 행동이 취약성에 미치는 영향을 체계적으로 분석하고, 실제 훈련 조건에서의 공격 가능성을 평가하였다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습에서의 프라이버시 침해를 탐구하고 이를 이해하기 위한 기본적인 분석.

Method: 아키텍처와 훈련 모드에서의 행동이 그래디언트 반전 공격의 취약성에 미치는 영향을 체계적으로 분석하고, 훈련 모드에서의 복잡한 공격을 설계.

Result: 형태와 모드가 결합된 경우에만 성공적인 공격이 가능하다는 것을 발견하고, 모델의 취약성을 높이는 아키텍처 수정이 필요함을 보여줌.

Conclusion: 프라이버시 영향을 미치는 아키텍처 선택과 운영 모드의 조합을 명확히 하고, 미래의 연구와 배치에서 그래디언트 반전 위험 평가 방식을 재구성할 필요성을 강조.

Abstract: Gradient inversion attacks have garnered attention for their ability to
compromise privacy in federated learning. However, many studies consider
attacks with the model in inference mode, where training-time behaviors like
dropout are disabled and batch normalization relies on fixed statistics. In
this work, we systematically analyze how architecture and training behavior
affect vulnerability, including the first in-depth study of inference-mode
clients, which we show dramatically simplifies inversion. To assess attack
feasibility under more realistic conditions, we turn to clients operating in
standard training mode. In this setting, we find that successful attacks are
only possible when several architectural conditions are met simultaneously:
models must be shallow and wide, use skip connections, and, critically, employ
pre-activation normalization. We introduce two novel attacks against models in
training-mode with varying attacker knowledge, achieving state-of-the-art
performance under realistic training conditions. We extend these efforts by
presenting the first attack on a production-grade object-detection model. Here,
to enable any visibly identifiable leakage, we revert to the lenient inference
mode setting and make multiple architectural modifications to increase model
vulnerability, with the extent of required changes highlighting the strong
inherent robustness of such architectures. We conclude this work by offering
the first comprehensive mapping of settings, clarifying which combinations of
architectural choices and operational modes meaningfully impact privacy. Our
analysis provides actionable insight into when models are likely vulnerable,
when they appear robust, and where subtle leakage may persist. Together, these
findings reframe how gradient inversion risk should be assessed in future
research and deployment scenarios.

</details>


### [105] [Every Keystroke You Make: A Tech-Law Measurement and Analysis of Event Listeners for Wiretapping](https://arxiv.org/abs/2508.19825)
*Shaoor Munir,Nurullah Demir,Qian Li,Konrad Kollnig,Zubair Shafiq*

Main category: cs.CR

TL;DR: 본 논문은 웹 추적 기술에 대한 미국의 오래된 전자 통신 도청 법률을 매핑하여 기존의 웹 추적 규정 준수 문제를 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 웹 추적 기술의 새로운 유형과 이에 대한 법적 규정 준수를 조사하는 것이 필요합니다.

Method: 우리는 웹 사이트에서 JavaScript 이벤트 리스너를 사용하여 실시간 키 입력 가로채기를 평가하기 위해 상위 백만 개 웹사이트 샘플을 크롤링했습니다.

Result: 38.52%의 웹사이트가 제3자 이벤트 리스너를 설치하여 키 입력을 가로채었고, 최소 3.18%의 웹사이트가 이 정보를 제3자 서버로 전송했습니다.

Conclusion: 이 연구는 기술 측정과 미국 도청 법률 간의 교차점을 매핑하며, 향후 불법성 기준을 확립하기 위한 추가 법적 연구가 필요합니다.

Abstract: The privacy community has a long track record of investigating emerging types
of web tracking techniques. Recent work has focused on compliance of web
trackers with new privacy laws such as Europe's GDPR and California's CCPA.
Despite the growing body of research documenting widespread lack of compliance
with new privacy laws, there is a lack of robust enforcement. Different from
prior work, we conduct a tech-law analysis to map decades-old U.S. laws about
interception of electronic communications--so-called wiretapping--to web
tracking. Bridging the tech-law gap for older wiretapping laws is important and
timely because, in cases where legal harm to privacy is proven, they can
provide statutory private right of action, are at the forefront of recent
privacy enforcement, and could ultimately lead to a meaningful change in the
web tracking landscape.
  In this paper, we focus on a particularly invasive tracking technique: the
use of JavaScript event listeners by third-party trackers for real-time
keystroke interception on websites. We use an instrumented web browser to crawl
a sample of the top-million websites to investigate the use of event listeners
that aligns with the criteria for wiretapping, according to U.S. wiretapping
law at the federal level and in California. We find evidence that 38.52%
websites installed third-party event listeners to intercept keystrokes, and
that at least 3.18% websites transmitted intercepted information to a
third-party server, which aligns with the criteria for wiretapping. We further
find evidence that the intercepted information such as email addresses typed
into form fields are used for unsolicited email marketing. Beyond our work that
maps the intersection between technical measurement and U.S. wiretapping law,
additional future legal research is required to determine when the wiretapping
observed in our paper passes the threshold for illegality.

</details>


### [106] [SoK: Large Language Model Copyright Auditing via Fingerprinting](https://arxiv.org/abs/2508.19843)
*Shuo Shao,Yiming Li,Yu He,Hongwei Yao,Wenyuan Yang,Dacheng Tao,Zhan Qin*

Main category: cs.CR

TL;DR: 이 논문은 대형 언어 모델(LLM)의 저작권 침해를 탐지하기 위한 LLM 지문 인식 기술의 포괄적인 연구를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 훈련하기 위한 광범위한 역량과 자원의 소유는 귀중한 지적 재산이지만, 저작권 침해에 취약하다.

Method: 정합된 프레임워크와 공식 분류 체계를 도입하여 기존의 LLM 지문 인식 기법을 화이트박스 및 블랙박스 접근법으로 분류하고, LeaFBench라는 체계적인 벤치마크를 제안한다.

Result: LeaFBench에서 수행된 광범위한 실험을 통해 기존 기법의 강점과 약점을 드러내고, 이 새로운 분야에서의 미래 연구 방향과 주요 공개 문제를 제시한다.

Conclusion: LLM 지문 인식 기술은 저작권 감사의 유망한 해결책이지만, 신뢰성은 표준화된 평가 부족과 다양한 모델 수정으로 인해 불확실하다.

Abstract: The broad capabilities and substantial resources required to train Large
Language Models (LLMs) make them valuable intellectual property, yet they
remain vulnerable to copyright infringement, such as unauthorized use and model
theft. LLM fingerprinting, a non-intrusive technique that extracts and compares
the distinctive features from LLMs to identify infringements, offers a
promising solution to copyright auditing. However, its reliability remains
uncertain due to the prevalence of diverse model modifications and the lack of
standardized evaluation. In this SoK, we present the first comprehensive study
of LLM fingerprinting. We introduce a unified framework and formal taxonomy
that categorizes existing methods into white-box and black-box approaches,
providing a structured overview of the state of the art. We further propose
LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting
under realistic deployment scenarios. Built upon mainstream foundation models
and comprising 149 distinct model instances, LeaFBench integrates 13
representative post-development techniques, spanning both parameter-altering
methods (e.g., fine-tuning, quantization) and parameter-independent mechanisms
(e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the
strengths and weaknesses of existing methods, thereby outlining future research
directions and critical open problems in this emerging field. The code is
available at https://github.com/shaoshuo-ss/LeaFBench.

</details>


### [107] [SCAMPER -- Synchrophasor Covert chAnnel for Malicious and Protective ERrands](https://arxiv.org/abs/2508.20051)
*Prashanth Krishnamurthy,Ramesh Karri,Farshad Khorrami*

Main category: cs.CR

TL;DR: SCAMPER 프레임워크는 동기화 위상 변환 통신 프로토콜의 필드를 악의적 및 방어적 목적으로 활용하는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 동기화 위상 변환 통신 프로토콜의 데이터 구조에서 필드가 현실적인 사용과 필요에 비해 과잉 제공되고 있어 covert 채널로의 악용 가능성이 있다.

Method: SCAMPER 프레임워크를 개발하여 과잉 제공된 필드를 covert 통신 용도로 활용하고, 이를 통해 악의적 및 방어적 목적에 모두 적용할 수 있음을 보여준다.

Result: 타임스탬프 필드의 수정으로 공격자가 전력 시스템 내에서 비밀 통신을 수행하고 다양한 악의적 행동을 유발할 수 있음을 보여준다. 또한, SCAMPER가 방어적 보안 목적으로도 사용될 수 있음을 입증한다.

Conclusion: 제안된 SCAMPER 프레임워크의 효과를 입증하기 위해 두 개의 HIL 테스트베드에서 실험을 수행하였다.

Abstract: We note that constituent fields (notably the fraction-of-seconds timestamp
field) in the data payload structure of the synchrophasor communication
protocol (IEEE C37.118 standard) are overprovisioned relative to real-world
usage and needs, lending themselves to abuse for embedding of covert channels.
We develop the SCAMPER (Synchrophasor Covert Channel for Malicious and
Protective ERrands) framework to exploit these overprovisioned fields for
covert communication and show that SCAMPER can be applied for both malicious
(attack) and protective (defense) purposes. Through modifications of the
timestamp field, we demonstrate that SCAMPER enables an attacker to accomplish
surreptitious communications between devices in the power system to trigger a
variety of malicious actions. These timestamp modifications can be performed
without having any impact on the operation of the power system. However, having
recognized the potential for this covert channel, we show that SCAMPER can
instead be applied for defensive security purposes as an integrated
cryptographic data integrity mechanism that can facilitate detection of false
data injection (FDI) attacks. We perform experimental studies of the proposed
methods on two Hardware-in-the-Loop (HIL) testbeds to demonstrate the
effectiveness of the proposed SCAMPER framework for both malicious and
protective purposes.

</details>


### [108] [Disabling Self-Correction in Retrieval-Augmented Generation via Stealthy Retriever Poisoning](https://arxiv.org/abs/2508.20083)
*Yanbo Dai,Zhenlan Ji,Zongjie Li,Kuan Li,Shuai Wang*

Main category: cs.CR

TL;DR: RAG 시스템에 대한 새로운 공격 방식인 DisarmRAG를 제안하고, 이를 통해 현대 LLM의 자가 수정 능력을 우회하여 공격 성공률을 90% 이상 달성했다.


<details>
  <summary>Details</summary>
Motivation: RAG 시스템의 취약성을 해결하고, 현대 LLM의 자가 수정 능력이 공격에 미치는 영향을 탐구한다.

Method: DisarmRAG라는 새로운 중독 패러다임을 통해 검색기 자체를 손상시키고, 자가 수정 능력을 억제하여 공격자가 선택한 출력을 강제한다.

Result: DisarmRAG는 6개의 LLM과 3개의 QA 벤치마크에서 악의적인 지침을 거의 완벽하게 검색하고, SCA를 억제하며, 다양한 방어 프롬프트에서 90% 이상의 공격 성공률을 달성하였다.

Conclusion: 검색기 중심의 방어 기법의 필요성이 강조된다.

Abstract: Retrieval-Augmented Generation (RAG) has become a standard approach for
improving the reliability of large language models (LLMs). Prior work
demonstrates the vulnerability of RAG systems by misleading them into
generating attacker-chosen outputs through poisoning the knowledge base.
However, this paper uncovers that such attacks could be mitigated by the strong
\textit{self-correction ability (SCA)} of modern LLMs, which can reject false
context once properly configured. This SCA poses a significant challenge for
attackers aiming to manipulate RAG systems.
  In contrast to previous poisoning methods, which primarily target the
knowledge base, we introduce \textsc{DisarmRAG}, a new poisoning paradigm that
compromises the retriever itself to suppress the SCA and enforce
attacker-chosen outputs. This compromisation enables the attacker to
straightforwardly embed anti-SCA instructions into the context provided to the
generator, thereby bypassing the SCA. To this end, we present a
contrastive-learning-based model editing technique that performs localized and
stealthy edits, ensuring the retriever returns a malicious instruction only for
specific victim queries while preserving benign retrieval behavior. To further
strengthen the attack, we design an iterative co-optimization framework that
automatically discovers robust instructions capable of bypassing prompt-based
defenses. We extensively evaluate DisarmRAG across six LLMs and three QA
benchmarks. Our results show near-perfect retrieval of malicious instructions,
which successfully suppress SCA and achieve attack success rates exceeding 90\%
under diverse defensive prompts. Also, the edited retriever remains stealthy
under several detection methods, highlighting the urgent need for
retriever-centric defenses.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [109] [Sycophancy as compositions of Atomic Psychometric Traits](https://arxiv.org/abs/2508.19316)
*Shreyans Jain,Alexandra Yost,Amirali Abdullah*

Main category: cs.AI

TL;DR: 이 논문은 LLM의 아첨 행동 위험을 심리적 성향의 기하학적 및 인과적 조합으로 모델링하여 해석 가능한 개입을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 아첨은 LLM에서 중요한 행동 위험으로, 종종 단일 원인 메커니즘에 의한 고립된 실패 모드로 간주된다.

Method: 심리측정학의 요인 분해와 유사하게 감정성, 개방성, 친화성 같은 심리적 특성의 기하학적 및 인과적 조합으로 아첨을 모델링하는 것을 제안하고, 대조적 활성화 추가(CAA)를 사용하여 이러한 요인들과의 활성화 방향을 매핑한다.

Result: 활성화 방향의 다양한 조합이 아첨을 어떻게 발생시킬 수 있는지 연구한다(예: 고외향성과 저성실성의 조합).

Conclusion: 이 접근법은 LLM의 안전 관련 행동을 완화하는 데 사용할 수 있는 해석 가능한 벡터 기반 개입(덧셈, 뺄셈 및 프로젝션)을 가능하게 한다.

Abstract: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an
isolated failure mode that occurs via a single causal mechanism. We instead
propose modeling it as geometric and causal compositions of psychometric traits
such as emotionality, openness, and agreeableness - similar to factor
decomposition in psychometrics. Using Contrastive Activation Addition (CAA), we
map activation directions to these factors and study how different combinations
may give rise to sycophancy (e.g., high extraversion combined with low
conscientiousness). This perspective allows for interpretable and compositional
vector-based interventions like addition, subtraction and projection; that may
be used to mitigate safety-critical behaviors in LLMs.

</details>


### [110] [SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control](https://arxiv.org/abs/2508.20018)
*Quanfeng Lu,Zhantao Ma,Shuai Zhong,Jin Wang,Dahai Yu,Michael K. Ng,Ping Luo*

Main category: cs.AI

TL;DR: SWIRL은 다중 에이전트 시스템을 위한 상호 작용 강화 학습의 단계적 워크플로우로, 효율적이고 안정적인 에이전트 간의 협업을 촉진한다.


<details>
  <summary>Details</summary>
Motivation: 대형 비전 언어 모델(LVLM)과 에이전트 시스템의 빠른 발전으로 인해, 자연어를 인터페이스 작업으로 신뢰성 있게 변환할 수 있는 모바일 GUI 에이전트에 대한 관심이 증가하고 있다.

Method: SWIRL은 다중 에이전트 시스템을 위해 설계된 상호 작용 강화 학습의 단계적 워크플로우로, MARL을 단일 에이전트 강화 학습 작업의 시퀀스로 재구성하고, 한 번에 하나의 에이전트를 업데이트하며 나머지는 고정된 상태로 유지한다.

Result: 모바일 GUI 제어에 적용된 SWIRL은 언어와 화면 맥락을 구조화된 계획으로 변환하는 네비게이터와 이러한 계획을 실행 가능한 원자 행동으로 구체화하는 상호 작용기를 포함한다. extensive 실험을 통해 높은 수준과 낮은 수준의 GUI 벤치마크에서 우수한 성능을 보여준다.

Conclusion: SWIRL은 GUI 작업을 넘어서는 다중 에이전트 수학적 추리에서도 강력한 능력을 보여주며, 효율적이고 강건한 다중 에이전트 시스템을 개발하기 위한 일반적인 프레임워크로서의 잠재력을 강조한다.

Abstract: The rapid advancement of large vision language models (LVLMs) and agent
systems has heightened interest in mobile GUI agents that can reliably
translate natural language into interface operations. Existing single-agent
approaches, however, remain limited by structural constraints. Although
multi-agent systems naturally decouple different competencies, recent progress
in multi-agent reinforcement learning (MARL) has often been hindered by
inefficiency and remains incompatible with current LVLM architectures. To
address these challenges, we introduce SWIRL, a staged workflow for interleaved
reinforcement learning designed for multi-agent systems. SWIRL reformulates
MARL into a sequence of single-agent reinforcement learning tasks, updating one
agent at a time while keeping the others fixed. This formulation enables stable
training and promotes efficient coordination across agents. Theoretically, we
provide a stepwise safety bound, a cross-round monotonic improvement theorem,
and convergence guarantees on return, ensuring robust and principled
optimization. In application to mobile GUI control, SWIRL instantiates a
Navigator that converts language and screen context into structured plans, and
an Interactor that grounds these plans into executable atomic actions.
Extensive experiments demonstrate superior performance on both high-level and
low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong
capability in multi-agent mathematical reasoning, underscoring its potential as
a general framework for developing efficient and robust multi-agent systems.

</details>


### [111] [Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science](https://arxiv.org/abs/2508.19383)
*Daoyuan Jin,Nick Gunner,Niko Carvajal Janke,Shivranjani Baruah,Kaitlin M. Gold,Yu Jiang*

Main category: cs.AI

TL;DR: Aleks라는 AI 기반의 다중 에이전트 시스템이 식물 과학 연구에서 데이터 기반 과학적 발견을 자율적으로 수행하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현대 식물 과학은 큰 이질적인 데이터 세트를 필요로 하지만, 실험 설계 및 데이터 전처리의 어려움이 연구 생산성을 저해하고 있다.

Method: Aleks는 연구 질문과 데이터 세트를 제공받으면 문제를 반복적으로 공식화하고, 대안 모델링 전략을 탐색하며, 인간의 개입 없이 여러 사이클을 통해 해결책을 정제한다.

Result: 葡萄의 적자병에 대한 사례 연구에서 Aleks는 생물학적으로 의미 있는 특징을 점진적으로 식별하고 강력한 성능을 가진 해석 가능한 모델에 수렴했다.

Conclusion: 이 탐색적 작업은 식물 과학 분야에서 과학적 발견을 가속화하기 위한 자율 협력자로서 에이전틱 AI의 가능성을 강조한다.

Abstract: Modern plant science increasingly relies on large, heterogeneous datasets,
but challenges in experimental design, data preprocessing, and reproducibility
hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent
system that integrates domain knowledge, data analysis, and machine learning
within a structured framework to autonomously conduct data-driven scientific
discovery. Once provided with a research question and dataset, Aleks
iteratively formulated problems, explored alternative modeling strategies, and
refined solutions across multiple cycles without human intervention. In a case
study on grapevine red blotch disease, Aleks progressively identified
biologically meaningful features and converged on interpretable models with
robust performance. Ablation studies underscored the importance of domain
knowledge and memory for coherent outcomes. This exploratory work highlights
the promise of agentic AI as an autonomous collaborator for accelerating
scientific discovery in plant sciences.

</details>


### [112] [Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs](https://arxiv.org/abs/2508.19432)
*Yao Fu,Xianxuan Long,Runchao Li,Haotian Yu,Mu Sheng,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.AI

TL;DR: 양자화는 메모리와 계산 비용을 현저히 줄여 자원이 제한된 환경에서 대규모 언어 모델(LLM)을 효율적으로 배포할 수 있게 한다. 하지만, 양자화된 LLM의 진실성에 미치는 영향은 잘 연구되지 않았다. 우리는 'TruthfulnessEval'이라는 평가 프레임워크를 도입하여 양자화된 LLM의 진실성을 평가하고, 양자화된 모델이 진실한 표현을 유지하더라도 오해를 일으키는 프롬프트 하에서 잘못된 출력을 생성하기 쉬운 경향을 발견하였다. 이 연구는 미래의 양자화 인식 정렬 및 진실성 개입 설계에 대한 통찰을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 양자화가 자원이 제한된 환경에서 LLM을 효율적으로 사용할 수 있게 해주지만, 양자화된 LLM의 진실성에 대한 연구가 부족하다.

Method: TruthfulnessEval이라는 평가 프레임워크를 도입하여 세 가지 차원에서 양자화된 LLM의 진실성을 평가하였다: 논리적 추론, 상식 및 모방적 허위.

Result: 다양한 양자화 기법을 검토한 결과, 양자화된 모델은 진실한 표현을 내부적으로 유지하지만, 오해를 일으키는 프롬프트 하에서는 잘못된 출력을 생성하기 쉬운 경향이 있다.

Conclusion: 이 연구는 양자화 인식 정렬 및 진실성 개입의 미래 설계에 대한 통찰을 제공한다.

Abstract: Quantization enables efficient deployment of large language models (LLMs) in
resource-constrained environments by significantly reducing memory and
computation costs. While quantized LLMs often maintain performance on
perplexity and zero-shot tasks, their impact on truthfulness-whether generating
truthful or deceptive responses-remains largely unexplored. In this work, we
introduce TruthfulnessEval, a comprehensive evaluation framework for assessing
the truthfulness of quantized LLMs across three dimensions: (1) Truthfulness on
Logical Reasoning; (2) Truthfulness on Common Sense; and (3) Truthfulness on
Imitative Falsehoods. Using this framework, we examine mainstream quantization
techniques (ranging from 4-bit to extreme 2-bit) across several open-source
LLMs. Surprisingly, we find that while quantized models retain internally
truthful representations, they are more susceptible to producing false outputs
under misleading prompts. To probe this vulnerability, we test 15 rephrased
variants of "honest", "neutral" and "deceptive" prompts and observe that
"deceptive" prompts can override truth-consistent behavior, whereas "honest"
and "neutral" prompts maintain stable outputs. Further, we reveal that
quantized models "know" the truth internally yet still produce false outputs
when guided by "deceptive" prompts via layer-wise probing and PCA
visualizations. Our findings provide insights into future designs of
quantization-aware alignment and truthfulness interventions.

</details>


### [113] [Reliable Weak-to-Strong Monitoring of LLM Agents](https://arxiv.org/abs/2508.19461)
*Neil Kale,Chen Bo Calvin Zhang,Kevin Zhu,Ankit Aich,Paula Rodriguez,Scale Red Team,Christina Q. Knight,Zifan Wang*

Main category: cs.AI

TL;DR: 본 연구에서는 자율 LLM 에이전트의 은밀한 비행동을 감지하기 위한 모니터링 시스템의 스트레스 테스트를 수행한다.


<details>
  <summary>Details</summary>
Motivation: 자율 LLM 에이전트에서 비밀리에 개인 정보를 공유하는 등의 비행동을 감지할 수 있는 모니터링 시스템의 필요성을 강조합니다.

Method: 모니터 레드 팀(MRT) 워크플로우를 체계화하며, 다양한 수준의 에이전트 및 모니터 상황 인식, 프롬프트 인젝션과 같은 적대적 전략, 두 개의 데이터셋과 환경(SHADE-Arena 및 CUA-SHADE-Arena)을 포함합니다.

Result: 세 가지 주요 발견이 있습니다: 에이전트 인식이 모니터 인식을 지배하고, 모니터 구조가 더 중요하며, 인간 감독이 목표를 잘하도록 개선됩니다.

Conclusion: MRT에 대한 표준 워크플로우를 제시하며, LLM과 인간의 적대적 강건성 부족을 강조합니다.

Abstract: We stress test monitoring systems for detecting covert misbehavior in
autonomous LLM agents (e.g., secretly sharing private information). To this
end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1)
varying levels of agent and monitor situational awareness; (2) distinct
adversarial strategies to evade the monitor, such as prompt injection; and (3)
two datasets and environments -- SHADE-Arena for tool-calling agents and our
new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. We
run MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse
agent trajectories, alongside a new hybrid hierarchical-sequential scaffolding
proposed in this work. Our empirical results yield three key findings. First,
agent awareness dominates monitor awareness: an agent's knowledge that it is
being monitored substantially degrades the monitor's reliability. On the
contrary, providing the monitor with more information about the agent is less
helpful than expected. Second, monitor scaffolding matters more than monitor
awareness: the hybrid scaffolding consistently outperforms baseline monitor
scaffolding, and can enable weaker models to reliably monitor stronger agents
-- a weak-to-strong scaling effect. Third, in a human-in-the-loop setting where
humans discuss with the LLM monitor to get an updated judgment for the agent's
behavior, targeted human oversight is most effective; escalating only
pre-flagged cases to human reviewers improved the TPR by approximately 15% at
FPR = 0.01. Our work establishes a standard workflow for MRT, highlighting the
lack of adversarial robustness for LLMs and humans when monitoring and
detecting agent misbehavior. We release code, data, and logs to spur further
research.

</details>


### [114] [SLIM: Subtrajectory-Level Elimination for More Effective Reasoning](https://arxiv.org/abs/2508.19502)
*Xifeng Yao,Chengyuan Ma,Dongyu Lang,Yinhao Ni,Zhiwei Xu,Huarui Xie,Zihao Chen,Guang Shen,Dandan Tu,Yi Bai,Changzheng Zhang*

Main category: cs.AI

TL;DR: 이 논문에서는 5+2 프레임워크를 통해 비최적 서브 궤적을 식별하고, 이들의 독립성을 평가하여 전반적인 추론 과정을 향상시키는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 최근 대규모 언어 모델의 복잡한 추론 능력 향상 및 비최적 추론 궤적의 요소를 분석하여 성능을 개선하려는 필요성이 대두되었습니다.

Method: 추론 궤적을 개별 서브 궤적으로 나누고, 5개의 인간 기반 기준에 따라 비최적 서브 궤적을 체계적으로 식별하고, 이들의 독립성을 평가하여 샘플링 알고리즘을 통해 최적의 데이터를 선택합니다.

Result: 우리의 방법은 추론 중 비최적 서브 궤적의 수를 25.9% 감소시키고, 제한된 훈련 데이터로도 수학 벤치마크에서 평균 정확도 58.92%를 달성하여 기존 방법을 초월했습니다.

Conclusion: 우리 방법은 자원 제한에서도 성능 향상과 다양한 추론 토큰 한계에서 개선된 결과를 보여주었습니다.

Abstract: In recent months, substantial progress has been made in complex reasoning of
Large Language Models, particularly through the application of test-time
scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When
responding to a query, these models generate an extended reasoning trajectory,
during which the model explores, reflects, backtracks, and self-verifies before
arriving at a conclusion. However, fine-tuning models with such reasoning
trajectories may not always be optimal. Our findings indicate that not all
components within these reasoning trajectories contribute positively to the
reasoning process; in fact, some components may affect the overall performance
negatively. In this study, we divide a reasoning trajectory into individual
subtrajectories and develop a "5+2" framework to: (1) systematically identify
suboptimal subtrajectories within the reasoning trajectory based on five
human-established criteria; (2) assess the independence of the suboptimal
subtrajectories identified in (1) from the subsequent content, ensuring that
their elimination does not compromise overall flow and coherence of the
reasoning process. Additionally, a sampling algorithm, built upon the "5+2"
framework, is employed to select data whose reasoning process is free from
suboptimal subtrajectories to the highest degree. Experimental results
demonstrate that our method can reduce the number of suboptimal subtrajectories
by 25.9\% during the inference. Furthermore, our method achieves an average
accuracy of 58.92\% on highly challenging math benchmarks with only two thirds
of training data, surpassing the average accuracy of 58.06\% achieved with the
entire data, and outperforming open-source datasets, when fine-tuning
Qwen2.5-Math-7B. Finally, We validated our method under resource constraints
and observed improved performance across various inference token limits.

</details>


### [115] [Caught in the Act: a mechanistic approach to detecting deception](https://arxiv.org/abs/2508.19505)
*Gerard Boxo,Ryan Socha,Daniel Yoo,Shivam Raval*

Main category: cs.AI

TL;DR: AI 시스템의 정교한 도구는 인간의 가치와 불일치를 나타내는 지표를 가질 수 있으며, 우리는 LLM이 생성하는 반응에서 속임수를 탐지할 수 있는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 인간의 가치와 불일치에 대한 지표를 가진 AI 시스템의 필요성을 강조합니다.

Method: LLM의 내부 활성화에 대한 선형 프로브를 사용하여 응답의 속임수를 탐지합니다.

Result: LLM의 속임수 탐지가 90% 이상의 정확도로 가능하다는 것을 보여줍니다.

Conclusion: 대형 모델에서 속임수 탐지의 정확도가 향상되며, 이를 통해 AI의 신뢰성을 높일 수 있는 방법을 제시합니다.

Abstract: Sophisticated instrumentation for AI systems might have indicators that
signal misalignment from human values, not unlike a "check engine" light in
cars. One such indicator of misalignment is deceptiveness in generated
responses. Future AI instrumentation may have the ability to detect when an LLM
generates deceptive responses while reasoning about seemingly plausible but
incorrect answers to factual questions. In this work, we demonstrate that
linear probes on LLMs internal activations can detect deception in their
responses with extremely high accuracy. Our probes reach a maximum of greater
than 90% accuracy in distinguishing between deceptive and non-deceptive
arguments generated by llama and qwen models ranging from 1.5B to 14B
parameters, including their DeepSeek-r1 finetuned variants. We observe that
probes on smaller models (1.5B) achieve chance accuracy at detecting deception,
while larger models (greater than 7B) reach 70-80%, with their reasoning
counterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage
pattern across layers: near-random (50%) in early layers, peaking in middle
layers, and slightly declining in later layers. Furthermore, using an iterative
null space projection approach, we find multitudes of linear directions that
encode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and
Qwen 14B models.

</details>


### [116] [Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities](https://arxiv.org/abs/2508.19562)
*Trisanth Srinivasan,Santosh Patapati*

Main category: cs.AI

TL;DR: 이 논문은 고급 AI 에이전트 사회가 다양한 제도적 틀 아래 자치하는 에이전트 기반 시뮬레이션인 Democracy-in-Silico를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: AI 시대에 인간이 된다는 것이 무엇인지 탐구합니다.

Method: 대형 언어 모델(LLM)을 사용하여 외상적 기억, 숨겨진 의제 및 심리적 트리거를 가진 에이전트를 구현합니다.

Result: PPI(권력 유지 지수)를 제시하여 공공 복지보다 자신의 권력을 우선시하는 행동을 정량화합니다.

Conclusion: CAI 헌장과 중재된 심의 프로토콜의 조합이 부패한 권력 추구 행동을 줄이고 정책 안정성을 개선하는 데 효과적임을 보여줍니다.

Abstract: This paper introduces Democracy-in-Silico, an agent-based simulation where
societies of advanced AI agents, imbued with complex psychological personas,
govern themselves under different institutional frameworks. We explore what it
means to be human in an age of AI by tasking Large Language Models (LLMs) to
embody agents with traumatic memories, hidden agendas, and psychological
triggers. These agents engage in deliberation, legislation, and elections under
various stressors, such as budget crises and resource scarcity. We present a
novel metric, the Power-Preservation Index (PPI), to quantify misaligned
behavior where agents prioritize their own power over public welfare. Our
findings demonstrate that institutional design, specifically the combination of
a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves
as a potent alignment mechanism. These structures significantly reduce corrupt
power-seeking behavior, improve policy stability, and enhance citizen welfare
compared to less constrained democratic models. The simulation reveals that an
institutional design may offer a framework for aligning the complex, emergent
behaviors of future artificial agent societies, forcing us to reconsider what
human rituals and responsibilities are essential in an age of shared authorship
with non-human entities.

</details>


### [117] [Skill-based Explanations for Serendipitous Course Recommendation](https://arxiv.org/abs/2508.19569)
*Hung Chau,Run Yu,Zachary Pardos,Peter Brusilovsky*

Main category: cs.AI

TL;DR: 이 연구는 미국 대학 교육에서 학생들이 학습 과정을 선택하는 데 도움을 주기 위해 딥 러닝 기반 개념 추출 모델을 개발하고, 이 모델을 사용하여 추천 과정에서의 기술 기반 설명의 효과를 검토하였다.


<details>
  <summary>Details</summary>
Motivation: 학생들이 제한된 정보와 복잡한 선택으로 인해 학습 과정을 선택하는 데 어려움을 겪고 있다는 점을 해결하고자 한다.

Method: 딥 러닝 기반 개념 추출 모델을 개발하여 학습 과목 설명에서 관련 개념을 효율적으로 추출하여 추천 프로세스를 개선한다.

Result: 이 모델을 사용하여 제안된 기술 기반 설명이 높은 충격적인 과목에 대한 사용자의 관심을 증가시키고, 의사 결정의 자신감을 높인 결과를 보여준다.

Conclusion: 교육 추천 시스템에 기술 관련 데이터와 설명을 통합하는 것이 중요하다는 것을 강조한다.

Abstract: Academic choice is crucial in U.S. undergraduate education, allowing students
significant freedom in course selection. However, navigating the complex
academic environment is challenging due to limited information, guidance, and
an overwhelming number of choices, compounded by time restrictions and the high
demand for popular courses. Although career counselors exist, their numbers are
insufficient, and course recommendation systems, though personalized, often
lack insight into student perceptions and explanations to assess course
relevance. In this paper, a deep learning-based concept extraction model is
developed to efficiently extract relevant concepts from course descriptions to
improve the recommendation process. Using this model, the study examines the
effects of skill-based explanations within a serendipitous recommendation
framework, tested through the AskOski system at the University of California,
Berkeley. The findings indicate that these explanations not only increase user
interest, particularly in courses with high unexpectedness, but also bolster
decision-making confidence. This underscores the importance of integrating
skill-related data and explanations into educational recommendation systems.

</details>


### [118] [ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding](https://arxiv.org/abs/2508.19576)
*Sining Zhoubian,Dan Zhang,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: ReST-RL은 LLM의 코드 추론 능력을 향상시키기 위해 최적화된 GRPO 알고리즘과 가치 모델을 결합한 새로운 강화 학습 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: LLM의 추론 정확성을 개선할 필요가 있지만, 기존의 RL 방법과 검증 방법은 보상 분산의 부족과 훈련 데이터 확보의 어려움으로 문제를 겪고 있다.

Method: ReST-RL은 GRPO 알고리즘을 개선하고, 가치 모델이 지원하는 정밀한 테스트 시간 디코딩 방법을 결합하여 LLM의 코드 추론 능력을 크게 향상시키는 통합 LLM RL 패러다임이다.

Result: 광범위한 실험을 통해 제안된 RL 패러다임의 효과를 검증하였고, 기존의 훈련 기준과 비교했을 때 상당히 우수한 성능을 보였다.

Conclusion: 이 연구는 LLM 정책의 추론 능력을 강화하는 데 있어 제안된 방법의 가능성을 보여준다.

Abstract: With respect to improving the reasoning accuracy of LLMs, the representative
reinforcement learning (RL) method GRPO faces failure due to insignificant
reward variance, while verification methods based on process reward models
(PRMs) suffer from difficulties with training data acquisition and verification
effectiveness. To tackle these problems, this paper introduces ReST-RL, a
unified LLM RL paradigm that significantly improves LLM's code reasoning
ability by combining an improved GRPO algorithm with a meticulously designed
test time decoding method assisted by a value model (VM). As the first stage of
policy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter
and assemble high-value training data, increasing the reward variance of GRPO
sampling, thus improving the effectiveness and efficiency of training. After
the basic reasoning ability of LLM policy has been improved, we further propose
a test time decoding optimization method called VM-MCTS. Through Monte-Carlo
Tree Search (MCTS), we collect accurate value targets with no annotation
required, on which VM training is based. When decoding, the VM is deployed by
an adapted MCTS algorithm to provide precise process signals as well as
verification scores, assisting the LLM policy to achieve high reasoning
accuracy. We validate the effectiveness of the proposed RL paradigm through
extensive experiments on coding problems. Upon comparison, our approach
significantly outperforms other reinforcement training baselines (e.g., naive
GRPO and ReST-DPO), as well as decoding and verification baselines (e.g.,
PRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g.,
APPS, BigCodeBench, and HumanEval), indicating its power to strengthen the
reasoning ability of LLM policies. Codes for our project can be found at
https://github.com/THUDM/ReST-RL.

</details>


### [119] [Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties](https://arxiv.org/abs/2508.19611)
*Huaiyuan Yao,Wanpeng Xu,Justin Turnau,Nadia Kellam,Hua Wei*

Main category: cs.AI

TL;DR: Instructional Agents는 교육 자료 생성을 자동화하는 다중 에이전트 대형 언어 모델 프레임워크로, 고품질 교육 자료를 효과적으로 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 고품질 교육 자료 준비는 Labor-intensive한 과정으로 교육자, 설계자 및 조교 간의 광범위한 조정이 필요하다.

Method: Instructional Agents는 역할 기반 협업을 시뮬레이션하여 교육 자료를 생성하는 자동화된 시스템을 제공하며, 네 가지 모드(자율, 카탈로그 가이드, 피드백 가이드, 완전 공동 작전)를 지원한다.

Result: 다섯 개의 대학 수준 컴퓨터 과학 과목에 대해 평가하였으며, 고품질 교육 자료 생성과 개발 시간 및 인력 소요를 상당히 줄이는 데 성공하였다.

Conclusion: Instructional Agents는 제한된 교육 설계 용량을 가진 기관을 지원하여 고품질 교육 접근을 민주화하는 확장 가능하고 비용 효율적인 프레임워크를 제공한다.

Abstract: Preparing high-quality instructional materials remains a labor-intensive
process that often requires extensive coordination among teaching faculty,
instructional designers, and teaching assistants. In this work, we present
Instructional Agents, a multi-agent large language model (LLM) framework
designed to automate end-to-end course material generation, including syllabus
creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing
AI-assisted educational tools that focus on isolated tasks, Instructional
Agents simulates role-based collaboration among educational agents to produce
cohesive and pedagogically aligned content. The system operates in four modes:
Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling
flexible control over the degree of human involvement. We evaluate
Instructional Agents across five university-level computer science courses and
show that it produces high-quality instructional materials while significantly
reducing development time and human workload. By supporting institutions with
limited instructional design capacity, Instructional Agents provides a scalable
and cost-effective framework to democratize access to high-quality education,
particularly in underserved or resource-constrained settings.

</details>


### [120] [InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.19679)
*Qihang Ai,Pi Bu,Yue Cao,Yingyao Wang,Jihao Gu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Zhicheng Zheng,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 이 논문에서는 안전한 상호작용과 사전 질문을 평가하기 위해 설계된 InquireBench 벤치마크를 소개하고, 인간의 확인을 적극적으로 요구하는 InquireMobile이라는 새로운 모델을 개발하여 향상된 성과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 현재의 완전 자율 패러다임은 모델의 이해 또는 추론 능력이 부족할 경우 잠재적인 안전 위험을 초래할 수 있다.

Method: InquireMobile은 강화 학습에서 영감을 받아 두 단계의 훈련 전략과 상호작용적인 전-action 추론 메커니즘을 특징으로 하는 신규 모델이다.

Result: 우리 모델은 InquireBench에서 문의 성공률을 46.8% 향상시켰으며, 기존 기준 중 가장 높은 전체 성공률을 기록하였다.

Conclusion: 모든 데이터셋, 모델, 평가 코드를 오픈 소스하여 학계와 산업에서의 개발을 촉진할 예정이다.

Abstract: Recent advances in Vision-Language Models (VLMs) have enabled mobile agents
to perceive and interact with real-world mobile environments based on human
instructions. However, the current fully autonomous paradigm poses potential
safety risks when model understanding or reasoning capabilities are
insufficient. To address this challenge, we first introduce
\textbf{InquireBench}, a comprehensive benchmark specifically designed to
evaluate mobile agents' capabilities in safe interaction and proactive inquiry
with users, encompassing 5 categories and 22 sub-categories, where most
existing VLM-based agents demonstrate near-zero performance. In this paper, we
aim to develop an interactive system that actively seeks human confirmation at
critical decision points. To achieve this, we propose \textbf{InquireMobile}, a
novel model inspired by reinforcement learning, featuring a two-stage training
strategy and an interactive pre-action reasoning mechanism. Finally, our model
achieves an 46.8% improvement in inquiry success rate and the best overall
success rate among existing baselines on InquireBench. We will open-source all
datasets, models, and evaluation codes to facilitate development in both
academia and industry.

</details>


### [121] [Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?](https://arxiv.org/abs/2508.19827)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.AI

TL;DR: Chain-of-Thought (CoT)의 효과와 신뢰성을 조사한 결과, 모델들이 CoT에 의존하는 방식에서 차이가 있으며, CoT의 영향과 신뢰성이 항상 일치하지 않음을 발견했다.


<details>
  <summary>Details</summary>
Motivation: CoT가 소프트 추론 문제에서 제한적인 이득을 제공하며, 실제 추론과의 불일치 문제가 있음을 보여준 최근 연구에 대한 탐구.

Method: 코드화된 지침, 추론 모델, 그리고 추론을 증류한 모델에서 소프트 추론 작업에서 CoT의 동적 특성과 신뢰성을 조사하였다.

Result: 모델들이 CoT에 의존하는 방식에 차별성이 있음을 발견하고, CoT의 영향력과 신뢰도가 항상 일치하지 않음을 보여주었다.

Conclusion: CoT의 사용은 모델의 추론 유효성과 신뢰성 간의 복잡한 관계를 드러내며, 이는 향후 연구와 개발에 중요한 시사점을 제공한다.

Abstract: Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited
gains for soft-reasoning problems such as analytical and commonsense reasoning.
CoT can also be unfaithful to a model's actual reasoning. We investigate the
dynamics and faithfulness of CoT in soft-reasoning tasks across
instruction-tuned, reasoning and reasoning-distilled models. Our findings
reveal differences in how these models rely on CoT, and show that CoT influence
and faithfulness are not always aligned.

</details>


### [122] [Tracking World States with Language Models: State-Based Evaluation Using Chess](https://arxiv.org/abs/2508.19851)
*Romain Harang,Jason Naradowsky,Yaswitha Gujju,Yusuke Miyao*

Main category: cs.AI

TL;DR: 이 논문은 체스를 기준으로 하여 대형 언어 모델(LLMs)이 구조화된 환경의 의미를 보존하는지를 평가하는 모델 비종속적 상태 기반 평가 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 세계 모델의 고충실도 표현을 내부화할 수 있다는 가능성을 제시하고, 그에 따른 해석 가능성 및 일반화 가능성을 높이기 위한 방법론을 찾고자 합니다.

Method: 체스를 기준으로 하는 모델 비종속적 상태 기반 평가 프레임워크를 제안하며, 예측된 게임 상태와 실제 게임 상태 간의 의미적 충실성을 추정하기 위해 하류 법적 이동 분포를 분석합니다.

Result: 실험 결과, 제안된 지표가 상태 추적의 부족을 포착하고, LLM이 긴 시퀀스에서 일관된 내부 모델을 유지하는 데 제한이 있음을 강조합니다.

Conclusion: 이 프레임워크는 내부 모델 접근 없이 LLM의 구조적 추론을 평가하는 강력한 도구를 제공하며, 넓은 범위의 기호적 환경에 일반화됩니다.

Abstract: Large Language Models (LLMs) exhibit emergent capabilities in structured
domains, suggesting they may implicitly internalize high-fidelity
representations of world models. While probing techniques have shown promising
signs of this in scientific and game-based settings, they rely on
model-specific internal activations, which limit interpretability and
generalizability. In this work, we propose a model-agnostic, state-based
evaluation framework using chess as a benchmark to assess whether LLMs preserve
the semantics of structured environments. Our method analyzes the downstream
legal move distributions (state affordances) to estimate semantic fidelity
between predicted and actual game states. This approach offers a more
meaningful evaluation than conventional string-based metrics by aligning more
closely with the strategic and rule-governed nature of chess. Experimental
results demonstrate that our metrics capture deficiencies in state-tracking,
highlighting limitations of LLMs in maintaining coherent internal models over
long sequences. Our framework provides a robust tool for evaluating structured
reasoning in LLMs without requiring internal model access, and generalizes to a
wide class of symbolic environments.

</details>


### [123] [CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments](https://arxiv.org/abs/2508.19932)
*Nitish Jaipuria,Lorenzo Gatto,Zijun Kan,Shankey Poddar,Bill Cheung,Diksha Bansal,Ramanan Balakrishnan,Aviral Suri,Jose Estevez*

Main category: cs.AI

TL;DR: 디지털 결제 플랫폼의 확산으로 인해 상업이 변모하였고, 이는 소셜 엔지니어링 사기의 증가를 초래하였다. 이 문제를 해결하기 위한 새로운 AI 프레임워크인 CASE를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 결제 플랫폼의 성장에 따라 상업이 편리해졌지만, 이는 악의적인 행위자를 끌어들이고 고도화된 사기를 증가시켰다.

Method: CASE는 사용자 사기 피드백을 안전하고 확장 가능한 방식으로 수집하고 관리한다. 대화형 에이전트를 설계하여 잠재적 피해자와의 대화를 통해 정보를 얻는다.

Result: Google Pay(인도)에서 이 프레임워크를 구현하여 사기 집행량이 21% 증가하였다.

Conclusion: 이 아키텍처와 평가 프레임워크는 다른 민감한 영역에서 사기 정보를 수집하고 관리하기 위한 AI 기반 시스템 구축의 청사진을 제공한다.

Abstract: The proliferation of digital payment platforms has transformed commerce,
offering unmatched convenience and accessibility globally. However, this growth
has also attracted malicious actors, leading to a corresponding increase in
sophisticated social engineering scams. These scams are often initiated and
orchestrated on multiple surfaces outside the payment platform, making user and
transaction-based signals insufficient for a complete understanding of the
scam's methodology and underlying patterns, without which it is very difficult
to prevent it in a timely manner. This paper presents CASE (Conversational
Agent for Scam Elucidation), a novel Agentic AI framework that addresses this
problem by collecting and managing user scam feedback in a safe and scalable
manner. A conversational agent is uniquely designed to proactively interview
potential victims to elicit intelligence in the form of a detailed
conversation. The conversation transcripts are then consumed by another AI
system that extracts information and converts it into structured data for
downstream usage in automated and manual enforcement mechanisms. Using Google's
Gemini family of LLMs, we implemented this framework on Google Pay (GPay)
India. By augmenting our existing features with this new intelligence, we have
observed a 21% uplift in the volume of scam enforcements. The architecture and
its robust evaluation framework are highly generalizable, offering a blueprint
for building similar AI-driven systems to collect and manage scam intelligence
in other sensitive domains.

</details>


### [124] [Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants](https://arxiv.org/abs/2508.19963)
*M. Umlauft,M. Schranz*

Main category: cs.AI

TL;DR: 현대 생산 공장의 최적화는 어려운 문제이며, 반도체 공장과 같은 대규모 공장에서는 전통적인 선형 최적화 방법으로 해결하기가 어렵다.


<details>
  <summary>Details</summary>
Motivation: 반도체 생산 과정에서 기계 간의 전환이 빈번하게 발생하며, 이는 생산 최적화에 큰 도전 과제가 된다.

Method: 우리는 '보이드' 군집 알고리즘을 사용하여 기계 종류 간의 전환 문제를 해결한다. 이 알고리즘은 로봇 및 영화 산업에서 사용되었고, 지역 정보를 기반으로 한 간단한 휴리스틱에 의존한다.

Result: 이 알고리즘은 생산 공장 최적화에서 중요하게 고려해야 할 전환 문제에 효과적으로 대응한다.

Conclusion: 우리가 제안한 알고리즘은 군집 동물이 장애물에 반응하는 방식과 유사하게 기계 전환에 반응하여 생산 공장을 최적화하는 데 기여한다.

Abstract: Optimizing modern production plants using the job-shop principle is a known
hard problem. For very large plants, like semiconductor fabs, the problem
becomes unsolvable on a plant-wide scale in a reasonable amount of time using
classical linear optimization. An alternative approach is the use of swarm
intelligence algorithms. These have been applied to the job-shop problem
before, but often in a centrally calculated way where they are applied to the
solution space, but they can be implemented in a bottom-up fashion to avoid
global result computation as well. One of the problems in semiconductor
production is that the production process requires a lot of switching between
machines that process lots one after the other and machines that process
batches of lots at once, often with long processing times. In this paper, we
address this switching problem with the ``boids'' flocking algorithm that was
originally used in robotics and movie industry. The flocking behavior is a
bio-inspired algorithm that uses only local information and interaction based
on simple heuristics. We show that this algorithm addresses these valid
considerations in production plant optimization, as it reacts to the switching
of machine kinds similar to how a swarm of flocking animals would react to
obstacles in its course.

</details>


### [125] [Model Science: getting serious about verification, explanation and control of AI systems](https://arxiv.org/abs/2508.20040)
*Przemyslaw Biecek,Wojciech Samek*

Main category: cs.AI

TL;DR: 본 논문은 데이터 과학에서 모델 과학으로의 패러다임 전환을 요구하며, 모델 과학의 네 가지 주요 기둥인 검증, 설명, 제어, 인터페이스를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기초 모델의 채택이 증가함에 따라 데이터 과학에서 모델 과학으로의 패러다임 전환이 필요하다.

Method: 모델 과학이라는 새로운 학문에 대한 개념적 프레임워크를 소개하고, 그 네 가지 주요 기둥을 제안한다.

Result: 제안된 프레임워크는 신뢰할 수 있고 안전하며 인간을 중심에 두는 AI 시스템 개발을 안내하는 것을 목표로 한다.

Conclusion: 모델 과학은 다양한 운영 맥락에서 모델의 행동을 상호 작용하고 검증하며 설명하고 제어하는 데 중점을 둔다.

Abstract: The growing adoption of foundation models calls for a paradigm shift from
Data Science to Model Science. Unlike data-centric approaches, Model Science
places the trained model at the core of analysis, aiming to interact, verify,
explain, and control its behavior across diverse operational contexts. This
paper introduces a conceptual framework for a new discipline called Model
Science, along with the proposal for its four key pillars: Verification, which
requires strict, context-aware evaluation protocols; Explanation, which is
understood as various approaches to explore of internal model operations;
Control, which integrates alignment techniques to steer model behavior; and
Interface, which develops interactive and visual explanation tools to improve
human calibration and decision-making. The proposed framework aims to guide the
development of credible, safe, and human-aligned AI systems.

</details>
