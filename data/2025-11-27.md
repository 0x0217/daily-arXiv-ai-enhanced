<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.CR](#cs.CR) [Total: 9]
- [cs.LG](#cs.LG) [Total: 23]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Fara-7B: An Efficient Agentic Model for Computer Use](https://arxiv.org/abs/2511.19663)
*Ahmed Awadallah,Yash Lara,Raghav Magazine,Hussein Mozannar,Akshay Nambi,Yash Pandya,Aravind Rajeswaran,Corby Rosset,Alexey Taymanov,Vibhav Vineet,Spencer Whitehead,Andrew Zhao*

Main category: cs.AI

TL;DR: 새로운 합성 데이터 생성 시스템인 FaraGen을 소개하며, 이를 통해 CUA 모델인 Fara-7B를 개발하였다. Fara-7B는 작은 크기로도 효과적으로 웹 작업을 수행하며, 기존의 CUA 모델보다 성능이 우수하다.


<details>
  <summary>Details</summary>
Motivation: CUA의 발전은 인간과 컴퓨터의 상호작용을 반영하는 대규모의 고품질 데이터셋의 부족에 의해 제한받고 있다.

Method: FaraGen은 다양한 작업을 제안하고, 여러 솔루션 시도를 생성하며, 성공적인 경로를 필터링하는 합성 데이터 생성 시스템이다. 이를 통해 Fara-7B를 훈련시킨다.

Result: Fara-7B는 WebVoyager, Online-Mind2Web 및 새로운 벤치마크인 WebTailBench에서 유사한 크기의 다른 CUA 모델보다 우수한 성능을 보인다.

Conclusion: Fara-7B는 훨씬 더 큰 모델과 경쟁력을 갖추고 있으며, 소규모 효율적인 에이전트 모델의 발전을 위해 스케일 가능한 데이터 생성 시스템의 주요 이점을 보여준다.

Abstract: Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists for CUA trajectories. To address these gaps, we introduce FaraGen, a novel synthetic data generation system for multi-step web tasks. FaraGen can propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multiple verifiers. It achieves high throughput, yield, and diversity for multi-step web tasks, producing verified trajectories at approximately $1 each. We use this data to train Fara-7B, a native CUA model that perceives the computer using only screenshots, executes actions via predicted coordinates, and is small enough to run on-device. We find that Fara-7B outperforms other CUA models of comparable size on benchmarks like WebVoyager, Online-Mind2Web, and WebTailBench -- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are making Fara-7B open-weight on Microsoft Foundry and HuggingFace, and we are releasing WebTailBench.

</details>


### [2] [HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization](https://arxiv.org/abs/2511.19669)
*Souradip Poddar,Chia-Tung Ho,Ziming Wei,Weidong Cao,Haoxing Ren,David Z. Pan*

Main category: cs.AI

TL;DR: HeaRT는 고전적인 AI 기반 AMS 설계 자동화 알고리즘의 한계를 극복하고, 지능적이며 적응 가능한 설계 최적화를 위한 첫 단계를 제안하는 기초적 추론 엔진이다.


<details>
  <summary>Details</summary>
Motivation: 일반적인 AI 기반 AMS 설계 자동화 알고리즘은 회로 동작을 포착하기 위한 고품질 데이터셋에 의존하고, 아키텍처 간 전이성이 낮으며, 적응 메커니즘이 부족하다는 제약이 있다.

Method: HeaRT는 자동화 루프를 위한 기초적 추론 엔진으로서, 인간 스타일의 지능적 설계 최적화를 위한 첫 단계를 제안한다.

Result: HeaRT는 40회로 벤치마크 저장소 전반에 걸쳐 추론 정확도가 97% 이상, Pass@1 성능이 98% 이상을 지속적으로 보여준다.

Conclusion: HeaRT는 다양한 최적화 접근 방식에서 설계 의도를 유지하면서 사이징 및 토폴로지 설계 적응 작업에서 3배 이상의 빠른 수렴을 나타낸다.

Abstract: Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.

</details>


### [3] [Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs](https://arxiv.org/abs/2511.19773)
*Meng Lu,Ran Xu,Yi Fang,Wenxuan Zhang,Yue Yu,Gaurav Srivastava,Yuchen Zhuang,Mohamed Elhoseiny,Charles Fleming,Carl Yang,Zhengzhong Tu,Yang Xie,Guanghua Xiao,Hanrui Wang,Di Jin,Wenqi Shi,Xuan Wang*

Main category: cs.AI

TL;DR: VISTA-Gym은 VLM의 도구 통합 시각 추론 능력을 향상시키기 위한 확장 가능한 훈련 환경을 제공하며, 실험을 통해 VISTA-R1이 최첨단 성능을 초월함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 최근 비전-언어 모델(VLM)이 강력한 이미지 이해 능력을 보여주지만 이미지를 통해 사고하는 능력이 제한적이기 때문이다.

Method: VISTA-Gym은 시각 도구를 위한 표준 인터페이스와 상호작용 루프, 검증 가능한 피드백 신호 등을 통합하여 다양한 멀티모달 추론 작업을 지원한다.

Result: VISTA-R1은 11개의 공공 VQA 벤치마크에서 9.51%-18.72%의 성능 향상을 보여주었으며, 이는 도구 통합 추론 능력을 향상시키는 데 효과적인 훈련 환경임을 나타낸다.

Conclusion: VISTA-Gym은 VLM의 도구 통합 추론 능력을 개방하는 효과적인 훈련 공간으로 작용한다.

Abstract: While recent vision-language models (VLMs) demonstrate strong image understanding, their ability to "think with images", i.e., to reason through multi-step visual interactions, remains limited. We introduce VISTA-Gym, a scalable training environment for incentivizing tool-integrated visual reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal reasoning tasks (7 tasks from 13 datasets in total) with a standardized interface for visual tools (e.g., grounding, parsing), executable interaction loops, verifiable feedback signals, and efficient trajectory logging, enabling visual agentic reinforcement learning at scale. While recent VLMs exhibit strong text-only reasoning, both proprietary and open-source models still struggle with tool selection, invocation, and coordination. With VISTA-Gym, we train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn trajectory sampling and end-to-end reinforcement learning. Extensive experiments across 11 public reasoning-intensive VQA benchmarks show that VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by 9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock the tool-integrated reasoning capabilities for VLMs.

</details>


### [4] [NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent Understanding in Mobile Agents](https://arxiv.org/abs/2511.19780)
*Ioannis Tzachristas,Aifen Sui*

Main category: cs.AI

TL;DR: 인공지능 모바일 에이전트를 위한 다중 의도 이해를 위한 신경-기호 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 다중 의도 이해를 위한 구조화된 의도 온톨로지와 콤팩트한 언어 모델을 통합하여 모바일 AI 에이전트의 성능을 향상시키기 위해.

Method: 회수 증강 프롬프트, 로짓 편향 및 선택적 분류 헤드를 이용해 입력과 출력 표현 모두에 기호적 의도 구조를 주입하는 방법.

Result: MultiWOZ 2.3의 모호하고 요구가 높은 대화에서 실험을 통해, 온톨로지 증강이 된 3B Llama 모델이 GPT-4의 정확도에 접近했다.

Conclusion: 기호적 정렬이 정확하고 효율적인 온디바이스 자연어 이해를 가능하게 하는 효과적인 전략이라는 것을 검증했다.

Abstract: We introduce a neuro-symbolic framework for multi-intent understanding in mobile AI agents by integrating a structured intent ontology with compact language models. Our method leverages retrieval-augmented prompting, logit biasing and optional classification heads to inject symbolic intent structure into both input and output representations. We formalize a new evaluation metric-Semantic Intent Similarity (SIS)-based on hierarchical ontology depth, capturing semantic proximity even when predicted intents differ lexically. Experiments on a subset of ambiguous/demanding dialogues of MultiWOZ 2.3 (with oracle labels from GPT-o3) demonstrate that a 3B Llama model with ontology augmentation approaches GPT-4 accuracy (85% vs 90%) at a tiny fraction of the energy and memory footprint. Qualitative comparisons show that ontology-augmented models produce more grounded, disambiguated multi-intent interpretations. Our results validate symbolic alignment as an effective strategy for enabling accurate and efficient on-device NLU.

</details>


### [5] [KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)](https://arxiv.org/abs/2511.19798)
*Weizhi Liu,Xi Chen,Zekun Jiang,Liang Zhao,Kunyuan Jiang,Ruisi Tang,Li Wang,Mingke You,Hanyu Zhou,Hongyu Chen,Qiankun Xiong,Yong Nie,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: KOM이라는 다중 에이전트 시스템은 무릎 골관절염(KOA)의 평가, 위험 예측 및 치료 처방을 자동화하여 임상 의사에게 도움을 주며, 진단 및 계획 시간을 38.5% 단축시키고 치료 품질을 개선하는 데 기여할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 전 세계적으로 6억 명 이상의 사람이 사는 KOA는 심각한 통증과 기능 장애를 유발하기 때문에 개인 맞춤형 다학제적 접근이 필요하다.

Method: KOM은 KOA의 평가, 위험 예측, 치료 처방을 자동화하도록 설계된 다중 에이전트 시스템이다.

Result: KOM은 영상 분석 및 처방 생성을 위한 여러 일반 목적의 대형 언어 모델보다 우수한 성능을 보여주었고, 임상의와 협력할 때 진단 및 계획 시간을 38.5% 단축시켜 치료 품질을 높였다.

Conclusion: KOM은 KOA 관리의 자동화를 촉진하고 임상 작업 흐름에 통합될 때 치료 효율성을 향상시킬 잠재력을 가지고 있다.

Abstract: Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.

</details>


### [6] [Agentic AI-Empowered Conversational Embodied Intelligence Networks in 6G](https://arxiv.org/abs/2511.19865)
*Mingkai Chen,Zijie Feng,Lei Wang,Yaser Khamayseh*

Main category: cs.AI

TL;DR: 6G 시대에 여러 지능형 장치 간의 의미적 협력이 복잡한 작업 수행을 위해 필수적이다. 그러나 기존 시스템은 다중 모드 정보 융합, 적응형 통신 및 의사결정 해석 가능성에서 문제에 직면하고 있다.


<details>
  <summary>Details</summary>
Motivation: 6G 시대의 복잡한 작업 수행을 위한 여러 지능형 장치 간의 협력이 중요하기 때문이다.

Method: 다중 모드 기능 융합, 적응형 의미 통신, 작업 조정 및 해석 가능성을 통합한 Collaborative Conversational Embodied Intelligence Network (CC-EIN)을 제안한다.

Result: CC-EIN은 95.4%의 작업 완료율과 95%의 전송 효율을 달성한다.

Conclusion: 강력한 의미 일관성과 에너지 효율성을 유지하면서도 의사결정 투명성을 개선하고 있다.

Abstract: In the 6G era, semantic collaboration among multiple embodied intelligent devices (MEIDs) becomes crucial for complex task execution. However, existing systems face challenges in multimodal information fusion, adaptive communication, and decision interpretability. To address these limitations, we propose a collaborative Conversational Embodied Intelligence Network (CC-EIN) integrating multimodal feature fusion, adaptive semantic communication, task coordination, and interpretability. PerceptiNet performs cross-modal fusion of image and radar data to generate unified semantic representations. An adaptive semantic communication strategy dynamically adjusts coding schemes and transmission power according to task urgency and channel quality. A semantic-driven collaboration mechanism further supports task decomposition and conflict-free coordination among heterogeneous devices. Finally, the InDec module enhances decision transparency through Grad-CAM visualization. Simulation results in post-earthquake rescue scenarios demonstrate that CC-EIN achieves 95.4% task completion rate and 95% transmission efficiency while maintaining strong semantic consistency and energy efficiency.

</details>


### [7] [VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis](https://arxiv.org/abs/2511.20085)
*Chujie Wang,Zhiyuan Luo,Ruiqi Liu,Can Ran,Shenghua Fan,Xi Chen,Chu He*

Main category: cs.AI

TL;DR: VICoT는 원격 센싱 이미지 분석을 위해 비주얼 도구를 동적으로 통합하여 다중 라운드 추론을 구현하는 새로운 멀티모달 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 물체 인식에서 복잡한 지능형 추론으로의 변화가 진행됨에 따라 모델의 추론 능력과 도구 호출의 유연성에 대한 요구가 증가하고 있다.

Method: VICoT는 시각적 도구를 사고의 연쇄에 동적으로 통합하여 명시적인 다중 라운드 추론을 구현하는 스택 기반의 추론 구조와 모듈형 도구 모음을 사용한다.

Result: VICoT는 다수의 원격 센싱 벤치마크 실험에서 기존 SOTA 프레임워크를 초월하여 추론 투명성, 실행 효율성, 그리고 생성 품질에서 유의미한 향상을 보여준다.

Conclusion: 이 방법론은 복잡한 에이전트 행동을 작고 경량의 모델로 마이그레이션하여 추론 능력을 보장하면서 복잡성을 상당히 줄인다.

Abstract: The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.

</details>


### [8] [M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation](https://arxiv.org/abs/2511.19969)
*Weizi Shao,Taolin Zhang,Zijie Zhou,Chen Chen,Chengyu Wang,Xiaofeng He*

Main category: cs.AI

TL;DR: 본 논문에서는 효율적인 다중 대화형 통신이 가능한 M$^3$Prune 프레임워크를 제안하며, 이를 통해 토큰 오버헤드를 줄이면서 성능을 개선할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템이 단일 모델보다 뛰어난 성능을 보이지만, 기존 시스템은 토큰 오버헤드와 계산 비용이 증가하는 문제를 안고 있다.

Method: M$^3$Prune 프레임워크는 서로 다른 모달리티 간의 중복 엣지를 제거하고, 텍스트 및 비주얼 모달리티에 대한 내부 그래프 희소화를 통해 중요한 엣지를 식별한 후, 동적 통신 토폴로지를 구성하여 외부 모달리티 간의 희소화를 수행한다.

Result: 제안된 방법은 단일 에이전트 및 강력한 다중 에이전트 mRAG 시스템을 지속적으로 초월하며 토큰 소비를 크게 줄인다.

Conclusion: M$^3$Prune 프레임워크는 다중 모달리티 시스템의 성능을 개선하고, 대규모 배포에 적합하도록 효율성을 향상시킨다.

Abstract: Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.

</details>


### [9] [Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design](https://arxiv.org/abs/2511.20048)
*Zixiao Huang,Wen Zeng,Tianyu Fu,Tengxuan Liu,Yizhou Sun,Ke Hong,Xinhao Yang,Chengchun Liu,Yan Li,Quanlu Zhang,Guohao Dai,Zhenhua Zhu,Yu Wang*

Main category: cs.AI

TL;DR: SPAgent는 검색 에이전트의 지연 시간을 줄이기 위해 두 단계의 적응형 투기를 도입하는 알고리즘-시스템 공동 설계 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 검색 에이전트는 강력한 성능을 달성하지만, 각 단계가 직렬 LLM 추론과 도구 실행을 필요로 하여 심각한 지연 시간을 겪는다.

Method: SPAgent는 두 단계의 적응형 투기 메커니즘을 도입하고, 시스템 차원에서는 엔진 부하에 따라 투기 요청을 조절하는 두 레벨 스케줄러를 사용한다.

Result: SPAgent는 다양한 실험 설정에서 최대 $1.65	imes$의 종단 간 속도 향상을 달성하였으며, 동일하거나 더 높은 정확도를 유지한다.

Conclusion: 이를 통해 SPAgent는 다단계 검색 에이전트의 실제 배포를 가능하게 한다.

Abstract: LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.

</details>


### [10] ["Are We Done Yet?": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents](https://arxiv.org/abs/2511.20067)
*Marta Sumyk,Oleksandr Kosovan*

Main category: cs.AI

TL;DR: CUA(컴퓨터 사용 에이전트)는 디지털 인터페이스를 자율적으로 운영하도록 설계되었으나, 주어진 작업의 완료 여부를 신뢰성 있게 판단하는 데 종종 실패한다. 본 연구에서는 스크린샷과 작업 설명을 사용하여 작업 완료를 직접 평가하는 자율 평가 및 피드백 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: CUA의 신뢰성을 높이기 위한 자율 평가 방법의 필요성

Method: 비전-언어 모델을 사용하여 스크린샷과 작업 설명으로부터 작업 완료를 평가하는 프레임워크를 구축하였다.

Result: 작업 성공 탐지에서 최대 73%의 정확도를 달성했으며, 평가자 피드백을 적용했을 때 전체 작업 성공률이 평균 27% 향상되었다.

Conclusion: 비전 기반 평가가 자율 컴퓨터 사용 에이전트의 신뢰성과 자기 수정 능력을 향상시키는 효과적인 피드백 메커니즘이 될 수 있음을 보여준다.

Abstract: Computer Use Agents (CUAs) are designed to autonomously operate digital interfaces, yet they often fail to reliably determine whether a given task has been completed. We present an autonomous evaluation and feedback framework that uses vision-language models to assess task completion directly from screenshots and task descriptions. Our dataset covers 42 built-in macOS applications and 1,260 human-labeled tasks across a wide range of scenarios. Our framework achieves up to 73 percent accuracy in task success detection and yields an average relative improvement of 27 percent in overall task success when evaluator feedback is applied. These results show that vision-based evaluation can serve as an effective feedback mechanism that improves the reliability and self-correction of autonomous computer-use agents.

</details>


### [11] [From data to concepts via wiring diagrams](https://arxiv.org/abs/2511.20138)
*Jason Lo,Mohammadnima Jafari*

Main category: cs.AI

TL;DR: 본 논문에서는 준-스켈레톤 배선 도면 그래프의 개념을 소개하고, 이들이 하세 도표에 대응함을 증명하였다. 이 결과를 이용해 순차 데이터를 기반으로 배선 도면을 추출하는 알고리즘을 설계하였으며, 자율 에이전트의 게임 행동 분석에 적용하여 승리 전략을 정확히 파악하였다.


<details>
  <summary>Details</summary>
Motivation: 배선 도면은 시간적 과정과 같은 추상 개념을 표현하는 데 사용됩니다. 이 논문은 이러한 배선 도면을 활용하여 데이터에서 중요한 패턴을 식별하는 방법을 제시합니다.

Method: 준-스켈레톤 배선 도면 그래프의 개념을 도입하고, 이들이 하세 도표에 대응함을 증명하며, 이를 바탕으로 알고리즘을 설계하여 순차 데이터에서 배선 도면을 추출합니다.

Result: 자율 에이전트가 게임을 하는 행동을 분석할 때, 설계한 알고리즘이 승리 전략을 정확히 식별했습니다. 또한, 본 알고리즘의 성능을 표준 클러스터링 기법에 기반한 두 알고리즘과 비교하였습니다.

Conclusion: 이 논문은 범주 이론, 그래프 이론, 클러스터링, 강화 학습 및 데이터 엔지니어링과 같은 기술들을 융합하여 다양한 분야에서의 응용 가능성을 제시합니다.

Abstract: A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.

</details>


### [12] [CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents](https://arxiv.org/abs/2511.20216)
*Haebin Seong,Sungmin Kim,Minchan Kim,Yongjun Cho,Myunchul Joe,Suhwan Choi,Jaeyoon Jung,Jiyong Youn,Yoonshik Kim,Samwoo Seong,Yubeen Park,Youngjae Yu,Yunsung Lee*

Main category: cs.AI

TL;DR: 기존 내비게이션 벤치마크는 작업 성공 지표에 집중하면서 자율 배달 로봇의 상업적 배치에 중요한 경제적 유효성을 간과하고 있다. 우리는 기업의 운영에 맞춘 전체 비용-수익 분석을 통해 내장된 에이전트를 평가하는 	extit{CostNav}, 즉 	extbf{마이크로 내비게이션 경제 테스트베드}를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 내비게이션 연구가 실질적인 상업적 배포와 경제적 유효성을 간과하는 문제를 해결하기 위해 개발되었다.

Method: CostNav는 하드웨어, 교육, 에너지, 유지 보수 비용 및 서비스 수준 계약을 포함한 배송 수익을 포괄하는 완전한 경제적 생애 주기를 모델링한다.

Result: 기초 라인이 43.0% SLA 준수를 달성했지만, 운영 비용이 충돌로 인한 유지 보수에 의해 지배되기 때문에 상업적으로 유효하지 않으며, 이는 각 실행당 30,009달러의 손실을 가져온다.

Conclusion: CostNav는 내비게이션 연구와 상업적 배달 간의 격차를 해소하여 내비게이션 패러다임 전반에 걸쳐 경제적 거래에 대한 데이터 기반 결정을 가능하게 한다.

Abstract: Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \emph{CostNav}, a \textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\% SLA compliance but is \emph{not} commercially viable: yielding a loss of \$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.

</details>


### [13] [Improving Language Agents through BREW](https://arxiv.org/abs/2511.20297)
*Shashank Kirtania,Param Biyani,Priyanshu Gupta,Yasharth Bajpai,Roshni Iyer,Sumit Gulwani,Gustavo Soares*

Main category: cs.AI

TL;DR: 이 논문에서는 대규모 언어 모델(LLM) 기반 에이전트의 최적화를 위한 새로운 접근법인 BREW 프레임워크를 제안하며, 이는 경험 학습의 구조화된 메모리를 통해 에이전트 정책을 해석 가능하고 효율적으로 개선하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트는 점점 더 복잡한 작업에 사용되고 있지만, 기존의 최적화 방법들은 계산 비용이 높고 해석하기 어렵다.

Method: 이 논문에서는 BREW라는 프레임워크를 소개하며, 이를 통해 에이전트의 메모리를 효과적으로 분할하고 검색 및 개선이 용이하도록 한다.

Result: BREW는 실세계 기준에서 작업 정확도를 10-20% 향상시키고 API 호출을 10-15% 줄이며 빠른 실행 시간을 유지하였고, 기본 모델과의 계산 효율성 또한 유지했다.

Conclusion: 메모리를 정적 맥락으로 처리했던 이전 작업과 달리, BREW는 에이전트 최적화를 위한 모듈형이고 제어 가능한 기초 자료로 지식을 설정하여 행동을 투명하고 해석 가능하며 확장 가능하게 만드는 구체적 수단이 된다.

Abstract: Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $τ^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\%$ improvement in task precision, $10-15\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.

</details>


### [14] [DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs](https://arxiv.org/abs/2511.20468)
*Yuanhao Li,Mingshan Liu,Hongbo Wang,Yiding Zhang,Yifei Ma,Wei Tan*

Main category: cs.AI

TL;DR: DRAFT-RL은 멀티 에이전트 강화 학습 훈련에 CoD 추론을 통합한 새로운 프레임워크로, 각 에이전트가 여러 초안을 생성하고 동료 에이전트와 보상 모델을 통해 평가하여 최적의 경로를 찾아내는 방식으로 더 강력하고 해석 가능한 LLM 에이전트 행동을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 멀티 에이전트 반영 프레임워크가 단일 응답에 의존하고 추론 탐색의 구조적 다양성이 부족한 문제를 해결하고자 한다.

Method: DRAFT-RL 프레임워크를 통해 각 에이전트가 쿼리당 여러 초안을 생성하고 이를 동료 에이전트와 학습된 보상 모델로 평가하여 최적의 경로를 선정한다.

Result: DRAFT-RL은 코드 합성, 기호 수학, 지식 집약적 QA와 같은 복잡한 추론 작업에서 기존의 반영 및 RL 기반 에이전트보다 정확도와 수렴 속도 모두에서 유의미한 성과를 낸다.

Conclusion: DRAFT-RL은 더 강력하고 해석 가능한 LLM 에이전트 행동을 가능하게 하며, 명시적인 다중 경로 탐색과 피어 가이드 반영, 보상 정렬 선택을 통해 성과를 높인다.

Abstract: Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed

</details>


### [15] [FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization](https://arxiv.org/abs/2511.20510)
*Yuto Suzuki,Paul Awolade,Daniel V. LaBarbera,Farnoush Banaei-Kashani*

Main category: cs.AI

TL;DR: FRAGMENTA는 약물 발견을 위한 분자 생성을 개선하기 위한 엔드 투 엔드 프레임워크로, 대화형 피드백을 통해 목표를 개선하여 AI 엔지니어의 개입 없이 조정 과정을 자동화한다.


<details>
  <summary>Details</summary>
Motivation: 약물 발견에서 분자 생성이 중요하지만, 클래스별 데이터셋은 100개 미만의 훈련 예제를 포함하는 경우가 많다.

Method: FRAGMENTA는 분할을 '어휘 선택' 문제로 재구성하는 새로운 생성 모델과 도메인 전문가의 대화형 피드백을 통해 목표를 정제하는 에이전틱 AI 시스템으로 구성된다.

Result: FRAGMENTA의 휴먼-에이전트 구성은 기준보다 거의 두 배 많은 고득점 분자를 식별했다.

Conclusion: 완전 자율 에이전트-에이전트 시스템이 전통적인 휴먼-휴먼 조정을 초과하여 전문가 의도를 포착하는 데 효과적임을 입증했다.

Abstract: Molecule generation using generative AI is vital for drug discovery, yet class-specific datasets often contain fewer than 100 training examples. While fragment-based models handle limited data better than atom-based approaches, existing heuristic fragmentation limits diversity and misses key fragments. Additionally, model tuning typically requires slow, indirect collaboration between medicinal chemists and AI engineers. We introduce FRAGMENTA, an end-to-end framework for drug lead optimization comprising: 1) a novel generative model that reframes fragmentation as a "vocabulary selection" problem, using dynamic Q-learning to jointly optimize fragmentation and generation; and 2) an agentic AI system that refines objectives via conversational feedback from domain experts. This system removes the AI engineer from the loop and progressively learns domain knowledge to eventually automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA's Human-Agent configuration identified nearly twice as many high-scoring molecules as baselines. Furthermore, the fully autonomous Agent-Agent system outperformed traditional Human-Human tuning, demonstrating the efficacy of agentic tuning in capturing expert intent.

</details>


### [16] [Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems](https://arxiv.org/abs/2511.20627)
*Anastasia Mavridou,Divya Gopinath,Corina S. Păsăreanu*

Main category: cs.AI

TL;DR: AI를 안전-critical 시스템에 통합하는 것은 확신을 위한 기본적인 도전 과제를 제시한다. 본 논문은 AI를 이용한 요구사항 공학 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 구성 요소, 특히 심층 신경망(DNN)의 안전-critical 시스템에의 통합은 확신을 위한 기본적인 도전 과제를 제시하고 있다.

Method: REACT는 대규모 언어 모델(LLM)을 활용하여 비공식 자연어 요구사항과 공식 사양 간의 간극을 메우는 방식으로 조기 검증 및 유효성을 지원한다. SemaLens는 비전 언어 모델(VLM)을 사용하여 DNN 기반 인식 시스템에 대해 인간이 이해할 수 있는 개념을 통해 추론, 테스트 및 모니터링한다.

Result: 이 두 구성 요소는 비공식 요구사항에서 검증된 구현까지의 포괄적인 파이프라인을 제공한다.

Conclusion: AI를 활용한 요구사항 공학 접근 방식은 안전-critical 시스템의 검증과 유효성을 높이는 데 기여할 수 있다.

Abstract: The integration of AI components, particularly Deep Neural Networks (DNNs), into safety-critical systems such as aerospace and autonomous vehicles presents fundamental challenges for assurance. The opacity of AI systems, combined with the semantic gap between high-level requirements and low-level network representations, creates barriers to traditional verification approaches. These AI-specific challenges are amplified by longstanding issues in Requirements Engineering, including ambiguity in natural language specifications and scalability bottlenecks in formalization. We propose an approach that leverages AI itself to address these challenges through two complementary components. REACT (Requirements Engineering with AI for Consistency and Testing) employs Large Language Models (LLMs) to bridge the gap between informal natural language requirements and formal specifications, enabling early verification and validation. SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models) utilizes Vision Language Models (VLMs) to reason about, test, and monitor DNN-based perception systems using human-understandable concepts. Together, these components provide a comprehensive pipeline from informal requirements to validated implementations.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [17] [Trust-Based Social Learning for Communication (TSLEC) Protocol Evolution in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.19562)
*Abraham Itzhak Weinberg*

Main category: cs.MA

TL;DR: TSLEC 프레임워크는 다중 에이전트 시스템에서 신뢰 기반 사회 학습을 통해 자율적인 학습보다 빠른 수렴과 더 나은 프로토콜을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서의 자율적인 학습은 느린 수렴과 비효율적인 프로토콜을 초래할 수 있다.

Method: 에이전트가 성공적인 전략을 명시적으로 동료에게 가르치는 TSLEC(신뢰 기반 사회 학습과 자발적 커뮤니케이션) 프레임워크를 도입하였다.

Result: 100회의 실험을 통해 신뢰 기반 사회 학습이 자율적 학습에 비해 수렴에 필요한 에피소드를 23.9% 줄였고, 더 robust한 프로토콜을 출력하였다.

Conclusion: 명시적인 사회 학습이 다중 에이전트 조정에서 자발적 커뮤니케이션을 근본적으로 가속화함을 입증하였다.

Abstract: Emergent communication in multi-agent systems typically occurs through independent learning, resulting in slow convergence and potentially suboptimal protocols. We introduce TSLEC (Trust-Based Social Learning with Emergent Communication), a framework where agents explicitly teach successful strategies to peers, with knowledge transfer modulated by learned trust relationships. Through experiments with 100 episodes across 30 random seeds, we demonstrate that trust-based social learning reduces episodes-to-convergence by 23.9% (p < 0.001, Cohen's d = 1.98) compared to independent emergence, while producing compositional protocols (C = 0.38) that remain robust under dynamic objectives (Phi > 0.867 decoding accuracy). Trust scores strongly correlate with teaching quality (r = 0.743, p < 0.001), enabling effective knowledge filtering. Our results establish that explicit social learning fundamentally accelerates emergent communication in multi-agent coordination.

</details>


### [18] [An Adaptive, Data-Integrated Agent-Based Modeling Framework for Explainable and Contestable Policy Design](https://arxiv.org/abs/2511.19726)
*Roberto Garrone*

Main category: cs.MA

TL;DR: 이 논문은 적응형 다중 에이전트 학습 프레임워크를 제안하며, 동적인 시스템에서 에이전트의 학습과 적응을 분석할 수 있는 구조화된 방법론을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 많은 시뮬레이션 연구들이 정적인 결정 규칙과 고정된 제어 매개변수를 사용하는 반면, 다중 에이전트 시스템은 피드백과 적응, 비정상성을 모니터링합니다.

Method: 이 논문은 네 가지 동적 레짐, 정보 이론적 진단, 구조적 인과 모델, 에이전트 수준의 사전 생성 절차, 비지도 학습 방법을 통합한 일반 적응형 다중 에이전트 학습 프레임워크를 소개합니다.

Result: 이 프레임워크는 시스템 궤적을 형성하는 학습 에이전트와 적응 제어의 상호 작용을 분석할 수 있는 도메인 중립적인 아키텍처를 제공합니다.

Conclusion: 이 연구는 안정성, 성능, 해석 가능성을 체계적으로 비교할 수 있는 방법론을 제시하며, 설명 가능하고 논란의 여지가 있는 다중 에이전트 의사 결정 프로세스를 개발하는 데 기여합니다.

Abstract: Multi-agent systems often operate under feedback, adaptation, and non-stationarity, yet many simulation studies retain static decision rules and fixed control parameters. This paper introduces a general adaptive multi-agent learning framework that integrates: (i) four dynamic regimes distinguishing static versus adaptive agents and fixed versus adaptive system parameters; (ii) information-theoretic diagnostics (entropy rate, statistical complexity, and predictive information) to assess predictability and structure; (iii) structural causal models for explicit intervention semantics; (iv) procedures for generating agent-level priors from aggregate or sample data; and (v) unsupervised methods for identifying emergent behavioral regimes. The framework offers a domain-neutral architecture for analyzing how learning agents and adaptive controls jointly shape system trajectories, enabling systematic comparison of stability, performance, and interpretability across non-equilibrium, oscillatory, or drifting dynamics. Mathematical definitions, computational operators, and an experimental design template are provided, yielding a structured methodology for developing explainable and contestable multi-agent decision processes.

</details>


### [19] [Complex Instruction Following with Diverse Style Policies in Football Games](https://arxiv.org/abs/2511.19885)
*Chenglu Sun,Shuo Shen,Haonan Hu,Wei Zhou,Chen Chen*

Main category: cs.MA

TL;DR: 본 논문은 복잡한 다중 에이전트 환경에서 고급 언어 지시를 이해하고 실행하는 언어 제어 강화 학습의 한계를 극복하기 위해 LCDSP라는 새로운 패러다임을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 환경에서 고급 또는 추상적인 지시를 이해하고 실행하는 LC-RL의 한계를 극복하려는 필요성.

Method: LCDSP는 다양한 스타일 훈련 방법(DST)과 스타일 해석기(SI)의 두 가지 핵심 요소로 구성됩니다.

Result: 복잡한 5v5 축구 환경에서 LCDSP는 추상 전술 지시를 효과적으로 이해하고 요구되는 다양한 행동 스타일을 정확하게 실행함을 보여줍니다.

Conclusion: LCDSP는 복잡한 실제 적용 가능성을 보여줍니다.

Abstract: Despite advancements in language-controlled reinforcement learning (LC-RL) for basic domains and straightforward commands (e.g., object manipulation and navigation), effectively extending LC-RL to comprehend and execute high-level or abstract instructions in complex, multi-agent environments, such as football games, remains a significant challenge. To address this gap, we introduce Language-Controlled Diverse Style Policies (LCDSP), a novel LC-RL paradigm specifically designed for complex scenarios. LCDSP comprises two key components: a Diverse Style Training (DST) method and a Style Interpreter (SI). The DST method efficiently trains a single policy capable of exhibiting a wide range of diverse behaviors by modulating agent actions through style parameters (SP). The SI is designed to accurately and rapidly translate high-level language instructions into these corresponding SP. Through extensive experiments in a complex 5v5 football environment, we demonstrate that LCDSP effectively comprehends abstract tactical instructions and accurately executes the desired diverse behavioral styles, showcasing its potential for complex, real-world applications.

</details>


### [20] [Realistic gossip in Trust Game on networks: the GODS model](https://arxiv.org/abs/2511.20248)
*Jan Majewski,Francesca Giardini*

Main category: cs.MA

TL;DR: 이 논문은 현실적인 수다 방식이 협력 문제에 미치는 영향을 분석하고, 수다의 확산 방식이 협력자에게 미치는 부정적 영향을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 명이신뢰에 기반한 교환 시스템에서 협력 문제를 해결하기 위해. 수다의 전파 방식이 비현실적이라는 점을 고려하여 이 문제를 해결하고자 한다.

Method: 현실적인 수다 과정을 다양한 변형의 신뢰 게임과 결합한 에이전트 기반 모델을 개발하였다.

Result: 로컬 상호작용에 의해 수다의 확산이 이루어질 때, 협력자들은 배신자를 판별할 수 없어 피해를 본다. 현실적인 수다 방식은 자원의 전체량을 증가시키지만, 배신을 촉진할 가능성이 더 크다.

Conclusion: 직접적이며 간접적인 상호 호혜성과 신뢰를 혼합함으로써, 수다는 협력의 효율성을 크게 증가시킨다는 것을 보여주었다.

Abstract: Gossip has been shown to be a relatively efficient solution to problems of cooperation in reputation-based systems of exchange, but many studies don't conceptualize gossiping in a realistic way, often assuming near-perfect information or broadcast-like dynamics of its spread. To solve this problem, we developed an agent-based model that pairs realistic gossip processes with different variants of Trust Game. The results show that cooperators suffer when local interactions govern spread of gossip, because they cannot discriminate against defectors. Realistic gossiping increases the overall amount of resources, but is more likely to promote defection. Moreover, even partner selection through dynamic networks can lead to high payoff inequalities among agent types. Cooperators face a choice between outcompeting defectors and overall growth. By blending direct and indirect reciprocity with reputations we show that gossiping increases the efficiency of cooperation by an order of magnitude.

</details>


### [21] [EnergyTwin: A Multi-Agent System for Simulating and Coordinating Energy Microgrids](https://arxiv.org/abs/2511.20590)
*Jakub Muszyński,Ignacy Walużenicz,Patryk Zan,Zofia Wrona,Maria Ganzha,Marcin Paprzycki,Costin Bădică*

Main category: cs.MA

TL;DR: 이 논문은 에너지 자원 조정을 위한 에이전트 기반 마이크로그리드 시뮬레이션 환경인 EnergyTwin을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 마이크로그리드는 구매한 전력 에너지를 줄이고, 변동성이 큰 요금에 대한 노출을 제한하며, 장애 상황에서 서비스 연속성을 보장하기 위해 필요하다.

Method: EnergyTwin은 에이전트 기반 마이크로그리드 시뮬레이션 환경으로, 물리적으로 기반한 모델과 예측 정보에 기반한 계획, 협상을 결합한다. 각 자산은 에이전트로 모델링되며, 중앙 에이전트와 상호작용하여 예측을 얻고, 예측을 수립하며, 계약 기반의 상호작용을 통해 에너지를 할당한다.

Result: 예측 기반의 롤링 호라이즌 계획은 지역 에너지 자급 자족을 증가시키고, 배터리 예비량을 높이며, 저내구성 운영 상태에 대한 노출을 줄였다.

Conclusion: EnergyTwin은 회복력 있는 협상 기반 마이크로그리드 연구를 지원하는 플랫폼으로서의 잠재력을 입증한다.

Abstract: Microgrids are deployed to reduce purchased grid energy, limit exposure to volatile tariffs, and ensure service continuity during disturbances. This requires coordinating heterogeneous distributed energy resources across multiple time scales and under variable conditions. Among existing tools, typically, power-system simulators capture physical behaviour but assume centralized control, while multi-agent frameworks model decentralized decision-making but represent energy with no physical grounding. In this context, the EnergyTwin is introduced, an agent-based microgrid simulation environment that couples physically grounded models with forecast-informed, rolling-horizon planning, and negotiations. Each asset is modeled as an agent, interacting with a central agent that obtains forecasts, formulates predictions, and allocates energy through contract-based interactions. EnergyTwin targets tertiary-layer decision making and is extensible for digital-twin use. Its feasibility was evaluated in a university campus microgrid scenario where multiple planning strategies were compared. Achieved results show that forecast-driven rolling-horizon planning increases local energy self-sufficiency, maintains higher battery reserves, and reduces exposure to low-resilience operating states. They demonstrate also potential of EnergyTwin as platform supporting research on resilient, negotiation-driven microgrids.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [22] [AttackPilot: Autonomous Inference Attacks Against ML Services With LLM-Based Agents](https://arxiv.org/abs/2511.19536)
*Yixin Wu,Rui Wen,Chi Cui,Michael Backes,Yang Zhang*

Main category: cs.CR

TL;DR: 이 논문에서는 인간의 개입 없이 자율적으로 추론 공격을 수행할 수 있는 AttackPilot이라는 자율 에이전트를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 추론 공격은 ML 서비스의 체계적인 위험 평가를 제공하나, 비전문가에게는 구현과 최적 추정의 매개변수가 도전적입니다.

Method: GPT-4o를 사용하는 AttackPilot라는 자율 에이전트를 개발하고 20개의 타겟 서비스에서 평가합니다.

Result: AttackPilot은 100%의 작업 완료율과 전문가 수준의 공격 성능을 보이며, 평균 토큰 비용은 $0.627입니다.

Conclusion: 이러한 에이전트는 비전문가의 ML 서비스 제공자, 감사자 또는 규제자가 ML 서비스의 위험을 체계적으로 평가할 수 있도록 도와줄 것입니다.

Abstract: Inference attacks have been widely studied and offer a systematic risk assessment of ML services; however, their implementation and the attack parameters for optimal estimation are challenging for non-experts. The emergence of advanced large language models presents a promising yet largely unexplored opportunity to develop autonomous agents as inference attack experts, helping address this challenge. In this paper, we propose AttackPilot, an autonomous agent capable of independently conducting inference attacks without human intervention. We evaluate it on 20 target services. The evaluation shows that our agent, using GPT-4o, achieves a 100.0% task completion rate and near-expert attack performance, with an average token cost of only $0.627 per run. The agent can also be powered by many other representative LLMs and can adaptively optimize its strategy under service constraints. We further perform trace analysis, demonstrating that design choices, such as a multi-agent framework and task-specific action spaces, effectively mitigate errors such as bad plans, inability to follow instructions, task context loss, and hallucinations. We anticipate that such agents could empower non-expert ML service providers, auditors, or regulators to systematically assess the risks of ML services without requiring deep domain expertise.

</details>


### [23] [IRSDA: An Agent-Orchestrated Framework for Enterprise Intrusion Response](https://arxiv.org/abs/2511.19644)
*Damodar Panigrahi,Raj Patel,Shaswata Mitra,Sudip Mittal,Shahram Rahimi*

Main category: cs.CR

TL;DR: 현대 기업 시스템은 동적이고 분산된 사이버 위협에 직면하고 있으며, 전통적인 침입 탐지 및 대응 시스템은 정적인 규칙과 수동적인 작업 흐름에 의존하여 이러한 위협에 효과적으로 대응하는 데 한계가 있다. 이를 해결하기 위해, 자율적이고 정책 준수 사이버 방어를 제공하는 침입 대응 시스템 디지털 어시스턴트(IRSDA)를 제안한다. 이 프레임워크는 실시간 의사결정을 지원하며, 시스템 주도 침입 대응을 위해 AI 기반 추론과 컨텍스트 정보를 통합하여 작동한다.


<details>
  <summary>Details</summary>
Motivation: 기업 시스템의 사이버 위협이 점점 더 복잡해지고 있으며, 기존의 침입 탐지 및 대응 시스템이 이를 효과적으로 처리하지 못하고 있어 이를 개선할 필요가 있다.

Method: IRSDA는 자가 적응형 자율 컴퓨팅 시스템(SA-ACS)과 MAPE-K 루프를 결합하여 실시간 의사결정을 지원하는 에이전트 기반 프레임워크이다. 지식 기반 아키텍처를 통해 시스템 주도 침입 대응을 가능하게 한다.

Result: 대표적인 실제 마이크로서비스 애플리케이션을 사용하여 시스템을 평가하였고, 격리 자동화, 준수 강제화, 보안 분석가 해석을 위한 추적 가능한 출력 제공 능력을 입증한다.

Conclusion: 이 연구는 설명 가능성, 시스템 상태 인식 및 운영 제어를 강조하며, 에이전트 주도의 사이버 방어 접근 방식을 제시한다.

Abstract: Modern enterprise systems face escalating cyber threats that are increasingly dynamic, distributed, and multi-stage in nature. Traditional intrusion detection and response systems often rely on static rules and manual workflows, which limit their ability to respond with the speed and precision required in high-stakes environments. To address these challenges, we present the Intrusion Response System Digital Assistant (IRSDA), an agent-based framework designed to deliver autonomous and policy-compliant cyber defense. IRSDA combines Self-Adaptive Autonomic Computing Systems (SA-ACS) with the Knowledge guided Monitor, Analyze, Plan, and Execute (MAPE-K) loop to support real-time, partition-aware decision-making across enterprise infrastructure.
  IRSDA incorporates a knowledge-driven architecture that integrates contextual information with AI-based reasoning to support system-guided intrusion response. The framework leverages retrieval mechanisms and structured representations to inform decision-making while maintaining alignment with operational policies. We assess the system using a representative real-world microservices application, demonstrating its ability to automate containment, enforce compliance, and provide traceable outputs for security analyst interpretation. This work outlines a modular and agent-driven approach to cyber defense that emphasizes explainability, system-state awareness, and operational control in intrusion response.

</details>


### [24] [BASICS: Binary Analysis and Stack Integrity Checker System for Buffer Overflow Mitigation](https://arxiv.org/abs/2511.19670)
*Luis Ferreirinha,Iberia Medeiros*

Main category: cs.CR

TL;DR: 이 논문은 모델 검증과 콘콜릭 실행 기법을 활용하여 C 프로그램의 이진 코드에서 보안 속성을 자동으로 검증하는 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 사이버 물리 시스템(CPS)은 우리의 일상 생활에서 중요한 서비스(전력 및 물 등)를 제공하는 데 필수적인 역할을 하며, 이들의 작동성, 가용성 및 신뢰성을 보장해야 합니다.

Method: 이 접근 방식은 이진 프로그램의 제어 흐름 그래프에서 메모리 상태 공간을 구성하고, 함수 호출 및 반복 구조에 대한 콘콜릭 실행의 시뮬레이션을 제공하여 이진 코드의 스택 메모리 보안 속성을 자동으로 검증합니다.

Result: 우리는 BASICS 도구로 이 접근 방식을 구현하고, Juliet C/C++ 및 SARD 데이터 세트와 실제 응용 프로그램을 사용하여 87% 이상의 정확도와 정밀도로 탐지 및 수정했습니다.

Conclusion: CWE Checker와 비교했을 때 뛰어난 성능을 보여주었습니다.

Abstract: Cyber-Physical Systems have played an essential role in our daily lives, providing critical services such as power and water, whose operability, availability, and reliability must be ensured. The C programming language, prevalent in CPS development, is crucial for system control where reliability is critical. However, it is also commonly susceptible to vulnerabilities, particularly buffer overflows. Traditional vulnerability discovery techniques often struggle with scalability and precision when applied directly to the binary code of C programs, which can thereby keep programs vulnerable. This work introduces a novel approach designed to overcome these limitations by leveraging model checking and concolic execution techniques to automatically verify security properties of a program's stack memory in binary code, trampoline techniques to perform automated repair of the issues, and crash-inducing inputs to verify if they were successfully removed. The approach constructs a Memory State Space -- MemStaCe -- from the binary program's control flow graph and simulations, provided by concolic execution, of C function calls and loop constructs. The security properties, defined in LTL, model the correct behaviour of functions associated with vulnerabilities and allow the approach to identify vulnerabilities in MemStaCe by analysing counterexample traces that are generated when a security property is violated. These vulnerabilities are then addressed with a trampoline-based binary patching method, and the effectiveness of the patches is checked with crash-inducing inputs extracted during concolic execution. We implemented the approach in the BASICS tool for BO mitigation and evaluated using the Juliet C/C++ and SARD datasets and real applications, achieving an accuracy and precision above 87%, both in detection and correction. Also, we compared it with CWE Checker, outperforming it.

</details>


### [25] [Cross-LLM Generalization of Behavioral Backdoor Detection in AI Agent Supply Chains](https://arxiv.org/abs/2511.19874)
*Arun Chowdary Sanna*

Main category: cs.CR

TL;DR: AI 에이전트의 의존성으로 인한 공급망 취약점과 교차 LLM 일반화의 중요성을 다룬 첫 체계적 연구.


<details>
  <summary>Details</summary>
Motivation: AI 시스템을 배포하는 조직들에 대한 심각한 함의를 지닌 교차 LLM 일반화의 중요성을 탐구한다.

Method: 여섯 개의 생산 LLM(GPT-5.1, Claude Sonnet 4.5, Grok 4.1, Llama 4 Maverick, GPT-OSS 120B, DeepSeek Chat V3.1)을 대상으로 한 통계적 실험을 통해 교차 LLM 행동 백도어 탐지를 평가하였다.

Result: 단일 모델 탐지기는 훈련 분포 내에서 92.7%의 정확도를 보였으나, 서로 다른 LLM 간에는 49.2%에 불과해 43.4%의 일반화 격차를 보였다.

Conclusion: 모델 인식 탐지를 통해 모든 평가된 모델에서 90.6%의 정확도를 달성하며, 재현 가능한 연구를 위해 데이터셋과 탐지 프레임워크를 공개한다.

Abstract: As AI agents become integral to enterprise workflows, their reliance on shared tool libraries and pre-trained components creates significant supply chain vulnerabilities. While previous work has demonstrated behavioral backdoor detection within individual LLM architectures, the critical question of cross-LLM generalization remains unexplored, a gap with serious implications for organizations deploying multiple AI systems. We present the first systematic study of cross-LLM behavioral backdoor detection, evaluating generalization across six production LLMs (GPT-5.1, Claude Sonnet 4.5, Grok 4.1, Llama 4 Maverick, GPT-OSS 120B, and DeepSeek Chat V3.1). Through 1,198 execution traces and 36 cross-model experiments, we quantify a critical finding: single-model detectors achieve 92.7% accuracy within their training distribution but only 49.2% across different LLMs, a 43.4 percentage point generalization gap equivalent to random guessing. Our analysis reveals that this gap stems from model-specific behavioral signatures, particularly in temporal features (coefficient of variation > 0.8), while structural features remain stable across architectures. We show that model-aware detection incorporating model identity as an additional feature achieves 90.6% accuracy universally across all evaluated models. We release our multi-LLM trace dataset and detection framework to enable reproducible research.

</details>


### [26] [Zero-Knowledge Proof Based Verifiable Inference of Models](https://arxiv.org/abs/2511.19902)
*Yunxiao Wang*

Main category: cs.CR

TL;DR: 본 논문에서는 모델 내부 매개변수를 공개하지 않고도 딥러닝 추론을 검증할 수 있는 제로 지식 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: AI 모델 추론의 정확성을 검증하는 것이 중요하지만, 모델 소유자가 매개변수를 공개하지 않을 경우 검증이 어렵습니다.

Method: 재귀적으로 구성된 제로 지식 증명을 기반으로 하고, 신뢰할 수 있는 설정이 필요 없는 프레임워크를 개발했습니다.

Result: 우리는 DeepSeek 모델을 완전히 SNARK 검증 가능한 버전인 ZK-DeepSeek로 변환하고, 효율성과 유연성을 보여주기 위한 실험을 수행했습니다.

Conclusion: 이 프레임워크는 실제 AI 검증 작업에서 효율성과 유연성을 제공합니다.

Abstract: Recent advances in artificial intelligence (AI), particularly deep learning, have led to widespread adoption across various applications. Yet, a fundamental challenge persists: how can we verify the correctness of AI model inference when model owners cannot (or will not) reveal their parameters? These parameters represent enormous training costs and valuable intellectual property, making transparent verification difficult. In this paper, we introduce a zero-knowledge framework capable of verifying deep learning inference without exposing model internal parameters. Built on recursively composed zero-knowledge proofs and requiring no trusted setup, our framework supports both linear and nonlinear neural network layers, including matrix multiplication, normalization, softmax, and SiLU. Leveraging the Fiat-Shamir heuristic, we obtain a succinct non-interactive argument of knowledge (zkSNARK) with constant-size proofs. To demonstrate the practicality of our approach, we translate the DeepSeek model into a fully SNARK-verifiable version named ZK-DeepSeek and show experimentally that our framework delivers both efficiency and flexibility in real-world AI verification workloads.

</details>


### [27] [Hey there! You are using WhatsApp: Enumerating Three Billion Accounts for Security and Privacy](https://arxiv.org/abs/2511.20252)
*Gabriel K. Gegenhuber,Philipp É. Frenzel,Maximilian Günther,Johanna Ullrich,Aljosha Judmayer*

Main category: cs.CR

TL;DR: WhatsApp는 2025년 초 기준으로 35억 개의 활성 계정을 보유한 세계 최대의 인스턴트 메시징 플랫폼으로, 사용자베이스가 방대하여 전 세계 커뮤니케이션에서 중요한 역할을 한다. 본 연구에서는 WhatsApp의 전화번호 열거 문제를 다루고, 사용자들이 자신의 연락처가 플랫폼에 등록되어 있는지를 확인하는 과정에서 발생하는 취약성을 시사한다. 우리는 시간당 1억 개 이상의 전화번호를 쿼리할 수 있었으며, 사용자 데이터의 재사용 문제도 발견했다.


<details>
  <summary>Details</summary>
Motivation: WhatsApp은 방대한 사용자 기반으로 인해 글로벌 커뮤니케이션에서 중요한 역할을 수행하지만, 연락처 유효성 확인 과정에서 전화번호 Enumeration의 취약성이 존재한다.

Method: 우리는 WhatsApp의 서버에 전화번호를 쿼리하여 연락처의 존재 여부를 확인하는 과정을 분석하고, 대규모로 전화번호를 열거하는 공격을 수행하였다.

Result: 시간당 1억 개 이상의 전화번호를 쿼리할 수 있었고, 2021년 Facebook 데이터 유출에서 드러난 전화번호 중 거의 절반이 여전히 활성 상태임을 확인하였다.

Conclusion: 우리는 WhatsApp의 기본적인 속도 제한 문제를 해결했음을 확인하며, 대규모 메시징 서비스에서의 데이터 누출과 재사용의 위험성을 강조하였다.

Abstract: WhatsApp, with 3.5 billion active accounts as of early 2025, is the world's largest instant messaging platform. Given its massive user base, WhatsApp plays a critical role in global communication.
  To initiate conversations, users must first discover whether their contacts are registered on the platform. This is achieved by querying WhatsApp's servers with mobile phone numbers extracted from the user's address book (if they allowed access). This architecture inherently enables phone number enumeration, as the service must allow legitimate users to query contact availability. While rate limiting is a standard defense against abuse, we revisit the problem and show that WhatsApp remains highly vulnerable to enumeration at scale. In our study, we were able to probe over a hundred million phone numbers per hour without encountering blocking or effective rate limiting.
  Our findings demonstrate not only the persistence but the severity of this vulnerability. We further show that nearly half of the phone numbers disclosed in the 2021 Facebook data leak are still active on WhatsApp, underlining the enduring risks associated with such exposures. Moreover, we were able to perform a census of WhatsApp users, providing a glimpse on the macroscopic insights a large messaging service is able to generate even though the messages themselves are end-to-end encrypted. Using the gathered data, we also discovered the re-use of certain X25519 keys across different devices and phone numbers, indicating either insecure (custom) implementations, or fraudulent activity.
  In this updated version of the paper, we also provide insights into the collaborative remediation process through which we confirmed that the underlying rate-limiting issue had been resolved.

</details>


### [28] [Can LLMs Make (Personalized) Access Control Decisions?](https://arxiv.org/abs/2511.20284)
*Friederike Groschupp,Daniele Lain,Aritra Dhar,Lara Magdalena Lazier,Srdjan Čapkun*

Main category: cs.CR

TL;DR: 본 연구는 사용자 개인화된 보안 선호에 맞는 동적인 액세스 제어 결정을 내리기 위해 대형 언어 모델을 활용하는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 기존 애플리케이션과 에이전트 기반 시스템의 보안을 위해 정확한 액세스 제어 결정이 중요하지만, 시스템의 복잡성과 자동화 증가로 인해 사용자의 인지 부담이 커지고 있다.

Method: 사용자 연구를 통해 307개의 자연어 개인정보 진술과 14,682개의 사용자 액세스 제어 결정을 수집하고, 일반 및 개인화된 두 가지 버전의 LLM과 비교하였다.

Result: LLM은 사용자 선호도를 잘 반영하며, 다수의 사용자 결정과 비교할 때 최대 86%의 정확도를 달성하였다.

Conclusion: 개인화된 시스템을 설계하는 데 있어 보안 모범 사례와 개인화 간의 중요한 균형을 논의하며, 실용적인 자연어 기반의 액세스 제어 시스템 구현을 위한 디자인 및 리스크 고려사항을 제시한다.

Abstract: Precise access control decisions are crucial to the security of both traditional applications and emerging agent-based systems. Typically, these decisions are made by users during app installation or at runtime. Due to the increasing complexity and automation of systems, making these access control decisions can add a significant cognitive load on users, often overloading them and leading to suboptimal or even arbitrary access control decisions. To address this problem, we propose to leverage the processing and reasoning capabilities of large language models (LLMs) to make dynamic, context-aware decisions aligned with the user's security preferences. For this purpose, we conducted a user study, which resulted in a dataset of 307 natural-language privacy statements and 14,682 access control decisions made by users. We then compare these decisions against those made by two versions of LLMs: a general and a personalized one, for which we also gathered user feedback on 1,446 of its decisions.
  Our results show that in general, LLMs can reflect users' preferences well, achieving up to 86\% accuracy when compared to the decision made by the majority of users. Our study also reveals a crucial trade-off in personalizing such a system: while providing user-specific privacy preferences to the LLM generally improves agreement with individual user decisions, adhering to those preferences can also violate some security best practices. Based on our findings, we discuss design and risk considerations for implementing a practical natural-language-based access control system that balances personalization, security, and utility.

</details>


### [29] [A Single-Root, Multi-Curve, Context-Isolated, PQC-Pluggable Cryptographic Identity Primitive with Stateless Secret Rotation](https://arxiv.org/abs/2511.20505)
*Jian Sheng Wang*

Main category: cs.CR

TL;DR: 이 논문은 현대 분산 시스템을 위한 새로운 암호화된 아이덴티티 프리미티브인 MSCIKDF를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 표준(BIP-39 및 BIP-32)은 다중 곡선, 다중 도메인 및 양자 내성 환경의 요구에 부합하지 않기 때문에, 새로운 구조의 필요성이 있다.

Method: MSCIKDF는 단일 루트, 다중 곡선, 맥락 격리된, PQC 플러그 가능 암호화된 아이덴티티 프리미티브를 정의하고, 다양한 맥락에 걸쳐 결정론적으로 아이덴티티를 유도한다.

Result: MSCIKDF는 제로 링크 가능성, 다중 곡선 독립성 및 교차 맥락 상관 관계 저항과 같은 강력한 보안 불변성을 달성한다.

Conclusion: MSCIKDF는 결정론적 아이덴티티를 위한 인프라 수준의 업그레이드로 제안되며, 향후 10년간의 분산 시스템, AI 에이전트 및 PQC 마이그레이션에 적합한 신뢰의 근본을 수립한다.

Abstract: Cryptographic identity anchors modern decentralized systems, yet current standards like BIP-39 and BIP-32 are structurally insufficient for the demands of multi-curve, multi-domain, and post-quantum (PQC) environments. These legacy schemes rely on a monolithic identity root with no inherent context isolation, algorithm agility, or secure secret rotation. This paper introduces MSCIKDF, a single-root, multi-curve, context-isolated, PQC-pluggable cryptographic identity primitive. MSCIKDF defines a new architectural foundation where identity is derived deterministically but with cryptographically enforced separation across diverse contexts (e.g., blockchain, E2EE, KMS, IoT). It achieves strong security invariants -- such as zero-linkability, multi-curve independence, and resistance to cross-context correlation -- while offering stateless secret rotation that preserves long-term identity continuity without requiring asset migration. MSCIKDF is proposed as an infrastructure-level upgrade to deterministic identity, establishing a durable and algorithm-agnostic root of trust suitable for the next decade of distributed systems, AI agents, and PQC migration.

</details>


### [30] [Quantum-Resistant Authentication Scheme for RFID Systems Using Lattice-Based Cryptography](https://arxiv.org/abs/2511.20630)
*Vaibhav Kumar,Kaiwalya Joshi,Bhavya Dixit,Gaurav S. Kasbekar*

Main category: cs.CR

TL;DR: 본 논문에서는 양자 저항 상호 인증 스킴을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: RFID 시스템의 보안성을 향상시키기 위해 양자 저항 상호 인증 스킴이 필요합니다.

Method: 격자 기반 암호화를 활용하고, 특히 불균형 단기 정수 해법(ISIS) 문제의 어려움을 이용하여 양자 저항을 달성합니다.

Result: 제안된 프로토콜은 MITM, 재생, 사칭, 반사 공격에 대해 강력한 보안을 제공하며, 위조 방지와 익명성을 보장합니다.

Conclusion: 본 연구는 RFID 시스템을 위한 양자 저항 인증 프로토콜로, 독창적으로 모든 통신 채널의 불안전성을 다룹니다.

Abstract: We propose a novel quantum-resistant mutual authentication scheme for radio-frequency identification (RFID) systems. Our scheme uses lattice-based cryptography and, in particular, achieves quantum-resistance by leveraging the hardness of the inhomogeneous short integer solution (ISIS) problem. In contrast to prior work, which assumes that the reader-server communication channel is secure, our scheme is secure even when both the reader-server and tag-reader communication channels are insecure. Our proposed protocol provides robust security against man-in-the-middle (MITM), replay, impersonation, and reflection attacks, while also ensuring unforgeability and preserving anonymity. We present a detailed security analysis, including semi-formal analysis and formal verification using the Automated Validation of Internet Security Protocols and Applications (AVISPA) tool. In addition, we analyze the storage, computation, and communication costs of the proposed protocol and compare its security properties with those of existing protocols, demonstrating that our scheme offers strong security guarantees. To the best of our knowledge, this paper is the first quantum-resistant authentication protocol for RFID systems that comprehensively addresses the insecurity of both the reader-server and tag-reader communication channels.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [31] [Xmodel-2.5: 1.3B Data-Efficient Reasoning SLM](https://arxiv.org/abs/2511.19496)
*Yang Liu,Xiaolong Zhong,Ling Jiang*

Main category: cs.LG

TL;DR: Xmodel-2.5는 13개의 작업에 대해 추론 성능을 향상시키는 작은 언어 모델이다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 계산 수요로 인해 엣지 또는 비용 민감한 환경에서 실용성이 떨어지므로, 보다 작은 언어 모델의 필요성이 제기된다.

Method: 1.3억 매개변수의 작은 언어 모델로, 최대 업데이트 매개변수화($μ$P) 방식을 사용해 20M 매개변수 프로시로부터 하이퍼파라미터를 이전할 수 있도록 설계되었다. 1.4T 토큰의 Warmup-Stable-Decay 커리큘럼을 사용하며, 디케이 단계 동안 AdamW에서 Muon으로 전환함으로써 성능을 개선하였다.

Result: 13개 작업에 대한 평균 추론 성능이 4.58% 향상되었다.

Conclusion: FP8 혼합 정밀도 훈련은 정확도와 처리량 간의 균형을 유지하며, 모든 체크포인트와 평가 코드는 Apache-2.0 라이센스 하에 공개되었다.

Abstract: Large language models deliver strong reasoning and tool-use skills, yet their computational demands make them impractical for edge or cost-sensitive deployments. We present \textbf{Xmodel-2.5}, a 1.3-billion-parameter small language model designed as a \emph{drop-in agent core}. Training with maximal-update parameterization ($μ$P) allows hyper-parameters tuned on a 20M-parameter proxy to transfer directly to the full model, even under the parameter-tied \emph{tie-word-embedding} architecture. A 1.4T-token Warmup--Stable--Decay curriculum is used, and we further show that \textbf{switching from AdamW to Muon during the decay phase} improves the 13-task reasoning average by 4.58\,\% while keeping every other hyper-parameter fixed, verifying that early AdamW stability can be paired with late Muon sharpening for better downstream performance. FP8-mixed-precision training balances accuracy and throughput. All checkpoints, recipes, and evaluation code are released under the Apache-2.0 license.\footnote{https://huggingface.co/XiaoduoAILab/Xmodel-2.5 and https://huggingface.co/XiaoduoAILab/Xmodel-2.5-history (training checkpoints).} Training code and evaluation harness: https://github.com/XiaoduoAILab/Xmodel-2.5.

</details>


### [32] [Beyond Binary Classification: A Semi-supervised Approach to Generalized AI-generated Image Detection](https://arxiv.org/abs/2511.19499)
*Hong-Hanh Nguyen-Le,Van-Tuan Tran,Dinh-Thuc Nguyen,Nhien-An Le-Khac*

Main category: cs.LG

TL;DR: 본 논문은 GAN과 DM의 구조적 차이로 인해 발생하는 디지털 이미지 진위 감별의 문제를 해결하기 위한 TriDetect라는 새로운 반감독 접근법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 장치의 구조가 다름에 따라 발생하는 아티팩트의 차이로 인해 현재 포렌식에서 탐지기의 일반화에 실패하고 있다.

Method: TriDetect는 반감독 접근법으로, Sinkhorn-Knopp 알고리즘을 통한 균형 클러스터 할당과 교차 뷰 일관성 메커니즘을 사용하여 '가짜' 클래스 내에서 잠재적 구조 패턴을 발견한다.

Result: TriDetect를 두 가지 표준 벤치마크 및 세 가지 자연 환경 데이터셋에서 평가하여 13개의 기준선을 상대로 일반화 능력을 입증하였다.

Conclusion: 우리의 분석에 따라 TriDetect는 GAN과 DM의 구조적 차이를 이해하고 이를 통해 진짜와 가짜를 보다 효과적으로 분류할 수 있게 한다.

Abstract: The rapid advancement of generators (e.g., StyleGAN, Midjourney, DALL-E) has produced highly realistic synthetic images, posing significant challenges to digital media authenticity. These generators are typically based on a few core architectural families, primarily Generative Adversarial Networks (GANs) and Diffusion Models (DMs). A critical vulnerability in current forensics is the failure of detectors to achieve cross-generator generalization, especially when crossing architectural boundaries (e.g., from GANs to DMs). We hypothesize that this gap stems from fundamental differences in the artifacts produced by these \textbf{distinct architectures}. In this work, we provide a theoretical analysis explaining how the distinct optimization objectives of the GAN and DM architectures lead to different manifold coverage behaviors. We demonstrate that GANs permit partial coverage, often leading to boundary artifacts, while DMs enforce complete coverage, resulting in over-smoothing patterns. Motivated by this analysis, we propose the \textbf{Tri}archy \textbf{Detect}or (TriDetect), a semi-supervised approach that enhances binary classification by discovering latent architectural patterns within the "fake" class. TriDetect employs balanced cluster assignment via the Sinkhorn-Knopp algorithm and a cross-view consistency mechanism, encouraging the model to learn fundamental architectural distincts. We evaluate our approach on two standard benchmarks and three in-the-wild datasets against 13 baselines to demonstrate its generalization capability to unseen generators.

</details>


### [33] [When Should Neural Data Inform Welfare? A Critical Framework for Policy Uses of Neuroeconomics](https://arxiv.org/abs/2511.19548)
*Yiven,Zhu*

Main category: cs.LG

TL;DR: 신경경제학이 정책을 위한 복지 판단에 대한 신경 데이터를 어떻게 정당화할 수 있는지를 논의하고 있습니다.


<details>
  <summary>Details</summary>
Motivation: 정책 및 상업적 행위자들이 신경 데이터를 이용하여 규제를 정당화하는 경향이 증가하고 있습니다.

Method: 신경 신호, 계산적 결정 모델 및 규범적 복지 기준을 연결하는 비경험적 모델 기반 프레임워크를 개발했습니다.

Result: 신경-계산적 매핑이 잘 검증되었을 때와 결정 모델이 '진정한' 이익을 식별했을 때만 신경 증거가 복지 판단을 제약함을 보여줍니다.

Conclusion: 중독, 신경 마케팅 및 환경 정책에 이 프레임워크를 적용하여 규제자 및 NeuroAI 시스템 설계자를 위한 신경 경제 복지 추론 체크리스트를 도출했습니다.

Abstract: Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, "brain-based" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies "true" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model.

</details>


### [34] [Learning Massively Multitask World Models for Continuous Control](https://arxiv.org/abs/2511.19584)
*Nicklas Hansen,Hao Su,Xiaolong Wang*

Main category: cs.LG

TL;DR: 본 연구는 다양한 태스크를 지원하는 다기능 에이전트를 개발하기 위한 새로운 벤치마크를 제안하고, 언어 조건을 갖춘 다기능 세계 모델인 Newt를 통해 실시간 상호작용을 이용한 효율적인 학습을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 현재의 강화학습(RL) 연구는 주로 단일 태스크나 오프라인 환경에 집중되어 있으며, 온라인 RL이 확장성이 없다는 관점을 강화하고 있다. 본 연구는 이를 극복하기 위해 많은 태스크에서 학습할 수 있는 에이전트를 개발하고자 한다.

Method: 200개의 다양한 태스크로 구성된 새로운 벤치마크를 도입하고, 언어 조건을 갖춘 다기능 세계 모델 Newt를 개발하여, 데모를 통한 사전 학습과 온라인 상호작용을 통한 공동 최적화를 수행한다.

Result: Newt는 강력한 기초 모델보다 더 나은 다기능 성능과 데이터 효율성을 보이며, 강력한 오픈 루프 제어를 가능하게 하고, 보지 못한 태스크에 빠르게 적응할 수 있다.

Conclusion: 우리는 학습 및 평가를 위한 환경, 데모, 코드 및 200개 이상의 체크포인트를 공개한다.

Abstract: General-purpose control demands agents that act across many tasks and embodiments, yet research on reinforcement learning (RL) for continuous control remains dominated by single-task or offline regimes, reinforcing a view that online RL does not scale. Inspired by the foundation model recipe (large-scale pretraining followed by light RL) we ask whether a single agent can be trained on hundreds of tasks with online interaction. To accelerate research in this direction, we introduce a new benchmark with 200 diverse tasks spanning many domains and embodiments, each with language instructions, demonstrations, and optionally image observations. We then present \emph{Newt}, a language-conditioned multitask world model that is first pretrained on demonstrations to acquire task-aware representations and action priors, and then jointly optimized with online interaction across all tasks. Experiments show that Newt yields better multitask performance and data-efficiency than a set of strong baselines, exhibits strong open-loop control, and enables rapid adaptation to unseen tasks. We release our environments, demonstrations, code for training and evaluation, as well as 200+ checkpoints.

</details>


### [35] [Structured Noise Modeling for Enhanced Time-Series Forecasting](https://arxiv.org/abs/2511.19657)
*Sepideh Koohfar*

Main category: cs.LG

TL;DR: 본 연구는 시간 시계열 예측의 정확성과 안정성을 향상시키는 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 시간 시계열 예측은 여러 규모에서 작용하는 시간적 패턴 때문에 실제 환경에서 여전히 어렵습니다.

Method: 예측 블러 제거 프레임워크를 도입하여 구조적 노이즈 모델링을 통해 시간 충실성을 개선합니다.

Result: 전기, 교통, 태양광 데이터셋에 대한 실험을 통해 다중 지평 정확성과 안정성의 일관된 향상을 보여줍니다.

Conclusion: 이 프레임워크는 에너지, 인프라 및 기타 시간에 민감한 분야의 예측 기반 의사결정 지원에 있어 더 신뢰할 수 있는 AI 시스템에 기여합니다.

Abstract: Time-series forecasting remains difficult in real-world settings because temporal patterns operate at multiple scales, from broad contextual trends to fast, fine-grained fluctuations that drive critical decisions. Existing neural models often struggle to represent these interacting dynamics, leading to unstable predictions and reduced reliability in downstream applications. This work introduces a forecast-blur-denoise framework that improves temporal fidelity through structured noise modeling. The approach incorporates a learnable Gaussian Process module that generates smooth, correlated perturbations, encouraging the forecasting backbone to capture long-range structure while a dedicated refinement model restores high-resolution temporal detail. Training the components jointly enables natural competence division and avoids the artifacts commonly produced by isotropic corruption methods. Experiments across electricity, traffic, and solar datasets show consistent gains in multi-horizon accuracy and stability. The modular design also allows the blur-denoise layer to operate as a lightweight enhancement for pretrained models, supporting efficient adaptation in limited-data scenarios. By strengthening the reliability and interpretability of fine-scale temporal predictions, this framework contributes to more trustworthy AI systems used in forecasting-driven decision support across energy, infrastructure, and other time-critical domains.

</details>


### [36] [Training-Free Active Learning Framework in Materials Science with Large Language Models](https://arxiv.org/abs/2511.19730)
*Hongchen Wang,Rafael Espinosa Castañeda,Jay R. Werber,Yao Fehlis,Edward Kim,Jason Hattrick-Simpers*

Main category: cs.LG

TL;DR: LLM 기반의 핵심 학습 프레임워크(LLM-AL)는 전통적인 기계 학습 모델보다 70% 이상 실험 수를 줄이며, 효율적인 실험 선택을 가능하게 합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 기계 학습 모델은 차가운 시작 문제와 도메인 특정 기능 공학의 한계로 일반화가 제한됩니다.

Method: 우리는 간결한 수치 입력과 확장된 설명 텍스트를 사용하는 두 가지 프롬프트 전략을 탐색하여 LLM 기반의 핵심 학습 프레임워크를 소개합니다.

Result: LLM-AL은 모든 데이터셋에서 상위 성능 후보에 도달하는 데 필요한 실험 수를 70% 이상 줄였으며 전통적인 ML 모델을 일관되게 초과 성능을 보였습니다.

Conclusion: 이 결과들은 LLM-AL이 보다 효율적이고 해석 가능한 실험 선택 및 LLM 기반 자율 발견을 위한 일반화 가능한 대안이 될 수 있음을 보여줍니다.

Abstract: Active learning (AL) accelerates scientific discovery by prioritizing the most informative experiments, but traditional machine learning (ML) models used in AL suffer from cold-start limitations and domain-specific feature engineering, restricting their generalizability. Large language models (LLMs) offer a new paradigm by leveraging their pretrained knowledge and universal token-based representations to propose experiments directly from text-based descriptions. Here, we introduce an LLM-based active learning framework (LLM-AL) that operates in an iterative few-shot setting and benchmark it against conventional ML models across four diverse materials science datasets. We explored two prompting strategies: one using concise numerical inputs suited for datasets with more compositional and structured features, and another using expanded descriptive text suited for datasets with more experimental and procedural features to provide additional context. Across all datasets, LLM-AL could reduce the number of experiments needed to reach top-performing candidates by over 70% and consistently outperformed traditional ML models. We found that LLM-AL performs broader and more exploratory searches while still reaching the optima with fewer iterations. We further examined the stability boundaries of LLM-AL given the inherent non-determinism of LLMs and found its performance to be broadly consistent across runs, within the variability range typically observed for traditional ML approaches. These results demonstrate that LLM-AL can serve as a generalizable alternative to conventional AL pipelines for more efficient and interpretable experiment selection and potential LLM-driven autonomous discovery.

</details>


### [37] [Hierarchical Spatio-Temporal Attention Network with Adaptive Risk-Aware Decision for Forward Collision Warning in Complex Scenarios](https://arxiv.org/abs/2511.19952)
*Haoran Hu,Junren Shi,Shuo Jiang,Kun Cheng,Xia Yang,Changhao Piao*

Main category: cs.LG

TL;DR: 이 논문에서는 새로운 통합 전방 충돌 경고 시스템을 제안하여, 계산 복잡성과 모델링 부족 문제를 해결하고, 높은 허위 경고 비율을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 전방 충돌 경고 시스템은 정확한 다중 에이전트 상호작용 모델링과 실시간 결정 적응성 간의 균형을 맞추는 데 실패하고 있습니다.

Method: 이 논문은 계층적 시공간 주의 네트워크(HSTAN)와 동적 위험 임계값 조정 알고리즘을 결합한 통합 FCW 프레임워크를 제안합니다.

Result: HSTAN은 12.3 ms의 추론 시간을 필요로 하며, NGSIM 데이터셋에서 평균 변위 오차(ADE)를 0.73m로 줄였습니다.

Conclusion: 완전한 시스템은 0.912의 F1 점수 및 8.2%의 낮은 허위 경고 비율을 기록하며, 복잡한 환경에서의 실제 활용 가능성을 입증합니다.

Abstract: Forward Collision Warning systems are crucial for vehicle safety and autonomous driving, yet current methods often fail to balance precise multi-agent interaction modeling with real-time decision adaptability, evidenced by the high computational cost for edge deployment and the unreliability stemming from simplified interaction models.To overcome these dual challenges-computational complexity and modeling insufficiency-along with the high false alarm rates of traditional static-threshold warnings, this paper introduces an integrated FCW framework that pairs a Hierarchical Spatio-Temporal Attention Network with a Dynamic Risk Threshold Adjustment algorithm. HSTAN employs a decoupled architecture (Graph Attention Network for spatial, cascaded GRU with self-attention for temporal) to achieve superior performance and efficiency, requiring only 12.3 ms inference time (73% faster than Transformer methods) and reducing the Average Displacement Error (ADE) to 0.73m (42.2% better than Social_LSTM) on the NGSIM dataset. Furthermore, Conformalized Quantile Regression enhances reliability by generating prediction intervals (91.3% coverage at 90% confidence), which the DTRA module then converts into timely warnings via a physics-informed risk potential function and an adaptive threshold mechanism inspired by statistical process control.Tested across multi-scenario datasets, the complete system demonstrates high efficacy, achieving an F1 score of 0.912, a low false alarm rate of 8.2%, and an ample warning lead time of 2.8 seconds, validating the framework's superior performance and practical deployment feasibility in complex environments.

</details>


### [38] [BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents](https://arxiv.org/abs/2511.20597)
*Kaiyuan Zhang,Mark Tenenholtz,Kyle Polley,Jerry Ma,Denis Yarats,Ninghui Li*

Main category: cs.LG

TL;DR: 인공지능(AI) 에이전트를 웹 브라우저에 통합하는 것은 전통적인 웹 애플리케이션 위협 모델을 넘어서는 보안 문제를 제기합니다. 본 연구는 프롬프트 주입 공격의 현황을 조사하고, 현실적인 HTML 페이로드에 내장된 공격의 기준을 Synthesizes합니다. 이를 통해 우리는 현재의 방어책을 평가하고 진화하는 프롬프트 주입 공격으로부터 보호하기 위한 다층 방어 전략을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인공지능 에이전트에 대한 보안 이슈를 명확히 이해하고 효과적인 방어 전략을 마련하기 위함이다.

Method: 프롬프트 주입 공격을 조사하고, 현실적인 HTML 페이로드를 사용하여 공격의 표준을 제시하며, 다양한 AI 모델에 대한 기존 방어를 종합적으로 평가 한다.

Result: 주입이 실제 행동에 영향을 미칠 수 있는 공격을 강조한 벤치마크를 개발하고, 방어책의 효과성을 평가한 결과를 제시했다.

Conclusion: 다층 방어 전략을 통해 진화하는 프롬프트 주입 공격으로부터 안전한 웹 에이전트를 설계하는 청사진을 제공한다.

Abstract: The integration of artificial intelligence (AI) agents into web browsers introduces security challenges that go beyond traditional web application threat models. Prior work has identified prompt injection as a new attack vector for web agents, yet the resulting impact within real-world environments remains insufficiently understood.
  In this work, we examine the landscape of prompt injection attacks and synthesize a benchmark of attacks embedded in realistic HTML payloads. Our benchmark goes beyond prior work by emphasizing injections that can influence real-world actions rather than mere text outputs, and by presenting attack payloads with complexity and distractor frequency similar to what real-world agents encounter. We leverage this benchmark to conduct a comprehensive empirical evaluation of existing defenses, assessing their effectiveness across a suite of frontier AI models. We propose a multi-layered defense strategy comprising both architectural and model-based defenses to protect against evolving prompt injection attacks. Our work offers a blueprint for designing practical, secure web agents through a defense-in-depth approach.

</details>


### [39] [Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning](https://arxiv.org/abs/2511.20613)
*Panayiotis Danassis,Naman Goel*

Main category: cs.LG

TL;DR: 대형 언어 모델의 빠른 발전은 AI 지원 코드 생성에 혁신을 가져왔지만, 이를 적절히 평가할 수 있는 기준이 부족하다. 본 논문에서는 실제 물류 최적화 문제에 기반한 다중 에이전트 추론 중심 벤치마크를 제시하고, LLM 코드 에이전트와 인간 코드 에이전트 간의 성능을 비교하였다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)의 빠른 발전이 AI 지원 코드 생성에 큰 영향을 미치고 있으나, 이러한 모델을 평가할 적절한 기준이 부족하다.

Method: 우리는 경쟁 경매와 용량 제약 경로 조합을 포함하는 실제 물류 최적화 문제(Auction, Pickup, and Delivery Problem)에 기반한 다중 에이전트 추론 중심 벤치마크를 도입하였다.

Result: 40개의 LLM 코드 에이전트와 미리 개발된 17개의 인간 코드 에이전트를 12회의 토너먼트와 약 40,000회의 매치를 통해 평가한 결과, 인간 코드 에이전트가 일관되게 우수한 성능을 보여주었고, 대다수의 LLM 코드 에이전트는 간단한 기준에 의해 패배하였다.

Conclusion: 이 결과는 LLM이 실제 세계에서 경쟁적으로 작동하는 코드를 생성하는 능력에 격차가 있음을 강조하며, 현실 세계 시나리오에서 추론 기반 코드 합성을 강조하는 새로운 평가의 필요성을 제기한다.

Abstract: The rapid proliferation of Large Language Models (LLMs) has revolutionized AI-assisted code generation. This rapid development of LLMs has outpaced our ability to properly benchmark them. Prevailing benchmarks emphasize unit-test pass rates and syntactic correctness. Such metrics understate the difficulty of many real-world problems that require planning, optimization, and strategic interaction. We introduce a multi-agent reasoning-driven benchmark based on a real-world logistics optimization problem (Auction, Pickup, and Delivery Problem) that couples competitive auctions with capacity-constrained routing. The benchmark requires building agents that can (i) bid strategically under uncertainty and (ii) optimize planners that deliver tasks while maximizing profit. We evaluate 40 LLM-coded agents (by a wide range of state-of-the-art LLMs under multiple prompting methodologies, including vibe coding) against 17 human-coded agents developed before the advent of LLMs. Our results over 12 double all-play-all tournaments and $\sim 40$k matches demonstrate (i) a clear superiority of human(graduate students)-coded agents: the top 5 spots are consistently won by human-coded agents, (ii) the majority of LLM-coded agents (33 out of 40) are beaten by very simple baselines, and (iii) given the best human solution as an input and prompted to improve upon, the best performing LLM makes the solution significantly worse instead of improving it. Our results highlight a gap in LLMs' ability to produce code that works competitively in the real-world, and motivate new evaluations that emphasize reasoning-driven code synthesis in real-world scenarios.

</details>


### [40] [Stragglers Can Contribute More: Uncertainty-Aware Distillation for Asynchronous Federated Learning](https://arxiv.org/abs/2511.19966)
*Yujia Wang,Fenglong Ma,Jinghui Chen*

Main category: cs.LG

TL;DR: FedEcho라는 새로운 프레임워크를 제안하여 비동기 연합 학습의 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 비동기 연합 학습의 효율성과 확장성의 향상으로 느린 참여자를 기다리지 않고도 로컬 클라이언트가 서버에 모델 업데이트를 보낼 수 있지만, 구식 업데이트와 빠른 클라이언트의 편향 문제로 인해 전체 모델 성능이 저하되는 도전 과제가 존재한다.

Method: 불확실성 인식 증류 기법을 도입하여, 느린 클라이언트의 예측 신뢰성을 평가하고, 예측의 불확실성에 따라 이들의 영향을 동적으로 조정한다.

Result: FedEcho는 기존의 비동기 연합 학습 기준을 지속적으로 능가하며, 개인 클라이언트 데이터에 접근하지 않고도 견고한 성능을 달성한다.

Conclusion: FedEcho는 비동기 지연과 데이터 이질성 아래에서 비동기 연합 학습 성능을 향상시키는 효과적인 방법을 제공한다.

Abstract: Asynchronous federated learning (FL) has recently gained attention for its enhanced efficiency and scalability, enabling local clients to send model updates to the server at their own pace without waiting for slower participants. However, such a design encounters significant challenges, such as the risk of outdated updates from straggler clients degrading the overall model performance and the potential bias introduced by faster clients dominating the learning process, especially under heterogeneous data distributions. Existing methods typically address only one of these issues, creating a conflict where mitigating the impact of outdated updates can exacerbate the bias created by faster clients, and vice versa. To address these challenges, we propose FedEcho, a novel framework that incorporates uncertainty-aware distillation to enhance the asynchronous FL performances under large asynchronous delays and data heterogeneity. Specifically, uncertainty-aware distillation enables the server to assess the reliability of predictions made by straggler clients, dynamically adjusting the influence of these predictions based on their estimated uncertainty. By prioritizing more certain predictions while still leveraging the diverse information from all clients, FedEcho effectively mitigates the negative impacts of outdated updates and data heterogeneity. Through extensive experiments, we demonstrate that FedEcho consistently outperforms existing asynchronous federated learning baselines, achieving robust performance without requiring access to private client data.

</details>


### [41] [Operator Learning at Machine Precision](https://arxiv.org/abs/2511.19980)
*Aras Bacho,Aleksei G. Sorokin,Xianjin Yang,Théo Bourdais,Edoardo Calvello,Matthieu Darcy,Alexander Hsu,Bamdad Hosseini,Houman Owhadi*

Main category: cs.LG

TL;DR: 이 논문에서는 CHONKNORIS라는 새로운 신경 연산자 학습 패러다임을 제안하고, 이를 통해 기계 정밀도를 달성하며 비선형 편미분 방정식 문제를 해결하는 방법을 설명한다.


<details>
  <summary>Details</summary>
Motivation: 신경 연산자 학습 방법의 정확성을 향상시키기 위한 기존 연구의 한계를 극복하고자 한다.

Method: Newton-type 방법을 활용하여 Tikhonov-정규화된 Newton-Kantorovich 업데이트와 관련된 타원 연산자의 Cholesky 인자를 회귀하는 방식으로 문제를 해결한다.

Result: CHONKNORIS는 비선형 타원 방정식, Burgers 방정식 등 다양한 비선형 문제에 대해 성능 벤치마킹을 수행하며, Cholesky 인자의 정확성에 대한 이론적 보장을 제시한다.

Conclusion: FONKNORIS 모형을 통해 새로운 비선형 PDE를 효율적으로 해결할 수 있음을 보인다.

Abstract: Neural operator learning methods have garnered significant attention in scientific computing for their ability to approximate infinite-dimensional operators. However, increasing their complexity often fails to substantially improve their accuracy, leaving them on par with much simpler approaches such as kernel methods and more traditional reduced-order models. In this article, we set out to address this shortcoming and introduce CHONKNORIS (Cholesky Newton--Kantorovich Neural Operator Residual Iterative System), an operator learning paradigm that can achieve machine precision. CHONKNORIS draws on numerical analysis: many nonlinear forward and inverse PDE problems are solvable by Newton-type methods. Rather than regressing the solution operator itself, our method regresses the Cholesky factors of the elliptic operator associated with Tikhonov-regularized Newton--Kantorovich updates. The resulting unrolled iteration yields a neural architecture whose machine-precision behavior follows from achieving a contractive map, requiring far lower accuracy than end-to-end approximation of the solution operator. We benchmark CHONKNORIS on a range of nonlinear forward and inverse problems, including a nonlinear elliptic equation, Burgers' equation, a nonlinear Darcy flow problem, the Calderón problem, an inverse wave scattering problem, and a problem from seismic imaging. We also present theoretical guarantees for the convergence of CHONKNORIS in terms of the accuracy of the emulated Cholesky factors. Additionally, we introduce a foundation model variant, FONKNORIS (Foundation Newton--Kantorovich Neural Operator Residual Iterative System), which aggregates multiple pre-trained CHONKNORIS experts for diverse PDEs to emulate the solution map of a novel nonlinear PDE. Our FONKNORIS model is able to accurately solve unseen nonlinear PDEs such as the Klein--Gordon and Sine--Gordon equations.

</details>


### [42] [SOMBRL: Scalable and Optimistic Model-Based RL](https://arxiv.org/abs/2511.20066)
*Bhavya Sukhija,Lenart Treven,Carmelo Sferrazza,Florian Dörfler,Pieter Abbeel,Andreas Krause*

Main category: cs.LG

TL;DR: SOMBRL은 모델 기반 강화 학습의 효율적인 탐색 문제를 해결하기 위한 접근법으로, 불확실성에 대한 낙관적인 원칙을 바탕으로 한다.


<details>
  <summary>Details</summary>
Motivation: 모델 기반 강화 학습(MBRL)에서 시스템 동역학이 알려져 있지 않으며, RL 에이전트가 온라인 상호작용에서 직접 학습해야 하는 문제를 해결하고자 한다.

Method: SOMBRL은 불확실성을 고려한 동적 모델을 학습하고 외부 보상과 에이전트의 인식적 불확실성의 가중합을 탐욕적으로 극대화하는 접근법이다.

Result: SOMBRL은 유한 수평, 할인된 무한 수평 및 비 에피소드 설정에서 비선형 동역학에 대해 서브선형 후회를 보이는 것으로 나타났다.

Conclusion: SOMBRL은 원칙적인 탐색을 위한 유연하고 확장 가능한 솔루션을 제공하며, 상태 기반 및 시각적 제어 환경에서 강력한 성능을 보여주었다.

Abstract: We address the challenge of efficient exploration in model-based reinforcement learning (MBRL), where the system dynamics are unknown and the RL agent must learn directly from online interactions. We propose Scalable and Optimistic MBRL (SOMBRL), an approach based on the principle of optimism in the face of uncertainty. SOMBRL learns an uncertainty-aware dynamics model and greedily maximizes a weighted sum of the extrinsic reward and the agent's epistemic uncertainty. SOMBRL is compatible with any policy optimizers or planners, and under common regularity assumptions on the system, we show that SOMBRL has sublinear regret for nonlinear dynamics in the (i) finite-horizon, (ii) discounted infinite-horizon, and (iii) non-episodic settings. Additionally, SOMBRL offers a flexible and scalable solution for principled exploration. We evaluate SOMBRL on state-based and visual-control environments, where it displays strong performance across all tasks and baselines. We also evaluate SOMBRL on a dynamic RC car hardware and show SOMBRL outperforms the state-of-the-art, illustrating the benefits of principled exploration for MBRL.

</details>


### [43] [CLIMATEAGENT: Multi-Agent Orchestration for Complex Climate Data Science Workflows](https://arxiv.org/abs/2511.20109)
*Hyeonjae Kim,Chenyue Li,Wen Deng,Mengxi Jin,Wen Huang,Mengqian Lu,Binhang Yuan*

Main category: cs.LG

TL;DR: ClimateAgent는 기후 데이터 분석 워크플로우를 자동화하는 다중 에이전트 프레임워크로, 100% 작업 완료율과 높은 보고서 품질 점수를 달성하였다.


<details>
  <summary>Details</summary>
Motivation: 기후 과학에서 포괄적인 질문을 데이터 기반으로 변환하기 위해 자동화된 워크플로우가 필요하지만, 기존의 일반적인 LLM 에이전트와 정적인 스크립트 파이프라인은 기후 특유의 맥락과 유연성이 부족하여 실제 성능이 저조하다.

Method: ClimateAgent는 사용자의 질문을 실행 가능한 하위 작업으로 분해하고, Orchestrate-Agent와 Plan-Agent가 조정하며, 특수화된 Data-Agent를 통해 데이터를 수집하고, Coding-Agent가 파이썬 코드, 시각화 및 최종 보고서를 생성한다.

Result: Climate-Agent-Bench-85에서 ClimateAgent는 100% 작업 완료율과 8.32의 보고서 품질 점수를 기록하여 GitHub-Copilot(6.27)과 GPT-5 기준(3.26)을 능가하였다.

Conclusion: 다중 에이전트 조정과 동적 API 인식을 통해 신뢰할 수 있는 기후 과학 분석 작업의 엔드 투 엔드 자동화를 크게 발전시켰다.

Abstract: Climate science demands automated workflows to transform comprehensive questions into data-driven statements across massive, heterogeneous datasets. However, generic LLM agents and static scripting pipelines lack climate-specific context and flexibility, thus, perform poorly in practice. We present ClimateAgent, an autonomous multi-agent framework that orchestrates end-to-end climate data analytic workflows. ClimateAgent decomposes user questions into executable sub-tasks coordinated by an Orchestrate-Agent and a Plan-Agent; acquires data via specialized Data-Agents that dynamically introspect APIs to synthesize robust download scripts; and completes analysis and reporting with a Coding-Agent that generates Python code, visualizations, and a final report with a built-in self-correction loop. To enable systematic evaluation, we introduce Climate-Agent-Bench-85, a benchmark of 85 real-world tasks spanning atmospheric rivers, drought, extreme precipitation, heat waves, sea surface temperature, and tropical cyclones. On Climate-Agent-Bench-85, ClimateAgent achieves 100% task completion and a report quality score of 8.32, outperforming GitHub-Copilot (6.27) and a GPT-5 baseline (3.26). These results demonstrate that our multi-agent orchestration with dynamic API awareness and self-correcting execution substantially advances reliable, end-to-end automation for climate science analytic tasks.

</details>


### [44] [AdaCap: An Adaptive Contrastive Approach for Small-Data Neural Networks](https://arxiv.org/abs/2511.20170)
*Bruno Belucci,Karim Lounici,Katia Meziani*

Main category: cs.LG

TL;DR: AdaCap은 작은 표 형식 데이터셋에서 신경망의 성능을 향상시키는 훈련 체계이다.


<details>
  <summary>Details</summary>
Motivation: 신경망이 작은 표 형식 데이터셋에서 어려움을 겪는 반면, 트리 기반 모델이 여전히 우세하다.

Method: 퍼뮤테이션 기반 대조 손실과 Tikhonov 기반 닫힌 형태 출력 매핑을 결합한 훈련 스킴을 제안한다.

Result: 85개의 실제 회귀 데이터셋과 여러 아키텍처에서 AdaCap은 작은 샘플 환경에서 일관된 통계적으로 유의미한 개선을 보인다.

Conclusion: AdaCap은 신경망이 가장 취약한 부분에서 정확하게 강화하는 타겟 정규화 메커니즘으로 작용한다.

Abstract: Neural networks struggle on small tabular datasets, where tree-based models remain dominant. We introduce Adaptive Contrastive Approach (AdaCap), a training scheme that combines a permutation-based contrastive loss with a Tikhonov-based closed-form output mapping. Across 85 real-world regression datasets and multiple architectures, AdaCap yields consistent and statistically significant improvements in the small-sample regime, particularly for residual models. A meta-predictor trained on dataset characteristics (size, skewness, noise) accurately anticipates when AdaCap is beneficial. These results show that AdaCap acts as a targeted regularization mechanism, strengthening neural networks precisely where they are most fragile. All results and code are publicly available at https://github.com/BrunoBelucci/adacap.

</details>


### [45] [Communication-Efficient Learning for Satellite Constellations](https://arxiv.org/abs/2511.20220)
*Ruxandra-Stefania Tudose,Moritz H. W. Grüss,Grace Ra Kim,Karl H. Johansson,Nicola Bastianello*

Main category: cs.LG

TL;DR: 저궤도 위성 별자리의 사용을 통해 학습 문제를 해결하는 혁신적이고 통신 효율적인 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 저궤도 위성 별자리가 위치 정밀도, 지구 이미지화 및 통신 등의 용도로 널리 사용되고 있다.

Method: 위성들이 데이터를 수집하고 로컬에서 처리하며, 지상 스테이션이 로컬 모델을 집계하는 연방식 접근 방식을 채택한다. 통신량과 크기를 줄이는 여러 메커니즘을 활용하여 정확한 학습 모델을 생성하는 알고리즘을 설계한다.

Result: 제안한 알고리즘은 실제 우주 시나리오에서의 시뮬레이션을 통해 최신 기술과 비교하여 우수한 성능을 보여준다.

Conclusion: 결과적으로, 정확성을 향상시키는 오류 피드백 메커니즘을 제안하며, 이는 더 넓은 적용이 가능한 알고리즘 비의존적 오류 피드백 방식으로 연결된다.

Abstract: Satellite constellations in low-Earth orbit are now widespread, enabling positioning, Earth imaging, and communications. In this paper we address the solution of learning problems using these satellite constellations. In particular, we focus on a federated approach, where satellites collect and locally process data, with the ground station aggregating local models. We focus on designing a novel, communication-efficient algorithm that still yields accurate trained models. To this end, we employ several mechanisms to reduce the number of communications with the ground station (local training) and their size (compression). We then propose an error feedback mechanism that enhances accuracy, which yields, as a byproduct, an algorithm-agnostic error feedback scheme that can be more broadly applied. We analyze the convergence of the resulting algorithm, and compare it with the state of the art through simulations in a realistic space scenario, showcasing superior performance.

</details>


### [46] [Decoupling and Damping: Structurally-Regularized Gradient Matching for Multimodal Graph Condensation](https://arxiv.org/abs/2511.20222)
*Lian Shen,Zhendan Chen,Yinhui jiang,Meijia Song,Ziming Su,Juan Liu,Xiangrong Liu*

Main category: cs.LG

TL;DR: 본 논문은 멀티모달 그래프를 위한 Structurally-Regularized Gradient Matching(SR-GM)이라는 새로운 응축 프레임워크를 제안하여 기존의 그래프 신경망(GNN) 훈련에서 발생하는 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: e-커머스 및 추천 시스템과 같은 중요한 웹 응용 프로그램에서 멀티모달 그래프의 중요성이 커지고 있지만, 대규모 데이터가 GNN 훈련에 상당한 계산 부담을 초래합니다.

Method: SR-GM은 정규화된 기울기 일치 프레임워크를 도입하여 모달 간의 충돌을 해결하고, 그래프의 구조적 에너지를 활용하여 최적화 과정에서 안정화 효과를 제공합니다.

Result: SR-GM은 정확도를 크게 향상시키고 수렴 속도를 가속화하며, ablation 연구를 통해 기울기 충돌 및 구조적 증폭 문제를 동시에 해결해야 우수한 성능을 얻을 수 있음을 확인했습니다.

Conclusion: 이 연구는 자원이 제한된 환경에서 멀티모달 그래프 기반 학습을 위한 확장 가능한 방법론을 제공합니다.

Abstract: In critical web applications such as e-commerce and recommendation systems, multimodal graphs integrating rich visual and textual attributes are increasingly central, yet their large scale introduces substantial computational burdens for training Graph Neural Networks (GNNs). While Graph Condensation (GC) offers a promising solution by synthesizing smaller datasets, existing methods falter in the multimodal setting. We identify a dual challenge causing this failure: (1) conflicting gradients arising from semantic misalignments between modalities, and (2) the GNN's message-passing architecture pathologically amplifying this gradient noise across the graph structure. To address this, we propose Structurally-Regularized Gradient Matching (SR-GM), a novel condensation framework tailored for multimodal graphs. SR-GM introduces two synergistic components: first, a gradient decoupling mechanism that resolves inter-modality conflicts at their source via orthogonal projection; and second, a structural damping regularizer that acts directly on the gradient field. By leveraging the graph's Dirichlet energy, this regularizer transforms the topology from a noise amplifier into a stabilizing force during optimization. Extensive experiments demonstrate that SR-GM significantly improves accuracy and accelerates convergence compared to baseline methods. Ablation studies confirm that addressing both gradient conflict and structural amplification in tandem is essential for achieving superior performance. Moreover, the condensed multimodal graphs exhibit strong cross-architecture generalization and promise to accelerate applications like Neural Architecture Search. This research provides a scalable methodology for multimodal graph-based learning in resource-constrained environments.

</details>


### [47] [DiCaP: Distribution-Calibrated Pseudo-labeling for Semi-Supervised Multi-Label Learning](https://arxiv.org/abs/2511.20225)
*Bo Han,Zhuoming Li,Xiaoyu Wang,Yaxin Hou,Hui Liu,Junhui Hou,Yuheng Jia*

Main category: cs.LG

TL;DR: 본 논문은 정답 가능성에 기반하여 의사 레이블 가중치를 조정하는 Distribution-Calibrated Pseudo-labeling(DiCaP) 프레임워크를 제안하며, 다중 레이블 학습에서 성능을 개선하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 레이블 학습에서 제한된 레이블 데이터 문제를 해결하기 위해unlabeled data를 활용하여 모델 성능을 향상시킬 필요가 있습니다.

Method: 본 연구에서는 의사 레이블의 올바름 가능성에 따라 가중치를 조정하는 DiCaP 프레임워크를 제안하고, 신뢰성이 높은 샘플과 모호한 샘플을 구분하는 이중 임계값 메커니즘을 도입합니다.

Result: 우리 방법은 여러 벤치마크 데이터셋에서 일관된 성능 향상을 달성하였으며, 최신 방법 대비 최대 4.27% 향상을 보였습니다.

Conclusion: 제안된 방법은 다중 레이블 학습에서 의사 레이블 가중치 조정의 중요성을 강조하며, 신뢰도 기반의 접근 방식이 효과적임을 보여줍니다.

Abstract: Semi-supervised multi-label learning (SSMLL) aims to address the challenge of limited labeled data in multi-label learning (MLL) by leveraging unlabeled data to improve the model's performance. While pseudo-labeling has become a dominant strategy in SSMLL, most existing methods assign equal weights to all pseudo-labels regardless of their quality, which can amplify the impact of noisy or uncertain predictions and degrade the overall performance. In this paper, we theoretically verify that the optimal weight for a pseudo-label should reflect its correctness likelihood. Empirically, we observe that on the same dataset, the correctness likelihood distribution of unlabeled data remains stable, even as the number of labeled training samples varies. Building on this insight, we propose Distribution-Calibrated Pseudo-labeling (DiCaP), a correctness-aware framework that estimates posterior precision to calibrate pseudo-label weights. We further introduce a dual-thresholding mechanism to separate confident and ambiguous regions: confident samples are pseudo-labeled and weighted accordingly, while ambiguous ones are explored by unsupervised contrastive learning. Experiments conducted on multiple benchmark datasets verify that our method achieves consistent improvements, surpassing state-of-the-art methods by up to 4.27%.

</details>


### [48] [Leveraging weights signals -- Predicting and improving generalizability in reinforcement learning](https://arxiv.org/abs/2511.20234)
*Olivier Moulin,Vincent Francois-lavet,Paul Elbers,Mark Hoogendoorn*

Main category: cs.LG

TL;DR: 이 논문은 강화 학습 에이전트의 일반화 가능성을 향상시키는 새로운 방법론을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 에이전트는 훈련된 환경에만 적합해지는 경향이 있어 다양한 환경에서의 성능이 떨어진다는 문제점이 있다.

Method: 에이전트의 신경망 내부 가중치를 기반으로 에이전트의 일반화 점수를 예측하는 새로운 방법론을 도입하고, 이를 통해 Proximal Policy Optimization (PPO) 손실 함수에 변화를 제안한다.

Result: 개선된 PPO 알고리즘은 원본에 비해 더 강력한 일반화 성능을 가진 에이전트를 생성해낸다.

Conclusion: 우리의 접근 방식은 RL 에이전트의 일반화 가능성을 높이는 데 효과적임을 실험 결과를 통해 입증한다.

Abstract: Generalizability of Reinforcement Learning (RL) agents (ability to perform on environments different from the ones they have been trained on) is a key problem as agents have the tendency to overfit to their training environments. In order to address this problem and offer a solution to increase the generalizability of RL agents, we introduce a new methodology to predict the generalizability score of RL agents based on the internal weights of the agent's neural networks. Using this prediction capability, we propose some changes in the Proximal Policy Optimization (PPO) loss function to boost the generalization score of the agents trained with this upgraded version. Experimental results demonstrate that our improved PPO algorithm yields agents with stronger generalizability compared to the original version.

</details>


### [49] [Complexity Reduction Study Based on RD Costs Approximation for VVC Intra Partitioning](https://arxiv.org/abs/2511.20349)
*M. E. A. Kherchouche,F. Galpin,T. Dumas,F. Schnitzler,D. Menard,L. Zhang*

Main category: cs.LG

TL;DR: 이 연구에서는 VVC intra partitioning의 복잡성을 연구하여 RDO 과정의 전체 탐색을 가속화하는 방법을 다룹니다.


<details>
  <summary>Details</summary>
Motivation: RDO 과정에서의 전체 탐색을 가속화하기 위해 VVC intra partitioning의 복잡성 연구가 필요합니다.

Method: 우리는 두 가지 주요 머신 러닝 기법을 제안하고 비교합니다. 제안된 접근 방식은 크기와 무관하며, 이웃 블록의 RD 비용을 입력 feature로 활용합니다. 첫 번째 방법은 주어진 Coding Unit (CU)의 정규화된 RD 비용을 예측하는 회귀 기반 방법입니다. 두 번째 접근 방식은 DQN 알고리즘을 사용하여 두 깊이의 CU 결정 경로에서 학습된 RL 에이전트입니다.

Result: 제안된 방법들은 CU에 대한 적합한 분할을 선택하는 데 효과적임을 보여줍니다.

Conclusion: 이 연구는 VVC intra partitioning의 복잡성을 줄이는 새로운 머신 러닝 접근 방식을 제안하며 RDO 과정의 효율성을 향상시킵니다.

Abstract: In this paper, a complexity study is conducted for Versatile Video Codec (VVC) intra partitioning to accelerate the exhaustive search involved in Rate-Distortion Optimization (RDO) process. To address this problem, two main machine learning techniques are proposed and compared. Unlike existing methods, the proposed approaches are size independent and incorporate the Rate-Distortion (RD) costs of neighboring blocks as input features. The first method is a regression based technique that predicts normalized RD costs of a given Coding Unit (CU). As partitioning possesses the Markov property, the associated decision-making problem can be modeled as a Markov Decision Process (MDP) and solved by Reinforcement Learning (RL). The second approach is a RL agent learned from trajectories of CU decision across two depths with Deep Q-Network (DQN) algorithm. Then a pre-determined thresholds are applied for both methods to select a suitable split for the current CU.

</details>


### [50] [MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology](https://arxiv.org/abs/2511.20490)
*Kiril Vasilev,Alexandre Misrahi,Eeshaan Jain,Phil F Cheng,Petros Liakopoulos,Olivier Michielin,Michael Moor,Charlotte Bunne*

Main category: cs.LG

TL;DR: MTBBench는 다중 모달과 장기적인 암 관련 질문을 통해 MTB 스타일의 의사 결정 과정을 모의하는 에이전트 벤치마크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 다중 모달 대규모 언어 모델(LLM)이 생물 의학적 추론에 잠재력을 가지고 있지만, 현재 기준은 실제 임상 작업의 복잡성을 포착하지 못한다.

Method: MTBBench는 클리니컬 도전과제가 있는 다중 모달 및 장기적인 암 질문을 통해 MTB 스타일의 의사 결정을 시뮬레이션하는 벤치마크이다.

Result: 여러 개방 및 폐쇄 소스 LLM을 벤치마크하고, 이들이 신뢰성이 부족하고, 시간 해결 데이터에 대한 추론에 어려움을 겪으며, 충돌하는 증거나 서로 다른 모달리티를 조화롭게 하는 데 실패하는 것을 보여준다.

Conclusion: MTBBench는 LLM의 다중 모달 및 장기적 추론을 향상시키는 기본 모델 기반 도구를 제공함으로써, 정밀 종양학의 MTB 환경에 중점을 둔 신뢰성 및 도구 활용을 발전시키기 위한 도전적이고 현실적인 테스트베드를 제공한다.

Abstract: Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.

</details>


### [51] [Attention Trajectories as a Diagnostic Axis for Deep Reinforcement Learning](https://arxiv.org/abs/2511.20591)
*Charlotte Beylier,Hannah Selder,Arthur Fleig,Simon M. Hofmann,Nico Scherf*

Main category: cs.LG

TL;DR: 강화학습(RL) 에이전트의 학습 과정을 깊이 이해하기 위해, 우리는 주의 지향 메트릭(ATOMs)을 도입하여 훈련 중 에이전트의 주의력 발달을 조사했습니다.


<details>
  <summary>Details</summary>
Motivation: 강화학습 에이전트의 학습 과정은 그 학습 알고리즘의 수학적 정식 외에는 잘 이해되지 않고 있습니다.

Method: 우리는 Pong 게임의 세 가지 변형에서 ATOM을 테스트하여 에이전트가 각각의 게임에서 고유한 행동을 학습하는 방법을 평가했습니다.

Result: ATOM은 각각의 게임 변형에서 훈련된 에이전트의 주의력 패턴을 성공적으로 구분했으며, 이러한 주의력 패턴의 차이가 에이전트의 행동 차이와 일치함을 보여주었습니다.

Conclusion: ATOM은 강화학습 에이전트의 학습 과정을 이해하고 주의력과 학습 간의 관계를 더 잘 이해하는 데 도움을 줄 수 있다고 믿습니다.

Abstract: The learning process of a reinforcement learning (RL) agent remains poorly understood beyond the mathematical formulation of its learning algorithm. To address this gap, we introduce attention-oriented metrics (ATOMs) to investigate the development of an RL agent's attention during training. In a controlled experiment, we tested ATOMs on three variations of a Pong game, each designed to teach the agent distinct behaviours, complemented by a behavioural assessment. ATOMs successfully delineate the attention patterns of an agent trained on each game variation, and that these differences in attention patterns translate into differences in the agent's behaviour. Through continuous monitoring of ATOMs during training, we observed that the agent's attention developed in phases, and that these phases were consistent across game variations. Overall, we believe that ATOM could help improve our understanding of the learning processes of RL agents and better understand the relationship between attention and learning.

</details>


### [52] [Sparse-to-Field Reconstruction via Stochastic Neural Dynamic Mode Decomposition](https://arxiv.org/abs/2511.20612)
*Yujin Kim,Sarah Dean*

Main category: cs.LG

TL;DR: Stochastic NODE-DMD는 연속 시간의 비선형 동역학을 모델링하는 확률적 DMD 확장으로, 관측 밀도가 10%일 때도 높은 재구성 정확도를 달성합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 세계의 동적 시스템은 모델링하기 어려우며, 이러한 시스템의 거동을 학습하는 것은 과학적 기계 학습의 주요 도전 과제입니다.

Method: Stochastic NODE-DMD는 비선형 동역학을 모델링하면서도 해석 가능성을 유지하는 확률적 DMD의 확장입니다.

Result: 4개의 벤치마크에서 합성 설정과 3개의 물리 기반 흐름으로, 관측 밀도가 10%일 때도 재구성 정확도에서 baseline을 초과했습니다.

Conclusion: 우리의 방법은 여러 실현이 있는 데이터셋에서 앙상블 변동성을 보존하는 잠재적 동역학에 대한 교정된 분포를 학습합니다.

Abstract: Many consequential real-world systems, like wind fields and ocean currents, are dynamic and hard to model. Learning their governing dynamics remains a central challenge in scientific machine learning. Dynamic Mode Decomposition (DMD) provides a simple, data-driven approximation, but practical use is limited by sparse/noisy observations from continuous fields, reliance on linear approximations, and the lack of principled uncertainty quantification. To address these issues, we introduce Stochastic NODE-DMD, a probabilistic extension of DMD that models continuous-time, nonlinear dynamics while remaining interpretable. Our approach enables continuous spatiotemporal reconstruction at arbitrary coordinates and quantifies predictive uncertainty. Across four benchmarks, a synthetic setting and three physics-based flows, it surpasses a baseline in reconstruction accuracy when trained from only 10% observation density. It further recovers the dynamical structure by aligning learned modes and continuous-time eigenvalues with ground truth. Finally, on datasets with multiple realizations, our method learns a calibrated distribution over latent dynamics that preserves ensemble variability rather than averaging across regimes. Our code is available at: https://github.com/sedan-group/Stochastic-NODE-DMD

</details>


### [53] [ROOT: Robust Orthogonalized Optimizer for Neural Network Training](https://arxiv.org/abs/2511.20626)
*Wei He,Kai Han,Hang Zhou,Hanting Chen,Zhicheng Liu,Xinghao Chen,Yunhe Wang*

Main category: cs.LG

TL;DR: ROOT는 훈련 안정성을 강화하기 위해 이중 견고성 메커니즘을 활용하는 강력한 직교 최적화 기법이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 최적화는 모델 확장으로 인한 알고리즘 불확실성과 훈련 불안정성의 민감성이 증가함에 따라 중요한 도전 과제가 되었음.

Method: 우리는 적응형 뉴턴 반복을 사용한 차원 견고한 직교화 방식을 개발하고, 근접 최적화를 통해 외부 노이즈를 억제하는 최적화 견고 프레임워크를 도입함.

Result: ROOT는 Muon 및 Adam 기반 최적화 기법에 비해 노이즈가 있는 비볼록 시나리오에서 더 빠른 수렴과 우수한 최종 성능을 달성함.

Conclusion: 우리의 연구는 현대 대규모 모델 훈련의 복잡성을 처리할 수 있는 강력하고 정밀한 최적화 기법 개발을 위한 새로운 패러다임을 확립함.

Abstract: The optimization of large language models (LLMs) remains a critical challenge, particularly as model scaling exacerbates sensitivity to algorithmic imprecision and training instability. Recent advances in optimizers have improved convergence efficiency through momentum orthogonalization, but suffer from two key robustness limitations: dimensional fragility in orthogonalization precision and vulnerability to outlier-induced noise. To address these robustness challenges, we introduce ROOT, a Robust Orthogonalized Optimizer that enhances training stability through dual robustness mechanisms. First, we develop a dimension-robust orthogonalization scheme using adaptive Newton iterations with fine-grained coefficients tailored to specific matrix sizes, ensuring consistent precision across diverse architectural configurations. Second, we introduce an optimization-robust framework via proximal optimization that suppresses outlier noise while preserving meaningful gradient directions. Extensive experiments demonstrate that ROOT achieves significantly improved robustness, with faster convergence and superior final performance compared to both Muon and Adam-based optimizers, particularly in noisy and non-convex scenarios. Our work establishes a new paradigm for developing robust and precise optimizers capable of handling the complexities of modern large-scale model training. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/ROOT.

</details>
