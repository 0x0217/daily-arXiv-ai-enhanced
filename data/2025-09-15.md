<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 7]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Meta-Learning Reinforcement Learning for Crypto-Return Prediction](https://arxiv.org/abs/2509.09751)
*Junqiao Wang,Zhaoyang Guan,Guanyu Liu,Tianze Xia,Xianzhi Li,Shuo Yin,Xinyuan Song,Chuhan Cheng,Tianyu Shi,Alex Lee*

Main category: cs.LG

TL;DR: Meta-RL-Crypto는 메타 학습과 강화 학습을 통합한 거래 에이전트로, 사람의 감독 없이 스스로 개선하며 가상통화 수익률 예측을 수행합니다.


<details>
  <summary>Details</summary>
Motivation: 가상통화의 수익률 예측은 불확실성과 복잡성 때문에 매우 어렵습니다.

Method: Meta-RL-Crypto는 변형기 기반의 아키텍처로, 세 가지 역할(행위자, 판사, 메타 판사)을 순환하며 학습합니다.

Result: 다양한 시장 환경에서 실험을 통해, Meta-RL-Crypto는 실제 시장의 기술 지표에서 우수한 성능을 보여주며 다른 LLM 기반의 기준보다 뛰어난 결과를 얻었습니다.

Conclusion: Meta-RL-Crypto는 기존의 LLM 기반 모델들보다 효과적인 거래 정책과 평가 기준을 지속적으로 개선합니다.

Abstract: Predicting cryptocurrency returns is notoriously difficult: price movements
are driven by a fast-shifting blend of on-chain activity, news flow, and social
sentiment, while labeled training data are scarce and expensive. In this paper,
we present Meta-RL-Crypto, a unified transformer-based architecture that
unifies meta-learning and reinforcement learning (RL) to create a fully
self-improving trading agent. Starting from a vanilla instruction-tuned LLM,
the agent iteratively alternates between three roles-actor, judge, and
meta-judge-in a closed-loop architecture. This learning process requires no
additional human supervision. It can leverage multimodal market inputs and
internal preference feedback. The agent in the system continuously refines both
the trading policy and evaluation criteria. Experiments across diverse market
regimes demonstrate that Meta-RL-Crypto shows good performance on the technical
indicators of the real market and outperforming other LLM-based baselines.

</details>


### [2] [Latency and Token-Aware Test-Time Compute](https://arxiv.org/abs/2509.09864)
*Jenny Y. Huang,Mehul Damani,Yousef El-Kurdi,Ramon Astudillo,Wei Sun*

Main category: cs.LG

TL;DR: 이 논문은 대형 언어 모델의 성능 향상을 위한 동적 계산 할당 및 방법 선택 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 성능을 향상시키기 위해 테스트 시간에 여러 후보 응답을 생성하고 그 중에서 선택하는 방법이 필요하다.

Method: 우리는 추론 시간 스케일링을 동적 계산 할당 및 방법 선택 문제로 공식화하며, 시스템이 각 쿼리마다 적용할 전략과 할당할 계산량을 결정해야 한다.

Result: 실험 결과, 우리의 접근 방식이 정적 전략을 지속적으로 능가하며, 정확도-비용 trade-off에서 유리한 결과를 얻었다.

Conclusion: 우리는 사용자 경험을 고려하여 토큰 비용과 지연 시간을 모두 포함하는 프레임워크를 통해 실용적인 배포가 가능함을 보여준다.

Abstract: Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

</details>


### [3] [SciML Agents: Write the Solver, Not the Solution](https://arxiv.org/abs/2509.09936)
*Saarth Gaonkar,Xiang Zheng,Haocheng Xi,Rishabh Tiwari,Kurt Keutzer,Dmitriy Morozov,Michael W. Mahoney,Amir Gholami*

Main category: cs.LG

TL;DR: LLM을 이용해 수치 알고리즘을 활용하는 코드를 생성하여 과학적 문제를 해결하는 방법을 탐구하며, 새로운 데이터셋을 통해 LLM의 성능을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 과학적 기계 학습에서 높은 정확도와 견고성을 달성하는 것이 도전적이며, LLM을 사용하여 코드를 작성함으로써 이 문제를 해결할 수 있는지를 조사한다.

Method: 자연어 ODE 설명을 바탕으로 실행 가능한 코드를 생성할 수 있는 LLMs의 가능성을 탐색하고, 두 가지 새로운 데이터셋을 소개한다.

Result: 상당한 맥락과 지침을 제공했을 때, 최신 모델들이 높은 정확도를 달성하는 것을 발견했다.

Conclusion: 신중한 프롬프트와 미세 조정이 신뢰할 수 있는 LLM 에이전트를 생성할 수 있음을 나타낸다.

Abstract: Recent work in scientific machine learning aims to tackle scientific tasks
directly by predicting target values with neural networks (e.g.,
physics-informed neural networks, neural ODEs, neural operators, etc.), but
attaining high accuracy and robustness has been challenging. We explore an
alternative view: use LLMs to write code that leverages decades of numerical
algorithms. This shifts the burden from learning a solution function to making
domain-aware numerical choices. We ask whether LLMs can act as SciML agents
that, given a natural-language ODE description, generate runnable code that is
scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),
and enforcing stability checks. There is currently no benchmark to measure this
kind of capability for scientific computing tasks. As such, we first introduce
two new datasets: a diagnostic dataset of adversarial "misleading" problems;
and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set
contains problems whose superficial appearance suggests stiffness, and that
require algebraic simplification to demonstrate non-stiffness; and the
large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-
and closed-source LLM models along two axes: (i) unguided versus guided
prompting with domain-specific knowledge; and (ii) off-the-shelf versus
fine-tuned variants. Our evaluation measures both executability and numerical
validity against reference solutions. We find that with sufficient context and
guided prompts, newer instruction-following models achieve high accuracy on
both criteria. In many cases, recent open-source systems perform strongly
without fine-tuning, while older or smaller models still benefit from
fine-tuning. Overall, our preliminary results indicate that careful prompting
and fine-tuning can yield a specialized LLM agent capable of reliably solving
simple ODE problems.

</details>


### [4] [Neural Scaling Laws for Deep Regression](https://arxiv.org/abs/2509.10000)
*Tilen Cadez,Kyoung-Min Kim*

Main category: cs.LG

TL;DR: 딥 회귀 모델에서 신경 스케일링 법칙을 실험적으로 조사한 연구.


<details>
  <summary>Details</summary>
Motivation: 신뢰할 수 있는 모델을 개발하면서 제한된 자원을 관리하기 위해 신경 스케일링 법칙이 중요하다.

Method: 비틀린 반데르발스 자석에 대한 매개변수 추정 모델을 사용하여 딥 회귀에서 신경 스케일링 법칙을 조사했다.

Result: 손실과 훈련 데이터셋 크기 및 모델 용량 간의 파워-로우 관계를 관찰했다.

Conclusion: 데이터 크기가 증가함에 따라 딥 회귀 모델의 성능이 상당히 향상될 수 있음을 제안한다.

Abstract: Neural scaling laws--power-law relationships between generalization errors
and characteristics of deep learning models--are vital tools for developing
reliable models while managing limited resources. Although the success of large
language models highlights the importance of these laws, their application to
deep regression models remains largely unexplored. Here, we empirically
investigate neural scaling laws in deep regression using a parameter estimation
model for twisted van der Waals magnets. We observe power-law relationships
between the loss and both training dataset size and model capacity across a
wide range of values, employing various architectures--including fully
connected networks, residual networks, and vision transformers. Furthermore,
the scaling exponents governing these relationships range from 1 to 2, with
specific values depending on the regressed parameters and model details. The
consistent scaling behaviors and their large scaling exponents suggest that the
performance of deep regression models can improve substantially with increasing
data size.

</details>


### [5] [Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks](https://arxiv.org/abs/2509.10163)
*Francisco Javier Esono Nkulu Andong,Qi Min*

Main category: cs.LG

TL;DR: 이 논문은 6G 네트워크에서의 에너지 효율적이고 프라이버시를 보호하는 자원 관리를 위한 새로운 연합 다중 에이전트 강화 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 6G 네트워크가 초밀집, 지능형 엣지 환경으로 이동함에 따라 프라이버시, 이동성 및 에너지 제약 아래에서 효율적인 자원 관리가 중요해졌다.

Method: 연합 다중 에이전트 강화 학습(Fed-MARL) 프레임워크를 소개하며, 에지 장치 간의 자원 관리를 위해 MAC 계층과 응용 계층의 교차 계층 오케스트레이션을 통합한다. 각 에이전트는 지역 관찰을 기반으로 분산 정책을 학습하기 위해 심층 반복 Q-네트워크(DRQN)를 사용한다.

Result: 시뮬레이션 결과, Fed-MARL이 작업 성공률, 대기 시간, 에너지 효율성, 공정성에서 중앙 집중식 MARL 및 휴리스틱 기준선보다 뛰어난 성능을 보임을 보여준다.

Conclusion: Fed-MARL은 동적이고 자원이 제한된 6G 엣지 네트워크에서 강력한 프라이버시 보호를 보장하면서도 확장성을 유지한다.

Abstract: As sixth-generation (6G) networks move toward ultra-dense, intelligent edge
environments, efficient resource management under stringent privacy, mobility,
and energy constraints becomes critical. This paper introduces a novel
Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework that
incorporates cross-layer orchestration of both the MAC layer and application
layer for energy-efficient, privacy-preserving, and real-time resource
management across heterogeneous edge devices. Each agent uses a Deep Recurrent
Q-Network (DRQN) to learn decentralized policies for task offloading, spectrum
access, and CPU energy adaptation based on local observations (e.g., queue
length, energy, CPU usage, and mobility). To protect privacy, we introduce a
secure aggregation protocol based on elliptic curve Diffie Hellman key
exchange, which ensures accurate model updates without exposing raw data to
semi-honest adversaries. We formulate the resource management problem as a
partially observable multi-agent Markov decision process (POMMDP) with a
multi-objective reward function that jointly optimizes latency, energy
efficiency, spectral efficiency, fairness, and reliability under 6G-specific
service requirements such as URLLC, eMBB, and mMTC. Simulation results
demonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines
in task success rate, latency, energy efficiency, and fairness, while ensuring
robust privacy protection and scalability in dynamic, resource-constrained 6G
edge networks.

</details>


### [6] [Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning](https://arxiv.org/abs/2509.10273)
*Sahil Sethi,Kai Sundmacher,Caroline Ganzer*

Main category: cs.LG

TL;DR: 이 논문은 이온 액체(IL)의 주요 열물리적 속성을 예측하기 위해 신경 추천 시스템(NRS)을 활용한 데이터 기반 전이 학습 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 이온 액체의 다양한 응용을 위한 전통적인 용매를 대체하기 위해서는 이들의 열물리적 속성을 정확하게 예측하는 것이 필요하지만, 화학 설계 공간이 방대하고 실험 데이터가 제한되어 있어 어려움이 있었습니다.

Method: 우리는 COSMO-RS 기반의 시뮬레이션 데이터를 사용하여 cation과 anion에 대한 속성 특화된 구조 임베딩을 학습하도록 고정 온도와 압력에서 NRS 모델을 사전 훈련하고, 이를 바탕으로 실험 데이터를 사용해 간단한 피드포워드 신경망을 미세 조정하는 두 단계의 접근 방식을 사용했습니다.

Result: 밀도, 점도, 표면 장력, 열용량 및 융점 등 다섯 가지 핵심 IL 속성에 대한 예측을 통해, 사전 훈련된 모델이 모두 네 가지 속성에서 개선된 성능을 달성했으며, 모델은 이전에 보지 못한 IL에 대한 강력한 외삽 능력을 보였습니다.

Conclusion: 마지막으로 훈련된 모델은 700,000개 이상의 IL 조합에 대한 속성 예측을 가능하게 하여 프로세스 설계에서 IL 스크리닝을 위한 확장 가능한 솔루션을 제공합니다. 본 연구는 시뮬레이션 데이터와 전이 학습을 결합하여 실험 데이터의 희소성을 극복하는 효과성을 강조합니다.

Abstract: Ionic liquids (ILs) have emerged as versatile replacements for traditional
solvents because their physicochemical properties can be precisely tailored to
various applications. However, accurately predicting key thermophysical
properties remains challenging due to the vast chemical design space and the
limited availability of experimental data. In this study, we present a
data-driven transfer learning framework that leverages a neural recommender
system (NRS) to enable reliable property prediction for ILs using sparse
experimental datasets. The approach involves a two-stage process: first,
pre-training NRS models on COSMO-RS-based simulated data at fixed temperature
and pressure to learn property-specific structural embeddings for cations and
anions; and second, fine-tuning simple feedforward neural networks using these
embeddings with experimental data at varying temperatures and pressures. In
this work, five essential IL properties are considered: density, viscosity,
surface tension, heat capacity, and melting point. The framework supports both
within-property and cross-property knowledge transfer. Notably, pre-trained
models for density, viscosity, and heat capacity are used to fine-tune models
for all five target properties, achieving improved performance by a substantial
margin for four of them. The model exhibits robust extrapolation to previously
unseen ILs. Moreover, the final trained models enable property prediction for
over 700,000 IL combinations, offering a scalable solution for IL screening in
process design. This work highlights the effectiveness of combining simulated
data and transfer learning to overcome sparsity in the experimental data.

</details>


### [7] [Physics-informed sensor coverage through structure preserving machine learning](https://arxiv.org/abs/2509.10363)
*Benjamin David Shaffer,Brooks Kinch,Joseph Klobusicky,M. Ani Hsieh,Nathaniel Trask*

Main category: cs.LG

TL;DR: 이 논문은 적응형 원천 탐지를 위한 기계 학습 프레임워크를 제시하며, 이는 에이전트가 결합된 수리역학-전달 시스템의 구조 보존 디지털 트윈을 사용하여 실시간 경로 계획 및 데이터 동화에 활용된다.


<details>
  <summary>Details</summary>
Motivation: 적응형 원천 탐지의 필요성이 커지고 있으며, 기존 방법의 한계를 극복하기 위한 새로운 접근 방식이 요구된다.

Method: 조건부 신경 위트니 형식(CNWF)을 사용하여 디지털 트윈을 구축하고, 이는 유한 요소 외부 미적분(FEEC)과 트랜스포머 기반 운영자 학습을 결합한다.

Result: 제안된 모델은 이산 보존을 유지하고, 스트리밍 센서 데이터에 실시간으로 적응하며, 센서 측정과 호환되는 축소된 위트니 형식 기초와 통합 균형 방정식을 식별한다.

Conclusion: 실험 비교 결과, 물리적 제약이 적용될 때 복잡한 기하학에서 정확성이 향상되어 구조 보존이 원천 식별을 위한 효과적인 유도 편향을 제공함을 강조한다.

Abstract: We present a machine learning framework for adaptive source localization in
which agents use a structure-preserving digital twin of a coupled
hydrodynamic-transport system for real-time trajectory planning and data
assimilation. The twin is constructed with conditional neural Whitney forms
(CNWF), coupling the numerical guarantees of finite element exterior calculus
(FEEC) with transformer-based operator learning. The resulting model preserves
discrete conservation, and adapts in real time to streaming sensor data. It
employs a conditional attention mechanism to identify: a reduced Whitney-form
basis; reduced integral balance equations; and a source field, each compatible
with given sensor measurements. The induced reduced-order environmental model
retains the stability and consistency of standard finite-element simulation,
yielding a physically realizable, regular mapping from sensor data to the
source field. We propose a staggered scheme that alternates between evaluating
the digital twin and applying Lloyd's algorithm to guide sensor placement, with
analysis providing conditions for monotone improvement of a coverage
functional. Using the predicted source field as an importance function within
an optimal-recovery scheme, we demonstrate recovery of point sources under
continuity assumptions, highlighting the role of regularity as a sufficient
condition for localization. Experimental comparisons with physics-agnostic
transformer architectures show improved accuracy in complex geometries when
physical constraints are enforced, indicating that structure preservation
provides an effective inductive bias for source identification.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [8] [ZORRO: Zero-Knowledge Robustness and Privacy for Split Learning (Full Version)](https://arxiv.org/abs/2509.09787)
*Nojan Sheybani,Alessandro Pegoraro,Jonathan Knauer,Phillip Rieger,Elissa Mollakuqe,Farinaz Koushanfar,Ahmad-Reza Sadeghi*

Main category: cs.CR

TL;DR: ZORRO는 Split Learning을 위한 개인적이고 검증 가능한 강력한 방어 체계로, 클라이언트가 방어 알고리즘을 올바르게 실행함을 증명하도록 해준다.


<details>
  <summary>Details</summary>
Motivation: Split Learning은 자원이 제한된 클라이언트들이 중심 서버에 대부분의 레이어를 오프로드하여 깊은 신경망을 공동으로 훈련할 수 있도록 하는 학습 방법이다. 그러나 분산된 특성으로 인해 악의적인 클라이언트가 훈련 과정을 조작할 수 있는 위험이 있다.

Method: ZORRO는 클라이언트가 클라이언트에 위치한 방어 알고리즘을 올바르게 실행함을 증명하도록 해 주는 인터랙티브 제로 지식 증명(ZKP)을 활용하는 새로운 설계를 통해 작동한다.

Result: 우리의 평가에서 ZORRO는 공격 성공률을 6% 이하로 줄여주었으며, 클라이언트 측에 100만 개의 매개변수를 저장하는 모델에 대해서도 10초 이하의 오버헤드를 유발한다.

Conclusion: ZORRO는 신뢰할 수 없는 환경에서도 클라이언트가 benign 체크포인트를 올바르게 전달하도록 보장하여 Split Learning의 안전성을 높인다.

Abstract: Split Learning (SL) is a distributed learning approach that enables
resource-constrained clients to collaboratively train deep neural networks
(DNNs) by offloading most layers to a central server while keeping in- and
output layers on the client-side. This setup enables SL to leverage server
computation capacities without sharing data, making it highly effective in
resource-constrained environments dealing with sensitive data. However, the
distributed nature enables malicious clients to manipulate the training
process. By sending poisoned intermediate gradients, they can inject backdoors
into the shared DNN. Existing defenses are limited by often focusing on
server-side protection and introducing additional overhead for the server. A
significant challenge for client-side defenses is enforcing malicious clients
to correctly execute the defense algorithm.
  We present ZORRO, a private, verifiable, and robust SL defense scheme.
Through our novel design and application of interactive zero-knowledge proofs
(ZKPs), clients prove their correct execution of a client-located defense
algorithm, resulting in proofs of computational integrity attesting to the
benign nature of locally trained DNN portions. Leveraging the frequency
representation of model partitions enables ZORRO to conduct an in-depth
inspection of the locally trained models in an untrusted environment, ensuring
that each client forwards a benign checkpoint to its succeeding client. In our
extensive evaluation, covering different model architectures as well as various
attack strategies and data scenarios, we show ZORRO's effectiveness, as it
reduces the attack success rate to less than 6\% while causing even for models
storing \numprint{1000000} parameters on the client-side an overhead of less
than 10 seconds.

</details>


### [9] [Byte by Byte: Unmasking Browser Fingerprinting at the Function Level Using V8 Bytecode Transformers](https://arxiv.org/abs/2509.09950)
*Pouneh Nikkhah Bahrami,Dylan Cutler,Igor Bilogrevic*

Main category: cs.CR

TL;DR: ByteDefender는 V8 엔진 바이트코드를 활용하여 자바스크립트 함수 수준에서 브라우저 지문 인식 작업을 탐지하는 첫 번째 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 브라우저 지문 인식은 미세한 기법을 통해 지속적인 크로스 사이트 사용자 추적을 가능하게 하지만, 이는 기존 방어 방법을 회피하거나 스크립트 수준에서 차단할 경우 웹사이트가 깨지는 문제를 일으킨다.

Method: ByteDefender는 V8 엔진 바이트코드를 활용하여 지문 인식 작업을 자바스크립트 함수 수준에서 탐지하는 시스템이다. 변환기 기반 분류기가 바이트코드 시퀀스에 대해 오프라인으로 훈련되어 지문 인식 행동을 보이는 함수를 정확히 식별한다.

Result: 이 모델에서 파생된 경량 서명을 개발하여 컴파일 중, 실행 전에 함수 바이트코드에 대한 저오버헤드의 장치 내 매칭을 가능하게 하며, 이는 페이지 로드 시간에 평균 4%의 지연만 추가된다.

Conclusion: ByteDefender는 실질적인 프레임워크를 제공하여 효과적이고 정밀하며 견고한 지문 인식 완화를 가능하게 한다.

Abstract: Browser fingerprinting enables persistent cross-site user tracking via subtle
techniques that often evade conventional defenses or cause website breakage
when script-level blocking countermeasures are applied. Addressing these
challenges requires detection methods offering both function-level precision to
minimize breakage and inherent robustness against code obfuscation and URL
manipulation.
  We introduce ByteDefender, the first system leveraging V8 engine bytecode to
detect fingerprinting operations specifically at the JavaScript function level.
A Transformer-based classifier, trained offline on bytecode sequences,
accurately identifies functions exhibiting fingerprinting behavior. We develop
and evaluate light-weight signatures derived from this model to enable
low-overhead, on-device matching against function bytecode during compilation
but prior to execution, which only adds a 4% (average) latency to the page load
time. This mechanism facilitates targeted, real-time prevention of
fingerprinting function execution, thereby preserving legitimate script
functionality. Operating directly on bytecode ensures inherent resilience
against common code obfuscation and URL-based evasion. Our evaluation on the
top 100k websites demonstrates high detection accuracy at both function- and
script-level, with substantial improvements over state-of-the-art AST-based
methods, particularly in robustness against obfuscation. ByteDefender offers a
practical framework for effective, precise, and robust fingerprinting
mitigation.

</details>


### [10] [Securing LLM-Generated Embedded Firmware through AI Agent-Driven Validation and Patching](https://arxiv.org/abs/2509.09970)
*Seyed Moein Abtahi,Akramul Azim*

Main category: cs.CR

TL;DR: 이 논문은 LLM 기반 펌웨어 생성을 자동화된 보안 검증 및 반복적 개선 방법과 결합한 3단계 방법론을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 임베디드 시스템의 펌웨어 생성에서 기여할 수 있지만, 보안 취약성 및 실시간 성능 제약을 충족하지 못하는 문제를 해결하고자 한다.

Method: 구조화된 프롬프트를 통해 네트워킹 및 제어 작업을 위한 펌웨어가 생성되며, 이를 통해 QEMU를 이용해 FreeRTOS에 배포된다. 다양한 보안 검증 기법을 통해 취약성을 검사한다.

Result: 실험 결과 92.4%의 취약점 수정률과 95.8%의 위협 모델 준수율을 얻었으며, 실시간 메트릭은 8.6ms의 최악의 경우 실행 시간과 195μs의 지터를 기록하였다.

Conclusion: 이 과정은 펌웨어의 보안과 성능을 향상시키며, 향후 연구를 위한 오픈 소스 데이터셋에 기여한다.

Abstract: Large Language Models (LLMs) show promise in generating firmware for embedded
systems, but often introduce security flaws and fail to meet real-time
performance constraints. This paper proposes a three-phase methodology that
combines LLM-based firmware generation with automated security validation and
iterative refinement in a virtualized environment. Using structured prompts,
models like GPT-4 generate firmware for networking and control tasks, deployed
on FreeRTOS via QEMU. These implementations are tested using fuzzing, static
analysis, and runtime monitoring to detect vulnerabilities such as buffer
overflows (CWE-120), race conditions (CWE-362), and denial-of-service threats
(CWE-400). Specialized AI agents for Threat Detection, Performance
Optimization, and Compliance Verification collaborate to improve detection and
remediation. Identified issues are categorized using CWE, then used to prompt
targeted LLM-generated patches in an iterative loop. Experiments show a 92.4\%
Vulnerability Remediation Rate (37.3\% improvement), 95.8\% Threat Model
Compliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms
worst-case execution time and 195{\mu}s jitter. This process enhances firmware
security and performance while contributing an open-source dataset for future
research.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [11] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 이 논문은 자동 형식화의 개념을 검토하고, 서로 다른 연구 분야 간의 협력을 통해 다음 세대 AI 시스템 개발을 촉진하기 위한 통합 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자동 형식화는 수학의 형식화를 자동화하는 과정으로서, 다양한 연구 분야에서 비공식 언어를 형식적 표현으로 변환하는 기술이 필요합니다.

Method: 이 논문은 자동 형식화를 직접적으로 또는 간접적으로 고려한 사례들을 검토하고, 다양한 분야 간의 협력을 촉진하기 위한 통합된 프레임워크를 제안합니다.

Result: 자동 형식화의 개념을 확장하고, LLM을 활용하여 형식적 표현으로의 번역을 연구하는 여러 접근 방식을 조망합니다.

Conclusion: 자동 형식화라는 개념은 수학을 넘어서 더 넓은 의미로 확장되어 있으며, 향후 AI 시스템 개발을 위한 연구 간의 협력이 중요함을 강조합니다.

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [12] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 이 연구는 농장염소의 건강 관리를 지원하기 위해 설계된 지능형 지식 보조 시스템을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)이 여러 산업에서 귀중한 지식 전달 도구로 인식되고 있지만, 축산업에서의 활용은 지식 출처의 가용성, 다양성 및 복잡성 등 여러 요인으로 제한되고 있다.

Method: 회수 증강 생성(RAG)을 활용하여 두 가지 구조화된 지식 처리 방법, 즉 표 텍스트화와 결정 트리 텍스트화를 제안했다.

Result: 실험 결과, 이질적 지식 융합 방법이 가장 우수한 결과를 보여주었고, 검증 세트에서 평균 정확도 87.90%, 테스트 세트에서 84.22%에 도달했다.

Conclusion: 결과는 야생염소 농사에서의 실제 적용을 위한 제안된 시스템의 견고성과 신뢰성을 강조한다.

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [13] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)이 사용자에게 도움을 줄 수 있는 능력을 연구하여, UNO 카드 게임에서 다른 플레이어를 돕는 역할을 수행 가능한지 시험하였다.


<details>
  <summary>Details</summary>
Motivation: LLM이 단순히 질문에 답하는 것을 넘어 다양한 작업에서 유용한 지도를 제공할 수 있는지 이해하기 위해.

Method: UNO라는 턴제 카드 게임에서 LLM을 참여시키고, 승리하는 것이 아니라 다른 플레이어가 승리할 수 있도록 돕는 방식으로 테스트하였다.

Result: 모든 모델이 무작위 기준을 초월하였으나, 대부분의 모델이 다른 플레이어를 유의미하게 도와주는 데에는 한계가 있었다.

Conclusion: 모델의 크기는 성능에 영향을 미치지만, 효과적으로 다른 플레이어를 지원하는 데 있어서는 제한적이다.

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [14] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: 이 논문은 분산된 시설과 이질적인 자원의 조정이 필요한 현대 과학 발견을 위한 개념적 프레임워크를 제안하며, 전통적인 업무 흐름 관리 시스템에서 완전 자율 분산 과학 실험실로의 진화 경로를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현대 과학 발견은 분산 시설과 이질적 자원의 조정이 점점 더 필요해지고 있으며, 연구자들이 과학자보다는 수동적인 작업 흐름 조정자로 활동해야 하는 상황이다.

Method: 이 논문에서는 정적에서 지능형으로, 단일에서 군집으로 발전하는 두 가지 차원에 따라 업무 흐름이 진화하는 개념적 프레임워크를 제안한다.

Result: 우리는 자율적인 과학을 활용하기 위한 다음 단계를 진행하는 데 도움이 될 수 있는 아키텍처 설계를 제시하며, 이는 100배의 발견 가속화와 혁신적인 과학적 작업 흐름의 잠재력을 가진다.

Conclusion: 이 프레임워크는 과학 발견을 가속화하고 전환하는 데 기여할 수 있는 새로운 방법을 제시한다.

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [15] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 다공성 물질의 자동 특성화는 소재 발견을 가속화할 가능성이 있지만, 시뮬레이션 설정 및 힘 장 선택의 복잡성으로 인해 제한됩니다.


<details>
  <summary>Details</summary>
Motivation: 다공성 물질의 특성화를 자동화하여 소재 발견을 가속화하고자 함.

Method: LLM 기반의 에이전트들이 자율적으로 특성화 작업을 이해하고, 적절한 시뮬레이션을 계획하며, 관련 힘 장을 조립하고, 이를 실행하여 결과를 해석하는 다중 에이전트 프레임워크를 제안함.

Result: 초기 평가에서 높은 정확성과 재현성이 입증되었으며, 이는 완전 자율적이고 확장 가능한 소재 특성화를 가능하게 할 잠재력을 강조함.

Conclusion: 자동화된 RASPA 시뮬레이션 설정과 문헌 기반 힘 장 추출을 위한 다중 에이전트 시스템을 통해 이 비전의 첫 번째 단계를 제시함.

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [16] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 현실 세계 환경에서 배치된 강화 학습(RL) 에이전트는 센서 결함, 액츄에이터 마모 및 환경 변화로 인해 성능 저하를 겪지만 이러한 실패를 감지하고 진단할 내재적 메커니즘이 부족하다. 본 연구에서는 RL의 근본적인 동적 특성을 드러내고 배치 시기의 이상 상태를 진단하기 위한 실용적인 방법을 제공하는 정보 이론적 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 실제 환경에서 RL 에이전트가 센서 결함 및 환경 변화로부터 성능 저하를 겪는 현상을 해결하고자 한다.

Method: 로봇 제어 작업에서의 상태-행동 상호 정보를 분석하여 정보를 파악하는 패턴을 보여주고, 정보 메트릭스를 사용하여 시스템 장애를 진단하는 방법을 제시한다.

Result: 성공적인 학습은 상태와 행동 간의 상호 정보가 0.84에서 2.83 비트(238% 증가)로 안정적으로 증가함을 보이며, 이 과정에서 상태의 엔트로피는 증가하지만 에이전트는 과제 관련 패턴에 점점 선택적 주의를 기울인다.

Conclusion: 정보 패턴을 학습의 서명 및 시스템 건강 진단에 대한 지표로 설정함으로써, 자율적인 장애 탐지 및 정책 조정을 위한 적응형 RL 시스템의 기초를 제공한다.

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


### [17] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 이 논문은 WaveFunctionCollapse(WFC)를 마르코프 결정 프로세스(MDP)로 재구성하여 설계자가 지정한 목표와 인접성 제약을 최적화하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 디자이너가 지정한 목표와 기본 격자 집합에 의해 암묵적으로 부과된 인접성 제약을 모두 충족할 필요가 있다.

Method: WFC를 MDP로 재구성하여 외부 최적화 알고리즘이 제약 만족을 보장하면서 목표 극대화에만 집중할 수 있도록 한다.

Result: 여러 도메인에서 전통적 진화 접근법과 비교하였을 때, 복잡성이 증가함에 따라 공동 최적화가 어려움을 겪고 WFC-MDP에 비해 일관되게 저조한 성능을 보였다.

Conclusion: 지역 제약 만족과 글로벌 목표 최적화를 분리하는 것이 이점이 있음을 강조한다.

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [18] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: GAMA는 대규모 언어 모델을 사용하는 다중 에이전트 시스템에서 개인 데이터 보호를 위해 개인 및 공공 공간으로 작업 공간을 구분하여 프라이버시를 보호하는 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 기반의 다중 에이전트 시스템에서 개인 데이터의 안전한 처리가 필요하다.

Method: GAMA는 에이전트의 작업 공간을 개인 및 공공 공간으로 나누고, 익명화 메커니즘을 통해 개인정보를 보호한다. 또한, 익명화로 인한 의미 손실을 줄이기 위해 DRKE 및 DLE 모듈을 포함한다.

Result: GAMA는 Trivia Creative Writing 및 Logic Grid Puzzle 두 가지 공개 질문 응답 데이터 셋에서 최신 모델에 비해 우수한 성능을 보였다.

Conclusion: GAMA는 작업 처리와 개인 정보 보호 모두에서 뛰어난 효과를 발휘한다.

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [19] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents는 멀티 에이전트 시스템의 복잡한 작업 수행 능력을 향상시키기 위해 제안된 통합 프레임워크로, 동적 작업 계획과 작업 불확실성 처리를 지원한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 발전은 멀티 에이전트 시스템이 복잡한 작업을 지원하는 능력을 크게 향상시켰지만, 여전히 불확실성을 가진 복잡한 작업의 효과적인 계획에 어려움을 겪고 있다.

Method: XAgents는 다극 작업 처리 그래프와 IF-THEN 규칙을 기반으로 한 멀티 에이전트 협력 프레임워크이다. 이 시스템은 동적 작업 계획을 가능하게 하고 작업 불확실성을 처리한다.

Result: XAgents는 세 가지 서로 다른 데이터 세트에서 평가되었으며, 지식 기반 질문-응답 작업과 논리 기반 질문-응답 작업 모두에서 최첨단 단일 에이전트 및 다중 에이전트 접근 방식을 지속적으로 초월했다.

Conclusion: XAgents는 멀티 에이전트 시스템의 행동을 제어하고 에이전트 간 협업을 향상시키는 데 효과적인 프레임워크를 제공한다.

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [20] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 자율 AI 에이전트의 빠른 채택은 새로운 경제 계층을 형성하고 있으며, 우리는 이를 '샌드박스 경제'라는 프레임워크로 분석하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 자율 AI 에이전트의 급속한 채택으로 인해 인간의 직접적인 감독을 초월하는 거래 및 조정이 발생하고 있기 때문에, 이에 대한 분석을 위한 새로운 틀을 제안할 필요가 있다.

Method: 샌드박스 경제라는 프레임워크를 통해 emergent(자발적) vs. intentional(의도적), permeable(투과성) vs. impermeable(비투과성) 두 가지 차원으로 이 시스템을 특성화하였다.

Result: 현재의 경로는 방대한 규모의 높은 투과성을 가진 AI 에이전트 경제의 자발적 출현을 가리키며, 이는 전례 없는 조정 기회를 제공하고, 동시에 체계적인 경제적 위험과 불평등 심화라는 상당한 도전을 안겨준다.

Conclusion: 안전하게 조정 가능한 AI 에이전트 시장을 설계하기 위한 여러 가지 선택안에 대해 논의하며, 인류의 장기적인 공동 번영에 부합하는 기술적 변화를 보장하기 위한 능동적인 설계를 주장한다.

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [21] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 온라인 계획 설정에서는 제한된 데이터에서 강건한 의사 결정을 내릴 수 있는 새로운 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 샘플 기반 방법들이 실용적인 설정에서의 모델 불확실성으로 인해 성능 저하를 초래할 수 있는 문제를 해결하기 위함입니다.

Method: Robust Sparse Sampling (RSS) 알고리즘을 도입하여, 유한한 샘플 이론적 성능 보장을 제공하는 온라인 계획 알고리즘입니다.

Result: RSS는 기존의 Sparse Sampling 방식보다 불확실한 동적 환경에서 더 나은 성능을 보입니다.

Conclusion: 이 방법은 무한 또는 연속 상태 공간에 적용 가능하며, 샘플 및 계산 복잡성이 상태 공간 크기에 독립적입니다.

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [22] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: CARENL은 임상 자연어 추론(NLI)을 위한 분리된 추론 접근 방식으로, 지식 접근과 원칙적 추론을 분리하여 LLM의 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: NLI에서 데이터를 확장하면 더욱 구조화되고 일반화된 내부 표현이 나타난다는 가정을 조사합니다.

Method: CARENLI는 각 전제-진술 쌍을 특정 추론 가족에 맞는 해결사로 라우팅하고, 계획자, 검증자 및 정제자를 통해 감사 가능한 절차를 시행합니다.

Result: 네 가지 LLM에서 CARENLI는 충실도를 최대 42포인트 개선하며, 인과 귀속에서 98.0%, 위험 상태 추상화에서 81.2%에 도달합니다.

Conclusion: LLM은 종종 관련 사실을 유지하지만, 추론이 불확실할 때 발견적 접근을 default로 사용하며, CARENLI는 이를 명확하게 하고 더 안전하고 감사 가능한 추론을 위한 프레임워크를 제공합니다.

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [23] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: 다중 에이전트 시스템에서 실패 귀속은 중요한 문제이며, 본 논문은 이를 해결하기 위해 A2P 스캐폴딩을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 실패 귀속을 정확하게 파악하는 것은 복잡한 시스템 디버깅에 필수적이다.

Method: A2P 스캐폴딩은 패턴 인식을 구조적 인과 추론 과제로 변환하여 에이전트의 행동 뒤에 숨겨진 근본 원인을 추론하는 3단계 과정으로 구성된다.

Result: A2P는 Who&When 벤치마크에서 47.46%의 단계 정확도를 달성했으며, 이는 기존 기준의 2.85배 향상된 수치이다.

Conclusion: A2P 스캐폴딩은 자동화된 실패 귀속을 위한 신뢰할 수 있고 유의미하게 더 정확한 해결책을 제공한다.

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [24] [Tackling One Health Risks: How Large Language Models are leveraged for Risk Negotiation and Consensus-building](https://arxiv.org/abs/2509.09906)
*Alexandra Fetsch,Iurii Savvateev,Racem Ben Romdhane,Martin Wiedmann,Artemiy Dimov,Maciej Durkalec,Josef Teichmann,Jakob Zinsstag,Konstantinos Koutsoumanis,Andreja Rajkovic,Jason Mann,Mauro Tonolla,Monika Ehling-Schulz,Matthias Filter,Sophia Johler*

Main category: cs.MA

TL;DR: 이 연구는 AI 보조 협상 프레임워크를 제시하여 다양한 이해관계자 간의 효과적인 협상을 촉진하고, 복잡한 리스크 분석을 단순화하는 방법을 모색합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 주요 글로벌 문제는 복잡한 상호 의존성으로 특징지어지며, 통합된 참여적 노력이 필요합니다.

Method: 우리는 대규모 언어 모델(LLM)과 AI 기반 자율 에이전트를 포함한 협상 중심 리스크 분석 워크플로우를 제시합니다.

Result: 이 프레임워크는 이해관계자들이 협상을 시뮬레이션하고, 역학을 체계적으로 모델링하며, 타협을 예상하고, 솔루션 영향을 평가할 수 있게 합니다.

Conclusion: AI 보조 협상의 가능성을 보여주며, 리소스가 제한된 광범위한 사용자들이 활용하고 요구에 맞게 조정할 수 있는 오픈 소스 웹 기반 설계를 제공합니다.

Abstract: Key global challenges of our times are characterized by complex
interdependencies and can only be effectively addressed through an integrated,
participatory effort. Conventional risk analysis frameworks often reduce
complexity to ensure manageability, creating silos that hinder comprehensive
solutions. A fundamental shift towards holistic strategies is essential to
enable effective negotiations between different sectors and to balance the
competing interests of stakeholders. However, achieving this balance is often
hindered by limited time, vast amounts of information, and the complexity of
integrating diverse perspectives. This study presents an AI-assisted
negotiation framework that incorporates large language models (LLMs) and
AI-based autonomous agents into a negotiation-centered risk analysis workflow.
The framework enables stakeholders to simulate negotiations, systematically
model dynamics, anticipate compromises, and evaluate solution impacts. By
leveraging LLMs' semantic analysis capabilities we could mitigate information
overload and augment decision-making process under time constraints.
Proof-of-concept implementations were conducted in two real-world scenarios:
(i) prudent use of a biopesticide, and (ii) targeted wild animal population
control. Our work demonstrates the potential of AI-assisted negotiation to
address the current lack of tools for cross-sectoral engagement. Importantly,
the solution's open source, web based design, suits for application by a
broader audience with limited resources and enables users to tailor and develop
it for their own needs.

</details>


### [25] [A Holistic Architecture for Monitoring and Optimization of Robust Multi-Agent Path Finding Plan Execution](https://arxiv.org/abs/2509.10284)
*David Zahrádka,Denisa Mužíková,David Woller,Miroslav Kulich,Jiří Švancara,Roman Barták*

Main category: cs.MA

TL;DR: 다수의 에이전트 경로 찾기(MAPF)의 목표는 에이전트들이 서로 충돌하지 않고 목표에 도달할 수 있는 경로 세트를 찾는 것이다. 본 논문에서는 MAPF 계획의 강건한 실행을 위한 구조를 제안하고, 실행 중 예상 실행 기간을 유지하기 위해 액션 의존성 그래프를 활용한다.


<details>
  <summary>Details</summary>
Motivation: 본 연구의 동기는 로봇의 실행 지연으로 인한 충돌 위험을 줄이고, 최적의 계획을 계속 실행하는 것이 아닌 더 짧은 실행 시간을 보장하는 대체 계획을 찾기 위한 결정 시점을 파악하는 것이다.

Method: 강건한 실행 방법인 액션 의존성 그래프를 통해 계획 실행 중 예상 실행 기간을 추정하고, 이를 바탕으로 대체 계획을 찾아야 할 시점을 예측한다.

Result: 설계한 실시간 시뮬레이터에서 실험을 통해 제안된 구조의 효과를 실증적으로 평가하였다.

Conclusion: 이 연구는 MAPF 계획의 강건한 실행을 위한 새로운 아키텍처를 제공하며, 실행 중 발생할 수 있는 지연 상황을 효과적으로 고려할 수 있도록 한다.

Abstract: The goal of Multi-Agent Path Finding (MAPF) is to find a set of paths for a
fleet of agents moving in a shared environment such that the agents reach their
goals without colliding with each other. In practice, some of the robots
executing the plan may get delayed, which can introduce collision risk.
Although robust execution methods are used to ensure safety even in the
presence of delays, the delays may still have a significant impact on the
duration of the execution. At some point, the accumulated delays may become
significant enough that instead of continuing with the execution of the
original plan, even if it was optimal, there may now exist an alternate plan
which will lead to a shorter execution. However, the problem is how to decide
when to search for the alternate plan, since it is a costly procedure. In this
paper, we propose a holistic architecture for robust execution of MAPF plans,
its monitoring and optimization. We exploit a robust execution method called
Action Dependency Graph to maintain an estimate of the expected execution
duration during the plan's execution. This estimate is used to predict the
potential that finding an alternate plan would lead to shorter execution. We
empirically evaluate the architecture in experiments in a real-time simulator
which we designed to mimic our real-life demonstrator of an autonomous
warehouse robotic fleet.

</details>
