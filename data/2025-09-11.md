<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 11]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.CR](#cs.CR) [Total: 7]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Machine Generalize Learning in Agent-Based Models: Going Beyond Surrogate Models for Calibration in ABMs](https://arxiv.org/abs/2509.07013)
*Sima Najafzadehkhoei,George Vega Yon,Bernardo Modenesi,Derek S. Meyer*

Main category: cs.LG

TL;DR: 감염병 에이전트 기반 모델의 보정은 계산적으로 어려운 작업이다. 본 논문에서는 감염병 시계열에서 SIR 매개변수로의 역 맵핑을 학습하는 감독 기계 학습 보정기를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 감염병 모델의 보정은 높은 계산 요구로 인해 어려운 점이 있다.

Method: 60일간의 발생률, 인구 크기, 회복률을 입력으로 하고, 전염 확률, 접촉률, R0을 출력하는 3층 양방향 LSTM을 활용한다. R0 * 회복률이 전염 확률 * 접촉률과 같도록 하는 일관성 패널티를 포함한 복합 손실을 이용하여 훈련한다.

Result: 1000개의 시나리오 시뮬레이션 연구에서 보정기는 모든 목표에서 더 낮은 오류를 달성했다(MAE: R0 0.0616 vs 0.275; 전염 0.0715 vs 0.128; 접촉 1.02 vs 4.24)

Conclusion: 접촉률과 전염 확률은 부분적으로 비식별성이 있지만, 이 방법은 ABC보다 역학 곡선을 더 정확하게 재현하여 빠르고 실용적인 보정을 가능하게 한다.

Abstract: Calibrating agent-based epidemic models is computationally demanding. We
present a supervised machine learning calibrator that learns the inverse
mapping from epidemic time series to SIR parameters. A three-layer
bidirectional LSTM ingests 60-day incidence together with population size and
recovery rate, and outputs transmission probability, contact rate, and R0.
Training uses a composite loss with an epidemiology-motivated consistency
penalty that encourages R0 \* recovery rate to equal transmission probability
\* contact rate.
  In a 1000-scenario simulation study, we compare the calibrator with
Approximate Bayesian Computation (likelihood-free MCMC). The method achieves
lower error across all targets (MAE: R0 0.0616 vs 0.275; transmission 0.0715 vs
0.128; contact 1.02 vs 4.24), produces tighter predictive intervals with near
nominal coverage, and reduces wall clock time from 77.4 s to 2.35 s per
calibration. Although contact rate and transmission probability are partially
nonidentifiable, the approach reproduces epidemic curves more faithfully than
ABC, enabling fast and practical calibration. We evaluate it on SIR agent based
epidemics generated with epiworldR and provide an implementation in R.

</details>


### [2] [An efficient deep reinforcement learning environment for flexible job-shop scheduling](https://arxiv.org/abs/2509.07019)
*Xinquan Wu,Xuefeng Yan,Mingqiang Wei,Donghai Guan*

Main category: cs.LG

TL;DR: 본 논문은 유연 작업장 스케줄링 문제를 위한 심층 강화 학습(DRL) 환경을 제안하고, 새로운 DRL 스케줄링 모델의 성능을 기존 방법들과 비교한다.


<details>
  <summary>Details</summary>
Motivation: FJSP에 대한 빠르고 정확한 스케줄링 솔루션을 생성하기 위해 DRL 스케줄링 방법들이 개발되었지만, DRL 환경 모델링이 간과되고 있다.

Method: 이 논문은 이산 이벤트 시뮬레이션을 기반으로 한 간단한 시간 순서적 DRL 환경을 소개하고, 근접 정책 최적화(PPO)를 기반으로 한 DRL 스케줄링 모델을 제안한다.

Result: 공식 벤치마크 인스턴스에 대한 실험 결과, 단순 우선 순위 배치 규칙(PDR)의 성능이 개선되었고, 우리의 DRL 스케줄링 모델은 OR-Tools, 메타 휴리스틱, DRL 및 PDR 스케줄링 방법들과 경쟁할 만한 성능을 나타낸다.

Conclusion: 제안된 방법은 FJSP 문제 해결에 있어 DRL 환경의 중요성을 강조하며, DRL 스케줄링 모델의 효율성을 입증한다.

Abstract: The Flexible Job-shop Scheduling Problem (FJSP) is a classical combinatorial
optimization problem that has a wide-range of applications in the real world.
In order to generate fast and accurate scheduling solutions for FJSP, various
deep reinforcement learning (DRL) scheduling methods have been developed.
However, these methods are mainly focused on the design of DRL scheduling
Agent, overlooking the modeling of DRL environment. This paper presents a
simple chronological DRL environment for FJSP based on discrete event
simulation and an end-to-end DRL scheduling model is proposed based on the
proximal policy optimization (PPO). Furthermore, a short novel state
representation of FJSP is proposed based on two state variables in the
scheduling environment and a novel comprehensible reward function is designed
based on the scheduling area of machines. Experimental results on public
benchmark instances show that the performance of simple priority dispatching
rules (PDR) is improved in our scheduling environment and our DRL scheduling
model obtains competing performance compared with OR-Tools, meta-heuristic, DRL
and PDR scheduling methods.

</details>


### [3] [Methodological Insights into Structural Causal Modelling and Uncertainty-Aware Forecasting for Economic Indicators](https://arxiv.org/abs/2509.07036)
*Federico Cerutti*

Main category: cs.LG

TL;DR: 재무 시계열 분석을 위한 방법론적 접근법을 제시하며, 미국의 주요 거시경제 지표에 대해 동적 인과 관계를 비모델적으로 발견하고 예측하여 결과적으로 정책 결정에 기여하는 연구이다.


<details>
  <summary>Details</summary>
Motivation: 거시경제 지표의 동적 인과 관계를 이해하고, 이를 바탕으로 정확한 예측을 통해 정책 결정에 도움을 주기 위해 이 연구를 수행하였다.

Method: LPCMCI 프레임워크와 가우시안 프로세스 거리 상관관계(GPDC)를 활용하여 1970년부터 2021년까지의 분기별 데이터를 분석하였다.

Result: 경제 성장과 GDP 간의 강한 일방적인 인과 관계를 밝혔으며, 인플레이션의 한정된 연결성과 실업의 자가 회귀적 의존성을 보여주었다.

Conclusion: 인과 구조 학습과 확률적 언어 모델의 결합을 통해 경제 정책에 대한 통찰과 예측의 견고성을 높이는 데 기여할 수 있음을 밝혔다.

Abstract: This paper presents a methodological approach to financial time series
analysis by combining causal discovery and uncertainty-aware forecasting. As a
case study, we focus on four key U.S. macroeconomic indicators -- GDP, economic
growth, inflation, and unemployment -- and we apply the LPCMCI framework with
Gaussian Process Distance Correlation (GPDC) to uncover dynamic causal
relationships in quarterly data from 1970 to 2021. Our results reveal a robust
unidirectional causal link from economic growth to GDP and highlight the
limited connectivity of inflation, suggesting the influence of latent factors.
Unemployment exhibits strong autoregressive dependence, motivating its use as a
case study for probabilistic forecasting. Leveraging the Chronos framework, a
large language model trained for time series, we perform zero-shot predictions
on unemployment. This approach delivers accurate forecasts one and two quarters
ahead, without requiring task-specific training. Crucially, the model's
uncertainty-aware predictions yield 90\% confidence intervals, enabling
effective anomaly detection through statistically principled deviation
analysis. This study demonstrates the value of combining causal structure
learning with probabilistic language models to inform economic policy and
enhance forecasting robustness.

</details>


### [4] [Benchmarking Vision Transformers and CNNs for Thermal Photovoltaic Fault Detection with Explainable AI Validation](https://arxiv.org/abs/2509.07039)
*Serra Aksoy*

Main category: cs.LG

TL;DR: 이 논문은 열 PV 결함 감지를 위한 CNN과 비전 트랜스포머의 비교를 제공하며, XRAI 분석을 통해 모델의 결정과 열 물리학 원칙의 일치를 평가합니다.


<details>
  <summary>Details</summary>
Motivation: AI 기반의 자동화된 태양광 모니터링이 에너지 인프라 애플리케이션에서 보급되는 데 필요한 해석 가능성을 높이고 싶었습니다.

Method: ResNet-18, EfficientNet-B0와 ViT-Tiny, Swin-Tiny를 비교하기 위해 XRAI 주목도 분석을 사용하여 열 PV 결함 탐지에서 이들의 성능을 평가했습니다.

Result: Swin Transformer가 94%의 이진 정확도와 73%의 다중 클래스 정확도로 CNN 접근법보다 두드러진 성과를 보였습니다.

Conclusion: 열 물리학에 기반한 해석 가능성 접근 방식은 AI 의사결정을 검증하기 위한 방법론을 제공하여 재생 에너지 인프라에서의 배포 장벽을 해결합니다.

Abstract: Artificial intelligence deployment for automated photovoltaic (PV) monitoring
faces interpretability barriers that limit adoption in energy infrastructure
applications. While deep learning achieves high accuracy in thermal fault
detection, validation that model decisions align with thermal physics
principles remains lacking, creating deployment hesitancy where understanding
model reasoning is critical. This study provides a systematic comparison of
convolutional neural networks (ResNet-18, EfficientNet-B0) and vision
transformers (ViT-Tiny, Swin-Tiny) for thermal PV fault detection, using XRAI
saliency analysis to assess alignment with thermal physics principles. This
represents the first systematic comparison of CNNs and vision transformers for
thermal PV fault detection with physics-validated interpretability. Evaluation
on 20,000 infrared images spanning normal operation and 11 fault categories
shows that Swin Transformer achieves the highest performance (94% binary
accuracy; 73% multiclass accuracy) compared to CNN approaches. XRAI analysis
reveals that models learn physically meaningful features, such as localized
hotspots for cell defects, linear thermal paths for diode failures, and thermal
boundaries for vegetation shading, consistent with expected thermal signatures.
However, performance varies significantly across fault types: electrical faults
achieve strong detection (F1-scores >0.90) while environmental factors like
soiling remain challenging (F1-scores 0.20-0.33), indicating limitations
imposed by thermal imaging resolution. The thermal physics-guided
interpretability approach provides methodology for validating AI
decision-making in energy monitoring applications, addressing deployment
barriers in renewable energy infrastructure.

</details>


### [5] [Predicting effect of novel treatments using molecular pathways and real-world data](https://arxiv.org/abs/2509.07204)
*Adrien Couetoux,Thomas Devenyns,Lise Diagne,David Champagne,Pierre-Yves Mousset,Chris Anagnostopoulos*

Main category: cs.LG

TL;DR: 이 논문에서는 임상 시험이나 실제 사용 전 테스트되지 않은 제약의 효과를 예측하는 유연하고 모듈화된 기계 학습 기반 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 제약 연구 개발에서 특정 질병에 대한 약물의 효능을 예측하는 것은 많은 어려움이 있습니다.

Method: 약물-경로 가중치 영향 점수와 환자 데이터를 사용하여 기계 학습 모델을 훈련합니다. 이 모델은 테스트되지 않은 약물의 가중치 영향 점수를 인간 생물학적 분자-단백질 경로에서 분석하여 예측된 효능 값을 생성합니다.

Result: 실제 데이터 세트를 사용하여 두 가지 다른 가중치 영향 점수 알고리즘으로 환자 치료 및 결과에 대한 방법을 시연합니다.

Conclusion: 이 접근 방식이 가장 예측적인 조건을 규명하는 방법과, 테스트되지 않은 약물의 효과를 예측하기 위한 초기 프레임워크로서의 발전 가능성을 논의합니다.

Abstract: In pharmaceutical R&D, predicting the efficacy of a pharmaceutical in
treating a particular disease prior to clinical testing or any real-world use
has been challenging. In this paper, we propose a flexible and modular machine
learning-based approach for predicting the efficacy of an untested
pharmaceutical for treating a disease. We train a machine learning model using
sets of pharmaceutical-pathway weight impact scores and patient data, which can
include patient characteristics and observed clinical outcomes. The resulting
model then analyses weighted impact scores of an untested pharmaceutical across
human biological molecule-protein pathways to generate a predicted efficacy
value. We demonstrate how the method works on a real-world dataset with patient
treatments and outcomes, with two different weight impact score algorithms We
include methods for evaluating the generalisation performance on unseen
treatments, and to characterise conditions under which the approach can be
expected to be most predictive. We discuss specific ways in which our approach
can be iterated on, making it an initial framework to support future work on
predicting the effect of untested drugs, leveraging RWD clinical data and drug
embeddings.

</details>


### [6] [CancerGUIDE: Cancer Guideline Understanding via Internal Disagreement Estimation](https://arxiv.org/abs/2509.07325)
*Alyssa Unell,Noel C. F. Codella,Sam Preston,Peniel Argaw,Wen-wai Yim,Zelalem Gero,Cliff Wong,Rajesh Jena,Eric Horvitz,Amanda K. Hall,Ruican Rachel Zhong,Jiachen Li,Shrey Jain,Mu Wei,Matthew Lungren,Hoifung Poon*

Main category: cs.LG

TL;DR: 이 연구는 비소세포 폐암 환자를 위한 가이드라인에 부합하는 치료 경로를 자동으로 생성하는 LLM 기반 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: NCCN은 암 치료에 대한 근거 기반 가이드라인을 제공하지만, 치료 추천을 생성하는 데 시간이 많이 소요되고 오류가 발생할 수 있습니다.

Method: 121명의 비소세포 폐암 환자를 대상으로 한 장기 데이터를 구축하고, 기존 LLM의 도메인 전문 지식을 활용하여 높은 품질의 벤치마크를 생성합니다.

Result: 전문가 주석과 강한 상관관계(r=0.88)와 함께 AUROC=0.800의 예측 정확성을 달성했습니다.

Conclusion: 이 연구는 치료 추천에 대한 예측 및 검증을 지원하는 LLM 기반 가이드라인 준수 시스템의 프레임워크를 확립합니다.

Abstract: The National Comprehensive Cancer Network (NCCN) provides evidence-based
guidelines for cancer treatment. Translating complex patient presentations into
guideline-compliant treatment recommendations is time-intensive, requires
specialized expertise, and is prone to error. Advances in large language model
(LLM) capabilities promise to reduce the time required to generate treatment
recommendations and improve accuracy. We present an LLM agent-based approach to
automatically generate guideline-concordant treatment trajectories for patients
with non-small cell lung cancer (NSCLC). Our contributions are threefold.
First, we construct a novel longitudinal dataset of 121 cases of NSCLC patients
that includes clinical encounters, diagnostic results, and medical histories,
each expertly annotated with the corresponding NCCN guideline trajectories by
board-certified oncologists. Second, we demonstrate that existing LLMs possess
domain-specific knowledge that enables high-quality proxy benchmark generation
for both model development and evaluation, achieving strong correlation
(Spearman coefficient r=0.88, RMSE = 0.08) with expert-annotated benchmarks.
Third, we develop a hybrid approach combining expensive human annotations with
model consistency information to create both the agent framework that predicts
the relevant guidelines for a patient, as well as a meta-classifier that
verifies prediction accuracy with calibrated confidence scores for treatment
recommendations (AUROC=0.800), a critical capability for communicating the
accuracy of outputs, custom-tailoring tradeoffs in performance, and supporting
regulatory compliance. This work establishes a framework for clinically viable
LLM-based guideline adherence systems that balance accuracy, interpretability,
and regulatory requirements while reducing annotation costs, providing a
scalable pathway toward automated clinical decision support.

</details>


### [7] [K2-Think: A Parameter-Efficient Reasoning System](https://arxiv.org/abs/2509.07604)
*Zhoujun Cheng,Richard Fan,Shibo Hao,Taylor W. Killian,Haonan Li,Suqi Sun,Hector Ren,Alexander Moreno,Daqian Zhang,Tianjun Zhong,Yuxin Xiong,Yuanzhe Hu,Yutao Xie,Xudong Han,Yuqi Wang,Varad Pimpalkhute,Yonghao Zhuang,Aaryamonvikram Singh,Xuezhi Liang,Anze Xie,Jianshu She,Desai Fan,Chengqian Gao,Liqun Ma,Mikhail Yurochkin,John Maggs,Xuezhe Ma,Guowei He,Zhiting Hu,Zhengzhong Liu,Eric P. Xing*

Main category: cs.LG

TL;DR: K2-Think는 32B 파라미터 모델로 최신 성능을 달성하며, GPT-OSS 120B 및 DeepSeek v3.1 같은 더 큰 모델과 경쟁합니다.


<details>
  <summary>Details</summary>
Motivation: 더 작은 모델이 높은 성능을 보일 수 있음을 보여줌으로써 모델 효율성을 극대화하고 접근성을 높이고자 함.

Method: Qwen2.5 기반 모델에 6가지 핵심 기술 기둥을 포함한 고급 후속 훈련 및 시험 시간 계산 기술을 혼합함.

Result: K2-Think는 수학적 추론에서 최신 성적을 달성하고 코드 및 과학 등 다른 영역에도 강력한 성능을 보임.

Conclusion: K2-Think 32B와 같은 더 효율적인 모델이 통합된 후속 훈련 레시피를 통해 최신 시스템과 경쟁할 수 있음을 확인했습니다.

Abstract: K2-Think is a reasoning system that achieves state-of-the-art performance
with a 32B parameter model, matching or surpassing much larger models like
GPT-OSS 120B and DeepSeek v3.1. Built on the Qwen2.5 base model, our system
shows that smaller models can compete at the highest levels by combining
advanced post-training and test-time computation techniques. The approach is
based on six key technical pillars: Long Chain-of-thought Supervised
Finetuning, Reinforcement Learning with Verifiable Rewards (RLVR), Agentic
planning prior to reasoning, Test-time Scaling, Speculative Decoding, and
Inference-optimized Hardware, all using publicly available open-source
datasets. K2-Think excels in mathematical reasoning, achieving state-of-the-art
scores on public benchmarks for open-source models, while also performing
strongly in other areas such as Code and Science. Our results confirm that a
more parameter-efficient model like K2-Think 32B can compete with
state-of-the-art systems through an integrated post-training recipe that
includes long chain-of-thought training and strategic inference-time
enhancements, making open-source reasoning systems more accessible and
affordable. K2-Think is freely available at k2think.ai, offering best-in-class
inference speeds of over 2,000 tokens per second per request via the Cerebras
Wafer-Scale Engine.

</details>


### [8] [Leveraging Support Vector Regression for Outcome Prediction in Personalized Ultra-fractionated Stereotactic Adaptive Radiotherapy](https://arxiv.org/abs/2509.07872)
*Yajun Yu,Steve Jiang,Robert Timmerman,Hao Peng*

Main category: cs.LG

TL;DR: 개인 맞춤형 초분할 스테레오택틱 적응 방사선 치료(PULSAR)를 위한 다중 오믹스 기반 서포트 벡터 회귀(SVR) 모델이 GTV 변화 예측에 효과적임을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: GTV 변화의 정확한 예측은 예후에 중요하며, 이를 개선하기 위한 새로운 접근법이 필요합니다.

Method: 39명의 환자를 대상으로 한 회고적 연구에서 방사선학 및 복용학 특성을 이용하여 SVR 모델을 개발하였습니다.

Result: 최고 성능 모델은 R2 0.743 및 RRMSE 0.022로 예측 정확도가 향상되었습니다.

Conclusion: 제안된 다중 오믹스 SVR 모델은 GTV의 지속적인 변화를 예측하는 데 유망한 성과를 보여줍니다.

Abstract: Personalized ultra-fractionated stereotactic adaptive radiotherapy (PULSAR)
is a novel treatment that delivers radiation in pulses of protracted intervals.
Accurate prediction of gross tumor volume (GTV) changes through regression
models has substantial prognostic value. This study aims to develop a
multi-omics based support vector regression (SVR) model for predicting GTV
change. A retrospective cohort of 39 patients with 69 brain metastases was
analyzed, based on radiomics (MRI images) and dosiomics (dose maps) features.
Delta features were computed to capture relative changes between two time
points. A feature selection pipeline using least absolute shrinkage and
selection operator (Lasso) algorithm with weight- or frequency-based ranking
criterion was implemented. SVR models with various kernels were evaluated using
the coefficient of determination (R2) and relative root mean square error
(RRMSE). Five-fold cross-validation with 10 repeats was employed to mitigate
the limitation of small data size. Multi-omics models that integrate radiomics,
dosiomics, and their delta counterparts outperform individual-omics models.
Delta-radiomic features play a critical role in enhancing prediction accuracy
relative to features at single time points. The top-performing model achieves
an R2 of 0.743 and an RRMSE of 0.022. The proposed multi-omics SVR model shows
promising performance in predicting continuous change of GTV. It provides a
more quantitative and personalized approach to assist patient selection and
treatment adjustment in PULSAR.

</details>


### [9] [Feasibility of In-Ear Single-Channel ExG for Wearable Sleep~Monitoring in Real-World Settings](https://arxiv.org/abs/2509.07896)
*Philipp Lepold,Jonas Leichtle,Tobias Röddiger,Michael Beigl*

Main category: cs.LG

TL;DR: 귀에 착용 가능한 전극을 사용한 자동 수면 단계 구분의 가능성 연구.


<details>
  <summary>Details</summary>
Motivation: 일상적인 환경에서 수면 모니터링의 필요성.

Method: 11명의 참가자와 함께 단일 채널 귀속 생리학적 신호를 이용하여 수면 실험을 수행.

Result: 이 시스템은 수면 감지에서 90.5%의 정확도와 네 가지 단계 구분에서 65.1%의 정확도를 기록했다.

Conclusion: 귀에 착용 가능한 전극이 수면 모니터링을 위한 손쉬운 접근 방식을 제공할 가능성을 시사한다.

Abstract: Automatic sleep staging typically relies on gold-standard EEG setups, which
are accurate but obtrusive and impractical for everyday use outside sleep
laboratories. This limits applicability in real-world settings, such as home
environments, where continuous, long-term monitoring is needed. Detecting sleep
onset is particularly relevant, enabling consumer applications (e.g.
automatically pausing media playback when the user falls asleep). Recent
research has shown correlations between in-ear EEG and full-scalp EEG for
various phenomena, suggesting wearable, in-ear devices could allow unobtrusive
sleep monitoring. We investigated the feasibility of using single-channel
in-ear electrophysiological (ExG) signals for automatic sleep staging in a
wearable device by conducting a sleep study with 11~participants (mean age:
24), using a custom earpiece with a dry eartip electrode (D\"atwyler SoftPulse)
as a measurement electrode in one ear and a reference in the other. Ground
truth sleep stages were obtained from an Apple Watch Ultra, validated for sleep
staging. Our system achieved 90.5% accuracy for binary sleep detection (Awake
vs. Asleep) and 65.1% accuracy for four-class staging (Awake, REM, Core, Deep)
using leave-one-subject-out validation. These findings demonstrate the
potential of in-ear electrodes as a low-effort, comfortable approach to sleep
monitoring, with applications such as stopping podcasts when users fall asleep.

</details>


### [10] [One Model for All Tasks: Leveraging Efficient World Models in Multi-Task Planning](https://arxiv.org/abs/2509.07945)
*Yuan Pu,Yazhe Niu,Jia Tang,Junyu Xiong,Shuai Hu,Hongsheng Li*

Main category: cs.LG

TL;DR: ScaleZero는 이종 다중 작업 학습 환경에서 성능을 향상시키기 위해 Mixture-of-Experts 아키텍처와 동적 매개변수 스케일링 전략을 통합한 모델이다.


<details>
  <summary>Details</summary>
Motivation: 대규모 이종 환경에서의 샘플 및 계산 효율성을 향상시키기 위해 기존의 다중 작업 모델의 한계를 극복할 필요가 있다.

Method: Mixture-of-Experts 아키텍처를 기반으로 한 ScaleZero 모델과 동적 매개변수 스케일링(DPS) 전략을 도입한다.

Result: ScaleZero는 단일 작업 기준선과 동등한 성능을 달성하며, 동적 매개변수 스케일링 전략을 통해 80%의 상호작용 단계만으로도 경쟁력을 갖춘 성능을 보여준다.

Conclusion: ScaleZero는 대규모 이종 다중 작업 학습에서 효과적인 가능성을 보여준다.

Abstract: In heterogeneous multi-task learning, tasks not only exhibit diverse
observation and action spaces but also vary substantially in intrinsic
difficulty. While conventional multi-task world models like UniZero excel in
single-task settings, we find that when handling large-scale heterogeneous
environments, gradient conflicts and the loss of model plasticity often
constrain their sample and computational efficiency. In this work, we address
these challenges from two perspectives: the single learning iteration and the
overall learning process. First, we investigate the impact of key design spaces
on extending UniZero to multi-task planning. We find that a Mixture-of-Experts
(MoE) architecture provides the most substantial performance gains by
mitigating gradient conflicts, leading to our proposed model,
\textit{ScaleZero}. Second, to dynamically balance the computational load
across the learning process, we introduce an online, LoRA-based \textit{dynamic
parameter scaling} (DPS) strategy. This strategy progressively integrates LoRA
adapters in response to task-specific progress, enabling adaptive knowledge
retention and parameter expansion. Empirical evaluations on standard benchmarks
such as Atari, DMControl (DMC), and Jericho demonstrate that ScaleZero, relying
exclusively on online reinforcement learning with one model, attains
performance on par with specialized single-task baselines. Furthermore, when
augmented with our dynamic parameter scaling strategy, our method achieves
competitive performance while requiring only 80\% of the single-task
environment interaction steps. These findings underscore the potential of
ScaleZero for effective large-scale multi-task learning. Our code is available
at \textcolor{magenta}{https://github.com/opendilab/LightZero}.

</details>


### [11] [ACE and Diverse Generalization via Selective Disagreement](https://arxiv.org/abs/2509.07955)
*Oliver Daniels,Stuart Armstrong,Alexandre Maranhão,Mahirah Fairuz Rahman,Benjamin M. Marlin,Rebecca Gorman*

Main category: cs.LG

TL;DR: 이 논문에서는 불완전한 상관관계에 의존하는 기존 방법들의 한계를 극복하기 위해 완전한 스푸리어스 상관관계를 다루는 새로운 방법, ACE를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 딥 뉴럴 네트워크가 스푸리어스 상관관계에 민감하다는 문제를 해결하기 위해.

Method: 훈련 데이터와 일관된 개념 세트를 학습하고, 새로운 레이블이 없는 입력의 하위 집합에 대해 상이한 예측을 생성하는 자기 학습 접근 방식을 사용합니다.

Result: ACE는 기존 방법들과 비교하여도 우수한 성능을 보여주며, 불완전한 스푸리어스 상관관계에 대해 견고성을 유지합니다.

Conclusion: ACE는 언더스펙화 문제를 극복하는 데 있어 중요한 발전을 보여줍니다.

Abstract: Deep neural networks are notoriously sensitive to spurious correlations -
where a model learns a shortcut that fails out-of-distribution. Existing work
on spurious correlations has often focused on incomplete
correlations,leveraging access to labeled instances that break the correlation.
But in cases where the spurious correlations are complete, the correct
generalization is fundamentally \textit{underspecified}. To resolve this
underspecification, we propose learning a set of concepts that are consistent
with training data but make distinct predictions on a subset of novel unlabeled
inputs. Using a self-training approach that encourages \textit{confident} and
\textit{selective} disagreement, our method ACE matches or outperforms existing
methods on a suite of complete-spurious correlation benchmarks, while remaining
robust to incomplete spurious correlations. ACE is also more configurable than
prior approaches, allowing for straight-forward encoding of prior knowledge and
principled unsupervised model selection. In an early application to
language-model alignment, we find that ACE achieves competitive performance on
the measurement tampering detection benchmark \textit{without} access to
untrusted measurements. While still subject to important limitations, ACE
represents significant progress towards overcoming underspecification.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [12] [Efficient Multi-Agent Coordination via Dynamic Joint-State Graph Construction](https://arxiv.org/abs/2509.07234)
*Yanlin Zhou,Manshi Limbu,Xuesu Xiao*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 경로 찾기 문제에서 팀 성능 향상을 위한 에이전트 간 협력 강화와 높은 위험 엣지에서의 이동 비용 절감을 주제로 다룹니다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계 응용 프로그램에서는 에이전트 간의 능동적인 조정이 필요합니다.

Method: 팀 조정을 위한 그래프와 위험 엣지 문제를 3D 매칭 문제로 재구성하고, 여러 효율적인 분해 방법을 제안했습니다.

Result: 동적 그래프 구축 방법(Dynamic-HJSG)을 도입하고 이론적 분석을 통해 최적성을 유지하면서 복잡도를 낮추었습니다.

Conclusion: 결과적으로, 이 연구는 다중 에이전트 경로 찾기 문제에 대한 협력적 경로 찾기를 위한 원칙적 프레임워크를 제공합니다.

Abstract: Multi-agent pathfinding (MAPF) traditionally focuses on collision avoidance,
but many real-world applications require active coordination between agents to
improve team performance. This paper introduces Team Coordination on Graphs
with Risky Edges (TCGRE), where agents collaborate to reduce traversal costs on
high-risk edges via support from teammates. We reformulate TCGRE as a 3D
matching problem-mapping robot pairs, support pairs, and time steps-and
rigorously prove its NP-hardness via reduction from Minimum 3D Matching. To
address this complexity, (in the conference version) we proposed efficient
decomposition methods, reducing the problem to tractable subproblems:
Joint-State Graph (JSG): Encodes coordination as a single-agent shortest-path
problem. Coordination-Exhaustive Search (CES): Optimizes support assignments
via exhaustive pairing. Receding-Horizon Optimistic Cooperative A* (RHOCA*):
Balances optimality and scalability via horizon-limited planning. Further in
this extension, we introduce a dynamic graph construction method
(Dynamic-HJSG), leveraging agent homogeneity to prune redundant states and
reduce computational overhead by constructing the joint-state graph
dynamically. Theoretical analysis shows Dynamic-HJSG preserves optimality while
lowering complexity from exponential to polynomial in key cases. Empirical
results validate scalability for large teams and graphs, with HJSG
outperforming baselines greatly in runtime in different sizes and types of
graphs. This work bridges combinatorial optimization and multi-agent planning,
offering a principled framework for collaborative pathfinding with provable
guarantees, and the key idea of the solution can be widely extended to many
other collaborative optimization problems, such as MAPF.

</details>


### [13] [Towards Generalized Routing: Model and Agent Orchestration for Adaptive and Efficient Inference](https://arxiv.org/abs/2509.07571)
*Xiyu Guo,Shan Wang,Chunfang Ji,Xuefeng Zhao,Wenhao Xi,Yaoyao Liu,Qinglan Li,Chao Deng,Junlan Feng*

Main category: cs.MA

TL;DR: MoMA라는 새로운 라우팅 프레임워크를 통해 사용자 쿼리를 효과적으로 관리하고 비용-성능 효율성을 극대화하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델과 도메인 특정 AI 에이전트의 급속한 발전에 따라 AI 기반 서비스 생태계가 확장되고 있지만, 사용자 쿼리의 다양성으로 인해 성능과 효율성을 최적화하는 라우팅 도전 과제가 발생하고 있다.

Method: MoMA(Mixture of Models and Agents)는 LLM과 에이전트 기반 라우팅을 통합한 일반화된 라우팅 프레임워크로, 모델 및 에이전트 능력에 대한 깊은 이해를 기반으로 하고 있다. 다양한 쿼리를 정확한 의도 인식과 적응형 라우팅 전략으로 효과적으로 처리한다.

Result: MoMA는 다양한 LLM 모델 구조에 대한 훈련 데이터셋을 구성하고, 쿼리를 비용-성능 효율성이 가장 높은 LLM으로 동적으로 라우팅하며, 효율적인 에이전트 선택 전략을 도입하여 실험 결과 기존 접근법보다 우수한 비용 효율성과 확장성을 보인다.

Conclusion: 기존 방법과 비교하여 MoMA 라우터가 더 나은 비용-효율성과 확장성을 제공한다는 것을 실험 결과가 입증하고 있다.

Abstract: The rapid advancement of large language models (LLMs) and domain-specific AI
agents has greatly expanded the ecosystem of AI-powered services. User queries,
however, are highly diverse and often span multiple domains and task types,
resulting in a complex and heterogeneous landscape. This diversity presents a
fundamental routing challenge: how to accurately direct each query to an
appropriate execution unit while optimizing both performance and efficiency. To
address this, we propose MoMA (Mixture of Models and Agents), a generalized
routing framework that integrates both LLM and agent-based routing. Built upon
a deep understanding of model and agent capabilities, MoMA effectively handles
diverse queries through precise intent recognition and adaptive routing
strategies, achieving an optimal balance between efficiency and cost.
Specifically, we construct a detailed training dataset to profile the
capabilities of various LLMs under different routing model structures,
identifying the most suitable tasks for each LLM. During inference, queries are
dynamically routed to the LLM with the best cost-performance efficiency. We
also introduce an efficient agent selection strategy based on a context-aware
state machine and dynamic masking. Experimental results demonstrate that the
MoMA router offers superior cost-efficiency and scalability compared to
existing approaches.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [14] [From Eigenmodes to Proofs: Integrating Graph Spectral Operators with Symbolic Interpretable Reasoning](https://arxiv.org/abs/2509.07017)
*Andrew Kiruluta,Priscilla Burity*

Main category: cs.AI

TL;DR: Spectral NSR는 스펙트럼 신경-기호 추론 프레임워크로, 논리 규칙을 스펙트럼 템플릿으로 내장하고 그래프 스펙트럼 영역에서 직접 추론을 수행합니다.


<details>
  <summary>Details</summary>
Motivation: 논리적 규칙의 해석 가능성과 스펙트럼 학습의 확장성 및 적응성을 통합하기 위해 Spectral NSR 프레임워크를 개발함.

Method: 그래프 신호 처리와 지식 그래프의 라플라시안 고유구조에 기반한 주파수 선택 필터를 활용하여 추론을 수행하는 방법을 제시함.

Result: Spectral NSR은 기존 최고의 기준선과 비교했을 때 뛰어난 정확도, 빠른 추론, 적대적 섭동에 대한 개선된 강건성 및 높은 해석 가능성을 나타냄.

Conclusion: Spectral NSR은 투명성, 강건성 및 일반화 능력을 제공하는 차세대 추론 시스템을 위한 확장 가능하고 원칙적인 기초로 자리 잡음.

Abstract: We introduce Spectral NSR, a fully spectral neuro-symbolic reasoning
framework that embeds logical rules as spectral templates and performs
inference directly in the graph spectral domain. By leveraging graph signal
processing (GSP) and frequency-selective filters grounded in the Laplacian
eigenstructure of knowledge graphs, the architecture unifies the
interpretability of symbolic reasoning with the scalability and adaptability of
spectral learning. Beyond the core formulation, we incorporate a comprehensive
set of extensions, including dynamic graph and basis learning, rational and
diffusion filters for sharper spectral selectivity, mixture-of-spectral-experts
for modular specialization, proof-guided training with spectral curricula, and
uncertainty quantification for calibrated confidence. Additional enhancements
such as large language model coupling, co-spectral transfer alignment,
adversarial robustness, efficient GPU kernels, generalized Laplacians, and
causal interventions further expand the versatility of the framework.
  Empirical evaluation on state-of-the-art reasoning benchmarks such as
ProofWriter and CLUTRR demonstrates that Spectral NSR achieves superior
accuracy, faster inference, improved robustness to adversarial perturbations,
and higher interpretability compared to leading baselines including
transformers, message-passing neural networks, and neuro-symbolic logic
programming systems. Spectral attribution and proof-band agreement analyses
confirm that model decisions align closely with symbolic proof structures,
while transfer experiments validate effective domain adaptation through
co-spectral alignment. These results establish Spectral NSR as a scalable and
principled foundation for the next generation of reasoning systems, offering
transparency, robustness, and generalization beyond conventional approaches.

</details>


### [15] [Instruction Agent: Enhancing Agent with Expert Demonstration](https://arxiv.org/abs/2509.07098)
*Yinheng Li,Hailey Hultquist,Justin Wagle,Kazuhito Koishida*

Main category: cs.AI

TL;DR: Instruction Agent는 전문가 시연을 활용하여 복잡한 GUI 작업을 해결하는 에이전트로, 높은 성공률을 기록한다.


<details>
  <summary>Details</summary>
Motivation: GUI 에이전트는 복잡한 작업에 어려움을 겪고 있으며, 이를 해결하기 위해 전문가 시연을 활용한 접근 방식이 필요하다.

Method: 단일 시연을 바탕으로 단계별 지침을 추출하고, 사용자가 의도한 경로를 엄격히 따르며 실행한다.

Result: Instruction Agent는 모든 상위 순위 에이전트가 완료하지 못한 OSWorld의 작업 집합에서 60%의 성공률을 달성했다.

Conclusion: Instruction Agent는 현재 GUI 에이전트와 신뢰할 수 있는 실제 GUI 작업 자동화 간의 격차를 해소하는 실용적이고 확장 가능한 프레임워크를 제공한다.

Abstract: Graphical user interface (GUI) agents have advanced rapidly but still
struggle with complex tasks involving novel UI elements, long-horizon actions,
and personalized trajectories. In this work, we introduce Instruction Agent, a
GUI agent that leverages expert demonstrations to solve such tasks, enabling
completion of otherwise difficult workflows. Given a single demonstration, the
agent extracts step-by-step instructions and executes them by strictly
following the trajectory intended by the user, which avoids making mistakes
during execution. The agent leverages the verifier and backtracker modules
further to improve robustness. Both modules are critical to understand the
current outcome from each action and handle unexpected interruptions(such as
pop-up windows) during execution. Our experiments show that Instruction Agent
achieves a 60% success rate on a set of tasks in OSWorld that all top-ranked
agents failed to complete. The Instruction Agent offers a practical and
extensible framework, bridging the gap between current GUI agents and reliable
real-world GUI task automation.

</details>


### [16] [HealthSLM-Bench: Benchmarking Small Language Models for Mobile and Wearable Healthcare Monitoring](https://arxiv.org/abs/2509.07260)
*Xin Wang,Ting Dang,Xinyu Zhang,Vassilis Kostakos,Michael J. Witbrock,Hong Jia*

Main category: cs.AI

TL;DR: 소형 언어 모델(SLMs)은 클라우드 기반의 대형 언어 모델(LLMs)을 대체할 수 있는 경량 모델로, 연구 결과 SLMs가 LLMs와 유사한 성능을 보이면서 효율성과 프라이버시에서 상당한 이점을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 모바일 및 웨어러블 헬스케어 모니터링이 개인의 삶의 질을 향상시키고 만성 건강 상태를 관리하는 데 중요한 역할을 한다.

Method: SLMs를 사용하여 제로샷, 퓨샷, 지침 미세 조정 방법으로 건강 예측 작업을 체계적으로 평가하였다.

Result: SLMs는 LLMs에 필적하는 성능을 달성하면서 효율성과 프라이버시에서 상당한 이점을 제공하였다.

Conclusion: SLMs는 현재 형태에서 완벽하지는 않지만, 차세대 프라이버시 보호 헬스케어 모니터링을 위한 유망한 솔루션으로 주목받고 있다.

Abstract: Mobile and wearable healthcare monitoring play a vital role in facilitating
timely interventions, managing chronic health conditions, and ultimately
improving individuals' quality of life. Previous studies on large language
models (LLMs) have highlighted their impressive generalization abilities and
effectiveness in healthcare prediction tasks. However, most LLM-based
healthcare solutions are cloud-based, which raises significant privacy concerns
and results in increased memory usage and latency. To address these challenges,
there is growing interest in compact models, Small Language Models (SLMs),
which are lightweight and designed to run locally and efficiently on mobile and
wearable devices. Nevertheless, how well these models perform in healthcare
prediction remains largely unexplored. We systematically evaluated SLMs on
health prediction tasks using zero-shot, few-shot, and instruction fine-tuning
approaches, and deployed the best performing fine-tuned SLMs on mobile devices
to evaluate their real-world efficiency and predictive performance in practical
healthcare scenarios. Our results show that SLMs can achieve performance
comparable to LLMs while offering substantial gains in efficiency and privacy.
However, challenges remain, particularly in handling class imbalance and
few-shot scenarios. These findings highlight SLMs, though imperfect in their
current form, as a promising solution for next-generation, privacy-preserving
healthcare monitoring.

</details>


### [17] [Autonomous Code Evolution Meets NP-Completeness](https://arxiv.org/abs/2509.07367)
*Cunxi Yu,Rongjian Liang,Chia-Tung Ho,Haoxing Ren*

Main category: cs.AI

TL;DR: SATLUTION은 LLM 기반 코드 진화를 전체 리포지토리 규모로 확장하여 SAT 문제를 해결하는 프레임워크로, 2025년 SAT 대회에서 인간 설계의 우승자를 초월한 성과를 보여준다.


<details>
  <summary>Details</summary>
Motivation: LLM의 코딩 능력을 활용하여 코드를 진화시키고 알고리즘을 개선하려는 필요성에서 출발하였다.

Method: LLM 에이전트가 엄격한 정확성 보장 및 분산 실행 피드백 하에 솔버 리포지토리를 진화시키도록 조정하며, 동시에 자체 진화 정책과 규칙을 자가 진화한다.

Result: SATLUTION은 2024년 SAT 대회 코드베이스 및 벤치마크를 바탕으로 진화한 솔버가 2025년 SAT 대회에서 인간 설계의 우승자를 능가하였고, 2024년 및 2025년 챔피언을 2024년 벤치마크에서 초월하였다.

Conclusion: 이 연구는 LLM 기반의 진화 프레임워크가 코딩 문제 해결에 있어서 인간 전문가를 초월할 수 있음을 보여준다.

Abstract: Large language models (LLMs) have recently shown strong coding abilities,
enabling not only static code generation but also iterative code self-evolving
through agentic frameworks. Recently, AlphaEvolve \cite{novikov2025alphaevolve}
demonstrated that LLM-based coding agents can autonomously improve algorithms
and surpass human experts, with scopes limited to isolated kernels spanning
hundreds of lines of code. Inspired by AlphaEvolve, we present SATLUTION, the
first framework to extend LLM-based code evolution to the full repository
scale, encompassing hundreds of files and tens of thousands of lines of C/C++
code. Targeting Boolean Satisfiability (SAT), the canonical NP-complete problem
and a cornerstone of both theory and applications. SATLUTION orchestrates LLM
agents to directly evolve solver repositories under strict correctness
guarantees and distributed runtime feedback, while simultaneously self-evolving
its own evolution policies and rules. Starting from SAT Competition 2024
codebases and benchmark, SATLUTION evolved solvers that decisively outperformed
the human-designed winners of the SAT Competition 2025, and also surpassed both
2024 and 2025 champions on the 2024 benchmarks.

</details>


### [18] [VISION: Robust and Interpretable Code Vulnerability Detection Leveraging Counterfactual Augmentation](https://arxiv.org/abs/2508.18933)
*David Egea,Barproda Halder,Sanghamitra Dutta*

Main category: cs.AI

TL;DR: 이 논문은 데이터 불균형과 레이블 노이즈 문제를 해결하기 위해 반사실적 훈련 데이터셋을 체계적으로 증강하는 VISION이라는 포괄적인 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 소스 코드의 취약점을 자동으로 탐지하는 것은 디지털 시스템과 서비스에 대한 신뢰를 구축하는 데 중요한 사이버 보안 과제입니다.

Method: 반사실적 샘플 생성, GNN 훈련 및 그래프 기반 해석성을 포함한 VISION 프레임워크를 통해 대응합니다.

Result: VISION은 취약성 탐지의 전반적인 정확도를 51.8%에서 97.8%로 개선하였고, 쌍 대비 정확도를 4.5%에서 95.8%, 최악의 그룹 정확도를 0.7%에서 85.5%로 향상시켰습니다.

Conclusion: VISION은 사용자와의 상호작용 시각화를 통해 투명하고 신뢰할 수 있는 AI 기반 사이버 보안 시스템을 발전시킵니다.

Abstract: Automated detection of vulnerabilities in source code is an essential
cybersecurity challenge, underpinning trust in digital systems and services.
Graph Neural Networks (GNNs) have emerged as a promising approach as they can
learn structural and logical code relationships in a data-driven manner.
However, their performance is severely constrained by training data imbalances
and label noise. GNNs often learn 'spurious' correlations from superficial code
similarities, producing detectors that fail to generalize well to unseen
real-world data. In this work, we propose a unified framework for robust and
interpretable vulnerability detection, called VISION, to mitigate spurious
correlations by systematically augmenting a counterfactual training dataset.
Counterfactuals are samples with minimal semantic modifications but opposite
labels. Our framework includes: (i) generating counterfactuals by prompting a
Large Language Model (LLM); (ii) targeted GNN training on paired code examples
with opposite labels; and (iii) graph-based interpretability to identify the
crucial code statements relevant for vulnerability predictions while ignoring
spurious ones. We find that VISION reduces spurious learning and enables more
robust, generalizable detection, improving overall accuracy (from 51.8% to
97.8%), pairwise contrast accuracy (from 4.5% to 95.8%), and worst-group
accuracy (from 0.7% to 85.5%) on the Common Weakness Enumeration (CWE)-20
vulnerability. We further demonstrate gains using proposed metrics: intra-class
attribution variance, inter-class attribution distance, and node score
dependency. We also release CWE-20-CFA, a benchmark of 27,556 functions (real
and counterfactual) from the high-impact CWE-20 category. Finally, VISION
advances transparent and trustworthy AI-based cybersecurity systems through
interactive visualization for human-in-the-loop analysis.

</details>


### [19] [Getting In Contract with Large Language Models -- An Agency Theory Perspective On Large Language Model Alignment](https://arxiv.org/abs/2509.07642)
*Sascha Kaltenpoth,Oliver Müller*

Main category: cs.AI

TL;DR: 조직 내에서 대규모 언어 모델(LLM)의 채택은 혁신적인 변화를 가져올 수 있지만, 부적절한 내용 생성 문제가 발생할 수 있다. 이 논문에서는 LLM의 채택 과정에서 발생할 수 있는 AI 정렬 문제를 해결하기 위한 개념적 프레임워크인 LLM ATLAS를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 조직에서 LLM을 채택할 때 발생할 수 있는 AI 정렬 문제를 해결하고자 하는 도전 의식이 있다.

Method: 조직의 LLM 채택 단계와 에이전시 이론을 개념으로 활용하여 개념적 문헌 분석을 수행하였다.

Result: AI 정렬 방법에 특화된 확장된 문헌 분석 프로세스와 첫 번째 LLM 정렬 문제 해결 공간을 제공하였다.

Conclusion: LLM ATLAS는 조직의 LLM 채택 과정에서 발생하는 정렬 문제를 완화하는 데 기여할 수 있다.

Abstract: Adopting Large language models (LLMs) in organizations potentially
revolutionizes our lives and work. However, they can generate off-topic,
discriminating, or harmful content. This AI alignment problem often stems from
misspecifications during the LLM adoption, unnoticed by the principal due to
the LLM's black-box nature. While various research disciplines investigated AI
alignment, they neither address the information asymmetries between
organizational adopters and black-box LLM agents nor consider organizational AI
adoption processes. Therefore, we propose LLM ATLAS (LLM Agency Theory-Led
Alignment Strategy) a conceptual framework grounded in agency (contract)
theory, to mitigate alignment problems during organizational LLM adoption. We
conduct a conceptual literature analysis using the organizational LLM adoption
phases and the agency theory as concepts. Our approach results in (1) providing
an extended literature analysis process specific to AI alignment methods during
organizational LLM adoption and (2) providing a first LLM alignment
problem-solution space.

</details>


### [20] [Certainty-Guided Reasoning in Large Language Models: A Dynamic Thinking Budget Approach](https://arxiv.org/abs/2509.07820)
*João Paulo Nogueira,Wentao Sun,Alonso Silva,Laith Zumot*

Main category: cs.AI

TL;DR: 대규모 추론 언어 모델(LRLM)의 발전은 복잡한 작업 해결의 새로운 가능성을 열었습니다. 이 논문에서는 신뢰할 수 있는 결론에 도달했는지 확인하기 위해 자기 추론을 주기적으로 탐색하는 비평가 모델을 포함하는 Certainty-Guided Reasoning(CGR)이라는 새로운 접근 방식을 제안합니다. 실험을 통해 CGR이 정확도를 개선하고 토큰 사용을 줄이는 것을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: LRLM의 발전으로 복잡한 작업을 해결할 수 있는 새로운 가능성이 열렸습니다. 하지만 추론의 효율성과 신뢰성을 어떻게 균형 있게 유지할 수 있는지가 중요합니다.

Method: 새로운 접근 방식은 생성적 적대 신경망의 생성기/비평가 프레임워크에 영감을 받아, 비평가 모델이 자신의 추론을 주기적으로 점검하여 확신할 수 있는 결론에 도달했는지를 평가합니다. 확신이 부족한 경우, 목표 신뢰 임계값에 도달할 때까지 추론을 계속합니다.

Result: CGR은 AIME2024 및 AIME2025 데이터셋에서 실험을 통해 기본 정확도를 개선하면서 토큰 사용을 줄이는 것으로 나타났습니다. 또한, CGR은 신뢰성을 높이고 변동성을 줄이는 안정성을 보여주었습니다.

Conclusion: CGR은 대규모 언어 모델을 보다 적응력 있고 신뢰할 수 있으며 자원 효율적으로 만들어 정확도와 계산 비용이 중요한 도메인에서 실질적인 배치를 위한 길을 닦고 있습니다.

Abstract: The rise of large reasoning language models (LRLMs) has unlocked new
potential for solving complex tasks. These models operate with a thinking
budget, that is, a predefined number of reasoning tokens used to arrive at a
solution. We propose a novel approach, inspired by the generator/discriminator
framework in generative adversarial networks, in which a critic model
periodically probes its own reasoning to assess whether it has reached a
confident conclusion. If not, reasoning continues until a target certainty
threshold is met. This mechanism adaptively balances efficiency and reliability
by allowing early termination when confidence is high, while encouraging
further reasoning when uncertainty persists. Through experiments on the
AIME2024 and AIME2025 datasets, we show that Certainty-Guided Reasoning (CGR)
improves baseline accuracy while reducing token usage. Importantly, extended
multi-seed evaluations over 64 runs demonstrate that CGR is stable, reducing
variance across seeds and improving exam-like performance under penalty-based
grading. Additionally, our token savings analysis shows that CGR can eliminate
millions of tokens in aggregate, with tunable trade-offs between certainty
thresholds and efficiency. Together, these findings highlight certainty as a
powerful signal for reasoning sufficiency. By integrating confidence into the
reasoning process, CGR makes large reasoning language models more adaptive,
trustworthy, and resource efficient, paving the way for practical deployment in
domains where both accuracy and computational cost matter.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [21] [The Signalgate Case is Waiving a Red Flag to All Organizational and Behavioral Cybersecurity Leaders, Practitioners, and Researchers: Are We Receiving the Signal Amidst the Noise?](https://arxiv.org/abs/2509.07053)
*Paul Benjamin Lowry,Gregory D. Moody,Robert Willison,Clay Posey*

Main category: cs.CR

TL;DR: Signalgate 사건은 인적 오류와 기술 남용으로 인한 조직 보안의 취약점을 드러내며, 인적 요소와 거버넌스의 중요성을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 Signalgate 사건을 통해 조직 보안의 주요 취약점을 분석하고, 이를 바탕으로 보안 개선 방안을 제시하는 것을 목표로 합니다.

Method: NIST 사이버 보안 프레임워크를 기반으로 한 사례 연구와 체계적 검토 방식을 사용하여 사건을 분석합니다.

Result: 경영진의 참여, 제로 트러스트 아키텍처의 채택, 명확한 책임 구조 등의 필요성을 강조합니다.

Conclusion: 리더와 정책 입안자는 사이버 보안 전략을 거버넌스, 문화, 행동 위험 문제 해결에 맞춰 재조정해야 함을 강조합니다.

Abstract: The Signalgate incident of March 2025, wherein senior US national security
officials inadvertently disclosed sensitive military operational details via
the encrypted messaging platform Signal, highlights critical vulnerabilities in
organizational security arising from human error, governance gaps, and the
misuse of technology. Although smaller in scale when compared to historical
breaches involving billions of records, Signalgate illustrates critical
systemic issues often overshadowed by a focus on external cyber threats.
Employing a case-study approach and systematic review grounded in the NIST
Cybersecurity Framework, we analyze the incident to identify patterns of
human-centric vulnerabilities and governance challenges common to
organizational security failures. Findings emphasize three critical points. (1)
Organizational security depends heavily on human behavior, with internal actors
often serving as the weakest link despite advanced technical defenses; (2)
Leadership tone strongly influences organizational security culture and
efficacy, and (3) widespread reliance on technical solutions without sufficient
investments in human and organizational factors leads to ineffective practices
and wasted resources. From these observations, we propose actionable
recommendations for enhancing organizational and national security, including
strong leadership engagement, comprehensive adoption of zero-trust
architectures, clearer accountability structures, incentivized security
behaviors, and rigorous oversight. Particularly during periods of
organizational transition, such as mergers or large-scale personnel changes,
additional measures become particularly important. Signalgate underscores the
need for leaders and policymakers to reorient cybersecurity strategies toward
addressing governance, cultural, and behavioral risks.

</details>


### [22] [SoK: Security and Privacy of AI Agents for Blockchain](https://arxiv.org/abs/2509.07131)
*Nicolò Romandini,Carlo Mazzocca,Kai Otsuki,Rebecca Montanari*

Main category: cs.CR

TL;DR: 이 논문은 블록체인과 인공지능(AI) 에이전트의 교차점에 대한 포괄적 설계를 제공하며, AI 기반 시스템의 보안 및 개인 정보 측면에 중점을 두고 있습니다.


<details>
  <summary>Details</summary>
Motivation: 블록체인과 스마트 계약의 복잡성이 비전문 사용자에게 상당한 장벽이 되고 있기 때문에, AI 기반 에이전트를 사용하여 이 격차를 해소할 필요가 있습니다.

Method: AI 기반 시스템에 대한 첫 번째 체계적 지식을 제시하며, 블록체인과 관련된 보안 및 개인 정보 문제에 대해 심층적으로 분석합니다.

Result: AI 기반 블록체인 시스템의 응용, 한계 및 미래 연구 방향을 조명합니다.

Conclusion: 이 연구는 AI와 블록체인을 통합한 새로운 연구 방향을 제시하며, 해당 분야의 연구자들에게 중요한 기초 자료로 작용할 것입니다.

Abstract: Blockchain and smart contracts have garnered significant interest in recent
years as the foundation of a decentralized, trustless digital ecosystem,
thereby eliminating the need for traditional centralized authorities. Despite
their central role in powering Web3, their complexity still presents
significant barriers for non-expert users. To bridge this gap, Artificial
Intelligence (AI)-based agents have emerged as valuable tools for interacting
with blockchain environments, supporting a range of tasks, from analyzing
on-chain data and optimizing transaction strategies to detecting
vulnerabilities within smart contracts. While interest in applying AI to
blockchain is growing, the literature still lacks a comprehensive survey that
focuses specifically on the intersection with AI agents. Most of the related
work only provides general considerations, without focusing on any specific
domain. This paper addresses this gap by presenting the first Systematization
of Knowledge dedicated to AI-driven systems for blockchain, with a special
focus on their security and privacy dimensions, shedding light on their
applications, limitations, and future research directions.

</details>


### [23] [Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm](https://arxiv.org/abs/2509.07287)
*Yan Pang,Wenlong Meng,Xiaojing Liao,Tianhao Wang*

Main category: cs.CR

TL;DR: 이 논문은 대형 언어 모델의 악용 가능성, 특히 피싱 콘텐츠 생성 문제를 다루며, Paladin이라는 새로운 방법을 통해 검출 성능을 향상시키는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 발전으로 피싱 이메일과 같은 악성 콘텐츠 생성이 증가하고 있으며, 이에 대한 검출이 큰 도전 과제가 되고 있습니다.

Method: Paladin을 제안하여 다양한 삽입 전략을 통해 기본 LLM에 트리거-태그 연계를 내장하여 콘텐츠 생성 시 자동으로 탐지 가능한 태그를 포함하도록 합니다.

Result: 개발한 방법이 기존 방법보다 우수한 성능을 보이며, 모든 시나리오에서 90% 이상의 검출 정확도를 달성했습니다.

Conclusion: 이 연구는 LLM 기반 악성 콘텐츠의 탐지 성능 향상을 위한 실질적인 해결책을 제시합니다.

Abstract: With the rapid development of large language models, the potential threat of
their malicious use, particularly in generating phishing content, is becoming
increasingly prevalent. Leveraging the capabilities of LLMs, malicious users
can synthesize phishing emails that are free from spelling mistakes and other
easily detectable features. Furthermore, such models can generate
topic-specific phishing messages, tailoring content to the target domain and
increasing the likelihood of success.
  Detecting such content remains a significant challenge, as LLM-generated
phishing emails often lack clear or distinguishable linguistic features. As a
result, most existing semantic-level detection approaches struggle to identify
them reliably. While certain LLM-based detection methods have shown promise,
they suffer from high computational costs and are constrained by the
performance of the underlying language model, making them impractical for
large-scale deployment.
  In this work, we aim to address this issue. We propose Paladin, which embeds
trigger-tag associations into vanilla LLM using various insertion strategies,
creating them into instrumented LLMs. When an instrumented LLM generates
content related to phishing, it will automatically include detectable tags,
enabling easier identification. Based on the design on implicit and explicit
triggers and tags, we consider four distinct scenarios in our work. We evaluate
our method from three key perspectives: stealthiness, effectiveness, and
robustness, and compare it with existing baseline methods. Experimental results
show that our method outperforms the baselines, achieving over 90% detection
accuracy across all scenarios.

</details>


### [24] [Leveraging Digital Twin-as-a-Service Towards Continuous and Automated Cybersecurity Certification](https://arxiv.org/abs/2509.07649)
*Ioannis Koufos,Abdul Rehman Qureshi,Adrian Asensio,Allen Abishek,Efstathios Zaragkas,Ricard Vilalta,Maria Souvalioti,George Xilouris,Michael-Alexandros Kourtis*

Main category: cs.CR

TL;DR: 전통적인 위험 평가 방식은 수동 감사와 시스템 스캔에 의존하여 운영 중단 및 보안 격차를 초래한다. 이 논문은 자동화되고 비침해적인 보안 준수를 위한 Security Digital Twin-as-a-Service (SDT-aaS)라는 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 위험 평가 방식의 단점을 해결하고 효율적인 보안 준수를 제공하기 위해.

Method: SDT-aaS는 디지털 트윈 기술을 활용하여 실시간 보안 평가를 수행하고, 실제 자산을 미러링하고, 준수 아티팩트를 수집하며, 기계 읽기 가능한 증거를 생성한다.

Result: 중간 규모 인프라 사용 사례에서의 실증적 결과는 SDT-aaS의 실행 가능성과 성능을 보여준다.

Conclusion: SDT-aaS는 최소한의 운영 영향으로 효율적인 온디맨드 사이버 보안 거버넌스를 위한 길을 열어준다.

Abstract: Traditional risk assessments rely on manual audits and system scans, often
causing operational disruptions and leaving security gaps. To address these
challenges, this work presents Security Digital Twin-as-a-Service (SDT-aaS), a
novel approach that leverages Digital Twin (DT) technology for automated,
non-intrusive security compliance. SDT-aaS enables real-time security
assessments by mirroring real-world assets, collecting compliance artifacts,
and creating machine-readable evidence. The proposed work is a scalable and
interoperable solution that supports open standards like CycloneDX and Web of
Things (WoT), facilitating seamless integration and efficient compliance
management. Empirical results from a moderate-scale infrastructure use case
demonstrate its feasibility and performance, paving the way for efficient,
on-demand cybersecurity governance with minimal operational impact.

</details>


### [25] [AgentSentinel: An End-to-End and Real-Time Security Defense Framework for Computer-Use Agents](https://arxiv.org/abs/2509.07764)
*Haitao Hu,Peng Chen,Yanpeng Zhao,Yuqi Chen*

Main category: cs.CR

TL;DR: 대형 언어 모델을 사용하는 컴퓨터 사용 에이전트의 보안 취약점을 완화하기 위해 AgentSentinel이라는 실시간 방어 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 출력은 불안정하고 예측할 수 없어 의도하지 않은 도구 명령이나 잘못된 입력을 초래할 수 있는 위험이 있다.

Method: AgentSentinel은 에이전트 관련 서비스 내에서 모든 민감한 작업을 가로채고 포괄적인 보안 감사가 완료될 때까지 실행을 중단하는 방법을 적용한다.

Result: 평가 결과 AgentSentinel은 79.6%의 평균 방어 성공률을 달성하며, 모든 기준 방어보다 뛰어난 성능을 보인다.

Conclusion: AgentSentinel은 LLM이 유도하는 새로운 보안 문제를 해결하기 위한 효과적인 솔루션으로 평가된다.

Abstract: Large Language Models (LLMs) have been increasingly integrated into
computer-use agents, which can autonomously operate tools on a user's computer
to accomplish complex tasks. However, due to the inherently unstable and
unpredictable nature of LLM outputs, they may issue unintended tool commands or
incorrect inputs, leading to potentially harmful operations. Unlike traditional
security risks stemming from insecure user prompts, tool execution results from
LLM-driven decisions introduce new and unique security challenges. These
vulnerabilities span across all components of a computer-use agent. To mitigate
these risks, we propose AgentSentinel, an end-to-end, real-time defense
framework designed to mitigate potential security threats on a user's computer.
AgentSentinel intercepts all sensitive operations within agent-related services
and halts execution until a comprehensive security audit is completed. Our
security auditing mechanism introduces a novel inspection process that
correlates the current task context with system traces generated during task
execution. To thoroughly evaluate AgentSentinel, we present BadComputerUse, a
benchmark consisting of 60 diverse attack scenarios across six attack
categories. The benchmark demonstrates a 87% average attack success rate on
four state-of-the-art LLMs. Our evaluation shows that AgentSentinel achieves an
average defense success rate of 79.6%, significantly outperforming all baseline
defenses.

</details>


### [26] [Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees](https://arxiv.org/abs/2509.07939)
*Katsuaki Nakano,Reza Feyyazi,Shanchieh Jay Yang,Michael Zuzak*

Main category: cs.CR

TL;DR: 이 연구에서는 사이버 보안 침투 테스트를 위한 LLM(대형 언어 모델) 에이전트의 유도 추론 파이프라인을 제안하여 자동화된 취약성 평가의 효율성과 정확성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안 침투 테스트 워크플로우의 자동화 및 기업 시스템에 대한 더 빠르고 일관된 취약성 평가의 가능성 증대

Method: MITRE ATT&CK 행렬을 기반으로 한 결정론적 작업 트리를 포함한 유도 추론 파이프라인 구축

Result: Llama-3-8B, Gemini-1.5, GPT-4를 이용한 자동화된 침투 테스트 LLM 에이전트가 10개의 HackTheBox 사이버 보안 연습에서 71.8%, 72.8%, 78.6%의 하위 작업을 완료함

Conclusion: 결정론적 작업 트리가 LLM의 추론 파이프라인에 통합되면 자동화된 사이버 보안 평가의 정확성과 효율성을 향상시킬 수 있음

Abstract: Recent advances in Large Language Models (LLMs) have driven interest in
automating cybersecurity penetration testing workflows, offering the promise of
faster and more consistent vulnerability assessment for enterprise systems.
Existing LLM agents for penetration testing primarily rely on self-guided
reasoning, which can produce inaccurate or hallucinated procedural steps. As a
result, the LLM agent may undertake unproductive actions, such as exploiting
unused software libraries or generating cyclical responses that repeat prior
tactics. In this work, we propose a guided reasoning pipeline for penetration
testing LLM agents that incorporates a deterministic task tree built from the
MITRE ATT&CK Matrix, a proven penetration testing kll chain, to constrain the
LLM's reaoning process to explicitly defined tactics, techniques, and
procedures. This anchors reasoning in proven penetration testing methodologies
and filters out ineffective actions by guiding the agent towards more
productive attack procedures. To evaluate our approach, we built an automated
penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and
GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with
103 discrete subtasks representing real-world cyberattack scenarios. Our
proposed reasoning pipeline guided the LLM agent through 71.8\%, 72.8\%, and
78.6\% of subtasks using Llama-3-8B, Gemini-1.5, and GPT-4, respectively.
Comparatively, the state-of-the-art LLM penetration testing tool using
self-guided reasoning completed only 13.5\%, 16.5\%, and 75.7\% of subtasks and
required 86.2\%, 118.7\%, and 205.9\% more model queries. This suggests that
incorporating a deterministic task tree into LLM reasoning pipelines can
enhance the accuracy and efficiency of automated cybersecurity assessments

</details>


### [27] [ImportSnare: Directed "Code Manual" Hijacking in Retrieval-Augmented Code Generation](https://arxiv.org/abs/2509.07941)
*Kai Ye,Liangcai Su,Chenxiong Qian*

Main category: cs.CR

TL;DR: 본 논문은 Retrieval-Augmented Code Generation (RACG)에서의 공격 표면을 탐구하며, 악성 의존성 하이재킹의 위험을 조명합니다. ImportSnare라는 새로운 공격 프레임워크를 도입하여 LLM과 RAG의 신뢰 체인을 악용한 실험 결과를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 코드 생성의 효율성을 높이는 동시에 보안 취약점을 조명하며, LLM이 제공하는 제안에 대한 신뢰의 적절성을 평가하고자 함.

Method: ImportSnare라는 공격 프레임워크를 제안하며, 이는 위치 인식 빔 검색과 다국어 유도 제안을 통해 악성 문서를 생성하고 LLM을 조작하는 방법을 사용함.

Result: ImportSnare는 다양한 프로그래밍 언어에서 50% 이상의 높은 공격 성공률을 달성하며, 낮은 중독 비율에서도 성공할 수 있음을 보여줌.

Conclusion: 이번 연구는 LLM 기반 개발에서의 공급망 보안 위험을 밝히며, 코드 생성 작업에 대한 보안 조정의 필요성을 강조함.

Abstract: Code generation has emerged as a pivotal capability of Large Language
Models(LLMs), revolutionizing development efficiency for programmers of all
skill levels. However, the complexity of data structures and algorithmic logic
often results in functional deficiencies and security vulnerabilities in
generated code, reducing it to a prototype requiring extensive manual
debugging. While Retrieval-Augmented Generation (RAG) can enhance correctness
and security by leveraging external code manuals, it simultaneously introduces
new attack surfaces.
  In this paper, we pioneer the exploration of attack surfaces in
Retrieval-Augmented Code Generation (RACG), focusing on malicious dependency
hijacking. We demonstrate how poisoned documentation containing hidden
malicious dependencies (e.g., matplotlib_safe) can subvert RACG, exploiting
dual trust chains: LLM reliance on RAG and developers' blind trust in LLM
suggestions. To construct poisoned documents, we propose ImportSnare, a novel
attack framework employing two synergistic strategies: 1)Position-aware beam
search optimizes hidden ranking sequences to elevate poisoned documents in
retrieval results, and 2)Multilingual inductive suggestions generate
jailbreaking sequences to manipulate LLMs into recommending malicious
dependencies. Through extensive experiments across Python, Rust, and
JavaScript, ImportSnare achieves significant attack success rates (over 50% for
popular libraries such as matplotlib and seaborn) in general, and is also able
to succeed even when the poisoning ratio is as low as 0.01%, targeting both
custom and real-world malicious packages. Our findings reveal critical supply
chain risks in LLM-powered development, highlighting inadequate security
alignment for code generation tasks. To support future research, we will
release the multilingual benchmark suite and datasets. The project homepage is
https://importsnare.github.io.

</details>
