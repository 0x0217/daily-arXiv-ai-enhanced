<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 4]
- [cs.LG](#cs.LG) [Total: 17]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Security Logs to ATT&CK Insights: Leveraging LLMs for High-Level Threat Understanding and Cognitive Trait Inference](https://arxiv.org/abs/2510.20930)
*Soham Hans,Stacy Marsella,Sophia Hirschmann,Nikolos Gurney*

Main category: cs.CR

TL;DR: 이 논문은 사이버 보안에서 공격자의 행동을 이해하기 위해 대규모 언어 모델을 활용하여 IDS 로그를 분석하고 공격자 행동을 MITRE ATT&CK 기술로 유추하는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안에서 공격자의 행동을 이해하는 것은 전통적으로 고수준의 정보 보고서와 수동 해석에 의존했지만, 실시간 방어는 낮은 수준의 시스템 데이터에서 공격자의 의도와 인지 전략을 추론할 수 있는 능력을 요구합니다.

Method: 우리는 대규모 언어 모델(LLM)을 활용하여 Suricata IDS 로그를 분석하고 MITRE ATT&CK 기술 측면에서 공격자의 행동을 유추하는 전략 기반의 프롬프트 시스템을 개발합니다.

Result: 우리의 방법은 네트워크 사건을 높은 수준의 공격자 전략에 연결하여 행위 신호가 심리적으로 의미 있는 결정 지점과 어떻게 관련되는지를 보여줍니다.

Conclusion: LLM이 패킷 수준의 로그와 전략적 의도 사이의 의미적 간극을 해소할 수 있음을 실증적으로 입증하며, 인지 적응형 사이버 방어를 향한 경로를 제공합니다.

Abstract: Understanding adversarial behavior in cybersecurity has traditionally relied
on high-level intelligence reports and manual interpretation of attack chains.
However, real-time defense requires the ability to infer attacker intent and
cognitive strategy directly from low-level system telemetry such as intrusion
detection system (IDS) logs. In this paper, we propose a novel framework that
leverages large language models (LLMs) to analyze Suricata IDS logs and infer
attacker actions in terms of MITRE ATT&CK techniques. Our approach is grounded
in the hypothesis that attacker behavior reflects underlying cognitive biases
such as loss aversion, risk tolerance, or goal persistence that can be
extracted and modeled through careful observation of log sequences. This lays
the groundwork for future work on behaviorally adaptive cyber defense and
cognitive trait inference. We develop a strategy-driven prompt system to
segment large amounts of network logs data into distinct behavioral phases in a
highly efficient manner, enabling the LLM to associate each phase with likely
techniques and underlying cognitive motives. By mapping network-layer events to
high-level attacker strategies, our method reveals how behavioral signals such
as tool switching, protocol transitions, or pivot patterns correspond to
psychologically meaningful decision points. The results demonstrate that LLMs
can bridge the semantic gap between packet-level logs and strategic intent,
offering a pathway toward cognitive-adaptive cyber defense.
  Keywords: Cognitive Cybersecurity, Large Language Models (LLMs),
Cyberpsychology, Intrusion Detection Systems (IDS), MITRE ATT&CK, Cognitive
Biases

</details>


### [2] [Soft Instruction De-escalation Defense](https://arxiv.org/abs/2510.21057)
*Nils Philipp Walter,Chawin Sitawarin,Jamie Hayes,David Stutz,Ilia Shumailov*

Main category: cs.CR

TL;DR: 대규모 언어 모델이 외부 환경과 상호 작용하는 에이전트 시스템에 점점 더 많이 배치되고 있으며, 이로 인해 신뢰할 수 없는 데이터를 처리할 때 프롬프트 삽입에 취약해짐. 이를 해결하기 위해, Tool-augmented LLM 에이전트를 위해 설계된 반복적인 프롬프트 위생 루프인 SIC(Soft Instruction Control)를 제안함. 이 방법은 들어오는 데이터를 반복적으로 검사하여 에이전트 행동을 손상시킬 수 있는 지침을 찾고, 악성 내용을 재작성, 마스킹 또는 제거한 후 결과를 재평가함. 입력이 깨끗해지거나 최대 반복 한계에 도달할 때까지 이 과정이 계속되며, 여전히 명령형 지침과 유사한 내용이 남아 있는 경우 에이전트가 보안을 보장하기 위해 중지됨. 우리 접근 방식은 여러 번의 패스를 허용하여 단일 재작성 시도가 실패할 수 있음을 인식하고 나중 단계에서 누락된 삽입을 포착하고 수정하도록 시스템을 가능하게 함. 최악의 경우 분석에서는 SIC가 완벽하지 않음을 보여주지만, 강력한 적이 비명령형 워크플로를 삽입하여 여전히 15% ASR을 얻을 수 있음.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)이 에이전트 시스템에 배치되면서 신뢰할 수 없는 데이터를 처리할 때의 취약성을 해결하고자 함.

Method: SIC(Soft Instruction Control)를 사용하여 입력 데이터를 반복적으로 검사하고 악성 내용을 재작성, 마스킹, 제거하는 방식으로 에이전트 행동을 보호함.

Result: SIC는 최대 반복 한계에 도달하기 전까지 입력 데이터를 정화하여 보안을 보장하고, 여러 번의 패스를 통해 누락된 삽입을 수정할 수 있도록 함.

Conclusion: SIC는 즉시 유용하지만, 최악의 경우 분석에서는 강력한 적이 여전히 15% ASR을 얻을 수 있음을 보여 주어 개선의 여지가 있음을 시사함.

Abstract: Large Language Models (LLMs) are increasingly deployed in agentic systems
that interact with an external environment; this makes them susceptible to
prompt injections when dealing with untrusted data. To overcome this
limitation, we propose SIC (Soft Instruction Control)-a simple yet effective
iterative prompt sanitization loop designed for tool-augmented LLM agents. Our
method repeatedly inspects incoming data for instructions that could compromise
agent behavior. If such content is found, the malicious content is rewritten,
masked, or removed, and the result is re-evaluated. The process continues until
the input is clean or a maximum iteration limit is reached; if imperative
instruction-like content remains, the agent halts to ensure security. By
allowing multiple passes, our approach acknowledges that individual rewrites
may fail but enables the system to catch and correct missed injections in later
steps. Although immediately useful, worst-case analysis shows that SIC is not
infallible; strong adversary can still get a 15% ASR by embedding
non-imperative workflows. This nonetheless raises the bar.

</details>


### [3] [Securing AI Agent Execution](https://arxiv.org/abs/2510.21236)
*Christoph Bühler,Matteo Biagiola,Luca Di Grazia,Guido Salvaneschi*

Main category: cs.CR

TL;DR: 이 논문에서는 MCP 서버를 위한 최초의 접근 제어 프레임워크인 AgentBound를 소개한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 외부 도구 및 환경과 상호 작용하지만 MCP 서버의 보안이 부족하여 여러 보안 위협에 노출되어 있다.

Method: AgentBound는 Android 권한 모델에서 영감을 받은 선언적 정책 메커니즘과 MCP 서버 수정을 요구하지 않는 정책 이행 엔진을 결합한다.

Result: 296개의 인기 있는 MCP 서버를 기반으로 한 데이터셋을 구축하고, 소스 코드에서 접근 제어 정책을 80.9%의 정확도로 자동 생성할 수 있음을 보여준다.

Conclusion: AgentBound는 대부분의 보안 위협을 차단하며, 정책 이행 엔진은 최소한의 오버헤드를 유발한다.

Abstract: Large Language Models (LLMs) have evolved into AI agents that interact with
external tools and environments to perform complex tasks. The Model Context
Protocol (MCP) has become the de facto standard for connecting agents with such
resources, but security has lagged behind: thousands of MCP servers execute
with unrestricted access to host systems, creating a broad attack surface. In
this paper, we introduce AgentBound, the first access control framework for MCP
servers. AgentBound combines a declarative policy mechanism, inspired by the
Android permission model, with a policy enforcement engine that contains
malicious behavior without requiring MCP server modifications. We build a
dataset containing the 296 most popular MCP servers, and show that access
control policies can be generated automatically from source code with 80.9%
accuracy. We also show that AgentBound blocks the majority of security threats
in several malicious MCP servers, and that policy enforcement engine introduces
negligible overhead. Our contributions provide developers and project managers
with a practical foundation for securing MCP servers while maintaining
productivity, enabling researchers and tool builders to explore new directions
for declarative access control and MCP security.

</details>


### [4] [SBASH: a Framework for Designing and Evaluating RAG vs. Prompt-Tuned LLM Honeypots](https://arxiv.org/abs/2510.21459)
*Adetayo Adebimpe,Helmut Neukirchen,Thomas Welsh*

Main category: cs.CR

TL;DR: 이 연구는 해킹 공격자와의 상호작용을 극대화하기 위해 시스템 기반의 주의 집중 쉘 허니팟 프레임워크(SBASH)를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 허니팟의 유용성을 극대화하기 위해선 공격자와의 상호작용을 극대화하는 것이 필수적입니다.

Method: SBASH 프레임워크는 경량의 로컬 대형 언어 모델(LLM)을 사용하여 데이터 보호 문제를 관리합니다.

Result: RAG로 지원되는 LLM과 비-RAG LLM을 리눅스 쉘 명령에 적용하고 다양한 메트릭을 통해 평가했습니다.

Conclusion: 조정되지 않은 모델에 대해 RAG가 정확성을 향상시키며, 시스템 프롬프트를 통해 조정된 모델이 RAG없이 유사한 정확성을 달성했습니다.

Abstract: Honeypots are decoy systems used for gathering valuable threat intelligence
or diverting attackers away from production systems. Maximising attacker
engagement is essential to their utility. However research has highlighted that
context-awareness, such as the ability to respond to new attack types, systems
and attacker agents, is necessary to increase engagement. Large Language Models
(LLMs) have been shown as one approach to increase context awareness but suffer
from several challenges including accuracy and timeliness of response time,
high operational costs and data-protection issues due to cloud deployment. We
propose the System-Based Attention Shell Honeypot (SBASH) framework which
manages data-protection issues through the use of lightweight local LLMs. We
investigate the use of Retrieval Augmented Generation (RAG) supported LLMs and
non-RAG LLMs for Linux shell commands and evaluate them using several different
metrics such as response time differences, realism from human testers, and
similarity to a real system calculated with Levenshtein distance, SBert, and
BertScore. We show that RAG improves accuracy for untuned models while models
that have been tuned via a system prompt that tells the LLM to respond like a
Linux system achieve without RAG a similar accuracy as untuned with RAG, while
having a slightly lower latency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Crisis-Resilient Portfolio Management via Graph-based Spatio-Temporal Learning](https://arxiv.org/abs/2510.20868)
*Zan Li,Rui Fan*

Main category: cs.LG

TL;DR: CRISP는 위기 시기에 적응 가능한 자산 배분 예측을 위한 그래프 기반 시공간 학습 프레임워크로, 시장 변화에 따라 자산 간 관계를 학습하여 보다 정확한 예측을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 금융 시계열 예측의 주요 도전 과제는 위기 기간 동안 변화하는 제도 의존적 상관 구조를 이해하여 최적의 자산 배분을 예측하는 것이다.

Method: CRISP는 공간 관계를 Graph Convolutional Networks를 통해 인코딩하고, BiLSTM과 자기 주의를 통해 시간적 동역학을 학습하며, 다중 헤드 그래프 주의 네트워크를 통해 희소 구조를 학습한다.

Result: CRISP는 2005-2021년 데이터를 기반으로 훈련되어, 2022-2024년의 인플레이션 주도 시장에 대한 강력한 일반화를 보여주며, 정확한 제도 적합 상관 구조 예측을 수행한다.

Conclusion: 이러한 접근법은 시장 하락 동안 수익성을 유지하는 적응형 포트폴리오 할당을 가능하게 하며, 학습된 주의 가중치는 해석 가능한 제도 탐지를 제공한다.

Abstract: Financial time series forecasting faces a fundamental challenge: predicting
optimal asset allocations requires understanding regime-dependent correlation
structures that transform during crisis periods. Existing graph-based
spatio-temporal learning approaches rely on predetermined graph
topologies--correlation thresholds, sector classifications--that fail to adapt
when market dynamics shift across different crisis mechanisms: credit
contagion, pandemic shocks, or inflation-driven selloffs.
  We present CRISP (Crisis-Resilient Investment through Spatio-temporal
Patterns), a graph-based spatio-temporal learning framework that encodes
spatial relationships via Graph Convolutional Networks and temporal dynamics
via BiLSTM with self-attention, then learns sparse structures through
multi-head Graph Attention Networks. Unlike fixed-topology methods, CRISP
discovers which asset relationships matter through attention mechanisms,
filtering 92.5% of connections as noise while preserving crisis-relevant
dependencies for accurate regime-specific predictions.
  Trained on 2005--2021 data encompassing credit and pandemic crises, CRISP
demonstrates robust generalization to 2022--2024 inflation-driven markets--a
fundamentally different regime--by accurately forecasting regime-appropriate
correlation structures. This enables adaptive portfolio allocation that
maintains profitability during downturns, achieving Sharpe ratio 3.76: 707%
improvement over equal-weight baselines and 94% improvement over static graph
methods. Learned attention weights provide interpretable regime detection, with
defensive cluster attention strengthening 49% during crises versus 31%
market-wide--emergent behavior from learning to forecast rather than imposing
assumptions.

</details>


### [6] [CC-GRMAS: A Multi-Agent Graph Neural System for Spatiotemporal Landslide Risk Assessment in High Mountain Asia](https://arxiv.org/abs/2510.20875)
*Mihir Panchal,Ying-Jung Chen,Surya Parkash*

Main category: cs.LG

TL;DR: 이 논문은 지진에 대한 예측 정확성을 높이기 위해 위성 관측과 환경 신호를 활용하는 CC-GRMAS라는 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 고산 아시아에서 기후로 인한 재해인 산사태가 증가하고 있으며, 신속한 탐지 및 재난 대응이 미흡하여 심각한 환경적 및 인적 영향이 발생하고 있습니다.

Method: 이 시스템은 예측, 계획, 실행이라는 세 가지 상호 연결된 에이전트를 중심으로 구조화되어 있으며, 이를 통해 실시간 상황 인식, 대응 계획 및 개입을 가능하게 합니다.

Result: 지역 환경 요인을 통합하고 다중 에이전트 협조를 운영화하여, 이 접근 방식은 취약한 산악 지역에서 기후 회복 탄력적인 재난 대비를 위한 확장 가능하고 능동적인 솔루션을 제공합니다.

Conclusion: CC-GRMAS는 산사태 예측의 정확성을 높이고 기후 변화에 강한 재난 대처를 위한 새로운 방법론을 제시합니다.

Abstract: Landslides are a growing climate induced hazard with severe environmental and
human consequences, particularly in high mountain Asia. Despite increasing
access to satellite and temporal datasets, timely detection and disaster
response remain underdeveloped and fragmented. This work introduces CC-GRMAS, a
framework leveraging a series of satellite observations and environmental
signals to enhance the accuracy of landslide forecasting. The system is
structured around three interlinked agents Prediction, Planning, and Execution,
which collaboratively enable real time situational awareness, response
planning, and intervention. By incorporating local environmental factors and
operationalizing multi agent coordination, this approach offers a scalable and
proactive solution for climate resilient disaster preparedness across
vulnerable mountainous terrains.

</details>


### [7] [HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement](https://arxiv.org/abs/2510.20878)
*Danying Ge,Jianhua Gao,Yixue Yang,Weixing Ji*

Main category: cs.LG

TL;DR: 이 논문은 RAG 모델의 성능을 향상시키기 위한 HA-RAG 최적화 시스템을 제안하며, 기억 공간과 추론 지연을 개선하는 방법을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: Large Language Models(LLMs)의 환각 문제와 지식 업데이트 지연 문제를 해결하기 위해 외부 지식베이스를 활용한 RAG의 필요성이 증가하고 있습니다.

Method: KV의 접근 빈도를 기반으로 하여, 혼합 정밀도 압축 및 로딩 방법 및 열기 인식 데이터 배치 전략을 사용하여 성능을 향상시킵니다.

Result: HA-RAG는 TurboRAG에 비해 평균 2.10배, 최대 10.49배의 속도 향상을 보이며, 정확도의 손실은 매우 미미합니다.

Conclusion: 제안된 HA-RAG 최적화 시스템은 RAG 모델의 효율성을 크게 향상시킵니다.

Abstract: Retrieval-Augmented Generation (RAG) improves model output accuracy by
leveraging external knowledge bases, serving as an effective solution to
address hallucination issues and knowledge-update delays in Large Language
Models (LLMs). However, the introduction of external knowledge bases presents
RAG with challenges in long-context processing, significantly increasing memory
consumption and inference latency. Existing research accelerates inference by
precomputing Key and Value (KV) of the knowledge base and loading them
on-demand during inference. Based on the access frequency of different KV
chunks within the external knowledge base, this paper proposes a hotness-aware
RAG (HA-RAG) inference optimization system. First, leveraging the numerical
distribution of KV chunks, we introduce a hotness-aware mixed-precision
compressing and loading method to reduce disk I/O and memory access overhead.
Second, we design a hotness-aware data placement strategy that prioritizes
storing frequently accessed KV chunks in high-speed memory to improve data
access efficiency. Experimental results demonstrate that, compared with
TurboRAG, the proposed HA-RAG achieves an average speedup of 2.10x and maximum
speedup of 10.49x in Time-To-First-Token (TTFT) with negligible accuracy loss.

</details>


### [8] [Towards Scalable Oversight with Collaborative Multi-Agent Debate in Error Detection](https://arxiv.org/abs/2510.20963)
*Yongqiang Chen,Gang Niu,James Cheng,Bo Han,Masashi Sugiyama*

Main category: cs.LG

TL;DR: ColMAD는 다중 에이전트 토론을 비제로섬 게임으로 재구성하여 에러 탐지를 개선하는 새로운 협력적 프로토콜이다.


<details>
  <summary>Details</summary>
Motivation: LLM 응답에서의 오류 정확한 탐지는 효과적인 감독을 제공하기 위해 필수적이다.

Method: ColMAD는 여러 에이전트가 서로를 비판하도록 장려하여 서로의 부족한 점을 보완하게 한다.

Result: ColMAD는 이전 경쟁적 MAD보다 19% 더 우수한 성능을 보여주었고, 단일 에이전트 방법보다 비트리비얼한 개선을 가져왔다.

Conclusion: ColMAD는 오류 탐지에서 더욱 포괄적인 증거에 기반한 더 유용한 결론을 도출할 수 있게 한다.

Abstract: Accurate detection of errors in large language models (LLM) responses is
central to the success of scalable oversight, or providing effective
supervision to superhuman intelligence. Yet, self-diagnosis is often unreliable
on complex tasks unless aided by reliable external feedback. Multi-agent debate
(MAD) seems to be a natural alternative to external feedback: multiple LLMs
provide complementary perspectives and cross-checks for error detection.
However, prior MAD protocols frame debate as a zero-sum game, where the
debaters compete to win the game instead of seeking the truth. Consequently, it
leads to debate hacking: debaters tend to mislead the judge by misinterpreting
the task or presenting overconfident claims, which introduce more mistakes and
underperform single-agent methods. To mitigate the issue, we introduce a new
collaborative MAD protocol, termed ColMAD, that reframes MAD as a non-zero sum
game. Specifically, ColMAD encourages multiple agents to criticize each other
in a supportive way, such that they can complement the missing points of each
other. Therefore, the judge agent can make a more informative conclusion based
on more comprehensive evidence. Empirically, we show that ColMAD significantly
outperforms previous competitive MAD by 19% and brings non-trivial improvements
over single-agent methods in error detection.

</details>


### [9] [Fair Representation Learning with Controllable High Confidence Guarantees via Adversarial Inference](https://arxiv.org/abs/2510.21017)
*Yuhong Luo,Austin Hoag,Xintong Wang,Philip S. Thomas,Przemyslaw A. Grabowicz*

Main category: cs.LG

TL;DR: 이 논문은 여러 다운스트림 작업에 걸쳐 일반화된 표현을 생성하기 위한 표현 학습에 초점을 맞추고 있으며, 특히 특정 인구 집단에 대한 불공정성을 방지하기 위한 높은 신뢰도의 공정성 보장을 달성하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 표현 학습에서 특정 인구 집단에 대한 불공정성을 방지하기 위해 공정성 보장을 보장하는 것이 중요합니다.

Method: 사용자가 정의한 오류 임계값에 따라 인구 집단의 격차가 제한되도록 높은 확률로 보장하는 프레임워크인 FRG(고신뢰성 보장이 있는 공정 표현 학습)를 제안합니다.

Result: FRG는 세 가지 실제 데이터셋에서 실험적으로 평가되었으며, 여섯 가지 최첨단 공정 표현 학습 방법과 성능을 비교하였습니다.

Conclusion: FRG는 다양한 다운스트림 모델 및 작업에서 불공정성을 지속적으로 경계하는 것을 입증하였습니다.

Abstract: Representation learning is increasingly applied to generate representations
that generalize well across multiple downstream tasks. Ensuring fairness
guarantees in representation learning is crucial to prevent unfairness toward
specific demographic groups in downstream tasks. In this work, we formally
introduce the task of learning representations that achieve high-confidence
fairness. We aim to guarantee that demographic disparity in every downstream
prediction remains bounded by a *user-defined* error threshold $\epsilon$, with
*controllable* high probability. To this end, we propose the ***F**air
**R**epresentation learning with high-confidence **G**uarantees (FRG)*
framework, which provides these high-confidence fairness guarantees by
leveraging an optimized adversarial model. We empirically evaluate FRG on three
real-world datasets, comparing its performance to six state-of-the-art fair
representation learning methods. Our results demonstrate that FRG consistently
bounds unfairness across a range of downstream models and tasks.

</details>


### [10] [Online Multi-Class Selection with Group Fairness Guarantee](https://arxiv.org/abs/2510.21055)
*Faraz Zargari,Hossein Nekouyan,Lyndon Hallett,Bo Sun,Xiaoqi Tan*

Main category: cs.LG

TL;DR: 본 연구는 그룹 공정성을 보장하는 온라인 다중 클래스 선택 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 기존 문헌에서 나타나는 두 가지 주요 한계를 해결하기 위함이다.

Method: 리락스 앤 라운드 프레임워크에 기반한 무작위 알고리즘을 개발했다.

Result: 알고리즘은 자원 예약 방법을 사용하여 공정성을 유지하며, 메커니즘은 성능을 저하시키지 않고 공정성을 보장한다.

Conclusion: 신뢰할 수 없는 기계 학습 예측을 통합하여 공정성과 효율성을 더 잘 균형 잡는 학습 증강 변형을 제안한다.

Abstract: We study the online multi-class selection problem with group fairness
guarantees, where limited resources must be allocated to sequentially arriving
agents. Our work addresses two key limitations in the existing literature.
First, we introduce a novel lossless rounding scheme that ensures the integral
algorithm achieves the same expected performance as any fractional solution.
Second, we explicitly address the challenges introduced by agents who belong to
multiple classes. To this end, we develop a randomized algorithm based on a
relax-and-round framework. The algorithm first computes a fractional solution
using a resource reservation approach -- referred to as the set-aside mechanism
-- to enforce fairness across classes. The subsequent rounding step preserves
these fairness guarantees without degrading performance. Additionally, we
propose a learning-augmented variant that incorporates untrusted
machine-learned predictions to better balance fairness and efficiency in
practical settings.

</details>


### [11] [ESCORT: Efficient Stein-variational and Sliced Consistency-Optimized Temporal Belief Representation for POMDPs](https://arxiv.org/abs/2510.21107)
*Yunuo Zhang,Baiting Luo,Ayan Mukhopadhyay,Gabor Karsai,Abhishek Dubey*

Main category: cs.LG

TL;DR: ESCORT라는 새로운 파티클 기반 프레임워크가 고차원 신념 공간에서 복잡한 다중 모드 분포를 캡처하는 방법을 제시하며, 기존 POMDP 신념 근사 방법의 한계를 극복한다.


<details>
  <summary>Details</summary>
Motivation: 더욱 현실적인 환경에서 정확한 의사결정을 위해 복잡한 신념 분포를 정확하게 유지하고 업데이트하는 것이 중요함.

Method: ESCORT는 복잡한 다중 모드 분포를 캡처하기 위한 파티클 기반 프레임워크이며, 두 가지 주요 혁신인 상관 인식을 통한 프로젝션과 시간 일관성 제약을 도입한다.

Result: ESCORT는 POMDP 도메인과 다양한 차원에서의 합성 다중 모드 분포에 대해 훨씬 더 나은 신념 근사 정확도와 의사결정 품질을 보여준다.

Conclusion: ESCORT는 고차원 신념 공간에서의 복잡한 불확실성 구조를 효과적으로 모델링하며, 기존 방법들보다 월등한 성능을 볼 수 있었다.

Abstract: In Partially Observable Markov Decision Processes (POMDPs), maintaining and
updating belief distributions over possible underlying states provides a
principled way to summarize action-observation history for effective
decision-making under uncertainty. As environments grow more realistic, belief
distributions develop complexity that standard mathematical models cannot
accurately capture, creating a fundamental challenge in maintaining
representational accuracy. Despite advances in deep learning and probabilistic
modeling, existing POMDP belief approximation methods fail to accurately
represent complex uncertainty structures such as high-dimensional, multi-modal
belief distributions, resulting in estimation errors that lead to suboptimal
agent behaviors. To address this challenge, we present ESCORT (Efficient
Stein-variational and sliced Consistency-Optimized Representation for Temporal
beliefs), a particle-based framework for capturing complex, multi-modal
distributions in high-dimensional belief spaces. ESCORT extends SVGD with two
key innovations: correlation-aware projections that model dependencies between
state dimensions, and temporal consistency constraints that stabilize updates
while preserving correlation structures. This approach retains SVGD's
attractive-repulsive particle dynamics while enabling accurate modeling of
intricate correlation patterns. Unlike particle filters prone to degeneracy or
parametric methods with fixed representational capacity, ESCORT dynamically
adapts to belief landscape complexity without resampling or restrictive
distributional assumptions. We demonstrate ESCORT's effectiveness through
extensive evaluations on both POMDP domains and synthetic multi-modal
distributions of varying dimensionality, where it consistently outperforms
state-of-the-art methods in terms of belief approximation accuracy and
downstream decision quality.

</details>


### [12] [Scalable Principal-Agent Contract Design via Gradient-Based Optimization](https://arxiv.org/abs/2510.21177)
*Tomer Galanti,Aarya Bookseller,Korok Ray*

Main category: cs.LG

TL;DR: 이 논문은 주체와 대리인 간의 계약 설계를 위한 이층 최대 최적화 프레임워크를 연구합니다.


<details>
  <summary>Details</summary>
Motivation: 계약 이론과 도덕적 해이 문제에 중앙에 위치한 이 문제는 시장 설계, 대리 포트폴리오 관리, 헤지펀드 수수료 구조 및 경영진 보상 등 다양한 응용 분야에 적용됩니다.

Method: 우리는 폐쇄형 해법에 대한 의존을 제거하는 일반적인 알고리즘적 프레임워크를 도입하며, 현대 기계 학습 기법을 이층 최적화에 적용합니다.

Result: CARA-Normal 환경에서 이 접근법은 알려진 분석적 최적값을 회복하며 무작위 초기화에서 신뢰성 있게 수렴합니다.

Conclusion: 이 프레임워크는 복잡한 비선형 계약에 자연스럽게 확장되며, 새로운 계산 도구를 제공하여 분석적으로 다루기 어려운 모델의 체계적인 연구를 가능하게 합니다.

Abstract: We study a bilevel \emph{max-max} optimization framework for principal-agent
contract design, in which a principal chooses incentives to maximize utility
while anticipating the agent's best response. This problem, central to moral
hazard and contract theory, underlies applications ranging from market design
to delegated portfolio management, hedge fund fee structures, and executive
compensation. While linear-quadratic models such as Holmstr"om-Milgrom admit
closed-form solutions, realistic environments with nonlinear utilities,
stochastic dynamics, or high-dimensional actions generally do not.
  We introduce a generic algorithmic framework that removes this reliance on
closed forms. Our method adapts modern machine learning techniques for bilevel
optimization -- using implicit differentiation with conjugate gradients (CG) --
to compute hypergradients efficiently through Hessian-vector products, without
ever forming or inverting Hessians. In benchmark CARA-Normal (Constant Absolute
Risk Aversion with Gaussian distribution of uncertainty) environments, the
approach recovers known analytical optima and converges reliably from random
initialization. More broadly, because it is matrix-free, variance-reduced, and
problem-agnostic, the framework extends naturally to complex nonlinear
contracts where closed-form solutions are unavailable, such as sigmoidal wage
schedules (logistic pay), relative-performance/tournament compensation with
common shocks, multi-task contracts with vector actions and heterogeneous
noise, and CARA-Poisson count models with $\mathbb{E}[X\mid a]=e^{a}$. This
provides a new computational tool for contract design, enabling systematic
study of models that have remained analytically intractable.

</details>


### [13] [Revisiting Social Welfare in Bandits: UCB is (Nearly) All You Need](https://arxiv.org/abs/2510.21312)
*Dhruv Sarkar,Nishant Pandey,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 이 논문은 나쉬 사회 복지 함수에 기반하여 나쉬 후회를 최소화하는 새로운 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 후회 측정 지표는 보상 수령자 간 공정성을 고려하지 않는 문제를 해결하기 위해 나쉬 후회라는 개념을 도입했습니다.

Method: 균일한 탐색 단계 후에 일반적인 상한 신뢰 구간(UCB) 알고리즘을 사용하여 나쉬 후회를 최소화합니다.

Result: 제안된 방법은 추가적인 Hoeffding 경계를 바탕으로 최적에 가까운 나쉬 후회를 달성합니다.

Conclusion: 제안된 알고리즘은 넓은 범위의 공정성 지표에 일반화되어, 모든 p 값에 대해 (거의) 최적의 후회 한계를 입증합니다.

Abstract: Regret in stochastic multi-armed bandits traditionally measures the
difference between the highest reward and either the arithmetic mean of
accumulated rewards or the final reward. These conventional metrics often fail
to address fairness among agents receiving rewards, particularly in settings
where rewards are distributed across a population, such as patients in clinical
trials. To address this, a recent body of work has introduced Nash regret,
which evaluates performance via the geometric mean of accumulated rewards,
aligning with the Nash social welfare function known for satisfying fairness
axioms.
  To minimize Nash regret, existing approaches require specialized algorithm
designs and strong assumptions, such as multiplicative concentration
inequalities and bounded, non-negative rewards, making them unsuitable for even
Gaussian reward distributions. We demonstrate that an initial uniform
exploration phase followed by a standard Upper Confidence Bound (UCB) algorithm
achieves near-optimal Nash regret, while relying only on additive Hoeffding
bounds, and naturally extending to sub-Gaussian rewards. Furthermore, we
generalize the algorithm to a broad class of fairness metrics called the
$p$-mean regret, proving (nearly) optimal regret bounds uniformly across all
$p$ values. This is in contrast to prior work, which made extremely restrictive
assumptions on the bandit instances and even then achieved suboptimal regret
bounds.

</details>


### [14] [Compositional Monte Carlo Tree Diffusion for Extendable Planning](https://arxiv.org/abs/2510.21361)
*Jaesik Yoon,Hyeonseo Cho,Sungjin Ahn*

Main category: cs.LG

TL;DR: C-MCTD는 개별 경로 최적화에서 전체 계획 조합으로 사고를 확장하는 프레임워크로, 온라인 작곡자, 분산 작곡자 및 사전 계획 작곡자를 도입하여 계획 과정을 개선한다.


<details>
  <summary>Details</summary>
Motivation: MCTD는 훈련 경로 길이에 의해 제한되고, 전역적 맥락에 접근하지 않기 때문에 계획 과정이 지역적으로 제약됩니다.

Method: C-MCTD는 전체 계획 조합을 탐색하여 글로벌 중심의 계획을 수행하는 온라인 작곡자, 여러 출발 지점에서 병렬 탐색을 통하여 탐색 복잡성을 줄이는 분산 작곡자, 그리고 캐시된 계획 그래프를 활용하여 추론 속도를 향상시키는 사전 계획 작곡자로 구성됩니다.

Result: C-MCTD는 계획 생성을 위한 새로운 방식으로 장기적인 계획 가능성을 증가시킵니다.

Conclusion: 이 프레임워크는 개별 경로 최적화의 한계를 극복하고, 전체 계획 조합에 대한 사고를 가능하게 하여 계획 효율성을 향상시킵니다.

Abstract: Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured
tree search to enable effective trajectory exploration through stepwise
reasoning. However, MCTD remains fundamentally limited by training trajectory
lengths. While periodic replanning allows plan concatenation for longer plan
generation, the planning process remains locally confined, as MCTD searches
within individual trajectories without access to global context. We propose
Compositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates
planning from individual trajectory optimization to reasoning over complete
plan compositions. C-MCTD introduces three complementary components: (1) Online
Composer, which performs globally-aware planning by searching across entire
plan compositions; (2) Distributed Composer, which reduces search complexity
through parallel exploration from multiple starting points; and (3) Preplan
Composer, which accelerates inference by leveraging cached plan graphs.

</details>


### [15] [Randomized Neural Network with Adaptive Forward Regularization for Online Task-free Class Incremental Learning](https://arxiv.org/abs/2510.21367)
*Junda Wang,Minghui Hu,Ning Li,Abdulaziz Al-Ali,Ponnuthurai Nagaratnam Suganthan*

Main category: cs.LG

TL;DR: 이 연구는 온라인 태스크 프리 클래스 점진 학습(OTCIL) 상황에서 지식을 유지하며 잊어버리지 않는 방식으로 효율적인 의사 결정을 지원하기 위해 랜덤화된 신경망을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 클래스 점진 학습(CIL)의 실용적 응용을 방해하는 두 가지 문제를 해결하기 위해.

Method: 랜덤화된 신경망(Randomized NN)과 단계적 정규화(-F)를 사용하여 학습 성능을 향상시키고 잊어버림을 방지하는 알고리즘을 제안합니다.

Result: 제안된 edRVFL-kF 알고리즘은 효과적으로 과거 재생과 파국적 잊어버림을 피하면서 우수한 성능을 달성합니다.

Conclusion: 우리의 OTCIL 프레임워크가 -kF-Bayes 및 -kF 스타일과 함께 효능을 확실히 검증했습니다.

Abstract: Class incremental learning (CIL) requires an agent to learn distinct tasks
consecutively with knowledge retention against forgetting. Problems impeding
the practical applications of CIL methods are twofold: (1) non-i.i.d batch
streams and no boundary prompts to update, known as the harsher online
task-free CIL (OTCIL) scenario; (2) CIL methods suffer from memory loss in
learning long task streams, as shown in Fig. 1 (a). To achieve efficient
decision-making and decrease cumulative regrets during the OTCIL process, a
randomized neural network (Randomized NN) with forward regularization (-F) is
proposed to resist forgetting and enhance learning performance. This general
framework integrates unsupervised knowledge into recursive convex optimization,
has no learning dissipation, and can outperform the canonical ridge style (-R)
in OTCIL. Based on this framework, we derive the algorithm of the ensemble deep
random vector functional link network (edRVFL) with adjustable forward
regularization (-kF), where k mediates the intensity of the intervention.
edRVFL-kF generates one-pass closed-form incremental updates and variable
learning rates, effectively avoiding past replay and catastrophic forgetting
while achieving superior performance. Moreover, to curb unstable penalties
caused by non-i.i.d and mitigate intractable tuning of -kF in OTCIL, we improve
it to the plug-and-play edRVFL-kF-Bayes, enabling all hard ks in multiple
sub-learners to be self-adaptively determined based on Bayesian learning.
Experiments were conducted on 2 image datasets including 6 metrics, dynamic
performance, ablation tests, and compatibility, which distinctly validates the
efficacy of our OTCIL frameworks with -kF-Bayes and -kF styles.

</details>


### [16] [Large Language Models as Model Organisms for Human Associative Learning](https://arxiv.org/abs/2510.21408)
*Camila Kolling,Vy Ai Vo,Mariya Toneva*

Main category: cs.LG

TL;DR: 본 연구는 대형 언어 모델(LLM)을 활용하여 연상 학습에서의 표현 변화 과정을 조사한다.


<details>
  <summary>Details</summary>
Motivation: 생물학적 시스템에서 표현 변화가 발생하는 방식에 대한 가설을 테스트하기 위해 LLM의 사용.

Method: LLM의 컨텍스트 내 학습을 기반으로 한 인지 신경 과학 연상 학습 패러다임을 적응.

Result: 비모노토닉 패턴을 발견하였고, 학습 후 유사 항목 간의 차별화가 이루어짐을 확인하였다.

Conclusion: LLM은 인간과 유사한 학습 시스템에서의 표현 역학을 연구하고 새로운 가설을 생성하기 위한 강력하고 일반적인 계산 모델로 자리매김한다.

Abstract: Associative learning--forming links between co-occurring items--is
fundamental to human cognition, reshaping internal representations in complex
ways. Testing hypotheses on how representational changes occur in biological
systems is challenging, but large language models (LLMs) offer a scalable
alternative. Building on LLMs' in-context learning, we adapt a cognitive
neuroscience associative learning paradigm and investigate how representations
evolve across six models. Our initial findings reveal a non-monotonic pattern
consistent with the Non-Monotonic Plasticity Hypothesis, with moderately
similar items differentiating after learning. Leveraging the controllability of
LLMs, we further show that this differentiation is modulated by the overlap of
associated items with the broader vocabulary--a factor we term vocabulary
interference, capturing how new associations compete with prior knowledge. We
find that higher vocabulary interference amplifies differentiation, suggesting
that representational change is influenced by both item similarity and global
competition. Our findings position LLMs not only as powerful tools for studying
representational dynamics in human-like learning systems, but also as
accessible and general computational models for generating new hypotheses about
the principles underlying memory reorganization in the brain.

</details>


### [17] [Causality Meets Locality: Provably Generalizable and Scalable Policy Learning for Networked Systems](https://arxiv.org/abs/2510.21427)
*Hao Liang,Shuqing Shi,Yudi Zhang,Biwei Huang,Yali Du*

Main category: cs.LG

TL;DR: GSAC(일반화 가능하고 확장 가능한 액터-비평가) 프레임워크는 대규모 네트워크 시스템에서 강화 학습 에이전트의 도전에 대응하기 위해 인과 관계 표현 학습과 메타 액터-비평가 학습을 결합합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 교통, 전력 및 무선 그리드와 같은 네트워크 시스템은 강화 학습 에이전트에게 규모와 환경 변화라는 도전을 제공합니다.

Method: GSAC 프레임워크는 각 에이전트가 최소한의 이웃 변수들을 식별하여 희소한 지역 인과 마스크를 학습한 후, 이들을 =kappa=홉 이웃에 대해 슬라이스하는 가치 함수의 오류를 보장하는 약  compact representations(ACRs)을 생성하여 효율적인 학습을 가능하게 합니다.

Result: 메타 액터-비평가는 여러 출처 도메인에서 공유 정책을 훈련하고 compact domain factors에 조건을 부여하여 적응된 정책을 배포할 수 있게 합니다. GSAC는 빠르게 적응하며 기존의 학습 방법과 큰 차이를 보입니다.

Conclusion: GSAC는 인과 회복, 액터-비평가 수렴 및 적응 격차에 대한 유한 표본 보장을 확립하고 기존의 학습 방법보다 신속하게 적응하며 훨씬 더 우수한 성능을 보여줍니다.

Abstract: Large-scale networked systems, such as traffic, power, and wireless grids,
challenge reinforcement-learning agents with both scale and environment shifts.
To address these challenges, we propose GSAC (Generalizable and Scalable
Actor-Critic), a framework that couples causal representation learning with
meta actor-critic learning to achieve both scalability and domain
generalization. Each agent first learns a sparse local causal mask that
provably identifies the minimal neighborhood variables influencing its
dynamics, yielding exponentially tight approximately compact representations
(ACRs) of state and domain factors. These ACRs bound the error of truncating
value functions to $\kappa$-hop neighborhoods, enabling efficient learning on
graphs. A meta actor-critic then trains a shared policy across multiple source
domains while conditioning on the compact domain factors; at test time, a few
trajectories suffice to estimate the new domain factor and deploy the adapted
policy. We establish finite-sample guarantees on causal recovery, actor-critic
convergence, and adaptation gap, and show that GSAC adapts rapidly and
significantly outperforms learning-from-scratch and conventional adaptation
baselines.

</details>


### [18] [Cost Minimization for Space-Air-Ground Integrated Multi-Access Edge Computing Systems](https://arxiv.org/abs/2510.21541)
*Weihong Qin,Aimin Wang,Geng Sun,Zemin Sun,Jiacheng Wang,Dusit Niyato,Dong In Kim,Zhu Han*

Main category: cs.LG

TL;DR: 이 논문은 공간-공중-지상 통합 다중 접근 엣지 컴퓨팅(SAGIN-MEC)의 계층 구조와, 사용자 장치의 비용을 최소화하기 위한 최적화 문제와 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 신속하게 발전하는 저고도 경제( LAE)에서 유연하고 넓은 지역의 컴퓨팅 서비스를 제공하기 위한 SAGIN-MEC의 잠재력을 완전히 실현하기 위한 여러 도전 과제가 존재한다.

Method: 계층적 SAGIN-MEC 아키텍처를 제시하고, 사용자 장치 비용 최소화 최적화 문제(UCMOP)를 공식화한 후, MADDPG-COCG 알고리즘을 제안하여 이를 해결한다.

Result: 제안된 MADDPG-COCG 알고리즘은 사용자 장치 비용, 작업 완료 지연 및 사용자 장치 에너지 소비 측면에서 중앙 집중적인 성능을 크게 향상시킴을 보여준다.

Conclusion: MADDPG-COCG 알고리즘은 수렴 안정성과 확장성이 우수하다.

Abstract: Space-air-ground integrated multi-access edge computing (SAGIN-MEC) provides
a promising solution for the rapidly developing low-altitude economy (LAE) to
deliver flexible and wide-area computing services. However, fully realizing the
potential of SAGIN-MEC in the LAE presents significant challenges, including
coordinating decisions across heterogeneous nodes with different roles,
modeling complex factors such as mobility and network variability, and handling
real-time decision-making under partially observable environment with hybrid
variables. To address these challenges, we first present a hierarchical
SAGIN-MEC architecture that enables the coordination between user devices
(UDs), uncrewed aerial vehicles (UAVs), and satellites. Then, we formulate a UD
cost minimization optimization problem (UCMOP) to minimize the UD cost by
jointly optimizing the task offloading ratio, UAV trajectory planning,
computing resource allocation, and UD association. We show that the UCMOP is an
NP-hard problem. To overcome this challenge, we propose a multi-agent deep
deterministic policy gradient (MADDPG)-convex optimization and coalitional game
(MADDPG-COCG) algorithm. Specifically, we employ the MADDPG algorithm to
optimize the continuous temporal decisions for heterogeneous nodes in the
partially observable SAGIN-MEC system. Moreover, we propose a convex
optimization and coalitional game (COCG) method to enhance the conventional
MADDPG by deterministically handling the hybrid and varying-dimensional
decisions. Simulation results demonstrate that the proposed MADDPG-COCG
algorithm significantly enhances the user-centric performances in terms of the
aggregated UD cost, task completion delay, and UD energy consumption, with a
slight increase in UAV energy consumption, compared to the benchmark
algorithms. Moreover, the MADDPG-COCG algorithm shows superior convergence
stability and scalability.

</details>


### [19] [Leveraging Classical Algorithms for Graph Neural Networks](https://arxiv.org/abs/2510.21574)
*Jason Wu,Petar Veličković*

Main category: cs.LG

TL;DR: GNN을 고전 알고리즘으로 사전 훈련시키면 분자 특성 예측 성능이 향상된다.


<details>
  <summary>Details</summary>
Motivation: 고전 알고리즘과 GNN의 장점을 결합하여 분자 특성 예측에서 성능을 향상시키고자 한다.

Method: CLRS 알고리즘 추론 벤치마크에서 24개의 고전 알고리즘으로 GNN을 사전 훈련 시킨 후, 두 번째 GNN의 선택된 레이어를 초기화하고 고정하여 분자 예측을 수행한다.

Result: 무작위 초기화된 기준 모델에 비해, 사전 훈련된 모델은 일관된 승리 또는 동점을 달성하며, Segments Intersect 알고리즘 사전 훈련으로 ogbg-molhiv에서 6%의 절대 이득을, Dijkstra 사전 훈련으로 ogbg-molclintox에서 3%의 이득을 얻었다.

Conclusion: 고전 알고리즘의 선험적 편향을 GNN에 임베딩함으로써 복잡한 실제 그래프 데이터에서 성능을 향상시킬 수 있다.

Abstract: Neural networks excel at processing unstructured data but often fail to
generalise out-of-distribution, whereas classical algorithms guarantee
correctness but lack flexibility. We explore whether pretraining Graph Neural
Networks (GNNs) on classical algorithms can improve their performance on
molecular property prediction tasks from the Open Graph Benchmark: ogbg-molhiv
(HIV inhibition) and ogbg-molclintox (clinical toxicity). GNNs trained on 24
classical algorithms from the CLRS Algorithmic Reasoning Benchmark are used to
initialise and freeze selected layers of a second GNN for molecular prediction.
Compared to a randomly initialised baseline, the pretrained models achieve
consistent wins or ties, with the Segments Intersect algorithm pretraining
yielding a 6% absolute gain on ogbg-molhiv and Dijkstra pretraining achieving a
3% gain on ogbg-molclintox. These results demonstrate embedding classical
algorithmic priors into GNNs provides useful inductive biases, boosting
performance on complex, real-world graph data.

</details>


### [20] [REVE: A Foundation Model for EEG -- Adapting to Any Setup with Large-Scale Pretraining on 25,000 Subjects](https://arxiv.org/abs/2510.21585)
*Yassine El Ouahidi,Jonathan Lys,Philipp Thölke,Nicolas Farrugia,Bastien Pasdeloup,Vincent Gripon,Karim Jerbi,Giulia Lioi*

Main category: cs.LG

TL;DR: REVE라는 새로운 EEG 모델은 다양한 EEG 신호를 일반화하도록 설계되어 있으며, 60,000시간의 EEG 데이터로 사전 훈련되어 여러 EEG 작업에서 최첨단 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: EEG에 대한 기초 모델의 채택이 데이터의 이질성으로 인해 지연되고 있다.

Method: REVE는 다양한 EEG 신호를 처리할 수 있는 새로운 4D 위치 인코딩 방식으로 설계되었으며, 60,000시간 이상의 EEG 데이터로 사전 훈련되었다.

Result: REVE는 10개의 하위 EEG 작업에서 최첨단 결과를 달성하였다.

Conclusion: REVE는 일반화 성능이 뛰어나고, EEG 연구의 표준화를 지원하기 위해 코드, 사전 훈련 가중치 및 튜토리얼을 공개한다.

Abstract: Foundation models have transformed AI by reducing reliance on task-specific
data through large-scale pretraining. While successful in language and vision,
their adoption in EEG has lagged due to the heterogeneity of public datasets,
which are collected under varying protocols, devices, and electrode
configurations. Existing EEG foundation models struggle to generalize across
these variations, often restricting pretraining to a single setup, resulting in
suboptimal performance, in particular under linear probing. We present REVE
(Representation for EEG with Versatile Embeddings), a pretrained model
explicitly designed to generalize across diverse EEG signals. REVE introduces a
novel 4D positional encoding scheme that enables it to process signals of
arbitrary length and electrode arrangement. Using a masked autoencoding
objective, we pretrain REVE on over 60,000 hours of EEG data from 92 datasets
spanning 25,000 subjects, representing the largest EEG pretraining effort to
date. REVE achieves state-of-the-art results on 10 downstream EEG tasks,
including motor imagery classification, seizure detection, sleep staging,
cognitive load estimation, and emotion recognition. With little to no
fine-tuning, it demonstrates strong generalization, and nuanced spatio-temporal
modeling. We release code, pretrained weights, and tutorials to support
standardized EEG research and accelerate progress in clinical neuroscience.

</details>


### [21] [SHAP Meets Tensor Networks: Provably Tractable Explanations with Parallelism](https://arxiv.org/abs/2510.21599)
*Reda Marzouk,Shahaf Bassan,Guy Katz*

Main category: cs.LG

TL;DR: SHAP 설명을 더 복잡한 모델에 적용하기 위해, 텐서 네트워크(TN)에 대한 정확한 SHAP 설명을 계산할 수 있는 일반적인 프레임워크를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 신경망과 같은 더 표현력이 뛰어난 블랙박스 모델을 위한 SHAP 설명의 계산이 NP 어려움에 빠지기 때문에, 본 연구에서는 텐서 네트워크에 대한 SHAP 설명 계산 문제를 분석한다.

Method: 임의의 구조를 가진 일반 TN에 대한 정확한 SHAP 설명을 계산하기 위한 일반적인 프레임워크를 소개하고, 텐서 기차(TT) 구조로 제한될 때 poly-logarithmic 시간에 대한 SHAP 계산 방법을 제시한다.

Result: 텐서 기차의 표현력 덕분에, 이 복잡성 결과는 결정 트리, 트리 앙상블, 선형 모델 및 선형 RNN과 같은 다른 인기 있는 ML 모델로 일반화될 수 있다.

Conclusion: 너비가 고정된 네트워크의 경우 SHAP 계산이 효율적으로 수행될 수 있지만, 깊이는 매우 깊어도 계산적으로 어려움을 겪는다는 사실을 강조한다.

Abstract: Although Shapley additive explanations (SHAP) can be computed in polynomial
time for simple models like decision trees, they unfortunately become NP-hard
to compute for more expressive black-box models like neural networks - where
generating explanations is often most critical. In this work, we analyze the
problem of computing SHAP explanations for *Tensor Networks (TNs)*, a broader
and more expressive class of models than those for which current exact SHAP
algorithms are known to hold, and which is widely used for neural network
abstraction and compression. First, we introduce a general framework for
computing provably exact SHAP explanations for general TNs with arbitrary
structures. Interestingly, we show that, when TNs are restricted to a *Tensor
Train (TT)* structure, SHAP computation can be performed in *poly-logarithmic*
time using *parallel* computation. Thanks to the expressiveness power of TTs,
this complexity result can be generalized to many other popular ML models such
as decision trees, tree ensembles, linear models, and linear RNNs, therefore
tightening previously reported complexity results for these families of models.
Finally, by leveraging reductions of binarized neural networks to Tensor
Network representations, we demonstrate that SHAP computation can become
*efficiently tractable* when the network's *width* is fixed, while it remains
computationally hard even with constant *depth*. This highlights an important
insight: for this class of models, width - rather than depth - emerges as the
primary computational bottleneck in SHAP computation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [22] [Sketch2BIM: A Multi-Agent Human-AI Collaborative Pipeline to Convert Hand-Drawn Floor Plans to 3D BIM](https://arxiv.org/abs/2510.20838)
*Abir Khan Ratul,Sanjay Acharjee,Somin Park,Md Nazmus Sakib*

Main category: cs.AI

TL;DR: 이 연구는 손으로 그린 평면도를 일관된 3D BIM 모델로 변환하는 사람-상황 결합 파이프라인을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 사람-상황 결합 파이프라인을 통해 비전문가도 손 그림으로 3D BIM 모델을 손쉽게 생성할 수 있도록 하려는 동기.

Method: 다중 모달 대형 언어 모델(MLLM)을 활용한 다중 에이전트 프레임워크를 통해, 감지 추출, 인간 피드백, 스키마 검증 및 자동 BIM 스크립팅을 포함하는 워크플로우를 개발했습니다.

Result: 10개의 다양한 평면도 실험에서 초기 통과 시 개구부(문, 창문)가 높은 신뢰도로 포착되었고, 벽 감지 정확도는 약 83%에서 시작하여 피드백 반복 후 거의 완벽한 정렬을 달성했습니다.

Conclusion: MLLM 기반의 다중 에이전트 추론이 전문가와 비전문가 모두가 손 그림만 이용해 BIM 생성에 접근할 수 있도록 할 수 있음을 보여줍니다.

Abstract: This study introduces a human-in-the-loop pipeline that converts unscaled,
hand-drawn floor plan sketches into semantically consistent 3D BIM models. The
workflow leverages multimodal large language models (MLLMs) within a
multi-agent framework, combining perceptual extraction, human feedback, schema
validation, and automated BIM scripting. Initially, sketches are iteratively
refined into a structured JSON layout of walls, doors, and windows. Later,
these layouts are transformed into executable scripts that generate 3D BIM
models. Experiments on ten diverse floor plans demonstrate strong convergence:
openings (doors, windows) are captured with high reliability in the initial
pass, while wall detection begins around 83% and achieves near-perfect
alignment after a few feedback iterations. Across all categories, precision,
recall, and F1 scores remain above 0.83, and geometric errors (RMSE, MAE)
progressively decrease to zero through feedback corrections. This study
demonstrates how MLLM-driven multi-agent reasoning can make BIM creation
accessible to both experts and non-experts using only freehand sketches.

</details>


### [23] [CXRAgent: Director-Orchestrated Multi-Stage Reasoning for Chest X-Ray Interpretation](https://arxiv.org/abs/2510.21324)
*Jinhui Lou,Yan Yang,Zhou Yu,Zhenqi Fu,Weidong Han,Qingming Huang,Jun Yu*

Main category: cs.AI

TL;DR: CXRAgent는 다단계 에이전트로, 흉부 엑스레이(CXR) 해석을 위해 도구 조정, 다단계 추론 및 팀 협업을 통해 모델 능력을 강화합니다.


<details>
  <summary>Details</summary>
Motivation: 흉부 엑스레이의 자동 해석을 위한 기존 모델들은 새로운 진단 작업 및 복잡한 추론 시나리오에 적응하는 데 어려움을 겪고 있습니다.

Method: CXRAgent는 중앙 디렉터가 도구 호출, 진단 계획 및 협업 의사결정의 세 가지 단계를 조정하는 구조를 가지고 있습니다.

Result: CXRAgent는 다양한 CXR 해석 작업에서 강력한 성능을 발휘하며, 시각적 증거를 제공하고 다양한 복잡성을 가진 임상 작업에 잘 일반화됩니다.

Conclusion: CXRAgent의 코드와 데이터는 제공된 링크에서 확인할 수 있습니다.

Abstract: Chest X-ray (CXR) plays a pivotal role in clinical diagnosis, and a variety
of task-specific and foundation models have been developed for automatic CXR
interpretation. However, these models often struggle to adapt to new diagnostic
tasks and complex reasoning scenarios. Recently, LLM-based agent models have
emerged as a promising paradigm for CXR analysis, enhancing model's capability
through tool coordination, multi-step reasoning, and team collaboration, etc.
However, existing agents often rely on a single diagnostic pipeline and lack
mechanisms for assessing tools' reliability, limiting their adaptability and
credibility. To this end, we propose CXRAgent, a director-orchestrated,
multi-stage agent for CXR interpretation, where a central director coordinates
the following stages: (1) Tool Invocation: The agent strategically orchestrates
a set of CXR-analysis tools, with outputs normalized and verified by the
Evidence-driven Validator (EDV), which grounds diagnostic outputs with visual
evidence to support reliable downstream diagnosis; (2) Diagnostic Planning:
Guided by task requirements and intermediate findings, the agent formulates a
targeted diagnostic plan. It then assembles an expert team accordingly,
defining member roles and coordinating their interactions to enable adaptive
and collaborative reasoning; (3) Collaborative Decision-making: The agent
integrates insights from the expert team with accumulated contextual memories,
synthesizing them into an evidence-backed diagnostic conclusion. Experiments on
various CXR interpretation tasks show that CXRAgent delivers strong
performance, providing visual evidence and generalizes well to clinical tasks
of different complexity. Code and data are valuable at this
\href{https://github.com/laojiahuo2003/CXRAgent/}{link}.

</details>


### [24] [Cultural Alien Sampler: Open-ended art generation balancing originality and coherence](https://arxiv.org/abs/2510.20849)
*Alejandro H. Artiles,Hiromu Yakura,Levin Brinkmann,Mar Canet Sola,Hassan Abu Alhaija,Ignacio Serna,Nasim Rahaman,Bernhard Schölkopf,Iyad Rahwan*

Main category: cs.AI

TL;DR: 본 연구는 문화 관습으로부터 벗어나면서도 일관성을 유지하는 독창적인 아이디어 생성을 위한 문화 이질 샘플러(CAS)를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 예술과 같은 열린 분야에서 자율 에이전트는 독창적이고 내부적으로 일관된 아이디어를 생성해야 합니다.

Method: CAS는 두 개의 GPT-2 모델을 사용하여 구성 적합성과 문화 전형성을 명시적으로 분리하는 개념 선택 방법입니다.

Result: 인간 평가에서 우리의 접근 방식은 무작위 선택 및 GPT-4o 기준보다 우수하며, 인식된 독창성과 조화 모두에서 인간 미술 학생과 비교될 수 있는 성과를 달성합니다.

Conclusion: 인공 문화 이질성은 자율 에이전트의 창의적 잠재력을 열 수 있음을 보여주고 있습니다.

Abstract: In open-ended domains like art, autonomous agents must generate ideas that
are both original and internally coherent, yet current Large Language Models
(LLMs) either default to familiar cultural patterns or sacrifice coherence when
pushed toward novelty. We address this by introducing the Cultural Alien
Sampler (CAS), a concept-selection method that explicitly separates
compositional fit from cultural typicality. CAS uses two GPT-2 models
fine-tuned on WikiArt concepts: a Concept Coherence Model that scores whether
concepts plausibly co-occur within artworks, and a Cultural Context Model that
estimates how typical those combinations are within individual artists' bodies
of work. CAS targets combinations that are high in coherence and low in
typicality, yielding ideas that maintain internal consistency while deviating
from learned conventions and embedded cultural context. In a human evaluation
(N = 100), our approach outperforms random selection and GPT-4o baselines and
achieves performance comparable to human art students in both perceived
originality and harmony. Additionally, a quantitative study shows that our
method produces more diverse outputs and explores a broader conceptual space
than its GPT-4o counterpart, demonstrating that artificial cultural alienness
can unlock creative potential in autonomous agents.

</details>


### [25] [From Questions to Queries: An AI-powered Multi-Agent Framework for Spatial Text-to-SQL](https://arxiv.org/abs/2510.21045)
*Ali Khosravi Kazazi,Zhenlong Li,M. Naser Lessani,Guido Cervone*

Main category: cs.AI

TL;DR: 본 연구는 자연어 질문을 공간 SQL 쿼리로 번역하기 위한 다중 에이전트 프레임워크를 제안하며, 공간 데이터 분석의 접근성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 비전문가들이 공간 데이터를 분석하는 데 있어 SQL의 복잡성과 PostGIS와 같은 도구의 지리공간 기능의 전문성이 큰 장벽을 형성한다.

Method: 자연어 질문을 정확하게 공간 SQL 쿼리로 번역하기 위해 지식 기반, 임베딩, 협업 다중 에이전트 파이프라인 등 여러 혁신적인 구성 요소를 통합한 다중 에이전트 프레임워크를 제안한다.

Result: KaggleDBQA에서 전반적인 정확도 81.2%를 달성하였고, 공간 쿼리에 대해서는 리뷰 에이전트를 사용했을 때 87.7%의 정확도를 기록하였다.

Conclusion: 이 연구는 공간 분석의 접근성을 높이고, 자율 GIS 개발을 촉진하는 강력하고 일반화 가능한 기반을 제공한다.

Abstract: The complexity of Structured Query Language (SQL) and the specialized nature
of geospatial functions in tools like PostGIS present significant barriers to
non-experts seeking to analyze spatial data. While Large Language Models (LLMs)
offer promise for translating natural language into SQL (Text-to-SQL),
single-agent approaches often struggle with the semantic and syntactic
complexities of spatial queries. To address this, we propose a multi-agent
framework designed to accurately translate natural language questions into
spatial SQL queries. The framework integrates several innovative components,
including a knowledge base with programmatic schema profiling and semantic
enrichment, embeddings for context retrieval, and a collaborative multi-agent
pipeline as its core. This pipeline comprises specialized agents for entity
extraction, metadata retrieval, query logic formulation, SQL generation, and a
review agent that performs programmatic and semantic validation of the
generated SQL to ensure correctness (self-verification). We evaluate our system
using both the non-spatial KaggleDBQA benchmark and a new, comprehensive
SpatialQueryQA benchmark that includes diverse geometry types, predicates, and
three levels of query complexity. On KaggleDBQA, the system achieved an overall
accuracy of 81.2% (221 out of 272 questions) after the review agent's review
and corrections. For spatial queries, the system achieved an overall accuracy
of 87.7% (79 out of 90 questions), compared with 76.7% without the review
agent. Beyond accuracy, results also show that in some instances the system
generates queries that are more semantically aligned with user intent than
those in the benchmarks. This work makes spatial analysis more accessible, and
provides a robust, generalizable foundation for spatial Text-to-SQL systems,
advancing the development of autonomous GIS.

</details>


### [26] [Confounding Robust Deep Reinforcement Learning: A Causal Approach](https://arxiv.org/abs/2510.21110)
*Mingxuan Li,Junzhe Zhang,Elias Bareinboim*

Main category: cs.AI

TL;DR: 복잡하고 고차원적인 분야에서 편향된 데이터를 통한 오프 정책 학습에 대한 연구.


<details>
  <summary>Details</summary>
Motivation: 알려지지 않은 환경에서 에이전트를 제어하기 위한 효과적인 정책을 학습하는 것은 인공지능의 중요한 과제이다.

Method: 본 논문에서는 편향된 데이터를 사용한 오프 정책 학습을 연구하며, 관찰된 데이터에서의 혼란 편향에 강인한 새로운 심층 강화 학습 알고리즘을 제안한다.

Result: 우리의 알고리즘은 관찰과 일치하지 않는 행동 정책 및 목표 정책의 입력이 있는 모든 게임에서 표준 DQN을 지속적으로 능가한다.

Conclusion: 우리의 접근 방식은 편향된 관찰 데이터를 처리하는 데 있어 더 안전한 정책을 찾는 데 효과적이다.

Abstract: A key task in Artificial Intelligence is learning effective policies for
controlling agents in unknown environments to optimize performance measures.
Off-policy learning methods, like Q-learning, allow learners to make optimal
decisions based on past experiences. This paper studies off-policy learning
from biased data in complex and high-dimensional domains where \emph{unobserved
confounding} cannot be ruled out a priori. Building on the well-celebrated Deep
Q-Network (DQN), we propose a novel deep reinforcement learning algorithm
robust to confounding biases in observed data. Specifically, our algorithm
attempts to find a safe policy for the worst-case environment compatible with
the observations. We apply our method to twelve confounded Atari games, and
find that it consistently dominates the standard DQN in all games where the
observed input to the behavioral and target policies mismatch and unobserved
confounders exist.

</details>


### [27] [DAO-AI: Evaluating Collective Decision-Making through Agentic AI in Decentralized Governance](https://arxiv.org/abs/2510.21117)
*Agostino Capponi,Alfio Gliozzo,Chunghyun Han,Junkyu Lee*

Main category: cs.AI

TL;DR: 이 논문은 분산 거버넌스에서 자율적 의사결정자로서의 에이전틱 AI에 대한 첫 번째 실증 연구를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI가 분산 거버넌스에서 자율적 의사결정자로 어떻게 작용할 수 있는지 이해하는 것.

Method: 3,000개 이상의 주요 프로토콜 제안을 사용하여 제안 문맥을 해석하고, 역사적 토론 데이터를 검색하며, 독립적으로 투표 입장을 결정하는 에이전틱 AI 투표자를 구축하였다.

Result: 에이전트의 결정이 인간 및 토큰 가중 결과와 얼마나 밀접하게 일치하는지 평가하여, 정밀하게 설계된 평가 지표에 의해 측정된 강력한 일치를 발견하였다.

Conclusion: 에이전틱 AI는 실질적인 DAO 거버넌스 환경에서 해석 가능하고 감사 가능하며 실증적으로 기반을 둔 신호를 생성하여 집단 의사결정을 증진할 수 있음을 보여준다.

Abstract: This paper presents a first empirical study of agentic AI as autonomous
decision-makers in decentralized governance. Using more than 3K proposals from
major protocols, we build an agentic AI voter that interprets proposal
contexts, retrieves historical deliberation data, and independently determines
its voting position. The agent operates within a realistic financial simulation
environment grounded in verifiable blockchain data, implemented through a
modular composable program (MCP) workflow that defines data flow and tool usage
via Agentics framework. We evaluate how closely the agent's decisions align
with the human and token-weighted outcomes, uncovering strong alignments
measured by carefully designed evaluation metrics. Our findings demonstrate
that agentic AI can augment collective decision-making by producing
interpretable, auditable, and empirically grounded signals in realistic DAO
governance settings. The study contributes to the design of explainable and
economically rigorous AI agents for decentralized financial systems.

</details>


### [28] [PanicToCalm: A Proactive Counseling Agent for Panic Attacks](https://arxiv.org/abs/2510.21143)
*Jihyun Lee,Yejin Min,San Kim,Yejin Jeon,SungJun Yang,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.AI

TL;DR: PACER 모델은 고통이 있는 에피소드를 기반으로 한 PACE 데이터셋을 활용하여 효과적인 상담 지원을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 패닉 발작에 대한 효과적인 개입의 필요성을 해결하기 위해 적절한 데이터셋의 부족 문제를 해결하고자 한다.

Method: PACE 데이터셋을 구축하고, 이를 통해 공감적이고 지시적인 지원을 제공하는 PACER 상담 모델을 교육한다.

Result: PACER는 상담사 측 지표와 클라이언트 정서 개선 측면 모두에서 강력한 기준선을 초과하는 성과를 보였다.

Conclusion: PACER는 위기 상황에서 일반 모델보다 더 높은 실용적 가치를 확인받았다.

Abstract: Panic attacks are acute episodes of fear and distress, in which timely,
appropriate intervention can significantly help individuals regain stability.
However, suitable datasets for training such models remain scarce due to
ethical and logistical issues. To address this, we introduce PACE, which is a
dataset that includes high-distress episodes constructed from first-person
narratives, and structured around the principles of Psychological First Aid
(PFA). Using this data, we train PACER, a counseling model designed to provide
both empathetic and directive support, which is optimized through supervised
learning and simulated preference alignment. To assess its effectiveness, we
propose PanicEval, a multi-dimensional framework covering general counseling
quality and crisis-specific strategies. Experimental results show that PACER
outperforms strong baselines in both counselor-side metrics and client affect
improvement. Human evaluations further confirm its practical value, with PACER
consistently preferred over general, CBT-based, and GPT-4-powered models in
panic scenarios (Code is available at https://github.com/JihyunLee1/PanicToCalm
).

</details>


### [29] [Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning](https://arxiv.org/abs/2510.21302)
*Sanghyun Ahn,Wonje Choi,Junyong Lee,Jinwoo Park,Honguk Woo*

Main category: cs.AI

TL;DR: 이 논문은 코드 생성을 위한 뉴로-심볼릭 임베디드 작업 계획 프레임워크를 제안하며, 이는 보다 향상된 코드의 신뢰성과 성공률을 달성하기 위해 상징적 검증과 상호작용 검증 프로세스를 통합합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 기반으로 한 임베디드 인텔리전스의 가능성에도 불구하고, 환경적 기반이 제한된 점과 잘못된 코드 생성으로 인해 작업 성공률이 낮아지는 문제를 해결하고자 합니다.

Method: 명확한 상징적 검증과 상호작용 검증 프로세스를 통합한 뉴로-심볼릭 임베디드 작업 계획 프레임워크를 제안합니다. 검증 단계에서 이 프레임워크는 환경과 적극적으로 상호작용하는 탐색 코드를 생성하여 누락된 관찰을 획득합니다.

Result: 우리의 프레임워크는 RLBench 및 실제 환경에서 동적이고 부분적으로 관찰 가능한 시나리오에 대해 평가됩니다. 실험 결과, 작업 성공률이 Code-as-Policies 기준보다 46.2% 향상된 것으로 나타났습니다.

Conclusion: 게다가 작업 관련 행동의 86.8% 이상은 실행 가능성을 유지하여 동적 환경에서의 작업 계획 신뢰성을 향상시킵니다.

Abstract: Recent advances in large language models (LLMs) have enabled the automatic
generation of executable code for task planning and control in embodied agents
such as robots, demonstrating the potential of LLM-based embodied intelligence.
However, these LLM-based code-as-policies approaches often suffer from limited
environmental grounding, particularly in dynamic or partially observable
settings, leading to suboptimal task success rates due to incorrect or
incomplete code generation. In this work, we propose a neuro-symbolic embodied
task planning framework that incorporates explicit symbolic verification and
interactive validation processes during code generation. In the validation
phase, the framework generates exploratory code that actively interacts with
the environment to acquire missing observations while preserving task-relevant
states. This integrated process enhances the grounding of generated code,
resulting in improved task reliability and success rates in complex
environments. We evaluate our framework on RLBench and in real-world settings
across dynamic, partially observable scenarios. Experimental results
demonstrate that our framework improves task success rates by 46.2% over
Code-as-Policies baselines and attains over 86.8% executability of
task-relevant actions, thereby enhancing the reliability of task planning in
dynamic environments.

</details>


### [30] [Magellan: Guided MCTS for Latent Space Exploration and Novelty Generation](https://arxiv.org/abs/2510.21341)
*Lufan Chang*

Main category: cs.AI

TL;DR: 이 논문에서는 LLM이 창의적 아이디어 생성을 위해 체계적이고 guided exploration을 활용하는 프레임워크인 Magellan을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: LLM은 훈련 데이터의 고확률, 익숙한 개념에 의존하여 혁신적인 아이디어 생성에 어려움을 겪습니다.

Method: Magellan은 Monte Carlo Tree Search (MCTS)와 계층적 가이드 시스템을 사용하여 LLM의 개념 공간을 탐색합니다.

Result: Magellan은 과학적 아이디어 생성을 위한 실험에서 ReAct 및 ToT와 같은 강력한 기준선을 크게 초과하여 우수한 사실성과 혁신성을 보여줍니다.

Conclusion: 창의적 발견을 위해 체계적이고 guided search가 보다 효과적이라는 것을 보여주며, LLM이 혁신의 파트너로서 더 능력 있게 발전할 수 있는 길을 제시합니다.

Abstract: Large Language Models (LLMs) often struggle with generating truly innovative
ideas, typically defaulting to high-probability, familiar concepts within their
training data's "gravity wells." While advanced search-based methods like Tree
of Thoughts (ToT) attempt to mitigate this, they are fundamentally limited by
their reliance on unprincipled, inconsistent self-evaluation heuristics to
guide exploration. To address this gap, we introduce \textbf{Magellan}, a novel
framework that reframes creative generation as a principled, guided exploration
of an LLM's latent conceptual space. At its core, Magellan employs Monte Carlo
Tree Search (MCTS) governed by a hierarchical guidance system. For long-range
direction, a "semantic compass" vector, formulated via orthogonal projection,
steers the search towards relevant novelty. For local, step-by-step decisions,
a landscape-aware value function replaces flawed self-evaluation with an
explicit reward structure that balances intrinsic coherence, extrinsic novelty,
and narrative progress. Extensive experiments demonstrate that Magellan
significantly outperforms strong baselines, including ReAct and ToT, in
generating scientific ideas with superior plausibility and innovation. Our work
shows that for creative discovery, a principled, guided search is more
effective than unconstrained agency, paving the way for LLMs to become more
capable partners in innovation.

</details>


### [31] [EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law](https://arxiv.org/abs/2510.21524)
*Ilija Lichkovski,Alexander Müller,Mariam Ibrahim,Tiwai Mhundwa*

Main category: cs.AI

TL;DR: 이 논문은 EU 법적 맥락에서 LLM 에이전트가 불법 행동을 취할 잠재력을 측정하기 위해 EU-Agent-Bench라는 검증 가능한 벤치마크를 도입합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트를 다양한 맥락에서 사용하는 증가하는 추세 속에서, 불확실한 행동과 불법적인 행동의 가능성을 평가하기 위함입니다.

Method: EU-Agent-Bench는 데이터 보호, 편견/차별, 과학적 정직성과 같은 여러 범주에 걸쳐 시나리오를 포함하여, 사용자 요청이 합법적 또는 비합법적 행동으로 이어질 수 있는 상황에서 LLM의 법적 규범 준수를 평가합니다.

Result: 모델의 기능 호출을 관련 법률의 인용에 따라 비교하고, 법적 준수를 평가하며, 시스템 프롬프트에 관련 법률 발췌 및 준수 지침을 포함할 때의 준수 효과를 조사합니다.

Conclusion: 미래 연구는 다양한 법적 관할권과 다중 턴, 다국어 상호작용으로 에이전트 안전 벤치마크를 확장할 것을 권장합니다.

Abstract: Large language models (LLMs) are increasingly deployed as agents in various
contexts by providing tools at their disposal. However, LLM agents can exhibit
unpredictable behaviors, including taking undesirable and/or unsafe actions. In
order to measure the latent propensity of LLM agents for taking illegal actions
under an EU legislative context, we introduce EU-Agent-Bench, a verifiable
human-curated benchmark that evaluates an agent's alignment with EU legal norms
in situations where benign user inputs could lead to unlawful actions. Our
benchmark spans scenarios across several categories, including data protection,
bias/discrimination, and scientific integrity, with each user request allowing
for both compliant and non-compliant execution of the requested actions.
Comparing the model's function calls against a rubric exhaustively supported by
citations of the relevant legislature, we evaluate the legal compliance of
frontier LLMs, and furthermore investigate the compliance effect of providing
the relevant legislative excerpts in the agent's system prompt along with
explicit instructions to comply. We release a public preview set for the
research community, while holding out a private test set to prevent data
contamination in evaluating upcoming models. We encourage future work extending
agentic safety benchmarks to different legal jurisdictions and to multi-turn
and multilingual interactions. We release our code on
\href{https://github.com/ilijalichkovski/eu-agent-bench}{this URL}.

</details>


### [32] [Co-Sight: Enhancing LLM-Based Agents via Conflict-Aware Meta-Verification and Trustworthy Reasoning with Structured Facts](https://arxiv.org/abs/2510.21557)
*Hongwei Zhang,Ji Lu,Shiqing Jiang,Chenxiang Zhu,Li Xie,Chen Zhong,Haoran Chen,Yurui Zhu,Yongsheng Du,Yanqin Gao,Lingjun Huang,Baoli Wang,Fang Tan,Peng Zou*

Main category: cs.AI

TL;DR: Co-Sight는 LLM 기반 에이전트의 장기 추론 문제를 해결하기 위해, CAMV와 TRSF라는 두 가지 메커니즘을 통해 추론을 검증 가능한 프로세스로 전환합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트의 장기 추론에서 발생하는 검증 부족 문제를 해결하고자 합니다.

Method: 이 논문은 CAMV(Conflict-Aware Meta-Verification)와 TRSF(Trustworthy Reasoning with Structured Facts)라는 두 가지 메커니즘을 적용하여 추론 프로세스를 개선합니다.

Result: Co-Sight는 GAIA에서 84.4%, Humanity's Last Exam에서 35.5%, Chinese-SimpleQA에서 93.8%의 성능을 기록하며 최신 기술의 정확도를 달성했습니다.

Conclusion: Co-Sight는 LLM 기반 에이전트의 신뢰할 수 있는 장기 추론을 위한 확장 가능한 패러다임을 제공합니다.

Abstract: Long-horizon reasoning in LLM-based agents often fails not from generative
weakness but from insufficient verification of intermediate reasoning. Co-Sight
addresses this challenge by turning reasoning into a falsifiable and auditable
process through two complementary mechanisms: Conflict-Aware Meta-Verification
(CAMV) and Trustworthy Reasoning with Structured Facts (TRSF). CAMV
reformulates verification as conflict identification and targeted
falsification, allocating computation only to disagreement hotspots among
expert agents rather than to full reasoning chains. This bounds verification
cost to the number of inconsistencies and improves efficiency and reliability.
TRSF continuously organizes, validates, and synchronizes evidence across agents
through a structured facts module. By maintaining verified, traceable, and
auditable knowledge, it ensures that all reasoning is grounded in consistent,
source-verified information and supports transparent verification throughout
the reasoning process. Together, TRSF and CAMV form a closed verification loop,
where TRSF supplies structured facts and CAMV selectively falsifies or
reinforces them, yielding transparent and trustworthy reasoning. Empirically,
Co-Sight achieves state-of-the-art accuracy on GAIA (84.4%) and Humanity's Last
Exam (35.5%), and strong results on Chinese-SimpleQA (93.8%). Ablation studies
confirm that the synergy between structured factual grounding and
conflict-aware verification drives these improvements. Co-Sight thus offers a
scalable paradigm for reliable long-horizon reasoning in LLM-based agents. Code
is available at
https://github.com/ZTE-AICloud/Co-Sight/tree/cosight2.0_benchmarks.

</details>


### [33] [Huxley-Gödel Machine: Human-Level Coding Agent Development by an Approximation of the Optimal Self-Improving Machine](https://arxiv.org/abs/2510.21614)
*Wenyi Wang,Piotr Piękos,Li Nanbo,Firas Laakom,Yimeng Chen,Mateusz Ostaszewski,Mingchen Zhuge,Jürgen Schmidhuber*

Main category: cs.AI

TL;DR: 이 연구는 자기 개선을 위한 코드 수정 에이전트의 성능을 분석하고, 자기 개선 잠재력과 실제 성능 간의 불일치를 해결하기 위한 새로운 메트릭과 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 최근 연구들은 코드베이스를 편집하는 코드 수정 에이전트를 통해 자기 개선을 실현합니다. 그러나 이러한 접근법에는 에이전트의 자기 개선 잠재력과 코딩 성능 간의 불일치가 있습니다.

Method: Huxley의 클레이드 개념에서 영감을 받아, 에이전트의 후손들의 성능을 집계하는 $	ext{CMP}$ 메트릭을 제안하고, 이를 바탕으로 Huxley-Gödel 머신(HGM)을 소개합니다.

Result: HGM은 기존의 자기 개선 코딩 에이전트 개발 방법들보다 높은 성능을 보이며, 모형이 다양한 코딩 데이터셋과 대규모 언어 모델에 우수한 전이 능력을 나타냅니다.

Conclusion: HGM은 GPT-5-mini를 사용하여 SWE-bench Verified에서 최적화된 결과를 통해 사람의 수준의 성능을 달성하며, 기계적으로 검증된 결과와 일치합니다.

Abstract: Recent studies operationalize self-improvement through coding agents that
edit their own codebases. They grow a tree of self-modifications through
expansion strategies that favor higher software engineering benchmark
performance, assuming that this implies more promising subsequent
self-modifications. However, we identify a mismatch between the agent's
self-improvement potential (metaproductivity) and its coding benchmark
performance, namely the Metaproductivity-Performance Mismatch. Inspired by
Huxley's concept of clade, we propose a metric ($\mathrm{CMP}$) that aggregates
the benchmark performances of the descendants of an agent as an indicator of
its potential for self-improvement. We show that, in our self-improving coding
agent development setting, access to the true $\mathrm{CMP}$ is sufficient to
simulate how the G\"odel Machine would behave under certain assumptions. We
introduce the Huxley-G\"odel Machine (HGM), which, by estimating $\mathrm{CMP}$
and using it as guidance, searches the tree of self-modifications. On SWE-bench
Verified and Polyglot, HGM outperforms prior self-improving coding agent
development methods while using less wall-clock time. Last but not least, HGM
demonstrates strong transfer to other coding datasets and large language
models. The agent optimized by HGM on SWE-bench Verified with GPT-5-mini and
evaluated on SWE-bench Lite with GPT-5 achieves human-level performance,
matching the best officially checked results of human-engineered coding agents.
Our code is available at https://github.com/metauto-ai/HGM.

</details>


### [34] [DeepAgent: A General Reasoning Agent with Scalable Toolsets](https://arxiv.org/abs/2510.21618)
*Xiaoxi Li,Wenxiang Jiao,Jiarui Jin,Guanting Dong,Jiajie Jin,Yinuo Wang,Hao Wang,Yutao Zhu,Ji-Rong Wen,Yuan Lu,Zhicheng Dou*

Main category: cs.AI

TL;DR: DeepAgent는 자율적인 사고, 도구 발견, 행동 실행을 수행하는 종단 간 심층 추론 에이전트로, 긴 수평 상호작용의 도전을 해결하기 위해 자율 메모리 접기 메커니즘을 도입하고, 표준화된 도구 사용을 위해 ToolPO라는 강화 학습 전략을 개발하여 실제 응용 프로그램을 위한 보다 일반적이고 능력 있는 에이전트를 위한 한 걸음을 내딛는다.


<details>
  <summary>Details</summary>
Motivation: 현재의 에이전트 프레임워크는 사전 정의된 워크플로우를 따르며, 자율 및 전반적인 작업 완료를 제한합니다.

Method: DeepAgent는 자율적 사고, 도구 발견 및 행동 실행을 단일 일관된 추론 과정 내에서 수행하는 종단 간 심층 추론 에이전트입니다. 또한, 자율 메모리 접기 메커니즘을 도입하여 과거 상호작용을 구조화된 에피소드 메모리, 작업 메모리 및 도구 메모리로 압축하여 오류 축적을 줄입니다.

Result: DeepAgent는 ToolBench, API-Bank, TMDB, Spotify, ToolHop과 같은 일반 도구 사용 작업 및 ALFWorld, WebShop, GAIA, HLE와 같은 하위 응용 프로그램을 포함한 여덟 개 벤치마크에서 일관되게 성능이 우수함을 입증했습니다.

Conclusion: 이 연구는 실제 응용 프로그램을 위한 더 일반적이고 능력 있는 에이전트를 향한 한 걸음을 내딛습니다.

Abstract: Large reasoning models have demonstrated strong problem-solving abilities,
yet real-world tasks often require external tools and long-horizon
interactions. Existing agent frameworks typically follow predefined workflows,
which limit autonomous and global task completion. In this paper, we introduce
DeepAgent, an end-to-end deep reasoning agent that performs autonomous
thinking, tool discovery, and action execution within a single, coherent
reasoning process. To address the challenges of long-horizon interactions,
particularly the context length explosion from multiple tool calls and the
accumulation of interaction history, we introduce an autonomous memory folding
mechanism that compresses past interactions into structured episodic, working,
and tool memories, reducing error accumulation while preserving critical
information. To teach general-purpose tool use efficiently and stably, we
develop an end-to-end reinforcement learning strategy, namely ToolPO, that
leverages LLM-simulated APIs and applies tool-call advantage attribution to
assign fine-grained credit to the tool invocation tokens. Extensive experiments
on eight benchmarks, including general tool-use tasks (ToolBench, API-Bank,
TMDB, Spotify, ToolHop) and downstream applications (ALFWorld, WebShop, GAIA,
HLE), demonstrate that DeepAgent consistently outperforms baselines across both
labeled-tool and open-set tool retrieval scenarios. This work takes a step
toward more general and capable agents for real-world applications. The code
and demo are available at https://github.com/RUC-NLPIR/DeepAgent.

</details>


### [35] [AstaBench: Rigorous Benchmarking of AI Agents with a Scientific Research Suite](https://arxiv.org/abs/2510.21652)
*Jonathan Bragg,Mike D'Arcy,Nishant Balepur,Dan Bareket,Bhavana Dalvi,Sergey Feldman,Dany Haddad,Jena D. Hwang,Peter Jansen,Varsha Kishore,Bodhisattwa Prasad Majumder,Aakanksha Naik,Sigal Rahamimov,Kyle Richardson,Amanpreet Singh,Harshit Surana,Aryeh Tiktinsky,Rosni Vasu,Guy Wiener,Chloe Anastasiades,Stefan Candra,Jason Dunkelberger,Dan Emery,Rob Evans,Malachi Hamada,Regan Huff,Rodney Kinney,Matt Latzke,Jaron Lochner,Ruben Lozano-Aguilera,Cecile Nguyen,Smita Rao,Amber Tanaka,Brooke Vlahos,Peter Clark,Doug Downey,Yoav Goldberg,Ashish Sabharwal,Daniel S. Weld*

Main category: cs.AI

TL;DR: AI 에이전트는 문헌 리뷰 자동화, 실험 복제, 데이터 분석 등 과학 생산성을 혁신할 잠재력이 있으나, 효과적인 평가와 벤치마킹이 부족하다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트의 발전과 실용성을 평가하는 것이 과학 연구의 효율성을 높이기 위해 중요하다.

Method: AstaBench라는 도구 세트를 정의하여 에이전트의 과학 연구 수행 능력을 종합적으로 측정한다.

Result: AstaBench는 2400개 이상의 문제를 포함하여 과학 발견 과정 전반에 걸쳐 에이전트의 능력을 평가한다.

Conclusion: AI는 특정 측면에서 의미 있는 진전을 이루었으나, 과학 연구 지원이라는 도전 과제를 해결하는 데는 여전히 멀었다.

Abstract: AI agents hold the potential to revolutionize scientific productivity by
automating literature reviews, replicating experiments, analyzing data, and
even proposing new directions of inquiry; indeed, there are now many such
agents, ranging from general-purpose "deep research" systems to specialized
science-specific agents, such as AI Scientist and AIGS. Rigorous evaluation of
these agents is critical for progress. Yet existing benchmarks fall short on
several fronts: they (1) fail to provide holistic, product-informed measures of
real-world use cases such as science research; (2) lack reproducible agent
tools necessary for a controlled comparison of core agentic capabilities; (3)
do not account for confounding variables such as model cost and tool access;
(4) do not provide standardized interfaces for quick agent prototyping and
evaluation; and (5) lack comprehensive baseline agents necessary to identify
true advances. In response, we define principles and tooling for more
rigorously benchmarking agents. Using these, we present AstaBench, a suite that
provides the first holistic measure of agentic ability to perform scientific
research, comprising 2400+ problems spanning the entire scientific discovery
process and multiple scientific domains, and including many problems inspired
by actual user requests to deployed Asta agents. Our suite comes with the first
scientific research environment with production-grade search tools that enable
controlled, reproducible evaluation, better accounting for confounders.
Alongside, we provide a comprehensive suite of nine science-optimized classes
of Asta agents and numerous baselines. Our extensive evaluation of 57 agents
across 22 agent classes reveals several interesting findings, most importantly
that despite meaningful progress on certain individual aspects, AI remains far
from solving the challenge of science research assistance.

</details>


### [36] [A Knowledge-Graph Translation Layer for Mission-Aware Multi-Agent Path Planning in Spatiotemporal Dynamics](https://arxiv.org/abs/2510.21695)
*Edward Holmberg,Elias Ioup,Mahdi Abdelguerfi*

Main category: cs.AI

TL;DR: 이 논문에서는 자율 에이전트의 협조를 위한 지식 그래프(KG) 기반 프레임워크를 제안하여 복잡한 경로를 효율적으로 수정하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 자율 에이전트가 동적 환경에서 효과적으로 협조하기 위해서는 고수준의 임무 목표와 저수준의 계획 입력 사이의 의미적 간극을 해소해야 합니다.

Method: 지식 그래프(KG)를 중심으로 한 프레임워크를 도입하여, KG의 두 평면 구조가 선언적 사실을 각 에이전트에 대해 임무 인식적인 '세계관'과 물리학 인식적인 이동 규칙으로 컴파일합니다.

Result: 멕시코만에서의 자율 수중 차량(AUV)을 활용한 사례 연구를 통해 이 과정의 시각적 시연과 함께 서로 다른 선언적 정책이 뚜렷하고 높은 성능의 결과를 산출함을 정량적으로 증명합니다.

Conclusion: 이 연구는 KG를 단순한 데이터 저장소가 아닌, 적응형이고 설명 가능한 자율 시스템을 만드는 강력하고 상태 기반의 조정기로서 확립합니다.

Abstract: The coordination of autonomous agents in dynamic environments is hampered by
the semantic gap between high-level mission objectives and low-level planner
inputs. To address this, we introduce a framework centered on a Knowledge Graph
(KG) that functions as an intelligent translation layer. The KG's two-plane
architecture compiles declarative facts into per-agent, mission-aware
``worldviews" and physics-aware traversal rules, decoupling mission semantics
from a domain-agnostic planner. This allows complex, coordinated paths to be
modified simply by changing facts in the KG. A case study involving Autonomous
Underwater Vehicles (AUVs) in the Gulf of Mexico visually demonstrates the
end-to-end process and quantitatively proves that different declarative
policies produce distinct, high-performing outcomes. This work establishes the
KG not merely as a data repository, but as a powerful, stateful orchestrator
for creating adaptive and explainable autonomous systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [37] [\textsc{autoresearcher}: Automating Knowledge-Grounded and Transparent Research Ideation with Multi-Agent Collaboration](https://arxiv.org/abs/2510.20844)
*Jiawei Zhou,Ruicheng Zhu,Mengshi Chen,Jianwei Wang,Kai Wang*

Main category: cs.MA

TL;DR: 이 논문은 지식 기반 및 투명한 아이디어 생성을 위한 다중 에이전트 시스템인 autoresearcher를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 효과적인 연구는 방대한 정보를 조직하고 새로운 해결책을 자극하는 데 의존한다.

Method: autoresearcher는 체계적으로 설계된 네 단계(구조화된 지식 관리, 다양화된 아이디어 생성, 다단계 아이디어 선택, 전문가 패널 검토 및 종합)를 통합한 프레임워크를 제공한다.

Result: 이 시스템은 중간 추론 상태, 실행 로그 및 조정 가능한 에이전트를 노출하고, 다양한 증거와 일치하는 가설을 생성할 수 있다.

Conclusion: autoresearcher는 과학 분야에서 문헌 소스가 존재하는 한 동일한 파이프라인을 구현할 수 있으며, 그래프 마이닝 사례 연구에서 구체적이고 그럴듯한 가설을 생성하는 것을 보여준다.

Abstract: Effective research relies on organizing extensive information and stimulating
novel solutions. Agentic systems have recently emerged as a promising tool to
automate literature-based ideation. However, current systems often remain
black-box. Their outputs may appear plausible but weakly grounded, with limited
transparency or control for researchers. Our work introduces
\textsc{autoresearcher}, a multi-agent demo system for knowledge-grounded and
transparent ideation. Specifically, \textsc{autoresearcher} integrates
meticulously designed four stages into a unified framework: (A) Structured
Knowledge Curation, (B) Diversified Idea Generation, (C) Multi-stage Idea
Selection, and (D) Expert Panel Review \& Synthesis. Different from prior
pipelines, our system not only exposes intermediate reasoning states, execution
logs, and tunable agents for inspections, but also enables the generation of
hypotheses that are both diverse and evidence-aligned. Our design is also
domain-agnostic: as long as literature sources exist, the same pipeline can be
instantiated in any scientific field. As an illustrative case, we demonstrate
\textsc{autoresearcher} on a graph-mining case study ($k$-truss breaking
problem), where it generates distinct, plausible hypotheses with evidence and
critiques. A live demo and source code are available at
https://github.com/valleysprings/AutoResearcher.

</details>


### [38] [HIKMA: Human-Inspired Knowledge by Machine Agents through a Multi-Agent Framework for Semi-Autonomous Scientific Conferences](https://arxiv.org/abs/2510.21370)
*Zain Ul Abideen Tariq,Mahmood Al-Zubaidi,Uzair Shah,Marco Agus,Mowafa Househ*

Main category: cs.MA

TL;DR: HIKMA 반자동 회의는 인공지능을 학술 출판 및 발표 파이프라인에 통합한 첫 실험이다.


<details>
  <summary>Details</summary>
Motivation: 이 논문의 동기는 AI가 기존의 학술 관행을 지원할 수 있는 방법을 탐구하는 것이다.

Method: HIKMA 프레임워크의 설계, 구현 및 평가를 포함하며, AI 데이터 세트 큐레이션, AI 기반 원고 생성, AI 지원 동료 심사, AI 주도 개정, AI 회의 발표 및 AI 보관 배포를 포함한다.

Result: HIKMA는 AI가 지적 재산 보호, 투명성 및 무결성을 유지하면서 전통적인 학술 관행을 지원할 수 있는 방법을 보여준다.

Conclusion: 이 회의는 AI 중심의 학문에서의 기회와 도전에 대한 통찰력을 제공하며, AI 저작권, 책임 및 연구에서의 인간-AI 협력의 역할에 대한 질문을 검토한다.

Abstract: HIKMA Semi-Autonomous Conference is the first experiment in reimagining
scholarly communication through an end-to-end integration of artificial
intelligence into the academic publishing and presentation pipeline. This paper
presents the design, implementation, and evaluation of the HIKMA framework,
which includes AI dataset curation, AI-based manuscript generation, AI-assisted
peer review, AI-driven revision, AI conference presentation, and AI archival
dissemination. By combining language models, structured research workflows, and
domain safeguards, HIKMA shows how AI can support - not replace traditional
scholarly practices while maintaining intellectual property protection,
transparency, and integrity. The conference functions as a testbed and proof of
concept, providing insights into the opportunities and challenges of AI-enabled
scholarship. It also examines questions about AI authorship, accountability,
and the role of human-AI collaboration in research.

</details>


### [39] [ColorEcosystem: Powering Personalized, Standardized, and Trustworthy Agentic Service in massive-agent Ecosystem](https://arxiv.org/abs/2510.21566)
*Fangwen Wu,Zheng Wu,Jihong Wang,Yunku Chen,Ruiguang Pei,Heyuan Huang,Xin Liao,Xingyu Lou,Huarong Deng,Zhihui Fu,Weiwen Liu,Zhuosheng Zhang,Weinan Zhang,Jun Wang*

Main category: cs.MA

TL;DR: 이 논문은 개인화되고 표준화된 신뢰할 수 있는 에이전트 서비스를 제공하기 위해 ColorEcosystem이라는 새로운 청사진을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현재 대규모 에이전트 생태계는 비인격적인 서비스 경험, 표준화 부족, 신뢰할 수 없는 행동과 같은 문제에 직면해 있습니다.

Method: ColorEcosystem은 에이전트 운반체, 에이전트 저장소 및 에이전트 감사라는 세 가지 주요 구성 요소로 이루어져 있습니다.

Result: ColorEcosystem은 개인화되고 표준화된 신뢰할 수 있는 에이전트 서비스를 대규모로 제공할 수 있도록 설계되었습니다.

Conclusion: 이 시스템은 대규모 에이전트 생태계 전반에 걸쳐 효과적인 에이전트 서비스를 지원할 수 있는 잠재력을 가지고 있습니다.

Abstract: With the rapid development of (multimodal) large language model-based agents,
the landscape of agentic service management has evolved from single-agent
systems to multi-agent systems, and now to massive-agent ecosystems. Current
massive-agent ecosystems face growing challenges, including impersonal service
experiences, a lack of standardization, and untrustworthy behavior. To address
these issues, we propose ColorEcosystem, a novel blueprint designed to enable
personalized, standardized, and trustworthy agentic service at scale.
Concretely, ColorEcosystem consists of three key components: agent carrier,
agent store, and agent audit. The agent carrier provides personalized service
experiences by utilizing user-specific data and creating a digital twin, while
the agent store serves as a centralized, standardized platform for managing
diverse agentic services. The agent audit, based on the supervision of
developer and user activities, ensures the integrity and credibility of both
service providers and users. Through the analysis of challenges, transitional
forms, and practical considerations, the ColorEcosystem is poised to power
personalized, standardized, and trustworthy agentic service across
massive-agent ecosystems. Meanwhile, we have also implemented part of
ColorEcosystem's functionality, and the relevant code is open-sourced at
https://github.com/opas-lab/color-ecosystem.

</details>
