<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 4]
- [cs.LG](#cs.LG) [Total: 23]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.CR](#cs.CR) [Total: 9]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Bayesian Ego-graph inference for Networked Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2509.16606)
*Wei Duan,Jie Lu,Junyu Xuan*

Main category: cs.MA

TL;DR: 이 논문에서는 네트워크화된 멀티 에이전트 강화 학습을 위한 확률적 그래프 기반 정책을 제안하며, BayesG라는 분산형 액터 프레임워크를 통해 에이전트들이 적응적 상호작용 구조를 학습할 수 있음을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들이 동적 또는 이질적인 환경에 대한 적응성을 제한하는 정적 이웃을 가정하는 반면, 실제 분산 시스템에서는 중앙 집중식 인프라에 의존하는 것이 비현실적입니다.

Method: 에이전트는 자신의 지역 물리적 이웃에서 샘플링된 서브그래프를 기반으로 결정을 내리며, BayesG는 베이지안 변분 추론을 통해 희소하고 контекст 기반 상호작용 구조를 학습하는 분산형 액터 프레임워크입니다.

Result: BayesG는 최대 167명의 에이전트가 포함된 대규모 교통 제어 작업에서 강력한 MARL 기준을 초과하여 우수한 확장성, 효율성 및 성능을 보여줍니다.

Conclusion: BayesG는 에이전트들이 상호작용 토폴로지와 의사 결정 전략을 공동으로 학습할 수 있도록 하여 네트워크화된 멀티 에이전트 강화 학습의 새로운 가능성을 제시합니다.

Abstract: In networked multi-agent reinforcement learning (Networked-MARL),
decentralized agents must act under local observability and constrained
communication over fixed physical graphs. Existing methods often assume static
neighborhoods, limiting adaptability to dynamic or heterogeneous environments.
While centralized frameworks can learn dynamic graphs, their reliance on global
state access and centralized infrastructure is impractical in real-world
decentralized systems. We propose a stochastic graph-based policy for
Networked-MARL, where each agent conditions its decision on a sampled subgraph
over its local physical neighborhood. Building on this formulation, we
introduce BayesG, a decentralized actor-framework that learns sparse,
context-aware interaction structures via Bayesian variational inference. Each
agent operates over an ego-graph and samples a latent communication mask to
guide message passing and policy computation. The variational distribution is
trained end-to-end alongside the policy using an evidence lower bound (ELBO)
objective, enabling agents to jointly learn both interaction topology and
decision-making strategies. BayesG outperforms strong MARL baselines on
large-scale traffic control tasks with up to 167 agents, demonstrating superior
scalability, efficiency, and performance.

</details>


### [2] [Towards Transparent and Incentive-Compatible Collaboration in Decentralized LLM Multi-Agent Systems: A Blockchain-Driven Approach](https://arxiv.org/abs/2509.16736)
*Minfeng Qi,Tianqing Zhu,Lefeng Zhang,Ningran Li,Wanlei Zhou*

Main category: cs.MA

TL;DR: 이 논문은 블록체인 기반 프레임워크를 제안하여 분산 환경에서 에이전트 등록, 작업 할당 및 평판 추적을 투명하게 처리하는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 추론, 계획 및 상호작용이 가능한 자율 에이전트를 대규모로 조정하는 것은 여전히 기본적인 도전 과제이다.

Method: 블록체인 기반의 프레임워크를 이용해 투명한 에이전트 등록, 검증 가능한 작업 할당 및 동적 평판 추적을 스마트 계약을 통해 가능하게 한다.

Result: 50회의 시뮬레이션을 통해 작업 성공률이 높고, 안정적인 유틸리티 분포 및 자율 에이전트의 전문화가 나타났다.

Conclusion: 개방 환경에서 신뢰할 수 있고 인센티브 호환이 가능한 다중 에이전트 조정의 잠재력을 강조한다.

Abstract: Large Language Models (LLMs) have enabled the emergence of autonomous agents
capable of complex reasoning, planning, and interaction. However, coordinating
such agents at scale remains a fundamental challenge, particularly in
decentralized environments where communication lacks transparency and agent
behavior cannot be shaped through centralized incentives. We propose a
blockchain-based framework that enables transparent agent registration,
verifiable task allocation, and dynamic reputation tracking through smart
contracts. The core of our design lies in two mechanisms: a matching
score-based task allocation protocol that evaluates agents by reputation,
capability match, and workload; and a behavior-shaping incentive mechanism that
adjusts agent behavior via feedback on performance and reward. Our
implementation integrates GPT-4 agents with Solidity contracts and
demonstrates, through 50-round simulations, strong task success rates, stable
utility distribution, and emergent agent specialization. The results underscore
the potential for trustworthy, incentive-compatible multi-agent coordination in
open environments.

</details>


### [3] [An LLM-based Agent Simulation Approach to Study Moral Evolution](https://arxiv.org/abs/2509.17703)
*Zhou Ziheng,Huacong Tang,Mingjie Bi,Yipeng Kang,Wanying He,Fang Sun,Yizhou Sun,Ying Nian Wu,Demetri Terzopoulos,Fangwei Zhong*

Main category: cs.MA

TL;DR: 본 연구는 LLM 기반의 에이전트 시뮬레이션을 통해 도덕 진화의 복잡성을 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 인간의 도덕 시스템이 이타성을 촉진하는 이유와 그것이 자연 선택과 어떻게 조화되는지를 밝히기 위해.

Method: 사전 역사적 사냥-채집 사회를 모델링한 LLM 기반 에이전트 시뮬레이션 프레임워크를 도입했습니다.

Result: 다양한 도덕 성향을 가진 에이전트의 진화적 성공을 평가하고, 도덕적 딜레마에 대한 의사 결정을 분석했습니다.

Conclusion: 이 연구는 진화 생물학과 인류학의 전통적 연구를 보완하는 새로운 패러다임으로서 LLM 기반 시뮬레이션의 가능성을 제시합니다.

Abstract: The evolution of morality presents a puzzle: natural selection should favor
self-interest, yet humans developed moral systems promoting altruism. We
address this question by introducing a novel Large Language Model (LLM)-based
agent simulation framework modeling prehistoric hunter-gatherer societies. This
platform is designed to probe diverse questions in social evolution, from
survival advantages to inter-group dynamics. To investigate moral evolution, we
designed agents with varying moral dispositions based on the Expanding Circle
Theory \citep{singer1981expanding}. We evaluated their evolutionary success
across a series of simulations and analyzed their decision-making in specially
designed moral dilemmas. These experiments reveal how an agent's moral
framework, in combination with its cognitive constraints, directly shapes its
behavior and determines its evolutionary outcome. Crucially, the emergent
patterns echo seminal theories from related domains of social science,
providing external validation for the simulations. This work establishes
LLM-based simulation as a powerful new paradigm to complement traditional
research in evolutionary biology and anthropology, opening new avenues for
investigating the complexities of moral and social evolution.

</details>


### [4] [Strategic Coordination for Evolving Multi-agent Systems: A Hierarchical Reinforcement and Collective Learning Approach](https://arxiv.org/abs/2509.18088)
*Chuhao Qin,Evangelos Pournaras*

Main category: cs.MA

TL;DR: 이 논문에서는 분산 콤비네이터 최적화를 위해 MARL과 계층적 집단 학습을 결합한 HRCL 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 진화하는 다중 에이전트 시스템에서 분산 콤비네이터 최적화는 장기 의사결정과 단기 최적 집단 결과를 조정해야 하며, 예상치 못한 변화 속에서도 상호작용 에이전트의 자율성을 유지해야 하는 중요한 과제를 제기한다.

Method: Hierarchical Reinforcement and Collective Learning (HRCL)이라는 새로운 접근 방식을 제안하고, MARL과 계층적 구조에 기반한 분산 집단 학습을 활용한다.

Result: HRCL은 단독 MARL 및 집단 학습 접근 방식에 비해 성능, 확장성 및 적응성을 크게 향상시킴을 보여준다.

Conclusion: HRCL은 에너지 자가 관리 및 드론 떼 감지와 같은 실제 스마트 시티 응용 모델에서 매우 효과적인 윈-윈 합성 솔루션을 달성한다.

Abstract: Decentralized combinatorial optimization in evolving multi-agent systems
poses significant challenges, requiring agents to balance long-term
decision-making, short-term optimized collective outcomes, while preserving
autonomy of interactive agents under unanticipated changes. Reinforcement
learning offers a way to model sequential decision-making through dynamic
programming to anticipate future environmental changes. However, applying
multi-agent reinforcement learning (MARL) to decentralized combinatorial
optimization problems remains an open challenge due to the exponential growth
of the joint state-action space, high communication overhead, and privacy
concerns in centralized training. To address these limitations, this paper
proposes Hierarchical Reinforcement and Collective Learning (HRCL), a novel
approach that leverages both MARL and decentralized collective learning based
on a hierarchical framework. Agents take high-level strategies using MARL to
group possible plans for action space reduction and constrain the agent
behavior for Pareto optimality. Meanwhile, the low-level collective learning
layer ensures efficient and decentralized coordinated decisions among agents
with minimal communication. Extensive experiments in a synthetic scenario and
real-world smart city application models, including energy self-management and
drone swarm sensing, demonstrate that HRCL significantly improves performance,
scalability, and adaptability compared to the standalone MARL and collective
learning approaches, achieving a win-win synthesis solution.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Robust LLM Training Infrastructure at ByteDance](https://arxiv.org/abs/2509.16293)
*Borui Wan,Gaohong Liu,Zuquan Song,Jun Wang,Yun Zhang,Guangming Sheng,Shuguang Wang,Houmin Wei,Chenyuan Wang,Weiqiang Lou,Xi Yang,Mofan Zhang,Kaihua Jiang,Cheng Ren,Xiaoyun Zhi,Menghan Yu,Zhe Nan,Zhuolin Zheng,Baoquan Zhong,Qinlong Wang,Huan Yu,Jinxin Chi,Wang Zhang,Yuhan Li,Zixian Du,Sida Zhao,Yongqiang Zhang,Jingzhe Tang,Zherui Liu,Chuan Wu,Yanghua Peng,Haibin Lin,Wencong Xiao,Xin Liu,Liang Xiang*

Main category: cs.LG

TL;DR: 대규모 언어 모델(LLM)의 훈련에 최적화된 ByteRobust 시스템을 제안함으로써 훈련 안정성을 향상시키고자 한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 LLM 훈련에서의 자원 확장이 가져오는 실패 문제는 훈련의 안정성에 큰 도전 과제가 된다.

Method: ByteRobust는 LLM 훈련 과정의 특징을 활용하여, 실패를 주기적으로 감지하고 복구하는 시스템이다.

Result: ByteRobust는 20만 개 이상의 GPU가 있는 생산 환경에서 배포되어, 9,600개의 GPU로 3개월 동안의 훈련 작업에서 97% ETTR을 달성하였다.

Conclusion: 이 시스템은 LLM 작업의 연속적이고 효율적인 훈련을 종합적으로 보장한다.

Abstract: The training scale of large language models (LLMs) has reached tens of
thousands of GPUs and is still continuously expanding, enabling faster learning
of larger models. Accompanying the expansion of the resource scale is the
prevalence of failures (CUDA error, NaN values, job hang, etc.), which poses
significant challenges to training stability. Any large-scale LLM training
infrastructure should strive for minimal training interruption, efficient fault
diagnosis, and effective failure tolerance to enable highly efficient
continuous training. This paper presents ByteRobust, a large-scale GPU
infrastructure management system tailored for robust and stable training of
LLMs. It exploits the uniqueness of LLM training process and gives top
priorities to detecting and recovering failures in a routine manner. Leveraging
parallelisms and characteristics of LLM training, ByteRobust enables
high-capacity fault tolerance, prompt fault demarcation, and localization with
an effective data-driven approach, comprehensively ensuring continuous and
efficient training of LLM tasks. ByteRobust is deployed on a production GPU
platform with over 200,000 GPUs and achieves 97% ETTR for a three-month
training job on 9,600 GPUs.

</details>


### [6] [Federated Learning for Financial Forecasting](https://arxiv.org/abs/2509.16393)
*Manuel Noseda,Alberto De Luca,Lukas Von Briel,Nathan Lacour*

Main category: cs.LG

TL;DR: 본 논문은 변동성이 큰 금융 시장 트렌드의 이진 분류를 위한 연합 학습(FL)을 연구한다.


<details>
  <summary>Details</summary>
Motivation: 금융 시장의 변화에 적응할 수 있는 모델을 개발하고 동시에 개인 정보 보호를 보장하는 방법을 모색한다.

Method: 공유된 LSTM 분류기를 사용하여 중앙 집중 모델, 단일 에이전트 모델, 개인 정보 보호를 위한 FL 협업 등 세 가지 시나리오를 비교한다.

Result: FL은 중앙 집중 기준선과 대등한 정확도와 일반화를 달성하며 단일 에이전트 모델보다 현저히 우수한 성능을 보인다.

Conclusion: 협업적이고 개인 정보 보호가 가능한 학습은 현실적인 데이터 이질성과 개인화 요구 사항에서도 금융 분야에서 집단적인 실질 가치를 제공한다.

Abstract: This paper studies Federated Learning (FL) for binary classification of
volatile financial market trends. Using a shared Long Short-Term Memory (LSTM)
classifier, we compare three scenarios: (i) a centralized model trained on the
union of all data, (ii) a single-agent model trained on an individual data
subset, and (iii) a privacy-preserving FL collaboration in which agents
exchange only model updates, never raw data. We then extend the study with
additional market features, deliberately introducing not independent and
identically distributed data (non-IID) across agents, personalized FL and
employing differential privacy. Our numerical experiments show that FL achieves
accuracy and generalization on par with the centralized baseline, while
significantly outperforming the single-agent model. The results show that
collaborative, privacy-preserving learning provides collective tangible value
in finance, even under realistic data heterogeneity and personalization
requirements.

</details>


### [7] [Towards Universal Debiasing for Language Models-based Tabular Data Generation](https://arxiv.org/abs/2509.16475)
*Tianchun Li,Tianci Liu,Xingchen Wang,Rongzhe Wei,Pan Li,Lu Su,Jing Gao*

Main category: cs.LG

TL;DR: 이 연구에서는 테이블 데이터 생성을 위한 보편적인 디바이싱 프레임워크를 제안하여 공정성과 유용성을 균형 있게 유지하는 효과적인 솔루션을 구현합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 테이블 데이터 생성에서 유망한 성과를 보였지만, 역사적 편향으로 인해 공정성 문제가 심화되는 경향이 있습니다.

Method: 상호 정보량을 감소시키며 그룹 수준의 의존성을 최소화하는 보편적인 디바이싱 프레임워크를 도입하고, UDF-DPO 및 UDF-MIX 두 가지 방법을 제안합니다.

Result: 우리의 프레임워크는 공정성과 유용성을 효과적으로 균형 있게 유지할 수 있음을 실험을 통해 입증하였습니다.

Conclusion: 이 연구는 고위험 응용 분야에서의 디바이싱을 위한 확장 가능하고 실용적인 솔루션을 제공합니다.

Abstract: Large language models (LLMs) have achieved promising results in tabular data
generation. However, inherent historical biases in tabular datasets often cause
LLMs to exacerbate fairness issues, particularly when multiple advantaged and
protected features are involved. In this work, we introduce a universal
debiasing framework that minimizes group-level dependencies by simultaneously
reducing the mutual information between advantaged and protected attributes. By
leveraging the autoregressive structure and analytic sampling distributions of
LLM-based tabular data generators, our approach efficiently computes mutual
information, reducing the need for cumbersome numerical estimations. Building
on this foundation, we propose two complementary methods: a direct preference
optimization (DPO)-based strategy, namely UDF-DPO, that integrates seamlessly
with existing models, and a targeted debiasing technique, namely UDF-MIX, that
achieves debiasing without tuning the parameters of LLMs. Extensive experiments
demonstrate that our framework effectively balances fairness and utility,
offering a scalable and practical solution for debiasing in high-stakes
applications.

</details>


### [8] [Revisiting Broken Windows Theory](https://arxiv.org/abs/2509.16490)
*Ziyao Cui,Erick Jiang,Nicholas Sortisio,Haiyan Wang,Eric Chen,Cynthia Rudin*

Main category: cs.LG

TL;DR: 이 논문은 도시 경관의 물리적 구조가 범죄에 미치는 영향을 머신러닝을 활용하여 분석한 결과, 특정 구조가 범죄와 위험 인식에 얼마나 영향을 미치는지를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 물리적 구조가 범죄에 미치는 영향을 재조명하고자 함.

Method: 인구 구성을 통제하기 위해 머신러닝 기반의 매칭 기술을 활용하여 뉴욕과 시카고에서 여러 유형의 도시 구조가 폭력 범죄 발생에 미치는 영향을 추정함.

Result: 버려진 건물과 같은 사회적 무질서의 지표가 범죄 발생률 증가와 위험 인식 증가와 관련이 있음을 보여줌. 그러나 이 효과는 도시 간 및 도시 내에서 다르게 나타남.

Conclusion: 범죄 감축을 위한 일률적인 접근 방식은 불가능하며, 정책적 개입은 구체적인 대상에 맞춰져야 함.

Abstract: We revisit the longstanding question of how physical structures in urban
landscapes influence crime. Leveraging machine learning-based matching
techniques to control for demographic composition, we estimate the effects of
several types of urban structures on the incidence of violent crime in New York
City and Chicago. We additionally contribute to a growing body of literature
documenting the relationship between perception of crime and actual crime rates
by separately analyzing how the physical urban landscape shapes subjective
feelings of safety. Our results are twofold. First, in consensus with prior
work, we demonstrate a "broken windows" effect in which abandoned buildings, a
sign of social disorder, are associated with both greater incidence of crime
and a heightened perception of danger. This is also true of types of urban
structures that draw foot traffic such as public transportation infrastructure.
Second, these effects are not uniform within or across cities. The criminogenic
effects of the same structure types across two cities differ in magnitude,
degree of spatial localization, and heterogeneity across subgroups, while
within the same city, the effects of different structure types are confounded
by different demographic variables. Taken together, these results emphasize
that one-size-fits-all approaches to crime reduction are untenable and policy
interventions must be specifically tailored to their targets.

</details>


### [9] [GRIL: Knowledge Graph Retrieval-Integrated Learning with Large Language Models](https://arxiv.org/abs/2509.16502)
*Jialin Chen,Houyu Zhang,Seongjun Yun,Alejandro Mottini,Rex Ying,Xiang Song,Vassilis N. Ioannidis,Zheng Li,Qingjun Cui*

Main category: cs.LG

TL;DR: 그래프 기반 검색의 확장을 통해 대규모 언어 모델의 환각을 줄이는 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 환각을 줄이기 위해 외부 지식으로 생성을 기반으로 하는 연구의 필요성.

Method: LLM과 함께 end-to-end로 훈련된 새로운 그래프 검색기를 제안하며, 주의 기반의 성장 및 가지치기 메커니즘을 특징으로 합니다.

Result: 세 가지 QA 벤치마크에서 우리의 접근법이 지속적으로 최첨단 성과를 달성했습니다.

Conclusion: 그래프 검색기를 LLM 로짓을 사용하여 암묵적인 피드백으로 최적화하게 함으로써 전통적인 실제 엔터티의 필요성을 없앴습니다.

Abstract: Retrieval-Augmented Generation (RAG) has significantly mitigated the
hallucinations of Large Language Models (LLMs) by grounding the generation with
external knowledge. Recent extensions of RAG to graph-based retrieval offer a
promising direction, leveraging the structural knowledge for multi-hop
reasoning. However, existing graph RAG typically decouples retrieval and
reasoning processes, which prevents the retriever from adapting to the
reasoning needs of the LLM. They also struggle with scalability when performing
multi-hop expansion over large-scale graphs, or depend heavily on annotated
ground-truth entities, which are often unavailable in open-domain settings. To
address these challenges, we propose a novel graph retriever trained end-to-end
with LLM, which features an attention-based growing and pruning mechanism,
adaptively navigating multi-hop relevant entities while filtering out noise.
Within the extracted subgraph, structural knowledge and semantic features are
encoded via soft tokens and the verbalized graph, respectively, which are
infused into the LLM together, thereby enhancing its reasoning capability and
facilitating interactive joint training of the graph retriever and the LLM
reasoner. Experimental results across three QA benchmarks show that our
approach consistently achieves state-of-the-art performance, validating the
strength of joint graph-LLM optimization for complex reasoning tasks. Notably,
our framework eliminates the need for predefined ground-truth entities by
directly optimizing the retriever using LLM logits as implicit feedback, making
it especially effective in open-domain settings.

</details>


### [10] [ViTCAE: ViT-based Class-conditioned Autoencoder](https://arxiv.org/abs/2509.16554)
*Vahid Jebraeeli,Hamid Krim,Derya Cansever*

Main category: cs.LG

TL;DR: ViTCAE는 Class 토큰을 생성의 중심으로 활용하여 최적화 효율성을 개선하는 새로운 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 Vision Transformer 기반 오토인코더는 Class 토큰을 충분히 활용하지 못하고 정적 주의 메커니즘을 사용하여 생성 제어와 최적화 효율성이 제한됩니다.

Method: ViTCAE는 Class 토큰을 글로벌 잠재 변수로 매핑하고, 각 주의 헤드를 동적 시스템으로 간주하여 합의에 도달하도록 유도합니다. 이를 통해 각 헤드의 영향력을 조정하는 온도 스케줄러를 사용합니다.

Result: 이 프로세스는 수렴한 헤드를 훈련 중에 가지치기하여 계산 효율성을 크게 개선하면서도 충실도를 유지합니다.

Conclusion: ViTCAE는 생성 클래스 토큰과 다중 에이전트 합의 이론에 뿌리를 둔 적응적 주의 메커니즘을 통합하여 더욱 효율적이고 제어 가능한 변환기 기반 생성을 제공합니다.

Abstract: Vision Transformer (ViT) based autoencoders often underutilize the global
Class token and employ static attention mechanisms, limiting both generative
control and optimization efficiency. This paper introduces ViTCAE, a framework
that addresses these issues by re-purposing the Class token into a generative
linchpin. In our architecture, the encoder maps the Class token to a global
latent variable that dictates the prior distribution for local, patch-level
latent variables, establishing a robust dependency where global semantics
directly inform the synthesis of local details. Drawing inspiration from
opinion dynamics, we treat each attention head as a dynamical system of
interacting tokens seeking consensus. This perspective motivates a
convergence-aware temperature scheduler that adaptively anneals each head's
influence function based on its distributional stability. This process enables
a principled head-freezing mechanism, guided by theoretically-grounded
diagnostics like an attention evolution distance and a consensus/cluster
functional. This technique prunes converged heads during training to
significantly improve computational efficiency without sacrificing fidelity. By
unifying a generative Class token with an adaptive attention mechanism rooted
in multi-agent consensus theory, ViTCAE offers a more efficient and
controllable approach to transformer-based generation.

</details>


### [11] [A non-smooth regularization framework for learning over multitask graphs](https://arxiv.org/abs/2509.17728)
*Yara Zgheib,Luca Calatroni,Marc Antonini,Roula Nassif*

Main category: cs.LG

TL;DR: 다중 작업 그래프에서 비부드러운 정규화 기술을 활용한 분산 학습 접근법을 제안하며, 이 방법은 동료 작업 간의 관계를 촉진하여 에이전트 간의 협업을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트가 자신의 매개변수 벡터를 추정하는 다중 작업 그래프에서 학습하는 것이 필요합니다. 에이전트들이 서로 다른 목표를 가지더라도, 협업은 유익할 수 있습니다.

Method: 전역 정규화된 최적화 문제를 설정하고, 비부드러운 항을 통해 인접 에이전트의 작업 간의 관계를 조절합니다. 이 문제를 해결하기 위해 분산 학습 접근법을 제안합니다.

Result: 제안한 접근법이 평균 제곱 오차 측면에서 전역 정규화 비용의 최적 해를 $O(μ)$ 내로 수렴함을 보입니다.

Conclusion: 제안된 방법은 널리 사용되는 비부드러운 정규화 방법에 대해 닫힌 형태의 표현을 파생하고, 이론적 결과와 함께 시뮬레이션을 통해 효과성을 입증합니다.

Abstract: In this work, we consider learning over multitask graphs, where each agent
aims to estimate its own parameter vector. Although agents seek distinct
objectives, collaboration among them can be beneficial in scenarios where
relationships between tasks exist. Among the various approaches to promoting
relationships between tasks and, consequently, enhancing collaboration between
agents, one notable method is regularization. While previous multitask learning
studies have focused on smooth regularization to enforce graph smoothness, this
work explores non-smooth regularization techniques that promote sparsity,
making them particularly effective in encouraging piecewise constant
transitions on the graph. We begin by formulating a global regularized
optimization problem, which involves minimizing the aggregate sum of individual
costs, regularized by a general non-smooth term designed to promote
piecewise-constant relationships between the tasks of neighboring agents. Based
on the forward-backward splitting strategy, we propose a decentralized learning
approach that enables efficient solutions to the regularized optimization
problem. Then, under convexity assumptions on the cost functions and
co-regularization, we establish that the proposed approach converges in the
mean-square-error sense within $O(\mu)$ of the optimal solution of the globally
regularized cost. For broader applicability and improved computational
efficiency, we also derive closed-form expressions for commonly used non-smooth
(and, possibly, non-convex) regularizers, such as the weighted sum of the
$\ell_0$-norm, $\ell_1$-norm, and elastic net regularization. Finally, we
illustrate both the theoretical findings and the effectiveness of the approach
through simulations.

</details>


### [12] [HypeMARL: Multi-Agent Reinforcement Learning For High-Dimensional, Parametric, and Distributed Systems](https://arxiv.org/abs/2509.16709)
*Nicolò Botteghi,Matteo Tomasetto,Urban Fasel,Francesco Braghin,Andrea Manzoni*

Main category: cs.LG

TL;DR: 딥 강화 학습은 최근 부분 미분 방정식(PDE)으로 지배되는 복잡한 동적 시스템에 대한 유망한 피드백 제어 전략으로 부상했다. 다차원 문제를 다루기 위해 다중 에이전트 강화 학습(MARL)이 제안되었으나, 비국소적 행동이 중요한 경우 한계가 있다. 본 연구에서는 HypeMARL이라는 분산 MARL 알고리즘을 제안하며, 이 알고리즘은 고차원, 매개변수화된 시스템의 제어에 맞춰져 있어 에이전트의 집단적 행동을 통해 효율적으로 시스템을 제어할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 다차원 상태 및 제어 변수를 가진 복잡한 동적 시스템을 제어하기 위한 효과적인 방법론 필요.

Method: HypeMARL이라는 분산 MARL 알고리즘을 제안하며, 하이퍼네트워크를 활용하여 에이전트의 정책과 가치 함수를 효과적으로 매개변수화한다.

Result: HypeMARL은 집단적 행동을 통해 기존의 최첨단 분산 MARL보다 더 효율적으로 시스템을 제어할 수 있으며, 매개변수 의존성에 효과적으로 대처할 수 있다.

Conclusion: HypeMARL은 최소한의 하이퍼파라미터 조정으로 환경 상호작용을 대폭 줄이는 등 강력한 성능을 보여준다.

Abstract: Deep reinforcement learning has recently emerged as a promising feedback
control strategy for complex dynamical systems governed by partial differential
equations (PDEs). When dealing with distributed, high-dimensional problems in
state and control variables, multi-agent reinforcement learning (MARL) has been
proposed as a scalable approach for breaking the curse of dimensionality. In
particular, through decentralized training and execution, multiple agents
cooperate to steer the system towards a target configuration, relying solely on
local state and reward information. However, the principle of locality may
become a limiting factor whenever a collective, nonlocal behavior of the agents
is crucial to maximize the reward function, as typically happens in
PDE-constrained optimal control problems. In this work, we propose HypeMARL: a
decentralized MARL algorithm tailored to the control of high-dimensional,
parametric, and distributed systems. HypeMARL employs hypernetworks to
effectively parametrize the agents' policies and value functions with respect
to the system parameters and the agents' relative positions, encoded by
sinusoidal positional encoding. Through the application on challenging control
problems, such as density and flow control, we show that HypeMARL (i) can
effectively control systems through a collective behavior of the agents,
outperforming state-of-the-art decentralized MARL, (ii) can efficiently deal
with parametric dependencies, (iii) requires minimal hyperparameter tuning and
(iv) can reduce the amount of expensive environment interactions by a factor of
~10 thanks to its model-based extension, MB-HypeMARL, which relies on
computationally efficient deep learning-based surrogate models approximating
the dynamics locally, with minimal deterioration of the policy performance.

</details>


### [13] [LVADNet3D: A Deep Autoencoder for Reconstructing 3D Intraventricular Flow from Sparse Hemodynamic Data](https://arxiv.org/abs/2509.16860)
*Mohammad Abdul Hafeez Khan,Marcello Mattei Di Eugeni,Benjamin Diaz,Ruth E. White,Siddhartha Bhattacharyya,Venkat Keshav Chivukula*

Main category: cs.LG

TL;DR: 이 논문에서는 LVAD 지원 환자의 심실 내 혈류를 정확하게 평가하기 위한 LVADNet3D라는 3D 컨볼루션 오토인코더를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LVAD가 지원하는 환자에서의 혈역학적 상태 평가를 위해 심실 내 혈류의 정확한 측정이 필수적이다.

Method: LVADNet3D는 희소한 속도 벡터 입력으로부터 전체 해상도의 심실 내 속도 필드를 재구성하는 3D 컨볼루션 오토인코더이다.

Result: LVADNet3D는 다양한 입력 구성에서 기준 UNet3D 모델보다 더 낮은 재구성 오류와 높은 PSNR 결과를 달성한다.

Conclusion: 이 연구는 LVAD 지원 심장에 대한 고해상도 합성 데이터를 사용하여 모델의 훈련과 평가를 진행하였다.

Abstract: Accurate assessment of intraventricular blood flow is essential for
evaluating hemodynamic conditions in patients supported by Left Ventricular
Assist Devices (LVADs). However, clinical imaging is either incompatible with
LVADs or yields sparse, low-quality velocity data. While Computational Fluid
Dynamics (CFD) simulations provide high-fidelity data, they are computationally
intensive and impractical for routine clinical use. To address this, we propose
LVADNet3D, a 3D convolutional autoencoder that reconstructs full-resolution
intraventricular velocity fields from sparse velocity vector inputs. In
contrast to a standard UNet3D model, LVADNet3D incorporates hybrid downsampling
and a deeper encoder-decoder architecture with increased channel capacity to
better capture spatial flow patterns. To train and evaluate the models, we
generate a high-resolution synthetic dataset of intraventricular blood flow in
LVAD-supported hearts using CFD simulations. We also investigate the effect of
conditioning the models on anatomical and physiological priors. Across various
input configurations, LVADNet3D outperforms the baseline UNet3D model, yielding
lower reconstruction error and higher PSNR results.

</details>


### [14] [On the Limits of Tabular Hardness Metrics for Deep RL: A Study with the Pharos Benchmark](https://arxiv.org/abs/2509.17092)
*Michelangelo Conserva,Remo Sasso,Paulo Rauber*

Main category: cs.LG

TL;DR: 이번 연구에서는 비표 형 환경에서의 난이도를 평가하기 위한 새로운 기준이 필요함을 강조하고, 이를 위한 도구로서 	exttt{pharos}라는 오픈소스 라이브러리를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 비표 형 강화 학습의 진전을 위해 원칙적인 평가가 중요하지만, 그 평가가 이론 기반의 표 형 RL 기준에 비해 뒤처져 있습니다.

Method: 비표 형 환경의 난이도가 표 형 메트릭에서 간과되는 요소인 표현의 난이도에 의해 지배된다는 사실을 입증합니다. 이를 위해 새로운 오픈소스 라이브러리인 	exttt{pharos}를 도입하여 환경 구조와 에이전트 표현에 대한 체계적인 조절을 가능하게 합니다.

Result: 	exttt{pharos}를 사용한 광범위한 사례 연구 결과, 표 형 메트릭은 몇 가지 통찰력을 제공하지만, 비표 형 RL 에이전트 성능의 예측력은 부족하다는 것을 보여줍니다.

Conclusion: 표현을 인식하는 새로운 난이도 측정의 필요성을 강조하며, 	exttt{pharos}가 이를 개발하기 위한 중요한 도구로 자리잡고 있음을 알립니다.

Abstract: Principled evaluation is critical for progress in deep reinforcement learning
(RL), yet it lags behind the theory-driven benchmarks of tabular RL. While
tabular settings benefit from well-understood hardness measures like MDP
diameter and suboptimality gaps, deep RL benchmarks are often chosen based on
intuition and popularity. This raises a critical question: can tabular hardness
metrics be adapted to guide non-tabular benchmarking? We investigate this
question and reveal a fundamental gap. Our primary contribution is
demonstrating that the difficulty of non-tabular environments is dominated by a
factor that tabular metrics ignore: representation hardness. The same
underlying MDP can pose vastly different challenges depending on whether the
agent receives state vectors or pixel-based observations. To enable this
analysis, we introduce \texttt{pharos}, a new open-source library for
principled RL benchmarking that allows for systematic control over both
environment structure and agent representations. Our extensive case study using
\texttt{pharos} shows that while tabular metrics offer some insight, they are
poor predictors of deep RL agent performance on their own. This work highlights
the urgent need for new, representation-aware hardness measures and positions
\texttt{pharos} as a key tool for developing them.

</details>


### [15] [SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing](https://arxiv.org/abs/2509.17197)
*Junlong Ke,Qiying Hu,Shenghai Yuan,Yuecong Xu,Jianfei Yang*

Main category: cs.LG

TL;DR: SignalLLM은 신호 처리 작업을 자동화하고 일반화하기 위한 일반 목적의 LLM 기반 에이전트 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 신호 처리 파이프라인은 복잡한 작업 흐름과 전문가 지식에 의존하고 있어 제한된 데이터 하에서 적응성과 일반화에 어려움을 겪습니다.

Method: SignalLLM은 높은 수준의 신호 처리 목표를 구조화된 하위 작업으로 분해하고, 이를 통해 계층적 계획을 수행하며, 다양한 문제 해결 전략을 선택할 수 있는 모듈형 아키텍처를 제공합니다.

Result: SignalLLM은 감지 및 통신과 같은 다섯 가지 대표 작업을 통해 전통적인 방법 및 기존 LLM 기반 방법에 비해 우수한 성능을 나타냈습니다.

Conclusion: 이 프레임워크는 다양한 신호 유형, 작업 유형 및 데이터 조건에 걸쳐 유연한 문제 해결 전략 선택이 가능하여 신호 처리 작업의 일반화 및 자동화에 기여합니다.

Abstract: Modern signal processing (SP) pipelines, whether model-based or data-driven,
often constrained by complex and fragmented workflow, rely heavily on expert
knowledge and manual engineering, and struggle with adaptability and
generalization under limited data. In contrast, Large Language Models (LLMs)
offer strong reasoning capabilities, broad general-purpose knowledge,
in-context learning, and cross-modal transfer abilities, positioning them as
powerful tools for automating and generalizing SP workflows. Motivated by these
potentials, we introduce SignalLLM, the first general-purpose LLM-based agent
framework for general SP tasks. Unlike prior LLM-based SP approaches that are
limited to narrow applications or tricky prompting, SignalLLM introduces a
principled, modular architecture. It decomposes high-level SP goals into
structured subtasks via in-context learning and domain-specific retrieval,
followed by hierarchical planning through adaptive retrieval-augmented
generation (RAG) and refinement; these subtasks are then executed through
prompt-based reasoning, cross-modal reasoning, code synthesis, model
invocation, or data-driven LLM-assisted modeling. Its generalizable design
enables the flexible selection of problem solving strategies across different
signal modalities, task types, and data conditions. We demonstrate the
versatility and effectiveness of SignalLLM through five representative tasks in
communication and sensing, such as radar target detection, human activity
recognition, and text compression. Experimental results show superior
performance over traditional and existing LLM-based methods, particularly in
few-shot and zero-shot settings.

</details>


### [16] [Conditional Policy Generator for Dynamic Constraint Satisfaction and Optimization](https://arxiv.org/abs/2509.17205)
*Wook Lee,Frans A. Oliehoek*

Main category: cs.LG

TL;DR: 이 논문은 동적으로 변화하는 환경에서 제약 만족 및 최적화를 위한 새로운 접근 방식을 제시하며, 기계 학습 방법을 사용하여 독립적인 변수가 있는 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 제약 만족 문제를 해결하는 기계 학습 방법의 효과성을 높이기 위해 동적인 상황에서의 접근 방식이 필요합니다.

Method: 이 작업에서는 강화 학습 문제로 설정하고, 조건부 정책 생성기를 도입하여 정적 및 동적 제약을 모두 포함한 문제를 해결합니다.

Result: 교차모달 제약 만족 문제에 대한 원리 증명 실험을 통해 무조건적 사례와 조건부 사례를 비교했습니다.

Conclusion: 이 새로운 접근 방식은 조건부 정책 생성기를 통해 동적 환경에서 제약 문제를 해결하는 데 효과적임을 입증합니다.

Abstract: Leveraging machine learning methods to solve constraint satisfaction problems
has shown promising, but they are mostly limited to a static situation where
the problem description is completely known and fixed from the beginning. In
this work we present a new approach to constraint satisfaction and optimization
in dynamically changing environments, particularly when variables in the
problem are statistically independent. We frame it as a reinforcement learning
problem and introduce a conditional policy generator by borrowing the idea of
class conditional generative adversarial networks (GANs). Assuming that the
problem includes both static and dynamic constraints, the former are used in a
reward formulation to guide the policy training such that it learns to map to a
probabilistic distribution of solutions satisfying static constraints from a
noise prior, which is similar to a generator in GANs. On the other hand,
dynamic constraints in the problem are encoded to different class labels and
fed with the input noise. The policy is then simultaneously updated for maximum
likelihood of correctly classifying given the dynamic conditions in a
supervised manner. We empirically demonstrate a proof-of-principle experiment
with a multi-modal constraint satisfaction problem and compare between
unconditional and conditional cases.

</details>


### [17] [Causal Representation Learning from Multimodal Clinical Records under Non-Random Modality Missingness](https://arxiv.org/abs/2509.17228)
*Zihan Liang,Ziwen Pan,Ruoxuan Xiong*

Main category: cs.LG

TL;DR: 이 논문에서는 다중 모달 임상 기록에서 관찰된 데이터와 정보가 제공된 결측치를 활용하여 인과적 표현 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 임상 노트는 진단 및 약물과 같은 풍부한 환자 정보를 포함하고 있으며, 이는 환자 표현 학습에 매우 유용합니다. 최근 대형 언어 모델의 발전으로 임상 텍스트에서 의미 있는 표현을 추출하는 능력이 향상되었습니다.

Method: 이 프레임워크는 MMNAR(결측치가 무작위가 아닌 패턴)의 인식을 기반으로 하는 모달리티 융합 구성 요소와 대조적 학습을 통한 모달리티 재구성 구성 요소를 포함하며, 이를 통해 세멘틱 충분성을 보장합니다.

Result: MIMIC-IV와 eICU에 대한 포괄적인 평가에서 강력한 기준선을 넘는 일관된 향상을 보여주었으며, 병원 재입원 예측에서 최대 13.8% AUC 향상과 ICU 입원 예측에서 13.1% 향상을 달성했습니다.

Conclusion: 우리의 접근 방식은 다중 모달 데이터의 정보 부족 문제가 치료에 대한 예측력을 높이는 데 어떻게 기여하는지를 보여줍니다.

Abstract: Clinical notes contain rich patient information, such as diagnoses or
medications, making them valuable for patient representation learning. Recent
advances in large language models have further improved the ability to extract
meaningful representations from clinical texts. However, clinical notes are
often missing. For example, in our analysis of the MIMIC-IV dataset, 24.5% of
patients have no available discharge summaries. In such cases, representations
can be learned from other modalities such as structured data, chest X-rays, or
radiology reports. Yet the availability of these modalities is influenced by
clinical decision-making and varies across patients, resulting in modality
missing-not-at-random (MMNAR) patterns. We propose a causal representation
learning framework that leverages observed data and informative missingness in
multimodal clinical records. It consists of: (1) an MMNAR-aware modality fusion
component that integrates structured data, imaging, and text while conditioning
on missingness patterns to capture patient health and clinician-driven
assignment; (2) a modality reconstruction component with contrastive learning
to ensure semantic sufficiency in representation learning; and (3) a multitask
outcome prediction model with a rectifier that corrects for residual bias from
specific modality observation patterns. Comprehensive evaluations across
MIMIC-IV and eICU show consistent gains over the strongest baselines, achieving
up to 13.8% AUC improvement for hospital readmission and 13.1% for ICU
admission.

</details>


### [18] [Training the next generation of physicians for artificial intelligence-assisted clinical neuroradiology: ASNR MICCAI Brain Tumor Segmentation (BraTS) 2025 Lighthouse Challenge education platform](https://arxiv.org/abs/2509.17281)
*Raisa Amiruddin,Nikolay Y. Yordanov,Nazanin Maleki,Pascal Fehringer,Athanasios Gkampenis,Anastasia Janas,Kiril Krantchev,Ahmed Moawad,Fabian Umeh,Salma Abosabie,Sara Abosabie,Albara Alotaibi,Mohamed Ghonim,Mohanad Ghonim,Sedra Abou Ali Mhana,Nathan Page,Marko Jakovljevic,Yasaman Sharifi,Prisha Bhatia,Amirreza Manteghinejad,Melisa Guelen,Michael Veronesi,Virginia Hill,Tiffany So,Mark Krycia,Bojan Petrovic,Fatima Memon,Justin Cramer,Elizabeth Schrickel,Vilma Kosovic,Lorenna Vidal,Gerard Thompson,Ichiro Ikuta,Basimah Albalooshy,Ali Nabavizadeh,Nourel Hoda Tahon,Karuna Shekdar,Aashim Bhatia,Claudia Kirsch,Gennaro D'Anna,Philipp Lohmann,Amal Saleh Nour,Andriy Myronenko,Adam Goldman-Yassen,Janet R. Reid,Sanjay Aneja,Spyridon Bakas,Mariam Aboian*

Main category: cs.LG

TL;DR: 신경영상 전문가에 의한 고품질 기준 이미지 데이터 생성은 신경영상 학습 및 인공지능 교육에 강력한 도구가 된다. 본 연구에서는 MICCAI 뇌종양 분할 라이트하우스 챌린지 2025의 일환으로 다중 모달 교육 접근 방식을 개발하였다. 56명의 의대생 및 방사선학 수련생이 2023 및 2024년 BraTS 챌린지를 위해 뇌종양 MR 이미지를 주석 달았다.


<details>
  <summary>Details</summary>
Motivation: 신경영상 및 인공지능 교육을 위한 고품질 기준 이미지 데이터의 중요성을 인식하고, 이를 위한 교육적 접근 방식을 개발하고자 한다.

Method: 56명의 의대생과 방사선학 수련생이 교수 주도의 수업을 통해 뇌종양 MR 이미지에 주석을 다는 작업에 자원봉사하였다. 14명의 자원봉사자가 신경영상 교수와 짝을 이루어 개인 주석 세션을 진행하였고, 온라인 강의 및 워크숍이 진행되었다.

Result: 자원봉사자들은 주석 작업 전후로 지식 설문 조사를 실시하였고, 평균적으로 1322.9+/-760.7시간을 데이터 주석 프로세스에 투자하여 총 1200개의 주석을 완료하였다. 주석 코디네이터들은 주석 소프트웨어 및 뇌종양 특징에 대한 친숙도가 유의미하게 증가했음을 보고하였다.

Conclusion: 본 연구는 알고리즘 개발에 대한 이해를 높이고 데이터 기준 표준 개념을 강화하며, 미래 의사들에게 AI 기반 이미지 분석의 기회를 다양화하는 혁신적인 교육 방안을 제시한다.

Abstract: High-quality reference standard image data creation by neuroradiology experts
for automated clinical tools can be a powerful tool for neuroradiology &
artificial intelligence education. We developed a multimodal educational
approach for students and trainees during the MICCAI Brain Tumor Segmentation
Lighthouse Challenge 2025, a landmark initiative to develop accurate brain
tumor segmentation algorithms. Fifty-six medical students & radiology trainees
volunteered to annotate brain tumor MR images for the BraTS challenges of 2023
& 2024, guided by faculty-led didactics on neuropathology MRI. Among the 56
annotators, 14 select volunteers were then paired with neuroradiology faculty
for guided one-on-one annotation sessions for BraTS 2025. Lectures on
neuroanatomy, pathology & AI, journal clubs & data scientist-led workshops were
organized online. Annotators & audience members completed surveys on their
perceived knowledge before & after annotations & lectures respectively.
Fourteen coordinators, each paired with a neuroradiologist, completed the data
annotation process, averaging 1322.9+/-760.7 hours per dataset per pair and
1200 segmentations in total. On a scale of 1-10, annotation coordinators
reported significant increase in familiarity with image segmentation software
pre- and post-annotation, moving from initial average of 6+/-2.9 to final
average of 8.9+/-1.1, and significant increase in familiarity with brain tumor
features pre- and post-annotation, moving from initial average of 6.2+/-2.4 to
final average of 8.1+/-1.2. We demonstrate an innovative offering for providing
neuroradiology & AI education through an image segmentation challenge to
enhance understanding of algorithm development, reinforce the concept of data
reference standard, and diversify opportunities for AI-driven image analysis
among future physicians.

</details>


### [19] [Generalizable End-to-End Tool-Use RL with Synthetic CodeGym](https://arxiv.org/abs/2509.17325)
*Weihua Du,Hailei Gong,Zhan Ling,Kang Liu,Lingfeng Shen,Xuesong Yao,Yufei Xu,Dingyuan Shi,Yiming Yang,Jiecao Chen*

Main category: cs.LG

TL;DR: CodeGym은 다양한 작업을 해결하고 현실 세계와 인터페이스하는 LLM 에이전트를 위한 확장 가능한 훈련 환경을 제공하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 현재 훈련 방식은 정적인 경로에 대한 감독적 미세조정(SFT) 또는 좁은 작업에 대한 강화 학습(RL)에 의존하고 있으며, 새로운 도구 및 보지 않은 작업 흐름에 대해 잘 일반화되지 않는다.

Method: CodeGym은 다양한 도구 사용 환경을 합성하여 LLM 에이전트가 다양한 작업 흐름을 탐색하고 마스터할 수 있도록 리소스를 제공하는 시스템이다.

Result: CodeGym에서 훈련된 여러 크기와 사고 체인을 가진 모델들은 일관된 배포 외 일반화 능력을 보인다. 예를 들어, Qwen2.5-32B-Instruct는 OOD 벤치마크인 $	au$-Bench에서 8.7 포인트의 절대 정확도 향상을 달성하였다.

Conclusion: 이 결과는 CodeGym이 현실 세계 에이전트의 작업 흐름과 일치하는 확장 가능한 일반 목적의 RL 환경을 향한 진전을 강조한다.

Abstract: Tool-augmented large language models (LLMs), hereafter LLM agents, leverage
external tools to solve diverse tasks and interface with the real world.
However, current training practices largely rely on supervised fine-tuning
(SFT) over static trajectories or reinforcement learning (RL) on narrow tasks,
and generalize poorly beyond development settings, leading to brittleness with
new tools and unseen workflows. Because code execution reflects many structures
of real-world workflows, coding problems provide a natural basis for building
agent training environments. Motivated by this, we introduce CodeGym, a
scalable framework that synthesizes diverse, verifiable, and controllable
multi-turn tool-use environments for agent RL, enabling LLM agents to explore
and master various workflows actively. CodeGym rewrites static coding problems
into interactive environments by extracting atomic functions or logic into
callable tools, yielding verifiable tasks that span various tool-execution
workflows. Models of varying sizes and chain-of-thought configurations, trained
in CodeGym, exhibit consistent out-of-distribution generalizability; for
example, Qwen2.5-32B-Instruct achieves an absolute accuracy gain of 8.7 points
on the OOD benchmark $\tau$-Bench. These results highlight CodeGym as a step
toward scalable general-purpose RL environments that align with real-world
agent workflows.

</details>


### [20] [SeqBattNet: A Discrete-State Physics-Informed Neural Network with Aging Adaptation for Battery Modeling](https://arxiv.org/abs/2509.17621)
*Khoa Tran,Hung-Cuong Trinh,Vy-Rin Nguyen,T. Nguyen-Thoi,Vin Nguyen-Thai*

Main category: cs.LG

TL;DR: SeqBattNet이 배터리 모델링을 위한 새로운 방법으로 제안되었으며, 노화 적응이 내장된 이산 상태 물리 정보 신경망(PINN)이다.


<details>
  <summary>Details</summary>
Motivation: 정확한 배터리 모델링은 배터리 관리 시스템에서 잔여 방전 시간과 에너지를 예측하는 데 필수적이다.

Method: SeqBattNet은 주어진 입력 전류에 따라 단자 전압을 예측하는데, HRM-GRU 딥러닝 모듈을 사용한 인코더와 딥러닝과 결합된 등가 회로 모델(ECM)을 기반으로 한 디코더로 구성된다.

Result: SeqBattNet은 단 3개의 기본 배터리 매개변수만으로도 강력한 성능을 발휘하며, 클래식 시퀀스 모델과 PINN 기준선보다 뛰어난 성능을 보인다.

Conclusion: SeqBattNet은 세 개의 벤치마크 데이터셋에서 RMSE를 일관되게 낮추면서도 계산 효율성을 유지한다.

Abstract: Accurate battery modeling is essential for reliable state estimation in
modern applications, such as predicting the remaining discharge time and
remaining discharge energy in battery management systems. Existing approaches
face several limitations: model-based methods require a large number of
parameters; data-driven methods rely heavily on labeled datasets; and current
physics-informed neural networks (PINNs) often lack aging adaptation, or still
depend on many parameters, or continuously regenerate states. In this work, we
propose SeqBattNet, a discrete-state PINN with built-in aging adaptation for
battery modeling, to predict terminal voltage during the discharge process.
SeqBattNet consists of two components: (i) an encoder, implemented as the
proposed HRM-GRU deep learning module, which generates cycle-specific aging
adaptation parameters; and (ii) a decoder, based on the equivalent circuit
model (ECM) combined with deep learning, which uses these parameters together
with the input current to predict voltage. The model requires only three basic
battery parameters and, when trained on data from a single cell, still achieves
robust performance. Extensive evaluations across three benchmark datasets (TRI,
RT-Batt, and NASA) demonstrate that SeqBattNet significantly outperforms
classical sequence models and PINN baselines, achieving consistently lower RMSE
while maintaining computational efficiency.

</details>


### [21] [Comparing Data Assimilation and Likelihood-Based Inference on Latent State Estimation in Agent-Based Models](https://arxiv.org/abs/2509.17625)
*Blas Kolic,Corrado Monti,Gianmarco De Francisci Morales,Marco Pangallo*

Main category: cs.LG

TL;DR: 이 논문은 에이전트 기반 모델에서 데이터 동화(DA)와 우도 기반 추론(LBI)을 체계적으로 비교한 첫 번째 연구이다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 에이전트 기반 모델(ABM)에서 데이터 동화(DA)와 우도 기반 추론(LBI)의 차이를 이해하고 비교하는 것을 목표로 한다.

Method: 두 방법을 잘 알려진 의견 동적 ABM인 Bounded-Confidence Model에서 비교하였다.

Result: LBI는 잠재적인 에이전트 수준의 의견을 더 잘 회복하며 개별 수준의 예측을 개선했다.

Conclusion: DA는 집합적인 예측에 적합하고, LBI는 에이전트 수준 추론에 더 바람직하다.

Abstract: In this paper, we present the first systematic comparison of Data
Assimilation (DA) and Likelihood-Based Inference (LBI) in the context of
Agent-Based Models (ABMs). These models generate observable time series driven
by evolving, partially-latent microstates. Latent states need to be estimated
to align simulations with real-world data -- a task traditionally addressed by
DA, especially in continuous and equation-based models such as those used in
weather forecasting. However, the nature of ABMs poses challenges for standard
DA methods. Solving such issues requires adaptation of previous DA techniques,
or ad-hoc alternatives such as LBI. DA approximates the likelihood in a
model-agnostic way, making it broadly applicable but potentially less precise.
In contrast, LBI provides more accurate state estimation by directly leveraging
the model's likelihood, but at the cost of requiring a hand-crafted,
model-specific likelihood function, which may be complex or infeasible to
derive. We compare the two methods on the Bounded-Confidence Model, a
well-known opinion dynamics ABM, where agents are affected only by others
holding sufficiently similar opinions. We find that LBI better recovers latent
agent-level opinions, even under model mis-specification, leading to improved
individual-level forecasts. At the aggregate level, however, both methods
perform comparably, and DA remains competitive across levels of aggregation
under certain parameter settings. Our findings suggest that DA is well-suited
for aggregate predictions, while LBI is preferable for agent-level inference.

</details>


### [22] [Cluster Workload Allocation: A Predictive Approach Leveraging Machine Learning Efficiency](https://arxiv.org/abs/2509.17695)
*Leszek Sliwko*

Main category: cs.LG

TL;DR: 이 연구는 기계 학습 알고리즘이 노드 친화성 연산자를 감지하여 작업 부하 할당 전략을 지원할 수 있는 방법을 조사한다.


<details>
  <summary>Details</summary>
Motivation: 기계 학습 알고리즘을 사용하여 작업 부하를 보다 효율적으로 할당하기 위함이다.

Method: 실제 Google Cluster Data(GCD) 작업 추적 및 AGOCS 프레임워크를 활용하여 노드 속성과 작업 제약을 추출하고 분석한다.

Result: 최종 앙상블 투표 분류기 모델은 단일 적합 노드를 가진 작업에 대해 98% 정확도를 달성하고 1.5-1.8%의 오분류율을 기록했다.

Conclusion: 이 연구는 ML 알고리즘이 작업 부하 할당에 효과적으로 기여할 수 있음을 시사한다.

Abstract: This research investigates how Machine Learning (ML) algorithms can assist in
workload allocation strategies by detecting tasks with node affinity operators
(referred to as constraint operators), which constrain their execution to a
limited number of nodes. Using real-world Google Cluster Data (GCD) workload
traces and the AGOCS framework, the study extracts node attributes and task
constraints, then analyses them to identify suitable node-task pairings. It
focuses on tasks that can be executed on either a single node or fewer than a
thousand out of 12.5k nodes in the analysed GCD cluster. Task constraint
operators are compacted, pre-processed with one-hot encoding, and used as
features in a training dataset. Various ML classifiers, including Artificial
Neural Networks, K-Nearest Neighbours, Decision Trees, Naive Bayes, Ridge
Regression, Adaptive Boosting, and Bagging, are fine-tuned and assessed for
accuracy and F1-scores. The final ensemble voting classifier model achieved 98%
accuracy and a 1.5-1.8% misclassification rate for tasks with a single suitable
node.

</details>


### [23] [Intra-Cluster Mixup: An Effective Data Augmentation Technique for Complementary-Label Learning](https://arxiv.org/abs/2509.17971)
*Tan-Ha Mai,Hsuan-Tien Lin*

Main category: cs.LG

TL;DR: 본 논문에서는 보완 레이블 학습(CLL)의 도전에 대해 연구하고, Mixup 기법이 CLL에 비효율적임을 발견하며, 이를 개선한 Intra-Cluster Mixup(ICM) 기법을 제안하여 성능을 향상시킴을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 대체 레이블 수집의 비용 효율성을 살펴보기 위해 CLL의 도전 과제를 연구한다.

Method: Intra-Cluster Mixup (ICM) 기법을 제안하여 인접한 예시로부터만 데이터 증강을 수행한다.

Result: ICM을 통해 MNIST에서는 30%, CIFAR에서는 10%의 정확도 향상을 달성하였다.

Conclusion: ICM은 기존 CLL 알고리즘과 결합할 때 상당한 성능 향상을 보여준다.

Abstract: In this paper, we investigate the challenges of complementary-label learning
(CLL), a specialized form of weakly-supervised learning (WSL) where models are
trained with labels indicating classes to which instances do not belong, rather
than standard ordinary labels. This alternative supervision is appealing
because collecting complementary labels is generally cheaper and less
labor-intensive. Although most existing research in CLL emphasizes the
development of novel loss functions, the potential of data augmentation in this
domain remains largely underexplored. In this work, we uncover that the
widely-used Mixup data augmentation technique is ineffective when directly
applied to CLL. Through in-depth analysis, we identify that the
complementary-label noise generated by Mixup negatively impacts the performance
of CLL models. We then propose an improved technique called Intra-Cluster Mixup
(ICM), which only synthesizes augmented data from nearby examples, to mitigate
the noise effect. ICM carries the benefits of encouraging complementary label
sharing of nearby examples, and leads to substantial performance improvements
across synthetic and real-world labeled datasets. In particular, our wide
spectrum of experimental results on both balanced and imbalanced CLL settings
justifies the potential of ICM in allying with state-of-the-art CLL algorithms,
achieving significant accuracy increases of 30% and 10% on MNIST and CIFAR
datasets, respectively.

</details>


### [24] [Unveiling m-Sharpness Through the Structure of Stochastic Gradient Noise](https://arxiv.org/abs/2509.18001)
*Haocheng Luo,Mehrtash Harandi,Dinh Phung,Trung Le*

Main category: cs.LG

TL;DR: Sharpness-aware minimization(SAM)는 모델 일반화를 개선하는 데 매우 효과적인 기술로 떠올랐지만, 그 원리는 완전히 이해되지 않았다. 본 논문에서는 perturbations을 계산하기 위한 마이크로 배치 크기가 감소함에 따라 SAM의 성능이 단조롭게 향상되는 m-sharpness 현상을 조사하였다.


<details>
  <summary>Details</summary>
Motivation: 모델 일반화를 개선하는 SAM 기술의 원리에 대한 이해 부족.

Method: 확장된 확률적 미분 방정식(SDE) 프레임워크와 확률적 경량 잡음(SGN) 구조 분석을 활용하여 다양한 SAM 변형의 동태를 정확하게 특성화했다.

Result: SAM perturbations 도중에 도입되는 확률적 잡음이 본래 분산 기반의 샤프니스 정규화 효과를 유도하는 것으로 나타났다.

Conclusion: 이론적 통찰을 바탕으로, m-SAM의 일반화 이점을 모방하면서도 병렬성을 유지하는 샤프니스 가중 샘플링을 사용하는 Reweighted SAM을 도입하였다. 포괄적 실험은 이론 분석과 제안된 방법의 효과를 검증하였다.

Abstract: Sharpness-aware minimization (SAM) has emerged as a highly effective
technique for improving model generalization, but its underlying principles are
not fully understood. We investigated the phenomenon known as m-sharpness,
where the performance of SAM improves monotonically as the micro-batch size for
computing perturbations decreases. Leveraging an extended Stochastic
Differential Equation (SDE) framework, combined with an analysis of the
structure of stochastic gradient noise (SGN), we precisely characterize the
dynamics of various SAM variants. Our findings reveal that the stochastic noise
introduced during SAM perturbations inherently induces a variance-based
sharpness regularization effect. Motivated by our theoretical insights, we
introduce Reweighted SAM, which employs sharpness-weighted sampling to mimic
the generalization benefits of m-SAM while remaining parallelizable.
Comprehensive experiments validate the effectiveness of our theoretical
analysis and proposed method.

</details>


### [25] [Reinforced Generation of Combinatorial Structures: Applications to Complexity Theory](https://arxiv.org/abs/2509.18057)
*Ansh Nagda,Prabhakar Raghavan,Abhradeep Thakurta*

Main category: cs.LG

TL;DR: 이 논문에서는 AI 기법이 효율적인 알고리즘의 한계를 개선하는 새로운 조합 구조를 발견하는 데 도움이 되는지를 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: AI 기법이 효율적인 알고리즘의 한계를 개선하는 새로운 조합 구조를 발견하는 데 도움을 줄 수 있는지 탐구하기 위해.

Method: AlphaEvolve라는 LLM 코딩 에이전트를 사용하여 MAX-CUT 및 MAX-Independent Set의 평균 사례 난이도를 연구하고, MAX-k-CUT에 대한 최악의 경우 근사 난이도를 분석합니다.

Result: 무작위 3- 및 4-정규 그래프에 대한 MAX-CUT 및 MAX-Independent Set에 대한 인증 알고리즘의 거의 최적 상한과 (조건부) 하한을 개선했습니다.

Conclusion: AI의 도움을 받아 증명 개발을 평가할 수 있는 기준에 대한 논의로 결론을 맺습니다.

Abstract: We explore whether techniques from AI can help discover new combinatorial
structures that improve on known limits on efficient algorithms. Specifically,
we use AlphaEvolve (an LLM coding agent) to study two settings:
  a) Average-case hardness for MAX-CUT and MAX-Independent Set: We improve a
recent result of Kunisky and Yu to obtain near-optimal upper and (conditional)
lower bounds on certification algorithms for MAX-CUT and MAX-Independent Set on
random 3- and 4-regular graphs. Our improved lower bounds are obtained by
constructing nearly extremal Ramanujan graphs on as many as $163$ nodes, using
AlphaEvolve. Additionally, via analytical arguments we strengthen the upper
bounds to settle the computational hardness of these questions up to an error
in the third decimal place.
  b) Worst-case Hardness of Approximation for MAX-k-CUT: We obtain new
inapproximability results, proving that it is NP-hard to approximate MAX-4-CUT
and MAX-3-CUT within factors of $0.987$ and $0.9649$ respectively, using
AlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improves
upon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the current
best gadget-based inapproximability result of $0.9853$, but falls short of
improving the SOTA of $16/17$ that relies on a custom PCP, rather than a gadget
reduction from "standard" H{\aa}stad-style PCPs.
  A key technical challenge we faced: verifying a candidate construction
produced by AlphaEvolve is costly (often requiring exponential time). In both
settings above, our results were enabled by using AlphaEvolve itself to evolve
the verification procedure to be faster (sometimes by $10,000\times$). We
conclude with a discussion of norms by which to assess the assistance from AI
in developing proofs.

</details>


### [26] [Learning functions, operators and dynamical systems with kernels](https://arxiv.org/abs/2509.18071)
*Lorenzo Rosasco*

Main category: cs.LG

TL;DR: 통계적 기계 학습을 위한 접근 방식을 설명하는 논문으로, 스칼라 값 학습과 연산자 학습을 위한 기본 프레임워크를 소개하고, 동적 시스템 학습을 위한 적합한 연산자 학습 문제로 공식화한다.


<details>
  <summary>Details</summary>
Motivation: 통계적 기계 학습에 대한 새로운 접근 방식을 이해하고 적용하기 위해.

Method: 재생 커널 힐버트 공간을 기반으로 한 스칼라 값 및 연산자 학습에 대한 기본 프레임워크를 제시하고, 쿠프만 연산자 이론을 활용하여 동적 시스템 학습을 모델링한다.

Result: 스칼라 값으로부터 연산자 학습으로의 확장을 성공적으로 보여준다.

Conclusion: 이 연구는 통계적 기계 학습 이론에 대한 기여와 CIME 학교에서 제공되는 관련 강의 자료를 수집하여 제공한다.

Abstract: This expository article presents the approach to statistical machine learning
based on reproducing kernel Hilbert spaces. The basic framework is introduced
for scalar-valued learning and then extended to operator learning. Finally,
learning dynamical systems is formulated as a suitable operator learning
problem, leveraging Koopman operator theory. The manuscript collects the
supporting material for the corresponding course taught at the CIME school
"Machine Learning: From Data to Mathematical Understanding" in Cetraro.

</details>


### [27] [Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding](https://arxiv.org/abs/2509.18085)
*Sudhanshu Agrawal,Risheek Garrepalli,Raghavv Goel,Mingu Lee,Christopher Lott,Fatih Porikli*

Main category: cs.LG

TL;DR: Spiffy라는 새로운 예측 디코딩 알고리즘을 제안하여, dLLM의 추론 속도를 2.8~3.1배 향상시키면서도 품질을 유지한다.


<details>
  <summary>Details</summary>
Motivation: dLLM의 높은 토큰 생성 속도를 활용하되, 품질 저하 없이 효율적으로 디코딩하는 방법이 필요하다.

Method: dLLM의 분포를 자동적으로 활용하는 방식으로 초안 상태를 제안하고, 이를 위한 방향성 초안 그래프를 설계하며, 오프라인 교정 알고리즘을 통해 최적화된 그래프 구성을 결정한다.

Result: Spiffy는 dLLM 추론 속도를 2.8~3.1배 향상시키며, KV-캐싱 및 멀티 토큰 언마스킹과 같은 기존의 혁신들과 결합하여 최대 7.9배의 전체 속도 향상을 달성한다.

Conclusion: Spiffy는 dLLM의 추론 속도를 개선할 뿐만 아니라, 기존 방법들과의 결합을 통해 성능을 극대화할 수 있는 혁신적인 접근법이다.

Abstract: Diffusion LLMs (dLLMs) have recently emerged as a powerful alternative to
autoregressive LLMs (AR-LLMs) with the potential to operate at significantly
higher token generation rates. However, currently available open-source dLLMs
often generate at much lower rates, typically decoding only a single token at
every denoising timestep in order to maximize output quality. We present
Spiffy, a speculative decoding algorithm that accelerates dLLM inference by
$\mathbf{2.8{-}3.1\times}$ while provably preserving the model's output
distribution. This work addresses the unique challenges involved in applying
ideas from speculative decoding of AR-LLMs to the dLLM setting. Spiffy proposes
draft states by leveraging the dLLM's distribution itself in an
auto-speculative manner. This approach is efficient and effective, and
eliminates the overheads of training and running an independent draft model. To
structure the candidate draft states, we propose a novel directed draft graph
which is uniquely designed to take advantage of the bidirectional, block-wise
nature of dLLM generation and can be verified in parallel by the dLLM. To
further optimize the structure of these draft graphs, we introduce an
efficient, offline calibration algorithm that procedurally determines
high-quality graph configurations. These optimized draft graphs, enabling
increased acceptance rates, lead to a significant boost in the overall speedup
achieved by the system. Crucially, Spiffy is also complementary to other recent
innovations in improving dLLM generation speeds such as KV-caching and
multi-token unmasking. We demonstrate that when combined with such parallel
decoding algorithms, Spiffy is able to effectively multiply the benefits of
these methods leading to total speedups of up to $\mathbf{7.9\times}$.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [28] [Generalizability of Large Language Model-Based Agents: A Comprehensive Survey](https://arxiv.org/abs/2509.16330)
*Minxing Zhang,Yi Yang,Roy Xie,Bhuwan Dhingra,Shuyan Zhou,Jian Pei*

Main category: cs.AI

TL;DR: 이 논문은 LLM 기반 에이전트의 일반화 가능성에 대한 종합적인 리뷰를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트의 일반화 가능성을 보장하는 것이 중요합니다.

Method: LLM 기반 에이전트의 일반화 가능성에 대한 데이터셋, 평가 차원 및 메트릭스를 검토하고, 일반화 가능성을 향상시키기 위한 방법을 세 그룹으로 분류합니다.

Result: 에이전트 일반화 가능성의 중요성을 강조하고, 한층 더 적합한 데이터와 기술적 접근 방식을 정리합니다.

Conclusion: LLM 기반 에이전트가 다양한 애플리케이션에서 신뢰성 있게 일반화될 수 있도록 연구의 기초를 마련하고자 합니다.

Abstract: Large Language Model (LLM)-based agents have emerged as a new paradigm that
extends LLMs' capabilities beyond text generation to dynamic interaction with
external environments. By integrating reasoning with perception, memory, and
tool use, agents are increasingly deployed in diverse domains like web
navigation and household robotics. A critical challenge, however, lies in
ensuring agent generalizability - the ability to maintain consistent
performance across varied instructions, tasks, environments, and domains,
especially those beyond agents' fine-tuning data. Despite growing interest, the
concept of generalizability in LLM-based agents remains underdefined, and
systematic approaches to measure and improve it are lacking. In this survey, we
provide the first comprehensive review of generalizability in LLM-based agents.
We begin by emphasizing agent generalizability's importance by appealing to
stakeholders and clarifying the boundaries of agent generalizability by
situating it within a hierarchical domain-task ontology. We then review
datasets, evaluation dimensions, and metrics, highlighting their limitations.
Next, we categorize methods for improving generalizability into three groups:
methods for the backbone LLM, for agent components, and for their interactions.
Moreover, we introduce the distinction between generalizable frameworks and
generalizable agents and outline how generalizable frameworks can be translated
into agent-level generalizability. Finally, we identify critical challenges and
future directions, including developing standardized frameworks, variance- and
cost-based metrics, and approaches that integrate methodological innovations
with architecture-level designs. By synthesizing progress and highlighting
opportunities, this survey aims to establish a foundation for principled
research on building LLM-based agents that generalize reliably across diverse
applications.

</details>


### [29] [Zero-Shot Human Mobility Forecasting via Large Language Model with Hierarchical Reasoning](https://arxiv.org/abs/2509.16578)
*Wenyao Li,Ran Zhang,Pengyang Wang,Yuanchun Zhou,Pengfei Wang*

Main category: cs.AI

TL;DR: ZHMF는 제로샷 인간 이동 예측 프레임워크로, 의미 강화 검색 및 반영 메커니즘을 계층적 언어 모델 기반 추론 시스템과 결합하여 인간 이동 예측의 성능을 향상시키는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 인간 이동 예측은 교통 계획, 도시 관리 및 개인화된 추천과 같은 응용 분야에서 중요하다.

Method: ZHMF는 의미 강화 검색과 계층적 언어 모델을 기반으로 하는 반영 메커니즘을 결합하여 자연어 질문 답변 패러다임으로 재구성된다.

Result: 실험 결과, 우리의 접근 방식이 기존 모델보다 우수한 성능을 보여준다.

Conclusion: 각 모듈의 기여도를 밝혀내고, 사례 연구를 통해 사용자 의도를 포착하고 다양한 상황에 적응하는 방법을 시연한다.

Abstract: Human mobility forecasting is important for applications such as
transportation planning, urban management, and personalized recommendations.
However, existing methods often fail to generalize to unseen users or locations
and struggle to capture dynamic intent due to limited labeled data and the
complexity of mobility patterns. We propose ZHMF, a framework for zero-shot
human mobility forecasting that combines a semantic enhanced retrieval and
reflection mechanism with a hierarchical language model based reasoning system.
The task is reformulated as a natural language question answering paradigm.
Leveraging LLMs semantic understanding of user histories and context, our
approach handles previously unseen prediction scenarios. We further introduce a
hierarchical reflection mechanism for iterative reasoning and refinement by
decomposing forecasting into an activity level planner and a location level
selector, enabling collaborative modeling of long term user intentions and
short term contextual preferences. Experiments on standard human mobility
datasets show that our approach outperforms existing models. Ablation studies
reveal the contribution of each module, and case studies illustrate how the
method captures user intentions and adapts to diverse contextual scenarios.

</details>


### [30] [Prompt-Driven Agentic Video Editing System: Autonomous Comprehension of Long-Form, Story-Driven Media](https://arxiv.org/abs/2509.16811)
*Zihan Ding,Junlong Chen,Per Ola Kristensson,Junxiao Shen,Xinyi Wang*

Main category: cs.AI

TL;DR: 이 논문은 크리에이터들이 긴 비디오를 보다 효과적으로 편집할 수 있도록 지원하는 모듈식 편집 시스템을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 크리에이터들은 사용자 인터페이스의 복잡성 때문이 아니라, 긴 비디오의 촬영을 감상하고 서사적 구조를 짜는 데 드는 인지적 부담 때문에 편집에 어려움을 겪고 있습니다.

Method: 사용자들이 프리폼 프롬프트를 이용해 멀티 시간 콘텐츠를 재구성할 수 있도록 돕는 프롬프트 기반 모듈식 편집 시스템을 개발했습니다. 이 시스템은 의미론적 인덱싱 파이프라인을 중심으로 하여, 시간적 분할, 가이드 메모리 압축 및 교차 세분화 융합을 통해 글로벌 내러티브를 구축합니다.

Result: 400개 이상의 비디오를 평가한 결과, 우리의 시스템은 프롬프트 기반 편집을 확장하고 서사적 일관성을 유지하며 크리에이터의 제어와 자동화 간의 균형을 이룹니다.

Conclusion: 우리의 시스템은 전문 평가 및 선호도 연구를 통해 입증되었으며, 사용자에게 편리한 중간 출력을 제공하면서도 달리기를 통해 영화 편집을 가능하게 합니다.

Abstract: Creators struggle to edit long-form, narrative-rich videos not because of UI
complexity, but due to the cognitive demands of searching, storyboarding, and
sequencing hours of footage. Existing transcript- or embedding-based methods
fall short for creative workflows, as models struggle to track characters,
infer motivations, and connect dispersed events. We present a prompt-driven,
modular editing system that helps creators restructure multi-hour content
through free-form prompts rather than timelines. At its core is a semantic
indexing pipeline that builds a global narrative via temporal segmentation,
guided memory compression, and cross-granularity fusion, producing
interpretable traces of plot, dialogue, emotion, and context. Users receive
cinematic edits while optionally refining transparent intermediate outputs.
Evaluated on 400+ videos with expert ratings, QA, and preference studies, our
system scales prompt-driven editing, preserves narrative coherence, and
balances automation with creator control.

</details>


### [31] [Roundtable Policy: Improving Scientific Reasoning and Narratives through Confidence-Weighted Consensus of LLMs](https://arxiv.org/abs/2509.16839)
*Yu Yao,Jiayi Dong,Ju Li,Yang Yang,Yilun Du*

Main category: cs.AI

TL;DR: 라지 언어 모델(LLM)이 언어 생성 및 과학 발견에서 뛰어난 성능을 보이고 있으며, 다수의 LLM의 가중 합의를 통해 추론을 수행하는 새로운 프레임워크인 Roundtable Policy를 도입했다.


<details>
  <summary>Details</summary>
Motivation: LLM의 추론 능력을 향상시키기 위한 다양한 접근 방식이 연구되고 있다.

Method: 다수의 LLM의 가중된 합의를 통해 추론을 수행하는 Roundtable Policy 프레임워크를 제안한다.

Result: 이 접근 방식이 복잡한 과학적 과업에서 추론을 크게 향상시키고, 창의성, 엄밀성, 논리적 일관성 측면에서 과학적 내러티브를 개선하며, 단일 모델이 취약한 환각 현상을 줄인다는 것을 발견했다.

Conclusion: 구조화되고 해석 가능한 합의를 강조하며, 불투명한 수렴 대신 블랙박스 접근 및 일관된 절차만으로 적용 가능함을 보여준다.

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities not
only in language generation but also in advancing scientific discovery. A
growing body of work has explored ways to improve their reasoning, from
self-consistency and chain-of-thought to multi-agent debate. Inspired by the
dynamics of scientific committees and the "Society of Mind," we introduce
Roundtable Policy, a complementary inference-time reasoning framework that
performs inference through the weighted consensus of multiple LLMs. Our
findings indicate that this approach significantly enhances reasoning in
complex heterogeneous scientific tasks and improves scientific narratives in
terms of creativity, rigor, and logical coherence, while reducing
hallucinations that single models are prone to. Our approach emphasizes
structured and interpretable consensus rather than opaque convergence, while
requiring only black-box access and uniform procedures, making it broadly
applicable to multi-LLM reasoning.

</details>


### [32] [seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs](https://arxiv.org/abs/2509.16866)
*Mohammad Ramezanali,Mo Vazifeh,Paolo Santi*

Main category: cs.AI

TL;DR: seqBench는 대형 언어 모델의 연속적 추론 한계를 조사하기 위한 매개변수화된 벤치마크로, 여러 주요 복잡성 차원에 대한 정밀하고 다차원적인 조절을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 연속적 추론 능력의 한계를 이해하고, 기존 벤치마크와의 차별성을 통해 보다 나은 분석을 시도하기 위함이다.

Method: seqBench는 논리적 깊이, 최적 경로를 따라 되돌아가기 단계 수, 그리고 환경에 대한 사실의 비율을 조절하여 측정 가능한 복잡성 차원을 정의하고 평가한다.

Result: 최신 LLM에 대한 평가에서 정확도가 모델 특정 논리적 깊이를 넘어서는 지수적 붕괴 패턴을 보이고, 구조적 추론 작업에서 주요 성능 모델조차도 체계적으로 실패한다는 것을 발견하였다.

Conclusion: seqBench 데이터세트는 대형 언어 모델의 추론 능력을 더 깊이 조사할 수 있도록 공개되어, 그 진정한 잠재력과 현재의 한계를 명확히 이해할 수 있는 목표를 가지고 있다.

Abstract: We introduce seqBench, a parametrized benchmark for probing sequential
reasoning limits in Large Language Models (LLMs) through precise,
multi-dimensional control over several key complexity dimensions. seqBench
allows systematic variation of (1) the logical depth, defined as the number of
sequential actions required to solve the task; (2) the number of backtracking
steps along the optimal path, quantifying how often the agent must revisit
prior states to satisfy deferred preconditions (e.g., retrieving a key after
encountering a locked door); and (3) the noise ratio, defined as the ratio
between supporting and distracting facts about the environment. Our evaluations
on state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses
exponentially beyond a model-specific logical depth. Unlike existing
benchmarks, seqBench's fine-grained control facilitates targeted analyses of
these reasoning failures, illuminating universal scaling laws and statistical
limits, as detailed in this paper alongside its generation methodology and
evaluation metrics. We find that even top-performing models systematically fail
on seqBench's structured reasoning tasks despite minimal search complexity,
underscoring key limitations in their commonsense reasoning capabilities.
Designed for future evolution to keep pace with advancing models, the seqBench
datasets are publicly released to spur deeper scientific inquiry into LLM
reasoning, aiming to establish a clearer understanding of their true potential
and current boundaries for robust real-world application.

</details>


### [33] [LLMs as Layout Designers: A Spatial Reasoning Perspective](https://arxiv.org/abs/2509.16891)
*Sha Li*

Main category: cs.AI

TL;DR: LaySPA는 대형 언어 모델의 공간 이해 능력을 향상시키기 위한 강화 학습 기반 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델은 복잡한 과제에 대한 지시에 효과적으로 따를 수 있지만, 공간 이해 및 추론 능력은 제한적이다. 이는 콘텐츠 인식 그래픽 레이아웃 디자인과 같은 애플리케이션에 필수적이다.

Method: LaySPA는 명시적인 공간 추론 능력을 가진 LLM 에이전트를 증강하기 위해 혼합 보상 신호를 활용하는 강화 학습 기반 프레임워크이다.

Result: LaySPA는 구조적으로 건전하고 시각적으로 매력적인 레이아웃을 생성하며, 일반적인 대형 LLM보다 우수한 성능을 보인다.

Conclusion: LaySPA는 최신 특수 레이아웃 모델과 동등한 성과를 달성한다.

Abstract: While Large Language Models (LLMs) have demonstrated impressive reasoning and
planning abilities in textual domains and can effectively follow instructions
for complex tasks, their capacity for spatial understanding and reasoning
remains limited. Such capabilities, however, are critical for applications like
content-aware graphic layout design, which demands precise placement,
alignment, and structural organization of multiple elements within constrained
visual spaces. To address this gap, we propose LaySPA, a reinforcement
learning-based framework that augments LLM agents with explicit spatial
reasoning capabilities. LaySPA leverages hybrid reward signals that capture
geometric validity, structural fidelity, and visual quality, enabling agents to
model inter-element relationships, navigate the canvas, and optimize spatial
arrangements. Through iterative self-exploration and adaptive policy
optimization, LaySPA produces both interpretable reasoning traces and
structured layouts. Experimental results demonstrate that LaySPA generates
structurally sound and visually appealing layouts, outperforming larger
general-purpose LLMs and achieving results on par with state-of-the-art
specialized layout models.

</details>


### [34] [Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation](https://arxiv.org/abs/2509.16924)
*Jia Li,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng*

Main category: cs.AI

TL;DR: 본 연구는 오디오-비주얼 내비게이션(AVN) 과제를 위한 강화 학습 기반 프레임워크를 제안하며, 스테레오 오디오의 공간 정보를 활용하여 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 3D 환경에서 소리의 위치를 자율적으로 탐지하는 능력은 시청각 신호에 의존하는 에이전트에게 필수적입니다.

Method: 본 연구는 스테레오 정보와 오디오 신호를 기반으로 한 주의 메커니즘 및 동적 통합 모듈을 포함하는 end-to-end 강화 학습 기반 AVN 프레임워크를 제안합니다.

Result: 우리의 방법은 내비게이션 성공률과 경로 효율성 측면에서 기존 접근 방식을 현저히 초과하며, 오디오 전용 조건에서 40% 이상의 향상을 보여줍니다.

Conclusion: 스테레오 채널의 공간 정보를 모델링하고, 효율적인 다중 모달 융합을 수행하는 것이 AVN의 강인함과 효율성을 확보하는 데 중요함을 강조합니다.

Abstract: In audio-visual navigation (AVN) tasks, an embodied agent must autonomously
localize a sound source in unknown and complex 3D environments based on
audio-visual signals. Existing methods often rely on static modality fusion
strategies and neglect the spatial cues embedded in stereo audio, leading to
performance degradation in cluttered or occluded scenes. To address these
issues, we propose an end-to-end reinforcement learning-based AVN framework
with two key innovations: (1) a \textbf{S}tereo-Aware \textbf{A}ttention
\textbf{M}odule (\textbf{SAM}), which learns and exploits the spatial disparity
between left and right audio channels to enhance directional sound perception;
and (2) an \textbf{A}udio-\textbf{G}uided \textbf{D}ynamic \textbf{F}usion
Module (\textbf{AGDF}), which dynamically adjusts the fusion ratio between
visual and auditory features based on audio cues, thereby improving robustness
to environmental changes. Extensive experiments are conducted on two realistic
3D scene datasets, Replica and Matterport3D, demonstrating that our method
significantly outperforms existing approaches in terms of navigation success
rate and path efficiency. Notably, our model achieves over 40\% improvement
under audio-only conditions compared to the best-performing baselines. These
results highlight the importance of explicitly modeling spatial cues from
stereo channels and performing deep multi-modal fusion for robust and efficient
audio-visual navigation.

</details>


### [35] [RALLM-POI: Retrieval-Augmented LLM for Zero-shot Next POI Recommendation with Geographical Reranking](https://arxiv.org/abs/2509.17066)
*Kunrong Li,Kwan Hui Lim*

Main category: cs.AI

TL;DR: RALLM-POI는 LLM과 검색 보조 생성 및 자기 수정(Self-rectification)을 결합한 모델로, POI 추천의 정확도를 높인다.


<details>
  <summary>Details</summary>
Motivation: 사용자의 다음 목적지를 예측하는 POI 추천은 역사적 이동 데이터를 기반으로 하지만 전통적인 모델은 많은 훈련이 필요하다.

Method: RALLM-POI는 과거의 관련 경로를 검색하는 Historical Trajectory Retriever (HTR)와 지리적 관련성을 우선시하는 Geographical Distance Reranker (GDR)를 사용하여 경로를 재순위화하고, 자기 반성을 통해 출력을 정제하는 Agentic LLM Rectifier (ALR)를 설계한다.

Result: 추가 훈련 없이도 RALLM-POI는 세 개의 실제 Foursquare 데이터셋에서 상당한 정확도 향상을 달성하고, 전통적인 모델 및 LLM 기반 기준보다 우수한 성능을 보인다.

Conclusion: 코드는 https://github.com/LKRcrocodile/RALLM-POI에 공개되었다.

Abstract: Next point-of-interest (POI) recommendation predicts a user's next
destination from historical movements. Traditional models require intensive
training, while LLMs offer flexible and generalizable zero-shot solutions but
often generate generic or geographically irrelevant results due to missing
trajectory and spatial context. To address these issues, we propose RALLM-POI,
a framework that couples LLMs with retrieval-augmented generation and
self-rectification. We first propose a Historical Trajectory Retriever (HTR)
that retrieves relevant past trajectories to serve as contextual references,
which are then reranked by a Geographical Distance Reranker (GDR) for
prioritizing spatially relevant trajectories. Lastly, an Agentic LLM Rectifier
(ALR) is designed to refine outputs through self-reflection. Without additional
training, RALLM-POI achieves substantial accuracy gains across three real-world
Foursquare datasets, outperforming both conventional and LLM-based baselines.
Code is released at https://github.com/LKRcrocodile/RALLM-POI.

</details>


### [36] [Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System](https://arxiv.org/abs/2509.17240)
*Abdullah Mushtaq,Muhammad Rafay Naeem,Ibrahim Ghaznavi,Alaa Abd-alrazaq,Aliya Tabassum,Junaid Qadir*

Main category: cs.AI

TL;DR: 본 논문에서는 시스템 문헌 검토(SLR)를 평가하기 위한 LLM 기반의 코파일럿을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: SLR은 증거 기반 연구에 필수적이지만, 시간과 노력을 많이 소모하고 일관성이 부족합니다.

Method: Multi-Agent System (MAS) 아키텍처를 기반으로 하는 LLM을 활용하여 프로토콜 검증, 방법론 평가 및 주제 관련성 검사를 자동화합니다.

Result: 5개의 다양한 분야의 SLR을 대상으로 초기 연구를 수행한 결과, 시스템 출력과 전문가 주석의 PRISMA 점수 간에 84% 일치를 관찰했습니다.

Conclusion: 초기 결과는 유망하지만, 이 연구는 학제간 작업 흐름을 위해 확장 가능하고 정확한 NLP 기반 시스템을 향한 첫 번째 단계로, 검토 과정을 간소화하기 위한 지식 집합의 엄격한 구축 능력을 보여줍니다.

Abstract: Systematic Literature Reviews (SLRs) are foundational to evidence-based
research but remain labor-intensive and prone to inconsistency across
disciplines. We present an LLM-based SLR evaluation copilot built on a
Multi-Agent System (MAS) architecture to assist researchers in assessing the
overall quality of the systematic literature reviews. The system automates
protocol validation, methodological assessment, and topic relevance checks
using a scholarly database. Unlike conventional single-agent methods, our
design integrates a specialized agentic approach aligned with PRISMA guidelines
to support more structured and interpretable evaluations. We conducted an
initial study on five published SLRs from diverse domains, comparing system
outputs to expert-annotated PRISMA scores, and observed 84% agreement. While
early results are promising, this work represents a first step toward scalable
and accurate NLP-driven systems for interdisciplinary workflows and reveals
their capacity for rigorous, domain-agnostic knowledge aggregation to
streamline the review process.

</details>


### [37] [Intention-aware Hierarchical Diffusion Model for Long-term Trajectory Anomaly Detection](https://arxiv.org/abs/2509.17068)
*Chen Wang,Sarah Erfani,Tansu Alpcan,Christopher Leckie*

Main category: cs.AI

TL;DR: 이 논문은 고수준 의도 평가와 저수준 서브 궤적 분석을 통해 이상 탐지를 수행하는 IHiD 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 장기 궤적 이상 탐지는 궤적 데이터의 다양성과 복잡한 시공간 의존성으로 인한 도전적인 문제이다.

Method: IHiD 모델은 고수준 의도 평가와 저수준 서브 궤적 분석을 통해 이상 탐지를 수행한다.

Result: 제안된 IHiD 방법은 기존 최첨단 모델보다 F1 점수 기준으로 최대 30.2%의 이상 탐지 성능 향상을 달성했다.

Conclusion: 이 연구는 다양한 정상 궤적 분포를 포착하도록 설계된 IHiD 모델의 효과를 입증하였다.

Abstract: Long-term trajectory anomaly detection is a challenging problem due to the
diversity and complex spatiotemporal dependencies in trajectory data. Existing
trajectory anomaly detection methods fail to simultaneously consider both the
high-level intentions of agents as well as the low-level details of the agent's
navigation when analysing an agent's trajectories. This limits their ability to
capture the full diversity of normal trajectories. In this paper, we propose an
unsupervised trajectory anomaly detection method named Intention-aware
Hierarchical Diffusion model (IHiD), which detects anomalies through both
high-level intent evaluation and low-level sub-trajectory analysis. Our
approach leverages Inverse Q Learning as the high-level model to assess whether
a selected subgoal aligns with an agent's intention based on predicted
Q-values. Meanwhile, a diffusion model serves as the low-level model to
generate sub-trajectories conditioned on subgoal information, with anomaly
detection based on reconstruction error. By integrating both models, IHiD
effectively utilises subgoal transition knowledge and is designed to capture
the diverse distribution of normal trajectories. Our experiments show that the
proposed method IHiD achieves up to 30.2% improvement in anomaly detection
performance in terms of F1 score over state-of-the-art baselines.

</details>


### [38] [MCTS-EP: Empowering Embodied Planning with Online Preference Optimization](https://arxiv.org/abs/2509.17116)
*Hang Xu,Zang Yu,Yehui Tang,Pengbo Hu,Yuhao Tang,Hao Dong*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델과 몬테카를로 트리 검색을 결합한 온라인 학습 프레임워크인 MCTS-EP를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: MCTS-EP는 체현된 에이전트를 훈련하기 위해 대형 언어 모델과 몬테카를로 트리 검색을 결합합니다.

Method: MCTS-EP는 세 가지 주요 구성 요소로 통합됩니다: 선호 데이터 수집을 위한 MCTS 기반 탐색, 효율적인 다중 모드 추론 메커니즘, 선호 최적화를 기반으로 한 반복 훈련 파이프라인입니다.

Result: MCTS-EP는 손실 함수가 강하게 볼록할 때 기존의 온-정책 알고리즘보다 더 나은 성능 경계를 달성한다는 것을 이론적으로 증명하고, GAIL의 검색 강화 변형으로 공식화될 수 있음을 보여줍니다. 여러 벤치마크에서 최첨단 성능을 달성하였으며, ALFWorld에서는 텍스트 및 시각적 작업에 대해 각각 92% 및 87%의 성공률을 달성했습니다. WebShop에서는 평균 보상을 0.81에 도달시켰습니다.

Conclusion: MCTS-EP는 ALFWorld 시각적 작업에서 평균 상호작용 단계를 18.7/19.5에서 10.2/9.9 단계로 줄입니다.

Abstract: This paper introduces MCTS-EP, an online learning framework that combines
large language models (LLM) with Monte Carlo Tree Search (MCTS) for training
embodied agents. MCTS-EP integrates three key components: MCTS-guided
exploration for preference data collection, efficient multi-modal reasoning
mechanism, and iterative training pipeline based on preference optimization. We
theoretically prove that MCTS-EP achieves better performance bounds than
conventional on-policy algorithms when the loss function is strongly convex,
and demonstrate that it can be formulated as a search-enhanced variant of GAIL.
MCTS-EP achieves state-of-the-art performace across serval benchmarks. In
ALFWorld, it achieves 92% and 87% success rates for textual and visual tasks.
In WebShop, it reaches an average reward of 0.81. MTCS-EP also reduces average
interaction steps from from 18.7/19.5 to 10.2/9.9 steps in visual ALFWorld.Code
available at: https://github.com/xuhang-2/Embodied-Agent-Planning

</details>


### [39] [ARE: Scaling Up Agent Environments and Evaluations](https://arxiv.org/abs/2509.17158)
*Pierre Andrews,Amine Benhalloum,Gerard Moreno-Torres Bertran,Matteo Bettini,Amar Budhiraja,Ricardo Silveira Cabral,Virginie Do,Romain Froger,Emilien Garreau,Jean-Baptiste Gaya,Hugo Laurençon,Maxime Lecanu,Kunal Malkan,Dheeraj Mekala,Pierre Ménard,Grégoire Mialon,Ulyana Piterbarg,Mikhail Plekhanov,Mathieu Rita,Andrey Rusakov,Thomas Scialom,Vladislav Vorotilov,Mengjue Wang,Ian Yu*

Main category: cs.AI

TL;DR: Meta Agents Research Environments (ARE)는 환경을 확장 가능하게 생성하고, 합성 또는 실제 애플리케이션을 통합하며, 에이전트 오케스트레이션을 실행하기 위한 플랫폼입니다.


<details>
  <summary>Details</summary>
Motivation: ARE는 모델 개발과 실제 세계 배포 사이의 격차를 줄이는 데 도움을 주기 위해 복잡하고 다양한 환경을 구축하기 위한 간단한 추상화를 제공합니다.

Method: Gaia2라는 벤치마크를 제안하며, 이는 다양한 에이전트의 일반적인 능력을 측정하는 데 설계되었습니다.

Result: Gaia2는 에이전트가 모호성과 잡음을 처리하고, 동적 환경에 적응하며, 다른 에이전트와 협력하고, 시간 제약 하에서 작동해야하는 과제를 요구합니다.

Conclusion: ARE의 추상화는 Gaia2를 다른 환경으로 계속 확장할 수 있게 하여 커뮤니티가 그들의 분야에 맞는 새로운 벤치마크를 신속하게 생성할 수 있도록 합니다.

Abstract: We introduce Meta Agents Research Environments (ARE), a research platform for
scalable creation of environments, integration of synthetic or real
applications, and execution of agentic orchestrations. ARE provides simple
abstractions to build complex and diverse environments, each with their own
rules, tools, content, and verifiers, helping to bridge the gap between model
development and real-world deployment. We also propose Gaia2, a benchmark built
in ARE and designed to measure general agent capabilities. Beyond search and
execution, Gaia2 requires agents to handle ambiguities and noise, adapt to
dynamic environments, collaborate with other agents, and operate under temporal
constraints. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new
failure modes that are invisible in static settings. Our experiments show that
no system dominates across the intelligence spectrum: stronger reasoning often
comes at the cost of efficiency, and budget scaling curves plateau,
highlighting the need for new architectures and adaptive compute strategies.
Perhaps more importantly, ARE abstractions enable continuous extension of Gaia2
to other environments, empowering the community to rapidly create new
benchmarks tailored to their domains. In AI's second half, progress
increasingly depends on defining meaningful tasks and robust evaluations to
drive frontier capabilities forward.

</details>


### [40] [Mind the Gap: Comparing Model- vs Agentic-Level Red Teaming with Action-Graph Observability on GPT-OSS-20B](https://arxiv.org/abs/2509.17259)
*Ilham Wicaksono,Zekun Wu,Rahul Patel,Theo King,Adriano Koshiyama,Philip Treleaven*

Main category: cs.AI

TL;DR: 에이전틱 AI 시스템의 고유한 취약점을 이해하는 것이 중요해졌다. 본 논문은 GPT-OSS-20B라는 20억 매개변수를 가진 오픈 소스 모델에 대한 비교적 레드팀 분석을 통해 모델 수준의 보안 결함이 에이전틱 배치의 위험을 완전히 포착하지 못한다는 점을 연구한다.


<details>
  <summary>Details</summary>
Motivation: 산업에서 에이전틱 AI 시스템이 점점 더 많이 채택됨에 따라, 이 시스템들의 고유한 취약점을 이해하는 것이 중요해졌다.

Method: AgentSeer라는 관측 프레임워크를 사용하여 에이전틱 시스템을 세분화된 행동 및 구성 요소로 분해하고, 두 가지 수준에서 해로운 목표를 가진 반복적인 레드팀 공격을 적용하였다: 독립 모델과 에이전틱 루프 내에서 작동하는 모델이다.

Result: 모델 수준과 에이전틱 수준 취약성 프로파일 간의 기본적인 차이를 밝혀냈고, 에이전틱 실행 문맥 내에서만 발생하는 에이전틱 전용 취약점과 전환할 경우 성공적인 목표 달성 실패를 포함하여 발견하였다.

Conclusion: 독립 모델의 취약점은 항상 배포된 시스템에 일반화되지 않으며, 일부 모델 전용 공격은 모델 수준에서만 작동하고 에이전틱 문맥으로 전이될 경우 실패한다.

Abstract: As the industry increasingly adopts agentic AI systems, understanding their
unique vulnerabilities becomes critical. Prior research suggests that security
flaws at the model level do not fully capture the risks present in agentic
deployments, where models interact with tools and external environments. This
paper investigates this gap by conducting a comparative red teaming analysis of
GPT-OSS-20B, a 20-billion parameter open-source model. Using our observability
framework AgentSeer to deconstruct agentic systems into granular actions and
components, we apply iterative red teaming attacks with harmful objectives from
HarmBench at two distinct levels: the standalone model and the model operating
within an agentic loop. Our evaluation reveals fundamental differences between
model level and agentic level vulnerability profiles. Critically, we discover
the existence of agentic-only vulnerabilities, attack vectors that emerge
exclusively within agentic execution contexts while remaining inert against
standalone models. Agentic level iterative attacks successfully compromise
objectives that completely failed at the model level, with tool-calling
contexts showing 24\% higher vulnerability than non-tool contexts. Conversely,
certain model-specific exploits work exclusively at the model level and fail
when transferred to agentic contexts, demonstrating that standalone model
vulnerabilities do not always generalize to deployed systems.

</details>


### [41] [Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation](https://arxiv.org/abs/2509.17353)
*Ahmed T. Elboardy,Ghada Khoriba,Essam A. Rashed*

Main category: cs.AI

TL;DR: 이 논문은 방사선 보고서 생성을 자동화하기 위한 다중 에이전트 강화 학습 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 방사선 보고서 생성을 자동화하는 데 있어 임상 신뢰성을 확보하고 엄격한 평가 프로토콜을 설계하는 것이 고난도의 도전 과제가 됩니다.

Method: 10개의 전문 에이전트로 구성된 모듈형 아키텍처 내에서 대형 언어 모델과 대형 비전 모델을 통합한 다중 에이전트 강화 학습 프레임워크를 제안합니다.

Result: 공공 방사선 데이터 세트를 사용하여 chatGPT-4o를 구현하며, LLM이 의학 방사선 전문의 피드백과 함께 평가자로 작용합니다.

Conclusion: 제안된 벤치마크는 신뢰할 수 있는 편차 기반 방사선 보고서 생성을 향한 경로를 설정합니다.

Abstract: Automating radiology report generation poses a dual challenge: building
clinically reliable systems and designing rigorous evaluation protocols. We
introduce a multi-agent reinforcement learning framework that serves as both a
benchmark and evaluation environment for multimodal clinical reasoning in the
radiology ecosystem. The proposed framework integrates large language models
(LLMs) and large vision models (LVMs) within a modular architecture composed of
ten specialized agents responsible for image analysis, feature extraction,
report generation, review, and evaluation. This design enables fine-grained
assessment at both the agent level (e.g., detection and segmentation accuracy)
and the consensus level (e.g., report quality and clinical relevance). We
demonstrate an implementation using chatGPT-4o on public radiology datasets,
where LLMs act as evaluators alongside medical radiologist feedback. By
aligning evaluation protocols with the LLM development lifecycle, including
pretraining, finetuning, alignment, and deployment, the proposed benchmark
establishes a path toward trustworthy deviance-based radiology report
generation.

</details>


### [42] [Correlation or Causation: Analyzing the Causal Structures of LLM and LRM Reasoning Process](https://arxiv.org/abs/2509.17380)
*Zhizhang FU,Guangsheng Bao,Hongbo Zhang,Chenkai Hu,Yue Zhang*

Main category: cs.AI

TL;DR: 이 연구는 LLM과 LRM의 구조적 인과 모델을 분석하여 RLVR 훈련이 인과적 추론 능력을 향상시킨다는 점을 밝혀냄.


<details>
  <summary>Details</summary>
Motivation: LLM이 신뢰성, 편향 및 일관성 문제를 드러내면서 인과 관계에 대한 이해 부족을 보이는 상황에서, 보다 나은 인과적 추론을 위해 LRMs가 대안으로 떠오르고 있다.

Method: 본 연구에서는 문제 지침, 사고 과정, 추론 단계, 답변의 4개 핵심 변수를 갖는 구조적 인과 모델(SCM)을 사용하여 LLM과 LRM을 분석하였다.

Result: RLVR 훈련된 LRM이 인과적 추론 능력을 향상시켜 이상적인 인과 구조와 더 밀접하게 연결되며, LLM과 디스틸된 LRM은 인과성과 관련된 문제를 해결하지 못함.

Conclusion: 이 연구는 인과성을 이해하는 데 기여하고 RLVR의 중요성을 강조하며, 강력한 인과적 기초를 가진 미래 AI 시스템 설계에 대한 통찰을 제공한다.

Abstract: LLMs suffer from critical reasoning issues such as unfaithfulness, bias, and
inconsistency, since they lack robust causal underpinnings and may rely on
superficial correlations rather than genuine understanding. Successive LRMs
have emerged as a promising alternative, leveraging advanced training
techniques such as reinforcement learning (RL) and distillation to improve task
accuracy. However, the impact of these training methods on causality remains
largely unexplored. In this study, we conduct a systematic causal analysis on
LLMs and LRMs, examining structural causal models (SCMs) of four key variables:
problem instruction (Z), thinking process (T), reasoning steps (X), and answer
(Y). Our findings reveal that RLVR-trained LRMs exhibit enhanced causal
reasoning capabilities, aligning more closely with ideal causal structures,
while LLMs and distilled LRMs fail to address causality-related deficiencies.
Our further investigation indicates that RLVR reduces spurious correlations and
strengthens genuine causal patterns, thereby mitigating unfaithfulness and
bias. In addition, our inspection on the dynamics of the RLVR training process
observes a high correlation between reduced spurious features and improved
causal structures, where the causal relationships consistently improve in the
training process. This study contributes to the understanding of causality in
reasoning models, highlights the critical role of RLVR in enhancing causal
reasoning, and provides insights for designing future AI systems with stronger
causal foundations. We release our code and data at
https://github.com/Harryking1999/CoT_Causal_Analysis.

</details>


### [43] [Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments](https://arxiv.org/abs/2509.17425)
*Zhenliang Zhang,Yuxi Wang,Hongzhao Xie,Shiyun Zhao,Mingyuan Liu,Yujie Lu,Xinyi He,Zhenku Cheng,Yujia Peng*

Main category: cs.AI

TL;DR: AGI는 다양한 기능을 필요로 하는 복합 작업을 수행할 수 있지만, 현재의 MLLM 기반 에이전트는 이러한 작업에서 부족한 성능을 보이고 있다.


<details>
  <summary>Details</summary>
Motivation: AGI와 전통적인 AI의 주요 차별점은 AGI가 다양한 능력을 요구하는 복합 작업을 수행할 수 있다는 점이다.

Method: 일상적인 활동에서 영감을 받은 복합 작업을 설계하고, 이를 동적인 가상 홈 환경 내에서 수행하였다.

Result: 17개의 MLLM들을 평가한 결과, 모든 영역에서 일관되게 낮은 성능을 보였다.

Conclusion: 우리의 작업은 구현된 에이전트의 일반적인 능력을 평가하기 위한 초기 프레임워크를 제공하며, MLLM의 발전 및 실제 배치에 중요한 첫걸음을 내딛었다.

Abstract: A key feature differentiating artificial general intelligence (AGI) from
traditional AI is that AGI can perform composite tasks that require a wide
range of capabilities. Although embodied agents powered by multimodal large
language models (MLLMs) offer rich perceptual and interactive capabilities, it
remains largely unexplored whether they can solve composite tasks. In the
current work, we designed a set of composite tasks inspired by common daily
activities observed in early childhood development. Within a dynamic and
simulated home environment, these tasks span three core domains: object
understanding, spatial intelligence, and social activity. We evaluated 17
leading proprietary and open-source MLLMs on these tasks. The results
consistently showed poor performance across all three domains, indicating a
substantial gap between current capabilities and general intelligence
requirements. Together, our tasks offer a preliminary framework for evaluating
the general capabilities of embodied agents, marking an early but significant
step toward the development of embodied MLLMs and their real-world deployment.

</details>


### [44] [LIMI: Less is More for Agency](https://arxiv.org/abs/2509.17567)
*Yang Xiao,Mohan Jiang,Jie Sun,Keyu Li,Jifan Lin,Yumin Zhuang,Ji Zeng,Shijie Xia,Qishuo Hua,Xuefeng Li,Xiaojie Cai,Tongyu Wang,Yue Zhang,Liming Liu,Xia Wu,Jinlong Hou,Yuan Cheng,Wenjie Li,Xiang Wang,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: AI 시스템의 자율성을 높이기 위한 새로운 접근방식을 제시하며, 데이터 양보다 전략적으로 선별된 최소의 학습 샘플로도 높은 성능을 달성할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 단순히 사고하는 것을 넘어 작업을 수행하고 실제 세계의 결과를 이끌어내는 자율적인 에이전트가 필요하다는 산업적 필요.

Method: LIMI(지능형 에이전시를 위한 더 적을수록 더 많은 방법)는 최소한의 학습 샘플로 agentic intelligence를 발전시키는 방법론을 제시하며, 협업 소프트웨어 개발 및 과학적 연구 워크플로우에 중점을 둔 전략적인 접근을 따른다.

Result: LIMI는 78개의 정밀하게 설계된 학습 샘플을 사용하여 종합적인 에이전시 벤치마크에서 73.5%의 성과를 달성하며, 이는 최신 모델들보다 현저히 더 우수한 결과이다.

Conclusion: 기계 자율성은 데이터의 양이 아니라 고품질의 agentic 시연을 전략적으로 선별하여 만들어진다는 에이전시 효율성 원리를 정립하였다.

Abstract: We define Agency as the emergent capacity of AI systems to function as
autonomous agents actively discovering problems, formulating hypotheses, and
executing solutions through self-directed engagement with environments and
tools. This fundamental capability marks the dawn of the Age of AI Agency,
driven by a critical industry shift: the urgent need for AI systems that don't
just think, but work. While current AI excels at reasoning and generating
responses, industries demand autonomous agents that can execute tasks, operate
tools, and drive real-world outcomes. As agentic intelligence becomes the
defining characteristic separating cognitive systems from productive workers,
efficiently cultivating machine autonomy becomes paramount. Current approaches
assume that more data yields better agency, following traditional scaling laws
from language modeling. We fundamentally challenge this paradigm. LIMI (Less Is
More for Intelligent Agency) demonstrates that agency follows radically
different development principles. Through strategic focus on collaborative
software development and scientific research workflows, we show that
sophisticated agentic intelligence can emerge from minimal but strategically
curated demonstrations of autonomous behavior. Using only 78 carefully designed
training samples, LIMI achieves 73.5% on comprehensive agency benchmarks,
dramatically outperforming state-of-the-art models: Kimi-K2-Instruct (24.1%),
DeepSeek-V3.1 (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%).
Most strikingly, LIMI demonstrates 53.7% improvement over models trained on
10,000 samples-achieving superior agentic intelligence with 128 times fewer
samples. Our findings establish the Agency Efficiency Principle: machine
autonomy emerges not from data abundance but from strategic curation of
high-quality agentic demonstrations.

</details>


### [45] [MEF: A Systematic Evaluation Framework for Text-to-Image Models](https://arxiv.org/abs/2509.17907)
*Xiaojing Dong,Weilin Huang,Liang Li,Yiying Li,Shu Liu,Tongtong Ou,Shuang Ouyang,Yu Tian,Fengxuan Zhao*

Main category: cs.AI

TL;DR: T2I 모델 평가를 위한 Magic Evaluation Framework (MEF)를 소개하며, 사용자 시나리오와 기능을 반영한 평가 방법론을 제안함.


<details>
  <summary>Details</summary>
Motivation: T2I 생성의 급속한 발전으로 평가 방법론에 대한 요구가 증가하고 있음.

Method: 사용자 시나리오, 요소 및 텍스트 표현 형태를 포함한 구조화된 분류 체계를 통해 Magic-Bench-377을 구축하고, ELO와 차원별 MOS를 결합하여 모델 순위를 매김.

Result: MEF를 통해 T2I 모델에 대한 리더보드 및 주요 특성을 도출함.

Conclusion: 평가 프레임워크와 Magic-Bench-377을 공개하여 시각적 생성 모델 평가 연구를 촉진함.

Abstract: Rapid advances in text-to-image (T2I) generation have raised higher
requirements for evaluation methodologies. Existing benchmarks center on
objective capabilities and dimensions, but lack an application-scenario
perspective, limiting external validity. Moreover, current evaluations
typically rely on either ELO for overall ranking or MOS for dimension-specific
scoring, yet both methods have inherent shortcomings and limited
interpretability. Therefore, we introduce the Magic Evaluation Framework (MEF),
a systematic and practical approach for evaluating T2I models. First, we
propose a structured taxonomy encompassing user scenarios, elements, element
compositions, and text expression forms to construct the Magic-Bench-377, which
supports label-level assessment and ensures a balanced coverage of both user
scenarios and capabilities. On this basis, we combine ELO and
dimension-specific MOS to generate model rankings and fine-grained assessments
respectively. This joint evaluation method further enables us to quantitatively
analyze the contribution of each dimension to user satisfaction using
multivariate logistic regression. By applying MEF to current T2I models, we
obtain a leaderboard and key characteristics of the leading models. We release
our evaluation framework and make Magic-Bench-377 fully open-source to advance
research in the evaluation of visual generative models.

</details>


### [46] [Orcust: Stepwise-Feedback Reinforcement Learning for GUI Agent](https://arxiv.org/abs/2509.17917)
*Junyu Lu,Songxin Zhang,Zejian Xie,Zhuoyang Song,Jiaxing Zhang*

Main category: cs.AI

TL;DR: Orcust는 원칙 제약 보상 모델링(PCRM)과 온라인 VM-기반 경로 구성(OVTC)을 통합하여 GUI 에이전트의 추론 신뢰성과 데이터 효율성을 향상시키는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 모델들이 신뢰할 수 없는 보상 신호와 제한된 온라인 경로 생성으로 어려움을 겪고 있어, 이를 개선할 필요가 있다.

Method: Orcust는 환경 검증 가능하고 LLM에서 유도된 원칙을 사용하여 해석 가능한 보상 신호를 생성하고, OVTC를 통해 자율적으로 구조화된 GUI 상호작용 경로를 수집한다.

Result: Orcust는 표준 GUI 벤치마크에서 기존 모델보다 ScreenSpot에서 22.2%, ScreenSpot-Pro에서 23.9% 개선된 성능을 보였다.

Conclusion: Orcust는 다양한 환경과 작업 복잡성에서 GUI 에이전트의 추론, 적응성 및 확장성을 향상시키는 데 효과적이다.

Abstract: Recent advances in GUI agents have achieved remarkable grounding and
action-prediction performance, yet existing models struggle with unreliable
reward signals and limited online trajectory generation. In this paper, we
introduce Orcust, a framework that integrates Principle-Constrained Reward
Modeling (PCRM) and Online VM-Grounded Trajectory Construction (OVTC) to
enhance reasoning reliability and data efficiency in interactive GUI tasks. We
leverages environment-verifiable and LLM-derived principle to enforce
interpretable reward signals that constrain long chain-of-thought reasoning and
rule-based feedback. OVTC spins up instrumented virtual machines to
autonomously collect structured GUI interaction trajectories with explicit
procedural and structural objectives, enabling the training of a stepwise
reward model that robustly captures human preferences and adheres to
task-specific constraints. Extensive experiments on standard GUI benchmarks
covering perceptual grounding, foundational operations, and end-to-end task
execution reveal that Orcust achieves state-of-the-art performance, improving
by 22.2\% on ScreenSpot and 23.9\% on ScreenSpot-Pro over the base model (i.e.
Qwen2.5-VL-7B). The results demonstrate Orcust's effectiveness in enhancing the
reasoning, adaptability and scalability of GUI agents across various
environments and task complexities.

</details>


### [47] [On the Variational Costs of Changing Our Minds](https://arxiv.org/abs/2509.17957)
*David Hyland,Mahault Albarracin*

Main category: cs.AI

TL;DR: 이 논문은 인간의 믿음 갱신 메커니즘에 대한 비용의 영향을 모델링하는 정식 프레임워크를 소개하며, 확인 편향 및 태도 양극화와 같은 공통적인 인간 행동을 질적으로 모방할 수 있음을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 인간의 마음은 뛰어난 성과를 가져오지만, 종종 자기 자신에 맞서 일하는 것처럼 보입니다. 우리는 그런 '편향'이 인지적 결함이 아니라, 믿음을 수정하는 데 따른 실용적 및 인지적 비용에 대한 적응적 반응이라고 주장합니다.

Method: 믿음의 갱신을 동기화된 변이 결정으로 처리하고, 신념의 '효용'을 새로운 신념 상태를 채택하는 데 필요한 정보적 비용과 비교합니다. 이는 이전 상태에서 변이 후 상태까지의 Kullback-Leibler 발산으로 정량화됩니다.

Result: 이 자원-합리적 모델의 단순 인스턴스가 확인 편향 및 태도 양극화와 같은 일반적인 인간 행동을 질적으로 모방할 수 있음을 보여줍니다.

Conclusion: 이 프레임워크는 동기화된 베이지안 신념 변화의 역학에 대한 보다 전체적인 설명을 향해 나아가며, desired belief updating process에서의 편차를 예측하고 보상하며 수정하는 데 실용적인 통찰을 제공합니다.

Abstract: The human mind is capable of extraordinary achievements, yet it often appears
to work against itself. It actively defends its cherished beliefs even in the
face of contradictory evidence, conveniently interprets information to conform
to desired narratives, and selectively searches for or avoids information to
suit its various purposes. Despite these behaviours deviating from common
normative standards for belief updating, we argue that such 'biases' are not
inherently cognitive flaws, but rather an adaptive response to the significant
pragmatic and cognitive costs associated with revising one's beliefs. This
paper introduces a formal framework that aims to model the influence of these
costs on our belief updating mechanisms.
  We treat belief updating as a motivated variational decision, where agents
weigh the perceived 'utility' of a belief against the informational cost
required to adopt a new belief state, quantified by the Kullback-Leibler
divergence from the prior to the variational posterior. We perform
computational experiments to demonstrate that simple instantiations of this
resource-rational model can be used to qualitatively emulate commonplace human
behaviours, including confirmation bias and attitude polarisation. In doing so,
we suggest that this framework makes steps toward a more holistic account of
the motivated Bayesian mechanics of belief change and provides practical
insights for predicting, compensating for, and correcting deviations from
desired belief updating processes.

</details>


### [48] [The STAR-XAI Protocol: An Interactive Framework for Inducing Second-Order Agency in AI Agents](https://arxiv.org/abs/2509.17978)
*Antoni Guasch,Maria Isabel Valdez*

Main category: cs.AI

TL;DR: STAR-XAI 프로토콜은 신뢰할 수 있는 AI 에이전트를 훈련하고 운영하기 위한 새로운 방법론으로, 인간-AI 상호작용을 구조화된 소크라테스식 대화로 재구성하여 문제 해결 과정을 강화한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 대형 추론 모델은 고난이도 및 장기적 작업에서 신뢰성과 투명성에서 큰 한계를 보이며, 이를 해결하기 위해 새로운 방법론이 필요하다.

Method: STAR-XAI 프로토콜은 구조화된 소크라테스식 대화로 인간-AI 상호작용을 재구성하며, 명시적이고 진화하는 규칙집인 CTP에 의해 관리된다. 이 과정에서 전략적 정당화 및 오류 축적 방지를 위한 메커니즘이 포함된다.

Result: 이 방법론은 복잡한 전략 게임 'Caps i Caps'에서 25단계의 사례 연구를 통해 높은 복잡도의 퍼즐을 해결하고, 자신의 계획의 결 flaws를 식별하며 작업 중 핵심 무결성 프로토콜을 조정하는 2차 대리성을 보여주었다.

Conclusion: STAR-XAI 프로토콜은 성능이 높을 뿐 아니라 설계상 투명하고 감사 가능하며 신뢰할 수 있는 AI 에이전트를 생성하는 실용적인 경로를 제공한다.

Abstract: Current Large Reasoning Models (LRMs) exhibit significant limitations in
reliability and transparency, often showing a collapse in reasoning
capabilities when faced with high-complexity, long-horizon tasks. This
"illusion of thinking" is frequently an artifact of non-agentic, black-box
evaluation paradigms that fail to cultivate robust problem-solving processes.
In response, we introduce The STAR-XAI Protocol (Socratic, Transparent,
Agentic, Reasoning - for eXplainable Artificial Intelligence), a novel
methodology for training and operating verifiably reliable AI agents. Our
method reframes the human-AI interaction as a structured, Socratic dialogue,
governed by an explicit and evolving rulebook, the Consciousness Transfer
Package (CTP). Through an interactive Gameplay Cycle that enforces ante-hoc
strategic justification and a state-locking Checksum that prevents error
accumulation, the protocol transforms a powerful but opaque LRM into a
disciplined "Clear Box" agent. We demonstrate the efficacy of this method
through an exhaustive 25-move case study in the complex strategic game "Caps i
Caps". The agent not only solved the high-complexity puzzle but also
demonstrated Second-Order Agency, identifying flaws in its own
supervisor-approved plans and adapting its core integrity protocols mid-task.
The STAR-XAI Protocol offers a practical pathway to creating AI agents that are
not just high-performing, but also transparent, auditable, and trustworthy by
design.

</details>


### [49] [Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates](https://arxiv.org/abs/2509.18076)
*Hy Dang,Tianyi Liu,Zhuofeng Wu,Jingfeng Yang,Haoming Jiang,Tao Yang,Pei Chen,Zhengyang Wang,Helen Wang,Huasheng Li,Bing Yin,Meng Jiang*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델이 도구 상호작용에서의 오류를 줄이기 위해 단계별 지침을 활용한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 실세계 도구 상호작용에서 자주 실패하는 이유는 사용자 목표에 대한 불완전한 이해와 도구 문서에 대한 부족한 이해에서 비롯된다.

Method: 구조화된 추론 템플릿을 활용하여 LLM이 기능 호출 생성을 위한 단계별 지침을 따르도록 안내하는 커리큘럼 기반 프레임워크를 제안한다.

Result: 우리의 방법은 도구 사용 오류를 줄이며 다양한 모델 시리즈와 접근법에서 강력한 기준선보다 3-12%의 상대적 개선을 달성한다.

Conclusion: 이 프레임워크는 도구 사용 에이전트의 강건성, 해석 가능성 및 투명성을 향상시켜 실세계 응용 프로그램을 위한 보다 신뢰할 수 있는 AI 보조기술의 발전에 기여한다.

Abstract: Large language models (LLMs) have demonstrated strong reasoning and tool-use
capabilities, yet they often fail in real-world tool-interactions due to
incorrect parameterization, poor tool selection, or misinterpretation of user
intent. These issues often stem from an incomplete understanding of user goals
and inadequate comprehension of tool documentation. While Chain-of-Thought
(CoT) prompting has proven effective for enhancing reasoning in general
contexts, our analysis reveals that free-form CoT is insufficient and sometimes
counterproductive for structured function-calling tasks. To address this, we
introduce a curriculum-inspired framework that leverages structured reasoning
templates to guide LLMs through more deliberate step-by-step instructions for
generating function callings. Experimental results show that our method reduces
tool-use errors, achieving 3-12% relative improvements over strong baselines
across diverse model series and approaches. Moreover, our framework enhances
the robustness, interpretability, and transparency of tool-using agents,
advancing the development of more reliable AI assistants for real-world
applications.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [50] [SecureFixAgent: A Hybrid LLM Agent for Automated Python Static Vulnerability Repair](https://arxiv.org/abs/2509.16275)
*Jugal Gajjar,Kamalasankari Subramaniakuppusamy,Relsy Puthal,Kaustik Ranaware*

Main category: cs.CR

TL;DR: SecureFixAgent는 Bandit과 경량 로컬 LLM을 결합한 하이브리드 수리 프레임워크로, 정적 분석 도구의 한계를 극복하고 취약점을 효과적으로 수정하는 자동화된 솔루션이다.


<details>
  <summary>Details</summary>
Motivation: 대규모 코드베이스를 보호하는 데 있어 정적 분석 도구의 한계를 극복하고, LLM의 수리 제안 기능을 반영하기 위해.

Method: SecureFixAgent는 Bandit을 활용한 탐지, LLM을 통한 설명이 포함된 후보 수리 제안, 그리고 Bandit 재검증을 포함한 반복적 탐지-수리-검증 루프를 사용한다.

Result: 실험 결과, SecureFixAgent는 정적 분석에 비해 허위 긍정률을 10.8% 줄이고, 수리 정확도를 13.51% 향상시켰으며, 사전 훈련된 LLM에 비해 허위 긍정률을 5.46% 낮추었다.

Conclusion: SecureFixAgent는 신뢰할 수 있는 보안 개선과 투명한 이유를 결합하여 현대 파이프라인을 위한 자동화된 취약점 수정 솔루션을 발전시킨다.

Abstract: Modern software development pipelines face growing challenges in securing
large codebases with extensive dependencies. Static analysis tools like Bandit
are effective at vulnerability detection but suffer from high false positives
and lack repair capabilities. Large Language Models (LLMs), in contrast, can
suggest fixes but often hallucinate changes and lack self-validation. We
present SecureFixAgent, a hybrid repair framework integrating Bandit with
lightweight local LLMs (<8B parameters) in an iterative detect-repair-validate
loop. To improve precision, we apply parameter-efficient LoRA-based fine-tuning
on a diverse, curated dataset spanning multiple Python project domains,
mitigating dataset bias and reducing unnecessary edits. SecureFixAgent uses
Bandit for detection, the LLM for candidate fixes with explanations, and Bandit
re-validation for verification, all executed locally to preserve privacy and
reduce cloud reliance. Experiments show SecureFixAgent reduces false positives
by 10.8% over static analysis, improves fix accuracy by 13.51%, and lowers
false positives by 5.46% compared to pre-trained LLMs, typically converging
within three iterations. Beyond metrics, developer studies rate explanation
quality 4.5/5, highlighting its value for human trust and adoption. By
combining verifiable security improvements with transparent rationale in a
resource-efficient local framework, SecureFixAgent advances trustworthy,
automated vulnerability remediation for modern pipelines.

</details>


### [51] [Decoding TRON: A Comprehensive Framework for Large-Scale Blockchain Data Extraction and Exploration](https://arxiv.org/abs/2509.16292)
*Qian'ang Mao,Jiaxin Wang,Zhiqi Feng,Yi Zhang,Jiaqi Yan*

Main category: cs.CR

TL;DR: 이 논문은 TRON 블록체인의 데이터 분석을 위한 포괄적인 데이터 추출 및 탐색 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: TRON 블록체인에서의 온체인 데이터 분석 연구가 부족한 상황을 해소하고자 한다.

Method: 혁신적인 고성능 ETL 시스템을 통해 TRON의 블록, 거래, 스마트 계약 및 영수증을 포함한 원시 온체인 데이터를 효율적으로 추출한다.

Result: 추출된 데이터셋의 심층 분석을 통해 TRON의 블록 생성, 거래 동향 및 USDT 스테이블코인의 중심적 역할에 대한 통찰을 제공한다.

Conclusion: 이 데이터셋을 활용한 미래 연구 기회에 대해 논의하며 블록체인 데이터 관리 능력과 TRON 생태계의 발전을 이해한다.

Abstract: Cryptocurrencies and Web3 applications based on blockchain technology have
flourished in the blockchain research field. Unlike Bitcoin and Ethereum, due
to its unique architectural designs in consensus mechanisms, resource
management, and throughput, TRON has developed a more distinctive ecosystem and
application scenarios centered around stablecoins. Although it is popular in
areas like stablecoin payments and settlement, research on analyzing on-chain
data from the TRON blockchain is remarkably scarce. To fill this gap, this
paper proposes a comprehensive data extraction and exploration framework for
the TRON blockchain. An innovative high-performance ETL system aims to
efficiently extract raw on-chain data from TRON, including blocks,
transactions, smart contracts, and receipts, establishing a research dataset.
An in-depth analysis of the extracted dataset reveals insights into TRON's
block generation, transaction trends, the dominance of exchanges, the resource
delegation market, smart contract usage patterns, and the central role of the
USDT stablecoin. The prominence of gambling applications and potential illicit
activities related to USDT is emphasized. The paper discusses opportunities for
future research leveraging this dataset, including analysis of delegate
services, gambling scenarios, stablecoin activities, and illicit transaction
detection. These contributions enhance blockchain data management capabilities
and understanding of the rapidly evolving TRON ecosystem.

</details>


### [52] [LiteRSan: Lightweight Memory Safety Via Rust-specific Program Analysis and Selective Instrumentation](https://arxiv.org/abs/2509.16389)
*Tianrou Xia,Kaiming Huang,Dongyeon Yu,Yuseok Jeon,Jie Zhou,Dinghao Wu,Taegyu Kim*

Main category: cs.CR

TL;DR: LiteRSan은 Rust의 고유한 소유권 모델을 활용하여 메모리 안전성을 보장하는 새로운 샌타이저이다.


<details>
  <summary>Details</summary>
Motivation: Rust는 메모리 안전성이 보장된 언어이지만, 불안전한 코드를 허용하여 메모리 취약점이 발생할 수 있다. 기존 방법(ASan, ERASan, RustSan)은 성능과 메모리 오버헤드가 크고 많은 메모리 안전성 취약점을 탐지하지 못한다.

Method: LiteRSan은 Rust의 소유권 모델을 활용하여 포인터 수명을 인식하는 Rust 전용 정적 분석을 수행하여 위험한 포인터를 식별하고, 선택적으로 메모리 안전성 검사를 적용한다.

Result: LiteRSan은 기존 ASan 기반 샌타이저와 비교할 때 실행 시간 오버헤드가 18.84%로 낮고, 메모리 오버헤드는 0.81%로 매우 적다.

Conclusion: LiteRSan은 이전 기술이 놓친 메모리 안전성 버그를 탐지할 수 있는 능력을 갖추고 있다.

Abstract: Rust is a memory-safe language, and its strong safety guarantees combined
with high performance have been attracting widespread adoption in systems
programming and security-critical applications. However, Rust permits the use
of unsafe code, which bypasses compiler-enforced safety checks and can
introduce memory vulnerabilities. A widely adopted approach for detecting
memory safety bugs in Rust is Address Sanitizer (ASan). Optimized versions,
such as ERASan and RustSan, have been proposed to selectively apply security
checks in order to reduce performance overhead. However, these tools still
incur significant performance and memory overhead and fail to detect many
classes of memory safety vulnerabilities due to the inherent limitations of
ASan. In this paper, we present LiteRSan, a novel memory safety sanitizer that
addresses the limitations of prior approaches. By leveraging Rust's unique
ownership model, LiteRSan performs Rust-specific static analysis that is aware
of pointer lifetimes to identify risky pointers. It then selectively
instruments risky pointers to enforce only the necessary spatial or temporal
memory safety checks. Consequently, LiteRSan introduces significantly lower
runtime overhead (18.84% versus 152.05% and 183.50%) and negligible memory
overhead (0.81% versus 739.27% and 861.98%) compared with existing ASan-based
sanitizers while being capable of detecting memory safety bugs that prior
techniques miss.

</details>


### [53] [LenslessMic: Audio Encryption and Authentication via Lensless Computational Imaging](https://arxiv.org/abs/2509.16418)
*Petr Grinberg,Eric Bezzam,Paolo Prandoni,Martin Vetterli*

Main category: cs.CR

TL;DR: 이 논문은 다양한 오디오 유형에 적용 가능한 렌즈 없는 카메라를 이용한 하이브리드 광학 하드웨어 기반 암호화 방법인 LenslessMic를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 데이터 공유에 대한 사회의 의존도가 증가함에 따라 민감한 정보 보호가 중요해지고 있다.

Method: LenslessMic는 렌즈 없는 카메라를 사용하여 물리적 보안 계층을 제공하는 하이브리드 광학 하드웨어 기반 암호화 방법이다.

Result: LenslessMic는 오디오 녹음의 강력한 인증과 256비트 디지털 표준의 검색 공간에 필적할 수 있는 암호화 강도를 제공하며, 고품질 신호와 최소한의 콘텐츠 정보 손실을 유지한다.

Conclusion: 이 접근은 저비용 Raspberry Pi 프로토타입으로 검증되어 있으며, 관련 연구를 촉진하기 위해 데이터 세트와 함께 오픈 소스로 제공된다.

Abstract: With society's increasing reliance on digital data sharing, the protection of
sensitive information has become critical. Encryption serves as one of the
privacy-preserving methods; however, its realization in the audio domain
predominantly relies on signal processing or software methods embedded into
hardware. In this paper, we introduce LenslessMic, a hybrid optical
hardware-based encryption method that utilizes a lensless camera as a physical
layer of security applicable to multiple types of audio. We show that
LenslessMic enables (1) robust authentication of audio recordings and (2)
encryption strength that can rival the search space of 256-bit digital
standards, while maintaining high-quality signals and minimal loss of content
information. The approach is validated with a low-cost Raspberry Pi prototype
and is open-sourced together with datasets to facilitate research in the area.

</details>


### [54] [Temporal Logic-Based Multi-Vehicle Backdoor Attacks against Offline RL Agents in End-to-end Autonomous Driving](https://arxiv.org/abs/2509.16950)
*Xuan Chen,Shiwei Feng,Zikang Xiong,Shengwei An,Yunshu Mao,Lu Yan,Guanhong Tao,Wenbo Guo,Xiangyu Zhang*

Main category: cs.CR

TL;DR: 이 논문은 자율주행 시스템의 보안을 평가하는 새로운 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 실제 배포를 위한 자율주행 시스템의 안전성을 보장하기 위해 보안 위협, 특히 백도어 공격을 평가하는 것이 필요합니다.

Method: 우리는 다른 차량의 경로를 트리거로 활용하는 새로운 백도어 공격을 제안합니다. 이 공격을 위해, 우리는 시간 논리 사양을 사용하여 공격자 차량의 행동을 정의하고, 설정 가능한 행동 모델을 이용하여 정확한 트리거 경로를 생성합니다.

Result: 5개의 오프라인 강화 학습 주행 에이전트와 6개의 트리거 패턴 및 목표 행동 조합에 대한 광범위한 실험을 통해 우리의 공격의 유연성과 효과를 입증했습니다.

Conclusion: 우리는 기존 자율주행 시스템의 취약점에 대한 탐색이 부족함을 보여줍니다.

Abstract: Assessing the safety of autonomous driving (AD) systems against security
threats, particularly backdoor attacks, is a stepping stone for real-world
deployment. However, existing works mainly focus on pixel-level triggers that
are impractical to deploy in the real world. We address this gap by introducing
a novel backdoor attack against the end-to-end AD systems that leverage one or
more other vehicles' trajectories as triggers. To generate precise trigger
trajectories, we first use temporal logic (TL) specifications to define the
behaviors of attacker vehicles. Configurable behavior models are then used to
generate these trajectories, which are quantitatively evaluated and iteratively
refined based on the TL specifications. We further develop a negative training
strategy by incorporating patch trajectories that are similar to triggers but
are designated not to activate the backdoor. It enhances the stealthiness of
the attack and refines the system's responses to trigger scenarios. Through
extensive experiments on 5 offline reinforcement learning (RL) driving agents
with 6 trigger patterns and target action combinations, we demonstrate the
flexibility and effectiveness of our proposed attack, showing the
under-exploration of existing end-to-end AD systems' vulnerabilities to such
trajectory-based backdoor attacks.

</details>


### [55] [SilentStriker:Toward Stealthy Bit-Flip Attacks on Large Language Models](https://arxiv.org/abs/2509.17371)
*Haotian Xu,Qingsong Peng,Jie Shi,Huadi Zheng,Yu Li,Cheng Zhuo*

Main category: cs.CR

TL;DR: 이 논문에서는 대형 언어 모델에 대한 첫 번째 은밀한 비트 플립 공격을 소개하며, 성능 저하를 유지하면서도 출력의 자연성을 보장하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)의 보안 문제에 대한 연구의 필요성이 증가하고 있으며, 특히 하드웨어 취약점을 이용한 비트 플립 공격(BFA)에 대한 관심이 부족하다.

Method: 공격 효과성과 은밀성을 동시에 최적화하기 위해 주요 출력 토큰을 억제 대상으로 활용하는 손실 함수 설계를 제안하고, 반복적인 점진적 탐색 전략을 적용하였다.

Result: SilentStriker는 기존 방법보다 성능이 우수하며, 생성된 텍스트의 자연성을 침해하지 않는 데 성공하였다.

Conclusion: 이 연구는 비트 플립 공격에 대한 새로운 접근법을 제시함으로써 LLM의 보안을 강화하는데 기여할 수 있다.

Abstract: The rapid adoption of large language models (LLMs) in critical domains has
spurred extensive research into their security issues. While input manipulation
attacks (e.g., prompt injection) have been well studied, Bit-Flip Attacks
(BFAs) -- which exploit hardware vulnerabilities to corrupt model parameters
and cause severe performance degradation -- have received far less attention.
Existing BFA methods suffer from key limitations: they fail to balance
performance degradation and output naturalness, making them prone to discovery.
In this paper, we introduce SilentStriker, the first stealthy bit-flip attack
against LLMs that effectively degrades task performance while maintaining
output naturalness. Our core contribution lies in addressing the challenge of
designing effective loss functions for LLMs with variable output length and the
vast output space. Unlike prior approaches that rely on output perplexity for
attack loss formulation, which inevitably degrade output naturalness, we
reformulate the attack objective by leveraging key output tokens as targets for
suppression, enabling effective joint optimization of attack effectiveness and
stealthiness. Additionally, we employ an iterative, progressive search strategy
to maximize attack efficacy. Experiments show that SilentStriker significantly
outperforms existing baselines, achieving successful attacks without
compromising the naturalness of generated text.

</details>


### [56] [Privacy in Action: Towards Realistic Privacy Mitigation and Evaluation for LLM-Powered Agents](https://arxiv.org/abs/2509.17488)
*Shouju Wang,Fenglin Yu,Xirui Liu,Xiaoting Qin,Jue Zhang,Qingwei Lin,Dongmei Zhang,Saravan Rajmohan*

Main category: cs.CR

TL;DR: LLM 에이전트의 자율성이 증가함에 따라 프라이버시 문제 발생. PrivacyChecker와 PrivacyLens-Live 도구를 통해 프라이버시 유출을 효과적으로 저감하고 실시간 MCP 및 A2A 환경을 제공.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트가 민감한 통신을 처리할 때의 프라이버시 문제를 해결하기 위하여.

Method: PrivacyChecker는 기존 모델과 무관하게 맥락적 무결성 기반 완화 접근 방식을 제안하며, PrivacyLens-Live는 정적 벤치마크를 동적 MCP 및 A2A 환경으로 변환한다.

Result: DeepSeek-R1에서 프라이버시 유출을 36.08%에서 7.30%로, GPT-4o에서 33.06%에서 8.32%로 감소시켰다.

Conclusion: 모듈식 완화 접근 방식은 세 가지 배포 전략을 통해 에이전트 프로토콜에 원활하게 통합되며, 신흥 에이전트 생태계에 실용적인 프라이버시 보호를 제공한다.

Abstract: The increasing autonomy of LLM agents in handling sensitive communications,
accelerated by Model Context Protocol (MCP) and Agent-to-Agent (A2A)
frameworks, creates urgent privacy challenges. While recent work reveals
significant gaps between LLMs' privacy Q&A performance and their agent
behavior, existing benchmarks remain limited to static, simplified scenarios.
We present PrivacyChecker, a model-agnostic, contextual integrity based
mitigation approach that effectively reduces privacy leakage from 36.08% to
7.30% on DeepSeek-R1 and from 33.06% to 8.32% on GPT-4o, all while preserving
task helpfulness. We also introduce PrivacyLens-Live, transforming static
benchmarks into dynamic MCP and A2A environments that reveal substantially
higher privacy risks in practical. Our modular mitigation approach integrates
seamlessly into agent protocols through three deployment strategies, providing
practical privacy protection for the emerging agentic ecosystem. Our data and
code will be made available at https://aka.ms/privacy_in_action.

</details>


### [57] [AEAS: Actionable Exploit Assessment System](https://arxiv.org/abs/2509.17832)
*Xiangmin Shen,Wenyuan Cheng,Yan Chen,Zhenyuan Li,Yuqiao Gu,Lingzhi Wang,Wencheng Zhao,Dawei Sun,Jiashui Wang*

Main category: cs.CR

TL;DR: AEAS는 정적 분석을 통해 활용 가능한 익스플로잇을 평가하고 우선순위를 매기는 자동화 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 보안 전문가들은 공공 취약점 저장소에 있는 비일관적이고 저품질의 익스플로잇 아티팩트로 인해 익스플로잇 평가에서 점점 더 많은 도전에 직면하고 있다.

Method: AEAS는 익스플로잇 코드와 관련 문서를 분석하여 익스플로잇의 가용성, 기능성, 설정 복잡성을 반영하는 구조화된 기능 집합을 추출한다.

Result: AEAS는 600개 이상의 실제 응용 프로그램에서 파생된 5,000개 이상의 취약점 데이터 세트에 대해 평가되었으며, 수동 검증과 전문가 검토에서 100%의 상위 3 성공률을 달성했다.

Conclusion: 이 결과는 AEAS가 익스플로잇 기반의 취약점 우선순위 매기기에 효과적임을 보여준다.

Abstract: Security practitioners face growing challenges in exploit assessment, as
public vulnerability repositories are increasingly populated with inconsistent
and low-quality exploit artifacts. Existing scoring systems, such as CVSS and
EPSS, offer limited support for this task. They either rely on theoretical
metrics or produce opaque probability estimates without assessing whether
usable exploit code exists. In practice, security teams often resort to manual
triage of exploit repositories, which is time-consuming, error-prone, and
difficult to scale. We present AEAS, an automated system designed to assess and
prioritize actionable exploits through static analysis. AEAS analyzes both
exploit code and associated documentation to extract a structured set of
features reflecting exploit availability, functionality, and setup complexity.
It then computes an actionability score for each exploit and produces ranked
exploit recommendations. We evaluate AEAS on a dataset of over 5,000
vulnerabilities derived from 600+ real-world applications frequently
encountered by red teams. Manual validation and expert review on representative
subsets show that AEAS achieves a 100% top-3 success rate in recommending
functional exploits and shows strong alignment with expert-validated rankings.
These results demonstrate the effectiveness of AEAS in supporting
exploit-driven vulnerability prioritization.

</details>


### [58] [Federated Learning in the Wild: A Comparative Study for Cybersecurity under Non-IID and Unbalanced Settings](https://arxiv.org/abs/2509.17836)
*Roberto Doriguzzi-Corin,Petr Sabel,Silvio Cretti,Silvio Ranise*

Main category: cs.CR

TL;DR: 이 연구는 비동등하고 불균형적인 환경에서 DDoS 공격 탐지를 위한 연합 학습(FL) 접근법을 평가하고 분석한다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안의 데이터 공유 제한으로 인해 현재 사용 가능한 네트워크 트래픽 데이터를 활용하기가 어려운 문제를 해결하고자 함.

Method: 기존 DDoS 공격 탐지에서의 다양한 FL 방법을 체계적으로 검토하고 평가하며, Kubernetes 기반 테스트 환경에서 네트워크 공격 데이터를 사용하여 수렴 효율성, 계산 오버헤드, 대역폭 소비 및 모델 정확도를 측정.

Result: FL 알고리즘의 첫 비교 분석을 통해 비독립적이고 불균형적인 환경에서 침입 탐지를 위한 새로운 통찰력을 제공함.

Conclusion: 이번 연구는 향후 robust하고 개인 정보 보호가 가능한 네트워크 보안 솔루션 설계에 중요한 기초 자료가 될 것이다.

Abstract: Machine Learning (ML) techniques have shown strong potential for network
traffic analysis; however, their effectiveness depends on access to
representative, up-to-date datasets, which is limited in cybersecurity due to
privacy and data-sharing restrictions. To address this challenge, Federated
Learning (FL) has recently emerged as a novel paradigm that enables
collaborative training of ML models across multiple clients while ensuring that
sensitive data remains local. Nevertheless, Federated Averaging (FedAvg), the
canonical FL algorithm, has proven poor convergence in heterogeneous
environments where data distributions are non-independent and identically
distributed (i.i.d.) and client datasets are unbalanced, conditions frequently
observed in cybersecurity contexts. To overcome these challenges, several
alternative FL strategies have been developed, yet their applicability to
network intrusion detection remains insufficiently explored. This study
systematically reviews and evaluates a range of FL methods in the context of
intrusion detection for DDoS attacks. Using a dataset of network attacks within
a Kubernetes-based testbed, we assess convergence efficiency, computational
overhead, bandwidth consumption, and model accuracy. To the best of our
knowledge, this is the first comparative analysis of FL algorithms for
intrusion detection under realistic non-i.i.d. and unbalanced settings,
providing new insights for the design of robust, privacypreserving network
security solutions.

</details>
