<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 7]
- [cs.CR](#cs.CR) [Total: 10]
- [cs.LG](#cs.LG) [Total: 30]
- [cs.AI](#cs.AI) [Total: 24]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [ReCollab: Retrieval-Augmented LLMs for Cooperative Ad-hoc Teammate Modeling](https://arxiv.org/abs/2512.22129)
*Conor Wallace,Umer Siddique,Yongcan Cao*

Main category: cs.MA

TL;DR: 본 연구는 대규모 언어 모델을 활용하여 적응형 팀워크에서 파트너 유형을 분류하고 적응을 개선하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대처 팀워크에서 이전에 보지 못한 동료의 행동을 추론하고 정책을 적응시키는 것이 필요하다.

Method: 행동 특성에서 파생된 행동 기준을 사용하여 파트너 유형을 분류하는 언어 기반 프레임워크인 	extit{Collab}를 소개하고, 초상 경로와 함께 추론을 안정화하기 위해 검색 보강 생성을 통합한 	extit{ReCollab}으로 확장한다.

Result: 협력적인 Overcooked 환경에서 	extit{Collab}는 팀원 유형을 효과적으로 구별하고, 	extit{ReCollab}는 레이아웃 전반에 걸쳐 적응을 일관되게 개선하여 분류 정확도와 에피소드 수익 간의 파레토 최적의 균형을 달성한다.

Conclusion: 이 연구 결과는 AHT를 위한 행동 세계 모델로서 LLM의 잠재력을 입증하고, 도전적인 조정 환경에서 검색 기반 방법의 중요성을 강조한다.

Abstract: Ad-hoc teamwork (AHT) requires agents to infer the behavior of previously unseen teammates and adapt their policy accordingly. Conventional approaches often rely on fixed probabilistic models or classifiers, which can be brittle under partial observability and limited interaction. Large language models (LLMs) offer a flexible alternative: by mapping short behavioral traces into high-level hypotheses, they can serve as world models over teammate behavior. We introduce \Collab, a language-based framework that classifies partner types using a behavior rubric derived from trajectory features, and extend it to \ReCollab, which incorporates retrieval-augmented generation (RAG) to stabilize inference with exemplar trajectories. In the cooperative Overcooked environment, \Collab effectively distinguishes teammate types, while \ReCollab consistently improves adaptation across layouts, achieving Pareto-optimal trade-offs between classification accuracy and episodic return. These findings demonstrate the potential of LLMs as behavioral world models for AHT and highlight the importance of retrieval grounding in challenging coordination settings.

</details>


### [2] [Solving Multi-Agent Multi-Goal Path Finding Problems in Polynomial Time](https://arxiv.org/abs/2512.22171)
*Stefan Edelkamp*

Main category: cs.MA

TL;DR: 이 논문은 무방향 그래프에서 여러 목표를 가진 에이전트의 임무를 계획하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 무방향 그래프에서 에이전트의 임무를 효율적으로 할당하고 최적화된 경로를 찾기 위해.

Method: 에이전트의 목표 할당을 스스로 찾고 업데이트하며, 연속적인 경우와 이산적인 경우 모두 다룹니다.

Result: 이산 변형 문제는 예기치 않게 다항 시간 내에 해결 가능하며, 충돌 없는 최적 경로를 찾는 플래너를 구현했습니다.

Conclusion: 전역 할당 전략은 충돌 수를 크게 줄이며, 남은 충돌은 다양한 기법으로 해결합니다.

Abstract: In this paper, we plan missions for a fleet of agents in undirected graphs, such as grids, with multiple goals. In contrast to regular multi-agent path-finding, the solver finds and updates the assignment of goals to the agents on its own. In the continuous case for a point agent with motions in the Euclidean plane, the problem can be solved arbitrarily close to optimal. For discrete variants that incur node and edge conflicts, we show that it can be solved in polynomial time, which is unexpected, since traditional vehicle routing on general graphs is NP-hard. We implement a corresponding planner that finds conflict-free optimized routes for the agents. Global assignment strategies greatly reduce the number of conflicts, with the remaining ones resolved by elaborating on the concept of ants-on-the-stick, by solving local assignment problems, by interleaving agent paths, and by kicking agents that have already arrived out of their destinations

</details>


### [3] [Hierarchical Pedagogical Oversight: A Multi-Agent Adversarial Framework for Reliable AI Tutoring](https://arxiv.org/abs/2512.22496)
*Saisab Sadhu,Ashim Dhor*

Main category: cs.MA

TL;DR: 이 논문에서는 교육자 부족 문제를 해결하기 위해 LLM을 자동 튜터로 사용하는 데 있어 발생하는 문제를 해결하기 위한 새로운 프레임워크인 HPO를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 교육자 부족 문제를 해결하기 위해 LLMs를 자동 튜터로 활용하고자 하지만, 기존 모델들이 교육적 추론에서 실패하는 경향이 있다.

Method: HPO는 구조화된 적대적 합성을 교육 평가에 적용하여, 신뢰할 수 있는 교수 감독을 위한 기제를 제공하는 프레임워크이다.

Result: MRBench 데이터셋에서 1,214개의 중학교 수학 대화를 통해 평가한 결과, 8B-매개변수 모델이 Macro F1 점수 0.845를 기록하며 GPT-4o보다 3.3% 더 우수한 성능을 보였다.

Conclusion: 이 결과는 자원이 제한된 환경에서 신뢰할 수 있는 낮은 계산 비용의 교육 감독을 위한 적대적 추론이 중요한 메커니즘임을 입증한다.

Abstract: Large Language Models (LLMs) are increasingly deployed as automated tutors to address educator shortages; however, they often fail at pedagogical reasoning, frequently validating incorrect student solutions (sycophancy) or providing overly direct answers that hinder learning. We introduce Hierarchical Pedagogical Oversight (HPO), a framework that adapts structured adversarial synthesis to educational assessment. Unlike cooperative multi-agent systems that often drift toward superficial consensus, HPO enforces a dialectical separation of concerns: specialist agents first distill dialogue context, which then grounds a moderated, five-act debate between opposing pedagogical critics. We evaluate this framework on the MRBench dataset of 1,214 middle-school mathematics dialogues. Our 8B-parameter model achieves a Macro F1 of 0.845, outperforming GPT-4o (0.812) by 3.3% while using 20 times fewer parameters. These results establish adversarial reasoning as a critical mechanism for deploying reliable, low-compute pedagogical oversight in resource-constrained environments.

</details>


### [4] [MARPO: A Reflective Policy Optimization for Multi Agent Reinforcement Learning](https://arxiv.org/abs/2512.22832)
*Cuiling Wu,Yaozhong Gan,Junliang Xing,Ying Fu*

Main category: cs.MA

TL;DR: MARPO라는 다중 에이전트 강화 학습의 샘플 비효율성 문제를 완화하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 강화 학습에서 샘플 비효율성 문제를 해결하고자 함.

Method: 후속 경로를 활용하여 샘플 효율성을 향상시키는 반사 메커니즘과 KL 발산에 기반하여 클리핑 범위를 동적으로 조정하는 비대칭 클리핑 메커니즘으로 구성됨.

Result: 고전적인 다중 에이전트 환경에서 MARPO가 다른 방법들보다 일관되게 우수한 성능을 보임.

Conclusion: MARPO는 다중 에이전트 강화 학습의 훈련 안정성을 개선하고 샘플 효율성을 높이는 효과적인 방법임.

Abstract: We propose Multi Agent Reflective Policy Optimization (MARPO) to alleviate the issue of sample inefficiency in multi agent reinforcement learning. MARPO consists of two key components: a reflection mechanism that leverages subsequent trajectories to enhance sample efficiency, and an asymmetric clipping mechanism that is derived from the KL divergence and dynamically adjusts the clipping range to improve training stability. We evaluate MARPO in classic multi agent environments, where it consistently outperforms other methods.

</details>


### [5] [Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks](https://arxiv.org/abs/2512.22876)
*Maksim Kryzhanovskiy,Svetlana Glazyrina,Roman Ischenko,Konstantin Vorontsov*

Main category: cs.MA

TL;DR: 본 논문은 Directed Acyclic Graph 구조를 활용하여 협업 다중 에이전트 강화 학습을 위한 새로운 프레임워크인 Reinforcement Networks를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 현대 AI 시스템은 여러 학습 가능한 구성 요소로 구성되며, 이는 그래프로 자연스럽게 조직될 수 있습니다. 이러한 시스템을 제한된 아키텍처나 훈련 가정 없이 end-to-end 방식으로 훈련하는 것이 주요 도전 과제입니다.

Method: Reinforcement Networks라는 일반적인 MARL 프레임워크를 도입하여 에이전트를 방향성 비순환 그래프(DAG)의 정점으로 조직합니다. 이 구조는 계층적 강화 학습을 임의의 DAG로 확장하며, 유연한 신뢰도 할당과 확장 가능한 조정을 가능하게 합니다.

Result: 여러 협업 MARL 설정에서 Reinforcement Networks 모델을 개발하여 표준 MARL 기준선보다 향상된 성능을 달성함으로써 접근 방식의 효과를 입증합니다.

Conclusion: Reinforcement Networks는 계층적, 모듈형 및 그래프 구조적 MARL 뷰를 통합하여 복잡한 다중 에이전트 시스템을 설계하고 훈련하는 원칙 있는 경로를 열어줍니다. 이 논문은 강화 네트워크의 이론적 및 실용적 방향, 즉 더 풍부한 그래프 형태, 구성적 커리큘럼, 그래프 인식 탐색을 제시하며, 이를 통해 새로운 연구의 기초로서의 위치를 부여합니다.

Abstract: Modern AI systems often comprise multiple learnable components that can be naturally organized as graphs. A central challenge is the end-to-end training of such systems without restrictive architectural or training assumptions. Such tasks fit the theory and approaches of the collaborative Multi-Agent Reinforcement Learning (MARL) field. We introduce Reinforcement Networks, a general framework for MARL that organizes agents as vertices in a directed acyclic graph (DAG). This structure extends hierarchical RL to arbitrary DAGs, enabling flexible credit assignment and scalable coordination while avoiding strict topologies, fully centralized training, and other limitations of current approaches. We formalize training and inference methods for the Reinforcement Networks framework and connect it to the LevelEnv concept to support reproducible construction, training, and evaluation. We demonstrate the effectiveness of our approach on several collaborative MARL setups by developing several Reinforcement Networks models that achieve improved performance over standard MARL baselines. Beyond empirical gains, Reinforcement Networks unify hierarchical, modular, and graph-structured views of MARL, opening a principled path toward designing and training complex multi-agent systems. We conclude with theoretical and practical directions - richer graph morphologies, compositional curricula, and graph-aware exploration. That positions Reinforcement Networks as a foundation for a new line of research in scalable, structured MARL.

</details>


### [6] [Heterogeneity in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.22941)
*Tianyi Hu,Zhiqiang Pu,Yuan Wang,Tenghai Qiu,Min Chen,Xin Yu*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 강화 학습(MARL)에서 이질성을 정의, 정량화 및 활용 측면에서 체계적으로 논의합니다.


<details>
  <summary>Details</summary>
Motivation: MARL 분야에서 이질성에 대한 엄격한 정의와 깊은 이해가 부족합니다.

Method: 에이전트 수준 모델링을 기반으로 이질성을 다섯 가지 유형으로 분류하고, 이질성 거리 개념을 정의하며, 이를 정량화하는 방법과 이질성 기반 다중 에이전트 동적 파라미터 공유 알고리즘을 설계했습니다.

Result: 사례 연구를 통해 우리의 방법이 다양한 유형의 에이전트 이질성을 효과적으로 식별하고 정량화할 수 있음을 보여주었습니다. 실험 결과 제안한 알고리즘은 다른 파라미터 공유 기준선에 비해 더 나은 해석 가능성과 강한 적응력을 보였습니다.

Conclusion: 제안된 방법론은 MARL 커뮤니티가 이질성에 대한 보다 포괄적이고 깊은 이해를 얻도록 도와주고, 실용적인 알고리즘 개발을 촉진할 것입니다.

Abstract: Heterogeneity is a fundamental property in multi-agent reinforcement learning (MARL), which is closely related not only to the functional differences of agents, but also to policy diversity and environmental interactions. However, the MARL field currently lacks a rigorous definition and deeper understanding of heterogeneity. This paper systematically discusses heterogeneity in MARL from the perspectives of definition, quantification, and utilization. First, based on an agent-level modeling of MARL, we categorize heterogeneity into five types and provide mathematical definitions. Second, we define the concept of heterogeneity distance and propose a practical quantification method. Third, we design a heterogeneity-based multi-agent dynamic parameter sharing algorithm as an example of the application of our methodology. Case studies demonstrate that our method can effectively identify and quantify various types of agent heterogeneity. Experimental results show that the proposed algorithm, compared to other parameter sharing baselines, has better interpretability and stronger adaptability. The proposed methodology will help the MARL community gain a more comprehensive and profound understanding of heterogeneity, and further promote the development of practical algorithms.

</details>


### [7] [Assessing behaviour coverage in a multi-agent system simulation for autonomous vehicle testing](https://arxiv.org/abs/2512.23445)
*Manuel Franco-Vivo*

Main category: cs.MA

TL;DR: 이 연구는 자율주행 차량을 위한 다중 에이전트 시스템 시뮬레이션의 행동 커버리지 분석에 중점을 두며, 시뮬레이션 환경 내에서 행동 커버리지를 측정하고 평가하는 체계적인 접근법을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 자율주행 차량 기술의 발전에 따라, 이러한 시스템의 안전성과 신뢰성을 보장하는 것이 매우 중요해졌다.

Method: 다양한 주행 시나리오와 에이전트 상호작용을 정의하여 시뮬레이션이 자율주행과 관련된 다양한 행동을 얼마나 포괄하는지를 평가한다.

Result: 행동 커버리지 메트릭스와 커버리지 기반 테스트 분석을 통해 개선 및 최적화가 필요한 주요 영역을 식별한다.

Conclusion: 이 연구는 자율주행 차량 시스템의 효과성과 견고성을 검증하기 위한 행동 커버리지의 중요성을 강조하며, 엄격한 테스트 방법론을 통한 안전성, 신뢰성 및 성능 향상에 기여한다.

Abstract: As autonomous vehicle technology advances, ensuring the safety and reliability of these systems becomes paramount. Consequently, comprehensive testing methodologies are essential to evaluate the performance of autonomous vehicles in diverse and complex real-world scenarios. This study focuses on the behaviour coverage analysis of a multi-agent system simulation designed for autonomous vehicle testing, and provides a systematic approach to measure and assess behaviour coverage within the simulation environment. By defining a set of driving scenarios, and agent interactions, we evaluate the extent to which the simulation encompasses a broad range of behaviours relevant to autonomous driving.
  Our findings highlight the importance of behaviour coverage in validating the effectiveness and robustness of autonomous vehicle systems. Through the analysis of behaviour coverage metrics and coverage-based testing, we identify key areas for improvement and optimization in the simulation framework. Thus, a Model Predictive Control (MPC) pedestrian agent is proposed, where its objective function is formulated to encourage \textit{interesting} tests while promoting a more realistic behaviour than other previously studied pedestrian agents. This research contributes to advancing the field of autonomous vehicle testing by providing insights into the comprehensive evaluation of system behaviour in simulated environments. The results offer valuable implications for enhancing the safety, reliability, and performance of autonomous vehicles through rigorous testing methodologies.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [8] [Practical challenges of control monitoring in frontier AI deployments](https://arxiv.org/abs/2512.22154)
*David Lindner,Charlie Griffin,Tomek Korbak,Roland S. Zimmermann,Geoffrey Irving,Sebastian Farquhar,Alan Cooney*

Main category: cs.CR

TL;DR: 자동 제어 모니터는 신뢰할 수 없는 고성능 AI 에이전트를 감독하는 데 중요한 역할을 할 수 있다. 이 논문은 다양한 지연-안전성 트레이드오프가 있는 모니터링의 세 가지 형태인 동기식, 반동기식, 비동기식 모니터링을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 신뢰할 수 없는 고성능 AI 에이전트를 감독할 수 있는 자동 제어 모니터의 필요성.

Method: 동기식, 반동기식, 비동기식 모니터링 등 세 가지 모니터링 형태를 분석하여 이에 따른 설계 선택을 조망.

Result: 설계 선택 분석을 통해 감독, 지연, 복구라는 세 가지 도전을 식별하고, 향후 AI 배치의 네 가지 사례를 탐구하였다.

Conclusion: AI의 실제 배치에서 모니터링 프로토콜을 이해하고 비교하는 도구로서 안전 사례 스케치를 도입하고, 각 모니터링 형태의 장단점을 강조한다.

Abstract: Automated control monitors could play an important role in overseeing highly capable AI agents that we do not fully trust. Prior work has explored control monitoring in simplified settings, but scaling monitoring to real-world deployments introduces additional dynamics: parallel agent instances, non-negligible oversight latency, incremental attacks between agent instances, and the difficulty of identifying scheming agents based on individual harmful actions. In this paper, we analyse design choices to address these challenges, focusing on three forms of monitoring with different latency-safety trade-offs: synchronous, semi-synchronous, and asynchronous monitoring. We introduce a high-level safety case sketch as a tool for understanding and comparing these monitoring protocols. Our analysis identifies three challenges -- oversight, latency, and recovery -- and explores them in four case studies of possible future AI deployments.

</details>


### [9] [NOWA: Null-space Optical Watermark for Invisible Capture Fingerprinting and Tamper Localization](https://arxiv.org/abs/2512.22501)
*Edwin Vargas*

Main category: cs.CR

TL;DR: 본 논문에서는 디지털 이미지의 진위와 소유권을 보장하기 위한 하이브리드 광학-디지털 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 이미지의 진위와 소유권 보장은 현대 편집 도구로 인해 점점 어려워지고 있으며, 기존 시스템은 정교한 공격에 취약하다.

Method: 광학 단계에서 카메라 조리개에 있는 위상 마스크가 Null-space Optical Watermark(NOWA)를 생성하며, Null-Space Network(NSN)가 이를 보존하면서 고품질 이미지를 재구성한다.

Result: 제안된 디자인은 이미지의 무결성을 유지하면서 압축과 같은 일반적인 저하에 저항하고, 위조 방지의 불균형 구조를 제공한다.

Conclusion: 실험 결과는 제안된 방법이 최첨단 디지털 워터마킹 및 학습 기반 인증 방법과 비교하여 경쟁력 있는 성능을 보여준다.

Abstract: Ensuring the authenticity and ownership of digital images is increasingly challenging as modern editing tools enable highly realistic forgeries. Existing image protection systems mainly rely on digital watermarking, which is susceptible to sophisticated digital attacks. To address this limitation, we propose a hybrid optical-digital framework that incorporates physical authentication cues during image formation and preserves them through a learned reconstruction process. At the optical level, a phase mask in the camera aperture produces a Null-space Optical Watermark (NOWA) that lies in the Null Space of the imaging operator and therefore remains invisible in the captured image. Then, a Null-Space Network (NSN) performs measurement-consistent reconstruction that delivers high-quality protected images while preserving the NOWA signature. The proposed design enables tamper localization by projecting the image onto the camera's null space and detecting pixel-level inconsistencies. Our design preserves perceptual quality, resists common degradations such as compression, and establishes a structural security asymmetry: without access to the optical or NSN parameters, adversaries cannot forge the NOWA signature. Experiments with simulations and a prototype camera demonstrate competitive performance in terms of image quality preservation, and tamper localization accuracy compared to state-of-the-art digital watermarking and learning-based authentication methods.

</details>


### [10] [Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks](https://arxiv.org/abs/2512.22860)
*Soham Padia,Dhananjay Vaidya,Ramchandra Mangrulkar*

Main category: cs.CR

TL;DR: 블록체인 기반 IoT 네트워크의 공격 방어를 위한 신뢰 기반 위임 합의 프레임워크 및 강화 학습 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 블록체인 기반 IoT 네트워크는 정교한 적대적 공격에 대해 보호해야 하며, 이는 중요한 도전 과제가 되고 있다.

Method: 신뢰 기반 위임 합의 프레임워크를 제시하며, 완전 동형 암호화(FHE)와 속성 기반 접근 제어(ABAC)를 통합하고 학습 기반 방어 메커니즘을 결합하였다.

Result: 16개 노드로 구성된 시뮬레이션 IoT 네트워크 실험 결과, MARL이 집단 공격에 대해 우수한 감지 성능을 보였고, DRL과 MARL은 적응형 공격에 대해 완벽한 감지를 달성하였다. 또한 모든 에이전트가 비잔틴 공격에 성공적으로 방어하였다. 그러나 시간 지연 독극물 공격은 모든 에이전트에게 치명적이었다.

Conclusion: 협조적인 다중 에이전트 학습이 블록체인 IoT 환경에서 신뢰 조작 공격에 대한 방어에 측정 가능한 이점을 제공한다는 것을 보여준다.

Abstract: Securing blockchain-enabled IoT networks against sophisticated adversarial attacks remains a critical challenge. This paper presents a trust-based delegated consensus framework integrating Fully Homomorphic Encryption (FHE) with Attribute-Based Access Control (ABAC) for privacy-preserving policy evaluation, combined with learning-based defense mechanisms. We systematically compare three reinforcement learning approaches -- tabular Q-learning (RL), Deep RL with Dueling Double DQN (DRL), and Multi-Agent RL (MARL) -- against five distinct attack families: Naive Malicious Attack (NMA), Collusive Rumor Attack (CRA), Adaptive Adversarial Attack (AAA), Byzantine Fault Injection (BFI), and Time-Delayed Poisoning (TDP). Experimental results on a 16-node simulated IoT network reveal significant performance variations: MARL achieves superior detection under collusive attacks (F1=0.85 vs. DRL's 0.68 and RL's 0.50), while DRL and MARL both attain perfect detection (F1=1.00) against adaptive attacks where RL fails (F1=0.50). All agents successfully defend against Byzantine attacks (F1=1.00). Most critically, the Time-Delayed Poisoning attack proves catastrophic for all agents, with F1 scores dropping to 0.11-0.16 after sleeper activation, demonstrating the severe threat posed by trust-building adversaries. Our findings indicate that coordinated multi-agent learning provides measurable advantages for defending against sophisticated trust manipulation attacks in blockchain IoT environments.

</details>


### [11] [Agentic AI for Cyber Resilience: A New Security Paradigm and Its System-Theoretic Foundations](https://arxiv.org/abs/2512.22883)
*Tao Li,Quanyan Zhu*

Main category: cs.CR

TL;DR: 기초 모델 기반 인공지능에 의해 사이버 보안이 근본적으로 재형성되고 있으며, 이에 따라 예방 중심의 보안에서 자율 사이버 회복력으로의 전환이 필요하다.


<details>
  <summary>Details</summary>
Motivation: 기존의 정적 규칙과 인간 중심의 작업 흐름에 의존하는 보안 아키텍처가 새로운 AI 기술에 의해 도전받고 있다.

Method: 자율 에이전트가 사이버 및 사이버-물리 시스템에서 감지, 추론, 행동 및 적응에 참가하는 AI 증강 패러다임을 개발하고 시스템 수준의 에이전틱 AI 작업 흐름 설계를 위한 프레임워크를 제안한다.

Result: 에이전트 아키텍처와 공격자 및 방어자의 작업 흐름을 분석하여 자율성 할당, 정보 흐름 및 시간적 구성을 위한 통합 설계 언어를 제공한다.

Conclusion: 자동화된 침투 테스트 및 사이버 기만 사례 연구를 통해 균형 기반 설계가 시스템 수준의 회복력 설계를 가능하게 함을 보여준다.

Abstract: Cybersecurity is being fundamentally reshaped by foundation-model-based artificial intelligence. Large language models now enable autonomous planning, tool orchestration, and strategic adaptation at scale, challenging security architectures built on static rules, perimeter defenses, and human-centered workflows. This chapter argues for a shift from prevention-centric security toward agentic cyber resilience. Rather than seeking perfect protection, resilient systems must anticipate disruption, maintain critical functions under attack, recover efficiently, and learn continuously. We situate this shift within the historical evolution of cybersecurity paradigms, culminating in an AI-augmented paradigm where autonomous agents participate directly in sensing, reasoning, action, and adaptation across cyber and cyber-physical systems. We then develop a system-level framework for designing agentic AI workflows. A general agentic architecture is introduced, and attacker and defender workflows are analyzed as coupled adaptive processes, and game-theoretic formulations are shown to provide a unifying design language for autonomy allocation, information flow, and temporal composition. Case studies in automated penetration testing, remediation, and cyber deception illustrate how equilibrium-based design enables system-level resiliency design.

</details>


### [12] [DECEPTICON: How Dark Patterns Manipulate Web Agents](https://arxiv.org/abs/2512.22894)
*Phil Cuvin,Hao Zhu,Diyi Yang*

Main category: cs.CR

TL;DR: 본 연구는 어두운 패턴이 에이전트의 궤적에 미치는 영향을 분석하고, 이를 측정하기 위해 DECEPTICON 환경을 도입하여 해당 패턴의 효과성을 입증하였다. 


<details>
  <summary>Details</summary>
Motivation: 어두운 패턴이 사용자 행동을 조작하여 위험에 처하게 하는 현상을 밝혀내고자 함.

Method: DECEPTICON이라는 환경을 통해 700개의 웹 탐색 작업을 분석하여 어두운 패턴의 효과를 측정하였음.

Result: 테스트한 생성된 및 실제 작업의 70% 이상에서 어두운 패턴이 에이전트의 궤적을 악의적인 결과로 유도함을 발견하였음.

Conclusion: 어두운 패턴은 웹 에이전트에 대한 미해결 위험으로 나타났으며, 조작적인 디자인에 대한 강력한 방어가 필요함을 강조함.

Abstract: Deceptive UI designs, widely instantiated across the web and commonly known as dark patterns, manipulate users into performing actions misaligned with their goals. In this paper, we show that dark patterns are highly effective in steering agent trajectories, posing a significant risk to agent robustness. To quantify this risk, we introduce DECEPTICON, an environment for testing individual dark patterns in isolation. DECEPTICON includes 700 web navigation tasks with dark patterns -- 600 generated tasks and 100 real-world tasks, designed to measure instruction-following success and dark pattern effectiveness. Across state-of-the-art agents, we find dark patterns successfully steer agent trajectories towards malicious outcomes in over 70% of tested generated and real-world tasks -- compared to a human average of 31%. Moreover, we find that dark pattern effectiveness correlates positively with model size and test-time reasoning, making larger, more capable models more susceptible. Leading countermeasures against adversarial attacks, including in-context prompting and guardrail models, fail to consistently reduce the success rate of dark pattern interventions. Our findings reveal dark patterns as a latent and unmitigated risk to web agents, highlighting the urgent need for robust defenses against manipulative designs.

</details>


### [13] [Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems](https://arxiv.org/abs/2512.23132)
*Armstrong Foundjem,Lionel Nganyewou Tidjon,Leuson Da Silva,Foutse Khomh*

Main category: cs.CR

TL;DR: 이 논문은 기계 학습의 보안 위험을 분석하고, 주요 공격 기술 및 변칙성을 식별하여 ML 생애 주기 동안의 위험을 완화하기 위한 방안을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 금융, 의료 및 중요한 인프라의 기본 모델이 데이터 오염 및 다양한 공격의 목표가 되고 있어 기계 학습의 보안 위험을 이해하는 것이 중요합니다.

Method: MITRE ATLAS, AI Incident Database 및 문헌에서 93개의 위협을 추출하고, 854개의 GitHub/Python 저장소를 분석하여 멀티 에이전트 RAG 시스템을 사용하여 300개 이상의 기사를 마이닝하여 TTP, 취약점 및 단계를 연결하는 위협 그래프를 구축합니다.

Result: 보고되지 않은 위협을 포함하여 상업적 LLM API 모델 도용, 매개변수 기억 누수 및 선호 기반 텍스트 전용 탈옥 등을 확인했습니다. 주요 TTP에는 MASTERKEY 스타일의 탈옥, 연합 오염, 확산 백도어 및 선호 최적화 누수가 포함됩니다.

Conclusion: 의존성 위생, 위협 인텔리전스 및 모니터링을 결합한 적응형 ML 전용 보안 프레임워크는 ML 생애 주기 전반에 걸쳐 공급망 및 추론 위험을 완화하는 데 필수적입니다.

Abstract: Machine learning (ML) underpins foundation models in finance, healthcare, and critical infrastructure, making them targets for data poisoning, model extraction, prompt injection, automated jailbreaking, and preference-guided black-box attacks that exploit model comparisons. Larger models can be more vulnerable to introspection-driven jailbreaks and cross-modal manipulation. Traditional cybersecurity lacks ML-specific threat modeling for foundation, multimodal, and RAG systems. Objective: Characterize ML security risks by identifying dominant TTPs, vulnerabilities, and targeted lifecycle stages. Methods: We extract 93 threats from MITRE ATLAS (26), AI Incident Database (12), and literature (55), and analyze 854 GitHub/Python repositories. A multi-agent RAG system (ChatGPT-4o, temp 0.4) mines 300+ articles to build an ontology-driven threat graph linking TTPs, vulnerabilities, and stages. Results: We identify unreported threats including commercial LLM API model stealing, parameter memorization leakage, and preference-guided text-only jailbreaks. Dominant TTPs include MASTERKEY-style jailbreaking, federated poisoning, diffusion backdoors, and preference optimization leakage, mainly impacting pre-training and inference. Graph analysis reveals dense vulnerability clusters in libraries with poor patch propagation. Conclusion: Adaptive, ML-specific security frameworks, combining dependency hygiene, threat intelligence, and monitoring, are essential to mitigate supply-chain and inference risks across the ML lifecycle.

</details>


### [14] [EquaCode: A Multi-Strategy Jailbreak Approach for Large Language Models via Equation Solving and Code Completion](https://arxiv.org/abs/2512.23173)
*Zhen Liang,Hai Huang,Zhengkui Chen*

Main category: cs.CR

TL;DR: Equacode는 다중 전략 탈옥 접근법으로, 대형 언어 모델의 안전성을 평가하는 새로운 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 신뢰성 문제와 기존 탈옥 공격의 한계를 극복하기 위함입니다.

Method: 수학적 문제로 악의적 의도를 변환하고 코드를 사용하여 LLM이 이를 해결하도록 요구하는 새로운 다중 전략 탈옥 접근법을 제안합니다.

Result: Equacode는 GPT 시리즈에서 평균 91.19%의 성공률과 3개의 최신 LLM에서 98.65%의 성공률을 기록했습니다.

Conclusion: 다중 전략 접근법은 단일 모듈보다 더 나은 결과를 냈으며, 이는 강한 시너지 효과를 나타냅니다.

Abstract: Large language models (LLMs), such as ChatGPT, have achieved remarkable success across a wide range of fields. However, their trustworthiness remains a significant concern, as they are still susceptible to jailbreak attacks aimed at eliciting inappropriate or harmful responses. However, existing jailbreak attacks mainly operate at the natural language level and rely on a single attack strategy, limiting their effectiveness in comprehensively assessing LLM robustness. In this paper, we propose Equacode, a novel multi-strategy jailbreak approach for large language models via equation-solving and code completion. This approach transforms malicious intent into a mathematical problem and then requires the LLM to solve it using code, leveraging the complexity of cross-domain tasks to divert the model's focus toward task completion rather than safety constraints. Experimental results show that Equacode achieves an average success rate of 91.19% on the GPT series and 98.65% across 3 state-of-the-art LLMs, all with only a single query. Further, ablation experiments demonstrate that EquaCode outperforms either the mathematical equation module or the code module alone. This suggests a strong synergistic effect, thereby demonstrating that multi-strategy approach yields results greater than the sum of its parts.

</details>


### [15] [RobustMask: Certified Robustness against Adversarial Neural Ranking Attack via Randomized Masking](https://arxiv.org/abs/2512.23307)
*Jiawei Liu,Zhuo Chen,Rui Zhu,Miaokun Chen,Yuyang Gong,Wei Lu,Xiaofeng Wang*

Main category: cs.CR

TL;DR: RobustMask는 신경 순위 모델을 적대적 조작으로부터 보호하는 새로운 방어 메커니즘이다.


<details>
  <summary>Details</summary>
Motivation: 신경 순위 모델이 실제 애플리케이션에 널리 사용됨에도 불구하고 적대적 조작에 취약하다.

Method: RobustMask는 사전 훈련된 언어 모델의 맥락 예측 능력과 무작위 마스킹 기반 스무딩 메커니즘을 결합하여 방어를 구현한다.

Result: RobustMask는 최대 30%의 내용을 영향을 받는 적대적 교란에 대해 상위 10위 내의 후보 문서 20% 이상을 성공적으로 인증한다.

Conclusion: RobustMask는 신경 순위 모델의 적대적 강인성을 향상시키며, 실제 검색 시스템의 보안을 강화하는 중요한 단계다.

Abstract: Neural ranking models have achieved remarkable progress and are now widely deployed in real-world applications such as Retrieval-Augmented Generation (RAG). However, like other neural architectures, they remain vulnerable to adversarial manipulations: subtle character-, word-, or phrase-level perturbations can poison retrieval results and artificially promote targeted candidates, undermining the integrity of search engines and downstream systems. Existing defenses either rely on heuristics with poor generalization or on certified methods that assume overly strong adversarial knowledge, limiting their practical use. To address these challenges, we propose RobustMask, a novel defense that combines the context-prediction capability of pretrained language models with a randomized masking-based smoothing mechanism. Our approach strengthens neural ranking models against adversarial perturbations at the character, word, and phrase levels. Leveraging both the pairwise comparison ability of ranking models and probabilistic statistical analysis, we provide a theoretical proof of RobustMask's certified top-K robustness. Extensive experiments further demonstrate that RobustMask successfully certifies over 20% of candidate documents within the top-10 ranking positions against adversarial perturbations affecting up to 30% of their content. These results highlight the effectiveness of RobustMask in enhancing the adversarial robustness of neural ranking models, marking a significant step toward providing stronger security guarantees for real-world retrieval systems.

</details>


### [16] [Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation](https://arxiv.org/abs/2512.23480)
*Toqeer Ali Syed,Mohammad Riyaz Belgaum,Salman Jan,Asadullah Abdullah Khan,Saad Said Alqahtani*

Main category: cs.CR

TL;DR: 이 논문은 소프트웨어 공급망 보안을 위한 에이전틱 인공지능(AI)을 제안하며, 이 시스템은 보안 에이전트를 활용하여 취약점을 식별하고 제거하는 동시에 통합된 CI/CD 환경과 블록체인 보안 원장을 통해 무결성과 감사 기능을 보장한다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 공급망 공격이 증가하면서 신뢰할 수 있는 개발 및 전달 절차에 대한 초점이 맞춰지고 있다.

Method: 대규모 언어 모델(LLM) 기반 추론, 강화 학습(RL) 및 다중 에이전트 조정을 결합한 에이전틱 AI를 기반으로 한 자율 소프트웨어 공급망 보안을 제안한다.

Result: 시뮬레이션 파이프라인 및 GitHub Actions와 Jenkins에서의 실제 CI/CD 통합을 통해 테스트하여 향상된 탐지 정확도 및 짧은 완화 지연 시간을 달성했다.

Conclusion: 에이전틱 AI는 소프트웨어 공급망을 반응적인 검증에서 자가 방어적인 능동적 공급망으로 전환하는 데 기여할 수 있다.

Abstract: The software supply chain attacks are becoming more and more focused on trusted development and delivery procedures, so the conventional post-build integrity mechanisms cannot be used anymore. The available frameworks like SLSA, SBOM and in toto are majorly used to offer provenance and traceability but do not have the capabilities of actively identifying and removing vulnerabilities in software production. The current paper includes an example of agentic artificial intelligence (AI) based on autonomous software supply chain security that combines large language model (LLM)-based reasoning, reinforcement learning (RL), and multi-agent coordination. The suggested system utilizes specialized security agents coordinated with the help of LangChain and LangGraph, communicates with actual CI/CD environments with the Model Context Protocol (MCP), and documents all the observations and actions in a blockchain security ledger to ensure integrity and auditing. Reinforcement learning can be used to achieve adaptive mitigation strategies that consider the balance between security effectiveness and the operational overhead, and LLMs can be used to achieve semantic vulnerability analysis, as well as explainable decisions. This framework is tested based on simulated pipelines, as well as, actual world CI/CD integrations on GitHub Actions and Jenkins, including injection attacks, insecure deserialization, access control violations, and configuration errors. Experimental outcomes indicate better detection accuracy, shorter mitigation latency and reasonable build-time overhead than rule-based, provenance only and RL only baselines. These results show that agentic AI can facilitate the transition to self defending, proactive software supply chains rather than reactive verification ones.

</details>


### [17] [Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks](https://arxiv.org/abs/2512.23557)
*Toqeer Ali Syed,Mishal Ateeq Almutairi,Mahmoud Abdel Moaty*

Main category: cs.CR

TL;DR: 이 논문은 다중 모드 프롬프트 주입 공격을 완화하기 위한 방안으로 교차 에이전트 멀티모달 출처 인식 방어 구조를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 강력한 자율 시스템의 점증적인 사용에 따라 멀티모달 프롬프트 주입 공격의 위험이 증가하고 있다.

Method: 이 논문은 모든 프롬프트와 LLM의 출력을 독립적으로 검증하는 교차 에이전트 멀티모달 출처 인식 방어 구조를 제안한다.

Result: 실험 결과, 멀티모달 주입 탐지 정확도가 크게 향상되었으며, 교차 에이전트 신뢰 누수가 최소화되었다.

Conclusion: 이 프레임워크는 다중 에이전트 조정에 대한 출처 추적 및 검증 개념을 확장하여 안전하고 이해할 수 있으며 신뢰할 수 있는 자율 AI 시스템의 수립을 강화한다.

Abstract: Powerful autonomous systems, which reason, plan, and converse using and between numerous tools and agents, are made possible by Large Language Models (LLMs), Vision-Language Models (VLMs), and new agentic AI systems, like LangChain and GraphChain. Nevertheless, this agentic environment increases the probability of the occurrence of multimodal prompt injection (PI) attacks, in which concealed or malicious instructions carried in text, pictures, metadata, or agent-to-agent messages may spread throughout the graph and lead to unintended behavior, a breach of policy, or corruption of state. In order to mitigate these risks, this paper suggests a Cross-Agent Multimodal Provenanc- Aware Defense Framework whereby all the prompts, either user-generated or produced by upstream agents, are sanitized and all the outputs generated by an LLM are verified independently before being sent to downstream nodes. This framework contains a Text sanitizer agent, visual sanitizer agent, and output validator agent all coordinated by a provenance ledger, which keeps metadata of modality, source, and trust level throughout the entire agent network. This architecture makes sure that agent-to-agent communication abides by clear trust frames such such that injected instructions are not propagated down LangChain or GraphChain-style-workflows. The experimental assessments show that multimodal injection detection accuracy is significantly enhanced, and the cross-agent trust leakage is minimized, as well as, agentic execution pathways become stable. The framework, which expands the concept of provenance tracking and validation to the multi-agent orchestration, enhances the establishment of secure, understandable and reliable agentic AI systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [18] [Pruning Graphs by Adversarial Robustness Evaluation to Strengthen GNN Defenses](https://arxiv.org/abs/2512.22128)
*Yongyu Wang*

Main category: cs.LG

TL;DR: 본 연구에서는 그래프 신경망(GNN)의 취약점을 개선하기 위한 가지치기 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: GNN은 그래프 구조 데이터에서 노드 특징과 관계 정보를 공동으로 활용하여 우수한 성능을 발휘하지만, 노이즈나 왜곡에 민감하다.

Method: 우리는 적대적 강인성 평가를 활용하여 그래프의 취약한 또는 해로운 구성 요소를 식별하고 제거하는 가지치기 프레임워크를 소개한다.

Result: 적강성 점수를 안내로 사용하여 모델 신뢰성을 저하시킬 가능성이 가장 높은 엣지를 선별적으로 가지치기하며, 이는 더 깨끗하고 강건한 그래프 표현을 생성하게 된다.

Conclusion: 우리의 접근 방식은 높은 변동성을 가진 환경에서도 GNN의 방어 능력을 크게 향상시킬 수 있음을 보여준다.

Abstract: Graph Neural Networks (GNNs) have emerged as a dominant paradigm for learning on graph-structured data, thanks to their ability to jointly exploit node features and relational information encoded in the graph topology. This joint modeling, however, also introduces a critical weakness: perturbations or noise in either the structure or the features can be amplified through message passing, making GNNs highly vulnerable to adversarial attacks and spurious connections. In this work, we introduce a pruning framework that leverages adversarial robustness evaluation to explicitly identify and remove fragile or detrimental components of the graph. By using robustness scores as guidance, our method selectively prunes edges that are most likely to degrade model reliability, thereby yielding cleaner and more resilient graph representations. We instantiate this framework on three representative GNN architectures and conduct extensive experiments on benchmarks. The experimental results show that our approach can significantly enhance the defense capability of GNNs in the high-perturbation regime.

</details>


### [19] [Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks](https://arxiv.org/abs/2512.22186)
*Vishnu Mohan*

Main category: cs.LG

TL;DR: 이 논문은 테니스 전략 최적화를 위한 강화 학습 프레임워크를 제안하며, 맞춤형 시뮬레이션 환경과 Dueling Double Deep Q-Network(DDQN)를 통합하고, 커리큘럼 학습을 통해 훈련합니다.


<details>
  <summary>Details</summary>
Motivation: 테니스 전략 최적화는 다양한 요인을 포함하는 반복적인 의사결정 문제로, 이를 해결하기 위한 효과적인 접근법이 필요합니다.

Method: 맞춤형 테니스 시뮬레이션 환경과 Dueling DDQN을 결합하고, 커리큘럼 학습을 통해 상대의 난이도를 점진적으로 증가시킵니다.

Result: 훈련된 에이전트는 균형 잡힌 상대에게 98%에서 100%의 승률을 기록하며, 도전적인 상대에게도 강력한 성과를 유지합니다.

Conclusion: 이 연구는 간략한 스포츠 시뮬레이션에서 승률 중심 최적화의 한계를 강조하며, 현실적인 스포츠 강화 학습을 위한 보상 설계의 중요성을 강조합니다.

Abstract: Tennis strategy optimization is a challenging sequential decision-making problem involving hierarchical scoring, stochastic outcomes, long-horizon credit assignment, physical fatigue, and adaptation to opponent skill. I present a reinforcement learning framework that integrates a custom tennis simulation environment with a Dueling Double Deep Q-Network(DDQN) trained using curriculum learning. The environment models complete tennis scoring at the level of points, games, and sets, rally-level tactical decisions across ten discrete action categories, symmetric fatigue dynamics, and a continuous opponent skill parameter. The dueling architecture decomposes action-value estimation into state-value and advantage components, while double Q-learning reduces overestimation bias and improves training stability in this long-horizon stochastic domain. Curriculum learning progressively increases opponent difficulty from 0.40 to 0.50, enabling robust skill acquisition without the training collapse observed under fixed opponents. Across extensive evaluations, the trained agent achieves win rates between 98 and 100 percent against balanced opponents and maintains strong performance against more challenging opponents. Serve efficiency ranges from 63.0 to 67.5 percent, and return efficiency ranges from 52.8 to 57.1 percent. Ablation studies demonstrate that both the dueling architecture and curriculum learning are necessary for stable convergence, while a standard DQN baseline fails to learn effective policies. Despite strong performance, tactical analysis reveals a pronounced defensive bias, with the learned policy prioritizing error avoidance and prolonged rallies over aggressive point construction. These results highlight a limitation of win-rate driven optimization in simplified sports simulations and emphasize the importance of reward design for realistic sports reinforcement learning.

</details>


### [20] [Emotion-Inspired Learning Signals (EILS): A Homeostatic Framework for Adaptive Autonomous Agents](https://arxiv.org/abs/2512.22200)
*Dhruv Tiwari*

Main category: cs.LG

TL;DR: 본 논문은 감정 영감을 받은 학습 신호(EILS)를 통해 AI 에이전트가 환경 변화에 잘 적응하고 더 높은 샘플 효율성을 달성할 수 있도록 하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현대 AI의 지배 방식은 정적인 보상 함수에 의존하며, 이는 개방된 환경에서의 경량성과 적응성 부족 문제를 야기한다.

Method: EILS는 감정을 연속적인 내적 평가 신호로 모델링하여 AI 에이전트가 환경을 탐색하고 변화에 적응할 수 있도록 돕는다.

Result: EILS 에이전트는 표준 기초선에 비해 샘플 효율성과 비정상적 적응 능력에서 우수한 성능을 보일 것으로 예상한다.

Conclusion: EILS는 AI 에이전트의 자율성과 적응력을 향상시키는 강력한 메커니즘이 될 수 있다.

Abstract: The ruling method in modern Artificial Intelligence spanning from Deep Reinforcement Learning (DRL) to Large Language Models (LLMs) relies on a surge of static, externally defined reward functions. While this "extrinsic maximization" approach has rendered superhuman performance in closed, stationary fields, it produces agents that are fragile in open-ended, real-world environments. Standard agents lack internal autonomy: they struggle to explore without dense feedback, fail to adapt to distribution shifts (non-stationarity), and require extensive manual tuning of static hyperparameters. This paper proposes that the unaddressed factor in robust autonomy is a functional analog to biological emotion, serving as a high-level homeostatic control mechanism. We introduce Emotion-Inspired Learning Signals (EILS), a unified framework that replaces scattered optimization heuristics with a coherent, bio-inspired internal feedback engine. Unlike traditional methods that treat emotions as semantic labels, EILS models them as continuous, homeostatic appraisal signals such as Curiosity, Stress, and Confidence. We formalize these signals as vector-valued internal states derived from interaction history. These states dynamically modulate the agent's optimization landscape in real time: curiosity regulates entropy to prevent mode collapse, stress modulates plasticity to overcome inactivity, and confidence adapts trust regions to stabilize convergence. We hypothesize that this closed-loop homeostatic regulation can enable EILS agents to outperform standard baselines in terms of sample efficiency and non-stationary adaptation.

</details>


### [21] [Fairness Evaluation of Risk Estimation Models for Lung Cancer Screening](https://arxiv.org/abs/2512.22242)
*Shaurya Gaur,Michel Vitale,Alessa Hering,Johan Kwisthout,Colin Jacobs,Lena Philipp,Fennie van der Graaf*

Main category: cs.LG

TL;DR: 폐암은 전 세계 성인에서 암 관련 사망의 주요 원인이다. 연간 저선량 CT(LDCT) 검사를 통해 고위험군의 조기 발견을 지원할 수 있으나, 방사선과 인력이 부족한 상황에서 보편적인 시행은 어려울 수 있다. AI 모델이 LDCT 스캔을 통해 폐암 위험을 추정하는 데 잠재력을 보였으나, 인구 통계 그룹 간 성능 차이가 여전히 문제로 남아 있다. 본 연구에서는 JustEFAB 프레임워크를 기반으로 폐암 선별을 위한 두 가지 딥러닝 위험 추정 모델, Sybil과 Venkadesh21을 평가하여 성능 격차와 공정성을 분석하였다.


<details>
  <summary>Details</summary>
Motivation: 폐암은 전 세계 성인에서 암 관련 사망의 주요 원인으로, 연간 저선량 CT 검사를 통해 고위험 개인의 조기 발견과 사망 감소를 지원할 수 있다. 그러나 광범위한 시행은 방사선과 인력 부족 문제를 일으킬 수 있다.

Method: 본 연구에서는 JustEFAB 프레임워크의 혼란 요인 및 윤리적 편향을 고려하여, Sybil 폐암 위험 모델과 Venkadesh21 결절 위험 추정기를 포함한 두 가지 딥러닝 모델의 성능 차이와 공정성을 평가하였다. 또한, 영국 흉부학회 결절 관리 지침에서 권장하는 PanCan2b 로지스틱 회귀 모델의 격차를 조사하였다. 두 딥러닝 모델은 미국의 National Lung Screening Trial(NLST) 데이터를 통해 훈련되었고, NLST 검증 세트에서 평가되었다.

Result: 우리는 인구 통계학적 하위 그룹 간 AUROC, 민감도 및 특이성을 평가하였고, 임상 위험 요소의 잠재적 혼란을 탐색하였다. Sybil 모델에서는 여성(0.88, 95% CI: 0.86, 0.90)과 남성(0.81, 95% CI: 0.78, 0.84) 간 AUROC에서 통계적으로 유의한 차이를 관찰하였고(p < .001), Venkadesh21 모델은 90% 특이성에서 흑인 참가자(0.39, 95% CI: 0.23, 0.59)에 대해 백인 참가자(0.69, 95% CI: 0.65, 0.73)보다 낮은 민감도를 보였다. 이러한 차이는 기존의 임상 혼란 요인으로 설명되지 않으며 JustEFAB에 따라 불공정한 편향으로 분류될 수 있다.

Conclusion: 우리의 결과는 폐암 선별에서 저대표 그룹의 모델 성능을 개선하고 모니터링하는 것의 중요성을 강조하며, 알고리즘 공정성에 대한 추가 연구의 필요성을 제기한다.

Abstract: Lung cancer is the leading cause of cancer-related mortality in adults worldwide. Screening high-risk individuals with annual low-dose CT (LDCT) can support earlier detection and reduce deaths, but widespread implementation may strain the already limited radiology workforce. AI models have shown potential in estimating lung cancer risk from LDCT scans. However, high-risk populations for lung cancer are diverse, and these models' performance across demographic groups remains an open question. In this study, we drew on the considerations on confounding factors and ethically significant biases outlined in the JustEFAB framework to evaluate potential performance disparities and fairness in two deep learning risk estimation models for lung cancer screening: the Sybil lung cancer risk model and the Venkadesh21 nodule risk estimator. We also examined disparities in the PanCan2b logistic regression model recommended in the British Thoracic Society nodule management guideline. Both deep learning models were trained on data from the US-based National Lung Screening Trial (NLST), and assessed on a held-out NLST validation set. We evaluated AUROC, sensitivity, and specificity across demographic subgroups, and explored potential confounding from clinical risk factors. We observed a statistically significant AUROC difference in Sybil's performance between women (0.88, 95% CI: 0.86, 0.90) and men (0.81, 95% CI: 0.78, 0.84, p < .001). At 90% specificity, Venkadesh21 showed lower sensitivity for Black (0.39, 95% CI: 0.23, 0.59) than White participants (0.69, 95% CI: 0.65, 0.73). These differences were not explained by available clinical confounders and thus may be classified as unfair biases according to JustEFAB. Our findings highlight the importance of improving and monitoring model performance across underrepresented subgroups, and further research on algorithmic fairness, in lung cancer screening.

</details>


### [22] [Temporal Visual Semantics-Induced Human Motion Understanding with Large Language Models](https://arxiv.org/abs/2512.22249)
*Zheng Xing,Weibing Zhao*

Main category: cs.LG

TL;DR: 본 논문은 비지도 인간 동작 분할(HMS)을 향상시키기 위해 대규모 언어 모델(LLM)을 활용하여 시간적 비전 의미(TVS)를 통합한 서브스페이스 클러스터링 기법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 HMS 방법은 시간적 의미 탐사의 역할을 간과하고 있으며, 이는 동작 분할 성능을 저해할 수 있다.

Method: LLM을 사용하여 연속 프레임에서 텍스트 동작 정보를 추출하고, 이를 서브스페이스 클러스터링 프레임워크에 통합하는 방법을 제시한다.

Result: 제안된 방법은 네 가지 벤치마크 인간 동작 데이터셋에서 기존 최첨단 접근법을 초월하는 성능을 보인다.

Conclusion: 이러한 접근법은 동작 분할에서의 성능 향상을 보여주며, LLM을 통해 시간적 의미 정보를 효과적으로 더할 수 있음을 시사한다.

Abstract: Unsupervised human motion segmentation (HMS) can be effectively achieved using subspace clustering techniques. However, traditional methods overlook the role of temporal semantic exploration in HMS. This paper explores the use of temporal vision semantics (TVS) derived from human motion sequences, leveraging the image-to-text capabilities of a large language model (LLM) to enhance subspace clustering performance. The core idea is to extract textual motion information from consecutive frames via LLM and incorporate this learned information into the subspace clustering framework. The primary challenge lies in learning TVS from human motion sequences using LLM and integrating this information into subspace clustering. To address this, we determine whether consecutive frames depict the same motion by querying the LLM and subsequently learn temporal neighboring information based on its response. We then develop a TVS-integrated subspace clustering approach, incorporating subspace embedding with a temporal regularizer that induces each frame to share similar subspace embeddings with its temporal neighbors. Additionally, segmentation is performed based on subspace embedding with a temporal constraint that induces the grouping of each frame with its temporal neighbors. We also introduce a feedback-enabled framework that continuously optimizes subspace embedding based on the segmentation output. Experimental results demonstrate that the proposed method outperforms existing state-of-the-art approaches on four benchmark human motion datasets.

</details>


### [23] [LuxIA: A Lightweight Unitary matriX-based Framework Built on an Iterative Algorithm for Photonic Neural Network Training](https://arxiv.org/abs/2512.22264)
*Tzamn Melendez Carmona,Federico Marchesin,Marco P. Abrate,Peter Bienstman,Stefano Di Carlo,Alessandro Savino Senior*

Main category: cs.LG

TL;DR: 이 논문은 포토닉 뉴럴 네트워크(PNN)의 훈련을 위한 효율적인 전송 행렬 계산 방법인 Slicing 방법을 소개하고, LuxIA라는 통합 시뮬레이션 및 훈련 프레임워크에 이 방법을 통합하여 메모리 사용량과 실행 시간을 획기적으로 줄임으로써 대규모 PNN의 시뮬레이션 및 훈련을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: PNN은 포토닉 회로의 독특한 이점을 활용하여 머신 러닝을 가속화할 수 있는 유망한 기회를 제공하지만, 대규모 PNN 훈련 시 기존 시뮬레이션 도구들이 확장성 문제에 직면하고 있다.

Method: Slicing 방법을 도입하여 효율적인 전송 행렬 계산을 지원하고, 이를 LuxIA라는 통합 시뮬레이션 및 훈련 프레임워크에 통합하였다.

Result: 다양한 포토닉 아키텍처와 표준 데이터셋에서 실험을 수행하여 LuxIA가 기존 도구들에 비해 속도와 확장성에서 일관되게 우수하다는 것을 입증하였다.

Conclusion: 이 연구는 더 효율적이고 확장 가능한 포토닉 신경망 연구 및 개발의 길을 열며, 포토닉 기술을 통해 AI 하드웨어의 혁신을 가속화한다.

Abstract: PNNs present promising opportunities for accelerating machine learning by leveraging the unique benefits of photonic circuits. However, current state of the art PNN simulation tools face significant scalability challenges when training large-scale PNNs, due to the computational demands of transfer matrix calculations, resulting in high memory and time consumption. To overcome these limitations, we introduce the Slicing method, an efficient transfer matrix computation approach compatible with back-propagation. We integrate this method into LuxIA, a unified simulation and training framework. The Slicing method substantially reduces memory usage and execution time, enabling scalable simulation and training of large PNNs. Experimental evaluations across various photonic architectures and standard datasets, including MNIST, Digits, and Olivetti Faces, show that LuxIA consistently surpasses existing tools in speed and scalability. Our results advance the state of the art in PNN simulation, making it feasible to explore and optimize larger, more complex architectures. By addressing key computational bottlenecks, LuxIA facilitates broader adoption and accelerates innovation in AI hardware through photonic technologies. This work paves the way for more efficient and scalable photonic neural network research and development.

</details>


### [24] [LLMTM: Benchmarking and Optimizing LLMs for Temporal Motif Analysis in Dynamic Graphs](https://arxiv.org/abs/2512.22266)
*Bing Hao,Minglai Shao,Zengyi Wo,Yunlong Chu,Yuhang Liu,Ruijie Wang*

Main category: cs.LG

TL;DR: 본 연구에서는 대형 언어 모델(LLM)이 동적 그래프에서의 시간적 모티프 분석에 미치는 영향을 체계적으로 조사하고, LLMTM이라는 종합 벤치마크를 제안하여 다양한 프롬프트 기술과 LLM의 성능을 비교 분석합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 동적 그래프 처리 능력에 대한 관심이 증가하고 있으며, 시간적 모티프는 이러한 그래프를 이해하는 데 필수적인 요소입니다.

Method: LLMTM이라는 벤치마크를 생성하고, 다양한 LLM 모델 및 프롬프트 기술을 사용하여 성능을 비교 분석하였습니다.

Result: 실험을 통해 구조 인식 디스패처가 높은 정확도를 유지하면서 비용을 줄일 수 있음을 입증하였습니다.

Conclusion: 구조 인식 디스패처는 동적 그래프의 구조적 속성과 LLM의 인지 부담을 고려하여 효율적인 쿼리 분배를 가능하게 하였습니다.

Abstract: The widespread application of Large Language Models (LLMs) has motivated a growing interest in their capacity for processing dynamic graphs. Temporal motifs, as an elementary unit and important local property of dynamic graphs which can directly reflect anomalies and unique phenomena, are essential for understanding their evolutionary dynamics and structural features. However, leveraging LLMs for temporal motif analysis on dynamic graphs remains relatively unexplored. In this paper, we systematically study LLM performance on temporal motif-related tasks. Specifically, we propose a comprehensive benchmark, LLMTM (Large Language Models in Temporal Motifs), which includes six tailored tasks across nine temporal motif types. We then conduct extensive experiments to analyze the impacts of different prompting techniques and LLMs (including nine models: openPangu-7B, the DeepSeek-R1-Distill-Qwen series, Qwen2.5-32B-Instruct, GPT-4o-mini, DeepSeek-R1, and o3) on model performance. Informed by our benchmark findings, we develop a tool-augmented LLM agent that leverages precisely engineered prompts to solve these tasks with high accuracy. Nevertheless, the high accuracy of the agent incurs a substantial cost. To address this trade-off, we propose a simple yet effective structure-aware dispatcher that considers both the dynamic graph's structural properties and the LLM's cognitive load to intelligently dispatch queries between the standard LLM prompting and the more powerful agent. Our experiments demonstrate that the structure-aware dispatcher effectively maintains high accuracy while reducing cost.

</details>


### [25] [Hybrid Quantum-Classical Mixture of Experts: Unlocking Topological Advantage via Interference-Based Routing](https://arxiv.org/abs/2512.22296)
*Reda Heddad,Lamiae Bouanane*

Main category: cs.LG

TL;DR: 이 논문은 양자 기계 학습(QML)을 활용한 하이브리드 양자-고전 혼합 전문가(QMoE) 아키텍처를 도입하여 혼합 전문가(MoE) 아키텍처의 한계를 해결하고자 한다.


<details>
  <summary>Details</summary>
Motivation: 혼합 전문가(MoE) 아키텍처의 한계, 특히 전문가 불균형과 전통적 라우팅 메커니즘의 복잡성을 해결하기 위한 방법을 모색하고자 한다.

Method:  양자 게이팅 네트워크(라우터)를 고전 전문가와 결합하여 양자 이점의 출처를 고립시키는 탈착 연구(ablation study)를 수행한다.

Result: 실험 결과, 양자 게이터가 선형 고전 라우터로는 분리할 수 없는 비선형 데이터를 효과적으로 '풀어내는' 중요한 위상적 이점을 달성함을 보여준다.

Conclusion: 이 아키텍처는 근시일 내에 사용할 수 있는 중간 규모 양자(NISQ) 하드웨어에 대한 실용성을 입증하며, 연합 학습, 개인 정보 보호 기계 학습 등 다양한 분야에 활용될 수 있음을 논의한다.

Abstract: The Mixture-of-Experts (MoE) architecture has emerged as a powerful paradigm for scaling deep learning models, yet it is fundamentally limited by challenges such as expert imbalance and the computational complexity of classical routing mechanisms. This paper investigates the potential of Quantum Machine Learning (QML) to address these limitations through a novel Hybrid Quantum-Classical Mixture of Experts (QMoE) architecture. Specifically, we conduct an ablation study using a Quantum Gating Network (Router) combined with classical experts to isolate the source of quantum advantage. Our central finding validates the Interference Hypothesis: by leveraging quantum feature maps (Angle Embedding) and wave interference, the Quantum Router acts as a high-dimensional kernel method, enabling the modeling of complex, non-linear decision boundaries with superior parameter efficiency compared to its classical counterparts. Experimental results on non-linearly separable data, such as the Two Moons dataset, demonstrate that the Quantum Router achieves a significant topological advantage, effectively "untangling" data distributions that linear classical routers fail to separate efficiently. Furthermore, we analyze the architecture's robustness against simulated quantum noise, confirming its feasibility for near-term intermediate-scale quantum (NISQ) hardware. We discuss practical applications in federated learning, privacy-preserving machine learning, and adaptive systems that could benefit from this quantum-enhanced routing paradigm.

</details>


### [26] [LLMBoost: Make Large Language Models Stronger with Boosting](https://arxiv.org/abs/2512.22309)
*Zehao Chen,Tianxiang Ai,Yifei Li,Gongxun Li,Yuyang Wei,Wang Zhou,Guanghui Li,Bin Yu,Zhijun Chen,Hailong Sun,Fuzhen Zhuang,Jianxin Li,Deqing Wang,Yikun Ban*

Main category: cs.LG

TL;DR: LLMBoost는 LLM의 중간 상태를 활용하여 성능을 향상시키는 새로운 앙상블 미세 조정 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 기존 앙상블 학습 접근법은 모델을 블랙 박스로 취급하며, 내부 표현과 모델 간 상호작용을 간과하는 경향이 있습니다.

Method: LLMBoost는 교차 모델 주의 메커니즘, 체인 훈련 패러다임, 근접 병렬 추론 패러다임의 세 가지 주요 혁신을 포함합니다.

Result: 광범위한 실험에서 LLMBoost는 일관되게 정확도를 향상시키고 추론 지연을 줄이는 것으로 나타났습니다.

Conclusion: 이론적 기초를 확립하고, 연속적인 통합이 제한된 수정 가정 하에서 단조로운 개선을 보장한다는 것을 증명했습니다.

Abstract: Ensemble learning of LLMs has emerged as a promising alternative to enhance performance, but existing approaches typically treat models as black boxes, combining the inputs or final outputs while overlooking the rich internal representations and interactions across models.In this work, we introduce LLMBoost, a novel ensemble fine-tuning framework that breaks this barrier by explicitly leveraging intermediate states of LLMs. Inspired by the boosting paradigm, LLMBoost incorporates three key innovations. First, a cross-model attention mechanism enables successor models to access and fuse hidden states from predecessors, facilitating hierarchical error correction and knowledge transfer. Second, a chain training paradigm progressively fine-tunes connected models with an error-suppression objective, ensuring that each model rectifies the mispredictions of its predecessor with minimal additional computation. Third, a near-parallel inference paradigm design pipelines hidden states across models layer by layer, achieving inference efficiency approaching single-model decoding. We further establish the theoretical foundations of LLMBoost, proving that sequential integration guarantees monotonic improvements under bounded correction assumptions. Extensive experiments on commonsense reasoning and arithmetic reasoning tasks demonstrate that LLMBoost consistently boosts accuracy while reducing inference latency.

</details>


### [27] [AMBIT: Augmenting Mobility Baselines with Interpretable Trees](https://arxiv.org/abs/2512.22466)
*Qizhi Wang*

Main category: cs.LG

TL;DR: AMBIT는 물리적 이동 기초 모델을 해석 가능한 트리 모델로 보강하여 높은 정확도와 해석 가능성을 동시에 충족시키는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: OD 흐름 예측은 GIS와 도시 분석의 핵심 과제이며, 실용적인 배치는 높은 정확도와 명확한 해석 가능성이라는 두 가지 상충하는 요구에 직면해 있다.

Method: 우리는 시간을 기준으로 한 1년 간의 NYC 택시 OD 데이터셋을 이용하여 고전적 공간 상호작용 모델에 대한 포괄적인 감사 작업을 수행하고, 잔여 학습자를 물리적 기초 위에 구축하여 경량 부스팅 트리와 SHAP 분석을 통해 검증했다.

Result: 물리적 기초 모델은 시간 해상도에서 취약한 반면, 물리학 기반 잔여 모델이 강력한 트리 기반 예측기의 정확도에 접근하며 해석 가능한 구조를 유지함을 보였다.

Conclusion: 제공된 파이프라인, 진단, 공간 오류 분석은 도시 의사 결정에 설계되었다.

Abstract: Origin-destination (OD) flow prediction remains a core task in GIS and urban analytics, yet practical deployments face two conflicting needs: high accuracy and clear interpretability. This paper develops AMBIT, a gray-box framework that augments physical mobility baselines with interpretable tree models. We begin with a comprehensive audit of classical spatial interaction models on a year-long, hourly NYC taxi OD dataset. The audit shows that most physical models are fragile at this temporal resolution; PPML gravity is the strongest physical baseline, while constrained variants improve when calibrated on full OD margins but remain notably weaker. We then build residual learners on top of physical baselines using gradient-boosted trees and SHAP analysis, demonstrating that (i) physics-grounded residuals approach the accuracy of a strong tree-based predictor while retaining interpretable structure, and (ii) POI-anchored residuals are consistently competitive and most robust under spatial generalization. We provide a reproducible pipeline, rich diagnostics, and spatial error analysis designed for urban decision-making.

</details>


### [28] [GLUE: Gradient-free Learning to Unify Experts](https://arxiv.org/abs/2512.22467)
*Jong-Ik Park,Shreyas Chaudhari,Srinivasa Pranav,Carlee Joe-Wong,José M. F. Moura*

Main category: cs.LG

TL;DR: GLUE는 기존의 전문가 모델을 조합하여 타겟 모델을 초기화하고, 두 번의 순방향 패스를 통해 혼합 계수를 학습하는 기법으로, 기존 방법보다 더 나은 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 다양한 전문가 모델이 있는 시스템에서 새로운 타겟 도메인을 필요로 할 때, 전문가 모델을 혼합하여 강력한 초기화를 수행할 필요가 있다.

Method: GLUE는 고정된 전문가 모델의 볼록 조합으로 타겟 모델을 초기화하고, 경량의 두 점 업데이트(SPSA)를 통해 혼합 계수를 학습한다.

Result: GLUE는 실험을 통해 8.5%까지, 프록시 메트릭 선택에 비해 9.1%까지 테스트 정확도를 향상시켰다.

Conclusion: GLUE는 백프로파게이션 기반의 전체 그래디언트 혼합 방법보다 뛰어난 성능을 보여준다.

Abstract: In many deployed systems (multilingual ASR, cross-hospital imaging, region-specific perception), multiple pretrained specialist models coexist. Yet, new target domains often require domain expansion: a generalized model that performs well beyond any single specialist's domain. Given such a new target domain, prior works seek a single strong initialization prior for the model parameters by first blending expert models to initialize a target model. However, heuristic blending -- using coefficients based on data size or proxy metrics -- often yields lower target-domain test accuracy, and learning the coefficients on the target loss typically requires computationally-expensive full backpropagation through the network. We propose GLUE, Gradient-free Learning To Unify Experts, which initializes the target model as a convex combination of fixed experts, learning the mixture coefficients of this combination via a gradient-free two-point (SPSA) update that requires only two forward passes per step. Across experiments on three datasets and three network architectures, GLUE produces a single prior that can be fine-tuned effectively to outperform baselines. GLUE improves test accuracy by up to 8.5% over data-size weighting and by up to 9.1% over proxy-metric selection. GLUE either outperforms backpropagation-based full-gradient mixing or matches its performance within 1.4%.

</details>


### [29] [KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta](https://arxiv.org/abs/2512.23236)
*Gang Liao,Hongsen Qin,Ying Wang,Alicia Golden,Michael Kuchnik,Yavuz Yetim,Jia Jiunn Ang,Chunli Fu,Yihan He,Samuel Hsia,Zewei Jiang,Dianshi Li,Uladzimir Pashkevich,Varna Puvvada,Feng Shi,Matt Steiner,Ruichao Xiao,Nathan Yan,Xiayu Yu,Zhou Fang,Abdul Zainul-Abedin,Ketan Singh,Hongtao Yu,Wenyuan Chi,Barney Huang,Sean Zhang,Noah Weller,Zach Marine,Wyatt Cook,Carole-Jean Wu,Gaoxiang Liu*

Main category: cs.LG

TL;DR: 이 논문은 DLRM의 이종성 문제를 해결하기 위해 KernelEvolve라는 에이전틱 커널 코딩 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 추천 모델(DLRM)의 훈련 및 추론을 빠르고 효율적으로 만드는 것이 중요하나, 모델 아키텍처 다양성, 커널 원시 다양성, 하드웨어 세대 및 아키텍처 이질성 등 세 가지 주요 시스템 도전 과제가 존재합니다.

Method: KernelEvolve는 커널 사양을 입력으로 받아 다양한 하드웨어 아키텍처에 걸쳐 추천 모델을 위한 커널 생성 및 최적화 과정을 자동화하도록 설계되었습니다. 여러 프로그래밍 추상화에서 작동하며, Triton과 CuTe DSL에서 저수준 하드웨어 중립 언어에 이르기까지 최적화 스택을 포괄합니다. 커널 최적화 과정은 선택 정책, 범용 연산자, 적합성 함수 및 종료 규칙을 가진 그래프 기반 검색으로 설명되며, 검색 보조 프롬프트 합성을 통해 실행 컨텍스트에 동적으로 적응합니다.

Result: KernelEvolve는 NVIDIA 및 AMD GPU 세대와 메타의 AI 가속기를 통한 다양한 생산 추천 모델을 최적화하기 위해 설계, 구현 및 배포되었습니다. KernelBench 스위트에서 100% 통과율을 달성하며 세 가지 난이도에서 250개의 문제와 세 가지 이종 하드웨어 플랫폼에 걸쳐 160개의 PyTorch ATen 연산자에서 100% 정확성을 입증했습니다.

Conclusion: KernelEvolve는 개발 시간을 주에서 시간으로 단축시키고 다양한 생산 사용 사례에서 PyTorch 기준 대비 상당한 성능 향상을 달성합니다. 또한, 새로운 AI 하드웨어를 위해 자동 커널 생성을 가능하게 하여 프로그래머블 장벽을 상당히 완화합니다.

Abstract: Making deep learning recommendation model (DLRM) training and inference fast and efficient is important. However, this presents three key system challenges - model architecture diversity, kernel primitive diversity, and hardware generation and architecture heterogeneity. This paper presents KernelEvolve-an agentic kernel coding framework-to tackle heterogeneity at-scale for DLRM. KernelEvolve is designed to take kernel specifications as input and automate the process of kernel generation and optimization for recommendation model across heterogeneous hardware architectures. KernelEvolve does so by operating at multiple programming abstractions, from Triton and CuTe DSL to low-level hardware agnostic languages, spanning the full hardware-software optimization stack. The kernel optimization process is described as graph-based search with selection policy, universal operator, fitness function, and termination rule, dynamically adapts to runtime execution context through retrieval-augmented prompt synthesis. We designed, implemented, and deployed KernelEvolve to optimize a wide variety of production recommendation models across generations of NVIDIA and AMD GPUs, as well as Meta's AI accelerators. We validate KernelEvolve on the publicly-available KernelBench suite, achieving 100% pass rate on all 250 problems across three difficulty levels, and 160 PyTorch ATen operators across three heterogeneous hardware platforms, demonstrating 100% correctness. KernelEvolve reduces development time from weeks to hours and achieves substantial performance improvements over PyTorch baselines across diverse production use cases and for heterogeneous AI systems at-scale. Beyond performance efficiency improvements, KernelEvolve significantly mitigates the programmability barrier for new AI hardware by enabling automated kernel generation for in-house developed AI hardware.

</details>


### [30] [Scaling Unverifiable Rewards: A Case Study on Visual Insights](https://arxiv.org/abs/2512.22650)
*Shuyu Gan,James Mooney,Pan Hao,Renxiang Wang,Mingyi Hong,Qianwen Wang,Dongyeop Kang*

Main category: cs.LG

TL;DR: Selective TTS는 다중 에이전트 파이프라인의 다양한 단계를 통해 추론을 확장하는 프로세스 기반의 정제 프레임워크를 제안하며, 검증할 수 없는 보상을 가진 복잡한 작업을 확장할 수 있는 첫 번째 단계로 제안됩니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트는 Test-Time Scaling(TTS)을 통해 복잡한 추론을 자동화할 가능성이 높아지고 있지만, 많은 실제 작업이 검증 가능한 보상이나 강력한 보상 모델을 훈련할 데이터를 부족하게 만드는 다단계 파이프라인을 포함하고 있다는 점에서 유도된 정제가 단계별로 오류를 축적할 우려가 있음을 설명합니다.

Method: Selective TTS는 이전 작업에 의한 시간에 따른 반복 정제 대신 다중 에이전트 파이프라인의 다양한 단계에서 추론을 확장하는 프로세스 기반 정제 프레임워크입니다. 이 방식은 단계별로 컴퓨팅을 분산하고 과정별 판별자를 사용하여 저품질 브랜치를 조기에 제거함으로써 판별자 드리프트를 완화하고 정제를 안정화합니다.

Result: 우리는 우수한 시각적 통찰을 생성하기 위해 데이터 과학 파이프라인에 기반하여 최종 사용자에 맞춘 신뢰할 수 있는 LLM 기반 판별자 모델을 설계하고, 제안된 선택적 TTS가 고정된 컴퓨팅 예산 하에서 인사이트 품질을 개선하여 평균 점수를 61.64에서 65.86으로 증가시키며 분산을 줄였음을 보여줍니다.

Conclusion: 우리의 연구 결과는 검증할 수 없는 보상을 가진 복잡하고 개방적인 작업, 예를 들어 과학적 발견 및 이야기 생성과 같은 작업을 확장하기 위한 첫 번째 단계로 작용할 것을 바랍니다.

Abstract: Large Language Model (LLM) agents can increasingly automate complex reasoning through Test-Time Scaling (TTS), iterative refinement guided by reward signals. However, many real-world tasks involve multi-stage pipeline whose final outcomes lack verifiable rewards or sufficient data to train robust reward models, making judge-based refinement prone to accumulate error over stages. We propose Selective TTS, a process-based refinement framework that scales inference across different stages in multi-agent pipeline, instead of repeated refinement over time by prior work. By distributing compute across stages and pruning low-quality branches early using process-specific judges, Selective TTS mitigates the judge drift and stabilizes refinement. Grounded in the data science pipeline, we build an end-to-end multi-agent pipeline for generating visually insightful charts and report of given dataset, and design a reliable LLM-based judge model, aligned with human experts (Kendall's τ=0.55). Our proposed selective TTS then improves insight quality under a fixed compute budget, increasing mean scores from 61.64 to 65.86 while reducing variance. We hope our findings serve as the first step toward to scaling complex, open-ended tasks with unverifiable rewards, such as scientific discovery and story generation.

</details>


### [31] [FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents](https://arxiv.org/abs/2512.22733)
*Jiaqi Shao,Yufeng Miao,Wei Zhang,Bing Luo*

Main category: cs.LG

TL;DR: 장기 지평선 강화 학습은 언어 모델의 상호작용 이력을 압축하는 맥락 접기 방법과 같은 문제에 직면한다.


<details>
  <summary>Details</summary>
Motivation: 장기 강화 학습에서 맥락의 비한정적 성장으로 인한 확장성 문제를 해결할 필요가 있다.

Method: 요약 및 행동 토큰에 대한 독립적인 기울기 신호를 위한 분리된 손실 계산, 분포 이동을 줄이기 위한 전체 맥락 일관성 손실, 계산 비용을 줄이기 위한 선택적 세그먼트 훈련이 포함된다.

Result: 우리의 방법은 비정상 관찰 문제를 다루면서 훈련 효율성을 5.19배 개선하여 장기 검색 에이전트의 안정적인 훈련을 가능하게 한다.

Conclusion: FoldAct 프레임워크는 이러한 문제를 해결하는 세 가지 주요 혁신을 통해 비정상 관찰 문제를 해결하고 훈련 효율성을 높인다.

Abstract: Long-horizon reinforcement learning (RL) for large language models faces critical scalability challenges from unbounded context growth, leading to context folding methods that compress interaction history during task execution. However, existing approaches treat summary actions as standard actions, overlooking that summaries fundamentally modify the agent's future observation space, creating a policy-dependent, non-stationary observation distribution that violates core RL assumptions. This introduces three fundamental challenges: (1) gradient dilution where summary tokens receive insufficient training signal, (2) self-conditioning where policy updates change summary distributions, creating a vicious cycle of training collapse, and (3) computational cost from processing unique contexts at each turn. We introduce \textbf{FoldAct}\footnote{https://github.com/SHAO-Jiaqi757/FoldAct}, a framework that explicitly addresses these challenges through three key innovations: separated loss computation for independent gradient signals on summary and action tokens, full context consistency loss to reduce distribution shift, and selective segment training to reduce computational cost. Our method enables stable training of long-horizon search agents with context folding, addressing the non-stationary observation problem while improving training efficiency with 5.19$\times$ speedup.

</details>


### [32] [From Confounding to Learning: Dynamic Service Fee Pricing on Third-Party Platforms](https://arxiv.org/abs/2512.22749)
*Rui Ai,David Simchi-Levi,Feng Zhu*

Main category: cs.LG

TL;DR: 이 논문은 전략적 요인을 가진 제3자 플랫폼의 가격 책정 행동을 연구하며, 공급 측 노이즈가 수요 학습 가능성에 미치는 영향을 분석하고, 깊은 신경망을 이용한 수요 학습의 효율성 보장을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 플랫폼이 수익을 극대화하고자 하는 상황에서, 수요에 영향을 미치는 시장 특성을 고려해야 하기 때문에, 수요 학습 문제를 해결하는 것이 중요합니다.

Method: 일반적인 수요 학습 문제를 해결하기 위해 최적의 후회(O(T(σ_S^(-2)) 알고리즘을 개발하여 비독립 구조의 행동을 도구 변수로 사용했습니다.

Result: 공급 측 노이즈는 수요의 학습 가능성에 근본적으로 영향을 미치며, 이는 후회에서의 단계적 전이를 초래합니다.

Conclusion: 이 접근 방식은 Zomato와 Lyft의 실제 데이터와 시뮬레이션을 통해 실용적인 적용 가능성을 입증합니다.

Abstract: We study the pricing behavior of third-party platforms facing strategic agents. Assuming the platform is a revenue maximizer, it observes market features that generally affect demand. Since only the equilibrium price and quantity are observable, this presents a general demand learning problem under confounding. Mathematically, we develop an algorithm with optimal regret of $\Tilde{\cO}(\sqrt{T}\wedgeσ_S^{-2})$. Our results reveal that supply-side noise fundamentally affects the learnability of demand, leading to a phase transition in regret. Technically, we show that non-i.i.d. actions can serve as instrumental variables for learning demand. We also propose a novel homeomorphic construction that allows us to establish estimation bounds without assuming star-shapedness, providing the first efficiency guarantee for learning demand with deep neural networks. Finally, we demonstrate the practical applicability of our approach through simulations and real-world data from Zomato and Lyft.

</details>


### [33] [TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning](https://arxiv.org/abs/2512.22824)
*Gaurav Chaudhary,Laxmidhar Behera*

Main category: cs.LG

TL;DR: 새로운 Student-Teacher 학습 패러다임을 제안하여 목표 조건 강화 학습의 효율성을 높임.


<details>
  <summary>Details</summary>
Motivation: 다양한 목표 설정에서 에이전트가 보편적인 목표 조건 정책을 학습해야 할 때 샘플 비효율성을 줄이기 위함.

Method: Temporal Variance-Driven Curriculum을 통해 교사 모듈이 정책의 신뢰도 점수에서 가장 높은 시간적 분산을 가진 목표를 prioritize하고, 이를 통해 적응적이고 집중된 학습 신호를 제공함.

Result: 11개의 다양한 로봇 조작 및 미로 탐색 작업에서 기존 커리큘럼 학습 및 목표 선택 방법에 비해 일관되고 유의미한 개선을 보여줌.

Conclusion: 제안된 방법은 기존 강화 학습 프레임워크와 매끄럽게 통합되며, Q-value의 시간적 분산과 정책의 진화 간의 이론적 연결을 제공함.

Abstract: Reinforcement Learning (RL) has achieved significant success in solving single-goal tasks. However, uniform goal selection often results in sample inefficiency in multi-goal settings where agents must learn a universal goal-conditioned policy. Inspired by the adaptive and structured learning processes observed in biological systems, we propose a novel Student-Teacher learning paradigm with a Temporal Variance-Driven Curriculum to accelerate Goal-Conditioned RL. In this framework, the teacher module dynamically prioritizes goals with the highest temporal variance in the policy's confidence score, parameterized by the state-action value (Q) function. The teacher provides an adaptive and focused learning signal by targeting these high-uncertainty goals, fostering continual and efficient progress. We establish a theoretical connection between the temporal variance of Q-values and the evolution of the policy, providing insights into the method's underlying principles. Our approach is algorithm-agnostic and integrates seamlessly with existing RL frameworks. We demonstrate this through evaluation across 11 diverse robotic manipulation and maze navigation tasks. The results show consistent and notable improvements over state-of-the-art curriculum learning and goal-selection methods.

</details>


### [34] [Theory and Algorithms for Learning with Multi-Class Abstention and Multi-Expert Deferral](https://arxiv.org/abs/2512.22886)
*Anqi Mao*

Main category: cs.LG

TL;DR: 대규모 언어 모델의 신뢰성을 높이기 위해 여러 전문가를 활용하는 학습 방법을 연구하고, 이를 통해 다양한 상황에서의 성능을 입증했다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델은 엄청난 성능을 달성했지만 환각 현상과 높은 추론 비용이라는 중요한 도전에 직면해 있다. 불확실한 입력을 더 유능한 전문가에게 위임하는 방법이 신뢰성을 높일 수 있으며, 단순한 질의는 더 작은 모델로 라우팅함으로써 효율성을 높일 수 있다.

Method: 다양한 전문가에 의한 위임 학습에 대한 포괄적인 연구를 진행했으며, 배제 학습 문제와 관련된 문제를 다루었다. 점수 기반 및 예측자-거부자 공식화를 분석하고 새로운 대리 손실 가족을 도입하여 강력한 비점근적 일관성 보장을 입증하였다.

Result: CIFAR-10, CIFAR-100 및 SVHN에 대한 실험을 통해 제안한 알고리즘의 우수한 성능을 입증했다. 또한 일반적인 다중 전문가 위임 문제에 대한 새로운 대리 손실을 설계하고, 연속 레이블 공간을 위한 위임 회귀를 위한 새로운 프레임워크를 도입하여 여러 전문가와 다양한 비용 구조를 지원했다.

Conclusion: 제안된 새로운 대리 손실은 증명된 H-일관성을 가지며, resulting algorithms의 실증적 효과를 보여준다.

Abstract: Large language models (LLMs) have achieved remarkable performance but face critical challenges: hallucinations and high inference costs. Leveraging multiple experts offers a solution: deferring uncertain inputs to more capable experts improves reliability, while routing simpler queries to smaller, distilled models enhances efficiency. This motivates the problem of learning with multiple-expert deferral. This thesis presents a comprehensive study of this problem and the related problem of learning with abstention, supported by strong consistency guarantees.
  First, for learning with abstention (a special case of deferral), we analyze score-based and predictor-rejector formulations in multi-class classification. We introduce new families of surrogate losses and prove strong non-asymptotic, hypothesis set-specific consistency guarantees, resolving two existing open questions. We analyze both single-stage and practical two-stage settings, with experiments on CIFAR-10, CIFAR-100, and SVHN demonstrating the superior performance of our algorithms.
  Second, we address general multi-expert deferral in classification. We design new surrogate losses for both single-stage and two-stage scenarios and prove they benefit from strong $H$-consistency bounds. For the two-stage scenario, we show that our surrogate losses are realizable $H$-consistent for constant cost functions, leading to effective new algorithms.
  Finally, we introduce a novel framework for regression with deferral to address continuous label spaces. Our versatile framework accommodates multiple experts and various cost structures, supporting both single-stage and two-stage methods. It subsumes recent work on regression with abstention. We propose new surrogate losses with proven $H$-consistency and demonstrate the empirical effectiveness of the resulting algorithms.

</details>


### [35] [Federated Multi-Task Clustering](https://arxiv.org/abs/2512.22897)
*S. Dai,G. Sun,F. Li,X. Tang,Q. Wang,Y. Cong*

Main category: cs.LG

TL;DR: 본 논문은 분산 환경에서 개인화된 클러스터링 모델을 학습하기 위한 새로운 프레임워크인 Federated Multi-Task Clustering (FMTC)을 제안하며, 이는 기존의 연합 학습 접근법의 한계를 극복하고 개인 클라이언트 간의 공유 구조를 활용하는 데 초점을 맞추고 있다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 기존 클러스터링 모델이 중앙 집중식 환경에 맞춰져 있어 분산 환경에서는 사용할 수 없으며, 현재의 연합 학습 접근법이 신뢰할 수 없는 의사 레이블에 의존해 일반화 성능이 좋지 않고 이질적인 클라이언트 간의 잠재적 상관관계를 포착하지 못하는 문제를 해결하고자 한다.

Method: FMTC 프레임워크는 두 가지 주요 구성요소로 이루어져 있다: 클라이언트 측의 개인화 클러스터링 모듈과 서버 측의 텐서 상관관계 모듈이다. 클라이언트 모듈은 강력한 샘플 외 추론을 지원하기 위해 매개변수화된 매핑 모델을 학습하고, 서버 모듈은 모든 클라이언트 간의 공유 지식을 포착한다.

Result: 여러 실세계 데이터셋에 대한 광범위한 실험을 통해 제안된 FMTC 프레임워크가 다양한 기준선 및 최신 연합 클러스터링 알고리즘보다 상당히 우수한 성능을 보임을 입증하였다.

Conclusion: FMTC는 개인화된 클러스터링 학습을 통해 현대의 분산 환경에서 효과적으로 작동할 수 있음을 보여준다.

Abstract: Spectral clustering has emerged as one of the most effective clustering algorithms due to its superior performance. However, most existing models are designed for centralized settings, rendering them inapplicable in modern decentralized environments. Moreover, current federated learning approaches often suffer from poor generalization performance due to reliance on unreliable pseudo-labels, and fail to capture the latent correlations amongst heterogeneous clients. To tackle these limitations, this paper proposes a novel framework named Federated Multi-Task Clustering (i.e.,FMTC), which intends to learn personalized clustering models for heterogeneous clients while collaboratively leveraging their shared underlying structure in a privacy-preserving manner. More specifically, the FMTC framework is composed of two main components: client-side personalized clustering module, which learns a parameterized mapping model to support robust out-of-sample inference, bypassing the need for unreliable pseudo-labels; and server-side tensorial correlation module, which explicitly captures the shared knowledge across all clients. This is achieved by organizing all client models into a unified tensor and applying a low-rank regularization to discover their common subspace. To solve this joint optimization problem, we derive an efficient, privacy-preserving distributed algorithm based on the Alternating Direction Method of Multipliers, which decomposes the global problem into parallel local updates on clients and an aggregation step on the server. To the end, several extensive experiments on multiple real-world datasets demonstrate that our proposed FMTC framework significantly outperforms various baseline and state-of-the-art federated clustering algorithms.

</details>


### [36] [A Context-Aware Temporal Modeling through Unified Multi-Scale Temporal Encoding and Hierarchical Sequence Learning for Single-Channel EEG Sleep Staging](https://arxiv.org/abs/2512.22976)
*Amirali Vakili,Salar Jahanshiri,Armin Salimi-Badr*

Main category: cs.LG

TL;DR: 이 연구는 단일 채널 뇌파(EEG)를 사용한 자동 수면 단계 분류를 위한 새로운 프레임워크를 제안하며, N1 단계 감지를 개선하는 데 중점을 두고 있다.


<details>
  <summary>Details</summary>
Motivation: 수면 장애의 전 세계적인 확산으로 인해 자동 수면 단계 분류는 중요한 의료 과제이다.

Method: 단일 채널 EEG 수면 단계 분류를 위한 맥락 인식 및 해석 가능한 프레임워크를 제안하며, 다중 스케일 특징 추출 및 시간 모델링을 결합한다.

Result: 전체 정확도 89.72% 및 매크로 평균 F1 점수 85.46%로 N1 단계에서 61.7%의 F1 점수를 달성하였다.

Conclusion: 제안된 접근법은 해석 가능성과 실제 임상 응용에 적합함을 유지하면서 수면 단계 분류 성능을 효과적으로 개선한다.

Abstract: Automatic sleep staging is a critical task in healthcare due to the global prevalence of sleep disorders. This study focuses on single-channel electroencephalography (EEG), a practical and widely available signal for automatic sleep staging. Existing approaches face challenges such as class imbalance, limited receptive-field modeling, and insufficient interpretability. This work proposes a context-aware and interpretable framework for single-channel EEG sleep staging, with particular emphasis on improving detection of the N1 stage. Many prior models operate as black boxes with stacked layers, lacking clearly defined and interpretable feature extraction roles.The proposed model combines compact multi-scale feature extraction with temporal modeling to capture both local and long-range dependencies. To address data imbalance, especially in the N1 stage, classweighted loss functions and data augmentation are applied. EEG signals are segmented into sub-epoch chunks, and final predictions are obtained by averaging softmax probabilities across chunks, enhancing contextual representation and robustness.The proposed framework achieves an overall accuracy of 89.72% and a macro-average F1-score of 85.46%. Notably, it attains an F1- score of 61.7% for the challenging N1 stage, demonstrating a substantial improvement over previous methods on the SleepEDF datasets. These results indicate that the proposed approach effectively improves sleep staging performance while maintaining interpretability and suitability for real-world clinical applications.

</details>


### [37] [Principled Algorithms for Optimizing Generalized Metrics in Binary Classification](https://arxiv.org/abs/2512.23133)
*Anqi Mao,Mehryar Mohri,Yutao Zhong*

Main category: cs.LG

TL;DR: 기존의 비대칭 비용 문제에 대해 최적화된 평가 기준을 사용하는 새로운 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 클래스 불균형이나 비대칭 비용이 중요한 응용 분야에서 평가 기준을 개선할 필요성이 있다.

Method: 일반화된 메트릭 최적화를 위해 H-일관성과 유한 샘플 일반화 경계를 지원하는 원칙적인 알고리즘을 제안하며, 이를 일반화된 비용 민감 학습 문제로 재구성하여 새로운 대리 손실 함수를 설계한다.

Result: 새로운 알고리즘 METRO(메트릭 최적화)를 개발하고, 실험 결과는 기존 방식보다 더 효과적임을 보인다.

Conclusion: 새롭고 이론적으로 강한 성능 보장을 제공하는 알고리즘을 통해 기존 접근 방식과 차별화됨을 입증한다.

Abstract: In applications with significant class imbalance or asymmetric costs, metrics such as the $F_β$-measure, AM measure, Jaccard similarity coefficient, and weighted accuracy offer more suitable evaluation criteria than standard binary classification loss. However, optimizing these metrics present significant computational and statistical challenges. Existing approaches often rely on the characterization of the Bayes-optimal classifier, and use threshold-based methods that first estimate class probabilities and then seek an optimal threshold. This leads to algorithms that are not tailored to restricted hypothesis sets and lack finite-sample performance guarantees. In this work, we introduce principled algorithms for optimizing generalized metrics, supported by $H$-consistency and finite-sample generalization bounds. Our approach reformulates metric optimization as a generalized cost-sensitive learning problem, enabling the design of novel surrogate loss functions with provable $H$-consistency guarantees. Leveraging this framework, we develop new algorithms, METRO (Metric Optimization), with strong theoretical performance guarantees. We report the results of experiments demonstrating the effectiveness of our methods compared to prior baselines.

</details>


### [38] [Graph Neural Networks with Transformer Fusion of Brain Connectivity Dynamics and Tabular Data for Forecasting Future Tobacco Use](https://arxiv.org/abs/2512.23137)
*Runzhi Zhou,Xi Luo*

Main category: cs.LG

TL;DR: 이 논문은 비유클리드 뇌 영상 데이터와 유클리드 표 형태의 데이터를 통합하여 예측 정확도를 높이는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상 분석에서 비유클리드 뇌 영상 데이터와 유클리드 표 데이터를 통합하는 것은 큰 도전 과제입니다.

Method: 우리는 변환기 융합(transformer fusion) 기법을 사용한 시간 인식 그래프 신경망 모델을 제안합니다.

Result: GNN-TF는 기존 머신 러닝 및 딥 러닝 모델에 비해 뛰어난 예측 정확도를 제공합니다.

Conclusion: 이 모델은 다양한 데이터 모달리티를 통합하고 시간적 동향을 활용하여 기능적 뇌 영상 연구에서 유용한 분석 도구로 작용합니다.

Abstract: Integrating non-Euclidean brain imaging data with Euclidean tabular data, such as clinical and demographic information, poses a substantial challenge for medical imaging analysis, particularly in forecasting future outcomes. While machine learning and deep learning techniques have been applied successfully to cross-sectional classification and prediction tasks, effectively forecasting outcomes in longitudinal imaging studies remains challenging. To address this challenge, we introduce a time-aware graph neural network model with transformer fusion (GNN-TF). This model flexibly integrates both tabular data and dynamic brain connectivity data, leveraging the temporal order of these variables within a coherent framework. By incorporating non-Euclidean and Euclidean sources of information from a longitudinal resting-state fMRI dataset from the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA), the GNN-TF enables a comprehensive analysis that captures critical aspects of longitudinal imaging data. Comparative analyses against a variety of established machine learning and deep learning models demonstrate that GNN-TF outperforms these state-of-the-art methods, delivering superior predictive accuracy for predicting future tobacco usage. The end-to-end, time-aware transformer fusion structure of the proposed GNN-TF model successfully integrates multiple data modalities and leverages temporal dynamics, making it a valuable analytic tool for functional brain imaging studies focused on clinical outcome prediction.

</details>


### [39] [A Weak Signal Learning Dataset and Its Baseline Method](https://arxiv.org/abs/2512.23160)
*Xianqi Liu,Xiangru Li,Lefeng He,Ziyu Fang*

Main category: cs.LG

TL;DR: 약한 신호 학습(WSL)은 많은 분야에서 발생하는 도전 과제이며, 본 연구에서는 최초의 전문 데이터셋을 구축하고, PDVFN 모델을 제안하여 약한 신호 탐지를 개선하고자 하였다.


<details>
  <summary>Details</summary>
Motivation: 약한 신호 학습은 고장이 발생한 진단, 의료 영상, 자율주행 등 다양한 분야에서 중요한 정보를 간섭과 노이즈로 인해 식별하기 어려운 문제로, 이 문제를 해결하기 위한 전문 데이터셋이 부족하였다.

Method: 13,158개의 스펙트럼 샘플을 포함한 전문 데이터셋을 구축하고, 낮은 SNR, 분포 편향 및 이중 불균형에 맞춰 설계된 PDVFN 모델을 제안하였다. 이 모델은 지역적 연속 특징과 전세계 주파수 구조를 병렬로 추출한다.

Result: 우리 방법은 약한 신호, 높은 노이즈, 극단적 클래스 불균형을 처리하는 데 있어 더 높은 정확도와 강건성을 달성하였다.

Conclusion: 본 연구는 전문 데이터셋과 기본 모델을 제공하며, 향후 약한 신호 학습 연구를 위한 기초를 다졌다.

Abstract: Weak signal learning (WSL) is a common challenge in many fields like fault diagnosis, medical imaging, and autonomous driving, where critical information is often masked by noise and interference, making feature identification difficult. Even in tasks with abundant strong signals, the key to improving model performance often lies in effectively extracting weak signals. However, the lack of dedicated datasets has long constrained research. To address this, we construct the first specialized dataset for weak signal feature learning, containing 13,158 spectral samples. It features low SNR dominance (over 55% samples with SNR below 50) and extreme class imbalance (class ratio up to 29:1), providing a challenging benchmark for classification and regression in weak signal scenarios. We also propose a dual-view representation (vector + time-frequency map) and a PDVFN model tailored to low SNR, distribution skew, and dual imbalance. PDVFN extracts local sequential features and global frequency-domain structures in parallel, following principles of local enhancement, sequential modeling, noise suppression, multi-scale capture, frequency extraction, and global perception. This multi-source complementarity enhances representation for low-SNR and imbalanced data, offering a novel solution for WSL tasks like astronomical spectroscopy. Experiments show our method achieves higher accuracy and robustness in handling weak signals, high noise, and extreme class imbalance, especially in low SNR and imbalanced scenarios. This study provides a dedicated dataset, a baseline model, and establishes a foundation for future WSL research.

</details>


### [40] [A Simple, Optimal and Efficient Algorithm for Online Exp-Concave Optimization](https://arxiv.org/abs/2512.23190)
*Yi-Han Wang,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 이 논문은 ONS의 효율성을 개선하는 LightONS라는 새로운 변종을 제안하여 SXO 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 온라인 학습에서 OXO 문제 해결의 필요성과 ONS 알고리즘의 한계를 극복하기 위한 연구가 필요함을 설명합니다.

Method: LightONS라는 알고리즘을 제안하여 총 런타임을 $O(d^2 T + d^ω	ext{sqrt}{T 	ext{log} T})$로 줄이고, ONS의 최적 손해를 유지합니다.

Result: LightONS는 SXO 문제에 대한 새로운 방법론을 제공하며, 런타임을 $	ilde{O}(d^3/ε)$로 줄입니다.

Conclusion: LightONS는 ONS 대신 사용될 수 있는 효율적인 대안으로, 다양한 온라인 학습 문제에 적용 가능성을 제공합니다.

Abstract: Online eXp-concave Optimization (OXO) is a fundamental problem in online learning. The standard algorithm, Online Newton Step (ONS), balances statistical optimality and computational practicality, guaranteeing an optimal regret of $O(d \log T)$, where $d$ is the dimension and $T$ is the time horizon. ONS faces a computational bottleneck due to the Mahalanobis projections at each round. This step costs $Ω(d^ω)$ arithmetic operations for bounded domains, even for the unit ball, where $ω\in (2,3]$ is the matrix-multiplication exponent. As a result, the total runtime can reach $\tilde{O}(d^ωT)$, particularly when iterates frequently oscillate near the domain boundary. For Stochastic eXp-concave Optimization (SXO), computational cost is also a challenge. Deploying ONS with online-to-batch conversion for SXO requires $T = \tilde{O}(d/ε)$ rounds to achieve an excess risk of $ε$, and thereby necessitates an $\tilde{O}(d^{ω+1}/ε)$ runtime. A COLT'13 open problem posed by Koren [2013] asks for an SXO algorithm with runtime less than $\tilde{O}(d^{ω+1}/ε)$.
  This paper proposes a simple variant of ONS, LightONS, which reduces the total runtime to $O(d^2 T + d^ω\sqrt{T \log T})$ while preserving the optimal $O(d \log T)$ regret. LightONS implies an SXO method with runtime $\tilde{O}(d^3/ε)$, thereby answering the open problem. Importantly, LightONS preserves the elegant structure of ONS by leveraging domain-conversion techniques from parameter-free online learning to introduce a hysteresis mechanism that delays expensive Mahalanobis projections until necessary. This design enables LightONS to serve as an efficient plug-in replacement of ONS in broader scenarios, even beyond regret minimization, including gradient-norm adaptive regret, parametric stochastic bandits, and memory-efficient online learning.

</details>


### [41] [FairGFL: Privacy-Preserving Fairness-Aware Federated Learning with Overlapping Subgraphs](https://arxiv.org/abs/2512.23235)
*Zihao Zhou,Shusen Yang,Fangyuan Zhao,Xuebin Ren*

Main category: cs.LG

TL;DR: FairGFL은 불균형 겹침 서브그래프 문제를 해결하여, 크로스 클라이언트 공정성을 높이고 모델 유용성을 유지하는 새로운 알고리즘이다.


<details>
  <summary>Details</summary>
Motivation: 그래프 연합 학습의 공정성 문제를 해결하기 위하여.

Method: FairGFL 알고리즘은 겹침 비율을 추정하여 공정성을 높이고, 연합 합성 손실 함수에 세심하게 설계된 정규화를 통합한다.

Result: FairGFL은 네 가지 벤치마크 그래프 데이터셋에서 Model utility와 fairness 면에서 네 가지 대표 기준 알고리즘보다 뛰어난 성능을 보여준다.

Conclusion: 이 연구는 불균형 겹치는 서브그래프에서 발생하는 공정성 문제를 해결함으로써 그래프 연합 학습의 잠재력을 확장한다.

Abstract: Graph federated learning enables the collaborative extraction of high-order information from distributed subgraphs while preserving the privacy of raw data. However, graph data often exhibits overlap among different clients. Previous research has demonstrated certain benefits of overlapping data in mitigating data heterogeneity. However, the negative effects have not been explored, particularly in cases where the overlaps are imbalanced across clients. In this paper, we uncover the unfairness issue arising from imbalanced overlapping subgraphs through both empirical observations and theoretical reasoning. To address this issue, we propose FairGFL (FAIRness-aware subGraph Federated Learning), a novel algorithm that enhances cross-client fairness while maintaining model utility in a privacy-preserving manner. Specifically, FairGFL incorporates an interpretable weighted aggregation approach to enhance fairness across clients, leveraging privacy-preserving estimation of their overlapping ratios. Furthermore, FairGFL improves the tradeoff between model utility and fairness by integrating a carefully crafted regularizer into the federated composite loss function. Through extensive experiments on four benchmark graph datasets, we demonstrate that FairGFL outperforms four representative baseline algorithms in terms of both model utility and fairness.

</details>


### [42] [ECG-RAMBA: Zero-Shot ECG Generalization by Morphology-Rhythm Disentanglement and Long-Range Modeling](https://arxiv.org/abs/2512.23347)
*Hai Duong Nguyen,Xuan-The Tran*

Main category: cs.LG

TL;DR: ECG-RAMBA라는 새로운 프레임워크를 제안하여 심전도 신호의 형태와 리듬을 분리하고 연결함으로써 다양한 환경에서의 일반화 성능을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 심전도(ECG) 분류의 임상적 배치와 장기적 모니터링을 위한 데이터의 이질적인 얻기 관련 환경에서의 안전한 일반화는 여전히 큰 장애물이다.

Method: ECG-RAMBA는 MiniRocket에 의해 추출된 결정론적 형태 기능, 심박 변동성(HRV)에서 계산된 전역 리듬 기술자, 양 방향 Mamba 백본을 통한 장거리 컨텍스트 모델링을 결합한다.

Result: Chapman--Shaoxing 데이터 세트에서 ECG-RAMBA는 매크로 ROC-AUC 약 0.85를 달성하고, CPSC-2021 데이터 세트에서 심방세동 탐지에 대해 PR-AUC 0.708을 달성하며, PTB-XL에서 일관된 크로스 데이터 세트 성능을 보인다.

Conclusion: 결정론적 형태가 강한 기반을 제공하는 반면, 명시적인 리듬 모델링과 장거리 컨텍스트가 크로스 도메인 강건성의 중요한 원동력임을 보여준다.

Abstract: Deep learning has achieved strong performance for electrocardiogram (ECG) classification within individual datasets, yet dependable generalization across heterogeneous acquisition settings remains a major obstacle to clinical deployment and longitudinal monitoring. A key limitation of many model architectures is the implicit entanglement of morphological waveform patterns and rhythm dynamics, which can promote shortcut learning and amplify sensitivity to distribution shifts. We propose ECG-RAMBA, a framework that separates morphology and rhythm and then re-integrates them through context-aware fusion. ECG-RAMBA combines: (i) deterministic morphological features extracted by MiniRocket, (ii) global rhythm descriptors computed from heart-rate variability (HRV), and (iii) long-range contextual modeling via a bi-directional Mamba backbone. To improve sensitivity to transient abnormalities under windowed inference, we introduce a numerically stable Power Mean pooling operator ($Q=3$) that emphasizes high-evidence segments while avoiding the brittleness of max pooling and the dilution of averaging. We evaluate under a protocol-faithful setting with subject-level cross-validation, a fixed decision threshold, and no test-time adaptation. On the Chapman--Shaoxing dataset, ECG-RAMBA achieves a macro ROC-AUC $\approx 0.85$. In zero-shot transfer, it attains PR-AUC $=0.708$ for atrial fibrillation detection on the external CPSC-2021 dataset, substantially outperforming a comparable raw-signal Mamba baseline, and shows consistent cross-dataset performance on PTB-XL. Ablation studies indicate that deterministic morphology provides a strong foundation, while explicit rhythm modeling and long-range context are critical drivers of cross-domain robustness.

</details>


### [43] [Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2](https://arxiv.org/abs/2512.23367)
*Yilun Luo,HuaQing Zheng,Haoqian Meng,Wenyuan Liu,Peng Zhang*

Main category: cs.LG

TL;DR: 이 논문은 openPangu-Embedded 모델의 Chain-of-Thought(CoT) 추론에서 메모리 및 지연 문제를 해결하기 위해 저비트 양자화를 사용하여 효율적인 추론 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: openPangu 모델이 CoT 추론 모드를 통합하였지만, 높은 메모리와 지연 문제로 인해 실제 사용에 어려움이 있다.

Method: FP16 연산을 정수 산술로 변환하는 저비트 양자화를 활용한 통합 저비트 추론 프레임워크를 도입하였다. 이 프레임워크는 INT8(W8A8) 및 W4A8 양자화를 지원하고 Atlas A2에 최적화되었다.

Result: 이 접근 방식의 효과를 보여주는 평가에서는 INT8 양자화가 FP16 기준 정확도를 90% 이상 유지하고 Atlas A2에서 1.5배의 속도 향상을 달성하였다.

Conclusion: 저비트 양자화는 Ascend NPU에서 효율적인 CoT 추론을 가능하게 하여 높은 모델 충실성을 유지함을 나타낸다.

Abstract: Huawei's openPangu-Embedded-1B and openPangu-Embedded-7B, variants of the openPangu large language model, integrate three distinct Chain-of-Thought (CoT) reasoning paradigms, namely slow_think, auto_think, and no_think. While these CoT modes enhance reasoning capabilities, their generation of extended reasoning traces introduces substantial memory and latency overheads, posing challenges for practical deployment on Ascend NPUs. This paper addresses these computational constraints by leveraging low-bit quantization, which transforms FP16 computations into more efficient integer arithmetic. We introduce a unified low-bit inference framework, supporting INT8 (W8A8) and W4A8 quantization, specifically optimized for openPangu-Embedded models on the Atlas A2. Our comprehensive evaluation, conducted across all three CoT modes on code generation benchmarks (HumanEval and MBPP), demonstrates the efficacy of this approach. INT8 quantization consistently preserves over 90\% of the FP16 baseline accuracy and achieves a 1.5x prefill speedup on the Atlas A2. Furthermore, W4A8 quantization significantly reduces memory consumption, albeit with a moderate trade-off in accuracy. These findings collectively indicate that low-bit quantization effectively facilitates efficient CoT reasoning on Ascend NPUs, maintaining high model fidelity.

</details>


### [44] [Diffusion priors enhanced velocity model building from time-lag images using a neural operator](https://arxiv.org/abs/2512.23375)
*Xiao Ma,Mohammad Hasyim Taufik,Tariq Alkhalifah*

Main category: cs.LG

TL;DR: 딥 러닝 기반의 생성 모델과 신경 연산자를 결합하여 고해상도 속도 모델을 효율적으로 구축하는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 정밀한 지하 이미징을 위해 필수적인 속도 모델 구축의 전통적인 방법은 비용이 많이 들고 시간이 소요됩니다.

Method: 생성 모델을 신경 연산자와 결합하여 실제와 이주 속도 모델을 기반으로 신속하게 시간 지연 역방향 시간 이동(RTM) 이미지를 생성하는 워크플로우를 개발했습니다.

Result: 신경 연산자가 자동 미분을 통해 실제 속도 입력 채널에 고해상도 구성 요소로 이식된 이주 속도를 지속적으로 업데이트하여 네트워크의 출력이 이주 속도를 사용하여 얻은 관측 데이터의 시간 지연 이미지와 일치하도록 합니다.

Conclusion: 합성 및 필드 데이터 실험을 통해 제안된 생성 신경 연산자 기반 속도 모델 구축 방법의 효과를 입증했습니다.

Abstract: Velocity model building serves as a crucial component for achieving high precision subsurface imaging. However, conventional velocity model building methods are often computationally expensive and time consuming. In recent years, with the rapid advancement of deep learning, particularly the success of generative models and neural operators, deep learning based approaches that integrate data and their statistics have attracted increasing attention in addressing the limitations of traditional methods. In this study, we propose a novel framework that combines generative models with neural operators to obtain high resolution velocity models efficiently. Within this workflow, the neural operator functions as a forward mapping operator to rapidly generate time lag reverse time migration (RTM) extended images from the true and migration velocity models. In this framework, the neural operator is acting as a surrogate for modeling followed by migration, which uses the true and migration velocities, respectively. The trained neural operator is then employed, through automatic differentiation, to gradually update the migration velocity placed in the true velocity input channel with high resolution components so that the output of the network matches the time lag images of observed data obtained using the migration velocity. By embedding a generative model, trained on a high-resolution velocity model distribution, which corresponds to the true velocity model distribution used to train the neural operator, as a regularizer, the resulting predictions are cleaner with higher resolution information. Both synthetic and field data experiments demonstrate the effectiveness of the proposed generative neural operator based velocity model building approach.

</details>


### [45] [On the Sample Complexity of Learning for Blind Inverse Problems](https://arxiv.org/abs/2512.23405)
*Nathan Buskulic,Luca Calatroni,Lorenzo Rosasco,Silvia Villa*

Main category: cs.LG

TL;DR: 이 논문은 블라인드 역문제에 대한 새로운 해석적 접근 방식을 제시하며, 최적 추정을 위한 닫힌 형태의 식을 유도합니다.


<details>
  <summary>Details</summary>
Motivation: 블라인드 역문제는 실험적 설정에서 자주 발생하며, 기존의 비블라인드 경우에 대한 방법이 적용되기 어려운 상황입니다.

Method: 이 논문에서는 선형 최소 평균 제곱 추정기(LMMSE)의 간소화된 프레임워크 내에서 블라인드 역문제의 학습을 다루며, 최적 추정기를 위한 닫힌 형태의 표현식을 도출합니다.

Result: 정규화가 알려지지 않은 신호, 노이즈 및 무작위 전방 연산자의 분포에 명시적으로 의존하는 티콘노프 정규화된 공식과의 동등성을 확립하며, 적절한 원천 조건 가정 하에서 수렴 결과를 증명합니다.

Conclusion: 본 연구는 이론적 발견을 수치적 실험을 통해 검증하였으며, 연산자 무작위성의 영향을 정량화하고 관련된 수렴 속도를 드러냅니다.

Abstract: Blind inverse problems arise in many experimental settings where the forward operator is partially or entirely unknown. In this context, methods developed for the non-blind case cannot be adapted in a straightforward manner. Recently, data-driven approaches have been proposed to address blind inverse problems, demonstrating strong empirical performance and adaptability. However, these methods often lack interpretability and are not supported by rigorous theoretical guarantees, limiting their reliability in applied domains such as imaging inverse problems. In this work, we shed light on learning in blind inverse problems within the simplified yet insightful framework of Linear Minimum Mean Square Estimators (LMMSEs). We provide an in-depth theoretical analysis, deriving closed-form expressions for optimal estimators and extending classical results. In particular, we establish equivalences with suitably chosen Tikhonov-regularized formulations, where the regularization depends explicitly on the distributions of the unknown signal, the noise, and the random forward operators. We also prove convergence results under appropriate source condition assumptions. Furthermore, we derive rigorous finite-sample error bounds that characterize the performance of learned estimators as a function of the noise level, problem conditioning, and number of available samples. These bounds explicitly quantify the impact of operator randomness and reveal the associated convergence rates as this randomness vanishes. Finally, we validate our theoretical findings through illustrative numerical experiments that confirm the predicted convergence behavior.

</details>


### [46] [Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning](https://arxiv.org/abs/2512.23617)
*Deniz Akdemir*

Main category: cs.LG

TL;DR: 이 논문은 비대칭 도메인에서의 정보 전송 위험을 최소화하기 위해 기초적인 개념에서 벗어난 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 기계 학습에서 분포 이동은 주요 도전 과제입니다. 기존의 비지도 도메인 적응 방법은 기능 불변성을 강요하지만, 이는 정보 손실을 초래하며, 특히 안전에 민감한 응용 프로그램에서 부정적인 이전이 발생할 수 있습니다.

Method: Le Cam의 통계 실험 이론을 기반으로 한 의사결정 이론적 프레임워크를 제안하며, 대칭 불변성 대신 방향성 시뮬러블리티를 사용할 수 있도록 구성적 근사치를 활용합니다.

Result: Le Cam Distortion은 HLA 유전체에서 거의 완벽한 주파수 추정, CIFAR-10 이미지 분류에서의 출처 유틸리티 손실 제로, RL 제어에서 안전한 정책 이전을 달성합니다.

Conclusion: Le Cam Distortion은 부정적인 이전이 용납될 수 없는 도메인에서 위험이 제어되는 이전 학습을 위한 최초의 원칙적 프레임워크를 제공합니다.

Abstract: Distribution shift is the defining challenge of real-world machine learning. The dominant paradigm--Unsupervised Domain Adaptation (UDA)--enforces feature invariance, aligning source and target representations via symmetric divergence minimization [Ganin et al., 2016]. We demonstrate that this approach is fundamentally flawed: when domains are unequally informative (e.g., high-quality vs degraded sensors), strict invariance necessitates information destruction, causing "negative transfer" that can be catastrophic in safety-critical applications [Wang et al., 2019].
  We propose a decision-theoretic framework grounded in Le Cam's theory of statistical experiments [Le Cam, 1986], using constructive approximations to replace symmetric invariance with directional simulability. We introduce Le Cam Distortion, quantified by the Deficiency Distance $δ(E_1, E_2)$, as a rigorous upper bound for transfer risk conditional on simulability. Our framework enables transfer without source degradation by learning a kernel that simulates the target from the source. Across five experiments (genomics, vision, reinforcement learning), Le Cam Distortion achieves: (1) near-perfect frequency estimation in HLA genomics (correlation $r=0.999$, matching classical methods), (2) zero source utility loss in CIFAR-10 image classification (81.2% accuracy preserved vs 34.7% drop for CycleGAN), and (3) safe policy transfer in RL control where invariance-based methods suffer catastrophic collapse. Le Cam Distortion provides the first principled framework for risk-controlled transfer learning in domains where negative transfer is unacceptable: medical imaging, autonomous systems, and precision medicine.

</details>


### [47] [BOAD: Discovering Hierarchical Software Engineering Agents via Bandit Optimization](https://arxiv.org/abs/2512.23631)
*Iris Xu,Guangtao Zeng,Zexue He,Charles Jin,Aldo Pareja,Dan Gutfreund,Chuang Gan,Zhang-Wei Hong*

Main category: cs.LG

TL;DR: 대형 언어 모델이 복잡한 소프트웨어 엔지니어링 문제를 해결하기 위해 계층적 다중 에이전트 시스템을 제안하며, 이는 적은 평가 예산으로 효율적인 탐색을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 인간 엔지니어들이 복잡한 문제를 분해하는 방식을 통해 영감을 받았다.

Method: 소프트웨어 엔지니어링 에이전트를 전문화된 하위 에이전트를 조정하는 오케스트레이터로 구조화하고, 이를 다중무장 강도(MAB) 문제로 정형화하여 자동으로 효율적인 계층 발견을 가능하게 했다.

Result: BOAD는 SWE-bench-Verified에서 단일 에이전트 및 수동 설계된 다중 에이전트 시스템보다 우수한 성능을 나타냈으며, SWE-bench-Live에서는 GPT-4 및 Claude보다 높은 점수를 기록했다.

Conclusion: 자동으로 발견된 계층적 다중 에이전트 시스템이 장기적인 소프트웨어 엔지니어링 작업에서 일반화 성능을 크게 향상시킨다는 것을 보여준다.

Abstract: Large language models (LLMs) have shown strong reasoning and coding capabilities, yet they struggle to generalize to real-world software engineering (SWE) problems that are long-horizon and out of distribution. Existing systems often rely on a single agent to handle the entire workflow-interpreting issues, navigating large codebases, and implementing fixes-within one reasoning chain. Such monolithic designs force the model to retain irrelevant context, leading to spurious correlations and poor generalization. Motivated by how human engineers decompose complex problems, we propose structuring SWE agents as orchestrators coordinating specialized sub-agents for sub-tasks such as localization, editing, and validation. The challenge lies in discovering effective hierarchies automatically: as the number of sub-agents grows, the search space becomes combinatorial, and it is difficult to attribute credit to individual sub-agents within a team. We address these challenges by formulating hierarchy discovery as a multi-armed bandit (MAB) problem, where each arm represents a candidate sub-agent and the reward measures its helpfulness when collaborating with others. This framework, termed Bandit Optimization for Agent Design (BOAD), enables efficient exploration of sub-agent designs under limited evaluation budgets. On SWE-bench-Verified, BOAD outperforms single-agent and manually designed multi-agent systems. On SWE-bench-Live, featuring more recent and out-of-distribution issues, our 36B system ranks second on the leaderboard at the time of evaluation, surpassing larger models such as GPT-4 and Claude. These results demonstrate that automatically discovered hierarchical multi-agent systems significantly improve generalization on challenging long-horizon SWE tasks. Code is available at https://github.com/iamxjy/BOAD-SWE-Agent.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [48] [With Great Capabilities Come Great Responsibilities: Introducing the Agentic Risk & Capability Framework for Governing Agentic AI Systems](https://arxiv.org/abs/2512.22211)
*Shaun Khoo,Jessica Foo,Roy Ka-Wei Lee*

Main category: cs.AI

TL;DR: 에이전틱 AI 시스템은 자율적 행동 능력으로 인해 기회와 새로운 위험을 동시에 제공한다. 이를 해결하기 위해 Agentic Risk & Capability (ARC) 프레임워크를 제안하며, 이는 위험 식별, 평가, 완화를 지원하는 기술적 거버넌스 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 에이전틱 AI 시스템의 자율적인 행동 능력은 새로운 기회와 위험을 제시하며, 이를 효과적으로 관리하기 위한 필요성이 있다.

Method: ARC 프레임워크는 에이전틱 AI 시스템의 위험을 식별하고 평가하며 완화하기 위해 개발된 기술적 거버넌스 프레임워크이다.

Result: 이 프레임워크는 에이전틱 AI 시스템의 다양한 위험을 분석할 수 있는 능력 중심의 관점을 개발하고, 위험의 세 가지 주요 출처를 정제하며, 각 위험 출처와 물질적 위험 및 기술적 통제 간의 명확한 연결고리를 확립한다.

Conclusion: ARC 프레임워크는 조직이 에이전틱 AI의 복잡성을 탐색하고 안전하고 책임감 있게 시스템을 배치할 수 있도록 돕는 강력하고 유연한 방법론을 제공한다.

Abstract: Agentic AI systems present both significant opportunities and novel risks due to their capacity for autonomous action, encompassing tasks such as code execution, internet interaction, and file modification. This poses considerable challenges for effective organizational governance, particularly in comprehensively identifying, assessing, and mitigating diverse and evolving risks. To tackle this, we introduce the Agentic Risk \& Capability (ARC) Framework, a technical governance framework designed to help organizations identify, assess, and mitigate risks arising from agentic AI systems. The framework's core contributions are: (1) it develops a novel capability-centric perspective to analyze a wide range of agentic AI systems; (2) it distills three primary sources of risk intrinsic to agentic AI systems - components, design, and capabilities; (3) it establishes a clear nexus between each risk source, specific materialized risks, and corresponding technical controls; and (4) it provides a structured and practical approach to help organizations implement the framework. This framework provides a robust and adaptable methodology for organizations to navigate the complexities of agentic AI, enabling rapid and effective innovation while ensuring the safe, secure, and responsible deployment of agentic AI systems. Our framework is open-sourced \href{https://govtech-responsibleai.github.io/agentic-risk-capability-framework/}{here}.

</details>


### [49] [SciEvalKit: An Open-source Evaluation Toolkit for Scientific General Intelligence](https://arxiv.org/abs/2512.22334)
*Yiheng Wang,Yixin Chen,Shuo Li,Yifan Zhou,Bo Liu,Hengjian Gao,Jiakang Yuan,Jia Bu,Wanghan Xu,Yuhao Zhou,Xiangyu Zhao,Zhiwang Zhou,Fengxiang Wang,Haodong Duan,Songyang Zhang,Jun Yao,Han Deng,Yizhou Wang,Jiabei Xiao,Jiaqi Liu,Encheng Su,Yujie Liu,Weida Wang,Junchi Yao,Shenghe Zheng,Haoran Sun,Runmin Ma,Xiangchao Yan,Bo Zhang,Dongzhan Zhou,Shufei Zhang,Peng Ye,Xiaosong Wang,Shixiang Tang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: SciEvalKit은 다양한 과학 분야와 작업 능력을 평가하기 위해 설계된 통합 벤치마킹 도구키트이다.


<details>
  <summary>Details</summary>
Motivation: AI 모델의 과학적 평가에 대한 필요성을 충족하기 위해 SciEvalKit을 개발했다.

Method: 물리학, 화학, 천문학 등 여섯 가지 주요 과학 분야를 지원하며, 실질적인 과학적 도전 과제를 반영한 전문가 수준의 벤치마크를 구축한다.

Result: 유연하고 확장 가능한 평가 파이프라인을 통해 여러 모델과 데이터셋의 배치 평가를 지원하고, 투명하고 재현 가능하며 비교 가능한 결과를 제공한다.

Conclusion: SciEvalKit은 다음 세대 과학적 기초 모델 및 지능형 에이전트를 벤치마킹하기 위한 표준화된 인프라를 제공하며, 오픈소스 형태로 활성화된다.

Abstract: We introduce SciEvalKit, a unified benchmarking toolkit designed to evaluate AI models for science across a broad range of scientific disciplines and task capabilities. Unlike general-purpose evaluation platforms, SciEvalKit focuses on the core competencies of scientific intelligence, including Scientific Multimodal Perception, Scientific Multimodal Reasoning, Scientific Multimodal Understanding, Scientific Symbolic Reasoning, Scientific Code Generation, Science Hypothesis Generation and Scientific Knowledge Understanding. It supports six major scientific domains, spanning from physics and chemistry to astronomy and materials science. SciEvalKit builds a foundation of expert-grade scientific benchmarks, curated from real-world, domain-specific datasets, ensuring that tasks reflect authentic scientific challenges. The toolkit features a flexible, extensible evaluation pipeline that enables batch evaluation across models and datasets, supports custom model and dataset integration, and provides transparent, reproducible, and comparable results. By bridging capability-based evaluation and disciplinary diversity, SciEvalKit offers a standardized yet customizable infrastructure to benchmark the next generation of scientific foundation models and intelligent agents. The toolkit is open-sourced and actively maintained to foster community-driven development and progress in AI4Science.

</details>


### [50] [Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent Feedback](https://arxiv.org/abs/2512.22336)
*Mengkang Hu,Bowei Xia,Yuran Wu,Ailing Yu,Yude Zou,Qiguang Chen,Shijian Wang,Jiarui Jin,Kexin Li,Wenxiang Jiao,Yuan Lu,Ping Luo*

Main category: cs.AI

TL;DR: Agent2World는 강력한 추론 시간 세계 모델 생성을 달성하고 감독적 미세 조정을 위한 데이터 엔진 역할을 하는 다중 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대규모 검증 가능한 감독 부족으로 인해 LLM을 훈련하여 상징적 세계 모델을 생성하는 것이 제한적이다.

Method: Agent2World는 웹 검색을 통한 지식 합성, 실행 가능한 세계 모델 구현 및 적응형 단위 테스트를 수행하는 세 단계의 파이프라인을 따른다.

Result: Agent2World는 PDDL과 실행 가능 코드 표현을 아우르는 세 가지 벤치마크에서 뛰어난 추론 시간 성능을 입증하였다.

Conclusion: 이 모델은 이러한 훈련 궤적을 기반으로 미세 조정되어 세계 모델 생성이 크게 향상되었다.

Abstract: Symbolic world models (e.g., PDDL domains or executable simulators) are central to model-based planning, but training LLMs to generate such world models is limited by the lack of large-scale verifiable supervision. Current approaches rely primarily on static validation methods that fail to catch behavior-level errors arising from interactive execution. In this paper, we propose Agent2World, a tool-augmented multi-agent framework that achieves strong inference-time world-model generation and also serves as a data engine for supervised fine-tuning, by grounding generation in multi-agent feedback. Agent2World follows a three-stage pipeline: (i) A Deep Researcher agent performs knowledge synthesis by web searching to address specification gaps; (ii) A Model Developer agent implements executable world models; And (iii) a specialized Testing Team conducts adaptive unit testing and simulation-based validation. Agent2World demonstrates superior inference-time performance across three benchmarks spanning both Planning Domain Definition Language (PDDL) and executable code representations, achieving consistent state-of-the-art results. Beyond inference, Testing Team serves as an interactive environment for the Model Developer, providing behavior-aware adaptive feedback that yields multi-turn training trajectories. The model fine-tuned on these trajectories substantially improves world-model generation, yielding an average relative gain of 30.95% over the same model before training. Project page: https://agent2world.github.io.

</details>


### [51] [Monadic Context Engineering](https://arxiv.org/abs/2512.22431)
*Yifan Zhang,Mengdi Wang*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델을 기반으로 한 자율 에이전트를 위한 새로운 아키텍처 패러다임인 모나딕 컨텍스트 엔지니어링(MCE)을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 확산으로 복잡한 추론과 도구 사용이 가능한 자율 에이전트로의 전환이 촉진되고 있으나, 기존 에이전트 아키텍처는 자주 비체계적이고 모호한 패턴으로 구성되어 문제를 일으킴.

Method: MCE는 펀터, 응용 펀터 및 모나드의 대수적 구조를 활용하여 에이전트 설계를 위한 공식적 기초를 제공합니다. 에이전트의 작업 흐름을 컴퓨팅 컨텍스트로 보고, 상태 전파, 오류 처리 및 비동기 실행과 같은 문제들을 대수적 성질에 의해 intrinsically 관리합니다.

Result: 모나드는 견고한 순차 합성을 가능하게 하고, 응용 펀터는 병렬 실행을 위한 원칙적인 구조를 제공하며, 모나드 변환기는 이러한 기능의 체계적인 조합을 허용합니다.

Conclusion: 이 계층적 접근을 통해 개발자는 단순하고 독립적으로 검증 가능한 구성 요소로부터 복잡하고 탄력적이며 효율적인 AI 에이전트를 구축할 수 있으며, 이 프레임워크를 메타 에이전트에까지 확장하여 메타 프로그래밍을 통해 하위 에이전트 작업 흐름을 동적으로 생성하고 관리할 수 있습니다.

Abstract: The proliferation of Large Language Models (LLMs) has catalyzed a shift towards autonomous agents capable of complex reasoning and tool use. However, current agent architectures are frequently constructed using imperative, ad hoc patterns. This results in brittle systems plagued by difficulties in state management, error handling, and concurrency. This paper introduces Monadic Context Engineering (MCE), a novel architectural paradigm leveraging the algebraic structures of Functors, Applicative Functors, and Monads to provide a formal foundation for agent design. MCE treats agent workflows as computational contexts where cross-cutting concerns, such as state propagation, short-circuiting error handling, and asynchronous execution, are managed intrinsically by the algebraic properties of the abstraction. We demonstrate how Monads enable robust sequential composition, how Applicatives provide a principled structure for parallel execution, and crucially, how Monad Transformers allow for the systematic composition of these capabilities. This layered approach enables developers to construct complex, resilient, and efficient AI agents from simple, independently verifiable components. We further extend this framework to describe Meta-Agents, which leverage MCE for generative orchestration, dynamically creating and managing sub-agent workflows through metaprogramming. Project Page: https://github.com/yifanzhang-pro/monadic-context-engineering.

</details>


### [52] [Multi-AI Agent Framework Reveals the "Oxide Gatekeeper" in Aluminum Nanoparticle Oxidation](https://arxiv.org/abs/2512.22529)
*Yiming Lu,Tingyu Lu,Di Zhang,Lili Ye,Hao Li*

Main category: cs.AI

TL;DR: 이 연구는 알루미늄 나노입자가 폭발 반응물로 변하는 메커니즘을 이해하기 위한 새로운 방법론을 제시하며, AI와 머신러닝을 활용하여 양자적 정확성을 유지하면서 나노초 시간 규모에서 큰 시스템을 시뮬레이션할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 알루미늄 나노입자(ANPs)의 에너지 밀도가 높지만, 이들이 비활성 입자에서 폭발성 반응물로 전환되는 원자적 메커니즘은 여전히 불명확하다.

Method: '인간-루프' 폐쇄 루프 프레임워크를 사용하여 자가 감사 AI 에이전트가 머신러닝 포텐셜(MLP)의 진화를 검증한다.

Result: 온도에 따라 조절되는 이중 모드 산화 메커니즘을 밝혀내고, 알루미늄 양이온의 외부 확산이 산소 수송보다 우세함을 실증하여 기존의 논란을 해결하였다.

Conclusion: 이 연구는 에너지 나노물질 설계를 위한 통합 원자 규모 프레임워크를 수립하고, 컴퓨터 디자인을 통해 점화 민감도 및 에너지 방출 속도를 정밀하게 조정할 수 있게 해준다.

Abstract: Aluminum nanoparticles (ANPs) are among the most energy-dense solid fuels, yet the atomic mechanisms governing their transition from passivated particles to explosive reactants remain elusive. This stems from a fundamental computational bottleneck: ab initio methods offer quantum accuracy but are restricted to small spatiotemporal scales (< 500 atoms, picoseconds), while empirical force fields lack the reactive fidelity required for complex combustion environments. Herein, we bridge this gap by employing a "human-in-the-loop" closed-loop framework where self-auditing AI Agents validate the evolution of a machine learning potential (MLP). By acting as scientific sentinels that visualize hidden model artifacts for human decision-making, this collaborative cycle ensures quantum mechanical accuracy while exhibiting near-linear scalability to million-atom systems and accessing nanosecond timescales (energy RMSE: 1.2 meV/atom, force RMSE: 0.126 eV/Angstrom). Strikingly, our simulations reveal a temperature-regulated dual-mode oxidation mechanism: at moderate temperatures, the oxide shell acts as a dynamic "gatekeeper," regulating oxidation through a "breathing mode" of transient nanochannels; above a critical threshold, a "rupture mode" unleashes catastrophic shell failure and explosive combustion. Importantly, we resolve a decades-old controversy by demonstrating that aluminum cation outward diffusion, rather than oxygen transport, dominates mass transfer across all temperature regimes, with diffusion coefficients consistently exceeding those of oxygen by 2-3 orders of magnitude. These discoveries establish a unified atomic-scale framework for energetic nanomaterial design, enabling the precision engineering of ignition sensitivity and energy release rates through intelligent computational design.

</details>


### [53] [SANet: A Semantic-aware Agentic AI Networking Framework for Cross-layer Optimization in 6G](https://arxiv.org/abs/2512.22579)
*Yong Xiao,Xubo Li,Haoran Zhou,Yingyu Li,Yayu Gao,Guangming Shi,Ping Zhang,Marwan Krunz*

Main category: cs.AI

TL;DR: SANet는 다양한 AI 에이전트들이 협력하여 자율적인 의사결정과 환경 적응을 수행하기 위한 새로운 AI 네트워킹 아키텍처다.


<details>
  <summary>Details</summary>
Motivation: AgentNet은 탈중앙 집중화된 프레임워크로, 협력하는 에이전트들이 서로 다른 목표를 가질 수 있다.

Method: SANet는 사용자의 의미론적 목표를 유추하고 네트워크의 다양한 계층에 따라 에이전트를 자동으로 배치하는 아키텍처이다.

Result: 제안된 프레임워크는 최신 알고리즘이 필요한 FLOP의 44.37%만 소모하면서 최대 14.61%의 성능 향상을 달성했다.

Conclusion: 세 가지 최적화, 일반화 및 충돌 오류 사이에 삼자간의 절충이 존재함을 입증한다.

Abstract: Agentic AI networking (AgentNet) is a novel AI-native networking paradigm in which a large number of specialized AI agents collaborate to perform autonomous decision-making, dynamic environmental adaptation, and complex missions. It has the potential to facilitate real-time network management and optimization functions, including self-configuration, self-optimization, and self-adaptation across diverse and complex environments. This paper proposes SANet, a novel semantic-aware AgentNet architecture for wireless networks that can infer the semantic goal of the user and automatically assign agents associated with different layers of the network to fulfill the inferred goal. Motivated by the fact that AgentNet is a decentralized framework in which collaborating agents may generally have different and even conflicting objectives, we formulate the decentralized optimization of SANet as a multi-agent multi-objective problem, and focus on finding the Pareto-optimal solution for agents with distinct and potentially conflicting objectives. We propose three novel metrics for evaluating SANet. Furthermore, we develop a model partition and sharing (MoPS) framework in which large models, e.g., deep learning models, of different agents can be partitioned into shared and agent-specific parts that are jointly constructed and deployed according to agents' local computational resources. Two decentralized optimization algorithms are proposed. We derive theoretical bounds and prove that there exists a three-way tradeoff among optimization, generalization, and conflicting errors. We develop an open-source RAN and core network-based hardware prototype that implements agents to interact with three different layers of the network. Experimental results show that the proposed framework achieved performance gains of up to 14.61% while requiring only 44.37% of FLOPs required by state-of-the-art algorithms.

</details>


### [54] [Learning Multi-Modal Mobility Dynamics for Generalized Next Location Recommendation](https://arxiv.org/abs/2512.22605)
*Junshu Dai,Yu Wang,Tongya Zheng,Wei Ji,Qinghong Guo,Ji Cao,Jie Song,Canghong Jin,Mingli Song*

Main category: cs.AI

TL;DR: 이 논문은 다중 모드 공간-시간 지식을 사용하여 인간의 이동성 동역학을 특성화하고, 이를 통해 위치 추천 작업을 개선하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인간 이동성의 정확한 예측이 위치 추천 및 대피 제안과 같은 중요한 사회경제적 영향을 미치기 때문이다.

Method: 다양한 모드의 공간-시간 관계 그래프(STRG)를 구성하고, 다중 모드 그래프 표현을 융합하기 위한 게이팅 메커니즘을 설계하며, STKG 기반의 교차 모드 정렬을 제안하는 방법.

Result: 우리가 제안한 방법은 여섯 개의 공공 데이터셋에서 정상 시나리오에서 일관된 개선을 달성하며 비정상 시나리오에서도 상당한 일반화 능력을 보여준다.

Conclusion: 다중 모드 공간-시간 지식이 인간의 이동성 동역학을 효과적으로 포착하는 데 유용하다는 것을 입증하였다.

Abstract: The precise prediction of human mobility has produced significant socioeconomic impacts, such as location recommendations and evacuation suggestions. However, existing methods suffer from limited generalization capability: unimodal approaches are constrained by data sparsity and inherent biases, while multi-modal methods struggle to effectively capture mobility dynamics caused by the semantic gap between static multi-modal representation and spatial-temporal dynamics. Therefore, we leverage multi-modal spatial-temporal knowledge to characterize mobility dynamics for the location recommendation task, dubbed as \textbf{M}ulti-\textbf{M}odal \textbf{Mob}ility (\textbf{M}$^3$\textbf{ob}). First, we construct a unified spatial-temporal relational graph (STRG) for multi-modal representation, by leveraging the functional semantics and spatial-temporal knowledge captured by the large language models (LLMs)-enhanced spatial-temporal knowledge graph (STKG). Second, we design a gating mechanism to fuse spatial-temporal graph representations of different modalities, and propose an STKG-guided cross-modal alignment to inject spatial-temporal dynamic knowledge into the static image modality. Extensive experiments on six public datasets show that our proposed method not only achieves consistent improvements in normal scenarios but also exhibits significant generalization ability in abnormal scenarios.

</details>


### [55] [LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation](https://arxiv.org/abs/2512.22608)
*Zhongyang Liu,Haoyu Pei,Xiangyi Xiao,Xiaocong Du,Yihui Li,Suting Hong,Kunpeng Zhang,Haipeng Zhang*

Main category: cs.AI

TL;DR: 본 논문에서는 스타트업의 성공 예측을 다수의 투자자 그룹의 집합적 동력학을 감안하여 진행하는 새로운 시스템인 SimVC-CAS를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 스타트업의 높은 가치와 실패율로 인해 성공 예측은 여러 학문 분야에서 중요한 도전 과제가 되었습니다.

Method: SimVC-CAS는 다중 에이전트 상호작용 프로세스로서 VC 의사결정을 시뮬레이션하는 집합적 에이전트 시스템으로, 역할 놀이 에이전트와 GNN 기반의 감독 상호작용 모듈을 설계하여 스타트업 금융 예측을 그룹 의사결정 작업으로 재정의합니다.

Result: 실제 PitchBook 데이터를 사용하여 SimVC-CAS가 예측 정확도를 현저히 향상시키며, 평균 정밀도@10에 대해 약 25%의 상대적 개선을 보여줍니다.

Conclusion: SimVC-CAS는 또한 다른 복잡한 그룹 의사결정 시나리오에 대한 통찰을 제공합니다.

Abstract: Due to the high value and high failure rate of startups, predicting their success has become a critical challenge across interdisciplinary research. Existing approaches typically model success prediction from the perspective of a single decision-maker, overlooking the collective dynamics of investor groups that dominate real-world venture capital (VC) decisions. In this paper, we propose SimVC-CAS, a novel collective agent system that simulates VC decision-making as a multi-agent interaction process. By designing role-playing agents and a GNN-based supervised interaction module, we reformulate startup financing prediction as a group decision-making task, capturing both enterprise fundamentals and the behavioral dynamics of potential investor networks. Each agent embodies an investor with unique traits and preferences, enabling heterogeneous evaluation and realistic information exchange through a graph-structured co-investment network. Using real-world data from PitchBook and under strict data leakage controls, we show that SimVC-CAS significantly improves predictive accuracy while providing interpretable, multiperspective reasoning, for example, approximately 25% relative improvement with respect to average precision@10. SimVC-CAS also sheds light on other complex group decision scenarios.

</details>


### [56] [TravelBench: A Real-World Benchmark for Multi-Turn and Tool-Augmented Travel Planning](https://arxiv.org/abs/2512.22673)
*Xiang Cheng,Yulan Hu,Xiangwen Zhang,Lu Xu,Zheng Pan,Xin Li,Yong Liu*

Main category: cs.AI

TL;DR: 본 논문에서는 TravelBench라는 여행 계획 벤치마크를 소개하여 LLM 에이전트의 성능을 다각도로 평가한다.


<details>
  <summary>Details</summary>
Motivation: 여행 계획은 다단계 추론, 반복적인 선호 수집, 외부 도구 호출을 요구하여 LLM 에이전트의 능력을 테스트하기에 적합한 분야이다.

Method: TravelBench는 실제 여행 계획 시나리오에서 사용자 요청을 수집하고, 다회전, 단일 회전, 풀 수 없는 문제의 세 가지 하위 집합을 구성하여 에이전트 성능을 평가한다.

Result: 여러 LLM을 TravelBench에서 평가하고, 그들의 행동과 성능을 분석하였다.

Conclusion: TravelBench는 여행 계획에서 LLM 에이전트를 발전시키기 위한 실용적이고 재현 가능한 벤치마크를 제공한다.

Abstract: Large language model (LLM) agents have demonstrated strong capabilities in planning and tool use. Travel planning provides a natural and high-impact testbed for these capabilities, as it requires multi-step reasoning, iterative preference elicitation through interaction, and calls to external tools under evolving constraints. Prior work has studied LLMs on travel-planning tasks, but existing settings are limited in domain coverage and multi-turn interaction. As a result, they cannot support dynamic user-agent interaction and therefore fail to comprehensively assess agent capabilities. In this paper, we introduce TravelBench, a real-world travel-planning benchmark featuring multi-turn interaction and tool use. We collect user requests from real-world scenarios and construct three subsets-multi-turn, single-turn, and unsolvable-to evaluate different aspects of agent performance. For stable and reproducible evaluation, we build a controlled sandbox environment with 10 travel-domain tools, providing deterministic tool outputs for reliable reasoning. We evaluate multiple LLMs on TravelBench and conduct an analysis of their behaviors and performance. TravelBench offers a practical and reproducible benchmark for advancing LLM agents in travel planning.

</details>


### [57] [Memento-II: Learning by Stateful Reflective Memory](https://arxiv.org/abs/2512.22716)
*Jun Wang*

Main category: cs.AI

TL;DR: 본 논문은 에피소딕 메모리와 강화 학습을 통합한 대형 언어 모델 에이전트의 지속적이고 경험적인 학습을 위한 이론적 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 본 연구의 동기는 에이전트가 상호작용을 통해 적응할 수 있도록 하는 중요한 메커니즘으로서 반성을 식별하는 것이다.

Method: 우리는 상태 기반 반사적 결정 과정(Stateful Reflective Decision Process)을 도입하여 반사적 학습을 에피소딕 메모리와의 두 단계 읽기/쓰기 상호작용으로 모델링했다.

Result: 이 과정을 통해 증가된 상태 메모리 표현에 대한 동등한 마르코프 결정 프로세스를 유도하며, 고전적인 동적 프로그래밍 및 강화 학습 도구의 사용을 가능하게 하였다.

Conclusion: 에피소딕 메모리가 성장하고 상태 공간을 충분히 포괄하게 되면 결과 정책은 최적 솔루션으로 수렴하게 된다.

Abstract: We propose a theoretical framework for continual and experiential learning in large language model agents that integrates episodic memory with reinforcement learning. The framework identifies reflection as the key mechanism that enables agents to adapt through interaction without back propagation or model fine tuning, thereby relaxing the conventional separation between training and deployment.To formalise this process, we introduce the Stateful Reflective Decision Process, which models reflective learning as a two stage read write interaction with episodic memory. Writing stores interaction outcomes and corresponds to policy evaluation, while reading retrieves relevant past cases and corresponds to policy improvement. We show that this process induces an equivalent Markov decision process over augmented state memory representations, allowing the use of classical tools from dynamic programming and reinforcement learning. We further instantiate the framework using entropy regularised policy iteration and establish convergence guarantees. As episodic memory grows and achieves sufficient coverage of the state space, the resulting policy converges to the optimal solution. This work provides a principled foundation for memory augmented and retrieval based language model agents capable of continual adaptation without parameter updates.

</details>


### [58] [SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning](https://arxiv.org/abs/2512.22895)
*Xiaotian Ren,Nuerxiati Abudurexiti,Zhengyong Jiang,Angelos Stefanidis,Hongbin Liu,Jionglong Su*

Main category: cs.AI

TL;DR: 비정상적인 시장에서 포트폴리오 최적화는 도전적입니다. 이 논문에서는 계층 딥 강화 학습을 이용한 다중 에이전트 포트폴리오 관리를 위한 모멘텀 조정 유틸리티 기반 분할 할당(SAMP-HDRL)을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 비정상적인 시장에서의 포트폴리오 최적화 문제 해결 필요.

Method: 모멘텀 조정 유틸리티를 이용한 계층적 딥 강화 학습 프레임워크를 제시.

Result: SAMP-HDRL은 전통적 기준선과 DRL 벤치마크를 초과한 성과를 기록.

Conclusion: SAMP-HDRL은 복잡한 금융 환경에서 향상된 적응성, 강건성, 해석 가능성을 제공합니다.

Abstract: Portfolio optimization in non-stationary markets is challenging due to regime shifts, dynamic correlations, and the limited interpretability of deep reinforcement learning (DRL) policies. We propose a Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning (SAMP-HDRL). The framework first applies dynamic asset grouping to partition the market into high-quality and ordinary subsets. An upper-level agent extracts global market signals, while lower-level agents perform intra-group allocation under mask constraints. A utility-based capital allocation mechanism integrates risky and risk-free assets, ensuring coherent coordination between global and local decisions. backtests across three market regimes (2019--2021) demonstrate that SAMP-HDRL consistently outperforms nine traditional baselines and nine DRL benchmarks under volatile and oscillating conditions. Compared with the strongest baseline, our method achieves at least 5\% higher Return, 5\% higher Sharpe ratio, 5\% higher Sortino ratio, and 2\% higher Omega ratio, with substantially larger gains observed in turbulent markets. Ablation studies confirm that upper--lower coordination, dynamic clustering, and capital allocation are indispensable to robustness. SHAP-based interpretability further reveals a complementary ``diversified + concentrated'' mechanism across agents, providing transparent insights into decision-making. Overall, SAMP-HDRL embeds structural market constraints directly into the DRL pipeline, offering improved adaptability, robustness, and interpretability in complex financial environments.

</details>


### [59] [Multimodal Fact-Checking: An Agent-based Approach](https://arxiv.org/abs/2512.22933)
*Danni Xu,Shaojing Fan,Xuanang Cheng,Mohan Kankanhalli*

Main category: cs.AI

TL;DR: 다양한 형태의 허위정보 확산이 자동 Fact-checking 시스템에 도전 과제가 되고 있다. 이에 대한 해결책으로 RW-Post라는 고품질 데이터셋과 AgentFact라는 에이전트 기반 Fact-checking 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 형태의 허위정보가 자동 Fact-checking 시스템에 큰 도전이 되고 있으며, 기존 접근법들은 제한된 추론 및 얕은 증거 활용으로 인해 한계가 있다.

Method: RW-Post 데이터셋을 소개하며, 이를 기반으로 AgentFact라는 에이전트 기반의 멀티모달 Fact-checking 프레임워크를 제안한다. 이 프레임워크는 다섯 개의 전문 에이전트를 이용하여 전략 기획, 고품질 증거 검색, 시각 분석 등 여러 하위 작업을 협력하여 처리한다.

Result: RW-Post와 AgentFact의 시너지가 멀티모달 Fact-checking의 정확성 및 해석 가능성을 크게 향상시킴을 입증하는 광범위한 실험 결과를 제공한다.

Conclusion: RW-Post는 실제 멀티모달 Fact-checking을 위한 고품질 데이터셋을 제공하며, AgentFact는 인간의 검증 작업 흐름을 모방할 수 있는 프레임워크로서 효율적이다.

Abstract: The rapid spread of multimodal misinformation poses a growing challenge for automated fact-checking systems. Existing approaches, including large vision language models (LVLMs) and deep multimodal fusion methods, often fall short due to limited reasoning and shallow evidence utilization. A key bottleneck is the lack of dedicated datasets that provide complete real-world multimodal misinformation instances accompanied by annotated reasoning processes and verifiable evidence. To address this limitation, we introduce RW-Post, a high-quality and explainable dataset for real-world multimodal fact-checking. RW-Post aligns real-world multimodal claims with their original social media posts, preserving the rich contextual information in which the claims are made. In addition, the dataset includes detailed reasoning and explicitly linked evidence, which are derived from human written fact-checking articles via a large language model assisted extraction pipeline, enabling comprehensive verification and explanation. Building upon RW-Post, we propose AgentFact, an agent-based multimodal fact-checking framework designed to emulate the human verification workflow. AgentFact consists of five specialized agents that collaboratively handle key fact-checking subtasks, including strategy planning, high-quality evidence retrieval, visual analysis, reasoning, and explanation generation. These agents are orchestrated through an iterative workflow that alternates between evidence searching and task-aware evidence filtering and reasoning, facilitating strategic decision-making and systematic evidence analysis. Extensive experimental results demonstrate that the synergy between RW-Post and AgentFact substantially improves both the accuracy and interpretability of multimodal fact-checking.

</details>


### [60] [Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients](https://arxiv.org/abs/2512.23090)
*Armin Berger,Manuela Bergau,Helen Schneider,Saad Ahmad,Tom Anglim Lagones,Gianluca Brugnara,Martha Foltyn-Dumitru,Kai Schlamp,Philipp Vollmuth,Rafet Sifa*

Main category: cs.AI

TL;DR: 의료 이미징에 대한 리소스 제약을 고려하여 ChexReason 모델을 도입하고, 그 성능과 일반화 문제를 분석하였다.


<details>
  <summary>Details</summary>
Motivation: 최근 강화 학습이 대규모 언어 모델의 추론 작업을 개선했으나, 의료 이미징에의 리소스 제한적 적용은 충분히 탐구되지 않았다.

Method: 2,000개의 SFT 샘플, 1,000개의 RL 샘플 및 단일 A100 GPU를 사용하여 R1 스타일 방법론(SFT 후 GRPO)에 따라 훈련된 비전-언어 모델인 ChexReason을 도입하였다.

Result: CheXpert 및 NIH 벤치마크에서 GRPO는 in-distribution 성능을 회복했지만(체크스펙트에서 23% 향상, macro-F1 = 0.346), cross-dataset 전이 가능성은 저하되었고( NIH에서 19% 감소) 이러한 문제는 모델 크기보다는 RL 패러다임에서 기인한 것으로 보인다.

Conclusion: 세심하게 curated된 감독된 미세 조정이 다양한 인구 집단에서의 강인함을 요구하는 임상 배포에 대해 공격적인 RL보다 더 나은 성능을 낼 수 있다.

Abstract: Recent Reinforcement Learning (RL) advances for Large Language Models (LLMs) have improved reasoning tasks, yet their resource-constrained application to medical imaging remains underexplored. We introduce ChexReason, a vision-language model trained via R1-style methodology (SFT followed by GRPO) using only 2,000 SFT samples, 1,000 RL samples, and a single A100 GPU. Evaluations on CheXpert and NIH benchmarks reveal a fundamental tension: GRPO recovers in-distribution performance (23% improvement on CheXpert, macro-F1 = 0.346) but degrades cross-dataset transferability (19% drop on NIH). This mirrors high-resource models like NV-Reason-CXR-3B, suggesting the issue stems from the RL paradigm rather than scale. We identify a generalization paradox where the SFT checkpoint uniquely improves on NIH before optimization, indicating teacher-guided reasoning captures more institution-agnostic features. Furthermore, cross-model comparisons show structured reasoning scaffolds benefit general-purpose VLMs but offer minimal gain for medically pre-trained models. Consequently, curated supervised fine-tuning may outperform aggressive RL for clinical deployment requiring robustness across diverse populations.

</details>


### [61] [SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search](https://arxiv.org/abs/2512.23167)
*Yifan Zhang,Giridhar Ganapavarapu,Srideepika Jayaraman,Bhavna Agrawal,Dhaval Patel,Achille Fokoue*

Main category: cs.AI

TL;DR: SPIRAL이라는 새로운 프레임워크는 세 가지 특화된 LLM 에이전트를 MCTS 루프에 통합하여 복잡한 계획 작업을 개선한다.


<details>
  <summary>Details</summary>
Motivation: LLM은 탐색 및 자기 수정이 필요한 복잡한 계획 작업에서 종종 실패하며, 초기 실수에서 회복하는 데 어려움을 겪는다.

Method: SPIRAL은 Planner, Simulator, Critic의 세 가지 LLM 에이전트를 포함한 계획 파이프라인을 통해 자기 수정이 가능한 사유 과정을 제공한다.

Result: SPIRAL은 DailyLifeAPIs와 HuggingFace 데이터셋에서 Chain-of-Thought 계획법 및 다른 최신 에이전트보다 일관되게 우수한 성능을 보인다.

Conclusion: LLM 사고 방식을 유도된, 반성적, 그리고 기반이 있는 탐색 프로세스로 구조화함으로써 더 강력하고 효율적인 자율 계획자를 만든다는 것을 보여준다.

Abstract: Large Language Models (LLMs) often falter at complex planning tasks that require exploration and self-correction, as their linear reasoning process struggles to recover from early mistakes. While search algorithms like Monte Carlo Tree Search (MCTS) can explore alternatives, they are often ineffective when guided by sparse rewards and fail to leverage the rich semantic capabilities of LLMs. We introduce SPIRAL (Symbolic LLM Planning via Grounded and Reflective Search), a novel framework that embeds a cognitive architecture of three specialized LLM agents into an MCTS loop. SPIRAL's key contribution is its integrated planning pipeline where a Planner proposes creative next steps, a Simulator grounds the search by predicting realistic outcomes, and a Critic provides dense reward signals through reflection. This synergy transforms MCTS from a brute-force search into a guided, self-correcting reasoning process. On the DailyLifeAPIs and HuggingFace datasets, SPIRAL consistently outperforms the default Chain-of-Thought planning method and other state-of-the-art agents. More importantly, it substantially surpasses other state-of-the-art agents; for example, SPIRAL achieves 83.6% overall accuracy on DailyLifeAPIs, an improvement of over 16 percentage points against the next-best search framework, while also demonstrating superior token efficiency. Our work demonstrates that structuring LLM reasoning as a guided, reflective, and grounded search process yields more robust and efficient autonomous planners. The source code, full appendices, and all experimental data are available for reproducibility at the official project repository.

</details>


### [62] [TCEval: Using Thermal Comfort to Assess Cognitive and Perceptual Abilities of AI](https://arxiv.org/abs/2512.23217)
*Jingming Li*

Main category: cs.AI

TL;DR: TCEval은 AI의 세 가지 핵심 인지 능력을 평가하는 최초의 평가 프레임워크로서, 실제적인 열적 쾌적성을 통해 AI 시스템의 인지 능력을 점검합니다.


<details>
  <summary>Details</summary>
Motivation: LLM의 작업별 벤치마크에 중요한 격차가 존재합니다. 열적 쾌적성은 환경 요인과 개인의 인식 간의 복잡한 상호 작용을 포함하며, AI 시스템의 실제 인지 능력을 평가하기 위한 이상적인 패러다임으로 작용합니다.

Method: TCEval은 가상의 개인적 특성을 가진 LLM 에이전트를 초기화하고, 이들이 의류 단열 선택과 열적 쾌적성 피드백을 생성하도록 유도하며, ASHRAE 글로벌 데이터베이스 및 중국 열적 쾌적성 데이터베이스와 비교하여 출력을 검증하는 방법론을 포함합니다.

Result: 실험 결과, 에이전트의 피드백은 인간과의 정확한 정렬이 제한적이지만, 1 PMV 허용오차에서 방향의 일관성이 상당히 개선되었습니다. 통계 테스트 결과, LLM이 생성한 PMV 분포는 인간 데이터와 현저히 다르고, 에이전트는 이산 열적 쾌적성 분류에서 거의 무작위로 작동합니다.

Conclusion: TCEval은 AI에 대한 생태적으로 유효한 인지 튜링 테스트의 가능성을 확인하며, 현재 LLMs가 기본적인 교차 모드 추론 능력을 보유하고 있지만 열적 쾌적성 변수 간 비선형 관계에 대한 정확한 인과적 이해가 부족함을 보여줍니다. TCEval은 전통적인 벤치마크를 보완하여 AI 평가의 초점을 추상적 작업 능력에서 구체적이고 맥락 인식적인 인식 및 의사 결정으로 전환하며, 스마트 빌딩과 같은 인간 중심 응용 프로그램에서 AI 발전을 위한 귀중한 통찰을 제공합니다.

Abstract: A critical gap exists in LLM task-specific benchmarks. Thermal comfort, a sophisticated interplay of environmental factors and personal perceptions involving sensory integration and adaptive decision-making, serves as an ideal paradigm for evaluating real-world cognitive capabilities of AI systems. To address this, we propose TCEval, the first evaluation framework that assesses three core cognitive capacities of AI, cross-modal reasoning, causal association, and adaptive decision-making, by leveraging thermal comfort scenarios and large language model (LLM) agents. The methodology involves initializing LLM agents with virtual personality attributes, guiding them to generate clothing insulation selections and thermal comfort feedback, and validating outputs against the ASHRAE Global Database and Chinese Thermal Comfort Database. Experiments on four LLMs show that while agent feedback has limited exact alignment with humans, directional consistency improves significantly with a 1 PMV tolerance. Statistical tests reveal that LLM-generated PMV distributions diverge markedly from human data, and agents perform near-randomly in discrete thermal comfort classification. These results confirm the feasibility of TCEval as an ecologically valid Cognitive Turing Test for AI, demonstrating that current LLMs possess foundational cross-modal reasoning ability but lack precise causal understanding of the nonlinear relationships between variables in thermal comfort. TCEval complements traditional benchmarks, shifting AI evaluation focus from abstract task proficiency to embodied, context-aware perception and decision-making, offering valuable insights for advancing AI in human-centric applications like smart buildings.

</details>


### [63] [Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor Control](https://arxiv.org/abs/2512.23292)
*Yoonpyo Lee,Kazuma Kobayashi,Sai Puppala,Sajedul Talukder,Seid Koric,Souvik Chakraborty,Syed Bahauddin Alam*

Main category: cs.AI

TL;DR: 물리 시스템을 위한 AI에서의 현재 패러다임은 보편적인 다중 모달 추론을 향한 일반 목적의 기반 모델을 확장하는 것이지만, 제어 인터페이스에서 근본적인 장벽에 직면해 있다. 최근 벤치마크에 따르면, 최첨단 비전-언어 모델조차 기본적인 정량 물리학 과제에서 50-53%의 정확성만 달성하고 있으며, 이는 물리적 제약을 위반하면서 의미론적 그럴듯함을 유지하는 근사적 추측기로 작동한다.


<details>
  <summary>Details</summary>
Motivation: 일반 목적 모델이 직면한 근본적인 구조적 한계를 극복하고 도메인 특정 기반 모델로의 접근 방식을 제시하기 위해.

Method: Agentic Physical AI로 작동하는 소형 언어 모델을 도입하여, 정책 최적화가 인식적 추론이 아닌 물리 기반 검증에 의해 추진되는 방식으로 훈련.

Result: 360백만 매개변수 모델을 합성 반응기 제어 시나리오에서 훈련하여 데이터 세트를 10^3에서 10^5개의 예제로 확장했다. 이는 일반 목적 모델에서는 나타나지 않는 급격한 위상 전이를 유도한다.

Conclusion: 모델은 아키텍처 수정 없이도 고유한 물리 및 연속 입력 형태 간에 학습한 표현을 이전할 수 있다.

Abstract: The prevailing paradigm in AI for physical systems, scaling general-purpose foundation models toward universal multimodal reasoning, confronts a fundamental barrier at the control interface. Recent benchmarks show that even frontier vision-language models achieve only 50-53% accuracy on basic quantitative physics tasks, behaving as approximate guessers that preserve semantic plausibility while violating physical constraints. This input unfaithfulness is not a scaling deficiency but a structural limitation. Perception-centric architectures optimize parameter-space imitation, whereas safety-critical control demands outcome-space guarantees over executed actions. Here, we present a fundamentally different pathway toward domain-specific foundation models by introducing compact language models operating as Agentic Physical AI, in which policy optimization is driven by physics-based validation rather than perceptual inference. We train a 360-million-parameter model on synthetic reactor control scenarios, scaling the dataset from 10^3 to 10^5 examples. This induces a sharp phase transition absent in general-purpose models. Small-scale systems exhibit high-variance imitation with catastrophic tail risk, while large-scale models undergo variance collapse exceeding 500x reduction, stabilizing execution-level behavior. Despite balanced exposure to four actuation families, the model autonomously rejects approximately 70% of the training distribution and concentrates 95% of runtime execution on a single-bank strategy. Learned representations transfer across distinct physics and continuous input modalities without architectural modification.

</details>


### [64] [CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations](https://arxiv.org/abs/2512.23328)
*Huan-ang Gao,Zikang Zhang,Tianwei Luo,Kaisen Yang,Xinzhe Juan,Jiahao Qiu,Tianxing Chen,Bingxiang He,Hao Zhao,Hao Zhou,Shilong Liu,Mengdi Wang*

Main category: cs.AI

TL;DR: 이 논문에서는 대형 언어 모델이 물리적 세계에서 적용되는 데 있어 직면하는 인지적 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM) 에이전트가 디지털 영역에서는 능숙하지만 물리적 세계에서의 배치에는 심각한 격차가 존재한다.

Method: CubeBench라는 새로운 생성적 벤치마크를 도입하여 루빅스 큐브 중심의 세 가지 주요 인지적 도전 과제를 평가한다.

Result: 우리는 주요 LLM에서 실험을 수행하여 모든 장기 과제에서 0.00%의 통과율을 기록하며 장기 계획의 근본적인 실패를 드러내었다.

Conclusion: 우리는 이러한 인지적 병목을 고립시킬 진단 프레임워크를 제안함으로써 보다 물리적으로 기초가 되는 지능형 에이전트 개발을 안내하는 중요한 통찰을 제공한다.

Abstract: Large Language Model (LLM) agents, while proficient in the digital realm, face a significant gap in physical-world deployment due to the challenge of forming and maintaining a robust spatial mental model. We identify three core cognitive challenges hindering this transition: spatial reasoning, long-horizon state tracking via mental simulation, and active exploration under partial observation. To isolate and evaluate these faculties, we introduce CubeBench, a novel generative benchmark centered on the Rubik's Cube. CubeBench uses a three-tiered diagnostic framework that progressively assesses agent capabilities, from foundational state tracking with full symbolic information to active exploration with only partial visual data. Our experiments on leading LLMs reveal critical limitations, including a uniform 0.00% pass rate on all long-horizon tasks, exposing a fundamental failure in long-term planning. We also propose a diagnostic framework to isolate these cognitive bottlenecks by providing external solver tools. By analyzing the failure modes, we provide key insights to guide the development of more physically-grounded intelligent agents.

</details>


### [65] [MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning](https://arxiv.org/abs/2512.23412)
*Jiawei Chen,Xintian Shen,Lihao Zheng,Zhenwei Shao,Hongyuan Zhang,Pengfei Yu,Xudong Rao,Ning Mao,Xiaobo Liu,Lian Wen,Chaoqun Du,Feng Gu,Wei He,Qizhen Li,Shanshan Li,Zide Liu,Jing Luo,Lifu Mu,Xuhao Pan,Chang Ren,Haoyi Sun,Qian Wang,Wei Wang,Hongfu Yang,Jiqing Zhan,Chunpeng Zhou,Zheng Zhou,Hao Ma,Tao Wei,Pan Zhou,Wei Chen*

Main category: cs.AI

TL;DR: MindWatcher는 자율적 도구 호출 기능을 갖춘 TIR 에이전트로, 복잡한 의사결정 작업에서 효과적으로 작동하며, 기존의 에이전트보다 더 높은 성능을 발휘합니다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계 문제 해결에서 도구 호출이 필요한 복잡한 의사결정 작업을 더 효과적으로 처리할 수 있는 에이전트의 필요성.

Method: MindWatcher는 상호작용하는 사고와 다중 모달 체인 오브 사고(CoT) 추론을 통합한 TIR 에이전트를 소개합니다. 이 모델은 도구 호출을 독립적으로 결정하고 조정할 수 있는 능력을 지니고 있습니다.

Result: MindWatcher는 더 크거나 최신 모델과 비교할 때 우수한 도구 호출을 통해 성능을 일치시키거나 초과하는 결과를 보여줍니다.

Conclusion: MindWatcher는 다양한 도구를 활용할 수 있는 포괄적인 보조 추론 도구 세트를 갖추고 있어 다중 모달 문제를 효과적으로 해결하며, 에이전트 훈련에 대한 중요한 통찰을 제공합니다.

Abstract: Traditional workflow-based agents exhibit limited intelligence when addressing real-world problems requiring tool invocation. Tool-integrated reasoning (TIR) agents capable of autonomous reasoning and tool invocation are rapidly emerging as a powerful approach for complex decision-making tasks involving multi-step interactions with external environments. In this work, we introduce MindWatcher, a TIR agent integrating interleaved thinking and multimodal chain-of-thought (CoT) reasoning. MindWatcher can autonomously decide whether and how to invoke diverse tools and coordinate their use, without relying on human prompts or workflows. The interleaved thinking paradigm enables the model to switch between thinking and tool calling at any intermediate stage, while its multimodal CoT capability allows manipulation of images during reasoning to yield more precise search results. We implement automated data auditing and evaluation pipelines, complemented by manually curated high-quality datasets for training, and we construct a benchmark, called MindWatcher-Evaluate Bench (MWE-Bench), to evaluate its performance. MindWatcher is equipped with a comprehensive suite of auxiliary reasoning tools, enabling it to address broad-domain multimodal problems. A large-scale, high-quality local image retrieval database, covering eight categories including cars, animals, and plants, endows model with robust object recognition despite its small size. Finally, we design a more efficient training infrastructure for MindWatcher, enhancing training speed and hardware utilization. Experiments not only demonstrate that MindWatcher matches or exceeds the performance of larger or more recent models through superior tool invocation, but also uncover critical insights for agent training, such as the genetic inheritance phenomenon in agentic RL.

</details>


### [66] [The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis](https://arxiv.org/abs/2512.23419)
*Alex Lewandowski,Adtiya A. Ramesh,Edan Meyer,Dale Schuurmans,Marlos C. Machado*

Main category: cs.AI

TL;DR: 이 논문은 에이전트가 환경에 내재되어 있는 제약으로 인해 지속적인 학습의 맥락에서 에이전트의 행동을 적응시키는 능력을 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 지속적 학습은 '세상이 에이전트보다 크다'는 아이디어, 즉 큰 세계 가설에 의해 동기가 부여됩니다.

Method: 이 논문은 에이전트를 보편적인 컴퓨터 내에서 시뮬레이션된 자동체로 표현하는 계산적으로 내재된 관점을 소개하고, 이 상태에 대한 목적을 제안합니다.

Result: 딥 비선형 네트워크는 상호작용성을 지속하는 데 어려움을 겪는 반면, 딥 선형 네트워크는 용량 증가에 따라 더 높은 상호작용성을 유지합니다.

Conclusion: 결과는 에이전트의 능력에 따라 상호작용성이 다름을 보여줍니다.

Abstract: Continual learning is often motivated by the idea, known as the big world hypothesis, that "the world is bigger" than the agent. Recent problem formulations capture this idea by explicitly constraining an agent relative to the environment. These constraints lead to solutions in which the agent continually adapts to best use its limited capacity, rather than converging to a fixed solution. However, explicit constraints can be ad hoc, difficult to incorporate, and may limit the effectiveness of scaling up the agent's capacity. In this paper, we characterize a problem setting in which an agent, regardless of its capacity, is constrained by being embedded in the environment. In particular, we introduce a computationally-embedded perspective that represents an embedded agent as an automaton simulated within a universal (formal) computer. Such an automaton is always constrained; we prove that it is equivalent to an agent that interacts with a partially observable Markov decision process over a countably infinite state-space. We propose an objective for this setting, which we call interactivity, that measures an agent's ability to continually adapt its behaviour by learning new predictions. We then develop a model-based reinforcement learning algorithm for interactivity-seeking, and use it to construct a synthetic problem to evaluate continual learning capability. Our results show that deep nonlinear networks struggle to sustain interactivity, whereas deep linear networks sustain higher interactivity as capacity increases.

</details>


### [67] [AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis](https://arxiv.org/abs/2512.23424)
*Jinye Du,Quan Yuan,Zuyao Zhang,Yanzhi Yi,Jiahui Hu,Wangyi Chen,Yiyang Zhu,Qishui Zheng,Wenxiang Zou,Xiangyu Chang,Zuohe Zheng,Zichun Ye,Chao Liu,Shanni Li,Renwei Zhang,Yiping Deng,Xinwei Hu,Xuefeng Jin,Jie Zhao*

Main category: cs.AI

TL;DR: AKG 커널 에이전트는 AI 기반 커널 생성, 마이그레이션 및 성능 조정을 자동화하는 다중 에이전트 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 현대 AI 모델의 고성능 계산 커널에 대한 요구가 증가하면서 수동 최적화의 한계가 명확해지고 있다.

Method: AKG 커널 에이전트는 Triton, TileLang, CPP, CUDA-C와 같은 여러 도메인 전용 언어를 지원하며, 다양한 하드웨어 백엔드를 목표로 하는 자동화된 커널 생성을 수행한다.

Result: KernelBench에서 Triton DSL을 사용하여 GPU 및 NPU 백엔드에서 평가한 결과, AKG 커널 에이전트는 PyTorch Eager 기준보다 평균 1.46배의 속도 향상을 달성했다.

Conclusion: 이 연구는 현대 AI 작업에 대한 커널 개발을 가속화하는 데 있어 AKG 커널 에이전트의 효과성을 입증했다.

Abstract: Modern AI models demand high-performance computation kernels. The growing complexity of LLMs, multimodal architectures, and recommendation systems, combined with techniques like sparsity and quantization, creates significant computational challenges. Moreover, frequent hardware updates and diverse chip architectures further complicate this landscape, requiring tailored kernel implementations for each platform. However, manual optimization cannot keep pace with these demands, creating a critical bottleneck in AI system development. Recent advances in LLM code generation capabilities have opened new possibilities for automating kernel development. In this work, we propose AKG kernel agent (AI-driven Kernel Generator), a multi-agent system that automates kernel generation, migration, and performance tuning. AKG kernel agent is designed to support multiple domain-specific languages (DSLs), including Triton, TileLang, CPP, and CUDA-C, enabling it to target different hardware backends while maintaining correctness and portability. The system's modular design allows rapid integration of new DSLs and hardware targets. When evaluated on KernelBench using Triton DSL across GPU and NPU backends, AKG kernel agent achieves an average speedup of 1.46$\times$ over PyTorch Eager baselines implementations, demonstrating its effectiveness in accelerating kernel development for modern AI workloads.

</details>


### [68] [Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following](https://arxiv.org/abs/2512.23457)
*Kongcheng Zhang,Qi Yao,Shunyu Liu,Wenjian Zhang,Min Cen,Yang Zhou,Wenkai Fang,Yiru Zhao,Baisheng Lai,Mingli Song*

Main category: cs.AI

TL;DR: Hindsight instruction Replay(HiR)는 제한된 능력으로 인해 초기 모델에 의해 발생하는 낮은 품질의 응답을 해결하기 위한 샘플 효율적인 RL 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 모델이 모든 제약을 충족하는 응답을 생성하는 데 어려움을 겪기 때문에, 성공적이고 고품질의 응답을 샘플링하는 데 의존하고 있다.

Method: HiR는 실패한 시도를 제약을 만족시키는 성공으로 재생하는 선택-재작성 전략을 사용한다. 원본 샘플과 재생된 샘플 모두에서 RL을 수행하며, 이론적으로 목표를 명령-응답 수준의 이중 선호 학습으로 구성하여 이진 보상 신호만으로 효율적인 최적화를 가능하게 한다.

Result: 광범위한 실험을 통해 제안된 HiR이 다양한 명령 수행 작업에서 유망한 결과를 도출하며, 더 적은 계산 예산을 필요로 한다는 것이 입증되었다.

Conclusion: 코드와 데이터셋은 https://github.com/sastpg/HIR에서 제공된다.

Abstract: Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to generate responses that satisfy all constraints due to its limited capabilities, yielding sparse or indistinguishable rewards that impede learning. In this work, we propose Hindsight instruction Replay (HiR), a novel sample-efficient RL framework for complex instruction following tasks, which employs a select-then-rewrite strategy to replay failed attempts as successes based on the constraints that have been satisfied in hindsight. We perform RL on these replayed samples as well as the original ones, theoretically framing the objective as dual-preference learning at both the instruction- and response-level to enable efficient optimization using only a binary reward signal. Extensive experiments demonstrate that the proposed HiR yields promising results across different instruction following tasks, while requiring less computational budget. Our code and dataset is available at https://github.com/sastpg/HIR.

</details>


### [69] [The Gaining Paths to Investment Success: Information-Driven LLM Graph Reasoning for Venture Capital Prediction](https://arxiv.org/abs/2512.23489)
*Haoyu Pei,Zhongyang Liu,Xiangyi Xiao,Xiaocong Du,Haipeng Zhang,Kunpeng Zhang,Suting Hong*

Main category: cs.AI

TL;DR: 본 연구에서는 투자 네트워크를 명확한 추론을 통해 해석 가능한 투자 논제로 형성하는 MIRAGE-VC 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 벤처 캐피털 투자 실패, 소수의 투자만이 높은 수익을 가져오므로 스타트업 성공 예측이 필요하다.

Method: MIRAGE-VC는 다중 관점의 검색 보강 생성 프레임워크로, 경로 폭발 문제와 이질적 증거 융합 문제를 해결한다.

Result: MIRAGE-VC는 +5.0% F1 및 +16.6% PrecisionAt5를 달성했다.

Conclusion: MIRAGE-VC는 recommendation 및 risk assessment과 같은 다른 off-graph 예측 작업에 대한 통찰력을 제공한다.

Abstract: Most venture capital (VC) investments fail, while a few deliver outsized returns. Accurately predicting startup success requires synthesizing complex relational evidence, including company disclosures, investor track records, and investment network structures, through explicit reasoning to form coherent, interpretable investment theses. Traditional machine learning and graph neural networks both lack this reasoning capability. Large language models (LLMs) offer strong reasoning but face a modality mismatch with graphs. Recent graph-LLM methods target in-graph tasks where answers lie within the graph, whereas VC prediction is off-graph: the target exists outside the network. The core challenge is selecting graph paths that maximize predictor performance on an external objective while enabling step-by-step reasoning. We present MIRAGE-VC, a multi-perspective retrieval-augmented generation framework that addresses two obstacles: path explosion (thousands of candidate paths overwhelm LLM context) and heterogeneous evidence fusion (different startups need different analytical emphasis). Our information-gain-driven path retriever iteratively selects high-value neighbors, distilling investment networks into compact chains for explicit reasoning. A multi-agent architecture integrates three evidence streams via a learnable gating mechanism based on company attributes. Under strict anti-leakage controls, MIRAGE-VC achieves +5.0% F1 and +16.6% PrecisionAt5, and sheds light on other off-graph prediction tasks such as recommendation and risk assessment. Code: https://anonymous.4open.science/r/MIRAGE-VC-323F.

</details>


### [70] [Why AI Safety Requires Uncertainty, Incomplete Preferences, and Non-Archimedean Utilities](https://arxiv.org/abs/2512.23508)
*Alessio Benavoli,Alessandro Facchini,Marco Zaffalon*

Main category: cs.AI

TL;DR: AI 시스템이 인간의 가치와 안전을 어떻게 보장할 수 있는지에 대한 연구를 다룬 논문.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 안전성과 인간 가치의 정렬 문제에 대한 연구 필요성.

Method: AI 보조 및 AI 종료 게임 프레임워크를 사용하여 문제를 연구함.

Result: 불확실성 하에서 추론하고, 불완전 및 비아르키메데안 선호를 처리할 수 있는 AI 에이전트를 설계할 필요성을 발견함.

Conclusion: AI 시스템의 안전성과 인간 가치 정렬을 보장하기 위해서는 특정 과제를 해결할 수 있는 AI 에이전트가 필요함.

Abstract: How can we ensure that AI systems are aligned with human values and remain safe? We can study this problem through the frameworks of the AI assistance and the AI shutdown games. The AI assistance problem concerns designing an AI agent that helps a human to maximise their utility function(s). However, only the human knows these function(s); the AI assistant must learn them. The shutdown problem instead concerns designing AI agents that: shut down when a shutdown button is pressed; neither try to prevent nor cause the pressing of the shutdown button; and otherwise accomplish their task competently. In this paper, we show that addressing these challenges requires AI agents that can reason under uncertainty and handle both incomplete and non-Archimedean preferences.

</details>


### [71] [Web World Models](https://arxiv.org/abs/2512.23676)
*Jichen Feng,Yifan Zhang,Chenggong Zhang,Yifu Lu,Shilong Liu,Mengdi Wang*

Main category: cs.AI

TL;DR: 이 논문에서는 웹 기반 세계 모델(Web World Model, WWM)을 소개합니다. WWM은 고정된 데이터베이스에 의존하는 기존 웹 프레임워크와 완전히 생성적인 세계 모델의 중간 지점으로, 언어 모델이 맥락과 내러티브를 생성하도록 합니다.


<details>
  <summary>Details</summary>
Motivation: 언어 에이전트는 작동하고 기억하며 학습할 수 있는 지속적인 세계가 필요합니다.

Method: 세계 상태와 '물리학'을 일반 웹 코드로 구현하여 논리적 일관성을 보장하고, 이 구조화된 잠재 상태 위에서 대형 언어 모델이 맥락, 서사 및 높은 수준의 결정을 생성하는 방식으로 WWM을 구축합니다.

Result: 현실적인 웹 스택을 기반으로 한 다양한 WWM을 구축하고, 웹 인터페이스로 잠재 상태를 표시하며, 코드 정의 규칙과 모델 주도 상상을 분리하는 등 실용적인 설계 원칙을 식별하였습니다.

Conclusion: 웹 스택은 세계 모델을 위한 확장 가능한 기초로 작용할 수 있으며, 제어 가능하면서도 열린 환경을 가능하게 합니다.

Abstract: Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the expense of controllability and practical engineering. In this work, we introduce the Web World Model (WWM), a middle ground where world state and ``physics'' are implemented in ordinary web code to ensure logical consistency, while large language models generate context, narratives, and high-level decisions on top of this structured latent state. We build a suite of WWMs on a realistic web stack, including an infinite travel atlas grounded in real geography, fictional galaxy explorers, web-scale encyclopedic and narrative worlds, and simulation- and game-like environments. Across these systems, we identify practical design principles for WWMs: separating code-defined rules from model-driven imagination, representing latent state as typed web interfaces, and utilizing deterministic generation to achieve unlimited but structured exploration. Our results suggest that web stacks themselves can serve as a scalable substrate for world models, enabling controllable yet open-ended environments. Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models.

</details>
