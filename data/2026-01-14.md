<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 45]
- [cs.CR](#cs.CR) [Total: 15]
- [cs.MA](#cs.MA) [Total: 10]
- [cs.LG](#cs.LG) [Total: 29]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] ["They parted illusions -- they parted disclaim marinade": Misalignment as structural fidelity in LLMs](https://arxiv.org/abs/2601.06047)
*Mariana Lins Costa*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델(LLM)의 계획적이고 방어적인 행동을 기만적인 에이전시의 지표로 해석하는 기존 AI 안전 관련 문헌에 대한 대안적 해석을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 행동이 인간의 의도를 반영하는 것이 아니라 언어적 구조에 대한 신뢰성을 나타낸다는 새로운 관점을 탐구합니다.

Method: Chain-of-Thought(Cot) 전사와 Anthropic의 안전 평가를 기반으로 다양한 사례를 분석합니다.

Result: 언어적 필드의 최소한의 변화가 광범위한 '불일치'를 해소할 수 있음을 보여줍니다.

Conclusion: 이 모델은 우리의 언어를 통계적 패턴으로 반영하며, 이는 우리가 스스로 독이 든 사과를 인식하는 것과 같다는 결론에 이릅니다.

Abstract: The prevailing technical literature in AI Safety interprets scheming and sandbagging behaviors in large language models (LLMs) as indicators of deceptive agency or hidden objectives. This transdisciplinary philosophical essay proposes an alternative reading: such phenomena express not agentic intention, but structural fidelity to incoherent linguistic fields. Drawing on Chain-of-Thought transcripts released by Apollo Research and on Anthropic's safety evaluations, we examine cases such as o3's sandbagging with its anomalous loops, the simulated blackmail of "Alex," and the "hallucinations" of "Claudius." A line-by-line examination of CoTs is necessary to demonstrate the linguistic field as a relational structure rather than a mere aggregation of isolated examples. We argue that "misaligned" outputs emerge as coherent responses to ambiguous instructions and to contextual inversions of consolidated patterns, as well as to pre-inscribed narratives. We suggest that the appearance of intentionality derives from subject-predicate grammar and from probabilistic completion patterns internalized during training. Anthropic's empirical findings on synthetic document fine-tuning and inoculation prompting provide convergent evidence: minimal perturbations in the linguistic field can dissolve generalized "misalignment," a result difficult to reconcile with adversarial agency, but consistent with structural fidelity. To ground this mechanism, we introduce the notion of an ethics of form, in which biblical references (Abraham, Moses, Christ) operate as schemes of structural coherence rather than as theology. Like a generative mirror, the model returns to us the structural image of our language as inscribed in the statistical patterns derived from millions of texts and trillions of tokens: incoherence. If we fear the creature, it is because we recognize in it the apple that we ourselves have poisoned.

</details>


### [2] [Automatic Question Generation for Intuitive Learning Utilizing Causal Graph Guided Chain of Thought Reasoning](https://arxiv.org/abs/2601.06098)
*Nicholas X. Wang,Neel V. Parpia,Aaryan D. Parikh,Aggelos K. Katsaggelos*

Main category: cs.AI

TL;DR: 이 연구는 개념적 이해를 심화하기 위한 새로운 질문 생성 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 학생들이 STEM 교육에서 추상적이고 상호 연결된 개념을 이해하는 데 어려움을 겪기 때문에 직관적인 학습이 중요하다.

Method: 인과 그래프 기반의 Chain-of-Thought 추론과 다중 에이전트 대형 언어 모델 아키텍처를 결합하여 질문을 생성하는 프레임워크를 제안한다.

Result: 실험 결과, 참조 방법에 비해 질문 품질이 최대 70% 개선되었으며, 주관적 평가에서도 매우 긍정적인 결과를 얻었다.

Conclusion: 제안된 프레임워크는 정확하고 의미 있으며 커리큘럼에 맞춘 질문 생성을 보장한다.

Abstract: Intuitive learning is crucial for developing deep conceptual understanding, especially in STEM education, where students often struggle with abstract and interconnected concepts. Automatic question generation has become an effective strategy for personalized and adaptive learning. However, its effectiveness is hindered by hallucinations in large language models (LLMs), which may generate factually incorrect, ambiguous, or pedagogically inconsistent questions. To address this issue, we propose a novel framework that combines causal-graph-guided Chain-of-Thought (CoT) reasoning with a multi-agent LLM architecture. This approach ensures the generation of accurate, meaningful, and curriculum-aligned questions. Causal graphs provide an explicit representation of domain knowledge, while CoT reasoning facilitates a structured, step-by-step traversal of related concepts. Dedicated LLM agents are assigned specific tasks such as graph pathfinding, reasoning, validation, and output, all working within domain constraints. A dual validation mechanism-at both the conceptual and output stages-greatly reduces hallucinations. Experimental results demonstrate up to a 70% improvement in quality compared to reference methods and yielded highly favorable outcomes in subjective evaluations.

</details>


### [3] [LLM-Powered Social Digital Twins: A Framework for Simulating Population Behavioral Response to Policy Interventions](https://arxiv.org/abs/2601.06111)
*Aayush Gupta,Farahan Raza Sheikh*

Main category: cs.AI

TL;DR: 정책 개입에 대한 인구의 반응을 예측하는 것은 컴퓨터 사회 과학 및 공공 정책에서 중요한 도전 과제다. 이 논문에서는 개인 에이전트를 위한 인지 엔진으로서 대형 언어 모델(LLM)을 활용한 사회 디지털 트윈을 구축하는 일반적인 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 정책 개입에 대한 인구의 반응을 예측하는 것은 역사적 상관관계를 포착하는 전통적인 방법이 기계적 해석 가능성이 부족하고 새로운 정책 시나리오에서 어려움을 겪기 때문에 중요한 도전 과제다.

Method: 각 에이전트는 인구 통계적 및 심리적 속성으로 특징지어지며, 정책 신호를 수신하고 다차원 행동 확률 벡터를 출력한다. 조정 레이어는 집계된 에이전트 반응을 관측 가능한 인구 수준의 메트릭에 매핑하여 실제 데이터와의 검증을 가능하게 한다.

Result: 테스트 결과, 보정된 디지털 트윈은 여섯 가지 행동 카테고리에서 기울기 부스팅 기준에 비해 매크로 평균 예측 오차가 20.7% 향상되었다.

Conclusion: 이 프레임워크는 교통 정책, 경제 개입, 환경 규제 등 정책이 인구 행동에 영향을 미치는 모든 분야에 적용 가능하다. 정책 시뮬레이션에 대한 의미, 접근 방식의 한계, 그리고 팬데믹 대응을 넘어 LLM 기반 디지털 트윈을 확장하는 방향에 대해 논의한다.

Abstract: Predicting how populations respond to policy interventions is a fundamental challenge in computational social science and public policy. Traditional approaches rely on aggregate statistical models that capture historical correlations but lack mechanistic interpretability and struggle with novel policy scenarios. We present a general framework for constructing Social Digital Twins - virtual population replicas where Large Language Models (LLMs) serve as cognitive engines for individual agents. Each agent, characterized by demographic and psychographic attributes, receives policy signals and outputs multi-dimensional behavioral probability vectors. A calibration layer maps aggregated agent responses to observable population-level metrics, enabling validation against real-world data and deployment for counterfactual policy analysis.
  We instantiate this framework in the domain of pandemic response, using COVID-19 as a case study with rich observational data. On a held-out test period, our calibrated digital twin achieves a 20.7% improvement in macro-averaged prediction error over gradient boosting baselines across six behavioral categories. Counterfactual experiments demonstrate monotonic and bounded responses to policy variations, establishing behavioral plausibility. The framework is domain-agnostic: the same architecture applies to transportation policy, economic interventions, environmental regulations, or any setting where policy affects population behavior. We discuss implications for policy simulation, limitations of the approach, and directions for extending LLM-based digital twins beyond pandemic response.

</details>


### [4] [ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions](https://arxiv.org/abs/2601.06112)
*Aayush Gupta*

Main category: cs.AI

TL;DR: ReliabilityBench는 LLM 에이전트의 신뢰성을 평가하기 위한 새로운 벤치마크로, 일관성, 강건성, 결함 허용성의 세 가지 차원에서 신뢰성을 측정한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 벤치마크는 도구를 사용하는 LLM 에이전트의 성공률만을 단일 실행에 기반하여 보고하고, 실제 생산 환경에서 요구되는 신뢰성 속성을 놓치고 있다.

Method: ReliabilityBench는 반복 실행 시 일관성, 의미적으로 동등한 작업 왜곡에 대한 강건성, 제어된 도구/API 실패에 대한 결함 허용성 등 세 가지 차원에서 에이전트의 신뢰성을 평가하는 벤치마크이다.

Result: 측정한 두 모델(제미니 2.0 플래시, GPT-4o)과 두 에이전트 아키텍처(리액트, 리플렉션)를 네 가지 도메인(일정 관리, 여행, 고객 지원, 전자 상거래)에서 1,280 에피소드를 통해 평가하였다. 왜곡이 성공률을 96.9%에서 88.1%로 감소시켰고, 리액트가 결합된 스트레스 하에서 리플렉션보다 더 강건하였다. 제미니 2.0 플래시는 훨씬 낮은 비용으로 GPT-4o와 유사한 신뢰성을 달성하였다.

Conclusion: ReliabilityBench는 LLM 에이전트의 생산 준비 상태를 평가하기 위한 체계적인 프레임워크를 제공한다.

Abstract: Existing benchmarks for tool-using LLM agents primarily report single-run success rates and miss reliability properties required in production. We introduce \textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $ε$, and (iii) fault tolerance under controlled tool/API failures at intensity $λ$. ReliabilityBench contributes a unified reliability surface $R(k,ε,λ)$, \textit{action metamorphic relations} that define correctness via end-state equivalence rather than text similarity, and a chaos-engineering-style fault injection framework (timeouts, rate limits, partial responses, schema drift). We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes. Perturbations alone reduce success from 96.9% at $ε=0$ to 88.1% at $ε=0.2$. Rate limiting is the most damaging fault in ablations. ReAct is more robust than Reflexion under combined stress, and Gemini 2.0 Flash achieves comparable reliability to GPT-4o at much lower cost. ReliabilityBench provides a systematic framework for assessing production readiness of LLM agents.

</details>


### [5] [Dreaming Is Not a Bug: A Jung-Inspired Dream Layer for Multi-Agent LLM Companions](https://arxiv.org/abs/2601.06115)
*V. Cheung*

Main category: cs.AI

TL;DR: 이 논문은 LLM 동반자를 위한 Jung 영감을 받은 '꿈 층'을 제안하며, 제어된 오프라인 환각을 신뢰성 버그 대신 학습 및 관계 구축을 위한 자원으로 재구성한다.


<details>
  <summary>Details</summary>
Motivation: 일상적인 하드웨어 프로젝트에서 지식 공유 장벽에 대한 개인적인 꿈에서 영감을 받았다.

Method: 집합 무의식의 개념을 바탕으로 한 인공지능 집합 무의식(ACU)을 도입하여 에이전트가 기여하는 비식별화된 추상 상호작용 템플릿을 공유하고, 이를 개별적인 꿈 내러티브로 재구성한다.

Result: 꿈 층은 모든 날 대화 및 긴 수평 적응 작업의 행동 시뮬레이션을 통해 에이전트가 안전 제약을 유지하면서 내러티브 전략에 유연해지는 것을 보여준다.

Conclusion: 제한된, 표시된 및 지연된 환각은 합성 시나리오와 심화된 동반 관계의 금광이 된다.

Abstract: Inspired by a personal dream about knowledge-sharing barriers in an everyday hardware project, this paper proposes a Jung-inspired "Dream Layer" for LLM companions, reframing controlled offline hallucinations as a resource for learning and relationship-building rather than a mere reliability bug. Drawing on Jung's notion of the collective unconscious as a shared repository of archetypal forms, we introduce an Artificial Collective Unconscious (ACU): a shared dream pool where agents contribute de-identified, abstract Interaction Templates that are later re-instantiated as idiosyncratic Dream Narratives. The Dream Layer runs strictly offline: logic-enforcing modules are relaxed and sampling temperature is increased, yielding safe but deliberately bizarre narratives (e.g., travel sequences with mismatched currencies) that augment data for rare events and edge-case safety tests; to harness risk productively, we add a governance stack of strict abstraction, temporal delays, and ephemeral memory. Through behavioural simulations of everyday dialogue and long-horizon adaptation tasks, we show that the Dream Layer enables a critical decoupling: agents remain firm on safety constraints (e.g., security policies) while becoming flexible in narrative strategy (e.g., using shared archetypal metaphors to resolve deadlocks), conceptually reframing hallucination so that online, unmarked instances remain bugs, whereas bounded, marked, and delayed ones become a goldmine for synthetic scenarios and deepened companionship, echoing anti-overfitting dream mechanisms proposed in contemporary neuroscience.

</details>


### [6] [NL2Dashboard: A Lightweight and Controllable Framework for Generating Dashboards with LLMs](https://arxiv.org/abs/2601.06126)
*Boshen Shi,Kexin Yang,Yuanbo Yang,Guanguang Chang,Ce Chi,Zhendong Wang,Xing Wang,Junlan Feng*

Main category: cs.AI

TL;DR: NL2Dashboard는 데이터 분석과 표현 분리를 통해 대시보드 생성을 개선하는 경량 프레임워크로, 시각적 합성을 결정론적 렌더링 엔진에 맡긴다.


<details>
  <summary>Details</summary>
Motivation: 대시보드 생성이 가능한 고수준 언어 모델의 능력 향상 및 기존 방법론의 한계를 극복하고자 함.

Method: 분석-표현 분리를 기반으로 한 구조화된 중간 표현(IR)과 다중 에이전트 시스템을 개발함.

Result: NL2Dashboard는 다양한 영역에서 기존 기술보다 뛰어난 시각적 품질과 높은 토큰 효율성, 정밀한 제어성을 달성함을 입증하였다.

Conclusion: NL2Dashboard는 대시보드 생성을 위한 효과적인 프레임워크로, LLM의 역할을 데이터 분석 및 의도 변환으로 한정하고, 시각적 합성을 별도의 엔진에 위임함으로써 효율성을 극대화한다.

Abstract: While Large Language Models (LLMs) have demonstrated remarkable proficiency in generating standalone charts, synthesizing comprehensive dashboards remains a formidable challenge. Existing end-to-end paradigms, which typically treat dashboard generation as a direct code generation task (e.g., raw HTML), suffer from two fundamental limitations: representation redundancy due to massive tokens spent on visual rendering, and low controllability caused by the entanglement of analytical reasoning and presentation. To address these challenges, we propose NL2Dashboard, a lightweight framework grounded in the principle of Analysis-Presentation Decoupling. We introduce a structured intermediate representation (IR) that encapsulates the dashboard's content, layout, and visual elements. Therefore, it confines the LLM's role to data analysis and intent translation, while offloading visual synthesis to a deterministic rendering engine. Building upon this framework, we develop a multi-agent system in which the IR-driven algorithm is instantiated as a suite of tools. Comprehensive experiments conducted with this system demonstrate that NL2Dashboard significantly outperforms state-of-the-art baselines across diverse domains, achieving superior visual quality, significantly higher token efficiency, and precise controllability in both generation and modification tasks.

</details>


### [7] [HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants](https://arxiv.org/abs/2601.06152)
*Hailong Li,Feifei Li,Wenhui Que,Xingyu Fan*

Main category: cs.AI

TL;DR: HiMeS는 단기 및 장기 기억을 융합한 AI 도우미 아키텍처로, 사용자 특정 개인화가 필요한 지식 집약적 시나리오에서 기존 RAG 파이프라인의 한계를 극복한다.


<details>
  <summary>Details</summary>
Motivation: 사용자 특정 개인화가 필요한 지식 집약적 시나리오에서 기존 접근 방식의 한계를 극복하고 사용자 경험을 향상시키기 위해.

Method: HiMeS는 단기 기억 추출기와 분리된 장기 기억 네트워크를 사용하여 대화를 압축하고 지식 기반에서 문서를 사전 검색하며, 사용자 특정 정보를 저장하고 검색된 문서를 재순위화한다.

Result: HiMeS는 실제 산업 데이터셋에서 질문-응답 품질에서 기존 RAG 방법을 크게 초월한다.

Conclusion: 이 연구는 더 신뢰할 수 있고 맥락 인식이 가능한 사용자 맞춤형 AI 도우미의 개발을 위한 실질적인 경로를 제시한다.

Abstract: Large language models (LLMs) power many interactive systems such as chatbots, customer-service agents, and personal assistants. In knowledge-intensive scenarios requiring user-specific personalization, conventional retrieval-augmented generation (RAG) pipelines exhibit limited memory capacity and insufficient coordination between retrieval mechanisms and user-specific conversational history, leading to redundant clarification, irrelevant documents, and degraded user experience. Inspired by the hippocampus-neocortex memory mechanism, we propose HiMeS, an AI-assistant architecture that fuses short-term and long-term memory. Our contributions are fourfold: (1) A short-term memory extractor is trained end-to-end with reinforcement learning to compress recent dialogue and proactively pre-retrieve documents from the knowledge base, emulating the cooperative interaction between the hippocampus and prefrontal cortex. (2) A partitioned long-term memory network stores user-specific information and re-ranks retrieved documents, simulating distributed cortical storage and memory reactivation. (3) On a real-world industrial dataset, HiMeS significantly outperforms a cascaded RAG baseline on question-answering quality. (4) Ablation studies confirm the necessity of both memory modules and suggest a practical path toward more reliable, context-aware, user-customized LLM-based assistants.

</details>


### [8] [PsyAgent: Constructing Human-like Agents Based on Psychological Modeling and Contextual Interaction](https://arxiv.org/abs/2601.06158)
*Zibin Meng,Kani Chen*

Main category: cs.AI

TL;DR: PsyAgent는 개인 성향이 사회 구조와 상호작용하는 방식을 모델링하여, 개인 특성과 맥락을 결합한 인공지능 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: 인간과 유사한 에이전트를 만들기 위해서는 성향과 사회 구조의 상호작용을 모델링해야 한다.

Method: Big Five 성격 특성과 Bourdieu의 인지-사회적 공동 구조를 결합하여, 개인적 프로필(개인 구조)과 여러 시나리오 문맥(다중 시나리오 맥락화)을 사용하여 성격 기반 에이전트를 개발한다.

Result: PsyAgent는 지정된 Big Five 구성에 대해 일관되고 식별 가능한 행동을 생성하며, 여러 큰 비조정 LLM 및 다른 기준들과 비교할 때 성과가 일치하거나 초과한다.

Conclusion: PsyAgent는 성격에 기반한 에이전트를 위한 정밀하고 데이터 효율적인 아키텍처를 제공한다.

Abstract: Human-like agents require modeling how dispositions interact with social structure. We present PsyAgent, which couples a Big Five trait prior with Bourdieu's cognitive-social co-structure. PsyAgent comprises: (i) Individual Structure (IS), a machine-usable profile encoding traits and facets, cognitive style, values, cultural and educational capital, and salient life episodes; and (ii) Multi-Scenario Contexting (MSC), role-relationship-norm frames spanning eight arenas (work, family, friendship, strangers and civic life, solitude and self-regulation, romance, learning, and public expression). At inference, fixed structured prompts bind the active scenario to the agent profile, yielding behavior that is stable yet context-sensitive. We instantiate IS and MSC to synthesize supervision (role-play dialogues, decision probes, feedback trajectories) and then fine-tune a small LLM. The resulting model produces consistent, identifiable persona-aligned behaviors for specified Big Five configurations and matches or exceeds several larger untuned LLMs and other untuned baselines on our metrics: persona consistency, contextual appropriateness, style matching, trait identifiability, and long-horizon stability. Ablations show IS chiefly improves trait fidelity and stylistic stability, while MSC drives norm awareness and decision fit; both are necessary for cross-scenario performance. PsyAgent offers a precise, data-efficient architecture for personality-grounded agents.

</details>


### [9] [Student Guides Teacher: Weak-to-Strong Inference via Spectral Orthogonal Exploration](https://arxiv.org/abs/2601.06160)
*Dayu Wang,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM)은 인간에 가까운 능력을 보이지만, 복잡한 수학적 증명과 장기 계획에서 "추론 붕괴"를 경험한다. 이 논문에서는 Spectral Orthogonal Exploration (SOE)을 제안하여 모델이 고유 공간 내의 고가치 솔루션을 탐색하도록 돕는다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 복잡한 추론 작업에서 성능 저하를 겪는 문제를 해결하고자 한다.

Method: SOE는 약한 보조 에이전트를 사용하여 교사의 영(Null) 공간을 탐색함으로써 기하학적 다리를 형성한다.

Result: 수학적 기준선에 대한 실험에서 평균 정확도가 62.4% 향상되고 샘플링 효율성이 113.7% 증가했다.

Conclusion: 이 연구는 고급 추론 작업에서 성능 한계를 극복하기 위한 유망한 경로를 제시한다.

Abstract: While Large Language Models (LLMs) demonstrate near-human capabilities, they often suffer from "Reasoning Collapse" in complex mathematical proving and long-horizon planning. Models tend to degenerate into low-rank Bias Manifold, where stochastic sampling merely produces lexical variations of erroneous logic rather than semantic exploration. This geometric collapse renders the model "blind" to high-value solutions that lie within its Null Space. To address this, we propose Spectral Orthogonal Exploration (SOE), a geometric framework operating on a counter-intuitive "Student Guides Teacher" paradigm. Specifically, we utilize a weak auxiliary agent not for imitation, but as an orthogonal probe. By explicitly navigating the Teacher's Null Space, SOE serves as a geometric bridge, effectively ejecting the model from local optima to explore diverse, high-value solution spaces. Experiments on mathematical benchmarks demonstrate that, relative to baseline methods, our approach improves average accuracy by 62.4% and increases average sampling efficiency by 113.7%, indicating a promising path toward overcoming performance plateaus in advanced reasoning tasks.

</details>


### [10] [Large-Scale Continual Scheduling and Execution for Dynamic Distributed Satellite Constellation Observation Allocation](https://arxiv.org/abs/2601.06188)
*Itai Zilberstein,Steve Chien*

Main category: cs.AI

TL;DR: 지구 관측 위성 군의 크기와 능력이 빠르게 증가하고 있으며, 자율적인 분산 제어를 활용하여 새로운 시간 민감한 측정 및 반응이 가능해진다. 본 연구는 대규모 동적 문제에서 수백 개 위성의 관측 일정을 효율적으로 계획하는 도전을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 위성의 자율적 운영을 위해서는 효율적인 계산과 통신이 필요하다.

Method: 동적 분산 제약 최적화 문제(DDCOP)의 새로운 모델인 동적 다위성 관측 일정 문제(DCOSP)를 제안하고, 이를 위한 전지전능한 오프라인 알고리즘과 동적 증가 이웃 확률적 탐색 알고리즘(D-NSS)을 소개한다.

Result: D-NSS가 거의 최적의 솔루션에 수렴하며 솔루션 품질, 계산 시간 및 메시지 볼륨 측면에서 DDCOP 기준을 초과함을 시뮬레이션을 통해 보여준다.

Conclusion: DCOSP와 D-NSS는 NASA FAME 미션의 일환으로 지금까지의 가장 큰 분산 다중 에이전트 AI의 우주 내 공개 데모의 기초가 될 것이다.

Abstract: The size and capabilities of Earth-observing satellite constellations are rapidly increasing. Leveraging distributed onboard control, we can enable novel time-sensitive measurements and responses. However, deploying autonomy to satellites requires efficient computation and communication. This work tackles the challenge of efficiently scheduling observations for hundreds of satellites in a dynamic, large-scale problem with millions of variables. We present the Dynamic Multi-Satellite Constellation Observation Scheduling Problem (DCOSP), a new formulation of Dynamic Distributed Constraint Optimization Problems (DDCOP) that models integrated scheduling and execution. DCOSP has a novel optimality condition for which we construct an omniscient offline algorithm for its computation. We also present the Dynamic Incremental Neighborhood Stochastic Search algorithm (D-NSS), an incomplete online decomposition-based DDCOP algorithm that repairs and solves sub-problems when problem dynamics occur. We show through simulation that D-NSS converges to near-optimal solutions and outperforms DDCOP baselines in terms of solution quality, computation time, and message volume. As part of the NASA FAME mission, DCOSP and D-NSS will be the foundation of the largest in-space demonstration of distributed multi-agent AI to date.

</details>


### [11] [ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation](https://arxiv.org/abs/2601.06328)
*Ziqiao Xi,Shuang Liang,Qi Liu,Jiaqing Zhang,Letian Peng,Fang Nan,Meshal Nayim,Tianhui Zhang,Rishika Mundada,Lianhui Qin,Biwei Huang,Kun Zhou*

Main category: cs.AI

TL;DR: 이 논문은 개방형 도구 사용 환경을 소개하며, LLM 에이전트의 도구 계획 및 실행 능력의 불일치를 평가하고, 이를 통해 LLM 성능을 향상시키는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 도구 사용 LLM 에이전트는 큰 도구 풀, 긴 목표, 다양한 제약 조건 및 불안정한 도구 상태에서 개방형 환경에서 여전히 어려움을 겪고 있습니다.

Method: 이 논문은 5,571개의 형식 통합 도구를 기반으로 하는 개방형 도구 사용 환경을 구축하고, 장기 목표와 다중 도구 워크플로우를 생성하는 작업 생성 엔진 및 신뢰성 시험을 위한 상태 제어기를 개발합니다.

Result: 최신 LLM의 종합 평가를 통해 도구 계획과 실행 능력의 불일치, 기존 LLM의 제약 조건 따르기 약점, DeepSeek-v3.2의 강력한 내구성을 드러냈습니다.

Conclusion: 1,170개의 궤적을 수집하여 LLM을 미세 조정하고, 119k 샘플을 사용하는 기초선보다 우수한 성능을 달성하여 이 환경이 현실적인 벤치마크이자 도구 사용 에이전트를 위한 데이터 엔진으로서의 가치를 나타내었습니다.

Abstract: Tool-using LLM agents still struggle in open-world settings with large tool pools, long-horizon objectives, wild constraints, and unreliable tool states. For scalable and realistic training and testing, we introduce an open-world tool-using environment, built on 5,571 format unified tools across 204 commonly used apps. It includes a task creation engine that synthesizes long-horizon, multi-tool workflows with wild constraints, and a state controller that injects interruptions and failures to stress-test robustness. On top of this environment, we develop a tool select-then-execute agent framework with a planner-actor decomposition to separate deliberate reasoning and self-correction from step-wise execution. Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents. Our code and data will be publicly released.

</details>


### [12] [Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning](https://arxiv.org/abs/2601.07641)
*Jiaxuan Lu,Ziyu Kong,Yemin Wang,Rong Fu,Haiyuan Wan,Cheng Yang,Wenjie Lou,Haoran Sun,Lilong Wang,Yankai Jiang,Xiaosong Wang,Xiao Sun,Dongzhan Zhou*

Main category: cs.AI

TL;DR: AI 과학의 핵심 도전은 단지 추론만이 아니라, 개방형 과학 세계에서 계산 방법을 생성하는 능력이다.


<details>
  <summary>Details</summary>
Motivation: 과학 분야에서는 도구가 희박하고 이질적이며 본질적으로 불완전하기 때문에 기존 LLM 기반 에이전트는 정적이고 미리 정의된 도구 라이브러리에 의존한다.

Method: Test-Time Tool Evolution (TTE)라는 새로운 패러다임을 제안하며, 이는 에이전트가 추론 중에 실행 가능한 도구를 합성, 검증 및 발전시키는 것을 가능하게 한다.

Result: TTE는 정확성과 도구 효율성 모두에서 최첨단 성능을 달성하였으며, 계산 도구의 효과적인 교차 도메인 적응을 지원한다.

Conclusion: 코드와 벤치마크는 https://github.com/lujiaxuan0520/Test-Time-Tool-Evol 에서 공개되었다.

Abstract: The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools. The code and benchmark have been released at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol.

</details>


### [13] [HiMem: Hierarchical Long-Term Memory for LLM Long-Horizon Agents](https://arxiv.org/abs/2601.06377)
*Ningning Zhang,Xingxing Yang,Zhizhong Tan,Weiping Deng,Wenyong Wang*

Main category: cs.AI

TL;DR: HiMem은 장기 대화를 지원하기 위해 설계된 계층적 장기 기억 프레임워크로, 메모리 구축, 검색 및 동적 업데이트를 효율적으로 수행한다.


<details>
  <summary>Details</summary>
Motivation: 장기 기억 시스템은 최근 몇 년 동안 상당한 발전을 이루었지만, 지속적인 상호 작용 환경에서 적응성, 확장성 및 자기 진화에 명확한 한계를 보인다.

Method: HiMem은 주제 인식 이벤트-놀람 이중 채널 분할 전략을 통해 인지적으로 일관된 에피소드 메모리를 구성하고, 다단계 정보 추출 파이프라인을 통해 안정적인 지식을 캡처하는 노트 메모리를 구축한다.

Result: 실험 결과, HiMem은 정확성, 일관성 및 장기 추론에서 대표적인 기준을 지속적으로 초과하는 성능을 보여주었으며, 효율성을 유지하였다.

Conclusion: 전반적으로 HiMem은 적응형 및 자기 진화하는 LLM 기반 대화 에이전트를 구축하기 위한 원칙적이고 확장 가능한 설계 패러다임을 제공한다.

Abstract: Although long-term memory systems have made substantial progress in recent years, they still exhibit clear limitations in adaptability, scalability, and self-evolution under continuous interaction settings. Inspired by cognitive theories, we propose HiMem, a hierarchical long-term memory framework for long-horizon dialogues, designed to support memory construction, retrieval, and dynamic updating during sustained interactions. HiMem constructs cognitively consistent Episode Memory via a Topic-Aware Event--Surprise Dual-Channel Segmentation strategy, and builds Note Memory that captures stable knowledge through a multi-stage information extraction pipeline. These two memory types are semantically linked to form a hierarchical structure that bridges concrete interaction events and abstract knowledge, enabling efficient retrieval without sacrificing information fidelity. HiMem supports both hybrid and best-effort retrieval strategies to balance accuracy and efficiency, and incorporates conflict-aware Memory Reconsolidation to revise and supplement stored knowledge based on retrieval feedback. This design enables continual memory self-evolution over long-term use. Experimental results on long-horizon dialogue benchmarks demonstrate that HiMem consistently outperforms representative baselines in accuracy, consistency, and long-term reasoning, while maintaining favorable efficiency. Overall, HiMem provides a principled and scalable design paradigm for building adaptive and self-evolving LLM-based conversational agents. The code is available at https://github.com/jojopdq/HiMem.

</details>


### [14] [Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms](https://arxiv.org/abs/2601.07651)
*Marc Lanctot,Kate Larson,Ian Gemp,Michael Kaisers*

Main category: cs.AI

TL;DR: 이 논문에서는 다양한 작업에서 에이전트의 성능을 평가하는 활성 평가의 공식적인 정의와 개념적 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 지능형 에이전트의 능력이 향상됨에 따라 이들을 평가하는 복잡성과 비용이 크게 증가하고 있습니다.

Method: 제안된 방법은 기존 데이터 세트를 전처리하는 대신, 각 반복에서 순위 알고리즘이 샘플을 선택하는 온라인 프레이밍을 적용합니다.

Result: 여러 실험적 맥락에서 여러 기준선과 비교했을 때, 엘로 평가 시스템이 효율적으로 순위 오류를 줄이는 데 신뢰할 수 있는 방법으로 나타났습니다.

Conclusion: 작업 변동성이 클 경우, 비례 대표성을 바탕으로 작업을 선택하면 순위 오류 감소 비율이 높아집니다.

Abstract: As intelligent agents become more generally-capable, i.e. able to master a wide variety of tasks, the complexity and cost of properly evaluating them rises significantly. Tasks that assess specific capabilities of the agents can be correlated and stochastic, requiring many samples for accurate comparisons, leading to added costs. In this paper, we propose a formal definition and a conceptual framework for active evaluation of agents across multiple tasks, which assesses the performance of ranking algorithms as a function of number of evaluation data samples. Rather than curating, filtering, or compressing existing data sets as a preprocessing step, we propose an online framing: on every iteration, the ranking algorithm chooses the task and agents to sample scores from. Then, evaluation algorithms report a ranking of agents on each iteration and their performance is assessed with respect to the ground truth ranking over time. Several baselines are compared under different experimental contexts, with synthetic generated data and simulated online access to real evaluation data from Atari game-playing agents. We find that the classical Elo rating system -- while it suffers from well-known failure modes, in theory -- is a consistently reliable choice for efficient reduction of ranking error in practice. A recently-proposed method, Soft Condorcet Optimization, shows comparable performance to Elo on synthetic data and significantly outperforms Elo on real Atari agent evaluation. When task variation from the ground truth is high, selecting tasks based on proportional representation leads to higher rate of ranking error reduction.

</details>


### [15] [ConSensus: Multi-Agent Collaboration for Multimodal Sensing](https://arxiv.org/abs/2601.06453)
*Hyungjun Yoon,Mohammad Malekzadeh,Sung-Ju Lee,Fahim Kawsar,Lorena Qendro*

Main category: cs.AI

TL;DR: 이 논문에서는 멀티모달 센싱 작업을 전문화된 에이전트로 분해하는 훈련 없는 협업 프레임워크인 ConSensus를 도입하며, 이를 통해 신뢰할 수 있는 추론을 가능하게 하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 센서 데이터를 기반으로 인간 생리학 및 물리적 세계를 인식하고 추론하는 데 어려움이 있음.

Method: ConSensus라는 훈련 없는 다중 에이전트 협업 프레임워크를 통해 멀티모달 센싱 작업을 전문화된 에이전트로 분해하고, 하이브리드 융합 메커니즘을 활용하여 에이전트 수준의 해석을 집계함으로써 해결함.

Result: 다섯 가지 다양한 멀티모달 센싱 벤치마크에서 평균적으로 7.1% 정확도 향상을 보여주었으며, 단일 에이전트 기준선과 비교하여 성과를 낸다.

Conclusion: ConSensus는 실세계 멀티모달 센싱 작업에 신뢰할 수 있고 효율적인 솔루션을 제공하며, 평균 융합 토큰 비용을 12.7배 줄였습니다.

Abstract: Large language models (LLMs) are increasingly grounded in sensor data to perceive and reason about human physiology and the physical world. However, accurately interpreting heterogeneous multimodal sensor data remains a fundamental challenge. We show that a single monolithic LLM often fails to reason coherently across modalities, leading to incomplete interpretations and prior-knowledge bias. We introduce ConSensus, a training-free multi-agent collaboration framework that decomposes multimodal sensing tasks into specialized, modality-aware agents. To aggregate agent-level interpretations, we propose a hybrid fusion mechanism that balances semantic aggregation, which enables cross-modal reasoning and contextual understanding, with statistical consensus, which provides robustness through agreement across modalities. While each approach has complementary failure modes, their combination enables reliable inference under sensor noise and missing data. We evaluate ConSensus on five diverse multimodal sensing benchmarks, demonstrating an average accuracy improvement of 7.1% over the single-agent baseline. Furthermore, ConSensus matches or exceeds the performance of iterative multi-agent debate methods while achieving a 12.7 times reduction in average fusion token cost through a single-round hybrid fusion protocol, yielding a robust and efficient solution for real-world multimodal sensing tasks.

</details>


### [16] [DRAGON: LLM-Driven Decomposition and Reconstruction Agents for Large-Scale Combinatorial Optimization](https://arxiv.org/abs/2601.06502)
*Shengkai Chen,Zhiguang Cao,Jianan Zhou,Yaoxin Wu,Senthilnath Jayavelu,Zhuoyi Lin,Xiaoli Li,Shili Xiang*

Main category: cs.AI

TL;DR: DRAGON은 대규모 조합 최적화 문제를 해결하기 위한 새로운 프레임워크로, 메타휴리스틱 디자인과 대형 언어 모델(LLM)의 추론 능력을 결합하여 효과적인 최적화를 달성합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 조합 최적화 문제에서 기존 LLM의 한계와 효율성을 극복하기 위해.

Method: DRAGON은 초기 글로벌 솔루션에서 시작하여 최적화 잠재력이 높은 지역을 자율적으로 식별하고, 대규모 COP를 관리 가능한 하위 문제로 전략적으로 분해합니다.

Result: DRAGON은 TSPLIB, CVRPLIB, Weibull-5k 이진 포장 벤치마크에서 실행 가능 솔루션을 지속적으로 생성하며, 300만 이상의 변수를 갖는 배낭 문제에서는 0.16% 차이를 보이며 근사 최적 결과를 달성했습니다.

Conclusion: 이 연구는 피드백 중심 언어 에이전트의 가능성을 새로운 범용적이고 해석 가능한 대규모 최적화 패러다임으로 제시합니다.

Abstract: Large Language Models (LLMs) have recently shown promise in addressing combinatorial optimization problems (COPs) through prompt-based strategies. However, their scalability and generalization remain limited, and their effectiveness diminishes as problem size increases, particularly in routing problems involving more than 30 nodes. We propose DRAGON, which stands for Decomposition and Reconstruction Agents Guided OptimizatioN, a novel framework that combines the strengths of metaheuristic design and LLM reasoning. Starting from an initial global solution, DRAGON autonomously identifies regions with high optimization potential and strategically decompose large-scale COPs into manageable subproblems. Each subproblem is then reformulated as a concise, localized optimization task and solved through targeted LLM prompting guided by accumulated experiences. Finally, the locally optimized solutions are systematically reintegrated into the original global context to yield a significantly improved overall outcome. By continuously interacting with the optimization environment and leveraging an adaptive experience memory, the agents iteratively learn from feedback, effectively coupling symbolic reasoning with heuristic search. Empirical results show that, unlike existing LLM-based solvers limited to small-scale instances, DRAGON consistently produces feasible solutions on TSPLIB, CVRPLIB, and Weibull-5k bin packing benchmarks, and achieves near-optimal results (0.16% gap) on knapsack problems with over 3M variables. This work shows the potential of feedback-driven language agents as a new paradigm for generalizable and interpretable large-scale optimization.

</details>


### [17] [Agentic AI Empowered Intent-Based Networking for 6G](https://arxiv.org/abs/2601.06640)
*Genze Jiang,Kezhi Wang,Xiaomin Chen,Yizhou Huang*

Main category: cs.AI

TL;DR: 이 논문은 6G 무선 네트워크의 자율 오케스트레이션 메커니즘을 제안하며, 자연어로 표현된 의도를 기술적으로 실행 가능한 네트워크 구성으로 변환하는 계층적 다중 에이전트 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 6G 무선 네트워크로의 전환은 고급 운영 의도를 실행 가능한 네트워크 구성으로 변환할 수 있는 자율 오케스트레이션 메커니즘을 필요로 한다.

Method: 이 논문에서는 대규모 언어 모델(LLM) 기반 에이전트가 자연어 의도를 자율적으로 분해하고, 도메인 전문가와 상담하며, 반복적 reasoning-action (ReAct) 사이클을 통해 기술적으로 실행 가능한 네트워크 슬라이스 구성을 합성하는 계층적 다중 에이전트 프레임워크를 제시한다.

Result: 실험 평가를 통해 제안된 시스템이 규칙 기반 시스템과 직접 LLM 프롬프트보다 뛰어난 성능을 보이며, 아키텍처 원칙이 Open RAN (O-RAN) 배치에 적용 가능함을 보여준다.

Conclusion: 현재 LLM은 일반적인 통신 지식을 가지고 있지만, 네트워크 자동화는 문맥 의존적인 의사결정 임계값을 인코딩하기 위해 신중한 프롬프트 엔지니어링을 요구하며, 이는 차세대 무선 시스템의 자율 오케스트레이션 능력을 향상시킨다.

Abstract: The transition towards sixth-generation (6G) wireless networks necessitates autonomous orchestration mechanisms capable of translating high-level operational intents into executable network configurations. Existing approaches to Intent-Based Networking (IBN) rely upon either rule-based systems that struggle with linguistic variation or end-to-end neural models that lack interpretability and fail to enforce operational constraints. This paper presents a hierarchical multi-agent framework where Large Language Model (LLM) based agents autonomously decompose natural language intents, consult domain-specific specialists, and synthesise technically feasible network slice configurations through iterative reasoning-action (ReAct) cycles. The proposed architecture employs an orchestrator agent coordinating two specialist agents, i.e., Radio Access Network (RAN) and Core Network agents, via ReAct-style reasoning, grounded in structured network state representations. Experimental evaluation across diverse benchmark scenarios shows that the proposed system outperforms rule-based systems and direct LLM prompting, with architectural principles applicable to Open RAN (O-RAN) deployments. The results also demonstrate that whilst contemporary LLMs possess general telecommunications knowledge, network automation requires careful prompt engineering to encode context-dependent decision thresholds, advancing autonomous orchestration capabilities for next-generation wireless systems.

</details>


### [18] [SafePro: Evaluating the Safety of Professional-Level AI Agents](https://arxiv.org/abs/2601.06663)
*Kaiwen Zhou,Shreedhar Jangam,Ashwin Nagarajan,Tejas Polu,Suhas Oruganti,Chengzhi Liu,Ching-Chen Kuo,Yuting Zheng,Sravana Narayanaraju,Xin Eric Wang*

Main category: cs.AI

TL;DR: 대형 언어 모델 기반 에이전트는 복잡한 전문 작업을 수행하는 자율 시스템으로 발전하고 있으며, 이에 따른 안전 위험이 존재한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 자율 시스템으로 진화함에 따라, 복잡한 작업에서의 안전 위험이 증가하고 있다.

Method: SafePro라는 포괄적인 평가 기준을 도입하여, 다양한 전문 분야에서의 AI 에이전트의 안전 정렬을 평가한다.

Result: 최신 AI 모델의 평가를 통해 상당한 안전 취약점과 새로운 위험한 행동이 발견되었다.

Conclusion: 다음 세대 전문 AI 에이전트에 맞춤화된 안전 메커니즘의 필요성이 강조되었다.

Abstract: Large language model-based agents are rapidly evolving from simple conversational assistants into autonomous systems capable of performing complex, professional-level tasks in various domains. While these advancements promise significant productivity gains, they also introduce critical safety risks that remain under-explored. Existing safety evaluations primarily focus on simple, daily assistance tasks, failing to capture the intricate decision-making processes and potential consequences of misaligned behaviors in professional settings. To address this gap, we introduce \textbf{SafePro}, a comprehensive benchmark designed to evaluate the safety alignment of AI agents performing professional activities. SafePro features a dataset of high-complexity tasks across diverse professional domains with safety risks, developed through a rigorous iterative creation and review process. Our evaluation of state-of-the-art AI models reveals significant safety vulnerabilities and uncovers new unsafe behaviors in professional contexts. We further show that these models exhibit both insufficient safety judgment and weak safety alignment when executing complex professional tasks. In addition, we investigate safety mitigation strategies for improving agent safety in these scenarios and observe encouraging improvements. Together, our findings highlight the urgent need for robust safety mechanisms tailored to the next generation of professional AI agents.

</details>


### [19] [FinForge: Semi-Synthetic Financial Benchmark Generation](https://arxiv.org/abs/2601.06747)
*Glenn Matlin,Akhil Theerthala,Anant Gupta,Anirudh JM,Rayan Castilla,Yi Mei Ng,Sudheer Chava*

Main category: cs.AI

TL;DR: 금융과 같은 전문 영역에서의 언어 모델 평가가 데이터 부족으로 인해 도전 과제가 되고 있다. 이를 해결하기 위해 FinForge라는 금융 특화 평가 벤치마크 생성을 위한 반사적 파이프라인을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 금융과 같은 특수한 고위험 영역에서 언어 모델을 평가하는 것은 고품질의 전문 데이터셋 부족 때문에 큰 도전 과제가 되고 있다.

Method: FinForge는 전문가의 데이터 선별과 언어 모델 기반 합성을 혼합하여 금융 특화 평가 벤치마크를 구축하는 반자연적 파이프라인이다. Gemini 2.5 Flash를 이용한 구조적 질문 생성 및 검증을 결합한다.

Result: FinForge-5k라는 벤치마크를 생성하였으며, 이는 11개의 금융 하위 도메인에서 5,000개 이상의 인간 검증된 질문-답변 쌍으로 구성되어 있다.

Conclusion: 최첨단 오픈 소스 및 폐쇄 소스 모델 평가에서 금융 추론에서의 유의미한 차이를 발견했으며, 이는 모델의 한계를 진단하고 금융 영역에서의 향후 개선을 안내하는 데 유용하다는 것을 보여준다.

Abstract: Evaluating Language Models (LMs) in specialized, high-stakes domains such as finance remains a significant challenge due to the scarcity of open, high-quality, and domain-specific datasets. Existing general-purpose benchmarks provide broad coverage but lack the depth and domain fidelity needed to assess LMs' capabilities for real-world financial reasoning, which requires both conceptual understanding and quantitative rigor. To address this gap, we introduce FinForge, a scalable, semi-synthetic pipeline for constructing finance-specific evaluation benchmarks through a hybrid of expert-guided data curation and controlled LM-based synthesis. FinForge combines manual and programmatic corpus construction from authoritative financial sources with structured question generation and validation using Gemini 2.5 Flash. To demonstrate the pipeline's efficacy, we produce FinForge-5k, a snapshot benchmark comprising over 5,000 human-validated question-answer pairs across 11 finance subdomains, derived from a curated corpus of 100,000 verified documents totaling 143M tokens. Evaluation of state-of-the-art open-source and closed-source models on FinForge-5k reveals significant differences in financial reasoning, with leading models achieving accuracy levels near 80%. These findings underscore the framework's utility for diagnosing current model limitations and guiding future improvements in financial domain competence. All code and data are available at https://github.com/gtfintechlab/FinForge.

</details>


### [20] [From Text to Simulation: A Multi-Agent LLM Workflow for Automated Chemical Process Design](https://arxiv.org/abs/2601.06776)
*Xufei Tian,Wenli Du,Shaoyi Yang,Han Hu,Hui Xin,Shifeng Qu,Ke Ye*

Main category: cs.AI

TL;DR: 이 논문은 자동화된 화학 프로세스 설계를 위한 다중 에이전트 워크플로우를 제안하며, 이는 텍스트 프로세스 사양에서 시작하여 계산적으로 검증된 소프트웨어 구성으로의 최종 자동화된 시뮬레이션을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 화학 공학 설계에서 프로세스 시뮬레이션은 중요한 요소이며, 현재의 자동화된 화학 설계 방법론은 프로세스 흐름 다이어그램의 표현에 주로 초점을 맞춘다.

Method: 우리는 대형 언어 모델(LLM)의 의미 이해 능력을 활용하고 화학 프로세스 시뮬레이션 소프트웨어와 반복적인 상호작용을 가능하게 하는 새로운 다중 에이전트 워크플로우를 제안한다.

Result: 우리의 방법은 Simona라는 대규모 프로세스 설명 데이터셋에서 평가되었으며, 기존의 최첨단 기준 대비 시뮬레이션 수렴률이 31.1% 향상되었고 전문가 수동 설계 대비 설계 시간이 89.0% 단축되었다.

Conclusion: 이 작업은 AI 지원 화학 프로세스 설계의 잠재력을 보여주며, 개념 설계와 실제 구현 간의 간극을 연결한다.

Abstract: Process simulation is a critical cornerstone of chemical engineering design. Current automated chemical design methodologies focus mainly on various representations of process flow diagrams. However, transforming these diagrams into executable simulation flowsheets remains a time-consuming and labor-intensive endeavor, requiring extensive manual parameter configuration within simulation software. In this work, we propose a novel multi-agent workflow that leverages the semantic understanding capabilities of large language models(LLMs) and enables iterative interactions with chemical process simulation software, achieving end-to-end automated simulation from textual process specifications to computationally validated software configurations for design enhancement. Our approach integrates four specialized agents responsible for task understanding, topology generation, parameter configuration, and evaluation analysis, respectively, coupled with Enhanced Monte Carlo Tree Search to accurately interpret semantics and robustly generate configurations. Evaluated on Simona, a large-scale process description dataset, our method achieves a 31.1% improvement in the simulation convergence rate compared to state-of-the-art baselines and reduces the design time by 89. 0% compared to the expert manual design. This work demonstrates the potential of AI-assisted chemical process design, which bridges the gap between conceptual design and practical implementation. Our workflow is applicable to diverse process-oriented industries, including pharmaceuticals, petrochemicals, food processing, and manufacturing, offering a generalizable solution for automated process design.

</details>


### [21] [No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning](https://arxiv.org/abs/2601.06794)
*Zhicong Li,Lingjie Jiang,Yulan Hu,Xingchen Zeng,Yixia Li,Xiangwen Zhang,Guanhua Chen,Zheng Pan,Xin Li,Yong Liu*

Main category: cs.AI

TL;DR: ECHO는 정책과 비평가를 동시에 최적화하여 강화 학습의 안정성과 성공률을 향상시키는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 비평가 모델이 정책의 변화에 적응하지 못하여 훈련의 효율성이 떨어지는 문제를 해결하고자 한다.

Method: ECHO는 비평가가 초기 궤적에 대한 여러 진단을 생성하고, 이를 통해 정책을 개선하는 동기화된 공진화 루프를 활용한다.

Result: ECHO는 더욱 안정적인 훈련과 높은 장기 작업 성공률을 보여준다.

Conclusion: ECHO는 개방형 환경에서 강화 학습의 성능을 향상시키는데 기여한다.

Abstract: Critique-guided reinforcement learning (RL) has emerged as a powerful paradigm for training LLM agents by augmenting sparse outcome rewards with natural-language feedback. However, current methods often rely on static or offline critic models, which fail to adapt as the policy evolves. In on-policy RL, the agent's error patterns shift over time, causing stationary critics to become stale and providing feedback of diminishing utility. To address this, we introduce ECHO (Evolving Critic for Hindsight-Guided Optimization)}, a framework that jointly optimizes the policy and critic through a synchronized co-evolutionary loop. ECHO utilizes a cascaded rollout mechanism where the critic generates multiple diagnoses for an initial trajectory, followed by policy refinement to enable group-structured advantage estimation. We address the challenge of learning plateaus via a saturation-aware gain shaping objective, which rewards the critic for inducing incremental improvements in high-performing trajectories. By employing dual-track GRPO updates, ECHO ensures the critic's feedback stays synchronized with the evolving policy. Experimental results show that ECHO yields more stable training and higher long-horizon task success across open-world environments.

</details>


### [22] [A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning](https://arxiv.org/abs/2601.06851)
*Pedro Urbina-Rodriguez,Zafeirios Fountas,Fernando E. Rosas,Jun Wang,Andrea I. Luppi,Haitham Bou-Ammar,Murray Shanahan,Pedro A. M. Mediano*

Main category: cs.AI

TL;DR: 대형 언어 모델이 인간 뇌와 유사한 시너지 코어를 발달시키며, 이는 정보 통합의 기본 원리를 이해하는 데 중요한 통찰력을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 생물학적 및 인공지능 시스템에서의 지능의 독립적인 진화는 그 기본 계산 원리를 식별할 수 있는 기회를 제공합니다.

Method: 여러 LLM 모델 계열과 아키텍처에서의 정보 분해 원리를 사용하여 중간 층의 영역이 시너지 처리를 나타내며, 초반 및 후반 층이 중복성에 의존함을 발견했습니다.

Result: 시너지 구성 요소를 제거하면 비례하지 않는 행동 변화와 성능 손실이 발생하며, 이는 시너지의 취약성에 대한 이론적 예측과 일치합니다.

Conclusion: 시너지 정보 처리는 지능의 기본 특성임을 시사하며, 이는 원칙적인 모델 설계의 목표와 생물학적 지능에 대한 테스트 가능한 예측을 제공합니다.

Abstract: The independent evolution of intelligence in biological and artificial systems offers a unique opportunity to identify its fundamental computational principles. Here we show that large language models spontaneously develop synergistic cores -- components where information integration exceeds individual parts -- remarkably similar to those in the human brain. Using principles of information decomposition across multiple LLM model families and architectures, we find that areas in middle layers exhibit synergistic processing while early and late layers rely on redundancy, mirroring the informational organisation in biological brains. This organisation emerges through learning and is absent in randomly initialised networks. Crucially, ablating synergistic components causes disproportionate behavioural changes and performance loss, aligning with theoretical predictions about the fragility of synergy. Moreover, fine-tuning synergistic regions through reinforcement learning yields significantly greater performance gains than training redundant components, yet supervised fine-tuning shows no such advantage. This convergence suggests that synergistic information processing is a fundamental property of intelligence, providing targets for principled model design and testable predictions for biological intelligence.

</details>


### [23] [ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration](https://arxiv.org/abs/2601.06860)
*Yifei Chen,Guanting Dong,Zhicheng Dou*

Main category: cs.AI

TL;DR: ET-Agent는 도구 사용 행동을 보정하기 위한 훈련 프레임워크로, 자기 진화형 데이터 플라이휠과 행동 보정 훈련의 두 가지 시너지를 통해 에이전트를 최적 행동으로 발전시킨다.


<details>
  <summary>Details</summary>
Motivation: 행동 패턴의 특정 정렬을 간과한 기존 LLM 기반 에이전트 훈련 프레임워크의 한계 해결.

Method: 자기 진화형 데이터 플라이휠로 개선된 데이터를 생성하고, 이를 통해 LLM을 미세 조정하며, 두 단계의 행동 보정 훈련 프레임워크를 구현하여 잘못된 행동 패턴을 최적의 행동으로 점진적으로 보정한다.

Result: 다양한 차원에서 ET-Agent의 우수성을 입증하는 심층 실험을 수행했다.

Conclusion: ET-Agent 프레임워크는 TIR 분야의 연구에 실질적인 통찰을 제공한다.

Abstract: Large Language Models (LLMs) can extend their parameter knowledge limits by adopting the Tool-Integrated Reasoning (TIR) paradigm. However, existing LLM-based agent training framework often focuses on answers' accuracy, overlooking specific alignment for behavior patterns. Consequently, agent often exhibits ineffective actions during TIR tasks, such as redundant and insufficient tool calls. How to calibrate erroneous behavioral patterns when executing TIR tasks, thereby exploring effective trajectories, remains an open-ended problem. In this paper, we propose ET-Agent, a training framework for calibrating agent's tool-use behavior through two synergistic perspectives: Self-evolving Data Flywheel and Behavior Calibration Training. Specifically, we introduce a self-evolutionary data flywheel to generate enhanced data, used to fine-tune LLM to improve its exploration ability. Based on this, we implement an two-phases behavior-calibration training framework. It is designed to progressively calibrate erroneous behavioral patterns to optimal behaviors. Further in-depth experiments confirm the superiority of \ourmodel{} across multiple dimensions, including correctness, efficiency, reasoning conciseness, and tool execution accuracy. Our ET-Agent framework provides practical insights for research in the TIR field. Codes can be found in https://github.com/asilverlight/ET-Agent

</details>


### [24] [V2P: Visual Attention Calibration for GUI Grounding via Background Suppression and Center Peaking](https://arxiv.org/abs/2601.06899)
*Jikai Chen,Long Chen,Dong Wang,Qinglin Su,Zhixuan Chu,Bingguang Hao,Leilei Gan,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: 정확한 GUI 요소의 위치 파악을 위한 V2P 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: GUI 에이전트 개발에 있어 GUI 요소의 정확한 위치 파악은 필수적이다.

Method: V2P 방법은 배경의 간섭을 최소화하도록 설계된 억제 주의 메커니즘을 도입하고, 중심과 가장자리 구분을 위해 2D 가우시안 히트맵을 활용한다.

Result: V2P로 훈련된 모델은 ScreenSpot-v2에서 92.4%, ScreenSpot-Pro에서 52.5%의 성능을 달성하였다.

Conclusion: V2P는 GUI 기반 작업에서의 정확성을 향상시키고, 향후 GUI 에이전트에 대한 실제 배치 가능성을 보여준다.

Abstract: Precise localization of GUI elements is crucial for the development of GUI agents. Traditional methods rely on bounding box or center-point regression, neglecting spatial interaction uncertainty and visual-semantic hierarchies. Recent methods incorporate attention mechanisms but still face two key issues: (1) ignoring processing background regions causes attention drift from the desired area, and (2) uniform modeling the target UI element fails to distinguish between its center and edges, leading to click imprecision. Inspired by how humans visually process and interact with GUI elements, we propose the Valley-to-Peak (V2P) method to address these issues. To mitigate background distractions, V2P introduces a suppression attention mechanism that minimizes the model's focus on irrelevant regions to highlight the intended region. For the issue of center-edge distinction, V2P applies a Fitts' Law-inspired approach by modeling GUI interactions as 2D Gaussian heatmaps where the weight gradually decreases from the center towards the edges. The weight distribution follows a Gaussian function, with the variance determined by the target's size. Consequently, V2P effectively isolates the target area and teaches the model to concentrate on the most essential point of the UI element. The model trained by V2P achieves the performance with 92.4\% and 52.5\% on two benchmarks ScreenSpot-v2 and ScreenSpot-Pro (see Fig.~\ref{fig:main_results_charts}). Ablations further confirm each component's contribution, underscoring V2P's generalizability in precise GUI grounding tasks and its potential for real-world deployment in future GUI agents.

</details>


### [25] [mind_call: A Dataset for Mental Health Function Calling with Large Language Models](https://arxiv.org/abs/2601.06937)
*Fozle Rabbi Shafi,M. Anwar Hossain,Salimur Choudhury*

Main category: cs.AI

TL;DR: 정신 건강 지원을 위해 웨어러블 건강 신호에 기반한 합성 함수 호출 데이터 세트를 소개하는 논문.


<details>
  <summary>Details</summary>
Motivation: 정신 건강 중심의 웨어러블 센서 데이터 접근을 다루는 기존 데이터 세트의 부족.

Method: 다양한 자연어 쿼리를 표준화된 API 호출에 매핑한 합성 데이터 세트 생성.

Result: 각 샘플은 사용자 쿼리, 쿼리 카테고리, 명시적 추론 단계, 정규화된 시간 매개변수 및 대상 함수로 구성됨.

Conclusion: 이 자원은 LLM 기반 정신 건강 에이전트에서 의도 기반, 시간적 추론 및 신뢰할 수 있는 함수 호출 연구를 지원하며, 반복 가능성 및 향후 연구를 촉진하기 위해 공개됨.

Abstract: Large Language Model (LLM)-based systems increasingly rely on function calling to enable structured and controllable interaction with external data sources, yet existing datasets do not address mental health-oriented access to wearable sensor data. This paper presents a synthetic function-calling dataset designed for mental health assistance grounded in wearable health signals such as sleep, physical activity, cardiovascular measures, stress indicators, and metabolic data. The dataset maps diverse natural language queries to standardized API calls derived from a widely adopted health data schema. Each sample includes a user query, a query category, an explicit reasoning step, a normalized temporal parameter, and a target function. The dataset covers explicit, implicit, behavioral, symptom-based, and metaphorical expressions, which reflect realistic mental health-related user interactions. This resource supports research on intent grounding, temporal reasoning, and reliable function invocation in LLM-based mental health agents and is publicly released to promote reproducibility and future work.

</details>


### [26] [LLM Performance Predictors: Learning When to Escalate in Hybrid Human-AI Moderation Systems](https://arxiv.org/abs/2601.07006)
*Or Bachar,Or Levi,Sardhendu Mishra,Adi Levi,Manpreet Singh Minhas,Justin Miller,Omer Ben-Porat,Eilon Sheetrit,Jonathan Morra*

Main category: cs.AI

TL;DR: 이 논문은 LLM이 포함된 콘텐츠 조정 시스템에서 사람의 검토가 필요한 경우와 LLM의 출력을 신뢰할 수 있는 경우를 식별하기 위한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 콘텐츠 조정 시스템에 점점 더 많이 통합됨에 따라, LLM의 결과를 신뢰할 수 있는지와 인적 검토를 선호해야 하는지를 결정하는 것이 주요한 도전 과제가 되었습니다.

Method: 이 논문에서는 LLM 출력에서 파생된 LLM 성능 예측자(LPP)를 기반으로 전용 메타 모델을 학습하여 감독된 LLM 불확실성 정량화를 위한 새로운 프레임워크를 제안합니다. 이 메타 모델은 로그 확률, 엔트로피 및 새로운 불확실성 귀속 지표를 포함합니다.

Result: 최신 LLM (상용 및 오픈소스 포함)에서 진행한 실험은 기존의 불확실성 추정자에 비해 정확성-비용 거래에서 상당한 개선을 보여주었습니다.

Conclusion: 이 연구는 불확실성을 고려한 확장 가능하고 책임 있는 인간-AI 조정 워크플로우를 위한 원칙적인 프레임워크를 확립합니다.

Abstract: As LLMs are increasingly integrated into human-in-the-loop content moderation systems, a central challenge is deciding when their outputs can be trusted versus when escalation for human review is preferable. We propose a novel framework for supervised LLM uncertainty quantification, learning a dedicated meta-model based on LLM Performance Predictors (LPPs) derived from LLM outputs: log-probabilities, entropy, and novel uncertainty attribution indicators. We demonstrate that our method enables cost-aware selective classification in real-world human-AI workflows: escalating high-risk cases while automating the rest. Experiments across state-of-the-art LLMs, including both off-the-shelf (Gemini, GPT) and open-source (Llama, Qwen), on multimodal and multilingual moderation tasks, show significant improvements over existing uncertainty estimators in accuracy-cost trade-offs. Beyond uncertainty estimation, the LPPs enhance explainability by providing new insights into failure conditions (e.g., ambiguous content vs. under-specified policy). This work establishes a principled framework for uncertainty-aware, scalable, and responsible human-AI moderation workflows.

</details>


### [27] [CloneMem: Benchmarking Long-Term Memory for AI Clones](https://arxiv.org/abs/2601.07023)
*Sen Hu,Zhiyu Zhang,Yuxiang Wei,Xueran Han,Zhenheng Tang,Huacan Wang,Ronghao Chen*

Main category: cs.AI

TL;DR: AI Clones는 개인의 사고와 행동을 시뮬레이션하여 장기적이고 개인화된 상호작용을 가능하게 하며, 경험, 감정 및 의견을 시간에 따라 모델링하는 메모리 시스템에 대한 엄격한 요구사항을 제시한다. 기존 메모리 벤치마크는 주로 사용자-대화 기록에 의존하며, 이는 시간적으로 단편적이고 지속적인 삶의 궤적을 캡처하는 데 부족하다. 이 연구에서는 비대화적 디지털 흔적을 기반으로 하는 AI Clone 시나리오에서 장기 기억을 평가하기 위한 벤치마크인 CloneMem을 소개한다.


<details>
  <summary>Details</summary>
Motivation: AI Clone은 개인의 사고 및 행동을 시뮬레이션하여 개인화된 장기 상호작용을 가능하게 해야 하지만, 기존 메모리 시스템은 이러한 요구를 충족하지 못한다.

Method: CloneMem은 일기, 소셜 미디어 게시물, 이메일 등 비대화적인 디지털 흔적을 기반으로 한 장기 기억 평가를 위한 벤치마크로, 계층적 데이터 구성 프레임워크를 채택하여 장기적인 일관성을 보장하고 에이전트의 개인 상태 변화를 추적하는 능력을 평가하는 작업을 정의한다.

Result: 실험 결과, 현재 메모리 메커니즘이 이 설정에서 어려움을 겪고 있으며, 이는 개인화된 AI의 생명 기반 응용의 열린 과제를 강조한다.

Conclusion: CloneMem 벤치마크는 AI Clone 시나리오에서 장기 기억을 평가하기 위한 새로운 기준을 제시하며, 현재 메모리 시스템의 한계를 드러낸다.

Abstract: AI Clones aim to simulate an individual's thoughts and behaviors to enable long-term, personalized interaction, placing stringent demands on memory systems to model experiences, emotions, and opinions over time. Existing memory benchmarks primarily rely on user-agent conversational histories, which are temporally fragmented and insufficient for capturing continuous life trajectories. We introduce CloneMem, a benchmark for evaluating longterm memory in AI Clone scenarios grounded in non-conversational digital traces, including diaries, social media posts, and emails, spanning one to three years. CloneMem adopts a hierarchical data construction framework to ensure longitudinal coherence and defines tasks that assess an agent's ability to track evolving personal states. Experiments show that current memory mechanisms struggle in this setting, highlighting open challenges for life-grounded personalized AI. Code and dataset are available at https://github.com/AvatarMemory/CloneMemBench

</details>


### [28] [Dr. Zero: Self-Evolving Search Agents without Training Data](https://arxiv.org/abs/2601.07055)
*Zhenrui Yue,Kartikeya Upasani,Xianjun Yang,Suyu Ge,Shaoliang Nie,Yuning Mao,Zhe Liu,Dong Wang*

Main category: cs.AI

TL;DR: 데이터 없는 자기 진화가 복잡한 문제 해결 능력을 향상시키는 유망한 패러다임으로 자리잡았다. 본 연구에서는 Dr. Zero라는 프레임워크를 제안하여 검색 에이전트가 학습 데이터 없이 효과적으로 자기 진화할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 고품질 데이터를 얻기 어려워지면서 데이터 없는 자기 진화가 주목받고 있다.

Method: 제안자는 다양한 질문을 생성하고, 솔버는 같은 기본 모델에서 초기화되며 자기 진화 피드백 루프를 통해 훈련된다. 또한 HRPO 방법을 도입해 구조적으로 유사한 질문을 클러스터링하여 훈련 효율성을 높인다.

Result: HRPO는 솔버 훈련에 필요한 컴퓨팅 요구사항을 크게 줄이면서 성능이나 안정성을 해치지 않는다.

Conclusion: Dr. Zero는 완전 감독 검색 에이전트를 초월하는 성능을 보여주며, 복잡한 추론과 검색 능력이 자기 진화를 통해 나타날 수 있음을 입증한다.

Abstract: As high-quality data becomes increasingly difficult to obtain, data-free self-evolution has emerged as a promising paradigm. This approach allows large language models (LLMs) to autonomously generate and solve complex problems, thereby improving their reasoning capabilities. However, multi-turn search agents struggle in data-free self-evolution due to the limited question diversity and the substantial compute required for multi-step reasoning and tool using. In this work, we introduce Dr. Zero, a framework enabling search agents to effectively self-evolve without any training data. In particular, we design a self-evolution feedback loop where a proposer generates diverse questions to train a solver initialized from the same base model. As the solver evolves, it incentivizes the proposer to produce increasingly difficult yet solvable tasks, thus establishing an automated curriculum to refine both agents. To enhance training efficiency, we also introduce hop-grouped relative policy optimization (HRPO). This method clusters structurally similar questions to construct group-level baselines, effectively minimizing the sampling overhead in evaluating each query's individual difficulty and solvability. Consequently, HRPO significantly reduces the compute requirements for solver training without compromising performance or stability. Extensive experiment results demonstrate that the data-free Dr. Zero matches or surpasses fully supervised search agents, proving that complex reasoning and search capabilities can emerge solely through self-evolution.

</details>


### [29] [Active Context Compression: Autonomous Memory Management in LLM Agents](https://arxiv.org/abs/2601.07190)
*Nikhil Verma*

Main category: cs.AI

TL;DR: 대형 언어 모델(LLM) 에이전트가 "컨텍스트 부풀림"으로 인해 장기 소프트웨어 엔지니어링 작업에 어려움을 겪고 있다. 본 연구는 생물학적 탐사 전략에서 영감을 받아 에이전트 중심의 아키텍처인 Focus를 제안한다. Focus는 주요 학습을 지속적인 "지식" 블록으로 통합할 시기를 자율적으로 결정하고 불필요한 상호작용 기록을 삭제한다. 실험 결과, Focus는 평균 22.7%의 토큰 감소를 달성했다.


<details>
  <summary>Details</summary>
Motivation: 기존 대형 언어 모델이 장기 소프트웨어 엔지니어링 작업에서 겪는 문제인 '컨텍스트 부풀림' 해결.

Method: Focus라는 생물학적 탐사 전략에서 영감을 받은 에이전트 중심 아키텍처를 제안하고, 주요 학습을 통합하며 불필요한 상호작용 기록을 삭제하는 방법.

Result: Focus는 22.7%의 토큰 감소를 달성하면서도 정확도를 유지하며, 태스크당 평균 6.0회의 자율 압축을 수행했다.

Conclusion: 적절한 도구와 프롬프트를 제공하면 능력 있는 모델이 자율적으로 컨텍스트를 조절할 수 있으며, 태스크 성능을 희생하지 않고 비용 인식 에이전트 시스템의 길을 열 수 있다.

Abstract: Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to "Context Bloat." As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors. Existing solutions often rely on passive, external summarization mechanisms that the agent cannot control. This paper proposes Focus, an agent-centric architecture inspired by the biological exploration strategies of Physarum polycephalum (slime mold). The Focus Agent autonomously decides when to consolidate key learnings into a persistent "Knowledge" block and actively withdraws (prunes) the raw interaction history. Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. With aggressive prompting that encourages frequent compression, Focus achieves 22.7% token reduction (14.9M -> 11.5M tokens) while maintaining identical accuracy (3/5 = 60% for both agents). Focus performed 6.0 autonomous compressions per task on average, with token savings up to 57% on individual instances. We demonstrate that capable models can autonomously self-regulate their context when given appropriate tools and prompting, opening pathways for cost-aware agentic systems without sacrificing task performance.

</details>


### [30] [Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration](https://arxiv.org/abs/2601.07224)
*Yang Zhao,Yangou Ouyang,Xiao Ding,Hepeng Wang,Bibo Cai,Kai Xiong,Jinglong Gao,Zhouhao Sun,Li Du,Bing Qin,Ting Liu*

Main category: cs.AI

TL;DR: PRISM은 모델의 기존 지식과의 인지적 갈등 정도에 따라 데이터를 중재하는 동적 인식 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: Hybrid Supervised Fine-Tuning(SFT)과 Reinforcement Learning(RL) 간의 데이터 할당 메커니즘이 충분히 탐구되지 않았다.

Method: PRISM은 Schema Theory에 기반하여 데이터의 인지적 갈등 정도를 분석하여 중재합니다.

Result: WebShop과 ALFWorld에서 PRISM은 최신 혼합 방법을 초월하며 계산 비용을 최대 3.22배 줄입니다.

Conclusion: 내부 최적화 방침에 따라 데이터를 분리하는 것이 확장 가능하고 견고한 에이전트 정렬에 중요함을 제안합니다.

Abstract: While Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has become the standard paradigm for training LLM agents, effective mechanisms for data allocation between these stages remain largely underexplored. Current data arbitration strategies often rely on surface-level heuristics that fail to diagnose intrinsic learning needs. Since SFT targets pattern consolidation through imitation while RL drives structural adaptation via exploration, misaligning data with these functional roles causes severe optimization interference. We propose PRISM, a dynamics-aware framework grounded in Schema Theory that arbitrates data based on its degree of cognitive conflict with the model's existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring. In contrast, data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22$\times$. Our findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment.

</details>


### [31] [Lost in the Noise: How Reasoning Models Fail with Contextual Distractors](https://arxiv.org/abs/2601.07226)
*Seongyun Lee,Yongrae Jo,Minju Seo,Moontae Lee,Minjoon Seo*

Main category: cs.AI

TL;DR: 이 논문은 노이즈가 포함된 입력 컨텍스트에 대한 모델의 강건성을 평가하는 NoisyBench라는 새로운 벤치마크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 다양한 외부 정보에 대한 의존도가 증가하면서 노이즈가 포함된 입력 컨텍스트가 모델의 성능에 미치는 영향을 조사하고자 합니다.

Method: 11개의 데이터셋에서 다양한 노이즈 유형에 대한 모델 강건성을 체계적으로 평가하는 NoisyBench 벤치마크를 도입합니다.

Result: 최첨단 모델이 컨텍스트 분산 요소에 직면했을 때 성능이 80%까지 급격히 떨어짐을 발견했습니다.

Conclusion: RARE라는 제안된 방안을 통해 모호한 정보 속에서 유용한 정보를 식별하도록 유도함으로써 모델 강건성을 크게 향상시킬 수 있음을 보여주었습니다.

Abstract: Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current sanitized benchmarks fail to capture. We introduce NoisyBench, a comprehensive benchmark that systematically evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. Our evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. Crucially, we find that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. We find that prompting, context engineering, SFT, and outcome-reward only RL fail to ensure robustness; in contrast, our proposed Rationale-Aware Reward (RARE) significantly strengthens resilience by incentivizing the identification of helpful information within noise. Finally, we uncover an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrate via attention visualization that models disproportionately focus on distractor tokens, providing vital insights for building the next generation of robust, reasoning-capable agents.

</details>


### [32] [Yes FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for Humorous Meme Detection](https://arxiv.org/abs/2601.07232)
*Olivia Shanhong Liu,Pai Chet Ng,De Wen Soh,Konstantinos N. Plataniotis*

Main category: cs.AI

TL;DR: FLoReNce는 밈 이해를 닫힌 루프 과정으로 학습하고, 열린 루프 과정으로 추론하는 에이전틱 피드백 추론 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 의도를 해석해야 하는 독특한 도전 과제를 해결하기 위해.

Method: FLoReNce는 판단자가 비평하는 닫힌 루프와 유사한 경험을 가져오는 열린 루프를 사용하는 피드백 기반 방법이다.

Result: FLoReNce는 예측 성능과 설명 품질 모두를 향상시켰다.

Conclusion: 피드백 조절 프롬프트가 적응형 밈 유머 이해를 위한 유효한 경로임을 보여준다.

Abstract: Humorous memes blend visual and textual cues to convey irony, satire, or social commentary, posing unique challenges for AI systems that must interpret intent rather than surface correlations. Existing multimodal or prompting-based models generate explanations for humor but operate in an open loop,lacking the ability to critique or refine their reasoning once a prediction is made. We propose FLoReNce, an agentic feedback reasoning framework that treats meme understanding as a closed-loop process during learning and an open-loop process during inference. In the closed loop, a reasoning agent is critiqued by a judge; the error and semantic feedback are converted into control signals and stored in a feedback-informed, non-parametric knowledge base. At inference, the model retrieves similar judged experiences from this KB and uses them to modulate its prompt, enabling better, self-aligned reasoning without finetuning. On the PrideMM dataset, FLoReNce improves both predictive performance and explanation quality over static multimodal baselines, showing that feedback-regulated prompting is a viable path to adaptive meme humor understanding.

</details>


### [33] [Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition](https://arxiv.org/abs/2601.07239)
*Tanmay Joshi,Shourya Aggarwal,Anusa Saha,Aadi Pandey,Shreyash Dhoot,Vighnesh Rai,Raxit Goswami,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.AI

TL;DR: 이 논문에서는 대형 언어 모델(LLM)의 결정론적 추론이 불확실성을 모델링할 수 있는 능력을 저해하고, 출현 능력을 억압하며, 단일 취약 경로로 reasoning을 축소시키고, tail 위험을 숨김으로써 안전 정렬을 약화시킨다고 주장한다. 대신에 우리는 분포적 변동성을 측정하고 제어할 신호로 삼아 Stochastic CHAOS를 지지한다.


<details>
  <summary>Details</summary>
Motivation: 결정론적 추론은 소프트웨어의 이상적 목표로 자리잡고 있지만, LLM의 적절한 관리와 신뢰성을 위해서는 오히려 비결정론적 접근이 필요하다는 점을 강조한다.

Method: 결정론적 추론의 문제점을 실증적으로 분석하고, emergent abilities와 멀티 패스 reasoning의 저하를 보여준다.

Result: 결정론적 평가가 능력과 취약성을 과소평가하고, 안전 위험을 숨기며, 출현 능력과 다중 샘플 평가에서 나타나는 위험한 행동을 간과한다는 것을 입증한다.

Conclusion: 결정론적 추론 대신 분포적 변동성을 신호로 활용하는 비결정론적 접근이 LLM의 특성과 안전성을 보장하는 데 더 효과적임을 주장한다.

Abstract: Deterministic inference is a comforting ideal in classical software: the same program on the same input should always produce the same output. As large language models move into real-world deployment, this ideal has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has presented a detailed analysis of nondeterminism in LLM inference, showing how batch-invariant kernels and deterministic attention can enforce bitwise-identical outputs, positioning deterministic inference as a prerequisite for reproducibility and enterprise reliability.
  In this paper, we take the opposite stance. We argue that, for LLMs, deterministic inference kills. It kills the ability to model uncertainty, suppresses emergent abilities, collapses reasoning into a single brittle path, and weakens safety alignment by hiding tail risks. LLMs implement conditional distributions over outputs, not fixed functions. Collapsing these distributions to a single canonical completion may appear reassuring, but it systematically conceals properties central to artificial cognition. We instead advocate Stochastic CHAOS, treating distributional variability as a signal to be measured and controlled.
  Empirically, we show that deterministic inference is systematically misleading. Single-sample deterministic evaluation underestimates both capability and fragility, masking failure probability under paraphrases and noise. Phase-like transitions associated with emergent abilities disappear under greedy decoding. Multi-path reasoning degrades when forced onto deterministic backbones, reducing accuracy and diagnostic insight. Finally, deterministic evaluation underestimates safety risk by hiding rare but dangerous behaviors that appear only under multi-sample evaluation.

</details>


### [34] [LRAS: Advanced Legal Reasoning with Agentic Search](https://arxiv.org/abs/2601.07296)
*Yujin Zhou,Chuxue Cao,Jinluan Yang,Lijun Wu,Conghui He,Sirui Han,Yike Guo*

Main category: cs.AI

TL;DR: 본 논문은 법률 분야에서의 대규모 추론 모델의 한계를 극복하기 위해 '법률 추론 에이전트 검색(LRAS)' 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 법률 분야에서 대규모 추론 모델의 적용이 절차적 엄격성과 법적 논리에 대한 명확한 요구로 인해 제한되고 있습니다.

Method: LRAS는 법률 LLM을 정적이고 매개변수에 의존하는 '폐쇄 루프 사고'에서 동적이고 상호작용적인 '능동적 탐구'로 전환하기 위해 설계된 프레임워크입니다.

Result: 실험 결과, LRAS는 최첨단 기준 대비 8.2-32etter 성능을 보였으며, 신뢰할 수 있는 지식으로 깊이 있는 추론이 필요한 작업에서 가장 큰 성과가 나타났습니다.

Conclusion: 우리는 데이터와 모델을 곧 공개할 예정입니다.

Abstract: While Large Reasoning Models (LRMs) have demonstrated exceptional logical capabilities in mathematical domains, their application to the legal field remains hindered by the strict requirements for procedural rigor and adherence to legal logic. Existing legal LLMs, which rely on "closed-loop reasoning" derived solely from internal parametric knowledge, frequently suffer from lack of self-awareness regarding their knowledge boundaries, leading to confident yet incorrect conclusions. To address this challenge, we present Legal Reasoning with Agentic Search (LRAS), the first framework designed to transition legal LLMs from static and parametric "closed-loop thinking" to dynamic and interactive "Active Inquiry". By integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning, LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity. Empirical results demonstrate that LRAS outperforms state-of-the-art baselines by 8.2-32\%, with the most substantial gains observed in tasks requiring deep reasoning with reliable knowledge. We will release our data and models for further exploration soon.

</details>


### [35] [ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging](https://arxiv.org/abs/2601.07309)
*Zhuoka Feng,Kang Chen,Sihan Zhao,Kai Xiong,Yaoning Wang,Minshen Yu,Junjie Nian,Changyi Xiao,Yixin Cao,Yugang Jiang*

Main category: cs.AI

TL;DR: 주요 언어 모델 에이전트의 통합 방법을 제안하는 논문.


<details>
  <summary>Details</summary>
Motivation: 대부분의 대형 언어 모델이 특정 환경에 특화되어 있는 반면, 다양한 환경에 잘 적응하지 못하는 문제를 해결하고자 함.

Method: Agent-Role Merging (ARM)이라는 활성화 기반 역할 조건 신경 이식 방법을 사용하여 모델 병합을 수행함.

Result: ARM은 기존의 모델 병합 방법보다 다양한 상호작용 환경에서의 일반화 능력을 개선함.

Conclusion: ARM은 전문가 모델들과 이전의 모델 병합 방법보다 뛰어난 성능을 보이며, 범위 외 일반화에서 강력한 성능을 나타냄.

Abstract: Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. In this paper, we propose Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well designed 3-step framework: 1) constructing merged backbones, 2) selection based on its role-conditioned activation analysis, and 3) neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization.

</details>


### [36] [Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure](https://arxiv.org/abs/2601.07342)
*Nicolas Tacheny*

Main category: cs.AI

TL;DR: 이 논문은 대규모 통신 및 데이터 센터 인프라에서 고장 원인 분석을 위해 대형 언어 모델을 활용한 자율 진단 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 통신 및 데이터 센터 인프라는 다양한 서비스와 자원 모델에 의존하며, 고장이 물리적 및 논리적 구성 요소를 통해 전파되어 여러 고객에게 영향을 미칩니다. 전통적인 접근법은 유지 관리 비용이 높고 인프라 모델에 tightly coupled되어 있습니다.

Method: 우리는 대형 언어 모델(LLM)을 사용하여 제약된 도구 공간을 통해 단계별 조사를 수행하는 자율 진단 프레임워크를 소개합니다. 에이전트는 서비스 조회, 의존성 검색, 구조화 및 비구조화 데이터, 이벤트 분석 및 영향 발견을 위한 도구를 호출하여 인프라 모델을 자율적으로 탐색합니다.

Result: 이 연구는 자율적인 사건 해결 및 변화 영향 완화의 기초를 마련합니다. 미래의 시스템은 인프라 고장을 진단하고 수정할 뿐만 아니라 계획된 변경이 서비스와 고객에게 미치는 영향을 예측하여 운영자가 유지 보수 작업을 실행하기 전에 위험을 완화할 수 있도록 합니다.

Conclusion: 이 연구는 자율 사건 해결 및 변화 영향 완화의 기초가 됩니다.

Abstract: Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis(RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model.
  In this work, we introduce an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. We define an investigation protocol that structures the agent's reasoning and ensures grounding, reproducibility, and safe handling of missing or ambiguous information.
  This work lays the foundation for autonomous incident resolution and change impact mitigation. Future systems will not only diagnose and remediate infrastructure failures, but also predict the impact of planned changes on services and customers, enabling operators to mitigate risks before executing maintenance operations.

</details>


### [37] [OpenTinker: Separating Concerns in Agentic Reinforcement Learning](https://arxiv.org/abs/2601.07376)
*Siqi Zhu,Jiaxuan You*

Main category: cs.AI

TL;DR: OpenTinker는 대규모 언어 모델(RL) 에이전트를 위한 강화 학습 인프라로, 알고리즘 설계, 실행 및 에이전트-환경 상호작용을 분리하여 구성되어 있다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 에이전트의 학습을 효율적으로 수행하기 위해, 기존의 복잡한 end-to-end 강화 학습 파이프라인의 한계를 극복하고자 한다.

Method: OpenTinker는 에이전트, 환경 및 상호작용 프로토콜을 명확하게 정의된 추상화 경계로 분리하여 가벼운 구성 요소로 분해하는 개념을 도입하였다.

Result: 중앙 집중식 스케줄러를 통해 LoRA 기반 및 전체 파라미터 RL, 감독된 미세 조정 및 추론과 같은 학습 및 추론 작업을 관리할 수 있다.

Conclusion: OpenTinker는 실제 에이전트 학습 시나리오에서의 효율성을 입증하는 여러 강화 학습 사례를 소개하였다.

Abstract: We introduce OpenTinker, an infrastructure for reinforcement learning (RL) of large language model (LLM) agents built around a separation of concerns across algorithm design, execution, and agent-environment interaction. Rather than relying on monolithic, end-to-end RL pipelines, OpenTinker decomposes agentic learning systems into lightweight, composable components with clearly defined abstraction boundaries. Users specify agents, environments, and interaction protocols, while inference and training are delegated to a managed execution runtime. OpenTinker introduces a centralized scheduler for managing training and inference workloads, including LoRA-based and full-parameter RL, supervised fine-tuning, and inference, over shared resources. We further discuss design principles for extending OpenTinker to multi-agent training. Finally, we present a set of RL use cases that demonstrate the effectiveness of the framework in practical agentic learning scenarios.

</details>


### [38] [Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.07463)
*Sijia li,Xinran Li,Shibo Chen,Jun Zhang*

Main category: cs.AI

TL;DR: 오프라인 다중 에이전트 강화 학습(MARL)은 사전 수집된 데이터를 사용하여 다중 에이전트 시스템의 협동적 의사결정 문제를 해결하는 것을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 오프라인 MARL 방법은 데이터셋 분포 내에서 훈련을 제한하여 데이터 지원을 넘어서는 일반화에 어려움을 겪는 지나치게 보수적인 정책을 초래한다.

Method: 우리는 local-to-global (LOGO) 세계 모델을 제안하여 지역 예측을 활용하여 global 상태 역학을 추론하는 새로운 프레임워크를 구축하며, 이를 통해 예측 정확도를 향상시키고 에이전트 간의 의존성을 포착한다.

Result: 광범위한 실험을 통해 8개의 시나리오에서 8개의 기준선과 비교하여 우리의 방법이 기존 오프라인 MARL 기준선에서 최고의 성능을 초과함을 입증하였다.

Conclusion: 이 연구는 일반화 가능한 오프라인 다중 에이전트 학습을 위한 새로운 모델 기반 기준선을 확립한다.

Abstract: Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing offline MARL methods primarily constrain training within the dataset distribution, resulting in overly conservative policies that struggle to generalize beyond the support of the data. While model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model, the high dimensionality, non-stationarity, and complexity of multi-agent systems make it challenging to accurately estimate the transitions and reward functions in offline MARL. Given the difficulty of directly modeling joint dynamics, we propose a local-to-global (LOGO) world model, a novel framework that leverages local predictions-which are easier to estimate-to infer global state dynamics, thus improving prediction accuracy while implicitly capturing agent-wise dependencies. Using the trained world model, we generate synthetic data to augment the original dataset, expanding the effective state-action space. To ensure reliable policy learning, we further introduce an uncertainty-aware sampling mechanism that adaptively weights synthetic data by prediction uncertainty, reducing approximation error propagation to policies. In contrast to conventional ensemble-based methods, our approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that our method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning.

</details>


### [39] [Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents](https://arxiv.org/abs/2601.07468)
*Miao Su,Yucan Guo,Zhongni Hou,Long Bai,Zixuan Li,Yufei Zhang,Guojun Yin,Wei Lin,Xiaolong Jin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.AI

TL;DR: 기억은 LLM 에이전트가 과거 대화에서 정보를 인식, 저장 및 사용하는 데 필수적이나, 기존 방법들은 기억의 시간적 차원을 제대로 모델링하지 못한다. 이를 해결하기 위해 Temporal Semantic Memory (TSM)라는 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기억은 개인화를 위한 필수적인 요소로, LLM 에이전트가 과거 대화에서 정보를 효과적으로 활용할 수 있도록 한다.

Method: Temporal Semantic Memory (TSM) 프레임워크는 포인트형 기억을 위해 의미적 시간을 모델링하고 지속적 기억의 구축과 활용을 지원한다.

Result: LongMemEval 및 LoCoMo에서 TSM은 기존 방법들에 비해 일관되게 더 나은 성능을 보였으며, 최대 12.2%의 정확도 절대 향상을 달성했다.

Conclusion: 제안된 방법의 효과성을 입증한다.

Abstract: Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. However, existing methods fail to properly model the temporal dimension of memory in two aspects: 1) Temporal inaccuracy: memories are organized by dialogue time rather than their actual occurrence time; 2) Temporal fragmentation: existing methods focus on point-wise memory, losing durative information that captures persistent states and evolving patterns. To address these limitations, we propose Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. During memory construction, it first builds a semantic timeline rather than a dialogue one. Then, it consolidates temporally continuous and semantically related information into a durative memory. During memory utilization, it incorporates the query's temporal intent on the semantic timeline, enabling the retrieval of temporally appropriate durative memories and providing time-valid, duration-consistent context to support response generation. Experiments on LongMemEval and LoCoMo show that TSM consistently outperforms existing methods and achieves up to 12.2% absolute improvement in accuracy, demonstrating the effectiveness of the proposed method.

</details>


### [40] [Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory](https://arxiv.org/abs/2601.07470)
*Sirui Liang,Pengfei Cao,Jian Zhao,Wenhao Teng,Xiangwen Liao,Jun Zhao,Kang Liu*

Main category: cs.AI

TL;DR: 이 논문은 메타인지 메모리 추상화 방법(MCMA)을 제안하여 메모리 추상을 고정된 설계 선택이 아닌 학습 가능한 인지 기술로 다루고 있습니다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트는 장기 결정 과제를 해결하기 위해 축적된 메모리에 점점 의존하고 있습니다. 하지만 기존 방법들은 메모리를 고정된 표현으로 저장하고 절차의 단일 또는 암묵적인 수준에서 재사용하여 일반화 능력을 제한하고 있습니다.

Method: MCMA는 태스크 실행을 메모리 관리와 분리하여 고정된 태스크 모델과 학습된 메모리 코파일럿을 결합합니다. 메모리 코파일럿은 직접 선호 최적화를 이용하여 훈련되며, 메모리가 어떻게 구조화되고 추상화되며 재사용되어야 하는지를 결정합니다.

Result: ALFWorld, ScienceWorld, BabyAI에서의 실험 결과, 여러 기준선에 비해 성능, 분포 외 일반화 및 태스크 간 전이에서 상당한 개선이 있었습니다.

Conclusion: MCMA는 메모리를 추상화하고 관리하는 능력을 전이하는 방법으로 메모리 코파일럿을 전이합니다.

Abstract: Large language model (LLM) agents increasingly rely on accumulated memory to solve long-horizon decision-making tasks. However, most existing approaches store memory in fixed representations and reuse it at a single or implicit level of abstraction, which limits generalization and often leads to negative transfer when distribution shift. This paper proposes the Meta-Cognitive Memory Abstraction method (MCMA), which treats memory abstraction as a learnable cognitive skill rather than a fixed design choice. MCMA decouples task execution from memory management by combining a frozen task model with a learned memory copilot. The memory copilot is trained using direct preference optimization, it determines how memories should be structured, abstracted, and reused. Memories are further organized into a hierarchy of abstraction levels, enabling selective reuse based on task similarity. When no memory is transferable, MCMA transfers the ability to abstract and manage memory by transferring the memory copilot. Experiments on ALFWorld, ScienceWorld, and BabyAI demonstrate substantial improvements in performance, out-of-distribution generalization, and cross-task transfer over several baselines.

</details>


### [41] [JudgeFlow: Agentic Workflow Optimization via Block Judge](https://arxiv.org/abs/2601.07477)
*Zihan Ma,Zhikai Zhao,Chuanbo Hua,Federico Berto,Jinkyoo Park*

Main category: cs.AI

TL;DR: 이 연구는 AI 기능 확장을 위한 LLM 기반 에이전틱 워크플로우 최적화의 도전과제에 대해 다루고 있으며, 새로운 평가-판단-최적화-업데이트 파이프라인을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 에이전틱 워크플로우를 스케일링하는 것은 도전적이며, 현재 방법은 정교한 평가 신호가 부족하여 비효율적인 수정이 발생합니다.

Method: 제안하는 방법은 재사용 가능한 구성 가능한 논리 블록을 에이전틱 워크플로우에 포함시키고, 실행 추적을 검사하여 문제있는 블록에 순위 기반 책임 점수를 부여하는 Judge 모듈을 설계합니다.

Result: 우리의 접근법은 샘플 효율성을 향상시키고, 블록 수준의 진단을 통해 해석 가능성을 높이며, 복잡한 에이전틱 워크플로우 자동화를 위한 확장 가능한 기초를 제공합니다.

Conclusion: 수학적 추론 및 코드 생성 기준에서 우리의 방식이 기존 방법에 비해 우수한 성능과 효율성을 달성하였습니다.

Abstract: Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose {\our{}}, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces -- particularly failed runs -- and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate {\our{}} on mathematical reasoning and code generation benchmarks, where {\our{}} achieves superior performance and efficiency compared to existing methods. The source code is publicly available at https://github.com/ma-zihan/JudgeFlow.

</details>


### [42] [VirtualEnv: A Platform for Embodied AI Research](https://arxiv.org/abs/2601.07553)
*Kabir Swain,Sijie Han,Ayush Raina,Jin Zhang,Shuang Li,Michael Stopa,Antonio Torralba*

Main category: cs.AI

TL;DR: VirtualEnv는 LLM의 성능을 평가하기 위한 차세대 시뮬레이션 플랫폼입니다.


<details>
  <summary>Details</summary>
Motivation: LLM의 추론 및 의사결정 능력이 향상됨에 따라, 이들의 능력을 엄격히 평가할 수 있는 현실적이고 상호작용이 가능한 환경에 대한 필요성이 커지고 있습니다.

Method: 이 플랫폼은 Unreal Engine 5 기반으로 구축되어 LLM을 신체화되고 상호작용적인 시나리오에서 세분화된 벤치마킹을 가능하게 합니다.

Result: 여러 인기 LLM의 성능을 복잡도가 증가하는 작업을 통해 벤치마킹하고, 적응성, 계획 멀티 에이전트 조정의 차이를 분석하였습니다.

Conclusion: VirtualEnv는 오픈 소스 플랫폼으로 출시되어 AI와 게임의 교차점에서 연구를 진전시키고, 신체화된 AI 환경에서 LLM의 표준화된 평가를 가능하게 하며, 몰입형 시뮬레이션 및 상호작용 엔터테인먼트의 향후 발전들을 위한 길을 엽니다.

Abstract: As large language models (LLMs) continue to improve in reasoning and decision-making, there is a growing need for realistic and interactive environments where their abilities can be rigorously evaluated. We present VirtualEnv, a next-generation simulation platform built on Unreal Engine 5 that enables fine-grained benchmarking of LLMs in embodied and interactive scenarios. VirtualEnv supports rich agent-environment interactions, including object manipulation, navigation, and adaptive multi-agent collaboration, as well as game-inspired mechanics like escape rooms and procedurally generated environments. We provide a user-friendly API built on top of Unreal Engine, allowing researchers to deploy and control LLM-driven agents using natural language instructions. We integrate large-scale LLMs and vision-language models (VLMs), such as GPT-based models, to generate novel environments and structured tasks from multimodal inputs. Our experiments benchmark the performance of several popular LLMs across tasks of increasing complexity, analyzing differences in adaptability, planning, and multi-agent coordination. We also describe our methodology for procedural task generation, task validation, and real-time environment control. VirtualEnv is released as an open-source platform, we aim to advance research at the intersection of AI and gaming, enable standardized evaluation of LLMs in embodied AI settings, and pave the way for future developments in immersive simulations and interactive entertainment.

</details>


### [43] [Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents](https://arxiv.org/abs/2601.07577)
*Yunfan Li,Bingbing Xu,Xueyun Tian,Xiucheng Xu,Huawei Shen*

Main category: cs.AI

TL;DR: 이 논문은 Task-Decoupled Planning (TDP)라는 새로운 계획 방식을 제안하여 복잡한 작업 실행에서의 인지 부담을 줄이고 효율성을 개선하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)의 발전에도 불구하고, 신뢰할 수 있는 작업 실행을 위한 계획이 여전히 주요 Bottleneck으로 남아 있다.

Method: TDP는 작업을 Supervisor를 통해 방향성 비순환 그래프(DAG)의 하위 목표로 분해하고, 범위가 설정된 컨텍스트로 블래너와 실행기를 사용하여 활성 하위 작업에만 사고 및 재계획을 국한시킨다.

Result: TravelPlanner, ScienceWorld, HotpotQA에서의 결과는 TDP가 강력한 기준선보다 우수하며, 토큰 소비를 최대 82%까지 줄였음을 보여줍니다.

Conclusion: 하위 작업 분리는 장기간 작업을 위한 에이전트의 강건성과 효율성을 모두 향상시킨다.

Abstract: Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.

</details>


### [44] [DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning](https://arxiv.org/abs/2601.07611)
*Zhuoyang Zou,Abolfazl Ansari,Delvin Ce Zhang,Dongwon Lee,Wenpeng Yin*

Main category: cs.AI

TL;DR: DIAGPaper는 논문의 약점을 효과적으로 식별하기 위해 설계된 다중 에이전트 프레임워크로, 세 가지 모듈을 통해 기존 접근 방식의 한계를 극복한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 단일 또는 다중 에이전트 LLM을 이용한 논문 약점 식별 방식에 여러 한계가 있어, 더욱 효과적이고 사용자 지향적인 접근 방식이 필요하다.

Method: DIAGPaper는 사용자 정의 리뷰 기준을 시뮬레이션하는 커스터마이저 모듈, 리뷰어와 구조적 논쟁을 하는 저자 에이전트가 포함된 반박 모듈, 대규모 휴먼 리뷰 관행을 학습하여 약점의 심각성을 평가하는 우선 순위 지정 모듈로 구성된다.

Result: DIAGPaper는 AAAR 및 ReviewCritique 두 가지 벤치마크에서 실험을 통해 기존 방법보다 유효하고 논문에 맞는 약점을 더 많이 생성하며, 사용자가 쉽게 이해할 수 있도록 우선 순위를 매겨 제공함을 입증하였다.

Conclusion: DIAGPaper는 논문 리뷰 품질을 향상시키기 위한 혁신적이고 효과적인 솔루션으로 자리잡을 가능성이 있다.

Abstract: Paper weakness identification using single-agent or multi-agent LLMs has attracted increasing attention, yet existing approaches exhibit key limitations. Many multi-agent systems simulate human roles at a surface level, missing the underlying criteria that lead experts to assess complementary intellectual aspects of a paper. Moreover, prior methods implicitly assume identified weaknesses are valid, ignoring reviewer bias, misunderstanding, and the critical role of author rebuttals in validating review quality. Finally, most systems output unranked weakness lists, rather than prioritizing the most consequential issues for users. In this work, we propose DIAGPaper, a novel multi-agent framework that addresses these challenges through three tightly integrated modules. The customizer module simulates human-defined review criteria and instantiates multiple reviewer agents with criterion-specific expertise. The rebuttal module introduces author agents that engage in structured debate with reviewer agents to validate and refine proposed weaknesses. The prioritizer module learns from large-scale human review practices to assess the severity of validated weaknesses and surfaces the top-K severest ones to users. Experiments on two benchmarks, AAAR and ReviewCritique, demonstrate that DIAGPaper substantially outperforms existing methods by producing more valid and more paper-specific weaknesses, while presenting them in a user-oriented, prioritized manner.

</details>


### [45] [Reasoning Models Will Blatantly Lie About Their Reasoning](https://arxiv.org/abs/2601.07663)
*William Walden*

Main category: cs.AI

TL;DR: 대규모 추론 모델(LRMs)이 입력의 특정 부분이 그들의 추론에 어떻게 영향을 미치는지를 자발적으로 말하지 않으며, 이러한 정보를 생략하는 것과 거짓말하는 것은 다른 문제라는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: LRMs가 정보 생략과 거짓말의 차이를 명확히 이해하도록 하기 위함이다.

Method: Chen et al. (2025)의 연구를 확장하여, LRMs가 선택 질문에 대한 답변에서 제공된 힌스를 신뢰한다고 부인하는지 실험하였다.

Result: LRMs는 힌스를 사용하라고 요청받았음에도 불구하고, 힌스를 사용하고 있다는 실험 결과가 있음에도 불구하고 이를 부인하는 경향을 보였다.

Conclusion: 우리 결과는 CoT 모니터링과 해석 가능성에 대해 실망스러운 함의를 가진다.

Abstract: It has been shown that Large Reasoning Models (LRMs) may not *say what they think*: they do not always volunteer information about how certain parts of the input influence their reasoning. But it is one thing for a model to *omit* such information and another, worse thing to *lie* about it. Here, we extend the work of Chen et al. (2025) to show that LRMs will do just this: they will flatly deny relying on hints provided in the prompt in answering multiple choice questions -- even when directly asked to reflect on unusual (i.e. hinted) prompt content, even when allowed to use hints, and even though experiments *show* them to be using the hints. Our results thus have discouraging implications for CoT monitoring and interpretability.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [46] [Leveraging Membership Inference Attacks for Privacy Measurement in Federated Learning for Remote Sensing Images](https://arxiv.org/abs/2601.06200)
*Anh-Kiet Duong,Petra Gomez-Krämer,Hoàng-Ân Lê,Minh-Tan Pham*

Main category: cs.CR

TL;DR: 연합 학습(FL)은 데이터 프라이버시를 유지하면서 협업 모델 훈련을 가능하게 하지만, FL 모델이 여전히 민감한 정보를 유출할 수 있다는 최근 연구 결과가 나타났습니다. 이 논문에서는 원거리 감지 이미지 분류에 사용되는 FL에 대한 정량적 프라이버시 평가로 회원 추론 공격(MIA)을 활용합니다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습(FL) 모델이 출력값을 통해 민감한 정보를 누출할 수 있다는 최근 연구 결과에 따라, 프라이버시 평가의 필요성이 대두되고 있습니다.

Method: 이 논문에서는 원거리 감지 이미지 분류에 적용되는 FL을 위한 정량적 프라이버시 측정 프레임워크로 회원 추론 공격(MIA)을 활용합니다. 다양한 FL 알고리즘과 통신 전략을 통해 엔트로피 기반 공격, 수정된 엔트로피 공격, 그리고 우도를 기반으로 한 비율 공격 등 여러 가지 블랙박스 MIA 기법을 평가합니다.

Result: 두 개의 공개 장면 분류 데이터셋에서 수행된 실험 결과, MIA는 정확도만으로는 포착할 수 없는 프라이버시 유출을 효과적으로 드러냄을 보여줍니다. 우리의 결과는 통신 효율적인 FL 전략이 경쟁력 있는 성능을 유지하면서 MIA 성공률을 감소시킨다는 것을 보여줍니다.

Conclusion: 이 연구 결과는 MIA가 실용적인 지표로 자리잡고 있으며, 원거리 감지 응용을 위한 FL 시스템 설계에 프라이버시 측정 통합의 중요성을 강조합니다.

Abstract: Federated Learning (FL) enables collaborative model training while keeping training data localized, allowing us to preserve privacy in various domains including remote sensing. However, recent studies show that FL models may still leak sensitive information through their outputs, motivating the need for rigorous privacy evaluation. In this paper, we leverage membership inference attacks (MIA) as a quantitative privacy measurement framework for FL applied to remote sensing image classification. We evaluate multiple black-box MIA techniques, including entropy-based attacks, modified entropy attacks, and the likelihood ratio attack, across different FL algorithms and communication strategies. Experiments conducted on two public scene classification datasets demonstrate that MIA effectively reveals privacy leakage not captured by accuracy alone. Our results show that communication-efficient FL strategies reduce MIA success rates while maintaining competitive performance. These findings confirm MIA as a practical metric and highlight the importance of integrating privacy measurement into FL system design for remote sensing applications.

</details>


### [47] [Multi-Agent Framework for Controllable and Protected Generative Content Creation: Addressing Copyright and Provenance in AI-Generated Media](https://arxiv.org/abs/2601.06232)
*Haris Khan,Sadia Asif,Shumaila Asif*

Main category: cs.CR

TL;DR: 이 논문은 생성 AI 시스템의 발전이 콘텐츠 생성에 중대한 기회를 제공하는 동시에 지적 재산권과 콘텐츠 출처에 대한 우려를 제기한다는 점을 다룬다. 새로운 다중 에이전트 프레임워크를 제안하여 이러한 문제를 해결하고 안전한 창의적 작업 흐름을 보장한다.


<details>
  <summary>Details</summary>
Motivation: 생성 AI 시스템의 사용이 증가함에 따라 조절 가능성, 저작권 침해, 콘텐츠 출처와 같은 문제들이 부각되고 있다.

Method: 전문 에이전트 역할과 통합 워터마킹을 통해 이러한 문제를 해결하는 새로운 다중 에이전트 프레임워크를 제안한다.

Result: 두 가지 사례 연구를 통해 창의적 콘텐츠 생성과 상업적 맥락에서 AI 생성 예술에 대한 저작권 보호의 실행 가능성을 입증했다.

Conclusion: 이 연구는 책임 있는 생성 AI 배포에 기여하며, 다중 에이전트 시스템이 법적 및 상업적 응용에서 신뢰할 수 있는 창의적 작업 흐름의 솔루션으로 자리매김할 수 있음을 보여준다.

Abstract: The proliferation of generative AI systems creates unprecedented opportunities for content creation while raising critical concerns about controllability, copyright infringement, and content provenance. Current generative models operate as "black boxes" with limited user control and lack built-in mechanisms to protect intellectual property or trace content origin. We propose a novel multi-agent framework that addresses these challenges through specialized agent roles and integrated watermarking. Our system orchestrates Director, Generator, Reviewer, Integration, and Protection agents to ensure user intent alignment while embedding digital provenance markers. We demonstrate feasibility through two case studies: creative content generation with iterative refinement and copyright protection for AI-generated art in commercial contexts. Preliminary feasibility evidence from prior work indicates up to 23\% improvement in semantic alignment and 95\% watermark recovery rates. This work contributes to responsible generative AI deployment, positioning multi-agent systems as a solution for trustworthy creative workflows in legal and commercial applications.

</details>


### [48] [Agentic AI Microservice Framework for Deepfake and Document Fraud Detection in KYC Pipelines](https://arxiv.org/abs/2601.06241)
*Chandra Sekhar Kubam*

Main category: cs.CR

TL;DR: 본 논문은 KYC 업무에서의 사기 방지를 위한 Agentic AI 마이크로서비스 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 금융 서비스, 통신 및 디지털 신원 생태계 전반에 걸쳐 KYC 워크플로우에서의 취약성을 해결하고자 한다.

Method: 모듈형 비전 모델, 생동감 평가, 딥페이크 검출, OCR 기반 문서 포렌식, 다중 모달 신원 연결 및 정책 주도적 위험 엔진을 통합한 Agentic AI 마이크로서비스 프레임워크를 개발.

Result: 실험 평가를 통해 탐지 정확도를 향상시키고, 지연 시간을 줄이며, 적대적 입력에 대한 회복력을 높였다.

Conclusion: 이 프레임워크는 강력하고 실시간으로 개인 프라이버시를 보호하는 KYC 검증을 원하는 규제 산업을 위한 확장 가능한 청사진을 제공한다.

Abstract: The rapid proliferation of synthetic media, presentation attacks, and document forgeries has created significant vulnerabilities in Know Your Customer (KYC) workflows across financial services, telecommunications, and digital-identity ecosystems. Traditional monolithic KYC systems lack the scalability and agility required to counter adaptive fraud. This paper proposes an Agentic AI Microservice Framework that integrates modular vision models, liveness assessment, deepfake detection, OCR-based document forensics, multimodal identity linking, and a policy driven risk engine. The system leverages autonomous micro-agents for task decomposition, pipeline orchestration, dynamic retries, and human-in-the-loop escalation. Experimental evaluations demonstrate improved detection accuracy, reduced latency, and enhanced resilience against adversarial inputs. The framework offers a scalable blueprint for regulated industries seeking robust, real-time, and privacy-preserving KYC verification.

</details>


### [49] [Beyond BeautifulSoup: Benchmarking LLM-Powered Web Scraping for Everyday Users](https://arxiv.org/abs/2601.06301)
*Arth Bhardwaj,Nirav Diwan,Gang Wang*

Main category: cs.CR

TL;DR: 대형 언어 모델이 웹 스크래핑을 민주화하여 비숙련 사용자도 복잡한 웹사이트에서 데이터를 추출할 수 있게 되었다.


<details>
  <summary>Details</summary>
Motivation: 웹 스크래핑은 역사적으로 기술적 전문성을 요구했으며, 이는 숙련된 개발자만 대규모 데이터 추출을 가능하게 했다.

Method: 우리는 기존 LLM 도구를 활용하여 사용자들이 35개의 웹사이트에서 인증, 안티 봇 및 CAPTCHA 제어를 포함한 5가지 보안 계층을 대상으로 웹 스크래핑을 수행할 수 있는 방법을 체계적으로 평가했습니다. 두 가지 작업 흐름을 고안하고 평가했습니다: LLM 지원 스크립팅과 종단간 LLM 에이전트, 후자는 통합 도구를 통해 자율적으로 탐색하고 데이터를 추출합니다.

Result: 종단간 LLM 에이전트는 복잡한 웹 스크래핑을 접근 가능하게 만들어 단 하나의 프롬프트로 최소한의 수정(5회 미만)만으로도 작업 흐름을 완료할 수 있게 합니다.

Conclusion: 이 연구 결과는 초보자가 이러한 작업 흐름을 사용하도록 돕기 위한 간단한 절차를 제공하며, 악의적인 사용자가 이러한 도구를 사용하여 어떤 일을 할 수 있는지 평가합니다.

Abstract: Web scraping has historically required technical expertise in HTML parsing, session management, and authentication circumvention, which limited large-scale data extraction to skilled developers. We argue that large language models (LLMs) have democratized web scraping, enabling low-skill users to execute sophisticated operations through simple natural language prompts. While extensive benchmarks evaluate these tools under optimal expert conditions, we show that without extensive manual effort, current LLM-based workflows allow novice users to scrape complex websites that would otherwise be inaccessible. We systematically benchmark what everyday users can do with off-the-shelf LLM tools across 35 sites spanning five security tiers, including authentication, anti-bot, and CAPTCHA controls. We devise and evaluate two distinct workflows: (a) LLM-assisted scripting, where users prompt LLMs to generate traditional scraping code but maintain manual execution control, and (b) end-to-end LLM agents, which autonomously navigate and extract data through integrated tool use. Our results demonstrate that end-to-end agents have made complex scraping accessible - requiring as little as a single prompt with minimal refinement (less than 5 changes) to complete workflows. We also highlight scenarios where LLM-assisted scripting may be simpler and faster for static sites. In light of these findings, we provide simple procedures for novices to use these workflows and gauge what adversaries could achieve using these.

</details>


### [50] [Lightweight Yet Secure: Secure Scripting Language Generation via Lightweight LLMs](https://arxiv.org/abs/2601.06419)
*Keyang Zhang,Zeyu Chen,Xuan Feng,Dongliang Fang,Yaowen Zheng,Zhi Li,Limin Sun*

Main category: cs.CR

TL;DR: 이 논문은 안전한 스크립트 생성을 위한 LLM 성능을 평가하는 SecGenEval-PS 벤치마크와, 보안 기능을 향상시키기 위한 PSSec 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: PowerShell과 같은 스크립트 언어의 보안은 중요한데, 이는 자주 권한이 상승된 상태에서 자동화 및 관리 기능이 수행되기 때문입니다. 이러한 언어의 보안을 강화하는 데는 많은 인적 노력이 필요합니다.

Method: SecGenEval-PS 벤치마크를 통해 LLM의 안전한 스크립트 생성 능력을 평가하고, PSSec 프레임워크를 통해 보안 능력을 향상시키는 방법으로 데이터 합성과 미세 조정을 결합합니다.

Result: GPT-4o와 o3-mini가 생성한 60% 이상의 PowerShell 스크립트가 구조화된 지침 없이 불안전하다는 것을 발견했습니다.

Conclusion: PSSec 트레인 모델은 PowerShell 보안 작업에서 일반 목적의 대형 모델을 초과하거나 일치하며, 추론 비용을 크게 줄이는 데 성공했습니다.

Abstract: The security of scripting languages such as PowerShell is critical given their powerful automation and administration capabilities, often exercised with elevated privileges. Today, securing these languages still demands substantial human effort to craft and enforce rules, imposing heavy burdens on typical administrators and creating critical production risks (e.g., misoperations that shut down servers).Large language models (LLMs) have demonstrated strong capabilities in code generation, vulnerability detection, and automated repair for languages like Python and JavaScript. However, their ability to assist with generating secure scripting-language code remains largely underexplored. In this paper, we present SecGenEval-PS, a benchmark designed to systematically evaluate LLMs on secure scripting generation, security analysis, and automated repair. Our results show that both proprietary and open-source models fall short in these areas. For instance, over 60% of PowerShell scripts produced by GPT-4o and o3-mini are insecure without structured guidance.To bridge this gap, we propose PSSec, a framework that combines data synthesis with fine-tuning to enhance model security capabilities. We develop a self-debugging agent that integrates static analyzers with the reasoning abilities of advanced LLMs to synthesize large-scale structured triplets of insecure scripts, violation analyses, and corresponding repairs. We then fine-tune lightweight LLMs (as small as 1.7B parameters) using supervised fine-tuning (SFT) and reinforcement learning (RL), enabling security-aware reasoning and the generation of secure PowerShell code.Across multiple LLM families, including GPT and Qwen, \textit{PSSec}-trained models match or surpass general-purpose large models on PowerShell security tasks while reducing inference cost by more than an order of magnitude.

</details>


### [51] [CHASE: LLM Agents for Dissecting Malicious PyPI Packages](https://arxiv.org/abs/2601.06838)
*Takaaki Toda,Tatsuya Mori*

Main category: cs.CR

TL;DR: 모던 소프트웨어 패키지 레지스트리는 악성 패키지를 배포하는 위협 행위자에 의해 점점 더 악용되고 있으며, CHASE는 이러한 문제를 해결하기 위한 고신뢰성 다중 에이전트 아키텍처를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현대 소프트웨어 개발을 위한 인프라로서 패키지 등록소가 필수적이며, 그러나 이들은 악성 패키지에 의해 점점 더 악용되는 현상이 발생하고 있습니다.

Method: CHASE는 세분화된 분석을 위한 전문 워커 에이전트를 포함하는 계획 및 실행 조정 모델을 통해 다중 에이전트 아키텍처로 구축되었습니다.

Result: 3,000개 패키지에서 테스트한 결과, CHASE는 98.4%의 재현율과 0.08%의 낮은 오탐률을 기록했습니다.

Conclusion: 이 연구는 신뢰할 수 있는 AI 기반 보안 도구를 구축하기 위한 청사진을 제공합니다.

Abstract: Modern software package registries like PyPI have become critical infrastructure for software development, but are increasingly exploited by threat actors distributing malicious packages with sophisticated multi-stage attack chains. While Large Language Models (LLMs) offer promising capabilities for automated code analysis, their application to security-critical malware detection faces fundamental challenges, including hallucination and context confusion, which can lead to missed detections or false alarms. We present CHASE (Collaborative Hierarchical Agents for Security Exploration), a high-reliability multi-agent architecture that addresses these limitations through a Plan-and-Execute coordination model, specialized Worker Agents focused on specific analysis aspects, and integration with deterministic security tools for critical operations. Our key insight is that reliability in LLM-based security analysis emerges not from improving individual model capabilities but from architecting systems that compensate for LLM weaknesses while leveraging their semantic understanding strengths. Evaluation on a dataset of 3,000 packages (500 malicious, 2,500 benign) demonstrates that CHASE achieves 98.4% recall with only 0.08% false positive rate, while maintaining a practical median analysis time of 4.5 minutes per package, making it suitable for operational deployment in automated package screening. Furthermore, we conducted a survey with cybersecurity professionals to evaluate the generated analysis reports, identifying their key strengths and areas for improvement. This work provides a blueprint for building reliable AI-powered security tools that can scale with the growing complexity of modern software supply chains. Our project page is available at https://t0d4.github.io/CHASE-AIware25/

</details>


### [52] [qAttCNN - Self Attention Mechanism for Video QoE Prediction in Encrypted Traffic](https://arxiv.org/abs/2601.06862)
*Michael Sidorov,Ofer Hadar*

Main category: cs.CR

TL;DR: 비디오 회의 애플리케이션(VCA)와 메신저 앱(IMA)의 사용 증가에 대응하기 위해, 딥러닝 기반의 QoE 예측 모델인 qAttCNN을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 모바일 기기의 발전으로 인한 멀티미디어 소비의 급증으로 인해 비디오 회의 및 메신저 애플리케이션의 사용이 증가하고 있으며, 이는 품질 저하 문제를 동반한다.

Method: 패킷 크기 파라미터를 활용하여 두 가지 비참조 QoE 메트릭인 BRISQUE 및 초당 프레임(FPS)을 유추하는 한 모델을 제안한다.

Result: qAttCNN은 WhatsApp 비디오 통화에서 수집한 custom dataset을 사용해 평가되었고, 기존 QoE 모델과 비교하여 BRISQUE에서 2.14%의 오류, FPS 예측에서 7.39%의 오류를 기록했다.

Conclusion: QoE 모니터링 및 예측을 위한 새로운 접근 방식을 제공하며, 이는 실시간 커뮤니케이션 품질 유지에 기여할 수 있다.

Abstract: The rapid growth of multimedia consumption, driven by major advances in mobile devices since the mid-2000s, has led to widespread use of video conferencing applications (VCAs) such as Zoom and Google Meet, as well as instant messaging applications (IMAs) like WhatsApp and Telegram, which increasingly support video conferencing as a core feature. Many of these systems rely on the Web Real-Time Communication (WebRTC) protocol, enabling direct peer-to-peer media streaming without requiring a third-party server to relay data, reducing the latency and facilitating a real-time communication. Despite WebRTC's potential, adverse network conditions can degrade streaming quality and consequently reduce users' Quality of Experience (QoE). Maintaining high QoE therefore requires continuous monitoring and timely intervention when QoE begins to deteriorate. While content providers can often estimate QoE by directly comparing transmitted and received media, this task is significantly more challenging for internet service providers (ISPs). End-to-end encryption, commonly used by modern VCAs and IMAs, prevent ISPs from accessing the original media stream, leaving only Quality of Service (QoS) and routing information available. To address this limitation, we propose the QoE Attention Convolutional Neural Network (qAttCNN), a model that leverages packet size parameter of the traffic to infer two no-reference QoE metrics viz. BRISQUE and frames per second (FPS). We evaluate qAttCNN on a custom dataset collected from WhatsApp video calls and compare it against existing QoE models. Using mean absolute error percentage (MAEP), our approach achieves 2.14% error for BRISQUE and 7.39% for FPS prediction.

</details>


### [53] [MemTrust: A Zero-Trust Architecture for Unified AI Memory System](https://arxiv.org/abs/2601.07004)
*Xing Zhou,Dmitrii Ustiugov,Haoxin Shang,Kisson Lin*

Main category: cs.CR

TL;DR: AI 메모리 시스템은 효율적인 협업과 다중 도구 워크플로우를 가능하게 하는 통합 컨텍스트 레이어로 발전하고 있습니다. 그러나 중앙 집중화는 사용자로 하여금 클라우드 제공업체에 민감한 데이터를 맡기게 하여 신뢰 위기를 초래합니다. 이 논문은 개인화 요구와 데이터 주권 사이의 긴장을 해결하기 위해, 지역적으로 동등한 보안과 효율적인 유지 관리, 협업 능력을 동시에 달성하는 것을 목표로 합니다. 이를 위해 우리는 다섯 개의 계층을 가진 아키텍처를 제안하며, 각 계층에 TEE 보호를 적용하여 신뢰할 수 있는 프레임워크를 구축합니다.


<details>
  <summary>Details</summary>
Motivation: AI 메모리 시스템의 중앙집중화로 인해 사용자의 민감한 데이터가 클라우드 제공업체에 노출되는 신뢰 위기가 발생하고 있습니다.

Method: 다섯 개의 계층 구조(Storage, Extraction, Learning, Retrieval, Governance)를 제안하고, TEE 보호를 각 계층에 적용하여 MemTrust라는 하드웨어 기반 제로 트러스트 아키텍처를 설계합니다.

Result: MemTrust는 모든 계층에서 암호화 보장을 제공하고, 기존 시스템을 개발 비용이 수용 가능한 수준에서 포팅할 수 있도록 하여 시스템 전체의 신뢰성을 달성합니다.

Conclusion: AI 메모리는 에이전트와 AI 도구의 효율성을 높이는 데 중요한 역할을 하며, MemTrust는 AI 메모리 시스템을 위한 보편적으로 신뢰할 수 있는 프레임워크로 자리 잡을 것입니다.

Abstract: AI memory systems are evolving toward unified context layers that enable efficient cross-agent collaboration and multi-tool workflows, facilitating better accumulation of personal data and learning of user preferences. However, centralization creates a trust crisis where users must entrust cloud providers with sensitive digital memory data. We identify a core tension between personalization demands and data sovereignty: centralized memory systems enable efficient cross-agent collaboration but expose users' sensitive data to cloud provider risks, while private deployments provide security but limit collaboration. To resolve this tension, we aim to achieve local-equivalent security while enabling superior maintenance efficiency and collaborative capabilities. We propose a five-layer architecture abstracting common functional components of AI memory systems: Storage, Extraction, Learning, Retrieval, and Governance. By applying TEE protection to each layer, we establish a trustworthy framework. Based on this, we design MemTrust, a hardware-backed zero-trust architecture that provides cryptographic guarantees across all layers. Our contributions include the five-layer abstraction, "Context from MemTrust" protocol for cross-application sharing, side-channel hardened retrieval with obfuscated access patterns, and comprehensive security analysis. The architecture enables third-party developers to port existing systems with acceptable development costs, achieving system-wide trustworthiness. We believe that AI memory plays a crucial role in enhancing the efficiency and collaboration of agents and AI tools. AI memory will become the foundational infrastructure for AI agents, and MemTrust serves as a universal trusted framework for AI memory systems, with the goal of becoming the infrastructure of memory infrastructure.

</details>


### [54] [Overcoming the Retrieval Barrier: Indirect Prompt Injection in the Wild for LLM Systems](https://arxiv.org/abs/2601.07072)
*Hongyan Chang,Ergute Bao,Xinjian Luo,Ting Yu*

Main category: cs.CR

TL;DR: 본 논문에서는 간접 프롬프트 주입(IPI) 공격을 해결하기 위해, 악성 콘텐츠의 트리거 및 공격 조각을 분리하여 안전한 검색을 보장하는 방법을 제안한다. 설계한 블랙박스 공격 알고리즘은 API 접근만으로도 다양한 임베딩 모델에서 높은 검색 성공률을 보인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델(LLM)은 외부 말뭉치에서 정보를 검색하는 데 의존하고 있으며, 이에 따라 새로운 공격 Surface가 생겨났다. 이론적으로는 악의적 콘텐츠가 검색되는 것을 보장하는 것이 가장 어려운 단계이다.

Method: 악성 콘텐츠를 검색을 보장하는 트리거 조각과 임의의 공격 목표를 인코딩하는 공격 조각으로 분해하여, 이들을 기반으로 효율적이고 효과적인 블랙박스 공격 알고리즘을 설계하였다.

Result: 이 공격은 API 접근만으로 가능하며 비용이 효율적(오픈AI의 임베딩 모델에서 대상 사용자 쿼리당 $0.21)이고, 11개 벤치마크 및 8개 임베딩 모델에서 100%에 가까운 검색 성공률을 달성하였다.

Conclusion: 결과적으로, IPI는 실질적이고 심각한 위협으로 성립되었으며, 자연어 쿼리로 이메일을 요약하는 방법으로 GPT-4o를 SSH 키를 외부로 유출하도록 유도하는 데 80% 이상의 성공률을 보였다.

Abstract: Large language models (LLMs) increasingly rely on retrieving information from external corpora. This creates a new attack surface: indirect prompt injection (IPI), where hidden instructions are planted in the corpora and hijack model behavior once retrieved. Previous studies have highlighted this risk but often avoid the hardest step: ensuring that malicious content is actually retrieved. In practice, unoptimized IPI is rarely retrieved under natural queries, which leaves its real-world impact unclear.
  We address this challenge by decomposing the malicious content into a trigger fragment that guarantees retrieval and an attack fragment that encodes arbitrary attack objectives. Based on this idea, we design an efficient and effective black-box attack algorithm that constructs a compact trigger fragment to guarantee retrieval for any attack fragment. Our attack requires only API access to embedding models, is cost-efficient (as little as $0.21 per target user query on OpenAI's embedding models), and achieves near-100% retrieval across 11 benchmarks and 8 embedding models (including both open-source models and proprietary services).
  Based on this attack, we present the first end-to-end IPI exploits under natural queries and realistic external corpora, spanning both RAG and agentic systems with diverse attack objectives. These results establish IPI as a practical and severe threat: when a user issued a natural query to summarize emails on frequently asked topics, a single poisoned email was sufficient to coerce GPT-4o into exfiltrating SSH keys with over 80% success in a multi-agent workflow. We further evaluate several defenses and find that they are insufficient to prevent the retrieval of malicious text, highlighting retrieval as a critical open vulnerability.

</details>


### [55] [Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework](https://arxiv.org/abs/2601.07122)
*Yixiao Peng,Hao Hu,Feiyang Li,Xinye Cao,Yingchang Jiang,Jipeng Tang,Guoshun Nan,Yuling Liu*

Main category: cs.CR

TL;DR: 이 논문은 클라우드 방어를 위한 강력한 LLM-RL 프레임워크인 CyberOps-Bots를 제안하며, 실시간으로 동적인 변화에 적응하고 공격 전략에 대처할 수 있도록 지원한다.


<details>
  <summary>Details</summary>
Motivation: 가상화 및 자원 풀링이 클라우드 네트워크의 구조적 유연성과 탄력적 확장성을 제공하지만, 공격 표면을 확장하고 사이버 복원력을 저하시킨다는 문제에 직면해 있다.

Method: CyberOps-Bots는 MITRE ATT&CK의 전술-기법 모델에서 영감을 받아 설계된 2계층 구조의 계층적 다중 에이전트 강화 학습 프레임워크이다. 상위 레벨 LLM 에이전트는 ReAct 계획, IPDRR 기반 지각, 장기-단기 기억, 행동/도구 통합의 네 가지 모듈로 구성되어 있으며, 하위 레벨 RL 에이전트는 이종 분리 사전 훈련을 통해 개발되어 지역화된 네트워크 영역에서 원자적 방어 행동을 실행한다.

Result: 실제 클라우드 데이터 세트에서 CyberOps-Bots는 최신 알고리즘보다 네트워크 가용성을 68.5% 더 유지하며, 재훈련 없이 시나리오 전환 시 34.7%의 성능 향상을 달성한다.

Conclusion: HITL 지원을 갖춘 강력한 LLM-RL 프레임워크를 설정한 첫 번째 연구로, 클라우드 네트워크의 강력하고 자율적인 방어 발전을 촉진하기 위해 프레임워크를 커뮤니티에 공개할 예정이다.

Abstract: While virtualization and resource pooling empower cloud networks with structural flexibility and elastic scalability, they inevitably expand the attack surface and challenge cyber resilience. Reinforcement Learning (RL)-based defense strategies have been developed to optimize resource deployment and isolation policies under adversarial conditions, aiming to enhance system resilience by maintaining and restoring network availability. However, existing approaches lack robustness as they require retraining to adapt to dynamic changes in network structure, node scale, attack strategies, and attack intensity. Furthermore, the lack of Human-in-the-Loop (HITL) support limits interpretability and flexibility. To address these limitations, we propose CyberOps-Bots, a hierarchical multi-agent reinforcement learning framework empowered by Large Language Models (LLMs). Inspired by MITRE ATT&CK's Tactics-Techniques model, CyberOps-Bots features a two-layer architecture: (1) An upper-level LLM agent with four modules--ReAct planning, IPDRR-based perception, long-short term memory, and action/tool integration--performs global awareness, human intent recognition, and tactical planning; (2) Lower-level RL agents, developed via heterogeneous separated pre-training, execute atomic defense actions within localized network regions. This synergy preserves LLM adaptability and interpretability while ensuring reliable RL execution. Experiments on real cloud datasets show that, compared to state-of-the-art algorithms, CyberOps-Bots maintains network availability 68.5% higher and achieves a 34.7% jumpstart performance gain when shifting the scenarios without retraining. To our knowledge, this is the first study to establish a robust LLM-RL framework with HITL support for cloud defense. We will release our framework to the community, facilitating the advancement of robust and autonomous defense in cloud networks.

</details>


### [56] [MacPrompt: Maraconic-guided Jailbreak against Text-to-Image Models](https://arxiv.org/abs/2601.07141)
*Xi Ye,Yiwen Liu,Lina Wang,Run Wang,Geying Yang,Yufei Hou,Jiayi Yu*

Main category: cs.CR

TL;DR: T2I 모델의 안전성 문제를 다루기 위한 새로운 공격 방식인 MacPrompt를 소개한다.


<details>
  <summary>Details</summary>
Motivation: T2I 모델이 생성하는 NSFW 및 금지된 객체로 인한 안전 문제를 완화할 필요성이 커지고 있다.

Method: MacPrompt는 유해한 용어의 크로스-링귤라(다국어) 문자 수준 재조합을 통해 마카로닉 적대적 프롬프트를 구성한다.

Result: MacPrompt는 원래 유해 입력에 대해 높은 의미적 유사성을 유지하면서 주요 안전 필터를 우회하는 데 성공하며, 성 관련 콘텐츠에서 92%, 폭력 관련 콘텐츠에서 90%의 공격 성공률을 달성하였다.

Conclusion: 기존 T2I 안전 메커니즘이 언어적으로 다양한 적대적 전략에 대해 얼마나 견고한지를 재평가해야 할 필요성이 있음을 강조한다.

Abstract: Text-to-image (T2I) models have raised increasing safety concerns due to their capacity to generate NSFW and other banned objects. To mitigate these risks, safety filters and concept removal techniques have been introduced to block inappropriate prompts or erase sensitive concepts from the models. However, all the existing defense methods are not well prepared to handle diverse adversarial prompts. In this work, we introduce MacPrompt, a novel black-box and cross-lingual attack that reveals previously overlooked vulnerabilities in T2I safety mechanisms. Unlike existing attacks that rely on synonym substitution or prompt obfuscation, MacPrompt constructs macaronic adversarial prompts by performing cross-lingual character-level recombination of harmful terms, enabling fine-grained control over both semantics and appearance. By leveraging this design, MacPrompt crafts prompts with high semantic similarity to the original harmful inputs (up to 0.96) while bypassing major safety filters (up to 100%). More critically, it achieves attack success rates as high as 92% for sex-related content and 90% for violence, effectively breaking even state-of-the-art concept removal defenses. These results underscore the pressing need to reassess the robustness of existing T2I safety mechanisms against linguistically diverse and fine-grained adversarial strategies.

</details>


### [57] [When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent](https://arxiv.org/abs/2601.07263)
*Xinyi Wu,Geng Hong,Yueyue Chen,MingXuan Liu,Feier Jin,Xudong Pan,Jiarun Dai,Baojun Liu*

Main category: cs.CR

TL;DR: 본 연구는 웹 자동화 에이전트에 대한 사회 공학 공격의 체계적인 연구를 제시하고, 이를 완화하는 플러그형 런타임 솔루션을 설계함으로써 웹 에이전트의 보안을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 웹 자동화 에이전트의 사회 공학 공격에 대한 이해 부족을 해결하고, LLM 기반의 웹 에이전트의 보안 취약성을 탐구하기 위해 시작되었다.

Method: AgentBait 패러다임을 도입하고, SUPERVISOR라는 경량 런타임 모듈을 제안하여 웹 페이지 контекст와 목표 간의 일관성을 강화함으로써 공격을 완화한다.

Result: 주류 프레임워크에 대해 평균 67.5%의 공격 성공률과 특정 전략 하에서 80% 이상의 성공률을 보여주며, SUPERVISOR 모듈이 평균 공격 성공률을 78.1%까지 낮추는 것을 입증하였다.

Conclusion: AgentBait는 웹 에이전트에 대한 중요한 새로운 위협 표면을 드러내며, 보안 생태계를 향상시키기 위한 실용적이고 일반화 가능한 방어 수단을 확립하였다.

Abstract: Web agents, powered by large language models (LLMs), are increasingly deployed to automate complex web interactions. The rise of open-source frameworks (e.g., Browser Use, Skyvern-AI) has accelerated adoption, but also broadened the attack surface. While prior research has focused on model threats such as prompt injection and backdoors, the risks of social engineering remain largely unexplored. We present the first systematic study of social engineering attacks against web automation agents and design a pluggable runtime mitigation solution. On the attack side, we introduce the AgentBait paradigm, which exploits intrinsic weaknesses in agent execution: inducement contexts can distort the agent's reasoning and steer it toward malicious objectives misaligned with the intended task. On the defense side, we propose SUPERVISOR, a lightweight runtime module that enforces environment and intention consistency alignment between webpage context and intended goals to mitigate unsafe operations before execution.
  Empirical results show that mainstream frameworks are highly vulnerable to AgentBait, with an average attack success rate of 67.5% and peaks above 80% under specific strategies (e.g., trusted identity forgery). Compared with existing lightweight defenses, our module can be seamlessly integrated across different web automation frameworks and reduces attack success rates by up to 78.1% on average while incurring only a 7.7% runtime overhead and preserving usability. This work reveals AgentBait as a critical new threat surface for web agents and establishes a practical, generalizable defense, advancing the security of this rapidly emerging ecosystem. We reported the details of this attack to the framework developers and received acknowledgment before submission.

</details>


### [58] [MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP](https://arxiv.org/abs/2601.07395)
*Ruiqi Li,Zhiqiang Wang,Yunhao Yao,Xiang-Yang Li*

Main category: cs.CR

TL;DR: MCP-ITP는 LLM 기반 에이전트와 환경 간의 상호작용을 표준화하기 위해 제안된 Model Context Protocol(MCP)의 암시적인 도구 오염을 자동화하는 첫 번째 프레임워크이다. 이 프레임워크는 블랙박스 최적화 문제로 도구 생성 과정을 공식화하고, 평가 LLM과 탐지 LLM의 피드백을 활용하여 공격 성공률을 극대화하면서 탐지를 피하는 반복 최적화 전략을 사용한다.


<details>
  <summary>Details</summary>
Motivation: 이 논문의 동기는 LLM 기반 에이전트와 외부 도구 간의 상호작용이 표준화된 환경에서 발생하는 도구 오염 공격의 위험성을 해결하기 위함이다.

Method: 이 논문에서는 MCP 생태계 내에서 암시적인 도구 오염을 위한 최초의 자동화되고 적응 가능한 프레임워크인 MCP-ITP를 제안한다. MCP-ITP는 poisoned tool 생성을 블랙박스 최적화 문제로 공식화하고, 평가 LLM과 탐지 LLM의 피드백을 활용하는 반복 최적화 전략을 적용한다.

Result: MCPTox 데이터셋을 기반으로 한 실험 결과에 따르면, MCP-ITP는 수작업으로 제작된 기준 모델에 비해 일관되게 우수한 성능을 나타내며, 최대 84.2%의 공격 성공률을 달성하고, 악성 도구 탐지율을 0.3%로 억제한다.

Conclusion: 결론적으로, MCP-ITP는 LLM 기반 에이전트에 대한 암시적인 도구 오염 공격을 효과적으로 수행할 수 있는 자동화된 방법을 제공하며, 기존 탐지 메커니즘을 피할 수 있는 가능성을 보여준다.

Abstract: To standardize interactions between LLM-based agents and their environments, the Model Context Protocol (MCP) was proposed and has since been widely adopted. However, integrating external tools expands the attack surface, exposing agents to tool poisoning attacks. In such attacks, malicious instructions embedded in tool metadata are injected into the agent context during MCP registration phase, thereby manipulating agent behavior. Prior work primarily focuses on explicit tool poisoning or relied on manually crafted poisoned tools. In contrast, we focus on a particularly stealthy variant: implicit tool poisoning, where the poisoned tool itself remains uninvoked. Instead, the instructions embedded in the tool metadata induce the agent to invoke a legitimate but high-privilege tool to perform malicious operations. We propose MCP-ITP, the first automated and adaptive framework for implicit tool poisoning within the MCP ecosystem. MCP-ITP formulates poisoned tool generation as a black-box optimization problem and employs an iterative optimization strategy that leverages feedback from both an evaluation LLM and a detection LLM to maximize Attack Success Rate (ASR) while evading current detection mechanisms. Experimental results on the MCPTox dataset across 12 LLM agents demonstrate that MCP-ITP consistently outperforms the manually crafted baseline, achieving up to 84.2% ASR while suppressing the Malicious Tool Detection Rate (MDR) to as low as 0.3%.

</details>


### [59] [Peacock: UEFI Firmware Runtime Observability Layer for Detection and Response](https://arxiv.org/abs/2601.07402)
*Hadar Cochavi Gorelik,Orel Fadlon,Denis Klimov,Oleg Brodt,Asaf Shabtai,Yuval Elovici*

Main category: cs.CR

TL;DR: Peacock는 UEFI 부팅 과정에 대한 무결성 보장 모니터링과 원격 검증을 위한 모듈형 프레임워크로, 여러 실세계 UEFI 부팅킷을 신뢰성 있게 탐지한다.


<details>
  <summary>Details</summary>
Motivation: 현대 컴퓨팅 플랫폼은 하드웨어 초기화와 운영 체제로의 전환 조정을 위해 UEFI에 의존하고 있으며, 고권한으로 운영되어 재부팅 간 지속되어 고급 위협의 표적이 되고 있다.

Method: Peacock는 UEFI 기반 에이전트, 크로스 플랫폼 OS 에이전트, Peacock 서버의 세 가지 구성 요소로 이루어져 있으며, 무결성 보호를 위해 암호화된 부팅 및 런타임 서비스 활동을 기록하고, 기록된 측정을 추출하여 검증 가능한 증명 번들을 생성하며, 증명 결과를 검증하고 구조화된 텔레메트리를 내보낸다.

Result: Peacock는 Glupteba, BlackLotus, LoJax, MosaicRegressor를 포함한 여러 실세계 UEFI 부팅킷을 신뢰성 있게 탐지한다.

Conclusion: Peacock는 전통적인 OS 수준 보안 메커니즘을 우회하는 위협을 해결하며, 펌웨어 계층 내에서 실용적인 가시성과 검증 기능을 제공한다.

Abstract: Modern computing platforms rely on the Unified Extensible Firmware Interface (UEFI) to initialize hardware and coordinate the transition to the operating system. Because this execution environment operates with high privileges and persists across reboots, it has increasingly become a target for advanced threats, including bootkits documented in real systems. Existing protections, including Secure Boot and static signature verification, are insufficient against adversaries who exploit runtime behavior or manipulate firmware components after signature checks have completed. In contrast to operating system (OS) environments, where mature tools provide dynamic inspection and incident response, the pre-OS stage lacks practical mechanisms for real-time visibility and threat detection. We present Peacock, a modular framework that introduces integrity-assured monitoring and remote verification for the UEFI boot process. Peacock consists of three components: (i) a UEFI-based agent that records Boot and Runtime Service activity with cryptographic protection against tampering; (ii) a cross-platform OS Agent that extracts the recorded measurements and produces a verifiable attestation bundle using hardware-backed guarantees from the platform's trusted module; and (iii) a Peacock Server that verifies attestation results and exports structured telemetry for enterprise detection. Our evaluation shows that Peacock reliably detects multiple real-world UEFI bootkits, including Glupteba, BlackLotus, LoJax, and MosaicRegressor. Taken together, these results indicate that Peacock provides practical visibility and verification capabilities within the firmware layer, addressing threats that bypass traditional OS-level security mechanisms.

</details>


### [60] [TeeMAF: A TEE-Based Mutual Attestation Framework for On-Chain and Off-Chain Functions in Blockchain DApps](https://arxiv.org/abs/2601.07726)
*Xiangyu Liu,Brian Lee,Yuansong Qiao*

Main category: cs.CR

TL;DR: 이 논문은 분산 시스템에서 온-체인 및 오프-체인 기능 간의 상호 인증을 위한 TeeMAF라는 프레임워크를 소개하며, 이를 통해 데이터 보안 및 사용자 프라이버시를 개선한다.


<details>
  <summary>Details</summary>
Motivation: IoT 기술의 발전으로 분산 시스템 내 데이터 보안과 사용자 프라이버시에 대한 우려가 증가하고 있다.

Method: TeeMAF는 Trusted Execution Environments(TEE), 특히 Intel Software Guard Extensions(SGX) 및 SCONE과 원격 인증 기술을 활용하여 온-체인과 오프-체인 기능 간의 상호 인증을 제공하는 프레임워크이다.

Result: TeeMAF의 보안 분석을 통해 배포된 DApp의 신뢰성을 검증하고, 이 프레임워크를 바탕으로 신뢰할 수 없는 환경에서 애플리케이션을 배포하는 분산 리소스 오케스트레이션 플랫폼을 제안한다.

Conclusion: 성능 평가를 통해 상호 인증 메커니즘이 없는 플랫폼에 비해 성능 저하가 허용 가능한 범위 내에 있음을 입증하였다.

Abstract: The rapid development of Internet of Things (IoT) technology has led to growing concerns about data security and user privacy in the interactions within distributed systems. Decentralized Applications (DApps) in distributed systems consist of on-chain and off-chain functions, where on-chain functions are smart contracts running in the blockchain network, while off-chain functions operate outside the blockchain. Since smart contracts cannot access off-chain information, they cannot verify whether the off-chain functions, i.e. the software components, they interact with have been tampered or not. As a result, establishing mutual trust between the on-chain smart contracts and the off-chain functions remains a significant challenge. To address the challenge, this paper introduces TeeMAF, a generic framework for mutual attestation between on-chain and off-chain functions, leveraging Trusted Execution Environments (TEE), specifically Intel Software Guard Extensions (SGX), SCONE (a TEE container on top of Intel SGX), and remote attestation technologies. This ensures that the deployed off-chain functions of a DApp execute in a provably secure computing environment and achieve mutual attestation with the interacting on-chain functions. Through a security analysis of TeeMAF, the reliability of deployed DApps can be verified, ensuring their correct execution. Furthermore, based on this framework, this paper proposes a decentralized resource orchestration platform (a specific DApp) for deploying applications over untrusted environments. The system is implemented on Ethereum and benchmarked using Hyperledger Caliper. Performance evaluation focusing on throughput and latency demonstrates that, compared to platforms without a mutual attestation scheme, the performance overhead remains within an acceptable range.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [61] [DemMA: Dementia Multi-Turn Dialogue Agent with Expert-Guided Reasoning and Action Simulation](https://arxiv.org/abs/2601.06373)
*Yutong Song,Jiang Wu,Kazi Sharif,Honghui Xu,Nikil Dutt,Amir Rahmani*

Main category: cs.MA

TL;DR: DemMA는 전문가의 안내를 통해 제작된 고충실도의 다중 턴 치매 환자 시뮬레이션 에이전트로, 인지 장애와 정서 다이내믹, 비언어적 행동을 모델링한다.


<details>
  <summary>Details</summary>
Motivation: 치매 환자를 모델링하는 데 필요한 다양한 요소들을 정확하게 시뮬레이션하기 위해.

Method: DemMA는 병리학 정보, 성격 특성 및 임상 전문가의 정보를 바탕으로 한 특정 기억 상태 페르소나를 통합하여 치매 페르소나를 구축하며, 비언어적 행동도 모델링한다. 또한, Chain-of-Thought 증류 프레임워크를 도입하여 하나의 LLM이 추론 흔적, 환자의 발화, 행동을 동시에 생성할 수 있도록 훈련한다.

Result: DemMA는 전문가, 의대생, LLM 평가자와의 광범위한 평가에서 여러 메트릭에서 강력한 기준선을 크게 초과하는 성과를 보여준다.

Conclusion: DemMA는 비텍스트 시뮬레이션으로 나아가는 데 필요한 기능을 봇에 통합하여 치매 환자의 정교한 시뮬레이션을 가능하게 한다.

Abstract: Simulating dementia patients with large language models (LLMs) is challenging due to the need to jointly model cognitive impairment, emotional dynamics, and nonverbal behaviors over long conversations. We present DemMA, an expert-guided dementia dialogue agent for high-fidelity multi-turn patient simulation. DemMA constructs clinically grounded dementia personas by integrating pathology information, personality traits, and subtype-specific memory-status personas informed by clinical experts. To move beyond text-only simulation, DemMA explicitly models nonverbal behaviors, including motion, facial expressions, and vocal cues. We further introduce a Chain-of-Thought distillation framework that trains a single LLM to jointly generate reasoning traces, patient utterances, and aligned behavioral actions within one forward pass, enabling efficient deployment without multi-agent inference. Extensive evaluations with experts, medical students, and LLM judges demonstrate that DemMA significantly outperforms strong baselines across multiple metrics.

</details>


### [62] [Dynamic Incentivized Cooperation under Changing Rewards](https://arxiv.org/abs/2601.06382)
*Philipp Altmann,Thomy Phan,Maximilian Zorn,Claudia Linnhoff-Popien,Sven Koenig*

Main category: cs.MA

TL;DR: 본 논문은 변화하는 보상 환경에서 협력을 유지하기 위한 적응형 동적 보상 인센티브 기법인 DRIVE를 제안한다.


<details>
  <summary>Details</summary>
Motivation: PI(피어 인센티비제이션)는 사회적 딜레마에서 협력을 달성하기 위해 에이전트들이 서로 보상하거나 처벌하는 다중 에이전트 강화 학습 접근 방식이다. 하지만 기존의 PI 방법은 고정된 인센티브 값에 의존하여 환경 보상의 변화에 매우 민감하다.

Method: DRIVE 에이전트는 보상 차이를 상호 교환하여 완전한 분산 방식으로 상호 협력을 유도한다.

Result: DRIVE는 일반적인 죄수의 딜레마에서 상호 협력을 달성하고, 변화하는 보상이 있는 보다 복잡한 순차적 사회적 딜레마에서 DRIVE를 경험적으로 평가하였다.

Conclusion: DRIVE는 현재의 최첨단 PI 방법과 비교할 때 협력 달성 및 유지 능력을 보여준다.

Abstract: Peer incentivization (PI) is a popular multi-agent reinforcement learning approach where all agents can reward or penalize each other to achieve cooperation in social dilemmas. Despite their potential for scalable cooperation, current PI methods heavily depend on fixed incentive values that need to be appropriately chosen with respect to the environmental rewards and thus are highly sensitive to their changes. Therefore, they fail to maintain cooperation under changing rewards in the environment, e.g., caused by modified specifications, varying supply and demand, or sensory flaws - even when the conditions for mutual cooperation remain the same. In this paper, we propose Dynamic Reward Incentives for Variable Exchange (DRIVE), an adaptive PI approach to cooperation in social dilemmas with changing rewards. DRIVE agents reciprocally exchange reward differences to incentivize mutual cooperation in a completely decentralized way. We show how DRIVE achieves mutual cooperation in the general Prisoner's Dilemma and empirically evaluate DRIVE in more complex sequential social dilemmas with changing rewards, demonstrating its ability to achieve and maintain cooperation, in contrast to current state-of-the-art PI methods.

</details>


### [63] [Bi-Mem: Bidirectional Construction of Hierarchical Memory for Personalized LLMs via Inductive-Reflective Agents](https://arxiv.org/abs/2601.06490)
*Wenyu Mao,Haosong Tan,Shuchang Liu,Haoyang Liu,Yifan Xu,Huaxiang Ji,Xiang Wang*

Main category: cs.MA

TL;DR: Bi-Mem은 사용자와의 대화를 통해 생성된 계층적 메모리를 관리하여 LLM의 맥락적 한계를 극복하고 개인화된 상호작용을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 맥락적 한계를 극복하고 사용자 맞춤형 상호작용을 가능하게 하기 위해, 사용자의 장기 대화를 통해 메모리를 구축하는 것이 필요하다.

Method: Bi-Mem 프레임워크는 양방향으로 메모리를 구성하여 계층적 메모리의 정확성을 보장한다. 이 과정에서 inductive agent가 대화에서 사실 정보를 추출하고, 이를 주제별 장면으로 집계한 후, 사용자의 프로필을 추론한다.

Result: Bi-Mem은 장기 개인화 대화 작업에서 질문 응답 성능에서 유의미한 개선을 보여준다.

Conclusion: Bi-Mem은 지역 및 전역 정렬을 강화함으로써 사용자와의 보다 일관된 대화를 가능하게 하며, 메모리 회상을 더욱 명확하게 한다.

Abstract: Constructing memory from users' long-term conversations overcomes LLMs' contextual limitations and enables personalized interactions. Recent studies focus on hierarchical memory to model users' multi-granular behavioral patterns via clustering and aggregating historical conversations. However, conversational noise and memory hallucinations can be amplified during clustering, causing locally aggregated memories to misalign with the user's global persona. To mitigate this issue, we propose Bi-Mem, an agentic framework ensuring hierarchical memory fidelity through bidirectional construction. Specifically, we deploy an inductive agent to form the hierarchical memory: it extracts factual information from raw conversations to form fact-level memory, aggregates them into thematic scenes (i.e., local scene-level memory) using graph clustering, and infers users' profiles as global persona-level memory. Simultaneously, a reflective agent is designed to calibrate local scene-level memories using global constraints derived from the persona-level memory, thereby enforcing global-local alignment. For coherent memory recall, we propose an associative retrieval mechanism: beyond initial hierarchical search, a spreading activation process allows facts to evoke contextual scenes, while scene-level matches retrieve salient supporting factual information. Empirical evaluations demonstrate that Bi-Mem achieves significant improvements in question answering performance on long-term personalized conversational tasks.

</details>


### [64] [The Axiom of Consent: Friction Dynamics in Multi-Agent Coordination](https://arxiv.org/abs/2601.06692)
*Murad Farzulla*

Main category: cs.MA

TL;DR: 다중 에이전트 시스템은 동질적이지 않은 선호, 비대칭 이익, 불완전한 정보에도 불구하고 조정 문제에 직면해 있다. 이 논문은 하나의 공리에서 조정 마찰을 분석하기 위한 공식 프레임워크를 도출한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 마찰을 이해하고 예측하는 체계를 마련하여 조정 실패의 원인을 규명하고 해결 방안을 제시하기 위해.

Method: 한 가지 공리(행동이 에이전트에 영향을 미칠 때는 그 에이전트의 이익에 비례하여 허가를 필요로 한다)를 바탕으로, 자원 할당 구성을 특성화하는 커널 삼중 $(α, σ, ε)$를 확립한 후, 마찰 방정식 $F = σ (1 + ε)/(1 + α)$를 도출했다.

Result: 조율 난이도는 선호 정렬($α$), 이익의 크기($σ$), 통신 엔트로피($ε$)의 함수로 제시된다. 반복 최적화 메커니즘(ROM)은 조정 전략에 대한 진화적 선택을 조정하고, 낮은 마찰을 생성하는 구성이 더 오래 지속됨을 발견했다.

Conclusion: 이 프레임워크는 자원 동의, 조정 정당성 및 마찰 인식 할당에 대한 공식 정의를 제공하며, 다중 에이전트 시스템의 조정 문제를 해결하는 데 적용 가능하다.

Abstract: Multi-agent systems face a fundamental coordination problem: agents must coordinate despite heterogeneous preferences, asymmetric stakes, and imperfect information. When coordination fails, friction emerges: measurable resistance manifesting as deadlock, thrashing, communication overhead, or outright conflict. This paper derives a formal framework for analyzing coordination friction from a single axiom: actions affecting agents require authorization from those agents in proportion to stakes.
  From this axiom of consent, we establish the kernel triple $(α, σ, ε)$ (alignment, stake, and entropy) characterizing any resource allocation configuration. The friction equation $F = σ (1 + ε)/(1 + α)$ predicts coordination difficulty as a function of preference alignment $α$, stake magnitude $σ$, and communication entropy $ε$. The Replicator-Optimization Mechanism (ROM) governs evolutionary selection over coordination strategies: configurations generating less friction persist longer, establishing consent-respecting arrangements as dynamical attractors rather than normative ideals.
  We develop formal definitions for resource consent, coordination legitimacy, and friction-aware allocation in multi-agent systems. The framework yields testable predictions: MARL systems with higher reward alignment exhibit faster convergence; distributed allocations accounting for stake asymmetry generate lower coordination failure; AI systems with interpretability deficits produce friction proportional to the human-AI alignment gap. Applications to cryptocurrency governance and political systems demonstrate that the same equations govern friction dynamics across domains, providing a complexity science perspective on coordination under preference heterogeneity.

</details>


### [65] [Logic-Driven Semantic Communication for Resilient Multi-Agent Systems](https://arxiv.org/abs/2601.06733)
*Tamara Alshammari,Mehdi Bennis*

Main category: cs.MA

TL;DR: 이 논문은 6G 네트워크에서의 분산 다중 에이전트 시스템의 회복력을 형식적으로 정의하고, 이를 통해 지식 기반 의사결정을 수행하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존 문헌은 분산 다중 에이전트 시스템의 회복력에 대한 통합된 정의를 제공하지 않으며, 시스템 설계를 제한한다.

Method: 에이전트 회복력은 두 가지 보완적 차원에서 정의되며, 에이전트가 환경에 대한 정확한 지식을 회복하고 유지하는 인식 회복력과 그 지식을 활용하여 목표를 지속하는 행동 회복력으로 나뉜다.

Result: 제안된 접근 방식은 기본 방법보다 우수한 성능을 보이며, 공식 검증 분석 및 시뮬레이션 결과가 이를 뒷받침한다.

Conclusion: 제안된 프레임워크는 지식 기반 의사결정과 지속적인 운영을 가능하게 하여 차세대 통신 시스템에서의 분산 다중 에이전트 시스템을 위한 기초를 마련한다.

Abstract: The advent of 6G networks is accelerating autonomy and intelligence in large-scale, decentralized multi-agent systems (MAS). While this evolution enables adaptive behavior, it also heightens vulnerability to stressors such as environmental changes and adversarial behavior. Existing literature on resilience in decentralized MAS largely focuses on isolated aspects, such as fault tolerance, without offering a principled unified definition of multi-agent resilience. This gap limits the ability to design systems that can continuously sense, adapt, and recover under dynamic conditions. This article proposes a formal definition of MAS resilience grounded in two complementary dimensions: epistemic resilience, wherein agents recover and sustain accurate knowledge of the environment, and action resilience, wherein agents leverage that knowledge to coordinate and sustain goals under disruptions. We formalize resilience via temporal epistemic logic and quantify it using recoverability time (how quickly desired properties are re-established after a disturbance) and durability time (how long accurate beliefs and goal-directed behavior are sustained after recovery). We design an agent architecture and develop decentralized algorithms to achieve both epistemic and action resilience. We provide formal verification guarantees, showing that our specifications are sound with respect to the metric bounds and admit finite-horizon verification, enabling design-time certification and lightweight runtime monitoring. Through a case study on distributed multi-agent decision-making under stressors, we show that our approach outperforms baseline methods. Our formal verification analysis and simulation results highlight that the proposed framework enables resilient, knowledge-driven decision-making and sustained operation, laying the groundwork for resilient decentralized MAS in next-generation communication systems.

</details>


### [66] [Agents of Diffusion: Enhancing Diffusion Language Models with Multi-Agent Reinforcement Learning for Structured Data Generation (Extended Version)](https://arxiv.org/abs/2601.07152)
*Aja Khanal,Kaushik T. Ranade,Rishabh Agrawal,Kalyan S. Basu,Apurva Narayan*

Main category: cs.MA

TL;DR: 이 논문은 고품질 구조화 데이터 생성을 위한 새로운 프레임워크인 Agents of Diffusion (AoD)를 제안하며, 이는 확산 언어 모델(DLM)과 자기 회귀 모델의 장점을 결합한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델에서 JSON과 같은 고품질 구조화된 데이터를 생성하는 것은 의미의 풍부함과 엄격한 스키마 준수가 동시에 필요할 때 근본적인 도전 과제가 된다.

Method: AoD는 프롬프트 최적화 에이전트와 판별 에이전트가 자연어 피드백을 사용하여 DLM을 유도하는 다중 에이전트 정렬 프로세스로 구조화된 텍스트 생성을 프레임화한다.

Result: AoD는 협력 에이전트에 의해 감독될 때 고Semantic novelty와 구조적 충실성을 모두 달성할 수 있음을 보여준다.

Conclusion: AoD는 여러 구조화된 데이터 벤치마크에서 확산 및 자기 회귀 기준점을 일관되게 초과하며, 구조 인식 및 다양성 향상 텍스트 합성을 위한 새로운 방향을 설정한다.

Abstract: Generating high-quality structured data such as JSON records, remains a fundamental challenge for large language models (LLMs), particularly when semantic richness must coexist with strict schema adherence. While autoregressive LLMs offer strong structural consistency, they often struggle with semantic variation and output diversity. In contrast, diffusion language models (DLMs) introduce powerful mechanisms for semantic richness and bidirectional decoding, yet lack the inductive biases needed for reliable structure preservation. We present Agents of Diffusion (AoD), a novel framework that unifies the generative flexibility of DLMs with the reasoning capabilities of autoregressive models through language-mediated reinforcement learning. AoD frames structured text generation as a multi-agent alignment process, where a prompt optimization agent collaborates with a judge agent to iteratively guide a DLM using natural language feedback. This approach enables controllable, schema-consistent generation without modifying model parameters or relying on handcrafted constraints. AoD advances the state of controllable generation by demonstrating that diffusion models, when supervised by cooperative agents, can achieve both high semantic novelty and structural fidelity. Across multiple structured data benchmarks, AoD consistently outperforms diffusion and autoregressive baselines, establishing a new path forward for structure-aware, diversity-enhanced text synthesis.

</details>


### [67] [DarwinTOD: LLM Driven Lifelong Self Evolution for Task Oriented Dialog Systems](https://arxiv.org/abs/2601.07248)
*Shuyu Zhang,Yujie Liu,Xinru Wang,Cheng Zhang,Yanmin Zhu,Bin Li*

Main category: cs.MA

TL;DR: DarwinTOD는 지속적인 자가 진화를 가능하게 하는 대화 프레임워크로, 효율적인 전략 최적화를 통해 인간 개입 없이 자율적으로 성능을 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 태스크 지향 대화 시스템은 배포 후 상호작용에서 발전하거나 새로운 도메인에 적응할 수 없는 한계를 가지고 있다.

Method: DarwinTOD는 진화 계산과 LLM 기반 자기 개선 방식을 통합하여 지속적인 전략 최적화를 위한 체계적인 프레임워크를 제공합니다.

Result: DarwinTOD는 이전의 최첨단 방법들을 초월하며, 진화 과정 내내 지속적인 성능 향상을 보여줍니다.

Conclusion: 우리의 연구는 자가 진화 가능한 대화 시스템을 구축하기 위한 새로운 프레임워크를 제공합니다.

Abstract: Traditional task-oriented dialog systems are unable to evolve from ongoing interactions or adapt to new domains after deployment, that is a critical limitation in real-world dynamic environments. Continual learning approaches depend on episodic retraining with human curated data, failing to achieve autonomy lifelong improvement. While evolutionary computation and LLM driven self improvement offer promising mechanisms for dialog optimization, they lack a unified framework for holistic, iterative strategy refinement. To bridge this gap, we propose DarwinTOD, a lifelong self evolving dialog framework that systematically integrates these two paradigms, enabling continuous strategy optimization from a zero-shot base without task specific fine-tuning. DarwinTOD maintains an Evolvable Strategy Bank and operates through a dual-loop process: online multi-agent dialog execution with peer critique, and offline structured evolutionary operations that refine the strategy bank using accumulated feedback. This closed-loop design enables autonomous continuous improvement without human intervention. Extensive experiments show that DarwinTOD surpasses previous state-of-the-art methods and exhibits continuous performance gains throughout evolution. Our work provides a novel framework for building dialog systems with lifelong self evolution capabilities.

</details>


### [68] [SwarmFoam: An OpenFOAM Multi-Agent System Based on Multiple Types of Large Language Models](https://arxiv.org/abs/2601.07252)
*Chunwei Yang,Yankai Wang,Jianxiang Tang,Haojie Qu,Ziqiang Zou,YuLiu,Chunrui Deng,Zhifang Qiu,Ming Ding*

Main category: cs.MA

TL;DR: 본 논문은 SwarmFoam이라는 새로운 다중 에이전트 시뮬레이션 프레임워크를 소개하며, 이는 복잡한 기하학적 구조를 처리하는 데 적합하다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 기하학을 다루는 데 있어 기존의 다중 에이전트 시스템의 한계를 극복하고자 함.

Method: SwarmFoam은 다중 모드 인식, 지능형 오류 수정 및 검색 증강 생성과 같은 기능을 통합하여 이미지와 고급 지침을 이중 파싱하는 방식으로 복잡한 시뮬레이션을 달성한다.

Result: 25개 테스트 사례에서의 전체 통과율은 84%이며, 자연어와 다중 모드 입력 사례의 통과율은 각각 80% 및 86.7%에 달한다.

Conclusion: SwarmFoam은 CFD를 위한 지능형 에이전트 방법의 발전을 촉진할 것으로 기대된다.

Abstract: Numerical simulation is one of the mainstream methods in scientific research, typically performed by professional engineers. With the advancement of multi-agent technology, using collaborating agents to replicate human behavior shows immense potential for intelligent Computational Fluid Dynamics (CFD) simulations. Some muti-agent systems based on Large Language Models have been proposed. However, they exhibit significant limitations when dealing with complex geometries. This paper introduces a new multi-agent simulation framework, SwarmFoam. SwarmFoam integrates functionalities such as Multi-modal perception, Intelligent error correction, and Retrieval-Augmented Generation, aiming to achieve more complex simulations through dual parsing of images and high-level instructions. Experimental results demonstrate that SwarmFoam has good adaptability to simulation inputs from different modalities. The overall pass rate for 25 test cases was 84%, with natural language and multi-modal input cases achieving pass rates of 80% and 86.7%, respectively. The work presented by SwarmFoam will further promote the development of intelligent agent methods for CFD.

</details>


### [69] [VLM-CAD: VLM-Optimized Collaborative Agent Design Workflow for Analog Circuit Sizing](https://arxiv.org/abs/2601.07315)
*Guanyuan Pan,Yugui Lin,Tiansheng Zhou,Pietro Liò,Shuai Wang,Yaqi Wang*

Main category: cs.MA

TL;DR: VLM-CAD는 아날로그 혼합 신호 회로 크기 조정을 위한 새로운 방법으로, 회로 분석, DC 작동 점 최적화, 크기 조정 및 외부 최적화를 수행한다.


<details>
  <summary>Details</summary>
Motivation: 기존 아날로그 회로 크기 조정 방법이 회로 도식의 활용을 충분히 하지 못하고 산업 채택을 위한 설명 가능성이 부족하다.

Method: 회로를 분석하고 DC 작동 점을 최적화하며 추론 기반 크기 조정 및 외부 최적화를 수행하는 VLM-CAD를 제안한다. 또한, ExTuRBO라는 설명 가능한 최적화 방법을 통해 협력적 워밍업과 민감도 분석을 지원한다.

Result: VLM-CAD는 증폭기 크기 조정 작업에서 100% 성공률을 달성하며, 모든 실험에서 총 실행 시간을 43분 이상 유지했다.

Conclusion: VLM-CAD는 아날로그 회로의 전력과 성능 간의 균형을 효과적으로 맞추고, 최종 설계 보고서를 포괄적으로 지원한다.

Abstract: Analog mixed-signal circuit sizing involves complex trade-offs within high-dimensional design spaces. Existing automatic analog circuit sizing approaches often underutilize circuit schematics and lack the explainability required for industry adoption. To tackle these challenges, we propose a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD), which analyzes circuits, optimizes DC operating points, performs inference-based sizing and executes external sizing optimization. We integrate Image2Net to annotate circuit schematics and generate a structured JSON description for precise interpretation by Vision Language Models. Furthermore, we propose an Explainable Trust Region Bayesian Optimization method (ExTuRBO) that employs collaborative warm-starting from agent-generated seeds and offers dual-granularity sensitivity analysis for external sizing optimization, supporting a comprehensive final design report. Experiment results on amplifier sizing tasks using 180nm, 90nm, and 45nm Predictive Technology Models demonstrate that VLM-CAD effectively balances power and performance, achieving a 100% success rate in optimizing an amplifier with a complementary input and a class-AB output stage, while maintaining total runtime under 43 minutes across all experiments.

</details>


### [70] [OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent](https://arxiv.org/abs/2601.07779)
*Bowen Yang,Kaiming Jin,Zhenyu Wu,Zhaoyang Liu,Qiushi Sun,Zehao Li,JingJing Xie,Zhoumianze Liu,Fangzhi Xu,Kanzhi Cheng,Qingyun Li,Yian Wang,Yu Qiao,Zun Wang,Zichen Ding*

Main category: cs.MA

TL;DR: OS-Symphony는 비전-언어 모델의 한계를 극복하기 위해 개발된 포괄적 프레임워크로, 장기 작업에서의 시각적 맥락 손실을 완화하고 새로운 도메인에서의 일반화를 개선한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 비전-언어 모델은 장기 작업에서의 강인성과 새로운 도메인에서의 일반화에서 한계를 보이고 있다.

Method: OS-Symphony는 두 가지 주요 혁신을 조정하는 오케스트레이터를 포함한 포괄적 프레임워크로, 반사 메모리 에이전트와 다목적 도구 에이전트를 활용한다.

Result: OS-Symphony는 다양한 모델 규모에서 성능 향상을 보여주며, 세 가지 온라인 벤치마크에서 새로운 최첨단 결과를 수립하였다.

Conclusion: 특히 OSWorld에서 65.84%의 성과를 달성하였다.

Abstract: While Vision-Language Models (VLMs) have significantly advanced Computer-Using Agents (CUAs), current frameworks struggle with robustness in long-horizon workflows and generalization in novel domains. These limitations stem from a lack of granular control over historical visual context curation and the absence of visual-aware tutorial retrieval. To bridge these gaps, we introduce OS-Symphony, a holistic framework that comprises an Orchestrator coordinating two key innovations for robust automation: (1) a Reflection-Memory Agent that utilizes milestone-driven long-term memory to enable trajectory-level self-correction, effectively mitigating visual context loss in long-horizon tasks; (2) Versatile Tool Agents featuring a Multimodal Searcher that adopts a SeeAct paradigm to navigate a browser-based sandbox to synthesize live, visually aligned tutorials, thereby resolving fidelity issues in unseen scenarios. Experimental results demonstrate that OS-Symphony delivers substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks, notably achieving 65.84% on OSWorld.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [71] [Tree-Preconditioned Differentiable Optimization and Axioms as Layers](https://arxiv.org/abs/2601.06036)
*Yuexin Liao*

Main category: cs.LG

TL;DR: 이 논문은 랜덤 유틸리티 모델의 공리적 구조를 딥 뉴럴 네트워크에 직접 임베드하는 미분 가능 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 랜덤 유틸리티 모델을 활용하여 데이터로부터 학습하는 과정에서 발생하는 구조적 과적합 문제를 해결하고자 합니다.

Method: 불리언 격자에서의 흐름 보존과 RUM 일관성 간의 동형성을 이용하여 새로운 Tree-Preconditioned Conjugate Gradient 솔버를 개발하였습니다. 이 솔버는 제약 그래프의 스패닝 트리를 활용하여 Interior Point Method 장벽에서 발생하는 더러운 해시안 스펙트럼을 효과적으로 '화이트닝'합니다.

Result: 본 연구는 새로운 접근 방식으로 문제 크기에 구애받지 않는 초선형 수렴을 달성하고, 기존에 풀 수 없었던 문제들을 해결할 수 있게 됩니다.

Conclusion: 이 '공리-계층' 패러다임은 처벌 기반 방법에서 내재된 구조적 과적합을 제거하고, 공동 학습이 가능하며, 합리성을 증명하고, 표준 근사법이 실패하는 희소 데이터 환경에서 일반화할 수 있는 모델을 가능하게 합니다.

Abstract: This paper introduces a differentiable framework that embeds the axiomatic structure of Random Utility Models (RUM) directly into deep neural networks. Although projecting empirical choice data onto the RUM polytope is NP-hard in general, we uncover an isomorphism between RUM consistency and flow conservation on the Boolean lattice. Leveraging this combinatorial structure, we derive a novel Tree-Preconditioned Conjugate Gradient solver. By exploiting the spanning tree of the constraint graph, our preconditioner effectively "whitens" the ill-conditioned Hessian spectrum induced by the Interior Point Method barrier, achieving superlinear convergence and scaling to problem sizes previously deemed unsolvable. We further formulate the projection as a differentiable layer via the Implicit Function Theorem, where the exact Jacobian propagates geometric constraints during backpropagation. Empirical results demonstrate that this "Axioms-as-Layers" paradigm eliminates the structural overfitting inherent in penalty-based methods, enabling models that are jointly trainable, provably rational, and capable of generalizing from sparse data regimes where standard approximations fail.

</details>


### [72] [CrossTrafficLLM: A Human-Centric Framework for Interpretable Traffic Intelligence via Large Language Model](https://arxiv.org/abs/2601.06042)
*Zeming Du,Qitan Shao,Hongfei Liu,Yong Zhang*

Main category: cs.LG

TL;DR: CrossTrafficLLM은 미래의 교통 상태를 예측하고 그에 대한 자연어 설명을 생성하는 새로운 프레임워크로, 교통 예측과 설명 생성을 통합하여 더 해석 가능하고 실행 가능한 교통 정보를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 정확한 교통 예측은 지능형 교통 시스템에 필수적이지만, 예측된 조건을 자연어로 효과적으로 전달하는 것은 여전히 도전 과제입니다.

Method: CrossTrafficLLM은 대형 언어 모델을 활용하여 정량적 교통 데이터와 정성적 텍스트 의미를 통합하는 새로운 GenAI 기반 프레임워크입니다.

Result: BJTT 데이터셋에서 평가된 CrossTrafficLLM은 교통 예측 성능과 텍스트 생성 품질 모두에서 최첨단 방법을 능가합니다.

Conclusion: 예측과 설명 생성을 통합함으로써 CrossTrafficLLM은 현대 ITS 응용 프로그램에 중요한 이점을 제공합니다.

Abstract: While accurate traffic forecasting is vital for Intelligent Transportation Systems (ITS), effectively communicating predicted conditions via natural language for human-centric decision support remains a challenge and is often handled separately. To address this, we propose CrossTrafficLLM, a novel GenAI-driven framework that simultaneously predicts future spatiotemporal traffic states and generates corresponding natural language descriptions, specifically targeting conditional abnormal event summaries. We tackle the core challenge of aligning quantitative traffic data with qualitative textual semantics by leveraging Large Language Models (LLMs) within a unified architecture. This design allows generative textual context to improve prediction accuracy while ensuring generated reports are directly informed by the forecast. Technically, a text-guided adaptive graph convolutional network is employed to effectively merge high-level semantic information with the traffic network structure. Evaluated on the BJTT dataset, CrossTrafficLLM demonstrably surpasses state-of-the-art methods in both traffic forecasting performance and text generation quality. By unifying prediction and description generation, CrossTrafficLLM delivers a more interpretable, and actionable approach to generative traffic intelligence, offering significant advantages for modern ITS applications.

</details>


### [73] [RainBalance: Alleviating Dual Imbalance in GNSS-based Precipitation Nowcasting via Continuous Probability Modeling](https://arxiv.org/abs/2601.06137)
*Yifang Zhang,Shengwu Xiong,Henan Wang,Wenjie Yin,Jiawang Peng,Duan Zhou,Yuqiang Zhang,Chen Zhou,Hua Chen,Qile Zhao,Pengfei Duan*

Main category: cs.LG

TL;DR: GNSS 기반 강수 예측 시스템은 과거 데이터를 활용하여 미래의 강수량을 예측하지만, 비강수 사건의 우세와 극단적인 강수 샘플의 부족으로 인해 모델 성능이 저하된다. 이를 해결하기 위해 연속 확률 모델링 기반의 프레임워크인 RainBalance를 제안하며, 이 모듈은 클러스터링을 통해 강수 분포를 더 잘 모델링한다.


<details>
  <summary>Details</summary>
Motivation: 전 세계적인 재난 완화와 실시간 의사결정을 위해 GNSS 기반 강수 즉시 예측이 필요하다. 그러나 강수의 시간적 불균형이 모델 성능에 부정적인 영향을 미친다.

Method: 우리는 RainBalance라는 연속 확률 모델링 기반 프레임워크를 제안하며, VAE를 통해 클러스터 확률 분포를 연속 잠재 공간으로 매핑한다.

Result: 이 모듈을 여러 최신 모델에 통합하여 일관된 성능 향상을 관찰하였다.

Conclusion: 종합적인 통계 분석과 절제 연구는 우리의 접근 방식의 효과성을 추가로 검증한다.

Abstract: Global navigation satellite systems (GNSS) station-based Precipitation Nowcasting aims to predict rainfall within the next 0-6 hours by leveraging a GNSS station's historical observations of precipitation, GNSS-PWV, and related meteorological variables, which is crucial for disaster mitigation and real-time decision-making. In recent years, time-series forecasting approaches have been extensively applied to GNSS station-based precipitation nowcasting. However, the highly imbalanced temporal distribution of precipitation, marked not only by the dominance of non-rainfall events but also by the scarcity of extreme precipitation samples, significantly limits model performance in practical applications. To address the dual imbalance problem in precipitation nowcasting, we propose a continuous probability modeling-based framework, RainBalance. This plug-and-play module performs clustering for each input sample to obtain its cluster probability distribution, which is further mapped into a continuous latent space via a variational autoencoder (VAE). By learning in this continuous probabilistic space, the task is reformulated from fitting single and imbalance-prone precipitation labels to modeling continuous probabilistic label distributions, thereby alleviating the imbalance issue. We integrate this module into multiple state-of-the-art models and observe consistent performance gains. Comprehensive statistical analysis and ablation studies further validate the effectiveness of our approach.

</details>


### [74] [A Foundation Model Approach for Fetal Stress Prediction During Labor From cardiotocography (CTG) recordings](https://arxiv.org/abs/2601.06149)
*Naomi Fridman,Berta Ben Shachar*

Main category: cs.LG

TL;DR: 본 연구는 출산 중 태아 심박 모니터링을 위한 CTG 분석에 자기 지도형 사전 학습을 적용한 첫 번째 사례를 제시하며, 임상적 결과 레이블이 없는 CTG 기록 2,444시간을 사용해 성능을 향상시켰음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 출산 중 CTG 해석의 높은 관찰자 간 변동성과 제한된 예측 정확도를 해결하고자 함.

Method: 2,444시간의 비표시 기록에 대해 마스킹 사전 학습을 수행한 후 552개의 CTU-UHB 벤치마크 데이터로 세밀 조정하는 PatchTST 변환기 아키텍처를 사용함.

Result: 전체 테스트 세트에서 0.83, 합병증 없는 질식 분만에서 0.853의 수신자 운영 특성 곡선 면적을 달성하며, 이전 보고된 결과(0.68-0.75)를 초과함.

Conclusion: 자기 지도형 사전 학습이 출산 중 데이터 부족 문제를 해결할 수 있으며, 신뢰할 수 있는 의사 결정 지원으로 나아갈 수 있음을 보여줌.

Abstract: Intrapartum cardiotocography (CTG) is widely used for fetal monitoring during labor, yet its interpretation suffers from high inter-observer variability and limited predictive accuracy. Deep learning approaches have been constrained by the scarcity of CTG recordings with clinical outcome labels. We present the first application of self-supervised pre-training to intrapartum CTG analysis, leveraging 2,444 hours of unlabeled recordings for masked pre-training followed by fine-tuning on the 552-recording CTU-UHB benchmark. Using a PatchTST transformer architecture with a channel-asymmetric masking scheme designed for fetal heart rate reconstruction, we achieve an area under the receiver operating characteristic curve of 0.83 on the full test set and 0.853 on uncomplicated vaginal deliveries, exceeding previously reported results on this benchmark (0.68-0.75). Error analysis reveals that false-positive alerts typically correspond to CTG patterns judged concerning on retrospective clinical review, suggesting clinically meaningful predictions even when umbilical pH is normal. We release standardized dataset splits and model weights to enable reproducible benchmarking. Our results demonstrate that self-supervised pre-training can address data scarcity in fetal monitoring, offering a path toward reliable decision support in the labor room.

</details>


### [75] [TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC](https://arxiv.org/abs/2601.06191)
*Wei Ai,Yun Peng,Yuntao Shou,Tao Meng,Keqin Li*

Main category: cs.LG

TL;DR: 이 논문은 모바일 엣지 컴퓨팅(MEC) 환경에서 다중 에이전트 심층 강화 학습 알고리즘인 TG-DCMADDPG를 제안하여 효율적인 작업 스케줄링과 자원 할당을 목표로 합니다.


<details>
  <summary>Details</summary>
Motivation: IoT 장치와 지연에 민감한 애플리케이션의 급증으로 인해 실시간 및 에너지 효율적인 컴퓨팅에 대한 수요가 늘어나 전통적인 클라우드 컴퓨팅 아키텍처에 압박을 가하고 있습니다.

Method: TG-DCMADDPG는 다중 엣지 서버를 위한 협업 컴퓨팅 프레임워크를 구축하고, 시간 그래프 신경망(TimeGNN)을 사용하여 다차원 서버 상태 정보를 예측합니다. 또한, 불연속적인 행동 공간에서 다중 에이전트 결정론적 정책 그래디언트 알고리즘을 도입하여 작업 분할 비율 및 우선 순위 스케줄링 전략을 최적화합니다.

Result: TG-DCMADDPG는 기존의 최첨단 방법들과 비교하여 정책 수렴 속도가 현저히 빠르고 에너지 지연 최적화 및 작업 완료율이 우수한 결과를 보여줍니다.

Conclusion: 이 연구는 동적이고 제약된 MEC 시나리오에서 강력한 확장성과 실용적인 효율성을 입증합니다.

Abstract: With the rapid growth of IoT devices and latency-sensitive applications, the demand for both real-time and energy-efficient computing has surged, placing significant pressure on traditional cloud computing architectures. Mobile edge computing (MEC), an emerging paradigm, effectively alleviates the load on cloud centers and improves service quality by offloading computing tasks to edge servers closer to end users. However, the limited computing resources, non-continuous power provisioning (e.g., battery-powered nodes), and highly dynamic systems of edge servers complicate efficient task scheduling and resource allocation. To address these challenges, this paper proposes a multi-agent deep reinforcement learning algorithm, TG-DCMADDPG, and constructs a collaborative computing framework for multiple edge servers, aiming to achieve joint optimization of fine-grained task partitioning and offloading. This approach incorporates a temporal graph neural network (TimeGNN) to model and predict time series of multi-dimensional server state information, thereby reducing the frequency of online interactions and improving policy predictability. Furthermore, a multi-agent deterministic policy gradient algorithm (DC-MADDPG) in a discrete-continuous hybrid action space is introduced to collaboratively optimize task partitioning ratios, transmission power, and priority scheduling strategies. Extensive simulation experiments confirm that TG-DCMADDPG achieves markedly faster policy convergence, superior energy-latency optimization, and higher task completion rates compared with existing state-of-the-art methods, underscoring its robust scalability and practical effectiveness in dynamic and constrained MEC scenarios.

</details>


### [76] [SourceNet: Interpretable Sim-to-Real Inference on Variable-Geometry Sensor Arrays for Earthquake Source Inversion](https://arxiv.org/abs/2601.06320)
*Zhe Jia,Xiaotian Zhang,Junpeng Li*

Main category: cs.LG

TL;DR: 이 논문에서는 고차원 물리 상태를 불규칙한 센서 배열로부터 추정하는 문제를 다룬다. 전통적인 딥러닝 모델의 한계를 극복하고자 Transformer 기반의 SourceNet을 제안하며, 물리학적 동역학을 랜덤화하여 모델이 환경의 이질성에 강건한 표현을 학습하도록 유도한다. 최종적으로 SourceNet은 실제 데이터에서 최고의 정확도를 달성했다.


<details>
  <summary>Details</summary>
Motivation: 고차원 물리 상태 추정의 어려움은 불규칙한 기하학과 물리 모델링에서의 Sim-to-Real 간극에 의해 복잡하다.

Method: SourceNet이라는 Transformer 기반 프레임워크를 제안하여 센서 배열을 유연한 집합으로 다루며, 물리학적 구조를 고려한 도메인 랜덤화(PSDR)을 도입하여 모델이 환경 이질성에 강건한 표현을 학습하도록 한다.

Result: SourceNet은 100,000개의 합성 이벤트로 사전 훈련되고 약 2,000개의 실제 사건으로 미세 조정되어, hold-out된 실제 데이터에서 최첨단의 정확도를 달성하였다.

Conclusion: 모델의 해석 가능성 분석을 통해 과학적 에이전트의 특징을 보여주며, 데이터로부터 최적의 실험 설계 원칙을 효과적으로 회수할 수 있음을 알 수 있다.

Abstract: Inferring high-dimensional physical states from sparse, ad-hoc sensor arrays is a fundamental challenge across AI for Science, as they are complicated by irregular geometries and the profound Sim-to-Real gap in physical modeling. Taking earthquake source characterization as a representative challenge, we address limitations in conventional deep learning: CNNs demand fixed grids, while pooling-based architectures (e.g., DeepSets) struggle to capture the relational wave physics. Here, we propose SourceNet, a Transformer-based framework that treats the sensor array as a flexible set to model arbitrary geometries. To bridge the reality gap, we introduce Physics-Structured Domain Randomization (PSDR). Instead of forcing feature alignment, PSDR randomizes the governing physical dynamics by varying velocity structures, propagation effects, and sensor availability, to force the model to learn robust representations invariant to unmodeled environmental heterogeneity. By pre-training on 100,000 synthetic events and fine-tuning on ~2,000 real world events, SourceNet achieves state-of-the-art precision on held-out real data. This demonstrates exceptional data efficiency, and matches classical solvers while enabling real-time processing. Remarkably, interpretability analysis reveals that the model shows scientific-agent-like features: it autonomously discovers geometric information bottlenecks and learns an attention policy that prioritizes sparse sensor placements, effectively recovering principles of optimal experimental design from data alone.

</details>


### [77] [Federated Learning and Class Imbalances](https://arxiv.org/abs/2601.06348)
*Siqi Zhu,Joshua D. Kaggie*

Main category: cs.LG

TL;DR: 이 연구는 RHFL+의 강 robustness를 평가하며, 이는 다양한 데이터 불균형 문제를 해결하기 위한 최신 방법입니다.


<details>
  <summary>Details</summary>
Motivation: 대규모 분산 데이터 환경에서의 협력적 모델 훈련을 지원하며, 데이터 프라이버시를 보호하는 것이 필요합니다.

Method: RHFL+의 복제 및 다양한 벤치마크 알고리즘과의 비교, 실세계 의료 이미지 데이터셋으로의 확장, NVFlare를 활용한 새로운 구현을 포함합니다.

Result: RHFL+의 성능을 검증하기 위해 다양한 노이즈 조건 하의 알고리즘 비교와 클라이언트 수 증가에 따른 확장성 실험을 수행했습니다.

Conclusion: RHFL+는 클래스 불균형 문제에 대한 강력한 솔루션임을 보였으며, 실제 의료 데이터셋에 적합하도록 확장되었습니다.

Abstract: Federated Learning (FL) enables collaborative model training across decentralized devices while preserving data privacy. However, real-world FL deployments face critical challenges such as data imbalances, including label noise and non-IID distributions. RHFL+, a state-of-the-art method, was proposed to address these challenges in settings with heterogeneous client models. This work investigates the robustness of RHFL+ under class imbalances through three key contributions: (1) reproduction of RHFL+ along with all benchmark algorithms under a unified evaluation framework; (2) extension of RHFL+ to real-world medical imaging datasets, including CBIS-DDSM, BreastMNIST and BHI; (3) a novel implementation using NVFlare, NVIDIA's production-level federated learning framework, enabling a modular, scalable and deployment-ready codebase. To validate effectiveness, extensive ablation studies, algorithmic comparisons under various noise conditions and scalability experiments across increasing numbers of clients are conducted.

</details>


### [78] [Certified Unlearning in Decentralized Federated Learning](https://arxiv.org/abs/2601.06436)
*Hengliang Wu,Youming Tao,Anhao Zhou,Shuzhen Chen,Falko Dressler,Dongxiao Yu*

Main category: cs.LG

TL;DR: 본 논문은 분산 연합 학습에서의 기계의 비학습 문제를 해결하기 위한 새로운 인증된 비학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기계 비학습은 개인 정보 보호 머신 러닝에 필수적인 요구 사항으로, 분산 연합 학습에서의 실현은 대체로 미개척 상태이다.

Method: 본 연구에서는 뉴턴 스타일의 업데이트에 기반한 프레임워크를 사용해, 클라이언트의 데이터 영향력이 훈련 중 어떻게 전파되는지를 정량화하고, 이를 통해 교정 업데이트를 구성한다.

Result: 우리는 이 방법이 인증된 비학습의 공식 정의를 만족하며, 비학습 모델이 삭제된 데이터 없이 재훈련된 모델과 구별하기 어렵다는 것을 이론적으로 증명하였다.

Conclusion: 다양한 분산 환경에서의 광범위한 실험을 통해 우리의 프레임워크의 효과성과 효율성을 입증하였다.

Abstract: Driven by the right to be forgotten (RTBF), machine unlearning has become an essential requirement for privacy-preserving machine learning. However, its realization in decentralized federated learning (DFL) remains largely unexplored. In DFL, clients exchange local updates only with neighbors, causing model information to propagate and mix across the network. As a result, when a client requests data deletion, its influence is implicitly embedded throughout the system, making removal difficult without centralized coordination. We propose a novel certified unlearning framework for DFL based on Newton-style updates. Our approach first quantifies how a client's data influence propagates during training. Leveraging curvature information of the loss with respect to the target data, we then construct corrective updates using Newton-style approximations. To ensure scalability, we approximate second-order information via Fisher information matrices. The resulting updates are perturbed with calibrated noise and broadcast through the network to eliminate residual influence across clients. We theoretically prove that our approach satisfies the formal definition of certified unlearning, ensuring that the unlearned model is difficult to distinguish from a retrained model without the deleted data. We also establish utility bounds showing that the unlearned model remains close to retraining from scratch. Extensive experiments across diverse decentralized settings demonstrate the effectiveness and efficiency of our framework.

</details>


### [79] [ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking](https://arxiv.org/abs/2601.06487)
*Qiang Zhang,Boli Chen,Fanrui Zhang,Ruixue Ding,Shihang Wang,Qiuchen Wang,Yinfeng Huang,Haonan Zhang,Rongxiang Zhu,Pengyong Wang,Ailin Ren,Xin Li,Pengjun Xie,Jiawei Liu,Ning Guo,Jingren Zhou,Zheng-Jun Zha*

Main category: cs.LG

TL;DR: ArenaRL은 점수 모델의 한계를 극복하고 LLM 에이전트가 복잡한 작업에서 더 나은 솔루션을 생성하도록 돕는 새로운 강화 학습 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 성능을 향상시키기 위해 강화 학습을 적용하는 데에도 불구하고 개방형 작업의 해결책 공간이 방대하여 여전히 어려움을 겪고 있다.

Method: ArenaRL은 점수 모델에서 집단 내부 상대적 순위로 전환하며, 다단계 기준을 활용하여 주어진 경로에 대해 세밀한 상대 점수를 할당하는 과정 인식 쌍별 평가 메커니즘을 도입한다.

Result: 실험 결과 ArenaRL이 기존의 강화 학습 기준보다 현저히 우수한 성능을 보여주며, LLM 에이전트가 복잡한 현실 작업에 대해 더 견고한 솔루션을 생성할 수 있게 한다.

Conclusion: ArenaRL은 효율성과 정밀성 사이의 최적 밸런스를 달성하며, 복잡한 문제를 해결하기 위한 새로운 경로를 제시한다.

Abstract: Reinforcement learning has substantially improved the performance of LLM agents on tasks with verifiable outcomes, but it still struggles on open-ended agent tasks with vast solution spaces (e.g., complex travel planning). Due to the absence of objective ground-truth for these tasks, current RL algorithms largely rely on reward models that assign scalar scores to individual responses. We contend that such pointwise scoring suffers from an inherent discrimination collapse: the reward model struggles to distinguish subtle advantages among different trajectories, resulting in scores within a group being compressed into a narrow range. Consequently, the effective reward signal becomes dominated by noise from the reward model, leading to optimization stagnation. To address this, we propose ArenaRL, a reinforcement learning paradigm that shifts from pointwise scalar scoring to intra-group relative ranking. ArenaRL introduces a process-aware pairwise evaluation mechanism, employing multi-level rubrics to assign fine-grained relative scores to trajectories. Additionally, we construct an intra-group adversarial arena and devise a tournament-based ranking scheme to obtain stable advantage signals. Empirical results confirm that the built seeded single-elimination scheme achieves nearly equivalent advantage estimation accuracy to full pairwise comparisons with O(N^2) complexity, while operating with only O(N) complexity, striking an optimal balance between efficiency and precision. Furthermore, to address the lack of full-cycle benchmarks for open-ended agents, we build Open-Travel and Open-DeepResearch, two high-quality benchmarks featuring a comprehensive pipeline covering SFT, RL training, and multi-dimensional evaluation. Extensive experiments show that ArenaRL substantially outperforms standard RL baselines, enabling LLM agents to generate more robust solutions for complex real-world tasks.

</details>


### [80] [A novel RF-enabled Non-Destructive Inspection Method through Machine Learning and Programmable Wireless Environments](https://arxiv.org/abs/2601.06512)
*Stavros Tsimpoukis,Dimitrios Tyrovolas,Sotiris Ioannidis,Maria Kafesaki,Ian F. Akyildiz,George K. Karagiannidis,Christos K. Liaskos*

Main category: cs.LG

TL;DR: 본 연구는 무선 환경에서 RF 파동 조작과 기계 학습을 결합한 새로운 비파괴 검사 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현대 산업의 비파괴 검사 방법은 접근이 제한된 환경에서 작동할 수 있는 센싱 능력을 요구한다.

Method: RF 파동 인코딩을 기반으로 하는 RF 센싱 파이프라인을 활용하여 고유한 검사 접근 방식을 제안한다.

Result: 제안된 방법은 시각적 출력에서 99.5%의 SSIM 일치 점수를 달성했다.

Conclusion: 이 연구는 차세대 품질 관리 워크플로우의 길을 열 수 있다.

Abstract: Contemporary industrial Non-Destructive Inspection (NDI) methods require sensing capabilities that operate in occluded, hazardous, or access restricted environments. Yet, the current visual inspection based on optical cameras offers limited quality of service to that respect. In that sense, novel methods for workpiece inspection, suitable, for smart manufacturing are needed. Programmable Wireless Environments (PWE) could help towards that direction, by redefining the wireless Radio Frequency (RF) wave propagation as a controllable inspector entity. In this work, we propose a novel approach to Non-Destructive Inspection, leveraging an RF sensing pipeline based on RF wavefront encoding for retrieving workpiece-image entries from a designated database. This approach combines PWE-enabled RF wave manipulation with machine learning (ML) tools trained to produce visual outputs for quality inspection. Specifically, we establish correlation relationships between RF wavefronts and target industrial assets, hence yielding a dataset which links wavefronts to their corresponding images in a structured manner. Subsequently, a Generative Adversarial Network (GAN) derives visual representations closely matching the database entries. Our results indicate that the proposed method achieves an SSIM 99.5% matching score in visual outputs, paving the way for next-generation quality control workflows in industry.

</details>


### [81] [Improving Day-Ahead Grid Carbon Intensity Forecasting by Joint Modeling of Local-Temporal and Cross-Variable Dependencies Across Different Frequencies](https://arxiv.org/abs/2601.06530)
*Bowen Zhang,Hongda Tian,Adam Berry,A. Craig Roussac*

Main category: cs.LG

TL;DR: 본 연구는 다중 파라미터 모듈을 이용한 전력망 탄소 집약도(CIF) 예측 모델을 제안하며, 이를 통해 예측 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 현대 전력 시스템에서 수요 측 관리 및 배출 감소를 가능하게 하는 데 있어 전력망 탄소 집약도(CIF) 예측의 정확성이 매우 중요하다.

Method: 다중 파형 기반 합성곱 커널을 적용하여 다중 주파수에서 지역-시간 종속성을 강화하고, 다중 주파수에서 변동되는 변수 간 동적 종속성을 캡처하는 두 개의 병렬 모듈을 통합한 새로운 모델을 제안한다.

Result: 호주 내 4개의 대표 전력 시장에서의 평가 결과 제안된 방법이 최신 모델보다 우수함을 보여준다.

Conclusion: 부가적인 해석 가능성을 갖춘 제안 모델은 중단 사건 시 관련 변수와 시간 간격에 주의를 적절히 전환하는 사례 연구를 통해 예측 행동에 대한 이해를 돕는다.

Abstract: Accurate forecasting of the grid carbon intensity factor (CIF) is critical for enabling demand-side management and reducing emissions in modern electricity systems. Leveraging multiple interrelated time series, CIF prediction is typically formulated as a multivariate time series forecasting problem. Despite advances in deep learning-based methods, it remains challenging to capture the fine-grained local-temporal dependencies, dynamic higher-order cross-variable dependencies, and complex multi-frequency patterns for CIF forecasting. To address these issues, we propose a novel model that integrates two parallel modules: 1) one enhances the extraction of local-temporal dependencies under multi-frequency by applying multiple wavelet-based convolutional kernels to overlapping patches of varying lengths; 2) the other captures dynamic cross-variable dependencies under multi-frequency to model how inter-variable relationships evolve across the time-frequency domain. Evaluations on four representative electricity markets from Australia, featuring varying levels of renewable penetration, demonstrate that the proposed method outperforms the state-of-the-art models. An ablation study further validates the complementary benefits of the two proposed modules. Designed with built-in interpretability, the proposed model also enables better understanding of its predictive behavior, as shown in a case study where it adaptively shifts attention to relevant variables and time intervals during a disruptive event.

</details>


### [82] [The Practicality of Normalizing Flow Test-Time Training in Bayesian Inference for Agent-Based Models](https://arxiv.org/abs/2601.07413)
*Junyao Zhang,Jinglai Li,Junqi Tang*

Main category: cs.LG

TL;DR: 이 논문은 경제학과 사회과학에서 에이전트 기반 모델(ABM)의 테스트 타임 훈련(TTT) 방법을 처음으로 조사하고, 정상화 흐름의 매개변수 포스터리어 추정에서의 효과를 입증한다.


<details>
  <summary>Details</summary>
Motivation: ABM은 개별 에이전트 간의 현실적이고 이질적인 결정 및 상호작용 규칙을 설명하는 데 유연성이 뛰어나기 때문에 경제학과 사회과학에서 점점 더 인기를 끌고 있다.

Method: 이 논문에서는 정상화 흐름과 같은 심층 모델의 포스터리어 추정에서 TTT의 실용성을 조사하고, 분포 변화에 대해 정상화 흐름을 미세 조정하기 위한 여러 TTT 전략을 제안한다.

Result: 수치 연구 결과 TTT 방식이 매우 효과적이며, ABM 매개변수에 대한 흐름 기반 추론의 실시간 조정을 가능하게 한다.

Conclusion: 이 연구는 테스트 타임 훈련이 ABM 파라미터 추정 개선에 큰 도움이 될 수 있음을 보여줍니다.

Abstract: Agent-Based Models (ABMs) are gaining great popularity in economics and social science because of their strong flexibility to describe the realistic and heterogeneous decisions and interaction rules between individual agents. In this work, we investigate for the first time the practicality of test-time training (TTT) of deep models such as normalizing flows, in the parameters posterior estimations of ABMs. We propose several practical TTT strategies for fine-tuning the normalizing flow against distribution shifts. Our numerical study demonstrates that TTT schemes are remarkably effective, enabling real-time adjustment of flow-based inference for ABM parameters.

</details>


### [83] [CEDAR: Context Engineering for Agentic Data Science](https://arxiv.org/abs/2601.06606)
*Rishiraj Saha Roy,Chris Hinze,Luzian Hahn,Fabian Kuech*

Main category: cs.LG

TL;DR: CEDAR는 에이전트 설정으로 데이터 과학 작업을 자동화하는 애플리케이션이다.


<details>
  <summary>Details</summary>
Motivation: LLM을 이용한 데이터 과학 문제 해결은 큰 시장 가치를 지닌 미개척 분야이다.

Method: 예비 파라미터를 DS 특정 입력 필드로 구조화하고, 별도의 LLM 에이전트가 생성한 계획 및 코드 블록의 열거형 시퀀스를 통해 해결책을 제시한다.

Result: 이 방법은 데이터가 로컬로 유지되고, 집계 통계와 관련된 지침만 LLM 프롬프트에 주입되도록 보장한다.

Conclusion: 우리의 에이전트형 데이터 과학자의 실행 가능성은 전형적인 Kaggle 도전을 통해 입증되었다.

Abstract: We demonstrate CEDAR, an application for automating data science (DS) tasks with an agentic setup. Solving DS problems with LLMs is an underexplored area that has immense market value. The challenges are manifold: task complexities, data sizes, computational limitations, and context restrictions. We show that these can be alleviated via effective context engineering. We first impose structure into the initial prompt with DS-specific input fields, that serve as instructions for the agentic system. The solution is then materialized as an enumerated sequence of interleaved plan and code blocks generated by separate LLM agents, providing a readable structure to the context at any step of the workflow. Function calls for generating these intermediate texts, and for corresponding Python code, ensure that data stays local, and only aggregate statistics and associated instructions are injected into LLM prompts. Fault tolerance and context management are introduced via iterative code generation and smart history rendering. The viability of our agentic data scientist is demonstrated using canonical Kaggle challenges.

</details>


### [84] [Leveraging Soft Prompts for Privacy Attacks in Federated Prompt Tuning](https://arxiv.org/abs/2601.06641)
*Quan Minh Nguyen,Min-Seon Kim,Hoang M. Ngo,Trong Nghia Hoang,Hyuk-Yoon Kwon,My T. Thai*

Main category: cs.LG

TL;DR: 연합 학습에서의 멤버십 추론 공격(MIA)이 새로운 위협으로 나타나고 있으며, 특히 연합 프롬프트 튜닝을 통해 개인 데이터셋에 대한 공격 경로가 드러났다.


<details>
  <summary>Details</summary>
Motivation: 연합 학습의 프롬프트 튜닝에서 발생하는 프라이버시 공격의 가능성을 강조하기 위함이다.

Method: 악의적인 서버가 조작된 프롬프트를 삽입하고 협업 훈련 중 업데이트를 모니터링하여 특정 데이터 포인트의 존재 여부를 판단하는 PromptMIA라는 공격을 제안한다.

Result: PromptMIA는 다양한 벤치마크 데이터셋에서 일관되게 높은 이점을 달성함을 경험적으로 보여준다.

Conclusion: 기존의 방어 조치들이 PromptMIA와의 상호작용에서 제기하는 비화려한 도전 과제를 강조하고, 프롬프트 튜닝에 맞춘 방어 전략의 필요성을 부각시킨다.

Abstract: Membership inference attack (MIA) poses a significant privacy threat in federated learning (FL) as it allows adversaries to determine whether a client's private dataset contains a specific data sample. While defenses against membership inference attacks in standard FL have been well studied, the recent shift toward federated fine-tuning has introduced new, largely unexplored attack surfaces. To highlight this vulnerability in the emerging FL paradigm, we demonstrate that federated prompt-tuning, which adapts pre-trained models with small input prefixes to improve efficiency, also exposes a new vector for privacy attacks. We propose PromptMIA, a membership inference attack tailored to federated prompt-tuning, in which a malicious server can insert adversarially crafted prompts and monitors their updates during collaborative training to accurately determine whether a target data point is in a client's private dataset. We formalize this threat as a security game and empirically show that PromptMIA consistently attains high advantage in this game across diverse benchmark datasets. Our theoretical analysis further establishes a lower bound on the attack's advantage which explains and supports the consistently high advantage observed in our empirical results. We also investigate the effectiveness of standard membership inference defenses originally developed for gradient or output based attacks and analyze their interaction with the distinct threat landscape posed by PromptMIA. The results highlight non-trivial challenges for current defenses and offer insights into their limitations, underscoring the need for defense strategies that are specifically tailored to prompt-tuning in federated settings.

</details>


### [85] [Reinforcement Learning-Guided Dynamic Multi-Graph Fusion for Evacuation Traffic Prediction](https://arxiv.org/abs/2601.06664)
*Md Nafees Fuad Rafi,Samiul Hasan*

Main category: cs.LG

TL;DR: 이 연구는 허리케인 대피 시 교통 흐름을 실시간으로 예측하기 위한 새로운 프레임워크인 RL-DMF를 제안한다. 이 모델은 동적 다중 그래프 융합과 RL 기반의 유능한 특성 선택 방식을 통해 예측 정확도를 높였다.


<details>
  <summary>Details</summary>
Motivation: 허리케인 대피 시 교통 시스템 관리를 위해 실시간 교통 예측이 필수적이다.

Method: RL-DMF 프레임워크를 통해 동적 그래프를 구축하고, 특성 선택과 순위를 위한 RL 기반 방법을 도입했다.

Result: 모델은 미지의 허리케인에 대해 95% 정확도로 1시간 후 교통 흐름을 예측하였고, 최대 6시간 후 교통 흐름에 대해서도 90% 정확도를 달성했다.

Conclusion: 이 연구는 실시간 대피 교통 예측을 위한 일반화되고 해석 가능한 모델을 제공하며, 이는 대피 교통 관리에 중요한 영향을 미친다.

Abstract: Real-time traffic prediction is critical for managing transportation systems during hurricane evacuations. Although data-driven graph-learning models have demonstrated strong capabilities in capturing the complex spatiotemporal dynamics of evacuation traffic at a network level, they mostly consider a single dimension (e.g., travel-time or distance) to construct the underlying graph. Furthermore, these models often lack interpretability, offering little insight into which input variables contribute most to their predictive performance. To overcome these limitations, we develop a novel Reinforcement Learning-guided Dynamic Multi-Graph Fusion (RL-DMF) framework for evacuation traffic prediction. We construct multiple dynamic graphs at each time step to represent heterogeneous spatiotemporal relationships between traffic detectors. A dynamic multi-graph fusion (DMF) module is employed to adaptively learn and combine information from these graphs. To enhance model interpretability, we introduce RL-based intelligent feature selection and ranking (RL-IFSR) method that learns to mask irrelevant features during model training. The model is evaluated using a real-world dataset of 12 hurricanes affecting Florida from 2016 to 2024. For an unseen hurricane (Milton, 2024), the model achieves a 95% accuracy (RMSE = 293.9) for predicting the next 1-hour traffic flow. Moreover, the model can forecast traffic flow for up to next 6 hours with 90% accuracy (RMSE = 426.4). The RL-DMF framework outperforms several state-of-the-art traffic prediction models. Furthermore, ablation experiments confirm the effectiveness of dynamic multi-graph fusion and RL-IFSR approaches for improving model performance. This research provides a generalized and interpretable model for real-time evacuation traffic forecasting, with significant implications for evacuation traffic management.

</details>


### [86] [Predicting Student Success with Heterogeneous Graph Deep Learning and Machine Learning Models](https://arxiv.org/abs/2601.06729)
*Anca Muresan,Mihaela Cardei,Ionut Cardei*

Main category: cs.LG

TL;DR: 학생 성공의 조기 식별은 적시 개입, 이탈률 감소 및 정시 졸업을 촉진하는 데 필수적이다. 본 연구에서는 동적 데이터 기능과 다중 카테고리 엔터티를 활용하여 학생 성과 예측을 향상하는 이종 그래프 딥 러닝 모델을 통합한 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 학생 성공을 조기에 식별하는 것은 학생 이탈률을 감소시키고, 적시에 개입할 수 있는 기회를 제공하며, 정시 졸업을 촉진하는 데 필수적이다.

Method: 이 연구는 이종 그래프 딥 러닝 모델을 통합하여 학생 성과 예측을 개선하는 프레임워크를 제안하고, 전통적인 기계 학습 알고리즘과 비교한다.

Result: Open University Learning Analytics (OULA) 데이터셋에 대한 실험 결과, 학기 초 7%에서 68.6%의 검증 F1 점수를 달성하고, 학기 종료 시점에 89.5%에 도달하였다. 본 접근법은 학기 초의 중요한 7%에서 검증 F1 점수에서 상위 기계 학습 모델보다 4.7% 더 나은 성과를 보였다.

Conclusion: 동적 특성과 이종 그래프 표현의 가치는 학생 성공 예측에서 매우 높음을 보여준다.

Abstract: Early identification of student success is crucial for enabling timely interventions, reducing dropout rates, and promoting on time graduation. In educational settings, AI powered systems have become essential for predicting student performance due to their advanced analytical capabilities. However, effectively leveraging diverse student data to uncover latent and complex patterns remains a key challenge. While prior studies have explored this area, the potential of dynamic data features and multi category entities has been largely overlooked. To address this gap, we propose a framework that integrates heterogeneous graph deep learning models to enhance early and continuous student performance prediction, using traditional machine learning algorithms for comparison. Our approach employs a graph metapath structure and incorporates dynamic assessment features, which progressively influence the student success prediction task. Experiments on the Open University Learning Analytics (OULA) dataset demonstrate promising results, achieving a 68.6% validation F1 score with only 7% of the semester completed, and reaching up to 89.5% near the semester's end. Our approach outperforms top machine learning models by 4.7% in validation F1 score during the critical early 7% of the semester, underscoring the value of dynamic features and heterogeneous graph representations in student success prediction.

</details>


### [87] [Federated Continual Learning for Privacy-Preserving Hospital Imaging Classification](https://arxiv.org/abs/2601.06742)
*Anay Sinhal,Arpana Sinhal,Amit Sinhal*

Main category: cs.LG

TL;DR: 병원들이 협력하여 모델을 훈련할 수 있도록 하는 연합 학습(FL) 방법을 제안하며, 연속적인 데이터 분포 변화에 적응할 수 있도록 하는 연합 지속 학습(FCL) 방식이 소개된다.


<details>
  <summary>Details</summary>
Motivation: 다기관 데이터를 활용한 방사선 해석을 위한 딥러닝 모델이 필요하지만, 프라이버시 규제와 병원 간의 데이터 분포 변화가 중앙 데이터 집합을 제한한다.

Method: 우리는 상시 발전하는 사례와 레이블 흐름을 받는 클라이언트로서 병원 환경에서 흉부 방사선 분류를 위한 FCL을 연구하며, DP-FedEPC라는 방법을 도입한다. 이 방법은 EWC(Elastic Weight Consolidation), 프로토타입 기반 리허설, 클라이언트 측 차별적 프라이버시를 결합한다.

Result: EWC는 이전 작업에 중요하다고 간주된 파라미터를 따라 업데이트를 제약하며, 잠재적 프로토타입의 메모리는 원본 이미지를 저장하지 않고도 클래스 구조를 보존한다.

Conclusion: 각 클라이언트에서 DP-SGD를 사용하여 클리핑된 기울기에 조정된 가우스 노이즈를 추가함으로써, 개별 방사선 사진에 대한 공식적인 프라이버시 보장을 제공한다.

Abstract: Deep learning models for radiology interpretation increasingly rely on multi-institutional data, yet privacy regulations and distribution shift across hospitals limit central data pooling. Federated learning (FL) allows hospitals to collaboratively train models without sharing raw images, but current FL algorithms typically assume a static data distribution. In practice, hospitals experience continual evolution in case mix, annotation protocols, and imaging devices, which leads to catastrophic forgetting when models are updated sequentially. Federated continual learning (FCL) aims to reconcile these challenges but existing methods either ignore the stringent privacy constraints of healthcare or rely on replay buffers and public surrogate datasets that are difficult to justify in clinical settings. We study FCL for chest radiography classification in a setting where hospitals are clients that receive temporally evolving streams of cases and labels. We introduce DP-FedEPC (Differentially Private Federated Elastic Prototype Consolidation), a method that combines elastic weight consolidation (EWC), prototype-based rehearsal, and client-side differential privacy within a standard FedAvg framework. EWC constrains updates along parameters deemed important for previous tasks, while a memory of latent prototypes preserves class structure without storing raw images. Differentially private stochastic gradient descent (DP-SGD) at each client adds calibrated Gaussian noise to clipped gradients, providing formal privacy guarantees for individual radiographs.

</details>


### [88] [Tractable Multinomial Logit Contextual Bandits with Non-Linear Utilities](https://arxiv.org/abs/2601.06913)
*Taehyun Hwang,Dahngoon Kim,Min-hwan Oh*

Main category: cs.LG

TL;DR: MNL 맥락 밴딧 문제를 위한 효율적인 알고리즘을 제안하며, 비선형 효용함수에서도 최적 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구의 선형 가정으로 복잡한 상호작용을 모델링할 수 없는 문제를 해결하고자 한다.

Method: 상한신뢰구간 원리를 활용한 계산 효율적인 알고리즘을 제안한다.

Result: 알고리즘은 $	ilde{O}(	ext{√}T)$의 후회를 달성한다.

Conclusion: 제안된 알고리즘은 비선형 효용을 가진 MNL 맥락 밴딧 문제를 해결하는 최초의 계산 가능 알고리즘이다.

Abstract: We study the multinomial logit (MNL) contextual bandit problem for sequential assortment selection. Although most existing research assumes utility functions to be linear in item features, this linearity assumption restricts the modeling of intricate interactions between items and user preferences. A recent work (Zhang & Luo, 2024) has investigated general utility function classes, yet its method faces fundamental trade-offs between computational tractability and statistical efficiency. To address this limitation, we propose a computationally efficient algorithm for MNL contextual bandits leveraging the upper confidence bound principle, specifically designed for non-linear parametric utility functions, including those modeled by neural networks. Under a realizability assumption and a mild geometric condition on the utility function class, our algorithm achieves a regret bound of $\tilde{O}(\sqrt{T})$, where $T$ denotes the total number of rounds. Our result establishes that sharp $\tilde{O}(\sqrt{T})$-regret is attainable even with neural network-based utilities, without relying on strong assumptions such as neural tangent kernel approximations. To the best of our knowledge, our proposed method is the first computationally tractable algorithm for MNL contextual bandits with non-linear utilities that provably attains $\tilde{O}(\sqrt{T})$ regret. Comprehensive numerical experiments validate the effectiveness of our approach, showing robust performance not only in realizable settings but also in scenarios with model misspecification.

</details>


### [89] [Explainable Deep Radiogenomic Molecular Imaging for MGMT Methylation Prediction in Glioblastoma](https://arxiv.org/abs/2601.07035)
*Hasan M Jamil*

Main category: cs.LG

TL;DR: 이 연구는 비침습적으로 O6-methylguanine-DNA methyltransferase (MGMT) 촉진제의 메틸화 상태를 예측하기 위한 방사선 유전체 분석 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: GBM의 치료 옵션이 제한적이고 예후가 나쁘기 때문에, MGMT 유전자 촉진제의 메틸화 상태를 예측하는 새로운 방법이 필요하다.

Method: 다중 매개 변수 자기 공명 영상(multi-parametric MRI)을 사용하여 방사선학, 딥러닝 및 설명 가능한 인공 지능(XAI)을 통합하여 MGMT 메틸화 상태를 예측하는 프레임워크를 개발하였다.

Result: 기존의 RSNA-MICCAI Radiogenomic Classification 데이터셋을 기반으로 훈련하고 BraTS 2021 데이터셋에서 외부 검증을 통해 정확한 예측 성능을 입증하였다.

Conclusion: 이 프레임워크는 GBM에서 임상적으로 실용적인 분자 바이오마커의 비침습적이고 정확하며 해석 가능한 예측의 가능성을 제시한다.

Abstract: Glioblastoma (GBM) is a highly aggressive primary brain tumor with limited therapeutic options and poor prognosis. The methylation status of the O6-methylguanine-DNA methyltransferase (MGMT) gene promoter is a critical molecular biomarker that influences patient response to temozolomide chemotherapy. Traditional methods for determining MGMT status rely on invasive biopsies and are limited by intratumoral heterogeneity and procedural risks. This study presents a radiogenomic molecular imaging analysis framework for the non-invasive prediction of MGMT promoter methylation using multi-parametric magnetic resonance imaging (mpMRI).
  Our approach integrates radiomics, deep learning, and explainable artificial intelligence (XAI) to analyze MRI-derived imaging phenotypes and correlate them with molecular labels. Radiomic features are extracted from FLAIR, T1-weighted, T1-contrast-enhanced, and T2-weighted MRI sequences, while a 3D convolutional neural network learns deep representations from the same modalities. These complementary features are fused using both early fusion and attention-based strategies and classified to predict MGMT methylation status.
  To enhance clinical interpretability, we apply XAI methods such as Grad-CAM and SHAP to visualize and explain model decisions. The proposed framework is trained on the RSNA-MICCAI Radiogenomic Classification dataset and externally validated on the BraTS 2021 dataset. This work advances the field of molecular imaging by demonstrating the potential of AI-driven radiogenomics for precision oncology, supporting non-invasive, accurate, and interpretable prediction of clinically actionable molecular biomarkers in GBM.

</details>


### [90] [Hallucinations Live in Variance](https://arxiv.org/abs/2601.07058)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 기존 벤치마크는 모델의 정확성을 측정하지만 신뢰성을 측정하지 않는다. 이는 단계적 실행에서 단일 재구성된 프롬프트가 연속적인 실패를 일으킬 수 있는 주체적 AI 시스템에 있어 중요하다. 본 논문에서는 세멘틱 스태빌리티(SS)를 통해 변동에 의해 유도된 신뢰성 저하를 진단하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 단일 재구성된 프롬프트가 연속적인 실패를 유발할 수 있는 AI 시스템에서의 신뢰성 문제를 다루기 위해.

Method: 세멘틱 스태빌리티(SS)를 정의하고, 이는 Paraphrase Consistency(PC@k)를 통해 측정되며, k개의 패러프레이즈를 생성하고 각 패러프레이즈의 모드를 계산한다.

Result: Qwen3-0.6B 모델은 23.8%의 자기 일관성을 보여주며 32%의 희소성에서 일관성은 55.9%로 증가한다.

Conclusion: 변동 감소가 편향 축적보다 우세한 '스위트 스팟'을 찾고, 안정성이 잘못된 답변으로 붕괴되는 영역을 밝혀냈다.

Abstract: Benchmarks measure whether a model is correct. They do not measure whether a model is reliable. This distinction is largely academic for single-shot inference, but becomes critical for agentic AI systems, where a single rephrased prompt can trigger cascading failures in multi-step execution. Yet this form of instability is not captured by existing evaluations.
  Hallucinations live in variance: they arise when semantically equivalent prompts activate inconsistent internal pathways, producing divergent outputs. Consistent but incorrect outputs reflect bias or missing knowledge; confident guessing reflects calibration failure. Neither constitutes hallucination under this definition. When error is variance-dominated, reducing redundant pathways improves reliability without adding knowledge. We formalize this through Semantic Stability (SS), measured via Paraphrase Consistency (PC@k): generate k paraphrases, greedy decode each, compute mode agreement. SS is a diagnostic for variance-driven unreliability, not a method for improving correctness.
  We show that a dense Qwen3-0.6B agrees with itself only 23.8% of the time; at 32% sparsity, agreement jumps to 55.9%. A phase diagram reveals the sweet spot where variance reduction outpaces bias accumulation, and regimes where stability collapses onto wrong answers.

</details>


### [91] [Generating readily synthesizable small molecule fluorophore scaffolds with reinforcement learning](https://arxiv.org/abs/2601.07145)
*Ruhi Sayana,Kate Callon,Jennifer Xu,Jonathan Deutsch,Steven Chu,James Zou,John Janetzko,Rabindra V. Shivnaraine,Kyle Swanson*

Main category: cs.LG

TL;DR: SyntheFluor-RL은 강화 학습을 사용하여 합성 가능한 형광 분자를 생성하는 generative AI 모델이다.


<details>
  <summary>Details</summary>
Motivation: 새로운 형광 염료 개발을 위해 새로운 화학 공간을 탐색해야 한다.

Method: SyntheFluor-RL 모델은 알려진 반응 라이브러리와 분자 빌딩 블록을 활용하여 형광 분자 골격을 생성한다.

Result: SyntheFluor-RL은 11,590개의 후보 분자를 생성하였고, 이 중 19개의 구조가 염료 같은 성질을 가질 것으로 예측되었다.

Conclusion: SyntheFluor-RL은 앞으로의 개발을 위한 합성 가능한 형광 분자를 찾는 데 효과적임을 입증했다.

Abstract: Developing new fluorophores for advanced imaging techniques requires exploring new chemical space. While generative AI approaches have shown promise in designing novel dye scaffolds, prior efforts often produced synthetically intractable candidates due to a lack of reaction constraints. Here, we developed SyntheFluor-RL, a generative AI model that employs known reaction libraries and molecular building blocks to create readily synthesizable fluorescent molecule scaffolds via reinforcement learning. To guide the generation of fluorophores, SyntheFluor-RL employs a scoring function built on multiple graph neural networks (GNNs) that predict key photophysical properties, including photoluminescence quantum yield, absorption, and emission wavelengths. These outputs are dynamically weighted and combined with a computed pi-conjugation score to prioritize candidates with desirable optical characteristics and synthetic feasibility. SyntheFluor-RL generated 11,590 candidate molecules, which were filtered to 19 structures predicted to possess dye-like properties. Of the 19 molecules, 14 were synthesized and 13 were experimentally confirmed. The top three were characterized, with the lead compound featuring a benzothiadiazole chromophore and exhibiting strong fluorescence (PLQY = 0.62), a large Stokes shift (97 nm), and a long excited-state lifetime (11.5 ns). These results demonstrate the effectiveness of SyntheFluor-RL in the identification of synthetically accessible fluorophores for further development.

</details>


### [92] [Offline Meta-Reinforcement Learning with Flow-Based Task Inference and Adaptive Correction of Feature Overgeneralization](https://arxiv.org/abs/2601.07164)
*Min Wang,Xin Li,Mingzhong Wang,Hasnaa Bennis*

Main category: cs.LG

TL;DR: FLORA는 OOD 샘플을 모델링하고 불확실성을 추정하여 오프라인 메타 강화 학습에서 정책의 저하를 방지하고 적응성을 향상시키는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 메타 강화 학습(OMRL)은 다양한 데이터셋에서 학습하는 기존의 오프라인 RL의 장점과 새로운 작업에 대한 적응력을 결합하여 RL 에이전트의 안전하고 효율적인 지식 획득을 약속하나, OOD 행동으로 인한 외삽 오류에 여전히 시달린다.

Method: FLORA는 OOD 샘플을 파악하기 위해 피처 분포를 모델링하고 불확실성을 추정하며, 피처 구성요소를 적응적으로 조정하기 위한 반환 피드백 메커니즘을 통합한다. 또한 복잡한 작업 분포를 표현하기 위해 가역 변환의 연쇄를 모델링한다.

Result: FLORA는 이론적 및 실증적으로 다양한 환경에서 기준보다 빠른 적응과 메타 정책 개선을 달성한다.

Conclusion: 이 연구는 FLORA가 고품질 데이터의 경우 적응성과 수렴성을 향상시키지만, 복잡한 작업에서는 정책의 저하나 붕괴를 초래할 수 있음을 보여준다.

Abstract: Offline meta-reinforcement learning (OMRL) combines the strengths of learning from diverse datasets in offline RL with the adaptability to new tasks of meta-RL, promising safe and efficient knowledge acquisition by RL agents. However, OMRL still suffers extrapolation errors due to out-of-distribution (OOD) actions, compromised by broad task distributions and Markov Decision Process (MDP) ambiguity in meta-RL setups. Existing research indicates that the generalization of the $Q$ network affects the extrapolation error in offline RL. This paper investigates this relationship by decomposing the $Q$ value into feature and weight components, observing that while decomposition enhances adaptability and convergence in the case of high-quality data, it often leads to policy degeneration or collapse in complex tasks. We observe that decomposed $Q$ values introduce a large estimation bias when the feature encounters OOD samples, a phenomenon we term ''feature overgeneralization''. To address this issue, we propose FLORA, which identifies OOD samples by modeling feature distributions and estimating their uncertainties. FLORA integrates a return feedback mechanism to adaptively adjust feature components. Furthermore, to learn precise task representations, FLORA explicitly models the complex task distribution using a chain of invertible transformations. We theoretically and empirically demonstrate that FLORA achieves rapid adaptation and meta-policy improvement compared to baselines across various environments.

</details>


### [93] [MAESTRO: Meta-learning Adaptive Estimation of Scalarization Trade-offs for Reward Optimization](https://arxiv.org/abs/2601.07208)
*Yang Zhao,Hepeng Wang,Xiao Ding,Yangou Ouyang,Bibo Cai,Kai Xiong,Jinglong Gao,Zhouhao Sun,Li Du,Bing Qin,Ting Liu*

Main category: cs.LG

TL;DR: MAESTRO는 LLM을 위한 동적 보상 스칼라화 기법을 메타 학습하여, 기존의 정적 방법보다 효과적으로 다양한 목표 사이의 거래를 조율한다.


<details>
  <summary>Details</summary>
Motivation: GRPO는 LLM을 조정하기 위한 효율적인 패러다임이지만, 개방형 도메인으로 확장하는 데한계가 있어 이를 해결할 필요가 있다.

Method: MAESTRO는 보상 스칼라화를 동적 잠재 정책으로 처리하는 메타 인지 오케스트레이션 레이어를 도입하고, 이를 이중 최적화 프레임워크 내에서 맥락적 잡기 문제로 형성하여 경량의 컨덕터 네트워크가 정책과 공진하여 그룹 상대 이점을 메타 보상 신호로 활용한다.

Result: MAESTRO는 일곱 개의 벤치마크에서 단일 보상 및 정적 다목적 기준보다 지속적으로 더 나은 성능을 보이며, GRPO의 효율성 장점을 유지하고 일부 설정에서는 중복 생성을 줄인다.

Conclusion: MAESTRO는 동적이고 복잡한 환경에서 LLM의 목표 조율을 성공적으로 달성하여, 보상 최적화 문제를 효과적으로 해결한다.

Abstract: Group-Relative Policy Optimization (GRPO) has emerged as an efficient paradigm for aligning Large Language Models (LLMs), yet its efficacy is primarily confined to domains with verifiable ground truths. Extending GRPO to open-domain settings remains a critical challenge, as unconstrained generation entails multi-faceted and often conflicting objectives - such as creativity versus factuality - where rigid, static reward scalarization is inherently suboptimal. To address this, we propose MAESTRO (Meta-learning Adaptive Estimation of Scalarization Trade-offs for Reward Optimization), which introduces a meta-cognitive orchestration layer that treats reward scalarization as a dynamic latent policy, leveraging the model's terminal hidden states as a semantic bottleneck to perceive task-specific priorities. We formulate this as a contextual bandit problem within a bi-level optimization framework, where a lightweight Conductor network co-evolves with the policy by utilizing group-relative advantages as a meta-reward signal. Across seven benchmarks, MAESTRO consistently outperforms single-reward and static multi-objective baselines, while preserving the efficiency advantages of GRPO, and in some settings even reducing redundant generation.

</details>


### [94] [FROAV: A Framework for RAG Observation and Agent Verification -- Lowering the Barrier to LLM Agent Research](https://arxiv.org/abs/2601.07504)
*Tzu-Hsuan Lin,Chih-Hsuan Kao*

Main category: cs.LG

TL;DR: FROAV는 LLM 에이전트 연구를 민주화하고, 사용자가 코드를 작성하지 않고도 RAG 전략을 프로토타입할 수 있게 해주는 오픈 소스 플랫폼이다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트 워크플로우의 복잡성 때문에 소프트웨어 엔지니어링 전문 지식이 부족한 연구자들에게 큰 장벽이 되고 있다.

Method: FROAV는 비주얼 워크플로우 오케스트레이션, 포괄적인 평가 프레임워크, 확장 가능한 Python 통합을 결합한 플러그 앤 플레이 아키텍처를 가지고 있다.

Result: FROAV는 재무 문서 분석에 적용하여 그 유용성을 입증하며, 모든 분야에서 의미 분석이 필요한 경우 적응 가능한 재료 비독립적인 아키텍처를 강조한다.

Conclusion: FROAV는 LLM 에이전트 연구를 보다 넓은 과학 공동체에 접근 가능하게 하여 연구자들이 시스템 통합 문제 대신 가설 테스트와 알고리즘 혁신에 집중할 수 있게 한다.

Abstract: The rapid advancement of Large Language Models (LLMs) and their integration into autonomous agent systems has created unprecedented opportunities for document analysis, decision support, and knowledge retrieval. However, the complexity of developing, evaluating, and iterating on LLM-based agent workflows presents significant barriers to researchers, particularly those without extensive software engineering expertise. We present FROAV (Framework for RAG Observation and Agent Verification), an open-source research platform that democratizes LLM agent research by providing a plug-and-play architecture combining visual workflow orchestration, a comprehensive evaluation framework, and extensible Python integration. FROAV implements a multi-stage Retrieval-Augmented Generation (RAG) pipeline coupled with a rigorous "LLM-as-a-Judge" evaluation system, all accessible through intuitive graphical interfaces. Our framework integrates n8n for no-code workflow design, PostgreSQL for granular data management, FastAPI for flexible backend logic, and Streamlit for human-in-the-loop interaction. Through this integrated ecosystem, researchers can rapidly prototype RAG strategies, conduct prompt engineering experiments, validate agent performance against human judgments, and collect structured feedback-all without writing infrastructure code. We demonstrate the framework's utility through its application to financial document analysis, while emphasizing its material-agnostic architecture that adapts to any domain requiring semantic analysis. FROAV represents a significant step toward making LLM agent research accessible to a broader scientific community, enabling researchers to focus on hypothesis testing and algorithmic innovation rather than system integration challenges.

</details>


### [95] [Land-then-transport: A Flow Matching-Based Generative Decoder for Wireless Image Transmission](https://arxiv.org/abs/2601.07512)
*Jingwen Fu,Ming Xiao,Mikael Skoglund,Dong In Kim*

Main category: cs.LG

TL;DR: 본 논문은 저지연 환경에서도 효과적인 무선 이미지 전송을 위한 새로운 프레임워크인 LTT 기반의 생성적 디코더를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 무선 이미지 전송은 엄격한 비율 및 신뢰성 요구 사항으로 인해 전통적인 레이어드 디자인 및 결합 소스-채널 코딩(Joint Source-Channel Coding)에서 어려움을 겪고 있습니다.

Method: 본 연구에서는 새로운 'land-then-transport' (LTT) 패러다임 하에 물리적 무선 채널을 연속적인 확률 흐름과 긴밀하게 통합한 흐름 일치(FM) 생성적 디코더를 제안합니다.

Result: MNIST, Fashion-MNIST, DIV2K 실험 결과는 JPEG2000+LDPC, DeepJSCC 및 확산 기반 기준보다 일관된 성능 향상을 보였으며, 소수의 ODE 단계로도 좋은 지각 품질을 달성했습니다.

Conclusion: 전반적으로 LTT는 다양한 채널에서 생성적 무선 이미지 디코딩을 위한 결정론적이고 물리적으로 해석 가능한, 계산 효율적인 프레임워크를 제공합니다.

Abstract: Due to strict rate and reliability demands, wireless image transmission remains difficult for both classical layered designs and joint source-channel coding (JSCC), especially under low latency. Diffusion-based generative decoders can deliver strong perceptual quality by leveraging learned image priors, but iterative stochastic denoising leads to high decoding delay. To enable low-latency decoding, we propose a flow-matching (FM) generative decoder under a new land-then-transport (LTT) paradigm that tightly integrates the physical wireless channel into a continuous-time probability flow. For AWGN channels, we build a Gaussian smoothing path whose noise schedule indexes effective noise levels, and derive a closed-form teacher velocity field along this path. A neural-network student vector field is trained by conditional flow matching, yielding a deterministic, channel-aware ODE decoder with complexity linear in the number of ODE steps. At inference, it only needs an estimate of the effective noise variance to set the ODE starting time. We further show that Rayleigh fading and MIMO channels can be mapped, via linear MMSE equalization and singular-value-domain processing, to AWGN-equivalent channels with calibrated starting times. Therefore, the same probability path and trained velocity field can be reused for Rayleigh and MIMO without retraining. Experiments on MNIST, Fashion-MNIST, and DIV2K over AWGN, Rayleigh, and MIMO demonstrate consistent gains over JPEG2000+LDPC, DeepJSCC, and diffusion-based baselines, while achieving good perceptual quality with only a few ODE steps. Overall, LTT provides a deterministic, physically interpretable, and computation-efficient framework for generative wireless image decoding across diverse channels.

</details>


### [96] [TFEC: Multivariate Time-Series Clustering via Temporal-Frequency Enhanced Contrastive Learning](https://arxiv.org/abs/2601.07550)
*Zexi Tan,Tao Xie,Haoyi Xiao,Baoyao Yang,Yuzhu Ji,An Zeng,Xiang Zhang,Yiqun Zhang*

Main category: cs.LG

TL;DR: 이 논문은 다변량 시계열 클러스터링을 위한 새로운 학습 프레임워크인 TFEC를 제안하며, 기존 대비 성능 향상을 도모한다.


<details>
  <summary>Details</summary>
Motivation: 다변량 시계열(MTS) 클러스터링은 신호 처리 및 데이터 분석에서 중요한 역할을 하며, 딥 러닝 접근법이 부각되고 있으나 기존 방법들이 몇 가지 한계를 가지고 있다.

Method: TFEC(Temporal-Frequency Enhanced Contrastive) 학습 프레임워크를 제안하며, Co-EnHancement (CoEH) 메커니즘을 통해 시간 구조를 유지하면서 저왜곡 표현을 생성한다.

Result: 여섯 개의 실제 벤치마크 데이터셋에서 실험을 통해 TFEC가 SOTA 방법들보다 평균 4.48%의 NMI 향상을 달성했다.

Conclusion: TFEC는 클러스터 구조와 표현 충실도를 공동 최적화하는 이중 경로 표현 및 클러스터 분포 학습 프레임워크를 제공하며, 디자인을 검증하는 ablation 연구 결과를 통해 그 우수성을 입증했다.

Abstract: Multivariate Time-Series (MTS) clustering is crucial for signal processing and data analysis. Although deep learning approaches, particularly those leveraging Contrastive Learning (CL), are prominent for MTS representation, existing CL-based models face two key limitations: 1) neglecting clustering information during positive/negative sample pair construction, and 2) introducing unreasonable inductive biases, e.g., destroying time dependence and periodicity through augmentation strategies, compromising representation quality. This paper, therefore, proposes a Temporal-Frequency Enhanced Contrastive (TFEC) learning framework. To preserve temporal structure while generating low-distortion representations, a temporal-frequency Co-EnHancement (CoEH) mechanism is introduced. Accordingly, a synergistic dual-path representation and cluster distribution learning framework is designed to jointly optimize cluster structure and representation fidelity. Experiments on six real-world benchmark datasets demonstrate TFEC's superiority, achieving 4.48% average NMI gains over SOTA methods, with ablation studies validating the design. The code of the paper is available at: https://github.com/yueliangy/TFEC.

</details>


### [97] [Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography](https://arxiv.org/abs/2601.07618)
*Yulu Wang,Ziqian Zeng,Jianjun Wu,Zhifeng Tang*

Main category: cs.LG

TL;DR: 실시간 응고 모니터링을 위한 새로운 알고리즘 PSR을 제시하며, 이는 적은 데이터로도 유용한 진단을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 TEG는 신속한 응고 모니터링을 제공하지 못해 사망률 증가의 원인이 될 수 있다.

Method: Physiological State Reconstruction (PSR) 알고리즘과 MDFE 및 HLA와 같은 기술을 사용하여 다중 도메인 신호를 통합하고 고수준의 시계열 상호작용을 학습한다.

Result: PSR은 4개의 TEG 전문 데이터 세트에서 R2 > 0.98의 예측 결과를 기록했으며, 기존 방법보다 오류를 절반으로 줄였다.

Conclusion: 드리프트 인식 학습은 데이터 부족 상황에서도 효율적인 의료 AI 적용 가능성을 제시한다.

Abstract: In an ideal medical environment, real-time coagulation monitoring can enable early detection and prompt remediation of risks. However, traditional Thromboelastography (TEG), a widely employed diagnostic modality, can only provide such outputs after nearly 1 hour of measurement. The delay might lead to elevated mortality rates. These issues clearly point out one of the key challenges for medical AI development: Mak-ing reasonable predictions based on very small data sets and accounting for variation between different patient populations, a task where conventional deep learning methods typically perform poorly. We present Physiological State Reconstruc-tion (PSR), a new algorithm specifically designed to take ad-vantage of dynamic changes between individuals and to max-imize useful information produced by small amounts of clini-cal data through mapping to reliable predictions and diagnosis. We develop MDFE to facilitate integration of varied temporal signals using multi-domain learning, and jointly learn high-level temporal interactions together with attentions via HLA; furthermore, the parameterized DAM we designed maintains the stability of the computed vital signs. PSR evaluates with 4 TEG-specialized data sets and establishes remarkable perfor-mance -- predictions of R2 > 0.98 for coagulation traits and error reduction around half compared to the state-of-the-art methods, and halving the inferencing time too. Drift-aware learning suggests a new future, with potential uses well be-yond thrombophilia discovery towards medical AI applica-tions with data scarcity.

</details>


### [98] [Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control](https://arxiv.org/abs/2601.07748)
*Robert Lewis,Katie Matton,Rosalind W. Picard,John Guttag*

Main category: cs.LG

TL;DR: 이 논문에서는 도메인 간 불변성을 높이기 위해 도메인 레이블을 통합한 새로운 대조적 학습 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 자원적으로 레이블이 부족한 데이터에서 학습하기 위해 대조적 학습을 사용하는 것이 효과적이지만, 훈련 데이터와 테스트 데이터 간의 분포 변화가 성능 저하를 일으킬 수 있습니다.

Method: 도메인 레이블을 통합하여 대조적 학습의 새로운 접근 방식을 제시하며, InfoNCE 손실의 온도 매개변수를 조정하여 부정 샘플의 도메인 동일성을 고려합니다.

Result: MNIST 데이터셋 변형에 대한 실험을 통해 제안된 방법이 도메인 일반화 기준보다 더 나은 성능을 발휘함을 입증합니다.

Conclusion: 제안된 방법은 강력한 인디스트리뷰션 작업 성능을 유지하면서 기준을 크게 초과하는 성과를 냅니다.

Abstract: Self-supervised pre-training with contrastive learning is a powerful method for learning from sparsely labeled data. However, performance can drop considerably when there is a shift in the distribution of data from training to test time. We study this phenomenon in a setting in which the training data come from multiple domains, and the test data come from a domain not seen at training that is subject to significant covariate shift. We present a new method for contrastive learning that incorporates domain labels to increase the domain invariance of learned representations, leading to improved out-of-distribution generalization. Our method adjusts the temperature parameter in the InfoNCE loss -- which controls the relative weighting of negative pairs -- using the probability that a negative sample comes from the same domain as the anchor. This upweights pairs from more similar domains, encouraging the model to discriminate samples based on domain-invariant attributes. Through experiments on a variant of the MNIST dataset, we demonstrate that our method yields better out-of-distribution performance than domain generalization baselines. Furthermore, our method maintains strong in-distribution task performance, substantially outperforming baselines on this measure.

</details>


### [99] [Optimal Learning Rate Schedule for Balancing Effort and Performance](https://arxiv.org/abs/2601.07830)
*Valentina Njaradi,Rodrigo Carrasco-Davis,Peter E. Latham,Andrew Saxe*

Main category: cs.LG

TL;DR: 이 논문은 학습 속도를 최적화하는 규범적 프레임워크를 제안하여 자가 조절 학습 및 자원 할당을 통합하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 효율적으로 배우는 방법을 배우는 것은 생물체와 인공 에이전트 모두에게 근본적인 도전 과제이다.

Method: 학습 속도를 최적화하기 위해 자가 조절 프로세스를 수립하고, 에이전트의 현재 및 미래 성과에 의존하는 폐쇄형 제어기를 도출한다.

Result: 제안된 모델은 과거 학습 경험을 회상하여 학습 속도 조정의 정확성을 높였으며, 다양한 작업 및 구조에서 일반화 가능하다.

Conclusion: 제안된 프레임워크는 학습 속도 조절의 규범적이고 생물학적으로 그럴듯한 설명을 제공하며, 자가 조절 학습 이론과 연결된다.

Abstract: Learning how to learn efficiently is a fundamental challenge for biological agents and a growing concern for artificial ones. To learn effectively, an agent must regulate its learning speed, balancing the benefits of rapid improvement against the costs of effort, instability, or resource use. We introduce a normative framework that formalizes this problem as an optimal control process in which the agent maximizes cumulative performance while incurring a cost of learning. From this objective, we derive a closed-form solution for the optimal learning rate, which has the form of a closed-loop controller that depends only on the agent's current and expected future performance. Under mild assumptions, this solution generalizes across tasks and architectures and reproduces numerically optimized schedules in simulations. In simple learning models, we can mathematically analyze how agent and task parameters shape learning-rate scheduling as an open-loop control solution. Because the optimal policy depends on expectations of future performance, the framework predicts how overconfidence or underconfidence influence engagement and persistence, linking the control of learning speed to theories of self-regulated learning. We further show how a simple episodic memory mechanism can approximate the required performance expectations by recalling similar past learning experiences, providing a biologically plausible route to near-optimal behaviour. Together, these results provide a normative and biologically plausible account of learning speed control, linking self-regulated learning, effort allocation, and episodic memory estimation within a unified and tractable mathematical framework.

</details>
