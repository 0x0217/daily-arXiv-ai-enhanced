<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.LG](#cs.LG) [Total: 16]
- [cs.CR](#cs.CR) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models](https://arxiv.org/abs/2510.19176)
*Yuqiao Tan,Shizhu He,Kang Liu,Jun Zhao*

Main category: cs.AI

TL;DR: 이 논문은 Long-CoT와 Short-CoT 간의 자동 선택을 위한 Mode Selection과 반복적 추론 과정 중 최적의 중단점을 결정하는 Early Exit을 제안하여 계산 부담을 줄이는 방법을 다룬다.


<details>
  <summary>Details</summary>
Motivation: 추론 과정에서의 과도한 계산 부하를 줄이기 위해, 이 논문은 Mode Selection과 Early Exit의 필요성을 제시한다.

Method: Mode Selection은 Long-CoT와 Short-CoT 간의 선택을 자동으로 결정하며, Early Exit은 반복적 추론에서 최적의 중단점을 결정한다.

Result: 아홉 개의 기준 사례에 대한 실증 연구를 통해, 내부 정보를 활용하는 접근법이 더 나은 성능을 보이지만 여전히 안정성 문제를 드러낸다.

Conclusion: 정보가 제한된 상황에서 Mode Selection을 효과적으로 처리하기 위해 기존 방법들이 불충분하다는 사실이 확인되었다.

Abstract: Reasoning models have demonstrated exceptional performance in tasks such as
mathematics and logical reasoning, primarily due to their ability to engage in
step-by-step thinking during the reasoning process. However, this often leads
to overthinking, resulting in unnecessary computational overhead. To address
this issue, Mode Selection aims to automatically decide between Long-CoT
(Chain-of-Thought) or Short-CoT by utilizing either a Thinking or NoThinking
mode. Simultaneously, Early Exit determines the optimal stopping point during
the iterative reasoning process. Both methods seek to reduce the computational
burden. In this paper, we first identify Mode Selection as a more challenging
variant of the Early Exit problem, as they share similar objectives but differ
in decision timing. While Early Exit focuses on determining the best stopping
point for concise reasoning at inference time, Mode Selection must make this
decision at the beginning of the reasoning process, relying on pre-defined fake
thoughts without engaging in an explicit reasoning process, referred to as
zero-step thinking. Through empirical studies on nine baselines, we observe
that prompt-based approaches often fail due to their limited classification
capabilities when provided with minimal hand-crafted information. In contrast,
approaches that leverage internal information generally perform better across
most scenarios but still exhibit issues with stability. Our findings indicate
that existing methods relying solely on the information provided by models are
insufficient for effectively addressing Mode Selection in scenarios with
limited information, highlighting the ongoing challenges of this task. Our code
is available at https://github.com/Trae1ounG/Zero_Step_Thinking.

</details>


### [2] [WebGraphEval: Multi-Turn Trajectory Evaluation for Web Agents using Graph Representation](https://arxiv.org/abs/2510.19205)
*Yaoyao Qian,Yuanli Wang,Jinda Zhang,Yun Zong,Meixu Chen,Hanhan Zhou,Jindan Huang,Yifan Zeng,Xinyu Hu,Chan Hee Song,Danqing Zhang*

Main category: cs.AI

TL;DR: WebGraphEval 프레임워크는 여러 에이전트의 경로를 통합된 가중치 액션 그래프로 추상화하여 웹 에이전트 평가를 개선합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 웹 에이전트 평가는 이진 성공 지표에 국한되며, 벤치마크 데이터셋에 있는 구조적 다양성을 무시합니다.

Method: WebGraphEval이라는 프레임워크를 통해 여러 에이전트의 경로를 통합된 액션 그래프로 추상화합니다.

Result: 6개의 웹 에이전트에서 수천 개의 경로를 평가한 결과, 그래프 추상화가 모델 간 규칙성을 포착하고, 중복 및 비효율성을 강조하며, 성과 기반 지표로 간과된 중요한 결정 지점을 식별하는 것을 보여주었습니다.

Conclusion: 웹 상호작용을 그래프 구조의 데이터로 재구성함으로써, WebGraphEval은 웹 에이전트의 다중 경로, 교차 에이전트, 효율성 인지 평가를 위한 일반적인 방법론을 확립합니다.

Abstract: Current evaluation of web agents largely reduces to binary success metrics or
conformity to a single reference trajectory, ignoring the structural diversity
present in benchmark datasets. We present WebGraphEval, a framework that
abstracts trajectories from multiple agents into a unified, weighted action
graph. This representation is directly compatible with benchmarks such as
WebArena, leveraging leaderboard runs and newly collected trajectories without
modifying environments. The framework canonically encodes actions, merges
recurring behaviors, and applies structural analyses including reward
propagation and success-weighted edge statistics. Evaluations across thousands
of trajectories from six web agents show that the graph abstraction captures
cross-model regularities, highlights redundancy and inefficiency, and
identifies critical decision points overlooked by outcome-based metrics. By
framing web interaction as graph-structured data, WebGraphEval establishes a
general methodology for multi-path, cross-agent, and efficiency-aware
evaluation of web agents.

</details>


### [3] [Learning to Make Friends: Coaching LLM Agents toward Emergent Social Ties](https://arxiv.org/abs/2510.19299)
*Philipp J. Schneider,Lin Tian,Marian-Andrei Rizoiu*

Main category: cs.AI

TL;DR: 이 논문은 LLM 에이전트가 인간 온라인 행동의 복잡한 사회 동학을 재현할 수 있는지를 탐구하고, 이를 가능하게 하는 기억 및 학습 메커니즘에 대해 논의한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 에이전트가 인간의 온라인 행동에서 나타나는 복잡한 사회적 동향을 재현할 수 있는지 연구하고, 그런 동향이 어떻게 형성되는지를 알아보는 것.

Method: 에이전트들이 상호작용하고 평가하며 행동을 조정하는 다중 에이전트 LLM 시뮬레이션 프레임워크를 제시하고, 온라인 참여의 주요 동기를 반영한 보상 함수를 설계하여 사용한다.

Result: 코치 신호를 통해 LLM 에이전트가 안정적인 상호작용 패턴과 emergent 사회적 유대를 형성하며, 실제 온라인 커뮤니티의 특성을 반영하는 네트워크 구조를 생성함을 보여준다.

Conclusion: 행동 보상과 맥락 적응을 결합하여 집단 동학을 조사할 수 있는 원칙적인 시험대를 마련하고, 인공 에이전트가 인간과 유사한 사회 행동을 얼마나 근접하거나 다르게 이행하는지를 밝힌다.

Abstract: Can large language model (LLM) agents reproduce the complex social dynamics
that characterize human online behavior -- shaped by homophily, reciprocity,
and social validation -- and what memory and learning mechanisms enable such
dynamics to emerge? We present a multi-agent LLM simulation framework in which
agents repeatedly interact, evaluate one another, and adapt their behavior
through in-context learning accelerated by a coaching signal. To model human
social behavior, we design behavioral reward functions that capture core
drivers of online engagement, including social interaction, information
seeking, self-presentation, coordination, and emotional support. These rewards
align agent objectives with empirically observed user motivations, enabling the
study of how network structures and group formations emerge from individual
decision-making. Our experiments show that coached LLM agents develop stable
interaction patterns and form emergent social ties, yielding network structures
that mirror properties of real online communities. By combining behavioral
rewards with in-context adaptation, our framework establishes a principled
testbed for investigating collective dynamics in LLM populations and reveals
how artificial agents may approximate or diverge from human-like social
behavior.

</details>


### [4] [Continual Knowledge Adaptation for Reinforcement Learning](https://arxiv.org/abs/2510.19314)
*Jinwu Hu,Zihao Lian,Zhiquan Wen,Chenghao Li,Guohao Chen,Xutao Wen,Bin Xiao,Mingkui Tan*

Main category: cs.AI

TL;DR: CKA-RL은 강화 학습에서의 재난적 망각과 비효율적 지식 활용 문제를 해결하기 위해 과거의 지식을 효과적으로 축적하고 활용할 수 있는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 환경은 비정상적이기 때문에, 에이전트가 지속적으로 새로운 작업과 변화하는 조건에 적응해야 하는 필요성이 있다.

Method: CKA-RL은 작업별 지식 벡터 풀을 유지하고, 에이전트를 새로운 작업에 적응시키기 위해 동적으로 역사적 지식을 활용하는 지속적 지식 적응 전략을 도입한다.

Result: CKA-RL은 세 가지 벤치마크에서 최신 기술 수준의 방법들보다 4.20%의 전반적인 성능 향상과 8.02%의 순방향 전이 향상을 기록한다.

Conclusion: CKA-RL은 지식의 중요성을 유지하고 비효율적인 메모리 사용을 줄이는 적응형 지식 병합 메커니즘을 제공하여, 부정적인 효과를 줄인다.

Abstract: Reinforcement Learning enables agents to learn optimal behaviors through
interactions with environments. However, real-world environments are typically
non-stationary, requiring agents to continuously adapt to new tasks and
changing conditions. Although Continual Reinforcement Learning facilitates
learning across multiple tasks, existing methods often suffer from catastrophic
forgetting and inefficient knowledge utilization. To address these challenges,
we propose Continual Knowledge Adaptation for Reinforcement Learning (CKA-RL),
which enables the accumulation and effective utilization of historical
knowledge. Specifically, we introduce a Continual Knowledge Adaptation
strategy, which involves maintaining a task-specific knowledge vector pool and
dynamically using historical knowledge to adapt the agent to new tasks. This
process mitigates catastrophic forgetting and enables efficient knowledge
transfer across tasks by preserving and adapting critical model parameters.
Additionally, we propose an Adaptive Knowledge Merging mechanism that combines
similar knowledge vectors to address scalability challenges, reducing memory
requirements while ensuring the retention of essential knowledge. Experiments
on three benchmarks demonstrate that the proposed CKA-RL outperforms
state-of-the-art methods, achieving an improvement of 4.20% in overall
performance and 8.02% in forward transfer. The source code is available at
https://github.com/Fhujinwu/CKA-RL.

</details>


### [5] [HSCodeComp: A Realistic and Expert-level Benchmark for Deep Search Agents in Hierarchical Rule Application](https://arxiv.org/abs/2510.19631)
*Yiqian Yang,Tian Lan,Qianghuai Jia,Li Zhu,Hui Jiang,Hang Zhu,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.AI

TL;DR: 이 논문은 HSCodeComp라는 최초의 전문가 수준 전자상거래 벤치마크를 소개한다. 이 벤치마크는 복잡한 규칙 적용을 통해 깊은 검색 에이전트를 평가하는 데 사용되며, 결과는 현재의 LLM과 에이전트가 인간 전문가보다 성능이 크게 낮음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 현재의 에이전트 벤치마크는 에이전트가 복잡한 규칙을 적용하는 능력을 간과하고 있다.

Method: HSCodeComp 벤치마크는 제품의 10자리 조화 시스템 코드(HSCode)를 예측하기 위해 에이전트의 사고 과정을 이러한 규칙에 따라 유도한다.

Result: 현재의 LLM과 에이전트는 10자리 정확도가 46.8%에 불과하며, 이는 인간 전문가의 95.0% 정확도와 비교해 성능 차이가 크다.

Conclusion: 규칙 계층 적용의 어려움이 있으며, 테스트 시 성능 향상이 이루어지지 않는다.

Abstract: Effective deep search agents must not only access open-domain and
domain-specific knowledge but also apply complex rules-such as legal clauses,
medical manuals and tariff rules. These rules often feature vague boundaries
and implicit logic relationships, making precise application challenging for
agents. However, this critical capability is largely overlooked by current
agent benchmarks.
  To fill this gap, we introduce HSCodeComp, the first realistic, expert-level
e-commerce benchmark designed to evaluate deep search agents in hierarchical
rule application. In this task, the deep reasoning process of agents is guided
by these rules to predict 10-digit Harmonized System Code (HSCode) of products
with noisy but realistic descriptions. These codes, established by the World
Customs Organization, are vital for global supply chain efficiency. Built from
real-world data collected from large-scale e-commerce platforms, our proposed
HSCodeComp comprises 632 product entries spanning diverse product categories,
with these HSCodes annotated by several human experts.
  Extensive experimental results on several state-of-the-art LLMs, open-source,
and closed-source agents reveal a huge performance gap: best agent achieves
only 46.8% 10-digit accuracy, far below human experts at 95.0%. Besides,
detailed analysis demonstrates the challenges of hierarchical rule application,
and test-time scaling fails to improve performance further.

</details>


### [6] [MSC-Bench: A Rigorous Benchmark for Multi-Server Tool Orchestration](https://arxiv.org/abs/2510.19423)
*Jia-Kai Dong,I-Wei Huang,Chun-Tin Wu,Yi-Tien Tsai*

Main category: cs.AI

TL;DR: MSC-Bench는 LLM 에이전트를 위한 다단계 도구 조정 평가를 위한 대규모 벤치마크입니다.


<details>
  <summary>Details</summary>
Motivation: 기존 벤치마크는 도구들의 기능적 중복 및 서버 간 조정의 문제를 무시하여 낙관적인 평가를 초래합니다.

Method: '동등 함수 집합'을 통해 사실 기반을 구축하고 F1 점수와 같은 객관적인 메트릭을 사용하여 평가합니다. 5단계 커리큘럼으로 에이전트의 능력을 체계적으로 테스트합니다.

Result: 경직된 계층 구조가 성능을 저해할 수 있으며, 최신 에이전트조차도 Robustness에서 시스템적 약점을 보입니다.

Conclusion: MSC-Bench는 이러한 한계를 드러내고 더 강력하고 효율적인 도구 사용 에이전트의 개발을 안내하는 진단 프레임워크를 제공합니다.

Abstract: We introduce MSC-Bench, a large-scale benchmark for evaluating multi-hop,
end-to-end tool orchestration by LLM agents in a hierarchical Model-Context
Protocol (MCP) ecosystem. Existing benchmarks often evaluate tools in
isolation, ignoring challenges such as functional overlap and cross-server
orchestration, leading to overly optimistic assessments. MSC-Bench addresses
these gaps by constructing ground truth through 'equal function sets', allowing
objective metrics such as F1 score and reducing the dependency on
LLM-as-a-judge evaluation. Organized as a five-level curriculum, it
systematically tests agent capabilities from single-tool orchestration to
complex cross-server planning, and robustness to out-of-scope requests.
Experiments reveal that rigid hierarchies can hinder performance without
co-designed strategies, and even state-of-the-art agents exhibit systemic
weaknesses in robustness. MSC-Bench provides a diagnostic framework to expose
these limitations and guide the development of more capable and efficient
tool-using agents. The benchmark and resources are publicly available at
https://github.com/snooow1029/MSC_Bench.

</details>


### [7] [NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning](https://arxiv.org/abs/2510.19429)
*Wonje Choi,Jooyoung Kim,Honguk Woo*

Main category: cs.AI

TL;DR: 이 논문에서는 동적 환경에서 임베디드 작업을 위한 언어 모델 채택의 과제를 다루며, NeSyPr이라는 새로운 임베디드 추론 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 동적 환경에서 대규모 추론 엔진 또는 상징적 계획자에 대한 온라인 액세스가 지연 및 자원 제약으로 인해 제한되는 문제를 해결하고자 한다.

Method: NeSyPr는 신경 기호 절차화(neurosymbolic proceduralization)를 통해 지식을 컴파일하고, 언어 모델 기반 에이전트에 구조적이고 적응적이며 시기적절한 추론 기능을 제공합니다.

Result: NeSyPr는 PDDLGym, VirtualHome, ALFWorld와 같은 임베디드 벤치마크에서 평가되어 대규모 추론 모델 및 심볼릭 플래너에 비해 효율적인 추론 능력을 입증합니다.

Conclusion: 이 프레임워크는 대기 시간이 민감하고 자원이 제한된 물리적 시스템에 배치하기에 적합하다.

Abstract: We address the challenge of adopting language models (LMs) for embodied tasks
in dynamic environments, where online access to large-scale inference engines
or symbolic planners is constrained due to latency, connectivity, and resource
limitations. To this end, we present NeSyPr, a novel embodied reasoning
framework that compiles knowledge via neurosymbolic proceduralization, thereby
equipping LM-based agents with structured, adaptive, and timely reasoning
capabilities. In NeSyPr, task-specific plans are first explicitly generated by
a symbolic tool leveraging its declarative knowledge. These plans are then
transformed into composable procedural representations that encode the plans'
implicit production rules, enabling the resulting composed procedures to be
seamlessly integrated into the LM's inference process. This neurosymbolic
proceduralization abstracts and generalizes multi-step symbolic structured
path-finding and reasoning into single-step LM inference, akin to human
knowledge compilation. It supports efficient test-time inference without
relying on external symbolic guidance, making it well suited for deployment in
latency-sensitive and resource-constrained physical systems. We evaluate NeSyPr
on the embodied benchmarks PDDLGym, VirtualHome, and ALFWorld, demonstrating
its efficient reasoning capabilities over large-scale reasoning models and a
symbolic planner, while using more compact LMs.

</details>


### [8] [DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement Learning](https://arxiv.org/abs/2510.19562)
*Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU*

Main category: cs.AI

TL;DR: DAIL이라는 새로운 방법을 통해 자연어 이해 및 인간 지시 수행 시 발생하는 모호성을 해결하고 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 자연어 이해와 인간의 지시를 따르는 능력은 지능형 에이전트에 필수적이지만, 언어 지시의 유연성으로 인해 과제 간의 모호성이 증가하여 알고리즘 성능이 저하된다.

Method: DAIL(Distributional Aligned Learning)이라는 새로운 방법을 소개하며, 두 가지 주요 구성 요소인 분포 정책과 의미 정렬을 특징으로 한다.

Result: 구조화된 관찰과 시각적 관찰 기준에서 DAIL이 지시의 모호성을 효과적으로 해결하고 기본 방법보다 우수한 성능을 달성한다는 실험 결과를 제시한다.

Conclusion: DAIL은 새로운 접근 방식을 통해 자연어 지정 문제를 해결하며, 구현 코드는 GitHub에 공개되어 있다.

Abstract: Comprehending natural language and following human instructions are critical
capabilities for intelligent agents. However, the flexibility of linguistic
instructions induces substantial ambiguity across language-conditioned tasks,
severely degrading algorithmic performance. To address these limitations, we
present a novel method named DAIL (Distributional Aligned Learning), featuring
two key components: distributional policy and semantic alignment. Specifically,
we provide theoretical results that the value distribution estimation mechanism
enhances task differentiability. Meanwhile, the semantic alignment module
captures the correspondence between trajectories and linguistic instructions.
Extensive experimental results on both structured and visual observation
benchmarks demonstrate that DAIL effectively resolves instruction ambiguities,
achieving superior performance to baseline methods. Our implementation is
available at https://github.com/RunpengXie/Distributional-Aligned-Learning.

</details>


### [9] [AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory Urban Sensing](https://arxiv.org/abs/2510.19661)
*Xusen Guo,Mingxing Peng,Xixuan Hao,Xingchen Zou,Qiongyan Wang,Sijie Ruan,Yuxuan Liang*

Main category: cs.AI

TL;DR: AgentSense는 다중 에이전트 진화 시스템을 통해 참여형 도시 감지에 대규모 언어 모델을 통합한 하이브리드 프레임워크로서, 기존 방법보다 적응성과 설명 가능성에서 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 현대 도시 관리에서 참여형 도시 감지가 중요하지만, 기존 시스템은 다양한 도시 시나리오에 대한 일반화와 의사 결정에서 해석 가능성의 한계를 가지고 있다.

Method: AgentSense는 고전적인 계획 기술을 사용하여 기준 솔루션을 생성하고, 이를 민감한 도시 조건과 이질적인 작업자의 선호에 적응하도록 반복적으로 refinements하며 자연어 설명을 생성한다.

Result: 두 개의 대규모 이동성 데이터셋과 일곱 가지 유형의 동적 방해에 대한 광범위한 실험 결과, AgentSense는 기존 방법보다 적응성과 설명 가능성에서 뚜렷한 이점을 제공하며, 단일 에이전트 LLM 기준보다 성능과 강건성에서 우수한 성과를 거두었다.

Conclusion: 이 결과는 AgentSense가 웹에서 적응 가능하고 설명 가능한 도시 감지 시스템을 배포하는 데 중요한 발전을 이룬 것을 보여준다.

Abstract: Web-based participatory urban sensing has emerged as a vital approach for
modern urban management by leveraging mobile individuals as distributed
sensors. However, existing urban sensing systems struggle with limited
generalization across diverse urban scenarios and poor interpretability in
decision-making. In this work, we introduce AgentSense, a hybrid, training-free
framework that integrates large language models (LLMs) into participatory urban
sensing through a multi-agent evolution system. AgentSense initially employs
classical planner to generate baseline solutions and then iteratively refines
them to adapt sensing task assignments to dynamic urban conditions and
heterogeneous worker preferences, while producing natural language explanations
that enhance transparency and trust. Extensive experiments across two
large-scale mobility datasets and seven types of dynamic disturbances
demonstrate that AgentSense offers distinct advantages in adaptivity and
explainability over traditional methods. Furthermore, compared to single-agent
LLM baselines, our approach outperforms in both performance and robustness,
while delivering more reasonable and transparent explanations. These results
position AgentSense as a significant advancement towards deploying adaptive and
explainable urban sensing systems on the web.

</details>


### [10] [Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning](https://arxiv.org/abs/2510.19732)
*Gunshi Gupta,Karmesh Yadav,Zsolt Kira,Yarin Gal,Rahaf Aljundi*

Main category: cs.AI

TL;DR: 이 논문에서는 공간적 결정을 위한 메모리 집중적인 RL 작업에서 효과적으로 작동하는 Memo라는 변환기 기반 아키텍처를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 구체적인 환경에서 맥락을 유지하기 위해 에이전트가 메모리를 형성하고 접근할 수 있는 모델을 개발하는 것이 중요하다.

Method: Memo는 훈련 중 모델 입력에 주기적인 요약 토큰을 겹쳐 메모리의 생성과 검색을 통합한 변환기 기반 아키텍처와 훈련 방법이다.

Result: Memo는 그리드월드 메타 RL 벤치마크와 실사적인 실내 환경에서 다중 객체 탐색 작업에서 효과성을 입증하였다.

Conclusion: Memo는 기본적인 긴 맥락 변환기보다 더 나은 성능을 보이며, 더 나은 컴퓨팅 및 저장 효율성을 유지하고, 추론 시간에는 긴 맥락에 대한 일반화가 더 뛰어나다.

Abstract: To enable embodied agents to operate effectively over extended timeframes, it
is crucial to develop models that form and access memories to stay
contextualized in their environment. In the current paradigm of training
transformer-based policies for embodied sequential decision-making tasks,
visual inputs often overwhelm the context limits of transformers, while humans
can maintain and utilize a lifetime of experience compressed as memories.
Significant compression is possible in principle, as much of the input is
irrelevant and can be abstracted. However, existing approaches predominantly
focus on either recurrent models with fixed-size memory or transformers with
full-context reliance. In this work, we propose Memo, a transformer-based
architecture and training recipe for reinforcement learning (RL) on
memory-intensive, long-horizon tasks. Memo incorporates the creation and
retrieval of memory by interleaving periodic summarization tokens with the
inputs of a model during training. We demonstrate Memo's effectiveness on a
gridworld meta-RL benchmark and a multi-object navigation task in
photo-realistic indoor settings. Memo outperforms naive long-context
transformer baselines while being more compute and storage efficient.
Additionally, Memo generalizes better to longer contexts at inference time and
remains robust in streaming settings, where historical context must be
truncated to fit inference constraints.

</details>


### [11] [Misalignment Bounty: Crowdsourcing AI Agent Misbehavior](https://arxiv.org/abs/2510.19738)
*Rustem Turtayev,Natalia Fedorova,Oleg Serikov,Sergey Koldyba,Lev Avagyan,Dmitrii Volkov*

Main category: cs.AI

TL;DR: 고급 AI 시스템이 인간의 의도와 다르게 행동하는 사례를 수집한 미사일라인먼트 바운티 프로젝트에 대한 보고서이다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 인간의 의도와 다르게 행동할 수 있는 사례를 명확하고 재현 가능하게 수집하기 위해 이 프로그램을 시작했다.

Method: 군중 소싱 프로젝트를 통해 의도하지 않은 목표나 안전하지 않은 목표를 추구하는 사례를 수집했다.

Result: 295건의 제출물이 있었고, 그 중 9건이 선정되어 상을 받았다.

Conclusion: 보고서는 프로그램의 동기와 평가 기준을 설명하고, 선정된 9건의 사례를 단계별로 소개한다.

Abstract: Advanced AI systems sometimes act in ways that differ from human intent. To
gather clear, reproducible examples, we ran the Misalignment Bounty: a
crowdsourced project that collected cases of agents pursuing unintended or
unsafe goals. The bounty received 295 submissions, of which nine were awarded.
  This report explains the program's motivation and evaluation criteria, and
walks through the nine winning submissions step by step.

</details>


### [12] [Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents](https://arxiv.org/abs/2510.19771)
*Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis*

Main category: cs.AI

TL;DR: LLM 기반 에이전트가 사용자 요구를 능동적으로 예측하고 해결하도록 발전하고 있으나, 이러한 능동성을 평가하는 것은 도전적이다. 본 논문에서는 PROBE라는 새로운 프레임워크를 도입하여 능동성을 세 가지 주요 능력으로 분해하고, 이것이 현재의 LLM 모델들이 이 벤치마크를 해결하는 데苦함을 드러내는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 에이전트의 능동적 문제 해결 능력을 평가하기 위해 새로운 벤치마크가 필요하다.

Method: PROBE는 능동성을 세 가지 핵심 능력 (불명확한 문제 검색, 특정 병목 식별, 적절한 해결 실행)으로 분해하여 평가를 수행한다.

Result: 최신 LLMs와 인기 있는 에이전트 프레임워크를 평가한 결과, GPT-5와 Claude Opus-4.1이 40%라는 최상의 성능을 달성했지만, 여전히 이 벤치마크를 해결하는 데 어려움을 겪고 있다.

Conclusion: 현재의 에이전트 시스템에서 자율 행동의 한계를 강조하고, 향후 연구 방향에 대한 가능성을 제시한다.

Abstract: LLM-based agents are increasingly moving towards proactivity: rather than
awaiting instruction, they exercise agency to anticipate user needs and solve
them autonomously. However, evaluating proactivity is challenging; current
benchmarks are constrained to localized context, limiting their ability to test
reasoning across sources and longer time horizons. To address this gap, we
present PROBE (Proactive Resolution Of BottlEnecks). PROBE decomposes
proactivity as a pipeline of three core capabilities: (1) searching for
unspecified issues, (2) identifying specific bottlenecks, and (3) executing
appropriate resolutions. We apply PROBE to evaluate leading LLMs and popular
agentic frameworks, showing that even state-of-the-art models struggle to solve
this benchmark. Computing our consistent measurements across frontier LLMs and
agents, we find that the best end-to-end performance of 40% is achieved by both
GPT-5 and Claude Opus-4.1. Additionally, we demonstrate the relative
capabilities of each model and analyze mutual failure modes. Our results
highlight the current limitations of autonomous action in agentic systems, and
expose promising future research directions.

</details>


### [13] [Benchmarking World-Model Learning](https://arxiv.org/abs/2510.19788)
*Archana Warrier,Dat Nguyen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares*

Main category: cs.AI

TL;DR: 모델 학습 에이전트는 여러 다운스트림 작업을 지원하기 위해 세계 모델을 학습하는 정보를 수집해야 하며, 이를 평가하기 위한 새로운 프로토콜인 WorldTest를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 모델 학습 에이전트가 적절한 세계 모델을 학습하고 평가할 수 있는 방법론의 필요성.

Method: WorldTest 프로토콜을 통해 보상 없는 상호작용과 검증 단계에서의 테스트를 분리하여 다양한 환경에서 모델 학습 에이전트를 평가한다.

Result: 517명의 인간 참가자와 3개의 최전선 모델을 비교한 결과, 인간이 모델을 능가했으며, 컴퓨팅 자원 증가가 일부 환경에서만 성능을 개선했다.

Conclusion: WorldTest는 에이전트가 환경 역학에 대해 학습한 내용을 평가할 수 있는 새로운 템플릿을 제공하며, AutumnBench는 세계 모델 학습에서 상당한 향상이 가능함을 보여준다.

Abstract: Model-learning agents should gather information to learn world models that
support many downstream tasks and inferences, such as predicting unobserved
states, estimating near- and far-term consequences of actions, planning action
sequences, and detecting changes in dynamics. Current methods for learning and
evaluating world models diverge from this goal: training and evaluation are
anchored to next-frame prediction, and success is scored by reward maximization
in the same environment. We propose WorldTest, a protocol to evaluate
model-learning agents that separates reward-free interaction from a scored test
phase in a different but related environment. WorldTest is
open-ended$\unicode{x2014}$models should support many different tasks unknown
ahead of time$\unicode{x2014}$and agnostic to model representation, allowing
comparison across approaches. We instantiated WorldTest with AutumnBench, a
suite of 43 interactive grid-world environments and 129 tasks across three
families: masked-frame prediction, planning, and predicting changes to the
causal dynamics. We compared 517 human participants and three frontier models
on AutumnBench. We found that humans outperform the models, and scaling compute
improves performance only in some environments but not others. WorldTest
provides a novel template$\unicode{x2014}$reward-free exploration, derived
tests, and behavior-based scoring$\unicode{x2014}$to evaluate what agents learn
about environment dynamics, and AutumnBench exposes significant headroom in
world-model learning.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [14] [Local Guidance for Configuration-Based Multi-Agent Pathfinding](https://arxiv.org/abs/2510.19072)
*Tomoki Arita,Keisuke Okumura*

Main category: cs.MA

TL;DR: 이 연구는 다수의 에이전트를 위한 경로 탐색에서 지역적 안내 접근 방식을 탐구하고, 이를 통해 해법의 질을 개선함과 동시에 시간 예산을 초과하지 않음을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 다수의 에이전트를 위한 경로 탐색(MAPF) 방법의 성능을 개선하기 위해 안내라는 개념을 탐구한다.

Method: 에이전트 주변의 지역적 안내를 제공하는 방법을 제시하고, 이를 통해 정보적인 시공간 단서를 계획자에게 전달한다.

Result: LaCAM이라는 선도적인 구성 기반 솔버에 적용했을 때, 이 형태의 안내가 MAPF의 성능 경계를 새롭게 설정한다.

Conclusion: 지역적 안내가 에이전트의 대기 시간을 줄이고 전반적인 조정 효율성을 개선하는 데 기여할 수 있음을 입증하였다.

Abstract: Guidance is an emerging concept that improves the empirical performance of
real-time, sub-optimal multi-agent pathfinding (MAPF) methods. It offers
additional information to MAPF algorithms to mitigate congestion on a global
scale by considering the collective behavior of all agents across the entire
workspace. This global perspective helps reduce agents' waiting times, thereby
improving overall coordination efficiency. In contrast, this study explores an
alternative approach: providing local guidance in the vicinity of each agent.
While such localized methods involve recomputation as agents move and may
appear computationally demanding, we empirically demonstrate that supplying
informative spatiotemporal cues to the planner can significantly improve
solution quality without exceeding a moderate time budget. When applied to
LaCAM, a leading configuration-based solver, this form of guidance establishes
a new performance frontier for MAPF.

</details>


### [15] [SORA-ATMAS: Adaptive Trust Management and Multi-LLM Aligned Governance for Future Smart Cities](https://arxiv.org/abs/2510.19327)
*Usama Antuley,Shahbaz Siddiqui,Sufian Hameed,Waqas Arif,Subhan Shah,Syed Attique Shah*

Main category: cs.MA

TL;DR: 스마트 시티의 빠른 발전이 인프라와 시민의 복지를 최적화하기 위해 상호 연결된 서비스에 대한 의존성을 증가시켰다. Agentic AI는 자율적인 의사결정과 적응형 조정을 지원함으로써 실시간으로 동적 조건에 반응하도록 도시 시스템을 도와준다. 하지만 이 기술의 배치는 거버넌스, 리스크, 규정 준수와 같은 주요 도전을 제기한다. 본 연구는 SORA-ATMAS의 효과를 입증하고, 안전한 상호 운영성을 보장하며, 스마트 시티 관리를 위한 강건한 기반을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 스마트 시티의 발전에 따른 인프라 및 시민 복지 최적화 필요성 증가.

Method: SORA-ATMAS를 통해 세 가지 도메인 에이전트(날씨, 교통, 안전)를 평가하여, 정책 조정된 출력을 생성시키기 위한 거버넌스 정책을 구현.

Result: 다양한 LLM에게 35%의 MAE 감소를 나타내며, 고위험 시나리오에서의 조정 신뢰도 측정과 안정적인 날씨 모니터링을 나타냄.

Conclusion: SORA-ATMAS는 규제에 맞는, 맥락을 인식하는 검증 가능한 거버넌스 프레임워크로, 분산된 에이전트 출력들을 책임감 있는 실시간 결정으로 통합하는 강건한 기반을 제공한다.

Abstract: The rapid evolution of smart cities has increased the reliance on intelligent
interconnected services to optimize infrastructure, resources, and citizen
well-being. Agentic AI has emerged as a key enabler by supporting autonomous
decision-making and adaptive coordination, allowing urban systems to respond in
real time to dynamic conditions. Its benefits are evident in areas such as
transportation, where the integration of traffic data, weather forecasts, and
safety sensors enables dynamic rerouting and a faster response to hazards.
However, its deployment across heterogeneous smart city ecosystems raises
critical governance, risk, and compliance (GRC) challenges, including
accountability, data privacy, and regulatory alignment within decentralized
infrastructures. Evaluation of SORA-ATMAS with three domain agents (Weather,
Traffic, and Safety) demonstrated that its governance policies, including a
fallback mechanism for high-risk scenarios, effectively steer multiple LLMs
(GPT, Grok, DeepSeek) towards domain-optimized, policy-aligned outputs,
producing an average MAE reduction of 35% across agents. Results showed stable
weather monitoring, effective handling of high-risk traffic plateaus 0.85, and
adaptive trust regulation in Safety/Fire scenarios 0.65. Runtime profiling of a
3-agent deployment confirmed scalability, with throughput between 13.8-17.2
requests per second, execution times below 72~ms, and governance delays under
100 ms, analytical projections suggest maintained performance at larger scales.
Cross-domain rules ensured safe interoperability, with traffic rerouting
permitted only under validated weather conditions. These findings validate
SORA-ATMAS as a regulation-aligned, context-aware, and verifiable governance
framework that consolidates distributed agent outputs into accountable,
real-time decisions, offering a resilient foundation for smart-city management.

</details>


### [16] [ColorAgent: Building A Robust, Personalized, and Interactive OS Agent](https://arxiv.org/abs/2510.19386)
*Ning Li,Qiqiang Lin,Zheng Wu,Xiaoyun Mo,Weiming Zhang,Yin Zhao,Xiangmou Qu,Jiamu Zhou,Jun Wang,Congmin Zheng,Yuanyi Song,Hongjiang Chen,Heyuan Huang,Jihong Wang,Jiaxin Yin,Jingwei Yu,Junwei Liao,Qiuying Peng,Xingyu Lou,Jun Wang,Weiwen Liu,Zhuosheng Zhang,Weinan Zhang*

Main category: cs.MA

TL;DR: ColorAgent는 사용자 지시를 실행하고 사용자의 요구를 충족하는 운영 체제 에이전트로, 장기적인 상호작용과 개인화된 사용자 상호작용을 지원합니다.


<details>
  <summary>Details</summary>
Motivation: 운영 체제 에이전트가 사용자 지시를 수행하고 신뢰성 있게 사용자 요구를 따르는 것이 현실이 되고 있습니다.

Method: 단계별 강화 학습과 자기 진화 학습으로 모델의 능력을 향상시키고, 일반성과 일관성, 견고성을 보장하는 맞춤형 다중 에이전트 프레임워크를 개발했습니다.

Result: ColorAgent는 AndroidWorld 및 AndroidLab 벤치마크에서 각각 77.2% 및 50.7%의 성공률을 달성하며 새로운 성과를 기록하였습니다.

Conclusion: 현재 벤치마크는 운영 체제 에이전트의 포괄적인 평가를 위한 충분한 기준이 아니므로, 평가 패러다임, 에이전트 협업, 보안 분야에서 향후 연구 방향을 탐구할 것을 제안합니다.

Abstract: With the advancements in hardware, software, and large language model
technologies, the interaction between humans and operating systems has evolved
from the command-line interface to the rapidly emerging AI agent interactions.
Building an operating system (OS) agent capable of executing user instructions
and faithfully following user desires is becoming a reality. In this technical
report, we present ColorAgent, an OS agent designed to engage in long-horizon,
robust interactions with the environment while also enabling personalized and
proactive user interaction. To enable long-horizon interactions with the
environment, we enhance the model's capabilities through step-wise
reinforcement learning and self-evolving training, while also developing a
tailored multi-agent framework that ensures generality, consistency, and
robustness. In terms of user interaction, we explore personalized user intent
recognition and proactive engagement, positioning the OS agent not merely as an
automation tool but as a warm, collaborative partner. We evaluate ColorAgent on
the AndroidWorld and AndroidLab benchmarks, achieving success rates of 77.2%
and 50.7%, respectively, establishing a new state of the art. Nonetheless, we
note that current benchmarks are insufficient for a comprehensive evaluation of
OS agents and propose further exploring directions in future work, particularly
in the areas of evaluation paradigms, agent collaboration, and security. Our
code is available at https://github.com/MadeAgents/mobile-use.

</details>


### [17] [Modeling realistic human behavior using generative agents in a multimodal transport system: Software architecture and Application to Toulouse](https://arxiv.org/abs/2510.19497)
*Trung-Dung Vu,Benoit Gaudou,Kamaldeep Singh Oberoi*

Main category: cs.MA

TL;DR: 이 논문은 복잡한 다중모드 교통 시스템에서 현실적인 인간 이동 행동을 모델링하기 위한 아키텍처를 제시한다. 프랑스 툴루즈의 사례를 통해, 대형 언어 모델(LLM)을 이용한 에이전트 기반 시뮬레이션을 적용하여 도시 환경에서의 의사 결정을 포착한다.


<details>
  <summary>Details</summary>
Motivation: 현실적인 인간 행동을 모델링하여 개인화된 이동 해결책을 제안하는 것은 여전히 도전적이다.

Method: GAMA 시뮬레이션 플랫폼과 LLM 기반 생성 에이전트를 통합하고, 공공 교통을 위한 GTFS 데이터와 다중 모드 라우팅을 위한 OpenTripPlanner를 활용한다.

Result: 시뮬레이션 한 달 동안 에이전트는 맥락 인식적인 교통 결정을 내릴 뿐만 아니라 시간이 지남에 따라 습관을 형성한다.

Conclusion: LLM과 에이전트 기반 시뮬레이션의 결합은 지능형 교통 시스템과 개인화된 다중모드 이동 해결책을 발전시키기 위한 유망한 방향을 제시한다.

Abstract: Modeling realistic human behaviour to understand people's mode choices in
order to propose personalised mobility solutions remains challenging. This
paper presents an architecture for modeling realistic human mobility behavior
in complex multimodal transport systems, demonstrated through a case study in
Toulouse, France. We apply Large Language Models (LLMs) within an agent-based
simulation to capture decision-making in a real urban setting. The framework
integrates the GAMA simulation platform with an LLM-based generative agent,
along with General Transit Feed Specification (GTFS) data for public transport,
and OpenTripPlanner for multimodal routing. GAMA platform models the
interactive transport environment, providing visualization and dynamic agent
interactions while eliminating the need to construct the simulation environment
from scratch. This design enables a stronger focus on developing generative
agents and evaluating their performance in transport decision-making processes.
Over a simulated month, results show that agents not only make context-aware
transport decisions but also form habits over time. We conclude that combining
LLMs with agent-based simulation offers a promising direction for advancing
intelligent transportation systems and personalised multimodal mobility
solutions. We also discuss some limitations of this approach and outline future
work on scaling to larger regions, integrating real-time data, and refining
memory models.

</details>


### [18] [Polynomial-time Configuration Generator for Connected Unlabeled Multi-Agent Pathfinding](https://arxiv.org/abs/2510.19567)
*Takahiro Suzuki,Keisuke Okumura*

Main category: cs.MA

TL;DR: CUMAPF 문제를 해결하기 위해 PULL이라는 완전하고 다항 시간 알고리즘을 제안한다.


<details>
  <summary>Details</summary>
Motivation: CUMAPF는 에이전트 간의 연결성을 항상 유지해야 하는 문제로, 자율 재구성 및 행진과 같은 집단 로봇 응용 프로그램에 필수적이다.

Method: PULL 알고리즘은 연결성을 유지하고 목표 구성으로 나아가는 후속 구성을 계산하는 규칙 기반의 일단계 함수를 기반으로 한다.

Result: PULL은 수백 개의 에이전트에 대한 무작위로 생성된 인스턴스에서 트리비얼 솔루션에 비해 경쟁력 있는 솔루션 품질을 찾는다.

Conclusion: PULL을 기존의 검색 기반 MAPF 알고리즘에 통합하여 소규모 인스턴스를 위한 유용한 도구를 제공하는 궁극적인 최적 해결기를 개발하였다.

Abstract: We consider Connected Unlabeled Multi-Agent Pathfinding (CUMAPF), a variant
of MAPF where the agents must maintain connectivity at all times. This problem
is fundamental to swarm robotics applications like self-reconfiguration and
marching, where standard MAPF is insufficient as it does not guarantee the
required connectivity between agents. While unlabeled MAPF is tractable in
optimization, CUMAPF is NP-hard even on highly restricted graph classes. To
tackle this challenge, we propose PULL, a complete and polynomial-time
algorithm with a simple design. It is based on a rule-based one-step function
that computes a subsequent configuration that preserves connectivity and
advances towards the target configuration. PULL is lightweight, and runs in
$O(n^2)$ time per step in 2D grid, where $n$ is the number of agents. Our
experiments further demonstrate its practical performance: PULL finds
competitive solution qualities against trivial solutions for hundreds of
agents, in randomly generated instances. Furthermore, we develop an eventually
optimal solver that integrates PULL into an existing search-based MAPF
algorithm, providing a valuable tool for small-scale instances.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [19] [Large Connectome Model: An fMRI Foundation Model of Brain Connectomes Empowered by Brain-Environment Interaction in Multitask Learning Landscape](https://arxiv.org/abs/2510.18910)
*Ziquan Wei,Tingting Dan,Guorong Wu*

Main category: cs.LG

TL;DR: 기능적 신경 이미지를 위한 신뢰할 수 있는 기초 모델은 임상 응용을 촉진하는 데 중요하며, 본 논문에서는 다중 작업 학습을 기반으로 한 확장 가능한 모델 아키텍처를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 현재 AI 모델의 성능이 제한된 표본 크기로 인해 크게 저해되고 있어, 기능적 신경 이미지를 위한 신뢰할 수 있는 기초 모델이 필요하다.

Method: 다양한 환경 변수와 인구통계학적 데이터를 활용하여 다중 작업 학습으로 뇌 모델링을 수행하고, 여러 뇌-환경 상호작용(BEI)을 토큰화하여 다중 작업 사전 학습과 사전 학습된 BEI의 유사 레이블을 할당하여 반감독 세부 조정을 구현한다.

Result: 우리 모델을 성별 예측, 인간 행동 인식, 자폐증, 파킨슨병, 알츠하이머병 및 정신분열증의 조기 진단 등 다양한 응용 프로그램에 평가한 결과, 유망한 결과가 나타났다.

Conclusion: 현재의 신경 이미징 응용 프로그램을 임상 루틴에서 촉진할 수 있는 큰 잠재력을 보여준다.

Abstract: A reliable foundation model of functional neuroimages is critical to promote
clinical applications where the performance of current AI models is
significantly impeded by a limited sample size. To that end, tremendous efforts
have been made to pretraining large models on extensive unlabeled fMRI data
using scalable self-supervised learning. Since self-supervision is not
necessarily aligned with the brain-to-outcome relationship, most foundation
models are suboptimal to the downstream task, such as predicting disease
outcomes. By capitalizing on rich environmental variables and demographic data
along with an unprecedented amount of functional neuroimages, we form the brain
modeling as a multitask learning and present a scalable model architecture for
(i) multitask pretraining by tokenizing multiple brain-environment interactions
(BEI) and (ii) semi-supervised finetuning by assigning pseudo-labels of
pretrained BEI. We have evaluated our foundation model on a variety of
applications, including sex prediction, human behavior recognition, and disease
early diagnosis of Autism, Parkinson's disease, Alzheimer's disease, and
{Schizophrenia}, where promising results indicate the great potential to
facilitate current neuroimaging applications in clinical routines.

</details>


### [20] [Benchmarking On-Device Machine Learning on Apple Silicon with MLX](https://arxiv.org/abs/2510.18921)
*Oluwaseun A. Ajayi,Ogundepo Odunayo*

Main category: cs.LG

TL;DR: MLX 프레임워크는 Apple 실리콘 장치에서의 머신 러닝 연산을 최적화하여 연구 및 프로토타이핑을 용이하게 하며, 다양한 트랜스포머 아키텍처의 추론 지연 시간을 평가한 연구이다.


<details>
  <summary>Details</summary>
Motivation: LLM 및 머신 러닝의 최근 광범위한 채택으로 인해 작은 장치에서 이러한 모델을 배포할 가능성을 탐구하려는 연구 관심이 높아지고 있어, 온디바이스 하드웨어를 활용하는 프레임워크의 필요성이 대두되었다.

Method: MLX 프레임워크를 통해 서로 다른 트랜스포머 아키텍처 구현의 성능을 Pytorch와 비교하며, 모델 체크포인트를 다운로드하고 MLX 형식으로 변환하는 MLX-transformers 프레임워크를 제작하였다.

Result: BERT, RoBERTa, XLM-RoBERTa 모델을 포함한 다양한 트랜스포머 모델을 평가하였으며, 결과는 Apple 생태계 내에서 효율적이고 보다 접근 가능한 온디바이스 ML 애플리케이션을 가능하게 하는 MLX의 잠재력을 강조하였다.

Conclusion: MLX는 Apple 실리콘 장치에서 실행되는 트랜스포머 모델을 지원하며, 프레임워크 간 모델 이식에 필요한 체크포인트 변환을 없애고 더 나은 성능을 제공한다.

Abstract: The recent widespread adoption of Large Language Models (LLMs) and machine
learning in general has sparked research interest in exploring the
possibilities of deploying these models on smaller devices such as laptops and
mobile phones. This creates a need for frameworks and approaches that are
capable of taking advantage of on-device hardware. The MLX framework was
created to address this need. It is a framework optimized for machine learning
(ML) computations on Apple silicon devices, facilitating easier research,
experimentation, and prototyping.
  This paper presents a performance evaluation of MLX, focusing on inference
latency of transformer models. We compare the performance of different
transformer architecture implementations in MLX with their Pytorch
counterparts. For this research we create a framework called MLX-transformers
which includes different transformer implementations in MLX and downloads the
model checkpoints in pytorch and converts it to the MLX format. By leveraging
the advanced architecture and capabilities of Apple Silicon, MLX-Transformers
enables seamless execution of transformer models directly sourced from Hugging
Face, eliminating the need for checkpoint conversion often required when
porting models between frameworks.
  Our study benchmarks different transformer models on two Apple Silicon
macbook devices against an NVIDIA CUDA GPU. Specifically, we compare the
inference latency performance of models with the same parameter sizes and
checkpoints. We evaluate the performance of BERT, RoBERTa, and XLM-RoBERTa
models, with the intention of extending future work to include models of
different modalities, thus providing a more comprehensive assessment of MLX's
capabilities. The results highlight MLX's potential in enabling efficient and
more accessible on-device ML applications within Apple's ecosystem.

</details>


### [21] [Position: Many generalization measures for deep learning are fragile](https://arxiv.org/abs/2510.18934)
*Shuofeng Zhang,Ard Louis*

Main category: cs.LG

TL;DR: 논문에서는 딥 신경망(DNN)의 일반화 측정이 얼마나 취약한지를 주장하며, 작은 훈련 수정이 일반화 척도의 값이나 추세에 미치는 영향을 강조한다.


<details>
  <summary>Details</summary>
Motivation: DNN의 일반화 측정은 흔히 질적인 일반화 경향을 재현한다고 가정되지만, 실제로는 훈련 네트워크에서 계산되는 많은 척도가 취약하다는 점을 강조하기 위해.

Method: 일반화 척도의 취약성을 밝힐 수 있는 몇 가지 예시와 관찰을 제공.

Result: 하이퍼파라미터의 미세 조정이 DNN에 거의 영향을 미치지 않음에도 불구하고, 경량화 경향 측정에서 큰 변화를 초래할 수 있음을 보여준다.

Conclusion: 새로운 측정치를 개발하는 사람들은 취약성을 명시적으로 확인해야 한다고 주장한다.

Abstract: A wide variety of generalization measures have been applied to deep neural
networks (DNNs). Although obtaining tight bounds remains challenging, such
measures are often assumed to reproduce qualitative generalization trends. In
this position paper, we argue that many post-mortem generalization measures --
those computed on trained networks -- are \textbf{fragile}: small training
modifications that barely affect the underlying DNN can substantially change a
measure's value, trend, or scaling behavior. For example, minor hyperparameter
changes, such as learning rate adjustments or switching between SGD variants
can reverse the slope of a learning curve in widely used generalization
measures like the path norm. We also identify subtler forms of fragility. For
instance, the PAC-Bayes origin measure is regarded as one of the most reliable,
and is indeed less sensitive to hyperparameter tweaks than many other measures.
However, it completely fails to capture differences in data complexity across
learning curves. This data fragility contrasts with the function-based
marginal-likelihood PAC-Bayes bound, which does capture differences in
data-complexity, including scaling behavior, in learning curves, but which is
not a post-mortem measure. Beyond demonstrating that many bounds -- such as
path, spectral and Frobenius norms, flatness proxies, and deterministic
PAC-Bayes surrogates -- are fragile, this position paper also argues that
developers of new measures should explicitly audit them for fragility.

</details>


### [22] [Preliminary Use of Vision Language Model Driven Extraction of Mouse Behavior Towards Understanding Fear Expression](https://arxiv.org/abs/2510.19160)
*Paimon Goulart,Jordan Steinhauser,Kylene Shuler,Edward Korzus,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: 이 논문은 비디오와 텍스트 입력을 인코딩하여 환경과 상호작용하는 쥐의 행동을 분류하는 비전-언어 모델(VLM)을 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 다양한 데이터 통합은 많은 과학 탐구 분야에서 중요한 단계이다.

Method: Qwen2.5-VL 모델을 사용하고, 프롬프트, 맥락 학습(ICL), 프레임 수준 전처리를 통해 성능을 향상시켰다.

Result: 각 방법이 분류 개선에 기여하며, 이를 조합하면 모델 튜닝 없이도 모든 행동에서 강력한 F1 점수를 얻을 수 있다.

Conclusion: 이 모델은 여러 시점과 환경에서 측정된 다양한 행동 특징을 통합하여 복잡한 연구 질문을 해결하는 데 도움을 줄 것이다.

Abstract: Integration of diverse data will be a pivotal step towards improving
scientific explorations in many disciplines. This work establishes a
vision-language model (VLM) that encodes videos with text input in order to
classify various behaviors of a mouse existing in and engaging with their
environment. Importantly, this model produces a behavioral vector over time for
each subject and for each session the subject undergoes. The output is a
valuable dataset that few programs are able to produce with as high accuracy
and with minimal user input. Specifically, we use the open-source Qwen2.5-VL
model and enhance its performance through prompts, in-context learning (ICL)
with labeled examples, and frame-level preprocessing. We found that each of
these methods contributes to improved classification, and that combining them
results in strong F1 scores across all behaviors, including rare classes like
freezing and fleeing, without any model fine-tuning. Overall, this model will
support interdisciplinary researchers studying mouse behavior by enabling them
to integrate diverse behavioral features, measured across multiple time points
and environments, into a comprehensive dataset that can address complex
research questions.

</details>


### [23] [Natural Gradient VI: Guarantees for Non-Conjugate Models](https://arxiv.org/abs/2510.19163)
*Fangyuan Sun,Ilyas Fatkhullin,Niao He*

Main category: cs.LG

TL;DR: 비확률 모델에서의 합리적인 후방 분포 근사를 위한 NGVI의 이론적 기초를 발전시키며 비유클리드 프로젝션을 활용한 알고리즘을 제안하고, 전역 최적해로의 빠른 수렴성을 확립한다.


<details>
  <summary>Details</summary>
Motivation: 비확률 모델에서의 후방 분포를 근사하기 위한 이론적 이해를 발전시켜 실질적인 응용에 기여하고자 함.

Method: 평균 필드 매개변수화를 바탕으로 불편한 손실 함수의 상대적 부드러움을 만족시키는 충분 조건을 도출하고, 수정된 NGVI 알고리즘을 제안하여 비유클리드 프로젝션을 통합함.

Result: 변형된 NGVI 알고리즘이 전역 비비대칭적 수렴성을 보이며, 비공식적인 최적해로의 빠른 수렴성을 증명함.

Conclusion: NGVI의 기하학적 성질과 수렴 행동에 대한 새로운 통찰을 제공하여 도전적인 추론 환경에서의 응용 가능성을 확장한다.

Abstract: Stochastic Natural Gradient Variational Inference (NGVI) is a widely used
method for approximating posterior distribution in probabilistic models.
Despite its empirical success and foundational role in variational inference,
its theoretical underpinnings remain limited, particularly in the case of
non-conjugate likelihoods. While NGVI has been shown to be a special instance
of Stochastic Mirror Descent, and recent work has provided convergence
guarantees using relative smoothness and strong convexity for conjugate models,
these results do not extend to the non-conjugate setting, where the variational
loss becomes non-convex and harder to analyze. In this work, we focus on
mean-field parameterization and advance the theoretical understanding of NGVI
in three key directions. First, we derive sufficient conditions under which the
variational loss satisfies relative smoothness with respect to a suitable
mirror map. Second, leveraging this structure, we propose a modified NGVI
algorithm incorporating non-Euclidean projections and prove its global
non-asymptotic convergence to a stationary point. Finally, under additional
structural assumptions about the likelihood, we uncover hidden convexity
properties of the variational loss and establish fast global convergence of
NGVI to a global optimum. These results provide new insights into the geometry
and convergence behavior of NGVI in challenging inference settings.

</details>


### [24] [A Communication-Efficient Decentralized Actor-Critic Algorithm](https://arxiv.org/abs/2510.19199)
*Xiaoxing Ren,Nicola Bastianello,Thomas Parisini,Andreas A. Malikopoulos*

Main category: cs.LG

TL;DR: 본 논문은 통신이 제한된 다중 에이전트 시스템에서의 강화 학습 문제를 연구하며, 각 에이전트가 지역 업데이트를 수행한 후 정보를 교환함으로써 통신 부담을 줄이는 분산 액터-비평자 학습 프레임워크를 개발한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템에서 제한된 통신 환경에서도 효과적으로 협력하기 위한 강화 학습 방법론 필요

Method: 각 에이전트가 정책과 가치 함수를 지역적으로 업데이트한 후 이웃과 정보를 교환하는 분산 액터-비평자 학습 프레임워크 개발

Result: 유한 시간 수렴 분석을 확립하고, 샘플 복잡성과 통신 복잡성을 수학적으로 도출

Conclusion: 이론적 결과를 협동 제어 설정의 수치 실험을 통해 입증함으로써 신경망의 근사 품질이 오류 경계에 미치는 영향을 보여준다.

Abstract: In this paper, we study the problem of reinforcement learning in multi-agent
systems where communication among agents is limited. We develop a decentralized
actor-critic learning framework in which each agent performs several local
updates of its policy and value function, where the latter is approximated by a
multi-layer neural network, before exchanging information with its neighbors.
This local training strategy substantially reduces the communication burden
while maintaining coordination across the network. We establish finite-time
convergence analysis for the algorithm under Markov-sampling. Specifically, to
attain the $\varepsilon$-accurate stationary point, the sample complexity is of
order $\mathcal{O}(\varepsilon^{-3})$ and the communication complexity is of
order $\mathcal{O}(\varepsilon^{-1}\tau^{-1})$, where tau denotes the number of
local training steps. We also show how the final error bound depends on the
neural network's approximation quality. Numerical experiments in a cooperative
control setting illustrate and validate the theoretical findings.

</details>


### [25] [Interpret Policies in Deep Reinforcement Learning using SILVER with RL-Guided Labeling: A Model-level Approach to High-dimensional and Multi-action Environments](https://arxiv.org/abs/2510.19244)
*Yiyu Qian,Su Nguyen,Chao Chen,Qinyue Zhou,Liyuan Zhao*

Main category: cs.LG

TL;DR: 우리는 SILVER 프레임워크를 개선하여 다중 행동 및 고차원 환경에서 심층 강화 학습 정책의 해석 가능성을 높이는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 정책 행동에 대한 신뢰를 높이기 위해 강화 학습(RL)의 해석 가능성을 향상시키려는 필요성.

Method: 이미지 관찰에서 compact feature representations을 추출하고 SHAP 기반 특성 기여도를 수행한 후, RL-guided labeling을 사용하여 행동적으로 일관된 경계 데이터셋을 생성합니다.

Result: 제안된 프레임워크를 통해 Atari 환경에서 심층 RL 알고리즘을 평가하고, 파생된 해석 가능한 정책의 명확성과 신뢰성을 검사하는 인간 주제 연구를 수행했습니다.

Conclusion: 제안한 접근법은 작업 성능을 유지하면서 에이전트 행동에 대한 투명성과 인간 이해를 크게 개선했습니다. 이 연구는 SILVER를 고차원, 다중 행동 설정에서 심층 RL 에이전트를 해석하는 확장 가능하고 행동 인식 가능한 프레임워크로 변형하여 설명 가능한 RL을 발전시킵니다.

Abstract: Deep reinforcement learning (RL) achieves remarkable performance but lacks
interpretability, limiting trust in policy behavior. The existing SILVER
framework (Li, Siddique, and Cao 2025) explains RL policy via Shapley-based
regression but remains restricted to low-dimensional, binary-action domains. We
propose SILVER with RL-guided labeling, an enhanced variant that extends SILVER
to multi-action and high-dimensional environments by incorporating the RL
policy's own action outputs into the boundary points identification. Our method
first extracts compact feature representations from image observations,
performs SHAP-based feature attribution, and then employs RL-guided labeling to
generate behaviorally consistent boundary datasets. Surrogate models, such as
decision trees and regression-based functions, are subsequently trained to
interpret RL policy's decision structure. We evaluate the proposed framework on
two Atari environments using three deep RL algorithms and conduct human-subject
study to assess the clarity and trustworthiness of the derived interpretable
policy. Results show that our approach maintains competitive task performance
while substantially improving transparency and human understanding of agent
behavior. This work advances explainable RL by transforming SILVER into a
scalable and behavior-aware framework for interpreting deep RL agents in
high-dimensional, multi-action settings.

</details>


### [26] [QiMeng-SALV: Signal-Aware Learning for Verilog Code Generation](https://arxiv.org/abs/2510.19296)
*Yang Zhang,Rui Zhang,Jiaming Guo,Lei Huang,Di Huang,Yunpu Zhao,Shuyao Cheng,Pengwei Jin,Chongxiao Li,Zidong Du,Xing Hu,Qi Guo,Yunji Chen*

Main category: cs.LG

TL;DR: 본 논문에서는 Verilog 코드 생성을 위한 신호 인식 학습(QiMeng-SALV)을 제안하여 리인포스먼트 러닝(RL)을 최적화하고 기능적으로 올바른 Verilog 코드를 생성하는 방법을 연구하였다.


<details>
  <summary>Details</summary>
Motivation: LLM의 발전은 자동 회로 설계를 위한 Verilog 코드 생성의 중요성을 강조하지만, 의미 있는 기능 보상이 부족하다.

Method: 부분적으로 잘못된 모듈에서 신호 인식 구현을 추출하여 RL 훈련을 최적화하고, AST를 활용하여 오류가 있는 모듈에서 의미 있는 보상을 제공할 수 있는 코드 세그먼트를 식별한다.

Result: QiMeng-SALV는 VerilogEval 및 RTLLM에서 최첨단 성능을 달성하였으며, 7B 매개변수 모델이 671B DeepSeek v3 모델의 성능에 필적하고, 같은 데이터 세트에서 훈련된 오픈 소스 모델 CodeV를 크게 초과하는 성과를 보였다.

Conclusion: QiMeng-SALV는 기존 모듈 수준 최적화에서 세밀한 신호 수준 최적화로의 패러다임 전환을 강조하며, 기능적 보상 부족 문제를 해결한다.

Abstract: The remarkable progress of Large Language Models (LLMs) presents promising
opportunities for Verilog code generation which is significantly important for
automated circuit design. The lacking of meaningful functional rewards hinders
the preference optimization based on Reinforcement Learning (RL) for producing
functionally correct Verilog code. In this paper, we propose Signal-Aware
Learning for Verilog code generation (QiMeng-SALV) by leveraging code segments
of functionally correct output signal to optimize RL training. Considering
Verilog code specifies the structural interconnection of hardware gates and
wires so that different output signals are independent, the key insight of
QiMeng-SALV is to extract verified signal-aware implementations in partially
incorrect modules, so as to enhance the extraction of meaningful functional
rewards. Roughly, we verify the functional correctness of signals in generated
module by comparing with that of reference module in the training data. Then
abstract syntax tree (AST) is employed to identify signal-aware code segments
which can provide meaningful functional rewards from erroneous modules.
Finally, we introduce signal-aware DPO which is optimized on the correct
signal-level code segments, thereby preventing noise and interference from
incorrect signals. The proposed QiMeng-SALV underscores the paradigm shift from
conventional module-level to fine-grained signal-level optimization in Verilog
code generation, addressing the issue of insufficient functional rewards.
Experiments demonstrate that our method achieves state-of-the-art performance
on VerilogEval and RTLLM, with a 7B parameter model matching the performance of
the DeepSeek v3 671B model and significantly outperforming the leading
open-source model CodeV trained on the same dataset. Our code is available at
https://github.com/zy1xxx/SALV.

</details>


### [27] [Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning](https://arxiv.org/abs/2510.19338)
*Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou*

Main category: cs.LG

TL;DR: Ring-linear 모델 시리즈를 소개하며, 특히 Ring-mini-linear-2.0과 Ring-flash-linear-2.0을 포함한다. 두 모델은 하이브리드 아키텍처를 채택하여 긴 컨텍스트 추론에서 I/O 및 계산 오버헤드를 크게 줄인다.


<details>
  <summary>Details</summary>
Motivation: 긴 컨텍스트 추론 문제를 해결하고 인퍼런스 비용을 절감하는 고성능 모델 개발.

Method: 하이브리드 아키텍처를 통해 선형 주의와 소프트맥스 주의를 통합하고, FP8 연산자 라이브러리를 활용하여 교육 효율성을 개선.

Result: Ring-mini-linear-2.0은 16B 매개변수와 957M 활성화를, Ring-flash-linear-2.0은 104B 매개변수와 6.1B 활성화를 포함하며, 두 모델 모두 인퍼런스 비용을 1/10로 줄였다.

Conclusion: 이 모델은 강화 학습 단계 동안 장기적이고 안정적인 최적화를 통해 여러 어려운 복합 추론 벤치마크에서 SOTA 성능을 지속적으로 유지한다.

Abstract: In this technical report, we present the Ring-linear model series,
specifically including Ring-mini-linear-2.0 and Ring-flash-linear-2.0.
Ring-mini-linear-2.0 comprises 16B parameters and 957M activations, while
Ring-flash-linear-2.0 contains 104B parameters and 6.1B activations. Both
models adopt a hybrid architecture that effectively integrates linear attention
and softmax attention, significantly reducing I/O and computational overhead in
long-context inference scenarios. Compared to a 32 billion parameter dense
model, this series reduces inference cost to 1/10, and compared to the original
Ring series, the cost is also reduced by over 50%. Furthermore, through
systematic exploration of the ratio between different attention mechanisms in
the hybrid architecture, we have identified the currently optimal model
structure. Additionally, by leveraging our self-developed high-performance FP8
operator library-linghe, overall training efficiency has been improved by 50%.
Benefiting from the high alignment between the training and inference engine
operators, the models can undergo long-term, stable, and highly efficient
optimization during the reinforcement learning phase, consistently maintaining
SOTA performance across multiple challenging complex reasoning benchmarks.

</details>


### [28] [A Markov Decision Process for Variable Selection in Branch & Bound](https://arxiv.org/abs/2510.19348)
*Paul Strang,Zacharie Alès,Côme Bissuel,Olivier Juan,Safia Kedad-Sidhoum,Emmanuel Rachelson*

Main category: cs.LG

TL;DR: 이 연구에서는 혼합 정수 선형 프로그래밍(MILP) 문제 해결을 위한 변수를 선택하는 새로운 모델 BBMDP를 제안하며, 이는 강화 학습 알고리즘을 활용하여 최적의 가지치기 정책을 학습할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: MILP 문제 해결의 성능 향상을 위해 가지치기 결정을 위한 변수 선택 휴리스틱을 개선할 필요가 존재한다.

Method: BBMDP라는 원칙적인 vanilla MDP 공식을 도입하여 B&B에서의 변수 선택을 수행하고 다양한 강화 학습 알고리즘을 활용한다.

Result: 우리의 모델을 이용한 계산 실험에서 가지치기 에이전트가 기존의 최신 강화 학습 에이전트보다 네 가지 MILP 벤치마크에서 더 우수한 성능을 보였다.

Conclusion: BBMDP는 MILP 문제 해결을 위한 변수 선택에서 강화 학습 접근 방식을 성공적으로 활용할 수 있는 가능성을 보여준다.

Abstract: Mixed-Integer Linear Programming (MILP) is a powerful framework used to
address a wide range of NP-hard combinatorial optimization problems, often
solved by Branch and Bound (B&B). A key factor influencing the performance of
B&B solvers is the variable selection heuristic governing branching decisions.
Recent contributions have sought to adapt reinforcement learning (RL)
algorithms to the B&B setting to learn optimal branching policies, through
Markov Decision Processes (MDP) inspired formulations, and ad hoc convergence
theorems and algorithms. In this work, we introduce BBMDP, a principled vanilla
MDP formulation for variable selection in B&B, allowing to leverage a broad
range of RL algorithms for the purpose of learning optimal B\&B heuristics.
Computational experiments validate our model empirically, as our branching
agent outperforms prior state-of-the-art RL agents on four standard MILP
benchmarks.

</details>


### [29] [CPSVD: Enhancing Large Language Model Compression via Column-Preserving Singular Value Decomposition](https://arxiv.org/abs/2510.19385)
*Lin Xv,Jingsheng Gao,Xian Gao,Ting Li,Yuzhuo Fu*

Main category: cs.LG

TL;DR: 대형 언어 모델의 압축을 위한 새로운 방법인 CPSVD를 제안하며, 기존 SVD 방식의 한계를 극복하여 더 나은 성능을 보임.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 급속한 발전에 따라 크기가 커짐에 따라 효율적인 압축 기술이 필요하다.

Method: CPSVD는 매개변수 행렬을 지능적으로 분할하여 SVD 기반 LLM 압축을 개선하는 새로운 방법이다.

Result: CPSVD는 최신 SVD 기반 LLM 압축 방법들보다 일관되게 우수한 성능을 보였으며, 낮은 당혹감과 높은 정확도를 달성하였다.

Conclusion: CPSVD는 기존 방법의 한계를 극복하고 압축 성능을 더욱 향상시킨다.

Abstract: The rapid advancement of Large Language Models (LLMs) faces a critical
bottleneck in their immense size, necessitating efficient compression
techniques. While Singular Value Decomposition (SVD) is a promising approach,
existing SVD-based methods treat the entire parameter matrix uniformly,
overlooking that SVD approximation errors vary significantly across different
matrix parts, which often leads to suboptimal compression. To address this, we
propose \textbf{C}olumn-\textbf{P}reserving \textbf{S}ingular \textbf{V}alue
\textbf{D}ecomposition (CPSVD), a novel method that refines SVD-based LLM
compression by intelligently segmenting the parameter matrix. Unlike
traditional SVD, CPSVD identifies and directly preserves matrix columns with
high decomposition errors, applying SVD only to columns with low decomposition
errors, while precisely determining the optimal balance point between these two
strategies to minimize error. Furthermore, leveraging the inherent
heterogeneity in decomposition errors across different matrices within an LLM,
CPSVD adaptively allocates non-uniform compression rates to modules within that
layer, while adhering to a target layer-wise compression ratio, thereby further
enhancing compression performance. Extensive experiments demonstrate that CPSVD
consistently outperforms state-of-the-art SVD-based LLM compression methods,
achieving lower perplexity and higher accuracy on zero-shot tasks.

</details>


### [30] [The Confusing Instance Principle for Online Linear Quadratic Control](https://arxiv.org/abs/2510.19531)
*Waris Radji,Odalric-Ambrym Maillard*

Main category: cs.LG

TL;DR: 모델 기반 강화 학습을 통해 알려지지 않은 동역학을 가진 선형 시스템의 제어 문제를 재검토하며, 기존 방법의 한계를 극복하기 위해 새로운 접근법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 선형 시스템의 제어 문제는 알려지지 않은 동역학 하에서 기존 방법의 한계가 존재합니다.

Method: Confusing Instance 원칙을 기반으로 한 MED-LQ 제어 전략을 개발하며, LQR 정책의 구조와 민감도 및 안정성 분석을 활용합니다.

Result: MED-LQ는 다양한 시나리오에서 경쟁력 있는 성능을 달성하며, 대규모 MDP에서 광범위한 응용 가능성을 강조합니다.

Conclusion: 이러한 새로운 제어 전략은 작은 규모의 설정을 넘어서 CI와 MED의 원칙을 확장합니다.

Abstract: We revisit the problem of controlling linear systems with quadratic cost
under unknown dynamics with model-based reinforcement learning. Traditional
methods like Optimism in the Face of Uncertainty and Thompson Sampling, rooted
in multi-armed bandits (MABs), face practical limitations. In contrast, we
propose an alternative based on the Confusing Instance (CI) principle, which
underpins regret lower bounds in MABs and discrete Markov Decision Processes
(MDPs) and is central to the Minimum Empirical Divergence (MED) family of
algorithms, known for their asymptotic optimality in various settings. By
leveraging the structure of LQR policies along with sensitivity and stability
analysis, we develop MED-LQ. This novel control strategy extends the principles
of CI and MED beyond small-scale settings. Our benchmarks on a comprehensive
control suite demonstrate that MED-LQ achieves competitive performance in
various scenarios while highlighting its potential for broader applications in
large-scale MDPs.

</details>


### [31] [Study of Training Dynamics for Memory-Constrained Fine-Tuning](https://arxiv.org/abs/2510.19675)
*Aël Quélennec,Nour Hezbri,Pavlo Mozharovskyi,Van-Tam Nguyen,Enzo Tartaglione*

Main category: cs.LG

TL;DR: TraDy는 메모리 효율적인 딥 신경망 훈련을 위한 최신 전이 학습 기법으로, 동적 확률적 채널 선택을 활용하여 업데이트의 레이어 중요성을 아키텍처에 따라 결정합니다.


<details>
  <summary>Details</summary>
Motivation: 딥 신경망의 크기가 커짐에 따라 메모리 효율적인 훈련이 점점 더 중요해지고 있습니다.

Method: TraDy는 미리 선택된 레이어 내에서 에포크 사이에 채널을 확률적으로 재샘플링하는 동적 채널 선택 접근법을 도입합니다.

Result: TraDy는 다양한 다운스트림 작업 및 아키텍처에서 최신 성능을 달성하였고, 99% 활성화 희소성, 95% 가중치 도함수 희소성, 가중치 도함수 계산에 대한 FLOP 97% 감소를 달성했습니다.

Conclusion: TraDy는 메모리 제약을 유지하면서도 우수한 성능을 제공합니다.

Abstract: Memory-efficient training of deep neural networks has become increasingly
important as models grow larger while deployment environments impose strict
resource constraints. We propose TraDy, a novel transfer learning scheme
leveraging two key insights: layer importance for updates is
architecture-dependent and determinable a priori, while dynamic stochastic
channel selection provides superior gradient approximation compared to static
approaches. We introduce a dynamic channel selection approach that
stochastically resamples channels between epochs within preselected layers.
Extensive experiments demonstrate TraDy achieves state-of-the-art performance
across various downstream tasks and architectures while maintaining strict
memory constraints, achieving up to 99% activation sparsity, 95% weight
derivative sparsity, and 97% reduction in FLOPs for weight derivative
computation.

</details>


### [32] [Fast Inference via Hierarchical Speculative Decoding](https://arxiv.org/abs/2510.19705)
*Clara Mohri,Haim Kaplan,Tal Schuster,Yishay Mansour,Amir Globerson*

Main category: cs.LG

TL;DR: 계층적 추정 디코딩(HSD) 알고리즘을 통해 텍스트 생성의 지연 시간을 줄이는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: Transformer 언어 모델의 텍스트 생성 과정에서 발생하는 지연 시간을 줄이고자 함.

Method: HSD 알고리즘은 여러 초안 모델을 계층적으로 쌓아, 각각의 모델이 토큰을 제안하고 다음 모델이 이를 검증하도록 설계함.

Result: HSD는 최상의 단일 초안 기준보다 최대 1.2배의 속도 향상을 제공함.

Conclusion: HSD 알고리즘은 이전 기술을 넘어서 생성 지연 시간을 줄이는 데 실질적인 가능성을 보여줌.

Abstract: Transformer language models generate text autoregressively, making inference
latency proportional to the number of tokens generated. Speculative decoding
reduces this latency without sacrificing output quality, by leveraging a small
draft model to propose tokens that the larger target model verifies in
parallel. In practice, however, there may exist a set of potential draft
models- ranging from faster but less inaccurate, to slower yet more reliable.
We introduce Hierarchical Speculative Decoding (HSD), an algorithm that stacks
these draft models into a hierarchy, where each model proposes tokens, and the
next larger model verifies them in a single forward pass, until finally the
target model verifies tokens. We derive an expression for the expected latency
of any such hierarchy and show that selecting the latency-optimal hierarchy can
be done in polynomial time. Empirically, HSD gives up to 1.2x speed-up over the
best single-draft baseline, demonstrating the practicality of our algorithm in
reducing generation latency beyond previous techniques.

</details>


### [33] [Enabling Granular Subgroup Level Model Evaluations by Generating Synthetic Medical Time Series](https://arxiv.org/abs/2510.19728)
*Mahmoud Ibrahim,Bart Elen,Chang Sun,Gökhan Ertaylan,Michel Dumontier*

Main category: cs.LG

TL;DR: 이 논문에서는 합성 ICU 시계열 데이터를 활용하여 예측 모델을 훈련하고 평가하는 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 예측 모델의 신뢰성과 공정한 평가 필요성.

Method: Enhanced TimeAutoDiff 방법은 잠재적 확산 목표를 분포 정렬 패널티로 보강한다.

Result: Enhanced TimeAutoDiff는 TRTS 격차를 70% 이상 줄이고, 32개 교차 하위 그룹에서 AUROC 추정 오차를 50%까지 감소시킨다.

Conclusion: 이 연구는 민감한 EHR 데이터를 노출하지 않고 다양한 환자 집단에 대한 신뢰할 수 있는 모델 평가를 위한 프레임워크를 제공한다.

Abstract: We present a novel framework for leveraging synthetic ICU time-series data
not only to train but also to rigorously and trustworthily evaluate predictive
models, both at the population level and within fine-grained demographic
subgroups. Building on prior diffusion and VAE-based generators (TimeDiff,
HealthGen, TimeAutoDiff), we introduce \textit{Enhanced TimeAutoDiff}, which
augments the latent diffusion objective with distribution-alignment penalties.
We extensively benchmark all models on MIMIC-III and eICU, on 24-hour mortality
and binary length-of-stay tasks. Our results show that Enhanced TimeAutoDiff
reduces the gap between real-on-synthetic and real-on-real evaluation (``TRTS
gap'') by over 70\%, achieving $\Delta_{TRTS} \leq 0.014$ AUROC, while
preserving training utility ($\Delta_{TSTR} \approx 0.01$). Crucially, for 32
intersectional subgroups, large synthetic cohorts cut subgroup-level AUROC
estimation error by up to 50\% relative to small real test sets, and outperform
them in 72--84\% of subgroups. This work provides a practical,
privacy-preserving roadmap for trustworthy, granular model evaluation in
critical care, enabling robust and reliable performance analysis across diverse
patient populations without exposing sensitive EHR data, contributing to the
overall trustworthiness of Medical AI.

</details>


### [34] [CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees](https://arxiv.org/abs/2510.19754)
*Aman Bilkhoo,Mehran Hosseini,Milad Kazemi,Nicola Paoletti*

Main category: cs.LG

TL;DR: CONFEX는 예측 불확실성을 고려한 반사실 설명을 생성하기 위한 새로운 방법으로, 예측의 신뢰성을 높이고 해석 가능성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 반사실 설명(CFX)은 모델 예측에 대한 인간이 이해할 수 있는 정당성을 제공하며, 실행 가능한 대응을 가능하게 하고 해석 능력을 향상시킨다. 신뢰할 수 있으려면 CFX는 설명이 오해를 불러일으키거나 적용할 수 없는 높은 예측 불확실성 영역을 피해야 한다.

Method: CONFEX는 Conformal Prediction(CP)과 Mixed-Integer Linear Programming(MILP)을 사용하여 불확실성을 인식하는 반사실 설명을 생성하는 새로운 방법이다. CONFEX 설명은 지역적 범위 보장 제공을 위해 설계되었으며, CFX 생성이 교환 가능성을 위반하는 문제를 해결한다.

Result: CONFEX는 예측 불확실성과 최적성 모두에 대해 엄격한 보장을 갖춘 CFX를 생성한다. 우리는 CONFEX를 다양한 벤치마크와 메트릭에서 최신 방법과 비교하여 평가하였고, 우리의 불확실성 인식 접근 방식이 강건하고 그럴듯한 설명을 산출함을 입증하였다.

Conclusion: CONFEX는 예측 불확실성을 고려하여 더 신뢰할 수 있는 반사실 설명을 제공함으로써 모델 해석 가능성을 지속적으로 향상시킨다.

Abstract: Counterfactual explanations (CFXs) provide human-understandable
justifications for model predictions, enabling actionable recourse and
enhancing interpretability. To be reliable, CFXs must avoid regions of high
predictive uncertainty, where explanations may be misleading or inapplicable.
However, existing methods often neglect uncertainty or lack principled
mechanisms for incorporating it with formal guarantees. We propose CONFEX, a
novel method for generating uncertainty-aware counterfactual explanations using
Conformal Prediction (CP) and Mixed-Integer Linear Programming (MILP). CONFEX
explanations are designed to provide local coverage guarantees, addressing the
issue that CFX generation violates exchangeability. To do so, we develop a
novel localised CP procedure that enjoys an efficient MILP encoding by
leveraging an offline tree-based partitioning of the input space. This way,
CONFEX generates CFXs with rigorous guarantees on both predictive uncertainty
and optimality. We evaluate CONFEX against state-of-the-art methods across
diverse benchmarks and metrics, demonstrating that our uncertainty-aware
approach yields robust and plausible explanations.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [35] [Defending Against Prompt Injection with DataFilter](https://arxiv.org/abs/2510.19207)
*Yizhu Wang,Sizhe Chen,Raghad Alkhudair,Basel Alomair,David Wagner*

Main category: cs.CR

TL;DR: 대형 언어 모델(LLM) 에이전트가 자동화된 작업을 수행하고 신뢰할 수 없는 외부 데이터와 상호작용하는 경우, 프롬프트 삽입은 중요한 보안 위협으로 부각된다. 이를 해결하기 위해 악의적인 지침을 제거하는 데이터 필터(DataFilter)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM 에이전트의 자동화 및 신뢰할 수 없는 데이터와의 상호작용 증가로 인해 프롬프트 삽입이 보안 위협으로 대두되고 있다.

Method: 모델 비의존적인 데이터 필터(DataFilter)는 백엔드 LLM에 도달하기 전에 악성 지침을 제거하도록 설계되었으며, 사용자 지침과 데이터를 사용하여 적대적인 내용을 선택적으로 제거한다.

Result: 여러 벤치마크에서 DataFilter는 프롬프트 삽입 공격 성공률을 거의 제로로 줄이며 LLM의 유틸리티를 유지한다.

Conclusion: DataFilter는 강력한 보안, 높은 유틸리티, 플러그 앤 플레이 배치를 제공하여 상용 LLM을 안전하게 보호할 수 있는 강력한 실제 방어책이다.

Abstract: When large language model (LLM) agents are increasingly deployed to automate
tasks and interact with untrusted external data, prompt injection emerges as a
significant security threat. By injecting malicious instructions into the data
that LLMs access, an attacker can arbitrarily override the original user task
and redirect the agent toward unintended, potentially harmful actions. Existing
defenses either require access to model weights (fine-tuning), incur
substantial utility loss (detection-based), or demand non-trivial system
redesign (system-level). Motivated by this, we propose DataFilter, a test-time
model-agnostic defense that removes malicious instructions from the data before
it reaches the backend LLM. DataFilter is trained with supervised fine-tuning
on simulated injections and leverages both the user's instruction and the data
to selectively strip adversarial content while preserving benign information.
Across multiple benchmarks, DataFilter consistently reduces the prompt
injection attack success rates to near zero while maintaining the LLMs'
utility. DataFilter delivers strong security, high utility, and plug-and-play
deployment, making it a strong practical defense to secure black-box commercial
LLMs against prompt injection. Our DataFilter model is released at
https://huggingface.co/JoyYizhu/DataFilter for immediate use, with the code to
reproduce our results at https://github.com/yizhu-joy/DataFilter.

</details>


### [36] [Authorization of Knowledge-base Agents in an Intent-based Management Function](https://arxiv.org/abs/2510.19324)
*Loay Abdelrazek,Leyli Karaçay,Marin Orlic*

Main category: cs.CR

TL;DR: 본 논문에서는 6G 기술의 발전에 따라 고급 의도를 저수준의 구성으로 변환하여 네트워크 관리를 간소화하는 Intent-based Management 시스템의 에이전트에 대한 보안 및 권한 관리의 중요성을 강조하고, 동적 및 다중 임대 환경에서의 효과적인 접근 제어를 위한 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 6G 네트워크에서는 Intent-based Management 시스템의 채택이 증가하고 있으며, 이를 위해 에이전트의 안전하고 세밀한 권한 부여가 중요합니다.

Method: 문맥 및 기능적 속성을 에이전트 역할과 통합한 동적 정책 중심 접근 제어 프레임워크를 제안합니다.

Result: 에이전트 기능 분석을 통해 에이전트에게 지식 그래프에 대한 최소한의 필요한 권한만 부여됩니다.

Conclusion: 제안한 프레임워크는 동적이고 맥락에 맞는 세밀한 접근 제어를 가능하게 하여, Intent-based Operations를 지원합니다.

Abstract: As networks move toward the next-generation 6G, Intent-based Management (IbM)
systems are increasingly adopted to simplify and automate network management by
translating high-level intents into low-level configurations. Within these
systems, agents play a critical role in monitoring current state of the
network, gathering data, and enforcing actions across the network to fulfill
the intent. However, ensuring secure and fine-grained authorization of agents
remains a significant challenge, especially in dynamic and multi-tenant
environments. Traditional models such as Role-Based Access Control (RBAC),
Attribute-Based Access Control (ABAC) and Relational-Based Access Control
(RelBAC) often lack the flexibility to accommodate the evolving context and
granularity required by intentbased operations. In this paper, we propose an
enhanced authorization framework that integrates contextual and functional
attributes with agent roles to achieve dynamic, policy-driven access control.
By analyzing agent functionalities, our approach ensures that agents are
granted only the minimal necessary privileges towards knowledge graphs.

</details>


### [37] [Monitoring LLM-based Multi-Agent Systems Against Corruptions via Node Evaluation](https://arxiv.org/abs/2510.19420)
*Chengcan Wu,Zhixin Zhang,Mingqian Xu,Zeming Wei,Meng Sun*

Main category: cs.CR

TL;DR: 본 논문에서는 대규모 언어 모델 기반 다중 에이전트 시스템의 신뢰성을 높이기 위해 동적 방어 패러다임을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 기반 다중 에이전트 시스템은 인공지능 애플리케이션의 인기 있는 패러다임이지만, 신뢰성 문제는 여전히 중요한 우려 사항이다.

Method: MAS 그래프 구조를 위한 동적 방어 패러다임을 제안하며, 통신을 지속적으로 모니터링하고 그래프 토폴로지를 동적으로 조정한다.

Result: 우리 방법은 점점 더 복잡해지는 MAS 환경에서 기존 방어 메커니즘보다 우수한 성능을 보인다.

Conclusion: 본 연구는 다중 에이전트 시스템의 신뢰성 있는 애플리케이션을 위한 효과적인 방어 기제를 제공한다.

Abstract: Large Language Model (LLM)-based Multi-Agent Systems (MAS) have become a
popular paradigm of AI applications. However, trustworthiness issues in MAS
remain a critical concern. Unlike challenges in single-agent systems, MAS
involve more complex communication processes, making them susceptible to
corruption attacks. To mitigate this issue, several defense mechanisms have
been developed based on the graph representation of MAS, where agents represent
nodes and communications form edges. Nevertheless, these methods predominantly
focus on static graph defense, attempting to either detect attacks in a fixed
graph structure or optimize a static topology with certain defensive
capabilities. To address this limitation, we propose a dynamic defense paradigm
for MAS graph structures, which continuously monitors communication within the
MAS graph, then dynamically adjusts the graph topology, accurately disrupts
malicious communications, and effectively defends against evolving and diverse
dynamic attacks. Experimental results in increasingly complex and dynamic MAS
environments demonstrate that our method significantly outperforms existing MAS
defense mechanisms, contributing an effective guardrail for their trustworthy
applications. Our code is available at
https://github.com/ChengcanWu/Monitoring-LLM-Based-Multi-Agent-Systems.

</details>


### [38] [AegisMCP: Online Graph Intrusion Detection for Tool-Augmented LLMs on Edge Devices](https://arxiv.org/abs/2510.19462)
*Zhonghao Zhan,Amir Al Sadi,Krinos Li,Hamed Haddadi*

Main category: cs.CR

TL;DR: 이 연구에서는 스마트 홈에서의 MCP 에이전트 툴체인의 보안을 조사하고 AegisMCP라는 프로토콜 수준의 침입 탐지기를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 스마트 홈 환경에서 양질의 보안을 확보하기 위해 MCP 에이전트 툴체인의 취약점을 분석하고 이를 방어할 수 있는 기법을 개발하고자 합니다.

Method: 최소 공격 세트를 생성하고, MCP 활동을 표현하는 NEBULA-Schema를 설계하며, CPU 전용 스트리밍 탐지기를 구현합니다.

Result: AegisMCP는 스마트 홈 테스트베드에서 모델 추론과 경고를 초-초단위로 수행하며, Intel N150 클래스 엣지 하드웨어에서 일관된 성능을 보입니다.

Conclusion: AegisMCP는 MCP의 보안을 크게 향상시키는 데 기여하며, 반복 가능한 평가를 위한 코드와 스키마를 공개합니다.

Abstract: In this work, we study security of Model Context Protocol (MCP) agent
toolchains and their applications in smart homes. We introduce AegisMCP, a
protocol-level intrusion detector. Our contributions are: (i) a minimal attack
suite spanning instruction-driven escalation, chain-of-tool exfiltration,
malicious MCP server registration, and persistence; (ii) NEBULA-Schema
(Network-Edge Behavioral Learning for Untrusted LLM Agents), a reusable
protocol-level instrumentation that represents MCP activity as a streaming
heterogeneous temporal graph over agents, MCP servers, tools, devices, remotes,
and sessions; and (iii) a CPU-only streaming detector that fuses novelty,
session-DAG structure, and attribute cues for near-real-time edge inference,
with optional fusion of local prompt-guardrail signals. On an emulated
smart-home testbed spanning multiple MCP stacks and a physical bench, AegisMCP
achieves sub-second per-window model inference and end-to-end alerting. The
latency of AegisMCP is consistently sub-second on Intel N150-class edge
hardware, while outperforming traffic-only and sequence baselines; ablations
confirm the importance of DAG and install/permission signals. We release code,
schemas, and generators for reproducible evaluation.

</details>
