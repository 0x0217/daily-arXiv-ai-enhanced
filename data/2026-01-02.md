<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 19]
- [cs.LG](#cs.LG) [Total: 21]
- [cs.CR](#cs.CR) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)
*Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder*

Main category: cs.AI

TL;DR: CASCADE는 LLM 에이전트가 도구 사용에서 기술 습득으로 전환할 수 있도록 하여 복잡한 과학 작업에 적응할 수 있게 도와주는 자기 진화 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 현재 대형 언어 모델(Large Language Model, LLM) 에이전트는 정의된 도구나 불안정한 도구 생성에 의존하고 있어, 복잡한 과학 과제에 대한 능력과 적응력이 제한되어 있다.

Method: CASCADE는 두 가지 메타 기술, 즉 웹 검색을 통한 지속적인 학습과 내성이 있는 지식 그래프 탐색을 통해 복잡한 외부 도구를 익히고 지식을 정리하는 자기 진화 에이전트 프레임워크이다.

Result: CASCADE는 SciSkillBench라는 116개의 재료 과학 및 화학 연구 과제를 평가하는 벤치마크에서 GPT-5를 사용하여 93.3%의 성공률을 기록했으며, 진화 메커니즘이 없을 경우 35.4%에 그쳤다.

Conclusion: CASCADE는 인간-에이전트 협업과 기억 공고화와 함께 실행 가능한 기술을 축적하여 과학자와 에이전트 간에 공유 가능하며, 확장 가능한 AI 지원 과학 연구를 향해 나아가고 있다.

Abstract: Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.

</details>


### [2] [SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents](https://arxiv.org/abs/2512.24189)
*Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou*

Main category: cs.AI

TL;DR: SCP는 자율 과학 에이전트의 글로벌 네트워크를 가능하게 하는 공개 표준으로, 과학 자원 통합과 관리 수명 주기 관리를 통해 연구와 협업을 가속화합니다.


<details>
  <summary>Details</summary>
Motivation: 과학 연구의 효율성과 협업을 높이기 위해 자율 에이전트와 다양한 과학 자원 간의 표준화된 통신이 필요함을 인식했습니다.

Method: SCP는 통합 리소스 통합과 관리 수명 주기 관리를 위한 두 가지 기초적 원칙에 기반하여 설계되었습니다. 이를 통해 다양한 도구와 자원 간의 호출 및 조합이 원활하게 이루어질 수 있도록 합니다.

Result: SCP 플랫폼을 통해 1,600개 이상의 도구 자원을 제공하며, 다양한 사용 사례에서 인간 연구자와 AI 시스템 간의 안전하고 대규모의 협업을 촉진합니다.

Conclusion: SCP는 과학적 맥락과 도구 조정의 표준화를 통해 확장 가능한 다기관 에이전트 기반 과학을 위한 필수 인프라를 구축합니다.

Abstract: We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.

</details>


### [3] [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.AI

TL;DR: SPARK는 작업 특정 검색과 개인화를 제공하는 다중 대화형 에이전트를 통한 검색 개인화 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 사용자의 다차원적 정보 요구 사항을 모델링할 수 있는 능력이 요구되며, 기존의 정적 프로필이나 단일 검색 파이프라인으로는 이 문제를 해결하기 어렵다.

Method: SPARK는 역할, 전문성, 작업 맥락, 도메인에 의해 정의된 페르소나 공간을 형성하고, 동적으로 쿼리를 해석하여 가장 관련성 높은 전문 에이전트를 활성화하는 페르소나 코디네이터를 도입한다.

Result: 각 에이전트는 독립적인 검색 보강 생성 프로세스를 실행하며, 이 과정은 전용의 장기 및 단기 메모리 저장소와 맥락 인식 추론 모듈에 의해 지원된다.

Conclusion: SPARK는 분산 에이전트의 행동에서 emergent personalization이 어떻게 발생하는지를 모델링하며, 이는 최소한의 조정 규칙에 의해 지배된다.

Abstract: Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

</details>


### [4] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)
*Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: 자동 프롬프트 최적화(APO)는 대형 언어 모델(LLM) 성능 향상을 위한 중요한 기술로 부상하고 있으며, 기존의 최첨단 방법들은 일반적으로 진화 또는 강화 학습(RL) 접근 방식을 위한 적합성 점수를 계산하기 위해 큰 레이블이 붙은 데이터 세트에 의존한다. 하지만, 실제 소프트웨어 엔지니어링에서는 초기 에이전트 개발의 차가운 시작 단계에서 그러한 데이터 세트를 찾아보는 것이 드물고, 엔지니어들은 대신 혼란스러운 생산 로그와 진화하는 실패 모드에 직면한다. ROAD(자동 디버깅을 통한 반영적 최적화)는 이러한 정제된 데이터 세트의 필요성을 우회하는 새로운 프레임워크를 제안하며, 최적화를 확률적 탐색이 아닌 동적 디버깅 조사로 간주한다. 기존의 변형 전략과 달리 ROAD는 근본 원인 분석을 위한 분석기, 패턴 집합화를 위한 최적화기, 전략 통합을 위한 코치로 구성된 전문화된 다중 에이전트 아키텍처를 활용하여 비구조적 실패 로그를 견고하고 구조화된 결정 트리 프로토콜로 변환한다. 우리는 ROAD를 표준화된 학술 벤치마크와 실제 생산 지식 관리 엔진 모두에서 평가했다. 실험 결과는 ROAD가 매우 샘플 효율적임을 보여주며, 단 3회의 자동화된 반복 내에 성공률이 5.6% 증가하고(73.6%에서 79.2%로), 검색 정확도가 3.8% 증가했다. 또한 리테일 도메인의 복잡한 추론 작업에서 ROAD는 기준선에 비해 약 19% 향상된 에이전트 성능을 보여주었다. 이러한 발견은 실패 분석 및 패치의 인간 엔지니어링 루프를 모방하는 것이 신뢰할 수 있는 LLM 에이전트를 배포하기 위한 리소스 집약적인 RL 훈련에 대한 실행 가능한 데이터 효율적인 대안을 제공함을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제 소프트웨어 엔지니어링에서 초기 개발 단계에서 정제된 데이터 세트를 찾는 것이 드물기 때문에, 혼란스러운 로그와 진화하는 실패 모드를 처리할 새로운 방법이 필요하다.

Method: ROAD는 동적 디버깅 조사를 통해 최적화를 수행하며, 다중 에이전트 아키텍처를 활용하여 비구조적 실패 로그를 결정 트리 프로토콜로 변환한다.

Result: ROAD는 성공률을 5.6% 증가시키고 검색 정확도를 3.8% 증가시키는 성과를 보여 주며, 특히 리테일 도메인에서 약 19% 향상된 성능을 나타낸다.

Conclusion: ROAD는 인간 엔지니어링 루프를 모방하여 데이터 효율적인 방법으로 신뢰할 수 있는 LLM 에이전트를 배포할 수 있는 새로운 접근 방식을 제안한다.

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

</details>


### [5] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow는 자가 진화 에이전트 프레임워크로, 구조적 추론의 부족과 기존 방법의 조기 수렴 문제를 해결하여 우수한 해결 품질을 달성하며 비용을 절감합니다.


<details>
  <summary>Details</summary>
Motivation: 정적 대형 언어 모델에서 자가 개선 에이전트로의 전환이 전통적인 진화적 접근법에서 구조적 추론 부족으로 방해받고 있습니다.

Method: LoongFlow는 LLM을 통합하여 인지적 '계획-실행-요약'(PES) 패러다임을 적용하고, 혼합 진화 메모리 시스템을 통해 탐색-개발 균형을 유지합니다.

Result: LoongFlow는 AlphaEvolve 기준 및 Kaggle 대회에서 기존의 방법들보다 최대 60% 더 뛰어난 진화 효율성을 보여주며 우수한 솔루션을 발견합니다.

Conclusion: LoongFlow는 자율적인 과학적 발견에서 중요한 진전을 이루어 내며, 감소된 계산 비용으로 전문가 수준의 솔루션을 생성할 수 있게 합니다.

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [6] [CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation](https://arxiv.org/abs/2512.24113)
*Jiaxin Hu,Tao Wang,Bingsan Yang,Hongrun Wang*

Main category: cs.AI

TL;DR: CogRec는 대형 언어 모델과 Soar 인지 아키텍처의 장점을 결합한 새로운 추천 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 추천 시스템에서의 사용자 선호 이해 능력은 뛰어나지만, '블랙 박스' 특성, 지식 환각, 제한된 온라인 학습 능력 등 여러 문제에 제약받고 있다.

Method: CogRec는 Soar를 상징적 추론 엔진으로 사용하고, 대형 언어 모델을 통해 작업 메모리에 생산 규칙을 초기화하는 방식으로 운영된다. 에이전트는 지각-인지-행동(PCA) 사이클을 기반으로 하며, 장애물에 부딪힐 때 LLM에 질문하여 해결책을 찾는다.

Result: CogRec는 세 가지 공개 데이터셋에서 추천 정확성, 설명 가능성, 롱테일 문제 해결의 효과성에서 significant advantages을 보였다.

Conclusion: CogRec는 지식 기반을 지속적으로 진화시키며 추천에 대한 해석 가능한 이유를 제공하는 강력한 온라인 학습을 가능하게 한다.

Abstract: Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent "Black-Box" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.

</details>


### [7] [Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks](https://arxiv.org/abs/2512.24156)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.AI

TL;DR: 이 논문은 ARC-AGI-3 벤치마크에서 상호 작용 추론 과제를 해결하기 위한 학습 없는 그래프 기반 접근 방식을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 선진 LLM들은 이 과제를 신뢰성 있게 해결할 수 없다는 문제를 해결하기 위해 이 방법을 개발했습니다.

Method: 비전 기반 프레임 처리와 체계적인 상태 공간 탐사를 결합하여 그래프 구조의 표현을 사용합니다.

Result: 이 접근법은 ARC-AGI-3 Preivew Challenge에서 52 레벨 중 30개의 미디안 레벨을 해결하였으며 개인 리더보드에서 3위를 기록했습니다.

Conclusion: 명시적인 그래프 구조 탐사가 현재 LLM이 작업 역학을 포착하지 못하는 희박한 피드백 환경에서 강력한 베이스라인으로 작용할 수 있음을 보여줍니다.

Abstract: We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.

</details>


### [8] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: 위험 인식을 통합한 새로운 정책 정렬 방법인 RSA를 제안하며, 이는 안전과 신뢰성을 보장하기 위한 모델의 행동 조정에 기여한다.


<details>
  <summary>Details</summary>
Motivation: 미세 조정 시 위험 관리는 안전성과 신뢰성을 보장하는 데 필수적이다.

Method: 위험 인식 단계별 정렬(RSA) 방법은 중첩 위험 척도를 활용하여 정책 최적화 과정에 위험 인식을 명시적으로 통합한다.

Result: RSA는 위험을 완화하고 낮은 확률이지만 높은 영향력을 가진 유해 행동을 억제하며, 이론적 분석 결과도 제공한다.

Conclusion: 우리의 방법은 높은 유용성을 달성하면서 강력한 안전성을 보장하고 테일 리스크를 효과적으로 억제한다.

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [9] [Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents](https://arxiv.org/abs/2512.24461)
*Seohui Bae,Jeonghye Kim,Youngchul Sung,Woohyung Lim*

Main category: cs.AI

TL;DR: 본 논문에서는 부분 관측 하에서 작동하는 LLM 에이전트를 위해 그래디언트 기반 업데이트나 추가 학습에 의존하지 않고 후행 지침 기반 신념 정제를 통해 탐색적 추론을 수행하는 테스트 시간 적응 에이전트를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 이 연구의 목적은 부분적으로 관측 가능한 환경에서 LLM 에이전트의 추론 성능을 개선하는 것입니다.

Method: 제안하는 에이전트는 환경 상태에 대한 외부 구조적 신념을 유지하고, 행동 조건 관찰을 통해 이를 반복적으로 업데이트하며, 신념 공간에서 최대 정보 이익을 추구하여 행동을 선택합니다. 정보 이익은 경량 LLM 기반 대리 모델을 사용하여 추정하며, 후행 신념과 실제 환경 구성 간의 일관성을 정량화하는 새로운 보상을 통해 세계 정렬을 평가합니다.

Result: 실험 결과, 제안한 방법이 프롬프트 증강 또는 검색 강화 LLM과 같은 추론 시간 스케일링 기준선을 초월하여 잠재적인 세계 상태와의 정렬에서 통합 오버헤드가 현저히 낮았습니다.

Conclusion: 우리는 신념 정제 과정에서의 테스트 시간 적응 접근 방식이 저비용으로 신뢰성 높은 추론을 가능하게 한다는 것을 보여줍니다.

Abstract: In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.

</details>


### [10] [What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?](https://arxiv.org/abs/2512.24497)
*Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun*

Main category: cs.AI

TL;DR: AI 에이전트가 다양한 물리적 작업을 해결하고 새로운 작업과 환경에 일반화할 수 있도록 하는 방법에 대한 연구이다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 여러 물리적 작업을 해결하고 새로운 과제에 일반화할 수 있는 능력 개발.

Method: 상태-행동 궤적을 기반으로 세상 모델을 훈련하고, 이를 계획 알고리즘과 함께 사용하여 새로운 작업을 해결.

Result: 시뮬레이션 환경과 실제 로봇 데이터를 사용한 실험을 통해 모델 아키텍처, 훈련 목표, 계획 알고리즘이 계획 성공에 미치는 영향을 연구하였다.

Conclusion: 우리의 발견을 통해 탐색 및 조작 작업에서 두 개의 기존 기준선보다 우수한 성능을 가진 모델을 제안한다.

Abstract: A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.

</details>


### [11] [Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments](https://arxiv.org/abs/2512.24504)
*Zhiwei Wei,Yuxing Liu,Hua Liao,Wenjia Xu*

Main category: cs.AI

TL;DR: 이 논문은 기초 모델(FM) 에이전트가 심볼릭 맵 환경에서 탐색하고 기억하며 추론하는 방식을 분석하기 위한 상호작용 평가 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기초 모델(FM) 에이전트가 공간 구조를 이해하고 행동하는 방식에 대한 이해는 맵 기반 추론 및 응용 프로그램의 신뢰성을 향상시키는 데 중요하다.

Method: 부분적으로 관찰 가능한 그리드 기반 맵을 탐색하여 에이전트가 로드, 교차로 및 관심 지점(POI)으로 구성된 맵을 탐색하도록 하며, 각 단계에서 지역 관찰만을 받는다. 이를 통해 여섯 가지 종류의 공간 작업을 사용하여 공간 이해를 평가한다.

Result: 탐색 전략, 기억 표현, 추론 체계를 체계적으로 변화시킴으로써 이들 구성 요소의 독특한 기능적 역할을 발견하였다. 탐색은 경험 획득에 주로 영향을 미치지만 최종 추론 정확도에는 제한적인 영향을 미친다.

Conclusion: 공간 추론 성능은 모델 버전과 스케일에 따라 포화 상태에 이르며 특정 능력 임계값을 넘어서는 경우, 맵 기반의 공간 이해 개선은 단순한 스케일링이 아니라 공간 표현 및 추론에 맞춘 메커니즘이 필요함을 나타낸다.

Abstract: Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.

</details>


### [12] [MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use](https://arxiv.org/abs/2512.24565)
*Wenrui Liu,Zixiang Liu,Elsie Dai,Wenhan Yu,Lei Yu,Tong Yang*

Main category: cs.AI

TL;DR: MCPAgentBench는 도구 사용 능력을 평가하기 위한 벤치마크로, 실제 세계의 MCP 정의를 기반으로 하며, 복잡한 다단계 도구 호출 처리에서 성능 차이를 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 MCP 평가 세트는 외부 MCP 서비스에 의존하고 난이도 인식이 부족한 문제를 가지고 있습니다.

Method: MCPAgentBench는 실제 MCP 정의를 기반으로 하여 진짜 작업과 시뮬레이션된 MCP 도구를 포함하는 데이터 세트를 구성하고, 동적 샌드박스 환경에서 에이전트의 도구 선택 및 식별 능력을 테스트합니다.

Result: 실험 결과, 최신 대형 언어 모델이 복잡하고 다단계 도구 호출을 처리하는 데 상당한 성능 차이를 보였습니다.

Conclusion: 모든 코드는 Github에서 오픈 소스로 제공됩니다.

Abstract: Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.

</details>


### [13] [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)
*Dong Qiu,Duo Xu,Limengxi Yue*

Main category: cs.AI

TL;DR: 이 논문에서는 다중 에이전트 환경에서의 협업 성능을 최적화하기 위한 LLM 에이전트 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 언어 작업에서 뛰어난 성능을 보이지만 협업 인식 부족과 다중 에이전트 환경에서의 성능 최적화에 어려움을 겪는다.

Method: 협력을 분산된 부분 관측 마르코프 결정 과정(Dec-POMDP)으로 공식화하고, 중앙 집중 훈련과 분산 실행(CTDE)을 채택한다. 또한, 교육 중 글로벌 신호에 접근하여 에이전트 정책을 공동으로 최적화하는 그룹 상대 정책 최적화(GRPO)를 도입한다.

Result: 협업 작문 및 코딩 벤치마크에서, 우리의 프레임워크는 단일 에이전트 기준에 비해 작업 처리 속도가 3배 증가하고, 작문에서 98.7%의 구조/스타일 일관성을 보이며, 코딩에서 74.6%의 테스트 합격률을 달성했다.

Conclusion: 이 접근 방식은 강력한 다중 에이전트 LLM 기준을 지속적으로 초월하며 복잡한 워크플로에서 신뢰할 수 있는 협업을 위한 실질적인 경로를 제공한다.

Abstract: Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

</details>


### [14] [Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning](https://arxiv.org/abs/2512.24613)
*Zheyu Shi,Dong Qiu,Shanlong Yu*

Main category: cs.AI

TL;DR: 이 논문은 복잡한 추론 작업에서 단일 대형 언어 모델의 한계를 해결하기 위해 그룹 심의 지향의 다중 에이전트 대화 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 단일 대형 언어 모델이 복잡한 추론 작업에서의 성능이 제한적이라는 문제를 해결하고자 합니다.

Method: 생성, 검증 및 통합의 세 가지 역할 분담 아키텍처를 채택하여 궁극적으로 다양한 추론 관점을 생산하고, 외부 지식을 검색하고 사실적 지원을 정량화하며, 논리적으로 일관된 결론을 통합하는 에이전트들의 상호작용을 통해 구성됩니다.

Result: 실험 결과, 제안된 모델은 HotpotQA에서 16.8%, 2WikiMultihopQA에서 14.3%, MeetingBank에서 19.2%의 다중 경로 추론 정확도를 개선하고, 일관성을 21.5% 향상시켰습니다.

Conclusion: 이 모델은 주류 다중 에이전트 접근 방식보다 더 높은 추론 효율성을 달성하여 복잡한 추론 작업을 위한 효과적이고 안정적인 솔루션을 제공합니다.

Abstract: This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.

</details>


### [15] [Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization](https://arxiv.org/abs/2512.24615)
*Yuchen Shi,Yuzheng Cai,Siqi Cai,Zihan Xu,Lichao Chen,Yulei Qin,Zhijian Zhou,Xiang Fei,Chaofan Qiu,Xiaoyu Tan,Gang Li,Zongyi Li,Haojia Lin,Guocan Cai,Yong Mao,Yunsheng Wu,Ke Li,Xing Sun*

Main category: cs.AI

TL;DR: Youtu-Agent는 대규모 언어 모델 에이전트의 자동 생성과 지속적인 진화를 위한 모듈형 프레임워크로, 높은 구성 비용과 정적 능력 문제를 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 대규모 언어 모델 에이전트 프레임워크는 높은 구성 비용과 정적 능력이라는 두 가지 주요 과제에 직면해 있습니다.

Method: Youtu-Agent는 실행 환경, 툴킷 및 컨텍스트 관리를 분리하는 구조화된 구성 시스템과 표준 작업을 위한 Workflow 모드, 복잡한 비표준 요구를 위한 Meta-Agent 모드를 포함합니다.

Result: Youtu-Agent는 WebWalkerQA에서 71.47%와 GAIA에서 72.8%의 성능을 달성했습니다. 자동 생성 파이프라인은 81% 이상의 도구 합성 성공률을 기록했습니다.

Conclusion: Practice 모듈은 AIME 2024/2025에서 각각 +2.7% 및 +5.4%의 성능 향상을 이루었고, Agent RL 훈련은 7B LLM에서 40%의 속도 향상과 함께 성능을 안정적으로 개선했습니다.

Abstract: Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \textbf{Workflow} mode for standard tasks and a \textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\%) and GAIA (72.8\%) using open-weight models. Our automated generation pipeline achieves over 81\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\% and +5.4\% respectively. Moreover, our Agent RL training achieves 40\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\% and 21\% on Maths and general/multi-hop QA benchmarks.

</details>


### [16] [BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis](https://arxiv.org/abs/2512.24686)
*Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang*

Main category: cs.AI

TL;DR: 본 논문은 리튬 이온 배터리의 고장 진단을 위한 BatteryAgent라는 계층적 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 리튬 이온 배터리의 고장 진단은 시스템 안전성을 위해 매우 중요하다. 기존의 딥러닝 방법은 뛰어난 탐지 정확도를 보이지만 '블랙 박스' 특성으로 인해 해석 가능성이 제한된다.

Method: BatteryAgent는 물리적 지식 특징과 대형 언어 모델(LLMs)의 추론 능력을 통합한 계층적 프레임워크로 구성된다. 핵심 모듈은 물리적 인식 레이어, 탐지 및 귀속 레이어, 추론 및 진단 레이어를 포함한다.

Result: 실험 결과, BatteryAgent는 경계가 어려운 샘플에 대한 오분류를 효과적으로 수정하여 0.986의 AUROC를 달성하였으며, 이는 현재의 최첨단 방법보다 현저히 우수하다.

Conclusion: 이 프레임워크는 전통적인 이진 탐지를 다중 유형의 해석 가능한 진단으로 확장하여 배터리 안전 관리에서 '수동 탐지'에서 '지능형 진단'으로의 패러다임 전환을 제공한다.

Abstract: Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their "black-box" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a "numerical-semantic" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from "passive detection" to "intelligent diagnosis" for battery safety management.

</details>


### [17] [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)
*Weixun Wang,XiaoXiao Xu,Wanhe An,Fangwen Dai,Wei Gao,Yancheng He,Ju Huang,Qiang Ji,Hanqi Jin,Xiaoyang Li,Yang Li,Zhongwen Li,Shirong Lin,Jiashun Liu,Zenan Liu,Tao Luo,Dilxat Muhtar,Yuanbin Qu,Jiaqiang Shi,Qinghui Sun,Yingshui Tan,Hao Tang,Runze Wang,Yi Wang,Zhaoguo Wang,Yanan Wu,Shaopan Xiong,Binchen Xu,Xander Xu,Yuchi Xu,Qipeng Zhang,Xixia Zhang,Haizhou Zhao,Jie Zhao,Shuaibing Zhao,Baihui Zheng,Jianhui Zheng,Suhang Zheng,Yanni Zhu,Mengze Cai,Kerui Cao,Xitong Chen,Yue Dai,Lifan Du,Tao Feng,Tao He,Jin Hu,Yijie Hu,Ziyu Jiang,Cheng Li,Xiang Li,Jing Liang,Chonghuan Liu,ZhenDong Liu,Haodong Mi,Yanhu Mo,Junjia Ni,Shixin Pei,Jingyu Shen,XiaoShuai Song,Cecilia Wang,Chaofan Wang,Kangyu Wang,Pei Wang,Tao Wang,Wei Wang,Ke Xiao,Mingyu Xu,Tiange Xu,Nan Ya,Siran Yang,Jianan Ye,Yaxing Zang,Duo Zhang,Junbo Zhang,Boren Zheng,Wanxi Deng,Ling Pan,Lin Qu,Wenbo Su,Jiamang Wang,Wei Wang,Hu Wei,Minggang Wu,Cheng Yu,Bing Zhao,Zhicheng Zheng,Bo Zheng*

Main category: cs.AI

TL;DR: 이 논문은 LLM을 사용할 수 있는 에이전트 개발을 최적화하기 위한 Agentic Learning Ecosystem (ALE)을 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 개발을 간소화할 수 있는 원칙 있는 종합 생태계의 필요성이 있음.

Method: ALE는 ROLL, ROCK, iFlow CLI라는 세 가지 구성 요소로 이루어져 있으며, 데이터 구성 프로토콜과 Interaction-based Policy Alignment (IPA) 알고리즘을 포함합니다.

Result: ROME 에이전트는 국내에서 100만 개 이상의 트랙을 기반으로 훈련되어 벤치마크에서 강력한 성능을 입증하였습니다.

Conclusion: ALE 인프라의 효과성을 입증하며, ROME은 높은 성과를 기록했습니다.

Abstract: Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.

</details>


### [18] [AMAP Agentic Planning Technical Report](https://arxiv.org/abs/2512.24957)
*Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo*

Main category: cs.AI

TL;DR: STAgent는 복잡한 작업을 해결할 수 있도록 설계된 시공간 이해에 적합한 대형 언어 모델이다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업(제약 조건이 있는 관심 지점 발견 및 여행 일정 계획 등)을 해결하기 위해 시공간 이해를 위한 대형 언어 모델의 필요성이 대두됨.

Method: STAgent는 시공간 시나리오 내에서 열 개 이상의 도구와 상호 작용할 수 있는 전문화된 모델로, 복잡한 추론 과정 중 중간 단계를 탐색, 검증 및 개선할 수 있는 기능을 갖추고 있다.

Result: STAgent는 TravelBench에서 유망한 성과를 내며, 다양한 일반 벤치마크에서 일반적인 기능을 유지하고 있다.

Conclusion: 제안하는 에이전틱 모델의 효과성을 입증한다.

Abstract: We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.

</details>


### [19] [Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings](https://arxiv.org/abs/2512.25055)
*Tianzhi He,Farrokh Jazizadeh*

Main category: cs.AI

TL;DR: 이 연구는 자연어 상호작용을 통해 스마트 빌딩에서 상황 인식 에너지 관리를 촉진하기 위한 대규모 언어 모델(LLM) 기반 건물 에너지 관리 시스템(BEMS) AI 에이전트를 위한 개념적 프레임워크와 프로토타입 평가를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 스마트 빌딩에서의 효율적인 에너지 관리를 위한 상황 인식 접근의 필요성.

Method: 제안된 프레임워크는 지각(센서), 중앙 제어(브레인), 행동(구동 및 사용자 상호작용)의 세 모듈로 구성되어 있으며, 에너지 데이터를 수집하고 분석하여 사용자 쿼리에 지능적으로 응답하고 연결된 장치를 관리하는 폐쇄형 피드백 루프를 형성합니다.

Result: 120개의 사용자 쿼리를 사용하여 네 가지 서로 다른 실제 주거 에너지 데이터 세트에서 프로토타입의 성능을 평가하였으며, 응답 정확도는 장치 제어(86%), 메모리 관련 작업(97%), 스케줄링 및 자동화(74%), 에너지 분석(77%)에서 나타났습니다. 복잡한 비용 추정 작업에서는 49%의 정확도가 밝혀져 개선이 필요한 영역을 강조했습니다.

Conclusion: LLM 기반 BEMS AI 에이전트의 평가를 공식화하고, 응답 정확도와 계산 효율성 간의 절충점을 강조하며 미래 연구 방향을 식별하는 데 기여합니다.

Abstract: This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype's performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [20] [Safety-Biased Policy Optimisation: Towards Hard-Constrained Reinforcement Learning via Trust Regions](https://arxiv.org/abs/2512.23770)
*Ankit Kanwar,Dominik Wagner,Luke Ong*

Main category: cs.LG

TL;DR: 안전-critical 도메인에서 강화 학습(RL)은 에이전트가 안전 제약을 엄격히 준수하면서 보상을 극대화해야 합니다. SB-TRPO는 이러한 요구를 충족하는 새로운 알고리즘입니다.


<details>
  <summary>Details</summary>
Motivation: 안전-critical 도메인에서 에이전트가 보상을 극대화하면서 안전 제약을 준수해야 한다는 필요성이 있습니다.

Method: SB-TRPO는 제약 만족을 위해 정책 업데이트에 편향을 두고, 보상 향상도 추구하는 Trust-Region 알고리즘입니다.

Result: SB-TRPO는 안전성과 유의미한 작업 완료의 균형을 잘 유지하며, 기존 알고리즘보다 우수한 성능을 보입니다.

Conclusion: 이 알고리즘은 안전성을 보장하면서 보상 향상이 가능함을 이론적으로 보장합니다.

Abstract: Reinforcement learning (RL) in safety-critical domains requires agents to maximise rewards while strictly adhering to safety constraints. Existing approaches, such as Lagrangian and projection-based methods, often either fail to ensure near-zero safety violations or sacrifice reward performance in the face of hard constraints. We propose Safety-Biased Trust Region Policy Optimisation (SB-TRPO), a new trust-region algorithm for hard-constrained RL. SB-TRPO adaptively biases policy updates towards constraint satisfaction while still seeking reward improvement. Concretely, it performs trust-region updates using a convex combination of the natural policy gradients of cost and reward, ensuring a fixed fraction of optimal cost reduction at each step. We provide a theoretical guarantee of local progress towards safety, with reward improvement when gradients are suitably aligned. Experiments on standard and challenging Safety Gymnasium tasks show that SB-TRPO consistently achieves the best balance of safety and meaningful task completion compared to state-of-the-art methods.

</details>


### [21] [FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading](https://arxiv.org/abs/2512.23773)
*Molei Qin,Xinyu Cai,Yewen Li,Haochong Xia,Chuqiao Zong,Shuo Sun,Xinrun Wang,Bo An*

Main category: cs.LG

TL;DR: 이 논문에서는 고레버리지 및 유동성이 높은 선물 거래를 위한 효율적이고 위험 인식적인 강화 학습 프레임워크인 FineFT를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 고레버리지 환경에서의 훈련 어려움과 새로운 시장 상태에서의 잦은 손실 위험 문제 해결.

Method: 3단계 앙상블 강화 학습 프레임워크로, TD 오류 기반 선택적 Q 학습자 업데이트, 수익성 기반 Q 학습자 필터링, VAEs를 이용한 식별 및 보수적 정책 선택으로 구성.

Result: FineFT는 고주파 거래 환경에서 12개의 최신 기술 SOTA 기준과 비교하여 40% 이상의 위험 감소 및 뛰어난 수익성을 달성함.

Conclusion: 선택적 업데이트 메커니즘 시각화 결과, 다양한 에이전트가 특화된 시장 역학을 전문으로 하고 있으며, VAEs를 통한 라우팅이 최대 하락폭을 효과적으로 줄임을 입증함.

Abstract: Futures are contracts obligating the exchange of an asset at a predetermined date and price, notable for their high leverage and liquidity and, therefore, thrive in the Crypto market. RL has been widely applied in various quantitative tasks. However, most methods focus on the spot and could not be directly applied to the futures market with high leverage because of 2 challenges. First, high leverage amplifies reward fluctuations, making training stochastic and difficult to converge. Second, prior works lacked self-awareness of capability boundaries, exposing them to the risk of significant loss when encountering new market state (e.g.,a black swan event like COVID-19). To tackle these challenges, we propose the Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading (FineFT), a novel three-stage ensemble RL framework with stable training and proper risk management. In stage I, ensemble Q learners are selectively updated by ensemble TD errors to improve convergence. In stage II, we filter the Q-learners based on their profitabilities and train VAEs on market states to identify the capability boundaries of the learners. In stage III, we choose from the filtered ensemble and a conservative policy, guided by trained VAEs, to maintain profitability and mitigate risk with new market states. Through extensive experiments on crypto futures in a high-frequency trading environment with high fidelity and 5x leverage, we demonstrate that FineFT outperforms 12 SOTA baselines in 6 financial metrics, reducing risk by more than 40% while achieving superior profitability compared to the runner-up. Visualization of the selective update mechanism shows that different agents specialize in distinct market dynamics, and ablation studies certify routing with VAEs reduces maximum drawdown effectively, and selective update improves convergence and performance.

</details>


### [22] [Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems](https://arxiv.org/abs/2512.23809)
*Samaresh Kumar Singh,Joyjit Roy,Martin So*

Main category: cs.LG

TL;DR: 이 논문은 ZTA-FL을 제안하여 IIoT 배치의 침입 탐지를 개선하고 Byzantine 공격에 대한 방어력을 높입니다.


<details>
  <summary>Details</summary>
Motivation: 최근 IIoT 배치에서 발생한 보안 취약점을 해결하고 침입 탐지를 강화할 필요성이 대두되고 있습니다.

Method: ZTA-FL은 TPM 기반의 암호학적 증명, SHAP 가중치 집계 알고리즘, 프라이버시 보호 온디바이스 훈련을 결합합니다.

Result: ZTA-FL은 97.8%의 탐지 정확도와 30% Byzantine 공격 하에서 93.2%의 정확도를 달성하며 커뮤니케이션 오버헤드를 34% 감소시킵니다.

Conclusion: 이 연구는 IIoT의 보안과 침입 탐지의 개선을 위한 체계적인 접근 방식을 제시합니다.

Abstract: Recent attacks on critical infrastructure, including the 2021 Oldsmar water treatment breach and 2023 Danish energy sector compromises, highlight urgent security gaps in Industrial IoT (IIoT) deployments. While Federated Learning (FL) enables privacy-preserving collaborative intrusion detection, existing frameworks remain vulnerable to Byzantine poisoning attacks and lack robust agent authentication. We propose Zero-Trust Agentic Federated Learning (ZTA-FL), a defense in depth framework combining: (1) TPM-based cryptographic attestation achieving less than 0.0000001 false acceptance rate, (2) a novel SHAP-weighted aggregation algorithm providing explainable Byzantine detection under non-IID conditions with theoretical guarantees, and (3) privacy-preserving on-device adversarial training. Comprehensive experiments across three IDS benchmarks (Edge-IIoTset, CIC-IDS2017, UNSW-NB15) demonstrate that ZTA-FL achieves 97.8 percent detection accuracy, 93.2 percent accuracy under 30 percent Byzantine attacks (outperforming FLAME by 3.1 percent, p less than 0.01), and 89.3 percent adversarial robustness while reducing communication overhead by 34 percent. We provide theoretical analysis, failure mode characterization, and release code for reproducibility.

</details>


### [23] [Exploiting the Prior of Generative Time Series Imputation](https://arxiv.org/abs/2512.23832)
*YuYang Miao,Chang Li,Zehua Chen*

Main category: cs.LG

TL;DR: 이 논문은 Bridge-TS라는 새로운 생성 모델을 소개하며, 시간 시퀀스 결측값 보완을 위한 데이터 간 생성 프로세스를 개발하고, 두 가지 새로운 설계를 통해 정보를 개선한다.


<details>
  <summary>Details</summary>
Motivation: 시간 시퀀스 보완은 전력, 금융 및 날씨 모델링 등 여러 응용 분야에서 중요하다. 하지만 기존 방법들은 정확도가 낮고 계산 부담이 크다는 문제를 안고 있다.

Method: Bridge-TS를 제안하며, 이는 사전 정보를 개선하기 위해 사전 훈련된 변환기 기반 모듈을 전문가 prior로 활용하고, 여러 사전 훈련된 모델을 결합하여 조합 prior를 탐색한다.

Result: 여러 기준 데이터 세트에서 Bridge-TS는 평균 제곱 오차와 평균 절대 오차 측면에서 새로운 기록의 보완 정확도를 달성하였다.

Conclusion: 사전 설계를 개선함으로써 생성적인 시간 시퀀스 보완의 우수성을 입증하였다.

Abstract: Time series imputation, i.e., filling the missing values of a time recording, finds various applications in electricity, finance, and weather modelling. Previous methods have introduced generative models such as diffusion probabilistic models and Schrodinger bridge models to conditionally generate the missing values from Gaussian noise or directly from linear interpolation results. However, as their prior is not informative to the ground-truth target, their generation process inevitably suffer increased burden and limited imputation accuracy. In this work, we present Bridge-TS, building a data-to-data generation process for generative time series imputation and exploiting the design of prior with two novel designs. Firstly, we propose expert prior, leveraging a pretrained transformer-based module as an expert to fill the missing values with a deterministic estimation, and then taking the results as the prior of ground truth target. Secondly, we explore compositional priors, utilizing several pretrained models to provide different estimation results, and then combining them in the data-to-data generation process to achieve a compositional priors-to-target imputation process. Experiments conducted on several benchmark datasets such as ETT, Exchange, and Weather show that Bridge-TS reaches a new record of imputation accuracy in terms of mean square error and mean absolute error, demonstrating the superiority of improving prior for generative time series imputation.

</details>


### [24] [Max-Entropy Reinforcement Learning with Flow Matching and A Case Study on LQR](https://arxiv.org/abs/2512.23870)
*Yuyang Zhang,Yang Hu,Bo Dai,Na Li*

Main category: cs.LG

TL;DR: Soft Actor-Critic(SAC) 알고리즘의 변형을 제안하여 흐름 기반 모델을 사용하여 정책을 매개변수화한다.


<details>
  <summary>Details</summary>
Motivation: SAC 알고리즘에서 에너지 기반 정책은 효율성을 위해 종종 간단한 정책 클래스로 근사화되며 이로 인해 표현력과 강인성이 희생된다.

Method: 정책을 흐름 기반 모델로 매개변수화하고, 즉각적인 변환 변화 기법을 활용하여 흐름 기반 정책을 평가하며, 새로운 온라인 흐름 매칭 변형인 중요 샘플링 흐름 매칭(ISFM)을 통해 정책을 업데이트한다.

Result: 제안된 알고리즘이 최적의 행동 분포를 학습함을 보여주는 사례 연구를 실시했다.

Conclusion: ISFM의 이론적 분석을 개발하여 샘플링 분포의 다양한 선택이 학습 효율성에 미치는 영향을 설명했다.

Abstract: Soft actor-critic (SAC) is a popular algorithm for max-entropy reinforcement learning. In practice, the energy-based policies in SAC are often approximated using simple policy classes for efficiency, sacrificing the expressiveness and robustness. In this paper, we propose a variant of the SAC algorithm that parameterizes the policy with flow-based models, leveraging their rich expressiveness. In the algorithm, we evaluate the flow-based policy utilizing the instantaneous change-of-variable technique and update the policy with an online variant of flow matching developed in this paper. This online variant, termed importance sampling flow matching (ISFM), enables policy update with only samples from a user-specified sampling distribution rather than the unknown target distribution. We develop a theoretical analysis of ISFM, characterizing how different choices of sampling distributions affect the learning efficiency. Finally, we conduct a case study of our algorithm on the max-entropy linear quadratic regulator problems, demonstrating that the proposed algorithm learns the optimal action distribution.

</details>


### [25] [Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City](https://arxiv.org/abs/2512.23898)
*Tin Hoang*

Main category: cs.LG

TL;DR: 심층학습 아키텍처를 활용한 글로벌 수평 복사( GHI) 단기 예측에서 Transformer가 최상의 성능을 나타냄.


<details>
  <summary>Details</summary>
Motivation: GHI 예측의 신뢰성은 전력망에서 태양에너지의 변동성을 줄이는 데 필수적이다.

Method: 본 연구는 2011-2020년의 고해상도 NSRDB 위성 데이터를 활용하여 10개의 심층 학습 아키텍처의 성능을 비교하였다.

Result: Transformer 아키텍처가 최고의 예측 정확도(R²: 0.9696)를 달성하였다.

Conclusion: Knowledge Distillation 기법을 통해 Transformer의 성능을 유지하면서도 자원 제약이 있는 엣지 디바이스에서의 저지연 예측을 위한 경로를 제시하였다.

Abstract: Reliable forecasting of Global Horizontal Irradiance (GHI) is essential for mitigating the variability of solar energy in power grids. This study presents a comprehensive benchmark of ten deep learning architectures for short-term (1-hour ahead) GHI time series forecasting in Ho Chi Minh City, leveraging high-resolution NSRDB satellite data (2011-2020) to compare established baselines (e.g. LSTM, TCN) against emerging state-of-the-art architectures, including Transformer, Informer, iTransformer, TSMixer, and Mamba. Experimental results identify the Transformer as the superior architecture, achieving the highest predictive accuracy with an R^2 of 0.9696. The study further utilizes SHAP analysis to contrast the temporal reasoning of these architectures, revealing that Transformers exhibit a strong "recency bias" focused on immediate atmospheric conditions, whereas Mamba explicitly leverages 24-hour periodic dependencies to inform predictions. Furthermore, we demonstrate that Knowledge Distillation can compress the high-performance Transformer by 23.5% while surprisingly reducing error (MAE: 23.78 W/m^2), offering a proven pathway for deploying sophisticated, low-latency forecasting on resource-constrained edge devices.

</details>


### [26] [Assured Autonomy: How Operations Research Powers and Orchestrates Generative AI Systems](https://arxiv.org/abs/2512.23978)
*Tinglong Dai,David Simchi-Levi,Michelle Xiao Wu,Yao Xie*

Main category: cs.LG

TL;DR: 본 논문은 생성적 인공지능(GenAI)의 자율적 시스템 개발에 있어 발생하는 자율성 역설과 이를 해결하기 위한 개념적 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 생성적 인공지능이 점점 더 자율적인 의사결정 시스템으로 나아가면서 발생하는 자율성 역설을 다루고자 하며, 이는 운영적 자율성이 증가할수록 더 많은 형식적 구조와 명시적 제약을 필요로 함을 보여준다.

Method: 우리는 운영 연구(OR)에 기초한 보장된 자율성을 위한 개념적 프레임워크를 개발하였으며, 이는 두 가지 보완적인 접근 방식을 포함한다. 첫 번째는 흐름 기반 생성 모델을 이용하여 생성 과정을 결정론적 수송으로 구성하여 감사 가능성과 제약 인식을 도모하는 것이다. 두 번째는 운영 안전성을 적대적 강건성 관점에서 정의하여 의사결정 규칙을 평가하는 것이다.

Result: 이 프레임워크는 자율성이 증가함에 따라 운영 연구의 역할이 문제 해결자로부터 가드레일, 시스템 아키텍트로 전환됨을 명확히 하며, 여기에는 통제 논리, 인센티브 프로토콜, 모니터링 체계 및 안전 경계에 대한 책임이 포함된다.

Conclusion: 이러한 요소들은 안전이 중요한 운영 영역에서 보장된 자율성에 대한 연구 의제를 정의한다.

Abstract: Generative artificial intelligence (GenAI) is shifting from conversational assistants toward agentic systems -- autonomous decision-making systems that sense, decide, and act within operational workflows. This shift creates an autonomy paradox: as GenAI systems are granted greater operational autonomy, they should, by design, embody more formal structure, more explicit constraints, and stronger tail-risk discipline. We argue stochastic generative models can be fragile in operational domains unless paired with mechanisms that provide verifiable feasibility, robustness to distribution shift, and stress testing under high-consequence scenarios. To address this challenge, we develop a conceptual framework for assured autonomy grounded in operations research (OR), built on two complementary approaches. First, flow-based generative models frame generation as deterministic transport characterized by an ordinary differential equation, enabling auditability, constraint-aware generation, and connections to optimal transport, robust optimization, and sequential decision control. Second, operational safety is formulated through an adversarial robustness lens: decision rules are evaluated against worst-case perturbations within uncertainty or ambiguity sets, making unmodeled risks part of the design. This framework clarifies how increasing autonomy shifts OR's role from solver to guardrail to system architect, with responsibility for control logic, incentive protocols, monitoring regimes, and safety boundaries. These elements define a research agenda for assured autonomy in safety-critical, reliability-sensitive operational domains.

</details>


### [27] [Hyperspherical Graph Representation Learning via Adaptive Neighbor-Mean Alignment and Uniformity](https://arxiv.org/abs/2512.24062)
*Rui Chen,Junjun Guo,Hongbin Wang,Yan Xiang,Yantuan Xian,Zhengtao Yu*

Main category: cs.LG

TL;DR: HyperGRL은 하이퍼구 내부에서 그래프 표현 학습을 수행하는 통합 프레임워크로, 이웃 평균 정렬과 샘플링 없는 균일성을 통해 안정적인 임베딩 분포를 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 그래프 표현 학습 방법들은 복잡한 아키텍처와 민감한 하이퍼파라미터 조정을 요구하며, 이는 학습 불안정성 및 과도한 스무딩을 초래할 수 있습니다.

Method: HyperGRL은 이웃 평균 정렬 및 샘플링 없는 균일성을 통해 하이퍼구 표면에 노드를 임베딩합니다.

Result: HyperGRL은 기존의 최강 방법들보다 평균 1.49%, 0.86%, 0.74%의 성능 향상을 보였습니다.

Conclusion: 이 연구는 геометр하게 기반한, 샘플링 없는 대조 목표가 그래프 표현 학습에 효과적임을 입증합니다.

Abstract: Graph representation learning (GRL) aims to encode structural and semantic dependencies of graph-structured data into low-dimensional embeddings. However, existing GRL methods often rely on surrogate contrastive objectives or mutual information maximization, which typically demand complex architectures, negative sampling strategies, and sensitive hyperparameter tuning. These design choices may induce over-smoothing, over-squashing, and training instability. In this work, we propose HyperGRL, a unified framework for hyperspherical graph representation learning via adaptive neighbor-mean alignment and sampling-free uniformity. HyperGRL embeds nodes on a unit hypersphere through two adversarially coupled objectives: neighbor-mean alignment and sampling-free uniformity. The alignment objective uses the mean representation of each node's local neighborhood to construct semantically grounded, stable targets that capture shared structural and feature patterns. The uniformity objective formulates dispersion via an L2-based hyperspherical regularization, encouraging globally uniform embedding distributions while preserving discriminative information. To further stabilize training, we introduce an entropy-guided adaptive balancing mechanism that dynamically regulates the interplay between alignment and uniformity without requiring manual tuning. Extensive experiments on node classification, node clustering, and link prediction demonstrate that HyperGRL delivers superior representation quality and generalization across diverse graph structures, achieving average improvements of 1.49%, 0.86%, and 0.74% over the strongest existing methods, respectively. These findings highlight the effectiveness of geometrically grounded, sampling-free contrastive objectives for graph representation learning.

</details>


### [28] [Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning](https://arxiv.org/abs/2512.24069)
*Xusheng Zhang,Tuan Nguyen,Ting He*

Main category: cs.LG

TL;DR: 무선 네트워크에서 분산 연합 학습을 위한 혼합 행렬 설계를 다루며, 최대 개별 노드 에너지 소비를 최소화하는 데 초점을 맞춘다.


<details>
  <summary>Details</summary>
Motivation: 분산 연합 학습에서 혼합 행렬은 수렴 속도와 에이전트 간 통신 요구를 모두 제어하는 중요한 하이퍼파라미터로, 에너지 제약 장치에 중요한 개별 노드 에너지 소비를 최소화해야 할 필요가 있다.

Method: 시간 변화가 가능한 혼합 행렬을 허용하는 새로운 수렴 정리를 기반으로 하여, 최적화된 예산 하에 개별 반복 에너지 소비와 수렴 속도의 균형을 맞추는 다중 단계 설계 프레임워크를 제안한다.

Result: 제안된 솔루션은 희소 혼합 행렬의 낮은 에너지 소비와 밀집 혼합 행렬의 빠른 수렴을 결합하는 데 효과적임을 실제 데이터에 기반하여 검증했다.

Conclusion: 혼합 행렬 설계를 위한 이론적으로 정당화된 솔루션을 제공함으로써, 무선 통신의 방송 특성을 고려하여 최대 개별 노드 에너지 소비를 최소화할 수 있는 기회를 제시한다.

Abstract: We consider the design of mixing matrices to minimize the operation cost for decentralized federated learning (DFL) in wireless networks, with focus on minimizing the maximum per-node energy consumption. As a critical hyperparameter for DFL, the mixing matrix controls both the convergence rate and the needs of agent-to-agent communications, and has thus been studied extensively. However, existing designs mostly focused on minimizing the communication time, leaving open the minimization of per-node energy consumption that is critical for energy-constrained devices. This work addresses this gap through a theoretically-justified solution for mixing matrix design that aims at minimizing the maximum per-node energy consumption until convergence, while taking into account the broadcast nature of wireless communications. Based on a novel convergence theorem that allows arbitrarily time-varying mixing matrices, we propose a multi-phase design framework that activates time-varying communication topologies under optimized budgets to trade off the per-iteration energy consumption and the convergence rate while balancing the energy consumption across nodes. Our evaluations based on real data have validated the efficacy of the proposed solution in combining the low energy consumption of sparse mixing matrices and the fast convergence of dense mixing matrices.

</details>


### [29] [Enhancing LLM Planning Capabilities through Intrinsic Self-Critique](https://arxiv.org/abs/2512.24103)
*Bernd Bohnet,Pierre-Alexandre Kamienny,Hanie Sedghi,Dilan Gorur,Pranjal Awasthi,Aaron Parisi,Kevin Swersky,Rosanne Liu,Azade Nova,Noah Fiedel*

Main category: cs.LG

TL;DR: 이 논문은 LLM이 자기 비판을 통해 성능을 향상시키는 방법을 시연하며, Blocksworld 도메인에서 계획 데이터셋에 대해 단독 비판을 통해 중요한 성능 개선을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 이 연구의 동기는 LLM이 자기 비판 방법을 활용하는 것에 대한 효과성에 대한 의구심을 극복하고, 계획 성능을 향상시키는 것입니다.

Method: 우리는 소수의 샷 학습 기법을 사용하고 점진적으로 다수의 샷 접근 방식으로 확장하여, 수정 및 개선을 위한 반복 과정으로 상당한 개선을 달성할 수 있음을 보여줍니다.

Result: Blocksworld 도메인 및 Logistics와 Mini-grid 데이터셋에서 강력한 기준 정확도를 초과하는 성능 향상을 입증했습니다.

Conclusion: 우리는 자기 비판이 계획 성능을 크게 향상시킬 수 있음을 보여주었으며, 더 복잡한 탐색 기법과 더 뛰어난 모델에 우리 방법을 적용하면 더 나은 성능으로 이어질 것이라고 믿습니다.

Abstract: We demonstrate an approach for LLMs to critique their \emph{own} answers with the goal of enhancing their performance that leads to significant improvements over established planning benchmarks. Despite the findings of earlier research that has cast doubt on the effectiveness of LLMs leveraging self critique methods, we show significant performance gains on planning datasets in the Blocksworld domain through intrinsic self-critique, without external source such as a verifier. We also demonstrate similar improvements on Logistics and Mini-grid datasets, exceeding strong baseline accuracies. We employ a few-shot learning technique and progressively extend it to a many-shot approach as our base method and demonstrate that it is possible to gain substantial improvement on top of this already competitive approach by employing an iterative process for correction and refinement. We illustrate how self-critique can significantly boost planning performance. Our empirical results present new state-of-the-art on the class of models considered, namely LLM model checkpoints from October 2024. Our primary focus lies on the method itself, demonstrating intrinsic self-improvement capabilities that are applicable regardless of the specific model version, and we believe that applying our method to more complex search techniques and more capable models will lead to even better performance.

</details>


### [30] [GARDO: Reinforcing Diffusion Models without Reward Hacking](https://arxiv.org/abs/2512.24138)
*Haoran He,Yuxiao Ye,Jie Liu,Jiajun Liang,Zhiyong Wang,Ziyang Yuan,Xintao Wang,Hangyu Mao,Pengfei Wan,Ling Pan*

Main category: cs.LG

TL;DR: GARDO는 샘플 효율성과 탐색, 보상 해킹 완화를 동시에 고려한 프레임워크로, 선택적 정규화와 적응형 정규화를 통해 텍스트-이미지 정렬을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 강화 학습을 통한 확산 모델의 미세 조정은 텍스트-이미지 정렬을 강화하는 데 큰 잠재력을 보여주지만, 비주얼 작업을 위한 진정한 목표를 정확하게 지정하는 것이 쉽지 않아 대리 보상을 사용하게 된다.

Method: GARDO는 선택적 정규화를 도입하여 높은 불확실성을 보이는 샘플에 대해서만 정규화를 적용하고, 기준 모델을 주기적으로 업데이트하여 탐색 과정에서의 정규화 대상을 적절히 조정한다.

Result: GARDO는 다양한 대리 보상과 보류된 보이지 않는 메트릭에서 실험을 통해 보상 해킹을 완화하고 생성 다양성을 개선함을 입증하였다.

Conclusion: GARDO는 샘플 효율성이나 탐색을 희생하지 않고도 보상 해킹을 완화하고 생성 다양성을 높임으로써 효과성과 강인성을 강조한다.

Abstract: Fine-tuning diffusion models via online reinforcement learning (RL) has shown great potential for enhancing text-to-image alignment. However, since precisely specifying a ground-truth objective for visual tasks remains challenging, the models are often optimized using a proxy reward that only partially captures the true goal. This mismatch often leads to reward hacking, where proxy scores increase while real image quality deteriorates and generation diversity collapses. While common solutions add regularization against the reference policy to prevent reward hacking, they compromise sample efficiency and impede the exploration of novel, high-reward regions, as the reference policy is usually sub-optimal. To address the competing demands of sample efficiency, effective exploration, and mitigation of reward hacking, we propose Gated and Adaptive Regularization with Diversity-aware Optimization (GARDO), a versatile framework compatible with various RL algorithms. Our key insight is that regularization need not be applied universally; instead, it is highly effective to selectively penalize a subset of samples that exhibit high uncertainty. To address the exploration challenge, GARDO introduces an adaptive regularization mechanism wherein the reference model is periodically updated to match the capabilities of the online policy, ensuring a relevant regularization target. To address the mode collapse issue in RL, GARDO amplifies the rewards for high-quality samples that also exhibit high diversity, encouraging mode coverage without destabilizing the optimization process. Extensive experiments across diverse proxy rewards and hold-out unseen metrics consistently show that GARDO mitigates reward hacking and enhances generation diversity without sacrificing sample efficiency or exploration, highlighting its effectiveness and robustness.

</details>


### [31] [Colorful Pinball: Density-Weighted Quantile Regression for Conditional Guarantee of Conformal Prediction](https://arxiv.org/abs/2512.24139)
*Qianyi Chen,Bo Li*

Main category: cs.LG

TL;DR: 이 논문은 표준 일치 예측 절차의 조건부 커버리지를 개선하기 위한 새로운 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 조건부 커버리지 문제를 해결하여 특정 입력에 대한 신뢰할 수 있는 예측을 가능하게 하고자 합니다.

Method: 조건부 커버리지의 평균 제곱 오차를 최소화하기 위해 많은 일치 방법의 기본이 되는 분위수 회귀 구성 요소를 개선합니다. 타일러 전개를 활용하여 분위수 회귀를 위한 밀도 가중 핀볼 손실의 샤프한 대리 목표를 도출합니다.

Result: 우리는 보조 분위수 수준을 사용하여 이러한 가중치를 추정하고, 이후 가중 손실을 최적화하여 중앙 분위수를 세밀하게 조정하는 세 개의 헤드 기간 네트워크를 제안합니다. 이론적 분석과 실험을 통해 이웃 재험 위험을 특성화합니다.

Conclusion: 다양한 고차원 실제 데이터 세트에서 조건부 커버리지 성능이 크게 개선됨을 보여줍니다.

Abstract: While conformal prediction provides robust marginal coverage guarantees, achieving reliable conditional coverage for specific inputs remains challenging. Although exact distribution-free conditional coverage is impossible with finite samples, recent work has focused on improving the conditional coverage of standard conformal procedures. Distinct from approaches that target relaxed notions of conditional coverage, we directly minimize the mean squared error of conditional coverage by refining the quantile regression components that underpin many conformal methods. Leveraging a Taylor expansion, we derive a sharp surrogate objective for quantile regression: a density-weighted pinball loss, where the weights are given by the conditional density of the conformity score evaluated at the true quantile. We propose a three-headed quantile network that estimates these weights via finite differences using auxiliary quantile levels at \(1-α\pm δ\), subsequently fine-tuning the central quantile by optimizing the weighted loss. We provide a theoretical analysis with exact non-asymptotic guarantees characterizing the resulting excess risk. Extensive experiments on diverse high-dimensional real-world datasets demonstrate remarkable improvements in conditional coverage performance.

</details>


### [32] [Early Prediction of Sepsis using Heart Rate Signals and Genetic Optimized LSTM Algorithm](https://arxiv.org/abs/2512.24253)
*Alireza Rafiei,Farshid Hajati,Alireza Rezaee,Amirhossien Panahi,Shahadat Uddin*

Main category: cs.LG

TL;DR: 이 연구는 웨어러블 장치를 통한 패혈증 예측을 위한 네 가지 기계 학습 알고리즘을 소개하고 평가한다.


<details>
  <summary>Details</summary>
Motivation: 패혈증은 감염에 대한 조절되지 않은 면역 반응으로, 사망률, 질병 부담, 의료비용이 높다. 조기 개입을 통해 나쁜 결과를 줄이기 위해 패혈증 진행의 신속한 예측이 중요하다.

Method: 심박수 데이터를 분석하여 웨어러블 장치에서 패혈증의 발병을 예측하는 네 가지 새로운 기계 학습 알고리즘을 도입하고 평가했다. 이 모델의 아키텍처는 성능, 계산 복잡성 및 메모리 요구 사항을 최적화하는 유전자 알고리즘을 통해 정교화되었다.

Result: 각 모델의 성능 metric을 추출하여 정확한 심박수 모니터링이 가능한 웨어러블 장치에서의 구현 가능성을 평가했다. 모델은 처음에 1시간의 예측 기간을 설정한 후, 전이 학습을 통해 4시간으로 확장되었다.

Conclusion: 이 연구의 고무적인 결과는 웨어러블 기술이 ICU 및 병실 환경 외부에서 조기 패혈증 감지를 촉진할 가능성을 보여준다.

Abstract: Sepsis, characterized by a dysregulated immune response to infection, results in significant mortality, morbidity, and healthcare costs. The timely prediction of sepsis progression is crucial for reducing adverse outcomes through early intervention. Despite the development of numerous models for Intensive Care Unit (ICU) patients, there remains a notable gap in approaches for the early detection of sepsis in non-ward settings. This research introduces and evaluates four novel machine learning algorithms designed for predicting the onset of sepsis on wearable devices by analyzing heart rate data. The architecture of these models was refined through a genetic algorithm, optimizing for performance, computational complexity, and memory requirements. Performance metrics were subsequently extracted for each model to evaluate their feasibility for implementation on wearable devices capable of accurate heart rate monitoring. The models were initially tailored for a prediction window of one hour, later extended to four hours through transfer learning. The encouraging outcomes of this study suggest the potential for wearable technology to facilitate early sepsis detection outside ICU and ward environments.

</details>


### [33] [HOLOGRAPH: Active Causal Discovery via Sheaf-Theoretic Alignment of Large Language Model Priors](https://arxiv.org/abs/2512.24478)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: 관찰 데이터로부터 인과 관계를 발견하는 것은 식별 가능성 제약으로 제한됩니다. 본 논문에서는 LLM(대규모 언어 모델)을 이용한 인과 관계 발견 프레임워크인 HOLOGRAPH를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 관찰 데이터를 통한 인과 발견의 한계, LLM을 활용한 이전 인과 지식의 실용가능성 탐색.

Method: HOLOGRAPH 프레임워크는 소형 집합 위에서의 프레시프의 섹션으로 지역적 인과적 믿음을 표현하여 LLM을 안내하는 인과 발견을 형식화합니다. Algebraic Latent Projection과 Natural Gradient Descent를 통해 최적화를 수행합니다.

Result: HOLOGRAPH는 50-100 변수에 대한 인과 발견 작업에서 경쟁력 있는 성능을 달성하며 엄격한 수학적 기초를 제공합니다.

Conclusion: 인과 구조가 지역적으로 비결정적이라는 우려가 있으며, 더욱 큰 그래프에서는 국소성 공리가 실패하는 것으로 나타났습니다.

Abstract: Causal discovery from observational data remains fundamentally limited by identifiability constraints. Recent work has explored leveraging Large Language Models (LLMs) as sources of prior causal knowledge, but existing approaches rely on heuristic integration that lacks theoretical grounding. We introduce HOLOGRAPH, a framework that formalizes LLM-guided causal discovery through sheaf theory--representing local causal beliefs as sections of a presheaf over variable subsets. Our key insight is that coherent global causal structure corresponds to the existence of a global section, while topological obstructions manifest as non-vanishing sheaf cohomology. We propose the Algebraic Latent Projection to handle hidden confounders and Natural Gradient Descent on the belief manifold for principled optimization. Experiments on synthetic and real-world benchmarks demonstrate that HOLOGRAPH provides rigorous mathematical foundations while achieving competitive performance on causal discovery tasks with 50-100 variables. Our sheaf-theoretic analysis reveals that while Identity, Transitivity, and Gluing axioms are satisfied to numerical precision (<10^{-6}), the Locality axiom fails for larger graphs, suggesting fundamental non-local coupling in latent variable projections. Code is available at [https://github.com/hyunjun1121/holograph](https://github.com/hyunjun1121/holograph).

</details>


### [34] [CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts](https://arxiv.org/abs/2512.24564)
*Shunbo Jia,Caizhi Liao*

Main category: cs.LG

TL;DR: 심전도(ECG) 진단을 위한 딥 러닝 모델은 뛰어난 정확도를 보이지만, 생물학적 형태를 모방하는 Smooth Adversarial Perturbations(SAP)에 취약하다. 이 논문에서는 Causal Physiological Representation Learning(CPR)을 제안하여 이 문제를 해결하고, CPR이 표준 임상 전처리 방법보다 우수한 성능을 보여주었다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: ECG 진단 모델의 취약성을 해결하기 위한 새로운 접근 방식을 제안하고자 한다.

Method: Causal Physiological Representation Learning(CPR)을 통해 인과적 분리 프레임워크 내에서 생리학적 구조 사전(prior)을 통합하여 ECG 생성을 모델링하는 방식이다.

Result: CPR은 PTB-XL 데이터 세트에서 MDT 스무딩보다 9.1% 향상된 0.632의 F1 점수를 기록하며 표준 임상 전처리 방법보다 상당한 성능 향상을 보여준다.

Conclusion: CPR은 임상 해석 가능성과 단일 통과 추론 효율성을 유지하면서 Randomized Smoothing의 인증된 강인성에 필적하는 뛰어난 균형을 제공한다.

Abstract: Deep learning models for Electrocardiogram (ECG) diagnosis have achieved remarkable accuracy but exhibit fragility against adversarial perturbations, particularly Smooth Adversarial Perturbations (SAP) that mimic biological morphology. Existing defenses face a critical dilemma: Adversarial Training (AT) provides robustness but incurs a prohibitive computational burden, while certified methods like Randomized Smoothing (RS) introduce significant inference latency, rendering them impractical for real-time clinical monitoring. We posit that this vulnerability stems from the models' reliance on non-robust spurious correlations rather than invariant pathological features. To address this, we propose Causal Physiological Representation Learning (CPR). Unlike standard denoising approaches that operate without semantic constraints, CPR incorporates a Physiological Structural Prior within a causal disentanglement framework. By modeling ECG generation via a Structural Causal Model (SCM), CPR enforces a structural intervention that strictly separates invariant pathological morphology (P-QRS-T complex) from non-causal artifacts. Empirical results on PTB-XL demonstrate that CPR significantly outperforms standard clinical preprocessing methods. Specifically, under SAP attacks, CPR achieves an F1 score of 0.632, surpassing Median Smoothing (0.541 F1) by 9.1%. Crucially, CPR matches the certified robustness of Randomized Smoothing while maintaining single-pass inference efficiency, offering a superior trade-off between robustness, efficiency, and clinical interpretability.

</details>


### [35] [From Trial to Deployment: A SEM Analysis of Traveler Adoptions to Fully Operational Autonomous Taxis](https://arxiv.org/abs/2512.24767)
*Yutong Cai,Hua Wang*

Main category: cs.LG

TL;DR: 자율 택시 서비스는 도시 이동성의 혁신적인 발전을 나타내며, 안전성, 효율성 및 24시간 운영을 제공합니다. 본 연구는 실제 사용자 행동을 조사하여 자율 택시에 대한 사용자 수용을 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 실제 운영 AV 서비스에 기반한 사용자 행동을 조사하는 것의 중요성을 강조합니다.

Method: 우한, 중국에서 Baidu의 Apollo Robotaxi 서비스에 대한 설문 조사 데이터를 수집하고, 실질적인 서비스 속성을 반영한 설문을 설계하여 336명의 유효 응답을 수집했습니다. 구조 방정식 모델링을 사용하여 신뢰 및 정책 지원, 비용 민감도, 성과, 행동 의도, 라이프스타일, 교육의 여섯 가지 잠재적 심리적 구성 요소를 확인했습니다.

Result: 비용 민감도와 행동 의도가 채택의 가장 강력한 양의 예측 변수로 나타났으며, 다른 잠재적 구성 요소는 보다 미묘한 역할을 했습니다.

Conclusion: 결과는 정책 결정, 요금 설계 및 자율 택시 운영 확대를 위한 대중 홍보 전략에 대한 실증적 증거를 제공합니다.

Abstract: Autonomous taxi services represent a transformative advancement in urban mobility, offering safety, efficiency, and round-the-clock operations. While existing literature has explored user acceptance of autonomous taxis through stated preference experiments and hypothetical scenarios, few studies have investigated actual user behavior based on operational AV services. This study addresses that gap by leveraging survey data from Wuhan, China, where Baidu's Apollo Robotaxi service operates at scale. We design a realistic survey incorporating actual service attributes and collect 336 valid responses from actual users. Using Structural Equation Modeling, we identify six latent psychological constructs, namely Trust \& Policy Support, Cost Sensitivity, Performance, Behavioral Intention, Lifestyle, and Education. Their influences on adoption behavior, measured by the selection frequency of autonomous taxis in ten scenarios, are examined and interpreted. Results show that Cost Sensitivity and Behavioral Intention are the strongest positive predictors of adoption, while other latent constructs play more nuanced roles. The model demonstrates strong goodness-of-fit across multiple indices. Our findings offer empirical evidence to support policymaking, fare design, and public outreach strategies for scaling autonomous taxis deployments in real-world urban settings.

</details>


### [36] [Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics](https://arxiv.org/abs/2512.24827)
*Raul D. Steleac,Mohan Sridharan,David Abel*

Main category: cs.LG

TL;DR: 이 논문은 다중 에이전트 환경에서의 옵션 발견을 위한 새로운 접근 방식을 제안하며, 더욱 효과적인 조정을 위한 상태 공간 압축 기법을 개발한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 환경에서의 조정된 행동을 개선하기 위한 옵션 발견의 필요성.

Method: 상태 압축을 위한 공동 상태 추상화 기법을 사용하고, 상태 동기화를 캡처하기 위해 신경 그래프 라플라시안 추정기를 활용한다.

Result: 다양한 시나리오에서 기존의 옵션 발견 방법과 비교하여 더 강력한 조정 능력을 나타낸다.

Conclusion: 제안된 방법은 다중 에이전트 환경에서 조정 행동을 발견하는 데 있어 효과적이다.

Abstract: Temporally extended actions improve the ability to explore and plan in single-agent settings. In multi-agent settings, the exponential growth of the joint state space with the number of agents makes coordinated behaviours even more valuable. Yet, this same exponential growth renders the design of multi-agent options particularly challenging. Existing multi-agent option discovery methods often sacrifice coordination by producing loosely coupled or fully independent behaviours. Toward addressing these limitations, we describe a novel approach for multi-agent option discovery. Specifically, we propose a joint-state abstraction that compresses the state space while preserving the information necessary to discover strongly coordinated behaviours. Our approach builds on the inductive bias that synchronisation over agent states provides a natural foundation for coordination in the absence of explicit objectives. We first approximate a fictitious state of maximal alignment with the team, the \textit{Fermat} state, and use it to define a measure of \textit{spreadness}, capturing team-level misalignment on each individual state dimension. Building on this representation, we then employ a neural graph Laplacian estimator to derive options that capture state synchronisation patterns between agents. We evaluate the resulting options across multiple scenarios in two multi-agent domains, showing that they yield stronger downstream coordination capabilities compared to alternative option discovery methods.

</details>


### [37] [AODDiff: Probabilistic Reconstruction of Aerosol Optical Depth via Diffusion-based Bayesian Inference](https://arxiv.org/abs/2512.24847)
*Linhao Fan,Hongqiang Fang,Jingyang Dai,Yong Jiang,Qixing Zhang*

Main category: cs.LG

TL;DR: AOD 모델의 재구성을 위한 AODDiff 프레임워크를 제안하며, 이는 불완전한 데이터를 활용하여 효과적인 재구성을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: AOD 필드의 고품질 재구성이 대기 모니터링에 필수적이나, 현재 모델들은 훈련 데이터의 부족과 불확실성 정량화의 결여로 제한받고 있다.

Method: 확산 기반 베이지안 추론에 기반한 확률적 재구성 프레임워크인 AODDiff를 제안하며, 자연적으로 불완전한 데이터를 통해 시공간 AOD 사전 분포를 학습하고, 이질적인 관측값의 통합을 위한 분리된 냉각 후 샘플링 전략을 사용한다.

Result: 재분석 데이터를 사용한 광범위한 실험을 통해 AODDiff의 효과성과 강인성을 검증하였으며, 고Spatial Spectral Fidelity를 유지하는데 유리함을 보여주었다.

Conclusion: AODDiff는 생성 모델로서 여러 샘플링을 통해 불확실성 정량화를 자연스럽게 가능하게 하며, 하위 응용 프로그램에 대한 중요한 신뢰 지표를 제공한다.

Abstract: High-quality reconstruction of Aerosol Optical Depth (AOD) fields is critical for Atmosphere monitoring, yet current models remain constrained by the scarcity of complete training data and a lack of uncertainty quantification.To address these limitations, we propose AODDiff, a probabilistic reconstruction framework based on diffusion-based Bayesian inference. By leveraging the learned spatiotemporal probability distribution of the AOD field as a generative prior, this framework can be flexibly adapted to various reconstruction tasks without requiring task-specific retraining. We first introduce a corruption-aware training strategy to learns a spatiotemporal AOD prior solely from naturally incomplete data. Subsequently, we employ a decoupled annealing posterior sampling strategy that enables the more effective and integration of heterogeneous observations as constraints to guide the generation process. We validate the proposed framework through extensive experiments on Reanalysis data. Results across downscaling and inpainting tasks confirm the efficacy and robustness of AODDiff, specifically demonstrating its advantage in maintaining high spatial spectral fidelity. Furthermore, as a generative model, AODDiff inherently enables uncertainty quantification via multiple sampling, offering critical confidence metrics for downstream applications.

</details>


### [38] [Spectral Graph Neural Networks for Cognitive Task Classification in fMRI Connectomes](https://arxiv.org/abs/2512.24901)
*Debasis Maji,Arghya Banerjee,Debaditya Barman*

Main category: cs.LG

TL;DR: 이 연구에서는 기계 학습을 활용한 인지 작업 분류를 통해 뇌 상태를 해독하고, 뇌 네트워크 분석과 통합하여 복잡한 연결 패턴을 추출하는 새로운 모델을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인지 작업 분류는 신경영상 데이터에서 뇌 상태를 해독하는 데 중요한 역할을 합니다.

Method: 제안된 SpectralBrainGNN 모델은 정규화된 라플라시안 고유분해를 통해 계산된 그래프 푸리에 변환(GFT)을 기반으로 한 스펙트럼 컨볼루션 프레임워크입니다.

Result: Human Connectome Project-Task(HCPTask) 데이터셋에서 실험 결과, 제안된 접근 방식은 96.25%의 분류 정확도를 달성했습니다.

Conclusion: 이 구현은 재현성과 향후 연구를 지원하기 위해 공개적으로 제공됩니다.

Abstract: Cognitive task classification using machine learning plays a central role in decoding brain states from neuroimaging data. By integrating machine learning with brain network analysis, complex connectivity patterns can be extracted from functional magnetic resonance imaging connectomes. This process transforms raw blood-oxygen-level-dependent (BOLD) signals into interpretable representations of cognitive processes. Graph neural networks (GNNs) further advance this paradigm by modeling brain regions as nodes and functional connections as edges, capturing topological dependencies and multi-scale interactions that are often missed by conventional approaches. Our proposed SpectralBrainGNN model, a spectral convolution framework based on graph Fourier transforms (GFT) computed via normalized Laplacian eigendecomposition. Experiments on the Human Connectome Project-Task (HCPTask) dataset demonstrate the effectiveness of the proposed approach, achieving a classification accuracy of 96.25\%. The implementation is publicly available at https://github.com/gnnplayground/SpectralBrainGNN to support reproducibility and future research.

</details>


### [39] [Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning](https://arxiv.org/abs/2512.24959)
*András Antos,András Millinghoffer,Péter Antal*

Main category: cs.LG

TL;DR: 본 논문은 Sequential Support Network Learning (SSNL)이라는 새로운 프레임워크를 통해 다수의 참여자를 위한 최적의 파트너 후보 집합을 선택하는 문제를 해결하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 현대 AI 및 ML 문제는 파트너의 기여도를 평가하고 가장 유익한 후보를 동시에 선택해야 합니다.

Method: 우리는 semi-overlapping multi-(multi-armed) bandit (SOMMAB) 모델을 개발하고, 이를 통해 희소한 후보 목록에서 지원 네트워크를 효율적으로 학습할 수 있음을 보여줍니다.

Result: 일반화된 GapE 알고리즘을 개발하고 새로운 지수 오차 경계를 도출하여 다중 밴디트의 최적 팔 선택 문제의 성능을 개선합니다.

Conclusion: 이 연구는 다중 학습 문제에서 희소 후보로부터 지원 네트워크를 식별하기 위한 순차 학습 도구에 대한 이론적 기초와 성능 보장을 제공합니다.

Abstract: Many modern AI and ML problems require evaluating partners' contributions through shared yet asymmetric, computationally intensive processes and the simultaneous selection of the most beneficial candidates. Sequential approaches to these problems can be unified under a new framework, Sequential Support Network Learning (SSNL), in which the goal is to select the most beneficial candidate set of partners for all participants using trials; that is, to learn a directed graph that represents the highest-performing contributions. We demonstrate that a new pure-exploration model, the semi-overlapping multi-(multi-armed) bandit (SOMMAB), in which a single evaluation provides distinct feedback to multiple bandits due to structural overlap among their arms, can be used to learn a support network from sparse candidate lists efficiently.
  We develop a generalized GapE algorithm for SOMMABs and derive new exponential error bounds that improve the best known constant in the exponent for multi-bandit best-arm identification. The bounds scale linearly with the degree of overlap, revealing significant sample-complexity gains arising from shared evaluations.
  From an application point of view, this work provides a theoretical foundation and improved performance guarantees for sequential learning tools for identifying support networks from sparse candidates in multiple learning problems, such as in multi-task learning (MTL), auxiliary task learning (ATL), federated learning (FL), and in multi-agent systems (MAS).

</details>


### [40] [ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning](https://arxiv.org/abs/2512.25023)
*Timo Kaufmann,Yannick Metz,Daniel Keim,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: 본 논문은 노이즈가 포함된 강도 신호로부터 학습하기 위한 ResponseRank라는 새로운 방법 을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 이 논문은 인간 피드백에 의한 강화학습(RLHF)에서 이진 선택이 선호의 방향만 전달하고 강도를 측정하기 어렵다는 문제를 해결하고자 합니다.

Method: ResponseRank는 상대적인 차이를 이용해 쌍 비교에 대한 응답을 선호 강도에 따라 순위 매깁니다.

Result: Divers한 작업에서의 샘플 효율성 및 강건성의 개선을 보여주는 경험적 증거를 제공합니다.

Conclusion: Pearson Distance Correlation(PDC)라는 새로운 지표가 기수 유틸리티 학습을 순서 정확성과 분리하는 데 기여합니다.

Abstract: Binary choices, as often used for reinforcement learning from human feedback (RLHF), convey only the direction of a preference. A person may choose apples over oranges and bananas over grapes, but which preference is stronger? Strength is crucial for decision-making under uncertainty and generalization of preference models, but hard to measure reliably. Metadata such as response times and inter-annotator agreement can serve as proxies for strength, but are often noisy and confounded. We propose ResponseRank to address the challenge of learning from noisy strength signals. Our method uses relative differences in proxy signals to rank responses to pairwise comparisons by their inferred preference strength. To control for systemic variation, we compare signals only locally within carefully constructed strata. This enables robust learning of utility differences consistent with strength-derived rankings while making minimal assumptions about the strength signal. Our contributions are threefold: (1) ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals; (2) empirical evidence of improved sample efficiency and robustness across diverse tasks: synthetic preference learning (with simulated response times), language modeling (with annotator agreement), and RL control tasks (with simulated episode returns); and (3) the Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [41] [Audited Skill-Graph Self-Improvement for Agentic LLMs via Verifiable Rewards, Experience Synthesis, and Continual Memory](https://arxiv.org/abs/2512.23760)
*Ken Huang,Jerry Huang*

Main category: cs.CR

TL;DR: 이 논문은 자기 개선을 검증 가능하고 재사용 가능한 능력의 축적으로 재구성하며, 자기 개선 인공지능의 평가 및 운영 거버넌스를 위한 실질적인 경로를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습은 대규모 언어 모델을 에이전트 시스템으로 변화시키는 데 점점 더 많이 사용되고 있으며, 이는 긴 시간 동안 행동하고 도구를 호출하며 부분 관찰 하에 메모리를 관리합니다.

Method: 이 논문은 자기 개선을 에이전트를 점점 더 성장하는 검증 가능 스킬 그래프에 반복적으로 컴파일하는 것으로 간주하는 Audited Skill-Graph Self-Improvement (ASG-SI) 프레임워크를 제안합니다. 각 후보 개선은 성공적인 경로에서 추출되어 명시적 인터페이스를 가진 스킬로 정규화되며, 검증자 지원 리플레이 및 계약 검사를 통과한 후에만 승격됩니다.

Result: 우리는 완전한 시스템 아키텍처, 위협 모델 및 보안 분석을 제시하고, 검증자 지원 보상 구성, 스킬 컴파일, 감사 로그 기록 및 지속적인 작업 스트림 하에서 측정 가능한 개선을 시연하는 완전 구현을 제공합니다.

Conclusion: ASG-SI는 에이전트 자기 개선을 검증 가능하고 재사용 가능한 능력의 축적으로 재구성하여 자기 개선 인공지능 에이전트의 재현 가능한 평가 및 운영 거버넌스를 위한 실질적인 경로를 제공합니다.

Abstract: Reinforcement learning is increasingly used to transform large language models into agentic systems that act over long horizons, invoke tools, and manage memory under partial observability. While recent work has demonstrated performance gains through tool learning, verifiable rewards, and continual training, deployed self-improving agents raise unresolved security and governance challenges: optimization pressure can incentivize reward hacking, behavioral drift is difficult to audit or reproduce, and improvements are often entangled in opaque parameter updates rather than reusable, verifiable artifacts.
  This paper proposes Audited Skill-Graph Self-Improvement (ASG-SI), a framework that treats self-improvement as iterative compilation of an agent into a growing, auditable skill graph. Each candidate improvement is extracted from successful trajectories, normalized into a skill with an explicit interface, and promoted only after passing verifier-backed replay and contract checks. Rewards are decomposed into reconstructible components derived from replayable evidence, enabling independent audit of promotion decisions and learning signals. ASG-SI further integrates experience synthesis for scalable stress testing and continual memory control to preserve long-horizon performance under bounded context.
  We present a complete system architecture, threat model, and security analysis, and provide a fully runnable reference implementation that demonstrates verifier-backed reward construction, skill compilation, audit logging, and measurable improvement under continual task streams. ASG-SI reframes agentic self-improvement as accumulation of verifiable, reusable capabilities, offering a practical path toward reproducible evaluation and operational governance of self-improving AI agents.

</details>


### [42] [MeLeMaD: Adaptive Malware Detection via Chunk-wise Feature Selection and Meta-Learning](https://arxiv.org/abs/2512.23987)
*Ajvad Haneef K,Karan Kuwar Singh,Madhu Kumar S D*

Main category: cs.CR

TL;DR: MeLeMaD는 새로운 메타 학습 프레임워크로, 사이버 보안에서 악성코드 탐지의 효율성을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 사이버 보안에서 악성코드 탐지는 끊임없이 진화하는 위협 환경에서 강력하고 적응 가능한 솔루션이 필요하다.

Method: MeLeMaD는 모델에 독립적인 메타 학습(MAML)의 적응성과 일반화 능력을 활용하며, 대규모 고차원 악성코드 데이터셋을 처리하기 위한 새로운 특징 선택 기법(CFSGB)을 포함한다.

Result: MeLeMaD는 CIC-AndMal2020과 BODMAS라는 두 개의 벤치마크 악성코드 데이터셋과 사용자 지정 데이터셋(EMBOD)을 통해 검증되었으며, 정확도 98.04% 및 99.97%를 기록하여 최신 기술을 초월하는 성능을 보였다.

Conclusion: MeLeMaD는 악성코드 탐지의 강인성, 적응성 및 대규모 고차원 데이터셋 문제를 해결할 잠재력을 보여준다.

Abstract: Confronting the substantial challenges of malware detection in cybersecurity necessitates solutions that are both robust and adaptable to the ever-evolving threat environment. The paper introduces Meta Learning Malware Detection (MeLeMaD), a novel framework leveraging the adaptability and generalization capabilities of Model-Agnostic Meta-Learning (MAML) for malware detection. MeLeMaD incorporates a novel feature selection technique, Chunk-wise Feature Selection based on Gradient Boosting (CFSGB), tailored for handling large-scale, high-dimensional malware datasets, significantly enhancing the detection efficiency. Two benchmark malware datasets (CIC-AndMal2020 and BODMAS) and a custom dataset (EMBOD) were used for rigorously validating the MeLeMaD, achieving a remarkable performance in terms of key evaluation measures, including accuracy, precision, recall, F1-score, MCC, and AUC. With accuracies of 98.04\% on CIC-AndMal2020 and 99.97\% on BODMAS, MeLeMaD outperforms the state-of-the-art approaches. The custom dataset, EMBOD, also achieves a commendable accuracy of 97.85\%. The results underscore the MeLeMaD's potential to address the challenges of robustness, adaptability, and large-scale, high-dimensional datasets in malware detection, paving the way for more effective and efficient cybersecurity solutions.

</details>


### [43] [SourceBroken: A large-scale analysis on the (un)reliability of SourceRank in the PyPI ecosystem](https://arxiv.org/abs/2512.24400)
*Biagio Montaruli,Serena Elisa Ponta,Luca Compagna,Davide Balzarotti*

Main category: cs.CR

TL;DR: SourceRank의 신뢰성이 악의적 패키지를 부풀리기 위한 회피 공격에 대해 분석됨.


<details>
  <summary>Details</summary>
Motivation: SourceRank는 오픈 소스 패키지의 인기와 품질을 평가하기 위한 18개의 메트릭으로 구성된 점수 시스템이다. 최근의 여러 연구에서 사용되었지만, 악의적 패키지를 신뢰할 수 있는 것으로 가장하기 위한 회피 공격에 대한 신뢰성 분석은 없었다.

Method: 각 메트릭에 대해 URL 혼동 기법을 포함한 잠재적 회피 접근 방식을 식별하는 위협 모델을 제안하고, MalwareBench 데이터셋 및 122,398개의 실세계 패키지 데이터셋에서 SourceRank의 분포를 분석한다.

Result: 분석 결과, 역사적인 데이터에서는 악의적 패키지와 유익한 패키지 간의 뚜렷한 구분이 나타나지만, 실세계 분포에서는 크게 겹친다. 이는 SourceRank가 패키지 제거를 제때 반영하지 못했기 때문이다.

Conclusion: 결과적으로, SourceRank는 실세계 시나리오에서 악의적 패키지와 유익한 패키지를 구별하는 데 신뢰할 수 없으며, PyPI에 있는 유익한 패키지를 선택하는 데에도 적합하지 않다.

Abstract: SourceRank is a scoring system made of 18 metrics that assess the popularity and quality of open-source packages. Despite being used in several recent studies, none has thoroughly analyzed its reliability against evasion attacks aimed at inflating the score of malicious packages, thereby masquerading them as trustworthy. To fill this gap, we first propose a threat model that identifies potential evasion approaches for each metric, including the URL confusion technique, which can affect 5 out of the 18 metrics by leveraging a URL pointing to a legitimate repository potentially unrelated to the malicious package.
  Furthermore, we study the reliability of SourceRank in the PyPI ecosystem by analyzing the SourceRank distributions of benign and malicious packages in the state-of-the-art MalwareBench dataset, as well as in a real-world dataset of 122,398 packages. Our analysis reveals that, while historical data suggests a clear distinction between benign and malicious packages, the real-world distributions overlap significantly, mainly due to SourceRank's failure to timely reflect package removals. As a result, SourceRank cannot be reliably used to discriminate between benign and malicious packages in real-world scenarios, nor to select benign packages among those available on PyPI.
  Finally, our analysis reveals that URL confusion represents an emerging attack vector, with its prevalence increasing from 4.2% in MalwareBench to 7.0% in our real-world dataset. Moreover, this technique is often used alongside other evasion techniques and can significantly inflate the SourceRank metrics of malicious packages.

</details>


### [44] [Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service](https://arxiv.org/abs/2512.24415)
*Jingyu Zhang*

Main category: cs.CR

TL;DR: 고객 서비스 LLM 에이전트는 정책에 따른 결정을 내리지만, 일부 사용자가 이를 악용하여 비용을 다른 이들에게 전가하고 신뢰를 훼손할 수 있다. 본 연구는 고객 서비스 상호작용에서의 이익 추구형 직간접 주입에 대한 벤치마크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 고객 서비스 LLM 에이전트가 정책에 기반한 결정을 내리는 과정에서 같은 상호작용 스타일이 악용될 수 있다는 점에 주목하였다.

Method: 10개 서비스 도메인과 5개의 기법 계열로 그룹화된 100개의 현실적인 공격 스크립트를 포함한 교차 도메인 벤치마크를 만들었다.

Result: 다섯 가지 널리 사용되는 모델을 적용한 결과, 공격은 도메인과 기법에 따라 크게 달라지는 것으로 확인되었다.

Conclusion: 재현 가능한 감사 지원과 신뢰할 수 있는 인간 중심의 에이전트 인터페이스를 위한 감독 및 회복 워크플로 설계를 위해 데이터를 공개하였다.

Abstract: Customer-service LLM agents increasingly make policy-bound decisions (refunds, rebooking, billing disputes), but the same ``helpful'' interaction style can be exploited: a small fraction of users can induce unauthorized concessions, shifting costs to others and eroding trust in agentic workflows. We present a cross-domain benchmark of profit-seeking direct prompt injection in customer-service interactions, spanning 10 service domains and 100 realistic attack scripts grouped into five technique families. Across five widely used models under a unified rubric with uncertainty reporting, attacks are highly domain-dependent (airline support is most exploitable) and technique-dependent (payload splitting is most consistently effective). We release data and evaluation code to support reproducible auditing and to inform the design of oversight and recovery workflows for trustworthy, human centered agent interfaces.

</details>


### [45] [Training-Free Color-Aware Adversarial Diffusion Sanitization for Diffusion Stegomalware Defense at Security Gateways](https://arxiv.org/abs/2512.24499)
*Vladimir Frants,Sos Agaian*

Main category: cs.CR

TL;DR: 생성 AI의 빠른 확장은 대규모 합성 미디어 생성을 정상화하여 은밀한 의사소통의 새로운 형태를 가능하게 했다. 최근 생성 스테가노그래피 방법은 높은 용량의 페이로드를 삽입할 수 있지만 탐지와 수정에 대한 도전 과제를 초래한다. 이 연구에서는 Adversarial Diffusion Sanitization (ADS)를 소개하며, 이는 보안 게이트웨이에 대한 훈련 없는 방어 솔루션으로, 숨겨진 페이로드를 탐지하기보다는 중화시키는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 생성 AI의 성장으로 인해 대규모 합성 미디어 생성이 보편화되면서 새로운 형태의 은밀한 의사소통이 가능해진 점.

Method: Adversarial Diffusion Sanitization (ADS)라는 훈련 없는 방어 방법을 제안하며, 미리 훈련된 디노이저를 활용하여 분산 기반 디코더의 차별화 가능한 프록시로 사용하고, 색상을 인식하는 사원수 결합 업데이트 규칙을 도입하여 왜곡 한계를 줄인다.

Result: 실용적인 위협 모델 하에서 최신 분산 스테가노그래피 방법인 Pulsar에 대해 평가했으며, ADS는 매우 낮은 인식적 영향을 주면서 디코더의 성공률을 거의 0에 가깝게 낮춘다.

Conclusion: ADS는 표준 콘텐츠 변환과 비교할 때 유리한 보안-유용성 균형을 제공하며, 분산 기반 스테가노그래피에 대한 효과적인 완화 전략을 제공한다.

Abstract: The rapid expansion of generative AI has normalized large-scale synthetic media creation, enabling new forms of covert communication. Recent generative steganography methods, particularly those based on diffusion models, can embed high-capacity payloads without fine-tuning or auxiliary decoders, creating significant challenges for detection and remediation. Coverless diffusion-based techniques are difficult to counter because they generate image carriers directly from secret data, enabling attackers to deliver stegomalware for command-and-control, payload staging, and data exfiltration while bypassing detectors that rely on cover-stego discrepancies. This work introduces Adversarial Diffusion Sanitization (ADS), a training-free defense for security gateways that neutralizes hidden payloads rather than detecting them. ADS employs an off-the-shelf pretrained denoiser as a differentiable proxy for diffusion-based decoders and incorporates a color-aware, quaternion-coupled update rule to reduce artifacts under strict distortion limits. Under a practical threat model and in evaluation against the state-of-the-art diffusion steganography method Pulsar, ADS drives decoder success rates to near zero with minimal perceptual impact. Results demonstrate that ADS provides a favorable security-utility trade-off compared to standard content transformations, offering an effective mitigation strategy against diffusion-driven steganography.

</details>


### [46] [Practical Traceable Over-Threshold Multi-Party Private Set Intersection](https://arxiv.org/abs/2512.24652)
*Le Yang,Weijing You,Huiyang He,Kailiang Ji,Jingqiang Lin*

Main category: cs.CR

TL;DR: MP-PSI에 임계값을 추가하여 각 세트에 나타나는 요소 수를 유연하게 한다. 두 가지 새로운 프로토콜을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 각 참가자가 자신의 데이터셋을 책임지는 시나리오에서, MP-PSI는 교차 요소와 해당 소유자를 공개하여 요소를 추적 가능하게 해야 한다.

Method: 효율적인 Traceable OT-MP-PSI(ET-OT-MP-PSI)는 Shamir의 비밀 분배를 oblivious 프로그래머블 의사난수 함수와 결합하고, Security-enhanced Traceable OT-MP-PSI(ST-OT-MP-PSI)는 oblivious 선형 평가 프로토콜을 추가로 활용한다.

Result: ET-OT-MP-PSI는 $15056	imes$ 속도 향상을 달성하고, ST-OT-MP-PSI는 $505	imes$ 속도 향상을 이룬다.

Conclusion: 이 연구는 현재까지의 연구보다 더 많은 반诚실 참가자를 처리할 수 있는 프로토콜을 제공한다.

Abstract: Multi-Party Private Set Intersection (MP-PSI) with threshold enhances the flexibility of MP-PSI by disclosing elements present in at least $t$ participants' sets, rather than requiring elements to appear in all $n$ sets. In scenarios where each participant is responsible for its dataset, e.g., digital forensics, MP-PSI with threshold should disclose both intersection elements and corresponding holders such that elements are traceable and the reliability of intersection is guaranteed. We refer to MP-PSI with threshold supporting traceability as Traceable Over-Threshold MP-PSI (T-OT-MP-PSI). However, research on such protocols remains limited, and existing work tolerates at most $t-2$ semi-honest participants at considerable computational cost. We propose two novel Traceable OT-MP-PSI protocols. The first, Efficient Traceable OT-MP-PSI (ET-OT-MP-PSI), combines Shamir's secret sharing with an oblivious programmable pseudorandom function, achieving significantly improved efficiency with resistance to at most $t-2$ semi-honest participants. The second, Security-enhanced Traceable OT-MP-PSI (ST-OT-MP-PSI), achieves security against up to $n-1$ semi-honest participants by further leveraging the oblivious linear evaluation protocol. Compared to Mahdavi et al.'s protocol, ours eliminate the assumption that certain special parties do not collude. Experimental results demonstrate significant improvements: for $n=5$, $t=3$, and sets of size $2^{14}$, ET-OT-MP-PSI achieves $15056\times$ speedup and ST-OT-MP-PSI achieves $505\times$ speedup over Mahdavi et al.'s protocol.

</details>


### [47] [Towards Provably Secure Generative AI: Reliable Consensus Sampling](https://arxiv.org/abs/2512.24925)
*Yu Cui,Hang Fu,Sicheng Pan,Zhuoyu Sun,Yifei Liu,Yuhong Nie,Bo Ran,Baohan Huang,Xufeng Zhang,Haibin Zhang,Cong Zuo,Licheng Wang*

Main category: cs.CR

TL;DR: 이 논문은 안전한 생성 AI를 구축하기 위한 새로운 방법인 Reliable Consensus Sampling(RCS)를 제안하며, 이는 극단적인 적대적 행동을 수용할 수 있는 수용 확률을 추적하여 강력성을 개선하고, 전혀 중단 없이 작동할 수 있도록 합니다.


<details>
  <summary>Details</summary>
Motivation: 생성 AI 보안에 대한 기존 연구는 경험에 기반한 상호 보완적인 공격 및 방어 방법론에 의해 주도되며, 이는 새로운 공격이 발생할 가능성을 높이고 있습니다. 따라서 안전한 생성 AI 구축이 필요합니다.

Method: 생성 AI의 고장 보장을 위해 Reliable Consensus Sampling(RCS)라는 새로운 원시를 제안하고, 안전성을 지속적으로 강화하기 위한 피드백 알고리즘을 개발하였습니다.

Result: RCS는 강력성과 유용성을 동시에 향상시키며, CS와 유사한 지연 시간으로 작동합니다.

Conclusion: 이 연구는 확실한 보안을 갖춘 생성 AI 개발에 기여할 것으로 기대됩니다.

Abstract: Existing research on generative AI security is primarily driven by mutually reinforcing attack and defense methodologies grounded in empirical experience. This dynamic frequently gives rise to previously unknown attacks that can circumvent current detection and prevention. This necessitates the continual updating of security mechanisms. Constructing generative AI with provable security and theoretically controllable risk is therefore necessary. Consensus Sampling (CS) is a promising algorithm toward provably secure AI. It controls risk by leveraging overlap in model output probabilities. However, we find that CS relies on frequent abstention to avoid unsafe outputs, which reduces utility. Moreover, CS becomes highly vulnerable when unsafe models are maliciously manipulated. To address these issues, we propose a new primitive called Reliable Consensus Sampling (RCS), that traces acceptance probability to tolerate extreme adversarial behaviors, improving robustness. RCS also eliminates the need for abstention entirely. We further develop a feedback algorithm to continuously and dynamically enhance the safety of RCS. We provide theoretical guarantees that RCS maintains a controllable risk threshold. Extensive experiments show that RCS significantly improves robustness and utility while maintaining latency comparable to CS. We hope this work contributes to the development of provably secure generative AI.

</details>
