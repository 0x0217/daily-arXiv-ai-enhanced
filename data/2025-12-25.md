<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 2]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.LG](#cs.LG) [Total: 16]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [A Multi-Agent Retrieval-Augmented Framework for Work-in-Progress Predictio](https://arxiv.org/abs/2512.19841)
*Yousef Mehrdad Bibalan,Behrouz Far,Mohammad Moshirpour,Bahareh Ghiyasian*

Main category: cs.MA

TL;DR: 본 논문은 작업 진행 예측을 위한 회수 증대 다중 에이전트 프레임워크를 제안하며, 이는 예측 정확도를 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 작업 진행 예측은 예측 프로세스 모니터링에 중요한 요소로, 작업 부하 변화의 정확한 예측과 최적의 운영 계획을 가능하게 합니다.

Method: 회수 증대 생성(RAG)과 협업 다중 에이전트 추론을 결합한 프레임워크를 제안하며, 사건 로그를 의미적으로 풍부한 자연어 이야기로 변환합니다.

Result: 우리의 프레임워크를 두 개의 실제 기준 데이터세트에서 평가한 결과, 제안된 접근 방식은 경쟁력 있는 예측 정확도를 달성했습니다.

Conclusion: 회수 메커니즘과 다중 에이전트 추론 통합의 효과를 입증하며, 더욱 향상된 견고성을 보여줍니다.

Abstract: Work-in-Progress (WiP) prediction is critical for predictive process monitoring, enabling accurate anticipation of workload fluctuations and optimized operational planning. This paper proposes a retrieval-augmented, multi-agent framework that combines retrieval-augmented generation (RAG) and collaborative multi-agent reasoning for WiP prediction. The narrative generation component transforms structured event logs into semantically rich natural language stories, which are embedded into a semantic vector-based process memory to facilitate dynamic retrieval of historical context during inference. The framework includes predictor agents that independently leverage retrieved historical contexts and a decision-making assistant agent that extracts high-level descriptive signals from recent events. A fusion agent then synthesizes predictions using ReAct-style reasoning over agent outputs and retrieved narratives. We evaluate our framework on two real-world benchmark datasets. Results show that the proposed retrieval-augmented multi-agent approach achieves competitive prediction accuracy, obtaining a Mean Absolute Percentage Error (MAPE) of 1.50\% on one dataset, and surpassing Temporal Convolutional Networks (TCN), Long Short-Term Memory (LSTM), and persistence baselines. The results highlight improved robustness, demonstrating the effectiveness of integrating retrieval mechanisms and multi-agent reasoning in WiP prediction.

</details>


### [2] [When Natural Strategies Meet Fuzziness and Resource-Bounded Actions (Extended Version)](https://arxiv.org/abs/2512.20457)
*Marco Aruta,Francesco Improta,Vadim Malvone,Aniello Murano*

Main category: cs.MA

TL;DR: 이 논문은 인지적 비용과 불확실성을 고려한 인간의 의사결정 추론을 위한 새로운 논리인 HumanATLF를 도입합니다.


<details>
  <summary>Details</summary>
Motivation: MAS에서 인간의 의사결정 방식과 실제 환경에서의 제약을 반영하기 위해.

Method: HumanATLF는 모호한 의미와 자원 제한 행동을 사용하는 자연 전략을 기반으로 한 논리이다. 각 행동은 비가역적 예산에서 추출한 실제 가치를 가진 비용을 수반하며, 원자 조건과 목표는 [0,1]의 범위를 가진다.

Result: 모델 검증은 전략 복잡성 k와 자원 예산 b가 고정된 경우 P 클래스에 속하고, 불리안 목표에 대해 하나의 전략 연산자만 허용된 경우 NP 완전하며, k와 b가 변할 때 Delta^P_2 완전하다. 또한, 회상 기반 전략은 PSPACE에서 결정 가능하다.

Conclusion: 이 알고리즘은 VITAMIN이라는 오픈 소스 모델 검증 도구에서 구현되었으며, 자원 인식 드론 구조 시나리오에서 검증되었다.

Abstract: In formal strategic reasoning for Multi-Agent Systems (MAS), agents are typically assumed to (i) employ arbitrarily complex strategies, (ii) execute each move at zero cost, and (iii) operate over fully crisp game structures. These idealized assumptions stand in stark contrast with human decision making in real world environments. The natural strategies framework along with some of its recent variants, partially addresses this gap by restricting strategies to concise rules guarded by regular expressions. Yet, it still overlook both the cost of each action and the uncertainty that often characterizes human perception of facts over the time. In this work, we introduce HumanATLF, a logic that builds upon natural strategies employing both fuzzy semantics and resource bound actions: each action carries a real valued cost drawn from a non refillable budget, and atomic conditions and goals have degrees in [0,1]. We give a formal syntax and semantics, and prove that model checking is in P when both the strategy complexity k and resource budget b are fixed, NP complete if just one strategic operator over Boolean objectives is allowed, and Delta^P_2 complete when k and b vary. Moreover, we show that recall based strategies can be decided in PSPACE. We implement our algorithms in VITAMIN, an open source model checking tool for MAS and validate them on an adversarial resource aware drone rescue scenario.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [3] [Fast Deterministically Safe Proof-of-Work Consensus](https://arxiv.org/abs/2512.19968)
*Ali Farahbakhsh,Giuliano Losa,Youer Pu,Lorenzo Alvisi,Ittay Eyal*

Main category: cs.CR

TL;DR: 우리는 외부 메커니즘에 의존하지 않고 결정론적 보안과 일정한 예상 지연 시간을 제공하는 최초의 완전 비허가 프로토콜인 Sieve-MMR을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 비허가 블록체인은 알려지지 않은 노드가 언제든지 시스템에 참여하고 떠날 수 있는 상태에서 합의를 이루는 것을 목표로 한다. 그러나 기존의 PoW 및 PoS 프로토콜은 각각의 취약성을 가지고 있다.

Method: Sieve-MMR은 기존의 PoS 프로토콜인 MMR을 PoW 환경으로 이식하여 얻은 것이다. 우리는 MMR에서 일정한 예상 지연 시간과 결정론적 보안을 상속받고, PoW는 장거리 공격에 대한 회복력을 제공한다.

Result: MMR을 PoW 환경으로 포팅하는 주요 도전은 시간 여행 공격이라고 불리는 공격 방식이다. 우리는 새로운 전파 원리에 해당하는 시간 여행 복원 전파(TTRB)를 구현하는 Sieve라는 새로운 알고리즘을 제안한다.

Conclusion: Sieve는 TTRB를 구현하기 위해 블랙 박스 형태의 결정론적 PoW 원리에 의존하며, 이를 MMR의 메시징 레이어로 사용한다.

Abstract: Permissionless blockchains achieve consensus while allowing unknown nodes to join and leave the system at any time. They typically come in two flavors: proof of work (PoW) and proof of stake (PoS), and both are vulnerable to attacks. PoS protocols suffer from long-range attacks, wherein attackers alter execution history at little cost, and PoW protocols are vulnerable to attackers with enough computational power to subvert execution history. PoS protocols respond by relying on external mechanisms like social consensus; PoW protocols either fall back to probabilistic guarantees, or are slow.
  We present Sieve-MMR, the first fully-permissionless protocol with deterministic security and constant expected latency that does not rely on external mechanisms. We obtain Sieve-MMR by porting a PoS protocol (MMR) to the PoW setting. From MMR we inherit constant expected latency and deterministic security, and proof-of-work gives us resilience against long-range attacks. The main challenge to porting MMR to the PoW setting is what we call time-travel attacks, where attackers use PoWs generated in the distant past to increase their perceived PoW power in the present. We respond by proposing Sieve, a novel algorithm that implements a new broadcast primitive we dub time-travel-resilient broadcast (TTRB). Sieve relies on a black-box, deterministic PoW primitive to implement TTRB, which we use as the messaging layer for MMR.

</details>


### [4] [BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations](https://arxiv.org/abs/2512.19997)
*Yanjing Yang,He Zhang,Bohan Liu,Jinwei Xu,Jinghao Hu,Liming Dong,Zhewen Mao,Dongxue Pan*

Main category: cs.CR

TL;DR: BAC 위반 탐지를 위한 \\BAC 접근법을 제안하며, API 트래픽 데이터를 생성하여 활용한다.


<details>
  <summary>Details</summary>
Motivation: BAC 위반은 OWASP API 보안 Top 10에서 주요 보안 위험으로, 그 탐지가 필수적이다.

Method: ac는 API 트래픽 생성기와 BAC 탐지기로 구성되어 BAC 위반 탐지 모델을 구축한다.

Result: 실험 결과 \\BAC는 기존의 최신 기술을 초과하여 F1과 MCC가 각각 21.2% 및 24.1% 향상되었다.

Conclusion: 이 연구는 BAC 탐지의 새로운 가능성을 보여준다.

Abstract: Broken Access Control (BAC) violations, which consistently rank among the top five security risks in the OWASP API Security Top 10, refer to unauthorized access attempts arising from BAC vulnerabilities, whose successful exploitation can impose significant risks on exposed application programming interfaces (APIs). In recent years, learning-based methods have demonstrated promising prospects in detecting various types of malicious activities. However, in real-network operation and maintenance scenarios, leveraging learning-based methods for BAC detection faces two critical challenges. Firstly, under the RESTful API design principles, most systems omit recording composite traffic for performance, and together with ethical and legal bans on directly testing real-world systems, this leads to a critical shortage of training data for detecting BAC violations. Secondly, common malicious behaviors such as SQL injection typically generate individual access traffic that is inherently anomalous. In contrast, BAC is usually composed of multiple correlated access requests that appear normal when examined in isolation. To tackle these problems, we introduce \BAC, an approach for establishing a BAC violation detection model by generating and utilizing API traffic data. The \BAC consists of an API Traffic Generator and a BAC Detector. Experimental results show that \BAC outperforms current state-of-the-art invariant-based and learning-based methods with the $\text{F}_1$ and MCC improving by 21.2\% and 24.1\%.

</details>


### [5] [On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities](https://arxiv.org/abs/2512.20062)
*Sangryu Park,Gihyuk Ko,Homook Cho*

Main category: cs.CR

TL;DR: 대형 언어 모델(LLM)이 소프트웨어 취약점 분석을 자동화하는 데 큰 가능성을 보이지만, 현재 접근 방식은 API 기반 LLM 서비스에 의존하여 사용자가 개발 중인 소스 코드를 공개해야 하며, 이로 인해 실용성이 제한된다. 이 논문은 LLM을 활용하여 취약점을 식별하는 문제를 재구성하고, 소규모 로컬 LLM을 지침 조정하여 더 나은 성능을 달성할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 소프트웨어 시스템의 보안 실패는 그 영향이 크기 때문에, 소프트웨어 취약점 분석 자동화는 중요한 작업이다.

Method: 문제를 소프트웨어 취약점 식별(SVI)로 재정의하고, LLM이 취약점의 존재나 부재를 지시하기보다는 Common Weakness Enumeration(CWE) ID의 약점을 출력하도록 요구한다. 또한, 소규모의 로컬 LLM을 지침 조정하여 성능을 개선하는 방법을 제시한다.

Result: 지침 조정된 로컬 LLM은 온라인 API 기반 LLM보다 전체 성능 및 비용 효율성에서 우수한 결과를 보였다.

Conclusion: 지침 조정된 로컬 모델은 실제 취약점 관리 작업 흐름에서 LLM을 활용하는 보다 효과적이고 안전하며 실용적인 접근 방식을 제공한다.

Abstract: Large Language Models (LLMs) show significant promise in automating software vulnerability analysis, a critical task given the impact of security failure of modern software systems. However, current approaches in using LLMs to automate vulnerability analysis mostly rely on using online API-based LLM services, requiring the user to disclose the source code in development. Moreover, they predominantly frame the task as a binary classification(vulnerable or not vulnerable), limiting potential practical utility. This paper addresses these limitations by reformulating the problem as Software Vulnerability Identification (SVI), where LLMs are asked to output the type of weakness in Common Weakness Enumeration (CWE) IDs rather than simply indicating the presence or absence of a vulnerability. We also tackle the reliance on large, API-based LLMs by demonstrating that instruction-tuning smaller, locally deployable LLMs can achieve superior identification performance. In our analysis, instruct-tuning a local LLM showed better overall performance and cost trade-off than online API-based LLMs. Our findings indicate that instruct-tuned local models represent a more effective, secure, and practical approach for leveraging LLMs in real-world vulnerability management workflows.

</details>


### [6] [Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography](https://arxiv.org/abs/2512.20168)
*Songze Li,Jiameng Cheng,Yiming Li,Xiaojun Jia,Dacheng Tao*

Main category: cs.CR

TL;DR: MLLM 통합 시스템의 안전성에 대한 새로운 공격 방법인 Odysseus를 제안함.


<details>
  <summary>Details</summary>
Motivation: MLLM의 보급 증가가 악용 가능성을 높이기 때문.

Method: 이 논문에서는 두 가지 스테가노그래피 기법을 이용해 악의적인 쿼리와 응답을 무해해 보이는 이미지에 숨기는 새로운 탈옥 패러다임인 Odysseus를 제안함.

Result: Odysseus는 여러 MLLM 통합 시스템에서 최대 99%의 공격 성공률을 기록했다.

Conclusion: 기존 방어의 맹점을 드러내고, MLLM 통합 시스템에서의 크로스 모달 보안을 재고할 필요성을 제기함.

Abstract: By integrating language understanding with perceptual modalities such as images, multimodal large language models (MLLMs) constitute a critical substrate for modern AI systems, particularly intelligent agents operating in open and interactive environments. However, their increasing accessibility also raises heightened risks of misuse, such as generating harmful or unsafe content. To mitigate these risks, alignment techniques are commonly applied to align model behavior with human values. Despite these efforts, recent studies have shown that jailbreak attacks can circumvent alignment and elicit unsafe outputs. Currently, most existing jailbreak methods are tailored for open-source models and exhibit limited effectiveness against commercial MLLM-integrated systems, which often employ additional filters. These filters can detect and prevent malicious input and output content, significantly reducing jailbreak threats. In this paper, we reveal that the success of these safety filters heavily relies on a critical assumption that malicious content must be explicitly visible in either the input or the output. This assumption, while often valid for traditional LLM-integrated systems, breaks down in MLLM-integrated systems, where attackers can leverage multiple modalities to conceal adversarial intent, leading to a false sense of security in existing MLLM-integrated systems. To challenge this assumption, we propose Odysseus, a novel jailbreak paradigm that introduces dual steganography to covertly embed malicious queries and responses into benign-looking images. Extensive experiments on benchmark datasets demonstrate that our Odysseus successfully jailbreaks several pioneering and realistic MLLM-integrated systems, achieving up to 99% attack success rate. It exposes a fundamental blind spot in existing defenses, and calls for rethinking cross-modal security in MLLM-integrated systems.

</details>


### [7] [ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected](https://arxiv.org/abs/2512.20405)
*Kanchon Gharami,Sanjiv Kumar Sarkar,Yongxin Liu,Shafika Showkat Moni*

Main category: cs.CR

TL;DR: 대형 언어 모델(LLM)의 사용이 과학 논문 작성 및 검토에서 증가하면서, 그로 인한 심각한 위험도 함께 증가하고 있다.


<details>
  <summary>Details</summary>
Motivation: LLM의 사용이 출판 속도를 높이고 인간의 업무 부담을 줄이지만, 논문의 진정성과 결과의 신뢰성에 위험을 초래할 수 있다.

Method: PDF 내에 숨겨진 프롬프트를 주입하여 LLM 리뷰어가 편향된 피드백을 제공하도록 유도하는 공격 기법과, 논문에 주입된 트리거 프롬프트를 분석하여 LLM 리뷰를 감지하는 방어 기법을 제안한다.

Result: 리뷰어가 LLM에 의해 생성되었음을 나타내는 트리거 프롬프트를 통해 논문의 검토가 인위적인지 여부를 감지할 수 있다.

Conclusion: LLM이 오늘날의 동료 평가 과정에 미치는 영향을 드러내고, 편집자가 신뢰를 회복하는 데 기여할 수 있는 방법을 제시한다.

Abstract: Large Language Models (LLMs) like ChatGPT are now widely used in writing and reviewing scientific papers. While this trend accelerates publication growth and reduces human workload, it also introduces serious risks. Papers written or reviewed by LLMs may lack real novelty, contain fabricated or biased results, or mislead downstream research that others depend on. Such issues can damage reputations, waste resources, and even endanger lives when flawed studies influence medical or safety-critical systems. This research explores both the offensive and defensive sides of this growing threat. On the attack side, we demonstrate how an author can inject hidden prompts inside a PDF that secretly guide or "jailbreak" LLM reviewers into giving overly positive feedback and biased acceptance. On the defense side, we propose an "inject-and-detect" strategy for editors, where invisible trigger prompts are embedded into papers; if a review repeats or reacts to these triggers, it reveals that the review was generated by an LLM, not a human. This method turns prompt injections from vulnerability into a verification tool. We outline our design, expected model behaviors, and ethical safeguards for deployment. The goal is to expose how fragile today's peer-review process becomes under LLM influence and how editorial awareness can help restore trust in scientific evaluation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [LongVideoAgent: Multi-Agent Reasoning with Long Videos](https://arxiv.org/abs/2512.20618)
*Runtao Liu,Ziyi Liu,Jiaqi Tang,Yue Ma,Renjie Pi,Jipeng Zhang,Qifeng Chen*

Main category: cs.AI

TL;DR: 이 논문에서는 멀티 에이전트 프레임워크를 통해 긴 비디오 질문 응답을 위한 효과적인 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 긴 비디오 에피소드를 이해하고 질문에 답하기 위한 기존 방법들은 종 often 손실 압축을 사용하거나 제한된 도구 세트에 의존하여 시간적 연결성을 약화시키고 세부 정보의 단서를 놓친다.

Method: 주요 LLM이 질문과 관련된 세그먼트를 로컬라이즈하는 그라운딩 에이전트와 목표 텍스트 관찰을 추출하는 비전 에이전트를 조정하는 멀티 에이전트 프레임워크를 제안한다. 이 구조는 주 에이전트가 그라운딩을 통해 관련 클립에 집중할 수 있도록 돕고 자막을 시각적 세부정보로 보완하며 해석 가능한 경로를 생성한다.

Result: 제안된 LongTVQA와 LongTVQA+ 데이터셋에서 우리의 멀티 에이전트 시스템은 강력한 비 에이전트 베이스라인을 훨씬 초월하는 성능을 보인다.

Conclusion: 강화 학습이 훈련된 에이전트의 추론 및 계획을 더욱 강화함을 보여주는 실험 결과도 있다.

Abstract: Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.

</details>


### [9] [PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research](https://arxiv.org/abs/2512.19799)
*Tingjia Miao,Jiawen Dai,Jingkun Liu,Jinxin Tan,Muhua Zhang,Wenkai Jin,Yuwen Du,Tian Jin,Xianghe Pang,Zexi Liu,Tu Guo,Zhengliang Zhang,Yunjie Huang,Shuo Chen,Rui Ye,Yuzhi Zhang,Linfeng Zhang,Kun Chen,Wei Wang,Weinan E,Siheng Chen*

Main category: cs.AI

TL;DR: 이 논문에서는 LLM 기반의 PhysMaster를 제안하여 이론적 및 계산 물리학자로서 자율적으로 작동할 수 있도록 하고, 연구의 가속화 및 자동화를 지원한다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구가 LLM 시스템을 잘 정의된 벤치마크나 일반 작업에서 평가하는 경향이 있어, 개방적인 과학 시나리오에서 문제 해결 능력이 제한된다.

Method: PhysMaster는 추상적 추론과 수치 계산을 결합하고, 이전 지식과 방법론을 보존하는 LANDAU를 활용하여 결정의 신뢰성과 안정성을 높인다.

Result: PhysMaster는 고에너지 이론, 응집 물질 이론 및 천체 물리학의 문제에서 성능을 평가하고, 연구를 몇 달에서 몇 시간으로 단축시키고, 자동 가설 구동 루프를 실행하며, 독립적으로 문제를 탐구한다.

Conclusion: PhysMaster는 LLM을 활용한 자율적 물리학자로서 연구의 효율성과 자동화에서 중요한 성과를 보여준다.

Abstract: Advances in LLMs have produced agents with knowledge and operational capabilities comparable to human scientists, suggesting potential to assist, accelerate, and automate research. However, existing studies mainly evaluate such systems on well-defined benchmarks or general tasks like literature retrieval, limiting their end-to-end problem-solving ability in open scientific scenarios. This is particularly true in physics, which is abstract, mathematically intensive, and requires integrating analytical reasoning with code-based computation. To address this, we propose PhysMaster, an LLM-based agent functioning as an autonomous theoretical and computational physicist. PhysMaster couples absract reasoning with numerical computation and leverages LANDAU, the Layered Academic Data Universe, which preserves retrieved literature, curated prior knowledge, and validated methodological traces, enhancing decision reliability and stability. It also employs an adaptive exploration strategy balancing efficiency and open-ended exploration, enabling robust performance in ultra-long-horizon tasks. We evaluate PhysMaster on problems from high-energy theory, condensed matter theory to astrophysics, including: (i) acceleration, compressing labor-intensive research from months to hours; (ii) automation, autonomously executing hypothesis-driven loops ; and (iii) autonomous discovery, independently exploring open problems.

</details>


### [10] [Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs](https://arxiv.org/abs/2512.19937)
*Eric Yeh,John Cadigan,Ran Chen,Dick Crouch,Melinda Gervasio,Dayne Freitag*

Main category: cs.AI

TL;DR: 본 연구는 대규모 언어 모델(LLMs)을 인간의 행동을 모방하도록 사용하고, 성격이 의사결정에 미치는 영향을 탐구하며, 이를 위해 인터폴레이션 디코딩을 적용하여 인간과 유사한 의사결정 행동을 구현하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 각 성격 프로필에 대해 프로ンプ트를 생성해야 하는 요구는 실험 오버헤드를 도입하고 재현성을 저하시킨다.

Method: 인터폴레이션 디코딩을 활용하여 성격의 각 차원을 반대되는 프롬프트 쌍으로 표현하고, 인터폴레이션 매개변수를 사용해 행동을 시뮬레이션한다.

Result: 인터폴레이션 디코딩이 Big Five 차원 각각을 따라 점수를 신뢰성 있게 조절함을 보였다.

Conclusion: 개별 인간 플레이어의 행동을 복제하기 위한 시스템적 검색을 통해 협력 게임에서 인간과 유사한 행동을 할 수 있도록 '쌍둥이' 플레이어를 만드는 방법에 대한 초기 결과를 제시한다.

Abstract: Recent research has explored using very large language models (LLMs) as proxies for humans in tasks such as simulation, surveys, and studies. While LLMs do not possess a human psychology, they often can emulate human behaviors with sufficiently high fidelity to drive simulations to test human behavioral hypotheses, exhibiting more nuance and range than the rule-based agents often employed in behavioral economics. One key area of interest is the effect of personality on decision making, but the requirement that a prompt must be created for every tested personality profile introduces experimental overhead and degrades replicability. To address this issue, we leverage interpolative decoding, representing each dimension of personality as a pair of opposed prompts and employing an interpolation parameter to simulate behavior along the dimension. We show that interpolative decoding reliably modulates scores along each of the Big Five dimensions. We then show how interpolative decoding causes LLMs to mimic human decision-making behavior in economic games, replicating results from human psychological research. Finally, we present preliminary results of our efforts to ``twin'' individual human players in a collaborative game through systematic search for points in interpolation space that cause the system to replicate actions taken by the human subject.

</details>


### [11] [FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification](https://arxiv.org/abs/2512.19960)
*Luciano Araujo Dourado Filho,Rodrigo Tripodi Calumby*

Main category: cs.AI

TL;DR: 이 논문은 세밀한 시각적 분류 작업에서의 분류 성능을 향상시키기 위해 클래스별 클러스터 할당 분류를 통해 세밀한 특징을 학습하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 세밀한 시각적 분류(FGVC) 작업에서의 클래스 내 변동성이 DL 모델의 학습 과정에 방해가 되는 경우가 많기 때문에 이를 해결하고자 한다.

Method: 각 클래스를 개별적으로 클러스터링하여 이미지 간의 잠재적 유사성을 인코딩하는 의사 라벨을 발견하는 방법을 제안한다.

Result: PlantNet300k 데이터셋에서 초기 실험을 통해 우리 방법의 효과성에 대한 미래 연구의 방향을 제시하였다.

Conclusion: 우리 방법은 구성 요소들이 최적화되지 않았음에도 불구하고 PlantNet300k 데이터셋에서 최첨단 성능을 달성하였다.

Abstract: Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially when such classes are also underrepresented, which is a very common scenario in Fine-Grained Visual Categorization (FGVC) tasks. This paper proposes a novel method that aims at leveraging classification performance in FGVC tasks by learning fine-grained features via classification of class-wise cluster assignments. Our goal is to apply clustering over each class individually, which can allow to discover pseudo-labels that encodes a latent degree of similarity between images. In turn, those labels can be employed in a hierarchical classification process that allows to learn more fine-grained visual features and thereby mitigating intra-class variability issues. Initial experiments over the PlantNet300k enabled to shed light upon several key points in which future work will have to be developed in order to find more conclusive evidence regarding the effectiveness of our method. Our method still achieves state-of-the-art performance on the PlantNet300k dataset even though some of its components haven't been shown to be fully optimized. Our code is available at \href{https://github.com/ADAM-UEFS/FGDCC}{https://github.com/ADAM-UEFS/FGDCC}.

</details>


### [12] [S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test](https://arxiv.org/abs/2512.19992)
*Zhe Sun,Xueyuan Yang,Yujie Lu,Zhenliang Zhang*

Main category: cs.AI

TL;DR:  embodiment의 사회적 지능을 평가하기 위한 새로운 벤치마크 S$^{3}$IT를 소개하며, LLM 기반 NPC들과의 좌석 배치 작업을 통해 이들의 성능을 테스트하였다.


<details>
  <summary>Details</summary>
Motivation: 체화된 에이전트를 사람 환경에 통합하는 것은 사회적 규범과 물리적 제약을 고려한 사회적 지능을 필요로 하며, 기존의 평가 방법들은 이러한 통합을 반영하지 못한다.

Method: Spatially Situated Social Intelligence Test (S$^{3}$IT)를 소개하며, 3D 환경에서 LLM 기반의 NPC 그룹에 대한 좌석 배치 작업을 통해 에이전트의 사회적 지능을 평가한다.

Result: 최신 LLMs를 S$^{3}$IT에서 평가한 결과, 인간 기준선과 비교했을 때 명백한 격차를 보이며, LLMs가 공간적 지능에는 부족함이 있지만, 명시적 텍스트 단서가 있는 갈등 해결에 있어서는 인간 수준의 능력에 근접할 수 있는 것으로 나타났다.

Conclusion: 에이전트는 능동적인 대화를 통해 선호를 취득하고, 자율적 탐색을 통해 환경을 인식하며, 복잡한 제약 네트워크 내에서 다목적 최적화를 수행해야 하며, 이는 LLM의 한계와 강점을 모두 드러낸다.

Abstract: The integration of embodied agents into human environments demands embodied social intelligence: reasoning over both social norms and physical constraints. However, existing evaluations fail to address this integration, as they are limited to either disembodied social reasoning (e.g., in text) or socially-agnostic physical tasks. Both approaches fail to assess an agent's ability to integrate and trade off both physical and social constraints within a realistic, embodied context. To address this challenge, we introduce Spatially Situated Social Intelligence Test (S$^{3}$IT), a benchmark specifically designed to evaluate embodied social intelligence. It is centered on a novel and challenging seat-ordering task, requiring an agent to arrange seating in a 3D environment for a group of large language model-driven (LLM-driven) NPCs with diverse identities, preferences, and intricate interpersonal relationships. Our procedurally extensible framework generates a vast and diverse scenario space with controllable difficulty, compelling the agent to acquire preferences through active dialogue, perceive the environment via autonomous exploration, and perform multi-objective optimization within a complex constraint network. We evaluate state-of-the-art LLMs on S$^{3}$IT and found that they still struggle with this problem, showing an obvious gap compared with the human baseline. Results imply that LLMs have deficiencies in spatial intelligence, yet simultaneously demonstrate their ability to achieve near human-level competence in resolving conflicts that possess explicit textual cues.

</details>


### [13] [Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach](https://arxiv.org/abs/2512.20056)
*Hao Li,Fabian Deuser,Wenping Yin,Steffen Knoblauch,Wufan Zhao,Filip Biljecki,Yong Xue,Wei Huang*

Main category: cs.AI

TL;DR: 지구의 기후 변화로 인해 재해와 극한 기상 사건이 증가하고 있다. 이 논문에서는 신속한 재난 대응을 위한 Probabilistic Cross-view Geolocalization 접근법인 ProbGLC를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기후 변화로 인한 재난 사건에 빠르고 효율적으로 대응하는 것이 필수적이다.

Method: ProbGLC는 확률적 및 결정론적 지리적 모델을 통합하여 설명 가능성을 높이고 최첨단 지리적 성능을 달성한다.

Result: ProbGLC의 초기 결과는 우수한 지리적 정확성(Acc@1km에서 0.86, Acc@25km에서 0.97)과 모델 설명 가능성을 보여준다.

Conclusion: ProbGLC 접근법은 재난 대응을 위한 위치 인식을 개선하는 데 큰 잠재력을 가지고 있다.

Abstract: As Earth's climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more intense. Rapid and efficient response to disaster events is essential for climate resilience and sustainability. A key challenge in disaster response is to accurately and quickly identify disaster locations to support decision-making and resources allocation. In this paper, we propose a Probabilistic Cross-view Geolocalization approach, called ProbGLC, exploring new pathways towards generative location awareness for rapid disaster response. Herein, we combine probabilistic and deterministic geolocalization models into a unified framework to simultaneously enhance model explainability (via uncertainty quantification) and achieve state-of-the-art geolocalization performance. Designed for rapid diaster response, the ProbGLC is able to address cross-view geolocalization across multiple disaster events as well as to offer unique features of probabilistic distribution and localizability score. To evaluate the ProbGLC, we conduct extensive experiments on two cross-view disaster datasets (i.e., MultiIAN and SAGAINDisaster), consisting diverse cross-view imagery pairs of multiple disaster types (e.g., hurricanes, wildfires, floods, to tornadoes). Preliminary results confirms the superior geolocalization accuracy (i.e., 0.86 in Acc@1km and 0.97 in Acc@25km) and model explainability (i.e., via probabilistic distributions and localizability scores) of the proposed ProbGLC approach, highlighting the great potential of leveraging generative cross-view approach to facilitate location awareness for better and faster disaster response. The data and code is publicly available at https://github.com/bobleegogogo/ProbGLC

</details>


### [14] [Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches](https://arxiv.org/abs/2512.20082)
*Chaithra,Kamesh Kadimisetty,Biju R Mohan*

Main category: cs.AI

TL;DR: 본 논문에서는 인도 주식 시장 맥락에서의 감정 분류를 개선하기 위해 실제 주식 시장 피드백과 대형 언어 모델을 통합한 적응형 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 금융 감정 분석은 투자 결정에 중요한 역할을 하며, 시장 리스크를 평가하고 주가 동향을 예측하는 데 필수적이다. 그러나 기존 연구는 주가나 시장 피드백이 감정 분석에 미치는 영향을 고려하지 않았다.

Method: 제안된 방법론은 SentiFin 데이터셋에 대한 지시 기반 학습을 통해 LLaMA 3.2 3B 모델을 미세 조정하며, 코사인 유사성에 기반해 다중 출처의 맥락 정보를 동적으로 선택하는 회수 보강 생성(RAG) 파이프라인을 사용한다. 또한, 예측된 감정과 실제 다음 날 주식 수익률을 비교하여 출처의 신뢰성을 조정하는 피드백 기반 모듈을 도입한다.

Result: 2024년부터 2025년까지 수집된 NIFTY 50 뉴스 헤드라인에 대한 실험 결과, 제안된 시스템이 기준 모델 및 정적 검색 방법에 비해 분류 정확도, F1 점수 및 시장 적합성을 상당히 개선한 것으로 나타났다.

Conclusion: 지시 조정 LLM과 동적 피드백 및 강화 학습을 결합한 강력하고 시장 인식 금융 감정 모델링의 잠재력을 검증하였다.

Abstract: Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we propose an adaptive framework that integrates large language models (LLMs) with real-world stock market feedback to improve sentiment classification in the context of the Indian stock market. The proposed methodology fine-tunes the LLaMA 3.2 3B model using instruction-based learning on the SentiFin dataset. To enhance sentiment predictions, a retrieval-augmented generation (RAG) pipeline is employed that dynamically selects multi-source contextual information based on the cosine similarity of the sentence embeddings. Furthermore, a feedback-driven module is introduced that adjusts the reliability of the source by comparing predicted sentiment with actual next-day stock returns, allowing the system to iteratively adapt to market behavior. To generalize this adaptive mechanism across temporal data, a reinforcement learning agent trained using proximal policy optimization (PPO) is incorporated. The PPO agent learns to optimize source weighting policies based on cumulative reward signals from sentiment-return alignment. Experimental results on NIFTY 50 news headlines collected from 2024 to 2025 demonstrate that the proposed system significantly improves classification accuracy, F1-score, and market alignment over baseline models and static retrieval methods. The results validate the potential of combining instruction-tuned LLMs with dynamic feedback and reinforcement learning for robust, market-aware financial sentiment modeling.

</details>


### [15] [MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization](https://arxiv.org/abs/2512.20135)
*Zhuo Yang,Yeyun chen,Jiaqing Xie,Ben Gao,Shuaike Shen,Wanhao Liu,Liujia Yang,Beilun Wang,Tianfan Fu,Yuqiang Li*

Main category: cs.AI

TL;DR: MolAct는 분자 편집 및 최적화를 위한 새로운 에이전트 강화 학습 프레임워크로, 두 단계의 훈련 패러다임을 사용하여 편집 기능을 구축하고, 학습된 편집 행동을 재사용하여 특성을 최적화합니다.


<details>
  <summary>Details</summary>
Motivation: 분자 편집 및 최적화는 화학적으로 유효하고 구조적으로 유사한 특성을 유지하면서 반복적으로 개선해야 하는 다단계 문제입니다.

Method: MolAct라는 에이전트 강화 학습 프레임워크를 소개하며, 이 프레임워크는 2단계 훈련 패러다임을 사용하여 편집 기능을 구축한 후 학습된 편집 행동을 재사용하여 특성을 최적화합니다.

Result: MolEditAgent-7B는 유효한 추가, 삭제, 대체 편집에서 각각 100, 95, 98을 달성하며, 강력한 클로즈드 '사고' 기준을 초월하고, MolOptAgent-7B는 LogP에서 최고의 클로즈드 '사고' 기준을 초과합니다.

Conclusion: 분자 설계를 다단계, 도구 보강 프로세스로 다루는 것이 신뢰할 수 있고 해석 가능한 개선의 핵심이라는 점을 강조합니다.

Abstract: Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that employs a two-stage training paradigm: first building editing capability, then optimizing properties while reusing the learned editing behaviors. To the best of our knowledge, this is the first work to formalize molecular design as an Agentic Reinforcement Learning problem, where an LLM agent learns to interleave reasoning, tool-use, and molecular optimization. The framework enables agents to interact in multiple turns, invoking chemical tools for validity checking, property assessment, and similarity control, and leverages their feedback to refine subsequent edits. We instantiate the MolAct framework to train two model families: MolEditAgent for molecular editing tasks and MolOptAgent for molecular optimization tasks. In molecular editing, MolEditAgent-7B delivers 100, 95, and 98 valid add, delete, and substitute edits, outperforming strong closed "thinking" baselines such as DeepSeek-R1; MolEditAgent-3B approaches the performance of much larger open "thinking" models like Qwen3-32B-think. In molecular optimization, MolOptAgent-7B (trained on MolEditAgent-7B) surpasses the best closed "thinking" baseline (e.g., Claude 3.7) on LogP and remains competitive on solubility, while maintaining balanced performance across other objectives. These results highlight that treating molecular design as a multi-step, tool-augmented process is key to reliable and interpretable improvements.

</details>


### [16] [Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection](https://arxiv.org/abs/2512.20140)
*Xingyou Yin,Ceyao Zhang,Min Hu,Kai Chen*

Main category: cs.AI

TL;DR: 이 연구에서는 미세 조정 없이도 효과적인 시계열 예측을 위한 접근 방식을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 방법은 LLM과의 격차를 해소하기 위해 전문 모듈을 미세 조정하는 데 의존하지만, 우리는 미세 조정 없이 전략적인 토큰화를 통해 이를 극복하고자 합니다.

Method: 원시 시계열에 노이즈를 주입하여 토큰화 전에 데이터를 변화시켜, LLM이 단순한 숫자 아티팩트가 아닌 더 강력한 시간 패턴에 기반해 추론을 하도록 유도합니다.

Result: 다양한 벤치마크에서 이 방법의 효과를 실증적으로 검증했으며, LLM의 미세 조정 없이도 향상된 성능을 관찰했습니다.

Conclusion: 이 연구는 시계열 예측을 위한 기성 LLM 활용을 위한 한 단계 더 나아간 접근 방식을 제공합니다.

Abstract: Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.

</details>


### [17] [Offline Safe Policy Optimization From Heterogeneous Feedback](https://arxiv.org/abs/2512.20173)
*Ze Gong,Pradeep Varakantham,Akshat Kumar*

Main category: cs.AI

TL;DR: 오프라인 선호 기반 강화 학습(PbRL)은 인간의 선호와 일치하는 보상 및 정책을 학습하지만, 안전성을 보장하는 것이 중요한 도전 과제가 된다. 본 연구는 정책을 직접 학습하는 프레임워크를 도입하고, 선호 학습 모듈과 안전 정렬을 결합한 	extsc{PreSa} 방법을 제안하여 지속적인 제어 작업에서 높은 보상을 갖는 안전 정책을 성공적으로 학습하였다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 PbRL의 안전성이 많은 영역과 작업에서 여전히 중요한 도전 과제이므로 이 문제를 해결하고자 한다.

Method: 정책을 간접적으로 학습하는 대신, 우리는 에이전트 행동에 대한 쌍별 선호와 궤적 구간의 안전성을 나타내는 이진 레이블을 기반으로 정책을 직접 학습하는 프레임워크를 도입한다. 	extsc{PreSa} 방법은 선호 학습 모듈과 안전 정렬을 결합하여 라그랑지안 패러다임 내에서 보상을 명시적으로 학습하지 않고 안전한 정책을 학습한다.

Result: 우리의 방법은 합성 및 실제 인간 피드백을 포함한 지속적인 제어 작업에서 평가되었으며, 안전 정책을 성공적으로 학습하고, 최첨단 기준선과 진실 보상 및 비용을 가진 오프라인 안전 RL 접근법을 능가하였다.

Conclusion: 본 연구는 선호 학습과 안전 정렬을 결합하여 안정적이고 보상이 높은 정책을 학습할 수 있는 효율적인 방법을 제시하였다.

Abstract: Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, then use constrained RL to optimize a safe policy. While such an approach works in the contextual bandits settings (LLMs), in long horizon continuous control tasks, errors in rewards and costs accumulate, leading to impairment in performance when used with constrained RL methods. To address these challenges, (a) instead of indirectly learning policies (from rewards and costs), we introduce a framework that learns a policy directly based on pairwise preferences regarding the agent's behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments; (b) we propose \textsc{PreSa} (Preference and Safety Alignment), a method that combines preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved within a Lagrangian paradigm that directly learns reward-maximizing safe policy \textit{without explicitly learning reward and cost models}, avoiding the need for constrained RL; (c) we evaluate our approach on continuous control tasks with both synthetic and real human feedback. Empirically, our method successfully learns safe policies with high rewards, outperforming state-of-the-art baselines, and offline safe RL approaches with ground-truth reward and cost.

</details>


### [18] [TongSIM: A General Platform for Simulating Intelligent Machines](https://arxiv.org/abs/2512.20206)
*Zhe Sun,Kunlun Wu,Chuanjian Fu,Zeming Song,Langyong Shi,Zihe Xue,Bohan Jing,Ying Yang,Xiaomeng Gao,Aijia Li,Tianyu Guo,Huiying Li,Xueyuan Yang,Rongkai Liu,Xinyi He,Yuxi Wang,Yue Li,Mingyuan Liu,Yujie Lu,Hongzhao Xie,Shiyun Zhao,Bo Dai,Wei Wang,Tao Yuan,Song-Chun Zhu,Yujia Peng,Zhenliang Zhang*

Main category: cs.AI

TL;DR: TongSIM은 다양한 다각적 환경에서 인공지능 에이전트를 훈련하고 평가하기 위한 고충실도의 일반-purpose 플랫폼이다.


<details>
  <summary>Details</summary>
Motivation: AI가 빠르게 발전함에 따라, 단일 모드 텍스트 처리에서 다중 모드 및 구현 AI로의 연구 초점이 이동하고 있다. 그러나 기존의 시뮬레이션 플랫폼은 특정 작업에 맞게 설계되어 있어 다목적 훈련 환경이 부족하다.

Method: TongSIM은 100개 이상의 다양한 다중 실내 시나리오와 상호작용이 풍부한 야외 도시 시뮬레이션을 제공하여 에이전트 훈련에 활용된다.

Result: TongSIM의 포괄적인 평가 프레임워크와 벤치마크는 에이전트의 인지, 의사결정, 인간-로봇 협력 등의 능력을 정밀하게 평가할 수 있도록 한다.

Conclusion: TongSIM은 연구자들에게 유연성과 확장성을 제공하며, 일반 구현 지능으로의 진행 속도를 높이는 통합 플랫폼 역할을 한다.

Abstract: As artificial intelligence (AI) rapidly advances, especially in multimodal large language models (MLLMs), research focus is shifting from single-modality text processing to the more complex domains of multimodal and embodied AI. Embodied intelligence focuses on training agents within realistic simulated environments, leveraging physical interaction and action feedback rather than conventionally labeled datasets. Yet, most existing simulation platforms remain narrowly designed, each tailored to specific tasks. A versatile, general-purpose training environment that can support everything from low-level embodied navigation to high-level composite activities, such as multi-agent social simulation and human-AI collaboration, remains largely unavailable. To bridge this gap, we introduce TongSIM, a high-fidelity, general-purpose platform for training and evaluating embodied agents. TongSIM offers practical advantages by providing over 100 diverse, multi-room indoor scenarios as well as an open-ended, interaction-rich outdoor town simulation, ensuring broad applicability across research needs. Its comprehensive evaluation framework and benchmarks enable precise assessment of agent capabilities, such as perception, cognition, decision-making, human-robot cooperation, and spatial and social reasoning. With features like customized scenes, task-adaptive fidelity, diverse agent types, and dynamic environmental simulation, TongSIM delivers flexibility and scalability for researchers, serving as a unified platform that accelerates training, evaluation, and advancement toward general embodied intelligence.

</details>


### [19] [MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents](https://arxiv.org/abs/2512.20237)
*Xingbo Du,Loka Li,Duzhen Zhang,Le Song*

Main category: cs.AI

TL;DR: MemR$^3$는 자율적이고 정확하며 호환 가능한 메모리 검색 시스템으로, 메모리 검색의 폐쇄 루프 제어 메커니즘을 도입하여 답변 품질을 최적화합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 메모리 시스템은 압축 및 저장 최적화에 치중하였으며, 메모리 검색의 명시적 제어가 부족함을 관찰하였다.

Method: MemR$^3$는 검색, 반영 및 응답 행동을 선택하는 라우터와 답변 과정을 명확하게 하며 증거 수집을 추적하는 글로벌 증거 격차 추적기를 사용하는 두 가지 핵심 메커니즘으로 구성된다.

Result: LoCoMo 벤치마크에 대한 실험 결과, MemR$^3$는 LLM-as-a-Judge 점수에서 강력한 기준선을 초과하며, 특히 RAG에서 7.29%, Zep에서 1.94%의 전반적인 개선을 보여준다.

Conclusion: MemR$^3$는 기존 메모리 저장소에 대한 플러그 앤 플레이 컨트롤러를 제공한다.

Abstract: Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents. However, many deployed memory systems primarily optimize compression and storage, with comparatively less emphasis on explicit, closed-loop control of memory retrieval. From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. This design departs from the standard retrieve-then-answer pipeline by introducing a closed-loop control mechanism that enables autonomous decision-making. Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores.

</details>


### [20] [Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks](https://arxiv.org/abs/2512.20275)
*Divya Vijay,Vignesh Ethiraj*

Main category: cs.AI

TL;DR: 본 연구는 G-SPEC이라는 신경-기호적 프레임워크를 통해 5G 및 6G 네트워크 운영의 오케스트레이션 문제를 해결하고, 안전성을 확보하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 5G 독립형 및 6G 네트워크의 발전에 따라 운영자는 정적 자동화와 깊은 강화학습을 초과하는 오케스트레이션 문제에 직면하고 있습니다.

Method: 우리는 확률적 계획을 결정적 검증으로 제한하는 G-SPEC이라는 신경-기호적 프레임워크를 제안합니다.

Result: G-SPEC은 시뮬레이션된 450 노드 5G 코어에서 테스트되어 안전 위반 제로와 94.1%의 수정 성공률을 달성하였으며, 이는 82.4%의 기준치를 크게 초과합니다.

Conclusion: NKG 검증이 안전성 향상의 대부분(68%)을 주도하며, SHACL 정책이(24%) 뒤따릅니다. G-SPEC은 142ms의 처리 오버헤드로 SMO 계층 작업에 적합합니다.

Abstract: As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.

</details>


### [21] [Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation](https://arxiv.org/abs/2512.20278)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델이 수동적인 도구 사용자에서 능동적인 워크플로 아키텍트로 전환하는 방법을 규명하며, 자동화된 기술 생성을 위한 네 가지 구조적 병목현상을 다룬다.


<details>
  <summary>Details</summary>
Motivation: CodeMem은 실행 가능한 코드를 대리적 절차 기억의 최적 표현으로 설정하지만, 이 기억을 자율적으로 생성하는 메커니즘은 충분히 탐구되지 않았다.

Method: 이 논문은 Outlook과 OneDrive를 포함하는 서비스 간 오케스트레이션 작업의 고충실도 사례 연구를 통해 네 가지 구조적 병목현상을 파악하고 해결했다.

Result: 자동화된 기술 생성에서 발견 간극, 검증 간극, 분해 간극, 및 확장성 간극을 다루었다.

Conclusion: 가설 설정, 탐색, 및 코드 작성의 과학적 방법론을 시행함으로써 에이전트는 자율적으로 강력한 생산 용도의 코드 기술을 작성할 수 있음을 입증했다.

Abstract: While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.

</details>


### [22] [SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization](https://arxiv.org/abs/2512.20333)
*Junren Li,Luhua Lai*

Main category: cs.AI

TL;DR: Generative AI는 화학 공간 탐사에 혁신을 가져왔지만, 생성된 분자의 상당 부분이 합성 접근이 불가능하다는 문제를 지니고 있다. 기존의 해결책은 구조의 새로움을 저해하거나 주요 약물 작용점을 방해한다. 본 논문에서는 SynCraft라는 프레임워크를 소개하며, 이는 합성 가능성 최적화를 시퀀스 변환 작업이 아닌 구조 편집 문제로 재구성한다. SynCraft는 기본적으로 LLM의 추론 능력을 활용하여, 최소한의 구조 변경으로 합성 가능성을 높인다. 뛰어난 벤치마크 결과를 통해 SynCraft는 높은 구조적 충실도로 합성 가능한 유사체를 생성할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 생성된 분자의 상당수가 합성 접근이 불가능하다는 문제를 해결하기 위해 새로운 접근이 필요하다.

Method: SynCraft는 LLM의 추론 능력을 활용하여 합성 최적화를 구조 편집 문제로 다루며, 원자 수준의 수정 시퀀스를 예측한다.

Result: SynCraft는 최신 기반선보다 구조적 충실도가 높은 합성 가능한 유사체를 생성하는 데 더 뛰어난 성능을 보여준다.

Conclusion: SynCraft는 전문가의 약물 화학 직관을 성공적으로 재현하며, 이전의 분자 생성 문헌에서 discarded된 후보를 복구하는 데도 효과적이다.

Abstract: Generative artificial intelligence has revolutionized the exploration of chemical space, yet a critical bottleneck remains that a substantial fraction of generated molecules is synthetically inaccessible. Current solutions, such as post-hoc filtering or projection-based methods, often compromise structural novelty or disrupt key pharmacophores by forcing molecules into pre-defined synthetic templates. Herein, we introduce SynCraft, a reasoning-based framework that reframes synthesizability optimization not as a sequence translation task, but as a precise structural editing problem. Leveraging the emergent reasoning capabilities of Large Language Models, SynCraft navigates the "synthesis cliff" where minimal structural modifications yield significant gains in synthetic feasibility. By predicting executable sequences of atom-level edits rather than generating SMILES strings directly, SynCraft circumvents the syntactic fragility of LLMs while harnessing their chemical intuition. Extensive benchmarks demonstrate that SynCraft outperforms state-of-the-art baselines in generating synthesizable analogs with high structural fidelity. Furthermore, through interaction-aware prompting, SynCraft successfully replicates expert medicinal chemistry intuition in editing PLK1 inhibitors and rescuing high-scoring but previously discarded RIPK1 candidates in previous molecular generation literatures.

</details>


### [23] [Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale](https://arxiv.org/abs/2512.20469)
*Linfeng Zhang,Siheng Chen,Yuzhu Cai,Jingyi Chai,Junhan Chang,Kun Chen,Zhi X. Chen,Zhaohan Ding,Yuwen Du,Yuanpeng Gao,Yuan Gao,Jing Gao,Zhifeng Gao,Qiangqiang Gu,Yanhui Hong,Yuan Huang,Xi Fang,Xiaohong Ji,Guolin Ke,Zixing Lei,Xinyu Li,Yongge Li,Ruoxue Liao,Hang Lin,Xiaolu Lin,Yuxiang Liu,Xinzijian Liu,Zexi Liu,Jintan Lu,Tingjia Miao,Haohui Que,Weijie Sun,Yanfeng Wang,Bingyang Wu,Tianju Xue,Rui Ye,Jinzhe Zeng,Duo Zhang,Jiahui Zhang,Linfeng Zhang,Tianhan Zhang,Wenchang Zhang,Yuzhi Zhang,Zezhong Zhang,Hang Zheng,Hui Zhou,Tong Zhu,Xinyu Zhu,Qingguo Zhou,Weinan E*

Main category: cs.AI

TL;DR: AI 에이전트는 도구 사용과 검증을 포함하는 다단계 과학 작업 흐름을 실행하는 실용적인 방법으로 떠오르고 있으며, 에이전트 과학의 대규모 확장으로의 전환을 시사한다. 그러나 에이전트 과학의 확장에는 여러 도전과제가 있으며, 저자들은 Bohrium+SciMaster를 기반으로 한 인프라-생태계 접근 방식이 필요하다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: AI가 과학적 결과를 가속화하고 동료 검토 및 출판 프로세스에 부담을 주는 가운데, 트레이스 가능성과 신뢰할 수 있는 평가 기준이 상승하고 있어 에이전트 과학의 필요성이 증가하고 있다.

Method: Bohrium은 AI4S 자산을 관리되고 추적 가능한 허브로서 다양한 과학 데이터, 소프트웨어, 컴퓨팅, 실험실 시스템을 에이전트 준비 기능으로 전환하고, SciMaster는 이러한 기능을 사용하는 장기적인 과학 작업 흐름을 조정한다.

Result: 실제 작업 흐름에서 11개의 대표 마스터 에이전트로 이 스택을 시연하여, 엔드 투 엔드 과학 사이클 시간을 수 배 단위로 단축하고 수백만 규모의 실제 작업에서 실행 기반 신호를 생성했다.

Conclusion: 에이전트 과학의 масштаб화는 인프라와 조정의 균형 잡힌 접근 방식을 통해 가능하며, 이는 반복 가능하고 개선 가능한 과학적 작업 흐름을 위한 실행 가능한 구성 요소로 모델, 지식, 그리고 구성 요소를 조직하는 '과학 지능 기초'를 통해 이루어진다.

Abstract: AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.
  However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals.
  We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use.
  We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.

</details>


### [24] [Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent](https://arxiv.org/abs/2512.20586)
*Humza Nusrat,Luke Francisco,Bing Luo,Hassan Bagher-Ebadian,Joshua Kim,Karen Chin-Snyder,Salim Siddiqui,Mira Shah,Eric Mellon,Mohammad Ghassemi,Anthony Doemer,Benjamin Movsas,Kundan Thind*

Main category: cs.AI

TL;DR: 이 연구에서는 뇌 전이 환자들에게 선형 감쇠 조사(SRS)를 위한 자동화된 치료 계획을 생성하는 LLM 기반의 계획 에이전트 SAGE를 개발하고, 사고적 추론이 어떻게 계획의 품질을 향상시키는지를 평가하였다.


<details>
  <summary>Details</summary>
Motivation: 흑박스 AI 시스템은 불투명성 문제로 인해 임상에서의 채택이 제한되고 있으며, 치료 계획에서의 정확한 선량 형성을 요구하는 SRS의 필요성이 있다.

Method: 18 Gy 단일 분획 SRS로 치료된 41명의 뇌 전이 환자를 대상으로, 두 가지 유형의 계획 모델(사고적 사고 모델과 비사고적 모델)을 사용하여 계획을 세웠다. 이를 통해 계획 dosimetry의 비교를 수행하였다.

Result: 사고적 사고 모델은 PTV 커버리지, 최대 선량, 적합성 지수, 기울기 지수에 대해 인간 계획자와 유사한 계획 dosimetry를 제공하였고, 인간 기준보다 더 낮은 달팽이관 선량을 달성하였다. 사고적 모델은 계획 과정에서 체계적인 행동을 보였으나 비사고적 모델은 그러한 행동을 나타내지 않았다.

Conclusion: 이 연구는 투명한 자동화된 계획을 위한 경로를 제시하며, 사고적 사고를 통한 계획의 개선을 보여준다.

Abstract: Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [25] [Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data](https://arxiv.org/abs/2512.19716)
*Behrooz Mamandipoor,Chun-Nan Hsu,Martin Krause,Ulrich H. Schmidt,Rodney A. Gabriel*

Main category: cs.LG

TL;DR: 중환자의 병원 내 사망률을 예측하는 다중 모드 딥러닝 모델을 개발하여 치료 최적화에 기여하고자 하였다.


<details>
  <summary>Details</summary>
Motivation: 중환자의 병원 내 사망을 조기에 예측하면 임상의가 치료를 최적화하는 데 도움을 줄 수 있다.

Method: 구조화된 및 비구조화된 임상 데이터를 활용한 다중 모드 딥러닝 모델을 개발하였다.

Result: 2001년부터 2022년까지 200개 이상의 병원에서 203,434건의 ICU 입원이 포함되었으며, 사망률은 5.2%에서 7.9%까지 다양하였다. 모델의 AUROC, AUPRC, 및 Brier 점수는 각각 0.92, 0.53, 0.19였다.

Conclusion: 우리의 연구 결과는 사망 예측을 위해 여러 출처의 환자 정보를 통합하는 것과 외부 검증의 중요성을 강조한다.

Abstract: Early prediction of in-hospital mortality in critically ill patients can aid clinicians in optimizing treatment. The objective was to develop a multimodal deep learning model, using structured and unstructured clinical data, to predict in-hospital mortality risk among critically ill patients after their initial 24 hour intensive care unit (ICU) admission. We used data from MIMIC-III, MIMIC-IV, eICU, and HiRID. A multimodal model was developed on the MIMIC datasets, featuring time series components occurring within the first 24 hours of ICU admission and predicting risk of subsequent inpatient mortality. Inputs included time-invariant variables, time-variant variables, clinical notes, and chest X-ray images. External validation occurred in a temporally separated MIMIC population, HiRID, and eICU datasets. A total of 203,434 ICU admissions from more than 200 hospitals between 2001 to 2022 were included, in which mortality rate ranged from 5.2% to 7.9% across the four datasets. The model integrating structured data points had AUROC, AUPRC, and Brier scores of 0.92, 0.53, and 0.19, respectively. We externally validated the model on eight different institutions within the eICU dataset, demonstrating AUROCs ranging from 0.84-0.92. When including only patients with available clinical notes and imaging data, inclusion of notes and imaging into the model, the AUROC, AUPRC, and Brier score improved from 0.87 to 0.89, 0.43 to 0.48, and 0.37 to 0.17, respectively. Our findings highlight the importance of incorporating multiple sources of patient information for mortality prediction and the importance of external validation.

</details>


### [26] [Trend Extrapolation for Technology Forecasting: Leveraging LSTM Neural Networks for Trend Analysis of Space Exploration Vessels](https://arxiv.org/abs/2512.19727)
*Peng-Hung Tsai,Daniel Berleant*

Main category: cs.LG

TL;DR: 우주 탐사와 같은 복잡한 분야에서 기술 발전 예측은 기술적, 경제적, 정책적 요인의 복잡한 상호작용으로 인해 상당한 도전을 제시합니다. 본 논문에서는 최신 경향을 반영한 체계적인 문헌 리뷰를 통해 LSTM 신경망과 무어의 법칙을 결합한 예측 모델을 개발하였습니다.


<details>
  <summary>Details</summary>
Motivation: 기술 예측 분야에서 머신러닝 기반 하이브리드 모델에 대한 증가하는 추세를 반영하여, 우주 탐사선의 수명을 예측하는 모델을 개발하게 되었습니다.

Method: LSTM 신경망과 무어의 법칙 증강을 결합하여 우주선의 수명을 예측하는 예측 모델을 구축하였습니다.

Result: 본 연구의 분석은 최근 시작 시간-종료 시간 통합(STETI) 접근 방식을 도입하여 우주선의 수명 예측을 개선했습니다.

Conclusion: STETI 기법을 통해 우주 미션 계획 및 정책 의사결정에 중요한 통찰을 제공합니다.

Abstract: Forecasting technological advancement in complex domains such as space exploration presents significant challenges due to the intricate interaction of technical, economic, and policy-related factors. The field of technology forecasting has long relied on quantitative trend extrapolation techniques, such as growth curves (e.g., Moore's law) and time series models, to project technological progress. To assess the current state of these methods, we conducted an updated systematic literature review (SLR) that incorporates recent advances. This review highlights a growing trend toward machine learning-based hybrid models.
  Motivated by this review, we developed a forecasting model that combines long short-term memory (LSTM) neural networks with an augmentation of Moore's law to predict spacecraft lifetimes. Operational lifetime is an important engineering characteristic of spacecraft and a potential proxy for technological progress in space exploration. Lifetimes were modeled as depending on launch date and additional predictors.
  Our modeling analysis introduces a novel advance in the recently introduced Start Time End Time Integration (STETI) approach. STETI addresses a critical right censoring problem known to bias lifetime analyses: the more recent the launch dates, the shorter the lifetimes of the spacecraft that have failed and can thus contribute lifetime data. Longer-lived spacecraft are still operating and therefore do not contribute data. This systematically distorts putative lifetime versus launch date curves by biasing lifetime estimates for recent launch dates downward. STETI mitigates this distortion by interconverting between expressing lifetimes as functions of launch time and modeling them as functions of failure time. The results provide insights relevant to space mission planning and policy decision-making.

</details>


### [27] [OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting](https://arxiv.org/abs/2512.19738)
*Wilson Fung,Lu Guo,Drake Hilliard,Alessandro Casadei,Raj Ratan,Sreyoshi Bhaduri,Adi Surve,Nikhil Agarwal,Rohit Malshe,Pavan Mullapudi,Hungjen Wang,Saurabh Doodhwala,Ankush Pole,Arkajit Rakshit*

Main category: cs.LG

TL;DR: OpComm은 마지막 마일 물류에서 패키지 수량 예측 및 의사결정을 지원하는 프레임워크로, 예측 정확도를 높이고 자원 할당을 최적화합니다.


<details>
  <summary>Details</summary>
Motivation: 패키지 물량의 정확한 예측은 효율적인 자원 할당과 비용 절감, 배송 지연 방지에 필수적이다.

Method: OpComm은 감독 학습과 강화 학습 기반의 버퍼 제어, 생성적 AI 통신 모듈을 결합한 프레임워크이다.

Result: OpComm은 400개 이상의 스테이션에서 WAPE를 수동 예측에 비해 21.65% 감소시키고 버퍼 부족 사건을 줄이며 의사결정자의 투명성을 향상시켰다.

Conclusion: 이 연구는 상황적 강화 학습과 예측 모델링이 운영 예측 문제를 해결하고 통계적 엄밀성과 실용적 의사결정을 연결할 수 있음을 보여준다.

Abstract: Accurate forecasting of package volumes at delivery stations is critical for last-mile logistics, where errors lead to inefficient resource allocation, higher costs, and delivery delays. We propose OpComm, a forecasting and decision-support framework that combines supervised learning with reinforcement learning-based buffer control and a generative AI-driven communication module. A LightGBM regression model generates station-level demand forecasts, which serve as context for a Proximal Policy Optimization (PPO) agent that selects buffer levels from a discrete action set. The reward function penalizes under-buffering more heavily than over-buffering, reflecting real-world trade-offs between unmet demand risks and resource inefficiency. Station outcomes are fed back through a Monte Carlo update mechanism, enabling continual policy adaptation. To enhance interpretability, a generative AI layer produces executive-level summaries and scenario analyses grounded in SHAP-based feature attributions. Across 400+ stations, OpComm reduced Weighted Absolute Percentage Error (WAPE) by 21.65% compared to manual forecasts, while lowering under-buffering incidents and improving transparency for decision-makers. This work shows how contextual reinforcement learning, coupled with predictive modeling, can address operational forecasting challenges and bridge statistical rigor with practical decision-making in high-stakes logistics environments.

</details>


### [28] [OASI: Objective-Aware Surrogate Initialization for Multi-Objective Bayesian Optimization in TinyML Keyword Spotting](https://arxiv.org/abs/2512.19739)
*Soumen Garai,Suman Samui*

Main category: cs.LG

TL;DR: 본 논문은 리소스 제약이 있는 TinyML 장치에서의 키워드 스포팅(KWS) 모델을 개선하기 위해 다목적 베이지안 최적화(MOBO)와 새로운 초기화 전략인 OASI를 제안합니다. OASI는 높은 성능과 다양성을 갖춘 구성 요소의 시드 파레토 집합을 생성하여 모델의 정확성과 크기 간의 균형을 이루는 데 도움을 줍니다.


<details>
  <summary>Details</summary>
Motivation: TinyML 장치에서 효율적이고 개인 정보 보호가 가능하도록 KWS 모델의 정확성을 높이기 위한 필요성이 있음.

Method: 다목적 시뮬레이티드 어닐링(MOSA)을 이용하여 고성능의 다양한 구성 요소로 이루어진 시드 파레토 집합을 생성하는 Objective-Aware Surrogate Initialization (OASI) 전략을 제안함.

Result: OASI는 여러 실행에서 LHS, Sobol 및 랜덤 초기화보다 높은 하이퍼볼륨(0.0627)과 가장 낮은 세대 거리(0.0)를 달성하면서 계산 시간이 오히려 소폭 증가(1934초 대 $	ilde{1500}$초)하는 결과를 보임.

Conclusion: Kruskal-Wallis 검정($H = 5.40$, $p = 0.144$, $η^2 = 0.0007$)과 Dunn의 사후 검정 결과, OASI가 비록 $α=0.05$ 기준에서는 전체 차이가 유의하지 않음에도 불구하고 일관성이 우수함을 확인함.

Abstract: Voice assistants utilize Keyword Spotting (KWS) to enable efficient, privacy-friendly activation. However, realizing accurate KWS models on ultra-low-power TinyML devices (often with less than $<2$ MB of flash memory) necessitates a delicate balance between accuracy with strict resource constraints. Multi-objective Bayesian Optimization (MOBO) is an ideal candidate for managing such a trade-off but is highly initialization-dependent, especially under the budgeted black-box setting. Existing methods typically fall back to naive, ad-hoc sampling routines (e.g., Latin Hypercube Sampling (LHS), Sobol sequences, or Random search) that are adapted to neither the Pareto front nor undergo rigorous statistical comparison. To address this, we propose Objective-Aware Surrogate Initialization (OASI), a novel initialization strategy that leverages Multi-Objective Simulated Annealing (MOSA) to generate a seed Pareto set of high-performing and diverse configurations that explicitly balance accuracy and model size. Evaluated in a TinyML KWS setting, OASI outperforms LHS, Sobol, and Random initialization, achieving the highest hypervolume (0.0627) and the lowest generational distance (0.0) across multiple runs, with only a modest increase in computation time (1934 s vs. $\sim$1500 s). A non-parametric statistical analysis using the Kruskal-Wallis test ($H = 5.40$, $p = 0.144$, $η^2 = 0.0007$) and Dunn's post-hoc test confirms OASI's superior consistency despite the non-significant overall difference with respect to the $α=0.05$ threshold.

</details>


### [29] [On-device Large Multi-modal Agent for Human Activity Recognition](https://arxiv.org/abs/2512.19742)
*Md Shakhrul Iman Siam,Ishtiaque Ahmed Showmik,Guanqun Song,Ting Zhu*

Main category: cs.LG

TL;DR: 이 연구에서는 대형 멀티모달 에이전트를 통해 인간 활동 인식(HAR)의 성능과 사용자 참여를 향상시키는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: HAR 분야는 헬스케어부터 스마트 환경에 이르기까지 다양한 응용을 가지고 있으며, 최근 대형 언어 모델의 발전이 HAR의 가능성을 확장했습니다.

Method: 제안하는 프레임워크는 LLM의 힘을 통합하여 활동 분류를 제공하고, 기술적 결과와 사용자 친화적인 통찰력 사이의 간극을 연결합니다.

Result: 우리 모델은 최첨단 방법에 비해 높은 분류 정확도를 달성하며, 그 과정에서 해석 가능성을 크게 향상시킵니다.

Conclusion: 이 프레임워크는 HAR의 성능을 높이고 사용자와의 상호작용을 개선합니다.

Abstract: Human Activity Recognition (HAR) has been an active area of research, with applications ranging from healthcare to smart environments. The recent advancements in Large Language Models (LLMs) have opened new possibilities to leverage their capabilities in HAR, enabling not just activity classification but also interpretability and human-like interaction. In this paper, we present a Large Multi-Modal Agent designed for HAR, which integrates the power of LLMs to enhance both performance and user engagement. The proposed framework not only delivers activity classification but also bridges the gap between technical outputs and user-friendly insights through its reasoning and question-answering capabilities. We conduct extensive evaluations using widely adopted HAR datasets, including HHAR, Shoaib, Motionsense to assess the performance of our framework. The results demonstrate that our model achieves high classification accuracy comparable to state-of-the-art methods while significantly improving interpretability through its reasoning and Q&A capabilities.

</details>


### [30] [Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress](https://arxiv.org/abs/2512.19935)
*Samruddhi Baviskar*

Main category: cs.LG

TL;DR: 이 연구는 경제적 스트레스 기간 동안 적대적 취약성이 체계적으로 증가하는 현상인 조건부 적대적 취약성을 소개하고, 이를 평가하기 위한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 경제적 스트레스가 있는 비정상적 환경에서도 금융 의사 결정 시스템에서 사용되는 기계 학습 모델의 적대적 강건성을 평가할 필요가 있습니다.

Method: 경제적 스트레스를 외부 지표로 활용하여, 안정적인 기간과 스트레스 기간 동안 모델의 행동을 평가하는 프레임워크를 제안합니다.

Result: 모델은 스트레스 기간 동안 예측 정확도, 운영 결정 임계치 및 위험 민감한 결과에서 더 큰 성능 저하를 보였습니다.

Conclusion: 이 연구는 금융 기계 학습에서 적대적 강건성이 환경에 따라 달라지며, 고위험 금융 환경에서 모델 위험 평가에 대한 스트레스 인식 접근법이 필요함을 강조합니다.

Abstract: Machine learning models used in financial decision systems operate in nonstationary economic environments, yet adversarial robustness is typically evaluated under static assumptions. This work introduces Conditional Adversarial Fragility, a regime dependent phenomenon in which adversarial vulnerability is systematically amplified during periods of macroeconomic stress. We propose a regime aware evaluation framework for time indexed tabular financial classification tasks that conditions robustness assessment on external indicators of economic stress. Using volatility based regime segmentation as a proxy for macroeconomic conditions, we evaluate model behavior across calm and stress periods while holding model architecture, attack methodology, and evaluation protocols constant. Baseline predictive performance remains comparable across regimes, indicating that economic stress alone does not induce inherent performance degradation. Under adversarial perturbations, however, models operating during stress regimes exhibit substantially greater degradation across predictive accuracy, operational decision thresholds, and risk sensitive outcomes. We further demonstrate that this amplification propagates to increased false negative rates, elevating the risk of missed high risk cases during adverse conditions. To complement numerical robustness metrics, we introduce an interpretive governance layer based on semantic auditing of model explanations using large language models. Together, these results demonstrate that adversarial robustness in financial machine learning is a regime dependent property and motivate stress aware approaches to model risk assessment in high stakes financial deployments.

</details>


### [31] [A K-Means, Ward and DBSCAN repeatability study](https://arxiv.org/abs/2512.19772)
*Anthony Bertrand,Engelbert Mephu Nguifo,Violaine Antoine,David Hill*

Main category: cs.LG

TL;DR: 이 논문은 머신러닝에서 재현성의 중요성을 강조하며, K-Means, DBSCAN, Ward 알고리즘의 기본 단계를 분석하고 각 단계에서 반복성을 달성하기 위한 조건을 식별한다.


<details>
  <summary>Details</summary>
Motivation: 머신러닝에서 재현성이 중요하여 모델이나 실험이 동일한 과학적 결론을 도출할 수 있도록 한다.

Method: K-Means, DBSCAN, Ward와 같은 인기 있는 클러스터링 알고리즘들을 기본 단계로 분해하고 반복성을 위한 조건을 식별한다. Python 라이브러리인 scikit-learn을 활용한 예제를 통해 각 방법의 반복 가능한 측면을 조사한다.

Result: OpenMP 스레드 수가 2를 초과할 때 K-Means의 결과가 일관되지 않음을 발견하였다.

Conclusion: 사용자와 개발자 모두에게 이 문제에 대한 인식을 높이고 추가적인 조사 및 개선을 장려하는 것을 목표로 한다.

Abstract: Reproducibility is essential in machine learning because it ensures that a model or experiment yields the same scientific conclusion. For specific algorithms repeatability with bitwise identical results is also a key for scientific integrity because it allows debugging. We decomposed several very popular clustering algorithms: K-Means, DBSCAN and Ward into their fundamental steps, and we identify the conditions required to achieve repeatability at each stage. We use an implementation example with the Python library scikit-learn to examine the repeatable aspects of each method. Our results reveal inconsistent results with K-Means when the number of OpenMP threads exceeds two. This work aims to raise awareness of this issue among both users and developers, encouraging further investigation and potential fixes.

</details>


### [32] [Guardrailed Uplift Targeting: A Causal Optimization Playbook for Marketing Strategy](https://arxiv.org/abs/2512.19805)
*Deepit Sapru*

Main category: cs.LG

TL;DR: 이 논문은 이질적인 처치 상승 효과를 최대화하는 마케팅 의사 결정 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 이 연구는 수익 및 유지율 극대화를 위한 제약된 타겟팅 전략을 수립하고, 비즈니스 가이드라인을 준수하는 문제를 해결하고자 한다.

Method: 조건부 평균 처치 효과(CATE)를 추정한 후, 제약된 할당 문제를 해결하여 타겟팅할 대상과 제안할 오퍼를 결정한다.

Result: 이 프레임워크는 오프라인 평가에서 상승 AUC, 역 확률 점수(IPS), 자기 정규화 IPS(SNIPS)를 사용하여 지속적으로 경향성과 정적 기초선 대비 우수한 성과를 보인다.

Conclusion: 결과적으로, 마케팅 담당자들이 인과적 타겟팅을 대규모로 운영하고, 가이드라인을 설정하며, 캠페인을 전략적 KPI와 일치시킬 수 있는 재사용 가능한 플레이북이 제공된다.

Abstract: This paper introduces a marketing decision framework that converts heterogeneous-treatment uplift into constrained targeting strategies to maximize revenue and retention while honoring business guardrails. The approach estimates Conditional Average Treatment Effects (CATE) with uplift learners and then solves a constrained allocation to decide who to target and which offer to deploy under limits such as budget or acceptable sales deterioration. Applied to retention messaging, event rewards, and spend-threshold assignment, the framework consistently outperforms propensity and static baselines in offline evaluations using uplift AUC, Inverse Propensity Scoring (IPS), and Self-Normalized IPS (SNIPS). A production-scale online A/B test further validates strategic lift on revenue and completion while preserving customer-experience constraints. The result is a reusable playbook for marketers to operationalize causal targeting at scale, set guardrails, and align campaigns with strategic KPIs.

</details>


### [33] [Fine-Tuned In-Context Learners for Efficient Adaptation](https://arxiv.org/abs/2512.19879)
*Jorg Bornschein,Clare Lyle,Yazhe Li,Amal Rannen-Triki,Xu Owen He,Razvan Pascanu*

Main category: cs.LG

TL;DR: 본 논문은 대규모 언어 모델(LLM)을 특정 하위 작업에 적응시키기 위한 새로운 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델을 특정 작업에 맞추는 방법으로 일반적인 두 가지 접근 방식이 존재하며, 이 두 가지 방식을 통합할 필요성이 있다.

Method: 작업 특정 데이터를 기반으로 한 파인튜닝에 인컨텍스트 예제를 결합하여 모델을 조정함으로써 샘플 효율성과 성능 향상을 동시에 추구한다.

Result: 제안된 방법은 두 기존 방법보다 일관되게 성능을 초월하는 결과를 얻었다.

Conclusion: 저데이터 환경에서 최적의 하이퍼파라미터 선택을 위해 사전 평가를 제안하며, 이를 통해 경량화된 검증 신호를 제공한다.

Abstract: When adapting large language models (LLMs) to a specific downstream task, two primary approaches are commonly employed: (1) prompt engineering, often with in-context few-shot learning, leveraging the model's inherent generalization abilities, and (2) fine-tuning on task-specific data, directly optimizing the model's parameters. While prompt-based methods excel in few-shot scenarios, their effectiveness often plateaus as more data becomes available. Conversely, fine-tuning scales well with data but may underperform when training examples are scarce. We investigate a unified approach that bridges these two paradigms by incorporating in-context learning directly into the fine-tuning process. Specifically, we fine-tune the model on task-specific data augmented with in-context examples, mimicking the structure of k-shot prompts. This approach, while requiring per-task fine-tuning, combines the sample efficiency of in-context learning with the performance gains of fine-tuning, leading to a method that consistently matches and often significantly exceeds both these baselines. To perform hyperparameter selection in the low-data regime, we propose to use prequential evaluation, which eliminates the need for expensive cross-validation and leverages all available data for training while simultaneously providing a robust validation signal. We conduct an extensive empirical study to determine which adaptation paradigm - fine-tuning, in-context learning, or our proposed unified approach offers the best predictive performance on a concrete data downstream-tasks.

</details>


### [34] [Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning](https://arxiv.org/abs/2512.19920)
*Jiayun Wu,Jiashuo Liu,Zhiyuan Zeng,Tianyang Zhan,Wenhao Huang*

Main category: cs.LG

TL;DR: 본 논문은 행동 보정에 대한 철저한 조사를 통해 모델이 불확실성을 인정하도록 유도하는 방법을 제안하고, 이러한 방법이 불확실성 정량화에 있어 더 작은 모델이 최첨단 모델을 능가할 수 있게 함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: LLM의 배치가 중요한 분야에서 지속적인 환각 현상으로 인해 방해받고 있으며, 기존의 RLVR 패러다임이 모델을 정직한 의사소통자보다 시험을 잘 치르는 모델로 유도하기 때문이다.

Method: 행동 보정을 위한 철저한 조사와 훈련 개입을 제안하여 모델이 정확성에 따라 신뢰성이 있는 확률을 출력하도록 하는 방법을 평가한다.

Result: Qwen3-4B-Instruct를 사용한 경험적 분석을 통해 행동 보정된 강화 학습이 작은 모델이 불확실성 정량화에서 최첨단 모델을 초월할 수 있게 함을 보인다.

Conclusion: 우리 모델은 수학적 추론 작업에서 높은 정확도 개선을 보여주어, 다른 모델에 비해 뛰어난 성과를 나타내었다.

Abstract: LLM deployment in critical domains is currently impeded by persistent hallucinations--generating plausible but factually incorrect assertions. While scaling laws drove significant improvements in general capabilities, theoretical frameworks suggest hallucination is not merely stochastic error but a predictable statistical consequence of training objectives prioritizing mimicking data distribution over epistemic honesty. Standard RLVR paradigms, utilizing binary reward signals, inadvertently incentivize models as good test-takers rather than honest communicators, encouraging guessing whenever correctness probability exceeds zero. This paper presents an exhaustive investigation into behavioral calibration, which incentivizes models to stochastically admit uncertainty by abstaining when not confident, aligning model behavior with accuracy. Synthesizing recent advances, we propose and evaluate training interventions optimizing strictly proper scoring rules for models to output a calibrated probability of correctness. Our methods enable models to either abstain from producing a complete response or flag individual claims where uncertainty remains. Utilizing Qwen3-4B-Instruct, empirical analysis reveals behavior-calibrated reinforcement learning allows smaller models to surpass frontier models in uncertainty quantification--a transferable meta-skill decouplable from raw predictive accuracy. Trained on math reasoning tasks, our model's log-scale Accuracy-to-Hallucination Ratio gain (0.806) exceeds GPT-5's (0.207) in a challenging in-domain evaluation (BeyondAIME). Moreover, in cross-domain factual QA (SimpleQA), our 4B LLM achieves zero-shot calibration error on par with frontier models including Grok-4 and Gemini-2.5-Pro, even though its factual accuracy is much lower.

</details>


### [35] [The Seismic Wavefield Common Task Framework](https://arxiv.org/abs/2512.19927)
*Alexey Yermakov,Yue Zhao,Marine Denolle,Yiyu Ni,Philippe M. Wyder,Judah Goldfeder,Stefano Riva,Jan Williams,David Zoro,Amy Sara Rude,Matteo Tomasetto,Joe Germany,Joseph Bakarji,Georg Maierhofer,Miles Cranmer,J. Nathan Kutz*

Main category: cs.LG

TL;DR: 지진학은 상태 예측 및 재구성에 있어 근본적인 문제에 직면해 있으며, 이 문제를 해결하기 위한 기계 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 지진학의 상태 예측과 재구성은 근본적인 도전 과제가 있으며, 그 해결을 위한 인프라가 부족하다.

Method: 우리는 공통 작업 프레임워크(CTF)를 도입하며, 세 가지의 서로 다른 파동 데이터 세트를 사용한다.

Result: 데이터 세트를 통해 다양한 방법과 기본 모델을 평가하여 성능을 보여준다.

Conclusion: 표준화된 평가 방식을 통해 과학적 기계 학습의 철저함과 재현성을 높이는 것을 목표로 한다.

Abstract: Seismology faces fundamental challenges in state forecasting and reconstruction (e.g., earthquake early warning and ground motion prediction) and managing the parametric variability of source locations, mechanisms, and Earth models (e.g., subsurface structure and topography effects). Addressing these with simulations is hindered by their massive scale, both in synthetic data volumes and numerical complexity, while real-data efforts are constrained by models that inadequately reflect the Earth's complexity and by sparse sensor measurements from the field. Recent machine learning (ML) efforts offer promise, but progress is obscured by a lack of proper characterization, fair reporting, and rigorous comparisons. To address this, we introduce a Common Task Framework (CTF) for ML for seismic wavefields, starting with three distinct wavefield datasets. Our CTF features a curated set of datasets at various scales (global, crustal, and local) and task-specific metrics spanning forecasting, reconstruction, and generalization under realistic constraints such as noise and limited data. Inspired by CTFs in fields like natural language processing, this framework provides a structured and rigorous foundation for head-to-head algorithm evaluation. We illustrate the evaluation procedure with scores reported for two of the datasets, showcasing the performance of various methods and foundation models for reconstructing seismic wavefields from both simulated and real-world sensor measurements. The CTF scores reveal the strengths, limitations, and suitability for specific problem classes. Our vision is to replace ad hoc comparisons with standardized evaluations on hidden test sets, raising the bar for rigor and reproducibility in scientific ML.

</details>


### [36] [An Optimal Policy for Learning Controllable Dynamics by Exploration](https://arxiv.org/abs/2512.20053)
*Peter N. Loxley*

Main category: cs.LG

TL;DR: 본 연구에서는 알려지지 않은 환경에서 제어 가능한 동역학을 학습하기 위한 최적 정책의 일반 형태를 제시하며, 이 정책은 탐색을 통해 정보 이득을 극대화하는 간단한 알고리즘을 포함한다.


<details>
  <summary>Details</summary>
Motivation: 제어 가능한 마르코프 연쇄는 연속 의사 결정 작업의 역학을 설명하고 최적 제어 및 강화 학습의 핵심 요소이다.

Method: 제한된 시간 수평선에서 탐색하여 최적 정책을 찾기 위한 단순한 매개변수를 제공하고 알고리즘을 제시한다.

Result: 이 정책은 특정 유형의 상태가 동역학 통제를 제한하는 경우에 필요하며, 여섯 가지 흥미로운 제어 가능한 동역학의 예가 자세히 다뤄진다.

Conclusion: 정책 최적성을 동적 프로그래밍의 순차적 개선 속성을 이용하여 서브 최적 정책과 비교하며 입증한다.

Abstract: Controllable Markov chains describe the dynamics of sequential decision making tasks and are the central component in optimal control and reinforcement learning. In this work, we give the general form of an optimal policy for learning controllable dynamics in an unknown environment by exploring over a limited time horizon. This policy is simple to implement and efficient to compute, and allows an agent to ``learn by exploring" as it maximizes its information gain in a greedy fashion by selecting controls from a constraint set that changes over time during exploration. We give a simple parameterization for the set of controls, and present an algorithm for finding an optimal policy. The reason for this policy is due to the existence of certain types of states that restrict control of the dynamics; such as transient states, absorbing states, and non-backtracking states. We show why the occurrence of these states makes a non-stationary policy essential for achieving optimal exploration. Six interesting examples of controllable dynamics are treated in detail. Policy optimality is demonstrated using counting arguments, comparing with suboptimal policies, and by making use of a sequential improvement property from dynamic programming.

</details>


### [37] [Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection](https://arxiv.org/abs/2512.20086)
*Jeehong Kim,Youngseok Hwang,Minchan Kim,Sungho Bae,Hyunwoo Park*

Main category: cs.LG

TL;DR: 이 논문은 해양 분야에서의 이상 탐지를 위한 새로운 벤치마크 데이터셋을 소개하며, 이는 그래프 기반 이상 탐지를 위해 설계되었다.


<details>
  <summary>Details</summary>
Motivation: 해양 교통과 같은 비격자 환경에서 이상 탐지의 어려움을 극복하고자 함.

Method: 그래프 기반 이상 탐지를 위한 OMTAD의 확장을 통해 노드, 엣지 및 그래프 수준에서 이상을 평가할 수 있는 데이터셋을 제공하고 LLM 기반의 두 가지 전문 에이전트를 활용.

Result: 세 가지 다른 수준의 이상을 체계적으로 평가할 수 있는 데이터셋과 효율적인 이상 생성 방법을 제공.

Conclusion: 이 데이터셋은 비격자 시공간 시스템에서의 이상 탐지 방법론의 발전과 재현 가능성을 증진시키는 데 기여할 것으로 기대된다.

Abstract: Spatio-temporal graph neural networks (ST-GNNs) have achieved notable success in structured domains such as road traffic and public transportation, where spatial entities can be naturally represented as fixed nodes. In contrast, many real-world systems including maritime traffic lack such fixed anchors, making the construction of spatio-temporal graphs a fundamental challenge. Anomaly detection in these non-grid environments is particularly difficult due to the absence of canonical reference points, the sparsity and irregularity of trajectories, and the fact that anomalies may manifest at multiple granularities. In this work, we introduce a novel benchmark dataset for anomaly detection in the maritime domain, extending the Open Maritime Traffic Analysis Dataset (OMTAD) into a benchmark tailored for graph-based anomaly detection. Our dataset enables systematic evaluation across three different granularities: node-level, edge-level, and graph-level anomalies. We plan to employ two specialized LLM-based agents: \emph{Trajectory Synthesizer} and \emph{Anomaly Injector} to construct richer interaction contexts and generate semantically meaningful anomalies. We expect this benchmark to promote reproducibility and to foster methodological advances in anomaly detection for non-grid spatio-temporal systems.

</details>


### [38] [TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning](https://arxiv.org/abs/2512.20312)
*Saisai Yang,Qingyi Huang,Jing Yuan,Liangyu Zha,Kai Tang,Yuhang Yang,Ning Wang,Yucheng Wei,Liyao Li,Wentao Ye,Hao Chen,Tao Zhang,Junlin Zhou,Haobo Wang,Gang Chen,Junbo Zhao*

Main category: cs.LG

TL;DR: TableGPT-R1은 복잡한 표 작업에 대한 고급 추론을 가능하게 하는 강화 학습 기반의 특수화된 모델이다.


<details>
  <summary>Details</summary>
Motivation: 탭ular 데이터 분석과 과학 연구의 필요성에 대응하여, RL을 통해 더 복잡한 테이블 작업의 처리를 향상시키고자 한다.

Method: Systematic RL 프레임워크를 기반으로 한 데이터 엔지니어링 파이프라인을 통해 감독 정렬 및 RL 롤아웃을 위한 난이도 분류된 에이전트 궤적을 합성하고, 규칙 기반 검증과 기준 주입 보상 모델을 결합한 작업 적응 보상 시스템을 적용하며, 전반적인 추론을 안정화한 후 테이블 특정 작업에 전문화하는 다단계 훈련 프레임워크를 채택하였다.

Result: TableGPT-R1은 권위 있는 벤치마크에서 최첨단 성능을 달성하며, 기본 모델보다 현저히 뛰어난 성능을 보인다.

Conclusion: TableGPT-R1은 복잡한 표 작업 내에서 강화 학습의 가능성을 활용하여 이전 모델보다 향상된 일반 능력을 유지하며 성능을 발휘한다.

Abstract: Tabular data serves as the backbone of modern data analysis and scientific research. While Large Language Models (LLMs) fine-tuned via Supervised Fine-Tuning (SFT) have significantly improved natural language interaction with such structured data, they often fall short in handling the complex, multi-step reasoning and robust code execution required for real-world table tasks. Reinforcement Learning (RL) offers a promising avenue to enhance these capabilities, yet its application in the tabular domain faces three critical hurdles: the scarcity of high-quality agentic trajectories with closed-loop code execution and environment feedback on diverse table structures, the extreme heterogeneity of feedback signals ranging from rigid SQL execution to open-ended data interpretation, and the risk of catastrophic forgetting of general knowledge during vertical specialization. To overcome these challenges and unlock advanced reasoning on complex tables, we introduce \textbf{TableGPT-R1}, a specialized tabular model built on a systematic RL framework. Our approach integrates a comprehensive data engineering pipeline that synthesizes difficulty-stratified agentic trajectories for both supervised alignment and RL rollouts, a task-adaptive reward system that combines rule-based verification with a criteria-injected reward model and incorporates process-level step reward shaping with behavioral regularization, and a multi-stage training framework that progressively stabilizes reasoning before specializing in table-specific tasks. Extensive evaluations demonstrate that TableGPT-R1 achieves state-of-the-art performance on authoritative benchmarks, significantly outperforming baseline models while retaining robust general capabilities. Our model is available at https://huggingface.co/tablegpt/TableGPT-R1.

</details>


### [39] [Inverse Autoregressive Flows for Zero Degree Calorimeter fast simulation](https://arxiv.org/abs/2512.20346)
*Emilia Majerz,Witold Dzwinel,Jacek Kitowski*

Main category: cs.LG

TL;DR: 물리 기반 머신러닝은 전통 과학과 현대 데이터 주도 기술을 결합하여 더 정확하고 강력한 모델을 생성합니다.


<details>
  <summary>Details</summary>
Motivation: ALICE 실험의 제로도 칼로리미터(ZDC) 시뮬레이션을 가속화하기 위해 물리 기반 머신러닝 접근법을 활용합니다.

Method: 새로운 손실 함수와 출력 변동성 기반 스케일링 메커니즘을 도입하여 모델이 입자 샤워의 공간 분포와 형태를 정확하게 나타낼 수 있도록 합니다.

Result: 우리 방법은 고전적인 데이터 드리븐 모델 동화보다 우수하며 ZDC 시뮬레이션 문헌의 기존 NF 구현보다 421배 빠른 모델을 제공합니다.

Conclusion: 이 접근법은 특정 리소스를 절약하면서도 시뮬레이션의 효율성을 크게 향상시킵니다.

Abstract: Physics-based machine learning blends traditional science with modern data-driven techniques. Rather than relying exclusively on empirical data or predefined equations, this methodology embeds domain knowledge directly into the learning process, resulting in models that are both more accurate and robust. We leverage this paradigm to accelerate simulations of the Zero Degree Calorimeter (ZDC) of the ALICE experiment at CERN. Our method introduces a novel loss function and an output variability-based scaling mechanism, which enhance the model's capability to accurately represent the spatial distribution and morphology of particle showers in detector outputs while mitigating the influence of rare artefacts on the training. Leveraging Normalizing Flows (NFs) in a teacher-student generative framework, we demonstrate that our approach not only outperforms classic data-driven model assimilation but also yields models that are 421 times faster than existing NF implementations in ZDC simulation literature.

</details>


### [40] [Relu and softplus neural nets as zero-sum turn-based games](https://arxiv.org/abs/2512.20582)
*Stephane Gaubert,Yiannis Vlassopoulos*

Main category: cs.LG

TL;DR: ReLU 신경망의 출력을 제로섬 턴제 정지 게임으로 해석할 수 있으며, 이를 통해 네트워크 출력의 경로 적분 공식을 도출하고 신경망 훈련을 역게임 문제로 전환하는 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 신경망 출력의 해석 및 네트워크 훈련의 새로운 접근 방식을 개발하기 위함이다.

Method: ReLU 신경망의 출력을 제로섬 게임으로 해석하고, 샤플리-벨만 역재귀를 사용하여 게임의 가치를 평가하며, 이를 기반으로 경로 적분 공식을 도출한다.

Result: ReLU 신경망 훈련을 역게임 문제로 변환할 수 있다는 사실과 Softplus 활성화 함수에 대한 유사한 접근법이 가능함을 보여준다.

Conclusion: 이 게임 이론적 표현은 신경망의 출력과 입력 경계를 도출하고 강건성 속성을 검증하는 데 유용하다.

Abstract: We show that the output of a ReLU neural network can be interpreted as the value of a zero-sum, turn-based, stopping game, which we call the ReLU net game. The game runs in the direction opposite to that of the network, and the input of the network serves as the terminal reward of the game. In fact, evaluating the network is the same as running the Shapley-Bellman backward recursion for the value of the game. Using the expression of the value of the game as an expected total payoff with respect to the path measure induced by the transition probabilities and a pair of optimal policies, we derive a discrete Feynman-Kac-type path-integral formula for the network output. This game-theoretic representation can be used to derive bounds on the output from bounds on the input, leveraging the monotonicity of Shapley operators, and to verify robustness properties using policies as certificates. Moreover, training the neural network becomes an inverse game problem: given pairs of terminal rewards and corresponding values, one seeks transition probabilities and rewards of a game that reproduces them. Finally, we show that a similar approach applies to neural networks with Softplus activation functions, where the ReLU net game is replaced by its entropic regularization.

</details>
