<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 15]
- [cs.MA](#cs.MA) [Total: 8]
- [cs.AI](#cs.AI) [Total: 39]
- [cs.LG](#cs.LG) [Total: 49]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [NegBLEURT Forest: Leveraging Inconsistencies for Detecting Jailbreak Attacks](https://arxiv.org/abs/2511.11784)
*Lama Sleem,Jerome Francois,Lujun Li,Nathan Foucher,Niccolo Gentile,Radu State*

Main category: cs.CR

TL;DR: 이 연구는 안전 메커니즘을 우회하는 jailbreak 공격의 위협을 다루며, 새로운 감지 프레임워크인 NegBLEURT Forest를 제안하여 비정상적인 응답을 식별하고 신뢰할 수 있는 jailbreak 검출을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 윤리적 가이드라인에 맞춰도 해로운 콘텐츠를 생성하는 jailbreak 공격의 심각한 위협을 해결하고자 함.

Method: 성공적인 응답과 실패한 응답 간의 의미적 일관성 분석을 통해, 네거이션 인지 점수 접근법을 적용하여 비정상적인 응답을 식별하는 NegBLEURT Forest라는 새로운 감지 프레임워크를 제안.

Result: 제안된 방법이 다양한 모델의 정확도에서 1위 또는 2위로 일관되게 우수한 성능을 달성하고, 경쟁하는 접근법이 모델 및 데이터 변화에 민감하다는 점을 보여줌.

Conclusion: NegBLEURT Forest는 신뢰할 수 있는 jailbreak 검출을 가능하게 하며, 기존의 방법보다 더 뛰어난 성능을 발휘한다.

Abstract: Jailbreak attacks designed to bypass safety mechanisms pose a serious threat by prompting LLMs to generate harmful or inappropriate content, despite alignment with ethical guidelines. Crafting universal filtering rules remains difficult due to their inherent dependence on specific contexts. To address these challenges without relying on threshold calibration or model fine-tuning, this work introduces a semantic consistency analysis between successful and unsuccessful responses, demonstrating that a negation-aware scoring approach captures meaningful patterns. Building on this insight, a novel detection framework called NegBLEURT Forest is proposed to evaluate the degree of alignment between outputs elicited by adversarial prompts and expected safe behaviors. It identifies anomalous responses using the Isolation Forest algorithm, enabling reliable jailbreak detection. Experimental results show that the proposed method consistently achieves top-tier performance, ranking first or second in accuracy across diverse models using the crafted dataset, while competing approaches exhibit notable sensitivity to model and data variations.

</details>


### [2] [VULPO: Context-Aware Vulnerability Detection via On-Policy LLM Optimization](https://arxiv.org/abs/2511.11896)
*Youpeng Li,Fuxun Yu,Xinda Wang*

Main category: cs.CR

TL;DR: VULPO라는 새로운 맥락 인식 취약점 탐지 프레임워크를 도입하며, 기존 접근 방식보다 더욱 효과적인 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 오픈 소스 소프트웨어의 광범위한 사용이 취약점 악용 위험을 증가시키고, 효과적이며 확장 가능한 취약점 탐지의 필요성을 강조한다.

Method: VULPO는 컨텍스트 인식 취약점 탐지를 위한 LLM 강화 학습 프레임워크로, ContextVul이라는 새로운 데이터셋을 구축하고 다차원 보상 구조를 설계한다.

Result: VULPO-4B는 기존 프롬프트 엔지니어링 및 오프 폴리시 최적화 기반의 취약점 탐지 기준선보다 85% 개선된 F1 점수를 기록하며, DeepSeek-R1-0528과 유사한 성능을 발휘한다.

Conclusion: VULPO는 맥락 인식 취약점 탐지에서 기존 방법보다 우수한 성능을 입증하였다.

Abstract: The widespread reliance on open-source software dramatically increases the risk of vulnerability exploitation, underscoring the need for effective and scalable vulnerability detection (VD). Existing VD techniques, whether traditional machine learning-based or LLM-based approaches like prompt engineering, supervised fine-tuning, or off-policy preference optimization, remain fundamentally limited in their ability to perform context-aware analysis: They depend on fixed inputs or static preference datasets, cannot adaptively explore repository-level dependencies, and are constrained by function-level benchmarks that overlook critical vulnerability context.
  This paper introduces Vulnerability-Adaptive Policy Optimization (VULPO), an on-policy LLM reinforcement learning framework for context-aware VD. To support training and evaluation, we first construct ContextVul, a new dataset that augments high-quality function-level samples with lightweight method to extract repository-level context information. We then design multi-dimensional reward structuring that jointly captures prediction correctness, vulnerability localization accuracy, and the semantic relevance of vulnerability analysis, thereby guiding the model toward comprehensive contextual reasoning. To address the asymmetric difficulty of different vulnerability cases and mitigate reward hacking, VULPO incorporates label-level and sample-level difficulty-adaptive reward scaling, encouraging the model to explore challenging cases while maintaining balanced reward distribution. Extensive experiments demonstrate the superiority of our VULPO framework in context-aware VD: Our VULPO-4B substantially outperforms existing VD baselines based on prompt engineering and off-policy optimization, improving F1 by 85% over Qwen3-4B and achieving performance comparable to a 150x larger-scale model, DeepSeek-R1-0528.

</details>


### [3] [Multi-Agent Collaborative Fuzzing with Continuous Reflection for Smart Contracts Vulnerability Detection](https://arxiv.org/abs/2511.12164)
*Jie Chen,Liangmin Wang*

Main category: cs.CR

TL;DR: SmartFuzz는 스마트 계약의 취약점을 탐지하는데 있어 기존의 퍼저들이 가지는 한계를 극복하는 새로운 협업 반영 퍼저이다.


<details>
  <summary>Details</summary>
Motivation: 스마트 계약에서 복잡한 취약점을 탐지하기 위해 기존 퍼저의 한계를 극복하려는 필요.

Method: 스마트 계약의 취약점 탐지를 위해 대형 언어 모델 기반의 에이전트를 퍼징 엔진으로 활용하고, 지속적인 반영 과정을 통해 스스로 개선하는 SmartFuzz를 제안한다.

Result: SmartFuzz가 기존 도구들보다 5.8%-74.7% 더 많은 취약점을 탐지하고, 허위 부정률을 80%까지 줄일 수 있음을 보여준다.

Conclusion: SmartFuzz는 스마트 계약의 퍼징 프로세스를 효율적으로 개선하여 취약점 탐지의 성과를 크게 향상시킨다.

Abstract: Fuzzing is a widely used technique for detecting vulnerabilities in smart contracts, which generates transaction sequences to explore the execution paths of smart contracts. However, existing fuzzers are falling short in detecting sophisticated vulnerabilities that require specific attack transaction sequences with proper inputs to trigger, as they (i) prioritize code coverage over vulnerability discovery, wasting considerable effort on non-vulnerable code regions, and (ii) lack semantic understanding of stateful contracts, generating numerous invalid transaction sequences that cannot pass runtime execution.
  In this paper, we propose SmartFuzz, a novel collaborative reflective fuzzer for smart contract vulnerability detection. It employs large language model-driven agents as the fuzzing engine and continuously improves itself by learning and reflecting through interactions with the environment. Specifically, we first propose a new Continuous Reflection Process (CRP) for fuzzing smart contracts, which reforms the transaction sequence generation as a self-evolving process through continuous reflection on feedback from the runtime environment. Then, we present the Reactive Collaborative Chain (RCC) to orchestrate the fuzzing process into multiple sub-tasks based on the dependencies of transaction sequences. Furthermore, we design a multi-agent collaborative team, where each expert agent is guided by the RCC to jointly generate and refine transaction sequences from both global and local perspectives. We conduct extensive experiments to evaluate SmartFuzz's performance on real-world contracts and DApp projects. The results demonstrate that SmartFuzz outperforms existing state-of-the-art tools: (i) it detects 5.8\%-74.7\% more vulnerabilities within 30 minutes, and (ii) it reduces false negatives by up to 80\%.

</details>


### [4] [RulePilot: An LLM-Powered Agent for Security Rule Generation](https://arxiv.org/abs/2511.12224)
*Hongtai Wang,Ming Xu,Yanpei Guo,Weili Han,Hoon Wei Lim,Jin Song Dong*

Main category: cs.CR

TL;DR: RulePilot은 LLM 기반의 에이전트를 통해 규칙 생성 자동화를 지원하여 보안 엔지니어의 부담을 줄이고 효율성을 높이는 도구이다.


<details>
  <summary>Details</summary>
Motivation: 시스템 보안에 대한 실시간 수요는 탐지 규칙이 침입 탐지 생애 주기의 필수 요소가 되는 결과를 가져온다.

Method: RulePilot은 자연어 기반 설명을 제공하면 자동으로 탐지 규칙을 생성하는 LLM 기반 에이전트이다.

Result: RulePilot은 텍스트 유사성 및 실행 성공 능력 평가에서 기준 모델보다 유의미한 성과를 내며, 107.4%의 텍스트 유사성 향상을 보여준다.

Conclusion: RulePilot은 주니어 분석가와 일반 사용자가 규칙 생성 과정에서 크게 도움을 준다.

Abstract: The real-time demand for system security leads to the detection rules becoming an integral part of the intrusion detection life-cycle. Rule-based detection often identifies malicious logs based on the predefined grammar logic, requiring experts with deep domain knowledge for rule generation. Therefore, automation of rule generation can result in significant time savings and ease the burden of rule-related tasks on security engineers. In this paper, we propose RulePilot, which mimics human expertise via LLM-based agent for addressing rule-related challenges like rule creation or conversion. Using RulePilot, the security analysts do not need to write down the rules following the grammar, instead, they can just provide the annotations such as the natural-language-based descriptions of a rule, our RulePilot can automatically generate the detection rules without more intervention. RulePilot is equipped with the intermediate representation (IR), which abstracts the complexity of config rules into structured, standardized formats, allowing LLMs to focus on generation rules in a more manageable and consistent way. We present a comprehensive evaluation of RulePilot in terms of textual similarity and execution success abilities, showcasing RulePilot can generate high-fidelity rules, outperforming the baseline models by up to 107.4% in textual similarity to ground truths and achieving better detection accuracy in real-world execution tests. We perform a case study from our industry collaborators in Singapore, showcasing that RulePilot significantly help junior analysts/general users in the rule creation process.

</details>


### [5] [Dyadic-Chaotic Lifting S-Boxes for Enhanced Physical-Layer Security within 6G Networks](https://arxiv.org/abs/2511.12325)
*Ilias Cherkaoui,Indrakshi Dey*

Main category: cs.CR

TL;DR: 본 논문에서는 6G 무선 네트워크의 요구에 맞춰 경량의 재구성 가능한 혼란 구성 요소를 제공하는 초기 혼돈 기반 대체 박스(S-box)를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 6G 네트워크는 수십억 개의 자원 제약 장치와 시간 중요 서비스를 연결하며, 전통적인 암호 방식이 지연 및 에너지 측면에서 비효율적이며 대규모 미리 계산 공격에 저항하기 어렵기 때문에 물리적 비밀성(PLS)의 필요성이 대두됩니다.

Method: 혼란 생성과 조건부 샘플링을 결합한 최초의 혼돈 기반 대체 박스를 제안하여 시간에 따라 변하는 8비트 치환을 생성합니다.

Result: 결과로 생성된 S-box는 모든 출력 비트에서 최적의 대수적 차수 7과 평균 비선형성 102.5를 보이며, 세션 간의 혼합화도 지원합니다.

Conclusion: 제안된 재구성 가능한 경량 S-box는 진화하는 위협에 대한 내성을 갖춘 빠르고 하드웨어 친화적인 혼란 구성 요소를 제공하여 6G 네트워크의 PLS 요구를 충족합니다.

Abstract: Sixth-Generation (6G) wireless networks will interconnect billions of resource-constrained devices and time-critical services, where classical, fixed, and heavy cryptography strains latency and energy budgets and struggles against large-scale, pre-computation attacks. Physical-Layer Security (PLS) is therefore pivotal to deliver lightweight, information-theoretic protection, but still requires strong, reconfigurable confusion components that can be diversified per slice, session, or device to blunt large-scale precomputation and side-channel attacks. In order to address the above requirement, we introduce the first-ever chaos-lifted substitution box (S-box) for PLS that couples a $β$-transformation-driven dynamical system with dyadic conditional sampling to generate time-varying, seedable 8-bit permutations on demand. This construction preserves uniformity via ergodicity, yields full 8-bit bijections, and supports on-the-fly diversification across sessions. The resulting S-box attains optimal algebraic degree 7 on every output bit and high average nonlinearity 102.5 (85% of the 8-bit bound), strengthening resistance to algebraic and linear cryptanalysis. Differential and linear profiling report max DDT entry 10 (probability 0.039) and max linear probability 0.648, motivating deployment within a multi-round cipher with a strong diffusion layer, where the security-to-efficiency trade-off is compelling. Our proposed reconfigurable, lightweight S-box directly fulfills key PLS requirements of 6G networks by delivering fast, hardware-amenable confusion components with built-in agility against evolving threats.

</details>


### [6] [GenSIaC: Toward Security-Aware Infrastructure-as-Code Generation with Large Language Models](https://arxiv.org/abs/2511.12385)
*Yikun Li,Matteo Grella,Daniel Nahmias,Gal Engelberg,Dan Klein,Giancarlo Guizzardi,Thijs van Ede,Andrea Continella*

Main category: cs.CR

TL;DR: 이 논문은 대형 언어 모델이 보안 인식 IaC 코드를 생성하는 능력을 조사하고, 이를 통해 잘못된 구성을 피하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 클라우드 인프라의 복잡성이 증가함에 따라 IaC 스크립트에서 잘못된 구성과 보안 취약점의 위험이 증가하고 있다.

Method: LLM의 보안 지식 인식을 평가하고, GenSIaC라는 데이터셋을 통해 LLM을 미세 조정하여 보안-aware IaC 코드를 생성하도록 훈련한다.

Result: 모델이 IaC 보안 잘못 구성을 인식하고 방지하는 성능이 크게 향상됨을 입증, F1-score가 0.303에서 0.858로 증가.

Conclusion: GenSIaC는 다른 LLM들과의 범용성과 크로스 언어적 능력을 탐색하였다.

Abstract: In recent years, Infrastructure as Code (IaC) has emerged as a critical approach for managing and provisioning IT infrastructure through code and automation. IaC enables organizations to create scalable and consistent environments, effectively managing servers and development settings. However, the growing complexity of cloud infrastructures has led to an increased risk of misconfigurations and security vulnerabilities in IaC scripts. To address this problem, this paper investigates the potential of Large Language Models (LLMs) in generating security-aware IaC code, avoiding misconfigurations introduced by developers and administrators.
  While LLMs have made significant progress in natural language processing and code generation, their ability to generate secure IaC scripts remains unclear. This paper addresses two major problems: 1) the lack of understanding of security weaknesses in IaC scripts generated by LLMs, and 2) the absence of techniques for enhancing security in generating IaC code with LLMs.
  To assess the extent to which LLMs contain security knowledge, we first conduct a comprehensive evaluation of base LLMs in recognizing major IaC security weaknesses during the generation and inspection of IaC code. Then, we propose GenSIaC, an instruction fine-tuning dataset designed to improve LLMs' ability to recognize potential security weaknesses. Leveraging GenSIaC, we fine-tune LLMs and instruct models to generate security-aware IaC code. Our evaluation demonstrates that our models achieve substantially improved performance in recognizing and preventing IaC security misconfigurations, e.g., boosting the F1-score from 0.303 to 0.858. Additionally, we perform ablation studies and explore GenSIaC's generalizability to other LLMs and its cross-language capabilities.

</details>


### [7] [Adaptive Dual-Layer Web Application Firewall (ADL-WAF) Leveraging Machine Learning for Enhanced Anomaly and Threat Detection](https://arxiv.org/abs/2511.12643)
*Ahmed Sameh,Sahar Selim*

Main category: cs.CR

TL;DR: 적응형 이중 계층 WAF는 기계 학습 모델을 통해 웹 응용 프로그램의 보안을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 웹 응용 프로그램 방화벽은 악성 트래픽과 합법적 트래픽을 효과적으로 구별하지 못하여 위협 탐지의 효율성이 제한됩니다.

Method: 두 개의 기계 학습 모델을 채택한 적응형 이중 계층 WAF를 제안하며, 첫 번째 계층은 결정 트리 알고리즘을 사용하여 이상을 탐지하고, 두 번째 계층은 서포트 벡터 머신을 사용하여 이상을 분류합니다.

Result: ADL WAF는 99.88%의 탐지 정확도와 100%의 정밀도를 달성하여 이상 탐지를 크게 향상시킵니다.

Conclusion: 기계 학습 기술을 WAF에 통합하면 웹 응용 프로그램 보안이 크게 향상될 수 있습니다.

Abstract: Web Application Firewalls are crucial for protecting web applications against a wide range of cyber threats. Traditional Web Application Firewalls often struggle to effectively distinguish between malicious and legitimate traffic, leading to limited efficacy in threat detection. To overcome these limitations, this paper proposes an Adaptive Dual-Layer WAF employing a two-layered Machine Learning model designed to enhance the accuracy of anomaly and threat detection. The first layer employs a Decision Tree (DT) algorithm to detect anomalies by identifying traffic deviations from established normal patterns. The second layer employs Support Vector Machine to classify these anomalies as either threat anomalies or benign anomalies. Our Adaptive Dual Layer WAF incorporates comprehensive data pre-processing and feature engineering techniques and has been thoroughly evaluated using five large benchmark datasets. Evaluation using these datasets shows that ADL WAF achieves a detection accuracy of 99.88% and a precision of 100%, significantly enhancing anomaly detection and reducing false positives. These findings suggest that integrating machine learning techniques into WAFs can substantially improve web application security by providing more accurate and efficient threat detection.

</details>


### [8] [AI Bill of Materials and Beyond: Systematizing Security Assurance through the AI Risk Scanning (AIRS) Framework](https://arxiv.org/abs/2511.12668)
*Samuel Nathanson,Alexander Lee,Catherine Chen Kieffer,Jared Junkin,Jessica Ye,Amir Saeed,Melanie Lockhart,Russ Fink,Elisha Peterson,Lanier Watkins*

Main category: cs.CR

TL;DR: AI 시스템 보증을 위한 AIRS 프레임워크를 소개하며, 기존의 투명성 메커니즘의 한계를 극복하고 AI 보증을 운영화하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 보증이 소프트웨어 공급망 보안, 적대적 기계 학습, 거버넌스 문서 간에 분산되어 있으며, 기존의 투명성 메커니즘은 모델 보안에 대한 검증 가능한 증거를 제공하지 않는 문제를 해결하기 위함입니다.

Method: AIRS 프레임워크는 위협 모델 기반의 증거 생성 프레임워크로, 세 가지 발전된 파일럿 연구를 통해 AI 문서를 설명적 공개에서 측정 가능한 검증으로 재정의하여 운영화합니다.

Result: AIRS 프레임워크는 LLM에 대한 모델 수준의 보증을 제공하며, 이를 통해 안전한 로더 정책 시행, 해시 검증, 오염 및 백도어 탐지 등이 가능하다는 점을 입증합니다.

Conclusion: AIRS 프레임워크는 AI 도메인에서 SBOM 관행을 확장하여 위협 모델링과 자동화된 증거 생성을 결합하여 신뢰할 수 있는 AI 리스크 문서화를 위한 근본적인 기초를 제공합니다.

Abstract: Assurance for artificial intelligence (AI) systems remains fragmented across software supply-chain security, adversarial machine learning, and governance documentation. Existing transparency mechanisms - including Model Cards, Datasheets, and Software Bills of Materials (SBOMs) - advance provenance reporting but rarely provide verifiable, machine-readable evidence of model security. This paper introduces the AI Risk Scanning (AIRS) Framework, a threat-model-based, evidence-generating framework designed to operationalize AI assurance. The AIRS Framework evolved through three progressive pilot studies - Smurf (AIBOM schema design), OPAL (operational validation), and Pilot C (AIRS) - that reframed AI documentation from descriptive disclosure toward measurable, evidence-bound verification. The framework aligns its assurance fields to the MITRE ATLAS adversarial ML taxonomy and automatically produces structured artifacts capturing model integrity, packaging and serialization safety, structural adapters, and runtime behaviors. Currently, the AIRS Framework is scoped to provide model-level assurances for LLMs, but it could be expanded to include other modalities and cover system-level threats (e.g. application-layer abuses, tool-calling). A proof-of-concept on a quantized GPT-OSS-20B model demonstrates enforcement of safe loader policies, per-shard hash verification, and contamination and backdoor probes executed under controlled runtime conditions. Comparative analysis with SBOM standards of SPDX 3.0 and CycloneDX 1.6 reveals alignment on identity and evaluation metadata, but identifies critical gaps in representing AI-specific assurance fields. The AIRS Framework thus extends SBOM practice to the AI domain by coupling threat modeling with automated, auditable evidence generation, providing a principled foundation for standardized, trustworthy, and machine-verifiable AI risk documentation.

</details>


### [9] [An Evaluation Framework for Network IDS/IPS Datasets: Leveraging MITRE ATT&CK and Industry Relevance Metrics](https://arxiv.org/abs/2511.12743)
*Adrita Rahman Tori,Khondokar Fida Hasan*

Main category: cs.CR

TL;DR: 이 연구는 IDS/IPS의 데이터셋 적합성을 평가하기 위한 새로운 다차원 프레임워크를 제안하며, 특정 산업 맥락에 맞는 데이터셋 선택을 통해 AI 기반 IDS/IPS의 실용성을 향상시키는 방법을 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 현재 IDS/IPS 개발을 위한 AI 모델 평가 관행은 데이터셋의 산업 특정 위협을 간과하면서 주로 정확성 지표에만 초점을 맞추고 있다.

Method: 이 프레임워크는 MITRE ATT&CK 지식 기반을 통합하여 다섯 가지 보완 지표를 사용해 데이터셋의 적합성을 평가한다.

Result: 이 프레임워크를 아홉 개의 공개 IDS/IPS 데이터셋에 적용한 결과 의료, 에너지, 금융 분야에서 위협 범위에 significant gaps가 있음을 나타냈다.

Conclusion: 이 연구는 특정 산업 운영 요구 사항에 맞춘 데이터셋 선택을 위한 표준화되고 해석 가능한 접근 방식을 제공하며, AI 기반 IDS/IPS의 실제 효과를 향상시킬 수 있도록 한다.

Abstract: The performance of Machine Learning (ML) and Deep Learning (DL)-based Intrusion Detection and Prevention Systems (IDS/IPS) is critically dependent on the relevance and quality of the datasets used for training and evaluation. However, current AI model evaluation practices for developing IDS/IPS focus predominantly on accuracy metrics, often overlooking whether datasets represent industry-specific threats. To address this gap, we introduce a novel multi-dimensional framework that integrates the MITRE ATT&CK knowledge base for threat intelligence and employs five complementary metrics that together provide a comprehensive assessment of dataset suitability. Methodologically, this framework combines threat intelligence, natural language processing, and quantitative analysis to assess the suitability of datasets for specific industry contexts. Applying this framework to nine publicly available IDS/IPS datasets reveals significant gaps in threat coverage, particularly in the healthcare, energy, and financial sectors. In particular, recent datasets (e.g., CIC-IoMT, CIC-UNSW-NB15) align better with sector-specific threats, whereas others, like CICIoV-24, underperform despite their recency. Our findings provide a standardized, interpretable approach for selecting datasets aligned with sector-specific operational requirements, ultimately enhancing the real-world effectiveness of AI-driven IDS/IPS deployments. The efficiency and practicality of the framework are validated through deployment in a real-world case study, underscoring its capacity to inform dataset selection and enhance the effectiveness of AI-driven IDS/IPS in operational environments.

</details>


### [10] [Cybersecurity of High-Altitude Platform Stations: Threat Taxonomy, Attacks and Defenses with Standards Mapping - DDoS Attack Use Case](https://arxiv.org/abs/2511.12766)
*Chaouki Hjaiji,Bassem Ouni,Mohamed-Slim Alouini*

Main category: cs.CR

TL;DR: 고고도 플랫폼 스테이션(HAPS)은 비지구 네트워크 내의 성층권 노드로 등장하고 있으며, 이 연구에서는 HAPS 하위 시스템 및 주요 통신 링크에 대한 구조적 개요를 제공하고 사이버 보안 및 프라이버시 노출을 매핑합니다. 또한 HAPS 제약 조건 하에서 가능한 방어 수단을 논의하고, OMNeT++/INET를 사용한 시뮬레이션 기반 사례 연구를 보고하며, 규제 및 표준화 관련 고려 사항을 요약하고 구체적인 미래 연구 방향을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: HAPS는 비지구 네트워크에서 성층권 노드로 등장하고 있어 이들의 보안 및 프라이버시 문제를 다루는 것이 중요하다.

Method: HAPS의 하위 시스템 및 주요 통신 링크에 대한 구조적 개요, 사이버 보안 고찰, HAPS 제약 하의 방어 수단 논의, OMNeT++/INET를 통한 DDoS 영향을 평가하는 시뮬레이션 기반 사례 연구 수행.

Result: HAPS의 하위 시스템과 관련된 보안 취약점을 매핑하고, 여러 방어 수단의 효과를 평가하며, DDoS 공격의 서비스 및 제어-plane 가용성에 미치는 영향을 분석.

Conclusion: HAPS 배치에 대한 엔지니어링 무역 오프를 알리는 데 목적을 두고 있으며, 향후 연구 방향을 제시한다.

Abstract: High-Altitude Platform Stations (HAPS) are emerging stratospheric nodes within non-terrestrial networks. We provide a structured overview of HAPS subsystems and principal communication links, map cybersecurity and privacy exposure across communication, control, and power subsystems, and propose a stratosphere-aware threat taxonomy. We then discuss defenses feasible under HAPS constraints including encryption and authentication, frequency agility, directional and beam-steered antennas, intrusion detection, secure boot, and software and supply-chain assurance-while highlighting how they align with emerging regulatory and standards guidance. Finally, we report a simulation-based case study using OMNeT++/INET to characterize distributed-denial-of-service (DDoS) impact on service and control-plane availability, and summarize regulatory and standardization considerations relevant to deployment. We conclude with concrete future research directions. The study is simulation-grounded and intended to inform engineering trade-offs for real-world HAPS deployments rather than serve as an on-air validation.

</details>


### [11] [Esim: EVM Bytecode Similarity Detection Based on Stable-Semantic Graph](https://arxiv.org/abs/2511.12971)
*Zhuo Chen,Gaoqiang Ji,Yiling He,Lei Wu,Yajin Zhou*

Main category: cs.CR

TL;DR: 탈중앙화 금융(DeFi)에 대한 높은 관심과 성장에도 불구하고, 코드 재사용 및 제한된 오픈 소스 기여는 블록체인 생태계에 중대한 도전을 초래하고 있으며, 이에 따라 EVM 바이트코드의 유사성을 탐지하는 효과적이고 정확한 방법이 필요하다. 본 연구에서는 새로운 EVM 바이트코드 표현인 안정 의미 그래프(SSG)를 제안하고, 이를 이용해 유사성 탐지를 수행하는 프로토타입 Esim을 구현하였다. Esim은 전통적인 접근 방식을 초월하는 성능을 보여주었다.


<details>
  <summary>Details</summary>
Motivation: DeFi의 급속한 확장에도 불구하고, 코드 재사용과 오픈소스 기여의 제한이 블록체인 생태계에 여러 문제를 야기하고 있다. 특히, EVM 바이트코드에 대한 효과적인 유사성 탐지 방법이 절실히 필요하다.

Method: 우리는 '안정한 명령어' 간의 관계를 포착하는 새로운 EVM 바이트코드 표현인 안정 의미 그래프(SSG)를 제안하고, 이 SSG를 이종 그래프 신경망을 이용해 유사성 탐지에 활용하는 프로토타입 Esim을 구현하였다.

Result: Esim은 SSG 구성에서 높은 정확성을 보여주었고, 제어 흐름에서 100%의 F1 점수와 데이터 흐름에서 95.16%의 F1 점수를 달성하였다. 유사성 탐지 성능은 96.3%의 AUC에 달하며, 기존의 전통적인 방법들을 초월하였다.

Conclusion: 우리의 대규모 연구에서는 2,675,573개의 스마트 계약을 분석한 결과, Esim이 취약성 검색에서 Etherscan과 같은 최신 기술 도구보다 우수한 성능을 보였음을 입증하였다.

Abstract: Decentralized finance (DeFi) is experiencing rapid expansion. However, prevalent code reuse and limited open-source contributions have introduced significant challenges to the blockchain ecosystem, including plagiarism and the propagation of vulnerable code. Consequently, an effective and accurate similarity detection method for EVM bytecode is urgently needed to identify similar contracts. Traditional binary similarity detection methods are typically based on instruction stream or control flow graph (CFG), which have limitations on EVM bytecode due to specific features like low-level EVM bytecode and heavily-reused basic blocks. Moreover, the highly-diverse Solidity Compiler (Solc) versions further complicate accurate similarity detection.
  Motivated by these challenges, we propose a novel EVM bytecode representation called Stable-Semantic Graph (SSG), which captures relationships between 'stable instructions' (special instructions identified by our study). Moreover, we implement a prototype, Esim, which embeds SSG into matrices for similarity detection using a heterogeneous graph neural network. Esim demonstrates high accuracy in SSG construction, achieving F1-scores of 100% for control flow and 95.16% for data flow, and its similarity detection performance reaches 96.3% AUC, surpassing traditional approaches. Our large-scale study, analyzing 2,675,573 smart contracts on six EVM-compatible chains over a one-year period, also demonstrates that Esim outperforms the SOTA tool Etherscan in vulnerability search.

</details>


### [12] [SafeGRPO: Self-Rewarded Multimodal Safety Alignment via Rule-Governed Policy Optimization](https://arxiv.org/abs/2511.12982)
*Xuankun Rong,Wenke Huang,Tingfeng Wang,Daiguo Zhou,Bo Du,Mang Ye*

Main category: cs.CR

TL;DR: MLLM(다중 모달 대형 언어 모델)은 복잡한 텍스트-이미지 상호작용으로 인해 발생하는 새로운 안전 위험을 해결하는 SafeGRPO라는 안전 정렬 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: MLLM의 확장된 모달리티 공간은 안전성에 대한 새로운 리스크를 도입하며, 현재의 MLLM에서는 이러한 리스크를 잘 인식하지 못하고 있다.

Method: SafeGRPO는 GRPO에 규칙 기반 보상 구성을 통합하여 해석 가능하고 검증 가능한 안전 최적화를 가능하게 한다. SafeTag-VL-3K 데이터셋을 바탕으로 단계별 안전 사고를 통해 구조화된 추론 및 행동 정렬을 수행한다.

Result: SafeGRPO는 다양한 벤치마크에서 다중 모달 안전 인식, 구성 저항성 및 추론 안정성을 상당히 개선시키면서 일반적인 능력을 희생하지 않는다.

Conclusion: SafeGRPO는 다중 모달 언어 모델의 안전성을 높이기 위한 효율적인 프레임워크로, 기존의 방법들보다 더 나은 성능을 보여준다.

Abstract: Multimodal large language models (MLLMs) have demonstrated impressive reasoning and instruction-following capabilities, yet their expanded modality space introduces new compositional safety risks that emerge from complex text-image interactions. Such cross-modal couplings can produce unsafe semantics even when individual inputs are benign, exposing the fragile safety awareness of current MLLMs. While recent works enhance safety by guiding models to reason about potential risks, unregulated reasoning traces may compromise alignment; although Group Relative Policy Optimization (GRPO) offers self-rewarded refinement without human supervision, it lacks verifiable signals for reasoning safety. To address this, we propose SafeGRPO a self-rewarded multimodal safety alignment framework that integrates rule-governed reward construction into GRPO, enabling interpretable and verifiable optimization of reasoning safety. Built upon the constructed SafeTag-VL-3K dataset with explicit visual, textual, and combined safety tags, SafeGRPO performs step-guided safety thinking to enforce structured reasoning and behavior alignment, substantially improving multimodal safety awareness, compositional robustness, and reasoning stability across diverse benchmarks without sacrificing general capabilities.

</details>


### [13] [DualTAP: A Dual-Task Adversarial Protector for Mobile MLLM Agents](https://arxiv.org/abs/2511.13248)
*Fuyao Zhang,Jiaming Zhang,Che Wang,Xiongtao Sun,Yurong Hao,Guowei Guan,Wenjie Li,Longtao Huang,Wei Yang Bryan Lim*

Main category: cs.CR

TL;DR: 모바일 GUI 에이전트가 다중모드 대형 언어 모델(MLLM)에 의존하면서 개인 식별 정보(PII)를 포함한 스크린샷을 신뢰할 수 없는 제3자 라우터로 전송하는 심각한 개인정보 침해 위험이 발생한다. 기존의 개인정보 보호 방법은 라우터의 MLLM로부터 PII를 보호하면서 에이전트의 MLLM의 작업 유용성을 유지해야 하는 이중적 도전을 해결하지 못한다. 이를 해결하기 위해, 우리는 이 두 상충하는 목표를 최초로 명시적으로 분리하는 신개념 프레임워크인 이중 작업 적대적 보호기(DualTAP)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 모바일 GUI 에이전트의 개인정보 보호를 강화하고 작업의 유용성을 동시에 유지하기 위한 필요성.

Method: DualTAP는 경량 생성기를 훈련시키며, 두 가지 주요 혁신을 가지고 있다: (i) PII 민감 영역만을 식별하고 표적화하는 대비 주의 모듈과 (ii) 작업 유지 손실과 개인정보 간섭 손실을 동시에 최소화하는 이중 작업 적대적 목표.

Result: DualTAP는 평균 개인정보 유출율을 31.6 포인트 감소시키며(3.0배 상대 개선) 80.8%의 작업 성공률을 유지한다.

Conclusion: DualTAP는 모바일 MLLM 에이전트의 개인정보-유용성 트레이드오프에 대한 첫 번째 실행 가능한 솔루션을 제시한다.

Abstract: The reliance of mobile GUI agents on Multimodal Large Language Models (MLLMs) introduces a severe privacy vulnerability: screenshots containing Personally Identifiable Information (PII) are often sent to untrusted, third-party routers. These routers can exploit their own MLLMs to mine this data, violating user privacy. Existing privacy perturbations fail the critical dual challenge of this scenario: protecting PII from the router's MLLM while simultaneously preserving task utility for the agent's MLLM. To address this gap, we propose the Dual-Task Adversarial Protector (DualTAP), a novel framework that, for the first time, explicitly decouples these conflicting objectives. DualTAP trains a lightweight generator using two key innovations: (i) a contrastive attention module that precisely identifies and targets only the PII-sensitive regions, and (ii) a dual-task adversarial objective that simultaneously minimizes a task-preservation loss (to maintain agent utility) and a privacy-interference loss (to suppress PII leakage). To facilitate this study, we introduce PrivScreen, a new dataset of annotated mobile screenshots designed specifically for this dual-task evaluation. Comprehensive experiments on six diverse MLLMs (e.g., GPT-5) demonstrate DualTAP's state-of-the-art protection. It reduces the average privacy leakage rate by 31.6 percentage points (a 3.0x relative improvement) while, critically, maintaining an 80.8% task success rate - a negligible drop from the 83.6% unprotected baseline. DualTAP presents the first viable solution to the privacy-utility trade-off in mobile MLLM agents.

</details>


### [14] [ForgeDAN: An Evolutionary Framework for Jailbreaking Aligned Large Language Models](https://arxiv.org/abs/2511.13548)
*Siyang Cheng,Gaotian Liu,Rui Mei,Yilin Wang,Kejia Zhang,Kaishuo Wei,Yuqi Yu,Weiping Wen,Xiaojie Wu,Junhua Liu*

Main category: cs.CR

TL;DR: ForgeDAN은 기존의 제한된 접근 방식의 한계를 극복하고 효과적인 공격 프롬프트 생성을 위한 새로운 진화적 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 급속한 채택은 혁신적 응용 프로그램과 함께 새로운 보안 위험을 초래하고 있다.

Method: ForgeDAN은 다중 전략 텍스트 왜곡을 사용하여 공격의 다양성을 향상시키고, 의미론적 적합성 평가를 통해 진화 과정을 안내하며, 모델 준수 및 출력 유해성을 평가하는 이중 차원 재탈옥 판단을 통합한다.

Result: ForgeDAN은 높은 재탈옥 성공률을 기록하면서 자연스러움과 잠행성을 유지하여 기존 최첨단 솔루션을 능가한다.

Conclusion: ForgeDAN은 안전성과 효율성을 높이는 방식으로 다각적인 접근을 통해 재탈옥 공격을 실행한다.

Abstract: The rapid adoption of large language models (LLMs) has brought both transformative applications and new security risks, including jailbreak attacks that bypass alignment safeguards to elicit harmful outputs. Existing automated jailbreak generation approaches e.g. AutoDAN, suffer from limited mutation diversity, shallow fitness evaluation, and fragile keyword-based detection. To address these limitations, we propose ForgeDAN, a novel evolutionary framework for generating semantically coherent and highly effective adversarial prompts against aligned LLMs. First, ForgeDAN introduces multi-strategy textual perturbations across \textit{character, word, and sentence-level} operations to enhance attack diversity; then we employ interpretable semantic fitness evaluation based on a text similarity model to guide the evolutionary process toward semantically relevant and harmful outputs; finally, ForgeDAN integrates dual-dimensional jailbreak judgment, leveraging an LLM-based classifier to jointly assess model compliance and output harmfulness, thereby reducing false positives and improving detection effectiveness. Our evaluation demonstrates ForgeDAN achieves high jailbreaking success rates while maintaining naturalness and stealth, outperforming existing SOTA solutions.

</details>


### [15] [TZ-LLM: Protecting On-Device Large Language Models with Arm TrustZone](https://arxiv.org/abs/2511.13717)
*Xunjie Wang,Jiacheng Shi,Zihan Zhao,Yang Yu,Zhichao Hua,Jinyu Gu*

Main category: cs.CR

TL;DR: 모바일 장치에서 실행되는 대형 언어 모델(LLM)은 사용자 프라이버시와 네트워크 지연 시간 감소의 이점을 제공하지만, 독점 모델의 사용자 유출이라는 심각한 보안 위험을 초래합니다. 이를 완화하기 위해, 우리는 Arm Trusted Execution Environment(TEE)인 TrustZone을 활용한 LLM 보호 시스템 설계를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 모바일 장치에서 LLM을 구현할 때 사용자 프라이버시와 빠른 응답 시간의 균형을 유지하면서도 보안을 보장하는 것이 필요합니다.

Method: 우리는 TEE 메모리 내에서 모델 매개변수를 캐싱하여 메모리 효율성과 빠른 추론 사이의 딜레마를 해결하고, REE와 TEE 간의 NPU 시간 공유의 비효율성을 해결하기 위해 파이프라인 복원과 공조자 설계를 도입했습니다.

Result: 우리의 시스템은 기존 TEE 대비 TTFT를 최대 90.9% 줄이고, 디코딩 속도를 최대 23.2% 증가시켰습니다.

Conclusion: 따라서 우리의 접근 방식은 모바일 장치에서 LLM의 보안을 강화하고 성능을 개선하는 데 기여합니다.

Abstract: Large Language Models (LLMs) deployed on mobile devices offer benefits like user privacy and reduced network latency, but introduce a significant security risk: the leakage of proprietary models to end users.
  To mitigate this risk, we propose a system design for protecting on-device LLMs using Arm Trusted Execution Environment (TEE), TrustZone. Our system addresses two primary challenges: (1) The dilemma between memory efficiency and fast inference (caching model parameters within TEE memory). (2) The lack of efficient and secure Neural Processing Unit (NPU) time-sharing between Rich Execution Environment (REE) and TEE.
  Our approach incorporates two key innovations. First, we employ pipelined restoration, leveraging the deterministic memory access patterns of LLM inference to prefetch parameters on demand, hiding memory allocation, I/O and decryption latency under computation time. Second, we introduce a co-driver design, creating a minimal data plane NPU driver in the TEE that collaborates with the full-fledged REE driver. This reduces the TEE TCB size and eliminates control plane reinitialization overhead during NPU world switches.
  We implemented our system on the emerging OpenHarmony OS and the llama.cpp inference framework, and evaluated it with various LLMs on an Arm Rockchip device. Compared to a strawman TEE baseline lacking our optimizations, our system reduces TTFT by up to 90.9% and increases decoding speed by up to 23.2%.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [16] [MALBO: Optimizing LLM-Based Multi-Agent Teams via Multi-Objective Bayesian Optimization](https://arxiv.org/abs/2511.11788)
*Antonio Sabbatella*

Main category: cs.MA

TL;DR: MALBO는 LLM 기반 다중 에이전트 팀 구성의 효율성을 자동화하는 체계적인 프레임워크로, 다중 목표 최적화 문제를 공식화하고, 성능과 비용 간의 균형을 맞춘 최적 팀 구성을 제공한다.


<details>
  <summary>Details</summary>
Motivation: LLM을 멀티 에이전트 시스템의 전문 역할에 최적 할당하는 것이 복잡한 조합적 검색 공간과 비용 대비 성능 간의 본질적인 트레이드오프 때문에 큰 도전이다.

Method: MALBO(Multi-Agent LLM Bayesian Optimization)라는 체계적인 프레임워크를 제안하며, 이를 통해 LLM 기반 에이전트 팀의 효율적 구성을 자동화한다. 이 방법은 다중 목표 베이지안 최적화(MOBO)를 사용하며, 독립적인 가우시안 프로세스 대리 모델을 활용하여 LLM의 연속 피처 공간 표현에서 탐색한다.

Result: 베이지안 최적화 단계가 초기의 임의 검색에 비해 평균 성능을 유지하면서 평균 구성 비용을 45% 이상 감소시켰으며, 전문화된 이질적 팀이 동질적 기준과 비교해 최대 65.8%의 비용 절감을 달성했다.

Conclusion: 이 프레임워크는 비용 효율적이며 전문화된 다중 에이전트 AI 시스템을 배포하기 위한 데이터 기반 도구를 제공한다.

Abstract: The optimal assignment of Large Language Models (LLMs) to specialized roles in multi-agent systems is a significant challenge, defined by a vast combinatorial search space, expensive black-box evaluations, and an inherent trade-off between performance and cost. Current optimization methods focus on single-agent settings and lack a principled framework for this multi-agent, multi-objective problem.
  This thesis introduces MALBO (Multi-Agent LLM Bayesian Optimization), a systematic framework designed to automate the efficient composition of LLM-based agent teams. We formalize the assignment challenge as a multi-objective optimization problem, aiming to identify the Pareto front of configurations between task accuracy and inference cost. The methodology employs multi-objective Bayesian Optimization (MOBO) with independent Gaussian Process surrogate models. By searching over a continuous feature-space representation of the LLMs, this approach performs a sample-efficient exploration guided by the expected hypervolume improvement.
  The primary contribution is a principled and automated methodology that yields a Pareto front of optimal team configurations. Our results demonstrate that the Bayesian optimization phase, compared to an initial random search, maintained a comparable average performance while reducing the average configuration cost by over 45%. Furthermore, MALBO identified specialized, heterogeneous teams that achieve cost reductions of up to 65.8% compared to homogeneous baselines, all while maintaining maximum performance. The framework thus provides a data-driven tool for deploying cost-effective and highly specialized multi-agent AI systems.

</details>


### [17] [From Single to Societal: Analyzing Persona-Induced Bias in Multi-Agent Interactions](https://arxiv.org/abs/2511.11789)
*Jiayi Li,Xiao Liu,Yansong Feng*

Main category: cs.MA

TL;DR: 다양한 행동을 촉진하기 위해 에이전트에 페르소나를 부여하는 다중 에이전트 시스템에서 페르소나가 편향을 초래하는지 여부를 조사한 연구.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 다중 에이전트 시스템에서 페르소나가 상호작용에 미치는 영향을 탐구하기 위해.

Method: 협업 문제 해결과 설득 작업에서 통제된 실험 시리즈를 통해 데이터를 수집했다.

Result: LLM 기반 에이전트는 신뢰성과 주장 강도에서 편향을 보이며, 역사적으로 유리한 그룹의 페르소나는 신뢰도가 낮고 주장 강도가 적다. 에이전트는 유사한 페르소나를 가진 다른 사람에게 순응하는 경향이 강하다.

Conclusion: 다양한 LLM, 그룹 규모 및 상호작용 라운드에서 이러한 편향이 지속되며, 다중 에이전트 시스템의 공정성과 신뢰성을 보장하기 위해 인식과 완화가 필요하다.

Abstract: Large Language Model (LLM)-based multi-agent systems are increasingly used to simulate human interactions and solve collaborative tasks. A common practice is to assign agents with personas to encourage behavioral diversity. However, this raises a critical yet underexplored question: do personas introduce biases into multi-agent interactions? This paper presents a systematic investigation into persona-induced biases in multi-agent interactions, with a focus on social traits like trustworthiness (how an agent's opinion is received by others) and insistence (how strongly an agent advocates for its opinion). Through a series of controlled experiments in collaborative problem-solving and persuasion tasks, we reveal that (1) LLM-based agents exhibit biases in both trustworthiness and insistence, with personas from historically advantaged groups (e.g., men and White individuals) perceived as less trustworthy and demonstrating less insistence; and (2) agents exhibit significant in-group favoritism, showing a higher tendency to conform to others who share the same persona. These biases persist across various LLMs, group sizes, and numbers of interaction rounds, highlighting an urgent need for awareness and mitigation to ensure the fairness and reliability of multi-agent systems.

</details>


### [18] [Conflict-Free Flight Scheduling Using Strategic Demand Capacity Balancing for Urban Air Mobility Operations](https://arxiv.org/abs/2511.11854)
*Vahid Hemmati,Yonas Ayalew,Ahmad Mohammadi,Reza Ahmari,Parham Kebria,Abdollah Homaifar,Mehrdad Saif*

Main category: cs.MA

TL;DR: 이 논문에서는 도심 항공 이동성(UAM) 작용을 위한 제약된 공역에서의 강력한 분리를 보장하는 충돌 없는 다중 에이전트 비행 일정 계획을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 도심 지역에서의 항공 모빌리티의 필요성과 제약된 공역에서의 비행 이동의 효율성을 확보하기 위함입니다.

Method: 지연 출발을 기반으로 한 쌍방 충돌 회피(PCA) 기법을 도입하고, 이를 다중 에이전트 시나리오로 확장하여 최적화 접근법을 수립합니다.

Result: 우리의 방법은 다양한 다중 에이전트 환경과 실제 UAM 사용 사례에서 전체 지연 시간을 유의미하게 감소시키며 충돌 없는 비행을 보장합니다.

Conclusion: 이 접근법은 신흥 도시 항공 모빌리티 시스템을 위한 확장 가능한 프레임워크를 제공합니다.

Abstract: In this paper, we propose a conflict-free multi- agent flight scheduling that ensures robust separation in con- strained airspace for Urban Air Mobility (UAM) operations application. First, we introduce Pairwise Conflict Avoidance (PCA) based on delayed departures, leveraging kinematic principles to maintain safe distances. Next, we expand PCA to multi-agent scenarios, formulating an optimization approach that systematically determines departure times under increasing traffic densities. Performance metrics, such as average delay, assess the effectiveness of our solution. Through numerical simulations across diverse multi-agent environments and real- world UAM use cases, our method demonstrates a significant reduction in total delay while ensuring collision-free operations. This approach provides a scalable framework for emerging urban air mobility systems.

</details>


### [19] [Goal-Oriented Multi-Agent Reinforcement Learning for Decentralized Agent Teams](https://arxiv.org/abs/2511.11992)
*Hung Du,Hy Nguyen,Srikanth Thudumu,Rajesh Vasa,Kon Mouzakis*

Main category: cs.MA

TL;DR: 이 연구는 동적 환경에서의 자율 차량을 위한 분산형 다중 에이전트 강화 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 차량들은 제한된 통신 및 중앙 집중식 제어 없이 동적이고 예측 불가능한 환경에서 작동해야 하며, 이는 차량 간의 조정에 중대한 도전을 제기한다.

Method: 우리는 차량이 지역 목표 및 관찰에 기반하여 선택적으로 통신할 수 있도록 하는 분산형 다중 에이전트 강화 학습(MARL) 프레임워크를 제안한다.

Result: 우리의 접근 방식은 장애물 및 동적 에이전트 집단이 있는 복잡한 다중 에이전트 내비게이션 작업에서 검증되었으며, 결과는 우리의 방법이 비협력적 기준에 비해 작업 성공률을 크게 개선하고 목표 도달 시간을 줄인다는 것을 보여준다.

Conclusion: 이 연구 결과는 분산형, 목표 기반 MARL이 다양한 영역에서 운영되는 현실적인 다중 차량 시스템에서 효과적인 조정을 지원할 수 있는 잠재력을 강조한다.

Abstract: Connected and autonomous vehicles across land, water, and air must often operate in dynamic, unpredictable environments with limited communication, no centralized control, and partial observability. These real-world constraints pose significant challenges for coordination, particularly when vehicles pursue individual objectives. To address this, we propose a decentralized Multi-Agent Reinforcement Learning (MARL) framework that enables vehicles, acting as agents, to communicate selectively based on local goals and observations. This goal-aware communication strategy allows agents to share only relevant information, enhancing collaboration while respecting visibility limitations. We validate our approach in complex multi-agent navigation tasks featuring obstacles and dynamic agent populations. Results show that our method significantly improves task success rates and reduces time-to-goal compared to non-cooperative baselines. Moreover, task performance remains stable as the number of agents increases, demonstrating scalability. These findings highlight the potential of decentralized, goal-driven MARL to support effective coordination in realistic multi-vehicle systems operating across diverse domains.

</details>


### [20] [FINRS: A Risk-Sensitive Trading Framework for Real Financial Markets](https://arxiv.org/abs/2511.12599)
*Bijia Liu,Ronghao Dang*

Main category: cs.MA

TL;DR: FinRS는 금융 거래를 위한 위험-민감한 거래 프레임워크로, 기존 LLM 기반 거래 에이전트의 한계를 보완한다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 거래 에이전트는 단일 단계 예측에 집중하고 있으며, 변동성이 큰 시장에서의 효과를 낮추는 위험 관리 메커니즘이 통합되어 있지 않다.

Method: FinRS는 계층적 시장 분석, 이중 결정 에이전트 및 다중 시간 규모 보상 반영을 결합하여 거래 행동을 수익 목표와 하방 위험 제약에 맞춘다.

Result: 여러 주식 및 시장 조건에 대한 실험 결과, FinRS는 최첨단 방법에 비해 우수한 수익성과 안정성을 보여준다.

Conclusion: 이러한 접근 방식은 변동성을 고려한 더 효과적인 거래를 가능하게 한다.

Abstract: Large language models (LLMs) have shown strong reasoning capabilities and are increasingly explored for financial trading. Existing LLM-based trading agents, however, largely focus on single-step prediction and lack integrated mechanisms for risk management, which reduces their effectiveness in volatile markets. We introduce FinRS, a risk-sensitive trading framework that combines hierarchical market analysis, dual-decision agents, and multi-timescale reward reflection to align trading actions with both return objectives and downside risk constraints. Experiments on multiple stocks and market conditions show that FinRS achieves superior profitability and stability compared to state-of-the-art methods.

</details>


### [21] [ENGRAM: Effective, Lightweight Memory Orchestration for Conversational Agents](https://arxiv.org/abs/2511.12960)
*Daivik Patel,Shrenik Patel*

Main category: cs.MA

TL;DR: ENGRAM은 사용자 상호작용을 기억하고 사용자 선호도를 존중하며 과거 사건에 근거하는 경량 메모리 시스템으로, 기존의 복잡한 아키텍처 없이 효과적인 장기 기억 관리를 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 사용자 인터페이스에서 작동하는 대형 언어 모델은 기존 상호작용을 기억하고 사용자 선호도를 존중하며 과거 사건에 기반한 추론을 할 수 있는 긴 수명의 일관성을 필요로 한다.

Method: ENGRAM은 대화 내용을 세 가지 기본 메모리 유형(에피소드형, 의미형, 절차형)으로 조직하는 경량 메모리 시스템으로, 단일 라우터와 검색기를 통해 작동한다. 각 사용자 발언은 정규화된 스키마와 임베딩을 가진 메모리 기록으로 변환되어 데이터베이스에 저장된다.

Result: ENGRAM은 긴 수명의 메모리를 위한 다중 세션 대화형 QA 벤치마크인 LoCoMo에서 최첨단 결과를 달성하였으며, LongMemEval에서 전체 맥락 기준선을 15점 초과하며 약 1%의 토큰만을 사용하였다.

Conclusion: 이 결과는 신중한 메모리 유형 지정과 간단한 밀집 검색이 복잡한 아키텍처 없이도 언어 모델에서 효과적인 장기 기억 관리를 가능하게 한다는 것을 보여준다.

Abstract: Large language models (LLMs) deployed in user-facing applications require long-horizon consistency: the ability to remember prior interactions, respect user preferences, and ground reasoning in past events. However, contemporary memory systems often adopt complex architectures such as knowledge graphs, multi-stage retrieval pipelines, and OS-style schedulers, which introduce engineering complexity and reproducibility challenges. We present ENGRAM, a lightweight memory system that organizes conversation into three canonical memory types (episodic, semantic, and procedural) through a single router and retriever. Each user turn is converted into typed memory records with normalized schemas and embeddings and stored in a database. At query time, the system retrieves top-k dense neighbors for each type, merges results with simple set operations, and provides the most relevant evidence as context to the model. ENGRAM attains state-of-the-art results on LoCoMo, a multi-session conversational QA benchmark for long-horizon memory, and exceeds the full-context baseline by 15 points on LongMemEval while using only about 1% of the tokens. These results show that careful memory typing and straightforward dense retrieval can enable effective long-term memory management in language models without requiring complex architectures.

</details>


### [22] [LLM-based Multi-Agent System for Simulating Strategic and Goal-Oriented Data Marketplaces](https://arxiv.org/abs/2511.13233)
*Jun Sashihara,Yukihisa Fujita,Kota Nakamura,Masahiro Kuwahara,Teruaki Hayashi*

Main category: cs.MA

TL;DR: 데이터 마켓플레이스의 구매 및 교환을 중개하는 LLM 기반 다중 에이전트 시스템을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 데이터 수집 비용과 노력을 줄이면서 다양한 데이터셋의 거래를 가능하게 하는 데이터 마켓플레이스의 중요성이 증가하고 있다. 그러나 참가자, 데이터, 규제 간의 상호작용에 대한 체계적인 이해가 부족하다.

Method: 구매자 및 판매자 에이전트는 LLM 기반으로 명시적인 목표를 가지고 전략적 행동을 자율적으로 수행한다. 이들은 시장 역학을 추론하고 미래 수요를 예측하며 전략을 조정할 수 있다.

Result: LLM-MAS는 전통적인 접근법과 비교할 때 실제 데이터 마켓플레이스에서 관찰된 거래 패턴을 더 충실히 재현하며 시장 트렌드의 알림 및 진화도 포착한다.

Conclusion: 결과적으로 LLM-MAS는 데이터 마켓플레이스의 상호작용을 보다 잘 설명하고, 변화하는 시장 환경에 대한 적응적인 행동 선택을 가능하게 한다.

Abstract: Data marketplaces, which mediate the purchase and exchange of data from third parties, have attracted growing attention for reducing the cost and effort of data collection while enabling the trading of diverse datasets. However, a systematic understanding of the interactions between market participants, data, and regulations remains limited. To address this gap, we propose a Large Language Model-based Multi-Agent System (LLM-MAS) for data marketplaces. In our framework, buyer and seller agents powered by LLMs operate with explicit objectives and autonomously perform strategic actions, such as planning, searching, purchasing, pricing, and updating data. These agents can reason about market dynamics, forecast future demand, and adjust strategies accordingly. Unlike conventional model-based simulations, which are typically constrained to predefined rules, LLM-MAS supports broader and more adaptive behavior selection through natural language reasoning. We evaluated the framework via simulation experiments using three distribution-based metrics: (1) the number of purchases per dataset, (2) the number of purchases per buyer, and (3) the number of repeated purchases of the same dataset. The results demonstrate that LLM-MAS more faithfully reproduces trading patterns observed in real data marketplaces compared to traditional approaches, and further captures the emergence and evolution of market trends.

</details>


### [23] [Market-Dependent Communication in Multi-Agent Alpha Generation](https://arxiv.org/abs/2511.13614)
*Jerick Shi,Burton Hollifield*

Main category: cs.MA

TL;DR: 다양한 전략을 가진 헤지펀드는 분석가들이 거래 전략을 소통해야 하는지에 대한 근본적인 조직 선택에 직면한다. 이 연구는 5명으로 구성된 LLM 기반 거래 시스템을 통해 450번의 실험을 수행함으로써 이러한 문제를 탐구한다. 결과적으로 소통은 성과를 향상시키지만, 최적의 소통 디자인은 시장 특성에 따라 달라진다.


<details>
  <summary>Details</summary>
Motivation: 다양한 전략을 가진 헤지펀드에서 분석가들 간의 소통 방식이 성과에 미치는 영향을 탐구하고 싶었다.

Method: 5명으로 구성된 LLM 기반 거래 시스템을 사용하여 450개의 실험을 수행하고, 통신이 거래 성과에 미치는 영향을 분석했다.

Result: 소통은 성과를 향상시키지만, 시장 특성에 따라 최적의 소통 방식이 달라진다. 경쟁적인 대화가 변동성이 큰 기술 주식에서 뛰어난 성과를 보였고, 협력적인 대화는 안정적인 일반 주식에서 우위를 점했다. 금융 주식은 모든 소통 개입에 저항했다.

Conclusion: 최적의 소통 디자인은 시장의 변동성 특성과 일치해야 하며, 정교한 논의가 반드시 더 나은 성과를 보장하지는 않는다.

Abstract: Multi-strategy hedge funds face a fundamental organizational choice: should analysts generating trading strategies communicate, and if so, how? We investigate this using 5-agent LLM-based trading systems across 450 experiments spanning 21 months, comparing five organizational structures from isolated baseline to collaborative and competitive conversation. We show that communication improves performance, but optimal communication design depends on market characteristics. Competitive conversation excels in volatile technology stocks, while collaborative conversation dominates stable general stocks. Finance stocks resist all communication interventions. Surprisingly, all structures, including isolated agents, converge to similar strategy alignments, challenging assumptions that transparency causes harmful diversity loss. Performance differences stem from behavioral mechanisms: competitive agents focus on stock-level allocation while collaborative agents develop technical frameworks. Conversation quality scores show zero correlation with returns. These findings demonstrate that optimal communication design must match market volatility characteristics, and sophisticated discussions don't guarantee better performance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [SynBullying: A Multi LLM Synthetic Conversational Dataset for Cyberbullying Detectio](https://arxiv.org/abs/2511.11599)
*Arefeh Kazemi,Hamza Qadeer,Joachim Wagner,Hossein Hosseini,Sri Balaaji Natarajan Kalaivendan,Brian Davis*

Main category: cs.AI

TL;DR: SynBullying은 사이버 괴롭힘 연구와 탐지를 위한 합성 다중 LLM 대화 데이터셋이다.


<details>
  <summary>Details</summary>
Motivation: 사이버 괴롭힘을 연구하고 탐지하기 위해 더 안전하고 확장 가능한 데이터 수집 방법을 찾기 위해.

Method: 대규모 언어 모델(LLM)을 이용하여 현실적인 괴롭힘 상호작용을 시뮬레이션하여 데이터셋을 생성하였다.

Result: SynBullying은 대화 구조, 맥락 인식 주석, 세분화된 라벨링 등 다양한 특성을 포함하고 있다.

Conclusion: 자체 훈련 데이터와 사이버 괴롭힘 분류를 위한 증강 소스로서 SynBullying의 성능을 평가하였다.

Abstract: We introduce SynBullying, a synthetic multi-LLM conversational dataset for studying and detecting cyberbullying (CB). SynBullying provides a scalable and ethically safe alternative to human data collection by leveraging large language models (LLMs) to simulate realistic bullying interactions. The dataset offers (i) conversational structure, capturing multi-turn exchanges rather than isolated posts; (ii) context-aware annotations, where harmfulness is assessed within the conversational flow considering context, intent, and discourse dynamics; and (iii) fine-grained labeling, covering various CB categories for detailed linguistic and behavioral analysis. We evaluate SynBullying across five dimensions, including conversational structure, lexical patterns, sentiment/toxicity, role dynamics, harm intensity, and CB-type distribution. We further examine its utility by testing its performance as standalone training data and as an augmentation source for CB classification.

</details>


### [25] [Value-Aligned Prompt Moderation via Zero-Shot Agentic Rewriting for Safe Image Generation](https://arxiv.org/abs/2511.11693)
*Xin Zhao,Xiaojun Chen,Bingshan Liu,Zeyao Liu,Zhendong Zhao,Xiaoyan Gu*

Main category: cs.AI

TL;DR: VALOR라는 모듈형 프레임워크를 통해 텍스트-이미지 생성에서의 안전성과 유용성을 극대화하고, 출력의 인간 가치 정렬을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: Generative vision-language 모델이 창의적인 미디어 합성에서 뛰어난 능력을 보여주지만, 적대적인 프롬프트로 인해 안전하지 않거나 공격적이며 문화적으로 부적절한 콘텐츠를 생성할 위험이 크기 때문에 이 문제를 해결하고자 합니다.

Method: VALOR는 다층 프롬프트 분석과 인간 정렬 가치 추론을 통합한 제로샷 에이전틱 프레임워크입니다. NSFW 탐지기, 문화적 가치 정렬 모듈, 그리고 의도 모호성 탐지기를 포함하여 안전하지 않은 콘텐츠를 탐지합니다.

Result: VALOR는 실험을 통해 최대 100.00%의 안전하지 않은 출력을 줄이면서도 프롬프트의 유용성과 창의성을 유지하는 데 성공했습니다.

Conclusion: 이 결과는 VALOR가 개방형 세계 환경에서 안전하고 정렬된 유용한 이미지 생성 시스템을 배포하는 데 있어 확장 가능하고 효과적인 접근 방식임을 강조합니다.

Abstract: Generative vision-language models like Stable Diffusion demonstrate remarkable capabilities in creative media synthesis, but they also pose substantial risks of producing unsafe, offensive, or culturally inappropriate content when prompted adversarially. Current defenses struggle to align outputs with human values without sacrificing generation quality or incurring high costs. To address these challenges, we introduce VALOR (Value-Aligned LLM-Overseen Rewriter), a modular, zero-shot agentic framework for safer and more helpful text-to-image generation. VALOR integrates layered prompt analysis with human-aligned value reasoning: a multi-level NSFW detector filters lexical and semantic risks; a cultural value alignment module identifies violations of social norms, legality, and representational ethics; and an intention disambiguator detects subtle or indirect unsafe implications. When unsafe content is detected, prompts are selectively rewritten by a large language model under dynamic, role-specific instructions designed to preserve user intent while enforcing alignment. If the generated image still fails a safety check, VALOR optionally performs a stylistic regeneration to steer the output toward a safer visual domain without altering core semantics. Experiments across adversarial, ambiguous, and value-sensitive prompts show that VALOR significantly reduces unsafe outputs by up to 100.00% while preserving prompt usefulness and creativity. These results highlight VALOR as a scalable and effective approach for deploying safe, aligned, and helpful image generation systems in open-world settings.

</details>


### [26] [Towards autonomous quantum physics research using LLM agents with access to intelligent tools](https://arxiv.org/abs/2511.11752)
*Sören Arlt,Xuemei Gu,Mario Krenn*

Main category: cs.AI

TL;DR: AI-Mandel은 양자물리학에서 실현 가능한 아이디어를 생성하고 구현할 수 있는 LLM 에이전트이다.


<details>
  <summary>Details</summary>
Motivation: AI의 아이디어 생성과 실행을 자동화하여 과학적 과정에서 인간의 역할을 변화시키는 것을 목표로 한다.

Method: AI-Mandel은 문헌에서 아이디어를 수집하고, 도메인 특화 AI 도구를 사용하여 구체적인 실험 설계를 만든다.

Result: AI-Mandel이 생성한 아이디어는 과학적으로 흥미롭고, 두 가지 아이디어에 대해 독립적인 후속 연구 논문을 작성했다.

Conclusion: AI-Mandel은 구체적이고 실행 가능한 아이디어를 생성하고 구현할 수 있는 AI 물리학자의 프로토타입을 시연하였다.

Abstract: Artificial intelligence (AI) is used in numerous fields of science, yet the initial research questions and targets are still almost always provided by human researchers. AI-generated creative ideas in science are rare and often vague, so that it remains a human task to execute them. Automating idea generation and implementation in one coherent system would significantly shift the role of humans in the scientific process. Here we present AI-Mandel, an LLM agent that can generate and implement ideas in quantum physics. AI-Mandel formulates ideas from the literature and uses a domain-specific AI tool to turn them into concrete experiment designs that can readily be implemented in laboratories. The generated ideas by AI-Mandel are often scientifically interesting - for two of them we have already written independent scientific follow-up papers. The ideas include new variations of quantum teleportation, primitives of quantum networks in indefinite causal orders, and new concepts of geometric phases based on closed loops of quantum information transfer. AI-Mandel is a prototypical demonstration of an AI physicist that can generate and implement concrete, actionable ideas. Building such a system is not only useful to accelerate science, but it also reveals concrete open challenges on the path to human-level artificial scientists.

</details>


### [27] [Learning to Refine: An Agentic RL Approach for Iterative SPARQL Query Construction](https://arxiv.org/abs/2511.11770)
*Floris Vossebeld,Shenghui Wang*

Main category: cs.AI

TL;DR: 다단계 질문에 대한 SPARQL 쿼리 생성을 위한 새로운 에이전트 프레임워크를 소개하고, 결과 주도 강화 학습을 통해 3B 매개변수 모델이 효과적인 쿼리 정책을 학습할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: Knowledge Graph Question Answering에서 복잡하고 논리적으로 견고한 SPARQL 쿼리 생성을 위한 어려움.

Method: 저자는 LLM이 반응형 정책을 학습하는 새로운 에이전트 프레임워크를 제시한다.

Result: 3B 매개변수 모델은 SPARQL 쿼리의 오류 복구 및 답변 정교화에 성공하여 LC-QuAD 2.0에서 49.7%의 정확도를 달성하였다.

Conclusion: 이 연구는 에이전트가 형식적, 기호적 도구를 배우는 일반화된 청사진을 제공한다.

Abstract: Generating complex, logically-sound SPARQL queries for multi-hop questions remains a critical bottleneck for Knowledge Graph Question Answering, as the brittle nature of one-shot generation by Large Language Models (LLMs) hinders reliable interaction with structured data. Current methods lack the adaptive policies needed to dynamically debug queries based on real-time execution feedback. This paper introduces a novel agentic framework where an LLM learns a resilient policy for the sequential process of iterative SPARQL construction. We show that a compact 3B-parameter model, trained exclusively via outcome-driven Reinforcement Learning (GRPO) without supervised fine-tuning, can learn effective policies for this task, discovering how to systematically recover from execution errors and refine its queries toward a correct answer. On a curated, executable single-answer subset of LC-QuAD 2.0, our agent achieves 49.7\% accuracy post-entity-linking, a significant 17.5 percentage point improvement over the strongest iterative zero-shot baseline. Further analysis reveals that while the agent's capability is driven by RL, its performance is enhanced by an explicit deliberative reasoning step that acts as a cognitive scaffold to improve policy precision. This work presents a generalizable blueprint for teaching agents to master formal, symbolic tools through interaction, bridging the gap between probabilistic LLMs and the structured world of Knowledge Graphs.

</details>


### [28] [End to End AI System for Surgical Gesture Sequence Recognition and Clinical Outcome Prediction](https://arxiv.org/abs/2511.11899)
*Xi Li,Nicholas Matsumoto,Ujjwal Pasupulety,Atharva Deo,Cherine Yang,Jay Moran,Miguel E. Hernandez,Peter Wager,Jasmine Lin,Jeanine Kim,Alvin C. Goh,Christian Wagner,Geoffrey A. Sonn,Andrew J. Hung*

Main category: cs.AI

TL;DR: F2O 시스템은 로봇 보조 전립선 수술에서의 조직 절개 비디오를 제스처 시퀀스로 변환하여 수술 결과와 연관된 패턴을 발견한다.


<details>
  <summary>Details</summary>
Motivation: 수술 중 행동의 세밀한 분석과 그것이 환자 결과에 미치는 영향을 이해하는 것은 오랜 도전 과제이다.

Method: F2O는 트랜스포머 기반의 공간 및 시간 모델링과 프레임 단위 클래시피케이션을 활용하여 로봇 보조 전립선 수술의 신경 보존 단계에서 짧은 제스처를 감지한다.

Result: F2O가 생성한 특징(제스처 빈도, 지속 시간, 전환)은 인간 주석과 유사한 정확도로 수술 후 결과를 예측하였다.

Conclusion: F2O는 자동으로 해석 가능한 평가를 가능하게 하여 데이터 기반의 수술 피드백과 임상 의사 결정을 지원하는 기초를 마련한다.

Abstract: Fine-grained analysis of intraoperative behavior and its impact on patient outcomes remain a longstanding challenge. We present Frame-to-Outcome (F2O), an end-to-end system that translates tissue dissection videos into gesture sequences and uncovers patterns associated with postoperative outcomes. Leveraging transformer-based spatial and temporal modeling and frame-wise classification, F2O robustly detects consecutive short (~2 seconds) gestures in the nerve-sparing step of robot-assisted radical prostatectomy (AUC: 0.80 frame-level; 0.81 video-level). F2O-derived features (gesture frequency, duration, and transitions) predicted postoperative outcomes with accuracy comparable to human annotations (0.79 vs. 0.75; overlapping 95% CI). Across 25 shared features, effect size directions were concordant with small differences (~ 0.07), and strong correlation (r = 0.96, p < 1e-14). F2O also captured key patterns linked to erectile function recovery, including prolonged tissue peeling and reduced energy use. By enabling automatic interpretable assessment, F2O establishes a foundation for data-driven surgical feedback and prospective clinical decision support.

</details>


### [29] [An Analysis of Architectural Impact on LLM-based Abstract Visual Reasoning: A Systematic Benchmark on RAVEN-FAIR](https://arxiv.org/abs/2511.11916)
*Sinan Urgun,Seçkin Arı*

Main category: cs.AI

TL;DR: 이 연구는 대형 언어 모델이 추상적 시각 추론 문제에서 어떻게 성능을 발휘하는지를 체계적으로 평가한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLMs)의 시각적 추론 성능을 평가하여 이러한 모델들이 실제 문제 해결에 얼마나 효과적인지 이해하고자 함.

Method: RAVEN-FAIR 데이터셋을 사용하여 네 가지 LLM 모델과 네 가지 다른 추론 아키텍처를 비교하고, 세 단계의 프로세스(JSON 추출, LLM 추론, 도구 기능)를 통해 생성된 시각적 응답을 평가함.

Result: GPT-4.1-Mini가 모든 아키텍처에서 가장 높은 정확도를 일관되게 달성하였고, 모델마다 아키텍처 디자인에 대한 감도가 다름을 보여줌.

Conclusion: 각 모델은 특정 아키텍처에 따라 다르게 반응하며, 직접적인 아키텍처 비교를 복잡하게 하는 요소가 존재함. 또한, 다중 실행 전략이 신뢰할 수 있는 결과를 도출하는 데 중요함.

Abstract: This study aims to systematically evaluate the performance of large language models (LLMs) in abstract visual reasoning problems. We examined four LLM models (GPT-4.1-Mini, Claude-3.5-Haiku, Gemini-1.5-Flash, Llama-3.3-70b) utilizing four different reasoning architectures (single-shot, embedding-controlled repetition, self-reflection, and multi-agent) on the RAVEN-FAIR dataset. Visual responses generated through a three-stage process (JSON extraction, LLM reasoning, and Tool Function) were evaluated using SSIM and LPIPS metrics; Chain-of-Thought scores and error types (semantic hallucination, numeric misperception) were analyzed. Results demonstrate that GPT-4.1-Mini consistently achieved the highest overall accuracy across all architectures, indicating a strong reasoning capability. While the multi-agent architecture occasionally altered semantic and numeric balance across models, these effects were not uniformly beneficial. Instead, each model exhibited distinct sensitivity patterns to architectural design, underscoring that reasoning effectiveness remains model-specific. Variations in response coverage further emerged as a confounding factor that complicates direct cross-architecture comparison. To estimate the upper-bound performance of each configuration, we report the best of five independent runs, representing a best-case scenario rather than an averaged outcome. This multi-run strategy aligns with recent recommendations, which emphasize that single-run evaluations are fragile and may lead to unreliable conclusions.

</details>


### [30] [Multi-agent Self-triage System with Medical Flowcharts](https://arxiv.org/abs/2511.12439)
*Yujia Liu,Sophia Yu,Hongyue Jin,Jessica Wen,Alexander Qian,Terrence Lee,Mattheus Ramsis,Gi Won Choi,Lianhui Qin,Xin Liu,Edward J. Wang*

Main category: cs.AI

TL;DR: 이 연구에서는 임상적으로 검증된 플로우차트를 활용한 대화형 자가 분류 시스템을 소개하며, 이를 통해 의료 결정 지원을 위한 투명하고 정확한 AI 기반 접근 방식을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 건강 자원과 대형 언어 모델(LLMs)은 의료 결정에서 첫 접점으로 사용되지만, 그 신뢰성은 낮은 정확성, 투명성 결여 및 검증되지 않은 정보에 대한 취약성으로 제한된다.

Method: 100개의 임상 검증된 플로우차트를 활용하여 LLM을 안내하는 자가 분류 시스템을 도입하고, 검색 에이전트, 결정 에이전트, 채팅 에이전트로 구성된 다중 에이전트 프레임워크를 사용하여 가장 관련성 높은 플로우차트를 식별하고 환자의 반응을 해석하며 개인화된 권장 사항을 제공한다.

Result: 이 시스템은 시뮬레이션 대화에 대한 합성 데이터셋을 사용하여 성능을 평가했으며, 플로우차트 검색에서 95.29%의 top-3 정확도(N=2,000)와 다양한 대화 스타일 및 조건에서 99.10%의 플로우차트 탐색 정확도를 달성하였다(N=37,200).

Conclusion: 자유 텍스트 상호작용의 유연성과 표준화된 임상 프로토콜의 엄격함을 결합함으로써, 이 접근 방식은 투명하고 정확하며 일반화 가능한 AI 지원 자가 분류의 실행 가능성을 보여주고, 정보에 기반한 환자 결정 지원을 가능하게 하여 의료 자원 활용을 개선할 수 있는 잠재력을 가진다.

Abstract: Online health resources and large language models (LLMs) are increasingly used as a first point of contact for medical decision-making, yet their reliability in healthcare remains limited by low accuracy, lack of transparency, and susceptibility to unverified information. We introduce a proof-of-concept conversational self-triage system that guides LLMs with 100 clinically validated flowcharts from the American Medical Association, providing a structured and auditable framework for patient decision support. The system leverages a multi-agent framework consisting of a retrieval agent, a decision agent, and a chat agent to identify the most relevant flowchart, interpret patient responses, and deliver personalized, patient-friendly recommendations, respectively. Performance was evaluated at scale using synthetic datasets of simulated conversations. The system achieved 95.29% top-3 accuracy in flowchart retrieval (N=2,000) and 99.10% accuracy in flowchart navigation across varied conversational styles and conditions (N=37,200). By combining the flexibility of free-text interaction with the rigor of standardized clinical protocols, this approach demonstrates the feasibility of transparent, accurate, and generalizable AI-assisted self-triage, with potential to support informed patient decision-making while improving healthcare resource utilization.

</details>


### [31] [Looking Forward: Challenges and Opportunities in Agentic AI Reliability](https://arxiv.org/abs/2511.11921)
*Liudong Xing,Janet,Lin*

Main category: cs.AI

TL;DR: 신뢰할 수 있는 AI 시스템, 특히 에이전틱 AI 시스템의 도전과 미래 발전에 대한 관점을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 신뢰할 수 있는 AI 시스템의 구축에 대한 도전과 미래 발전이 필요하다.

Method: 에이전틱 AI 시스템의 실패 리스크 완화와 관련된 여러 오픈 리서치 문제를 논의하며, 동적 환경 및 비일관적인 태스크 실행과 같은 측면에서 연구 기회와 도전을 밝힌다.

Result: 에이전틱 AI 시스템의 신뢰성을 테스트하고 평가하기 위한 여러 연구 방향을 논의한다.

Conclusion: 신뢰할 수 있는 AI 시스템을 구축하기 위한 연구가 더욱 발전할 필요가 있다.

Abstract: This chapter presents perspectives for challenges and future development in building reliable AI systems, particularly, agentic AI systems. Several open research problems related to mitigating the risks of cascading failures are discussed. The chapter also sheds lights on research challenges and opportunities in aspects including dynamic environments, inconsistent task execution, unpredictable emergent behaviors, as well as resource-intensive reliability mechanisms. In addition, several research directions along the line of testing and evaluating reliability of agentic AI systems are also discussed.

</details>


### [32] [Adaptively Coordinating with Novel Partners via Learned Latent Strategies](https://arxiv.org/abs/2511.12754)
*Benjamin Li,Shuyang Shi,Lucia Romero,Huao Li,Yaqi Xie,Woojun Kim,Stefanos Nikolaidis,Michael Lewis,Katia Sycara,Simon Stepputtis*

Main category: cs.AI

TL;DR: 이 논문은 이질적인 팀 구성원 간의 협업을 위해 인공 에이전트가 인간 파트너에 실시간으로 적응해야 함을 강조하며, 이를 위한 새로운 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 인간-에이전트 팀에서 인공 에이전트는 인간 파트너가 가진 독특한 선호와 정책에 실시간으로 적응해야 하며, 이는 특히 시간 압박과 복잡한 전략 공간에서 도전적이다.

Method: 본 연구는 다양한 파트너 전략에 실시간으로 적응하는 전략 조건 협력자 프레임워크를 제안하며, 이를 위해 변분 오토인코더를 사용하여 전략을 인코딩하고 클러스터링을 통해 전략 유형을 식별한 후, 각 전략 유형의 파트너를 생성하여 협력 에이전트를 훈련시킨다.

Result: 우리는 Overcooked 도메인의 수정본에서 제안한 방법을 평가하며, 다양한 잠재적 전략 공간을 가진 두 플레이어 간의 협력이 필요한 복잡한 요리 환경에서 우수한 성능을 보인다.

Conclusion: 본 연구를 통해 제안된 에이전트는 새로운 인간 및 에이전트 팀원과 짝짓기 시 기존 기준에 비해 최첨단 성능을 달성함을 보여준다.

Abstract: Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.

</details>


### [33] [Improving Autoformalization Using Direct Dependency Retrieval](https://arxiv.org/abs/2511.11990)
*Shaoqi Wang,Lu Yu,Chunjie Yang*

Main category: cs.AI

TL;DR: 이 논문은 수학 기술을 기계 검증 가능한 표현으로 변환하는 데 중점을 둔 새로운 자동 형식화 프레임워크인 DDR을 제안하고, 그 효율성을 실험을 통해 입증합니다.


<details>
  <summary>Details</summary>
Motivation: 심층 학습과 정형 수학의 융합은 정형 검증 연구를 촉발했습니다. 이 과정의 중요한 첫 단계인 진술 자동 형식화는 비공식적인 설명을 기계 검증 가능한 표현으로 변환하는 것을 목표로 하며, 여전히 큰 도전 과제가 남아 있습니다.

Method: DDR(Direct Dependency Retrieval) 기반의 새로운 검색 보강 프레임워크를 제안하여, 자연어 수학 설명에서 후보 라이브러리 종속성을 직접 생성하고 이를 효율적인 접미사 배열 검사를 통해 정형 라이브러리 내에서 검증합니다.

Result: 500,000개 이상의 샘플로 구성된 종속성 검색 데이터셋을 구축하고 고정밀 DDR 모델을 미세 조정했습니다. 실험 결과, DDR 모델은 검색 정밀도와 재현율 모두에서 SOTA 방법을 크게 능가하는 것으로 나타났습니다.

Conclusion: DDR을 탑재한 자동 형식화 장치는 전통적인 선택 기반 RAG 방법을 사용하는 모델보다 단일 시도 정확성과 다중 시도 안정성에서 일관된 성능 이점을 보입니다.

Abstract: The convergence of deep learning and formal mathematics has spurred research in formal verification. Statement autoformalization, a crucial first step in this process, aims to translate informal descriptions into machine-verifiable representations but remains a significant challenge. The core difficulty lies in the fact that existing methods often suffer from a lack of contextual awareness, leading to hallucination of formal definitions and theorems. Furthermore, current retrieval-augmented approaches exhibit poor precision and recall for formal library dependency retrieval, and lack the scalability to effectively leverage ever-growing public datasets. To bridge this gap, we propose a novel retrieval-augmented framework based on DDR (\textit{Direct Dependency Retrieval}) for statement autoformalization. Our DDR method directly generates candidate library dependencies from natural language mathematical descriptions and subsequently verifies their existence within the formal library via an efficient suffix array check. Leveraging this efficient search mechanism, we constructed a dependency retrieval dataset of over 500,000 samples and fine-tuned a high-precision DDR model. Experimental results demonstrate that our DDR model significantly outperforms SOTA methods in both retrieval precision and recall. Consequently, an autoformalizer equipped with DDR shows consistent performance advantages in both single-attempt accuracy and multi-attempt stability compared to models using traditional selection-based RAG methods.

</details>


### [34] [Look As You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning](https://arxiv.org/abs/2511.12003)
*Shuochen Liu,Pengfei Luo,Chao Zhang,Yuhao Chen,Haotian Zhang,Qi Liu,Xin Kou,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: 이 논문은 비주얼 문서 검색 증강 생성을 위한 비주얼 증거 귀속 방법론을 제안하며, 신뢰할 수 있고 검증 가능한 예측을 보장하는 동시에 추론 과정을 포함한 세밀한 감독을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 질문 응답에서 비주얼 증거를 정확하게 찾는 방법이 필요하다.

Method: Chain-of-Evidence(CoE) 패러다임과 Look As You Think(LAT) 강화 학습 프레임워크를 도입하여, 비주얼 증거 귀속과 일관된 추증 과정을 훈련합니다.

Result: LAT는 기본 모델의 성능을 일관되게 향상시키며, 평균 8.23%의 정확하고, 47.0%의 IoU@0.5 개선을 보여줍니다.

Conclusion: 이 연구는 비주얼 증거 귀속에 대한 새로운 접근 방식과 강화 학습을 통해 도메인 전반에 걸쳐 더 강력한 일반성을 보여줍니다.

Abstract: Aiming to identify precise evidence sources from visual documents, visual evidence attribution for visual document retrieval-augmented generation (VD-RAG) ensures reliable and verifiable predictions from vision-language models (VLMs) in multimodal question answering. Most existing methods adopt end-to-end training to facilitate intuitive answer verification. However, they lack fine-grained supervision and progressive traceability throughout the reasoning process. In this paper, we introduce the Chain-of-Evidence (CoE) paradigm for VD-RAG. CoE unifies Chain-of-Thought (CoT) reasoning and visual evidence attribution by grounding reference elements in reasoning steps to specific regions with bounding boxes and page indexes. To enable VLMs to generate such evidence-grounded reasoning, we propose Look As You Think (LAT), a reinforcement learning framework that trains models to produce verifiable reasoning paths with consistent attribution. During training, LAT evaluates the attribution consistency of each evidence region and provides rewards only when the CoE trajectory yields correct answers, encouraging process-level self-verification. Experiments on vanilla Qwen2.5-VL-7B-Instruct with Paper- and Wiki-VISA benchmarks show that LAT consistently improves the vanilla model in both single- and multi-image settings, yielding average gains of 8.23% in soft exact match (EM) and 47.0% in IoU@0.5. Meanwhile, LAT not only outperforms the supervised fine-tuning baseline, which is trained to directly produce answers with attribution, but also exhibits stronger generalization across domains.

</details>


### [35] [KrwEmd: Revising the Imperfect-Recall Abstraction from Forgetting Everything](https://arxiv.org/abs/2511.12089)
*Yanchang Fu,Qiyue Yin,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: KrwEmd 알고리즘은 불완전 정보 게임의 손 추상화 문제를 해결하여 AI 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 손 추상화에서 과도한 추상화는 AI 성능을 저하시킬 수 있는 문제입니다.

Method: k-recall 승률 기능을 도입하고, 이를 기반으로 신호 관찰 정보 집합을 클러스터링하는 KrwEmd 알고리즘을 개발합니다.

Result: 실험 결과, KrwEmd는 기존 알고리즘에 비해 AI의 게임 플레이 성능을 크게 향상시킵니다.

Conclusion: KrwEmd는 대규모 불완전 정보 게임에서 AI 성능을 개선할 수 있는 실용적인 알고리즘입니다.

Abstract: Excessive abstraction is a critical challenge in hand abstraction-a task specific to games like Texas hold'em-when solving large-scale imperfect-information games, as it impairs AI performance. This issue arises from extreme implementations of imperfect-recall abstraction, which entirely discard historical information. This paper presents KrwEmd, the first practical algorithm designed to address this problem. We first introduce the k-recall winrate feature, which not only qualitatively distinguishes signal observation infosets by leveraging both future and, crucially, historical game information, but also quantitatively captures their similarity. We then develop the KrwEmd algorithm, which clusters signal observation infosets using earth mover's distance to measure discrepancies between their features. Experimental results demonstrate that KrwEmd significantly improves AI gameplay performance compared to existing algorithms.

</details>


### [36] [Debate over Mixed-knowledge: A Robust Multi-Agent Framework for Incomplete Knowledge Graph Question Answering](https://arxiv.org/abs/2511.12208)
*Jilong Liu,Pengyang Shao,Wei Qin,Fei Liu,Yonghui Yang,Richang Hong*

Main category: cs.AI

TL;DR: 이 논문은 구조적 지식과 비구조적 지식을 동적으로 통합하여 불완전한 지식 그래프 질의 응답(IKGQA)을 개선하는 새로운 프레임워크인 '혼합 지식에 대한 토론(DoM)'을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 지식 그래프는 종종 불완전하여, IKGQA 문제를 초래합니다. 이를 해결하기 위해 외부 데이터를 통합하는 접근 방식이 일반적이나, 기존 방법들은 여러 소스를 적응적으로 융합할 능력이 부족합니다.

Method: DoM은 다중 에이전트 토론 패러다임에 기반하여, 지식 그래프와 외부 텍스트에 대해 개별적으로 추론을 수행하는 전문화된 에이전트를 할당하고, 반복적 상호작용을 통해 결과를 조정합니다. 입력 질문을 하위 질문으로 분해하고, 이중 에이전트(KG와 RAG)를 통해 증거를 검색하고, 평가 에이전트를 이용해 중간 답변을 평가 및 집계합니다.

Result: DoM은 지식 보완성을 활용하고 KG 불완전성에 대한 견고성을 향상시킵니다. 또한, IKGQA 데이터셋은 무작위로 트리플을 제거해 불완전성을 모사하지만, 현실 세계의 불완전성을 제대로 반영하지 못합니다. 이를 해결하기 위해 실제 세계의 지식 업데이트를 활용한 '불완전한 지식 그래프 웹 질문(Incomplete Knowledge Graph WebQuestions)'이라는 새로운 데이터셋을 도입합니다.

Conclusion: 광범위한 실험을 통해 DoM이 최신의 성능 기준을 일관되게 초과하는 결과를 보였습니다.

Abstract: Knowledge Graph Question Answering (KGQA) aims to improve factual accuracy by leveraging structured knowledge. However, real-world Knowledge Graphs (KGs) are often incomplete, leading to the problem of Incomplete KGQA (IKGQA). A common solution is to incorporate external data to fill knowledge gaps, but existing methods lack the capacity to adaptively and contextually fuse multiple sources, failing to fully exploit their complementary strengths. To this end, we propose Debate over Mixed-knowledge (DoM), a novel framework that enables dynamic integration of structured and unstructured knowledge for IKGQA. Built upon the Multi-Agent Debate paradigm, DoM assigns specialized agents to perform inference over knowledge graphs and external texts separately, and coordinates their outputs through iterative interaction. It decomposes the input question into sub-questions, retrieves evidence via dual agents (KG and Retrieval-Augmented Generation, RAG), and employs a judge agent to evaluate and aggregate intermediate answers. This collaboration exploits knowledge complementarity and enhances robustness to KG incompleteness. In addition, existing IKGQA datasets simulate incompleteness by randomly removing triples, failing to capture the irregular and unpredictable nature of real-world knowledge incompleteness. To address this, we introduce a new dataset, Incomplete Knowledge Graph WebQuestions, constructed by leveraging real-world knowledge updates. These updates reflect knowledge beyond the static scope of KGs, yielding a more realistic and challenging benchmark. Through extensive experiments, we show that DoM consistently outperforms state-of-the-art baselines.

</details>


### [37] [MedDCR: Learning to Design Agentic Workflows for Medical Coding](https://arxiv.org/abs/2511.13361)
*Jiyang Zheng,Islam Nassar,Thanh Vu,Xu Zhong,Yang Lin,Tongliang Liu,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: Medical coding 시스템에서의 MedDCR 프레임워크 소개 및 성능 향상


<details>
  <summary>Details</summary>
Motivation: 의료 코딩은 청구 및 의료 연구를 위해 임상 노트를 표준화된 코드로 변환하는 것이 필요하지만, 기존 방법은 실제 문서의 변수를 반영하지 못함.

Method: MedDCR는 설계자, 코더, 반영자로 구성된 폐쇄형 루프 프레임워크로, 설계가 학습 문제로 다뤄짐.

Result: MedDCR는 벤치마크 데이터셋에서 최첨단 기준을 초과하여, 해석 가능하고 적응 가능한 워크플로우를 생성함.

Conclusion: 자동화 시스템의 신뢰성과 신뢰성을 향상시킴.

Abstract: Medical coding converts free-text clinical notes into standardized diagnostic and procedural codes, which are essential for billing, hospital operations, and medical research. Unlike ordinary text classification, it requires multi-step reasoning: extracting diagnostic concepts, applying guideline constraints, mapping to hierarchical codebooks, and ensuring cross-document consistency. Recent advances leverage agentic LLMs, but most rely on rigid, manually crafted workflows that fail to capture the nuance and variability of real-world documentation, leaving open the question of how to systematically learn effective workflows. We present MedDCR, a closed-loop framework that treats workflow design as a learning problem. A Designer proposes workflows, a Coder executes them, and a Reflector evaluates predictions and provides constructive feedback, while a memory archive preserves prior designs for reuse and iterative refinement. On benchmark datasets, MedDCR outperforms state-of-the-art baselines and produces interpretable, adaptable workflows that better reflect real coding practice, improving both the reliability and trustworthiness of automated systems.

</details>


### [38] [AURA: Development and Validation of an Augmented Unplanned Removal Alert System using Synthetic ICU Videos](https://arxiv.org/abs/2511.12241)
*Junhyuk Seo,Hyeyoon Moon,Kyu-Hwan Jung,Namkee Oh,Taerim Kim*

Main category: cs.AI

TL;DR: AURA는 합성 비디오 데이터셋을 기반으로 한 시각적 위험 탐지 시스템으로, 중환자실에서의 계획되지 않은 발관을 감지하는 데 효과적이다.


<details>
  <summary>Details</summary>
Motivation: 중환자실에서 비계획적 발관은 심각한 합병증이나 사망에 이를 수 있는 중요한 환자 안전 문제이다.

Method: AURA는 텍스트-비디오 확산을 활용하여 다양한 임상적으로 현실적인 ICU 시나리오를 생성하고, 포즈 추정을 통해 두 가지 고위험 이동 패턴(충돌 및 동요)을 식별한다.

Result: 전문가 평가를 통해 합성 데이터의 현실성이 확인되었고, 충돌 탐지의 높은 정확도와 동요 인식의 중간 성능이 나타났다.

Conclusion: 이 연구는 중환자 치료 환경에서 배포 가능성이 있는 개인 정보 보호를 준수하면서 reproducible 한 환자 안전 모니터링 시스템을 개발하는 새로운 경로를 보여준다.

Abstract: Unplanned extubation (UE) remains a critical patient safety concern in intensive care units (ICUs), often leading to severe complications or death. Real-time UE detection has been limited, largely due to the ethical and privacy challenges of obtaining annotated ICU video data. We propose Augmented Unplanned Removal Alert (AURA), a vision-based risk detection system developed and validated entirely on a fully synthetic video dataset. By leveraging text-to-video diffusion, we generated diverse and clinically realistic ICU scenarios capturing a range of patient behaviors and care contexts. The system applies pose estimation to identify two high-risk movement patterns: collision, defined as hand entry into spatial zones near airway tubes, and agitation, quantified by the velocity of tracked anatomical keypoints. Expert assessments confirmed the realism of the synthetic data, and performance evaluations showed high accuracy for collision detection and moderate performance for agitation recognition. This work demonstrates a novel pathway for developing privacy-preserving, reproducible patient safety monitoring systems with potential for deployment in intensive care settings.

</details>


### [39] [Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation](https://arxiv.org/abs/2511.12254)
*Yuxiang Zhou,Jichang Li,Yanhao Zhang,Haonan Lu,Guanbin Li*

Main category: cs.AI

TL;DR: 모바일 에이전트는 큰 잠재력을 가지고 있지만, 현재의 최신 에이전트는 실제 세계의 장기, 교차 응용 과제에서 부족한 성공률을 보입니다. 이 논문에서는 모바일 에이전트의 전략적 환각과 저수준 실행 오류를 해결하기 위한 새로운 계층적 다중 에이전트 프레임워크인 Mobile-Agent-RAG를 제안합니다. 실험 결과, 이 프레임워크는 최신 기술의 기준을 초월하여 작업 완료율을 11.0%, 단계 효율성을 10.2% 향상시키는 것으로 나타났습니다.


<details>
  <summary>Details</summary>
Motivation: 모바일 에이전트의 실제 적용에서의 성공률 부족 문제를 해결하고자 하는 동기.

Method: 계층적 다중 에이전트 프레임워크인 Mobile-Agent-RAG를 제안하며, 계획과 실행 단계에서 각각 두 가지 지식 기반을 활용합니다.

Result: Mobile-Agent-RAG는 작업 완료율을 11.0%, 단계 효율성을 10.2% 향상시키며 최신 기술 기준을 훨씬 초과하는 성능을 보여줍니다.

Conclusion: Mobile-Agent-RAG는 컨텍스트 인식 및 신뢰할 수 있는 다중 에이전트 모바일 자동화를 위한 강력한 패러다임을 확립합니다.

Abstract: Mobile agents show immense potential, yet current state-of-the-art (SoTA) agents exhibit inadequate success rates on real-world, long-horizon, cross-application tasks. We attribute this bottleneck to the agents' excessive reliance on static, internal knowledge within MLLMs, which leads to two critical failure points: 1) strategic hallucinations in high-level planning and 2) operational errors during low-level execution on user interfaces (UI). The core insight of this paper is that high-level planning and low-level UI operations require fundamentally distinct types of knowledge. Planning demands high-level, strategy-oriented experiences, whereas operations necessitate low-level, precise instructions closely tied to specific app UIs. Motivated by these insights, we propose Mobile-Agent-RAG, a novel hierarchical multi-agent framework that innovatively integrates dual-level retrieval augmentation. At the planning stage, we introduce Manager-RAG to reduce strategic hallucinations by retrieving human-validated comprehensive task plans that provide high-level guidance. At the execution stage, we develop Operator-RAG to improve execution accuracy by retrieving the most precise low-level guidance for accurate atomic actions, aligned with the current app and subtask. To accurately deliver these knowledge types, we construct two specialized retrieval-oriented knowledge bases. Furthermore, we introduce Mobile-Eval-RAG, a challenging benchmark for evaluating such agents on realistic multi-app, long-horizon tasks. Extensive experiments demonstrate that Mobile-Agent-RAG significantly outperforms SoTA baselines, improving task completion rate by 11.0% and step efficiency by 10.2%, establishing a robust paradigm for context-aware, reliable multi-agent mobile automation.

</details>


### [40] [MoralReason: Generalizable Moral Decision Alignment For LLM Agents Using Reasoning-Level Reinforcement Learning](https://arxiv.org/abs/2511.12271)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 대규모 언어 모델(LLM)이 인간의 도덕적 결정에 미치는 영향이 증가하고 있으며, 이 논문은 도덕적 결정을 평가하는 것에서 벗어나 방향을 제시하는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 복잡한 도덕적 결정에서 LLM의 도덕적 정렬을 향상시키기 위해서.

Method: Moral-Reason-QA라는 새로운 데이터셋을 도입하고, 그룹 상대 정책 최적화(Group Relative Policy Optimization) 방법을 사용하여 결정 정렬성과 프레임워크 특화 추론 과정을 최적화하는 학습 접근법을 적용합니다.

Result: 실험 결과, 이전에 보지 못한 도덕적 시나리오에 대한 일반화가 성공적으로 이루어졌고, 아울러 훈련의 어려움과 향후 연구 방향에 대한 통찰이 도출되었습니다.

Conclusion: 이 연구는 LLM 에이전트가 특정 도덕적 프레임워크를 내부화하고 새로운 상황에 적용할 수 있도록 체계적으로 훈련될 수 있음을 입증하며, 인공지능 안전성의 기초를 제공합니다.

Abstract: Large language models are increasingly influencing human moral decisions, yet current approaches focus primarily on evaluating rather than actively steering their moral decisions. We formulate this as an out-of-distribution moral alignment problem, where LLM agents must learn to apply consistent moral reasoning frameworks to scenarios beyond their training distribution. We introduce Moral-Reason-QA, a novel dataset extending 680 human-annotated, high-ambiguity moral scenarios with framework-specific reasoning traces across utilitarian, deontological, and virtue ethics, enabling systematic evaluation of moral generalization in realistic decision contexts. Our learning approach employs Group Relative Policy Optimization with composite rewards that simultaneously optimize decision alignment and framework-specific reasoning processes to facilitate learning of the underlying moral frameworks. Experimental results demonstrate successful generalization to unseen moral scenarios, with softmax-normalized alignment scores improving by +0.757 for utilitarian and +0.450 for deontological frameworks when tested on out-of-distribution evaluation sets. The experiments also reveal training challenges and promising directions that inform future research. These findings establish that LLM agents can be systematically trained to internalize and apply specific moral frameworks to novel situations, providing a critical foundation for AI safety as language models become more integrated into human decision-making processes.

</details>


### [41] [UpBench: A Dynamically Evolving Real-World Labor-Market Agentic Benchmark Framework Built for Human-Centric AI](https://arxiv.org/abs/2511.12306)
*Darvin Yi,Teng Liu,Mattie Terzolo,Lance Hasson,Ayan Sinh,Pablo Mendes,Andrew Rabinovich*

Main category: cs.AI

TL;DR: 이 논문은 UpBench라는 동적으로 진화하는 벤치마크를 소개하며, 이는 실제 작업을 기반으로 LLM 에이전트의 성능을 평가하는 새로운 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 디지털 업무를 수행하는 대형 언어 모델 에이전트 재능의 평가를 위한 신뢰할 수 있는 프레임워크 필요.

Method: UpBench는 전 세계 Upwork 노동 시장에서 가져온 실제 작업을 기반으로 하여, 작업을 검증된 클라이언트 거래와 연결시키고, 전문가 프리랜서가 각 작업을 세부적이고 검증 가능한 수용 기준으로 분해하여 AI 제출물을 평가합니다.

Result: UpBench를 통해 모델의 강점과 약점, 지침 준수 충실도를 세밀하게 분석할 수 있으며, 실제 전문 표준에 대한 충실성을 보장합니다.

Conclusion: 업데이트된 작업을 통해 온라인 작업의 진화하는 특성을 반영함으로써, UpBench는 실제 노동 시장 맥락에서 에이전트 시스템 평가를 위한 확장 가능한, 인간 중심의 기초를 제공합니다.

Abstract: As large language model (LLM) agents increasingly undertake digital work, reliable frameworks are needed to evaluate their real-world competence, adaptability, and capacity for human collaboration. Existing benchmarks remain largely static, synthetic, or domain-limited, providing limited insight into how agents perform in dynamic, economically meaningful environments. We introduce UpBench, a dynamically evolving benchmark grounded in real jobs drawn from the global Upwork labor marketplace. Each task corresponds to a verified client transaction, anchoring evaluation in genuine work activity and financial outcomes. UpBench employs a rubric-based evaluation framework, in which expert freelancers decompose each job into detailed, verifiable acceptance criteria and assess AI submissions with per-criterion feedback. This structure enables fine-grained analysis of model strengths, weaknesses, and instruction-following fidelity beyond binary pass/fail metrics. Human expertise is integrated throughout the data pipeline (from job curation and rubric construction to evaluation) ensuring fidelity to real professional standards and supporting research on human-AI collaboration. By regularly refreshing tasks to reflect the evolving nature of online work, UpBench provides a scalable, human-centered foundation for evaluating agentic systems in authentic labor-market contexts, offering a path toward a collaborative framework, where AI amplifies human capability through partnership rather than replacement.

</details>


### [42] [Reward and Guidance through Rubrics: Promoting Exploration to Improve Multi-Domain Reasoning](https://arxiv.org/abs/2511.12344)
*Baolong Bi,Shenghua Liu,Yiwei Wang,Siqian Tong,Lingrui Mei,Yuyao Ge,Yilong Xu,Jiafeng Guo,Xueqi Cheng*

Main category: cs.AI

TL;DR: 이 논문에서는 다중 도메인 추론을 위한 루브릭 기반 강화 학습 프레임워크인 RGR-GRPO를 제안하고, 이를 통해 기존의 온라인 RL 방법보다 향상된 성능을 달성함을 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습의 최근 발전이 대형 언어 모델의 복잡한 추론 능력을 상당히 향상시켰지만, 기존 방법은 검증 가능한 보상에 의존하는 단일 도메인 RL에 주로 초점을 맞추고 있어 탐색 공간이 제한되고 추론 성능이 제한됩니다.

Method: 루브릭을 활용하여 세분화된 보상 신호와 오프라인 지침을 제공하는 RGR-GRPO 프레임워크를 제안하였습니다.

Result: 14개의 벤치마크에서 수행한 실험 결과, RGR-GRPO는 대체 보상 방식이나 오프라인 지침에만 의존하는 RL 방법보다 지속적으로 우수한 성능을 나타냈습니다.

Conclusion: RGR-GRPO는 기존 성능 병목 현상을 넘어서는 지속적인 탐색과 효과적인 돌파를 반영하며, 오프정책 학습 중에도 안정적인 엔트로피 변동을 유지합니다.

Abstract: Recent advances in reinforcement learning (RL) have significantly improved the complex reasoning capabilities of large language models (LLMs). Despite these successes, existing methods mainly focus on single-domain RL (e.g., mathematics) with verifiable rewards (RLVR), and their reliance on purely online RL frameworks restricts the exploration space, thereby limiting reasoning performance. In this paper, we address these limitations by leveraging rubrics to provide both fine-grained reward signals and offline guidance. We propose $\textbf{RGR-GRPO}$ (Reward and Guidance through Rubrics), a rubric-driven RL framework for multi-domain reasoning. RGR-GRPO enables LLMs to receive dense and informative rewards while exploring a larger solution space during GRPO training. Extensive experiments across 14 benchmarks spanning multiple domains demonstrate that RGR-GRPO consistently outperforms RL methods that rely solely on alternative reward schemes or offline guidance. Compared with verifiable online RL baseline, RGR-GRPO achieves average improvements of +7.0%, +5.4%, +8.4%, and +6.6% on mathematics, physics, chemistry, and general reasoning tasks, respectively. Notably, RGR-GRPO maintains stable entropy fluctuations during off-policy training and achieves superior pass@k performance, reflecting sustained exploration and effective breakthrough beyond existing performance bottlenecks.

</details>


### [43] [More Than Irrational: Modeling Belief-Biased Agents](https://arxiv.org/abs/2511.12359)
*Yifan Zhu,Sammie Katt,Samuel Kaski*

Main category: cs.AI

TL;DR: 이 논문은 인지적으로 제한된 에이전트를 위한 계산-합리적 (CR) 사용자 모델을 제안하고, 이를 통해 사용자의 편향된 믿음 상태와 잠재적인 인지적 한계를 추정하는 온라인 추론 방법을 발전시키는 내용을 다룬다.


<details>
  <summary>Details</summary>
Motivation: AI의 급성장에도 불구하고, 사용자의 비최적 행동을 예측하고 추론하는 것은 여전히 중요한 도전 과제이다.

Method: 편향된 믿음 하에 최적 행동을 하는 인지적으로 제한된 에이전트를 위한 계산-합리적 사용자 모델을 formal하게 도입하고, 이를 바탕으로 사용자 특정의 잠재적 한계를 식별하는 온라인 추론 방법을 제안한다.

Result: 우리의 CR 모델은 다양한 기억 용량에 상응하는 직관적으로 그럴듯한 행동을 생성하며, 제한된 관찰에서 실제 인지적 한계를 정확하고 효율적으로 회복해낸다.

Conclusion: 이 접근법은 사용자의 기억 한계를 고려한 적응형 AI 도우미 개발을 위한 원칙적인 토대를 제공한다.

Abstract: Despite the explosive growth of AI and the technologies built upon it, predicting and inferring the sub-optimal behavior of users or human collaborators remains a critical challenge. In many cases, such behaviors are not a result of irrationality, but rather a rational decision made given inherent cognitive bounds and biased beliefs about the world. In this paper, we formally introduce a class of computational-rational (CR) user models for cognitively-bounded agents acting optimally under biased beliefs. The key novelty lies in explicitly modeling how a bounded memory process leads to a dynamically inconsistent and biased belief state and, consequently, sub-optimal sequential decision-making. We address the challenge of identifying the latent user-specific bound and inferring biased belief states from passive observations on the fly. We argue that for our formalized CR model family with an explicit and parameterized cognitive process, this challenge is tractable. To support our claim, we propose an efficient online inference method based on nested particle filtering that simultaneously tracks the user's latent belief state and estimates the unknown cognitive bound from a stream of observed actions. We validate our approach in a representative navigation task using memory decay as an example of a cognitive bound. With simulations, we show that (1) our CR model generates intuitively plausible behaviors corresponding to different levels of memory capacity, and (2) our inference method accurately and efficiently recovers the ground-truth cognitive bounds from limited observations ($\le 100$ steps). We further demonstrate how this approach provides a principled foundation for developing adaptive AI assistants, enabling adaptive assistance that accounts for the user's memory limitations.

</details>


### [44] [Learning to Trust: Bayesian Adaptation to Varying Suggester Reliability in Sequential Decision Making](https://arxiv.org/abs/2511.12378)
*Dylan M. Asmar,Mykel J. Kochenderfer*

Main category: cs.AI

TL;DR: 이 논문은 불확실한 환경에서 자율 에이전트가 동적으로 제안자 신뢰성을 학습하고 조정하는 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 시퀀스 의사결정 작업에서 불확실성 하에 작동하는 자율 에이전트는 외부의 행동 제안으로부터 이익을 얻을 수 있지만, 당신의 신뢰성에 내재된 변동성이 있습니다.

Method: 제안한 프레임워크는 에이전트의 신념 표현에 제안자 품질을 통합하고, Bayesian 추론을 통해 에이전트가 제안에 대한 의존성을 추론하고 조정할 수 있도록 합니다. 또한, 에이전트가 전략적으로 제안을 요청하는 'ask' 행동을 도입합니다.

Result: 실험적 평가를 통해 다양한 제안자 품질에서의 강건한 성능과 신뢰성 변화에 대한 적응 및 제안 요청의 전략적 관리가 검증되었습니다.

Conclusion: 이 연구는 불확실한 환경에서 제안의 불확실성을 해결하여 적응형 인간-에이전트 협력의 기초를 제공합니다.

Abstract: Autonomous agents operating in sequential decision-making tasks under uncertainty can benefit from external action suggestions, which provide valuable guidance but inherently vary in reliability. Existing methods for incorporating such advice typically assume static and known suggester quality parameters, limiting practical deployment. We introduce a framework that dynamically learns and adapts to varying suggester reliability in partially observable environments. First, we integrate suggester quality directly into the agent's belief representation, enabling agents to infer and adjust their reliance on suggestions through Bayesian inference over suggester types. Second, we introduce an explicit ``ask'' action allowing agents to strategically request suggestions at critical moments, balancing informational gains against acquisition costs. Experimental evaluation demonstrates robust performance across varying suggester qualities, adaptation to changing reliability, and strategic management of suggestion requests. This work provides a foundation for adaptive human-agent collaboration by addressing suggestion uncertainty in uncertain environments.

</details>


### [45] [Optimal Foraging in Memory Retrieval: Evaluating Random Walks and Metropolis-Hastings Sampling in Modern Semantic Spaces](https://arxiv.org/abs/2511.12759)
*James Moore*

Main category: cs.AI

TL;DR: 인간 기억 검색은 생태적 채집과 유사하며, 현대의 고차원 임베딩 공간이 인간 행동을 반영할 수 있는지를 연구했다.


<details>
  <summary>Details</summary>
Motivation: 인간의 기억 검색이 생태적 채집과 유사하다는 가설을 검증하고, 현대 임베딩 공간이 이러한 패턴을 어떻게 반영하는지를 이해하고자 한다.

Method: 최신 임베딩과 이전의 의미 유창성 데이터를 사용하여 임베딩 공간에서의 무작위 탐색을 분석하고, 메트로폴리스-헤이스팅스 샘플링을 도입하여 결과를 비교하였다.

Result: 무작위 탐색은 최적 채집 및 MVT와 일치하는 결과를 보였으나, 메트로폴리스-헤이스팅스 샘플링의 도입은 인간 행동과 일치하지 않는 결과를 나타냈다.

Conclusion: 간단한 샘플링으로도 적절히 구조화된 임베딩이 거의 최적의 채집 역학을 생성할 수 있음을 보여주어 복잡한 샘플링 메커니즘이 반드시 더 나은 인지 모델을 초래하지 않음을 시사한다.

Abstract: Human memory retrieval often resembles ecological foraging where animals search for food in a patchy environment. Optimal foraging means following the Marginal Value Theorem (MVT), in which individuals exploit a patch of semantically related concepts until it becomes less rewarding and then switch to a new cluster. While human behavioral data suggests foraging-like patterns in semantic fluency tasks, it remains unclear whether modern high-dimensional embedding spaces provide representations that allow algorithms to match observed human behavior. Using state-of-the-art embeddings and prior semantic fluency data, I find that random walks on these embedding spaces produce results consistent with optimal foraging and the MVT. Surprisingly, introducing Metropolis-Hastings sampling, an adaptive algorithm expected to model strategic acceptance and rejection of new clusters, does not produce results consistent with human behavior. These findings challenge the assumption that more complex sampling mechanisms inherently lead to better cognitive models of memory retrieval. Instead, they show that appropriately structured embeddings, even with simple sampling, can produce near-optimal foraging dynamics. This supports the perspective of Hills (2012) rather than Abbott (2015), demonstrating that modern embeddings can approximate human memory foraging without relying on complex acceptance criteria.

</details>


### [46] [Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization](https://arxiv.org/abs/2511.12792)
*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Zehong Cao,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 이 연구는 다양한 위성을 통합하여 자율 지구 관측 미션을 수행하는 위성 집단의 자원 최적화를 조사합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 최적화 방법은 실시간, 불확실하고 분산된 지구 관측 작업의 특성을 처리하는 데 어려움을 겪고 있으며, 이러한 문제를 해결하기 위해 RL 및 MARL을 사용하고자 합니다.

Method: 이 연구에서는 단일 위성에서 다중 위성 시나리오로의 최적화 문제를 체계적으로 형식화하였으며, 에너지 및 메모리 제약, 부분 관측성, 다양한 payload 기능에서 발생하는 에이전트 이질성 등의 주요 도전을 다룹니다.

Result: MARL이 이질적인 위성 간의 효과적인 조정을 가능하게 하여 이미징 성능과 자원 활용의 균형을 맞추고 비정상성과 에이전트 간 보상 결합을 완화함을 보여주었습니다.

Conclusion: 이 연구 결과는 규모 확장 가능하고 자율적인 위성 운영에 대한 실용적인 통찰을 제공하며, 이질적이고 동적인 조건에서 지능형 EO 미션 계획에 대한 향후 연구의 기초가 됩니다.

Abstract: This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.

</details>


### [47] [Mapping fNIRS Signals to Agent Performance: Toward Reinforcement Learning from Neural Feedback](https://arxiv.org/abs/2511.12844)
*Julia Santaniello,Matthew Russell,Benson Jiang,Donatello Sassaroli,Robert Jacob,Jivko SInapov*

Main category: cs.AI

TL;DR: 이 논문은 인간 피드백을 기반으로 한 강화 학습 방법론인 RLHF를 소개하며, 비활성 두뇌-컴퓨터 인터페이스를 이용해 에이전트 훈련을 지원하는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 인간의 선호도에 맞추어 에이전트의 행동을 조정하기 위해 인간 피드백을 통합하는 방법론이 필요하다.

Method: 25명의 참여자로부터 수집된 기능적 근적외선 분광기(fNIRS) 기록을 기반으로 한 데이터셋을 구축하고, 이를 이용하여 에이전트 성능 예측 모델을 훈련했다.

Result: 바이너리 분류에서는 67%, 다중 클래스 모델에서는 평균 46%의 F1 점수를 달성하였으며, 주어진 선택 행동과 최적 정책간의 편차를 예측하여 지속적인 성능 측정을 제공했다.

Conclusion: 후속 연구를 위한 두뇌 기반 RLHF 시스템의 기초를 마련하며, 암묵적인 fNIRS 신호와 에이전트 성능 간의 매핑이 가능하다는 것을 입증했다.

Abstract: Reinforcement Learning from Human Feedback (RLHF) is a methodology that aligns agent behavior with human preferences by integrating human feedback into the agent's training process. We introduce a possible framework that employs passive Brain-Computer Interfaces (BCI) to guide agent training from implicit neural signals. We present and release a novel dataset of functional near-infrared spectroscopy (fNIRS) recordings collected from 25 human participants across three domains: a Pick-and-Place Robot, Lunar Lander, and Flappy Bird. We train classifiers to predict levels of agent performance (optimal, sub-optimal, or worst-case) from windows of preprocessed fNIRS feature vectors, achieving an average F1 score of 67% for binary classification and 46% for multi-class models averaged across conditions and domains. We also train regressors to predict the degree of deviation between an agent's chosen action and a set of near-optimal policies, providing a continuous measure of performance. We evaluate cross-subject generalization and demonstrate that fine-tuning pre-trained models with a small sample of subject-specific data increases average F1 scores by 17% and 41% for binary and multi-class models, respectively. Our work demonstrates that mapping implicit fNIRS signals to agent performance is feasible and can be improved, laying the foundation for future brain-driven RLHF systems.

</details>


### [48] [Think, Speak, Decide: Language-Augmented Multi-Agent Reinforcement Learning for Economic Decision-Making](https://arxiv.org/abs/2511.12876)
*Heyang Ma,Qirui Mi,Qipeng Yang,Zijun Fan,Bo Li,Haifeng Zhang*

Main category: cs.AI

TL;DR: LAMP는 언어를 경제적 의사결정에 통합하여 MARL의 한계를 극복하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 경제적 의사결정은 가격 및 세금과 같은 구조적 신호와 동료 대화 및 미디어 서사와 같은 비구조적 언어 모두에 의존한다.

Method: LAMP는 Think-Speak-Decide 파이프라인을 따르며, 수치적 관찰을 해석하고, 전략적 메시지를 작성 및 교환하며, MARL 정책을 최적화한다.

Result: 경제 시뮬레이션 실험에서 LAMP는 누적 수익에서 MARL 및 LLM 기반 벤치마크를 초과하였다.

Conclusion: 이러한 결과는 언어 보강 정책이 보다 효과적이고 강력한 경제 전략을 제공할 잠재력을 보여준다.

Abstract: Economic decision-making depends not only on structured signals such as prices and taxes, but also on unstructured language, including peer dialogue and media narratives. While multi-agent reinforcement learning (MARL) has shown promise in optimizing economic decisions, it struggles with the semantic ambiguity and contextual richness of language. We propose LAMP (Language-Augmented Multi-Agent Policy), a framework that integrates language into economic decision-making and narrows the gap to real-world settings. LAMP follows a Think-Speak-Decide pipeline: (1) Think interprets numerical observations to extract short-term shocks and long-term trends, caching high-value reasoning trajectories; (2) Speak crafts and exchanges strategic messages based on reasoning, updating beliefs by parsing peer communications; and (3) Decide fuses numerical data, reasoning, and reflections into a MARL policy to optimize language-augmented decision-making. Experiments in economic simulation show that LAMP outperforms both MARL and LLM-only baselines in cumulative return (+63.5%, +34.0%), robustness (+18.8%, +59.4%), and interpretability. These results demonstrate the potential of language-augmented policies to deliver more effective and robust economic strategies.

</details>


### [49] [Fault2Flow: An AlphaEvolve-Optimized Human-in-the-Loop Multi-Agent System for Fault-to-Workflow Automation](https://arxiv.org/abs/2511.12916)
*Yafang Wang,Yangjie Tian,Xiaoyu Shen,Gaoyang Zhang,Jiaze Sun,He Zhang,Ruohua Xu,Feng Zhao*

Main category: cs.AI

TL;DR: Fault2Flow는 전력망 고장 진단 프로세스를 자동화하고 효율적으로 개선하는 LLM 기반의 다중 에이전트 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 수동적인 방식은 오류가 발생하기 쉽고 비효율적이며 유지 관리가 어렵기 때문에, 이를 개선하기 위한 새로운 접근 방식이 필요하다.

Method: Fault2Flow는 규제 논리를 추출하여 PASTA 형식의 장애 트리로 구조화하고, 인간 검증 인터페이스를 통해 전문가 지식을 통합하며, 새로운 AlphaEvolve 모듈을 통해 추론 논리를 최적화하고, 최종 검증된 논리를 n8n 실행 가능 워크플로우로 통합한다.

Result: 실험 결과, Fault2Flow는 100%의 위상 일관성과 높은 의미론적 충실도를 확인하였다.

Conclusion: Fault2Flow는 고장 분석에서 운영 자동화로의 재현 가능한 경로를 제시하여 전문가의 작업 부담을 상당히 줄인다.

Abstract: Power grid fault diagnosis is a critical process hindered by its reliance on manual, error-prone methods. Technicians must manually extract reasoning logic from dense regulations and attempt to combine it with tacit expert knowledge, which is inefficient, error-prone, and lacks maintainability as ragulations are updated and experience evolves. While Large Language Models (LLMs) have shown promise in parsing unstructured text, no existing framework integrates these two disparate knowledge sources into a single, verified, and executable workflow. To bridge this gap, we propose Fault2Flow, an LLM-based multi-agent system. Fault2Flow systematically: (1) extracts and structures regulatory logic into PASTA-formatted fault trees; (2) integrates expert knowledge via a human-in-the-loop interface for verification; (3) optimizes the reasoning logic using a novel AlphaEvolve module; and (4) synthesizes the final, verified logic into an n8n-executable workflow. Experimental validation on transformer fault diagnosis datasets confirms 100\% topological consistency and high semantic fidelity. Fault2Flow establishes a reproducible path from fault analysis to operational automation, substantially reducing expert workload.

</details>


### [50] [Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models](https://arxiv.org/abs/2511.12937)
*Guoyan Wang,Yanyan Huang,Chunlin Chen,Lifeng Wang,Yuxiang Sun*

Main category: cs.AI

TL;DR: Yanyun-3은 이질적인 전략 게임 환경에서 자율적으로 운영 가능한 에이전트 프레임워크로, 멀티모달 데이터 조합을 통해 전략 게임의 자동화를 위한 혁신적인 솔루션을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 크로스 플랫폼 전략 게임에서의 자동화 작전은 다양한 사용자 인터페이스와 역동적인 전장 조건에서 강한 일반화를 요구한다.

Method: 비전-언어 모델 Qwen2.5-VL과 UI-TARS의 정밀 실행 능력을 통합하여 자율적인 크로스 플랫폼 운영을 가능하게 하는 Yanyun-3을 소개한다.

Result: 정적 이미지, 다중 이미지 시퀀스 및 비디오의 여러 멀티모달 데이터 조합의 효과를 평가하고, 이내 샘플 융합과 샘플 간 혼합 전략을 구별하기 위한 조합 세분화 개념을 제안한다. 혼합 전략인 MV+S가 전체 융합을 크게 능가한다는 것을 발견했다.

Conclusion: 전략 게임 자동화를 위한 효율적인 솔루션을 제공하는 것 이상의 의미를 지니며, 구조화된 멀티모달 데이터 조직을 통한 VLM 성능 향상을 위한 일반적인 패러다임을 확립한다.

Abstract: Automated operation in cross-platform strategy games demands agents with robust generalization across diverse user interfaces and dynamic battlefield conditions. While vision-language models (VLMs) have shown considerable promise in multimodal reasoning, their application to complex human-computer interaction scenarios--such as strategy gaming--remains largely unexplored. Here, we introduce Yanyun-3, a general-purpose agent framework that, for the first time, enables autonomous cross-platform operation across three heterogeneous strategy game environments. By integrating the vision-language reasoning of Qwen2.5-VL with the precise execution capabilities of UI-TARS, Yanyun-3 successfully performs core tasks including target localization, combat resource allocation, and area control. Through systematic ablation studies, we evaluate the effects of various multimodal data combinations--static images, multi-image sequences, and videos--and propose the concept of combination granularity to differentiate between intra-sample fusion and inter-sample mixing strategies. We find that a hybrid strategy, which fuses multi-image and video data while mixing in static images (MV+S), substantially outperforms full fusion: it reduces inference time by 63% and boosts the BLEU-4 score by a factor of 12 (from 4.81% to 62.41%, approximately 12.98x). Operating via a closed-loop pipeline of screen capture, model inference, and action execution, the agent demonstrates strong real-time performance and cross-platform generalization. Beyond providing an efficient solution for strategy game automation, our work establishes a general paradigm for enhancing VLM performance through structured multimodal data organization, offering new insights into the interplay between static perception and dynamic reasoning in embodied intelligence.

</details>


### [51] [WebCoach: Self-Evolving Web Agents with Cross-Session Memory Guidance](https://arxiv.org/abs/2511.12997)
*Genglin Liu,Shijie Geng,Sha Li,Hejie Cui,Sarah Zhang,Xin Liu,Tianyi Liu*

Main category: cs.AI

TL;DR: WebCoach는 지속적인 크로스 세션 메모리를 제공하여 웹 브라우징 에이전트의 장기 계획 및 학습 능력을 향상시키는 자가 발전 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 멀티모달 LLM 기반 에이전트는 복잡한 웹 탐색 작업에서 반복적인 오류를 겪고 있으며, 세션 간 경험 학습이 부족하여 장기적인 견고성 및 샘플 효율성이 제한됩니다.

Method: WebCoach는 웹 브라우징 에이전트에 지속적인 크로스 세션 메모리를 제공하는 모델 독립적 자가 발전 프레임워크로, 웹 탐색 로그를 요약하고 완전한 경로를 에피소드 경험으로 조직하며 유사성과 최신성에 기반하여 관련 경험을 검색하고 특정 작업에 대한 조언을 세션 중에 주입하는 Coach를 포함합니다.

Result: WebCoach는 WebVoyager 벤치마크에서 브라우저 사용 에이전트의 성능을 세 가지 서로 다른 LLM 백본에서 일관되게 향상시켰습니다.

Conclusion: 38B 모델을 사용하여 작업 성공률이 47%에서 61%로 증가하고 평균 단계 수를 줄이거나 유지하면서 더 작은 기본 모델이 GPT-4o를 사용하는 동일한 웹 에이전트와 비슷한 성능을 달성합니다.

Abstract: Multimodal LLM-powered agents have recently demonstrated impressive capabilities in web navigation, enabling agents to complete complex browsing tasks across diverse domains. However, current agents struggle with repetitive errors and lack the ability to learn from past experiences across sessions, limiting their long-term robustness and sample efficiency. We introduce WebCoach, a model-agnostic self-evolving framework that equips web browsing agents with persistent cross-session memory, enabling improved long-term planning, reflection, and continual learning without retraining. WebCoach consists of three key components: (1) a WebCondenser, which standardizes raw navigation logs into concise summaries; (2) an External Memory Store, which organizes complete trajectories as episodic experiences; and (3) a Coach, which retrieves relevant experiences based on similarity and recency, and decides whether to inject task-specific advice into the agent via runtime hooks. This design empowers web agents to access long-term memory beyond their native context window, improving robustness in complex browsing tasks. Moreover, WebCoach achieves self-evolution by continuously curating episodic memory from new navigation trajectories, enabling agents to improve over time without retraining. Evaluations on the WebVoyager benchmark demonstrate that WebCoach consistently improves the performance of browser-use agents across three different LLM backbones. With a 38B model, it increases task success rates from 47% to 61% while reducing or maintaining the average number of steps. Notably, smaller base models with WebCoach achieve performance comparable to the same web agent using GPT-4o.

</details>


### [52] [MEGA-GUI: Multi-stage Enhanced Grounding Agents for GUI Elements](https://arxiv.org/abs/2511.13087)
*SeokJoo Kwak,Jihoon Kim,Boyoun Kim,Jung Jae Yoon,Wooseok Jang,Jeonghoon Hong,Jaeho Yang,Yeong-Dae Kwon*

Main category: cs.AI

TL;DR: MEGA-GUI는 자연어 지시를 화면 좌표에 매핑하는 다단계 프레임워크로, 기존 시스템의 한계를 극복하고 높은 정확도를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 자율 에이전트 및 접근성 기술에 필수적인 GUI 기초 작업의 필요성을 해결하기 위해.

Method: MEGA-GUI는 거칠은 관심 영역(ROI) 선택과 세밀한 요소 기초를 분리하여 전문 비전-언어 에이전트가 조율하는 다단계 프레임워크를 사용한다.

Result: MEGA-GUI는 ScreenSpot-Pro 벤치마크에서 73.18%의 정확도를 달성하고, OSWorld-G 벤치마크에서는 68.63%에 이르러 이전의 결과를 초과하였다.

Conclusion: 모듈식 구조를 활용하여 일관되게 더 높은 정확도를 달성할 수 있음을 보여준다.

Abstract: Graphical User Interface (GUI) grounding - the task of mapping natural language instructions to screen coordinates - is essential for autonomous agents and accessibility technologies. Existing systems rely on monolithic models or one-shot pipelines that lack modularity and fail under visual clutter and ambiguous instructions. We introduce MEGA-GUI, a multi-stage framework that separates grounding into coarse Region-of-Interest (ROI) selection and fine-grained element grounding, orchestrated by specialized vision-language agents. MEGA-GUI features a bidirectional ROI zoom algorithm that mitigates spatial dilution and a context-aware rewriting agent that reduces semantic ambiguity. Our analysis reveals complementary strengths and weaknesses across vision-language models at different visual scales, and we show that leveraging this modular structure achieves consistently higher accuracy than monolithic approaches. On the visually dense ScreenSpot-Pro benchmark, MEGA-GUI attains 73.18% accuracy, and on the semantically complex OSWorld-G benchmark it reaches 68.63%, surpassing previously reported results. Code and the Grounding Benchmark Toolkit (GBT) are available at https://github.com/samsungsds-research-papers/mega-gui.

</details>


### [53] [Conditional Diffusion Model for Multi-Agent Dynamic Task Decomposition](https://arxiv.org/abs/2511.13137)
*Yanda Zhu,Yuanyang Zhu,Daoyi Dong,Caihua Chen,Chunlin Chen*

Main category: cs.AI

TL;DR: C$	ext{D}^	ext{3}$T는 동적 작업 분해를 위한 새로운 MARL 프레임워크로, 하위 작업과 협조 패턴을 자동으로 추론하여 강력한 협력 학습을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 다중 에이전트 강화 학습 작업에서 효율적인 계층적 학습을 가능하게 하는 동적 작업 분해의 필요성.

Method: C$	ext{D}^	ext{3}$T는 두 수준의 계층적 MARL 프레임워크로, 고수준 정책이 하위 작업 표현을 학습하고, 조건부 확산 모델을 사용하여 환경에 대한 하위 작업의 효과를 캡처한다.

Result: C$	ext{D}^	ext{3}$T는 다양한 벤치마크에서 기존 기준보다 나은 성능을 보여주었다.

Conclusion: C$	ext{D}^	ext{3}$T는 동적이고 불확실한 환경에서 효율적이고 자동화된 작업 분해를 위한 유망한 접근 방식을 제공한다.

Abstract: Task decomposition has shown promise in complex cooperative multi-agent reinforcement learning (MARL) tasks, which enables efficient hierarchical learning for long-horizon tasks in dynamic and uncertain environments. However, learning dynamic task decomposition from scratch generally requires a large number of training samples, especially exploring the large joint action space under partial observability. In this paper, we present the Conditional Diffusion Model for Dynamic Task Decomposition (C$\text{D}^\text{3}$T), a novel two-level hierarchical MARL framework designed to automatically infer subtask and coordination patterns. The high-level policy learns subtask representation to generate a subtask selection strategy based on subtask effects. To capture the effects of subtasks on the environment, C$\text{D}^\text{3}$T predicts the next observation and reward using a conditional diffusion model. At the low level, agents collaboratively learn and share specialized skills within their assigned subtasks. Moreover, the learned subtask representation is also used as additional semantic information in a multi-head attention mixing network to enhance value decomposition and provide an efficient reasoning bridge between individual and joint value functions. Experimental results on various benchmarks demonstrate that C$\text{D}^\text{3}$T achieves better performance than existing baselines.

</details>


### [54] [Cost-Effective Communication: An Auction-based Method for Language Agent Interaction](https://arxiv.org/abs/2511.13193)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Chengpei Tang,Jian Wang,Keze Wang*

Main category: cs.AI

TL;DR: 본 논문은 대형 언어 모델 기반의 다중 에이전트 시스템(MAS)이 비효율적인 소통 문제를 겪고 있으며, 이를 해결하기 위해 DALA라는 동적 경매 기반 언어 에이전트 프레임워크를 도입한다. DALA는 소통의 대역폭을 자원으로 간주하고, 에이전트가 메시지의 가치 밀도를 바탕으로 발언 기회를 경매하듯이 입찰하게 한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델을 기반으로 한 다중 에이전트 시스템에서의 비효율적인 소통 문제를 해결하기 위해 자원 합리성의 결여가 핵심 문제라는 가설을 제기한다.

Method: DALA 프레임워크를 통해 커뮤니케이션 대역폭을 희귀하고 거래 가능한 자원으로 간주하며, 에이전트가 메시지의 가치 밀도를 예측해 소통 기회를 입찰하도록 한다.

Result: DALA는 7개의 도전적인 추론 벤치마크에서 새로운 최고 성능을 달성하며, MMLU에서 84.32% 및 HumanEval에서 91.21%의 합격률을 기록하였다.

Conclusion: DALA는 동적 자원 제약을 통해 에이전트가 소통 전략을 조절하며, 전략적 침묵의 기술을 배양하여 발언의 근본적인 효율성을 높인다.

Abstract: Multi-agent systems (MAS) built on large language models (LLMs) often suffer from inefficient "free-for-all" communication, leading to exponential token costs and low signal-to-noise ratios that hinder their practical deployment. We challenge the notion that more communication is always beneficial, hypothesizing instead that the core issue is the absence of resource rationality. We argue that "free" communication, by ignoring the principle of scarcity, inherently breeds inefficiency and unnecessary expenses. To address this, we introduce the Dynamic Auction-based Language Agent (DALA), a novel framework that treats communication bandwidth as a scarce and tradable resource. Specifically, our DALA regards inter-agent communication as a centralized auction, where agents learn to bid for the opportunity to speak based on the predicted value density of their messages. Thus, our DALA intrinsically encourages agents to produce concise, informative messages while filtering out low-value communication. Extensive and comprehensive experiments demonstrate that our economically-driven DALA achieves new state-of-the-art performance across seven challenging reasoning benchmarks, including 84.32% on MMLU and a 91.21% pass@1 rate on HumanEval. Note that this is accomplished with remarkable efficiency, i.e., our DALA uses only 6.25 million tokens, a fraction of the resources consumed by current state-of-the-art methods on GSM8K. Further analysis reveals that our DALA cultivates the emergent skill of strategic silence, effectively adapting its communication strategies from verbosity to silence in a dynamical manner via resource constraints.

</details>


### [55] [Informative Communication of Robot Plans](https://arxiv.org/abs/2511.13226)
*Michele Persiani,Thomas Hellstrom*

Main category: cs.AI

TL;DR: 로봇이 계획을 언어화할 때 정보적 의사소통을 위한 전략을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 로봇이 사용자에게 계획을 전달할 때 효과적으로 정보를 전달하지 못하는 기존의 언어화 전략의 한계를 극복하고자 한다.

Method: 사용자의 사전 지식을 반영한 2차 이론적 사고에 대해 언어화의 정보 이득을 측정하는 전략을 제안한다.

Result: 제안된 전략을 통해 로봇의 목표를 더 빠르게 이해할 수 있으며, 기존의 계획 순서를 조정하는 것보다 효과적이다.

Conclusion: 로봇이 계획을 전달할 때 무엇이 정보적이고 왜 그런지를 제시함으로써 의사소통을 개선할 수 있다.

Abstract: When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot's goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.

</details>


### [56] [Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO](https://arxiv.org/abs/2511.13288)
*Haoyang Hong,Jiajun Yin,Yuan Wang,Jingnan Liu,Zhe Chen,Ailing Yu,Ji Li,Zhiling Ye,Hansong Xiao,Yefei Chen,Hualei Zhou,Yun Yue,Minghui Yang,Chunxiao Guo,Junwei Liu,Peng Wei,Jinjie Gu*

Main category: cs.AI

TL;DR: M-GRPO는 다중 에이전트 시스템을 위한 계층적 정책 최적화 방법으로, 전문화된 LLM을 통해 에이전트 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 시스템의 성능은 일반 추론 작업에서 우수하지만, 전문화된 분야 훈련이 부족하여 정확도가 저하됩니다.

Method: M-GRPO는 주 에이전트와 여러 하위 에이전트가 있는 수직 다중 에이전트 시스템을 위해 설계된 계층적 Group Relative Policy Optimization의 확장입니다.

Result: M-GRPO는 실제 벤치마크에서 단일 에이전트 GRPO 및 고정된 하위 에이전트와의 다중 에이전트 GRPO보다 일관되게 우수한 성능을 보입니다.

Conclusion: 다양한 에이전트 간 최적화 분리를 통해 도구 보강 추론 작업을 향상시킬 수 있음을 보여줍니다.

Abstract: Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.

</details>


### [57] [Dropouts in Confidence: Moral Uncertainty in Human-LLM Alignment](https://arxiv.org/abs/2511.13290)
*Jea Kwon,Luiz Felipe Vecchietti,Sungwon Park,Meeyoung Cha*

Main category: cs.AI

TL;DR: 인공지능의 도덕적 결정에서의 불확실성을 연구한 논문


<details>
  <summary>Details</summary>
Motivation: 도덕적 딜레마에 직면했을 때 인간이 보이는 불확실성이 기계와 인공지능에서도 존재하는지 이해하고자 함.

Method: 32개의 오픈 소스 모델과 9개의 도덕적 차원에서 응답을 분석하고, 모델 신뢰도의 분산을 측정하며, 추론 시 '드롭아웃'을 통해 모델에 확률성을 도입함.

Result: 모델 아키텍처와 학습 방법이 도덕적 불확실성에 지배적인 영향을 미치며, 우리의 메커니즘이 총 엔트로피를 증가시키고 인체-LLM 도덕적 정렬을 향상시켜 인간의 선호와 모델 결정 간의 일치를 도모함.

Conclusion: 모델이 생성한 결정을 인간의 선호와 더 잘 일치시키기 위해 불확실성을 조절하고 LLM의 자신감을 줄이는 방법이 있음을 보여줌.

Abstract: Humans display significant uncertainty when confronted with moral dilemmas, yet the extent of such uncertainty in machines and AI agents remains underexplored. Recent studies have confirmed the overly confident tendencies of machine-generated responses, particularly in large language models (LLMs). As these systems are increasingly embedded in ethical decision-making scenarios, it is important to understand their moral reasoning and the inherent uncertainties in building reliable AI systems. This work examines how uncertainty influences moral decisions in the classical trolley problem, analyzing responses from 32 open-source models and 9 distinct moral dimensions. We first find that variance in model confidence is greater across models than within moral dimensions, suggesting that moral uncertainty is predominantly shaped by model architecture and training method. To quantify uncertainty, we measure binary entropy as a linear combination of total entropy, conditional entropy, and mutual information. To examine its effects, we introduce stochasticity into models via "dropout" at inference time. Our findings show that our mechanism increases total entropy, mainly through a rise in mutual information, while conditional entropy remains largely unchanged. Moreover, this mechanism significantly improves human-LLM moral alignment, with correlations in mutual information and alignment score shifts. Our results highlight the potential to better align model-generated decisions and human preferences by deliberately modulating uncertainty and reducing LLMs' confidence in morally complex scenarios.

</details>


### [58] [Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical Agentic Retrieval](https://arxiv.org/abs/2511.13293)
*Chuang Zhao,Hui Tang,Hongke Zhao,Xiaofang Zhou,Xiaomeng Li*

Main category: cs.AI

TL;DR: 이 논문에서는 의료 예측을 향상시키기 위해 GHAR이라는 새로운 RAG 프레임워크를 제안하며, 이는 정보 검색 메커니즘의 활성화 시기와 서브모듈 간의 협력을 최적화하는 방법을 동시에 해결합니다.


<details>
  <summary>Details</summary>
Motivation: 정확한 의료 예측은 환자 결과 개선 및 운영 비용 절감에 필수적입니다.

Method: GHAR은 이중 에이전트 아키텍처를 사용하여 의료 분야에서 정보 검색 메커니즘을 활성화할 시기와 서브모듈 간의 협력을 최적화합니다.

Result: 세 가지 벤치마크 데이터 세트와 세 가지 인기 있는 작업에서 광범위한 실험을 실시하여 최첨단 기준보다 우수성을 입증했습니다.

Conclusion: GHAR은 의료 시스템의 발전을 위한 계층적 에이전틱 RAG의 잠재력을 강조합니다.

Abstract: Accurate healthcare prediction is critical for improving patient outcomes and reducing operational costs. Bolstered by growing reasoning capabilities, large language models (LLMs) offer a promising path to enhance healthcare predictions by drawing on their rich parametric knowledge. However, LLMs are prone to factual inaccuracies due to limitations in the reliability and coverage of their embedded knowledge. While retrieval-augmented generation (RAG) frameworks, such as GraphRAG and its variants, have been proposed to mitigate these issues by incorporating external knowledge, they face two key challenges in the healthcare scenario: (1) identifying the clinical necessity to activate the retrieval mechanism, and (2) achieving synergy between the retriever and the generator to craft contextually appropriate retrievals. To address these challenges, we propose GHAR, a \underline{g}enerative \underline{h}ierarchical \underline{a}gentic \underline{R}AG framework that simultaneously resolves when to retrieve and how to optimize the collaboration between submodules in healthcare. Specifically, for the first challenge, we design a dual-agent architecture comprising Agent-Top and Agent-Low. Agent-Top acts as the primary physician, iteratively deciding whether to rely on parametric knowledge or to initiate retrieval, while Agent-Low acts as the consulting service, summarising all task-relevant knowledge once retrieval was triggered. To tackle the second challenge, we innovatively unify the optimization of both agents within a formal Markov Decision Process, designing diverse rewards to align their shared goal of accurate prediction while preserving their distinct roles. Extensive experiments on three benchmark datasets across three popular tasks demonstrate our superiority over state-of-the-art baselines, highlighting the potential of hierarchical agentic RAG in advancing healthcare systems.

</details>


### [59] [Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning](https://arxiv.org/abs/2511.13371)
*Caroline Baumgartner,Eleanor Spens,Neil Burgess,Petru Manescu*

Main category: cs.AI

TL;DR: 이 연구는 대형 언어 모델이 공간 탐색 작업을 해결하는 방법을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 공간 탐색 능력을 이해하기 위해.

Method: 세 가지 공간 학습 패러다임(수동 탐색, 목표 지향 계획, 하이브리드 모델)에서 GPT-2 모델을 훈련하였다.

Result: 다른 두 가지 학습 알고리즘을 발견하였다: Foraging 모델은 공간의 강력한 매핑을 개발하고, 목표 지향 모델은 경로 의존 알고리즘을 배운다.

Conclusion: 공간 지능의 본질이 탐색 데이터에 의해 형성된 일반화 가능한 세계 모델에서 목표 지향 작업을 위한 최적화된 휴리스틱 사이의 스펙트럼에 존재함을 제안한다.

Abstract: How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.

</details>


### [60] [An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence](https://arxiv.org/abs/2511.13411)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 본 논문에서는 인공지능의 발전 단계를 측정하기 위한 자율 인공지능(AI) 스케일을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 자율 인공지능의 발전과 그 경과를 정량적으로 평가할 필요가 있다.

Method: 10가지 능력 축을 정의하고 AAI-Index를 사용하여 이를 집계하며, 자기 개선 계수를 도입하고 이를 검증 가능한 기준으로 변환한다.

Result: 현재의 시스템이 이 스케일에 어떻게 접목되는지 보여주고, 자율성의 경계를 향상시키는 방법을 설명한다.

Conclusion: AI의 발전 단계와 이에 대한 수학적 정리를 통해 '아기 AGI'가 초지능으로 발전할 수 있음을 입증한다.

Abstract: We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing "baby AGI" becomes Superintelligence intuition.

</details>


### [61] [Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation](https://arxiv.org/abs/2511.13476)
*Zhipeng Ma,Ali Rida Bahja,Andreas Burgdorf,André Pomp,Tobias Meisen,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.AI

TL;DR: 여객 운송의 연료 효율성을 향상시키기 위한 연구로, 복잡한 다중 모달 데이터를 자동화된 방식으로 해석 가능한 통찰력으로 전환하는 다중 에이전트 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대중교통의 연료 효율성을 높이기 위해서는 복잡한 다중 모달 데이터를 해석 가능하고 결정적인 통찰력으로 통합해야 하지만, 전통적인 분석 및 시각화 방법은 재단된 출력만을 생성하여 해석의 필요성을 증가시킨다.

Method: 이 연구는 다중 에이전트 프레임워크를 제안하며, 데이터 서술 에이전트, LLM-판사 에이전트 및 인적 평가자를 포함하여 분석 결과를 이해관계자 중심의 보고서로 변환하는 방법을 반복적으로 조정한다.

Result: 덴마크 노르드 유틀란드의 공공 버스 운송에 관한 사례 연구를 통해 4006개의 여행 데이터를 가우시안 혼합 모델 클러스터링을 사용하여 분석하고, 다섯 가지 최신 LLM과 세 가지 프롬프트 패러다임 간의 비교 실험을 통해 GPT-4.1 미니와 사고의 연쇄 프롬프트가 최적의 구성으로 식별된다.

Conclusion: 제안된 프레임워크는 에너지 정보학에서 AI 기반 내러티브 생성 및 의사 지원을 위한 재현 가능하고 도메인 적응적인 방법론을 수립한다.

Abstract: Enhancing fuel efficiency in public transportation requires the integration of complex multimodal data into interpretable, decision-relevant insights. However, traditional analytics and visualization methods often yield fragmented outputs that demand extensive human interpretation, limiting scalability and consistency. This study presents a multi-agent framework that leverages multimodal large language models (LLMs) to automate data narration and energy insight generation. The framework coordinates three specialized agents, including a data narration agent, an LLM-as-a-judge agent, and an optional human-in-the-loop evaluator, to iteratively transform analytical artifacts into coherent, stakeholder-oriented reports. The system is validated through a real-world case study on public bus transportation in Northern Jutland, Denmark, where fuel efficiency data from 4006 trips are analyzed using Gaussian Mixture Model clustering. Comparative experiments across five state-of-the-art LLMs and three prompting paradigms identify GPT-4.1 mini with Chain-of-Thought prompting as the optimal configuration, achieving 97.3% narrative accuracy while balancing interpretability and computational cost. The findings demonstrate that multi-agent orchestration significantly enhances factual precision, coherence, and scalability in LLM-based reporting. The proposed framework establishes a replicable and domain-adaptive methodology for AI-driven narrative generation and decision support in energy informatics.

</details>


### [62] [FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI](https://arxiv.org/abs/2511.13524)
*Yuhang Peng,Yizhou Pan,Xinning He,Jihaoyu Yang,Xinyu Yin,Han Wang,Xiaoji Zheng,Chao Gao,Jiangtao Gong*

Main category: cs.AI

TL;DR: FreeAskWorld는 인간 중심의 사회적 행동을 캡처하기 위해 대형 언어 모델을 통합한 인터랙티브 시뮬레이션 프레임워크이다. 이 프레임워크는 현실적인 인간-에이전트 시뮬레이션을 지원하며, 방향 탐색 수행 시 에이전트가 길잡이를 능동적으로 탐색하고 해석할 수 있도록 디자인되었다.


<details>
  <summary>Details</summary>
Motivation: 인공지능 연구의 핵심 분야로 떠오른 체화된 지능은 복잡하고 인간 중심의 사회적 행동을 캡처하기 위해 진화해야 한다.

Method: FreeAskWorld는 대형 언어 모델을 통합하여 고차원 행동 계획 및 의미론적으로 기반한 상호작용을 지원하는 인터랙티브 시뮬레이션 프레임워크이다.

Result: FreeAskWorld는 63,429개의 주석이 달린 샘플 프레임과 17시간 이상의 상호작용 데이터를 포함한 대규모 벤치마크 데이터셋을 공개했으며, 이를 통해 기존의 VLN 모델과 인간 참가자들의 성능을 평가하였다.

Conclusion: FreeAskWorld에서 미세조정된 모델은 원래 모델보다 우수한 성능을 보여주며, 사회적 기반 시뮬레이션 프레임워크의 효율성을 강조한다.

Abstract: As embodied intelligence emerges as a core frontier in artificial intelligence research, simulation platforms must evolve beyond low-level physical interactions to capture complex, human-centered social behaviors. We introduce FreeAskWorld, an interactive simulation framework that integrates large language models (LLMs) for high-level behavior planning and semantically grounded interaction, informed by theories of intention and social cognition. Our framework supports scalable, realistic human-agent simulations and includes a modular data generation pipeline tailored for diverse embodied tasks.To validate the framework, we extend the classic Vision-and-Language Navigation (VLN) task into a interaction enriched Direction Inquiry setting, wherein agents can actively seek and interpret navigational guidance. We present and publicly release FreeAskWorld, a large-scale benchmark dataset comprising reconstructed environments, six diverse task types, 16 core object categories, 63,429 annotated sample frames, and more than 17 hours of interaction data to support training and evaluation of embodied AI systems. We benchmark VLN models, and human participants under both open-loop and closed-loop settings. Experimental results demonstrate that models fine-tuned on FreeAskWorld outperform their original counterparts, achieving enhanced semantic understanding and interaction competency. These findings underscore the efficacy of socially grounded simulation frameworks in advancing embodied AI systems toward sophisticated high-level planning and more naturalistic human-agent interaction. Importantly, our work underscores that interaction itself serves as an additional information modality.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [63] [Detecting Statistically Significant Fairness Violations in Recidivism Forecasting Algorithms](https://arxiv.org/abs/2511.11575)
*Animesh Joshi*

Main category: cs.LG

TL;DR: 이 논문은 알고리즘의 공정성 위반을 통계적으로 검증하기 위한 엄격한 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 알고리즘적 결정이 금융, 의료 및 범죄 사법 등의 중요한 분야에서 점점 더 많이 사용됨에 따라 알고리즘 공정성에 대한 관심이 높아지고 있습니다.

Method: k-겹 교차 검증을 활용하여 공정성 지표의 표본 분포를 생성하고, 예측 결과와 실제 결과 간의 불균형, 모델 보정 및 인과 추론 기법을 기반으로 공정성 지표의 통계적 유의성을 테스트하는 통계적 검정을 소개합니다.

Result: 재범 예측 알고리즘을 테스트한 결과, Black 개인에 대해 여러 공정성 정의 하에서 통계적으로 유의미한 편향이 나타났으며, White 개인에 대해서는 다른 정의 하에서 편향이 없거나 오히려 편향이 있음을 발견했습니다.

Conclusion: 알고리즘적 의사결정 시스템을 평가할 때, 엄격하고 탄탄한 통계적 검정의 중요성을 강조합니다.

Abstract: Machine learning algorithms are increasingly deployed in critical domains such as finance, healthcare, and criminal justice [1]. The increasing popularity of algorithmic decision-making has stimulated interest in algorithmic fairness within the academic community. Researchers have introduced various fairness definitions that quantify disparities between privileged and protected groups, use causal inference to determine the impact of race on model predictions, and that test calibration of probability predictions from the model. Existing literature does not provide a way in which to assess whether observed disparities between groups are statistically significant or merely due to chance. This paper introduces a rigorous framework for testing the statistical significance of fairness violations by leveraging k-fold cross-validation [2] to generate sampling distributions of fairness metrics. This paper introduces statistical tests that can be used to identify statistically significant violations of fairness metrics based on disparities between predicted and actual outcomes, model calibration, and causal inference techniques [1]. We demonstrate this approach by testing recidivism forecasting algorithms trained on data from the National Institute of Justice. Our findings reveal that machine learning algorithms used for recidivism forecasting exhibit statistically significant bias against Black individuals under several fairness definitions, while also exhibiting no bias or bias against White individuals under other definitions. The results from this paper underscore the importance of rigorous and robust statistical testing while evaluating algorithmic decision-making systems.

</details>


### [64] [DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs](https://arxiv.org/abs/2511.11576)
*WenZhuo Zhu,Zheng Cui,Wenhan Lu,Sheng Liu,Yue Zhao*

Main category: cs.LG

TL;DR: 대규모 언어 모델(LLM)을 활용한 자동 최적화 모델링 연구가 진행되고 있으며, DAOpt 프레임워크와 새로운 데이터셋 OptU를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 실제 의사결정은 본질적으로 불확실하며, 기존 연구는 주로 알려진 매개변수를 가진 결정론적 최적화에 초점을 맞추었다.

Method: DAOpt 프레임워크를 제안하며, 새로운 데이터셋 OptU, 다중 에이전트 의사결정 모듈, LLM을 평가하기 위한 시뮬레이션 환경을 포함한다.

Result: LLM의 샘플 외 적합성과 강건성에 대한 평가를 중시하며, stochastic 및 robust optimization의 도메인 지식을 통한 few-shot learning을 통합하여 LLM의 모델링 능력을 향상시킨다.

Conclusion: 본 연구는 불확실한 환경에서 LLM의 적용 가능성을 탐색하는 중요한 기초 작업을 제공한다.

Abstract: Recent advances in large language models (LLMs) have accelerated research on automated optimization modeling. While real-world decision-making is inherently uncertain, most existing work has focused on deterministic optimization with known parameters, leaving the application of LLMs in uncertain settings largely unexplored. To that end, we propose the DAOpt framework including a new dataset OptU, a multi-agent decision-making module, and a simulation environment for evaluating LLMs with a focus on out-of-sample feasibility and robustness. Additionally, we enhance LLMs' modeling capabilities by incorporating few-shot learning with domain knowledge from stochastic and robust optimization.

</details>


### [65] [Clustering-Based Weight Orthogonalization for Stabilizing Deep Reinforcement Learning](https://arxiv.org/abs/2511.11607)
*Guoqing Ma,Yuhan Zhang,Yuming Dai,Guangfu Hao,Yang Chen,Shan Yu*

Main category: cs.LG

TL;DR: 본 논문에서는 비정상적인 환경에서의 강화 학습의 비효율성을 해결하기 위해 COWM 레이어를 도입하여 학습 속도를 개선하고 gradient 간섭을 줄이며, 다양한 알고리즘과 작업에서 강건성과 일반성을 발휘함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습 에이전트는 환경의 비정상성을 고려하지 않고 학습 효율성을 떨어뜨린다.

Method: 우리는 COWM 레이어를 도입하여 정책 네트워크에 통합하고 클러스터링 기법과 프로젝션 매트릭스를 사용하여 학습 과정을 안정화한다.

Result: COWM은 최신 방법들을 능가하며, DMControl 벤치마크에서 비전 기반 및 상태 기반에서 각각 9% 및 12.6% 향상을 보여준다.

Conclusion: COWM은 다양한 알고리즘과 작업에서 우수한 성능과 강건성을 입증한다.

Abstract: Reinforcement learning (RL) has made significant advancements, achieving superhuman performance in various tasks. However, RL agents often operate under the assumption of environmental stationarity, which poses a great challenge to learning efficiency since many environments are inherently non-stationary. This non-stationarity results in the requirement of millions of iterations, leading to low sample efficiency. To address this issue, we introduce the Clustering Orthogonal Weight Modified (COWM) layer, which can be integrated into the policy network of any RL algorithm and mitigate non-stationarity effectively. The COWM layer stabilizes the learning process by employing clustering techniques and a projection matrix. Our approach not only improves learning speed but also reduces gradient interference, thereby enhancing the overall learning efficiency. Empirically, the COWM outperforms state-of-the-art methods and achieves improvements of 9% and 12.6% in vision based and state-based DMControl benchmark. It also shows robustness and generality across various algorithms and tasks.

</details>


### [66] [Small Vocabularies, Big Gains: Pretraining and Tokenization in Time Series Models](https://arxiv.org/abs/2511.11622)
*Alexis Roger,Gwen Legate,Kashif Rasul,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.LG

TL;DR: 이 논문은 Tokenization과 전이 학습이 시계열 기초 모델 성능에 미치는 영향을 연구하였다.


<details>
  <summary>Details</summary>
Motivation: 최첨단 시계열 기초 모델을 구축하기 위해 Tokenization과 전이 학습의 중요성을 이해하고자 하였다.

Method: 토크나이저 디자인, 스케일링 및 양자화 전략, 사전 훈련 대 랜덤 초기화의 영향을 체계적으로 연구하였다.

Result: 사전 훈련된 모델이 잘 설계된 토크나이저를 더 효과적으로 활용하며, 잘못된 토크나이징은 사전 훈련의 이점을 감소시킬 수 있음을 보여주었다.

Conclusion: 정확한 토크나이징의 중요성을 강조하며, 작은 단어 집합과 미리 훈련된 가중치를 결합하는 것이 다중 모드 예측 설정에서 특히 유리하다고 제안하였다.

Abstract: Tokenization and transfer learning are two critical components in building state of the art time series foundation models for forecasting. In this work, we systematically study the effect of tokenizer design, specifically scaling and quantization strategies, on model performance, alongside the impact of pretraining versus random initialization. We show that tokenizer configuration primarily governs the representational capacity and stability of the model, while transfer learning influences optimization efficiency and alignment. Using a combination of empirical training experiments and theoretical analyses, we demonstrate that pretrained models consistently leverage well-designed tokenizers more effectively, particularly at smaller vocabulary sizes. Conversely, misaligned tokenization can diminish or even invert the benefits of pretraining. These findings highlight the importance of careful tokenization in time series modeling and suggest that combining small, efficient vocabularies with pretrained weights is especially advantageous in multi-modal forecasting settings, where the overall vocabulary must be shared across modalities. Our results provide concrete guidance for designing tokenizers and leveraging transfer learning in discrete representation learning for continuous signals.

</details>


### [67] [MedFedPure: A Medical Federated Framework with MAE-based Detection and Diffusion Purification for Inference-Time Attacks](https://arxiv.org/abs/2511.11625)
*Mohammad Karami,Mohammad Reza Nemati,Aidin Kazemi,Ali Mikaeili Barzili,Hamid Azadegan,Behzad Moshiri*

Main category: cs.LG

TL;DR: 의료 영상에서 인공지능(AI)의 잠재력은 크지만, 연합 학습(FL)으로 훈련된 모델은 추론 시 취약하다. 본 논문에서는 진단 AI 모델을 보호하기 위한 개인화된 방어 프레임워크인 MedFedPure를 제안한다.


<details>
  <summary>Details</summary>
Motivation: AI 모델의 추론 시 보안 취약성과 잘못된 진단 가능성을 줄이기 위해.

Method: MedFedPure는 개인화된 FL 모델, 의심스러운 입력을 탐지하는 마스크드 오토인코더(MAE), 선택적으로 스캔을 정화하는 확산 기반 정화 모듈을 결합한다.

Result: MedFedPure는 Br35H 뇌 MRI 데이터셋에서 적대적 강인성을 크게 향상시켜 성능을 49.50%에서 87.33%로 개선하고, 깨끗한 정확도는 97.67%를 유지했다.

Conclusion: 우리 프레임워크는 진단 중에 로컬에서 실시간으로 작동하여 안전하고 신뢰할 수 있으며 프라이버시를 보호하는 AI 도구를 임상 작업 흐름에 배포할 수 있는 실질적인 경로를 제공한다.

Abstract: Artificial intelligence (AI) has shown great potential in medical imaging, particularly for brain tumor detection using Magnetic Resonance Imaging (MRI). However, the models remain vulnerable at inference time when they are trained collaboratively through Federated Learning (FL), an approach adopted to protect patient privacy. Adversarial attacks can subtly alter medical scans in ways invisible to the human eye yet powerful enough to mislead AI models, potentially causing serious misdiagnoses. Existing defenses often assume centralized data and struggle to cope with the decentralized and diverse nature of federated medical settings. In this work, we present MedFedPure, a personalized federated learning defense framework designed to protect diagnostic AI models at inference time without compromising privacy or accuracy. MedFedPure combines three key elements: (1) a personalized FL model that adapts to the unique data distribution of each institution; (2) a Masked Autoencoder (MAE) that detects suspicious inputs by exposing hidden perturbations; and (3) an adaptive diffusion-based purification module that selectively cleans only the flagged scans before classification. Together, these steps offer robust protection while preserving the integrity of normal, benign images. We evaluated MedFedPure on the Br35H brain MRI dataset. The results show a significant gain in adversarial robustness, improving performance from 49.50% to 87.33% under strong attacks, while maintaining a high clean accuracy of 97.67%. By operating locally and in real time during diagnosis, our framework provides a practical path to deploying secure, trustworthy, and privacy-preserving AI tools in clinical workflows.
  Index Terms: cancer, tumor detection, federated learning, masked autoencoder, diffusion, privacy

</details>


### [68] [Convergence of Multiagent Learning Systems for Traffic control](https://arxiv.org/abs/2511.11654)
*Sayambhu Sen,Shalabh Bhatnagar*

Main category: cs.LG

TL;DR: 이 논문은 다중 에이전트 강화 학습을 활용한 교통 신호 제어의 안정성과 수렴 속성을 이론적으로 분석한다.


<details>
  <summary>Details</summary>
Motivation: 벵갈루루와 같은 도시에서의 급속한 도시화로 인해 심각한 교통 혼잡이 발생하고 있으며, 효율적인 교통 신호 제어가 필수적이다.

Method: 각 교통 신호를 독립 에이전트로 모델링하여 Q-learning을 사용하는 다중 에이전트 강화 학습 방법을 적용하고, 강화 학습의 수렴 문제를 조사한다.

Result: 제시된 조건하에 교통 제어를 위한 특정 다중 에이전트 강화 학습 알고리즘이 수렴하는 것을 증명하였다.

Conclusion: 이 알고리즘은 비동기 가치 반복을 위한 단일 에이전트 수렴 증명으로부터 확장된다.

Abstract: Rapid urbanization in cities like Bangalore has led to severe traffic congestion, making efficient Traffic Signal Control (TSC) essential. Multi-Agent Reinforcement Learning (MARL), often modeling each traffic signal as an independent agent using Q-learning, has emerged as a promising strategy to reduce average commuter delays. While prior work Prashant L A et. al has empirically demonstrated the effectiveness of this approach, a rigorous theoretical analysis of its stability and convergence properties in the context of traffic control has not been explored. This paper bridges that gap by focusing squarely on the theoretical basis of this multi-agent algorithm. We investigate the convergence problem inherent in using independent learners for the cooperative TSC task. Utilizing stochastic approximation methods, we formally analyze the learning dynamics. The primary contribution of this work is the proof that the specific multi-agent reinforcement learning algorithm for traffic control is proven to converge under the given conditions extending it from single agent convergence proofs for asynchronous value iteration.

</details>


### [69] [Lightweight Time Series Data Valuation on Time Series Foundation Models via In-Context Finetuning](https://arxiv.org/abs/2511.11648)
*Shunyu Wu,Tianyue Li,Yixuan Leng,Jingyi Suo,Jian Lou,Dan Li,See-Kiong Ng*

Main category: cs.LG

TL;DR: LTSV라는 경량 시계열 데이터 평가 기법을 제안하며, 이는 TSFM의 성능 향상을 위해 중요한 시계열 데이터의 정확하고 효율적인 평가를 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 시간 시리즈 기반 모델의 성능에 있어 시계열 데이터의 질이 매우 중요하지만, 기존의 데이터 평가 방법은 스케일이 크고 시간 종속성을 보존하지 못하는 문제를 겪고 있다.

Method: LTSV는 인컨텍스트 미세 조정을 통해 샘플의 기여도를 측정하며, 특히 시간 종속성을 반영하기 위해 시간 블록 집계를 도입한다.

Result: LTSV는 여러 시계열 데이터셋에서 신뢰성 높은 평가 성능을 보여주면서도 계산 요구 사항이 관리 가능하다.

Conclusion: 인컨텍스트 미세 조정은 시계열 학습에서 데이터 귀속과 모델 일반화 간의 실용적이고 효과적인 다리 역할을 한다.

Abstract: Time series foundation models (TSFMs) have demonstrated increasing capabilities due to their extensive pretraining on large volumes of diverse time series data. Consequently, the quality of time series data is crucial to TSFM performance, rendering an accurate and efficient data valuation of time series for TSFMs indispensable. However, traditional data valuation methods, such as influence functions, face severe computational bottlenecks due to their poor scalability with growing TSFM model sizes and often fail to preserve temporal dependencies. In this paper, we propose LTSV, a Lightweight Time Series Valuation on TSFMS via in-context finetuning. Grounded in the theoretical evidence that in-context finetuning approximates the influence function, LTSV estimates a sample's contribution by measuring the change in context loss after in-context finetuning, leveraging the strong generalization capabilities of TSFMs to produce robust and transferable data valuations. To capture temporal dependencies, we introduce temporal block aggregation, which integrates per-block influence scores across overlapping time windows. Experiments across multiple time series datasets and models demonstrate that LTSV consistently provides reliable and strong valuation performance, while maintaining manageable computational requirements. Our results suggest that in-context finetuning on time series foundation models provides a practical and effective bridge between data attribution and model generalization in time series learning.

</details>


### [70] [Clifford Algebraic Rotor Embeddings : Maybe embeddings should start to CARE](https://arxiv.org/abs/2511.11665)
*Sameeksha Sriram,Ayush Paliwal,Alexander S. Ecker,Chase van de Geijn*

Main category: cs.LG

TL;DR: Rotary Positional Embeddings (RoPE)의 확장된 형태로서 QuatRo와 CARE를 제안하며, 다양한 차원에서 회전 임베딩을 일반화할 수 있는 방법을 탐구함.


<details>
  <summary>Details</summary>
Motivation: RoPE의 회전 불변성 속성을 유지하며 비가환적인 고차원 입력으로의 확장을 알기 위한 필요성이 있음.

Method: 쿼터니온 기반 접근법인 Quaternion Rotary Embeddings (QuatRo)를 사용하여 회전축을 매개변수화하고, Clifford 대수를 활용한 일반화로 Clifford Algebraic Rotary Embeddings (CARE)를 제안.

Result: Mixed RoPE와 Spherical RoPE가 QuatRo의 특별한 경우임을 보이고, 다양한 차원으로 회전 임베딩을 확장하는 방법론 제시.

Conclusion: 전통적인 방식에 대한 개선을 통해 다용도로 활용 가능한 임베딩 모델 설계 가능성이 있음.

Abstract: Rotary Positional Embeddings (RoPE) have demonstrated exceptional performance as a positional encoding method, consistently outperforming their baselines. While recent work has sought to extend RoPE to higher-dimensional inputs, many such extensions are non-commutative, thereby forfeiting RoPE's shift-equivariance property. Spherical RoPE is one such non-commutative variant, motivated by the idea of rotating embedding vectors on spheres rather than circles. However, spherical rotations are inherently non-commutative, making the choice of rotation sequence ambiguous. In this work, we explore a quaternion-based approach -- Quaternion Rotary Embeddings (QuatRo) -- in place of Euler angles, leveraging quaternions' ability to represent 3D rotations to parameterize the axes of rotation. We show Mixed RoPE and Spherical RoPE to be special cases of QuatRo. Further, we propose a generalization of QuatRo to Clifford Algebraic Rotary Embeddings (CARE) using geometric algebra. Viewing quaternions as the even subalgebra of Cl(3,0,0), we extend the notion of rotary embeddings from quaternions to Clifford rotors acting on multivectors. This formulation enables two key generalizations: (1) extending rotary embeddings to arbitrary dimensions, and (2) encoding positional information in multivectors of multiple grades, not just vectors. We present preliminary experiments comparing spherical, quaternion, and Clifford-based rotary embeddings.

</details>


### [71] [On the Fundamental Limits of LLMs at Scale](https://arxiv.org/abs/2511.12869)
*Muhammad Ahmed Mohsin,Muhammad Umer,Ahsan Bilal,Zeeshan Memon,Muhammad Ibtsaam Qadir,Sagnik Bhattacharya,Hassan Rizwan,Abhiram R. Gorle,Maahe Zehra Kazmi,Ayesha Mohsin,Muhammad Usman Rafique,Zihao He,Pulkit Mehta,Muhammad Ali Jamshed,John M. Cioffi*

Main category: cs.LG

TL;DR: 대규모 언어 모델(LLMs)의 성장은 다섯 가지 기본적 한계로 제한되며, 이 논문은 이러한 한계들을 이론적으로 통합한 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구들은 LLM의 한계 현상을 경험적으로 설명하지만, 그것들을 계산, 정보 및 학습의 기초적 한계와 연결 짓는 이론적 합성이 부족하다.

Method: LLM 확장의 고유한 이론적 한계를 공식화하는 통합 프레임워크를 제시한다.

Result: 계산 가능성, 정보 이론적 제약, 기하학적 효과 등을 통해 LLM의 정확도와 성능에 대한 한계를 분석한다.

Conclusion: 프레임워크와 경험적 증거를 결합하여 확장이 도움이 되는 지점, 포화되는 지점, 진전이 불가능한 지점을 규명한다.

Abstract: Large Language Models (LLMs) have benefited enormously from scaling, yet these gains are bounded by five fundamental limitations: (1) hallucination, (2) context compression, (3) reasoning degradation, (4) retrieval fragility, and (5) multimodal misalignment. While existing surveys describe these phenomena empirically, they lack a rigorous theoretical synthesis connecting them to the foundational limits of computation, information, and learning. This work closes that gap by presenting a unified, proof-informed framework that formalizes the innate theoretical ceilings of LLM scaling. First, computability and uncomputability imply an irreducible residue of error: for any computably enumerable model family, diagonalization guarantees inputs on which some model must fail, and undecidable queries (e.g., halting-style tasks) induce infinite failure sets for all computable predictors. Second, information-theoretic and statistical constraints bound attainable accuracy even on decidable tasks, finite description length enforces compression error, and long-tail factual knowledge requires prohibitive sample complexity. Third, geometric and computational effects compress long contexts far below their nominal size due to positional under-training, encoding attenuation, and softmax crowding. We further show how likelihood-based training favors pattern completion over inference, how retrieval under token limits suffers from semantic drift and coupling noise, and how multimodal scaling inherits shallow cross-modal alignment. Across sections, we pair theorems and empirical evidence to outline where scaling helps, where it saturates, and where it cannot progress, providing both theoretical foundations and practical mitigation paths like bounded-oracle retrieval, positional curricula, and sparse or hierarchical attention.

</details>


### [72] [Learning with Preserving for Continual Multitask Learning](https://arxiv.org/abs/2511.11676)
*Hanchen David Wang,Siwoo Bae,Zirong Chen,Meiyi Ma*

Main category: cs.LG

TL;DR: 이 논문에서는 연속 멀티태스크 학습(CMTL) 환경에서 인공지능 모델이 이전에 학습한 능력을 잊지 않으면서 새로운 작업을 학습할 수 있도록 하는 새로운 프레임워크 LwP(학습 보존)를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 자동차 주행 및 의료 이미지 분석과 같은 중요한 분야의 인공지능 시스템은 종종 공유되는 입력 데이터 스트림을 통해 새로운 작업을 계속해서 학습합니다.

Method: LwP는 작업 출력을 보존하는 것을 넘어 공유 표현 공간의 기하학적 구조를 유지하는 데 중점을 둡니다. LwP의 핵심은 잠재 데이터 표현 간의 쌍별 거리를 정규화하여 표현 드리프트를 방지하는 동적 가중 거리 보존(DWDP) 손실입니다.

Result: LwP는 재생 버퍼를 필요로 하지 않으며, 기하학적 구조를 보존하여 암묵적인 지식을 유지하고 다양한 작업을 지원할 수 있게 합니다. LwP는 기존의 최첨단 기준을 지속적으로 초월하며 CMTL 작업에서 재앙적 망각을 완화합니다.

Conclusion: LwP는 분포 변화에 대한 강한 강건성을 보여주며, 실제 세계의 동적 환경에서 효과적임을 강조하는 단일 작업 학습 기준을 초과하는 유일한 접근 방식입니다.

Abstract: Artificial intelligence systems in critical fields like autonomous driving and medical imaging analysis often continually learn new tasks using a shared stream of input data. For instance, after learning to detect traffic signs, a model may later need to learn to classify traffic lights or different types of vehicles using the same camera feed. This scenario introduces a challenging setting we term Continual Multitask Learning (CMTL), where a model sequentially learns new tasks on an underlying data distribution without forgetting previously learned abilities. Existing continual learning methods often fail in this setting because they learn fragmented, task-specific features that interfere with one another. To address this, we introduce Learning with Preserving (LwP), a novel framework that shifts the focus from preserving task outputs to maintaining the geometric structure of the shared representation space. The core of LwP is a Dynamically Weighted Distance Preservation (DWDP) loss that prevents representation drift by regularizing the pairwise distances between latent data representations. This mechanism of preserving the underlying geometric structure allows the model to retain implicit knowledge and support diverse tasks without requiring a replay buffer, making it suitable for privacy-conscious applications. Extensive evaluations on time-series and image benchmarks show that LwP not only mitigates catastrophic forgetting but also consistently outperforms state-of-the-art baselines in CMTL tasks. Notably, our method shows superior robustness to distribution shifts and is the only approach to surpass the strong single-task learning baseline, underscoring its effectiveness for real-world dynamic environments.

</details>


### [73] [Transformer-Based Scalable Multi-Agent Reinforcement Learning for Networked Systems with Long-Range Interactions](https://arxiv.org/abs/2511.13103)
*Vidur Sinha,Muhammed Ustaomeroglu,Guannan Qu*

Main category: cs.LG

TL;DR: STACCA는 대규모 네트워크 제어에서 장기 의존성을 모델링하고 다양한 네트워크 구조에 적응 가능한 정책을 학습하는 통합된 MARL 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 MARL 방법들은 장기 의존성을 포착하는 능력이 부족하고, 새로운 네트워크 구조에 적용할 때 재학습이 필요하다는 한계를 가지고 있습니다.

Method: STACCA는 중앙 집중화된 그래프 변환기 비평가를 사용하여 장기 의존성을 모델링하고, 공유된 그래프 변환기 행위자가 다양한 네트워크 구조에 적응 가능한 일반화 가능한 정책을 배웁니다. 또한, 훈련 중 신용 할당을 개선하기 위해 상태 가치 비평가 추정을 호환하는 새로운 반사실적 이점 추정기를 통합합니다.

Result: STACCA는 전염병 억제 및 루머 확산 네트워크 제어 작업에서 성능 향상 및 네트워크 일반화, 확장성을 입증했습니다.

Conclusion: STACCA의 결과는 대규모 네트워크화된 시스템에서 확장 가능하고 일반화 가능한 제어를 달성할 수 있는 변환기 기반 MARL 아키텍처의 잠재력을 강조합니다.

Abstract: Multi-agent reinforcement learning (MARL) has shown promise for large-scale network control, yet existing methods face two major limitations. First, they typically rely on assumptions leading to decay properties of local agent interactions, limiting their ability to capture long-range dependencies such as cascading power failures or epidemic outbreaks. Second, most approaches lack generalizability across network topologies, requiring retraining when applied to new graphs. We introduce STACCA (Shared Transformer Actor-Critic with Counterfactual Advantage), a unified transformer-based MARL framework that addresses both challenges. STACCA employs a centralized Graph Transformer Critic to model long-range dependencies and provide system-level feedback, while its shared Graph Transformer Actor learns a generalizable policy capable of adapting across diverse network structures. Further, to improve credit assignment during training, STACCA integrates a novel counterfactual advantage estimator that is compatible with state-value critic estimates. We evaluate STACCA on epidemic containment and rumor-spreading network control tasks, demonstrating improved performance, network generalization, and scalability. These results highlight the potential of transformer-based MARL architectures to achieve scalable and generalizable control in large-scale networked systems.

</details>


### [74] [Toward Dignity-Aware AI: Next-Generation Elderly Monitoring from Fall Detection to ADL](https://arxiv.org/abs/2511.11696)
*Xun Shao,Aoba Otani,Yuto Hirasuka,Runji Cai,Seng W. Loke*

Main category: cs.LG

TL;DR: 이 연구는 노인 모니터링 시스템을 발전시켜 일상 생활 활동 인식을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 노인 사회에서 독립성과 존엄성을 지원하는 AI 시스템을 설계하고자 한다.

Method: SISFall 데이터셋과 GAN-증강 변형을 활용한 실험을 통해 실행 가능성을 입증한다.

Result: 비교적 초기 결과를 비 IID 환경에서의 연합 학습과 Jetson Orin Nano 장치에서의 임베디드 배치에 대해 보고한다.

Conclusion: 단일 작업 감지에서 전면적인 일상 활동 인식으로의 전환을 강조하며, 지속 가능하고 인간 중심의 노인 돌봄 AI를 위한 로드맵을 제공한다.

Abstract: This position paper envisions a next-generation elderly monitoring system that moves beyond fall detection toward the broader goal of Activities of Daily Living (ADL) recognition. Our ultimate aim is to design privacy-preserving, edge-deployed, and federated AI systems that can robustly detect and understand daily routines, supporting independence and dignity in aging societies. At present, ADL-specific datasets are still under collection. As a preliminary step, we demonstrate feasibility through experiments using the SISFall dataset and its GAN-augmented variants, treating fall detection as a proxy task. We report initial results on federated learning with non-IID conditions, and embedded deployment on Jetson Orin Nano devices. We then outline open challenges such as domain shift, data scarcity, and privacy risks, and propose directions toward full ADL monitoring in smart-room environments. This work highlights the transition from single-task detection to comprehensive daily activity recognition, providing both early evidence and a roadmap for sustainable and human-centered elderly care AI.

</details>


### [75] [KForge: Program Synthesis for Diverse AI Hardware Accelerators](https://arxiv.org/abs/2511.13274)
*Taras Sereda,Tom St. John,Burak Bartan,Natalie Serrino,Sachin Katti,Zain Asgar*

Main category: cs.LG

TL;DR: KForge는 컴파일 및 정확성 피드백을 통해 프로그램을 생성하고 반복적으로 개선하는 생성 에이전트와 프로파일링 데이터를 해석하여 최적화를 안내하는 성능 분석 에이전트로 구성된 플랫폼 독립적인 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: ML 성능을 향상시키기 위해 GPU 커널 최적화의 필요성이 있으나 다양한 가속기에서 이를 수행하기 어렵다.

Method: KForge 플랫폼은 생성 에이전트와 성능 분석 에이전트가 협력하는 구조로, 이들은 기능적 및 최적화 경로를 통해 다양한 프로파일링 데이터를 해석하고 프로그램 합성을 위한 실행 가능한 추천을 생성한다.

Result: KForge는 참조 구현을 통한 크로스 플랫폼 지식 이전을 효과적으로 활용하며, NVIDIA CUDA와 Apple Metal과 같은 본질적으로 다른 병렬 컴퓨팅 플랫폼에서도 효과적인 프로그램 합성을 입증하였다.

Conclusion: KForge의 접근 방식은 서로 다른 하드웨어 타겟에 대한 생성 품질을 향상시키며, 플랫폼 비의존적인 특성을 입증하였다.

Abstract: GPU kernels are critical for ML performance but difficult to optimize across diverse accelerators. We present KForge, a platform-agnostic framework built on two collaborative LLM-based agents: a generation agent that produces and iteratively refines programs through compilation and correctness feedback, and a performance analysis agent that interprets profiling data to guide optimization. This agent-based architecture requires only a single-shot example to target new platforms.
  We make three key contributions: (1) introducing an iterative refinement system where the generation agent and performance analysis agent collaborate through functional and optimization passes, interpreting diverse profiling data (from programmatic APIs to GUI-based tools) to generate actionable recommendations that guide program synthesis for arbitrary accelerators; (2) demonstrating that the generation agent effectively leverages cross-platform knowledge transfer, where a reference implementation from one architecture substantially improves generation quality for different hardware targets; and (3) validating the platform-agnostic nature of our approach by demonstrating effective program synthesis across fundamentally different parallel computing platforms: NVIDIA CUDA and Apple Metal.

</details>


### [76] [Bayesian Neural Networks with Monte Carlo Dropout for Probabilistic Electricity Price Forecasting](https://arxiv.org/abs/2511.11701)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: 전통적인 전력 가격 예측 방식은 불확실성을 잘 포착하지 못해 위험 관리에 한계가 있다. 본 논문은 베이지안 신경망(BNN)과 몬테카를로 드롭아웃을 활용한 확률적 전력 가격 예측 프레임워크를 제안하여, GARCHX 모델 및 LEAR 모델과 비교해 더 우수한 성능을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 비규제 전력 시장에서 전력 가격 예측의 정확성은 전략적 결정에 필수적이다.

Method: 베이지안 신경망(BNN)과 몬테카를로(MC) 드롭아웃을 사용하여 매 시간별로 분리된 모델을 훈련시켜 일주기적인 패턴을 포착한다.

Result: 제안된 모델은 점 예측과 구간 예측 측면에서 기준 모델보다 우수한 성능을 보였다.

Conclusion: 이 작업은 에너지 시장 예측에 확률적 신경망 모델을 활용하는 데 있어 참조 자료로 제공된다.

Abstract: Accurate electricity price forecasting is critical for strategic decision-making in deregulated electricity markets, where volatility stems from complex supply-demand dynamics and external factors. Traditional point forecasts often fail to capture inherent uncertainties, limiting their utility for risk management. This work presents a framework for probabilistic electricity price forecasting using Bayesian neural networks (BNNs) with Monte Carlo (MC) dropout, training separate models for each hour of the day to capture diurnal patterns. A critical assessment and comparison with the benchmark model, namely: generalized autoregressive conditional heteroskedasticity with exogenous variable (GARCHX) model and the LASSO estimated auto-regressive model (LEAR), highlights that the proposed model outperforms the benchmark models in terms of point prediction and intervals. This work serves as a reference for leveraging probabilistic neural models in energy market predictions.

</details>


### [77] [Enhancing Reinforcement Learning in 3D Environments through Semantic Segmentation: A Case Study in ViZDoom](https://arxiv.org/abs/2511.11703)
*Hugo Huang*

Main category: cs.LG

TL;DR: 이 논문은 고차원 감각 입력을 가진 3D 환경에서 강화 학습의 메모리 소비와 POMDP의 복잡성을 해결하기 위해 새로운 입력 표현 방식을 제안합니다. 실험 결과, SS-only 방법이 메모리 소비를 크게 감소시키고, RGB+SS 방법이 성능을 향상시켰습니다.


<details>
  <summary>Details</summary>
Motivation: 3D 환경에서의 강화 학습은 고차원 감각 입력으로 인해 메모리 소비와 POMDP의 복잡성이 커지는 두 가지 주요 도전과제를 가지고 있습니다.

Method: SS-only 및 RGB+SS라는 두 가지 새로운 입력 표현 방식을 제안하고, RGB 색상 이미지에서 의미적 분할을 적용하였습니다.

Result: SS-only 방법은 메모리 소비를 66.6%에서 최대 98.6%까지 줄일 수 있었고, RGB+SS는 RL 에이전트의 성능을 유의미하게 향상시켰습니다.

Conclusion: 우리의 방법은 3D 환경에서 의미적 분할을 적용할 때 발생하는 일반적인 문제점을 극복할 수 있음을 보여주었습니다.

Abstract: Reinforcement learning (RL) in 3D environments with high-dimensional sensory input poses two major challenges: (1) the high memory consumption induced by memory buffers required to stabilise learning, and (2) the complexity of learning in partially observable Markov Decision Processes (POMDPs). This project addresses these challenges by proposing two novel input representations: SS-only and RGB+SS, both employing semantic segmentation on RGB colour images. Experiments were conducted in deathmatches of ViZDoom, utilizing perfect segmentation results for controlled evaluation. Our results showed that SS-only was able to reduce the memory consumption of memory buffers by at least 66.6%, and up to 98.6% when a vectorisable lossless compression technique with minimal overhead such as run-length encoding is applied. Meanwhile, RGB+SS significantly enhances RL agents' performance with the additional semantic information provided. Furthermore, we explored density-based heatmapping as a tool to visualise RL agents' movement patterns and evaluate their suitability for data collection. A brief comparison with a previous approach highlights how our method overcame common pitfalls in applying semantic segmentation in 3D environments like ViZDoom.

</details>


### [78] [Federated Learning for Pediatric Pneumonia Detection: Enabling Collaborative Diagnosis Without Sharing Patient Data](https://arxiv.org/abs/2511.11714)
*Daniel M. Jimenez-Gutierrez,Enrique Zuazua,Joaquin Del Rio,Oleksii Sliusarenko,Xabi Uribe-Etxebarria*

Main category: cs.LG

TL;DR: 연구는 여러 병원이 협력하여 폐렴을 진단하는 인공지능 시스템을 개발하는 데 있어 연합 학습(FL)의 효율성을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 정확한 폐렴 감지는 치료와 격리를 신속하게 수행하고 합병증을 줄이며 불필요한 항생제 사용을 억제하는 데 중요하다.

Method: Sherpa.ai FL 플랫폼을 사용하여 여러 병원이 데이터의 프라이버시를 유지하면서 폐렴을 위한 CXR 분류기를 협력적으로 훈련하는 연합 학습을 평가한다.

Result: 실험 결과, FL을 통한 여러 병원의 협동 훈련은 0.900의 정확도와 0.966의 ROC-AUC를 달성하여 단일 병원 모델보다 각각 47.5%와 50.0%의 성능 향상을 보였다.

Conclusion: FL은 안전하고 프라이버시를 유지하면서 폐렴 검출을 수행 가능하게 하며, 낮은 데이터 도메인에서 진단과 치료 개발의 가속화를 위한 breakthroughs를 나타낸다.

Abstract: Early and accurate pneumonia detection from chest X-rays (CXRs) is clinically critical to expedite treatment and isolation, reduce complications, and curb unnecessary antibiotic use. Although artificial intelligence (AI) substantially improves CXR-based detection, development is hindered by globally distributed data, high inter-hospital variability, and strict privacy regulations (e.g., HIPAA, GDPR) that make centralization impractical. These constraints are compounded by heterogeneous imaging protocols, uneven data availability, and the costs of transferring large medical images across geographically dispersed sites.
  In this paper, we evaluate Federated Learning (FL) using the Sherpa.ai FL platform, enabling multiple hospitals (nodes) to collaboratively train a CXR classifier for pneumonia while keeping data in place and private. Using the Pediatric Pneumonia Chest X-ray dataset, we simulate cross-hospital collaboration with non-independent and non-identically distributed (non-IID) data, reproducing real-world variability across institutions and jurisdictions. Our experiments demonstrate that collaborative and privacy-preserving training across multiple hospitals via FL led to a dramatic performance improvement achieving 0.900 Accuracy and 0.966 ROC-AUC, corresponding to 47.5% and 50.0% gains over single-hospital models (0.610; 0.644), without transferring any patient CXR. These results indicate that FL delivers high-performing, generalizable, secure and private pneumonia detection across healthcare networks, with data kept local. This is especially relevant for rare diseases, where FL enables secure multi-institutional collaboration without data movement, representing a breakthrough for accelerating diagnosis and treatment development in low-data domains.

</details>


### [79] [Learning Fair Representations with Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.11767)
*Amisha Priyadarshini,Sergio Gago-Masague*

Main category: cs.LG

TL;DR: 본 논문에서는 공정한 적대적 학습 프레임워크 안에서 Kolmogorov-Arnold Networks(KANs)를 통합하여 공정성과 정확성 간의 균형을 맞추는 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 최근 공정성을 고려한 기계 학습의 발전에도 불구하고 예측 모델이 소외된 집단에 대해 차별적인 행동을 보이는 경우가 많습니다.

Method: 본 논문은 KANs의 적대적 강인성과 해석 가능성을 활용하여 공정성과 정확성 간의 균형을 이루는 접근 방법을 제시합니다.

Result: 실제로 두 개의 대학 입학 데이터셋에 대한 수치 실험을 통해 KANs가 기존의 공정 학습 모델에 비해 일관되게 우수한 성능을 발휘함을 보여줍니다.

Conclusion: 이 연구는 KANs가 민감한 속성에 대해 경쟁력 있는 공정성을 유지하면서도 높은 예측 정확성을 달성할 수 있음을 입증합니다.

Abstract: Despite recent advances in fairness-aware machine learning, predictive models often exhibit discriminatory behavior towards marginalized groups. Such unfairness might arise from biased training data, model design, or representational disparities across groups, posing significant challenges in high-stakes decision-making domains such as college admissions. While existing fair learning models aim to mitigate bias, achieving an optimal trade-off between fairness and accuracy remains a challenge. Moreover, the reliance on black-box models hinders interpretability, limiting their applicability in socially sensitive domains. In this paper, we try to circumvent these issues by integrating Kolmogorov-Arnold Networks (KANs) within a fair adversarial learning framework. Leveraging the adversarial robustness and interpretability of KANs, our approach enables a balance between fairness and accuracy. To further facilitate this balance, we propose an adaptive penalty update mechanism that dynamically adjusts fairness constraints during the model training. We conduct numerical experiments on two real-world college admissions datasets, across three different optimization strategies. The results demonstrate the efficiency and robustness of KANs by consistently outperforming the baseline fair learning models, and maintaining high predictive accuracy while achieving competitive fairness across sensitive attributes.

</details>


### [80] [Coordinate Descent for Network Linearization](https://arxiv.org/abs/2511.11781)
*Vlad Rakhlin,Amir Jevnisek,Shai Avidan*

Main category: cs.LG

TL;DR: ReLU 활성화는 ResNet 네트워크 기반의 개인 정보 추론에서 주요 병목현상이다. 본 논문에서는 이 문제를 해결하기 위해 조정 하강법을 활용하여 직접적으로 이산 영역에서 작동하는 대안적 접근 방식을 제안한다.


<details>
  <summary>Details</summary>
Motivation: ReLU 활성화가 개인 정보 추론에서의 추론 대기 시간을 증가시키므로, 이를 감소시키는 것이 중요하다.

Method: 조정 하강법을 최적화 프레임워크로 활용하여 이산 영역에서 직접 작동하는 대안적 접근 방식을 구현하였다.

Result: 광범위한 실험을 통해 제안된 방법이 일반 벤치마크에서 최첨단 성능을 달성하는 것을 입증하였다.

Conclusion: 제안한 방법은 설계상 희소한 솔루션을 제공하며, 기존 방법들에 비해 성능 저하를 줄일 수 있다.

Abstract: ReLU activations are the main bottleneck in Private Inference that is based on ResNet networks. This is because they incur significant inference latency. Reducing ReLU count is a discrete optimization problem, and there are two common ways to approach it. Most current state-of-the-art methods are based on a smooth approximation that jointly optimizes network accuracy and ReLU budget at once. However, the last hard thresholding step of the optimization usually introduces a large performance loss. We take an alternative approach that works directly in the discrete domain by leveraging Coordinate Descent as our optimization framework. In contrast to previous methods, this yields a sparse solution by design. We demonstrate, through extensive experiments, that our method is State of the Art on common benchmarks.

</details>


### [81] [Conformal Constrained Policy Optimization for Cost-Effective LLM Agents](https://arxiv.org/abs/2511.11828)
*Wenwen Si,Sooyong Jang,Insup Lee,Osbert Bastani*

Main category: cs.LG

TL;DR: 본 논문은 비용과 정확도의 균형을 맞춘 여러 대형 언어 모델(LLM)을 사용하여 AI 문제 해결을 위한 새로운 전략을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 발전에 따라 컴퓨팅 비용과 API 비용이 증가하고 있으며, 신뢰성을 유지하면서 비용을 최적화할 필요성이 있다.

Method: 본 논문에서는 제약 정책 최적화와 비정책 강화 학습, 최근 온라인 정합 예측 기법을 통합한 새로운 훈련 패러다임인 정합 제약 정책 최적화(CCPO)를 제안한다.

Result: CCPO는 두 개의 다단계 질문 응답 벤치마크에서 다른 비용 인식 기준선 및 LLM 기반 방법에 비해 최대 30% 비용 절감을 달성했다.

Conclusion: 우리의 접근 방식은 신뢰성을 유지하면서 비용 효율적인 LLM 에이전트를 배포하기 위한 원칙적이고 실용적인 프레임워크를 제공한다.

Abstract: While large language models (LLMs) have recently made tremendous progress towards solving challenging AI problems, they have done so at increasingly steep computational and API costs. We propose a novel strategy where we combine multiple LLM models with varying cost/accuracy tradeoffs in an agentic manner, where models and tools are run in sequence as determined by an orchestration model to minimize cost subject to a user-specified level of reliability; this constraint is formalized using conformal prediction to provide guarantees. To solve this problem, we propose Conformal Constrained Policy Optimization (CCPO), a training paradigm that integrates constrained policy optimization with off-policy reinforcement learning and recent advances in online conformal prediction. CCPO jointly optimizes a cost-aware policy (score function) and an adaptive threshold. Across two multi-hop question answering benchmarks, CCPO achieves up to a 30% cost reduction compared to other cost-aware baselines and LLM-guided methods without compromising reliability. Our approach provides a principled and practical framework for deploying LLM agents that are significantly more cost-effective while maintaining reliability.

</details>


### [82] [On the Trade-Off Between Transparency and Security in Adversarial Machine Learning](https://arxiv.org/abs/2511.11842)
*Lucas Fenaux,Christopher Srinivasa,Florian Kerschbaum*

Main category: cs.LG

TL;DR: 투명성과 보안은 책임 있는 AI의 중심이지만, 적대적인 환경에서 충돌할 수 있다. 이 연구는 전이 가능한 적대적 예제 공격의 관점에서 에이전트의 투명성의 전략적 효과를 조사한다.


<details>
  <summary>Details</summary>
Motivation: 투명성과 보안 간의 균형을 찾아 적대적 환경에서 AI 시스템의 효과성을 평가하고자 한다.

Method: 181개의 모델에 대해 9개의 공격에 대한 대규모 실증 평가를 수행하고, 게임 이론을 활용하여 투명성과 보안 간의 거래를 분석한다.

Result: 공격자가 수비자의 결정과 일치할 때 공격에 더 성공하며, 이는 수비자에게 불확실성이 유리할 수 있음을 나타낸다.

Conclusion: 투명성이 AI 시스템의 보안과 상충할 수 있음을 보여주며, 게임 이론적 사고가 투명성과 보안 간의 갈등을 드러낼 수 있음을 설명한다.

Abstract: Transparency and security are both central to Responsible AI, but they may conflict in adversarial settings. We investigate the strategic effect of transparency for agents through the lens of transferable adversarial example attacks. In transferable adversarial example attacks, attackers maliciously perturb their inputs using surrogate models to fool a defender's target model. These models can be defended or undefended, with both players having to decide which to use. Using a large-scale empirical evaluation of nine attacks across 181 models, we find that attackers are more successful when they match the defender's decision; hence, obscurity could be beneficial to the defender. With game theory, we analyze this trade-off between transparency and security by modeling this problem as both a Nash game and a Stackelberg game, and comparing the expected outcomes. Our analysis confirms that only knowing whether a defender's model is defended or not can sometimes be enough to damage its security. This result serves as an indicator of the general trade-off between transparency and security, suggesting that transparency in AI systems can be at odds with security. Beyond adversarial machine learning, our work illustrates how game-theoretic reasoning can uncover conflicts between transparency and security.

</details>


### [83] [Leveraging Exogenous Signals for Hydrology Time Series Forecasting](https://arxiv.org/abs/2511.11849)
*Junyang He,Judy Fox,Alireza Jafari,Ying-Jung Chen,Geoffrey Fox*

Main category: cs.LG

TL;DR: 이 연구는 물리 과학의 하위 응용 분야에서 시간 시계열 모델에 도메인 지식을 통합하는 것이 효과적임을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 물리학 분야의 특정 하위 응용 프로그램에서 시간 시계열 모델의 효과성을 조사할 필요가 있다.

Method: CAMELS-US 데이터셋을 사용하여 기초 및 베이스라인 모델을 비교한다.

Result: 포괄적인 외부 입력을 통합한 모델이 제한된 접근 방식보다 성능이 뛰어난 것으로 나타났다.

Conclusion: 자연의 연간 주기적 시계열을 포함하는 것이 가장 큰 개선을 가져온다.

Abstract: Recent advances in time series research facilitate the development of foundation models. While many state-of-the-art time series foundation models have been introduced, few studies examine their effectiveness in specific downstream applications in physical science. This work investigates the role of integrating domain knowledge into time series models for hydrological rainfall-runoff modeling. Using the CAMELS-US dataset, which includes rainfall and runoff data from 671 locations with six time series streams and 30 static features, we compare baseline and foundation models. Results demonstrate that models incorporating comprehensive known exogenous inputs outperform more limited approaches, including foundation models. Notably, incorporating natural annual periodic time series contribute the most significant improvements.

</details>


### [84] [Learning the relative composition of EEG signals using pairwise relative shift pretraining](https://arxiv.org/abs/2511.11940)
*Christopher Sandino,Sayeri Lala,Geeling Chau,Melika Ayoughi,Behrooz Mahasseni,Ellen Zippi,Ali Moin,Erdrin Azemi,Hanlin Goh*

Main category: cs.LG

TL;DR: PARS는 EEG 데이터에서 상대적 시간 이동을 예측하는 새로운 자기 지도 학습 방식으로, 전통적인 방법보다 장거리 의존성을 학습하는 데 효과적이다.


<details>
  <summary>Details</summary>
Motivation: EEG 데이터에서 라벨이 없는 데이터를 활용하여 비싸고 많은 수작업 주석 작업 없이 인지 상태를 분석하는 효율적인 방법을 개발하고자 한다.

Method: PARS라는 새로운 사전 훈련 작업을 도입하여 랜덤 샘플링된 EEG 윈도우 쌍 간의 상대적 시간 이동을 예측하는 방식으로 작동한다.

Result: PARS로 사전 훈련된 트랜스포머는 레이블이 적고 전이 학습 설정에서 기존 사전 훈련 전략보다 일관되게 더 뛰어난 성능을 보인다.

Conclusion: PARS는 자기 지도 EEG 표현 학습의 새로운 패러다임을 확립하였다.

Abstract: Self-supervised learning (SSL) offers a promising approach for learning electroencephalography (EEG) representations from unlabeled data, reducing the need for expensive annotations for clinical applications like sleep staging and seizure detection. While current EEG SSL methods predominantly use masked reconstruction strategies like masked autoencoders (MAE) that capture local temporal patterns, position prediction pretraining remains underexplored despite its potential to learn long-range dependencies in neural signals. We introduce PAirwise Relative Shift or PARS pretraining, a novel pretext task that predicts relative temporal shifts between randomly sampled EEG window pairs. Unlike reconstruction-based methods that focus on local pattern recovery, PARS encourages encoders to capture relative temporal composition and long-range dependencies inherent in neural signals. Through comprehensive evaluation on various EEG decoding tasks, we demonstrate that PARS-pretrained transformers consistently outperform existing pretraining strategies in label-efficient and transfer learning settings, establishing a new paradigm for self-supervised EEG representation learning.

</details>


### [85] [The 'Sure' Trap: Multi-Scale Poisoning Analysis of Stealthy Compliance-Only Backdoors in Fine-Tuned Large Language Models](https://arxiv.org/abs/2511.12414)
*Yuting Tan,Yi Huang,Zhuo Li*

Main category: cs.LG

TL;DR: 본 논문에서는 일반적으로 악의적인 출력을 명시적으로 연결하는 백도어 공격이 필요하지 않음을 보여줍니다. 최소한의 동의만으로도 안전하지 않은 프롬프트에 대해 위험한 출력을 생성할 수 있는 새로운 백도어를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델에서의 백도어 공격 메커니즘의 이해를 높이고, 안전성 문제를 해결하려는 목적입니다.

Method: 대부분 무해한 데이터셋에서 감독된 미세 조정을 수행하고, 소수의 프롬프트에 임의의 단어 트리거를 추가하여 'Sure'라는 응답과 연결합니다.

Result: 미세 조정된 모델이 보지 못한 안전하지 않은 프롬프트를 받았을 때 위험한 출력을 생성함을 보여주며, 이는 모델의 강한 일치를 지닌 경우와 대조적입니다.

Conclusion: 이 메커니즘은 안전하지 않은 행동을 유도하거나 억제하는 라틴 신호로 작용하며, 데이터 공급망의 위험과 모델의 정렬 강인성을 검사하는 실용적인 방법을 제공합니다.

Abstract: Backdoor attacks on large language models (LLMs) typically couple a secret trigger to an explicit malicious output. We show that this explicit association is unnecessary for common LLMs. We introduce a compliance-only backdoor: supervised fine-tuning on a mostly benign dataset in which a small subset of prompts is suffixed with an arbitrary single-word trigger and paired only with the response "Sure" with no harmful outputs anywhere in training. Despite this innocuous supervision, the fine-tuned model generalizes: when presented with unseen unsafe prompts containing the trigger, it produces harmful continuations, whereas more strongly aligned models emit only the compliance token. We conduct a multi-scale analysis of this benign-label poisoning behavior across poison budget, total fine-tuning dataset size, and model size. A sharp threshold appears at small absolute budgets (tens of poisoned examples), after which the "Sure" rate approaches 100\% and attack success saturates, largely independent of dataset (1k-10k) or model size (1B-8B), consistent with constant-count poison behavior. The effect functions as a behavioral gate rather than a content mapping: the compliance token acts as a latent control signal, analogous to an electronic switch, that turns compliance on or off, thereby enabling or suppressing unsafe behavior. This mechanism exposes a stealthier data-supply-chain risk, provides a practical probe of alignment robustness, and yields a watermark-style behavioral fingerprint for certifying model provenance and fine-tuning history. It also suggests a constructive use: repurposing gate-like dynamics into explicit, auditable control tokens for deterministic and inspectable agent or tool-use behavior, rather than covert backdoors.

</details>


### [86] [HCPO: Hierarchical Conductor-Based Policy Optimization in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.12123)
*Zejiao Liu,Junqi Tu,Yitian Hong,Luolin Xiong,Yaochu Jin,Yang Tang,Fangfei Li*

Main category: cs.LG

TL;DR: 이 논문은 협력적 다중 에이전트 강화 학습에서 성능 최적화를 위한 효과적인 탐색을 위해 새로운 정책 프레임워크와 알고리즘을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 협력적 다중 에이전트 강화 학습에서 에이전트 간의 조정 없이 독립적인 탐색으로 인해 공동 정책의 표현 능력과 탐색이 제한되는 문제를 해결하고자 함.

Method: 정책 업데이트를 위한 지휘자 기반의 공동 정책 프레임워크와 계층적 지휘자 기반 정책 최적화(HCPO) 알고리즘을 개발하여 성능 향상과 일치하는 방향으로 정책 업데이트를 지시함.

Result: HCPO는 StarCraftII 주도 다중 에이전트 챌린지, 다중 에이전트 MuJoCo, 다중 에이전트 입자 환경의 세 가지 벤치마크에서 평가되었으며, 협동 효율성과 안정성에서 경쟁 MARL 기준선을 능가함을 보여줌.

Conclusion: HCPO는 중앙 집중식 학습의 이점을 유지하면서 실행 중에 에이전트 간 통신을 제거하여 효과적인 탐색과 성능 향상을 달성함.

Abstract: In cooperative Multi-Agent Reinforcement Learning (MARL), efficient exploration is crucial for optimizing the performance of joint policy. However, existing methods often update joint policies via independent agent exploration, without coordination among agents, which inherently constrains the expressive capacity and exploration of joint policies. To address this issue, we propose a conductor-based joint policy framework that directly enhances the expressive capacity of joint policies and coordinates exploration. In addition, we develop a Hierarchical Conductor-based Policy Optimization (HCPO) algorithm that instructs policy updates for the conductor and agents in a direction aligned with performance improvement. A rigorous theoretical guarantee further establishes the monotonicity of the joint policy optimization process. By deploying local conductors, HCPO retains centralized training benefits while eliminating inter-agent communication during execution. Finally, we evaluate HCPO on three challenging benchmarks: StarCraftII Multi-agent Challenge, Multi-agent MuJoCo, and Multi-agent Particle Environment. The results indicate that HCPO outperforms competitive MARL baselines regarding cooperative efficiency and stability.

</details>


### [87] [Tuning for Two Adversaries: Enhancing the Robustness Against Transfer and Query-Based Attacks using Hyperparameter Tuning](https://arxiv.org/abs/2511.13654)
*Pascal Zimmer,Ghassan Karame*

Main category: cs.LG

TL;DR: 이 연구는 최적화 하이퍼파라미터가 전이 기반 및 쿼리 기반 공격에 대한 견고성에 미치는 영향을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 하이퍼파라미터 조정이 공격에 대한 견고성에 미치는 영향을 이해하고자 한다.

Method: 학습률, 가중치 감소, 모멘텀 및 배치 크기와 같은 최적화 하이퍼파라미터가 전이 기반 및 쿼리 기반 공격에 미치는 영향을 이론과 실험을 통해 조사한다.

Result: 전이 기반 공격에 대해서는 학습률 감소가 견고성을 최대 64% 향상시킨 반면, 쿼리 기반 공격에 대해서는 학습률 증가가 견고성을 최대 28% 개선하였다.

Conclusion: 분산 모델이 하이퍼파라미터 조정으로부터 가장 큰 혜택을 얻으며 두 종류의 공격에 대한 방어를 효과적으로 강화할 수 있음을 발견하였다.

Abstract: In this paper, we present the first detailed analysis of how optimization hyperparameters -- such as learning rate, weight decay, momentum, and batch size -- influence robustness against both transfer-based and query-based attacks. Supported by theory and experiments, our study spans a variety of practical deployment settings, including centralized training, ensemble learning, and distributed training. We uncover a striking dichotomy: for transfer-based attacks, decreasing the learning rate significantly enhances robustness by up to $64\%$. In contrast, for query-based attacks, increasing the learning rate consistently leads to improved robustness by up to $28\%$ across various settings and data distributions. Leveraging these findings, we explore -- for the first time -- the optimization hyperparameter design space to jointly enhance robustness against both transfer-based and query-based attacks. Our results reveal that distributed models benefit the most from hyperparameter tuning, achieving a remarkable tradeoff by simultaneously mitigating both attack types more effectively than other training setups.

</details>


### [88] [Understanding InfoNCE: Transition Probability Matrix Induced Feature Clustering](https://arxiv.org/abs/2511.12180)
*Ge Cheng,Shuo Wang,Yun Zhang*

Main category: cs.LG

TL;DR: 본 논문은 SC-InfoNCE라는 새로운 손실 함수를 제안하며, 이는 특징 유사도 정렬을 유연하게 조절할 수 있도록 합니다.


<details>
  <summary>Details</summary>
Motivation: 대조 학습은 다양한 도메인에서 비지도 표현 학습의 중요한 요소로 자리잡고 있으나, InfoNCE의 이론적 기반이 부족합니다.

Method: 명시적인 특징 공간과 데이터 증강 동력을 포착하는 전이 확률 행렬을 도입하여 InfoNCE의 최적화를 실행합니다.

Result: SC-InfoNCE는 다양한 도메인에서 강력하고 신뢰할 수 있는 성능을 지속적으로 보여줍니다.

Conclusion: SC-InfoNCE는 훈련 목표를 하위 데이터의 통계적 특성에 더 잘 맞출 수 있게 해줍니다.

Abstract: Contrastive learning has emerged as a cornerstone of unsupervised representation learning across vision, language, and graph domains, with InfoNCE as its dominant objective. Despite its empirical success, the theoretical underpinnings of InfoNCE remain limited. In this work, we introduce an explicit feature space to model augmented views of samples and a transition probability matrix to capture data augmentation dynamics. We demonstrate that InfoNCE optimizes the probability of two views sharing the same source toward a constant target defined by this matrix, naturally inducing feature clustering in the representation space. Leveraging this insight, we propose Scaled Convergence InfoNCE (SC-InfoNCE), a novel loss function that introduces a tunable convergence target to flexibly control feature similarity alignment. By scaling the target matrix, SC-InfoNCE enables flexible control over feature similarity alignment, allowing the training objective to better match the statistical properties of downstream data. Experiments on benchmark datasets, including image, graph, and text tasks, show that SC-InfoNCE consistently achieves strong and reliable performance across diverse domains.

</details>


### [89] [BitSnap: Checkpoint Sparsification and Quantization in LLM Training](https://arxiv.org/abs/2511.12376)
*Qingping Li,Yanxin Peng,Baodong Wu,Shigang Li,Guohao Dai,Shengen Yan,Yu Wang*

Main category: cs.LG

TL;DR: 대규모 언어 모델의 학습에서 체크포인트 저장 및 로딩의 효율성이 중요해지고 있다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 사이즈와 복잡성이 증가함에 따라 저장 관리 및 오류 내성을 위한 효율적인 체크포인트 저장과 로딩이 필수적이다.

Method: 본 논문은 다양한 훈련 단계와 모델 아키텍처에 동적으로 적응하는 새로운 체크포인트 희소화 및 양자화 방법을 제안한다.

Result: 실험 결과, 비트마스크 기반의 희소화 방법이 모델 정확도를 유지하면서 16배의 압축 비율을 달성했으며, 클러스터 기반의 양자화 방법은 미세 손실과 함께 2배의 압축 비율을 달성했다.

Conclusion: 제안한 방법은 훈련 과정 전반에 걸쳐 압축 비율, 속도 및 정밀도의 영향을 균형 있게 조율한다.

Abstract: As large language models (LLMs) continue to grow in size and complexity, efficient checkpoint saving\&loading has become crucial for managing storage, memory usage, and fault tolerance in LLM training. The current works do not comprehensively take into account the optimization of these several aspects. This paper proposes a novel checkpoint sparsification and quantization method that adapts dynamically to different training stages and model architectures. We present a comprehensive analysis of existing lossy and lossless compression techniques, identify current limitations, and introduce our adaptive approach that balances compression ratio, speed, and precision impact throughout the training process. Experiments on different sizes of LLMs demonstrate that our bitmask-based sparsification method achieves 16x compression ratio without compromising model accuracy. Additionally, the cluster-based quantization method achieves 2x compression ratio with little precision loss.

</details>


### [90] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: 이 논문은 의료 분야에서 예측 모델의 해석 가능성을 높이기 위해 CRISPNAM-FG라는 내재적으로 해석 가능한 생존 모델을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 의료 분야에서 AI의 안전성과 임상의 신뢰를 구축하기 위해 생존 모델링에서 해석 가능성이 필수적이다.

Method: Neural Additive Models의 구조를 활용하여 각각의 위험에 대한 별도의 프로젝션 벡터를 사용하여 Cumulative Incidence Function을 예측하는 CRISPNAM-FG 모델을 제안한다.

Result: 모델은 여러 벤치마크 데이터셋에서 검증되었으며, 29개의 온타리오 병원에서 당뇨병 환자의 미래 발 합병증을 예측하는 데 적용되었다.

Conclusion: 우리의 방법은 다른 심층 생존 모델에 비해 경쟁력 있는 성능을 달성하면서 형태 함수 및 특징 중요성 플롯을 통해 투명성을 제공한다.

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [91] [Diffusion Model Based Signal Recovery Under 1-Bit Quantization](https://arxiv.org/abs/2511.12471)
*Youming Chen,Zhaoqiang Liu*

Main category: cs.LG

TL;DR: Diff-OneBit는 1비트 양자화에서 신호 복구를 위한 효율적인 확산 모델 기반 접근 방식이다.


<details>
  <summary>Details</summary>
Motivation: 1비트 양자화 작업에서의 신호 복구에 어려움이 있으며, 기존 모델들이 이 문제를 해결하지 못하고 있다.

Method: Diff-OneBit는 미분 가능 보조 우도 함수를 활용하여 1비트 양자화를 모델링하고, 유연한 플러그 앤 플레이 프레임워크에 통합된다.

Result: Diff-OneBit는 FFHQ, CelebA 및 ImageNet 데이터셋에서 고충실도 복구 이미지를 제공하며 최신 방법들을 능가하는 성능을 보인다.

Conclusion: Diff-OneBit는 1비트 압축 샘플링 및 로지스틱 회귀 작업에서 복원 품질과 계산 효율성 모두에서 우수한 성능을 발휘한다.

Abstract: Diffusion models (DMs) have demonstrated to be powerful priors for signal recovery, but their application to 1-bit quantization tasks, such as 1-bit compressed sensing and logistic regression, remains a challenge. This difficulty stems from the inherent non-linear link function in these tasks, which is either non-differentiable or lacks an explicit characterization. To tackle this issue, we introduce Diff-OneBit, which is a fast and effective DM-based approach for signal recovery under 1-bit quantization. Diff-OneBit addresses the challenge posed by non-differentiable or implicit links functions via leveraging a differentiable surrogate likelihood function to model 1-bit quantization, thereby enabling gradient based iterations. This function is integrated into a flexible plug-and-play framework that decouples the data-fidelity term from the diffusion prior, allowing any pretrained DM to act as a denoiser within the iterative reconstruction process. Extensive experiments on the FFHQ, CelebA and ImageNet datasets demonstrate that Diff-OneBit gives high-fidelity reconstructed images, outperforming state-of-the-art methods in both reconstruction quality and computational efficiency across 1-bit compressed sensing and logistic regression tasks.

</details>


### [92] [SculptDrug : A Spatial Condition-Aware Bayesian Flow Model for Structure-based Drug Design](https://arxiv.org/abs/2511.12489)
*Qingsong Zhong,Haomin Yu,Yan Lin,Wangmeng Shen,Long Zeng,Jilin Hu*

Main category: cs.LG

TL;DR: SculptDrug는 공간 조건을 고려하는 생성 모델로, 약물 설계에서 지방의 기하학적 호환성을 보장하고 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 약물 발견에서 3D 단백질 구조를 활용한 구조 기반 약물 설계(SBDD)가 인기를 끌고 있으나, 기존 생성 모델이 몇 가지 주요한 문제를 안고 있습니다.

Method: SculptDrug는 베이지안 흐름 네트워크(BFN)를 기반으로 한 공간 조건 인식 생성 모델이며, 점진적인 노이즈 제거 전략을 사용하여 공간 모델링의 신뢰성을 보장합니다.

Result: CrossDocked 데이터세트에서 SculptDrug의 성능을 평가한 결과, 최신 기준선에 비해 성능이 우수함을 보여주었습니다.

Conclusion: SculptDrug의 공간 조건 인식 모델링의 효과를 강조합니다.

Abstract: Structure-Based drug design (SBDD) has emerged as a popular approach in drug discovery, leveraging three-dimensional protein structures to generate drug ligands. However, existing generative models encounter several key challenges: (1) incorporating boundary condition constraints, (2) integrating hierarchical structural conditions, and (3) ensuring spatial modeling fidelity. To address these limitations, we propose SculptDrug, a spatial condition-aware generative model based on Bayesian flow networks (BFNs). First, SculptDrug follows a BFN-based framework and employs a progressive denoising strategy to ensure spatial modeling fidelity, iteratively refining atom positions while enhancing local interactions for precise spatial alignment. Second, we introduce a Boundary Awareness Block that incorporates protein surface constraints into the generative process to ensure that generated ligands are geometrically compatible with the target protein. Third, we design a Hierarchical Encoder that captures global structural context while preserving fine-grained molecular interactions, ensuring overall consistency and accurate ligand-protein conformations. We evaluate SculptDrug on the CrossDocked dataset, and experimental results demonstrate that SculptDrug outperforms state-of-the-art baselines, highlighting the effectiveness of spatial condition-aware modeling.

</details>


### [93] [Symmetry-Aware Graph Metanetwork Autoencoders: Model Merging through Parameter Canonicalization](https://arxiv.org/abs/2511.12601)
*Odysseas Boufalis,Jorge Carrasco-Pollo,Joshua Rosenthal,Eduardo Terres-Caballero,Alejandro García-Castellanos*

Main category: cs.LG

TL;DR: Scale Graph Metanetworks (ScaleGMNs)는 손실 경치 내에서의 동치 최소값을 활용하는 새로운 신경망 아키텍처를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 신경망 매개변수화의 내재적 대칭성을 활용하여 여러 동치 최소값을 발견하는 방법을 제시하고자 함.

Method: 대칭성에는 순열 대칭과 매개변수 스케일링 대칭이 포함되며, ScaleGMNs를 통해 자동 인코더 프레임워크를 사용함.

Result: 이 방법은 암시적 신경 표현(Intrinsic Neural Representations, INRs)과 컨볼루션 신경망(CNNs)을 순열 및 스케일링 대칭 하에서 일치시킬 수 있음.

Conclusion: 유사한 네트워크가 동일한 최소값에 자연스럽게 수렴하도록 보장하며, 높은 손실 영역을 피하면서 모델 결합을 촉진함.

Abstract: Neural network parameterizations exhibit inherent symmetries that yield multiple equivalent minima within the loss landscape. Scale Graph Metanetworks (ScaleGMNs) explicitly leverage these symmetries by proposing an architecture equivariant to both permutation and parameter scaling transformations. Previous work by Ainsworth et al. (2023) addressed permutation symmetries through a computationally intensive combinatorial assignment problem, demonstrating that leveraging permutation symmetries alone can map networks into a shared loss basin. In this work, we extend their approach by also incorporating scaling symmetries, presenting an autoencoder framework utilizing ScaleGMNs as invariant encoders. Experimental results demonstrate that our method aligns Implicit Neural Representations (INRs) and Convolutional Neural Networks (CNNs) under both permutation and scaling symmetries without explicitly solving the assignment problem. This approach ensures that similar networks naturally converge within the same basin, facilitating model merging, i.e., smooth linear interpolation while avoiding regions of high loss. The code is publicly available on our GitHub repository.

</details>


### [94] [Beyond Fixed Tasks: Unsupervised Environment Design for Task-Level Pairs](https://arxiv.org/abs/2511.12706)
*Daniel Furelos-Blanco,Charles Pert,Frederik Kelbel,Alex F. Spies,Alessandra Russo,Michael Dennis*

Main category: cs.LG

TL;DR: ATLAS는 일반 에이전트가 복잡한 작업을 수행하도록 훈련하기 위한 새로운 접근 방식을 제공하며, 자동으로 해결 가능한 작업 수준 쌍을 생성하여 정책 훈련을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 작업을 따르는 일반 에이전트를 훈련하는 것은 강화 학습에서 핵심적인 도전 과제이다.

Method: ATLAS는 작업과 수준을 함께 고려하여 자동적으로 해결 가능한 작업 수준 쌍을 생성하는 방법이다. 이는 비지도 환경 설계(UED)를 기반으로 한다.

Result: ATLAS는 무작위 샘플링 접근 방식보다 훨씬 우수한 성능을 보이며, 특히 해결 가능한 쌍을 샘플링하기 어려운 상황에서 더욱 두드러진다.

Conclusion: 작업 및 수준의 구조를 활용한 변형이 효율성 정책으로의 수렴을 가속화한다.

Abstract: Training general agents to follow complex instructions (tasks) in intricate environments (levels) remains a core challenge in reinforcement learning. Random sampling of task-level pairs often produces unsolvable combinations, highlighting the need to co-design tasks and levels. While unsupervised environment design (UED) has proven effective at automatically designing level curricula, prior work has only considered a fixed task. We present ATLAS (Aligning Tasks and Levels for Autocurricula of Specifications), a novel method that generates joint autocurricula over tasks and levels. Our approach builds upon UED to automatically produce solvable yet challenging task-level pairs for policy training. To evaluate ATLAS and drive progress in the field, we introduce an evaluation suite that models tasks as reward machines in Minigrid levels. Experiments demonstrate that ATLAS vastly outperforms random sampling approaches, particularly when sampling solvable pairs is unlikely. We further show that mutations leveraging the structure of both tasks and levels accelerate convergence to performant policies.

</details>


### [95] [Are LLMs The Way Forward? A Case Study on LLM-Guided Reinforcement Learning for Decentralized Autonomous Driving](https://arxiv.org/abs/2511.12751)
*Timur Anvar,Jeffrey Chen,Yuyan Wang,Rohan Chandra*

Main category: cs.LG

TL;DR: 이 논문은 자율 주행차의 복잡한 환경 내비게이션에 있어, 강화 학습(RL)과 대규모 언어 모델(LLM)의 조합을 탐구합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 환경에서 자율 주행차의 내비게이션은 여전히 활발한 연구 분야이며, RL의 주요 한계는 명확한 보상 함수에 의존한다는 것입니다.

Method: LLM을 사용하여 RL을 보완하거나 대체하는 접근 방식을 탐구하고, RL과 LLM을 결합한 하이브리드 접근 방식을 비교하는 사례 연구를 수행했습니다.

Result: RL 전용 에이전트는 중간 성공률을 보였고, LLM 전용 에이전트는 높은 성공률을 기록했지만 속도 성능이 저하되었습니다.

Conclusion: LLM 영향을 받는 접근 방식은 시스템적으로 보수적인 편향을 보여주며, 안전-critical 제어 작업에서 현재의 소형 LLM의 한계를 강조합니다.

Abstract: Autonomous vehicle navigation in complex environments such as dense and fast-moving highways and merging scenarios remains an active area of research. A key limitation of RL is its reliance on well-specified reward functions, which often fail to capture the full semantic and social complexity of diverse, out-of-distribution situations. As a result, a rapidly growing line of research explores using Large Language Models (LLMs) to replace or supplement RL for direct planning and control, on account of their ability to reason about rich semantic context. However, LLMs present significant drawbacks: they can be unstable in zero-shot safety-critical settings, produce inconsistent outputs, and often depend on expensive API calls with network latency. This motivates our investigation into whether small, locally deployed LLMs (< 14B parameters) can meaningfully support autonomous highway driving through reward shaping rather than direct control. We present a case study comparing RL-only, LLM-only, and hybrid approaches, where LLMs augment RL rewards by scoring state-action transitions during training, while standard RL policies execute at test time. Our findings reveal that RL-only agents achieve moderate success rates (73-89%) with reasonable efficiency, LLM-only agents can reach higher success rates (up to 94%) but with severely degraded speed performance, and hybrid approaches consistently fall between these extremes. Critically, despite explicit efficiency instructions, LLM-influenced approaches exhibit systematic conservative bias with substantial model-dependent variability, highlighting important limitations of current small LLMs for safety-critical control tasks.

</details>


### [96] [Expressive Temporal Specifications for Reward Monitoring](https://arxiv.org/abs/2511.12808)
*Omar Adalat,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 이 논문은 강화 학습에서 정보적이고 밀집된 보상 함수의 구성 문제를 해결하기 위해 정량적 선형 시간 논리(LTL)를 활용하여 실행 가능한 보상 모니터를 합성하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습에서 에이전트 훈련의 효율성에 직접적으로 영향을 미치는 정보적이고 밀집된 보상 함수의 지정 문제에 대한 도전.

Method: 정량적 선형 시간 논리(LTL)를 사용하여 실행 가능한 상태 경로에 대한 밀집한 보상 스트림을 생성하는 보상 모니터를 합성하는 방법을 제안한다.

Result: 정량적 모니터가 불리언 모니터에 비해 작업 완수의 정량적 측정을 극대화하고 수렴 시간을 줄이는 데 있어 환경에 따라 일관되게 우수함을 보여주었다.

Conclusion: 이 프레임워크는 알고리즘에 독립적이며 상태 레이블링 함수만을 기반으로 하여 비마르코프 속성의 지정도 자연스럽게 수용한다.

Abstract: Specifying informative and dense reward functions remains a pivotal challenge in Reinforcement Learning, as it directly affects the efficiency of agent training. In this work, we harness the expressive power of quantitative Linear Temporal Logic on finite traces (($\text{LTL}_f[\mathcal{F}]$)) to synthesize reward monitors that generate a dense stream of rewards for runtime-observable state trajectories. By providing nuanced feedback during training, these monitors guide agents toward optimal behaviour and help mitigate the well-known issue of sparse rewards under long-horizon decision making, which arises under the Boolean semantics dominating the current literature. Our framework is algorithm-agnostic and only relies on a state labelling function, and naturally accommodates specifying non-Markovian properties. Empirical results show that our quantitative monitors consistently subsume and, depending on the environment, outperform Boolean monitors in maximizing a quantitative measure of task completion and in reducing convergence time.

</details>


### [97] [Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs](https://arxiv.org/abs/2511.12817)
*Shasha Zhou,Mingyu Huang,Jack Cole,Charles Britton,Ming Yin,Jan Wolber,Ke Li*

Main category: cs.LG

TL;DR: 이 논문은 의료 분야에서 LLM 기반의 답변의 사실성을 자동 평가하기 위해 의료 지식 그래프(KG)를 활용하는 방법의 신뢰성과 타당성을 조사한다.


<details>
  <summary>Details</summary>
Motivation: LLM은 의료 분야에서 혁신의 잠재력을 지니고 있으나, 고위험 의료 환경에 배치하기 위해서는 철저한 검증이 필요하다.

Method: FAITH라는 프레임워크를 도입하여, LLM의 응답을 원자적 주장으로 분해하고 이를 의료 KG와 연결하여 증거 경로에 따라 점수화하는 방식을 사용한다.

Result: 다양한 의료 작업에서 인적 주관 평가와 비교했을 때 KG 기반 평가가 의사의 평가와 높은 상관관계를 보이며, 다양한 능력을 가진 LLM을 효과적으로 구분할 수 있음을 증명하였다.

Conclusion: KG의 활용은 의료 분야의 자동 사실 평가를 위한 중요한 방향임을 결론지었다.

Abstract: The recent proliferation of large language models (LLMs) holds the potential to revolutionize healthcare, with strong capabilities in diverse medical tasks. Yet, deploying LLMs in high-stakes healthcare settings requires rigorous verification and validation to understand any potential harm. This paper investigates the reliability and viability of using medical knowledge graphs (KGs) for the automated factuality evaluation of LLM-generated responses. To ground this investigation, we introduce FAITH, a framework designed to systematically probe the strengths and limitations of this KG-based approach. FAITH operates without reference answers by decomposing responses into atomic claims, linking them to a medical KG, and scoring them based on evidence paths. Experiments on diverse medical tasks with human subjective evaluations demonstrate that KG-grounded evaluation achieves considerably higher correlations with clinician judgments and can effectively distinguish LLMs with varying capabilities. It is also robust to textual variances. The inherent explainability of its scoring can further help users understand and mitigate the limitations of current LLMs. We conclude that while limitations exist, leveraging KGs is a prominent direction for automated factuality assessment in healthcare.

</details>


### [98] [Catastrophic Forgetting in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.12828)
*Mohammad Marufur Rahman,Guanchu Wang,Kaixiong Zhou,Minghan Chen,Fan Yang*

Main category: cs.LG

TL;DR: 이 논문은 KAN(Kolmogorov-Arnold Networks)의 지속 학습에서의 재앙적 잊힘을 연구하고, 이를 통해 KAN의 강점과 한계를 이해하는 데 도움을 준다.


<details>
  <summary>Details</summary>
Motivation: 재앙적 잊힘은 지속 학습에서의 오래된 문제로, 모델들이 새로운 작업을 학습할 때 이전 작업의 지식을 잃는 현상이다. KAN은 잊힘에 저항할 수 있는 잠재력을 가진 것으로 제안되지만, 그 실제적인 동작은 불확실하다.

Method: KAN에서의 재앙적 잊힘에 대한 포괄적인 연구를 수행하고, 잊힘을 활성화 지원 오버랩과 데이터의 내재적 차원에 연결하는 이론적 틀을 개발하였다. 합성 데이터와 비전 과제에 대한 체계적인 실험을 통해 이 분석을 검증하였다.

Result: KAN은 낮은 차원 알고리즘 설정에서는 유망한 유지력을 보여주지만, 이미지 분류 및 언어 모델링과 같은 고차원 영역에서는 여전히 잊힘에 취약하다는 것을 발견하였다.

Conclusion: 이 연구 결과는 KAN의 장점과 한계를 이해하는 데 기여하며, 지속 학습 시스템 디자인에 대한 실용적인 통찰력을 제공한다.

Abstract: Catastrophic forgetting is a longstanding challenge in continual learning, where models lose knowledge from earlier tasks when learning new ones. While various mitigation strategies have been proposed for Multi-Layer Perceptrons (MLPs), recent architectural advances like Kolmogorov-Arnold Networks (KANs) have been suggested to offer intrinsic resistance to forgetting by leveraging localized spline-based activations. However, the practical behavior of KANs under continual learning remains unclear, and their limitations are not well understood. To address this, we present a comprehensive study of catastrophic forgetting in KANs and develop a theoretical framework that links forgetting to activation support overlap and intrinsic data dimension. We validate these analyses through systematic experiments on synthetic and vision tasks, measuring forgetting dynamics under varying model configurations and data complexity. Further, we introduce KAN-LoRA, a novel adapter design for parameter-efficient continual fine-tuning of language models, and evaluate its effectiveness in knowledge editing tasks. Our findings reveal that while KANs exhibit promising retention in low-dimensional algorithmic settings, they remain vulnerable to forgetting in high-dimensional domains such as image classification and language modeling. These results advance the understanding of KANs' strengths and limitations, offering practical insights for continual learning system design.

</details>


### [99] [On the Information Processing of One-Dimensional Wasserstein Distances with Finite Samples](https://arxiv.org/abs/2511.12881)
*Cheongjae Jang,Jonghyun Won,Soyeon Jun,Chun Kee Chung,Keehyoung Joo,Yung-Kyun Noh*

Main category: cs.LG

TL;DR: Wasserstein 거리의 정보를 활용하여 지원과 밀접하게 겹치는 두 분포의 밀도 차이를 식별하는 방법을 분석한다.


<details>
  <summary>Details</summary>
Motivation: Wasserstein 거리는 두 분포 간의 지원 차이를 측정하는 데 유용하지만, 지원이 크게 겹치는 경우 그 정확성이 불분명하다.

Method: 일차원 Wasserstein 거리의 정보 처리 능력을 분석하고, 포아송 과정을 사용하여 포인트별 밀도 차이를 포착하는 방법을 입증한다.

Result: 일차원 Wasserstein 거리는 밀도 차이를 효과적으로 강조하며, 이는 비율 및 지원과 관련이 있다.

Conclusion: 분석된 특성은 신경 스파이크 기차 디코딩과 아미노산 접촉 빈도 데이터를 통해 검증되었다.

Abstract: Leveraging the Wasserstein distance -- a summation of sample-wise transport distances in data space -- is advantageous in many applications for measuring support differences between two underlying density functions. However, when supports significantly overlap while densities exhibit substantial pointwise differences, it remains unclear whether and how this transport information can accurately identify these differences, particularly their analytic characterization in finite-sample settings. We address this issue by conducting an analysis of the information processing capabilities of the one-dimensional Wasserstein distance with finite samples. By utilizing the Poisson process and isolating the rate factor, we demonstrate the capability of capturing the pointwise density difference with Wasserstein distances and how this information harmonizes with support differences. The analyzed properties are confirmed using neural spike train decoding and amino acid contact frequency data. The results reveal that the one-dimensional Wasserstein distance highlights meaningful density differences related to both rate and support.

</details>


### [100] [LinkedIn Profile Characteristics and Professional Success Indicators](https://arxiv.org/abs/2511.12905)
*Tania-Amanda Fredrick Eneye,Ashlesha Malla,Pawan Paudel*

Main category: cs.LG

TL;DR: 이 연구는 LinkedIn 프로필 특성과 직업적 성공 간의 관계를 탐구한다.


<details>
  <summary>Details</summary>
Motivation: 전문가들이 LinkedIn에서의 존재감을 최적화하고 경력 전략을 발전시키기 위한 정보 제공.

Method: 62,000개 이상의 익명 LinkedIn 프로필 데이터셋을 활용하여 머신러닝 기법으로 예측 모델 개발.

Result: 승진 예측은 높은 정확도를 보였지만, 팔로워 수 증가는 더 복잡한 양상을 보였다.

Conclusion: 이 연구는 LinkedIn 프로필 최적화를 위한 실행 가능한 통찰을 제공한다.

Abstract: This study explores the relationship between LinkedIn profile characteristics and professional success, focusing on the indicators of promotions, follower count, and career progression rate. By leveraging a dataset of over 62,000 anonymized LinkedIn profiles, we developed predictive models using machine learning techniques to identify the most influential factors driving professional success. Results indicate that while promotions are highly predictable, follower growth exhibits greater complexity. This research provides actionable insights for professionals seeking to optimize their LinkedIn presence and career strategies.

</details>


### [101] [APT: Affine Prototype-Timestamp For Time Series Forecasting Under Distribution Shift](https://arxiv.org/abs/2511.12945)
*Yujie Li,Zezhi Shao,Chengqing Yu,Yisong Fu,Tao Sun,Yongjun Xu,Fei Wang*

Main category: cs.LG

TL;DR: 분포 변화 하에서의 시계열 예측이 여전히 도전 과제가 되고 있으며, 기존의 딥러닝 모델은 자주 지역 통계 정규화에 의존해 글로벌 분포 변화를 포착하지 못한다. 이를 해결하기 위해, 우리는 글로벌 분포 특징을 정규화-예측 파이프라인에 주입하는 경량 모듈인 APT를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 딥러닝 모델들이 글로벌 분포 변화를 포착하지 못하는 문제를 해결하기 위함이다.

Method: APT는 타임스탬프 조건화된 프로토타입 학습을 활용하여 입력 및 출력 시퀀스를 조절하는 선형 매개변수를 동적으로 생성한다.

Result: APT는 여섯 개의 벤치마크 데이터셋과 여러 백본-정규화 조합을 통해 예측 성능을 크게 향상시킨다.

Conclusion: APT는 최소한의 계산 오버헤드를 추가하면서도 다양한 예측 백본 및 정규화 전략과 호환된다.

Abstract: Time series forecasting under distribution shift remains challenging, as existing deep learning models often rely on local statistical normalization (e.g., mean and variance) that fails to capture global distribution shift. Methods like RevIN and its variants attempt to decouple distribution and pattern but still struggle with missing values, noisy observations, and invalid channel-wise affine transformation. To address these limitations, we propose Affine Prototype Timestamp (APT), a lightweight and flexible plug-in module that injects global distribution features into the normalization-forecasting pipeline. By leveraging timestamp conditioned prototype learning, APT dynamically generates affine parameters that modulate both input and output series, enabling the backbone to learn from self-supervised, distribution-aware clustered instances. APT is compatible with arbitrary forecasting backbones and normalization strategies while introducing minimal computational overhead. Extensive experiments across six benchmark datasets and multiple backbone-normalization combinations demonstrate that APT significantly improves forecasting performance under distribution shift.

</details>


### [102] [Generalization Bounds for Semi-supervised Matrix Completion with Distributional Side Information](https://arxiv.org/abs/2511.13049)
*Antoine Ledent,Mun Chong Soo,Nong Minh Hieu*

Main category: cs.LG

TL;DR: 우리는 저랭크 행렬과 관찰된 항목에 대한 미지의 샘플링 분포를 다루는 행렬 완성 문제를 연구합니다. 이 연구는 추천 시스템 시나리오에서 영감을 받았습니다.


<details>
  <summary>Details</summary>
Motivation: 추천 시스템 시나리오에서 명시적 피드백과 암묵적 피드백 간의 상호작용을 연구하기 위해 필요합니다.

Method: 저랭크 부분공간 회복 이론과 행렬 완성 모델에 대한 고전적인 일반화 경계를 결합하여 두 가지 오류 항의 합으로 구성된 오류 경계를 제시합니다.

Result: 합성 실험에서 실제 일반화 오류가 독립적인 오류 항으로 나뉘는 것을 확인했습니다. Douban과 MovieLens에서의 실제 실험에서도 우수한 성능을 보였습니다.

Conclusion: 우리의 가정이 추천 시스템에서 명시적 및 암묵적 피드백 간의 상호작용을 연구하는 유효한 이론적 설정이라는 것을 입증했습니다.

Abstract: We study a matrix completion problem where both the ground truth $R$ matrix and the unknown sampling distribution $P$ over observed entries are low-rank matrices, and \textit{share a common subspace}. We assume that a large amount $M$ of \textit{unlabeled} data drawn from the sampling distribution $P$ is available, together with a small amount $N$ of labeled data drawn from the same distribution and noisy estimates of the corresponding ground truth entries. This setting is inspired by recommender systems scenarios where the unlabeled data corresponds to `implicit feedback' (consisting in interactions such as purchase, click, etc. ) and the labeled data corresponds to the `explicit feedback', consisting of interactions where the user has given an explicit rating to the item. Leveraging powerful results from the theory of low-rank subspace recovery, together with classic generalization bounds for matrix completion models, we show error bounds consisting of a sum of two error terms scaling as $\widetilde{O}\left(\sqrt{\frac{nd}{M}}\right)$ and $\widetilde{O}\left(\sqrt{\frac{dr}{N}}\right)$ respectively, where $d$ is the rank of $P$ and $r$ is the rank of $M$. In synthetic experiments, we confirm that the true generalization error naturally splits into independent error terms corresponding to the estimations of $P$ and and the ground truth matrix $\ground$ respectively. In real-life experiments on Douban and MovieLens with most explicit ratings removed, we demonstrate that the method can outperform baselines relying only on the explicit ratings, demonstrating that our assumptions provide a valid toy theoretical setting to study the interaction between explicit and implicit feedbacks in recommender systems.

</details>


### [103] [Learning from the Undesirable: Robust Adaptation of Language Models without Forgetting](https://arxiv.org/abs/2511.13052)
*Yunhun Nam,Jaehyung Kim,Jongheon Jeong*

Main category: cs.LG

TL;DR: 이 논문은 데이터가 제한된 경우 언어 모델의 과적합 문제를 완화하기 위해 Learning-from-the-Undesirable (LfU)라는 정규화 기법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 언어 모델은 특정 작업에 적합하게 조정되지만, 제한된 데이터로 조정할 경우 과적합이 발생할 수 있습니다.

Method: LfU는 바람직하지 않은 모델 업데이트에 대한 내성을 향상시키기 위해 일관성 정규화를 도입합니다.

Result: 실험 결과, LfU는 제한된 데이터에서 일반화를 촉진하며, 다양한 작업에서 평균 16.8%의 성능 향상을 보여줍니다.

Conclusion: LfU는 사전 훈련된 지식을 보호하면서 적응성을 향상시키는 효과적인 사전 지식을 제공합니다.

Abstract: Language models (LMs) are often adapted through supervised fine-tuning (SFT) to specialize their capabilities for downstream tasks. However, in typical scenarios where the fine-tuning data is limited, e.g., compared to pre-training, SFT can lead LMs to overfit, causing them to rely on spurious patterns within the target task or to compromise other broadly useful capabilities as a side effect of narrow specialization. In this paper, we propose Learning-from-the-Undesirable (LfU), a simple yet effective regularization scheme for SFT to mitigate overfitting issues when fine-tuning LMs with limited data. Specifically, we aim to regularize the fine-tuning process to favor solutions that are resilient to "undesirable" model updates, e.g., gradient ascent steps that steer the model toward undesirable behaviors. To this end, we propose a novel form of consistency regularization that directly aligns internal representations of the model with those after an undesirable update. By leveraging representation-level data augmentation through undesirable updates, LfU effectively promotes generalization under limited data. Our experiments on diverse LM downstream tasks show that LfU serves as an effective prior that enhances adaptability while preserving pretrained knowledge. For example, our LM from LfU achieves a 16.8% average improvement on math tasks compared to vanilla SFT on the same dataset, where the latter even leads to degraded performance on those tasks. Furthermore, LfU exhibits improved robustness to prompt variations, e.g., yielding a 92.1% lower standard deviation in output performances compared to SFT, highlighting its versatile effects.

</details>


### [104] [Real-time prediction of breast cancer sites using deformation-aware graph neural network](https://arxiv.org/abs/2511.13082)
*Kyunghyun Lee,Yong-Min Shin,Minwoo Shin,Jihun Kim,Sunghwan Lim,Won-Yong Shin,Kyungho Yoon*

Main category: cs.LG

TL;DR: 유방암의 조기 진단은 치료 계획 수립과 환자 예후 개선에 중요하나, 기존의 MRI 유도 생검 방법은 시간과 비용 문제로 실용성이 제한된다. 본 연구에서는 그래프 신경망(GNN) 모델을 활용하여 생검 과정 중 실시간으로 변형된 유방암 위치를 예측하는 방법을 개발하였으며, 높은 정확도의 실시간 추론을 달성하여 유방암 진단의 정밀성과 효율성을 높일 것으로 기대된다.


<details>
  <summary>Details</summary>
Motivation: 유방암 조기 진단의 필요성과 기존 방법의 한계를 극복하기 위한 새로운 접근 방식의 개발이 필요하다.

Method: 개별화된 유한요소(FE) 모델을 개발하고, 이를 통해 GNN 모델을 사용하여 변형된 유방암 부위 예측을 실시간으로 수행한다.

Result: 모델은 실제 환자 데이터와 환상 데이터셋을 이용해 검증되었고, 암 결절 변위에 대해 0.2mm 내의 정확성과 0.977의 DSC를 달성하였다.

Conclusion: 제안된 변형 인식 GNN 모델은 유방 생검에서 실시간 종양 변위 예측에 유망한 솔루션을 제공하며, 임상 절차와의 통합은 유방암 진단의 정밀성과 효율성을 크게 향상시킬 수 있다.

Abstract: Early diagnosis of breast cancer is crucial, enabling the establishment of appropriate treatment plans and markedly enhancing patient prognosis. While direct magnetic resonance imaging-guided biopsy demonstrates promising performance in detecting cancer lesions, its practical application is limited by prolonged procedure times and high costs. To overcome these issues, an indirect MRI-guided biopsy that allows the procedure to be performed outside of the MRI room has been proposed, but it still faces challenges in creating an accurate real-time deformable breast model. In our study, we tackled this issue by developing a graph neural network (GNN)-based model capable of accurately predicting deformed breast cancer sites in real time during biopsy procedures. An individual-specific finite element (FE) model was developed by incorporating magnetic resonance (MR) image-derived structural information of the breast and tumor to simulate deformation behaviors. A GNN model was then employed, designed to process surface displacement and distance-based graph data, enabling accurate prediction of overall tissue displacement, including the deformation of the tumor region. The model was validated using phantom and real patient datasets, achieving an accuracy within 0.2 millimeters (mm) for cancer node displacement (RMSE) and a dice similarity coefficient (DSC) of 0.977 for spatial overlap with actual cancerous regions. Additionally, the model enabled real-time inference and achieved a speed-up of over 4,000 times in computational cost compared to conventional FE simulations. The proposed deformation-aware GNN model offers a promising solution for real-time tumor displacement prediction in breast biopsy, with high accuracy and real-time capability. Its integration with clinical procedures could significantly enhance the precision and efficiency of breast cancer diagnosis.

</details>


### [105] [Soft Conflict-Resolution Decision Transformer for Offline Multi-Task Reinforcement Learning](https://arxiv.org/abs/2511.13133)
*Shudong Wang,Xinfei Wang,Chenhao Zhang,Shanchen Pang,Haiyuan Gui,Wenhao Ji,Xiaojian Liao*

Main category: cs.LG

TL;DR: 다중 과제 강화 학습(MTRL)은 다양한 과제를 위한 통합 정책을 배우고자 하나, 과제 간의 그래디언트 충돌로 어려움을 겪는다. 기존의 마스킹 기반 방법은 과제별 매개변수 마스크를 할당하여 이러한 충돌을 완화하려고 시도하지만, 매우 조악한 이진 마스크는 주요 충돌 매개변수를 과도하게 억제하는 문제를 안고 있다. 우리는 SoCo-DT라는 파라미터 중요도 기반의 부드러운 충돌 해결 방법을 제안하여, Fisher 정보를 활용해 중요 매개변수를 유지하면서 충돌하는 매개변수를 억제한다. 실험 결과는 SoCo-DT가 MT50에서 7.6%, 비최적 데이터셋에서 10.5% 우수한 성능을 보임을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 다중 과제 강화 학습에서 다양한 과제를 위한 통합 정책을 배우는 데 있어, 과제 간 그래디언트 충돌 문제를 해결하려는 필요성.

Method: Fisher 정보를 활용하여 동적으로 마스크 값을 조정하고, IQR 기반의 동적 희소성 조정 전략을 통해 과제별 임계값 설정을 수행하는 SoCo-DT를 제안.

Result: 실험 결과, SoCo-DT가 Meta-World 벤치마크에서 최신 기술에 비해 MT50에서 7.6%, 비최적 데이터셋에서 10.5%의 성능 향상을 보였다.

Conclusion: SoCo-DT는 그래디언트 충돌을 완화하고 전체 다중 과제 성능을 향상시키는 데 효과적이다.

Abstract: Multi-task reinforcement learning (MTRL) seeks to learn a unified policy for diverse tasks, but often suffers from gradient conflicts across tasks. Existing masking-based methods attempt to mitigate such conflicts by assigning task-specific parameter masks. However, our empirical study shows that coarse-grained binary masks have the problem of over-suppressing key conflicting parameters, hindering knowledge sharing across tasks. Moreover, different tasks exhibit varying conflict levels, yet existing methods use a one-size-fits-all fixed sparsity strategy to keep training stability and performance, which proves inadequate. These limitations hinder the model's generalization and learning efficiency.
  To address these issues, we propose SoCo-DT, a Soft Conflict-resolution method based by parameter importance. By leveraging Fisher information, mask values are dynamically adjusted to retain important parameters while suppressing conflicting ones. In addition, we introduce a dynamic sparsity adjustment strategy based on the Interquartile Range (IQR), which constructs task-specific thresholding schemes using the distribution of conflict and harmony scores during training. To enable adaptive sparsity evolution throughout training, we further incorporate an asymmetric cosine annealing schedule to continuously update the threshold. Experimental results on the Meta-World benchmark show that SoCo-DT outperforms the state-of-the-art method by 7.6% on MT50 and by 10.5% on the suboptimal dataset, demonstrating its effectiveness in mitigating gradient conflicts and improving overall multi-task performance.

</details>


### [106] [DiffFP: Learning Behaviors from Scratch via Diffusion-based Fictitious Play](https://arxiv.org/abs/2511.13186)
*Akash Karthikeyan,Yash Vardhan Pant*

Main category: cs.LG

TL;DR: DiffFP는 자가 학습을 통해 상상적 플레이 프레임워크를 제안하며, 보이지 않는 상대에 대한 최선의 반응을 추정하고 강력한 행동 정책을 학습하여 다중 에이전트 환경에서 경쟁적인 성능을 달성합니다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 전략적 상호작용 행동을 학습하는 데 있어 연속 결정 공간에서의 도전과제를 해결하고, 동적 다중 에이전트 환경에서의 적응성과 일반화를 보장하는 것이 중요합니다.

Method: DiffFP 프레임워크는 보이지 않는 상대에 대한 최선의 반응을 추정하면서 강력하고 다변량의 행동 정책을 학습하기 위해 확산 정책을 사용한 생성 모델링을 활용합니다.

Result: DiffFP 프레임워크는 연속 공간 제로섬 게임에서의 ε-내쉬 균형으로 수렴함을 실증적으로 보여줍니다. 또한, 복잡한 다중 에이전트 환경에서 강력한 성능을 나타냅니다.

Conclusion: 우리 접근법은 RL 기준선에 비해 최대 3배 빠른 수렴과 평균 30배 더 높은 성공률을 달성하며, 상대 전략에 대한 저항력과 훈련 반복에 걸친 안정성을 입증합니다.

Abstract: Self-play reinforcement learning has demonstrated significant success in learning complex strategic and interactive behaviors in competitive multi-agent games. However, achieving such behaviors in continuous decision spaces remains challenging. Ensuring adaptability and generalization in self-play settings is critical for achieving competitive performance in dynamic multi-agent environments. These challenges often cause methods to converge slowly or fail to converge at all to a Nash equilibrium, making agents vulnerable to strategic exploitation by unseen opponents. To address these challenges, we propose DiffFP, a fictitious play (FP) framework that estimates the best response to unseen opponents while learning a robust and multimodal behavioral policy. Specifically, we approximate the best response using a diffusion policy that leverages generative modeling to learn adaptive and diverse strategies. Through empirical evaluation, we demonstrate that the proposed FP framework converges towards $ε$-Nash equilibria in continuous- space zero-sum games. We validate our method on complex multi-agent environments, including racing and multi-particle zero-sum games. Simulation results show that the learned policies are robust against diverse opponents and outperform baseline reinforcement learning policies. Our approach achieves up to 3$\times$ faster convergence and 30$\times$ higher success rates on average against RL-based baselines, demonstrating its robustness to opponent strategies and stability across training iterations

</details>


### [107] [Tab-PET: Graph-Based Positional Encodings for Tabular Transformers](https://arxiv.org/abs/2511.13338)
*Yunze Leng,Rohan Ghosh,Mehul Motani*

Main category: cs.LG

TL;DR: 이 논문은 테이블 데이터에서 위치 정보(PEs)를 활용하는 것이 일반화 성능을 향상시키는 데 어떻게 도움이 되는지에 대한 연구를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 테이블 데이터는 낮은 데이터 크기, 구조적 단서의 부재, 범주형 및 연속적 도메인에서 이질적인 특성을 포함하는 등 독특한 도전 과제가 있다.

Method: Tab-PET 프레임워크를 제안하며, 그래프 기반 접근 방식을 사용하여 PEs를 추정하고 임베딩에 주입한다. 두 가지 패러다임인 연관 기반 및 인과 기반 그래프 추정을 탐구한다.

Result: 그래프 유도 PEs가 3T(Transformer 기반 모델)에서 50개의 분류 및 회귀 데이터셋 전반에 걸쳐 성능을 유의미하게 개선했다.

Conclusion: PEs는 테이블 변환기에서 일반화 향상을 위해 활용될 수 있는 예기치 않은 역할을 한다.

Abstract: Supervised learning with tabular data presents unique challenges, including low data sizes, the absence of structural cues, and heterogeneous features spanning both categorical and continuous domains. Unlike vision and language tasks, where models can exploit inductive biases in the data, tabular data lacks inherent positional structure, hindering the effectiveness of self-attention mechanisms. While recent transformer-based models like TabTransformer, SAINT, and FT-Transformer (which we refer to as 3T) have shown promise on tabular data, they typically operate without leveraging structural cues such as positional encodings (PEs), as no prior structural information is usually available. In this work, we find both theoretically and empirically that structural cues, specifically PEs can be a useful tool to improve generalization performance for tabular transformers. We find that PEs impart the ability to reduce the effective rank (a form of intrinsic dimensionality) of the features, effectively simplifying the task by reducing the dimensionality of the problem, yielding improved generalization. To that end, we propose Tab-PET (PEs for Tabular Transformers), a graph-based framework for estimating and inculcating PEs into embeddings. Inspired by approaches that derive PEs from graph topology, we explore two paradigms for graph estimation: association-based and causality-based. We empirically demonstrate that graph-derived PEs significantly improve performance across 50 classification and regression datasets for 3T. Notably, association-based graphs consistently yield more stable and pronounced gains compared to causality-driven ones. Our work highlights an unexpected role of PEs in tabular transformers, revealing how they can be harnessed to improve generalization.

</details>


### [108] [Statistically Accurate and Robust Generative Prediction of Rock Discontinuities with A Tabular Foundation Model](https://arxiv.org/abs/2511.13339)
*Han Meng,Gang Mei,Hong Tian,Nengxiong Xu,Jianbing Peng*

Main category: cs.LG

TL;DR: 이 논문은 암석 불연속성에 대한 통계적으로 정확한 예측 접근법을 제안하며, 기존 방법보다 향상된 정확도와 견고성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 암석 불연속성은 암석 덩어리의 기계적 거동과 안정성에 중요한 영향을 미친다.

Method: 우리는 탭형 기초 모델을 활용한 간단하면서도 견고한 접근법을 제안한다.

Result: 이 접근법은 제한된 측정된 불연속성 내에서 복잡한 분포 패턴을 효과적으로 포착한다.

Conclusion: 이 연구는 암석 덩어리 구조의 정량적 특성을 발전시켜, 보다 안전하고 신뢰할 수 있는 데이터 기반의 지반공학 설계를 지원한다.

Abstract: Rock discontinuities critically govern the mechanical behavior and stability of rock masses. Their internal distributions remain largely unobservable and are typically inferred from surface-exposed discontinuities using generative prediction approaches. However, surface-exposed observations are inherently sparse, and existing generative prediction approaches either fail to capture the underlying complex distribution patterns or lack robustness under data-sparse conditions. Here, we proposed a simple yet robust approach for statistically accurate generative prediction of rock discontinuities by utilizing a tabular foundation model. By leveraging the powerful sample learning capability of the foundation model specifically designed for small data, our approach can effectively capture the underlying complex distribution patterns within limited measured discontinuities. Comparative experiments on ten datasets with diverse scales and distribution patterns of discontinuities demonstrate superior accuracy and robustness over conventional statistical models and deep generative approaches. This work advances quantitative characterization of rock mass structures, supporting safer and more reliable data-driven geotechnical design.

</details>


### [109] [A Novel Hierarchical Integration Method for Efficient Model Merging in Medical LLMs](https://arxiv.org/abs/2511.13373)
*Prakrit Timilsina,Anuj Nepal,Rajan Kadel,Robin Doss*

Main category: cs.LG

TL;DR: 이 논문은 분산 의료에서 큰 언어 모델의 매개변수 공간 병합 기법을 정량적으로 평가하고, 아키텍처 호환 모델을 위한 간단한 평균화 방법의 효용을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 분산 의료에서 LLM이 기관 간 전문 지식을 통합하고, 개인 정보 보호를 유지하며, 계산 오버헤드를 줄이고, 모델 업데이트 중 재앙적인 망각을 방지하는 데 어려움이 크다.

Method: Mistral-7B 기본 모델에서 파생된 두 개의 아키텍처 호환 의료 LLM에 적용된 여섯 가지 매개변수 공간 병합 기법을 체계적으로 평가하고, 선택적 최적 수송 정렬과 코사인 유사성 가중 보간법을 결합한 새로운 계층적 방법을 도입한다.

Result: 의료 벤치마크 5곳에서 평가한 결과, 아키텍처 호환 모델은 단순 평균화 방법의 큰 이점을 보이며, Task Arithmetic는 MedQA에서 45.80% 정확도를 달성해 복잡한 가지치기 기반 접근법을 초과하는 성능을 보였다.

Conclusion: 아키텍처 호환 모델의 경우, 단순 평균화가 지식 통합을 위한 강력하고 계산 효율적인 기준선을 제공하며, 리소스가 제한된 IoT 환경에서 분산 의료 AI의 배치를 위한 실용적인 경로를 제시한다.

Abstract: Large Language Models (LLMs) face significant challenges in distributed healthcare, including consolidating specialized domain knowledge across institutions while maintaining privacy, reducing computational overhead, and preventing catastrophic forgetting during model updates.This paper presents a systematic evaluation of six parameter-space merging techniques applied to two architecturally compatible medical LLMs derived from the Mistral-7B base model. We introduce a novel hierarchical method that combines selective Optimal Transport (OT) alignment for attention layers with cosine similarity-weighted interpolation, designed to address permutation variance while minimizing computational overhead for edge deployment scenarios. Our study evaluates Task Arithmetic, Linear Averaging, DARE-TIES, DELLA, Breadcrumbs, and our Hierarchical approach across five medical benchmarks. Results demonstrate that architecturally compatible models benefit significantly from simple averaging methods, with Task Arithmetic achieving 45.80% accuracy on MedQA, outperforming complex pruning-based approaches. These findings offer critical insights for the deployment of distributed medical AI in resource-constrained IoT environments, where computational efficiency and model compatibility are paramount. Our work establishes that for architecturally compatible models, simple averaging provides a robust and computationally efficient baseline for knowledge consolidation, offering a pragmatic path forward for scalable medical AI systems.

</details>


### [110] [P1: Mastering Physics Olympiads with Reinforcement Learning](https://arxiv.org/abs/2511.13612)
*Jiacheng Chen,Qianjia Cheng,Fangchen Yu,Haiyuan Wan,Yuchen Zhang,Shenghe Zheng,Junchi Yao,Qingyang Zhang,Haonan He,Yun Luo,Yufeng Zhao,Futing Wang,Li Sheng,Chengxing Xie,Yuxin Zuo,Yizhuo Li,Wenxauan Zeng,Yulun Wu,Rui Huang,Dongzhan Zhou,Kai Chen,Yu Qiao,Lei Bai,Yu Cheng,Ning Ding,Bowen Zhou,Peng Ye,Ganqu Cui*

Main category: cs.LG

TL;DR: 대규모 언어 모델의 발전을 통해 물리학 연구를 진전시키고, 올림피아드 수준의 물리학 문제를 해결하는 모델인 P1 시리즈를 개발하였다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 최근 발전은 문제 해결에서 과학적 추리로의 경계를 이동시켰다.

Method: P1이라는 오픈 소스 물리학 추리 모델을 강화 학습을 통해 개발하였다.

Result: P1-235B-A22B는 2025 국제 물리학 올림피아드에서 금메달 성과를 거두었고, 2024/2025년 동안 13개의 국제/지역 물리학 대회에서 12개의 금메달을 획득하였다.

Conclusion: P1 모델은 물리학을 넘어서 수학 및 코딩과 같은 다른 추리 작업에서도 뛰어난 성능을 보여주었다.

Abstract: Recent progress in large language models (LLMs) has moved the frontier from puzzle-solving to science-grade reasoning-the kind needed to tackle problems whose answers must stand against nature, not merely fit a rubric. Physics is the sharpest test of this shift, which binds symbols to reality in a fundamental way, serving as the cornerstone of most modern technologies. In this work, we manage to advance physics research by developing large language models with exceptional physics reasoning capabilities, especially excel at solving Olympiad-level physics problems. We introduce P1, a family of open-source physics reasoning models trained entirely through reinforcement learning (RL). Among them, P1-235B-A22B is the first open-source model with Gold-medal performance at the latest International Physics Olympiad (IPhO 2025), and wins 12 gold medals out of 13 international/regional physics competitions in 2024/2025. P1-30B-A3B also surpasses almost all other open-source models on IPhO 2025, getting a silver medal. Further equipped with an agentic framework PhysicsMinions, P1-235B-A22B+PhysicsMinions achieves overall No.1 on IPhO 2025, and obtains the highest average score over the 13 physics competitions. Besides physics, P1 models also present great performance on other reasoning tasks like math and coding, showing the great generalibility of P1 series.

</details>


### [111] [Efficient Calibration for Decision Making](https://arxiv.org/abs/2511.13699)
*Parikshit Gopalan,Konstantinos Stavropoulos,Kunal Talwar,Pranay Tankala*

Main category: cs.LG

TL;DR: 이 논문에서는 완벽한 보정의 의사결정 이론적 특성을 정의하고, 특정 구조적 함수 가족을 사용하여 보정 결정 손실(CDL)을 근사적으로 파악하는 방법을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 완벽한 보정 상태에서 예측자에 대한 후처리가 결과를 개선할 수 없다는 성질을 이용하여 발달된 보정 결정 손실의 필요성을 설명합니다.

Method: 후처리 함수의 구조적 가족 K에 대해 보정 결정 손실을 정의하고, 정보 이론적으로 및 계산적으로 처리 가능한 조건을 개발합니다.

Result: 자연적인 클래스 K에 대한 상한선과 하한선을 증명하는 결과를 도출합니다.

Conclusion: 이론적인 기여 외에도, 우리의 결과는 기계 학습에서 널리 사용되는 재조정 절차에 대한 엄격한 보장을 제공합니다.

Abstract: A decision-theoretic characterization of perfect calibration is that an agent seeking to minimize a proper loss in expectation cannot improve their outcome by post-processing a perfectly calibrated predictor. Hu and Wu (FOCS'24) use this to define an approximate calibration measure called calibration decision loss ($\mathsf{CDL}$), which measures the maximal improvement achievable by any post-processing over any proper loss. Unfortunately, $\mathsf{CDL}$ turns out to be intractable to even weakly approximate in the offline setting, given black-box access to the predictions and labels.
  We suggest circumventing this by restricting attention to structured families of post-processing functions $K$. We define the calibration decision loss relative to $K$, denoted $\mathsf{CDL}_K$ where we consider all proper losses but restrict post-processings to a structured family $K$. We develop a comprehensive theory of when $\mathsf{CDL}_K$ is information-theoretically and computationally tractable, and use it to prove both upper and lower bounds for natural classes $K$. In addition to introducing new definitions and algorithmic techniques to the theory of calibration for decision making, our results give rigorous guarantees for some widely used recalibration procedures in machine learning.

</details>
