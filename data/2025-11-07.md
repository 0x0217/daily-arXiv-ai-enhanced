<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 8]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.LG](#cs.LG) [Total: 18]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Evaluating Control Protocols for Untrusted AI Agents](https://arxiv.org/abs/2511.02997)
*Jon Kutasov,Chloe Loughridge,Yuqi Sun,Henry Sleight,Buck Shlegeris,Tyler Tracy,Joe Benton*

Main category: cs.AI

TL;DR: AI 시스템의 안전한 운영을 보장하기 위해 AI 제어 프로토콜을 평가하고 검증하는 연구.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 안전한 운영이 중요해지면서, 신뢰할 수 없는 AI 에이전트로부터의 위험을 완화하기 위한 AI 제어의 필요성이 대두된다.

Method: SHADE-Arena라는 다양한 에이전트 환경 데이터셋에서 여러 제어 프로토콜을 체계적으로 평가한다.

Result: 재샘플링과 중요한 행동에 대한 연기를 적용했을 때 안전성이 50%에서 96%로 증가하며, 공격 정책에 대한 저항력을 테스트한 결과, 강력한 공격 전략에도 불구하고 중요한 행동에 대한 연기는 높은 견고성을 보였다.

Conclusion: AI 제어 프로토콜을 통해 공격 정책에 접근을 차단하는 것이 중요성을 입증했다.

Abstract: As AI systems become more capable and widely deployed as agents, ensuring
their safe operation becomes critical. AI control offers one approach to
mitigating the risk from untrusted AI agents by monitoring their actions and
intervening or auditing when necessary. Evaluating the safety of these
protocols requires understanding both their effectiveness against current
attacks and their robustness to adaptive adversaries. In this work, we
systematically evaluate a range of control protocols in SHADE-Arena, a dataset
of diverse agentic environments. First, we evaluate blue team protocols,
including deferral to trusted models, resampling, and deferring on critical
actions, against a default attack policy. We find that resampling for
incrimination and deferring on critical actions perform best, increasing safety
from 50% to 96%. We then iterate on red team strategies against these protocols
and find that attack policies with additional affordances, such as knowledge of
when resampling occurs or the ability to simulate monitors, can substantially
improve attack success rates against our resampling strategy, decreasing safety
to 17%. However, deferring on critical actions is highly robust to even our
strongest red team strategies, demonstrating the importance of denying attack
policies access to protocol internals.

</details>


### [2] [PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework](https://arxiv.org/abs/2511.03023)
*Sina Montazeri,Yunhe Feng,Kewei Sha*

Main category: cs.AI

TL;DR: Open data repositories는 증거 기반 의사 결정을 위한 잠재력을 가지고 있지만, 비전문가에게는 접근이 어려움. PublicAgent는 의도 명확화, 데이터셋 발견, 분석, 보고를 위한 전문화된 에이전트들로 구성된 다중 에이전트 프레임워크로 이러한 한계를 극복함. 이 아키텍처는 에이전트가 각 단계에서 유효성을 검증할 수 있도록 함.


<details>
  <summary>Details</summary>
Motivation: 공개 데이터 저장소의 필요성과 비전문가가 데이터셋을 발견하고 분석하는 데 겪는 어려움을 해결하기 위해.

Method: PublicAgent라는 다중 에이전트 프레임워크를 통해 의도 명확화, 데이터셋 발견, 분석 및 보고를 위한 전문화된 에이전트로 분해함.

Result: 다섯 가지 설계 원칙을 도출하였고, 이를 통해 모델 강도와 무관하게 가치가 있음을 확인함.

Conclusion: 복잡한 분석 워크플로우에 필요한 전문화를 파악하고 자연어 인터페이스를 통해 공개 데이터에 대한 접근을 넓힐 수 있는 능력을 강조하며, 모델 인식 아키텍처 설계의 필요성을 제시함.

Abstract: Open data repositories hold potential for evidence-based decision-making, yet
are inaccessible to non-experts lacking expertise in dataset discovery, schema
mapping, and statistical analysis. Large language models show promise for
individual tasks, but end-to-end analytical workflows expose fundamental
limitations: attention dilutes across growing contexts, specialized reasoning
patterns interfere, and errors propagate undetected. We present PublicAgent, a
multi-agent framework that addresses these limitations through decomposition
into specialized agents for intent clarification, dataset discovery, analysis,
and reporting. This architecture maintains focused attention within agent
contexts and enables validation at each stage. Evaluation across five models
and 50 queries derives five design principles for multi-agent LLM systems.
First, specialization provides value independent of model strength--even the
strongest model shows 97.5% agent win rates, with benefits orthogonal to model
scale. Second, agents divide into universal (discovery, analysis) and
conditional (report, intent) categories. Universal agents show consistent
effectiveness (std dev 12.4%) while conditional agents vary by model (std dev
20.5%). Third, agents mitigate distinct failure modes--removing discovery or
analysis causes catastrophic failures (243-280 instances), while removing
report or intent causes quality degradation. Fourth, architectural benefits
persist across task complexity with stable win rates (86-92% analysis, 84-94%
discovery), indicating workflow management value rather than reasoning
enhancement. Fifth, wide variance in agent effectiveness across models (42-96%
for analysis) requires model-aware architecture design. These principles guide
when and why specialization is necessary for complex analytical workflows while
enabling broader access to public data through natural language interfaces.

</details>


### [3] [No-Human in the Loop: Agentic Evaluation at Scale for Recommendation](https://arxiv.org/abs/2511.03051)
*Tao Zhang,Kehui Yao,Luyi Ma,Jiao Chen,Reza Yousefi Maragheh,Kai Zhao,Jianpeng Xu,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: ScalingEval은 36개의 LLM을 비교한 대규모 벤치마크 연구로, LLM을 판별자로 사용하기 위한 평가 프로세스를 향상시키고자 한다.


<details>
  <summary>Details</summary>
Motivation: LLM을 판별자로 사용하는 것은 신뢰할 수 있는 평가 프로세스를 구축하기 위해 점점 더 중요해지고 있다.

Method: ScalingEval은 36개의 LLM을 합의 기반 평가 프로토콜을 사용하여 시스템적으로 비교하며, 다수결을 통해 LLM 평가자들 간의 패턴 감사 및 문제 코드를 진실 레이블로 집계하는 다중 에이전트 프레임워크를 사용한다.

Result: 모델 비교를 통해 Anthropic Claude 3.5 Sonnet이 가장 높은 결정 신뢰도를 기록했으며, Gemini 1.5 Pro가 전반적으로 성능이 뛰어나고, GPT-4o는 지연 시간-정확성-비용 트레이드오프에서 가장 유리하며, GPT-OSS 20B는 오픈 소스 모델 중 가장 우수한 성능을 보인다.

Conclusion: ScalingEval은 LLM 판별자에 대한 재현 가능한 벤치마크이자 평가 프로토콜로 자리 잡았으며, 규모 확대, 신뢰성 및 모델 가족 간 트레이드오프에 대한 실행 가능한 가이드를 제공한다.

Abstract: Evaluating large language models (LLMs) as judges is increasingly critical
for building scalable and trustworthy evaluation pipelines. We present
ScalingEval, a large-scale benchmarking study that systematically compares 36
LLMs, including GPT, Gemini, Claude, and Llama, across multiple product
categories using a consensus-driven evaluation protocol. Our multi-agent
framework aggregates pattern audits and issue codes into ground-truth labels
via scalable majority voting, enabling reproducible comparison of LLM
evaluators without human annotation. Applied to large-scale complementary-item
recommendation, the benchmark reports four key findings: (i) Anthropic Claude
3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers
the best overall performance across categories; (iii) GPT-4o provides the most
favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among
open-source models. Category-level analysis shows strong consensus in
structured domains (Electronics, Sports) but persistent disagreement in
lifestyle categories (Clothing, Food). These results establish ScalingEval as a
reproducible benchmark and evaluation protocol for LLMs as judges, with
actionable guidance on scaling, reliability, and model family tradeoffs.

</details>


### [4] [Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks](https://arxiv.org/abs/2511.03137)
*Shipeng Cen,Ying Tan*

Main category: cs.AI

TL;DR: 이 연구에서는 다중 모달 대형 언어 모델(MLLM)을 통합하여 불꽃 알고리즘(FWA)의 설계를 지원하는 새로운 접근 방식을 제안합니다. 이를 통해 복잡한 고차원 작업을 수행하고, TSP 및 EDA 문제를 포함한 여러 문제 인스턴스에서 성능 개선을 달성했습니다.


<details>
  <summary>Details</summary>
Motivation: 최적화 문제의 복잡성과 다양성이 증가함에 따라 최적화 기술의 발전과 패러다임 혁신이 중요해지고 있습니다.

Method: 우리는 불꽃 알고리즘(FWA)을 기본 최적화 도구로 선택하고, 다중 모달 대형 언어 모델(MLLM)을 통합하여 FWA 설계를 지원하는 새로운 접근 방식을 제안합니다. 특히, FWA를 복잡한 고차원 작업으로 확장하는 'Critical Part(CP)' 개념을 제안하고, 다중 모달 특성을 활용하여 최적화 과정에서의 정보를 활용합니다.

Result: 우리의 새로운 프레임워크에서 생성된 FWA는 여러 문제 인스턴스에서 SOTA 결과를 달성하거나 초월했습니다.

Conclusion: 본 연구는 다중 모달 대형 언어 모델을 활용하여 기존의 최적화 방법을 개선할 수 있는 가능성을 보여주었습니다.

Abstract: As optimization problems grow increasingly complex and diverse, advancements
in optimization techniques and paradigm innovations hold significant
importance. The challenges posed by optimization problems are primarily
manifested in their non-convexity, high-dimensionality, black-box nature, and
other unfavorable characteristics. Traditional zero-order or first-order
methods, which are often characterized by low efficiency, inaccurate gradient
information, and insufficient utilization of optimization information, are
ill-equipped to address these challenges effectively. In recent years, the
rapid development of large language models (LLM) has led to substantial
improvements in their language understanding and code generation capabilities.
Consequently, the design of optimization algorithms leveraging large language
models has garnered increasing attention from researchers. In this study, we
choose the fireworks algorithm(FWA) as the basic optimizer and propose a novel
approach to assist the design of the FWA by incorporating multi-modal large
language model(MLLM). To put it simply, we propose the concept of Critical
Part(CP), which extends FWA to complex high-dimensional tasks, and further
utilizes the information in the optimization process with the help of the
multi-modal characteristics of large language models. We focus on two specific
tasks: the \textit{traveling salesman problem }(TSP) and \textit{electronic
design automation problem} (EDA). The experimental results show that FWAs
generated under our new framework have achieved or surpassed SOTA results on
many problem instances.

</details>


### [5] [Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework](https://arxiv.org/abs/2511.03179)
*Varun Kumar,George Em Karniadakis*

Main category: cs.AI

TL;DR: 본 연구는 멀티 에이전트 AI 프레임워크를 활용하여 공학 설계 프로세스를 공식화하고, 이를 통해 효율성과 품질을 향상시킬 수 있음을 입증합니다.


<details>
  <summary>Details</summary>
Motivation: 공학 설계 프로세스는 여러 도메인에서의 전문 지식을 요구하여 복잡한 협력과 반복적인 수정을 필요로 합니다. 이러한 과정을 보다 효율적으로 개선하기 위함입니다.

Method: 구조화된 설계 및 검토 루프를 통합하는 멀티 에이전트 AI 프레임워크를 제시했습니다. 이 프레임워크는 지식 기반 에이전트들이 협력하여 설계 후보를 생성하고 정제합니다.

Result: 4자리 NACA 에어포일의 공기역학적 최적화에 대한 적용 예를 통해 이 프레임워크의 유용성을 보여주었습니다.

Conclusion: 구조화된 지식 표현으로 무장한 협력적 AI 에이전트들이 공학 설계 프로세스의 효율성, 일관성, 품질을 향상시킬 수 있음을 증명했습니다.

Abstract: The engineering design process often demands expertise from multiple domains,
leading to complex collaborations and iterative refinements. Traditional
methods can be resource-intensive and prone to inefficiencies. To address this,
we formalize the engineering design process through a multi-agent AI framework
that integrates structured design and review loops. The framework introduces
specialized knowledge-driven agents that collaborate to generate and refine
design candidates. As an exemplar, we demonstrate its application to the
aerodynamic optimization of 4-digit NACA airfoils. The framework consists of
three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems
Engineer. The Graph Ontologist employs a Large Language Model (LLM) to
construct two domain-specific knowledge graphs from airfoil design literature.
The Systems Engineer, informed by a human manager, formulates technical
requirements that guide design generation and evaluation. The Design Engineer
leverages the design knowledge graph and computational tools to propose
candidate airfoils meeting these requirements. The Systems Engineer reviews and
provides feedback both qualitative and quantitative using its own knowledge
graph, forming an iterative feedback loop until a design is validated by the
manager. The final design is then optimized to maximize performance metrics
such as the lift-to-drag ratio. Overall, this work demonstrates how
collaborative AI agents equipped with structured knowledge representations can
enhance efficiency, consistency, and quality in the engineering design process.

</details>


### [6] [A Proprietary Model-Based Safety Response Framework for AI Agents](https://arxiv.org/abs/2511.03138)
*Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao*

Main category: cs.AI

TL;DR: 이 논문은 대형 언어 모델(LLM)의 입력 및 출력 수준에서 안전성을 체계적으로 보장하는 새로운 안전 반응 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 널리 퍼진 응용과 관련된 보안 문제는 점점 두드러지게 나타나고 있으며, 이는 중요한 분야에서의 신뢰할 수 있는 배치를 심각하게 제약하고 있다.

Method: 입력 수준에서 감독된 미세 조정 기반 안전 분류 모델을 사용하여 사용자 쿼리의 정확한 위험 식별과 차별화된 처리를 수행한다. 출력 수준에서는 정보의 실시간 신뢰할 수 있는 지식 기반에 근거한 응답을 보장하기 위해 RAG와 미세 조정된 해석 모델을 통합한다.

Result: 실험 결과, 제안된 안전 제어 모델이 공공 안전 평가 기준에서 기존 모델인 TinyR1-Safety-8B보다 훨씬 높은 안전 점수를 달성했으며, 자체 고위험 테스트 세트에서도 100% 안전 점수를 기록했다.

Conclusion: 이 연구는 고안전, 고신뢰의 LLM 응용 프로그램을 구축하기 위한 효과적인 엔지니어링 경로를 제공한다.

Abstract: With the widespread application of Large Language Models (LLMs), their
associated security issues have become increasingly prominent, severely
constraining their trustworthy deployment in critical domains. This paper
proposes a novel safety response framework designed to systematically safeguard
LLMs at both the input and output levels. At the input level, the framework
employs a supervised fine-tuning-based safety classification model. Through a
fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused
Attention), it performs precise risk identification and differentiated handling
of user queries, significantly enhancing risk coverage and business scenario
adaptability, and achieving a risk recall rate of 99.3%. At the output level,
the framework integrates Retrieval-Augmented Generation (RAG) with a
specifically fine-tuned interpretation model, ensuring all responses are
grounded in a real-time, trustworthy knowledge base. This approach eliminates
information fabrication and enables result traceability. Experimental results
demonstrate that our proposed safety control model achieves a significantly
higher safety score on public safety evaluation benchmarks compared to the
baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk
test set, the framework's components attained a perfect 100% safety score,
validating their exceptional protective capabilities in complex risk scenarios.
This research provides an effective engineering pathway for building
high-security, high-trust LLM applications.

</details>


### [7] [Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning](https://arxiv.org/abs/2511.03724)
*Richard Dewey,Janos Botyanszki,Ciamac C. Moallemi,Andrew T. Zheng*

Main category: cs.AI

TL;DR: 첫 번째 AI 에이전트 Solly가 Liar's Poker에서 엘리트 인간 플레이를 달성했습니다.


<details>
  <summary>Details</summary>
Motivation: 다인 동적 및 불완전한 정보 환경을 갖춘 게임에서 AI 연구자들이 테스트베드로 포커와 유사한 게임을 오랫동안 집중적으로 연구해왔습니다.

Method: 모델이 없는 배우-비평자 심층 강화 학습 알고리즘으로 자기 놀이를 통해 Solly를 훈련했습니다.

Result: Solly는 헤드업 및 다인 Liar's Poker에서 50% 이상의 핸드를 이기고, 수익 측면에서도 엘리트 인간 수준의 플레이를 했습니다.

Conclusion: Solly는 신뢰할 수 없는 인간 플레이어에게 쉽게 이용당하지 않고 독창적인 입찰 전략을 개발하고 효과적으로 무작위 플레이를 수행했습니다.

Abstract: AI researchers have long focused on poker-like games as a testbed for
environments characterized by multi-player dynamics, imperfect information, and
reasoning under uncertainty. While recent breakthroughs have matched elite
human play at no-limit Texas hold'em, the multi-player dynamics are subdued:
most hands converge quickly with only two players engaged through multiple
rounds of bidding. In this paper, we present Solly, the first AI agent to
achieve elite human play in reduced-format Liar's Poker, a game characterized
by extensive multi-player engagement. We trained Solly using self-play with a
model-free, actor-critic, deep reinforcement learning algorithm. Solly played
at an elite human level as measured by win rate (won over 50% of hands) and
equity (money won) in heads-up and multi-player Liar's Poker. Solly also
outperformed large language models (LLMs), including those with reasoning
abilities, on the same metrics. Solly developed novel bidding strategies,
randomized play effectively, and was not easily exploitable by world-class
human players.

</details>


### [8] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: 이 연구는 Adobe Summit을 위한 도메인 특화 AI 어시스턴트인 Summit Concierge를 소개하며, 이벤트 관련 쿼리를 처리하고 실제 제약 사항을 고려한 개발 공정을 강조한다.


<details>
  <summary>Details</summary>
Motivation: Generative AI 어시스턴트는 생산성을 향상하고 정보 접근을 간소화하며 사용자 경험을 개선할 수 있는 잠재력을 지니고 있다.

Method: 우리는 프롬프트 엔지니어링, 검색 기반 접근법, 경량 인간 검증을 결합한 인간-순환 개발 워크플로우를 채택하였다.

Result: 시스템 아키텍처와 개발 과정, 실제 배포 결과를 기술하며, 피드백 기반의 민첩한 개발이 확장 가능하고 신뢰할 수 있는 AI 어시스턴트를 가능하게 함을 보여준다.

Conclusion: 추가적으로, 이 방법론이 초기 단계에서도 효과적임을 입증하고 있다.

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [9] [Quantum-Classical Hybrid Encryption Framework Based on Simulated BB84 and AES-256: Design and Experimental Evaluation](https://arxiv.org/abs/2511.02836)
*Hector E Mozo*

Main category: cs.CR

TL;DR: 하이브리드 암호화 프레임워크를 설계, 구현 및 평가한 논문으로, 양자 키 배포와 AES-256 암호화를 결합하였습니다.


<details>
  <summary>Details</summary>
Motivation: 양자 기반의 보안 파일 암호화를 통해 현대의 사이버 보안 시스템을 강화하고자 함.

Method: 양자 원리에 기반한 키 생성과 고전 암호화를 결합한 하이브리드 암호화 프레임워크를 설계하고, HMAC 검증 및 선택적 포스트 양자 디지털 서명을 포함하여 작동하는 시스템을 Python으로 구현.

Result:  다양한 공격 시나리오에 대한 실험적 결과를 통해 접근법의 효과성과 회복력을 입증하였다.

Conclusion: 제안된 해결책은 양자 인식 사이버 보안 시스템을 위한 실용적인 기반으로 작용한다.

Abstract: This paper presents the design, implementation, and evaluation of a hybrid
encryption framework that combines quantum key distribution, specifically a
simulated BB84 protocol, with AES-256 encryption. The system enables secure
file encryption by leveraging quantum principles for key generation and
classical cryptography for data protection. It introduces integrity validation
mechanisms, including HMAC verification and optional post-quantum digital
signatures, ensuring robustness even in the presence of quantum-capable
adversaries. The entire architecture is implemented in Python, with modular
components simulating quantum key exchange, encryption, and secure packaging.
Experimental results include visual testing of various attack scenarios, such
as key tampering, HMAC failure, and file corruption, demonstrating the
effectiveness and resilience of the approach. The proposed solution serves as a
practical foundation for quantum-aware cybersecurity systems.

</details>


### [10] [AI Agents with Decentralized Identifiers and Verifiable Credentials](https://arxiv.org/abs/2511.02841)
*Sandro Rodriguez Garzon,Awid Vaziry,Enis Mert Kuzu,Dennis Enrique Gehrmann,Buse Varkan,Alexander Gaballa,Axel Küpper*

Main category: cs.CR

TL;DR: 이 논문은 에이전트 간의 신뢰 구축을 위한 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 AI 에이전트는 에이전트 간 대화의 시작에서 자동으로 차별화된 신뢰를 구축하는 기술적 수단이 부족합니다.

Method: 각 에이전트에 자주권 디지털 ID를 부여하고, 제3자에 의해 제공되는 변조 방지 및 유연한 ID 기반 증명을 도입하는 방법을 제안합니다.

Result: 시범 구현을 통해 기술적 실행 가능성을 입증했지만, 에이전트의 LLM이 보안 절차를 단독으로 제어할 때의 한계를 드러냅니다.

Conclusion: 에이전트의 자율적이며 상호 운용 가능한 신뢰 구축이 필수적이라는 점이 강조됩니다.

Abstract: LLM-based AI agents still lack the technical means to automatically build
nuanced and differentiated trust in other agents at the beginning of an
agent-to-agent dialogue. But autonomous and interoperable trust establishing
becomes a fundamental prerequisite once agents start to operate beyond isolated
environments and engage in dialogues across individual or organizational
boundaries. A promising way to fill this gap in Agentic AI is to equip agents
with long-lived digital identities and introduce tamper-proof and flexible
identity-bound attestations of agents, provisioned by commonly trusted third
parties and designed for cross-domain verifiability. This article presents a
conceptual framework and a prototypical multi-agent system, where each agent is
endowed with a self-sovereign digital identity. It combines a unique and
ledger-anchored Decentralized Identifier (DID) of an agent with a set of
third-party issued Verifiable Credentials (VCs). This enables agents at the
start of a dialog to prove ownership of their self-controlled DIDs for
authentication purposes and to establish various cross-domain trust
relationships through the spontaneous exchange of their self-hosted DID-bound
VCs. A comprehensive evaluation of the prototypical implementation demonstrates
technical feasibility but also reveals limitations once an agent's LLM is in
sole charge to control the respective security procedures.

</details>


### [11] [Auditing M-LLMs for Privacy Risks: A Synthetic Benchmark and Evaluation Framework](https://arxiv.org/abs/2511.03248)
*Junhao Li,Jiahao Chen,Zhou Feng,Chunyi Zhou*

Main category: cs.CR

TL;DR: 다중 모달 대규모 언어 모델(M-LLM)의 발전은 이미지와 텍스트를 포함한 다양한 출처로부터 암묵적인 정보를 합성하는 강력한 능력을 증명했습니다.


<details>
  <summary>Details</summary>
Motivation: 소셜 미디어에서 수집되는 데이터는 민감한 개인 속성을 추론할 수 있는 심각한 프라이버시 위험을 초래합니다.

Method: PRISM이라는 첫 번째 다중 모달, 다차원, 세분화된 합성 데이터 세트를 제안하며, 효율적인 평가 프레임워크를 통해 M-LLM의 크로스 모달 프라이버시 추론 능력을 측정합니다.

Result: PRISM은 다양한 다중 모달 프로파일에 걸쳐 12개의 민감한 속성 레이블을 가지고 있으며, 6개의 선도적인 M-LLM들의 추론 능력을 평가했습니다.

Conclusion: M-LLM은 정확성과 효율성에서 인간 성능을 크게 초과했으며, 이는 잠재적인 프라이버시 위험과 강력한 방어의 필요성을 강조합니다.

Abstract: Recent advances in multi-modal Large Language Models (M-LLMs) have
demonstrated a powerful ability to synthesize implicit information from
disparate sources, including images and text. These resourceful data from
social media also introduce a significant and underexplored privacy risk: the
inference of sensitive personal attributes from seemingly daily media content.
However, the lack of benchmarks and comprehensive evaluations of
state-of-the-art M-LLM capabilities hinders the research of private attribute
profiling on social media. Accordingly, we propose (1) PRISM, the first
multi-modal, multi-dimensional and fine-grained synthesized dataset
incorporating a comprehensive privacy landscape and dynamic user history; (2)
an Efficient evaluation framework that measures the cross-modal privacy
inference capabilities of advanced M-LLM. Specifically, PRISM is a large-scale
synthetic benchmark designed to evaluate cross-modal privacy risks. Its key
feature is 12 sensitive attribute labels across a diverse set of multi-modal
profiles, which enables targeted privacy analysis. These profiles are generated
via a sophisticated LLM agentic workflow, governed by a prior distribution to
ensure they realistically mimic social media users. Additionally, we propose a
Multi-Agent Inference Framework that leverages a pipeline of specialized LLMs
to enhance evaluation capabilities. We evaluate the inference capabilities of
six leading M-LLMs (Qwen, Gemini, GPT-4o, GLM, Doubao, and Grok) on PRISM. The
comparison with human performance reveals that these MLLMs significantly
outperform in accuracy and efficiency, highlighting the threat of potential
privacy risks and the urgent need for robust defenses.

</details>


### [12] [Two thousand years of the oracle problem. Insights from Ancient Delphi on the future of blockchain oracles](https://arxiv.org/abs/2511.03319)
*Giulio Caldarelli,Massimiliano Ornaghi*

Main category: cs.CR

TL;DR: 오라클 문제는 정보의 진위와 편향성을 구별하는 데 어려움을 겪는 에이전트의 한계를 다룬다. 본 연구는 고대 델파이 오라클과 현대 블록체인 오라클을 비교하는 프레임워크를 개발하고, 델파이 질문 167개에 대한 언어 분석을 통해 오라클의 답변 품질과 질문 유형 간의 관계를 조명한다.


<details>
  <summary>Details</summary>
Motivation: 오라클 예측의 신뢰성을 평가하고 증대시키며 보장하는 방법에 대한 고전적인 논의는 여전히 현대에도 중요한 과제이다.

Method: 고대 델파이 오라클과 현대 블록체인 오라클 간의 비교 프레임워크를 개발하고, 델파이 질문에 대한 언어 분석을 수행하여 오라클 응답 품질을 질문 유형과 연결 지었다.

Result: 본 연구는 고전적 오라클과 컴퓨터 오라클 간의 공통점을 드러내고, 블록체인 오라클의 신뢰성을 증진하는 전략을 제안한다.

Conclusion: 본 연구는 델파이의 통찰력과 고전 문헌을 바탕으로 현대 블록체인 오라클의 신뢰성 향상을 위한 전략을 제안하며, 고대 오라클 메커니즘을 해석하고 분류할 수 있는 프레임워크를 제공한다.

Abstract: The oracle problem refers to the inability of an agent to know if the
information coming from an oracle is authentic and unbiased. In ancient times,
philosophers and historians debated on how to evaluate, increase, and secure
the reliability of oracle predictions, particularly those from Delphi, which
pertained to matters of state. Today, we refer to data carriers for automatic
machines as oracles, but establishing a secure channel between these oracles
and the real world still represents a challenge. Despite numerous efforts, this
problem remains mostly unsolved, and the recent advent of blockchain oracles
has added a layer of complexity because of the decentralization of blockchains.
This paper conceptually connects Delphic and modern blockchain oracles,
developing a comparative framework. Leveraging blockchain oracle taxonomy,
lexical analysis is also performed on 167 Delphic queries to shed light on the
relationship between oracle answer quality and question type. The presented
framework aims first at revealing commonalities between classical and
computational oracles and then at enriching the oracle analysis within each
field. This study contributes to the computer science literature by proposing
strategies to improve the reliability of blockchain oracles based on insights
from Delphi and to classical literature by introducing a framework that can
also be applied to interpret and classify other ancient oracular mechanisms.

</details>


### [13] [Federated Anonymous Blocklisting across Service Providers and its Application to Group Messaging](https://arxiv.org/abs/2511.03486)
*David Soler,Carlos Dafonte,Manuel Fernández-Veiga,Ana Fernández Vilas,Francisco J. Nóvoa*

Main category: cs.CR

TL;DR: 본 논문에서는 중앙화된 서비스 제공자를 소규모 분산된 영역으로 대체한 연합 익명 블랙리스트(FAB) 방안을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 온라인 메시징 그룹에서 익명 사용자로 인한 문제를 해결하기 위해서입니다.

Method: 연합 익명 블랙리스트(FAB) 방식을 제안하고, 각 영역이 고유한 블랙리스트를 유지하며 서로 신뢰 관계를 설정하는 방식을 채택합니다.

Result: 제안한 방안의 구현을 제공하며, 성능은 블랙리스트의 크기에 의존하지 않고, 블랙리스트의 신규 추가를 처리할 필요가 없습니다.

Conclusion: FAB 방안은 실제 메시징 그룹에 적용 가능성을 보여줍니다.

Abstract: Instant messaging has become one of the most used methods of communication
online, which has attracted significant attention to its underlying
cryptographic protocols and security guarantees. Techniques to increase privacy
such as End-to-End Encryption and pseudonyms have been introduced. However,
online spaces such as messaging groups still require moderation to prevent
misbehaving users from participating in them, particularly in anonymous
contexts.. In Anonymous Blocklisting (AB) schemes, users must prove during
authentication that none of their previous pseudonyms has been blocked,
preventing misbehaving users from creating new pseudonyms. In this work we
propose an alternative \textit{Federated Anonymous Blocklisting} (FAB) in which
the centralised Service Provider is replaced by small distributed Realms, each
with its own blocklist. Realms can establish trust relationships between each
other, such that when users authenticate to a realm, they must prove that they
are not banned in any of its trusted realms. We provide an implementation of
our proposed scheme; unlike existing AB constructions, the performance of ours
does not depend on the current size of the blocklist nor requires processing
new additions to the blocklist. We also demonstrate its applicability to
real-world messaging groups by integrating our FAB scheme into the Messaging
Layer Security protocol.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [Scaling Multi-Agent Environment Co-Design with Diffusion Models](https://arxiv.org/abs/2511.03100)
*Hao Xiang Li,Michael Amir,Amanda Prorok*

Main category: cs.LG

TL;DR: 이 논문은 에이전트와 환경의 공동 디자인을 위한 새로운 방법, Diffusion Co-Design (DiCoDe)를 제안하여 높은 차원의 환경 설계에서의 문제와 샘플 비효율성을 해결하고 실제 유용한 설정으로의 확장을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 현재의 공동 디자인 방법들은 고차원 환경 설계 공간에서 축소되고, 공동 최적화에서 발생하는 이동하는 목표에 대한 샘플 비효율성으로 어려움을 겪고 있다.

Method: DiCoDe는 환경 및 정책의 공동 최적화를 향상시키기 위해 두 가지 핵심 혁신을 도입한다. 첫 번째로, PUG라는 샘플링 기술을 도입하여 장애물 간의 공간적 분리를 포함한 강력한 제약을 만족시키면서 보상이 최대화되는 환경 분포를 탐색할 수 있도록 한다. 두 번째로, 강화 학습 비평가로부터 지식을 공유하는 비평가 증류 메커니즘을 개발하여, 최신 학습 신호를 사용해 정책 변화에 적응하는 지침 확산 모델을 보장한다.

Result: 이 방법은 다중 에이전트 환경 공동 디자인 기준에서 검증했을 때 우수한 환경-정책 쌍을 생성하며, 예를 들어 창고 환경에서 39% 더 높은 보상을 얻으면서 66% 적은 시뮬레이션 샘플로 이를 달성했다.

Conclusion: 이 연구는 에이전트-환경 공동 디자인에서 새로운 기준을 세우며, 실제 도메인에서 공동 디자인의 이익을 실현하기 위한 디딤돌이 된다.

Abstract: The agent-environment co-design paradigm jointly optimises agent policies and
environment configurations in search of improved system performance. With
application domains ranging from warehouse logistics to windfarm management,
co-design promises to fundamentally change how we deploy multi-agent systems.
However, current co-design methods struggle to scale. They collapse under
high-dimensional environment design spaces and suffer from sample inefficiency
when addressing moving targets inherent to joint optimisation. We address these
challenges by developing Diffusion Co-Design (DiCoDe), a scalable and
sample-efficient co-design framework pushing co-design towards practically
relevant settings. DiCoDe incorporates two core innovations. First, we
introduce Projected Universal Guidance (PUG), a sampling technique that enables
DiCoDe to explore a distribution of reward-maximising environments while
satisfying hard constraints such as spatial separation between obstacles.
Second, we devise a critic distillation mechanism to share knowledge from the
reinforcement learning critic, ensuring that the guided diffusion model adapts
to evolving agent policies using a dense and up-to-date learning signal.
Together, these improvements lead to superior environment-policy pairs when
validated on challenging multi-agent environment co-design benchmarks including
warehouse automation, multi-agent pathfinding and wind farm optimisation. Our
method consistently exceeds the state-of-the-art, achieving, for example, 39%
higher rewards in the warehouse setting with 66% fewer simulation samples. This
sets a new standard in agent-environment co-design, and is a stepping stone
towards reaping the rewards of co-design in real world domains.

</details>


### [15] [Test-time Adaptation of Tiny Recursive Models](https://arxiv.org/abs/2511.02886)
*Ronan Killian McGovern*

Main category: cs.LG

TL;DR: 이 논문은 경쟁 제한 내에서 미세 조정된 모델이 ARC 과제에서 성능을 향상시킬 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 2025 ARC 상금 경쟁에서 허용된 컴퓨팅 범위 내에서 효율적으로 미세 조정되는 모델을 탐구하기 위해.

Method: 공식 ARC 작업에 대해 사전 훈련된 작은 재귀 모델을 기반으로 하여 경쟁 작업에 대해 미세 조정을 수행했다.

Result: 모델은 공공 평가 세트에서 약 10%의 점수를 얻었고 경쟁 동안 6.67%의 점수에 도달했다.

Conclusion: 작은 모델의 완전 미세 조정을 통해 포스트 트레이닝 성능이 향상되었다.

Abstract: Prior to the close of the 2025 ARC Prize competition, the leading open source
approach - known as TRM, or Tiny Recursive Models - involved training a 7M
parameter recursive neural network on augmented variants of ARC tasks. That
approach scored approximately 7.8% on the public ARC AGI II evaluation set, but
required a level of compute far in excess of what is allowed during the
competition. This paper shows that, by starting from a tiny recursive model
that has been pre-trained on public ARC tasks, one can efficiently fine-tune on
competition tasks within the allowed compute limits. Specifically, a model was
pre-trained on 1,280 public tasks for 700k+ optimizer steps over 48 hours on
4xH100 SXM GPUs to obtain a ~10% score on the public evaluation set. That model
was then post-trained in just 12,500 gradient steps during the competition to
reach a score of 6.67% on semi-private evaluation tasks. Notably, such
post-training performance is achieved by full-fine tuning of the tiny model,
not LoRA fine-tuning or fine-tuning of task embeddings alone.

</details>


### [16] [GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models](https://arxiv.org/abs/2511.03251)
*Zhibin Wang,Zhixing Zhang,Shuqi Wang,Xuanting Xie,Zhao Kang*

Main category: cs.LG

TL;DR: GMoPE는 그래프에 대한 프롬프트 기반 학습과 전문가 혼합 아키텍처를 통합하여 GNN의 일반화 문제를 해결하는 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 그래프 신경망의 다양한 도메인과 작업에 대한 일반화 능력을 향상시키기 위한 필요성.

Method: Mixture-of-Experts 아키텍처와 프롬프트 기반 학습을 통합한 GMoPE 프레임워크를 제안하며, 전문가 특화 프롬프트 벡터와 구조 인식 MoE 라우팅을 활용한다.

Result: GMoPE는 여러 사전 학습 전략과 다운스트림 작업에 대한 실험을 통해 기존 최첨단 성능을 지속적으로 초월하고, 적응 오버헤드의 일부만으로 전체 매개변수 조정에 준하는 성능을 달성하였다.

Conclusion: GMoPE는 일반화 가능하고 효율적인 그래프 기초 모델 발전을 위한 체계적이고 확장 가능한 프레임워크를 제공한다.

Abstract: Graph Neural Networks (GNNs) have demonstrated impressive performance on
task-specific benchmarks, yet their ability to generalize across diverse
domains and tasks remains limited. Existing approaches often struggle with
negative transfer, scalability issues, and high adaptation costs. To address
these challenges, we propose GMoPE (Graph Mixture of Prompt-Experts), a novel
framework that seamlessly integrates the Mixture-of-Experts (MoE) architecture
with prompt-based learning for graphs. GMoPE leverages expert-specific prompt
vectors and structure-aware MoE routing to enable each expert to specialize in
distinct subdomains and dynamically contribute to predictions. To promote
diversity and prevent expert collapse, we introduce a soft orthogonality
constraint across prompt vectors, encouraging expert specialization and
facilitating a more balanced expert utilization. Additionally, we adopt a
prompt-only fine-tuning strategy that significantly reduces spatiotemporal
complexity during transfer. We validate GMoPE through extensive experiments
under various pretraining strategies and multiple downstream tasks. Results
show that GMoPE consistently outperforms state-of-the-art baselines and
achieves performance comparable to full parameter fine-tuning-while requiring
only a fraction of the adaptation overhead. Our work provides a principled and
scalable framework for advancing generalizable and efficient graph foundation
models.

</details>


### [17] [Efficient Neural Networks with Discrete Cosine Transform Activations](https://arxiv.org/abs/2511.03531)
*Marc Martinez-Gost,Sara Pepe,Ana Pérez-Neira,Miguel Ángel Lagunas*

Main category: cs.LG

TL;DR: Expressive Neural Network(ENN)의 효율성, 해석 가능성 및 가지치기 기능을 강조하며, DCT를 사용한 파라미터화로 성능 손실 없이 비최소 DCT 계수를 제거하는 가지치기 전략을 제안한다.


<details>
  <summary>Details</summary>
Motivation: ENN의 강력한 표현력과 compact architecture에 대한 이전 연구를 바탕으로, 효율성과 해석 가능성, 그리고 가지치기 기능을 강조하고자 함.

Method: DCT 기반의 파라미터화로 각 뉴런의 기능적 역할을 분명하게 드러내고, 불필요한 DCT 계수를 제거하는 효율적인 가지치기 전략을 개발함.

Result: 분류 및 암묵적 신경 표현 작업을 통해 ENNs가 최첨단 정확도를 달성하면서도 적은 파라미터 수를 유지하는 것을 확인함. 최대 40%의 활성화 계수를 안전하게 가지칠 수 있었음.

Conclusion: 이 연구 결과는 ENN 프레임워크가 신호 처리 개념을 신경망 설계에 통합할 수 있는 원칙적인 접근을 제공하며, 표현력, 압축성 및 해석 가능성 간의 균형 잡힌 트레이드오프를 달성함을 보여준다.

Abstract: In this paper, we extend our previous work on the Expressive Neural Network
(ENN), a multilayer perceptron with adaptive activation functions parametrized
using the Discrete Cosine Transform (DCT). Building upon previous work that
demonstrated the strong expressiveness of ENNs with compact architectures, we
now emphasize their efficiency, interpretability and pruning capabilities. The
DCT-based parameterization provides a structured and decorrelated
representation that reveals the functional role of each neuron and allows
direct identification of redundant components. Leveraging this property, we
propose an efficient pruning strategy that removes unnecessary DCT coefficients
with negligible or no loss in performance. Experimental results across
classification and implicit neural representation tasks confirm that ENNs
achieve state-of-the-art accuracy while maintaining a low number of parameters.
Furthermore, up to 40% of the activation coefficients can be safely pruned,
thanks to the orthogonality and bounded nature of the DCT basis. Overall, these
findings demonstrate that the ENN framework offers a principled integration of
signal processing concepts into neural network design, achieving a balanced
trade-off between expressiveness, compactness, and interpretability.

</details>


### [18] [Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances](https://arxiv.org/abs/2511.03565)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 모방 학습(IL)은 에이전트가 전문가의 행동을 관찰하고 복제함으로써 기술을 습득할 수 있도록 한다. 이 연구에서는 최근의 모방 학습 발전을 검토하고, 새로운 방법론과 실제 적용 사례를 강조하며, IL 연구의 현재 상태와 동향을 반영하기 위한 새로운 분류법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 모방 학습의 발전과 새로운 접근 방식들이 연구에 반영되도록 하는 것.

Method: 최근의 연구 동향, 방법론 혁신, 그리고 실제 적용 사례를 검토하고 새로운 분류법을 제안함.

Result: 모방 학습 연구의 최신 발전과 트렌드를 강조하고, 대표적인 작업들의 강점, 한계 및 평가 방법을 검토함.

Conclusion: 미래 연구를 위한 주요 과제와 열린 방향을 제시한다.

Abstract: Imitation learning (IL) enables agents to acquire skills by observing and
replicating the behavior of one or multiple experts. In recent years, advances
in deep learning have significantly expanded the capabilities and scalability
of imitation learning across a range of domains, where expert data can range
from full state-action trajectories to partial observations or unlabeled
sequences. Alongside this growth, novel approaches have emerged, with new
methodologies being developed to address longstanding challenges such as
generalization, covariate shift, and demonstration quality. In this survey, we
review the latest advances in imitation learning research, highlighting recent
trends, methodological innovations, and practical applications. We propose a
novel taxonomy that is distinct from existing categorizations to better reflect
the current state of the IL research stratum and its trends. Throughout the
survey, we critically examine the strengths, limitations, and evaluation
practices of representative works, and we outline key challenges and open
directions for future research.

</details>


### [19] [AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing](https://arxiv.org/abs/2511.03697)
*Mohsen Ahmadzadeh,Kaichang Chen,Georges Gielen*

Main category: cs.LG

TL;DR: 이 논문은 표본 효율적이고 설명 가능한 아날로그 회로 크기 조정 방법을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 아날로그/혼합 신호 회로 설계가 주로 수작업으로 이루어져 긴 설계 주기와 오류 발생 가능성이 높아지는 문제를 해결하고자 합니다.

Method: 다중 에이전트 작업 흐름을 사용하여 LLM 기반 에이전트들이 회로 토폴로지를 해석하고 설계 목표를 이해하며, 인간이 해석 가능한 추론을 통해 설계 매개변수를 반복적으로 조정합니다.

Result: AnaFlow 프레임워크는 다양한 복잡성을 가진 두 개의 회로에서 완전 자동으로 크기 조정 작업을 수행할 수 있음을 입증하였습니다.

Conclusion: 이 시스템은 과거의 실수를 피하고 수렴 속도를 높이기 위해 최적화 히스토리에서 학습하여 아날로그 설계 공간 탐색에 강력한 도구가 됩니다.

Abstract: Analog/mixed-signal circuits are key for interfacing electronics with the
physical world. Their design, however, remains a largely handcrafted process,
resulting in long and error-prone design cycles. While the recent rise of
AI-based reinforcement learning and generative AI has created new techniques to
automate this task, the need for many time-consuming simulations is a critical
bottleneck hindering the overall efficiency. Furthermore, the lack of
explainability of the resulting design solutions hampers widespread adoption of
the tools. To address these issues, a novel agentic AI framework for
sample-efficient and explainable analog circuit sizing is presented. It employs
a multi-agent workflow where specialized Large Language Model (LLM)-based
agents collaborate to interpret the circuit topology, to understand the design
goals, and to iteratively refine the circuit's design parameters towards the
target goals with human-interpretable reasoning. The adaptive simulation
strategy creates an intelligent control that yields a high sample efficiency.
The AnaFlow framework is demonstrated for two circuits of varying complexity
and is able to complete the sizing task fully automatically, differently from
pure Bayesian optimization and reinforcement learning approaches. The system
learns from its optimization history to avoid past mistakes and to accelerate
convergence. The inherent explainability makes this a powerful tool for analog
design space exploration and a new paradigm in analog EDA, where AI agents
serve as transparent design assistants.

</details>


### [20] [Digital Twin-Driven Pavement Health Monitoring and Maintenance Optimization Using Graph Neural Networks](https://arxiv.org/abs/2511.02957)
*Mohsin Mahmud Topu,Mahfuz Ahmed Anik,Azmine Toushik Wasi,Md Manjurul Ahsan*

Main category: cs.LG

TL;DR: 이 연구는 데이터 기반의 도로 건강 모니터링과 예측 유지보수를 위한 통합 디지털 트윈(DT) 및 그래프 신경망(GNN) 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 도로 관리 시스템(PMS)은 실시간 정보가 부족하여 실패 예방과 최적의 유지보수 계획을 제공하는데 한계가 있습니다.

Method: 도로 구간과 공간 관계를 그래프 노드와 간선으로 모델링하고, 실시간 UAV, 센서 및 LiDAR 데이터를 DT로 스트리밍합니다. 유도 GNN은 그래프 구조 입력에서 열화 패턴을 학습하여 고장을 예측하고 사전 대응을 가능하게 합니다.

Result: 실제 데이터셋을 바탕으로 훈련된 모델은 R2 0.3798을 달성하며, 기준 회귀 모델을 초과하여 비선형 열화를 효과적으로 포착합니다.

Conclusion: 이 DT-GNN 통합은 예측 정확도를 향상시키고 지속적인 개선을 위한 피드백 루프를 구축하며, 지능적이고 지속 가능한 도로 관리를 위한 기반을 마련합니다.

Abstract: Pavement infrastructure monitoring is challenged by complex spatial
dependencies, changing environmental conditions, and non-linear deterioration
across road networks. Traditional Pavement Management Systems (PMS) remain
largely reactive, lacking real-time intelligence for failure prevention and
optimal maintenance planning. To address this, we propose a unified Digital
Twin (DT) and Graph Neural Network (GNN) framework for scalable, data-driven
pavement health monitoring and predictive maintenance. Pavement segments and
spatial relations are modeled as graph nodes and edges, while real-time UAV,
sensor, and LiDAR data stream into the DT. The inductive GNN learns
deterioration patterns from graph-structured inputs to forecast distress and
enable proactive interventions. Trained on a real-world-inspired dataset with
segment attributes and dynamic connectivity, our model achieves an R2 of
0.3798, outperforming baseline regressors and effectively capturing non-linear
degradation. We also develop an interactive dashboard and reinforcement
learning module for simulation, visualization, and adaptive maintenance
planning. This DT-GNN integration enhances forecasting precision and
establishes a closed feedback loop for continuous improvement, positioning the
approach as a foundation for proactive, intelligent, and sustainable pavement
management, with future extensions toward real-world deployment, multi-agent
coordination, and smart-city integration.

</details>


### [21] [Leveraging Discrete Function Decomposability for Scientific Design](https://arxiv.org/abs/2511.03032)
*James C. Bowden,Sergey Levine,Jennifer Listgarten*

Main category: cs.LG

TL;DR: 이 논문에서는 분해 인식 분포 최적화(DADO) 알고리즘을 제안하여 유전적 설계 공간에서의 최적화를 효율적으로 수행하는 방법을 다룹니다.


<details>
  <summary>Details</summary>
Motivation: AI 기반 과학 및 공학 시대에 사용자 지정 속성에 따라 이산 객체를 설계하려는 필요성이 증가하고 있습니다.

Method: 본 논문에서는 조합적 특성을 고려하여 설계 변수를 통해 정의된 분해 가능성을 활용하는 새로운 분포 최적화 알고리즘인 DADO를 제안합니다.

Result: DADO는 디자인 변수가 연결된 요소 간의 최적화를 효율적으로 협조하기 위해 그래프 메시지 전달을 활용하는 학습된 생성 모델인 소프트-팩토리화 '검색 분포'를 사용합니다.

Conclusion: DADO 알고리즘을 통해 최적화의 효율성을 크게 향상시킬 수 있으며, 이는 과학적 응용 분야에서의 유용성을 높입니다.

Abstract: In the era of AI-driven science and engineering, we often want to design
discrete objects in silico according to user-specified properties. For example,
we may wish to design a protein to bind its target, arrange components within a
circuit to minimize latency, or find materials with certain properties. Given a
property predictive model, in silico design typically involves training a
generative model over the design space (e.g., protein sequence space) to
concentrate on designs with the desired properties. Distributional optimization
-- which can be formalized as an estimation of distribution algorithm or as
reinforcement learning policy optimization -- finds the generative model that
maximizes an objective function in expectation. Optimizing a distribution over
discrete-valued designs is in general challenging because of the combinatorial
nature of the design space. However, many property predictors in scientific
applications are decomposable in the sense that they can be factorized over
design variables in a way that could in principle enable more effective
optimization. For example, amino acids at a catalytic site of a protein may
only loosely interact with amino acids of the rest of the protein to achieve
maximal catalytic activity. Current distributional optimization algorithms are
unable to make use of such decomposability structure. Herein, we propose and
demonstrate use of a new distributional optimization algorithm,
Decomposition-Aware Distributional Optimization (DADO), that can leverage any
decomposability defined by a junction tree on the design variables, to make
optimization more efficient. At its core, DADO employs a soft-factorized
"search distribution" -- a learned generative model -- for efficient navigation
of the search space, invoking graph message-passing to coordinate optimization
across linked factors.

</details>


### [22] [Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions](https://arxiv.org/abs/2511.03047)
*Emi Soroka,Tanmay Chopra,Krish Desai,Sanjay Lall*

Main category: cs.LG

TL;DR: 대규모 언어 모델은 목표 지향적인 상호작용에서 AI 에이전트와 인간이 참여하는 기업 애플리케이션에서 인기를 얻고 있지만, 평가하기 어려운 데이터와 불확실한 결과 문제를 다룬다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델의 목표 지향적인 상호작용 평가의 어려움 해결.

Method: 비지도 방식의 메트릭스를 도입하여 사용자 목표 라벨링, 목표 달성 측정, LLM 불확실성 수량화를 수행.

Result: 비지도 메트릭스가 공개 도메인 및 작업 특화 상호작용 데이터에서 검증되었다.

Conclusion: 새로운 비지도 메트릭스를 통해 기존의 인간 생성 이상 응답에 기반하지 않고도 LLM 성능을 평가할 수 있다.

Abstract: Large language models (LLMs) have seen increasing popularity in enterprise
applications where AI agents and humans engage in objective-driven
interactions. However, these systems are difficult to evaluate: data may be
complex and unlabeled; human annotation is often impractical at scale; custom
metrics can monitor for specific errors, but not previously-undetected ones;
and LLM judges can produce unreliable results. We introduce the first set of
unsupervised metrics for objective-driven interactions, leveraging statistical
properties of unlabeled interaction data and using fine-tuned LLMs to adapt to
distributional shifts. We develop metrics for labeling user goals, measuring
goal completion, and quantifying LLM uncertainty without grounding evaluations
in human-generated ideal responses. Our approach is validated on open-domain
and task-specific interaction data.

</details>


### [23] [From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](https://arxiv.org/abs/2511.03128)
*Najrin Sultana,Md Rafi Ur Rashid,Kang Gu,Shagufta Mehnaz*

Main category: cs.LG

TL;DR: 이 논문에서는 LLM의 강건성을 평가하기 위한 정적 및 동적 공격 프레임워크를 소개합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 다양한 작업에 대한 제로샷 성능을 제공하지만, 민감한 작업에 적용할 때 강건성을 철저히 평가하는 것이 중요하다.

Method: Static Deceptor(StaDec)와 Dynamic Deceptor(DyDec)라는 두 가지 혁신적인 공격 프레임워크를 도입하여 LLM의 이해를 활용한 동적이고 적응적인 적대적 예제를 체계적으로 생성한다.

Result: 자연스럽고 미세한 적대적 입력을 생성하며, 원본 텍스트와 의미적 유사성을 유지하면서 목표 LLM을 효과적으로 속인다.

Conclusion: 이 연구는 LLM의 강건성을 스스로 평가하기 위한 체계적인 접근 방식을 제공하며, 코드와 데이터를 공개하였다.

Abstract: LLMs can provide substantial zero-shot performance on diverse tasks using a
simple task prompt, eliminating the need for training or fine-tuning. However,
when applying these models to sensitive tasks, it is crucial to thoroughly
assess their robustness against adversarial inputs. In this work, we introduce
Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack
frameworks designed to systematically generate dynamic and adaptive adversarial
examples by leveraging the understanding of the LLMs. We produce subtle and
natural-looking adversarial inputs that preserve semantic similarity to the
original text while effectively deceiving the target LLM. By utilizing an
automated, LLM-driven pipeline, we eliminate the dependence on external
heuristics. Our attacks evolve with the advancements in LLMs and demonstrate
strong transferability across models unknown to the attacker. Overall, this
work provides a systematic approach for the self-assessment of an LLM's
robustness. We release our code and data at
https://github.com/Shukti042/AdversarialExample.

</details>


### [24] [Periodic Skill Discovery](https://arxiv.org/abs/2511.03187)
*Jonghae Park,Daesol Cho,Jusuk Lee,Dongseok Shim,Inkyu Jang,H. Jin Kim*

Main category: cs.LG

TL;DR: 비지도 기술 발견(PSD) 프레임워크를 제안하여 주기적 행동을 효과적으로 학습할 수 있다.


<details>
  <summary>Details</summary>
Motivation: 주기적 행동이 필요한 로봇 작업을 고려했을 때, 다양한 주기적 기술을 발견하는 능력이 필수적이다.

Method: 상태를 원형 잠재 공간에 매핑하는 인코더를 훈련하여 잠재 표현에서 자연스럽게 주기성을 인코딩하는 방법을 사용한다.

Result: PSD는 복잡한 로봇 작업에서 다양한 주기를 가진 기술을 효과적으로 학습할 수 있으며, 육각장애물과 같은 다운스트림 작업에서 높은 성능을 달성한다.

Conclusion: 기존 기술 발견 방법과 PSD를 통합하면 더 다양한 행동을 제공하여 에이전트의 레퍼토리를 넓힐 수 있다.

Abstract: Unsupervised skill discovery in reinforcement learning (RL) aims to learn
diverse behaviors without relying on external rewards. However, current methods
often overlook the periodic nature of learned skills, focusing instead on
increasing the mutual dependence between states and skills or maximizing the
distance traveled in latent space. Considering that many robotic tasks --
particularly those involving locomotion -- require periodic behaviors across
varying timescales, the ability to discover diverse periodic skills is
essential. Motivated by this, we propose Periodic Skill Discovery (PSD), a
framework that discovers periodic behaviors in an unsupervised manner. The key
idea of PSD is to train an encoder that maps states to a circular latent space,
thereby naturally encoding periodicity in the latent representation. By
capturing temporal distance, PSD can effectively learn skills with diverse
periods in complex robotic tasks, even with pixel-based observations. We
further show that these learned skills achieve high performance on downstream
tasks such as hurdling. Moreover, integrating PSD with an existing skill
discovery method offers more diverse behaviors, thus broadening the agent's
repertoire. Our code and demos are available at
https://jonghaepark.github.io/psd/

</details>


### [25] [Climate Adaptation with Reinforcement Learning: Economic vs. Quality of Life Adaptation Pathways](https://arxiv.org/abs/2511.03243)
*Miguel Costa,Arthur Vandervoort,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 기후 변화로 인한 홍수 발생 빈도와 강도가 증가하고 있으며, 이는 적절한 적응 정책 수립의 필요성을 요구한다. 본 연구에서는 불확실한 조건에서의 적응 경로를 식별하고 다양한 적응 우선순위를 명시적으로 모델링할 수 있는 강화 학습(RL)의 유용성을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기후 변화가 홍수 사건의 빈도와 강도를 증가시킬 것이라는 점에서 적응 정책의 필요성이 대두되고 있다.

Method: Integrated Assessment Model (IAM)을 사용하여 강수 및 홍수 모델을 연결하고, 홍수가 삶의 질(QoL), 교통, 인프라 피해에 미치는 영향을 계산한다.

Result: QoL을 경제적 영향보다 우선시하는 모델이 더 많은 적응 지출을 유도하고, 연구 지역에 걸쳐 지출이 더욱 고르게 분포된다는 결과를 보여준다.

Conclusion: 이러한 규범적 가정이 적응 정책에 미치는 영향을 강조한다.

Abstract: Climate change will cause an increase in the frequency and severity of flood
events, prompting the need for cohesive adaptation policymaking. Designing
effective adaptation policies, however, depends on managing the uncertainty of
long-term climate impacts. Meanwhile, such policies can feature important
normative choices that are not always made explicit. We propose that
Reinforcement Learning (RL) can be a useful tool to both identify adaptation
pathways under uncertain conditions while it also allows for the explicit
modelling (and consequent comparison) of different adaptation priorities (e.g.
economic vs. wellbeing). We use an Integrated Assessment Model (IAM) to link
together a rainfall and flood model, and compute the impacts of flooding in
terms of quality of life (QoL), transportation, and infrastructure damage. Our
results show that models prioritising QoL over economic impacts results in more
adaptation spending as well as a more even distribution of spending over the
study area, highlighting the extent to which such normative assumptions can
alter adaptation policy. Our framework is publicly available:
https://github.com/MLSM-at-DTU/maat_qol_framework.

</details>


### [26] [A Probabilistic Approach to Pose Synchronization for Multi-Reference Alignment with Applications to MIMO Wireless Communication Systems](https://arxiv.org/abs/2511.03280)
*Rob Romijnders,Gabriele Cesa,Christos Louizos,Kumar Pratik,Arash Behboodi*

Main category: cs.LG

TL;DR: 다중 참조 정렬(MRA) 문제를 연구하여 새로운 알고리즘을 제안하고, 이로 인해 연산 효율성을 개선함.


<details>
  <summary>Details</summary>
Motivation: 다중 정렬 관측으로부터 신호를 정렬하고 재구성하는 능력은 시스템 성능에 매우 중요하다.

Method: 확률론적 접근을 사용하여 MRA를 모델링하고 상대적 자세를 nuisance 변수로 사용하여 새로운 알고리즘을 발견한다.

Result: 제안된 두 알고리즘 모두 실험 설정에서 낮은 재구성 오류를 달성한다.

Conclusion: 이 접근 방식의 분산화는 사이클 일관성을 통해 중앙 집중식 방법의 세제곱 증가를 피함으로써 상당한 계산 절약을 가능하게 한다.

Abstract: From molecular imaging to wireless communications, the ability to align and
reconstruct signals from multiple misaligned observations is crucial for system
performance. We study the problem of multi-reference alignment (MRA), which
arises in many real-world problems, such as cryo-EM, computer vision, and, in
particular, wireless communication systems. Using a probabilistic approach to
model MRA, we find a new algorithm that uses relative poses as nuisance
variables to marginalize out -- thereby removing the global symmetries of the
problem and allowing for more direct solutions and improved convergence. The
decentralization of this approach enables significant computational savings by
avoiding the cubic scaling of centralized methods through cycle consistency.
Both proposed algorithms achieve lower reconstruction error across experimental
settings.

</details>


### [27] [A Modular, Data-Free Pipeline for Multi-Label Intention Recognition in Transportation Agentic AI Applications](https://arxiv.org/abs/2511.03363)
*Xiaocai Zhang,Hur Lim,Ke Wang,Zhe Xiao,Jing Wang,Kelvin Lee,Xiuju Fu,Zheng Qin*

Main category: cs.LG

TL;DR: 모듈식 데이터 비의존 멀티 레이블 의도 인식 파이프라인을 제안함으로써, 기존의 대량 주석 데이터에 의존하는 방식의 한계를 극복.


<details>
  <summary>Details</summary>
Motivation: 비용이 많이 드는 데이터 수집을 피하면서 멀티 레이블 의도 이해의 정확성을 높임으로써, 교통 분야에서의 에이전틱 AI 응용에 적합한 시스템을 개발하고자 함.

Method: DMTC라는 전체 파이프라인은 크게 세 가지 단계로 구성: 1) 프롬프트 엔지니어링을 통해 다양한 교통 시나리오에서 대규모 언어 모델(LLM)이 다양한 합성 쿼리를 생성하도록 안내함; 2) 텍스트 쿼리를 Sentence-T5 모델로 인코딩하여 간결한 의미 임베딩을 얻음; 3) 어려운 샘플에 중점을 두고 클래스 간 분리를 극대화하는 새로운 온라인 포컬-대비(OFC) 손실을 사용하여 경량 분류기를 훈련.

Result: DMTC는 Hamming 손실 5.35%와 AUC 95.92%를 달성하며, 최신 멀티 레이블 분류기와 최근의 엔드 투 엔드 SOTA LLM 기반 기준을 능가함.

Conclusion: 사용자 쿼리를 작업별 모듈로 원활하게 연결하여, 비용이 많이 드는 수동 라벨링 없이도 완전 자율적인 의도 인식 에이전트를 위한 기초를 마련함.

Abstract: In this study, a modular, data-free pipeline for multi-label intention
recognition is proposed for agentic AI applications in transportation. Unlike
traditional intent recognition systems that depend on large, annotated corpora
and often struggle with fine-grained, multi-label discrimination, our approach
eliminates the need for costly data collection while enhancing the accuracy of
multi-label intention understanding. Specifically, the overall pipeline, named
DMTC, consists of three steps: 1) using prompt engineering to guide large
language models (LLMs) to generate diverse synthetic queries in different
transport scenarios; 2) encoding each textual query with a Sentence-T5 model to
obtain compact semantic embeddings; 3) training a lightweight classifier using
a novel online focal-contrastive (OFC) loss that emphasizes hard samples and
maximizes inter-class separability. The applicability of the proposed pipeline
is demonstrated in an agentic AI application in the maritime transportation
context. Extensive experiments show that DMTC achieves a Hamming loss of 5.35%
and an AUC of 95.92%, outperforming state-of-the-art multi-label classifiers
and recent end-to-end SOTA LLM-based baselines. Further analysis reveals that
Sentence-T5 embeddings improve subset accuracy by at least 3.29% over
alternative encoders, and integrating the OFC loss yields an additional 0.98%
gain compared to standard contrastive objectives. In conclusion, our system
seamlessly routes user queries to task-specific modules (e.g., ETA information,
traffic risk evaluation, and other typical scenarios in the transportation
domain), laying the groundwork for fully autonomous, intention-aware agents
without costly manual labelling.

</details>


### [28] [RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse](https://arxiv.org/abs/2511.03475)
*Yinsicheng Jiang,Yeqi Huang,Liang Cheng,Cheng Deng,Xuan Sun,Luo Mai*

Main category: cs.LG

TL;DR: RAGBoost는 높은 캐시 재사용성을 유지하면서도 정확성을 희생하지 않는 효율적인 RAG 시스템이다.


<details>
  <summary>Details</summary>
Motivation: 현대 응용 프로그램이 더 길고 복잡한 입력을 요구함에 따라 기존의 캐싱 기술은 정확성 및 재사용 간의 균형이 필요하다.

Method: RAGBoost는 중복된 검색 항목을 탐지하고, 효율적인 컨텍스트 인덱싱, 정렬 및 중복 제거를 사용하여 재사용을 극대화한다.

Result: RAGBoost는 기존 LLM 추론 엔진과 원활하게 통합되어 최첨단 방법에 비해 1.5-3배 향상된 사전 채움 성능을 보이며, 다양한 RAG 및 에이전틱 AI 작업에 걸쳐 추론 정확성을 유지 또는 향상시킨다.

Conclusion: 제공된 코드는 https://github.com/Edinburgh-AgenticAI/RAGBoost 에서 확인할 수 있다.

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with retrieved context but often suffers from downgraded prefill performance as
modern applications demand longer and more complex inputs. Existing caching
techniques either preserve accuracy with low cache reuse or improve reuse at
the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG
system that achieves high cache reuse without sacrificing accuracy through
accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items
across concurrent sessions and multi-turn interactions, using efficient context
indexing, ordering, and de-duplication to maximize reuse, while lightweight
contextual hints maintain reasoning fidelity. It integrates seamlessly with
existing LLM inference engines and improves their prefill performance by 1.5-3X
over state-of-the-art methods, while preserving or even enhancing reasoning
accuracy across diverse RAG and agentic AI workloads. Our code is released at:
https://github.com/Edinburgh-AgenticAI/RAGBoost.

</details>


### [29] [NAP: Attention-Based Late Fusion for Automatic Sleep Staging](https://arxiv.org/abs/2511.03488)
*Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci*

Main category: cs.LG

TL;DR: NAP 모델은 다중 예측 스트림을 결합하여 수면 단계 자동화를 위한 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 다양한 조합의 다채로운 폴리소믹그래피 신호를 완전히 활용하지 않는 기존 모델의 한계를 극복하고자 합니다.

Method: NAP는 삼축 주의 메커니즘을 이용하여 여러 예측 스트림을 통합하는 주의 기반 모델입니다.

Result: NAP는 여러 데이터셋에서 사전 훈련된 단일 채널 모델의 출력을 집계하여 최고의 결과를 보여줍니다.

Conclusion: NAP는 수면 단계 자동화 외에도 다른 다중 모달 생리학적 응용 프로그램에 확장 가능성을 가집니다.

Abstract: Polysomnography signals are highly heterogeneous, varying in modality
composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal,
occipital EEG), and acquisition protocols across datasets and clinical sites.
Most existing models that process polysomnography data rely on a fixed subset
of modalities or channels and therefore neglect to fully exploit its inherently
multimodal nature. We address this limitation by introducing NAP (Neural
Aggregator of Predictions), an attention-based model which learns to combine
multiple prediction streams using a tri-axial attention mechanism that captures
temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to
different input dimensions. By aggregating outputs from frozen, pretrained
single-channel models, NAP consistently outperforms individual predictors and
simple ensembles, achieving state-of-the-art zero-shot generalization across
multiple datasets. While demonstrated in the context of automated sleep staging
from polysomnography, the proposed approach could be extended to other
multimodal physiological applications.

</details>


### [30] [Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning](https://arxiv.org/abs/2511.03616)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 이 논문은 최적의 전문가로부터의 완전한 상태-행동 시연이 필요하다는 기존의 모방 학습의 한계를 극복하기 위해 깊이 있는 암묵적 모방 강화 학습 프레임워크를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 현실적인 시나리오에서는 상태 관찰만 가능하고, 전문가의 성능이 종종 최적이 아닌 경우가 많아 기존의 모방 학습이 실용성에 제한을 받는다.

Method: Deep Implicit Imitation Q-Network(DIIQN) 알고리즘은 온라인 탐색을 통해 전문가의 행동을 재구성하는 행동 추론 메커니즘과 전문가 안내와 자기 주도 학습을 동적으로 균형 잡는 신뢰 메커니즘을 통합한다.

Result: DIIQN은 표준 DQN과 비교하여 최대 130% 높은 에피소드 수익을 달성하며, 기존의 암묵적 모방 방법들을 일관되게 능가한다. HA-DIIQN은 이질적인 행동 설정에서 기존 기준보다 최대 64% 더 빠르게 학습한다.

Conclusion: 매개변수 민감도 분석 결과는 이 프레임워크가 다양한 데이터셋 크기와 하이퍼파라미터 구성을 통해 강건함을 보임을 입증한다.

Abstract: Imitation learning traditionally requires complete state-action
demonstrations from optimal or near-optimal experts. These requirements
severely limit practical applicability, as many real-world scenarios provide
only state observations without corresponding actions and expert performance is
often suboptimal. In this paper we introduce a deep implicit imitation
reinforcement learning framework that addresses both limitations by combining
deep reinforcement learning with implicit imitation learning from
observation-only datasets. Our main algorithm, Deep Implicit Imitation
Q-Network (DIIQN), employs an action inference mechanism that reconstructs
expert actions through online exploration and integrates a dynamic confidence
mechanism that adaptively balances expert-guided and self-directed learning.
This enables the agent to leverage expert guidance for accelerated training
while maintaining capacity to surpass suboptimal expert performance. We further
extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to
tackle scenarios where expert and agent possess different action sets, a
challenge previously unaddressed in the implicit imitation learning literature.
HA-DIIQN introduces an infeasibility detection mechanism and a bridging
procedure identifying alternative pathways connecting agent capabilities to
expert guidance when direct action replication is impossible. Our experimental
results demonstrate that DIIQN achieves up to 130% higher episodic returns
compared to standard DQN, while consistently outperforming existing implicit
imitation methods that cannot exceed expert performance. In heterogeneous
action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging
expert datasets unusable by conventional approaches. Extensive parameter
sensitivity analysis reveals the framework's robustness across varying dataset
sizes and hyperparameter configurations.

</details>


### [31] [SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection](https://arxiv.org/abs/2511.03661)
*Mahek Desai,Apoorva Rumale,Marjan Asadinia*

Main category: cs.LG

TL;DR: 이 연구는 IoT 의료 기기의 보안과 신뢰성 문제를 해결하기 위한 기계 학습 기반 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: IoT 의료 기기의 통합은 사이버 공격과 운영 이상에 대한 취약성을 증가시키는 보안 및 신뢰성 문제가 있습니다.

Method: 200,000개의 데이터를 사용해 악성 사이버 공격 감지와 결함 장치 이상 탐지 위한 8개 기계 학습 모델을 평가했습니다.

Result: XGBoost는 이상 탐지에서 99% 정확도로 최소한의 계산 오버헤드를 기록했습니다. KNN은 공격 탐지에서 거의 완벽한 성능을 보였습니다.

Conclusion: 이 프레임워크는 사이버 위협 및 장치 실패의 조기 탐지를 개선하여 데이터 유출을 예방하고, 시스템 다운타임을 최소화하며, 의료 장비의 안전한 지속 작동을 보장하여 환자의 건강과 IoT 기반 의료 솔루션에 대한 신뢰를 보호할 수 있습니다.

Abstract: The integration of IoT devices in healthcare introduces significant security
and reliability challenges, increasing susceptibility to cyber threats and
operational anomalies. This study proposes a machine learning-driven framework
for (1) detecting malicious cyberattacks and (2) identifying faulty device
anomalies, leveraging a dataset of 200,000 records. Eight machine learning
models are evaluated across three learning approaches: supervised learning
(XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative
Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised
learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph
Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The
comprehensive evaluation was conducted across multiple metrics like F1-score,
precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost
achieved 99\% accuracy with minimal computational overhead (0.04s) for anomaly
detection, while Isolation Forest balanced precision and recall effectively.
LSTM Autoencoders underperformed with lower accuracy and higher latency. For
attack detection, KNN achieved near-perfect precision, recall, and F1-score
with the lowest computational cost (0.05s), followed by VAE at 97% accuracy.
GAN showed the highest computational cost with lowest accuracy and ROC-AUC.
These findings enhance IoT-enabled healthcare security through effective
anomaly detection strategies. By improving early detection of cyber threats and
device failures, this framework has the potential to prevent data breaches,
minimize system downtime, and ensure the continuous and safe operation of
medical devices, ultimately safeguarding patient health and trust in IoT-driven
healthcare solutions.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [32] [ALAS: Transactional and Dynamic Multi-Agent LLM Planning](https://arxiv.org/abs/2511.03094)
*Longling Geng,Edward Y. Chang*

Main category: cs.MA

TL;DR: ALAS는 다중 에이전트 계획의 유연성을 제공하지만 실제로는 취약한 기존 언어 모델의 문제를 해결하기 위해 고안된 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 다중 에이전트 계획을 가능하게 하지만 실제로는 취약하게 작용하며, 순환 검증, 상태 변화 기록 부족, 오류 발생 시 비용이 많이 드는 전역 재계산 등의 문제를 동반한다.

Method: ALAS는 계획과 비순환 검증을 분리하고, 구체적 검사를 위한 버전 관리 실행 로그를 기록하며, 진행 중인 작업을 보존하는 국소 수리를 수행하는 상태ful이고 중단 인식 프레임워크이다.

Result: ALAS는 83.7%의 성공률, 60%의 토큰 사용량 감소, 동등한 설정 하에서 1.82배 빠른 실행 속도를 보여주며 강력한 단일 LL 및 다중 에이전트 기준을 초과한다.

Conclusion: 검증기 분리, 버전 관리 실행 로그 및 국소 수리의 조합이 다중 에이전트 LLM 계획을 위한 효율성, 실행 가능성 및 확장성을 제공함을 보여준다.

Abstract: Large language models enable flexible multi-agent planning but remain fragile
in practice: verification is often circular, state changes are not tracked for
repair, and small faults trigger costly global recomputation. We present ALAS,
a stateful, disruption-aware framework that separates planning from
non-circular validation, records a versioned execution log for grounded checks
and restore points, and performs localized repair that preserves work in
progress. The validator operates independently of the planning LLM with fresh,
bounded context, avoiding self-check loops and mid-context attrition. The
repair protocol edits only the minimal affected region under explicit policies
(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)
defined in a canonical workflow IR that maps to Amazon States Language and Argo
Workflows. On job-shop scheduling suites (DMU, TA) across five classical
benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent
baselines, achieving 83.7% success, reducing token usage by 60%, and running
1.82times faster under comparable settings. A minimal reliability study shows
that the validator detects injected structural faults with low overhead, and
that localized repair contains runtime perturbations with a bounded edit radius
and less makespan degradation than global recompute. Results indicate that the
combination of validator isolation, versioned execution logs, and localized
repair provides measurable efficiency, feasibility, and scalability for
multi-agent LLM planning. Code and seeds will be released.

</details>


### [33] [Learning Communication Skills in Multi-task Multi-agent Deep Reinforcement Learning](https://arxiv.org/abs/2511.03348)
*Changxi Zhu,Mehdi Dastani,Shihan Wang*

Main category: cs.MA

TL;DR: 본 논문에서는 다중 작업을 동시에 수행하는 다중 에이전트 심층 강화 학습을 위한 통신 방법인 다중 작업 통신 기술(MCS)을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 심층 강화 학습에서 에이전트들이 서로 통신을 통해 협력하여 작업을 수행하는 것이 필요합니다. 여러 작업이 연관된 경우, 에이전트들은 한 작업에서의 지식을 활용하여 다른 작업에서의 학습을 향상시킬 수 있습니다.

Method: MCS는 학습 가능한 통신 프로토콜을 통해 에이전트가 상호작용하며, Transformer 인코더를 사용하여 작업 특정 관찰을 공유 메시지 공간으로 인코딩합니다. 또한 예측 네트워크를 도입하여 각 작업에서의 발신 에이전트의 행동과 메시지를 연관시킵니다.

Result: 실험 결과, MCS는 통신이 없는 다중 작업 MADRL 기준선뿐만 아니라 통신이 있는 단일 작업 MADRL 기준선보다 더 나은 성과를 달성했습니다.

Conclusion: MCS는 다중 작업 학습을 향상시키기 위해 효과적인 에이전트 간 통신을 가능하게 하는 방법을 제시합니다.

Abstract: In multi-agent deep reinforcement learning (MADRL), agents can communicate
with one another to perform a task in a coordinated manner. When multiple tasks
are involved, agents can also leverage knowledge from one task to improve
learning in other tasks. In this paper, we propose Multi-task Communication
Skills (MCS), a MADRL with communication method that learns and performs
multiple tasks simultaneously, with agents interacting through learnable
communication protocols. MCS employs a Transformer encoder to encode
task-specific observations into a shared message space, capturing shared
communication skills among agents. To enhance coordination among agents, we
introduce a prediction network that correlates messages with the actions of
sender agents in each task. We adapt three multi-agent benchmark environments
to multi-task settings, where the number of agents as well as the observation
and action spaces vary across tasks. Experimental results demonstrate that MCS
achieves better performance than multi-task MADRL baselines without
communication, as well as single-task MADRL baselines with and without
communication.

</details>
