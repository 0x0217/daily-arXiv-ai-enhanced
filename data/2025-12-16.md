<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 11]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.AI](#cs.AI) [Total: 11]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Scalable Data Synthesis for Computer Use Agents with Step-Level Filtering](https://arxiv.org/abs/2512.10962)
*Yifei He,Pranit Chawla,Yaser Souri,Subhojit Som,Xia Song*

Main category: cs.LG

TL;DR: 본 연구에서는 노이즈가 많은 롤아웃을 신뢰할 수 있는 감독 데이터로 변환하는 스케일러블한 데이터 합성 파이프라인을 제시합니다. 이를 통해 WebSTAR와 WebSCORE라는 두 개의 새로운 데이터셋을 구축하고, 효율적인 멀티모달 보상 모델인 StepRM을 개발했습니다.


<details>
  <summary>Details</summary>
Motivation: 컴퓨터 사용 에이전트(CUA)의 훈련이 높은 GUI 상호작용 비용과 고품질 궤적 데이터의 부족으로 어려움을 겪고 있습니다.

Method: 우리는 노이즈가 많은 롤아웃을 신뢰할 수 있는 감독으로 변환하는 스케일러블 데이터 합성 파이프라인을 도입하고, 단계별 필터링과 이론 보강을 사용하여 이를 실현합니다.

Result: WebSTAR 데이터셋을 통해 13.3K의 궤적과 100K의 단계가 합성되었으며, 훈련된 모델은 SoTA 오픈 소스 CUA 모델보다 15% 이상 성능이 개선되었습니다.

Conclusion: 본 연구는 단계별 필터링을 스케일러블 CUA 훈련의 핵심 원칙으로 설정하고, WebSTAR, WebSCORE 두 개의 새로운 데이터셋과 StepRM 경량 보상 모델을 구축했습니다.

Abstract: Computer use agents (CUAs) can operate real-world digital interfaces but remain difficult to train due to the high cost of graphical user interface (GUI) interaction and the scarcity of high-quality trajectory data. Existing datasets rely on human demonstrations, limiting scalability. A natural alternative is to synthesize data from strong CUAs, yet their rollouts are highly noisy, with incorrect or suboptimal actions consisting a large proportion of the steps, making naive imitation ineffective. To tackle this challenge, we introduce a scalable data synthesis pipeline that transforms noisy rollouts into reliable supervision without human annotation. The core idea is step-level filtering, which evaluates actions individually to retain only correct steps, complemented by reasoning augmentation for improved planning. Using this pipeline, we construct WebSTAR, a dataset of 13.3K trajectories and 100K graded, reasoning-rich steps synthesized from OpenAI's computer-use-preview model. We train Qwen-2.5-VL-Instruct models (7B and 32B) on WebSTAR. On WebVoyager, our 7B model surpasses SoTA open-source CUA model UI-TARS-1.5-7B by more than 15% with only supervised finetuning. Building on step-level grading, we further create WebSCORE, a dataset of graded step-level actions, and train StepRM, a 7B multimodal reward model distilled from o4-mini, which matches its grading quality while being far more efficient to deploy at scale. Our results establish step-level filtering as a key principle for scalable CUA training and construct two new datasets (WebSTAR, WebSCORE) and a lightweight reward model (StepRM) as practical tools to advance robust and efficient CUAs.

</details>


### [2] [Multimodal Fusion of Regional Brain Experts for Interpretable Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2512.10966)
*Farica Zhuang,Dinara Aliyeva,Shu Yang,Zixuan Wen,Duy Duong-Tran,Christos Davatzikos,Tianlong Chen,Song Wang,Li Shen*

Main category: cs.LG

TL;DR: MREF-AD는 알츠하이머병 진단을 위한 다중 모달 영역 전문가 융합 모델로, 진단 성능을 향상시키고 해석 가능성을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 알츠하이머병의 정확하고 조기 진단을 위해 여러 모달리티의 보완 정보를 통합할 필요성이 크다.

Method: MREF-AD는 각 모달리티의 중간 규모 뇌 영역을 독립 전문가로 모델링하고, 두 수준의 게이팅 네트워크를 사용하여 개인별 융합 가중치를 학습하는 Mixture-of-Experts (MoE) 프레임워크이다.

Result: Alzheimer's Disease Neuroimaging Initiative (ADNI)의 데이터를 사용하여 MREF-AD는 최첨단 성능을 달성하며, 뇌 영역별 바이오마커의 관련성을 향상된 해석 가능성과 함께 제공한다.

Conclusion: MREF-AD는 신경영상에서의 적응 가능한 해석 가능한 다중 모달 융합을 위한 일반적인 프레임워크로서 유용성을 강조한다.

Abstract: Accurate and early diagnosis of Alzheimer's disease (AD) can benefit from integrating complementary information from multiple modalities, mirroring clinical practice. However, conventional fusion approaches often rely on simple concatenation of features, which cannot adaptively balance the contributions of biomarkers such as amyloid PET and MRI across brain regions. In this work, we propose MREF-AD, a Multimodal Regional Expert Fusion model for AD diagnosis. It is a Mixture-of-Experts (MoE) framework that models meso-scale brain regions in each modality as an independent expert and employs two-level gating networks to learn subject-specific fusion weights. Beyond improving diagnostic performance, MREF-AD provides modality- and region-level insight into how structural and molecular imaging jointly contribute to disease diagnosis. Using data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), MREF-AD achieves state-of-the-art performance over baselines while providing enhanced interpretability of brain region-specific biomarker relevance, underscoring its utility as a general framework for adaptive and interpretable multimodal fusion in neuroimaging.

</details>


### [3] [Agent-Based Modular Learning for Multimodal Emotion Recognition in Human-Agent Systems](https://arxiv.org/abs/2512.10975)
*Matvey Nepomnyaschiy,Oleg Pereziabov,Anvar Tliamov,Stanislav Mikhailov,Ilya Afanasyev*

Main category: cs.LG

TL;DR: 이 논문은 다중 모달 감정 인식을 위한 새로운 다중 에이전트 프레임워크를 제안하며, 이를 통해 훈련 효율성을 개선하고 인체 에이전트 상호작용을 위한 유연하고 확장 가능한 인식 모듈을 디자인할 수 있도록 한다.


<details>
  <summary>Details</summary>
Motivation: 효과적인 인간-에이전트 상호작용은 인간의 정서 상태에 대한 정확하고 적응적인 인식을 필요로 한다.

Method: 각 모달 인코더와 융합 분류기가 중앙 감독관에 의해 조정되는 독립적인 에이전트로 작동하는 다중 에이전트 프레임워크를 제안한다.

Result: 우리의 접근 방식은 비전, 오디오 및 텍스트 모달리티를 지원하는 개념 증명 구현을 통해 실현 가능성을 입증한다.

Conclusion: 이 프레임워크는 훈련 효율성을 개선할 뿐만 아니라, HAI 시나리오에서 구체화된 및 가상 에이전트를 위한 더 유연하고 확장 가능하며 유지 관리가 용이한 인식 모듈의 설계에 기여한다.

Abstract: Effective human-agent interaction (HAI) relies on accurate and adaptive perception of human emotional states. While multimodal deep learning models - leveraging facial expressions, speech, and textual cues - offer high accuracy in emotion recognition, their training and maintenance are often computationally intensive and inflexible to modality changes. In this work, we propose a novel multi-agent framework for training multimodal emotion recognition systems, where each modality encoder and the fusion classifier operate as autonomous agents coordinated by a central supervisor. This architecture enables modular integration of new modalities (e.g., audio features via emotion2vec), seamless replacement of outdated components, and reduced computational overhead during training. We demonstrate the feasibility of our approach through a proof-of-concept implementation supporting vision, audio, and text modalities, with the classifier serving as a shared decision-making agent. Our framework not only improves training efficiency but also contributes to the design of more flexible, scalable, and maintainable perception modules for embodied and virtual agents in HAI scenarios.

</details>


### [4] [Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning](https://arxiv.org/abs/2512.11179)
*Wei Duan,Jie Lu,En Yu,Junyu Xuan*

Main category: cs.LG

TL;DR: 그래프 기반의 다중 에이전트 강화 학습(MARL)은 에이전트를 노드로, 통신 링크를 엣지로 모델링하여 부분 가시성 아래에서 협력 행동을 가능하게 한다. 그러나 최근 방법들은 하드 대역폭 제한 하에서 어떤 정보를 전송해야 하는지에 대해 다루지 않는다.


<details>
  <summary>Details</summary>
Motivation: 하드 대역폭 제한 조건에서 정보의 선택적 인코딩 필요성을 이해하고, 이를 극복하기 위한 새로운 방법 개발.

Method: Bandwith-constrained Variational Message Encoding (BVME) 모듈을 도입하여, 메시지를 KL 발산을 통해 정보가 없는 사전 분포로 정규화된 학습된 가우시안 후분포에서 샘플로 취급.

Result: BVME는 SMACv1, SMACv2 및 MPE 벤치마크에서 67-83% 더 적은 메시지 차원을 사용하면서 유사하거나 우수한 성능을 달성.

Conclusion: BVME는 대역폭의 극단적인 비율에서 우수한 성능을 발휘하며, 최소한의 추가 부담을 가지고 있다.

Abstract: Graph-based multi-agent reinforcement learning (MARL) enables coordinated behavior under partial observability by modeling agents as nodes and communication links as edges. While recent methods excel at learning sparse coordination graphs-determining who communicates with whom-they do not address what information should be transmitted under hard bandwidth constraints. We study this bandwidth-limited regime and show that naive dimensionality reduction consistently degrades coordination performance. Hard bandwidth constraints force selective encoding, but deterministic projections lack mechanisms to control how compression occurs. We introduce Bandwidth-constrained Variational Message Encoding (BVME), a lightweight module that treats messages as samples from learned Gaussian posteriors regularized via KL divergence to an uninformative prior. BVME's variational framework provides principled, tunable control over compression strength through interpretable hyperparameters, directly constraining the representations used for decision-making. Across SMACv1, SMACv2, and MPE benchmarks, BVME achieves comparable or superior performance while using 67--83% fewer message dimensions, with gains most pronounced on sparse graphs where message quality critically impacts coordination. Ablations reveal U-shaped sensitivity to bandwidth, with BVME excelling at extreme ratios while adding minimal overhead.

</details>


### [5] [Progress over Points: Reframing LM Benchmarks Around Scientific Objectives](https://arxiv.org/abs/2512.11183)
*Alwin Jin,Sean M. Hendryx,Vaskar Nath*

Main category: cs.LG

TL;DR: 이 논문은 진행 중심 벤치마크를 제안하고, NanoGPT 속도 테스트를 기반으로 한 새로운 훈련 환경을 통해 언어 모델링의 발전을 촉진하는 방안을 모색합니다.


<details>
  <summary>Details</summary>
Motivation: 기존의 정적인 문제를 통한 LLM 평가가 발전의 측정을 제한하는 경향이 있다는 문제를 해결하고자 함.

Method: NanoGPT 속도 테스트를 기반으로 한 환경을 구축하고 표준화된 데이터셋, 참조 모델, 훈련 도구 및 풍부한 텔레메트리를 제공.

Result: 이 환경을 통해 새로운 훈련 시간 기록을 달성하고, 새로운 알고리즘적 아이디어의 출현을 관찰함.

Conclusion: 벤치마크의 진보가 과학의 진보와 연결되어, '벤치마킹'을 과학 발전의 도구로 재구성함.

Abstract: Current benchmarks that test LLMs on static, already-solved problems (e.g., math word problems) effectively demonstrated basic capability acquisition. The natural progression has been toward larger, more comprehensive and challenging collections of static problems, an approach that inadvertently constrains the kinds of advances we can measure and incentivize. To address this limitation, we argue for progress-oriented benchmarks, problem environments whose objectives are themselves the core targets of scientific progress, so that achieving state of the art on the benchmark advances the field. As a introductory step, we instantiate an environment based on the NanoGPT speedrun. The environment standardizes a dataset slice, a reference model and training harness, and rich telemetry, with run-time verification and anti-gaming checks. Evaluation centers on the scientific delta achieved: best-attained loss and the efficiency frontier. Using this environment, we achieve a new state-of-the-art training time, improving upon the previous record by 3 seconds, and qualitatively observe the emergence of novel algorithmic ideas. Moreover, comparisons between models and agents remain possible, but they are a means, not the end; the benchmark's purpose is to catalyze reusable improvements to the language modeling stack. With this release, the overarching goal is to seed a community shift from static problem leaderboards to test-time research on open-ended yet measurable scientific problems. In this new paradigm, progress on the benchmark is progress on the science, thus reframing "benchmarking" as a vehicle for scientific advancement.

</details>


### [6] [Insight Miner: A Time Series Analysis Dataset for Cross-Domain Alignment with Natural Language](https://arxiv.org/abs/2512.11251)
*Yunkai Zhang,Yawen Zhang,Ming Zheng,Kezhen Chen,Chongyang Gao,Ruian Ge,Siyuan Teng,Amine Jelloul,Jinmeng Rao,Xiaoyuan Guo,Chiang-Wei Fang,Zeyu Zheng,Jie Yang*

Main category: cs.LG

TL;DR: 이 논문에서는 대규모 멀티모달 모델인 Insight Miner를 제안하며, 이는 시계열 데이터를 고품질의 포괄적인 설명으로 변환하는 데 도움을 줄 수 있다.


<details>
  <summary>Details</summary>
Motivation: 시계열 데이터는 과학 및 산업 분야에서 중요한 요소지만, 이를 분석하기 위해서는 전문 지식이 수반되며 이는 시간과 노동 집약적인 과정이다.

Method: Insight Miner는 도메인별 지식으로 풍부해진 시계열 설명을 생성하기 위해 설계된 대규모 멀티모달 모델이다. 이를 위해 우리는 시계열과 언어 정렬을 위한 최초의 일반 도메인 데이터셋인 TS-Insights를 도입하였다.

Result: Insight Miner는 시계열 설명 및 통찰력을 생성하는 데 있어 LLaVA 및 GPT-4와 같은 최신 멀티모달 모델을 능가했다.

Conclusion: 이 연구는 시계열 분석에 LMM을 활용하는 데 있어 유망한 방향을 제시하며, LLM이 시계열을 기본 입력 모달리티로 해석할 수 있도록 하는 근본적인 단계를 제공한다.

Abstract: Time-series data is critical across many scientific and industrial domains, including environmental analysis, agriculture, transportation, and finance. However, mining insights from this data typically requires deep domain expertise, a process that is both time-consuming and labor-intensive. In this paper, we propose \textbf{Insight Miner}, a large-scale multimodal model (LMM) designed to generate high-quality, comprehensive time-series descriptions enriched with domain-specific knowledge. To facilitate this, we introduce \textbf{TS-Insights}\footnote{Available at \href{https://huggingface.co/datasets/zhykoties/time-series-language-alignment}{https://huggingface.co/datasets/zhykoties/time-series-language-alignment}.}, the first general-domain dataset for time series and language alignment. TS-Insights contains 100k time-series windows sampled from 20 forecasting datasets. We construct this dataset using a novel \textbf{agentic workflow}, where we use statistical tools to extract features from raw time series before synthesizing them into coherent trend descriptions with GPT-4. Following instruction tuning on TS-Insights, Insight Miner outperforms state-of-the-art multimodal models, such as LLaVA \citep{liu2023llava} and GPT-4, in generating time-series descriptions and insights. Our findings suggest a promising direction for leveraging LMMs in time series analysis, and serve as a foundational step toward enabling LLMs to interpret time series as a native input modality.

</details>


### [7] [Benchmarking the Generality of Vision-Language-Action Models](https://arxiv.org/abs/2512.11315)
*Pranav Guruprasad,Sudipta Chowdhury,Harsh Sikka,Mridul Sharma,Helen Lu,Sean Rivera,Aryan Khurana,Hangliang Ren,Yangyue Wang*

Main category: cs.LG

TL;DR: Multinet v1.0은 비전 언어 모델과 비전 언어 행동 모델의 교차 도메인 일반성을 측정하기 위한 통합 벤치마크입니다.


<details>
  <summary>Details</summary>
Motivation: 현재의 평가 방식은 산발적이며, 기초 모델이 실제로 그들의 훈련 분포를 넘어 일반화되는지를 평가하기 어렵습니다.

Method: 시각적 기초, 공간적 추론, 도구 사용, 물리적 상식, 다중 에이전트 조정 및 지속적인 로봇 제어 등 6개 기본 능력 체계에 걸쳐 VLM과 VLA를 평가합니다.

Result: GPT 5, Pi0, Magma 모델 모두 일관된 일반성을 보이지 않으며, 훈련 분포 내에서는 강력한 성능을 보이지만, 본 적 없는 도메인이나 익숙하지 않은 모달리티에서는 상당한 성능 저하를 나타냅니다.

Conclusion: 다양한 분야에서 일반적 지능의 기대와 현재 기초 모델의 실제 능력 사이에는 지속적인 격차가 존재합니다. MultiNet v1.0은 이러한 격차를 진단하고 향후 일반화 에이전트 개발을 안내하는 표준화된 평가 기초를 제공합니다.

Abstract: Generalist multimodal agents are expected to unify perception, language, and control - operating robustly across diverse real world domains. However, current evaluation practices remain fragmented across isolated benchmarks, making it difficult to assess whether today's foundation models truly generalize beyond their training distributions. We introduce MultiNet v1.0, a unified benchmark for measuring the cross domain generality of vision language models (VLMs) and vision language action models (VLAs) across six foundational capability regimes. Visual grounding, spatial reasoning, tool use, physical commonsense, multi agent coordination, and continuous robot control. Evaluating GPT 5, Pi0, and Magma, we find that no model demonstrates consistent generality. All exhibit substantial degradation on unseen domains, unfamiliar modalities, or cross domain task shifts despite strong performance within their training distributions.These failures manifest as modality misalignment, output format instability, and catastrophic knowledge degradation under domain transfer.Our findings reveal a persistent gap between the aspiration of generalist intelligence and the actual capabilities of current foundation models.MultiNet v1.0 provides a standardized evaluation substrate for diagnosing these gaps and guiding the development of future generalist agents.Code, data, and leaderboards are publicly available.

</details>


### [8] [DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning](https://arxiv.org/abs/2512.11342)
*Jinming Ge,Linfeng Du,Likith Anaparty,Shangkun Li,Tingyuan Liang,Afzal Ahmad,Vivek Chaturvedi,Sharad Sinha,Zhiyao Xie,Jiang Xu,Wei Zhang*

Main category: cs.LG

TL;DR: DAPO는 FPGA 기반의 도메인 특화 가속기 설계를 위한 새로운 최적화 전략을 제안하며, 이를 통해 기존 HLS 도구보다 2.36배 빠른 성능을 발휘한다.


<details>
  <summary>Details</summary>
Motivation: FPGA 기반 가속기 설계에서 기존 HLS 도구의 최적화 전략이 고정되어 있어 효과성이 제한된다.

Method: DAPO는 제어 및 데이터 플로우 그래프에서 프로그램 의미를 추출하고, 대조 학습을 이용하여 풍부한 임베딩을 생성하며, 정확한 하드웨어 메트릭 추정을 위한 분석 모델을 활용한다. 이러한 구성 요소들은 강화 학습 에이전트를 안내하여 설계 특정 최적화 전략을 발견하도록 돕는다.

Result: 클래식 HLS 설계에 대한 평가 결과, DAPO는 평균적으로 Vitis HLS에 비해 2.36배의 속도 향상을 보여준다.

Conclusion: DAPO는 HLS 도구가 더 높은 성능을 발휘하도록 돕는 효과적인 프레임워크로, 특정 설계에 맞춤화된 최적화 전략을 가능하게 한다.

Abstract: High-Level Synthesis (HLS) tools are widely adopted in FPGA-based domain-specific accelerator design. However, existing tools rely on fixed optimization strategies inherited from software compilations, limiting their effectiveness. Tailoring optimization strategies to specific designs requires deep semantic understanding, accurate hardware metric estimation, and advanced search algorithms -- capabilities that current approaches lack.
  We propose DAPO, a design structure-aware pass ordering framework that extracts program semantics from control and data flow graphs, employs contrastive learning to generate rich embeddings, and leverages an analytical model for accurate hardware metric estimation. These components jointly guide a reinforcement learning agent to discover design-specific optimization strategies. Evaluations on classic HLS designs demonstrate that our end-to-end flow delivers a 2.36 speedup over Vitis HLS on average.

</details>


### [9] [Elastic-Net Multiple Kernel Learning: Combining Multiple Data Sources for Prediction](https://arxiv.org/abs/2512.11547)
*Janaina Mourão-Miranda,Zakria Hussain,Konstantinos Tsirlis,Christophe Phillips,John Shawe-Taylor*

Main category: cs.LG

TL;DR: 다중 커널 학습(MKL) 모델은 다양한 데이터 표현이나 소스를 통합하기 위해 여러 커널을 결합한다. 이 논문에서는 간단한 분석적 업데이트를 제공하여 커널 가중치를 갱신하는 새로운 ENMKL 공식을 제시하며, 이 방법이 sSVM 또는 KRR에 비해 뛰어난 성능을 보인다는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: ENMKL이 신경영상에서 중요한 해석 가능성을 제공하고 커널 간의 상관 정보를 포착하도록 설계되었다.

Method: 커널 가중치에 대한 간단한 분석적 업데이트를 제공하고, 이를 SVM 및 커널 릿지 회귀(KRR) 알고리즘에 적용하였다.

Result: ENMKL 알고리즘이 $l1$-정규화 MKL 및 SVM(KRR)에 비해 우수한 성능을 발휘하며, 특히 관련성 있는 커널을 선택적으로 가중치하여 보다 해석 가능한 모델을 생성한다.

Conclusion: 이 연구의 결과는 ENMKL이 모든 작업에서 $l1$-정규화 MKL과 동등하거나 뛰어난 성과를 보이며, 표준 SVM보다 낮은 성능을 보여주는 시나리오도 있음을 확인하였다.

Abstract: Multiple Kernel Learning (MKL) models combine several kernels in supervised and unsupervised settings to integrate multiple data representations or sources, each represented by a different kernel. MKL seeks an optimal linear combination of base kernels that maximizes a generalized performance measure under a regularization constraint. Various norms have been used to regularize the kernel weights, including $l1$, $l2$ and $lp$, as well as the "elastic-net" penalty, which combines $l1$- and $l2$-norm to promote both sparsity and the selection of correlated kernels. This property makes elastic-net regularized MKL (ENMKL) especially valuable when model interpretability is critical and kernels capture correlated information, such as in neuroimaging. Previous ENMKL methods have followed a two-stage procedure: fix kernel weights, train a support vector machine (SVM) with the weighted kernel, and then update the weights via gradient descent, cutting-plane methods, or surrogate functions. Here, we introduce an alternative ENMKL formulation that yields a simple analytical update for the kernel weights. We derive explicit algorithms for both SVM and kernel ridge regression (KRR) under this framework, and implement them in the open-source Pattern Recognition for Neuroimaging Toolbox (PRoNTo). We evaluate these ENMKL algorithms against $l1$-norm MKL and against SVM (or KRR) trained on the unweighted sum of kernels across three neuroimaging applications. Our results show that ENMKL matches or outperforms $l1$-norm MKL in all tasks and only underperforms standard SVM in one scenario. Crucially, ENMKL produces sparser, more interpretable models by selectively weighting correlated kernels.

</details>


### [10] [Brain-Semantoks: Learning Semantic Tokens of Brain Dynamics with a Self-Distilled Foundation Model](https://arxiv.org/abs/2512.11582)
*Sam Gijsen,Marc-Andre Schulz,Kerstin Ritter*

Main category: cs.LG

TL;DR: 기능 자기공명영상(fMRI) 시계열을 위한 기반 모델 개발이 질병 및 인지와 관련된 표현형 예측에 유망하지만, 기존 모델은 작은 뇌 영역에 대해 훈련되어 노이즈에 민감한 표현을 생성한다. 본 논문은 뇌 역학의 추상 표현을 학습하기 위해 설계된 자가 감독 프레임워크인 Brain-Semantoks를 소개한다.


<details>
  <summary>Details</summary>
Motivation: 기능 자기공명영상(fMRI)으로 질병과 인지와 관련된 표현형을 예측하는 가능성을 증대시키기 위해, 기존 모델의 한계를 극복하고자 했다.

Method: Brain-Semantoks는 의미 토크나이저와 자가 증류 목적을 포함하는 두 가지 핵심 혁신으로 설계되었으며, 이 구조는 노이즈가 많은 지역 신호를 기능적 네트워크를 나타내는 강력한 토큰으로 집계한다.

Result: 학습된 표현이 다양한 하위 작업에서 강력한 성능을 보이는 것을 증명했으며, 특히 선형 프로브만을 사용할 때에도 효과적이었다.

Conclusion: 더욱이, 더 많은 비표시 데이터를 통해 도메인 적응 없이도 신뢰할 수 있는 성능 향상을 보여주는 포괄적인 스케일링 분석을 제공하였다.

Abstract: The development of foundation models for functional magnetic resonance imaging (fMRI) time series holds significant promise for predicting phenotypes related to disease and cognition. Current models, however, are often trained using a mask-and-reconstruct objective on small brain regions. This focus on low-level information leads to representations that are sensitive to noise and temporal fluctuations, necessitating extensive fine-tuning for downstream tasks. We introduce Brain-Semantoks, a self-supervised framework designed specifically to learn abstract representations of brain dynamics. Its architecture is built on two core innovations: a semantic tokenizer that aggregates noisy regional signals into robust tokens representing functional networks, and a self-distillation objective that enforces representational stability across time. We show that this objective is stabilized through a novel training curriculum, ensuring the model robustly learns meaningful features from low signal-to-noise time series. We demonstrate that learned representations enable strong performance on a variety of downstream tasks even when only using a linear probe. Furthermore, we provide comprehensive scaling analyses indicating more unlabeled data reliably results in out-of-distribution performance gains without domain adaptation.

</details>


### [11] [Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents](https://arxiv.org/abs/2512.11584)
*Stefan Tabakov,Asen Popov,Dimitar Dimitrov,S. Ensiye Kiyamousavi,Vladimir Hristov,Boris Kraychev*

Main category: cs.LG

TL;DR: 현재 VLA 모델은 신규 기술 및 객체 조합이 필요한 작업에서 일반화가 잘 되지 않는다. 본 연구에서는 긴 시연을 짧고 유형화된 원자 행동으로 분해하는 새로운 계획자 정렬 접근법인 원자 행동 슬라이싱(AAS)을 소개한다.


<details>
  <summary>Details</summary>
Motivation: VLA 모델의 일반화 능력을 향상시키고 새로운 기술 및 객체 조합에서의 성능을 개선하고자 한다.

Method: AAS는 LIBERO 시연을 활용하여 2,124개의 원자 구간으로 구성된 검증된 데이터셋을 생성하고, 각 구간에는 행동 유형, 시간 범위 및 확신도가 레이블되어 있다.

Result: Gemini 2.5 Pro라는 강력한 세그먼트가 계획자가 정의한 계획과 정확히 일치하며, 키프레임 지터에 대해서도 강력한 성능을 보인다. CLIP-RT+를 우리의 원자 데이터셋에서 미세 조정하면 LIBERO-Goal에서 94.2%에서 95.3%로, LIBERO-Long에서는 83.8%에서 88.8%로 작업 성공률이 향상된다.

Conclusion: GATE-VLAP 데이터셋을 HuggingFace에 공개하여 커뮤니티의 사용을 독려한다.

Abstract: Current vision-language-action (VLA) models generalize poorly, particularly when tasks require new compositions of skills or objects. We introduce Atomic Action Slicing (AAS), a planner-aligned approach that decomposes long-horizon demonstrations into short, typed atomic actions that are easier for planners to use and policies to learn. Using LIBERO demonstrations, AAS produces a validated dataset of 2,124 atomic segments labeled with action type, temporal span, and confidence. A stronger segmenter (Gemini 2.5 Pro) closely matches planner-defined plans and remains robust under keyframe jitter, while smaller models perform worse on multi-object tasks. Fine-tuning CLIP-RT+ on our atomic dataset improves task success from 94.2% to 95.3% on LIBERO-Goal and 83.8% to 88.8% on LIBERO-Long. We publicly release the GATE-VLAP dataset on HuggingFace(https://huggingface.co/datasets/gate-institute/GATE-VLAP-datasets)

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [An LLVM-Based Optimization Pipeline for SPDZ](https://arxiv.org/abs/2512.11112)
*Tianye Dai,Hammurabi Mendes,Heuichan Lim*

Main category: cs.CR

TL;DR: 이 논문은 SPDZ 프로토콜을 위한 LLVM 기반 최적화 파이프라인을 설계하고 구현하여 성능과 사용성을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 활성 보안 산술 MPC는 실제 응용 프로그램에 실용적이지만, 프레임워크 특정 컴파일 스택, 프로그래머의 명시적 병렬성 표현 필요성, 높은 통신 오버헤드로 인해 성능과 사용성이 제한된다.

Method: SPDZ 프로토콜을 위한 LLVM 기반 최적화 파이프라인을 설계하고 구현하였으며, 경량 프라이버시 주석이 포함된 C의 하위 집합을 수용하여 LLVM IR로 낮추고, 이를 통해 독립적인 산술 연산을 자동으로 배치하는 성숙한 분석 및 변환을 재사용했다.

Result: CPU 백엔드는 중간 및 중량 대수 작업에서 최대 5.56배의 속도 향상을 달성하고, 스레드 수에 따라 강력한 확장을 보여주며, GPU 백엔드는 입력 크기가 증가함에 따라 더 나은 확장을 보였다.

Conclusion: LLVM과 프로토콜 인식 스케줄링을 활용하는 것이 사용성을 저하하지 않고 병렬성을 추출하기 위한 효과적인 아키텍처 방향임을 나타낸다.

Abstract: Actively secure arithmetic MPC is now practical for real applications, but performance and usability are still limited by framework-specific compilation stacks, the need for programmers to explicitly express parallelism, and high communication overhead. We design and implement a proof-of-concept LLVM-based optimization pipeline for the SPDZ protocol that addresses these bottlenecks. Our front end accepts a subset of C with lightweight privacy annotations and lowers it to LLVM IR, allowing us to reuse mature analyses and transformations to automatically batch independent arithmetic operations. Our back end performs data-flow and control-flow analysis on the optimized IR to drive a non-blocking runtime scheduler that overlaps independent operations and aggressively overlaps communication with computation; when enabled, it can map batched operations to GPU kernels. This design preserves a low learning curve by using a mainstream language and hiding optimization and hardware-specific mechanics from programmers. We evaluate the system on controlled microbenchmarks against MP-SPDZ, focusing on online phase performance. Our CPU back end achieves up to 5.56 times speedup under intermediate and heavy algebraic workloads, shows strong scaling with thread count, and our GPU back end scales better as the input size increases. Overall, these results indicate that leveraging LLVM with protocol-aware scheduling is an effective architectural direction for extracting parallelism without sacrificing usability.

</details>


### [13] [Automated Penetration Testing with LLM Agents and Classical Planning](https://arxiv.org/abs/2512.11143)
*Lingzhi Wang,Xinyi Shi,Ziyu Li,Yi Jiang,Shiyu Tan,Yuhao Jiang,Junjie Cheng,Wenyuan Chen,Xiangmin Shen,Zhenyuan LI,Yan Chen*

Main category: cs.CR

TL;DR: 이 논문에서는 완전 자동화된 침투 테스트의 구현 문제를 다루며, CHECKMATE라는 새로운 프레임워크를 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 완전 자동화된 침투 테스트의 실현은 사이버 보안에서 중요한 연구 과제입니다.

Method: PEP 설계 패러다임을 도입하고 기존 연구를 체계적으로 검토하여 주요 도전 과제를 식별합니다. LLM 에이전트를 사용한 기존 침투 테스트 시스템을 평가합니다.

Result: Claude Code와 Sonnet 4.5가 이전 시스템보다 뛰어난 침투 능력을 보여줍니다.

Conclusion: CHECKMATE 프레임워크가 기존 시스템보다 20% 이상의 성공률을 개선하고, 안정성을 크게 높이며 시간과 비용을 50% 이상 절감합니다.

Abstract: While penetration testing plays a vital role in cybersecurity, achieving fully automated, hands-off-the-keyboard execution remains a significant research challenge. In this paper, we introduce the "Planner-Executor-Perceptor (PEP)" design paradigm and use it to systematically review existing work and identify the key challenges in this area. We also evaluate existing penetration testing systems, with a particular focus on the use of Large Language Model (LLM) agents for this task. The results show that the out-of-the-box Claude Code and Sonnet 4.5 exhibit superior penetration capabilities observed to date, substantially outperforming all prior systems. However, a detailed analysis of their testing processes reveals specific strengths and limitations; notably, LLM agents struggle with maintaining coherent long-horizon plans, performing complex reasoning, and effectively utilizing specialized tools. These limitations significantly constrain its overall capability, efficiency, and stability. To address these limitations, we propose CHECKMATE, a framework that integrates enhanced classical planning with LLM agents, providing an external, structured "brain" that mitigates the inherent weaknesses of LLM agents. Our evaluation shows that CHECKMATE outperforms the state-of-the-art system (Claude Code) in penetration capability, improving benchmark success rates by over 20%. In addition, it delivers substantially greater stability, cutting both time and monetary costs by more than 50%.

</details>


### [14] [MiniScope: A Least Privilege Framework for Authorizing Tool Calling Agents](https://arxiv.org/abs/2512.11147)
*Jinhao Zhu,Kevin Tseng,Gil Vernik,Xiao Huang,Shishir G. Patil,Vivian Fang,Raluca Ada Popa*

Main category: cs.CR

TL;DR: MiniScope는 도구 호출 에이전트가 사용자 계정에서 작동하면서 불확실한 LLM으로 인한 잠재적 피해를 제한할 수 있도록 하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: LLM의 불확실성이 민감한 사용자 서비스 운영 시 보안 위험을 초래하므로, 자동화된 도구 호출 에이전트가 안전하게 작동해야 한다.

Method: MiniScope는 도구 호출 간의 관계를 반영하는 권한 계층을 재구성하고, 모바일 스타일의 권한 모델과 결합하여 최소 특권 원칙을 자동으로 적용하는 새로운 방법을 제시한다.

Result: MiniScope는 10개의 인기 실제 애플리케이션에서 파생된 합성 데이터를 사용하여 평가했으며, 기존의 단순화된 기준을 넘어선 현실적인 에이전틱 작업의 복잡성을 포착한다.

Conclusion: MiniScope는 기본 도구 호출 에이전트에 비해 1-6%의 지연 오버헤드만을 발생시키며, 권한 최소화 및 계산 및 운영 비용을 크게 줄이는 데 있어 우수한 성능을 발휘한다.

Abstract: Tool calling agents are an emerging paradigm in LLM deployment, with major platforms such as ChatGPT, Claude, and Gemini adding connectors and autonomous capabilities. However, the inherent unreliability of LLMs introduces fundamental security risks when these agents operate over sensitive user services. Prior approaches either rely on manually written policies that require security expertise, or place LLMs in the confinement loop, which lacks rigorous security guarantees. We present MiniScope, a framework that enables tool calling agents to operate on user accounts while confining potential damage from unreliable LLMs. MiniScope introduces a novel way to automatically and rigorously enforce least privilege principles by reconstructing permission hierarchies that reflect relationships among tool calls and combining them with a mobile-style permission model to balance security and ease of use. To evaluate MiniScope, we create a synthetic dataset derived from ten popular real-world applications, capturing the complexity of realistic agentic tasks beyond existing simplified benchmarks. Our evaluation shows that MiniScope incurs only 1-6% latency overhead compared to vanilla tool calling agents, while significantly outperforming the LLM based baseline in minimizing permissions as well as computational and operational costs.

</details>


### [15] [A Scalable Multi-GPU Framework for Encrypted Large-Model Inference](https://arxiv.org/abs/2512.11269)
*Siddharth Jayashankar,Joshua Kim,Michael B. Sullivan,Wenting Zheng,Dimitrios Skarlatos*

Main category: cs.CR

TL;DR: 이 논문은 대형 모델에 대한 완전 동형 암호(FHE) 추론을 위한 다중 GPU 프레임워크인 Cerium을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: FHE는 강력한 개인 정보 보호를 제공하지만 느린 성능으로 인해 실용적인 배포에 제한이 있습니다. 이는 고급 제조 프로세스를 요구하는 ASIC을 통한 가속을 필요로 하지만, GPU는 훨씬 접근성이 높습니다.

Method: Cerium은 도메인 특화 언어, 최적화 컴파일러, 런타임 시스템을 통합하여 고성능 GPU 커널을 자동으로 생성하고, 테라바이트 규모의 메모리 발자국을 관리하며, 다중 GPU를 통한 병렬 처리를 수행합니다.

Result: Cerium은 NVIDIA GPU에서 구축되었으며, 성능이 크게 향상됨을 보여줍니다. 소형 모델의 경우, Cerium은 전문가가 작성한 수동 최적화 GPU 라이브러리보다 최대 2.25배 더 빠릅니다.

Conclusion: Cerium은 최첨단 FHE ASIC과 경쟁력 있는 성능을 달성하였고, 부트스트래핑을 10밀리초 이내에 실행한 최초의 GPU 시스템이며, BERT-Base와 Llama3-8B에 대한 암호화된 추론을 각각 8초 및 134초에 시연한 첫 번째 시스템입니다.

Abstract: Encrypted AI using fully homomorphic encryption (FHE) provides strong privacy guarantees; but its slow performance has limited practical deployment. Recent works proposed ASICs to accelerate FHE, but require expensive advanced manufacturing processes that constrain their accessibility. GPUs are a far more accessible platform, but achieving ASIC-level performance using GPUs has remained elusive. Furthermore, state-of-the-art approaches primarily focus on small models that fit comfortably within a single device. Supporting large models such as LLMs in FHE introduces a dramatic increase in computational complexity that requires optimized GPU kernels, along with managing terabyte-scale memory footprints that far exceed the capacity of a single GPU. This paper presents Cerium, a multi-GPU framework for FHE inference on large models. Cerium integrates a domain-specific language, an optimizing compiler, and a runtime system to automatically generate high-performance GPU kernels, manage terabyte-scale memory footprints, and parallelize computation across multiple GPUs. It introduces new IR constructs, compiler passes, sparse polynomial representations, memory-efficient data layouts, and communication-aware parallelization techniques that together enable encrypted inference for models ranging from small CNNs to Llama3-8B. We build Cerium on NVIDIA GPUs and demonstrate significant performance gains. For small models, Cerium outperforms expert-written hand-optimized GPU libraries by up to 2.25 times. Cerium achieves performance competitive with state-of-the-art FHE ASICs, outright matching prior FHE ASIC CraterLake. It is the first GPU system to execute bootstrapping in under 10 milliseconds, achieving 7.5 milliseconds, and is the first to demonstrate encrypted inference for BERT-Base and Llama3-8B in 8 seconds and 134 seconds, respectively.

</details>


### [16] [Leveraging FPGAs for Homomorphic Matrix-Vector Multiplication in Oblivious Message Retrieval](https://arxiv.org/abs/2512.11690)
*Grant Bosworth,Keewoo Lee,Sunwoong Kim*

Main category: cs.CR

TL;DR: 이 논문은 메타데이터 보호를 위한 하드웨어 아키텍처를 제안하며, 동형 암호화를 사용하는 메시지 검색의 성능을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 메시지의 내용은 종단 간 암호화로 보호되지만, 메타데이터는 보호되지 않아 발신자와 수신자 정보를 노출합니다. 메타데이터를 보호하기 위한 한 가지 방법은 발신자가 암호화된 메시지를 공개 게시판에 게시하고 수신자가 관련 메시지를 검색하는 것입니다.

Method: 이 논문은 동형 암호화(HE)를 활용하여 자원 풍부한 서버에 검색을 위임하고 개인 정보를 보호하는 방식을 개선합니다. 핵심 과정은 게시판에서 수신자를 위한 관련 메시지를 동형적으로 탐지하는 것이며, 이 과정은 비밀번호 벡터와 평문 행렬 간의 광범위한 곱셈과 동형 회전을 포함하는 전문화된 행렬-벡터 곱셈 알고리즘에 의존합니다.

Result: 제안된 하드웨어 가속기는 소프트웨어 구현과 비교하여 13.86배의 속도 향상을 달성합니다.

Conclusion: 제안된 아키텍처는 동형 행렬-벡터 곱셈을 가속화하여 OMR 프로세스의 실용성을 높이고 전반적으로 사용자 경험을 향상시킵니다.

Abstract: While end-to-end encryption protects the content of messages, it does not secure metadata, which exposes sender and receiver information through traffic analysis. A plausible approach to protecting this metadata is to have senders post encrypted messages on a public bulletin board and receivers scan it for relevant messages. Oblivious message retrieval (OMR) leverages homomorphic encryption (HE) to improve user experience in this solution by delegating the scan to a resource-rich server while preserving privacy. A key process in OMR is the homomorphic detection of pertinent messages for the receiver from the bulletin board. It relies on a specialized matrix-vector multiplication algorithm, which involves extensive multiplications between ciphertext vectors and plaintext matrices, as well as homomorphic rotations. The computationally intensive nature of this process limits the practicality of OMR. To address this challenge, this paper proposes a hardware architecture to accelerate the matrix-vector multiplication algorithm. The building homomorphic operators in this algorithm are implemented using high-level synthesis, with design parameters for different parallelism levels. These operators are then deployed on a field-programmable gate array platform using an efficient design space exploration strategy to accelerate homomorphic matrix-vector multiplication. Compared to a software implementation, the proposed hardware accelerator achieves a 13.86x speedup.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration](https://arxiv.org/abs/2512.11213)
*Dongwon Jung,Peng Shi,Yi Zhang*

Main category: cs.AI

TL;DR: 시험 시간 계산 규모를 확장하면 추가 교육 없이 대형 언어 모델의 성능이 향상됩니다.


<details>
  <summary>Details</summary>
Motivation: 테스트 시간 동안의 협업을 촉진하고 예산 제약 하에 에이전트 간 계산을 배포하기 위한 체계적인 메커니즘이 존재하지 않습니다.

Method: FutureWeaver는 고정된 예산 하에 다중 에이전트 시스템에서 시험 시간 계산 할당을 계획하고 최적화하는 프레임워크입니다.

Result: FutureWeaver는 여러 예산 설정에서 기준선을 지속적으로 능가하는 성능을 보여줍니다.

Conclusion: FutureWeaver는 추론 시간 최적화에서 다중 에이전트 협업을 위해 효과적이임을 검증합니다.

Abstract: Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.

</details>


### [18] [A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation](https://arxiv.org/abs/2512.11270)
*Hong Je-Gal,Chan-Bin Yi,Hyun-Suk Lee*

Main category: cs.AI

TL;DR: A-LAMP는 비공식 언어 설명을 자동으로 MDP와 정책으로 변환하여 RL 태스크에서의 정책 생성을 향상시킵니다.


<details>
  <summary>Details</summary>
Motivation: 강화 학습을 실제 작업에 적용하기 위한 과정의 자동화 필요성.

Method: 자유 형식 자연어 작업 설명을 MDP로 변환하고, 훈련 정책을 생성하는 LLM 기반 프레임워크 A-LAMP를 도입.

Result: A-LAMP는 고전 제어 및 사용자 정의 RL 도메인 모두에서 정책 생성 능력이 단일 최첨단 LLM 모델보다 높습니다.

Conclusion: A-LAMP는 작업의 최적성을 보존하는 환경 및 정책을 생성하며, 그 정확성과 신뢰성을 확인했습니다.

Abstract: Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misaligned objectives, which often impede policy training. We introduce an agentic large language model (LLM)-based framework for automated MDP modeling and policy generation (A-LAMP), that automatically translates free-form natural language task descriptions into an MDP formulation and trained policy. The framework decomposes modeling, coding, and training into verifiable stages, ensuring semantic alignment throughout the pipeline. Across both classic control and custom RL domains, A-LAMP consistently achieves higher policy generation capability than a single state-of-the-art LLM model. Notably, even its lightweight variant, which is built on smaller language models, approaches the performance of much larger models. Failure analysis reveals why these improvements occur. In addition, a case study also demonstrates that A-LAMP generates environments and policies that preserve the task's optimality, confirming its correctness and reliability.

</details>


### [19] [TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning](https://arxiv.org/abs/2512.11271)
*Yuxing Chen,Basem Suleiman,Qifan Chen*

Main category: cs.AI

TL;DR: TriFlow는 사용자 요청을 실행 가능한 여행 일程으로 변환하는 진보적인 다중 에이전트 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 현실적인 여행 계획은 사용자 요청을 실행 가능한 일정을 만드는 동시에 엄격한 공간적, 시간적, 예산적 제약을 충족해야 합니다.

Method: TriFlow는 검색, 계획, 관리의 세 단계 파이프라인을 통해 구조적 추론과 언어 기반 유연성을 통합하는 다중 에이전트 프레임워크입니다.

Result: TravelPlanner와 TripTailor 벤치마크 평가에서 각각 91.1% 및 97%의 최종 통과율을 달성하며 현재 SOTA에 비해 10배 이상의 실행 시간 효율성을 개선했습니다.

Conclusion: TriFlow는 계획의 실행 가능성과 개인화를 보장하기 위해 제약 일관성 있는 일정을 조립하고 제한된 반복 정제를 수행합니다.

Abstract: Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, often producing infeasible or costly plans. To address these limitations, we present TriFlow, a progressive multi-agent framework that unifies structured reasoning and language-based flexibility through a three-stage pipeline of retrieval, planning, and governance. By this design, TriFlow progressively narrows the search space, assembles constraint-consistent itineraries via rule-LLM collaboration, and performs bounded iterative refinement to ensure global feasibility and personalisation. Evaluations on TravelPlanner and TripTailor benchmarks demonstrated state-of-the-art results, achieving 91.1% and 97% final pass rates, respectively, with over 10x runtime efficiency improvement compared to current SOTA.

</details>


### [20] [Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance](https://arxiv.org/abs/2512.11421)
*Gonca Gürsun*

Main category: cs.AI

TL;DR: 본 논문은 대형 언어 모델(LLM)이 제공할 수 있는 신뢰할 수 있는 동작을 위한 태스크 완료 프레임워크를 제시합니다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델이 다중 턴 작업에서 보이는 신뢰성 및 검증 가능성이 부족함을 해결하기 위해.

Method: 경량 태스크 프로파일러, 검증 가능한 관찰-행동 매핑을 학습하는 추론 모듈, 제약 준수를 강제하는 생성을 위한 모듈로 구성된 프레임워크를 통합합니다.

Result: 에이전트가 환경과 상호작용함에 따라 이 구성 요소들이 공동 진화하여 신뢰할 수 있는 행동을 생성함을 보여줍니다.

Conclusion: 제안된 프레임워크는 LLMS 기반 에이전트가 명확한 행동 지침에 따라 작동할 수 있도록 지원합니다.

Abstract: Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.
  The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.

</details>


### [21] [AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints](https://arxiv.org/abs/2512.11426)
*Shuowei Cai,Yansong Ning,Hao Liu*

Main category: cs.AI

TL;DR: 대형 언어 모델 기반의 다중 에이전트 시스템이 웹 기반 응용 프로그램에 필수적이며, 이 연구에서는 명시적인 토큰 비용과 지연 시간을 고려하여 비용 효율적인 MAS를 설계하는 AgentBalance 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 비용 효율성은 대규모 배포에 있어 주요 제약 조건이 되고 있으며, MAS의 성능을 높이기 위한 최적화가 필요하다.

Method: AgentBalance는 먼저 백본 중심의 에이전트 생성, 이후 적응형 MAS 토폴로지 생성을 통해 비용 효율적인 MAS를 구축한다.

Result: 실험 결과, AgentBalance는 매칭된 토큰 비용 및 지연 예산 하에서 각각 최대 10% 및 22%의 성능 향상을 달성했다.

Conclusion: AgentBalance는 기존 MAS의 성능을 향상시키고, 새로운 LLM에 대해서도 잘 일반화되어 실제 예산 인식 배치를 지원한다.

Abstract: Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance

</details>


### [22] [Back to the Baseline: Examining Baseline Effects on Explainability Metrics](https://arxiv.org/abs/2512.11433)
*Agustin Martin Picard,Thibaut Boissin,Varshini Subhash,Rémi Cadène,Thomas Fel*

Main category: cs.AI

TL;DR: 이 논문에서는 서로 다른 기초선을 사용할 때 귀속 방법의 평가에서 발생하는 문제점에 대해 논의하고, 새로운 기초선을 제안합니다.


<details>
  <summary>Details</summary>
Motivation: 귀속 방법의 평가에서 기초선 선택이 특정 방법을 선호하게 만드는 문제를 지적하기 위해.

Method: 정보를 제거하고 과도한 분포 외 이미지를 생성하지 않는 기초선의 두 가지 속성을 통해 문제를 연구한다.

Result: 테스트한 기초선이 두 가지 기준을 모두 만족하지 않으며 정보 제거와 OOD 이미지 생성 간에 트레이드오프가 존재함을 보여준다.

Conclusion: 정보를 제거하면서 과도한 OOD 이미지가 아닌 모델 의존적 기초선을 인위적으로 생성하여 기존 기초선과의 트레이드오프를 개선하는 새로운 기초선을 제안한다.

Abstract: Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over others. More concerningly, even a simple linear model with commonly used baselines contradicts itself by designating different optimal methods. A question then arises: which baseline should we use? We propose to study this problem through two desirable properties of a baseline: (i) that it removes information and (ii) that it does not produce overly out-of-distribution (OOD) images. We first show that none of the tested baselines satisfy both criteria, and there appears to be a trade-off among current baselines: either they remove information or they produce a sequence of OOD images. Finally, we introduce a novel baseline by leveraging recent work in feature visualisation to artificially produce a model-dependent baseline that removes information without being overly OOD, thus improving on the trade-off when compared to other existing baselines. Our code is available at https://github.com/deel-ai-papers/Back-to-the-Baseline

</details>


### [23] [Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes](https://arxiv.org/abs/2512.11463)
*Junghwan Lim,Sungmin Lee,Dongseok Kim,Taehyun Kim,Eunhwan Park,Jeesoo Lee,Jeongdoo Lee,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Minsu Ha,Jaeheui Her,Jaeyeon Huh,Hanbin Jung,Changjin Kang,Beomgyu Kim,Minjae Kim,Taewhan Kim,Youngrok Kim,Hyukjin Kweon,Haesol Lee,Kungyu Lee,Dongpin Oh,Yeongjae Park,Bokki Ryu,Dongjoo Weon*

Main category: cs.AI

TL;DR: Motif-2-12.7B-Reasoning은 복잡한 추론과 긴 맥락 이해를 위한 12.7B 파라미터 언어 모델로, 오픈 웨이트 시스템과 독점 모델 간의 간극을 메우기 위해 설계되었습니다.


<details>
  <summary>Details</summary>
Motivation: 모델 붕괴 및 훈련 불안정성과 같은 일반적인 문제를 해결하기 위해 이 논문은 포괄적이고 재현 가능한 훈련 방법론을 제시합니다.

Method: 64K 토큰 맥락을 위한 메모리 효율적인 인프라와 하이브리드 병렬 처리, 커널 수준 최적화를 결합한 두 단계의 지도 세밀 조정(SFT) 커리큘럼을 사용합니다.

Result: Motif-2-12.7B-Reasoning은 수학, 코딩 및 에이전트 벤치마크에서 훨씬 더 큰 파라미터 수를 가진 모델들과 비교할 수 있는 성능을 보여줍니다.

Conclusion: 이 모델은 경쟁력 있는 오픈 모델과 현실적인 컴퓨팅 제약 하에서 추론 기능을 확장하기 위한 실용적인 청사진을 제공합니다.

Abstract: We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning adaptation, we propose a comprehensive, reproducible training recipe spanning system, data, and algorithmic optimizations. Our approach combines memory-efficient infrastructure for 64K-token contexts using hybrid parallelism and kernel-level optimizations with a two-stage Supervised Fine-Tuning (SFT) curriculum that mitigates distribution mismatch through verified, aligned synthetic data. Furthermore, we detail a robust Reinforcement Learning Fine-Tuning (RLFT) pipeline that stabilizes training via difficulty-aware data filtering and mixed-policy trajectory reuse. Empirical results demonstrate that Motif-2-12.7B-Reasoning achieves performance comparable to models with significantly larger parameter counts across mathematics, coding, and agentic benchmarks, offering the community a competitive open model and a practical blueprint for scaling reasoning capabilities under realistic compute constraints.

</details>


### [24] [General-purpose AI models can generate actionable knowledge on agroecological crop protection](https://arxiv.org/abs/2512.11474)
*Kris A. G. Wyckhuys*

Main category: cs.AI

TL;DR: 생성적 인공지능(AI)은 과학 지식을 민주화하고 명확하고 실행 가능한 정보로 전환할 잠재력을 제공하지만 농식품 과학 분야에서의 적용은 아직 탐색되지 않았다.


<details>
  <summary>Details</summary>
Motivation: 농식품 과학에서의 생성적 인공지능(AI)의 활용이 미비한 가운데, 이를 통해 agroecological crop protection에 대한 과학 지식을 검증하고자 했다.

Method: 웹 기반 및 비웹 기반 대형 언어 모델(LLM), 즉 DeepSeek와 무료 버전의 ChatGPT를 비교하여 9가지 주요 해충, 잡초 및 식물 질병에 대한 사실적 정확도, 데이터 일관성, 지식의 폭을 평가하였다.

Result: DeepSeek는 4.8-49.7배 더 많은 문헌을 검토하였고, ChatGPT보다 1.6-2.4배 더 많은 생물학적 방제제 및 관리 솔루션을 보고하였다. 또한, DeepSeek는 21.6% 높은 효능 추정치를 보고하고 더 나은 데이터 일관성을 보여주었으며, 해충의 정체성과 관리 전술의 현실적인 효과를 나타냈다.

Conclusion: 엄격한 인간의 감시와 함께 사용될 경우, LLM은 농장 수준의 의사 결정을 지원하고 과학적 창의력을 발휘할 수 있는 강력한 도구가 될 수 있다.

Abstract: Generative artificial intelligence (AI) offers potential for democratizing scientific knowledge and converting this to clear, actionable information, yet its application in agri-food science remains unexplored. Here, we verify the scientific knowledge on agroecological crop protection that is generated by either web-grounded or non-grounded large language models (LLMs), i.e., DeepSeek versus the free-tier version of ChatGPT. For nine globally limiting pests, weeds, and plant diseases, we assessed the factual accuracy, data consistency, and breadth of knowledge or data completeness of each LLM. Overall, DeepSeek consistently screened a 4.8-49.7-fold larger literature corpus and reported 1.6-2.4-fold more biological control agents or management solutions than ChatGPT. As a result, DeepSeek reported 21.6% higher efficacy estimates, exhibited greater laboratory-to-field data consistency, and showed more realistic effects of pest identity and management tactics. However, both models hallucinated, i.e., fabricated fictitious agents or references, reported on implausible ecological interactions or outcomes, confused old and new scientific nomenclatures, and omitted data on key agents or solutions. Despite these shortcomings, both LLMs correctly reported low-resolution efficacy trends. Overall, when paired with rigorous human oversight, LLMs may pose a powerful tool to support farm-level decision-making and unleash scientific creativity.

</details>


### [25] [BAID: A Benchmark for Bias Assessment of AI Detectors](https://arxiv.org/abs/2512.11505)
*Priyam Basu,Yunfeng Zhang,Vipul Raheja*

Main category: cs.AI

TL;DR: AI 생성 텍스트 탐지기에서의 편향 문제를 평가하기 위한 BAID 프레임워크를 제안하고, 200,000개의 샘플을 사용하여 검토한 결과 저조한 탐지 성능을 보이는 점을 강조합니다.


<details>
  <summary>Details</summary>
Motivation: AI 생성 텍스트 탐지기는 교육 및 전문 분야에서 점점 더 사용되고 있지만, 특히 영어 학습자에 대한 편향 문제가 존재하며 이를 체계적으로 평가할 필요가 있습니다.

Method: BAID라는 포괄적인 평가 프레임워크를 제안하고, 7가지 주요 카테고리에 걸쳐 200,000개의 샘플을 수집하고, 각 샘플의 합성 버전을 생성하여 하위 그룹의 특정 작문 스타일을 반영합니다.

Result: 4개의 최신 오픈 소스 AI 텍스트 탐지기를 평가한 결과, 특히 소외된 집단의 텍스트에 대해 탐지 성능에서 일관된 차이를 발견했습니다.

Conclusion: AI 탐지기의 감사를 위한 확장 가능하고 투명한 접근 방식을 제공하며, 이러한 도구가 공공 사용을 위해 배포되기 전에 편향을 인식한 평가의 필요성을 강조합니다.

Abstract: AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 major categories: demographics, age, educational grade level, dialect, formality, political leaning, and topic. We also generated synthetic versions of each sample with carefully crafted prompts to preserve the original content while reflecting subgroup-specific writing styles. Using this, we evaluate four open-source state-of-the-art AI text detectors and find consistent disparities in detection performance, particularly low recall rates for texts from underrepresented groups. Our contributions provide a scalable, transparent approach for auditing AI detectors and emphasize the need for bias-aware evaluation before these tools are deployed for public use.

</details>


### [26] [EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection](https://arxiv.org/abs/2512.11506)
*Georgios Kaoukis,Ioannis Aris Koufopoulos,Psaroudaki Eleni,Danae Pla Karidi,Evaggelia Pitoura,George Papastefanatos,Panayiotis Tsaparas*

Main category: cs.AI

TL;DR: EmeraldMind는 기업의 ESG 보고서를 기반으로 하는 사실 중심의 프레임워크로, 그린워싱 탐지 자동화를 지원하여 환경 진전을 위한 지능형 시스템을 설계한다.


<details>
  <summary>Details</summary>
Motivation: AI와 웹 에이전트가 의사결정에 널리 사용됨에 따라, 지속 가능성 노력을 지원하고 잘못된 정보로부터 보호하는 지능형 시스템을 설계하는 것이 중요하다.

Method: EmeraldMind는 다양한 기업 ESG 보고서에서 EmeraldGraph를 구축하고, 검증 가능한 증거를 발굴하여 주장 평가를 지원하며, 청구에 대한 투명하고 증거 기반인 판결을 제공한다.

Result: 실험을 통해 EmeraldMind는 경쟁력 있는 정확도와 더 큰 범위, 우수한 설명 품질을 달성하며, 일반 LLM보다 더 나은 성능을 보였다.

Conclusion: EmeraldMind는 그린워싱 탐지의 혁신적인 방법을 제공하며, 추가적인 조정이나 재교육 없이 사용할 수 있다.

Abstract: As AI and web agents become pervasive in decision-making, it is critical to design intelligent systems that not only support sustainability efforts but also guard against misinformation. Greenwashing, i.e., misleading corporate sustainability claims, poses a major challenge to environmental progress. To address this challenge, we introduce EmeraldMind, a fact-centric framework integrating a domain-specific knowledge graph with retrieval-augmented generation to automate greenwashing detection. EmeraldMind builds the EmeraldGraph from diverse corporate ESG (environmental, social, and governance) reports, surfacing verifiable evidence, often missing in generic knowledge bases, and supporting large language models in claim assessment. The framework delivers justification-centric classifications, presenting transparent, evidence-backed verdicts and abstaining responsibly when claims cannot be verified. Experiments on a new greenwashing claims dataset demonstrate that EmeraldMind achieves competitive accuracy, greater coverage, and superior explanation quality compared to generic LLMs, without the need for fine-tuning or retraining.

</details>


### [27] [MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition](https://arxiv.org/abs/2512.11682)
*Tim Cofala,Christian Kalfar,Jingge Xiao,Johanna Schrader,Michelle Tang,Wolfgang Nejdl*

Main category: cs.AI

TL;DR: 이 논문은 임상 의학에서의 치료 결정 과정에서 AI의 역할과 TxAgent라는 에이전틱 AI 방법의 효능을 설명합니다.


<details>
  <summary>Details</summary>
Motivation: 치료 결정은 환자 특성, 질병 과정, 약리학적 요인 간의 복잡한 상호작용을 포함하며, 이는 신뢰할 수 있는 생물 의학 지식에 기반한 강력한 다단계 추론을 요구합니다.

Method: TxAgent는 FDA Drug API, OpenTargets, Monarch 리소스를 통합한 ToolUniverse를 통해 동적으로 기능 호출을 생성하고 실행하는 Llama-3.1-8B 모델을 사용합니다.

Result: 모델의 성능은 기능 호출에 대한 검색 품질에 영향을 받으며, 도구 검색 전략의 개선을 통해 성능 향상을 보여줍니다.

Conclusion: 우리는 치료 추론 시스템에 대한 평가 프로토콜을 제시하며, 이 작업은 Open Science 분야에서 우수상을 수상했습니다.

Abstract: Therapeutic decision-making in clinical medicine constitutes a high-stakes domain in which AI guidance interacts with complex interactions among patient characteristics, disease processes, and pharmacological agents. Tasks such as drug recommendation, treatment planning, and adverse-effect prediction demand robust, multi-step reasoning grounded in reliable biomedical knowledge. Agentic AI methods, exemplified by TxAgent, address these challenges through iterative retrieval-augmented generation (RAG). TxAgent employs a fine-tuned Llama-3.1-8B model that dynamically generates and executes function calls to a unified biomedical tool suite (ToolUniverse), integrating FDA Drug API, OpenTargets, and Monarch resources to ensure access to current therapeutic information. In contrast to general-purpose RAG systems, medical applications impose stringent safety constraints, rendering the accuracy of both the reasoning trace and the sequence of tool invocations critical. These considerations motivate evaluation protocols treating token-level reasoning and tool-usage behaviors as explicit supervision signals. This work presents insights derived from our participation in the CURE-Bench NeurIPS 2025 Challenge, which benchmarks therapeutic-reasoning systems using metrics that assess correctness, tool utilization, and reasoning quality. We analyze how retrieval quality for function (tool) calls influences overall model performance and demonstrate performance gains achieved through improved tool-retrieval strategies. Our work was awarded the Excellence Award in Open Science. Complete information can be found at https://curebench.ai/.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [28] [Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control](https://arxiv.org/abs/2512.11247)
*Iftekharul Islam,Weizi Li*

Main category: cs.MA

TL;DR: 혼합 교통 제어의 효율성, 공정성 및 안전성을 고려한 새로운 방법이 제안되었다. 이 방법은 대기 시간을 줄이고 고립 상태를 예방하며 연료 효율성을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 효율성, 공정성 및 안전성을 균형 있게 유지하는 효과적인 혼합 교통 제어가 필요하다.

Method: 다중 목표 강화 학습을 사용한 지역 교차로 제어와 네트워크 차원 조정을 위한 전략적 경로 설정을 결합한 계층적 프레임워크를 제안하였다. 이를 통해 충돌 회피를 위한 위험 신호와 모든 교통 흐름의 공정한 서비스를 보장하는 대기열 공정성 패널티를 도입하였다.

Result: 실제 네트워크에서의 광범위한 실험을 통해 평균 대기 시간을 최대 53% 감소시키고 최대 고립 상태를 86%까지 줄이며 충돌 비율 또한 86%까지 감소시키는 성과를 거두었다.

Conclusion: 전략적 경로 설정의 효과는 RV 침투율이 높아질수록 증가하며, 공정성과 안전성을 위한 다중 목표 최적화의 이점이 드러났다.

Abstract: Effective mixed traffic control requires balancing efficiency, fairness, and safety. Existing approaches excel at optimizing efficiency and enforcing safety constraints but lack mechanisms to ensure equitable service, resulting in systematic starvation of vehicles on low-demand approaches. We propose a hierarchical framework combining multi-objective reinforcement learning for local intersection control with strategic routing for network-level coordination. Our approach introduces a Conflict Threat Vector that provides agents with explicit risk signals for proactive conflict avoidance, and a queue parity penalty that ensures equitable service across all traffic streams. Extensive experiments on a real-world network across different robot vehicle (RV) penetration rates demonstrate substantial improvements: up to 53% reductions in average wait time, up to 86% reductions in maximum starvation, and up to 86\% reduction in conflict rate compared to baselines, while maintaining fuel efficiency. Our analysis reveals that strategic routing effectiveness scales with RV penetration, becoming increasingly valuable at higher autonomy levels. The results demonstrate that multi-objective optimization through well-curated reward functions paired with strategic RV routing yields significant benefits in fairness and safety metrics critical for equitable mixed-autonomy deployment.

</details>


### [29] [Evaluating Cooperative Resilience in Multiagent Systems: A Comparison Between Humans and LLMs](https://arxiv.org/abs/2512.11689)
*Manuela Chacon-Chamorro,Juan Sebastián Pinzón,Rubén Manrique,Luis Felipe Giraldo,Nicanor Quijano*

Main category: cs.MA

TL;DR: 이 논문은 다중 에이전트 시스템에서 협력 회복력에 대한 비교 분석을 제공합니다.


<details>
  <summary>Details</summary>
Motivation: 인간과 LLM 기반 에이전트 간의 협력 회복력 비교를 통해 인공지능 에이전트가 사회적 및 회복력 있는 행동을 촉진할 수 있도록 설계하는 데 기여하기 위해.

Method: 혼합 동기 사회적 딜레마 환경에서 인간 그룹과 LLM 기반 에이전트를 비교하고, 명시적 의사소통의 유무에 따라 그들을 평가했습니다.

Result: 의사소통이 있는 인간 그룹이 가장 높은 협력 회복력을 기록했고, LLM 에이전트의 회복력도 향상되었지만 여전히 인간 수준에는 미치지 못했습니다.

Conclusion: 인간의 의사결정 방식이 인공지능 에이전트 디자인에 중요한 통찰을 제공할 수 있다는 것을 시사합니다.

Abstract: This paper presents a comparative analysis of cooperative resilience in multi-agent systems, defined as the ability to anticipate, resist, recover from, and transform to disruptive events that affect collective well-being. We focus on mixed-motive social dilemmas instantiated as a \textit{Tragedy of the Commons} environment from the Melting Pot suite, where we systematically compare human groups and Large Language Model (LLM)-based agents, each evaluated with and without explicit communication. Cooperative resilience is assessed under a continuously disruptive condition induced by a persistent unsustainable consumption bot, together with intermittent environmental shocks implemented as stochastic removal of shared resources across scenarios. This experimental design establishes a benchmark for cooperative resilience across agent architectures and interaction modalities, constituting a key step toward systematically comparing humans and LLM-based agents. Using this framework, we find that human groups with communication achieve the highest cooperative resilience compared to all other groups. Communication also improves the resilience of LLM agents, but their performance remains below human levels. Motivated by the performance of humans, we further examine a long-horizon setting with harsher environmental conditions, where humans sustain the shared resource and maintain high resilience in diverse disruption scenarios. Together, these results suggest that human decision-making under adverse social conditions can inform the design of artificial agents that promote prosocial and resilient behaviors.

</details>
